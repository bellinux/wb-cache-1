1|1238|Public
40|$|International audienceThis present paper {{describes}} a 3 -D geological {{model in the}} Upper Rhine Graben, around the EGS (Enhanced Geothermal System) Soultz site (France). This model is a 30 x 20 x 6 km geological model built from the surface to the crystalline basement. The goal is to visualize the complex fault network of the graben by federating the knowledge on this specific area. The building of the 3 -D geological model is based on two main kinds of data: (1) seismic profile interpretations and (<b>2)</b> <b>borehole</b> <b>data.</b> The seismic profiles have been acquired for oil exploration in the 70 - 80 's, and reprocessed recently {{in the framework of}} various projects. The 2 -D information is interpolated to the whole 3 -D space using a geostatistical analysis. For our model, a network of 26 fault has been built. The orientation of the major faults is NNE-SSW (i. e. Rhenish direction), with a main eastward dipping. Secondary, principally antithetic faults, trend N-S to NNW-SSE, with an average dip of 60 °. This 3 -D geological model could be now used as a basis for many exploration investigations and different kinds of modelling...|$|E
40|$|Abstract: Mapping of {{groundwater}} aquifers has historically followed {{the path of}} 2 D geological maps and interpreted cross sections derived from available geological <b>borehole</b> <b>data.</b> Isopachs or aquifer thicknesses are then derived from data layers. The addition of geophysical interpretation, through methods such as gravity and electro-magnetic surveys provide some confidence of continuity between boreholes. The advent of GIS and modern computer modelling has stretched the data further into the three dimensional digital world {{with the use of}} high-end numerical modelling and high-tech visualisation tools. Input data may be assessed for quality and integrity. However, rarely are the digital data layers assessed by visual inspection. With a visual inspection the influence of individual data points on data layers is more easily accounted for, enabling a more rigorous assessment of the quality and or suitability of input data. Visual inspection aids in the identification of geological structures that often have significant impacts on groundwater dynamics, where such structures are often not identifiable from <b>2</b> dimensional <b>borehole</b> <b>data.</b> Visual inspection also allows a range of experts to view the aquifers in a multi- dimensional state and apply additional knowledge {{to the development of the}} models. While many models may be based upon all available data, we argue that without visual assessment they are not based upon all available interpretation and assessment tools. We propose that models of complicate...|$|R
50|$|The raw dataset {{that are}} used for {{industrial}} mineral deposit modeling can be classified into two major types: <b>borehole</b> and non-borehole <b>data.</b> The management of <b>borehole</b> <b>data</b> {{is very different from}} non-borehole <b>data.</b> Specifically, <b>borehole</b> <b>data</b> requires a relational database management system (e.g. Access, FileMaker, SQL, Oracle,) whereas non-borehole data (with the exception of land ownership) can be handled with simple “flat” file managers (e.g. Microsoft Excel, Lotus 1-2-3).|$|R
40|$|Joint {{inversion}} of surface and three-component <b>borehole</b> magnetic <b>data</b> Yaoguo Li ∗ and Douglas W. Oldenburg‡ The {{inversion of}} magnetic data is inherently non-unique {{with respect to}} the distance between the source and observation locations. This manifests itself as an am-biguity in the source depth when surface data are in-verted and as an ambiguity in the distance between the source and <b>boreholes</b> if <b>borehole</b> <b>data</b> are inverted. Joint inversion of surface and <b>borehole</b> <b>data</b> can help to re-duce this nonuniqueness. To achieve this, we develop an algorithm for inverting data sets that have arbitrary observation locations in boreholes and above the sur-face. The algorithm depends upon weighting functions that counteract the geometric decay of magnetic ker-nels with distance from the observer. We apply these weighting functions to the inversion of three-component magnetic <b>data</b> collected in <b>boreholes</b> and then to the joint inversion of surface and <b>borehole</b> <b>data.</b> Both syn-thetic and field data sets are used to illustrate the new inversion algorithm. When <b>borehole</b> <b>data</b> are inverted directly, three-component data are far more useful in constructing good susceptibility models than are single-component data. However, either can be used effectively in a joint inversion with surface data to produce models that are superior to those obtained by inversion of sur-face data alone...|$|R
30|$|In contrast, the {{structure}} of the upper crystalline crust is based on the surface geology (Figure  4) extrapolated to great depth and also <b>borehole</b> <b>data.</b>|$|R
2500|$|Integrating diverse {{types of}} {{observations}} into 3D geomodels: geological mapping <b>data,</b> <b>borehole</b> <b>data</b> and interpretations, seismic images and interpretations, potential field data, well test data, etc., ...|$|R
40|$|Abstract: Taking 3 D <b>borehole</b> <b>data</b> for {{research}} object, an algorithm flow of volume rendering based GPU is given. According {{to the limited}} and discrete characteristics of 3 D <b>borehole</b> <b>data,</b> Kriging interpolation algorithm is used to construct a regular grid data model. Ray-casting algorithm based on GPU is realized with the Visualization Toolkit (VTK). The results show that after the application of volume rendering technology, {{it is easy to}} practice the functions of arbitrary section displaying, volume clipping and volume data extracting which are practicalities...|$|R
40|$|Four Electrical Resistivity Tomography (ERT) {{profiles}} and <b>borehole</b> <b>data</b> {{were acquired}} {{on the front}} face of the earth-filled dam and on the flanks, constituting Lake # 1, in order to locate the seepage zone, the flow path, and to determine possible reasons of the seepage. The seepage, observed {{a year after the}} construction in the southwestern part of the lake, was severe and could cause further softening, slippage and erosion of soil, developing of pipe holes, increasing the water outflow and risk to the embankment integrity. The owner agreed to drain the lake in order to acquire geophysical and <b>borehole</b> <b>data.</b> Based on the analyses of the acquired ERT and <b>borehole</b> <b>data,</b> four solution-widened fracture zones trending from southwest to northeast were identified. It was concluded that the seepage pathway beneath the dam was through a solution-widened fracture zone, the top of which constituted the original stream channel...|$|R
40|$|Delaunay {{triangulation}} is {{a commonly}} used method for generating surface models which have many uses, including height interpolation and volumetric analysis. This method {{can be adapted}} to accurate volume estimation using <b>borehole</b> <b>data.</b> This paper compares volume estimation of three different techniques which use triangulated surfaces for volume calculation. Some of the problems in using Delaunay triangulation for volume calculation are identified and modifications are suggested to adapt it for more accurate volume estimation. A routine for automated volume estimation from <b>borehole</b> <b>data,</b> which incorporates some of these techniques, has been developed. 1...|$|R
40|$|Flood basalt {{successions}} cover many. potentially prospective sedimentary basins world-wide, and a {{few instances}} exist of intra-basalt petroleum discoveries. However, {{little is known about}} the architecture and rock propel-ties of the lava flows, intrusions and other lithologies that make up these successions. We present a simple, effective method of obtaining information from <b>borehole</b> <b>data</b> on the different volcanic facies within a flood basalt succession. Our aims are: (1) to provide a means of determining proportions of different volcanic facies without detailed examination of <b>borehole</b> <b>data</b> or where <b>borehole</b> <b>data</b> are limited; (<b>2)</b> to explore the relationship between onshore and offshore observations. The facies classification scheme providing the framework for this research includes tabular-classic lava flows, compound-braided lava flows, hyaloclastites and intrusions. We show how this scheme can increase our knowledge of the offshore succession and can be useful in hydrocarbon exploration. In the Faroe Islands, three different basalt formations display a range of facies onshore. Boreholes have been drilled through these, and several kilometres' depth of log data collected. The proximity of these boreholes to onshore observations allows the identification of different facies within the wireline log data. This work demonstrates that histograms of P-wave velocities provide an efficient method of identifying the different facies, and we also explore why these distributions are so different. When applied to <b>borehole</b> <b>data</b> from published ODP wells and one commercial well, it is possible to estimate proportions of the different volcanic facies using the velocity distributions alone...|$|R
40|$|At the Violet Grove pilot project, near Drayton Valley, Alberta, CO 2 {{is being}} {{injected}} into the Cardium Formation in the Pembina Oil Field for enhanced recovery and carbon sequestration purposes. The reservoir is being monitored for changes using simultaneously acquired timelapse multicomponent surface and borehole seismic surveys. The baseline survey was acquired in March 2005 prior to CO 2 injection. The second survey was acquired in December 2005 after eight months of CO <b>2</b> injection. The <b>borehole</b> seismic <b>data</b> displays higher bandwidth and increased resolution {{as compared to the}} surface seismic data; in particular, the PS-wave <b>borehole</b> seismic <b>data</b> shows significantly better results. Prelimary comparisons between the baseline and monitor borehole seismic surveys show an increase in amplitudes at the reservoir...|$|R
40|$|Students {{investigate}} {{the characteristics of}} permafrost and investigate permafrost <b>borehole</b> <b>data</b> to learn about recent changes in the permafrost. They analyze the changing concentrations in atmospheric methane and correlate the change to thawing permafrost. Educational levels: Middle school, High school, General public...|$|R
40|$|The natural {{complexities}} of petroleum reservoir systems {{continue to provide}} a challenge to geoscientists. In petroleum geology, exploration and production wells are often analysedusing image logs and the use ofall the available <b>borehole</b> <b>data</b> to completely characterize the reservoir potentials and performance is a...|$|R
40|$|Abstract Seismic shear-wave {{velocity}} as {{a function}} of depth for generic rock sites has been estimated from <b>borehole</b> <b>data</b> and studies of crustal velocities, and these velocities have been used to compute frequency-dependent amplifications for zero attenuation for use in simulations of strong ground motion. We define a genetic rock site as one whose velocity at shallow depths equals the average of those from the rock sites sampled by the <b>borehole</b> <b>data.</b> Most of the boreholes are in populated areas; for that reason, the rock sites sampled are of particular engineering significance. We consider two genetic rock sites: rock, corresponding tothe bulk of the <b>borehole</b> <b>data,</b> and very hard rock, such as is found in glaciated regions in large areas of eastern North America or in portions of western North America. The amplifications on rock sites can be in excess of 3. 5 at high frequencies, in contrast o the amplifications of less than 1. 2 on very hard rock sites. The consideration of unattenuated amplification alone is computationally convenient, but what matters for ground-motion estimation is the combined effect of amplification and attenuation. For reasonable values of the attenuation parameter K 0, the combined effect of attenuation and amplification fo...|$|R
40|$|The Hanford Borehole Geologic Information System (HBGIS) is a {{prototype}} web-based {{graphical user interface}} (GUI) for viewing and downloading <b>borehole</b> geologic <b>data.</b> The HBGIS is being developed {{as part of the}} Remediation Decision Support function of the Soil and Groundwater Remediation Project, managed by Fluor Hanford, Inc., Richland, Washington. Recent efforts have focused on improving the functionality of the HBGIS website in order to allow more efficient access and exportation of available data in HBGIS. Users will benefit from enhancements such as a dynamic browsing, user-driven forms, and multi-select options for selecting <b>borehole</b> geologic <b>data</b> for export. The need for translating <b>borehole</b> geologic <b>data</b> into electronic form within the HBGIS continues to increase, and efforts to populate the database continue at an increasing rate. These new web-based tools should help the end user quickly visualize what data are available in HBGIS, select from among these data, and download the <b>borehole</b> geologic <b>data</b> into a consistent and reproducible tabular form. This revised user’s guide supersedes the previous user’s guide (PNNL- 15362) for viewing and downloading data from HBGIS. It contains an updated data dictionary for tables and fields containing <b>borehole</b> geologic <b>data</b> as well as instructions for viewing and downloading <b>borehole</b> geologic <b>data...</b>|$|R
40|$|Improvements in {{computing}} {{speed and}} capacity {{and the increasing}} collection and digitisation of geological data now allow geoscientists to produce meaningful 3 D spatial models of the shallow subsurface in many large urban areas, to predict ground conditions and reduce risk and uncertainty in urban planning. It {{is not yet clear}} how useful this 3 D modelling approach is at smaller urban scales, where poorly characterised anthropogenic deposits (artificial/made ground and fill) form the dominant subsurface material and where the availability of borehole and other geological data is less comprehensive. This is important as it is these smaller urban sites, with complex site history, which frequently form the focus of urban regeneration and redevelopment schemes. This paper examines {{the extent to which the}} 3 D modelling approach previously utilised at large urban scales can be extended to smaller less well-characterised urban sites, using a historic landfill site in Sheepcote Valley, Brighton, UK as a case study. Two 3 D models were generated and compared using GSI 3 D™ software, one using <b>borehole</b> <b>data</b> only, one combining <b>borehole</b> <b>data</b> with local geological maps and results from a desk study (involving collation of available site data, including ground contour plans). These models clearly delimit the overall subsurface geology at the site, and allow visualisation and modelling of the anthropogenic deposits present. Shallow geophysical data collected from the site partially validate the 3 D modelled data, and can improve GSI 3 D™ outputs where boundaries of anthropogenic deposits may not be clearly defined by surface, contour or <b>borehole</b> <b>data.</b> Attribution of geotechnical and geochemical properties to the 3 D model is problematic without intrusive investigations and sampling. However, combining available <b>borehole</b> <b>data,</b> shallow geophysical methods and site histories may allow attribution of generic fill properties, and consequent reduction of urban development risk and uncertainty...|$|R
40|$|In {{conventional}} way, {{investigation of}} the subsurface parameter is determined from <b>boreholes</b> <b>data.</b> However, the information retrieved from a bore log only provides information at a discrete location. Geophysical method such as seismic refraction has been routinely used to compliment the ‘missing’ boreholes information as it offers continuous information along the survey line. This paper presents the relationship between seismic refraction method and borehole logging in a granitic area at Ulu Tiram, Johor. Three lines of seismic survey were carried out to assess the subsurface for quarry development. Two boreholes were drilled along the seismic line {{in the effort to}} find relationship between information gathered from those methods. The seismic survey results are evaluated along with SPT and RQD information. Results for the correlation of seismic refraction survey and <b>borehole</b> <b>data</b> can be used for better subsurface characteristics exploration between <b>boreholes</b> besides providing <b>data</b> rapidly at a relatively low cost and give benefits in terms of work time...|$|R
40|$|In {{areas of}} high {{structural}} complexity (e. g., near salt bodies), <b>borehole</b> seismic <b>data</b> may give detailed subsurface information that cannot {{be obtained from}} surface seismic data. Seismic interferometry (Curtis et al., 2006) opens possibilities for innovative uses of <b>borehole</b> seismic <b>data,</b> because seismic interferometry reconstructs waves that propagate between receivers as i...|$|R
40|$|A {{peat layer}} is {{normally}} {{occurred in the}} Nile Delta at shallow depths, ranging from 5 to 15. 5 meters with a maximum thickness of 3. 5 meters. In this work, the area of southern Mansoura City was covered by a shallow geoelectrical survey aiming to delineate the peat layer to assist the engineers for future planning of the infra structures in the area. The survey included self potential (SP), induced polarization (IP) and time domain electromagnetic (TDEM) techniques. The {{results showed that the}} peat layer is associated with a relatively high chargeability than the surrounding layers. The depths of peat layer that inferred from the SP, IP and high resolution TDEM profiles are highly correlated with the <b>borehole</b> <b>data.</b> In addition, its thickness inferred from the TDEM results are highly correlated with the <b>borehole</b> <b>data.</b> However, the thicknesses of the high chargeabilit...|$|R
40|$|The {{borehole}} gravity {{technique has}} been well established in hydrocarbon exploration geophysics since the 1970 's. The concept behind borehole gravity is simply to measure the variation in the Earth's gravitational field while traveling along a borehole. Densities both close to and far from the borehole {{can be derived from}} such measurements. However, the borehole gravity technique has not yet been routinely used for mineral exploration because gravimeters that fit in the narrower diameter holes used in mineral exploration have not existed. Such gravimeters are now being developed. Complementary investigation and development of interpretation procedures for <b>borehole</b> gravity <b>data</b> in a mineral exploration context are required. Here, results are presented of a study inverting synthetic <b>borehole</b> gravity <b>data</b> for three-dimensional, mineral exploration relevant Earth models. The forward-modelling on which the inversion is based is a finite-difference solution of Poisson's equation. The inversion is performed using a standard minimum-structure algorithm for multiple scenarios of varying borehole locations, amount of <b>borehole</b> <b>data</b> and varying model parameters. The intention is to demonstrate what we can expect to determine about the density variation around and between boreholes given varying amounts and locations of down-hole and surface data. It is observed that the benefits of <b>borehole</b> gravity <b>data</b> depend on the locations of the boreholes relative to the anomalous mass. Inversions which produce images of complex subsurface density distributions are attainable with the most successful models resulting from combined surface and <b>borehole</b> <b>data.</b> Minimum-structure <b>borehole</b> gravity inversion is shown to be a beneficial interpretation option which can provide accurate information of an anomaly's shape with proper depth resolution and density distribution...|$|R
40|$|Geophysical {{methods have}} been used for {{characterization}} of hydrogeologic conditions and/or contaminant distributions at the Hanford site since at least the mid- to late- 1940 s. A review of these geophysical methods is presented in two parts: (1) shallow surface-based geophysical methods and (<b>2)</b> <b>borehole</b> geophysical-logging methods...|$|R
25|$|The Tunbridge Wells Sand Formation {{comprises}} complex cyclic {{sequences of}} siltstones with sandstones and clays, typically fining upwards, and is lithologically {{similar to the}} older Ashdown Formation. It has a total thickness typically {{in the region of}} about 75 m. However, near Haywards Heath <b>borehole</b> <b>data</b> has proven the formation to be up to 150m thick.|$|R
30|$|The twenty-nine story {{residential}} Lions Tower Kotodai is 104  m {{tall and}} {{was constructed in}} 2009. No noticeable structural damage was reported following the earthquake. Given the close proximity to site T 2 and the MYG 013 station, the soil profile at the building was obtained by interpolating the two locations’ <b>borehole</b> <b>data</b> with their relative distances.|$|R
40|$|The paper {{contains}} the experimental research performed in Bucharest like the <b>borehole</b> <b>data</b> (Standard Penetration Test) {{and the data}} obtained from seismic investigations (down-hole prospecting and surface-wave methods). The evaluation of the soils liquefaction resistance {{based on the results}} of the SPT, down-hole prospecting and surface-wave method tests and the use of the earthquake records will be presented...|$|R
50|$|The Tunbridge Wells Sand Formation {{comprises}} complex cyclic {{sequences of}} siltstones with sandstones and clays, typically fining upwards, and is lithologically {{similar to the}} older Ashdown Formation. It has a total thickness typically {{in the region of}} about 75 m. However, near Haywards Heath <b>borehole</b> <b>data</b> has proven the formation to be up to 150m thick.|$|R
40|$|This {{research}} introduces rough sets {{to better}} characterizing spatial relationships and uncertainty in two examples. First, scale issues in census data are addressed. Census data provide demographic and socio-economic information at specific area units. Hence, derived spatial information are scale-dependent leading to uncertainty when analyzing results at different scales. Rough sets mitigate scale distortions and provide scale-sensitivity measure during scale transition. It employs {{the metaphor of}} topology to illustrate the ability of rough sets to retain spatial relationships of adjacency and contiguity. Second, rough sets and transition probability are used to characterize sediment distribution. The study simulates sediment state and transitions for low and high quality <b>borehole</b> <b>data</b> by providing better geological understanding. It also assesses Geological Survey of Canada standardization scheme for classifying <b>borehole</b> <b>data.</b> The utility of rough sets is demonstrated as a knowledge base tool for characterizing uncertainty irrespective of the data under study...|$|R
40|$|Thesis (M. Sc.) [...] Memorial University of Newfoundland, 2009. Earth SciencesIncludes bibliographical {{references}} (leaves 112 - 117). The borehole gravity {{technique has}} been well established in hydrocarbon exploration geophysics since the 1970 's. The concept behind borehole gravity is simply to measure the variation in the Earth's gravitational field while traveling along a borehole. Densities both close to and far from the borehole {{can be derived from}} such measurements. However, the borehole gravity technique has not yet been routinely used for mineral exploration because gravimeters that fit in the narrower diameter holes used in mineral exploration have not existed. Such gravimeters are now being developed. Complementary investigation and development of interpretation procedures for <b>borehole</b> gravity <b>data</b> in a mineral exploration context are required. Here, results are presented of a study inverting synthetic <b>borehole</b> gravity <b>data</b> for three-dimensional, mineral exploration relevant Earth models. The forward-modelling on which the inversion is based is a finite-difference solution of Poisson's equation. The inversion is performed using a standard minimum-structure algorithm for multiple scenarios of varying borehole locations, amount of <b>borehole</b> <b>data</b> and varying model parameters. The intention is to demonstrate what we can expect to determine about the density variation around and between boreholes given varying amounts and locations of down-hole and surface data. It is observed that the benefits of <b>borehole</b> gravity <b>data</b> depend on the locations of the boreholes relative to the anomalous mass. Inversions which produce images of complex subsurface density distributions are attainable with the most successful models resulting from combined surface and <b>borehole</b> <b>data.</b> Minimum-structure <b>borehole</b> gravity inversion is shown to be a beneficial interpretation option which can provide accurate information of an anomaly's shape with proper depth resolution and density distribution...|$|R
30|$|The authors {{conducted}} a comprehensive <b>borehole</b> <b>data</b> {{analysis of the}} Soultz geothermal <b>boreholes.</b> The <b>data</b> collected during the drilling operations included drilling mud losses, natural outflow, gas content, {{and the rate of}} penetration (ROP). Geophysical well logs, such as caliper, gamma ray (GR), bulk density, neutron porosity, and borehole wall images, were used and compared to the mud logging data. The depth match interval of − 4  m between the drilling mud logging data and the geophysical well logging data must be taken into account. To avoid moving these data sets artificially upward or downward, it was decided to leave the data in their own separate depth reference frames.|$|R
30|$|For the {{foreshock}} of the 2016 Kumamoto earthquake, {{the preliminary}} JMA magnitude was 6.5. The moment magnitude I derived from <b>borehole</b> strain <b>data</b> was 6.2, {{as was the}} final moment magnitude (JMA 2018) (Fig.  5 b). For the mainshock of the 2016 Kumamoto earthquake, the preliminary JMA magnitude was 7.3, the moment magnitude I derived from <b>borehole</b> strain <b>data</b> was 7.1, and the final moment magnitude was 7.0 (JMA 2018) (Fig.  5 c). For the 2016 Central Tottori earthquake, the preliminary JMA magnitude was 6.6, the moment magnitude I derived from <b>borehole</b> strain <b>data</b> was 6.0, and the final moment magnitude was 6.2 (JMA 2018) (Fig.  5 d).|$|R
40|$|In {{this paper}} we apply spatial {{database}} and structure {{to render the}} paleo-relief of the Borod Basin. The <b>boreholes</b> <b>data</b> are stored in a spatial database. For the effective surface rendering we use local-Shepard interpolation with variable radius, based on a spatial grid and Delaunay triangulation. The generated pictures are more realistic compared to pictures generated by means of other methods...|$|R
40|$|This paper {{presents}} an inversion algorithm for obtaining azimuthal angle and borehole flexural wave dispersion in an anisotropic formation. The technique constructs an objective function {{that can be}} minimized using standard non-linear inversion methods, which is sensitive to both dispersion and rotation. The method is tested on both synthetic and real <b>borehole</b> <b>data</b> and gives good agreement with traditional processing. ...|$|R
40|$|AbstractAnalysis of {{geophysical}} <b>borehole</b> <b>data</b> {{can often}} be hampered by too much information and noise in the trace leading to subjective interpretation of layer boundaries. Wavelet analysis of <b>borehole</b> <b>data</b> has provided an effective way of mitigating noise and delineating relevant boundaries. We extend wavelet analysis by providing {{a complete set of}} code and functions that will objectively block a geophysical trace based on a derivative operator algorithm that searches for inflection points in the bore log. Layer boundaries detected from the operator output are traced back to a zero-width operator so that boundaries are consistently and objectively detected. Layers are then classified based on importance and analysis is completed by selecting either total number of layers, a portion {{of the total number of}} layers, selection of minimum layer thickness, or layers detected by a specified minimum operator width. We demonstrate the effectiveness of the layer blocking technique by applying it to a case study for alluvial aquifer detection in the Gascoyne River area of Western Australia...|$|R
40|$|The tests {{identified}} Scansoft OmniPage 15 as {{the package}} most {{suited to the}} project requirement. This report describes how we tested different Optical Character Recognition (OCR) packages for use on borehole scans. ScanSoft OmniPage 15, ABBYY FineReader 8, Readiris Pro 10 and TextBridge Pro 11, were analysed against certain criteria to determine which one would be more beneficial by increasing the speed of <b>borehole</b> <b>data</b> entry...|$|R
30|$|The {{groundwater}} <b>borehole</b> <b>data</b> {{were obtained}} from the General Commission of Groundwater/Ministry of Water Resources, Iraq. The data involved locations of the borehole (UTM), borehole discharge, depth of the borehole, type of aquifer, and chemical analysis of groundwater for major ions. In fact, there are 80 wells in the study area. Only boreholes with high flow rate (> 8  l/s) (about 68 boreholes) were used {{in the rest of the}} analysis and randomly divided into two sets using MINITAB 16 software. The splitting criteria were 70 / 30. The training <b>data</b> contained 47 <b>boreholes</b> and testing <b>data</b> contained 21 <b>boreholes.</b>|$|R
30|$|This {{short article}} reports a {{preliminary}} evaluation of displacement signals estimated using <b>borehole</b> <b>data</b> {{provided by the}} KiK-net (Okada et al., 2004) of the NIED (National Research Institute for Earth Science and Disaster Prevention) for the 2011 Tohoku Earthquake. Given {{the magnitude of this}} event (Mw = 9.0), the strong-motion records may be quite different from previous records. The generation and propagation of static displacement are evaluated based on near-field recordings.|$|R
40|$|The actual estuary that {{occupies}} the Boina-Arade paleovalley accommodated the Holocene sedimentary sequence whose thickness does not exceed 35 m {{in the deepest}} zones, as registered from geotechnical <b>borehole</b> <b>data.</b> We present here the results of partial analyses of two continuous cores which cross the Holocene sequence until the Pre-Quaternary substratum. In the P 5 core (Boina river), the sedimentary column, which spans 20 m accumulated during ca 8500 years...|$|R
