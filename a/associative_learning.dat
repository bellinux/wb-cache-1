2212|272|Public
5|$|In amphibians, {{there is}} {{evidence}} of habituation, <b>associative</b> <b>learning</b> through both classical and instrumental learning, and discrimination abilities.|$|E
25|$|<b>Associative</b> <b>learning</b> {{in animal}} {{behaviour}} is any learning {{process in which}} a new response becomes associated with a particular stimulus. The first studies of <b>associative</b> <b>learning</b> were made by Russian physiologist Ivan Pavlov. Examples of <b>associative</b> <b>learning</b> include when a goldfish swims to the water surface when a human is going to feed it, or the excitement of a dog whenever it sees a leash as a prelude for a walk.|$|E
25|$|The {{connections}} between orbitofrontal cortex and amygdala play a notable role in emotional decision making process. These connections contribute in modulating the <b>associative</b> <b>learning</b> process and emotion regulation in amygdala.|$|E
40|$|This paper {{investigates the}} {{application}} of <b>associative</b> reinforcement <b>learning</b> techniques to the optimal control of linear discrete-time dynamic systems. <b>Associative</b> reinforcement <b>learning</b> involves the trial and error interaction with a dynamic system to determine the control actions that optimally achieve some desired performance index. The methodology can be applied either on-line or off-line and in a model based or model free manner. <b>Associative</b> reinforcement <b>learning</b> techniques are applied to the optimal regulator (LQR) control of discrete-time linear systems. Adaptive critic designs are implemented and the convergence speed compared for the different approaches. These methods can determine the optimal state and state/action value function and the optimal policy without requiring system models...|$|R
5000|$|J.S. deBelle and M. Heisenberg: <b>Associative</b> odor <b>learning</b> in Drosophila {{abolished}} by chemical ablation of Mushroom Bodies. Science 263, 692-695 (1994) ...|$|R
40|$|This paper {{analyses}} the behaviour of {{a general}} class of learning automata algorithms for feedforward connectionist systems in an <b>associative</b> reinforcement <b>learning</b> environment. The type of connectionist system considered is also fairly general. The <b>associative</b> reinforcement <b>learning</b> task is first posed as a constrained maximization problem. The algorithm is approximated hy an ordinary differential equation using weak convergence techniques. The equilibrium points of the ordinary differential equation are then compared with the solutions to the constrained maximization problem {{to show that the}} algorithm does behave as desired...|$|R
25|$|Limax maximus {{is capable}} of <b>associative</b> <b>learning,</b> {{specifically}} classical conditioning, because it {{is capable of}} aversion learning and other types of learning. It can also detect deficiencies in a nutritionally incomplete diet if the essential amino acid methionine is experimentally removed from its food.|$|E
25|$|The habit–goal {{interface}} or {{interaction is}} {{constrained by the}} particular manner in which habits are learned and represented in memory. Specifically, the <b>associative</b> <b>learning</b> underlying habits {{is characterized by the}} slow, incremental accrual of information over time in procedural memory. Habits can either benefit or hurt the goals a person sets for themselves.|$|E
25|$|Survival {{for most}} animal species depends upon maximizing contact with {{beneficial}} stimuli and minimizing contact with harmful stimuli. Reward cognition serves {{to increase the}} likelihood of survival and reproduction by causing <b>associative</b> <b>learning,</b> eliciting approach and consummatory behavior, and triggering positive emotions. Thus, reward is a mechanism that evolved to help increase the adaptive fitness of animals.|$|E
40|$|Emotional deficits {{are among}} the core {{features}} of schizophrenia and both <b>associative</b> emotional <b>learning</b> and the related ability to verbalize emotions can be reduced. We investigated whether schizophrenia patients demonstrated impaired function of limbic and prefrontal areas during <b>associative</b> emotional <b>learning.</b> Patients and controls filled out an alexithymia questionnaire and performed an <b>associative</b> emotional <b>learning</b> task with positive, negative and neutral picture-word pairs during fMRI scanning. After scanning, they indicated for each pair whether they remembered it We conducted standard GLM analysis and Independent Component Analysis (ICA). Both the GLM results and task-related ICA components were compared between groups. The alexithymia questionnaire indicated more cognitive-emotional processing difficulties in patients than controls, but equal experienced intensity of affective states. Patients remembered less picture-word pairs, irrespective of valence. GLM analysis showed significant visual, temporal, amygdalar/hippocampal, and prefrontal activation in all subjects. ICA identified a network of brain areas similar to GLM, mainly in response to negative stimuli. Neither analysis showed differences between patients and controls during learning. Although in previous studies schizophrenia patients showed abnormalities in both memory and emotion processing, neural circuits involved in cross-modal <b>associative</b> emotional <b>learning</b> may remain intact to a certain degree, which may have potential consequences for treatment. (C) 2013 Elsevier Ireland Ltd. All rights reserved. ...|$|R
40|$|<b>Associative</b> {{emotional}} <b>learning,</b> {{which is}} important for the social emotional functioning of individuals and is often impaired in psychiatric illnesses, is in part mediated by dopamine and glutamate pathways in the brain. The protein DARPP- 32 is involved in the regulation of dopaminergic and glutaminergic signaling. Consequently, {{it has been suggested that}} the haplotypic variants of the gene PPP 1 R 1 B that encodes DARPP- 32 are associated with working memory and emotion processing. We hypothesized that PPP 1 R 1 B should have a significant influence on the network of brain regions involved in <b>associative</b> emotional <b>learning</b> that are rich in DARPP- 32, namely the striatum, prefrontal cortex (comprising the medial frontal gyrus and inferior frontal gyrus (IFG)), amygdala and parahippocampal gyrus (PHG). Dynamic causal models were applied to functional MRI data to investigate how brain connectivity during an <b>associative</b> emotional <b>learning</b> task is affected by different single-nucleotide polymorphisms (SNPs) of PPP 1 R 1 B: rs 879606, rs 907094 and rs 3764352. Compared to heterozygotes, homozygotes with GTA alleles displayed increased intrinsic connectivity between the IFG and PHG, as well as increased excitability of the PHG for negative emotional stimuli. We have also elucidated the directionality of these genetic influences. Our data suggest that homozygotes with GTA alleles involve stronger functional connections between brain areas in order to maintain activation of these regions. Homozygotes might engage a greater degree of motivational learning and integration of information to perform the emotional learning task correctly. We conclude that PPP 1 R 1 B is associated with the neural network involved in <b>associative</b> emotional <b>learning.</b> (C) 2011 Elsevier Inc. All rights reserved...|$|R
40|$|Recent neuropsychological {{theories}} {{emphasize the}} influence of maladaptive learning and memory processes on pain perception. However, the precise relationship between these processes {{as well as the}} underlying mechanisms remain poorly understood; especially the role of perceptual discrimination and its modulation by <b>associative</b> fear <b>learning</b> has received little attention so far. Experimental work with exteroceptive stimuli consistently points to effects of fear learning on perceptual discrimination acuity. In addition, clinical observations have revealed that in individuals with chronic pain perceptual discrimination is impaired, and that tactile discrimination training reduces pain. Based on these findings, we present a theoretical model of which the central tenet is that <b>associative</b> fear <b>learning</b> contributes to the development of chronic pain through impaired interoceptive and proprioceptive discrimination acuity. (C) 2015 Elsevier Ltd. All rights reserved...|$|R
25|$|Jensen claimed, on {{the basis}} of his research, that general {{cognitive}} ability is essentially an inherited trait, determined predominantly by genetic factors rather than by environmental conditions. He also contended that while <b>associative</b> <b>learning,</b> or memorizing ability, is equally distributed among the races, conceptual learning, or synthesizing ability, occurs with significantly greater frequency in whites than in non-whites.|$|E
25|$|Jensen's {{interest}} in learning differences directed him to the extensive testing of school children. The results led him to distinguish between two separate types of learning ability. Level I, or <b>associative</b> <b>learning,</b> may be defined as retention of input and rote memorization of simple facts and skills. Level II, or conceptual learning, is roughly equivalent {{to the ability to}} manipulate and transform inputs, that is, the ability to solve problems.|$|E
25|$|In particular, <b>associative</b> <b>learning,</b> {{which is}} another type of episodic memory, is {{vulnerable}} {{to the effects of}} aging, and this has been demonstrated across various study paradigms. This has been explained by the Associative Deficit Hypothesis (ADH), which states that aging is associated with a deficiency in creating and retrieving links between single units of information. This can include knowledge about context, events or items. The ability to bind pieces of information together with their episodic context in a coherent whole has been reduced in the elderly population. Furthermore, the older adults’ performances in free recall involved temporal contiguity to a lesser extent than for younger people, indicating that associations regarding contiguity become weaker with age.|$|E
40|$|<b>Associative</b> {{reinforcement}} <b>learning</b> (ARL) tasks defined originally by Barto and Anandan [1] combine {{elements of}} problems involving optimization under uncertainty, studied by learning automata theorists, and supervised learning pattern-classification. The stochastic real-valued (SRV) unit algorithm [6] {{has been designed}} for an extended version of ARL tasks wherein the learning system's outputs can take on real values. In this paper, we present a strong convergence theorem that implies a form of optimal performance (under certain general conditions) of the SRV algorithm on ARL tasks. Simulation results are presented to illustrate the convergence behavior of the algorithm under {{the conditions of the}} theorem. The robustness of the algorithm is also demonstrated by simulations in which some of the conditions of the theorem are violated. I. INTRODUCTION <b>Associative</b> reinforcement <b>learning</b> (ARL) tasks [1] combine elements of problems involving optimization under uncertainty, studied by learni [...] ...|$|R
40|$|In their {{review article}} Zentall et al. propose that nonhumans {{can come to}} relate stimuli based on their {{physical}} properties (perceptual concept learning) or the relationship established between or among physically related stimuli (relational concept learning). At the same time, they draw upon findings from within the animal learning literature in order to argue that nonhumans can also derive untrained yet predictable relations between stimuli {{in the absence of}} direct training (<b>associative</b> concept <b>learning).</b> We are both intrigued and excited by the body of work contained in this paper and believe that it may accelerate our understanding of animal as well as human cognition in several ways. Nevertheless, a number of important questions still need to be addressed before we can conclude that <b>associative</b> concept <b>learning</b> in nonhumans is functionally similar to that observed in our own species...|$|R
40|$|<b>Associative</b> {{reinforcement}} <b>learning</b> tasks {{defined by}} Barto and Anandan [4] combine elements of problems involving optimization under uncertainty, studied by learning automata theorists, and supervised learning pattern-classification. In our previous work, we presented the SRV algorithm [15] {{which had been}} designed for extended versions of <b>associative</b> reinforcement <b>learning</b> tasks wherein the learning system's outputs could take on real values. In this paper, we state and prove a strong convergence theorem that implies a form of optimal performance (under certain conditions) of the SRV algorithm on these tasks. Simulation results are presented to illustrate the convergence behavior of the algorithm under {{the conditions of the}} theorem. The robustness of the algorithm is also demonstrated by simulations in which some of the conditions of the theorem are violated. This material is based upon work supported by the Air Force Office of Scientific Research, Bolling AFB, under Grant AFOSR- 89 - 0526 [...] ...|$|R
2500|$|... produce <b>associative</b> <b>learning</b> (i.e., {{classical}} conditioning and operant reinforcement); ...|$|E
2500|$|Manatees {{are capable}} of {{understanding}} discrimination tasks and show signs of complex <b>associative</b> <b>learning.</b> [...] They also have good long-term memory. They demonstrate discrimination and task-learning abilities similar to dolphins and pinnipeds in acoustic and visual studies.|$|E
2500|$|In neuroscience, {{the reward}} {{system is a}} {{collection}} of brain structures and neural pathways that are responsible for reward-related cognition, including <b>associative</b> <b>learning</b> (primarily classical conditioning and operant reinforcement), incentive salience (i.e., motivation and [...] "wanting", desire, or craving for a reward), and positive emotions, particularly emotions that involve pleasure (i.e., hedonic [...] "liking").|$|E
40|$|In this paper, a peg-in-hole {{insertion}} task {{is used as}} {{an example}} to illustrate the utility of direct <b>associative</b> reinforcement <b>learning</b> methods for learning control under real-world conditions of uncertainty and noise. An <b>associative</b> reinforcement <b>learning</b> system has to learn appropriate actions in various situations through search guided by evaluative performance feedback. We used such a learning system, implemented as a connectionist network, to learn active compliant control for peg-in-hole insertion. Our results indicate that direct reinforcement learning {{can be used to}} learn a reactive control strategy that works well even {{in the presence of a}} high degree of noise and uncertainty. 1 Introduction The peg-in-hole insertion task has been widely used by roboticists for testing various approaches to robot control. Peg-in-hole insertion is also studied as a canonical robot assembly operation by researchers in industrial robotics. Both two-dimensional [15] and three-dimensional [8] pe [...] ...|$|R
40|$|We {{present a}} new {{algorithm}} for <b>associative</b> reinforcement <b>learning.</b> The algorithm {{is based upon}} the idea of matching a network's output probability with a probability distribution derived from the environment's reward signal. This Probability Matching algorithm is shown to perform faster and be less susceptible to local minima than previously existing algorithms. We use Probability Matching to train mixture of experts networks, an architecture for which other reinforcement learning rules fail to converge reliably on even simple problems. This architecture is particularly well suited for our algorithm as it can compute arbitrarily complex functions yet calculation of the output probability is simple. 1 INTRODUCTION The problem of <b>learning</b> <b>associative</b> networks from scalar reinforcement signals is notoriously difficult. Although general purpose algorithms such as REINFORCE (Williams, 1992) and Generalized Learning Automata (Phansalkar, 1991) exist, they are generally slow and have trouble [...] ...|$|R
50|$|<b>Associative</b> {{sequence}} <b>learning</b> (ASL) {{explains how}} mirror neurons {{are able to}} match observed and performed actions, and how individuals (adults, children, animals) are able to imitate body movements. The theory was proposed by Cecilia Heyes in 2000. (For reviews see). A conceptually similar model proposed by Christian Keysers and David Perrett, {{based on what we}} know about the neural properties of mirror neurons and spike-timing-dependent plasticity is the Hebbian learning account of mirror neurons.|$|R
2500|$|Individual carp {{captured}} by anglers {{have been shown}} to become less catchable thereafter. This suggests that fish use their memory of negative experiences to associate capture with stress and therefore become less easy to catch. [...] This type of <b>associative</b> <b>learning</b> has also been shown in paradise fish (Macropodus opercularis) which avoid places where they have experienced a single attack by a predator and continue to avoid for many months.|$|E
2500|$|... {{respondent}} conditioning: A type of <b>associative</b> <b>learning.</b> These {{associations are}} formed by pairing two stimuli—what Ivan Pavlov {{described as the}} learning of conditioned behavior—to condition an animal to give a certain response. The simplest form of classical conditioning is reminiscent of what Aristotle would have called the law of contiguity which states that: [...] "When two things commonly occur together, the appearance of one will bring the other to mind." ...|$|E
2500|$|Goldfish {{have strong}} <b>associative</b> <b>{{learning}}</b> abilities, {{as well as}} social learning skills. In addition, their visual acuity allows them to distinguish between individual humans. Owners may notice that fish react favorably to them (swimming {{to the front of the}} glass, swimming rapidly around the tank, and going to the surface mouthing for food) while hiding when other people approach the tank. Over time, goldfish learn to associate their owners and other humans with food, often [...] "begging" [...] for food whenever their owners approach.|$|E
40|$|Human {{language}} is a unique ability. It sits apart from other systems of communication in two striking ways: it is syntactic, and it is learned. While most approaches {{to the evolution of}} language have focused on the evolution of syntax, this paper explores the computational issues that arise in shifting from a simple innate communication system to an equally simple one that is <b>learned.</b> <b>Associative</b> network <b>learning</b> within an observational learning paradigm is used to explore the computational difficulties involved in establishing and maintaining a simple learned communication system. Because Hebbian learning is found to be sufficient for this task, it is proposed that the basic computational demands of learning are unlikely to account for the rarity of even simple learned communication systems. Instead, it is the problem of *observing* that is likely to be central [...] in particular the problem of determining what meaning a signal is intended to convey...|$|R
40|$|The {{cooperative}} behaviour {{of interacting}} neurons and synapses is studied using models and methods from statistical physics. The competition between training error and entropy {{may lead to}} discontinuous properties of the neural network. This is demonstrated for a few examples: Perceptron, <b>associative</b> memory, <b>learning</b> from examples, generalization, multilayer networks, structure recognition, Bayesian estimate, on-line training, noise estimation and time series generation. Comment: Plenary talk for MINERVA workshop on mesoscopics, fractals and neural networks, Eilat, March 1997 Postscript Fil...|$|R
40|$|This paper {{studies the}} {{fundamental}} interplay between Hebbian synaptic changes and neuronally driven processes modifying synaptic efficacies, {{and its role}} in <b>associative</b> memory <b>learning.</b> The importance of neuronally driven normalization processes has already been demonstrated in the context of self-organization of cortical maps [1, 2] and in continuous unsupervised learning as in Principal-Component-Analysis networks [3]. In these scenarios such normalization was shown to be necessary to prevent the excessive growth of synaptic efficacies that occurs when learning and neuronal activity are strongly coupled. In this paper we focus on <b>associative</b> memory <b>learning</b> where this excessive synaptic runaway growth is mild [4], and show that even in this more simple learning paradigm, normalization processes are essential. Moreover, while various normalization procedures can prevent synaptic runaway, our analysis shows that a specific neuronally-driven correction procedure that preserves the total sum of synaptic efficacies is essential for effective memory storage. To this end we analyze the effectiveness of Hebbian synaptic learning rules and identify a critical constraint on effective learning. We then describe a neuronal procedure obtaining this constraint and show how it can be implemented via a biologically plausible mechanism. 2 The Space of Synaptic Learning Rule...|$|R
2500|$|Honey {{bees are}} adept at <b>associative</b> <b>learning,</b> {{and many of}} the {{phenomena}} of operant and classical conditioning take the same form in honey bees as they do in the vertebrates. Efficient foraging requires such learning. For example, honey bees make few repeat visits to a plant if it provides {{little in the way of}} reward. [...] A single forager will visit different flowers in the morning and, if there is sufficient reward in a particular kind of flower, she will make visits to that type of flower for most of the day, unless the plants stop producing nectar or weather conditions change.|$|E
2500|$|The (long) {{indirect}} pathway {{originates in}} the dorsal striatum and inhibits the GPe, resulting in disinhibition of the GPi {{which is then}} free to inhibit the thalamus. [...] This pathway consists of MSNs that express dopamine receptor D2, muscarinic acetylcholine receptor M1, and adenosine receptor A2a. [...] This pathway has been proposed to result in global motor inhibition(inhibition of all motor activity), and termination of responses. [...] Another shorter indirect pathway has been proposed, which involves cortical excitation of the subthalamic nucleus resulting in direct excitation of the GPe, and inhibition of the thalamus. [...] This pathway is proposed to result in inhibition of specific motor programs based on <b>associative</b> <b>learning.</b>|$|E
2500|$|The {{reward system}} {{is a group of}} neural {{structures}} responsible for incentive salience (i.e., motivation and [...] "wanting", desire, or craving for a reward), <b>associative</b> <b>learning</b> (primarily positive reinforcement and classical conditioning), and positive emotions, particularly ones which involve pleasure as a core component (e.g., joy, euphoria and ecstasy). Reward is the attractive and motivational property of a stimulus that induces appetitive behavior – also known as approach behavior – and consummatory behavior. In its description of a rewarding stimulus (i.e., [...] "a reward"), a review on reward neuroscience noted, [...] "any stimulus, object, event, activity, or situation that has the potential to make us approach and consume it is by definition a reward." [...] In operant conditioning, rewarding stimuli function as positive reinforcers; however, the converse statement also holds true: positive reinforcers are rewarding.|$|E
40|$|Drosophila <b>associative</b> {{olfactory}} <b>learning.</b> Perturbations in adenosine 3 �, 5 � monophosphate signaling also disrupt learning. To integrate these observations, {{expression of}} a constitutively activated stimulatory heterotrimeric guanosine triphosphate–binding protein � subunit (G� s *) was targeted to these brain structures. The ability to associate odors with electroshock was abolished when G� s * was targeted to MB, but not CC, structures, whereas sensorimotor responses to these stimuli remained normal. Expression of G� s did not affect gross MB morphology, and wild-type G...|$|R
40|$|<b>Associative</b> fear <b>learning,</b> {{resulting}} from whisker stimulation paired with {{application of a}} mild electric shock to the tail in a classical conditioning paradigm, changes the motor behavior of mice and modifies the cortical functional representation of sensory receptors involved in the conditioning. It also induces the formation of new inhibitory synapses on double-synapse spines of the cognate barrel hollows. We studied density and distribution of polyribosomes, the putative structural markers of enhanced synaptic activation, following conditioning. By analyzing serial sections of the barrel cortex by electron microscopy and stereology, {{we found that the}} density of polyribosomes was significantly increased in dendrites of the barrel activated during conditioning. The results revealed fear learning-induced increase in the density of polyribosomes associated with both excitatory and inhibitory synapses located on dendritic spines (in both single- and double-synapse spines) and only with the inhibitory synapses located on dendritic shafts. This effect was accompanied by {{a significant increase in the}} postsynaptic density area of the excitatory synapses on single-synapse spines and of the inhibitory synapses on double-synapse spines containing polyribosomes. The present results show that <b>associative</b> fear <b>learning</b> not only induces inhibitory synaptogenesis, as demonstrated in the previous studies, but also stimulates local protein synthesis an...|$|R
40|$|Recent results {{indicate}} that visual recognition memory (as assessed by habituation and dishabituation of the orienting response) is influenced by associative knowledge, and that this influence is mediated by the hippocampus. A standard, <b>associative</b> model of <b>learning</b> has been recently reported to provide a parsimonious explanation for these results...|$|R
