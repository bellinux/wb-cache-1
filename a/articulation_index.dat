45|5|Public
50|$|In audiology, the <b>Articulation</b> <b>Index</b> (AI) {{is a tool}} used {{to predict}} the amount of speech that is audible to a patient with a {{specific}} hearing loss. The AI figure for a given patient can range from zero to one, representing {{the proportion of the}} average speech signal that is audible. The closer the AI is to one, or 100 percent, the better the person should be able to hear speech. The calculation is also used in industrial settings for the design of safety devices, such as flight helmets, where audio signals are required to be clearly heard.|$|E
5000|$|Fletcher's {{contributions}} {{to the theory of}} speech perception are among his best-known work. He showed that speech features are usually spread over a wide frequency range, and developed the <b>articulation</b> <b>index</b> to approximately quantify the quality of a speech channel. [...] He also developed the concepts of equal-loudness contours (commonly known as Fletcher-Munson curves), loudness scaling and summation, and the critical band. At Bell Labs, he oversaw research in electrical sound recording, including the first successful stereophonic recordings, the first live stereo sound transmission, and the production of the first vinyl recording. All of this was done {{with the help of the}} conductor of the Philadelphia Orchestra, Leopold Stokowski between 1931-32. Some of his other accomplishments include the production of the first functional hearing aid, the 2-A audiometer, and the artificial larynx.|$|E
50|$|Since speech {{privacy is}} the most {{important}} sound that needs evaluation, The Privacy Index has been developed; it based on the well established <b>Articulation</b> <b>Index.</b> The privacy calculation is done for each of several frequencies important for speech. Each frequency is then weighted for its importance in intelligibility and summed up. Thus it is a measureable means to ascertain the ability to understand speech and thus determine speech privacy. Numerous tests over fifty years have shown a strong relationship of that metric to the degrees of privacy. The value of PI varies from 0 (no privacy) to 100 (complete confidentiality). The curve in the figure shows that the relationship between speech privacy and Privacy Index is not a straight line, suggesting that the brain goes from nearly complete understanding of speech to virtually none with small changes in the PI. Sound masking applications make use of this fact. If the other two factors can move the Privacy Index to near 70 (the knee of the curve), addition of sound masking will have a large effect on the degree of privacy {{despite the fact that the}} PI does not change significantly.|$|E
40|$|The {{topic of}} study remains poorly {{understood}} and relevant. It {{is still too}} early to talk about the existence of prose rhythm, because it deals with different research approaches and interests of researchers in this field. Therefore, there is no uniform method of identifying prose rhythm. The author suggests a method of determining the rhythm of prose, which presents the figures of the regularity of prosodic units alternation: verbal accents, borders of syntagmatic <b>articulation</b> and intonation. <b>Indices</b> of the three rhythmic characteristics: syllabic, syntagmatic and intonational — give the opportunity to compare rhythms of different writers and to assess the accuracy of the translation, matching the rhythms of the original and translated texts.  </p...|$|R
40|$|In {{this article}} the authors compare the {{visibility}} of Latin American and Caribbean (LAC) publications in the Core Collection indexes of the Web of Science (WoS) inlcuding Science Citation Index Expanded, Social Sciences Citation Index, and Arts & Humanities Citation Index, and the SciELO Citation Index (SciELO CI) which was integrated into the larger WoS platform in 2014. The purpose of this comparison is {{to contribute to the}} broader understanding of the communication of scientific knowledge produced in Latin America and the Caribbean, and to provide some reflections on the potential benefits of the <b>articulation</b> of regional <b>indexing</b> exercises into WoS for a better understanding of geographic and disciplinary contributions. How is the regional level of SciELO CI related to the global range of WoS? In WoS, LAC authors are integrated at the global level in international networks, while SciELO has provided a platform for interactions among LAC researchers. The articulation of SciELO into WoS may improve the international visibility of the regional journals, but at the cost of own journal inclusion criteria independence...|$|R
40|$|We {{compare the}} {{visibility}} of Latin American and Caribbean (LAC) publications in the Core Collection indexes of the Web of Science (WoS) [...] Science Citation Index Expanded, Social Sciences Citation Index, and Arts & Humanities Citation Index [...] and the SciELO Citation Index (SciELO CI) which was integrated into the larger WoS platform in 2014. The purpose of this comparison is to contribute {{to our understanding of}} the communication of scientific knowledge produced in Latin America and the Caribbean, and to provide some reflections on the potential benefits of the <b>articulation</b> of regional <b>indexing</b> exercises into WoS for a better understanding of geographic and disciplinary contributions. How is the regional level of SciELO CI related to the global range of WoS? In WoS, LAC authors are integrated at the global level in international networks, while SciELO has provided a platform for interactions among LAC researchers. The articulation of SciELO into WoS may improve the international visibility of the regional journals, but at the cost of independent journal inclusion criteria...|$|R
50|$|TL is the {{transmission}} loss in decibels, MS and BS are respectively masking and ambient sound levels in decibels. The speech weighting factors W are those listed with <b>Articulation</b> <b>Index.</b> The first two ratings {{account for the}} high sound loss at frequencies that are important for intelligibility. ESL treats {{the difference between the}} masking spectrum and the background spectrum as an additional loss. The figure on the right shows the Speech Loss for a furniture panel with high STC; it is the excess loss caused by sound diffraction over the panel. The Effective Speech Loss is higher and shows sound masking as if it were part of the partition. The masking level for this example was set at 47 dB(A) and the background level was 39 dB(A). This graph demonstrates the significant value of sound masking when it acts as an additional panel height. It is clear that the level used in the graph only would be necessary for low panel heights, but is excessive with higher panels. The graph also demonstrates the panel tradeoff with sound masking. Adding masking permits lower panels to achieve the same speech loss. Adding masking roughly permits a reduction of at least 12 inches in panel height so there can be a significant cost savings.The reflection of speech from a ceiling in an open office depends on the sound absorbing characteristics of the ceiling tile and the height of the suspended ceiling. Because ceiling tiles tend to absorb the higher frequencies better, the speech loss is relatively good, as seen in the figure on the right. It should be noted that an upgrade in NRC rating adds expense but not always appreciable speech privacy improvement. A goal of SL=20 for the ceiling would require the panel height to be at least 60-66 inches to balance the two paths with added masking, otherwise, the panel would be the weakest sound path. Higher ceilings also increase sound diffusion for masking speakers in the ceiling plenum, increasing acceptability.|$|E
40|$|The {{physical}} characteristics of speech, {{the methods of}} speech masking measurement, {{and the effects of}} noise on speech communication are investigated. Topics include the speech signal and intelligibility, the effects of noise on intelligibility, the <b>articulation</b> <b>index,</b> and various devices for evaluating speech systems...|$|E
40|$|Speech {{perception}} experiments {{tell us a}} {{great deal}} about which factors affect human performance and behavior. In particular many experiments indicate that the signal-to-noise ratio spectrum is an important factor, indeed the signal-to-noise ratio spectrum is the basis of the <b>Articulation</b> <b>Index,</b> a standard measure of “speech channel capacity. ” In this paper we compare speech recognition performance for features based on the <b>Articulation</b> <b>Index</b> with two alternatives typically used in speech recognition. The experimental conditions vary the spectrum and level of noise distorting the speech in the training and test set. The perceptually inspired features generally perform better when there is a mismatch between the training and test noise spectrum and level, but worse when the test and training noises match. 1...|$|E
40|$|Starting from EU-SILC data, {{a sample}} survey {{that defines the}} {{harmonised}} lists of target primary (annual) and secondary (every four years or less frequently) variables transmitted to Eurostat by the 27 countries, we have chosen a set of about fifty indicators on a qualitative basis. An exploratory factorial analysis led us to accept only eleven variables distributed around three principle components, assuming that each of them could become, after further inquiry, an index of deprivation. Then we carried out the factorial analysis on the three principle components just found. The distribution of the eleven remaining data can be roughly interpreted as follows: the first group indicates material deprivation; the second one social deprivation; the third one can be labelled as depending on economic policy. Three factorial indexes consist in the factor score resulting from the factorial analysis on the partial indicators summarizing information supplied by each variable; the sum of our three indicators offers a global index {{of the quality of}} life (QL-index), whose values can be classified in order to identify groups of countries with similar conditions. A map will be drawn to overview the condition of the countries considered. We will test the three obtained indicators with the Spearman rho, comparing it with the ranking score of the Human Development Index and the Inequality Adjusted Human Development Index of European countries. The expected result is quite high correlation between them, mainly for the material deprivation index. The correlation with the ranking score will allow us to compare the relation of HDI, our QL-index, and the three components of it considered separately. The comparison between the two, the HD Index and the QL-Index, should reveal that the latter is more correlated with the IHDI. The greater number of indicators in our index should improve its explaining power, taking into account also social dimensions not so relevant in the HDI. The <b>articulation</b> of our <b>index</b> makes it possible to analyse the phenomenon more precisely; at the same time, the sum of the three indicators could be a good validation of the HDI...|$|R
40|$|Este estudo propõe analisar as estratégias usadas pelo Sistema Nervoso Central para controlar os movimentos multiarticulares, assim como avaliar a importância das informações proprioceptivas na manutenção desta estratégia. Sujeitos. Participaram deste estudo cinco sujeitos normais e dois sujeitos portadores de neuropatia periférica. Método. Os sujeitos permaneciam sentados em uma cadeira estando com o tronco firmemente fIxado no encosto. Nesta condição os sujeitos realizavam movimentos de reversão no plano {{vertical}} com o membro superior dominante. Partindo da posição inicial os sujeitos moviam em direção a três alvos o mais rápido possível. Resultados. Os sujeitos normais obtiveram trajetórias retilíneas à custa de uma dissociação do padrão de deslocamento articular e torque muscular entre a articulação do ombro e do cotovelo. Este comportamento determinou baixos índices 'de correlação linear entre os torques musculares gerados nas articulações do ombro e do cotovelo. Por outro lado, sujeitos portadores de neuropatia periférica não puderam dissociar o comportamento cinemático e cinético das duas articulações, estabelecendo altos índices de correlação linear entre os torques musculares. O acoplamento destas duas articulações resultou na formação de trajetórias lineares com menor retilinearidade. Discussão. Portanto, os sujeitos portadores de neuropatia periférica não conseguiram dissociar o comportamento entre as duas articulações para executar uma trajetória retilínea. Estas observações destacam dois pontos fundamentais sobre o controle dos movimentos multiarticulares. Primeiro, o Sistema Nervoso Central íntegro tem como principal estratégia manter a retilinearidade da trajetória e, segundo, as informações proprioceptivas são de fundamental importância para adequar o comportamento de cada articulação envolvida na tarefa em função da trajetória linearThis study aims {{amplify the}} understanding of the strategies launched by the Central Nervous System in the execution of multijoint tasks, as well as establish the differences in the motor behavior between subjects with neuropathies and normal ones. This differences can clarify the way the Central Nervous System integrates the proprioceptive afferent information in the programe configuration and motor commands. Subjects. Five neurologically normal subjects and two subjects with peripheral neuropathy volunteered themselves to participate in this study. Methods. The subjects made reversal movements in the vertical plan being seated in a chair with their upper bodies fnmily flXed {{to the back of the}} chairs. Starting from the initial position the subjects made movements in the three ta:çgets direction as fast as possible. No instructions were given as to the trajectory of the movement to be made. Results. The neurologically normal subjects obtained straighter trajectories differentiation in the articulate movement pattem between the shoulder and the elbow, differentiation in the musc 1 e torque pattem among the <b>articulation</b> and the <b>index</b> of linear correlation among the musc 1 e torque. However, the subjects with peripheral neuropathies could not make straight trajectories. They presented some compromise in the articulate movement of the elbow, similar to the shoulder pattem. They obtained an altemation in the muscle torque pattem of the elbow, establishing behavior similar to the one the shoulder presents. They determined high index of linear correlation. Discussion. Summarizing, the subjects could not dissociate the articulate dislocation patterns among the articulations of shoulder and elbow to guarantee the execution of a straight trajectory. This behavior would only be possible if the linear correlation index among the muscle torque was reduced. However, the subjects with peripheral neuropathy could not establish the same index present in the neur 9 logically normal subjects. It is possible that the proprioceptive information from a variety of muscle-skeletal structure would play an important role in elaborating motor programes that will command the sequence of muscle recruitment to establish adequate pattems of muscle torqu...|$|R
40|$|A new highly {{parallel}} {{approach to}} automatic recognition of speech, inspired by early Fletcher's research on <b>Articulation</b> <b>Index,</b> {{and based on}} independent probability estimates in several sub-bands of the available speech spectrum, is presented. The approach is especially suitable for situations when part of the spectrum of speech is corrupted. In such cases, it can yield an order-of-magnitude improvement in the error rate over a conventional full-band recognizer. 1...|$|E
40|$|This bachelor’s thesis {{presents}} evaluating {{of speech}} intelligibility in environment with noise. There are described two methods {{to reach this}} purpose – <b>articulation</b> <b>index</b> and speech intelligibility index, according to relevant standards. Part of this thesis deals with measurement of sound pressure to calculation sound pressure spectrum level. The last part of this work includes voice recordings of eight people and noise recordings of moving car in interior for different situations and their processing and evaluation...|$|E
40|$|Unlike {{most of the}} world's languages, Korean distinguishes {{three types}} of voiceless stops, namely lenis, fortis, and {{aspirated}} stops. All occur at three places of articulation. In previous work, acoustic measurements are mostly collapsed over the three places of articulation. This study therefore provides acoustic measurements of Korean lenis, fortis, and aspirated stops at all three places of articulation separately. Clear differences are found among the acoustic characteristics of the stops at the different places of <b>articulation.</b> <b>Index</b> Terms: speech production, stop consonants, phonetics 1...|$|E
40|$|The {{auditory}} {{system is}} capable of perceptually restoring inaudible portions of speech. This restoration may be compromised {{as a result of}} hearing impairment, particularly if it is combined with advanced age, because of degradations in the bottom-up and top-down processes. To test this hypothesis, phonemic restoration was quantitatively measured with hearing-impaired listeners of varying ages and degrees of hearing impairment, as well as with a normal hearing control group. The results showed that the restoration benefit was negatively correlated with both hearing impairment and age, supporting the original hypothesis. Group data showed that listeners with mild hearing loss were able to perceptually restore the missing speech segments as well as listeners with normal hearing. By contrast, the moderately-impaired listeners showed no evidence of perceptual restoration. Further analysis using the <b>articulation</b> <b>index</b> showed that listeners with mild hearing loss were able to increase phonemic restoration with audibility. Moderately-impaired listeners, on the other hand, were unable to do so, even when the <b>articulation</b> <b>index</b> was high. The overall findings suggest that, in addition to insufficient audibility, degradations in the bottom-up and/or top-down mechanisms as a result of hearing loss may limit or entirely prevent phonemic restoration. (C) 2009 Elsevier B. V. All rights reserved...|$|E
40|$|The {{relationship}} between the internal noise environment of helicopters {{and the ability of}} personnel to understand commands and instructions was studied. A test program was conducted to relate speech intelligibility to a standard measurement called <b>Articulation</b> <b>Index.</b> An acoustical simulator was used to provide noise environments typical of Army helicopters. Speech material (command sentences and phonetically balanced word lists) were presented at several voice levels in each helicopter environment. Recommended helicopter internal noise criteria, based on speech communication, were derived and the effectiveness of hearing protection devices were evaluated...|$|E
40|$|The {{effects of}} noise {{on human health}} (both mental and physical) are well known, and {{motivation}} to decrease noise in daily life is prevalent. Wind noise within automotive interior cabins could be detrimental to human health and comfort because of the negative impact on speech intelligibility and fatigue overall. There is little information on human perception of wind noise in automobile interiors though Loudness and <b>Articulation</b> <b>Index</b> have been examined as predictors of human response. They {{have been found to}} predict well in some circumstances, but not in others. In this research, a variety of sound quality metrics are being examined to better define how people perceive wind noise. Ford collected sounds in cars in a wind tunnel using four artificial Aachen heads, varying wind speed and direction. A variety of cars were tested, including midsize and compact SUVs. A database was created in order to easily compare a variety of characteristics for each sound and test configurations. Metrics for the front passenger and driver measurements were compared for symmetry and several unexpected asymmetries were found. High correlation (R 2 3 ̆e 0. 9) was found between several metrics: roughness, <b>Articulation</b> <b>Index,</b> A-weighted sound pressure level, and Zwicker Loudness. Subjective testing is still needed to be done to confirm which metrics provide the best predictions of people 2 ̆ 7 s responses...|$|E
40|$|The {{evaluation}} of the acoustical comfort in an open plan office typically involves a rather complex acoustical analysis. Many parameters, such {{as the number of}} square meters per employee, the shape of the room, the absorptive properties of interior surfaces and background noise levels, but also the nature of the activities of the users, are determining factors. Due to the quite complex character of this kind of multisource environment, the way to assess the acoustical comfort differs from country to country. Often, the reverberation time is taken into consideration. However, since furniture and screens are partitioning open plan offices, the global reverberation time is not an adequate quantity to fully describe their acoustical comfort. An alternative way to describe the acoustical comfort requirements for an open plan office is by stating the wanted minimal speech privacy together with the desired maximum value of background noise. To define speech privacy (as the opposite of speech intelligibility), two generally accepted approaches are known: the <b>Articulation</b> <b>Index,</b> and the Speech Transmission Index, or similarly the U 50 value. In this article, the feasibility to describe the speech privacy in open plan offices is compared between the Speech Transmission Index and the <b>Articulation</b> <b>Index.</b> The comparison is performed for 16 architectural setups that differ in the value and positioning of acoustically absorbing surfaces, and the placement of furniture elements that act as acoustical screens. status: publishe...|$|E
40|$|Cepstral {{normalisation}} in automatic {{speech recognition}} is investigated {{in the context of}} robustness to additive noise. In this paper, it is argued that such normalisation leads naturally to a speech feature based on signal to noise ratio rather than absolute energy (or power). Explicit calculation of this SNR-cepstrum by means of a noise estimate is shown to have theoretical and practical advantages over the usual (energy based) cepstrum. The relationship between the SNR-cepstrum and the <b>articulation</b> <b>index,</b> known in psycho-acoustics, is discussed. Experiments are presented suggesting that the combination of the SNR-cepstrum with the well known perceptual linear prediction method can be beneficial in noisy environments. ...|$|E
40|$|A {{practical}} and repeatable method of assessing acoustic performance of vehicle carpet systems {{was developed and}} tested. The method was employed during in-situ tests to evaluate the vehicle carpet&# 039;s sound absorption performance and transmission loss capability under stationary conditions. The acoustic performance of vehicle carpet systems was evaluated by introduction of floor mats. The resulting acoustic measurements were then compared and analysed. The various vehicle carpet systems are rated {{in terms of their}} effectiveness. Psychoacoustic analysis, using the Artemis software, was undertaken to evaluate the characteristics of interior cabin noise. The evaluation parameters include sound pressure level (SPL) in the entire frequency range, <b>articulation</b> <b>index,</b> loudness, fluctuation strength, roughness, sharpness, and tonality. Results indicate that loudness have the largest influence on sound quality...|$|E
40|$|In-car {{automatic}} {{speech recognition}} (ASR) is usually evaluated by determining one single word error rate (WER) for an in-car task. This measure does not allow {{to look at the}} recogniser behaviour for different levels of noise. Yet this is interesting for car manufacturers in order to predict system performances for different speeds and different car models and thus allow to design speech based applications in a better way. It therefore makes sense to split the single WER into SNR dependent WERs, where SNR stands for the signal to noise ratio, which is an appropriate measure for the noise level. In this paper a SNR measure based on the concept of the <b>Articulation</b> <b>Index</b> is developed, which allows the direct comparison with human recognition performance. 1...|$|E
40|$|This paper {{reports on}} the {{analysis}} of the spectral variation of emotional speech. Spectral envelopes of time aligned speech frames are compared between emotionally neutral and active utterances. Statistics are computed over the resulting differential spectral envelopes for each phoneme. Finally, these statistics are classified using agglomerative hierarchical clustering and a measure of dissimilarity between statistical distributions and the resulting clusters are analysed. The results show that there are systematic changes in spectral envelopes when going from neutral to sad or happy speech, and those changes depend on the valence of the emotional content (negative, positive) {{as well as on the}} phonetic properties of the sounds such as voicing and place of <b>articulation.</b> <b>Index</b> Terms: emotional speech, hierarchical clustering, spectral envelope...|$|E
30|$|Although {{it can be}} {{expected}} that an SNR improvement in frequency regions important for speech recognition would result in higher speech recognition, the gains obtained in intelligibility-weighted SNR can only {{be related to the}} potential of this system to improve intelligibility. This is particularly critical when individual hearing impairments (e.g., limitation in audibility, spectral resolution, or temporal fine structure processing) are considered. The effect of hearing impairment on speech intelligibility might be addressed by using modifications to the speech-weighted SNR measure such as those proposed in, for example, [27] for the <b>Articulation</b> <b>Index.</b> However, in order to demonstrate the true benefit of the BMWF system in complex scenarios, speech intelligibility tests with hearing aid users need to be conducted. Also, the quality of the processed speech could be addressed.|$|E
40|$|A {{major issue}} in {{evaluating}} speech enhancement and hearing compensation algorithms is {{to come up with}} a suitable metric that predicts intelligibility as judged by a human listener. Previous methods such as the widely used Speech Transmission Index (STI) fail to account for masking effects that arise from the highly nonlinear cochlear transfer function. We therefore propose a Neural <b>Articulation</b> <b>Index</b> (NAI) that estimates speech intelligibility from the instantaneous neural spike rate over time, produced when a signal is processed by an auditory neural model. By using a well developed model of the auditory periphery and detection theory we show that human perceptual discrimination closely matches the modeled distortion in the instantaneous spike rates of the auditory nerve. In highly rippled frequency transfer conditions the NAI’s prediction error is 8 % versus the STI’s prediction error of 10. 8 %. ...|$|E
40|$|Several {{measurement}} techniques exist {{to quantify the}} intelligibility of a speech transmission chain. In the objective domain, the <b>Articulation</b> <b>Index</b> [1] and the Speech Transmission Index STI [2], [3], [4], [5] have been standardized for predicting intelligibility. The STI uses a signal that contains spectro-temporal characteristics similar to natural speech. By comparing intensity fluctuations of degraded and reference signals, the modulation transfer function of the system under test is measured from which the STI can then be calculated. In modern speech transmission, various types of coding are used that may behave differently for speech than for the STI test signal, implying a possible incorrect intelligibility prediction. A more fundamental approach in assessing intelligibility is to take natural speech signals, and derive internal representations of the reference and degraded signals, the difference of which can then be used to estimate speech intelligibility...|$|E
40|$|Objectives: The {{purpose of}} this study is to {{evaluate}} the performance of a number of speech intelligibility indices in terms of predicting the intelligibility of vocoded speech. Design: Noise-corrupted sentences were vocoded in a total of 80 conditions, involving three different signal-to-noise ratio levels (� 5, 0, and 5 dB) and two types of maskers (steady state noise and two-talker). Tone-vocoder simulations and combined electric-acoustic stimulation (EAS) simulations were used. The vocoded sentences were presented to normal-hearing listeners for identification, and the resulting intelligibility scores were used to assess the correlation of various speech intelligibility measures. These included measures designed to assess speech intelligibility, including the speech transmission index (STI) and <b>articulation</b> <b>index</b> based measures, as well as distortions in hearing aids (e. g., coherence-based measures). These measures employed primarily either the temporal-envelope or the spectral-envelope information in th...|$|E
40|$|A new {{evaluation}} method Speech features typically evaluated through a phone classification task Requires aligned phonetic labels We propose an {{evaluation method}} that operates on whole words Idea: Good speech features should discriminate between any pair of words The ABX task A classical psychophysical task [1] Given some sounds A, B, X, is X closer to A or B? XA B mercredi 21 août 2013 Application to speech features a, b, x features for sounds A, B, X: d(a, x) > d(b, x) ? d: DTW + cosine distance [2] Database of sounds A {{subset of the}} <b>Articulation</b> <b>Index</b> corpus [3] All 343 possible CV of American En-glish (15 Vowels, 24 Consonants) 20 speakers (12 Male, 8 Female) 6839 syllables in total Between 4. 1 and 4. 6 millions eligible ABX triplets, depending on task Several variants of the task Tasks based on minimal-pairs to improve in-terpretability of the results A...|$|E
40|$|International audienceUsing {{the data}} {{presented}} in the accompanying paper [Hilkhuysen et al., J. Acoust. Soc. Am. 131, 531 - 539 (2012) ], the ability of six metrics to predict intelligibility of speech in noise before and after noise suppression was studied. The metrics considered were the Speech Intelligibility Index (SII), the fractional <b>Articulation</b> <b>Index</b> (fAI), the coherence intelligibility index based on the mid-levels in speech (CSIImid), {{an extension of the}} Normalized Coherence Metric (NCM+), a part of the speech-based envelope power model (pre-sEPSM), and the Short Term Objective Intelligibility measure (STOI). Three of the measures, SII, CSIImid, and NCM+, overpredicted intelligibility after noise reduction, whereas fAI underpredicted these intelligibilities. The pre-sEPSM metric worked well for speech in babble but failed with car noise. STOI gave the best predictions, but overall the size of intelligibility prediction errors were greater than the change in intelligibility caused by noise suppression. Suggestions for improvements of the metrics are discussed...|$|E
40|$|Abstract [...] Although most {{clinical}} tests {{focus on}} how much a particular hearing aid improves speech audibility under controlled conditions, {{it is unclear how}} these measures relate to hearing aid effectiveness, or the benefit perceived by the patient under everyday conditions. In this study, the relationship between audibility and hearing aid effectiveness was examined in a cohort of patients who obtained hearing aids through the Veteran's Administration. The measure of audibility was the <b>Articulation</b> <b>Index,</b> a common index of speech audibility. Measures of effectiveness included two hearing-specific surveys and self-reported ratings of global satisfaction and hearing aid use adherence. Results indicated that there were no systematic relationships between measurements of improved audibility and patient ratings of communication ability. Additionally, improved audibility was not related to overall satisfaction with the amplification characteristics of the hearing aid (fitting). However, improved audibility is related to hearing aid use adherence, with patients who achieve better audibility reporting that they use their hearing aids more frequently...|$|E
40|$|During {{the first}} half of the 20 th century, {{communications}} engineers at Bell Telephone Laboratories developed the articulation model for predicting speech intelligibility transmitted through different telecommunication devices under varying electroacoustic conditions. The profession of audiology adopted this model and its quantitative aspects, known as the <b>Articulation</b> <b>Index</b> and Speech Intelligibility Index, and applied these indices to the prediction ofunaided and aided speech intelligibility in hearing-impaired listeners. Over time, the calculation methods of these indices-referred to collectively in this paper as the Audibility Index-have been continually refined and simplified for clinical use. This article provides (1) an overview of the basic principles and the calculation methods of the Audibility Index, the Speech Transmission Index and related indices, as well as the Speech Recognition Sensitivity Model, (2) a review of the literature on using the Audibility Index to predict speech intelligibility ofhearing-impaired listeners, (3) a review of the literature on the applicability of the Audibility Index to the selection and fitting of hearing aids, and (4) a discussio...|$|E
40|$|The long‐term average speech {{spectrum}} (LTASS) and some dynamic characteristics of speech were determined for 12 languages: English (several dialects), Swedish, Danish, German, French (Canadian), Japanese, Cantonese, Mandarin, Russian, Welsh, Singhalese, and Vietnamese. The LTASS only was also measured for Arabic. Speech samples (18) were recorded, using standardized equipment and procedures, in 15 localities for (usually) ten male and ten female talkers. All {{analyses were conducted}} at the National Acoustic Laboratories, Sydney. The LTASS was similar for all languages although there were many statistically significant differences. Such differences were small and not always consistent {{for male and female}} samples of the same language. For one‐third octave bands of speech, the maximum short‐term rms level was 10 dB above the maximum long‐term rms level, consistent across languages and frequency. A ‘‘universal’’ LTASS is suggested as being applicable, across languages, for many purposes including use in hearing aid prescription procedures and in the <b>Articulation</b> <b>Index...</b>|$|E
40|$|The Minimal-Pair ABX (MP-ABX) {{paradigm}} {{has been}} pro-posed {{as a method}} for evaluating speech features for zero-resource/unsupervised speech technologies. We apply it in a phoneme discrimination task on the <b>Articulation</b> <b>Index</b> corpus to evaluate the resistance to noise of various speech features. In Experiment 1, we evaluate the robustness to additive noise at different signal-to-noise ratios, using car and babble noise from the Aurora- 4 database and white noise. In Experiment 2, we ex-amine the robustness to different kinds of convolutional noise. In both experiments we consider two classes of techniques to induce noise resistance: smoothing of the time-frequency rep-resentation and short-term adaptation in the time-domain. We consider smoothing along the spectral axis (as in PLP) and along the time axis (as in FDLP). For short-term adaptation in the time-domain, we compare {{the use of a}} static compressive non-linearity followed by RASTA filtering to an adaptive com-pression scheme. Index Terms: noise resistance, zero-resource, speech features, evaluation framework, minimal-pair ABX tas...|$|E
40|$|Abstract—Although most {{clinical}} tests {{focus on}} how much a particular hearing aid improves speech audibility under con-trolled conditions, {{it is unclear how}} these measures relate to hearing aid effectiveness, or the benefit perceived by the patient under everyday conditions. In this study, the relation-ship between audibility and hearing aid effectiveness was examined in a cohort of patients who obtained hearing aids through the Veteran's Administration. The measure of audibili-ty was the <b>Articulation</b> <b>Index,</b> a common index of speech audi-bility. Measures of effectiveness included two hearing-specific surveys and self-reported ratings of global satisfaction and hearing aid use adherence. Results indicated that there were no systematic relationships between measurements of improved audibility and patient ratings of communication ability. Additionally, improved audibility was not related to overall sat-isfaction with the amplification characteristics of the hearing aid (fitting). However, improved audibility is related to hearing aid use adherence, with patients who achieve better audibility reporting that they use their hearing aids more frequently. This material is based on work {{supported by a grant from}} the Deafnes...|$|E
40|$|The <b>articulation</b> <b>index</b> (AI), speech-transmission index (STI), and coherence-based {{intelligibility}} metrics {{have been}} evaluated primarily in steady-state noisy conditions and have not been tested extensively in fluctuating noise conditions. The aim of the present work is to evaluate the performance of new speech-based STI measures, modified coherence-based measures, and AI-based measures operating on short-term (30 ms) intervals in realistic noisy conditions. Much {{emphasis is placed on}} the design of new band-importance weighting functions which can be used in situations wherein speech is corrupted by fluctuating maskers. The proposed measures were evaluated with intelligibility scores obtained by normal-hearing listeners in 72 noisy conditions involving noise-suppressed speech (consonants and sentences) corrupted by four different maskers (car, babble, train, and street interferences). Of all the measures considered, the modified coherence-based measures and speech-based STI measures incorporating signal-specific band-importance functions yielded the highest correlations (r= 0. 89 – 0. 94). The modified coherence measure, in particular, that only included vowel∕consonant transitions and weak consonant information yielded the highest correlation (r= 0. 94) with sentence recognition scores. The results from this study clearly suggest that the traditional AI and STI indices could benefit from the use of the proposed signal- and segment-dependent band-importance functions...|$|E
40|$|Individuals with {{speaking}} disabilities, particularly people suf-fering from dysarthria, {{often use}} a TTS synthesizer for speech communication. Since users {{always have to}} type sound symbols and the synthesizer reads them out in a monotonous style, {{the use of the}} current synthesizers usually renders real-time opera-tion and lively communication difficult. This is why dysarthric users often fail to control the flow of conversation. In this pa-per, we propose a novel speech generation framework which makes use of hand gestures as input. People usually use tongue gesture transitions for speech generation but we develop a spe-cial glove, by wearing which, speech sounds are generated from hand gesture transitions. For development, GMM-based voice conversion techniques (mapping techniques) are applied to esti-mate a mapping function between a space of hand gestures and another space of speech sounds. In this paper, as an initial trial, a mapping between hand gestures and Japanese vowel sounds is estimated so that topological features of the selected gestures in a feature space and those of the five Japanese vowels in a cepstrum space are equalized. Experiments show that the spe-cial glove can generate good Japanese vowel transitions with voluntary control of duration and <b>articulation.</b> <b>Index</b> Terms: Dysarthria, speech production, hand motions, media conversion, arrangement of gestures and vowel...|$|E
40|$|Abstract—The {{field of}} {{wearable}} robotics is gaining momentum {{thanks to its}} potential application in rehabilitation engineering, assistive robotics, and power augmentation. These devices {{are designed to be}} used in direct contact with the user, to aid the movement or increase the power of specific skeletal joints. The design of the so-called physical human robot interface is critical, since it determines not only the efficacy of the robot, but also the kinematic compatibility of the device with the human skeleton, and the degree of adaptation to different anthropometries. Failing to deal with these problems causes misalignments between the robot and the user joint. Axes misalignment leads to the impossibility of controlling the torque effectively transmitted to the user joint, and causes undesired loading forces on articulations and soft tissues. In this paper, we propose a general analytical method for the design of exoskeletons able to assist human joints without being subjected to misalignment effects. This method is based on a kineto-static analysis of a coupled mechanism (robot-human skeleton), and can be applied in the design of selfaligning mechanisms. The method is exemplified in the design of an assistive robotic chain for a two degrees-of-freedom human <b>articulation.</b> <b>Index</b> Terms—Axes misalignment, exoskeleton, kinematics, mechanism design, rehabilitation robotics, wearability...|$|E
