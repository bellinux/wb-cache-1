43|40|Public
40|$|ISBN : 978 - 1 - 4244 - 2748 - 2 International audienceWe propose an <b>automatic</b> <b>instrumentation</b> {{method for}} {{embedded}} software annotation to enable performance modeling {{in high level}} hardware/software co-simulation environments. The proposed ldquocross-annotationrdquo technique consists of extending a retargetable compiler infrastructure to allow the <b>automatic</b> <b>instrumentation</b> of embedded software at the basic block level. Thus, target and annotated native binaries are guaranteed to have isomorphic control flow graphs (CFG). The proposed method {{takes into account the}} processor-specific optimizations at the compiler level and proves to be accurate with low simulation overhead...|$|E
40|$|ABSTRACT / RESUMEN A simple {{automatic}} control for applications of optical {{characterization of materials}} using the optical Z-scan technique is presented in this paper. The emphasis {{is placed in the}} automation process. For this purpose, a communication I/O port of a PCI-MIO- 16 E data acquisition card (from National Instruments) was used and the graphical programming language LabVIEW. <b>Automatic</b> <b>Instrumentation</b> with...|$|E
40|$|Java makes easier {{the coding}} phase of {{concurrent}} applications and provides friendly mechanisms {{for the information}} exchange among threads and different processes. The nature of communication and synchronization mechanisms and the actual parallelism of a distributed environment introduce potential sources of non-deterministic behavior in concurrent applications. In order to investigate on undesired effects related to non-deterministic behaviors, tracing and replay capabilities {{can be added to}} the programming environment. Such capabilities are useful for testing, debugging, monitoring and performance evaluation purposes. This paper presents a solution for providing tracing and replay capabilities to Java concurrent applications. Such a solution addresses portability and {{it is based on the}} <b>automatic</b> <b>instrumentation</b> of the original source code. Some transformation schemes have been applied to some classes in the standard Java packages in order to make easier and more efficient the <b>automatic</b> <b>instrumentation</b> task. It is shown how the object-oriented structure of Java can be exploited in a deep and efficient way both in the instrumentation and in the tracing and replay phases...|$|E
5000|$|Tecnólogo en Control Automático e Instrumentación (<b>Automatic</b> Control and <b>Instrumentation)</b> ...|$|R
50|$|<b>Automatic</b> {{discrete}} analysis <b>instrumentation</b> {{revolutionized the}} field of clinical chemistry, and, eventually, the practice of medicine, as well.|$|R
5000|$|<b>Automatic</b> source level: <b>instrumentation</b> {{added to}} the source code by an {{automatic}} tool according to an instrumentation policy.|$|R
40|$|A technology-independent, {{mathematical}} {{approach is}} {{proposed for the}} look-up-table based nonlinear modeling of electron devices. The model allows for accurate large-signal performance prediction at high operating frequencies, even {{in the presence of}} important parasitic and low-frequency dispersive effects. All the notitinear functions which characterise this black-box model are directly related to conventional measurements which can be carried out with <b>automatic</b> <b>instrumentation.</b> Preliminary experimental results are presented which confirm the validity of the approach...|$|E
40|$|Abstract: In {{this paper}} we present results on {{magnetic}} and magnetoelastic uniformity measurements of magnetostrictive ribbons and fibers. Both magnetic and magnetoelastic measurements {{are based on}} the magnetostrictive delay line (MDL) response. Measurements were realized by using an <b>automatic</b> <b>instrumentation</b> device, with parametric control of field and frequency. The device has been calibrated with respect to standard Ni wires. Indicative results are given concerning amorphous magnetostrictive ribbons and fibers, showing a good agreement with other measuring techniques...|$|E
40|$|A b s t r a c t A {{cost-effective}} {{instrument for}} the self-monitoring of peak expiratory flow (PEF) {{was used to}} map the time structure or chronome of this variable, with circadian to circadecennian rhythms. Self-measurements may detect changes in PEF associated with changes in personal health and/or air quality. For basic and applied purposes, a reduction in size of the measurement tool will be important until <b>automatic</b> <b>instrumentation</b> is developed. K e y w o r d s Peak expiratory flow, Self-monitoring, Circadian rhyth...|$|E
40|$|This paper {{presents}} {{a new technique}} that enhances {{the process and the}} methodology used in a performance prediction analysis. An <b>automatic</b> dynamic <b>instrumentation</b> methodology is added to Warwick's Performance Analysis and Characterization Environment PACE [1]. The automation process has eliminated the need to manually obtain application information and data...|$|R
40|$|<b>Automatic</b> {{software}} <b>instrumentation</b> {{is usually}} {{done at the}} machine level or is targeted at specific program behavior for use with a particular monitoring application. This paper describes CCI, an <b>automatic</b> software <b>instrumentation</b> tool for ANSI C designed to serve {{a broad range of}} program execution monitors. CCI supports high level instrumentation for both application-specific behavior as well as standard libraries and data types. The event generation mechanism is defined by the execution monitor which uses CCI, providing flexibility for different monitors' execution models. Code explosion and the runtime cost of instrumentation are reduced by declarative configuration facilities that allow the monitor to select specific events to be instrumented. Higher level events can be defined by combining lower level events with information obtained from semantic analysis of the instrumented program. 1 Introduction Program execution monitoring is an important tool for use in debugging, performanc [...] ...|$|R
40|$|Abstract. In {{this paper}} we {{describe}} an autotuning tool for optimiza-tion of OpenMP applications on highly multicore and multithreaded ar-chitectures. Our work {{was motivated by}} in-depth performance analysis of scientific applications and synthetic benchmarks on IBM Power 775 architecture. The tool provides an <b>automatic</b> code <b>instrumentation</b> of OpenMP parallel regions. Based on measurement of chosen hardware performance counters the tool decides {{on the number of}} parallel threads that should be used for execution of chosen code fragments...|$|R
40|$|In {{this paper}} we present new results on {{magnetic}} and magnetoelastic uniformity measurements on Fe 78 Si 7 B 15 amorphous ribbons and wires. The measurements are performed using an <b>automatic</b> <b>instrumentation</b> device {{based on the}} magnetostrictive delay line technique, {{with the ability to}} determine the B(H) and λ(H) functions along the length of a ribbon with parametric control of field and frequency. According to these results, it has been determined that magnetic and magnetoelastic uniformity functions are subject to the history of the under test samples...|$|E
40|$|International audienceThis paper {{focuses on}} the assertion-based {{verification}} (ABV) of hardware/software embedded systems, described at the Electronic System Level. We first summarize the features of a tool that enables the <b>automatic</b> <b>instrumentation</b> of SystemC TLM platforms with property checkers produced from PSL assertions and the runtime verification of these requirements. We also present its last improvements. Then we describe a return of experience using as case study a SoC modem for digital radio reception developed by Thales Communications & Security. Various temporal properties that capture the intended requirements, regarding hardware or hardware/software interactions, are formalized in PSL and checked during simulation...|$|E
40|$|In this paper, {{we propose}} an {{automatic}} generic instrumentation scheme on a formal protocol specification {{to enhance the}} observability and controllability of the implementation for conformance testing purposes. This approach is a special case of design for testability. It is cost effective considering the entire cycle of protocol development. The advantage of <b>automatic</b> <b>instrumentation</b> is that the user need not {{pay special attention to}} testing problems in the design phase. Unlike most other techniques, our scheme also works with existing protocol specifications since it does not affect the original design. Our models can handle both sequential and concurrent formal protocol specifications...|$|E
40|$|Floating-point {{rounding}} error {{is a well-known}} problem in numerical computation that distorts results and is difficult to analyze accurately. We propose a tool that performs <b>automatic</b> binary <b>instrumentation</b> of floating-point code to detect cancellations and to run side-by-side calculations in alternate precisions. The results of this analysis can help developers find areas of their code that are causing a loss of precision. In the future, it will also point out where reduced precision {{could be used to}} achieve a faster running time without losing accuracy. In this paper we explain the techniques and present several results, focusing on cancellation detection. ...|$|R
40|$|This field report {{documents}} the general sea-ice conditions in 2013 / 14, and shows preliminary {{results from a}} suite of meteorological and oceanographic measurements. The used methods included manual drillings, autonomous <b>instrumentation</b> (<b>automatic</b> weather and radiation station), thermistor chain and snow buoys. The study was performed {{in the framework of}} the Antarctic Fast Ice Network...|$|R
40|$|This paper {{presents}} an <b>automatic</b> code <b>instrumentation</b> technique, based on multithreaded vector clocks, for extracting the causal partial order on relevant state update events from a running multithreaded program. This technique {{is used in}} a formal testing environment, not only to detect, but especially to predict safety errors in multithreaded programs. The prediction process consists of rigorously analyzing other potential executions {{that are consistent with}} the causal partial order: some of these can be erroneous {{despite the fact that the}} particular observed execution was successful. The technique has been implemented as part of a Java program analysis tool. key words: runtime verification; multithreaded systems; vector clocks 1...|$|R
40|$|Software {{transactional}} memory (STM) {{systems are}} an attractive environment to evaluate optimistic concurrency. We describe {{our experience of}} supporting and optimizing an STM system at both the managed runtime and compiler levels. We describe the design policies of our STM system, and the statistics collected by the runtime to identify performance bottlenecks and guide tuning decisions. We present initial work on supporting <b>automatic</b> <b>instrumentation</b> of STM primitives for C/C++ and Java programs in the IBM XL compiler and J 9 JVM. We evaluate and discuss the performance of several transactional programs running on our system. key words: transactional memory, software transactional memory, compiler optimization, optimistic concurrency 1...|$|E
40|$|Abstract—CHIMP is a {{tool for}} assertion-based dynamic {{verification}} of SystemC models. The various features of CHIMP include automatic generation of monitors from temporal assertions, <b>automatic</b> <b>instrumentation</b> of the model-under-verification (MUV), and three-way communication among the MUV, the generated monitors, and the SystemC simulation kernel during the monitored execution of the instrumented MUV. Empirical results show that CHIMP puts minimal runtime overhead on the monitored execution of the MUV. A newly added path in CHIMP results in a significant (over 75 %) reduction of average monitor generation and compilation time. The average size of the monitors is reduced by over 60 %, without increasing runtime overhead. I...|$|E
40|$|In {{this paper}} {{we present a}} new {{technique}} able to recover behavioral design pattern instances which combines static analysis, based on visual language parsing, with dynamic analysis, based on source code instrumentation. In particular, the dynamic analysis is performed through the <b>automatic</b> <b>instrumentation</b> of the method calls involved in the candidate pattern instances identified during static analysis. The results obtained from a program monitoring activity are matched against the definitions of the pattern behaviors {{expressed in terms of}} monitoring grammars. We also present and discuss the results of a case study on JHotDraw 5. 1 software library performed to assess the retrieval effectiveness of the proposed approach...|$|E
40|$|We present CONCURRIT, a domain-specific {{language}} (DSL) for reproducing concurrency bugs. Given some partial {{information about}} the nature of a bug in an application, a programmer can write a CONCURRIT script to formally and concisely specify a set of thread schedules to explore in order to find a schedule exhibiting the bug. Further, the programmer can specify how these thread schedules should be searched to find a schedule that reproduces the bug. We implemented CONCURRIT as an embedded DSL in C++, which uses manual or <b>automatic</b> source <b>instrumentation</b> to partially control the scheduling of the software under test. Using CONCURRIT, we were able to write concise tests to reproduce concurrency bugs in a variety of benchmarks, including the Mozilla’s SpiderMonke...|$|R
40|$|This paper {{presents}} a test framework to support unit component testing in distributed component-based {{systems that are}} built upon component technologies like CORBA, COM/. NET, J 2 EE/RMI. The framework exploits <b>automatic</b> code <b>instrumentation</b> at the stubs and the skeletons of the calls in order to monitor a global call session. The calls can be cross-thread, cross-process and cross-processor. We further define certain testing-related interfaces for driver components in the component test harness and extend the IDL compiler, such that at runtime, test-related attributes can be automatically embedded in the call session identifier and propagated system-wide. As a result, various support for unit component testing can be enabled, including behavior coordination for stub components, collaborator component determination from historical execution, selective regression testing, and crash site pinpointing. 1...|$|R
40|$|This thesis {{presents}} a dynamic security vulnerability detection framework that sets up an infrastructure for automatic security testing of Free and Open Source Software (FOSS) projects. It makes three {{contributions to the}} design and implementation of a dynamic vulnerability detection system. Firstly, a mathematical model called Team Edit Automata is defined and implemented for security property specification. Secondly, an <b>automatic</b> code <b>instrumentation</b> tool is designed and implemented by extending the GNU Compiler Collection (GCC). The extension facilitates seamless integration of code instrumentation into FOSS projects' existing build system. Thirdly, a dynamic vulnerability detection system is prototyped to integrate the aforementioned two techniques. Experiments with the system are elaborated to automatically build, execute, and detect vulnerabilities of FOSS projects. Overall, this research demonstrates that monitoring program with Team Edit Automata can effectively detect security property violation...|$|R
40|$|We {{describe}} the Monitoring and Checking (MaC) framework which assures the correctness {{of the current}} execution at run-time. Monitoring is performed based on a formal specication of system requirements. MaC bridges the gap between formal specication and verication, which ensures the correctness of a design rather than an implementation, and testing, which partially validates an implementation. An {{important aspect of the}} framework is a clear separation be-tween implementation-dependent description of monitored objects and high-level requirements speci cation. Another salient feature is <b>automatic</b> <b>instrumentation</b> of executable code. The paper presents an overview of the framework and two languages to specify monitoring scripts and requirements, and brie y explain our on-going prototype implementation. ...|$|E
40|$|International audienceThe {{long-term}} {{goal of the}} work presented here is the <b>automatic</b> <b>instrumentation</b> of C programs with temporal property checkers to perform the runtime verification that these programs behave as expected, both for debugging purposes and for security or safety-oriented monitoring. This paper describes our first results towards this objective. To give requirements engineers or software developers the possibility to express advanced properties, the chosen specification language is the IEEE standard PSL (Property Specification Language). From PSL properties, a tool automatically generates assertion checkers and instruments the program with these verification components together with an observation mechanism that enables their event-driven activation. For maximum flexibility, the current implementation proposes either to decorate the source code or to observe the binary code under execution. An analysis of these solutions is achieved by means of experimental results...|$|E
40|$|Modern FPGA-based {{systems are}} complex and {{difficult}} to verify. One approach to easing the verification problem and reducing perceived complexity is to use libraries of reusable functions. These reusable functions, known as intellectual property blocks, are commonly created as netlists or RTL components. Complex systems can be created from IP blocks by using high-level design environments. These tools define the types and semantics of component interfaces which permit systems to be debugged using system-level transaction monitoring. However, the insertion of on-chip monitoring circuitry is a manual process in FPGA design flows. In this paper we present an algorithm which exploits the high-level design environment to permit <b>automatic</b> <b>instrumentation</b> of designs. We demonstrate that the algorithm can harness existing HDL generation techniques and reduce the insertion and configuration effort required of the designer...|$|E
40|$|We {{present an}} {{in-depth}} {{analysis of the}} crash-recovery problem and propose a novel approach to recover from otherwise fatal operating system (OS) crashes. We show how an unconventional, but careful, OS design, aided by <b>automatic</b> compiler-based code <b>instrumentation,</b> offers a practical solution towards the survivability of the entire system. Current results are encouraging and show that our approach is able to recover even the most critical OS subsystems without exposing the failure to user applica- tions or hampering the scalability of the system...|$|R
40|$|A formal {{analysis}} technique {{aiming at}} finding safety errors in multithreaded systems at runtime is investigated. An <b>automatic</b> code <b>instrumentation</b> procedure based on multithreaded vector clocks for generating the causal partial order on relevant state update events from a running multithreaded program is first presented. Then, {{by means of}} several examples, it is shown how this technique {{can be used in}} a formal testing environment, not only to detect, but especially to predict safety errors in multithreaded programs. The prediction process consists of rigorously analyzing other potential executions that are consistent with the causal partial order: some of these can be erroneous despite the fact that the particular observed execution is successful. The proposed technique has been implemented as part of a Java program analysis tool. A bytecode instrumentation package is used, so the Java source code of the tested programs is not necessary. 1...|$|R
40|$|This paper {{presents}} an <b>automatic</b> counter <b>instrumentation</b> and pro ling module {{added to the}} MPI library on Cray T 3 E and SGI Origin 2000 systems. A detailed summary of the hardware performance counters and the MPI calls of any MPI production program is gathered during execution and written in MPI Finalize on a special syslog file. The user can get the same information in a different file. Statistical summaries are computed weekly and monthly. The paper describes experiences with this library on the Cray T 3 E systems at HLRS Stuttgart and TU Dresden. It focuses on the problems integrating the hardware performance counters into MPI counter profiling and presents first results with these counters. Also, a second software design is described that allows {{the integration of the}} pro ling layer into a dynamic shared object MPI library without consuming the user's PMPI profiling interface...|$|R
40|$|AbstractWe {{describe}} Java-MaC, {{a prototype}} {{implementation of the}} Monitoring and Checking (MaC) architecture for Java programs. The MaC architecture provides assurance about the correct execution of target programs at run-time. Monitoring and checking is performed based on a formal specification of system requirements. MaC bridges the gap between formal verification, which ensures the correctness of a design rather than an implementation, and testing, which only partially validates an implementation. Java-MaC provides a lightweight formal method solution as a viable complement to the current heavyweight formal methods. An {{important aspect of the}} architecture is the clear separation between monitoring implementation-dependent low-level behaviors and checking high-level behaviors against a formal requirements specification. Another salient feature is <b>automatic</b> <b>instrumentation</b> of executable codes. The paper presents an overview of the MaC architecture and a prototype implementation Java-MaC...|$|E
40|$|This report {{describes}} the REAPAR system (REcursive programs Automatically PARallelized) for <b>automatic</b> <b>instrumentation,</b> parallelization strategy selection and parallelization of recursive programs. It presents the background required {{for understanding the}} system and explains how a user can automatically instrument a program for producing recursion prole information, how to derive a thread-parallel program from recursive ANSI C source code, and how parallelization strategies are selected automatically. Also, the report explains the options offered by the system and gives troubleshooting advice and workarounds for system limitations. Supplemental chapters outline {{the structure of the}} system and describe the options in depth. They also detail the algorithms used for instrumenting code to generate recursion prole information, code insertion to allow for thread-parallel execution, and selection of parallelization strategies for both ne and coarse grained programs. Additionally, example of s [...] ...|$|E
40|$|We {{describe}} Java-MaC, {{a prototype}} {{implementation of the}} Monitoring and Check-ing (MaC) architecture for Java programs. The MaC architecture provides assur-ance about the correct execution of target programs at run-time. Monitoring and checking is performed based on a formal specication of system requirements. MaC bridges the gap between formal verication, which ensures the correctness of a design rather than an implementation, and testing, which only partially validates an im-plementation. Java-MaC provides a lightweight formal method solution as a viable complement to the current heavyweight formal methods. An {{important aspect of the}} architecture is the clear separation between monitoring implementation-dependent low-level behaviors and checking high-level behaviors against a formal requirements speci cation. Another salient feature is <b>automatic</b> <b>instrumentation</b> of executable codes. The paper presents an overview of the MaC architecture and a prototype implementation Java-MaC. ...|$|E
40|$|Robust and {{powerful}} software instrumentation tools are es-sential for dynamic program analysis {{tasks such as}} profiling, performance evaluation, and bug detection. Dynamic binary instrumentation (DBI) is a general purpose technique that eases the development of program analysis tools by facili-tating <b>automatic</b> low-level <b>instrumentation.</b> DBI-based pro-gram analysis can introduce high overhead and it is crucial for tool writers to minimize the cost. Analyzing the per-formance of instrumentation tools is challenging because most systems use a just-in-time compiler (JIT) to dynami-cally generate code. In this paper, we describe our method for analyzing the performance of instrumentation tools. The instrumented code is itself instrumented with basic block counters. We implement the profiler in Pin {{and use it to}} an-alyze the behavior of simple and complex instrumentation tools. The analysis yields several unexpected results about the dynamic behavior of instrumented programs. By exam-ining these results, we often find effective solutions to im-prove performance. 1...|$|R
40|$|A 3 D {{iteration}} space visualizer (ISV) {{is presented}} to analyze the parallelism in loops and to find loop transformations which enhance the parallelism. Using <b>automatic</b> program <b>instrumentation,</b> the iteration space dependency graph (ISDG) is constructed, which shows the exact data dependencies of arbitrarily nested loops. Various graphical operations such as rotation, zooming, clipping, coloring and filtering, permit a detailed examination of the dependence relations. Furthermore, an animated dataflow execution shows the maximal parallelism and the parallel loops are indicated automatically by an embedded data dependence analysis. In addition, the user may discover and indicate additional parallelism for which a suitable unimodular loop transformation is calculated and verified. The ISV {{has been applied to}} parallelize algorithmic kernel programs, a computational fluid dynamics (CFD) simulation code, the detection of statement-level parallelism and loop variable privatization. The applications show that the visualizer is a versatile and easy to use tool for the high-performance application programmer...|$|R
40|$|This paper {{presents}} a test framework which interlaces the test process {{with the development}} process {{in the domain of}} embedded control systems. The framework shows the following characteristics: • Strong integration of test and development process by solving test management issues inside development tools instead of specialized test management tools • Test in very early development stages by assuming a model-based development process where executable models are available • Reuse of test sequences at different abstraction levels and tool flexibility by tool-coupling The paper demonstrates concept and realisation of the test framework, which offers a manual but comfortable test suite derivation where test cases can be archived in the requirements database and interlinked with the requirement specification modules. Once the test sequences are defined, an <b>automatic</b> test <b>instrumentation,</b> execution and evaluation can be done. The test instrumentation is flexible, such that the system under test can be either a model or the realized hardware/software system...|$|R
