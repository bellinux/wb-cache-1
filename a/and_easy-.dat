14|19|Public
40|$|This paper {{investigates the}} power control and {{beamforming}} {{design in the}} MISO-IC (Multiple Input Single Output-Interference Channel) when constraints are placed at the receivers’ input power. In this way regulatory constraints are met and transmissions can coexist spatially. Dynamic <b>and</b> <b>easy-</b> to-implement distributed designs a re proposed; thus, using only local per user power measurements, which includes that of the intended signal {{as well as the}} undesired interference from other users plus receiver noise. Peer ReviewedPostprint (published version...|$|E
40|$|The {{period between}} 1880 and 1940 {{was a time}} of great growth in the urban {{population}} of the United States and Delaware. Accompanying this growth was the development of suburbs and new building types that expressed the values, desires, and economic situation of the suburban population. One of these new forms was the bungalow. Its thrifty style <b>and</b> <b>easy-</b> to-build design made it very attractive to urban dwel. lers seeking a new environment. During this period, a proliferation of bungalow advertisements, floor plans, and decorating ideas appeared in the popular literature of the period...|$|E
40|$|Recent {{developments}} {{in the area of}} Wireless sensor networks and Mobile ad hoc networks provide flexible <b>and</b> <b>easy-</b> to-deploycommunication means {{for a wide range of}} appli- cations without any need for an infrastructure being pre-con- figured. Our paper studies performance of proactive and reactive routing protocols in a scenario with agro-sensors. Our results, achieved by simulating a network both in OPNET Modeler and NS 2, show that the AODV routing protocol performs better for a large-scale network (where node density is higher) while the DSR routing protocol performs better in a small-scale network given the particular scenario we studied...|$|E
40|$|While it {{is widely}} {{acknowledged}} that knowledge can be acquired via testimony, {{it has been argued}} that understanding cannot. While there is no consensus about what the epistemic relationship of understanding consists in, I argue here that regardless of how understanding is conceived there are kinds of understanding that can be acquired through testimony: easy understanding <b>and</b> <b>easy-s</b> understanding. I address a number of aspects of understanding that might stand in the way of being able to acquire understanding through testimony, focusing on understanding ’s paradigmatic form and what it means to say that in order to understand something you need to “grasp” some information or the relationship between bits of information. I argue that in cases of both easy <b>and</b> <b>easy-s</b> understanding, no aspect of understanding stands in the way of it being able to acquire it through testimony. As a result, while not all understanding be acquired through testimony in all instances and for all subjects, this failure of acquisition is only a product of the complexity of the relevant information or one’s unfamiliarity with it, and not a product of the epistemic relationship of understandin...|$|R
60|$|It was a {{surprise}} to him one afternoon to find that his wife had so far unbent as to tidy up the parlour. Ornaments had been dusted and polished and the carpet swept. She had even altered the position of the furniture. The table had been pushed against the wall, <b>and</b> the <b>easy-</b> chair, with its back to the window, stood stiffly confronting six or seven assorted chairs, two of which at least had been promoted from a lower sphere.|$|R
40|$|We {{have studied}} the {{biquadratic}} exchange coupling in epitaxially grown Fe/Si/Fe. The temperature and thickness dependence of the biquadratic coupling strength were determined unambiguously by fitting the <b>easy-</b> <b>and</b> hard-axis magneto-optical Kerr effect loops. The origin of the biquadratic coupling can be fully {{understood in terms of}} Slonczewski's loose spins mechanism. © 2000 American Institute of Physic...|$|R
40|$|Backhousia citriodora {{is typical}} of the many commercially {{valuable}} woody Australian Myrtaceae species that are recalcitrant in forming adventitious roots from cuttings after maturation. A series of experiments were conducted to identify an endogenous rooting inhibitor in line with established criteria. Endogenous levels of citral were correlated with the rooting capacities of juvenile versus mature, <b>and</b> <b>easy-</b> versus difficult-to-root genotypes of B. citriodora, in both winter and summer. The biological activity of citral was confirmed in bioassays on mung beans and easy-to-root B. citriodora seedlings. Evidence of a common mechanism of root inhibition with other species in the family Myrtaceae and the role of action of citral are discussed...|$|E
40|$|AbstractHydrogen has {{a strong}} polarization-dependent neutron {{scattering}} cross section. This property has been exploited {{in the study of}} soft matters, especially biological macromolecules. When a polarized neutron beam is scattered off a polarized hydrogenous sample, the otherwise large hydrogen incoherent cross section is drastically reduced while the coherent signal is significantly increased. Past experiments have demonstrated the potentials and benefits of polarized neutron scattering from soft materials. The main technical challenge of polarized neutron scattering from biological matters lies at sample polarization. Dynamic nuclear polarization is a proven yet rather sophisticated technique. Its complexity {{is one of the main}} reasons for the technique's slow adoption. The future of polarized neutron scattering in biology may rest largely in neutron protein crystallography. Polarization of protein crystals is much easier to accomplish, since protein crystals are typically rather small (<< 1 mm) and only require small <b>and</b> <b>easy-</b> to-operate polarization apparatuses. In addition, the high resolution nature of neutron protein crystallography means that we will be able to study individual atoms using the polarized neutron scattering technique...|$|E
40|$|This paper {{presents}} Confidence, a {{tool for}} identifying and addressing faults in wireless sensing systems. Confidence pinpoints potential sensor and network faults in real time, allowing users to validate unexpected data and address any failures in the field. By introducing a well defined, low-dimension feature space, and functions to map sensor data into this space, {{we are able to}} achieve fault detection and diagnosis with relatively simple mechanisms such as outlier detection. Users can directly modify system outcomes by altering a classification label in instances when Confidence's automated algorithm draws the wrong inference. This label is applied to all similar points in the feature space, enabling Confidence to learn from user interaction in the field. This abstraction for incorporating user knowledge provides a lightweight <b>and</b> <b>easy-</b> to-understand interface for the user, while limiting user bur- den and reducing the required a priori environmental knowledge. Confidence has performed well on real-world deployments, including one deployment of 130 sensors, replayed datasets, and network simulations. Confidence accurately detects and diagnoses at least 90 % of all data, and user interaction improves it's performance...|$|E
40|$|The {{purpose of}} the work: the cytomorphological {{analysis}} of the histostructure of the pithy beams in the wood of the shoots of the <b>easy-</b> <b>and</b> hardrooting sorts of the fruitful plants. For the first time, the count of the pithy beams in the wood has been performed, and {{the differences in the}} cytomorphology of the beam parenchyma of the one-year shoot of the <b>easy-</b> <b>and</b> hard-rooting plants have been revealed. The obtained results can be used for the primary selection of the easily-rooted plants, using the signs of the medullar beams histostructure. The results of the investigation allow to test them for rooting with the selection of the new plants for the green cutting. The obtained data will be used in reading the course of lectures on botany of the wood plants anatomy, in practic of the fruit-growing and decorative gardeningAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|R
40|$|We {{studied the}} {{interlayer}} exchange coupling between Fe films across iron monosilicide spacer layers with the metastable CsCl structure. The bilinear (J(1)) and the biquadratic (J(2)) coupling strengths {{are determined by}} fitting the in-plane <b>easy-</b> <b>and</b> hard-axis magnetization curves. Both coupling coefficients have a strong, nonmonotonous temperature dependence and vary exponentially {{as a function of}} the spacer thickness. The temperature dependence of the coupling constants is explained within the framework of Slonczewski's loose spin model [J. Appl. Phys. 73, 5957 (1993) ] in which a decrease of the loose spin concentration upon cooling is introduced. The exponentially decaying coupling strength with increasing spacer layer thickness is attributed to the semi-metallic nature of the metastable monosilicide phase. status: publishe...|$|R
40|$|Although {{the blood}} {{pressure}} (BP) of many patients can be controlled using standard combinations, treatment of hypertension frequently represents a clinical challenge to the primary care physician. This article will review best practices for managing patients with <b>easy-</b> <b>and</b> difficult-to-treat hypertension, including preferred antihypertensive combinations, optimizing adherence and persistence, recognizing white-coat hypertension, and intensifying therapy for treatment-resistant patients. Each physician must decide based {{on his or her}} own level of experience at what point a patient becomes too challenging and would benefit from referral to a hypertension specialist for more intensive management and to complete the exclusion of secondary forms of arterial hypertension. With intensive pharmacotherapy, many patients with difficult-to-treat hypertension can achieve BP control. If it fails, interventional strategies (e. g., renal denervation) are a valid option to get BP controlled...|$|R
40|$|Médecins Sans Frontières. Campaign for Access to Essential Medicines Rio de Janeiro, RJ, August 30 - 31, 2007 Trypanosoma cruzi {{infection}} {{is often not}} detected early on or actively diagnosed, partly because most infected individuals are either asymptomatic or oligosymptomatic. Moreover, in most places, neither blood banks nor healthcare units offer diagnostic confirmation or treatment access. By the time patients present clinical manifestations of advanced chronic Chagas disease, specific treatment with current drugs usually has limited effectiveness. Better- quality serological assays are urgently needed, especially rapid diagnostic tests for diagnosis patients in both acute and chronic phases, {{as well as for}} confirming that a parasitological cure has been achieved. Some new antigen combinations look promising and it is important to assess which ones are potentially the best, together with their requirements in terms of investigation and development. In August 2007, a group of specialized researchers and healthcare professionals met to discuss the state of Chagas infection diagnosis and to build a consensus for a plan of action to develop efficient, affordable, accessible <b>and</b> <b>easy-</b> to- use diagnostic tests for Chagas disease. This technical report presents the conclusions from that meeting...|$|E
40|$|Abstract. The Ngram Statistics Package (NSP) is a {{flexible}} <b>and</b> <b>easy-</b> to-use software tool {{that supports the}} identification and analysis of Ngrams, sequences of N tokens in online text. We have designed and implemented NSP {{to be easy to}} customize to particular problems and yet remain general enough to serve a broad range of needs. This paper provides an introduction to NSP while raising some general issues in Ngram analysis, and summarizes several applications where NSP has been successfully employed. NSP is written in Perl and is freely available under the GNU Public License. 1 Introduction A simple model of written text is as a series of symbols that carry some meaning when considered as a whole. We may wish to treat those symbols as phrases, words, or characters depending on our motivations. Ngrams are a simple representation that suits this view of written language. An Ngram is a sequence of N units, or tokens, of text, where those units are typically single characters or strings that are delimited by spaces. However, a token could also be a fixed length character sequence, strings with embedded spaces, etc. depending on the intended application...|$|E
40|$|One of {{the most}} {{pressing}} issues facing the global conservation community is how to distribute limited resources between regions identified as priorities for biodiversity conservation(1 - 3). Approaches such as biodiversity hotspots(4), endemic bird areas(5) and ecoregions(6) are used by international organizations to prioritize conservation efforts globally(7). Although identifying priority regions is {{an important first step}} in solving this problem, it does not indicate how limited resources should be allocated between regions. Here we formulate how to allocate optimally conservation resources between regions identified as priorities for conservation - the 2 ̆ 7 conservation resource allocation problem 2 ̆ 7. Stochastic dynamic programming is used to find the optimal schedule of resource allocation for small problems but is intractable for large problems owing to the curse of dimensionality(8). We identify two easy- to- use <b>and</b> <b>easy-</b> to- interpret heuristics that closely approximate the optimal solution. We also show the importance of both correctly formulating the problem and using information on how investment returns change through time. Our conservation resource allocation approach can be applied at any spatial scale. We demonstrate the approach with an example of optimal resource allocation among five priority regions in Wallacea and Sundaland, the transition zone between Asia and Australasia...|$|E
40|$|When judging their {{likelihood}} {{of success in}} competitive tasks, {{people tend to be}} overoptimistic for easy tasks and overpessimistic for hard tasks (the shared circumstance effect; SCE). Previous research has shown that feedback and experience from repeated-play competitions has a limited impact on SCEs. However, in this paper, we suggest that competitive situations, in which the shared difficulty or easiness of the task is more transparent, will be more amenable to debiasing via repeated play. Pairs of participants competed in, made predictions about, and received feedback on, multiple rounds of a throwing task involving both <b>easy-</b> <b>and</b> hard-to-aim objects. Participants initially showed robust SCEs, but they also showed a significant reduction in bias after only one round of feedback. These and other results support a more positive view (than suggested from past research) on the potential for SCEs to be debiased through outcome feedback...|$|R
40|$|The {{effect of}} {{strangulation}} of the stems of 2 - and 7 -year-old Pinus radiata D. Don {{trees on the}} development and rootability of fascicle shoots was examined. Strangulation of the stems of juvenile P. radiata may be beneficial, in terms of subsequent development of shoots from needle fascicles, and speed and percentage of rooting. Both the development and rootability of needle fascicle shoots declined with increased spacing of strangulation along the stem. Strangulation of stems of 7 -year-old trees was done at different crown positions, using clones that were easy and difficult to root as stem cuttings. Fascicle bud development was better in {{the upper part of}} the crown but strangulation had no significant effect. Needle fascicle development varied with clone, and there was no significant difference between <b>easy-</b> <b>and</b> difficult-to-root clones. None of the fascicle buds from 7 -year-old trees had rooted 90 days after setting...|$|R
40|$|Background: Polymerase chain {{reaction}} (PCR) {{as a means}} to amplify nucleic acids has become an essential element in diagnosis of infections. It has evolved into a simple <b>and</b> rapid, <b>easy-</b> to- use approach. At present there are no published guidelines for the usage of PCR technology for the diagnosis of infections of the nervous system. Methods: We reviewed the advantages and pitfalls of PCR in order to guide neurologists and infectious diseases experts in its application for the diagnosis of infections of the nervous system. Medical reference systems were searched, and original papers, meta-analyses, review papers, book chapters and guidelines recommendations were reviewed. The final literature search was performed in May 2012. Recommendations were reached by consensus. Recommendations: The reliability of PCR technology for the diagnosis of neurological infections is currently based on the pathogens. The main contribution of PCR is to the diagnosis of viral infections followed by bacterial CNS infections with the notable exception of tuberculous meningitis. Efficacy for the diagnosis of protozoal infections and helminthic infestations has also been established in many instances. Unfortunately, current molecular PCR technology is far from becoming routine in resource-poor countries where such infections are prevalent. Despite the importance of fungal infections {{in the context of the}} immune-compromised host, there is not enough data to recommend the routine use of PCR. Conclusions: PCR technology is currently a reliable method for the diagnosis of viral and bacterial (except tuberculosis) infections, and only for some protozoal infections and helminthic infestations...|$|R
40|$|Weak {{electrical}} {{currents in}} the brain flow {{as a consequence of}} acquisition, processing and transmission of information by neurons, giving rise to electric and magnetic fields, which can be modeled by the quasi- stationary approximation of Maxwell’s equations. Electroencephalography (EEG) and magnetoencephalog- raphy (MEG) techniques allow for reconstructing the cerebral electrical currents and thus investigating the neuronal activity in the human brain in a non-invasive way. This is a typical electromagnetic inverse prob- lem which can be addressed in two stages. In the first one a physical and geometrical representation of the head is used to find the relation between a given source model and the electromagnetic fields generated by the sources. Then the inverse problem is solved: the sources of measured electric scalar potentials or magnetic fields are estimated by using the forward solution. Thus, an accurate and efficient solution of the forward problem is an essential prerequisite for the solution of the inverse one. The authors have proposed the method of fundamental solutions (MFS) as an accurate, efficient, meshfree, boundary-type <b>and</b> <b>easy-</b> to-implement alternative to traditional mesh-based methods, such as the boundary element method and the finite element method, for computing the solution of the M/EEG forward problem. In this paper, further investigations about the accuracy of the MFS approximation are reported. In particular, the open question of how to efficiently design a good solution basis is approached with an algorithm inspired by the Leave- One-Out Cross Validation (LOOCV) strategy. Numerical results are presented with the aim of validating the augmented MFS with the state-of-the-art BEM approach. Promising results have been obtained...|$|E
40|$|A {{mathematical}} model for miniature fluxgate magnetometers {{is presented in}} the first part of this work. It is based on certain well- defined <b>and</b> <b>easy-</b> measurable parameters of the hysteresis loop exhibited by the fluxgate magnetic core, i. e., the coercive force and the field intensities at which the. flux- reversal starts and saturates. Two signal extraction techniques are modeled, the classical second-order harmonic one, and the current sampling one. For both cases, analytical expressions (in time and frequency domains) are derived for the magnetometer transfer function (voltage vs. field) and the influence of the aforementioned hysteresis loop parameters on the magnetometer response. Consequently the signal- to- noise ratio (SNR) in the ELF (Extremely Low Frequency) range and the effective magnetometer bandwidth are calculated for both cases. The SNR is a function of the variance of the aforementioned hysteresis loop parameters. Several noise- sources of different origin have been found to influence this variance, namely: (a) the magnetic (Barkhausen) noise, (b) the noise superimposed to the excitation waveform, (c) the noise generated due to electromagnetic- interference, and (d) the noise generated due to mechanical vibration of fluxgate cores. The extend, up to which the power of these noise-sources boost the variance of the aforementioned hysteresis loop parameters, is a function of certain fluxgate core characteristics, namely: (a) the saturation magnetization, (b) the coercive field, (c) the flux- reversal duration, (d) the dependence of flux- reversal duration on the excitation field slope (slew rate), (e) the core cross- section, and (f) the core frequency response (magnetic damping and magnetic viscosity). Finally, the conditions are investigated so that the current- sampling technique exhibits better SNR compared to the classical second- order- harmonic one. In the second part of this work the theory presented here is applied to explain the noise performance of miniature fluxgates employing amorphous wire cores...|$|E
40|$|Water {{resources}} {{planning and management}} has a considerable history {{in the use of}} computers. By covering a problem domain that combines a solid foundation in the physical sciences, and a large amount of data, with strong elements of socio-economic and political considerations, water {{resources planning}} and management is also an ideal application area for the latest advanced information technology. Advanced information technology provides the tools to design and implement smart software where, in a broad sense, the emphasis is on the man-machine interface. Integration, interaction and visualization are three key concepts that are discussed in detail, using a number of operational software examples. Integration implies that in any given software system for real-world applications, more than one problem representation form or model, several sources of information or data bases, and a multi-faceted, problem-oriented user interface ought to be combined in a common framework to provide a useful and realistic information base. Integration also means that tools such as expert systems components can be embedded in, for example, simulation models and user interfaces in general, providing the means for smart systems behavior. The increasing complexity of such composite tools, in turn, requires a well-structured and modular approach, supported by technological developments such as powerful workstations supporting bit-mapped color graphics and cost-effective high-volume mass storage, distributed computing and networking support, or object-oriented software. Interaction is a central feature of any effective man-machine system: a realtime dialogue allows the user to define and explore a problem incrementally in response to immediate answers from the system; fast and powerful systems with modern processor technology can offer the possibility to simulate dynamic processes with animated output, and they can provide a high degree of responsiveness that is essential to maintaining a successful dialogue and direct control over the software. Obviously, raw computer power, but also the availability of appropriate input and output devices such as high-resolution color screens or mouse pointers, are key requirements here. Visualization provides the band-width necessary to understand large amounts of highly structured information, and permits the development of an intuitive understanding of processes and interdependencies, of spatial and temporal patterns, and complex systems in general. Many of the problem components in a real-world planning or management situation are rather abstract: representing them in a symbolic, graphical format that allows visual inspection of systems behavior and, in general, symbolic interaction with the machine and its software, is an important element in friendly <b>and</b> <b>easy-</b> to-use computer-based systems. Several examples of smart software systems are introduced below, ranging from surface to groundwater flow and transport models, and finally rule- based or expert systems for water resources applications. Some basic principles and building blocks of smart software are discussed with these examples...|$|E
40|$|BACKGROUND Part I {{introduced}} {{the concept of}} <b>easy-</b> <b>and</b> difficult-to-mill chickpea genotypes, the broad chemical composition of their seed fractions and proposed mechanistic explanations for physical differences consistent with observed variation in milling ease. Part II continues this research by delving deeper into the amino acid, fatty acid and mineral components. RESULTS No association between fatty acid composition and ease of milling was observed. However, particular amino acids and mineral elements were identified that further support roles of lectins, pectins and mineral-facilitated binding in the adhesion of chickpea seed coat and cotyledons. CONCLUSION These differences suggest underlying mechanisms that could be exploited by breeding programmes to improve milling performance. This study shows that the content and composition of amino acids, fatty acids and minerals within different chickpea tissues vary with seed type (desi and kabuli) and within desi genotypes {{in ways that are}} consistent with physical explanations of how seed structure and properties relate to milling behaviour...|$|R
40|$|Additive Manufacturing (AM) {{offers the}} {{possibility}} to design and build products with high geometrical  omplexity and in smaller batch numbers. In this work we applied AM to design and build a disposable bioreactor in combination with a scaffold. This work applies rapid prototyping {{to design and fabricate}} scaffolds pre-enclosed into a disposable and ready-to-use perfusion chamber. Computerized tomography was used to scan a 3 cm sheep tibia section and generate a porous computer model replica. A fully enclosed perfusion chamber was designed around the replica. As a proof of principle the perfusion chamber and porous implant within were prototyped in one single piece by fused deposition modeling of ABS. The device’s watertightness was conﬁrmed by micro-CT and high ﬂow perfusion studies. Micro-CT also conﬁrmed that although prototyped in one piece, one inside the other, the implant and surrounding chamber were not merged together at any point. Opening the chamber we observed that perfused ﬂuids had totally and homogenously reached the highly interconnected porous network of the scaffold. This device is currently being fabricated from PLA for performing in vitro perfusion cell cultures in its interior.  This work demonstrated {{the possibility to}} produce <b>easy-</b> <b>and</b> ready-to-use ﬂuid-efﬁcient culture chambers pre-enclosing tailor-made and patient-speciﬁc scaffolds...|$|R
40|$|This book {{focuses on}} the two {{psychological}} factors of naturalness and ease of viewing of three-dimensional high-definition television (3 D HDTV) images. It {{has been said that}} distortions peculiar to stereoscopic images, such as the “puppet theater” effect or the “cardboard” effect, spoil the sense of presence. Whereas many earlier studies have focused on geometrical calculations about these distortions, this book instead describes the relationship between the naturalness of reproduced 3 D HDTV images and the nonlinearity of depthwise reproduction. The ease of viewing of each scene is {{regarded as one of the}} causal factors of visual fatigue. Many of the earlier studies have been concerned with the accurate extraction of local parallax; however, this book describes the typical spatiotemporal distribution of parallax in 3 D images. The purpose of the book is to examine the correlations between the psychological factors and amount of characteristics of parallax distribution in order to understand the characteristics of <b>easy-</b> <b>and</b> difficult-to-view images and then to seek to create a new 3 D HDTV system that minimizes visual fatigue for the viewer. The book is an important resource for researchers who wish to investigate and better understand various psychological effects caused by stereoscopic images...|$|R
30|$|TiO 2 {{is widely}} used as a {{photocatalyst}} {{and it can be}} applied in environmental and energy fields, including self-cleaning surfaces, air and water purification systems, anti-fogging surfaces, among others [1]. The self-cleaning property of TiO 2 is provided by two photo-induced phenomena [2]. The first one is the photocatalysis, wherein organic contaminants adsorbed on film surface are decomposed under ultraviolet light [3]. This property allows TiO 2 to be applied in air and water purification systems as well as for self-cleaning surfaces. The second one is the photo-induced superhydrophilicity, wherein contaminants and dirt are washed off the surface by the film of water on it [4]. On the superhydrophilic surface, a very small water contact angle is formed (θ[*]≤[*] 5 °), as the water tends to spread completely across the surface rather than forming droplets. This makes the surface anti-fogging <b>and</b> <b>easy-</b> washing [1, 3]. Commercial self-cleaning and anti-fogging surfaces are usually made of TiO 2 thin films [5]. However, TiO 2 thin films have some limitations, for example, they reduce the glass transmittance due to the high refractive index of TiO 2 [6]. Moreover, in dark environments TiO 2 films have a rapid reestablishment of hydrophobicity, which affects negatively the self-cleaning efficiency [7]. TiO 2 /SiO 2 composite films can circumvent these limitations, slowing down the increase of water contact angle in dark environments and presenting higher transmittance with respect TiO 2, which is essential for the application as a self-cleaning surface in solar energy area [2, 6, 7]. Self-cleaning surface are indeed important for PV application, since the dust, pollution, and other particles accumulation reduce the transparency of the PV module cover glasses and consequently decrease the electrical performances of the modules. In particular for CPV modules, the soling effect is particularly severe, since such modules mainly collect the sun direct light which can be strongly reduced by the dust accumulation on the module. Performance degradation up to 30 % has been measured [8]. Several studies have been made to address the severity of deposited particles (like dust, water stains, carbon from smoke, and pollen from agricultural regions) on the efficiency reduction of solar devices, which results in additional costs either from oversizing the system or from cleaning them [9]. For photovoltaic application, besides the self-cleaning properties, the coating should present adequate adhesion and transparency in the wavelength region 300 – 1800  nm. Several techniques have been reported for the deposition of TiO 2 and SiO 2 thin films, like CVD [10], sputtering [11 - 13], electron beam evaporation [14] and sol–gel process [2, 6, 7, 15]. Sol–gel method has the advantage of offering small and large area deposition at a low cost [15]. In literature, however, detailed analyses of the anti-soling film in term of structural properties, transparency, robustness and cost are still missing. In this work, pure TiO 2 and TiO 2 /SiO 2 composite films containing different titanium content have been deposited over glass substrates by sol–gel dip-coating method aiming at obtaining super hydrophilic, adherent and transparent coating. The influence of the titanium content and the calcination temperature has been evaluated. The coatings have been compared and characterized regarding their optical, mechanical and microstructural properties.|$|E
40|$|The {{magnetic}} properties and interactions between transition metal (TM) impurities and clusters in low-dimensional metallic hosts are studied using a first principles theoretical method. In {{the first part}} of this work, the effect of magnetic order in 3 d- 5 d systems is addressed from the perspective of its influence on the enhancement of the magnetic anisotropy energy (MAE). In the second part, the possibility of using external electric fields (EFs) to control the {{magnetic properties}} and interactions between nanoparticles deposited at noble metal surfaces is investigated. The inﬂuence of 3 d composition and magnetic order on the spin polarization of the substrate and its consequences on the MAE are analyzed for the case of 3 d impurities in one- and two-dimensional polarizable hosts. It is shown that the MAE <b>and</b> <b>easy-</b> axis of monoatomic free standing 3 d-Pt wires is mainly determined by the atomic spin-orbit (SO) coupling contributions. The competition between ferromagnetic (FM) and antiferromagnetic (AF) order in FePtn wires is studied in detail for n= 1 - 4 as a function of the relative position between Fe atoms. Our results show an oscillatory behavior of the magnetic polarization of Pt atoms as a function of their distance from the magnetic impurities, which can be correlated to a long-ranged magnetic coupling of the Fe atoms. Exceptionally large variations of the induced spin and orbital moments at the Pt atoms are found as a function of concentration and magnetic order. Along with a violation of the third Hund’s rule at the Fe sites, these variations result in a non trivial behavior of the MAE. In the case of TM impurities and dimers at the Cu(111), the effects of surface charging and applied EFs on the magnetic properties and substrate-mediated magnetic interactions have been investigated. The modifications of the surface electronic structure, impurity local moments and magnetic exchange coupling as a result of the EF-induced metallic screening and charge rearrangements are analysed. In a ﬁrst study, the properties of surface substitutional Co and Fe impurities are investigated as a function of the external charge per surface atom q. At large inter-impurity distances the effective magnetic exchange coupling ∆E between impurities shows RKKY-like oscillations as a function of the distance which are not signiﬁcantly affected by the considered values of q. For distances r < 10 Å, important modifications in the magnitude of ∆E, involving changes from FM to AF coupling, are found depending non-monotonously on the value and polarity of q. The interaction energies are analysed from a local perspective. In a second study, the interplay between external EF effects, internal magnetic order and substrate-mediated magnetic coupling has been investigated for Mn dimers on Cu(111). Our calculations show that EF (∼ 1 eV/Å) can induce a switching from AF to FM ground-state magnetic order within single Mn dimers. The relative coupling between a pair of dimers also shows RKKY-like oscillations as a function of the inter-dimer distance. Their effective magnetic exchange interaction is found to depend significantly on the magnetic order within the Mn dimers and on their relative orientation on the surface. The dependence of the substrate-mediated interaction on the magnetic state of the dimers is qualitatively explained in terms of the differences in the scattering of surface electrons. At short inter-dimer distances, the ground-state conﬁguration is determined by an interplay between exchange interactions and EF effects. These results demonstrate that external surface charging and applied EFs offer remarkable possibilities of manipulating the sign and strength of the magnetic coupling of surface supported nanoparticles...|$|E
40|$|The {{widespread}} of multi-drug resistant (MDR) Mycobacterium tuberculosis, resistant {{at least}} to rifampin (RIF) and isoniazid (INH), represents serious threats to the control of tuberculosis (TB) and increases the public health challenge worldwide. Surveillance program and rapid identification of drug-resistance strains are key-elements for an early and appropriate TB management. The aim is to evaluate the Genotype MTBDR (Hain Lifescience, Nehren, Germany), a reverse hybridization-based assay, as a rapid tool to identify mutations in the rpoB and katG genes associated to RIF-/INH-resistance directly in clinical specimens. We also evaluate {{the performance of a}} paper based device (Genocard – Hain Lifescience, Nehren, Germany) to collect and transport inactivated biological material. The test was evaluated retrospectively on 68 respiratory samples with positive cultures for M. tuberculosis. Considering the smear-positive samples only, the Genotype MTBDR gave interpretable results in 56 out of 57 samples (98. 2 %). The main limitations of the Genotype MTBDR are the difficulties in the amplification from smear-negative samples and the low sensitivity for the INH-resistance. The inclusion of probes targeting other regions involved in INH-resistance will increase the sensitivity of the test. The GenoCard, with its <b>easy-</b> <b>and</b> rapid-to use features, represents a functional tool for the sample collection with cost-effective and bio-safety benefits. The possibility to use the GenoCard directly in amplification reactions facilitates the gathering of data by molecular approaches...|$|R
40|$|ABSTRACT Objective: The aim of {{this study}} was to {{evaluate}} the role of urodynamic test in diagnosis of urinary incontinence, comparing detailed data of history and physical examination, <b>and</b> some <b>easy-</b> to-apply clinical tests. Methods: A cross-sectional retrospective study was carried out by reviewing the medical charts of 55 patients with complaint of loss of urine, seen at the Urogynecology Service of Women's Health Outpatient Clinic of Hospital Universitário de Jundiaí, between October 2006 and March 2007. The patients answered a specific questionnaire involving the epidemiological and physical examination variables considered in this study. They were submitted to physical examination and urodynamic tests. Results: The complaint of loss of urine upon exertion, either isolated or associated with urge incontinence, was confirmed by urodynamic tests in most women, and only 4 of 49 symptomatic women had negative results. The clinical sign was present in 35 patients (63. 6 %), and 46 patients (83. 6 %) had the exertion component in the urodynamic test. The exertion component was observed in 10 (18 %) out of 15 patients without symptoms (30 %). The positive and negative predictive values of the clinical sign for diagnosis of any type of urinary incontinence in this studied group were 97. 1 and 26. 7 %, respectively. As for the clinical complaint of urinary loss upon exertion, the positive and negative predictive values for any type of urinary incontinence were 92 and 40 %, respectively. For the clinical complaint of urge incontinence, the positive and negative predictive values of 92. 5 and 23. 1 %, respectively. Conclusions: It was concluded that the urodynamic evaluation is an important instrument to evaluate the severity of incontinence, although it was not necessary to diagnose loss of urine. The finding of urinary loss during physical examination had low sensitivity and specificity in diagnosis of the type of loss of urine. Urodynamic tests had better performance in demonstrating urinary incontinence in patients with complaint of incontinence upon exertion and without loss of urine seen upon physical examination than in confirming urge incontinence in patients with those symptoms...|$|R
40|$|The {{ferromagnetic}} semiconductor gallium manganese arsenide {{is an important}} test-bed material for spintronics applications. Whilst a Curie temperature anywhere close to room temperature {{has yet to be}} demonstrated, the excellent micromagnetic properties, simple band structure and unusual combination of having both low moment densities and high spin-orbit coupling make this an interesting material to study from both theoretical and experimental perspectives. This thesis reports some experimental studies into the magnetic and magnetoresistive anisotropies in gallium manganese arsenide. In the first main chapter a study of the Anisotropic Magnetoresistance in thin (Ga,Mn) As films is reported, based on transport measurements of micro-scale devices, contributing to the first systematic study in this material. The Anisotropic Magnetoresistance comprises crystalline and non-crystalline components; this study shows that a uniaxial crystalline component can dominate over the whole range of temperatures from 2 K up to the Curie temperature, the first time this has been seen in any material system to our knowledge. The following chapter shows that the magnetic anisotropy of gallium manganese arsenide thin films can be engineered by lithographically patterning the material into structures on length scales of a micron or less. Using electron beam lithography to define the structures and SQUID magnetometery to study the resulting magnetic configuration, it is shown that the magnetic anisotropy can be greatly modified, even resulting in a switching of the <b>easy-</b> <b>and</b> hard-axis directions. Finally a new technique based on Anisotropic Magnetoresistance measurements is presented to locate the crossover of competing magnetic anisotropy coefficients in the temperature domain. Conventionally performed by SQUID magnetometry, this new technique is cheaper and simpler whilst qualitatively reproducing the main features of the SQUID measurements...|$|R
40|$|The goal of {{this study}} was to {{determine}} the osmoregulatory ability of a juvenile marine fish, silver moony (), for the purpose of developing a new experimental species for ecophysiological research. In this study, was acclimated to freshwater (FW), brackish water (BW), or seawater (SW). The salinity tolerance of this euryhaline species was effective, and the fish survived well upon osmotic challenges. The largest apical surface of mitochondrion-rich cells was found in the FW individuals. Immunohistochemical staining revealed that Na+, K+-ATPase immunoreactive (NKA-IR) cells were distributed in the interlamellar region of the gill filaments of the silver moony in all experimental groups. In addition to the filaments, NKA-IR cells were also found in the lamellae of the FW individuals. The number of NKA-IR cells in the gills of the FW individuals exceeded that of the BW and SW individuals. The NKA-IR cells of FW and SW individuals exhibited bigger size than that of BW fish. The NKA activities and protein expression of the NKA alpha-subunit in the gills of the FW individuals were significantly higher than in the BW and SW groups. Additionally, the relative amounts of Na+, K+, 2 Cl(-) cotransporter 1 (NKCC 1) were salinity-dependent in the gills. Immunofluorescent signals of NKCC 1 were localized to the basolateral membrane of NKA-IR cells in all groups. In the gills of the FW individuals, however, some NKA-IR cells did not exhibit a basolateral NKCC 1 signal. In conclusion, the present study illustrated the osmoregulatory mechanisms of this <b>easy-</b> <b>and</b> economic-to-rear marine teleost with euryhaline capacity and proved the silver moony to be a good experimental animal...|$|R
40|$|Classical signal {{detection}} theory attributes bias in perceptual decisions to a threshold criterion, against which sensory excitation is compared. The optimal criterion setting {{depends on the}} signal level, which may vary over time, and about which the subject is naïve. Consequently, the subject must optimise its threshold by responding appropriately to feedback. Here a series of experiments was conducted, and a computational model applied, {{to determine how the}} decision bias of the ferret in an auditory {{signal detection}} task tracks changes in the stimulus level. The time scales of criterion dynamics were investigated by means of a yes-no signal-in-noise detection task, in which trials were grouped into blocks that alternately contained <b>easy-</b> <b>and</b> hard-to-detect signals. The responses of the ferrets implied both long- and short-term criterion dynamics. The animals exhibited a bias in favour of responding "yes" during blocks of harder trials, and vice versa. Moreover, the outcome of each single trial had a strong influence on the decision at the next trial. We demonstrate that the single-trial and block-level changes in bias are a manifestation of the same criterion update policy by fitting a model, in which the criterion is shifted by fixed amounts according to the outcome of the previous trial and decays strongly towards a resting value. The apparent block-level stabilisation of bias arises as the probabilities of outcomes and shifts on single trials mutually interact to establish equilibrium. To gain an intuition into how stable criterion distributions arise from specific parameter sets we develop a Markov model which accounts for the dynamic effects of criterion shifts. Our approach provides a framework for investigating the dynamics of decisions at different timescales in other species (e. g., humans) and in other psychological domains (e. g., vision, memory) ...|$|R
40|$|Background and objectives: "Difficult-to-recruit" {{patients}} are sometimes less compliant with their care, are {{more reluctant to}} seek medical attention {{and less likely to}} survive than their "easy-to-recruit" counterparts. They also tend to be excluded from clinical trials. The aim of this paper was to evaluate whether such differences extend to patients' willingness to be screened for diabetic nephropathy in a family practice setting. Design: A cross-sectional study. Setting: A Canadian university family practice unit. Patients: Two hundred and forty-seven patients with type 2 (adult-onset) diabetes mellitus as identified by computer searches of patient records of approximately 12 000 patients in the family practice unit. Intervention: A cross-sectional secondary preventive screening program obtained urine samples from all patients with type 2 diabetes mellitus, regardless of patients' willingness to participate. Main outcome measure: The prevalence of micro- and macroalbuminuria. Results: Of the 247 patients identified, 186 (75 %) easy-to-recruit enrollees agreed to participate in screening and 61 (25 %) difficult-to-recruit non-enrollees initially declined to be screened. The non-enrollees were subsequently evaluated by their own family physicians as part of routine clinical care and the results were captured for analysis. Overall rates of albuminuria were similar in the <b>easy-</b> <b>and</b> difficult-to-recruit groups (31 % versus 38 %, p = 0. 151). The main predictors of albuminuria were female sex (odds ratio [OR] = 2. 1, p = 0. 021), duration of diabetes in years (OR = 1. 05, p = 0. 023), current use of angiotensin-converting enzyme inhibitor (OR = 2. 26, p = 0. 008) and number of diabetic complications (OR = 1. 45, p = 0. 028). Conclusions: There is little difference in the prevalence of albuminuria related to patients' willingness to participate in a screening program. Therefore, there are no disproportionate gains for family practice researchers who aggressively seek difficult-to-recruit patients in this setting. In contrast, primary care doctors should make every effort to ensure optimal care to diabetic patients regardless of a patient's initial hesitancy. link_to_subscribed_fulltex...|$|R
40|$|The task of {{automatic}} speaker recognition, wherein a system verifies or determines a speaker's identity using {{a sample of}} speech, has been studied for a few decades. In that time, {{a great deal of}} {{progress has been made in}} improving the accuracy of the system's decisions, through the use of more successful machine learning algorithms, and the application of channel compensation techniques and other methodologies aimed at addressing sources of errors such as noise or data mismatch. In general, errors can be expected to have one or more causes, involving both intrinsic and extrinsic factors. Extrinsic factors correspond to external influences, including reverberation, noise, and channel or microphone effects. Intrinsic factors relate inherently to the speaker himself, and include sex, age, dialect, accent, emotion, speaking style, and other voice characteristics. This dissertation focuses on the relatively unexplored issue of dependence of system errors on intrinsic speaker characteristics. In particular, I investigate the phenomenon that some speakers within a given population have a tendency to cause a large proportion of errors, and explore ways of finding such speakers. There are two main components to this thesis. In the first, I establish the dependence of system performance on speakers, building upon and expanding previous work demonstrating the existence of speakers with tendencies to cause false alarm or false rejection errors. To this end, I explore two different data sets: one that is an older collection of telephone channel conversational speech, and one that is a more recent collection of conversational speech recorded on a variety of channels, including the telephone, as well as various types of microphones. Furthermore, in addition to considering a traditional speaker recognition system approach, for the second data set I utilize the outputs of a more contemporary approach that is better able to handle variations in channel. The results of such analysis repeatedly show variations in behavior across speakers, both for true speaker and impostor speaker cases. Variation occurs both at the level of speech utterances, wherein a given speaker's performance can depend on which of his speech utterances is used, as well as on the speaker level, wherein some speakers have overall tendencies to cause false rejection or false alarm errors. Additionally, lamb-ish speaker behavior (where the speaker tends to produce false alarms as the target) is correlated with wolf-ish behavior (where the speaker tends to produce false alarms as the impostor). On the more recent data set, 50 % of the false rejection and false alarm errors are caused by only 15 - 25 % of the speakers. The second component of this thesis investigates a straightforward approach to predict speakers that will be difficult for a system to correctly recognize. I use a variety of features to calculate feature statistics that are then used to compute a measure of similarity between speaker pairs. By ranking these similarity measures for a set of impostor speaker pairs, I determine those speaker pairs that are easy for a system to distinguish and those that are difficult-to-distinguish. A variety of these simple distance measures could successfully select both <b>easy-</b> <b>and</b> difficult-to-distinguish speaker pairs, as evaluated by differences in detection cost and false alarm probability across a large number of systems. Of those tested, the best feature-measure at finding the most and least difficult-to-distinguish speaker pairs was the Euclidean distance between vectors of the mean first, second, and third formant frequencies. Even greater success was attained by the Kullback-Liebler (KL) divergence between pairs of speaker-specific GMMs. Furthermore, an examination of the smallest and biggest distances (as computed by the KL divergence) revealed individual speaker tendencies to consistently fall among the most (or least) difficult-to-distinguish speaker pairs. I then develop an approach for finding those individual speakers who will be difficult for the system, using a set of feature statistics calculated over regions of speech. In particular, a support vector machine (SVM) classifier is trained to distinguish between difficult and easy speaker examples, in order to produce an overall measure of speaker difficulty as a target or impostor. The resulting precision and recall measures were over 0. 8 for difficult impostor speaker detection, and over 0. 7 for difficult target speaker detection. Depending on the application, the detection threshold can be tuned to improve precision, recall, or specificity in order to best suit the needs of a particular task. The same approach can be taken with single conversation sides, as with a set of conversation sides corresponding to the same speaker, since the input feature statistics can be calculated over any number of speech samples...|$|R

