5|62|Public
40|$|At present, most {{aggregation}} routing algorithms for WSNs {{assume that}} aggregation expends are so little {{as to be}} neglected. But with the growing demand for the collection of multimedia data, the aggregation expends are much larger and can’t be neglect. In view of this problem, this paper proposes an adaptive aggregation routing algorithm with the minimal energy consumption (RMEAAT). Firstly, it constructs an -balancing spanning tree {{on the basis of}} SPT and MST as the initial communication path. And then it defines the <b>aggregation</b> <b>benefit</b> with consideration of aggregation expend and transmission expend, and data are adaptively judged whether to aggregate at every node of -balancing spanning tree according to <b>aggregation</b> <b>benefit</b> in the process of transmission. Correspondingly, the initial transmission path is gradually improved in terms of the aggregation judgment. The simulation results show that RMEAAT algorithm has better performance in WSNs with different aggregation expends and fusion degrees. </p...|$|E
40|$|Electronic {{intermediaries}} play {{an important}} role in many Web-based electronic markets, adding value for participants by offering services such as matchmaking and trust. This paper presents an economic model of intermediation where the intermediary offers services to two types of actors: consumers and providers. When consumers are heterogeneous, differentiated on their willingness to pay for intermediation, the intermediary can potentially offer two (or, generally, multiple) levels of service quality to target various consumer segments. How should electronic intermediaries choose their levels of service and prices for these services? Our analysis highlights the <b>aggregation</b> <b>benefit</b> that consumers derive from having access to multiple providers through the intermediary. We model this benefit as a network effect. According to prior research on vertically differentiated digital goods, it is optimal to offer only one quality level in the market, and segmentation causes cannibalization and lowers profits. In the case of intermediation, however, the <b>aggregation</b> <b>benefit</b> [...] by providing additional utility to consumers [...] makes it optimal for the intermediary to offer both levels of service. The intermediary’s profits increase upon decreasing the quality of the lower quality service, suggesting that the two quality levels should be differentiated a...|$|E
40|$|Eco-efficiency of {{production}} {{is an important}} concept both {{from the viewpoint of}} society and business community; but as yet, there is no unambiguous way to its measurement. The {{purpose of this paper is}} to present a general measurement framework based on production theory and the activity analysis approach. Although we exploit the existing methods and techniques, our approach diverges essentially from the usual treatments of the environmental performance of firms in the productive efficiency analysis. The main difference between our approach and the earlier studies is that we build on the definition of eco-efficiency as the ratio of economic value added to the environmental damage index. Related to this orientation, we also approach eco-efficiency from a more aggregate perspective. Our general framework is illustrated by an empirical application to the evaluation of eco-efficiency of road transportation in Finland. Eco-efficiency, Environmental Pressures, <b>Aggregation,</b> <b>Benefit</b> of the Doubt Weighting, Distance Function, Activity Analysis, Data Envelopment Analysis, Road transportation...|$|E
40|$|This {{presentation}} {{describes how}} you could conceivably allocate variability and reserve requirements, including how to allocate <b>aggregation</b> <b>benefits.</b> Conclusions of this presentation are: (1) <b>Aggregation</b> provides <b>benefits</b> because individual requirements are not 100 % correlated; (2) Method needed to allocate reduced requirement among participants; (3) Differences between allocation results are subtle - (a) Not immediately obvious which method is 'better'; (b) Many are numerically 'correct', they sum to the physical requirement; (c) Many are not 'fair', Results depend on sub-aggregation and/or the order individuals are included; and (4) Vector allocation method is simple and fair...|$|R
40|$|In this paper, {{we study}} how {{datacenter}} energy cost can be effectively reduced in the wholesale electricity market via cooperative power procurement. Intuitively, by aggregating workloads and renewables across {{a group of}} datacenters, the overall power demand uncertainty of datacenters can be reduced, resulting in less chance of being penalized when participating in the wholesale electricity market. We use cooperative game theory to model the cooperative electricity procurement process of datacenters as a cooperative game, and show the cost saving <b>benefits</b> of <b>aggregation.</b> Then, a cost allocation scheme based on the marginal contribution of each datacenter to the total expected cost is proposed to distribute the <b>aggregation</b> <b>benefits</b> among the participating datacenters. Besides, we propose proportional cost allocation scheme to distribute the <b>aggregation</b> <b>benefits</b> among the participating datacenters after realizations of power demand and market prices. Finally, numerical experiments based on real-world traces are conducted to illustrate the <b>benefits</b> of <b>aggregation</b> compared to noncooperative power procurement. Comment: This journal paper will soon get rejecte...|$|R
40|$|IEA WIND R&D Task 25 on “Design and Operation of Power Systems with Large Amounts of Wind Power” {{collects}} {{and shares}} information on wind power impacts on power systems, with analyses and guidelines on methodologies. There {{are dozens of}} studies made and ongoing related to wind integration, however, the results {{are not easy to}} compare. In the stateoftheart report (October, 2007), and the final report of the 3 years period (July, 2009) the most relevant wind power grid integration studies have been analysed especially regarding methodologies and input data. Several issues that impact on the amount of wind power that can be integrated have been identified. Large balancing areas and <b>aggregation</b> <b>benefits</b> of large areas help in reducing the variability and forecast errors of wind power as well as help in pooling more cost effective balancing resources. System operation and functioning electricity markets at less than dayahead time scales help reduce forecast errors of wind power. Transmission is the key to <b>aggregation</b> <b>benefits,</b> electricity markets and larger balancing areas. Best practices in wind integration studies are described. There is also benefit when adding wind power to power systems: it reduces the total operating costs and emissions as wind replaces fossil fuels and this should be highlighted more in future studies. QC 2011121...|$|R
40|$|Electronic {{intermediaries}} offer {{matching services}} that facilitate {{establishment of a}} buyerseller agreement; and value-added services that either provide a stand-alone benefit or enhance benefits from matching services. This paper analyzes buyer-sided biased intermediaries (to simplify exposition; the results are applicable to seller-sided intermediaries also), and develops economic models of intermediation to examine their pricing and product line design strategies. Intermediaries provide aggregation benefits, and these benefits increase {{with the size of}} the network. In buyer-sided markets, the sellers ’ indirect contribution to the intermediary’s revenue, through the <b>aggregation</b> <b>benefit</b> to buyers, gives the intermediary an incentive to subsidize sellers. In the case of intermediaries who provide stand-alone value added services, an increase in the level of the low-quality service reduces the intermediary’s profits. Hence the intermediary’s optimal strategy is to offer one product with only the matching service and a second bundle of the matching service and high quality value-added services. Intermediaries whose value-added services are useful only in conjunction with the matching function should offer a balanced set of features for matching and value-added services. An increase in service quality increase...|$|E
40|$|The {{explosive}} {{deployment of}} wired and wireless communication infrastructure has recently enabled many novel applications and sparked new research problems. One of the unsolved issues in today’s Internet – the main topic of this thesis – {{is the goal}} of increasing data transfer speeds of end hosts by aggregating and simultaneously using multiple network interfaces. This objective is most interesting when the Internet is accessible through several, relatively slow and variable (typically wireless) networks, which are unable to single-handedly provide the required data rate for resource-intensive applications, such as bulk file transfers and high-definition multimedia streaming. Communication devices equipped with multiple network interfaces are now commonplace. Smartphones and laptops are often shipped with built-in network adapters of different wireless technologies, typically enabling them to connect to wireless local area networks and cellular data networks (such as WLAN and HSPA). At the same time, wireless network coverage has become so widespread that mobile devices are often located in overlapping coverage areas of independent access networks. However, even if multiple interfaces are successfully connected to the Internet, operating systems typically use only a single default interface for data transmission, leaving secondary interfaces idle. This technical restriction is {{based on the fact that}} the majority of current Internet traffic is conveyed by transport protocols (TCP and UDP) that do not support multiple IP addresses per endpoint. Another crucial factor is that path heterogeneity introduces packet reordering, which can negatively affect the performance of transport protocols and strain the buffer requirements of applications. This thesis explores the problem of multipath aggregation with the attempt to find solutions that achieve increased data throughput by concurrently utilizing heterogeneous and dynamic access networks. We strive for approaches that support existing applications without requiring significant modifications to the current infrastructure. The exploration starts at the IP layer with a study of the IP packet reordering that is caused by the use of heterogeneous paths. Our practical experiments confirm that multipath reordering exceeds the typical packet reordering in the Internet by an extent that renders the usual reordering metric useless. The outcome of our network-layer study is a proxy-based, adaptive multipath scheduler that is able to mitigate packet reordering while transparently forwarding a single transport connection over multiple paths. After introducing a novel metric for quantifying the benefit of path aggregation, our analysis continues on the transport layer, where we investigate TCP’s resilience to multipath-inflicted packet reordering. While IP packet reordering is known for its destructive effect on TCP’s performance, our practical experiments indicate that a modern implementation is significantly more robust to packet reordering than standard TCP and achieves a substantial <b>aggregation</b> <b>benefit</b> even in certain cases of extreme multipath heterogeneity. In addition, we run a large set of emulation-based multipath experiments and identify several TCP parameters that lead to improved multipath performance when correctly tuned. Finally, we present an application-layer solution that builds upon the idea of logical file segmentation for streaming a single video to multihomed clients. The novelity of this approach lies in diverting standard protocol features (i. e., HTTP pipelining and range retrieval requests) from their intended purpose and using them for scheduling video segments over different paths. Interoperable with existing server infrastructure, our proposed solution can be deployed in a lightweight and purely client-based manner. We validate the proposed algorithms by implementing them into an existing video streaming platform...|$|E
40|$|International audienceData {{aggregation}} is a {{key problem}} in wireless sen- sor networks due to both energy-constrained and bandwidth- constrained. In this paper, we highlight the <b>aggregation</b> <b>benefits</b> in network layer and MAC layer by modeling the energy consumption for some energy-efficient routing protocols and MAC protocols. Besides, we define two parameters, aggregation ratio w and packet size coefficient λ, to evaluate the efficiency of an aggregation method, and we discuss their trade-off. Additionally, we propose comparison between A-ARMA and compressive sensing, which are {{on behalf of the}} state-of- the-art forecasting aggregation and compressing aggregation respectively...|$|R
50|$|One of {{the most}} {{compelling}} reasons for vendors/ISVs to utilize multitenancy is for the inherent data <b>aggregation</b> <b>benefits.</b> Instead of collecting data from multiple data sources, with potentially different database schemas, all data for all customers is stored in a single database schema. Thus, running queries across customers, mining data, and looking for trends is much simpler. This reason is probably overhyped {{as one of the}} core multitenancy requirements is the need to prevent Service Provider access to customer (tenant) information. Further, it is common to separate the operational database from the mining database (usually because of different workload characteristics), thus weakening the argument even more.|$|R
40|$|Physical {{inactivity}} and low maximal exercise {{oxygen consumption}} (VO 2 max) are predictors of mortality and coronary events in adults, respectively. Lowering serum cholesterol and platelet <b>aggregation</b> <b>benefits</b> cardiovascular function in aging persons. D- 003, {{a mixture of}} sugarcane wax acids, exhibits antiplatelet and cholesterol-lowering effects, and could benefit the performance of middle-aged and older subjects in effort tests. This randomised, double-blinded, placebo-controlled study investigated the effects of D- 003 (10 mg/day) for 12 weeks on the effort test in the static bicycle and the health status of 50 subjects (50 - 70 years old). Compared with baseline and placebo, D- 003 improved significantly VO 2 max values, pain/discomfort and health perception EuroQoL scores, and the cardiovascular capacity assessed by the Specific Activity Scale. Also, D- 003 displayed cholesterol-lowering effects versus placebo, being well tolerated. There were no study withdrawals. Concluding, D- 003 improved VO 2 max values in the effort test, lipid profile, health perception and cardiovascular status of study subjects...|$|R
40|$|Correlations between single-item self-reports of {{intelligence}} and IQ scores are rather low (. 20 -. 25) in college samples. The literature suggested that self-reports could be improved by three strategies: (1) aggregation, (2) item weighting, and (3) use of indirect, rather than direct, questions. To evaluate these strategies, we compared the validity of aggregated and unaggregated versions of direct measures with four indirect measures (Gough's Intellectual efficiency scale, Hogan's Intellect composite scale, Sternberg's Behavior Check List, and Trapnell's Smart scale). All measures were administered to two large samples of undergraduates (Ns = 310, 326), who also took an IQ test. Although results showed some success for both direct and indirect measures, the failure of their validities to exceed. 30 impugns their utility as IQ proxies in competitive college samples. The content of the most valid items referred to global mental abilities or reading involvement. <b>Aggregation</b> <b>benefited</b> indirect more than direct measures, but prototype-weighting contributed little...|$|R
40|$|Integration as a {{principle}} in urban transport policy is frequently advocated but rarely defined. We suggest {{a range of}} types of integration, and highlight the problems in developing an effective integrated strategy, {{given the number of}} variables involved. We argue that integration should be designed to serve agreed objectives of transport policy, rather than being an objective in its own right. We then consider the principles for designing an effective integrated strategy. We define the concept of synergy, which is often advocated as a benefit of integration, and discuss whether it, and other <b>aggregation</b> <b>benefits</b> short of true synergy, are achievable. We then consider the alternative approach of using integration to overcome barriers, an approach which is likely to be in conflict with pursuit of synergy, but more likely to lead to readily implemented strategies. We then review a number of examples where these principles have been applied, and investigate them to assess whether synergy has been demonstrated. Generally we find little evidence of synergy in outcome indicators. We conclude with some more general guidance on approaches to integration...|$|R
30|$|In Analysis 4, we {{also found}} that the {{performance}} of teams was stable across two tests separated by 1 week. Importantly, this correlation was not explained by the average individual accuracy of team members alone, suggesting that qualitative differences in the performance of individual team members contributes to team performance. This is an intriguing possibility, and consistent with theoretical accounts of response <b>aggregation</b> <b>benefits</b> which propose that accuracy gains will be greater in teams where different cognitive strategies are used by individual team members (see Hong & Page, 2004; O'Toole et al., 2007). This account is intuitively appealing; the different perceptual processes of individuals will produce different patterns of errors, and so averaging will reduce the impact of these uncorrelated errors on team performance. In machine learning, this principle is well known and accounts for benefits of aggregating decisions of multiple algorithms performing the same task, sometimes referred to as ‘boosting’ (Hastie, Tibshirani, & Friedman, 2001; see Danileiko & Lee, in press) or ‘fusion’ (see O'Toole et al., 2007). This account is especially appealing in light of some evidence suggesting that different people use different perceptual processes to perform face identification tasks, and that these differences can be stable across time (e.g. Richler, Floyd, & Gauthier, 2014).|$|R
40|$|The {{existing}} {{economic theory}} of copyright collectives, or copyright management organizations (CMOs) is strongly {{focused on the}} benefits of sharing of transaction costs. Here, we appeal to the contractual environment of CMOs to offer a different perspective. Copyright collectives form contracts at two principle points along the supply chain. First, there are the contracts between the collective’s members themselves (the copyright holders), for distribution of the collective’s income. And second there are the licensing contracts that the collective signs with users of the repertory. Using standard economic theory, the paper argues that there are significant efficiency benefits from having copyrights managed as an aggregate repertory, rather than individually, based on risk-pooling and risk-sharing through the contracts between the members themselves. Similarly, there are also <b>aggregation</b> <b>benefits</b> (at least in terms of the profit of the CMO) of licensing only the entire repertory, rather than smaller sub-sets. Interestingly, there is a link between these two theories of the efficiency of collective, rather than individual, management, and it {{lies at the heart of}} the theory of syndicates, and the characteristics that imply that the group (or syndicate as a whole) can be considered as a valid “representative”, sharing the same preferences as each individual syndicate member. 1...|$|R
40|$|Buffer sizing is an {{important}} network configuration parameter that impacts the quality of data traffic. Falling memory cost and the fallacy that ‘more is better’ lead to over provisioning network devices with large buffers. Over-buffering or the so called ‘bufferbloat’ phenomenon creates excessive end-to-end delay in today’s networks. On the other hand, under-buffering results in frequent packet loss and subsequent under-utilization of network resources. The buffer sizing problem has been studied extensively for wired networks. However, there is little work addressing the unique challenges of wireless environment. In this dissertation, we discuss buffer sizing challenges in wireless networks, classify the state-of-the-art solutions, and propose two novel buffer sizing schemes. The first scheme targets buffer sizing in wireless multi-hop networks where the radio spectral resource is shared among a set of con- tending nodes. Hence, it sizes the buffer collectively and distributes it over a set of interfering devices. The second buffer sizing scheme is designed to cope up with recent Wi-Fi enhancements. It adapts the buffer size based on measured link characteristics and network load. Also, it enforces limits on the buffer size to maximize frame <b>aggregation</b> <b>benefits.</b> Both mechanisms are evaluated using simulation as well as testbed implementation over half-duplex and full-duplex wireless networks. Experimental evaluation shows that our proposal reduces latency by an order of magnitude...|$|R
40|$|Achieving {{a tighter}} level of {{aggregation}} between LTE and Wi-Fi networks at the radio access network (a. k. a. LTE-Wi-Fi Aggregation or LWA) {{has become one of}} the most prominent solutions in the era of 5 G to boost network capacit y and improve end user's quality of experience. LWA offers flexible resource scheduling decisions for steering user tr affic via LTE and Wi-Fi links. In this work, we propose a Collocated LTE/WLAN Radio Level Integration architecture at IP layer (C-LWIP), an enhancement over 3 GPP non-collocated LWIP architecture. We have evaluated C-LWIP performance in vari ous link aggregation strategies (LASs). A C-LWIP node (i. e., the node having collocated, aggregated LTE eNodeB and Wi-Fi access point functionalities) is implemented in NS- 3 which introd uces a traffic steering layer (i. e., Link Aggregation Layer) for efficient integration of LTE and Wi-Fi. Using extensive simulations, we verified the correctness of C-LWIP module in NS- 3 and evaluat ed the <b>aggregation</b> <b>benefits</b> over standalone LTE and Wi-Fi netwo rks with respect to varying number of users and traffic types. We found that split bearer performs equivalently to switched b earer for UDP flows and switched bearer outperforms split bearer in the case of TCP flows. Also, we have enumerated the potential challenges to be addressed for unleashing C-LWIP capabilit ies. Our findings also include WoD-Link Aggregation Strategy whi ch is shown to improve system throughput by 50...|$|R
40|$|High {{penetration}} of wind power has impacts {{that have to}} be managed through proper plant interconnection, integration, transmission planning, and system and market operations. This report is a summary of case studies addressing concerns about the impact of wind powers variability and uncertainty on power system reliability and costs. The case studies summarized in this report are not easy to compare due to different methodology and data used, as well as different assumptions on the interconnection capacity available. Integration costs of wind power need to be compared to something, like the production costs or market value of wind power, or integration cost of other production forms. There is also benefit when adding wind power to power systems: it reduces the total operating costs and emissions as wind replaces fossil fuels. Several issues that impact on the amount of wind power that can be integrated have been identified. Large balancing areas and <b>aggregation</b> <b>benefits</b> of large areas help in reducing the variability and forecast errors of wind power as well as help in pooling more cost effective balancing resources. System operation and working electricity markets at less than day-ahead time scales help reduce forecast errors of wind power. Transmission is the key to <b>aggregation</b> <b>benefits,</b> electricity markets and larger balancing areas. From the investigated studies it follows that at wind penetrations of up to 20 % of gross demand (energy), system operating cost increases arising from wind variability and uncertainty amounted to about 14 /MWh. This is 10 % or less of the wholesale value of the wind energy. With current technology, wind power plants can be designed to meet industry expectations such as riding through voltage dips, supplying reactive power to the system, controlling terminal voltage, and participating in system operation with output and ramp rate control. The cost of grid reinforcements due to wind power is very dependent on where the wind power plants are located relative to load and grid infrastructure. The grid reinforcement costs from studies in this report vary from 50 /kW to 160 /kW. The costs are not continuous; there can be single very high cost reinforcements, and there can also be differences in how the costs are allocated to wind power. Wind generation will also provide some additional load carrying capability to meet forecasted increases in system demand. This contribution can be up to 40 % of installed capacity if wind power production at times of high load is high, and down to 5 % in higher penetrations and if local wind characteristics correlate negatively with the system load profile. Aggregating larger areas benefits the capacity credit of wind power. State-of-the-art best practices so far include (i) capturing the smoothed out variability of wind power production time series for the geographic diversity assumed and utilising wind forecasting best practice for the uncertainty of wind power production (ii) examining wind variation in combination with load variations, coupled with actual historic utility load and load forecasts (iii) capturing system characteristics and response through operational simulations and modelling and (iv) examining actual costs independent of tariff design structure...|$|R
40|$|In this paper, {{the results}} of a pilot study of {{willingness}} to pay (WTP) to avoid poultry-borne illness are reported. Through this, the problems of devising an economic measure of the 'intangible' benefits of prevention of food-borne risk are explored. The study is the first to allow those against a prevention policy (irradiation of poultry-meat) to register their WTP not to have the policy implemented. The study demonstrates that it is feasible to obtain answers to WTP questions from a self-selected sample. Future studies should ensure greater representativeness of respondents, that better information about benefits is provided to respondents and that an appropriate method of <b>aggregation</b> of <b>benefits</b> is used...|$|R
30|$|The {{first of}} Type-(1) work has {{recently}} been made in [80, 81], showing that the macroscale model works very well and uncovering some important features regarding the model itself and the microstructure–conductivity correlation. For nanofluids consisting of in-line arrays of perfectly dispersed two-dimensional circular, square or hollow particles, for example, the heat conduction is diffusion-dominant so that the effective thermal conductivity can be predicted adequately by the mixture rule with the effect of particle shape and particle–fluid conductivity ratio incorporated into its empirical parameter [80]. Thermal waves appear more likely at smaller particle–fluid conductivity ratio and lower particle volume fraction, a result that agrees with the experimentally observed significant conductivity enhancement in the oil-in-water emulsion [28, 74]. The computed thermal conductivity predicts some experimental data in the literature very well and shows the sensitivity to the surface-to-volume ratio [80]. The simulation results in [81] show that the radius of gyration and the non-dimensional particle–fluid interfacial area are two important parameters in characterizing the geometrical structure of nanoparticles. A non-uniform particle size {{is found to be}} unfavorable for the conductivity enhancement, while particle <b>aggregation</b> <b>benefits</b> the enhancement especially when the radius of gyration of aggregates is large [81]. Without considering the interfacial thermal resistance, larger non-dimensional particle–fluid interfacial area between the base fluid and the nanoparticles is also desirable for enhancing thermal conductivity [81]. The nanofluids with nanoparticles of connected cross-shape show a much higher (lower) effective thermal conductivity when particle–fluid conductivity ratio is larger (smaller) than 1 [81].|$|R
40|$|Published by the Ecological Society of AmericaWe {{examined}} {{the impact of}} a tending ant, Formica altipetens, on the population dynamics of a membracid, Publilia modesta. Controlled ant-exclusion experiments revealed three ways in which the strength and occurrence of this mutualism was conditional. First, we detected yearly variation in {{the impact of a}}nts on membracids. Ants had a significant positive impact on membracid abundance in 1985 and 1987, but not in 1986. Second, we found age-specific effects of ants on membracids. In 1985 and 1987 our experiments revealed that only membracid nymphs benefit directly from ant tending; we did not detect a direct positive impact of ants on the survival of membracid adults in any year. Third, we documented a density-dependent effect of ants on membracids. In 1985 and 1987, nymphs in large <b>aggregations</b> <b>benefited</b> from ant tending more than nymphs in small aggregations. Observations in 1985 - 1987 suggest that protection from a predatory salticid spider, Pellenes sp., may be at least one mechanism by which ants benefit membracid nymphs. In 1985 and 1987, when the association was mutualistic, spiders were significantly more abundant on membracid-infested plants without ants than on infested plants with ants, whereas {{this was not the case}} in 1986. We hypothesize that the age-specific benefits in this system may result because nymphs are especially susceptible to predation by spiders whereas the more agile and sclerotized adults are not. This research has been supported by grants from NSF (BSR- 8604983, BSR- 8705347, and BSR- 8815544), USDA (GAM- 8700709), Northern Arizona University, Sigma Xi, and the American Museum of Natural History. We thank the Wilson Foundation for permission to conduct research at Fern Mountain Ranch...|$|R
40|$|There {{are already}} several power systems coping with {{large amounts of}} wind power. High {{penetration}} of wind power has impacts {{that have to be}} managed through proper plant interconnection, integration, transmission planning, and system and market operations. This report is a summary of case studies addressing concerns about the impact of wind power s variability and uncertainty on power system reliability and costs. The case studies summarized in this report are not easy to compare due to different methodology and data used, as well as different assumptions on the interconnection capacity available. Integration costs of wind power need to be compared to something, like the production costs or market value of wind power, or integration cost of other production forms. There is also benefit when adding wind power to power systems: it reduces the total operating costs and emissions as wind replaces fossil fuels. Several issues that impact on the amount of wind power that can be integrated have been identified. Large balancing areas and <b>aggregation</b> <b>benefits</b> of large areas help in reducing the variability and forecast errors of wind power as well as help in pooling more cost effective balancing resources. System operation and working electricity markets at less than day-ahead time scales help reduce forecast errors of wind power. Transmission is the key to aggregation benefits,electricity markets and larger balancing areas. From the investigated studies it follows that at wind penetrations of up to 20 % of gross demand (energy), system operating cost increases arising from wind variability and uncertainty amounted to about 1 4 /MWh. This is 10 % or less of the wholesale value of the wind energy...|$|R
50|$|On {{overall economy}} {{examination}} (macroeconomics, <b>aggregation</b> problem) the <b>benefit</b> which individual economies {{want to achieve}} for themselves (legitimately) often appears as so called lead effect as against an inevitable lag effect of others. When lag effects are condoned, no paradox of competition arises. Solely because individual supply and individual demand {{turn out to be}} more elastic than overall supply and overall demand the classical paradox of competition can occur.|$|R
40|$|This {{paper is}} the first of a two-paper study of {{fairness}} issues for decisions that affect the benefits received and the risks encountered by a population. The study examines fairness for individuals and for homogeneous groups within the population. It considers fairness both for population benefit-risk profiles and for probability distributions over profiles that reflect uncertainty about outcomes of decisions. The present paper focuses on fairness for profiles in which benefits and risks are not aggregated within groups or across the population. It ties fairness to notions of envy among individuals and groups that are based on individuals' preferences. The sequel will discuss <b>aggregation</b> of <b>benefits</b> and risks along with fairness from an aggregated perspective. fairness, envy, social risk, distributive justice, equity...|$|R
40|$|Principles of {{need are}} {{constantly}} {{referred to in}} health care priority setting. The common denominator for any principle of need {{is that it will}} ascribe some kind of special normative weight to people being worse off. However, this common ground does not answer the question how a plausible principle of need should relate to the <b>aggregation</b> of <b>benefits</b> across individuals. Principles of need are sometimes stated as being incompatible with aggregation and sometimes characterized as accepting aggregation {{in much the same way}} as utilitarians do. In this paper we argue that if one wants to take principles of need seriously both of these positions have unreasonable implications. We then characterize and defend a principle of need consisting of sufficientarian elements as well as prioritarian which avoids these unreasonable implications...|$|R
50|$|Many {{species of}} sharks, {{including}} the lemon shark, {{are known to}} actively prefer to be social and live in groups or loose <b>aggregations.</b> A few <b>benefits</b> of group living are enhanced communication, courtship, predatory behavior, and protection. Group living and a preference for social interaction {{is thought to be}} important for the survival and success of juvenile lemon sharks. Group living, though, comes with its costs. A few include increased risk of disease, ease of parasite transmission, and competition for resources.|$|R
40|$|Electric Energy Storage (EES) is {{considered}} {{as one of the}} promising options for reducing the need for costly upgrades in distribution networks in Queensland (QLD). However, It is expected, the full potential for storage for distribution upgrade deferral cannot be fully realized due to high cost of EES. On the other hand, EES used for distribution deferral application can support a variety of complementary storage applications such as energy price arbitrage, time of use (TOU) energy cost reduction, wholesale electricity market ancillary services, and transmission upgrade deferral. <b>Aggregation</b> of <b>benefits</b> of these complementary storage applications would have the potential for increasing the amount of EES that may be financially attractive to defer distribution network augmentation in QLD. In this context, this paper analyzes distribution upgrade deferral, energy price arbitrage, TOU energy cost reduction, and integrated solar PV-storage benefits of EES devices in QLD...|$|R
40|$|Given {{the ever}} {{increasing}} quantity of sequence data, functional annotation of new gene sequences persists {{as being a}} significant challenge for bioinformatics. This is a particular problem for transcriptomics studies in crop plants where large genomes and evolutionarily distant model organisms, means that identifying the function of a given gene used on a microarray, is often a non-trivial task. Information pertinent to gene annotations is spread across technically and semantically heterogeneous biological databases. Combining and exploiting these data in a consistent way {{has the potential to}} improve our ability to assign functions to new or uncharacterised genes. Methods: The Ondex data integration framework was further developed to integrate databases pertinent to plant gene annotation, and provide data inference tools. The CoPSA annotation pipeline was created to provide automated annotation of novel plant genes using this knowledgebase. CoPSA was used to derive annotations for Affymetrix GeneChips available for plant species. A conjoint approach was used to align GeneChip sequences to orthologous proteins, and identify protein domain regions. These proteins and domains were used together with multiple evidences to predict functional annotations for sequences on the GeneChip. Quality was assessed with reference to other annotation pipelines. These improved gene annotations were used in the analysis of a time-series transcriptomics study of the differential responses of durum wheat varieties to water stress. Results and Conclusions: The integration of plant databases using the Ondex showed {{that it was possible to}} increase the overall quantity and quality of information available, and thereby improve the resulting annotation. Direct data <b>aggregation</b> <b>benefits</b> were observed, as well as new information derived from inference across databases. The CoPSA pipeline was shown to improve coverage of the wheat microarray compared to the NetAffx and BLAST 2 GO pipelines. Leverage of these annotations during the analysis of data from a transcriptomics study of the durum wheat water stress responses, yielded new biological insights into water stress and highlighted potential candidate genes that could be used by breeders to improve drought response. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|We {{review the}} {{literature}} regarding the <b>aggregation</b> of <b>benefit</b> value estimates for non-market goods. Two case studies are presented {{through which we}} develop an approach to aggregation which applies the spatial analytic capabilities of a geographical information system to combine geo-referenced physical, census and survey data to estimate a spatially sensitive valuation function. These case {{studies show that the}} common reliance upon political jurisdictions and the use of sample mean values within the aggregation process are liable to lead to significant errors in resultant values. We also highlight the fact that for resources with use values then we should expect overall values to reduce with increasing distance from such sites, but that changes in the choice of welfare measure will determine whether such distance decay is to be expected within values stated by those who are presently non-users. The paper concludes by providing recommendations for future improvements to the methodology...|$|R
30|$|One of {{the most}} serious {{challenges}} to using the EU-SILC for microsimulation modelling is the <b>aggregation</b> of <b>benefits.</b> Within the EU-SILC, social benefits are aggregated into 6 benefits recorded at the individual level (unemployment, old-age, survivor, sickness, disability and education) plus 3 recorded at the household level (family, social exclusion, housing benefits). If it were possible, utilising other data to model all <b>benefits,</b> then this <b>aggregation</b> would not be an issue, as we could replace the data recorded benefits with the simulated benefits. However, while in practice we model most benefits in Ireland as there are no earnings related benefits, we model the value for most benefits. The Irish social science data archive makes available a variant of the SILC for Ireland with disaggregated benefits. However this dataset is not suitable for tax-benefit microsimulation modelling as incomes are aggregated to the household level and some variables such as age have been banded.|$|R
40|$|Abstract — Data {{aggregation}} is {{a mechanism}} in which multiple packets are transmitted to a receiver, {{followed by a}} single acknowledgment. As opposed to typical explicit-acknowledgment schemes, <b>aggregation</b> schemes <b>benefit</b> from amortizing the control overhead over multiple packets. The achievable <b>benefit</b> from data <b>aggregation</b> is often of interest, especially {{in the face of}} several factors that can impact its performance (e. g., link rates, error-recovery schemes, inter-frame spacing options, etc.). In this paper, we present an analytical approach for estimating the performance of aggregation schemes as a function of several factors, including packet error rate and the number of frames aggregated into each transmission. We then demonstrate the use of these techniques in evaluating the performance of a data aggregation scheme specified in 802. 11 e. We also study other aggregation ideas, like frame aggregation at the MAC and Physica layer, proposed recently for next-generation wireless mesh networks. Keywords-WLAN, 802. 11,Aggregation,high throughput, block ACK. I...|$|R
40|$|This paper {{reviews the}} {{literature}} regarding the <b>aggregation</b> of <b>benefit</b> value estimates for environmental resources. The paper is {{prompted by the}} UK Environment Agency 'political jurisdiction' approach to aggregation of values for a single site as used in their study for the River Kennet tribunal. Two case studies are presented through which an alternative approach to aggregation is developed that applies the spatial analytic capabilities of a geographical information system to combine geo-referenced physical, census and survey data to estimate a spatially sensitive valuation function. These functions highlight the fact that resource values are expected to decline with increasing distance of households from the resource. The case {{studies show that the}} reliance upon political jurisdictions and the use of sample mean values within the aggregation process are liable to lead to significant errors in resultant values. The paper concludes with some limitations of the approach used as well as recommendations for future work in this area...|$|R
50|$|Given the {{detrimental}} effects avian brood parasites {{can have on}} their hosts' reproductive success, host species {{have come up with}} various defenses against this unique threat. Given that the cost of egg removal concurrent with parasitism is unrecoverable, the best defense for hosts is avoiding parasitism in the first place. This can take several forms, including selecting nest sites which are difficult to parasitize, starting incubation early so they are sitting on the nests when parasites visit them early in the morning, and aggressive territorial defense. Birds nesting in <b>aggregations</b> can also <b>benefit</b> from group defense.|$|R
40|$|This paper {{considers}} {{the use of}} a "combinatorial optimization" technique in the <b>aggregation</b> of environmental <b>benefit</b> values. Combinatorial optimization is used to statistically match population census data to a contingent valuation survey The matched survey and census information is then used to produce regional and national total willingness-to-pay figures. These figures are then compared to figures derived using More standard approaches to calculating aggregate environment benefit values. The choice of aggregation approach is shown to have a major impact upon estimates of total benefits at a regional level, especially when the target population displays considerable heterogeneity across space...|$|R
40|$|Many {{studies in}} the stated {{preference}} literature on environmental valuation {{do not include the}} effects of substitutes and distance in willingness-to-pay (WTP) models, in spite of the relevance of these effects in <b>aggregation</b> and <b>benefit</b> transfer. Heterogeneity in the availability of substitutes over space may cause multidirectional distance effects in WTP. As a result, disregarding this spatial heterogeneity may lead to biased estimators of the distance effect and associated WTP values (Cameron, 2006). In this paper, we demonstrate that distance decay is subject to significant directional effects which tend to be related to differences in the availability of substitutes across the study area. We apply a straightforward methodology to account for such spatial heterogeneity in choice experiments and assess the effect on WTP for improvements in ecosystem services in a lake district. We model distance-decay effects, whilst controlling for heterogeneity between users and non-users and non-use related WTP reasons. The directional effects result in significantly different WTP estimates, different market sizes reflecting the population with positive WTP, and differences in total WTP up to 32 %. <br/...|$|R
40|$|Recent debate {{following}} {{the rejection of}} the Environment Agency case regarding an application for water abstraction at Axford on the River Kennet has focused upon the benefits procedure employed for aggregating non-user benefits which underpinned the economic case put forward by the Agency (although this was not the reason cited by the inquiry for rejection of the case). Commentators have seen this case as setting an unfortunate precedent for the use of economic assessments in such resource management issues. The paper presents a number of highly tractable alternative methods for the <b>aggregation</b> of <b>benefits</b> estimates designed to address the central problems of the definition of a relevant aggregation population and a potential decay of values with increasing distance from a given valuation site. These methods are tested using data obtained from a national survey of non-users of a specific natural area. Results from this application indicate that simpler approaches such as that used at the Axford inquiry may result in aggregate benefits estimates which are very substantially larger than those produced by our proposed alternative approaches to aggregation. ...|$|R
