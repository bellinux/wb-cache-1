6|10|Public
5|$|The film is also {{noteworthy}} {{because its}} soundtrack {{is the first}} in Indian cinema to be released in DVD-Audio in addition to other audio formats. The tracks have been mixed in London in 5.1 Surround Sound and audiophiles can choose the format from the <b>audio</b> <b>menu.</b> Four bonus tracks from other films are included, and the lyrics of all 10 tracks can be viewed on-screen while the music is playing, enabling karaoke sing-along.|$|E
5000|$|<b>Audio</b> <b>menu</b> {{allowing}} {{users to}} activate many BlindSquare functions by pressing buttons on their headsets {{instead of using}} the touch screen of their iOS device.|$|E
50|$|Similarly, {{the limited}} number of DVDs {{available}} with description in North America (less than 100—as compared to over 500 in the United Kingdom and over 700 in Australia) is further complicated by the lack of an <b>audio</b> <b>menu</b> on no {{more than a handful of}} those DVDs.|$|E
50|$|Pink Floyd Pulse DVD — Music {{producer}}. DVD producer (with Storm Thorgerson). Video restoration. <b>Audio</b> for <b>menus</b> (with Joel Plante). (2005-2006).|$|R
50|$|VOB (Video Object) is the {{container}} format in DVD-Video media. VOB can contain digital video, digital <b>audio,</b> subtitles, DVD <b>menus</b> and navigation contents multiplexed {{together into a}} stream form. Files in VOB format may be encrypted.|$|R
50|$|One feature {{allowed the}} viewer to move between the two {{different}} locations in the venue which he felt had the best sound: the front row, and behind the front-of-house console. Z7 Konzertfabrik supplied blueprints for the venue; Evans and mix engineer Rich Mouser (who had run front-of-house sound for the show) designed two surround mixes to simulate both listening positions. The <b>audio</b> setup <b>menu</b> on the DVD and Blu-ray versions showed the Z7 blueprint, and displayed the listener's current position.|$|R
50|$|The film is also {{noteworthy}} {{because its}} soundtrack {{is the first}} in Indian cinema to be released in DVD-Audio in addition to other audio formats. The tracks have been mixed in London in 5.1 Surround Sound and audiophiles can choose the format from the <b>audio</b> <b>menu.</b> Four bonus tracks from other films are included, and the lyrics of all 10 tracks can be viewed on-screen while the music is playing, enabling karaoke sing-along.|$|E
5000|$|The {{following}} is {{a complete list of}} music-oriented radio stations in Grand Theft Auto IV and the music programming found on them, as credited in the Grand Theft Auto IV game manual and the Amazon.com MP3 Music Store. In the PC version there is also a [...] "Independence FM" [...] station which plays music files stored in My Documents\Rockstar Games\GTA IV\User Music path (the songs also need to be scanned on the <b>Audio</b> <b>menu</b> in Settings). Songs that featured with the downloadable content can also be heard in the original version.|$|E
40|$|As mobile devices {{increase}} in functionality, users perform more tasks when on the move. Spatial audio interfaces offer {{a solution for}} eyes-free interaction. However, such interfaces face a number of challenges when supporting multiple and simultaneous tasks, namely: 1) interference amongst multiple audio streams, and 2) the constraints of cognitive load. We present a comparative study of spatial audio techniques evaluated in a divided- and selective-attention task. A podcast was used for high cognitive load (dividedattention) and classical music for low cognitive load (selective-attention), while interacting with an <b>audio</b> <b>menu.</b> Results showed that spatial audio techniques were preferred when cognitive load was kept low, while a baseline technique using an interruptible single audio stream was significantly less preferred. Conversely, when cognitive load was increased the preferences reversed. Thus, given an appropriate task structure, spatial techniques offer a means of designing effective audio interfaces to support eyes-free mobile multitasking. Author Keywords Multitasking, audio interfaces, eyes-free interaction, cognitive load, divided-attention task, selective-attention task...|$|E
40|$|Today, {{people with}} certain reading disabilities, such as, illiterates or elderly people, are {{impacted}} in accessing and understanding highly relevant medical information in daily. Medical package information {{is presented in}} scientific writing style, with small font size, and can hardly be associated to severe diseases to the users, therefore resulting in bad usability. Paradoxically exactly {{those people who have}} difficulties reading the package insert are most likely to take medicine. The mobile service BaMoS (Barrier free Mobile Service) aims at providing assistance to people who have difficulties reading package inserts. BaMoS supports the user by using the mobile phone to read the relevant medical information and transfer the information into an understandable manner to him/her. Specifically adapted <b>audio</b> based <b>menu</b> navigation allows the user to interact with the application even though the user might have little or no reading skills at all. The <b>audio</b> based <b>menu</b> navigation provides assistance for illiterates, but also elderly people might benefit from it. This paper presents the innovative concept, the complete outline of the system architecture, and preliminary results. In future work it is planned to facilitate the usage of BaMoS by enabling the service to be attached with an alternative input device that is primarily designed for elderly people...|$|R
2500|$|The user's friends' Boxee {{activity}} feeds {{are displayed}} on the user's home screen, as is the user's own recent activity. Internet content is accessed through a sub-menu {{of each of the}} video, <b>audio,</b> and photo <b>menu</b> items, such as Video -> [...] "My videos" [...] and Video -> [...] "Internet videos".|$|R
40|$|This study investigates {{auditory}} display (<b>audio</b> only) <b>menu</b> interfaces and navigational cues. In {{an experiment}} using a prototype auditory display menu interface, differences in task completion time, {{the number of}} keystrokes used and preferences between navigational cues that were either short, short repeated or persistent. The navigational cues were based on earcon inspired design and were either persistent, short or repeated short navigational cues. The results of the experiment showed no support {{for any of the}} cues giving better performance results than any the other. The gathered data did however show how the subjects made significant improvements in completion time and keystroke count after 10 performance tasks. Validerat; 20101217 (root...|$|R
40|$|Presented of the 6 th International Conference on Auditory Display (ICAD), Atlanta, GA, April 2 - 5, 2000 This paper {{describes}} {{a framework for}} integrating non-speech <b>audio</b> to hierarchical <b>menu</b> structures where the visual feedback is limited. In {{the first part of}} this paper, emphasis is put on how to extract sound design principles from actual navigation problems. These design principles are then applied in the second part, through the design, implementation and evaluation of a set of sounds in a computer-based simulation of the Nokia 6110 mobile phone. The evaluation indicates that non-speech sound improves the performance of navigational tasks in terms of the number of errors made and the number of keypresses taken to complete the given tasks. This study provides both theoretical and practical insights about the design of audio cues intended to support navigation in complex menu structures...|$|R
40|$|This paper {{describes}} {{a framework for}} integrating non-speech <b>audio</b> to hierarchical <b>menu</b> structures where the visual feedback is limited. In {{the first part of}} this paper, emphasis is put on how to extract sound design principles from actual navigation problems. These design principles are then applied in the second part, through the design, implementation and evaluation of a set of sounds in a computer-based simulation of the Nokia 6110 mobile phone. The evaluation indicates that non-speech sound improves the performance of navigational tasks in terms of the number of errors made and the number of keypresses taken to complete the given tasks. This study provides both theoretical and practical insights about the design of audio cues intended to support navigation in complex menu structures. Keywords Telephone-Based Interfaces, Mobile Phones, Navigation, Menus, Sonification. INTRODUCTION This paper {{describes a}} framework for using non-speech audio to support navigation in menu-based int [...] ...|$|R
40|$|Mobile and {{wearable}} computers present input/output prob-lems due {{to limited}} screen space and interaction techniques. When mobile, users typically focus their visual attention on navigating their environment - making visually demanding interface designs hard to operate. This paper presents two multimodal interaction techniques designed {{to overcome these}} problems and allow truly mobile, 'eyes-free' device use. The first is a 3 D <b>audio</b> radial pie <b>menu</b> that uses head gestures for selecting items. An evaluation of a range of different audio designs showed that egocentric sounds re-duced task completion time, perceived annoyance, and al-lowed users to walk closer to their preferred walking speed. The second is a sonically enhanced 2 D gesture recognition system for use on a belt-mounted PDA. An evaluation of the system with and without audio feedback showed users' ges-tures were more accurate when dynamically guided by au-dio-feedback. These novel interaction techniques demon-strate effective alternatives to visual-centric interface de-signs on mobile devices...|$|R

