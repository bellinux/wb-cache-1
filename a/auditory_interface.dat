78|141|Public
40|$|The basic <b>auditory</b> <b>interface</b> {{techniques}} of auditory icons, earcons, and sonification can deftly {{address the needs}} of most domains. However, there are domains that cannot be adequately addressed by any single one of these techniques. By combining the characteristics of these basic techniques, hybrid <b>auditory</b> <b>interface</b> techniques can be created to cover those domains that auditory icons, earcons, or sonification cannot. This chapter describes a methodology for creating hybrid <b>auditory</b> <b>interface</b> techniques. This methodology is demonstrated through the development of a sonscation-auditory icons hybrid for use in a complex supervisory control environment. The Varkse system, which incorporates the sonjfication-auditory icons hybrid technique, is then developed to aid monitoring, fault detection, and fault isolation in a satellite-ground control environment...|$|E
30|$|AALFI {{makes use}} of a simple <b>auditory</b> <b>interface</b> to provide a person with access to {{intervention}} and feedback messages. The intervention messages detail something that the subject needs to correct, “the back door has been left open for 10  minutes please close the back door, or an action that they should carry out, “it is morning and {{it is recommended that}} you have breakfast”. In comparison the Sweet-Home project [39] provides an <b>auditory</b> <b>interface</b> that allows the person to issue commands to control a smart home; communicate with the outside and to make use of shared electronic calendar. It was decided to concentrate on only providing simple key auditory interactions to a person to help prevent information overload and to keep auditory interactions simple so that confusion may be avoided. AALFI is similar to Sweet-Home in that both offer intervention type prompts to a person however meaningful feedback is not provided by the Sweet-Home <b>auditory</b> <b>interface.</b>|$|E
30|$|However, any {{increase}} in eyes off-road time should give cause for concern and future smart in-vehicle systems should consider a design limiting the user to <b>auditory</b> <b>interface</b> only when complex road situations arise.|$|E
40|$|Proceedings of the 9 th International Conference on Auditory Display (ICAD), Boston, MA, July 7 - 9, 2003. In {{this paper}} {{we present a}} unified {{framework}} {{for the design of}} <b>auditory</b> <b>interfaces.</b> We describe the steps of the sonification process and their parameters. The process is modeled as a sequence of transformation functions from the data to be conveyed to the produced sounds. The usefulness of the framework for classifying existing <b>auditory</b> <b>interfaces</b> and for designing new ones is also discussed...|$|R
40|$|In mobile computing, {{there is}} a need for {{interfaces}} that better suit the context of use. <b>Auditory</b> <b>interfaces</b> have the potential to address the limitations of small screens and support eyes-free tasks. In order to fill this gap, we must develop more fluid and usable <b>auditory</b> <b>interfaces.</b> A key aspect of this is understanding the process of designing overviews. In this work, we describe a conceptual strategy for providing an overview of disruptions in the London Underground: The approach adopted is based on what information is perceived as most crucial to the user...|$|R
40|$|This paper {{provides}} {{an introduction to}} <b>auditory</b> <b>interfaces</b> and suggests some future work will make their development more straightforward. A review of the basic concepts of psychoacoustics is provided as without the knowledge of how humans perceive sounds, interfaces which use them effectively cannot be designed. Pitch and loudness perception, localization and auditory pattern recognition are described. Some psychological reasons for why mixed graphics and sound interfaces can be beneficial are presented and arguments are given for use of non-speech sounds. Four <b>auditory</b> <b>interfaces</b> are examined in detail. The interfac...|$|R
40|$|This paper {{discusses}} {{the importance of}} <b>auditory</b> <b>interface</b> aesthetics and presents an empirical investigation of sound aesthetics in context. The theoretical discussion examines the relationship between sound aesthetics and user satisfaction and concludes that, despite the creation of numerous auditory design methods and guidelines, none are dedicated to achieving aesthetically pleasing designs. In a case study, an empirical investigation is conducted to evaluate {{the relationship between the}} functional and aesthetic value of an <b>auditory</b> <b>interface.</b> By investigating two different tasks, this study demonstrates that the nature of the tasks allocated to subjects has {{a significant impact on the}} aesthetic judgments made by the subjects. Consequently, functional and aesthetic properties of auditory cannot be dealt with independently. 1...|$|E
40|$|This paper {{presents}} {{the design and}} evaluation of a hypermedia system for blind users, making use of a non-visual interface, non-speech sounds, three input devices, and a 37 node hypermedia module. The important components of an effective <b>auditory</b> <b>interface</b> are discussed, together with {{the design of the}} <b>auditory</b> <b>interface</b> to hypermedia material. The evaluation, which was conducted over several weeks and used a range of complementary objective and subjective measures to assess users' performance and preferences, is described. The findings from the evaluation with nine visually impaired student participants are presented. The results from this research {{can be applied to the}} design and evaluation of other non-visual hypermedia systems, such as auditory World Wide Web (WWW) browsers and digital talking books. ?? 1999 Taylor & Francis Ltd...|$|E
40|$|Presented at the 10 th International Conference on Auditory Display (ICAD 2004) This paper {{discusses}} {{the importance of}} <b>auditory</b> <b>interface</b> aesthetics and presents an empirical investigation of sound aesthetics in context. The theoretical discussion examines the relationship between sound aesthetics and user satisfaction and concludes that, despite the creation of numerous auditory design methods and guidelines, none are dedicated to achieving aesthetically pleasing designs. In a case study, an empirical investigation is conducted to evaluate {{the relationship between the}} functional and aesthetic value of an <b>auditory</b> <b>interface.</b> By investigating two different tasks, this study demonstrates that the nature of the tasks allocated to subjects has {{a significant impact on the}} aesthetic judgments made by the subjects. Consequently, functional and aesthetic properties of auditory cannot be dealt with independently...|$|E
40|$|This paper {{introduces}} a draft framework for a shared <b>auditory</b> user <b>interface</b> (AUI) environment. Y-Windows, {{similar to the}} approach of the X-Windows GUI framework [1] in the Unix world, aims to provide common functionality for the easier development and design of AUIs. This initial publication of these ideas, originally roughly developed within a diploma thesis [2], should encourage researchers and developers from the <b>auditory</b> <b>interfaces</b> community to contribute to the further development and possible future implementation of this concept...|$|R
40|$|Presented at 2 nd International Conference on Auditory Display (ICAD), Santa Fe, New Mexico, November 7 - 9, 1994. Current {{research}} in <b>auditory</b> <b>interfaces</b> {{has produced a}} number of interesting interfaces without resulting in the compilation of design guidelines for creating descendent interfaces. This lack of a common design methodology may be partially responsible for the scarcity of commercial interfaces that make use of sound. Factors that affect the usability of <b>auditory</b> <b>interfaces</b> are identified, and are {{used as the basis}} for a simple design methodology for incorporating auditory icons in human-computer interfaces. Two steps in this methodology are evaluating the identifiability of auditory cues and evaluating the possible conceptual mappings between the cues and concepts in interfaces. Two experiments that explore these issues are summarized...|$|R
40|$|Presented at the 11 th International Conference on Auditory Display (ICAD 2005) The {{computer}} game {{has begun to}} establish itself within the wider entertainment industry, and has thus attracted considerable interest from more general interaction designers. However, while {{computer game}} audio has become increasingly sophisticated, it remains a discipline largely overlooked by the research community. We begin by outlining similarities between each discipline, highlighting those which we believe provide interesting opportunities for designers of <b>auditory</b> <b>interfaces.</b> We also suggest that, through {{an understanding of the}} everyday practices of computer game sound designers and their colleagues within the industry, the process of sound design for alternative forms of interfaces can be considerably informed. To discover and understand some of these practices, we present our experiences conducting a field study using ethnographic methods with a major UK-based computer game developer. We highlight discoveries which we believe are pertinent for the design of <b>auditory</b> <b>interfaces</b> and thus merit further research. Our study forms part of our wider research to develop a grounded theory (i. e. a theory conceived via the data collected during the field study) to understand the reality of sound design within the computer games industry, relationships to the design of more general interfaces and thus how we approach the design of contemporary <b>auditory</b> <b>interfaces...</b>|$|R
40|$|We {{describe}} the speech-enabling approach to building auditory interfaces that treat speech as a first-class modality. The process of designing effective auditory interfaces is decomposed into identifying the atomic actions {{that make up}} the user interaction and the conversational gestures that enable these actions. The <b>auditory</b> <b>interface</b> is then synthesized by mapping these conversational gestures to appropriate primitives in the auditory environment. We illustrate this process with a concrete example by developing an <b>auditory</b> <b>interface</b> to the visually intensive task of playing tetris. Playing Tetris is a fun activity 1 that has many of the same demands as day-to-day activities on the electronic desktop. Speech-enabling Tetris thus not only provides a fun way to exercise ones geometric reasoning abilities —it provides useful lessons in speech-enabling common-place computing tasks...|$|E
40|$|Mitsopoulos and Edwards ICAD 1998 paper {{deals with}} the design of {{auditory}} widgets as exemplars of applying sound psycholog-ical theories of auditory perception and attention {{in the field of}} <b>auditory</b> <b>interface</b> design. The research, briefly herein described, is presented in detail in Mitsopoulos [2000]. Future work at all three levels of the methodology is foreseen, {{as well as in the}} integration of input and output modalities...|$|E
40|$|Presented at 3 rd International Conference on Auditory Display (ICAD), Palo Alto, California, November 4 - 6, 1996. This paper {{discusses}} the design considerations of an <b>auditory</b> <b>interface</b> for an operating {{system with a}} graphic user interface. The Cutting Edge Scenario, the last publicly shown Taligent OS demo, illustrates certain audio interface design points. Additional subsequent ideas regarding adding audio to an operating system like the TalOS will be discussed...|$|E
40|$|The {{computer}} game {{has begun to}} establish itself within the wider entertainment industry, and has thus attracted considerable interest from more general interaction designers. However, while {{computer game}} audio has become increasingly sophisticated, it remains a discipline largely overlooked by the research community. We begin by outlining similarities between each discipline, highlighting those which we believe provide interesting opportunities for designers of <b>auditory</b> <b>interfaces.</b> We also suggest that, through {{an understanding of the}} everyday practices of computer game sound designers and their colleagues within the industry, the process of sound design for alternative forms of interfaces can be considerably informed. To discover and understand some of these practices, we present our experiences conducting a field study using ethnographic methods with a major UK-based computer game developer. We highlight discoveries which we believe are pertinent for the design of <b>auditory</b> <b>interfaces</b> and thus merit further research. Our study forms part of our wider research to develop a grounded theory (i. e. a theory conceived via the data collected during the field study) to understand the reality of sound design within the computer games industry, relationships to the design of more general interfaces and thus how we approach the design of contemporary <b>auditory</b> <b>interfaces.</b> 1...|$|R
40|$|Presented at the 8 th International Conference on Auditory Display (ICAD), Kyoto, Japan, July 2 - 5, 2002. This paper {{introduces}} a draft framework for a shared <b>auditory</b> user <b>interface</b> (AUI) environment. Y-Windows, {{similar to the}} approach of the X-Windows GUI framework [1] in the Unix world, aims to provide common functionality for the easier development and design of AUIs. This initial publication of these ideas, originally roughly developed within a diploma thesis [2], should encourage researchers and developers from the <b>auditory</b> <b>interfaces</b> community to contribute to the further development and possible future implementation of this concept...|$|R
40|$|A {{number of}} experiments, {{which have been}} carried out using non-speech <b>auditory</b> <b>interfaces,</b> are {{reviewed}} and {{the advantages and disadvantages of}} each are discussed. The possible advantages of using non-speech audio media such as music are discussed – richness of the representations possible, the aesthetic appeal, and the possibilities of such interfaces being able to handle abstraction and consistency across the interface. 1...|$|R
40|$|This paper {{describes}} the functionality, the used models and {{an evaluation of}} the Visual <b>Auditory</b> <b>Interface</b> Design (Visual-AID) prototyping tool which assists the Usability Engineering Process for Auditory User Interfaces (AUI). The process generalizes the experiences made in the INVITE-ZIB-Project, which creates an auditory Web browser for blind users (Donker et al. 2002). The complete user-centered design process defines three main components: guidelines and rules, auditory interaction objects (audIO) and a tool to generate evaluation mock-ups. ...|$|E
40|$|Abstract: The paper {{describes}} an <b>auditory</b> <b>interface</b> using directional sound as a pos-sible support for pilots during approach in an instrument landing scenario. Several ways of producing directional sounds are illustrated. One using speaker pairs and controlling power distribution between speakers is evaluated experimentally. Results show, that power alone is insufficient for positioning single isolated sound events, although {{discrimination in the}} horizontal plane performs better than in the vertical. Additional sound parameters to compensate for this are proposed. Copyright © 2003 IFA...|$|E
40|$|AbstractClick In {{contrast}} to common language teaching software, a software has been developed, using speech recognition technology {{with a rich}} visual and <b>auditory</b> <b>interface</b> allowing user to pronounce and learn pronunciation activities with their pictures, in this work. Purpose is to provide material for children in early age and special education centers to contribute language education. In this way, the usage of learning techniques in language teaching in a computer aided environment to learn pronunciations and some other concept with users’ speech will be possible...|$|E
40|$|A brief {{introduction}} to the basic auditory abilities of the human perceiver with particular attention toward issues that may be important {{for the design of}} <b>auditory</b> <b>interfaces</b> is presented. The importance of appropriate auditory inputs to observers with normal hearing is probably related to the role of hearing as an omnidirectional, early warning system and to its role as the primary vehicle for communication of strong personal feelings...|$|R
40|$|Presented at the 11 th International Conference on Auditory Display (ICAD 2005) A {{number of}} experiments, {{which have been}} carried out using non-speech <b>auditory</b> <b>interfaces,</b> are {{reviewed}} and {{the advantages and disadvantages of}} each are discussed. The possible advantages of using non-speech audio media such as music are discussed – richness of the representations possible, the aesthetic appeal, and the possibilities of such interfaces being able to handle abstraction and consistency across the interface...|$|R
40|$|There is {{a danger}} that <b>auditory</b> <b>{{interfaces}}</b> will only be usable by people with musical skills. Researchers in testing new interfaces often try to control for musical abilities by classifying participants as `musicians' and `non-musicians'. However, {{there is no agreement}} as to what constitutes a musician. It is proposed, therefore, {{that there should be a}} standard pre-test that can be applied to all participants. This paper describes a version of such a test which is being developed...|$|R
40|$|Presented at the 16 th International Conference on Auditory Display (ICAD 2010) on June 9 - 15, 2010 in Washington, DC. This paper {{describes}} a soundscape mapping tool, and provides {{an illustration of}} its use {{in the evaluation of}} an in-car <b>auditory</b> <b>interface.</b> The tool addresses three areas: communicating what people are listening to, showing how soundscapes can be visualized, and demonstrating how the approach can be used by a designer during the evaluation of an auditory display. The strengths and limitations of this approach are discussed and future work identified...|$|E
40|$|In {{this paper}} we {{describe}} one method of transforming a mouse-based {{graphical user interface}} into a navigable, grid-based <b>auditory</b> <b>interface.</b> We also report {{the results of an}} experiment that tested the effectiveness of a drawing tool for the blind called IC 2 D that uses this interaction style. The experiment included eight visually impaired participants and eight blindfolded sighted participants. The results show that auditory interpretation of graphics is an effective interface technique for visually impaired users. Further, the experiment demonstrates that visually impaired users can develop meaningful drawings when given adequate t chnological support...|$|E
40|$|This paper {{explores the}} {{prototype}} design of an <b>auditory</b> <b>interface</b> enhancement called the Sonic Grid that helps visually impaired users navigate GUI-based environments. The Sonic Grid provides an auditory representation of GUI elements {{embedded in a}} two-dimensional interface, giving a ‘global ’ spatial context for use of auditory icons, ear-cons and speech feedback. This paper introduces the Sonic Grid, discusses insights gained through participatory design {{with members of the}} visually impaired community, and suggests various applications of the technique, including its use to ease the learning curve for using computers by the visually impaired...|$|E
40|$|This book {{covers the}} design, {{evaluation}} and development process for interactive human computer interfaces including user interface design principles, task analysis, <b>interface</b> design methods, <b>auditory</b> <b>interfaces,</b> haptics, user interface evaluation, usability testing prototyping, issues in interface construction, interface evaluation, World Wide Web and mobile device interface issues. The book {{is ideal for}} the student that wants {{to learn how to}} use prototyping tools as part of the interface design and how to evaluate an interface and its interaction quality by using usability testing techniques...|$|R
40|$|This paper {{describes}} work {{to provide}} mappings between X-based graphical user <b>interfaces</b> and <b>auditory</b> <b>interfaces</b> transparently to applications. The primary motivation {{for this work}} is to provide accessibility to graphical applications for users who are blind. We describe our architecture for capturing, modeling, and translating X-based interfaces. We conclude with some ideas for future work, a description of {{some aspects of the}} X Window System which caused difficulties in the design and implementation of our system, and some indications of possible solutions to the problems we encountered...|$|R
50|$|An <b>auditory</b> output brain-computer <b>interface</b> for speech communication.|$|R
40|$|This paper {{presents}} {{a study of}} an auditory version of the game "Towers of Hanoi". In this study, we have compared three different strategies for continuous presentation of the objects. The focus for {{this study is to}} investigate the nature of auditory direct manipulation, where continuous presentation {{is one of the key}} aspects. The results show that the differences between the strategies need to be explored further by experimentation. Additionally, much effort has to be put on the learning phase of the <b>auditory</b> <b>interface</b> and the mouse interaction has to be investigated further...|$|E
40|$|We {{present a}} {{design for a}} voting system with a modular voting {{architecture}} and an electronic audit trail. The voting system consists of am electronic ballot printer, a PC with a visual or <b>auditory</b> <b>interface</b> that prints a paper ballot and mtaintains an electronic audit trail, a ballot verification station that reads a paper ballot and either displays or “speaks ” the ballot’s selections and undervotes, and a ballot tabulation and reconciliation station that reads the ballots and tabulates the votes and reconciles them against the electronic audit trail. A prototype of this system has been built and demonstrated. 1...|$|E
40|$|This paper {{describes}} an exploratory experiment investigating access to non-seen diagrams {{with a view}} to present-ing such diagrams through an <b>auditory</b> <b>interface.</b> Sighted individuals asked questions of a human experimenter about diagrams they could not see, in order to learn about them. The dialogue was recorded and analysed. The analysis resulted in an insight into the strategies used by the participants and a handle on the information requirements of the participants. Results showed that participants could understand and internalise the simpler diagrams, though not with complete success, but faltered on the more complex diagram. Several strategies and points for further investigation emerged. ...|$|E
25|$|She is {{best known}} for her {{research}} in the fields of human-computer interaction, ubiquitous computing, health informatics, and assistive technology. She pioneered creating nonspeech <b>auditory</b> <b>interfaces</b> from graphical interfaces to enable blind computer users to work with modern computer applications. From 2001 to 2005, she was selected to be the associate director of the GVU Center at Georgia Tech, and in 2005 she was appointed director. Her current research explores the implications and opportunities stemming from the pervasive presence of computation in the informal activities of everyday life.|$|R
30|$|The National Highway Traffic Safety Administration (NHTSA) is in {{the process}} of {{developing}} voluntary guidelines to minimize driver distraction created by electronic devices in the vehicle. There are three planned phases to the NHTSA guidelines. The phase 1 guidelines, entered into the Federal Register on March 15, 2012, address visual–manual interfaces for devices installed by vehicle manufactures. The phase 2 guidelines, scheduled for release sometime in 2016, will address visual–manual interfaces for portable and aftermarket electronic devices. Phase 3 guidelines will address voice-based <b>auditory</b> <b>interfaces</b> for devices installed in vehicles and for portable aftermarket devices.|$|R
50|$|She is {{best known}} for her {{research}} in the fields of human-computer interaction, ubiquitous computing, health informatics, and assistive technology. She pioneered creating nonspeech <b>auditory</b> <b>interfaces</b> from graphical interfaces to enable blind computer users to work with modern computer applications. From 2001 to 2005, she was selected to be the associate director of the GVU Center at Georgia Tech, and in 2005 she was appointed director. Her current research explores the implications and opportunities stemming from the pervasive presence of computation in the informal activities of everyday life.|$|R
