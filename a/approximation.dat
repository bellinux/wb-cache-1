10000|10000|Public
5|$|At the time, {{the general}} method {{to compute the}} inverse square root was to {{calculate}} an <b>approximation</b> for , then revise that <b>approximation</b> via another method until it came within an acceptable error range of the actual result. Common software methods in the early 1990s drew approximations from a lookup table. The key of the fast inverse square root was to directly compute an <b>approximation</b> by utilizing the structure of floating-point numbers, proving faster than table lookups. The algorithm was approximately four times faster than computing the square root with another method and calculating the reciprocal via floating point division. The algorithm was designed with the IEEE 754-1985 32-bit floating point specification in mind, but investigation from Chris Lomont showed {{that it could be}} implemented in other floating point specifications.|$|E
5|$|Elliptic {{filters are}} filters {{produced}} by the insertion-loss method which use elliptic rational functions in their transfer function as an <b>approximation</b> to the ideal filter response {{and the result is}} called a Chebyshev <b>approximation.</b> This is the same Chebyshev <b>approximation</b> technique used by Cauer on image filters but follows the Darlington insertion-loss design method and uses slightly different elliptic functions. Cauer had some contact with Darlington and Bell Labs before WWII (for a time he worked in the US) but during the war they worked independently, in some cases making the same discoveries. Cauer had disclosed the Chebyshev <b>approximation</b> to Bell Labs but had not left them with the proof. Sergei Schelkunoff provided this and a generalisation to all equal ripple problems. Elliptic filters are a general class of filter which incorporate several other important classes as special cases: Cauer filter (equal ripple in passband and stopband), Chebyshev filter (ripple only in passband), reverse Chebyshev filter (ripple only in stopband) and Butterworth filter (no ripple in either band).|$|E
5|$|In this Proposition, Newton derives the {{consequences}} of his theorem of revolving orbits in the limit of nearly circular orbits. This <b>approximation</b> is generally valid for planetary orbits and the orbit of the Moon about the Earth. This <b>approximation</b> also allows Newton to consider a great variety of central force laws, not merely inverse-square and inverse-cube force laws.|$|E
30|$|Since only {{explicit}} solutions {{of a small}} {{class of}} SDEs with Poisson random measure can be obtained, one needs, in general, discrete time <b>approximations</b> which {{can be divided into}} strong <b>approximations</b> and weak <b>approximations.</b> Strong <b>approximations</b> provide pathwise <b>approximations,</b> while weak <b>approximations</b> are appropriate for problems such as derivative pricing or the evaluation of risk measures and expected utilities.|$|R
40|$|Recently, many {{scholars}} investigated interval, triangular, and trapezoidal <b>approximations</b> of fuzzy numbers. These researches can be grouped into two classes: the Euclidean distance {{class and the}} non-Euclidean distance class. Most <b>approximations</b> in the Euclidean distance class can be calculated by formulas, but calculating <b>approximations</b> in the other class is more complicated. In this paper, we study interval, triangular, and trapezoidal <b>approximations</b> under a weighted Euclidean distance which generalize all <b>approximations</b> in the Euclidean distance class. First, we embed fuzzy numbers into a Hilbert space, and then introduce these weighted <b>approximations</b> by means of best <b>approximations</b> from closed convex subsets of the Hilbert space. Finally, we apply the reduction principle to simplify calculations of these <b>approximations...</b>|$|R
40|$|AbstractA {{new type}} of Taylor series based finite {{difference}} <b>approximations</b> of higher-degree derivatives of a function are presented in closed forms, with their coefficients given by explicit formulas for arbitrary orders. Characteristics and accuracies of presented <b>approximations</b> and already presented central difference higher-degree <b>approximations</b> are investigated by performing example numerical differentiations. It is shown that the presented <b>approximations</b> are more accurate than the central difference <b>approximations,</b> especially for odd degrees. However, for even degrees, central difference <b>approximations</b> become attractive, as the coefficients of the presented <b>approximations</b> of even degrees do not correspond to equispaced input samples...|$|R
5|$|Refine the <b>approximation</b> using {{a single}} {{iteration}} of the Newton's method.|$|E
5|$|The ~30-day {{month is}} an <b>approximation</b> {{of the lunar}} cycle.|$|E
5|$|This {{provides}} the geometrical interpretation of : {{it is the}} best <b>approximation</b> to x by elements of V.|$|E
5000|$|The {{successive}} <b>approximations</b> reinforced {{are increasingly}} accurate <b>approximations</b> {{of a response}} desired by a trainer. As training progresses the trainer stops reinforcing the less accurate <b>approximations.</b> For example, in training a rat to press a lever, the following successive <b>approximations</b> might be reinforced: ...|$|R
40|$|Abstract—Rough sets, a {{tool for}} data mining, deal with the vagueness and {{granularity}} in information systems. Rough <b>approximations</b> on a complete completely distributive lattice(CCD lattice for short) and brings generalizations of rough sets into a unified framework are discussed in [3]. This paper {{is devoted to the}} discussion of the relationship between <b>approximations</b> and topologies on a CCD lattice. It is proved that the set of all upper <b>approximations</b> (or of lower <b>approximations)</b> with respect to a partition consists of a clopen topology; and conversely, a clopen topology which obey disjoint axiom can be induced by <b>approximations.</b> Furthermore, the axiomatic characterizations of upper and lower <b>approximations</b> are presented. Index Terms—Rough sets, complete completely distributive lattice, <b>approximations,</b> clopen topology I...|$|R
5000|$|These {{empirical}} <b>approximations</b> are {{equivalent to}} the particle integral <b>approximations</b> ...|$|R
25|$|The {{best known}} <b>approximation</b> ratio of a {{polynomial}} time <b>approximation</b> algorithm for pathwidth is O((logn)3/2).|$|E
25|$|The Max-Cut Problem is APX-hard, {{meaning that}} there is no polynomial-time <b>approximation</b> scheme (PTAS), {{arbitrarily}} close to the optimal solution, for it, unless P = NP. Thus, every polynomial-time <b>approximation</b> algorithm achieves an <b>approximation</b> ratio strictly less than one.|$|E
25|$|Simultaneous {{perturbation}} stochastic <b>approximation</b> (SPSA) {{method for}} stochastic optimization; uses random (efficient) gradient <b>approximation.</b>|$|E
40|$|We propose <b>approximations</b> to {{the normal}} {{distribution}} function and to its inverse function using single polynomials in each case. The absolute error of these <b>approximations</b> is significantly less than those of other <b>approximations</b> available in the literature. We compare all the polynomial <b>approximations</b> empirically by calculating their respective percentage absolute relative errors. </p...|$|R
40|$|Discrete scan {{statistics}} {{are used for}} testing the null hypothesis that the observations are identically distributed against a clustering alternative that specifies an increased incidence of observations in a connected subregion of the circle. To implement the testing procedures based on the scan statistics, accurate <b>approximations</b> are needed for their tail probabilities. In this article we derive accurate product-type and Poisson-type <b>approximations</b> for the probabilities of discrete scan statistics for the binomial and the Poisson models. Numerical results are presented to evaluate {{the performance of the}} <b>approximations</b> derived in this article. Compound-Poisson <b>approximations</b> Moving sums Poisson <b>approximations</b> Product-type <b>approximations</b> Testing for identical observations...|$|R
40|$|The exact {{measurement}} of the welfare costs of tax and price reform requires a detailed knowledge of individual preferences. Typically, first-order <b>approximations</b> of welfare costs are calculated avoiding detailed knowledge of substitution effects. The authors derive second-order <b>approximations</b> which, unlike first-order <b>approximations,</b> require knowledge {{of the distribution of}} substitution elasticities. This paper asks to what extent simple <b>approximations</b> can be used to measure the welfare costs of tax reform and evaluates the magnitude of the biases for a plausible size tax reform. In the authors' empirical examples, first-order <b>approximations</b> display systematic biases; second-order <b>approximations</b> always work well. Copyright 1996 by Royal Economic Society. ...|$|R
25|$|Function <b>approximation,</b> or {{regression}} analysis, including {{time series}} prediction, fitness <b>approximation</b> and modeling.|$|E
25|$|Complex {{values of}} the gamma {{function}} can be computed numerically with arbitrary precision using Stirling's <b>approximation</b> or the Lanczos <b>approximation.</b>|$|E
25|$|<b>Approximation</b> theory studies how to {{find the}} best <b>approximation</b> to a given {{function}} by another function from some predetermined class, and how good this <b>approximation</b> is. This clearly yields a bound on how well the interpolant can approximate the unknown function.|$|E
5000|$|... #Caption: The Taylor <b>approximations</b> for [...] (black). For , the <b>approximations</b> diverge.|$|R
40|$|Saddlepoint <b>approximations</b> for the {{trimmed mean}} and the studentized trimmed mean are established. Some {{numerical}} {{evidence on the}} quality of our saddlepoint <b>approximations</b> is also included. These <b>approximations</b> {{can be applied to the}} bootstrap for the studentized trimmed mean, to provide very fast and accurate <b>approximations</b> to the bootstrap without the need for extensive resampling...|$|R
40|$|In {{this paper}} the (e#ective) bias of certain {{generalised}} linear <b>approximations</b> to the S-box are considered. Whereas, in the literature, the cryptanalyst typically restricts this search to linear <b>approximations</b> over Z 2, we here consider linear <b>approximations</b> over Z 4 and, more generally still, consider <b>approximations</b> which are linear {{in the sense}} that they can be completely factorised into the tensor product of length-two vectors. Consequently, significantly higher biases can be found in comparison to Z 2 -linear <b>approximations...</b>|$|R
25|$|The total {{least squares}} <b>approximation</b> {{of the data}} is generically {{equivalent}} to the best, in the Frobenius norm, low-rank <b>approximation</b> of the data matrix.|$|E
25|$|The Gaussian <b>approximation</b> {{works to}} varying degrees {{depending}} on the optical details, and corrections can sometimes be applied to offset the errors in <b>approximation.</b>|$|E
25|$|A general {{upper bound}} for the <b>approximation</b> error in the central limit theorem is given by the Berry–Esseen theorem, {{improvements}} of the <b>approximation</b> are given by the Edgeworth expansions.|$|E
40|$|In this paper, {{we propose}} a {{collection}} of <b>approximations</b> for the 8 -point discrete cosine transform (DCT) based on integer functions. <b>Approximations</b> could be systematically obtained and several existing <b>approximations</b> were identified as particular cases. Obtained <b>approximations</b> were compared with the DCT and assessed {{in the context of}} JPEG-like image compression. Comment: 21 pages, 4 figures, corrected typo...|$|R
40|$|Derivation of literal <b>approximations</b> to the {{aircraft}} dynamic modes {{remains one of}} the central problems in the theory of aircraft flight dynamics, and one that has never been satisfactorily resolved. Although <b>approximations</b> to the fast modes (short period, roll) are generally good, the slow modes (phugoid, dutch roll, spiral) seem to have several competing <b>approximations,</b> none of which are uniformly satisfactory. This paper examines the fundamental assumptions behind the traditional approach to the derivation of literal <b>approximations.</b> A major flaw in all previous derivations resulting in incorrect slow-mode <b>approximations</b> is uncovered. In following a formal procedure, improved literal <b>approximations</b> are derived for the slow modes. In this process, a new condition for onset of directional departure is obtained, which is related to the dutch-roll frequency. Predictions from the literal <b>approximations</b> derived in this paper are compared with actual numerical values for an example aircraft to illustrate conditions under which the <b>approximations</b> work well, and to point out the fundamental limitations of the literal <b>approximations</b> derived by the traditional approach...|$|R
5000|$|... #Caption: Darker {{version of}} the flag using RGB <b>approximations</b> of semi-official Pantone <b>approximations</b> ...|$|R
25|$|There are two {{important}} points: Firstly, if the grains are not uniformly distributed, then the <b>approximation</b> will be poor. Secondly, {{there should be}} a large number of inputs. The <b>approximation</b> is generally poor if only a few grains are randomly dropped into the whole square. On average, the <b>approximation</b> improves as more grains are dropped.|$|E
25|$|A {{more complex}} {{model of the}} point charge array {{introduces}} an effective medium by averaging the microscopic charges; for example, the averaging can arrange that only dipole fields play a role. A related approach is to divide the charges into those nearby the point of observation, and those far enough away to allow a multipole expansion. The nearby charges then give rise to local field effects. In a common model of this type, the distant charges are treated as a homogeneous medium using a dielectric constant, and the nearby charges are treated only in a dipole <b>approximation.</b> The <b>approximation</b> of a medium or an array of charges by only dipoles and their associated dipole moment density is sometimes called the point dipole <b>approximation,</b> the discrete dipole <b>approximation,</b> or simply the dipole <b>approximation.</b>|$|E
25|$|The {{diffusion}} equation yields an <b>approximation</b> of {{the time}} evolution of the probability density function associated {{to the position of}} the particle going under a Brownian movement under the physical definition. The <b>approximation</b> is valid on short timescales.|$|E
40|$|Rough sets, a {{tool for}} data mining, deal with the vagueness and {{granularity}} in information systems. Rough <b>approximations</b> on a complete completely distributive lattice(CCD lattice for short) and brings generalizations of rough sets into a unified framework are discussed in [3]. This paper {{is devoted to the}} discussion of the relationship between <b>approximations</b> and topologies on a CCD lattice. It is proved that the set of all upper <b>approximations</b> (or of lower <b>approximations)</b> with respect to a partition consists of a clopen topology; and conversely, a clopen topology which obey disjoint axiom can be induced by <b>approximations.</b> Furthermore, the axiomatic characterizations of upper and lower <b>approximations</b> are presented. </p...|$|R
40|$|<b>Approximations</b> {{which can}} be {{evaluated}} with precision using floating-point arithmetic are presented. The particular set of <b>approximations</b> thus far developed are for the function TAN and the functions of USASI FORTRAN excepting SQRT and EXPONENTIATION. These <b>approximations</b> are, furthermore, specialized to particular forms which are especially suited to a computer with a small memory, in {{that all of the}} <b>approximations</b> can share one general purpose subroutine for the evaluation of a polynomial in the square of the working argument. Includes bibliographical references (p. 68). <b>Approximations</b> {{which can be}} evaluated with precision using floating-point arithmetic are presented. The particular set of <b>approximations</b> thus far developed are for the function TAN and the functions of USASI FORTRAN excepting SQRT and EXPONENTIATION. These <b>approximations</b> are, furthermore, specialized to particular forms which are especially suited to a computer with a small memory, in that all of the <b>approximations</b> can share one general purpose subroutine for the evaluation of a polynomial in the square of the working argument. Mode of access: Internet...|$|R
40|$|Abstract—Rough sets {{deal with}} the vagueness and {{granularity}} in information systems. Reference[3] discusses rough <b>approximations</b> on a complete completely distributive lattice(CCD lattice for short) and brings generalizations of rough sets into a unified framework. This paper {{is devoted to the}} discussion of the relationship between <b>approximations</b> and topologies on a CCD lattice. It is proved that the set of all upper <b>approximations</b> (or of lower <b>approximations)</b> with respect to a partition consists of a clopen topology. Index Terms—Rough sets, Complete Completely DistributiveLattice, <b>Approximations,</b> Clopen Topology...|$|R
