7|253|Public
50|$|RAM {{contains}} multiplexing and demultiplexing circuitry, {{to connect}} the data lines to the <b>addressed</b> <b>storage</b> for reading or writing the entry. Usually more than one bit of storage is accessed by the same address, and RAM devices often have multiple data lines and {{are said to be}} '8-bit' or '16-bit' etc. devices.|$|E
40|$|This paper {{provides}} {{a summary of}} an NCSE, (nuclear critical safety evaluation) which was performed to establish conditions for which the contents of an F Canyon tank would remain subcritical. The tank contains fissionable isotopes of americium, curium, plutonium and uranium. The evaluation <b>addressed</b> <b>storage</b> of the tank contents and provided information relative for processing to ecover or {{to dispose of the}} americium and curium isotopes. Calculations were performed using the Savannah River Site JOSHUA J- 70 version modules of GLASS-ANISN for the determination of neutron multiplication constants, k{sub inf} and k{sub eff}, and subcritical mass of various Am, Cm, and Pu homogeneous water mixtures...|$|E
40|$|Centera uses {{cryptographic}} hash {{functions as a}} means of addressing stored objects, thus creating a new class of data storage referred to as CAS (content <b>addressed</b> <b>storage).</b> Such hashing serves the useful function of providing a means of uniquely identifying data and providing a global handle to that data, referred to as the Content Address or CA. However, such a model begs the question: how certain can one be that a given CA is indeed unique? In this paper we describe fundamental concepts of {{cryptographic hash}} functions, such as collision resistance, pre-image resistance, and second-preimage resistance. We then map these properties to the MD 5 and SHA- 256 hash algorithms, which are used to generate the Centera content address. Finally, we present a proof of the collision resistance of the Centera Content Address. Comment: 10 pages, 4 figure...|$|E
5000|$|Profile G - <b>Addresses</b> video <b>storage,</b> recording, search, and retrieval.|$|R
40|$|The HDF Group {{maintains}} and evolves HDF software used by NASA ESDIS {{program to}} manage remote sense data. In this talk {{we will discuss}} new features of HDF (Virtual Datasets, Single writerMultiple reader access, Community supported HDF 5 compression filters) that <b>address</b> <b>storage</b> and IO performance requirements of the applications that work with the ESDIS data products...|$|R
30|$|One of {{the most}} {{prominent}} ones are Berkeley Data Analytics Stack (BDAS) from the AMPLAb project in Berkeley. BDAS is a multi-layered architecture that provides tools for virtualizing resources, <b>addressing</b> <b>storage,</b> data processing and querying as underlying tools for Big Data aware applications. Another important Big Data stack system is AsterixDB 21 from the Asterix project. AsterixDB is a scalable, open source Big Data Management System (BDMS).|$|R
40|$|Dimirovski, Georgi M. (Dogus Author) The robust Hinfin control {{problem for}} the {{generator}} excitation system with the damping coefficient uncertainty and external disturbances, is <b>addressed.</b> <b>Storage</b> functions of the control system are constructed based on modified adaptive backstepping sliding mode control method and Lyapunov method. A nonlinear robust Hinfin controller and a parameter updating law are obtained simultaneously. The controller can not only attenuate the influences of external disturbances on the system output, but also has strong robustness for system parameters variation. Since the controller design is based completely on the nonlinear dynamic system without any linearization, the nonlinear property of the dynamic system is well preserved. The simulation results show that more rapid speed response and stronger robustness {{can be obtained by}} the proposed method than the conventional adaptive backstepping and adaptive backstepping sliding mode control methods...|$|E
40|$|This chapter {{gives an}} {{overview}} of probe-based data storage research {{over the last three}} decades, encompassing all aspects of a probe recording system. Following the division found in all mechanically <b>addressed</b> <b>storage</b> systems, the different subsystems (media, read/write heads, positioning, data channel, and file system) will be discussed. In the media subsection various recording media will be treated, such as polymer based, phase change, ferroelectric and magnetic. In the probe array subsection various generations of thermal probes will be discussed, as well as examples of alternative write probes using currents, electric or magnetic fields, and different principles for data detection. Special attention is paid to parallel readout of probe arrays. In the positioning section, examples will be shown of electric and magnetic scanners, either precision engineered or realized by micromachining technologies, or combinations thereof. In the systems subsection the data channel will be discussed, including the read/write electronics circuitry, data detection, and coding algorithms. Special attention is paid to the writing strategy and considerations for probe-based storage file systems. ...|$|E
40|$|Many memory {{institutions}} hold large {{collections of}} hand-held media, which can comprise hundreds of terabytes of data spread over {{many thousands of}} data-carriers. Many of these carriers {{are at risk of}} significant physical degradation over time, depending on their composition. Unfortunately, handling them manually is enormously time consuming and so a full and frequent evaluation of their condition is extremely expensive. It is, therefore, important to develop scalable processes for stabilizing them onto backed-up online storage where they can be subject to highquality digital preservation management. This {{goes hand in hand with}} the need to establish efficient, standardized ways of recording metadata and to deal with defective data-carriers. This paper discusses processing approaches, workflows, technical set-up, software solutions and touches on staffing needs for the stabilization process. We have experimented with different disk copying robots, defined our metadata, and <b>addressed</b> <b>storage</b> issues to scale stabilization to the vast quantities of digital objects on hand-held data-carriers that need to be preserved. Working closely with the content curators, we have been able to build a robust data migration workflow and have stabilized over 16 terabytes of data in a scalable and economical manner. Comment: 11 pages, presented at iPres 2011. Also publishing in corresponding conference proceeding...|$|E
30|$|One pipeline, {{described}} in [65], did not <b>address</b> the <b>storage</b> stage {{and did not}} explain this decision.|$|R
5000|$|Working Group on Collection and Transfer Technology: <b>addresses</b> the <b>storage,</b> collection, {{transfer}} and transportation of solid wastes.|$|R
5000|$|The program {{must either}} {{be linked to}} be aware of the <b>address</b> the <b>storage</b> appears at in the system, or must be position-independent, ...|$|R
40|$|Twenty-seven {{individual}} {{tree growth}} models are reviewed. The models {{take into account}} the same main physiological processes involved in carbon metabolism (photosynthate production, respiration, reserve dynamics, allocation of assimilates and growth) and share common rationales that are discussed. It is shown that the spatial resolution and representation of tree architecture used mainly depend on model objectives. Beyond common rationales, the models reviewed exhibit very different treatments of each process involved in carbon metabolism. The treatments of all these processes are presented and discussed in terms of formulation simplicity, ability to account for response to environment, and explanatory or predictive capacities. Representation of photosynthetic carbon gain ranges from merely empirical relationships that provide annual photosynthate production, to mechanistic models of instantaneous leaf photosynthesis that explicitly account for the effects of the major environmental variables. Respiration is often described empirically as the sum of two functional components (maintenance and growth). Maintenance demand is described by using temperature-dependent coefficients, while growth efficiency is described by using temperature-independent conversion coefficients. Carbohydrate reserve pools are generally represented as black boxes and their dynamics is rarely <b>addressed.</b> <b>Storage</b> and reserve mobilisation are often treated as passive phenomena, and reserve pools are assumed to behave like buffers that absorb the residual, excessive carbohydrate on a daily or seasonal basis. Various approaches to modelling carbon allocation have been applied, {{such as the use of}} empirical partitioning coefficients, balanced growth considerations and optimality principles, resistance mass-flow models, or the source-sink approach. The outputs of carbon-based models of individual tree growth are reviewed, and their implications for forestry and ecology are discussed. Three critical issues for these models to date are identified: (i) the representation of carbon allocation and of the effects of architecture on tree growth is Achilles' heel of most of tree growth models; (ii) reserve dynamics is always poorly accounted for; (iii) the representation of below ground processes and tree nutrient economy is lacking in most of the models reviewed. Addressing these critical issues could greatly enhance the reliability and predictive capacity of individual tree growth models in the near future...|$|E
40|$|Abstract. A {{preliminary}} framework, termed as DL 2 Go, {{that enables}} editable and portable personal digital libraries is presented. For mobile offline users of digital libraries, DL 2 Go can: (1) package digital libraries into mobile storage {{devices such as}} flash drives, along with needed application softwares (e. g., wiki and DBMS), (2) (de-) compress contents of digital libraries to <b>address</b> <b>storage</b> constraints of mobile users when needed, (3) enables users to add, delete, and update entities of digital libraries using wiki framework, and (4) share/sync edited contents with other DL 2 Go users and the server using web services and RSS framework. ...|$|R
40|$|The reverse mode of {{automatic}} differentiation {{is widely used}} in sci-ence and engineering. A severe bottleneck {{for the performance of}} the reverse mode, however, is the necessity to recover certain intermediate values of the program in reverse order. Among these values are computed addresses, which traditionally are recovered through forward recompu-tation and storage in memory. We propose an alternative approach for recovery that uses inverse computation based on dependency information. <b>Address</b> <b>storage</b> constitutes {{a significant portion of the}} overall storage re-quirements. An example illustrates substantial gains that the proposed approach yields and we show use cases in practical applications...|$|R
40|$|The {{instructions}} that transmit data between the index registers {{and the memory}} work only on the left half (address) portion of memory. These instructions are LDXn (load index n from <b>address</b> of <b>storage</b> word). And STXn (store the contents of index n in <b>address</b> of <b>storage</b> word). The effective address of both of these instructions includes modification by index registers. A corresponding set of instructions for transmitting data to or from the right half of memory would facilitate list structure operations. The present order code {{makes it impossible to}} so list-chaining operations (car or cdr) without disturbing the A or Q registers...|$|R
50|$|Asigra {{introduced}} the patent pending Recovery License Model® (RLM) on July 10, 2013 to <b>address</b> rising <b>storage</b> costs stemming from growing data volume. This licensing model {{allows users to}} pay based on data recovered.|$|R
50|$|OFA covers {{where to}} install {{each part of}} each product; it <b>addresses</b> the <b>storage</b> of both {{applications}} and data. Much like the FHS, OFA imposes no constraints on the locations: it merely makes recommendations.|$|R
2500|$|The 68000 has a 24-bit {{external}} {{address bus}} and two byte-select signals [...] "replaced" [...] A0. These 24 lines can therefore address 16 MB of physical memory with byte resolution. <b>Address</b> <b>storage</b> and computation uses 32 bits internally; however, the 8 high-order address bits are ignored due to the physical lack of device pins. This allows it to run software written for a logically flat 32-bit address space, while accessing only a 24-bit physical address space. [...] Motorola's intent with the internal 32-bit address space was forward compatibility, making it feasible to write 68000 software that would {{take full advantage of}} later 32-bit implementations of the 68000 instruction set.|$|R
40|$|Cryopreservation is {{fundamental}} in prolonging the viabilities of cells and tissues of clinical and biotechnological relevance ex vivo. Furthermore, {{there is an}} increasing need to <b>address</b> <b>storage</b> at more easily accessible temperatures {{in the developing world}} due to limited resources. Here, the cryopreservation of erythrocytes (red blood cells) with storage at - 20 °C using hydroxyethyl starch (HES) and the ice recrystallization inhibitor, poly(vinyl alcohol) (PVA) that is a biomimetic of naturally occurring antifreeze (glyco) proteins (AF(G) Ps) is described. This strategy eliminates the need for high concentrations of membrane penetrating solvents such as glycerol or dimethyl sulphoxide (DMSO). The addition of only 0. 1 - 0. 5 wt. ...|$|R
5000|$|The 68000 has a 24-bit {{external}} {{address bus}} and two byte-select signals [...] "replaced" [...] A0. These 24 lines can therefore address 16 MB of physical memory with byte resolution. <b>Address</b> <b>storage</b> and computation uses 32 bits internally; however, the 8 high-order address bits are ignored due to the physical lack of device pins. This allows it to run software written for a logically flat 32-bit address space, while accessing only a 24-bit physical address space. Motorola's intent with the internal 32-bit address space was forward compatibility, making it feasible to write 68000 software that would {{take full advantage of}} later 32-bit implementations of the 68000 instruction set.|$|R
40|$|Over {{the past}} few years, {{cloud-based}} platforms have been proposed to <b>address</b> <b>storage,</b> management, and computation of large-scale data, especially {{in the field of}} genomics. However, for collaboration efforts involving multiple institutes, data transfer and management, interoperability and standardization among different platforms have imposed new challenges. This paper proposes a distributed bioinformatics platform that can leverage local clusters with remote computational clusters for genomic analysis using the unified bioinformatics workflow. The platform is built with a data server configured with iRODS, a computation cluster authenticated with iPlant Agave system, and web server to interact with the platform. A Genome-Wide Association Study workflow is integrated to validate the feasibility of the proposed approach. © 2015 IEEE...|$|R
40|$|ITC/USA 2008 Conference Proceedings / The Forty-Fourth Annual International Telemetering Conference and Technical Exhibition / October 27 - 30, 2008 / Town and Country Resort & Convention Center, San Diego, CaliforniaA common {{concern in}} {{telemetry}} post-processing environments is adequate disk storage capacity to house captured and post-processed telemetry data. In today's network environments {{there are many}} storage solutions that can be deployed to <b>address</b> <b>storage</b> needs. Recent trends in storage systems reveal movement to implement security services in storage systems. After reviewing storage options appropriate for telemetry post-processing environments; the security services such systems typically offer will also be discussed and contrasted with other third party security services that might be implemented directly {{on top of a}} networked storage system...|$|R
40|$|The U. S. Department of Energy (DOE) Complex {{includes}} many sites and laboratories that store quantities of low-level, solid nuclear waste in drums {{and other types}} of shipping containers. The drums may be stored {{for long periods of time}} prior to being transported and final dispositioning. Based on the radioactivity (e. g., Pu{sup 239 } equivalent), chemical nature (e. g. volatile organic compounds) and other characteristics of the stored waste, flammable gases may evolve. Documented safety analyses (DSAs) for storage of these drums must <b>address</b> <b>storage</b> and safety management issues to protect workers, the general public, and the environment. This paper discusses an improved analytical method for determining the explosion effects flammable gas-air mixtures as well as the subsequent accident phenomenology...|$|R
5000|$|Everspin {{developed}} nvNITRO {{products to}} <b>address</b> <b>storage</b> requirements that are typically being served by NVMe products. There {{are two different}} form factors, HHHL (PCIe Gen3 x8), and U.2. These devices can store up to 1GB in data today, with greater capacities planned as MRAM densities scale up over time. nvNITRO products can handle both NVMe 1.1 and block storage requirements. Because these products are built on MRAM, they do not require the battery backup of typical magnetic storage products {{in order to protect}} data in flight. Everspin officially launched the first version of the nvNITRO in August 2017, based on 256Mb ST-MRAM (1GB and 2GB capacities). Future versions will be based on the upcoming 1Gb ST-MRAM densities which recently began sampling to customers.|$|R
40|$|This paper {{presents}} CARP, {{an integrated}} program and storage replication solution. CARP extends program replication systems {{which do not}} currently <b>address</b> <b>storage</b> errors, builds upon a record-and-replay scheme that handles nondeterminism in program execution, and uses a scheme based on recorded program state and I/O logs to enable efficient detection of silent data errors and efficient recovery from such errors. CARP {{is designed to be}} transparent to applications with minimal run-time impact and is general enough to be implemented on commodity machines. We implemented CARP as a prototype on the Linux operating system and conducted extensive sensitivity analysis of its overhead with different application profiles and system parameters. In particular, we evaluated CARP with standard unmodified email, database, and web server benchmarks and showed that it imposes acceptable overhead while providing sub-second program state recovery times on detecting a silent data error. 1...|$|R
25|$|In {{all of the}} overloads, {{the first}} {{parameter}} to the operator delete function is of type , which is the <b>address</b> of the <b>storage</b> to deallocate.|$|R
5000|$|In {{all of the}} overloads, {{the first}} {{parameter}} to the [...] function is of type void *, which is the <b>address</b> of the <b>storage</b> to deallocate.|$|R
50|$|Technologies of {{hydrogen}} economy, batteries, compressed air energy storage, and flywheel energy <b>storage</b> <b>address</b> the energy <b>storage</b> problem {{but not the}} source of primary energy. Other technologies like fission power, fusion power, and solar power {{address the problem of}} a source of primary energy but not energy <b>storage.</b> Vegetable oil <b>addresses</b> both the source of primary energy and of energy storage. The cost and weight to store a given amount of energy as vegetable oil is low compared to many of the potential replacements for fossil fuels.|$|R
40|$|A space-based radar {{mission and}} {{spacecraft}} are examined to determine system requirements for a 300 kWe space nuclear reactor power system. The spacecraft configuration and its orbit, launch vehicle, and propulsion are described. Mission profiles are <b>addressed,</b> and <b>storage</b> in assembly orbit is considered. Dynamics and attitude {{control and the}} problems of nuclear and thermal radiation are examined...|$|R
40|$|This paper <b>addresses</b> the <b>storage</b> requirement, shelf life, and the {{reliability}} of M 119 Whistling Simulator. Experimental conditions have been determined and the data analysis has been completed for the accelerated testing of the system. A general methodology to evaluate the shelf life of {{the system as a}} function of the storage time, temperature, and relative humidity is discussed...|$|R
5000|$|OpenSDS is an {{open source}} {{software}} defined storage controller. As journalist Swapnil Bhartiya explained for CIO, it was formed to create [...] "an industry response to <b>address</b> software-defined <b>storage</b> integration challenges {{with the goal of}} driving enterprise adoption of open standards." [...] It’s supported by storage users/vendors, including Dell, Huawei, Fujitsu, HDS, Vodafone and Oregon State University.|$|R
2500|$|Technologies of [...] {{hydrogen}} economy, batteries, {{compressed air}} energy storage, and flywheel energy <b>storage</b> <b>address</b> the energy <b>storage</b> problem {{but not the}} source of primary energy. [...] Other technologies like fission power, fusion power, and solar power {{address the problem of}} a source of primary energy but not energy storage. [...] Vegetable oil addresses both the source of primary energy and of energy storage. The cost and weight to store a given amount of energy as vegetable oil is low compared to many of the potential replacements for fossil fuels.|$|R
40|$|Embedded systems provide {{means for}} {{enhancing}} the functionality delivered by small-sized electronic {{devices such as}} hand-held computers and cellular phones. Java is a programming language which incorporates a number of features that are useful for developing such embedded systems. However, the size and {{the complexity of the}} Java language and its libraries have slowed its adoption for embedded systems, due to the processing power and storage space limitations found in these systems. A common approach to <b>address</b> <b>storage</b> space limitations is for the vendor to offer special versions of the libraries with reduced functionality and size to meet the constraints of embedded systems. This paper presents a technique that is used for dynamically selecting, on an as needed basis, the subset of library entities that is exactly required for a given Java application to run. This subset can then be down-loaded to the device for execution. The advantage of this approach is that the developer can use arb [...] ...|$|R
50|$|For a {{warehouse}} to function efficiently, the facility must be properly slotted. Slotting <b>addresses</b> which <b>storage</b> medium {{a product is}} picked from (pallet rack or carton flow), {{and how they are}} picked (pick-to-light, pick-to-voice, or pick-to-paper). With a proper slotting plan, {{a warehouse}} can improve its inventory rotation requirements—such as first in, first out (FIFO) and last in, first out (LIFO)—control labor costs and increase productivity.|$|R
50|$|Novell Storage Manager {{dynamically}} manages and provisions storage {{based on}} user and group events {{that occur in}} the directory, including user creations, group assignments, moves, renames, and deletions. When a change happens in the directory that affects a user’s file storage needs or user storage policy, Storage Manager applies the appropriate policy and makes the necessary changes at the file system level to <b>address</b> those <b>storage</b> needs.|$|R
