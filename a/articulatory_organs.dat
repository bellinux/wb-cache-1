28|6|Public
2500|$|I {{have devoted}} much space and {{discussion}} {{to the role}} of the Mongol 'phags-pa alphabet in the origin of the Korean alphabet, but it should be clear to any reader that in the total picture, that role was quite limited. [...] The origin of the Korean alphabet is, in fact, not a simple matter at all. Those who say it is [...] "based" [...] in 'phags-pa are partly right; those who say it is [...] "based" [...] on abstract drawings of <b>articulatory</b> <b>organs</b> are partly right. [...] Nothing would disturb me more, after this study is published, than to discover in a work on the history of writing a statement like the following: [...] "According to recent investigations, the Korean alphabet was derived from the Mongol 'phags-pa script" [...] phags-pa contributed none of the things that make this script perhaps the most remarkable in the world.|$|E
5000|$|Sound {{duration}} is {{a common}} factor in reduction: In fast speech, vowels are reduced due to physical limitations of the <b>articulatory</b> <b>organs,</b> e.g., the tongue cannot move to a prototypical position fast or completely enough to produce a full-quality vowel (compare with clipping). Different languages have different types of vowel reduction, {{and this is one}} of the difficulties in language acquisition; see, e.g., [...] "Non-native pronunciations of English" [...] and [...] "Anglophone pronunciation of foreign languages". Vowel reduction of second language speakers is a separate study.|$|E
5000|$|I {{have devoted}} much space and {{discussion}} {{to the role}} of the Mongol phags-pa alphabet in the origin of the Korean alphabet, but it should be clear to any reader that in the total picture, that role was quite limited. ... The origin of the Korean alphabet is, in fact, not a simple matter at all. Those who say it is [...] "based" [...] in phags-pa are partly right; those who say it is [...] "based" [...] on abstract drawings of <b>articulatory</b> <b>organs</b> are partly right. ... Nothing would disturb me more, after this study is published, than to discover in a work on the history of writing a statement like the following: [...] "According to recent investigations, the Korean alphabet was derived from the Mongol phags-pa script" ... phags-pa contributed none of the things that make this script perhaps the most remarkable in the world.|$|E
40|$|The {{variability}} of speech due to dialects, age, gender, anatomical {{structures of the}} speech organs, phonological status, phonation and resonance can be a barrier for automatic speech recognition. Especially in children and among speaker with communication, language and speech difficulties speech is variable. In the project Cross-linguistic study of protracted phonological (speech) development in children: Slovenian we have analyzed 54 preschool children and focused our research on epi-, pro- and epen-thesis. The most evident for of process is epenthesis of schwa in consonant clusters and epithesis of a stop or a fricative before fricatives. The data show that vocalic epenthesis frequently occurs in consonant clusters, especially in those clusters which require different manner of articulation, or <b>articulatory</b> <b>organ</b> (or part of it) for example between obstruents and sonorants, between obstruents and between sonorants. Consonantal epenthesis occurs in words with difficult phonemes, especially obstruents, before the velars, before sibilant, before fricatives (adding affricates). An interesting addition is voiceless {{stop in front of}} the fricative at the beginning of words...|$|R
30|$|The voice {{individuality}} {{caused by}} different <b>articulatory</b> speech <b>organs</b> is distributed non-uniformly in some invariant {{parts of the}} vocal tract, such as the nasal cavity, piriform fossa, and laryngeal tube[12]. The information of the glottis is encoded in the low-frequency region from 100 to 400 Hz, and the piriform fossa is positioned in the medium frequency band from 4 to 5 kHz. The information of consonant factor exists in a higher frequency region, i.e., 7 to 8 kHz[12, 14]. The first three formants are encoded in the lower and middle frequency regions from 200 Hz to 3 kHz.|$|R
40|$|Phonologists {{have long}} debated {{the role of}} {{phonetics}} in phonological theories. A key point in this debate {{is whether or not}} phonological computation is to be regarded as modally-independent, that is, whether or not facts about the <b>articulatory</b> and perceptual <b>organs</b> are regarded as external to the phonology. This dissertation argues for a form of grounded phonology, by drawing on findings in neuroscience, as well giving grounded analysis of unnatural phenomena in Kashaya, Zuni and Odawa...|$|R
40|$|International audienceNever was {{the effect}} of {{bilateral}} stimulation of the subthalamic nucleus (STN) evaluated quantitatively on all the components of speech production, that is articulation, respiration and phonation, at the same time. It {{is the purpose of}} this study which uses force measurements of the <b>articulatory</b> <b>organs</b> and acoustic analysis in 16 parkinsonian patients. With STN stimulation, reaction and movement time of the <b>articulatory</b> <b>organs</b> decreased and their maximal strength, as well as their precision increased. We also noted a large beneficial effect on voice with a significant improvement in respiratory and phonatory functions...|$|E
40|$|Background/Aim. In {{children}} {{with cerebral palsy}} speech is a big problem. Speech of these children {{is more or less}} understandable, depending on the degree of reduced mobility of <b>articulatory</b> <b>organs.</b> Reduced mobility is affected by inability to control facial grimacing and poor muscle strength when performing targeted movements. The aim {{of this study was to}} determine the mobility of tongue in patients with cerebral palsy. Methods. The study included a sample of 34 children - patients with cerebral palsy who had been treated in the Special Hospital for the Cerebral Palsy and Developmental Neurology in Belgrade. The patients were divided according to the determined diagnosis into two groups: Quadriparesis spastica (n = 11) and Morbus Little (n = 16). The children, aged 8 - 12 years, had preserved intelectual abilities, and all of them had preserved hearing. The study was conducted during the period from January to September 2009. The functional state of <b>articulatory</b> <b>organs</b> in both groups was tested by the C-test that examines the anatomic structure and mobility of the <b>articulatory</b> <b>organs.</b> Results. Our research showed that both groups of the patients had impaired functional state of the tongue - the most mobile articulatory organ. Also, the research showed that the functional state of the tongue was worse in children diagnosed with Quadriparesis spastica. A statistically significant correlation between the diagnosis and the functional state of the tongue, the tongue test performance and the retention of the tongue in a given position was found (r = 0. 594, p < 0. 005; r = 0. 816, p < 0. 01 and r = 0. 738, p < 0. 001, respectively). Conclusion. A large percentage of {{children with}} cerebral palsy were not able to establish control over the position of <b>articulatory</b> <b>organs,</b> especially the tongue, and its retention in a given position, all of which affect the quality of speech...|$|E
40|$|In {{this paper}} I {{will try to}} show that {{theories}} of phonological structure must incorporate some measure of phonetic naturalness, specifically {{the idea that there}} exists a tendency to conserve energy {{in the use of the}} <b>articulatory</b> <b>organs,</b> with ‘easy ’ sounds being those that require less physical effort to produce on the part of the speaker. ...|$|E
40|$|Besides {{manner of}} {{articulation}} and glottal activity, {{which have been}} more studied, place of articulation also {{plays an important role}} in determining the relative strength of a consonant. This is so because the joint contribution of magnitude and duration of articulatory gestures (glottal, velo-pharyngeal, and oral) defines a global level of intraoral pressure that can be related to strength (Malécot, 1970). This aerodynamic criterion has been used to explain the role that a back place of articulation can have in reducing oral volume and thus increasing intraoral pressure, namely strength. This can interfere with glottal activity (e. g. in passive devoicing). I will provide examples of diachronic change in several languages which show a tight relationship between back places and strength. These examples are mainly from Semitic languages, such as Arabic, but also from some others, such as Samoan (Austronesian) and Vlach Romani (Indo-European). A relation has been proposed between order of diffusion of linguistic change and place of articulation. However, there is controversy about the relative order between labials and coronals. I will examine different proposals and I will present articulatory, aerodynamic and perceptual data to support the idea that coronal consonants are weaker than labial consonants. The lesser the mass of the <b>articulatory</b> <b>organ,</b> the faster the movements and the shorter the duration of the gesture, which leads to weakness. In addition, certain kinds of coronals might be associated with a relatively descended position of the jaw, which can cause an increase of the oral volume and, consequently, a decrease of the intraoral pressure. Nevertheless, further study is needed on the link between jaw gestures and different types of labials and coronals. To finish, there are some optimal durations for the correct perception of each manner, which vary depending on the place of articulation, and these thresholds seem to favour the weakening of coronals much more than that of labials or dorsals (García Santos, 2002) ...|$|R
40|$|Cranial {{bases of}} 5 days old mice {{along with the}} {{temporomandibular}} joints and the whole mandibles were maintained in organ culture for one, two or three weeks. A device consisting of an electric motor rotating a bar with three magnets was developed for providing an articulating function for the temporomandibular joints. The tissue samples were attached {{to the end of}} a lever arm inside a container and a piece of iron was fixed to the other end of the lever arm to allow it to be lifted magnetically every 45 seconds. This movement pressed the other end of the lever arm downwards, submerging the tissues in the medium. As the anterior end of the mandible was attached to a wire above the tissues with a silk thread while the rest of the tissue sample moved downwards, a rotating movement was produced in the mandibular joint. Control mandibles were cultured without any such movement in the temporomandibular joints. The reactions in the condyles were studied macroscopically after alizarin red injections and microscopically with haematoxylin and eosin, alcian blue, osteoid and von Kossa stains. The condylar processes had increased 0. 6 mm in length in functional organ culture, 0. 4 mm more than the sham-cultured condyles. Osteoid formation was more marked in the latter and calcification had proceeded closer to the superior surface of the cartilage than in the condyles cultured with <b>articulatory</b> function. The <b>organ</b> culture system developed here obviously resembles the situation in vivo more closely than do previously available organ culture systems and is the first in which it has been possible to provide the function necessary for maintaining growth. The system also seems suitable for culturing organs in which tissue size has previously been a limiting factor...|$|R
40|$|A respiratory, {{resonator}} and <b>articulatory</b> <b>organ,</b> nose is {{an important}} organ for human health. During inhalation and exhalation, nose makes the weather humid, warms it and enables the sound to become peculiar to the person, aerating the ears. Nose is an organ which provides speech {{and the production of}} sound. Nasal cavity aids the resonation and amplification of the primary sound that forms in cricoarytenoid muscles. Nasal voices are the sounds in which oral cavity is completely blocked,and the air is allowed to go out through nasal cavity. /m/,/n/ letters are in that group (Altundağ, 2008; 11). The complaint about nasal obstruction {{is one of the reasons}} for application with which the doctors of ear, nose and throat are faced often times. Sound is negatively influenced by the nasal obstruction resulting fromanatomical problems (Ö. Koç, 2008; 6). In such cases as the obstructions in the nasal cavity and nasopharynx or abnormal structural situations, the obstruction of sound transmission leadsto deficit in the oral and nasal resonation in the course of the transmission of sound through nasal cavity (Kummer and Lee, 1996; 272). Rhinolalia (nasal dysfunction and rhinophonia) is a speechof pathology arising out of the breakdown of nasal resonation. (Ö. Koç, 2008; 14 - 15). They can be seen in three forms. Hyper nasality (rhinolalia aperture) is the breakdown of resonation resulting from the velopharyngeal insufficiency. Freezing can be detected especially in famous voices notably in hyper nasality because these voices are uttered for a long time (Kummer and Lee, 1996; 272). Hypo nasality (rhinolalia cause) is called the insufficiency of nasal resonation. The nasal obstruction leading to such an abnormality results from such pathologies as upper respiratory infection, nasal structural deficits and nasal tumours (Enver and Akan, 1995; 122). Rhinolaryngitis is the case in which hyper and hypo nasality can be seen together. Velopharyngeal insufficiency and nasal pathologies and the blockage of a mass to denture in nasopharynx cause the mixed type. Resonation cannot be seen in nasal sounds (Aktaran: Çağlar, 2006; 8). Since nose is a resonator organ, the structural deficits in it such as symptom deviation, concha hypertrophy, nasal valve narrowness, symptom perforation, symptom hematoma and abscess, nasoseptitis deformity and choanal atresia all lead to nasal obstruction and respiratory defection and resonation breakdown. Symptom deviation forms as a result of the breakage of the nose from the centre to the right or left. Deviation continues to form generally based on trauma and congenital (Yılmaz, 2002; 55). The most significant symptom of deviation is nasal obstruction. Due to nasal obstruction and the air not warming, not dampening or not being cleared, respiratory illnesses such as angina, pharyngitis, laryngitis, bronchitis…etc. come in to existence. Sinus nasal cavities could become blocked owing to deviation and for that reason, sinusitis might develop. Concha hypertrophy which can be seen with chronic hypertrophic rhino sinusitis, allergic rhinitis or symptom deviation is one of the most important reasons for obstruction (Köybaşıand Yılmaz, 2005; 115). The symptoms of the disease can be seen with general nose stiffening, respiratory difficulty, and the necessity to inhale and exhale through mouth, sleep deficits accompanying snoring. (Fethallah, 2005; 20). Nasal valve region is the region where respiratory passage is the narrowest and nasal resonation is the highest. Nasal valve iscalled the distance between septum and upper lateral cartilage. Patients complain about the nasal obstruction. Other symptoms are helminthiasis and bleeding. Septum perforation is the case in which mucoperichondrium and cartilage get exposed to inflammation. Nasal dryness, nasal stiffening, frequent crusting, action of creating whistle during respiration can be seen in the patients. Perforation affects the air passage in the nasal resonation. Septum hematom arises as a consequence of the bleeding in-between trauma and septum plates. If septum hematom is not treated, it will turn into abscess with infection. The symptomsof septum hematom are nasal stiffening, flix, nose ache and nasal weakness. Patients feel nasal swelling, headache and edema when abscess happens (Somdaş, 2005). Bilateral pleural involvement, which is most often seen in congenital nasal abnormality, can be encountered once in every 8000 living births. During the early period of development, noseis separated from pharynx with biconasal membrane. When this membrane does not disappear, it will cover posterior coanal bleeding. In the structural deficits of nose, acoustical Rhinometryis use in order to determine nasal cavity volume. As a result ofacoustical Rhinometry measurements, minimal cutting areas and selected point volume can be measured in that way. The parameters such as acoustical sound frequency, vibration and periodicity are analysed. 40 first class students who read Selcuk University education faculty fine arts music major branch have been included in the study. So as to obtain data from all the students, they were asked to fill in personal information form and nasal obstruction scala. Acoustical Rhinometry together with phonatory skills measurements were applied on these studentsby the interested experts. Descriptive statistical methods (average, standard deviation) and Mann-Whitney U test were used for the evaluation of these data. 40 first class students who read Selcuk University education faculty fine arts music major branch have been included in the study. In this study, it is aimed that the sound education can be modified in the faculty of music over the sentence “How are the sound features of the people with nasal structure deficits?” As a result of examination in ear, nose and throat major branches at the faculty of medicine at Selcuk University, septum deviation was detected in 12 students, concha hypertrophy 6 students, septum deviation and concha hypertrophy 7 students. Besides, 15 students were detected to be free of nasal defection. Because the students of BYBB have low points at NOSE, the diseases like septum deviation and conca hypertrophy narrow the nasal cavity volume, influencing phonatory talents negatively. It has been identified that the acoustic properties of the sound frequencies of the fundamental frequency F 0 and formant F 1, F 2, F 3, F 4, F 5 values did not differ significantly among the students of BYBS BYBB. When the arithmetic average related to the formant frequencies of the acoustical features of sound has beenanalysed in the students participating in the study, it is determined that (F 3) formant is for the singer. At the courses giving a professional music education, voice education methods should be developed, based on the anatomical features of the organs working in constitution of voice and the structural breakdowns in such organs with their effects. Ear nose throat doctors should maintain the studies with audiologists on the basis of the thought that voice education is disciplinary. Professional voice users must learn how to sustain their voice health and take precautions against illnesses, giving importanceto hygiene. It is thought that this study will be much more convenient for a larger group in terms of statistics...|$|R
40|$|OBJECTIVES—To {{assess the}} oral system of parkinsonian {{patients}} treated with chronic {{stimulation of the}} bilateral subthalamic nucleus (STN) to evaluate precisely {{the effectiveness of this}} procedure on the <b>articulatory</b> <b>organs.</b>  METHODS—Load sensitive cantilevers were used to sample ramp and hold force contractions generated by the upper lip, lower lip, and tongue. The subject was given the instruction to produce forces as rapidly and as accurately as possible in response to the target signal (ranging from 0. 25 to 2 N), which appeared on a screen. Maximal force of each effector organ was also measured. Fourteen healthy control subjects and 10 patients participated in this study. After an overnight fast the patients were evaluated in the morning under two conditions: during bilateral stimulation and 1 hour after stopping STN stimulation.  RESULTS—During STN stimulation, dynamic and static control of the <b>articulatory</b> <b>organs</b> were improved: the maximal strength of the <b>articulatory</b> <b>organs,</b> their accuracy to reach the target, and the precision of the hold phase increased. In addition, the reaction time and the rise time of the ramp phase decreased. Patients' speech as assessed by the item 18 of the unified Parkinson's disease rating scale (UPDRS) was greatly improved by electrical stimulation of the STN CONCLUSIONS—Improvement of oral control of the stimulated patients suggests that STN stimulation modulates neuronal structures involved in speech. However, more patients have to be evaluated for a fuller understanding of the effect of this surgical procedure on speech. ...|$|E
40|$|This payer {{presents}} {{a system for}} the automated tracking of non-rigid anatomic structures in two-dimensional image sequences. It is applied to X-ray image sequences of the vocal tract. In this application <b>articulatory</b> <b>organs</b> have to be measured to investigate the complex dynamic characteristics of human speech production, with particular interest in the robust boundary detection of non-rigid organs such as the tongue...|$|E
40|$|This paper {{proposes a}} new method that determines {{segmental}} duration for text-to-speech conversion {{based on the}} movement of <b>articulatory</b> <b>organs</b> which compose an articulatory model. The articulatory model comprises four time-variable articulatory parameters representing the conditions of <b>articulatory</b> <b>organs</b> whose physical restriction seems to significantly influence the segmental duration. The parameters are controlled according to an input sequence of phonetic symbols, following which segmental duration is determined based on the variation of the articulatory parameters. The proposed method is evaluated through an experiment using a Japanese speech database that consists of 150 phonetically balanced sentences. The {{results indicate that the}} mean square error of predicted segmental duration is approximately 15 [ms] for the closed set and 15 - 17 [ms] for the open set. The error is within 20 [ms], the level of acceptability for distortion of segmental duration without loss of naturalness, and hence the method is proved to effectively predict segmental duration. 1...|$|E
30|$|During general {{pronunciation}}, <b>articulatory</b> <b>organs,</b> such as {{the tongue}} and the soft palate, change form. By observing these organs in MRI movie images during pronunciation of /asa/, {{we found that the}} velar apex was elevated with mouth opening and contacted the posterior wall of the pharynx. In some subjects, the velar apex did not contact the posterior pharyngeal wall. In contrast, the velar apex in all subjects contacted the posterior pharyngeal wall during production of /s/, and velopharyngeal closure was completed. The tongue apex also approached the lingual surface of the maxillary anterior teeth.|$|E
40|$|According to Felizatti (1998), {{dysarthria}} is {{a disorder}} in motor production that affects patterns of movement, coordination and strenght of <b>articulatory</b> <b>organs.</b> It {{can be caused}} by brain damage and it is usually characterized by slow speech. The analysis of some prosodic aspects of almost unintelligible dysarthric patients’speech indicates that the strange reaction their speech causes in their listeners is mainly due to the prosodic strategies they use (consciouslly or not) to improve their oral language intelligibility. In other words, despite the fact that dysarthric patients’s brain lesions cause articulatory difficulties, they are able to compensate them through prosody...|$|E
30|$|Orthodontic appliances, {{including}} metallic materials, {{may produce}} a significant error in {{measurement of the}} <b>articulatory</b> <b>organs</b> when using MRI movie images. Metallic orthodontic appliances such as the fixed retainer and metal brackets often make anatomical structures disappear and become distorted by signal void caused by metallic artifact. When the velum is evaluated in a distorted image, caution should be exercised as the measurement may be altered. In conclusion, the influence on MRI examination varies among orthodontic metallic appliances and orthodontists should not necessarily remove all metallic appliances before MRI examination. Meanwhile, orthodontists should know {{the fact that a}} significant measurement error in speech evaluation using MRI movie may occur by image distortion caused by metallic artifacts and share the information with radiologists.|$|E
40|$|In {{emotional}} speech studies, it is {{well known}} that loudness, pitch, position and length of pauses, etc. are important factors in expressing emotions. Besides those phonation features, the articulation of the vocal tract endows some spectral features that reflect emotions. Those features come from the special way of controlling <b>articulatory</b> <b>organs</b> in emotional states. Daily experiences tell us that some specific control strategies in articulation can result in certain emotional states. How-ever, the relation between the articulation and acoustic fea-tures is not clear yet. In this study, we investigate the spectral features using a physiological articulation model by manip-ulating the configurations of speech organs and synthesizing the corresponding speech sounds, in an analysis-by-synthesis way. The acoustic features concerned with emotional state...|$|E
40|$|This paper {{discusses}} {{the subject of}} pronunciation visualization, based on methodologies in experimental phonetics. It presents a brief survey of major Polish instrumental research into articulation, focusing primarily on contemporary dynamic visualizations using electromagnetic articulography. The author’s own investigations were conducted using an AG 500 articulograph, a device which records and visualizes the working and movement of the <b>articulatory</b> <b>organs.</b> Two speakers were recorded: one with standard pronunciation {{and the other with}} articulation defects. A multi-specialist team prepared vocal tract models, taking into account the speaker’s anatomical conditions as recorded with the articulograph, video recordings, and photographs. Articulographic data enabled the preparation of pronunciation animations of 45 words, which show the standard realization of all vowels and consonants of Polish, and eight animations of non-standard articulation...|$|E
40|$|The p,ionological {{output of}} a {{generative}} grammar may {{be regarded as}} an abstract description {{of a set of}} input commands to a speech syn-thesizer. This synthesizer should be a true model of human speech production. The question as to what form the outputs of the phono-logical component should take is thus dependent {{on the nature of the}} parameters controlling the synthesizer. Modern acoustic phonetics has provided a firm understanding of the physical basis relating articulatory configurations to the resulting sound pressure wave. On the other hand, research at this level has demonstrated an overwhelming inconstancy in the acoustic correlates of the phonological invariants. Studies of articulatory dynamics sug-gest, however, that much of this variability may be due to built-in physiological properties of the <b>articulatory</b> <b>organs</b> and of the neural cir-cuits controlling them. A speech synthesizer for phonology shoul...|$|E
40|$|International audienceHuman speech {{arises from}} orchestrated {{activities}} of phonatory and <b>articulatory</b> <b>organs</b> and reflects human-specific characteristics in anatomy and physiology. The tongue and larynx are less tightly coupled in humans, {{and they are}} also innervated separately from the cortex. These biological specificities provide aerodynamic and acoustic bases of speech production and contribute to generating a parallel time-pattern of gradually changing vocal signals with ripples in amplitude and spectrum due to rapid articulatory movements. A close look at local sound variations suggests that tongue-larynx linkage still exists as an old trait common to the primate family, {{as seen in the}} variation of vocal frequency due to articulation. Contrarily, articulatory control may also be influenced by laryngeal control, as seen in irregular articulation in certain vocal expressions. Vowel devoicing may be a complex case of such bilateral interactions, and a special attention was made on the topic in this report...|$|E
40|$|This study {{analyses}} {{the interference}} of Turkish first language speech {{properties in the}} production of utterances in English as a second language and shows how experimental phonetics can be used in language teaching. A contrastive analysis of Turkish and English phonetic features is presented using palatography and in particular spectrography. A visual representation of some of the acoustic features as they change between Turkish and English is given through the sound spectrographs included in the book. The phonetic properties of Turkish vowel sounds and the effect lengthening has on these vowels is also presented. As the articulatory positions are subject to modification during continuous speech due to the movements of the <b>articulatory</b> <b>organs</b> preceding and succeeding the current point of articulation, it is particularly important that connected speech as well as utterances in isolation should be examined. Accordingly, this study also shows the importance of looking at connected speech, particularly in Turkish, rather than analysing single lexical items...|$|E
40|$|This article {{presents}} {{a system for}} the automated tracking of non-rigid anatomic structures in two-dimensional image sequences, which was primarily applied to X-ray image sequences of the vocal tract. In this particular application <b>articulatory</b> <b>organs</b> have to be measured to investigate the complex dynamic characteristics of human speech production. Of particular interest is a robust boundary detection of non-rigid organs such as lips and tongue. To solve this ill-posed detection problem under the presence of transparently superimposing structures, varying textural appearances of organs and noise, a two-level system is proposed. At the lower level, several edge-, region-, and motion-based image operators are combined to exploit their respective benefits and concomitantly compensate for their deficiencies. For the sake of precision, the result of these operators are not represented as larger tokens, such as line segments, but remain pixel-related cues or image evidences. At the higher level, an active contour-based component allows for {{the introduction of a}} priori knowledge about the object to be detected...|$|E
40|$|The {{aim of this}} {{bachelor}} {{thesis is}} to create a program of logopaedic prevention for individual work with a child as a general rule aged between five and six in kindergarten and with focus on sound L and R, which belong to the frequent speech impediment in pronunciation. In a theoretical part is described the general definition of logopaedics (speech therapy), its sense and there are given reasons of need for logopaedic prevention in kindergarten. The theoretical part is also focused on the development of speech and pronunciation of child at preschool age, on the articulation disorder and the diagnostics of pronunciation of child at preschool age. There are described the sorting of sounds of Czech language and the characteristic of sounds L and R. In practical part are described breathing, vocal, hearing, graphomotoric training and gymnastic of speech organs for development of <b>articulatory</b> <b>organs</b> and exercises for support of right pronunciation of sound L a R. In this part are also located pictures that illustrate and introduce the work with children...|$|E
40|$|Abstract. This {{paper is}} focused on {{improving}} visual Czech speech synthesis. Our aim was {{the design of a}} highly natural and realistic talking head with a realistic 3 D face model, improved co-articulation, and a realistic model of inner <b>articulatory</b> <b>organs</b> (teeth, the tongue and the palate). Besides very good articulation our aim was also expression of the mimic and emotions of the talking head. The intelligibility was verified by the listening test and the results of this test were analysed. Firstly, the face model reconstruction from real data is presented. A 3 D computer vision was employed in order to obtain a model of an arbitrary face. The stereovision technique that is used to reconstruct the model is described in detail in Section 2. Details concerning a visual speech synthesis are discussed in Section 3. Special features of the visual speech synthesis of the Czech language are mentioned, too. Furthermore, the design of a talking head including the solution of co-articulation problem is presented. Next, the modeling of expression and emotions in animation is described. The last part of the paper, Section 4, contains results of the performed listening test. ...|$|E
40|$|Human {{voice and}} speech are a complex {{acoustic}} expression. Respiratory, phonation and <b>articulatory</b> <b>organs</b> {{participate in this}} process. Very different scientific disciplines - medicine, physics, philosophy - are engaged in solving its problems. At present there is no complete, modern publication available which would take into consideration all these aspects. In its essence, problems with generations of voice and sound lend themselves very suitably to the processing by utilization of modern means for creation of multimedia applications. The objective of the thesis is creation of a multimedia application on the CD ROM, which would deal with depiction of laryngeal phonation functions from the medical, physiological, physical as well as philosophical point of view. Taking into consideration the developing environment which was used, in future {{it will be possible}} to use an application by means of the Internet, for example it may be available within university computer networks. The application has been processed on computers with the Windows 98, Windows 98 E or Windows 2000 operation systems, therefore all the following data related to the processing methodology deal with work under these operation systems. Available from STL Prague, CZ / NTK - National Technical LibrarySIGLECZCzech Republi...|$|E
40|$|Background and Aim: Speech as a motor {{phenomenon}} requires repetitive {{and rapid}} function of <b>articulatory</b> <b>organs</b> performing extremely fine movements. Practice on motor skills results in facilitation in treatment progress {{of children with}} phonological disorders. The {{purpose of this study}} was to compare motor skills in 5 -year-old children with phonological and phonetic disorders. Methods: Thirty-two children age 5 years, 16 with phonemical speech sound disorders and 16 with difficulty at a phonetic level participated in this study. TOLD Test was performed for linguistic skills investigation among children. Phonetic test, Wepman test, diadochokinesis and oral assessment was used for diagnosis between phonological and phonetic disorders. The children were also evaluated with Oseretsky motor developmental scale. Results: In comparison, mean scores of movement skills between both groups showed significant difference (p= 0. 006) and children with phonetic disorder got significantly higher scores on all part of this test. Conclusions: The findings of this study support the idea that speech sound disorders are frequently associated with motor problems, and that type of articulation disorder affects the motor performance in a different way. Phonological disorders seem to have more impact on motor performance than phonetic disorders. The results authenticate the need to pay more attention to the motor skills of children with articulation disorders...|$|E
40|$|Universal {{linguistic}} constraints seem {{to govern}} the organization of sound sequences in words. However, {{our understanding of the}} origin and development of these constraints is incomplete. One possibility is that the development of neuromuscular control of articulators acts as a constraint for the emergence of sequences in words. Repetitions of the same consonant observed in early infancy and an increase in variation of consonantal sequences over months of age have been interpreted {{as a consequence of the}} development of neuromuscular control. Yet, it is not clear how sequential coordination of articulators such as lips, tongue apex and tongue dorsum constrains sequences of labial, coronal and dorsal consonants in words over the course of development. We examined longitudinal development of consonant-vowel-consonant(-vowel) sequences produced by Japanese children between 7 and 60 months of age. The sequences were classified according to places of articulation for corresponding consonants. The analyses of individual and group data show that infants prefer repetitive and fronting articulations, as shown in previous studies. Furthermore, we reveal that serial order of different places of articulations within the same organ appears earlier and then gradually develops, whereas serial order of different <b>articulatory</b> <b>organs</b> appears later and then rapidly develops. In the same way, we also analyzed the sequences produced by English children and obtained similar developmental trends. These results suggest that the development of intra- and inter-articulator coordination constrains the acquisition of serial orders in speech with the complexity that characterizes adul...|$|E
40|$|To {{explore the}} {{mechanisms}} of speech articulation, {{which is one of}} the most sophisticated human motor skills controlled by the central nervous system, we investigate the force gen-eration dynamics of the human speech articulator muscles [lips: orbicularis oris superior (OOS) and inferior (OOI) ]. Short pulse electrical stimulation (300 µs) with approximately three or four times the sensation threshold intensity of each subject induced the muscle response. The responses of these muscles were modeled as second-order dynamics with a time delay, and the model parameters [natural frequency (NF), damping ratio (DR), and time delay (TD) ] were identified using a nonlinear least mean squares method. The lips [orbicularis oris superior (NF: 6. 1 Hz, DR: 0. 71, TD: 14. 5 ms), orbicularis oris inferior (NF: 6. 1 Hz, DR: 0. 68, TD: 15. 6 ms) ] showed roughly similar characteristics in eight subjects. The dynamics in the tongue (generated by combined muscles) also showed similar char-acteristics (NF: 6. 1 Hz, DR: 0. 68, TD: 17. 4 ms) in two subjects. The NF was higher and the DR lower than for the arms [triceps long head, NF: 4. 25 Hz, DR: 1. 05, TD: 23. 8 ms], indicating that <b>articulatory</b> <b>organs</b> adapt for more rapid movement. In contrast, slower response dynamics was estimated when muscle force data by voluntarily contraction task was used for force generation dynamics modeling. We discuss methodological problems in estimating muscle dynamics when different kinds of muscle contraction methods are used...|$|E
40|$|International audienceDysarthria in Parkinson's disease (PD) {{consists}} of articulatory, p honatory and respiratory impairment. Bilateral subthalamic nucleus (STN) stimulation greatly improves motor disability,b ut its long-term effect on speech within {{a large group}} of patients has not been precisely evaluated. The aim {{of this study was to}} determine the effect of bilateral STN stimulation on oral force control in PD. We measured forces of the upper lip, lower lip and tongue in twenty-six PD patients treated with bilateral STN stimulation. Measurements of the articulatory organ force,as well as a motor evaluation using the Unified Parkinson's Disease Rating Scale (UPDRS),were made with and without STN stimulation. Maximal voluntary force (MVF),reaction time (RT),movement time (MT),im precision of the peak force (PF) and the hold phase (HP) were all improved with STN stimulation during the articulatory force task, as well as the motor examination scores of the UPDRS. It seems that the beneficial STN stimulation-induced effect on articulatory forces persisted whatever the duration of post-surgical follow-up. However, dysarthria evaluated by the UPDRS was worse in two subgroups of patients with a one to two year and three to five year post-surgical follow- up,in comparison with a subgroup of patients with a three month follow-up. STN stimulation has a beneficial long-term effect on the <b>articulatory</b> <b>organs</b> involved in speech production,and this indicates that parkinsonian dysarthria is associated,a t least in part,w ith an alteration in STN neuronal activity. Nevertheless,t o confirm the persistence of the beneficial effect of STN stimulation on parkinsonian dysarthria,a longitudinal evaluation is still needed...|$|E
40|$|It was {{recently}} suggested (l) (') that {{by studying the}} speech mimicking behavior one could gain some insight {{in the performance of}} the initial stages of speech perception without the complication of semantic and syntactic analyses of the message at higher levels of speech processing. In order to elicit a response vowel corresponding to a stimulus vowel the nervous system has to transform the auditory pattern of the stimulus vowel into a set of instructions to the centers, responsible for programming and control of the <b>articulatory</b> <b>organs.</b> Recently {{there appears to be a}} certain disagreement concerning the appropriate terminology for dealing with such instructions (distinctive features, motor parameters, and so on) and how closely they are associated with immediate muscle activity and proprioceptive feedback (3) (4) (5). To avoid discussion we can call this set of instructions the "Intermediate representations " of the vowel, which can be stored and used as input signals both by the mechanism of speech production and by higher levels of speech message processing. These signals correspond to output signals of the subphonemic auditory pattern block in Fant ' s model (4), to the V ' representation in Stevens and House (6 J, and to the y representation in Galonov and Chistovich (I). It seems to us, at the present stage of research, that the physiological nature of these signals and their location in the brainaxe of secondary importance. More pertinent is the question concerning their logical structure and the rules of transformation from auditory patterns to this representation of signals. i...|$|E
30|$|Intonation {{provides}} a suitable unit {{of information for}} the spoken mode by facilitating distinctions {{in the flow of}} sound, with the tonic foot realising the focus of information, or New, through the natural association of pitch change with auditory focus. Punctuation {{provides a}} suitable unit of information for the written mode by facilitating the saccade of the reading eye, with the position preceding punctuation (or a conjunction) realising the focus of information, or New, though the natural association of easily-identifiable fixation points with visual focus. It is a mistake to confuse the two modes of realisation. The units of Information in speech and in reading {{do not need to be}} the same, as they both have a non-arbitrary, natural relationship to the associated physical and cognitive constraints and potential affordances of independent neurophysiological systems. Final position in a clause has long been recognised as the default realisation of New information in written English (Fries, 1992; Matthiessen 1995 b), but this was only made possible as result of spaces and punctuation marks disconnecting the saccading eye of written English from the <b>articulatory</b> <b>organs</b> of spoken English, quite apart from the apparent sensation of hearing written English or the ability to render written text as spoken English. While intonation in spoken English provides flexibility for the speaker to create newsworthy items in almost any position, written English provides considerable flexibility through structures that re-organise the clause to allow newsworthy items to appear before punctuation marks. It is because of this single function, information structure, operating in written English that we can describe punctuation for grammar and punctuation for prosody, or punctuation for texts written to be read and punctuation for texts written to be spoken, respectively. In an optimal English text that is written to be spoken, the units of information in the written text will be constrained by the potentials of the articulatory system. In an optimal English text that is written to be read, the units of information in the written text will be constrained by the potentials of the visual system. This is achieved most effectively through punctuation marks.|$|E

