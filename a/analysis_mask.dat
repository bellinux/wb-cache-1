5|167|Public
40|$|Infrastructure Added {{continuous}} {{integration with}} TravisCI. Mixed effects workflow Fixed a bug where the <b>analysis</b> <b>mask</b> was getting smoothed on the surface. FNIRT-based normalization workflow Fixed a bug where the outputs of FNIRT were not properly renamed and thus were not correctly {{picked up by}} the registration stage of the functional pipeline. Surface snapshots script Fixed a bug where surface visualization would crash when the <b>analysis</b> <b>mask</b> includes all vertices. Added a brief pause between updating the view and saving a snapshot to allow redrawing to finish...|$|E
30|$|Using NDVI as an {{indicator}} of post-fire vegetation regrowth and cover, we created an NDVI raster using the 2009 CERP imagery and the pre-fire tree island boundaries as the <b>analysis</b> <b>mask</b> within the spatial analysis tool in ESRI® ArcMap™ 9.3. Consequently, we only calculated NDVI for those pixels that fell within the pre-fire boundary and ignored all other regions (i.e., the marsh).|$|E
40|$|Concerns {{over the}} {{potential}} negative health effects {{from exposure to}} air pollution have led to interest in assessing personal exposure and finding ways to reduce it. As journey-time exposure accounts for a disproportionately high amount of an individual’s total exposure, this article assesses the potential to apply least-cost techniques within a GIS {{in order to identify}} paths of lower journey-time exposure. The methodology adopted uses pollution surfaces for PM 10 and CO generated by the dispersion model ADMS, with an <b>analysis</b> <b>mask</b> derived from OS MasterMap to create a least-cost surface. Actual routes taken by a cohort of 11 – 13 year old children on their journeys to school are used to compare observed journey time exposure with the exposure along alternative routes generated using the least-cost path function. While the least-cost approach proved to be successful in defining low exposure routes the ability to scale up this approach is constrained by the amount of editing required to successfully create an <b>analysis</b> <b>mask</b> from OS MasterMap data. Such alternative routes have the potential to assist in promoting safer environmental choices, however, their likelihood of adoption is dependant on a number of social and environmental influences which affect an individual’s route choice...|$|E
30|$|The {{more recent}} trials (Bowden et al. [2000]; Calabrese et al. [2003]; Bowden et al. [2003]; Weisler et al. [2011]) {{overcome}} {{many of the}} methodological weaknesses of the older trials of lithium that have been described in the past such as lack of intention-to-treat <b>analysis,</b> <b>masking</b> of treatment allocation, size, diagnosis, and discontinuation artifacts (Burgess et al. [2001]). However, the descriptions of the method of treatment allocation procedures and allocation concealment often remained inadequate.|$|R
40|$|Abstract — Differential Power Analysis is a side channel {{attack for}} any {{symmetrical}} cryptosystem. This paper will review the brief explanation of DPA and also some of its countermeasures. This paper will be focusing on the countermeasure using Boolean and arithmetic masking. These masking techniques will be useful for encryption schemes such as IDEA and RC 6, etc. since these schemes require both Boolean and arithmetic operations. Index Terms — Differential Power <b>Analysis,</b> <b>Masking</b> Techniques, cryptanalysis I...|$|R
5000|$|Turvey, M. T. (1973). On {{peripheral}} {{and central}} processes in vision: Inferences from an information-processing <b>analysis</b> of <b>masking</b> with patterned stimuli. Psychological Review, 80, 1-52.|$|R
40|$|In this paper, we try {{to probe}} whether a clean CMB map {{obtained}} from the raw satellite data using a cleaning procedure is sufficiently clean. Specifically we study {{if there are any}} foreground residuals still present in the cleaned data using a cross-correlation statistic. Residual contamination is expected to be present, primarily, in the galactic plane due to the high emission from our own galaxy. A foreground mask is applied conventionally to avoid biases in the estimated quantities of interest due to foreground leakage. Here, we map foreground residuals, if present, in the unmasked region i. e., outside a CMB <b>analysis</b> <b>mask.</b> Further locally extended foreground-contaminated regions, found eventually, are studied to understand them better. The few contaminated regions thus identified may be used to slightly extend the available masks to make them more stringent. Comment: 9 pages, 6 figures, Accepted in MNRA...|$|E
40|$|Serial Magnetic Resonance (MR) Imaging {{can reveal}} {{structural}} atrophy in {{the brains of}} subjects with neurodegenerative diseases such as Alzheimer’s Disease (AD). Methods of computational neuroanatomy allow the detection of statistically significant patterns of brain change over time and/or over multiple subjects. The focus of this thesis is the development and application of statistical and supporting methodology {{for the analysis of}} three-dimensional brain imaging data. There is a particular emphasis on longitudinal data, though much of the statistical methodology is more general. New methods of voxel-based morphometry (VBM) are developed for serial MR data, employing combinations of tissue segmentation and longitudinal non-rigid registration. The methods are evaluated using novel quantitative metrics based on simulated data. Contributions to general aspects of VBM are also made, and include a publication concerning guidelines for reporting VBM studies, and another examining an issue in the selection of which voxels to include in the statistical <b>analysis</b> <b>mask</b> for VBM of atrophic conditions. Research is carried out into the statistical theory of permutation testing for application to multivariate general linear models, and is then used to build software for the analysis of multivariate deformation- and tensor-based morphometry data, efficiently correcting for the multiple comparison problem inherent in voxel-wise analysis of images. Monte Carlo simulation studies extend results available in the literature regarding the different strategies available for permutation testing in the presence of confounds. Theoretical aspects of longitudinal deformation- and tensor-based morphometry are explored, such as the options for combining within- and between-subject deformation fields. Practical investigation of several different methods and variants is performed for a longitudinal AD study. ...|$|E
40|$|Abstract: Introduction: Different {{electrophysiologic}} {{tests were}} developed to ascertain or detect endolymphatic hydrops (ELH). Recently, Cochlear Hydrops <b>Analysis</b> <b>Masking</b> Procedure (CHAMP), a new auditory brainstem response (ABR) technique, proved {{to be able to}} separate normal controls from definite Meniere's disease (MD) with 100 % sensitivity and 100 % specificity. Objective: To evaluate the applicability and diagnostic value of CHAMP in a series of MD and non-MD patients with otovestibular complaints. Study Design: An observational retrospective study. Setting: Tertiary referral centre. Patients: Forty-five patients, of which 28 patients had MD. Interventions: Cochlear Hydrops <b>Analysis</b> <b>Masking</b> Procedure test was conducted, and audiometric data and clinical information were collected. All responses were blindly evaluated and divided into three categories: (1) test suggestive for cochlear/ELH, (2) test within normal ranges, and (3) test not interpretable. Main Outcome Measures: Sensitivity and specificity, evaluation of diagnostic value. Results: Forty-nine percent of the tests were found to be not interpretable. Of the remaining responses, 13 tests were suggestive for ELH, and 16 tests were within normal ranges. This yields a sensitivity of 31 % and a specificity of 28 %. There {{was no significant difference between}} the mean latency difference (mean [SD]) for Wave V of the MD group (0. 43 ms [0. 37]) and the non-MD group (0. 65 ms [0. 44]). Using logistic regression analysis, we found that CHAMP test did not contribute to the ability to discriminate between hydropic and nonhydropic ears. Conclusion: In contrast to studies assessing CHAMP performance in Meniere patients and normal controls, the present study revealed this new test offers no discriminative value in differentiating Meniere's from non-MD subjects with otovestibular symptoms...|$|R
30|$|So far, we have {{conducted}} the analysis on the pooled sample from the 12 countries under study. It could {{be the case that}} the lack of difference in prosociality that we find in the conditional regressions {{is due to the fact}} that we mix countries where public sector workers are more prosocially motivated than their private sector counterparts with countries where public sector workers are more antisocial, for instance, because public sector employment is a way to extract rents and bribes from the rest of society. To assess whether the previous <b>analysis</b> <b>masks</b> such types of cross-country heterogeneity, in this section, we conduct the analysis for each of the 12 countries in our sample separately, with the caveat that, as evident from Table 1, sample sizes can become rather small.|$|R
50|$|In the {{aperture}} masking technique, the bispectral <b>analysis</b> (speckle <b>masking)</b> method is typically applied to image data taken through masked apertures, {{where most of}} {{the aperture}} is blocked off and light can only pass through a series of small holes (subapertures). The aperture mask removes atmospheric noise from these measurements, allowing the bispectrum to be measured more quickly than for an un-masked aperture.|$|R
40|$|Objective: To {{investigate}} {{the usefulness of}} the cochlear hydrops <b>analysis</b> <b>masking</b> procedure (CHAMP) as an additional diagnostic test in patients with definite unilateral Meniere's disease. Study Design: Prospective validation study for a diagnostic test. Setting: Tertiary referral center. Patients: Subjects (n = 22) with definite unilateral Meniere's disease. Interventions: The CHAMP test was performed in both ears of the patients. Main Outcome Measure: Difference in latency delay between the affected and the unaffected ears. Results: In 20 subjects, latency delays could be measured in both ears. The mean latency delay for the affected ears (0. 55 ms; standard error, 0. 12 ms) differs significantly from that for the unaffected ears (3. 36 ms; standard error, 0. 43 ms). With the standard criterion to separate ears with an abnormally short delay (Conclusion: Abnormal latency delays for CHAMP are delays shorter than 2 ms. Earlier results with CHAMP should be reconsidered using this criterion, instead of 0. 3 ms...|$|R
40|$|Purpose – The {{purpose of}} this paper is to explore the {{relationship}} between educational orientation and employer influenced pedagogy and to consider some implications for work-based learning (WBL) higher education (HE) policy and practice in Europe. Design/methodology/approach – The paper draws on purposefully selected case studies to describe the key attributes of WBL related pedagogy associated with three HE programmes in Finland, Spain and the UK. Findings – The national regulatory environment has a key role to play in issues associated with WBL pedagogy. The case studies also demonstrate a pluralistic approach to pedagogy and the key role that employers play in both providing regular intelligence to inform curriculum design and contributing to pedagogy. Research limitations/implications – The small number of case studies limits the opportunity for generalisation and the level of <b>analysis</b> <b>masks</b> subtle and interesting differentiations in pedagogy worthy of further exploration. Practical implications – The paper highlights implications for government to provide the vision and regulatory environment to encourage WBL and for universities and academics to design and implement innovative, pluralist pedagogies. Originality/value – The paper provides a new framework and a unique analysis of programme level case studies from three European countries...|$|R
40|$|Cervical {{vestibular}} evoked myogenic potential (cVEMP) and cochlear hydrops <b>analysis</b> <b>masking</b> procedure (CHAMP) {{have both}} shown sensitivity in identifying Meniere’s disease. However {{none of the}} previous reports have compared the two tests for their relative efficacy in identifying Meniere’s disease. Hence the present study aimed to compare the efficiency of cVEMP and CHAMP in evaluating Meniere’s disease. The study included 58 individuals with unilateral definite Meniere’s disease and {{an equal number of}} age and gender matched healthy individuals. cVEMP corresponding to 500 [*]Hz tone burst was recorded from ipsilateral sternocleidomastoid muscle and CHAMP was acquired from the conventional electrode sites for single channel auditory brainstem response recording using a default protocol of the Biologic Navigator Pro evoked potential system. Both cVEMP and CHAMP showed statistically significant differences between the groups (P< 0. 05). The receiver operating curves revealed 100 % sensitivity and specificity for CHAMP as against 70. 7 % sensitivity and 100 % specificity for cVEMP in identifying Meniere’s disease. Therefore, CHAMP appears to be the test of choice provided the degree of hearing loss does not exceed a moderate degree. cVEMP could be used for all degrees of hearing losses, but with slight constraint on the sensitivity...|$|R
40|$|Much safety climate {{research}} has focused on the organization as the unit of analysis. However, using the organization as the level of <b>analysis</b> can <b>mask</b> important sub-unit differences. Workgroups in the Australian construction industry have been found to demonstrate significant within group homogeneity and between-group variation in safety climate. In particular, subcontracted work groups are reported to develop unique and variable safety climates. A typology of group-level safety climates is developed, based on the combination of climate level and climate strength...|$|R
40|$|Compositional changes {{through local}} {{extinction}} and colonization are inherent to natural communities, but human activities are increasingly influencing the rate {{and nature of}} the species being lost and gained. Biotic homogenization refers to the process by which the compositional similarity of communities increases over time through a nonrandom reshuffling of species. Despite the extensive conceptual development of the homogenization framework, approaches to quantify patterns of homogenization are scarcely developed. Most studies have used classical dissimilarity indices that actually quantify two components of compositional variation: turnover and nestedness. Here we demonstrate that a method that partitions those two components reveals patterns of homogenization that are otherwise obscured using traditional techniques. The forest understorey vegetation of an unmanaged reserve was recorded in permanent plots in 1979 and 2009. In only thirty years, the local species richness significantly decreased and the variation in the species composition from site to site shifted towards a structure with reduced true species turnover and increased dissimilarity due to nestedness. A classic <b>analysis</b> <b>masked</b> those patterns. In summary, we illustrated the need to move beyond the simple quantification of homogenization using classical indices and advocate integration of the multitude of ways to quantify community similarity into the homogenization framework. status: publishe...|$|R
40|$|The DJANAL (DisJunct ANALyzer) Program {{provides}} a means for the LSI designer to format output from the <b>Mask</b> <b>Analysis</b> Program (MAP) for input to the FETLOG (FETSIM/LOGSIM) processor. This document presents {{a brief description of}} the operation of DJANAL and provides comprehensive instruction for its use...|$|R
3000|$|The <b>masking</b> <b>analysis</b> method {{described}} in MPEG 1 audio coder {{is used to}} detect the tonal and nontonal components[15]. The tonal and noise masking threshold that give the maximum level of noise that is inaudible {{in the presence of}} speech is computed. The calculation steps as {{described in}}[15] are: [...]...|$|R
40|$|We {{investigate}} sets {{of random}} variables {{that can be}} arranged sequentially such that a given variable only depends conditionally on its immediate predecessor. For such sets, we show that the full joint probability distribution may be expressed exclusively in terms of uni- and bivariate marginals. Under {{the assumption that the}} CMB power spectrum likelihood only exhibits correlations within a banded multipole range, ∆`, we apply this expression to two outstanding problems in CMB likelihood analysis. First, we derive a statistically well-defined hybrid likelihood estimator, merging two independent (e. g., low- and high-`) likelihoods into a single expression that properly accounts for correlations between the two. Applying this expression to the WMAP likelihood, we verify that the effect of correlations on cosmological parameters in the transition region is negligible in terms of cosmological parameters for WMAP; the largest relative shift seen for any parameter is 0. 06 σ. However, because this may not hold for other experimental setups (e. g., for different instrumental noise properties or <b>analysis</b> <b>masks),</b> but must rather be verified on a case-by-case basis, we recommend our new hybridization scheme for future experiments for statistical self-consistency reasons. Second, we use the same expression to improve the convergence rate of the Blackwell-Rao likelihood estimator, reducing the required number of Monte Carlo samples by several orders of magnitude, and thereby extend it to high- ` applications...|$|R
40|$|Heart Rate Variability (HRV) is {{extensively}} used {{to investigate}} general Autonomic Nervous System (ANS) function and {{is affected by}} many factors including age, gender, pathology such as diabetes and genetic polymorphisms. One of these genetic polymorphisms is the Angiotensin Converting Enzyme (ACE) polymorphism corresponding to insertion (I) or deletion (D) of a 287 -base pair sequence of DNA in intron 16 of the ACE gene (rs 4340). Some studies have addressed the relationship between HRV and D/D, I/D and I/I ACE polymorphism while others combined I/D and I/I ACE groups. In this study HRV is determined for diabetic and control individuals with different ACE polymorphism considering either separate or combined I/D and I/I genotypes. Linear time domain parameters, entropy, low frequency and total power of HRV {{were found to be}} significantly different between diabetic and control individuals with combined I/I and I/D ACE polymorphism, while only entropy was different for diabetic and control subjects with D/D ACE genotype. Separate analysis of I/I and I/D genotypes was preferred for a thorough investigation of HRV and ACE polymorphism, as the combined <b>analysis</b> <b>masked</b> some differences in HRV parameters such as Poincaré plot between ACE polymorphisms and diabetes status. Furthermore, a separate analysis demonstrated that most of the significant differences for HRV were between the diabetic group with I/I genotype and I/D and D/D groups. 4 page(s...|$|R
40|$|Hierarchical {{application}} of Triple-Modular Redundancy (TMR) increases fault tolerance of digital Integrated Circuit (IC). In this paper, a simple probabilistic model was proposed for <b>analysis</b> of fault <b>masking</b> performance of hierarchical TMR networks. Performance improvements obtained by second order TMR network were theoretically compared with first order TMR network. Comment: Proposition section was adde...|$|R
40|$|Left {{ventricular}} hypertrophy (LVH) {{associates with}} {{increased risk for}} cardiovascular disease. Hypertension leads to LVH in adults, but {{its role in the}} pathogenesis of LVH in children is not as well established. To examine left ventricular mass and evaluate factors associated with LVH in children with stages 2 through 4 chronic kidney disease (CKD), we analyzed cross-sectional data from children who had baseline echocardiography (n = 366) and underwent ambulatory BP monitoring (n = 226) {{as a part of the}} observational Chronic Kidney Disease in Children (CKiD) cohort study. At baseline, 17 % of children had LVH (11 % eccentric and 6 % concentric) and 9 % had concentric remodeling of the left ventricle. On the basis of a combination of ambulatory and casual BP assessment (n = 198), 38 % of children had masked hypertension (normal casual but elevated ambulatory BP) and 18 % had confirmed hypertension (both elevated casual and ambulatory BP). There was no significant association between LVH and kidney function. LVH was more common in children with either confirmed (34 %) or masked (20 %) hypertension compared with children with normal casual and ambulatory BP (8 %). In multivariable <b>analysis,</b> <b>masked</b> (odds ratio 4. 1) and confirmed (odds ratio 4. 3) hypertension were the strongest independent predictors of LVH. In conclusion, casual BP measurements alone are insufficient to predict the presence of LVH in children with CKD. The high prevalence of masked hypertension and its association with LVH supports early echocardiography and ambulatory BP monitoring to evaluate cardiovascular risk in children with CKD...|$|R
40|$|Background: Appropriateness for lung volume {{reduction}} {{surgery is}} often determined {{based on the}} results of high-resolution CT (HRCT) scanning of the chest. At many centers, radiologists and pulmonary physicians both review the images, but the agreement between readers from these specialties is not known. Methods: Two thoracic radiologists and three pulmonologists retrospectively reviewed the HRCT scans of 30 patients with emphysema involved in two clinical studies at our institution. Each reader assigned an emphysema severity score and assessed upper lobe predominance, using a methodology similar to that of the National Emphysema Treatment Trial. In addition, the percentage of emphysema at – 910 Hounsfield units was objectively determined by density <b>mask</b> <b>analysis.</b> Results: For the emphysema severity scores, (Spearman) correlation between readers ranged from 0. 59 (p 0. 0005) to 0. 87 (p < 0. 0001), with generally stronger correlations among readers from the same medical specialty. Emphysema severity scores were significantly correlated with prebronchodilator and postbronchodilator spirometry findings, as well as with density <b>mask</b> <b>analysis.</b> In the assessment of upper lobe predominance, statistics for agreement ranged from 0. 20 (p 0. 4) to 0. 60 (p 0. 0008). Examining all possible radiologist-pulmonologist pairs, the two readers agreed in their assessments of emphysema distribution in 75 % of the comparisons. Readers agreed on upper lobe-predominant disease in 9 of the 10 patients in which regional density <b>mask</b> <b>analysis</b> clearly showed upper lobe predominance. Conclusions: In a group of patients with varying emphysema severity, interobserver agreement in the determination of upper lobe-predominant disease was poor. Agreement between readers tended to be better in cases with clear upper lobe predominance as determined by densitometry...|$|R
40|$|OBJECTIVES: Extensive {{endurance}} {{training and}} arterial hypertension are established {{risk factors for}} atrial fibrillation. We aimed to assess the proportion of masked hypertension in endurance athletes and the impact on cardiac remodeling, mechanics, and supraventricular tachycardias (SVT). METHODS: Male participants of a 10 -mile race were recruited and included if office blood pressure was normal (< 140 / 90 mmHg). Athletes were stratified into a masked hypertension and normotension group by ambulatory blood pressure. Primary endpoint was diastolic function, expressed as peak early diastolic mitral annulus velocity (E'). Left ventricular global strain, left ventricular mass/volume ratio, left atrial volume index, signal-averaged P-wave duration (SAPWD), and SVT during 24 -h Holter monitoring were recorded. RESULTS: From 108 runners recruited, 87 {{were included in the}} final analysis. Thirty-three (38 %) had masked hypertension. The mean age was 42 +/- 8 years. Groups did not differ with respect to age, body composition, cumulative training hours, and 10 -mile race time. Athletes with masked hypertension had a lower E' and a higher left ventricular mass/volume ratio. Left ventricular global strain, left atrial volume index, SAPWD, and SVT showed {{no significant differences between the}} groups. In multiple linear regression <b>analysis,</b> <b>masked</b> hypertension was independently associated with E' (beta = - 0. 270, P = 0. 004) and left ventricular mass/volume ratio (beta = 0. 206, P = 0. 049). Cumulative training hours was the only independent predictor for left atrial volume index (beta = 0. 474, P < 0. 001) and SAPWD (beta = 0. 481, P < 0. 001). CONCLUSION: In our study, a relevant proportion of middle-aged athletes had masked hypertension, associated with a lower diastolic function and a higher left ventricular mass/volume ratio, but unrelated to left ventricular systolic function, atrial remodeling, or SVT...|$|R
40|$|Masking is {{the central}} topic of this thesis based on publications. Masking is a {{technique}} that allows the secure execution of cryptographic algorithms in untrusted environments. More concretely, masking provides security guarantees even if an adversary observes side-channel leakage. We first propose a methodology to attack masked implementations more quickly. Our method is relevant in practice since it allows to carry out attacks that before took months in days. The proposed method first locates the relevant time samples for an attack and then only attacks those. For this purpose we rely on versatile information-theoretic tools. The second selected paper in this thesis deals with Differential Power <b>Analysis,</b> <b>masking</b> and bit-slicing at very high clock speeds, such as those typically found in today's smartphones and personal electronic devices. We present an attack on an ARM Cortex-A 8 running at 1 GHz, and then apply the principles of gate-level masking to develop a DPA-resistant bit-sliced AES implementation. In our third selected paper, we propose a new masking strategy for a post-quantum public-key algorithm: ring-LWE. Our solution is essentially arithmetic masking with a bespoke probabilistic decoder. Our approach fits in a standard FPGA and incurs manageable performance overheads. We explain in our fourth paper {{similarities and differences between}} theoretical and practical instances of masking schemes. These observations allow us to break some masking schemes proposed in literature and transfer attractive features from one scheme to another. To conclude, in the fifth paper we describe a simple, yet powerful tool to detect flaws in masking schemes. Sound masking schemes can be surprisingly difficult to design (especially if they provide higher-order security guarantees); our tool assists the design process of a masking scheme by assessing the soundness of a masking scheme at the algorithmic level before implementing it on an actual device. status: publishe...|$|R
40|$|In {{longitudinal}} data <b>analysis,</b> <b>masking</b> and swamping (MS) are two common effects {{that can cause}} severe problems. Successful identification of MS effects is essential to both outlier detection and {{longitudinal data}} analysis because ignorance of the MS effects can make the conclusion of analysis totally meaningless and misleading. In this thesis, a statistical method for analyzing and diagnosing longitudinal data sets is proposed as the forward search of the generalized estimating equation (GEE) method (FSGEE). Starting from an outlier-free initial subset of the data selected using a robust method, FSGEE makes its progress to the next subset by expanding the subset according to {{the distance of the}} observations to the GEE model fitted from the current subset. Through monitoring statistical diagnostics during the forward search process, the forward plots are produced by plotting the diagnostics against the sizes of the forward search subsets. The MS effects can then be discovered by simply investigating the forward plots of residuals. When the inclusion of an observation affects the model and the diagnostics of other points significantly, the observation is suspected to be an outlier. When necessary, by examining the forward plots of various statistical diagnostics, {{a deeper understanding of the}} observation can be acknowledged, for example changes in the values of the coefficients after the observation is included, or changes in the diagnostics of other observations when the suspicious outlier is removed from the data set. The acknowledgement will help in deciding whether the observation is a true outlier, or just a non-outlying observation with relatively high leverage. Through simulation studies and the analysis of seizure data and hormone data, the forward search of the GEE method is shown to be able to provide a wealth of information for guiding both outlier detection and the identification of MS effects. published_or_final_versionStatistics and Actuarial ScienceMasterMaster of Philosoph...|$|R
40|$|A new {{approach}} to the separation of speech from speech-in-noise mixtures {{is the use of}} time–frequency (T-F) masking. Originated in the field of computational auditory scene <b>analysis,</b> T-F <b>masking</b> performs separation in the time–frequency domain. This article introduces the T-F masking concept and reviews T-F masking algorithms that separate target speech from either monaural or binaural mixtures, as well as microphone-array recordings. The review emphasizes techniques that are promising for hearing aid design. This article also surveys recent studies that evaluate the perceptual effects of T-F masking techniques, particularly their effectiveness in improving human speech recognition in noise. An assessment is made of the potential benefits of T-F masking methods for the hearing impaired in light of the processing constraints of hearing aids. Finally, several issues pertinent to T-F masking are discussed...|$|R
40|$|METHODS We used a phase 2 {{exploratory}} cluster randomised controlled {{trial with}} eight general practices in Glasgow in very deprived areas that involved multimorbid patients aged 30 – 65 years. The intervention comprised structured longer consultations, relationship continuity, practitioner support, and self-management support. Control practices continued treatment as usual. Primary outcomes were quality of life (EQ- 5 D- 5 L utility scores) and well-being (W-BQ 12; 3 domains). Cost-effectiveness from a health service perspective, engagement, and retention were assessed. Recruitment and baseline measurements occurred prior to randomisation. Blinding post-randomisation was not possible but outcome measurement and <b>analysis</b> were <b>masked.</b> Analyses were by intention to treat. RESULTS Of 76 eligible practices contacted, 12 accepted, and eight were selected, randomised and participated {{for the duration of}} the trial. Of 225 eligible patients, 152 (68...|$|R
40|$|It {{has been}} {{demonstrated}} that traffic analysis can disclose information supposedly secured by encrypted channels. Key feature of packetized traffic exploited to that purpose are packet lengths, inter-packet times, direction of packets. This work aims at assessing the overhead and delay implied by traffic masking algorithms that conceal the information leakage exploited by statistical traffic <b>analysis.</b> Traffic <b>masking</b> is obtained by reshaping packet lengths and inter-arrival times in a masking device. It is shown that the overhead-delay trade-off of the masking device is optimized by using circuit like traffic shaping, under the constraint of removing information leakage entirely (full privacy). Numerical examples are provided with real traffic traces both for full privacy and for a relaxed heuristic masking algorithm that leaks some information on packet lengths to mitigate the overhead. © 2013 IEEE...|$|R
40|$|This {{contribution}} {{details the}} development of a mask-based post- pro-cessor to improve the interference suppression in speech signals sep-arated using linear deconvolution algorithms like Independent Com-ponent Analysis (ICA). The design of the proposed post-filter is in two stages: in the first stage, use is made of the disjointness of the separated signals in the time-frequency domain to obtain binary masks to suppress cross-talk that generally remains after separation. In the next stage, a novel smoothing of the masks is proposed that preserves the speech structure of the target source while eliminating the random peaks in the time-frequency plane that lead to fluctuat-ing background noise. The result is an enhanced signal with reduced cross-talk and no musical noise. Index Terms — independent component <b>analysis,</b> time-frequency <b>masking,</b> post processing, cepstro-temporal smoothing, musical noise 1...|$|R
40|$|The article {{provides}} {{an analysis of}} image processing and color segmentation applied {{to the problem of}} selection of homogeneous regions in the parameters of the color model. Methods of image processing such as Gaussian filter, median filter, histogram equalization and mathematical morphology are considered. The segmentation algorithm with the parameters of color components is presented, followed by isolation of the resulting connected component of a binary segmentation <b>mask.</b> <b>Analysis</b> of methods performed on images colposcopic research...|$|R
40|$|A {{document}} {{intended to}} serve as a User's Manual and a Programmer's Manual for the <b>Mask</b> <b>Analysis</b> Program is presented. The first portion of the document is devoted to the user. It contains all of the information required to execute MAP. The remainder of the document describes the details of MAP software logic. Although the information in this portion is not required to run the program, it is recommended that every user review it to gain an appreciation for the program functions...|$|R
40|$|Most {{theoretical}} work on coded aperture masks in X-ray and low-energy gamma-ray astronomy has {{concentrated on}} masks {{with large numbers}} of elements. For gamma-ray spectrometers in the MeV range, the detector plane usually has only a few discrete elements, so that masks with small numbers of elements are called for. For this case it is feasible to analyze by computer all the possible mask patterns of given dimension to find the ones that best satisfy the desired performance criteria. A particular set of performance criteria for comparing the flux sensitivities, source positioning accuracies and transparencies of different mask patterns is developed. The results of such a computer <b>analysis</b> for <b>masks</b> up to dimension 5 x 5 unit cell are presented and it is concluded that {{there is a great deal}} of flexibility in the choice of mask pattern for each dimension...|$|R
40|$|Abstract. We are {{developing}} two crucial improvements on the time-frequency masking {{approach to the}} blind speech separation of underdetermined mixtures when processing anechoic and echoic mixtures. First, the proposed method copes with the usually large amount of delay estimation error that appears in a low frequency band. This step generates a restrictive mask for phase delays {{on the basis of}} local and global energy distribution <b>analysis.</b> This <b>mask</b> allows the selected cells to contribute to the orientation histogram. Second, the strong WDO assumption (disjoint orthogonal frequency domain) is relaxed by allowing some frequency bins to be shared by both sources. By detecting fundamental frequencies of speakers at instantaneous time points, mask creation is supported by exploring their harmonic frequencies. The proposed method is proved to be effective and reliable in conducting experiments with both simulated and real-life mixtures...|$|R
40|$|International audienceThis paper {{presents}} an efficient platform for fault robustness estimation of digital circuits. The proposed platform, named FIFA, {{was designed as}} a hardware IP to accelerate the Fault Injection and Fault <b>masking</b> <b>Analysis</b> approach. It supports several fault models as well as single and multiple faults. Synthesis results have shown that the proposed platform can exceed those existent in the literature in terms of area efficiency and performance. In addition, the FIFA platform allows the designer to control complexity and completeness of the analysis process...|$|R
40|$|Abstract. The {{literature}} on side-channel <b>analysis</b> describes numerous <b>masking</b> schemes {{designed to protect}} block ciphers at the implementation level. Such masking schemes typically require the computation of masked tables prior to the execution of an encryption function. In this paper we revisit an attack which directly exploits this computation {{in such a way}} as to recover all or some of the masks used. We show that securely implementing masking schemes is only possible where one has access to a significant amount of random numbers...|$|R
