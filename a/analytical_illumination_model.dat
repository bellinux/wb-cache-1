0|571|Public
40|$|Analytical {{models of}} light {{reflection}} are in common use in computer graphics. However, as {{the sophistication of}} rendering methods has increased, analytical models have become less adequate for generating images. Reflectance data obtained by empirically measuring real world surfaces is needed to create more realistic looking images. In this paper we examine several issues relevant to using measured reflectance functions in generating computer graphics images. We give {{an overview of the}} techniques involved in measuring and tabulating reflectance data. We compare and contrast measured reflectance functions with <b>analytical</b> <b>illumination</b> <b>models,</b> and evaluate several methods for interpolating tabulated reflectance functions. We also highlight potential areas of future research. 1 Introduction The most fundamental operation in rendering computer graphics images is the computation of how light reflects off surfaces. This computation is often performed using a local <b>illumination</b> <b>model.</b> This is [...] ...|$|R
40|$|This report {{concern the}} {{representation}} of trees for high quality landscapes rendering dedicated to the realistic representation of forest conifers. The main characteristic of a natural landscape is its complexity, in all senses of the term. A landscape is a vast land for the scientific observer where {{of the thousands of}} phenomena interacts between them to give a qualitative and quantitative wealth of shapes, of movements, of colors, etc. Like all scene a stage of landscape requires a phase of modelling of the factor there taking room, mainly the land and trees. Techniques of tree modelling give good results in terms of diversity of species and shapes. However, the multitude of polygons of their geometrical representations generates a high computing cost an important problems of aliasing at rendering. Mesh simplification in order to built level of details is not adapted to trees since is alters global illumination and opacity, because of the discontinuous repartition of the leaves. With the idea of representing groups of primitives (leaves) using packets combining geometric and photometric appearance. Using the knowledge of the geometric distribution of needles, we use a representation based on the <b>analytical</b> computation global <b>illumination</b> <b>model</b> of the geometric branch of needles. In this case, we compute an analytical a hierarchy of three shaders able to represent effect of lower levels, without sampling and with self shadowing and visibility. The analytical aspect of these shaders allows in the same time the acceleration of computing time and good image quality, particularly with little aliasing...|$|R
40|$|Abstract. Realistic {{graphics}} for {{virtual reality}} {{system has been}} a hot research at home and abroad, the <b>illumination</b> <b>model</b> mapping and its application of the algorithms {{is one of the}} key level to achieve realistic scenes. This paper introduced the <b>illumination</b> <b>model</b> mapping and classification of the algorithms, focused on ray tracing algorithms and bounding box technology of the global <b>illumination</b> <b>model</b> which were realized in the oilfield virtual reality system and have been achieved good results...|$|R
40|$|The {{object of}} this work is to design and {{implement}} an application for interactive experiments with local <b>illumination</b> <b>models.</b> The user can arbitrarily define an <b>illumination</b> <b>model</b> with mathematical formulas and mark certain parameters to be changeable. While such parameters are changed, the program smoothly draws an updated 3 D scene. The scene can be defined in the text format, while several scenes are bundled with the program. Two predefined well-known <b>illumination</b> <b>models</b> are also bundled with the program - Strauss' and Phong's model...|$|R
40|$|There {{are some}} methods {{suggested}} by researchers {{were used to}} simulate one or two characteristics of textile {{in the past few}} years. With 3 D geometry models, most of these methods are somewhat complex, {{and it is difficult to}} simulate fabric attributes. This paper represents a method for textile simulation based on improved BRDF <b>illumination</b> <b>models.</b> As one simple type of BRDF <b>model,</b> Phong <b>illumination</b> <b>model</b> can be used to simulate fabric 3 D geometry model. The more complex BRDF <b>illumination</b> <b>model</b> may be used to simulate fabric 3 D structure. The pixel color values, derived from simulating fabric 3 D structure, is taken as the parameters to be entered into Phong <b>illumination</b> <b>model.</b> And thus both the fabric 3 D geometry model and structure can be achieved, based on which the textile can be simulated successfully and obtain a perfect display effect...|$|R
5000|$|Support of {{different}} <b>illumination</b> <b>models</b> (Phong reflection model, tone shading, ambient occlusion) ...|$|R
5000|$|Multiple <b>illumination</b> <b>models</b> are available, per material. These are {{enumerated}} as follows: ...|$|R
5000|$|Apply an <b>illumination</b> <b>model</b> to each pixel to {{calculate}} the light intensity from Ni.|$|R
40|$|Abstract. This {{article is}} {{intended}} as an update {{of the major}} survey by Max [1] on optical models for direct volume rendering. It provides {{a brief overview of}} the subject scope covered by [1], and brings recent developments, such as new shadow algorithms and refraction rendering, into the perspective. In particular, we examine three fundamentals aspects of direct volume rendering, namely the volume rendering integral, local <b>illumination</b> <b>models</b> and global <b>illumination</b> <b>models,</b> in a wavelength-independent manner. We review the developments on spectral volume rendering, in which visible light are considered as a form of electromagnetic radiation, optical models are implemented in conjunction with representations of spectral power distribution. This survey can provide a basis for, and encourage, new efforts for developing and using complex <b>illumination</b> <b>models</b> to achieve better realism and perception through optical correctness. ...|$|R
40|$|International audienceIn this paper, {{we propose}} {{a method for}} taking into account {{lighting}} conditions for photometric stereo. Indeed, with its classic form, the photometric stereo requires directional light sources and uniform intensity to determine the geometry and albedo of a surface from a reverse <b>illumination</b> <b>model.</b> These constraints are usually not realistic in practice for compact systems, our formulation thus takes account all lighting system properties. We use an iterative process to include the geometry of the surface in the reverse <b>illumination</b> <b>model.</b> Each iteration provides a refined reconstruction and significantly improves the results. Our method {{does not require a}} new <b>illumination</b> <b>models</b> and the iteration number is small. It allows to quickly recover geometry and albedo. To evaluate the performance of our method, we compare it to classical photometric stereo by simulation and on real surfaces...|$|R
40|$|Figure 1 : A CT scan {{of a mouse}} (360 × 270 × 550 voxels) {{rendered}} {{with the}} proposed <b>illumination</b> <b>model.</b> The closeups on the right show, that semi-transparent, diffuse as well as specular materials are captured realistically. In this paper we present a volumetric lighting model, which simulates scattering as well as shadowing in order to generate high quality volume renderings. By approximating light transport in inhomogeneous participating media, {{we are able to}} come up with an efficient GPU implementation, in order to achieve the desired effects at interactive frame rates. Moreover, in many cases the frame rates are even higher as those achieved with conventional gradientbased shading. To evaluate the impact of the proposed <b>illumination</b> <b>model</b> on the spatial comprehension of volumetric objects, we have conducted a user study, in which the participants had to perform depth perception tasks. The results of this study show, that depth perception is significantly improved when comparing our <b>illumination</b> <b>model</b> to conventional gradient-based volume shading. Additionally, since our volumetric <b>illumination</b> <b>model</b> is not based on gradient calculation, it is also less sensitive to noise and therefore also applicable to imaging modalities incorporating a higher degree of noise, as for instance magnet resonance tomography or 3 D ultrasound...|$|R
40|$|Abstract. Building {{mountains}} as {{the basic}} <b>model</b> for <b>illumination</b> <b>model</b> in the system of 3 DGIS visualization. The establishing of this model adopts {{the approach of the}} global <b>illumination</b> <b>model</b> combine with the local reflection model and also the combination of shading and shadow. Complete the drawing of the shadow in the global illumination model,using the shadow algorithm of Ray tracing as the main algorithm for drawing shadow, take advantage of shadow volume algorithm as the additional algorithm for shadow; complete the drawing of the shading in the local reflection model,using the Blinn proportion algorithm as the main algorithm. Select the single ideal fixed point source as the light source of the <b>illumination</b> <b>model.</b> The results of this experimental show that the approach of combination of global and local model is feasible, the selection of the shadow and shading algorithms are also can reference. ...|$|R
40|$|Problem: Model light‐surface {{interaction}} at vertices {{to determine}} vertex color and brightness � Per vertex calculation? Usually done in vertex shader lighting Shading? � After triangle is rasterized (drawn) Triangle {{converted to a}} group of pixels Per‐vertex lighting calculation means we know color of pixels coinciding with vertices (red dots) � Shading problem: figure out color of interior pixels � How? Assume linear change => interpolate Shading Lighting (or <b>Illumination)</b> <b>Model?</b> � Governing principles for computing illumination � An <b>illumination</b> <b>model</b> usually considers: 3. Interaction between lights and object...|$|R
40|$|We {{consider}} {{a problem that}} arises {{in the evaluation of}} computer graphics <b>illumination</b> <b>models.</b> In particular, {{there is a need to}} find a finite set of wavelengths at which the <b>illumination</b> <b>model</b> should be evaluated. The result of evaluating the <b>illumination</b> <b>model</b> at these points is a sampled representation of the spectral power density of light emanating from a point in the scene. These values are then used to determine the RGB coordinates of the light by evaluating three definite integrals, each with a common integrand (the SPD) and interval of integration but with distinct weight functions. We develop a method for selecting the sample wavelengths in an optimal manner. More abstractly, we examine the problem of numerically evaluating a set of m definite integrals taken with respect to distinct weight functions but related by a common integrand and interval of integration. It is shown that when m 3 it is not efficient to use a set of m Gauss rules because valuable information is wast [...] ...|$|R
40|$|This work is {{restricted}} {{to the field of}} Graphics Representation in Architecture, analyzing the use of <b>illumination</b> <b>models</b> which are present at the software usually used for the development of images to describe the architectural objects. The differences between the real scene and the equivalences structured into the world of computer graphics related to the <b>illumination</b> <b>models</b> and light, are specially specified. This work analyses the categories of architectural problems associated to each of the available models; questions how this associations are included in architectural teaching context and studies how associated they are during the academic studies of the architect...|$|R
40|$|The Phong <b>illumination</b> <b>model</b> {{is still}} {{widely used in}} realtime 3 D {{visualization}} systems. The aim {{of this article is}} to document problems with the Phong <b>illumination</b> <b>model</b> that are encountered by an important professional user group, namely digital designers. This leads to a visual evaluation of Phong illumination, which at least in this condensed form seems still to be missing in the literature. It is hoped that by explicating these flaws, awareness about the limitations and interdependencies of the model will increase, both among fellow users, and among researchers and developers. Comment: 17 pages, 8 figure...|$|R
40|$|In {{recent years}} {{a number of}} {{techniques}} {{have been developed for}} rendering volume effects (haze, fog, smoke, clouds, etc.). Such techniques have been implemented for projective scanline renderers, ray-tracers and for radiosity. Roughly speaking, such a method depends on an <b>illumination</b> <b>model</b> which accounts for the light-material interaction, together with a sampling strategy for reading the data of the density field. The <b>illumination</b> <b>models</b> proposed in literature are quite complicated and require several time-consuming operations, such as exponential functions, roots and trigonometrical functions. Ray-tracing and radiosity evaluate the <b>illumination</b> <b>model</b> at every voxel of the density field. Since several hundred complicated calculations are necessary for each ray, such a rigorous evaluation is very time-consuming. On the other hand, methods proposed for scanline renderes solve the equations describing scattering and reflection of light analytically along each ray within a volume; thus, such methods do not account for arbitrary density distribution. The {{purpose of this paper is}} not to propose a new <b>illumination</b> <b>model,</b> but to compare several methods for efficiently sampling arbitrary distributed data, i. e., efficiently distribute the samples within the sampling volume. We propose that several sampling strategies can be used to reduce the number of evaluations of the illumination calculations along a ray and, thus, reduce the rendering time needed. Such methods are well suited for scanline renderers but can be used with ray-tracers. We propose a Monte-Carlo approach and an approximative method with user-adjustable accuracy to sample the volume data...|$|R
40|$|In {{this paper}} {{we present a}} {{volumetric}} lighting model, which simulates scattering as well as shadowing in order to generate high quality volume renderings at interactive frame rates. By approximating light transport in inhomogeneous participating media, {{we are able to}} come up with an efficient GPU implementation, which allows the simulation of scattering and shadowing at interactive frame rates. Moreover, in many cases the frame rates are even higher as those achieved with conventional gradient-based shading. To evaluate the impact of the proposed <b>illumination</b> <b>model</b> on the spatial comprehension of volumetric objects, we have conducted a user study, in which the participants had to perform depth perception tasks. The results of this study show, that depth perception is significantly improved when comparing our <b>illumination</b> <b>model</b> to conventional gradient-based volume shading. Additionally, since our volumetric <b>illumination</b> <b>model</b> is not based on gradient calculation, it is also less sensitive to noise and therefore also applicable to imaging modalities incorporating a higher degree of noise, as for instance magnet resonance tomography or 3 D ultrasound...|$|R
40|$|A spherical target {{irradiated}} by {{laser beams}} located at 49 o and 131 o {{with respect to}} the polar axis has been considered. The <b>illumination</b> <b>model</b> has been used to evaluate the irradiation non-uniformity assuming circular and elliptical super-gaussian laser intensity profiles and the irradiation scheme has been optimized by means of the Polar Direct Drive technique. A parametric study has been performed providing the irradiation non-uniformity {{as a function of the}} Polar Direct Drive displacement and of the laser intensity profile parameters. Moreover, two-dimensional axis-symmetric hydrodynamic simulations have been performed for a plastic sphere irradiated by laser beams characterized by a constant flat temporal power pulse. In these simulations the front of the inward shock wave has been tracked providing the time-evolution of any non-uniformity. The results provided by the two methods - <b>illumination</b> <b>model</b> and hydrodynamic data - have been compared and it is found that the <b>illumination</b> <b>model</b> reproduces the main behaviour exhibited by the hydrodynamic data. The two models provide compatible values for the optimum Polar Direct Drive parameter and similar optimal super-gaussian profiles...|$|R
40|$|Abstract – For {{improved}} multispectral classification and {{retrieval of}} Lambertian reflectances from patches of arbitrary surface orientation, we investigate {{the consequences of}} a dichromatic <b>illumination</b> <b>model</b> accounting for direct sunlight and diffuse skylight. This <b>illumination</b> <b>model</b> leads to the concept of spectral classes as two dimensional planes in the feature space. This paper addresses three questions arising from this concept and applies them to experimental data: We presents the projected spectral angle as a novel spectral distance for the classification of multispectral images. We show how the normalized Lambertian reflectance of a surface can be retrieved from at least two observed spectra under arbitrary angles...|$|R
40|$|Abstract. Anisotropic shading {{techniques}} {{can be used}} for materials like hair and silk. Such materials have a surface consisting of very small fibers having a main direction. Geometrically each fiber {{can be viewed as a}} cylinder. Poulin and Fournier proposed an <b>illumination</b> <b>model</b> for such materials using a flat topology only. In the paper a model using a varying topology is described. The varying topology is a more correct model and visible differences are clearly apparent. In the paper the necessary equations for computing the geometry of the fibers are presented. Key Words: anisotropic shading techniques, <b>illumination</b> <b>model,</b> flat topology, varying topology is de...|$|R
40|$|For highly diffuse rendering, some {{materials}} {{like snow}} are commonly accomplished {{through the use}} of simplified local <b>illumination</b> <b>models</b> for ambient and diffuse light. In reality, however, for a given point on a surface, the incident light is not only contributed from directional light sources, but also from backscattering from nearby surfaces. To account for this effect, a new technology has been developed, using Curvature Maps for Rendering. This rendering algorithm integrates normal mapping with curvature mapping into a local <b>illumination</b> <b>model</b> to solve the previous mentioned problem. In this report, I will derive different measures to calculate curvature maps from normal maps and I evaluate their suitability for rendering...|$|R
40|$|In {{this paper}} {{we present a}} model-based {{algorithm}} for the estimation of three-dimensional motion parameters of an object moving in 3 D-space. Photometric e#ects {{are taken into account}} by adding di#erent <b>illumination</b> <b>models</b> to the virtual scene. Using the additional information from three-dimensional geometric models of the scene leads to linear algorithms for the parameter estimation of the <b>illumination</b> <b>models</b> which are all computationally e#cient. Experiments show that the Peak Signal Noise Ratio (PSNR) between camera and reconstructed synthetic images can be increased by up to 7 dB compared to global illumination compensation. The average estimation error of the motion parameters {{is at the same time}} reduced by 40 %...|$|R
40|$|This paper {{proposes a}} method to {{estimate}} the parameters of an <b>illumination</b> <b>model</b> and then uses these parameters for the synthesis of specular surface textures. We used the relationship between surface gradient maps in the frequency domain as a constraint for the separation of diffuse and specular components. During the estimation, we always keep errors between the real images and reconstructed images as small as possible. The estimated parameters form sample surface representation maps, which are then used as inputs for the synthesis of large representation maps. The synthesized representation maps are finally relit using the <b>illumination</b> <b>model</b> to produce new images under arbitrary illumination directions. 1...|$|R
40|$|This paper proposes an {{accurate}} <b>illumination</b> <b>model</b> for rendering objects coated with multilayer films. Optical phenomenaof multilayer films {{are caused by}} reflection, refraction, interference, and absorption of light inside each layer of multiple films, and these physical phenomena are complicatedly related with each other. The proposed method calculates composite reflectance and transmittance of multilayer films, taking into account all the physical phenomena described above, and visualizes the optical phenomena caused by the multilayer films accurately. The <b>illumination</b> <b>model</b> proposed in the paper can handle both smooth surface and locally smooth rough surfaces. Several examples of objects coated with various kinds of films demonstrate {{the usefulness of the}} proposed method. 1...|$|R
40|$|Aiming at detail {{enhancement}} {{in volume}} rendering, a new volume <b>illumination</b> <b>model,</b> called Composed Scattering Model (CSM), is presented. In order to enhance different details in data, scattering intensity is decomposed into volume scattering intensity and surface scattering intensity, and composed with boundary detection operators. CSM can generate images containing more details than current volume rendering models. This {{model has been}} applied to the direct volume rendering of 3 D data sets obtained by CT and MRT. The resultant iMages show not only rich details but also clear boundary surfaces. CSM is demonstrated as an accurate volume rendering model suited for detail enhancement in volume data set. Key Words: volume rendering, volume <b>illumination</b> <b>model,</b> ray casting algorith...|$|R
40|$|We {{capitalize}} on {{recent advances in}} modern programmable graphics hardware, originally designed to support advanced local <b>illumination</b> <b>models</b> for shading, to instead perform two di#erent kinds of global <b>illumination</b> <b>models</b> for light transport. We first use the new floating-point texture map formats to find matrix radiosity solutions for light transport in a di#use environment, and use this example to investigate the di#erences between GPU and CPU performance on matrix operations. We then examine multiple-scattering subsurface light transport, which can be modeled to resemble a single radiosity gathering step. We use a multiresolution meshed atlas to organize a hierarchy of precomputed subsurface links, and devise a three-pass GPU algorithm to render in real time the subsurface-scattered illumination of an object, with dynamic lighting and viewing...|$|R
40|$|This paper {{describes}} three {{alternative approaches}} to visualizing computational fluid dynam- ics (CFD) data. One new approach uses realistic volumetric gas rendering techniques to produce photo-realistic images and animations from CFD data. The second uses ray casting {{that is based}} on a simpler <b>illumination</b> <b>model</b> and is mainly centered around a versatile new tool for the design of transfer functions. The third method employs a simple <b>illumination</b> <b>model</b> and rapid rendering mechanisms to provide ecient preview capabilities. These tools provide a large range of rendering capabilities to be used by the CFD explorer to render rapidly for navigation through the data, to emphasize data features (e. g., shock waves) with a specific transfer function, or to present a realistic rendition of the model...|$|R
50|$|Blitters {{have been}} {{replaced}} by the modern graphics processing unit. GPUs are designed primarily for 3D graphics, and have added the ability to modify bitmaps in mathematically advanced ways, allowing arbitrary image transformations, texture decompression and filtering, shading for <b>illumination</b> <b>models,</b> alpha blend compositing operations, and depth-buffer comparison/update.|$|R
40|$|Abstract — We {{present in}} this paper a way to achieve {{positioning}} tasks by visual servoing under complex luminance variations. To do that, we use as visual features the luminance of all pixels in the image {{as we did in}} our previous work [4]. An important issue of this approach {{is that it does not}} rely at all on a any matching nor tracking process, contrary to all the approaches based on geometric visual features (points, straight lines, pose, homography, etc.). However, we consider {{in this paper}} a complete <b>illumination</b> <b>model</b> contrary to [4] where the temporal luminance constancy hypothesis was assumed. The main issue of this paper is thus the analytical computation of the interaction matrix related to the luminance from the Phong <b>illumination</b> <b>model.</b> Experimental results on specular objects validate our approach. I...|$|R
40|$|Natural {{illumination}} {{from the}} sun and sky plays {{a significant role in the}} appearance of outdoor scenes. We propose the use of sophisticated outdoor <b>illumination</b> <b>models,</b> developed in the computer graphics community, for estimating appearance and timestamps from a large set of uncalibrated images of an outdoor scene. We first present an analysis of the relationship between these <b>illumination</b> <b>models</b> and the geolocation, time, surface orientation, and local visibility at a scene point. We then use this relationship to devise a data-driven method for estimating per-point albedo and local visibility information from a set of Internet photos taken under varying, unknown illuminations. Our approach significantly extends prior work on appearance estimation to work with sun-sky models, and enables new applications, such as computing timestamps for individual photos using shading information. ...|$|R
40|$|People {{perceive}} smooth luminance variations {{as being}} {{due to the}} shading produced by surface undulations: shape-from-shading. To do this the visual system must simultaneously estimate {{the nature of the}} illumination and the shape of the surface. Shape-from- shading operates even when both these properties are unknown and neither can be estimated directly from the image. In such circumstances humans are thought to adopt a default <b>illumination</b> <b>model.</b> It is widely held that the default illuminant is a point source located above the observer's head, but some have argued that the default illuminant is a diffuse source. We present evidence that humans adopt an <b>illumination</b> <b>model</b> that includes both diffuse and directional (overhead) elements. This record was migrated from the OpenDepot repository service in June, 2017 before shutting down...|$|R
40|$|Bui-Tuong Phong {{published}} his <b>illumination</b> <b>model</b> in 1973, {{in the paper}} titled “Illumination for Computer-Generated Imagesi. Phong's model is a local <b>illumination</b> <b>model,</b> which means only direct reflections are taken into account. Light that bounces off more than one surface before reaching the eye is not accounted for. While {{this may not be}} very realistic, it allows the lighting to be computed efficiently. To properly handle indirect lighting, a global illumination method such as radiosity is required, which is much more expensive. In addition to Phong's basic lighting equation, we will look at a variation invented by Jim Blinn. Blinn changed the way specular is calculated, making the computations slightly cheaper. Blinn {{published his}} approach in his paper “Models of Light Reflection for Computer Synthesised Picturesi in 1977. ...|$|R
40|$|In this paper, {{we address}} the problem of face {{tracking}} across illumination changes and occlusions. The method is based on leveraging the strengths of both Adaboost to deal with clutter and the image based parametric <b>illumination</b> <b>model</b> proposed by Kale and Jaynes. We show that a simple non-linear transformation of the Adaboost score multiplied with the illumination compensated likelihood leads to a fast robust tracking paradigm. We demonstrate the ability of our method to detect occlusions at the same time ensuring that misassignments between the occluder and the occluded does not occur. We present experimental results of our method on low resolution surveillance indoor and outdoor videos using an off the shelf DSP. We also demonstrate the power of the parametric <b>illumination</b> <b>model</b> for pose constrained face recognition when matching across known illumination conditions. 1...|$|R
40|$|We develop or enhance hair {{modelling}} and rendering {{techniques to}} produce three {{different forms of}} hair commonly found in African hairstyles. The forms of hair are natural curly hair, straightened hair, and braids or twists of hair. We use an implicit model, implemented {{as a series of}} textured layers to represent curly hair. Straightened hair is represented explicitly, and modelled by defining and replicating a few control hairs. Braids and twists are implemented as textured generalized cylinders. A synthesis of existing hair <b>illumination</b> <b>models</b> is used as a basis for an African hair <b>illumination</b> <b>model.</b> Parameter values to match African hair characteristics are discussed. A number of complete African hairstyles are shown, demonstrating that the techniques can be used to model and render African hair successfully. <br /...|$|R
30|$|In {{the context}} of this work, the normal vectors to the curves and regions perform a role of great significance. The {{inference}} of a normal field to the image, make it possible for any <b>illuminations</b> <b>model</b> providing three-dimensional effects on the cartoon. The next section describes this attribute in detail.|$|R
