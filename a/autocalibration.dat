166|0|Public
5000|$|Manmohan Chandraker, Sameer Agarwal, David Kriegman, Serge Belongie: Globally Optimal Affine and Metric Upgrades in Stratified <b>Autocalibration</b> ...|$|E
5000|$|<b>Autocalibration</b> or self-calibration is the {{classical}} approach, in which camera motion and parameters are recovered first, using rigidity, then structure is readily calculated. Two methods implementing this idea {{are presented as}} follows: ...|$|E
5000|$|In December 2011 an {{entertainment}} center ATMASFERA 360 {{was founded on}} the basis of the planetarium. Specifications of the dome: diameter - 23 meters, the height of the dome - 11.5 meters. It is equipped with a modern 4k digital projection system supplied by Ukrainian company Front Pictures. The system uses 15 projectors which work on a single Screenberry media server. Due to digital <b>autocalibration</b> system the calibration process takes up to 15 minutes and includes all 5 stages: ...|$|E
50|$|Initially, Clark {{programmed}} {{the game}} to require the player to be relatively accurate to the music's beat, similar to the accuracy used by rhythm games. He found this timing to be too tense, as the player {{was more likely to}} miss the short accuracy window while stressed and would lead to the character being harmed, creating more stress on the player. Instead, he greatly expanded the accuracy window, as well as programmed a simple <b>autocalibration</b> system that recognized if the player was ahead or behind the beat to some degree as to match the player's current stress levels, both aimed to help make the game more fair and remove player frustration. Furthermore, he found that when he had the player move on the beat and monsters on the half-beat, the game played too closely to a roguelike and instead had all characters move on the beat, with the player's action having priority, which while posed a few drawbacks he had to program around, felt much more natural to the game.|$|E
40|$|We {{present the}} results on MDT (monitored drift tubes) <b>autocalibration</b> studies {{obtained}} from the analisys of the data collected in Summer 1995 on the H 8 B Muon Test Beam. In particular we studied the possibility of <b>autocalibration</b> of the MDT using four or three layers of tubes, and we compared the calibration obtained using a precise external tracker with {{the output of the}} <b>autocalibration</b> procedure. Results show the feasibility of <b>autocalibration</b> with four and three tubes and the good accuracy of the <b>autocalibration</b> procedure...|$|E
40|$|<b>Autocalibration</b> is a {{difficult}} problem. Not only is its computation very noisesensitive, but there also exist many critical motions that prevent the estimation {{of some of the}} camera parameters. When a "stratified" approach is considered, affine and Euclidean calibration are computed in separate steps and it is possible to see that a part of these ambiguities occur during affine-toEuclidean calibration. This paper studies the affine-to-Euclidean step in detail using the real Jordan decomposition of the infinite homography. It gives a new way to compute the <b>autocalibration</b> and analyzes the effects of critical motions on the computation of internal parameters. Finally, it shows that in some cases, it is possible to obtain complete calibration in the presence of critical motions. Keywords : <b>Autocalibration,</b> critical motions, real Jordan decomposition, affine calibration, infinite homography. 1 Introduction This article raises the problem of <b>autocalibration</b> of a camera undergoing rigid mo [...] ...|$|E
40|$|Accurate {{registration}} in an Augmented Reality system requires accurate trackers. An electronic compass can be {{a valuable}} sensor in an outdoor Augmented Reality system because it provides absolute heading estimates. However, compasses are vulnerable to distortion caused by environmental disturbances to Earth's magnetic field. These disturbances vary with geographic location and are not trivial to model. Static calibration methods exist but these require an explicit initial calibration step and do not adapt to changing distortion patterns. This paper describes in detail an <b>autocalibration</b> method that compensates for changing compass distortions. With minimal user input, it automatically measures and adjusts the calibration table used to correct the compass output. <b>Autocalibration</b> uses redundant heading information computed from rate gyroscopes We demonstrate that <b>autocalibration</b> converges to solutions similar to a distortion table that was manually measured with a mechanical turntable. With <b>autocalibration,</b> an electronic compass can provide usefid measurements even as the user walks around through areas of varying magnetic distortion...|$|E
40|$|Given a {{projective}} {{reconstruction of}} a 3 D scene, we {{address the problem}} of recovering the Euclidean structure of the scene in a recursive way. This leads to the application of Kalman filtering to the problem of camera <b>autocalibration</b> and to new algorithms for the <b>autocalibration</b> of cameras with varying parameters. This has benefits in saving memory and computational effort, and obtaining faster updates of the 3 D Euclidean structure of the scene under consideration...|$|E
40|$|The {{development}} of smart sensors involves {{the design of}} reconfigurable systemscapable of working with different input sensors. Reconfigurable systems ideally shouldspend the least possible {{amount of time in}} their calibration. An <b>autocalibration</b> algorithmfor intelligent sensors should be able to fix major problems such as offset, variation of gainand lack of linearity, as accurately as possible. This paper describes a new autocalibrationmethodology for nonlinear intelligent sensors based on artificial neural networks, ANN. The methodology involves analysis of several network topologies and training algorithms. The proposed method was compared against the piecewise and polynomial linearizationmethods. Method comparison was achieved using different number of calibration points,and several nonlinear levels of the input signal. This paper also shows that the proposedmethod turned out to have a better overall accuracy than the other two methods. Besides,experimentation results and analysis of the complete study, the paper describes theimplementation of the ANN in a microcontroller unit, MCU. In order to illustrate themethod capability to build <b>autocalibration</b> and reconfigurable systems, a temperaturemeasurement system was designed and tested. The proposed method is an improvement over the classic <b>autocalibration</b> methodologies, because it impacts on the design process of intelligent sensors, <b>autocalibration</b> methodologies and their associated factors, like time and cost...|$|E
40|$|Abstract. As it {{has been}} noted several times in literature, the {{difficult}} part of <b>autocalibration</b> efforts resides in the structural non-linearity {{of the search for}} the plane at infinity. In this paper we present a robust and versatile <b>autocalibration</b> method based on the enumeration of the inherently bounded space of the intrinsic parameters of two cameras in order to find the collineation of space that upgrades a given projective reconstruction to Euclidean. Each sample of the search space (which reduces to a finite subset of R 2 under mild assumptions) defines a consistent plane at infinity. This in turn produces a tentative, approximate Euclidean upgrade of the whole reconstruction which is then scored according to the expected intrinsic parameters of a Euclidean camera. This approach has been compared with several other algorithms on both synthetic and concrete cases, obtaining favourable results. Key words: <b>Autocalibration,</b> Self-calibration...|$|E
40|$|This paper {{describes}} a unified theory for <b>autocalibration</b> of a moving camera. The camera models can be 2 D projective, 2 D affine camera and 1 D projective projections. The scenes {{can be either}} non-planar scenes or planar scenes and the camera may also undergoes a pure rotation. All these cases are unified into the same framework based on the direction bases. Each formulation on the direction bases is also paralleled with that on projective geometry concepts, essentially encoded by {{the various forms of}} the absolute conic. This unification provides not only a common theoretical framework, but also suggests unified parameterisation schema for estimation procedures. 1 Introduction <b>Autocalibration</b> is the recovery of metric information from only point correspondences of uncalibrated images, using geometric self-consistency constraints. The potential advantages of <b>autocalibration</b> are a reduced need for off-line calibration and greater on-line flexibility. We will assume familiarity with the [...] ...|$|E
40|$|The {{three-dimensional}} (3 D) metric {{reconstruction of}} a scene from two-dimensional images is a fundamental problem in Computer Vision. The major bottleneck {{in the process of}} retrieving such structure lies in the task of recovering the camera parameters. These parameters can be calculated either through a pattern-based calibration procedure, which requires an accurate knowledge of the scene, or using a more flexible approach, known as camera <b>autocalibration,</b> which exploits point correspondences across images. While pattern-based calibration requires the presence of a calibration object, <b>autocalibration</b> constraints are often cast into nonlinear optimization problems which are often sensitive to both image noise and initialization. In addition, <b>autocalibration</b> fails for some particular motions of the camera. To overcome these problems, we propose to combine scene and <b>autocalibration</b> constraints and address in this thesis (a) the problem of extracting geometric information of the scene from uncalibrated images, (b) the problem of obtaining a robust estimate of the affine calibration of the camera, and (c) the problem of upgrading and refining the affine calibration into a metric one. In particular, we propose a method for identifying the major planar structures in a scene from images and another method to recognize parallel pairs of planes whenever these are available. The identified parallel planes are then used to obtain a robust estimate of both the affine and metric 3 D structure of the scene without resorting to the traditional error prone calculation of vanishing points. We also propose a refinement method which, unlike existing ones, is capable of simultaneously incorporating plane parallelism and perpendicularity constraints in the <b>autocalibration</b> process. Our experiments demonstrate that the proposed methods are robust to image noise and provide satisfactory results...|$|E
40|$|In {{this paper}} we discuss how Interval Analysis {{can be used to}} solve some {{problems}} in Computer Vision, namely <b>autocalibration</b> and triangulation. The crucial property of Interval Analysis is its ability to rigorously bound the range of a function over a given domain. This allows to propagate input errors with guaranteed results (used in multi-views triangulation) and to search for solution in non-linear minimisation problems with provably correct branch-and-bound algorithms (used in <b>autocalibration).</b> Experiments with real calibrated images illustrate the interval approach. Categories and Subject Descriptors (according to AC...|$|E
40|$|Abstract—In {{order to}} extract {{accurate}} 3 D models from uncalibrated image data {{it is necessary}} to upgrade the gen-erated projective reconstructions to a metric space, a process known as <b>autocalibration.</b> The key challenge associated with <b>autocalibration</b> is the nonlinear optimization of a cost func-tion based on extracting camera intrinsics from a potential upgrading transform, and evaluating fitness with respect to prior knowledge of physical cameras. The nonlinearity of the problem leads, in general, to poor convergence and a failure of the calibration process. This paper presents a novel <b>autocalibration</b> pipeline that seeks to develop a more robust approach to the nonlinear optimization. After testing a variety of methods, none of which yielded satisfactory solutions, we have developed a strategy combining the best aspects of two methods representing {{the current state of the}} art. The former method preconditions the projective space by transformation to a quasi-affine re-construction with respect to camera centers allowing a naive initialization in the new space, and uses a fitness measure resistant to focal length collapse. The latter method initializes using the best results of an exhaustive search over reasonable values of focal length. Our novel approach, presented here, uses the exhaustive search initialization of the latter combined with the improved fitness measure of the former, producing results that outperform both of its predecessors. Keywords- 3 D reconstruction, <b>autocalibration,</b> computer vi-sion I...|$|E
40|$|Estimation of {{the camera}} {{intrinsic}} calibration parameters is a prerequisite {{to a wide variety}} of vision tasks related to motion and stereo analysis. A major breakthrough related to the intrinsic calibration problem was the introduction in the early nineties of the <b>autocalibration</b> paradigm, according to which calibration is achieved not with the aid of a calibration pattern but by observing a number of image features in a set of successive images. Until recently, however, most research efforts have been focused on applying the <b>autocalibration</b> paradigm to estimating constant intrinsic calibration parameters. Therefore, such approaches are inapplicable to cases where the intrinsic parameters undergo continuous changes due to focusing and/or zooming. In this paper, our previous work for <b>autocalibration</b> in the case of constant camera intrinsic parameters is extended and a novel <b>autocalibration</b> method capable of handling variable intrinsic parameters is proposed. The method relies upon the Singular Value Decomposition of the fundamental matrix, which leads to a particularly simple form of the Kruppa equations. In contrast to the classical formulation that yields an over-determined system of constraints, a purely algebraic derivation is proposed here which provides a straightforward answer to the problem of determining which constraints to employ among the set of available ones. Additionally, the new formulation does not employ the epipoles, which are known to be difficult to estimate accurately. The intrinsic calibration parameters are recovered from th...|$|E
30|$|Calibration is {{the process}} of {{computing}} the intrinsic (internal) camera parameters from a series of images. Normally calibration is done by placing predefined targets in the scene or by having special camera motions, such as rotations. If these two restrictions do not hold, then this calibration process is called <b>autocalibration</b> because it is done automatically, without user intervention. Using <b>autocalibration,</b> it is possible to create 3 D reconstructions from a sequence of uncalibrated images without having to rely on a formal camera calibration process. The fundamental matrix describes the epipolar geometry between a pair of images, and it can be calculated directly from 2 D image correspondences. We show that <b>autocalibration</b> from a set of fundamental matrices can simply be transformed into a global minimization problem utilizing a cost function. We use a stochastic optimization approach taken from the field of evolutionary computing to solve this problem. A number of experiments are performed on published and standardized data sets that show the effectiveness of the approach. The basic assumption of this method is that the internal (intrinsic) camera parameters remain constant throughout the image sequence, that is, the images are taken from the same camera without varying such quantities as the focal length. We show that for the <b>autocalibration</b> of the focal length and aspect ratio, the evolutionary method achieves results comparable to published methods but is simpler to implement and is efficient enough to handle larger image sequences.|$|E
40|$|Abstract: :This paper {{presents}} an <b>autocalibration</b> method {{to determine the}} pose of a stereo vision system based on knowing the geometry of {{the ground in front}} of the cameras. This pose changes considerably while the vehicle is driven, therefore it is good to know constantly the pose of the camera for several applications based on computer vision, such as advanced driver assistance systems, autonomous vehicles or robotics. These constant changes of the pose make interesting to be able to detect constantly the variations in its extrinsic parameters (height, pitch, roll). The validation of the <b>autocalibration</b> method is accomplished by a visual odometry implementation. A study of the improvement of the results of the visual odometry estimation taking into account the changes of the camera pose is presented, demonstrating the advantages of the <b>autocalibration</b> method. This work was also supported by Spanish Government through the CICYT projects FEDORA (Grant TRA 2010 - 20255 -C 03 - 01) and Driver Distraction Detector System (Grant TRA 2011 - 29454 -C 03 - 02) ...|$|E
40|$|Many {{sophisticated}} high-resolution {{methods have}} been proposed. The study describes the practical experience in the combined application of superresolution and <b>autocalibration</b> methods for the resolution of multipath signals. An experimental linear array antenna {{has been used to}} perform superresolution after applying <b>autocalibration</b> to signals from one or several radiating sources, for example base stations for mobile communication. In case of multipath propagation, the line-of-sight signals are extracted by space-time processing. These line-of-sight signals are then used as a reference for blind channel estimation and are applied to obtain superresolution of sources and reflectors in azimuth and in differential delay. The suggested methods are tested with the real data...|$|E
30|$|The {{proposed}} method can {{be integrated}} with automated human detection methods to fully perform <b>autocalibration,</b> and this provides a useful avenue for future research. In addition, future research should introduce lens distortion parameters to a simplified camera model.|$|E
40|$|International audienceThis paper {{describes}} {{a method for}} autocalibrating a stereo rig. A planar object perfforming several general and unknown motions is observes by the stereo rig and, based on point correspondences only, the <b>autocalibration</b> of the stereo rig is computed. a stratified approach is used and the <b>autocalibration</b> is computed by estimating first the epipolar geometry of the rig, then the plane at infinity (affine calibration) and finally the absolute conic (Euclidean calibration). We show that the affine and Euclidean calibrations involve quadratic constraints and we describe an algorithm to solve them based on conic intersection. Experiments with both synthetic and real data are {{used to evaluate the}} performance of the method...|$|E
40|$|Many environments lack enough {{architectural}} {{information to}} allow an <b>autocalibration</b> based on features {{extracted from the}} scene structure. Nevertheless, the observation over time of walking people can generally be used to estimate the vertical vanishing point and the horizon line in the acquired image. However, this information {{is not enough to}} allow the calibration of a general camera without presuming excessive simplifications. This paper presents a study on the capabilities and limitations of the mono-camera calibration methods based solely on the knowledge of the vertical vanishing point and the horizon line in the image. The mathematical analysis sets the conditions to assure the feasibility of the mono-camera pedestrian-based <b>autocalibration.</b> In addition, examples of applications are presented and discusse...|$|E
40|$|We {{have built}} a full scale {{prototype}} of the precision tracking chambers (Monitored Drift Tubes, MDT) for the muon spectrometer of the Atlas Experiment at the LHC collider. This article describes in detail the procedures used in constructing the drift tubes and in assembling the chamber. It presents data showing that the required mechanical precision has been achieved as well as test beam results displaying the over all chamber performance. The article presents data demonstrating the derivation of the space-time relation of the drift tubes by the <b>autocalibration</b> procedure using real data from the tracks crossing the chamber. <b>Autocalibration</b> is the procedure which must be used during run time. (C) 1999 Elsevier Science B. V. All rights reserved...|$|E
40|$|Abstract: The {{development}} of smart sensors involves {{the design of}} reconfigurable systems capable of working with different input sensors. Reconfigurable systems ideally should spend the least possible {{amount of time in}} their calibration. An <b>autocalibration</b> algorithm for intelligent sensors should be able to fix major problems such as offset, variation of gain and lack of linearity, as accurately as possible. This paper describes a new <b>autocalibration</b> methodology for nonlinear intelligent sensors based on artificial neural networks, ANN. The methodology involves analysis of several network topologies and training algorithms. The proposed method was compared against the piecewise and polynomial linearization methods. Method comparison was achieved using different number of calibration points, and several nonlinear levels of the input signal. This paper also shows that the proposed method turned out to have a better overall accuracy than the other two methods. Besides, experimentation results and analysis of the complete study, the paper describes the implementation of the ANN in a microcontroller unit, MCU. In order to illustrate the method capability to build <b>autocalibration</b> and reconfigurable systems, a temperature measurement system was designed and tested. The proposed method is an improvemen...|$|E
40|$|We {{describe}} a new method of achieving <b>autocalibration</b> {{that uses a}} stochastic optimization approach taken {{from the field of}} evolutionary computing and we perform a number of experiments on standardized data sets that show the effectiveness of the approach. The basic assumption of this method is that the internal (intrinsic) camera parameters remain constant throughout the image sequence, i. e. they are taken from the same camera without varying the focal length. We show that for the <b>autocalibration</b> of focal length and aspect ratio, the evolutionary method achieves comparable results without the implementation complexity of other methods. Autocalibrating from the fundamental matrix is simply transformed into a global minimization problem utilizing a cost function based on the properties of the fundamental matrix and the essential matrix...|$|E
40|$|We present new {{results on}} the Absolute Line Quadric (ALQ), the {{geometric}} object representing the set of lines that intersect the absolute conic. We include new techniques for the obtainment of the Euclidean structure that lead to an efficient algorithm for the <b>autocalibration</b> of cameras with varying parameters...|$|E
40|$|We {{address the}} problem of <b>autocalibration</b> of a moving camera with unknown {{constant}} intrinsic parameters. Existing <b>autocalibration</b> techniques use numerical optimization algorithms whose convergence to the correct result cannot be guaranteed, in general. To address this problem, we have developed a method where an interval branch-and-bound method is employed for numerical minimization. Thanks to the properties of Interval Analysis this method converges to the global solution with mathematical certainty and arbitrary accuracy and the only input information it requires from the user are a set of point correspondences and a search interval. The cost function is based on the Huang-Faugeras constraint of the essential matrix. A recently proposed interval extension based on Bernstein polynomial forms has been investigated to speed up the search for the solution. Finally, experimental results are presented...|$|E
40|$|As it {{has been}} noted several times in literature, the {{difficult}} part of <b>autocalibration</b> efforts resides in the structural non-linearity {{of the search for}} the plane at infinity. In this paper we present a robust and versatile <b>autocalibration</b> method based on the enumeration of the inherently bounded space of the intrinsic parameters of two cameras in order to find the collineation of space that upgrades a given projective reconstruction to Euclidean. Each sample of the search space (which reduces to a finite subset of ℝ 2 under mild assumptions) defines a consistent plane at infinity. This in turn produces a tentative, approximate Euclidean upgrade of the whole reconstruction which is then scored according to the expected intrinsic parameters of a Euclidean camera. This approach has been compared with several other algorithms on both synthetic and concrete cases, obtaining favourable results...|$|E
40|$|This paper {{provides}} a review on techniques for computing a three-dimensional {{model of a}} scene from a single moving camera, with unconstrained motion and unknown parameters. In the classical approach, called <b>autocalibration</b> or self-calibration, camera motion and parameters are recovered first, using rigidity; then structure is easily computed. Recently, new methods {{based on the idea}} of stratification have been proposed. They upgrade the projective structure, achievable from correspondences only, to the Euclidean structure, by exploiting all the available constraints. Key words: 3 D vision, <b>Autocalibration,</b> Euclidean reconstruction, Self-calibration, Uncalibrated cameras. 1 Introduction The goal of Computer Vision (see [1] for an introduction) is to compute properties (mainly geometric) of the three-dimensional world from images. One of the challenging problems of Computer Vision is to reconstruct a three-dimensional model of the scene from a moving camera. Possible applications include [...] ...|$|E
40|$|The aim of <b>autocalibration</b> is {{to compute}} the {{internal}} parameters, starting from weakly calibrated cameras. More in general, the task is to recover metric properties of camera and/or scene, i. e., to compute a Euclidean reconstruction. There are two classes of methods: 1. Direct: solve directly for the internal parameters. 2. Stratified: first obtain a projective reconstruction and then transform it to a Euclidean reconstruction (in some cases an affine reconstruction is obtained in between). The reader is referred to [8] {{for a review of}} <b>autocalibration,</b> and to [33, 46, 21, 36, 35, 11] for classical and recent work on the subject. 6. 1 Counting argument 93 Consider m cameras. The difference between the d. o. f. of the multifocal geometry (e. g. 7 for two views) and the d. o. f. of the rigid displacements (e. g. 5 for tw...|$|E
40|$|The main {{objective}} of this thesis is presentation of various features of technical diagnostics, such as autodiagnostics and <b>autocalibration.</b> Thesis describes ways to diagnostics of rotocure, presents various types of sensors used in vibrodiagnostics and shows possibilities for their calibration. This work also contains information about automatic calibration of external influences, which affect sensor characteristics...|$|E
40|$|The present {{paper is}} a short {{explanation}} related to what happen in ultrasonic calibration process. The material velocity and zero offset functions are related with the two known distance peaks classical requirement for setup. The <b>autocalibration</b> function is also explored and explained. The aim is to help beginners to understand the foundations of ultrasonic setup. 1...|$|E
40|$|The {{calibration}} of the space-time relationship r(t) of the Monitored Drift Tube Chambers in ATLAS {{will have}} to be done with the chambers' own data because no external reference detector will be available. Techniques for this so-called ``autocalibration'' have been worked on {{since the early days of}} ATLAS preparation. It is a known problem that speed and precision of <b>autocalibration</b> convergence depend crucially on the range of track incidence angles. This note presents an algebraic approach to this dependence. We shall investigate under which conditions <b>autocalibration</b> has enough information to determine the r-t relationship uniquely. A new technical realization will be introduced which is designed for making optimal use of all available information. Finally we determine the spread of track incidence angles for each ATLAS MDT chamber, and discuss the achievable calibration precision. Our calculations are based on the detector response for the gas Ar/CO$_{ 2 }$ (93 / 7) ...|$|E
40|$|<b>Autocalibration</b> of MDT {{chambers}} {{requires a}} good start-value for the space-time relationship. This note presents two improvements on the "Integration Method": the first corrects for δ-rays, the second also {{takes into account}} resolution and efficiency effects. Both methods use only the drift-time spectrum. The new methods improve the rms error from 345 μm to 80 μm and 18 μm respectively...|$|E
40|$|This paper {{describes}} a theory and a practical algorithm for the <b>autocalibration</b> of a moving projective camera, from m 5 {{views of a}} planar scene. The unknown camera calibration, and (up to scale) the unknown scene geometry and camera motion are recovered from {{the hypothesis that the}} camera's internal parameters remain constant during the motion. This work extends the various existing methods for non-planar <b>autocalibration</b> to a practically common situation in which {{it is not possible to}} bootstrap the calibration from an intermediate projective reconstruction. It also extends Hartley's method for the internal calibration of a rotating camera, to allow camera translation and to provide 3 D as well as calibration information. The basic constraint is that the projections of orthogonal direction vectors (points at infinity) in the plane must be orthogonal in the calibrated camera frame of each image. Abstractly, since the two circular points of the 3 D plane (representing its Euclidean structu [...] ...|$|E
40|$|Università degli studi di Verona We {{address the}} problem of <b>autocalibration</b> of a moving camera with unknown {{constant}} intrinsic parameters. Existing <b>autocalibration</b> techniques use numerical optimization algorithms whose convergence to the correct result cannot be guaranteed, in general. To address this problem, we have developed a method where an interval branchand-bound method is employed for numerical minimization. Thanks to the properties of Interval Analysis this method converges to the global solution with mathematical certainty and arbitrary accuracy, and the only input information it requires from the user are a set of point correspondences and a search box. The cost function is based on the Huang-Faugeras constraint of the fundamental matrix, and a closed form expression for its Jacobian and Hessian matrices is derived through matrix differential calculus. A recently proposed interval extension based on Bernstein polynomial forms has been investigated to speed up the search for the solution. Finally, experimental results on synthetic and real images are presented...|$|E
40|$|Abstract—This paper {{presents}} {{a method for}} fully automatic and robust estimation of two-view geometry, <b>autocalibration,</b> and 3 D metric reconstruction from point correspondences in images taken by cameras with wide circular field of view. We focus on cameras which have more than 180 field of view and for which the standard perspective camera model is not sufficient, e. g., the cameras equipped with circular fish-eye lenses Nikon FC-E 8 (183), Sigma 8 mm-f 4 -EX (180), or with curved conical mirrors. We assume a circular field of view and axially symmetric image projection to autocalibrate the cameras. Many wide field of view cameras can still be modeled by the central projection followed by a nonlinear image mapping. Examples are the above-mentioned fish-eye lenses and properly assembled catadioptric cameras with conical mirrors. We show that epipolar geometry of these cameras can be estimated from {{a small number of}} correspondences by solving a polynomial eigenvalue problem. This allows the use of efficient RANSAC robust estimation to find the image projection model, the epipolar geometry, and the selection of true point correspondences from tentative correspondences contaminated by mismatches. Real catadioptric cameras are often slightly noncentral. We show that the proposed <b>autocalibration</b> with approximate central models is usually good enough to get correct point correspondences which can be used with accurate noncentral models in a bundle adjustment to obtain accurate 3 D scene reconstruction. Noncentral camera models are dealt with and results are shown for catadioptric cameras with parabolic and spherical mirrors. Index Terms—Omnidirectional vision, fish-eye lens, catadioptric camera, <b>autocalibration.</b> ...|$|E
