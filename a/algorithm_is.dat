10000|10000|Public
5|$|Although the Euclidean <b>algorithm</b> <b>is</b> used to {{find the}} {{greatest}} common divisor of two natural numbers (positive integers), it may be generalized to the real numbers, and to other mathematical objects, such as polynomials, quadratic integers and Hurwitz quaternions. In the latter cases, the Euclidean <b>algorithm</b> <b>is</b> used to demonstrate the crucial property of unique factorization, i.e., that such numbers can be factored uniquely into irreducible elements, the counterparts of prime numbers. Unique factorization is essential to many proofs of number theory.|$|E
5|$|Euclid's <b>algorithm</b> <b>is</b> {{widely used}} in practice, {{especially}} for small numbers, due to its simplicity. For comparison, the efficiency of alternatives to Euclid's algorithm may be determined.|$|E
5|$|The Euclidean <b>algorithm</b> <b>is</b> one of {{the oldest}} {{algorithms}} in common use. It appears in Euclid's Elements (c. 300 BC), specifically in Book 7 (Propositions 1–2) and Book 10 (Propositions 2–3). In Book 7, the <b>algorithm</b> <b>is</b> formulated for integers, whereas in Book 10, it is formulated for lengths of line segments. (In modern usage, one would say it was formulated there for real numbers. But lengths, areas, and volumes, represented as real numbers in modern usage, are not measured in the same units and there is no natural unit of length, area, or volume; the concept of real numbers was unknown at that time.) The latter <b>algorithm</b> <b>is</b> geometrical. The GCD of two lengths a and b corresponds to the greatest length g that measures a and b evenly; in other words, the lengths a and b are both integer multiples of the length g.|$|E
50|$|Two {{other common}} classes of {{probabilistic}} <b>algorithms</b> <b>are</b> Monte Carlo <b>algorithms</b> and Las Vegas algorithms. Monte Carlo <b>algorithms</b> <b>are</b> always fast, but only probably correct. On the other hand, Las Vegas <b>algorithms</b> <b>are</b> always correct, but only probably fast. The Atlantic City <b>algorithms</b> which <b>are</b> bounded probabilistic polynomial time <b>algorithms</b> <b>are</b> probably correct and probably fast.|$|R
40|$|Discrete-time {{symmetric}} polynomial equations {{with complex}} coefficients are {{studied in the}} scalar and matrix case. New theoretical results are derived and several <b>algorithms</b> <b>are</b> proposed and evaluated. Polynomial reduction <b>algorithms</b> <b>are</b> first described to study theoretical properties of the equations. Sylvester matrix <b>algorithms</b> <b>are</b> then developed to solve numerically the equations. The <b>algorithms</b> <b>are</b> implemented in the Polynomial Toolbox for MATLAB. 1...|$|R
40|$|Abstract. Several {{algorithms}} {{that generate}} {{the set of}} all formal concepts and diagram graphs of concept lattices are considered. Some modifications of wellknown <b>algorithms</b> <b>are</b> proposed. Algorithmic complexity of the <b>algorithms</b> <b>is</b> studied both theoretically (in the worst case) and experimentally. Conditions of preferable use of some <b>algorithms</b> <b>are</b> given in terms of density/sparseness of underlying formal contexts. Principles of comparing practical performance of <b>algorithms</b> <b>are</b> discussed. ...|$|R
5|$|The {{bottleneck}} of this greedy <b>algorithm</b> <b>is</b> the subproblem {{of finding}} which two clusters to merge in each step.|$|E
25|$|In big O notation, the brute-force <b>algorithm</b> <b>is</b> O(n) and the {{efficient}} <b>algorithm</b> <b>is</b> O(1) (assuming constant time arithmetic operations).|$|E
25|$|Usually the baby-step giant-step <b>algorithm</b> <b>is</b> {{used for}} groups whose order is prime. If {{the order of}} the group is {{composite}} then the Pohlig–Hellman <b>algorithm</b> <b>is</b> more efficient.|$|E
40|$|Several SOR-like <b>algorithms</b> <b>are</b> {{proposed}} for solving augmented systems which {{have appeared in}} many different applications of scientific computing, for example, constrained optimization and the finite element approximation for solving the Stokes equation. The convergence and the choice of optimal parameter for these <b>algorithms</b> <b>are</b> studied. The convergence and divergence regions for some <b>algorithms</b> <b>are</b> given, and the new <b>algorithms</b> <b>are</b> applied to solve the approximation to Stokes equations as well...|$|R
30|$|Dijkstra’s and A* <b>algorithms</b> <b>were</b> {{executed}} on {{the original}} graphs and the proposed <b>algorithm</b> <b>was</b> applied to the reduced ones. Each <b>algorithm</b> <b>was</b> executed 10 times; the highest and lowest values were discarded. Finally, the average time among the remaining 8 values are shown.|$|R
40|$|Effective pathfinding {{algorithm}} {{based on}} Theta* and Hybrid A* <b>algorithms</b> <b>was</b> developed for four-wheeled robot. Pseudocode for <b>algorithm</b> <b>was</b> showed and explained. Algorithm and simulator for four-wheeled robot were implemented using Java programming language. <b>Algorithm</b> <b>was</b> tested on U-obstacles, complex maps and for parking problem </p...|$|R
25|$|Of course, this <b>algorithm</b> <b>is</b> {{not useful}} for actual multiplication. This <b>algorithm</b> <b>is</b> just a {{user-friendly}} {{way to see}} what the result looks like.|$|E
25|$|A {{distributed}} {{variant of}} the Bellman–Ford <b>algorithm</b> <b>is</b> used in distance-vector routing protocols, for example the Routing Information Protocol (RIP). The <b>algorithm</b> <b>is</b> distributed because it involves a number of nodes (routers) within an Autonomous system, a collection of IP networks typically owned by an ISP.|$|E
25|$|This <b>algorithm</b> <b>is</b> {{a form of}} radix sort.|$|E
40|$|Natural {{computing}} {{elements are}} presented. Data mining <b>algorithms</b> <b>are</b> discussed and quality {{characteristics of the}} <b>algorithms</b> <b>are</b> analyzed. Than domains of application for the data mining <b>algorithms</b> <b>are</b> shown. Experimental results are obtained using the simulation application NetLogo through a custom path finding algorithm. natural computing, data mining, optimization. ...|$|R
40|$|In this paper, Swendsen-Wang-Wolff <b>algorithms</b> <b>are</b> {{extended}} to simulate spatial point processes with symmetric and stationary interactions. Convergence of these <b>algorithms</b> <b>are</b> considered. Some further generalizations of the <b>algorithms</b> <b>are</b> discussed. The ideas {{presented in this}} paper can also be useful in handling some large and complicated systems...|$|R
5000|$|The set of <b>algorithms</b> <b>is</b> not complete: for example, the [...] <b>algorithm</b> <b>was</b> left out, {{though it}} has been added in C++11.|$|R
25|$|The CORDIC <b>algorithm</b> <b>is</b> {{commonly}} used in scientific calculators.|$|E
25|$|The <b>algorithm</b> <b>is</b> run in phases. Each phase {{consists}} of the following steps.|$|E
25|$|The {{complexity}} of an <b>algorithm</b> <b>is</b> often expressed using big O notation.|$|E
40|$|The {{analysis}} and the incorporation into a multigrid scheme of several vectorizable <b>algorithms</b> <b>are</b> discussed. von Neumann analyses of vertical-line, horizontal-line, and alternating-direction ZEBRA <b>algorithms</b> <b>were</b> performed; {{and the results}} were used to predict their multigrid damping rates. The <b>algorithms</b> <b>were</b> then successfully implemented in a transonic conservative full-potential computer program. The convergence acceleration effect of multiple grids is shown, and the convergence rates of the vectorizable <b>algorithms</b> <b>are</b> compared with those of standard successive-line overrelaxation (SLOR) algorithms...|$|R
40|$|Efficient <b>algorithms</b> <b>are</b> {{described}} for matrix multiplication on SIMD computers. SIMD implementations of Winograd’s <b>algorithm</b> <b>are</b> {{considered in the}} case where additions are faster than multiplications. Classical kernels {{and the use of}} Strassen’s <b>algorithm</b> <b>are</b> also considered. Actual performance figures using the MasPar family of SIMD computers are presented and discussed...|$|R
5000|$|The SMS4 <b>algorithm</b> <b>was</b> {{invented by}} Prof. LU Shu-wang(吕述望). The <b>algorithm</b> <b>was</b> declassified in January, 2006. A few {{details of the}} SMS4 cipher are: ...|$|R
25|$|An <b>algorithm</b> <b>is</b> {{said to be}} {{exponential}} time, if T(n) is upper {{bounded by}} 2poly(n), where poly(n) is some polynomial in n. More formally, an <b>algorithm</b> <b>is</b> exponential time if T(n) is bounded by O(2n'k) for some constant k. Problems which admit exponential time algorithms on a deterministic Turing machine form the complexity class known as EXP.|$|E
25|$|An <b>algorithm</b> <b>is</b> {{said to be}} subquadratic time if T(n) = o(n2).|$|E
25|$|The baby-step giant-step <b>algorithm</b> <b>is</b> {{a generic}} algorithm. It works for every finite cyclic group.|$|E
30|$|Two {{critical}} point aware data acquisition <b>algorithms</b> <b>are</b> proposed based on numerical analysis [27] and Lagrange interpolation [28] techniques. The algorithms can adjust the sampling {{frequency of the}} sensors automatically according to variation of the physical world. The correctness of the <b>algorithms</b> <b>is</b> proved and {{the complexities of the}} <b>algorithms</b> <b>are</b> analyzed.|$|R
40|$|Abstract. Recently concept lattices became {{widely used}} tools for {{intelligent}} data analysis. In this paper, several algorithms that generate {{the set of}} all formal concepts and diagram graphs of concept lattices are considered. Some modifications of wellknown <b>algorithms</b> <b>are</b> proposed. Algorithmic complexity of the <b>algorithms</b> <b>is</b> studied both theoretically (in the worst case) and experimentally. Conditions of preferable use of some <b>algorithms</b> <b>are</b> given in terms of density/sparseness of underlying formal contexts. Principles of comparing practical performance of <b>algorithms</b> <b>are</b> discussed. 1...|$|R
50|$|Some <b>algorithms</b> <b>are</b> useful {{only when}} the {{characteristic}} data are molecular (DNA, RNA); other <b>algorithms</b> <b>are</b> useful {{only when the}} characteristic data <b>are</b> morphological. Other <b>algorithms</b> can <b>be</b> used when the characteristic data includes both molecular and morphological data.|$|R
25|$|This <b>algorithm</b> <b>is</b> efficient, and has {{running time}} O(C3) where C {{is the number}} of candidates.|$|E
25|$|The ACO <b>algorithm</b> <b>is</b> used in image {{processing}} for image edge detection and edge linking.|$|E
25|$|The BHHH <b>algorithm</b> <b>is</b> a {{non-linear}} {{optimization algorithm}} that is popular for Maximum Likelihood estimations.|$|E
30|$|Through {{mathematical}} Example (1), the step-by-step {{procedures of}} the proposed <b>algorithm</b> <b>are</b> described and, at each step, {{the details of the}} identification <b>algorithm</b> <b>are</b> stated.|$|R
30|$|Two {{variations}} of the greedy <b>algorithm</b> <b>are</b> presented and implemented in NS 3. Those <b>algorithms</b> <b>are</b> compared with maximum fairness (MF) and round-robin (RR) algorithms.|$|R
30|$|In this paper, we {{extend the}} {{approach}} in [21] to the APA, SPU-NLMS, SPU-APA, and SR-APA and four novel VSS adaptive filter <b>algorithms</b> <b>are</b> established. These <b>algorithms</b> <b>are</b> computationally efficient. We demonstrate the good {{performance of the}} presented algorithms through several simulation results in system identification scenario. The comparison of the proposed algorithms with other <b>algorithms</b> <b>is</b> also presented.|$|R
