0|10000|Public
40|$|The {{main object}} {{of this paper}} is to {{describe}} a Decision Support System for an automatic classification of complaints as received by users via Internet. We propose a System that uses two separate sub-systems. The first sub-system produces the creation of a reference database with the "most frequent complaints”. The second subsystem, by means of an original <b>Algorithm,</b> <b>is</b> <b>devoted</b> to classifying complaints...|$|R
40|$|Nowadays, {{thanks to}} {{advances}} in information and power technology induction motors are deployed there, where previously only {{other types of}} electric motors were possible to use. Those typically lack the reliability and low cost of induction motors. Best results in control of induction motors are achieved when vector control is used, to which {{part of the work}} is paid. If induction motor reaches the speed when it is no longer possible to continue to increase stator voltage, there is possibility of field weakening or reduction of magnetic flux and thus achieve higher speed. A comparison of several <b>algorithms</b> <b>is</b> <b>devoted</b> to this work. As a simulation tool MATLAB-Simulink was used. Another part <b>is</b> <b>devoted</b> to implementation of these algorithms to the processor of 56 F 800 E series which uses calculations in fixed point...|$|R
30|$|In other words, our <b>algorithm</b> has <b>been</b> {{designed}} {{having in}} mind the way a human would manually detect wave activity by looking at a wavelet spectra; namely, by looking for portions of the wavelet spectrum where wavelet power appears to be significantly {{higher than in the}} surrounding and the frequency around which the enhancement in wavelet power is centred varies with time in some regular way. Nonetheless, both step changes and spikes present in the magnetic field time series are transformed during filtering, which results in a characteristic pattern of a damped sinusoidal oscillation of varying frequency. A significant part of the <b>algorithm</b> <b>is</b> <b>devoted</b> to detecting exactly these features in the wavelet power spectrum and classify them as a “False Positive” signal.|$|R
3000|$|... and {{propose a}} new {{iterative}} <b>algorithm.</b> Section  3 <b>is</b> <b>devoted</b> to {{the proof of}} its global convergence and also show {{the relation between the}} solution set of [...]...|$|R
40|$|Spatial {{co-location}} patterns {{represent the}} subsets of events whose instances are frequently located together in geographic space. We identified the computational bottleneck in the execution {{time of a}} current co-location mining algorithm. A large fraction of the join-based co-location miner <b>algorithm</b> <b>is</b> <b>devoted</b> to computing joins to identify instances of candidate co-location patterns. We propose a novel partialjoin approach for mining co-location patterns efficiently. It transactionizes continuous spatial data while {{keeping track of the}} spatial information not modeled by transactions. It uses a transaction-based Apriori algorithm as a building block and adopts the instance join method for residual instances not identified in transactions. We show that the <b>algorithm</b> <b>is</b> correct and complete in finding all co-location rules which have prevalence and conditional probability above the given thresholds. An experimental evaluation using synthetic datasets and a real dataset shows that our <b>algorithm</b> <b>is</b> computationally more efficient than the join-based algorithm...|$|R
40|$|Abstract — The {{approximation}} of humanoid robot by an inverted pendulum {{is one of}} the most used model to generate a stable walking motion. Many studies have been carried out to improve the reliability of this model. One of the proposed models is the quadratic system model, which has been validated by conducting real experiments on the humanoid robot. In this paper, we propose several controlling algorithms for the quadratic system. Some of these <b>algorithms</b> <b>are</b> <b>devoted</b> for on-line and off-line walking pattern generation algorithms for the humanoid robot. Dynamically stable walking patterns have been generated in order to validate these algorithms. The stability and feasibility of walking patterns have been confirmed using dynamical simulation and conducting real experiments on the humanoid robot HRP- 4 C. Index Terms — Humanoid robot; ZMP control; Optimization; Nonlinear system control...|$|R
40|$|In this paper, we {{introduce}} {{two different}} {{contributions to the}} efforts of IEEE 802. 14 Working Group in order to define a common background for broadband/multimedia residential services based on HFC (Hybrid Fiber Coax) access networks. Nowadays, the best positioned proposals of MAC protocols to be used by IEEE 802. 14 could be those based on n-ary tree-based contention resolution algorithms, such as described in [2, 3, 6]. Our first contribution is the description of a new implementation of the XDQRAP (eXtended Distributed Queuing Random Access Protocol) MAC protocol that operates in a slot basis with interleaving. We show that its performance for the access delay and throughput is better than the results presented in [6]. Our second contribution, not depending of the contention <b>algorithm,</b> <b>is</b> <b>devoted</b> to investigate the feasibility of Constant Bit Rate (CBR) services over HFC networks in an ATM environment. We analyze the cell delay variation time for different slot allocat [...] ...|$|R
30|$|The rest of {{the paper}} is {{organized}} as follows. First, we discuss related work in Section 2. In Section 3, we present our solution and give its detailed <b>algorithms.</b> Section 4 <b>is</b> <b>devoted</b> to an analysis and a simulation of the proposed solution. Section 5 concludes our work.|$|R
40|$|Abstract—The {{cryptography}} is nowadays {{applied to}} almost all information systems- from Internet up to databases. Swindle {{attempts are made}} and legality of financial transactions is provided by means of cryptographic <b>algorithms.</b> This paper <b>is</b> <b>devoted</b> to an <b>algorithm</b> based on the wavelet decomposition of B-splines of the second degree on a non-uniform grid. Keywords: B-splines, non-uniform grid, formulas of decomposition and reconstruction...|$|R
40|$|Abstract: This paper {{focuses on}} a new Wireless LAN {{developed}} {{in the framework of}} the WIND-FLEX project, sponsored by the European IST program. Medium Access Control and Dynamic Link Control protocols are described with respect to their functionalities and the implemented algorithms. The main emphasis is on the Connection Admission Control <b>algorithm,</b> which <b>is</b> <b>devoted</b> to guarantee the preventive control of the supported traffic. A low-cost estimate of the so-called Effective Bandwidth (or bandwidth requirement) of multiplexed connections is proposed, based on statistical characteristic and the Quality of Service requirements of traffic applications. Results of computer simulations are presented to analyze the performance of the proposed algorithm...|$|R
40|$|International {{audience}} Integer Linear Programming (ILP) solvers made recent {{progress with}} heuristics {{based on the}} linear relaxation and variable fixing. On one hand, it allowes to cut off earlier branches of the Branch&Bound tree, and on an other hand, very good solutions are found quickly, that allowes to uses an ILP solver in a heuristic mode with a time limit. Most of the resolution time in a Branch& Bound <b>algorithm</b> <b>is</b> <b>devoted</b> to prove the optimality of the solution. Local search heuristics improve a given solution, with modification allowed in a defined neighbourhood. Difficulties come with local extrema, where no local improvement is possible. Variable Neighbourhood Search (VNS) basic idea is to consider different types of neighbourhoods, and to change systematicaly of neighbourhood within a local search, to have less local extrema. A VNS local extremum is thus is local extremum for all considered neighbourhoods. This paper shows how an ILP solver in a heuristic mode can be very useful and effective in a VNS scheme, considering for neighbourhoods small Integer Linear Programs. This <b>algorithm</b> can naturally <b>be</b> parallelized. These concepts are applied on short term Unit Commitment Problems with discrete dynamic constraints, long term scheduling of nuclear power plants and to the classical Vehicle Routing Problem with Time Windows. For these applications, solutions found with an ILP formulation in a defined time limit were imprioved with our VNS scheme. </p...|$|R
40|$|This thesis {{addresses}} {{the problem of}} defect detection on complex textural surfaces. In general, whether the texture to be inspected is regular or random, in image terms it is characterized by local variations in pixel grey level values. These normal variations render the problem of texture defect detection extremely difficult as defects are often manifested by grey level changes and their detection requires more than mere pixel comparisons. In the thesis, classical techniques on texture representation are studied and various existing texture defect detection <b>algorithms</b> <b>are</b> reviewed. Three novel <b>algorithms</b> have <b>been</b> developed to tackle the problem of defect detection on random or regular textures. The first two <b>are</b> <b>devoted</b> {{to the problem of}} crack detection and the third <b>algorithm</b> <b>is</b> <b>devoted</b> to the problem of detecting regional defects. For texture crack detection, a cojoint spatial and spatial frequency representation, that is, wigner distribution is proposed to model the inspected texture surface. A detailed analysis of the wigner distribution, its properties and the effect of windowing on its crack detection performance are carried out. Two postprocessing methods, ie, probabilistic relaxation labelling and linear filtering are incorporated into the crack detection algorithm to refine the results. The potential of the Wigner model has also been explored by modifying the crack detection algorithm so as to detect other types of defects. For real world applications, an efficient crack detection algorithm based on a new distribution <b>is</b> proposed. The <b>algorithm</b> <b>is</b> shown to produce comparable results but in much shorter time. For regional defect detection, a hybrid chromato-structural approach to colour texture representation is proposed where combined colour texture information is extracted from various chromatic classes associated with the inspected surface. In the approach, a unified defect detection framework which combines a new colour clustering scheme, morphological smoothing and blob analysis are used to capture the relevant combined colour texture information. With this framework, good defect detection results are obtained and presented in this thesis...|$|R
40|$|This paper {{presents}} a region-based coding algorithm for video sequences. The coding approach involves a time-recursive segmentation {{relying on the}} pixels homogeneity, a region-based motion estimation, and motion compensated contour and texture coding. This <b>algorithm</b> <b>is</b> mainly <b>devoted</b> to very low bit rate video coding applications. One of the important features of the approach is that no assumption is made about the sequence content. Moreover the algorithm structure leads to a scalable coding process giving various levels of quality and bit rates. The coding {{as well as the}} segmentation are controlled to regulate the bit stream. Finally, the interest of morphological tools in the content of region-based coding is extensively reviewed. Peer ReviewedPostprint (published version...|$|R
40|$|AUC is an {{important}} performance measure and many <b>algorithms</b> have <b>been</b> <b>devoted</b> to AUC optimization, mostly by minimizing a surrogate convex loss on a training data set. In this work, we focus on one-pass AUC optimization that requires going through the training data only once without storing the entire training dataset, where conventional online learning <b>algorithms</b> cannot <b>be</b> applied directly because AUC is measured by a sum of losses defined over pairs of instances from different classes. We develop a regressionbased algorithm which only needs to maintain the first and second-order statistics of training data in memory, resulting a storage requirement independent from the size of training data. To efficiently handle highdimensional data, we develop a randomized algorithm that approximates the covariance matrices by low-rank matrices. We verify, both theoretically and empirically, {{the effectiveness of the}} proposed algorithm...|$|R
40|$|Development {{of plant}} embryo {{beginning}} {{from the very}} early stages is not fully studied yet. For example, detailed description of dynamics of cellular composition of embryo, and the cells growth are unknown. Herein we propose a quantitative description of the early Arabidopsis thaliana development. The description is quantitative with respect to cell shapes, division planes, dynamics though time lapse data are not available. We have designed three algorithms. The first one <b>is</b> <b>devoted</b> to 3 D reconstruction from stacks of confocal images. The second algorithm builds a tree representation of the embryo. Each node of the tree corresponds {{to a set of}} related cells and each branch points towards a daughter cell. This representation is based on topological and geometrical rules applied on the 3 D reconstructions. The third <b>algorithm</b> <b>is</b> <b>devoted</b> to embryos comparisons. Considering two embryos at different stages of development and their associated tree representations we propose to plug the younger embryo inside the older one. This is realized by tree explorations from the root. Results: 3 D geometrical models of early stages of Arabidopsis embry development were constructed in meshes representation. Different features such as volumes, neighboring structure have been computed. For several embryos, the history of divisions has been reconstructed. Growth rates could be inferred from the plug-in of embryos. Conlusion: From a collection of Arabidopsis embryos observed iconfocal microscopy quantitative data such as volumes can be analyzed. Despite the fact that no time lapse is available dynamics information could be inferred. At least several rounds of divisions can be guess. Of course variability should be addressed and the plug-in algorithm we propose can be helpful. The 4 D information we got can now be used for designing models for biomechanics and transport phenomena evaluation during early plant embryo development...|$|R
40|$|Face {{recognition}} is a challenging problem in computer vision. Difficulties such as slight differences between similar faces of different people, changes in facial expressions, light and illumination condition, and pose variations add extra complications {{to the face}} recognition research. Many <b>algorithms</b> <b>are</b> <b>devoted</b> to solving the face recognition problem, among which the family of nonnegative matrix factorization (NMF) <b>algorithms</b> has <b>been</b> widely used as a compact data representation method. Different versions of NMF have been proposed. Wang et al. proposed the graph-based semi-supervised nonnegative learning (S 2 N 2 L) algorithm that uses labeled data in constructing intrinsic and penalty graph to enforce separability of labeled data, {{which leads to a}} greater discriminating power. Moreover the geometrical structure of labeled and unlabeled data is preserved through using the smoothness assumption by creating a similarity graph that conserves the neighboring information for all labeled and unlabeled data. However, S 2 N 2 L is sensitive to light changes, illumination, and partial occlusion. In this thesis, we propose a Semi-Supervised Half-Quadratic NMF (SSHQNMF) algorithm that combines the benefits of S 2 N 2 L and the robust NMF by the half- quadratic minimization (HQNMF) algorithm. Our algorithm improves upon the S 2 N 2 L algorithm by replacing the Frobenius norm with a robust M-Estimator loss function. A multiplicative update solution for our SSHQNMF algorithmis driven using the half- 4 quadratic (HQ) theory. Extensive experiments on ORL, Yale-A and a subset of the PIE data sets for nine M-estimator loss functions for both SSHQNMF and HQNMF <b>algorithms</b> <b>are</b> investigated, and compared with several state-of-the-art supervised and unsupervised algorithms, along with the original S 2 N 2 L algorithm in the context of classification, clustering, and robustness against partial occlusion. The proposed algorithm outperformed the other algorithms. Furthermore, SSHQNMF with Maximum Correntropy (MC) loss function obtained the best results for most test cases...|$|R
30|$|The {{article is}} {{organized}} as follows. In Section 2, we give formal definitions of our target EP(f, C) and the pseudomonotonicity of f. We then combined an idea {{often used for}} multivalued variational inequalities to EP(f, C) and interior proximal technique to develop an iterative <b>algorithm.</b> Section 3 <b>is</b> <b>devoted</b> to the proof of its global convergence to a solution of EP(f, C). In the last section, we apply the algorithm for the Nash-Cournot oligopolistic market equilibrium model. The numerical results are implemented to verify our development.|$|R
40|$|Many hard {{problems}} can be solved efficiently when the input is restricted to graphs of bounded treewidth. By the celebrated result of Courcelle, every decision problem expressible in monadic second order logic is fixed parameter tractable when parameterized by the treewidth of the input graph. Moreover, for every fixed k ≥ 0, such {{problems can}} be solved in linear time on graphs of treewidth at most k. In particular, this implies that basic problems like Dominating Set, Graph Coloring, Clique, and Hamiltonian Cycle are solvable in linear time on graphs of bounded treewidth. A significant amount of research in graph <b>algorithms</b> has <b>been</b> <b>devoted</b> to extending this result to larger classes of graphs. It was shown {{that some of the}} algorithmic meta-theorems for treewidth can be carried over to graphs o...|$|R
40|$|In {{this work}} we {{introduce}} a new algorithm for in-core parallel sorting integer keys {{which is based on}} the overpartitioning scheme introduced by Li and Sevcik [1]. The <b>algorithm</b> <b>is</b> <b>devoted</b> to clusters with processors running at different speeds i. e. correlated by a multiplicative constant factor. We compare experimentally this approach with another one related to the Parallel Sorting by Regular Sampling [2] that we have augmented to deal with the case of clusters with processors at different speeds. The metric used for the comparison is the sublist expansion metric that measures the load balancing of the <b>algorithm.</b> What <b>is</b> important in our work is the load balance factor, not (yet) the execution time. It is clear that improved load balance leads to improved execution time. The results we have obtained demonstrate that load balancing for the case of computers with heterogeneous processing capacity is more challenging than for the homogeneous case. An efficient load balancing strategy for the heterogeneous case: The problem that we address is the following: Ò data (with no duplicate) that are physically distributed on Ô processors have to be sorted. The cluster is composed with Ô processors characterized by their speeds that we denote by × � � � � � Ô. The average sustained disk transfer rate and the interconnection network bandwidth is no matter here. We also consider only the “perfect case ” that is to say the case of an input size that can be decomposed into Ô integer sums defined according to the processor speeds. The lowest common multiple is necessary here to expres...|$|R
40|$|This paper {{deals with}} inverse {{scattering}} techniques based on genetic <b>algorithms</b> (GAs), and <b>is</b> <b>devoted</b> to microwave imaging and microwave nondestructive testing and evaluation (NDT/NDE). In {{the framework of}} near-field spatial-domain algorithms, {{a brief overview of}} current trends and future developments of the research work is given. Numerical results of selected simulations, modeling realistic geometries, are presented in order to assess the effectiveness of the proposed optimization methodology. Finally, a discussion fixes some guidelines and points out the open problems to be addressed in order to enlarge the application area of GA-based inverse scattering techniques...|$|R
40|$|Studying {{the theory}} of {{regional}} economic clusters allows to state that in the Russian practice cluster policy is mostly aimed at the creation and support of new clusters rather than the development {{and support of the}} already existing ones. The artificial creation of a regional cluster is a long and resource-intensive process, therefore the selection of industries on the basis of which the creation of the cluster will be effective becomes an important task. It is also necessary to predict and compare the various options for the development of events, firstly, to make optimal management decisions, and secondly, to make timely changes and corrections in order to avoid undesirable results. This article presents the authors’ methodology for identifying the prospects for creating a regional economic cluster, which <b>is</b> a three-stage <b>algorithm.</b> The first two stages of the <b>algorithm</b> <b>are</b> <b>devoted</b> to the classification of Russian regions using hierarchical cluster analysis. For each of these stages, a system of indicators has been developed, which makes it possible to adequately break up the objects into groups in accordance with the goal. At the third stage, an imitation model for the functioning of the cluster is constructed, with the help of which it is possible to play various scenario scenarios, and the most optimal option will serve as a guide for the cluster policy of the region. This stage involves the formalization of links between the main elements that characterize the industry (GRP, investments, etc.), and largely depends on the specifics of this industry. The advantages of this technique, in our opinion, lie in the availability of indicators to a wide circle of researchers, as well as the versatility of research tools – cluster analysis and simulation...|$|R
40|$|Hybrid vehicle control {{strategies}} <b>are</b> <b>algorithms</b> <b>devoted</b> to {{the energy}} management. At each sampling time they choose the powertrain operating point {{in order to minimize}} a criterion, usually the fuel consumption. In simulation, an optimization <b>algorithm</b> can <b>be</b> derived from the minimum principle. For real time control, a Model Predictive Control scheme can be used but it requires the prediction of the future driving conditions. Their time ordered prediction is very difficult. Moreover, if the optimal costate is constant, only the prediction of their distribution is sufficient and allows deriving a real time control strategy. Experimental results are provided to illustrate the benefits of this approach...|$|R
40|$|This master thesis {{deals with}} {{optimization}} of {{the shape of}} the stator and rotor slots of induction motor with focusing on increasing efficiency. The theoretical part introduces the principles of optimization <b>algorithms.</b> Another part <b>is</b> <b>devoted</b> to design the shape of slots and its influence on the shape of slots on machine. On the models of motor was conducted the optimized shape of slots by using a genetic <b>algorithm.</b> Firstly, it <b>was</b> performed by using the analytical calculation in the RMxprt program, then by using the finite element method on two different models, whose difference simulates the influence of the production technology on the efficiency of the motor. Laboratory measurement was made on a real machine as well. The results of the measurement, calculations and optimizations are compared in the work...|$|R
40|$|Abstract. Let x = {xn}n∈IN be {{a hidden}} process, y = {yn}n∈IN an {{observed}} process and r = {rn}n∈IN some auxiliary process. We assume that t = {tn}n∈IN with tn = (xn,rn,yn− 1) is a (Triplet) Markov Chain (TMC). TMC {{are more general}} than Hidden Markov Chains (HMC) and yet enable the development of efficient restoration and parameter estimation <b>algorithms.</b> This paper <b>is</b> <b>devoted</b> to Bayesian smoothing algorithms for TMC. We first propose twelve algorithms for general TMC. In the Gaussian case, these smoothers reduce {{to a set of}} algorithms which include, among other solutions, extensions to TMC of classical Kalman-like smoothing algorithms (originally designed for HMC) such as the RTS algorithms, the Two-Filter algorithms or the Bryson and Frazier algorithm...|$|R
40|$|Let x = {xn}n∈IN be {{a hidden}} process, y = {yn}n∈IN an {{observed}} process and r = {rn}n∈IN some auxiliary process. We assume that t = {tn}n∈IN with tn = (xn, rn, yn− 1) is a (Triplet) Markov Chain (TMC). TMC {{are more general}} than Hidden Markov Chains (HMC) and yet enable the development of efficient restoration and parameter estimation <b>algorithms.</b> This paper <b>is</b> <b>devoted</b> to Bayesian smoothing algorithms for TMC. We first propose twelve algorithms for general TMC. In the Gaussian case, they reduce {{to a set of}} algorithms which includes, among other solutions, extensions to TMC of classical Kalman-like smoothing algorithms such as the RTS algorithms, the Two-Filter algorithm or the Bryson and Frazier algorithm. We finally propose particle filtering (PF) approximations for the general case. 1...|$|R
40|$|AbstractThis paper <b>is</b> <b>devoted</b> to the {{unification}} of the auxiliary problem principle and the principle of iterative regularization for the approximate solution of variational inequalities. This unification permits {{the extension of the}} principle of iterative regularization to real reflexive Banach spaces. On the basis of this unification, an <b>algorithm</b> <b>is</b> proposed and the strong convergence of the proposed <b>algorithm</b> <b>is</b> depicted...|$|R
40|$|Abstract—The paper <b>is</b> <b>devoted</b> to {{time series}} {{prediction}} using linear, perceptron and Elman neural networks {{of the proposed}} pattern structure. Signal wavelet de-noising in the initial stage is discussed as well. The {{main part of the}} paper <b>is</b> <b>devoted</b> to the comparison of different models of time series prediction. The proposed <b>algorithm</b> <b>is</b> applied to the real signal representing gas consumption. Index Terms—AR modelling, neural networks, Elman net-works, signal prediction, distributed computing I...|$|R
40|$|The paper <b>is</b> <b>devoted</b> to {{the review}} and {{analysis}} of algorithms for creation electronic digital signature. Known electronic digital signature <b>algorithms</b> <b>are</b> compared, examined the questions of implementation of the elliptic curve digital signature algorithm, proposed scheme of its software implementation...|$|R
40|$|This paper <b>is</b> <b>devoted</b> to {{extending}} common {{factors and}} categorical {{variables in the}} model of a finite mixture of factor analyzers based on the multivariate generalized linear model and the principle of maximum random utility in the probabilistic choice theory. The EM algorithm and Newton-Raphson <b>algorithm</b> <b>are</b> used to estimate model parameters, and then the <b>algorithm</b> <b>is</b> illustrated with a simulation study and a real example. ...|$|R
30|$|The {{remainder}} {{of this paper is}} organized as follows. The Retinex theory and the proposed SSVR <b>algorithm</b> <b>are</b> introduced in Section 2. Experimental results and comparison of SSVR with other methods <b>are</b> <b>devoted</b> in Section 3. Finally, Section 4 concludes the paper.|$|R
40|$|The paper <b>is</b> <b>devoted</b> to the {{construction}} of a probabilistic particle <b>algorithm.</b> This <b>is</b> related to nonlin-ear forward Feynman-Kac type equation, which represents the solution of a nonconservative semilinear parabolic Partial Differential Equations (PDE). Illustrations of the efficiency of the <b>algorithm</b> <b>are</b> provided by numerical experiments. Comment: arXiv admin note: substantial text overlap with arXiv: 1608. 0487...|$|R
40|$|Adaptive {{filtering}} <b>algorithms</b> <b>are</b> {{considered in}} this work. The main effort <b>is</b> <b>devoted</b> {{to improve the}} performance of such algorithms. Two classes of <b>algorithms</b> <b>are</b> given. The first one uses averaging in the approximation sequence obtained via slowly varying gains, and the second one utilizes averages in both the approximation sequence and the observed signals. Asymptotic properties{convergence and rate of convergence are developed. Analysis {{to one of the}} <b>algorithms</b> <b>is</b> presented. It is shown that the averaging approach gives rise to asymptotically optimal performance and results in asymptotically efficient procedures...|$|R
40|$|The {{problem of}} visual {{tracking}} of multiple objects is considered in this paper. Special emphasis <b>is</b> <b>devoted</b> {{to the case}} when two OT more objects overlap {{with respect to the}} visual system causing occlusion. The <b>algorithm</b> <b>is</b> based on the Kalman filtering and Bi-nary Space Partition tree representations of the ob-jects geometry. The real-time implementation of the <b>algorithm</b> <b>is</b> ezperimentally tested for the case of vi-sual tracking of two objects using two cameras. ...|$|R
40|$|Abstract—This paper {{presents}} a quality-of-service (QoS) provisioning dynamic connection-admission control (CAC) algorithm for multimedia wireless networks. A multimedia connection consists of several substreams (i. e., service classes), {{each of which}} presets a range of feasible QoS levels (e. g., data rates). The proposed <b>algorithm</b> <b>is</b> mainly <b>devoted</b> to finding the best possible QoS levels for all the connections (i. e., QoS vector) that maximize resource utilization by fairly distributing wireless resources among the connections while maximizing the statistical multiplexing gain (i. e., minimizing the blocking and dropping probabilities). In the case of congestion (overload), the algorithm uniformly degrades the QoS levels of the existing connections (but only slightly) in order to spare some resources for serving new or handoff connections, thereby naturally minimizing the blocking and dropping probabilities (it amounts to maximizing the statistical multiplexing gain). The algorithm employs a Hopfield neural network (HNN) for finding a QoS vector. The problem itself is formulated as a multi-objective optimization problem. Hardware-based HNN exhibits high (computational) speed that permits real time running of the CAC algorithm. Simulation {{results show that the}} algorithm can maximize resource utilization and maintain fairness in resource sharing, while maximizing the statistical multiplexing gain in providing acceptable service grades. Furthermore, the results are relatively insensitive to handoff rates. Index Terms—Dynamic connection-admission control (CAC), Hopfield neural network (HNN), multimedia services, quality of service (QoS), wireless networks. I...|$|R
30|$|The {{remainder}} {{of this paper is}} organized as follows. Section 2 <b>is</b> <b>devoted</b> to the system model and problem formulation. In Section 3, the distributed <b>algorithm</b> <b>is</b> proposed and analyzed in detail. Numerical results confirm the convergence of the proposed algorithm in Section 4. Section 5 concludes this article.|$|R
40|$|This paper <b>is</b> <b>devoted</b> to {{the study}} of optimal image {{quantization}} and its sensitivity to initial conditions. The optimal mean squared <b>algorithm</b> <b>is</b> elaborated, for gray-level as well as for color images. A genetic quantization <b>algorithm</b> <b>is</b> developed, which is a hybrid technique combining optimal quantization with a genetic <b>algorithm.</b> It <b>is</b> shown that the latter technique is almost insensitive to initial conditions and performs better than the former. In the case of color images, the difference between both techniques clearly affects the visual quality...|$|R
