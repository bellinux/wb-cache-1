0|980|Public
5000|$|Schütze, H. 1998. <b>Automatic</b> <b>word</b> sense discrimination. Computational Linguistics, 24(1): 97-123.|$|R
3000|$|This paper {{systematically}} reconstructs {{the mechanisms}} of reference as they function with and without language in an agent-based computational framework. [...] Language-dependent surfaces play a role only in the <b>automatic</b> <b>word</b> form recognition of the hear mode and the <b>automatic</b> <b>word</b> form production of the speak mode. [...] In conclusion, the agent-based reconstruction of reference {{is applied to the}} medieval distinction between de dicto and de re (“De dicto/de re” section).|$|R
5000|$|Mihalcea, R. 2007. Using Wikipedia for <b>Automatic</b> <b>Word</b> Sense Disambiguation. In Proc. of the North American Chapter of the Association for Computational Linguistics (NAACL 2007), Rochester, April 2007.|$|R
5000|$|SQL Assistant SQL Assistant add-on for SQL*Plus Windows version extends SQL*Plus with SQL <b>automatic</b> <b>word</b> completion, in-line Oracle SQL Reference, data export/import, code unit testing, data browsing, and code {{development}} functions.|$|R
40|$|This {{paper is}} about the {{creation}} of a digital dialect database, and the focus is on <b>automatic</b> <b>word</b> segmentation. <b>Automatic</b> <b>word</b> segmentation has been studied by several research groups during the last two decades. However, the task we are faced with differs in several respects from previous ones. For instance, in our case we are dealing with recordings of interviews containing spontaneous dialect speech and `enriched' (quasi-phonetic) orthographic transcriptions (instead of `normal' orthographic transcriptions, which are usually available). Furthermore, the nature of the task requires that the word segmentation procedure can be adapted for each interview...|$|R
40|$|Aspects of the Roumanian {{spelling}} checker ROMSP are presented: effective vocabulary representation, similar <b>words</b> detection algorithms, <b>automatic</b> <b>word</b> inflection, the user interface, supporting tools, further development. Problems of user interface engineering support by object oriented methods are of special interest...|$|R
40|$|We {{describe}} an <b>automatic</b> <b>word</b> classification system {{which uses a}} locally optimal annealing algorithm and average class mutual information. A new word-class representation, the structural tag is introduced and its advantages for use in statistical language modelling are presented. A summary of some results with the one million word lob corpus is given; the algorithm is also shown to discover the vowel-consonant distinction and displays an ability to cluster words syntactically in a Latin corpus. Finally, a comparison is made between the current classification system and several alternative systems, which shows that the current system performs tolerably well. 1 Introduction This paper contains a description of some work on an <b>automatic</b> <b>word</b> classification system which uses a technique similar to annealing [1]. The <b>automatic</b> acquisition of <b>word</b> classes corresponds to the paradagmatic component [5] of the syntagmatic-paradagmatic bootstrapping problem [19]. The best of the recent classifi [...] ...|$|R
50|$|Nationality <b>words</b> <b>link</b> to {{articles}} {{with information}} on the nation's poetry or literature (for instance, Irish or France).|$|R
40|$|In this {{position}} paper, we make several observations {{about the state}} of the art in <b>automatic</b> <b>word</b> sense disambiguation. Morivated by these observations, we offer several specific proposals to the community regarding improved evaluation criteria, common training and testing resources, and the definition of sense inventories...|$|R
40|$|We {{present a}} {{syllable}} bigram model for segmenting a Korean sentence into words and correcting word-spacing {{errors in the}} spelling checker. We evaluated the system's performance for <b>automatic</b> <b>word</b> segmentation, word-spacing error detection, and the word-splitting problem of the character recognition system {{at the end of}} a line...|$|R
40|$|We {{prove that}} the {{isomorphism}} of scattered tree automatic linear orders {{as well as the}} existence of automorphisms of scattered <b>word</b> <b>automatic</b> linear orders are undecidable. For the existence of <b>automatic</b> automorphisms of <b>word</b> <b>automatic</b> linear orders, we determine the exact level of undecidability in the arithmetical hierarchy...|$|R
40|$|<b>Automatic</b> <b>word</b> {{alignment}} is {{an important}} technology for extracting translation knowledge from parallel corpora. However, automatic techniques cannot resolve this problem completely because of variances in translations. We therefore need to investigate the performance potential of <b>automatic</b> <b>word</b> alignment and then decide how to suitably apply it. In this paper we first propose a lexical knowledge-based approach to word alignment on a Japanese-Chinese corpus. Then we evaluate {{the performance of the}} proposed approach on the corpus. At the same time we also apply a statistics-based approach, the well-known toolkit GIZA++, to the same test data. Through comparison of the performances of the two approaches, we propose a multi-aligner, exploiting the lexical knowledge-based aligner and the statistics-based aligner at the same time. Quantitative results confirmed the effectiveness of the multi-aligner. ...|$|R
40|$|We {{prove the}} undecidability of the {{existence}} of an isomorphism between scattered tree-automatic linear orders as well as the existence of automorphisms of scattered <b>word</b> <b>automatic</b> linear orders. For the existence of <b>automatic</b> automorphisms of <b>word</b> <b>automatic</b> linear orders, we determine the exact level of undecidability in the arithmetical hierarchy...|$|R
40|$|We {{describe}} {{a method for}} the identification of medical term variations using parallel corpora and measures of distributional similarity. Our approach is based on <b>automatic</b> <b>word</b> alignment and standard phrase extraction techniques commonly used in statistical machine translation. Combined with pattern-based filters we obtain encouraging results compared to related approaches using similar datadriven techniques. ...|$|R
50|$|Its {{features}} include crash-recovery via automatic saving, syntax highlighting, snippets, <b>automatic</b> <b>word</b> completion, pair character completion, smart indentation, bookmarks, and various text editing functions. However, {{it does not}} provide the options to turn off some of those features, such as involuntary automatic saving (which can overwrite the old version of opened file without user's consent).|$|R
60|$|At these <b>words</b> <b>Link</b> grew {{pale and}} shot a swift glance at Hank Snogger. Then, {{in a sudden}} rage, he shook his fist at the cowboy.|$|R
5000|$|Frequently the <b>word</b> <b>link</b> {{is used to}} {{describe}} any submanifold of the sphere [...] diffeomorphic to a disjoint union of {{a finite number of}} spheres, [...]|$|R
40|$|Abstract. The {{purpose of}} the study is to prove that results of <b>automatic</b> <b>word</b> {{clustering}} (AWC) may contribute much in investigating semantic structure of texts and in evaluating plot complexity. Experiments were carried out for Russian texts, mainly stories and short novels. Data obtained in course of study allowed to formulate and verify several linguistic hypotheses...|$|R
6000|$|... ‘Come {{and look}} at her!’ he cried; and, with the <b>word,</b> <b>links</b> his arm in mine and carries me to the {{outhouse}} where the chaise was on view.|$|R
30|$|This {{work was}} {{supported}} by the funding project of A study on multiple mapping fusion Chinese and English <b>automatic</b> <b>word</b> alignment system based on multi-preprocessing mechanism takes the establishment of parallel corpus on the Chinese-English translation website of Hainan tourism text as an example (No. 20167238) and the funding project of Construction and application of female health system in Hainan (No. ZDYF 2016136).|$|R
50|$|Bitext word {{alignment}} is {{an important}} supporting task for most methods of statistical machine translation; the parameters of statistical machine translation models are typically estimated by observing word-aligned bitexts, and conversely <b>automatic</b> <b>word</b> alignment is typically done by choosing that alignment which best fits a statistical machine translation model. Circular application of these two ideas results in an instance of the expectation-maximization algorithm.|$|R
40|$|Abstract. The {{principle}} of Maximum Matching Method (MM) is “First Matching the Maximum Word-Length”. At present, however, {{the method of}} Maximum Matching Method (MM) does not incarnate the {{principle of}} “First Matching the Maximum Word-Length ” well. So in order to incarnate well, a revised BMM and RMM Algorithm of Chinese <b>automatic</b> <b>words</b> segmentation is put forward, and its algorithm is also given...|$|R
40|$|This paper {{presents}} {{a new approach}} to <b>automatic</b> <b>word</b> categorization which improves both the efficiency of the algorithm {{and the quality of the}} formed clusters. The unigram and the bigram statistics of a corpus of about two million words are used with an efficient distance function to measure the similarities of words, and a greedy algorithm to put the words into clusters...|$|R
40|$|An <b>automatic</b> <b>word</b> spacing {{is one of}} the {{important}} tasks in Korean language processing and information retrieval. Since {{there are a number of}} confusing cases in word spacing of Korean, there are some mistakes in many texts including news articles. This paper presents a high-accurate method for <b>automatic</b> <b>word</b> spacing based on self-organizing-gram model. This method is basically a variant of-gram model, but achieves high accuracy by automatically adapting context size. In order to find the optimal context size, the proposed method automatically increases the context size when the contextual distribution after increasing it dose not agree with that of the current context. It also decreases the context size when the distribution of reduced context is similar to that of the current context. This approach achieves high accuracy by considering higher dimensional data in case of necessity, and the increased computational cost are compensated by the reduced context size. The experimental results show that the self-organizing structure of-gram model enhances the basic model. ...|$|R
40|$|Abstract Background <b>Automatic</b> <b>word</b> {{alignment}} of parallel texts {{with the same}} content in different languages is among other things used to generate dictionaries for new translations. The quality of the generated word alignment depends {{on the quality of}} the input resources. In this paper we report on <b>automatic</b> <b>word</b> {{alignment of}} the English and Swedish versions of the medical terminology systems ICD- 10, ICF, NCSP, KSH 97 -P and parts of MeSH and how the terminology systems and type of resources influence the quality. Methods We automatically word aligned the terminology systems using static resources, like dictionaries, statistical resources, like statistically derived dictionaries, and training resources, which were generated from manual word alignment. We varied which part of the terminology systems that we used to generate the resources, which parts that we word aligned and which types of resources we used in the alignment process to explore the influence the different terminology systems and resources have on the recall and precision. After the analysis, we used the best configuration of the <b>automatic</b> <b>word</b> alignment for generation of candidate term pairs. We then manually verified the candidate term pairs and included the correct pairs in an English-Swedish dictionary. Results The results indicate that more resources and resource types give better results but the size of the parts used to generate the resources only partly affects the quality. The most generally useful resources were generated from ICD- 10 and resources generated from MeSH were not as general as other resources. Systematic inter-language differences in the structure of the terminology system rubrics make the rubrics harder to align. Manually created training resources give nearly as good results as a union of static resources, statistical resources and training resources and noticeably better results than a union of static resources and statistical resources. The verified English-Swedish dictionary contains 24, 000 term pairs in base forms. Conclusion More resources give better results in the <b>automatic</b> <b>word</b> alignment, but some resources only give small improvements. The most important type of resource is training and the most general resources were generated from ICD- 10. </p...|$|R
40|$|Reordering {{has been}} an {{important}} topic in statistical machine translation (SMT) as long as SMT has been around. State-of-the-art SMT systems such as Pharaoh (Koehn, 2004 a) still employ a simplistic model of the reordering process to do non-local reordering. This model penalizes any reordering no matter the words. The reordering is only selected if it leads to a translation that looks like a much better sentence than the alternative. Recent developments have, however, seen improvements in translation quality following from syntax-based reordering. One such development is the pre-translation approach that adjusts the source sentence to resemble target language word order prior to translation. This is done based on rules that are either manually created or automatically learned from word aligned parallel corpora. We introduce a novel approach to syntactic reordering. This approach provides better exploitation of the information in the reordering rules and eliminates problematic biases of previous approaches. Although the approach is examined within a pre-translation reordering framework, it easily extends to other frameworks. Our approach significantly outperforms a state-of-the-art phrase-based SMT system and previous approaches to pretranslation reordering, including (Li et al., 2007; Zhang et al., 2007 b; Crego & Mari˜ no, 2007). This is consistent both for a very close language pair, English-Danish, and a very distant language pair, English-Arabic. We also propose automatic reordering rule learning based on a rich set of linguistic information. As opposed to most previous approaches that extract a large set of rules, our approach produces a small set of predominantly general rules. These provide a good reflection of the main reordering issues of a given language pair. We examine the influence of several parameters that may have influence {{on the quality of the}} rules learned. Finally, we provide a new approach for improving <b>automatic</b> <b>word</b> alignment. This word alignment is used in the above task of automatically learning reordering rules. Our approach learns from hand aligned data how to combine several <b>automatic</b> <b>word</b> alignments to one superior <b>word</b> alignment. The <b>automatic</b> <b>word</b> alignments are created from the same data that has been preprocessed with different tokenization schemes. Thus utilizing the different strengths that different tokenization schemes exhibit in word alignment. We achieve a 38 % error reduction for the <b>automatic</b> <b>word</b> alignmen...|$|R
40|$|We {{describe}} {{a method for}} extracting translation verb frames (parallel subcategorization frames) from a parallel dependency treebank. The extracted frames constitute {{an important part of}} machine translation dictionary for a structural machine translation system. We evaluate our method independently, using a manually annotated test dataset, and conclude that the bottleneck of the method lies in quality of <b>automatic</b> <b>word</b> alignment of the training data. ...|$|R
40|$|This work shows Information Retrieval {{experiments}} performed over handwritten documents {{produced by}} a single writer. The same retrieval task has been performed over both manual (no errors) and <b>automatic</b> (<b>Word</b> Error Rate around 45 %) transcriptions of 200 handwritten texts. The {{results show that the}} performance loss due to recognition errors is acceptable and that Information Retrieval technologies can be effectively applied to handwritten data...|$|R
40|$|Abstract — Keywords are the {{thematic}} words in any document. They represent topic of that document. Keywords {{are commonly used}} for search engines and document databases to locate information and determine if two pieces of test are related to each other. Key terms retrieval is also addressed as mining of words, words retrieval, recognition of words, or retrieval of glossary, is a small phase of retrieval of information. Overall motive of retrieval of terminology is retrieving relevant words automatically in a corpus. Moreover, techniques of <b>automatic</b> <b>words</b> retrieval mainly apply language techniques (<b>automatic</b> chunking of <b>words</b> phrases and tagging part of speech) fo...|$|R
50|$|In {{everyday}} language, {{the different}} {{meaning of the}} <b>wording</b> <b>Link</b> 1 TDL Standard (format) and Link 1 information content (subject matter) to be transmitted on this particular TDL Standard is mixed up in many cases.|$|R
50|$|A feature {{related to}} English. In the past, Word worm's pages {{regularly}} featured {{a list of}} <b>words</b> <b>linked</b> to the month's topic, with multiple choice definitions. The reader then had to identify the correct definition.|$|R
40|$|MorP is {{a system}} for <b>automatic</b> <b>word</b> class {{assignment}} {{on the basis of}} surface features. It has a very small lexicon of form words (%o entries), and for the rest works entirely on morphological and configurational patterns. This makes it robust and fast, and in spite of the (deliberate) restrictedness of the system, its performance reaches an average ac-curacy level above 91 % when run on un-restricted Swedish text...|$|R
40|$|This work shows {{experiments}} on the retrieval of handwritten documents. The {{performance of the}} same state-of-the-art information retrieval system is compared when dealing with manual (no errors) and <b>automatic</b> (<b>word</b> error rate around 50 %) transcriptions of the same handwritten texts. The results show that, {{in terms of the}} user effort required to find the desired items, the performance degradation due to the recognition errors can be considered acceptable...|$|R
50|$|It {{included}} all the basic features common to most word processors of the day, including <b>automatic</b> <b>word</b> wrapping, spell checking, copy and paste, underlining, and boldfacing; {{and it also}} boasted {{a few of the}} most-commonly-used advanced features, such as mail merge and few others. The product was considerably easier to both learn and use than its far more fully featured and expensive DOS word processing competitors, WordPerfect, Microsoft Word and XyWrite.|$|R
40|$|<b>Automatic</b> {{classification}} of <b>words</b> use abstract representations of lexical items. The representations {{are usually not}} easily derived from the data available (strings of letters). This is a core problem in nearest neighbor methods. This article describes research towards a genetic algorithm for inventing features of relevance for <b>automatic</b> <b>word</b> classification. The GA attempts to optimize a representation created by a random process. Factors in genetic algorithms are identified for the task, and a novel solution is presented for creating features {{that can be used}} with large data sets of millions of words, with minimal demands on feedback. The result is an unsupervised categorization of a large corpus...|$|R
40|$|Background. <b>Automatic</b> <b>word</b> {{alignment}} of parallel texts {{with the same}} content in different languages is among other things used to generate dictionaries for new translations. The quality of the generated word alignment depends {{on the quality of}} the input resources. In this paper we report on <b>automatic</b> <b>word</b> {{alignment of}} the English and Swedish versions of the medical terminology systems ICD- 10, ICF, NCSP, KSH 97 -P and parts of MeSH and how the terminology systems and type of resources influence the quality. Methods. We automatically word aligned the terminology systems using static resources, like dictionaries, statistical resources, like statistically derived dictionaries, and training resources, which were generated from manual word alignment. We varied which part of the terminology systems that we used to generate the resources, which parts that we word aligned and which types of resources we used in the alignment process to explore the influence the different terminology systems and resources have on the recall and precision. After the analysis, we used the best configuration of the <b>automatic</b> <b>word</b> alignment for generation of candidate term pairs. We then manually verified the candidate term pairs and included the correct pairs in an English-Swedish dictionary. Results. The results indicate that more resources and resource types give better results but the size of the parts used to generate the resources only partly affects the quality. The most generally useful resources were generated from ICD- 10 and resources generated from MeSH were not as general as other resources. Systematic inter-language differences in the structure of the terminology system rubrics make the rubrics harder to align. Manually created training resources give nearly as good results as a union of static resources, statistical resources and training resources and noticeably better results than a union of static resources and statistical resources. The verified English-Swedish dictionary contains 24, 000 term pairs in base forms. Conclusion. More resources give better results in the <b>automatic</b> <b>word</b> alignment, but some resources only give small improvements. The most important type of resource is training and the most general resources were generated from ICD- 10. © 2007 Nyström et al, licensee BioMed Central Ltd. Original Publication:Mikael Nyström, Magnus Merkel, Håkan Petersson and Hans Åhlfeldt, Creating a medical dictionary using word alignment: The influence of sources and resources, 2007, BMC Medical Informatics and Decision Making, (7), 37. [URL] BioMed Central[URL]...|$|R
