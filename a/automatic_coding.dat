73|1035|Public
5000|$|Lexical {{search and}} <b>automatic</b> <b>coding</b> of {{references}} (with context) ...|$|E
5000|$|... 1968: Richard Hamming for {{his work}} on {{numerical}} methods, <b>automatic</b> <b>coding</b> systems, and error-detecting and error-correcting codes.|$|E
5000|$|... #Caption: The Fortran <b>Automatic</b> <b>Coding</b> System for the IBM 704 (15 October 1956), {{the first}} Programmer's Reference Manual for Fortran ...|$|E
40|$|A {{viewgraph}} {{presentation of}} an <b>automatic</b> <b>code</b> scheme for source verification issues is shown. The topics include: 1) Model-Based Control Law Development with <b>Automatic</b> <b>Code</b> Generation; 2) Source Verification Issues of Automatically Generated Code; 3) MXZ Code Generator; 4) Benefits and Limitations of MXZ; and 5) Current State of the Tool...|$|R
5000|$|Construction: this {{involves}} the reuse software components and <b>automatic</b> <b>code.</b>|$|R
5000|$|... 2013: ERIKA Enterprise is {{supported}} by E4Coder <b>automatic</b> <b>code</b> generation tool.|$|R
50|$|Richard Hamming won the Turing Award in 1968 for {{his work}} at Bell Labs in {{numerical}} methods, <b>automatic</b> <b>coding</b> systems, and error-detecting and error-correcting codes. He invented the concepts known as Hamming codes, Hamming windows, Hamming numbers, and Hamming distance.|$|E
50|$|Results of {{supervised}} {{methods can}} be validated by drawing a distinct sub-sample of the corpus, called a 'validation set'. Documents in the validation set can be hand-coded and {{compared to the}} <b>automatic</b> <b>coding</b> output to evaluate how well the algorithm replicated human coding. This comparison can {{take the form of}} inter-coder reliability scores like those used to validate the consistency of human coders in traditional textual analysis.|$|E
50|$|The first {{high-level}} compiler, {{introduced as}} the Fortran <b>Automatic</b> <b>Coding</b> System in 1957, broke the code into blocks and devised {{a table of}} the frequency each block is executed via a simulated execution of the code in a Monte Carlo fashion in which the outcome of conditional transfers (as via IF-type statements) is determined by a random number generator suitably weighted by whatever FREQUENCY statements were provided by the programmer.|$|E
5000|$|<b>Automatic</b> <b>code</b> {{generation}} for {{the skeleton}} application, CRUD applications, through the Gii tool.|$|R
40|$|Productivity {{is a key}} {{concept in}} today's {{software}} industry, that's {{why a lot of}} researches became interested in <b>automatic</b> <b>Code</b> Generation. But these researches focused only on the application structure and high-level design details. In this research, a framework for <b>automatic</b> <b>code</b> generation from a flowchart is introduced, based on metamodels for the flowchart and for the programming language of the generated code...|$|R
50|$|Some {{models are}} {{constructed}} by <b>automatic</b> <b>code</b> generators (e.g. Autochem or KPP). In this approach {{a set of}} constituents are chosen and the <b>automatic</b> <b>code</b> generator will then select the reactions involving those constituents from a set of reaction databases. Once the reactions have been chosen the ordinary differential equations (ODE) that describe their time evolution can be automatically constructed.|$|R
5000|$|The [...] {{statement}} was used originally (and optionally) to give branch probabilities {{for the three}} branch cases of the arithmetic IF statement. The first FORTRAN compiler used this weighting to perform at compile time a Monte Carlo simulation of the generated code, the results of which were used to optimize the placement of basic blocks in memory a very sophisticated optimization for its time. The Monte Carlo technique is documented in Backus et al.'s paper on this original implementation, The FORTRAN <b>Automatic</b> <b>Coding</b> System: ...|$|E
5000|$|The term {{autocoder}} {{needs to}} be distinguished from autocode, a term of the same era which {{was used in the}} UK for languages of a higher level. Both terms derive from the phrase <b>automatic</b> <b>coding,</b> which referred generally to programs which eased the burden of producing the numeric machine language codes of programs. [...] ("Autocoding" [...] is seen occasionally, and can refer to any kind of programming system.) In some circles [...] "autocoder" [...] could be used in a rather generic way to refer to what is now called a macro-assembler.|$|E
50|$|FOR TRANSIT was {{the name}} of a reduced version of the IBM 704 FORTRAN language,which was {{implemented}} for the IBM 650, using a translator program developedat Carnegie in the late 1950s.The following comment appears in the IBM Reference Manual (FOR TRANSIT <b>Automatic</b> <b>Coding</b> System C28-4038, Copyright 1957, 1959 by IBM):The FORTRAN system was designed for a more complex machine than the 650, and consequently some of the 32 statements found in the FORTRAN Programmer's Reference Manual are not acceptable to the FOR TRANSIT system. In addition, certain restrictions to the FORTRAN language have been added. However, none of these restrictions make a source program written for FOR TRANSIT incompatible with the FORTRAN system for the 704.|$|E
5000|$|<b>Automatic</b> <b>code</b> {{generation}} for ECUs {{in production}} quality (more than 65 million produced since 1997) ...|$|R
30|$|The {{identified}} {{potential problems}} do not only apply to implementation models with <b>automatic</b> <b>code</b> generation {{but also to}} manual coding.|$|R
5000|$|Integrated <b>automatic</b> <b>code</b> {{checkers}} (syntax, {{errors and}} style, PEP-8) for static program analysis {{as well as}} support of Pylint via plug-in ...|$|R
5000|$|... f4analyse {{provides}} the basic tools for computer-assisted qualitative data analysis. These include hierarchical text coding, writing of memos and comments, selection of quotations, lexical search with <b>automatic</b> <b>coding</b> {{as well as}} the export of certain quotations into word processor software. Compared to other CAQDAS programs, f4analyse explicitly reduces the scope of functions. For example, no mixed-method strategies are supported and there are no visualization functions. The software is mainly used in the context of qualitative research and evaluation. f4analyse is under continuous review through the scholarly community. The software has been used for qualitative data analysis in academic research across various disciplines, such as development economics, political science or in the field of software engineering.|$|E
50|$|SNOMED CT {{provides}} for consistent information interchange and {{is fundamental to}} an interoperable electronic health record. It provides a consistent means to index, store, retrieve, and aggregate clinical data across specialties and sites of care. It also helps in organizing the content of electronic health records systems by reducing the variability in the way data are captured, encoded and used for clinical care of patients and research. SNOMED CT {{can be used to}} directly record clinical details of individuals in electronic patient records. It also provides the user with a number of linkages to clinical care pathways, shared care plans and other knowledge resources, in order to facilitate informed decision-making, and to support long-term patient care. The availability of free <b>automatic</b> <b>coding</b> tools and services, which can return a ranked list of SNOMED CT descriptors to encode any clinical report, could help healthcare professionals to navigate the terminology.|$|E
40|$|Although {{protocol}} {{analysis can}} be an important tool for researchers to investigate the process of collaboration and communication, the use of this method of analysis can be time consuming. Hence, an <b>automatic</b> <b>coding</b> procedure for coding dialogue acts was developed. This procedure helps to determine the communicative function of messages in online discussions by recognizing discourse markers and cue phrases in the utterances. Five main communicative functions are distinguished: argumentative, responsive, informative, elicitative, and imperative. A total of 29 different dialogue acts are specified and recognized automatically in collaboration protocols. The reliability of the <b>automatic</b> <b>coding</b> procedure was determined by comparing automatically coded dialogue acts to hand-coded dialogue acts by a human rater. The validity of the <b>automatic</b> <b>coding</b> procedure was examined using three different types of analyses. First, an examination of group differences was used (dialogue acts used by female versus male students). Ideally, the coding procedure should be able to distinguish between groups who are likely to communicate differently. Second, to examine the validity of the <b>automatic</b> <b>coding</b> procedure through examination of experimental intervention, the results of the <b>automatic</b> <b>coding</b> procedure of students, with access to a tool that visualizes the degree of participation of each student, were compared to students who did not have access to this tool. Finally, the validity of the <b>automatic</b> <b>coding</b> procedure of dialogue acts was examined using correlation analyses. Results of the <b>automatic</b> <b>coding</b> procedure of dialogue acts of utterances (form) were related to results of a manual coding procedure of the collaborative activities to which the utterances refer (content). The analyses presented in this paper indicate promising results concerning {{the reliability and validity of}} the <b>automatic</b> <b>coding</b> procedure for dialogue acts. However, limitations of the procedure were also found and discussed...|$|E
5000|$|Optional equipment:5-Speed <b>Automatic</b> - <b>code</b> 42/3 in the data-card;7-Speed <b>Automatic</b> (7G-TRONIC) - <b>code</b> ...|$|R
5000|$|Towards <b>Automatic</b> <b>Code</b> Generation for EAI Solutions using DSL Tools, In Conference on Software Engineering and Databases (JISBD). 134-145. 2009. - http://www.guarana-project.net/rzfrantz/publications/jisbd-2009.pdf ...|$|R
40|$|This work {{deals with}} issues of <b>automatic</b> <b>code</b> {{generation}} for microcontrollers. Knowledge of this area is subsequently used for adjustment of the part of code of the experimental vehicle Car 4. The main theme of this work is to design a control platform of the based platform dsPIC, which serve for driving Car 4. Tooling capabilities for <b>automatic</b> <b>code</b> generation in creating firmware for this remote control are then tested in practice on this remote control...|$|R
40|$|An <b>automatic</b> <b>coding</b> {{procedure}} is described {{to determine the}} communicative functions of messages in chat discussions. Five main communicative functions are distinguished: argumentative (indicating a line of argumentation or reasoning), responsive (e. g., confirmations, denials, and answers), informative (transfer of information), elicitative (questions or proposals requiring a response), and imperative (commands). A total of 29 different dialogue acts are specified and recognized automatically in the chats of students during collaboration. The validity of the <b>automatic</b> <b>coding</b> procedure was examined using three different types of analyses. First, an examination of group differences was used to provide evidence {{about the validity of}} the <b>automatic</b> <b>coding</b> procedure. Ideally, the coding procedure should be able to distinguish between groups who are likely to communicate differently. For example, it has been shown extensively, that women communicate differently than men do: women use more affiliative language, whereas men use more assertive language. The coding procedure was able to mostly replicate these findings. For example, women were found to use more responsive dialogue acts, whereas men used more informative and imperative dialogue acts. Second, to examine the validity of the <b>automatic</b> <b>coding</b> procedure through examination of experimental intervention, the results of the <b>automatic</b> <b>coding</b> procedure of students with access to a tool that visualizes the degree of participation of each student were compared to students that did not have that sort of visualization. It was expected that students with access to the tool would engage in more argumentative interactions. This expectation was partly confirmed as it was found that students with access used more conditional arguments. However, they did not use more reasons, contra arguments, etc. Finally, the validity of the <b>automatic</b> <b>coding</b> procedure was examined using correlation analyses. Results of the <b>automatic</b> <b>coding</b> procedure were correlated with results of a manual coding procedure. This manual coding was aimed at identifying the task-related and social aspects of online collaboration. Because some aspects of the manual coding procedure focused on similar aspects of online collaboration as the <b>automatic</b> <b>coding</b> procedure, moderate to strong correlations were expected. Indeed, several significant correlations were found In conclusion, the results presented in this paper indicate favorable results concerning the validity of the <b>automatic</b> <b>coding</b> procedure for dialogue acts...|$|E
40|$|When {{processing}} survey data, {{the coding}} stage {{is becoming increasingly}} automated, since the productivity gains made possible are substantial. This is why <b>automatic</b> <b>coding</b> techniques are gradually introduced in most statistical institutes. At INSEE, France, <b>automatic</b> <b>coding</b> exists for more than 15 years through the QUID software. This method {{had been used in}} many applications since 1983. However it had some drawbacks and needed to be improved. Since 1993 a new software and a new management structure for the <b>automatic</b> <b>coding</b> are being developped: SICORE. This article attempts to describe this SICORE system (software and management structure) and presents results of its first applications...|$|E
40|$|Describes the {{adoption}} of <b>automatic</b> <b>coding</b> by text recognition into ASHE and the significant benefits that will ensue. The <b>automatic</b> <b>coding</b> tool, <b>automatic</b> <b>coding</b> by text recognition (ACTR), is being introduced for the Annual Survey of Hours and Earnings (ASHE). ACTR {{has been shown to}} improve the quality of occupation coding. However, it also brings a moderate discontinuity in the ASHE results. The improvement in the quality of the coding, and the savings obtained from using ACTR, mean that the benefits of its adoption are significant. For continuity, a revised 2006 data set will also be created on an ACTR-coded basis. Economic & Labour Market Review (2007) [1], 29 – 32; doi: 10. 1057 /palgrave. elmr. 1410122...|$|E
40|$|Abstract: In {{this paper}} {{incorporating}} manual and <b>automatic</b> <b>code</b> generation is discussed. A solution for <b>automatic</b> metadata-driven <b>code</b> generation is presented illustrated with multi tier Enterprise Resource Planning System. We intend {{to make our}} solution available to public {{in order to encourage}} investigation of code generation and schema-driven tools for. NET Framework...|$|R
40|$|Abstract- Model-Based Design in {{industry}} {{relies heavily on}} <b>automatic</b> <b>code</b> generation technology. The need to obtain code for different configurations such as rapid prototyping, hardware-in-the-loop simulation, and processor-in-the-loop simulation introduces extensive code generation from high-level models and to be cost effective and competitive requires the automation of this code generation. This paper shows {{some of the issues}} that embedded systems engineers have to negotiate as a consequence of this. It indicates that there is a shift in required skills from the algorithmic to the architectural level. As such, <b>automatic</b> <b>code</b> generation technology provides an opportunity in academia to better prepare students to be successful in the field of embedded control system design by including such architectural aspects in the curriculum, while shifting focus of algorithm design from creation to inspection. Index Terms- Engineering education; model-based design; <b>automatic</b> <b>code</b> generatio...|$|R
40|$|AbstractTime-dependent partial {{differential}} equations are often treated by semidiscretization {{and the resulting}} problem solved using existing ordinary differential equation software restricted to low-order formulas. For certain classes of problems, the Backward Differentiation Formulas (BDF) are often dismissed due to their poor stability behavior near the imaginary axis for orders three and above. We explain why and for what problems this happens, what the appropriate tactic should be, and why {{this is not the}} tactic taken by most <b>automatic</b> <b>codes.</b> We present an idea that avoids this inefficiency in one <b>automatic</b> <b>code...</b>|$|R
40|$|Medical coding {{has become}} an {{important}} new industry that has originated {{from the field of}} medical informatics. <b>Automatic</b> <b>coding</b> of specimens has emerged as a way of relieving hospitals from the cost of paying professional coders and for achieving uniform coding for all specimens. Unfortunately, <b>automatic</b> <b>coding,</b> like manual coding, has numerous pitfalls. Further, the coding algorithms employed by manufacturers of automatic coders are typically proprietary. We have developed a method for <b>automatic</b> <b>coding</b> of pathology reports. Using this public domain autocoder, we have previously demonstrated that automatic SNOMED coding was superior to manual coding in several measurable categories, including the overall number of codes generated and the number of distinct code entities provided. In this report, we describe an algorithm that executes this strategy in the M-Technology environment...|$|E
40|$|University of Minnesota Ph. D. dissertation. February 2012. Major: History of Science and Technology. Advisor: Arthur L. Norberg. 1 {{computer}} file (PDF); vi, 342 page, appendices One-Two. Changes in computer programming methods were responses to specific stimuli, and that (contrary to much existing analyses) {{the development of}} programming methods does not fit an ideal of "progress. " I focus on the rise of two fundamental computing problems: complexity, or the proliferation of people and methods; and verification, which is the (in) ability to verify that a program functions as intended. Complexity and verification were the catalyst {{for the development of}} <b>automatic</b> <b>coding</b> systems but also increased exponentially as a result of <b>automatic</b> <b>coding</b> systems like FORTRAN and COBOL. These systems have English-like commands that simplify programming. The adoption of <b>automatic</b> <b>coding</b> systems opened up the programming field to more software engineers and allowed the creation of more elaborate software systems, creating ever more complexity in the discipline. I argue that since the introduction of <b>automatic</b> <b>coding</b> systems in the 1950 s, methodological changes and new programming languages have been attempts to solve long standing problems faced by programmers. Not, as the traditional insider narrative suggests, a steady evolution based on a better understanding of programming. In this dissertation, I focus on the changes motivated by two stimuli [...] complexity and verification...|$|E
40|$|Content {{analysis}} of political communication usually covers {{large amounts of}} material and makes the study of dynamics in issue salience a costly enterprise. In this article, we present a supervised machine learning approach for the <b>automatic</b> <b>coding</b> of policy issues, which we apply to news articles and parliamentary questions. Comparing computer-based annotations with human annotations shows that our method approaches the performance of human coders. Furthermore, we investigate the capability of an <b>automatic</b> <b>coding</b> tool, {{which is based on}} supervised machine learning, to generalize across contexts. We conclude by highlighting implications for methodological advances and empirical theory testing...|$|E
40|$|Suppose a {{software}} development manager is considering {{whether or not}} to add <b>automatic</b> <b>code</b> inspection to the current development process. The paper shows what properties of the current process to measure, and how to use these measurements {{in order to make a}} rational decision. Let P 1 denote the process whose steps are {write code, test program against requirements, find faults, fix faults} and P 2 be the process P 1 augmented by the single step {test code against guidelines}. The fractional effort actually saved by adopting P 2 rather than P 1 is given by dfic, where d, f and i are measurable properties of the process P 1, and c is the efficiency of the <b>automatic</b> <b>code</b> inspection tool employed. Over a wide range of realistic values for these quantities, <b>automatic</b> <b>code</b> inspection will save more than 10 % of the effort devoted to the process P 1 defined above...|$|R
40|$|<b>Automatic</b> <b>code</b> {{generation}} {{is a standard}} method in software engineering, improving the code reliability as well as reducing the overall development time. In hardware engineering, <b>automatic</b> <b>code</b> {{generation is}} utilized within a number of development tools, the integrated code generation functionality, however, is not exposed to developers wishing to implement their own generators. In this paper, VHDL Manipulation and Generation Interface (vMAGIC), a Java library to read, manipulate, and write VHDL code is presented. The basic functionality {{as well as the}} designflow is described, stressing the advantages when designing with vMAGIC. Two real-world examples demonstrate the power of code generation in hardware engineering...|$|R
5000|$|VisSim A {{visually}} programmed {{block diagram}} language supporting a fixed-point block set to allow simulation and <b>automatic</b> <b>code</b> generation of fixed-point operations. Both word size and radix point {{can be specified}} on an operator basis.|$|R
