1|22|Public
40|$|One {{of factors}} that support the success of {{teaching}} and learning is textbook. Textbook serves {{an important role in the}} teaching and learning process. Many novice teachers lack of the experience and confidence to prepare their own materials and rely on the textbook to ease their burden. Hence, a lot of teachers put a textbook as their first choice as it is relatively easy to find and commercially provided. Apart from considering as old-style teaching material, through a textbook, teacher feels so much ease when deals with a textbook rather than another material. This current research was aimed to describe the reading activities in Bahasa Inggris textbook for Tenth Grades of Senior High School based on the 2013 Curriculum published by Ministry of Education and Culture, and investigate the relevance of the reading materials in Bahasa Inggris textbook for Tenth Grades of Senior High School based on the 2013 Curriculum published by Ministry of Education and Culture to the 2013 Curriculum English Standard Competence. This research was conducted using qualitative research design. The object of this research is Bahasa Inggris textbook for tenth grade student of senior high school published by Ministry of Education and Culture. Furthermore, the researcher used document analysis as the research instrument. Based on the findings, there are three kinds of reading activities presented. Those are selective reading such as matching task and picture-cued task; interactive reading such as cloze task, short <b>answer</b> <b>scanning</b> task and ordering task; and extensive reading such as skimming and summarizing and responding task. Furthermore, the researcher found the reading materials in all chapters are relevant to the reading material of 2013 Curriculum English Standard Competence. The reading materials which are relevant to the 2013 Curriculum English Standard Competence are able to fulfill the purposes of the topic, language features, and social functions that are intended to be achieved by the students. Therefore, it is suggested that the author to apply more integrated skill in every chapter. It is seen that integrated skill would be effective, less consuming time and much helpful for the teacher in class...|$|E
60|$|Now as Rosamund {{prepared}} {{herself to}} <b>answer</b> Masouda <b>scanned</b> her face through her half-closed eyes. But whatever {{she may have}} felt within, it remained calm and cold {{as though it were}} cut in stone.|$|R
5000|$|In Batman: Arkham City, {{one of the}} Riddler's riddles {{references}} the Terrible Trio: [...] "Air, sea or land. It {{would be}} criminal to not hire these guys, wouldn't it?" [...] However, the Riddle is <b>answered</b> by <b>scanning</b> the Falcone Warehousing & Storage sign.|$|R
6000|$|... "Yes," [...] <b>answered</b> Benoni <b>scanning</b> his visitor, [...] "I knew Hilliel--a clever man, but one {{who fell}} into a trap at last, and I see that you are his son. Your face proves it; indeed, it might be Hilliel who stands before me." ...|$|R
40|$|The {{objective}} of this project was to automate the process of grading handwritten numerical answers in a classroom setting. The final program accepts a <b>scanned</b> <b>answer</b> sheet completed by the student along {{with a description of}} the correct answers and produces a detailed report describing the confidence of correctness for each answer. Computer vision techniques are used to automatically locate the locations of the <b>answers</b> in the <b>scan.</b> Each digit is then passed through a convolutional neural network to predict what was written by the student. The individual probabilities of each digit produced by the network are aggregated into a single score describing the model’s confidence in the correctness of the answer...|$|R
60|$|The hot blood surged to my forehead, for I {{understood}} what he meant, {{but that was a}} side issue, and, <b>answering</b> nothing, I <b>scanned</b> the slope for some way of ascent. There was none, and nothing without wings could have gained the valley. Ormond, too, realized this.|$|R
40|$|Here is the briefly {{discussion}} about web based learning system using Quick Response (QR) Technology in Learning Session. With the technology will let students have opportunity interactive with QR {{technology in the}} early stage. The aim of the proposed system is to bring alternative ways for kindergarten student to learn in an easy and attractive method during their kindergarten time so that they have interest to learn and engage students actively participate with it. They can have self-learning during at home by using smartphone to scan the QR codes which can automatically link to the shortened Uniform Resource Locator (URL) generator. Besides that, when students have problem with the assessment question, they can get <b>answer</b> through <b>scan</b> the QR codes and learn from there by itself...|$|R
40|$|Public {{libraries}} {{are currently}} the conduit for local, state, and federal funds {{used to support}} reference referral and other reference-related functions in California. Given potential funding constraints, this 5 -month study expanded its original scope [...] to assess the cost effectiveness and efficiency of the Bay Area Reference Center (BARC) and the Southern California <b>Answering</b> Network (<b>SCAN)</b> [...] to an examination of BARC and SCAN {{in the context of}} the existing reference referral system. This system involves local public libraries and 17 System Reference Centers to which reference questions are referred before they are passed along to BARC and SCAN. The study focused on: (1) defining the nature of reference-related services provided by BARC, SCAN, and the System Reference Centers; (2) describing the major differences in reference services between EARC and SCAN and those of the System Reference Centers (e. g., uni...|$|R
6000|$|... "Oh, of course," [...] Guy <b>answered,</b> still <b>scanning</b> the map in [...] "Bradshaw" [...] close. [...] "He couldn't {{have been}} there; but {{one likes to}} know. I think, indeed, to make sure, I'll {{telegraph}} to Tilgate. Naturally, when a man's got only one relation in the whole wide world--without being a sentimentalist--that one relation means a good deal in life to him. And Cyril and I are more to one another, of course, than most ordinary brothers." [...] He bit his thumb. [...] "Still, I can't imagine how he could possibly be there," [...] he went on, glancing at [...] "Bradshaw" [...] once more. [...] "You see, if he went to work, he'd have got out at Warnworth; and if he meant to come to town to consult his dentist, he'd have taken the 9.30 express straight through from Tilgate, which gets up to London twenty-five minutes earlier." ...|$|R
5000|$|Examination House, {{also known}} as Mahatma Jyotirao Phule Bhavan houses {{the office of the}} Controller of Examinations. Centralized {{assessment}} of answer books for various departments is carried out in a separate four-storey annex. Examination processes were made more efficient by the introduction of online delivery of question papers for examinations, and assessment of <b>answer</b> books by <b>scanning</b> at remote examination centres. The academic depository of the university was started in collaboration with CDSL in 2015. The university is the first university in the country to start an academic depository. https://www.cdslindia.com/downloads/PR%20%20UoM%20launch%20v1.1.pdf ...|$|R
40|$|Proximity searching {{consists}} in retrieving from a database those {{elements that are}} similar to a query. As the distance is usually expensive to compute, the goal is to use as few distance computations as possible to satisfy queries. Indexes use precomputed. distances among database elements to speed up queries. As such, a baseline is AESA, which stores all the distances among database objects, but has been unbeaten in query performance for 20 years. In this paper we show {{that it is possible to}} improve upon AESA by using a radically different method to select promising database elements to compare against the query. Our experiments show improvements of up to 75 % in document databases. We also explore the usage of our method as a probabilistic algorithm that may lose relevant answers. On a database of faces where any exact algorithm must examine virtually all elements, our probabilistic version obtains 85 % of the correct <b>answers</b> by <b>scanning</b> only 10 % of the database...|$|R
5000|$|Studies {{of public}} library {{services}} in California {{had shown that}} {{large parts of the}} state, particularly rural areas, were underserved. In response, a 1962 master plan called for the establishment of four levels of library services: local libraries, regional reference centers, tertiary reference centers covering larger regions, and as the fourth and final level, the State Library in Sacramento. The Bay Area Reference Center was established in August 1967 as a tertiary center, or [...] "source of last resort", as a collaboration between the San Francisco Public Library and the North Bay Cooperative Library System (NBCLS), a consortium of nine public library systems including 17 libraries in six counties north of San Francisco, with its headquarters in Santa Rosa. It was made possible by a federal grant under the 1964 Library Services and Construction Act; the initial grant was $750,735 for a two-year pilot project. A corresponding service was set up for Southern California, the Southern California <b>Answering</b> Network (<b>SCAN).</b>|$|R
40|$|A novel image {{processing}} based method to automatically mark printed multiple choice answer sheets is presented. This new method enables users to customize and print their own answer sheets and uses ordinary document scanner and computer {{to perform the}} marking as opposed to relying on expensive, specialized and restrictive answer sheets and optical mark recognition scanners. It can also annotate the <b>scanned</b> <b>answer</b> sheet images with feedback and send back to students via email, while compiling the assessment results for the assessor. Experiments show the proposed method can mark as fast as 1. 4 seconds per sheet with 100 % accuracy...|$|R
5000|$|Common Educational Proficiency Assessment (CEPA) {{is a set}} of locally-developed {{standardized}} tests used for admissions and placement by three federal institutions of higher education in the United Arab Emirates (Zayed University, the Higher Colleges of Technology, and UAEU). The tests are produced by the UAE Ministry of Higher Education and Scientific research as part of NAPO (National Admissions and Placement Office) and administered in the three federal institutions. [...] Around 17,000 grade 12 Emirati students take the tests each year.There are two CEPA exams. CEPA-English tests basic English proficiency, and CEPA-Math measures basic math skills. Both exams are administered in two formats: paper-based (with <b>scanned</b> <b>answer</b> sheets) and computer-based.|$|R
40|$|Malicious attackers often scan nodes in {{a network}} in order to {{identify}} vulnerabilities that they may exploit as they traverse the network. In this paper, we propose that the system generates a mix of true and false answers in response to scan requests. If the attacker believes that all scan results are true, then he will be on a wrong path. If he believes some scan results are faked, he would have to expend time and effort in order to separate fact from fiction. We propose a probabilistic logic of deception and show that various computations are NP-hard. We model the attacker’s state and show the effects of faked scan results. We then show how the defender can generate fake scan results in different states that minimize the damage the attacker can produce. We develop a Naive-PLD algorithm and a Fast-PLD heuristic algorithm for the defender to use and show experimentally that the latter performs well in a fraction of the run time of the former. We ran detailed experiments to assess the performance of these algorithms and further show that by running Fast-PLD off-line and storing the results, we can very efficiently <b>answer</b> run-time <b>scan</b> requests...|$|R
5000|$|The 9-12 course {{lessons are}} also {{provided}} by K12. CAVA {{high school is}} a good option for the extremely self-motivated student. Additionally, CAVA is a good option for student who would otherwise attend small rural schools that don't offer AP and other advanced classes. CAVA students {{are part of a}} large student body, but they rarely, if ever, meet any of the other students. The population is diverse of both race and culture, although like all online schools the population is more white than the general student body. [...] It is also a good option for the challenged student who has huge parental support. The pass rate and test scores of the CAVA students is well below state averages. The assignments are graded either by the computer for the multiple choice questions or by the teacher for the short answer questions, the longer essays or papers, and the laboratory reports. Students can either do the word processing online or can print out the questions and <b>answer</b> them, <b>scan</b> them and submit the scans or doc files into a 'drop box.' Because each student receives their own set of lab equipment and unlike in a conventional classroom, the labs must be completed at home without help and are limited to inexpensive items that are almost completely safe.|$|R
40|$|There are two {{objectives}} in this research. The {{first is to}} design appropriate science reading learning materials for Language Support Program for English Immersion Program students. The second is to identify characteristics of appropriate science reading learning materials for Language Support Program of Grade 7 in SMPN 2 Wonosari Gunungkidul Yogyakarta. This research is a Research and Development (R and D) study. The research subjects were students of Grade 7 of English Immersion Program in SMP N 2 Wonosari Gunungkidul Yogyakarta. The data were gathered from questionnaires, class observations, and interviews. The data were analyzed by using descriptive statistics and qualitative data analysis. In the research, designed materials consist of three units. The research findings indicate that the science reading learning materials are appropriate for the students {{as indicated by the}} average of the mean that is 3. 26 (good category). Each unit of the appropriate materials has two cycles (Mission 1 and Mission 2). The cycles are organized into unit title, objectives of unit, pre-reading tasks, while-reading tasks, after reading tasks, grammar tasks, recycling, discussion tasks, homework tasks, game, summary and vocabulary list. The research indicates that appropriate science reading learning materials are supported by the appropriate task components (goal, input activity, setting, learner role, and teacher role). The appropriate goals are giving an early description on whole topic of the unit, encouraging learner to acquire reading skills and to apply it, getting information from the text, and learning particular form of grammar. The appropriate inputs are authentic texts, simplified texts with pictures, tips related to reading skills, figures, and phonetics transcriptions. The appropriate activities are checking correct <b>answer,</b> matching, <b>scanning,</b> skimming, guessing, finding main idea, answering comprehension questions, group discussion, completing word puzzle. The appropriate settings are individual work, pair work, group discussion and project work. The appropriate learner’s role is as an active participant. The appropriate teacher’s roles are as facilitator, controller, assessor, and informer...|$|R
40|$|This thesis {{presents}} the {{hardware and software}} design of the PC based electronic checker systems for standardized entrance examinations. The system consists of PC, printer, sensor circuits, multiplexer. The PC including designed software manipulates {{the operation of the}} system and the printer. The printer is used as feeder of the answer sheets answer key. The sensor circuit senses the shaded area in answer sheet and keys. The feeding of the answer sheets is the same as feeding paper in a printer. Items are answered by marking specified areas of the examination sheet with the use of carbon pencil. The answer key sheet is to be scanned first and to be stored in the memory where the rest of the sheets to be scanned are being compared with. The shaded area of the scanned sheets as well as the results of the <b>scanned</b> <b>answer</b> sheets such as name, ID numbers and scores are displayed in the monitor and can be manipulated through the software, programmed in Turbo C++. The software is capable of sorting the names and ID numbers, searching records, ranking the scores, and also provides the database used. The developed system will be beneficial for every faculty or admission personnel at least to ease burden and save time for checking test paper...|$|R
40|$|Mindener Museum's Lapidarium {{incorporates}} {{a collection of}} stone work like reliefs, sculptures and inscriptions from different time epochs as advices of the city's history. These gems must be protected against environmental influences and deterioration. In advance of the measures a 3 D reconstruction and detailed documentation has to be taken. The framework to establish hard- and software must match the museum's infrastructure. Two major question will be <b>answered.</b> Are low-cost <b>scanning</b> devices like depth cameras and digital of the shelf cameras suitable for the data acquisition? Does the functionality of open source and freeware covers the demand on investigation and analysis in this application? The working chain described in this contribution covers the structure from motion method and the reconstruction with RGB-D cameras. Mesh processing such as cleaning, smoothing, poisson surface reconstruction and texturing will be accomplished with MeshLab. Data acquisition and modelling continues in structure analysis. Therefore the focus lies as well on latest software developments related to 3 D printing technologies. Repairing and finishing of meshes is a task for MeshMixer. Netfabb {{as a tool for}} positioning, dimensioning and slicing enables virtual handling of the items. On the Sketchfab web site one can publish and share 3 D objects with integration into web pages supported by WebGL. Finally if a prototype is needed, the mesh can be uploaded to a 3 D printing device provided by an online service...|$|R
40|$|Background: Magnetic Resonance Imaging (MRI) {{is one of}} today’s {{fastest growing}} imaging modalities, spurred in part by rapid {{advances}} in technology and important new applications in patient care. It was introduced in Western Jamaica in March 2005 at a non-hospital-based facility called North Coast Imaging MRI Service. Aims: The study examined the socio-demographics, accessibility and affordability of the services to patients. Materials and Method: A random sample of 100 patients was used and the research instrument was a questionnaire. The study was conducted between August and November 2008. Results: The findings of the study showed that {{majority of the respondents}} lived in rural areas and were within the age group 30 - 59 years. One-half of the respondents resided in St. James, were employed; earned more than US$ 1, 351. 00 per month and could afford the cost of the MRI procedure. More than one half {{of the respondents indicated that}} it took 15 – 30 minutes to be examined after arrival at the Centre; most (81 %) of the respondents indicated that the MRI procedure was adequately explained, and 99 % indicated that questions about the procedure were satisfactorily <b>answered.</b> The MRI <b>Scans</b> performed at the North Coast Imaging MRI Service showed an increase of 157. 49 % in 2006 when compared with 2005, and 70. 90 % in 2007 when compared with 2006. Our findings suggest that the number of MRI scans done at the North Coast Imaging MRI Service is likely to increase. Conclusion: Although most of the respondents were able to afford the procedure there are concerns about persons in the lower socio-economic group who are unable to afford expensive diagnostic imaging tests such as MRI scans. There is an urgent need for government-owned hospital-based MRI Units in Jamaica to offer lower cost MRI scans to the public...|$|R
40|$|The use of {{computers}} to interpret psychological tests is a 2 ̆ 2 hot 2 ̆ 2 topic, both within psychology and without. It is hot {{in the sense of}} giving rise to an increasing number of books and articles (e. g., Butcher, 1985, 1987; Eyde, 1987; Krug, 1987). It is hot in the sense of giving rise to an ever-increasing number of business enterprises (compare any recent APA Monitor with an issue from 1981). It is hot in the sense of capturing the attention of the news media (e. g., Petterson, 1983). And it is hot in the sense of giving rise to increasing controversy within psychology itself. In a Science editorial Matarazzo (1983) expressed concern lest computer-based test interpretations (CBTIs) {{fall into the hands of}} unqualified users, his bottom line being: 2 ̆ 2 Until more research establishes that the validity of application of these computer products by a health practitioner is not dependent on the practitioner 2 ̆ 7 s experience and training in psychometric science, such automated consultations should be restricted to [...] . qualified user groups. 2 ̆ 2 Matarazzo (1985, 1986) has continued to write in that same vein, causing others to take up the cudgels to defend CBTI (Ben-Porath 2 ̆ 6 Butcher, 1986; Fowler 2 ̆ 6 Butcher, 1986; Murphy, 1987). Lanyon (1984) in his chapter on personality assessment in the Annual Review of Psychology, indicated that he was concerned by the proliferation of CBTI systems: 2 ̆ 2 There is a real danger that the few satisfactory services will be squeezed out by the many unsatisfactory ones, since the consumer professionals are generally unable to discriminate among them [...] 2 ̆ 2 and 2 ̆ 2 [...] . lack of demonstrated program validity has now become the norm 2 ̆ 2 (p. 690). Finally the Subcommittee on Tests and Assessment of the American Psychological Association (APA) Committee on Professional Standards and the APA Committee on Psychological Tests and Assessment have developed standards for the area (American Psychological Association, 1986). I published an article describing attempts to establish the validity of CBTIs and made some suggestions regarding the shape future attempts might take (Moreland, 1985). The heat generated by the debate over CBTI seems not to have dissipated; however, some light seems to have been shed on the field since I was writing in 1984. In view of all this, a revision and expansion of my earlier efforts seems timely. SOME HISTORY The use of machines to process psychological test data is not a recent innovation (Fowler, 1985). A progression from hand scoring materials through a variety of mechanical and electronic 2 ̆ 2 scoring machines 2 ̆ 2 to the digital computer, has freed successive generations of beleaguered secretaries and graduate students from laborious hand scoring of objective tests. The first information concerning scoring machines for the Strong Vocational Interest Blank (SVIB) appeared in 1930 (Campbell, 1971). These initial machines were very cumbersome, involving the use of 1, 260 Hollerith cards to score each protocol. In 1946, Elmer Hankes, a Minneapolis engineer, built the analogue computer that was the first automatic scoring and profiling machine for the SVIB (Campbell, 1971). A year later, he adapted the same technology to the scoring of the Minnesota Multiphasic Personality Inventory (MMPI) (Dahlstrom, Welsh, 2 ̆ 6 Dahlstrom, 1972). In the mid 1950 s, E. F. Lindquist 2 ̆ 7 s Measurement Research Center in Iowa City began to use optical (<b>answer</b> sheet) <b>scanning</b> devices instead of card-based scoring equipment. In 1962, National Computer Systems linked an optical scanner with a digital computer and began scoring both the SVIB and the MMPI (Campbell, 1971; Dahlstrom et aI., 1972). Most automated test scoring still employs optical scanning/ digital computer technology and the number and types of tests scored by this method have grown exponentially during the last three decades. Though automated scoring is most easily accomplished for objective tests with a limited number of response alternatives, sophisticated computer programs have also been developed to score the narrative responses elicited by projective techniques (e. g., Gorham, 1967). Prior to the advent of these programs, extensive training, if not professional expertise, was required to score projective tests. Similar programs have also been developed to evaluate other types of complex verbal productions (e. g., Tucker 2 ̆ 6 Rosenberg, 1980). In addition to keeping nerves from becoming frayed, automated scoring frees psychologists to spend more time in other functions, such as psychotherapy, where computer technology is not so advanced (see, however, Colby, 1980). It also enables more individuals to undergo psychological assessment. Finally, though not completely immune from the slings and arrows of human imperfections (e. g., Fowler 2 ̆ 6 Coyle, 1968; Grayson 2 ̆ 6 Backer, 1972; Weigel 2 ̆ 6 Phillips, 1967), computer scoring appears to be more reliable than that done solely by humans (Greene, 1980, pp. 25 - 26; Klett, Schaefer, 2 ̆ 6 Plemel, 1985). A computer, once correctly programmed, will apply scoring rules with slavish consistency, whereas fatigue and other human frailties may render the psychologist, graduate student, or secretary inconsistent in the application of even the most objective scoring rules (Kleinmuntz, 1969) ...|$|R
40|$|Nowadays {{traditional}} traffic {{simulation models}} {{are becoming more}} complex and more detailed. Often policy questions do not require this level of details and needs faster answers than can be reach with traditional models. Of course traditional traffic simulation models are necessary for the evaluations of transportation alternatives. It is relevant to have next to these complex models, simpler models, such as quick scan tools. With quick scan tools the effect of measurements/alternatives of infrastructure related projects in the strategic and tactical phase can be calculated. Among other things, there is need for quick scan tools for the acceleration of the reconnaissance phase in the “Meerjarenprogramma Infrastructuur, Ruimte en Transport” (MIRT) projects. According to the Projectdirectie Sneller & Beter there are at this moment no suitable quick scan tools for the MIRTprojects. From these findings the central problem follows that in current practice there is need for suitable quick scan tools for fast and coarse evaluations of transportation alternatives. In this thesis {{the objective is to}} develop a suitable quick scan tool for fast and coarse evaluations of transportation alternatives. To develop a suitable quick scan tool, first the application and requirements of quick scan tools needs to be specified. Policy questions in the phase of mind setting and in the reconnaissance phase can be <b>answered</b> with quick <b>scan</b> tools. The application of quick scan tools is at a high level of time, space and travel behaviour simplification. The policy questions can be mostly answered by the calculation of measures focussed at spatial planning, price policy, mobility management, public transport and the changing and extending of infrastructure. These measures require certain output. Quick scan tools should provide at least information about mobility effects and a quick scan tool distinct from other tools and detailed models by also provide the economic, environmental and safety effects. One of the requirements of a quick scan tool is that it should fit the application. These and other requirements can be divided in functional, performance, quality, output and input requirements and wishes. A quick scan tool differs from detailed models by the short computation time (performance requirement) and the low effort of the end users according to the interviewees. Low effort requires easy applicability and simple input. Other functional requirements are that quick scan tools should at least determine the direct behavioural changes of a measure and be able to assess different alternatives. The quality requirements are transparency, fitting logical transportation relations, no conflicts with traffic flow theory and visualisation reliability of the output. The output should fit logical transport relations and should not be in contradiction with traffic flow theory. Also a quick scan tool should visualize the reliability of the output, because otherwise the tool will be used by the customers like the model can make accurate predictions. One of the output requirements is that a quick scan tool requires a clear visualisation, so a tool can be used easily. Further more simple input and wide support for the input is required. Next to this requirement, the desires of quick scan tools are the connection with existing models and not only calculated the effect on mobility, but also other traffic related effects, such as environmental, economic and safety effects. Developing a new quick scan tool requires the overview of the existing quick scan tools to know the additional value of a new quick scan tool/method. Seventeen tools in the Netherlands and the United States are investigated. All the tools were in conflict with at least one requirement. The ScenarioVerkenner, Quick filter, Fast Simple Model and eventually also the Mobiliteitsscan are tools that meet almost all the requirements except visualisation of the reliability of the output. A new quick scan tool should provide inside in the reliability of the output. The calculation of the measures for mobility management are hard to determine with the existing quick scan tools. Also from the existing quick scan tools, it could conclude that no tool at this moment can calculate reliable travel times and because of this economic effects. Besides a tool that provides insight in mobility, environment, economy and safety is more likely to succeed, because the calculation of other traffic related effects is a large advantage of a quick scan tool compared to detailed models. Also the high level of time, space and behaviour simplification is often missing in the existing quick scan tools. In a quick scan tool methods are used to meet the requirements of a quick scan tool. The methods can simplify the data of time, space and travel behaviour. Time simplification can be done by choosing some time periods or taking the sum of multiple time periods. For the spatial simplification, zone simplification, route, link and node simplification can be used. Simplification exists of the simplification, selection or reduction of data or model elements. Also Macroscopic Fundamental Diagrams (MFD) can show the network performance. The MFD is a graph that reflects the outflow of a network compared to the accumulation. Simplified methods can be used to model the travel behaviour; trip generation, modal split, period of day and route assignment. Next to the simplification techniques some other methods can be used in quick scan tools, such as the incremental approach, elasticities, rules of thumps and demand and supply curves. With the incremental approach only the difference between the new situation and the reference scenario will be calculated without using an integral new equilibrium calculation. Another option is to calculated only the effects on roads with a certain traffic condition, such as congested roads. Elasticities and rules of thumb could make assumptions and so less calculation have to be made during the usage of a quick scan tool. With demand and supply curves the equilibrium between price and demand can be calculated. From the application, requirements, existing tools opportunities and methods for the development of quick scan tools or method for fast and coarse evaluations of transportation alternatives follow. The high level of simplification can be reached by corridor models. Corridor models are models in which cities/regions are visualized by dots and vectors represent the flows between the dots. A corridor model requires simple input. Another opportunity that will decrease the computation time enormously is spatial simplification based on traffic states. This innovative method offers the chance to develop a quick scan tool that meets the requirements. In this research the method of spatial simplification based on traffic states is developed. With this method the effect of measures that affects the total network or measures that effects changes in a specific area can be calculated. For the calculation of the measures that affects the total network, only the effect of the measure on the amount of trips is required. This can be determined by elasticities. The method works with an approximation of traffic assignment by interpolation between the traffic flows on a link for two assignments. When using the tool the choice can be made to simulate only certain traffic states. With this link categorization the high level of simplification can be reached. For the measures that affect a specific area, on forehand the advisor needs to define this area and assign the traffic from and to the area, so the distribution is known. With interpolation the effect of the measures in the area will be determined. A disadvantage of the method is that measures that affect certain links cannot be calculated, because this requires a new equilibrium. The developed method meets the requirements. The method can be used under conditions for spatial planning, pricing policy, mobility management and the improvements of public transport. A disadvantage of the method is that it requires a detailed underlying model, so it could not be used when little data is available. The model is assessed for spatial planning and pricing policy in the Nationaal Verkeers Model 2. 0 (NVM 2. 0). The categorization is divided in congested links, critical links or insignificant links. The computation time is less than ten seconds for the calculation of the congested links and 30 seconds for all the links instead of 5000 seconds with the traditional assignment. So the computation time is short and the calculation of only the congested links can be used when visiting a customer and direct results are required. When an advisor is writing a report in the office, the calculation of the other links can also be interesting, but the high level of simplification will be reached by the link categorisation. Certainly the implementation in a quick scan tool will require some extra time to visualize the results. For the implementation of the method in a quick scan tool, some recommendations are made. To calculate also the travel times correctly, another model than the NVM 2. 0, should be used. STAQ, the static assignment model of Goudappel Coffeng BV with the calculation of the effect of congestion and spillback, can be used. For a complete suitable quick scan tool the effect of all the measures should be calculated. The calculation of the effect on the link loads can be calculated with the same scripts as for spatial planning and pricing policy. The used linear function works in the NVM 2. 0. It could be that another function will fit better the reality. So by the implementation in STAQ, the recommendation is to investigate this function. Also the opportunities for the calculation of measures that affects a certain link should be investigated. Overall the method of spatial simplification based on traffic condition with interpolation is a good basis of a suitable quick scan tool for fast and coarse evaluations of transportation alternatives. Transport & PlanningTransport & PlanningCivil Engineering and Geoscience...|$|R

