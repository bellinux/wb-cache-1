7|2425|Public
40|$|Understanding how {{contingencies}} work is at {{the heart}} of a behavior analysis, yet the task is more than daunting. Some schedule arrange-ments may be easy to describe, but the behaviors resulting from their application may be very hard to understand. We are still trying to understand performance features of a fixed-interval schedule and that was first investigated by Skinner more than 70 years ago! Feedback functions are a way to <b>approach</b> <b>schedule</b> performance by considering how the environment feeds back the effects of consequences, given a particular behavior-conse-quence arrangement. Baum’s (1989) paper is an invaluable orienta-tion to this rather difficult, but essential concep...|$|E
40|$|Contract DE-AC 07 - 05 ID 14517 iii This report {{identifies}} {{and compares}} onsite and offsite disposal alternatives for {{the disposal of}} remote-handled low-level waste generated by the Idaho National Laboratory and its tenants. Each alternative addresses the disposal path for all remote-handled low-level waste types over the period of interest. The alternatives are compared using cost, risk, and complexity discriminators {{to arrive at a}} recommended <b>approach.</b> <b>Schedule</b> alignment with disposal needs is addressed to ensure that all waste types are managed appropriately. The recommended alternative for disposal of remote-handled low-level waste based on this analysis is to build a disposal facility at the Idaho National Laboratory Site. i...|$|E
40|$|Correspondence {{issued by}} the Government Accountability Office with an {{abstract}} that begins "The United Nations (UN) headquarters in New York City neither conforms to current building codes nor meets UN technology or security requirements. As the UN's host country and largest contributor, the United States has a substantial interest {{in the success of}} the Capital Master Plan (CMP), a project to renovate the complex. In this update, GAO reviewed the following key areas: renovation <b>approach,</b> <b>schedule,</b> cost, funding, risk management, project progress, procurement, and oversight. To perform this work, GAO reviewed UN documents and met with officials from the CMP office and other UN departments. To assess oversight and monitoring, GAO reviewed UN documents and oversight reports and interviewed UN officials from the Office of Internal Oversight Services (OIOS) and officials from the U. S. Department of State (State). ...|$|E
40|$|The paper {{presents}} a static process <b>scheduling</b> <b>approach</b> as a front-end to hardware-software cosynthesis of small embedded systems which allows global system optimiza-tion. Unlike earlier <b>approaches,</b> <b>scheduling</b> is executed before hardware definition assuming scalable system per-formance. Scheduling supports process communication and external timing requirements. We explain the algo-rithm and give results using an example. ...|$|R
40|$|We {{address the}} area of {{scheduling}} and {{the differences between the}} way operations research and artificial intelligence <b>approach</b> <b>scheduling.</b> We introduce the concept of constraint programming, and describe how operations research techniques can be integrated in constraint programming. Finally, we give a short overview of the results obtained with our approach...|$|R
50|$|Bloomington Jefferson High School was {{constructed}} {{to support a}} new curriculum offering. This curriculum used a Modular <b>Scheduling</b> <b>approach</b> to <b>scheduling,</b> based loosely on a lecture attendance and test attendance policy. Students were required to attend {{a certain number of}} class lectures a week, as well as test-times.|$|R
40|$|This paper {{provides}} an overview of NASA's focused hypersonic technology program, i. e. the Hyper-X program. This program is designed to move hypersonic, air breathing vehicle technology from the laboratory environment to the flight environment, the last stage preceding prototype development. This paper presents some history leading to the flight test program, research objectives, <b>approach,</b> <b>schedule</b> and status. Substantial experimental data base and concept validation have been completed. The program is concentrating on Mach 7 vehicle development, verification and validation in preparation for wind tunnel testing in 1998 and flight testing in 1999. It is also concentrating on finalization of the Mach 5 and 10 vehicle designs. Detailed evaluation of the Mach 7 vehicle at the flight conditions is nearing completion, and will provide a data base for validation of design methods once flight test data are available...|$|E
40|$|This report {{identifies}} {{and compares}} on-site and off-site disposal {{options for the}} disposal of contract-handled and remote-handled low-level waste generated by the Idaho National Laboratory and its tenants. Potential disposal options are screened for viability by waste type resulting in {{a short list of}} options for further consideration. The most crediable option are selected after systematic consideration of cost, schedule constraints, and risk. In order to holistically address the approach for low-level waste disposal, options are compiled into comprehensive disposal schemes, that is, alternative scenarios. Each alternative scenario addresses the disposal path for all low-level waste types over the period of interest. The alternative scenarios are compared and ranked using cost, risk and complexity to arrive at the recommended <b>approach.</b> <b>Schedule</b> alignment with disposal needs is addressed to ensure that all waste types are managed appropriately. The recommended alternative scenario for the disposal of low-level waste based on this analysis is to build a disposal facility at the Idaho National Laboratory Site...|$|E
40|$|This paper {{presents}} a new power-aware software pipelining method for superscalar or VLIW architectures which can minimize the power consumption of software pipelined loops without sacrificing performance. This method {{is motivated by}} the following observations: (1) functional units in modern architectures are fully pipelined; (2) {{there are plenty of}} instructions in a loop which are not on the critical cycle. Traditional software pipelining <b>approach</b> <b>schedule</b> instructions as long as the resource requirement is fulfilled and this applies to both instructions on the critical cycle, and those are not. However, intuitively from the angle of power reduction, it may be reasonable to delay the issue of certain non-critical instructions so they can be issued in the available empty slot of a pipelined functional unit at a later cycle without the penalty of performance degradation. One interesting questions is: if such pipelined function units can be utilized, can we reduce the total number of function units in use, thus provide an opportunity of power reduction? In this paper we formulate the power consumption problem in software pipelined loops as a integer linear programming (ILP) problem. With this model the software pipelined schedule and the pipelined functional unit usage in each cycle in the repetitive pattern are modeled precisely, an...|$|E
5000|$|Operant {{conditioning}} and reinforcement: this implies a behaviourist <b>approach</b> using <b>schedules</b> of reinforcement to [...] "shape behaviour".|$|R
40|$|Providing {{efficient}} {{support for}} interactive operations such as fast-forward and fast-backward {{is essential in}} video-on-demand and other multimedia server systems. In this paper, we present two basic <b>approaches</b> for <b>scheduling</b> interactive operations, the prefetching approach and the grouping <b>approach.</b> <b>Scheduling</b> algorithms are presented for both fine-grain and coarse-grain data blocks. These algorithms can precisely schedule video streams for both normal playout and interactive operations. keywords [...] - parallel video servers, real-time scheduling, interactive operations, fast forward, Qualityof -Service. 1. Introduction There is an increasing demand on capacity of video servers in large-scale video-on-demand systems [8, 1]. Interactive scan operations, such as fast-forward and fast-backward 1 are desirable features in video-ondemand and other multimedia servers. It is necessary to provide efficient supports for interactive operations with Quality-of-Service (QoS) guarantee. There can be [...] ...|$|R
40|$|Federated {{scheduling}} is {{a promising}} <b>approach</b> to <b>schedule</b> parallel real-time tasks on multi-cores, where each heavy task exclusively executes {{on a number}} of dedicated processors, while light tasks are treated as sequential sporadic tasks and share the remaining processors. However, federated scheduling suffers resource waste since a heavy task with processing capacity requirement x + ϵ (where x is an integer and 0 < ϵ < 1) needs x + 1 dedicated processors. In the extreme case, almost half of the processing capacity is wasted. In this paper we propose the semi-federate <b>scheduling</b> <b>approach,</b> which only grants x dedicated processors to a heavy task with processing capacity requirement x + ϵ, and schedules the remaining ϵ part together with light tasks on shared processors. Experiments with randomly generated task sets show the semi-federated <b>scheduling</b> <b>approach</b> significantly outperforms not only federated scheduling, but also all existing <b>approaches</b> for <b>scheduling</b> parallel real-time tasks on multi-cores...|$|R
40|$|In {{the past}} year the Yucca Mountain Site Characterization Project has {{implemented}} a new Program Approach to the licensing process. The Program Approach suggests a step-wise approach to licensing in which the early phases will require less site information than previously planned and necessitate a lesser degree {{of confidence in the}} longer-term performance of the repository. Under the Program Approach, the thermal test program is divided into two principal phases: (1) short-term in situ tests (in the 1996 to 2000 time period) and laboratory thermal tests to obtain preclosure information, parameters, and data along with bounding information for postclosure performance; and (2) longer-term in situ tests to obtain additional data regarding postclosure performance. This effort necessitates a rethinking of the testing program because the amount of information needed for the initial licensing phase is less than previously planned. This document proposes a revised and consolidated in situ thermal test program (including supporting laboratory tests) that is structured {{to meet the needs of}} the Program Approach. A customer-supplier model is used to define the Project data needs. These data needs, along with other requirements, were then used to define a set of conceptual experiments that will provide the required data within the constraints of the Program <b>Approach</b> <b>schedule.</b> The conceptual thermal tests presented in this document represent a consolidation and update of previously defined tests that should result in a more efficient use of Project resources. This document focuses on defining the requirements and tests needed to satisfy the goal of a successful license application in 2001, should the site be found suitable...|$|E
40|$|This chapter {{involves}} a <b>scheduling</b> <b>approach</b> for cross-domain scientific workflow execution with time-related QoSevaluation. Generally, scientific workflow execution often spans self-managing administrative domains to achieve global collaboration advantage. In practice, it is infeasible for a domain-specific application to disclose its process details for privacy or security reasons. Consequently, it is a challenging endeavor to coordianate scientific workflows and its distributed domain-specific applications for service invocation perspective. Therefore, in this chapter, the authors aim at proposing a collaborative <b>scheduling</b> <b>approach,</b> with time-related QoS evaluation, for navigating cross-domain collaboration. Under this collaborative <b>scheduling</b> <b>approach,</b> a private workflow fragment could maintain temporal consistency {{with a global}} scientific workflow in resource sharing and task enactments. Furthermore, an evaluation is presented to demonstrate the <b>scheduling</b> <b>approach...</b>|$|R
30|$|Different SP <b>scheduling</b> <b>approaches</b> for {{interference}} mitigation.|$|R
40|$|In this thesis, an {{intuitive}} <b>approach</b> to determine <b>scheduling</b> and allocation of a behavioral algorithm {{defined by a}} netlist is presented. In this <b>approach,</b> <b>scheduling</b> {{is based on a}} weighted list scheduling where operations have the longest critical path are scheduled first. The component allocations are resorted to the PDCPA algorithm which focus on making efficient and correct clusters for hardware reuse problem. Several constraints are used in order to ensure the causality of processes and prevent conflicts of hardware components. This approach can give the total number of control steps and the number of registers and multiplexers in detail. Hence, designers obtain useful information from it and can make trade-offs between different resource conditions. The program is implemented in MATLAB programming environment and provides parts of behavioral synthesis to facilitate the whole synthesis procedure...|$|R
40|$|In most {{practical}} environments, scheduling {{is an ongoing}} reactive process where evolving and changing circumstances continually force reconsideration and revision of pre-established plans. Scheduling research has traditionally ignored this "process view" of the problem, focusing instead on optimization of performance under idealized assumptions of environmental stability and solution executability. In this paper, we present work aimed at the development of reactive <b>scheduling</b> systems, which <b>approach</b> <b>scheduling</b> as a problem of maintaining a prescriptive solution over time, and emphasize objectives (e. g., solution continuity, system responsiveness) which relate directly to effective {{development and use of}} schedules in dynamic environments. We describe OPIS, a scheduling system designed to incrementally revise schedules in response to changes to solution constraints. OPIS implements a constraint-directed <b>approach</b> to reactive <b>scheduling.</b> Constraint analysis is used to prioritize outstandin [...] ...|$|R
5000|$|Cost {{of delay}} (CD3 Prioritisation), an <b>approach</b> for <b>scheduling</b> work through a scarce {{resource}} that maximises Return on Investment. (CD3 = CDx3 from Cost of Delay Divided by Duration).|$|R
40|$|The paper {{presents}} a static process <b>scheduling</b> <b>approach</b> as a front-end to hardware-software cosynthesis of small embedded systems which allows global system optimization. Unlike earlier <b>approaches,</b> <b>scheduling</b> is executed before hardware definition assuming scalable system performance. Scheduling supports process communication and external timing requirements. We explain the algorithm and give results using an example. 1 Introduction Process scheduling {{is a well}} known problem in embedded system design. In current approaches, the hardware-software architecture is widely known at compile time. With the advent of hardware-software co-synthesis, hardware-software partitioning can be moved to a very late design stage (late binding) because changing system descriptions and generating and modifying hardwaresoftware architectures has become much easier. This {{is very much like}} the automation of physical layout has reduced the cost of netlist changes and logic synthesis has simplified RT-level [...] ...|$|R
40|$|A brief {{overview}} of the NASA-sponsored HSCT propulsion system studies is presented that includes objectives, <b>approach,</b> <b>schedules,</b> and a summary of interim results highlighting the NASA in-house studies. Seven propulsion system concepts have been considered to date and comparatively evaluated on a first-order basis using takeoff gross weight (TOGW) as the main discriminator. Only two concepts have been screened out thus far and {{it is apparent that}} TOGW is not a strong discriminator. However, the first-order screening process did not account for differences in propulsion installation effects or climb-noise suppression penalties-both of which may strongly influence the screening process...|$|R
40|$|In {{this paper}} we {{consider}} a sports league scheduling problem which occurs in planning non-professional table-tennis leagues. The problem consists {{in finding a}} schedule for a time-relaxed double round robin tournament where different hard and soft constraints {{have to be taken}} into account. We model the problem as an integer linear program and a multi-mode resource-constrained project scheduling problem, respectively. Based on the second model a heuristic solution algorithm is proposed, which proceeds in two stages using local search and genetic algorithms. Computational results show the efficiency of the <b>approaches.</b> <b>Scheduling</b> Sports league Resource-constrained project scheduling problem Partially renewable resources Genetic algorithm...|$|R
40|$|In this chapter, {{we review}} a few {{important}} concepts from Grid computing related to scheduling problems and their resolution using heuristic and meta-heuristic <b>approaches.</b> <b>Scheduling</b> problems {{are at the}} heart of any Grid-like computational system. Different types of scheduling based on different criteria, such as static vs. dynamic environment, multi-objectivity, adaptivity, etc., are identified. Then, heuristics and meta-heuristics methods for scheduling in Grids are presented. The chapter reveals the complexity of the scheduling problem in Computational Grids when compared to scheduling in classical parallel and distributed systems and shows the usefulness of heuristics and meta-heuristics approaches for the design of efficient Grid schedulers...|$|R
40|$|The vast {{majority}} of the research efforts in project scheduling assume complete information about the scheduling problem to be solved and a static deterministic environment within which the pre-computed baseline schedule will be executed. However, in the real world, project activities are subject to considerable uncertainty, that is gradually resolved during project execution. In this survey we review the fundamental <b>approaches</b> for <b>scheduling</b> under uncertainty: reactive scheduling, stochastic project scheduling, stochastic GERT network scheduling, fuzzy project scheduling, robust (proactive) scheduling and sensitivity analysis. We discuss the potentials of these <b>approaches</b> for <b>scheduling</b> projects under uncertainty. Management; Project management; Robustness; Scheduling; Stability;...|$|R
40|$|This paper {{addresses}} a practical scheduling problem arising in the packaging department of a pharmaceutical industrial plant. The problem is modeled as a multi-purpose machine scheduling problem with setup and removal times, release and due dates and additional constraints {{related to the}} scarce availability of tools and human operators. The objective functions are minimization of makespan and maximum tardiness in lexicographic order. Representing a solution with a directed graph allows us to devise an effective tabu search algorithm to solve the problem. Computational experiments, carried on real and randomly generated instances, show {{the effectiveness of this}} <b>approach.</b> <b>Scheduling</b> Packaging Tabu search Pharmaceutical industry...|$|R
40|$|In this paper, {{we propose}} a {{scalable}} and fault-tolerant job scheduling framework for grid computing. The proposed framework loosely couples a dynamic job <b>scheduling</b> <b>approach</b> with the hybrid replications <b>approach</b> to <b>schedule</b> jobs efficiently {{while at the}} same time providing fault-tolerance. The novelty of the proposed framework is that it uses passive replication approach under high system load and active replication approach under low system loads. The switch between these two replication methods is also done dynamically and transparently...|$|R
40|$|Real-time {{co-ordination}} is {{an emerging}} approach to operational engineering management aimed at being more comprehensive and widely applicable than existing <b>approaches.</b> <b>Schedule</b> management {{is a key}} characteristic of operational co-ordination related to managing the planning and dynamic assignment of tasks to resources, and {{the enactment of the}} resulting schedules, throughout a changeable process. This paper presents the application of an agent-oriented system, called the Design Co-ordination System, to an industrial case study in order to demonstrate the appropriate use of a genetic algorithm for the purpose of real-time scheduling. The application demonstrates that real-time co-ordinated scheduling can provide significant reductions in time to complete the computational design process...|$|R
30|$|Achieving {{optimality}} in scheduling tasks over computing nodes in {{cloud computing}} is {{the aim of}} all researchers interested in both scheduling and cloud. Balancing between throughput, waiting time and response time may provide a way to <b>approach</b> <b>scheduling</b> optimality but on another level it may causes long tasks starvation. Most of the previous studies have concentrated only on one side either starvation or throughput but not both so {{in this study we}} have tried to develop a hybrid algorithm based on SJF and dynamic quantum RR, while concentrating on splitting the ready queue into to sub-queues Q 1 for short tasks and Q 2 long tasks.|$|R
40|$|Applications {{that use}} {{parallel}} TCP streams to increase throughput must multiplex and demultiplex data blocks over {{a set of}} TCP streams transmitting on one or more network paths. When applications use the obvious round robin scheduling algorithm for multiplexing data blocks, differences in transmission rate between individual TCP streams can lead to significant data block reordering. This forces the demultiplexing receiver to buffer out-of-order data blocks, consuming memory and potentially causing the receiving application to stall. This paper describes a new adaptive weighted <b>scheduling</b> <b>approach</b> for multiplex-ing data blocks over a set of parallel TCP streams. Our new <b>scheduling</b> <b>approach,</b> compared with the <b>scheduling</b> <b>approached</b> used by GridFTP, reduces reordering of data blocks between individual TCP streams, maintains the ag-gregate throughput gains of parallel TCP, consumes less re-ceiver memory for buffering out-of-order packets, and de-livers smoother application goodput. We demonstrate the improved characteristics of our new <b>scheduling</b> <b>approach</b> using data transmission experiments over real and emu-lated wide-area networks. 1. Introduction an...|$|R
40|$|The {{acoustic}} propagation speed under water poses significant {{challenges to the}} design of underwater sensor networks and their medium access control protocols. Similar to the air, scheduling transmissions under water has significant impact on throughput, energy consumption, and reliability. In this paper we present an extended set of simplified scheduling constraints which allows easy scheduling of underwater acoustic communication. We also present two algorithms for scheduling communications, i. e. a centralized <b>scheduling</b> <b>approach</b> and a distributed <b>scheduling</b> <b>approach.</b> The centralized approach achieves the highest throughput while the distributed approach aims to minimize the computation and communication overhead. We further show how the centralized <b>scheduling</b> <b>approach</b> can be extended with transmission dependencies to reduce the end-to-end delay of packets. We evaluate the performance of the centralized and distributed <b>scheduling</b> <b>approaches</b> using simulation. The centralized approach outperforms the distributed approach in terms of throughput, however we also show the distributed approach has significant benefits in terms of communication and computational overhead required to setup the schedule. We propose a novel way of estimating the performance of <b>scheduling</b> <b>approaches</b> using the ratio of modulation time and propagation delay. We show the performance is largely dictated by this ratio, although the number of links to be scheduled also has a minor impact on the performance. ﻿</div...|$|R
50|$|After its {{original}} release Pordata {{had a second}} development stage, with the new European database. New themes and different <b>approaches</b> are <b>scheduled</b> to complete the already existing ones, such as the database expansion to the Portuguese regions and municipalities.|$|R
40|$|This paper {{explores the}} problem of {{dynamically}} scheduling large scale applications over wide area networks and then proposes an adaptive scheduling algorithm to provide quality of service. Our adaptive algorithm takes into account unexpected events and priority fluctuations and gives high priority to jobs with low probability of failure. Experimental {{results show that the}} new <b>approach</b> outperforms traditional <b>scheduling</b> <b>approaches</b> in grid computing environments. 1...|$|R
40|$|Previous <b>approaches</b> for <b>scheduling</b> {{a league}} with {{round-robin}} and divisional tournaments involved decomposing the problem into easier subproblems. This <b>approach,</b> used to <b>schedule</b> the top Swedish handball league Elitserien, reduces the problem complexity but {{can result in}} suboptimal schedules. This paper presents an integrated constraint programming model that allows to perform the scheduling in a single step. Particular attention is given to identifying implied and symmetry-breaking constraints that reduce the computational complexity significantly. The experimental evaluation of the integrated approach takes considerably less computational effort than the previous approach...|$|R
3000|$|The paper {{entitled}} [...] "Run-time HW/SW scheduling of {{data flow}} applications on reconfigurable architectures" [...] by F. Ghaffari et al. presents an efficient dynamic and run-time Hardware/Software <b>scheduling</b> <b>approach.</b> This <b>scheduling</b> heuristic consists in mapping on line the different tasks {{of a highly}} dynamic application {{in such a way}} that the total execution time is minimized. On several image processing applications, the scheduling method is applied. The presented experiments include simulation and synthesis results on a Virtex V-based platform. These results show a better performance against existing methods.|$|R
40|$|Most {{productions}} scheduling {{problems in}} the planning of operations or worksdo not consider the factor of activity associated with the project activities ofindividual agents. Based on the elements of an open (agreed) managementand to promote the theory of active systems, the article presents speciﬁcation and decomposition of the new task scheduling, which is a fundamental difference from earlier in the literature (including the previously published works ofauthors [3, 4, 5]) {{is the use of}} matching elements in target functions synthesisschedules. Evolution of <b>approaches</b> <b>scheduling</b> involves the transition froma purely technical aspects of the synthesis to the semantic and technicalsystems, taking into account the functioning of the «human factor» in theface of considerable uncertainty...|$|R
40|$|In {{this paper}} we survey {{computational}} models for Grid scheduling problems and their resolution using heuristic and meta-heuristic <b>approaches.</b> <b>Scheduling</b> problems {{are at the}} heart of any Grid-like computational system. Different types of scheduling based on different criteria, such as static versus dynamic environment, multi-objectivity, adaptivity, etc., are identified. Then, heuristic and meta-heuristic methods for scheduling in Grids are presented. The paper reveals the complexity of the scheduling problem in Computational Grids when compared to scheduling in classical parallel and distributed systems and shows the usefulness of heuristic and meta-heuristic approaches for the design of efficient Grid schedulers. We also discuss on requirements for a modular Grid scheduling and its integration with Grid architecture...|$|R
40|$|Abstract—This paper {{studies the}} {{automatic}} scheduling prob-lem at the Canadian national synchrotron facility Canadian Light Source (CLS). An automatic scheduling tool {{needs to be}} developed to replace the current manual <b>scheduling</b> <b>approach</b> for <b>scheduling</b> the experiments {{on a set of}} beamlines- the resources that generate high-intensity X-rays for use in many kinds of scientific experiments. We present a Integer programming model for this scheduling problem by formulating it as a problem of unrelated and paralleled machines with partially overlapping capabilities. We present a heuristic based approach that can save computation time by pruning the search space. We compare our method against the base line approach, CPLEX implemented Integer programming with different testing data sets generated. The results show that the heuristic approach runs faster than the CPLEX Integer programming approach at the cost of a less optimal solution. The obvious advantage is that the automatic <b>scheduling</b> <b>approach</b> can handle more scheduling conditions and constraints than human beings are able to handle manually and reach optimal solutions. As we know, this is the first attempt to propose an automatic <b>scheduling</b> <b>approach</b> for synchrotron facilities like CLS around the world...|$|R
