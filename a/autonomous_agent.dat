882|4279|Public
25|$|In Beyond Freedom and Dignity, Skinner {{suggests}} that a technology of behavior could help {{to make a better}} society. We would, however, have to accept that an <b>autonomous</b> <b>agent</b> is not the driving force of our actions. Skinner offers alternatives to punishment, and challenges his readers to use science and modern technology to construct a better society.|$|E
25|$|Others take a {{systemic}} viewpoint {{that does not}} necessarily depend on molecular chemistry. One systemic definition of life is that living things are self-organizing and autopoietic (self-producing). Variations of this definition include Stuart Kauffman's definition as an <b>autonomous</b> <b>agent</b> or a multi-agent system capable of reproducing itself or themselves, and of completing at least one thermodynamic work cycle. This definition is extended by the apparition of novel functions over time.|$|E
500|$|Bill Tomlinson used a more {{original}} {{approach to}} the problem. He devised {{a system in which}} the camera is an <b>autonomous</b> <b>agent</b> with its own personality. The style of the shots and their rhythm will be affected by its mood. Thus a happy camera will [...] "cut more frequently, spend more time in close-up shots, move with a bouncy, swooping motion, and brightly illuminate the scene".|$|E
5000|$|The ACM/SIGAI <b>Autonomous</b> <b>Agents</b> Research Award recognizes {{researchers}} in <b>autonomous</b> <b>agents</b> whose current work {{is an important}} influence on the field. The award is an official ACM award, funded by an endowment created by ACM SIGAI from the proceeds of previous <b>Autonomous</b> <b>Agents</b> conferences. Prior to 2014, it {{was known as the}} ACM/SIGART <b>Autonomous</b> <b>Agents</b> Award. Winners include the following: ...|$|R
40|$|Artificial neural {{networks}} {{have been successfully}} used in many technical applications. They are also important tools for the control of <b>autonomous</b> <b>agents.</b> The major goal of research on <b>autonomous</b> <b>agents</b> is to study intelligence {{as the result of}} a system environment interaction, rather than understanding intelligence on a computational level. In contrast to other applications, <b>autonomous</b> <b>agents</b> might not distinguish between a learning and a performance phase; they have to continuously learn while they are behaving in their environment. Thus, a neural network for <b>autonomous</b> <b>agents</b> should feature incremental learning, should not exhibit overlearning and should not suffer from a high VC dimension. The review presented in this paper reveals that most existing models are not ideally suited for <b>autonomous</b> <b>agents.</b> The main goals of this paper are (1) to discuss the <b>autonomous</b> <b>agents</b> perspective, (2) to identify important properties of {{neural networks}} for <b>autonomous</b> <b>agents,</b> and (3), very impo [...] ...|$|R
5000|$|<b>Autonomous</b> <b>Agents</b> and Multi-Agent Systems is a peer-reviewed {{scientific}} journal {{covering the}} study of <b>autonomous</b> <b>agents</b> and multi-agent systems.|$|R
50|$|Actin {{software}} {{supports the}} following communication protocols for connecting the human operator (or <b>autonomous</b> <b>agent</b> software control system) to physical robotic hardware: Modbus, EtherCAT, CANopen, Serial, Data Distribution Service, UDP, and TCP.|$|E
5000|$|An <b>autonomous</b> <b>agent</b> is an {{intelligent}} agent operating on an owner's behalf {{but without any}} interference of that ownership entity. An intelligent agent, however appears according to a multiply cited statement in a no longer accessible IBM white paper as follows: ...|$|E
50|$|The {{main issue}} of MIBE {{architecture}} consists {{in defining the}} boundaries of the state-space by shaping the motivational structure (i.e.: tuning the drive-generation functions and/or their learning algorithms) so that the <b>autonomous</b> <b>agent</b> performs the right behavior for each robot+environment state.|$|E
50|$|The International Conference on <b>Autonomous</b> <b>Agents</b> and Multi-Agent Systems or AAMAS is {{the leading}} {{scientific}} conference for research {{in the areas of}} artificial intelligence, <b>autonomous</b> <b>agents,</b> and multiagent systems. It is annually organized by a non-profit organization called the International Foundation for <b>Autonomous</b> <b>Agents</b> and Multiagent Systems (IFAAMAS).|$|R
5000|$|... 2007 ACM/SIGART <b>Autonomous</b> <b>Agents</b> Research Award. The {{award is}} given by ACM SIGART, in {{collaboration}} with IFAAMAS, for excellence in {{research in the area}} of <b>autonomous</b> <b>agents</b> ...|$|R
40|$|This paper {{demonstrates}} the potential role of <b>autonomous</b> <b>agents</b> in economic theory. We first dispatch <b>autonomous</b> <b>agents,</b> built by genetic programming, to double auction markets. We then study the bargaining strategies discovered by them, {{and from there}} an autonomous-agent-inspired economic theory {{with regard to the}} optimal procrastination is derived. Agent-Based Double Auction Markets, <b>Autonomous</b> <b>Agents,</b> Genetic Programming, Bargaining Strategies, Monopsony, Procrastination Strategy...|$|R
50|$|In Beyond Freedom and Dignity, Skinner {{suggests}} that a technology of behavior could help {{to make a better}} society. We would, however, have to accept that an <b>autonomous</b> <b>agent</b> is not the driving force of our actions. Skinner offers alternatives to punishment, and challenges his readers to use science and modern technology to construct a better society.|$|E
50|$|FANN was {{originally}} written by Steffen Nissen. Its original implementation {{is described in}} Nissen’s 2003 report Implementation of a Fast Artificial Neural Network Library (FANN). This report was submitted to the computer science department at the University of Copenhagen (DIKU). In his original report Nissen describes {{that one of his}} primary motivations in writing FANN was developing a neural network library that was friendly to both, fixed point, and floating point arithmetic. Nissen wanted to develop an <b>autonomous</b> <b>agent</b> that can learn from experience. His goal was to use this <b>autonomous</b> <b>agent</b> to create a virtual player in Quake III Arena that can learn from game play.Since its original 1.0.0 version release, the library’s functionality has been expanded by the creator and its many contributors to include more practical constructors, different activation functions, simpler access to parameters and bindings to multiple programming languages. It has been downloaded 450,000 times since its move to Source Forge in 2003 and 29,000 times in 2016 alone.|$|E
50|$|A {{pervasive}} game is leveraging the sensed human contexts {{to adapt}} game system behaviors. By blending of real and virtual elements and enabling users to physically {{interact with their}} surroundings during the play, people can become fully involved in and attain better gaming experience. For example, a pervasive game that uses the contexts of human activity and location in smart homes is reported by an <b>autonomous</b> <b>agent.</b>|$|E
40|$|This article {{argues that}} it is {{possible}} to hold <b>autonomous</b> <b>agents</b> themselves, and not only their makers, users or owners, responsible for the acts of these agents. In this connection autonomous systems are computer programs that interact with the outside world without human interference. They include such systems as ‘intelligent’ weapons and self-driving cars. The argument is based on an analogy between human beings and <b>autonomous</b> <b>agents</b> and its main element asserts that if humans can be held responsible, so can, in principle, <b>autonomous</b> <b>agents,</b> as humans are more like <b>autonomous</b> <b>agents</b> than is often assumed (rather than the other way round) ...|$|R
50|$|Jon Gratch and Stacy Marsella - 2010 <b>Autonomous</b> <b>Agents</b> Research Award, ACM/SIGART for {{significant}} and sustained contributions to <b>autonomous</b> <b>agents</b> and multiagent {{systems in the}} area of virtual agents, in particular in emotion modeling and social simulation.|$|R
40|$|<b>Autonomous</b> <b>agents</b> {{developed}} by experts are embedded with {{the capability to}} interact well with people from different cultures. When designing expert agents intended to interact with <b>autonomous</b> <b>agents</b> {{developed by}} Non Game Theory Agents (NGTE), it is beneficial to obtain insights {{on the behavior of}} these NGTE agents. Is the behavior of these NGTE agents similar to human behavior from different cultures? This is an important question as such a quality would allow an expert agent interacting with NGTE agents to model them using the same methods that are used to model humans from different cultures. To study this point, we evaluated NGTE agents behavior using a game called the Trust-Revenge game, which is known in social science for capturing different human tendencies. The Trust-Revenge game has a unique subgame-perfect equilibrium strategy profile, however, very rarely do people follow it. We compared the behavior of <b>autonomous</b> <b>agents</b> to the actions of several human demographic groups—one of which is similar to the designers of the <b>autonomous</b> <b>agents.</b> We claim that <b>autonomous</b> <b>agents</b> are similar to human players from various cultures. This enables the use of approaches, developed for handling cultural diversity among humans, to be applied for interaction with NGTE agents. This paper also analyzes additional aspects of <b>autonomous</b> <b>agents</b> behavior and whether composing <b>autonomous</b> <b>agents</b> affects human behavior...|$|R
5000|$|Bill Tomlinson used a more {{original}} {{approach to}} the problem. He devised {{a system in which}} the camera is an <b>autonomous</b> <b>agent</b> with its own personality. The style of the shots and their rhythm will be affected by its mood. Thus a happy camera will [...] "cut more frequently, spend more time in close-up shots, move with a bouncy, swooping motion, and brightly illuminate the scene".|$|E
5000|$|Like the {{previous}} game, every plant, animal and insect in Albia {{is a separate}} system called an <b>autonomous</b> <b>agent,</b> or just [...] "agent" [...] for short. Many user-created agents have been made, which can be injected into the world using the Injector Kit applet, which also includes an analysis page giving the opportunity to check new objects for potentially harmful contents before injecting them.|$|E
50|$|Others take a {{systemic}} viewpoint {{that does not}} necessarily depend on molecular chemistry. One systemic definition of life is that living things are self-organizing and autopoietic (self-producing). Variations of this definition include Stuart Kauffman's definition as an <b>autonomous</b> <b>agent</b> or a multi-agent system capable of reproducing itself or themselves, and of completing at least one thermodynamic work cycle. This definition is extended by the apparition of novel functions over time.|$|E
5000|$|... #Subtitle level 3: ACM/SIGAI <b>Autonomous</b> <b>Agents</b> Research Award ...|$|R
40|$|In this paper, we {{describe}} the enactment of <b>autonomous</b> <b>agents</b> and avatars in the web-based social collaborative virtual environment of REVERIE that supports natural, human-like behavior, physical interaction and engagement. Represented by avatars, users feel immersed in this virtual world {{in which they can}} meet and share experiences as in real life. Like the avatars, <b>autonomous</b> <b>agents</b> that may act in this world are capable of demonstrating human-like non-verbal behavior and facilitate social interaction. We describe how reasoning components of the REVERIE system connect and cooperatively control <b>autonomous</b> <b>agents</b> and avatars representing a user...|$|R
40|$|Recent {{years are}} seeing a worrisome decline in the {{activity}} of roboticists within the <b>Autonomous</b> <b>Agents</b> and Multi-Agent Systems (AAMAS) community. Robotics papers, that were abundant in the early <b>Autonomous</b> <b>Agents</b> conferences, have almost disappeared in recent editions of the International Joint Conference on <b>Autonomous</b> <b>Agents</b> and Multi-Agent Systems. To some, this trend seems natural. After all, what do physical robots, with their assortment of hardware issues, mechanical design challenges, and sensory uncertainty, {{have to do with}} web crawlers, interaction protocols, auctions, and game-theoretical results or logical proofs? What do they have to do wit...|$|R
50|$|The Meca Sapiens {{architecture}} {{is based on}} the software engineering tools and techniques used in other information systems. It describes a purposefully designed embedded <b>autonomous</b> <b>agent</b> that will be conscious. The architecture makes no use of the structures or processes that take place in human (or animal) brains. In particular, Artificial Neural Networks, whose role is central in many AGI related projects, are treated as stochastic optimization mechanisms.|$|E
50|$|MIBE {{architecture}} {{is based on}} the belief that autonomy is grounded on motivation and autonomy should arise from superimposition of synergetic activities in response to multiple drives. An <b>autonomous</b> <b>agent</b> is developed to achieve several goals (primary goals), but secondary goals also originate as a consequence of environmental or functional constraints. In MIBE architecture both primary and secondary goals are handled in the same way and defined as needs. A specific drive originates from each need.MIBE architecture generates and weights all these drives in an explicit motivational state. The higher the urgency to satisfy a specific need, the higher its weight in the motivational state and the higher the drive to perform a behavior that satisfies the given need.|$|E
5000|$|Practical {{reasoning}} is basically goal-directed reasoning from an agent's goal, and from some action selected {{as a means}} to carry out the goal, to the agent's reasoned decision to carry out the action. The agent can be a person or a technical device, such as a robot or a software device for multi-agent communications. It is a type of reasoning used all the time in everyday life and all kinds of technology where autonomous {{reasoning is}} required. Argumentation theorists have identified two kinds of practical reasoning: instrumental practical reasoning that does not explicitly take values into account, and value-based practical reasoning. The following argumentation scheme for instrumental practical reasoning is given in [...] The pronoun I represents an <b>autonomous</b> <b>agent.</b>|$|E
40|$|As we {{move towards}} a richer model of {{computation}} based on interactions among <b>autonomous</b> <b>agents</b> {{in lieu of}} the more traditional numeric batch processing model, it is necessary to devise techniques and abstractions for the development of such <b>autonomous</b> <b>agents.</b> The abil-ity to generate, reason about, and select the means to achieve explicit goals is critical for <b>autonomous</b> <b>agents,</b> the so called goal-driven autonomy. Reasoning about goals demands a suitable abstraction for meta-level rea-soning, so that an agent not only reasons about the ac-tions it needs to take, but also about the viability of (and interaction among) such goals. In this paper we dis-cuss the use of motivations as an abstraction of meta-reasoning for goal-driven <b>autonomous</b> <b>agents.</b> We re-view recent developments in motivated agent architec-tures and discuss possible directions for future research. ...|$|R
40|$|<b>Autonomous</b> <b>agents</b> {{have become}} an {{influential}} and powerful paradigm in {{a great variety of}} disciplines, from sociology and economics to distributed artificial intelligence and software engineering to philosophy. Given that the paradigm has been around for awhile, one would expect a broadly agreed-upon, solid understanding of what <b>autonomous</b> <b>agents</b> are and what they are not. This, however, is not the case. We therefore join the ongoing debate on what are the appropriate notions of autonomous agency. We approach agents and agent ontology from a cybernetics and general systems perspective, in contrast to the much more common in the agent literature sociology, anthropology and/or cognitive psychology based approaches. We attempt to identify the most fundamental attributes of <b>autonomous</b> <b>agents,</b> and propose a tentative hierarchy of <b>autonomous</b> <b>agents</b> based on those attributes...|$|R
40|$|This paper {{describes}} ECM, a new coordination {{model and}} STL its corresponding language. STL's power and expressiveness are shown through a distributed {{implementation of a}} generic autonomy-based multi-agent system, which is applied to a collective robotics simulation, thus demonstrating the appropriateness of STL for developing a generic coordination platform for <b>autonomous</b> <b>agents.</b> Keywords: Coordination, Distributed Systems, <b>Autonomous</b> <b>Agents,</b> Collective Robotics. 1 Introduction Coordination constitutes a major scientific domain of Computer Science. Works coming within Coordination encompass conceptual and methodological issues as well as implementations in order to efficiently help expressing and implementing distributed applications. <b>Autonomous</b> <b>Agents,</b> a discipline of Artificial Intelligence which enjoys a boom since a couple of years, embodies inherent distributed applications. Works coming within <b>Autonomous</b> <b>Agents</b> are intended {{to capitalize on the}} co-existence of distributed e [...] ...|$|R
50|$|Embodied {{cognitive}} science borrows heavily from embodied philosophy {{and the related}} research fields of {{cognitive science}}, psychology, neuroscience and artificial intelligence. From the perspective of neuroscience, {{research in this field}} was led by Gerald Edelman of the Neurosciences Institute at La Jolla, the late Francisco Varela of CNRS in France, and J. A. Scott Kelso of Florida Atlantic University. From the perspective of psychology, research by Michael Turvey, Lawrence Barsalou and Eleanor Rosch. From the perspective of language acquisition, Eric Lenneberg and Philip Rubin at Haskins Laboratories. From the perspective of <b>autonomous</b> <b>agent</b> design, early work is sometimes attributed to Rodney Brooks or Valentino Braitenberg. From the perspective of artificial intelligence, see Understanding Intelligence by Rolf Pfeifer and Christian Scheier or How the body shapes the way we think, also by Rolf Pfeifer and Josh C. Bongard. From the perspective of philosophy see Andy Clark, Shaun Gallagher, and Evan Thompson.|$|E
5000|$|The {{notion of}} Superman robots was reintroduced for post-Crisis comic {{continuity}} in a late 1990s storyline. During the period where Superman (under {{the control of}} Dominus) felt he must police the entire earth, 24 hours a day, 7 days a week he built an army of Superman robots (created in his own image, all wearing the famous [...] "S" [...] shield but wearing variations of the Red, Blue and Yellow costume). However, unlike the pre-Crisis Superman robots, these automata were not realistic androids capable of passing for the real Superman, but instead were obviously mechanical, with metallic bodies that possessed no artificial skin. These modern Superman robot's powers included super-strength, flight, and heat vision, but were inferior to Superman's own powers. The Superman robots were also given a small degree of sentience, making each one an <b>autonomous</b> <b>agent</b> of the Man of Steel. Their job was to protect mankind (aggressively if necessary) and attend to crises beyond Superman's reach.|$|E
5000|$|Many {{researchers}} have argued that, {{by way of}} an [...] "intelligence explosion" [...] sometime in the 21st century, a self-improving AI could become so vastly more powerful than humans {{that we would not}} be able to stop it from achieving its goals.In his paper Ethical Issues in Advanced Artificial Intelligence, the Oxford philosopher Nick Bostrom even argues that artificial intelligence has the capability to bring about human extinction. He claims that general super-intelligence would be capable of independent initiative and of making its own plans, and may therefore be more appropriately thought of as an <b>autonomous</b> <b>agent.</b> Since artificial intellects need not share our human motivational tendencies, it would be up to the designers of the super-intelligence to specify its original motivations. In theory, a super-intelligent AI would be able to bring about almost any possible outcome and to thwart any attempt to prevent the implementation of its top goal, many uncontrolled unintended consequences could arise. It could kill off all other agents, persuade them to change their behavior, or block their attempts at interference.|$|E
5000|$|... #Article: International Conference on <b>Autonomous</b> <b>Agents</b> and Multiagent Systems ...|$|R
5000|$|... 2003-2009 co-editor-in-chief of the Journal <b>Autonomous</b> <b>Agents</b> and Multi-Agent Systems ...|$|R
5000|$|... 2006 ACM/SIGART <b>Autonomous</b> <b>Agents</b> Research Award. For {{significant}} and sustained {{contributions to the}} research on <b>autonomous</b> <b>agents</b> and multi agent systems. In particular, Dr. Wooldridge has made seminal contributions to the logical foundations of multi-agent systems, especially to formal theories of cooperation, teamwork and communication, computational complexity in multi-agent systems, and agent-oriented software engineering.|$|R
