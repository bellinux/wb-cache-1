384|574|Public
50|$|As such, MC4 is {{strategically}} integrating {{with future}} Army systems, including PEO Soldier. MC4 {{will provide an}} interface to these systems that enables <b>automated</b> <b>assessment</b> and remote monitoring capabilities for deployed medical forces.|$|E
5000|$|Currently, CBTI {{programs}} {{fall into}} one of two categories: actuarial assessment programs or <b>automated</b> <b>assessment</b> programs. Actuarial assessment programs are based on statistical or actuarial prediction (e.g., statistical analyses, linear regression equations and Bayesian rules), which is empirically based while <b>automated</b> <b>assessment</b> programs consist of a series of if-then statements derived by expert clinicians and informed by published research and clinical experience. For the purposes of this article, both types will be referred to as computer-based test interpretations (CBTIs). The use of CBTIs is found in a variety of psychological domains (e.g., clinical interviewing and problem rating), but is most commonly utilized in personality and neuropsychological assessments. [...] This article will focus on the use of CBTIs in personality assessment, most commonly using the MMPI and its subsequent revised editions.|$|E
50|$|Computer {{software}} applications have been tasked with the <b>automated</b> <b>assessment</b> of retinal images to recognize lesions {{associated with an}} ocular disease of interest. The clinical process entails initially discriminating retinal lesions from non-factor artifacts, subsequently distinguishing lesions associated with the disease in question from other types of lesions, and finally grading the disease according to guideline-endorsed severity scales set by medical authorities.|$|E
40|$|This paper {{describes}} tools {{developed at}} Educational Testing Service which use statistical modeling of textual corpora to provide <b>automated</b> <b>assessments</b> of student responses. Details are given {{for three of}} these systems: Critique Writing Analysis Tools for providing feedback to students, e-rater for assigning a holistic score to student essays, and c-rater, which scores responses to content-based, short-answer test or chapter review questions...|$|R
5000|$|ZENworks Patch Management <b>automates</b> patch <b>assessment,</b> {{monitoring}} and remediation; monitors patch compliance to detect security vulnerabilities ...|$|R
50|$|A {{computer}} security audit is a manual or systematic measurable technical {{assessment of a}} system or application. Manual assessments include interviewing staff, performing security vulnerability scans, reviewing application and operating system access controls, and analyzing physical access to the systems. <b>Automated</b> <b>assessments,</b> or CAAT's, include system generated audit reports or using software to monitor and report changes to files and settings on a system. Systems can include personal computers, servers, mainframes, network routers, switches.|$|R
50|$|PESQ, Perceptual Evaluation of Speech Quality, is {{a family}} of {{standards}} comprising a test methodology for <b>automated</b> <b>assessment</b> of the speech quality as experienced by a user of a telephony system. It is standardised as ITU-T recommendation P.862 (02/01). Today, PESQ is a worldwide applied industry standard for objective voice quality testing used by phone manufacturers, network equipment vendors and telecom operators. Its usage requires a license.|$|E
50|$|CASP, {{which stands}} for Critical Assessment of Techniques for Protein Structure Prediction, is a community-wide {{experiment}} for protein structure prediction taking place every two years since 1994. CASP provides {{with an opportunity to}} assess the quality of available human, non-automated methodology (human category) and automatic servers for protein structure prediction (server category, introduced in the CASP7). The official results of <b>automated</b> <b>assessment</b> in 2012 CASP10 are available at for automated servers and for human and server predictors. In December 2014 next CASP11 assessment will be publicly available.|$|E
50|$|Research on {{language}} MOOCs, and related technology and methodology, offer ways {{to address some}} of these challenges, motivating students and implicating them more fully in learning activities related to the development of their second language competences. Furthermore, as the nature of society changes, then so to will the way in which online language learning is undertaken. As in other areas of online learning, the role of mobile devices is becoming ever more important here, leading to the notion of mobile-driven or mobile-assisted LMOOCs, or MALMOOCs, where such devices go beyond being just portable course clients to act as mobile sensor-enabled based around extensible app-based devices that can extend language learning into everyday real-world activities. Other emerging educational technologies that will arguably be important for LMOOCs include learning analytics, gamification, personal learning networks, adaptive and <b>automated</b> <b>assessment.</b>|$|E
5000|$|Operate and {{maintain}} online <b>automated</b> vulnerability <b>assessment</b> tools for each server on their network to include systems managed remotely by another organization.|$|R
40|$|Abstract. Web {{accessibility}} is {{an important}} goal of the European i 2010 strategy. Several one-off surveys of eAccessibility have been conducted {{in the past few}} years. In this paper, we describe an approach to supplement the results of such surveys with <b>automated</b> <b>assessments,</b> that can easily be repeated at regular intervals. The software basis is provided by the European Internet Accessibility Observatory (EIAO). We analyse how the data collected by EIAO can be compared to other surveys. ...|$|R
40|$|Software {{projects}} requiring satisfaction assessment {{are often}} large scale systems containing hundreds of requirements and design elements. These projects may exist within a high assurance domain where human lives {{and millions of}} dollars are at stake. Satisfaction assessment can help identify unsatisfied requirements early in the software development lifecycle, when issues can be corrected with less impact and lower cost. Manual satisfaction assessment is expensive both in terms of human effort and project cost. <b>Automated</b> satisfaction <b>assessment</b> assists requirements analysts during the satisfaction assessment process to more quickly determine satisfied requirements and to reduce the satisfaction assessment search space. This paper introduces two new <b>automated</b> satisfaction <b>assessment</b> techniques and empirically demonstrates their effectiveness, as well as validates two previously existing <b>automated</b> satisfaction <b>assessment</b> techniques. Validation shows that automatically generated satisfaction assessments have high accuracy, thus reducing the workload of the analyst in the satisfaction assessment process...|$|R
50|$|Computer-based test {{interpretation}} (CBTI) {{programs are}} technological tools {{that have been}} commonly used to interpret data in psychological assessments since the 1960s. CBTI programs are used for a myriad of psychological tests, like clinical interviews or problem rating, but are most frequently exercised in psychological and neuropsychological assessments. CBTI programs are either empirically based or clinically based. The empirically based programs, or actuarial assessment programs, use statistical analyses to interpret the data, while the clinically based programs, or <b>automated</b> <b>assessment</b> programs, rely on information from expert clinicians and research. Although CBTI programs are successful in test-retest reliability, there have been major concerns and criticisms regarding the programs' ability to assess inter-rater and internal consistency reliability. Research {{has shown that the}} validity of CBTI programs has not been confirmed, due to the varying reports of individual programs. CBTI programs are very efficient in that they save time, reduce human error, are cost effective, and are objective/reliable, yet limited in that they are not always used by adequately trained evaluators or are not integrated with multiple sources of data. As technology continues to transform our modern society, computer-based interpretation programs have the possibility to expand their software and even alleviate some of the current concerns with the programs' methodology.|$|E
40|$|On {{the basis}} of {{analyzing}} the actual demand of <b>automated</b> <b>assessment</b> system for the command and control specialty in ships, {{the thought of the}} overall design of <b>automated</b> <b>assessment</b> system for the command and control specialty in ships is given, and the concrete realization methods of the user login module, test paper operation module and system maintenance module are studied and demonstrated. The proposed design idea and implementation method of <b>automated</b> <b>assessment</b> system for the command and control specialty in ships is scientific, efficient and practical, and provides reference for the exploitation of <b>automated</b> <b>assessment</b> system for the command and control specialty in ships...|$|E
30|$|The {{evaluation}} procedure involved three tests: (1) comparison between human assessment performed by three different teachers, (2) comparison between final marks obtained by human and <b>automated</b> <b>assessment</b> system, and (3) comparison between human and <b>automated</b> <b>assessment</b> system toward {{the identification of}} marks’ gaps by particular skill.|$|E
40|$|This paper {{presents}} an ongoing research project concerning {{the development of}} an <b>automated</b> safety <b>assessment</b> framework for earthmoving and surface mining activities. This research seeks to determine data needs for safety assessment and investigates how to utilize collected data to promote more informed and efficient safety decision-making. The research first examined accidents and fatalities involved with earthmoving and surface mining activities—more specifically, those involving loading, hauling, and dumping operations,—investigated risk factors involved with the accidents, and finally identified data needs for safety assessment based on safety regulations and practices. An <b>automated</b> safety <b>assessment</b> method was then developed using the data needs that had been identified. This research is expected to contribute to the introduction of a fundamental framework for <b>automated</b> safety <b>assessment</b> and the systematic collection of safety-related data from construction activities. Implementation of the entire safety assessment process on actual construction sites remains a task for future research...|$|R
40|$|In this paper, we {{describe}} {{an approach to}} developing an ecologically valid framework for performing <b>automated</b> cognitive <b>assessment.</b> To <b>automate</b> <b>assessment,</b> we use a machine learning approach that builds a model of cognitive health based on observations of activity performance and uses lab-based assessment to provide ground truth for training and testing the learning algorithm. To evaluate our approach, we recruited older adults to perform a set of activities in our smart home test-bed. While participants perform activities, sensors placed in the smart home unobtrusively capture {{the progress of the}} activity. During analysis, we extract features that indicate how well participants perform the activities. Our machinelearning algorithm accepts these features as input and outputs the cognitive status of the participants as belonging to one of two groups: Cognitively healthy or Dementia. We conclude that machine-learning algorithms can distinguish between cognitively healthy older adults and older adults with dementia given adequate features that represent how well they have performed the activity...|$|R
40|$|International audienceComputer Supported Collaborative Learning (CSCL) environments {{have become}} a viable {{learning}} alternative from which valuable data can be extracted and used for advanced analyses centered on evaluating participants' involvement and their interactions. Such <b>automated</b> <b>assessments</b> are implemented within our ReaderBench framework, a Natural Language Processing platform that contains multiple advanced text analysis functionalities. The ReaderBench framework is based on Cohesion Network Analysis from which different sociograms, relying on semantic similarity, are generated in order to reflect interactions between participants. In this paper, we briefly describe the enforced mechanisms used to analyze three scenarios: individual chat conversations, virtual communities of practice and MOOCs...|$|R
40|$|<b>Automated</b> <b>assessment</b> {{systems are}} {{very helpful in}} {{reducing}} the amount of repetitive work done by instructors on computer science courses with a lot of practical exercises. These systems can also help students by providing objective grading and quicker feedback. In this paper we explore the usage of software metrics in <b>automated</b> <b>assessment.</b> The metrics are utilized to assess algorithm complexity among other aspects that currently demand instructor attention. Additional value of our approach is programming language independency of the used tools: SMIILE for software metrics calculation and Testovid for <b>automated</b> <b>assessment...</b>|$|E
40|$|This paper {{argues that}} <b>automated</b> <b>assessment</b> {{systems can be}} useful for both {{students}} and educators provided that its results correspond well with human markers. Thus, evaluating such a system is crucial. We present an evaluation framework and show why it can be useful for both producers and consumers of <b>automated</b> <b>assessment.</b> The framework builds on previous work to analyse Latent Semantic Analysis- (LSA) based systems, {{a particular type of}} <b>automated</b> <b>assessment,</b> that produced a research taxonomy that could help developers publish their results in a format that is comprehensive, relatively compact, and useful to other researchers. The paper contends that, in order to see a complete picture of an <b>automated</b> <b>assessment</b> system, certain pieces must be emphasised. It presents the framework as a jigsaw puzzle whose pieces join together to form the whole picture and provides an example of the utility of the framework by presenting some empirical results from our assessment system that marks questions about html. Finally, the paper suggests that the framework is not limited to LSA-based systems. With slight modifications, it can be applied to any <b>automated</b> <b>assessment</b> system...|$|E
30|$|Over {{the last}} few decades, new {{education}} forms have increased the student-to-lecturer ratios, as an example, the open education. Arnold (2012) regards the Massive Open Online Courses (MOOCs) as the best example to illustrate the issue of effectively assessing thousands {{of students enrolled in}} these courses each semester. Considering the assessment {{as an integral part of}} the learning process (Ehlers 2013), we can also transform this fact to learning systems and <b>automated</b> <b>assessment.</b> There is a major agreement that <b>automated</b> <b>assessment</b> systems are really motivating. Lahtonen and Isomöttönen (2012) argue that this motivation refers to the reduction of the teacher’s workload and the easiness of interaction between the teacher and students. They summarize that <b>automated</b> <b>assessment</b> can also make grading more consistent and objective. This fact has resulted in an increasing effort to develop automated grading systems in order to achieve these objectives. Although the research in the design of <b>automated</b> <b>assessment</b> systems has a long history in many educational domains (Lahtonen and Isomöttönen 2012), only a few attempts have been established to develop <b>automated</b> <b>assessment</b> systems for IT skills, and Office skills in particular (Kovacic and Green, 2012).|$|E
40|$|Physiology and {{assessment}} constitute major bottlenecks of school learning among {{students with low}} socioeconomic status. The limited resources and household overcrowding typical of poverty produce deficits in nutrition, sleep, and exercise that strongly hinder physiology and hence learning. Likewise, overcrowded classrooms hamper the assessment of individual learning with enough temporal resolution to make individual interventions effective. Computational measurements of learning offer hope for low-cost, fast, scalable, and yet personalized academic evaluation. Improvement of school schedules by reducing lecture time in favor of naps, exercise, meals, and frequent <b>automated</b> <b>assessments</b> of individual performance is an easily achievable goal for education...|$|R
40|$|Abstract: There are {{different}} ways of <b>automating</b> the <b>assessment</b> of the intent of a target. However, {{the most effective way}} is one that can offer the most accurate estimates compared to human-defined benchmarks. To allow various intent assessment technologies to be evaluated against the benchmarks, a reconfigurable simulation environment has been designed. In order to cope with future tests and different technologies, the software architecture has been structured {{in such a way that}} the simulation environment talks to different intent assessment technologies via an interface, hence forming a plug-and-play simulation environment. This paper describes a simulation of <b>automated</b> intent <b>assessment.</b> ...|$|R
40|$|The {{quality of}} Learning Objects (LOs) is {{currently}} being promoted by certain tools which consider specific criteria for their evaluation; however, there is no existing methodology that considers both the value assigned to the LO itself and the percentage related {{to the number of}} evaluators who have compared the quality of resources. As in the case of various products offered through the Internet backed by an assessment of users in a unified ranking, {{the purpose of this paper}} is to suggest a proposal for the <b>automated</b> <b>assessments</b> of experts who can clearly see the best or worst aspects in LO quality...|$|R
40|$|Abstract: This paper {{argues that}} <b>automated</b> <b>assessment</b> {{systems can be}} useful for both {{students}} and educators provided that its results correspond well with human markers. Thus, evaluating such a system is crucial. We present an evaluation framework and show why it can be useful for both producers and consumers of <b>automated</b> <b>assessment.</b> The framework builds on previous work to analyse Latent Semantic Analysis- (LSA) based systems, {{a particular type of}} <b>automated</b> <b>assessment,</b> that produced a research taxonomy that could help developers publish their results in a format that is comprehensive, relatively compact, and useful to other researchers. The paper contends that, in order to see a complete picture of an <b>automated</b> <b>assessment</b> system, certain pieces must be emphasised. It presents the framework as a jigsaw puzzle whose pieces join together to form the whole picture and provides an example of the utility of the framework by presenting some empirical results from our assessment system that marks questions about html. Finally, the paper suggests that the framework is not limited to LSA-based systems. With slight modifications, it can be applied to any <b>automated</b> <b>assessment</b> system...|$|E
30|$|The {{demand for}} <b>automated</b> <b>assessment</b> and {{certification}} systems has grown {{due to the}} fact that it would be extremely complex and hard to assess the huge amount of candidates manually by humans. This demand is confirmed by both employability and institutional needs. This situation drives the design of <b>automated</b> <b>assessment</b> systems in order to decrease both cost and time of manual assessment processes. Furthermore, <b>automated</b> <b>assessment</b> and certification systems are expected to avoid subjectivity and errors of human assessment. Indeed, a panoply of systems and tools have been designed and implemented in order to automatically assess IT skills. The next section provides a detailed review of those developments.|$|E
40|$|A rapidly {{increasing}} number of modulesin degree programmes now utilise virtuallearning environments. A main feature ofvirtual learning environments, to whichtheir adoption by many educators isattributed, is <b>automated</b> <b>assessment.</b> <b>Automated</b> <b>assessment</b> is particularlyattractive where the number of studentstaking a module is large. As mathematicsis an essential pre-requisite for thosestudying engineering courses and iscompulsory in almost every engineeringprogramme, classes tend to be large. However, there is ongoing scrutiny ofthe various aspects of virtual learningenvironments, including automatedassessment. This paper {{is based on a}} casestudy that highlights aspects of the impactof <b>automated</b> <b>assessment</b> by studyingthe performance of students taking anengineering mathematics module whereautomated assessment is utilised in theform of quizzes...|$|E
40|$|Concept {{maps are}} an {{educational}} tool {{that is used}} both for learning and knowledge <b>assessment.</b> <b>Automated</b> knowledge <b>assessment</b> has a limited ability to assess non-standard constructions. and current automated concept map-based knowledge assessment systems fail to recognise the fact that learner’s chosen labels for conceptual relationships may differ from teacher’s preferred labels and still be correct. This paper conceptually introduces several mechanisms for overcoming this drawback which distinguish real misconceptions from correct statements that are expressed using different words...|$|R
40|$|Pressure {{for better}} {{measurement}} of stated learning outcomes {{has resulted in}} a demand for more frequent assessment. The resources available are seen to be static or dwindling, but Information and Communications Technology is seen to increase productivity by <b>automating</b> <b>assessment</b> tasks. This paper reviews computer-assisted assessment (CAA) and suggests future developments. A search was conducted of CAA-related literature from the past decade to trace the development of CAA from the beginnings of its large-scale use in higher education. Lack of resources, individual inertia and risk propensity are key barriers for individual academics, while proper resourcing and cultural factors outweigh technical barriers at the institutional level...|$|R
40|$|Agricultural {{areas are}} declining {{in many areas}} of the world, often because {{socio-economic}} and political changes make agriculture less profitable. The transition from centralized to market-oriented economies in Eastern Europe and the former Soviet Union after 1989 represented major economic and political changes, yet the resulting rates and spatial pattern of post-socialist farmland abandonment remain largely unknown. Remote sensing offers unique opportunities to map farmland abandon-ment, but <b>automated</b> <b>assessments</b> are challenging because phenology and crop types often vary substantially. We developed a change detection method based on support vector machines (SVM) to map farmland abandonment in the border triangle of Poland, Slovakia, and Ukraine in the Carpathians from Landsat TM/ETM+ images fro...|$|R
40|$|The need to {{interpret}} imprecise diagrams (those with malformed, missing or extraneous features) {{occurs in the}} <b>automated</b> <b>assessment</b> of diagrams. We outline our proposal for an architecture to enable the interpretation of imprecise diagrams. We discuss our preliminary work on an assessment tool, developed within this architecture, for automatically grading answers to a computer architecture examination question. Early indications are that performance {{is similar to that}} of human markers. We will be using Entity-Relationship Diagrams (ERDs) as the primary application area for our investigation of <b>automated</b> <b>assessment.</b> This paper will detail our reasons for choosing this area and outline the work ahead. Keywords <b>automated</b> <b>assessment,</b> diagram understanding entity-relationship modelling. 1...|$|E
30|$|Derived {{from these}} explanations, the next {{subsection}} provides insights on our XML-based approach to an <b>automated</b> <b>assessment</b> system.|$|E
40|$|This paper {{presents}} {{the outcome of}} a pre-project that resulted in an initial version (prototype) of an <b>automated</b> <b>assessment</b> algorithm for a specific maritime operation. The prototype is based on identified control requirements that human operators must meet to conduct safe navigation. Current assessment methods of navigation in simulators involve subject matter experts, whose evaluations unfortunately have some limitations related to reproducibility and consistency. <b>Automated</b> <b>assessment</b> algorithms may address these limitations. For a prototype, our algorithm had a large correlation with evaluations performed by subject matter experts in assessment of navigation routes. The results indicate that further research in <b>automated</b> <b>assessment</b> of maritime navigation has merit. The algorithm can be a stepping stone in developing a consistent, unbiased, and transparent assessment module for evaluating maritime navigation performance...|$|E
40|$|Quantifying {{behavior}} {{is a challenge}} for scientists studying neuroscience, ethology, psychology, pathology, etc. Until now, behavior was mostly considered as qualitative descriptions of postures or labor intensive counting of bouts of individual movements. Many prominent behavioral scientists conducted studies describing postures of mice and rats, depicting step by step eating, grooming, courting, and other behaviors. <b>Automated</b> video <b>assessment</b> technologies permit scientists to quantify daily behavioral patterns/routines, social interactions, and postural changes in an unbiased manner. Here, we extensively reviewed published research {{on the topic of}} the structural blocks of behavior and proposed a structure of behavior based on the latest publications. We discuss the importance of defining a clear structure of behavior to allow professionals to write viable algorithms. We presented a discussion of technologies that are used in <b>automated</b> video <b>assessment</b> of behavior in mice and rats. We considered advantages and limitations of supervised and unsupervised learning. We presented the latest scientific discoveries that were made using <b>automated</b> video <b>assessment.</b> In conclusion, we proposed that the automated quantitative approach to evaluating animal {{behavior is}} the future of understanding the effect of brain signaling, pathologies, genetic content, and environment on behavior...|$|R
40|$|BACKGROUND <b>Automated</b> sensor-based <b>assessments</b> {{of upper}} {{extremity}} (UE) function after cervical {{spinal cord injury}} (SCI) could provide more detailed tracking of individual recovery profiles than is possible with existing assessments, and optimize the delivery and assessment of new interventions. The design of reliable <b>automated</b> <b>assessments</b> requires identifying the key variables {{that need to be}} measured to meaningfully quantify UE function. An unanswered question is to what extent measures of sensorimotor impairment can quantitatively predict performance on functional tasks. OBJECTIVE The objective was to define the predictive value of impairment measures for concurrent functional task performance in traumatic cervical SCI, as measured by the Graded Redefined Assessment of Strength, Sensibility and Prehension (GRASSP). SETTING Retrospective analysis. METHODS A data set of 138 GRASSP assessments was analyzed. The Strength and Sensation modules were used as measures of impairment, whereas the concurrent Prehension Performance module was used as the surrogate measure of function. Classifiers were trained to predict the scores on each of the six individual tasks in the Prehension Performance module. The six scores were added to obtain a total score. RESULTS The Spearman's ρ between predicted and actual total Prehension Performance scores was 0. 84. Predictions using both the Strength and Sensation scores were not found to be superior to predictions using the Strength scores alone. CONCLUSIONS Measures of UE motor impairment are highly predictive of functional task performance after cervical SCI. <b>Automated</b> sensor-based <b>assessments</b> of UE motor function after SCI can rely on measuring only impairment and estimating functional performance accordingly. Spinal Cord advance online publication, 31 May 2016; doi: 10. 1038 /sc. 2016. 77...|$|R
40|$|Nowadays {{banks are}} faced with an {{increased}} level of doubtful debts. This research examines some firm- market- and industry-related factors {{that can be used}} to explain the level of doubtful debts. Some moderating factors (type, size and duration of the loan) are also considered. The sample is consisted from 129 credit analysts and branch managers from five of the biggest banks operating in Greece. The results suggest that the use of <b>automated</b> credit <b>assessment</b> tools, very good knowledge of the assessment process and rules, and the implementation of suitable control mechanism can help towards reducing the level of doubtful debts. doubtful debts; regression modelling; Greek banking system; credit risk assessment; Greece; loan type; loan size; loan duration; <b>automated</b> credit <b>assessment.</b> ...|$|R
