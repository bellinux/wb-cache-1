181|150|Public
25|$|An <b>augmenting</b> <b>path</b> in a {{matching}} problem {{is closely related}} to the augmenting paths arising in maximum flow problems, paths along which one may increase the amount of flow between the terminals of the flow. It is possible to transform the bipartite matching problem into a maximum flow instance, such that the alternating paths of the matching problem become augmenting paths of the flow problem. In fact, a generalization of the technique used in Hopcroft–Karp algorithm to arbitrary flow networks is known as Dinic's algorithm.|$|E
25|$|Both {{approaches}} use {{the observation}} that in claw-free graphs, no vertex can have more than two neighbors in an independent set, and so the symmetric difference of two independent sets must induce a subgraph of degree at most two; that is, it is a union of paths and cycles. In particular, if I is a non-maximum independent set, it differs from any maximum independent set by even cycles and so called augmenting paths: induced paths which alternate between vertices not in I and vertices in I, and for which both endpoints have only one neighbor in I. As the symmetric difference of I with any <b>augmenting</b> <b>path</b> gives a larger independent set, the task thus reduces to searching for augmenting paths until no more can be found, analogously as in algorithms for finding maximum matchings.|$|E
2500|$|An <b>augmenting</b> <b>path</b> is a path [...] in the {{residual}} network, where , , and [...] A network {{is at maximum}} flow {{if and only if}} there is no <b>augmenting</b> <b>path</b> in {{the residual}} network [...]|$|E
3000|$|... the <b>augmenting</b> <b>paths</b> {{corresponding}} to the pickup stage, the PoI visiting stage and the drop-off stage.|$|R
5000|$|By Berge's lemma, {{matching}} M is maximum if {{and only}} if there is no M-augmenting path in G. Hence, either a matching is maximum, or it can be augmented. Thus, starting from an initial matching, we can compute a maximum matching by augmenting the current matching with <b>augmenting</b> <b>paths</b> {{as long as we can}} find them, and return whenever no <b>augmenting</b> <b>paths</b> are left. We can formalize the algorithm as follows: ...|$|R
25|$|The {{algorithm}} terminates when no more <b>augmenting</b> <b>paths</b> {{are found}} in the breadth first search part of one of the phases.|$|R
2500|$|A vertex {{that is not}} the {{endpoint}} of an edge in some {{partial matching}} [...] is called a free vertex. The basic concept that the algorithm relies on is that of an <b>augmenting</b> <b>path,</b> a path that starts at a free vertex, ends at a free vertex, and alternates between unmatched and matched edges within the path. It follows from this definition that, except for the endpoints, all other vertices (if any) in <b>augmenting</b> <b>path</b> must be non-free vertices. An <b>augmenting</b> <b>path</b> could consist of only two vertices (both free) and single unmatched edge between them.|$|E
2500|$|... an <b>augmenting</b> <b>path</b> is an {{alternating}} path that starts from and ends on free (unmatched) vertices.|$|E
2500|$|One {{can prove}} that a {{matching}} is maximum {{if and only if}} it does not have any <b>augmenting</b> <b>path.</b> (This result is sometimes called Berge's lemma.) ...|$|E
50|$|We {{still have}} to {{describe}} how <b>augmenting</b> <b>paths</b> can be found efficiently. The subroutine to find them uses blossoms and contractions.|$|R
3000|$|... node-disjoint paths. In {{the process}} of computing, an <b>augment</b> <b>path</b> between any two nodes is found by Prim’s minimum {{spanning}} tree algorithm. If the graph G(V,E) is stored in the adjacency list, the complexity of Prim’s minimum spanning tree algorithm is O(m[*]+[*]n). After finding the <b>augment</b> <b>paths,</b> these paths are used to update the flow. The flow updating of each path in worst case take n- 1 times addition operation and subtraction operation, then the total time of finding the k [...]...|$|R
3000|$|... node-disjoint paths. As {{showed in}} Fig.  4, the <b>augment</b> <b>path</b> {{is marked by}} a dotted line. Specifically, in Fig.  4, the source and {{destination}} are, respectively, v [...]...|$|R
2500|$|It can {{be shown}} that each phase {{increases}} {{the length of the}} shortest <b>augmenting</b> <b>path</b> by at least one: the phase finds a maximal set of augmenting paths of the given length, so any remaining <b>augmenting</b> <b>path</b> must be longer. Therefore, once the initial [...] phases of the algorithm are complete, the shortest remaining <b>augmenting</b> <b>path</b> has at least [...] edges in it. However, the symmetric difference of the eventual optimal matching and of the partial matching M found by the initial phases forms a collection of vertex-disjoint augmenting paths and alternating cycles. If each of the paths in this collection has length at least , there can be at most [...] paths in the collection, {{and the size of the}} optimal matching can differ from the size of [...] by at most [...] edges. Since each phase of the algorithm increases the size of the matching by at least one, there can be at most [...] additional phases before the algorithm terminates.|$|E
2500|$|All free {{vertices}} in [...] at layer [...] {{are collected}} into a set [...] That is, a vertex [...] {{is put into}} [...] {{if and only if}} it ends a shortest <b>augmenting</b> <b>path.</b>|$|E
2500|$|Conversely, {{suppose that}} a {{matching}} [...] is not optimal, and let [...] be the symmetric difference [...] where [...] is an optimal matching. Because [...] and [...] are both matchings, every vertex has degree at most 2 in [...] So [...] must form {{a collection of}} disjoint augmenting paths and cycles or paths in which matched and unmatched edges are of equal number; the difference in size between [...] and [...] {{is the number of}} augmenting paths in [...] Thus, whenever there exists a matching [...] larger than the current matching , there must also exist an <b>augmenting</b> <b>path.</b> If no <b>augmenting</b> <b>path</b> can be found, an algorithm may safely terminate, since in this case [...] must be optimal.|$|E
30|$|Compared with [19] we {{also improve}} the Dinic {{algorithm}} {{according to the}} updating the residual graphs with a key flag. The key steps of Dinic algorithm are including: searching the <b>augmenting</b> <b>paths</b> through the DFS process in the inner graph; updating the residual graphs according to the known <b>augmenting</b> <b>paths,</b> and judging whether the blocking flow forms. Reference [19] constructed a new graph L in every updating of residual graphs. And it should copy the flow in the new graph L into the initial graph G continually. Therefore, it consumes extra computing resources and is time-consuming. So we add a flag to every edge of G. If the capacity in the edge is valid, the corresponding flag is set as TRUE, otherwise FALSE. The edge of which flag is FALSE is unable to be an <b>augment</b> <b>path</b> in the next iteration and the max flow only includes the edges of which flag is TRUE. Therefore, the execution efficiency of this algorithm has been improved.|$|R
40|$|We present new {{algorithms}}, {{based on}} random sampling, that find maximum flows in undirected uncapacitated graphs. Our algorithms dominate <b>augmenting</b> <b>paths</b> over all parameter values (number of vertices and edges and flow value). They also dominate blocking flows {{over a large}} range of parameter values. Furthermore, they achieve time bounds on graphs with parallel (equivalently, capacitated) edges that previously could only be achieved on graphs without them. The key contribution {{of this paper is}} to demonstrate that such an improvement is possible. This shows that <b>augmenting</b> <b>paths</b> and blocking flows are non-optimal, and reopens the question of how fast we can find a maximum flow. We improve known time bounds by only a small (but polynomial) factor, and the complicated nature of our algorithms suggests they will not be practical. A new idea of our algorithm is to find flow by diminishing cuts instead of <b>augmenting</b> <b>paths.</b> Rather than finding a way to push flow from the source to the sink, we [...] ...|$|R
5000|$|Note {{that after}} step 1 {{as well as}} after step 5, the {{residual}} capacities of edges , [...] and [...] are in the form , [...] and , respectively, for some [...] This means {{that we can use}} <b>augmenting</b> <b>paths</b> , , [...] and [...] infinitely many times and residual capacities of these edges will always be in the same form. Total flow in the network after step 5 is [...] If we continue to use <b>augmenting</b> <b>paths</b> as above, the total flow converges to , while the maximum flow is [...] In this case, the algorithm never terminates and the flow doesn't even converge to the maximum flow.|$|R
2500|$|If [...] is a matching, and [...] is an <b>augmenting</b> <b>path</b> {{relative}} to , then the symmetric difference {{of the two}} sets of edges, , would form a matching with size [...] Thus, by finding augmenting paths, an algorithm may increase the size of the matching.|$|E
2500|$|The Ford–Fulkerson {{algorithm}} {{finds it}} by repeatedly finding an <b>augmenting</b> <b>path</b> from some [...] to some [...] and updating the matching M {{by taking the}} symmetric difference of that path with M (assuming such a path exists). As each path {{can be found in}} [...] time, the running time is [...] This solution is equivalent to adding a super source [...] with edges to all vertices in , and a super sink [...] with edges from all vertices in , and finding a maximal flow from [...] to [...] All edges with flow from [...] to [...] then constitute a maximum matching.|$|E
2500|$|The {{algorithm}} {{was found}} by [...] As in previous methods for matching such as the Hungarian algorithm {{and the work of}} , the Hopcroft–Karp algorithm repeatedly increases the size of a partial matching by finding augmenting paths: sequences of edges that alternate between being {{in and out of the}} matching, such that swapping which edges of the path are in and which are out of the matching produces a larger matching. However, instead of finding just a single <b>augmenting</b> <b>path</b> per iteration, the algorithm finds a maximal set of shortest augmenting paths. As a result, only [...] iterations are needed. The same principle has also been used to develop more complicated algorithms for non-bipartite matching with the same asymptotic running time as the Hopcroft–Karp algorithm.|$|E
3000|$|... 9 is {{selected}} as a node {{in the minimum}} spanning tree (MST) found based on the links weight LIS(G), the calculation of the <b>augment</b> <b>path</b> is achieved, and the algorithm enters next step.|$|R
2500|$|The {{same idea}} {{of finding a}} maximal set of {{shortest}} <b>augmenting</b> <b>paths</b> works also for finding maximum cardinality matchings in non-bipartite graphs, and {{for the same reasons}} the algorithms based on this idea take [...] phases. However, for non-bipartite graphs, the task of finding the <b>augmenting</b> <b>paths</b> within each phase is more difficult. Building on the work of several slower predecessors, [...] showed how to implement a phase in linear time, resulting in a non-bipartite matching algorithm with the same time bound as the Hopcroft–Karp algorithm for bipartite graphs. The Micali–Vazirani technique is complex, and its authors did not provide full proofs of their results; subsequently, ...|$|R
25|$|When we {{were not}} able to find any {{shortest}} <b>augmented</b> <b>path</b> from a vertex, DFS returns false. In this case it would be good to mark these vertices to not to visit them again. This marking is simply done by setting Dist to infinity.|$|R
2500|$|In a {{weighted}} bipartite graph, each edge has an associated value. A maximum weighted bipartite matching {{is defined as}} a matching where the sum of the values of the edges in the matching have a maximal value. If the graph is not complete bipartite, missing edges are inserted with value zero. Finding such a matching is known as the assignment problem. The Hungarian algorithm solves the assignment problem {{and it was one of}} the beginnings of combinatorial optimization algorithms. It uses a modified shortest path search in the <b>augmenting</b> <b>path</b> algorithm. If the Bellman–Ford algorithm is used for this step, the running time of the Hungarian algorithm becomes , or the edge cost can be shifted with a potential to achieve [...] running time with the Dijkstra algorithm and Fibonacci heap.|$|E
2500|$|The {{algorithm}} finds a maximal set of vertex disjoint augmenting {{paths of}} length [...] (Maximal means {{that no more}} such paths can be added. This is different from finding {{the maximum number of}} such paths, which would be harder to do. Fortunately, it is sufficient here to find a maximal set of paths.) This set may be computed by depth first search (DFS) from [...] to the free vertices in , using the breadth first layering to guide the search: the DFS is only allowed to follow edges that lead to an unused vertex in the previous layer, and paths in the DFS tree must alternate between matched and unmatched edges. Once an <b>augmenting</b> <b>path</b> is found that involves one of the vertices in , the DFS is continued from the next starting vertex. Any vertex encountered during the DFS can immediately be marked as used, since if there is no path from it to [...] at the current point in the DFS, then that vertex can't be used to reach [...] at any other point in the DFS. This ensures [...] running time for the DFS. It is also possible to work in the other direction, from free vertices in [...] to those in , which is the variant used in the pseudocode.|$|E
5000|$|An <b>augmenting</b> <b>path</b> is a path [...] in the {{residual}} network, where , , and [...] A network {{is at maximum}} flow {{if and only if}} there is no <b>augmenting</b> <b>path</b> in {{the residual}} network [...]|$|E
40|$|This paper {{considers}} two similar graph algorithms {{that work}} by repeatedly increasing “flow” along “augmenting paths”: the Ford-Fulkerson algorithm for the maximum flow {{problem and the}} Gale-Shapley algorithm for the stable allocation problem (a many-to-many generalization of the stable matching problem). Both algorithms clearly terminate when given integral input data. For real-valued input data, it was previously known that the Ford-Fulkerson algorithm runs in polynomial time if <b>augmenting</b> <b>paths</b> are chosen via breadth-first search, but that the algorithm might fail to terminate if <b>augmenting</b> <b>paths</b> are chosen in an arbitrary fashion. However, {{the performance of the}} Gale-Shapley algorithm on real-valued data was unresolved. Our main result shows that, in contrast to the Ford-Fulkerson algorithm, the Gale-Shapley algorithm always terminates in finite time on real-valued data. Although the Gale-Shapley algorithm may take exponential time in the worst case, it is a popular algorithm in practice due to its simplicity {{and the fact that it}} often runs very quickly (even in sublinear time) for many inputs encountered in practice. We also study the Ford-Fulkerson algorithm when <b>augmenting</b> <b>paths</b> are chosen via depth-first search, a common implementation in practice. We prove that, like breadth-first search, depth-first search also leads to finite termination (although not necessarily in polynomial time) ...|$|R
25|$|How do we {{make sure}} <b>augmented</b> <b>paths</b> are vertex disjoint? It is already guaranteed: After doing the {{symmetric}} difference for a path, none of its vertices could be considered again just because the Dist will not be equal to Dist + 1 (It would be exactly Dist).|$|R
5000|$|The {{same idea}} {{of finding a}} maximal set of {{shortest}} <b>augmenting</b> <b>paths</b> works also for finding maximum cardinality matchings in non-bipartite graphs, and {{for the same reasons}} the algorithms based on this idea take [...] phases. However, for non-bipartite graphs, the task of finding the <b>augmenting</b> <b>paths</b> within each phase is more difficult. Building on the work of several slower predecessors, [...] showed how to implement a phase in linear time, resulting in a non-bipartite matching algorithm with the same time bound as the Hopcroft-Karp algorithm for bipartite graphs. The Micali-Vazirani technique is complex, and its authors did not provide full proofs of their results; subsequently,a [...] "clear exposition" [...] was published by [...] and alternative methods were described by other authors. In 2012, Vazirani offered a new simplified proof of the Micali-Vazirani algorithm.|$|R
5000|$|Given G = (V, E) and a {{matching}} M of G, a vertex v is exposed if no edge of M is incident with v. A path in G is an alternating path, if its edges are alternately not in M and in M (or in M {{and not in}} M). An <b>augmenting</b> <b>path</b> P is an alternating path that starts and ends at two distinct exposed vertices. Note that number of unmatched edges in an <b>augmenting</b> <b>path</b> is greater by one {{than the number of}} matched edges, and hence the total number of edges in an <b>augmenting</b> <b>path</b> is odd. A matching augmentation along an <b>augmenting</b> <b>path</b> P is the operation of replacing M with a new matching [...]|$|E
5000|$|A vertex {{that is not}} the {{endpoint}} of an edge in some {{partial matching}} [...] is called a free vertex. The basic concept that the algorithm relies on is that of an <b>augmenting</b> <b>path,</b> a path that starts at a free vertex, ends at a free vertex, and alternates between unmatched and matched edges within the path. It follows from this definition that, except for the endpoints, all other vertices (if any) in <b>augmenting</b> <b>path</b> must be non-free vertices. An <b>augmenting</b> <b>path</b> could consist of only two vertices (both free) and single unmatched edge between them.|$|E
5000|$|The {{algorithm}} {{is identical to}} the Ford-Fulkerson algorithm, except that the search order when finding the [...] <b>augmenting</b> <b>path</b> is defined. The path found must be a shortest path that has available capacity. This can be found by a breadth-first search, as we let edges have unit length. The running time of O(V E2) is found by showing that each <b>augmenting</b> <b>path</b> can be found in O(E) time, that every time {{at least one of the}} E edges becomes saturated (an edge which has the maximum possible flow), that the distance from the saturated edge to the source along the <b>augmenting</b> <b>path</b> must be longer than last time it was saturated, and that the length is at most V. Another property of this {{algorithm is}} that the length of the shortest <b>augmenting</b> <b>path</b> increases monotonically. There is an accessible proof in Introduction to Algorithms.|$|E
25|$|Several {{authors have}} {{performed}} experimental comparisons of bipartite matching algorithms. Their results in general tend {{to show that}} the Hopcroft–Karp method is not as good in practice as it is in theory: it is outperformed both by simpler breadth-first and depth-first strategies for finding <b>augmenting</b> <b>paths,</b> and by push-relabel techniques.|$|R
5000|$|Consider {{the flow}} network {{shown on the}} right, with source , sink , {{capacities}} of edges , [...] and [...] respectively , [...] and [...] and the capacity of all other edges some integer [...] The constant [...] was chosen so, that [...] We use <b>augmenting</b> <b>paths</b> according to the following table, where , [...] and [...]|$|R
50|$|So what is {{the mission}} of these two lines in pseudocode?: Distu = ∞ return falseWhen {{we were not able}} to find any {{shortest}} <b>augmented</b> <b>path</b> from a vertex, DFS returns false. In this case it would be good to mark these vertices to not to visit them again. This marking is simply done by setting Distu to infinity.|$|R
