59|523|Public
40|$|An {{approach}} to multiple asteroid rendezvous missions {{to the main}} belt region is proposed. In this approach key information which consists of a launch date and delta V can be generated for all possible pairs of asteroids satisfying specific constraints. This information is made available on a computer file for 1000 numbered asteroids with reasonable <b>assumptions,</b> <b>limitations,</b> and approximations to limit the computer requirements {{and the size of}} the data file...|$|E
40|$|Maintenance or {{restoration}} of physical aquatic habitat in streams during critical periods {{can often be}} accommodated {{with the development of}} low-flow channels, designed to concentrate flows and increase channel velocity and depth during low-flow periods. A procedure for the first-order approximation of a stable low-flow channel form based upon physical reasoning, empirical evidence, and constraints common to low-flow channel projects is presented in this technical note. Topics discussed include simplifying <b>assumptions,</b> <b>limitations,</b> and applicability. PLANNIN...|$|E
40|$|This paper surveys global {{illumination}} algorithms for environments including participating {{media and}} accounting for multiple scattering. The {{objective of this}} survey is the characterization of those methods: Identification of their base techniques, their <b>assumptions,</b> <b>limitations</b> and range of utilization. To this end, the algorithms are grouped into functional categories and each method is briefly reviewed, {{with a discussion of}} its complexity and its pros and cons. We finish by discussing some applications as well as remaining areas for investigation...|$|E
30|$|We next discuss basic {{principles}} of how GW processes are represented in atmospheric models, reviewing the underlying <b>assumptions</b> and <b>limitations.</b>|$|R
40|$|Abstract. Identity-based {{encryption}} (IBE) techniques {{promise to}} solve the key distribution problem for secure email. We argue that before this technology is adopted for the important application of secure email {{it needs to be}} critically examined in terms of its benefits and risks. To that end our analysis summarizes the unique benefits of IBE and also the significant <b>assumptions</b> and <b>limitations</b> behind it. We then argue that all of these benefits can be achieved with RSA without any additional <b>assumptions</b> and <b>limitations</b> by developing IB-MKD (Identity Based- Message Key Distribution). ...|$|R
50|$|Users of valuations benefit when key information, <b>assumptions,</b> and <b>limitations</b> are {{disclosed}} to them. Then they can weigh {{the degree of}} reliability of the result and make their decision.|$|R
40|$|International Telemetering Conference Proceedings / October 18 - 21, 2004 / Town & Country Resort, San Diego, CaliforniaThere are {{a number}} of {{telemetry}} applications where {{it would be helpful to}} have networks of sensors that could autonomously discover their connectivity, and dynamically reconfigure themselves during use. A number of research groups have developed wireless ad-hoc sensor network systems. This paper reviews the state-of-the-art in wireless ad-hoc networks, examining the features, <b>assumptions,</b> <b>limitations</b> and unique attributes of some of the more popular solutions to this problem...|$|E
40|$|Assessing {{the status}} of widely {{distributed}} marine species can prove difficult because virtually every sampling technique has <b>assumptions,</b> <b>limitations,</b> and biases that affect {{the results of the}} study. These biases often are overlooked when the biological and nonbiological implications of the results are discussed. In a recent review, Thompson (1988) used mostly unpublished population census data derived from studies conducted by the National Marine Fisheries Service (NMFS) to draw conclusions about {{the status of}} Kemp's ridley, Lepidochelys kempi; Atlantic coast green turtles, Chelonia mydas; and the loggerhead sea turtle, Caretta caretta...|$|E
40|$|Abstract: This paper surveys global {{illumination}} algorithms for environments including participating {{media and}} accounting for multiple scattering. The {{objective of this}} survey is the characterization of those methods: Identification of their base techniques, their <b>assumptions,</b> <b>limitations</b> and range of utilization. To this end, the algorithms are grouped into functional categories and each method is briefly reviewed, {{with a discussion of}} its complexity and its pros and cons. We finish by discussing some applications as well as remaining areas for investigation. inria- 00510096, version 1 - 17 Aug 2010...|$|E
50|$|Computational Limitations: Make {{the minimal}} <b>assumptions</b> about {{computational}} <b>limitations.</b>|$|R
30|$|Overall, {{there are}} {{different}} methods that can be utilized to design a waste stabilization pond. Choosing the appropriate design technique requires careful consideration of <b>assumptions</b> and <b>limitations,</b> pond type, and the wastewater quality indicators that are desired to be analyzed and removed.|$|R
40|$|A {{modified}} {{method for}} fitting {{the model of}} Shemin and Rittenberg to study {{the life span of}} red cells is described. In this modification the assumption that incorporation of tag is complete before any cells die is relaxed. A recursion formula useful for fitting the model on the digital computer is given. Good results were obtained with data from the sheep, rat, cat, rabbit, and the dog, whereas in several of these cases the method of Shemin and Rittenberg was not satisfactory. By varying critical parameters of the model a continuum of curves is possible. Curves which formerly were explained on the basis of random death can be obtained without this <b>assumption.</b> <b>Limitations</b> and implications of the method are discussed...|$|R
40|$|The {{central theme}} {{and purpose of}} the paper is to {{illustrate}} and describe the asymmetric technology partnership formation in the ICT sector and compare how well partnering in such high-velocity environment is explained by the Interaction Approach (Håkansson 1982). The evaluation of the Interaction Approach will be done by analysing and comparing its basic <b>assumptions,</b> <b>limitations</b> and propositions to the empirical reality of asymmetric partnerships in the ICT sector. Our endeavour is finalized by the discussion of how the Interaction Approach should be interpreted and applied in the high-velocity environment...|$|E
40|$|Abstract { With {{the growing}} {{emphasis}} on reuse, software development process moves toward component-based software design. In this paper we present anoverview of the architecturebased approach to reliability {{estimation of the}} software composed of components. First, the common requirements of the architecture-based models are identi ed, and the classi cation is proposed. Then, the key models in each class are described in detail. Also, a critical analysis of underlying <b>assumptions,</b> <b>limitations</b> and applicability of these models is provided which should be helpful in determining the directions for future research. Keywords { Architecture-based software reliability, state-based models, path-based models, additive models. 1...|$|E
40|$|Data {{acquisition}} {{systems are}} becoming widespread in various motorsport categories. Manufacturers and suppliers of such systems can provide excellent training materials regarding their installation and use {{but it is}} felt that the advantage goes to those teams with full understanding of the issues associated with obtaining and interpreting data. In particular, <b>assumptions,</b> <b>limitations</b> and sources of error associated with sensors and data processing systems {{must be at least}} appreciated for understanding and making decisions based on information yielded. This paper highlights some of these issues and recommends that suitable education courses be completed by practitioners in the field...|$|E
40|$|Three {{chemical}} fate models (SLSA, TOXIC and EXAMS II) {{were applied}} to a flood control/recreational reservoir in Iowa to assess the long-term fate of a persistent chemical, dieldrin. These models were validated via calibration, verification and sensitivity analysis based on 16 years of field data sets. The three models were calibrated interactively to supplement the shortcomings of an individual model and minimize differences between them. The results indicated that these models can serve as useful tools for assessing the long-term fate of persistent chemicals, {{as long as the}} user is fully aware of the model <b>assumptions</b> and <b>limitations.</b> The models were discussed in terms of differences, <b>assumptions</b> and <b>limitations</b> to aid model users in their understanding and in the proper choice of the models for their applications...|$|R
30|$|By definition, any {{subset of}} GCMs is a {{reduction}} in information compared to the full ensemble and therefore subsetting should only be undertaken when limited resources are required elsewhere in an integrated assessment process. A clear understanding of <b>assumptions</b> and <b>limitations</b> is therefore necessary when subsetting is necessary.|$|R
40|$|MERIDL is {{a program}} that calculates a meridional plane stream {{function}} solution, and TSONIC {{is a program}} that calculates a blade to blade stream function solution for turbomachine blade passages. Both programs are discussed, including input required and <b>assumptions</b> and <b>limitations.</b> Examples of use and references are included...|$|R
40|$|To include {{competitive}} {{interactions in}} a physiologically-based model of mixed growth-form plant communities presents a major methodological problem. This paper outlines a two-step solution: (1) a spatial framework for calculating a continuous surface that depicts {{the magnitude of}} influences of crowns, roots, and stems on resource availability, termed ECOLOGICAL FIELD THEORY (EFT), and (2) a mathematical technique for coupling water, light, and nutrients into a single growth equation using a physiologically-based continuous-time Markov approach, termed the CTM METHOD. <b>Assumptions,</b> <b>limitations,</b> and an application of the methodology to plant growth in a semiarid woodland community in Australia are presented...|$|E
40|$|International audienceRendering {{participating}} {{media is}} important {{for a number of}} domains, ranging from commercial applications (entertainment, virtual reality) to simulation systems (driving, ﬂying and space simulators) and safety analyses (driving conditions, sign visibility). This article surveys global illumination algorithms for environments including participating media. It reviews both appearance-based and physically-based media methods, including the single scattering and the more general multiple-scattering techniques. The objective of the survey is the characterization of all these methods: Identiﬁcation of their base techniques, <b>assumptions,</b> <b>limitations</b> and range of utilization. We conclude with some reﬂections about the suitability of the methods depending on the speciﬁc application involved, and possible future research lines...|$|E
40|$|The paper {{gives an}} {{overview}} and evaluates the theoretical traditions underlying choice models {{that are used}} in marketing. In particular, the emphasis of this essay is on the underlying <b>assumptions,</b> <b>limitations</b> and empirical demands of these choice models. Four fundamental choice models are used as a basis to analyze this complex field; the neoclassical economic theory as extended by Lancaster, the Risk-Preference Theory of Choices under uncertainty, the Strict Utility Theory and the Random Utility Theory. These four choice models and their extensions are compared and contrasted along the three critical steps in the model building process: theory generation, parameterization and estimation. choice models, economics, psychology...|$|E
40|$|The objectives, approach, <b>assumptions,</b> and <b>limitations</b> of a {{study of}} nuclear waste {{disposal}} in space are discussed with emphasis on the following: (1) payload characterization; (2) safety assessment; (3) health effects assessment; (4) long-term risk assessment; and (5) program planning support to NASA and DOE. Conclusions are presented for each task...|$|R
50|$|A {{description}} of Debye-Hückel theory includes a very {{detailed discussion of}} the <b>assumptions</b> and their <b>limitations</b> {{as well as the}} mathematical development and applications.|$|R
40|$|Until recently, {{much effort}} {{has been devoted to}} the {{estimation}} of panel data regression models without adequate attention being paid to the drivers of diffusion and interaction across cross section and spatial units. We discuss some new methodologies in this emerging area and demonstrate their use in measurement and inferences on cross section and spatial interactions. Specifically, we highlight the important dis?tinction between spatial dependence driven by unobserved common factors and those based on a spatial weights matrix. We argue that, purely factor driven models of spatial dependence may be somewhat inadequate because of their connection with the exchangeability <b>as?sumption.</b> <b>Limitations</b> and potential enhancements of the existing methods are discussed, and several directions for new research are highlighted. Cross Sectional and Spatial Dependence, Spatial Weights Matrix, Interactions and Diffusion, Monetary Policy Committee, Generalised Method of Moments. ...|$|R
40|$|AbstractWith growing {{emphasis}} on reuse, the software development process moves toward component-based software design. As a result, {{there is a}} need for modeling approaches that are capable of considering the architecture of the software made out of components. This paper presents an overview of the state of the research and practice in the architecture-based approach to quantitative assessment of software systems. First, the common requirements of the architecture-based models are identified and the classification is proposed. Then, the key models in each class are described in detail with a focus on their relation and unification. Finally, a critical analysis of the underlying <b>assumptions,</b> <b>limitations,</b> and applicability of these models is provided, which should be helpful in determining the directions for future research...|$|E
40|$|Abstract. In this work, the {{analysis}} of Hutchinson and Neale is used for wrinkling prediction. Under a number of <b>assumptions,</b> <b>limitations</b> and simplifications a wrinkling criterion with some restrictive applicability, is obtained. Unfortunately, Hutchinson analysis is limited to regions of the sheet that are free of any contact. When contact is taken into account the problem is further complicated. Consequently, a local indicator based on the change of curvatures under compressive stresses is developed. Both wrinkling indicators are used to drive the adaptive mesh refinement {{in order to be}} able to accurately spot wrinkling. The numerical results will be compared to those obtained through experimental testing. A number of hemispherical product samples have been used with various blank holder forces and drawn to different depths to capture the onset of wrinkling, its mode and location...|$|E
40|$|This {{document}} {{presents a}} detailed {{record of the}} methodologies, <b>assumptions,</b> <b>limitations,</b> and references used in creating the human figure model in Jack, a program that displays and manipulates articulated geometric figures. This report reflects current efforts to develop and refine Jack software to enable its validation and verification {{as a tool for}} performing human engineering analysis. These efforts include human figure model improvements, statistical anthropometric data processing methods, enhanced human figure model construction and measuring methods, and automated accomodation analysis. This report discusses basic details of building human models, model anthropometry, scaling, Jack anthropometry-based human models, statistical data processing, figure generation tools, anthropometric errors, inverse dynamics, smooth skin implementation, guidelines used in estimating landmark locations on the model, and recommendations for validating and verifying the Jack human figure model...|$|E
50|$|There {{is a need}} to {{understand}} how a language classification method works in order to determine its <b>assumptions</b> and <b>limitations.</b> It may only be valid under certain conditions or be suitable for small databases. The methods differ in their data requirements, their complexity and running time. The methods also differ in their optimisation criteria.|$|R
40|$|Abstract of {{the article}} {{referenced}} in the citation field. Original in Spanish. Objectives: To present the <b>assumptions</b> and <b>limitations</b> of "lifestyle", to then submit the contributions of social epidemiology. U. S. Department of Education Title VI TICFIA (Technological Innovation and Cooperation for Foreign Information Access) P 337 A 050005, University of New Mexico/Universidad de Guadalajara Centro Universitario de Ciencias de la Salud (CUCS...|$|R
40|$|In {{this paper}} we discuss a {{mathematical}} model for gas storage processes. In addition we outline an approach for numerical simulations. The focus is on model <b>assumptions</b> and <b>limitations</b> with respect to the software to be developed. AMS Subject Classification (1991) : 65 M 06, 76 S 05 Keywords & Phrases: second-order accurate discretizations, gas storage 1. Introduction Gas injection into gas reservoirs can be considered for reasons of gas storage or CO 2 disposal. It is {{the purpose of this paper}} to present a basic mathematical model for these gas injection processes, and to outline a numerical approach. Since we aim at developing numerical software, we focus on the model <b>assumptions</b> and <b>limitations</b> (Section 2). The mathematical model used (Section 3) is quite standard, and is discussed in more detail in [2] and [3]. In addition to the mathematical model we outline the numerical method to be used (Section 4). After discussing the concept of numerical diffusion, we propose a method that shou [...] ...|$|R
40|$|Values are {{fundamental}} to choice and decision. This paper addresses how {{the notion of}} value is implicated, addressed and integrated in relation to decisions that affect natural areas. Three topics - rationality, citizen participation and values - are brought together {{in a review of}} methods for value integration. Each method is discussed in relation to its processes and products, value inclusiveness, <b>assumptions,</b> <b>limitations,</b> strengths and application. None of the methods have the ability to integrate all relevant values for all actors across the variety of contexts in which environmental choices must be made. Application of an integrative rationality is needed to yield a combined approach that utilises a number of methods such that their respective limitations and weaknesses are, as far as possible, overcome. A crucial task is to enhance our capacity for designing citizen-inclusive, value comprehensive and transparent multi-method processes...|$|E
40|$|Text and {{accompanying}} data tables {{in this report}} compare Hagerstown Junior College (HJC) with the Maryland community colleges as a whole {{with regard to the}} findings of three statewide follow-up studies: a survey (conducted in Spring, 1978) of first-time students who entered the colleges i- Fall, 1974; a survey (conducted in Spring, 1980) of first-time students who entered the colleges in Fall, 1976; and a survey (conducted in Spring, 1981) of students who graduated from the colleges in 1980. The report first summarizes the goals, <b>assumptions,</b> <b>limitations,</b> methodology, procedures, and return rates for the three studies, which were designed {{to evaluate the effectiveness of}} the Maryland community colleges in helping students achieve educational goals, find employment, or uransfer to a university. The next three sections of the report compare HJC and statewide findings for the two first-time student surveys, for th...|$|E
40|$|The {{self-controlled}} {{case series}} method {{was developed to}} investigate associations between acute outcomes and transient exposures, using only data on cases, that is, on individuals who have experienced the outcome of interest. Inference is within individuals, and hence fixed covariates effects are implicitly controlled for within a proportional incidence framework. We describe the origins, <b>assumptions,</b> <b>limitations,</b> and uses of the method. The rationale for the model and the derivation of the likelihood are explained in detail using a worked example on vaccine safety. Code for fitting the model in the statistical package STATA is described. Two further vaccine safety data sets are used to illustrate a range of modelling issues and extensions of the basic model. Some brief pointers {{on the design of}} case series studies are provided. The data sets, STATA code, and further implementation details in SAS, GENSTAT and GLIM are available from an associated websit...|$|E
40|$|This article {{suggests}} {{ideas for}} introducing integer modeling of fixed (entry) costs with Excel Solver to business students. The presented example uses concepts from accounting, such as assessing distribution channel prof-itability, and blends them with management science techniques. The {{effectiveness of the}} software use is in in-tegrating it successfully into a comprehensive discussion about <b>assumptions,</b> modeling, <b>limitations,</b> software pitfalls, validation, and implications for managerial decision making. 1...|$|R
40|$|We {{sought to}} {{estimate}} the number of crocodile nests on the Liverpool River, Northern Territory, Australia. Two methods of survey were available, aerial survey and ground survey, in each of which sightings could be mapped. Hence, those nests which were detected by both methods could be identified. These counts were used to demonstrate the method by which an estimate of total number could be calculated. The <b>assumptions</b> and <b>limitations</b> are discussed...|$|R
40|$|Abstract While many lessons {{have been}} {{learned from the}} spatial {{analysis}} of cancer, there are several caveats that apply to many, if not all such analyses. As "flies in the ointment", these can substantially detract from a spatial analysis, and if not accounted for, can lead to weakened and erroneous conclusions. This paper discusses several <b>assumptions</b> and <b>limitations</b> of spatial analysis, identifies problems of scientific inference, and concludes with potential solutions and future directions. </p...|$|R
