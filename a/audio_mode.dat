27|72|Public
5000|$|Discs marketed without [...] "music" [...] {{endorsement}} aren't rejected since Yellow Book mode (CD-ROM) {{is being}} used instead of Red Book <b>audio</b> <b>mode.</b>|$|E
50|$|When the <b>audio</b> <b>mode</b> of HDR-FX1/HDR-FX1E {{camcorder}} is {{switched to}} the 16-bit setting (in DV mode) and the unit is then turned off, the unit resets to the default 12-bit setting, though the LCD indicator of the unit continues to display the 16-bit audio setting.|$|E
50|$|The link {{security}} modes and mega stereo {{cable support}} {{are not available}} on the Sound Blaster Roar 2. The Roar button has been combined with the TeraBass button behind the speaker. There is a switch to toggle between USB Mass Storage mode and USB <b>Audio</b> <b>mode.</b>|$|E
50|$|A video decoder’’’ It {{transforms}} video packets into {{a sequence}} of pictures, which are displayed by the TV monitor.An audio decoder’’’ It decompresses the audio bit-stream. Different <b>audio</b> <b>modes</b> are usually supported by the DTV receiver: mono and dual channel, stereo, and joint stereo.A data decoder.|$|R
500|$|The DWG distinguishes two <b>audio</b> device <b>modes</b> {{specification}}s: Audio1.0 specification and Audio2.0 specification. Three {{types of}} devices are defined: ...|$|R
5000|$|The DWG distinguishes two <b>audio</b> device <b>modes</b> {{specification}}s: <b>Audio</b> 1.0 specification and Audio 2.0 specification. Three {{types of}} devices are defined: ...|$|R
50|$|On the {{right-hand}} side of the phone there are three keys - two for controlling volume (when in <b>audio</b> <b>mode),</b> skipping through tracks in the Media Player and zooming in and out when in camera mode after the photograph has been taken. The included handsfree headset is also required to listen to the radio since it functions as the antenna.|$|E
50|$|For sound generation, the SCSP {{contains}} 32 sound generators {{which can}} function in either FM synthesis or PCM digital <b>audio</b> <b>mode.</b> The sound generation hardware is then {{fed into the}} FH-1 128-step sound effects Digital Signal Processor, which includes 16 sound effect presets. Finally each audio channel is mixed together, with fully configurable channel combining for various levels of FM generation complexity. This allowed the channels to modulate each other, in practice four generators were connected at a time but all 32 generators could be combined into one channel if desired. The SCSP also included a 7-level interrupt controller.|$|E
5000|$|My Little Eye is {{available}} on DVD from MCA/Universal Home Video {{with most of the}} special features available on the Region 2 Special Edition including a filmmakers' commentary and deleted scenes. There is an <b>audio</b> <b>mode</b> [...] "Conversations of the Company (Eavesdropping Audio Track)" [...] which allows the viewer to listen to the radio conversations between the members of the company: Travis and [...] "the cop". However, during this mode, the viewer cannot hear all of the dialogue of the cast in the scene. A UK release contains a 'Special Mode' where viewers see the film from the perspective of an internet subscriber, and more extra features become unlocked as the film goes on. You can watch other things going on in 'the house' in real time to what's happening in the film.|$|E
5000|$|PUMA: Protected User <b>Mode</b> <b>Audio</b> (PUMA) {{is the new}} User <b>Mode</b> <b>Audio</b> (UMA) audio stack. Its aim is {{to provide}} an {{environment}} for audio playback that restricts the copying of copyrighted audio, and restricts the enabled audio outputs to those allowed by {{the publisher of the}} protected content.|$|R
50|$|For normal dial-up data communications, modems enter data mode {{only once}} - {{starting}} when the session connects, and ending when the session disconnects. However, when modems {{are used for}} fax and voice (audio) communication, they rapidly switch between command and data modes several times during a call. This is because {{the role of the}} modem changes more frequently - rather than simply handing bytes from point A to point B, it is either negotiating parameters and pages with a fax machine, or switching between recording, pausing, and playback <b>audio</b> <b>modes.</b>|$|R
5000|$|General Settings: The hoster of {{chat room}} {{ability to control}} general {{settings}} such as Auto anti-scroll/anti-spam filter, automatically kicked users without webcams, not allow to bring any Camfrog Bots, Only set teen room (13-19 years old), disable microphone usage, chat commands, set topic by only owners, disabled hyperlinks to non-members of room, adjust the timer for microphone usage, adjust the timer to block the microphone, default ban time, set default expire punish time, and control of maximum allowed number of users. The hoster of room also can adjust the typical of <b>audio</b> <b>modes.</b>|$|R
3000|$|To {{calculate}} the join cost between two segments, both auditory and visual properties are used. For the <b>audio</b> <b>mode,</b> we measure {{the difference in}} energy and spectrum (the Euclidean distance between the MFCC's). Pitch levels are also taken into account by calculating the absolute difference in logarithmic [...]...|$|E
40|$|In {{this paper}} {{we present a}} case study of kids' {{appropriation}} of GarageBand digital music software to create an informal, ad hoc collaborative process. We argue that elements of the socio-spatial context of use combined with the software and the <b>audio</b> <b>mode</b> created a "safe" space for collaboration and a powerful mode for informal creative exchange and feedback. We conclude with suggestions for future study and questions to consider for the design of systems to support kids' creative collaboration...|$|E
30|$|In {{this paper}} we have {{described}} our strategy to perform audiovisual text-to-speech synthesis. We adopted the unit selection method {{to work with}} multimodal units, using audiovisual selection costs. This strategy {{makes it possible to}} create multimodal speech signals of which the synthetic <b>audio</b> <b>mode</b> and the synthetic video mode are highly coherent. This differs from most strategies found in the literature, which use completely separated systems, methods and databases to construct the auditory and the visual mode of the output speech.|$|E
50|$|EVS employs similar {{concepts}} to its predecessors, such as AMR-WB, {{to which it}} retains backward-compatibility. It switches between speech and <b>audio</b> compression <b>modes</b> depending on the content, using ACELP and MDCT.|$|R
50|$|As {{with many}} of Creative's {{previous}} sound cards, the X-Fi supports SoundFonts. Additionally, the <b>Audio</b> Creation <b>Mode</b> of the card allows the use of EAX in MIDI playback via the use of controllers.|$|R
50|$|Android version: Published by MobiSystems, Inc. Premium version {{includes}} <b>audio</b> pronunciation, offline <b>mode,</b> priority support, no ads.|$|R
40|$|Based on the {{assumption}} that providing information using multiple modalities improves learners’ performance, the teaching of computer-aided design (CAD) in the built environment is increasingly shifting from printed material to a multimedia approach. Yet, the evidence base suggests that presenting information by using multiple modalities does not always enhance learning. This paper reports on an empirically based study that sought to determine under which conditions architectural engineering students benefit most from multimedia CAD learning. It investigated the effects of multimedia on novice CAD learners’ practice performance (time and accuracy). One hundred and one students were randomly assigned to four groups to undertake specific CAD learning tasks, with different treatments; media mode (printed-text vs. audio) and the visual mode (static-illustration vs. animation). The results indicated that the <b>audio</b> <b>mode</b> shortened learning time much more than the text mode. Conversely, the text mode enhanced CAD design accuracy, in comparison with the <b>audio</b> <b>mode</b> with the illustration mode alone. In addition, the animation mode improved design accuracy with text and audio significantly more than with illustration visual mode. The animation mode increased the learning time considerably with the text mode. The implications of the design of CAD instructional materials for architectural engineering education are examined...|$|E
40|$|Abstract — The diverse access {{technologies}} used IP Multimedia (IMS) as {{a solution}} for providing robust multimedia applications and bandwidth optimization. Information sharing by the audio / video call through ubiquitous innovative applications and bandwidth utilization is gaining more popularity in the mobile world. This paper provides a novel solution for seamless connectivity through codec switching and bandwidth optimization by using an IMS server in real time. The mobile user will switch from <b>audio</b> <b>mode</b> to video mode and vice versa without losing connectivity. The technique used in our developed application will optimize the bandwidth utilization in an efficient way...|$|E
3000|$|... [...]. Note {{that the}} quality of the {{separate}} <b>audio</b> <b>mode</b> of the (SVO) samples is at least as high as the quality of the <b>audio</b> <b>mode</b> of the (MUL) samples, since the (SVO) samples are synthesized using only acoustic selection costs. In addition, the ARCTIC database is much larger than the LIPS 08 database which results in more candidate units for synthesis. This implies that the perceived naturalness of the visual speech of the (SVO) sentences was degraded by the artificial combinations of audio/video present in these samples. This indicates that the minimization of such intermodal mismatches will have a profound positive influence on the perceived overall naturalness. In contrast, only a little decrease in perceived naturalness is noticed between the (MUL) and the (SAV) samples. As explained earlier, for both groups the audio quality and the degree of audiovisual coherence are probably too similar to cause noticeable perception differences. It also shows that the synchronization of the two separately synthesized modes was realized with appropriate accuracy. Further analysis of the test results shows that there exists a difference between the ratings for the (MUL) samples and the ratings for the (RES) samples. Since the audio track of the (RES) samples contained natural auditory speech, an optimal perception of these video tracks could be expected. However, the results indicate that the viewers gave a higher rating to the samples of the (MUL) group [...]...|$|E
5000|$|Yate/YateClient {{supports}} Jingle in both {{client and}} server <b>mode,</b> <b>audio</b> and file transfer, also call transfer and DTMF.|$|R
5000|$|... 2002 - Received the American Association for Public Opinion Research Innovators Award for the {{development}} of the <b>Audio</b> Computer-Assisted Self-Interviewing <b>mode</b> of survey data collection ...|$|R
50|$|Freemake Audio Converter {{features}} a batch <b>audio</b> conversion <b>mode</b> to convert multiple audio files simultaneously. The program can also combine multiple audio files {{into a single}} file. The software includes several ready-made presets for each supported output file format {{and the ability to}} create a custom preset with the adjustment of bitrate, audio channels, and sample rate.|$|R
40|$|The {{ubiquitous}} {{computers with}} multimedia technology {{serve as an}} attractive learning tool because {{they are able to}} deliver integrated, different source media as well as access these media easily and instantaneously. Thus, to take advantage of these qualities to help language learners, multimedia annotations of lexical items, which present information of the items via printed text, <b>audio</b> <b>mode,</b> still pictures and animation, are utilized. This paper reports on the effects of integrating multimedia annotations in expository texts on the learning of lexical items by 109 Science students from Universiti Sains Malaysia. In this within-subjects design study, the participants read expository texts on the computer. ...|$|E
3000|$|For {{this test}} {{we used the}} same groups of samples as we used in the first {{experiment}} (ORI, MUL, SAV, and SVO), augmented with a fifth group (RES) containing sentences from which the <b>audio</b> <b>mode</b> is an original recording from the LIPS 2008 database. The video mode of these samples was synthesized using the [...] "best video quality'' settings and the LIPS 2008 speech database from which the particular sentence was excluded. Afterwards, both modes were aligned and joined {{in the same way}} as we did for the (SVO) and (SAV) samples. Note that this synthesis method can be seen as a special case of audio-driven visual speech synthesis, where the auditory speech used as input and the video database used for synthesis are recordings from the same speaker.|$|E
40|$|This study aims to {{test the}} {{relative}} effectiveness of testimonials compared to simple informational health messages, presented both through different modalities and to recipients with different levels of involvement. Results of the three independent exper-iments demonstrate that testimonials are more persuasive when presented through the <b>audio</b> <b>mode</b> rather than when presented through the written mode. Also, the informa-tional messages are more persuasive when perceived by individuals characterized by high rather than low involvement and high rather than low need for cognition. The results are {{explained in terms of}} the Elaboration Likelihood Model. The interactive effect of transportation and involvement on persuasion is further examined. The find-ings help in the development of more efficient message targeting. The highest level of efficiency can be achieved if the appropriate media modality and message format are used for recipients with certain initial involvement or need for cognition...|$|E
50|$|Frequencies above 30 MHz are {{referred}} to as Very High Frequency (VHF) region and those above 300 MHz are called Ultra High Frequency (UHF). The allocated bands for amateurs are many megahertz wide, allowing for high-fidelity <b>audio</b> transmission <b>modes</b> (FM) and very fast data transmission modes that are unfeasible for the kilohertz-wide allocations in the HF bands.|$|R
40|$|This paper {{presents}} a research of current practices in audio description broadcast in Spanish television channels. The {{results of this}} research show that in some television channels the audio description is broadcasted in ‘receiver mix <b>audio</b> description’ <b>mode</b> while in other channels the alternative used is ‘broadcaster mix <b>audio</b> description’ <b>mode.</b> In both cases, correct signalling and correct audio description coding is crucial so that digital television receivers can recognize audio description in the broadcast signal and reproduce it upon user request. The current practice of audio description broadcast in Spanish television channels only partially fulfils DVB standard. In addition, not all digital television receivers are able to reproduce appropriately {{the wide range of}} options defined in DVB to convey audio description in the television channels. The consequence for the users is less availability of audio description services than expected. Some of the problems detected for the activation of audio description in users’ receivers can be solved by applying some enhancement to signalling information used by broadcasters in their DVB television channels. Finally, some recommendations for the users are included to present the key aspects for audio description activation in their digital television receivers. Peer Reviewe...|$|R
50|$|The USB Type-C Cable and Connector Specification Revision 1.1 {{specifies}} {{a mapping}} from a USB Type-C jack to a 4-pole TRRS jack, {{for the use}} of headsets, and supports both CTIA and OMTP (YD/T 1885-2009) <b>modes.</b> See <b>Audio</b> Adapter Accessory <b>Mode</b> (Appendix A).|$|R
40|$|The aim of {{this paper}} is to offer a preview of the pilot project in {{progress}} at the “Paolo Orsi” Regional Archaeological Museum of Syracuse, in Sicily (Italy). Thanks to a free partnership with Google Business Photos/Street View Indoor, we managed to map the entire museum, the only archaeological museum in South Italy that can be visited online on a 360 ° tour on a Google platform. Also a dozen archaeological finds have been selected which can be clicked as points of interest from the museum windows and explored, taking 360 ° virtual tours. They are provided with descriptive sheets, and could be also available in <b>audio</b> <b>mode.</b> In this way, the “Paolo Orsi” Museum is also an unicum on Google map with 360 ° virtual tours with integration of captions and full description of artworks. The aim of the project is, finally, is to begin to bridge the gap of Sicilian Cultural Heritage’s visibility on the web...|$|E
40|$|Technology changes often force teachers, trainers, {{instructional}} designers, {{and administrators}} to make instructional design and delivery decisions that ideally {{should be based}} upon pedagogy research. In many circumstances, however, a foundational pedagogy question is only recognized when a technology decision reveals it. Such is the case when deciding what mode (video or audio) to use for learner interaction in a synchronous online learning event. While some {{research has focused on}} the learning and the satisfaction of learners when they were interacting, almost no research has addressed the learning value of observing the interactions of other learners. The purpose of this research study was to investigate whether the mode in which direct learner interactions were made affected non-interacting learners 2 ̆ 7 recall of content in a synchronous virtual learning environment. The participants in this study viewed one of three versions of a webinar on Multimedia Games for Learning: a) all learners interacted in video mode; b) all learners interacted in audio mode; or all learners interacted in both video and audio in a mixed mode. No statistically significant difference was found between the video, audio, and mixed treatment conditions in terms of the recall of content from the questions or comments made by directly interacting learners. However, a statically significant difference was found in non-interacting learners 2 ̆ 7 recall of the contributions of direct interactors based on the mode of interaction within the mixed-mode group. Study participants recalled more of the contributions made in the <b>audio</b> <b>mode</b> of interaction than in the video mode when the modes were mixed. These findings suggest that designers of synchronous online learning may choose either video or <b>audio</b> <b>mode</b> without affecting those learners who are not directly interacting but should take care in mixing interaction modes within a single synchronous online learning event. The contributions of the study reach beyond the findings. The study supports vicarious interaction as a process worthy of research and e-Learning design consideration. It provides a model for experimental manipulation of 2 ̆ 2 simulated 2 ̆ 2 synchronous sessions, and it introduces recall of others 2 ̆ 7 verbal contributions as an approach to measurement of the attention granted vicarious interactions by those not interacting directly with others...|$|E
40|$|With the {{development}} of automobile industry, the number of private cars is greatly increasing. Correspondingly, the number of rookie drivers is increasing as well. For the rookie drivers, how to backing is always a troublesome operation. Many of them complained that their valuable cars are easily got damaged by obstacles that are hardly seen through their rearview mirror. So in this project, a new type system has been designed: smart system of ultrasonic car parking with different display mode, <b>audio</b> <b>mode</b> and smart mode: i. Liquid crystal display (LCD) display modes: Used to display the zone of your car based on condition that have been set. ii. LED display modes: Ordinary display modes. 6 LEDs are used to display the distance of obstacles. The more LEDs are lightening, the closer obstacles are. iii. A buzzer or a beeper which is a signaling device is used to show {{the distance of the}} car with the obstacles behind it. The faster tone of the beep of buzzer means the distance of obstacles and car are closer. iv. Smart mode: The engine will automatically stop if the car is in stop zone which mean it is dangerous condition to parking the car...|$|E
50|$|VTech {{has been}} {{identified}} as one of the world's top 50 electronics manufacturing services providers, providing electronics manufacturing services for medium-sized companies. VTech's CMS has focused on four main product categories: professional <b>audio</b> equipment, switching <b>mode</b> power supplies, wireless products and solid-state lighting.|$|R
50|$|Audio {{cannot be}} {{recorded}} on a VHS tape without recording a video signal, {{even in the}} <b>audio</b> dubbing <b>mode.</b> If there is no video signal to the VCR input, most VCRs will record black video as well as generate a control track while the audio is being recorded. Some early VCRs would record audio without a control track signal, but this was of little practical use since {{the absence of a}} control track signal meant that the linear tape speed was irregular during playback.|$|R
40|$|In this paper, we {{introduce}} a direct manipulation tabletop multi-touch user interface for spatial audio scenes. Although spatial audio rendering existed {{for several decades}} now, mass market applications have not been developed and the user interfaces still address {{a small group of}} expert users. We implemented an easy-to-use direct manipulation interface for multiple users, taking full advantage of the object-based <b>audio</b> rendering <b>mode.</b> Two versions of the user interface have been developed to explore variations in information architecture and will be evaluated in user tests...|$|R
