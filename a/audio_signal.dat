3200|2506|Public
5|$|Analogue {{filters are}} a basic {{building}} block of signal processing much used in electronics. Amongst their many applications are the separation of an <b>audio</b> <b>signal</b> before application to bass, mid-range and tweeter loudspeakers; the combining and later separation of multiple telephone conversations onto a single channel; {{the selection of a}} chosen radio station in a radio receiver and rejection of others.|$|E
5|$|Quad {{have now}} brought out five {{generations of the}} classic {{electrostatic}} design. Originally designed for monaural sound in a domestic context, the popularisation of stereophonic sound prompted the manufacturer to modify the electrostatic panels to improve their stereo dispersion. These speakers featured larger panels and a revolutionary stator design, made up of eight concentric rings fed from the centre outwards through analogue delay lines, so that the <b>audio</b> <b>signal</b> gives the illusion of radiating from a point source one foot behind the panel.|$|E
5|$|The most {{important}} and widely used application of the heterodyne technique is in the superheterodyne receiver (superhet), invented by U.S. engineer Edwin Howard Armstrong in 1918. In this circuit, the incoming radio frequency signal from the antenna is mixed with a signal from a local oscillator (LO) and converted by the heterodyne technique to a lower fixed frequency signal called the intermediate frequency (IF). This IF is amplified and filtered, before being applied to a detector which extracts the <b>audio</b> <b>signal,</b> which {{is sent to the}} loudspeaker.|$|E
30|$|We {{will only}} {{consider}} tonal <b>audio</b> <b>signals,</b> that is, signals having a continuous spectrum containing {{a finite number}} of dominant frequency components. In this way, the majority of <b>audio</b> <b>signals</b> is covered, except for the class of percussive sounds. The performance of the different LP models described below will be evaluated for three types of audio signals: synthetic <b>audio</b> <b>signals</b> consisting of a sum of harmonic sinusoids in white noise, true monophonic <b>audio</b> <b>signals,</b> and true polyphonic <b>audio</b> <b>signals.</b>|$|R
3000|$|We {{have tested}} the above {{presented}} scheme with <b>audio</b> <b>signals.</b> Since <b>audio</b> <b>signals</b> are nonstationary and the whitening filter [...]...|$|R
3000|$|... − 1 are {{the power}} {{spectrum}} of the original SWB <b>audio</b> <b>signals</b> and extended SWB <b>audio</b> <b>signals</b> at the previous frame.|$|R
5|$|A Leslie speaker {{consists}} {{of a number of}} individual components. The <b>audio</b> <b>signal</b> enters the amplifier from the instrument. Once amplified, the signal travels to an audio crossover, which splits it into separate frequency bands that can be individually routed to each loudspeaker. Different models have different combinations of speakers, but the most common model, the 122, {{consists of}} a single woofer for bass and a single compression driver and acoustic horn for treble. The audio emitted by the speakers is isolated inside an enclosure, aside from a number of outlets that lead towards either a rotating horn or drum. An electric motor rotates both horn and drum at a constant speed.|$|E
5|$|Continuously {{variable}} phase control circuits {{are common in}} subwoofer amplifiers, and {{may be found in}} crossovers and as do-it-yourself electronics projects. Phase controls allow the listener to change the arrival time of the subwoofer sound waves relative to the same frequencies from the main speakers (i.e., at and around the crossover point to the subwoofer). A similar effect can be achieved with the delay control on many home theater receivers. The subwoofer phase control found on many subwoofer amplifiers is actually a polarity inversion switch. It allows users to reverse the polarity of the subwoofer relative to the <b>audio</b> <b>signal</b> it is being given. This type of control allows the subwoofer to either be in phase with the source signal, or 180 degrees out of phase.|$|E
5|$|The {{development}} of commercial sound cinema had proceeded {{in fits and}} starts before The Jazz Singer, and the film's success did not change things overnight. Not until May 1928 did the group of four big studios (PDC had dropped out of the alliance), along with United Artists and others, sign with ERPI for conversion of production facilities and theaters for sound film. Initially, all ERPI-wired theaters were made Vitaphone-compatible; most were equipped to project Movietone reels as well. However, even with access to both technologies, most of the Hollywood companies remained slow to produce talking features of their own. No studio besides Warner Bros. released even a part-talking feature until the low-budget-oriented Film Booking Offices of America (FBO) premiered The Perfect Crime on June 17, 1928, eight months after The Jazz Singer. FBO had come under the effective control of a Western Electric competitor, General Electric's RCA division, which was looking to market its new sound-on-film system, Photophone. Unlike Fox-Case's Movietone and De Forest's Phonofilm, which were variable-density systems, Photophone was a variable-area system—a refinement in the way the <b>audio</b> <b>signal</b> was inscribed on film that would ultimately become the standard. (In both sorts of systems, a specially-designed lamp, whose exposure to the film is determined by the audio input, is used to record sound photographically as a series of minuscule lines. In a variable-density process, the lines are of varying darkness; in a variable-area process, the lines are of varying width.) By October, the FBO-RCA alliance would lead to the creation of Hollywood's newest major studio, RKO Pictures.|$|E
40|$|Kwang-Sub Jeon․Ho-Yong Cheong․Seung-Yo Lee) Abstract- Use of the 5. 1 channel <b>audio</b> <b>signals</b> {{suitable}} for the television system is improper for the radio broadcasting system, which uses the stereo audio system. Therefore, {{it is necessary to}} develop an audio down-mixer to convert 5. 1 multi-channel <b>audio</b> <b>signals</b> to stereo signals for radio broadcasting. In this paper, a development of an audio down-mixer was carried out to convert 5. 1 multi-channel <b>audio</b> <b>signals</b> to stereo signals. The down-mixer which was developed can use the <b>audio</b> <b>signals</b> separated from video signals, including sound signals or individual signals provided from 3 -channel AES/EB...|$|R
40|$|The method {{involves}} {{transforming the}} <b>audio</b> <b>signals</b> to a spectral range and determining a masking threshold (W(omega)) for the <b>audio</b> <b>signals.</b> The method also provides pseudorandom noise signals and data signals. The pseudorandom noise signals are multiplied {{with the data}} signals in order to evenly spread the data signal over a frequency range. The spread data signal is then weighted with the masking threshold and overlaid with the <b>audio</b> <b>signals.</b> Preferably when transforming the <b>audio</b> <b>signals</b> the method uses a fast fourier transform. USE/ADVANTAGE - E. g. for spread spectrum communication system. Reduces interference and multipath propagation...|$|R
30|$|The mood {{recognition}} module {{is activated}} when the perception system detects musical <b>signals.</b> <b>Audio</b> <b>signals</b> transmitted through a microphone of a robot {{can be either}} musical signals or human voice <b>signals.</b> Thus, the <b>audio</b> <b>signals</b> need to be classified into music and voice, since the system is programmed to process voice signals in the speech emotion recognition module. For the classification of <b>audio</b> <b>signals,</b> we employ the standard method of voice activity detection based on the zero crossing rate (ZCR) and energy [25]. When the <b>audio</b> <b>signals</b> indicate relatively high values in both ZCR and energy, the signals are regarded as musical signals. Otherwise, the signals are categorized as voice signals and submitted to the speech processing module.|$|R
25|$|An {{expander}} {{increases the}} dynamic {{range of the}} <b>audio</b> <b>signal.</b> Expanders are generally used to make quiet sounds even quieter by reducing the level of an <b>audio</b> <b>signal</b> that falls below a set threshold level. A noise gate {{is a type of}} expander.|$|E
25|$|It is also {{possible}} to measure traffic density on a road using the <b>Audio</b> <b>signal</b> that consists of the cumulative sound from tire noise, engine noise, engine-idling noise, honks and air turbulence noise. A roadside-installed microphone picks up the audio that comprises the various vehicle noise and <b>Audio</b> <b>signal</b> processing techniques {{can be used to}} estimate the traffic state. The accuracy of such a system compares well with the other methods described above.|$|E
25|$|In {{an article}} {{released}} in January 2014 by the Journal of the Audio Engineering Society, Emmanuel Deruty and Damien Tardieu performed a systematic study describing {{the influence of}} compressors and brickwall limiters on the musical <b>audio</b> <b>signal.</b> The experiment involved four software limiters: Waves L2, Sonnox Oxford Limiter, Thomas Mundt’s Loudmax, Blue Cat’s Protector, as well as four software compressors: Waves H-Comp, Sonnox Oxford Dynamics, Sonalksis SV-3157, and URS 1970. The study provides objective data on what limiters and compressors do to the <b>audio</b> <b>signal.</b>|$|E
50|$|The Sound Blaster X7’s Bluetooth {{feature is}} only for {{receiving}} <b>audio</b> <b>signals</b> from Bluetooth devices, it can’t be used for transmitting <b>audio</b> <b>signals</b> to Bluetooth speakers and headphones.The Bluetooth codecs supported by the X7 are AAC, SBC, aptX and aptX Low Latency.|$|R
50|$|<b>Audio</b> <b>signals</b> are {{electronic}} {{representations of}} sound waves—longitudinal waves which travel through air, consisting of compressions and rarefactions. The energy contained in <b>audio</b> <b>signals</b> is typically measured in decibels. Audio processing {{was necessary for}} early radio broadcasting, as there were many problems with studio to transmitter links.|$|R
40|$|We {{address the}} issue of {{automatically}} extracting rhythm descriptors from <b>audio</b> <b>signals,</b> to be eventually used in content-based musical applications such as in the context of MPEG 7. Our aim is to approach the comprehension of auditory scenes in raw polyphonic <b>audio</b> <b>signals</b> without preliminary source separation...|$|R
25|$|PSAP models differ {{significantly}} in price and functionality. Some devices simply amplify sound. Others contain directional microphones, equalizers {{to adjust the}} <b>audio</b> <b>signal</b> gain and filter noise.|$|E
25|$|Plate modulation: In plate modulation, {{the plate}} voltage of the RF {{amplifier}} is modulated with the <b>audio</b> <b>signal.</b> The audio power requirement is 50 {{percent of the}} RF-carrier power.|$|E
25|$|The {{received}} {{signal is}} now processed by the demodulator stage where the <b>audio</b> <b>signal</b> (or other baseband signal) is recovered and then further amplified. AM demodulation requires the simple rectification of the RF signal (so-called envelope detection), {{and a simple}} RC low pass filter to remove remnants of the intermediate frequency. FM signals may be detected using a discriminator, ratio detector, or phase-locked loop. Continuous wave (Morse code) and single sideband signals require a product detector using a so-called beat frequency oscillator, {{and there are other}} techniques used for different types of modulation. The resulting <b>audio</b> <b>signal</b> (for instance) is then amplified and drives a loudspeaker.|$|E
40|$|An {{experienced}} sonographer can {{by listening}} to the Doppler <b>audio</b> <b>signals</b> perceive various timbres that distinguish different types of umbilical artery flow despite an unchanged pulsatility index (PI). Our aim was to develop an objective measure of the Doppler <b>audio</b> <b>signals</b> recorded from fetoplacental circulation in a sheep model...|$|R
40|$|Master’s thesis {{deals with}} {{description}} of issues of reading spatial <b>audio</b> <b>signals</b> using microphone array. Basic method of beamforming (Delay and Sum) is characterized on basis of chosen {{conception of the}} microphone array. Specific issues of audio detection and digital signal processing of converted <b>audio</b> <b>signals</b> are characterized and some ways how to solve the issues are adumbrated. Features and limitations of chosen ARM processor in the digital processing of multiple <b>audio</b> <b>signals</b> are described. Especially features and limitations of an internal A/D converter {{from the perspective of}} the beamforming are described...|$|R
40|$|An {{apparatus}} {{for providing}} a current loudspeaker-enclosure-microphone system {{description of a}} loudspeaker-enclosure-microphone system is provided. The apparatus comprises a first transformation unit (130) for generating a plurality of wave-domain loudspeaker <b>audio</b> <b>signals.</b> Moreover, the apparatus comprises a second transformation unit (140) for generating a plurality of wave-domain microphone <b>audio</b> <b>signals.</b> Furthermore, the apparatus comprises a system description generator (150) for generating the current loudspeaker-enclosure-microphone system description based on the plurality of wave- domain loudspeaker <b>audio</b> <b>signals,</b> based on the plurality of wave-domain microphone <b>audio</b> <b>signals,</b> and based on a plurality of coupling values, wherein the system description generator (150) is configured to determine each coupling value assigned to a wave-domain pair of a plurality of wave-domain pairs by determining a relation indicator indicating a relation between a loudspeaker-signal-transformation value and a microphone-signal- transformation value...|$|R
25|$|ITE {{hearing aids}} can be {{connected}} wirelessly to FM systems, for instance with a body-worn FM receiver with induction neck-loop which transmits the <b>audio</b> <b>signal</b> from the FM transmitter inductively to the telecoil inside the hearing instrument.|$|E
25|$|Wideband audio {{has been}} broadly {{deployed}} {{in conjunction with}} videoconferencing. Providers of this technology quickly discovered that despite the explicit emphasis on video transmission, {{the quality of the}} participant experience was significantly influenced by the fidelity of the associated <b>audio</b> <b>signal.</b>|$|E
25|$|In analog {{frequency}} modulation, such as FM {{radio broadcasting}} of an <b>audio</b> <b>signal</b> representing voice or music, the instantaneous frequency deviation, {{the difference between}} the frequency of the carrier and its center frequency, is proportional to the modulating signal.|$|E
30|$|As {{mentioned}} in Section 1, musical <b>audio</b> <b>signals</b> {{should be separated}} into instrument parts beforehand to boost and reduce the volume of those parts. Although a number of sound source separation methods [11 – 14] have been studied, most of them still focus on dealing with music performed on either pitched instruments that have harmonic sounds or drums that have inharmonic sounds. For example, most separation methods for harmonic sounds [11 – 14] cannot separate inharmonic sounds, while most separation methods for inharmonic sounds, such as drums [15], cannot separate harmonic ones. Sound source separation methods based on the stochastic properties of <b>audio</b> <b>signals,</b> for example, independent component analysis and sparse coding [16 – 18], treat particular kind of <b>audio</b> <b>signals</b> which are recorded with a microphone array or have small number of simultaneously voiced musical notes. However, these methods cannot separate complex <b>audio</b> <b>signals</b> such as commercial CD recordings. We describe our sound source separation method which can separate complex <b>audio</b> <b>signals</b> with both harmonic and inharmonic sounds in this section.|$|R
50|$|A DR-10 {{telephone}} switcher {{used for}} switching <b>audio</b> <b>signals.</b>|$|R
30|$|For the {{stationary}} <b>audio</b> <b>signals,</b> the HF spectrum {{changes at}} a relatively slow rate over time {{in comparison with the}} LF spectrum. By using the traditional BWE method, the envelope of the extended HF spectrum for the stationary <b>audio</b> <b>signals</b> is affected by the transient components contained in the LF spectrum, and some sudden changes of energy for the HF spectrum may occur between frames and degrade the auditory quality of the stationary <b>audio</b> <b>signals</b> according to the informal listening tests. Inspired by the studies on audio perceptual quality [13]-[15] that the temporal smoothness of audio spectrum is partially beneficial for the subjective quality, we attempt to eliminate the impact of transients from the features in order to improve the temporal smoothness of the extended HF spectrum. In the proposed method, the ‘steady-state’ spectrum of <b>audio</b> <b>signals</b> is first obtained by using MCRA for describing the spectrum components which are slowly evolved over time. Then, the resulting ‘steady-state’ spectrum is further used to remove the transients from the original spectrum of <b>audio</b> <b>signals</b> by the spectral weighting method. Finally, the cepstral features are computed from the weighted spectrum. Though some transients in the HF spectrum may be not well reconstructed by using the proposed method, the quality of the extended <b>audio</b> <b>signals</b> is partially improved on the whole according to the objective and subjective tests shown in Section 4.|$|R
25|$|The {{psychoacoustic model}} {{provides}} for high quality lossy signal compression by describing which {{parts of a}} given digital <b>audio</b> <b>signal</b> can be removed (or aggressively compressed) safely—that is, without significant losses in the (consciously) perceived quality of the sound.|$|E
25|$|A {{compressor}} {{reduces the}} level of an <b>audio</b> <b>signal</b> if its amplitude exceeds a certain threshold. It is commonly set in decibels dB, where a lower threshold (e.g. -60dB) means a larger portion of the signal is treated (compared to a higher threshold of, e.g., −5dB).|$|E
25|$|The first {{amplifier}} stage is a preamplifier. It amplifies the <b>audio</b> <b>signal</b> {{to a level}} that can drive the power stage. The preamplifier also changes {{the tone of the}} signal; high preamp settings add overdrive. The power amplifier produces a high current signal to drive a loudspeaker and produce sound.|$|E
5000|$|An {{audio encoder}} {{converts}} analog audio to digital <b>audio</b> <b>signals</b> ...|$|R
5000|$|DIN 41524, for {{circular}} connectors {{often used}} for <b>audio</b> <b>signals</b> ...|$|R
5000|$|Multi-modal analysis: finding correspondences between textual, visual, and <b>audio</b> <b>signals.</b>|$|R
