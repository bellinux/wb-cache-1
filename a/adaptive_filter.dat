1815|4450|Public
5|$|There is {{considerable}} {{evidence that the}} cerebellum plays {{an essential role in}} some types of motor learning. The tasks where the cerebellum most clearly comes into play are those in which it is necessary to make fine adjustments to the way an action is performed. There has, however, been much dispute about whether learning takes place within the cerebellum itself, or whether it merely serves to provide signals that promote learning in other brain structures. Most theories that assign learning to the circuitry of the cerebellum are derived from the ideas of David Marr and James Albus, who postulated that climbing fibers provide a teaching signal that induces synaptic modification in parallel fiber–Purkinje cell synapses. Marr assumed that climbing fiber input would cause synchronously activated parallel fiber inputs to be strengthened. Most subsequent cerebellar-learning models, however, have followed Albus in assuming that climbing fiber activity would be an error signal, and would cause synchronously activated parallel fiber inputs to be weakened. Some of these later models, such as the <b>Adaptive</b> <b>Filter</b> model of Fujita made attempts to understand cerebellar function in terms of optimal control theory.|$|E
2500|$|Others {{causes of}} signal {{impairment}} include amplitude ripple and slope across the passband, phase ripple across the passband, large band-edge phase shifts caused by band-limiting filters, [...] phase modulation due to poorly regulated power supplies, {{all of which}} lead to higher sidelobe levels. [...] Tolerances for these various parameters can be derived {{with the aid of}} paired echo theory. [...] Fortunately, with the aid of modern processing techniques and using a procedure similar to reciprocal ripple correction, or [...] an optimization method with an <b>adaptive</b> <b>filter</b> it is possible to correct for many of these shortcomings.|$|E
5000|$|In signal processing, a [...] kernel <b>adaptive</b> <b>filter</b> {{is a type}} of {{nonlinear}} <b>adaptive</b> <b>filter.</b> An <b>adaptive</b> <b>filter</b> is {{a filter}} that adapts its transfer function to changes in signal properties over time by minimizing an error or loss function that characterizes how far the filter deviates from ideal behavior. The adaptation process is based on learning from a sequence of signal samples and is thus an online algorithm. A nonlinear <b>adaptive</b> <b>filter</b> is one in which the transfer function is nonlinear.|$|E
30|$|Based on the {{different}} implementation methods, the <b>adaptive</b> <b>filtering</b> modes of data transmission system {{can be divided into}} analog <b>adaptive</b> <b>filtering</b> and digital <b>adaptive</b> <b>filtering.</b> Analog <b>adaptive</b> <b>filtering</b> technology is to add an analog filter at the front end of demodulator to adapt channel amplitude and group delay characteristic. This technology cannot adjust with channel changes, has poor adaptability, and cannot solve orthogonal unbalance impact of microwave modulator. Digital <b>adaptive</b> <b>filtering</b> technology has strong adaptability, highly matches with channel, and can rectify orthogonal unbalance, thus its overall effect is superior to analog <b>adaptive</b> <b>filtering</b> technology. Therefore, digital <b>adaptive</b> <b>filtering</b> technology is adopted in high-speed data transmission system.|$|R
40|$|The stochastic-gradient-descent LMS <b>adaptive</b> <b>filtering</b> {{algorithm}} {{provides a}} powerful and computationally efficient means of realizing <b>adaptive</b> <b>filters.</b> In this work, we present architectural synthesis of low-power computational engines (or hardware accelerators) for LMS <b>adaptive</b> <b>filtering.</b> This engine could be configured for delayed LMS/delayed normalized LMS, full-band/subband <b>adaptive</b> <b>filtering</b> depending on the application requirements. ...|$|R
40|$|<b>Adaptive</b> <b>filtering</b> in subbands have {{originally}} been proposed to overcome limitations of classic adaptive algorithms in some areas. In general, subband <b>adaptive</b> <b>filters</b> offer computational savings, {{as well as}} faster convergence over the classical Least Mean Squared (LMS) algorithm. However, improvements to current subband <b>adaptive</b> <b>filters</b> could be further enhanced by a more elegant choice of their design/structure. Classical subband <b>adaptive</b> <b>filters</b> employ DFT-based analysis and synthesis filter banks which results in subband signals that are complex [...] valued. In this paper, we modify the structure of subband <b>adaptive</b> <b>filters</b> by using single sideband (SSB) modulated analysis and synthesis filter banks, which result in subband signals that are real [...] valued. This simplifies realisation of subband <b>adaptive</b> <b>filters...</b>|$|R
50|$|The {{idea behind}} a closed loop <b>adaptive</b> <b>filter</b> {{is that a}} {{variable}} filter is adjusted until the error (the difference between the filter output and the desired signal) is minimized. The Least Mean Squares (LMS) filter and the Recursive Least Squares (RLS) filter are types of <b>adaptive</b> <b>filter.</b>|$|E
50|$|S. Haykin, <b>Adaptive</b> <b>Filter</b> Theory, 4th Edition, Prentice Hall, 2002.|$|E
50|$|S. Haykin, <b>Adaptive</b> <b>Filter</b> Theory, 5th Edition, Prentice Hall, 2013.|$|E
40|$|The {{theory of}} {{structural}} sub-band decomposition of an FIR filters is extended to <b>adaptive</b> <b>filters.</b> It is shown that this sub-band decomposition {{is equivalent to}} the transform of input data by orthogonal matrices, of which the Walsh-Hadamard Transform (WHT) is a special case. Thus, the proposed method is a generalization of the transform domain <b>adaptive</b> <b>filtering</b> (TDAF) using WHT, which is already known to enhance the convergence speed of <b>adaptive</b> <b>filters.</b> Furthermore, our method yields one possible hardware implementation of the fast WHT. The convergence behavior of the proposed sub-band <b>adaptive</b> <b>filters</b> is simulated using the Least Mean Squares (LMS) and Recursive Least Squares (RLS) algorithms. The results show the faster convergence speed of the proposed <b>adaptive</b> <b>filters</b> compared to conventional <b>adaptive</b> <b>filters...</b>|$|R
50|$|Because high-dimensional {{feature space}} is linear, kernel <b>adaptive</b> <b>filters</b> {{can be thought}} of as a {{generalization}} of linear <b>adaptive</b> <b>filters.</b> As with linear <b>adaptive</b> <b>filters,</b> there are two general approaches to adapting a filter: the least mean squares filter (LMS) and the recursive least squares filter (RLS).|$|R
30|$|Over {{the past}} few decades, <b>adaptive</b> <b>filters</b> have gained huge {{recognition}} in innumerable applications extending {{over a wide range}} of fields. <b>Adaptive</b> <b>filtering</b> {{is an important part of}} statistical signal processing, and <b>adaptive</b> <b>filters</b> have been successfully applied in diverse fields such as equalization, noise cancellation, linear prediction, and in system identification [1, 2]. <b>Adaptive</b> <b>filters</b> are preferred over conventional filters because of their accuracies due to adaptive capability in the domain of the problem in which it is being used. <b>Adaptive</b> <b>filters</b> automatically adjust their weights according to some adaptive algorithm which is usually based on minimization of a function of the difference between the desired signal and the observed signal [1, 2]. The most widely used algorithms for <b>adaptive</b> <b>filters</b> are the least mean squares (LMS) algorithm [1, 2] and the recursive least squares algorithm [1, 2].|$|R
5000|$|... 2D Adaptive Filters {{can be used}} to {{identify}} systems. The system function of the unknown system is given by , and [...] is the system function of the 2D <b>adaptive</b> <b>filter</b> when its output comes to steady. The error signal [...] between the unknown system output,, and the <b>adaptive</b> <b>filter</b> output,, is minimized if the unknown system and known 2D <b>adaptive</b> <b>filter</b> have the same input, and if the resulting outputs are similar. Then, it can be shown that [...] can be represented by [...] [...] is known as the system identification model of the unknown system.|$|E
50|$|Another popular {{stochastic}} {{gradient descent}} algorithm {{is the least}} mean squares (LMS) <b>adaptive</b> <b>filter.</b>|$|E
50|$|The Multidelay block {{frequency}} domain <b>adaptive</b> <b>filter</b> (MDF) algorithm is a block-based {{frequency domain}} {{implementation of the}} (normalised) Least mean squares filter (LMS) algorithm.|$|E
40|$|In {{applications}} like {{echo cancellation}} and speech enhancement, {{where there is}} need to track changes continuously, <b>adaptive</b> <b>filtering</b> is usually used. Long <b>adaptive</b> <b>filters</b> gives problems like slow convergence and high complexity. Subband <b>adaptive</b> <b>filtering</b> has been introduced to overcome these problems. The filter banks used in subband <b>adaptive</b> <b>filtering</b> introduce large delays. In order {{to compensate for the}} delays, delayless subband <b>adaptive</b> <b>filtering</b> is introduced. Delayless subband <b>adaptive</b> <b>filtering</b> is used in both open loop and closed loop configuration, where the subband filters are transformed to a fullband filter using a weight transform. This paper proposes a new subband weight transform based on the filter banks that are used. We investigate the performance of the weight transform using Monte Carlo simulations of a system identification situation. Different adaptive algorithms are used to compare the weight transform to previously proposed weight transforms...|$|R
40|$|Multikernel <b>adaptive</b> <b>filtering</b> has {{recently}} attracted significant re-search interest {{due to its}} enhanced flexibility and adaptation perfor-mance over single-kernel methods. In this paper, we focus on convex combinations of two single-kernel <b>adaptive</b> <b>filters,</b> characterized by different convergence speeds and steady-state performances, {{in order to get}} the best of both. We consider online estimation using single-kernel <b>adaptive</b> <b>filters</b> that may use different algorithms and kernels. Simulation results illustrate the efficiency of our approach. Index Terms — Kernel <b>adaptive</b> <b>filtering,</b> convex combination, multikernel method, tracking 1...|$|R
40|$|<b>Adaptive</b> <b>filtering</b> is {{a growing}} area of {{research}} due to its vast no of application in many fields and its numerous advantages over non <b>adaptive</b> <b>filters.</b> In fact there are many areas where the use of <b>adaptive</b> <b>filters</b> is becoming mandatory. Few of them are System Identification, Inverse Modeling, Linear Prediction, Feedforward Control etc. although enough wor...|$|R
50|$|To {{circumvent}} {{this potential}} loss of information, an <b>adaptive</b> <b>filter</b> could be used. The <b>adaptive</b> <b>filter</b> would take input {{both from the}} patient and from the mains and would thus be able to track the actual frequency of the noise as it fluctuates and subtract the noise from the recording. Such an adaptive technique generally allows for a filter with a smaller rejection range, which means, in this case, {{that the quality of}} the output signal is more accurate for medical purposes.|$|E
5000|$|... where [...] and [...] are, respectively, {{the output}} and input of the <b>adaptive</b> <b>filter.</b> [...] and [...] are the masks of the filter`s input and output. The error signal is given by ...|$|E
50|$|A {{two-dimensional}} (2D) <b>adaptive</b> <b>filter</b> is {{very much}} like a one-dimensional <b>adaptive</b> <b>filter</b> in that it is a linear system whose parameters are adaptively updated throughout the process, according to some optimization approach. The main difference between 1D and 2D adaptive filters is that the former usually take as inputs signals with respect to time, what implies in causality constraints, while the latter handles signals with 2 dimensions, like x-y coordinates in the space domain, which are usually non-causal. Moreover, just like 1D filters, most 2D adaptive filters are digital filters, because of the complex and iterative nature of the algorithms.|$|E
40|$|This paper {{presents}} a design of <b>Adaptive</b> <b>Filtering</b> Algorithm {{for control of}} the vibration force applied on the specimen in testing control systems. In order to reduce the computational complexity associated with time-domain <b>adaptive</b> <b>filtering</b> method, frequency-domain <b>adaptive</b> <b>filtering</b> scheme was adapted instead to alleviate the above mentioned complexity. In this paper <b>Adaptive</b> <b>Filtering</b> algorithm in association with Fast Fourier Transformation (FFT) was used and implemented in Digital Signal Processor (DSP). Our algorithm show significant reduction in computational complexity as shown in the result given in section 6...|$|R
40|$|In this paper, the {{stability}} and convergence properties {{of the class of}} transform-domain least mean square (LMS) <b>adaptive</b> <b>filters</b> with second-order autoregressive (AR) process are investigated. It is well known that this class of <b>adaptive</b> <b>filters</b> improve convergence property of the standard LMS <b>adaptive</b> <b>filters</b> by applying the fixed data-independent orthogonal transforms and power normalization. However, the convergence performance of this class of <b>adaptive</b> <b>filters</b> can be quite different for various input processes, and it has not been fully explored. In this paper, we first discuss the mean-square stability and steady-state performance of this class of <b>adaptive</b> <b>filters.</b> We then analyze the effects of the transforms and power normalization performed in the various <b>adaptive</b> <b>filters</b> for both first-order and second-order AR processes. We derive the input asymptotic eigenvalue distributions and make comparisons on their convergence performance. Finally, computer simulations on AR process as well as moving-average (MA) process and autoregressive-moving-average (ARMA) process are demonstrated for the support of the analytical results. <br /...|$|R
40|$|Multi-user mobile {{communication}} systems use linearly constrained <b>adaptive</b> <b>filters</b> for a blind adaptive interference cancelation and/or adaptive beamforming. Conjugate gradient (CG) techniques have been proposed, in the literature, for solving the <b>adaptive</b> <b>filtering</b> and the linearly constrained <b>adaptive</b> <b>filtering</b> problems. In <b>adaptive</b> <b>filtering,</b> the sample-by-sample update of the correlation matrix and the cross-correlation vector causes {{a loss of}} the residue orthogonality in a modified online algorithm, which, in turn, results in loss of convergence and an increase of the filter quadratic mean error. This paper extends a recently proposed optimality and convergence proof of the degenerated CG method {{to the case of}} linearly constrained <b>adaptive</b> <b>filtering,</b> and proposes a constrained Steepest Descent (CSD) method. The proposed algorithms are applied to a single-user detection in a DS-CDMA {{mobile communication}} system and shown to have performance comparable to those of algorithms proposed earlier without formal convergence proofs. Key words: Linearly constrained <b>adaptive</b> <b>filtering</b> algorithms, adaptiv...|$|R
50|$|An <b>adaptive</b> <b>filter</b> is {{a system}} with a linear filter that has a {{transfer}} function controlled by variable parameters and a means to adjust those parameters according to an optimization algorithm. Because {{of the complexity of}} the optimization algorithms, almost all adaptive filters are digital filters. Adaptive filters are required for some applications because some parameters of the desired processing operation (for instance, the locations of reflective surfaces in a reverberant space) are not known in advance or are changing. The closed loop <b>adaptive</b> <b>filter</b> uses feedback {{in the form of an}} error signal to refine its transfer function.|$|E
5000|$|... #Caption: <b>Adaptive</b> <b>Filter,</b> compact representation. k = sample number, x = {{reference}} input, d = desired input, ε = error output, f = filter impulse response, Σ = summation, box=linear {{filter and}} adaption algorithm.|$|E
50|$|The <b>adaptive</b> <b>filter</b> {{approach}} {{works by}} modeling {{the transfer function}} of the sound reinforcement system and subtracts the reinforced sound from the inputs to the system {{in the same way}} that an echo canceller removes echoes from a communications system.|$|E
5000|$|The {{topic of}} 2D <b>adaptive</b> <b>filters</b> is very {{important}} in electrical engineering and signal processing since these filters have the ability {{to take into account the}} nonstationary statistical properties of 2D signals. <b>Adaptive</b> <b>filters</b> find applications in areas such as Noise cancellation, Signal prediction, Equalization and Echo cancellation. Examples of applications of 2D <b>adaptive</b> <b>filters</b> include Image Denoising, Motion Tracking, OFDM channel estimation, magnetic recording equalization ...|$|R
40|$|A split hypercomplex {{learning}} algorithm for {{the training}} of nonlinear finite impulse response <b>adaptive</b> <b>filters</b> for the processing of hypercomplex signals of any dimension is proposed. The derivation strictly {{takes into account the}} laws of hypercomplex algebra and hypercomplex calculus, some of which have been neglected in existing learning approaches (e. g. for quaternions). Already in the case of quaternions we can predict improvements in performance of hypercomplex processes. The convergence of the proposed algorithms is rigorously analyzed. Keywords: Quaternionic <b>adaptive</b> <b>filtering,</b> Hypercomplex <b>adaptive</b> <b>filtering,</b> Nonlinear <b>adaptive</b> <b>filtering,</b> Hypercomplex Multilayer Perceptron, Clifford geometric algebraComment: 14 pages, 1 figur...|$|R
40|$|This paper {{reviews the}} {{existing}} developments of adaptive methods of sparse <b>adaptive</b> <b>filters</b> for {{the identification of}} sparse impulse response in both network and acoustic echo cancellation from the last decade. A variety of different architectures and novel training algorithms have been proposed in literature. At present {{most of the work}} in echo cancellation on using more than one method. Sparse <b>adaptive</b> <b>filters</b> take the advantage of each method and showing good improvement in the sparseness measure performance. This survey gives an overview of existing sparse <b>adaptive</b> <b>filters</b> mechanisms and discusses their advantages over the traditional <b>adaptive</b> <b>filters</b> developed for echo cancellation...|$|R
5000|$|The {{weight matrix}} {{at the next}} {{iteration}} {{is equal to the}} present weight matrix plus a change proportional to the negative gradient of the mean square error. For the two-dimensional LMS <b>adaptive</b> <b>filter,</b> the filter coefficients are updated as follows: ...|$|E
5000|$|For a {{two-dimensional}} LMS IIR <b>Adaptive</b> <b>filter,</b> its basic idea {{is the same}} as 2D LMS FIR Adaptive Filters, except we are using an IIR filter, which can reduce the filter order requirements. The two-dimensional IIR filter`s difference equation can be written as ...|$|E
50|$|Advantages: The TDLMS <b>adaptive</b> <b>filter</b> can be {{implemented}} without any form of matrix operations or any averaging or differentiation. The algorithm convergence {{does not depend on}} the initial conditions and it will converge for any arbitrarily initial value, hence, it provides good performance in nonstationary images.|$|E
40|$|Combining the {{channels}} of a multiple input/multiple output (MIMO) system into suitably chosen modes by a domain transformation offers great improvements of <b>adaptive</b> <b>filtering</b> algorithms. In this paper we present an algorithm for <b>adaptive</b> MIMO <b>filtering,</b> called source-domain <b>adaptive</b> <b>filtering</b> (SDAF), with application to multichannel acoustic echo cancellation operating in an optimally adjusted transform domain without requiring a-priori {{knowledge about the}} system. Experimental results show a significant performance improvement compared to fixed transformation bases. Index Terms — multichannel acoustic echo cancellation, transform-domain, basis estimation, <b>adaptive</b> <b>filtering.</b> 1...|$|R
30|$|As an {{alternative}} to time-domain <b>adaptive</b> <b>filters,</b> frequency-domain and subband <b>adaptive</b> <b>filters</b> are frequently used as they enable more efficient and frequency-dependent filter updates [2, 21 – 25]. Frequency-domain <b>adaptive</b> <b>filtering</b> algorithms, such as the frequency-domain least mean square (FLMS) [21], the partitioned block frequency-domain <b>adaptive</b> <b>filtering</b> (PB-FDAF) [22] and the multidelay block frequency-domain <b>adaptive</b> <b>filtering</b> (MDF) algorithm [23], are typically based on the overlap-save method [24, 25] and use the fast Fourier transform (FFT) to efficiently compute the required time-domain convolution and correlation operations. In [26], the M-Max tap selection scheme has been proposed for the frequency-domain MDF algorithm. Alternatively, <b>adaptive</b> <b>filtering</b> can be performed using subband processing, where an analysis filterbank transforms the time-domain signals into the subband domain, the filter adaptation and processing is performed independently in each subband, and a synthesis filterbank is used to reconstruct the time-domain signals. In this paper, we will only consider subband <b>adaptive</b> <b>filters.</b> More specifically, we will use the well-known weighted overlap-add (WOLA) method [2, 27], i.e., using an FFT analysis filterbank to transform the (windowed) time-domain signals to the short-time Fourier transform (STFT) domain and an inverse FFT synthesis filterbank. Such a processing scheme provides a suitable compromise between computational complexity and latency, and enables to achieve a suitable time and frequency resolution.|$|R
40|$|Subband <b>adaptive</b> <b>filters</b> {{have been}} {{proposed}} to circumvent the drawbacks of slow convergence and high computational complexity associated with time domain <b>adaptive</b> <b>filters.</b> Subband processing introduces transmission delays and signal degradations due to aliasing effects. In order to overcome the transmission delays, delayless <b>adaptive</b> <b>filtering</b> has been introduced where the coefficient adaptation is performed in the subband domain while signal filtering is performed in fullband. In this paper convergence behavior and computational complexity of {{two different types of}} delayless <b>adaptive</b> <b>filters</b> are considered. Both open loop and closed loop configurations are studied. The theoretical results are compared with simulations of algorithms in a system identification scenario...|$|R
