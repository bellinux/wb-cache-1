1304|84|Public
5|$|Most {{vertebrate}} {{species have}} a cerebellum {{and one or}} more cerebellum-like structures, brain areas that resemble the cerebellum in terms of cytoarchitecture and neurochemistry. The only cerebellum-like structure found in mammals is the dorsal cochlear nucleus (DCN), {{one of the two}} primary sensory nuclei that receive input directly from the <b>auditory</b> <b>nerve.</b> The DCN is a layered structure, with the bottom layer containing granule cells {{similar to those of the}} cerebellum, giving rise to parallel fibers that rise to the superficial layer and travel across it horizontally. The superficial layer contains a set of GABAergic neurons called cartwheel cells that resemble Purkinje cells anatomically and chemically—they receive parallel fiber input, but do not have any inputs that resemble climbing fibers. The output neurons of the DCN are pyramidal cells. They are glutamatergic, but also resemble Purkinje cells in some respects—they have spiny, flattened superficial dendritic trees that receive parallel fiber input, but they also have basal dendrites that receive input from <b>auditory</b> <b>nerve</b> fibers, which travel across the DCN in a direction at right angles to the parallel fibers. The DCN is most highly developed in rodents and other small animals, and is considerably reduced in primates. Its function is not well understood; the most popular speculations relate it to spatial hearing in one way or another.|$|E
5|$|The <b>auditory</b> <b>nerve</b> {{was also}} large, {{suggesting}} good hearing, {{which may have}} been useful for auditory communication and spatial awareness. The nerve had a well-developed vestibular component as well, which implies a good sense of balance and coordination. In contrast, the nerves and brain structures associated with eyesight were smaller and undeveloped. The midbrain tectum, responsible for visual processing in reptiles, was very small in Tarbosaurus, as were the optic nerve and the oculomotor nerve, which controls eye movement. Unlike Tyrannosaurus, which had forward-facing eyes that provided some degree of binocular vision, Tarbosaurus had a narrower skull more typical of other tyrannosaurids in which the eyes faced primarily sideways. All of this suggests that Tarbosaurus relied more on its senses of smell and hearing than on its eyesight.|$|E
25|$|Based on {{clinical}} testing of subjects with auditory neuropathy, the disruption {{in the stream}} of sound information has been localized {{to one or more}} of three probable locations: the inner hair cells of the cochlea, the synapse between the inner hair cells and the <b>auditory</b> <b>nerve,</b> or a lesion of the ascending <b>auditory</b> <b>nerve</b> itself.|$|E
5000|$|Purudan - in {{the region}} of the ears forming 120 {{branches}} or <b>auditory</b> <b>nerves</b> ...|$|R
30|$|We {{extract the}} {{features}} by imitating the process {{occurred in the}} auditory periphery and pathway, such as outer ear, middle ear, basilar membrane, inner hair cell, <b>auditory</b> <b>nerves,</b> and cochlear nucleus.|$|R
50|$|The vestibulocochlear <b>nerve</b> (<b>auditory</b> {{vestibular}} <b>nerve),</b> {{known as}} the eighth cranial nerve, transmits sound and equilibrium (balance) information from the inner ear to the brain.|$|R
25|$|The cochlea, {{dedicated}} to hearing; converting sound pressure patterns {{from the outer}} ear into electrochemical impulses which are {{passed on to the}} brain via the <b>auditory</b> <b>nerve.</b>|$|E
25|$|A {{neuropathy}} usually {{refers to}} a disease of the peripheral nerve or nerves, but the <b>auditory</b> <b>nerve</b> itself is not always affected in auditory neuropathy spectrum disorders.|$|E
25|$|It may {{be caused}} by {{increased}} neural activity in the auditory brainstem, where the brain processes sounds, causing some <b>auditory</b> <b>nerve</b> cells to become over-excited. The basis of this theory is that many with tinnitus also have hearing loss.|$|E
3000|$|... 0 {{variation}} {{over time}} for voiced speech. Previous psychophysical tests using tonal sweeps {{suggest that the}} processing mechanism underlying the perception of slowly frequency-modulated tones {{is related to the}} temporal processing mechanisms of auditory system, e.g., the phase-locking firing of <b>auditory</b> <b>nerves</b> (Sek and Moore 1995).|$|R
60|$|In utter silence they conversed, {{for they}} have no oral speech since they are without <b>auditory</b> <b>nerves.</b> Their method of {{communication}} Perry has likened to the projection of a sixth sense into a fourth dimension, where it becomes cognizable to the sixth sense of their audience.|$|R
30|$|High-fidelity {{interface}} devices will, however, remain the major obstacle {{in the foreseeable}} future. Effectively recreating sensory input for seamless interactions will require new thoughts and ideas. Direct displays onto the retina and artificial stimulation of the mechanoreceptors and <b>auditory</b> <b>nerves</b> may bring us closer {{to the goal of}} iVR.|$|R
25|$|Auditory {{neuropathy}} (AN) is {{a variety}} of hearing loss in which the outer hair cells within the cochlea are present and functional, but sound information is not faithfully transmitted to the <b>auditory</b> <b>nerve</b> and brain properly. Also known as auditory neuropathy/auditory dys-synchrony (AN/AD) or auditory neuropathy spectrum disorder (ANSD).|$|E
25|$|The bullet had severed an <b>auditory</b> <b>nerve,</b> {{leaving him}} deaf in one ear, {{and he has}} {{suffered}} from chronic pain from bullet fragments lodged in his brain. He was visited {{the day after the}} shooting by Mayor John V. Lindsay and Police Commissioner Patrick V. Murphy, and the police department harassed him with hourly bed checks. He later testified before the Knapp Commission.|$|E
25|$|The cochlea {{is filled}} with a watery liquid, the perilymph, which moves in {{response}} to the vibrations coming from the middle ear via the oval window. As the fluid moves, the cochlear partition (basilar membrane and organ of Corti) moves; thousands of hair cells sense the motion via their stereocilia, and convert that motion to electrical signals that are communicated via neurotransmitters to many thousands of nerve cells. These primary auditory neurons transform the signals into electrochemical impulses known as action potentials, which travel along the <b>auditory</b> <b>nerve</b> to structures in the brainstem for further processing.|$|E
40|$|The {{electrode}} is {{an important}} part of cochlear implant system because it affects the current spread and the response of the <b>auditory</b> <b>nerves.</b> In this paper, a new electrode-tissue interface model is coupled with a 3 D cochlea and electrode model to simulate the condition of the electrodes in human cochlea is proposed. The effect of incorporating the electrode-tissue interface in a cochlea and the response of the <b>auditory</b> <b>nerves</b> is discussed. Three models are studied, a model of electrode without interface, a model of electrode incorporating the interface effect through an equivalent circuit, and a new model of electrode incorporating a thin layer between the electrode and the scala typmani. The three electrode models were studied using activating functions. Significant different results were found for electrodes with or without taking interface into account. The model results for the electrode model taking into account of the interface effect using an equivalent circuit and a thin interface layer are almost identical. Index Terms—Cochlear implant, computational neuroscience model, electrode-tissue interface, equivalent circuits, interfacial layer, volume conduction method. I...|$|R
40|$|The {{anterior}} {{division of}} the ventral cochlear nucleus (AVCN) is the first relay station of the auditory pathway. It receives auditory information via the <b>auditory</b> <b>nerves</b> emanating from the cochlea. Electrical stimulation via current cochlear implants [] {{does not lead to}} responses at the cochlear nucleus that exactly match tho elicited by comparable auditory stimulation. Complex temporal patterns of electrical stimulation may provide a better simulation of the acoustic input. 2 - 7 MarchOpen Acces...|$|R
30|$|In 1960, Bèkèsy {{reported}} that sounds of different frequencies generate surface waves on the basilar membrane in cochlea with peak amplitudes at different places, which {{are determined by}} the frequencies [34]. In other words, a specific frequency is mapped to a specific place on the basilar membrane, or FPT, and this specific frequency for a given place is called Characteristic Frequency (CF [35]). Hair cells on that place then transform the mechanical swing into electric signals of <b>auditory</b> <b>nerves.</b>|$|R
25|$|Neural {{structures}} {{form and}} become more sophisticated {{as a result of}} experience. For example, the preference for consonance, the harmony or agreement of components, over dissonance, an unstable tone combination, is found early in development. Research suggests that this is due to both the experiencing of structured sounds and the fact they stem from development of the basilar membrane and <b>auditory</b> <b>nerve,</b> two early developing structures in the brain. An incoming auditory stimulus evokes responses measured {{in the form of an}} Event-related potential (ERP), measured brain responses resulting directly from a thought or perception. There is a difference in ERP measures for normally developing infants ranging from 2–6 months in age. Measures in infants 4 months and older demonstrate faster, more negative ERPs. In contrast, newborns and infants up to 4 months of age show slow, unsynchronized, positive ERPs. Trainor, et al. (2003) hypothesized that these results indicated that responses from infants less than four months of age are produced by subcortical auditory structures, whereas with older infants responses tend to originate in the higher cortical structures.|$|E
2500|$|Murray B. Sachs [...] - [...] Director of the [...] Johns Hopkins University Department of Biomedical Engineering from 1991-2005, [...] and {{a pioneer}} in the field of Biomedical Engineering in Hearing Science winning the 1998 Von Bekesy award. He and members of his laboratory, the Neural Encoding Laboratory at Johns Hopkins, were {{one of the first to}} derive primary <b>auditory</b> <b>nerve</b> {{population}} codes that became the basis of the modern cochlear implant.|$|E
2500|$|The cochlea is {{a portion}} of the inner ear that looks like a snail shell (cochlea is Greek for snail.) The cochlea {{receives}} sound in the form of vibrations, which cause the stereocilia to move. The stereocilia then convert these [...] vibrations into nerve impulses which are taken up to the brain to be interpreted. Two of the three fluid sections are canals and the third is a sensitive 'organ of Corti' which detects pressure impulses which travel along the <b>auditory</b> <b>nerve</b> to the brain. The two canals are called the vestibular canal and the tympanic canal.|$|E
50|$|Many revolutionary {{concepts}} regarding {{hearing and}} encoding {{sound in the}} brain were founded {{in the late nineteenth}} and early twentieth centuries. Various tool were used induce a response in <b>auditory</b> <b>nerves</b> that were to be recorded. Experiments by Helmholtz, Wever, and Bray often involved the use of organ pipes, stretched springs, loaded reeds, lamellas, vibrating forks, beats, and interruption tones to create “clicks”, harmonics, or pure tones. Today, electronic oscillators are often used to create sinusoidal or square waves of precise frequencies.|$|R
6000|$|Poor strange Jews! They had, doubtless, what Darwin {{would call}} a {{specific}} 'paralysis' of the <b>auditory</b> <b>nerves</b> to the writings of their own Prophets, which yet were read Sabbath after Sabbath in their public Synagogues. For neither John nor Christ himself ever did, or indeed could, speak in language more contemptuous of the folly of considering rites as substitutions for moral duty, or in severer words denounce the blasphemy of such an opinion. Why need I refer to Isaiah or Micah? ...|$|R
50|$|Electrophonic {{hearing is}} the direct {{stimulation}} of the <b>auditory</b> <b>nerves</b> by external electromagnetic fields. In 1962 Allan H Frey carried {{out a series of}} experiments which proved that microwaves can produce the sound even in those who are deaf.http://jap.physiology.org/content/17/4/689.abstract The theory is unable to explain why only the sense of hearing is affected - though there are rare reports of people noting odd smells accompanying an aurora display. See also the discussion of the Electrophonic effect/Microwave auditory effect which covers various mechanisms in detail.|$|R
2500|$|Iron is {{essential}} for several critical metabolic enzymes and a deficiency of this mineral can disrupt brain development. For, example chronic marginal iron affects dopamine metabolism and myelin fatty acid composition [...] and behavior in mice. In rats a marginal iron deficiency that does not cause anemia disrupted axon growth in the <b>auditory</b> <b>nerve</b> affecting auditory brainstem latency without major changes in myelination. In rhesus macaques, prenatal iron deficiency disrupts emotional behavior [...] and polymorphisms that reduce the expression of monoamine oxidase interact with gestational iron deficiency to exacerbate the response to a stressful situation leading to increased aggressiveness. Inexpensive and effective iron supplementation is an available preventative strategy recommended by the World Health Organization. However, iron supplementation can exacerbate malaria infection. Therefore, individuals receiving iron supplementation in malaria-endemic areas must be carefully monitored.|$|E
2500|$|Loudness is {{perceived}} as how [...] "loud" [...] or [...] "soft" [...] a sound is and relates to the totalled number of <b>auditory</b> <b>nerve</b> stimulations over short cyclic time periods, most likely over the duration of theta wave cycles. This means that at short durations, a very short sound can sound softer than a longer sound {{even though they are}} presented at the same intensity level. Past around 200 ms this is no longer the case and the duration of the sound no longer affects the apparent loudness of the sound. Figure 3 gives an impression of how loudness information is summed over a period of about 200 ms before being sent to the auditory cortex. Louder signals create a greater 'push' on the Basilar membrane and thus stimulate more nerves, creating a stronger loudness signal. A more complex signal also creates more nerve firings and so sounds louder (for the same wave amplitude) than a simpler sound, such as a sine wave.|$|E
2500|$|In a model {{outlined}} by Stefan Koelsch and Walter Siebel, music stimuli are perceived in a successive timeline, {{breaking down the}} auditory input into different characteristics and meaning. He maintained that upon perception the sound reaches the <b>auditory</b> <b>nerve,</b> brainstem and thalamus. At this point features involving pitch height, chroma, timbre, intensity and roughness are extracted. This occurs about at about 10–100ms. Next, melodic and rhythmic grouping occurs, which is then perceived by auditory sensory memory. After this, an analysis is made of intervals and chord progressions. A harmony is then built upon the structure of metre, rhythm and timbre. This occurs from about 180–400ms after the initial perception. Following this, structural reanalysis and repair occur, at about 600–900ms. Finally, the autonomic nervous system and multimodal association cortices are activated. Koelsch and Siebel proposed that from about 250–500ms, based on the sound's meaning, interpretation and emotion occurs continuously throughout this process. This is indicated by N400, a negative spike at 400ms, as measured by an [...] "event related potential".|$|E
40|$|Cochlear implant (CI) is an {{auditory}} prosthesis {{that delivers}} electrical stimulation via inserted electrodes into a cochlea. To evaluate CI performance, {{it is important}} to understand how <b>auditory</b> <b>nerves</b> are responded to electrical stimulations. In clinic, electrically evoked compound action potential (ECAP) is measured. In this study, we developed 3 D finite element (FE) cochlear model to simulate ECAP in response to electrical stimulation. The model prododuced ECAP similar to that measured in animal experiments and clinics. This 3 D FE cochlear model could be used in electrical stimulus method stud...|$|R
50|$|Presbycusis (also spelled presbyacusis, from Greek presbys “old” + akousis “hearing”), or age-related hearing loss, is the {{cumulative}} effect of aging on hearing. It is a progressive and irreversible bilateral symmetrical age-related sensorineural hearing loss resulting from degeneration of the cochlea or associated structures of the inner ear or <b>auditory</b> <b>nerves.</b> The hearing loss is most marked at higher frequencies. Hearing loss that accumulates with age but is caused by factors other than normal aging (nosocusis and sociocusis) is not presbycusis, although differentiating the individual effects of multiple causes of hearing loss can be difficult.|$|R
5000|$|... 3-D audio (processing) is {{the spatial}} domain {{convolution}} of sound waves using Head-related transfer functions. It is {{the phenomenon of}} transforming sound waves (using head-related transfer function or HRTF filters and cross talk cancellation techniques) to mimic natural sounds waves, which emanate from a point in a 3-D space. It allows trickery of the brain using the ears and <b>auditory</b> <b>nerves,</b> pretending to place different sounds in different 3-D locations upon hearing the sounds, even though the sounds may just be produced from just 2 speakers (dissimilar to surround sound).|$|R
6000|$|I {{have just}} spoken of that morbid {{condition}} of the <b>auditory</b> <b>nerve</b> which rendered all music intolerable to the sufferer, {{with the exception of}} certain effects of stringed instruments. It was, perhaps, the narrow limits to which he thus confined himself upon the guitar, which gave birth, in great measure, to the fantastic character of his performances. But the fervid facility of his impromptus could not be so accounted for. They must have been, and were, in the notes, {{as well as in the}} words of his wild fantasias (for he not unfrequently accompanied himself with rhymed verbal improvisations), the result of that intense mental collectedness and concentration to which I have previously alluded as observable only in particular moments of the highest artificial excitement. The words of one of these rhapsodies I have easily remembered. I was, perhaps, the more forcibly impressed with it, as he gave it, because, in the under or mystic current of its meaning, I fancied that I perceived, and for the first time, a full consciousness on the part of Usher, of the tottering of his lofty reason upon her throne. The verses, which were entitled [...] "The Haunted Palace," [...] ran very nearly, if not accurately, thus: ...|$|E
6000|$|... "No doubt," [...] he said, [...] "you {{have seen}} that before. It does not hurt a pin-prick. But what does it show? The {{capacity}} for pain is not needed in the muscle, {{and it is not}} placed there,--is but little needed in the skin, and only here and there over the thigh is a spot capable of feeling pain. Pain is simply our intrinsic medical adviser to warn us and stimulate us. Not all living flesh is painful; nor is all nerve, not even all sensory nerve. There's no taint of pain, real pain, in the sensations of the optic nerve. If you wound the optic nerve, you merely see flashes of light,--just as disease of the <b>auditory</b> <b>nerve</b> merely means a humming in our ears. Plants do not feel pain, nor the lower animals; it's possible that such animals as the starfish and crayfish do not feel pain at all. Then with men, the more intelligent they become, the more intelligently they will see after their own welfare, and the less they will need the goad {{to keep them out of}} danger. I never yet heard of a useless thing that was not ground out of existence by evolution sooner or later. Did you? And pain gets needless.|$|E
6000|$|... "'Oh, {{try and do}} {{something}} for her, sir!' says I. 'Oh, for God's sake, don't give her up, sir!' 'My good soul,' says he, 'you must set her an example of cheerfulness, and keep up her spirits--that's all {{that can be done}} for her now.' 'Not all, sir,' says I, 'surely not all!' 'Indeed it is,' says he; 'her hearing is completely gone; the experiment with my watch proves it. I had an exactly similar case with the mason's boy,' he says, turning to the other doctor. 'The shock of that fall has, I believe, paralyzed the <b>auditory</b> <b>nerve</b> in her, as it did in him.' I remember those words exactly, sir, though I didn't quite understand them at the time. But he explained himself to me very kindly; telling me over again, in a plain way, what he'd just told the doctor. He reminded me, too, that the remedies which had been already tried had been of no use; and told me I might feel sure that any others would only end in the same way, and put her to useless pain into the bargain. 'I hope,' says he, 'the poor child is too young to suffer much mental misery under her dreadful misfortune. Keep her amused, and keep her talking, if you possibly can--though I doubt very much whether, in a little time, you won't fail completely in getting her to speak at all.' ...|$|E
60|$|Qu. 23. Is not Vision perform'd chiefly by the Vibrations of this Medium, excited in {{the bottom}} of the Eye by the Rays of Light, and {{propagated}} through the solid, pellucid and uniform Capillamenta of the optick Nerves into the place of Sensation? And is not Hearing perform'd by the Vibrations either of this or some other Medium, excited in the <b>auditory</b> <b>Nerves</b> by the Tremors of the Air, and propagated through the solid, pellucid and uniform Capillamenta of those Nerves into the place of Sensation? And so of the other Senses.|$|R
30|$|There {{are many}} people who suffer from the hearing impediments, which caused by many reasons such as age, cancer, tuberculosis, noise, drug abuse, {{physical}} trauma worldwide [1 – 4]. As one of most serious and typical hearing impairment, sensorineural hearing loss is often caused by the damage or loss of hair cells of the organ of the Corti in the cochlea, which leads to the disorder of frequency discrimination of the hearing function [5 – 7]. The most important functions of cochlea are separating the incoming sound waves by their frequencies and convert different frequency of sound-induced vibration into electricity to stimulate <b>auditory</b> <b>nerves</b> [8, 9]. The basilar membrane which is a special film plays a significance role for the frequencies selectivity. Most of patients who suffer from the sensorineural hearing loss choose to cochlea implants, which transform the acoustic into electricity to stimulate <b>auditory</b> <b>nerves</b> through an electric array inserted in the cochlea [10, 11]. However, these cochlea implants make the patients feel very uncomfortable for they have many additional equipment located on the patients’ head, which result in many inconveniences when the patients sleep or excise. On the other hand, they also need peripheral devices to provide electric energy for all the system [12]. To overcome those disadvantages, fabricating a self-powered article and fully self-contained implantable artificial cochlea has been focus of efforts by many researchers globally.|$|R
40|$|In {{multichannel}} cochlear implants, {{low frequency}} information is delivered to apical cochlear locations while high frequency information is delivered to more basal locations, mimicking the normal acoustic tonotopic {{organization of the}} <b>auditory</b> <b>nerves.</b> In clinical practice; {{little attention has been}} paid to the distribution of acoustic input across the electrodes of an individual patient that might vary in terms of spacing and absolute tonotopic location. In normal-hearing listeners, Baskent and Shannon (J. Acoust. Soc. Am. 113, 2003) simulated implant signal processing conditions in which the frequency range assigned to the array was systematically made wider or narrower than the simulated stimulation range in the cochlea, resulting in frequency-place compression or expansion, respectively. In general, the best speech recognition was obtained when the input acoustic information was delivered to the matching tonotopic place in the cochlea with least frequency-place distortion. The present study measured phoneme and sentence recognition scores with similar frequency-place manipulations in six Med-El Combi 40 + implant subjects. Stimulation locations were estimated using the Greenwood mapping function based on the estimated electrode insertion depth. Results from frequency-place compression and expansion with implants were similar to simulation, results, especially for postlingually deafened subjects, despite the uncertainty in the actual stimulation sites of the <b>auditory</b> <b>nerves.</b> The present study shows that frequency-place mapping is an important factor in implant performance and an individual implant patient's map could be optimized with functional tests using frequency-place manipulations. (C) 2004 Acoustical Society of America...|$|R
