115|3489|Public
25|$|In August 2013, Nissan {{announced}} {{its plans to}} launch several driverless cars by 2020. The company is building in Japan a dedicated autonomous driving proving ground, {{to be completed in}} 2014. Nissan installed its autonomous car technology in a Nissan Leaf for demonstration purposes. The car was demonstrated at Nissan 360 test drive event held in California in August 2013. In September 2013, the Leaf fitted the prototype <b>Advanced</b> <b>Driver</b> <b>Assistance</b> <b>System</b> was granted a license plate that allows to drive it on Japanese public roads. The testing car will be used by Nissan engineers to evaluate how its in-house autonomous driving software performs in the real-world. Time spent on public roads will help refine the car’s software for fully automated driving. The autonomous Leaf was demonstrated on public roads {{for the first time at}} a media event held in Japan in November 2013. The Leaf drove on the Sagami Expressway in Kanagawa prefecture, near Tokyo. Nissan vice chairman Toshiyuki Shiga and the prefecture’s Governor, Yuji Kuroiwa, rode in the car during the test.|$|E
50|$|Intersection {{assistant}} is an <b>advanced</b> <b>driver</b> <b>assistance</b> <b>system</b> {{first introduced}} in 2009.|$|E
50|$|Turning {{assistant}} {{is a new}} <b>advanced</b> <b>driver</b> <b>assistance</b> <b>system</b> {{introduced in}} 2015.|$|E
40|$|Response to UK Government Consultation: 'pathways to driverless cars: {{proposals}} to support <b>advanced</b> <b>driver</b> <b>assistance</b> <b>systems</b> and automated vehicle technologies' {{for which a}} quote appeared in the Government's Report (Pathway to driverless cars: consultation on {{proposals to}} support <b>advanced</b> <b>driver</b> <b>assistance</b> <b>systems</b> and automated vehicles government response...|$|R
5000|$|Toshiba TMPV75 Series image {{recognition}} SoCs for <b>advanced</b> <b>driver</b> <b>assistance</b> <b>systems</b> (ADAS) ...|$|R
5000|$|Automotive ADAS and Infotainment for <b>Advanced</b> <b>Driver</b> <b>Assistance</b> <b>Systems,</b> Front Camera, Park Assist, Surround/Top View, Rear Camera, Radar, Fusion, Driver Monitoring ...|$|R
50|$|Wrong-way driver warning {{is a new}} <b>advanced</b> <b>driver</b> <b>assistance</b> <b>system</b> {{introduced}} in 2010 to prevent wrong-way driving.|$|E
5000|$|... 2014: Geotab {{announced}} their J1939 integration with the Mobileye 560 (Mobileye’s <b>Advanced</b> <b>Driver</b> <b>Assistance</b> <b>System).,</b> Enterprise Fleet Management announces partnership with Geotab, Geotab and Telefonica announce a working partnership.|$|E
5000|$|Velodyne donated one of {{its early}} {{prototype}} sensors to the Robotics Collection at the Smithsonian Institution’s National Museum of American History in 2011. In 2015, Frost & Sullivan gave Velodyne's VLP-16 sensor the North American Automotive ADAS (<b>Advanced</b> <b>Driver</b> <b>Assistance</b> <b>System)</b> Sensors Product Leadership Award.|$|E
50|$|In 2015 DEWESoft {{together}} with SMI integrated the Eye Tracking Glasses into a driver machine {{monitoring and analysis}} platform for <b>Advanced</b> <b>Driver</b> <b>Assistance</b> <b>Systems</b> (ADAS).|$|R
5000|$|Kia {{demonstrated}} their upcoming [...] "Drive Wise" [...] sub-brand at the 2016 Consumer Electronics Show with a Kia Soul EV modified with <b>Advanced</b> <b>Driver</b> <b>Assistance</b> <b>Systems</b> (ADAS) technology.|$|R
50|$|Infotainment {{options include}} MMI Navigation plus, Bose {{surround}} sound system with 14 loudspeakers {{with up to}} 465 watts of output power, Bluetooth car phone online <b>advanced</b> <b>driver</b> <b>assistance</b> <b>systems.</b>|$|R
5000|$|Ticmirror [...] is a in-car robot {{integrating}} Mobvoi’s voice engine. Ticmirror {{allows users}} to perform everything they could with Ticauto and more {{with the addition of}} 7.84 inch touch screen that doubles as a rear view mirror. It has a 160 degrees wide angle lens allowing it {{to be used as a}} 1080p dashcam. Ticmirror is compatible with Ticeye, which is an <b>Advanced</b> <b>Driver</b> <b>Assistance</b> <b>System</b> (ADAS) enable front collision warning and lane departure warnings.|$|E
50|$|In August 2013 Nissan {{announced}} {{its plans to}} launch several driverless cars by 2020. The company is building a dedicated autonomous driving proving ground in Japan, {{to be completed in}} 2014. Nissan installed its autonomous car technology in a Nissan Leaf all-electric car for demonstration purposes. The car was demonstrated at Nissan 360 test drive event held in California in August 2013. In September 2013, the Leaf fitted with the prototype <b>Advanced</b> <b>Driver</b> <b>Assistance</b> <b>System</b> was granted a license plate that allows to drive it on Japanese public roads. The testing car will be used by Nissan engineers to evaluate how its in-house autonomous driving software performs in the real world. Time spent on public roads will help refine the car’s software for fully automated driving. The autonomous Leaf was demonstrated on public roads {{for the first time at}} a media event held in Japan in November 2013. The Leaf drove on the Sagami Expressway in Kanagawa prefecture, near Tokyo. Nissan vice chairman Toshiyuki Shiga and the prefecture’s Governor, Yuji Kuroiwa, rode in the car during the test.|$|E
30|$|The PROTON-PLATA project [93] is a European {{project that}} aims at {{developing}} a reconfigurable prototype based on emerging software-defined technologies for telematics applications for cars-to-roadside and car-to-car communications. The project proposes a multitechnology cooperative <b>Advanced</b> <b>Driver</b> <b>Assistance</b> <b>System</b> (ADAS) {{that is based}} on the integration of SDR devices in vehicles.|$|E
50|$|The {{category}} of features that is increasing most rapidly is <b>Advanced</b> <b>Driver</b> <b>Assistance</b> <b>Systems</b> (ADAS). Within {{a couple of}} years, a standard passenger car {{will be able to}} drive with a great level of autonomy.|$|R
50|$|Cognitive Technologies - is a Russian {{software}} {{corporation that}} develops corporate business- applications, AI-based <b>advanced</b> <b>driver</b> <b>assistance</b> <b>systems.</b> Founded in 1993 in Moscow (Russia), {{the company has}} offices in Eastern Europe, with R&D Centers in Russia.|$|R
40|$|In {{order to}} {{decrease}} the amount of accidents or mitigate the consequences of them, today’s vehicles are being equipped with <b>Advanced</b> <b>Driver</b> <b>Assistance</b> <b>Systems.</b> The functionality and design of these systems is almost entirely based on research related to the driving concerns in Western countries. However, with the rapid motorization in developing countries such as China, there is an increasing need to investigate how these systems should be designed for new and growing markets. In order to address this need, research was conducted to discover the most common traffic problems facing Chinese drivers, how those problems differ from those for drivers {{in a country with}} a more developed driving culture (Sweden), and what consequences these differences will have for the design of <b>Advanced</b> <b>Driver</b> <b>Assistance</b> <b>Systems.</b> Results show that, even though Swedish and Chinese traffic rules and regulations are similar, driver behavior is highly culturally mediated. Results also indicate that the type of <b>assistance</b> <b>drivers</b> need in different traffic situations depends a great deal on driver behavior. The observed differences between Swedish and Chinese <b>drivers</b> suggest that <b>Advanced</b> <b>Driver</b> <b>Assistance</b> <b>Systems</b> designed for roads in Sweden may not necessarily be optimal in other markets...|$|R
30|$|For the {{development}} of ADAS an iterative development process has been established [34, p. 30]: In an initial step the technical feasibility has to be proven, before, in a second step, human factors have to be considered. Finally, a proof of concept ensures the practical suitability of the <b>advanced</b> <b>driver</b> <b>assistance</b> <b>system.</b>|$|E
30|$|While the unproved {{absolute}} validity {{might not}} be a hinder for cases where the tendency and the effect size of the results may matter the most (i.e. when road safety measures are under investigation), there are cases that numerical proximity is critical, such as in the cases that the warning or intervention thresholds of an <b>Advanced</b> <b>Driver</b> <b>Assistance</b> <b>System</b> (ADAS) need to be determined.|$|E
40|$|This thesis {{proposes a}} new {{general-purpose}} methodology to conduct studies on Human Factors in Transportation Systems. A full-fledged setup {{and implementation of}} the methodology is provided for validation. This setup, which uses real data to perform the simulation, includes a traffic micro-simulator, a driving simulator, a traffic control centre and an <b>Advanced</b> <b>Driver</b> <b>Assistance</b> <b>System,</b> providing an experimentation laboratory, in which empirical research can be conducted. The communication between the simulation components is made interchangeably using both the European standard Datex II and the SUMO TraCI protocols. Several usage scenarios are implemented and indications on how to extend the methodology to accommodate different requirements are provided; as to prove its usability and feasibility. A simple Human Factors study was conducted using the implemented setup. This study uses naturalistc data and evaluates the network performance gain by using an <b>Advanced</b> <b>Driver</b> <b>Assistance</b> <b>System</b> that recommends new routes to drivers in congestion situations and provides a final validation of the methodology. In conclusion, the methodology has been proved usable to effectively conduct Human Factors research and also to develop Advanced Driver Assistance Systems applications in a controlled, yet realistic environment. This thesis proposes a new general-purpose methodology to conduct studies on Human Factors in Transportation Systems. A full-fledged setup {{and implementation of the}} methodology is provided for validation. This setup, which uses real data to perform the simulation, includes a traffic micro-simulator, a driving simulator, a traffic control centre and an <b>Advanced</b> <b>Driver</b> <b>Assistance</b> <b>System,</b> providing an experimentation laboratory, in which empirical research can be conducted. The communication between the simulation components is made interchangeably using both the European standard Datex II and the SUMO TraCI protocols. Several usage scenarios are implemented and indications on how to extend the methodology to accommodate different requirements are provided; as to prove its usability and feasibility. A simple Human Factors study was conducted using the implemented setup. This study uses naturalistc data and evaluates the network performance gain by using an <b>Advanced</b> <b>Driver</b> <b>Assistance</b> <b>System</b> that recommends new routes to drivers in congestion situations and provides a final validation of the methodology. In conclusion, the methodology has been proved usable to effectively conduct Human Factors research and also to develop Advanced Driver Assistance Systems applications in a controlled, yet realistic environment...|$|E
40|$|Assessing Stress and Strain while Driving  the Value for <b>Driver</b> <b>Assistance</b> The {{concepts}} stress and strain are distinguished {{and discussed}} {{with regard to}} <b>advanced</b> <b>driver</b> <b>assistance</b> <b>systems.</b> The approach of two empirical studies (analyses of real driving situations and a questionnaire study) concerned with driving through intersections is pre-sented, which was conducted {{within the framework of}} the INVENT initiative. In this study, different aspects of stress were manipulated. The effects on subjective strain, physiology (heart rate) and driving behaviour (driver and vehicle reactions) were measured. It is shown that different levels of stress factors quite accurately predict actual strain while driving. Com-bining the different measures gives an indication of how strain arises and what drivers do to cope. The consequences of these results with regard to <b>advanced</b> <b>driver</b> <b>assistance</b> <b>systems</b> are discussed...|$|R
40|$|This paper {{presents}} the working principle, functionality {{and the experience}} during the first operational period of the VEHIL laboratory, dedicated to the development and testing of <b>advanced</b> <b>driver</b> <b>assistance</b> <b>systems.</b> The position of VEHIL and its PC based full software variant PRESCAN is illustrated based on the so-called V-cycle...|$|R
5000|$|In January 2016, Valens raised $20 {{million in}} its third round of funding and {{announced}} their intention to branch out and implement their solutions in automotive infrastructure, partnering with General Motors, Delphi Automotive, and Daimler AG. Valens' automotive solutions are used in <b>Advanced</b> <b>Driver</b> <b>Assistance</b> <b>Systems</b> and infotainment systems.|$|R
40|$|Within {{the scope}} of the European policy for Intelligent Transport Systems (ITS), the PLATA-PROTON project proposes a multi {{technology}} cooperative <b>Advanced</b> <b>Driver</b> <b>Assistance</b> <b>System</b> (ADAS), based on the integration of Software-Defined Radio (SDR) devices in vehicles. With the choice of significant road-safety related scenarios, V 2 V and V 2 I communications have been both implemented and simulated. This paper proposes an overview of the Software-Defined Radio (SDR) platform development and the performance evaluation based on network simulation, performed within this project...|$|E
40|$|Abstract—This paper proposes an {{improvement}} of <b>Advanced</b> <b>Driver</b> <b>Assistance</b> <b>System</b> based on saliency estimation of road signs. After a road sign detection stage, its saliency is estimated using a SVM learning. A model of visual saliency linking {{the size of}} an object and a size-independent saliency is proposed. An eye tracking experiment in context close to driving proves that this computational evaluation of the saliency fits well with human perception, and demonstrates the applicability of the proposed estimator for improved ADAS...|$|E
40|$|Abstract. Predicting vehicle {{trajectory}} accurately is {{a crucial}} task for an autonomous vehicle. It is also necessary for many <b>Advanced</b> <b>Driver</b> <b>Assistance</b> <b>System</b> to predict trajectory of the ego-vehicle’s. In recent years, some vehicles trajectory prediction algorithm is mainly based on a simple Motion Model. This paper puts forward a method which combines road recognition and the hypothesis of steady preview and dynamic correction for trajectory prediction. In the road recognition algorithm, both methods of Kalman Filter(KF) and Recursive Least-Square(RLS) work well to estimate the road slope and road friction coefficient...|$|E
50|$|In August 2016, IMI {{announced}} that it will acquired 76 percent stake in the optical bonding and display solutions provider, VIA optronics GmbH. This brings new technology to IMI for display solution in the automotive industry by providing automotive camera and display monitor solutions for <b>advanced</b> <b>driver</b> <b>assistance</b> <b>systems</b> (ADAS).|$|R
40|$|<b>Advanced</b> <b>driver</b> <b>assistance</b> <b>systems</b> or highly {{automated}} driving systems for lane change maneuvers {{are expected to}} enhance highway traffic safety, transport efficiency, and driver comfort. To extend the capability of current <b>advanced</b> <b>driver</b> <b>assistance</b> <b>systems,</b> and eventually progress to highly automated highway driving, the task of automatically determine if, when, and how to perform a lane change maneuver, is essential. This paper thereby presents a low-complexity lane change maneuver algorithm which determines whether a lane change maneuver is desirable, and if so, selects an appropriate inter-vehicle traffic gap and time instance to perform the maneuver, and calculates the corresponding longitudinal and lateral control trajectory. The ability of the proposed lane change maneuver algorithm to make appropriate maneuver decisions and generate smooth and safe lane change trajectories in various traffic situations is demonstrated by simulation and experimental results...|$|R
40|$|IEEE 802. 11 p {{is the new}} {{standard}} proposed by the IEEE for wireless connectivity in a vehicular context. It {{can be used by}} <b>Advanced</b> <b>Driver</b> <b>Assistance</b> <b>Systems</b> (ADAS) and Intelligent Transport Systems (ITS) to make vehicles aware of the traffic around them and increase vehicle safety with applications like cooperative cruise control, assiste...|$|R
40|$|This paper {{explores the}} {{technical}} feasibility of five <b>Advanced</b> <b>Driver</b> <b>Assistance</b> <b>System</b> (ADAS) functions {{to contribute to}} road traffic safety, to reach stated European (EU) and national road traffic safety targets. These functions - enhanced navigation, speed assistance, collision avoidance, intersection support and lane keeping - were selected from previous research as adequate substitutes for infrastructure related measures. State-of-the-art enabling technologies (like positioning, radar, laser, vision and communication) and their potential are analysed from a technical perspective, and possible obstacles for large-scale dedicated ADAS implementation for road traffic safety are discussed...|$|E
30|$|On GTX 1080, the RCC-Net took 25.5 ms for {{the forward}} {{inference}} of 480 × 360 images, including fetching and displaying the image. It is {{also able to}} run one inference on a car-deployable mini PC Zotac EN- 761 in 67.5 ms with the network size of 4.9 MB, which draws out the power consumption around 62.4 watt. It means the proposed network is fast and small enough to enable the <b>Advanced</b> <b>Driver</b> <b>Assistance</b> <b>System</b> (ADAS). We plan to run the network on a GPU-based embedded system, such as NVIDIA Jetson TK 1 for further investigation 1.|$|E
40|$|This paper {{presents}} {{a new approach}} to the detection of a vehicle with low relative speed to a monocular moving camera, for complementing moving vehicle detection using motion vectors from H. 264 /AVC encoder. This method makes use of the generic horizontal line features that exist on most vehicles as a clue of localizing moving vehicles. Further filtering and grouping of these detected lines followed by ego motion compensation can effectively detect moving vehicle with low relative speed for application in <b>advanced</b> <b>driver</b> <b>assistance</b> <b>system.</b> Our test results show a high detection rate of over 90...|$|E
40|$|Today's {{drivers have}} to cope with a growing amount of {{information}} coming from on-board information messages, telematics and <b>advanced</b> <b>driver</b> <b>assistance</b> <b>systems.</b> The interaction between the driver and these systems is critical since it may distract the driver from the primary task of driving. The paper, addressing this problem has a twofold aim: in one hand to carry out...|$|R
40|$|In this paper, {{we present}} a concept for an open {{vehicular}} data interface and describe it’s components and architecture. We discuss the enabled applications {{in the context of}} <b>advanced</b> <b>driver</b> <b>assistance</b> <b>systems</b> with a focus on humanmachine interfaces, vehicle-to-x (V 2 X) communication and context inference systems. We conclude by a presentation of the initial implementation and deployed system...|$|R
50|$|Series7XT Plus achieve up to 4x {{performance}} {{increase for}} vision applications.The GPUs {{are designed to}} offer improved in-system efficiency, improved power efficiency and reduced bandwidth for vision and computational photography in consumer devices, mid-range and mainstream smartphones, tablets and automotive <b>systems</b> such as <b>advanced</b> <b>driver</b> <b>assistance</b> <b>systems</b> (ADAS), infotainment, computer vision and advanced processing for instrument clusters.|$|R
