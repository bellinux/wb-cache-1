80|284|Public
5000|$|... #Subtitle level 4: Networks derived {{using the}} {{potential}} <b>analogue</b> <b>method</b> ...|$|E
5000|$|Gaudi's <b>analogue</b> <b>method</b> {{includes}} {{the main features}} of a computational of a parametric model (input parameters, equation, output): ...|$|E
50|$|The {{potential}} <b>analogue</b> <b>method</b> {{was proposed}} by Darlington {{as a simple}} way to choose pole-zero positions for delay networks. The method allows the designer to implement a delay characteristic by locating poles and zero on the complex frequency plane intuitively, without the need for complicated mathematics or the recourse to reference tables.|$|E
5000|$|... #Subtitle level 3: The Generation of Chirp Waveforms - <b>Analogue</b> <b>Methods</b> ...|$|R
5000|$|Deeley, E. M., MacKay, D. M., Multiplication and {{division}} by electronic <b>analogue</b> <b>methods,</b> Nature 163 (4147): 650-650. 1949 ...|$|R
50|$|In {{contrast}} to the coarse counter in the previous section, fine measurement methods with much better accuracy but far smaller measuring range are presented here. <b>Analogue</b> <b>methods</b> like time interval stretching or double conversion as well as digital methods like tapped delay lines and the Vernier method are under examination. Though the <b>analogue</b> <b>methods</b> still obtain better accuracies, digital time interval measurement is often preferred due to its flexibility in integrated circuit technology and its robustness against external perturbations like temperature changes.|$|R
50|$|Another way {{to create}} a delay time is to {{implement}} a delay line in an integrated circuit storage device. This can be done digitally or with a discrete <b>analogue</b> <b>method.</b> The analogue one uses bucket-brigade devices or charge coupled devices (CCD), which transport a stored electric charge stepwise {{from one end to}} the other. Both digital and analog methods are bandwidth limited at the upper end to the half of the clock frequency, which determines the steps of transportation.|$|E
50|$|In some later {{equation}} clocks, {{a pendulum}} swings {{at a constant}} frequency, controlling a normal clock mechanism. Often, this mechanism drives a display showing mean (clock) time. However, there are additional components: an equation of time simulation mechanism as described above, and a device that automatically adds the equation of time to clock time, and drives a display that shows solar time. The addition is done by an <b>analogue</b> <b>method,</b> using a differential gear. This type of equation clock mechanism is the most versatile. Both solar and mean times can be easily and clearly displayed, as can the equation of time. Striking the hours in both kinds of time is also easy to arrange. After its invention in 1720, this mechanism became the standard one, and was used {{for much of the}} 18th Century, until the demand for equation clocks ceased.|$|E
40|$|Large power {{transformers}} (LPTs) {{are critical}} yet increasingly vulnerable {{components of the}} power grid. More frequent and intense heat waves or high temperatures can degrade their operational lifetime and thereby increase the premature failure risk. Without adequate preparedness, a widespread situation would ultimately lead to prolonged grid disruption and incur excessive economic costs. In this study, we investigate the impact of climate warming and corresponding shifts in heat waves on a selected LPT located in the Northeast corridor of the United States. We apply an <b>analogue</b> <b>method,</b> which detects the occurrence of heat waves based on the salient, associated large-scale atmospheric conditions (“composites”), to assess the risk of future change in heat wave occurrence. Compared with the more conventional approach that relies on climate model-simulated daily maximum temperature, the <b>analogue</b> <b>method</b> produces model medians of late twentieth-century heat wave frequency that are more consistent with observation and have stronger inter-model consensus. Under the future climate warming scenarios, multi-model medians of both model daily maximum temperature and the <b>analogue</b> <b>method</b> indicate strong decadal increases in heat wave frequency {{by the end of}} the 21 st century, but the <b>analogue</b> <b>method</b> improves model consensus considerably. We perform a preliminary assessment on the decrease of transformer lifetime with temperature increase. Future work will focus on using more advanced algorithms to quantify the impact of more frequent heat waves on the transformer’s expected lifetime and associated additional costs. The improved inter-model consensus of the <b>analogue</b> <b>method</b> is viewed as a promising step toward providing actionable information for a more stable, reliable, and environmentally responsible national grid. This work was funded by MIT Lincoln Lab (DE-FOA- 0000768) ...|$|E
5000|$|Other <b>analogue</b> <b>methods,</b> {{which were}} devised {{to aid the}} {{designer}} to choose the pole zero positions for his networks, include the [...] "rubber sheet model" [...] and the [...] "electrolytic tank". and Teledeltos paper ...|$|R
40|$|The use of <b>analogue</b> <b>methods</b> of {{addition}} {{and integration}} in the solution of differential equations is introduced. A circuit for the solution of a reactor problem is then developed {{and the way in}} which an operator would use it is described. The essential features of a hybrid computer are briefly reviewed...|$|R
5000|$|The {{album was}} {{recorded}} to tape using <b>analogue</b> <b>methods,</b> with Regan noting, [...] "I {{just love the}} sound of it, I love the process. I love the idea that there's a master tape. It's a very potent thing." [...] Regan and producer Sean Read recorded using the same console that The White Stripes used to record their fourth studio album, Elephant.|$|R
40|$|An <b>analogue</b> <b>method</b> is {{presented}} to detect the occurrence of heavy precipitation events without relying on modeled precipitation. The approach is based on using composites to identify distinct large-scale atmospheric conditions associated with widespread heavy precipitation events across local scales. These composites, exemplified in the south-central, midwestern, and western United States, are derived through the analysis of 27 -yr (1979 – 2005) Climate Prediction Center (CPC) gridded station data and the NASA Modern-Era Retrospective Analysis for Research and Applications (MERRA). Circulation features and moisture plumes associated with heavy precipitation events are examined. The analogues are evaluated against the relevant daily meteorological fields from the MERRA reanalysis and achieve a success rate of around 80 % in detecting observed heavy events within one or two days. The method also captures the observed interannual variations of seasonal heavy events with higher correlation and smaller RMSE than MERRA precipitation. When applied to the same 27 -yr twentieth-century climate model simulations from Phase 5 of the Coupled Model Intercomparison Project (CMIP 5), the <b>analogue</b> <b>method</b> produces a more consistent and less uncertain number of seasonal heavy precipitation events with observation as opposed to using model-simulated precipitation. The <b>analogue</b> <b>method</b> also performs better than model-based precipitation in characterizing the statistics (minimum, lower and upper quartile, median, and maximum) of year-to-year seasonal heavy precipitation days. These results indicate the capability of CMIP 5 models to realistically simulate large-scale atmospheric conditions associated with widespread local-scale heavy precipitation events with a credible frequency. Overall, the presented analyses highlight the improved diagnoses of the <b>analogue</b> <b>method</b> against an evaluation that considers modeled precipitation alone to assess heavy precipitation frequency. United States. National Aeronautics and Space Administration. Energy and Water Cycle Study Research Announcement (NNH 07 ZDA 001 N) National Science Foundation (U. S.). MacroSystems Biology Program (NSF-AES EF 1137306...|$|E
40|$|This study {{examined}} the impact of Tomm’s (1988) four questioning styles on the therapeutic alliance in family therapy using an <b>analogue</b> <b>method</b> devised by Dozier in which families viewed videotaped scenes from simulated family therapy sessions portraying each of Tomm’s questioning styles and rated the alliance between the therapist and family...|$|E
40|$|International audienceAn {{adaptation}} technique {{based on}} the synoptic atmospheric circulation to forecast local precipitation, namely the <b>analogue</b> <b>method,</b> has been implemented for the western Swiss Alps. During the calibration procedure, relevance maps were established for the geopotential height data. These maps highlight the locations were the synoptic circulation was found of interest for the precipitation forecasting at two rain gauge stations (Binn and Les Marécottes) that are located both in the alpine Rhône catchment, {{at a distance of}} about 100 km from each other. These two stations are sensitive to different atmospheric circulations. We have observed that the most relevant data for the <b>analogue</b> <b>method</b> can be found where specific atmospheric circulation patterns appear concomitantly with heavy precipitation events. Those skilled regions are coherent with the atmospheric flows illustrated, for example, by means of the back trajectories of air masses. Indeed, the circulation recurrently diverges from the climatology during days with strong precipitation on {{the southern part of the}} alpine Rhône catchment. We have found that for over 152 days with precipitation amount above 50 mm at the Binn station, only 3 did not show a trajectory of a southerly flow, meaning that such a circulation was present for 98 % of the events. Time evolution of the relevance maps confirms that the atmospheric circulation variables have significantly better forecasting skills close to the precipitation period, and that it seems pointless for the <b>analogue</b> <b>method</b> to consider circulation information days before a precipitation event as a primary predictor. Even though the occurrence of some critical circulation patterns leading to heavy precipitation events can be detected by precursors at remote locations and 1 week ahead (Grazzini, 2007; Martius et al., 2008), time extrapolation by the <b>analogue</b> <b>method</b> seems to be rather poor. This would suggest, in accordance with previous studies (Obled et al., 2002; Bontron and Obled, 2005), that time extrapolation should be done by the Global Circulation Model, which can process atmospheric variables that can be used by the adaptation method...|$|E
40|$|A {{modified}} version of Multhopp's lifting surface theory, programmed for NAL Sirius computer, is presented. Aerodynamic characteristics are determined {{for a number of}} composite planforms and compared with those existing in the literature. Some interesting comparisons are also made with the results obtained from electrical <b>analogue</b> <b>methods.</b> The method is applied to cambered wings also. It is found that the method gives excellent and reliable results...|$|R
40|$|A {{principal}} {{factor in}} realizing a high-performance bandwidth-efficient fiber communication system at an acceptable cost {{is the choice}} of modulation format on the optical carrier. In this context pulse time modulation (PTM) techniques represent an attractive alternative to purely digital or <b>analogue</b> <b>methods.</b> This paper reviews the PTM family and explores their potential for use in high-speed fiber systems intended for transmission of analogue data...|$|R
40|$|The {{principal}} {{factor in}} realising a high-performance bandwidth-efficient fibre communication system at an acceptable cost {{is the choice}} of modulation format on the optical carrier. In this context, pulse time modulation (PTM) techniques represent an attractive alternative to purely digital or <b>analogue</b> <b>methods.</b> The PTM family is reviewed, a classification system is proposed and their potential for use in high-speed fibre systems intended for the transmission of analogue data is examined...|$|R
40|$|Abstract: In {{this paper}} the {{temperature}} time {{series of three}} Slovak mountain stations and one Slovak lowland station are analyzed {{from the point of}} view of their warmer periods. These warmer periods are analysed by an <b>analogue</b> <b>method.</b> Selected periods (warmer summer and warmer winter seasons) are characterized by air temperature as well as by precipitation, humidity and some other variables. In the second part of this paper the behaviour of the Canadian climate model outputs are studied {{from the point of view}} of their ability to catch similar warmer periods for this Central European region in the model control periods (1900 - 2004). Finally the results obtained by the <b>analogue</b> <b>method</b> and by climate model outputs are compared. Obtained results are in good coincidence between both used methods. Past warmer periods can be considered as some analogue of future climate events under enhanced greenhouse conditions...|$|E
40|$|Ab. sfract-A network <b>analogue</b> <b>method</b> for {{calculation}} of the capacitance matrix of certain two-dimensional multiconductor systems is presented. The system is contained in a finite or infinite conducting rectangular boundary. An arbitrary number of parallel dielectric layers can be present, and the conductors consist of an arbitrary number of conducting strips at {{one or more of}} the dielectric interfaces. The strips are assumed to have zero thickness. B...|$|E
40|$|This paper {{examines}} an <b>analogue</b> <b>method</b> {{for power}} spectral density estimation which employs an asymmetrical modulation. The approximate expressions for the expected value and for the dispersion of the estimate thus obtained are worked out by means of simplifying hypotheses. Then a comparison is drawn between the method under examination and another one with symmetrical modulation; it is shown {{that in some cases}} the former has advantageous results in that at a parity of estimate dispersion it demands a smaller number of components...|$|E
40|$|The {{design of}} {{analogue}} electronic experiments to investigate phenomena in nonlinear dynamics, especially stochastic phenomena, {{is described in}} practical terms. The {{advantages and disadvantages of}} this approach, in comparison to more conventional digital methods, are discussed. It is pointed out that analogue simulation provides a simple, inexpensive, technique that is easily applied in any laboratory to facilitate the design and implementation of complicated and expensive experimental projects; and that there are some important problems for which <b>analogue</b> <b>methods</b> have so far provided the only experimental approach. Applications to several topical problems are reviewed. Large rare fluctuations are studied through measurements of the prehistory probability distribution, thereby testing for the first time some fundamental tenets of fluctuation theory. It has thus been shown for example that, whereas the fluctuations of equilibrium systems obey time-reversal symmetry, those under non-equilibrium conditions are temporally asymmetric. Stochastic resonance, in which the signal-to-noise ratio for a weak periodic signal in a nonlinear system can be enhanced by added noise, has been widely studied by <b>analogue</b> <b>methods,</b> and the main result...|$|R
50|$|His first {{work was}} for the Admiralty {{designing}} radar countermeasures, work that eventually took him to Harvard University in the United States {{until the end of}} the war. He then studied for a PhD at the University of Manchester Institute of Science and Technology, and was there from 1948 until 1965. He worked for a long time with Henry Lipson on the development of optical diffraction <b>analogue</b> <b>methods.</b> He was awarded a DSc in 1960.|$|R
40|$|The paper {{explains}} {{the advantages of}} digital processing of dynamic data compared to <b>analogue</b> <b>methods.</b> Use of digital computers in processing the data, both off-line and on-line, connected with steady state, transient and random vibration testing is explained with reference to a few actual tests. The practical importance of real-time processing, {{with the help of}} on-line digital computers, when multiple shakers are used is described in connection with both steady state and random vibration tests...|$|R
40|$|The e::tension of the {{resistance}} network <b>analogue</b> <b>method</b> {{to the study of}} a M. O. S. T. structure is described. By means of an iterative technique, data regarding channel current, field distribution, surface charge and position of pinch-off point as function of gate and drain voltagen can be obtained which do not involve the usual 'gradual' channel approximation Results for a particular device geometry are presented. A discussion of a digital computer approach to the solution of semiconductor device current flow problems is included, together with preliminary results...|$|E
40|$|The {{analysis}} {{and design of}} a microwave amplifier tube {{has been carried out}} in which amplification is produced by the interaction of two streams of electrons. An electron gun system, able to provide the two streams of electrons, has been built according to observations made on a rubber membrane analogue of the system. Electron-optical tests have verified the behaviour which the <b>analogue</b> <b>method</b> of design predicted. The mechanical construction of the tube is described here in detail. Radio frequency tests made at a signal wavelength of 10. 7 cm. have confirmed the existence of the process of double-stream amplification...|$|E
40|$|Abstract: Conductive rubber {{material}} {{has been widely}} investigated as a sensor and transducer material due to its high piezoresistive, conductive properties. In this paper, we report on a flexible tactile sensor {{which is based on}} conductive rubber filled with carbon black. Firstly, a physical model related linear elasticity mechanics and franklinic <b>analogue</b> <b>method</b> is deduced. Then the sensing mechanism of flexible tactile sensor based on conductive rubber is discussed based on the physical model and used as the principle in designing tactile sensor. Theoretical analysis and simulations both verify the structure is reasonable. Copyright © 2013 IFSA...|$|E
40|$|Craft {{practitioners}} have deftly navigated a {{wide range}} of digital media tools as they have evolved, to enhance and originate forms of practice. Human centric and <b>analogue</b> <b>methods</b> are informing digital creation, which in some cases is softening a prevalent signature aesthetic evidenced in the use of computer fabrication processes. This article observes recent applications of computing media in making spheres consistent with this progression, and evidences new roles for makers as they drive technology use and related agendas, which is leading to craft skill influencing wider realms of practice and industry...|$|R
40|$|This {{article was}} {{prompted}} by the current popularity and acceptance of <b>analogue</b> <b>methods</b> in gender-related research. The use of analogues in research with women is examined here for both its strengths and limita-tions. We acknowledge the distinctive advantages of <b>analogue</b> <b>methods</b> in revealing the nature, extent, and potential outcomes of gender bias and stereotyping of all minority status groups. While recognizing that any method can be feminist, we address four major concerns with cur-rent applications of analogue research to questions about women and gender. These concerns cover: (a) relevance to the questions asked, (b) attention to the context of women’s lives, (c) significance for situational behavior, and (d) applicability to social change. We propose a set of transformations that applies feminist scholarship to reconceptualizing analogues in research related to women and gender. The documentation and exploration of stereotyping and response bias based on gender, ethnicity, and other group status variables represent important advances in research with women. Because participants in a research study may be unaware or reluctant to reveal biased attitudes and beliefs, researchers have frequently resorted to indirect methods to un-cover personally held stereotypes. The written analogue, or vignette, has provided a major vehicle for the indirect measure of gender bias. A re-search vignette presents {{a brief description of}} individuals or situations to which the respondent is asked to assign evaluative ratings, provide causal An earlier version of this article was presented at the annual convention of the America...|$|R
40|$|Aims/hypothesis The risk of {{developing}} a range of solid tumours is increased in type 2 diabetes, and {{may be influenced by}} glucose-lowering therapies. We examined the risk of development of solid tumours in relation to treatment with oral agents, human insulin and insulin <b>analogues.</b> <b>Methods</b> This was a retrospective cohort study of people treated in UK general practices. Those included in the analysis developed diabetes> 40 years of age, and started treatment with oral agents or insulin after 2000. A total of 62, 809 patients were divided into four groups according to whether they received monotherapy with metformin or sulfonylurea, combined therapy (metformin plus sulfonyl-urea), or insulin. Insulin users were grouped according t...|$|R
40|$|Digital Signal Processing {{is used in}} {{many areas}} where <b>analogue</b> <b>method</b> was difficult. Filters are used to {{separate}} or combine different frequencies. In this paper low pass filter has been designed and simulated using different windows techniques. Hamming and Kaiser Windows techniques are used along with Rectangular window technique for the design analysis by using matlabs. The performances of all the designs have been compared in terms of sidelobe attenuation and mainlobe width. The simulated result shows that the Kaiser window has near optimum performance and having the simplest implementation. The result also shows that increasing the Kaiser Window parameter Beta widens the mainlobe and decreases the amplitude of sidelobe...|$|E
40|$|A {{dynamical}} downscaling {{scheme is}} usually {{used to provide}} a short range flood forecasting system with high-resolved precipitation fields. Unfortunately, a single forecast of this scheme has a high uncertainty concerning intensity and location especially during extreme events. Alternatively, statistical downscaling techniques like the <b>analogue</b> <b>method</b> can be used which can supply a probabilistic forecasts. However, {{the performance of the}} <b>analogue</b> <b>method</b> is affected by the similarity criterion, which is used to identify similar weather situations. To investigate this issue in this work, three different similarity measures are tested: the euclidean distance (1), the Pearson correlation (2) and a combination of both measures (3). The predictor variables are geopotential height at 1000 and 700 hPa-level and specific humidity fluxes at 700 hPa-level derived from the NCEP/NCAR-reanalysis project. The study is performed for three mesoscale catchments located in the Rhine basin in Germany. It is validated by a jackknife method for a period of 44 years (1958 – 2001). The ranked probability skill score, the Brier Skill score, the Heidke skill score and the confidence interval of the Cramer association coefficient are calculated to evaluate the system for extreme events. The results show that the combined similarity measure yields the best results in predicting extreme events. However, the confidence interval of the Cramer coefficient indicates that this improvement is only significant compared to the Pearson correlation but not for the euclidean distance. Furthermore, the performance of the presented forecasting system is very low during the summer and new predictors have to be tested to overcome this problem...|$|E
40|$|Abstract. The {{continuity}} of concrete cellular slab was damaged by tubular hollow tubes which {{are arranged in}} slabs in parallel and the mechanical properties of slab exists anisotropy leading by different shapes of cross section in both directions of parallel and vertical to hollow tubes. Slab stiffness is weak greatly in direction of parallel to hollow tubes. For concrete cellular slab, the mechanical and deformation properties have been studied, the rigidity and stiffness ratio formula in both directions are been given. Orthotropic slab <b>analogue</b> <b>method</b> that is simplified calculation method for slab deflections are put out. The calculated results show that this method is adaptable and processes are simple. The calculated results are close to with engineering practices...|$|E
40|$|This paper {{deals with}} the {{analysis}} of acoustic biomedical signals, especially the infant cry. A plenty of important information is comprehended in the infant cry (e. g. {{the mood of the}} baby, the condition of the organ of speech, other physiological parameters, etc.). As these factors are not severable in the reality, this information has to be treated together during the acoustical analysis. Authors judge it necessary to adopt algorithms from other fields of the acoustic technique (e. g. audio segmentation); to digitize former <b>analogue</b> <b>methods</b> of examination (e. g. noting down the melody of the cry); and to combine these techniques. This study summarizes the major procedures and parameters by the analysis of the infant cry. KEY WORD...|$|R
40|$|Daily {{precipitation}} {{in northern}} Europe has different sta-tistical properties depending on season. In this study, four statistical downscaling methods were evaluated {{in terms of}} their ability to capture statistical properties of daily pre-cipitation in different seasons. Two of the <b>methods</b> were <b>analogue</b> downscaling methods; one using principal compo-nent analysis (PCA) and one using gradients in the pressure field (Teweles-Wobus scores, TWS) to select the analogues in the predictor field. The other two methods were con-ditional-probability methods; one using classification of weather patterns (MOFRBC) and the other using a regres-sion method conditioning a stochastic weather generator (SDSM). The two <b>analogue</b> <b>methods</b> were used as bench-mark methods. The study was performed on seven precip-itation stations in south-central Sweden and the large-scale predictor was gridded mean-sea-level pressure over Northern Europe. The four methods were trained and calibrated on 25 years of data (1961 – 1978, 1994 – 2000) and validated on 15 years (1979 – 1993). Temporal and spatial limitations were imposed on the methods to find the optimum predictor settings for the downscaling. The quality measures used for evaluating the downscaling methods were the residuals of a number of key statistical properties, and the ranked prob-ability scores (RPS) for precipitation and maximum length of dry and wet spells. The results showed that (1) the MOFRBC and SDSM outperformed the other methods for the RPS, (2) the statistical properties for the <b>analogue</b> <b>methods</b> were better during winter and autumn; for SDSM and TWS during spring; and for MOFRBC during summer, (3) larger predictor areas were needed for summer and autumn precipitation than winter and spring, and (4) no method could well capture the difference between dry and wet summers. 1...|$|R
50|$|Abdulkareem Adisa {{directed}} {{that the}} Federal School of Surveying should channel the evolution from <b>analogue</b> to digital <b>methods.</b>|$|R
