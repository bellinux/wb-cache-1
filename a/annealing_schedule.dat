132|63|Public
25|$|For {{any given}} finite problem, the {{probability}} that the simulated annealing algorithm terminates with a global optimal solution approaches 1 as the <b>annealing</b> <b>schedule</b> is extended. This theoretical result, however, is not particularly helpful, since the time required to ensure a significant probability of success will usually exceed the time required for a complete search of the solution space.|$|E
2500|$|In {{order to}} apply the SA method to a {{specific}} problem, one must specify the following parameters: the state space, the energy (goal) function E (...) , the candidate generator procedure neighbour (...) , the acceptance probability function P (...) , and the <b>annealing</b> <b>schedule</b> temperature (...) AND initial temperature >. These choices can {{have a significant impact}} on the method's effectiveness. [...] Unfortunately, there are no choices of these parameters that will be good for all problems, and there is no general way to find the best choices for a given problem. [...] The following sections give some general guidelines.|$|E
2500|$|Sometimes it {{is better}} to move back to a {{solution}} that was significantly better rather than always moving from the current state. [...] This process is called restarting of simulated annealing. [...] To do this we set s and e to sbest and ebest and perhaps restart the <b>annealing</b> <b>schedule.</b> [...] The decision to restart could be based on several criteria. Notable among these include restarting based on a fixed number of steps, based on whether the current energy is too high compared to the best energy obtained so far, restarting randomly, etc.|$|E
40|$|Classical and quantum {{annealing}} are two heuristic optimization {{methods that}} {{search for an}} optimal solution by slowly decreasing thermal or quantum fluctuations. Optimizing <b>annealing</b> <b>schedules</b> is important both for performance and fair comparisons between classical annealing, quantum annealing, and other algorithms. Here we present a heuristic approach for the optimization of <b>annealing</b> <b>schedules</b> for quantum <b>annealing</b> {{and apply it to}} 3 D Ising spin glass problems. We find that if both classical and quantum <b>annealing</b> <b>schedules</b> are similarly optimized, classical annealing outperforms quantum annealing for these problems when considering the residual energy obtained in slow annealing. However, when performing many repetitions of fast annealing, simulated quantum annealing is seen to outperform classical annealing for our benchmark problems...|$|R
40|$|New <b>annealing</b> <b>schedules</b> for quantum <b>annealing</b> are {{proposed}} {{based on the}} adiabatic theorem. These schedules exhibit faster decrease of the excitation probability than a linear schedule. To derive this conclusion, the asymptotic form of the excitation probability for quantum annealing is explicitly obtained {{in the limit of}} long annealing time. Its first-order term, which is inversely proportional to the square of the annealing time, is shown to be determined only by the information at the initial and final times. Our <b>annealing</b> <b>schedules</b> make it possible to drop this term, thus leading to a higher order (smaller) excitation probability. We verify these results by solving numerically the time-dependent Schrodinger equation for small size system...|$|R
40|$|The {{simulated}} annealing (SA) algorithm [12] [5] {{has been widely}} used to address intractable global optimizations in many fields, including training of artificial neural networks. Implementations of annealing universally use a monotone decreasing, or "cooling ", temperature schedule which is motivated by the algorithm's proof of optimality as well as analogies with statistical thermodynamics. In this paper, we challenge this motivation: the fact that cooling schedules are "optimal" in theory {{is not related to}} the practical performance of the algorithm. Our finding is based on a new "best-so-far" criterion for measuring the quality of <b>annealing</b> <b>schedules.</b> Motivated by studies of optimal schedules for small problems, we study highly nonstandard <b>annealing</b> <b>schedules</b> for training of feedforward perceptron networks on a real-world sensor classification benchmark. We find clear evidence that optimal schedules do not necessarily decrease monotonically to zero. 1 Introduction A typical applic [...] ...|$|R
2500|$|The {{following}} pseudocode {{presents the}} simulated annealing heuristic as described above. It starts {{from a state}} [...] and continues to either a maximum of [...] steps or until a state with an energy of [...] or less is found. In the process, the call [...] should generate a randomly chosen neighbour of a given state the call [...] should pick and return a value in the range , uniformly at random. The <b>annealing</b> <b>schedule</b> {{is defined by the}} call , which should yield the temperature to use, given the fraction [...] of the time budget that has been expended so far.|$|E
50|$|For {{any given}} finite problem, the {{probability}} that the simulated annealing algorithm terminates with a global optimal solution approaches 1 as the <b>annealing</b> <b>schedule</b> is extended. This theoretical result, however, is not particularly helpful, since the time required to ensure a significant probability of success will usually exceed the time required for a complete search of the solution space.|$|E
5000|$|A simple {{algorithm}} - {{simulated annealing}} - yields good results with relatively good performance. It works like local optimization, {{but it may}} keep a change even if it worsens the result. The chance of keeping such a change is , where [...] is {{the change in the}} evaluation function, and [...] is the temperature. The temperature is gradually lowered according to the <b>annealing</b> <b>schedule.</b> When the temperature is high, simulated annealing performs almost random changes to the label placement, being able to escape a local optimum. Later, when hopefully a very good local optimum has been found, it behaves {{in a manner similar to}} local optimization. The main challenges in developing a simulated annealing solution are choosing a good evaluation function and a good <b>annealing</b> <b>schedule.</b> Generally too fast cooling will degrade the solution, and too slow cooling will degrade the performance, but the schedule is usually quite a complex algorithm, with more than just one parameter.|$|E
40|$|We employ both master {{equation}} {{and order}} parameter approaches {{to analyze the}} asymptotic dynamics of on-line learning with dif-ferent learning rate <b>annealing</b> <b>schedules.</b> We examine {{the relations between the}} results obtained by the two approaches and obtain new results on the optimal decay coefficients and their dependence on the number of hidden nodes in a two layer architecture. ...|$|R
40|$|International audienceStarting from {{essentially}} flat nanometer-thick Fe films, epitaxially {{grown at}} room temperature on W(110) surfaces, we used carefully tuned <b>annealing</b> <b>schedules</b> to produce periodic arrays of nanoscale ferromagnetic wires. The structural transition from continuous films to nanowire arrays is accompanied with an in-plane 90 ° rotation of the spontaneous magnetization. Using spin-polarized low-energy electron microscopy to map the local magnetization directions while annealing, we studied {{the role of the}} dewetting mechanism on the self-organization and magnetization reorientation processes...|$|R
40|$|The {{study was}} made into {{processes}} of formation and characteristic properties of the composition and structure of Nb 3 Sn formed in multifilament superconductors during annealing within 700 - 820 °C for up to 200 h. The current carrying capacity of the above materials was studied {{in the field of}} < 18 T. It is established that the best critical current density of intermetallic Nb 3 Sn in low and high magnetic fields is achieved through dissimilar <b>annealing</b> <b>schedules...</b>|$|R
5000|$|Sometimes it {{is better}} to move back to a {{solution}} that was significantly better rather than always moving from the current state. This process is called restarting of simulated annealing. To do this we set [...] and [...] to [...] and [...] and perhaps restart the <b>annealing</b> <b>schedule.</b> The decision to restart could be based on several criteria. Notable among these include restarting based on a fixed number of steps, based on whether the current energy is too high compared to the best energy obtained so far, restarting randomly, etc.|$|E
5000|$|The {{following}} pseudocode {{presents the}} simulated annealing heuristic as described above. It starts {{from a state}} [...] and continues to either a maximum of [...] steps or until a state with an energy of [...] or less is found. In the process, the call [...] should generate a randomly chosen neighbour of a given state the call [...] should pick and return a value in the range , uniformly at random. The <b>annealing</b> <b>schedule</b> {{is defined by the}} call , which should yield the temperature to use, given the fraction [...] of the time budget that has been expended so far.|$|E
5000|$|It {{has been}} {{demonstrated}} experimentally as well as theoretically, that quantum annealing can indeed outperform thermal annealing (simulated annealing) in certain cases, especially where the potential energy (cost) landscape consists of very high but thin barriers surrounding shallow local minima. Since thermal transition probabilities (proportional to , with [...] the temperature and [...] the Boltzmann constant) depend only on the height [...] of the barriers, for very high barriers, {{it is extremely difficult}} for thermal fluctuations to get the system out from such local minima. However, as argued earlier in 1989 by Ray, Chakrabarti & Chakrabarti, the quantum tunneling probability through the same barrier depends not only on the height [...] of the barrier, but also on its width [...] and is approximately given by , where [...] is the tunneling field. If the barriers are thin enough (i.e. [...] ), quantum fluctuations can surely bring the system out of the shallow local minima. For -spin glasses, [...] is proportional to , and with a linear <b>annealing</b> <b>schedule</b> for the transverse field, one gets [...] proportional to [...] for the annealing time (instead of [...] proportional to [...] for thermal annealing). This [...] advantage in quantum search (compared to the classical effort growing linearly with [...] or , the problem size) is well established.|$|E
40|$|Starting from {{essentially}} flat nanometer-thick Fe films, epitaxially {{grown at}} room temperature on W(110) surfaces, we used carefully tuned <b>annealing</b> <b>schedules</b> to produce periodic arrays of nanoscale ferromagnetic wires. The structural transition from continuous films to nanowire arrays is accompanied with an in-plane 90 degree rotation of the spontaneous magnetization. Using spin-polarized low-energy electron microscopy to map the local magnetization directions while annealing, we studied {{the role of the}} dewetting mechanism on the self-organization and magnetization reorientation processes...|$|R
40|$|This paper {{examines}} {{the use of}} stochastic scheduling rules for maximizing the net present value of a project. A comprehensive set of 1440 test problems, representing five different project characteristics, is constructed. These test problems are {{used to evaluate the}} performance of nine stochastic scheduling rules. A simulated <b>annealing</b> <b>scheduling</b> procedure is shown to perform best, generating the highest net present values for most of the test problems. In certain environments, two previously examined rules, the Rank Positional Weight and a Discounted Cumulative Cash Flow Weight rule, also perform well with high net present values...|$|R
40|$|This paper {{surveys the}} {{application}} of simulated annealing (SA) to operations research (OR) problems. It is concluded that SA {{has been applied to}} both traditional (like single machine, flowshop and jobshop scheduling, lot sizing, traveling salesman problems) and non-traditional (like graph coloring, number partitioning) OR areas. It is also concluded that SA is quite appropriate when the alternative solution method is based on enumeration. SA usually requires more computational resources in exchange for not being trapped in local optima. simulated <b>annealing</b> <b>scheduling</b> QAP TSP routing facility layout lot sizing...|$|R
40|$|Abstract We {{outline the}} {{derivation}} of our <b>annealing</b> <b>schedule</b> A new simulated <b>annealing</b> <b>schedule</b> has been developed; {{its application to}} the standard cell placement and the traveling salesman problems results in a two to twenty-four times speedup over annealing schedules clirrently available in the literature. Since it uses only statistical quantities, the <b>annealing</b> <b>schedule</b> is applicable to general combinatorial optimization problems. 1...|$|E
40|$|Boltzmann {{selection}} {{is an important}} selection mechanism in evolutionary algorithms as it has theoretical properties which help in theoretical analysis. However, Boltzmann {{selection is}} not used in practice because a good <b>annealing</b> <b>schedule</b> for the `inverse temperature' parameter is lacking. In this {{paper we propose a}} Cauchy <b>annealing</b> <b>schedule</b> for Boltzmann selection scheme based on a hypothesis that selection-strength should increase as evolutionary process goes on and distance between two selection strengths should decrease for the process to converge. To formalize these aspects, we develop formalism for selection mechanisms using fitness distributions and give an appropriate measure for selection-strength. In this paper, we prove an important result, by which we derive an <b>annealing</b> <b>schedule</b> called Cauchy <b>annealing</b> <b>schedule.</b> We demonstrate the novelty of proposed <b>annealing</b> <b>schedule</b> using simulations in the framework of genetic algorithms...|$|E
40|$|Simulated Annealing (SA) is {{a widely}} used meta-heuristic that was {{inspired}} from the annealing process of recrystallization of metals. Therefore, the efficiency of SA is highly affected by the <b>annealing</b> <b>schedule.</b> As a result, in this paper, we presented an empirical work to provide a comparable <b>annealing</b> <b>schedule</b> to solve symmetric traveling salesman problems (TSP). Randomized complete block design is also used in this study. The results show that different parameters do affect the efficiency of SA and thus, we propose the best found <b>annealing</b> <b>schedule</b> based on the Post Hoc test. SA was tested on seven selected benchmarked problems of symmetric TSP with the proposed <b>annealing</b> <b>schedule.</b> The performance of SA was evaluated empirically alongside with benchmark solutions and simple analysis to validate the quality of solutions. Computational {{results show that the}} proposed <b>annealing</b> <b>schedule</b> provides a good quality of solution...|$|E
40|$|The use of {{patterned}} stress {{fields to}} direct phase separation in thin film alloys is investigated computationally with Monte Carlo simulations in which atomic interactions {{are represented by}} a Lennard-Jones potential. We show that careful design of <b>annealing</b> <b>schedules</b> based on consideration of the system phase diagram can lead to vastly enhanced patterning kinetics. In particular, by avoiding the low temperature formation of highly stable nuclei within the entire system, the kinetics of patterning are accelerated by rapid monomer diffusion, rather than classical Ostwald ripening in which small precipitates must dissolve to feed larger ones...|$|R
40|$|We derive {{real-time}} global optimization {{methods for}} several clustering optimization problems used in unsupervised texture segmentation. Speed {{is achieved by}} exploiting the topological relation of features to design a multiscale optimization technique, while accuracy and global optimization properties are gained using a deterministic annealing method. Coarse grained cost functions are derived for both central and sparse pairwise clustering, where the problem of coarsening sparse random graphs is solved by the concept of structured randomization. <b>Annealing</b> <b>schedules</b> and coarse-to-fine optimization are tightly coupled by a statistical convergence criterion derived from computational learning theory. The algorithms are benchmarked on Brodatz-like micro-texture mixtures. Results are presented for an autonomous robotics application...|$|R
40|$|This paper {{presents}} an algorithm for RNA secondary structure prediction based on Simulated Annealing (SA) and also studies {{the effect of}} using different types of <b>annealing</b> <b>schedules.</b> SA {{is known to be}} effective in solving many different types of minimization problems and for being able to approximate global minima in the solution space. Based on free energy minimization techniques, this permutation-based SA algorithm heuristically searches for the structure with a free energy value close to the minimum free energy ∆G for that strand, within given constraints. Other contributions of this paper include the use of permutation-based encoding for RNA secondary structure and the swap mutation operator. Also, a detailed study of the convergence behavior of the algorithm is conducted and various <b>annealing</b> <b>schedules</b> are investigated. An evaluation of the performance of the new algorithm in terms of prediction accuracy is made via comparison with the dynamic programming algorithm mfold for thirteen individual known structures from four RNA classes (5 S rRNA, Group I intron 23 rRNA, Group I intron 16 S rRNA and 16 S rRNA). Although dynamic programming algorithms for RNA folding are guaranteed to give the mathematically optimal (minimum energy) structure, the fundamental problem of this approach seems to be that the thermodynamic model is only accurate within 5 − 10 %. Therefore, it is difficult for a single sequence folding algorithm to resolve which of the plausible lowest-energy structure is correct. The new algorithm showed comparable results with mfold and demonstrated a slightly higher specificity...|$|R
40|$|A new {{simulated}} <b>annealing</b> <b>schedule</b> {{has been}} developed; {{its application to}} the standard cell placement and the traveling salesman problems results in a two to twentyfour times speedup over annealing schedules clirrently available in the literature. Since it uses only statistical quantities, the <b>annealing</b> <b>schedule</b> is applicable to general combinatorial optimization problems. 1...|$|E
30|$|Given {{transactions}} and an initial configuration S_ 0, SOR returns a preferable configuration S, {{so that the}} consumed time of the transactions is significantly reduced. In Algorithm 3, the main loop shows the iterative search process based on an <b>annealing</b> <b>schedule</b> proposed in [21]. The temperature function is the core function of the <b>annealing</b> <b>schedule.</b> In this algorithm, the temperature shrinks {{at a rate of}} (1 - cooling_rate). Function Neighbor(S) generates another configuration which swaps two random reordering blocks of the configuration of S.|$|E
40|$|Annealed {{importance}} sampling (AIS) is {{a common}} algorithm to estimate partition functions of useful stochastic models. One important problem for obtaining accurate AIS estimates is the selection of an <b>annealing</b> <b>schedule.</b> Conventionally, an <b>annealing</b> <b>schedule</b> is often determined heuristically or is simply set as a linearly increasing sequence. In this paper, we propose an algorithm for the optimal schedule by deriving a functional that dominates the AIS estimation error and by numerically minimizing this functional. We experimentally demonstrate that the proposed algorithm mostly outperforms conventional scheduling schemes with large quantization numbers...|$|E
40|$|For many {{optimization}} algorithms the time-to-solution depends {{not only}} on the problem size but also on the specific problem instance and may vary by many orders of magnitude. It is then necessary to investigate the full distribution and especially its tail. Here we analyze the distributions of annealing times for simulated annealing and simulated quantum annealing (by path integral quantum Monte Carlo) for random Ising spin glass instances. We find power-law distributions with very heavy tails, corresponding to extremely hard instances, but far broader distributions - and thus worse performance for hard instances - for simulated quantum annealing than for simulated annealing. Fast, non-adiabatic, <b>annealing</b> <b>schedules</b> can improve the performance of simulated quantum annealing for very hard instances by many orders of magnitude...|$|R
40|$|In many {{practical}} optimization problems, {{evaluation of}} a solution is subject to noise, e. g., due to stochastic simulations or measuring errors. Therefore, heuristics are needed {{that are capable of}} handling such noise. This paper first reviews the state-of-the-art in applying simulated annealing to noisy optimization problems. Then, two new algorithmic variants are proposed: an improved version of stochastic annealing that allows for arbitrary <b>annealing</b> <b>schedules,</b> and a new approach called simulated annealing in noisy environments (SANE). The latter integrates ideas from statistical sequential selection {{in order to reduce the}} number of samples required for making an acceptance decision with sufficient statistical confidence. Finally, SANE is shown to significantly outperform other state-of-the-art simulated annealing techniques on a stochastic travelling salesperson problem...|$|R
40|$|We {{present an}} energy based {{automatic}} image segmentation algorithm {{that uses a}} novel active contour scheme, called the stochastic active contour scheme (STACS). The algorithm overcomes some unique challenges arising in cardiac magnetic resonance (MR) images by minimizing an energy functional with four terms, each representing the region and edge based information of the image and the global and local properties of the contour. We use <b>annealing</b> <b>schedules</b> to control the relative strength {{of each of the}} terms during the minimization process. The segmentation results when applying STACS to a set of real cardiac MR sequences of a rat are presented and quantitatively assessed by comparing them to the manually-traced contours using two similarity measures, the area and shape similarity measures. This assessment validates STACS’s results, demonstrating its very good and consistent segmentation performance. 1...|$|R
3000|$|... [...]. T(sweepID) {{represents}} an <b>annealing</b> <b>schedule</b> with decreasing rate of temperature T for each sweep (indexed by sweepID) that denotes the time interval within which all sites have updated their states.|$|E
40|$|DraftAn {{algorithm}} is developed to statistically {{find the best}} global fit of a nonlinear non-convex cost-function over a D-dimensional space. It is argued that this algorithm permits an <b>annealing</b> <b>schedule</b> for ‘‘temperature’’ T decreasing exponentially in annealing-time k, T = T 0 exp(−ck 1 /D). The introduction of re-annealing also permits adaptation to changing sensitivities in the multidimensional parameter-space. This <b>annealing</b> <b>schedule</b> is faster than fast Cauchy annealing, where T = T 0 /k, and much faster than Boltzmann annealing, where T = T 0 / ln k. Applications are being made to fit empirical data to Lagrangians representing nonlinear Gaussian-Markovian systems...|$|E
40|$|Adaptive Simulated Annealing (ASA) is a C-language code {{developed}} to statistically {{find the best}} global fit of a nonlinear constrained non-convex cost-function over a D-dimensional space. This algorithm permits an <b>annealing</b> <b>schedule</b> for “temperature ” T decreasing exponentially in annealing-time k, T = T 0 exp(−ck 1 /D). The introduction of re-annealing also permits adaptation to changing sensitivities in the multi-dimensional parameter-space. This <b>annealing</b> <b>schedule</b> is faster than fast Cauchy annealing, where T = T 0 /k, and much faster than Boltzmann annealing, where T = T 0 /ln k. ASA has over 100 OPTIONS to provide robust tuning over many classes of nonlinear stochastic systems. *Adaptive Simulated Annealing (ASA...|$|E
40|$|With {{the ever}} {{increasing}} {{awareness of the}} toxicity of Pb, significant pressure {{has been put on}} the electronics industry to get the Pb out of solder. This work pertains to the development and characterization of an alloy which is Pb-free, yet retains the proven positive qualities of current Sn-Pb solders while enhancing the shortcomings of Sn-Pb solder. The solder studied is the Sn- 4. 7 Ag- 1. 7 Cu wt% alloy. By utilizing a variety of experimental techniques the alloy was characterized. The alloy has a melting temperature of 217 {degrees}C and exhibits eutectic melting behavior. The solder was examined by subjecting to different <b>annealing</b> <b>schedules</b> and examining the microstructural stability. The effect of cooling rate on the microstructure of the solder was also examined. Overall, this solder alloy shows great promise as a viable alternative to Pb-bearing solders and, as such, an application for a patent has been filed...|$|R
40|$|The {{simulated}} annealing (SA) algorithm [14] [5] {{has been applied}} to every difficult optimization problem in VLSI CAD. Existing SA implementations use monotone decreasing, or cooling, temperature schedules motivated by the algorithm's proof of optimality as well as by an analogy with statistical thermodynamics. This paper gives strong evidence that challenges the correctness of using such schedules. Specifically, the theoretical framework under which monotone cooling schedules is proved optimal fails to capture the practical application of {{simulated annealing}}; in practice, the algorithm runs for a finite rather than infinite amount of time; and the algorithm returns the best solution visited during the entire run ("best-so-far") rather than the last solution visited ("where-you-are"). For small instances of classic VLSI CAD problems, we determine <b>annealing</b> <b>schedules</b> that are optimal in terms of the expected quality of the best-so-far solution. These optimal schedules do not decrease mo [...] ...|$|R
40|$|We {{propose a}} {{checking}} parameter utilizing {{the breaking of}} the Jarzynski equality in the simulated annealing method using the Monte Carlo method. This parameter is based on the Jarzynski equality. By using this parameter, to detect that the system is in global minima of the free energy under gradual temperature reduction is possible. Thus, by using this parameter, one is able to investigate the efficiency of <b>annealing</b> <b>schedules.</b> We apply this parameter to the +-J Ising spin glass model. The application to the Gaussian Ising spin glass model is also mentioned. We discuss that {{the breaking of the}} Jarzynski equality is induced by the system being trapped in local minima of the free energy. By performing Monte Carlo simulations of the +-J Ising spin glass model and a glassy spin model proposed by Newman and Moore, we show the efficiency of the use of this parameter. Comment: 14 pages, 2 figures. v 6 : this is the final versio...|$|R
