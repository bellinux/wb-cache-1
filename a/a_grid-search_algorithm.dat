8|86|Public
30|$|We used NonLinLoc {{software}} (Lomax et al. 2000) {{based on}} <b>a</b> <b>grid-search</b> <b>algorithm</b> for hypocenter determination with a three-dimensional model. The grid node spacing of the velocity model {{was assumed to}} be 1  km. We introduced site correction values calculated from average O–C times {{in the same manner as}} that used for hypocenter determination with the one-dimensional velocity model.|$|E
30|$|We used NonLinLoc {{software}} (Lomax et al. 2000), {{which is}} based on <b>a</b> <b>grid-search</b> <b>algorithm,</b> to determine locations and origin times of the earthquakes using the arrival data of the P- and S- waves. The spacing of the grid nodes in the velocity model was assumed to be 1  km. Figure  2 b shows the 1288 earthquakes relocated with an error of less than 2  km in the horizontal direction and less than 3  km along the depth direction. The RMS values of the travel time residuals for the P-wave and S-wave arrival times are 0.43 and 0.90  s, respectively.|$|E
40|$|International audienceCharacter {{recognition}} {{plays an}} important role in the modern world. In recent years, character recognition systems for different languages has gain importance. The recognition of Arabic writing is still an important challenge due to its cursive nature and great topological variability. The Artificial Immune System is a supervised learning technique that embodies the concepts of natural immunity to cope with complex classification problems. The objective of this research is to investigate the applicability of an Artificial Immune System in Offline Isolated Handwritten Arabic Characters. The developed system is composed of three main modules: preprocessing, feature extraction and recognition. The system was trained and tested with ten-fold cross-validation technique on an original realistic database that we built from the well-known IFN/ENIT benchmark. Parameter tuning was performed with <b>a</b> <b>grid-search</b> <b>algorithm</b> with leave-one-out cross-validation. The obtained results of the proposed system are promising with a classification rate of 93. 25 % and often outperform most well-known classifiers from Scikit Learn Library...|$|E
40|$|Abstract Based on {{waveform}} {{data from}} a profile of aftershocks following the north-south trace of the 28 June 1992 Landers rupture across the Mojave desert, we construct a new velocity model for the Mojave region that features athin, slow crust. Using this model, we obtain source parameters, including depth and duration, {{for each of the}} aftershocks in the profile and, in addition, any significant (M> 3. 7) Joshua Tree-Landers aftershock between April 1992 and October 1994 for which coherent TERRAscope data were available. In all, we determine source parameters and stress drops for 45 significant (M w> 4) earthquakes a sociated with the Joshua Tree and Landers sequences, using <b>a</b> waveform <b>grid-search</b> <b>algorithm.</b> Stress drops for these earthquakes appear to vary systematically with location, with respect o previous seismic activity, proximity to previous rupture (i. e., with respect o the Landers rupture), and with tectonic province. In general, for areas north of the Pinto Mountain fault, stress drops of aftershocks located off the faults involved with the Landers rupture are higher than those located on the fault, with the exception of aftershocks on the newly recognized Kickapoo (Landers) fault. Stress drops are mod-erate south of the Pinto Mountain fault, where there is a history of seismic swarms but no single throughgoing fault. In contrast to aftershocks in the eastern Transverse ranges, and related to the 1992 Big Bear, California, sequence, Landers events how no clear relationship between stress drop and depth. Instead, higher stress-drop af-tershocks appear to correlate with activity on nascent faults or those that experienced relatively small slip during mainshock rupture...|$|R
40|$|Abstract: We have {{developed}} a simple docking procedure that is able to utilize low-resolution models of proteins created by structure prediction algorithms such as threading or ab initio folding to predict the conformation of receptor–small ligand complexes. In our approach, using only approximate, discretized models of both molecules, we search for the steric and quasi-chemical complementarity between a ligand and the receptor molecules. This averaging procedure allows for the compensation of numerous structural inaccuracies resulting from the theoretical predictions of the receptor structure. The best relative orientation of these two models is obtained by an exhaustive scan over the rigid body’s six-dimensional translational and rotational degrees of freedom. The search method is based on <b>a</b> real space <b>grid-searching</b> <b>algorithm,</b> unlike docking methods based on the fast Fourier Transform algorithm. We have applied this algorithm to rebuild structures of several complexes available in the Protein Data Bank. The structures of the receptors are produced by means of our threading algorithm PROSPECTOR, subsequently refined, and then utilized in the docking experiment. In many cases, {{not only is the}} localization of the binding site on the receptor surface correctly identified, but the proper orientation of the bounded ligand is also reasonably well reproduced within the level of accuracy of the modeled receptor itself...|$|R
3000|$|... [...]. Numerical {{values of}} this bound shown in Section 6 have been {{obtained}} by performing <b>a</b> <b>grid-search</b> over the (ρ,θ [...]...|$|R
40|$|Abstract. Source {{parameters}} {{determined from}} interferometric {{synthetic aperture radar}} (InSAR) measurements and from seismic data are compared from four moderate size (less than M 6) earthquakes in southern California. The purpose is to verify approximate detection capabilities of InSAR, assess differences in the results, and to test how the two results can be reconciled. First, we calculate the expected surface deformation from all earthquakes greater than magnitude 4 in areas with available InSAR data. A search for deformation from {{the events in the}} interferograms yielded 4 possible events with magnitudes less than 6. The search for deformation was based on a visual inspection as well as cross-correlation in 2 -D between the measured signal and the expected signal. <b>A</b> <b>grid-search</b> <b>algorithm</b> was then used to estimate focal mechanism and depth from the InSAR data. The results were compared with locations and focal mechanisms from published catalogs. An independent relocation using seismic data was also performed. For the three events that show clear surface deformation, the radar data was unable to improve the epicentral (latitude and longitude) location as the seismic locations fell within the expected rupture zone. However, the InSAR data provides tighter control o...|$|E
40|$|In this paper, we {{introduce}} a new method for estimating the source parameters of moderate earthquakes (M_w ~ 5. 0) by modeling short-period teleseismic waveforms. This method uses <b>a</b> <b>grid-search</b> <b>algorithm</b> to minimize misfits between observed data and synthetic seismograms in depth, magnitude, and mechanism domain in a relative high-frequency range of 0. 8 – 2. 0 Hz, similar to the traditional cut-and-paste method used in regional modeling (Zhu and Helmberger, Bull Sesimol Soc Am 86 : 1634 – 1641, 1996). In this frequency range, a significant challenge is determining the initial P-wave polarity because of a low signal-to-noise ratio (SNR). Therefore we first determine source properties for a master earthquake with a relative strong SNR. Both the travel time and amplitude corrections are developed relative to the reference 1 D model along each path used in inverting the master event. We then applied these corrections to other earthquakes clustered {{in the same area}} to constrain the initial P polarities. Thus the focal mechanisms can be determined reasonably well. We inverted focal mechanisms for a small set of events beneath Qeshm Island in southern Iran and demonstrate the importance of radiation pattern at short periods...|$|E
40|$|On 22 October 1916, a {{moderate}} earthquake {{occurred in the}} vicinity of Tejon Pass and was felt over much of southern California. An intriguing aspect of this event involves reports of ground cracks that formed during the earthquake. We evaluate the reports of ground cracking and attempt to precisely locate the cracks with respect to active faults; we infer that the earthquake produced minor fault rupture along a newly discovered trace of the easternmost Lockwood Valley fault (formerly mapped as the easternmost Big Pine fault) and/or along the San Andreas fault. We also re-evaluate and present new intensity data, and we use <b>a</b> <b>grid-search</b> <b>algorithm</b> (derived from empirical analysis of modern earthquakes) to find the magnitude most consistent with the reported intensities. Although previous authors have attempted to use intensity data to constrain the magnitude of this event, the algorithm we use provides an alternative and statistically more robust determination of the magnitude. Our results suggest M 5. 6 (- 0. 3 /+ 0. 2) (at 95 % confidence) for the 1916 event, which is consistent with earlier work. The 1916 earthquake {{appears to have been a}} rare and remarkable event in terms of its size and location and the production of minor surface rupture...|$|E
40|$|Abstract. The {{algorithm}} in {{this paper}} {{is based on the}} basic principle of SVM. The sale data classification SVM classifier is designed using this algorithm. Also three classifiers including traditional grid search algorithm, ZGenetic Algorithm and Particle Swarm Optimization are used to do the comparison experiments of classification. Result shows that the improved <b>grid-search</b> <b>algorithm</b> can reduce the SVM classifier’s computational complexity effectively and improve its performance and classification accuracy...|$|R
40|$|We {{show that}} any convex region which {{contains}} a unit segment, an equilateral triangle of sides 1 / 2, and {{a square of}} side 1 / 3 always has area at least 0. 227498. Using <b>grid-search</b> <b>algorithm,</b> we attempt to find a configuration of these three objects with minimal convex hull area. Consequently, we improve a lower bound for Moser's worm problem from 0. 2194 to 0. 227498. Comment: 12 pages, 9 figures. v 2 : reorganized proof of the main theorem, added results and reference...|$|R
30|$|In this study, we {{assessed}} the {{spatial and temporal}} characteristics of process noise values for unknown tropospheric parameters in kinematic analysis of GNSS data from the GEONET network, Japan. We used <b>a</b> <b>grid-search</b> approach to extract optimum process noise values for each site on 3  days during 2011.|$|R
40|$|In general, {{the depths}} of shallow {{earthquakes}} are poorly resolved in current catalogues. Variations in depth of ± 10 km can significantly alter the tectonic interpretation of such earthquakes. If the depth of a seismic event is in error then moment tensor estimates can also be significantly altered. In the context of nuclear-test-ban monitoring, a seismic event whose depth can be confidently shown to exceed say, 10 km, {{is unlikely to be}} an explosion. Surface wave excitation is sensitive to source depth, especially at intermediate and short periods, owing to the approximate exponential decay of surface wave displacements with depth. The radiation pattern and amplitude of surface waves are controlled by the depth variations in the six components of the strain tensor associated with the surface wave eigenfunctions. The potential exists, therefore, for improvements to be made to depth and moment tensor estimates by analysing surface wave amplitudes and radiation patterns. A new method is developed to better constrain seismic source parameters by analysing 100 - 20 s period amplitude spectra of fundamental-mode surface waves. Synthetic amplitude spectra are generated for all double-couple sources over a suitable depth range and compared with data in <b>a</b> <b>grid-search</b> <b>algorithm.</b> Best fitting source parameters are calculated and appropriate bounds are placed on these results. This approach is tested and validated using a representative set of globally-distributed events. Source parameters are determined for 14 moderately-sized earthquakes (5. 4 ≤ M w ≤ 6. 5), occurring in a variety of tectonic regimes with depths calculated between 4 - 39 km. For very shallow earthquakes the use of surface wave recordings as short as 15 s is shown to improve estimates of source parameters, especially depth. Analysis of aftershocks (4. 8 ≤ M w ≤ 6. 0) of the 2004 great Sumatra earthquake is performed to study the depth distribution of seismicity in the region. Three distinct tectonic regimes are identified and depth estimates calculated between 3 - 61 km, including the identification of one CMT depth estimate to be in error by some 27 km. </p...|$|E
40|$|The San Andreas {{fault is}} the longest fault in California {{and one of the}} longest strike-slip faults in the world, yet {{little is known about the}} {{aftershocks}} following the most recent great event on the San Andreas, the M_W 7. 8 San Francisco earthquake on 18 April 1906. We conducted a study to locate and to estimate magnitudes for the largest aftershocks and triggered events of this earthquake. We examined existing catalogs and historical documents for the period April 1906 to December 1907, compiling data on the first 20 months of the aftershock sequence. We grouped felt reports temporally and assigned modified Mercalli intensities for the larger events based on the descriptions judged to be the most reliable. For onshore and near-shore events, <b>a</b> <b>grid-search</b> <b>algorithm</b> (derived from empirical analysis of modern earthquakes) was used to find the epicentral location and magnitude most consistent with the assigned intensities. For one event identified as far offshore, the event's intensity distribution was compared with those of modern events, in order to constrain the event's location and magnitude. The largest aftershock within the study period, an M ∼ 6. 7 event, occurred ∼ 100 km west of Eureka on 23 April 1906. Although not within our study period, another M ∼ 6. 7 aftershock occurred near Cape Mendocino on 28 October 1909. Other significant aftershocks included an M ∼ 5. 6 event near San Juan Bautista on 17 May 1906 and an M ∼ 6. 3 event near Shelter Cove on 11 August 1907. An M ∼ 4. 9 aftershock occurred on the creeping segment of the San Andreas fault (southeast of the mainshock rupture) on 6 July 1906. The 1906 San Francisco earthquake also triggered events in southern California (including separate events in or near the Imperial Valley, the Pomona Valley, and Santa Monica Bay), in western Nevada, in southern central Oregon, and in western Arizona, all within 2 days of the mainshock. Of these triggered events, the largest were an M ∼ 6. 1 earthquake near Brawley and an M ∼ 5. 0 event under or near Santa Monica Bay, 11. 3 and 31. 3 hr after the San Francisco mainshock, respectively. The western Arizona event is inferred to have been triggered dynamically. In general, the largest aftershocks occurred at the ends of the 1906 rupture or away from the rupture entirely; very few significant aftershocks occurred along the mainshock rupture itself. The total number of large aftershocks was less than predicted by a generic model based on typical California mainshock–aftershock statistics, and the 1906 sequence appears to have decayed more slowly than average California sequences. Similarities can be drawn between the 1906 aftershock sequence and that of the 1857 (M_W 7. 9) San Andreas fault earthquake...|$|E
3000|$|An {{alternative}} approach for estimating the DOAs relies on subspace-based methods like the [...] (MUltiple Signal Classication) [20] or ESPRIT algorithms [14]. In the following we discuss DOA estimation based on ESPRIT. The {{reason is that}} this method provides estimates in closed form while <b>a</b> <b>grid-search</b> is needed with MUSIC.|$|R
40|$|This paper {{presents}} {{a novel approach}} named extinction profiles to model the spatial information of remote sensing images. Then, {{the output of the}} extinction profile is fed to <b>a</b> <b>grid-search</b> random forest classification method. Results indicate that the proposed approach can effectively extract spatial information from remote sensing gray scale images and provide high classification accuracies in an automatic way...|$|R
40|$|We present seismic moment tensor {{solutions}} for 63 events at Uturuncu volcano, Bolivia. Moment tensor solutions were generated using body waves and surface waves. The best solution (M 0) was obtained through <b>a</b> <b>grid-search</b> in moment tensor space using the "cut-and-paste" (CAP) approach of Zhu and Helmberger (1996) and Zhu and Ben-Zion (2013). The files here {{are part of}} the PhD thesis work by Celso Alvizur...|$|R
40|$|We {{present moment}} tensor {{solutions}} for 15 earthquakes in the Minto Flats fault zone. Moment tensor solutions were generated using body waves and surface waves. The best solution was obtained through <b>a</b> <b>grid-search</b> in the double-couple moment tensor space using the "cut-and-paste" (CAP) approach of Zhu and Helmberger (1996). The files here {{are part of}} the PhD thesis work by Vipul Silwal. The materials were included as part of the supplement to Tape et al. (2015, BSSA) ...|$|R
40|$|Five {{families}} of three-dimensional doubly symmetric motions are computed after establishing their existence {{by means of}} <b>a</b> <b>grid-search</b> technique. It is confirmed that within the same family orbits of lower inclination {{with respect to the}} plane of motion of the primaries are stable while the critical inclination at which instability occurs varies between families. The maximum inclination at which stable motions of the type presented here were found is about 52 °. © 1976 D. Reidel Publishing Company...|$|R
40|$|This paper uses a {{threshold}} model {{to examine a}} possible threshold effect in the impact of exchange rate volatility on trade volume for the bilateral trade volumes between the US and other G- 7 countries. <b>A</b> <b>grid-searching</b> method is used to obtain the threshold points, and time-series econometric techniques are applied to estimate the long run stable relationships as well as short-run dynamics. The results support the existence of nonlinearity in the effect of exchange rate volatility, and indicate that trade volume tends to increase when exchange rate volatility surpasses a certain threshold point. Exchange rate volatility, trade, threshold,...|$|R
40|$|Using {{data from}} {{reorganization}} proposals filed by bankrupt Canadian firms, we estimate {{the discount rate}} implicit in the creditors’ reorganization decision. Using two approaches, <b>a</b> <b>grid-search</b> and <b>an</b> optimization <b>algorithm,</b> we estimate the implicit monthly discount rate in reorganization to be around 5 percent, which corresponds to In their recent work, Fisher and Martel (2004) depict the bankruptcy process, {{such as the one}} prevailing in the U. S. and Canada, as a multi-stage game. At stage one, the managers of a financially distressed firm decide between liquidation and reorganization. At stage two, if reorganization is chosen, th...|$|R
30|$|The {{performance}} of the SVM model is depended on the choice of kernel functions and their parameters especially the penalty factor C and γ terms. In this study, <b>a</b> <b>grid-search</b> method with 5 -folder cross-validation was used to locate the optimal values of C and γ [Hsu et al., 2003] as follows: (1) Set a pair of (C, γ) values for SVM model; (2) Randomly divided the training dataset into 5 equal sized subsets; (3) Use Four subsets of them to train the SVM model; (4) Validate the trained model using the one remaining subset; (5) Repeat step three and four for five times {{for each of the}} subset; (6) Calculate the overall accuracy defined as the percentage of data which are correctly predicted.|$|R
40|$|Hydraulic rescue {{spreaders}} {{are used}} by emergency response personnel to extricate occupants from a vehicle crash. A lighter and more portable rescue spreader is required for better usability and to enable utilization {{in a variety of}} scenarios. To meet this requirement, topological synthesis, dimensional synthesis, and an optimization were used to develop a solution linkage. The topological synthesis technique demonstrates that ten links are the minimum possible number that achieves the desired motion without depending primarily on rotation of the spreader jaws. A novel integrated kinematic-structural dimensional synthesis technique is presented and used in <b>a</b> <b>grid-search</b> optimizing the linkage dimensions to minimize linkage mass. The resulting ten-bar linkage meets or exceeds the kinematic performance parameters while simultaneously achieving a near-optimum predicted mass...|$|R
40|$|The files {{here are}} part of the PhD thesis work by Vipul Silwal. This {{supplement}} will be cited in a manuscript to be submitted. A seismic moment tensor catalog of 106 events was generated using body waves and surface waves. The best solution (M 0) was obtained through <b>a</b> <b>grid-search</b> in the double-couple moment tensor space (M) using the "cut-and-paste" (CAP) approach of Zhu and Helmberger (1996). The waveform fits for the 21 events in the Part I catalog is shown in Figure A, with the best-fitting depth plots in Figure B. The uncertainty analysis for these Part I events is shown in Figure C. The waveform fits for the other 85 events (Part II) is shown in Figure D; for these events the best depth search and uncertainty analysis was not performed...|$|R
40|$|Bankruptcy {{prediction}} {{has drawn}} {{a lot of}} research interests in previous literature, and recent studies have shown that machine learning techniques achieved better performance than traditional statistical ones. This paper applies support vector machines (SVMs) to the bankruptcy prediction problem in an attempt to suggest a new model with better explanatory power and stability. To serve this purpose, we use <b>a</b> <b>grid-search</b> technique using 5 -fold cross-validation to find out the optimal parameter values of kernel function of SVM. In addition, to evaluate the prediction accuracy of SVM, we compare its performance with those of multiple discriminant analysis (MDA), logistic regression analysis (Logit), and three-layer fully connected back-propagation neural networks (BPNs). The experiment results show that SVM outperforms the other methods. q 2005 Published by Elsevier Ltd. Keywords: Bankruptcy prediction; Support vector machine; Grid-search; Kernel function; Back-propagation neural network...|$|R
40|$|This paper {{studies the}} finite sample {{properties}} of the kernel regression method of Boudoukh, Richardson, Stanton and Whitelaw (1998) for estimating multifactor continuous [...] time term structure models. Monte Carlo simulations are employed, with <b>a</b> <b>grid-search</b> technique to find the optimal kernel bandwidth. The performance of the estimator is also studied under model misspecification. Irrelevant regressors reduce e#ciency and induce additional biases in the estimates. Using Treasury bill data, I test whether the estimates produced by the nonparametric estimator are statistically distinguishable from estimates obtained under a parametric model. The kernel regressions pick up nonlinearities that the parametric model cannot capture. 2 In a series of recent papers, researchers in finance have developed nonparametric methods for estimating the drift and di#usion functions of continuous time stochastic processes. Stanton (1997) pioneered a method based on the theory of weak approxima [...] ...|$|R
40|$|Abstract — A key step in many {{statistical}} learning {{methods used}} in machine learning involves solving a convex optimization problem containing {{one or more}} hyper-parameters that must be selected by the users. While cross validation is a commonly employed and widely accepted method for selecting these parameters, its implementation by <b>a</b> <b>grid-search</b> procedure in the parameter space effectively limits the desirable number of hyper-parameters in a model, due to the combinatorial explosion of grid points in high dimensions. This paper proposes a novel bilevel optimization approach to cross validation that provides a systematic search of the hyper-parameters. The bilevel approach {{enables the use of}} the state-of-the-art optimization methods and their well-supported softwares. After introducing the bilevel programming approach, we discuss computational methods for solving a bilevel cross-validation program, and present numerical results to substantiate the viability of this novel approach as a promising computational tool for model selection in machine learning...|$|R
40|$|Dropout {{is used as}} a {{practical}} tool to obtain uncertainty estimates in large vision models and reinforcement learning (RL) tasks. But to obtain well-calibrated uncertainty estimates, <b>a</b> <b>grid-search</b> over the dropout probabilities is necessary - a prohibitive operation with large models, and an impossible one with RL. We propose a new dropout variant which gives improved performance and better calibrated uncertainties. Relying on recent developments in Bayesian deep learning, we use a continuous relaxation of dropout's discrete masks. Together with a principled optimisation objective, this allows for automatic tuning of the dropout probability in large models, and as a result faster experimentation cycles. In RL this allows the agent to adapt its uncertainty dynamically as more data is observed. We analyse the proposed variant extensively on a range of tasks, and give insights into common practice in the field where larger dropout probabilities are often used in deeper model layers...|$|R
40|$|This paper {{deals with}} the {{simultaneous}} optimization of prices and shipment quantities in a supply network when the supplier has the market power to set prices, thereby influencing demand directly. We focus on the distribution stage of the supply chain where the firm’s products are shipped from several locations (plants, warehouses) to various independent markets, and address the following questions: (i) {{what is the best}} price at each market?, and (ii) what is the best distribution plan given these prices? The combined problem can be modeled as a nonlinear optimization problem. For its solution, we propose an iterative linear programming approach that utilizes shadow price information from a series of successive transportation problems. To evaluate the heuristic’s effectiveness, we compare it with a “brute-force ” enumeration using <b>a</b> <b>grid-search.</b> The grid-search is implemented on a spreadsheet with a programming loop to facilitate repeated invocation of the transportation problem solver routine...|$|R
40|$|This paper {{studies the}} finite sample {{properties}} of the kernel regression method of Boudoukh et al. (1998) for estimating multifactor continuous-time term structure models. Monte Carlo simulations are employed, with <b>a</b> <b>grid-search</b> technique to find the optimal kernel bandwidth. The estimator exhibits truncation and correlated residuals biases near {{the boundaries of the}} data. However, the variance of the estimator is so high that the biases are unlikely to be relevant from a hypothesis testing point of view. The performance of the estimator is also studied under model misspecification. Irrelevant regressors reduce efficiency and induce additional biases in the estimates. Using Treasury bill data, I test whether the estimates produced by the nonparametric estimator are statistically distinguishable from estimates obtained under a parametric model. The kernel regressions pick up nonlinearities in the data that the parametric model cannot capture. Interest rates; Econometric models; Time-series analysis...|$|R
40|$|A new machine {{learning}} method {{referred to as}} F-score_ELM was proposed to classify the lying and truth-telling using the electroencephalogram (EEG) signals from 28 guilty and innocent subjects. Thirty-one features were extracted from the probe responses from these subjects. Then, a recently-developed classifier called extreme learning machine (ELM) was combined with F-score, a simple but effective feature selection method, to jointly optimize {{the number of the}} hidden nodes of ELM and the feature subset by <b>a</b> <b>grid-searching</b> training procedure. The method was compared to two classification models combining principal component analysis with back-propagation network and support vector machine classifiers. We thoroughly assessed the performance of these classification models including the training and testing time, sensitivity and specificity from the training and testing sets, as well as network size. The experimental results showed that the number of the hidden nodes can be effectively optimized by the proposed method. Also, F-score_ELM obtained the best classification accuracy and required the shortest training and testing time...|$|R
30|$|In our experiments, {{we choose}} ten {{representative}} unsupervised feature selection algorithms as the comparison approaches. The ten comparison approaches include LS [11], MCFS [8], SPEC [12], UDSFS [13], RUFS [16], RSR [18], SPNFSR [20], JGSC [21], NSSRD [23], and MFFS [27]. Meanwhile, several details for the experiment parameter setting are as follows. For LS, MCFS, SPEC, UDSFS, SPNFSR, JGSC, NSSRD, and our approach, we fix {{the number of}} neighborhoods to 5 on all the databases. For UDSFS, RUFS, RSR, SPNFSR, JGSC, and NSSRD, the sparsity parameters will be tuned by <b>a</b> <b>grid-search</b> strategy from{ 10 − 3,[*] 10 − 2,[*] 10 − 1,[*] 100,[*] 101,[*] 102,[*] 103 }. Following [27], we fix {{the value of the}} parameter in MFFS to 108. For DRMFFS, we exploit the parameters α and β in the range of { 0, [*][*] 100,[*] 101,[*] 102,[*] 103,[*] 104,[*] 105 } on all the databases. We will report the best results obtained from the optimal parameters for all the approaches.|$|R
40|$|A station (FAGN) {{installed}} on {{a segment of}} the fault system that generated the April 2009 L’Aquila earthquakes shows larger ground motions compared to nearby stations. Spectral ratios using 304 earthquakes result in a station amplification significantly varying event by event in the frequency band 1 – 8 Hz. The resulting pattern of amplitude dependence on causative earthquake location reveals that the strongest (up to a factor of 10) amplifications occur for tightly clustered aftershocks aligned with the fault dip beneath FAGN thus indicating a fault‐guided effect. Fault models are investigated in <b>a</b> <b>grid‐search</b> approach by varying velocity, Q, width and depth of the fault zone. Although the problem solution is not unique and there are strong trade‐offs among the model parameters, constraints from observations yield a deep trapping structure model where the most likely values of velocity reduction, Q and damage zone width are 25 %, 20, and 280 m, respectively...|$|R
40|$|Multi-step ahead {{forecasting}} is {{an important}} issue for organizations, often used to assist in tactical decisions. Such forecasting can be achieved by adopting time series forecasting methods, such as the classical Holt-Winters (HW) that is quite popular for seasonal series. An alternative forecasting approach comes from the use of more flexible learning algorithms, such as Neural Networks (NN) and Support Vector Machines (SVM). This paper presents a simultaneous variable (i. e. time lag) and model selection algorithm for multi-step ahead forecasting using NN and SVM. Variable selection is based on a backward algorithm that is guided by a sensitivity analysis procedure, while model selection is achieved using <b>a</b> <b>grid-search.</b> Several experiments were devised by considering eight seasonal series and the forecasts were analyzed using two error criteria (i. e. SMAPE and MSE). Overall, competitive results were achieved when comparing the SVM and NN algorithms with HW. Fundação para a Ciência e Tecnologia (FCT) - Project PTDC/EIA/ 64541 / 2006...|$|R
40|$|A local {{magnitude}} {{scale has}} been defined for southern Italy, in the area monitored by the recently installed Irpinia Seismic Network. Waveforms recorded from more than 100 events of small magnitude are processed to extract synthetic Wood– Anderson traces. Assuming a general description of peak-displacement scaling with the distance, by means of linear and logarithmic contributions, a global exploration of the parameter space is performed by <b>a</b> <b>grid-search</b> method {{with the aim of}} investigating the correlation between the two decay contributions and seeking for a physical solution of the problem. Assuming an L 2 norm, we found M log A 1 : 79 log R 0 : 58; yielding an error on the single estimation smaller than 0. 2, at least when the hypocenter location is accurate. Station corrections are investigated through the station residuals, referring to the average value of the magnitude. Using a z test, we found that some stations exhibit a correction term significantly different from 0. The use of the peak acceleration and peak velocity as indicators of the magnitude is also investigated...|$|R
40|$|The focal {{mechanisms}} of Mw 6. 3 aftershocks, Chiang Rai Province, Northern Thailand, {{were determined by}} using a multistation waveform inversion. Three aftershocks were selected and their waveforms were inverted for moment tensor calculation. Waveform inversions were derived from three broadband stations with three components and epicentral distances less than 250 [*]km after all seismic stations were considered. The deviatoric moment tensor inversion was used for focal mechanism calculations. Band-pass filtering {{in the range of}} 0. 03 – 0. 15 [*]Hz was selected for reducing low- and high-frequency noise. Source positions were created by using a single-source inversion and <b>a</b> <b>grid-search</b> method computed to optimize the waveform match. The results showed stable moment tensors and fault geometries with the southwest azimuth {{in the northern part of}} the Payao Fault Zone (PFZ) with depths shallower than 10 [*]km. Left-lateral strike-slip with a reverse component was detected. The tectonics of the PFZ is constrained by fault-plane solutions of earthquakes. WSW directional strikes are observed in the northern part of the PFZ...|$|R
