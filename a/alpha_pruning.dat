0|10|Public
5000|$|... #Subtitle level 2: Negamax with <b>alpha</b> beta <b>pruning</b> and {{transposition}} tables ...|$|R
50|$|Ataxx Arcade is an iPhone {{version that}} {{attempts}} to recreate some of {{the atmosphere of the}} original arcade game. It has 5 opponents: Colony, Droolman, Mushman, Medusa, and Cephalo; and 40 levels in its current version. The AI uses a min/max <b>alpha</b> beta <b>pruning</b> strategy, with Medusa employing a 1-ply search and Cephalo employing a 2-ply search, which most players find difficult to beat.|$|R
40|$|Abstract- Traditionally chess gaming {{software}} takes {{considerable amount}} of time in calculating the optimal move that can be made by a computer system. Most computer systems that make such calculations use some version of the minimax search with <b>alpha</b> beta <b>pruning.</b> Minimax with <b>alpha</b> beta <b>pruning</b> can be made distributed with principal variation splitting. The system can thus be used to reduce the time necessary to calculate the optimal move. Additionally, to select the distributed node containing less workload from the grid, a dynamic CPU availability prediction can be deployed to enhance the performance of task (searching game tree to find the optimal move) execution. An algorithm for dynamic monitoring of CPU has been proposed and discussed in this paper besides PV-Splitting minimum and maximum algorithms. Prediction of CPU availability is important in the context of making task assignment and scheduling decisions. Extensive experimental studies and statistical analysis are performed to evaluate the performance improvement of the model using the chess software system which uses the PV-Splitting for task parallelism...|$|R
40|$|Chess {{is one of}} the world’s most {{widespread}} games. We {{propose the}} novel concept of ‘group chess’, with the objective of using information technology as an educational aid for novice chess players, as well as for experienced players to play as groups. In the proposed game, up to thirty players can play chess in two groups. The player who makes the best move at each turn is awarded with marks. Finally the player with the highest marks wins. Artificial intelligence and networking technologies are used in the system. The <b>Alpha</b> Beta <b>pruning</b> algorithm is used to find the best movement out of a set of given inputs. This is a new adaptation of the <b>Alpha</b> Beta <b>pruning</b> which is normally used to find the best possible move. We propose this game for chess learners as well as a novel approach to the game for experienced players. The concept of 'group chess' will direct future development of the game of chess towards a new variant. The game has been named Sanuthi Prayathna...|$|R
50|$|This {{implementation}} {{also shows}} optional move ordering {{prior to the}} foreach loop that evaluates child nodes. Move ordering is an optimization for <b>alpha</b> beta <b>pruning</b> that attempts to guess the most probable child nodes that yield the node's score. The algorithm searches those child nodes first. The result of good guesses is earlier and more frequent alpha/beta cut offs occur, thereby pruning additional game tree branches and remaining child nodes from the search tree.|$|R
40|$|Abstract. We define Realtime Online solving of Quantified Constraint Satisfaction Problems (QCSPs) as a {{model for}} realtime online CSP solving. We use a {{combination}} of propagation, lookahead and heuristics and show how all three improve performance. For adversarial opponents we show that we can achieve promising results through good lookahead and heuristics and that a version of <b>alpha</b> beta <b>pruning</b> performs strongly. For random opponents, we show that we can frequently achieve solutions even on problems which lack a winning strategy and that we can improve our success rate by using Existential Quantified Generalised Arc Consistency, a lower level of consistency than SQGAC, to maximise pruning without removing solutions. We also consider the power of the universal opponent and show that through good heuristic selection we can generate a significantly stronger player than a static heuristic provides. ...|$|R
40|$|In {{this thesis}} I focused myself on problematics of solving {{life and death}} {{problems}} {{in the game of}} Go, which is one of fundamental skills of a Go playing program. Together with thesis, life and death solving program TGA was created. Program is built upon basic space search algorithms from the game theory (e. g. <b>alpha</b> beta <b>pruning,</b> transposition tables) in combination with methods using knowledges about the game of Go (heuristics and pruning methods). For program purposes I created "block oriented" position representation, I implemented simpliffied static analysis of life and death of the group and I proposed a set of heuristic. These heuristics not only speed up search signifficantly, moreover they make it possible to solve di±cult problems of "under the stones" type. Program is designed to solve mostly enclosed problems and it is capable to treat di®erent life and death solving pecularities (e. g. different types of ko, seki, "bent four in the corner"). As for performance, I estimate program's strength in solving speciffied Go problems to be 1 dan. This is comparable with a strong human player...|$|R
40|$|This report {{describes}} Caesar- a table based {{program to}} play {{a modified version of}} Othello. Caesar was developed as a project for the course CS 221 at Stanford University and was the winner in a tournament among 56 programs developed by students taking the course. Caesar uses an efficient board representation scheme that allows it to perform all tasks including computing legal moves and the computation of features by just table lookups. The tables have been generated offline. For building and searching the game tree, Caesar uses mini-max search with <b>alpha</b> beta <b>pruning,</b> iterative deepening, a simple move ordering scheme that exploits iterative deepening, an advanced time management strategy that helps in tournament play and a complete end game search of 17 plies. Caesar uses a linear evaluation function combining 4 features- edge stability, difference in mobility, difference in potential mobility and piece difference. A self-devised modification of the application of TDλ (called Bootstrapped TDλ) was used to train Caesar. Some experiments that might help in building a stronger program are also presented...|$|R
40|$|<b>Alpha</b> Beta <b>Pruning</b> is an {{algorithm}} {{to prune}} unnecessary branches. The idea of not exploring the branches {{if we know}} that it is worthless makes it a powerful algorithm ever invented. The algorithm is useful in some of the game search available today. Meanwhile, the ability of greedy algorithm to solve problem by choosing any alternatives that leads to the optimal solution without having care of what will happen after that as long as it achieves its goal makes it suitable in any game it applies. Some of the games are checkers. Checkers uses game search to find the solution to win the game. There are many available locations that the pieces can move in the board. It makes it difficult for the player to determine the next move that it should go to win the game. This game will be used to compare both algorithm based on time and the number of moves it takes to win the game. By applying both algorithms, we can determine which algorithm is the most powerful algorithm to generate the winning strategies in the game of checkers. The result will also show how the algorithms generate the winning solution...|$|R
40|$|Project (M. S., Computer Science) [...] California State University, Sacramento, 2013. Games are an {{interesting}} field of study in field of artificial intelligence. Minimax search is a game theory applied to game playing and it {{has proved to be}} successful for many games but not all. One of them is the Game of Go. Go is an ancient Chinese Game usually played on 19 x 19 board. It is a 2 -player game where the objective is to capture the opponent???s stones and control as many territories as possible to win the game. Go has its own set of challenges that makes it difficult for Minimax to be efficient. Some of the challenges of Computer Go involve huge branching factor and difficulty {{to come up with an}} optimal evaluation function for the leaf nodes. The objective of this project is to implement a system that combines the Selective Minimax search and the Neural Network to evolve the Computer Go player. The limitations of Minimax approach are addressed by using the concepts of Selective Minimax tree and <b>Alpha</b> Beta <b>Pruning.</b> Selective Minimax search provides focused search space and faster evaluation of the moves for the computer. The idea of Selective Minimax is to search and evaluate only those moves that look promising among the legal moves or empty intersections. The Neural Network is trained using supervised learning and Resilient Backpropagation is used for the learning process. The learning method of Resilient Backpropagation proves to be faster and more efficient than the standard Backpropagation for the game of Go. The trained Neural Network combined with an evaluation function is used to evaluate the leaf nodes of the Selective Minimax tree. For Minimax to suggest an optimal move for the computer, it would need to search at greater depths to look ahead which in result would be very costly. For Neural Network to suggest an optimal move, it would need many data and game records to recognize patterns from the board that might not be feasible. Using the hybrid method, the Neural Network helps Minimax to look ahead and the static evaluation function helps Neural Network to suggest a sensible move in case of unseen patterns. This hybrid method provides an advantage over Minimax search as the learning and the experience of Neural Network helps to look ahead without actually searching at greater depths and helps to avoid falling for local maxima. NNGo 9 x 9 uses the hybrid method of Neural Network and Selective Minimax and proves to be an effective player which minimizes the drawbacks of each method. Computer Scienc...|$|R

