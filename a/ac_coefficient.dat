24|234|Public
25|$|RUNLENGTH is {{the number}} of zeroes that came before this non-zero <b>AC</b> <b>coefficient.</b>|$|E
2500|$|The run-length {{encoding}} {{works by}} examining each non-zero <b>AC</b> <b>coefficient</b> [...] and determining how many zeroes {{came before the}} previous <b>AC</b> <b>coefficient.</b> [...] With this information, two symbols are created: ...|$|E
2500|$|This has the {{immediate}} implication of Symbol 1 being only able store {{information regarding the}} first 15 zeroes preceding the non-zero <b>AC</b> <b>coefficient.</b> [...] However, JPEG defines two special Huffman code words. [...] One is for ending the sequence prematurely when the remaining coefficients are zero (called [...] "End-of-Block" [...] or [...] "EOB"), and another when the run of zeroes goes beyond 15 before reaching a non-zero <b>AC</b> <b>coefficient.</b> [...] In such a case where 16 zeroes are encountered before a given non-zero <b>AC</b> <b>coefficient,</b> Symbol 1 is encoded [...] "specially" [...] as: (15, 0)(0).|$|E
40|$|In a {{television}} transmission system for digital picture signals each picture {{is divided into}} sub-pictures of N x N picture elements {{for the purpose of}} limiting the bit rate. Each sub-picture is subjected to a two-dimensional forward transform to determine coefficients. These coefficients are converted into a series of serially occurring coefficients in which the <b>AC</b> <b>coefficients</b> in this series are arranged {{in such a way that}} the magnitude variation of these <b>AC</b> <b>coefficients</b> in the series is monotonous. The magnitudes of the <b>AC</b> <b>coefficients</b> thus arranged are subjected to a differential encoding so that the difference between the magnitudes of two successive <b>AC</b> <b>coefficients</b> is transmitted instead of the magnitude of the <b>AC</b> <b>coefficients</b> themselves...|$|R
40|$|It is {{a common}} {{approach}} for JPEG and MPEG encryption systems to provide higher protection for dc coefficients and less protection for <b>ac</b> <b>coefficients.</b> Some authors have employed a cryptographic encryption algorithm for the dc coefficients and left the <b>ac</b> <b>coefficients</b> to techniques based on random permutation lists which {{are known to be}} weak against known-plaintext and chosen-ciphertext attacks. In this paper we show that in block-based DCT, it is possible to recover dc <b>coefficients</b> from <b>ac</b> <b>coefficients</b> with reasonable image quality and show the insecurity of image encryption methods which rely on the encryption of dc values using a cryptoalgorithm. The method proposed in this paper combines dc recovery from <b>ac</b> <b>coefficients</b> and the fact that <b>ac</b> <b>coefficients</b> can be recovered using a chosen ciphertext attack. We demonstrate that a method proposed by Tang to encrypt and decrypt MPEG video can be completely broken...|$|R
30|$|Cryptographic security: the <b>AC</b> <b>coefficients</b> zigzag scan used in I-frames {{encoding}} {{is replaced}} by a pseudorandom permutation. Statistics of the <b>AC</b> <b>coefficients</b> are preserved. Therefore, ciphertext-only, chosen, and known-plaintext attacks are feasible and allow recovering all <b>AC</b> <b>coefficients.</b> Qiao et al. [6] and Uehara and Safavi-Naini [7] propose cryptanalytic attacks (chosen-plaintext attacks) on this approach. The DC coefficient can be set to a fixed value while still having a comprehensible result, and then a chosen or known-plaintext attack can be conducted to reconstruct the <b>AC</b> <b>coefficients</b> and get a semantically good reconstruction [11]. Two conclusions can be made. First, energy concentration is not systematically a good criterion for selective encryption. Second, high-visual distortion does not mean high security level.|$|R
5000|$|The run-length {{encoding}} {{works by}} examining each non-zero <b>AC</b> <b>coefficient</b> [...] and determining how many zeroes {{came before the}} previous <b>AC</b> <b>coefficient.</b> With this information, two symbols are created: ...|$|E
5000|$|This has the {{immediate}} implication of Symbol 1 being only able store {{information regarding the}} first 15 zeroes preceding the non-zero <b>AC</b> <b>coefficient.</b> However, JPEG defines two special Huffman code words. One is for ending the sequence prematurely when the remaining coefficients are zero (called [...] "End-of-Block" [...] or [...] "EOB"), and another when the run of zeroes goes beyond 15 before reaching a non-zero <b>AC</b> <b>coefficient.</b> In such a case where 16 zeroes are encountered before a given non-zero <b>AC</b> <b>coefficient,</b> Symbol 1 is encoded [...] "specially" [...] as: (15, 0)(0).|$|E
5000|$|RUNLENGTH is {{the number}} of zeroes that came before this non-zero <b>AC</b> <b>coefficient.</b>|$|E
3000|$|... (2) Embedding {{capacity}} and distortion: The positions are chosen {{by considering the}} embedding {{capacity and}} the distortion. The embedding capacity is measured using the number of embeddable <b>AC</b> <b>coefficients.</b> The distortion is modeled using the number of shiftable <b>AC</b> <b>coefficients,</b> quantization table, and PSNR function.|$|R
3000|$|... {{neighborhood}} of blocks {{are used to}} estimate the <b>AC</b> <b>coefficients</b> for the center block. They did not consider variations in the image in <b>AC</b> <b>coefficients</b> estimation, but Veeraswamy and Kumar in [4] proposed a new method that considered the variation in the image and accordingly <b>AC</b> <b>coefficients</b> have been estimated with different equations. This method is better than Gonzales method in terms of reduced blocking artifacts and improved PSNR value. Based on these ideas, here, at first, a grayscale watermark image is created by applying DCT on each [...]...|$|R
30|$|Embeddable coefficients: <b>AC</b> <b>coefficients</b> valued either + 1 or − 1.|$|R
5000|$|JPEG XR's {{entropy coding}} phase is more {{adaptive}} and complex than JPEG's, involving a DC and <b>AC</b> <b>coefficient</b> prediction scheme, adaptive coefficient reordering (in contrast to JPEG's fixed zigzag ordering), and {{a form of}} adaptive Huffman coding for the coefficients themselves.|$|E
40|$|This study {{presents}} a robust and semi-blind watermarking by embedding information into low frequency AC coefficients of Discrete Cosine Transform (DCT). Since the imperceptibility {{is the most}} significant issue in watermarking, the DC value is maintained unchanged. The proposed methods utilize the DC values of the neighboring blocks to predict the AC coefficients of the center block. The low frequency AC coefficients are modified to carry watermark information. The Least Mean Squares (LMS) is employed to yield the intermediate filters, cooperating with the neighboring DC coefficients to precisely predict the original AC coefficients. Two watermarking methods, namely Watermark Embedding in the Predicted <b>AC</b> <b>Coefficient</b> (WEPAC) and Watermark Embedding in the Original <b>AC</b> <b>coefficient</b> (WEOAC), are presented in this study. Moreover, many attacks are addressed to show the robustness of the proposed methods. Key words: Discrete cosine transform, digital watermarking, least mean squares, watermark embedding in the predicted <b>ac</b> <b>coefficient,</b> watermark embedding in the original <b>ac</b> <b>coefficient.</b> I...|$|E
30|$|Estimate the {{parameters}} of the Laplacian and Cauchy distribution for each <b>AC</b> <b>coefficient</b> using (20) and (24), respectively.|$|E
5000|$|In JPEG, {{the image}} DC {{coefficients}} of the DCT blocks are predicted by applying DC prediction {{from the left}} neighbor transform block, and no other coeffients are predicted. In JPEG XR, 4 × 4 blocks are grouped into macroblocks of 16 × 16 samples, and the 16 DC coefficients from the 4 × 4 blocks of each macroblock are passed through another level of frequency transformation, leaving three types of coefficients to be entropy coded: the macroblock DC coefficients (called DC), macroblock-level <b>AC</b> <b>coefficients</b> (called [...] "lowpass"), and lower-level <b>AC</b> <b>coefficients</b> (called <b>AC).</b> Prediction of <b>coefficient</b> values across transform blocks {{is applied to the}} DC coefficients and to an additional row or column of <b>AC</b> <b>coefficients</b> as well.|$|R
30|$|Encrypting all stream headers and all DC {{and lower}} <b>AC</b> <b>coefficients</b> of intracoded blocks.|$|R
3000|$|DCT {{block of}} {{selected}} subimage. As result, the robustness of mohanty's method decreases because the <b>AC</b> <b>coefficients</b> of DCT block is not robust to many attacks such as Low Pass Filtering, Compression, Median Filtering. Therefore, the many of embedded <b>AC</b> <b>coefficients</b> of used watermark are degraded after such attacks. To solve this drawback, {{in the proposed}} method, the coefficients of [...]...|$|R
3000|$|... be {{a random}} {{variable}} representing an integer transform coefficient, {{which can be}} either uniform (for a DC coefficient) or Laplacian/Cauchy (for an <b>AC</b> <b>coefficient).</b>|$|E
30|$|Huang et al. [19] first {{proposed}} a block ordering {{based on the}} number of zero AC coefficients. The experimental results show that blocks with many zero AC coefficients will likely contain many − 1 or + 1 valued AC coefficients. Using this statistical feature, [19] proposed only embedding in + 1 and − 1 and set embedding order such that the blocks with more zero AC coefficients are embedded first. This strategy effectively reduced distortion. Additionally, the file size increase is also lessened. The modification of zero <b>AC</b> <b>coefficient</b> increases the file size. This is because whenever a zero <b>AC</b> <b>coefficient</b> is modified to non-zero, an extra symbol is needed to be coded. Therefore, their method leads to smaller distortion and smaller file size than the existing schemes, which embed in zero AC coefficients.|$|E
3000|$|... the {{embedded}} {{message is}} the same for all the three techniques but it differs among the images. The message length for a given image is set as a fixed percentage of the image nonzero AC DCT coefficients (bpac-bit per nonzero <b>AC</b> <b>coefficient).</b> The following [10] experiments are performed at 0.05, 0.1, 0.15, 0.2 [*]bpac; [...]...|$|E
30|$|Shiftable coefficients: <b>AC</b> <b>coefficients</b> {{which are}} greater than + 1 or less than − 1.|$|R
30|$|In the {{discrete}} cosine transform, {{the first}} coefficient {{is basically the}} average of all pixel values within a given block [17]. Therefore, for a precise inverse transforming result, the accurate DC coefficient is crucial. In {{order to make sure}} that the inverse transformation result is the product of vital block information, our proposed method does not apply hard thresholding on the DC coefficient. Instead, it only applies hard thresholding on <b>AC</b> <b>coefficients.</b> The <b>AC</b> <b>coefficients</b> carry various block frequency information [1, 7, 17]. This information varies from low-frequency to high-frequency information. Thresholding all <b>AC</b> <b>coefficients</b> in the same manner might lead to losing some significant information, while preserving some other insignificant information.|$|R
3000|$|DCT {{block of}} watermark. Then the {{estimation}} formulas {{are used to}} evaluate the <b>AC</b> <b>coefficients</b> of each [...]...|$|R
30|$|It {{has been}} shown in the {{previous}} studies that in the DCT transform domain of a natural image, while the DC coefficients can be approximated as the uniform distribution, the <b>AC</b> <b>coefficient</b> distribution can be modeled by a generalized Gaussian [35, 36] or Laplacian [37, 38] probability density function. Although the generalized Gaussian model gives the most accurate representation of the <b>AC</b> <b>coefficient</b> distribution, the Laplacian model is commonly employed due to it being more tractable both mathematically and computationally. Recently, Kamaci et al. [39] proposed to use the Cauchy model, which is shown as a better choice than the Laplacian model for estimating the actual probability distribution of AC coefficients in H. 264 /AVC. In this paper, both Laplacian and Cauchy models will be examined for the estimation of the reconstructed video. In what follows, we present a method to estimate the parameters of both distribution models by using the decoded values from the compressed videos.|$|E
3000|$|Based {{upon the}} above three steps, we can {{transform}} any encrypted color JPEG image into a feature vector with 12 [*]×[*](T[*]+[*] 1)[*]×[*](T[*]+[*] 1) dimensions. Here, T[*]=[*] 7 is recommended because the VLI code {{length of the}} <b>AC</b> <b>coefficient</b> is in general less than 7. A statistical result in 1000 JPEG images from Corel image database [22] shows that about 99.89  % of all elements of the matrix D [...]...|$|E
3000|$|Robustness" [...] to noise: a {{statistical}} analysis of a large set of images affected by color noise showed that some AC coefficients are more sensitive to noise than others. A constant weight has been assigned to each <b>AC</b> <b>coefficient</b> in dependence on {{its position in the}} block, in order to preserve the most robust coefficients (which carry suitable information) and discard the ones that, with high probability, are corrupted by noise.|$|E
30|$|The spatial {{homogeneity}} of a CU can be characterised by its energy {{distribution in the}} frequency domain. Therefore, we utilise the alternating current (<b>AC)</b> <b>coefficients</b> energy to evaluate the textural complexity of a LCU. For a homogeneous area of an image, the low-frequency components tend to contain {{the majority of the}} frequency domain energy, whereas for a region comprising rich detail, more DCT energy is distributed over other <b>AC</b> <b>coefficients.</b>|$|R
30|$|Recently, {{reversible}} {{data hiding}} (RDH) techniques for JPEG images {{have become more}} extensively used to combine image and authentication information conveniently into one file. Although embedding data in JPEG image degrades visual quality and increases file size, it is proven to be useful for data communication and image authentication. In this paper, a data hiding method in JPEG image using a new coefficient selection technique is proposed. The proposed scheme embeds data using the histogram shifting (HS) method. According {{to the number of}} zero <b>AC</b> <b>coefficients,</b> block ordering is used to embed data first in the blocks causing less distortion. In order to further reduce the distortion, positions of <b>AC</b> <b>coefficients</b> are selected carefully. Finally, <b>AC</b> <b>coefficients</b> valued + 1 and − 1 are used for embedding, and the remaining non-zero <b>AC</b> <b>coefficients</b> are shifted to the left or right directions according to their sign. Compared to the current state-of-the-art method, experimental results show that the proposed method has higher peak signal to noise ratio (PSNR) and smaller file size.|$|R
40|$|Abstract — In this work, an {{adaptive}} image compression {{algorithm is proposed}} based on the prediction of <b>AC</b> <b>coefficients</b> in Discrete Cosine Transform (DCT) block during reconstruction of image. In the prediction phase, DC values of the nearest neighbour DCT blocks is utilized to predict the <b>AC</b> <b>coefficients</b> of centre block. Surrounding DC values of a DCT blocks are adaptively weighed for <b>AC</b> <b>coefficients</b> prediction. Linear programming {{is used to calculate}} the weights with respect to the image content. Results show that this method is good in terms of good Peak Signal to Noise Ratio (PSNR) and less blocking artifacts. The proposed scheme has been demonstrated through several experiments including Lena. Reconstructed image is of good quality with same compression ratio compared to the existing technique in the literature. In addition, an image watermarking algorithm is proposed using DCT <b>AC</b> <b>coefficients</b> obtained. The performance of the proposed watermarking scheme is measured in terms of PSNR and Normalized Cross Correlation (NCC). Further, this algorithm is robust for various attacks including JPEG compression on watermarked image. Index Terms—Image compression, DCT, linear programming, watermarking...|$|R
40|$|We {{propose a}} {{selective}} encryption scheme for HEVC {{which allows for}} transparent encryption {{in a wide range}} of quantization parameters. Our approach focusses on the <b>AC</b> <b>coefficient</b> signs, since they can be altered directly in the bit stream without entropy reencoding. This allows for fast encryption and decryption while retaining full format-compliance and length-preservation. Furthermore, we show our approach’s applicability for a number of use cases by evaluating the quality degradation and robustness against attacks. Index Terms — HEVC, transparent, encryption, bit stream, coefficient, key spac...|$|E
30|$|As {{commonly}} known, a color JPEG {{image is}} composed of Y, U, and V components, {{each of which is}} partitioned into non-overlapped blocks sized 8 [*]×[*] 8. In each block, there are 64 DCT coefficients, namely, one DC and 63 AC coefficients. According to JPEG standard [19], DC and AC coefficients can be transformed into intermediate symbols by utilizing the one-dimensional predictor and the run length coding (RLC), respectively, and then are further Huffman-coded into binary sequences, each of which consists of two parts: the Huffman code and the VLI code. Obviously, the generation of the abovementioned binary sequences is conditioned by the Huffman and VLI code tables, which are beforehand stored in the JPEG file header. In general, the Huffman code of the DC coefficient only contains the information about the length of the VLI code. But the Huffman code for the <b>AC</b> <b>coefficient</b> also has other information about the number of consecutive zero AC coefficients before the next nonzero <b>AC</b> <b>coefficient</b> in the zigzag sequence. The final JPEG bit-stream will be formed by concatenating the JPEG file header and binary sequences of all DCT coefficients of all components. As a matter of fact, the JPEG bit-stream is also a binary sequence and thus converts into a JPEG file when writing to a file byte by byte.|$|E
3000|$|Considering an {{encrypted}} image, {{the server}} first parses its corresponding encrypted JPEG bit-stream to extract all Huffman codes for DCT coefficients of each component. The extraction operation, in this step, is readily accomplished because of file format compliance {{before and after}} encryption. Next, exploiting the Huffman tables obtained from the file header to decode Huffman codes, we can obtain the length of each VLI code next to the Huffman code. That is, any DC or nonzero <b>AC</b> <b>coefficient</b> can be represented as a nonnegative integer that {{is equal to the}} length of the corresponding VLI code. Meanwhile, the number of consecutive zero-valued AC coefficients between two adjacent nonzero AC coefficients can also be achieved during the Huffman decoding. Based on the above results, we can construct the three two-dimensional matrices, denoted by D [...]...|$|E
40|$|In this work, an {{adaptive}} image compression {{algorithm is proposed}} based on the prediction of <b>AC</b> <b>coefficients</b> in Discrete Cosine Transform (DCT) block during reconstruction of image. In the prediction phase, DC values of the nearest neighbour DCT blocks is utilized to predict the <b>AC</b> <b>coefficients</b> of centre block. Surrounding DC values of a DCT blocks are adaptively weighed for <b>AC</b> <b>coefficients</b> prediction. Linear programming {{is used to calculate}} the weights with respect to the image content. Results show that this method is good in terms of good Peak Signal to Noise Ratio (PSNR) and less blocking artifacts. The proposed scheme has been demonstrated through several experiments including Lena. Reconstructed image is of good quality with same compression ratio compared to the existing technique in the literature. In addition, an image watermarking algorithm is proposed using DCT <b>AC</b> <b>coefficients</b> obtained. The performance of the proposed watermarking scheme is measured in terms of PSNR and Normalized Cross Correlation (NCC). Further, this algorithm is robust for various attacks including JPEG compression on watermarked image. </p...|$|R
3000|$|Count {{the total}} number of embeddable, shiftable, and {{unchangeable}} <b>AC</b> <b>coefficients</b> for each of the 63 possible positions [...]...|$|R
2500|$|... encoded {{rather than}} the actual value. The {{encoding}} of the 63 quantized <b>AC</b> <b>coefficients</b> does not use such prediction differencing.|$|R
