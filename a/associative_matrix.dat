11|16|Public
50|$|This {{article will}} focus on the Combs method itself. To learn more about the way rules are {{traditionally}} formed, see fuzzy logic and fuzzy <b>associative</b> <b>matrix.</b>|$|E
50|$|A fuzzy <b>associative</b> <b>matrix</b> expresses {{fuzzy logic}} rules in tabular form. These rules usually take two {{variables}} as input, mapping cleanly to a two-dimensional matrix, although theoretically {{a matrix of}} any number of dimensions is possible.|$|E
40|$|Abstract. Consider an (<b>associative)</b> <b>matrix</b> algebra MI(R) graded {{by means}} of an abelian group G, and a graded {{automorphism}} φ on MI(R). By defining a new product by x⋆y: = φ(x) φ(y) on MI(R), (MI(R),⋆) becomes a hom-associative algebra graded by a twist of G. The structure of (MI(R),⋆) is studied, by showing that MI(R) is of the form MI(R) = U +...|$|E
40|$|By {{considering}} representation {{theory for}} non-associative algebras we construct the fundamental and adjoint {{representations of the}} octonion algebra. We then show how these representations by <b>associative</b> <b>matrices</b> allow a consistent octonionic gauge theory to be realized. We find that non-associativity implies the existence of new terms in the transformation laws of fields and the kinetic term of an octonioni...|$|R
40|$|This work uses {{recursive}} autoencoders (Socher et al., 2011), word embeddings (Pennington et al., 2014), <b>associative</b> <b>matrices</b> (Schuler, 2014) and lexical overlap {{features to}} model human judgments of sentential similarity on SemEval- 2015 Task 2 : English STS (Agirre et al., 2015). Results show a modest {{positive correlation between}} system predictions and human similarity scores, ranking 69 th out of 74 submitted systems. ...|$|R
40|$|By consireding {{representation}} {{theory for}} non-associative algebras we construct the fundamental and adjoint {{representations of the}} octonion algebra. We then show how these representations by <b>associative</b> <b>matrices</b> allow a consistent octonionic gauge theory to be realised. We find that non-associativity implies the existence of new terms in the transformation laws of fields and the kinetic term of an octonionic Lagrangian. Comment: 20 pages,latex, UM- P- 92 / 6...|$|R
40|$|Motivated by the controllability/reachability {{problems}} for switched linear control systems and some classes of nonlinear (mechanical) control systems we address a related problem of {{existence of a}} cyclic vector for an <b>associative</b> (<b>matrix)</b> algebra. We provide a sufficient criterion for existence of cyclic vector and draw conclusions for controllability. Comment: 14 pages; submitted to 54 th IEEE Conference on Decision and Control, CDC' 201...|$|E
40|$|We {{discuss how}} to {{represent}} the non-associative octonionic structure {{in terms of the}} <b>associative</b> <b>matrix</b> algebra using the left and right octonionic operators. As an example we construct explicitly some Lie and Super Lie algebra. Then we discuss the notion of octonionic Grassmann numbers and explain its possible application for giving a superspace formulation of the minimal supersymmetric Yang-Mills models. Comment: RevTex file, 12 pages, to be published in Int. J. of Mod. Phys. A; Some references adde...|$|E
40|$|This paper {{analyzes}} {{the effect of}} this technological progress on the design of nanoelectronic circuits and describes computational paradigms revealing novel features such as distributed storage, fault tolerance, self-organization, and local processing. In particular, linear threshold networks, the <b>associative</b> <b>matrix,</b> self-organizing feature maps, and cellular arrays are investigated from the viewpoint of their potential significance for nanoelectronics. Although these concepts have already been implemented using present technologies, the intention {{of this paper is to}} give an impression of their usefulness to system implementations with quantum-effect devices...|$|E
50|$|The set of all {{reflections}} in lines through {{the origin and}} rotations about the origin, together with the operation of composition of reflections and rotations, forms a group. The group has an identity: Rot(0). Every rotation Rot(φ) has an inverse Rot(−φ). Every reflection Ref(θ) is its own inverse. Composition has closure and is <b>associative,</b> since <b>matrix</b> multiplication is <b>associative.</b>|$|R
40|$|Sparsely coded {{associative}} memory (SpaCAM) {{can be regarded}} as a special form of neural networks. SpaCAMs are well suited for pattern recognition and completion in such different fields as text retrieval, OCR and speech recognition. Its straightforward representation has an unbearable space demand for large pattern sets. Limited memory resources require new techniques for the representation of <b>associative</b> <b>matrices.</b> Most messages are redundant. Data compression tries to get a more compact representation by eliminating the redundancy thus reducing space or transmission time. After introducing some data structures for matrix representation the most important data compression techniques are explained in this paper. Huffman and run length codes, arithmetic coding and two lossless image compression procedures are discussed. A combination of distance coding and statistical compression seems to be an adequate mean {{to deal with the problem}} of limited memory resources. (orig.) SIGLEAvailable from TIB Hannover: RO 8347 (1994, 13) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekDEGerman...|$|R
40|$|This study tested {{whether the}} word {{association}} employed by individual student {{could be used}} to predict their performance in a particular course. It was designed t explore a new method for describing the various models used in thinking and t determine whether this approach would yield results that were consonant with curren cognitive theory. At {{the beginning and end of}} an introductory course in Sod Psychology, college freshmen and their instructor filled out association matrices f 20 words that were central to the course. Using 1 word as 'i subject, the student assigned associability scale values to all possible pairs of words on a 7 -point scal indicating to what degree each of the other words would 'fit in * with (top of scale) change (bottom of scale) the subject. At the end of the term the association matrice were analyzed by a new, non-parametric method of factor analysis, the Matra Optimizing System (Mopsy). Two major hypotheses of the study were confirmed wi levels of correlations in the. 3 to. 4 range: students whose <b>associative</b> <b>matrices</b> yiel a larger number of dimensions under the non-parametric factor analysis tend to ge higher grades, and those whose cognitive dimensions match those of the instruct also tend to get higher grades. The Mopsy, which is discussed in detail, is suggest as a probably alternative to standard parametric methods of factor analysis. (WM) a 2 - 6 : 10, 1 c...|$|R
40|$|This paper {{describes}} the novel approach to Knowledge Extraction using conceptual association. Web {{has a huge}} collection of unstructured information. In this paper we have discovered structured knowledge from unstructured information available on the web browser and examine relationship between different concepts using web. Our concept is OCEAN WATER DESALINATION(OWD). OceanWater Desalination {{is the process of}} creating fresh water by removing saline(salt) from large ocean bodies with saline water. We have taken the view of four countries of the world namely INDIA(a country in continent ASIA), AUSTRALIA (a country in continent AUSTRALIA),U. S. A(a country in continent NORTH AMERICA) and AUSTRIA (a country in continent EUROPE) and studied the techniques presently used and proposed for OWD. Based on our study, we have classified techniques into two generations namely first and second generation and then we have attempted to extract the knowledge taking the help of Rough set theory and Fuzzy logic. Using overlap coefficient method to find Co-occurrence number, fuzzy membership function we have defined the concept strength in terms of nodes and arcs in visibility graph. Finally, fuzzy <b>associative</b> <b>matrix</b> depicts how various elements have worked together to yield some useful result. Keywords Concept association learning (CAL),Rough set theory, Overlap coefficient method,Co-occurrence matrix, Fuzzy membership function, Fuzzy <b>associative</b> <b>matrix.</b> 1...|$|E
40|$|We {{discuss how}} to {{represent}} the non-associative octonionic structure {{in terms of the}} <b>associative</b> <b>matrix</b> algebra using the left and right octonionic operators. As an example we construct explicitly some Lie and Super Lie algebra. Then we discuss the notion of octonionic Grassmann numbers and explain its possible application for giving a superspace formulation of the minimal supersymmetric Yang-Mills models. Usually we define an almost complex manifold as a real manifold equipped with a complex structure I such that I 2 = − 1 which may be a matrix lik...|$|E
40|$|Orthogonal matrix + {{translation}} (affine transformation) • An operational way {{to compose}} transformations 4 Sets of Transformations � Regularities {{in the set}} transformations have certain properties: Composing transformations creates only transformations in the set Composing transformations is <b>associative</b> (<b>matrix</b> property) There is an identity transformation. For every transformation, there is a inverse transformation, which undoes the original 5 Strip patterns (Friezes) � (p 11) ppppppppppp Iv + (1 0) � (p 1 g) pbpbpbpbpbp Av + (1 0) � (pm 1) bdbdbdbdbdb Bv, Iv + (1 0) � (p 12) bqbqbqbqbqb Cv, Iv + (1 0...|$|E
40|$|Abstract-This paper {{presents}} {{an investigation of}} two odor coding mechanisms in Freeman's KIII nenrodynamics model. Motivated by experimental evidence that supports {{the existence of a}} neural code based on synchronous oscillations, we propose an analogy between synchronization in neural populations and phase locking in KIl l channels. The information carried by the phase is compared against the conventional amplitude code in terms of pattern-recovery capabilities. First, the scalar invariance of the KIll with respect to phase information is established. Symmetries and redundancies in the <b>associative</b> memory <b>matrices</b> are then exploited to perform an exhaustive evaluation of patterns on an 8 -channel model. Simulation results show that phase information outperforms amplitude information in the recovery of odor patterns from incomplete or corrupted sensory stimulus. 1...|$|R
40|$|This paper proposes {{the use of}} {{associative}} {{memories for}} obtaining preliminary parameter estimates for nonlinear systems. For each parameter vector r, in a selected training set, the system equations are used to determine a vector s, of system outputs, An <b>associative</b> memory <b>matrix</b> M is then constructed which optimally, in the least squares sense, associates each system output vector s, with its corresponding parameter vector I-,. Given any observed system output vector s*, an estimate i for the system parameters is obtained by setting i = Ms*. Numerical experiments are reported which indicate {{the effectiveness of this}} approach, especially for the nonlinear associative memory case in which the training vectors s, include not only the system output levels but also products of these levels. Training with noisy output vectors is shown to improve the accuracy of the parameter estimates when th...|$|R
40|$|Abstract: Given an <b>associative</b> {{multiplication}} in <b>matrix</b> algebra {{compatible with}} the usual one or, in other words, a linear deformation of the matrix algebra, we construct {{a solution to the}} classical Yang-Baxter equation. We also develop a theory of such defor-mations and construct numerous examples. It turns out that these deformations are in one-to-one correspondence with representations of certain algebraic structures, which we call M-structures. We also describe an important class of M-structures related to the affine Dynkin diagrams of A, D, E-type. These M-structures and their representations are described in terms of quiver representations...|$|R
40|$|Given {{an element}} P(X_ 1, [...] .,X_d) of the finitely {{generated}} free Lie algebra, for any Lie algebra g we can consider the induced polynomial map P: g^d→ g. Assuming that K is an arbitrary field of characteristic 2, we prove that if P {{is not an}} identity in sl(2,K), then this map is dominant for any Chevalley algebra g. This result {{can be viewed as}} a weak infinitesimal counterpart of Borel's theorem on the dominancy of the word map on connected semisimple algebraic groups. We prove that for the Engel monomials [[[X,Y],Y], [...] .,Y] and, more generally, for their linear combinations, this map is, moreover, surjective onto the set of noncentral elements of g provided that the ground field K is big enough, and show that for monomials of large degree the image of this map contains no nonzero central elements. We also discuss consequences of these results for polynomial maps of <b>associative</b> <b>matrix</b> algebras. Comment: 22 page...|$|E
40|$|A {{recent article}} (Stanton and Sejnowski 1989) on {{long-term}} synaptic {{depression in the}} hippocampus has reopened {{the issue of the}} com-putational efficiency of particular synaptic learning rules (Hebb 1949; Palm 1988 a; Morris and Willshaw 1989) - homosynaptic versus het-erosynaptic and monotonic versus nonmonotonic changes in synaptic efficacy. We have addressed these questions by calculating and maxi-mizing the signal-to-noise ratio, a measure of the potential fidelity of recall, in a class of <b>associative</b> <b>matrix</b> memories. Up to a multiplicative constant, there are three optimal rules, each providing for synaptic de-pression such that positive and negative changes in synaptic efficacy balance out. For one rule, which is found to be the Stent-Singer rule (Stent 1973; Rauschecker and Singer 1979), the depression is purely het-erosynaptic; for another (Stanton and Sejnowski 19891, the depression is purely homosynaptic; for the third, which is a generalization of the first two, and has a higher signal-to-noise ratio, it is both heterosynaptic and homosynaptic. The third rule {{takes the form of a}} covariance rule (Sejnowski 1977 a,b) and includes, as a special case, the prescription due to Hopfield (1982) and others (Willshaw 1971; Kohonen 1972). In principle, the association between the synchronous activities in two neurons could be registered by a mechanism that increases the ef-ficacy of the synapses between them, in the manner first proposed by Hebb (1949); the generalization of this idea to the storage of the asso-ciations between activity in two sets of neurons is in terms of a matri...|$|E
40|$|Abstract. Parameter {{estimation}} {{problems for}} nonlinear systems are typically formulated as nonlinear optimization problems. For such problems, {{one has the}} usual difficulty that standard successive approximation schemes require good initial estimates for the parameter vector. This paper develops a simple multicriteria associative memory (MAM) procedure for obtaining useful initial parameter estimates for nonlinear systems. An easily calculated one-parameter family of <b>associative</b> memory <b>matrices</b> is developed; see Equation (25). Each memory matrix is efficient with respect to two criteria: accurate recovery of parameter-output training case associations; and small matrix norm to guard against noise arising from imprecise calculations and observations. For illustration, the MAM procedure is used to obtain initial parameter estimates for a well-known nonlinear economic model, the Solow-Swan growth model. Surprisingly accurate initial parameter estimates are obtained over broad ranges {{of the family of}} MAM memory matrices, even when observations are corrupted by i. i. d. or correlated noise. Key words. Nonlinear estimation, artificial neural networks, associative memory, multicriteria optimi-zation, Solow-Swan growth model...|$|R
40|$|The binary {{operation}} of usual addition is <b>associative</b> in all <b>matrices</b> over R. However, a {{binary operation}} of addition in matrices over Z n of a nonassociative structures of AG-groupoids and AG-groups are defined and investigated here. It is shown that both these structures exist for every integer n > 3. Various properties of these structures are explored like: (i) Every AG-groupoid of matrices over Z n is transitively commutative AG-groupoid {{and is a}} cancellative AG-groupoid ifn is prime. (ii) Every AG-groupoid of matrices over Z n of Type-II is a T 3 -AG-groupoid. (iii) An AG-groupoid of matrices over Z n; G nAG(t,u), is an AG-band, ift+ u= 1 (mod n) ...|$|R
40|$|We {{say that}} a {{function}} F(tau) obeys WDVV equations, if for a given invertible symmetric matrix eta^alpha beta and all tau ∈ T ⊂ R^n, the expressions c^alpha_beta gamma(tau) = eta^alpha lambda c_lambda beta gamma(tau) = eta^alpha lambda∂_lambda∂_beta∂_gamma F {{can be considered as}} structure constants of commutative <b>associative</b> algebra; the <b>matrix</b> eta_alpha beta inverse to η^αβ determines an invariant scalar product on this algebra. A function x^alpha(z, tau) obeying ∂_alpha∂_beta x^gamma (z, tau) = z^- 1 c^varepsilon_alpha beta∂_epsilon x^gamma (z, tau) is called a calibration of a solution of WDVV equations. We show that there exists an infinite-dimensional group acting on the space of calibrated solutions of WDVV equations (in different form such a group was constructed in [2]). We describe the action of Lie algebra of this group. Comment: LaTeX, 15 page...|$|R
40|$|Conventional {{simulation}} of neural networks implemented using our pulsed analog topology is slow. The commercial circuit simulator HSPICE takes {{about half a}} day to simulate even a medium scale network, which is frustrating at the design stage. A new simulator, PULSE, has been developed to relieve the designer from this problem. PULSE provides about two orders of speed improvement over HSPICE while predicting the circuit, performance with comparable accuracy. It uses a macromodeling approach {{in contrast to the}} transistor level simulation approach in HSPICE. Special features of pulsed analog networks are exploited constantly to reduce the simulation time. The analysis algorithms used are Waveform Gauss-Seidel and Functional iteration. Circuit equations formulated being very sparse, correct ordering of the equations leads to convergence to the solution in only one Gauss-Seidel iteration. Using PULSE as the simulation tool, a <b>Matrix</b> <b>Associative</b> Memory has also been designed which {{is in the process of}} fabrication...|$|R
40|$|Thesis (M. Eng.) [...] Memorial University of Newfoundland, 1993. Engineering and Applied ScienceBibliography: leaves 119 - 123. Conventional {{simulation}} of neural networks implemented using our pulsed analog topology is slow. The commercial circuit simulator HSPICE takes {{about half a}} day to simulate even a medium scale network, which is frustrating at the design stage. A new simulator, PULSE, has heen developed to relieve the designer from this problem. PULSE provides about two orders of speed improvement over HSPICE while predicting the circuit, performance with comparable accuracy. It uses a macromodeling approach {{in contrast to the}} transistor level simulation approach in HSPICE. Special features of pulsed analog networks are exploited constantly to reduce the simulation time. The analysis algorithms used are Waveform Gauss-Seidel and Functional iteration. Circuit equations formulated being very sparse, correct ordering of the equations leads to convergence to the solution in only one Gauss-Seidel iteration. Using PULSE as the simulation tool, a <b>Matrix</b> <b>Associative</b> Memory has also been designed which {{is in the process of}} fabrication...|$|R
40|$|We {{consider}} a certain generalization {{of the well}} known 2 nd order linear recurrences X i = a i Δ X iΓ 1 + b i Δ X iΓ 2 i = 1 : : : n to indexed recurrences with linear combinations X g(i) = a i Δ X f(i) + b i Δ X h(i), where g(i); f(i); h(i) are arbitrary functions from [1; : : :; n] to [1; : : :; m]. The problem is to find an efficient parallel algorithm that can compete with the sequential execution of the loop for i = 1; : : :; n do X [g(i) ] = a i Δ X [f(i) ] + b i Δ X [h(i) ] : which solve the above recurrence generalization. Such an algorithm (that uses only O(n) work) {{can be used for}} automatic parallelization of sequential loops, which in many practical cases fit to the form of the above generalized recurrence. A natural solution is to transform the above sequential loop into a set of matrix multiplications and use the <b>associative</b> property of <b>matrix</b> multiplications to compute the result in log n parallel steps. We show that unlike the ca [...] ...|$|R

