0|172|Public
50|$|Advantages of {{striping}} include {{performance and}} throughput. Sequential time interleaving of data accesses allows the lesser data <b>access</b> <b>throughput</b> of each storage devices to be cumulatively {{multiplied by the}} number of storage devices employed. Increased throughput allows the data processing device to continue its work without interruption, and thereby finish its procedures more quickly. This is manifested in improved performance of the data processing.|$|R
40|$|Abstract. Cloud {{computing}} {{is becoming}} one of the most convenient ways for information services through network accesses. In this paper, we describe the architecture of cloud computing and discuss the issue of in-cast, which may downgrade the transmission performance when the number of simultaneous transmission servers is getting larger. The in-cast transmission may introduce the out of sequence of packet delivery and may reduce the system throughput. This paper constructs the software environment to simulate the performance of video streaming services delivered by the servers in cloud. We first examine the performance of the out of sequence issue of packet transmission when the Hashed Credit Fair (HCF) algorithm was applied and investigate the multicast performance of video streaming service with respect to the numbers of servers. With the increasing of the number of servers, we note that transmission performance is not improved, on the contrary, the system <b>throughput</b> <b>downgrades</b> sharply. We believe the simulation results of this paper will be helpful for the design of cloud video multicast services. 1...|$|R
40|$|Random-access {{algorithms}} such as CSMA {{provide a}} popular mechanism for distributed {{medium access control}} in largescale wireless networks. In recent years, tractable models {{have been shown to}} yield accurate throughput estimates for CSMA networks. We consider the saturated model on a general conflict graph, and prove that for each graph, there exists a vector of activation rates (or mean back-off times) that leads to equal throughputs for all users. We describe an algorithm for computing such activation rates, and discuss a few specific conflict graphs that allow for explicit characterization of these fair activation rates. Keywords: CSMA, fixed point, global invertibility, loss networks, Markov processes, random <b>access,</b> <b>throughput,</b> wireless network...|$|R
40|$|Many {{distributed}} storage systems achieve {{high data}} <b>access</b> <b>throughput</b> via partitioning and replication, each system {{with its own}} advantages and tradeoffs. In order to achieve high scalability, however, today’s systems generally reduce transactional support, disallowing single transactions from spanning multiple partitions. Calvin is a practical transaction scheduling and data replication layer that uses a deterministic ordering guarantee to significantly reduce the normally prohibitive contention costs associated with distributed transactions. Unlike previous deterministic database system prototypes, Calvin supports disk-based storage, scales near-linearly on a cluster of commodity machines, and has no single point of failure. By replicating transaction inputs rather than effects, Calvin is also able to support multiple consistency levels—including Paxosbased strong consistency across geographically distant replicas—at no cost to transactional throughput...|$|R
40|$|This paper {{describes}} a free filesystem for external flash mem-ory {{to be employed}} with low-complexity sensor nodes. The system uses a standard secure digital (SD) card {{that can be easily}} connected to the serial port interface (SPI) or any general input/output port of the sensor’s processor. The filesystem is evaluated with SD- cards used in SPI mode and achieves an average random write throughput of about 40 kByte/sec. For random write <b>access</b> <b>throughputs</b> larger than 400 kByte/sec are achieved. The filesystem allows for stor-age of large amounts of sensor or program data and can assist more memory expensive algorithms. It requires 7 kByte of program memory and about 570 Bytes of RAM. Categories and Subject Descriptors D. 4. 3 [Software]: Operating Systems—File Systems Man...|$|R
40|$|In this thesis, we {{describe}} and evaluate novel memory designs for multi-port on-chip and off-chip use in advanced computer architectures. We focus on combining multi-porting and evaluating the performance over {{a range of}} design parameters. Multi-porting is essential for caches and shared-data systems, especially multi-core System-on-chips (SOC). It can significantly increase the memory <b>access</b> <b>throughput.</b> We evaluate FinFET voltage-mode multi-port SRAM cells using different metrics including leakage current, static noise margin and read/write performance. Simulation results show that single-ended multi-port FinFET SRAMs with isolated read ports offer improved read stability and flexibility over classical double-ended structures {{at the expense of}} write performance. By increasing the size of the access transistors, we show that the single-ended multi-port structures can achieve equivalent write performance to the classical double-ended multi-port structure for 9...|$|R
40|$|In this paper, we {{introduce}} a novel CSMA/CA-based reservation scheme that improves the multiple <b>access</b> <b>throughput</b> of wireless ad-hoc networks using switched beam antennas. First, we show the performance {{limitations of the}} omni-directional and directional reservation paradigms investigated in the literature. This is done via emphasizing the trade-off between minimizing the number of control/data packet collisions and minimizing the number of neighbors that back-off unnecessarily. Next, we propose a novel concept that balances this trade-off via sending reservation messages, that carry information about the intended direction of transmission, on all unblocked beams. The innovation in this approach is to send directional information to as many neighbors as possible {{in order to better}} assist them in deciding whether to transmit or refrain from transmission on a specific beam. Finally, the algorithm is examined via simulations and compared to the omni-directional and directional reservation approaches...|$|R
40|$|The {{well known}} problem among most random access {{protocols}} in wireless networks {{is that the}} throughput drops rapidly in heavy load. To cope with this problem, one has to control to the load offered to a network. Unlike the traditional backoff policy in Ethernet where backoff occurs after collision, {{in this paper we}} propose various control schemes based on the new idea of resampling, where carrier sensing ability is used to determine whether a backoff command should be issued or not. We show from various experiments that our schemes are capable of controlling the offer load to the optimal offer load. As a result, the throughputs of these schemes are kept close to the network capacity in heavy load. Key words: wireless networks, multiple <b>access,</b> random <b>access,</b> <b>throughput,</b> capacity Corresponding author. E-mail:cschang@ee. nthu. edu. tw. Fax: + 886 - 35 - 715971...|$|R
40|$|Multiport {{memories}} are extensively used in modern system designs {{because of the}} performance advantages they offer. The increased memory <b>access</b> <b>throughput</b> could lead to significantly faster sched-ules in behavioral synthesis. However, they also have an associ-ated area and energy penalty. We describe a technique for mapping data accesses to multiport memories during behavioral synthesis that results in significantly better energy characteristics than an un-optimized multiport design. The technique consists of an initial colouring of the array access nodes in the data flow graph based on spatial locality, followed by attempts to consecutively access mem-ory locations with the same colour on the same port. Our experi-ments on several applications indicate {{a significant reduction in}} ad-dress bus switching activity, leading to an overall energy reduction over an unoptimized design, while still maintaining a performance advantage over a single-port solution. 1...|$|R
5000|$|Protein design {{labs and}} Signature BioScience Signature BioSciences {{acquired}} Protein Design Lab’s Small Molecule Group <b>access</b> its high <b>throughput</b> screening and small molecule drug discovery efforts. (Jan 2002) ...|$|R
40|$|This study uses {{a unique}} dataset to {{investigate}} university <b>access,</b> <b>throughput,</b> and dropout for the 2008 South African national matric cohort. The {{findings show that}} university access in South Africa is limited, even among learners who perform relatively well in matric. In addition, those who do gain access to university often {{take a long time}} to complete their studies, with many never completing at all. As a result, only a select minority of matric learners manage to obtain university qualifications. Significant inequalities in university outcomes between race groups and across geographical space also remain evident. However, the results from the analysis suggests that observed patterns of university access and university success are strongly influenced by school results. The weak school system has a major influence on who reaches matric, and how they perform in matric. This, and particularly the achievement of Bachelor passes, explains much of the differences in university outcomes by race, gender and province...|$|R
40|$|IEEE 802. 16 {{mesh network}} is a {{promising}} next generation wireless backbone network. In this paper an enhanced wireless mesh network {{has been designed}} using different spread spectrum schemes such as DSSS and FHSS by means of OPNETTM 14. 0 and a comparison is carried out for both the schemes viz. Performance parameters such as medium <b>access</b> delay, <b>throughput,</b> retransmission delay and traffic load...|$|R
40|$|The term graceful {{degradation}} describes the smooth {{change to a}} lower state of some system aspect {{as a response to}} the occurrence of an event that prohibits the manifestation of the fully fledged system behavior. Graceful degradation has appeared in a variety of domains, from image processing and telecommunications to shared memory multiprocessors and multi-modular memory systems. In each domain, {{graceful degradation}} has targeted a different system aspect, e. g. image quality, voice quality, computational capacity, memory <b>access</b> <b>throughput,</b> etc. However, irrespectively of the system aspect that has been gracefully degraded, the basic concepts behind the corresponding mechanisms have been similar in all the domains where graceful degradation has been used. This paper presents two design patterns that capture design principles of graceful degradation. The first of the presented patterns captures the general idea behind lowering the state of a system aspect in the occurrence of an unsolicited event that affects the quality of that aspect. The second pattern elaborates on a method for lowering gracefully the system statte. ...|$|R
40|$|The {{performance}} of high-speed network-attached storage applications is often limited by end-system overhead, caused primarily by memory copying and network protocol processing. In this paper, we examine alternative strategies for reducing overhead in such systems. We consider optimizations to {{remote procedure call}} (RPC) -based data transfer using either remote direct memory access (RDMA) or network interface support for pre-posting of application receive buffers. We demonstrate that both mechanisms enable file <b>access</b> <b>throughput</b> that saturates a 2 Gb/s network link when performing large I/Os on relatively slow, commodity PCs. However, for multi-client workloads dominated by small I/Os, throughput {{is limited by the}} per-I/O overhead of processing RPCs in the server. For such workloads, we propose the use of a new network I/O mechanism, Optimistic RDMA (ORDMA). ORDMA is an alternative to RPC that aims to improve server throughput and response time for small I/Os. We measured performance improvements of up to 32 % in server throughput and 36 % in response time with use of ORDMA in our prototype. ...|$|R
40|$|Most {{parallel}} file systems provide applications {{with conventional}} sequential views of files that stripe data transparently across multiple disks thus reducing the bottleneck of relatively slow disk <b>access</b> <b>throughput.</b> The Unix-like interface increases {{the ease of}} application portability, but conceals the underlying parallelism within the file system precluding any optimization of the I/O access pattern from different processes. Although recent multiprocessor file systems incorporate more sophisticated I/O interfaces, e. g. collective I/O interfaces, enabling the I/O access-pattern information to flow from an application program down to the data management system, they still lack flexibility {{and they do not}} enable application-specific codes to run on I/O nodes. Therefore application-specific processing operations cannot be directly executed where data resides. Moreover, with the conventional approach of developing parallel I/O- and compute- intensive applications on distributed memory architectures, programmers are faced with two different systems: a parallel file system for parallel I/O and a message passing system for parallel computation. This separation between storage and processing makes it difficult for application programmers to combine I/O and computation in an efficient manner, i. e. overlap I/O requests with computations...|$|R
40|$|As {{more data}} {{management}} software {{is designed for}} deployment {{in public and private}} clouds, or on a cluster of commodity servers, new distributed storage systems increasingly achieve high data <b>access</b> <b>throughput</b> via partitioning and replication. In order to achieve high scalability, however, today’s systems generally reduce transactional support, disallowing single transactions from spanning multiple partitions. This article describes Calvin, a practical transaction scheduling and data replication layer that uses a deterministic ordering guarantee to significantly reduce the normally prohibitive contention costs associ-ated with distributed transactions. This allows near-linear scalability on a cluster of commodity machines, without eliminating traditional transactional guarantees, introducing a single point of failure, or requir-ing application developers to reason about data partitioning. By replicating transaction inputs instead of transactional actions, Calvin is able to support multiple consistency levels—including Paxos-based strong consistency across geographically distant replicas—at no cost to transactional throughput. Furthermore, Calvin introduces a set of tools that will allow application developers to gain the full performance benefit of Calvin’s server-side transaction scheduling mechanisms without introducing the additional code complexity and inconvenience normally associated with using DBMS stored procedures in place of ad hoc client-side transactions...|$|R
40|$|International audiencePerformance {{degradation}} of an IEEE 802. 11 g network is studied in case legacy stations {{are associated with}} the AP. Custom event-driven simulator was developed for the purpose. We demonstrate its consistency by comparing the outputs with a widely accepted network simulator and with results of an analytical study. Performance degradation is analyzed in terms of <b>access</b> delay and <b>throughput.</b> We study the effect of an associated legacy node on access delay as a function of number of nodes in the network. Additionally, we focus on a fixed size network and examine the effect of the bit rate used for transmission of protection mechanisms' control frames. Significant performance drop is observed both in terms of <b>access</b> delay and <b>throughput...</b>|$|R
40|$|A new tunable optical {{delay line}} for OTDM {{applications}} can achieve sub-nanosecond tuning time across three time slots spaced 100 ps apart. Using parallel fiber delays, the delay line requires only one modulator operating below the baseband data rate. A simple control algorithm {{based on a}} latency diagram can further reduce the average latency beyond that of the straightforward hardware implementation by 50 %. Using the demonstrated delay line, 10 GHz electronics {{has the potential to}} <b>access</b> a <b>throughput</b> of 160 Gb/s optical data...|$|R
40|$|Main goal of {{this work}} is to give insight on the possibile {{performance}} improvement arising in the wireless local and/or ”ad-hoc ” access from the synergic cooperation of two emerging paradigms, e. g., Multi-Antenna and Cognitive radios. As application scenario, we consider both the faded uplink of a WLAN working in infrastructure-mode, where noncooperative Multi-Antenna cognitive radios attempt to join to a (possibly Multi-Antenna) Access Point (AP) and an ”ad-hoc ” scenario where each node can communicate with each ”free ” node. The target can be twofold and two different approaches are considered. The first is the competitive maximization of own <b>access</b> <b>throughput</b> {{in the presence of}} Multiple-Access Interference (MAI) induced by the other accessing terminals, the second one is the BER minimization. Being the radios cognitive, they are capable to autonomously ”learn” the ambient-context and, then, ”self-configure ” their access strategy via suitable power-allocation that is time-frequency-code-space signal-shaping. Furthermore, a generalized approach is developed that allows the node to access with a (possibly hybrid) scheme to the medium by combining different x-DMA strategies under QoS-guaranteed access policy. The presented Generalized Multiple-Access (GMA) approach is able to work even when the information learned by the cognitive radios about the network-state (e. g., faded link-state and MAI level) is imperfect...|$|R
40|$|Many {{algorithms}} {{and applications}} in scientific computing exhibit irregular access patterns as consecutive accesses {{are dependent on}} the structure of the data being processed and as such cannot be known a priori. This manifests itself as a lack of temporal and spatial locality meaning these applications often perform poorly in traditional processor cache hierarchies. This thesis demonstrates that heterogeneous architectures containing Field Programmable Gate Arrays (FPGAs) alongside traditional processors can improve memory <b>access</b> <b>throughput</b> by 2 - 3 x by using the FPGA to insert data directly into the processor cache, eliminating costly cache misses. When fetching data to be processed directly on the FPGA, scatter-gather Direct Memory Access (DMA) provides the best performance but its storage format is inefficient for these classes of applications. The presented optimised storage and generation of these descriptors on-demand leads to a 16 x reduction in on-chip Block RAM usage and a 2 / 3 reduction in data transfer time. Traditional scatter-gather DMA requires a statically defined list of access instructions and is managed by a host processor. The system presented in this thesis expands the DMA operation to allow data-driven memory requests in response to processed data and brings all control on-chip allowing autonomous operation. This dramatically increases system flexibility and provides a further 11...|$|R
40|$|In a {{smart grid}} environment, a WiMAX network has {{to support a}} large number of {{machine-to-machine}} (M 2 M) applications with diverse bandwidth, latency and network entry requirements. While M 2 M devices like smart meters and time-triggered sensors will periodically perform network re-entry to send data, {{a large number of}} event driven sensors might initiate network entry procedures simultaneously after an event. Without mechanisms to handle such a large number of network access requests, the entire ranging channel could be congested degrading the performance of the whole network. In this paper a novel ranging scheme is proposed that can provide contention free network access to the periodic M 2 M applications in a smart grid. We first evaluate the performance of the existing WiMAX ranging channel in terms of random access success rate, access delay and <b>access</b> <b>throughput</b> using a discrete event simulation model based on OPNET Modeler v 16. 0. The results indicate that at high random access loads, the access success rate drops sharply and the mean access delay increases exponentially. We then simulate a smart grid event where the underlying WiMAX network faces a heavy random access load and show that the proposed scheme is able to provide better performance in comparison to that of the conventional ranging scheme...|$|R
40|$|We {{consider}} a single cell uplink {{in which many}} devices randomly transmit a data payload to the base station. Given a fixed latency constraint per device, we propose a time and frequency slotted random access scheme with retransmissions, which when necessary, are Chase combined at the receiver. We analyze the proposed setting at constant SNR. We characterize the scaling of random <b>access</b> <b>throughput</b> versus the latency, by optimizing the number of retransmissions {{and the number of}} frequency bins. For infinite block length (IBL), we conclude that at low SNR devices should completely share the time and frequency resources. For high SNR, however, the number of frequency bins should scale with altered load, and the slot duration for each retransmission is determined by the outage tolerance. Since infinite packet sizes are not possible, we extend our model to the finite block length (FBL) regime and characterize the gap versus the IBL regime. We also provide some new results for FBL capacity to bound the probability of outage. The proposed random access model gives an upper bound for the total uplink traffic that can be successfully decoded for a single receive antenna given the latency constraint, and provides insights for 5 G cellular system design...|$|R
5000|$|The {{performance}} of a RAM drive is in general orders of magnitude faster than other forms of storage media, such as an SSD, hard drive, tape drive, or optical drive. [...] This performance gain is due to multiple factors, including <b>access</b> time, maximum <b>throughput,</b> and type of file system.|$|R
40|$|Introduction: There is a {{shortage}} internationally of adequately trained health professionals to service rural areas. Health professionals {{are more likely to}} practice in communities that are like the one in which they grew up. The WHO therefore suggests targeted university admission policies to facilitate the enrolment of students from rural areas. In South Africa, rural students have special needs with regard to university <b>access</b> and <b>throughput</b> because they come from the most economically disadvantaged communities and often are the first in their families to attend university. This descriptive study, the first in South Africa with...|$|R
40|$|Transactional {{memory is}} a lock-free {{parallel}} programming model, which aims at replacing conventional lock-based threaded programming techniques, currently used by multi-core systems. These techniques {{are difficult to}} implement and impose unnecessary overheads caused by conservative programming practices. In this thesis, the scalability potential of a transactional memory system, called TMFab, was explored for different numbers of processors and {{it was concluded that}} for more than 4 processors the system presents reduced scalability, due to an increase in the validation overhead. In response to this observation, a novel validation scheme was proposed which reduces this overhead, first by allowing multiple transactions to perform their validations and commit operations concurrently, and second by removing the need for broadcasting messages between the active transactions. A distributed shared memory scheme was used to increase the validation and memory <b>access</b> <b>throughput,</b> as well as allow for transactions to commit concurrently on different memory partitions. The two architectures were compared by means of SystemC simulation, and a maximum of 2. 5 x validation speedup was observed for the modified design, together with a 2. 7 x reduction in memory access latency. In total, the modified design achieved a maximum execution speedup of 30 % over the original, for the benchmarks that were used. Furthermore, the modified system guarantees sequential consistency even in corner case scenarios. Computer EngineeringCircuits and SystemsElectrical Engineering, Mathematics and Computer Scienc...|$|R
40|$|Abstract. Non-cooperative {{behaviors}} in communication networks can significantly adversely affect the entire network. Recently, researchers {{have begun to}} study such non-cooperative communication systems within a game theory framework and strive to engineer the system to prevent performance degradation under non-cooperative behaviors. The WWAN/WLAN two-hop-relay system described in [1] integrates two types of wireless technologies to improve wireless <b>access</b> <b>throughput</b> and coverage. The relay nodes in the two-hop-relay system can be wireless relay routers deployed by wireless service providers, or dual-mode users who voluntarily relay traffic for other users. However, {{it is reasonable to}} assume that all dual-mode terminals are selfish and are not willing to relay for other users without an incentive. In this paper, we will use the basic concepts of game theory, especially the concept of the Nash Equilibrium, to design our scheduling algorithms. Several scheduling algorithms, including the maximum rate C/I scheduler, the proportional fair scheduler, and the round robin scheduler, are examined to understand performance while operating under the assumption that all users are selfish. Under the C/I scheduler or the proportional fair scheduler, Nash Equilibriums exist at the operating points where no user will relay for other users—an undesirable situation. Under the round robin scheduler, selfish users are indifferent on relaying voluntarily or not relaying. Therefore, we are inspired to design a novel incentive scheduler. By applying the proposed incentive scheduler, all selfish users relay cooperatively at the Nash Equilibrium...|$|R
40|$|Abstract — Non-cooperative {{behaviors}} in communication networks can significantly adversely affect the entire network. Recently, researchers {{have begun to}} study such non-cooperative communication systems within a game theory framework and strive to engineer the system to prevent performance degradation under non-cooperative behaviors. The WWAN/WLAN two-hoprelay system described in [1] integrates two types of wireless technologies to improve wireless <b>access</b> <b>throughput</b> and coverage. The relay nodes in the two-hop-relay system can be wireless relay routers deployed by wireless service providers, or dual-mode users who voluntarily relay traffic for other users. However, {{it is reasonable to}} assume that all dual-mode terminals are selfish and are not willing to relay for other users without an incentive. In this paper, we propose a proper scheduling algorithm as an incentive mechanism for the hybrid wireless relay network. We will use the basic concepts of game theory, especially the concept of the Nash Equilibrium, to design our scheduling algorithms. Several scheduling algorithms, including the maximum rate C/I scheduler, the proportional fair scheduler, and the round robin scheduler, are examined to understand performance while operating under the assumption that all users are selfish. Under the C/I scheduler or the proportional fair scheduler, Nash Equilibriums exist at the operating points where no user will relay for other users [...] -an undesirable situation. Under the round robin scheduler, selfish users are indifferent on relaying voluntarily or not relaying. Therefore, we are inspired to design a novel incentive scheduling algorithm to encourage relay. By applying the proposed incentive scheduler at the base station, all selfish users relay cooperatively at the Nash Equilibrium. I...|$|R
40|$|As distributed, global-scale, data-intensive {{applications}} {{are becoming more}} and more common, an increasing pressure is being put on the underlying distributed data services. As such services need to support massively concurrent, largely distributed accesses to huge shared datasets, the stability and scalability of their performance are critical. More specifically, the ability to sustain a stable high throughput is a very desirable property, as it strongly impacts the quality of service of the data storage system and thereby the overall application performance. Handling quality of service in a large-scale distributed system is however a very difficult task, as a very large number of factors are involved: the data access patterns, the status of a huge number of physical components, etc. In this paper we explore an approach to the management of quality of service in distributed storage systems based on global behavior modeling combined with client-side quality of service feedback. Our objective is to automate the process of identifying dangerous behavior patterns in storage services. To demonstrate our approach, we apply GloBeM, a global behavior modeling technique based on monitoring data analysis and machine learning, to improve the quality of service in BlobSeer, a distributed storage for large-scale data-intensive applications specifically designed to sustain high <b>throughput</b> under heavy <b>access</b> concurrency. We evaluate this improvement through extensive evaluations on the Grid' 5000 testbed using hard experimental conditions: highly-concurrent data access patterns, for long periods of service uptime, while supporting failures of the physical storage components. Our results show substantial progress in sustaining a higher and more stable data <b>access</b> <b>throughput...</b>|$|R
40|$|Over-the-air {{characterization}} of wireless devices {{is performed using}} specific channel models. Channel models define {{the distribution of the}} incident signals over angle and polarization, but always assuming a large number of signal paths. However, in some real cases, the number of signal paths can be limited. This letter studies the effect of the number of signal paths on the high-speed downlink packet <b>access</b> (HSDPA) <b>throughput,</b> using a commercial phone. Differences in performance are found, depending on the number of signal paths. This highlights the importance of the number of signal paths in the {{characterization of}} wireless devices. This work {{was supported in part by}} MICINN (Project TEC 2008 - 05811) under FPI Doctoral Grant BES- 2009 - 01376...|$|R
40|$|MA) {{protocol}} {{which is}} designed to support different types of service on future wireless indoor local area networks. The proposed architecture does not follow the conventional cellular or ad-hoc approaches but still supports both peer-to-peer communication and infrastructure access. It is assumed that a high bit rate (20 Mbits/s) radio solution is used to provide the physical connectivity with omni-directional antennae. The goal of the ATDM-MA protocol is to provide efficient channel utilisation and re-use and operates in conjunction with different Medium Access Control (MAC) protocols for different traffic types (i. e. polling and random <b>access).</b> The <b>throughput</b> and delay of the proposed scheme obtained from computer simulation shows that good performance can be achieved with modest complexity...|$|R
40|$|Holographic {{technique}} offers high-density {{data storage}} with parallel <b>access</b> and high <b>throughput.</b> Several methods exist for data multiplexing {{based on the}} fundamental principle of volume hologram Bragg selectivity. We recently demonstrated that spatial shift selectivity associated with a random (amplitude-phase) encoding of the reference beam is an alternative method for high-density, high capacity data multiplexing. In this report we show some characteristics of the random encoded reference beam hologram selectivity...|$|R
40|$|Praca doktorska. Akademia Górniczo-Hutnicza im. Stanisława Staszica (Kraków), 2011. Zawiera bibliogr. Dostępna także w wersji drukowanej. Tryb dostępu: Internet. Misbehaviour in EDCA, QoS in Ad-hoc Networks, Misbehaviour in Ad-hoc Networks, Modeling EDCA, Detecting MAC Misbehaviour, Preventing or Discouraging Misbehaviour, Game-theoretic Approaches, Impact of Misbehaviour on QoS, Single-hop Networks, Multi-hop Networks, Saturation <b>Throughput,</b> Reference Case, <b>Downgrading</b> Forwarded Traffic, Promoting Local Traffic, Lessons Learned, IEEE 802. 11 EDCA Model, Assumptions, Model Analysis, Misbehaviour Analysis, Validation, Model Verification, Comparison with Other Models, Impact of Misbehaving Nodes, Detecting Backoff Misbehaviour, Detection Method, Detecting in Single-hop Networks, in Multi-hop Networks, Reacting to Backoff Misbehaviour, Simplified EDCA Model, Study of EDCA Games, Single-player EDCA Games, Multi-player Games, Proposed Solution, Application of Penalty Mechanism, Single AC Traffic, Multiple AC Traffic, Multiple Misbehaving Nodes, Multi-hop Networks, Misbehaviour on the Penalty Mechanis...|$|R
40|$|There is a {{shortage}} internationally of adequately trained health professionals to service rural areas. Health professionals {{are more likely to}} practice in communities that are like the one in which they grew up. The WHO therefore suggests targeted university admission policies to facilitate the enrolment of students from rural areas. In South Africa, rural students have special needs with regard to university <b>access</b> and <b>throughput</b> because they come from the most economically disadvantaged communities and often are the first in their families to attend university. This descriptive study, the first in South Africa with a cohort of dentistry students, draws on data from undergraduates at a single faculty of dentistry in South Africa. It investigates the factors affecting rural students’ access to university, their academic success, as well as their employment intentions. Web of Scienc...|$|R
30|$|The {{objective}} {{of this article is}} to investigate key parameters that delineate practically relevant regimes of dense spectrum usage. Our focus is on delay-sensitive applications and random spectrum access with carrier sensing (CSMA). Specifically, we seek succinct conditions that predict excessive dependence between channel access delay and system size. Our ultimate interest is in understanding the relationship among <b>throughputs,</b> <b>access</b> delays, and system size; and thereby in identifying throughput levels that entail admissible access delay regardless of the system size.|$|R
5000|$|DDR SDRAM (Double {{data rate}} SDRAM) This could {{transfer}} twice the data (two consecutive words) on each clock cycle by double pumping (transferring data {{on both the}} rising and falling edges of the clock pulse). Extensions of this idea are the current (2012) technique being used to increase memory <b>access</b> rate and <b>throughput.</b> Since it is proving difficult to further increase the internal clock speed of memory chips, these chips increase the transfer rate by transferring more data words on each clock cycle ...|$|R
30|$|Thus, we further {{introduced}} a novel handover process where PMIPv 6 was enhanced with a handover coordinator (HC) {{to further enhance}} the handover performance. With the HC being a network-based entity that coordinates the facilitation of handover activities {{on behalf of the}} MN ahead of time, handover delay and packet loss were reduced without incurring extrasignaling overhead in the air interface. Furthermore, data packets were delivered to the MN as real-time as possible even during the actual handover period without any need for buffering either at the source or target <b>access.</b> The <b>throughput</b> rates observed during the handover period in the PMIPv 6 -HC scheme confirm the handover performance improvement of the scheme. Furthermore, the scalability of the proposed scheme in terms of its performance as the number of MNs that are involved in handovers at the same time increase was investigated.|$|R
