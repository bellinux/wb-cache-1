1|360|Public
40|$|We {{present a}} noise-robust {{algorithm}} for estimating the active level of speech, {{which is the}} <b>average</b> <b>speech</b> <b>power</b> during intervals of speech activity. The proposed algorithm uses the clean speech phase to remove the quadrature noise component from the short-time power spectrum of the noisy speech, as well as SNR-dependent techniques to improve the estimation. The pitch of voiced speech frames is determined using a noise-robust pitch tracker and the speech level is estimated from {{the energy of the}} pitch harmonics using the harmonic summation principle. At low noise levels, the resultant active speech level estimate is combined with that from the standardized ITU-T P. 56 algorithm to give a final composite estimate. The algorithm has been evaluated using a range of noise signals and gives consistently lower errors than previous methods and than the ITU-T P. 56 algorithm, which is accurate for SNR levels of above 15 dB...|$|E
40|$|A noise {{estimation}} {{algorithm is}} proposed for highly nonstationary noise environments. The noise estimate is updated by <b>averaging</b> the noisy <b>speech</b> <b>power</b> spectrum using a time and frequency dependent smoothing factor, which is adjusted based on signal presence probability in subbands. Signal presence is determined by computing {{the ratio of the}} noisy <b>speech</b> <b>power</b> spectrum to its local minimum, which is computed by averaging past values of the noisy <b>speech</b> <b>power</b> spectra with a look-ahead factor. The local minimum estimation algorithm adapts very quickly to highly non-stationary noise environments. This was confirmed with formal listening tests that indicated that our noise estimation algorithm when integrated in speech enhancement was preferred over other noise estimation algorithms. 1...|$|R
30|$|This paper {{seeks to}} improve CSP {{analysis}} in noisy environments {{with a special}} weighting algorithm. We assume the target sound source is a human speaker and the noise is broadband noise such as a fan, wind, or road noise in an automobile. Denda et al. proposed weighted CSP analysis using <b>average</b> <b>speech</b> spectrums as weights [7]. The assumption is that a subband with more <b>speech</b> <b>power</b> conveys more reliable information for localization. However, it {{did not use the}} harmonic structures of human speech. Because the harmonic bins must contain more <b>speech</b> <b>power</b> than the other bins, they should give us more reliable information in noisy environments. The use of harmonic structures for localization has been investigated in prior art [8, 9], but not for CSP analysis. This work estimated the pitches (F 0) of the target sound and extracted localization cues from the harmonic structures based on those pitches. However, the pitch estimation and the associated voiced-unvoiced classification may be insufficiently accurate in noisy environments. Also, {{it should be noted that}} not all harmonic bins have distinct harmonic structures. Some bins may not be in the speech formants and be dominated by noise. Therefore, we want a special weighting algorithm that puts larger weights on the bins where the harmonic structures are distinct, without requiring explicit pitch detection and voiced-unvoiced classification.|$|R
40|$|Recently, it {{has been}} shown that MMSE-based noise power estima-tion [1] results in an {{improved}} noise tracking performance with re-spect to minimum statistics-based approaches. The MMSE-based approach employs two estimates of the <b>speech</b> <b>power</b> to estimate the unbiased noise power. In this work, we improve the MMSE-based noise power estimator by employing a more advanced estimator of the <b>speech</b> <b>power</b> based on temporal cepstrum smoothing (TCS). TCS can exploit knowledge about the speech spectral structure. As a result, only one <b>speech</b> <b>power</b> estimate is needed for MMSE-based noise power estimation. Moreover, the presented estimator results in an improved noise tracking performance, especially in babble noise, where SNR improvements of 1 dB over the original MMSE-based approach can be observed. Index Terms — Noise <b>power</b> estimation, <b>speech</b> enhancement. 1...|$|R
5000|$|The Cato Institute is {{concerned}} that most proposed responses to Citizens United will give [...] "Congress unchecked new power over spending on political <b>speech,</b> <b>power</b> that will be certainly abused." ...|$|R
40|$|Distant-talking speech {{recognition}} in noisy environments is indis-pensable for self-moving robots or tele-conference systems. How-ever, background noise and room reverberations seriously degrade the sound-capture quality in real acoustic environments. A micro-phone array {{is an ideal}} candidate as an effective method for captur-ing distant-talking speech. AMNOR (Adaptive Microphone-array for NOise Reduction) was proposed as an adaptive beamformer for capturing the desired distant signals in noisy environments by Kaneda et al. Although the AMNOR has been proven effective, it can be further improved if we know the spectrum characteristics of the desired distant signals in advance. Therefore, we regarded speech as a desired distant signal and designed an AMNOR based on the <b>average</b> <b>speech</b> spectrum. In this paper, we particularly fo-cused {{on the performance of}} AMNOR based on the <b>average</b> <b>speech</b> spectrum for distant-talking speech capture and recognition. As a result of evaluation experiments in real acoustic environments, we confirmed that the ASR (Automatic Speech Recognition) perfor-mance was improved 5 – 10 % by using an AMNOR based on the <b>average</b> <b>speech</b> spectrum in noisy environments. In addition, the proposed AMNOR provides better noise reduction performance than that of conventional AMNOR. 1...|$|R
50|$|The Player is set of APIs (e.g. position2d, bumper, ir, <b>speech,</b> <b>power)</b> {{that can}} be {{implemented}} by a robot chassis (Roomba, Khephera etc.), possibly over serial line or network, or by Stage (2D simulator) or Gazebo (3D simulator).|$|R
40|$|Abstract—This paper explores a {{geometric}} {{framework for}} modeling non-stationary but slowly varying time series, {{based on the}} assumption that short-windowed power spectra capture their spectral character, and that energy transference in the frequency domain has a physical significance. The framework relies on certain notions of transportation distance and their respective geodesics to model possible non-parametric changes in the power spectral density with respect to time. We discuss the relevance of this framework to applications in spectral tracking, spectral <b>averaging,</b> and <b>speech</b> morphing. Index Terms—spectral metrics, geodesics, transportation distance, spectral analysis, spectral tracking, spectral <b>averaging,</b> <b>speech</b> morphing I...|$|R
50|$|Gorfs {{most notable}} feature is its robotic {{synthesised}} <b>speech,</b> <b>powered</b> by the Votrax speech chip. One {{of the first}} games to allow the player to buy additional lives before starting the game, Gorf allows the player to insert extra coins to buy up to seven starting lives.|$|R
5000|$|The [...] "Political Recoreda" [...] in 1987 was {{conducted}} in Iloilo City to drum up support for the Draft Constitution {{and at the same}} time the members distributed copies of the constitution and primers. <b>Speech</b> <b>power</b> of SABAKA members were heard when they spoke in rallies and symposia.|$|R
40|$|Enhancement {{algorithms}} {{are widely}} used to overcome the degra-dation of noisy speech signals. Most enhancement algorithms re-quire {{an estimate of the}} noise and noisy <b>speech</b> <b>power</b> spectra in order to compute the gain function used for the noise suppression. The variance of these power spectral estimates degrades the qual-ity of the enhanced signal and smoothing techniques are therefore often used to decrease the variance. In this paper we present a method to determine the noisy <b>speech</b> <b>power</b> spectrum based on an adaptive time segmentation. More specifically, the proposed al-gorithm determines for each noisy frame which of the surrounding frames should contribute to the corresponding noisy power spec-tral estimate. Objective and subjective experiments show that an adaptive time segmentation leads to significant performance im-provements, particularly in transitional speech regions. 1...|$|R
40|$|The {{ability of}} the Speech Transmission Index (STI) to predict speech {{intelligibility}} under noisy conditions is highly dependent on the assumed spectrum of the speech signal. Examination of the literature showed that the long-term <b>average</b> <b>speech</b> spectrum of male talkers differs substantially from the speech spectrum recommended for STI calculations (IEC 60268 - 16). To explore these issues, the long-term <b>average</b> <b>speech</b> spectrum of forty male British English people was first measured, compared with the available literature and proposed for STI calculations. Then, using several voice alarm systems, {{the influence of the}} measured spectrum on STI calculations was assessed and comparisons made with the standard speech spectrum. The results showed significant STI differences under noisy conditions and considerable reductions in the required electrical power {{with the use of the}} new proposed male spectrum. This indicated that the current STI method could benefit from a revised speech spectrum...|$|R
40|$|Abstract: This paper {{deals with}} the problem of {{checking}} the consistency of the speech corpus during recording in terms of the level of <b>speech</b> <b>power</b> of individual recordings. The question was whether or not setting of the limits of RMS value is useful for checking the volume consistency of recordings destinated for unit selection speech synthesis...|$|R
50|$|On {{the day of}} his 18th birthday, Billy {{attended}} a <b>Speech</b> <b>Power</b> Toastmasters course, and registered his first finance business called the Australian Credit Network. He pursued a career in finance for approximately 15 years, working as a broker, financial planner and corporate banker. In 2011, he was awarded Corporate Solutions Executive of the Year by The Commonwealth Bank.|$|R
40|$|Most {{approaches}} {{to the problem of}} source separation use the assumption of statistical independence. To capture statistical independence higher order statistics are required. In this chapter we will demonstrate how higher order criteria, such as maximum kurtosis, arise naturally from the property of non-stationarity. We will also show that source sepa-ration of non-stationary signals can be based entirely on second order statistics of the signals. Natural signals, be it images or time sequences, are for the most part non-stationary. For natural signals therefore we argue that non-stationarity is the fundamental property, from which speci c second or higher order separation criteria can be derived. We contrast the linear bases obtained using second order non-stationarity and ICA for the cases of natural images and <b>speech</b> <b>powers.</b> Based on these results we argue that <b>speech</b> <b>powers</b> can in fact be understood as a linear superposition of non-stationary spectro-temporal independen...|$|R
40|$|ICSLP 2002 : the 7 th International Conference on Spoken Language Processing, September 16 - 20, 2002, Denver, Colorado, USA. Recognition of distant-talking {{speech is}} {{indispensable}} for self-moving robots or teleconference systems. However, background noise and room reverberations seriously degrade the sound capture quality in real acoustic environments. A microphone array {{is an ideal}} candidate as an effective method for capturing distant-talking speech. AMNOR (Adaptive Microphone-array for NOise Reduction) was proposed an adaptive beamformer for capturing the desired distant signals in noisy environments by Kaneda et al. Although AMNOR has proven itself effective, it could be further improved if we knew the spectrum characteristics of desired distant signals in advance. Therefore, {{in this paper we}} regard speech as a desired distant signal and design AMNOR based on the <b>average</b> <b>speech</b> spectrum for distant-talking speech capture and recognition. As a result of evaluation experiments in real acoustic environments, we could confirm that the ASR (Automatic Speech Recognition) performance was improved 5 ~ 10 % by AMNOR based on <b>average</b> <b>speech</b> spectrum in noisy environments...|$|R
30|$|The MS [13] {{approach}} {{has been shown to}} be a reliable estimator of the noise PSD for moderately time-varying noise conditions. This approach relies on the assumption that the minimum of the noisy <b>speech</b> <b>power,</b> P_x̃(k,ℓ), over a short temporal sliding window is not affected by the speech. The noise PSD σ _ṽ^ 2 (k,ℓ) is then estimated by tracking the minimum of P_x̃(k,ℓ) over this sliding window, whose usual length corresponds to 1.5 s according to [13].|$|R
40|$|Abstract—Single-channel {{enhancement}} algorithms {{are widely}} used to overcome the degradation of noisy speech signals. Speech enhancement gain functions are typically computed from two quantities, namely, {{an estimate of the}} noise power spectrum and of the noisy <b>speech</b> <b>power</b> spectrum. The variance of these power spectral estimates degrades the quality of the enhanced signal and smoothing techniques are, therefore, often used to decrease the variance. In this paper, we present a method to determine the noisy <b>speech</b> <b>power</b> spectrum based on an adaptive time segmentation. More specifically, the proposed algorithm determines for each noisy frame which of the surrounding frames should contribute to the corresponding noisy power spectral estimate. Further, we demonstrate the potential of our adaptive segmentation in both maximum likelihood and decision direction-based speech enhancement methods by making a better estimate of the a priori signal-to-noise ratio (SNR). Objective and subjective experi-ments show that an adaptive time segmentation leads to significant performance improvements in comparison to the conventionally used fixed segmentations, particularly in transitional regions, where we observe local SNR improvements in the order of 5 dB. Index Terms—Adaptive time segmentation, a priori signal-to-noise ratio (SNR), decision directed approach, hypothesis test, speech enhancement. I...|$|R
30|$|The {{distances}} from different microphone positions {{to the mouth}} are 20 – 27 cm (Pos. 1), 28 cm (Pos. 2 / 3), and 58 cm (Pos. 4). All microphones are calibrated {{to have the same}} <b>speech</b> <b>power</b> at standstill. This comparison shows that at higher frequencies, the behavior of all microphones is almost similar, whereas at low and medium frequencies, the belt microphone outperforms conventional hands-free microphones. An improvement of up to 6 – 10 dB in SNR can be achieved.|$|R
50|$|It is {{a version}} sold by Orbit Research, {{designed}} {{for people with}} disabilities. It includes <b>speech</b> features. <b>Power</b> source comes from 9V battery instead of solar panel.|$|R
50|$|In audiology, the Articulation Index (AI) {{is a tool}} used {{to predict}} the amount of speech that is audible to a patient with a {{specific}} hearing loss. The AI figure for a given patient can range from zero to one, representing {{the proportion of the}} <b>average</b> <b>speech</b> signal that is audible. The closer the AI is to one, or 100 percent, the better the person should be able to hear speech. The calculation is also used in industrial settings for the design of safety devices, such as flight helmets, where audio signals are required to be clearly heard.|$|R
5000|$|Roman Jakobson {{described}} {{literature as}} [...] "organized violence committed on ordinary speech." [...] Literature constitutes a deviation from <b>average</b> <b>speech</b> that intensifies, invigorates, and estranges the mundane speech patterns. In other words, for the Formalists, literature is set apart {{because it is}} just that: set apart. The use of devices such as imagery, rhythm, and meter is what separates [...] "Ladies {{and gentlemen of the}} jury, exhibit number one is what the seraphs, the misinformed, simple, noble-winged seraphs, envied. Look at this tangle of thorns (Nabokov Lolita 9)", from [...] "the assignment for next week is on page eighty four." ...|$|R
40|$|In {{this paper}} we propose a new {{framework}} for utilizing frequency information from the short-term <b>power</b> spectrum of <b>speech.</b> Feature extraction is based on the cepstral coefficients derived from the histograms of subband spectral centroids (SSC). Two new feature extraction algorithms are proposed, one based on frequency information alone, and the other which efficiently combines the frequency and amplitude information from the <b>speech</b> <b>power</b> spectrum. Experimental study on an automatic speech recognition task has shown that the proposed methods outperform the conventional speech front-ends in presence of additive white noise, while they perform comparably in the noise-free conditions. 1...|$|R
40|$|In this paper, {{a speech}} signal {{recovery}} algorithm is presented for a personalized voice command automatic recognition system in vehicle and restaurant environments. This novel algorithm {{is able to}} separate a mixed speech source from multiple speakers, detect presence/absence of speakers by tracking the higher magnitude portion of <b>speech</b> <b>power</b> spectrum and adaptively suppress noises. An automatic speech recognition (ASR) process {{to deal with the}} multi-speaker task is designed and implemented. Evaluation tests have been carried out by using the speech da-tabase NOIZEUS and the experimental results show that the proposed algorithm achieves impres-sive performance improvements...|$|R
40|$|A {{practical}} {{speech enhancement}} system {{consists of two}} major components, the estimation of noise power spectrum, and the estimation of speech. In single channel speech enhancement systems, most algorithms require an estimation of average noise spectrum since a secondary channel is not available. This requires a reliable speech/silence detector. Thus the speech/silence detection can be a determining factor {{for the performance of}} the whole speech enhancement system. The speech/silence detection finds out the frames of the noisy speech that contain only noise. If the speech/silence detection is not accurate then speech echoes and residual noise tend to be present in the enhanced speech. The performance of noise estimation algorithm is usually a tradeoff between speech distortion and noise reduction. In existing methods, noise is estimated only during speech pauses and these pauses are identified using Voice Activity Detector (VAD). This paper describes novel noise estimation method to estimate noise in non-stationary environments. This approach uses an algorithm that classifies noisy speech signal into pure speech, quasi speech and non-speech frames based on adaptive thresholds without using of VAD. Speech presence is determined by computing the ratio of the noisy <b>speech</b> <b>power</b> spectrum to its local minimum, which is computed by averaging past values of the noisy <b>speech</b> <b>power</b> spectra with a look-ahead factor. To evaluate proposed method performance, segmental SNR as evaluation criteria and compared with weighted average noise estimation method. The simulation results of the proposed algorithm shows better performance than conventional methods...|$|R
40|$|We propose an {{algorithm}} {{for blind}} {{estimation of the}} magni-tude response of a channel using the observations of a single microphone. The algorithm employs channel robust RASTA filtered Mel-frequency cepstral coefficients as features and a Gaussian mixture model based classifier to generate a dictio-nary of <b>average</b> <b>speech</b> spectra. These are then used to infer the channel response from speech that has undergone spectral modification in the capturing process. Simulation results us-ing babble noise, car noise and white Gaussian noise are pre-sented, which demonstrate that the proposed method is able to estimate a variety of channel responses to within 3 − 4 dB in terms of weighted spectral distance; and it is more accurate than a previously published method. 1...|$|R
50|$|The final {{implementation}} {{replaced the}} integrator with a Predictor implemented with a two pole complex pair low-pass filter designed to approximate {{the long term}} <b>average</b> <b>speech</b> spectrum. The theory was that ideally the integrator should be a predictor designed to match the signal spectrum. A nearly perfect Shindler Compander replaced the modified version. It was found the modified compander resulted in a less than perfect step size at most signal levels and the fast gain error recovery increased the noise as determined by actual listening tests as compared to simple signal to noise measurements. The final compander achieved a very mild gain error recovery due to the natural truncation rounding error caused by twelve bit arithmetic.|$|R
40|$|In this paper, {{we propose}} a perceptually-motivated method for modifying the <b>speech</b> <b>power</b> {{spectrum}} {{to obtain a}} set of linear prediction coding (LPC) parameters that possess good noiserobustness properties in network speech recognition. Speech recognition experiments were performed to compare the accuracy obtained from MFCC features extracted from AMR-coded speech that use these modified LPC parameters, {{as well as from}} LPCCs extracted from AMR bitstream parameters. The results show that when using the proposed LP analysis method, the recognition performance was on average 1. 2 % - 6. 1 % better than when using the conventional LP method, depending on the recognition task. Griffith Sciences, Griffith School of EngineeringFull Tex...|$|R
40|$|This {{paper is}} to {{investigate}} the effectiveness of Prontest software to improve English pronunciation and proficiency for Japanese EFL learners. Several parameters such as <b>speech</b> duration, <b>speech</b> <b>power,</b> F 0 (pitch), the ratio of vowel and consonant length and power were introduced {{to find out how}} much students made progress in English pronunciation and overall English proficiency. The study concluded that the average score of CASEC computer test improved from 532 (SD 109. 2) in April to 583 (SD 83. 1) in July after having used this software for six lessons. The differences of parameters between pre and post-recorded readings indicated that this software helped students to improve English pronunciation. 1...|$|R
40|$|There {{has been}} an {{increase}} in use of noninvasive positive-pressure ventilators (NPPV) to provide breathing assistance to people who are limited in their ability to breathe on their own as a result of neuromuscular impairment. To date, essentially nothing is known about how NPPV inspirations are used to <b>power</b> <b>speech,</b> beginning with whether or not individuals actually use their NPPV device for the purposes of speech. This project aimed to quantify inspirations that <b>power</b> <b>speech</b> in users of NPPV, and the amount of speech that followed NPPV <b>powered</b> <b>speech.</b> While participants claimed that NPPV helped them speak, NPPV was found to power only 37...|$|R
40|$|The article {{explores the}} concept of {{censorship}} viewed as an integral attribute of any society. The authors describe censorship as a “social blindfold” intended to eliminate the implications triggered by the information warfare. Analyzing the modern regime of restrictions and constraints, the authors explore such relevant concepts as freedom of <b>speech,</b> <b>power,</b> mass media, stereotypes and manipulative technologies shaping an illusionary reality for the people. Censorship {{is described as a}} factor of information warfare which aims to filter the information through manipulation of individual and mass consciousness. Summing up the results of the study, the authors define the status and goals of censorship in modern society...|$|R
40|$|A {{reliable}} speech presence probability (SPP) estimator {{is important}} to many frequency domain speech enhancement algorithms. It is known that a good estimate of SPP {{can be obtained by}} having a smooth a-posteriori signal to noise ratio (SNR) function, which can be achieved by reducing the noise variance when estimating the <b>speech</b> <b>power</b> spectrum. Recently, the wavelet denoising with multitaper spectrum (MTS) estimation technique was suggested for such purpose. However, traditional approaches directly make use of the wavelet shrinkage denoiser which has not been fully optimized for denoising the MTS of noisy speech signals. In this paper, we firstly propose a two-stage wavelet denoising algorithm for estimating the <b>speech</b> <b>power</b> spectrum. First, we apply the wavelet transform to the periodogram of a noisy speech signal. Using the resulting wavelet coefficients, an oracle is developed to indicate the approximate locations of the noise floor in the periodogram. Second, we make use of the oracle developed in stage 1 to selectively remove the wavelet coefficients of the noise floor in the log MTS of the noisy speech. The wavelet coefficients that remained are then used to reconstruct a denoised MTS and in turn generate a smooth a-posteriori SNR function. To adapt to the enhanced a-posteriori SNR function, we further propose a new method to estimate the generalized likelihood ratio (GLR), which is an essential parameter for SPP estimation. Simulation results show that the new SPP estimator outperforms the traditional approaches and enables an improvement in both the quality and intelligibility of the enhanced speeches. Department of Electronic and Information Engineerin...|$|R
5000|$|... 1961. The Future of Catholic <b>Power</b> <b>Speech</b> to DAR, Am. United Sep. C & S ...|$|R
40|$|The {{concept of}} near end {{listening}} enhancement allows {{to improve the}} speech intelligibility of telecommunication de-vices {{in the presence of}} ambient background noise. It raises adaptively the <b>average</b> <b>speech</b> spectrum of the received sig-nal from the far end speaker over the average noise spectrum of the near end background noise, which leads to reduced listening efforts for the near end listener. In this paper, we will propose an improved algorithm for near end listening enhancement which uses a non-uniform filter-bank with Bark-scaled frequency bands. The em-ployed filter-bank has a significantly lower signal delay than commonly used non-uniform analysis-synthesis filter-banks. This allows to achieve a comparable speech intelligibility with low latency, which is of interest, e. g., for applications in mobile phones. ...|$|R
40|$|We propose and {{describe}} several methods for using <b>speech</b> <b>power</b> as {{an estimate of}} intentional loudness, and a mapping from this loudness estimate to a continuous control. This is performed {{in the context of}} a novel voice-based human-computer interface designed to enable individuals with motor impairments to use vocal tract parameters for both discrete and continuous control tasks. The interface uses vocal gestures to control continuous movement and discrete sounds for other events. We conduct a user preference survey to gauge user reaction to the various methods in a mouse cursor control context. We find that loudness is an effective mechanism to control mouse cursor movement speed when mapping vocalic gestures to spatial position. 1...|$|R
40|$|Abstract. In this paper, a noise {{estimator}} with rapid adaptation in a variable-level noisy environment is presented. To make noise estimation adapt quickly to highly non-stationary noise environments, a robust voice activity detector (VAD) is utilized {{in this paper}} and {{it depends on the}} variation of the spectral energy not on the amount of that. The noise power spectrum in subbands are estimated by averaging past spectral power values using a time and frequency dependent smoothing parameter, which is chosen as a sigmoid function changing with speech-present probability in subbands. The speech-present probability is determined by computing the ratio of the noisy <b>speech</b> <b>power</b> spectrum to its local minimum. Noise measurement, speech enhancement, spectral analysis, signal process. ...|$|R
