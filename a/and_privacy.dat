10000|10000|Public
5|$|American attitudes {{regarding}} government surveillance <b>and</b> <b>privacy,</b> constitutionally guaranteed {{rights to}} confront one's accuser in criminal prosecutions, and skepticism towards government power {{might also have}} a role in concerns about transportation safety in the United States.|$|E
5|$|Born in Pittsburgh, Pennsylvania, Paul {{attended}} Baylor University and is {{a graduate}} of the Duke University School of Medicine. Paul began practicing ophthalmology in 1993 in Bowling Green, Kentucky, and established his own clinic in December 2007. Throughout his life he volunteered for his father's campaigns. In 2010 he entered politics by running for a seat in the United States Senate. A Republican, Paul has described himself as a Constitutional conservative and a supporter of the Tea Party movement and has advocated for a balanced budget amendment, term limits, <b>and</b> <b>privacy</b> reform.|$|E
5|$|In 1955 Pei's group took a {{step toward}} {{institutional}} independence from Webb and Knapp by establishing a new firm called I.M. Pei & Associates. (The name changed later to I.M. Pei & Partners.) They gained the freedom to work with other companies, but continued working primarily with Zeckendorf. The new firm distinguished itself through the use of detailed architectural models. They took on the Kips Bay residential area {{on the east side of}} Manhattan, where Pei set up Kips Bay Towers, two large long towers of apartments with recessed windows (to provide shade <b>and</b> <b>privacy)</b> in a neat grid, adorned with rows of trees. Pei involved himself in the construction process at Kips Bay, even inspecting the bags of concrete to check for consistency of color.|$|E
50|$|CIHI {{ensures the}} confidentiality, {{integrity}} {{and availability of}} its health information through a comprehensive <b>and</b> integrated <b>privacy</b> <b>and</b> security program. Its <b>Privacy</b> <b>and</b> Security Framework outlines how the organization approaches data governance, <b>and</b> maintains <b>privacy</b> <b>and</b> security protection. CIHI enacts numerous policies and practices to prohibit personal identification, one key policy being strict levels of data suppression.|$|R
40|$|Security and {{efficiency}} are {{widely recognized as}} important requirements for query on encrypted data in the cloud environment. In this paper we propose efficient searchable symmetric encryption (named ESSE) schemes that support binary search and achieve both plaintext <b>privacy</b> <b>and</b> predicate <b>privacy.</b> Firstly, we present an idea that constructing a searchable symmetric encryption scheme that has capability of supporting binary search. Then we give a new framework for ESSE and its security definition to show that an ESSE scheme has both plaintext <b>privacy</b> <b>and</b> predicate <b>privacy</b> if the underlying symmetric-key predicateonly encryption scheme has both plaintext <b>privacy</b> <b>and</b> predicate <b>privacy.</b> Next, we propose a general construction with SKPOE scheme supporting inner product queries, where the class of predicates to be F = {fy|y 2 ⌃} with fy(x) = 1 i ↵ hx, yi = 0. Finally, we propose a concrete construction on the groups of prime order, which achieves both plaintext <b>privacy</b> <b>and</b> predicate <b>privacy</b> under d-linear assumption. Our initial experimental results show that ESSE schemes are more efficient for query on encrypted indices in the cloud environment...|$|R
5000|$|... complex {{questions}} of <b>privacy</b> <b>and</b> access and ownership. (user control, <b>privacy</b> <b>and</b> trust) ...|$|R
5|$|Morrison {{moved back}} to Europe in the late 1970s, first {{settling}} in London's Notting Hill Gate area. Later, he moved to Bath, where he purchased the Wool Hall studio in January 1994. He also has {{a home in the}} Irish seaside village of Dalkey near Dublin, where legal actions against two different neighbours concerning safety <b>and</b> <b>privacy</b> issues have been taken to court in 2001 and in 2010. In the former case, Morrison pursued his action {{all the way to the}} Irish Supreme Court.|$|E
5|$|Once {{patients}} {{reach their}} teens, {{they need more}} specific information about pregnancy, birth control, self-esteem, and dating. Teenagers with lost or reduced genital sensation benefit from education about alternative ways to experience pleasure and satisfaction from sexual acts. The teen years are often particularly difficult for those with SCI, in terms of body image and relationships. Given the importance they place on sexuality <b>and</b> <b>privacy,</b> adolescents may experience humiliation when parents or caregivers bathe them or take care of bowel and bladder needs. They can benefit from sexuality counseling, support groups, and mentoring by adults with SCI who can share experiences and lead discussions with peers. With the right care and education from family and professionals, injured children and adolescents can develop into sexually healthy adults.|$|E
5|$|Related to privacy, the ACLU {{engaged in}} several battles {{to ensure that}} {{government}} records about individuals were kept private, and to give individuals the right to review their records. The ACLU supported several measures, including the 1970 Fair Credit Reporting Act required credit agencies to divulge credit information to individuals; the 1973 Family Educational Rights <b>and</b> <b>Privacy</b> Act, which provided students the right to access their records; and the 1974 Privacy Act which prevented the federal government from disclosing personal information without good cause.|$|E
40|$|Abstract. Federated {{identity}} management allows a user to efficiently authenticate and use identity information from data distributed across multiple domains. The sharing of data across domains blurs security boundaries <b>and</b> potentially creates <b>privacy</b> risks. We examine <b>privacy</b> risks <b>and</b> fundamental <b>privacy</b> protections of federated identity-management systems. The protections include minimal disclosure and providing PII {{only on a}} “need-to-know ” basis. We then look at the Liberty Alliance system <b>and</b> analyze previous <b>privacy</b> critiques of that system. We show how law <b>and</b> policy provide <b>privacy</b> protections in federated identitymanagement systems, <b>and</b> that <b>privacy</b> threats are best handled {{using a combination of}} technology and law/policy tools...|$|R
50|$|This act {{established}} {{both the}} position of Director of National Intelligence (DNI), the National Counterterrorism Center (NCTC), <b>and</b> the <b>Privacy</b> <b>and</b> Civil Liberties Oversight Board.|$|R
5000|$|Googles `privacy {{by design}} {{protocols}} in various areas, like: {{data collection and}} its dynamic presentation, employing differential <b>privacy,</b> <b>and</b> beacons <b>privacy</b> based on Ephemeral IDs.|$|R
5|$|In May 2007, the TSB {{released}} {{copies of}} the audio recordings of the air traffic control transmissions associated with the flight. The transcripts of these recordings had been released in 1998 (within days of the crash), but the TSB had refused to release the audio on privacy grounds. The TSB argued that under Canada's Access to Information Act <b>and</b> <b>Privacy</b> Act, the audio recordings constituted personal information and were thus not disclosable. Canada's Federal Court of Appeal rejected this argument in 2006 in a legal proceeding concerned with air traffic control recordings in four other air accidents. The Supreme Court of Canada did not grant leave to appeal that decision and consequently the TSB released {{a copy of the}} Swissair 111 air traffic control audio recordings to the Canadian Press, which had requested the recordings under the Access to Information Act. Several key minutes of the air traffic control audio {{can be found on the}} Toronto Star web site.|$|E
5|$|Leading {{off from}} the Great Hall are the family's private Drawing Room and Parlour. In the 16th and early 17th centuries, in a house such as Montacute, the Parlour was where the family would dine, {{possibly}} with some of their upper servants. It allowed them not only privacy from dining publicly in the hall, but also less state and pomp than if dining in the Great Chamber above. Like its grander cousin above, the Parlour also had an adjoining principal bed chamber, now the Drawing Room, originally known as the White Chamber and later as the Round Parlour. As fashions and uses changed, <b>and</b> <b>privacy</b> from servants became desirable, like the later Baroque state apartments, these ground-floor rooms lost their original purpose and became a series of seemingly meaningless drawing rooms. The National Trust installed an incongruous 18th-century fireplace from Coleshill House in the Drawing Room in the mid-20th century. It is now furnished in 18th-century style.|$|E
5|$|Many {{recently}} developed SGDs include performance measurement and analysis tools to help monitor the content used by an individual. This raises concerns about privacy, and {{some argue that}} the device user {{should be involved in}} the decision to monitor use in this way. Similar concerns have been raised regarding the proposals for devices with automatic content generation, <b>and</b> <b>privacy</b> is increasingly a factor in design of SGDs. As AAC devices are designed to be used in all areas of a user’s life, there are sensitive legal, social, and technical issues centred on a wide family of personal data management problems that can be found in contexts of AAC use. For example, SGDs may have to be designed so that they support the user's right to delete logs of conversations or content that has been added automatically.|$|E
40|$|This thesis {{provides}} {{an analysis of}} <b>privacy</b> <b>and</b> security controls for internet-connected data-driven systems, known as the Internet of Things (IoT). The grounding theory is that numerous pre-existing <b>privacy</b> <b>and</b> security control methods [...] not necessarily crafted for IoT [...] will bear {{on the future of}} IoT <b>privacy</b> <b>and</b> security. This thesis covers fifteen case studies across six different control categories: Individual Choice, Command and Control Regulations, Operational Standards, Technical Standards, Compliance Frameworks, and Federal Authorities. These case studies reveal major deficiencies in current IoT <b>privacy</b> <b>and</b> security controls. IoT <b>privacy</b> <b>and</b> security controls lack a domain or contextual-use focus. Further, most current controls also fail to specify the risks or harms they intend to resolve. Therefore, the current IoT <b>privacy</b> <b>and</b> security controls induce a significant <b>privacy</b> <b>and</b> security market failure. This market failure is evident in recent IoT <b>privacy</b> <b>and</b> security events such as the Federal Trade Commission's cases against the IoT system developers TRENDnet and D-Link. I define three necessary paradigm shifts needed to improve IoT <b>privacy</b> <b>and</b> security controls. I also recommend a specific research endeavor to develop domain-, risk-, <b>and</b> harms-centric <b>privacy</b> <b>and</b> security standards. The realization of these paradigm shifts, and the products from this research endeavor, will navigate the IoT ecosystem towards more effective <b>privacy</b> <b>and</b> security control. by Brandon Allan Karpf. Thesis: S. M. in Technology and Policy, Massachusetts Institute of Technology, School of Engineering, Institute for Data, Systems, and Society, Technology and Policy Program, 2017. This electronic version was submitted by the student author. The certified thesis is available in the Institute Archives and Special Collections. Cataloged from student-submitted PDF version of thesis. Includes bibliographical references (pages 201 - 218) ...|$|R
50|$|BCRs {{should be}} seen as a {{framework}} having different elements (Internal legal agreement, Policies, training, audit, etc.) providing compliance with EU data protection regulations <b>and</b> effective <b>privacy</b> <b>and</b> data protection.|$|R
50|$|In 2010-2011, {{she was a}} Fellow at the Radcliffe Institute for Advanced Study at Harvard, {{where she}} {{investigated}} issues involving security of government systems, <b>and</b> their <b>privacy</b> <b>and</b> policy implications.|$|R
25|$|High {{security}} <b>and</b> <b>privacy.</b>|$|E
25|$|The law of defamation, {{trespass}} <b>and</b> <b>privacy</b> {{is governed}} at the provincial level.|$|E
25|$|Intel Security Cyber{{security}} exhibition. Online security <b>and</b> <b>privacy</b> in the 21st Century.|$|E
5000|$|International Standard for Protection of <b>Privacy</b> <b>and</b> Personal Information. (<b>Privacy</b> protections when {{collecting}} and using athlete personal information.) ...|$|R
5000|$|An {{extensive}} {{series of}} fact sheets on privacy issues, available in English {{and some in}} Spanish. Subject areas include basic privacy information, computer security and data breaches, technology <b>and</b> online <b>privacy,</b> identity theft, banking and finance, credit reports, debt collection, telephone privacy, junk mail, junk faxes <b>and</b> spam, medical <b>privacy,</b> insurance, Social Security Numbers, workplace issues including background checks <b>and</b> employment <b>privacy,</b> public <b>and</b> government records, education, harassment, stalking, etc.|$|R
40|$|The 1 st International Workshop on <b>Privacy</b> <b>and</b> Security of Big Data (PSBD 2014) focuses the {{attention}} on <b>privacy</b> <b>and</b> security research {{issues in the}} context of Big Data, a vibrant and challenging research context which is playing {{a leading role in the}} Database research community. Indeed, while Big Data is gaining {{the attention}} from the research community, also driven by some relevant technological innovations (like Clouds) as well as novel paradigms (like social networks), the issues of <b>privacy</b> <b>and</b> security of Big Data represent a fundamental problem in this research context, due to the fact Big Data are typically published online for supporting knowledge management and fruition processes and, in addition to this, such data are usually handled by multiple owners, with possible secure multi-part computation issues. Some of the hot topics in the context <b>privacy</b> <b>and</b> security of Big Data include: (i) <b>privacy</b> <b>and</b> security of Big Data integration <b>and</b> exchange; (ii) <b>privacy</b> <b>and</b> security of Big Data in data-intensive Cloud computing; (iii) system architectures in support of <b>privacy</b> <b>and</b> security of Big Data, e. g., GPUs: (iv) <b>privacy</b> <b>and</b> security issues of Big Data querying and analysis. These topics are first-class aspects to be addressed and investigated by PSBD 2014. These proceedings contain the papers selected for presentation at the workshop. We received 12 submissions from countries in North America, Europe and Asia. After careful review, the program committee selected 5 papers for presentation at the workshop. The accepted papers were presented in 2 sessions: scalable privacy-preserving and security-control methods for Big Data processing, user-oriented <b>and</b> data-oriented <b>privacy</b> methods for Big Data processing. A panel discussed advanced aspects of <b>privacy</b> <b>and</b> security of Big Data. We hope that these proceedings will serve as a valuable reference for researchers and practitioners focusing on <b>privacy</b> <b>and</b> security of Big Data...|$|R
25|$|In 2006, he {{debated the}} {{architect}} of the Patriot Act, Viet Dinh, on terrorism <b>and</b> <b>privacy</b> issues.|$|E
25|$|Common {{concerns}} about genealogical DNA testing are cost <b>and</b> <b>privacy</b> issues. Some testing companies retain samples and results {{for their own}} use without a privacy agreement with subjects.|$|E
25|$|Comodo Dragon is a rebranded {{version of}} Chromium for 32-bit Windows 8.1, 8, Windows 7 and Vista {{produced}} by the Comodo Group. According to the developer, it provides improved security <b>and</b> <b>privacy</b> features.|$|E
40|$|We {{focus here}} on two secure {{biometric}} systems (a common randomness based scheme and a fuzzy commitment scheme) <b>and</b> discuss their <b>privacy</b> preserving properties. We derive bounds on the privacy leakage in these schemes. We also show {{the relation between}} employed error-correction and leakage on biometric information, <b>and</b> between <b>privacy</b> <b>and</b> security for the fuzzy commitment scheme...|$|R
40|$|The {{first part}} of this paper is about the notion of (information) <b>privacy</b> <b>and</b> its {{grounding}} in law. It discusses the tension between the right to <b>privacy</b> <b>and</b> the right to receive information. The second part of this paper explores how (mobile) ICTs challenge <b>and</b> complicate <b>privacy</b> claims <b>and</b> satisfy the right to receive information. [URL]...|$|R
40|$|Publishing a {{database}} instance containing individual information poses {{two kinds of}} privacy risk: presence leakage, by which the attackers can explicitly identify individuals in (or not in) the database, and association leakage, by which the attackers can unambiguously associate individuals with sensitive information. However, the existing privacy-preserving data publishing techniques that can protect both presence <b>privacy</b> <b>and</b> association <b>privacy</b> have considerable amounts of information loss, while the techniques that produce better utility fail to protect the presence privacy. In this paper, we propose a novel technique, ambiguity, to protect both presence <b>privacy</b> <b>and</b> association <b>privacy</b> with low information loss. We formally define the <b>privacy</b> model <b>and</b> quantify the <b>privacy</b> guarantee of our ambiguity technique against both presence leakage and association leakage. We investigate the information loss of the ambiguity technique and theoretically prove that it always has less information loss than the generalization-based techniques. We accompany the theory with an efficient algorithm that constructs the ambiguity scheme that provides sufficient protection of both presence <b>privacy</b> <b>and</b> association <b>privacy</b> with low information loss. Extensive experiments demonstrate that compared with generalization approach, our ambiguity technique always achieves better accuracy of data analysis. ...|$|R
25|$|During his brother's 2008 presidential campaign, Malik Obama was a {{spokesman}} for the extended Obama family in Kenya. He dealt with safety <b>and</b> <b>privacy</b> concerns arising from the increased attention from the press.|$|E
25|$|Compliance Strategy Group (Kiedrowski's Report) {{conducted}} an independent {{review of the}} adoption and use of Conducted Energy Weapons by the Royal Canadian Mounted Police in June 2008 and released under the Access to Information <b>and</b> <b>Privacy</b> Act.|$|E
25|$|U.S. {{information}} privacy legislation such as HIPAA and the Family Educational Rights <b>and</b> <b>Privacy</b> Act (FERPA) {{applies only}} to the specific areas that each such law addresses. Use of data mining {{by the majority of}} businesses in the U.S. is not controlled by any legislation.|$|E
40|$|Thesis (Ph. D.) [...] University of Washington, 2013 Designers {{who create}} user {{interfaces}} are frequently required to ask users for personal information. For the user, {{this is a}} "trust question": Do I, the user, trust the system or entity that is asking me for this information? The creation and management of these trust questions is {{an important aspect of}} the research field called usable <b>privacy</b> <b>and</b> security. However, most working designers do not focus exclusively on usable <b>privacy</b> <b>and</b> security problems. Decomposition and modularity of trust <b>and</b> usable <b>privacy</b> <b>and</b> security issues are problematic for working designers. Studies in the usable <b>privacy</b> <b>and</b> security field have traditionally focused on the usability of specific interface elements, or on a specific usable <b>privacy</b> <b>and</b> security problem. This dissertation explores how designers approach and handle these trust questions in their design process. A multi-modal study investigates how designers conceive of usable <b>privacy</b> <b>and</b> security in their daily work. The object of study is a working designer for whom <b>privacy</b> <b>and</b> security is not a primary task in their daily job. The study uses a survey based on a snowball sample of professional design online forums and semi-structured interviews to explore the attitudes and conceptual models of designers who produce designs involving "trust questions. " The results showed that working designers are interested in usable <b>privacy</b> <b>and</b> security issues but often have problems decomposing and modularizing the problem space of usable <b>privacy</b> <b>and</b> security. Usable <b>privacy</b> <b>and</b> security problems are seen as important in the abstract but are hard to identify and engage as part of day-to-day work. To reach the shared goal of making it easy for working designers to achieve positive usable <b>privacy</b> <b>and</b> security outcomes including an increased sense of user satisfaction and safety, it will be important for the research community to find ways to assist working designers with that decomposition and modularization process...|$|R
5000|$|Communication with {{authentication}} <b>and</b> without <b>privacy</b> (AuthNoPriv).|$|R
3000|$|Complement laws <b>and</b> {{regulations}} on <b>privacy</b> <b>and</b> data protection, {{as well as}} codes for the ethical governance of research; [...]...|$|R
