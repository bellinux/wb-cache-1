3|428|Public
40|$|We {{introduce}} a deep scattering network, which computes invariants with iterated con-tractions adapted to training data. It defines a deep convolution network model, whose contraction properties {{can be analyzed}} mathematically. A cascade of wavelet transform convolutions are computed with a multirate filter bank, and adapted with permutations. Unsupervised learning of permutations optimize the contraction directions, by maxi-mizing the average discriminability of training data. For Haar wavelets, it is solved with a polynomial complexity pairing <b>algorithm.</b> <b>Translation</b> and rotation invariance learning is shown with classification experiments on hand-written digits. ...|$|E
40|$|According to IEC 61131 - 3 norm, {{controllers}} {{and distributed}} control systems can be programmed in textual and graphical languages. In many scenarios using a graphical language is preferred by the user, because diagrams can be more legible and easier to understand or modify also by {{people who do not}} have strong programming skills. What is more, they can be attached to the documentation to present a part of a system implementation. CPDev is an engineering environment that makes possible to program PLCs, PACs, softPLCs and {{distributed control systems}} with the usage of languages defined in IEC 61131 - 3 norm. In earlier versions, it supported only textual languages - ST and IL. Currently, graphics editors for FBD, LD and SFC languages are also available, so users can choose a suitable language depending on their skills and a specificity of a program that they have to prepare. The article presents implementation of the graphics editors, made by the author, which support creating program organization units in all graphical languages defined in IEC 61131 - 3 norm. They are equipped with a set of basic and complex functionalities to provide an easy and intuitive way of creating programs, function blocks and functions with visual programming. In the article the project structure and some important mechanisms are described. They include e. g. automatic connections finding (with A* <b>algorithm),</b> <b>translation</b> to ST code, conversion to and from XML format and an execution mode supporting multiple data sources and breakpoints...|$|E
40|$|Discriminative training, a. k. a. tuning, is an {{important}} part of Statistical Machine Translation. This step optimises weights for the several statistical models and heuristics used in a machine translation system, in order to balance their relative effect on the translation output. Different weights lead to significant changes in the quality of translation outputs, and thus selecting appropriate weights is of key importance. This thesis addresses three major problems with current discriminative training methods in order to improve translation quality. First, we design more accurate automatic machine translation evaluation metrics that have better correlation with human judgements. An automatic evaluation metric is used in the loss function in most discriminative training methods, however what the best metric is for this purpose is still an open question. In this thesis we propose two novel evaluation metrics that achieve better correlation with human judgements than the current de facto standard, the BLEU metric. We show that these metrics can improve translation quality when used in discriminative training. Second, we design an algorithm to select sentence pairs for training the discriminative learner from large pools of freely available parallel sentences. These resources tend to be noisy and include translations of varying degrees of quality and suitability for the translation task at hand, especially if obtained using crowdsourcing methods. Nevertheless, they are crucial when professionally created training data is scarce or unavailable. There is very little previous research on the data selection for discriminative training. Our novel data selection algorithm does not require knowledge of the test set nor uses decoding outputs, and is thus more generally useful and efficient. Our experiments show that with this data selection <b>algorithm,</b> <b>translation</b> quality consistently improves over strong baselines. Finally, the third component of the thesis is a novel weighted ranking-based optimisation algorithm for discriminative training. In contrast to previous approaches, this technique assigns a different weight to each training instance according to its reachability and its relationship to test sentence being decoded, a form of transductive learning. Our experimental results show improvements over a modern state-of-the-art method across different language pairs. Overall, the proposed approaches lead to better translation quality when compared strong baselines in our experiments, both in isolation and when combined, and can be easily applied to most existing statistical machine translation approaches. ...|$|E
40|$|We {{consider}} {{the efficiency of}} queries generated by XML to SQL translation. We first show that published XML-to-SQL query <b>translation</b> <b>algorithms</b> are suboptimal in that they often translate simple path expressions into complex SQL queries even when much simpler equivalent SQL queries exist. There are two logical {{ways to deal with}} this problem. One could generate suboptimal SQL queries using a fairly naive <b>translation</b> <b>algorithm,</b> and then attempt to optimize the resulting SQL; or one could use a more intelligent <b>translation</b> <b>algorithm</b> with the hopes of generating efficient SQL directly. We show that optimizing the SQL after it is generated is problematic, becoming intractable even in simple scenarios; by contrast, designing a <b>translation</b> <b>algorithm</b> that exploits information readily available at translation time is a promising alternative. To support this claim, we present a <b>translation</b> <b>algorithm</b> that exploits <b>translation</b> time information to generate efficient SQL for path expression queries over tree schemas. ...|$|R
40|$|Abstract. In recent years, brain-computer {{interface}} (BCI) technology has emerged very rapidly. Brain-computer interfaces (BCIs) bring {{us a new}} communication interface technology which can translate brain activities into control signals of devices like computers, robots. The preprocessing of electroencephalographic (EEG) signal and <b>translation</b> <b>algorithms</b> {{play an important role}} in EEG-based BCIs. In this study, we employed an independent component analysis (ICA) -based preprocessing method and a committee machine-based <b>translation</b> <b>algorithm</b> for the offline analysis of a cursor control experiment. The results show that ICA is an efficient preprocessing method and the committee machine is a good choice for <b>translation</b> <b>algorithm.</b> ...|$|R
40|$|This paper {{presents}} {{several new}} results for game theory. The results {{have in common}} {{that they have been}} obtained from the literature on (probability theory and) decision making under uncertainty by simple <b>translation</b> <b>algorithms,</b> mainly by replacing "state of nature" by "player. " The aim {{of this paper is to}} show the usefulness of such <b>translation</b> <b>algorithms...</b>|$|R
40|$|This paper {{presents}} {{a brief description}} of the current work on a tool that analyses temporal behavior of Ada/RavenSPARK programs and, with the use of a <b>translation</b> <b>algorithm,</b> outputs an Uppaal system that simulates the program’s control flow. The focus will be the <b>translation</b> <b>algorithm,</b> it’s implementation and syntactic scope, along with results and difficulties encountered during the development process. ...|$|R
40|$|Abstract — Many {{computer}} vision tasks require interest point detection and description, such as real-time visual navigation. We present a GPU {{implementation of the}} recently proposed Speeded-Up Robust Feature extractor [1], currently {{the state of the}} art for this task. Robust feature descriptors can give vast improvements in the quality and speed of subsequent steps, but require intensive computation up front that is well-suited to inexpensive graphics hardware. We describe the <b>algorithm’s</b> <b>translation</b> to the GPU in detail, with several novel optimizations, including a new method of computing multi-dimensional parallel prefix sums. It operates at over 30 Hz at HD resolutions with thousands of features and in excess of 70 Hz at SD resolutions. I...|$|R
40|$|The paper {{proposes a}} new <b>translation</b> <b>algorithm</b> that {{translates}} a hybrid system {{described as a}} discrete hybrid automaton (DHA) into an equivalent piecewise affine (PWA) system. The <b>translation</b> <b>algorithm</b> exploits, among others, a new technique for cell enumeration in hyperplane arrangement, all proposed in this paper. The new translation technique enables the transfer of several analysis and synthesis tools developed for PWA systems to a DHA class of hybrid systems...|$|R
40|$|We {{investigate}} {{the utility of}} an <b>algorithm</b> for <b>translation</b> lexicon acquisition (SABLE), used previously on a very large corpus to acquire general translation lexicons, when that algorithm is applied to a much smaller corpus to produce candidates for domain-specific translation lexicons. Comment: 8 page...|$|R
40|$|AbstractWe {{present an}} {{efficient}} solution method for packing d-dimensional polytopes {{within the bounds}} of a polytope container. The central geometric operation of the method is an exact one-dimensional translation of a given polytope to a position which minimizes its volume of overlap with all other polytopes. We give a detailed description and a proof of a simple algorithm for this operation in which one only needs to know the set of (d− 1) -dimensional facets in each polytope. Handling non-convex polytopes or even interior holes is a natural part of this <b>algorithm.</b> The <b>translation</b> <b>algorithm</b> is used as part of a local search heuristic and a meta-heuristic technique, guided local search, is used to escape local minima. Additional details are given for the three-dimensional case and results are reported for the problem of packing polyhedra in a rectangular parallelepiped. Utilization of container space is improved by an average of more than 14 percentage points compared to previous methods. The <b>translation</b> <b>algorithm</b> {{can also be used to}} solve the problem of maximizing the volume of intersection of two polytopes given a fixed translation direction. For two polytopes with complexity O(n) and O(m) and a fixed dimension, the running time is O(nmlog(nm)) for both the minimization and maximization variants of the <b>translation</b> <b>algorithm...</b>|$|R
40|$|SNMPv 3 {{supports}} authentication, condentiality {{and access}} control. Ac-cess control {{is based on}} MIB views, which {{makes it possible to}} have ne grained control over who accesses what in the MIB. Dierent users can be given dierent access rights. However, as the number of users increase, it be-comes very dicult to keep control over all the dierent access rights. MIB View Modeling Language is a graphical language that provides a tool for easy specication of MIB views. It is a hierarchical language that provides mech-anisms for supporting a large number of dierent users and MIB views. An <b>algorithm,</b> MVML <b>Translation</b> <b>Algorithm,</b> translates the graphical diagrams into MIB values {{that can be used to}} congure the managed entities. ...|$|R
40|$|Abstract. We present <b>{{algorithms}}</b> for the <b>translation</b> of statecharts to the AbstractMachine Notation of the B method. These algorithms {{have been}} implemented in iState, a tool for translating statecharts to various programming languages. Thetranslation proceeds in several phases. We give a model of statecharts, {{a model of the}} code in AMN, as well as the intermediate representations in terms of class di-agrams and their textual counterpart. The <b>translation</b> <b>algorithms</b> are expressed in terms of these models. We also discuss optimizations of the generated code. Thetranslation scheme is motivated by making the generated code comprehensible...|$|R
40|$|An {{approach}} {{to the problem of}} translation of algebraic programs into executable codes is presented. In particular, an <b>algorithm</b> for <b>translation</b> of algebraic programs represented in the language Aplan into C codes is proposed. An algorithm of reconstruction of types in Aplan is considered that also checks the absence of features used for dynamic specification of procedures in a code...|$|R
40|$|AbstractWe {{present a}} new {{variant of the}} Earley parsing {{algorithm}} capable of efficiently supporting context-free grammars with regular right hand-sides. We present the core state-machine driven <b>algorithm,</b> the <b>translation</b> of grammars into state machines, and the reconstruction algorithm. We also include a theoretical framework for presenting the algorithm and for evaluating optimizations. Finally, we evaluate the algorithm by testing its implementation...|$|R
40|$|Recent {{successful}} {{applications of}} AI planning technology have highlighted the knowledge engineering of planning domain models {{as an important}} research area. We describe a prototype implementation of a <b>translation</b> <b>algorithm</b> between two languages used in planning representation: PDDL, a language used for communication of example domains between research groups, and OCL h, a language developed specifically for planning domain modelling. The <b>translation</b> <b>algorithm</b> {{has been used as}} part of OCL h 's tool support to import models expressed in PDDL to OCL h 's environment. In this paper we detail the <b>translation</b> <b>algorithm</b> between the two languages, and discuss the issues that it uncovers. The tool performs well when its output is measured against hand-crafted OCL h models, but more importantly, we show how it has helped uncover insecurities in PDDL encodings. 1 Introduction Despite many years of research into AI Planning and Scheduling, knowledge engineering for applications of AI Plannin [...] ...|$|R
50|$|In {{the study}} an {{algorithm}} for automatic SysML views generation from an OPM model {{was developed and}} applied. For each SysML view, a mapping scheme from OPM elements to SysML elements constitutes {{the foundation for the}} OPM-toSysML sub <b>algorithm</b> and <b>translation</b> engine application. The mappings are partial and do not utilize all the available language elements. The software implementation was OPCAT, the OPM-supporting modeling tool.|$|R
40|$|The study {{evaluates the}} {{accuracy}} of determining coordinates of a corner of a building measured in the RTN GNSS mode (Real Time Network Global Navigation Satellite System) using the method of line-line intersection and having applied the <b>algorithm</b> of vector <b>translation,</b> developed by the author. The performed analysis of accuracy proved a high precision in determining the points subjected to studies. An {{important factor in the}} formation of a mean error regarding the position of the corner of a building, having used the <b>algorithm</b> of vector <b>translation,</b> is the assumption of correctness of the reference points, i. e. the so-called base points, determined in the RTN GNSS mode. In this case, the base points take the role of measurement control points. The mean error of the position of the corner of a building, taking into account the innovative solution, is at the level of several centimeters. The study results presented in the article allow to positively evaluate the <b>algorithm</b> of vector <b>translation</b> in terms of accuracy of determining the position of a corner of a building, measured in real time...|$|R
50|$|Large corpora used as {{training}} sets for machine <b>translation</b> <b>algorithms</b> are usually extracted from large bodies of similar sources, such as databases of news articles {{written in the}} first and second languages describing similar events.|$|R
40|$|Static Single Assignment form is an {{intermediate}} representation, that uses -functions to merge values at each confluent {{points of the}} control flow graph. functions are not machine instructions and should be renamed back to move operations when translating out-of-SSA form. Without a coalescing <b>algorithm,</b> out-of-SSA <b>translation</b> generates many move instructions. In this paper we propose {{an extension of the}} algorithm of Leung and George [7] to minimize the -related copies during the out-of-SSA translation...|$|R
40|$|Abstract Peers in a {{peer-to-peer}} {{data management}} system often have heterogeneous schemas and no mediated global schema. To translate queries across peers, we assume each peer provides correspondences between its schema {{and a small}} number of other peer schemas. We focus on query reformulation in the presence of heterogeneous XML schemas, including data–metadata conflicts. We develop an algorithm for inferring precise mapping rules from informal schema correspondences. We define the semantics of query answering in this setting and develop query <b>translation</b> <b>algorithm.</b> Our <b>translation</b> handles an expressive fragment of XQuery and works both along and against the direction of mapping rules. We describe the HePToX heterogeneous P 2 P XML data management system which incorporates our results. We report the results of extensive experiments on HePToX on both synthetic and real datasets. We demonstrate our system utility and scalability on different P 2 P distributions...|$|R
40|$|We {{present a}} new {{variant of the}} Earley parsing {{algorithm}} capable of efficiently supporting context-free grammars with regular right hand-sides. We present the core state-machine driven <b>algorithm,</b> the <b>translation</b> of grammars into state machines, and the reconstruction algorithm. We also include a theoretical framework for presenting the algorithm and for evaluating optimizations. Finally, we evaluate the algorithm by testing its implementation. Key words: Context-free grammars, Earley parsing, regular right sides, scannerless parsing, transducers, augmented transition networks...|$|R
40|$|The work {{deals with}} the {{automated}} translation of a natural language to temporal logic. Existing research attempts are summarized and built upon. For specificating the temporal properties a subset of English is introduced. The main contribution {{of the work is}} the proposed <b>algorithm</b> of <b>translation</b> of a property in the given language to LTL temporal logic, based on processing of and finding patterns in grammatical dependencies of The Stanford English Parser. Future research directions are discussed at the end...|$|R
40|$|AbstractPurposeTo {{elevate the}} level of care to the {{community}} {{it is essential to}} provide usable tools for healthcare professionals to extract knowledge from clinical data. In this paper a generic <b>translation</b> <b>algorithm</b> is proposed to translate a restricted natural language query (RNLQ) to a standard query language like SQL (Structured Query Language). MethodsA special purpose clinical data analytics language (CliniDAL) has been introduced which provides scheme of six classes of clinical questioning templates. A <b>translation</b> <b>algorithm</b> is proposed to translate the RNLQ of users to SQL queries based on a similarity-based Top-k algorithm which is used in the mapping process of CliniDAL. Also a two layer rule-based method is used to interpret the temporal expressions of the query, based on the proposed temporal model. The mapping and <b>translation</b> <b>algorithms</b> are generic and thus able to work with clinical databases in three data design models, including Entity-Relationship (ER), Entity–Attribute–Value (EAV) and XML, however it is only implemented for ER and EAV design models in the current work. ResultsIt is easy to compose a RNLQ via CliniDAL’s interface in which query terms are automatically mapped to the underlying data models of a Clinical Information System (CIS) with an accuracy of more than 84 % and the temporal expressions of the query comprising absolute times, relative times or relative events can be automatically mapped to time entities of the underlying CIS and to normalized temporal comparative values. ConclusionThe proposed solution of CliniDAL using the generic mapping and <b>translation</b> <b>algorithms</b> which is enhanced by a temporal analyzer component provides a simple mechanism for composing RNLQ for extracting knowledge from CISs with different data design models for analytics purposes...|$|R
40|$|We {{propose a}} {{rule-based}} approach for transforming B abstract machines into UML diagrams. We believe that important {{insight into the}} structure underlying a B model can be gained by representing it in UML, for example in order to explain the model to stakeholders that are not experts in the B formalism. We focus on the generation of class diagram and state machines. Our approach does not prescribe a mechanic <b>algorithm</b> for <b>translation,</b> giving the modeler choices to adapt the resulting UML models as appropriate...|$|R
40|$|Design and CFD {{analysis}} of gerotor with multiple profiles (ellipse–involute–ellipse type and 3 -ellipses type) using rotation and <b>translation</b> <b>algorithm</b> Jun Ho Bae 1, Hyo Seo Kwak 3, Sereisith San 3 and Chul Kim 2 Gerotor {{is a key}} component used in internal gear pumps of vehicles, and as the technology of sintering process is highly advanced, the gerotor has advantages for manufacturing complex profiles and obtaining durability and minimization. But internal gear pumps have been continuously required to improve flow rate and noise for fuel efficiency. The existing gerotors with multiple profiles have been designed by only <b>translation</b> <b>algorithm,</b> which is limited to improve the performances. In this study, a new automated design and multiple calculation programs using rotation and <b>translation</b> <b>algorithm</b> were developed for improving the performances of multiple profiles, and two types of combined multiple profiles (ellipse 1 -involute-ellipse 2 type and 3 -ellipses type) were generated. The performances (flow rate, irregularity, specific sliding and pressure angle) of the profiles were calculated by using theoretical analysis, and optimal designs of the two types were carried out {{on the basis of}} analysis results. Also, internal flow characteristics in the optimized gerotor generated were analyzed by using commercial CFD (computational fluid dynamics) code, ANSYS-CFX...|$|R
40|$|In this paper, {{we present}} a query <b>translation</b> <b>algorithm</b> which allows object -oriented queries to be {{automatically}} translated into a relational query language. Our goal is to provide an improved query interface for existing relational database systems. The <b>translation</b> <b>algorithm,</b> we propose in this paper {{may be used to}} directly access relational databases, but it may also be useful in the context of object-oriented multidatabase systems to translate the common global query language into the query languages of participating relational databases. Necessary steps in providing object-oriented access to relational databases are schema enrichment and transformation as well as query translation. The main focus of this paper is the query translation which has to be performed fully automatically since {{it has to be done}} each time, a query is processed by the system, whereas schema enrichment and transformation may be done only once in the beginning. Our query <b>translation</b> <b>algorithm</b> ensures a full automatic translation of object-oriented queries into equivalent SQL queries for the original relational schema in all cases where a direct translation is possible. In all other cases, it generates SQL queries providing a superset of the desired data and a sequence of `formatting' functions that transform the data into the desired result. Problems may occur if additional user defined functions are used...|$|R
40|$|This paper {{proposes a}} uniform {{framework}} {{for the development of}} parsing and <b>translation</b> <b>algorithms</b> for weighted extended (top-down) tree transducers and input strings. The asymptotic time complexity of these algorithms can be improved in practice by exploiting an algorithm for rule factorization in the above transducers...|$|R
40|$|Current corpus-based machine {{translation}} systems usually require {{significant amount of}} parallel text to build a useful bilingual dictionary for translation. To alleviate this data dependency I propose a novel approach based on genetic <b>algorithms</b> to improve <b>translations</b> by fusing different linguistic hypotheses. A preliminary evaluation is also reported...|$|R
40|$|Automatic {{detection}} and tracking of subviral particles in image sequences is an indispensable supportive method for modern medicine research programs. This paper describes {{the development of}} a highly adaptable camera-to-world system motion invariant tracking <b>algorithm.</b> A <b>translation</b> compensation is obtained by cross correlations. Particles are detected by an implemented existing algorithm. The detected particles are linked by solving a Linear Assignment Problem. For highly stable results the tracks are improved by Kalman filtering. The algorithm is tested on simulated sequences. The results show a great ability for stable tracking...|$|R
40|$|AbstractWe {{introduce}} {{a family of}} coarse quantization algorithms for heavily oversampled Gabor expansions of certain classes of functions in L 2 (R). These algorithms, which we call the TFΣΔ quantization algorithms, are inspired by sigma–delta modulation, a widely implemented coarse quantization scheme for oversampled bandlimited functions. We show that the TFΣΔ algorithms produce weak type approximations where modulation spaces M 1, 1 m with suitable weight functions m are the appropriate test function spaces. We also show that the TFΣΔ <b>algorithms</b> are <b>translation</b> invariant up to some uniform correction...|$|R
40|$|In {{statistical}} machine translation, {{a researcher}} seeks {{to determine whether}} some innovation (e. g., a new feature, model, or inference <b>algorithm)</b> improves <b>translation</b> quality in comparison to a baseline system. To answer this question, he runs an experiment to evaluate {{the behavior of the}} two systems on held-out data. In this paper, we consider how to make such experiments more statistically reliable. We provide a systematic analysis of the effects of optimizer instability—an extraneous variable that is seldom controlled for—on experimental outcomes, and make recommendations for reporting results more accuratel...|$|R
40|$|Abstract. Horn ⊃ is a logic {{programming}} language, defined on the underlying logic FO ⊃ (an extension of FO with intuitionistic implication), which permits {{a form of}} inner modularity in terms of open blocks of local clauses [8, 7, 3, 1, 9]. A translation from these logic programs with embedded implications to Horn clause programs is an interesting approach not only for giving logical foundation {{to this kind of}} extended logic programs but also for making it useful for implementation issues. In this paper we present a suitable <b>translation</b> <b>algorithm</b> from Horn ⊃ programs to Horn clause programs, in the propositional setting, and we formally prove that this translation preserves the original operational semantics in Horn ⊃ by means of SLD-resolution on the translation result. We also give an implementation of the <b>translation</b> <b>algorithm</b> written in Haskell and we show execution examples. ...|$|R
40|$|This project {{aimed to}} {{optimize}} vegetation index (VI) continuity across different sensors by {{taking advantage of}} EO- 1 satellite technologies, namely the Hyperion and ALI sensors. In a project duration period of 2 years and 10 months, we accomplished the following objectives and tasks: • Development of an empirical and theoretical framework to approach the problems of multi-sensor VI continuity/compatibility, • An identification of several "key " factors that would allow for VI continuity/compatibility to be successfully accomplished, thru empirical and theoretical investigations, • Development of a VI <b>translation</b> <b>algorithm,</b> • An application of the developed <b>translation</b> <b>algorithm</b> to the NDVI and validation using EO- 1 Hyperion and ALI data, • A performance evaluation of the hyperspectral Hyperion sensor on land cover conversion/characterization/degradation studies in semi-arid lands and savannah, • Development of an integrated PC and UNIX, Hyperion processing facility. 1...|$|R
40|$|Recent {{successful}} {{applications of}} AI planning technology have highlighted the knowledge engineering of planning domain models {{as an important}} research area. We describe an implemented <b>translation</b> <b>algorithm</b> between two languages used in planning representation: PDDL, a language used for communication of example domains between research groups, and OCL h, a language developed specifically for planning domain modelling. The algorithm is being used as part of OCL h ’s tool support to import models expressed in PDDL to OCL h ’s environment. Here we outline the <b>translation</b> <b>algorithm,</b> and discuss the issues that it uncovers. Although the tool performs reasonably well when its output is measured against hand-crafted OCL h, it results in only partially specified models. Analyis of the translation results shows that this is because many natural assumptions about domains are not captured in the PDDL encodings...|$|R
40|$|Introduction POLENG is a {{transfer}} text-to-text Polish-English MT system. It operates on an electronic dictionary annotated for morphological, syntactic, and partly semantic information. The dictionary {{is based on}} the corpus of Polish texts from the domain of computer science. The local version of the system has the form of a two-window editor. The client-server version is available at [URL] The system is intended to deal with HTML Polish texts as well as cooperate with Microsoft Word. The detailed structure of the system is described in (Wypych 2000). In our short presentation we will concentrate on corpus-based methods we adopt in order to improve the efficiency of the translation. 2. General properties of the POLENG system 1. 1 <b>Translation</b> <b>algorithm</b> The POLENG system is based on a uni-directional <b>translation</b> <b>algorithm.</b> The tree for representing English output expressions is built {{in the course of the}} analysis of Polish input...|$|R
