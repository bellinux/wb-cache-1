0|10000|Public
5000|$|Let [...] be a {{point in}} the {{original}} image and [...] {{be a point}} in <b>an</b> <b>image</b> <b>formed</b> by convolving with the first kernel and [...] be a point in <b>an</b> <b>image</b> <b>formed</b> by convolving with the second kernel. The gradient can then be defined as: ...|$|R
60|$|After <b>a</b> time <b>an</b> <b>image</b> <b>formed</b> on the screen. A heavy face, bushy black {{beard and}} large eyes.|$|R
50|$|Luck of the Corpse is {{the first}} album from the death metal band Deceased. The cover is <b>an</b> <b>image</b> <b>form</b> the 1963 film, Black Sabbath.|$|R
5000|$|Optical {{aberration}} correctionAs DHM {{systems do}} not have <b>an</b> <b>image</b> <b>forming</b> lens, traditional optical aberrations {{do not apply to}} DHM. Optical aberrations are [...] "corrected" [...] by design of the reconstruction algorithm. A reconstruction algorithm that truly models the optical setup will not suffer from optical aberrations.|$|R
5000|$|An {{article by}} Ivan Illich {{may help to}} {{understand}} this ancient university motto, {{at a time when}} scientists were progressively replacing the concept of vision as a gaze radiating from the pupil by the concept of vision as the retinal perception of <b>an</b> <b>image</b> <b>formed</b> by reflected sunlight: ...|$|R
50|$|Processed C-41 negatives, as {{with all}} color films, consist of <b>an</b> <b>image</b> <b>formed</b> of dye. Due to the {{long-term}} instability of dyes, C-41 negatives can fade or color-shift over time. This was a significant problem with early films; whether the newer films are archival or not is a subject of some debate.|$|R
40|$|The role of {{measurements}} of noncommuting quantum observables is {{considered in the}} detection of signals and estimation of signal parameters by quantum receivers. The restoration of <b>images</b> focused on <b>a</b> photosensitive surface is discussed for data as numbers of photoelectrons ejected from {{various parts of the}} surface. The detection of <b>an</b> <b>image</b> <b>formed</b> on <b>a</b> photosensitive surface in the presence of background illumination for similar data is also considered...|$|R
40|$|This year’s cover illustration, {{reproduced}} here as figure 1, depicts <b>an</b> <b>image</b> <b>formed</b> by <b>a</b> short-time (1 / 1000 s) {{exposure of}} a non-premixed hydrocarbon flame. The flow {{is driven by}} the buoyancy forces generated by the density difference from the combustion heat release and resulting temperature rise. The Reynolds number for this buoyancy-induced, turbulent flow is relatively low, estimated at a few thousand. Figure 1. Non-premixed hydrocarbon flame...|$|R
50|$|The {{sustained}} and shared economic {{growth of the}} member-economies are represented through an arrow pointed upward {{at the center of}} the globe, <b>an</b> <b>image</b> <b>formed</b> by the 21 triangles. The light blue shade of the arrow symbolized the promising development of a member-economy resulting from positive interaction with partners and compliance to sound macroeconomic fundamentals. The triangle itself symbolizes balance which leads to a strong and stable economy.|$|R
40|$|A new non-silver halide imaging {{material}} is proposed. The light sensitive element within the material generates free radicals upon exposure, through a fragmentation process. The free radicals, {{which can be}} generated imagewise, are then used as a catalyst to promote the reduction of <b>an</b> <b>image</b> <b>forming</b> element. The <b>image</b> <b>forming</b> element is <b>a</b> stabilized, soluble, metal salt which is chelated rendering it unaccessible for reduction by the atmosphere. The film matrix is virtually grain-free as is the final image, with some dependence on the binder and amplification process employed...|$|R
50|$|The {{monoscope}} {{was similar}} in construction to a CRT, with an electron gun at one end, but {{in place of}} a phosphor-coated screen which displayed <b>an</b> <b>image,</b> it had <b>a</b> metal target with <b>an</b> <b>image</b> <b>formed</b> on it. <b>As</b> the electron beam scanned the target, varying amounts of electrons were reflected from the different areas of the image. The reflected electrons were picked up by an internal electrode ring, producing a varying electrical signal which was amplified to become the video output of the tube.|$|R
25|$|In optics, <b>a</b> virtual <b>image</b> is <b>an</b> <b>image</b> <b>formed</b> {{when the}} {{outgoing}} rays {{from a point}} on an object always diverge. The image appears to be located {{at the point of}} apparent divergence. Because the rays never really converge, <b>a</b> virtual <b>image</b> cannot be projected onto a screen. In diagrams of optical systems, virtual rays are conventionally represented by dotted lines. Virtual images are located by tracing the real rays that emerge from an optical device (lens, mirror, or some combination) backward to a perceived point of origin.|$|R
40|$|An {{apparatus}} for eliminating beamsplitter generated optical aberrations in a pupil concentric {{optical system}} providing {{a plurality of}} spatially separated images on different focal planes or surfaces is presented. The system employs a buried surface beamsplitter having spherically curved entrance and exit faces which are concentric to a system aperture stop with the entrance face being located {{in the path of}} a converging light beam directed there from <b>an</b> <b>image</b> <b>forming</b> objective element which is also concentric to the aperture stop...|$|R
40|$|Multidimensional image {{retrieval}} (MIR) views <b>an</b> <b>image</b> as <b>a</b> multidimensional object, {{where each}} dimension is a channel for retrieval. MIR {{has the potential}} of putting at work together the many methods and techniques for image retrieval proposed in several different fields of computer science. We have developed a model of MIR, based on a fuzzy description logic, that identifies two main dimensions in <b>an</b> <b>image</b> (<b>form</b> and content) and views MIR as a special form of uncertain implication. In this paper, we present ARIANNA, a system that implements the model. ARIANNA allows to quickly develop a prototype of a MIR application, and use it to test the adequacy of the application to the user’s functional requirements. 1...|$|R
40|$|This paper {{describes}} {{and discusses}} a new technique, the multi-step adaptive flux interpolation (MAFI) and {{its application to}} image data for coding. The output of MAFI, when applied to <b>an</b> <b>image,</b> is still in <b>an</b> <b>image</b> <b>form</b> but has <b>a</b> more uniform feature density. This is because the original image has been warped by removing those rows and columns which contain mostly redundant pixels. It is also greatly reduced in size and the side information is minimal. The MAFI output can be further compressed using conventional coders, making its compression ratio even higher. Because of its warped nature, the MAFI output's statistics are also more consistent with the properties assumed by block-based discrete cosine transform (DCT) models...|$|R
40|$|Computed {{laminography}} (CL) is <b>an</b> <b>image</b> <b>forming</b> {{method of}} X-ray testing that yields images of object slices {{by a simple}} linear translation of the object relative to the tube-detector system. No relative movement of the X-ray tube to the detector is needed and in contrast to classical laminography all object layers {{can be obtained by}} one scan. Moreover CL turns out to be equivalent to a computed tomography (CT) with a limited angular region, which allows the reconstruction of object slices using slightly modified CT algorithms, resulting in higher resolution compared with simple tomosynthesis in the case of classical laminography...|$|R
5000|$|Following {{the stop}} bath, {{the film is}} {{bleached}} to remove the developed negative image. The film then contains <b>a</b> latent positive <b>image</b> <b>formed</b> from unexposed and undeveloped silver halide salts.|$|R
50|$|An electrofax {{involved}} {{electrostatic printer}} and copier technology, where <b>an</b> <b>image</b> was <b>formed</b> {{directly on the}} paper, instead of first on a drum, then transferred to paper, {{as it would be}} in xerography. It was used in the United States from the 1950s through the 1980s.|$|R
40|$|Abstract—The {{reason of}} image {{enhancement}} methods {{is to raise}} image visibility and aspects. Image enhancement {{is one of the}} ways as they get better of <b>an</b> <b>image</b> <b>form</b> by ever-increasing dominance of some aspects or by decreasing uncertainty among unusual areas of the image. Image enhancement methods exist of a collected works of techniques that try to find to improve the visual appearance of <b>an</b> <b>image</b> or to convert the <b>image</b> to <b>a</b> <b>form</b> enhanced appropriate for investigation by anyone or any piece of tools. Several images bear from poor contrast on behalf of that inspiration, it is vital to enhance the contrast. Contrast enhancement {{is one of the most}} demanding concerns in low level image processing. Contrast enhancement methods are utilized for get better for the visual observation and color facsimile of low contrast images. In this paper, various contrast enhancement techniques for low contrast images are reviewed...|$|R
2500|$|Therefore, if {{an object}} is placed at a {{distance}} [...] from a positive lens of focal length f, we will find <b>an</b> <b>image</b> distance S2 according to this formula. If a screen is placed {{at a distance}} S2 {{on the opposite side of}} the lens, <b>an</b> <b>image</b> is <b>formed</b> on it. This sort of image, which can be projected onto <b>a</b> screen or <b>image</b> sensor, is known as <b>a</b> real <b>image.</b>|$|R
30|$|However, {{the process}} of {{converting}} the backprojection output into <b>an</b> <b>image</b> buffer that {{can be converted to}} <b>a</b> PNG <b>image</b> (<b>Form</b> <b>Image)</b> runs faster when executed as part of the software program. This step is performed in software regardless of where the backprojection algorithm was executed. The difference in run time can be attributed to memory caching. When backprojection occurs in software, the result data lie in the processor cache. When backprojection occurs in hardware, the result data are copied via DMA into the processor main memory, and must be loaded into the cache before the <b>Form</b> <b>Image</b> step can begin.|$|R
40|$|QC 351 A 7 no. 19 ABSTRACT The {{classical}} {{properties of}} <b>an</b> <b>image</b> <b>formed</b> by <b>an</b> optical system {{looking through a}} turbulent medium are scintillation, agitation, and blur. A simple but adequate statistical model is obtained describing the pupil function {{in the presence of}} random wavefront disturbances in both amplitude and phase. A measure of scintillation is then obtained {{in the form of a}} normalized, weighted integral in frequency space containing all the pertinent properties of the optical system. A similar measure of agitation is then developed, and finally a description of the blur is obtained in the form of an equivalent transfer function for the turbulent medium in which the contribution from amplitude variations and the contribution from phase variations are independent...|$|R
25|$|Deep <b>image,</b> <b>a</b> poetic <b>form</b> {{coined by}} Jerome Rothenberg and Robert Kelly, is {{inspired}} by García Lorca's Deep Song.|$|R
50|$|Therefore, if {{an object}} is placed at a {{distance}} S1 > f from a positive lens of focal length f, we will find <b>an</b> <b>image</b> distance S2 according to this formula. If a screen is placed {{at a distance}} S2 {{on the opposite side of}} the lens, <b>an</b> <b>image</b> is <b>formed</b> on it. This sort of image, which can be projected onto <b>a</b> screen or <b>image</b> sensor, is known as <b>a</b> real <b>image.</b>|$|R
40|$|Contour {{trees have}} been used in {{geographic}} information systems (GIS) and medical imaging to display scalar data. Contours are only defined for continuous functions. For <b>an</b> <b>image</b> represented by discrete data, a continuous function is first defined as an interpolation of the data. Then the contour tree is defined on this continuous function. In this paper, we introduce a new concept termed monotonic line, which is directly defined on discrete data. All monotonic lines in <b>an</b> <b>image</b> <b>form</b> <b>a</b> tree, called monotonic tree. As compared with contour trees, monotonic trees avoid the step of interpolation, thus can be computed more efficiently. Monotonic tree can be reduced. The reduced monotonic tree can also be used as a hierarchical representation of image structures in image processing. In particular, we demonstrate its application on image smoothing and texture retrieval. Experiments show that our smoothing scheme is successful in both noise reduction and texture retrieval. ...|$|R
50|$|Holography is {{the science}} and {{practice}} of making holograms. Typically, a hologram is a photographic recording of a light field, rather than of <b>an</b> <b>image</b> <b>formed</b> by <b>a</b> lens, and {{it is used to}} display <b>a</b> fully three-dimensional <b>image</b> of the holographed subject, which is seen without the aid of special glasses or other intermediate optics. The hologram itself is not <b>an</b> <b>image</b> and it is usually unintelligible when viewed under diffuse ambient light. It is an encoding of the light field as an interference pattern of seemingly random variations in the opacity, density, or surface profile of the photographic medium. When suitably lit, the interference pattern diffracts the light into a reproduction of the original light field and the objects that were in it appear to still be there, exhibiting visual depth cues such as parallax and perspective that change realistically with any change in the relative position of the observer.|$|R
40|$|This work {{shows the}} {{development}} and application of computational algorithms based on chaos theory and cellular automaton to simulate the grain growth process on squared steel billets produced by continuous casting. Three algorithms were developed to simulate the grain structures on chill, columnar and equiaxed zones. These include routines to simulate grain nucleation and growth. These routines were compiled separately from the main routine {{in order to make}} more efficient the simulator. Algorithms analyze each node at every step time during simulation and a graphical interface is used to display the results on the screen. Chaos theory is used for integrating a random selection process. The result is <b>an</b> <b>image</b> <b>formed</b> with cells that represent grains (cellular automaton) displayed on the screen based on a numeric code assigned to the nodal positions...|$|R
50|$|In {{printers}} and plotters, {{paper is}} typically electrostatically charged by passing {{it over a}} bar containing {{hundreds or thousands of}} charging contacts. As paper passes over it, <b>an</b> <b>image</b> is <b>formed</b> by either applying or removing a charge from each individual contact. The result is a grid of charged dots on the paper. Toner is then applied as described above.|$|R
500|$|The {{anterior}} ASV is more anterior {{than the}} ASV and {{is outside the}} femoral vessels plan. The two veins terminate in a common trunk near the groin, the sapheno-femoral junction. Here, the ASV can be located [...] aligned with the femoral vessels at the [...] "alignment sign". Also, at the groin {{it can be seen}} at the outside of the great saphenous vein, and together with the common femoral vein (CFV) these three create <b>an</b> <b>image,</b> the so-called [...] "Mickey Mouse sign". Some authors, inspired by this sign (presented {{for the first time at}} CHIVA's 2002 meeting in Berlin), described a [...] "Mickey Mouse view" [...] at the groin, <b>an</b> <b>image</b> <b>formed</b> by the common femoral vein, the GSV and the superficial femoral artery. When the ASV is incompetent, its flow becomes retrograde and tries to drain in the superior fibular perforator, at the side of the knee, or sometimes it runs down towards the ankle to drain in the inferior fibular perforator.|$|R
3000|$|... } is {{the median}} {{of the data}} set. The MAD is a robust measure of {{the spread of the}} data [36]. For <b>an</b> <b>image,</b> all pixels <b>form</b> <b>a</b> set of data denoted as {x [...]...|$|R
40|$|Abstract — The {{logarithmic}} of {{a binary}} number may be determined approximately {{from the number}} itself by simple shifting and counting. Since the logarithms used are approximate there can be errors in the result. This paper presents a simple and efficient logarithmic multiplier with the possibility to achieve an arbitrary accuracy through an iterative procedure. Digital image processing is used in variety of application. Many algorithm used in image processing include convolution. In this coding is done using VHDL for the FPGA. Synthesis and simulation is done using Xilinx and MATLAB is used to convert input <b>image</b> in to <b>a</b> matrix form which is convolved with the kernel value using proposed multiplier {{and the result is}} again converted back into <b>a</b> <b>image</b> <b>form</b> using m. file. Key word — logarithmic number system, computer arithmetic, digital signal processing, multiplier, convolution...|$|R
40|$|Video content {{analysis}} for still- and moving {{images can be}} used for various applications, such as high-level semantic-driven operations or pixel-level contentdependent image manipulation. Within video {{content analysis}}, sky regions of <b>an</b> <b>image</b> <b>form</b> visually important objects, for which interesting applications at both mentioned levels can be envisaged. This paper introduces a new algorithm and model for detecting blue-sky areas, with suitable properties for TV video material. The proposed method is capable of robustly detecting various sky appearances, while addressing the requirements of the target applications. A special feature of our proposal is that we use adaptive color 1 - and position models for computing a pixel-accurate sky-probability measure. The experimental simulations show that our proposal considerably improves the correct detection/ rejection of sky regions, and yields better spatial and temporal consistency of the detection results with respect to the currently available systems...|$|R
50|$|The {{contrast}} {{transfer function}} determines how much phase signal gets {{transmitted to the}} real space wavefunction in the <b>image</b> plane. <b>As</b> the modulus squared of the real space wavefunction gives the image signal, the contrast transfer function limits how much information can ultimately be translated into <b>an</b> <b>image.</b> The <b>form</b> of the contrast transferfunction determines the quality of real space image formation in the TEM.|$|R
5000|$|Exposure: <b>A</b> latent <b>image</b> is <b>formed</b> in the resist e.g. (a) via {{exposure}} to ultraviolet light through a photomask with opaque and transparent regions or (b) by direct writing using {{a laser beam}} or electron beam.|$|R
5000|$|The {{focal length}} of a thin lens can be easily {{measured}} by using it to <b>form</b> <b>an</b> <b>image</b> of <b>a</b> distant light source on a screen. The lens is moved until <b>a</b> sharp <b>image</b> is <b>formed</b> on the screen. In this case [...] is negligible, and the focal length is then given by ...|$|R
5000|$|... #Caption: Self {{organizing}} map (SOM) of Fisher's Iris Flower Data Set with U-Matrix. Top left: <b>a</b> color <b>image</b> <b>formed</b> by {{the first}} three dimensions of the four-dimensional SOM weight vectors. Top Right: <b>a</b> pseudo-color <b>image</b> {{of the magnitude of}} the SOM weight vectors. Bottom Left: a U-Matrix (Euclidean distance between weight vectors of neighboring cells) of the SOM. Bottom Right: An overlay of data points (red: I. setosa, green: I. versicolor and blue: I. virginica) on the U-Matrix based on the minimum Euclidean distance between data vectors and SOM weight vectors.|$|R
