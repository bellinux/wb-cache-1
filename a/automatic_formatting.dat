11|46|Public
2500|$|All times Eastern Time, first 5 are while {{daylight}} saving time was in effect (EDT), attempt 6 is during outside of {{daylight saving}} (EST). Because of this, the final [...] "turnaround" [...] category should be 111 days, 2 hours, 49 minutes, it is not due to <b>automatic</b> <b>formatting.</b>|$|E
2500|$|The {{separate}} encoding of the Unicode fraction slash {{is intended}} to permit <b>automatic</b> <b>formatting</b> of the preceding and succeeding digits by glyph substitution with numerator and denominator glyphs (e.g., display of [...] as [...] ), although this may not yet be supported in certain environments and fonts. By lack of support, some authors still use Unicode subscripts and superscripts to compose fractions, the more as in many popular fonts, these characters are repurposed as numerators and denominators. A number of common fractions—with their slashes—are specially encoded in Unicode, these include , , , and [...]|$|E
5000|$|Editor with syntax {{highlighting}} {{and various}} <b>automatic</b> <b>formatting</b> options.|$|E
40|$|In {{most current}} PCM based {{telemetry}} systems, an instrumentation engineer manually creates the sampling format. This time consuming and tedious process typically involves manually placing each measurement into the format {{at the proper}} sampling rate. The telemetry industry is now moving towards Ethernet-based systems comprised of multiple autonomous data acquisition units, which share a single global time source. The architecture of these network systems greatly simplifies the task of implementing an <b>automatic</b> <b>format</b> generator. <b>Automatic</b> <b>format</b> generation eliminates much of the effort required to create a sampling format because the instrumentation engineer only has to specify the desired sampling rate for each measurement. The system handles the task of organizing the format {{to comply with the}} specified sampling rates. This paper examines the issues involved in designing an <b>automatic</b> <b>format</b> generator for a network data acquisition system...|$|R
40|$|ITC/USA 2006 Conference Proceedings / The Forty-Second Annual International Telemetering Conference and Technical Exhibition / October 23 - 26, 2006 / Town and Country Resort & Convention Center, San Diego, CaliforniaIn {{most current}} PCM based {{telemetry}} systems, an instrumentation engineer manually creates the sampling format. This time consuming and tedious process typically involves manually placing each measurement into the format {{at the proper}} sampling rate. The telemetry industry is now moving towards Ethernet-based systems comprised of multiple autonomous data acquisition units, which share a single global time source. The architecture of these network systems greatly simplifies the task of implementing an <b>automatic</b> <b>format</b> generator. <b>Automatic</b> <b>format</b> generation eliminates much of the effort required to create a sampling format because the instrumentation engineer only has to specify the desired sampling rate for each measurement. The system handles the task of organizing the format {{to comply with the}} specified sampling rates. This paper examines the issues involved in designing an <b>automatic</b> <b>format</b> generator for a network data acquisition system...|$|R
50|$|GenomeSpace is an {{environment}} for genomics software tools and applications. It helps users manage their analysis workflows involving multiple diverse tools, including web applications and desktop tools and facilitates {{the transfer of}} data between tools via <b>automatic</b> <b>format</b> conversion. Analyses can use data from local or cloud-based stores.|$|R
50|$|Amazon StoryWriter {{is a free}} {{cloud-based}} screenwriting app {{launched by}} Amazon in 2015. Storywriter provides <b>automatic</b> <b>formatting</b> for screenplays on the Master Scene Standard. The app allows easy submission of original screenplays for production consideration in Amazon Studios.|$|E
5000|$|All times Eastern Time, first 5 are while {{daylight}} saving time was in effect (EDT), attempt 6 is during outside of {{daylight saving}} (EST). Because of this, the final [...] "turnaround" [...] category should be 111 days, 2 hours, 49 minutes, it is not due to <b>automatic</b> <b>formatting.</b>|$|E
50|$|A {{document}} processor is {{a computer}} application that superficially resembles a word processor—but emphasizes the visual layout of the document's components, above creation and formatting of text. Document processor tools are not just typical document elements—paragraphs, lists, headers, etc. The primary attraction of a document processor {{is the ability to}} program documents with strong layout controls and powerful conditional <b>automatic</b> <b>formatting</b> rules that create structured documents. This facilitates creating large numbers of similar elements generated and reformatted for different media with little human effort.|$|E
5000|$|The HP-45 added {{many more}} features, {{including}} {{the ability to}} control the output format (rather than the purely <b>automatic</b> <b>format</b> of the HP-35). It also contained an undocumented timer feature. The timer worked, but was not accurate enough to use as a stopwatch due to lack of a crystal oscillator.|$|R
40|$|A {{review and}} {{discussion}} of the technique of <b>automatic</b> <b>format</b> recognition (AFR) of bibliographic data are presented. A comparison is made of the record-building facilities of the Library of Congress, the University of California (both AFR techniques), and the Ohio College Library Center (non-AFR). A projection of a next logical generation is described...|$|R
50|$|The DAF XF is a {{range of}} trucks {{produced}} by the Dutch manufacturer DAF since 1997. All right hand drive versions of the XF are assembled at Leyland Trucks in the UK.The XF 105 won the International Truck of the Year 2007 award. The truck features the 12.9 litre engine and ZF gearbox in both manual and <b>automatic</b> <b>formats.</b>|$|R
5000|$|The {{separate}} encoding of the Unicode fraction slash {{is intended}} to permit <b>automatic</b> <b>formatting</b> of the preceding and succeeding digits by glyph substitution with numerator and denominator glyphs (e.g., display of [...] as [...] ), although this may not yet be supported in certain environments and fonts. By lack of support, some authors still use Unicode subscripts and superscripts to compose fractions, the more as in many popular fonts, these characters are repurposed as numerators and denominators. A number of common fractions—with their slashes—are specially encoded in Unicode, these include , , , and [...]|$|E
5000|$|SQLyog is a GUI tool {{available}} in free {{as well as}} paid versions. Data manipulations (e.g., insert, update, and delete) may be done from a spreadsheet-like interface. Its editor has syntax highlighting and various <b>automatic</b> <b>formatting</b> options. Both raw table data and a result set from a query can be manipulated. Its data search feature uses Google-like search syntax and translates to SQL transparently for the user. It has a backup tool for performing unattended backups. Backups may be compressed and optionally stored as a file-per-table as well as identified with a timestamp.|$|E
5000|$|Faerber writes his {{comic book}} scripts in Mozilla's Open Office software, and I write his {{television}} scripts in Final Draft, {{though he does}} not use the latter's <b>automatic</b> <b>formatting</b> or templates, as he prefers to perform those tasks manually, explaining {{that he is a}} fast typist. Although he likes the idea of using applications in his writing, and has Evernote on his iPhone, iPad and laptop, he does not use it, preferring to write down ideas on his phone's Notes application. He uses GoodReader on his iPad, and the Adonit Jot Pro stylus to write notes on scripts written by himself or others. He prefers to work in silence rather than listen to music, but will wear Bose noise-cancelling headphones to listen to instrumental film or television soundtracks that [...] "fit" [...] with what he is writing if the noise from the school across the street from his home becomes too distracting.|$|E
40|$|Configuring a modern, {{high-performance}} {{data acquisition}} system is typically a very time-consuming and complex process. Any enhancement to the data acquisition setup software that can {{reduce the amount of}} time needed to configure the system is extremely useful. <b>Automatic</b> <b>format</b> generation {{is one of the most}} useful enhancements to a data acquisition setup application. By using <b>Automatic</b> <b>Format</b> Generation, an instrumentation engineer can significantly reduce the amount of time that is spent configuring the system while simultaneously gaining much greater flexibility in creating sampling formats. This paper discusses several techniques that can be used to generate sampling formats automatically while making highly efficient use of the system’s bandwidth. This allows the user to obtain most of the benefits of a hand-tuned, manually created format without spending excessive time creating it. One of the primary techniques that this paper discusses is an enhancement to the commonly used power-of-two rule, for selecting sampling rates. This allows the system to create formats that use a wider variety of rates. The system is also able to handle groups of related measurements that must follow each other sequentially in the sampling format. This paper will also cover a packet based formatting scheme that organizes measurements based on common sampling rates. Each packet contains a set of measurements that are sampled at a particular rate. A key benefit of using an <b>automatic</b> <b>format</b> generation system with this format is the optimization of sampling rates that are used to achieve the best possible match for each measurement’s desired sampling rate...|$|R
5000|$|<b>Automatic</b> script <b>formatting</b> - {{automatically}} formats {{the script}} {{as it is}} typed through auto-complete and keyboard shortcuts.|$|R
40|$|ITC/USA 2009 Conference Proceedings / The Forty-Fifth Annual International Telemetering Conference and Technical Exhibition / October 26 - 29, 2009 / Riviera Hotel & Convention Center, Las Vegas, NevadaConfiguring a modern, {{high-performance}} {{data acquisition}} system is typically a very timeconsuming and complex process. Any enhancement to the data acquisition setup software that can {{reduce the amount of}} time needed to configure the system is extremely useful. <b>Automatic</b> <b>format</b> generation {{is one of the most}} useful enhancements to a data acquisition setup application. By using <b>Automatic</b> <b>Format</b> Generation, an instrumentation engineer can significantly reduce the amount of time that is spent configuring the system while simultaneously gaining much greater flexibility in creating sampling formats. This paper discusses several techniques that can be used to generate sampling formats automatically while making highly efficient use of the system's bandwidth. This allows the user to obtain most of the benefits of a hand-tuned, manually created format without spending excessive time creating it. One of the primary techniques that this paper discusses is an enhancement to the commonly used power-of-two rule, for selecting sampling rates. This allows the system to create formats that use a wider variety of rates. The system is also able to handle groups of related measurements that must follow each other sequentially in the sampling format. This paper will also cover a packet based formatting scheme that organizes measurements based on common sampling rates. Each packet contains a set of measurements that are sampled at a particular rate. A key benefit of using an <b>automatic</b> <b>format</b> generation system with this format is the optimization of sampling rates that are used to achieve the best possible match for each measurement's desired sampling rate...|$|R
5000|$|The station {{went on the}} air as {{country music}} {{formatted}} KDOL in 1961. In the late 1970s KDOL enjoyed its greatest success led by zany morning disc jockey [...] "Country" [...] Tom Fielding and afternoon DJ, Gene [...] "The King Of Mobile Disco" [...] Pro. The station played top 40 and oldies by its own version of <b>automatic</b> <b>formatting,</b> inferior to what TM Productions used, in the early 1980s and later changed to a gold-based Adult Contemporary format in 1986 with the same call letters after being sold to Chambers Broadcasting, which owned KTPI. A year later, on 1987-07-15, the call letters were changed to KVOY and the Country format restored. On 1998-12-11, the station changed its call sign to KAVC and the Christian Talk format was moved to 1340 AM from 105.5 FM. On 2002-12-01, the station's call letters were changed to KTPI and the station flipped to an automated Classic Country format as 1340 KTPI AM as a counterpart to FM sister station 103.1 KTPI FM. In early 2003, the station changed names to Community Radio 1340 which included a morning show that discussed local politics and events, but retaining the automated Classic Country format the rest of the time. In mid-2004, after KWJL 1380 in Lancaster, California dropped the Adult Standards/MOR format in favor of Mexican Oldies, KTPI took the old name and format and became K-Jewel 1340 for a brief time. A few months later the station's name was changed to Magic 1340 while retaining the Adult Standards/MOR format.|$|E
40|$|Version 1. 0 ! This release {{has been}} a long time coming and brings with it some fairly major {{improvements}} in speed, report filesize and report performance. There's also a bunch of new modules, more options, features and a whole lot of bug fixes. The version number is being bumped up to 1. 0 for a couple of reasons: MultiQC is now (hopefully) relatively stable. A number of facilities and users are now using it in a production setting and it's published. It feels like it probably deserves v 1 status now somehow. This update brings some fairly major changes which will break backwards compatibility for plugins. As such, semantic versioning suggests a change in major version number. Breaking Changes For most people, you shouldn't have any problems upgrading. There are two scenarios where you may need to make changes with this update: 1. You have custom file search patterns Search patterns have been flattened and may no longer have arbitrary depth. For example, you may need to change the following: fastqc: data: fn: 'fastqc_data. txt' zip: fn: '*_fastqc. zip' to this: fastqc/data: fn: 'fastqc_data. txt' fastqc/zip: fn: '*_fastqc. zip' See the documentation for instructions on how to write the new file search syntax. See search_patterns. yaml for the new module search keys and more examples. 2. You have custom plugins / modules / external code To see what changes need to applied to your custom plugin code, please see the MultiQC docs. Module updates: Adapter Removal - new module! AdapterRemoval v 2 - rapid adapter trimming, identification, and read merging BUSCO - new module! New module for the BUSCO v 2 tool, used for assessing genome assembly and annotation completeness. Cluster Flow - new module! Cluster Flow is a workflow tool for bioinformatics pipelines. The new module parses executed tool commands. RNA-SeQC - new module! New module to parse output from RNA-SeQC, a java program which computes a series of quality control metrics for RNA-seq data. goleft indexcov - new module! Thanks to @chapmanb and @brentp goleft indexcov uses the PED and ROC data files to create diagnostic plots of coverage per sample, helping to identify sample gender and coverage issues. SortMeRNA - new module! Written by @bschiffthaler New module for SortMeRNA, commonly used for removing rRNA contamination from datasets. Bcftools Fixed bug with display of indels when only one sample Cutadapt Now takes the filename if the sample name is - (stdin). Thanks to @tdido FastQC Data for the Sequence content plot can now be downloaded from reports as a JSON file. FastQ Screen Rewritten plotting method for high sample numbers plot (~ > 20 samples) Now shows counts for single-species hits and bins all multi-species hits Allows plot to show proper percentage view for each sample, much easier to interpret. HTSeq Fix bug where header lines caused module to crash Picard New RrbsSummaryMetrics Submodule! New WgsMetrics Submodule! CollectGcBiasMetrics module now prints summary statistics to multiqc_data if found. Thanks to @ahvigil Preseq Now trims the x axis to the point that meets 90 % of min(unique molecules). Hopefully prevents ridiculous x axes without sacrificing too much useful information. Allows to show estimated depth of coverage instead of less informative molecule counts (see details). Plots dots with externally calculated real read counts (see details). Qualimap RNASeq Transcript Profile now has correct axis units. Thanks to @roryk BamQC module now doesn't crash if reports don't have genome gc distributions RSeQC Fixed Python 3 error in Junction Saturation code Fixed JS error for Junction Saturation that made the single-sample combined plot only show All Junctions Core MultiQC updates: Change in module structure and import statements (see details). Module file search has been rewritten (see above changes to configs) Significant improvement in search speed (test dataset runs in approximately half the time) More options for modules to find their logs, eg. filename and contents matching regexes (see the docs) Report plot data is now compressed, significantly reducing report filesizes. New [...] ignore-samples option to skip samples based on parsed sample name Alternative to filtering by input filename, which doesn't always work Also can use config vars sample_names_ignore (glob patterns) and sample_names_ignore_re (regex patterns). New [...] sample-names command line option to give file with alternative sample names Allows one-click batch renaming in reports New [...] cl_config option to supply MultiQC config YAML directly on the command line. New config option to change numeric multiplier in General Stats For example, if reports have few reads, can show Thousands of Reads instead of Millions of Reads Set config options read_count_multiplier, read_count_prefix and read_count_desc Config options decimalPoint_format and thousandsSep_format now apply to tables as well as plots By default, thosands will now be separated with a space and. used for decimal places. Tables now have a maximum-height by default and scroll within this. Speeds up report rendering in the web browser and makes report less stupidly long with lots of samples Button beneath table toggles full length if you want a zoomed-out view Refactored and removed previous code to make the table header "float" Set config. collapse_tables to False to disable table maximum-heights Bar graphs and heatmaps can now be zoomed in on Interactive plots sometimes hide labels due to lack of space. These can now be zoomed in on to see specific samples in more detail. Report plots now load sequentially instead of all at once Prevents the browser from locking up when large reports load Report plot and section HTML IDs are now sanitised and checked for duplicates New template available (called sections) which has faster loading Only shows results from one module at a time Makes big reports load in the browser much more quickly, but requires more clicking Try it out by specifying -t sections Module sections tidied and refactored New helper function self. add_section() Sections hidden in nav if no title (no more need for the hacky self. intro +=) Content broken into description, help and plot, with <b>automatic</b> <b>formatting</b> Empty module sections are now skipped in reports. No need to check if a plot function returns None! Changes should be backwards-compatible Report plot data export code refactored Now doesn't export hidden samples (uses HighCharts export-csv plugin) Handle error when git isn't installed on the system. Refactored colouring of table cells Was previously done in the browser using chroma. js Now done at report generation time using the spectra package Should helpfully speed up report rendering time in the web browser, especially for large reports Docs updates (thanks to @varemo) Previously hidden log file. multiqc. log renamed to multiqc. log in multiqc_data Added option to load MultiQC config file from a path specified in the environment variable MULTIQC_CONFIG_PATH New table configuration options sortRows: False prevents table rows from being sorted alphabetically col 1 _header allows the default first column header to be changed from "Sample Name" Tables no longer show Configure Columns and Plot buttons if they only have a single column Custom content updates New custom_content/order config option to specify order of Custom Content sections Tables now use the header for the first column instead of always having Sample Name JSON + YAML tables now remember order of table columns Many minor bugfixes Line graphs and scatter graphs axis limits If limits are specified, data exceeding this is no longer saved in report Visually identical, but can make report file sizes considerable smaller in some cases Creating multiple plots without a config dict now works (previously just gave grey boxes in report) All changes are now tested on a Windows system, using AppVeyor Fixed rare error where some reports could get empty General Statistics tables when no data present. Fixed minor bug where config option force: true didn't work. Now you don't have to always specify -f...|$|E
5000|$|... #Subtitle level 2: <b>Automatic</b> Picture Transmission <b>format</b> (APT) ...|$|R
5000|$|JSON buffer <b>format,</b> <b>automatic</b> {{conversion}} between JSON and UBF available ...|$|R
40|$|Hyphenated full-scan MS {{technology}} creates {{large amounts}} of data. A versatile easy to handle automation tool aiding in the data analysis {{is very important in}} handling such a data stream. MetAlign software-as described in this manuscript-handles a broad range of accurate mass and nominal mass GC/MS and LC/MS data. It is capable of <b>automatic</b> <b>format</b> conversions, accurate mass calculations, baseline corrections, peak-picking, saturation and mass-peak artifact filtering, as well as alignment of up to 1000 data sets. A 100 to 1000 -fold data reduction is achieved. MetAlign software output is compatible with most multivariate statistics programs...|$|R
40|$|Design and {{implement}} a programmer's text editor with syntax directed functions. Syntax rules submitted in a suitable format shall be used to visually distinguish syntactic constructs and to drive various functionality like <b>automatic</b> indentation, <b>formatting,</b> and auto-completion of parentheses, keywords, or XML elements...|$|R
50|$|Authorea allows {{researchers}} to write documents together and attach references, figures, data, and source code. Features {{of the tool}} include collaborative editing (multiple people editing a document at the same time), <b>automatic</b> citation <b>formatting,</b> tracking changes, {{and the ability to}} make any document public or fully private.|$|R
50|$|PRONOM 4, {{released}} in October 2005, includes a significant reworking {{of the underlying}} data model to allow the capture of detailed technical information on file formats and support future interoperability with other planned registry systems, {{and the release of}} the DROID software for <b>automatic</b> file <b>format</b> identification.|$|R
40|$|This study reports an {{integrated}} microfluidic system capable of isolation, counting, and sorting of hematopoietic stem cells (HSCs) from cord blood in an <b>automatic</b> <b>format</b> by utilizing a magnetic-bead-based immunoassay. Three functional modules, including cell isolation, cell counting, and cell sorting modules are integrated {{on a single}} chip by using microfluidic technology. The cell isolation module is comprised of a four-membrane-type micromixer for binding of target stem cells and magnetic beads, two pneumatic micropumps for sample transport, and an S-shaped channel for isolation of HSCs using a permanent magnet underneath. The counting and sorting of HSCs are performed by utilizing the cell counting and sorting modules. Experimental results show that a separation efficiency as high as 88 % for HSCs from cord blood is achieved within 40 min for a sample volume of 100 μl. Therefore, {{the development of this}} integrated microfluidic system may be promising for various applications such as stem cell research and cell therapy...|$|R
40|$|One {{problem of}} the (re-) {{usability}} and exchange of annotated corpora is in the lack of standards in corpus formats and corpus query tools. This paper reports on the NXT Search tool, which was used to query two corpora with very different annotation formats. It is shown that with <b>automatic</b> data <b>format</b> conversion both corpora can be accessed and searched with NXT Search. 1...|$|R
40|$|Linguistically enriched text {{generated}} from natural language modules contributes significantly {{on the quality}} of speech synthesis. For all cases where such modules are not available, such enriched input needs to be produced from plain text in order to maintain quality. This work reports on a framework of several combined language resources and procedures (word/sentence identification, syntactic analysis, prosodic feature annotation) for text annotation/processing from plain text. Using that, the implementation of an <b>automatic</b> XML <b>formatted</b> output generation module produces the prosodically enriched markup. 1...|$|R
40|$|Abstract. The {{goal of the}} EU FP 6 project DIAMONDS 1 is {{to build}} a {{computational}} platform for studying the cell-cycle regulation process in several different (model) organisms (S. cerevisiae, S. pombe, A. thaliana and human). This platform will enable wet-lab biologists to use a systems biology approach encompassing data integration, modeling and simula-tion, thereby supporting analysis and interpretation of biochemical path-ways involved in the cell cycle. To facilitate the computational handling of cell-cycle specific knowledge a detailed cell-cycle ontology is essential. The currently existing cell-cycle branch of the Gene Ontology (GO) pro-vides only a static view and it is not rich enough to support in-depth cell-cycle studies. In this work, an enhanced Cell-Cycle Ontology (CCO) is proposed as an extension to existing GO. Besides the classical add-ons given by an ontology (data repository, knowledge sharing, validation, annotation, and so on), CCO is intended to further evolve into a knowledge-based system that provides reasoning services oriented to hypotheses evaluation in the context of cell-cycle studies. A data integration pipeline prototype, covering the entire life cycle of the knowledge base, is presented. Concrete problems and initial results related to the implementation of <b>automatic</b> <b>format</b> mappings between ontologies and inconsistency checking issues are discussed in detail. ...|$|R
40|$|Logs are {{ubiquitous}} for {{system monitoring}} and debugging. However, there lacks a comprehensive {{system that is}} capable of performing heterogeneous log organization and analysis for various purposes with very limited domain knowledge and human surveillance. In this manuscript, a novel system for heterogeneous log analysis is proposed. The system, denoted as Heterogeneous Log Analyzer (HLAer), achieves the following goals concurrently: 1) heterogeneous log categorization and organization; 2) <b>automatic</b> log <b>format</b> recognition and 3) heterogeneous log indexing. Meanwhile, HLAer supports queries and outlier detection on heterogeneous logs. HLAer provides a framework which is purely data-oriented and thus general enough to adapt to arbitrary log formats, applications or systems. The current implementation of HLAer is scalable to Big Data. I...|$|R
40|$|The paper {{presents}} {{a system for}} the <b>automatic</b> MPEG <b>format.</b> In contrast to the approaches proposed up to now, it employs a multi-expert classification system arranged according to a multi-stage architecture. The system is able to recognize not only four pure classes (music, speech, silence and noise) but also confused audio signals, {{such as the ones}} resulting from the overlap of pure audio components (for example, speech overlapped with music or noise, etc.). An extensive experimental analysis has been carried on a large audio database extracted from about 30 moving pictures recorded on low-quality magnetic media. Results confirm the effectiveness of the approach, with an average improvement of about 45 % with respect to single classifier solutions...|$|R
40|$|We {{review the}} {{literature}} on <b>automatic</b> document <b>formatting</b> {{with an emphasis on}} recent work in the field. One common way to frame document formatting is as a constrained optimization problem where decision variables encode element placement, constraints enforce required geometric relationships, and the objective function measures layout quality. We present existing research using this framework, describing the kind of optimization problem being solved and the basic optimization techniques used to solve it. Our review focuses on the formatting of primarily textual documents, including both micro- and macro-typographic concerns. We also cover techniques for automatic table layout. Related problems such as widget and diagram layout, as well as temporal layout issues that arise in multimedia documents are outside the scope of this review...|$|R
40|$|GUItar is a GPL-licensed, cross-platform, {{graphical}} {{user interface}} for automata drawing and manipulation, written in C++ and Qt 5. This tool offers support for styling, <b>automatic</b> layouts, several <b>format</b> exports and interface with any foreign finite automata manipulation library that can parse the serialized XML or JSON produced. In this paper we describe a new redesign of the GUItar framework and specially the method used to interface GUItar with automata manipulation libraries...|$|R
40|$|This study {{presents}} {{an approach to}} Web information extraction for the question and answering system about prices of Chinese agricultural products. This approach first uses the training corpus to product keyword dictionary and then matches the sample pages to find key information path to <b>format</b> <b>automatic</b> information extraction. The advantage {{of this approach is}} effectively to avoid the nonstandard Hyper Text Marked Language (HTML) pages and to obtain high extraction accuracy in specific domain...|$|R
40|$|Neuroscientists use many {{different}} software tools to acquire, analyse and visualise electrophysiological signals. However, incompatible data models and file formats {{make it difficult}} to exchange data between these tools. This reduces scientific productivity, renders potentially useful analysis methods inaccessible and impedes collaboration between labs. A common representation of the core data would improve interoperability and facilitate data-sharing. To that end, we propose here a language-independent object model, named Neo, suitable for representing data acquired from electroencephalographic, intracellular, or extracellular recordings, or generated from simulations. As a concrete instantiation of this object model we have developed an open source implementation in the Python programming language. In addition to representing electrophysiology data in memory for the purposes of analysis and visualisation, the Python implementation provides a set of input/output (IO) modules for reading/writing the data from/to a variety of commonly used file formats. Support is included for formats produced by most of the major manufacturers of electrophysiology recording equipment and also for more generic formats such as MATLAB. Data representation and data analysis are conceptually separate: it is easier to write robust analysis code if it is focused on analysis and relies on an underlying package to handle data representation. For that reason, and also to be as lightweight as possible, the Neo object model and the associated Python package are deliberately limited to representation of data, with no functions for data analysis or visualisation. Software for neurophysiology data analysis and visualisation built on top of Neo automatically gains the benefits of interoperability, easier data sharing and <b>automatic</b> <b>format</b> conversion; there is already a burgeoning ecosystem of such tools. We intend that Neo should become the standard basis for Python tools in neurophysiology...|$|R
