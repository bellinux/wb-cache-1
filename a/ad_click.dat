19|81|Public
40|$|This paper {{addresses}} {{estimating the}} number of the users of a specific application behind IP addresses (IPs). This prob-lem is central to combating abusive traffic, such as DDoS attacks, <b>ad</b> <b>click</b> fraud and email spam. We share our expe-rience building a general framework at Google for estimating {{the number of}} users behind IPs, called hereinafter the sizes of the IPs. The primary goal of this framework is combating abusive traffic without violating the user privacy. The esti-mation techniques produce statistically sound estimates of sizes relying solely on passively mining aggregated applica-tion log data, without probing machines or deploying active content like Java applets. This paper also explores using the estimated sizes to detect and filter abusive traffic. The pro-posed framework was used to build and deploy an <b>ad</b> <b>click</b> fraud filter at Google. The first 50 M clicks tagged by the fil-ter had a significant recall of all tagged clicks, and their false positive rate was below 1. 4 %. For the sake of comparison, we simulated a näıve IP-based filter that does not consider the sizes of the IPs. To reach a comparable recall, the näıve filter’s false positive rate was 37 % due to aggressive tagging...|$|E
40|$|Sponsored {{search is}} at the center of a multibil-lion dollar market {{established}} by search tech-nology. Accurate <b>ad</b> <b>click</b> prediction is a key component for this market to function since the pricing mechanism heavily relies on the estimation of click probabilities. Lexical fea-tures derived from the text of both the query and ads play a significant role, complementing features based on historical click information. The purpose of this paper is to explore the use of word embedding techniques to generate ef-fective text features that can capture not only lexical similarity between query and ads but also the latent user intents. We identify several potential weaknesses of the plain application of conventional word embedding methodolo-gies for <b>ad</b> <b>click</b> prediction. These observa-tions motivated us to propose a set of novel joint word embedding methods by leveraging implicit click feedback. We verify the effec-tiveness of these new word embedding models by adding features derived from the new mod-els to the click prediction system of a com-mercial search engine. Our evaluation results clearly demonstrate the effectiveness of the proposed methods. To the best of our knowl-edge this work is the first successful applica-tion of word embedding techniques for the task of click prediction in sponsored search. ...|$|E
40|$|Many {{real life}} {{datasets}} have skewed distributions of events when {{the probability of}} observing few events far exceeds the others. In this paper, we observed that in skewed datasets {{the state of the}} art collaborative filtering methods perform worse than a simple probabilistic model. Our test bench includes a real <b>ad</b> <b>click</b> stream dataset which is naturally skewed. The same conclusion is obtained even from the popular movie rating dataset when we pose a binary prediction problem of whether a user will give maximum rating to a movie or not...|$|E
40|$|Treballs Finals de Grau d'Enginyeria Informàtica, Facultat de Matemàtiques, Universitat de Barcelona, Any: 2017, Director: Jordi Vitrià i MarcaThis {{project is}} based on a {{challenge}} provided by the website called Kaggle, which involves the creation of an automatic learning system that makes possible a prediction of clicks on online advertising. Assuming this challenge, a program that is able to predict <b>ad</b> <b>clicks</b> has been created, but by using new technologies like Docker, which makes possible a virtualization of a customized Linux environment ideal for programming Tensorflow, a library that enables an automatic, fast and flexible learning. The program’s main algorithm makes an automatic learning using a linear regression model that feeds from the database provided by Kaggle, which is destined for this challenge. This database is composed of a 10 day history of <b>ad</b> <b>clicks</b> and no clicks...|$|R
50|$|Prioritizing clicks {{refers to}} display <b>click</b> <b>ads,</b> {{although}} advantageous by being ‘simple, fast and inexpensive’ rates for display ads in 2016 is only 0.10 {{percent in the}} United States. This means one in a thousand <b>click</b> <b>ads</b> are relevant therefore having little effect. This displays that marketing companies should not just use <b>click</b> <b>ads</b> {{to evaluate the effectiveness}} of display advertisements (Whiteside, 2016).|$|R
50|$|A trick banner is {{a banner}} ad where the ad copy imitates some screen element users {{commonly}} encounter, {{such as an}} operating system message or popular application message, to induce <b>ad</b> <b>clicks.</b> Trick banners typically do not mention the advertiser in the initial ad, and thus they are a form of bait-and-switch. Trick banners commonly attract a higher-than-average click-through rate, but tricked users may resent the advertiser for deceiving them.|$|R
40|$|Abstract: In {{this paper}} {{addresses}} estimating {{the number of}} the users of a specific application behind IP address (IPs). This problem is central to combating abusive traffic, such as DDoS attacks, <b>ad</b> <b>click</b> fraud and email spam, scams, phishing, and malware distribution. Here we proposed an efficient method to classify the IP addresses that are associated with a large number of user requests. The idea is to classify the network traffic based on the IP addresses by first clustering the data using K-mean clustering and then applying horizontal partition based id 3 decision tree. 1...|$|E
40|$|The contextual {{recommender}} task is {{the problem}} of making useful offers, e. g., placing ads or related links on a web page, based on the context information, e. g., contents of the page and information about the user visiting, and information on the available alternatives, i. e., the advertisements or relevant links. In the case of ads for example, the goal is to select ads that result in high click rates, where the (<b>ad)</b> <b>click</b> rate is some unknown function of the attributes of the context and ad. We describe the task and make connections to related problems including recommender and multi-armed bandit problems...|$|E
40|$|This thesis {{deals with}} the {{optimization}} of displaying online ads (frequency capping), where ad serving represents a cost, and clicks on the ads represent advertising revenue. In this case {{we would like to}} display the ad to the user so many times to have the biggest probability of the <b>ad</b> <b>click.</b> For this purpose, we converted the ad serving data to the appropriate format, analyzed it and used machine learning methods to make predictive models with the aim of predicting the optimal number of viewable impressions per user on a specific ad campaign. Afterwards, we used these predictive models in the ad serving simulation where we measured the performance of each procedure. The result of the thesis is the selection of the best procedure to assess the optimal number of viewable ad impressions per user...|$|E
5000|$|Google claims their users click (organic) {{search results}} {{more often than}} ads, {{essentially}} rebutting the research cited above. A 2012 Google study found that 81% of ad impressions and 66% of <b>ad</b> <b>clicks</b> happen {{when there is no}} associated organic search result on the first page. Research has shown that searchers may have a bias against ads, unless the ads are relevant to the searcher's need or intent ...|$|R
40|$|In this {{research}} we {{examine how the}} number of organic clicks change when search ads are present and when search ad campaigns are turned off. We then develop a statistical model to estimate the fraction of total clicks that {{can be attributed to}} search advertising. A meta-analysis of several hundred of these studies reveals that over 89 % of the <b>ads</b> <b>clicks</b> are incremental, {{in the sense that the}} visits to the advertiser’s site would not have occurred without the ad campaigns. ...|$|R
40|$|In this research, {{we examine}} how the number of mobile organic clicks changes when {{advertisers}} significantly change their mobile ad spend. This continues the line of research of search ads pause by applying it to the mobile platform. We utilize a statistical model to estimate the fraction of clicks that {{can be attributed to}} mobile search advertising. A metastudy of 327 advertisers reveals that 88 % of <b>ad</b> <b>clicks</b> are incremental, {{in the sense that the}} visits to the advertiser’s site would not have occurred without the mobile ad campaigns. ...|$|R
40|$|We {{study the}} {{trade-off}} between layout {{elements of the}} search results page and revenue in the real-time sponsored search auction. Using data from a randomized experiment on a major search engine, we find that having images present among the search results tends to simultaneously raise the ad click-through rate and flatten the <b>ad</b> <b>click</b> curve, reducing the premium for occupying the top slot and thus impacting bidding incentives. Theoretical analysis shows {{that this type of}} change creates an ambiguous impact on revenue in equilibrium: a steeper curve with lower total click-through rate is preferable only if the expected revenue distribution is skewed enough towards the top bidder. Empirically, we show that this is a relatively rare phenomenon, and we also find that whole page satisfaction causally raises the click-through rate of the ad block. This means search engines have a short-run incentive to boost search result quality, not just a long-run incentive based on competition between providers...|$|E
40|$|Click {{prediction}} {{is one of}} the fundamental problems in sponsored search. Most of existing studies took ad-vantage of machine learning approaches to predict <b>ad</b> <b>click</b> for each event of ad view independently. However, as observed in the real-world sponsored search system, user’s behaviors on ads yield high dependency on how the user behaved along with the past time, especially in terms of what queries she submitted, what ads she clicked or ignored, and how long she spent on the land-ing pages of clicked ads, etc. Inspired by these observa-tions, we introduce a novel framework based on Recur-rent Neural Networks (RNN). Compared to traditional methods, this framework directly models the depen-dency on user’s sequential behaviors into the click pre-diction process through the recurrent structure in RNN. Large scale evaluations on the click-through logs from a commercial search engine demonstrate that our ap-proach can significantly improve the click prediction ac-curacy, compared to sequence-independent approaches...|$|E
40|$|Behavioral Targeting (BT), {{which aims}} to deliver the most {{appropriate}} advertisements to the most appropriate users, is attracting much attention in online advertising market. A key challenge of BT is how to automatically segment users for ads delivery, and good user segmentation may significantly improve the ad click-through rate (CTR). Different from classical user segmentation strategies, which rarely take the semantics of user behaviors into consideration, we propose in this paper a novel user segmentation algorithm named Probabilistic Latent Semantic User Segmentation (PLSUS). PLSUS adopts the probabilistic latent semantic analysis to mine the relationship between users and their behaviors so as to segment users in a semantic manner. We perform experiments on the real world <b>ad</b> <b>click</b> through log of a commercial search engine. Comparing {{with the other two}} classical clustering algorithms, K-Means and CLUTO, PLSUS can further improve the ads CTR up to 100 %. To our best knowledge, this work is an early semantic user segmentation study for BT in academia...|$|E
5000|$|NebuAd used data such as Web search terms, page views, {{page and}} <b>ad</b> <b>clicks,</b> {{time spent on}} {{specific}} sites, zip code, browser info and connection speed to categorise a user's interests. [...] NebuAd did {{not have access to}} user identification information from the ISP, but may have been able to discover this through traffic monitoring (for example, email traffic may tie an email address to an ip address). Bob Dykes, the NebuAd CEO claimed in 2008; [...] "We have 800 interest segments today and we're expanding that to multiple thousands".|$|R
40|$|Click-spam {{in online}} advertising, where {{unethical}} publishers use malware or trick users into <b>clicking</b> <b>ads,</b> siphons off {{hundreds of millions}} of advertiser dollars meant to support free websites and apps. Ad networks today, sadly, rely primarily on security through obscurity to defend against click-spam. In this paper, we present Viceroi, a principled approach to catching click-spam in search ad networks. It is designed based on the intuition that click-spam is a profit-making business that needs to deliver higher return on investment (ROI) for click-spammers thanother (ethical) business models to offset the risk of getting caught. Viceroi operates at the ad network where it has visibility into all <b>ad</b> <b>clicks.</b> Working with a large real-world ad network, we find that thesimple-yet-generalViceroiapproachcatchesoversixvery different classes of click-spam attacks (e. g., malware-driven, search-hijacking, arbitrage) without any tuning knobs...|$|R
50|$|Sometimes these {{visitors}} {{are the result}} of targeted or un-targeted advertisements that may lead to impulse buys that fulfill desires for luxury or non-essential items. These ads might show up as banner <b>ads,</b> pay per <b>click</b> <b>ads,</b> social network ads and other revenue generators through ad networks and affiliate marketing.|$|R
40|$|Predicting user responses, such as clicks and conversions, is {{of great}} {{importance}} and has found its usage in many Web applications including recommender systems, web search and online advertising. The data in those applications is mostly categorical and contains multiple fields; a typical representation is to transform it into a high-dimensional sparse binary feature representation via one-hot encoding. Facing with the extreme sparsity, traditional models may limit their capacity of mining shallow patterns from the data, i. e. low-order feature combinations. Deep models like deep neural networks, on the other hand, cannot be directly applied for the high-dimensional input because of the huge feature space. In this paper, we propose a Product-based Neural Networks (PNN) with an embedding layer to learn a distributed representation of the categorical data, a product layer to capture interactive patterns between inter-field categories, and further fully connected layers to explore high-order feature interactions. Our experimental results on two large-scale real-world <b>ad</b> <b>click</b> datasets demonstrate that PNNs consistently outperform the state-of-the-art models on various metrics. Comment: 6 pages, 5 figures, ICDM 201...|$|E
40|$|Abstract—Estimating a user’s {{propensity}} to click on a display ad or purchase a particular item {{is a critical}} task in targeted advertising, a burgeoning online industry worth billions of dollars. Better and more accurate estimation methods result in improved online user experience, as only relevant and interesting ads are shown, and may also lead to large benefits for advertisers, as targeted users {{are more likely to}} click or make a purchase. In this paper we address this important problem, and propose an approach for improved estimation of <b>ad</b> <b>click</b> or conversion prob-ability based on a sequence of user’s online actions, modeled using Hidden Conditional Random Fields (HCRF) model. In addition, in order to address the sparsity issue at the input side of the HCRF model, we propose to learn distributed, low-dimensional representations of user actions through a directed skip-gram, a neural architecture suitable for sequential data. Experimental results on a real-world data set comprising thousands of user sessions collected at Yahoo servers clearly indicate the benefits and the potential of the proposed approach, which outperformed competing state-of-the-art algorithms and obtained significant improvements in terms of retrieval measures. I...|$|E
40|$|Abstract—Estimating user’s {{propensity}} to click on a display ad or purchase a particular item {{is a critical}} task in targeted advertising, a burgeoning online industry worth billions of dollars. Better and more accurate estimation methods result in improved online experience for users, as only relevant and interesting ads are shown, and may also lead to large benefits for advertisers, as targeted users {{are more likely to}} click or make a purchase. In this paper we address this important problem, and propose an approach for improved estimation of <b>ad</b> <b>click</b> or conversion probability based on a sequence of user’s online actions, modeled using state-of-the-art Hidden Conditional Random Fields (HCRF) model. In addition, in order to address the sparsity issue at the input side of the HCRF model, we propose to learn a distributed, low-dimensional representation of user actions through a directed skip-gram model, a novel deep architecture suitable for sequential data. The experimental results on a real-world data set comprising thousands of online user sessions collected at servers of a large internet company clearly indicate the benefits and the potential of the proposed approach, which outperformed the competing state-of-the-art algorithms and obtained significant improvements in terms of retrieval measures. I...|$|E
40|$|This paper {{proposes a}} new unified {{optimization}} framework combining pay-per-click auctions and guaranteed delivery in sponsored search. Advertisers usually have different (and sometimes mixed) marketing goals: brand awareness and direct response. Different mechanisms {{are good at}} addressing different goals, e. g., guaranteed delivery was often used to build brand awareness and pay-per-click auctions was widely used for direct marketing. Our new method accommodates both in a unified framework, with the search engine revenue as an optimization objective. In this way, we can target a guaranteed number of <b>ad</b> <b>clicks</b> (or impressions) per campaign for advertisers {{willing to pay a}} premium and enabl...|$|R
50|$|Cost-per-click (CPC). Advertiser pays {{publisher}} {{a commission}} {{every time a}} visitor clicks on the advertiser's ad. It is irrelevant (for the compensation) how often an ad is displayed. commission is only due when the <b>ad</b> is <b>clicked.</b> See also click fraud.|$|R
50|$|An {{impression}} (in {{the context}} of online advertising) is when an ad is fetched from its source, and is countable. Whether the <b>ad</b> is <b>clicked</b> is not taken into account.Each time an ad is fetched, it is counted as one impression.|$|R
40|$|Each {{search term}} {{put into a}} search engine {{produces}} a separate set of results. Correspondingly, each of the sets of ads displayed alongside the results is priced using a separate auction. We investigate how bids for these context-based ads depends on the difficulty of making a match. This contrasts with the existing literature {{that focuses on the}} effect of match quality. We examine advertising prices paid by lawyers for 139 Google search terms in 195 locations. Other things being equal, the fewer searches there are on a term, the higher the price. To identify a causal relationship between match-difficulty and prices paid, we exploit a natural experiment in 'ambulance-chaser' regulations across states. When lawyers cannot contact a client by mail and matching becomes more difficult, the relative price per <b>ad</b> <b>click</b> is $ 0. 93 higher. We check the robustness of this result by performing a falsification test using a different ambulance-chaser regulation. Our results suggest that prices are higher for context-based ads when the difficulty of both online and off-line matching increases. This highlights that a major reason why search advertising is profitable is because its use of context can monetize the 'long tail' by reducing friction in the matching process. ...|$|E
40|$|On most {{sponsored}} search platforms, advertisers bid on some keywords {{for their}} advertisements (ads). Given a search request, ad retrieval module rewrites the query into bidding keywords, and uses these keywords as keys to select Top N ads through inverted indexes. In this way, an ad {{will not be}} retrieved even if queries are related when the advertiser does not bid on corresponding keywords. Moreover, most ad retrieval approaches regard rewriting and ad-selecting as two separated tasks, and focus on boosting relevance between search queries and ads. Recently, in e-commerce sponsored search more and more personalized information has been introduced, such as user profiles, long-time and real-time clicks. Personalized information makes ad retrieval able to employ more elements (e. g. real-time clicks) as search signals and retrieval keys, however it makes ad retrieval more difficult to measure ads retrieved through different signals. To address these problems, we propose a novel ad retrieval framework beyond keywords and relevance in e-commerce sponsored search. Firstly, we employ historical <b>ad</b> <b>click</b> data to initialize a hierarchical network representing signals, keys and ads, in which personalized information is introduced. Then we train a model {{on top of the}} hierarchical network by learning the weights of edges. Finally we select the best edges according to the model, boosting RPM/CTR. Experimental results on our e-commerce platform demonstrate that our ad retrieval framework achieves good performance...|$|E
40|$|Each {{search term}} {{put into a}} search engine {{produces}} a separate set of results. Correspondingly, each of the sets of ads displayed alongside these results is priced using a separate auction. Search engine advertising prices therefore reflect willingness to pay for context, unlike traditional ad prices that reflect willingness to pay for audience demographics. A growing policy debate asks if this marketing strategy merely makes advertising more informative, or whether it also effectively extracts rent from advertisers. To inform this debate and to better understand search engine advertising more generally, we examine advertising prices paid by lawyers for 174 Google search terms in 195 locations and exploit a natural experiment in “ambulance-chaser” regulations across states. Where contingency fee limits exist, the relative price of advertising is $ 2. 27 lower. This suggests that context-based pricing allows prices to reflect heterogeneity in the profitability of customer leads. When lawyers cannot contact a client in writing, the relative price per <b>ad</b> <b>click</b> is $ 0. 93 higher. This suggests that context-based pricing allows prices to reflect heterogeneity in advertisers’ other advertising options, even within a given local market. Thus, our results suggest that search engine advertising does give market power to the media platform; however, this market power is mitigated by substantial competition from offline marketing communications channels. search engines, advertising, market power, advertising prices...|$|E
50|$|Pay-per-click (PPC), {{also known}} as cost per click (CPC), is an {{internet}} advertising model used to direct traffic to websites, in which an advertiser pays a publisher (typically a website owner or a network of websites) when the <b>ad</b> is <b>clicked.</b>|$|R
40|$|The {{study is}} aimed to {{investigate}} the relationships among consumers' beliefs about online advertising, attitudes toward online advertising (ATOA), and consumer behavioral responses in three different nations. Among the major findings, (1) all five belief factors (i. e., information seeking, entertainment, economy, credibility, and value corruption) were statistically significant predictors of ATOA, which in turn, significantly predicted online <b>ad</b> <b>clicking</b> and frequency of online shopping, and (2) consumers' beliefs, attitudes and behavioral responses toward online advertising, and relationships thereof, varied across countries (i. e., the U. S., China, and Romania). Romanians had the most positive ATOA and {{were most likely to}} click on advertisements. Americans, however, made the most online purchases. Attitudes Beliefs China Online advertising Romania...|$|R
40|$|Abstract. Search {{engines are}} key to finding {{information}} on the web. Search presently is free for users – financed by targeted advertisement. Today, the current search terms determine the ad placement. In the near future, search-engine providers will make use of detailed user profiles for better ad placement. This puts user privacy at risk. Anonymizing search histories, which is a solution in principle, gives way to a trade-off between privacy and the usability of the data for ad placement. This paper studies this tradeoff systematically. To this end, we implement an algorithm for the anonymization of search histories which is flexible regarding the target function. It can retain frequent terms or terms where corresponding <b>ads</b> are <b>clicked</b> with a high probability, keep up the number of users it can derive interests for, etc. We quantify {{the usefulness of the}} anonymized log for ad placement in a broad way, e. g., by estimating the number of <b>ad</b> <b>clicks</b> or of <b>ad</b> impressions, based on marketing data from Yahoo! As a result, anonymized search logs are still useful for ad placement, but this very much depends on the target function. ...|$|R
40|$|To reach {{consumers}} with marketing in today's digital climate {{is in need}} of highly accurate and relevant ads. Consumer are in constant information bombardment and increasingly tougher competition is making it more complicated to reach your target consumers that wants to see and get what they want whenever they want it. Dynamic retargeting is highly intelligent, utilizing the latest technology for performance marketing, which enables ads that are highly accurate and relevant through personalization, cost efficient and revenue generating. This is possible due to algorithms targeting most likely conversion (company defined valuable post <b>ad</b> <b>click</b> actions) targets and at the right moment in their purchasing funnel. Our findings, based on analysis of dynamic retargeting campaigns from a Swedish-, Danish- and Finnish company, support previous literature that ad personalization and timing will affect consumer engagement and also their purchase behavior, positively affecting ROI. The data show that dynamic retargeting considering timing (in this case, ads targeted directly after browsing instead of 8 -hour delay) had 3. 4 % higher banner click-through rate and a conversion rate that was 13. 1 % higher. We also found that dynamic retargeting is increasing ROI. The result show that dynamic retargeting had a incremental ROI of 62 times the investment compared to buyers not targeted with dynamic retargeting. Lastly, we recognized the importance of being able to recognize users across different devices. We found that 72 % of buyers used at least 2 devices and switched at least 3 times before the purchase, which highly suggest cross device recognition as an important feature in dynamic retargeting, in order to gain efficiency in ad delivery, costs and results...|$|E
40|$|Summary Atopic {{dermatitis}} (AD) {{has a high}} {{negative impact}} on quality of life. Acupuncture has antipruritic actions and may assist in treatment of AD; however, {{the current state of}} evidence for this remains unknown. We aimed to evaluate the efficacy of acupuncture against placebo/sham acupuncture in the management of AD. Electronic searches were conducted on a number of databases, from their inception until November 2013. Studies comparing the effects of acupuncture with those of placebo/sham acupuncture on severity of disease or symptoms/signs of AD were included. We did not find any studies that were eligible to be included in this systematic review. Among the excluded studies, there were two studies that evaluated the antipruritic effects of acupuncture and one study that evaluated the effects of acupuncture on IgE-mediated allergy. However, there were no randomized controlled trials evaluating the effects of acupuncture on AD as a disease. This finding therefore provides an indication of the current state of evidence of acupuncture in the management of AD, and highlights the research gap that exists, in that {{there is a lack of}} gold-standard studies (i. e. RCTs) to support valid conclusions. There is currently no evidence of the effects of acupuncture in the management of AD, and no evidence-based recommendations or conclusions can be made from this review. Several studies indicated that acupuncture may have a role in reducing itch or regulating IgE-mediated allergy, both of which are major characteristics of AD. However, there were no RCTs evaluating the effects of acupuncture on AD as a disease. There is therefore an urgent need for rigorously designed RCTs to assess the efficacy of acupuncture in the management of <b>AD.</b> <b>Click</b> here for the corresponding questions to this CME article...|$|E
40|$|Following the Netflix prize, the {{collaborative}} filtering problem has gained significant attention within machine learning, spawning novel models and theoretical analyses. In parallel, {{the growth of}} social media has driven research in link prediction, {{with the aim of}} determining whether two individuals in a network are likely to know each other. Both problems involve the prediction of label (star ratings or friendship) between a pair of entities (user-movie or user-user). We call this general problem dyadic prediction. The problem arises in several other guises: predicting student responses to test questions, military disputes between nations, and clickthrough rates of webpages on ads, to name a few. In general, each such domain employs a markedly different approach, obscuring the underlying similarity of the problems being solved. This dissertation aims to explore the use of a single general method, based on latent feature modelling, for generic dyadic prediction problems. To this end, we make three contributions. First, we propose a generic framework with which to analyze dyadic prediction problems. This lets one reason about seemingly disparate problems in a unified manner. Second, we propose a model based on the log-linear framework, which is applicable to each of the aforementioned problems. The model learns latent features from dyadic data, and estimates a probability distribution over labels. Third, we systematically explore applications of our latent feature model to domains such as collaborative filtering, link prediction, and clickthrough rate prediction. In all cases, we show performance comparable or superior to existing state-of-the-art methods. For clickthrough rate prediction, ours represents the first application of latent feature modelling to the problem, demonstrating the value in a single framework with which to reason about these problems. We also show that latent feature modelling is scalable to datasets with hundreds of millions of observations on a single machine (the Netflix prize dataset), and hundreds of billions of observations on a small cluster (Yahoo! <b>ad</b> <b>click</b> data). We conclude with a discussion of future research directions, including transferring information from one network to another, and adapting to domains with extreme label sparsit...|$|E
50|$|Ad fraud (also {{referred}} to as Invalid Traffic) is concerned with {{theory and practice of}} fraudulently representing online advertisement impressions, clicks, conversion or data events in order to generate revenue. While ad fraud is more generally associated with banner ads, video ads and in-app <b>ads,</b> <b>click</b> fraud has been associated with search marketing and conversion fraud with affiliate marketing. Ad fraud is the categorical term inclusive of all forms of online advertising fraud. In 2004 Google's CFO George Reyes said that fraud is the biggest threat to internet economy with the first research paper covering the topic in 1999 or earlier. In 2016 World Federation of Advertisers published its first guidance on Ad fraud to advice its members on how to counter the problem allegedly eating close to US$20 billion of its members ad budgets in 2015.|$|R
40|$|Many Android {{applications}} are distributed for free but {{are supported by}} advertisements. Ad libraries embedded in the app fetch content from the ad provider and display it on the app's user interface. The ad provider pays the developer for the ads displayed to the user and <b>ads</b> <b>clicked</b> by the user. A major threat to this ecosystem is ad fraud, where a miscreant's code fetches ads without displaying them to the user or " on ads automatically. Ad fraud has been extensively studied {{in the context of}} web advertising but has gone largely unstudied in the context of mobile advertising. We take the rst step to study mobile ad fraud perpe-trated by Android apps. We identify two fraudulent ad behaviors in apps: 1) requesting ads while the app is in the background, and 2) <b>clicking</b> on <b>ads</b> without user in...|$|R
50|$|Some of the {{problems}} associated with search engine advertising is click fraud. This is when <b>ads</b> are <b>clicked</b> on with no intention of purchasing anything. The search engines still charge the advertiser for these clicks, if the advertiser does not discover the fraud. Many online advertisers have discovered that clicks do not equal calls.|$|R
