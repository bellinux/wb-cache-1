1139|5606|Public
25|$|The {{simplest}} {{method for}} scan converting (rasterizing) a Bézier curve is to evaluate it at many closely spaced points and scan convert the approximating sequence of line segments. However, {{this does not}} guarantee that the rasterized output looks sufficiently smooth, because the points may be spaced too far apart. Conversely it may generate too many points {{in areas where the}} curve is close to linear. A common <b>adaptive</b> <b>method</b> is recursive subdivision, in which a curve's control points are checked to see if the curve approximates a straight line to within a small tolerance. If not, the curve is subdivided parametrically into two segments, 0 ≤ t ≤ 0.5 and 0.5 ≤ t ≤ 1, and the same procedure is applied recursively to each half. There are also forward differencing methods, but great care must be taken to analyse error propagation.|$|E
2500|$|OptiPNG, pngcrush, pngout, and zopflipng all offer options {{applying}} one of {{the filter}} types 0–4 globally (using the same filter type for all lines) or with a [...] "pseudo filter" [...] (numbered 5), which for each line chooses {{one of the}} filter types 0–4 using an adaptive algorithm. Zopflipng offers 3 different <b>adaptive</b> <b>method,</b> including a brute-force search that attempts to optimize the filtering.|$|E
5000|$|RPROP+ {{is defined}} at A Direct <b>Adaptive</b> <b>Method</b> for Faster Backpropagation Learning: The RPROP Algorithm.|$|E
40|$|Grid <b>adaptive</b> <b>methods</b> {{combined}} with domain adaptation are discussed for two-dimensional seepage flow problems with free boundaries through porous media. Examples of grid and domain <b>adaptive</b> <b>methods</b> are presented to demonstrate {{several ways to}} predict grids and shapes of free boundaries using an iterative scheme. Finally, the combined <b>adaptive</b> <b>methods</b> are applied to obtain smooth non-oscillatory shape of a free boundary of seepage flow through non-homogeneous porous media...|$|R
40|$|The {{ability of}} human {{teachers}} {{to adapt the}} teaching process to features of the individual learner {{is one of the}} key factors for effective teaching and learning. Individualized instruction utilizes <b>adaptive</b> <b>methods</b> for the optimization of the learning process and its outcome. <b>Adaptive</b> <b>methods</b> and their effective variation and integration in learning environments are the subject of this work. In the first part a schema for the classification of <b>adaptive</b> <b>methods</b> consisting of four dimensions is introduced: The means of adaptation (What is adapted?), the content of the adaptation (What is the criteria for adaptation?), the process of adaptation (How does the system adapt?), and the aim of the adaptation (Why does the system adapt?). Based on this schema recent works from the fields of adaptive hypermedia, intelligent multimedia, adaptive user interfaces, and intelligent tutoring systems are analysed. In the second part empirical studies that evaluate several variations of <b>adaptive</b> <b>methods</b> are described. The results show the complex interaction of <b>adaptive</b> <b>methods</b> and learner features and give some starting points for effective integration of <b>adaptive</b> <b>methods</b> in learning environments. The systems and experiments from the empirical part can be found in the WWW ([URL]...|$|R
40|$|This thesis {{contains}} {{research into}} <b>adaptive</b> <b>methods</b> for the spatial and angular {{dimensions of the}} neutral particle transport equation. <b>Adaptive</b> <b>methods</b> {{have been developed for}} two angular discretisations: the spherical harmonics method and an octahedron-based wavelet discretisation. The spatial discretisation used is a sub-grid scale finite element method. The primary focus of the research is goal-based <b>adaptive</b> <b>methods</b> which optimise a particular functional of the solution. The error measures that drive the <b>adaptive</b> <b>methods</b> are presented along with the novel and efficient techniques that are used to approximate them. Adaptive algorithms are first developed and presented for the spatial and angular discretisations separately. The <b>adaptive</b> <b>methods</b> for the angular dimensions produce variable angular resolution across the space and energy dimensions of the equation. The <b>adaptive</b> <b>methods</b> for the spatial dimensions use an anisotropic mesh optimisation algorithm which repositions nodes and elements of the mesh. The adaptive wavelet discretisation allows anisotropic resolution of the angular domain at each point in space and energy which can be very efficient. The ultimate outcome of the research is an algorithm that adapts the angular and spatial resolution simultaneously. This is achieved using the wavelet discretisation by combining the individual adaptive procedures. All <b>adaptive</b> <b>methods</b> developed are shown to produce results with a given accuracy for a smaller number of degrees of freedom. The performance of the methods heavily depends on the physical system that is being modelled. Typically performing best in shielding type calculations. The benefits from the <b>adaptive</b> <b>methods</b> are two-fold: (i) the reduction in degrees of freedom can lead to smaller computational times, and (ii) the automated adaptive process can reduce the overall user time spent performing convergence analysis. Open Acces...|$|R
5000|$|<b>Adaptive</b> <b>Method</b> and Software Architecture for Efficient Transaction Processing and Error Management [...] "Patent Application No. 11/515470 Pub. No. 20070174185." ...|$|E
50|$|The <b>Adaptive</b> <b>method</b> of {{measurement}} is {{implemented by the}} so-called electronic apex locator. In the process of penetrating the instrument makes continuous measurements and selects a suitable method {{of measurement}}. In case of dry canal the device uses the method of Prof. Sonada. In case of wet canal the device automatically adjusts the measurement method of Professor Kobayashi. The <b>adaptive</b> <b>method</b> is highly accurate and does not require moistening or drying the canal.|$|E
5000|$|OptiPNG, pngcrush, pngout, and zopflipng all offer options {{applying}} one of {{the filter}} types 0-4 globally (using the same filter type for all lines) or with a [...] "pseudo filter" [...] (numbered 5), which for each line chooses {{one of the}} filter types 0-4 using an adaptive algorithm. Zopflipng offers 3 different <b>adaptive</b> <b>method,</b> including a brute-force search that attempts to optimize the filtering.|$|E
40|$|<b>Adaptive</b> {{optimization}} <b>methods,</b> which perform local optimization with a metric {{constructed from}} the history of iterates, are becoming increasingly popular for training deep neural networks. Examples include AdaGrad, RMSProp, and Adam. We show that for simple overparameterized problems, <b>adaptive</b> <b>methods</b> often find drastically different solutions than gradient descent (GD) or stochastic gradient descent (SGD). We construct an illustrative binary classification problem where the data is linearly separable, GD and SGD achieve zero test error, and AdaGrad, Adam, and RMSProp attain test errors arbitrarily close to half. We additionally study the empirical generalization capability of <b>adaptive</b> <b>methods</b> on several state-of-the-art deep learning models. We observe that the solutions found by <b>adaptive</b> <b>methods</b> generalize worse (often significantly worse) than SGD, even when these solutions have better training performance. These results suggest that practitioners should reconsider the use of <b>adaptive</b> <b>methods</b> to train neural networks...|$|R
40|$|Simpson (1988) {{has argued}} that the method of {{constant}} stimuli is as efficient as <b>adaptive</b> <b>methods</b> of threshold estimation and has supported this claim with simulations. It is shown that Simpson's simulations are not a reasonable model of the experimental process and that more plausible simulations confirm that <b>adaptive</b> <b>methods</b> are much more efficient that the method of constant stimuli...|$|R
5000|$|... <b>adaptive</b> <b>methods</b> which {{work with}} fewer (or no) {{parameters}} under {{a large number}} of condition ...|$|R
50|$|Adaptive {{histogram}} equalization (AHE) {{is a computer}} image processing technique used to improve contrast in images. It differs from ordinary {{histogram equalization}} in the respect that the <b>adaptive</b> <b>method</b> computes several histograms, each corresponding to a distinct section of the image, and uses them to redistribute the lightness values of the image. It is therefore suitable for improving the local contrast and enhancing the definitions of edges in each region of an image.|$|E
50|$|Adaptive {{methods are}} used to improve the {{accuracy}} of the solutions. The <b>adaptive</b> <b>method</b> is referred to as ‘h’ method if mesh refinement is used, ‘r’ method if the number of grid point is fixed and not redistributed and ‘p’ if the order of solution scheme is increased in finite-element theory. The multi diemensional problems using the equi-distribution scheme can be accomplished in several ways. The simplest to understand are the Poisson Grid Generators with control function based on the equidistribution of the weight function with the diffusion set as a multiple of desired cell volume. The equidistribution scheme can also be applied to the unstructured problem. The problem is the connectivity hampers if mesh point movement is very large. Steady flow and the time-accurate flow calculation can be solved through this <b>adaptive</b> <b>method.</b> The grid is refined and after a predetermined number of iteration in order to adapt it in a steady flow problem. The grid will stop adjusting to the changes once the solution converges. In time accurate case coupling of the Partial Differential Equations of the physical problem and those describing the grid movement is required.|$|E
50|$|The Gauss-Kronrod {{quadrature}} {{formula is}} an <b>adaptive</b> <b>method</b> for numerical integration. It is {{a variant of}} Gaussian quadrature, in which the evaluation points are chosen so that an accurate approximation can be computed by re-using the information produced by the computation of a less accurate approximation. It {{is an example of}} what is called a nested quadrature rule: for the same set of function evaluation points, it has two quadrature rules, one higher order and one lower order (the latter called an embedded rule). The difference between these two approximations is used to estimate the calculational error of the integration.|$|E
5000|$|Marc Lankhorst. Agile Service Development - Combining <b>Adaptive</b> <b>Methods</b> and Flexible Solutions. With others (ed.). Berlin: Springer-Verlag, 2012.|$|R
40|$|Abstract:- This paper {{deals with}} the {{experimental}} control of a rotating active magnetic bearing (AMB) system using PID-type fuzzy controllers (PIDFCs) with parameter <b>adaptive</b> <b>methods.</b> There are three kinds of parameter <b>adaptive</b> <b>methods,</b> including fuzzy tuner, function tuner, and relative rate observer, have been proposed in literatures for tuning the coefficients of PIDFCs. However, only a simulation comparison between these methods for control of a second-order linear system with varying parameters and time delay {{has been done in}} literatures. In general, theoretical models need to be confirmed and modified through experimental results. This paper provides experimental verification by applying PIDFCs with self-tuning algorithms for control of a highly nonlinear AMB system. Key-Words:- PID-type fuzzy controllers, parameter <b>adaptive</b> <b>methods,</b> self-tuning scaling factors, active magnetic bearing...|$|R
30|$|Methods {{based on}} the {{statistics}} of the image, which include Price and spatially <b>adaptive</b> <b>methods,</b> Bayesian-based and super-resolution methods.|$|R
50|$|Adaptive methods {{focus on}} {{adapting}} quickly to changing realities. When {{the needs of}} a project change, an adaptive team changes as well. An adaptive team has difficulty describing exactly what will happen in the future. The further away a date is, the more vague an <b>adaptive</b> <b>method</b> is about what will happen on that date. An adaptive team cannot report exactly what tasks they will do next week, but only which features they plan for next month. When asked about a release six months from now, an adaptive team might be able to report only the mission statement for the release, or a statement of expected value vs. cost.|$|E
50|$|In June 2008, at the Hospital Clínic de Barcelona, Professor Paolo Macchiarini and his team, of the University of Barcelona, {{performed}} the first tissue engineered trachea (wind pipe) transplantation. Adult stem cells were {{extracted from the}} patient's bone marrow, grown into a large population, and matured into cartilage cells, or chondrocytes, using an <b>adaptive</b> <b>method</b> originally devised for treating osteoarthritis. The team then seeded the newly grown chondrocytes, as well as epithileal cells, into a decellularised (free of donor cells) tracheal segment that was donated from a 51-year-old transplant donor who had died of cerebral hemorrhage. After four days of seeding, the graft was used to replace the patient's left main bronchus. After one month, a biopsy elicited local bleeding, indicating that the blood vessels had already grown back successfully.|$|E
50|$|The {{simplest}} {{method for}} scan converting (rasterizing) a Bézier curve is to evaluate it at many closely spaced points and scan convert the approximating sequence of line segments. However, {{this does not}} guarantee that the rasterized output looks sufficiently smooth, because the points may be spaced too far apart. Conversely it may generate too many points {{in areas where the}} curve is close to linear. A common <b>adaptive</b> <b>method</b> is recursive subdivision, in which a curve's control points are checked to see if the curve approximates a straight line to within a small tolerance. If not, the curve is subdivided parametrically into two segments, 0 ≤ t ≤ 0.5 and 0.5 ≤ t ≤ 1, and the same procedure is applied recursively to each half. There are also forward differencing methods, but great care must be taken to analyse error propagation.|$|E
3000|$|..., {{which is}} in general difficult. To {{overcome}} this difficulty, several authors proposed several various of <b>adaptive</b> <b>methods,</b> which permit the step size [...]...|$|R
40|$|AbstractWe {{study the}} problem of optimal {{recovery}} {{in the case of}} a nonsymmetric convex class of functions. We compare <b>adaptive</b> and nonadaptive <b>methods</b> and prove a bound on how much better <b>adaptive</b> <b>methods</b> can be. We use new inequalities between Gelfand widths and Bernstein widths and new relations between these widths and optimal error bounds for <b>adaptive</b> and nonadaptive <b>methods,</b> respectively...|$|R
40|$|We {{study the}} problem of optimal {{recovery}} {{in the case of}} a nonsymmetric convex class of functions. In particular we show that <b>adaptive</b> <b>methods</b> may be much better than nonadaptive methods. We define certain Gelfand-type widths that are useful for nonsymmetric classes and prove relations to optimal error bounds for <b>adaptive</b> and nonadaptive <b>methods,</b> respectively. 1 Optimal Recovery and n-Widths For Convex Classes of Functions Erich Novak Abstract. We study {{the problem of}} optimal recovery {{in the case of a}} nonsymmetric convex class of functions. In particular we show that <b>adaptive</b> <b>methods</b> may be much better than nonadaptive methods. We define certain Gelfand-type widths that are useful for nonsymmetric classes and prove relations to optimal error bounds for <b>adaptive</b> and nonadaptive <b>methods,</b> respectively. 1...|$|R
50|$|A Fuel Model is {{a stylized}} set of fuel bed {{characteristics}} {{used as input}} {{for a variety of}} wildfire modeling applications. Wildfire behavior models, such as those of Rothermel, take into account numerous empirical variables. While these inputs are important for equation outputs, they are often difficult and time-consuming, if not impossible, to measure for each fuel bed. A fuel model defines these input variables for a stylized set of quantitative vegetation characteristics that can be visually identified in the field. Depending on local conditions, one of several fuel models may be appropriate. As Anderson states “Fuel models are simply tools to help the user realistically estimate fire behavior. The user must maintain a flexible frame of mind and an <b>adaptive</b> <b>method</b> of operating to totally utilize these aids". Furthermore, depending on the application, the user must choose a fuel model classification system. The major classification systems for use in the United States include the National Fire Danger Rating System, the 13 ‘original’ fuel models of Anderson and Albini, the subsequent set of 40 fuels produced by Scott and Burgan, and the Fuel Characteristics Classification System.|$|E
50|$|At {{the method}} level, the LoD leads to narrow interfaces, giving access to only as much {{information}} as it needs to do its job, as each method needs to know about a small set of methods of closely related objects. On the other hand, at the class level, the LoD leads to wide (i.e. enlarged) interfaces, because the LoD requires introducing many auxiliary methods instead of digging directly into the object structures. One {{solution to the problem of}} enlarged class interfaces is the aspect-oriented approach, where the behavior of the method is specified as an aspect at a high level of abstraction. This is done by having an <b>adaptive</b> <b>method</b> that encapsulates the behaviour of an operation into a place, with which the scattering problem is solved. It also abstracts over the class structure that results in avoiding the tangling problem. The wide interfaces are managed through a language that specifies implementations. Both the traversal strategy and the adaptive visitor use only a minimal set of classes that participate in the operation, and the information about the connections between these classes is abstracted out.|$|E
40|$|Abstract This is {{part two}} of a work on {{adaptive}} integration methods aimed at multidimensional option pricing problems in finance. It presents simulation results of an <b>adaptive</b> <b>method</b> developed in the companion article [3] {{for the evaluation of}} multidimensional integrals over the unit cube. The article focuses on a rather general test problem constructed to give insights in the success of the <b>adaptive</b> <b>method</b> for option pricing problems. We establish a connection between the decline rate of the ordered eigenvalues of the pricing problem and the efficiency of the <b>adaptive</b> <b>method</b> relative to the non-adaptive. This gives criteria for when the <b>adaptive</b> <b>method</b> can be expected to outperform the non-adaptive for other pricing problems. In addition to evaluating the method for different problem parameters, we present simulation results after adding various techniques to enhance the <b>adaptive</b> <b>method</b> itself. This includes using variance reduction techniques for each sub-problem resulting from the partitioning of the integration domain. All simulations are done with both pseudo-random numbers and quasi-random numbers (low discrepancy sequences), resulting in Monte Carlo (MC) and quasi-Monte Carlo (QMC) estimators and the ability to compare them in the given setting. The results show that the <b>adaptive</b> <b>method</b> can give performance gains in the order of magnitudes for many configurations, but it should not be used incautious, since this ability depends heavily on the problem at hand. ...|$|E
30|$|Among these  <b>adaptive</b> <b>methods</b> stand {{empirical}} mode decomposition (EMD). This {{technique has}} been introduced recently by Huang et al. (1998) as a required step to compute the instantaneous frequencies through the Hilbert transform. However, being quite intuitive and direct, it {{has become one of}} the most used <b>adaptive</b> <b>methods</b> to deal with data series originating from nonlinear and non-stationary processes. Because of its excellence, it has been applied in different physical contexts from seismology (Battista et al. 2007) to oceanography (Schlurmann 2000, 2002) without considering the applications in biomedical signal processing (Pachori 2008) and in signal denoising (Flandrin et al. 2004).|$|R
40|$|The {{general theory}} {{development}} for <b>adaptive</b> <b>methods</b> of the non-linear spectral estimation in problems with finite samples of observations is {{the aim of}} the paper. As a result the new variation principle and the new class of <b>adaptive</b> <b>methods</b> for the non-linear spectral estimation, methods corresponding to the information criterion of the observation entropy minimax, have been developed. Some new adaptive algorithms for the information processing, realized in the form of application packages for personal computers, have been synthesized and investigated of effectivenessAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|R
40|$|Recent {{work has}} shown that endfire {{beamforming}} of ocean noise {{can be used to}} produce images of the seabed layering [Siderius et al., J. Acoust. Soc. Am. 120, 1315 – 1323 (2006) ]. This initial noise imaging technique used conventional beamforming and was later extended to adaptive beamforming that is theoretically optimal. However, there can be problems with <b>adaptive</b> <b>methods,</b> which include extreme sensitivity to random errors, the required averaging time, and computational complexity. Here, the concept of supergain is used to show that delay and sum beamforming can produce nearly the same results as the optimal <b>adaptive</b> <b>methods</b> without the drawbacks...|$|R
40|$|In this paper, a local stencil <b>adaptive</b> <b>method</b> is presented, {{which is}} {{designed}} for solving computational fluid dynamics (CFD) problems with curved boundaries accurately. A local multiquadric-differential quadrature (MQ-DQ) method is used to discretize the governing equations, taking advantage of its meshless nature. The present method bears the properties of both local MQ-DQ method and local stencil <b>adaptive</b> <b>method</b> and is thus named the local MQ-DQ-based stencil <b>adaptive</b> <b>method.</b> Two test problems with curved boundaries are solved to investigate the performance of this solution-adaptive method. The numerical {{results indicate that the}} proposed method is effective and efficient by combining the advantages of meshless property for complex geometries and local adaptation for accuracy improvement. Copyright q 2007 Joh...|$|E
40|$|Abstract The paper {{presents}} an <b>adaptive</b> <b>method</b> {{for the evaluation}} of multidimensional integrals over the unit cube. The measure used to partition the domain is suited for integrands which are monotonic in each dimension individually, and is therefore suitable for problems stemming from finance where this is often the case. We use a QMC method for each sub-problem resulting from the partitioning of the domain. The article is part one of a work on this topic, and presents the method together with various local variance reduction techniques. The material is presented with an alignment to option pricing problems. In the companion paper we present an option pricing problem and simulation results on different setups of this. We compare the convergence properties of the <b>adaptive</b> <b>method</b> with the convergence properties of the QMC method used directly on the problem. We find that the <b>adaptive</b> <b>method</b> in many configurations outperform the conventional QMC method, and we develop criteria on the problem for when the <b>adaptive</b> <b>method</b> can be expected to outperform the conventional. ...|$|E
40|$|The Chaotic {{beamforming}} adaptive {{algorithm is}} new <b>adaptive</b> <b>method</b> for antenna array’s radiation pattern synthesis. This <b>adaptive</b> <b>method</b> {{based on the}} optimization of the Least Mean Square algorithm using Chaos theory enables fast adaptation of antenna array radiation pattern, reduction of the noisy reference signal’s impact, and {{the improvement of the}} tracking capabilities. We performed simulations for linear and circular antenna arrays. We also compared the performances of the used and existing algorithms in terms of the radiation pattern comparison...|$|E
50|$|<b>Adaptive</b> Simpson's <b>method,</b> {{also called}} <b>adaptive</b> Simpson's rule, {{is a method}} of {{numerical}} integration proposed by G.F. Kuncir in 1962. It is probably the first recursive adaptive algorithm for numerical integration to appear in print, although more modern <b>adaptive</b> <b>methods</b> based on Gauss-Kronrod quadrature and Clenshaw-Curtis quadrature are now generally preferred. <b>Adaptive</b> Simpson's <b>method</b> uses {{an estimate of the}} error we get from calculating a definite integral using Simpson's rule. If the error exceeds a user-specified tolerance, the algorithm calls for subdividing the interval of integration in two and applying <b>adaptive</b> Simpson's <b>method</b> to each subinterval in a recursive manner. The technique is usually much more efficient than composite Simpson's rule since it uses fewer function evaluations in places where the function is well-approximated by a cubic function.|$|R
40|$|AbstractWe {{study the}} problem of optimal {{recovery}} {{in the case of}} a nonsymmetric convex class of functions. In particular we show that <b>adaptive</b> <b>methods</b> may be much better than nonadaptive methods. We define certain Gelfand-type widths that are useful for nonsymmetric classes and prove relations to optimal error bounds for <b>adaptive</b> and nonadaptive <b>methods,</b> respectively...|$|R
50|$|Unlike the {{classical}} methods, where {{the pattern for}} changing the stimuli is preset, in <b>adaptive</b> <b>methods</b> the subject's response to the previous stimuli determines {{the level at which}} a subsequent stimulus is presented.|$|R
