2|1|Public
40|$|A case of {{pemphigus}} vulgaris (PV), putatively {{induced by}} topical application of polymyxin B ear drops, is described. A 3 -year-old, female Tosa Inu, presented with acute onset swelling, blistering and ulceration of the pinnae, nostrils, lips and oral mucous membranes. The dog was depressed, febrile and anorexic. For 7 {{days prior to}} {{the onset of the}} acute ulcerative disease, polymyxin B ear drops had been applied to both ears to treat an ear infection. Skin and mucosal biopsies showed suprabasilar cleft formation and acantholysis, indicative of PV. The polymyxin B ear drops were discontinued and the dog was treated with intravenous fluids, systemic and topical antibacterial therapy, and immunosuppressive therapy comprising prednisone and azathioprine. Complete remission was noted after 2 weeks, and the immunosuppressive therapy was discontinued one month later. No clinical signs of PV recurred over a 1 year follow-up period. As PV does not usually resolve spontaneously, or enter long-term remission, it was considered that the condition was most likely drug induced due to the <b>aural</b> <b>application</b> of polymyxin B. Jan Rybníçek and Peter B. Hil...|$|E
40|$|Indiana University-Purdue University Indianapolis (IUPUI) Existing web {{applications}} force {{users to}} focus their visual attentions on mobile devices, while browsing content and services on the go (e. g., while walking or driving). To support mobile, eyes-free web browsing and minimize interaction with devices, designers can leverage the auditory channel. Whereas acoustic interfaces {{have proven to be}} effective in regard to reducing visual attention, a perplexing challenge exists in designing aural information architectures for the web because of its non-linear structure. To address this problem, we introduce and evaluate techniques to remodel existing information architectures as "playlists" of web content - aural flows. The use of aural flows in mobile web browsing can be seen in ANFORA News, a semi-aural mobile site designed to facilitate browsing large collections of news stories. An exploratory study involving frequent news readers (n= 20) investigated the usability and navigation experiences with ANFORA News in a mobile setting. The initial evidence suggests that aural flows are a promising paradigm for supporting eyes-free mobile navigation while on the go. Interacting with aural flows, however, requires users to select interface buttons, tethering visual attention to the mobile device even when it is unsafe. To reduce visual interaction with the screen, we also explore the use of simulated voice commands to control aural flows. In a study, 20 participants browsed aural flows either through a visual interface or with a visual interface augmented by voice commands. The results suggest that using voice commands decreases by half the time spent looking at the device, but yields similar walking speeds, system usability and cognitive effort ratings as using buttons. To test the potential of using aural flows in a higher distracting context, a study (n= 60) was conducted in a driving simulation lab. Each participant drove through three driving scenario complexities: low, moderate and high. Within each driving complexity, the participants went through an alternative <b>aural</b> <b>application</b> exposure: no device, voice-controlled aural flows (ANFORADrive) or alternative solution on the market (Umano). The results suggest that voice-controlled aural flows do not affect distraction, overall safety, cognitive effort, driving performance or driving behavior when compared to the no device condition...|$|E
40|$|Abstract. The UCSB Allosphere is a 3 -story-high spherical {{instrument}} in which virtual environments and performances can be experienced in full immersion. The space {{is now being}} equipped with high-resolution active stereo projectors, a 3 D sound system with several hundred speakers, and with tracking and interaction mechanisms. The Allosphere {{is at the same}} time multimodal, multimedia, multi-user, immersive, andinteractive. This novel and unique instrument will be used for research into scientific visualization/auralization and data exploration, and as a research environment for behavioral and cognitive scientists. It will also serve as a research and performance space for artists exploring new forms of art. In particular, the Allosphere has been carefully designed to allow for immersive music and <b>aural</b> <b>applications.</b> In this paper, we give an overview of the instrument, focusing on the audio subsystem. We give the rationale behind some of the design decisions and explain the different techniques employed in making the Allosphere a truly generalpurpose immersive audiovisual lab and stage. Finally, we present first results and our experiences in developing and using the Allosphere in several prototype projects. ...|$|R

