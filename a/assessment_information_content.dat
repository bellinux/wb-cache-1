1|10000|Public
40|$|Effective and {{efficient}} objective video quality assessment (VQA) methods are highly desirable in modern visual communication sys-tems for performance evaluation, quality control and resource alloca-tion purposes. Simple VQA algorithms may be developed by direct extensions of still image quality assessment (IQA) approaches on a frame-by-frame basis. Advanced VQA methods {{take into account}} the temporal correlation and motion information contained in video signals but often lead to significantly increased computational com-plexity. Here we use a different approach to examine a video signal by considering it as a three-dimensional (3 D) volume image. Specif-ically, we propose a 3 D structural similarity (3 D-SSIM) approach, which first creates a 3 D quality map by applying SSIM evaluations within local 3 D blocks, and then use local information content and local distortion based weighting methods to pool the quality map into a single quality measure. The resulting 3 D-SSIM algorithm is computationally efficient and demonstrates highly competitive per-formance in comparison with state-of-the-art VQA algorithms when tested using four publicly available video quality databases 1. Index Terms — video quality assessment, structural similarity, 3 D volume image quality <b>assessment,</b> <b>information</b> <b>content</b> weighting 1...|$|E
40|$|An {{algorithm}} {{has been}} developed to retrieve altitude information at di 8 erent diurnal stages for trace gasspecies by combining direct-sun and zenith-sky UV-visible di 8 erential slant column density (DSCD) measurements. DSCDs are derived here using di 8 erential optical absorption spectroscopy. Combining the complementaryzenith-sky measurements (sensitive to the stratosphere) with direct-sun measurements (sensitive to thetroposphere) allows this vertical distinction. Trace gas species such as BrO and NO 2 have vertical pro) leswith strong diurnal dependence. Information about the diurnal variation is simultaneously retrieved with thealtitude distribution of the trace gas. The retrieval is a formal optimal estimation pro) le retrieval, allowing acomplete <b>assessment</b> of <b>information</b> <b>content</b> and errors...|$|R
40|$|This study {{attempts}} {{to provide an}} empirical <b>assessment</b> of the <b>information</b> <b>content</b> of selected hospital service efforts and accomplishment (SEA) measures with respect to one dimension of hospital evaluation, financial performance. The relative <b>information</b> <b>content</b> of traditional financial accounting information is compared with selected SEA measures using bond ratings {{as a measure of}} financial performance. A bond rating model is constructed using six SEA measures. Its predictive ability is compared to a bond rating model constructed using six traditional financial accounting variables. The SEA model slightly outperformed the predictive ability of the financial accounting model. Our results not only indicate that SEA measures ar...|$|R
40|$|In {{the past}} few years, {{scatterometer}} winds have been successfully assimilated in weather analysis. A good <b>assessment</b> of the <b>information</b> <b>content</b> of these winds is particularly important for such activities. Besides retrieval problems in cases of a confused sea state, a particularly acute problem of Ku-band scatterometry is the sensitivity to rain. Elimination of poor quality data is therefore a prerequisite for the successful use of the new National Aeronautics and Space Administration (NASA) scatterometer, QuikSCAT. This issue has been the topic of recent work. On the on...|$|R
40|$|Summary. Learning tasks {{from human}} {{demonstration}} is a core feature for house-hold service robots. Task knowledge should {{at the same}} time encode the constraints of a task while leaving as much flexibility for optimized reproduction at execution time as possible. This raises the question, which features of a task are the constrain-ing or relevant ones both for execution of and reasoning over the task knowledge. In this paper, a system to record and interpret demonstrations of household tasks is presented. A measure for the <b>assessment</b> of <b>information</b> <b>content</b> of task features is introduced. This measure for the relevance of certain features relies both on general background knowledge as well as task-specific knowledge gathered from the user demonstrations. The results of the incremental growth of the task knowledge when more task demonstrations become available is demonstrated within the task of laying a table. ...|$|R
40|$|Motion {{is one of}} {{the most}} {{important}} types of information contained in natural video, but direct use of motion informa-tion in the design of video quality assessment algorithms has not been deeply investigated. Here we propose to incorporate a recent motion perception model in an information theoretic framework. This allows us to estimate both the motion infor-mation content and the perceptual uncertainty in video sig-nals. Improved video quality assessment algorithms are ob-tained by incorporating the model as spatiotemporal weight-ing factors, where the weight increases with the <b>information</b> <b>content</b> and decreases with the perceptual uncertainty. The proposed approach is validated using the Video Quality Ex-perts Group Phase I test dataset. Index Terms — video quality <b>assessment,</b> motion percep-tion, <b>information</b> <b>content,</b> perceptual uncertainty, visual atten-tio...|$|R
40|$|Abstract—Many {{state-of-the-art}} perceptual {{image quality}} as-sessment (IQA) algorithms {{share a common}} two-stage structure: local quality/distortion measurement followed by pooling. While significant {{progress has been made}} in measuring local image quality/distortion, the pooling stage is often done in ad-hoc ways, lacking theoretical principles and reliable computational models. This paper aims to test the hypothesis that when viewing natural images, the optimal perceptual weights for pooling should be proportional to local <b>information</b> <b>content,</b> which can be estimated in units of bit using advanced statistical models of natural images. Our extensive studies based upon six publicly-available sub-ject-rated image databases concluded with three useful findings. First, <b>information</b> <b>content</b> weighting leads to consistent improve-ment in the performance of IQA algorithms. Second, surprisingly, with <b>information</b> <b>content</b> weighting, even the widely criticized peak signal-to-noise-ratio can be converted to a competitive perceptual quality measure when compared with state-of-the-art algorithms. Third, the best overall performance is achieved by combining <b>information</b> <b>content</b> weighting with multiscale struc-tural similarity measures. Index Terms—Gaussian scale mixture (GSM), image quality <b>assessment</b> (IQA), pooling, <b>information</b> <b>content</b> measure, peak signal-to-noise-ratio (PSNR), structural similarity (SSIM), statis-tical image modeling. I...|$|R
40|$|Abstract — Robot assistants in {{the same}} {{environment}} with humans have to interact with humans and learn or at least adapt to individual human needs. One of the core abilities is learning from human demonstrations, were the robot is supposed to observe the execution of a task, acquire task knowledge and reproduce it. In this paper, a system to interpret and reason over demonstrations of household tasks is presented. The {{focus is on the}} model based representation of manipulation tasks, which serves as a basis for reasoning over the acquired task knowledge. The aim of the reasoning is to condense and interconnect the knowledge. A measure for the <b>assessment</b> of <b>information</b> <b>content</b> of task features is introduced that relies both on general background knowledge as well as task-specific knowledge gathered from the user demonstrations. Beside the autonomous information estimation of features, speech comments during the execution, pointing out the relevance of features are considered as well. I...|$|R
40|$|Human-induced {{environmental}} changes alter terrestrial and aquatic ecosystems worldwide. This influences also evolutionary processes, such as sexual selection, by constraining mate choice and mate competition. Organisms often use multiple cues in mate choice, with different cues indicating {{the same or}} different benefits. Because the <b>assessment</b> and <b>information</b> <b>content</b> of cues can vary with environmental conditions, changes in the environment could alter mate choice. Here we determined if increased phytoplankton turbidity influences the relative use of olfactory and visual cues in mate choice in the three-spined stickleback Gasterosteus aculeatus. In a mate choice experiment, we found that females relied more on visual than olfactory cues in clear water. However, in turbid water, the pattern was the opposite with olfactory cues being more important than visual cues. Interestingly, mate preferences based on visual and olfactory cues did not agree, which suggests that human-induced environmental change could shift mate choice. This could influence the direction and target of sexual selection and have further consequences for {{the viability of the}} population under the new conditions. Copyright 2009, Oxford University Press. ...|$|R
40|$|This report {{presents}} {{the findings of}} an experiment that investigated the effects of cultural background, message <b>information</b> <b>content,</b> rank status, and source credibility on situation <b>assessment.</b> Although <b>information</b> <b>content,</b> rank status, and source credibility have received much attention by researchers in command and control decision-making, cultural variations in these factors have seldom been studied. Study participants were junior military officers from the U. S. and five foreign countries: Greece, Malaysia, the Philippines, Singapore, and Turkey. Messages describing ongoing events in an imaginary geopolitical region provided the decision-making context. At the outset, each participant received instructions that either (1) favored an attack by one country on another country in that region, (2) favored the occurrence of war games in that country, or (3) that were neutral {{with regard to the}} likelihood of attack and war games. The 100 messages were organized into 10 blocks of 10 messages. Each message originated from one of three sources that differed in terms of their credibility. After reviewing each block of messages, participants estimated the likelihood of attack and rated their confidence in that estimate. To examine effects of rank status, simulated e-mail messages were interjected into the message stream at periodic intervals. These messages requested participants to assess a situation that was not directly related to the primary task. Responses provided from superior and subordinate sources either agreed or disagreed with the participant's original assessment, which could then be changed if the participant so desired. All cultural groups increased their estimates of the likelihood of attack as more messages about the developing situation were reviewed. However, [...] ...|$|R
40|$|Data {{from the}} {{literature}} were used to systematize intermediate-term (with advance times of 1 month to ~ 2. 5 years) precursors to the M ≥ 6. 6 Kamchatka earthquakes of 1987 − 2004. The precursors were observed as changes in seismological, geodetic, geophysical, water-level, and hydrochemical parameters. Retrospective <b>assessment</b> of the <b>information</b> <b>content</b> in these intermediate-term precursors for earthquake prediction is in progress. The focus was on estimating the occurrence times of various precursors as functions of earthquake parameters (magnitude M, hypocentral distance R, and epicenter location). In {{the conditions of the}} Kamchatka observing network, precursors can be identified by a combination of methods, mostly before M ~ 7 earthquakes or greater south of the Kronotskii Peninsula, for which It is shown that the relative proportion of earthquakes for which precursors have been identified in the observations considered here is 0. 43 – 0. 86...|$|R
40|$|Includes bibliographical {{references}} (leaves 39 - 44). Matrix Assisted Laser Desorption Ionization {{mass spectrometry}} (MALDI-MS) has been recently introduced {{in to the}} field of microbiology. The use of this technique overcomes some of the limitations of current phenotypic and genotypic methods. MALDI-typing of microorganisms is an approach based on the differentiation of MALDI-acquired protein fingerprints. Employed in clinical settings, it allows rapid identification of microorganisms down to the strain level. Leading to high morbidity and mortality rates, antibiotic resistant strains of Staphylococcus aureus have become a worldwide concern. Herein, we carried out a comparative study of 20 variations of an acid/alcohol bacterial protein extraction method using a clinical isolate of S. aureus. Protein fingerprints of these extracts acquired in linear mode (800 - 20, 000 Da) were used for <b>assessment</b> of <b>information</b> <b>content</b> (number of peaks) and identity (size of proteins/peptides, m/z). Two methods were shown to be most efficient for sample preparation, i. e. formic acid/methanol and trifluoroacetic acid/ethanol, yielding 28 peaks each. Proteins obtained by the classic formic acid/ethanol extraction were separated using 2 -dimensional electrophoresis (2 -DE) yielding more than 50 protein spots. Nine proteins were successfully identified using peptide mass fingerprinting (PMF), two of which are virulence related proteins, SpoVG and endonuclease IV. These proteins are considered prospects for MALDI-typing. 1 hard copy: xv, 44, [25] leaves; 30 cm. available at RNL...|$|R
40|$|Abstract Background The {{frequent}} {{exchange of}} genetic material among prokaryotes means that extracting a majority or plurality phylogenetic signal from many gene families, and {{the identification of}} gene families that are in significant conflict with the plurality signal is a frequent task in comparative genomics, and especially in phylogenomic analyses. Decomposition of gene trees into embedded quartets (unrooted trees each with four taxa) is a convenient and statistically powerful technique to address this challenging problem. This approach was shown to be useful in several studies of completely sequenced microbial genomes. Results We present here a web server that takes a collection of gene phylogenies, decomposes them into quartets, generates a Quartet Spectrum, and draws a split network. Users are also provided with various data download options for further analyses. Each gene phylogeny is to be represented by an <b>assessment</b> of phylogenetic <b>information</b> <b>content,</b> such as sets of trees reconstructed from bootstrap replicates or sampled from a posterior distribution. The Quartet Decomposition server is accessible at [URL]. Conclusions The Quartet Decomposition server presented here provides a convenient means to perform Quartet Decomposition analyses and will empower users to find statistically supported phylogenetic conflicts. </p...|$|R
40|$|Behavioral <b>Assessment</b> <b>information,</b> a {{more general}} form of Problem- Oriented Record data, appears to have many useful {{clinical}} qualities and was selected to be the <b>information</b> <b>content</b> for a computer interview system. This interview system was designed to assess problematic behaviors of psychiatric patients. The computer interview covered 29 life problem areas and took patients from four to eight hours to complete. In two reliability studies, the computer interview was compared to human interviews. A greater number of general and specific patient problems were identified in the computer interview than in the human interviews. The attitudes of computer patients and clinicians receiving the computer reports were surveyed...|$|R
40|$|In this paper, {{we examine}} the level of {{information}} quality obtained by the end-of-the-year accrual financial statements of Greek municipalities in terms of accounting principles compliance. The level of compliance is measured by two alternative compliance indices developed {{on the basis of}} data retrieved by auditors' reports. Our results indicate that there is room for improvement in relation {{to the quality of the}} <b>information</b> <b>content</b> of municipalities'financial reports. Additionally, variables that relate to the auditor size as well as to the municipality size, wealth and experience in accrual accounting were found to exhibit an influential role on the quality of the accounting information provided to stakeholders through end-of-the-year financial statements in terms of accounting standards compliance. The paper attempts to assess whether the introduction of accrual accounting in a public sector setting succeeded in producing the expected quality of accounting information in practice via analysing compliance with accounting standards. public sector, accrual accounting, compliance indices, audit reports, financial reporting, municipalities, Greece, local government, quality <b>assessment,</b> <b>information</b> quality, end-of-the-year statements, accrual statements, financial statements, compliance levels, auditors, <b>information</b> <b>content,</b> financial reports, variables, auditor size, municipality size, stakeholders, wealth, experience, economics, finance, accounting standards,...|$|R
40|$|The {{objective}} {{of this study is}} to investigate whether net income, net sale, and operating cash flow has incremental <b>information</b> <b>content.</b> This study also investigate whether net sales and operating cash flow have relative <b>information</b> <b>content.</b> Sample of this study is collected from Indonesian Capital Market (IDX). Collected sample is done during 2000 to 2004 in manufacturing industry. The result of this study is net income has not incremental <b>information</b> <b>content.</b> Net sale and operating cash flow have incremental <b>information</b> <b>content.</b> Net sale has not relative <b>information</b> <b>content</b> but operating cash flow has relative <b>information</b> <b>content...</b>|$|R
5000|$|... {{conditional}} entropy, mean conditional <b>information</b> <b>content,</b> average conditional <b>information</b> <b>content</b> H(X|Y) ...|$|R
40|$|As digital terrain {{models are}} {{indispensable}} for visualizing and modeling geographic processes, terrain <b>information</b> <b>content</b> {{is useful for}} terrain generalization and representation. For terrain generalization, if the terrain information is considered, the generalized terrain may be of higher fidelity. In other words, the richer the terrain information at the terrain surface, the smaller the degree of terrain simplification. Terrain <b>information</b> <b>content</b> is also important for {{evaluating the quality of}} the rendered terrain, e. g., the rendered web terrain tile service in Google Maps (Google Inc., Mountain View, CA, USA). However, a unified definition and measures for terrain <b>information</b> <b>content</b> have not been established. Therefore, in this paper, a definition and measures for terrain <b>information</b> <b>content</b> from Digital Elevation Model (DEM, i. e., a digital model or 3 D representation of a terrain’s surface) data are proposed and are based on the theory of map <b>information</b> <b>content,</b> remote sensing image <b>information</b> <b>content</b> and other geospatial <b>information</b> <b>content.</b> The <b>information</b> entropy was taken as the information measuring method for the terrain <b>information</b> <b>content.</b> Two experiments were carried out to verify the measurement methods of the terrain <b>information</b> <b>content.</b> One is the analysis of terrain <b>information</b> <b>content</b> in different geomorphic types, and the results showed that the more complex the geomorphic type, the richer the terrain <b>information</b> <b>content.</b> The other is the analysis of terrain <b>information</b> <b>content</b> with different resolutions, and the results showed that the finer the resolution, the richer the terrain information. Both experiments verified the reliability of the measurements of the terrain <b>information</b> <b>content</b> proposed in this paper...|$|R
40|$|The aim of {{this paper}} is to compare {{different}} fuzzy regression methods in the <b>assessment</b> of the <b>information</b> <b>content</b> on future realised volatility of option-based volatility forecasts. These methods offer a suitable tool to handle both imprecision of measurements and fuzziness of the relationship among variables. Therefore, they are particularly useful for volatility forecasting, since the variable of interest (realised volatility) is unobservable and a proxy for it is used. Moreover, measurement errors in both realised volatility and volatility forecasts may affect the regression results. We compare both the possibilistic regression method of Tanaka et al. (IEEE Trans Syst Man Cybern 12 : 903 - 907, 1982) and the least squares fuzzy regression method of Savic and Pedrycz (Fuzzy Sets Syst 39 : 51 - 63, 1991). In our case study, based on intra-daily data of the DAX-index options market, both methods have proved to have advantages and disadvantages. Overall, among the two methods, we prefer the Savic and Pedrycz (Fuzzy Sets Syst 39 : 51 - 63, 1991) method, since it contains as special case (the central line) the ordinary least squares regression, is robust to the analysis of the variables in logarithmic terms or in levels, and provides sharper results than the Tanaka et al. (IEEE Trans Syst Man Cybern 12 : 903 - 907, 1982) method...|$|R
40|$|This study {{distinguishes between}} {{incremental}} and relative <b>information</b> <b>content.</b> Incremental comparisons ask whether one accounting measure provides <b>information</b> <b>content</b> beyond that provided by another, and apply when one measure {{is viewed as}} given and an assessment is desired regarding the incremental contribution of another (e. g., a supplemental disclosure). Relative comparisons ask which measure has greater <b>information</b> <b>content,</b> and apply when making mutually exclusive choices among alternatives, or when rankings by <b>information</b> <b>content</b> are desired (e. g., when comparing alternative disclosures). Questions of both incremental and relative <b>information</b> <b>content</b> arise frequently in accounting. However, few previous studies have examined questions of relative <b>information</b> <b>content.</b> Possible explanations include unfamiliarity with the relative versus incremental distinction, and the additional statistical complexity involved in testing for relative <b>information</b> <b>content.</b> First, we examine analytically the relation between incremental and relative <b>information</b> <b>content,</b> demonstrating that they address different research questions and require different tests for statistical significance. Second, we identify accounting research contexts in which questions of relative and incremental <b>information</b> <b>content</b> arise. Third, we propose a new regression-based test for relative <b>information</b> <b>content.</b> This test applies to both returns and valuation studies, generalizes to any number of predictor variables, {{and can be used}} in conjunction with White's (1980) adjustment for heteroskedasticity. Fourth, we illustrate tests for relative and incremental <b>information</b> <b>content</b> in a familiar research setting that compares the <b>information</b> <b>contents</b> of net income, cash flows, and net sales in 40 industries. link_to_subscribed_fulltex...|$|R
40|$|In {{this paper}} two notions of <b>information</b> <b>content</b> for the {{characteristic}} sequences of sets are compared. One is the minimal-program {{complexity of the}} sequences and represents a quantitative <b>information</b> <b>content,</b> {{and the other is}} the degree of unsolvability of the underlying set and represents a qualitative <b>information</b> <b>content.</b> The major conclusion from this work is that with few exceptions these measures of <b>information</b> <b>content</b> are unrelated. Various tradeoffs between these measures are also demonstrated...|$|R
40|$|Black hole {{is called}} optimal if <b>information</b> <b>content</b> is minimal at the University region, {{consisting}} of usual substance and one(n) black hole(s). Optimal black hole mass {{does not depend}} on the mass of the Universe region. Optimal black holes can exist when at least the two types of substance are available in the Universe: with non-linear and linear correspondence between <b>information</b> <b>content</b> and mass. <b>Information</b> <b>content</b> of optimal black hole is proportional to squared coefficient correlating <b>information</b> <b>content</b> with mass in usual substance and in inverse proportion to coefficient correlating <b>information</b> <b>content</b> with black hole mass. Concentration of mass in optimal black hole minimizes <b>information</b> <b>content</b> in the system "usual substance - black holes". Minimal <b>information</b> <b>content</b> of the Universe consisting of optimal black holes only is twice as less as <b>information</b> <b>content</b> available of the Universe of the same mass filled with usual substance only. Under the radiation temperature T ≈ 1 E + 12 K the mass of optimal black holes that emerged in the systems "radiation - black hole" is equal to the mass of optimal black holes that emerged in the systems "hydrogen (protons) - black hole". Comment: 15 page...|$|R
40|$|Abstract. A {{new method}} was {{proposed}} to solve multi-attribute group decision-making problems with natural language <b>assessment</b> <b>information.</b> In this method, firstly the linguistic <b>assessment</b> <b>information</b> given by each decision maker was aggregated by LWD and LOWA operators {{in order to}} obtain the group <b>assessment</b> <b>information.</b> Then, the preferred scheme is obtained from the result of aggregation. Finally, a simulation example was given to illustrate the validity of this approach...|$|R
40|$|A {{measure of}} the <b>information</b> <b>content</b> of an {{evidence}} inducing a belief function or a possibility function is axiomatically defined. Its major property is to be additive for distinct evidences. Measures are developed of the <b>information</b> <b>content</b> of an evidence appropriate when belief or possibility functions are used. The additivity means that the <b>information</b> <b>content</b> derived from two distinct and non-conflictual evidences {{is the sum of}} the <b>information</b> <b>contents</b> of each evidence. Properties of these measures are studied. Refs. SCOPUS: NotDefined. jinfo:eu-repo/semantics/publishe...|$|R
40|$|A {{measure is}} {{proposed}} {{based on the}} information theory and geostatistics to evaluate <b>information</b> <b>content</b> in remotely sensed images. The method is based on the additive noise model and maximum mutual information. These factors affecting the <b>information</b> <b>content</b> have been taken into account, such as noise, spatial correlation and so on. It is suitable for measuring the <b>information</b> <b>content</b> in optical images that have robust spatial correlation with different land cover types. An experiment was performed on a Landsat TM image with three different kinds of land cover types (city, farmland and mountain). The result shows that city has the most <b>information</b> <b>content.</b> It also proves that there is a log positive correlation between <b>information</b> <b>content</b> and the variance of the images...|$|R
50|$|Frank used {{agent-based}} {{models and}} the theory of autonomous agents with cognitive abilities (see multi-agent system) to operationalize measuring pragmatic <b>information</b> <b>content.</b> The transformation between the received message and the executed message {{is defined by the}} agents rules; the pragmatic <b>information</b> <b>content</b> is the <b>information</b> in the transformed message, measured by the methods given by Shannon. The general case can be split in (deterministic) actions to change the information the agent already has and the optimal decision using this information. To measure the pragmatic <b>information</b> <b>content</b> is relevant to assess the value of information received by an agent and influences the agents willingness to pay for information - not measured by Shannon communication <b>information</b> <b>content,</b> but by the received pragmatic <b>information</b> <b>content.</b>|$|R
40|$|The {{aim of this}} {{research}} is to investigate the <b>information</b> <b>content</b> of operating income and cash flow operating with stock return in information asymmetry situations in the accepted companies at Tehran stock exchange. This study was done according to data obtained from 70 companies during 2006 - 2010. This is an after event research. This research is calcified as the applicable research. And the hypothesis was examined, using liner multiple regression. The results of the examination reveal that operating income and cash flow operating contain the <b>information</b> <b>content</b> and they can explain the stock return and on the other hand, <b>information</b> <b>content</b> of operating income and cash flow operating are different from each other and <b>information</b> <b>content</b> of operating income is higher than cash flow operating. Also, the results indicated that information asymmetry effects on the income <b>information</b> <b>content</b> and cash flow operating and whatever the information asymmetry is higher, then <b>information</b> <b>content</b> of cash flow operating is increased...|$|R
5000|$|A {{familiar}} application my {{clarify the}} approach:Different car navigation systems produce different instructions {{but if they}} manage to guide you to the same location, their pragmatic <b>information</b> <b>content</b> must be the same (despite different <b>information</b> <b>content</b> when measured with Shannon's measure (SAME). A novice in the area may need all instructions received - the pragmatic <b>information</b> <b>content</b> and the (minimally encoded) <b>information</b> <b>content</b> of the message is the same. An experienced driver will ignore all [...] "follow the road" [...] and [...] "go straight" [...] instructions, thus the pragmatic <b>information</b> <b>content</b> is lower; for an driver {{with knowledge of the}} area, large parts of the instructions may be subsumed by simple instructions [...] "drive to X"; typically, only the last part ("the last mile") of the instructions are meaningful - the pragmatic <b>information</b> <b>content</b> is smaller, because much knowledge is already available (DIFF). Messages with more or less verbiage have for this user the same pragmatic content (SAME).|$|R
5000|$|... {{based on}} the notion of <b>information</b> <b>content.</b> The <b>information</b> <b>content</b> of a concept (term or word) is the {{logarithm}} of the probability of finding the concept in a given corpus.|$|R
5000|$|The court {{reasoned}} that Roommates.com was not immune under 230(c) for the questions it asked in its dropdown menus, because the website qualified as an <b>information</b> <b>content</b> provider. By requiring users {{to answer questions}} relating to gender and sexual orientation, Roommates.com provided content. Just because the users of Roommates.com are <b>information</b> <b>content</b> providers {{does not mean that}} Roommates.com is not also an <b>information</b> <b>content</b> provider. The court explained: ...|$|R
40|$|Data were {{available}} for 12 poultry microsatellites and 29 poultry single nucleotide polymorphisms (SNPs), and for 34 cattle microsatellites and 36 cattle SNPs. Stochastic permutation {{was used to determine}} the number of SNPs needed to obtain the same average <b>information</b> <b>content</b> as a given number of microsatellites. For poultry, the <b>information</b> <b>content</b> averaged 0. 71 for the 12 microsatellites compared to 0. 72 for the 29 SNPs. For cattle, the <b>information</b> <b>content</b> averaged 0. 92 for the 34 microsatellites compared with 0. 79 for the 36 SNPs. This study shows that, for each microsatellite, three SNPs are needed to obtain the same average <b>information</b> <b>content...</b>|$|R
5000|$|... #Subtitle level 3: Outcome and <b>assessment</b> <b>information</b> set (OASIS) ...|$|R
40|$|The {{objective}} {{of this study is}} to provide empirical evidence for the existence of the <b>information</b> <b>content</b> of accounting earnings, funds flows. and cash flows in relation to company stock returns. Differ from PSAK Pio. 2 (IN, 1994) about cash flows statement, basically We unexpected return model employed in this study is using dividend as a proxy for aggregate cash flows. This matter is supported by Lawson (1981 and 7985) findings which cited by Clubb (1995) that dividend or net dividend is the appropriate measures of aggregate cash flow for equity valuation purposes. While PSAK No. 2 defined cash flow as cash inflow and cash outflow of the cash or cash equivalent (par 05). The result of this study conclude that accounting earnings and funds flows (working capital from operation) have <b>information</b> <b>content</b> in relation to company stock returns. Beside that, it is also conclude that funds flows have incremental <b>information</b> <b>content</b> beyond accounting earnings in relation to company stock returns and cash flows have incremental <b>information</b> <b>content</b> beyond accounting earnings (the "institutional" perspective). As recommended by PSAK No. 2, par 09 fo present the statement of cash flows to be classified according to operating, investing, and financing activity so this study is also testing the <b>information</b> <b>content</b> of these three components of cash flows The result indicates that cash flows (dividend) and these three components of cash flows have <b>information</b> <b>content</b> in relationto company stock returns, but these three components have no <b>Information</b> <b>content</b> beyond cash flows The other conclusion is that accounting earnings have incremental <b>information</b> <b>content</b> beyond cash flows (the perspective that cash flows are the "primitive" concept) in relation to company stock returns. Keywords : <b>Information</b> <b>Content,</b> Earnings, Fund Flows. Cash Flow...|$|R
30|$|The system stores the <b>assessment</b> <b>information</b> {{extracted}} from the database.|$|R
30|$|The left {{column of}} Figure 3 shows how valence {{decreases}} with {{the estimation of}} the <b>information</b> <b>content</b> for each context size. Each bar represents {{the same amount of}} words within a language and has an area proportional to the rescaled average <b>information</b> <b>content</b> carried by these words. The color of each bar represents the average valence of the binned words. The decrease of average valence with <b>information</b> <b>content</b> is similar for estimations using 2 -grams and 3 -grams. For the case of 4 -grams it also decreases for English and Spanish, but this trend is not so clear for German. These trends are properly quantified by Pearson’s correlation coefficients between valence and <b>information</b> <b>content</b> for each context size (Table 1). Each correlation coefficient becomes smaller for larger sizes of the context, as the <b>information</b> <b>content</b> estimation includes a larger context but becomes less accurate.|$|R
40|$|The main {{objective}} {{of this study is}} to evaluate the <b>information</b> <b>content</b> of earnings and operating cash flows in explaining stock returns in the manufacturing companies listed in Indonesian Stock Exchange. Moreover, the present study investigates the loss effect on the <b>information</b> <b>content</b> of earnings and operating cash flows. Using secondary data obtained from companies’ financial reports and companies’ stock price index during the years 2009 - 2012, <b>information</b> <b>content</b> of earnings and operating cash flows are analyzed using regression analysis in relation to explaining stock returns. The results of this study indicate that the earnings have more relative and incremental <b>information</b> <b>content</b> than operating cash flows in explaining stock returns. In addition, earnings model is better in explaining stock returns than operating cash flows model. Also, results show that loss affects the <b>information</b> <b>content</b> of earnings and operating cash flows in explaining stock return...|$|R
