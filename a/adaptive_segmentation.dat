116|212|Public
30|$|<b>Adaptive</b> <b>segmentation</b> of the AM-FM signal {{based on}} TVAR {{modeling}} and computation of underlying time-varying poles.|$|E
40|$|Subject of this {{bachelor}} {{project is}} {{the introduction of the}} EEG signal. Are discussed his characteristics, application and methods of processing. The main part deals with the segmentation of the EEG signal. Two methods are implemented in program Matlab - <b>adaptive</b> <b>segmentation</b> based on differential average amplitude and differential average frequency and <b>adaptive</b> <b>segmentation</b> based on differential estimated based on FFT. Functionality of algorithms is verified on real EEG signals...|$|E
40|$|This {{project is}} aimed at EEG signal, {{especially}} at segmentation of signal and next at processing signal, witch this segmentation go before. Problem with signals stacionarity and stress importance of <b>adaptive</b> <b>segmentation</b> are outlined here. Principle of basic methods of <b>adaptive</b> <b>segmentation</b> are explained {{and two of them}} are processed by Matlab to segmentation channel. Parameters (limiting value and window length) influence segmentation. The limiting value is assessed with help of white noise...|$|E
5000|$|SATZAn <b>Adaptive</b> Sentence <b>Segmentation</b> Systemby David D. PalmerC ...|$|R
3000|$|... {{is defined}} from the ratio {{difference}} of overlapped areas, calculated from <b>adaptive</b> hand <b>segmentation</b> algorithm.|$|R
3000|$|To {{test the}} {{accuracy}} {{and efficiency of}} our proposed IRG and <b>adaptive</b> thresholding <b>segmentation</b> methods, we used a widely accepted evaluation criterion of DSC [...]...|$|R
40|$|The {{dissertation}} thesis {{focuses on}} objective assessment and reduction of disturbing background noise {{in a musical}} signal. In this work, a new algorithm {{for the assessment of}} background noise audibility is proposed. The listening tests performed show that this new algorithm better predicts the background noise audibility than the existing algorithms do. An advantage of this new algorithm {{is the fact that it}} can be used even in the case of a general audio signal and not only musical signal, i. e. in the case when the audibility of one sound on the background of another sound is assessed. The existing algorithms often fail in this case. The next part of the dissertation thesis deals with an <b>adaptive</b> <b>segmentation</b> scheme for the segmentation of long-term musical signals into short segments of different lengths. A new <b>adaptive</b> <b>segmentation</b> scheme is then introduced here. It has been shown that this new <b>adaptive</b> <b>segmentation</b> scheme significantly improves the subjectively perceived quality of the musical signal from the output of noise reduction systems which use this new <b>adaptive</b> <b>segmentation</b> scheme. The quality improvement is better than that achieved by other segmentation schemes tested...|$|E
3000|$|... [m, n], {{to express}} the {{oscillation}} modes of x[n]. These issues are resolved simultaneously by <b>adaptive</b> <b>segmentation</b> which is addressed in the following section.|$|E
40|$|Column-store {{database}} systems {{open new}} vistas for improved maintenance through self-organization. Individual columns are the focal point, which simplify balancing conflicting requirements. This work presents two workload-driven selforganizing techniques in a column-store, i. e. <b>adaptive</b> <b>segmentation</b> and adaptive replication. <b>Adaptive</b> <b>segmentation</b> splits a column into non-overlapping segments {{based on the}} actual query load. Likewise, adaptive replication creates segment replicas. The strategies can support different application requirements by trading off the reorganization overhead for storage cost. Both techniques can significantly improve system performance as demonstrated in an evaluation of different scenarios. 1...|$|E
40|$|AbstractWe {{propose a}} variable-length {{segmentation}} strategy which significantly reduces {{the average number}} of additions required by the m-ary segmentation and the canonical recodiing algorithms for multiplication of large binary numbers. This strategy produces two new algorithms: the <b>adaptive</b> m-ary <b>segmentation</b> algorithm utilizes both the speedup inherent in high-radix multiplication and the ability to skip zero bits; the <b>adaptive</b> m-ary <b>segmentation</b> canonical recoding algorithm gains additional benefit from the increased probability of zero after the canonical recoding. The average number of additions required is computed using Markov chains...|$|R
40|$|Enhancement {{algorithms}} {{are widely}} used to overcome the degra-dation of noisy speech signals. Most enhancement algorithms re-quire {{an estimate of the}} noise and noisy speech power spectra in order to compute the gain function used for the noise suppression. The variance of these power spectral estimates degrades the qual-ity of the enhanced signal and smoothing techniques are therefore often used to decrease the variance. In this paper we present a method to determine the noisy speech power spectrum based on an <b>adaptive</b> time <b>segmentation.</b> More specifically, the proposed al-gorithm determines for each noisy frame which of the surrounding frames should contribute to the corresponding noisy power spec-tral estimate. Objective and subjective experiments show that an <b>adaptive</b> time <b>segmentation</b> leads to significant performance im-provements, particularly in transitional speech regions. 1...|$|R
40|$|There {{are various}} ways to binarize images automatically. Our study {{is how to}} binarize {{character}} images which were taken under bad lighting conditions with CCD camera. We propose a linear equation for threshold and the <b>adaptive</b> image <b>segmentation.</b> The dynamic thresholding by this method makes these shading images well binarized in quality...|$|R
40|$|This paper {{proposes a}} {{combined}} method including <b>adaptive</b> <b>segmentation</b> and Higuchi fractal dimension (HFD) of electroencephalograms (EEG) to monitor depth of anesthesia (DOA). The EEG data {{was captured in}} both ICU and operating room and different anesthetic drugs, including propofol and isoflurane were used. Due to the nonstationary nature of EEG signal, <b>adaptive</b> <b>segmentation</b> methods seem to have better results. The HFD of a single channel EEG was computed through adaptive windowing methods consist of adaptive variance and auto correlation function (ACF) based methods. We have compared the results of fixed and adaptive windowing in different methods of calculating HFD in order to estimate DOA. Prediction probability (Pk) {{was used as a}} measure of correlation between the predictors and BIS index to evaluate our proposed methods. The results show that HFD increases with increasing BIS index. In ICU, all of the methods reveal better performance than in other groups. In both ICU and operating room, the results indicate no obvious superiority in calculating HFD through <b>adaptive</b> <b>segmentation...</b>|$|E
40|$|Abstract Background Segmentation is {{the most}} crucial part in the {{computer-aided}} bone age assessment. A well-known type of segmentation performed in the system is <b>adaptive</b> <b>segmentation.</b> While providing better result than global thresholding method, the <b>adaptive</b> <b>segmentation</b> produces a lot of unwanted noise that could affect the latter process of epiphysis extraction. Methods A proposed method with anisotropic diffusion as pre-processing and a novel Bounded Area Elimination (BAE) post-processing algorithm to improve the algorithm of ossification site localization technique are designed {{with the intent of}} improving the <b>adaptive</b> <b>segmentation</b> result and the region-of interest (ROI) localization accuracy. Results The results are then evaluated by quantitative analysis and qualitative analysis using texture feature evaluation. The result indicates that the image homogeneity after anisotropic diffusion has improved averagely on each age group for 17. 59 %. Results of experiments showed that the smoothness has been improved averagely 35 % after BAE algorithm and the improvement of ROI localization has improved for averagely 8. 19 %. The MSSIM has improved averagely 10. 49 % after performing the BAE algorithm on the adaptive segmented hand radiograph. Conclusions The result indicated that hand radiographs which have undergone anisotropic diffusion have greatly reduced the noise in the segmented image and the result as well indicated that the BAE algorithm proposed is capable of removing the artifacts generated in <b>adaptive</b> <b>segmentation.</b> </p...|$|E
40|$|We propose Virtual Full Replication by <b>Adaptive</b> <b>segmentation</b> (ViFuR-A), and {{evaluate}} {{its ability to}} maintain scalability in a replicated real-time database. With full replication and eventual consistency, transaction timeliness becomes independent of network delays for all transactions. However, full replication does not scale well, since all updates must be replicated to all nodes, also when data is needed only at {{a subset of the}} nodes. With Virtual Full Replication that adapts to actual data needs, resource usage can be bounded and the database can be made scalable. We propose a scheme for <b>adaptive</b> <b>segmentation</b> that detects new data needs and adapts replication. The scheme includes an architecture, a scalable protocol and a replicated directory service that together maintains scalability. We show that <b>adaptive</b> <b>segmentation</b> bounds the required storage at a significantly lower level compared to static segmentation, for a typical workload where the data needs change repeatedly. Adaptation time can be kept constant for the workload when there is sufficient resources. Also, the storage is constant with an increasing amount of nodes and linear with an increasing rate of change to data needs. ...|$|E
40|$|AbstractÐAn <b>adaptive</b> image <b>segmentation</b> {{scheme is}} {{proposed}} employing the Delaunay triangulation for image splitting. The tessellation grid of the Delaunay triangulation {{is adapted to}} the semantics of the image data by combining region and edge information. To achieve robustness against imaging conditions (e. g., shading, shadows, illumination, and highlights), photometric invariant similarity measures, and edge computation is proposed. Experimental results on synthetic and real images show that the segmentation method is robust to edge orientation, partially weak object boundaries, and noisy, but homogeneous regions. Furthermore, the method is robust {{to a large degree}} to varying imaging conditions. Index TermsÐImage <b>segmentation,</b> <b>adaptive</b> splitting, integrating region and edge information, photometric color invariance, noise robustness. ...|$|R
40|$|Abstract—We {{propose a}} time-frequency {{analysis}} based method {{to discriminate between}} undamaged and three types of damaged wheat kernels by using impact acoustic emissions. The proposed algorithm is based on <b>adaptive</b> <b>segmentations</b> of the time-frequency plane constructed by using non-dyadic local discriminant bases (LDB). Non-dyadic LDB are obtained by combining local cosine packet analysis and a frequency axis clustering approach which supports individual time and frequency band adaptation. Discriminant features are extracted from the adaptively segmented acoustic signals, sorted and fed to a linear discriminant for classification. We compared {{the performance of the}} proposed algorithm with that of a baseline technique that uses time domain modeling, short time window variances and frequency spectra magnitudes. The non-dyadic LDB and the baseline approach resulted in an average error of 8. 9 % and 22. 1 % respectively. We observed that the proposed LDB approach automatically located relevant indexes. K I...|$|R
40|$|In {{this paper}} we develop {{hypothesis}} tests for speech waveform nonstationarity based on time-varying autoregressive models, and demonstrate their efficacy in speech analysis tasks at both segmental and sub-segmental scales. Key {{to the successful}} synthesis of these ideas is our employment of a generalized likelihood ratio testing framework tailored to autoregressive coefficient evolutions suitable for speech. After evaluating our framework on speech-like synthetic signals, we present preliminary results for two distinct analysis tasks using speech waveform data. At the segmental level, we develop an <b>adaptive</b> short-time <b>segmentation</b> scheme and evaluate it on whispered speech recordings, while at the sub-segmental level, we {{address the problem of}} detecting the glottal flow closed phase. Results show that our hypothesis testing framework can reliably detect changes in the vocal tract parameters across multiple scales, thereby underscoring its broad applicability to speech analysis. Index Terms: TVAR models, hypothesis testing, GLRT, <b>adaptive</b> speech <b>segmentation,</b> glottal flow analysi...|$|R
30|$|In {{this novel}} method of IF extraction, the Hilbert {{transform}} {{that is a}} global operator is not employed. Additionally, a linear model {{is applied to the}} phase of components segment by segment in spite of differentiating throughout. It makes the proposed method less sensitive to phase changes. Therefore, the <b>adaptive</b> <b>segmentation</b> is advantageous for both decomposition and frequency estimation.|$|E
40|$|An image {{enhancement}} algorithm based on <b>adaptive</b> <b>segmentation</b> for image contrast enhancement is presented. In this study, an automatic <b>adaptive</b> <b>segmentation</b> histogram enhancement (ASHE), based on discriminant analysis, is utilized to recursively segment an image into several clusters first. After segmentation, different object and background components are segmented into separate clusters, called object planes. Then, the dynamic range of each object plane is adjusted {{according to its}} visual characteristics. Finally, each object plane is enhanced within the new dynamic range respectively. Because the proposed algorithm can automatically segment an image into different object planes and enhance the image according to the visual characteristic of each object plane, each object and background components of the image can be well enhanced. Experimental results for poor-contrast images and the comparisons {{for some of the}} previous studies are provided to demonstrate the robustness, visual quality, and effectiveness of the proposed algorithm. 1...|$|E
40|$|Scene {{classification}} and concept-based {{procedures have}} been the great interest for image catego-rization applications for large database. Knowing the category to which scene belongs, we can filter out uninterested images {{when we try to}} search a specific scene category such as beach, mountain, forest and field from database. In this paper, we propose an <b>adaptive</b> <b>segmentation</b> method for re-al-world natural scene classification based on a semantic modeling. Semantic modeling stands for the classification of sub-regions into semantic concepts such as grass, water and sky. Our adaptive segmen-tation method utilizes the edge detection to split an image into sub-regions. Frequency of occurrences of these semantic concepts represents the information of the image and classifies it to the scene categories. K-Nearest Neighbor (k-NN) algorithm is also applied as a classifier. The empirical results demonstrate that the proposed <b>adaptive</b> <b>segmentation</b> method outperforms the Vogel and Schiele’s method in terms of accuracy...|$|E
40|$|Seamline {{optimization}} {{is a key}} step in {{the process}} of aerial image seamless mosaicking. This paper presents a novel algorithm of seamline optimization for aerial image mosaicking by <b>adaptive</b> marker-based watershed <b>segmentation.</b> The preferred region is determined by the difference of the region achieved by <b>adaptive</b> marker-based watershed <b>segmentation.</b> Then, the minimum binary heap Dijkstra's algorithm is adopted to determine the final seamlines in the preferred region. The experimental results show that the seamline determined by our method can avoid crossing obvious stand-alone objects. Compared with other algorithms,our method has higher feasibility and higher speed...|$|R
40|$|On {{the basis}} of the flow feature in the micro blood vessels, a method to track the trace of cell {{movement}} was proposed in this paper. The algorithm employed the space domain enhancement, <b>adaptive</b> threshold <b>segmentation</b> techniques. For the sake of calculating blood flow, the active contour-based template matching method was applied to sequential images. The experimental results show that this method can accurately track movement of tiny particles and estimate its moving speed in the micro-blood vessels...|$|R
40|$|Obstacle {{detection}} is a {{key component}} of autonomous systems. In particular, when dealing with large robots in unstructured environments, robust obstacle detection is vital. In this paper, we describe an obstacle detection methodology which combines two complimentary methods: <b>adaptive</b> color <b>segmentation,</b> and stereo-based color homography. This algorithm is particularly suited for environments in which the terrain is relatively flat and of roughly the same color. We will show results in applying this method to an autonomous outdoor robot. 1...|$|R
40|$|This paper {{deals with}} a hybrid {{simplification}} method for triangular meshes. Our approach {{is based on a}} first simplification step where vertices are clustered, followed by an iterative edge collapse step. More precisely, vertices are first clustered into surface patches through an <b>adaptive</b> <b>segmentation</b> process (using both absolute discrete curvature and principal component analysis); the edge collapse process is based on quadratic error metrics...|$|E
30|$|The {{first task}} is {{intended}} to reduce noise and pre-estimate the vessels boundaries, from which the initial contours will be calculated. In so-doing, <b>adaptive</b> <b>segmentation</b> is performed, subtracting a heavy diffused version of the retinal image itself followed by a threshold by a fixed value, obtaining a binary map. To ensure that we are outside of the vessels location, some erosions are applied. The final image contains the initial contours.|$|E
40|$|Abstract:- In {{this paper}} we present an {{approach}} to the detection and extraction of text in road sign panels. Text strings, indicators and signs extraction is efficiently performed so OCR algorithms can recognize different characters that may be present on the traffic plane. In a first step, basic color segmentation and shape classification is done {{for the purpose of}} detecting possible rectangular planes. Every detected plane is extracted from the original image and then reoriented. Chrominance and luminance histogram analysis and <b>adaptive</b> <b>segmentation</b> is carried out, and connected components labeling and position clustering is finally done for the arrangement of the different characters on the panel. Special emphasis has been placed on the <b>adaptive</b> <b>segmentation.</b> Experimental results have showed that following steps strongly depends on correct separation between the background and foreground objects of the panel. Moreover, OCR systems are highly sensitive to noise, and we have put special attention into it in order that the OCR system could be able to recognize characters properly. Key-Words:- Road-sign, detection, classification, image segmentation. ...|$|E
40|$|Abstract: This study {{deals with}} {{constructing}} and implementing new algorithm based on hiding {{a large amount}} of data (image, audio, text) file into color BMP image. We have been used adaptive image filtering and <b>adaptive</b> image <b>segmentation</b> with bits replacement on the appropriate pixels. These pixels are selected randomly rather than sequentially by using new concept defined by main cases with their sub cases for each byte in one pixel. This concept based on both visual and statistical. According to the steps of design, we have been concluded 16 main cases with their sub cases that cover all aspects of the input data into color bitmap image. High security layers have been proposed through three layers to make it difficult to break through the encryption of the input data and confuse steganalysis too. Our results against statistical and visual attacks are discussed and make comparison with the previous Steganography algorithms like S-Tools. We show that our algorithm can embed efficiently {{a large amount of}} data that has been reached to 75 % of the image size with high quality of the output. Key words: Hiding with high security, hiding with high capacity, <b>adaptive</b> image <b>segmentation,</b> steganograph...|$|R
40|$|Abstract: In this paper, {{we present}} an <b>adaptive</b> variational <b>segmentation</b> {{algorithm}} of spectral-texture regions in satellite images using level set. Satellite images contain both textured and non-textured regions, so for each region cues of spectral and texture are integrated {{according to their}} discrimination power. Motivated by Fisher-Rao’s linear discriminant analysis, two region’s weights are defined to code respectively the relevance of spectral and texture cues. Therefore, regions with or without texture are processed in the same framework. The obtained segmentation criterion is minimized via curves evolution within an explicit correspondence between the interiors of evolving curves and regions in segmentation. Thus, an unambiguous segmentation to a given arbitrary number of regions is obtained by the multiregion competition algorithm. Experimental results on both natural and satellite images are shown. Key-words: Level set theory, <b>adaptive</b> multispectral image <b>segmentation,</b> textured / non-textured regions, discrimination power, multiregion competition. ∗ This work is partially supported by QuerySat project and INRIA STIC project...|$|R
30|$|It {{can be seen}} in Fig.  3 {{that after}} the {{threshold}} segmentation, the features are more prominent, and the target recognition is more convenient. At the same time, with some methods based on global threshold or optimal threshold <b>segmentation,</b> this <b>adaptive</b> threshold <b>segmentation</b> is not sensitive to the effects of illumination conditions and reflections. After the threshold segmentation forms the binarized image e, the connected regions formed by the self-color pixel points in the image are re-marked to obtain a candidate text region.|$|R
40|$|Abstract. In this paper, a {{self-adapting}} segmentation algorithm for low-quality video Image {{based on}} camera information {{is present in}} detail. An adaptive threshold value method is used to extract the goal information. Combining features of the goal and video background, an <b>adaptive</b> <b>segmentation</b> algorithm based on hue histogram and saturation histogram is proposed, which can adapt the changing environmental conditions. The experiments have demonstrated the good performance of the self-adapting segmentation algorithm...|$|E
40|$|We {{continue}} {{previous work}} about {{the combination of}} top-down and bottom-up <b>adaptive</b> <b>segmentation</b> techniques, Voronoi diagrams and irregular pyramids. We extend our considerations to the dual irregular pyramid to overcome the problem of increasing degree inherent to the "classical" irregular pyramid. Experimental results are presented, the analysis of which reveals inconsistencies {{in the theory of}} dual irregular pyramids. The conclusion of the report outlines two strategies for research in view of a solution...|$|E
40|$|International audienceWe {{propose a}} {{framework}} for the segmentation by region growing approach leveraging on feature space. It has the advantages to deal with multidimensional data and easily specify locally <b>adaptive</b> <b>segmentation.</b> It relies upon {{the definition of a}} robust neighborhood which drives the region growing. We propose two applications to illustrate this framework: a segmentation of physical parameters maps of MRI by using n-dimensional region growing and a segmentation of highly noisy image by using adaptive region growing...|$|E
40|$|This paper {{proposes a}} novel {{approach}} to extract image features like contour extraction and edge detection for image segmentation with self organizing properties for a network of <b>adaptive</b> elements. <b>Segmentation</b> {{is a collection of}} methods allowing to interpret parts of the image as objects. The object is everything what is of interest in the image {{and the rest of the}} image is background. Through experiments, the proposed approach will be intensively evaluated by applying a large number of segmentation tests to medical images...|$|R
40|$|Abstract. Aiming at {{detecting}} the moving targeting from video sequence, this paper proposes a mixed algorithm in video sequence {{based on the}} motion target detection. Combining the median filtering background modeling and the improved TemporalDifference method (MFTD) to detect the object which also use the self- <b>adaptive</b> threshold <b>segmentation</b> method to optimize moving object extraction, {{and at the same}} time, we introduce the gaussian filter and morphological filter to eliminate noise and improve the effect of moving region extraction. In practical engineering, the MFTD algorithm can extract the moving object regions accurately and effectively...|$|R
40|$|WISDOM++ is a {{document}} analysis system whose main design requirements are real-time user interaction and adaptivity. This paper presents the two-phased skew estimation algorithm and the <b>adaptive</b> document block <b>segmentation</b> and classification techniques. An {{evaluation of the}} performance of some of these tasks is also conducted according to a benchmarking procedure...|$|R
