11|543|Public
30|$|In {{the recent}} years, the {{availability}} of GNSS radio front ends with USB has improved, making {{the implementation of a}} pure software receiver on a PC platform quite straightforward. The area where pure software receivers have already made a breakthrough is postprocessing applications. Postprocessing with software receivers allows fast <b>algorithm</b> <b>prototyping</b> and signal analysis. Typical postprocessing applications are ionospheric monitoring, geodetic applications, and other scientific applications [21, 32].|$|E
40|$|We {{describe}} three MATLAB {{classes for}} manipulating tensors {{in order to}} allow fast <b>algorithm</b> <b>prototyping.</b> A tensor is a multidimensional or N-way array. We present a tensor class for manipulating tensors which allows for tensor multiplication and 'matricization. ' We have further added two classes for representing tensors in decomposed format: cp{_}tensor and tucker{_}tensor. We demonstrate the use of these classes by implementing several algorithms that have appeared in the literature...|$|E
40|$|This master's thesis {{deals with}} {{implementation}} of ISO C 99 language interpreter. The {{goal of this}} thesis is to provide support of education in C language programming and fast <b>algorithm</b> <b>prototyping.</b> It enables students to create own C programs and to experiment with language constructions without compiling. User interface includes editor and simple debugger. The interpreter is implemented in a novel grammar development environment written in Java language - ANTLRWorks which includes ANTLR language tool...|$|E
40|$|This paper can be {{seen from}} two sides. From the first side as the answer of the question: how to {{initialize}} the Learning Vectors Quantization algorithm. And from second side it {{can be seen}} as the method of improving of instances selection algorithms. In the article we propose to use a conjunction of the LVQ and some of instances selection algorithms because it simplify the LVQ initialization and provide to better prototypes set. Moreover prepared experiments clearly show that such combinations of methods provide to higher classification accuracy on the unseen data. The results were computed and averaged for several benchmarks. KEY WORDS Learning vector quantization (LVQ), instance selection <b>algorithm,</b> <b>prototype</b> selection <b>algorithm,</b> <b>prototype</b> based learning, similarity based models. ...|$|R
40|$|It is {{well known}} that the {{hardware-in-the-loop}} simulation (HILS) is a wide range used method for control prototyping and system modeling applications. This paper presents a microcontroller-based control system design and development for real-time control <b>algorithms</b> <b>prototyping</b> using the HILS strategy. The entire hardware module of this system is based on a BigPIC 6 development board interfaced to the Matlab/Simulink software environment. The plant is modeled by using Simulink components on the xPC target and the control algorithms are implemented on the microcontroller-based module. As a result of the adopted development strategy, a powerful and versatile system has been obtained for real-time control <b>algorithms</b> <b>prototyping</b> and development. A large set of experimental results proves the feasibility and efficiency of the developed HILS system, providing a very efficient research and development tool both for modeling and experimental purposes. Index Terms — hardware-in-the-loop, microcontroller, real-time control, rapid prototyping, HIL simulatio...|$|R
40|$|This User Guide {{describes}} SOSS (Surface Operations Simulator and Scheduler) {{software build}} and graphic user interface. SOSS is a desktop application that simulates airport surface operations in fast time using traffic management algorithms. It moves aircraft on the airport surface {{based on information}} provided by scheduling <b>algorithm</b> <b>prototypes,</b> monitors separation violation and scheduling conformance, and produces scheduling algorithm performance data...|$|R
40|$|This thesis investigates how audio {{analysis}} {{techniques and}} representations {{can be used}} to automate the sequencing of arbitrary sounds in order to provide a higher level and more expressive control over the creation of sample based music. This pursuit required the creation of a mosaicing <b>algorithm</b> <b>prototyping</b> language, which expedites the process of creating and testing different ways to interactively control the creation of audio mosaics. A number of different mosaicing algorithms were written and tested within this framework that gave insight into the efficacy of different audio representations as both a control mechanism for creating audio mosaics and as a mapping between raw samples and their cumulative perceptual effect. i...|$|E
40|$|Tensors (also {{known as}} multidimensional arrays or N-way arrays) {{are used in}} a variety of {{applications}} ranging from chemometrics to psychometrics. We describe four MATLAB classes for tensor manipulations {{that can be used for}} fast <b>algorithm</b> <b>prototyping.</b> The tensor class extends the functionality of MATLAB’s multidimensional arrays by supporting additional operations such as tensor multiplication. The tensor as matrix class supports the “matricization ” of a tensor, i. e., the conversion of a tensor to a matrix (and vice versa), a commonly used operation in many algorithms. Two additional classes represent tensors stored in decomposed formats: cp tensor and tucker tensor. We describe all of these classes and then demonstrate their use by showing how to implement several tensor algorithms that have appeared in the literature...|$|E
40|$|In {{this paper}} we {{consider}} techniques {{for improving the}} performance of codes for general sparse problems by extracting both local and global structure information from a sparse matrix instance. This information {{can be used to}} improve the performance of the primitives through the utilization of specialized methods for the component parts which result from the matrix decomposition. A calculus is defined for controlling the decompositions and algorithms are presented for implementing the techniques within a code development environment. 1 Introduction The development of libraries for high-performance computers and their effective use in application codes is an iterative process involving the refinement of the algorithms and implementations, and the tuning of parameters to match the machine architecture and the application context. This process includes the complex <b>algorithm</b> <b>prototyping</b> stage and continues during the lifetime of the library, as the algorithms are updated and ported between [...] ...|$|E
40|$|We {{present a}} system for a visual control of {{ready-made}} food based on image processing algorithms. Pictures are taken with a CCD camera and a frame-grabber {{at a rate of}} one per second. In the first processing level the relevant information is extracted via a recursive split-and-merge <b>algorithm.</b> <b>Prototypes</b> are applied to the obtained clusters to get probability values for each ingredient. In a final decision stage connected objects belonging to the same prototype are compared to get an optimal global classification...|$|R
40|$|Abstract. The Nearest Neighbor (NN) {{algorithm}} {{is a well-known}} and effective classification <b>algorithm.</b> <b>Prototype</b> Selection (PS), which pro-vides NN with a good training set to pick its neighbors from, is an important topic as NN is highly susceptible to noisy data. Accurate state-of-the-art PS methods are generally slow, which motivates us to propose a new PS method, called OWA-FRPS. Based on the Ordered Weighted Average (OWA) fuzzy rough set model, we express the quality of instances, and use a wrapper approach to decide which instances to se-lect. An experimental evaluation shows that OWA-FRPS is significantly more accurate than state-of-the-art PS methods without requiring a high computational cost...|$|R
40|$|Learning Vector Quantization (LVQ) {{are popular}} multi-class {{classification}} <b>algorithms.</b> <b>Prototypes</b> in an LVQ system represent the typical features of {{classes in the}} data. Frequently multiple prototypes are employed for a class to improve the representation of variations within the class and the generalization ability. In this paper, we investigate the dynamics of LVQ in an exact mathematical way, aiming at understanding {{the influence of the}} number of prototypes and their assignment to classes. The theory of on-line learning allows a mathematical description of the learning dynamics in model situations. We demonstrate using a system of three prototypes the different behaviors of LVQ systems of multiple prototype and single prototype class representation. ...|$|R
40|$|In the {{framework}} of an ENVISAT Expert Support Laboratories Group {{set up by the}} European Space Agency, the DLR supports several critical aspects of the ENVISAT ASAR product quality and algorithm development. This study is focusing on <b>algorithm</b> <b>prototyping</b> and image radiometric quality based on real SIR-C ScanSAR data. The Extended Chirp Scaling Algorithm used for the processing combines the accuracy of the Chirp Scaling Algorithm with the efficiency of the SPECAN approach. Due {{to the use of the}} SPECAN approach, an azimuth scaling function is introduced in order to avoid the azimuth interpolation for geometric correction. The azimuth scaling removes the varying Doppler rate with range and introduces a constant Doppler rate which leads to the desired sampling space in azimuth. For Doppler centroid estimation a new approach for the ScanSAR imaging mode is proposed. For the roll angle estimation, standard techniques are used which are based on the signal ratio in the overlapping region between subswaths. (orig.) Available from TIB Hannover: RN 437 (96 - 25) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekSIGLEDEGerman...|$|E
40|$|The {{accuracy}} that GNSS and GBAS {{can provide}} {{is the key}} to improve air traffic where bottlenecks appear: terminal areas surrounding main airports. Its implementation would represent lower budgets in cost and maintenance in comparison to current guidance systems that would remain as backup. This project focuses on processing raw satellite data and producing a standard output to increase air traffic navigation, approach and landing capacities in terminal areas. This involves tasks such as <b>algorithm</b> <b>prototyping</b> in Matlab and -integrity monitoring testing- with bad ephemeris data to check the output response. The impact of known errors will be analyzed to obtain a robust and scalable system. The next step will be the GBAS message codification and generation (Type 1) for a GBAS station. This station will be made up of four reference receivers located in the proximity of airport's Runways to accomplish CAT (I) requirements and provide the best measurements in approach and landing maneuvers. The project is located in the base of an ambitious bigger scheme (CATGOS) under development by Indra, which aims to implement and certificate a GBAS station for an airport environment in a four-year prospect...|$|E
40|$|Multielectrode arrays {{may have}} several {{advantages}} {{compared to the}} traditional single macroelectrode brain electrical stimulation technique including less tissue damage due to implantation {{and the ability to}} deliver several spatio-temporal patterns of stimulation. Prior work on cell cultures has shown that multielectrode arrays are capable of completely stopping seizure-like spontaneous bursting events through a distributed asynchronous multi-site approach. In my studies, I used a similar approach for controlling seizures in a rat model of temporal lobe epilepsy. First, I developed a new method of electroplating in vivo microelectrode arrays for durably improving their impedance. I showed that microelectrode arrays electroplated through the new technique called sonicoplating, required the least amount of voltage in current controlled stimulation studies and also produced the least amplitude and duration of stimulation artifact compared to unplated, DC electroplated or pulse-plated microelectrodes. Second, using c-fos immunohistochemistry, I showed that 16 -electrode sonicoplated microelectrode arrays can activate 5. 9 times more neurons in the dorsal hippocampus compared to a single macroelectrodes while causing < 77 % the tissue damage. Next, through open-loop multisite asynchronous microstimulation, I reduced seizure frequency by ~ 50 % in the rodent model of temporal lobe epilepsy. Preliminary studies aimed at using the same stimulation protocol in closed-loop responsive and predictive seizure control did not stop seizures. Finally, through an internship at Medtronic Neuromodulation, I worked on developing and implementing a rapid <b>algorithm</b> <b>prototyping</b> research tool for closed-loop human deep brain stimulation applications. Ph. D...|$|E
40|$|The Nearest Neighbor (NN) {{algorithm}} {{is a well-known}} and effective classification <b>algorithm.</b> <b>Prototype</b> Selection (PS), which provides NN with a good training set to pick its neighbors from, is an important topic as NN is highly susceptible to noisy data. Accurate state-of-the-art PS methods are generally slow, which motivates us to propose a new PS method, called OWA-FRPS. Based on the Ordered Weighted Average (OWA) fuzzy rough set model, we express the quality of instances, and use a wrapper approach to decide which instances to select. An experimental evaluation shows that OWA-FRPS is significantly more accurate than state-of-the-art PS methods without requiring a high computational cost...|$|R
40|$|The Crew Exploration Vehicle (CEV) is {{required}} to maintain continuous abort capability from lift off through destination arrival. This requirement {{is driven by the}} desire to provide the capability to safely return the crew to Earth after failure scenarios during the various phases of the mission. This paper addresses abort trajectory design considerations, concept of operations and guidance <b>algorithm</b> <b>prototypes</b> for the portion of the ascent trajectory following nominal jettison of the Launch Abort System (LAS) until safe orbit insertion. Factors such as abort system performance, crew load limits, natural environments, crew recovery, and vehicle element disposal were investigated to determine how to achieve continuous vehicle abort capability...|$|R
40|$|This {{viewgraph}} presentation {{reviews the}} creation of a <b>prototype</b> <b>algorithm</b> for atmospheric correction using high spatial resolution earth observing imaging systems. The objective of the work was to evaluate accuracy of a <b>prototype</b> <b>algorithm</b> that uses satellite-derived atmospheric products to generate scene reflectance maps for high spatial resolution (HSR) systems. This presentation focused on preliminary results of only the satellite-based atmospheric correction algorithm...|$|R
30|$|This article {{presents}} a Model-Based Design (MBD) approach to rapidly implement power quality (PQ) metering algorithms. Power supply quality {{is a very}} important aspect of modern power systems and will become even more important in future smart grids. In this case, maintaining the PQ parameters at the desired level will require efficient implementation methods of the metering algorithms. Currently, the development of new, advanced PQ metering algorithms requires new hardware with adequate computational capability and time intensive, cost-ineffective manual implementations. An alternative, considered here, is an MBD approach. The MBD approach focuses on the modelling and validation of the model by simulation, which is well-supported by a Computer-Aided Engineering (CAE) packages. This paper presents two algorithms utilized in modern PQ meters: a phase-locked loop based on an Enhanced Phase Locked Loop (EPLL), and the flicker measurement according to the IEC 61000 - 4 - 15 standard. The algorithms were chosen because of their complexity and non-trivial development. They were first modelled in the MATLAB/Simulink package, then tested and validated in a simulation environment. The models, in the form of Simulink diagrams, were next used to automatically generate C code. The code was compiled and executed in real-time on the Zynq Xilinx platform that combines a reconfigurable Field Programmable Gate Array (FPGA) with a dual-core processor. The MBD development of PQ algorithms, automatic code generation, and compilation form a rapid <b>algorithm</b> <b>prototyping</b> and implementation path for PQ measurements. The main advantage of this approach is the ability to focus on the design, validation, and testing stages while skipping over implementation issues. The code generation process renders production-ready code that can be easily used on the target hardware. This is especially important when standards for PQ measurement are in constant development, and the PQ issues in emerging smart grids will require tools for rapid development and implementation of such algorithms.|$|E
40|$|Environmental {{datasets}} grow in {{size and}} specialization while models designed for local scale are often unsuitable at regional/continental scale. At regional scale, data are usually available as georeferenced collections of spatially distributed despite semantically atomic information. Complex data intrinsically impose modellers to manipulate nontrivial information structures. For example, multi-dimensional arrays of time series may be composed by slices of raster spatial matrices for each time step, whilst heterogeneous collections of uneven arrays are common when dealing with data analogous to precipitation events, and these structures may ask for integration at several spatial scales, projections and temporal extents. Interestingly, it might be far more difficult to practically implement such a complexity rather than conceptually describe it: a subset of modelling generalizations may deal more with abstraction rather than with the explosion of lines of code. Many environmental modelling algorithms are composed by chains of data-transformations or trees of domain specific sub-algorithms. Concisely expressing them {{without the need for}} paying attention on the enormous set of spatio-temporal details, is a highly recommendable practice in both mathematical formulation and implementation. The use of semantic array programming paradigm is here exemplified as a powerful conceptual and practical (with the free software library Mastrave) tool for easing scalability and semantic integration in environmental modelling. Array programming, AP, is widely used for its computational effectiveness but often underexploited in reducing the gap between mathematical notation and algorithm implementations, i. e. by promoting arrays (vectors, matrices, tensors) as atomic quantities with extremely compact manipulating operators. Coherent array-based mathematical description of models can simplify complex <b>algorithm</b> <b>prototyping</b> while moving mathematical reasoning directly into the source code – because of its substantial size reduction – where the mathematical description is actually expressed in a completely formalized and reproducible way. The proposed paradigm suggests to complement the characteristic AP weak typing with semantics, both by composing generalized modular sub-models and via array oriented – thus concise – constraints. The Mastrave library use is exemplified with a regional scale benchmark application to local-average invariant (LAI) downscaling of climate raster data. Unnecessary errors frequently introduced by non-LAI upsampling are shown to be easily detected and removed when the scientific modelling practice is terse enough to let mathematical reasoning and model coding merge together. JRC. H. 3 -Forest Resources and Climat...|$|E
40|$|Most {{research}} on 3 -D object classification and recognition focuses on recognition {{of objects in}} 3 -D scenes from a small database of known 3 -D models. Such an approach does not scale well to large databases of objects and does not generalize well to unknown (but similar) object classification. This paper presents two ideas to address these problems (i) class selection, i. e., grouping similar objects into classes (ii) class prototyping, i. e., exploiting common structure within classes to represent the classes. At run time matching a query against the prototypes is sufficient for classification. This approach will not only reduce the retrieval time but also will help increase the generalizing power of the classification algorithm. Objects are segmented into classes automatically using an agglomerative clustering <b>algorithm.</b> <b>Prototypes</b> from these classes are extracted using one of three class <b>prototyping</b> <b>algorithms.</b> Experimental results demonstrate {{the effectiveness of the}} two steps in speeding up the classification process without sacrificing accuracy. 1...|$|R
40|$|Several network flows based {{methods have}} been {{suggested}} {{in the past for}} the solution of the complementary suppression problem (CSP). Adding some of those methods to the t-Argus system is one of the tasks to be performed within the scope of the ongoing IST CASC project. In this paper the authors briefly present how modeling languages can be used for the quick development of <b>algorithm</b> <b>prototypes</b> for CSP. This will permit evaluating and testing different algorithmic options prior to the costly development of an efficient exploitation code. We illustrate the use of modeling languages with a particular network flow based method. This method is implemented using a state-of-the-art modeling language, and some preliminary computational results are presented...|$|R
40|$|To express {{temporal}} {{properties of}} dense-time real-valued signals, the Signal Temporal Logic (STL) {{has been defined}} by Maler et al. The work presented a monitoring algorithm deciding the satisfiability of STL formulae on finite discrete samples of continuous signals. The logic {{has been used to}} express and analyse biological systems, but it is not expressive enough to sufficiently distinguish oscillatory properties important in biology. In this paper we define the extended logic STL ∗ in which STL is augmented with a signal-value freezing operator allowing us to express (and distinguish) detailed properties of biological oscillations. The logic is supported by a monitoring <b>algorithm</b> <b>prototyped</b> in Matlab. The monitoring procedure of STL ∗ is evaluated on a biologically-relevant case study. ...|$|R
40|$|The Crosstrack Infrared Sounder (CrIS) is a {{spaceborne}} Fourier Transform Spectrometer (FTS). The flight module 1 (FM 1) {{is currently}} flying onboard the SUOMI-NPP satellite that was launched on October 28 th 2011. Three distinct subjects are presented: (1) Statistics {{on the long}} term monitoring system are presented focusing on the instrument stability, the data quality flags, and anomaly detection, (2) Validation effort of the CrIS SDR <b>algorithm</b> <b>prototype</b> that can generate radiance at high resolution, (3) The flight module 2 (FM 2) {{which is scheduled to}} be launched onboard the JPSS- 1 satellite in 2017 has just undergone the bench testing. Analysis of the bench data are presented here focusing on the laser ILS, the noise (NEdN), and the instrument stability...|$|R
40|$|AbstractWe {{extend the}} Markov Chain Tree Theorem to general {{commutative}} semirings, and we generalize the State Reduction Algorithm to general commutative semifields. This {{leads to a}} new universal <b>algorithm,</b> whose <b>prototype</b> is the State Reduction Algorithm which computes the Markov chain tree vector of a stochastic matrix...|$|R
40|$|Summary: "This book is for {{academic}} researchers and engineers {{who work with}} distance learning programs and software systems, as well as general users of distance education technologies and methods including computational methods, <b>algorithms,</b> implemented <b>prototype</b> systems, and applications of open and distance learning" [...] Provided by publisher...|$|R
40|$|We {{extend the}} Markov chain tree theorem to general {{commutative}} semirings, and we generalize the state reduction algorithm to commutative semifields. This {{leads to a}} new universal <b>algorithm,</b> whose <b>prototype</b> is the state reduction algorithm which computes the Markov chain tree vector of a stochastic matrix. Comment: 13 page...|$|R
40|$|A. Orbit Correction System Optimization: Recipes for {{optimizing}} {{an orbit}} correction system configuration at {{the design level}} are presented. Linear algebraic tools are applied to various flavors of response matrices to uniformly control unobservability, uncorrectability, and response matrix singularity. Application at Jefferson Lab is discussed. B. Orbit Correction at Jefferson Lab: Unique challenges posed by orbit correction, as well as algorithms and tools developed at the CEBAF accelerator at Jefferson Lab are discussed. C. Orbit Interpretation and Virtual Monitors: A new approach to developing an orbit correction package with software structural, algorithmic and operational advantages is introduced. It consists of an orbit interpretation module, a virtual monitor module, and a generic steering engine. Mathematical formulation, <b>algorithms</b> <b>prototyped</b> and tested on simulated and real data, and future possibilities are discussed...|$|R
40|$|International audienceThe high {{performance}} Digital Signal Processors (DSP) currently manufactured by Texas Instruments are heterogeneous multiprocessor architectures. Programming these architectures {{is a complex}} task often reserved to specialized engineers because the bottlenecks of both the algorithm and the architecture need to be deeply understood {{in order to obtain}} a fairly parallel execution. The PREESM framework objective is to simplify the programming of multicore DSP systems by building on dataflow programming methods. The current functionalities of this scalable framework cover memory and time analysis, as well as automatic deadlock-free code generation. Several tutorials are provided with the tool for fast initiation of C programmers to multicore DSP programming. This paper demonstrates PREESM capabilities by comparing simulation and execution performances on a stereo matching <b>algorithm</b> <b>prototyped</b> on the TMS 320 C 6678 8 -core DSP device...|$|R
40|$|Includes bibliographical {{references}} (page 65) The {{goal of the}} Linked List <b>Algorithm</b> <b>Prototype</b> (LLAP) {{project is}} to develop a Computer-Aided-Instruction package that simulates three algorithms: RETRIEVAL, INSERTION and DELETION of linked lists. The package is implemented to run on a Teleray terminal and is written in OMSI PASCAL for a PDP 11 / 70. It contains three lessons with four phases: introduction, tutor, simulation, and conclusion. The algorithm???s purpose and required data structures are discussed in the introduction phase. The tutor phase describes a pseudo-code algorithm and the necessacy variables and data structures. The simulation phase steps through the algorithm and updates a graphic display of the list structures and the attendant variables. A conclusion screen is used to summarize each algorithm's performance relative to other simulations in the package...|$|R
40|$|This thesis {{presents}} {{a prototype of}} a dynamic load balancing algorithm designed for compilation servers. The algorithm takes a user ID and finds the optimal compilation server for the user based on the historical CPU and RAM load of the user. It includes a monitoring tool for gathering user and server resource usage at a process level. The data is stored in a historical database and the historical data is used to predict load on servers. A compilation sever system is monitored over time {{and the results are}} analysed to find potential bottlenecks in the system. The data gathered by the monitoring script is used to make a custom tailored load balancing algorithm. This paper presents the reasoning behind the design of the monitoring tool and the load balancing <b>algorithm</b> <b>prototype...</b>|$|R
40|$|Modern {{condition}} of {{hardware and software}} for manufacturing of journal production is considered. Macros, as means of automation of prepress preparations of editions and scripts are investigated of software. Recommendations about perfection of technology of imposition of journal production are developed, the cause and effect diagramme and <b>algorithm</b> of <b>prototyping</b> of magazines. ??????????? ??????????? ????????? ?????????? ? ??????????? ??????? (???) ??? ???????????? ?????????? ?????????. ??????????? ???????????? (???????), ??? ???????? ????????????? ???????? ?????????? ?????????? ??????? ? ??????? ??. ??????????? ???????????? ?? ?????????????????? ?????????? ??????? ?????????? ?????????, ????????-???????????? ????????? ? ???????? ????????????? ????????...|$|R
40|$|A dual {{frequency}} and dual-linear polarization multi-layer microstrip antenna element for array-antenna applications is presented. The {{performance of the}} element was computed using a commercial software based on the finite-element-method (FEM) <b>algorithm.</b> A <b>prototype</b> with dimensions based on the simulations was built and tested. Good agreement between the measured and numerical results is obtained. (C) 2004 Wiley Periodicals, Inc...|$|R
40|$|With the {{increased}} availability {{and complexity of}} distributed systems comes a greater need for solutions {{to assist in the}} management of distributed system components. Despite the significant contributions made towards the development of management tools that monitor and control distributed systems, little has been done to address issues such as the cost of management and how it can adapt to the dynamic changes in user requirements as well as system resources. We present an adaptive model, in which an initial optimal configuration of management agents is determined according to a set of user/system requirements. These agents can later be dynamically reconfigured to adapt to changes in resource availability and user/system constraints, with minimal effect on the behaviour of the managed system components. <b>Algorithm,</b> <b>prototype,</b> and experimental results are presented. 1 Introduction With {{the increased}} availability and complexity of distributed systems comes a greater need for solutions to [...] ...|$|R
40|$|Previous work at this {{department}} {{has been directed}} towards a method of producing efficient parallel implementations from functional <b>prototypes</b> using <b>algorithms</b> {{from the field of}} computer vision as applications. There is existing code in both a functional language (SML) and in an intrinsically parallel language (Occam 2) for a Canny based edge detector [Kou 93] and a perspective inversion based model matching programme [WMM 90]. This report presents a similar analysis of a Hough transform based segmentation <b>algorithm,</b> <b>prototyped</b> in SML and then implemented in Occam 2. The process of <b>prototyping</b> a single <b>algorithm</b> and converting this prototype into a parallel implementation has been studied in detail [Bus 93, Bra 92]. There has been little experience, however, in combining existing implementations into an overall system. The three individual components (edge detection, feature segmentation and model matching) were combined into a complete intensity based scene interpretation program [...] ...|$|R
50|$|Experimental work {{published}} in 2011 and 2012 demonstrates significantly greater speedups for advanced PRAM <b>algorithms</b> on XMT <b>prototypes</b> {{than for the}} same problems on state-of-the-art multi-core computers.|$|R
