37|22|Public
25|$|Designed to {{meet the}} {{training}} requirements of a company-sized unit in an urban environment, Military Operations in Urban Terrain (MOUT) Site Calero includes 48 buildings constructed from connex containers up to two stories high, {{with a mixture of}} rubble and complete structures. The layout includes a residential area, school, marketplace, and worship area. Soldiers learn how to clear rooms and buildings in built-up areas, conduct house-to-house searches by foot in hostile urban areas and distinguish between the characteristics of an innocent civilian and an embedded insurgent aiming to do harm. The MOUT also includes a building used for training classes and <b>after-action</b> <b>review</b> sessions. The site is named in honor of Maj. Jeffrey R. Calero of Queens Village, N.Y. Calero, a member of Operational Detachment Alpha 2132, C Company, 1st Battalion, 20th Special Forces Group (Airborne), was killed in action in Afghanistan on October 29, 2007.|$|E
50|$|In 2007, defense {{contractor}} Boeing commissioned ProSIM {{to create a}} custom version of the game {{for use as a}} ground combat simulator, to be paired with an intelligent tutor and <b>after-action</b> <b>review</b> agent application developed by Boeing.|$|E
50|$|In 2011, Saab Bofors Dynamics (successor {{company of}} Bofors Defence) {{announced}} {{the introduction of}} the new RBS 70 New Generation (RBS 70 NG). The upgraded version included an improved sighting system capable of night vision and improved training and <b>after-action</b> <b>review</b> features.|$|E
5000|$|Task Force Palehorse {{provides}} invaluable {{feedback to}} units through professional <b>After-Action</b> <b>Reviews</b> and written reports {{in support of}} ten National Training Center rotations a year.|$|R
2500|$|Virtual Convoy Operations Trainer (VCOT)- Simulates Baghdad {{and other}} geo-specific areas for mission rehearsals, leader training, and <b>after-action</b> <b>reviews.</b> Provides {{360-degree}} visibility and weapon engagement area. Exercises include enemy IEDs, RPGs, machine gunners, riflemen, [...] "technical" [...] trucks, mortars, and suicide vehicles.|$|R
40|$|Abstract This paper {{describes}} an Explainable Artificial Intelligence (XAI) tool that allows entities {{to answer questions}} about their activities within a tactical simulation. We show how XAI can be used to provide more meaningful <b>after-action</b> <b>reviews</b> and discuss ongoing work to integrate an intelligent tutor into the XA...|$|R
50|$|All {{these events}} are {{recorded}} on the exercise computer. <b>After-Action</b> <b>Review</b> (AAR) can include comprehensive analysis of weapon firing, accuracy and warhead {{effects on the}} targets. Such techniques have taken much speculation out of the assessment of field exercises and have resulted in more realistic training than used to be available other than by using (dangerous) live firing.|$|E
50|$|After the Beirut deployment, Lieutenant General Alfred M. Gray, Jr. did an <b>after-action</b> <b>review</b> of the 2nd Radio Battalion {{detachment}} {{that went}} with that force. Part {{of the reason for}} this was that the irregular units that presented the greatest threat did not follow conventional military signal operating procedures, and used nonstandard frequencies and callsigns. Without NSA information on these groups, the detachment had to acquire this information from their own resources.|$|E
50|$|At the time, {{there was}} a great deal of {{interest}} in leveraging the stability, low cost and computational/rendering power of the new generation of game consoles, chiefly Sony’s PlayStation 2 and Microsoft’s Xbox, for training applications. Legal restrictions on the PlayStation (using the platform for a military purpose) combined with the default Xbox configuration “persistence” (i.e. missions recorded on the embedded hard drive for <b>after-action</b> <b>review)</b> led to the final selection of the Xbox platform for development.|$|E
40|$|Excerpt} <b>After-action</b> <b>reviews</b> are a {{leadership}} and knowledge-sharing tool which {{bring together the}} team that is closest to the activity or project, when a critical milestone has been reached, to discuss successes and failures in an open and honest fashion. The purpose is {{to learn from the}} experience and take the lessons learned into the next phase of the activity or project, or to accomplish related tasks more effectively the next time a similar activity or project is conducted. <b>After-action</b> <b>reviews</b> and retrospects are linked conceptually. The difference lies in the degree of detail and the formality applied to the process of conducting them. Exit interviews are a way to capture knowledge from leavers. Peer assists are about teams asking for help for the benefit of their members. They are about “learning before doing. ” But continuously assessing organizational performance to meetor exceed expectations requires also that one obtain feedback and understand what happened (or did not happen) during an activity or project, or soon after completion. <b>After-action</b> <b>reviews</b> are about “learning while doing:” they identify how to correct shortcomings and sustain accomplishments. Retrospects are about “learning after doing:” they capture the new knowledge acquired after the fact. In both instances, knowledge gleaned from and compiled by those closest to the review can be used to improve results and can be shared with others who are planning, developing, implementing, and evaluating similar efforts...|$|R
25|$|Those who deliver {{training}} must exemplify both military {{skills and}} cultural sensitivity. While one's own country might consider searching <b>after-action</b> <b>reviews</b> a recognized learning experience, such techniques are counterproductive {{in countries where}} even one-on-one direct criticism is insulting, {{and even more so}} if criticism is delivered in front of third parties. Especially in intelligence and psychological operations, the FID and HN personnel should recognize they can learn from one another.|$|R
50|$|An after {{action review}} (AAR) is a {{structured}} review or de-brief (debriefing) process for analyzing what happened, why it happened, {{and how it}} can be done better by the participants and those responsible for the project or event. <b>After-action</b> <b>reviews</b> in the formal sense were originally developed by the U.S. Army. Formal AARs are used by all US military services and by many other non-US organizations. Their use has extended to business as a knowledge management tool and a way to build a culture of accountability.|$|R
50|$|In the {{practice}} of the United Nations the concept has been made explicit in the name of their Working Group on Lessons Learned of the Peacebuilding Commission.In the military field, conducting a Lessons learned analysis requires a leader-led after-actions debriefing. These debriefings require the leader to extend the lessons-learned orientation of the standard <b>after-action</b> <b>review.</b> He uses the event reconstruction approach or has the individuals present their own roles and perceptions of the event, whichever best fits the situation and time available.|$|E
50|$|After {{thorough}} {{testing and}} field use (in cooperation with United States Marine Corps), VBS1 was made {{available in the}} fall of 2002 for qualified government clients and military organizations. On May 21, 2004, VBS1 underwent limited public distribution. On August 14, 2004 it was released for North America; distribution was handled by Coalescent Technologies. According to the company, funding through Australian Defence Simulation Office helped add a number of improvements to VBS1 including making it HLA/DIS compliant and improving the <b>after-action</b> <b>review</b> feature in its next iteration, VBS2.|$|E
50|$|The SMODIM {{maintains}} a dynamic position database through player-to-player network communications. The onboard telemetry radio supports simultaneous distribution to multiple locations. The radio {{acts as a}} message repeater to overcome line of sight (LOS) interruptions. The SMODIM interfaces with distributed interactive simulation (DIS) networks using SMODIM tracking analysis and recording (SMOTAR), an advanced software suite that provides visual display and tracking of SMODIM instrumented players. GPS provides real-time position data as players are dynamically simulated, tracked and recorded over tactical maps and aerial photos for <b>after-action</b> <b>review</b> (AAR).|$|E
3000|$|... c An NIMH {{report on}} best {{practices}} for early psychological interventions following mass violence events[62] noted great confusion regarding the term “debriefing.” The authors {{recommend that the}} term “debriefing” be reserved for operational <b>after-action</b> <b>reviews,</b> and not be applied to psychological treatment interventions such as Critical Incident Stress Debriefing[63]. For {{groups such as the}} military, after-action group debriefings, properly timed and conducted and focused on events rather than emotions and reactions, can have great therapeutic value for many participants by helping them to place potentially traumatizing events in a broader context of positive meaning[64].|$|R
500|$|In March 1937, McNair was {{assigned}} to command of the 2nd Field Artillery Brigade, {{a unit of the}} 2nd Infantry Division, then based at Fort Sam Houston, Texas. [...] The Army continued to experiment with equipment, weapons, and organizational design as it moved towards mechanization and modernization; the Army Chief of Staff directed tests of the triangular division concept (as opposed to the square division of World War I) through creation of a Proposed Infantry Division (PID). [...] The 2nd Infantry Division was selected to conduct the tests, and McNair performed additional duty as the PID's chief of staff. [...] In this position, he managed and supervised the PID's design, field tests, <b>after-action</b> <b>reviews,</b> and reports and recommendations to the War Department.|$|R
40|$|Game manuals and {{tutorial}} {{scenarios are}} insufficient for new players to learn games of deep complexity such as highly realistic tactical simulations of modern battlefields. Adding post-game <b>after-action</b> <b>reviews</b> improves the situation, but these typically {{do not provide}} guidance during the mission and {{tend to focus on}} quantitative feedback, rather than specifics about what the player did wrong and how to improve. Intelligent tutoring system (ITS) technology provides a higher level of interactivity and a more specific qualitative analysis to guide players during game play. This use of an AI technology is demonstrated with the integration of an ITS component with the tactical simulation Armored Task Force (ATF) resulting in a combined system called the the Virtual Combat Training Center (V-CTC) ...|$|R
5000|$|Program Manager Training Systems (PM TRASYS) {{improves}} {{the effectiveness of}} the Marine Air-Ground Task Force and globally deployed maritime expeditionary forces by providing training support and developing and sustaining training systems and devices. They are the training systems acquisition arm for the Marine Corps. The various training products they provide include simulators, mock weapons, range targets and range instrumentation. PM TRASYS also provides training technology research and development, distributed learning capabilities, training observation capabilities, <b>after-action</b> <b>review</b> systems, training personnel and combat environment role players. The Product Manager (PdM) portfolios for PM TRASYS are: ...|$|E
50|$|Observer, coach, {{trainers}} are personally {{selected by}} the MCTP commander and a Chief of Operations Group (COG). They are subject matter experts on doctrine and in their specific warfighting functions. They are also certified through a rigorous training program including providing feedback using the <b>After-Action</b> <b>Review</b> process. During a warfighter, they are located at unit command posts and tactical operating centers to observe the operations process. An assignment as an observer, coach/trainer (OC/T) is a rewarding and a recognized professionally broadening experience. There is no better place to truly understand how the Army fights at the Brigade and above levels.|$|E
50|$|VBS3 comes {{equipped}} with several built-in applications that support development training capabilities. These include the following: mission editors, which allow users to add, modify or delete objects {{before and during}} game play, and an <b>after-action</b> <b>review</b> module, which allows administrators and users to conduct post-training analysis {{with the ability to}} fast-forward or rewind to events; a full development suite, allowing users to create buildings, edit terrains and convert 3D models to the VBS3 simulation environment; a massive content library, including more than 9,000 entities; an HLA/DIS gateway that connects VBS with other military simulations or interconnects many VBS servers together.|$|E
40|$|We {{describe}} a new sand table display that combines physical models with computer-generated projection and painting-style interaction. Designed for military training, our sand table has physical models of buildings, illuminated by multiple projectors adding aerial and synthetic imagery, with additional imagery for location and movement of personnel. Interaction with the tabletop scene is enabled through wand-controlled painting on all surfaces. We describe the system requirements and design constraints, such as number of projectors, pixel densities {{on the various}} surfaces, accessibility to multiple users, transportability and size. The targeted training facility currently uses a conventional physical sand table with wooden building models to plan movements of small groups of exercise forces. Our new display should enhance this planning process and also support <b>after-action</b> <b>reviews.</b> Beyond this initial application, our display may also be useful in applications such as surveillance and architectural design review. 1...|$|R
40|$|Good {{knowledge}} {{is essential to}} prevent disease and improve health. Knowledge management (KM) provides a systematic process and tools to promote access to and use of knowledge among health and development practitioners to improve health and development outcomes. KM tools range from publications and resources (briefs, articles, job aids) and products and services (websites, eLearning courses, mobile applications), to training and events (workshops, webinars, meetings) and approaches and techniques (peer assists, coaching, <b>after-action</b> <b>reviews,</b> knowledge cafés). By its very nature, global health and developmentwork involves a multitude of actors working toward common goals that transcend geographic, sectoral, organizational, and financial boundaries. These efforts require immediate access to the latest research and know-how and demand optimal use of limited resources to achieve maximum impact. 1 Knowl-edge management (KM) can improve coordination, enhance learning and knowledge application, and improve capacity, thus heightening service quality...|$|R
40|$|Proceedings for the 1998 Command and Control Research and Technology Symposium Command and Control for the Next Millenium June 29 -July 1, 1998 Naval Postgraduate School Monterey, California Track 1 ArchitecturesSeveral {{principles}} of warfare {{have been developed}} through experience over time. These principles provide a framework {{that can be used}} to assess model-derived command and control architectures from a military perspective. This paper will dis-cuss and present analysis of data collected on participants’ ratings of three model-based archi-tectures on the {{principles of}} warfare to determine quantitative differences among the architectures. Comparisons of these ratings with critical dimen-sions used by modelers to optimize the architec-tures will be discussed, including feedback provid-ed during <b>after-action</b> <b>reviews</b> from military personnel who operated under these organizational architectures when responding to computer-driven scenarios. The objective was to compare the advantages and disadvantages of the three model-derived architectures vis-à- vis military principles. Cognitive and Neural Science Technology Division of ON...|$|R
5000|$|The eight columns reunited at 9 p.m. in Puerta del Sol under {{a banner}} saying [...] "WELCOME DIGNITY," [...] {{received}} with cheers and applause. The march {{culminated in a}} wrap up and <b>after-action</b> <b>review</b> assembly, at which participants shared the social, political and economic problems of the towns visited along the way, {{as well as the}} proposals made by the townspeople. The protesters created The Book of the People to collect these experiences and redacted it into an official document to be deposited in the Congress of Deputies' register. A provisional camp was established in Paseo del Prado to host the thousands of newly arrived walkers.|$|E
50|$|Unlike first-generation ACMI systems, {{which use}} ground radars {{to track and}} record the {{position}} of the aircraft on the range, AACMI systems use aircraft-mounted satellite navigation systems such as the US NAVSTAR GPS system. Recording of aircraft tracks can therefore be independent of ground-based radar, and are sometimes called range-less or autonomous. Radio transmissions from the aircraft report its position in three dimensions to other aircraft on the range and also to ground control. This enables real-time air-to-air exercises to be carried out and also complex ground debriefs (<b>after-action</b> <b>review</b> or AAR) based on data recorded at the time. Such de-briefs involve the use of modern graphics and display techniques that can bring out training and other points to aircrew and ground staff.|$|E
50|$|Learning {{organizations}} are organizations that actively work to optimize learning. Learning organizations use the active process of knowledge management to design organizational processes and systems that concretely facilitate knowledge creation, transfer, and retention. Organizational metacognition {{is used to}} refer to the processes by which the organization 'knows what it knows'. The study of organizational learning and other fields of research such as organizational development, System theory, and cognitive science provide the theoretical basis for specifically prescribing these interventions. An example of an organizational process implemented to increase organizational learning is the U.S. Army's use of a formally structured de-brief process called an <b>after-action</b> <b>review</b> (AAR) to analyze what happened, why it happened, and how it could be improved immediately after a mission. Learning laboratories are a type or learning organization dedicate to knowledge creation, collection, and control.|$|E
40|$|Pre-recorded video {{segments}} can be {{very compelling}} {{for a variety of}} immersive training purposes, including providing answers to questions in <b>after-action</b> <b>reviews.</b> Answering questions fluently using pre-recorded video poses challenges, however. When humans interact, answers are constructed after questions are posed. When answers are pre-recorded, even if a correct answer exists in a library of video segments, the answer may be phrased {{in a way that is}} not coherent with the question. This paper reports on basic research experiments with short “linking dialogues ” that mediate between the question and answer to reduce (or eliminate) the incoherence, resulting in more natural human-system interaction. A set of experiments were performed in which links were elicited to bridge between questions from users of an existing training application and selected answers from the system, and then comparisons made with unlinked answers. The results show that a linking dialogue can significantly increase the perceived relevance of the system’s answers. ...|$|R
5000|$|Ulchi-Freedom Guardian (UFG) is {{an annual}} {{simulation}} driven, command transformation-oriented Command Post Exercise (CPX). Elements of the ROK and US governments participate, {{as well as}} ROK and US forces from {{on and off the}} Korean peninsula. UFG integrates the annual ROK government exercise [...] "Ulchi", which focuses on procedures for transitioning to war, government support. Ulchi also emphasizes ROK procedures for coordination between government and military organizations from the national to local level. UFG typically incorporates the following components: a Crisis Management Exercise focused on strategic and operational decisions needed to defuse a crisis, or posture the command for successful execution of the appropriate OPLAN if the enemy actions dictate; a Senior Leader Seminar (SLS) designed to foster senior-level discussion on a variety of topics related to crisis management and war-fighting; and a two-week Computer Assisted Exercise that exercises the transition to war, defense, and counteroffensive phases of the war-fight. The exercise culminates in detailed senior leader level <b>After-Action</b> <b>Reviews</b> (AARs).|$|R
40|$|One of {{the primary}} tools {{available}} to a Unified Commander-in-Chief (CINC) for training his staffs in execution of their joint plans a command post exercise supported by a computer simulation. This is {{commonly referred to as}} a Computer Aided Exercise (CAX). The computer simulation used for this thesis is the Joint Theater Level Simulation. Currently, the <b>after-action</b> <b>reviews</b> (AARs) are mostly subjective in nature with very little quantitative analysis. The objective of this thesis is to develop a methodology for quantitatively evaluating the data produced by the computer simulation and presenting this analysis graphically. The methodology is based on the Universal Joint Task List which is a comprehensive listing of all joint tasks pertaining to the Armed Forces of the United States. These joint tasks provide the critical events that are analyzed during the CAX. The graphs display a casual audit trail for the critical events of the CAX. The focus of this thesis is Strategic Task Four, Theater Logistics, with specific analysis of amphibious logistics operations. NAU. S. Marine Corps (U. S. M. C.) autho...|$|R
50|$|Designed to {{meet the}} {{training}} requirements of a company-sized unit in an urban environment, Military Operations in Urban Terrain (MOUT) Site Calero includes 48 buildings constructed from connex containers up to two stories high, {{with a mixture of}} rubble and complete structures. The layout includes a residential area, school, marketplace, and worship area. Soldiers learn how to clear rooms and buildings in built-up areas, conduct house-to-house searches by foot in hostile urban areas and distinguish between the characteristics of an innocent civilian and an embedded insurgent aiming to do harm. The MOUT also includes a building used for training classes and <b>after-action</b> <b>review</b> sessions. The site is named in honor of Maj. Jeffrey R. Calero of Queens Village, N.Y. Calero, a member of Operational Detachment Alpha 2132, C Company, 1st Battalion, 20th Special Forces Group (Airborne), was killed in action in Afghanistan on October 29, 2007.|$|E
40|$|Military {{training}} relies {{upon the}} <b>after-action</b> <b>review</b> (AAR) to provide feedback and instruction to the trainee. <b>After-action</b> <b>review</b> {{can refer to}} any number of activities including verbal feedback, review of audio and video recording, and playback of the training session. Training can be directed at an individual or group of individuals. The effectiveness of the review is dependent upon timely and accurate expert assessment. Traditionally, this assessment is made by a human expert; however, the need {{for this type of}} expertise far exceeds its availability. Modern intelligent computer systems cannot completely replace human expertise, but there are certainly places where an intelligent system can aid and add to the <b>after-action</b> <b>review</b> process. This paper examines {{the current state of the}} research and development in this area. In addition, some recent research in intelligent systems is reviewed for the possibility of use in the automation of military AAR...|$|E
40|$|As the {{military}} has moved increasingly towards distributed networked environments for Command and Control Intelligence, Surveillance, and Reconnaissance (C 2 ISR) missions, teams often operate remotely, and decision-making is distributed. Traditionally team training involved human observers for performance assessment, diagnosis, and <b>after-action</b> <b>review</b> and other training intervention. However, {{with much of the}} communication and coordination happening electronically, key aspects of the interactions between team members are no longer accessible to these trainers. Analyzing these communications involves poring over high volumes of raw electronic data. This is infeasible in all but the smallest scales of operation. Intelligent automated performance assessment tools can be valuable cognitive aids to trainers and assist them by warehousing and analyzing team interaction data, and presenting it to them in a user-friendly manner for real time coaching and <b>after-action</b> <b>review.</b> In order to build such a system, it is important to first define a concrete model of team behavior for the domain and to define rules to assess team performance dimensions from observations of team behavior in training exercises. Research literature is rich with different models of team performance; however, these models are defined at a very abstract level and not directly useful at the level of specificity that would be needed by a rule-based artificially intelligent assessment tool. This has always been the challenge of artificial intelligence. In this paper, we will present a case study that show...|$|E
40|$|In {{the setting}} of mass {{casualty}} incidents (MCIs), hospitals need to divert from normal routine to delivering the best possible care to {{the largest number of}} victims. This should be accomplished by activating an established hospital disaster management plan (DMP) known to all staff through prior training drills. Over the recent decades, imaging has increasingly been used to evaluate critically ill patients. It {{can also be used to}} increase the accuracy of triaging MCI victims, since overtriage (falsely higher triage category) and undertriage (falsely lower triage category) can severely impact resource availability and mortality rates, respectively. This article emphasizes the importance of including the radiology department in hospital preparations for a MCI and highlights factors expected to influence performance during hospital DMP activation including issues pertinent to effective simulation, such as establishing proper learning objectives. <b>After-action</b> <b>reviews</b> including performance evaluation and debriefing on issues are invaluable following simulation drills and DMP activation, in order to improve subsequent preparedness. Historically, most hospital DMPs have not adequately included radiology department operations, and they have not or to a little extent been integrated in the DMP activation simulation. This article aims to increase awareness of the need for radiology department engagement in order to increase radiology department preparedness for DMP activation after a MCI occur...|$|R
40|$|How does {{knowledge}} management (KM) {{by a government}} agency responsible for environmental impact assessment (EIA) potentially contribute to better environmental assessment and management practice? Staff members at government agencies {{in charge of the}} EIA process are knowledge workers who perform judgement-oriented tasks highly reliant on individual expertise, but also grounded on the agency`s knowledge accumulated over the years. Part of an agency`s knowledge can be codified and stored in an organizational memory, but is subject to decay or loss if not properly managed. The EIA agency operating in Western Australia was used as a case study. Its KM initiatives were reviewed, knowledge repositories were identified and staff surveyed to gauge the utilisation and effectiveness of such repositories in enabling them to perform EIA tasks. Key elements of KM are the preparation of substantive guidance and spatial information management. It was found that treatment of cumulative impacts on the environment is very limited and information derived from project follow-up is not properly captured and stored, thus not used to create new knowledge and to improve practice and effectiveness. Other opportunities for improving organizational learning include the use of <b>after-action</b> <b>reviews.</b> The learning about {{knowledge management}} in EIA practice gained from Western Australian experience should be of value to agencies worldwide seeking to understand where best to direct their resources for their own knowledge repositories and environmental management practice. (C) 2011 Elsevier Ltd. All rights reserved...|$|R
40|$|Performance and {{efficacy}} are reciprocally causal; however, {{the effect of}} performance on subsequent perceptions of efficacy has received little attention, especially {{in the context of}} team training. In addition, the moderating effect of feedback accuracy on the relationship between team performance and team-efficacy is largely unexplored. As such, the objective {{of the present study was}} to investigate the relationship between team performance and team-efficacy in the context of <b>after-action</b> <b>reviews</b> (AARs). Specifically, this study examined the conjoint influence of (a) the accuracy of performance feedback available to trainees during AARs, and (b) time on the predictive validity of team performance on team-efficacy. Data were obtained from 492 undergraduate students assigned to 123 teams in a 5 hr team training protocol using a 3 (training condition: non-AAR, versus subjective AAR, versus objective AAR) x 3 (sessions) repeated measures design. Contrary to the first set of hypotheses, the positive relationship between performance {{and efficacy}} was strongest for teams trained without AARs and weakest for teams trained using subjective AARs. Although team-efficacy was predicted more strongly by more proximal team performance than by more distal team performance, this pattern of results was found only for teams trained either without AARs or with objective AARs. The predictive validity of performance on efficacy decreased as performance episodes became more proximal among teams trained using subjective AARs. Finally, within-team agreement of team-efficacy ratings decreased over time for teams that engaged in AARs and remained constant over time for teams that did not engage in AARs. The theoretical and practical implications of these findings are discussed. It is anticipated that this research will provide insight into the roles of feedback accuracy and time in the performance-efficacy relationship and provide guidance to researchers and practitioners in effectively integrating AAR design characteristics into team training environments...|$|R
