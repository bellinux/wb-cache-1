69|20|Public
25|$|One {{technique}} used on early IBM XT computers was to install additional RAM into the video memory address range {{and push the}} limit up {{to the start of}} the Monochrome Display Adapter (MDA). Sometimes software or a custom <b>address</b> <b>decoder</b> was required for this to work. This moved the barrier to 704 KB (with MDA/HGC) or 736 KB (with CGA).|$|E
50|$|In digital electronics, an <b>address</b> <b>decoder</b> is {{a binary}} decoder that has {{two or more}} inputs for address bits and one or more outputs for device {{selection}} signals. When the address for a particular device appears on the address inputs, the decoder asserts the selection output for that device. A dedicated, single-output <b>address</b> <b>decoder</b> may be incorporated into each device on an address bus, or a single <b>address</b> <b>decoder</b> may serve multiple devices.|$|E
5000|$|A single <b>address</b> <b>decoder</b> with n address input bits {{can serve}} up to 2n devices. Several {{members of the}} 7400 series of {{integrated}} circuits {{can be used as}} address decoders. For example, when used as an <b>address</b> <b>decoder,</b> the 74154 provides four address inputs and sixteen (i.e., 24) device selector outputs. An <b>address</b> <b>decoder</b> is a particular use of a binary decoder circuit known as a [...] "demultiplexer" [...] or [...] "demux" [...] (the 74154 is commonly called a [...] "4-to-16 demultiplexer"), which has many other uses besides address decoding.|$|E
50|$|In CPU design, {{the use of}} a Sum <b>Addressed</b> <b>Decoder</b> (SAD) or Sum <b>Addressed</b> Memory (SAM) <b>Decoder</b> is {{a method}} of {{reducing}} the latency of the CPU cache access. This is achieved by fusing the address generation sum operation with the decode operation in the cache SRAM.|$|R
50|$|Locomotive decoders {{are small}} {{electronic}} circuits fitted inside locomotives {{to interpret the}} digital signals and provide individual control. Although all active decoders receive commands, only the <b>addressed</b> <b>decoder</b> will respond.|$|R
50|$|Some SPARC designs have {{improved}} {{the speed of}} their L1 caches by a few gate delays by collapsing the virtual address adder into the SRAM decoders. See Sum <b>addressed</b> <b>decoder.</b>|$|R
5000|$|Digital memory: Lyon did {{early work}} on static CMOS memory and {{designed}} {{the most efficient}} large CMOS <b>address</b> <b>decoder.</b>|$|E
50|$|An <b>address</b> <b>decoder</b> {{converts}} from binary or {{gray code}} to one-hot representation.A priority encoder converts from one-hot representation to binary or gray code.|$|E
50|$|In SDM a word {{could be}} stored in memory by writing it in a free storage {{location}} {{and at the same}} time providing the location with the appropriate <b>address</b> <b>decoder.</b> A neuron as an <b>address</b> <b>decoder</b> would select a location based on similarity of the location's address to the retrieval cue. Unlike conventional Turing machines SDM is taking advantage of parallel computing by the address decoders. The mere accessing the memory is regarded as computing, the amount of which increases with memory size.|$|E
5000|$|Digital control {{supplies}} {{constant power}} to the track with the power being switched many times a second to provide the [...] "bits" [...] of data (0 and 1) necessary for control (such digital power is neither DC nor AC). Every locomotive must be fitted with a decoder circuit which will interpret instructions and individually control the motor. Each decoder has its own address, instructions sent from the controller have a corresponding address so that while every active decoder will receive the instructions only the <b>addressed</b> <b>decoder</b> will respond. Once a locomotive is running it will continue and so even with one controller several trains can be running.|$|R
5000|$|... 66031 DELTA <b>decoder,</b> <b>address</b> {{change by}} DIP switch with 4 addresses. 28 speed steps, 1 {{switched}} function.|$|R
50|$|However, {{even if we}} limit ASO {{within a}} picture, the decoder {{complexity}} is significantly increased. Because Flexible Macroblock Order FMO extend the concept of slices by allowing non-consecutive macroblocks {{to belong to the}} same slice, this section also <b>addresses</b> the <b>decoder</b> complexity introduced by (FMO).|$|R
5000|$|U1 = M50734-SP10 Mitsubishi Microprocessor U2 = 74HC373P {{address latch}} U3 = CD4060BCN 14-bit {{asynchronous}} binary counter U4 = 74HC139N <b>Address</b> <b>decoder</b> U5 = Static RAM (130 kB) U6 = 27C256BQ EPROM U7 = Static RAM (32 kB) ...|$|E
50|$|On IBM XT computers, it was {{possible}} to add more memory to the motherboard and use a custom <b>address</b> <b>decoder</b> PROM to make it appear in the upper memory area http://www.textfiles.com/computers/pc869kb.txt. As with the 386-based upper memory described above, the extra RAM could be used to load TSR files, or as a RAM disk.|$|E
50|$|One {{technique}} used on early IBM XT computers was to install additional RAM into the video memory address range {{and push the}} limit up {{to the start of}} the Monochrome Display Adapter (MDA). Sometimes software or a custom <b>address</b> <b>decoder</b> was required for this to work. This moved the barrier to 704 KB (with MDA/HGC) or 736 KB (with CGA).|$|E
5000|$|... 6603 Original DELTA <b>decoder,</b> <b>address</b> {{change by}} solder pad, later by DIP switch, with 4 addresses. 14 speed steps, no {{switched}} function.|$|R
5000|$|... 66032 DELTA <b>decoder,</b> <b>address</b> {{change by}} DIP switch with 80 {{addresses}} and automatic mode detection (digital / analog). 28 speed steps, 1 switched function.|$|R
40|$|The Synergistic Processing Element (SPE) is a {{processor}} designed to accelerate media and streaming workloads [1]. The Local Store (LS) {{unit in the}} SPE is a local memory comprised of several macros performing: (1) load/stores, (2) transactions for DMA, and (3) instruction fetches into an instruction line buffer (ILB). Because the LS occupies one-third of the SPE floorplan, area, power and yield {{are as important as}} performance. The LS consists of a sum <b>addressed</b> <b>decoder</b> (memdec), four 64 kB memory arrays (mem 64 k), write accumulation buffers (wacc and wtb), and read accumulation buffers (rdb 1, rdb 2, and rdb 41), distributed throughout the SPE (Fig. 26. 7. 1). It takes four cycles to complete a write and six cycles to perform a read. The 6 -cycle read path is shown in Fig. 26. 7. 1. The numbered latch points in the pipeline diagram also appear in the physical image to indicate the latch locations. A memory access starts by settin...|$|R
50|$|With 100-bit words 2100 {{locations}} {{would be}} needed, i.e. an enormously large memory. However if we construct the memory as we store {{the words of}} the dataset we need only one location (and one <b>address</b> <b>decoder)</b> for each word of the data set. None of the unoccupied locations need to be present. This represents the aspect of sparseness in SDM.|$|E
5000|$|The ZX8301 is an Uncommitted Logic Array (ULA) {{integrated}} circuit {{designed for the}} Sinclair QL microcomputer. Also known as the [...] "Master Chip", it provides a Video Display Generator, the division of a 15 MHz crystal to provide the 7.5 MHz system clock, ZX8302 register <b>address</b> <b>decoder,</b> DRAM refresh and bus controller. The ZX8301 is IC22 on the QL motherboard.|$|E
50|$|Inside the {{coprocessor}} unit {{a proprietary}} chip (the Tube ULA, manufactured initially by Ferranti) interfaced and logically isolated the host and coprocessor buses. This allowed the Tube {{to work with}} a completely different bus architecture in the coprocessor unit. The only other active components needed were a microprocessor, some RAM, a small ROM containing processor specific client code, glue logic such as an <b>address</b> <b>decoder</b> and a power supply.|$|E
40|$|Many {{machine vision}} {{applications}} require predictions for every pixel of the input image (for example semantic segmentation, boundary detection). Models for such problems usually consist of encoders which decreases spatial resolution while learning a high-dimensional representation, followed by decoders who recover the original input resolution {{and result in}} low-dimensional predictions. While encoders have been studied rigorously, relatively few studies <b>address</b> the <b>decoder</b> side. Therefore this paper presents an extensive comparison {{of a variety of}} decoders for a variety of pixel-wise prediction tasks. Our contributions are: (1) Decoders matter: we observe significant variance in results between different types of decoders on various problems. (2) We introduce a novel decoder: bilinear additive upsampling. (3) We introduce new residual-like connections for decoders. (4) We identify two decoder types which give a consistently high performance...|$|R
40|$|A {{low power}} high speed 32 Bit ROM circuit {{implemented}} on 0. 18 µm CMOS {{process has been}} presented in this paper. The circuit is build using a parallel ROM core structure and runs on 1. 8 V supply voltage. A novel <b>Address</b> Transition <b>Decoder</b> (ATD) circuit is proposed which energizes the ROM components such as Row Decoder, Column Decoder, ROM core etc, for short time intervals {{when there is a}} transition in input address bits. The power consumed in ROM with proposed ATD circuit is 0. 78 mW, which corresponds to 82. 27 % reduction in power as compared to ROM without ATD circuit (4. 46 mW). At the output almost full signal swing has been achieved without using any sense amplifier. The implemented ROM has a very low latency of 0. 56 ns. </p...|$|R
40|$|This is a {{tutorial}} paper {{meant to}} introduce the reader to the new concept of turbo codes. This is a new and very powerful error correction technique which outperforms all previous known coding schemes. It {{can be used in}} any communication system where a significant power saving is required or the operating signal [...] to [...] noise ratio (SNR) is very low. Deep space communications, mobile satellite/cellular communications, microwave links, paging, etc., are some of the possible applications of this revolutionary coding technique. Part I of the paper discussed the history of turbo codes, why they are different from traditional convolutional/block codes, the turbo encoder structures and issues related to the interleaver design. Part II <b>addresses</b> the <b>decoder</b> architecture, the achievable performance for turbo codes {{for a wide range of}} coding rates and modulation techniques and discusses delay and implementation issues. 2 1 Introduction The optimum decoding of turbo codes is the maximum likeli [...] ...|$|R
5000|$|In {{order to}} reduce the amount of time {{consumed}} by these steps, most modern CPUs use a technique known as instruction pipelining in which the instructions pass through several sub-units in turn. The first sub-unit reads the address and decodes it, the next [...] "fetches" [...] the values at those addresses, and the next does the math itself. With pipelining the [...] "trick" [...] is to start decoding the next instruction even before the first has left the CPU, in the fashion of an assembly line, so the <b>address</b> <b>decoder</b> is constantly in use. Any particular instruction takes the same amount of time to complete, a time known as the latency, but the CPU can process an entire batch of operations much faster and more efficiently than if it did so one at a time.|$|E
5000|$|Consider {{a memory}} with N {{locations}} where [...] Let each location {{have the capacity}} for one n-bit word (e.g. N= 2100 100-bit words), and let the address decoding be done by N <b>address</b> <b>decoder</b> neurons. Set the threshold of each neuron x to its maximum weighted sum [...] and use a common parameter d to adjust all thresholds when accessing the memory. The effective threshold of neuron x will be then [...] {{which means that the}} location x is accessible every time the address x is within d bits of the address presented to memory (i.e. the address held by the address register).With [...] we have a conventional random-access memory. Assume further that each location has a special location-occupied bit that can be accessed {{in the same way as}} the regular datum bits. Writing a word to a location sets this location-occupied bit. Assume that only occupied location can be read.|$|E
50|$|Even in {{very simple}} systems, {{at various times}} the data bus {{is driven by the}} program memory, by RAM, and by I/O devices.To prevent bus {{contention}} on the data bus, at any one instant only one device drives the data bus.In very simple systems, only the data bus is required to be a bidirectional bus.In very simple systems, the memory address register always drives the address bus, the control unit always drives the control bus,and an <b>address</b> <b>decoder</b> selects which particular device is allowed to drive the data bus during this bus cycle.In very simple systems, every instruction cycle starts with a READ memory cycle where program memory drives the instruction onto the data bus while the instruction register latches that instruction from the data bus.Some instructions continue with a WRITE memory cycle where the memory data register drives data onto the data bus into the chosen RAM or I/O device.Other instructions continue with another READ memory cycle where the chosen RAM, program memory, or I/O device drives data onto the data bus while the memory data register latches that data from the data bus.|$|E
40|$|Nanoscale {{crossbars}} {{built from}} nanowires can form high density memories and programmable logic devices. To integrate such nanoscale devices with other circuits, nanowire decoders are needed. Due to the stochastic {{output of the}} nanoscale fabrication, the <b>decoder</b> <b>addresses</b> to select the nanowires must be generated after fabrication. In this paper, we develop a mathematical model of the nanowire decoders for the generation of the proper addresses. Assuming a simple testing approach called on-off measurement, we prove that {{the maximum number of}} the proper addresses can be generated in finite time. We design the algorithms to generate a required number of the proper addresses. Experimental results confirm the efficiency of our algorithms...|$|R
5000|$|Other {{successful}} hacks involved sampling the datastream {{between the}} card and the decoder, for example you could record a movie and store the decoder information so that people could then use it to decode the same movie that they recorded earlier with a decoder and [...] "dummy" [...] card (the dummy smartcard was an interface that received the synchronised decryption seeds from a computer). The attack {{was known as the}} Delayed Data Transfer hack and it worked because the conditional access data, <b>decoder</b> <b>addressing</b> and encrypted keys, were on the video lines that are recorded by normal VCRs and the data rate, unlike that of Teletext, was slow enough to allow the data to be recorded with the encrypted video.|$|R
30|$|The content {{stored in}} the {{non-volatile}} memory is used for generating actual addresses which point to soft messages {{stored in the}} volatile memory (RAM). An actual address can easily be determined by adding an offset address to the base <b>address.</b> A <b>decoder</b> retrieves a soft message by accessing the RAM via an actual memory address. The number of addresses required to retrieve all the content of message RAM equals {{to the number of}} 1 -components in the H-matrix. Each 1 -component in H represents a RAM address. All the RAM addresses needed for the decoder to obtain the soft messages are stored in the non-volatile memory. Without optimization, the size of this non-volatile memory is equal to Z × U bits, where Z is the address width (Z ≧ log 2 N) [5], and U is the total number of 1 -components in an H-matrix with code length N. In QC-LDPC block codes, the non-volatile memory for recording the RAM addresses can be replaced by a reduced 2 -D Y-matrix, in which only shift values are stored. With the content of Y and an AGU [5], the original memory space can effectively be reduced. This section shows how an H-matrix of a QC-LDPC code can be compactly stored and how actual addresses can be determined by an AGU.|$|R
40|$|Multimedia {{applications}} {{are characterized by}} {{a large number of}} data accesses and complex array index manipulations. The built-in <b>address</b> <b>decoder</b> in the RAM memory model commonly used by most memory synthesis tools, unnecessarily restricts the freedom of address generator synthesis. Therefore a memory model in which the <b>address</b> <b>decoder</b> is decoupled from the memory cell array is proposed. In order to demonstrate the benefits and limitations of this alternative memory model, synthesis results for a Shift Register based Address Generator that does not require address decoding are compared to those for a counter-based address generator that requires address decoding. Results show that delay can be nearly halved at the expense of increased area...|$|E
40|$|<b>Address</b> <b>decoder</b> {{and sense}} {{amplifier}} is {{important component of}} SRAM memory. Selection of storage cell and read operation is depends on decoder and sense amplifier respectively. Hence, performance of SRAM is depends on these components. This work survey the <b>address</b> <b>decoder</b> and sense amplifier for SRAM memory, concentrating on delay optimization and power efficient circuit techniques. We have concentrated on optimal decoder structure with least number of transistors to reduce area of SRAM In static decoders we have stared with simple AND gate decoder and its result is examined. These simple decoder are neither area efficient nor faster one because AND/OR gate are not natural gates, they are made up from combination of NAND/NOR and NOT gate. Decoder having only NOR/NAND gate are area efficient and fast too. Therefore universal decoding having NAND-NOR alternate stages scheme is taken and examined. Universal decoding scheme are having some serious issue like different path delay which may results in false decoding as well as extra power dissipation. To overcome from this issue Novel Address decoding scheme is implemented and their result is compared with simple AND decoder and Universal decoder. Novel <b>address</b> <b>decoder</b> circuit is presented and analyzed. Novel <b>address</b> <b>decoder</b> using NAND-NOR alternate stages with pre-decoder and replica inverter chain circuit is implemented successfully. Current mirror sense-amp and latched type sense amplifier is also implemented for SRAM. These two amplifiers are the basic one and having tremendous advantage due to their small size. They are fast enough and can be fit below the SRAM cell. We have implemented and tested 1 Kb; 8 bit; 1. 25 GHz SRAM memory in Cadence by using UMC 90 nm technology, for that decoder and sense amplifier is deployed...|$|E
40|$|Abstract—We have {{developed}} a high-speed pipelined super-conductor look-up table to generate programmable predistortion functions for direct linearization of radio frequency (RF) power amplifiers. The look-up table comprises an <b>address</b> <b>decoder</b> and a memory matrix with throughput above 10 GHz. The decoder per-forms code-matching of each input word and its conversion into a row address of the memory matrix. We discuss different possible implementations of the <b>address</b> <b>decoder,</b> including a preferred one for integrated circuit implementation. The memory matrix consists of RS flip-flops with nondestructive readout connected in series for slow-speed contents writing. Each row of the memory matrix contains a number, which can be read out by signal from the decoder. We present the design {{and the results of}} experimental evaluation of the look-up table and its components. Index Terms—Decoder, memory matrix, predistortion, RSFQ. I...|$|E
40|$|Endowing a chatbot with {{personality}} or {{an identity}} is quite challenging but critical to deliver more realistic and natural conversations. In this paper, we {{address the issue}} of generating responses that are coherent to a pre-specified agent profile. We design a model consisting of three modules: a profile detector to decide whether a post should be responded using the profile and which key should be <b>addressed,</b> a bidirectional <b>decoder</b> to generate responses forward and backward starting from a selected profile value, and a position detector that predicts a word position from which decoding should start given a selected profile value. We show that general conversation data from social media can be used to generate profile-coherent responses. Manual and automatic evaluation shows that our model can deliver more coherent, natural, and diversified responses. Comment: an error on author informatio...|$|R
40|$|This paper {{propose a}} decoder {{architecture}} for low-density parity-check convolutional code (LDPCCC). Specifically, the LDPCCC {{is derived from}} a quasi-cyclic (QC) LDPC block code. By making use of the quasi-cyclic structure, the proposed LDPCCC decoder adopts a dynamic message storage in the memory and uses a simple <b>address</b> controller. The <b>decoder</b> efficiently combines the memories in the pipelining processors into a large memory block so as {{to take advantage of}} the data-width of the embedded memory in a modern field-programmable gate array (FPGA). A rate- 5 / 6 QC-LDPCCC has been implemented on an Altera Stratix FPGA. It achieves up to 2. 0 Gb/s throughput with a clock frequency of 100 MHz. Moreover, the decoder displays an excellent error performance of lower than $ 10 ^{- 13 }$ at a bit-energy-to-noise-power-spectral-density ratio ($E_b/N_ 0 $) of 3. 55 dB. Comment: accepted to IEEE Transactions on Circuits and Systems...|$|R
50|$|The {{original}} 6020 Central Unit provided track power & generated locomotive commands but {{required a}} separate 6035 locomotive Control 80 with speed controller, keypad for <b>decoder</b> <b>address,</b> Function / Off buttons, and Start / Stop buttons to switch track power. The red Stop button was provided {{as an emergency}} stop to immediately halt all trains. A two digit display showed the selected locomotive address (01 - 80). Solenoid devices, such as turnouts, were controlled by the 6040 Keyboard. Up to ten controllers could {{be added to the}} right hand side of the Central Unit, and up to 16 keyboards could be added to the left hand side, with each keyboard controlling 16 accessories (signals, turnouts, lights, etc.) for a total of 256. For large layouts 6016 Boosters and their own power supplies would provide additional power to additional layout sections with all Boosters linked to the Central Unit by a ribbon cable.|$|R
