358|1623|Public
5000|$|VCM (Variable Coding and Modulation) and ACM (<b>Adaptive</b> <b>Coding</b> and Modulation) modes, {{which allow}} {{optimizing}} bandwidth utilization by dynamically changing transmission parameters.|$|E
5000|$|Modulated {{carriers}} can be dynamically {{altered in}} response to rain problems or other link impairments using a process called <b>adaptive</b> <b>coding</b> and modulation, or [...] "ACM". ACM allows the bit rates to be increased substantially during normal clear sky conditions, {{increasing the number of}} bits per Hz transmitted, and thus reducing overall cost per bit. <b>Adaptive</b> <b>coding</b> requires some sort of a return or feedback channel which can be via any available means, satellite or terrestrial.|$|E
50|$|Any <b>adaptive</b> <b>coding</b> {{method has}} a {{corresponding}} static model method, {{in which the}} data model is precalculated and then transmitted with the data.|$|E
40|$|We {{introduce}} {{a new class of}} non-standard variable-length <b>codes,</b> called <b>adaptive</b> <b>codes.</b> This class of codes associates a variable-length codeword to the symbol being encoded depending on the previous symbols in the input data string. An efficient algorithm for constructing <b>adaptive</b> <b>codes</b> of order one is presented. Then, we {{introduce a}} natural generalization of <b>adaptive</b> <b>codes,</b> called GA codes. Comment: 10 page...|$|R
40|$|<b>Adaptive</b> (variable-length) <b>codes</b> {{associate}} variable-length codewords to symbols being encoded {{depending on}} the previous symbols in the input data string. This class of codes has been presented in [Dragos Trinca, cs. DS/ 0505007] as {{a new class of}} non-standard variable-length <b>codes.</b> Generalized <b>adaptive</b> <b>codes</b> (GA codes, for short) have been also presented in [Dragos Trinca, cs. DS/ 0505007] not only as a new class of non-standard variable-length codes, but also as a natural generalization of <b>adaptive</b> <b>codes</b> of any order. This paper is intended to continue developing the theory of variable-length codes by establishing several interesting connections between <b>adaptive</b> <b>codes</b> and other classes of codes. The connections are discussed not only from a theoretical point of view (by proving new results), but also from an applicative one (by proposing several applications). First, we prove that adaptive Huffman encodings and Lempel-Ziv encodings are particular cases of encodings by GA codes. Second, we show that any (n, 1,m) convolutional code satisfying certain conditions can be modelled as an <b>adaptive</b> <b>code</b> of order m. Third, we describe a cryptographic scheme based on the connection between <b>adaptive</b> <b>codes</b> and convolutional codes, and present an insightful analysis of this scheme. Finally, we conclude by generalizing <b>adaptive</b> <b>codes</b> to (p,q) -adaptive codes, and discussing connections between <b>adaptive</b> <b>codes</b> and time-varying codes. Comment: 17 page...|$|R
40|$|The general {{problem of}} image data {{compression}} is discussed briefly with {{attention given to}} the use of Karhunen-Loeve transforms, suboptimal systems, and block quantization. A survey is then conducted encompassing the four categories of adaptive systems: (1) <b>adaptive</b> transform <b>coding</b> (<b>adaptive</b> sampling, adaptive quantization, etc.), (2) <b>adaptive</b> predictive <b>coding</b> (<b>adaptive</b> delta modulation, adaptive DPCM encoding, etc.), (3) <b>adaptive</b> cluster <b>coding</b> (blob algorithms and the multispectral cluster coding technique), and (4) <b>adaptive</b> entropy <b>coding...</b>|$|R
5000|$|<b>Adaptive</b> <b>coding</b> and {{modulation}} (ACM) {{to allow}} flexibly adapting transmission parameters {{to the reception}} conditions of terminals, e.g., switching to a lower code rate during fading.|$|E
50|$|Ultra-high {{capacity}} Microwave Backhaul Systems {{also use}} 1024-QAM. With 1024-QAM, <b>Adaptive</b> <b>Coding</b> and Modulation (ACM), and XPIC, Vendors can obtain Gigabit capacity {{in a single}} 56 MHz channel.|$|E
50|$|Forscene {{has its own}} codecs {{for both}} video and audio. These use a form of <b>adaptive</b> <b>coding</b> to allow local {{variations}} {{in the type of}} data to be encoded efficiently.|$|E
40|$|Abstract — This paper {{surveys the}} various {{combining}} schemes along with <b>adaptive</b> <b>coded</b> modulation {{with respect to}} fading in wireless environment. <b>Adaptive</b> <b>coded</b> modulation increases the energy efficiency and data rate and this modulation scheme along with combining provides high spectral and power efficiency. Antenna diversity systems can increase the reliability of wireless fading channels by {{improving the quality of}} received signal through diversity combining. Adaptive modulation with combining will make higher-order transmission mode feasible under the same required BER and enhances spectral efficiency...|$|R
40|$|A {{number of}} {{adaptive}} data compression techniques are considered {{for reducing the}} bandwidth of multispectral data. They include <b>adaptive</b> transform <b>coding,</b> <b>adaptive</b> DPCM, <b>adaptive</b> cluster <b>coding,</b> and a hybrid method. The techniques are simulated and their performance in compressing the bandwidth of Landsat multispectral images is evaluated and compared using signal-to-noise ratio and classification consistency as fidelity criteria...|$|R
40|$|<b>Adaptive</b> video <b>coding</b> {{algorithms}} are {{digital video}} compression algorithms that can adapt the encoding {{of a video}} stream dynamically based {{on the amount of}} bandwidth available on the network. While such algorithms are more complicated than traditional video coding algorithms, they are attractive because of their inherent robustness to changes in network load (i. e., network congestion). <b>Adaptive</b> video <b>coding</b> algorithms seem particularly suitable for high speed network environments, such as B-ISDN/ATM, that offer Available Bit Rate (ABR) services. The goal {{of this paper is to}} assess the role that <b>adaptive</b> video <b>coding</b> algorithms will play in future high speed networks. The paper presents a simple mathematical model and analysis of several hypothetical video coding algorithms for high speed networks, and a simulation study of one such <b>adaptive</b> video <b>coding</b> algorithm that we have implemented in a local area network environment. The results show that <b>adaptive</b> video <b>coding</b> algorithms are indeed robust across a wide range of network loads. More importantly, however, the results suggest that the domain of <b>adaptive</b> video <b>coding</b> algorithms is quite narrow: moderately to heavily loaded networks with speeds on the order of 10 Mbps and 100 Mbps. As a result, <b>adaptive</b> video <b>coding</b> algorithms will likely play only a limited role in future high speed networks. ...|$|R
50|$|In data compression, <b>adaptive</b> <b>coding</b> {{algorithms}} such as Adaptive Huffman coding or Prediction by {{partial matching}} {{can take a}} stream of data as input, and adapt their compression technique based on the symbols that they have already encountered.|$|E
50|$|Adaptive Huffman coding (also called Dynamic Huffman coding) is an <b>adaptive</b> <b>coding</b> {{technique}} {{based on}} Huffman coding. It permits building the code as the symbols are being transmitted, having no initial knowledge of source distribution, that allows one-pass encoding and adaptation to changing conditions in data.|$|E
50|$|<b>Adaptive</b> <b>Coding</b> and Modulation gathers fading {{conditions}} {{from each}} terminal and adapts signal encoding and modulation to each individual terminal's receiving condition. This allows efficient transmission to each terminal, without degenerating {{the efficiency of}} the whole network. A return channel on the end-user terminal is needed to send the condition changes.|$|E
40|$|Abstract. <b>Adaptive</b> <b>codes</b> {{associate}} variable-length codewords to symbols being encoded {{depending on}} the previous symbols in the input data string. This class of codes has been introduced in [9] as {{a new class of}} non-standard variable-length codes. New algorithms for data compression, based on <b>adaptive</b> <b>codes</b> of order one, have been presented in [10], where we have behaviorally shown that for a large class of input data strings, these algorithms substantially outperform the Lempel-Ziv universal data compression algorithm [18]. EAH has been introduced in [11], as an improved generalization of these algorithms. In this paper, we present a translation of the EAH algorithm into the graph theory...|$|R
40|$|<b>Adaptive</b> <b>codes</b> {{associate}} variable-length codewords to symbols being encoded {{depending on}} the previous symbols in the input data string. This class of codes has been introduced in [Dragos Trinca, cs. DS/ 0505007] as {{a new class of}} non-standard variable-length codes. New algorithms for data compression, based on <b>adaptive</b> <b>codes</b> of order one, have been presented in [Dragos Trinca, ITCC- 2004], where we have behaviorally shown that for a large class of input data strings, these algorithms substantially outperform the Lempel-Ziv universal data compression algorithm. EAH has been introduced in [Dragos Trinca, cs. DS/ 0505061], as an improved generalization of these algorithms. In this paper, we present a translation of the EAH algorithm into the graph theory. Comment: 10 page...|$|R
40|$|Abstract. In this paper, {{the context}} {{quantization}} for I-ary sources {{based on the}} affinity propagation algorithm is presented. In purpose of finding the optimal number of classes, the increment of the <b>adaptive</b> <b>code</b> length is suggested to be the similarity measure between two conditional probability distributions, by which the similarity matrix is constructed as the input of the affinity propagation algorithm. After the given number of iterations, the optimal quantizer with the optimal number of classes is achieved and the <b>adaptive</b> <b>code</b> length is minimized at the same time. The simulations indicate that the proposed algorithm produces results that are better than the results obtained by the minimum conditional entropy context quantization implemented by K-means with lower computational complexity...|$|R
50|$|<b>Adaptive</b> <b>coding</b> {{refers to}} {{variants}} of entropy encoding methods of lossless data compression. They are particularly suited to streaming data, as they adapt to localized {{changes in the}} characteristics of the data, and don't require a first pass over the data to calculate a probability model. The cost paid for these advantages is that the encoder and decoder must be more complex to keep their states synchronized, and more computational power is needed to keep adapting the encoder/decoder state.|$|E
50|$|In <b>adaptive</b> <b>coding,</b> the encoder and decoder are instead {{equipped}} with a predefined meta-model about how they will alter their models {{in response to the}} actual content of the data, and otherwise start with a blank slate, meaning that no initial model needs to be transmitted. As the data is transmitted, both encoder and decoder adapt their models, so that unless the character of the data changes radically, the model becomes better-adapted to the data it is handling and compresses it more efficiently approaching the efficiency of the static coding.|$|E
5000|$|Rice coding (invented by Robert F. Rice) denotes using {{a subset}} of the family of Golomb codes to produce a simpler (but {{possibly}} suboptimal) prefix code. Rice used this set of codes in an <b>adaptive</b> <b>coding</b> scheme; [...] "Rice coding" [...] can refer either to that adaptive scheme or to using that subset of Golomb codes. Whereas a Golomb code has a tunable parameter that can be any positive integer value, Rice codes are those in which the tunable parameter is a power of two. This makes Rice codes convenient for use on a computer since multiplication and division by 2 can be implemented more efficiently in binary arithmetic.|$|E
40|$|Abstract. The context {{quantization}} for aryI − source {{based on}} the modified K-means clustering algorithm is present in this paper. In this algorithm, the adaptive complementary relative entropy between two conditional probability distributions, which is used as the distance measure for K-means instead, is formulated to describe the similarity of these two probability distributions. The rules of the initialized centers chosen for K-means are also discussed. The proposed algorithm will traverse all possible number of the classes to search the optimal one which is corresponding to the shortest <b>adaptive</b> <b>code</b> length. Then the optimal context quantizer is achieved rapidly and the <b>adaptive</b> <b>code</b> length is minimized at the same time. Simulations indicate that the proposed algorithm produces better coding result than the result of other algorithm...|$|R
30|$|Another {{area for}} further {{work is to}} {{consider}} ways for suppressing redundant information delivery to further improve bandwidth efficiency. There is also an increasing interest in allowing the sources to adjust their coding rates to match the network conditions and peer capabilities (e.g. multi-rate and <b>adaptive</b> <b>coded</b> video sources) [42, 83]. The idea is also applicable to RRG.|$|R
40|$|A new {{progressive}} image transmission technique using <b>adaptive</b> block truncation <b>coding</b> is introduced in this paper. The <b>adaptive</b> block truncation <b>coding</b> was proposed as a non-transform coding mode for edge blocks in digital video sequences. By adapting more sophisticated just-noticeable-difference {{model of the}} human visual system, we can get an improved <b>adaptive</b> block truncation <b>coding</b> than the original work. With this improvement, we propose a progressive transport format of the <b>adaptive</b> block truncation <b>coding</b> {{so that we can}} reconstruct images in 3 -pass coarse-to-fine manner. Simulation results on the <b>adaptive</b> block truncation <b>coding</b> is compared with those of JPEG and GIF. Through the transmission test via a World Wide Web browser, we can confirm the proposed transport format reduces bandwidth usage. Keywords : progressive transmission, transport format, <b>adaptive</b> block truncation <b>coding,</b> just noticeable difference 1. Introduction The Internet has been acknowledged as an international [...] ...|$|R
50|$|A {{generalization}} of Thompson sampling to arbitrary dynamical environments and causal structures, known as Bayesian control rule, {{has been shown}} to be the optimal solution to the <b>adaptive</b> <b>coding</b> problem with actions and observations. In this formulation, an agent is conceptualized as a mixture over a set of behaviours. As the agent interacts with its environment, it learns the causal properties and adopts the behaviour that minimizes the relative entropy to the behaviour with the best prediction of the environment's behaviour. If these behaviours have been chosen according to the maximum expected utility principle, then the asymptotic behaviour of the Bayesian control rule matches the asymptotic behaviour of the perfectly rational agent.|$|E
50|$|Link adaptation, or <b>adaptive</b> <b>coding</b> and {{modulation}} (ACM), is a {{term used}} in wireless communications to denote the matching of the modulation, coding and other signal and protocol parameters to the conditions on the radio link (e.g. the pathloss, the interference due to signals coming from other transmitters, {{the sensitivity of the}} receiver, the available transmitter power margin, etc.). For example, WiMAX uses a rate adaptation algorithm that adapts the modulation and coding scheme (MCS) according {{to the quality of the}} radio channel, and thus the bit rate and robustness of data transmission. The process of link adaptation is a dynamic one and the signal and protocol parameters change as the radio link conditions change—for example in High-Speed Downlink Packet Access (HSDPA) in Universal Mobile Telecommunications System (UMTS) this can take place every 2 ms.|$|E
40|$|An <b>adaptive</b> <b>coding</b> {{scheme is}} {{introduced}} for a discrete sequence code-division multiple-access system. The system uses noncoherent M-ary orthogonal modulation with RAKE receiver and power control. Both a fast fading channel and a combined fast fading, shadowing and power control channel are considered. Analytical bounds and simulations are done {{to evaluate the}} performance of the system. It is found that there are significant improvement in the average throughput and the bit-error-rate performance in the <b>adaptive</b> <b>coding</b> scheme. The amount of improvement drops with the increase of diversity branches used. More importantly, it is found that <b>adaptive</b> <b>coding</b> scheme is relatively robust to shadowing, while fix-rate codes are ineffective in the shadowing environment. Finally, <b>adaptive</b> <b>coding</b> scheme is found to be robust to mobile speed, feedback delay, and finite interleaving depth...|$|E
40|$|Video coding {{algorithms}} {{are important}} for the proliferation of multimedia applications (i. e., those that incorporate video, voice and data) in high speed networks. Video coding algorithms reduce the bandwidth required for video images while maintaining good picture quality. Of particular interest are <b>adaptive</b> video <b>coding</b> algorithms, which can adapt the encoding of a video stream (and thus its bandwidth requirements) dynamically based {{on the amount of}} bandwidth available in the network. Such applications can make efficient use of the available bit rate (ABR) service class proposed for B-ISDN. The goal of this research was to evaluate <b>adaptive</b> video <b>coding</b> algorithms. Therefore there were three main objectives in this research. The first objective was to determine the robustness of <b>adaptive</b> video <b>coding</b> algorithms to changes in network load. The second objective was to identify the domain (network types and load characteristics) in which <b>adaptive</b> video <b>coding</b> algorithms are feasible. T [...] ...|$|R
40|$|In this paper, {{a simple}} {{lossless}} image compression method {{based on a}} combination between bit-plane slicing and <b>adaptive</b> predictive <b>coding</b> is adopted for compressing natural and medical images. The idea basically utilized the spatial domain efficiently after discarding the lowest order bits namely, exploiting only the highest order bits in which the most significant bit corresponds to last layer 7 used <b>adaptive</b> predictive <b>coding,</b> while the other layers used run length coding. The test results leads to high system performance in which higher compression ratio achieves for lossless system that characterized by guaranty fully reconstruction. General Terms Bit-plane slicing along with <b>adaptive</b> predictive <b>coding</b> for lossless image compression...|$|R
40|$|<b>Adaptive</b> Luminance <b>Coding)</b> ????? ??? ??? ???? ??? ?? ?? ?? ??? ????? ????? ????? ??. ??? ???? ????? ?? ??? ???? ?????? ???? ??? ???? ?? ???? ? ????? ??? ?? ?? ???? ?? ?? ??? ???? ?? ??? ???? ??? ????? ??. ????? ?? ???? ??? ?? ???? ?? Precision ? Recall? ??? ?? ??? ? ??. ? ??? ??????? ? ??????????? ?? ICT ???? ??????? ????? ????? (IITP- 2015 –H 8501 - 15 - 1005...|$|R
40|$|Our {{ability to}} {{discriminate}} and recognize thousands of faces despite their similarity as visual patterns relies on adaptive, norm-based, coding mechanisms that are continuously updated by experience. Reduced <b>adaptive</b> <b>coding</b> of face identity {{has been proposed}} as a neurocognitive endophenotype for autism, because it is found in autism and in relatives of individuals with autism. Autistic traits can also extend continuously into the general population, raising the possibility that reduced <b>adaptive</b> <b>coding</b> of face identity may be more generally associated with autistic traits. In the present study, we investigated whether <b>adaptive</b> <b>coding</b> of face identity decreases as autistic traits increase in an undergraduate population. <b>Adaptive</b> <b>coding</b> was measured using face identity aftereffects, and autistic traits were measured using the Autism-Spectrum Quotient (AQ) and its subscales. We also measured face and car recognition ability to determine whether autistic traits are selectively related to face recognition difficulties. We found that men who scored higher on levels of autistic traits related to social interaction had reduced <b>adaptive</b> <b>coding</b> of face identity. This result {{is consistent with the}} idea that atypical adaptive face-coding mechanisms are an endophenotype for autism. Autistic traits were also linked with face-selective recognition difficulties in men. However, there were some unexpected sex differences. In women, autistic traits were linked positively, rather than negatively, with <b>adaptive</b> <b>coding</b> of identity, and were unrelated to face-selective recognition difficulties. These sex differences indicate that autistic traits can have different neurocognitive correlates in men and women and raise the intriguing possibility that endophenotypes of autism can differ in males and females...|$|E
40|$|To {{efficiently}} {{represent all}} of the possible rewards in the world, dopaminergic midbrain neurons dynamically adapt their coding range to the momentarily available rewards. Specifically, these neurons increase their activity for an outcome that is better than expected and decrease it for an outcome worse than expected, independent of the absolute reward magnitude. Although this <b>adaptive</b> <b>coding</b> is well documented, it remains unknown how this rescaling is implemented. To investigate the <b>adaptive</b> <b>coding</b> of prediction errors and its underlying rescaling process, we used human {{functional magnetic resonance imaging}} (fMRI) in combination with a reward prediction task that involved different reward magnitudes. We demonstrate that reward prediction errors in the human striatum are expressed according to an <b>adaptive</b> <b>coding</b> scheme. Strikingly, we show that <b>adaptive</b> <b>coding</b> is gated by changes in effective connectivity between the striatum and other reward-sensitive regions, namely the midbrain and the medial prefrontal cortex. Our results provide evidence that striatal prediction errors are normalized by a magnitude-dependent alteration in the interregional connectivity within the brain's reward system...|$|E
40|$|Abstract—Recently, analog Joint Source-Channel Coding (JSCC) {{has been}} shown to {{approach}} the optimal distortion-cost trade-off when transmitting over AWGN channels. In this work we consider analog JSCC over frequency-selective channels using Orthogonal Frequency Division Multiplexing (OFDM) modula-tion. Due to its high complexity, optimal MMSE analog JSCC decoding is infeasible in OFDM, hence a practical two-stage decoding approach made up of a MMSE estimator followed by a Maximum Likelihood (ML) decoder is proposed. Three different alternatives for system optimization are considered: non-adaptive coding, <b>adaptive</b> <b>coding,</b> and <b>adaptive</b> <b>coding</b> with precoding. We show that the three analog JSCC transmission strategies approach the optimal distortion-cost trade-off although much better performance is obtained with the <b>adaptive</b> <b>coding</b> with precoding method, specially in Multiple Input Multiple Output (MIMO) OFDM systems. I...|$|E
50|$|A {{variation}} called <b>adaptive</b> Huffman <b>coding</b> involves {{calculating the}} probabilities dynamically based on recent actual frequencies {{in the sequence}} of source symbols, and changing the coding tree structure to match the updated probability estimates. It is used rarely in practice, since the cost of updating the tree makes it slower than optimized <b>adaptive</b> arithmetic <b>coding,</b> which is more flexible and has better compression.|$|R
40|$|This paper {{summarizes}} a {{study on}} two-dimensional linear prediction of images and its application to <b>adaptive</b> predictive <b>coding</b> of monochrome images. The study was focused on three major areas: two-dimensional linear prediction of images and its performance, implementation of an adaptive predictor and adaptive quantizer for use in image coding, and linear prediction and <b>adaptive</b> predictive <b>coding</b> of density (logarith...|$|R
50|$|Repetition {{codes are}} one of the few known codes whose code rate can be {{automatically}} adjusted to varying channel capacity, by sending more or less parity information as required to overcome the channel noise, and it is the only such code known for non-erasure channels. Practical <b>adaptive</b> <b>codes</b> for erasure channels have been invented only recently, and are known as fountain codes.|$|R
