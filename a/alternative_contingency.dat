8|33|Public
50|$|Increased {{accessibility}} to regulator first-stages and cylinder valves improves {{efficiency and speed}} of critical cylinder shut-down procedures, allows immediate gas-loss identification and provides the diver with quick access to <b>alternative</b> <b>contingency</b> procedures, such as swapping regulators between cylinders, manual operation of a cylinder valve to control gas flow through a regulator which is free-flowing, or to allow breathing directly from the tank valve.|$|E
40|$|Launching new {{products}} {{is an exciting}} and daunting task. As new product success rate is only 60 % to 70 % across industries, to avoid possible losses and trauma of failure, one needs to take care to do thorough homework on operations and <b>alternative</b> <b>contingency</b> plans. More importantly the antecedents and predictors of new product success need to be identified and incorporated in the new product ideation-concept development-testing-screening-business analysis-physi-cal product development and test - launch process. Twenty four factors that are drivers of new product success have been identified from past studies. These drivers of new product success are classified under product characteristics, process characteristics, stra-tegy characteristics and market place characteristics. ...|$|E
40|$|A {{series of}} preflight, inflight, and postflight {{vestibular}} experiments {{were conducted on}} Spacelab missions SL- 1 and D- 1. Two portions of the investigation, the 'sled' and 'dome' functional objectives, involved recording the torsional motion of human subject's eyes. In the SL- 1 sled and dome experiments, preflight and postflight ocular torsion was recorded on 35 mm film using a Nikon motor driven camera (2. 6 frames/sec). The film was to be analyzed by measuring the motion of contact lens landmarks using a Hermes senior film scanner. However, an inflight failure of the dome experiment camera flash unit led the crew to utilize the Spacelab video camera as an <b>alternative</b> <b>contingency</b> method for imaging the eye in this FO. A suitable method for analysis of the video data was developed. Results of the analysis are presented...|$|E
40|$|The {{purpose of}} this {{experiment}} was to evaluate the effects of <b>alternative</b> <b>contingencies</b> on instruction following by an ABA design. Three college students consistently pressed keys 1 - 5 - 3 and 4 - 8 - 6 {{in the presence of}} the written instruction "Press 153 " or "Press 486. " During condition A, the contingencies for following and not following the instruction were the same: CON FR 5 FR 5 and CON FR 20 FR 20. During condition B, the contingencies for following and not following the instruction were different: CON FR 20 FR 5. For one participant, the schedule of reinforcement was then changed to FR 30. The results showed that subjects followed instructions when the schedule of reinforcement was the same for instruction following and not following...|$|R
40|$|Oren, Phil Overholt, and {{the army}} {{of past and present}} {{students}} who worked on parts of this project over the years for their support and for helpful comments {{during the course of this}} work. All conclusions, recommendations, and remaining errors are the sole responsibility of the authors. 1 Executive Summary The FERC report on reactive power clearly and succinctly lays out the issues and raises important questions about market power, contingent-claim versus real-time markets, the need for an optimal power flow that incorporates reactive power, etc. Unfortunately, the economic/engineering models so far available in the literature fail to represent the true economic optimum. This optimum involves maximization of the expected net benefits of electricity production, transportation, and use under the constraint of a full alternating-current (AC) power flow where the expected net benefit is defined as the sum of the probability-weighted economic outcomes for all contingencies, including line and generator failures. This is the correct way, in terms of economics, to determine optimal reliability, levels of investment, and operation parameters under <b>alternative</b> <b>contingencies,</b> as well as efficient and optimal production an...|$|R
40|$|Statistically {{inclined}} experimental scientists may {{be interested}} in chapters 1 and 9, and in parts of Sections 3. 2, 3. 3, 3. 4, 5. 6, 5. 7, 5. 3 and 6. 4. Chapter 1 is an introduction and summary, using a minimum of mathematical language. Chapter 9 considers several testing problems with restricted <b>alternatives</b> for <b>contingency</b> tables, and gives tests which are asymptotically optimal in the sense of chapters 7 and 8. [...] . Zie: Preface and Summary...|$|R
40|$|Three {{reinforcement}} contingencies {{were compared}} with regard to performance differences and cost-effectiveness (i. e., responses per unit reinforcer). Pairs of college students were studied under individual, cooperative, or competitive contingencies using a concurrent setting that included one of these three contingencies as one alternative and a lower paying individual contingency as the other alternative. With {{the individual and the}} cooperative contingencies, overall response rates were typically high; under competitive contingencies the overall response rates were substantially lower. Subjects responded at very high rates when competing, but chose not to compete most of the time. Competition and cooperation produced the most cost-effective responding, assessed as the number of responses made per $. 01 of reinforcer. High overall rates of competitive responding were obtained when the contests were longer and the lower paying <b>alternative</b> <b>contingency</b> was not available...|$|E
40|$|This paper {{develops}} a service systems model {{which is then}} used to discuss {{a number of important}} implications for service design. We begin by outlining the existing service design literature which is either too abstract or too low level for design. Thus, we develop the requirement for a service systems model which enables the consideration of a number of different âlevelsâ. The main contribution of this paper is the development of the service systems model from data collected in a single case study of a large international Telco. We conclude by considering three implications for service design of developing a systems model. Firstly, we challenge the level or unit of analysis of service systems design research. Secondly, we propose an <b>alternative</b> <b>contingency</b> variable based on the input type and finally we suggest the model may be used within service improvement to identify the appropriate approach to mathematical modeling. Roger Maull, Philip Godsiff, Irene N...|$|E
40|$|Abstract—Robots {{that operate}} in {{hazardous}} and dynamic environments must {{be equipped with}} onboard reasoning capabilities {{that enable them to}} autonomously generate mission plans. To operate in such environments, the mission plans must be continuous and temporally flexible. For critical missions, such as search and rescues, the success of the mission relies not only on the feasibility of the plan, but also {{on the quality of the}} plan. Thus, to generate robust efficient, temporally flexible plans, a measure of utility is required. We introduce a novel, forward heuristic planner that quickly extracts the optimal, temporally flexible plan, given a hierarchical description of <b>alternative</b> <b>contingency</b> plans and a utility function. Contingency plans are encoded as Temporal Plan Networks (TPNs). Our work presents two key innovations. The first is a compact encoding of a TPN search state. The second is an admissible and informative heuristic, TPN-Max. We empirically validate our solution on TPNs with increasing level of difficulty. Our results show that the TPN-Max heuristic performs significantly better, for TPNs, than the Max heuristic used in the forward heuristic planners [1]. I...|$|E
40|$|The {{display of}} the data by means of {{contingency}} tables is used in different approaches to statistical inference, for example, to broach the test of homogeneity of independent multinomial distributions. We develop a Bayesian procedure to test simple null hypotheses versus bilateral <b>alternatives</b> in <b>contingency</b> tables. Given independent samples of two binomial distributions and taking a mixed prior distribution, we calculate the posterior probability {{that the proportion of}} successes in the first population is the same as in the second. This posterior probability is compared with the p-value of the classical method, obtaining a reconciliation between both results, classical and Bayesian. The obtained results are generalized for r × s tables...|$|R
25|$|Following {{a change}} of {{government}} in October 1993, the incoming Liberal Party ordered the immediate cancellation of the order, forcing the payment of C$500 million of cancellation fees. By not purchasing the helicopters and slashing the DND budget, the government aimed to trim the deficit and be more fiscally responsible. As a negative, the Liberal government left itself with little maneuvering room as the Sea King fleet continued to age and its systems become obsolete; a replacement was needed but no <b>alternative</b> or <b>contingency</b> plan had been made. Some commentators observed that cancelling the NSA contract was not a fiscally responsible move. During one debate, Chrétien famously retorted that the President of the United States still flew in a Sea King, thus the helicopter was also good enough for Canada.|$|R
40|$|An r x s {{table is}} used for {{different}} approaches to statistical inference. We develop a Bayesian procedure to test simple null hypotheses versus bilateral <b>alternatives</b> in <b>contingency</b> tables. We consider testing equality of proportions of independent multinomial distributions when the common proportions are known. A lower bound of the posterior probabilities of the null hypothesis is calculated {{with respect to a}} mixture of a point prior on the null and an epsilon-contaminated prior on the proportions under the alternative. The resulting Bayes tests are compared numerically to Pearson's chi(2) in a number of examples. For the examined examples the lower bound and the p-value can be made close. The obtained results are generalized when the common proportions vector under the null is unknown or has a known functional form...|$|R
40|$|The {{purpose of}} this {{dissertation}} {{was to develop a}} conceptual framework which can be used to account for policy decisions made by the House Ways and Means Committee (HW 2 ̆ 6 MC) of the Texas House of Representatives. This analysis will examine the actions of the committee over a ten-year period with the goal of explaining and predicting the success of failure of certain efforts to raise revenue. ^ The basis framework for modelling the revenue decision-making process includes three major components [...] the decision alternatives, the external factors and two competing contingency theories. The decision alternatives encompass the particular options available to increase tax revenue. The options were classified as non-innovative or innovative. The non-innovative options included the sales, franchise, property and severance taxes. The innovative options were principally the personal and corporate income taxes. ^ The external factors included political and economic constraints that affected the actions of the HW 2 ̆ 6 MC. Several key political constraints on committee decision-making were addressed [...] including public attitudes, interest groups, political party strength and tradition and precedents. The economic constraints that affected revenue decisions included court mandates, federal mandates and the fiscal condition of the nation and the state. ^ The third component of the revenue decision-making framework included two <b>alternative</b> <b>contingency</b> theories. The first alternative theory postulated that the committee structure, including the individual member roles and the overall committee style, resulted in distinctive revenue decisions. This theory will be favored if evidence points to the committee acting autonomously with less concern for the policies of the Speaker of the House. The Speaker assignment theory, postulated that the assignment of committee members shaped or changed the course of committee decision-making. This theory will be favored if there was evidence that the committee was strictly a vehicle for the Speaker to institute his preferred tax policies. ^ The ultimate goal of this analysis is to develop an explanation for legislative decision-making about tax policy. This explanation will be based on the linkages across various tax options, political and economic constraints, member roles and committee style and the patterns of committee assignment. ...|$|E
40|$|Roadmapping is a {{powerful}} tool to manage technical risks and opportunities associated with complex problems. Roadmapping identifies technical capabilities required for both project- and program-level efforts and provides the basis for plans that ensure the necessary enabling activities will be done when needed. Roadmapping reveals where to focus further development of the path forward by evaluating uncertainties for levels of complexity, impacts, and/or the potential for large payback. Roadmaps can be customized to the application, a “graded approach” if you will. Some roadmaps are less detailed. We have called these less detailed, top-level roadmaps “mini-roadmaps”. These miniroadmaps are created to tie the needed enablers (e. g., technologies, decisions, etc.) to the functions. If it is found during the mini-roadmapping that areas of significant risk exist, then those can be roadmapped further to {{a lower level of}} detail. Otherwise, the mini-roadmap may be sufficient to manage the project / program risk. Applying a graded approach to the roadmapping can help keep the costs down. Experience has indicated that it is best to do mini-roadmapping first and then evaluate the risky areas to determine whether to further evaluate those areas. Roadmapping can be especially useful for programs / projects that have participants from multiple sites, programs, or other entities which are involved. Increased synergy, better communications, and increased cooperation are the results from roadmapping a program / project with these conditions. And, as with any trip, the earlier you use a roadmap, the more confidence you will have that you will arrive at your destination with few, if any, problems. The longer the trip or complicated the route, the sooner the map is needed. This analogy holds true for using roadmapping for laying out program / project baselines and any <b>alternative</b> (<b>contingency)</b> plans. The mini-roadmapping process has been applied to past projects like the hydrogen gas generation roadmap and the subsurface contaminant focus area (SCFA), and it’s basic form is being applied in the formulation of the ‘ 2012 Plan’ at the Idaho National Engineering and Environmental Laboratory (INEEL). There are also plans to apply this process in the near future for other projects/programs...|$|E
40|$|Young adults {{performed}} a lever-pressing task for money on two schedules of reinforcement: concurrent fixed-interval 1 min—differential-reinforcement-of-low-rate 20 -sec, and concurrent fixed-interval 1 -min—fixed ratio 100 responses. All subjects were trained on both schedules. Fixed-interval performance concurrent with the differential reinforcement procedure {{was characterized by}} high constant rates with no post-reinforcement pauses. Fixed-interval performance concurrent with fixed ratio was characterized by low rates and lengthy post-reinforcement pauses. These results differ from those obtained in prior studies {{on the effects of}} conditioning history upon subsequent fixed-interval performance. The prior work, using non-concurrent procedures, had shown that fixed-interval performance following differential reinforcement of low rates was characterized by post-reinforcement pauses and low rates, while fixed-interval performance following fixed ratio exhibited high constant rates and no post-reinforcement pause. The present results suggest that <b>alternative</b> concurrent <b>contingencies</b> are another major determinant of human fixed-interval performance...|$|R
5000|$|There {{are many}} {{different}} behavioral strategies that PBS can use to encourage individuals to change their behavior. Some of these strategies are delivered through the consultation process to teachers. The strong part of functional behavior assessment {{is that it allows}} interventions to directly address the function (purpose) of a problem behavior. For example, a child who acts out for attention could receive attention for <b>alternative</b> behavior (<b>contingency</b> management) or the teacher could make an effort {{to increase the amount of}} attention throughout the day (satiation). Changes in setting events or antecedents are often preferred by PBS because contingency management often takes more effort. Another tactic especially when dealing with disruptive behavior is to use information from a behavior chain analysis to disrupt the behavioral problem early in the sequence to prevent disruption. Some of the most commonly used approaches are: ...|$|R
50|$|Operation Sledgehammer was a World War II Allied {{plan for}} a cross-Channel {{invasion}} of Europe, {{as the first step}} in helping to reduce pressure on the Soviet Red Army by establishing a Second Front. Essentially, Allied forces were to seize the French ports of either Brest or Cherbourg during the early autumn of 1942 along with areas of the Cotentin Peninsula, and then amass troops for a breakout in the spring of 1943, and as such, was a <b>contingency</b> <b>alternative</b> to Operation Roundup, the original Allied plan for the invasion of Europe in 1943.|$|R
40|$|The EU's import {{policies}} towards {{developing countries}} are complex, stemming from important sectoral and country variations in policy. Average tariffs are modest, and, while there are tariff peaks and escalation {{in some areas of}} interest to developing countries, these are being reduced {{as a result of the}} implementation of the results of the Uruguay Round. The use of non-tariff measures has fallen, particularly as a result of agricultural tariffication, and is being further reduced in textiles and clothing. The elimination of VERs has not led to an increase in the use of <b>alternative</b> measures. <b>Contingency</b> protection falls more heavily in chemicals, iron and steel, certain textile items and certain electrical consumer goods and on Asian, Central and Eastern European and former Soviet Union countries. The operation of various factors appears to be working to mitigate the use of trade defence measures in recent years, helping to counter pressures that seem likely to arise as liberalization proceeds...|$|R
40|$|Although the {{concepts}} of organisational culture (OC) and individual behaviour (IB) have attracted considerable interests from both academics and practitioners, there are few studies that {{examine the relationship between}} them directly (which were conducted under person-culture fit research (see Chatman and O’Reilly, 2016)). While these few existing studies have made an overall contribution to the culture-behaviour relationship, they have critical limitations and gaps in knowledge. Specifically, they primarily adopt functional and quantitative approaches for examining {{the relationship between the two}} concepts, and consequently, they neglect alternative non-functional perspectives of OC (opposition and ambiguity) and their relationship with IB. Also, most of these studies were conducted in organisations from countries that have strict separation between religion and state (e. g. the UK and USA), with very few studies located in countries where people at work actively engage in religious and social practices, particularly Saudi Arabia. This study explores the relationship between OC and IB through an ethnographic case study in a single Saudi Arabian organisation that operates in a vital industry, i. e. financial industry. It adopts a three-perspective theoretical framework (see Martin, 1992), to explore the relationship between OC and IB in a country that is renowned to be highly attached to ancient social norms and religious traditions. The findings of the study lead to the development of a range of insights into the integrated, differentiated, and fragmented nature of OC and how organisational members interact (i. e. perceive and behave) with such cultural components. The empirical evidence suggests that examining the interaction between OC elements (values, believes, and underlying assumptions) and individual traits, including psychology/ social (e. g. values and beliefs), social category (e. g. age and gender), and other subjective characteristics (e. g. education and work experience) is important to understand the relationship between OC and IB. Accordingly, this study develops a conceptual analysis that explains the relationship between OC and IB and considers the dynamic and multidimensional aspects of the two concepts. It also offers contributions to knowledge on organisational literature in general, and Saudi literature in particular, by revealing <b>alternative</b> <b>contingencies</b> that affect the behaviour of organisations and individuals...|$|R
40|$|Exerpted {{material}} from Physics in Perspective, Vol. 1, is presented on recommendations, priorities, and program emphases. The major recommendations are {{addressed to the}} Federal Government and support agencies, the physics community, and the educational community, including precollege, undergraduate, and graduate sectors. Approaches to the questions involved in establishing scientific priorities are discussed, and an approach is evolved {{which is based on}} the jury rating application of certain criteria to the program elements of a subfield. The question of national support level for the physics enterprise is also considered, and <b>contingency</b> <b>alternatives</b> are suggested such that whatever the level of available support, it may be used with maximum effectiveness...|$|R
50|$|The {{original}} {{description of}} the model positioned the DRM as an <b>alternative</b> to the <b>contingency</b> model (CM) of optimal foraging and pointed out {{that some of the}} predictions of the DRM provide a better match than did the CM with observed diet choice and behavior of e.g. herbivores. The DRM went largely unnoticed, but a recent paper by Van Gils describes how red knots Calidris canutus forage based on digestive s and confirmed their foraging according to the DRM rather than the CM model of optimal foraging. The case is particularly interesting as a major difference in individual foraging behavior is related to a large intraspecific difference in the digestive tract of the knots.|$|R
40|$|Marketing {{executives}} {{responsible for}} inter-firm collaboration {{live in a}} world in which business partnerships are popular, but often risky, unstable and vulnerable to failure with less than 50 % of the arrangements performing satisfactorily. There is evidence to suggest that marketing academics have undervalued the role of strategy implementation. It is in this context that the author argues that both marketing academics and practitioner s could benefit from an increased academic focus into the development of intervention strategies to facilitate the improved efficacy of implementation and management problems within the context of business partnering relationships. To examine this issue the structure of this paper is firstly to start with a brief examination of alternative approaches to intervention problem solving so as to define a methodology that marketing academics and practitioners could use to efficaciously deal with inter-firm relationship problems. Secondly, a situational contingency model is adapted from situational leadership theory to consider the business partnering context. <b>Alternative</b> situational <b>contingencies</b> are outlined and based on these contingencies the author proposes a range of intervention strategy approaches defined as either directive, collaborative, persuasive and delegative. 13 page(s...|$|R
40|$|Fiedler and Freytag (2004) {{proposed}} an <b>alternative</b> pathway to <b>contingency</b> assessment {{in terms of}} pseudocontingencies (PCs). PCs reflect the utilization of base-rate information {{in the formation of}} contingency judgments. Here, we introduce an instantiation of the phenomenon based on the mere reproduction of the base rates. Using a relationship-counseling scenario, participants in two experiments produced positive correlations on both indirect and direct measures of the contingency between partners’ responses to the subscales of a relationship inventory, although the objective contingency within each subscale had been negative in an initial learning phase. The magnitude of these effects was predicted accurately by computer simulations reproducing the base rate of ‘yes’ responses for each partner and domain. The findings are discussed within the PC framework...|$|R
40|$|This paper applies {{concepts}} from {{transaction processing}} to workflows, thus enabling workflows to exhibit relaxed transactional behaviour. A general model for transactional workflows is presented. We define correctness of transactional workflows {{in terms of}} the model, and use the model to find schedules such that the execution of a transactional workflow is guaranteed to terminate in one of its acceptable termination (commit or abort) states. We allow a transactional workflow to consist of a number of tasks composed by the constructs ordering, <b>contingency,</b> <b>alternative,</b> conditional and iteration. In addition, we show how the model can be used to support proper nesting of transactional workflows to reduce the diffculty of scheduling algorithms and to provide for structured and modular TWF specification...|$|R
40|$|Congruency {{sequence}} effects (CSEs) {{refer to}} the observation that congruency effects in conflict tasks are typically smaller following incongruent compared to following congruent trials. This measure has long been thought to provide a unique window into top-down attentional adjustments and their underlying brain mechanisms. According to the renowned conflict monitoring theory, CSEs reflect enhanced selective attention following conflict detection. Still, alternative accounts suggested that bottom-up associative learning suffices to explain the pattern of reaction times and error rates. A couple of years ago, a review by Egner (2007) pitted these two rivalry accounts against each other, concluding that both conflict adaptation and feature integration contribute to the CSE. Since then, a wealth of studies has further debated this issue, and two additional accounts have been proposed, offering intriguing <b>alternative</b> explanations. <b>Contingency</b> learning accounts put forward that predictive relationships between stimuli and responses drive the CSE, whereas the repetition expectancy hypothesis suggests that top-down, expectancy-driven control adjustments affect the CSE. In the present paper, we build further on the previous review (Egner, 2007) by summarizing and integrating recent behavioral and neurophysiological studies on the CSE. In doing so, we evaluate the relative contribution and theoretical value of the different attentional and memory-based accounts. Moreover, we review how all of these influences can be experimentally isolated, and discuss designs and procedures that can critically judge between them...|$|R
40|$|Concurrent {{schedules}} may {{be viewed}} as consisting of two pairs of stay and switch schedules, each pair associated with one of the alternatives. A stay schedule arranges reinforcers for staying and responding at one alternative, whereas the associated switch schedule arranges reinforcers for switching to the other alternative. In standard concurrent schedules, the stay schedule at each alternative is equivalent to the switch schedule at the other alternative. MacDonall (1999) exposed rats to one pair of stay and switch variable-ratio schedules and varied the response requirements across conditions. Combining results from symmetric pairs produced composite performances that were described by the generalized matching law. This outcome was noteworthy because the data were obtained from performances at two <b>alternatives</b> with <b>contingencies</b> that were functionally unrelated to each other. This result suggests that concurrent performances may consist of two unrelated performances that alternate as behavior moves between alternatives. The purpose of the present experiment was to extend those results to interval schedules. Rats were exposed to pairs of random-interval schedules, and across conditions their mean intervals were varied. When data from appropriately paired conditions were combined, the composite performances were consistent with the generalized matching law. In addition, the results supported two models of concurrent performances that were based on local variables at an alternative (behavior, and stay and switch reinforcers) : {{a modified version of the}} contingency discrimination model (Davison & Jenkins, 1985) and the local model (MacDonall, 1999) ...|$|R
40|$|The {{extent of}} {{environmental}} contamination {{created by the}} nuclear weapons legacy combined with expensive, ineffective waste cleanup strategies at many U. S. Department of Energy (DOE) sites prompted Congress to pass the FY 96 Energy and Water Development Appropriations Act, which directed the DOE to: ''provide sufficient attention and resources to longer-term basic science research, which {{needs to be done}} to ultimately reduce cleanup costs'', ''develop a program that takes advantage of laboratory and university expertise, and'' ''seek new and innovative cleanup methods to replace current conventional approaches which are often costly and ineffective. '' In response, the DOE initiated the Environmental Management Science Program (EMSP) -a targeted, long-term research program intended to produce solutions to DOE's most pressing environmental problems. EMSP funds basic research to lower cleanup cost and reduce risk to workers, the public, and the environment; direct the nation's scientific infrastructure towards cleanup of contaminated waste sites; and bridge the gap between fundamental research and technology development activities. EMSP research projects are competitively awarded based on the project's scientific, merit coupled with relevance to addressing DOE site needs. This paper describes selected EMSP research projects with long, mid, and short-term deployment potential and discusses the impacts, focus, and results of the research. Results of EMSP research are intended to accelerate cleanup schedules, reduce cost or risk for current baselines, provide <b>alternatives</b> for <b>contingency</b> planning, or provide solutions to problems where no solutions exist...|$|R
40|$|To date, most export {{performance}} {{studies have focused}} on providing business practitioners with set 'prescriptions' for export success. However, this approach has resulted in overwhelmingly inconsistent findings, so {{there is a need for}} alternative approaches. One <b>alternative</b> is through <b>contingency</b> theory, which posits that each firm's {{export performance}} is dependent on the context in which the firm operates. This study therefore uses contingency theory to establish if there is a relationship between export performance and the level of 'fit' between a firm's strategic orientation and its context. This study focused on exporting firms in the apparel industry in New Zealand. Firms were categorised as to whether they were entrepreneurial or conservative in their strategic orientation. The results showed that entrepreneurial firms could operate successfully in hostile or benign external environments, by using either organic or mechanistic export channel structures. But when entrepreneurial and conservative firms have a strategic orientation and channel structure that matches their external environment then there are no real performance advantages for entrepreneurial firms. Contingency approach Export performance Strategy Channel structure...|$|R
5000|$|Operation Bolero was the {{commonly}} used reference for the code {{name of the}} United States military troop buildup in the United Kingdom during World War II {{in preparation for the}} initial cross-channel invasion plan known as Operation Roundup, to be implemented in mid-1943, or for its lesser <b>contingency</b> <b>alternative,</b> Operation Sledgehammer, to be executed in the fall of 1942 in the event of German setbacks or to ease Axis pressure on the Eastern Front. ("Bolero" [...] was the code name used in official communications to stand in for [...] "United Kingdom" [...] when describing the theater or movements.) What later became the Bolero plan [...] - [...] the buildup of a strategic air force in Great Britain in preparation for Roundup [...] - [...] was first submitted by Commanding General of the U.S. Army Air Forces, Henry H. Arnold, to General George Marshall, the U.S. Army Chief of Staff, on April 12, 1942, and set in motion a huge movement of men and material that laid the groundwork for Operation Overlord.|$|R
40|$|In {{laboratory}} contingency learning tasks, {{people usually}} give accurate {{estimates of the}} degree of contingency between a cue and an outcome. However, if they are asked to estimate the probability of the outcome {{in the presence of the}} cue, they tend to be biased by the probability of the outcome in the absence of the cue. This bias is often attributed to an automatic contingency detection mechanism, which is said to act via an excitatory associative link to activate the outcome representation at the time of testing. We conducted 3 experiments to test <b>alternative</b> accounts of <b>contingency</b> bias. Participants were exposed to the same outcome probability in the presence of the cue, but different outcome probabilities in the absence of the cue. Phrasing the test question in terms of frequency rather than probability and clarifying the test instructions reduced but did not eliminate contingency bias. However, removal of ambiguity regarding the presence of additional causes during the test phase did eliminate contingency bias. We conclude that contingency bias may be due to ambiguity in the test question, and therefore it does not require postulation of a separate associative link-based mechanism. © 2013 Copyright The Experimental Psychology Society...|$|R
40|$|Over {{the past}} decade, {{many studies have}} shown that {{individuals}} with reduced sensitivity for risk due to traumatic brain injury in orbital parts of the prefrontal cortex tend to ignore the long term outcomes of their behavioral actions (the same holds true for individuals with socio-/psychopathy). Instead, these individuals merely base decisions on anticipated immediate gains, similar to impulsive choice in children. The Iowa gambling task has been designed specifically to measure this behavioral tendency. We used this task to investigate a state opposite to that of impulsiveness and carelessness, namely enhanced anxiety and risk intolerance. We expected beneficial effects on decision-making, especially since high anxiety in both healthy populations and patients with anxiety disorders has been linked with enhanced activation of orbitofrontal cortex. Our most important finding is that intolerance towards uncertainty is indeed positively correlated with overall performance on the Iowa gambling task in a sample of adults as well as with anxiety in a sample of children. Results illustrate the protective functions of anxiety and risk aversion, and their positive long-term effects on decision-making. These motives seem to enable individuals to better consider future consequences of their actions, and to switch from previously reinforced behaviors to <b>alternative</b> behaviors when <b>contingencies</b> change...|$|R
40|$|Abstract- Multi-rate {{teletraffic}} models {{aim at the}} call-level QoS {{assessment of}} modern telecom networks. This assessment {{is important for the}} bandwidth allocation among serviceclasses, the avoidance of too costly over-dimensioning of the network and the prevention, through traffic engineering mechanisms, of excessive throughput degradation. Despite of its importance, the call-level QoS evaluation remains an open issue, due to the presence of elastic traffic in modern telecom networks. In this paper we consider elastic traffic in connectionoriented networks at call level, i. e. a) calls which have <b>contingency</b> <b>alternative</b> bandwidth requirements at the call setup phase and b) the ability of in-service calls to reduce their bandwidth (elastic bandwidth), while increasing simultaneously their service time. According to the call arrival process, the bandwidth requirements of calls and their behavior during their lifetime, we distinguish the study of multi-service loss models into four categories: A: Random arriving calls with either fixed or elastic bandwidth requirements, and constant use of their assigned bandwidth (constant-bit-rate) during their lifetime. B: Random arriving calls with either fixed or elastic bandwidth requirements, and elastic bandwidth during their lifetime. C: Quasi-random arriving calls with either fixed or elastic bandwidth requirements, and constant use of their assigned bandwidth (constant-bit-rate) during their lifetime. D: Quasi-random arriving calls with either fixed or elastic bandwidth requirements, and elastic bandwidth during their lifetime. We review the models of categories A and C and propose new models for categories B and D...|$|R
40|$|Vallitsevan poliittisen järjestelmän vastustaminen on piirre, joka on leimannut ranskalaista äärinationalismia aina 1800 -luvun loppupuolelta alkaen. Tuula Vaarakallio tarkastelee tutkimuksessaan kolmea erilaista äärikansallisen liikehdinnän edustajaa, jotka ovat hyökänneet edustuksellista demokratiaa, parlamentarismia sekä poliittista eliittiä vastaa eri aikakausina. Vaarakallio tutki äärioikeistolaista järjestelmän vastaisuutta yksityiskohtaisesti poliittisissa ohjelmateksteissä. Näin hän keräsi lisätietoa siitä, mitä itsestäänselvyytenä pidetyn äärikansallisen protestin taakse kätkeytyy. One of {{the main}} {{components}} (topoi) {{of the politics of}} the French nationalists since the late 19 th century has been the rhetoric against the existing ”system,” that is the discourse against the representative form of democracy, the parliamentary form of government and the political establishment. This study focuses on the nationalist anti-system rhetoric {{at the turn of the}} 20 th and the turn of the 21 st centuries, namely on Boulangism (1886 - 1889) and its representative Maurice Barrès (1862 - 1923), the nationalist Charles Maurras (1868 - 1952), and the contemporary radical right movement, the Front National (1972 -). This study aims to carry out a detailed and politically oriented exploration of the changes that can be detected in this rejection from the time of Boulanger to that of the Front National. Methodologically, the study is neither strictly rhetorical nor historical but is instead located somewhere between these two approaches. The main objective is to distinguish the political assumptions and commitments that lie behind the terminology of the political programs not only by analyzing the attack against parliamentarism and the ”deteriorated” establishment but also by examining the ”political alternative” provided, that is, for example the populist calls for direct democracy. The use of antithetical pairs clearly typifies this kind of nationalist rhetoric, and the dichotomy between ”the real nation” and ”the legal nation” is a specific emblematic manifestation of how in the nationalist discourse ”the true political essence” is distinguished from the ”the false political appearance,” thereby serving as a basis for the nationalist attempt at achieving ”one truth or one essence”. The study illustrates how nationalist politics actually aims at harmonizing political life and simplifying politics, not only by demanding firm authority and relying directly on the people by means of referenda but also by avoiding political struggles, ”vain” politicking and useless parliamentary discussions. Although there are variations in the rhetoric of the various political agents and ideologists covered in this study, one may nevertheless conclude that the call for national coherence and political unanimity on the one hand, and the renunciation of pluralism, political <b>alternatives</b> and <b>contingency</b> on the other, seem to prevail...|$|R
40|$|Modern {{planning}} and scheduling systems {{are capable of}} dealing with the size and complexity of many real world problems. However, mission critical planning is still often done by humans. Even if only a couple of plans are produced (“Master Plan ” and “Plan B”), human experts evaluate multiple <b>alternatives,</b> think of <b>contingencies,</b> consider the likelihood of failure of various steps, and account for schedule slack and plan flexibility. Computers can evaluate thousands of alternative scenarios, but the solutions they ultimately produce are often not convincing enough for expert decision makers to trust human lives or mission critical operations to computer decisions. Further, automated systems often require significant changes in the way people operate, which in high-stakes high-pressure environments leads to rejection of the system by the users. In this paper we describe the decision support functionality of the Coordinated Multi-source Maintenance on Demand (CMMD) system. CMMD is designed to support the complete life cycle of mission plans for human space exploration, starting with initial long-term {{planning and}} ending with day-by-day execution of a detailed schedule. The goal of CMMD is not to replace human experts, but to assist them. To do so, CMMD explains reasons for commitments it makes, allows the user to interactively explore alternatives, guide the search toward more desirable solutions, and to run various queries (e. g., what courses of action have not yet been explored with respect to some goal?). We claim that giving users insight into workings of the system and gradually enhancing existing processes is crucial for gaining user confidence in produced plans and ultimately for adoption of the system...|$|R
40|$|This study {{explored}} the views and perceptions about agency {{social work in}} England. At its core is the first known case study of adult services social work teams in a rural local authority. The case study took place over the period 2008 - 2010 and used qualitative methodology to capture perspectives from agency and employed social workers, agency and employed managers and agency and employed administrative staff. Agency social work was seen to have developed from a background of deteriorating conditions in local government employment {{and in the absence}} of effective and flexible workforce planning. Labour process theory provided a meaningful framework to help explore the phenomenon of agency social work within a public sector increasingly dominated by markets and managerialism. A directional tendency towards a degraded workplace was noted despite some perceptions of upskilling in respect of agency social workers. A range of explanations regarding the motivation and the experiences of agency social workers was found that largely supported previous case study findings from urban local authorities. The roles carried out by employed social workers under the care management system were indistinguishable from those of agency social workers, several agency social workers having remained in post for periods of two years or more. No ways of working were identified as being particularly tailored to a rural context. The antipathy toward agency social workers noted in previous case studies was largely absent in the rural case study and agency social workers were not perceived as part of the private sector. Issues regarding the cost-effectiveness of agency social work and its affect on service users and carers were inconclusive. Recommendations for further research were made and agency social work was seen as being likely to remain as a core feature of modernised social work while vacancies remain high and <b>alternative</b> models for <b>contingency</b> workforce planning remain absent...|$|R
40|$|Abstract Contingency {{tables are}} a very common basis for the {{investigation}} of effects of different treatments or influences on a disease or the health state of patients. Many journals put {{a strong emphasis on}} p-values to support the validity of results. Therefore, even small contingency tables are analysed by techniques like t-test or ANOVA. Both these concepts are based on normality assumptions for the underlying data. For larger data sets, this assumption is not so critical, since the underlying statistics are based on sums of (independent) random variables which can be assumed to follow approximately a normal distribution, at least for a larger number of summands. But for smaller data sets, the normality assumption can often not be justified. Robust methods like the Wilcoxon-Mann-Whitney-U test or the Kruskal-Wallis test do not lead to statistically significant p-values for small samples. Median polish is a robust <b>alternative</b> to analyse <b>contingency</b> tables providing much more insight than just a p-value. Median polish is a technique that provides more information than just a p-value. It explains the contingency table in terms of an overall effect, row and columns effects and residuals. The underlying model for median polish is an additive model which is sometimes too restrictive. In this paper, we propose two related approach to generalise median polish. A power transformation {{can be applied to the}} values in the table, so that better results for median polish can be achieved. We propose a graphical method how to find a suitable power transformation. If the original data should be preserved, one can apply other transformations – based on so-called additive generators – that have an inverse transformation. In this way, median polish can be applied to the original data, but based on a non-additive model. The non-linearity of such a model can also be visualised to better understand the joint effects of rows and columns in a contingency table...|$|R
