94|10000|Public
5|$|Darlington {{additionally}} used {{a transformation}} found by Hendrik Bode that predicted {{the response of}} a filter using non-ideal components but all with the same Q. Darlington used this transformation in reverse to produce filters with a prescribed insertion-loss with non-ideal components. Such filters have the ideal insertion-loss response plus a flat attenuation <b>across</b> <b>all</b> <b>frequencies.</b>|$|E
500|$|The {{impedance}} of {{a loudspeaker}} is not constant <b>across</b> <b>all</b> <b>frequencies.</b> [...] In a typical loudspeaker the impedance will rise {{with increasing frequency}} from its DC value, {{as shown in the}} diagram, until it reaches a point of its mechanical resonance. [...] Following resonance, the impedance falls to a minimum and then begins to rise again. [...] Speakers are usually designed to operate at frequencies above their resonance, and for this reason it is the usual practice to define nominal impedance at this minimum and then round to the nearest standard value. [...] The ratio of the peak resonant frequency to the nominal impedance can be as much as 4:1. [...] It is, however, still perfectly possible for the low frequency impedance to actually be lower than the nominal impedance. [...] A given audio amplifier may not be capable of driving this low frequency impedance even though it is capable of driving the nominal impedance, a problem that can be solved either with the use of crossover filters or underrating the amplifier supplied.|$|E
2500|$|In 1999, Charlie Hughes of Peavey Electronics {{filed for}} a patent on a hybrid horn he called Quadratic-Throat Waveguide. The horn was {{basically}} a simple conic section but its throat was curved {{in a circular arc}} to match the desired throat size for proper mating to the speaker driver. Instead of increasing the horn mouth size with a flare to control midrange beaming, a relatively thin layer of foam covering the mouth edge was found to suit the same end. The QT waveguide, when compared to popular CD horns, produced about [...] lower levels of second harmonic distortion <b>across</b> <b>all</b> <b>frequencies,</b> and an average of [...] lower levels of the more annoying third harmonic distortion. Being without a diffraction slot, the QT waveguide was free from problems with apparent apex, making it arrayable as needed for public address purposes.|$|E
50|$|As a {{consequence}} of Parseval's theorem, one can prove that the signal energy is always equal to the summation <b>across</b> <b>all</b> <b>frequency</b> components of the signal's spectral energy density.|$|R
30|$|Finally, {{there are}} {{situations}} in which the channel measurement can be done on a per-tone basis, but the physical transmission platforms only permit each AN to allocate one value of power <b>across</b> <b>all</b> <b>frequency</b> tones. In this case, we take the average power (AP) values of IFEM algorithms, and call the resulting method AP algorithms. For example, AP HSIFEM takes the average power value of the HSIFEM.|$|R
30|$|Reference [33] has {{proposed}} a permutation alignment approach based on the power ratio measure. Binwise permutation alignment is applied first <b>across</b> <b>all</b> <b>frequency</b> bins, using the correlation of separated signal powers; then the full frequency band is partitioned into small regions based on the binwise permutation alignment result. Finally, regionwise permutation alignment is performed, which can prevent the spreading of the misalignment at isolated frequency bins to others and thus improves permutation. This permutation alignment approach is employed in the proposed method.|$|R
2500|$|Pitch is {{perceived}} as how [...] "low" [...] or [...] "high" [...] a sound is and represents the cyclic, repetitive nature of the vibrations that make up sound. For simple sounds, pitch relates to {{the frequency of the}} slowest vibration in the sound (called the fundamental harmonic). In the case of complex sounds, pitch perception can vary. Sometimes individuals identify different pitches for the same sound, based on their personal experience of particular sound patterns. Selection of a particular pitch is determined by pre-conscious examination of vibrations, including their frequencies and the balance between them. Specific attention is given to recognising potential harmonics. [...] Every sound is placed on a pitch continuum from low to high. For example: white noise (random noise spread evenly <b>across</b> <b>all</b> <b>frequencies)</b> sounds higher in pitch than pink noise (random noise spread evenly across octaves) as white noise has more high frequency content. [...] Figure 1 shows an example of pitch recognition. During the listening process, each sound is analysed for a repeating pattern (See Figure 1: orange arrows) and the results forwarded to the auditory cortex as a single pitch of a certain height (octave) and chroma (note name).|$|E
50|$|Darlington {{additionally}} used {{a transformation}} found by Hendrik Bode that predicted {{the response of}} a filter using non-ideal components but all with the same Q. Darlington used this transformation in reverse to produce filters with a prescribed insertion-loss with non-ideal components. Such filters have the ideal insertion-loss response plus a flat attenuation <b>across</b> <b>all</b> <b>frequencies.</b>|$|E
50|$|A bandwidth-limited pulse (also {{known as}} Fourier-transform-limited pulse, or more commonly, transform-limited pulse) is a pulse {{of a wave}} that has the minimum {{possible}} duration for a given spectral bandwidth. Optical pulses of this type can be generated by mode-locked lasers. Bandwidth-limited pulses have a constant phase <b>across</b> <b>all</b> <b>frequencies</b> making up the pulse.|$|E
40|$|We {{present a}} new {{technique}} which corrects the wideband quadrature errors associated with homodyne stepped-frequency radar receivers. The correction algorithm is derived using singular value decomposition (SVD) which diagonalizes and scales the covariance matrix of a test signal while preserving the coherent phasor alignment <b>across</b> <b>all</b> <b>frequency</b> steps of the homodyne receiver. Using our technique, the wideband quadrature errors of a 1 - 2 GHz stepped-frequency radar receiver were corrected to within a 0. 1 dB gain imbalance, and to within a 0. 5 deg phase imbalance. The Hermitian images were shown to be suppressed by more than 50 dB below the main target peaks...|$|R
3000|$|... channel values {{drifted to}} > 10, 000 ohm-m up to December 2011. This drift {{resulted}} in drifting of impedance phases to around 80 – 320 Hz; these values were corrected immediately by changing electrodes in December 2011, and the apparent resistivity <b>across</b> <b>all</b> <b>frequency</b> ranges was not influenced by this changing of electrodes. The {{electrical power supply}} was maintained {{by a series of}} solar panels (80 W each×six panels), a charging controller, and a number of deep-cycle batteries (105 Ah each × six batteries). Approximately every two months, we visited the MT observation site to maintain the MT apparatus, replacing the electrodes if necessary and collecting the digital time series data that had been recorded.|$|R
40|$|In this paper, a novel {{modified}} complex multi-task Bayesian compressive sensing (MCMT-BCS) {{algorithm is}} proposed to acquire high-resolution images in stepped-frequency through-the-wall radar imaging (TWRI) exploiting multipath. Un-like traditional TWRI approaches that assume frequency-independent scattering model, we develop a practical subband scattering model to characterize real-world scattering mech-anisms. The target imaging is reformulated as a multi-task sparse signal recovery problem <b>across</b> <b>all</b> <b>frequency</b> subbands as well as multipath modes, where the sparse entries of each task share the same support in the imaged scene. The proposed MCMT-BCS algorithm accounts for both types of coexisting group sparsity to achieve improved high-resolution imaging capability. Simulation results verify {{the effectiveness of the}} proposed algorithm. Index Terms — Through-the-wall radar imaging, sparse construction, multipath exploitation, Bayesian compressive sensing, group sparsity. 1...|$|R
5000|$|The {{column vector}} gives the Fourier co-efficients for all {{points on the}} grid at a given frequency. This is then built up into a two {{dimensional}} matrix which covers the complex Fourier co-efficients for all points <b>across</b> <b>all</b> <b>frequencies.</b> Then, an inverse fast Fourier transform is performed to get the time series. That is, ...|$|E
50|$|Broadband over Power Lines (BPL) {{technology}} uses a {{wide range}} of HF frequencies to transmit data (3.5 through 30 MHz), which includes the CB frequencies. There is great potential for interference, as power lines were never specifically designed to shield radio frequencies. RF leakage from BPL is regulated under Part 15 and is a big problem for amateur radio operators <b>across</b> <b>all</b> <b>frequencies</b> that the BPL uses.|$|E
50|$|In 2009, Alpha {{was joined}} by {{neighbouring}} station Minster Northallerton to share the sudio complex in a cost-cutting exercise. To make further savings, both Alpha and Minster Northallerton, along with Durham FM were rebranded as Star Radio North East which meant all three stations lost their heritage names and, until recently, only produced a daily breakfast show. Since June 2010, output has been networked <b>across</b> <b>all</b> <b>frequencies,</b> although commercial breaks are still unique to the three areas.|$|E
40|$|This paper {{deals with}} the problem of under-determined convolutive blind source separation. We model the {{contribution}} of each source to all mixture channels in the time-frequency domain as a zero-mean Gaussian random variable whose covariance encodes the spatial properties of the source. We consider two covariance models and address the estimation of their parameters from the recorded mixture by a suitable initialization scheme followed by an iterative expectationmaximization (EM) procedure in each frequency bin. We then align the order of the estimated sources <b>across</b> <b>all</b> <b>frequency</b> bins based on their estimated directions of arrival (DOA). Experimental results over a stereo reverberant speech mixture show the effectiveness of the proposed approach. Index Terms — Convolutive blind source separation, under-determined mixtures, spatial covariance models, EM algorithm, permutation problem. 1...|$|R
40|$|This article {{addresses}} the modeling of reverberant recording environments {{in the context}} of under-determined convolutive blind source separation. We model the contribution of each source to all mixture channels in the time-frequency domain as a zero-mean Gaussian random variable whose covariance encodes the spatial characteristics of the source. We then consider four specific covariance models, including a full-rank unconstrained model. We derive a family of iterative expectationmaximization (EM) algorithms to estimate the parameters of each model and propose suitable procedures to initialize the parameters and to align the order of the estimated sources <b>across</b> <b>all</b> <b>frequency</b> bins based on their estimated directions of arrival (DOA). Experimental results over reverberant synthetic mixtures and live recordings of speech data show the effectiveness of the proposed approach...|$|R
40|$|A novel internal, {{quad-band}} antenna placed {{inside a}} ‘foldable’ type of Mobile Phone is presented. Its structure {{consists of a}} helical and a monopole element exciting two broad frequency bands. Using a simple matching circuit the proposed antenna covers several frequency bands including the Global System for Mobile Communication (890 - 960 MHz), Digital Communication System (1710 - 1880 MHz), Personal Communication System (1850 - 1990 MHz) and Universal Mobile Telecommunication System (1920 - 2170 MHz). It achieves a Voltage Standing Wave Ratio (VSWR) of less than three <b>across</b> <b>all</b> <b>frequency</b> bands with total radiation efficiency of more than 50 %. Its novel design and structure occupies only 1. 8 cm 3 of volume making this antenna very small and very suitable for internal use inside mobile terminals...|$|R
50|$|Røde {{entered the}} shotgun {{microphone}} market in 2005, with the NTG1 and NTG2 microphones. Both feature a permanently polarised ½” condenser capsule, with the NTG2 accepting a battery power source {{in addition to}} phantom power.The NTG3 was released in 2008, providing Røde with a premium true condenser shotgun microphone, featuring RF bias technology to allow the microphone to continue operation in humid and cold conditions where traditional microphones could fail.In 2012 Røde announced the NTG8, a long shotgun version of the NTG3 which features enhanced directionality <b>across</b> <b>all</b> <b>frequencies.</b>|$|E
50|$|Where {{both the}} OHCs and the IHCs are damaged, the {{resulting}} neural tuning curve would show {{the elimination of}} sensitivity at the ‘tip'. However, due to IHC damage, the whole tuning curve becomes raised, giving a loss of sensitivity <b>across</b> <b>all</b> <b>frequencies</b> (See Figure 6). It is only necessary for the first row of OHCs to be damaged {{for the elimination of}} the finely tuned ‘tip’ to occur. This supports the idea that the incidence of OHC damage and thus a loss of sensitivity to quiet sounds, occurs more than IHC loss.|$|E
5000|$|Weber's {{law does}} not hold at {{perception}} of higher intensities. Intensity discrimination improves at higher intensities. The first demonstration of the phenomena was presented by Riesz in 1928, in Physical Review. This deviation of the Weber's law {{is known as the}} [...] "near miss" [...] of the Weber's law. This term was coined by McGill and Goldberg in their paper of 1968 in Perception & Psychophysics. Their study consisted of intensity discrimination in pure tones. Further {{studies have shown that the}} near miss is observed in noise stimuli as well. Jesteadt et al. (1977) demonstrated that the near miss holds across all the frequencies, and that the intensity discrimination is not a function of frequency, and that the change in discrimination with level can be represented by a single function <b>across</b> <b>all</b> <b>frequencies.</b>|$|E
40|$|Abstract—This article {{addresses}} the modeling of reverberant recording environments {{in the context}} of under-determined convolutive blind source separation. We model the contribution of each source to all mixture channels in the time-frequency domain as a zero-mean Gaussian random variable whose covariance encodes the spatial characteristics of the source. We then consider four specific covariance models, including a full-rank unconstrained model. We derive a family of iterative expectationmaximization (EM) algorithms to estimate the parameters of each model and propose suitable procedures adapted from the stateof-the-art to initialize the parameters and to align the order of the estimated sources <b>across</b> <b>all</b> <b>frequency</b> bins. Experimental results over reverberant synthetic mixtures and live recordings of speech data show the effectiveness of the proposed approach. Index Terms—Convolutive blind source separation, underdetermined mixtures, spatial covariance models, EM algorithm, permutation problem. I...|$|R
40|$|A good speech {{model is}} {{essential}} for speech enhancement, {{but it is very}} difficult to build because of huge intra- and extra-speaker variation. We present a new speech model for speech enhancement, which is based on statistical models of magnitude-normalized complex spectra of speech signals. Most popular speech enhancement techniques work in the spectrum space, but the large variation of speech strength, even from the same speaker, makes accurate speech modeling very difficult because the magnitude is correlated <b>across</b> <b>all</b> <b>frequency</b> bins. By performing magnitude normalization for each speech frame, we are able to get rid of the magnitude variation and to build a much better speech model with only a small number of Gaussian components. This new speech model is applied to speech enhancement for our previously developed microphone headsets that combine a conventional air microphone with a bone sensor. Much improved results have been obtained. 1...|$|R
50|$|Mechanical RF components, such as wave-guide, {{can produce}} Doppler {{modulation}} due to phase shift induced by vibration. This introduces a requirement to perform full spectrum operational tests using shake tables {{that can produce}} high power mechanical vibration <b>across</b> <b>all</b> anticipated audio <b>frequencies.</b>|$|R
50|$|In 1999, Charlie Hughes of Peavey Electronics {{filed for}} a patent on a hybrid horn he called Quadratic-Throat Waveguide. The horn was {{basically}} a simple conic section but its throat was curved {{in a circular arc}} to match the desired throat size for proper mating to the speaker driver. Instead of increasing the horn mouth size with a flare to control midrange beaming, a relatively thin layer of foam covering the mouth edge was found to suit the same end. The QT waveguide, when compared to popular CD horns, produced about 3-4 dB lower levels of second harmonic distortion <b>across</b> <b>all</b> <b>frequencies,</b> and an average of 9 dB lower levels of the more annoying third harmonic distortion. Being without a diffraction slot, the QT waveguide was free from problems with apparent apex, making it arrayable as needed for public address purposes.|$|E
50|$|Other {{than the}} {{narrowing}} vertical coverage, {{the length of}} the array also plays a role in what wavelengths will be affected by this narrowing of dispersion. The longer the array, the lower frequency the pattern will control. At frequencies below 100 Hz (wavelength of 11.3 ft) the line array which is less than approximately 3 meter long will start to become omnidirectional, so the system will not conform to line array theory <b>across</b> <b>all</b> <b>frequencies.</b> Above about 400 Hz the driver cones themselves become directional, again violating the theory’s assumptions, and at high frequencies, many practical systems use directional waveguides whose behavior cannot be described using classical line array theory. In short, the geometry of real-world audio line arrays as used in public address systems can only be modeled approximately by line array theory, and only in the 100-400 Hz range.|$|E
50|$|This {{quadratic}} equation suggested to Hughes {{the name of}} the horn design: the Quadratic-Throat Waveguide (QT waveguide). Instead of increasing the horn mouth size with a flare to control midrange beaming, a relatively thin layer of foam covering the mouth edge was found to suit the same end. The QT waveguide, when compared to popular constant directivity (CD) horns, produced about 3-4 dB lower levels of second harmonic distortion <b>across</b> <b>all</b> <b>frequencies,</b> and an average of 9 dB lower levels of the more annoying third harmonic distortion. Being without a diffraction slot, the QT waveguide was free from problems with apparent apex, making it arrayable as needed for public address purposes. In New York City, Hughes presented a paper on the technology at the Audio Engineering Society convention in September 1999. His patent for the QT waveguide was provisionally filed on March 5, 1999, and granted on May 9, 2000.|$|E
40|$|A new general {{linear model}} (GLM) {{beamformer}} method is described for processing magnetoencephalography (MEG) data. A standard nonlinear beamformer {{is used to}} determine the time course of neuronal activation for each point in a predefined source space. A Hilbert transform gives the envelope of oscillatory activity at each location in any chosen frequency band (not necessary in the case of sustained (DC) fields), enabling the general linear model to be applied and a volumetric T statistic image to be determined. The new method is illustrated by a two-source simulation (sustained field and 20 Hz) and is shown to provide accurate localization. The method is also shown to locate accurately the increasing and decreasing gamma activities to the temporal and frontal lobes, respectively, {{in the case of a}} scintillating scotoma. The new method brings the advantages of the general linear model to the analysis of MEG data and should prove useful for the localization of changing patterns of activity <b>across</b> <b>all</b> <b>frequency</b> ranges including DC (sustained fields) ...|$|R
40|$|Objective: This paper {{presents}} automatic {{method of}} segmentation of heart sound using {{the occurrence of}} the cardiac rhythmic events. Methods: Noisy heart sound is filtered using the 6 th order Chebyshev type I low pass filter to remove the redundant noise. Bark Spectrogram is calculated from the cardiac signal by converting spectrogram to the bark scale. The bark spectrogram is smoothened and the loudness index is calculated by averaging the amplitude <b>across</b> <b>all</b> <b>frequency</b> bands. The loudness index is smoothened and differentiated to obtain the event detection function. The smoothened event detection function gives the occurrence of the cardiac events namely {{the first and the}} second heart sounds. Conclusion: This method is highly effective in identifying peaks S 1 and S 2 with the segmentation accuracy of 96. 98 % giving an F 1 measure of 97. 09 %. Significance: This method does not require the setting up of any type of threshold. So it is a highly effective type of segmentation under noisy conditions...|$|R
40|$|The primary aim of {{this study}} was to {{establish}} whether redintegrative effects can be revealed under conditions with complex sensory stimulation.   Specifically, would the cortical activity involved in the single-trial, passive encoding of a movie, be reactivated when subsequently exposed to a unisensory component of that movie, e. g. an audio- or visual-only segment?  High-density electrical neuroimaging analysis in the frequency domain was used to assist this aim.  The statistical comparisons revealed a greater number of oscillating neuronal regions <b>across</b> <b>all</b> <b>frequency</b> bands in participants who received audiovisual stimulation prior to unisensory exposure (compared to participants who experienced the same unisensory stimulus without prior audiovisual stimulation).    This difference between groups was significant in the alpha 2 (right frontal lobe) and gamma (right frontal, sub-lobar and temporal lobes) frequencies during audio-only stimulation.     This enhanced cortical activity during unisensory stimulation suggests that participants were retrieving associated memory traces from their prior multisensory experience, although specific redintegrative effects could not be confirmed...|$|R
5000|$|The {{impedance}} of {{a loudspeaker}} is not constant <b>across</b> <b>all</b> <b>frequencies.</b> In a typical loudspeaker the impedance will rise {{with increasing frequency}} from its DC value, {{as shown in the}} diagram, until it reaches a point of its mechanical resonance. Following resonance, the impedance falls to a minimum and then begins to rise again. [...] Speakers are usually designed to operate at frequencies above their resonance, and for this reason it is the usual practice to define nominal impedance at this minimum and then round to the nearest standard value. [...] The ratio of the peak resonant frequency to the nominal impedance can be as much as 4:1. [...] It is, however, still perfectly possible for the low frequency impedance to actually be lower than the nominal impedance. [...] A given audio amplifier may not be capable of driving this low frequency impedance even though it is capable of driving the nominal impedance, a problem that can be solved either with the use of crossover filters or underrating the amplifier supplied.|$|E
5000|$|Pitch is {{perceived}} as how [...] "low" [...] or [...] "high" [...] a sound is and represents the cyclic, repetitive nature of the vibrations that make up sound. For simple sounds, pitch relates to {{the frequency of the}} slowest vibration in the sound (called the fundamental harmonic). In the case of complex sounds, pitch perception can vary. Sometimes individuals identify different pitches for the same sound, based on their personal experience of particular sound patterns. Selection of a particular pitch is determined by pre-conscious examination of vibrations, including their frequencies and the balance between them. Specific attention is given to recognising potential harmonics. [...] Every sound is placed on a pitch continuum from low to high. For example: white noise (random noise spread evenly <b>across</b> <b>all</b> <b>frequencies)</b> sounds higher in pitch than pink noise (random noise spread evenly across octaves) as white noise has more high frequency content. Figure 1 shows an example of pitch recognition. During the listening process, each sound is analysed for a repeating pattern (See Figure 1: orange arrows) and the results forwarded to the auditory cortex as a single pitch of a certain height (octave) and chroma (note name).|$|E
50|$|Musician's earplugs are {{designed}} to attenuate sounds evenly <b>across</b> <b>all</b> <b>frequencies</b> (pitches) which helps maintain the ear's natural frequency response and thus minimizes {{the effect on}} the user's perception of bass and treble levels. These are commonly used by musicians and technicians, both in the studio and in concert, to avoid overexposure to high volume levels. Musician's earplugs generally achieve this by incorporating a tiny diaphragm to reduce low frequencies, together with absorbent or damping material for high frequencies. These earplugs are not intended for protection from very high noise levels (beyond 105 dB). Preformed earplugs, such as the ER-20 earplug are universal (non-custom) earplugs with a noise reduction rating (NRR) of about 12 dB. A more expensive option is the custom musician's earplug, which is custom-made for the individual listener. These earplugs are typically made out of silicone or vinyl materials and come with a vent and a variety of filters that can change the amount of attenuation provided. Common filter attenuations are 9, 15, and 25 dB, and with these filters, the musician can adjust their earplugs depending on the music they are playing. In order to have custom musicians' earplugs made, an audiologist administers a hearing test and makes molds of the ear. A company then makes a custom ear-piece into which the different filters may be inserted. These types of earplugs will provide the flattest attenuation and the truest isolation from outside noise, as they fit firmly into the individual's ears. They also provide much better protection from very high noise levels. This type of plug is quite popular amongst audio engineers who can safely listen to loud mixes for extended periods of time. However, they can be quite costly, being intended for constant re-use unlike simple earplugs which are disposable.|$|E
40|$|Functional {{connectivity}} {{in human}} brain {{can be represented}} as a network using electroencephalography (EEG) signals. Network representation of EEG time series can be an efficient vehicle to understand the underlying mechanisms of brain function. Brain functional networks whose nodes are brain regions and edges correspond to functional links between them are characterized by neurobiologically meaningful graph theory metrics. This study investigates {{the degree to which}} graph theory metrics are sex dependent. To this end, EEGs from 24 healthy female subjects and 21 healthy male subjects were recorded in eyes-closed resting state conditions. The connectivity matrices were extracted using correlation analysis and were further binarized to obtain binary functional networks. Global and local efficiency measures as graph theory metrics were computed for the extracted networks. We found that male brains have significantly greater global efficiency (i. e., global communicability of the network) <b>across</b> <b>all</b> <b>frequency</b> bands {{for a wide range of}} cost values in both hemispheres. Furthermore, for a range of cost values, female brains showed significantly greater right-hemispheric local efficiency (i. e., local connectivity) than male brains. © American Institute of Mathematical Sciences...|$|R
40|$|In {{this paper}} we study how the meso-scale and micro-scale {{electroencephalography}} (EEG) synchronization measures {{can be used}} for discriminating patients suffering from Alzheimer&# 039;s disease (AD) from normal control subjects. To this end, two synchronization measures, namely power spectral density and multivariate phase synchronization, are considered and the topography of the changes in patients vs. Controls is shown. The AD patients showed increased power spectral density in the frontal area in theta band and widespread decrease in the higher frequency bands. It was also characterized with decreased multivariate phase synchronization in the left fronto-temporal and medial regions, which was consistent <b>across</b> <b>all</b> <b>frequency</b> bands. A region of interest was selected based on these maps and the average of the power spectral density and phase synchrony was obtained in these regions. These two quantities were then used as features for classification of the subjects into patients&# 039; and controls&# 039; groups. Our analysis showed that the theta band can be a marker for discriminating AD patients from normal controls, where a simple linear discriminant resulted in 83 % classification precision...|$|R
40|$|This paper {{discusses}} {{a frequency}} domain method for blind identication of MIMO convolutive channels driven by white quasi-stationary sources. The sources can assume arbitrary probability distributions {{and in some}} cases they can even be all Gaussian distributed. We also show that under slightly more restrictive assumptions the algorithm {{can be applied to the}} case when the sources are colored, non-stationary signals. We demonstrate that by using the second order statistics of the channel outputs, under mild conditions on the non-stationarity of sources, and under the condition that channel is column-wise coprime, the impulse response of the MIMO channel can be identied up to an inherent scaling and permutation ambiguity. We prove that by using the new algorithm, under the stated assumptions, a uniform permutation <b>across</b> <b>all</b> <b>frequency</b> bins is guaranteed, and the inherent frequency dependent scaling ambiguities can be resolved. Hence no post processing is required as is the case with previous frequency domain algorithms. We further present an ecient, two step frequency domain algorithm for identifying the channel. Numerical simulations are presented to demonstrate the performance of the new algorithm 1. I...|$|R
