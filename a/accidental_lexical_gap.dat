0|128|Public
40|$|In {{this paper}} {{we present a}} {{methodology}} for automatically classifying the translation equivalents of a machine readable bilingual dictionary in three main groups: <b>lexical</b> units, <b>lexical</b> <b>gaps</b> (that is cases when a lexical concept of a language {{does not have a}} correspondent in the other language) and translation equivalents that need to be manually classified as lexical units or <b>lexical</b> <b>gaps.</b> This preventive classification reduces the manual work necessary to cope with <b>lexical</b> <b>gaps</b> in the construction of aligned multilingual wordnets. 1...|$|R
5000|$|The humour {{comes from}} the {{translator}} filling in an English <b>lexical</b> <b>gap</b> based on the lexical noun, [...] "miss" [...] by adding a prefix mis-. English employs the two verbs miss the carriage and miscarriages to mean vastly different actions. There is a <b>lexical</b> <b>gap</b> in English because the action of missing a carriage cannot be expressed with the same import and the same economy of verbalisation. The misuse of this <b>lexical</b> <b>gap</b> and overgeneralisation conflates the ludicrous idea of the horse-driven tours with no miscarriages.|$|R
40|$|<b>Lexical</b> <b>Gaps</b> Abstract in English The general {{assumption}} {{among most}} language users {{is that every}} single concept in our world can be labeled by a proper lexical item, i. e. there is a name {{for all of the}} physical or abstract entities we live with and situations we experience. It has been suggested by several studies, and we will concentrate on these, that there are usually several conceptual structures in the studied languages which are in fact not lexicalized. This linguistic phenomenon is called a <b>lexical</b> <b>gap,</b> and {{there is more than one}} type of <b>lexical</b> <b>gap</b> observable in languages. Recent studies of the occurrence of a <b>lexical</b> <b>gap</b> show various approaches to the subject with various results. The study of <b>lexical</b> <b>gaps</b> can be approached from the point of view of lexical fields, as suggested by Alan Cruse and Adrienne Lehrer among others. In this approach different fields: taxonomies, hierarchies, clusters, grids, linear structures and matrixes help to organize the lexicon into conceptual structures where the missing structural part is then best observable and studied with relation to the other units in the field. Other approaches, Bentivogli and Pianta for example, favour contrastive lexicological studies where a <b>lexical</b> <b>gap</b> is identified as a missing translational equivalent in a target language to a lexical [...] ...|$|R
50|$|<b>Lexical</b> <b>gaps</b> {{concerns}} {{words or}} phrases with no direct translation {{in any given}} language.|$|R
5000|$|The {{translation}} {{procedures that}} are available in cases of lacunae, or <b>lexical</b> <b>gaps,</b> include the following: ...|$|R
40|$|In {{this paper}} we {{present the results}} of a {{quantitative}} evaluation of the discrepancies between the Italian and English lexica in terms of <b>lexical</b> <b>gaps.</b> This evaluation has been carried out in the context of MultiWordNet, an ongoing project that aims at building a multilingual lexical database. The quantitative evaluation of the English-to-Italian <b>lexical</b> <b>gaps</b> shows that the English and Italian lexica are highly comparable and gives empirical support to the MultiWordNet model. 1...|$|R
50|$|All being said, {{languages}} do have {{a productive}} (linguistics) and recursion property that can also allow words and phrases to combine creatively {{to fill in the}} <b>lexical</b> <b>gaps.</b>|$|R
5000|$|There is a <b>lexical</b> <b>gap</b> between Chinese {{names and}} {{descriptions}} of hallucinogenic plants and English pharmacological terminology for hallucinogens, which are commonly divided into psychedelics, dissociatives, and deliriants.|$|R
50|$|Humor, then, {{results from}} the interlocutor's {{inability}} to grasp the <b>lexical</b> <b>gaps</b> in target language and linguistic representations may either be over generalised or under generalised {{to the point of}} absurdity.|$|R
50|$|The {{language}} of Waray has borrowed vocabulary extensively from other languages, especially from Spanish. These words are being adopted to fill <b>lexical</b> <b>gaps</b> {{of the recipient}} language. Spanish colonialization introduced new systems to the Philippine society.|$|R
40|$|This thesis {{focuses on}} the {{terminology}} of History Science and its lexicographic description in a German-Czech dictionary of terms. It starts with a discussion about various types of equivalence {{and the need for}} an encyclopedic section. In particular, attention is paid to the <b>lexical</b> <b>gaps</b> that result from zero equivalence. <b>Lexical</b> <b>gaps</b> are demonstrated on the translation of culture-specific terms, i. e. the selection of a surrogate equivalent. It is shown that surrogate equivalents require relatively detailed encyclopedic notes and that their usage can only be established within the examples. The dictionary article of a culture-specific lemma must therefore provide such citations and examples that both demonstrate the applicability of the surrogate in the context and add encyclopedic information...|$|R
40|$|This paper {{discusses}} {{a sentence}} generation system protector which uses: (i) a non-hierarchical semantic representation {{which allows for}} flexible lexical choice and uniform treatment of different languages, (ii) a lexicalised D-Tree Grammar which {{is very similar to}} Tree-Adjoining Grammar in spirit, and (iii) dynamic programming techniques to avoid doing redundant computations. We review the motivation for choosing such an organisation of the generation system and give an example of the generation of a sentence which involves a <b>lexical</b> <b>gap.</b> The generation of the example sentence requires a nondeterministic mode of computation (the <b>lexical</b> <b>gap</b> forcing backtracking). We show how dynamic programming techniques can be used to save re-generating structures using a top-down generation algorithm...|$|R
40|$|We {{study the}} design of an {{information}} re-trieval (IR) system that assists customer service agents while they interact with end-users. The type of IR needed is difficult {{because of the large}} <b>lexical</b> <b>gap</b> between problems as described by cus-tomers, and solutions. We describe an approach that bridges this <b>lexical</b> <b>gap</b> by learning semantic relatedness using tensor representations. Queries that are short and vague, which are common in practice, re-sult in a large number of documents be-ing retrieved, and a high cognitive load for customer service agents. We show how to reduce this burden by providing suggestions that are selected based on the learned measures of semantic relatedness. Experiments show that the approach offers substantial benefit compared to the use of standard lexical similarity. ...|$|R
50|$|David Gil {{reports that}} the Maricopa managed quite well despite having no {{equivalent}} for and. The various relevant relations are solved by using different linguistic structures. However, whether {{the absence of a}} lexeme constitutes a <b>lexical</b> <b>gap</b> depends on not a theory but the shared verbal habits of the people using the relevant conceptualization.|$|R
40|$|In {{this paper}} {{we present a}} {{proposal}} to extend WordNet-like lexical databases by adding phrasets, i. e. sets of free combinations of words which are recurrently used to express a concept (let's call them recurrent free phrases). Phrasets are a use- ful source of information for different NLP tasks, and particularly in a multilingual environment to manage <b>lexical</b> <b>gaps.</b> Tw...|$|R
50|$|In translation, {{the source}} {{language}} {{is the language}} being translated from; it is the antonym of the target language, which is the language being translated to. Part of the difficulty in translation arises due to the <b>lexical</b> <b>gap</b> between the source language and the target language. The necessity of translation arises from that gap, especially between two languages belonging to different language families.|$|R
40|$|A {{pattern in}} the {{translation}} of locative prepositional phrases between English and Spanish is presented. A way of exploiting this pattern is proposed {{in the context of}} a multilingual machine translation system under development. Introduction Two of the main problems in machine translation (MT) are ambiguity and <b>lexical</b> <b>gaps.</b> Ambiguity occurs when a word in the source language (SL) has more that one translation into the target language (TL). <b>Lexical</b> <b>gaps</b> occur when a word in one language can not be translated directly into another language. This latter problem is viewed by some as the key translation problem, (Kameyama et al., 1991). A case in point is the translation of prepositional phrases (PP). The following entry for the translations into Spanish of the preposition along demonstrates this (entry taken from (Garcia-Pelayo, 1988)). along: por (by), a lo largo de (to the length of), seg'un (according to) Both problems occur here: there are three different translations for the sa [...] ...|$|R
2500|$|Proper {{names and}} {{technical}} terms {{are likely to}} appear in its original language,like [...] "lock brake", [...] "kick down", and [...] "power shift" [...] in auto magazines. English is either used to fill the <b>lexical</b> <b>gap</b> where generally accepted Chinese translation is unavailable, or to avoid confusion if one single English term has different versions of translation in Mainland China, Taiwan and Hong Kong.|$|R
40|$|It is {{very costly}} {{to build up}} lexical {{resources}} and domain ontologies. Especially when confronted with a new application domain <b>lexical</b> <b>gaps</b> and a poor coverage of domain concepts are {{a problem for the}} successful exploitation of natural language document analysis systems that need and exploit such knowledge sources. In this paper we report about ongoing experiments with `bootstrapping techniques' for lexicon and ontology creation...|$|R
50|$|Puchkov {{is known}} as a strong {{advocate}} of quality translation, and opposes the practice of literal interpretation of movies, which has become commonplace in Russia. His position is that precise translation backed by thorough research and identification of Russian equivalents in cases of <b>lexical</b> <b>gaps</b> should be the product provided to Russian aficionados of foreign films. Puchkov maintains lists of gaffes made by other film translators.|$|R
5000|$|Proper {{names and}} {{technical}} terms {{are likely to}} appear in its original language,like [...] "lock brake", [...] "kick down", and [...] "power shift" [...] in auto magazines. English is either used to fill the <b>lexical</b> <b>gap</b> where generally accepted Chinese translation is unavailable, or to avoid confusion if one single English term has different versions of translation in Mainland China, Taiwan and Hong Kong.|$|R
5000|$|Many {{languages}} do {{not distinguish}} between what in English are described as [...] "blue" [...] and [...] "green" [...] and instead use a cover term spanning both. To describe this English <b>lexical</b> <b>gap,</b> linguists use the portmanteau word grue, from green and blue, which the philosopher Nelson Goodman coined in his 1955 Fact, Fiction, and Forecast to illustrate the [...] "new riddle of induction".|$|R
40|$|Lexical {{contrastive}} {{studies are}} a neglected part of contrastive analysis in general. Since {{little attention has}} been paid to the possible basis for lexical contrastive analysis, conceptual dictionaries (in combination with bilingual dictionaries and existing corpora) are suggested as a possible starting point. This kind of approach would insure a more detailed insight into the structure of the vocabulary, as well as <b>lexical</b> <b>gaps</b> and ways of lexicalization of each language...|$|R
5000|$|Some {{researchers}} {{have criticized the}} indirect role of mutual exclusivity in word learning because an alternative explanation could account for children’s motivation to assign novel labels to novel objects. They may simply be motivated to fill the <b>lexical</b> <b>gap</b> created by a novel object rather than avoiding second labels. In other words, children may be motivated to give a name to objects {{that they do not}} already have a name for.|$|R
40|$|Maarten Janssen, Marc van Campenhoudt : Terminologie traductive et représentation des {{connaissances}} : l'usage des relations hyponymiques. One of {{the major}} problems in multilingual terminology is the existence of <b>lexical</b> <b>gaps.</b> Amongst the models that have been proposed {{to deal with this}} problem are the TERMISTI model, using a tree, and SIMuLLDa, using a lattice. The TERMISTI model is prompted by a practical need; the SIMuLLDA system is a practical implementation of a formal framework. This article gives a brief overview and a comparison of these two models, and how they deal with <b>lexical</b> <b>gaps.</b> A central question is whether the concrete cases raised by the TERMISTI project can be correctly dealt with in the more formalised SIMuLLDA system. The major obstacle for the SIMuLLDA system are the cases of partial overlap, where two terms have overlapping, but non-identical meanings. Janssen Maarten, Van Campenhoudt Marc. Terminologie traductive et représentation des connaissances : l'usage des relations hyponymiques. In: Langages, 39 ᵉ année, n° 157, 2005. La terminologie : nature et enjeux, sous la direction de Loïc Depecker. pp. 63 - 79...|$|R
40|$|This paper explores log-based query {{expansion}} (QE) {{models for}} Web search. Three lexicon models are proposed {{to bridge the}} <b>lexical</b> <b>gap</b> between Web documents and user queries. These models are trained on pairs of user queries and titles of clicked documents. Evaluations on a real world data set show that the lexicon models, integrated into a ranker-based QE system, not only significantly improve the document retrieval performance but also outperform two state-of-the-art log-based QE methods. ...|$|R
40|$|Abstract The aim of {{this study}} was twofold. On the one hand, the aim was to discuss how <b>lexical</b> <b>gaps</b> can be solved or dealt with when a text about {{wildlife}} and nature {{different from that of the}} target culture is translated. On the other hand, the aim was also to discuss how the style and tone of such a text can be preserved and transferred into the target text. The study was qualitative and based on a translation into Swedish of short chapters of the book Spirit of the Bush by Peter Borchert, describing the South African wildlife and nature. The intended target reader of the translation is anyone with an interest in nature, wildlife and animals, as well as anyone with an interest in the history and culture of South Africa. Despite the fact that the terminology used in both the source text and the target text may require some previous knowledge on behalf of the reader, both texts could, nevertheless, very well be appreciated by a complete “wildlife-novice”. In order to create a theoretical base and a framework for the analysis, relevant research made in translation theory and stylistics was presented and discussed. Regarding <b>lexical</b> <b>gaps,</b> all the different strategies, apart from omission, proved to be of great help when the source text was translated into Swedish. Several examples of metaphors were discussed, such as how the wilderness is described as a stage, the animals as actors, and the visitors as making a pilgrimage. The metaphors in combination with the similes and the personifications in the source text, such as bold clouds and confident rivulets, fire the readers’ imagination and create a very vivid and capturing text. This is also something that supports the claim made that Spirit of the Bush is more than an ordinary informative text.   Keywords: translation, <b>lexical</b> <b>gaps,</b> style, tone, stylistics, wildlife, bush. ...|$|R
40|$|The {{purpose of}} this work {{is to examine the}} {{translation}} of technical language from German into Swedish within the field of small arms. The analysis is based on translation of a selected part of a specialist reference book on the historical development of small arms which was printed in East Germany in 1979. The work is divided into two major parts. The work is divided into two major parts. The first part is referred to as theoretical background and here the author gives a thorough description of major concepts related to technical language such as denotative equivalence, <b>lexical</b> <b>gaps</b> and the construction of terms. In the second part the author analyses the original text and the translation in regard to these concepts. Also, to some extent, different logical and hierarchical relations between terms are discussed. One main focus lies on the analysis of <b>lexical</b> <b>gaps</b> whereby various methods used for closing these gaps are thoroughly discussed. In relation to this, the author also focuses on different contextual and cultural preferences and adaptations {{when it comes to the}} terminological naming of small arms and their components. Another central topic is how technical terms are constructed when it comes to small arms. More specifically the focus lies on language-specific properties regarding nominal compositions between various parts of speech, but also on the use of metaphors. From the analysis several conclusions can be drawn. In most cases it is possible to translate a technical term with a corresponding term in the target language. <b>Lexical</b> <b>gaps</b> mainly emerge when we are dealing with a type of small arm that is popular in one country but hardly exists in the other. Another conclusion is that there are several possibilities to construct technical terms. It is quite common that the German nominal composition differs from the Swedish one. Also, metaphors can be translated with certain flexibility...|$|R
50|$|In {{linguistics}} {{an accidental}} gap, {{also known as}} a <b>gap,</b> <b>lexical</b> <b>gap,</b> lacuna, or a hole in the pattern, is a word or other form that does not exist in some language but which would be permitted by the grammatical rules of the language. Accidental gaps differ from systematic gaps, those words or other forms which do not exist in a language due to the boundaries set by phonological, morphological, and other rules of that specific language.|$|R
40|$|Living {{languages}} are in constant demand of new words. Whenever a new object or an idea {{need to be}} given a name, a <b>lexical</b> <b>gap</b> arises in the language. There are several different ways in which the gap can be filled. Generally speaking, one can distinguish between the three frequent ones: lexical borrowing, word formation and multiplication of meaning. This essay begins with a short general description of the methods and then follows the analysis of Internet terminology in Croatian with many examples...|$|R
40|$|The {{subject of}} the present paper {{is the notion of}} ‘lexical {{competence}}’. This type of competence is often analysed in a too narrow sense, although over the years the notion has been broadened. Since in the Author’s opinion the definition of lexical competence should include not only the knowledge about vocabulary or its usage, but also the ability to compensate for <b>lexical</b> <b>gaps,</b> a new, slightly broader definition has been formulated and the factors were presented which may influence its developmen...|$|R
40|$|Process-based studies {{investigating}} composing {{behavior in}} Ll and L 2 /L 3 writing have generally {{focused on the}} way writers plan, formulate,' revise and edit their written compositions. They, however, {{paid little attention to}} the lexical problems those writers were aware of and how they endeavored to solve them using communication strategies. This study examines a) the lexical problems (types and rates per 100 words) that Tunisian students noticed when writing argumentative essays in French (L 2) and English (L 3) in an exam- simulated situation as well as b) the various lexical strategies (types and percentages) they used to solve their lexical problems. Their c) notice ability is also examined and a new measure of the notice phenomenon is suggested. The variation of a, band c was looked at in relation to the three factors under-investigation namely language (L 2 vs. L 3), lexical proficiency and course level (Baccalaureat students vs. EFL majors). Background questionnaire together with vocabulary tests, think-aloud protocols, retrospective interviews and subjects' L 2 and L 3 essays constitute the main research instruments. Quantitative and qualitative results show that different types of competence-based problems (<b>lexical</b> <b>gaps</b> and problems originating from incomplete mastery of known words) and performance-based problems (retrieval problems and perceived problems of words inappropriateness and repetition) were identified in the process of both L 2 and L 3 writing. The frequency of some lexical problems varied across languages (e. g. <b>lexical.</b> <b>gaps),</b> <b>lexical</b> proficiency (e. g. <b>lexical</b> <b>gaps</b> and mastery of aspects of known words) and course level (e. g. retrieval of word aspect problems in L 2 writing). With regards to lexical strategies, subjects had recourse to a) target language-based strategies b) mediator language-based strategies i. e. using lexical knowledge of other languages they learnt/are still learning c) reading information already available in the compositions and d) non- linguistic strategies such as message abandonment, ignoring, and postponing. Lexical proficiency {{played a crucial role in}} determining the percentages of. target language-based and mediator language-based strategies. The notice ability turned out to be weak and its variation was dependent only on subjects' lexical proficiency in English. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|Nature has {{repeated}} its evolution {{processes and}} developed its own ?engineering? principles {{over a long}} period of time. Bioinspired design starts from the belief that nature has the most effective and optimized problem-solving schemes, which can be applied to human problems directly or indirectly. In summary, bioinspired design is the study of the design process, adapting the structure, behavior, or organic mechanisms of biology to engineering problems. In bioinspired design studies, researchers have sought a way of improving concept generation through texts. Generally, there are two problems in text-based bioinspired design. First, there is a great <b>lexical</b> <b>gap</b> between two areas?biology and engineering. Thus, understanding the context of biological text is compromised, prohibiting analogical transfer between the two domains. Second, the amount of text is too great to be assimilated by engineers. This knowledge gap makes the engineer confused by the extensive information and slows down the design process. The present work tried to apply lexical substitution and text mining theories to effectively process biological text. Regarding the matter of the <b>lexical</b> <b>gap,</b> this research developed an algorithm that translates biological terminology to words or phrases that are understandable to engineers by adapting four lexical sources: WordNet, Wikipedia, the Integrated Taxonomy Information System (ITIS), and WordNik. For the second problem, this research tried to categorize biological text based on morphological solutions by adapting the Latent Semantic Analysis (LSA) technique. Two main contributions are made in this dissertation. First of all, this work is the first attempt to directly bridge the <b>lexical</b> <b>gap</b> between biology and engineering by translating biological terminology. The existing approach to bioinspired design study involves building a thesaurus or database that connects a few engineering keywords and their biological correspondences. However, since most other biological terms remain unchanged, this research is meaningful as it attempts to overcome this limitation. The second contribution is that this research ameliorates the natural language-based bioinspired concept generation. Specifically, the accessibility to biotexts for bioinspired design seems to be improved by enabling engineers to selectively acquire biological information for their problems...|$|R
40|$|We {{present a}} simple and {{effective}} way to perform out-of-domain statistical parsing by drastically reducing lexical data sparseness in a PCFG-LA architecture. We replace terminal symbols with unsupervised word clusters acquired from a large newspaper corpus augmented with biomedical targetdomain data. The resulting clusters are effective in bridging the <b>lexical</b> <b>gap</b> between source-domain and target-domain vocabularies. Our experiments combine known self-training techniques with unsupervised word clustering and produce promising results, achieving an error reduction of 21 % on a new evaluation set for biomedical text with manual bracketing annotations. ...|$|R
40|$|Abstract. BabelNet {{is a very}} large, wide-coverage {{multilingual}} ontology. This {{resource is}} created by linking the largest multilingual Web encyclopedia – i. e., Wikipedia – to the most popular computational lexicon – i. e., WordNet. The integration is performed via an automatic mapping and by filling in <b>lexical</b> <b>gaps</b> in resource-poor languages {{with the aid of}} Machine Translation. The result is an “encyclopedic dictionary” that provides babel synsets, i. e., concepts and named entities lexicalized in many languages and connected with large amounts of semantic relations. BabelNet is available online a...|$|R
40|$|In this paper, we aim {{to reveal}} the impact of lexical-semantic resources, used in {{particular}} for word sense disambiguation and sense-level semantic categorization, on automatic personality classification task. While stylistic features (e. g., part-of-speech counts) have been shown their power in this task, the impact of semantics beyond targeted word lists is relatively unexplored. We propose and extract three types of lexical-semantic features, which capture high-level concepts and emotions, overcoming the <b>lexical</b> <b>gap</b> of word n-grams. Our experimental results are comparable to state-of-the-art methods, while no personality-specific resources are required...|$|R
