7|49|Public
40|$|Availability quantifies the {{propensity}} {{of a system}} to be functionally operative upon demand. It increases if operating times between failures (up times) are long, and decreases if, following failure or anticipatory removal, logistics delays and repair (down times) are protracted. This chapter summarizes the general <b>availability</b> <b>concept</b> and discusses the limitation of operational availability suggesting that mission availability is often more useful and appropriate...|$|E
40|$|Abstract—The paper {{proposes a}} new {{analytical}} method for determining traffic characteristics of multi-stage switching networks implementing threshold mechanism with hysteresis. The proposed method {{makes it possible}} to calculate point-to-group blocking probability in switching networks with multi-rate traffic streams. The basis of the presented method is the effective <b>availability</b> <b>concept.</b> The results of analytical calculations in two switching networks are compared with simulation data. Keywords-switching networks; multi-rate traffic; threshold mechanism with hysteresis; I...|$|E
40|$|International audience—The {{efficient}} use of bandwidth for radio communications {{becomes more and more}} crucial when developing new information technologies and their applications. The core issues are addressed by the so-called Frequency Assignment Problems (FAP). Our work investigates static FAP, where an attempt is first made to configure a kernel of links. We study the problem based on the concepts and techniques of Constraint Programming and integrate the site <b>availability</b> <b>concept.</b> Numerical simulations conducted on scenarios provided by CELAR are very promising...|$|E
40|$|Abstract: High {{availability}} is {{more important}} than ever now that your customers, suppliers, and/or employees rely on your Web site. This paper reviews <b>availability</b> <b>concepts</b> and practices that can help you achieve your availability objectives. It includes a summary of practices that pertain specifically to e-business infrastructures. © Copyright IBM Corporation 200 2 Maximizing Web Site availabilityExecutive summary What happens when your Web site is down? At the least, your site’s users become idle, your staff goes into crisis mode, and everyone’s productivity decreases. At the worst, the users are your customers and they go somewhere else to buy the product or service your company offers. Depending on how long the site is down, customer satisfaction and revenue are diminished, and the reputation of your IT organization, if not your company, is damaged. It’s not a good place to be. That’s why availability is such an important aspect of managing a successful e-business Web site. This paper reviews <b>availability</b> <b>concepts,</b> all of which are well known to IT professionals. Given the increasing complexities of managing e-business infrastructures and the increasing intolerance for any outages, the paper stresses that the basic concepts and practices of availability are more important than ever. It also reviews practices specifically related to e-business infrastructures; understanding an...|$|R
30|$|Accuracy, integrity, {{continuity}} and <b>availability</b> <b>concepts</b> {{are in fact}} the quality criteria commonly used for describing the performances provided by a GNSS. Expected performances of on-board Galileo-based equipment have been defined in the Galileo specification documents [6]. They {{can be used to}} describe the RAMS attributes associated to the Galileo positioning function. We explain below how this is done. We will show why the analogy between the two classes of quality criteria is not immediate but possible. It requires the background of the GNSS quality criteria to be explained. This will be presented in the last section of this article with a methodology to prove the analogy.|$|R
50|$|The {{idea of the}} {{availability}} cascade was first developed by Timur Kuran and Cass Sunstein as a variation of information cascades mediated by {{the availability}} heuristic, {{with the addition of}} reputational cascades. The <b>availability</b> cascade <b>concept</b> has been highly influential in finance theory and regulatory research, particular with respect to assessing and regulating risk.|$|R
40|$|The {{efficient}} use of bandwidth for radio communications {{becomes more and more}} crucial when developing new information technologies and their applications. The core issues are addressed by the so-called Frequency Assignment Problems (FAP). Our work investigates static FAP, where an attempt is first made to configure a kernel of links. We study the problem based on the concepts and techniques of Constraint Programming and integrate the site <b>availability</b> <b>concept.</b> Numerical simulations conducted on scenarios provided by CELAR are very promising. Comment: 11 pages, 1 figure and 3 table...|$|E
40|$|Plantation {{forestry}} {{has been}} widely used for industrial purposes, creating vast extensions of culture forests. Although these plantations have a primary economic goal, they may indirectly serve other functions, such as landscape connectivity. Eucalypts are among the main plantation species used worldwide. In those areas {{in which they are}} not native, eucalyptus have been regarded as pernicious species for autochthonous forest and forest dwelling fauna. However, they may enhance connectivity between natural forest patches, thus favouring faunal dispersal. In Cantabria (Spain), Eucalyptus globulus were extensively planted in deforested areas mainly occupied by bushes and meadows. Here, we examine whether their massive introduction has modified landscape connectivity in the region. We used two indices based on graph theory and on the habitat <b>availability</b> <b>concept</b> (Integral Index of Connectivity and Probability of Connectivity), and applied them to the current forest network. Our results show how eucalyptus afforestation, principally based on temporary woodlands, has not improved forest connectivity in Cantabria significantly, though in the coast some of the new plantation areas may be locally important. Specific management actions targeted at these particularly relevant patches may enhance faunal dispersal and thus maintain biodiversity by reducing the fragmentation of these highly humanized areas...|$|E
40|$|Landscape {{connectivity}} {{has become}} a key issue {{for the conservation of}} biodiversity to counteract the adverse effects of habitat fragmentation and to facilitate the accommodation of species to the shifts in their natural domains caused by climate change. It is actually being included into an increasing number of policies, programs and projects. However connectivity is a dynamic property affected by global and local changes (land use, climate, etc.), and landscape planning and conservation efforts should take into account the current and foreseen patterns of change in the landscape and habitat patterns. Here we compared the contribution of different forest habitat patches for maintaining connectivity across different land-use change scenarios, including (1) loss of forest patches through forest fires, conversion to agriculture, and urban development and (2) land use changes in the non-forest matrix that may cause a reduced connectivity in the forest landscape. We integrated each of these changes into a least-cost model, where the distance between forest patches is weighted by the effort (resistance) of a particular species to traverse the different landscape elements in the matrix (effective or least-cost paths). These effective distances were incorporated into the Probability of Connectivity index index (PC) (Pascual-Hortal and Saura 2006; 2007; Saura and Pascual-Hortal 2007), which is based on graphs and the habitat <b>availability</b> <b>concept</b> (Pascual-Hortal and Saura 2006; 2007). Through {{a new version of the}} Conefor Sensinode software developed specifically for these purposes, we analyzed the importance of each forest patch as a connecting element or stepping stone between the rest of the forest habitat, through the recently described PCconnector component of that index (Saura 2007). To illustrate this methodology we applied it to a forest-dwelling bird (Sitta europaea) in the region of Galicia (NW Spain), with an extent of 29574 km 2. This bird, affected by forest fragmentation, has a median dispersal distance of 3 Km (Matthysen et al. 1995) and prefers wooded cover in its dispersal movements (Verboom et al. 1991), avoiding open areas (Bélisle et al. 2001). We model the population dispersal through the least-cost analysis, taking into account the intrinsic characteristics of each land cover type (increasing the resistance from wooded to open areas, according with the forest¿s natural succession schemes, and with maximum resistance on anthropogenic land uses) and the spatial context of each pixel (percentage of forest cover around each pixel), based on a recent model (Rodríguez Freire 2006; Rodríguez Freire and Crecente 2006; 2007) that was modified to incorporate the different analyzed land-cover changes. We illustrate how the different land-use change scenarios impact the connectivity of the forest landscape and how the conservation priorities in the landscape have to be adapted to minimize the consequences of land cover change. Finally, we discuss how the methodology can be applied to a wide range of forest landscape management applications in different countries, where both the conservation of the forest critical areas and an adequate management of the landscape matrix between them are of concern to achieve the sustainability of the ecological flows and ecosystem services in the forest landscapes. JRC. H. 7 -Land management and natural hazard...|$|E
40|$|Scientific {{high-end}} computing (HEC) {{has become an}} important tool for scientists world-wide to under-stand problems, such as in nuclear fusion, human ge-nomics and nanotechnology. Every year, new HEC sys-tems emerge on the market with better performance and higher scale. With only very few exceptions, the over-all availability of recently installed systems has been lower {{in comparison to the}} same deployment phase of their predecessors. In contrast to the experienced loss of availability, the demand for continuous availability has risen dramatically due to the recent trend towards capability computing. In this paper, we analyze the ex-isting deficiencies of current HEC systems and present several high <b>availability</b> <b>concepts</b> to counter the experi-enced loss of availability and to alleviate the expected impact on next-generation systems. We explain the ap-plication of these concepts to current and future HEC systems and list past and ongoing related research. This paper closes with a short summary of the presented work and a brief discussion of future efforts. 1...|$|R
50|$|From August to October 1985, Coontz {{underwent}} {{her first}} Phased Maintenance <b>Availability,</b> a new <b>concept</b> involving {{short periods of}} intense industrial work designed to maximize operational availability rather than placing ships in prolonged overhauls.|$|R
5000|$|The {{relationship}} between MFI and temperature {{can be used}} to obtain the activation energies for polymers. [...] The activation energies developed from MFI values has the advantage of simplicity and easy <b>availability.</b> The <b>concept</b> of obtaining activation energy from MFI can be extended to copolymers as well wherein there exists an anomalous temperature dependence of melt viscosity leading to the existence of two distinct values of activation energies for each copolymer.|$|R
40|$|Cluster {{computing}} {{has been}} attracting {{more and more}} attention from both the industrial and the academic world for its enormous computing power and scalability. Beowulf type cluster, for example, is a typical High Performance Computing (HPC) cluster system. Availability, as a key attribute of the system, needs to be considered at the system design stage and monitored at mission time. Moreover, system monitoring is a must to help identify the defects and ensure the system’s availability requirement. In this paper, novel solutions which provide availability modeling, model evaluation, and data analysis as a single framework have been investigated. Three key components in the investigation are availability modeling, model evaluation, and data analysis. The general <b>availability</b> <b>concepts</b> and modeling techniques are briefly reviewed. The system’s availability model is divided into submodels based upon their functionalities. Furthermore, an object oriented Markov model specification to facilitate availability modeling and runtime configuration has been developed. Numerical solutions for Markov models are examined, especially on the uniformization method. The paper also presents a monitoring and data analysis framework, {{which is responsible for}} failure analysis and availability reconfiguration. ACM Classification: D. 2. 11, D. 2. 12, D. 2. 13 1...|$|R
40|$|Information and {{communication}} technologies {{are designed to}} support and anticipate the continuing changes of the information society, while outlining new economic, social and cultural dimensions. We see the growth of new business models whose aim is to remove traditional barriers and improve the value of goods and services. Information is a strategic resource and its manipulation raises new problems for all entities involved in the process. Information {{and communication}} technologies should be a stable support in managing the flow of data and support the integrity, confidentiality and <b>availability.</b> <b>Concepts</b> such as eBusiness, eCommerce, Software as a Service, Cloud Computing and Social Media are based on web technologies consisting of complex languages, protocols and standards, built around client-server architecture. One of the most used technologies in mobile applications are the Web Services defined as an application model supported by any operating system able to provide certain functionalities using Internet technologies to promote interoperability between various appli-cations and platforms. Web services use HTTP, XML, SSL, SMTP and SOAP, because their stability has proven over the years. Their functionalities are highly variable, with Web services applications exchange type, weather, arithmetic or authentication services. In this article {{we will talk about}} SOAP and REST architectures for web services in mobile applications and we will also provide some practical examples based on Android platform...|$|R
30|$|Figure  10 {{shows that}} the {{performance}} on this experiment is determined by two sub concepts; Time behavior and Resource utilization. The results of the performance analysis show that the main performance measures involved in these sub concepts are: Processing time, Job turnaround and Hard disk bytes written. In addition, there are two sub concepts which have greater influence in the performance sub concepts; Capacity and <b>Availability.</b> These <b>concepts</b> contribute with the performance by means of their specific performance measures which have contribution {{in the behavior of}} the performance measures, they are respectively: Memory utilization, Load reduce task, and Time system up.|$|R
40|$|Each leaf {{is both a}} {{sink and}} a source of carbon that determines the growth of plant structure. Therefore, {{simulation}} of individual leaf expansion is essential in modeling plant structural growth. Leaf expansion has been often fitted to logistic sigmoidal functions that require initial and final leaf length, and duration of elongation to be known. A different method, based on the compound interest law, determines leaf length using initial length, relative elongation rate and duration of elongation. We aimed to evaluate which factors are most important in explaining final leaf length variability. Elongation of individual leaves on peach shoots was monitored over 21 days. Individual leaf lengths were fitted to logistic functions to determine their initial and final lengths, and durations of elongation in growing degree hours. Parameters that could affect final leaf length were evaluated: shoot characteristics below the leaf, initial length, duration of elongation, and temperature during the initial days after leaf appearance. Final leaf length had significant relationships with leaf area and length of the shoot axis excluding sylleptic branches, but it was not significantly related to initial length or duration of elongation. Total shoot leaf area and temperature during the initial days after leaf appearance also affected final leaf length. Our results showed that final leaf length is mainly determined by factors acting during leaf elongation. Based on these data, we used compound interest law and carbon <b>availability</b> <b>concepts</b> to develop a mechanistic model of final lengths of individual leaves...|$|R
40|$|This study {{identifies}} {{the concepts of}} reliability, cost of downtime, cost of spare parts, and procurement lead time as the four key moderators of spare parts <b>availability.</b> These <b>concepts</b> are used to establish a model to manage spare parts inventories. Reliability was assessed in terms of developing failure predictions for major component categories. Cost of downtime was evaluated by identifying various methods for determining costs associated with downtime. Cost of spare parts was examined to find correlations with economic indicators. These correlations were used to predict future price movements. Yearly changes in lead time were identified and correlated with economic indexes to develop movement predictability...|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedThis thesis evaluates NALCOMIS based upon maintenance management information requirements and highlights how NALCOMIS {{does not support}} the Maintenance Material Control Officer (MMCO) as an information system. The Automated Maintenance Environment (AME) initiative currently in development will be capable of providing the MMCO with the information needed to improve maintenance management decisions. The overall result will be reduced aircraft lifecycle costs and improved operational <b>availability.</b> A <b>concept</b> of operations at the organizational maintenance level is presented to illustrate the AME concept. The full implementation of AME will {{have a profound effect on}} Naval aviation maintenance processes. Recommendations for further research are presented. [URL] Commander, United States Nav...|$|R
40|$|<b>Availability</b> is a <b>concept</b> used to {{characterize}} {{the performance of a}} machine, component, or system with respect to its ability to fulfill the function for which it is operated. In this article, a general introduction to quantitative modeling for the availability analysis of components and systems is provided. Both, cases of continuously monitored and periodically tested components are considered. Markov modeling and Monte Carlo simulation are presented as methods for the evaluation of the availability of complex systems...|$|R
40|$|Abstract: The {{extensive}} seasonal {{tropical forests}} and limestone karts of northern Southeast Asia preserve an excellent record of prehistoric hunter-gatherer activity. Recent {{work by the}} Highland Archaeology Project in Pang Mapha, NW Thailand has produced a high volume of hunter-gatherer cultural materials from these seasonal forests dating to the terminal Pleistocene and Holocene. These stone artefact assemblages are interpreted using a human behavioural ecology framework to show that assemblage variation {{is a result of}} variation in residential mobility, risk and uncertainty in resource <b>availability.</b> The <b>concepts</b> and methods of human behavioural ecology provide rich explanations of assemblage variability and overcome the limitations of formal lithic typological classification systems that show minimal and ambiguous assemblage variation over time and space. This approach has good potential for the analysis and interpretation of other similarly amorphous cobble-based lithic assemblages in mainland Southeast Asia...|$|R
40|$|This paper {{presents}} a unique approach to aircraft maintenance optimization during base maintenance planning. The necessity to optimize maintenance follows from {{a need to}} reduce heavy maintenance visits that require significant downtime and are capital intensive. Further, unnecessary maintenance and frequent opening and closing of panels results in significant wear and tear, and thus reducing the inherent reliability of the aircraft. A simulation model has been developed to predict the maintenance requirement of aircraft in an airline operating under known conditions. Construction and validation of the model are based on knowledge and statistical data of actual operations and maintenance practices. The main use of the model is to group maintenance tasks into manageable packages that can be executed at extended maintenance intervals and within specified periods, and thus increasing aircraft <b>availability.</b> The <b>concept</b> of initial interval de-escalation of maintenance is introduced and its positive effects are demonstrated...|$|R
50|$|A <b>concept's</b> <b>availability</b> can be {{affected}} by how recently and how frequently it has been brought to mind. In one study, subjects were given partial sentences to complete. The words were selected to activate the concept either of hostility or of kindness: {{a process known as}} priming. They then had to interpret the behavior of a man described in a short, ambiguous story. Their interpretation was biased towards the emotion they had been primed with: the more priming, the greater the effect. A greater interval between the initial task and the judgment decreased the effect.|$|R
3000|$|System {{is modeled}} {{based on the}} {{positive}} <b>availability</b> of all <b>concepts</b> and their initial states are defined as A^ 0 =[1111111111]. Although all concepts are positively existence in the model, system include some opposite interacts among concepts such as increase {{of the cost of}} systems will cause to decrease of the new generation capacities of the solar and wind energy system. The solar and wind energy generation-based model reaches steady state at zero level which means system is at the balance {{and there will be no}} change in the long term. Results of the model can be listed as follows (Fig.  9): [...]...|$|R
40|$|Abstract. A {{major issue}} {{in the study of}} {{semantic}} Web services concerns the matching problem of Web services. Various techniques for this problem have been proposed. Typical ones include FSM modeling, DAML-S ontology matching, description logics reasoning, and WSDL dual operation composition. They often assume the <b>availability</b> of <b>concept</b> semantic relations, based on which the capability satisfiability is evaluated. However, we find that the use of semantic relations alone in the satisfiability evaluation may lead to inappropriate results. In this paper, we study the problem and classify the existing techniques of satisfiability evaluation into three approaches, namely, set inclusion checking, concept coverage comparison and concept subsumption reasoning. Two different semantic interpretations, namely, capacity interpretation and restriction interpretation, are identified. However, each of the three approaches assumes only one interpretation and its evaluation is inapplicable to the other interpretation. To address this limitation, a novel interpretation model, called CRI model, is formulated. This model supports both semantic interpretations, and allows the satisfiability evaluation to be uniformly conducted. Finally, we present an algorithm for the unified satisfiability evaluation. ...|$|R
40|$|The {{standard}} method of measuring pollen limitation {{is to add}} pollen {{to a number of}} flowers, preferably to a whole plant, and to compare fruit and seed set with that of naturally pollinated flowers on other plants. In 25 yr of research, this method has yielded valuable data, {{but it is difficult to}} use in large plants. This has caused a bias in the available data towards smaller, herbaceous plants with relatively few flowers. I argue that, in order to widen our knowledge of how pollen limitation affects plants, we should go beyond whole-plant pollen addition and change our concept of how a flowering plant functions. The traditional method does not take into account the variation in and dynamics of resource allocation and pollen <b>availability.</b> The <b>concept</b> of integrated physiological units (IPUs) does, but, although it has been applied to pollination biology, it has not received the attention it deserves. I use this article to present its merits again, to propose a step-by-step methodology for studying pollen limitation, and to examine factors influencing possible plant strategies...|$|R
40|$|Distributed {{systems are}} complex to design, build and debug. Components crash due to {{software}} bugs such as unchecked array bounds, logic errors, and unchecked return codes. Components hang due to deadlocks and resource leaks. Instead {{of relying on}} failure-proofing the services which is rarely feasible, we focus on detecting and restarting failed components as an approach to improve system <b>availability.</b> With the <b>concepts</b> and benefits of restarting in mind, I will present a watchdog service for detecting and recovering from failed components in a distributed system. As a case study, I will describe the design and implementation of a watchdog service for a distributed storage system called Ursa Minor. Experiences and novel extensions will be highlighted. ...|$|R
40|$|In the {{corporate}} world, {{a large number}} of people store their data on clouds. For doing this they need to give their confidential data in the hands of the third party, commonly known as service providers. These cloud service providers cannot be trusted since the complete data is stored in one single cloud. This increases security risks to the user's sensitive data. Due to this issue of data integrity risk and service <b>availability</b> failure, the <b>concept</b> of "Cloud-of-Clouds" comes into picture. Cloud-of-clouds are also known as "inter-clouds" or "multi-clouds". Use of cloud-of-clouds provides a higher level of security to the user's confidential data. The aim of this paper is to secure the user's data by using cloud-of clouds...|$|R
40|$|This paper {{presents}} {{a case study}} on how to apply ITIL availability management best practice to assess the end-to-end service availability in a tiered web service delivery environment. It also helps pinpoint the road blocks to the required service level and provide cost-effective solution for improved service delivery. An overview of basic ITIL <b>availability</b> management <b>concept</b> is provided along with the introduction to two key parameters, {{mean time between failure}} (MTBF) for reliability and mean time to repair (MTTR) for maintainability. Then a block diagram modeling approach for the overall information system availability assessment is presented. The block diagrams are used to describe the interrelationship among the components or subsystems to define a system model. The ITIL best practice approaches for availability management are discussed in detail in the case study. It demonstrates that the overall service availability is affected by the availability of information systems as well as applications and operational processes. The modeling approach is capable of gaining visibility on root cause of the service availability degradation, identifying risks in the existing information system, and providing support to future application development and infrastructure upgrade for high availability business services...|$|R
40|$|The Western Australian {{resources}} boom {{has created}} a demand for {{a large amount of}} domestic accommodations, known as mining camps. However, due to the absent infrastructure within the remote regions of Australia, the energy supply of these mining camps is expensive. In order to reduce the electricity consumption of the mining camps, the Smart Camp project was initiated. The system infrastructure consists of a home automation based controller, placed in each mining accommodation unit to reduce energy consumption, and a centralized management unit, coordinating the controllers. Due {{to the fact that the}} size and complexity of mining camps may grow over time, the provided infrastructure of the management unit has to be able to evolve. One possible solution is to design a system in the context of high availability and horizontal scalability. This paper proposes a horizontally scalable and high <b>availability</b> infrastructural <b>concept,</b> in the context of the Smart Camp project. This concept also utilizes cost effective open source solutions running on commodity hardware. Within the context of horizontal scalability and reliability, this paper provides an applied research outline of some of the real world considerations, such as open source based high availability, load balancing, and distributed database solutions...|$|R
40|$|This {{article is}} {{concerned}} with how people process text in {{the presence or absence}} of a relevant schema. In particular, we focus on the effects of schema <b>availability</b> and <b>concept</b> repetition on both on-line integration and memory for text. Subjects were required to read &quot;vague &quot; texts (like Bransford and Johnson's, 1972, well-known &quot;washing clothes &quot; story) and their reading time for each sentence in each text was recorded. Half the texts were preceded by a title that activated a relevant schema, whereas the other half were presented without relevant schemas. Overall, reading time per sentence was substantially longer when reading without a schema than with one. The amount of extra time needed to read a sentence when no schema was available was the same at all points in the story. Also, when no schema was available reading time per sentence decreased with the number of repeated concepts in the sentence, whereas when a schema was available concept repetition had little effect. These results, along with the finding that schemas facilitated recall, indicate that: (a) schemas affect on-line comprehension, not just recall; and (b) reading without a schema involves the use of repeated concepts to connect propositions and perhaps the use of an abstract default schema to aid integration...|$|R
40|$|We {{examined}} whether language {{affects the}} strength of a visual representation in memory. Participants studied a picture, read a story about the depicted object, and then selected out of two pictures the one whose transparency level most resembled that of the previously presented picture. The stories contained two linguistic manipulations that have been demonstrated to affect <b>concept</b> <b>availability</b> in memory, i. e., object presence and goal-relevance. The results show that described absence of an object caused people to select the most transparent picture more often than described presence of the object. This effect was not moderated by goal-relevance, suggesting that our paradigm tapped into the perceptual quality of representations rather than, for example, their linguistic availability. We discuss the implications of these findings within a framework of grounded cognition...|$|R
40|$|A {{detailed}} description and {{explanation of the}} operational availability parameter is presented. The fundamental mathematical basis for operational availability is developed, {{and its relationship to}} a system's overall performance effectiveness is illustrated within the context of identifying specific availability requirements. Thus, in attempting to provide a general methodology for treating both hypothetical and existing <b>availability</b> requirements, the <b>concept</b> of an <b>availability</b> state, in conjunction with the more conventional probability-time capability, is investigated. In this respect, emphasis is focused upon a balanced analytical and pragmatic treatment of operational availability within the system design process. For example, several applications of operational availability to typical aerospace systems are presented, encompassing the techniques of Monte Carlo simulation, system performance availability trade-off studies, analytical modeling of specific scenarios, as well as the determination of launch-on-time probabilities. Finally, an extensive bibliography is provided to indicate further levels of depth and detail of the operational availability parameter...|$|R
40|$|Abstract. Computational {{models of}} {{grounded}} language learning {{have been based}} on the premise that words and concepts are learned simultaneously. Given the mounting cognitive evidence for concept formation in infants, we argue that <b>availability</b> of pre-lexical <b>concepts</b> (learned from image sequences) leads to considerable computational efficiency in word acquisition. Key to the process is a model of bottom-up visual attention in dynamic scenes. Background learning and foreground segmentation is used to generate robust tracking and detect occlusion events. Trajectories are clustered to obtain motion event concepts, and object concepts (image schemas) are abstracted from the combined appearance and motion data. The set of acquired concepts under visual attentive focus are then correlated with contemporaneous commentary to learn the grounded semantics of words and multi-word phrasal concatenations from the narrative. We demonstrate that even based on a mere half hour of video (of a scene involving many occlusions), a number of rudimentar...|$|R
40|$|It {{is widely}} agreed that {{architecture}} documentation, independent of its form, {{is necessary to}} prescribe architectural concepts for development and to con-serve architectural information over time. However, very often architecture documentation is perceived as inadequate, too long, too abstract, too detailed, or simply outdated. While developers have tasks to develop certain features or parts of a system, they are confronted with architecture documents that globally de-scribe the architecture and use concepts like separation of concerns. Then, the developers have the hard task to find all information of the separated concerns and to synthesize the excerpt relevant for their concrete task. Ideally, they would get an architecture document, which is exactly tailored to their need of architectural information for their task at hand. Such documentation can however not be created by architects in reasonable time. In this paper, we propose an approach of modeling architecture and automatically synthesizing a tailored architecture documentation for each developer and each development task. Therefor architectural concepts are selected from the model based on the task and an interleaving of concepts is done. This makes for example all interfaces explicit, which a component has to implement in order to comply with security, <b>availability,</b> etc. <b>concepts.</b> The required modeling and automation is realized in the tool Enterprise Architect. We got already very positive feedback for this idea from practitioners and expect a significant improvement of implementation quality and architecture compliance...|$|R
40|$|The {{energy for}} {{sustaining}} life is released through the oxidation of glucose, fats, and proteins. A {{part of the}} energy released within each cell is stored as chemical energy of Adenosine Tri-Phosphate molecules, which is essential for performing life-sustaining functions, while the remainder is released as heat {{in order to maintain}} isothermal state of the body. Earlier literature introduced the <b>availability</b> <b>concepts</b> from thermodynamics, related the specific irreversibility and entropy generation rates to metabolic efficiency and energy release rate of organ k, computed whole body specific entropy generation rate of whole body at any given age as a sum of entropy generation within four vital organs Brain, Heart, Kidney, Liver (BHKL) with 5 th organ being the rest of organs (R 5) and estimated the life span using an upper limit on lifetime entropy generated per unit mass of body, σM,life. The organ entropy stress expressed in terms of lifetime specific entropy generated per unit mass of body organs (kJ/(K kg of organ k)) was used to rank organs and heart ranked highest while liver ranked lowest. The present work includes the effects of (1) two additional organs: adipose tissue (AT) and skeletal muscles (SM) which are of importance to athletes; (2) proportions of nutrients oxidized which affects blood temperature and metabolic efficiencies; (3) conversion of the entropy stress from organ/cellular level to mitochondrial level; and (4) use these parameters as metabolism-based biomarkers for quantifying the biological aging process in reaching the limit of σM,life. Based on the 7 -organ model and Elia constants for organ metabolic rates for a male of 84 kg steady mass and using basic and derived allometric constants of organs, the lifetime energy expenditure is estimated to be 2725 MJ/kg body mass while lifetime entropy generated is 6050 kJ/(K kg body mass) with contributions of 190; 1835. 0; 610; 290; 700; 1470 and 95 kJ/K contributed by AT-BHKL-SM-R 7 to 1 kg body mass over life time. The corresponding life time entropy stresses of organs are: 1. 2; 60. 5; 110. 5; 110. 5; 50. 5; 3. 5; 3. 0 MJ/K per kg organ mass. Thus, among vital organs highest stress is for heart and kidney and lowest stress is for liver. The 5 -organ model (BHKL and R 5) also shows similar ranking. Based on mitochondrial volume and 5 -organ model, the entropy stresses of organs expressed in kJ/K per cm 3 of Mito volume are: 12, 670; 5465; 2855; 4730 kJ/cm 3 of Mito for BHKL indicating brain to be highly stressed and liver to be least stressed. Thus, the organ entropy stress ranking based on unit volume of mitochondria within an organ (kJ/(K cm 3 of Mito of organ k)) differs from entropy stress based on unit mass of organ. Based on metabolic loading, the brains of athletes already under extreme mitochondrial stress and facing reduced metabolic efficiency under concussion are subjected to more increased stress. In the absence of non-intrusive measurements for estimating organ-based metabolic rates which can serve as metabolism-based biomarkers for biological aging (BA) of whole body, alternate methods are suggested for estimating the biological aging rate...|$|R
40|$|During {{the last}} decades we have seen an {{enormous}} growth of change <b>concepts</b> available. <b>Availability</b> of these <b>concepts</b> has grown considerably due to the ongoing globalization process. A growing amount of literature has recently been focusing on the processes of the spread of these concepts. We try to take this discussion further by analyzing the implementation of such a global change concept in a Norwegian oil company. The global change concept {{is based on a}} “Business Process Reengineering ” (BPR) implementation of an ERP-system. Our focus is the micro political processes that appear in the process were this global concept meets the local context, the realization of the concept into concrete action. The different perspectives, the different experiences and interests between affected actors cause processes of translations, interpretations, negotiations and constructions of meaning. The result is a complexity of agendas and understandings influencing the change initiatives. Through these discussions we illustrate the mechanisms affecting the implementation process and its unpredictability. ...|$|R
