152|344|Public
6000|$|Even from M. Comte's own work, {{numerous}} facts, admissions, and arguments, {{might be}} picked out, tending to show this. We have already quoted his words in proof that both abstract and concrete mathematics have progressed towards {{a higher degree}} of generality, and that he looks forward to a higher generality still. Just to strengthen this adverse hypothesis, let us take a further instance. From the particular case of the scales, the law of equilibrium of which was familiar to the earliest nations known, Archimedes advanced to the more general case of the unequal lever with unequal weights; the law of equilibrium of which includes that of the scales. By the help of Galileo's discovery concerning the composition of forces, D'Alembert [...] "established, for the first time, the equations of equilibrium of any system of forces applied to the different points of a solid body"--equations which include all cases of levers and an infinity of cases besides. Clearly this is progress towards a higher generality--towards a knowledge more independent of special circumstances--towards a study of phenomena [...] "the most disengaged from the incidents of particular cases;" [...] which is M. Comte's definition of [...] "the most simple phenomena." [...] Does it not indeed follow from the familiarly admitted fact, that mental advance is from the concrete to the abstract, from the particular to the general, that the universal and therefore most simple truths are the last to be discovered? Is not the government of the solar system by a force varying inversely as the square of the distance, a simpler conception than any that preceded it? Should we ever succeed in reducing all orders of phenomena to some single law--say of <b>atomic</b> <b>action,</b> as M. Comte suggests--must not that law answer to his test of being independent of all others, and therefore most simple? And would not such a law generalise the phenomena of gravity, cohesion, atomic affinity, and electric repulsion, just as the laws of number generalise the quantitative phenomena of space, time, and force? ...|$|E
5000|$|... {{a process}} {{deleting}} node B requires an <b>atomic</b> <b>action</b> on the node's predecessor ...|$|E
50|$|If {{a script}} is more complicated, {{it can be}} broken down to several scripts and a {{hierarchical}} FSM can be exploited. In such an automaton, every state can contain substates. Only the states at the atomic level are associated with a script (which is not complicated) or an <b>atomic</b> <b>action.</b>|$|E
40|$|<b>Atomic</b> <b>actions</b> {{represents}} {{a powerful tool}} for system structuring, controlling accesses to shared data implementing backward error recovery techniques. In this paper properties of <b>atomic</b> <b>actions</b> are analyzed, specifically referring to crash recovery problems. In order to guarantee consistency of shared data in spite of crashes, programs implementing <b>atomic</b> <b>actions</b> must satisfy some constraints...|$|R
30|$|RTI 1 –RTI 5 are the {{defining}} equations for the abstraction operator τ _I: RTI 2 and RTI 4 {{says that it}} renames <b>atomic</b> <b>actions</b> from I into τ, while RTI 1, RTI 3, RTI 5 say that it leaves <b>atomic</b> <b>actions</b> outside I and the deadlock δ unchanged.|$|R
40|$|The paper {{presents}} a general model for persistent replicated object management and identifies what meta information about objects {{needs to be}} maintained by a naming and binding service to ensure that objects named by application programs are bound to only those object replicas which are in a mutually consistent state. These ideas are developed {{within the framework of}} a distributed system in which application programs are composed of <b>atomic</b> <b>actions</b> (<b>atomic</b> transactions) manipulating persistent (long-lived) objects. Key words persistent objects, <b>atomic</b> <b>actions,</b> distributed systems, replication, naming and binding. 1. Introduction We consider a distributed system in which application programs are composed out of <b>atomic</b> <b>actions</b> (<b>atomic</b> transactions) manipulating persistent (long-lived) objects. <b>Atomic</b> <b>actions</b> ensure that only consistent state changes to objects take place despite failures such as node crashes. Objects not in use normally remain in a passive state: their states are stored i [...] ...|$|R
5000|$|E-block: A {{block for}} {{evaluating}} the trigger conditions associated with each transition. The input signals to this block are the data variables, while the output {{is a set of}} binary signals taken for input by the FSM-block. Information about redundant computation is extracted by analyzing the interactions among the three basic blocks. Using this information, certain input operands of the arithmetic block and evaluation block can be frozen through input gating under specific run time conditions to reduce the unnecessary switching in the design. At the architecture level, if each trigger evaluation & data operation is regarded as an <b>atomic</b> <b>action,</b> then the EFSM implies an almost lowest-power implementation.|$|E
5000|$|Astro Boy became Tezuka's {{most famous}} work. Frederik L. Schodt, {{author of the}} English-language version of Astro Boy, said it had [...] "extraordinary {{longevity}} and appeal across cultures." [...] Schodt said {{that many of the}} stories are [...] "sometimes" [...] of [...] "uneven quality." [...] Schodt said that as the time becomes closer to [...] "a true age of robots," [...] Astro Boy assumes more meaning. Jeff Yang of the San Francisco Chronicle, in discussing Schodt's The Astro Boy Essays, said [...] "while kids came for Astro's <b>atomic</b> <b>action</b> - just about every installment included Astro harrowing a fellow robot who'd fallen from digital grace with his fission-powered fists - they stayed for the textured, surprisingly complex stories." ...|$|E
50|$|There are {{two ways}} of how to produce {{behaviour}} by a FSM. They depend on what {{is associated with the}} states by a designer --- they can be either 'acts', or scripts. An 'act' is an <b>atomic</b> <b>action</b> that should be performed by the agent if its FSM is the given state. This action is performed in every time step then. However, more often is the latter case. Here, every state is associated with a script, which describes a sequence of actions that the agent has to perform if its FSM is in a given state. If a transition activates a new state, the former script is simply interrupted, and the new one is started.|$|E
5000|$|Activities can be {{decomposed}} into subactivities, {{until at}} the bottom we find <b>atomic</b> <b>actions.</b>|$|R
5000|$|... {{introduces}} the [...] and [...] primitives, allowing alternative <b>atomic</b> <b>actions</b> to be composed together.|$|R
30|$|In this section, we take {{an example}} of {{renaming}} operators which are used to rename the <b>atomic</b> <b>actions.</b>|$|R
40|$|International audienceThe dynamic {{description}} logic DDL {{provides a}} kind of action theories based on description logics (DLs). Compared with another important DL-based action formalism constructed by Baader et. al., a shortcoming of DDL {{is the absence of}} occlusions and conditional post-conditions in the description of atomic actions. In this paper, we extend <b>atomic</b> <b>action</b> definitions of DDL to overcome this limitation. Firstly, we introduce extended <b>atomic</b> <b>action</b> definitions in which the occlusions and conditional post-conditions are incorporated. Secondly, for each <b>atomic</b> <b>action</b> specified by an extended <b>atomic</b> <b>action</b> definition, a function named Expand is introduced to transform it into a choice action which is composed of atomic actions defined by ordinary <b>atomic</b> <b>action</b> definitions. Finally, based on the Expand function, the satisfiability-checking algorithm of DDL is extended to support occlusions and conditional post-conditions...|$|E
30|$|The first {{transition}} rule says that each history of an <b>atomic</b> <b>action</b> υ [m] can reverse successfully, {{and leads to}} an <b>atomic</b> <b>action</b> υ. Similarly, the reverse {{transition rule}} /υ [m] ^υ [m]υ implies a successful reverse.|$|E
40|$|Inspired by the {{properties}} of the refinement development of the Mondex Electronic Purse, we view an <b>atomic</b> <b>action</b> as a family of transitions with a common before-state, and different after-states corresponding to different possible outcomes when the action is attempted. We view a protocol for an <b>atomic</b> <b>action</b> as a computation tree, each branch of which achieves in several steps, one of the outcomes of the <b>atomic</b> <b>action.</b> We show that in this picture, the protocol {{can be viewed as a}} relational refinement of the <b>atomic</b> <b>action</b> in a number of ways. Firstly, it yields a ‘big diagram ’ simulation à la ASM. Secondly, it yields a ‘small diagram’ simulation, in which the <b>atomic</b> <b>action</b> is synchronised with an individual step along each path through the protocol, and all the other steps of the path simulate skip. We show that provided each path through the protocol contains one step synchronised with the <b>atomic</b> <b>action,</b> the choice of synchronisation point can be made freely. We describe the relationship between such synchronisations and forward and backward simulations. We relate this theory to serialisations of system runs containing multiple transactions, and show how existing Mondex refinements embody the ideas developed...|$|E
40|$|Abstract. Many {{parallel}} {{programs are}} {{expressed in terms of}} conditional <b>atomic</b> <b>actions</b> with different degrees of atomicity. It is known that these synchronization primitives are expensive to implement in its fully generality [2]. Many platforms provide an efficient set of synchronization primitives. Semaphores are a very special case of conditional <b>atomic</b> <b>actions</b> which can be considered a canonical synchronization primitive. There exist methods to transform general conditional <b>atomic</b> <b>actions</b> into these very special ones. One of the simplest is the Change of Variables method introduced in [1, 2] and generalized in [10]. We review and improve this method in the context of formal development of multiprograms [4, 7]. Keywords: Program transformation; Semaphore synchronization; Multiprograms; Program derivation; Theory of Owicki and Gries; Efficien...|$|R
30|$|In GLARE, we {{distinguish}} between <b>atomic</b> and composite <b>actions</b> (plans), where <b>atomic</b> <b>actions</b> represent simple steps in a CIG, and plans represent actions {{that can be}} {{defined in terms of}} their components via the “has-part” relation.|$|R
30|$|RD 6 -RD 8 {{say that}} in ∂ _H(t), all {{transitions}} of t labelled with <b>atomic</b> <b>actions</b> from H are blocked.|$|R
40|$|Inspired by the {{properties}} of the refinement development of the Mondex Electronic Purse, we view an isolated <b>atomic</b> <b>action</b> as a family of transitions with a common before-state, and different after-states corresponding to different possible outcomes when the action is attempted. We view a protocol for an <b>atomic</b> <b>action</b> as a computation DAG, each path of which achieves in several steps one of the outcomes of the <b>atomic</b> <b>action.</b> We show that in this picture, the protocol {{can be viewed as a}} relational refinement of the <b>atomic</b> <b>action</b> in a number of ways. Firstly, it yields a ‘big diagram ’ simulation à la ASM. Secondly, it yields a ‘small diagram ’ simulation, in which the <b>atomic</b> <b>action</b> is synchronised with an individual step along each path through the protocol, and all the other steps of the path simulate skip. We show that provided each path through the protocol contains one step synchronised with the <b>atomic</b> <b>action,</b> the choice of synchronisation point can be made freely. We describe the relationship between such synchronisations and forward and backward simulations. We relate this theory to serialisations of system runs containing multiple interleaved transactions, showing how the clean picture of the refinement of an isolated <b>atomic</b> <b>action</b> to an isolated protocol becomes obscured by the details of the interleaving. In effect, the fact that protocols are typically executed by a number of co-operating agents, not all of which embark on executing the protocol at the same moment, results in ‘ragged starts’ and ‘ragged ends’ to protocol instantiations, leading to potential overlaps between unrelated protocol instances that the theory must handle. We show how existing Mondex refinements embody the ideas developed, an...|$|E
40|$|International audienceInspired by the {{properties}} of the refinement development of the Mondex Electronic Purse, we view an isolated <b>atomic</b> <b>action</b> as a family of transitions with a common before-state, and different after-states corresponding to different possible outcomes when the action is attempted. We view a protocol for an <b>atomic</b> <b>action</b> as a computation DAG, each path of which achieves in several steps one of the outcomes of the <b>atomic</b> <b>action.</b> We show that in this picture, the protocol {{can be viewed as a}} relational refinement of the <b>atomic</b> <b>action</b> in a number of ways. Firstly, it yields a ‘big diagram' simulation à la ASM. Secondly, it yields a ‘small diagram' simulation, in which the <b>atomic</b> <b>action</b> is synchronised with an individual step along each path through the protocol, and all the other steps of the path simulate. We show that provided each path through the protocol contains one step synchronised with the <b>atomic</b> <b>action,</b> the choice of synchronisation point can be made freely. We describe the relationship between such synchronisations and forward and backward simulations. We relate this theory to serialisations of system runs containing multiple interleaved transactions, showing how the clean picture of the refinement of an isolated <b>atomic</b> <b>action</b> to an isolated protocol becomes obscured by the details of the interleaving. In effect, the fact that protocols are typically executed by a number of co-operating agents, not all of which embark on executing the protocol at the same moment, results in ‘ragged starts' and ‘ragged ends' to protocol instantiations, leading to potential overlaps between unrelated protocol instances that the theory must handle. We show how existing Mondex refinements embody the ideas developed, and describe a mechanical verification of the results presented...|$|E
30|$|If n is an <b>atomic</b> <b>action,</b> then it {{does not}} contain any {{parallel}} operators.|$|E
30|$|RTI 6 –RTI 7 {{say that}} in τ _I(t), all {{transitions}} of t labelled with <b>atomic</b> <b>actions</b> from I are renamed into τ.|$|R
50|$|Arvind's {{research}} interests include verification of large-scale digital systems using Guarded <b>Atomic</b> <b>Actions,</b> Memory Models and Cache Coherence Protocols for parallel architectures and languages.|$|R
40|$|Atomic delegation, an {{object-oriented}} linguistic {{mechanism that}} allows the creation of dynamically defined classes of <b>atomic</b> <b>actions</b> is presented. When a type is modified, atomic delegation updates functionalities of the the types that delegate to the modified type. This mechanism permits dynamic binding and code reuse in <b>atomic</b> <b>actions.</b> The Sina language is used to illustrate the utility of atomic delegation in the modeling of a real-world problem, involving an office {{with a number of}} departments, using object-oriented techniques. Implementation issues are discusse...|$|R
30|$|BRPA {{includes}} three kind of operators: {{the execution of}} <b>atomic</b> <b>action</b> a, the choice composition operator + and the sequential composition operator ·. Each finite process can be represented by a closed term that is built from the set A of atomic actions or histories of an <b>atomic</b> <b>action,</b> the choice composition operator +, and the sequential composition operator ·. The collection of all basic process terms is called Basic Reversible Process Algebra (BRPA), which is abbreviated to BRPA.|$|E
30|$|The first {{transition}} rule says that each <b>atomic</b> <b>action</b> υ can execute successfully, {{and leads to}} a history υ [m]. The forward {{transition rule}} /υυυ [m] implies a successful forward execution.|$|E
30|$|In {{comparison}} to ACP, {{it is almost}} a brand new algebra for reversible computation which has the same advantages of ACP, such as modularity, axiomatization, etc. Firstly, in RACP, the alternative composition is replaced by choice composition, since in reversible computing, all choice branches should be retained. Secondly, the parallel operator cannot be captured by an interleaving semantics. Thirdly, more importantly to establish a full axiomatization, all the atomic actions are distinct, the same <b>atomic</b> <b>action</b> in different branches (including choice branches and parallel branches) will be deemed as the same one <b>atomic</b> <b>action.</b> Also auto-concurrency is out of scope for our work here.|$|E
40|$|A common {{technique}} for constructing reliable distributed applications {{is to use}} <b>atomic</b> <b>actions</b> for controlling operations on persistent objects. <b>Atomic</b> <b>actions</b> are used to ensure that inconsistencies in application state do not arise when failures occur or when concurrent activities operate on shared objects. Within such an application, objects provide a convenient unit for distribution and concurrency-control. The properties of <b>atomic</b> <b>actions</b> and objects can be exploited together to configure distributed applications, without affecting the correct functioning of the application. This leads {{to the possibility of}} changing the configuration of concurrency and distribution of the distributed application to improve availability and performance. These changes in concurrency and distribution can be achieved by varying the object decomposition within the application. In this paper, we show how some kinds of reconfiguration can be achieved without any modification to client applications. The o [...] ...|$|R
40|$|Arjuna is a fault {{tolerant}} distributed system supporting nested <b>atomic</b> <b>actions</b> (nested <b>atomic</b> transactions) {{that are used}} for controlling operations on objects (instances of C++ classes). Objects are long lived entities (persistent) and are the main repositories for holding system state; {{they are also the}} units of replication for increasing availability. This paper describes the design and implementation of two object replication schemes for Arjuna. Support for replication is provided by a naming and binding service for persistent replicated objects that ensures that applications only ever get to use mutually consistent copies of replicas. Key words <b>Atomic</b> <b>actions,</b> active replication, passive replication, persistent objects. 2 1. Introduction Arjuna is a distributed system, implemented in C++, that provides facilities for constructing applications using persistent objects which can be manipulated under the control of <b>atomic</b> <b>actions</b> (<b>atomic</b> transactions) [1]. Fault tolerance is necess [...] ...|$|R
40|$|The University of Rochester's Rhino {{system is}} a locally {{organized}} cooperative agent architecture that uses observation as its primary means of inter-agent coordination. Observing agents recognize on-going individual actions, and from sequences of actions reason about likely on-going plans. Sets of individual plans are combined to form hypothesized group plans. A key element in the group plan inference process is the recognition of individual agents' actions. Action recognition {{is the problem of}} describing an observed agent's activity as goal-directed behavior. <b>Atomic</b> <b>actions</b> are those whose effects occur instantaneously; composite actions take place over time. This paper proposes a knowledge-based, Bayesian technique for describing, detecting and classifying <b>actions.</b> To recognize <b>atomic</b> <b>actions,</b> we use Bayes nets to detect the corresponding instantaneous changes in world state. Composite actions are recognized by hidden Markov models, which describe them as sequences of <b>atomic</b> <b>actions</b> [...] . ...|$|R
40|$|Although {{the number}} of {{proposals}} discussing various <b>atomic</b> <b>action</b> schemes is increasing, these schemes are very rarely used in designing practical applications. To a large extent, this is {{accounted for by the}} gap existing between the languages used in research and the standard or widely spread languages (e. g. C, C++, Ada 83, Ada 95, Java) employed by practitioners. Moreover, very often researchers extend languages with new features or invent new languages to express their ideas better. Even though these approaches seem to be quite natural, they widen the gap between practice and research. To bridge this gap, we should consider fault tolerance schemes in terms of a standard language, taking the language itself for granted. The question which we believe should be addressed is how to use/implement a particular scheme in these languages rather than how to modify the language. Only in this way the schemes could be used directly and the application domains of <b>atomic</b> <b>action</b> schemes extended. The main intention {{of this paper is to}} summarise research that has been done in the last years in designing various <b>atomic</b> <b>action</b> an...|$|E
40|$|Coordinated Atomic {{actions have}} proved to be a very general concept which can be {{successfully}} applied for structuring complex concurrent systems consisting of elements which both cooperate and compete. The canonical Coordinated <b>Atomic</b> <b>action</b> is built of several cooperating participants (roles) and a set of local objects which represent the action state and provide the feature for cooperation. In addition, Coordinated Atomic actions can compete for external objects which have conventional transactional properties. The intention {{of this paper is to}} offer a general approach to designing distributed Coordinated <b>Atomic</b> <b>action</b> schemes. Problems of action components partitioning and distribution are discussed. We consider ways of dealing with external and local objects within distributed Coordinated <b>Atomic</b> <b>action</b> schemes; several proposals are discussed in detail. The approach proposed relies on using forward error recovery in the form of distributed and concurrent exception handling and resolution. After discussing the general approach, we demonstrate how it can be applied when the standard distributed model of Ada 95 is used. The presentation of the scheme is sufficiently detailed for it to be used in practice. In particular, a thorough description of the action support and all patterns (skeletons) required for designing application software are given...|$|E
40|$|The {{state of}} art in {{handling}} and resolving concurrent exceptions is discussed and a brief outline of all {{research in this area}} is given. Our intention is to demonstrate that exception resolution is a very useful concept which facilitates joint forward error recovery in concurrent and distributed systems. To do this, several new arguments are considered. We understand resolution as reaching an agreement among cooperating participants of an <b>atomic</b> <b>action.</b> It is provided by the underlying system to make it unified and less error prone, which is important for forward error recovery, complex by nature. We classify <b>atomic</b> <b>action</b> schemes into asynchronous and synchronous ones and discuss exception handling for schemes of both kinds. The paper also deals with introducing <b>atomic</b> <b>action</b> schemes based on exception resolution into existing concurrent and distributed languages, which usually have only local exceptions. We outline the basic approach and demonstrate its applicability by showing how exception resolution can be used in Ada 83, Ada 95 (for both concurrent and distributed systems) and Java. A discussion of ways to make this concept more object oriented and, with the help of reflection, more flexible and useful, concludes the paper...|$|E
40|$|Record // Important utility class RecoveryRecord // handles object {{recovery}} LockRecord // handles object locking 5 RecordList // Intentions list other management record types 3. 6 Building transactional applications The API relieves programmers {{from having}} to explicitly register resources with a transaction. Neither {{do they have to}} manage persistence or concurrency control, which are managed on their behalf by the JavaArjuna classes StateManager and LockManager. To make use of <b>atomic</b> <b>actions</b> in an application, instances of the class AtomicAction must be declared by the programmer. The operations this class provides (begin, abort, commit) can then be used to start and manipulate <b>atomic</b> <b>actions</b> (including nested actions). The only objects controlled by the resulting <b>atomic</b> <b>actions</b> are those objects which are either instances of JavaArjuna classes or are user-defined classes derived from LockManager and hence are members of the hierarchy shown previously. Most JavaArjuna system classe [...] ...|$|R
40|$|Record // Important utility class RecoveryRecord // handles object {{recovery}} LockRecord // handles object locking RecordList // Intentions list other management record types To {{make use}} of <b>atomic</b> <b>actions</b> in an application, instances of the class AtomicAction must be declared by the programmer in the application as illustrated earlier. The operations this class provides (Begin, Abort, End) can then be used to start and manipulate <b>atomic</b> <b>actions</b> (including nested actions). The only objects controlled by the resulting <b>atomic</b> <b>actions</b> are those objects which are either instances of Arjuna classes or are user-defined classes derived from LockManager and hence {{are members of the}} hierarchy shown above. Most Arjuna system classes are derived from the base class StateManager, which provides primitive facilities necessary for managing persistent and recoverable objects. These facilities include support for the activation and de-activation of objects, and state-based object recovery. Thus, instanc [...] ...|$|R
40|$|Abstract. We {{examine the}} role of {{transactional}} memory from two perspectives: that of a programming language with <b>atomic</b> <b>actions</b> and that of implementations of the language. We {{argue that it is}} difficult to formulate a clean, separate, and generally useful definition of transactional memory. In both programming-language semantics and implementations, the treatment of <b>atomic</b> <b>actions</b> benefits from being combined with that of other language features. In this respect (as in many others), transactional memory is analogous to garbage collection, which is often coupled with other parts of language runtime systems. ...|$|R
