28|460|Public
5000|$|Plato's {{explanation}} of why the deepest truths cannot be expressed in written form is famously abstruse. Before one attains the [...] "thing which is cognizable and true" [...] (gnōston te kai alēthes), one must have apprehended the [...] "name," [...] "account" [...] (logos), [...] "image," [...] and [...] "knowledge" [...] (epistēmē). Name and account are approached through verbal description, while sense perception perceives the image. One attains knowledge only from the combination of verbal description and sense perception, and one must have knowledge before one can attain the object of knowledge (which Plato calls simply [...] "the Fifth," [...] name, <b>account,</b> <b>image,</b> and knowledge being [...] "the Four"). The Fifth, moreover, differs from what is sensible and verbal expressions of it. Name and account provide the [...] "quality" [...] of a thing (to poion), but not its [...] "essence" [...] or [...] "being" [...] (to on). They are, moreover, akin to sense perceptions {{in that they are}} ever shifting and relative, not fixed. As a result, the student who attempts to understand the Fifth through name, <b>account,</b> <b>image,</b> and knowledge is confused; he seeks the essence, but always finds the quality intruding. Only certain kinds of student can scrutinize the Four, and even then the vision of the Fifth comes by a sudden flash.|$|E
50|$|No {{telescope}} {{can form}} a perfect image. Even if a reflecting telescope {{could have a}} perfect mirror, or a refracting telescope could have a perfect lens, the effects of aperture diffraction are unavoidable. In reality, perfect mirrors and perfect lenses do not exist, so image aberrations in addition to aperture diffraction {{must be taken into}} <b>account.</b> <b>Image</b> aberrations can be broken down into two main classes, monochromatic, and polychromatic. In 1857, Philipp Ludwig von Seidel (1821 - 1896) decomposed the first order monochromatic aberrations into five constituent aberrations. They are now commonly referred to as the five Seidel Aberrations.|$|E
40|$|Introduction to Image Processing and the MATLAB EnvironmentIntroduction Digital Image Definitions: Theoretical <b>Account</b> <b>Image</b> Properties MATLAB Algorithmic Account MATLAB CodeImage Acquisition, Types, and File I/OImage Acquisition Image Types and File I/O Basics of Color Images Other Color Spaces Algorithmic Account MATLAB CodeImage ArithmeticIntroduction Operator Basics Theoretical TreatmentAlgorithmic Treatment Coding ExamplesAffine and Logical Operations, Distortions, and Noise in ImagesIntroduction Affine Operations Logical Operators Noise in Images Distortions in ImagesAlgorithmic Accoun...|$|E
50|$|Imgur {{used to have}} {{a policy}} to keep images unless they went three months without {{receiving}} any views, at which point (unless they were Pro <b>account</b> <b>images)</b> they might be removed in response to space needs. In early 2015 it was announced all images will be kept forever (even if not added from a Pro account) and only removed if deletion is requested.|$|R
50|$|By one <b>account,</b> the <b>image</b> of the Madonna {{was moved}} to Montserrat in 718, to avoid the danger posed by invading Saracens.|$|R
30|$|See Johnson 2007 : 144 – 145 for {{a summary}} <b>account</b> of <b>image</b> schemas. For {{a partial list}} of image schemata, see Johnson 1987 : 126.|$|R
40|$|In this paper, {{we propose}} a unified {{optimization}} framework for feature extraction that lets us simultaneously take into <b>account</b> <b>image</b> data and semantic knowledge: We model objects using {{a language that}} specifies both photometric and geometric constraints and define an information-theoretic objective function that measures the fit of the models to the data. We then treat the problem of finding objects as one of generating the optimal description of the image {{in terms of this}} language. We hav...|$|E
3000|$|Since {{the early}} papers {{describing}} the potential gain of TOF-PET, several studies {{were performed to}} validate this gain. The effective sensitivity gain was described in [4] as the ratio between the object size D and the spatial FWHM of the TOF kernel △x. Another paper (taking into <b>account</b> <b>image</b> reconstruction) by Tomitani predicts a smaller gain of D 1.6 [...] x. A recent lesion detectability study [20] using simulated data found the gain in non-pre whitening SNR (NPW-SNR) to correlate well with the gain predicted by Tomitani.|$|E
40|$|ISBN: 978 - 146732533 - 2 International audienceWe present here {{discrete}} {{and continuous}} partial differential equation (PDE) -based methods for image enhancement/ sharpening. Using more robust and spatially adaptive PDEs, multiscale morphological operators that <b>account</b> <b>image</b> features are introduced, and then, {{used to provide}} a discrete enhancement operator, thanks to the former Kramer and Bruckner filter. A novel PDE associated to the introduced enhancement operator is established in 2 D. Both the discrete and PDE-based sharpening filters are illustrated on synthetic, binary and real images...|$|E
5000|$|Number of {{pictures}} - Ordinarily, up to 1 GB of total storage, shared with Picasa Web. If you've upgraded to Google+, your photos will {{be stored in}} Google Photos, where you have 15 GB of storage space shared with Gmail and Drive. However, if one has signed up for Google+ <b>account,</b> <b>images</b> less than 16 megapixels (4920 x 3264) would not be counted to this storage limit. For users not signed up for Google+, 800 x 800 pixels and below images would not be included in this storage space.|$|R
3000|$|We {{describe}} an automatic image enhancement technique based on features extraction methods. The approach takes into <b>account</b> <b>images</b> in Bayer data format, captured using a CCD/CMOS sensor and/or 24 -bit color images; after identifying the visually significant features, the algorithm adjusts the exposure level using a [...] "camera response"-like function; then a final HUE reconstruction is achieved. This method {{is suitable for}} handset devices acquisition systems (e.g., mobile phones, PDA, etc.). The process is also suitable to solve some of the typical drawbacks due to several factors such as poor optics, absence of flashgun, and so forth.|$|R
40|$|We {{describe}} an automatic image enhancement technique based on features extraction methods. The approach takes into <b>account</b> <b>images</b> in Bayer data format, captured using a CCD/CMOS sensor and/or 24 -bit color images; after identifying the visually significant features, the algorithm adjusts the exposure level using a &# 147; camera response &# 148;-like function; then a final HUE reconstruction is achieved. This method {{is suitable for}} handset devices acquisition systems (e. g., mobile phones, PDA, etc.). The process is also suitable to solve some of the typical drawbacks due to several factors such as poor optics, absence of flashgun, and so forth. </p...|$|R
40|$|We {{present an}} {{approach}} for exploiting user labels with random field level sets in image segmentation. A sparse {{set of user}} labels is propagated {{to the rest of}} the image by computing a generalized distance transform which takes into <b>account</b> <b>image</b> intensity information. The region-based level set formulation is modified to use random field level sets whose range is restricted to the probability values. These two ideas are combined in a single level set functional. Improved results are shown on a liver segmentation task. International Symposium on Biomedical Imagin...|$|E
40|$|We {{propose a}} modular and {{scalable}} framework for dense coregistration and cosegmentation with two key characteristics: first, we substitute ground truth data with the semantic map output of a classifier; second, we combine this output with population deformable registration to improve both alignment and segmentation. Our approach deforms all volumes towards consensus, taking into <b>account</b> <b>image</b> similarities and label consistency. Our pipeline can incorporate any classifier and similarity metric. Results on two datasets, containing annotations of challenging brain structures, demonstrate {{the potential of}} our method. Comment: The first two authors contributed equall...|$|E
40|$|A multi-scale {{statistical}} non-redundancy modeling {{approach is}} introduced for saliency detection in images. The statisti-cal non-redundancy of pixels at different wavelet sub-bands is characterized using a multi-dimensional lattice of non-parametric statistical models, thus taking into <b>account</b> <b>image</b> saliency at multiple scales. This identifies saliency in image attributes at multiple scales, and makes saliency detection strongly robust against noisy input images. Results based on images {{from a public}} database show that the proposed approach outperforms existing single and multi-scale ap-proaches, particularly when dealing with noisy images. Index Terms — multi-scale analysis, non-parametric methods, wavelet transforms, saliency detection 1...|$|E
50|$|The above {{algorithm}} {{does not}} <b>account</b> for <b>images</b> containing {{an object that}} is partially occluded. The following algorithm assumes that all contours are rigidly coupled, meaning the pose of one contour defines the pose of another contour.|$|R
50|$|In {{surrounding}} villages, {{many residents}} fled immediately. According to Yazidis, ISIL fighters asked the remaining Yazidis {{to convert to}} Islam or face death, and ISIL Twitter <b>accounts</b> posted <b>images</b> of murders on individuals in the Sinjar area.|$|R
3000|$|... is {{calculated}} by filling the bins {{with the standard}} deviation values for each frame in FBR 1. This method then provides normalized features that also take into <b>account</b> the <b>image</b> and motion, {{and can be used}} as inputs to a classifier.|$|R
40|$|Part 2 : WorkshopInternational audienceIn {{this paper}} authors present their new {{proposition}} of system for cognitive analysis of dynamic computer tomography perfusion maps (dpCT). The novel contribution {{of this article}} is introducing an augmented reality visualization module that supports real time volume rendering (VR) of derived data. Authors also presents the results of their researches on optimization of VR algorithm memory usage by dynamic computation of volume gradient instead of pre-generation of gradient Authors compare five different discrete gradient computation schemas taking into <b>account</b> <b>image</b> quality and processing speed on two VR algorithms: volume ray casting and texture based visualization with view aligned slices...|$|E
40|$|In {{this paper}} we propose two {{algorithms}} {{for the restoration of}} images based on the bispectrum. The bispectrum of a signal is the Fourier transform of its triple correlation. While second-order statistics (e. g., correlation function, power spectrum, etc.) do not provide any information about the phase of the signal, third-order statistics (e. g., triple correlation, bispectrum, etc.) allow the recovery of the phase of the signal. We propose two algorithms for estimating the magnitude and the phase of the image, where the ambiguity due {{to the use of the}} principal value of the phase component is taken into <b>account.</b> <b>Image</b> lines are used in our experiments to test the effectiveness of the proposed algorithms. 1...|$|E
40|$|International audienceSeveral {{modifications}} of scatter-plot-based method for mixed noise parameters estimation are proposed. The modifications {{relate to the}} stage of image segmentation and {{they are intended to}} adaptively separate image blocks into clusters taking into <b>account</b> <b>image</b> peculiarities and to choose a required number of clusters. Comparative performance analysis of the proposed modifications for images from TID 2008 database is performed. It is shown that the best estimation accuracy is provided by a method with automatic determination of a required number of clusters followed by block separation into clusters using k-means method. This modification allows improving the accuracy of noise characteristics estimation by up to 5 % for both signal-independent and signal-dependent noise components in comparison to the basic method. The results for real-life data are presented. © 2016 SPIE. ...|$|E
30|$|An {{important}} aspect to {{be pointed out}} is that the execution time ratio for the tasks is constant even when changing the image size. This fact allows using the same approach when parallelization is addressed, without taking into <b>account</b> the <b>image</b> size.|$|R
50|$|The {{community}} was so named on <b>account</b> of the <b>image</b> of a buckhorn {{on a local}} tavern sign.|$|R
40|$|International audienceA {{method is}} {{presented}} here for modeling and predicting the rolling and yaw behavior of an aircraft tire which {{is subjected to}} a strong inflation pressure and a concentrated load on the axle, in contact with a flat, rigid surface. Finite element methods were used to model and simulate the aircraft tire/ground interactions. The incompressibility of the material, the large transformations and the unilateral contact with Coulomb friction law were all taken into <b>account.</b> <b>Imaging</b> methods were {{used to examine the}} complex structure of the tire cross-section. Comparisons are made between the data obtained with the model, the experimental data and those provided by the manufacturer. The tire response predictions were found to depend considerably on the material and the geometrical characteristics of the tire...|$|R
40|$|We study {{suspensions}} of hydrophobic charged colloidal spheres dispersed in a demixed oil-water mixture {{by means}} of a modified Poisson-Boltzmann theory, taking into <b>account</b> <b>image</b> charge effects and partitioning of the monovalent ions. We find that the ion's aversion for oil can destroy the double layers of the oil-dispersed colloids. This affects the salt-concentration dependence of the colloidal adsorption to the oil-water interface qualitatively. The theory also predicts a narrow range of the oil-dielectric constant in which micron-sized water-in-oil droplets acquire enough charge to crystallize at volume fractions as small as ∼ 10 ^- 3 in the absence of colloids. These findings explain recent observations [M. E. Leunissen et al., Proc. Nat. Ac. Sci 104, 2585 (2007) ]. Comment: 4 pages, 2 figures (figure 1 a, 1 b, 2...|$|E
40|$|In this paper, {{we propose}} a unified {{optimization}} framework for feature extraction that lets us simultaneously take into <b>account</b> <b>image</b> data and semantic knowledge: We model objects using {{a language that}} specifies both photometric and geometric constraints and defines an information-theoretic objective function that measures the fit of the models to the data. We then treat the problem of finding objects as one of generating the optimal description of the image {{in terms of this}} language. We have validated our framework by performing extensive experiments on detecting objects in aerial imagery described by simple geometric constraints and have developed two algorithms for generating optimal descriptions. The first one starts with a rough sketch of a polygonal object and deforms the initial contour to maximize the objective function, thus finding object outlines. The second one automatically extracts complex rectilinear buildings from complex aerial images...|$|E
40|$|The chapter aims {{to point}} out the most {{emerging}} technologies in analysing and sharing knowledge about ‘not outstanding’ cultural landscapes. Therefore the chapter starts focusing on the concept of ‘minor’ cultural landscapes in the wider debate on heritage, then shows the changing approach to the question: the relevance of bottom-up vision in considering heritage. Secondly are taken into <b>account</b> <b>image</b> and information technologies through some definite research topics: Educating by multimedia; Experiencing and sharing new contents by people; Transmitting local heritage; Using image and information technologies to share collective experiences of places; Answering demand for social participation and free access to sources; Connecting tangible and intangible heritage in a tourist perspective. The goal of the chapter is to show how digital technologies can support knowledge and share of values about ‘minor’ cultural landscapes both through inhabitants and potential tourists to be attracted to...|$|E
5000|$|... (1998) Do You Know What’s Happened? Personal <b>Accounts</b> and <b>Images</b> of the Troubles. (Output of the Cost of the Troubles Study) Opened November, 1998 by Secretary of State for NI, Dr Marjorie Mowlam, The Great Hall, Belfast City Hall; toured venues, {{including}} House of Commons, Westminster, Glasgow, Dublin.|$|R
50|$|On March 3, 2015, Jennifer Lopez teased the song's {{official}} music video, posting {{images from}} the shoot on her Instagram <b>account.</b> The <b>images</b> showed her wearing a white suit, {{standing in front of}} a green screen and sporting a braid. Erin Strecker of Billboard noted that the shoot appears to be intergalactic.|$|R
40|$|Speckle {{reduction}} {{is a key}} step in several SAR image processing procedures. In this paper, a new despeckling technique based on the “nonlocal” denoising filter BM 3 D is presented. The filter has been modified {{in order to take}} into <b>account</b> SAR <b>image</b> characteristics. The experimental results, conducted on both synthetic and real SAR images, confirm the potential of the proposed approach...|$|R
40|$|International audienceIn this paper, {{we propose}} a new {{formalism}} that enables {{to take into}} <b>account</b> <b>image</b> textural features in a very robust and selective way. This approach also permits to visualize these features so experts can efficiently supervise an image segmentation process based on texture analysis. The texture concept has been studied through different approaches. One of them {{is based on the}} notion of ordered local extrema and is very promising. Unfortunately, this approach does not take in charge texture directionality; and the mathematical morphology formalism, on which it is based, does not enable extensions to this feature. This led us to design a new formalism for texture representation which is able to include directionality features. It produces a representation of texture relevant features {{in the form of a}} surface z = f (x,y). The visualization of this surface gives experts sufficient information to discriminate different textures...|$|E
40|$|EN] In {{this paper}} we study a variational problem {{derived from a}} {{computer}} vision application: video camera calibration with smoothing constraint. By video camera calibration we meanto estimate the location, orientation and lens zoom-setting of the camera for each video frame taking into <b>account</b> <b>image</b> visible features. To simplify the problem {{we assume that the}} camera is mounted on a tripod, in such case, for each frame captured at time t, the calibration is provided by 3 parameters : (1) P(t) (PAN) which represents the tripod vertical axis rotation, (2) T(t) (TILT) which represents the tripod horizontal axis rotation and (3) Z(t) (CAMERA ZOOM) the camera lens zoom setting. The calibration function t -> u(t) = (P(t),T(t),Z(t)) is obtained as the minima of an energy function I[u]. In thIs paper we study the existence of minima of such energy function as well as the solutions of the associated Euler-Lagrange equations...|$|E
40|$|Abstract: Tunnelling probabilities {{in field}} {{emission}} processes are usually calculated assuming flat emitting surfaces. This corresponds {{to consider the}} electric field as a constant along the potential barrier. Previous work have shown the importance of taking into <b>account</b> <b>image</b> effects but neglecting local field variations. Even when the local field has been taken into account, a proper three dimensional calculation of the transmission coefficient was not performed. We discuss previous calculation models, their limitations and conclusions, comparing them with our model results. We have determined the transmission coefficient using a 3 -D numerical integration process. Considering a completely planar surface and another one with an hemispherical protrusion superimposed on it, we could compare the relative influence of either the local field variation along the potential barrier and image effects. These results lead {{to the conclusion that}} corrections due to the local field variation are of a magnitude that deserves to be considered, together as those resulting from the image potential. 1...|$|E
40|$|AbstractThe {{existence}} of some accounting policies and procedures, which are {{adapted to the}} complexity and the specific of each entity in part, {{is one of the}} essential conditions for producing and supplying useful information through the financial statements. Along this goal, the objective of having a “trustworthy image” of the: financial position, assets, liabilities and of the represented performance, imply knowing, understanding and correspondingly applying these in practice. Actually, as instruments of internal control, the accounting procedures, which are adopted for drafting and presenting the financial statements, are applied. Regardless of this, the <b>accounting</b> <b>images</b> obtained in his manner do not always reflect the represented economic reality. In this context, the objective of the carried research has focused on identifying the role of the accounting policies and procedures in treating risks that could affect the utility of the accounting information, respectively the trustworthy image of the financial situation and of the performance of an entity...|$|R
40|$|Image {{processing}} and object/pattern analysis {{have been a}} major challenge in the field of biometric and has always been resulting into complex mathematical, algorithmic and programming problems. Many articles have considered particular questions related to this in scene modeling, object geometry <b>accounting,</b> <b>image</b> contours processing. The problem of recovery of disaster-zone-remains as it is chosen in our research is presented as a sequence of scene modeling, and this research will actually determine the weight of the object involve in the scene so as to evaluate the kind of machine to be deployed down to the area for evacuation of the object. This research, after the implementation, shows the results for the camera distance to the object in the scene, the size (length) of the object as well as the weight of the object in the same scene. The implementation has helped us to determine one other information about image parameters aside its width and height...|$|R
40|$|International audienceSpeckle {{reduction}} {{is a key}} step in several SAR image processing procedures. In this paper, a new despeckling technique based on the “nonlocal” denoising filter BM 3 D [1] is presented. The filter has been modified {{in order to take}} into <b>account</b> SAR <b>image</b> characteristics. The experimental results, conducted on both synthetic and real SAR images, confirm the potential of the proposed approach...|$|R
