9|17|Public
5000|$|... "Rigging {{is making}} our {{characters}} able to move. The process of rigging is we take that digital sculpture, {{and we start}} building the skeleton, the muscles, and we attach the skin to the character, and we also create a set of animation controls, which our animators use to push and pull the body around."This technique is used by constructing a series of 'bones,' {{sometimes referred to as}} rigging. Each bone has a three-dimensional transformation (which includes its position, scale and orientation), and an optional parent bone. The bones therefore form a hierarchy. The full transform of a child node is the product of its parent transform and its own transform. So moving a thigh-bone will move the lower leg too. As the character is animated, the bones change their transformation over time, under the influence of some <b>animation</b> <b>controller.</b> A rig is generally composed of both forward kinematics and inverse kinematics parts that may interact with each other. Skeletal animation is referring to the forward kinematics part of the rig, where a complete set of bones configurations identifies a unique pose.|$|E
40|$|This is a {{proposal}} for a general use system based, on the SGI IRIS workstation platform, for recording computer animation to videotape. In addition, this system would provide features for simple editing and enhancement. Described here are a list of requirements for the system, and a proposed configuration including the SGI VideoLab Integrator, VideoMedia VLAN <b>animation</b> <b>controller</b> and the Pioneer rewritable laserdisc recorder...|$|E
40|$|This paper {{describes}} {{a method for}} optimizing the parameters of a physics-basedcontrollerforfull-body, 3 Dwalking. AmodifiedversionoftheSIMBICONcontroller[Yinetal. 2007]isoptimizedfor characters of varying body shape, walking speed and step length. The objective function includes terms for power minimization, angular momentum minimization, and minimal head motion, among others. Together these terms produce {{a number of important}} featuresofnaturalwalking,includingactivetoe-off,near-passiveknee swing, and leg extension during swing. We explain the specific formofourobjectivecriteria,andshowtheimportanceofeachterm towalkingstyle. Wedemonstrateoptimizedcontrollersforwalking withdifferentspeeds,variationinbodyshape,andingroundslope. Keywords: Physics-based <b>animation,</b> <b>controller</b> synthesis, human motion, optimization. ...|$|E
40|$|Researchers demand {{much from}} their {{embodied}} conversational agents (ECAs), {{requiring them to}} be both life-like, as well as responsive to events in an interactive setting. We find that a flexible combination of animation approaches {{may be needed to}} satisfy these needs. In this paper we present SmartBody, an open source modular framework for animating ECAs in real time, based on the notion of hierarchically connected <b>animation</b> <b>controllers.</b> Controllers in SmartBody can employ arbitrary animation algorithms such as keyframe interpolation, motion capture or procedural <b>animation.</b> <b>Controllers</b> can also schedule or combine other controllers. We discuss our architecture in detail, including how we incorporate traditional approaches, and develop the notion of a controller as a reactive module within a generic framework, for realizing modular animation control. To illustrate the versatility of the architecture, we also discuss a range of applications that have used SmartBody successfully...|$|R
40|$|The project {{presented}} in this paper explores the possibility of designing and implementing a physics-based real-time animation engine capable of generating realistically looking motion for articulated human characters with at least 16 degrees of freedom, based on the FreeWill+ framework and its skeleton model. Some new <b>animation</b> <b>controllers</b> are developed to map the real physical quantities into the FreeWill+ model of the world and to simulate the dynamics aspects of the human motion. At the current stage of research the solution allows estimating physically valid balance of a virtual character. In case of loosing its balance the character may initiate some reflexive behaviour...|$|R
40|$|Animations {{express a}} sense of process and {{continuity}} {{that is difficult to}} convey through other techniques. Although interfaces can often benefit from animation, User Interface Management Systems (UIMSs) rarely provide the tools necessary to easily support complex, state-dependent application output, such as animations. Here we describe Player, an interface component that facilitates sequencing these animations. One difficulty of integrating animations into interactive systems is that animation scripts typically only work in very specific contexts. Care must be taken to establish the required context prior to executing an animation. Player employs a precondition and postcondition-based specification language, and automatically computes which animation scripts should be invoked to establish the neces- sary state. Player's specification language has been designed to make it easy to express the desired behavior of <b>animation</b> <b>controllers.</b> Since planning can be a timeconsuming process inappr [...] ...|$|R
40|$|In this work, a {{developmental}} hierarchy {{is applied to}} the evolution of a relatively complex physics-based character <b>animation</b> <b>controller.</b> This means that the artificial neural network that makes up that controller is composed from a number of interdependent sub-networks; the control modules. It is hypothesized that evolving these modules one-by-one, with each of them dependent on its predecessors, will allow evolution to converge faster, and possibly to better results, than for a pair of baseline controllers. Both muscle-based actuation and joint torque-based actuation are tested, but only the latter succeeds. It is demonstrated that developmental hierarchies can lead to faster evolutionary convergence, while dealing with compound animations more adequately...|$|E
40|$|We {{introduce}} a comprehensive biomechanical {{model of the}} human upper body. Our model confronts the combined challenge of modeling and controlling more or less all of the relevant articular bones and muscles, as well as simulating the physics-based deformations of the soft tissues. Its dynamic skeleton comprises 68 bones with 147 jointed degrees of freedom, including those of each vertebra {{and most of the}} ribs. To be properly actuated and controlled, the skeletal submodel requires comparable attention to detail with respect to muscle modeling. We incorporate 814 muscles, each of which is modeled as a piecewise uniaxial Hill-type force actuator. To simulate biomechanically-realistic flesh deformations, we also develop a coupled finite element model with the appropriate constitutive behavior, in which are embedded the detailed 3 D anatomical geometries of the hard and soft tissues. Finally, we develop an associated physics-based <b>animation</b> <b>controller</b> that computes the muscle activation signals necessary to drive the elaborate musculoskeletal system in accordance with a sequence of target poses specified by an animator...|$|E
40|$|Figure 1 : By {{modeling}} user {{behavior and}} not thresholding transitions, we create a high overall quality on-line motion generator suitable for directly controlled characters. Left, a screen capture. Middle, users control the character with a gamepad. Right, characters must respond immediately to user input, lest they {{run afoul of}} environmental hazards. In game environments, animated character motion must rapidly adapt to changes in player input – for example, if a directional signal from the player’s gamepad is not incorporated into the character’s trajectory immediately, the character may blithely run off a ledge. Traditional schemes for data-driven character animation lack the split-second reactivity required for this direct control; while they {{can be made to}} work, motion artifacts will result. We describe an on-line character <b>animation</b> <b>controller</b> that assembles a motion stream from short motion fragments, choosing each fragment based on current player input and the previous fragment. By adding a simple model of player behavior we are able to improv...|$|E
5000|$|... 3D models rigged for {{animation}} {{may contain}} thousands of control points — for example, [...] "Woody" [...] from Toy Story uses 700 specialized <b>animation</b> <b>controllers.</b> Rhythm and Hues Studios labored {{for two years}} to create Aslan in the movie The Chronicles of Narnia: The Lion, the Witch and the Wardrobe, which had about 1,851 controllers (742 in the face alone). In the 2004 film The Day After Tomorrow, designers had to design forces of extreme weather {{with the help of}} video references and accurate meteorological facts. For the 2005 remake of King Kong, actor Andy Serkis was used to help designers pinpoint the gorilla's prime location in the shots and used his expressions to model [...] "human" [...] characteristics onto the creature. Serkis had earlier provided the voice and performance for Gollum in J. R. R. Tolkien's The Lord of the Rings trilogy.|$|R
40|$|The {{dominant}} {{paradigm for}} 3 -D character animation requires an animator {{to specify the}} values for all degrees of freedom of an articulated figure at key frames. Specifying motion that is physically believable and biologically plausible is a tedious practice requiring great skill. We use evolutionary techniques (specifically Genetic Programming) {{as a means of}} controller synthesis for character <b>animation.</b> <b>Controllers</b> which drive a dynamic simulation of the character are evolved using the goals of the animation as an objective function, resulting in physically plausible motion. We discuss the development of objective functions used to guide the controller evolution, making reusable skill controllers, and comparisons of the convergence rates for different parameters of the evolutionary runs. 1. Introduction In this investigation, we are concerned with a particular subset of computer animation: character animation. In an animation, many objects may be moving around. Characters are those ob [...] ...|$|R
40|$|Virtual humans {{should be}} {{responsive}} to unexpected events, life-like in their behavior and interpretable so users can interpret their response to situations, including their cognitive and emotional state. To address such demands, a variety of approaches {{have been used to}} animate virtual humans. While procedural animation is flexible to respond to events, hand-animated (or motion captured) sequences are better suited to display life-like expressive behavior. We propose that a combination of animation approaches may be required to achieve responsive, life-like and interpretable behavior. Our motion control architecture [1] is based on controllers that can be hierarchically interconnected in real-time in order to achieve continuous motion. This approach has evolved into a general character animation system called SmartBody, an open source modular framework for realizing embodied characters. Controllers in SmartBody can employ arbitrary animation algorithms such as keyframe interpolation, motion capture or procedural <b>animation.</b> <b>Controllers</b> can also schedule or blend other controllers. Composable controllers provide flexibility and a wide range of potentia...|$|R
40|$|Figure 1 : Walking {{controllers}} {{optimized for}} different environments with uncertainty. (a) Walking can be relaxed in a deterministic environment, without random external perturbations. (b) Under gusty conditions, the gait is more aggressive, {{with a wider}} stance. (c) On a slipperysurfacewithinternalmotornoise,thegaitiscautiouswitharmsextendedforbalance. (d) Walkingonanarrowwallonawindyday produces anarrowergaitwithsmallsteps. (e) Withinternalmotor noise, carryinghotbeverages requires aslowgait withsteady arms. We introduce methods for optimizing physics-based walking controllers for robustness to uncertainty. Many unknown factors, such as external forces, control torques, and user control inputs, cannot be known in advance and must be treated as uncertain. These variables are represented with probability distributions, and a return function scores the desirability of a single motion. Controller optimization entails maximizing the expected value of the return, which is computed by Monte Carlo methods. We demonstrate examples with different sources of uncertainty and task constraints. Optimizing control strategies under uncertainty increases robustness andproduces naturalvariations instyle. Keywords: Physics-based <b>animation,</b> <b>controller</b> synthesis, human motion, optimization. ...|$|E
40|$|Figure 1 : The biomechanical {{model in}} action. A motion {{controller}} drives the musculoskeletal system toward {{a sequence of}} target poses. We introduce a comprehensive biomechanical model of the human upper body. Our model confronts the combined challenge of modeling and controlling more or less all of the relevant articular bones and muscles, as well as simulating the physics-based deformations of the soft tissues. Its dynamic skeleton comprises 68 bones with 147 jointed degrees of freedom, including those of each vertebra {{and most of the}} ribs. To be properly actuated and controlled, the skeletal submodel requires comparable attention to detail with respect to muscle modeling. We incorporate 814 muscles, each of which is modeled as a piecewise uniaxial Hill-type force actuator. To simulate biomechanically realistic flesh deformations, we also develop a coupled finite element model with the appropriate constitutive behavior, in which are embedded the detailed 3 D anatomical geometries of the hard and soft tissues. Finally, we develop an associated physics-based <b>animation</b> <b>controller</b> that computes the muscle activation signals necessary to drive the elaborate musculoskeletal system in accordance with a sequence of target poses specified by an animator...|$|E
40|$|In game environments, {{animated}} character motion must rapidly {{adapt to}} changes in player input - for example, if a directional signal from the player 2 ̆ 7 s gamepad is not incorporated into the character 2 ̆ 7 s trajectory immediately, the character may blithely run off a ledge. Traditional schemes for data-driven character animation lack the split-second reactivity required for this direct control; while they {{can be made to}} work, motion artifacts will result. We describe an on-line character <b>animation</b> <b>controller</b> that assembles a motion stream from short motion fragments, choosing each fragment based on current player input and the previous fragment. By adding a simple model of player behavior we are able to improve an existing reinforcement learning method for precalculating good fragment choices. We demonstrate the efficacy of our model by comparing the animation selected by our new controller to that selected by existing methods and to the optimal selection, given knowledge of the entire path. This comparison is performed over real-world data collected from a game prototype. Finally, we provide results indicating that occasional low-quality transitions between motion segments are crucial to high-quality on-line motion generation; this is an important result for others crafting animation systems for directly-controlled characters, as it argues against the common practice of transition thresholding...|$|E
40|$|This paper {{addresses}} {{the design and}} visualization of animated models for coordinated and decentralized discrete event control systems, e. g. manufacturing systems and traffic control systems. We introduce an approach to the design and <b>animation</b> of such <b>controllers</b> based on Coloured Petri nets models and the Design/CPN tool. The approach is illustrated by a simple traffic control network modeling...|$|R
40|$|We {{developed}} a rhythmic instruments ensemble simulator generating <b>animation</b> using game <b>controllers.</b> The motion {{of a player}} is transformed into musical expression data of MIDI to generate sounds, and MIDI data are transformed into animation control parameters to generate movies. These animations and music are shown as the reflection of player performance. Multiple players can perform a musical ensemble to make more varied patterns of animation. Our system is so easy that everyone can enjoy performing a fusion of music and animation...|$|R
40|$|This thesis {{introduces}} locomotion synthesis {{methods for}} humanoid characters. Motion synthesis is an under-constrained problem that requires additional constraints beyond user inputs. Two main approaches to introducing additional constraints are physics-based and data-driven. Despite {{significant progress in}} the past 20 years, major difficulties still exist for both approaches. In general, building animation systems that are flexible to user requirements while keeping the synthesized motions plausible remain a challenging task. The methods introduced in this thesis, presented in two-parts, aim to allow animation systems to be more flexible to user demands without radically violating constraints that are important for maintaining plausibility. In {{the first part of}} the thesis, we address an important subproblem in physics-based <b>animation</b> — <b>controller</b> synthesis for humanoid characters. We describe a method for optimizing the parameters of a physics-based controller for full-body, 3 D walking. The objective function includes terms for power minimization, angular momentum minimiza-tion, and minimal head motion, among others. Together these terms produce a number of important features of natural walking, including active toe-off, near-passive knee swing...|$|R
40|$|We {{describe}} how to synthesize, automatically, motion controllers for locomotive tasks involving animated characters modeled as 3 D mass-spring lattices. The motion controllers determine an actuation sequence based on elapsed time, not physical state; actuation is represented economically using a small, predefined set of global lattice deformations; and stochastic search {{is used to}} determine effective values for the controller parameters. Our algorithm generates controllers that produce attractive, visually plausible motion for simple locomotive tasks in under an hour on a standard workstation, {{which is more than}} an order of magnitude faster than comparable approaches to motion synthesis for 3 D articulated-linkage models. Key Words: <b>animation,</b> motion synthesis, <b>controller</b> synthesis, heuristic methods, stochastic optimization, mass-spring models. 1 Introduction Motion synthesis is the task of automatically generating visually plausible movement of an animated character that conforms to th [...] ...|$|R
40|$|Controllers are {{necessary}} for physically-based synthesis of character <b>animation.</b> However, creating <b>controllers</b> requires either manual tuning or expensive computer optimization. We introduce linear Bellman combination as a method for reusing existing controllers. Given a set of controllers for related tasks, this combination creates a controller that performs a new task. It naturally weights the contribution of each component controller by its relevance to the current state and goal of the system. We demonstrate that linear Bellman combination outperforms naive combination often succeeding where naive combination fails. Furthermore, this combination is provably optimal for a new task if the component controllers are also optimal for related tasks. We demonstrate the applicability of linear Bellman combination to interactive character control of stepping motions and acrobatic maneuvers. Singapore-MIT GAMBIT Game LabNational Science Foundation (U. S.) (Grant 2007043041) National Science Foundation (U. S.) (Grant CCF- 0810888) Adobe SystemsPixar (Firm...|$|R
40|$|For the ViewCorrect project, an {{x-y plotter}} is built. This is a {{research}} setup for testing concurrent real-time software. The context of the ViewCorrect project is to bring different disciplines, involved in a mechatronic system project, in a structured way together and therefore making the traditional gap between them smaller. One way of bringing different disciplines together is co-simulation. This project has researched the possibilities to co-simulate the CT-based plotter software written in gCSP with the 20 -sim model that describes the behaviour of the ViewCorrect Plotter setup. The existing model of the ViewCorrect Plotter setup has been adjusted and validated. The difference between simulated and measured model is less than five percent. Next a 3 D <b>animation</b> model and <b>controllers</b> have been designed. The controllers are capable of controlling {{the position of the}} pen. The plotter software has been made in gCSP. A workflow is presented which allows the user to make a drawing in a CAD drawing package and plot this drawing with the plotter. The controllers, designed in 20 -Sim, and the safety layer are embedded in the plotter software. Co-simulation has been analysed in the scope of heterogeneous system design. A flexibl...|$|R
40|$|E-learning package {{containing}} interactive {{resources to}} aid awareness {{of mental health}} needs of older carers. The resource is structured around three stories about the experience of older carers to trigger reflective learning. It also contains three editions of an e-magazine to support development of reflective skills. Users can access a downloadable reflective log book to track learning and future development needs. Each story will enable thinking about how the unique demands of being a carer in later life impacts on people's well-being. Using this resource allows consideration of how {{to address the needs}} of older carers when designing and planning health promotion activities for older people in general. Each story is divided into sections or parts that address focused questions. The questions have reflective exercises focusing on a variety of issues pertinent to promoting the mental health and wellbeing of older carers. Feedback can be accessed for each of the exercises within the resources. The resource is structured like a website with a series of folders and an index. html file. There are <b>animations</b> and voiceover <b>controllers</b> that require Flash Player to display properly, although there are available transcripts. ...|$|R
40|$|With the {{evolution}} in the game industry and other virtual environments, demands on what comes with an application is higher than ever before. This leads to many companies trying to to procedurally generate content {{in order to save}} up on storage space and get a wider variety of content. It has become essential to infuse immersion in such application and some companies has even gone as far as to let the player recreate him- or herself to be the hero or heroine of the game. Even so, many AAA companies refrain from using face segmentation software as it gives the power of adding game content by the end users, and that may lead to an increased risk of offensive content, that goes against company standards and policy, to enter their application. By taking the concept of procedural generation and applying this together with face segmentation, placing a Principal Component Analysis (PCA) based texturization model, we allow for a controlled yet functioning face texturization in a run-time virtual environment. In this project we use MatLab to create a controlled Eigen space, infuses this into an application built in Unity 3 D using UMA, and lets smaller recreation vectors, that spans a few kilobytes as most, to create textures in run-time. In doing so, we can project faces onto the Eigen space and get fully functioning and texturized characters, able to use ready <b>animations</b> and <b>controllers</b> of the developer’s choice. These Eigen spaces may cost more storage space and loading times up to a limit, but can in turn generate a seemingly endless variation of textural content dynamically. In order to see what potential users prioritize when it comes to applications like these, we conducted a survey where the responders saw variations of this technique and were able to express their view on attributes expected from a “good” (from their point of view) application. In the end we have a UMA ready set of scripts, and a one-time use system to create Eigen spaces for the applications to use it. We worked in close relation with Högström’s Selfie to Avatar face segmentation software and proved the concept in Unity 3 D applications...|$|R
40|$|Simulation, {{animation}} and {{rendering of}} crowds {{has become an}} important part of real-time applications such as videogames. Virtual environments achieve higher realism when being populated by virtual crowds as opposed to appearing uninhabited. There has been a large amount of research on simulation, animation and rendering of crowds, but in most cases they seem to be treated separately as if the limitations in one area did not affect the others. At {{the end of the day}} the goal is to populate environments with as many characters as possible in real time, and it is of little use if one can for instance render thousands of characters in real time, but you cannot move more than a hundred due to a simulation bottleneck. The goal of our work is to provide a framework that lets the researcher focus on each of these topics at a time (simulation, animation, or rendering) and be able to explore and push the boundaries on one topic without being strongly limited by the other related issues. This paper presents therefore a new prototyping testbed for crowds that lets the researcher focus on one of these areas of research at a time without loosing sight of the others. We offer default representations, <b>animation</b> and simulation <b>controllers</b> for real time crowd simulation, that can easily be replaced or extended. Fully configurable level-of-detail for both rendering and simulation is also availablePeer ReviewedPostprint (published version...|$|R
40|$|Humanoid motion {{generation}} {{based on}} physics based controllers {{has the potential}} to revolutionize the realism and autonomy of motion in games, movies and even robotics. The area of simulation and control is broad and this thesis focuses on the problem of designing humanoid <b>animations</b> with physics-based <b>controllers.</b> Physics based <b>animation</b> has been an active field of research since the 90 's but to this day has had rather minor appearances in the CG Industry. The primary setback is the complexity of the programming task that is needed and the lack of tools for artists to design robust controllers. The primary contribution of my work is the development of a set of tools that allow non-programmers to develop feedback based controllers to generate and parametrize different motion skills for a physics based character. In my system a user, who is knowledgeable about humanoid physics, is able to develop controllers for physics based characters with an intuitive user interface by visually creating a graph structure, independent of the character's mass properties, that represents the control hierarchy. Then our system explores the range of functionality of the input graph to make a parametrized controller. Our system has several low level components that maintain balance and allow the manipulation of the character configuration through Inverse Kinematics and Virtual Forces. I also present a control interface and network communication system to control motions for a humanoid robot and a method for using an XBox Kinect to recognize hand configurations. The intent of this last topic is to explore novel possible user interfaces to control and experiment with variations of physics controllers...|$|R
40|$|Realistic {{character}} {{motion is}} an important component in media production, such as movies and video games. More lifelike characters enhance storytelling and immersive experience. To date, the most common approach to offer high degree of realism is based on large databases of motion capture data. The motion capture process, however, is expensive and time-consuming, while only a limited number and range of motions can be captured at a time. As a consequence, realistic motion synthesis has become a core research topic in computer animation. Many of the most successful techniques are based on fragmenting and recombining motion capture data. The connectivity among the motion fragments is encoded with a graph structure, and novel motions can be generated with graph traversals. In addition, most systems allow a user to provide a number of constraints to specify the desired motion. By formulating the constraints as a cost function, motion synthesis is cast as a graph search problem, and the optimally-synthesized motion corresponds to the path through the graph that minimizes the total cost. The search complexity for an optimal or near-optimal solution, however, is exponential to the connectivity of the graph and the length of the desired motion sequence. Synthesizing optimal or near-optimal motions is thus challenging for interactive applications. In this dissertation, we explore the two most significant research directions toward near-optimal motion synthesis, including graph search and reinforcement learning, and present algorithms for interactive and real-time character animation. This dissertation begins by reviewing previous work on searching motion graphs. In particular, A* search is optimally efficient and considered the state-of-the-art technique for optimal motion synthesis. However, applying A* search on motion graphs is challenging when interactive performance is demanded. To make A* search more applicable to interactive applications, we present a bidirectional search algorithm to improve the search efficiency while preserving the search quality. This can reduce the maximal search depth by almost a factor of two, leading to significant performance improvements. We further demonstrate its application to interactive motion synthesis using an intuitive sketching interface. The second part of the dissertation consists of reinforcement learning frameworks for real-time character <b>animation.</b> The character <b>controller</b> makes near-optimal decisions in response to user input in real-time. The controller is constructed in a pre-process by exploring all possible situations. We introduce a tree-based regression algorithm, which is more efficient and robust than previous strategies for learning controllers. In addition, we extend the learning framework to include parameterized motions and interpolation for precise motion control. Finally, we show how to leverage character controllers by letting the character "see'' the environment directly with depth perception. We derive a hierarchical state model and a regression algorithm to avoid the curse of dimensionality resulting from raw vision input. The controller can be generalized to allow a character to navigate or survive in environments containing arbitrarily shaped obstacles, which is hard to achieve with previous reinforcement learning framework...|$|R

