10000|10000|Public
5|$|In mathematics, <b>a</b> <b>matrix</b> is a {{rectangular}} array of numbers or other data. In physics, <b>a</b> <b>matrix</b> {{model is a}} particular kind of physical theory whose mathematical formulation involves the notion of <b>a</b> <b>matrix</b> in an important way. <b>A</b> <b>matrix</b> model describes the behavior of a set of matrices within the framework of quantum mechanics.|$|E
5|$|Matrices {{which have}} a single row are called row vectors, and those {{which have a}} single column are called column vectors. <b>A</b> <b>matrix</b> which has {{the same number of}} rows and columns is called a square matrix. <b>A</b> <b>matrix</b> with an {{infinite}} number of rows or columns (or both) is called an infinite matrix. In some contexts, such as computer algebra programs, it is useful to consider <b>a</b> <b>matrix</b> with no rows or no columns, called an empty matrix.|$|E
5|$|The minors and cofactors of <b>a</b> <b>matrix</b> {{are found}} by {{computing}} the determinant of certain submatrices.|$|E
50|$|The {{product of}} two anti-{{diagonal}} <b>matrices</b> is <b>a</b> diagonal <b>matrix.</b> Furthermore, {{the product of}} <b>an</b> anti-diagonal <b>matrix</b> with <b>a</b> diagonal <b>matrix</b> is anti-diagonal, as {{is the product of}} <b>a</b> diagonal <b>matrix</b> with <b>an</b> anti-diagonal <b>matrix.</b>|$|R
50|$|Any <b>matrix</b> {{congruent}} to <b>a</b> symmetric <b>matrix</b> {{is again}} symmetric: if X is <b>a</b> symmetric <b>matrix</b> then so is AXAT for any <b>matrix</b> <b>A.</b> <b>A</b> symmetric <b>matrix</b> is necessarily <b>a</b> normal <b>matrix.</b>|$|R
5000|$|<b>A</b> block {{diagonal}} <b>matrix</b> is <b>a</b> block <b>matrix</b> that is <b>a</b> square <b>matrix,</b> {{and having}} main diagonal blocks square matrices, {{such that the}} off-diagonal blocks are zero <b>matrices.</b> <b>A</b> block diagonal <b>matrix</b> <b>A</b> has the form ...|$|R
5|$|The rank of <b>a</b> <b>matrix</b> A is {{the maximum}} number of linearly {{independent}} row vectors of the matrix, which is the same as {{the maximum number}} of linearly independent column vectors. Equivalently it is the dimension of the image of the linear map represented by A. The rank‚Äìnullity theorem states that the dimension of the kernel of <b>a</b> <b>matrix</b> plus the rank equals the number of columns of the matrix.|$|E
5|$|The size of <b>a</b> <b>matrix</b> {{is defined}} by the number of rows and columns that it contains. <b>A</b> <b>matrix</b> with m rows and n columns is called an m√ón matrix or m-by-n matrix, while m and n are called its dimensions. For example, the matrix A above is a 3√ó2 matrix.|$|E
5|$|Traditional mesh {{analysis}} and nodal analysis in electronics {{lead to a}} system of linear equations that can be described with <b>a</b> <b>matrix.</b>|$|E
3000|$|Several special {{matrices}} with reserved {{symbols are}} as follows: I, J, 0, and D are <b>an</b> identity <b>matrix,</b> <b>a</b> reversal identity <b>matrix,</b> <b>a</b> null <b>matrix,</b> and <b>a</b> diagonal <b>matrix</b> with alternating ¬± 1 entries (i.e., diag{ 1,- 1, 1,- 1,‚ãØ }), respectively. Also, ¬∑ [...]...|$|R
50|$|In linear algebra, <b>a</b> square <b>matrix</b> <b>A</b> {{is called}} {{diagonalizable}} {{if it is}} similar to <b>a</b> diagonal <b>matrix,</b> i.e., if there exists <b>an</b> invertible <b>matrix</b> P such that P‚àí1AP is <b>a</b> diagonal <b>matrix.</b> If V is a finite-dimensional vector space, then a linear map T : V ‚Üí V is called diagonalizable if there exists an ordered basis of V with respect to which T is represented by <b>a</b> diagonal <b>matrix.</b> Diagonalization {{is the process of}} finding <b>a</b> corresponding diagonal <b>matrix</b> for <b>a</b> diagonalizable <b>matrix</b> or linear map. <b>A</b> square <b>matrix</b> that is not diagonalizable is called defective.|$|R
5000|$|Given {{a square}} {{invertible}} [...] <b>matrix</b> , <b>an</b> [...] <b>matrix</b> , and <b>a</b> [...] <b>matrix</b> , let [...] be <b>an</b> [...] <b>matrix</b> such that [...] Then, assuming [...] is invertible, we have ...|$|R
5|$|An {{asterisk}} is occasionally used {{to refer}} to whole rows or columns in <b>a</b> <b>matrix.</b> For example, a'i,‚àó refers to the ith row of A, and a‚àó,j refers to the jth column of A. The set of all m-by-n matrices is denoted ùïÑ(m, n).|$|E
5|$|Every finite {{group is}} {{isomorphic}} to <b>a</b> <b>matrix</b> group, {{as one can}} see by considering the regular representation of the symmetric group. General groups can be studied using matrix groups, which are comparatively well understood, by means of representation theory.|$|E
5|$|The {{finite element}} method is an {{important}} numerical method to solve partial differential equations, widely applied in simulating complex physical systems. It attempts to approximate the solution to some equation by piecewise linear functions, where the pieces are chosen {{with respect to a}} sufficiently fine grid, which in turn can be recast as <b>a</b> <b>matrix</b> equation.|$|E
50|$|In mathematics, <b>a</b> {{unimodular}} polynomial <b>matrix</b> is <b>a</b> square polynomial <b>matrix</b> whose inverse {{exists and}} is itself <b>a</b> polynomial <b>matrix.</b> Equivalently, <b>a</b> polynomial <b>matrix</b> <b>A</b> is unimodular if its determinant det(A) is a nonzero constant.|$|R
3000|$|... is <b>a</b> {{circulant}} permutation <b>matrix,</b> <b>a</b> circulant <b>matrix</b> with {{row and column}} weights 1. Each 0 is <b>a</b> null <b>matrix.</b> The matrix H [...]...|$|R
50|$|To give {{a linear}} {{involution}} {{is the same}} as giving <b>an</b> involutory <b>matrix,</b> <b>a</b> square <b>matrix</b> <b>A</b> such thatwhere I is the identity matrix.|$|R
5|$|The numbers, symbols or {{expressions}} in {{the matrix}} are called its entries or its elements. The {{horizontal and vertical}} lines of entries in <b>a</b> <b>matrix</b> are called rows and columns, respectively.|$|E
5|$|A {{group is}} a {{mathematical}} structure consisting {{of a set of}} objects together with a binary operation, that is, an operation combining any two objects to a third, subject to certain requirements. A group in which the objects are matrices and the group operation is matrix multiplication is called <b>a</b> <b>matrix</b> group. Since in a group every element has to be invertible, the most general matrix groups are the groups of all invertible matrices of a given size, called the general linear groups.|$|E
5|$|Although {{there exist}} {{polynomial}} time algorithms to find <b>a</b> <b>matrix</b> having given {{row and column}} sums, the solution may be far from unique: any submatrix {{in the form of}} a 22 identity matrix can be complemented without affecting the correctness of the solution. Therefore, researchers have searched for constraints on the shape to be reconstructed that can be used to restrict the space of solutions. For instance, one might assume that the shape is connected; however, testing whether there exists a connected solution is NP-complete. An even more constrained version that is easier to solve is that the shape is orthogonally convex: having a single contiguous block of squares in each row and column.|$|E
50|$|In mathematics, {{particularly}} matrix {{theory and}} combinatorics, the Pascal <b>matrix</b> is <b>an</b> infinite <b>matrix</b> containing the binomial coefficients as its elements. There are three ways to achieve this: as either <b>an</b> upper-triangular <b>matrix,</b> <b>a</b> lower-triangular <b>matrix,</b> or <b>a</b> symmetric <b>matrix.</b> The 5√ó5 truncations {{of these are}} shown below.|$|R
5000|$|The <b>matrix</b> {{exponential}} of <b>a</b> skew-symmetric <b>matrix</b> <b>A</b> is then <b>an</b> orthogonal <b>matrix</b> R: ...|$|R
5000|$|Suppose a QR {{decomposition}} for <b>a</b> non-square <b>matrix</b> A:where [...] is <b>a</b> zero <b>matrix</b> and [...] is <b>a</b> unitary <b>matrix.</b>|$|R
5|$|An {{example of}} the use of Fleiss' kappa may be the following: Consider {{fourteen}} psychiatrists are asked to look at ten patients. Each psychiatrist gives one of possibly five diagnoses to each patient. These are compiled into <b>a</b> <b>matrix,</b> and Fleiss' kappa can be computed from this matrix (see example below) to show the degree of agreement between the psychiatrists above the level of agreement expected by chance.|$|E
5|$|Exponentiation {{occurs in}} many areas of {{mathematics}} and its inverse function {{is often referred to as}} the logarithm. For example, the logarithm of <b>a</b> <b>matrix</b> is the (multi-valued) inverse function of the matrix exponential. Another example is the p-adic logarithm, the inverse function of the p-adic exponential. Both are defined via Taylor series analogous to the real case. In the context of differential geometry, the exponential map maps the tangent space at a point of a manifold to a neighborhood of that point. Its inverse is also called the logarithmic (or log) map.|$|E
5|$|HIV is {{different}} in structure from other retroviruses. It is roughly spherical with a diameter of about 120nm, around 60times smaller than a red blood cell. It is composed of two copies of positive single-stranded RNA that codes for the virus's nine genes enclosed by a conical capsid composed of 2,000 copies of the viral protein p24. The single-stranded RNA is tightly bound to nucleocapsid proteins, p7, and enzymes needed {{for the development of}} the virion such as reverse transcriptase, proteases, ribonuclease and integrase. <b>A</b> <b>matrix</b> composed of the viral protein p17 surrounds the capsid ensuring the integrity of the virion particle.|$|E
30|$|For {{symmetric}} <b>matrices</b> <b>A,</b> B, we denote A< B or B>A if <b>matrix</b> B-A is <b>a</b> positive definite <b>matrix.</b> Particularly, A> 0 if <b>a</b> symmetric <b>matrix</b> <b>A</b> is <b>a</b> positive definite <b>matrix.</b>|$|R
5000|$|For example, the Hadamard {{product for}} <b>a</b> 3√ó3 <b>matrix</b> <b>A</b> with <b>a</b> 3√ó3 <b>matrix</b> B is: ...|$|R
50|$|<b>A</b> Hermitian <b>matrix</b> (or {{the special}} case of <b>a</b> real {{symmetric}} <b>matrix)</b> or <b>a</b> unitary <b>matrix</b> is never defective; more generally, <b>a</b> normal <b>matrix</b> (which includes Hermitian and unitary as special cases) is never defective.|$|R
5|$|In the Multiple Classification Card Sorting Task, {{children}} are shown cards {{and asked to}} sort them based on two different dimensions (e.g. by color, such as yellow and blue, and object type, such as animals and food) simultaneously into four piles within <b>a</b> <b>matrix</b> (e.g. yellow animals, yellow foods, blue animals and blue foods). This task {{appears to be more}} difficult as research has shown that seven-year-old children were incapable of sorting cards based on the two dimensions simultaneously. These children focused on the two dimensions separately, whereas at the age of eleven, children were capable of sorting cards based on these two dimensions simultaneously. This demonstrates an increase in cognitive flexibility between the ages of seven and eleven.|$|E
5|$|Many of the {{applications}} of Hilbert spaces exploit {{the fact that}} Hilbert spaces support generalizations of simple geometric concepts like projection and change of basis from their usual finite dimensional setting. In particular, the spectral theory of continuous self-adjoint linear operators on a Hilbert space generalizes the usual spectral decomposition of <b>a</b> <b>matrix,</b> and this often {{plays a major role}} in applications of the theory to other areas of mathematics and physics.|$|E
5|$|One {{important}} {{example of}} <b>a</b> <b>matrix</b> {{model is the}} BFSS matrix model proposed by Tom Banks, Willy Fischler, Stephen Shenker, and Leonard Susskind in 1997. This theory describes {{the behavior of a}} set of nine large matrices. In their original paper, these authors showed, among other things, that the low energy limit of this matrix model is described by eleven-dimensional supergravity. These calculations led them to propose that the BFSS matrix model is exactly equivalent to M-theory. The BFSS matrix model can therefore be used as a prototype for a correct formulation of M-theory and a tool for investigating the properties of M-theory in a relatively simple setting.|$|E
2500|$|The {{above-mentioned}} Euler vector is the eigenvector of <b>a</b> rotation <b>matrix</b> (<b>a</b> rotation <b>matrix</b> has <b>a</b> unique real eigenvalue).|$|R
5000|$|The {{definition}} of matrix multiplication {{is that if}} [...] for <b>an</b> [...] <b>matrix</b> [...] and <b>an</b> [...] <b>matrix</b> , then [...] is <b>an</b> [...] <b>matrix</b> with entries ...|$|R
5000|$|<b>A</b> block tri{{diagonal}} <b>matrix</b> {{is another}} special block matrix, {{which is just}} like the block diagonal <b>matrix</b> <b>a</b> square <b>matrix,</b> having square matrices (blocks) in the lower diagonal, main diagonal and upper diagonal, with all other blocks being zero matrices. It is essentially <b>a</b> tridiagonal <b>matrix</b> but has submatrices in places of scalars. <b>A</b> block tridiagonal <b>matrix</b> <b>A</b> has the form ...|$|R
