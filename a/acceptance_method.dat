21|428|Public
40|$|In practice, order {{acceptance}} and production planning are often functionally separated. As a result, order acceptance {{decisions are made}} without considering the actual workload in the production system, or by only regarding the aggregate workload. We investigate {{the importance of a}} good workload based order <b>acceptance</b> <b>method</b> in over-demanded job shop environments, and study approaches that integrate order {{acceptance and}} resource capacity loading. We present sophisticated methods that consider technological restrictions, such as precedence relations, and release and due dates of orders. We use a simulation model of a generic job shop to compare these methods with straightforward methods, which consider capacity restrictions at an aggregate level and ignore precedence relations. We compare the performance of the approaches based on criteria such as capacity utilisation. The simulation results show that the sophisticated approaches significantly outperform the straightforward approaches in case of tight due dates (little slack). In that case, improvements of up to 30 % in utilisation rate can be achieved. In case of much slack, a sophisticated order <b>acceptance</b> <b>method</b> is less important...|$|E
40|$|Hyper-heuristics {{have emerged}} as {{automated}} high level search methodologies that manage a set of low level heuristics for solving computationally hard problems. A generic selection hyper-heuristic combines heuristic selection and move acceptance methods under an iterative single point-based search framework. At each step, the solution in hand is modified after applying a selected heuristic and a decision is made whether the new solution is accepted or not. In this study, we represent the trail of a hyper-heuristic as a third order tensor. Factorization of such a tensor reveals the latent relationships between the low level heuristics and the hyper-heuristic itself. The proposed learning approach partitions the set of low level heuristics into two subsets where heuristics in each subset {{are associated with a}} separate move <b>acceptance</b> <b>method.</b> Then a multi-stage hyper-heuristic is formed and while solving a given problem instance, heuristics are allowed to operate only in conjunction with the associated <b>acceptance</b> <b>method</b> at each stage. To the best of our knowledge, {{this is the first time}} tensor analysis of the space of heuristics is used as a data science approach to improve the performance of a hyper-heuristic in the prescribed manner. The empirical results across six different problem domains from a benchmark indeed indicate the success of the proposed approach...|$|E
40|$|A {{traditional}} iterative selection hyper-heuristic {{which manages}} {{a set of}} low level heuristics relies on two core components, a method for selecting a heuristic to apply at a given point, and a method {{to decide whether or}} not to accept the result of the heuristic application. In this paper, we present an initial study of a fuzzy system to control the list-size parameter of late- acceptance move <b>acceptance</b> <b>method</b> as a selection hyper-heuristic component. The performance of the fuzzy controlled selection hyper-heuristic is compared to its fixed parameter version and the best hyper-heuristic from a competition on the MAX-SAT problem domain. The results illustrate that a fuzzy control system can potentially be effective within a hyper-heuristic improving its performance...|$|E
40|$|It {{discussed}} {{the theory of}} <b>acceptance</b> rejection <b>method,</b> described the geometric scene of <b>acceptance</b> and reject <b>method</b> by using geometric probability, and then, found out the improvement about <b>acceptance</b> rejection <b>method,</b> given evaluation criteria of superior function, {{discussed the}} relationship between superior function and the probability of acceptance. It studied squeeze and adaptive sampling method, given evaluation criteria of squeeze function and envelope function, used <b>acceptance</b> rejection <b>method</b> to generate nonî€‘uniform random numbers by Matlab and Sas sofeware,discussed algorithm of generation random number of several special density function,given the program by an example...|$|R
40|$|A {{selection}} hyper-heuristic is a {{high level}} search methodology which operates over a fixed set of low level heuristics. During the iterative search process, a heuristic is selected and applied to a candidate solution in hand, producing a new solution which is then accepted or rejected at each step. Selection hyper-heuristics have been increasingly, and successfully, applied to single-objective optimization problems, while work on multi-objective selection hyper-heuristics is limited. This work presents one of the initial studies on selection hyper-heuristics combining a choice function heuristic selection methodology with great deluge and late acceptance as non-deterministic move <b>acceptance</b> <b>methods</b> for multi-objective optimization. A well-known hypervolume metric is integrated into the move <b>acceptance</b> <b>methods</b> to enable the approaches to deal with multi-objective problems. The performance of the proposed hyper-heuristics is investigated on the Walking Fish Group test suite which is a common benchmark for multi-objective optimization. Additionally, they are applied to the vehicle crashworthiness design problem as a real-world multi-objective problem. The experimental results demonstrate {{the effectiveness of the}} non-deterministic move acceptance, particularly great deluge when used as a component of a choice function based selection hyper-heuristic...|$|R
40|$|This is {{a survey}} of {{simulation}} methods in economics, with a specific focus on integration problems. It describes <b>acceptance</b> <b>methods,</b> importance sampling procedures, and Markov chain Monte Carlo methods for simulation from univariate and multivariate distributions and their application to the approximation of integrals. The exposition gives emphasis to combinations of different approaches and assessment of the accuracy of numerical approximations to integrals and expectations. The survey illustrates these procedures with applications to simulation and integration problems in economics. Econometrics...|$|R
40|$|Grouping {{problems}} {{are hard to}} solve combinatorial optimization problems which require partitioning of objects into a minimum number of subsets while another additional objective is simultaneously optimized. Considerable research e ort has recently been directed towards automated problem-independent reusable heuristic search methodologies such as hyper-heuristics, which operate on a space formed {{by a set of}} low level heuristics rather than solutions, directly. Hyper-heuristics are commonly split into two main categories: selection hyper-heuristics, which are the focus of the work presented in this thesis, and generation hyper-heuristics. Most of the recently proposed selection hyper-heuristics are iterative and make use of two key methods which are employed successively; heuristic selection and move acceptance. At each step, a new solution is produced after a selected heuristic is applied to the solution at hand and then the move <b>acceptance</b> <b>method</b> is used to decide whether the resultant solution replaces the current one or not. This thesis presents a novel generic single point-based selection hyper-heuristic search framework, referred to as grouping hyper-heuristic framework. The proposed framework deals with one solution at any given decision point during the search process and embeds axed set of reusable standard low level heuristics specifically designed for the grouping problems. The use of standard heuristics enables the re-usability of the whole framework across different grouping problem domains with less development effort. The proposed grouping hyper-heuristic framework is based on a bi-objective formulation of any given grouping problem. Inspired from multi-objective optimization, a set of high quality solutions is maintained during the search process, capturing the trade-of between the number of groups and the additional objective for the given grouping problem. Moreover, the grouping framework includes a special two-phased acceptance mechanism that use the traditional move <b>acceptance</b> <b>method</b> only to make a preliminary decision regarding whether to consider the new solution for acceptance or not. The performance of different selection hyper-heuristics combining different components, implemented based on the proposed framework is investigated on a range of sample grouping problem domains, including graph coloring, exam timetabling and data clustering domains. Additionally, the selection hyper-heuristics performing the best on each domain are compared to the previously proposed problem-specific algorithms from the scientific literature. The empirical results shows that the grouping hyper-heuristics built based on the proposed framework are not only sufficiently general, but also able to obtain high quality solutions, competitive to some previously proposed approaches. The selection hyper-heuristic employing the 'reinforcement learning' heuristic selection method and embedding the 'iteration limited threshold accepting' move <b>acceptance</b> <b>method</b> performs the best in the overall across those grouping problem domains...|$|E
40|$|Today, University Timetabling {{problems}} are occurred annually {{and they are}} often hard and time consuming to solve. This paper describes Hyper Heuristics (HH) method based on Great Deluge (GD) and its variants for solving large, highly constrained timetabling problems from different domains. Generally, in hyper heuristic framework, {{there are two main}} stages: heuristic selection and move acceptance. This paper emphasizes on the latter stage to develop Hyper Heuristic (HH) framework. The main contribution of this paper is that Great Deluge (GD) and its variants: Flex Deluge(FD), Non-linear(NLGD), Extended Great Deluge(EGD) are used as move <b>acceptance</b> <b>method</b> in HH by combining Reinforcement learning (RL). These HH methods are tested on exam benchmark timetabling problem and best results and comparison analysis are reported...|$|E
40|$|Automating the {{neighbourhood}} {{selection process}} in an iterative approach that uses multiple heuristics {{is not a}} trivial task. Hyper-heuristics are search methodologies that not only aim to provide a general framework for solving problem instances at different difficulty levels in a given domain, but a key goal is also to extend the level of generality so that different problems from different domains can also be solved. Indeed, a major challenge is to explore how the heuristic design process might be automated. Almost all existing iterative selection hyper-heuristics performing single point search contain two successive stages; heuristic selection and move acceptance. Different operators {{can be used in}} either of the stages. Recent studies explore ways of introducing learning mechanisms into the search process for improving the performance of hyper-heuristics. In this study, a broad empirical analysis is performed comparing Monte Carlo based hyper-heuristics for solving capacitated examination timetabling problems. One of these hyper-heuristics is an approach that overlaps two stages and presents them in a single algorithmic body. A learning heuristic selection method (L) operates in harmony with a simulated annealing move <b>acceptance</b> <b>method</b> using reheating (SA) based on some shared variables. Yet, the heuristic selection and move acceptance methods can be separated as the proposed approach respects the common selection hyper-heuristic framework. The experimental results show that simulated annealing with reheating as a hyper-heuristic move <b>acceptance</b> <b>method</b> has significant potential. On the other hand, the learning hyper-heuristic using simulated annealing with reheating move acceptance (Lâ€“SA) performs poorly due to certain weaknesses, such as the choice of rewarding mechanism and the evaluation of utility values for heuristic selection as compared to some other hyper-heuristics in examination timetabling. Trials with other heuristic selection methods confirm that the best alternative for the simulated annealing with reheating move acceptance for examination timetabling is a previously proposed strategy known as the choice function. status: publishe...|$|E
40|$|In your March 3, 1998 letter {{you made}} five {{requests}} to the Environmental Protection Agency (EPA). They were: 1. EPA <b>acceptance</b> of your <b>method</b> {{as an alternative}} to Method 18 to determine compliance for several subparts in part 60, 61,and 63. 2. EPA <b>acceptance</b> of your <b>method</b> {{as an alternative to}} Method 25 to determine compliance for several subparts in part 60, 61,and 63. 3. EPA <b>acceptance</b> of your <b>method</b> as an alternative to Method 25 in several subparts in part 264 and 265. 4. EPA <b>acceptance</b> of your <b>method</b> as an alternative to Method 106 to determine compliance for subpart F in part 61. 5. EPA proposal of your method in Appendix M, part 51. We have reviewed your request and have made the following conclusions...|$|R
50|$|The Bennett <b>acceptance</b> ratio <b>method</b> is {{implemented}} in modern molecular dynamics systems, such as Gromacs.Python-based code for MBAR and BAR {{is available for}} download at https://simtk.org/home/pymbar.|$|R
5000|$|Intergovernmental <b>acceptances</b> {{of testing}} <b>methods</b> and {{standards}} ...|$|R
40|$|Under section 303 (d) of the Clean Water Act, {{states must}} {{identify}} water segments where loads of. pollutants are violating numeric water quality standards. Consequences of misidentification are quite important. A decision that water quality is impaired initiates the total maximum daily load or TMDL planning requirement. Falsely concludin ~ that a water segment is impaired results in unnecessary TMDL plannine and oollution control i~n~lemeniation costs. On the other hand. hlscly concluding that a,&ment is not inlp~~rcd m. 8 ~ pose a nrk {{to human health}} or to the sen ices of the aquatic environment. Becausc of the cunsequencc,, a method 1 s dc,ired that minimizes or controls the error rates. The most commonlv. applied [...] aooroach [...] {{is to use the}} Environmental Protection Agency (EPA) 's mw score approach in which a stream scgmrnr is lirted 31 impired when grcaler than 10 per cent of the measurements of water quality conditions exceed a numeric criteria. An alternative to the EPA aovroach is the binomial test that the orooortion exceedine the standard is 0. 10 or less. This ao~roach uses the number of samples exceeding the criteha as a tesi statistic Gong with the binomial distribution fi; evaluation and estimation of error rates. Both approaches treat measurements as binary; thevalues either exceed or do not exceed the standard. An alternative approach is to use thc actual numerical;ulucr to eval~atc al~ndard. This method is referred to as variables acceptance sampling in quality control literature. The methods are compared on the basis of error rates. If certain assumptions are met then the variables <b>acceptance</b> <b>method</b> is superior {{in the sense that the}} variables <b>acceptance</b> <b>method</b> requires smaller sample sizes to achieve the same error rates as the raw score method or the binomial method. Issues associated with potential problems with environmental measurements and adjustments for their effects are discussed. Copyright 02003 John Wiley & Sons, Ltd. KEY WOKDS:TMDL; monitoring; standards; acceptance sampling by variables; binomial distributio...|$|E
40|$|Abstract Educational {{timetabling}} {{problem is}} a challenging real world problem which has been of interest to many researchers and practitioners. There are many variants of this problem which mainly require scheduling of events and resources under various constraints. In this study, a curriculum based course timetabling problem at Yeditepe University is described and an iterative selection hyper-heuristic {{is presented as a}} solution method. A selection hyper-heuristic as a high level methodology operates on the space formed by a fixed set of low level heuristics which operate directly on the space of solutions. The move acceptance and heuristic selection methods are the main components of a selection hyper-heuristic. The proposed hyper-heuristic in this study combines a simulated annealing move <b>acceptance</b> <b>method</b> with a learning heuristic selection method and manages a set of low level constraint oriented heuristics. A key goal in hyper-heuristic research is to build low cost methods which are general and can be reused The initial version of this study was presented at UKCI 2012...|$|E
40|$|High school {{timetabling}} is one {{of those}} recurring NP-hard real-world combinatorial optimisation problems that has to be dealt with by many educational institutions periodically, and so has been of interest to practitioners and researchers. Solving a high school timetabling problem requires scheduling of resources and events into time slots subject to a set of constraints. Recently, an international competition, referred to as ITC 2011 was organised to determine the state-of-the-art approach for high school timetabling. The problem instances, obtained from eight different countries across the world used in this competition became a benchmark for further research in the field. Selection hyper-heuristics are general-purpose improvement methodologies that control/mix a given set of low level heuristics during the search process. In this study, we evaluate the performance of a range of selection hyper-heuristics combining different reusable components for high school timetabling. The empirical results show the success of the approach which embeds an adaptive great-deluge move <b>acceptance</b> <b>method</b> on the ITC 2011 benchmark instances. This selection hyper-heuristic ranks the second among the previously proposed approaches including the ones competed at ITC 2011...|$|E
40|$|Selection hyper-{{heuristics}} {{are high}} level search methodologies which control {{a set of}} low level heuristics while solving a given problem. Move acceptance is a crucial component of selection hyper-heuristics, deciding whether to accept or reject a new solution at each step during the search process. This study investigates group decision making strategies as ensemble methods exploiting the strengths of multiple move <b>acceptance</b> <b>methods</b> for improved performance. The empirical results indicate {{the success of the}} proposed methods across six combinatorial optimisation problems from a benchmark as well as an examination timetabling problem...|$|R
40|$|A hyper-heuristic is a {{high level}} {{methodology}} which performs search over the space of heuristics each operating on the space of solutions to solve hard computational problems. This search process is based on either generation or selection of low level heuristics. The latter approach is used in selection hyper-heuristics. A generic selection hyper-heuristic has two main components which operate successively: heuristic selection and move <b>acceptance</b> <b>methods.</b> An initially generated solution is improved iteratively using these methods. At a given step, the most appropriate heuristic is selected from a fixed set of low level heuristics and applied to a candidate solution producing a new one. Then, a decision is made whether to accept or reject the new solution. This process is repeated until the termination criterion is satisfied. There is strong empirical evidence that the choice of selection hyper-heuristic influences its overall performance. This {{is one of the}} first studies to the best of our knowledge that suggests and explores the use of group decision making <b>methods</b> for move <b>acceptance</b> in selection hyper-heuristics. The acceptance decision for a move is performed by multiple methods instead of a single one. The performance of four such group decision making move <b>acceptance</b> <b>methods</b> are analysed within different hyper-heuristics over a set of benchmark functions. The experimental results show that the group decision making strategies have potential to improve the overall performance of selection hyper-heuristics...|$|R
50|$|Another {{fixed point}} are Crevenna's efforts for the method biofeedback, {{especially}} for its medical indication. Crevenna could improve the <b>acceptance</b> of this <b>method</b> under medical practitioners. As {{president of the}} Ã–sterreichische Gesellschaft fÃ¼r Biofeedback und Psychophysiologie, Ã–BFP, Crevenna integrated biofeedback into the curriculum of the MUW, which improved the <b>acceptance</b> of the <b>method</b> under medical practitioners.|$|R
40|$|Abstract Automating the {{neighbourhood}} {{selection process}} in an iterative approach that uses multiple heuristics {{is not a}} trivial task. Hyper-heuristics are search methodologies that not only aim to provide a general framework for solving problem instances at different difficulty levels in a given domain, but a key goal is also to extend the level of generality so that different problems from different domains can also be solved. Indeed, a major challenge is to explore how the heuristic design process might be automated. Almost all existing iterative selection hyper-heuristics performing single point search contain two successive stages; heuristic selection and move acceptance. Different operators {{can be used in}} either of the stages. Recent studies explore ways of introducing learning mechanisms into the search process for improving the performance of hyper-heuristics. In this study, a broad empirical analysis is performed comparing Monte Carlo based hyper-heuristics for solving capacitated examination timetabling problems. One of these hyper-heuristics is an approach that overlaps two stages and presents them in a single algorithmic body. A learning heuristic selection method (L) operates in harmony with a simulated annealing move <b>acceptance</b> <b>method</b> using reheating (SA) based on some shared variables. Yet, the heuristic selection and mov...|$|E
40|$|There is {{a growing}} {{interest}} towards the design of reusable general purpose search methods that are applicable to different problems instead of tailored solutions to a single particular problem. Hyper-heuristics have emerged as such high level methods that explore the space formed {{by a set of}} heuristics (move operators) or heuristic components for solving computationally hard problems. A selection hyper-heuristic mixes and controls a predefined set of low level heuristics with the goal of improving an initially generated solution by choosing and applying an appropriate heuristic to a solution in hand and deciding whether to accept or reject the new solution at each step under an iterative framework. Designing an adaptive control mechanism for the heuristic selection and combining it with a suitable <b>acceptance</b> <b>method</b> is a major challenge, because both components can influence the overall performance of a selection hyper-heuristic. In this study, we describe a novel iterated multi-stage hyper-heuristic approach which cycles through two interacting hyper-heuristics and operates based on the principle that not all low level heuristics for a problem domain would be useful at any point of the search process. The empirical results on a hyper-heuristic benchmark indicate the success of the proposed selection hyper-heuristic across six problem domains beating the state-of-the-art approach...|$|E
40|$|Educational {{timetabling}} {{problem is}} a challenging real world problem which has been of interest to many researchers and practitioners. There are many variants of this problem which mainly require scheduling of events and resources under various constraints. In this study, a curriculum based course timetabling problem at Yeditepe University is described and an iterative selection hyper-heuristic {{is presented as a}} solution method. A selection hyper-heuristic as a high level methodology operates on the space formed by a fixed set of low level heuristics which operate directly on the space of solutions. The move acceptance and heuristic selection methods are the main components of a selection hyper-heuristic. The proposed hyper-heuristic in this study combines a simulated annealing move <b>acceptance</b> <b>method</b> with a learning heuristic selection method and manages a set of low level constraint oriented heuristics. A key goal in hyper-heuristic research is to build low cost methods which are general and can be reused on unseen problem instances as well as other problem domains desirably with no additional human expert intervention. Hence, the proposed method is additionally applied to a high school timetabling problem, as well as six other problem domains from a hyper-heuristic benchmark to test its level of generality. The empirical results show that our easy-to-implement hyper-heuristic is effective in solving the Yeditepe course timetabling problem. Moreover, being sufficiently general, it delivers a reasonable performance across different problem domains...|$|E
5000|$|The Bennett <b>acceptance</b> ratio <b>method</b> (sometimes {{abbreviated}} to BAR) is an algorithm for estimating {{the difference in}} free energy between two systems (usually the systems will be simulated on the computer).It was suggested by [...] Charles H. Bennett in 1976.|$|R
40|$|A hyperheuristic is a {{high level}} problem solving {{methodology}} that performs a search over the space generated {{by a set of}} low level heuristics. One of the hyperheuristic frameworks is based on a single point search containing two main stages: heuristic selection and move acceptance. Most of the existing move <b>acceptance</b> <b>methods</b> compare a new solution, generated after applying a heuristic, against a current solution in order to decide whether to reject it or replace the current one. Late Acceptance Strategy is presented as a promising local search methodology based on a novel move <b>acceptance</b> mechanism. This <b>method</b> performs a comparison between the new candidate solution and a previous solution that is generated L steps earlier. In this study, the performance of a set of hyper-heuristics utilising different heuristic selection methods combined with the Late Acceptance Strategy are investigated over an examination timetabling problem. The results illustrate the potential of this approach as a hyper-heuristic component. The hyper-heuristic formed by combining a random heuristic selection with Late Acceptance Strategy improves on the best results obtained in a previous study...|$|R
40|$|Copyright Â© 2015 Carl-Ludwig Fischer-FroÌˆhlich et al. This is an {{open access}} article {{distributed}} under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. Background. Scarcity of grafts for kidney transplantation (KTX) caused an increased consideration of deceased donors with substantial risk factors. There is no agreement on which ones are detrimental for overall graft-survival. Therefore, we investigated in a nationwide multicentre study the impact of donor and recipient related risks known before KTX on graft-survival based on the original data used for allocation and graft <b>acceptance.</b> <b>Methods.</b> A nationwide deidentified multicenter study-database was created of data concerning kidneys donated and transplanted in Germany between 2006 and 2008 as provided by the national orga...|$|R
40|$|The final {{publication}} {{is available}} at Springer via [URL] timetabling problem is a challenging real world problem which has been of interest to many researchers and practitioners. There are many variants of this problem which mainly require scheduling of events and resources under various constraints. In this study, a curriculum based course timetabling problem at Yeditepe University is described and an iterative selection hyper-heuristic {{is presented as a}} solution method. A selection hyper-heuristic as a high level methodology operates on the space formed by a fixed set of low level heuristics which operate directly on the space of solutions. The move acceptance and heuristic selection methods are the main components of a selection hyper-heuristic. The proposed hyper-heuristic in this study combines a simulated annealing move <b>acceptance</b> <b>method</b> with a learning heuristic selection method and manages a set of low level constraint oriented heuristics. A key goal in hyper-heuristic research is to build low cost methods which are general and can be reused on unseen problem instances as well as other problem domains desirably with no additional human expert intervention. Hence, the proposed method is additionally applied to a high school timetabling problem, as well as six other problem domains from a hyper-heuristic benchmark to test its level of generality. The empirical results show that our easy-to-implement hyper-heuristic is effective in solving the Yeditepe course timetabling problem. Moreover, being sufficiently general, it delivers a reasonable performance across different problem domains...|$|E
40|$|FM Radio {{broadcasting}} systems {{almost entirely}} {{have used the}} stereo system. A transmitter and receiver FM able to process the information signal with the frequency more than 75 kHz so that stereo system can be realized easily. Stereo broadcast bandwidth requirement is equal to 53 kHz, the rest bandwidth is applicable to be other that is by adding SCA system (Subsidiary Communications Authorization). SCA used to deliver and accept the text data. Bandwidth of SCA system requires being limited {{in order not to}} bother the main broadcast program. Band from the limited SCA system used to deliver the digital information, for the reason need a digital modulation to optimize the bandwidth. Speed of data also require to be paid attention because the limited bandwidth. Data delivered have the start code so that only just certain receiver able to accept the data. Information delivery of SCA system is by using frequency modulation with the 67 kHz carrier frequency. To limit the bandwidth hence require to be filtered before transmitted. Digital information beforehand converted to in the form of analogue with the digital modulation FSK. Baud rate of delivery and data acceptance is same that is equal to 600 bps. Data delivered use the start code in the form of certain character which not present at the computer keyboard. Data <b>Acceptance</b> <b>method</b> represent the process which have reverse from delivery process. System have earned realized that is data sent acceptable successful and not bother the main broadcast program. By adding this system, modulation signal from stereo signal have to be decrease 11, 11...|$|E
40|$|Educational {{timetabling}} is a hard, challenging {{real world}} optimization problem {{which has been}} interest to researchers {{in the fields of}} optimization and artificial intelligence. This problem has many variants including examination timetabling, university course timetabling, and high school timetabling. In this study we focus on high school timetabling problem which requires scheduling of resources and events in time slots under a set of constraints. Selection hyper-heuristic is a high level search methodology that operates on the space of a fixed set of low level heuristics that operates directly on the space of the solution. The selection hyper-heuristic has two main components: heuristic selection, and move acceptance. A heuristic selection selects a low level heuristic from a set of low level heuristics and applies it to generate a solution. The <b>acceptance</b> <b>method</b> decides to accept or reject the new solution. In this study we present a set of effective selection hyper-heuristics that mixes and controls a set of perturbative low level heuristics to present a solution to the high school timetabling problem. A set of selection methods combined with a set of move acceptance methods were tested and their performance was analysed using different statistical measures on a set of instances of the high school timetabling problem by the aim of comparing and determining the performance variations between the selection hyper-heuristics and choosing the best approach to solve the high school timetabling problem. The empirical results of the study proved the effectiveness of the approach in solving the high school problem achieving results that outperformed most of the best known approaches...|$|E
5000|$|For the one {{carrying}} the [...] "burden of proof", the advocate, to marshal evidence for his/her position {{in order to}} convince or force the opponent's <b>acceptance.</b> The <b>method</b> by which this is accomplished is producing valid, sound, and [...] arguments, devoid of weaknesses, and not easily attacked.|$|R
40|$|In {{carrying}} out surveys to estimate disease prevalence or health services coverage in a region, investigators are often interested in identifying communities or other subareas {{in which the}} problem of interest is especially severe. In view of {{the large number of}} subareas to be examined, the investigator seeks rapid methods of assess-ment that require minimum sampling in each. Lot quality assurance sampling, developed more than 60 years ago to meet industrial quality control needs, has been found to serve public health purposes as well. Curiously, other more recent and more powerful industrial techniques have not received the recognition they deserve. Several of them are discussed in this paper and likely applications are cited. They fall into two categories: 1) lot <b>acceptance</b> <b>methods</b> to depict static conditions in a population and 2) more dynamic process monitoring methods for continuous surveillance. Under the firs...|$|R
40|$|The nonequilibrium work {{fluctuation}} theorem {{provides the}} way for calculations of (equilibrium) free energy based on work measurements of nonequilibrium, finite-time processes and their reversed counterparts by applying Bennett's <b>acceptance</b> ratio <b>method.</b> A nice property of this method is that each free energy estimate readily yields {{an estimate of the}} asymptotic mean square error. Assuming convergence, it is easy to specify the uncertainty of the results. However, sample sizes have often to be balanced with respect to experimental or computational limitations and the question arises whether available samples of work values are sufficiently large in order to ensure convergence. Here, we propose a convergence measure for the two-sided free energy estimator and characterize some of its properties, explain how it works, and test its statistical behavior. In total, we derive a convergence criterion for Bennett's <b>acceptance</b> ratio <b>method.</b> Comment: 14 pages, 17 figure...|$|R
40|$|This thesis {{addresses}} {{the most important}} element of operational performance of roundabout traffic intersections in Rourkela on capacity analysis. The movements of the vehicles were observed at 5 roundabouts along ring road in Rourkela. Gap acceptance and follow up time were estimated for cars for one hour analysis. The relation between a roundabout performance measure and capacity is expressed in terms of degree of saturation (volume â€“ Capacity ratio). The capacity analysis is done based on gap <b>acceptance</b> <b>method</b> that is adopted by Tanner based on the HCM 2010. The traffic movement data with vehicle characteristics were collected from 5 roundabouts in Rourkela. These 5 roundabouts are directly related to their approach leg numbers. Tanner models use the gap-acceptance theory (or critical headway) to simulate the behaviour of entering vehicles and vehicles circulating within the roundabout. Current research work on roundabout models mostly concentrates on determining the capacity of an approach based on the entering and circulating flows. Approach capacity is calculated as a mathematical function of critical headway and follow-up headway. The Tanner model is based on gap- acceptance theory with gap-acceptance parameters. The Highway Capacity Manual (HCM 2010) roundabout tanner capacity model is an analytical (exponential regression) model with clear basis in gap-acceptance theory. The NCHRP Report 572 model is based on empirical exponential regression) capacity model with no explicitly. Capacity analysis results indicated that out of 5 roundabouts 1 of them has greater than 0. 85 degree of saturation and this roundabout has critical for traffic flow because this has degree of saturation more than 0. 85...|$|E
40|$|The {{conformational}} {{free energy}} landscape {{of a system}} is a fundamental thermodynamic quantity of importance particularly {{in the study of}} soft matter and biological systems, in which the entropic contributions play a dominant role. While computational methods to delineate the free energy landscape are routinely used to analyze the relative stability of conformational states, to determine phase boundaries, and to compute ligand-receptor binding energies its use in problems involving the cell membrane is limited. Here, we present an overview of four different free energy methods to study morphological transitions in bilayer membranes, induced either by the action of curvature remodeling proteins or due to the application of external forces. Using a triangulated surface {{as a model for the}} cell membrane and using the framework of dynamical triangulation Monte Carlo, we have focused on the methods of Widom insertion, thermodynamic integration, Bennett acceptance scheme, and umbrella sampling and weighted histogram analysis. We have demonstrated how these methods can be employed in a variety of problems involving the cell membrane. Specifically, we have shown that the chemical potential, computed using Widom insertion, and the relative free energies, computed using thermodynamic integration and Bennett <b>acceptance</b> <b>method,</b> are excellent measures to study the transition from curvature sensing to curvature inducing behavior of membrane associated proteins. The umbrella sampling and WHAM analysis has been used to study the thermodynamics of tether formation in cell membranes and the quantitative predictions of the computational model are in excellent agreement with experimental measurements. Furthermore, we also present a method based on WHAM and thermodynamic integration to handle problems related to end-point-catastrophe that are common in most free energy methodsComment: 15 pages and 6 figure...|$|E
40|$|There is {{a growing}} {{interest}} towards self configuring/tuning automated general-purpose reusable heuristic approaches for combinatorial optimisation, such as, hyper-heuristics. Hyper-heuristics are search methodologies which explore the space of heuristics rather than the solutions to solve {{a broad range of}} hard computational problems without requiring any expert intervention. There are two common types of hyper-heuristics in the literature: selection and generation methodologies. This work focuses on the former type of hyper-heuristics. Almost all selection hyper-heuristics perform a single point based iterative search over the space of heuristics by selecting and applying a suitable heuristic to the solution in hand at each decision point. Then the newly generated solution is either accepted or rejected using an <b>acceptance</b> <b>method.</b> This improvement process is repeated starting from an initial solution until a set of termination criteria is satisfied. The number of studies on the design of hyper-heuristic methodologies has been rapidly increasing and currently, we already have a variety of approaches, each with their own strengths and weaknesses. It has been observed that different hyper-heuristics perform differently on a given subset of problem instances and more importantly, a hyper-heuristic performs differently as the set of low level heuristics vary. This thesis introduces a general "multi-stage" hyper-heuristic framework enabling the use and exploitation of multiple selection hyper-heuristics at different stages during the search process. The goal is designing an approach utilising multiple hyper-heuristics for a more effective and efficient overall performance when compared to the performance of each constituent selection hyper-heuristic. The level of generality that a hyper-heuristic can achieve has always been of interest to the hyper-heuristic researchers. Hence, a variety of multi-stage hyper-heuristics based on the framework are not only applied to the real-world combinatorial optimisation problems of high school timetabling, multi-mode resource-constrained multi-project scheduling and construction of magic squares, but also tested on the well known hyper-heuristic benchmark of CHeSC 2011. The empirical results show that the multi-stage hyper-heuristics designed based on the proposed framework are still inherently general, easy-to-implement, adaptive and reusable. They can be extremely effective solvers considering their success in the competitions of ITC 2011 and MISTA 2013. Moreover, a particular multi-stage hyper-heuristic outperformed the state-of-the-art selection hyper-heuristic from CHeSC 2011...|$|E
25|$|As {{there is}} no formal {{procedure}} for any community to record <b>acceptance,</b> the primary <b>method</b> of determining Indigenous population is from self-identification on census forms.|$|R
40|$|In {{the last}} decade, Government/Industry {{programs}} have advanced powder metallurgy-near-net-shape technology {{to permit the}} use of hot isostatic pressed (HIP) turbine disks in the commercial aircraft fleet. These disks offer a 30 % savings of input weight and an 8 % savings in cost compared in cast-and-wrought disks. Similar savings were demonstrated for other rotating engine components. A compressor rotor fabricated from hot-die-forged-HIP superalloy billets revealed input weight savings of 54 % and cost savings of 35 % compared to cast-and-wrought parts. Engine components can be produced from compositions such as Rene 95 and Astroloy by conventional casting and forging, by forging of HIP powder billets, or by direct consolidation of powder by HIP. However, each process produces differences in microstructure or introduces different defects in the parts. As a result, their mechanical properties are not necessarily identical. <b>Acceptance</b> <b>methods</b> should be developed which recognize and account for the differences...|$|R
40|$|Reflects on {{the controversies}} and {{conflicts}} {{associated with the}} collective management of music copyright. Reviews the initial opposition to collective enterprises for collecting performance fees, the factors contributing to their <b>acceptance,</b> the <b>methods</b> of collection, the development of litigation, its uses, and the move to shift liability to performance venues. Discusses the development of sustainable data infrastructures linking data to music...|$|R
