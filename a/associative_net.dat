18|27|Public
50|$|In 1969 {{scientists}} D. Wilshaw, O.P. Buneman and H Longuet-Higgins {{proposed an}} alternative, non-holographic model that fulfilled {{many of the}} same requirements as Gabor's original holographic model. The Gabor model did not explain how the brain could use Fourier analysis on incoming signals or how it would deal with the low signal-noise ratio in reconstructed memories. Longuet-Higgin's correlograph model built on the idea that any system could perform the same functions as a Fourier holograph if it could correlate pairs of patterns. It uses minute pinholes that do not produce diffraction patterns to create a similar reconstruction as that in Fourier holography. Like a hologram, a discrete correlograph can recognize displaced patterns and store information in a parallel and non-local way so it usually will not be destroyed by localized damage. They then expanded the model beyond the correlograph to an <b>associative</b> <b>net</b> where the points become parallel lines arranged in a grid. Horizontal lines represent axons of input neurons while vertical lines represent output neurons. Each intersection represents a modifiable synapse. Though this cannot recognize displaced patterns, it has a greater potential storage capacity. This was not necessarily meant to show how the brain is organized, but instead to show the possibility of improving on Gabor's original model. P. Van Heerden countered this model by demonstrating mathematically that the signal-noise ratio of a hologram could reach 50% of ideal. He also used a model with a 2D neural hologram network for fast searching imposed upon a 3D network for large storage capacity. A key quality of this model was its flexibility to change the orientation and fix distortions of stored information, which is important for our ability to recognize an object as the same entity from different angles and positions, something the correlograph and association network models lack.|$|E
40|$|We have {{determined}} the capacity and information efficiency of an <b>associative</b> <b>net</b> configured in a brain-like way with partial connec-tivity and noisy input cues. Recall theory {{was used to}} calculate the capacity when pattern recall is achieved using a winners-take-all strategy. Transforming the dendritic sum according to input activity and unit usage can greatly increase the capacity of the <b>associative</b> <b>net</b> under these conditions. For moderately sparse pat-terns, maximum information efficiency is achieved with very low connectivity levels (~ 10 %). This corresponds to the level of con-nectivity commonly seen in the brain and invites speculation that the brain is connected in the most information efficient way. ...|$|E
40|$|This paper {{describes}} {{a method for}} improving the generalization performance {{by means of the}} out-of-bag estimate for the generalization error in regression problems. We analyze the effect of the size of bags from the viewpoint of piecewise linear prediction achieved by the CAN 2 (competitive <b>associative</b> <b>net).</b> Here, the CAN 2 basically is a neural net for learning efficient piecewise linear approximation of nonlinear functions. We also examine and validate the effectiveness via numerical experiments...|$|E
40|$|Abstract—We {{present a}} robust {{implementation}} of a motion detection algorithm based on a markovian relaxation both on General Purpose Processors, and on a specialized architecture, the Associative Mesh. The Mesh architecture is an instance of the <b>associative</b> <b>nets</b> model targeting real time execution of low level image algorithms and vision-Soc implementation. The algorithm implementation on both architectures is described, and also the required optimizations to speedup the execution...|$|R
5000|$|Neural Networks (Perceptron, <b>associative</b> memories, spiking <b>nets)</b> ...|$|R
40|$|In the {{critical}} bibliography referred to Lope de Vega, the scholar usually finds {{the image of}} this author as a forerunner of Calderón. A good strategy to verify this impression is through partial studies as this devoted {{to the analysis of}} the bestiary in the sacramental plays. This article analyses the bestiary assigned to Christ, the devil and others more eclectic references ascribed to metaphorical expressions, or biblical characters. In short, the author proves that there is a strategy of performance through <b>associative</b> <b>nets</b> (that combines biblical text, patristic references, emblems, sculpture and painting) laying down the way to the magnificense of Calderón...|$|R
40|$|Principle of {{parallel}} neuronal constellations [...] 4 Principle of coherent functional group of neurons [...] 5 Population coding paradigm [...] . 5 Neuronal cortex as multidimensional coding “Fourier- windows “ [...] 6 The proposal of fractal mechanism in the cortex [...] . 7 Phase detection in the Fourier transformation [...] . 9 Is the cortex a hologram-like processor? [...] … [...] . 10 Neuroanatomical {{advantages of the}} neuronal Fourier hologram [...] . 11 Basic cognitive advantage of the neuronal Fourier hologram [...] . 12 Fourier hologram versus <b>associative</b> <b>net</b> neuronal models [...] 1...|$|E
40|$|Abstract. The {{competitive}} <b>associative</b> <b>net</b> called CAN 2 {{has been}} shown effective in many applications, such as function approximation, control, rainfall estimation, time-series prediction, and so on, but the learning method has been constructed basically for reducing the training (empir-ical) error. In order to reduce prediction (generalization) error, we, in this article, try to apply the ensemble scheme to the CAN 2 and present a method to select an effective number of units for the ensemble. We show the result of numerical experiments and examine {{the effectiveness of the}} present method. ...|$|E
40|$|Temperature {{control of}} RCA {{solutions}} for stably clean-ing silicon wafers is important but difficult owing that the RCA solutions such as SPM (sulfric acid and hydro-gen peroxide mixture) expose time-varying and nonlinear exothermic chemical reactions. So far, {{we have developed}} MSPC (model switching predictive controller) using an online learning CAN 2 (competitive <b>associative</b> <b>net),</b> {{but it has a}} possibility to forget the data for the transient period after a long stationary period. In order to overcome the problem, we here apply the batch learning CAN 2. Nu-merical experiments show that the batch learning CAN 2 shows better control performance than the online learning CAN 2...|$|E
40|$|Abstract — Cross-validation and bootstrap, or {{resampling}} {{methods in}} general, are examined for applying them to optimizing {{the number of}} units of competitive <b>associative</b> <b>nets</b> called CAN 2. There {{are a number of}} resampling methods available, but the performance depends on the neural network to be applied and functions to be learned. So, we apply several resampling methods to the CAN 2 which has been shown effective in many areas so far. By means of numerical experiments, we have observed that a modified bootstrap method and the Lendasse’s bootstrap estimator work well for selecting the number of units. We also describe a new method and its performance for estimating generalization error via resampling methods. I...|$|R
40|$|The symbol-based, {{correspondence}} epistemology used in AI is {{contrasted with}} the constructivist, coherence epistemology promoted by cybernetics. The latter leads to bootstrapping knowledge representations, in which {{different parts of the}} cognitive system mutually support each other. Gordon Pask's entailment meshes and their implementation in the THOUGHTSTICKER program are reviewed as a basic application of this approach. Entailment meshes are then extended to entailment nets: directed graph representations governed by the bootstrapping axiom, determining which concepts are to be distinguished ormerged. This allows a constant restructuring and elicitation of the conceptual network. Semantic networks and frame-like representations with inheritance can be expressed in this very general scheme by introducing a basic ontology of node and link types. Entailment nets are then generalized to <b>associative</b> <b>nets</b> characterized by weighted links. Learning algorithms are presented which [...] ...|$|R
40|$|<b>Associative</b> <b>nets</b> is a {{well suited}} {{parallel}} computing model for image analysis. It allows to perform asynchronous computations an irregular data. Some efficient implementations have been designed, either in hardware or software. Asynchronism can largely improve the algorithm speeds, provided these algorithms can be written with operators that allow the asynchronous implementation. Classical operators, such as min, max, And, or, [, ", lcm, gcd, : : :, {{are known for their}} ability to stabilize asynchronous computations. We defined a larger class of operators, called the r-operators, that still insure the termination of the asynchronous computations. After presenting our model, the interest of the asynchronism and the r-operators, we investigate in this paper the applications of the r-operators in image analysis. We show that they are useful for distance transformation, contour closing and image segmentation. Chapter 1 Introduction 1. 1 Image analysis Several properties characterize im [...] ...|$|R
40|$|A new AI {{programming}} language is described which provides facilities for the storage, retrieval and manipulation of fuzzy information. The language (called FUZZY) contains such standard features as an associative data base and a pattern-directed data access and procedure invocation mechanism. These basic facilities are extended, however, by "fuzzifying" the <b>associative</b> <b>net,</b> and by allowing fuzzy procedures and "procedure demons" {{to be specified}} for the control of fuzzy processes. The paper discusses {{some of the major}} features of FUZZY in the context of previous AI language efforts, presents a simple fuzzy question-answerer as an example, and then summarizes the complete language as it now stands. FUZZY is currently being programmed in LISP on a UNIVAC 1110 computer...|$|E
40|$|Abstract. For {{cleaning}} silicon wafers via the RCA clean, {{temperature control}} {{is important in}} order to obtain a stable performance, but it is difficult mainly because the RCA solutions expose nonlinear and time-varying exothermic chemical reactions. So far, the MSPC (model switch-ing predictive controller) using the CAN 2 (competitive <b>associative</b> <b>net</b> 2) has been developed and the effectiveness has been validated. However, we have observed that the control performance, such as overshoot and settling time, does not always improve as the number of learning itera-tions increases when using multiple units of the CAN 2. So we apply the ensemble learning scheme to the CAN 2 for stable control over learning iterations, and we examine the effectiveness of the present method by means of computer simulation. ...|$|E
40|$|Abstract The <b>associative</b> <b>net</b> {{model of}} {{heteroassociative}} memory with binaryvalued synapses {{has been extended}} to include recent experimental data that indicates that in the hippocampus one form of synaptic modification {{is a change in}} the probability of synaptic transmission [2]. Pattern pairs are stored in the net by a version of the Hebbian learning rule that changes the probability of transmission at synapses where the presynaptic and postsynaptic units are simultaneously active from a low, base value to a high, modified value. Numerical calculations of the expected recall response have been used to assess the performance for different values of the base and modified probabilities. If there is a cost incurred with generating the difference between these probabilities, then the optimal difference is around 0. 4. Performance can be greatly enhanced by using multiple cue presentations during recall...|$|E
40|$|AI {{requires}} Logic. But its Classical version shows {{too many}} insufficiencies. So, {{it is very}} necessary to introduce more sophisticated tools, as may be Fuzzy Logic, Modal Logic, Non-Monotonic Logic, and so on [2]. Among the things that AI needs to represent are Categories, Objects, Properties, Relations between objects, Situations, States, Time, Events, Causes and effects, Knowledge about knowledge, and so on. The problems in AI can be classified in two general types[3, 4], Search Problems and Representation Problem. There exist different ways to reach this objective. So, we have [3] Logics, Rules, Frames, <b>Associative</b> <b>Nets,</b> Scripts, and so on, many times interconnect. Also {{it will be very}} useful, in the treatment of the problems of uncertainty and causality, the introduction of Bayesian Networks and particularly, a principal tool as the Essential Graph. We attempt here to show the scope of application of such versatile methods, currently fundamental in Medicine...|$|R
40|$|Artificial Intelligence {{requires}} logic. But its classical version shows {{too many}} insufficiencies. So, {{it is absolutely}} necessary to introduce more sophisticated tools, such as Fuzzy Logic, Modal Logic, Non-Monotonic Logic, and so on [2]. Among the things that AI needs to represent are categories, objects, properties, relations between objects, situations, states, time, events, causes and effects, knowledge about knowledge, and so on. The problems in AI can be classified in two general types [3, 4]: Search Problems and Representation Problem. There exist different ways to reach this objective. So, we have [3] Logics, Rules, Frames, <b>Associative</b> <b>Nets,</b> Scripts and so on, that are often interconnected. Also, {{it will be very}} useful, in dealing with problems of uncertainty and causality, to introduce Bayesian Networks, and particularly, a principal tool as the Essential Graph. We attempt here to show the scope of application of such versatile methods, currently fundamental in Medicine...|$|R
40|$|A {{model of}} {{associate}} memory incorporating global linearity and pointwise nonlinearities {{in a state}} space of n-dimensional binary vectors is considered. Attention {{is focused on the}} ability to store a prescribed set of state vectors as attractors within the model. Within the framework of such <b>associative</b> <b>nets,</b> a specific strategy for information storage that utilizes the spectrum of a linear operator is considered in some detail. Comparisons are made between this spectral strategy and a prior scheme that utilizes the sum of Kronecker outer products of the prescribed set of state vectors, which are to function nominally as memories. The storage capacity of the spectral strategy is linear in n (the dimension of the state space under consideration), whereas an asymptotic result of n/ 4 log n holds for the storage capacity of the outer product scheme. Computer-simulated results show that the spectral strategy stores information more efficiently. The preprocessing costs incurred in the two algorithms are estimated, and recursive strategies are developed for their computation...|$|R
40|$|The {{classical}} {{forms of}} knowledge representation fail when a strong dynamical interconnection between system and environment comes into play. We propose here {{a model of}} information retrieval derived from the Kintsch-Ericsson scheme, based upon a long term memory (LTM) <b>associative</b> <b>net</b> whose structure changes in time according to the textual content of the analyzed documents. Both the theoretical analysis carried out by using simple statistical tools and the tests show the appearing of typical power-laws and the net configuration as a scale-free graph. The information retrieval from LTM shows that the entire system can {{be considered to be}} an information amplifier which leads to the emergence of new cognitive structures. It has to be underlined that the expanding of the semantic domain regards the user-network as a whole system. Comment: 8 pages, 11 figures, 2 tables. Submitted to Emergence: Complexity and Organizatio...|$|E
40|$|The RCA {{cleaning}} {{method is}} {{the industry standard}} way for cleaning silicon wafers, and the temperature control is important for a stable cleaning performance. However, the difficulty {{lies in the fact}} that the RCA solutions cause nonlinear and time-varying exothermic chemical reactions. So far, the MSPC (model switching predictive controller) using the CAN 2 (competitive <b>associative</b> <b>net</b> 2) has been developed and the effectiveness has been validated. However, we have observed that the control performance, such as the settling time and the overshoot, does not always improve with the increase of the number of learning iterations for the CAN 2. To solve this problem, we introduce the bagging method for the CAN 2 and first-difference signals for effectively embedding the bagging method. The effectiveness and the performance of the present method are examined by means of numerical experiments...|$|E
40|$|Numerical {{calculations}} {{have been}} used to assess the performance of three different winners-take-all recall strategies for the <b>associative</b> <b>net</b> model of heteroassociative memory. Two strategies designed to improve recall when the net is partially connected or the input cues are noisy are shown to provide significantly greater capacity and information efficiency under these conditions. Estimates are made for the capacity of nets that are the size of the CA 3 region of the rat hippocampus. These indicate that thousands of patterns can be stored, with the exact number highly dependent on pattern coding rates and the recall strategy. Analysis of nets with different types of structure shows that the capacity is much more sensitive to net size than to connectivity level. This has implications for neurobiology where there are examples of environmentally produced changes in both the size and connectivity of various brain regions...|$|E
40|$|Abstract:- Unified Modeling Language (UML) is a {{standard}} language for software blueprints, UML {{can be used to}} visualize, specify, construct and document software-intensive system of heritage. In the UML, the activity diagrams often are widely used to workflow and system flow in system analysis. However, the activity diagram of UML now there are still many drawbacks to be overcome, such as lacks support for simulation, dynamic semantics limits and verifiability capabilities. Petri nets are a popular technique for modeling the control flow dimension of workflows. <b>Associative</b> Petri <b>nets</b> (APNs) not only take all the advantages of PNs but also has a complete semantics, simulation and verifiability capabilities. Therefore, in this paper, we propose a methodology to describe how UML Activity diagrams can be intuitively translated into an APN model. This work can improve the simulation and verifiability capabilities of activity diagram and provides the systematic procedure to reduce complexity of translating activity diagrams into <b>associative</b> Petri <b>net...</b>|$|R
40|$|An {{approach}} to time series prediction of the CATS benchmark (for competition on artificial time series) is presented, where we use Fourier bandpass filters and competitive <b>associative</b> <b>nets</b> (CAN 2 s). Since {{one of the}} difficulties of this prediction is that the given time series {{does not seem to}} involve sufficient number of data for obtaining the underlying dynamics of the time series to reproduce low frequency components, we apply the CAN 2 only for learning high frequency components extracted via Fourier bandpass filters with trial parameter values of the upper and lower cutoff frequencies and the missing last value of the given time series. Supposing that the optimal values among the trial values will give the best prediction performance for high frequency components, we can identify such optimal values via a certain reasonable validation method, with which we predict the missing high frequency components, and then we obtain the missing data to be predicted via adding high and low frequency components...|$|R
40|$|ABSTRACT AI {{requires}} Logic. But its Classical version shows {{too many}} insufficiencies. So, {{it is very}} necessary to introduce more sophisticated tools, as may be Fuzzy Logic, Modal Logic, NonMonotonic Logic, and so on [2]. Among the things that AI needs to represent are Categories, Objects, Properties, Relations between objects, Situations, States, Time, Events, Causes and effects, Knowledge about knowledge, and so on. The problems in AI can be classified in two general types [3, 4], Search Problems and Representation Problem. There exist different ways to reach this objective. So, we have [3] Logics, Rules, Frames, <b>Associative</b> <b>Nets,</b> Scripts, and so on, many times interconnect. Also {{it will be very}} useful, in the treatment of the problems of uncertainty and causality, the introduction of Bayesian Networks and particularly, a principal tool as the Essential Graph. We attempt here to show the scope of application of such versatile methods, currently fundamental in Medicine...|$|R
40|$|A {{detailed}} compartmental {{model of}} a cortical pyramidal cell is {{used to determine the}} effect of the spatial distribution of synapses across a dendritic tree on the pattern recognition capability of the neuron. By setting synaptic strengths according to the clipped Hebbian learning rule used in the <b>associative</b> <b>net</b> neural network model, the cell is able to recognise input patterns, but with a one to two order of magnitude decrease in performance compared to the computing units in the network model. Performance of the cell is optimised by particular forms of input signal, but is not altered by different pattern recognition criteria. 1 Introduction The experimental phenomena of long-term potentiation (LTP) and long-term depression (LTD) suggest certain synaptic pathways within the mammalian central nervous system are modified in a Hebbian fashion (for a review see [4]). Neural network models of associative memory use Hebbian learning for pattern storage. Such memories are often [...] ...|$|E
40|$|Somd-st-/the issues {{associated}} with'the {{lack of a}} precisely stated theory of memory organization are considered., The first sec*ion {{provides an overview of}} the concept of organization. emphasis is on problems associated with the definition. of organization, especially the distinction between organization as a process'ard as the product of a process. A definition of organization is offered that is 'linked to a'progolem solving view of list learning. he second section attempts to provide an overview of the different types of organizational processe 8 and strategies that fall within the domain of a theory of organization. Of particular concern are the problems that have-arisen because single and multiple measures of organizational strategies have been derived in the absence of specific process theoriesoThe final section attempts to consider-the strengths and weaknesses Of a precisely specified thejory of free recnll, embodied in a computer program called 'Free Recall by an <b>Associative</b> <b>Net</b> (FRANI. (Author/GKI *;le-productions supplied by EDRS are the best that can be uiale t from the original document. *********************vt***********************ws%W*******************...|$|E
40|$|The {{competitive}} <b>associative</b> <b>net</b> called CAN 2 - 2 {{has been}} presented for learning to approximate time-varying dynamics of a plant {{in order to control}} the plant. Although the learning method has been shown effective in the previous studies, it uses the gradient method involving local minima problems. To overcome the problems, we here consider asymptotic situation, where the number of units of the net is very large, and show that the mean square error of the CAN 2 - 2 in approximating time-varying function decreases to be minimized as the number of units increases when the firing numbers of the units are equated. Next, we embed the condi-tion for equating the firing numbers into the learning algorithm of the CAN 2 - 2, and then examine the conventional MSPC (model switching predictive controller) using the modified CAN 2 - 2 in tem-perature control of the RCA solutions for cleaning silicon wafers which expose exothermic nonlinear and time-varying chemical re-actions. As a result, the present method has better learning prop-erties than the conventional one. 1...|$|E
40|$|This work {{deals with}} the {{termination}} of global computations performed in a distributed network of computing entities defined as follows. Each computing entity computes with a given operator a single value using those it receives from its direct ancestors in the network. This value is then sent to its direct descendants. The network is supplied {{at the beginning of}} the global computation with private datum of each entity. The system runs in asynchronous mode. Binary operators which are associative, commutative and idempotent (s-operators) allow to the global computation to terminate (Tel, 1994). In previous work, we introduced a more general class of operators, called the binary r-operators, that still allow termination of global computations. In this report, we complete the definition of the <b>associative</b> <b>nets</b> in such a way that n-ary operators can be used by the entities. Then, we extend previous results to the n-ary r-operators. Next, we study some more general operators and we disc [...] ...|$|R
40|$|Abstract-A {{model of}} {{associative}} memory incorporating global linearity and pointwise nonlinearities {{in a state}} space of n-dimensional binary vectors is considered. Attention {{is focused on the}} ability to store a prescribed set of state vectors as attractors within the model. Within the framework of such <b>associative</b> <b>nets,</b> a specific strategy for information storage that utilizes the spectrum of a linear operator is considered in some detail. Comparisons are made between this spectral strategy and a prior proposed scheme which utilizes the sum of Kronecker outer products of the prescribed set of state vectors which are to function nominally as memories. The storage capacity of the spectral strategy is linear in n, the dimension of the state space under consideration, while an asymptotic result of n/ 4 logn holds for the storage capacity of the outer product scheme. Computer-simulated results are quoted in suppod of the analysis to show that the spectral strategy stores information more efficiently than the outer product scheme. Estimates of the preprocessing costs incurred in the two algorithms are provided, and recursive strategies are developed for their computation. I...|$|R
40|$|Recently, we have {{presented}} {{a method of}} probabilistic prediction of chaotic time series. The method employs learning machines involving strong learners capable of making predictions with desirably long predictable horizons, where, however, usual ensemble mean for making representative prediction is not effective when there are predictions with shorter predictable horizons. Thus, the method selects a representative prediction from the predictions generated {{by a number of}} learning machines involving strong learners as follows: first, it obtains plausible predictions holding large similarity of attractors with the training time series and then selects the representative prediction with the largest predictable horizon estimated via LOOCV (leave-one-out cross-validation). The method is also capable of providing average and/or safe estimation of predictable horizon of the representative prediction. We have used CAN 2 s (competitive <b>associative</b> <b>nets)</b> for learning piecewise linear approximation of nonlinear function as strong learners in our previous study, and this paper employs bagging (bootstrap aggregating) to improve the performance, which enables us to analyze the validity and the effectiveness of the method...|$|R
40|$|A joint algorithm-architecture {{study has}} {{resulted}} {{into a new}} version of a picture segmentation system complying with multimedia mobile terminal constraints, i. e., real-time computing, and low power consumption. Previously published watershed segmentation algorithms required at least three global synchronization points: minima detection, labeling and flooding. This paper presents a new fully asynchronous algorithm, where pixels can compute their local data in parallel and independently from one another, and which requires only a unique final global synchronization point. This paper provides a formal demonstration of the convergence and correctness of this new parallel asynchronous algorithm using a mathematical model of data propagation in a graph: the <b>associative</b> <b>net</b> formalism. We demonstrate the simplicity of implementation of this algorithm on parallel processor arrays. We explore, simulate, and validate several configurations of the algorithm-architecture using a “SystemC” model. Simulations reveal an image segmentation rate up to 66, 000 QCIF images/sec, i. e., a speed-up factor of more than 1, 000 times compared with state of the art watershed algorithms. A fine grain processor array design using STmicroelectronics 0 : 18 _m CMOS technology confirms that this new approach is a breakthrough in the domain of real-time image segmentation...|$|E
40|$|This work is {{concerned}} with the problem of constructing associative memory models which store and retrieve information in a distributed fashion - that is each store location can be involved in the storage of more than one piece of information. The models are to be logically simple in form and efficient in their use of store. It is hoped that those proposed may find a place in neurophysiological theories of memory. From the starting point of seeking a less complex representation of a holographic model of memory called the Holophone, several memory models have been proposed and their properties investigated by analytical and computer simulation methods. All the systems considered belong to a family of memory models which are described by a pair of matrix equations. It is found that the models which perform well are non-linear devices which have to store and retrieve highly redundant information. One of these, the <b>Associative</b> <b>Net,</b> is closely related to a recent theory of the cerebellum. Some of the contents of Chapters 3, 4 and 5 have already appeared in papers published in collaboration with H. C. Longuet-Higgins and O. P. Buneman. Otherwise this dissertation is believed to be original in content and in arrangement...|$|E
40|$|Knowledge {{representation}} {{is an active}} field of Artificial Intelligence research. The method of representation strongly influences the possible types of processing of the knowledge base. The knowledge base and the mechanisms for its manipulation determine the intelligence of a computer program. Therefore a powerful representation system is desired to enable the mechanisms to operate at full potential. Numerous approaches to representing knowledge {{have resulted in a}} wide range of knowledge representation (KR) formalisms. At one end of the scale are the simple techniques which give little or no indication of the structure of knowledge, such as LISP Property Lists. At the other extreme are semantic networks, frames, actors, predicate calculus and production systems. The distance between them is large - the designers had different ideas of how to best represent the knowledge when the systems were developed. Many of the earlier attempts, such as the associational network model of "semantic memory" proposed by M. Quillian [Quillian 66], provided the groundwork for later KR languages. Quillian's model used associative links connecting nodes in order to permit "human like use" of the meanings of the words, and closely reflected the organisation of a dictionary. Further improvements lead to hierarchies of concepts with attached properties [Collins & Quillian 70]. Predicate logic systems, such as PROLOG [Colmerauer et alia 73], developed independently, and were oriented towards using facts to make deductions. Production systems were first proposed in 1943 by E. Post [Post 43]. These were based on productions, a set of conditions and an action, which work on a knowledge base. Some non-network formalisms like KRL [Bobrow & Winograd 77] and FRL [Roberts & Goldstein 77] share many features with semantic network systems such as KLONE [Brachman 79]. The aim of this project is to determine the differences between the formalisms. This includes determining which features are common to all formalisms, which features are unique, the methods of representing knowledge, and some measure of the power of each formalism. The large number of formalisms and independent research has lead to a wide range of terms for very similar items. To avoid confusion, some clarification of terminology is required. A class is a general concept which usually consists of the common features, called attributes, of a group of concepts. This is also called a generic or a prototype. An example is person, which has attributes such as name and age. An instance of a class is a single concept which is a member of the group of concepts of the class. It has the attributes of the class concepts. It is also called an individual or an instantiation of the class. An example is the person Juerg Daellenbach, who is a person with a name and an age. A subclass is a class which contains all the attributes of another class, and some more of its own. It is also called a further specification. An example is student, which is a subclass of person, and has the additional attributes of course and stage. Classes, instances and subclasses build hierarchies, with classes at the top, and subclasses and instances below each class. Some formalisms do not distinguish between instances and subclasses; every instance is treated as a subclass and can be further specified. A relation is a mapping between several classes. Most relations are binary, which means there is a domain class and a range class. A more complex relation involves a cross-product domain. An example is the grade of a student with respect to a course. The student/course cross-product maps to the range which is the mark. An instance of a relation is an occurrence of a relation between two or more instantiations. It is called an assertion or a proposition. A Frame [Minsky 75] is a data structure for representing a stereotyped situation. It can be thought of as a hierarchy of nodes and relations. The "top levels" represent things that are always true about the situation, and are fixed. The lower levels have many storage locations called slots that are filled by specific instances or data, subject to certain restrictions. The term semantic network was derived from the early applications of associative networks, working with the meanings of words stored and used in the net. However the term is now used for any <b>associative</b> <b>net</b> regardless of the types of concepts stored in the KR language. A demon is an active process with a set of requirements. It constantly checks for the satisfaction of the requirements using the values in the knowledge base, and they are satisfied, its actions are performed. The demon is independent of any other processes running "at the same time". Once a demon is started it remains active until it terminates itself. The only control over a demon is by setting the values in the knowledge base to force or prevent satisfaction of the requirements...|$|E
40|$|This paper, {{written for}} {{interdisciplinary}} audience, presents computational image reconstruction implementable by quantum optics. The input-triggered {{selection of a}} high-resolution image among many stored ones, and its reconstruction if the input is occluded or noisy, has been successfully simulated. The original algorithm, based on the Hopfield <b>associative</b> neural <b>net,</b> was transformed in order to enable its quantum-wave implementation based on holography. The main limitations of the classical Hopfield net are much reduced with the simulated new quantum-optical implementation. (C) 2004 Optical Society of America...|$|R
40|$|The {{perceptron}} and the hologram are two dissimilar devices {{which have}} been advanced as neurological models. It :is shown {{that there are other}} and perhaps more plausible models which have properties common to both of these devices. The performance of these intermediate models which are termed <b>Associative</b> <b>Nets</b> is described and analysed statistically. The main similarities and differences between perceptron theory and holography can also be demonstrated; it is possible to demonstrate formal links between the translation invariance in certain types of holography and group invariance in perception. theory. Some single proofs of certain theorems in the latter are also given and some other learning procedures are formulated. It is shown that the important difference between these various models resides in the method used to accomplish a modification. If this modification is an analogue of a neurological change a a synaptic level, then {{it should be possible to}} qualify the relevance of those models by determining what types of synaptic change can take place in different parts of the nervous system. -Although the evidence is far from complete, it suggests that the neocortex is limited to having one type of synaptic change. Finally, each model is discussed in respect of its neurological plausibility. ...|$|R
40|$|ABSTRACT The {{historical}} {{origin of}} the Artificial Intelligence (AI) is usually established in the Dartmouth Conference, of 1956. But we can find many more arcane origins [1]. Also, we can consider, in more recent times, very great thinkers, as Janos Neumann (then, John von Neumann, arrived in USA), Norbert Wiener, Alan Mathison Turing, or Lofti Zadeh, for instance [12, 14]. Frequently AI requires Logic. But its Classical version shows too many insufficiencies. So, {{it was necessary to}} introduce more sophisticated tools, as Fuzzy Logic, Modal Logic, Non-Monotonic Logic and so on [1, 2]. Among the things that AI needs to represent are categories, objects, properties, relations between objects, situations, states, time, events, causes and effects, knowledge about knowledge, and so on. The problems in AI can be classified in two general types [3, 5], search problems and representation problems. On this last "peak", there exist different ways to reach their summit. So, we have [4] Logics, Rules, Frames, <b>Associative</b> <b>Nets,</b> Scripts, and so on, many times connected among them. We attempt, in this paper, a panoramic vision of the scope of application of such representation methods in AI. The two more disputable questions of both modern philosophy of mind and AI will be perhaps the Turing Test and the Chinese Room Argument. To elucidate these very difficult questions, see our final note...|$|R
