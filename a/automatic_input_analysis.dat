1|1747|Public
40|$|Abstract. The paper {{describes}} {{the process of}} designing a natural language dialogue interface for querying large databases with time data about electrical power network failures. The first stage of implementation of such dialogue interface consists of creation and preparation of several auxiliary resources that are required for natural language processing of texts over this specific domain. All modern methods of <b>automatic</b> <b>input</b> <b>analysis</b> of texts covering a domain with special terminology {{are based on a}} collection of large amount of texts from the field, so called textual corpus. We describe the process and statistical results of creation of a corpus of electrical power networks texts consisting of more than 100. 000 of positions (words and marks). We also offer some preliminary results of syntactical analysis of these texts. In the last part of this paper, we present the design of a dialogue system based on the analysis techniques using the corpus data that will allow natural language queries (in Czech) over the database of power networks failures. ...|$|E
40|$|This paper {{presents}} novel {{unit cell}} architecture for short wave infrared (SWIR) imaging applications. It has two input stages which are CTIA and SFD covering for both respectively {{low and high}} light levels and <b>automatic</b> <b>input</b> stage selection circuitry that chooses best input stage. A user can select 2 modes for FPA manual and automatic mode. In manual mode, user can set CTIA or SFD for all pixels according to user needs. In automatic mode, each pixel selects input stage itself according to light level. <b>Automatic</b> <b>input</b> stage selection for each pixel brings high SNR level and low noise along with highest possible dynamic range. Standard CMOS 0. 18 mu m TSMC technology is used to realize unit cell. In the architecture of unit cell, circuit level techniques are used to optimize layout size. ...|$|R
40|$|The {{distinct}} element {{method is}} adapted {{in this study}} as a numerical tool to provide a simulation of pack ice interaction with ships and icebreakers. Several special enhancements are implemented to a software package, {{which is used to}} deal with the environmental driving forces and <b>automatic</b> <b>input</b> data generation of pack ice field. Peer reviewed: NoNRC publication: Ye...|$|R
40|$|Data {{conventions}} for the <b>automatic</b> <b>input</b> of multiperiod stochastic linear {{programs are}} described. The input format {{is based on}} the MPSX standard and is designed to promote the efficient conversion of originally deterministic problems by introducing stochastic variants in separate files. A flexible "header" syntax generates a useful variety of stochastic dependencies. An extension using the NETGEN format is proposed for stochastic network programs...|$|R
40|$|In recent years, rapid {{progress}} has been made in computer processing of oriental languages, and the research developments in this area have resulted in tremendous changes in handwriting processing, printed oriental character recognition, document <b>analysis</b> and recognition, <b>automatic</b> <b>input</b> methodologies for oriental languages, etc. Advances in computer processing of oriental languages can also be seen in multimedia computing and the World Wide Web. Many of the results in those domains are presented in this book...|$|R
40|$|Pilot {{project of}} {{traceability}} and meat labelling system {{was used to}} build up database of Cattle Breeding Service of Slovenia. We have developed software for identification of beef carcasses on the slaughter line and the comparison between central data base and slaughterhouse database. The software enables <b>automatic</b> <b>input</b> of carcass weights, conformation scores and printing of labels. The system is involved in WEB and enables the consumers to check up the origin of meat they had bought...|$|R
40|$|The ATLAS {{data quality}} {{software}} infrastructure provides tools for prompt investigation of and feedback on collected data and propagation {{of these results}} to analysis users. Both manual and <b>automatic</b> <b>inputs</b> are used in this system. In 2009 and 2010 we have gained significant experience with collision data operations and analysis; we have used this experience to improve the data quality system, particularly in areas of scaling and user interface. This talk desecribes the commissioning experience and subsequent improvements...|$|R
5000|$|... "Applications of <b>Input</b> Output <b>Analysis</b> for Less Developed Countries", in Sohn, I. (ed.), Readings in <b>Input</b> Output <b>Analysis,</b> Oxford University Press, 1986 ...|$|R
40|$|With some {{intelligent}} algorithms, such as Genetic Algorithms (GA) and Kohonen Neural Network (NN), {{in addition}} to traditional digital image processing algorithms, a color map <b>automatic</b> <b>input</b> algorithm is proposed in this paper which {{is important for the}} data acquiring of CAD and GIS, etc. These have been realized in our Digital Map System (DMS) successfully. In this paper, a new color image segmentation algorithm based on color space transformation and vectorization algorithm based on GA are presented in detail...|$|R
40|$|In {{the paper}} {{the model of}} voice interface, which {{provides}} <b>automatic</b> <b>input</b> of Russian speech is proposed. The morphemes level of speech representation is introduced {{and as a result}} the size of vocabulary is significantly decreased. The developed morphemes databases are used for collecting the statistics of morphemes co-ordination by text corpuses. At that during recognition the degree of co-ordination between root morphemes has main significance. As a result of such processing the invariance to grammatical deviations is provided and also the speed of recognition of Russian speech and other languages with complex mechanism of word formation is improved. 1...|$|R
50|$|Some Armenian {{letters are}} entered as Latin digraphs, {{and may also}} be {{followed}} by the input of an ASCII single quote (which acts as the only letter modifier recognized) but this quote does not always mean that the intended Armenian letter should be aspirated (this may be the reverse for the input ch), it is also used as a vowel modifier. Due to ambiguities, texts must be corrected by entering an intermediate dummy character before entering the second Latin letter or quote, then removing the dummy character, so that the <b>automatic</b> <b>input</b> converter keeps the Armenian letters distinct.|$|R
40|$|Assertions {{can be used}} to {{automate}} the process of testing software. Two methods for automating the generation of input test data are described in this paper. One method selects the input values of variables at regular intervals in a 'grid'. The other, adaptive testing, uses assertion violations as a measure of errors detected and generates new test cases based on test results. The important features of assertion testing are that: it can be used throughout the entire testing cycle; it provides automatic notification of error conditions; and it can be used with <b>automatic</b> <b>input</b> generation techniques which eliminate the subjectivity in choosing test data...|$|R
5000|$|Introduced the AudioBox AB1616 {{including}} 16 {{digital audio}} playback channels {{on board with}} <b>automatic</b> <b>input</b> switching between live and playback on the first eight channels. On September 16 in Los Angeles, the Ride Vehicle version of the AudioBox (used in every ride vehicle on the Spider-Man ride at the Universal Studios Florida Islands of Adventure theme park) was awarded the Thea Award 2000 for Outstanding Achievement {{in the area of}} 'Breakthrough Technology' by the Themed Entertainment Association (TEA). The award states, [...] "Having been judged to represent the highest standards of excellence and creative achievement in the arts and sciences of the Themed Entertainment Industry." ...|$|R
5000|$|Another {{goal was}} to develop [...] "a large, {{distributed}} system architecture for managing the huge volume of raw data <b>input,</b> <b>analysis</b> results, and feedback, {{that will result in}} a simpler, more flexible data store that performs well and allows us to retain important data indefinitely." ...|$|R
50|$|<b>Automatic</b> form <b>input</b> systems use {{different}} types of recognition methods such as optical character recognition (OCR) for machine print, optical mark reading (OMR) for check/mark sense boxes, bar code recognition (BCR) for barcodes, and intelligent character recognition (ICR) for hand print.|$|R
40|$|Abstract. Techniques {{have been}} {{proposed}} to find the semantic differ-ences between two binary programs when the source code is not available. Analyzing control flow, and in particular, intra-procedural control flow, has become an attractive technique in the latest binary diffing tools since it is more resistant to syntactic, but non-semantic, differences. However, this makes such techniques vulnerable to simple function obfuscation techniques (e. g., function inlining) attackers any malware writers could use. In this paper, we first show function obfuscation as an attack to such binary diffing techniques, and then propose iBinHunt which uses deep taint and <b>automatic</b> <b>input</b> generation to find semantic differences in inter-procedural control flows. Evaluation on comparing various ver-sions of...|$|R
40|$|This paper {{describes}} {{the construction and}} <b>input</b> <b>analysis</b> of the Sign Language Analyses (SLAY) Database, both as it currently stands and {{as a guide to}} further expansion of the project. SLAY contains condensed cross-linguistic grammatical information from signed languages. It was designed so that the framewor...|$|R
50|$|The Unistat {{computer}} {{program is a}} statistical data analysis tool featuring two modes of operation: The stand-alone user interface is a complete workbench for data <b>input,</b> <b>analysis</b> and visualization while the Microsoft Excel add-in mode extends {{the features of the}} mainstream spreadsheet application with powerful analytical capabilities.|$|R
40|$|The {{study of}} pre{{conscious}} versus conscious processing has an extensive history in cognitive psychology, {{dating back to}} the writings of William James. Much of the experimental work on this issue has focused on perception, conceived of as <b>input</b> <b>analysis,</b> and on the relation of consciousness to attentional processing. The present paper examines when <b>input</b> <b>analysis</b> becomes conscious from the perspectives of cognitive modelling, methodology, and a more detailed understanding of what is meant by "conscious processing. " Current evidence suggests that perception becomes conscious at a late-arising stage of focal-attentive processing concerned with information integration and dissemination. Reliable criteria for determining when perception becomes conscious combine the evidence of "first-person," phenomenological reports with "third-person" functional dissociations between preconscious and conscious processing. There are three, distinct senses in which a process may be said to be "conscious. " It might be "conscious" (a) in the sense that one is conscious of the process, (b) {{in the sense that the}} operation of the process is accompanied by consciousness (of its results) and (c) in the sense that consciousness enters into or causally influences the process. Consciousness of familiar stimuli, rather than entering into <b>input</b> <b>analysis,</b> appears to follow it, in human information processing. Processes closely associated with the appearance of consciousness such as information integration and dissemination appear to operate unconsciously. Consequently, perception appears to be "conscious" only in sense (b) ...|$|R
40|$|A Mach-Zehnder {{interferometer}} is {{used for}} optical flow measurements in a transonic wind tunnel. Holographic interferograms are reconstructed by illumination with a He-Ne-laser and viewed by a video camera through wide angle optics. This setup was used for investigating industrial double exposure holograms of truck tires {{in order to develop}} methods of automatic recognition of certain manufacturing faults. <b>Automatic</b> <b>input</b> is achieved by a transient recorder digitizing the output of a TV camera and transferring the digitized data to a PDP 11 - 34. Interest centered around sequences of interferograms showing the interaction of vortices with a profile and subsequent emission of sound generated by this process. The objective is the extraction of quantitative data which relates to the emission of noise...|$|R
40|$|International audienceIn recent years, {{more and}} more {{attention}} has been given to the safety of agricultural products, whose demands for the traceability system are increasingly urgent. This paper, in response to the demands, by using the C# programming language, database technology, IOT technology and RFID technology, realized the traceability system of agricultural products, and explained the implementation of network technology and RFID technology in detail. The traceability system can complete the functions of data collection, early warning, control and data <b>automatic</b> <b>input</b> & management during the production process. This system can well solve the problem of data entry in the farming operation, timely and effectively record the information involved in the production of agricultural products, which can ensure the authenticity of the data in the traceability system...|$|R
40|$|The {{accommodations}} (3) hold releasable fixing components (4) each {{of which}} is provided with fixture devices for the small part. The accommodations are openings, in which the fixing components are inserted. In each accommodation, several fixing components or a group of them are inserted. The accommodation openings fully penetrate the magazine round carrier (1). The accommodations are arranged on the round carrier in a regular manner and especially in a form which allows a simple programming of a control unit for the input, handling and/or removal of the stored small parts. ADVANTAGE - Each small part has a defined location in the magazine so that apart from a manual input and removal an <b>automatic</b> <b>input</b> and removal in arbitrary sequence is possible...|$|R
40|$|The {{objective}} of this thesis is development study of airport Hradec Králové for IFR traffic {{on the basis of}} RNAV, with instrument approach, and it’s evaluation. Thesis contains author’s methodology for problem solving, description of the airport, determination of the lifting factors and study, including <b>inputs</b> <b>analysis,</b> description of the work and evaluation...|$|R
40|$|AbstractWe {{put forward}} an {{engineering}} realization method for security protocols. First, a formal description language for security protocols is designed. Then, a security protocol interpreter is designed, {{through which the}} corresponding objective code is generated with the description document as <b>input.</b> <b>Analysis</b> indicates that compared with the existing schemes our scheme has obvious advantages...|$|R
40|$|The paper {{describes}} the developed <b>automatic</b> data <b>input</b> algorithm (VBA - program), that allows significant simplification and fastening of calculation brushless DC motor magnetic field {{and analysis of}} its results in accordance with geometric size of the magnetic circuit separate elements and properties of the materials...|$|R
40|$|The aim of {{the paper}} is to {{indicate}} the significance of R&D in innovation process at company's level. It is achieved by studying the evolution of indicators measuring innovativeness. The authors propose set of indicators allowing to measure the influence of R&D on innovativeness of companies. The indicators include both outlays (<b>input</b> <b>analysis)</b> and their results (output analysis) ...|$|R
40|$|JavaScript {{is widely}} used in Web applications; however, its {{dynamism}} renders static analysis ineffective. Our JavaScript Blended Analysis Framework is designed to handle JavaScript dynamic features. It performs a flexible combined static/dynamic analysis. The blended analysis focuses static analysis on a dynamic calling structure collected at runtime in a lightweight manner, and refines the static analysis using dynamic information. The framework is instantiated for points-to analysis with stmt-level MOD <b>analysis</b> and tainted <b>input</b> <b>analysis.</b> Using JavaScript codes from actual webpages as benchmarks, we show that blended points-to analysis for JavaScript obtains good coverage (86. 6 % on average per website) of the pure static analysis solution and finds additional points-to pairs (7. 0 % on average per website) contributed by dynamically generated/loaded code. Blended tainted <b>input</b> <b>analysis</b> reports all 6 true positives reported by static analysis, but without false alarms, and finds three additional true positives...|$|R
40|$|Abstract: The {{conventional}} marking {{and identification}} of animals {{can be done in}} several different ways. With the application of modern informatics and electronics solutions, it is possible to substitute conventional ways with the different types of the electronic marking and identification. All types of electronic identification for transferring data are using the technology of the radio frequency (RFDI). With application of electronic marking, it is possible to achieve a great number of advantages of which the most important are the high precision of reading the data, individual supervision for every animal, <b>automatic</b> <b>input</b> of data, processing and keeping the information as a permanent actualization of data base. It is necessary to remove all existing defects and in future to work on the improvement of existing types of the electronic marking of animals...|$|R
40|$|The final {{publication}} {{is available}} at Springer via [URL] methodology to integrate geographical information system (GIS) data with large-scale pedestrian simulations has been developed. Advances in automatic data acquisition and archiving from GIS databases, <b>automatic</b> <b>input</b> for pedestrian simulations, as well as scalable pedestrian simulation tools {{have made it possible}} to simulate pedestrians at the individual level for complete cities in real time. An example that simulates the evacuation of the city of Barcelona demonstrates that this is now possible. This is the first step towards a fully integrated crowd prediction and management tool that takes into account not only data gathered in real time from cameras, cell phones or other sensors, but also merges these with advanced simulation tools to predict the future state of the crowd. Peer ReviewedPostprint (author's final draft...|$|R
40|$|Bachelor’s thesis {{describes}} procedures during {{creation of}} e-shop. Description starts with <b>input</b> <b>analysis,</b> continues with design of information architecture, design of graphic layout {{and ends with}} programming and inserting of websites on the internet. These procedures are applied and real model eshop is created. Bachelor’s thesis is focused on a usability of shop design and its utility in the real world...|$|R
40|$|Abstract—In {{this paper}} we develop a dynamic <b>analysis,</b> named {{relevant}} <b>input</b> <b>analysis,</b> {{that characterizes the}} role and strength of inputs in the computation of different values during a program execution. The role indicates whether a computed value is derived from an input value or its computation is simply influenced by an input value. The strength indicates if role (derived or influenced) relied upon the precise value of the input or it is among one of many values that can play a similar role. While {{it is clear that}} the results of our analysis can be very useful for the programmer in understanding relationships between inputs and program behavior, we also demonstrate the usefulness of the analysis by developing an efficient delta debugging algorithm. Other applications of relevant <b>input</b> <b>analysis</b> include—assisting in generating test inputs and detection of security holes. Index Terms—value dependence, address dependence, role of inputs, strength of inputs, delta debugging, testin...|$|R
40|$|In present days, most of {{the design}} {{activity}} is performed {{at a high level}} of abstraction, thus designers need to be sure that their designs are syntactically and semantically correct before starting the automatic synthesis process. The goal {{of this paper is to}} propose an <b>automatic</b> <b>input</b> pattern generation tool able to assist designers in the generation of a test bench for difficult parts of small- or medium- sized digital protocol interfaces. The proposed approach exploit a Genetic Algorithm connected to a commercial simulator for cultivating a set of input sequence able to execute given statements in the interface description. The proposed approach has been evaluated on the new ITC' 99 benchmark set, a collection of circuits offering a wide spectrum of complexity. Experimental results show that some portions of the circuits remained uncovered, and the subsequent manual analysis allowed identifying design redundancies...|$|R
40|$|Techniques {{have been}} {{proposed}} to find the semantic differences between two binary programs when the source code is not available. Analyzing control flow, and in particular, intra-procedural control flow, has become an attractive technique in the latest binary diffing tools since it is more resistant to syntactic, but non-semantic, differences. However, this makes such techniques vulnerable to simple function obfuscation techniques (e. g., function inlining) attackers any malware writers could use. In this paper, we first show function obfuscation as an attack to such binary diffing techniques, and then propose iBinHunt which uses deep taint and <b>automatic</b> <b>input</b> generation to find semantic differences in inter-procedural control flows. Evaluation on comparing various versions of a http server and gzip shows that iBinHunt not only is capable of comparing inter-procedural control flows of two programs, but offers substantially better accuracy and efficiency in binary diffing...|$|R
40|$|Reduction of chip {{packaging}} and cooling costs for deep sub-micron System-On-Chip (SOC) designs is an emerging issue. We present a simulationbased methodology able to realistically model the complex {{environment in which}} a SOC design operates {{in order to provide}} early and accurate power consumption estimation. We show that a rich functional test bench provided by a designer with a deep knowledge of a complex system is very often not appropriate for power analysis and can lead to power estimation errors of some orders of magnitude. To address this issue, we propose an <b>automatic</b> <b>input</b> sequence generation approach based on a heuristic algorithm able to upgrade a set of test vectors provided by the designer. The obtained sequence closely reflects the worst-case power consumption for the chip and allows looking at how the chip is going to work over time...|$|R
40|$|The {{objective}} {{of our work}} {{is the development of}} a natural language dialogue system for information retrieval with multimodal input and multimedia output. Overall, the system consists of three phases: <b>input</b> <b>analysis,</b> information and knowledge management and output generation. The dialogue system is designed for consulting old Mexican historical documents. In this paper we describe the designed architecture of each of the three phases...|$|R
40|$|We {{propose a}} theory of the {{development}} of speeded responding in choice tasks. Non-decision processing is performed by a cascade of linear accumulators, with accumulation beginning a fixed time after stimulus presentation (perceptual delay). The output of the non-decision stages feed into a decision stage consisting of an accumulator representing each choice. The first choice-accumulator to exceed its criterion, where criteria vary randomly and independently from trial-to-trial between accumulators, initiates a response after a fixed motor delay. The rates of all stages also vary randomly and independently from trial-to-trial. For almost any distributions of log-criteria and log-rates, response time (RT) has a Lognormal distribution with a lower bound determined by the sum of delays. Automaticity develops because the input to the correct accumulator increases exponentially with practice due to the formation of links to the choice stage with weights that interact multiplicatively. The mean log-rate of accumulation of each choice unit is determined by its input relative to inputs to other choice units, and so the rate for the correct response approaches an upper bound of with practice. The theory provided an accurate account of the effect of consistent-mapping practice on correct RT distribution in memory search (Kramer, Strayer & Buckley, 1990), mental rotation (Sutton & Heathcote, 2003), visual search (Heathcote & Mewhort, 2003) and categorization (Palmeri, 1997), including the effects of within- and between-category similarity in the latter data set. To account for the effect of algorithmic processing the correct choice unit was provided with an input from controlled-processing that does not change with practice. In cases where the controlled-processing input is initially larger than the <b>automatic</b> <b>input</b> a sigmoid (slow-fast-slow) decrease in RT is produced, whereas a smooth exponential decrease occurs when <b>automatic</b> <b>inputs</b> dominate. Strong control inputs accounted for sigmoid speedups prominent in Rickard’s (2004) data from an alphabet-arithmetic task, as well for some participants and conditions in Palmeri and Heathcote and Mewhort...|$|R
