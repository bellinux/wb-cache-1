1|9513|Public
40|$|Panicle {{caterpillars}} comprise {{an economically}} important insect pest complex of sorghum throughout the Great Plains of the United States, particularly in Kansas, Oklahoma, and Texas. The sorghum panicle caterpillar complex consists of larvae of two polyphagous lepidopteran species: the corn earworm, Helicoverpa zea (Boddie), and fall armyworm, Spodoptera frugiperda (J. E. Smith) (Lepidoptera: Noctuidae). Sampling for panicle caterpillars in sorghum fields is usually accomplished by the beat bucket sampling technique with a fixed {{sample size of}} 30 beat bucket samples of one sorghum panicle each per 16. 2 ha of field. We used Wald's sequential probability ratio test for a negative binomial distribution to develop a sequential sampling plan for panicle caterpillars. In total, 115 sorghum fields were sampled in Kansas, Oklahoma, and Texas from June to August 2010. Panicle caterpillars had an aggregated distribution of counts confirmed by Pearson's chi-square statistic for lack of fit to the negative binomial distribution for each sampled field. A sequential sampling plan was developed using a high threshold (an economic threshold) of 0. 5 caterpillars per sorghum panicle, a low threshold (a safe level) of 0. 20 caterpillars per panicle, and fixed error rates (α = 0. 10 and β = 0. 05). At caterpillar densities > 0. 45 and < 0. 12 per panicle, {{the average number of}} panicles inspected to make a decision was less than the current recommendation of 30. In a 2013 validation test of 25 fields, the expected number of samples taken from <b>average</b> <b>sample</b> <b>number</b> <b>curve</b> was in close agreement with the number of samples required using the sequential plan (r 2 = 0. 93), and all fields were correctly classified when compared with a fixed sample size result. The plan improved upon current sampling recommendations for panicle caterpillars in sorghum because at known acceptable fixed error rates fewer samples were required when caterpillars are scarce or abundant, whereas more samples were required to make decisions with the same acceptable error rates when densities were near the economic thresholds...|$|E
40|$|Approved {{for public}} release; {{distribution}} is unlimitedThe {{implementation of a}} Naval Supply Systems Command Quality Control Program is intended to promote improved performance at U. S. Naval stockpoints. this paper examines current quality control procedures, compares current practice to quality control theory, and recommends that sequential sampling techniques be adopted. Sequential sampling plans and their associated operating characteristics <b>curves</b> and <b>average</b> <b>sample</b> <b>number</b> <b>curves</b> are provided. Implementation of the recommended procedures {{could result in a}} more flexible and efficient Quality Control Program at Naval Supply System stockpoints. [URL] Commander, United States Nav...|$|R
40|$|Objective To {{test the}} {{applicability}} of lot quality assurance sampling (LQAS) for the rapid assessment of the prevalence of active trachoma. Methods Prevalence of active trachoma in six communities was found by examining all children aged 2 – 5 years. Trial surveys were conducted in these communities. A sampling plan appropriate for classifying communities with prevalences 20 % and 40 % {{was applied to the}} survey data. Operating characteristic and <b>average</b> <b>sample</b> <b>number</b> <b>curves</b> were plotted, and screening test indices were calculated. The ability of LQAS to provide a three-class classification system was investigated. Findings Ninety-six trial surveys were conducted. All communities with prevalences 20 % and 40 % were identified correctly. The method discriminated between communities with prevalences 30 % and> 30 %, with sensitivity of 98 % (95 % confidence interval (CI) = 88. 2 – 99. 9 %), specificity of 84. 4 % (CI = 69. 9 – 93. 0 %), positive predictive value of 87. 7 % (CI = 75. 7 – 94. 5 %), negative predictive value of 97. 4 % (CI = 84. 9 – 99. 9 %), and accuracy of 91. 7 % (CI = 83. 8 – 96. 1 %). Agreement between the three prevalence classes and survey classifications was 84. 4 % (CI = 75. 2 – 90. 7 %). The time needed to complete the surveys was consistent with the need to complete a survey in one day. Conclusion Lot quality assurance sampling provides a method of classifying communities according to the prevalence of active trachoma. It merits serious consideration as a replacement for the assessment of the prevalence of active trachoma with th...|$|R
40|$|This article {{proposes a}} {{variables}} two-plan sampling system called tightened-normal-tightened (TNT) sampling inspection scheme where the quality characteristic follows a normal distribution or a lognormal distribution {{and has an}} upper or a lower specification limit. The TNT variables sampling inspection scheme will be useful when testing is costly and destructive. The advantages of the variables TNT scheme over variables single and double sampling plans and attributes TNT scheme are discussed. Tables are also constructed for the selection of parameters of known and unknown standard deviation variables TNT schemes for a given acceptable quality level (AQL) and limiting quality level (LQL). The problem is formulated as a nonlinear programming where the objective function to be minimized is the <b>average</b> <b>sample</b> <b>number</b> and the constraints are related to lot acceptance probabilities at AQL and LQL under the operating characteristic <b>curve.</b> <b>average</b> <b>sample</b> <b>number,</b> OC <b>curve,</b> <b>sampling</b> system, two-plan system,...|$|R
40|$|OBJECTIVE: To {{test the}} {{applicability}} of lot quality assurance sampling (LQAS) for the rapid assessment of the prevalence of active trachoma. METHODS: Prevalence of active trachoma in six communities was found by examining all children aged 2 - 5 years. Trial surveys were conducted in these communities. A sampling plan appropriate for classifying communities with prevalences 40 % {{was applied to the}} survey data. Operating characteristic and <b>average</b> <b>sample</b> <b>number</b> <b>curves</b> were plotted, and screening test indices were calculated. The ability of LQAS to provide a three-class classification system was investigated. FINDINGS: Ninety-six trial surveys were conducted. All communities with prevalences 40 % were identified correctly. The method discriminated between communities with prevalences 30 %, with sensitivity of 98 % (95 % confidence interval (CI) = 88. 2 - 99. 9 %), specificity of 84. 4 % (CI = 69. 9 - 93. 0 %), positive predictive value of 87. 7 % (CI = 75. 7 - 94. 5 %), negative predictive value of 97. 4 % (CI = 84. 9 - 99. 9 %), and accuracy of 91. 7 % (CI = 83. 8 - 96. 1 %). Agreement between the three prevalence classes and survey classifications was 84. 4 % (CI = 75. 2 - 90. 7 %). The time needed to complete the surveys was consistent with the need to complete a survey in one day. CONCLUSION: Lot quality assurance sampling provides a method of classifying communities according to the prevalence of active trachoma. It merits serious consideration as a replacement for the assessment of the prevalence of active trachoma with the currently used trachoma rapid assessment method. It may be extended to provide a multi-class classification method...|$|R
40|$|Abstract: All {{classical}} {{acceptance sampling}} plans were constructed with {{the proportion of}} defective that is crisp value. In the manufacturing processes, this parameter in a production lot may not be precis ely known. Hence it is meaningful to treat such parameter as fuzzy quantities. In this paper we have argued for the acceptance double sampling plan when the proportion of defective items is a fuzzy number and it is being modeled based on the fuzzy Poisson distribution. The calculation of the Operating Characteristic (OC) <b>curves,</b> <b>Average</b> <b>Sample</b> <b>Number</b> (ASN) <b>curves,</b> <b>Average</b> Outgoing Quality (AOQ) curves and Average Total Inspection (ATI) curves of the plan will be presented for double plan by using the concept of fuzzy probability. The results show that these four curves are like band having high and low bounds with their width depending on the ambiguity proportion parameter in the lot, when the size and acceptance <b>numbers</b> of the <b>samples</b> are fixed. We have als o shown that in this plan, if the process quality is perfect or poor, then the ASN and AOQ bands will be of lower value. Key words: Statistical quality control • acceptance double <b>sampling</b> • fuzzy <b>numbers</b> • <b>average</b> <b>sample</b> <b>number</b> • <b>average</b> outgoing quality • average total inspectio...|$|R
40|$|In this paper, we {{investigate}} a sequential test for binary hypothesis testing for stationary, first-order Markov dependent observations in steady state. Wald's {{first and second}} lemmas are generalized. For a Markov chain with symmetric transition probability matrix the <b>average</b> <b>sample</b> <b>number</b> required by the test to decide a hypothesis is derived. Numerical analysis shows that accounting for a positive correlation in the observations results in {{a significant decrease in}} the <b>average</b> <b>sample</b> <b>number</b> for fixed error probabilities...|$|R
40|$|In this paper, {{we present}} the {{designing}} of the skip-lot sampling plan including the re-inspection called SkSP-R. The plan {{parameters of the}} pro-posed plan are determined through a nonlinear optimization problem by minimizing the <b>average</b> <b>sample</b> <b>number</b> satisfying both the producer’s risk and the consumer’s risks. The proposed plan is shown to perform better than the existing sampling plans {{in terms of the}} <b>average</b> <b>sample</b> <b>number.</b> The application of the proposed plan is explained with the help of illustra-tive examples...|$|R
40|$|A double {{sampling}} plan based on truncated life tests is proposed and designed under a general life distribution. The design parameters such as sample sizes and acceptance {{numbers for the}} first and the second samples are determined so as to minimize the <b>average</b> <b>sample</b> <b>number</b> subject to satisfying the consumer's and producer's risks at the respectively specified quality levels. The resultant tables can be used regardless of the underlying distribution as long as the reliability requirements are specified at two risks. In addition, Gamma and Weibull distributions are particularly considered to report the design parameters according to the quality levels in terms of the mean ratios. acceptance probability, <b>average</b> <b>sample</b> <b>number,</b> consumer's risk, life distribution, life test, producer's risk,...|$|R
40|$|In this paper, we have {{established}} a new framework of multistage hypothesis tests. Within the new framework, we have developed specific multistage tests which guarantee prescribed level of power and are more efficient than previous tests in terms of <b>average</b> <b>sampling</b> <b>number</b> and the <b>number</b> of <b>sampling</b> operations. Without truncation, the maximum <b>sampling</b> <b>number...</b>|$|R
40|$|In this paper, we have {{developed}} new multistage tests which guarantee prescribed level of power and are more efficient than previous tests in terms of <b>average</b> <b>sampling</b> <b>number</b> and the <b>number</b> of <b>sampling</b> operations. Without truncation, the maximum <b>sampling</b> <b>numbers</b> of our testing plans are absolutely bounded. Based on geometrical arguments, we have derived extremely tight bounds for the operating characteristic function. ...|$|R
40|$|Sequential {{probability}} ratio test {{is developed}} for testing the hypothesis regarding the parameter of Pareto distribution. The expression for the operating characteristics (OC) and <b>average</b> <b>sample</b> <b>number</b> (ASN) functions are derived. For {{the purpose of}} the plotting the OC and ASN functions different approaches are used. These different approaches give quite satisfactorily results...|$|R
40|$|Methodology is {{proposed}} {{for the design of}} sequential methods when data are obtained by gauging articles into groups. Exact expressions are obtained for the operating characteristics and <b>average</b> <b>sampling</b> <b>number</b> of Wald Sequential Probability Ratio Tests (SPRTs), and for the average run length of Cumulative Sum (CUSUM) schemes based on grouped data. Step by ste...|$|R
40|$|Reliable {{and swift}} {{spectrum}} sensing {{is a crucial}} technical challenge of cognitive radio. This study proposes a Sequential Energy Detection (SED) scheme to reduce the <b>average</b> required <b>sample</b> <b>number</b> and sensing time for spectrum sensing in low signal-to-noise ratio regime. In the scheme, the data samples are first grouped into data blocks and the Sequential Probability Ratio Test (SPRT) use the energies of the data blocks as the statistic variables. The resulting detection rule exhibits simplicity in implementation and in analysis and retains the high sample-efficiency of sequential probability ratio test. The detection performance in terms of <b>Average</b> <b>Sample</b> <b>Number</b> (ASN) is evaluated theoretically. Simulation results are provided to verify the theoretical analysis...|$|R
40|$|In this paper, we have {{established}} a new framework of multistage parametric estimation. Specially, we have developed sampling schemes for estimating parameters of common important distributions. Without any information of the unknown parameters, our sampling schemes rigorously guarantee prescribed levels of precision and confidence, while achieving unprecedented efficiency {{in the sense that}} the <b>average</b> <b>sample</b> <b>numbers</b> are virtually the sam...|$|R
40|$|Let [lambda] > 0 be {{the unknown}} {{parameter}} {{of the common}} exponential distribution of the i. i. d. sequence X 1, X 2 [...] . Exact formulae of a simple from for the error probabilities and {{the average number of}} the SPRT of against H 1 : [lambda] [greater-or-equal, slanted] [lambda] 0 ([lambda] 0 exponential distribution sequential probability ratio test error probabilities <b>average</b> <b>sample</b> <b>number...</b>|$|R
40|$|NOMBAS is {{an acronym}} for NOrmal Myopic Bayes Sequential, and {{is the name of}} a Bayesian {{procedure}} for selecting the category with the greatest mean. This paper describes NOMBAS in detail and then compares it with other procedures on the basis of Bayes risk versus <b>average</b> <b>sample</b> <b>number.</b> This research was supported by the Office of Naval Research through the NPS Foundation Research Program. [URL]...|$|R
40|$|The mixed variables-attributes test {{plans for}} single {{acceptance}} sampling are proposed to protect “good lots” from attributes aspect and to optimize sample sizes from variables aspect. For the single and double mixed plans, exact formulas {{of the operating}} characteristic and <b>average</b> <b>sample</b> <b>number</b> are developed for the exponential distribution. Numerical illustrations show that the mixed sampling plans have some advantages over the variables plans or attributes plans alone...|$|R
40|$|As {{a helpful}} guide for applications, the {{alternative}} hypotheses of the three-hypothesis test problems are designed under the required error probabilities and <b>average</b> <b>sample</b> <b>number</b> in this paper. The asymptotic formulas {{and the proposed}} numerical quadrature formulas are adopted, respectively, to obtain the hypothesis designs and the corresponding sequential test schemes under the Koopman-Darmois distributions. The example of the normal mean test shows that our methods are quite efficient and satisfactory for practical uses...|$|R
40|$|Sequential testing {{procedures}} are {{developed for the}} parameters of generalized life distributions. Robustness of the {{testing procedures}} is studied, when the distribution under consideration has undergone a change. In order to apply Newton-Raphson method {{for the purpose of}} plotting the operating characteristic (OC) and <b>average</b> <b>sample</b> <b>number</b> (ASN) functions, a method of choosing the initial values is provided. Key words: Generalized life distributions; OC and ASN functions; robustness; sequential probability ratio tests. ...|$|R
40|$|The {{present study}} proposes an {{attributes}} sampling plan under the gamma-Poisson {{distribution for the}} resubmitted lots. The design parameters of the proposed plan such as the <b>sample</b> <b>number</b> and the acceptance number are determined by using two points on operating characteristics curve such that both the producer’s and the consumer’s risks are satisfied for some specified values of acceptable quality level and rejectable quality level. The parameters are selected using the minimum <b>average</b> <b>sample</b> <b>number</b> criteria. Extensive tables are provided for some selected combinations of two quality levels {{and the results are}} explained with examples...|$|R
40|$|A {{test was}} {{described}} for two systems, long term and short term with an exponentially distributed time between failures. The test {{is intended for}} checking the ratio MTBFl /MTBFs exceeds or equals a prescribed value, versus one that it {{is less than the}} prescribed value, by means of long term tests with large <b>average</b> <b>sample</b> <b>number</b> in the earlier system. Our proposed system focus on improving test by using low <b>average</b> <b>sample</b> <b>number</b> in short term which is having the advantage of economy in time requirement and cost. It produces optimum truncated test called binomial Sequential Probability Ratio Test. Criteria are proposed for determining the characteristics of truncated test followed with the discretizing effect of truncation on error probabilities with a view to optimization of its parameters. The search algorithm for truncation apex used in this system achieves closeness to the optimum which depends on successful choice of the initial approximation, search boundaries and on the search step. The enhanced reliability of modern technological systems, combined with the reduced time quotas allotted for creating new system is capable of yielding a highly efficacious test which increases reliability and feasibility of decisions...|$|R
40|$|Acceptance {{sampling}} plans {{are used to}} assess the quality of an ongoing production process, in addition to the lot acceptance. In this paper, we consider sampling inspection plans for monitoring the Markov-dependent production process. We construct sequential plans that satisfy the usual probability requirements at acceptable quality level and rejectable quality level and. in addition, possess the minimum <b>average</b> <b>sample</b> <b>number</b> under semicurtailed inspection. As these plans result in large sample sizes, especially when the serial correlation is high, we suggest new plans called "systematic {{sampling plans}}. " The minimum <b>average</b> <b>sample</b> <b>number</b> systematic plans that satisfy the probability requirements are constructed. Our algorithm uses some simple recurrence relations to compute the required acceptance probabilities. The optimal systematic plans require much smaller sample sizes and acceptance numbers, compared to the sequential plans. However, they need larger production runs to make a decision. Tables for choosing appropriate sequential and systematic plans are provided. The problem of selecting the best systematic sampling plan is also addressed. The operating characteristic curves of some of the sequential and the systematic plans are compared, and are observed to be almost identical. (C) 2001, Inc...|$|R
40|$|In this paper, we have {{established}} a general framework of multistage hypothesis tests which applies to arbitrarily many mutually exclusive and exhaustive composite hypotheses. Within the new framework, we have constructed specific multistage tests which rigorously control the risk of committing decision errors and are more efficient than previous tests in terms of <b>average</b> <b>sample</b> <b>number</b> and the <b>number</b> of <b>sampling</b> operations. Without truncation, the <b>sample</b> <b>numbers</b> of our testing plans are absolutely bounded. Comment: 77 pages, no figure; added more references; in Proceedings of SPIE Conferences, Orlando, Florida, April 5 - 10, 2010 and April 25 - 29, 201...|$|R
40|$|AbstractIn this paper, a time {{truncated}} {{life test}} {{based on two}} stage group acceptance sampling plan for the percentile lifetime following half-normal distribution is proposed. The optimal parameters for the proposed plan are determined such that both producer’s and consumer’s risks are satisfied simultaneously for the given experimentation time and sample size. The efficiency of the proposed sampling plan is {{discussed in terms of}} <b>average</b> <b>sample</b> <b>number</b> with the existing sampling plan. The proposed sampling plan is explained with the help of industrial examples...|$|R
40|$|Consider {{the problem}} of testing H 0 : p = p 0 vs. H 1 : p = p 1 where p 1 > p 0 and p is the {{parameter}} of a Bernoulli distribution. The triangular test is a sequential test that has the attractive properties of a reasonable <b>average</b> <b>sample</b> <b>number</b> (ASN) at (p 0 + p 1) / 2 and an upper bound {{on the number of}} required observations. We present an algorithm {{that can be used to}} design ASN-minimizing triangular tests...|$|R
40|$|In this paper, a time {{truncated}} {{life test}} {{based on two}} stage group acceptance sampling plan for the percentile lifetime following half-normal distribution is proposed. The optimal parameters for the proposed plan are determined such that both producer’s and consumer’s risks are satisfied simultaneously for the given experimentation time and sample size. The efficiency of the proposed sampling plan is {{discussed in terms of}} <b>average</b> <b>sample</b> <b>number</b> with the existing sampling plan. The proposed sampling plan is explained with the help of industrial examples...|$|R
40|$|A {{generalized}} modified {{method is}} proposed {{to control the}} sum of error probabilities in sequential probability ratio test to minimize the weighted average of the two <b>average</b> <b>sample</b> <b>numbers</b> under a simple null hypothesis and a simple alternative hypothesis with the restriction that the sum of error probabilities is a pre-assigned constant to find the optimal sample size and finally a comparison is done with the optimal sample size found from fixed sample size procedure. The results are applied to the cases when the random variate follows a normal law as well as Bernoullian law...|$|R
40|$|In this article, {{a general}} problem of {{sequential}} statistical inference for general discrete-time stochastic processes is considered. The {{problem is to}} minimize an <b>average</b> <b>sample</b> <b>number</b> given that Bayesian risk due to incorrect decision does not exceed some given bound. We characterize the form of optimal sequential stopping rules in this problem. In particular, we have a characterization of the form of optimal sequential decision procedures when the Bayesian risk includes both the loss due to incorrect decision {{and the cost of}} observations. Comment: Shortened version for print publication, 17 page...|$|R
40|$|A further {{generalization}} {{of the family}} of 'two-stage' chain sampling inspection plans is developed - viz, the use of different sample sizes in the two stages. Evaluation of the operating characteristics is accomplished by the Markov chain approach of the earlier work, modified to account for the different sample sizes. Markov chains for a number of plans are illustrated and several algebraic solutions are developed. Since these plans involve a variable amount of sampling, an evaluation of the <b>average</b> <b>sampling</b> <b>number</b> (ASN) is developed. A <b>number</b> of OC <b>curves</b> and ASN curves are presented. Some comparisons with plans having only one sample size are presented and indicate that improved discrimination is achieved by the two-sample-size plans...|$|R
40|$|A model {{residual}} based Sequential Probability Ratio Test (SPRT) {{framework for}} vibration based struc-tural damage diagnosis is introduced. This employs the residual sequences {{obtained from a}} single sta-tistical time series model of the healthy structure, and its performance is pre-determined via {{the use of the}} Operating Characteristic and <b>Average</b> <b>Sample</b> <b>Number</b> functions in combination with baseline experiments. The approach postulated in this framework is shown to achieve early damage detection and identification (classification) via its application to damage diagnosis on a GARTEUR scale aircraft skeleton structure. Comparisons with a non-parametric Power Spectral Density based method are also presented...|$|R
40|$|As {{alternatives}} to usual double sampling, lot-by-lot acceptance sampling procedures are proposed here. In these schemes, whenever a second sample is needed, the sample information from neighbouring lots is used. The procedures are applicable for attributes {{as well as}} for variables such as known and unknown sigma plans. They are also applicable when the acceptance criterion is the variance. These plans have operating characteristic curves identical to that of comparable double sampling plans under a set of mild conditions. The primary advantage of these plans is a reduction in cost due to a smaller <b>average</b> <b>sample</b> <b>number...</b>|$|R
40|$|This paper {{introduces}} {{the concept of}} repetitive group sampling (RGS) for variables inspection. The repetitive group sampling plan for variables inspection will be useful when testing is costly and destructive. The advantages of the variables RGS plan over variables single sampling plan, variables double sampling plan and attributes RGS plan are discussed. Tables are also constructed for the selection of parameters of known and unknown standard deviation variables repetitive group sampling plan indexed by acceptable quality level and limiting quality level. Acceptable quality level, <b>average</b> <b>sample</b> <b>number,</b> limiting quality level, repetitive group sampling, sampling by variables,...|$|R
40|$|The {{present study}} proposes a Bayesian double {{sampling}} {{plan for the}} inspection of attribute quality characteristics under the gamma-Poisson distribution. The design parameters of the proposed plan such as the sample sizes and the acceptance numbers are determined for specified two points on operating characteristics curve such as acceptable quality level and limiting quality level along with the corresponding producer’s and the consumer’s risks. The optimal parameters are determined using the minimum <b>average</b> <b>sample</b> <b>number</b> criteria. Extensive tables are provided for selection of parameters of the proposed plan for selected combinations of two quality levels {{and the results are}} explained with examples...|$|R
40|$|A random walk, {Sn}∞n = 0, having {{positive}} drift {{and starting}} at the origin, is stopped the first time Sn > t ≧ 0. The present paper studies the "excess," Sn - t, when the walk is stopped. The main result is an upper bound on {{the mean of the}} excess, uniform in t. Through Wald's equation, this gives an upper bound on the mean stopping time, as well as upper bounds on the <b>average</b> <b>sample</b> <b>numbers</b> of sequential probability ratio tests. The same elementary approach yields simple upper bounds on the moments and tail probabilities of residual and spent waiting times of renewal processes...|$|R
40|$|Methodology is {{presented}} {{for the design}} of single and double compressed limit Sequential Probability Ratio Tests (SPRT) and Cumulative Sum (CUSUM) control charts to detect one-sided mean shifts in a symmetric probability distribution. We also show how to evaluate the average run length properties with the Fast Initial Response (FIR) feature. The resulting CUSUM plans have a simple scoring procedure, and are extremely simple to derive and implement. The use of two compressed limit gauges is more efficient than a single compressed limit gauge. In the case of SPRTs, the use of two compressed limit gauges minimizes the <b>average</b> <b>sampling</b> <b>number</b> required for specified operating characteristics. In th...|$|R
