0|60|Public
40|$|A {{description}} is given {{of an experiment}} in which {{an attempt was made}} to show that <b>audio-visual</b> <b>feedback</b> is more effective in intonation learning than auditory feedback. The factors in the experiment were feedback mode and practice time. The results showed a significant effect of <b>audio-visual</b> <b>feedback</b> over auditory feedback, whereas practice time did Intonation has always been a difficult aspect of foreign language teaching. On the one hand, all handbooks on the teaching of pronunciation agree that correct pronunciation of a foreign language (L 2) cannot be achieved without complete control of the intonation...|$|R
40|$|We {{present the}} AV-ZoomSlider {{interface}} for video browsing. It complements existing approaches, such as storyboards and video skims by enabling users to interactively navigate {{along the time}} line of a video file. Our solution smoothly integrates position- and speed-based navigation concepts and provides synchronized <b>audio-visual</b> <b>feedback</b> during scrolling when applicable...|$|R
40|$|A {{tangible}} audio–visual interface {{based on}} the metaphor of balancing a ball on a tiltable track allows the measurement of human control movements under different conditions of sensory feedback. This specific scenario of human–system interaction forms an example for the definition of various measures of performance and quality of interaction. The dependence of these measures on specific configurations of the interface {{with regard to the}} employed <b>audio–visual</b> <b>feedback,</b> and their relationship is discussed. 1...|$|R
40|$|In {{this paper}} we {{describe}} {{a system which}} allows users to use their full-body for controlling in real-time the generation of an expressive <b>audio-visual</b> <b>feedback.</b> The system extracts expressive motion features from the user’s full-body movements and gestures. The values of these motion features are mapped both onto acoustic parameters for the real-time expressive rendering {{of a piece of}} music, and onto real-time generated visual feedback projected on a screen in front of the user. Keywords Expressive interaction; multimodal environments; interactive music systems 1...|$|R
40|$|We present MyoSpat, an {{interactive}} system that enables performers to control sound and light projections through hand-gestures. MyoSpat is designed and developed using the Myo armband as {{an input device}} and Pure Data (Pd) as an audio-visual engine. The system is built upon human- computer interaction (HCI) principles; specifically, tan- gible computing and embodied, sonic and music interac- tion design (MiXD). This paper covers {{a description of the}} system and its <b>audio-visual</b> <b>feedback</b> design. Finally, we evaluate the system and its potential use in exploring em- bodied, sonic and music interaction principles in different multimedia contexts...|$|R
40|$|This thesis {{report is}} {{submitted}} in partial {{fulfillment of the}} requirements for the degree of Bachelor of Science in Electrical and Electronic Engineering, 2015. UAV is defined as an aerial vehicle that does not carry a human operator, uses aerodynamic forces to provide vehicle lift, can fly autonomously or be piloted remotely, can be expandable or recoverable, and can carry a lethal or nonlethal payload. It is controlled either autonomously by on-board computers or by remote control of a pilot on the ground. Its usage is currently limited by difficulties such as satellite communication and cost. A Drone has been built that can be operated by radio frequency controller and send live <b>audio-visual</b> <b>feedback.</b> The developed Drone control system has been simulated in MATLAB/Simulink. The simulation shows a very stable operation {{and control of the}} developed Drone. Microcontroller based drone control system has also been developed where a RF transmitter and receiver operating in the frequency of 2. 4 GHz are used for remote operation for the Drone. Earlier, Drones were deployed for military applications such as spying on both domestic and international threats. The developed drone in this work can be used for a number of applications, such as policing, firefighting, monitoring flood effected areas, recording video footage from impassable areas and both military and non-military security work. In addition, using an Android mobile device incorporation with GPS has been used for live position tracking of Drone and real time <b>audio-visual</b> <b>feedback</b> from Drone...|$|R
40|$|This paper {{describes}} {{the work with}} F 0 and segment duration when developing a prototype system for analysis of speaker age using data-driven formant synthesis. The system was developed to extract 23 parameters from the test words—spoken by four differently aged female speakers of the same dialect and family — and to generate synthetic copies. <b>Audio-visual</b> <b>feedback</b> enabled the user to compare the natural and synthetic versions and facilitated parameter adjustment. Next, weighted linear interpolation was used in a ﬁrst crude attempt to synthesize speaker age. Evaluation of the system revealed its strengths and weaknesses, and suggested further improvements. F 0 and duration performed better than most other parameters...|$|R
40|$|This lecture-demonstration {{reflects}} on a research-informed teaching project in which teaching staff in {{dance and music}} technology collaborated on technical and pedagogic research and artistic creation in interactive dance. Our primary aim was to throw light on how interactive technologies might challenge and develop {{the ways in which}} students in dance and music technology engage in creative practice through the exploration of a set of technologies and conceptual approaches the research has revealed very particular compositional structures and methods. Experimental sketches were developed with a particular focus on emergent behavior and richly behaviored <b>audio-visual</b> <b>feedback</b> systems that were both controlled by and influenced the dancers. The demonstration presents our approaches and offers methodologies and strategies for the use of new technologies in dance pedagogy...|$|R
40|$|This paper {{describes}} an interactive application {{that aims to}} support the rehabilitation of handwriting skills in people that suffer from paralysis after a stroke. The purpose of the application {{is to make the}} rehabilitation of handwriting skills fun and engaging. Four platform-independent games with adjustable levels of difficulty were created in order to target varying levels of skills. The application also features a performance history, <b>audio-visual</b> <b>feedback,</b> and posture reminders. It was evaluated with medical staff and patients from the Hoensbroeck Rehabilitation Centre in the Netherlands. The initial results indicated that the games are more motivating and fun than traditional pen and paper exercises. The feedback received from therapists supports our claim that the games are a useful addition to the rehabilitation of handwriting...|$|R
40|$|Objective : Awareness {{of errors}} is an {{important}} prerequisite in rehabilitation. Few studies have investigated rehabilitation of error awareness following acquired brain injury. Pilot {{research has shown that}} receiving feedback about errors during a computerised task of sustained attention improves performance in patients who have sustained a traumatic brain injury. In this study, a computer-based intervention training programme aimed at improving error awareness was developed. Participants and Methods: 20 patients who sustained a Traumatic or Acquired Brain Injury and had low error awareness level were enrolled in the study. Matched random groups design was used to test the effects of <b>audio-visual</b> <b>feedback</b> on error awareness. One group (n= 10) received <b>audio-visual</b> <b>feedback</b> on errors and a second group (n= 10) did not receive feedback on error. The task involved responding or withholding a response to specific images on a computer screen. Training was undertaken in 8 sessions over 4 weeks. Results: Analysis of pre and post intervention measures indicated that error awareness improved for all participants, and that the improvement was greater for the feedback group. An unexpected finding was that during recruitment more than 80 candidates with serious and recently diagnosed ABI were excluded because they had high levels of error awareness. Conclusions : This intervention provides an engaging task suitable for use amongst a broad age span that can be delivered in the home, community or clinical setting. Its potential use for assessing as well as rehabilitating error awareness shall be explored further. Acknowledgements: The {{authors would like to thank}} the patients of the National Rehabilitation Hospital. This work was supported by grants from the Health Research Board, National Rehabilitation Hospital Trust, UCD Seed Fund, and National Disability Authorit...|$|R
40|$|This study {{considers}} {{the competence of}} lawyers. in carrying out the work of interviewing their clients {{and the value of}} training and experience in acquiring client interviewing skills. Literature on legal skills is first surveyed to assist in understanding the concept and help decide on methodology. Literature on client, interviewing' and the educational value of experiencee reviewed to provide background to subsequent studies. The first study provides an overall framework for solicitors' work and monitors, through observation and questionnaire, the work of a number of solicitors over a four day period. Client interviewing is found to take up a larger proportion of solicitors' professional work than other categories noted, and observation proves to be a more sound basis for studying detail than a questionnaire approach. The second study assesses the competence of 27 new trainee solicitors at interviewing clients through a detailed monitoring of their performance over thirteen tasks using eighteen different techniques and providing thirteen heads of information. Their performance exhibited many of the deficiencies recognised in the literature. The trainees were then randomly allocated to three treatment groups. One group received full training, one received training without <b>audio-visual</b> <b>feedback</b> of first interviews and the third (control) received no training at all. They all then undertook a second interview which was similarly assessed. Training was found significantly to enhance performance over the spectrum of measurement, an <b>audio-visual</b> <b>feedback)</b> especially enhanced behavioral aspects of performance. In the final study, solicitors and trainees ranging widely in experience were videotaped interviewing their clients and similarly assessed. Experience was not found to have- the expected effect of enhancing performance significantly except in some minor respects, but it did increase the feeling of confidence in interviewing ability. In conclusion, suggestions are made for stronger linking of training with experience in the production of new lawyers...|$|R
40|$|BACKGROUND Efficiently {{performed}} basic {{life support}} (BLS) after cardiac arrest {{is proven to}} be effective. However, cardiopulmonary resuscitation (CPR) is strenuous and rescuers' performance declines rapidly over time. <b>Audio-visual</b> <b>feedback</b> devices reporting CPR quality may prevent this decline. We aimed to investigate the effect of various CPR feedback devices on CPR quality. METHODS In this open, prospective, randomised, controlled trial we compared three CPR feedback devices (PocketCPR, CPRmeter, iPhone app PocketCPR) with standard BLS without feedback in a simulated scenario. 240 trained medical students performed single rescuer BLS on a manikin for 8 min. Effective compression (compressions with correct depth, pressure point and sufficient decompression) as well as compression rate, flow time fraction and ventilation parameters were compared between the four groups. RESULTS Study participants using the PocketCPR performed 17 ± 19...|$|R
40|$|When {{playing on}} {{multiline}} slot machine games, small “wins” often amount {{to less than}} the original spin wager, which results in a financial loss to the gambler. However, the gambler may feel {{as if he is}} winning because these “wins” are paired with <b>audio-visual</b> <b>feedback.</b> The influence of losses disguised as wins was examined to determine if this had an influence on latency, trial ratings, and the number of trials played. Thirty-one participants played a minimum of 50 trials on a simulated multi-line slot machine. The participants were divided into three groups with 16 %, 30 %, and 46 % of trials being losses disguised as wins. Results showed that trial type {{had a significant impact on}} latency and rating, as losses disguised as wins fell between wins and losses in terms of latencies and ratings. Clinical implications and future directions are discussed...|$|R
40|$|In {{this paper}} we {{describe}} a system allowing users {{to express themselves}} through their full-body movement and gesture and to control in real-time the generation of an <b>audio-visual</b> <b>feedback.</b> The systems analyses in real-time the user’s full-body movement and gesture, extracts expressive motion features and maps {{the values of the}} expressive motion features onto real-time control of acoustic parameters for rendering a music performance. At the same time, a visual feedback generated in real-time is projected on a screen in front of the users with their coloured silhouette, depending on the emotion their movement communicates. Human movement analysis and visual feedback generation were done with the EyesWeb software platform and the music performance rendering with pDM. Evaluation tests were done with human participants to test the usability of the interface and the effectiveness of the design...|$|R
30|$|The Ambient Wood (Rogers et al. 2004) and Hunter and Snark {{projects}} (Price et al. 2003; Harris et al. 2004) are well-cited interdisciplinary {{examples of}} learning applications in context-aware environments beyond the classroom. These projects developed novel interaction environments for enquiry-based situated learning experiences. In the Ambient Wood project, mobile devices {{were used to}} present information to children engaged in scientific enquiry and explore biological ideas and triggered by the immediate environment of a woodland area. As pairs of children interacted with the woodland area, they captured data about the wood and used these later on as a reflection tool to form and test hypotheses about the various woodland habitats. Games developed through the Hunter and Snark enabled interactions for children to create and discover more about characters in stories through <b>audio-visual</b> <b>feedback</b> received via Radio Frequency Identification (RFID) tags embedded inside coloured clay, mobile devices and ultra-sonic sensing.|$|R
40|$|Can {{implicit}} {{interaction with}} a computer easily drive useful interface improvements in physical world settings? This paper presents a case study presenting multiple such context-aware interaction improvements in a sink. We have identified opportunities where automated interfaces at the sink have positive consequences for safety, hygiene and ecology. The danger of scalding oneself with hot water is confronted by transforming the water into a graphical user interface and using image understanding to dispense the proper temperature of water. <b>Audio-visual</b> <b>feedback</b> at the sink can motivate users to conserve water. Used in combination with an RFID reader, the sink can serve as {{an effective means of}} verifying hand-washing compliance for clean environments. Finally, automatic actuation of the sink’s height based on the user and task can prevent burns and ergonomic injuries. This project demonstrates that the integration of digital interaction in a hostile environment can facilitate and improve our daily rituals...|$|R
40|$|The Robotics Development Group at the Savannah River Site is {{developing}} a high performance teleoperated vehicle for use in radioactive and hazardous environments. The three-wheeled vehicle incorporates a highly dexterous 6 degree-of-freedom (DOF), hydraulically-powered manipulator made by Schilling Development, Inc. The teleoperator is called Little MoRT (MObile Radio-controlled Teleoperator) and is {{a modified version of}} a commercially available, battery-powered, warehouse vehicle. Little MoRT is controlled remotely by a universal robot controller either through a radio frequency link or a tethered cable. Six video cameras and a microphone provide the operator with <b>audio-visual</b> <b>feedback</b> of the vehicle and its surrounding environment. The vehicle also incorporates a hydraulic power unit consisting of a propane-driven engine for powering the Schilling manipulator. Little MoRT is capable of operating in outdoor as well as indoor environments and is well suited for decontamination and decommissioning activities such as dismantling, sorting, and surveying of radioactive waste...|$|R
40|$|The {{continuous}} {{quest for}} ever increasing fidelity in 3 D virtual worlds is running {{parallel to the}} emergence and adoption of low-cost technologies to implement such environments. In education and training, complex simulations can now be implemented on standard desktop technologies. However, such tools lack the means to represent multisensory data beyond <b>audio-visual</b> <b>feedback.</b> This paper reports on a study that involved the design, {{development and implementation of}} a 3 D learning environment for underground mine evacuation. The requirements of the environment are discussed in terms of the sensory information that needs to be conveyed and techniques are described to achieve this using multiple modes of representation, appropriate levels of abstraction and synesthesia {{to make up for the}} lack of tactile and olfactory sensory cues. The study found that audio-visual cues that used such techniques were effective in communicating complex sensory information for novice miners...|$|R
40|$|We {{describe}} a novel system for tennis performance analysis that allows coaches to review games and provide detailed <b>audio-visual</b> <b>feedback</b> to tennis athletes. The basis for {{our system is}} a network of low-cost IP cameras surrounding the tennis court. Our system exploits the output of several visual analysis modules, including the tracking of players and the tennis ball, and the extraction of player silhouettes for 3 D reconstruction. A range of intuitive tools within the interface allow tennis coaches to add 2 D and 3 D annotations to live video, view play from multiple perspectives, record audio commentary and compute game statistics in real-time. The result is a video file {{that can be used}} to provide personalised feedback to the players or for use as a teaching resource for others. While we focus on tennis in this work, we believe our system can be generalised to other sports and allow a range of non-professional sports clubs to provide high-quality feedback to their athletes...|$|R
40|$|Abstract. This paper {{presents}} an immersive multimodal Gumdo simulation game {{that allows a}} user to experience the whole body interaction with an intelli-gent cyber fencer. The proposed system consists of three modules: (i) a nondis-tracting multimodal interface with 3 D vision and speech (ii) an intelligent cyber fencer and (iii) an immersive feedback by a big screen and sound. Firstly, the multimodal interface allows a user to move around and to shout without dis-tracting the user. Secondly, an intelligent cyber fencer provides the user with intelligent interactions by perception and reaction modules that are created by the analysis of real Gumdo game. Finally, an immersive <b>audio-visual</b> <b>feedback</b> helps a user experience an immersive interaction. The proposed interactive sys-tem with an intelligent fencer is designed to satisfy comfortable interface, per-ceptual intelligence, and natural interaction (I-cubed) and enhance the life-like impression of fighting actions. The suggested system {{can be applied to}} various applications such as education, art, and exercise. ...|$|R
40|$|In {{order to}} better {{understand}} how to design hands-on child-computer interaction, we explore how different styles of interaction facilitate children‟s thinking while they use their hands to manipulate objects. We present an exploratory study of children solving a spatial puzzle task. We investigate how the affordances of physical, graphical, and tangible interfaces may facilitate the development of thinking skills including mental visualization, problem space exploration, and collaboration. We utilize the theory of complementary actions taken from embodied cognition to develop a video coding methodology {{that allows us to}} classify behavioural activity and make inferences about thinking skills development. Our findings indicated that the combination of direct hands-on input style with <b>audio-visual</b> <b>feedback</b> facilitated by the tangible user interface enabled a dynamic task completion strategy, which supports the development of mental skills with a slight time cost. The mouse and graphical user interface supported a trial and error approach, which may limit skills development. The physical cardboard puzzle enabled effective task completion but provided less support for social interaction and problem space exploration. We conclude with design recommendations...|$|R
40|$|BACKGROUND Resuscitation {{guidelines}} {{encourage the}} use of cardiopulmonary resuscitation (CPR) feedback devices implying better outcomes after sudden cardiac arrest. Whether effective continuous feedback could also be given verbally by a second rescuer ("human feedback") has not been investigated yet. We, therefore, compared the effect of human feedback to a CPR feedback device. METHODS In an open, prospective, randomised, controlled trial, we compared CPR performance of three groups of medical students in a two-rescuer scenario. Group "sCPR" was taught standard BLS without continuous feedback, serving as control. Group "mfCPR" was taught BLS with mechanical <b>audio-visual</b> <b>feedback</b> (HeartStart MRx with Q-CPR-Technology™). Group "hfCPR" was taught standard BLS with human feedback. Afterwards, 326 medical students performed two-rescuer BLS on a manikin for 8  min. CPR quality parameters, such as "effective compression ratio" (ECR: compressions with correct hand position, depth and complete decompression multiplied by flow-time fraction), and other compression, ventilation and time-related parameters were assessed for all groups. RESULTS ECR was comparable between the hfCPR and the mfCPR group (0. 33 vs. 0. 35, p[*]=[*] 0. 435). The hfCPR group needed less time until starting chest compressions (2 vs. 8  s, p[*]<[*] 0. 001) and showed fewer incorrect decompressions (26 vs. 33...|$|R
40|$|BACKGROUND: Clinical {{decision-making}} is {{a complex}} activity that is critical to patient safety. Simulation, augmented by feedback, affords learners {{the opportunity to learn}} critical clinical decision-making skills. More detailed feedback following simulation exercises has the potential to further enhance student learning, particularly in relation to developing improved clinical decision-making skills. OBJECTIVE: To investigate the feasibility of head-mounted video camera recordings, to augment feedback, following acute patient deterioration simulations. DESIGN: Pilot study using an observational design. METHODS: Ten final-year nursing students participated in three simulation exercises, each focussed on detection and management of patient deterioration. Two observers collected behavioural data using an adapted version of Gaba 2 ̆ 7 s Clinical Simulation Tool, to provide verbal feedback to each participant, following each simulation exercise. Participants wore a head-mounted video camera during the second simulation exercise only. Video recordings were replayed to participants to augment feedback, following the second simulation exercise. Data were collected on: participant performance (observed and perceived); participant perceptions of feedback methods; and head-mounted video camera recording feasibility and capability for detailed <b>audio-visual</b> <b>feedback.</b> RESULTS: Management of patient deterioration improved for six participants (60...|$|R
40|$|Having {{evolved over}} {{approximately}} 20 years, Multimedia {{can now be}} considered a mature field. The term media traditionally refers to entities such as audio, video, text, images, graphics, sound, and animation. Today, while the range of these media and their applications are vast, all of them correspond {{in one way or}} another to only two main human perceptions: hearing and vision. As such, even though we are seeing more and more advanced multimedia applications and tools in both research and in practice, they are limited to the human senses of hearing and vision. To truly exploit Multimedia, other human senses must be added. These include the sense of touch, taste, and smell. While some limited research has been performed about taste and smell, the more significant sense of touch has started to emerge in both research and practical arenas at a fast pace. This is referred to as haptics: the new media that deals with the human sense of touch. Haptics enable users to manipulate objects in a natural and effective way, enhance the sensation of “presence”, and provide information about the objects such as stiffness, texture, elasticity, temperature, and weight, which cannot be described completely with only <b>audio-visual</b> <b>feedback.</b> The technology has already been explored in contexts a...|$|R
40|$|Vection-Builder used agent-environment {{interaction}} as an auto-generative composition {{system for}} audio visually demonstrating felt_space as a dynamic spectrum alive with three-dimensional effects polarised within {{a field of}} forces. Participation and improvisational reciprocal action was facilitated through an experimental capture and relay system that was natively adjustable and tuned to the site controlling the parameters of audio-visual mirroring/cueing paradigms in terms of calibrating the sensitivity and dynamic range of feedback genesis, evolution and rest. The form schema for Vection-builder consisted of three elements (i) participant interaction or affect agents, (ii) the xenomorphic space as causal field, and (iii) a co-operative system of <b>audio-visual</b> <b>feedback</b> loops for which a computer, prepared Microsoft Kinect sensor, eye tracking device and bio feedback system served as automatic attention capture device with real time sequencing and sampling, allowing direct forms of communication between the situated engagement and reverberating series of endogenous mirroring. The project involved live participation and technical support from PerceptionLab: Detmolder Schule für Architektur und Innenarchitektur, Germany, whose specialist knowledge in eye-tracking and biofeedback systems, enabled me to create the performative event as a medium to simultaneously receive, transmit and observe agent-environment interaction. Artist Residency 2010 - 2012 : The Roman Baths, Bath. The Roman Baths, Bat...|$|R
40|$|This action {{research}} explored {{the potential of}} audio-visual screencasting for assignment feedback on a distance learning (DL) course. A screencast {{is a combination of}} voice recording and screen capture, which can be played in any browser, like a video. Here it is used to capture a tutor’s editing and highlighting activities in a document, whilst simultaneously recording spoken feedback. Research suggests that <b>audio-visual</b> <b>feedback</b> may resolve some of the current problems with written feedback. A pilot study is reported which trialled screencasting for essay feedback on a master's level DL module at Sheffield Hallam University. Fourteen students participated and were randomly divided between two groups to receive either written or screencast feedback first. After receiving the first feedback type, students completed a short questionnaire online. The second type of feedback was then distributed to the students, who completed the same questionnaire for the second type of feedback. The results suggest that feedback is received more positively in the richer media of audio-visual screencasting and that this may encourage emotions more conducive to receiving and processing feedback and help to socialise students within the learning context by giving them a sense of belonging to the community. Simultaneous visual cues and explanations appear to help wit...|$|R
40|$|Abstract — Mobile robot {{teleoperation}} {{has been}} used in many areas of industrial automation, such as explosives disposal, nuclear waste manipulation, freight handling or transportation. Here, the commonly provided <b>audio-visual</b> <b>feedback</b> often resulted in an inadequate perception of the remote environment. Haptic augmentation was shown to improve and positively enhance the control of the mobile robot. This paper presents a novel Self-Organizing Fuzzy Adaptive Mapping algorithm (SOFAMap) for a haptic teleoperation of mobile robots. The SOFAMap algorithm was specifically developed for a mobile robot with a rotational sonar sensory system, constituting an alternative to a traditionally used multi-sonar array. The main contributions of this work are: 1) development of a specific selforganizing environment mapping structure inspired by the Growing Neural Gas algorithm; 2) incorporating a fuzzy controller into the algorithm to adapt to robot’s motion; 3) resolving typical issues such as sensor noise, communication time delay and low sampling rate. The experimental testing was performed in both virtual environment and on a real robotic platform, consisting of a Lego NXT mobile robot and a Novint Falcon 3 -DOF haptic interface. The results showed that a highfidelity haptic feedback can be successfully generated using a simpler and more affordable rotational sonar sensory system, as opposed to the typical multi-sonar array. Further, it was demonstrated that the SOFAMap algorithm improves the operator’s awareness of unstructured environments, making it applicable to wide range of mobile robot teleoperation systems...|$|R
40|$|Studies {{suggest that}} prosody plays a {{critical}} role in the production and perception of L 2 speech, but {{more research is needed to}} investigate L 2 prosodic patterns and their effects on perceived foreign accent, intelligibility and speech interactions. A pilot study was conducted to investigate the effects of Italian L 1 prosody in English. 2 native English speakers and 8 Italian speakers of English produced a variety of English sentences. The prosodic patterns of the recorded sentences were analyzed using the speech analysis software Praat. The analysis showed that, while native English speakers’ intonation is characterized by prominence peaks and contours with variations in modulations depending on sentence types, Italian speakers’ intonation in English is characterized by rather flat and unvaried contours. The observed differences suggest that the two groups produce and respond to very different prosodic information, which may affect Italians’ intelligibility and successful communication in English. This calls for further investigation with perception tests. The study also addressed the question of whether an increased awareness of English prosody could improve prosodic productions in L 2. Praat was used to provide Italian students with <b>audio-visual</b> <b>feedback</b> on their productions in English, to raise their awareness of the differences between L 1 and L 2 prosody, and to help them produce prosodic patterns resembling the native speakers’. This method proved to be effective, and shows that improvement is possible in an area like prosody which has traditionally been considered hard to teach...|$|R
50|$|Fully {{integrated}} {{development environment}} with What You See Is What You Get integrated editing and runtime preview. The WYSIWYG editing environment provides designers and developers with instant visual <b>feedback</b> for <b>animation,</b> interaction, real time shadows, pixel shaders and post process effects during {{the creation of the}} interactive 3D visual computing applications. The fully {{integrated development environment}} enables all aspects of an interactive 3D project to be created, modified and published inside a single application.|$|R
40|$|Intonation is {{fundamental}} to human speech in conveying meaning. Teachers and researchers have raised the concern that the intonation of a second language is difficult both to teach and to learn in the language classroom. However, due to particular characteristics of technology-based instruction, there is an increasing tendency to teach and learn second language intonation {{through the use of}} technology and software. For the above reasons, an open-access tool which incorporates computer-based <b>audio-visual</b> <b>feedback</b> was designed and piloted to help Chinese learners of English improve their perception and production of rising and falling tag questions. Six international students (native speakers of Mandarin) participated in the study. The participants were pre- and post tested on their perception (in context and in isolation) and production (in context) of question tags. The participants also underwent training lasting approximately two weeks. Each week, {{the participants were asked to}} complete two blocks of the training materials, for about 15 - 20 minutes each time. Individual semi-structured interviews took place after the training with all participants. Based on observations, pre- and post-test scores, and the interviews conducted, the results revealed that the participants have become more aware of their perception of tag questions. Also, the participants showed some improvement in their production of tag questions. Participants also stated that the two applications used: WASP, a software that allows the recording, display and analysis of speech and Online Audio Recording, a plug-in for the e-learning platform Moodle were beneficial, interesting to use and helpful for their learning...|$|R
40|$|This {{developmental}} research study explores {{the effects of}} <b>audio-visual</b> <b>feedback</b> and user input mechanisms on user behaviors and satisfaction, through development of a first-grade reading program for the computer. Specific design elements investigated include human vs. synthesized audio feedback, segmented vs. whole-word pronunciation, format of supporting graphic (image vs. animation), use of automatic speech recognition (ASR) to encourage or enforce oral reading of an e-book, and effect of tutorial with mouse-click word identification or ASR-controlled word synthesis games. The study examines a variety of quantitative and qualitative measures including use logs, recorded screen-capture videos of use sessions, one-on-one interviews, and satisfaction surveys. The results of testing for each design element are analyzed and most appropriate design choice is implemented for subsequent design phases in an iterative manner. Design guidelines are given confirm the existing literature 2 ̆ 7 s findings of user preference for human speech over computer-synthesized speech (TTS) and that supporting graphics can increase user satisfaction of e-books, but also {{have the potential for}} distraction and reduction of active reading tasks. ASR was found to be ineffective as an input mechanism due to user error and low success rate in this study, but was found to be better-suited as a tool for smaller discrete tasks such as word synthesis practice and games, and may be effective for practice or support when offered as an optional tool to be used voluntarily by users. (Keywords: literacy, reading, e-books, CAI, educational technology, elementary education, animation, synthesized speech, TTS, ASR, {{developmental research}}...|$|R
40|$|The limited {{ability to}} control for a tumour's {{location}} compromises the accuracy with which radiation can be delivered to tumour-bearing tissue. The resultant requirement for larger treatment volumes to accommodate target uncertainty restricts the radiation dose because more surrounding normal tissue is exposed. With image-guided radiation therapy (IGRT), these volumes can be optimized and tumouricidal doses may be delivered, achieving maximum tumour control with minimal complications. Moreover, with the ability of high precision dose delivery and real-time knowledge of the target volume location, IGRT has initiated the exploration of new indications in radiotherapy such as hypofractionated radiotherapy (or stereotactic body radiotherapy), deliberate inhomogeneous dose distributions coping with tumour heterogeneity (dose painting by numbers and biologically conformal radiation therapy), and adaptive radiotherapy. In short: "individualized radiotherapy". Tumour motion management, especially for thoracic tumours, is a particular problem in this context both for the delineation of tumours and organs at risk as well as during the actual treatment delivery. The latter will be covered in this paper with some examples based {{on the experience of}} the UZ Brussel. With the introduction of the NOVALIS system (BrainLAB, Feldkirchen, Germany) in 2000 and consecutive prototypes of the ExacTrac IGRT system, gradually a hypofractionation treatment protocol was introduced for the treatment of lung tumours and liver metastases evolving from motion-encompassing techniques towards respiratory-gated radiation therapy with <b>audio-visual</b> <b>feedback</b> and most recently dynamic tracking using the VERO system (BrainLAB, Feldkirchen, Germany). This evolution will be used to illustrate the recent developments in this particular field of research. Copyright © 2010. Published by Elsevier SAS. status: publishe...|$|R
40|$|Outcome after {{cardiac arrest}} is {{dependent}} on the quality of chest compressions (CC). A great number of devices have been developed to provide guidance during CPR. The present study evaluates a new CPR feedback system (Mini-VREM: Mini-Virtual Reality Enhanced Mannequin) designed to improve CC during training. Methods: Mini-VREM system consists of a Kinect® (Microsoft, Redmond, WA, USA) motion sensing device and specifically developed software to provide <b>audio-visual</b> <b>feedback.</b> Mini-VREM was connected to a commercially available mannequin (Laerdal Medical, Stavanger, Norway). Eighty trainees (healthcare professionals and lay people) volunteered in this randomised crossover pilot study. All subjects performed a 2 min CC trial, 1 h pause and a second 2 min CC trial. The first group (FB/NFB, n= 40) performed CC with Mini-VREM feedback (FB) followed by CC without feedback (NFB). The second group (NFB/FB, n= 40) performed vice versa. Primary endpoints: adequate compression (compression rate between 100 and 120 min- 1 and compression depth between 50 and 60 mm); compressions rate within 100 - 120 min- 1; compressions depth within 50 - 60 mm. Results: When compared to the performance without feedback, with Mini-VREM feedback compressions were more adequate (FB 35. 78 % vs. NFB 7. 27 %, p< 0. 001) and more compressions achieved target rate (FB 72. 04 % vs. 31. 42 %, p< 0. 001) and target depth (FB 47. 34 % vs. 24. 87 %, p= 0. 002). The participants perceived the system to be easy to use with effective feedback. Conclusions: The Mini-VREM system was able to improve significantly the CC performance by healthcare professionals and by lay people in a simulated CA scenario, in terms of compression rate and dept...|$|R
40|$|On {{multiline}} {{slot machine}} games, small “wins” often amount {{to less than}} the spin wager, resulting in a monetary loss to the gambler. Nevertheless, these monetary losses are still accompanied by “winning” (and potentially reinforcing) <b>audio-visual</b> <b>feedback.</b> Dixon, Harrigan, Sandhu, Collins, and Fugelsang (2010) termed these potentially reinforcing losses as losses disguised as wins, or LDWs. Dixon et al. previously showed that novice gamblers appear to somatically miscategorize LDWs as wins rather than correctly categorizing these outcomes as losses. Two studies are presented which investigated whether novice gamblers would psychologically miscategorize LDWs as wins as well. In both studies, we investigated participants’ categorizations of LDWs using two measures. First, we asked participants to recall how many times they had won during a playing session and predicted that if participants miscategorize LDWs as wins, then they should conflate LDWs and wins in memory. In Study 1, participants played 200 spins on a real slot machine game with either relatively fewer or relatively many expected LDWs. We found that participants who experienced more LDWs during the playing session recalled winning significantly more often than participants who experienced fewer LDWs, despite how many actual wins the participant experienced, or how much they won or lost overall. In Study 2, we found that participants recalled winning significantly more often in simulator games with more rather than fewer LDWs, despite identical numbers of real wins and identical payback percentages in both games. We referred {{to this type of}} memory error as the LDW overestimation effect. The second measure we used to investigate participants’ categorizations of LDWs was more immediate and direct. We evaluated whether participants would miscategorize LDWs as wins or correctly categorize these outcomes as losses by simply asking them to verbally label slot machine spin outcomes. In both studies, we found that the majority of participants miscategorized LDWs as wins rather than correctly categorizing the outcomes as losses. Implications for problem gambling are discussed...|$|R
40|$|This {{document}} specifies an Internet standards track {{protocol for}} the Internet community, and requests discussion {{and suggestions for}} improvements. Please refer to the current edition of the "Internet Official Protocol Standards " (STD 1) for the standardization state and status of this protocol. Distribution of this memo is unlimited. This document specifies a few extensions to the messages defined in the <b>Audio-Visual</b> Profile with <b>Feedback</b> (AVPF). They are helpful primarily in conversational multimedia scenarios where centralized multipoint functionalities are in use. However, some are also usable in smaller multicast environments and point-to-point calls...|$|R
40|$|AbstractThis paper {{introduces}} {{the development of}} a customized virtual reality system based on a serious game which allows the user to carry out physical and cognitive rehabilitation therapies using a natural user interface based on Microsoft© Kinect. Within these serious games you can find the exergames. It is a type of serious game which aims to stimulate body mobility through an immersive experience that situates the user inside virtual interactive landscapes. This type of game has become popular in recent years thanks to the creation of consoles like Nintendo Wii, Playstation or Xbox, which use gestural interaction game interfaces. Likewise, these technologies have become extremely useful tools in rehabilitation, and they are expected to permit a reduction of costs in socio-sanitary environments. The proposed virtual reality platform consists of different types of exercises by which the user is able to train or rehabilitate several aspects such as strength, aerobic or cognitive capacities. The system has been modelled so that the physical presence of a therapist is not required {{during the course of the}} session and there is no need to wear any kind of marker or sensor. Moreover, all parameters of the different exercises can be configured without the physical presence of a therapist. The reports of each session can also be read offline, therefore, the therapist will always know if a user has performed the session in a good way and act accordingly modifying whatever he deems necessary in the patient's therapy. Due to these facts the system developed and presented in this article is a rehabilitation system based on remote assistance. It is important that this type of serious games accomplish all the functionalities a videogame fulfils at the same time that accomplish specific functionalities in its therapeutic environment. Remarkably, it is required an adaptation to the patient's abilities to avoid frustration and provide immediate feedback to the user during the exercises. In our system, the users are monitored and receive an <b>audio-visual</b> <b>feedback</b> during the session, so that they know in real-time if they are correctly doing the exercises of the specific therapy that was designed for them...|$|R
