145|36|Public
50|$|In the <b>auditory</b> <b>midbrain</b> nucleus, the {{inferior}} colliculus (IC), many ILD sensitive neurons have response functions that decline steeply from maximum to zero spikes {{as a function}} of ILD. However, there are also many neurons with much more shallow response functions that do not decline to zero spikes.|$|E
50|$|During {{this time}} she was {{involved}} in development of a <b>Auditory</b> <b>Midbrain</b> Implant (AMI) which is a new hearing prosthesis designed for stimulation of the inferior colliculus in deaf patients who cannot sufficiently benefit from cochlear implants. In 2008, she defended her post doctoral thesis in the field of Otorhinolaryngology and received permission for teaching in this field.|$|E
50|$|Because {{the ears}} receive audio signals at {{different}} times, the sound source {{can be determined}} by using the delays retrieved from the two ears. By cross-correlating the delays from {{the left and right}} channels (of the model), the coincided peaks can be categorized as the same localized sound, despite their temporal location in the input signal. The use of interaural cross-correlation mechanism has been supported through physiological studies, paralleling the arrangement of neurons in the <b>auditory</b> <b>midbrain.</b>|$|E
40|$|Auditory {{units that}} responded to sound {{only when it}} {{originated}} from a limited area of space {{were found in the}} lateral and anterior portions of the <b>midbrain</b> <b>auditory</b> nucleus of the owl (Tyto alba). The areas of space to which these units responded (their receptive fields) were largely independent of the nature and intensity of the sound stimulus. The units were arranged systematically within the <b>midbrain</b> <b>auditory</b> nucleus according to the relative locations of their receptive fields, thus creating a physiological map of auditory space...|$|R
40|$|The {{responses}} of auditory units with limited spatial receptive fields (L-F units) were studied {{before and after}} acute monaural occlusion. The L-F units were recorded in the space-mapped region of the <b>midbrain</b> <b>auditory</b> nucleus (MLD) of the owl (Tyro alba). Excitatory receptive fields and best areas were plotted using a movable sound source under free-field conditions...|$|R
40|$|Deficits {{in central}} {{auditory}} processing may {{occur in a}} variety of clinical conditions including traumatic brain injury, neurodegenerative disease, auditory neuropathy/dyssynchrony syndrome, neurological disorders associated with aging, and aphasia. Deficits in central auditory processing of a more subtle nature have also been studied extensively in neurodevelopmental disorders in children with learning disabilities, ADD, and developmental language disorders. Illustrative cases are reviewed demonstrating the use of an audiological test battery in patients with auditory neuropathy/dyssynchrony syndrome, bilateral lesions to the inferior colliculi, and bilateral lesions to the temporal lobes. Electrophysiological tests of auditory function were utilized to define the locus of dysfunction at neural levels ranging from the <b>auditory</b> nerve, <b>midbrain,</b> and cortical levels...|$|R
50|$|Cochlear {{implants}} (CIs), auditory {{brain stem}} implants (ABIs), and <b>auditory</b> <b>midbrain</b> implants (AMIs) {{are the three}} main categories for auditory prostheses. CI electrode arrays are implanted in the cochlea, ABI electrode arrays stimulate the cochlear nucleus complex in the lower brain stem, and AMIs stimulates auditory neurons in the inferior colliculus. Cochlear implants have been very successful among these three categories. Today the Advanced Bionics Corporation, the Cochlear Corporation and the Med-El Corporation are the major commercial providers of cochlea implants.|$|E
5000|$|The primary {{findings}} about neurostimulation originated {{from the idea}} to stimulate nerves for therapeutic purposes. The 1st recorded use of electrical stimulation for pain relief goes back to 46 AD, when Scribonius Largus used torpedo fish (electric ray) for relieving headaches. In the late 18th century, Luigi Galvani discovered that the muscles of dead frog legs twitched when struck by direct current on the nervous system. The modulation of the brain activity by electrical stimulation of the motor cortex in dogs was shown in 1870 that resulted in limb movement. [...] From the late 18th century to today many milestones have been developed. Nowadays, sensory prosthetic devices, such as visual implants, cochlear implants, <b>auditory</b> <b>midbrain</b> implants, and spinal cord stimulators and also motor prosthetic devices, such as deep brain stimulators, Bion microstimulators, the brain control and sensing interface, and cardiac electro-stimulation devices are widely used.|$|E
40|$|The cortex {{is thought}} to be the primary site of sensory plasticity, {{particularly}} during development. Here, we report that large-scale reorganization of the mouse <b>auditory</b> <b>midbrain</b> tonotopic map is induced by a specific sound-rearing environment consisting of paired low- (16 kHz) and high-frequency (40 kHz) tones. To determine the potential for plasticity in the mouse <b>auditory</b> <b>midbrain,</b> we used manganese-enhanced MRI to analyze the midbrain tonotopic maps of control mice during normal development and mice reared in the two-tone (16 + 40 kHz) environment. We found that the tonotopic map emerged during the third postnatal week in normal mice. Before 3 weeks, a larger percentage of <b>auditory</b> <b>midbrain</b> responded to each of the suprathreshold test frequencies, {{despite the fact that the}} primary afferent projections are in place even before hearing onset. By 3 weeks, the midbrain tonotopic map of control mice was established, and manganese-enhanced MRI showed a clear separation between the 16 - and 40 -kHz responses. Two-tone rearing dramatically altered the appearance of these discrete frequency-specific responses. A significant volume of the <b>auditory</b> <b>midbrain</b> became responsive to both rearing frequencies, resulting in a large-scale reorganization of the tonotopic map. These results indicate that developmental plasticity occurs on a much greater scale than previously appreciated in the mammalian <b>auditory</b> <b>midbrain...</b>|$|E
40|$|Statistical {{characteristics}} of background firing in the <b>midbrain</b> <b>auditory</b> units of grass frog (Rana t. temporaria) located in torus semicircular (TS) were investigated. Only about 5 % {{of the cells}} demonstrated prominent spontaneous firing. For such units the following characteristics were obtained: the distribution of interpulse intervals, the autocorrelation functions (ACF) for the real firing process and for the process with shuffled intervals, the hazard function (HF) and the joint distribution of adjacent interpulse intervals. The burstiness of firing was also estimated. In the absolute majority of the cells, the background firing demonstrated considerable deviation from the renewal process. There was weak but significant positive correlation between adjacent interpulse intervals. The burstiness of firing in the <b>midbrain</b> <b>auditory</b> units was moderate but higher than reported for medullary auditory neurons. The value of burstiness did not decrease after interval shuffling. Along with the reduction in excitability (generalized refractoriness) in many neurons observed post-spike facilitation effects were observed. Comparing background activity in medullary and midbrain nucleus {{suggests that there is}} an increase in complexity of the information processing along the auditory pathway...|$|R
40|$|Diabetic {{patients}} have longer interpeak latencies in the brainstem auditory evoked responses than age-matched controls. The delay {{is not related}} to clinical hearing loss or blood glucose level at time of testing. Since waves I and II are normal in latency, the conduction velocity of the eighth nerve is not involved. The delay occurs between waves II and V, which would reflect altered transmission times in <b>auditory</b> brainstem and <b>midbrain</b> structures, and suggests the presence of a central neuropathy in patients with diabetes...|$|R
50|$|As {{with other}} primary sensory {{cortical}} areas, auditory sensations reach perception only if received and processed by a cortical area. Evidence for {{this comes from}} lesion studies in human patients who have sustained damage to cortical areas through tumors or strokes, or from animal experiments in which cortical areas were deactivated by surgical lesions or other methods. Damage to the Primary Auditory Cortex in humans leads {{to a loss of}} any awareness of sound, but an ability to react reflexively to sounds remains as {{there is a great deal}} of subcortical processing in the <b>auditory</b> brainstem and <b>midbrain.</b>|$|R
40|$|For neurons in the <b>auditory</b> <b>midbrain</b> of {{the grass}} frog {{the use of a}} {{combined}} spectro-temporal characterization has been evaluated against the separate characterizations of frequency-sensitivity and temporal response properties. By factoring the joint density function of stimulus intensity, I(f, t), preceding a spike, into two marginal density functions I 1 (f) and I 2 (t) one may under the assumption of statistical independence reconstruct the joint density by multiplication: I 1 (f) · I 2 (t). The reconstructed Î(f,t) is compared to the original I(f, t) for 83 neurons: in 23 % thereof the Î(f, t) appeared to be vastly different from I(f, t). These units appeared to be located dominantly in the ventral parts of the <b>auditory</b> <b>midbrain</b> and had a latency exceeding 30 ms. On the basis of the action-potential wave forms the absence of non-separable I(f, t) in the incoming nerve fiber population is concluded. A spectro-temporal characterization of auditory neurons seems mandatory for investigations in and central from the <b>auditory</b> <b>midbrain...</b>|$|E
40|$|Most citizen {{people are}} exposed daily to {{environmental}} noise at moderate levels {{with a short}} duration. The aim {{of the present study}} was to determine the effects of daily short-term exposure to moderate noise on sound level processing in the <b>auditory</b> <b>midbrain.</b> Sound processing properties of <b>auditory</b> <b>midbrain</b> neurons were recorded in anesthetized mice exposed to moderate noise (80 [*]dB SPL, 2 [*]h/d for 6 weeks) and were compared with those from age-matched controls. Neurons in exposed mice had a higher minimum threshold and maximum response intensity, a longer first spike latency, and a higher slope and narrower dynamic range for rate level function. However, these observed changes were greater in neurons with the best frequency within the noise exposure frequency range compared with those outside the frequency range. These sound processing properties also remained abnormal after a 12 -week period of recovery in a quiet laboratory environment after completion of noise exposure. In conclusion, even daily short-term exposure to moderate noise can cause long-term impairment of sound level processing in a frequency-specific manner in <b>auditory</b> <b>midbrain</b> neurons...|$|E
40|$|Scientific Session - fMRI Basic Neuroscience, Including Optogenetics: no. 0481 In the {{auditory}} system, the midbrain inferior colliculus (IC) receives massive corticofugal projections, yet their functional implications remain unclear. Previous studies utilizing single neuron recordings and electrical activation or cryogenical inactivation of the cortex {{could not provide}} a cell-type specific understanding of the large-scale corticofugal modulation effects. This study combines auditory and optogenetic fMRI to investigate the corticofugal influences on <b>auditory</b> <b>midbrain</b> processing. Large-view fMRI was used to monitor the IC noise response during cell-type specific optogenetic stimulation of the VC. The results demonstrate the feasibility of this novel approach and show that VC normally facilitates <b>auditory</b> <b>midbrain</b> responses...|$|E
40|$|This review {{describes}} {{mechanisms and}} circuitry underlying combination-sensitive response {{properties in the}} <b>auditory</b> brainstem and <b>midbrain.</b> Combination-sensitive neurons, performing a type of auditory spectro-temporal integration, respond to specific, properly timed combinations of spectral elements in vocal signals and other acoustic stimuli. While these neurons are known {{to occur in the}} auditory forebrain of many vertebrate species, the work described here establishes their origin in the <b>auditory</b> brainstem and <b>midbrain.</b> Focusing on the mustached bat, we review several major findings: 1) Combination-sensitive responses involve facilitatory interactions, inhibitory interactions, or both when activated by distinct spectral elements in complex sounds. 2) Combination-sensitive responses are created in distinct stages: inhibition arises mainly in lateral lemniscal nuclei of the auditory brainstem, while facilitation arises in the inferior colliculus (IC) of the midbrain. 3) Spectral integration underlying combination-sensitive responses requires a low frequency input tuned well below a neuron’s characteristic frequency (ChF). Low-ChF neurons in the auditory brainstem project to high-ChF regions in brainstem or IC to create combination sensitivity. 4) At their sites of origin, both facilitatory and inhibitory combination-sensitive interactions depend on glycinergic inputs and are eliminated by glycine receptor blockade. Surprisingly, facilitatory interactions in IC depend almost exclusively on glycinergic inputs and are largely independent of glutamatergic and GABAergic inputs. 5) The medial nucleus of the trapezoid body, the lateral lemniscal nuclei, and the IC play critical roles in creating combination-sensitive responses. We propose that these mechanisms, based on work in the mustached bat, apply to a broad range of mammals and other vertebrates that depend on temporally sensitive integration of information across the audible spectrum...|$|R
40|$|Background and Aim: Tinnitus is {{a common}} symptom among lots of people but {{little is known about}} its origins. This study was aimed at {{comparing}} the Auditory Steady-State Response (ASSR) thresholds in normal cases and patients with subjective idiopathic tinnitus (SIT) in order to diagnose its real origins. Materials and Methods: This case-control study was conducted on 19 patients with tinnitus and 24 normal cases aged 18 - 40 yr. The patients underwent broad medical tests to roll out any background reason for their tinnitus. ASSR thresholds were estimated in both groups at 20 and 40 amplitude modulation. The patients were selected from tinnitus patients in Research Center in Hazrat Rasoul Hospital, Tehran, Iran. Results: The mean ASSR thresholds at 40 HZ modulation were worse in tinnitus patients compared to normal ones (p< 0. 05) but no significant statistical differences was detected at 20 HZ. These results were found in both situations in which we averaged both ears thresholds and when we estimated the thresholds of the ears separately. Conclusion: It seems that the origin of the responses of the modulation of 40 Hz, primary <b>auditory</b> cortex, <b>midbrain</b> regions and subcortical areas, in these patients is involved or the origin of their tinnitus is related to some kind of problems in these areas, although more investigation is needed about 20 Hz...|$|R
40|$|We {{investigated}} the functional {{architecture of the}} inferior colliculus (IC) in rhesus monkeys. We systematically mapped multiunit responses to tonal stimuli and noise in the IC and surrounding tissue of six rhesus macaques, collecting data at evenly placed locations and recording nonresponsive locations to define boundaries. The results show a modest tonotopically organized region (17 of 100 recording penetration locations in 4 of 6 monkeys) surrounded by a large mass of tissue that, although vigorously responsive, showed no clear topographic arrangement (68 of 100 penetration locations). Rather, most cells in these recordings responded best to frequencies {{at the low end}} of the macaque auditory range. The remaining 15 (of 100) locations exhibited auditory responses that were not sensitive to sound frequency. Potential anatomical correlates of functionally defined regions and implications for <b>midbrain</b> <b>auditory</b> prosthetic devices are discussed...|$|R
40|$|Electronic Poster Session: Functional MRI (Neuro) - Preclinical fMRI: no. 3907 The cortex is {{commonly}} {{thought of as}} the site at which ascending projections from all sensory modalities are integrated, yet cortical feedback to subcortical nuclei modulates early information processing. Here, we demonstrate that descending inputs from both auditory and visual cortex are integrated in the <b>auditory</b> <b>midbrain.</b> Using BOLD fMRI to measure sound-evoked responses throughout the <b>auditory</b> <b>midbrain,</b> we show that auditory cortical input normally suppresses the gain of midbrain response, while visual cortical input increases the gain. Our results demonstrate the large-scale influence of cortical projections from more than one sensory modality, demonstrating that while ascending integration occurs in cortex, descending integration occurs in the brainstem...|$|E
40|$|In the {{auditory}} brainstem, information processed within the several parallel pathways that diverge from the cochlear nucleus converges {{again in the}} principal nucleus of the <b>auditory</b> <b>midbrain,</b> the inferior colliculus (IC). The output of the IC is {{the main source of}} input to {{the auditory}} thalamus and subsequently the auditor...|$|E
40|$|International audienceVocal {{learning}} in songbirds and humans occurs by imitation of adult vocalizations. In both groups, vocal {{learning in}}cludes a perceptual phase during which juveniles birds and infants memorize adult vocalizations. Despite intensive research, the neural mechanisms supporting this auditory memory are still poorly understood. The present functional MRI study demonstrates that in adult zebra finches, the right <b>auditory</b> <b>midbrain</b> nucleus responds selectively to the copied vocalizations. The selective signal {{is distinct from}} selectivity for the bird's own song and does not simply reflect acoustic differences between the stimuli. Furthermore, the amplitude of the selective signal is positively correlated with the strength of vocal learning, measured {{by the amount of}} song that experimental birds copied from the adult model. These results indicate that early sensory experience can generate a long-lasting memory trace in the <b>auditory</b> <b>midbrain</b> of songbirds that may support song learning...|$|E
50|$|Sensory {{maps are}} formed largely by experience. Basic wiring {{of the brain}} is {{established}} in vivo {{by a variety of}} molecular guidance cues, and the wiring is then refined by patterns of neural activity based in sensory experience. For synchronization of multiple maps, replay of sensory input in circuits allows neurons to be organized into vertical topographic functional units before horizontal integration. Neurons become specialized: in the big brown bat, delay-tuned neurons encode a target range and act as probability encoders, and this comes from experience. In the owl, auditory units responded to specific locations in space, and units were arranged systematically according to the relative locations of their receptive fields, thereby creating a physiological map of auditory space. The receptive fields of the neurons found in the <b>midbrain</b> <b>auditory</b> nucleus had receptive fields independent of nature and intensity of the sound.|$|R
40|$|Subjective {{tinnitus}} is {{the conscious}} (attended) awareness perception of {{sound in the}} absence of an external source and can be classified as an auditory phantom perception. The current tinnitus development models depend on the role of external events congruently paired with the causal physical events that precipitate the phantom perception. We propose a novel Neurofunctional tinnitus model to indicate that the conscious perception of phantom sound is essential in activating the cognitive-emotional value. The cognitive-emotional value plays a crucial role in governing attention allocation as well as developing annoyance within tinnitus clinical distress. Structurally, the Neurofunctional tinnitus model includes the peripheral auditory system, the thalamus, the limbic system, brain stem, basal ganglia, striatum and the auditory along with prefrontal cortices. Functionally, we assume the model includes presence of continuous or intermittent abnormal signals at the peripheral <b>auditory</b> system or <b>midbrain</b> <b>auditory</b> paths. Depending on the availability of attentional resources, the signals may or may not be perceived. The cognitive valuation process strengthens the lateral-inhibition and noise canceling mechanisms in the mid-brain, which leads to the cessation of sound perception and renders the signal evaluation irrelevant. However, the sourceless sound is eventually perceived and can be cognitively interpreted as suspicious or an indication of a disease in which the cortical top-down processes weaken the noise canceling effects. This results in an increase in cognitive and emotional negative reactions such as depression and anxiety. The negative or positive cognitive-emotional feedbacks within the top-down approach may have no relation to the previous experience of the patients. They can also be associated with aversive stimuli similar to abnormal neural activity in generating the phantom sound. Cognitive and emotional reactions depend on general personality biases toward evaluative conditioning combined with a cognitive-emotional negative appraisal of stimuli such as the case of people with present hypochondria. We acknowledge that the projected Neurofunctional tinnitus model does not cover all tinnitus variations and patients. To support our model, we present evidence from several studies using neuroimaging, electrophysiology, brain lesion, and behavioral technique...|$|R
50|$|An {{auditory}} pathway that is {{used for}} auditory learning brings auditory information into the vocal pathway, but the auditory pathway {{is not unique to}} vocal learners. Ear hair cells project to cochlear ganglia neurons to auditory pontine nuclei to midbrain and thalamic nuclei and to primary and secondary pallial areas. A descending auditory feedback pathway exists projecting from the dorsal nidopallium to the intermediate arcopallium to shell regions around the thalamic and <b>midbrain</b> <b>auditory</b> nuclei. Remaining unclear is the source of auditory input into the vocal pathways described above. It is hypothesized that songs are processed in these areas in a hierarchical manner, with the primary pallial area responsible for acoustic features (field L2), the secondary pallial area (fields L1 and L3 as well as the caudal medial nidopallium or NCM) determining sequencing and discrimination, and the highest station, the caudal mesopallium (CM), modulating fine discrimination of sounds. Secondary pallial areas including the NCM and CM are also thought to be involved in auditory memory formation of songs used for vocal learning, but more evidence is needed to substantiate this hypothesis.|$|R
40|$|Responses in {{auditory}} cortex {{tend to be}} weaker, more phasic, and noisier {{than those}} of auditory brainstem and midbrain nuclei. Is the activity in cortex therefore merely a “degraded echo” of lower-level neural representations? In this issue of Neuron, Chechik and colleagues show that, while cortical responses indeed convey less sensory information than <b>auditory</b> <b>midbrain</b> neurons, their responses are also much less redundant...|$|E
40|$|Acoustic {{communication}} {{plays an}} important role in the reproductive behavior of anurans. Males of concave-eared torrent frog (_Odorrana tormota_) have ultrasonic communication capacity 1, 2, but it is unknown whether females communicate with ultrasound. Here we show that _O. tormota_ exhibits great sex differences in the auditory frequency sensitivity. Acoustic playback experiments demonstrated that the male&#x 27;s advertisement calls evoke gravid females&#x 27; positive phonotaxis and vocal responses, whereas ultrasonic components of the male&#x 27;s calls (frequencies above 20 kHz) do not elicit female phonotaxis or vocalization. The behavioral study was complemented by electrophysiological recordings from the <b>auditory</b> <b>midbrain</b> and by laser Doppler vibrometer measurements of the tympanic membrane&#x 27;s response to acoustic stimuli. These measurements revealed that females have an upper frequency limit up to 16 kHz (threshold 107 dB SPL) and no ultrasound sensitivity, unlike males which have an upper frequency limit of up to 35 kHz (87 dB SPL). Single units in the female <b>auditory</b> <b>midbrain</b> have the best excitatory frequencies (BEFs) peaked around 5 kHz, corresponding to the fundamental frequency (F 0) of male&#x 27;s most calls, whereas the male <b>auditory</b> <b>midbrain</b> units have BEFs mostly above 8 kHz, largely consistent with the F 0 of female courtship calls. Females have a frequency sensitive bandwidth (10 dB above threshold) ranged from 2 to 6 kHz, narrower than that males have (5 - 20 kHz). The velocity amplitude of the tympanic membranes peaked around 5 kHz in females, whereas 7 kHz in males. The results suggest that the frog species O. tormota is an example of a vertebrate, which demonstrates well phonotaxis and extraordinary sex differences in hearing...|$|E
40|$|Hierarchical {{processing}} of sensory information requires interaction at multiple levels along the peripheral to central pathway. Recent {{evidence suggests that}} interaction between driving and modulating components can shape both top down and bottom up {{processing of}} sensory information. Here we show that a component inherited from extrinsic sources combines with local components to code sound intensity. By applying high concentrations of divalent cations to neurons in {{the nucleus of the}} inferior colliculus in the <b>auditory</b> <b>midbrain,</b> we show that as sound intensity increases, the source of synaptic efficacy changes from inherited inputs to local circuits. In neurons with a wide dynamic range response to intensity, inherited inputs increase firing rates at low sound intensities but saturate at mid-to-high intensities. Local circuits activate at high sound intensities and widen dynamic range by continuously increasing their output gain with intensity. Inherited inputs are necessary and sufficient to evoke tuned responses, however local circuits change peak output. Push-pull driving inhibition and excitation create net excitatory drive to intensity-variant neurons and tune neurons to intensity. Our results reveal that dynamic range and tuning re-emerge in the <b>auditory</b> <b>midbrain</b> through local circuits that are themselves variable or tuned...|$|E
40|$|The {{connections}} of {{the inferior}} colliculus, the mammalian <b>midbrain</b> <b>auditory</b> center, were determined {{in the greater}} horseshoe bat (Rhinolophus ferrumequinum), using the horseradish peroxidase method. In order to localize the auditory centers of this bat, brains were investigated {{with the aid of}} cell and fiber-stained material. The results show that most auditory centers are highly developed in this echolocating bat. However, the organization of the central auditory system does not generally differ from the mammalian scheme. This holds also for the organization of the superior olivary complex where a well-developed medial superior olivary nucleus was found. In addition to the ventral and dorsal nuclei of the lateral lemniscus a third well-developed nucleus has been defined which projects ipsilaterally to the inferior colliculus and which was called the intermediate nucleus of the lateral leminiscus. All nuclei of the central auditory pathway project ipsi-, contra-, or bilaterally to the central nucleus of the inferior colliculus {{with the exception of the}} medial nucleus of the trapezoid body and the medial geniculate body. The tonotopic organization of these projections and their possible functions are discussed in context with neurophysiological investigations. ...|$|R
40|$|Background: Cortical neurons {{implement}} a high frequency-specific modulation of subcortical nuclei {{that includes the}} cochlear nucleus. Anatomical studies show that corticofugal fibers terminating in the <b>auditory</b> thalamus and <b>midbrain</b> are mostly ipsilateral. Differently, corticofugal fibers terminating in the cochlear nucleus are bilateral, which fits {{to the needs of}} binaural hearing that improves hearing quality. This leads to our hypothesis that corticofugal modulation of initial neural processing of sound information from the contralateral and ipsilateral ears could be equivalent or coordinated at the first sound processing level. Methodology/Principal Findings: With the focal electrical stimulation of the auditory cortex and single unit recording, this study examined corticofugal modulation of the ipsilateral cochlear nucleus. The same methods and procedures as described in our previous study of corticofugal modulation of contralateral cochlear nucleus were employed simply for comparison. We found that focal electrical stimulation of cortical neurons induced substantial changes in the response magnitude, response latency and receptive field of ipsilateral cochlear nucleus neurons. Cortical stimulation facilitated auditory response and shortened the response latency of physiologically matched neurons whereas it inhibited auditory response and lengthened the response latency of unmatched neurons. Finally, cortical stimulation shifted the best frequencies of cochlear neurons towards those of stimulated cortical neurons...|$|R
40|$|Sexual {{selection}} and signal detection theories predict that females should be {{selective in their}} responses to mating signals in mate choice, while the response of males to signals in male competition should be less selective. The neural processes underlying this behavioural sex difference remain obscure. Differences in behavioural selectivity could result from differences in how sensitive sensory systems are to mating signals, distinct thresholds in motor areas regulating behaviour, or sex differences in selectivity at a gateway relaying sensory information to motor systems. We tested these hypotheses in frogs using the expression of egr- 1 to quantify the neural responses of each sex to mating signals. We found that egr- 1 expression in a <b>midbrain</b> <b>auditory</b> region was elevated in males in response to both conspecific and heterospecific calls, whereas in females, egr- 1 induction occurred only in response to conspecific signals. This differential neural selectivity mirrored the sex differences in behavioural responsiveness to these stimuli. By contrast, egr- 1 expression in lower brainstem auditory centres was not different in males and females. Our results support a model in which sex differences in behavioural selectivity arise from sex differences in the neural selectivity in midbrain areas relaying sensory information to the forebrain...|$|R
40|$|Auditory brain areas undergo {{reorganization}} {{resulting from}} abnormal sensory input during early postnatal development. This {{is evident from}} studies at the cortical level but it remains unclear whether there is reorganization in the <b>auditory</b> <b>midbrain</b> in a species similar to the human, that is, with early hearing onset. We have explored midbrain plasticity in the chinchilla, a precocious species that matches the human in terms of hearing development. Neonatal chinchillas were chronically exposed to a 2 [*]kHz narrowband sound at 70 [*]dB[*]SPL for 4 weeks. Tonotopic maps in inferior colliculus (central nucleus) were defined based on single neuron characteristic frequency. We hypothesized an overrepresentation of the 2 [*]kHz region of the maps. However, we observed {{a significant decrease in}} the proportion of neurons dedicated to the 2 [*]kHz octave band and also away from the exposure frequency at 8 [*]kHz. In addition, we report a significant increase in low frequency representation (< 1 [*]kHz), again a change to tonotopic mapping distant to the 2 [*]kHz region. Thus in a precocious species, tonotopic maps in <b>auditory</b> <b>midbrain</b> are altered following abnormal stimulation during development. However, these changes are more complex than the overrepresentation of exposure related frequency regions that are often reported...|$|E
40|$|Age-related {{hearing loss}} (ARHL) {{is marked by}} {{audiometric}} hearing deficits that propagate along the auditory pathway. Neurochemical changes {{as a function of}} aging have also been identified in neurons along the auditory pathway in both rodents and carnivores, however, very little is known about how these neurochemicals change in the non-human primate. To examine how these compensatory neurochemical changes relate to normal aging and audiometric sensitivity along the auditory pathway, we collected auditory brainstem responses (ABRs) and brain specimens from seven rhesus monkeys spanning in age from 15 to 35 years old, and examined the relationship between click evoked ABR thresholds and the ABR evoked pure tone average and changes in the number of parvalbumin and NADPH-diaphorase positive cells in the <b>auditory</b> <b>midbrain.</b> We found that the number of parvalbumin positive cells in the central nucleus and the surrounding cortex regions of the inferior colliculus were strongly correlated with advancing age and ABR pure tone average. We also found that the numbers of NADPHd positive cells in these same regions were not associated with normal aging or changes in the ABR thresholds. These findings suggest that the <b>auditory</b> <b>midbrain</b> undergoes an up-regulation of parvalbumin expressing neurons with aging that is related to changes in the processing of frequencies across the audiometric range...|$|E
40|$|Electrophysiological {{studies on}} duration-tuned neurons (DTNs) from the {{mammalian}} <b>auditory</b> <b>midbrain</b> have typically evoked spiking responses from these cells using monaural or free-field acoustic stimulation {{focused on the}} contralateral ear, with fewer studies devoted to examining the electrophysiological properties of duration tuning using binaural stimulation. Because the inferior colliculus (IC) receives convergent inputs from lower brainstem auditory nuclei that process sounds from each ear, many midbrain neurons have responses shaped by binaural interactions and are selective to binaural cues important for sound localization. In this study, we used dichotic stimulation to vary interaural level difference (ILD) and interaural time difference (ITD) acoustic cues and explore the binaural interactions and response properties of DTNs and non-DTNs from the IC of the big brown bat Eptesicus fuscus. Our results reveal that both DTNs and non-DTNs can have responses selective to binaural stimulation, with a majority of IC neurons showing some type of ILD selectivity, fewer cells showing ITD selectivity, {{and a number of}} neurons showing both ILD and ITD selectivity. This study provides the first demonstration that the temporally selective responses of DTNs from the vertebrate <b>auditory</b> <b>midbrain</b> can be selective to binaural cues used for sound localization in addition to having spiking responses that are selective for stimulus frequency, amplitude, and duration...|$|E
40|$|Mice are of {{paramount}} importance in biomedical research and their vocalizations are a subject of interest for researchers across {{a wide range of}} health-related disciplines due to their increasingly important value as a phenotyping tool in models of neural, speech and language disorders. However, the mechanisms underlying the auditory processing of vocalizations in mice are not well understood. The mouse audiogram shows a peak in sensitivity at frequencies between 15 - 25 kHz, but weaker sensitivity for the higher ultrasonic frequencies at which they typically vocalize. To investigate the auditory processing of vocalizations in mice, we measured evoked potential, single-unit, and multi-unit responses to tones and vocalizations at three different stages along the auditory pathway: the auditory nerve and the cochlear nucleus in the periphery, and the inferior colliculus in the <b>midbrain.</b> <b>Auditory</b> brainstem response measurements suggested stronger responses in the midbrain relative to the periphery for frequencies higher than 32 kHz. This result was confirmed by single- and multi-unit recordings showing that high ultrasonic frequency tones and vocalizations elicited responses from {{only a small fraction of}} cells in the periphery, while a much larger fraction of cells responded in the inferior colliculus. These results suggest that the processing of communication calls in mice is supported by a specialization of the auditory system for high frequencies that emerges at central stations of the auditory pathway...|$|R
40|$|Autoradiography with [14 C] 2 -deoxyglucose (2 -DG) {{was used}} to examine the {{functional}} activity of the rat auditory system during long- and short-term habituation of the acoustic startle reflex. The data showed that presentation of the acoustic stimulus to long-term habituated rats resulted in a learning-related metabolic enhancement that was significantly greater than the response evoked by the same acoustic stimulus in the inexperienced rats. This enhancement was localized to brainstem and <b>midbrain</b> <b>auditory</b> nuclei and no significant changes occurred at thalamocortical levels of the auditory pathway. The largest difference in 2 -DG uptake between long- and short-term habituated rats was in the lateral superior olivary nucleus (LSO). The LSO activation suggests that olivocochlear efferents may operate in a central feedback control of peripheral auditory input during long-term habituation. Findings of enhanced metabolism from the cochlear nuclei to the central nucleus of the inferior colliculus indicated that active processes of neuronal plasticity take place in the lower auditory system during long-term habituation. The results provide the first demonstration of how a nonassociative learning experience such as long-term habituation modifies the metabolic activity of the auditory system. The findings support the conclusion that auditory responses of behaving animals to acoustic stimuli are dependent not only on the physical parameters of a stimulus, but also on its learned behavioral significance...|$|R
40|$|Cortical neurons {{implement}} a high frequency-specific modulation of subcortical nuclei {{that includes the}} cochlear nucleus. Anatomical studies show that corticofugal fibers terminating in the <b>auditory</b> thalamus and <b>midbrain</b> are mostly ipsilateral. Differently, corticofugal fibers terminating in the cochlear nucleus are bilateral, which fits {{to the needs of}} binaural hearing that improves hearing quality. This leads to our hypothesis that corticofugal modulation of initial neural processing of sound information from the contralateral and ipsilateral ears could be equivalent or coordinated at the first sound processing level. With the focal electrical stimulation of the auditory cortex and single unit recording, this study examined corticofugal modulation of the ipsilateral cochlear nucleus. The same methods and procedures as described in our previous study of corticofugal modulation of contralateral cochlear nucleus were employed simply for comparison. We found that focal electrical stimulation of cortical neurons induced substantial changes in the response magnitude, response latency and receptive field of ipsilateral cochlear nucleus neurons. Cortical stimulation facilitated auditory response and shortened the response latency of physiologically matched neurons whereas it inhibited auditory response and lengthened the response latency of unmatched neurons. Finally, cortical stimulation shifted the best frequencies of cochlear neurons towards those of stimulated cortical neurons. Our data suggest that cortical neurons enable a high frequency-specific remodelling of sound information processing in the ipsilateral cochlear nucleus {{in the same manner as}} that in the contralateral cochlear nucleus...|$|R
