13|2|Public
50|$|The {{appropriate}} {{method of}} <b>annualization</b> {{depends on whether}} returns are reinvested or not.|$|E
5000|$|Oklahoma Office of Medicolegal Investigations - $1 million {{supplemental}} and $1.5 million <b>annualization</b> of supplemental for personnel, equipment, {{and infrastructure}} improvement ...|$|E
5000|$|<b>Annualization</b> of the Federal Medical Assistance Percentages change {{associated}} with premium costs for Medicare Parts A and B and the Medicare Prescription Drug Phased-down State Contribution ...|$|E
5000|$|... $59 {{million for}} {{maintenance}} and <b>annualizations</b> in the Oklahoma Health Care Authority ...|$|R
5000|$|<b>Annualizations</b> - $67 million {{increase}} in base agency budgets to replace one-time funding ...|$|R
50|$|The {{information}} {{ratio is}} often annualized. While {{it is then}} common for the numerator to be calculated as the arithmetic difference between the annualized portfolio return and the annualized benchmark return, this is an approximation because the <b>annualization</b> of an arithmetic difference between terms is not the arithmetic difference of the annualized terms. Since the denominator is here taken to be the annualized standard deviation of the arithmetic difference of these series, which is a standard measure of annualized risk, and since the ratio of annualized terms is the <b>annualization</b> of their ratio, the annualized information ratio provides the annualized risk-adjusted active return of the portfolio relative to the benchmark.|$|E
5000|$|After making Aliyah and {{arriving}} to Ottoman Jerusalem, in 1824 the rabbi {{was sent to}} Constantinopole {{by the head of}} Perushim of Jerusalem, and succeeded in procuring a royal firman, commanding the kadi of Jerusalem to enforce the declaration of debt <b>annualization</b> concerning the Ashkenazi Jewish community of Jerusalem.|$|E
50|$|Any {{confusion}} over {{the meaning of}} the term return or rate of return should be avoided. The return calculated by these methods is the return per dollar (or per some other unit of currency), not per year (or other unit of time). <b>Annualization,</b> which means conversion to an annual rate of return, is a separate process. Refer to the article rate of return.|$|E
40|$|The {{cost-effectiveness}} {{of carbon}} sequestration alternatives {{has often been}} discussed in the economics literature on sequestration. Average or marginal costs and annual carbon supply curves are often used as measures of cost-effectiveness. Sequestration is inherently a temporal process and how time is accounted for in the various measures of cost-effectiveness is critical for appropriate cross-study comparisons. I examine three factors that affect the magnitude of measured cost-effectiveness: the study period, the sequestration path, and the discount rate if discounting is used. The {{extent to which these}} factors affect the consistency of cross-study comparisons is empirically illustrated. <b>annualization,</b> carbon sequestration, the study period. ...|$|E
40|$|A {{review of}} the {{research}} accomplished in 2009 in the System-Level Design, Analysis and Simulation Tools (SLDAST) of the NASA's Airspace Systems Program is presented. This research thrust focuses on the integrated system-level assessment of component level innovations, concepts and technologies of the Next Generation Air Traffic System (NextGen) under research in the ASP program to enable the development of revolutionary improvements and modernization of the National Airspace System. The review includes the accomplishments on baseline research and the advancements on design studies and system-level assessment, including the cluster analysis as an <b>annualization</b> standard of the air traffic in the U. S. National Airspace, and the ACES-Air MIDAS integration for human-in-the-loop analyzes within the NAS air traffic simulation...|$|E
40|$|The first {{systematic}} {{analysis of the}} skew-normal distribution in a scalar case is done by Azzalini (1985). Unlike most of the skewed distributions, the skew-normal distribution allows continuity of the passage from the normal distribution to the skew-normal distribution and is mathematically tractable. The skew-normal distribution and its extensions have been applied in lots of financial applications. This thesis contributes to the recent development of the skew-normal distribution by, firstly, analyzing the the properties of <b>annualization</b> and time-scaling of the skew-normal distribution under heteroskedasticity which, in turn allows us to model financial time series with the skew-normal distribution at different time scales; and, secondly, extending the Skew-Normal-GARCH(1, 1) model of Arellano-Valle and Azzalini (2008) to allow for time-varying skewness. Chapter one analyses {{the performance of the}} time scaling rules for computing volatility and skewness under the Skew-Normal-GARCH(1, 1) model at multiple horizons by simulation and applies the simulation results to the Skew-Normal-Black-Scholes option pricing model introduced by Corns and Satchell (2007). Chapter two tests the Skew-Normal Black-Scholes model empirically. Chapter three extends the Skew-Normal-GARCH(1, 1) model to allow for time-varying skewness. The time-varying-skewness adjusted model is then applied to test the relationship between heterogeneous beliefs, shortsale restrictions and market declines...|$|E
40|$|This paper {{draws on}} {{critical}} political economic theory {{to discuss the}} implications of the dominant mode of production and circulation of "Triple-A" or blockbuster console games. It is argued that the seventh generation Triple-A game is a highly standardized cultural commodity giving way to two distinctive "formatting strategies", which taken together, draw attention to the console game’s hybrid nature; being a physical, disc-based artefact that is digitally extended via DLC (downloadable content). This hybridity invites questions as to the commodity form's techno-economic particularities vis-à-vis publishing strategies of non-software based cultural commodities, such as movies and TV series. The popular Call of Duty series of first person shooters serves as case study to demonstrate how game publisher Activision Blizzard not only formalized and institutionalized the <b>annualization</b> of the serialization strategy, the publisher also upped the ante in terms of post-launch content, theorized as "branched serialization". The Call of Duty series demonstrates that the rules of play for Triple-A games are as much governed by a game's internal ludic properties as they are structured and alternated by a distinctive and very explicit market logic. In this sense, the Triple-A game never seems truly finished; it is marketed by game publishers and positioned by critics as an unfinished commodity...|$|E
40|$|Reconstruction after natural {{disasters}} can represent large peaks in a community’s {{greenhouse gas emission}} inventory. Components of the built environment destroyed by natural hazards have their useful life shortened, requiring replacement before functionally necessary. Though the hazard itself does not release greenhouse gasses, the demolition and rebuilding process does, {{and these are the}} emissions we can quantify to better understand the climate impacts of disasters. The proposed methodology draws data from existing emission and hazard resource literature and combines the information in a community scale life cycle assessment. Case studies of past disasters are used to refine the methodology and quantify the emissions of single events. The methodology is then annualized projecting the emissions of future hazards. The <b>annualization</b> of greenhouse gasses caused by hazard events provides a baseline from which reduction strategies can be measured against. Hazard mitigation strategies can then be quantified as greenhouse gas reduction strategies for use in Climate Action Plans. The methodology combines the fields of climate action, hazard mitigation, and climate adaptation. Each field attempts to create sustainable and resilient communities, but most plans silo each discipline, missing opportunities that are mutually beneficial. Quantifying the greenhouse gasses associated with recovery following a disaster blends these fields to allow development of comprehensive resilience and sustainability strategies that lower greenhouse gases and decrease risk from existing or projected hazards. An online supplement to this thesis is available online at disasterghg. wordpress. co...|$|E
40|$|The {{problem at}} hand is to {{investigate}} the near-term commercial feasibility {{of a wide range}} of automotive emission control technologies. The central issues can best be explained in terms of the emission control characteristics of each technology and their costs. Governmentally established emission control standards may be viewed as constraints on the use of a given vehicle and engine design. Either the technology meets the standard in use or it will not be sold. Emission control technologies that show promise of near-term manufacturability will be identified. Then, without presuming what future emission standards will be, the emission characteristics of example vehicle-engine combinations will be listed. Technologies that are acceptable, given a specified emission standard, can then be identified by a process of elimination. The approach to identifying the relevant costs associated with a given technology is not as clear cut. One would like to think that the most basic question governing the adoption of a given feasible technology is, "Will it be purchased by the public?" The second part of this paper will discuss the impact of pollution control technology on the economic decisions facing the new car customer. The cost considered by the rational new car consumer involves more than first cost. Other important factors include maintenance, operating expenses, resale value, and financing charges. Since resale value and financing charges are highly time dependent, it is possible that a new car purchaser's decision on which technology to buy may depend on how long he plans to keep the car. A cost <b>annualization</b> procedure will thus be developed which considers these factors...|$|E
40|$|This study {{compared}} the effects produced by two different molar distalizers, namely cervical headgear (CHG) and the intraoral pendulum appliance, associated with fixed orthodontic appliances. The headgear group comprised 30 patients (19 females, 11 males), {{with an initial}} age of 13. 07 years [standard deviation (SD) = 1. 3], treated with CHG and fixed orthodontic appliances for a mean period of 3. 28 years, and the pendulum group 22 patients (15 females, 7 males), with initial age of 13. 75 years (SD = 1. 86), treated with the pendulum appliance followed by fixed orthodontic appliances for a mean period of 4. 12 years. Lateral cephalograms were taken at the start (T 1) and on completion (T 2) of orthodontic treatment. The pendulum and CHG groups were similar as to initial age, severity of the Class II malocclusion, gender distribution, initial cephalometric characteristics, and initial and final treatment priority index (TPI). Only treatment time was not similar between the groups, with a need for <b>annualization</b> for data for the pendulum group. The data were compared with independent t-tests. There was significantly greater restriction of maxillary forward growth and improvement of the skeletal maxillomandibular relationship in the CHG group (P < 0. 05). The maxillary molars were more mesially tipped and extruded and the mandibular molars more uprighted in the CHG group compared with the pendulum group (P < 0. 05). There was more labial tipping of the mandibular incisors and greater overbite reduction in the pendulum group. The pendulum appliance produced only dentoalveolar effects, different from the CHG appliance, which restricted maxillary forward displacement, thus improving the skeletal maxillomandibular relationship. CNPq Conselho Nacional de Desenvolvimento Cientifico e Tecnologic...|$|E

