20|10000|Public
50|$|He {{currently}} (2011) is {{a thesis}} advisor for {{graduate students in}} the Berkeley Vision Processing Laboratory. He has over 190 published articles in the <b>area</b> <b>of</b> <b>vision</b> perception.|$|E
5000|$|It is {{estimated}} that this much less common form of retinoschisis affects one in 5,000 to 25,000 individuals, primarily young males. Schisis {{is derived from the}} Greek word meaning splitting, describing the splitting of the retinal layers from each other. However, schisis is a word fragment, and the term retinoschisis should be used, as should the term iridoschisis when describing splitting of the iris. If the retinoschisis involves the macula, then the high-resolution central <b>area</b> <b>of</b> <b>vision</b> used to view detail is lost, and this one form of macular disease. Although it might be described by some as a [...] "degeneration", the term macular degeneration should be reserved for the specific disease [...] "age-related macular degeneration".|$|E
40|$|This paper {{surveys the}} {{developments}} of the last 20 years in the <b>area</b> <b>of</b> <b>vision</b> for mobile robot navigation. Two major components of the paper deal with indoor navigation and outdoor navigation. For each component, we have further subdivided our treatment of the subject {{on the basis of}} structured and unstructured environments. For indoor robots in structured environments, we have dealt separately with the cases of geometrical and topological models of space. For unstructured environments, we have discussed the cases of navigation using optical flows, using methods from the appearance-based paradigm, and by recognition of specific objects in the environment...|$|E
50|$|The College <b>of</b> Optometrists in <b>Vision</b> Development (COVD) awards {{the yearly}} Skeffington Award in his honor, {{to be awarded}} to an {{individual}} who has made outstanding contributions to optometric literature in the <b>areas</b> <b>of</b> <b>vision</b> therapy and vision development.|$|R
50|$|It is also {{possible}} to construct and install an artificial organ to give its possessor abilities which are not naturally occurring. Research is proceeding in <b>areas</b> <b>of</b> <b>vision,</b> memory, and information processing. Some current research focuses on restoring short-term memory in accident victims and long-term memory in dementia patients.|$|R
5000|$|Distorted {{vision in}} the form of metamorphopsia, in which a grid of {{straight}} lines appears wavy and parts of the grid may appear blank: Patients often first notice this when looking at things like miniblinds in their home or telephone poles while driving. There may also be central scotomas, shadows or missing <b>areas</b> <b>of</b> <b>vision</b> ...|$|R
40|$|Abstract—This paper {{surveys the}} {{developments}} of the last 20 years in the <b>area</b> <b>of</b> <b>vision</b> for mobile robot navigation. Two major components of the paper deal with indoor navigation and outdoor navigation. For each component, we have further subdivided our treatment of the subject {{on the basis of}} structured and unstructured environments. For indoor robots in structured environments, we have dealt separately with the cases of geometrical and topological models of space. For unstructured environments, we have discussed the cases of navigation using optical flows, using methods from the appearance-based paradigm, and by recognition of specific objects in the environment. Index Terms—Mobile robotics, navigation, computer vision, indoor navigation, outdoor navigation...|$|E
40|$|For long time, it {{was thought}} that sensing of {{polarization}} in animals is invariably related to their behavior like navigation and orientation. Recently, it was found that polarization can be part of a high-level visual perception, permitting a wide <b>area</b> <b>of</b> <b>vision</b> applications. Polarization vision can be used for most tasks of color vision like: object recognition, contrast enhancement, camouflage breaking, and signal detection and discrimination. The polarization based visual behavior in the animal kingdom will be briefly covered. Then, we will go in depth with the bio-inspired applications based on polarization in computer vision and robotics. The aim is to have a comprehensive survey highlighting the key principles of polarization based techniques and how they are biologically inspired...|$|E
40|$|The {{ability to}} {{autonomously}} acquire new knowledge through {{interaction with the}} environment is an important research topic {{in the field of}} robotics. The knowledge can be acquired only if suitable perception-action capabilities are present: a robotic system {{has to be able to}} detect, attend to and manipulate objects in its surrounding. In this paper, we present the results of our longterm work in the <b>area</b> <b>of</b> <b>vision</b> based sensing and control. The work on finding, attending, recognizing and manipulating objects in domestic environments is studied. We present a stereo based vision system framework where aspects of Top-down and Bottom-up attention as well as foveated attention are put into focus and demonstrate how the system can be utilized for robotic object grasping. ...|$|E
5000|$|... (H53.1, H53.4) Scotoma (blind spot) — an <b>area</b> {{impairment}} <b>of</b> <b>vision</b> {{surrounded by}} a field <b>of</b> relatively well-preserved <b>vision.</b> See also Anopsia.|$|R
5000|$|Active <b>vision</b> - an <b>area</b> <b>of</b> {{computer}} <b>vision</b> {{and machine}} learning concerned with active sampling of sensory data ...|$|R
5000|$|The main <b>areas</b> <b>of</b> {{emphasis}} <b>of</b> <b>Vision</b> 2020 {{fall into}} the following areas: ...|$|R
40|$|This paper {{surveys the}} {{developments}} of last 10 {{years in the}} <b>area</b> <b>of</b> <b>vision</b> based target tracking for autonomous vehicles navigation. First, the motivations and applications of using vision based target tracking for autonomous vehicles navigation are presented in the introduction section. It can be concluded {{that it is very}} necessary to develop robust visual target tracking based navigation algorithms for the broad applications of autonomous vehicles. Then this paper reviews the recent techniques in three different categories: vision based target tracking for the applications of land, underwater and aerial vehicles navigation. Next, the increasing trends of using data fusion for visual target tracking based autonomous vehicles navigation are discussed. Through data fusion the tracking performance is improved and becomes more robust. Based on the review, the remaining research challenges are summarized and future research directions are investigated...|$|E
40|$|Historically, {{architecture}} has {{a wealth}} of visualisation techniques that have evolved throughout the period of structural design, with Virtual Reality (VR) being a relatively recent addition to the toolbox. To date the effectiveness of VR has been demonstrated from conceptualisation through to final stages and maintenance, however, its full potential {{has yet to be}} realised (Bouchlaghem et al, 2005). According to Dewey (1934), perceptual integration was predicted to be transformational; as the observer would be able to ‘engage’ with the virtual environment. However, environmental representations are predominately focused on the <b>area</b> <b>of</b> <b>vision,</b> regardless of evidence stating that the experience is multi sensory. In addition, there is a marked lack of research exploring the complex interaction of environmental design and the user, such as the role of attention or conceptual interpretation. This paper identifies the potential of VR models to aid communication for the Built Environment with specific reference to human perception issues...|$|E
40|$|This {{tutorial}} aims {{to present}} a survey of recent as well as traditional object recognition/classification methods based on image moments. We review various types of moments (geometric moments, complex moments, Legendre moments, Zernike and Pseudo-Zernike moments, and Fourier-Mellin moments) and moment-based invariants with respect to various image degradations and distortions (rotation, scaling, affine transform, image blurring, etc.) {{which can be used}} as shape features for classification. We explain a general theory how to construct these invariants and show also a few of them in explicit forms. We review efficient numerical algorithms {{that can be used for}} moment computation. Finally, we demonstrate practical examples of using moment invariants in real applications from the <b>area</b> <b>of</b> <b>vision,</b> remote sensing, and medical imaging. The target audience of the tutorial are • researchers from all application areas who need to recognize 2 -D objects extracted from binary/graylevel/color images and who look for invariant and robust object features, • specialists in moment-based pattern recognition interested in new development on this field...|$|E
50|$|Common {{problems}} of the visual field include scotoma (<b>area</b> <b>of</b> reduced <b>vision),</b> hemianopia (half <b>of</b> visual field lost), homonymous hemianopsia and bitemporal hemianopia.|$|R
40|$|In most <b>areas</b> <b>of</b> <b>vision</b> science, {{liquid crystal}} {{displays}} (LCDs) have widely replaced the long dominating {{cathode ray tube}} (CRT) technology. In recent years, however, LCD panels have been repeatedly analyzed and their use been criticized with reference to vision science applications. We measured and analyzed the photometric output of eleven contemporary LCD monitors. Our {{results show that the}} specifications given by the manufacturers are partially misleading and mostly insufficient for appropriate display selection for many vision science related tasks. In recent years, novel display technologies have been introduced to improve fast luminance transitions or to optimize the appearance of moving objects. While we found that the luminance transition times of modern LCD monitors are considerably faster than those of earlier LCD generations, these novel technologies may be accompanied by side effects relevant to vision research. Furthermore, we demonstrate a number of intriguing technical deficiencies which may severely impair visual experiments. Several undesired und uncontrolled components of the photometric output as well as unreliable onsets and offsets of visual stimuli require ample measurements prior to applications in all <b>areas</b> <b>of</b> <b>vision</b> science where either precise timing or the knowledge of the exact shape of the photometric output signal matters...|$|R
50|$|Essa's work focuses {{mainly in}} the <b>areas</b> <b>of</b> Computer <b>Vision,</b> Computational Photography, Computer Graphics and Animation, Robotics, Computational Perception, Human-Computer Interaction, Machine Learning, Computational Journalism and Artificial Intelligence.|$|R
40|$|A {{survey of}} {{research}} in the <b>area</b> <b>of</b> <b>vision</b> sensor planning is presented. The problem can be summarized as follows: given information about the environment as well as information about the task that the vision system is to accomplish, develop strategies to automatically determine sensor parameter values that achieve this task with a certain degree of satisfaction. With such strategies, sensor parameters values can be selected and can be purposefully changed in order to effectively perform the task at hand. The focus here is on vision sensor planning for the task of robustly detecting object features. For this task, camera and illumination parameters such as position, orientation, and optical settings are determined so that object features are, for example, visible, in focus, within the sensor field of view, magnified as required, and imaged with sufficient contrast. References to, and a brief description of, representative sensing strategies for the tasks of object recognition and scene reconstruction are also presented. For these tasks, sensor configurations are sought that will prove most useful when trying to identify an object or reconstruct a scene...|$|E
40|$|As I sat {{reading the}} {{invitation}} to write this editorial, the ABC radio news was playing {{in the background and}} it was announced that Bob Dylan had just been awarded the 2016 Nobel Prize for literature. I remember a more progressive English teacher at high school in the 1970 s basing her classes around Dylan’s song lyrics. She would be thrilled by Dylan’s prize but to me as an adolescent it all seemed as impenetrable as the plays of Shakespeare that we studied. My attitude to high school science was not much different (I wasn’t much of a student); however, I came to appreciate Dylan and science some years later. There is some good science in this issue of the Clinical and Experimental Optometry, which contains papers ranging across topics of ocular biometry, accommodation and multifocal contact lens optics. All of these topics directly or indirectly relate to the <b>area</b> <b>of</b> <b>vision</b> science that I ﬁnd most intriguing, namely, why do eyes develop refractive errors and {{what can we do about}} it [...] ...|$|E
40|$|Vision therapy, {{like any}} {{area in a}} health profession, is practiced {{differently}} by various clinicians. I will restrict this discussion to the most commonly practiced and largest portion of the <b>area</b> <b>of</b> <b>vision</b> therapy: treatment of accommodative and vergence anomalies, including strabismus. These categories include the majority of patients treated by optometrists providing vision therapy service. In addition, all schools of optometry include {{diagnosis and treatment of}} anomalies of accommodation and vergence in their curricula. Negative feedback control theory analysis of the accommodative and vergence systems provides the basis of today’s optometric vision therapy. These models have a strong physiological and anatomical basis, and have been described in numerous articles 1 - 4 and textbooks. 5 - 7 Computer simulations using control theory demonstrates the predictability of both the accommodative and vergence systems. 1, 2, 5 Defects in any component of the system may result in asthenopia, diplopia, and/or strabismus. 8 The most common cause of asthenopia is related to inadequate slow vergence. 4, 9 Vision therapy differs from orthoptic models in that control theory analysis acknowledges the dynamic interaction o...|$|E
6000|$|How strange it looked! How vastly {{different}} from the flat and puny <b>area</b> <b>of</b> the circumscribed <b>vision</b> <b>of</b> the dweller upon the outer crust! ...|$|R
40|$|In Canada, the West Vancouver School Board {{proposed}} 13 propositions {{about the}} selection, management, and {{effective use of}} information technology. For each proposition, the senior management included a full outline of the current status, a plan of action, {{the name of the}} staff member responsible, and a time line. An external assessment of implementation of each proposition and of the impact on achievement was undertaken. The propositions, clustered in the <b>areas</b> <b>of</b> <b>vision,</b> statement <b>of</b> beliefs, student learning goals, definition, social issues, learning issues, clarification of roles and responsibilities, integration of information delivery systems, community-based information infrastructure, and assessment, are discussed...|$|R
50|$|An <b>area</b> <b>of</b> {{computer}} <b>vision</b> {{is active}} vision, sometimes also called active computer vision. An active vision system {{is one that}} can manipulate the viewpoint of the camera(s) in order to investigate the environment and get better information from it.|$|R
40|$|Abstract � This paper {{describes}} the Metrovisionlab computer application implemented as a toolbox for the Matlab program. It {{is designed for}} learning the key aspects of camera calibration techniques in dimensional metrology applications such as laser triangulation sensors and photogrammetry or stereovision systems. The software is used in several industrial vision courses for senior undergraduate mechanical engineering students. The application: 1) simulates a virtual camera, providing a simple and visual {{understanding of how the}} various characteristics of a camera influence the image that it captures; 2) generates the coordinates of synthetic calibration points, both in the world reference system and the image reference system, commonly used in camera calibration; and 3) can calibrate with the most important and widely-used methods in the <b>area</b> <b>of</b> <b>vision</b> cameras, using coplanar (2 D) or non-coplanar (3 D) calibration points. Thus, the main goal is to have a simulation tool that allows characterizing the accuracy, repeatability, error mechanisms and influences for different measurement conditions and camera calibration algorithms. on the parameters of the application. This means that the student can understand the effect of the various parameters of the camera on the obtained image intuitively...|$|E
40|$|Abstract: The {{prevalence}} {{of visual impairment}} and blindness increases dramatically with advancing age. The major diseases that cause visual impairment and blindness, specifi cally cataract, macular degeneration, and glaucoma, are age-related. The number of visually impaired Americans older than 40 years is projected to double by 2030. Half of all cases of blindness may be preventable. Research in the <b>area</b> <b>of</b> <b>vision</b> has developed into ophthalmologically defi ned silos that follow specifi c diseases or study subparts of the eye. To overcome the limitations of current subspecialty conceptualization of vision prob-lems, {{it is necessary to}} develop new models that can expand the current research paradigms in new directions. This review paper details literature within a conceptual model to explain the increases in visual impairment, the age and other demo-graphic disparities in prevalence, and the lack of vision screening, treatment, and rehabilitation. At the core of the conceptual framework are the twin phenomena of vision health as perceived by the individual and vision health as clinically-measured. Other domains of the framework include adaptation, vision demands, quality of life, and cues to using vision services suc...|$|E
40|$|Abstract — The {{computer}} is an ubiquitous element of modern society, nonetheless, human computer interaction is still rather inflexible. Particularly in local collaborative environments, like office meetings, the property that the mouse and keyboard exhibit {{of being a}} gateway for the individual to act upon a workspace, has barred {{the way to the}} production of co-located collaboration technologies, because the users have to time-share their actions upon the workspace. Despite recent developments in touch sensitive multi-user tabletops, we still believe the portability, low cost and potentially large input <b>area</b> <b>of</b> <b>vision</b> sensors presents the most promising approach to unravel natural human computer interfaces. We present in this paper our design of a computationally inexpensive vision based interface that allows multiple users to interact simultaneously with a single computer by performing hand gestures, which are filmed by a static video camera. This interface attempts to continuously recognize predefined postures and movements using a view-dependent method. We also present A. C. O, a co-located groupware application that receives input from the vision-based interface and allows users around a table to collaborate playing synthesized music instruments by moving their hands. This prototype gave us important hints on the more immediate obstacles the technology must overcome. Index Terms — co-located groupware, human computer interface, gesture recognition, computer vision I...|$|E
40|$|The {{purpose of}} this study was to examine the best {{practices}} of high school principals for improving student achievement in eight urban high schools in the Metro Atlanta area. Specifically, the best practices of urban Georgia high school principals in the <b>areas</b> <b>of</b> <b>vision,</b> risk-taking, human development, belief in others and integrity were explored through an interview process. Each participant was asked five open-ended questions since these allow for participants to answer questions in a more complete manner. The qualitative, phenomenological research design was employed. Qualitative analysis was used to determine recurring themes related to the research questions. The recurring emerging themes from the data collectio...|$|R
40|$|AbstractThe {{new global}} Euro-Mediterranean {{partnership}} aims to develop human resources and promote {{understanding between cultures}} and set up exchanges between civil societies. In this context, learning is a strategic lever to achieve these objectives whenever {{there are questions about}} methodology and processing systems within the Euro-Mediterranean area. It is thus important that the teachers operating in this area can possess and develop a specific set of strategic and shared visions and skills guided by these values. These skills and values are the subject of this study involving 100 teachers who work in these contexts. The results allow to highlight <b>areas</b> <b>of</b> <b>vision</b> and strategic skills necessary for teachers in Euro-Mediterranean context. © 2010 Published by Elsevier Ltd...|$|R
40|$|This paper proposes and {{illustrates}} a general framework {{to integrate the}} <b>areas</b> <b>of</b> <b>vision</b> research and complex networks. Each image pixel is associated to a network node and the Euclidean distance between the visual properties (e. g. gray-level intensity, color or texture) at each possible pair of pixels is assigned as the respective edge weight. In addition to investigating the therefore obtained weight and adjacency matrices in terms of node degree densities, it is shown {{that the combination of}} the concepts of network hub and 2 -expansion of the adjacency matrix provides an effective means to separate the image elements, a challenging task in computer vision known as segmentation. Comment: 6 pages, 5 figure...|$|R
40|$|Today, {{security}} cameras used in stores and buildings {{have a limited}} <b>area</b> <b>of</b> <b>vision.</b> Multiple cameras are needed if a larger area is to be covered. With the technique described in this paper, {{it is possible to}} get a 360 -degree panoramic vision by using a spherical mirror placed vertically with respect to a camera. First, image reflected from a spherical mirror is captured with a regular camera and then it is transformed into Cartesian coordinates to produce four separate views of the area in north, south, east, and west directions. Since it is possible to get the full vision of an area using only one camera with this technique, it can provide significant cost savings in building security systems. It can also be used in systems that require rotation of a camera to see different directions, such as the periscopes used in submarines. In this paper, we first describe the software and hardware needed to build such a vision system. In addition, we explain different techniques that are developed to minimize the distortion and hence improve the accuracy of the transformed images. Software and hardware techniques to increase the processing speed for video images and to produce enough number of frames per second for real-time processing are also explained in the paper. 1...|$|E
40|$|The {{computer}} is an ubiquitous element of modern society, nonetheless, human computer interaction is still rather inflexible. Particularly in local collaborative environments, like office meetings, the property that the mouse and keyboard exhibit {{of being a}} gateway for the individual to act upon a workspace, has barred {{the way to the}} production of co-located collaboration technologies, because the users have to time-share their actions upon the workspace. Despite recent developments in touch sensitive multi-user tabletops, we still believe the portability, low cost and potentially large input <b>area</b> <b>of</b> <b>vision</b> sensors presents the most promising approach to unravel natural human computer interfaces. We present in this paper our design of a computationally inexpensive vision based interface that allows multiple users to interact simultaneously with a single computer by performing hand gestures, which are filmed by a static video camera. This interface attempts to continuously recognize predefined postures and movements using a view-dependent method. We also present A. C. O, a co-located groupware application that receives input from the vision-based interface and allows users around a table to collaborate playing synthesized music instruments by moving their hands. This prototype gave us important hints on the more immediate obstacles the technology must overcome. </p...|$|E
40|$|The {{prevalence}} {{of visual impairment}} and blindness increases dramatically with advancing age. The major diseases that cause visual impairment and blindness, specifically cataract, macular degeneration, and glaucoma, are age-related. The number of visually impaired Americans older than 40 years is projected to double by 2030. Half of all cases of blindness may be preventable. Research in the <b>area</b> <b>of</b> <b>vision</b> has developed into ophthalmologically defined silos that follow specific diseases or study subparts of the eye. To overcome the limitations of current subspecialty conceptualization of vision problems, {{it is necessary to}} develop new models that can expand the current research paradigms in new directions. This review paper details literature within a conceptual model to explain the increases in visual impairment, the age and other demo- graphic disparities in prevalence, and the lack of vision screening, treatment, and rehabilitation. At the core of the conceptual framework are the twin phenomena of vision health as perceived by the individual and vision health as clinically-measured. Other domains of the framework include adaptation, vision demands, quality of life, and cues to using vision services such as access to care and social support. The framework incorporates multiple demographic, behavioral, and social factors that influence the vision health of individuals and communities. Areas of future research include population-based study of the knowledge, attitudes, and practices regarding vision health among both individuals and providers and multi-pronged interventions aimed at the individual, provider, organizational, and community levels to improve visual function...|$|E
25|$|Complex eyes can {{distinguish}} shapes and colours. The visual fields of many organisms, especially predators, involve large <b>areas</b> <b>of</b> binocular <b>vision</b> to improve depth perception. In other organisms, eyes are located {{so as to}} maximise the field of view, such as in rabbits and horses, which have monocular vision.|$|R
40|$|Abstract:- Natural images {{recognition}} {{is an important}} <b>area</b> <b>of</b> machine <b>vision.</b> This paper presents a novel approach for natural images recognition, based on the non-Gaussian distribution property of natural images. In this new method for recognition, first supervised classification is conducted to the natural images based on thei...|$|R
5000|$|Fei-Fei Li (born 1976), who publishes {{under the}} name Li Fei-Fei（), is an Associate Professor of Computer Science at Stanford University. She is the {{director}} of the Stanford Artificial Intelligence Lab (SAIL) [...] and the Stanford Vision Lab. She works in the <b>areas</b> <b>of</b> computer <b>vision</b> and cognitive neuroscience.|$|R
