4|9|Public
40|$|Circuit enhances {{vertical}} resolution in electron beam, raster scanning systems exhibiting <b>aperture</b> <b>distortion</b> in the vertical direction. A sensitized area /image/ produces a video output when the scan beam nears it, which causes vertical elongation in the reconstructed images of all sensitized {{areas on the}} surface...|$|E
40|$|Background {{subtraction}} is an extensively used {{approach to}} localize the moving object {{in a video}} sequence. However, detecting an object under the spatiotemporal behavior of background such as rippling of water, moving curtain and illumination change or low resolution is not a straightforward task. To deal with the above-mentioned problem, we address a background maintenance scheme based on the updating of background pixels by estimating the current spatial variance along the temporal line. The work is focused to immune the variation of local motion in the background. Finally, the most suitable label assignment to the motion field is estimated and optimized by using iterated conditional mode (ICM) under a Markovian framework. Performance evaluation and comparisons with the other well-known background subtraction methods show that the proposed method is unaffected by the problem of <b>aperture</b> <b>distortion,</b> ghost image, and high frequency noise...|$|E
40|$|Adaptive phased-array antennas provide {{cost-effective}} {{implementation of}} large, light weight apertures with high directivity and precise beamshape control. Adaptive self-calibration allows for relaxation of all mechanical tolerances across the aperture and electrical component tolerances, providing high performance with a low-cost, lightweight array, {{even in the}} presence of large physical distortions. Beam-shape is programmable and adaptable to changes in technical and operational requirements. Adaptive digital beam-forming eliminates uplink contention by allowing a single electronically steerable antenna to service a large number of receivers with beams which adaptively focus on one source while eliminating interference from others. A large, adaptively calibrated and fully programmable aperture can also provide precise beam shape control for power-efficient direct broadcast from space. Advanced adaptive digital beamforming technologies are described for: (1) electronic compensation of <b>aperture</b> <b>distortion,</b> (2) multiple receiver adaptive space-time processing, and (3) downlink beam-shape control. Cost considerations for space-based array applications are also discussed...|$|E
50|$|The lens is {{exceptionally}} sharp {{throughout its}} zoom range, {{with only a}} slight fall-off in acuity toward {{the edges of the}} frame at faster <b>apertures.</b> <b>Distortion,</b> vignetting, and chromatic aberration are all well controlled.|$|R
5000|$|In {{reviewing}} the lens, British photographer and blogger Keith Cooper concluded that"At appreciably less cost than the EF-S 10-22, the 10-18mm surprised me with its build quality and optical performance. The image stabilisation adds to its general purpose usefulness and partly {{makes up for}} its relatively restricted <b>aperture....</b> <b>Distortions</b> are well under control, and when suitable correction profiles arrive, the lens {{will be more than}} adequate for serious use if you were looking to photograph property for example..." ...|$|R
50|$|The lens is {{exceptionally}} sharp {{throughout its}} zoom range at its maximum <b>aperture</b> of f/2.8. <b>Distortion,</b> vignetting, and chromatic aberration are all well controlled.|$|R
40|$|Research and {{development}} on smart antennas, which {{are recognized as}} a promising technique to improve the performance of mobile communications, have been extensive in the recent years. Smart antennas combine multiple antenna elements with a signal processing capability in both space and time to optimize its radiation and reception pattern automatically {{in response to the}} signal environment. This paper concentrates on the signal processing aspects of smart antenna systems. Smart antennas are often classified as either switched-beam or adaptive-array systems, for which a variety of algorithms have been developed to enhance the signal of interest and reject the interference. The antenna systems need to differentiate the desired signal from the interference, and normally requires either a priori knowledge or the signal direction to achieve its goal. There exists a variety of methods for direction of arrival (DOA) estimation with conflicting demands of accuracy and computation. Similarly, there are many algorithms to compute array weights to direct the maximum radiation of the array pattern toward the signal and place nulls toward the interference, each with its convergence property and computational complexity. This paper discusses some of the typical algorithms for DOA estimation and beamforming. The concept and details of each algorithm are provided. Smart antennas can significantly help in improving the performance of communication systems by increasing channel capacity and spectrum efficiency, extending range coverage, multiplexing channels with spatial division multiple access (SDMA), and compensating electronically for <b>aperture</b> <b>distortion.</b> They also reduce delay spread, multipath fading, co-channel interference, system complexity, bit error rates, and outage probability. In addition, smart antennas can locate mobile units or assist the location determination through DOA and range estimation. This capability can support and benefit many location-based services including emergency assistance, tracking services, safety services, billing services, and information services such as navigation, weather, traffic, and directory assistance...|$|E
40|$|In May 93 the {{operation}} of DORIS for high energy physics was discontinued and the ring became a dedicated source for synchrotron radiation operated at 4. 5 GeV. Meanwhile a multibunch feedback system to control beam instabilities had been installed and positrons were stored instead of electrons. The resulting improvements and also the present status are described by discussing some important parameters and their limitations. These parameters include the beam lifetime, the maximum stored currents, the number of bunches, the beam dimensions and <b>aperture,</b> orbit <b>distortions,</b> position control of the photon beams, the reliability {{and the influence of}} the 10 insertion devices on the stored beam. INTRODUCTION DORIS has been in operation for high energy physics and synchrotron radiation (SR) since 1974. During this period it was rebuilt several times, the last time in 1991. The new ring is called DORIS III and has been described elsewhere. [1] In 1993 it became a dedicated source for SR which n [...] ...|$|R
40|$|In {{this paper}} {{we report on}} {{theoretical}} results and practical experiments for depth recovery from static scenes using active camera devices. Range estimation from linear and rotational camera motion and zoom purposive variation are discussed. Qualitative as well as quantitative depth estimation techniques are applied. Feature tracking in color images is used to estimate distances. Since focus, zoom, <b>aperture,</b> and lens <b>distortion</b> are not independent, and no calibration is desired here, the major goal is simple qualitative depth estimation. In the experiments we use a cost surveillance camera Canon VC [...] C 1 for which we show that depth can be estimated from zoom variation in a limited range. 1 Introduction In the last decade, computer vision research concentrated mainly on the analysis of static images or recorded image sequences. Each image was analyzed as good as possible generating a symbolic description; this is quoted as the so called "Marr paradigm" [15]. The new idea of "active visi [...] ...|$|R
40|$|Non-paraxial {{theories}} of wave propagation {{are essential to}} model the interaction of highly focused light with matter. Here we investigate the energy, momentum and propagation of the Laguerre–, Hermite– and Ince–Gaussian solutions (LG, HG, and IG) of the paraxial wave equation in an apertured non-paraxial regime. We investigate the far-field relationships between the LG, HG, and IG solutions and the vector spherical wave function (VSWF) solutions of the vector Helmholtz wave equation. We investigate the convergence of the VSWF and the various Gaussian solutions {{in the presence of}} an aperture. Finally, we investigate the differences in linear and angular momentum evaluated in the paraxial and non-paraxial regimes. The non-paraxial model we develop can be applied to calculations of the focusing of high-order Gaussian modes in high-resolution microscopes. We find that the addition of an aperture in high numerical aperture optical systems does not greatly affect far-field properties except when the beam is significantly clipped by an aperture. Diffraction from <b>apertures</b> causes large <b>distortions</b> in the near-field and will influence light–matter interactions. The method is not limited to a particular solution of the paraxial wave equation. Our model is constructed in a formalism that is commonly used in scattering calculations. It is thus applicable to optical trapping and other optical investigations of matter...|$|R
40|$|Electron {{diffraction}} from {{thin films}} can be {{recorded in the}} TEM with either convergent beam (CBED) or parallel beam (SAED, NBD) illumination. Although CBED carries {{a wealth of information}} from single crystalline regions, parallel illumination is preferred for the structure examination of either nanocrystalline (nc) or amorphous thin films. Both the sharp rings in the former case and the diffuse rings in the latter case can be quantitatively analysed with the ProcessDiffraction program, which is distributed free of charge [1]. Both the volume fractions and the possible preferred orientation of the nc phases can be quantified with this program [2 - 4]. The short range order for either nc or amorphous materials can be determined with that program [5 - 7 volt meg egy cikk ahol hasznaltam amorfra]. When Bragg reflections are analysed it gives the global structure, while the pair distribution function (PDF) provides the local structure. Differences between local and global structures are exemplified e. g. in [8]. Recently, a possibility was implemented in ProcessDiffraction to apply a “Mask”, i. e. to disregard pre-selected parts of the pattern from processing. In addition to eliminating the possible distortion in the ring-averages caused by the presence of “Beam-stop”, the Mask also facilitates separation of incoherently superposed components, like the sc?-spots originated from traces of the not-completely removed substrate when the ring pattern from the layer is to be analysed. The example in Fig.   1 shows the effect of masking, while Fig.   2 demonstrates the change in lattice parameter due to mutual solution of the two phase-components (AlN and TiN) in each other. Refinement of such lattice parameter changes is also included in the program. The talk will also include examples from determination of local structure through PDF-analysis. Special problems of calibration, scattered radiation when using selected area <b>aperture</b> and possible <b>distortions</b> of lenses as a function of lens settings are also discussed. These problems are more serious in PDF-analysis than in evaluation of Bragg-reflections...|$|R
40|$|The {{only way}} to measure the mass of star is by {{analyzing}} its orbit with Kepler’s laws. Knowing the luminosity of a star {{in addition to its}} mass is very useful in theoretical astrophysics. For single stars with known distances, it is straightforward to calculate the luminosity. For binary stars determining the luminosity is often difficult, as most techniques measure the blended light from both and not that of the individual components. Three methods for measuring the differential magnitudes of resolved binary stars are investigated: adaptive optics (AO), aperture masking and bispectrum analysis. Of the three techniques used here adaptive optics performed the best, producing differential magnitudes in Johnson I, R, V and B filters for 36 stars. The observational technique was to take many exposures of the same object in an effort to increase the signal-to-noise ratio. It was discovered that AO frames show frame-to-frame intensity variations. These inter-frame variations showed up in AO data from both the 1. 5 -m telescope at the Starfire Optical Range and the 100 -inch telescope at Mt. Wilson Observatory. These variations are most likely caused by the failure of the AO system to fully compensate for the atmospheric <b>distortions.</b> <b>Aperture</b> masking consists of dividing the telescope’s aperture into several subapertures. The light from each subaperture interferes and creates fringes. The brightness ratio of the binary can be determined from the resulting fringe pattern. The technique was hampered by the Intensified CCD (ICCD) detector used in these experiments and performed rather poorly, producing only one differential magnitude measurement. The main thrust of the bispectrum technique was to derive differential magnitudes from archival speckle data. The standard bispectrum technique is used to reconstruct images from speckle data, but it requires the observation of calibration stars, which are not needed in the standard speckle method. Instead, the method used here fits the phase of the bispectrum to a model binary star. This avoids having to use a calibrator star, because the phase of the bispectrum is not distorted by the atmosphere. Unfortunately this technique seems ill suited to ICCD speckle data, though it looks promising for photon-limited data...|$|R
40|$|The {{particles}} accelerated in CERN accelerator chain reach high energies, {{topped by}} the particle energy at collision in the LHC, 7 GeV. During the operation, {{an amount of}} particles is inevitably lost from the beam. Depending {{on the extent of}} the losses, physical damage to machine components may be caused and the shower of secondary emission particles deposits energy in the surrounding equipment constituting the accelerator. The hadronic cascade also activates their materials, representing a hazard to the workers at CERN. In the LHC, the superconducting magnets that constitute the synchrotron lattice are kept at an operating temperature of 1 : 9 K through a cryogenic facility employing superliquid helium, the increase in their temperature potentially initiates a quench. In the SPS, the damage due to a lost beam is also visible. The Beam Loss Monitoring (BLM) system has been developed to reliably protect the machines composing CERN’s accelerator chain and additionally provide information about the beam status: the system provides observations about local <b>aperture</b> restrictions, orbit <b>distortion,</b> beam oscillations and particle diffusion, allowing the operators to tune the machines, measure and maximize the efficiency of the chain. To achieve this, two types of particles detectors are distributed along the machines in the positions where the most intense losses are expected, typically where aperture limitations are present – for exa mple where the collimators are located. The main type of detector in use is the ionization chamber, albeit where a very high dose rate is expected Secondary Emission Monitor (SEM) are employed instead. Both types of detectors are sensitive to the hardronic showers initiated by high energy particles and they are characterized by high linearity and accuracy with respect to the energy lost by the particles, a fast responses and good radiation tolerance. Where timely machine protection is in place, for every detector location the fraction of particles from the hardronic showers has been linked to the energy distribution within the coil through simulation-based analysis and maximum allowable energy value has been established. The signal from the detector is acquired by the front-end electronics and, where applicable, the measurement is compared with the threshold relevant for the considered ring location. As the dimensions of the accelerators varies greatly, the signal might be acquired, digitized in the accelerator tunnel and then sent to the surface electronics to be processed – as it happens in the LHC – or the complete processing may occur in a shielded facility closely located. In the former case, radiation tolerant electronics is required. In the LHC, when a threshold is exceeded, the beam permit signal is revoked and the circulating particles are directed towards the dump line. In machines employing warm magnets – such as the PS Booster – the beam parameters are tuned before the next injection, to increase the quality of the beam. A discrete components design of a current digitizer based on the current-to-frequency converter (CFC) principle has been studied in this work. The design targets at rather high input current compared to similar acquisition systems, with a maximum equal to 100 mA and a minimum of 1 nA, as required by the ionization chamber that will be employed in the Proton Synchrotron and Booster accelerators {{as well as in the}} LINAC 4. It allows the integral acquisition of currents of both polarities without requiring any configuration and provides a digital number having an LSB equal to a reference charge complemented with an additional fractional count through an ADC, to increase the resolution. Several architectural choices we considered for the front-end circuit, including charge balance integrators, dual-integrator input stages, integrators with switchable-capacitor, in both synchronous and asynchronous versions. The signal is processed by an FPGA and transmitted over a VME 64 x bus...|$|R

