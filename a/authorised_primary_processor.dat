0|115|Public
5000|$|Justice Jagot {{inferred}} that iiNet was {{liable for}} <b>authorising</b> <b>primary</b> infringements. Justice Jagot established her conclusion on certain findings including that iiNet knew a considerable proportion of BitTorrent traffic involved copyright infringement. Her Honour held that: ...|$|R
50|$|To {{standardize}} thermal behavior, processor {{position is}} defined, including <b>primary</b> and secondary <b>processor</b> identification. For motherboards {{with only one}} processor installed, it is recommended the <b>primary</b> <b>processor</b> socket be populated first.|$|R
5000|$|Some {{multi-core}} chips can {{be programmed}} {{so that one}} of their <b>processors</b> is the <b>primary</b> <b>processor,</b> and the other processors are supporting coprocessors.|$|R
50|$|The EZ80L92 is the <b>primary</b> <b>processor</b> in the ST Robotics robot controller, clocked at 50MHz. It has 128Kb of {{external}} RAM and 128Kb {{of external}} flash memory.|$|R
40|$|Real-time {{multiprocessor}} systems frequently {{assume that}} there exists a dedicated processor for task allocation that never fails. This assumption is, however, too strong {{in the sense that}} all the physical objects are subject to failure. Moreover, once the dedicated processor fails, the whole multiprocessor system will fail. As a way to solve this problem, we propose a fault-tolerant scheduling algorithm based on moving dual-token. While the <b>primary</b> <b>processor</b> holding a <b>primary</b> token performs task allocation, the backup processor holding a backup token, in case that the <b>primary</b> <b>processor</b> has failed, does <b>primary</b> <b>processor</b> creation. Since no dedicated processor for task allocation exists in this scheme, failure of the whole multiprocessor system due to that of the dedicated processor can be avoided. In addition, the deadline-friendly scheduling policy used for backup task allocation, compared to heuristic scheduling, allows easier implementation and improved scheduling predictability. Simulation results show that the proposed dualtoken based algorithm yields low rejection rates over those with dedicated processor for task allocation...|$|R
50|$|The Firefly {{contained}} a <b>primary</b> <b>processor</b> board and zero, one, {{two or three}} secondary processor boards. These processor boards were 8 by 10 inches large. The <b>primary</b> <b>processor</b> board {{contained a}} microprocessor, its floating-point coprocessor and cache, and the Q-Bus control logic. The secondary processor boards each contained two microprocessors, their floating-point coprocessors and caches. The original Firefly processor boards used the MicroVAX 78032 microprocessor and MicroVAX 78132 floating-point coprocessor, but later Firefly systems used the faster CVAX 78034 microprocessors, CVAX Floating Point Chips (floating-point coprocessors). The processor boards communicated {{with each other and}} the memory via the MBus. The components used in the processor boards of the original Firefly were the same as those originally designed for the MicroVAX II system.|$|R
50|$|Canada has {{a supply}} {{management}} system where marketing boards govern the broiler and broiler hatching egg industries. For broilers, prices are negotiated at the provincial level. In each province, the minimum {{price per kg}} that processors will pay to producers is set periodically through negotiations between processors and the provincial marketing board. From 1992 to 2003, negotiated prices in Ontario are generally used as a benchmark when conducting price negotiations in other provinces. In Ontario, Chicken Farmers of Ontario (CFO) has price-negotiating authority. It negotiates the base price paid by <b>primary</b> <b>processors</b> for live chicken with <b>primary</b> <b>processors.</b> Since 2003, the live chicken price is determined by a “live price formula” established by the Agriculture, Food, and Rural Affairs Appeals Tribunal that includes the price of chicks, feed and producer margin.|$|R
50|$|Roadshow Films Pty Ltd & others v iiNet Ltd (commonly {{known as}} AFACT v iiNet) {{was a case}} in the Federal and High Courts of Australia between members of the Australian Federation Against Copyright Theft (AFACT) and other movie and {{television}} studios and iiNet, Australia's second-largest Internet service provider (ISP). The alliance of 34 companies unsuccessfully claimed that iiNet <b>authorised</b> <b>primary</b> copyright infringement by failing to take reasonable steps to prevent its customers from downloading and sharing infringing copies of films and television programs using BitTorrent.|$|R
50|$|IWTO is the {{international}} body representing {{the interests of the}} world's wool textile trade and industry. IWTO membership covers wool growers, traders, <b>primary</b> <b>processors,</b> spinners, weavers, garment makers and retailers of wool and allied fibers in its member-countries, as well as all kinds of organizations related to wool products and the wool business in general.|$|R
40|$|While the USDA {{regulation}} {{for meat}} inspection only requires that “all meat {{offered for sale}} must originate from a federally inspected slaughter facility, ” the USDA Food Safety Inspection Service (FSIS) allows two <b>primary</b> <b>processor</b> exemptions to this rule: custom and retail. These exemptions, available in their entirety within the Code of Federal Registers a...|$|R
50|$|The International Wool Textile Organisation (IWTO) is the {{international}} body representing {{the interests of the}} world's wool-textile trade and industry. IWTO membership covers woolgrowers, traders, <b>primary</b> <b>processors,</b> spinners, weavers, garment makers and retailers of wool and allied fibres in its member-countries, as well as all kind of organizations related to wool products and the wool business in general.|$|R
50|$|In The Terminator: Dawn of Fate, the Resistance invades Cheyenne Mountain {{in order}} to destroy Skynet's Central Processor. Kyle Reese is {{instrumental}} in destroying the <b>primary</b> <b>processor</b> core despite heavy opposition from attacking Skynet units. Before its destruction, Skynet is able to contact an orbiting satellite and activates a fail-safe which restores Skynet at a new location (presumably the Los Angeles base).|$|R
5000|$|... #Caption: Merit PDP-11 based <b>Primary</b> Communications <b>Processor</b> (PCP) at the University of Michigan, c. 1975 ...|$|R
40|$|Abstract—Energymanagement andreliabilityaretwoimportantdesignobjectivesforreal-timeembeddedsystems. Recently, the standby-sparing {{scheme that}} uses a <b>primary</b> <b>{{processor}}</b> and a spare processor has been exploited to provide fault tolerance while keeping the energy consumption under control through DVSandDPMtechniques. Inthispaper,weconsiderthestandbysparingtechniqueforfixed-priorityperiodicreal-timetasks. We propose a dual-queue mechanism through which the execution of backup tasks are maximally delayed, as well as online algorithms to manage energy consumption. Our experimental {{results show that the}} proposed scheme provides energy savings overtime-redundancybasedtechniqueswhileofferingreliability improvements. I...|$|R
50|$|The {{first model}} was the DN416 workstation, later {{referred}} to as the DN100 after the green screen was substituted with a black and white screen. This system used two 68000 processors and implemented virtual memory (which the 68000 wasn't theoretically capable of) by stopping one processor when there was a page fault and having the other processor handle the fault, then release the <b>primary</b> <b>processor</b> when the page fault was handled.|$|R
40|$|The declining price anomaly for {{sequential}} {{sales of}} identical commodities challenges auction theory which predicts constant prices within a day. Among other hypotheses explaining the phenomenon stands the dual value of goods including a risk premium in early transactions. We consider that asymmetric bidder groups (<b>primary</b> <b>processors,</b> fishmongers, supermarket buyers) and seasonal landings may also affect the daily price pattern. On {{the basis of}} stylized facts and several panel data models, this hypothesis is tested on a Redundant French fish market of homogenous goods (live Nephrops norvegicus) when the time effects (high and low seasons, weekday effect) affecting the demand and supply conditions are taken into consideration. All models support the evidence of a daily declining pattern, {{but not to the}} same extent for all days and seasons, and all categories of buyers. Our results also show an earlier and steeper decline on periods of lower supply (or higher demand), supporting the theoretical hypothesis of risk-averse behaviors of bidders, especially fishmongers with respect to <b>primary</b> <b>processors</b> and supermarkets...|$|R
40|$|Zooplankton are the <b>primary</b> <b>processors</b> of photosynthetically {{fixed carbon}} in the oceans, and play pivotal roles in {{transferring}} {{matter and energy}} to higher trophic levels (Ingrid et al. 1996, Turner et al. 2001). Zooplankton grazing transfers substantial amounts of organic matter from surface waters to deeper water layers. The magnitude of the downward flux of organic carbon {{is determined by the}} partitioning of carbon among various size classes of grazers. Meso- and macrozooplankton substantially contribute to th...|$|R
50|$|A {{coprocessor}} is {{a computer}} processor used to supplement {{the functions of the}} <b>primary</b> <b>processor</b> (the CPU). Operations performed by the coprocessor may be floating point arithmetic, graphics, signal processing, string processing, encryption or I/O Interfacing with peripheral devices. By offloading processor-intensive tasks from the main processor, coprocessors can accelerate system performance. Coprocessors allow a line of computers to be customized, so that customers who do not need the extra performance don't need to pay for it.|$|R
25|$|One of the {{earliest}} non-IBM channel systems was hosted in the CDC 6600 supercomputer in 1965. The CDC utilized 10 logically independent computers called peripheral processors, or PPs for this role. PPs were powerful, a modern version of CDC's first 'personal computer', the CDC 160A. The operating system resided and executed in the <b>primary</b> <b>processor,</b> PP0. Since then, channel controllers have been a standard part of most mainframe designs and a primary advantage mainframes have over smaller, faster, personal computers and network computing.|$|R
40|$|This paper designs {{a set of}} {{evaluation}} indexes of supply chain {{from the perspectives of}} the organization and the operation of supply chains, and constructs an effective matrix. Based on 6 <b>primary</b> <b>processors</b> and further processors, we use AHP to calculate the weight of each index and put the data of sample enterprises in effective matrix of supply chain to valuate effectiveness. We find that there are not strong partnership and perfect communication in pork supply chain, so processing enterprises should integrate with upstream farmers to set up strategic alliance and consolidate information communication...|$|R
40|$|The Magellan {{synthetic}} aperture radar (SAR) produces Venus surface images from data collected by the SAR carried on board the Magellan spacecraft. The core of the <b>primary</b> Magellan SAR <b>processor</b> is the digital correlator subsystem (DCS). The pipeline DSC architecture enables the Magellan <b>primary</b> SAR <b>processor</b> (PSP) to achieve real-time data processing capability. The implementation and performance of the DSC are described. Hardware (H/W) constraints that influenced the processing algorithm design are highlighted...|$|R
2500|$|II. - The {{prohibition}} {{provided for}} in section 1 hereof shall not apply if the clothing is prescribed or <b>authorised</b> by <b>primary</b> or secondary legislation, {{if it is}} justified for health or occupational reasons, {{or if it is}} worn in the context of sports, festivities or artistic or traditional events.” ...|$|R
40|$|SummaryArabidopsis encodes four DICER-like (DCL) {{proteins}} [1]. DCL 1 produces miRNAs [2 – 4], DCL 2 produces some virus-derived siRNAs, and DCL 3 produces endogenous RDR 2 -dependent siRNAs [5], but {{the role}} of DCL 4 is unknown. We show that DCL 4 is the <b>primary</b> <b>processor</b> of endogenous RDR 6 -dependent trans-acting siRNAs (tasiRNAs). Molecular and phenotypic analyses of all dcl double mutants also revealed partially compensatory functions among DCL proteins. In the absence of DCL 4, some RDR 6 -dependent siRNAs were produced by DCL 2 and DCL 3, {{and in the absence}} of DCL 3, some RDR 2 -dependent siRNAs were produced by DCL 2 and DCL 4. Consistent with partial redundancies, dcl 2 and dcl 3 mutants developed normally, whereas dcl 4 and dcl 3 dcl 4 mutants had weak and severe rdr 6 phenotypes, respectively, and increased tasiRNA target mRNA accumulation. After three generations, dcl 3 dcl 4 and dcl 2 dcl 3 mutants exhibited stochastic developmental phenotypes, some of which were lethal, likely owing to the accumulated loss of heterochromatic siRNA-directed marks. dcl 1 dcl 3 and dcl 1 dcl 4, but not dcl 1 dcl 2 mutants, had phenotypes more severe than dcl 1 mutants, consistent with DCL 1, DCL 3, and DCL 4 acting as the <b>primary</b> <b>processors</b> of the three respective classes of endogenous silencing RNAs and DCL 2 acting to produce viral-derived siRNAs and as an alternative DCL for endogenous siRNA production...|$|R
40|$|Brine water {{recovery}} represents a current technology gap in water recycling for human spaceflight. The {{role of a}} brine processor {{is to take the}} concentrated discharge from a <b>primary</b> wastewater <b>processor,</b> called brine, and recover most of the remaining water from it. The current stateoftheart <b>primary</b> <b>processor</b> is the ISS Urine Processor Assembly (UPA) that currently achieves 70 % {{water recovery}}. Recent advancements in chemical pretreatments are expected to increase this to 85 % in the near future. This is a welcome improvement, yet is still not high enough for deep space transit. Mission architecture studies indicate that at least 95 % is necessary for a Mars mission, as an example. Brine water recovery is the technology that bridges the gap between 85 % and 95 %, and moves life support systems one step closer to full closure of the water loop. Several brine water recovery systems have been proposed for human spaceflight, most of them focused on solving two major problems: operation in a weightless environment, and management and containment of brine residual. Brine residual is the leftover byproduct of the brine recovery process, and is often a viscous, sticky paste, laden with crystallized solid particles. Due to the chemical pretreatments added to wastewater prior to distillation in a <b>primary</b> <b>processor,</b> these residuals are typically toxic, which further complicates matters. Isolation of crewmembers from these hazardous materials is paramount. The Coiled Brine Recovery Assembly (CoBRA) is a recently developed concept from the Johnson Space Center that offers solutions to these challenges. CoBRA is centered on a softgoods evaporator that enables a passive fill with brine, and regeneration by discharging liquid brine residual to a collection bag. This evaporator is meant to be lightweight, which allows it to be discarded along with the accumulated brine solids contained within it. This paper discusses design and development of a first CoBRA prototype, and reports initial test results...|$|R
50|$|Control of Galaxy IV {{was lost}} on May 19, 1998 when the satellite's <b>primary</b> control <b>{{processor}}</b> failed. The backup control processor {{had suffered a}} previously undetected anomaly, and PanAmSat {{was not able to}} regain control of the spacecraft. Galaxy IV was declared a loss on May 20, 1998. Failure of the <b>primary</b> control <b>processor</b> was attributed to tin whisker growth, a phenomenon in which tendrils grow from solder, causing an electrical short circuit. Engineers believe that a hole developed in the conformal wax coating over the solder, allowing whiskers to develop. The satellite manufacturer, Hughes, has replaced pure tin plating with nickel to alleviate the problem in newer designs, adding 45 to 90 kg per payload.|$|R
40|$|Currently, {{the single}} screw {{extruder}} (SSE) {{is not a}} <b>primary</b> <b>processor</b> of RPVC dry blend because they have required a complex vacuum hopper and a crammer feeder. Conical twin screw extruders (TSE), being capable of processing RPVC dry blend {{without the use of}} a crammer feeder or vacuum hopper has therefore dominated RPVC dry blend processing. A new SSE is introduced that overcomes the need for a vacuum hopper and a crammer feeder with a simple screw design. This paper presents data on an SSE showing simple processing of RPVC dry blend with a surprising increase in screw speed to 180 rpm and output at only 174 °C, vented, starved or flood fed...|$|R
50|$|In {{spite of}} these problems, FullWrite {{developed}} a faithful following and some amount of commercial success. Douglas Adams used FullWrite as his <b>primary</b> word <b>processor</b> for some time. Douglas Hofstadter published several of his books directly from FullWrite, notably Le Ton beau de Marot.|$|R
5000|$|The 1st Aero on February 6, 1967, moved {{operations}} to the Group III Space Defense Center, the integrated missile warning/space surveillance facility (496L Spacetrack system with Philco 212 <b>primary</b> <b>processor)</b> at the Cheyenne Mountain nuclear bunker (FOC {{of the new}} bunker's command center—a portion of the Burroughs 425L Command/Control and Missile Warning System—had been on July 1, 1966.) Interim operations of the Avco 474N SLBM Detection and Warning System began in July 1970 (IOC was 5 May 1972), and in 1972 20% of the Bendix AN/FPS-85 Phased Array Radar's surveillance capability [...] "became dedicated to search for SLBMs" [...] (the FPS-85 relayed SLBM data via the 474N network for SLBM warning to [...] "SAC, the National Military Command Center, and the Alternate NMCC over BMEWS circuits").|$|R
40|$|The {{exploration}} of techniques to accelerate big data applicationshas been an active area of research. Although we have highly efficient computing cores and high-speed networks, the bottleneck in most big data applications {{has been the}} latency of data access. The foremost contributors to this latency are the network communication, storage systems, software stack and data transfer. Heterogeneous co-processors, FPGA accelerators, and flash based storage accelerators try to overcome this latency by offloading processing from the <b>primary</b> <b>processor,</b> but these cause additional overheads to an already costly data-center server and increase the total deployment cost. With an ever growing size of data, the need to exploit the available resources in the <b>primary</b> <b>processor</b> while achieving the best possible performance becomes increasingly necessary. A humble performance improvement of even 1 % {{goes a long way}} in a typical data center environment. Consequently, this work evaluates the effectiveness of Data Direct Input Output (DDIO) commonly known as Direct Cache Access (DCA) for I/O intensive big data workloads. We begin with a survey of various kinds and characteristics of big data workloads and then present the performance gain/loss due to DCA for I/O intensive workloads on Xeon E 5 based servers. The big data applications are considerably different from the workloads traditionally used in architectural studies hence micro-benchmarks are used to emulate workloads which could gain/lose considerable performance when using direct cache access. Also, we present the performance of I/O intensive tasks from state of the art Cloudsuite benchmark suite. We finally make a case for the dynamic use of DCA in the processor for better performance of big data applications (change the percentage of cache available for DDIO to use or the cache levels DCA can access) ...|$|R
40|$|There {{has been}} {{considerable}} interest in implementing a multithreaded program execution and architecture model on a multiprocessor whose <b>primary</b> <b>processors</b> consist of today's off-the-shelf microprocessors. Unlike some custom-designed multithreaded processor architectures, which can interleave multiple threads concurrently, conventional processors can only execute one thread at a time. This presents {{a unique and}} challenging problem to the compiler: partition a program into threads so that it executes both correctly and in minimal time. We present a new heuristic algorithm based on an interesting extension of the classical list scheduling algorithm. Based on a cost model, our algorithm groups instructions into threads by considering the trade-offs among parallelism, latency tolerance, thread switching costs and sequential execution efficiency. The proposed algorithm has been implemented, and its performance measured through experiments {{on a variety of}} architecture parameters a [...] ...|$|R
5000|$|Much later, the {{channels}} were implemented as an on-board processor {{residing in the}} same box as the CPU, generally {{referred to as a}} [...] "channel processor", and which was usually a RISC processor, but which could be a System/390 microprocessor with special microcode as in IBM's CMOS mainframes. One of the earliest non-IBM channel systems was hosted in the CDC 6600 supercomputer in 1965. The CDC utilized 10 logically independent computers called peripheral processors, or PPs for this role. PPs were powerful, a modern version of CDC's first 'personal computer', the CDC 160A. The operating system resided and executed in the <b>primary</b> <b>processor,</b> PP0. Since then, channel controllers have been a standard part of most mainframe designs and a primary advantage mainframes have over smaller, faster, personal computers and network computing.|$|R
50|$|To {{expand the}} network, the Merit staff {{developed}} new hardware interfaces for the Digital PDP-11 based on printed circuit technology. The new system {{became known as}} the <b>Primary</b> Communications <b>Processor</b> (PCP), with the earliest PCPs connecting a PDP-10 located at WMU and a DEC VAX running UNIX at U-M's Electrical Engineering department.|$|R
25|$|Video game {{manufacturers}} {{used the}} 68000 as {{the backbone of}} many arcade games and home game consoles: Atari's Food Fight, from 1982, {{was one of the}} first 68000-based arcade games. Others included Sega's System 16, Capcom's CP System and CPS-2, and SNK's Neo Geo. By the late 1980s, the 68000 was inexpensive enough to power home game consoles, such as Sega's Mega Drive (Genesis) console and also the Sega CD attachment for it (A Sega CD system has three CPUs, two of them 68000s). The 1993 multi-processor Atari Jaguar console used a 68000 as a support chip, although some developers used it as the <b>primary</b> <b>processor</b> due to familiarity. The 1994 multi-processor Sega Saturn console used the 68000 as a sound co-processor (much as the Mega Drive/Genesis uses the Z80 as a co-processor for sound and/or other purposes).|$|R
40|$|A {{computer}} framework {{feasible for}} developing parallel systems {{according to the}} Bulk Synchronous Parallel (BSP) computing model is described: Switched Interconnection of Parallel Processors (Swipp). Demanding applications {{can be described as}} directed graphs where the interdependent subtasks constitute the nodes. The tasks are predistributed by a system master, Computer Executive Engine (CEE), to a set of heterogeneous computing nodes. Each computing node has a preprogrammed secondary control processor attached for performing communication and runtime tasks, thus allowing <b>primary</b> <b>processors</b> of various kinds and programming styles. Synchronization of a bulk of subactivities is done in locksteps by the CEE. Basic features are modelled by the Ptolemy framework and prototype modules are being implemented. I. INTRODUCTION The performance of sequential single CPU processors has been steadily increasing over the last decades due to circuit technology improvements. The von Neumann model of comp [...] ...|$|R
50|$|Video game {{manufacturers}} {{used the}} 68000 as {{the backbone of}} many arcade games and home game consoles: Atari's Food Fight, from 1982, {{was one of the}} first 68000-based arcade games. Others included Sega's System 16, Capcom's CP System and CPS-2, and SNK's Neo Geo. By the late 1980s, the 68000 was inexpensive enough to power home game consoles, such as Sega's Mega Drive (Genesis) console and also the Sega CD attachment for it (A Sega CD system has three CPUs, two of them 68000s). The 1993 multi-processor Atari Jaguar console used a 68000 as a support chip, although some developers used it as the <b>primary</b> <b>processor</b> due to familiarity. The 1994 multi-processor Sega Saturn console used the 68000 as a sound co-processor (much as the Mega Drive/Genesis uses the Z80 as a co-processor for sound and/or other purposes).|$|R
5000|$|Section 2“I. - For the {{purposes}} of section 1 hereof, ‘public places’ comprise the public highway and any places {{open to the public}} or assigned to a public service.II. - The prohibition provided for in section 1 hereof shall not apply if the clothing is prescribed or <b>authorised</b> by <b>primary</b> or secondary legislation, if it is justified for health or occupational reasons, or if it is worn in the context of sports, festivities or artistic or traditional events.” ...|$|R
