135|57|Public
5|$|DAB {{has also}} been marketed as having two major {{advantages}} over analogue radio broadcasting in that using MPEG-1 Audio Layer II lossy audio compression technology and more recently DAB+ using High-Efficiency Advanced Audio Coding, parts of the <b>audio</b> <b>spectrum</b> that cannot be heard by humans are discarded, meaning less data needs to be sent over the air. This, as well as multiplexing technology, allows a number of channels to be broadcast together on one frequency as opposed to one channel for analogue radio broadcasts.|$|E
25|$|Dynamic {{microphones}} use {{the same}} dynamic principle as in a loudspeaker, only reversed. A small movable induction coil, positioned in the magnetic field of a permanent magnet, {{is attached to the}} diaphragm. When sound enters through the windscreen of the microphone, the sound wave moves the diaphragm. When the diaphragm vibrates, the coil moves in the magnetic field, producing a varying current in the coil through electromagnetic induction. A single dynamic membrane does not respond linearly to all audio frequencies. For this reason some microphones utilize multiple membranes for the different parts of the <b>audio</b> <b>spectrum</b> and then combine the resulting signals. Combining the multiple signals correctly is difficult and designs that do this are rare and tend to be expensive. On the other hand, there are several designs that are more specifically aimed towards isolated parts of the <b>audio</b> <b>spectrum.</b> The AKG D 112, for example, is designed for bass response rather than treble. In audio engineering several kinds of microphones are often used {{at the same time to}} get the best results.|$|E
25|$|The lateral cut NAB curve {{was remarkably}} similar to the NBC Orthacoustic curve that evolved from {{practices}} within the National Broadcasting Company since the mid-1930s. Empirically, and not by any formula, it was learned that the bass end of the <b>audio</b> <b>spectrum</b> below 100Hz could be boosted somewhat to override system hum and turntable rumble noises. Likewise at the treble end beginning at 1,000Hz, if audio frequencies were boosted by 16dB at 10,000Hz the delicate sibilant sounds of speech and high overtones of musical instruments could survive the noise level of cellulose acetate, lacquer–aluminum, and vinyl disc media. When the record was played back using a complementary inverse curve, signal-to-noise ratio was improved and the programming sounded more lifelike.|$|E
50|$|The {{nonlinear}} interaction mixes ultrasonic tones in air {{to produce}} sum and difference frequencies. A DSB-AM modulation scheme with an appropriately large baseband DC offset, {{to produce the}} demodulating tone superimposed on the modulated <b>audio</b> <b>spectra,</b> {{is one way to}} generate the signal that encodes the desired baseband <b>audio</b> <b>spectra.</b> This technique suffers from extremely heavy distortion as not only the demodulating tone interferes, but also all other frequencies present interfere with one another. The modulated spectra is convolved with itself, doubling its bandwidth by the length property of the convolution. The baseband distortion in the bandwidth of the original <b>audio</b> <b>spectra</b> is inversely proportional to the magnitude of the DC offset (demodulation tone) superimposed on the signal. A larger tone results in less distortion.|$|R
3000|$|Intuitively, we can {{interpret}} this result as the weighted {{average of the}} normalized <b>audio</b> <b>spectra</b> with respect to v [...]...|$|R
5000|$|... #Caption: Sidebands {{are evident}} in this {{spectrogram}} of an AM broadcast (The carrier is highlighted in red, the two mirrored <b>audio</b> <b>spectra</b> (green) are the lower and upper sideband).|$|R
500|$|Loudspeaker {{impedances}} {{are kept}} relatively low {{compared with other}} audio components so that the required audio power can be transmitted without using inconveniently (and dangerously) high voltages. [...] The most common nominal impedance for loudspeakers is 8Ω. [...] Also used are 4Ω and 16Ω. [...] The once common 16Ω is now mostly reserved for high frequency compression drivers since the high frequency end of the <b>audio</b> <b>spectrum</b> does not usually require so much power to reproduce.|$|E
500|$|The first sensors {{utilized}} {{by the program}} were Air-Delivered Seismic Intrusion Detector (ADSID), which had been developed from devices then in use in underground mapping for the oil industry. The device could sense vertical earth motion {{by the use of}} an internal geophone and could determine whether a man or a vehicle was in motion at a range of [...] and [...] respectively. The first acoustic sensors were developed from the U.S. Navy's Project Jezebel anti-submarine warfare sonobuoys, which recorded and processed sound by the utilization of an <b>audio</b> <b>spectrum</b> analyzer. The first model of seismic detectors (Phase I) outshone their contemporary acoustic types in {{the quality and quantity of}} the information they reported. The Phase I models of both the acoustic and seismic sensors were only available for operation in a continuous mode, which meant that under normal conditions, their lithium batteries would function for approximately 30 days.|$|E
500|$|Linn {{brochures}} dwell {{little on}} performance specifications, mentioning somewhat vaguely that the frequency response [...] "varies {{by only a}} few db from 20Hz to 20KHz with the isobaric loading extending usable bass response to below 10Hz". Linn also claimed [...] "very low distortion" [...] and [...] "high sound pressure levels", without quantification. Recommended amplifier power rating is {{in the range of}} 50500watts. Hi-Fi for Pleasure noted that the speakers' impedance, although quoted at 3 ohms nominal, dipped considerably at some parts of the <b>audio</b> <b>spectrum.</b> This made the DMS Isobarik very hard for amplifiers to drive, potentially causing many amplifiers' output protection to trip. Equally, the two heavy woofers in each Isobarik made them twice as power-hungry. Such demands happened to make Naim amplification the perfect match because of its high current delivery capabilities and its toleration of near short circuits. The Isobarik was famously used as the acid test for the budget-priced NAD 3020 amplifier at its UK launch. In the 1970s, the DMS Isobarik, available in a number of veneers, sold for £1,000.|$|E
50|$|Narrowband is {{also used}} in sending <b>audio</b> <b>spectrums</b> that consume a {{restricted}} range of frequencies. The US FCC has allocated a specific range of frequency for mobile radio services based on narrowband that spans from 50cps to 64kbit/s.|$|R
30|$|In all experiments, {{the audio}} signal is first {{transformed}} using STFT with the frame length of 1024 and the frame shift of 10 ms, so {{the size of}} <b>audio</b> <b>spectrums</b> is 513 × 128. The mini-batch size is set to be 50, and the learning rate is initialized with 0.001.|$|R
5000|$|... #Caption: The voice {{waveform}} {{over time}} (left) has a broad <b>audio</b> power <b>spectrum</b> (right).|$|R
2500|$|Wired was {{impressed}} by the audio quality and commented that UE 900s produce [...] "some truly glorious sound, supremely rich {{from one end of the}} <b>audio</b> <b>spectrum</b> to the other. The bass is heavy and direct. Mid-range frequencies are perfectly represented, and the chiming highs are only slightly tempered at the very, very top end." [...] The reviewer also noted an excellent clarity and ability to hear details he had never picked up on before.|$|E
2500|$|On a {{different}} note, the Kurzweil K150 and the Kawai K5 explored additive synthesis where harmonics can be proportioned to make different tones while enveloping groups of them {{differently in the}} mid '80s. RMI had explored this to a limited extent in 1974 with the harmonic synthesizer they produced. It should also be mentioned that they were producing the earliest electric piano machines in 1970. This less common synthesis method is also used in Kawai's last synthesizer product series, the K5000's from 1996. [...] Organs like the Hammond B3 use drawbars to control harmonic content of the tone. [...] But the K5000 has an envelope for each harmonic in the entire <b>audio</b> <b>spectrum</b> and dynamic filter control over that for vast possibilities in sound creation.|$|E
50|$|Since hi-fi audio {{requires}} that the loudspeaker be capable of faithful reproduction of the recorded material, it follows that a loudspeaker that better covers the <b>audio</b> <b>spectrum</b> will have better hi-fi performance. Therefore, most hi-fi loudspeakers employ multiple drivers to cover the <b>audio</b> <b>spectrum</b> satisfactorily.|$|E
40|$|The {{synthesis}} of rich <b>audio</b> <b>spectra</b> requires usually complex source waveforms, {{a large number}} of simple source components, or increased algorithmic complexity. This paper describes an implementation, which shows that simple elementary bitwise logical operations (OR, AND, XOR) possess power to produce such spectra. Applying these operations to two sinusoidal audio oscillators produced wide variety of new harmonically related sonic material. The synthesis method is efficient to implement and easily controllable, but it is not generally band-limited. 1...|$|R
5000|$|Some {{people use}} [...] "spectral centroid" [...] {{to refer to}} the median of the spectrum. This is a {{different}} statistic, the difference being essentially the same as the difference between the unweighted median and mean statistics. Since both are measures of central tendency, in some situations they will exhibit some similarity of behaviour. But since typical <b>audio</b> <b>spectra</b> are not normally distributed, the two measures will often give strongly different values. Grey and Gordon in 1978 found the mean a better fit than the median.|$|R
40|$|A novel {{approach}} to classification of peaks of <b>audio</b> <b>spectra</b> is presented. In extending previous work on detecting transient spectral peaks we here investigate into {{the classification of}} sinusoidal and noise peaks. The classification is based on descriptors derived from properties related to time-frequency distributions: mean time, duration, instantaneous frequency and normalized bandwidth. In contrast to existing methods, the descriptors are designed to properly deal with non-stationary sinusoids, which considerably increases the range of applications. The experimental investigation shows superior classification results compared to the standard correlationbased approach. 1...|$|R
5000|$|Strong undamped {{resonance}} in {{the middle}} of the <b>audio</b> <b>spectrum</b> ...|$|E
5000|$|Pro <b>Audio</b> <b>Spectrum</b> (1991): 8-bit ISA {{audio card}} with CD-ROM interface.|$|E
5000|$|Presidential Interview (Flying Saucer '64) / Paul Revere — <b>Audio</b> <b>Spectrum</b> 75 — 10/1964 ...|$|E
5000|$|Voice Of The Outsider: The Best of Kevin Coyne - 2013 (<b>Spectrum</b> <b>Audio)</b> ...|$|R
40|$|Abstract — we {{introduce}} {{a system for}} generalized sound classification and similarity using a machine learning framework. Applications of the system include automatic classification of environmental sounds, musical instruments, music genre and human speakers. In addition to classification, the system may {{also be used for}} computing similarity metrics between a target sound and other sounds in a database. We discuss the use of hidden Markov models for representing the temporal evolution of <b>audio</b> <b>spectra</b> and present results of testing the system on classification and retrieval tasks. The system has been incorporated into the MPEG- 7 international standard for multimedia content description and is therefore publicly available {{in the form of a}} set of standardized interfaces and software reference tools for developers and researchers...|$|R
40|$|We {{propose the}} product-of-filters (PoF) model, a {{generative}} model that decomposes <b>audio</b> <b>spectra</b> as sparse linear combinations of "filters" in the log-spectral domain. PoF makes similar assumptions {{to those used}} in the classic homomorphic filtering approach to signal processing, but replaces hand-designed decompositions built of basic signal processing operations with a learned decomposition based on statistical inference. This paper formulates the PoF model and derives a mean-field method for posterior inference and a variational EM algorithm to estimate the model's free parameters. We demonstrate PoF's potential for audio processing on a bandwidth expansion task, and show that PoF can serve as an effective unsupervised feature extractor for a speaker identification task. Comment: ICLR 2014 conference-track submission. Added link to the source cod...|$|R
5000|$|... {{multimedia}} kits, each bundling a Pro <b>Audio</b> <b>Spectrum</b> sound card, CD-ROM {{drive and}} software ...|$|E
5000|$|Supported Sound Devices - Sound Blaster -family, Gravis Ultrasound, Pro <b>Audio</b> <b>Spectrum,</b> and 100% compatibles ...|$|E
50|$|It {{is normal}} for such {{speakers}} to vary in impedance by over 100:1 across the <b>audio</b> <b>spectrum.</b>|$|E
40|$|This paper {{describes}} a software tool {{developed in the}} Java language to facilitate time and frequency warping of <b>audio</b> <b>spectra.</b> The application utilises the Java Advanced Image Processing (AIP) API which contains classes for image manipulation and, in particular, for non-linear warping using polynomial transformations. Warping of spectral representations is fundamental to sound processing techniques such as sound transformation and morphing. Dynamic time warping has been the method of choice for many implementations of temporal and spectral alignment for morphing. This tool offers greater advantage by providing an interactive approach to warping, thus allowing greater flexibility in achieving a desired transformation. This application can then be used as input to a signal synthesis routine, which will recover the transformed sound. 1...|$|R
5000|$|... 2011: Trojan Presents: Dancehall - 40 Sound System Favourites - [...] "Good To Be There" [...] (<b>Spectrum</b> <b>Audio)</b> http://www.discogs.com/Various-Trojan-Presents-Dancehall-40-Sound-System-Favourites/release/2982591 ...|$|R
5000|$|... 1967 - Herostratus. Directed by Don Levy. One scene {{features}} <b>audio</b> of El-Dabh's <b>Spectrum</b> no. 1: Symphonies in Sonic Vibration ...|$|R
5000|$|Pro Sonic 16: Based on Media Vision's JAZZ 16 chipset (not {{compatible}} with the Pro <b>Audio</b> <b>Spectrum</b> line).|$|E
5000|$|Narrowband {{can also}} be used with the <b>audio</b> <b>spectrum</b> to {{describe}} sounds which occupy a narrow range of frequencies.|$|E
5000|$|... #Caption: Image of a buffalo, {{trailing}} buffalo chips, etched on {{a digital}} filter chip from the HP3582a <b>audio</b> <b>spectrum</b> analyzer.|$|E
50|$|These {{distorting}} {{effects may}} be better mitigated by using another modulation scheme that {{takes advantage of the}} differential squaring device nature of the nonlinear acoustic effect. Modulation of the second integral of the square root of the desired baseband audio signal, without adding a DC offset, results in convolution in frequency of the modulated square-root spectra, half the bandwidth of the original signal, with itself due to the nonlinear channel effects. This convolution in frequency is a multiplication in time of the signal by itself, or a squaring. This again doubles the bandwidth of the spectra, reproducing the second time integral of the input <b>audio</b> <b>spectra.</b> The double integration corrects for the -ω² filtering characteristic associated with the nonlinear acoustic effect. This recovers the scaled original spectra at baseband.|$|R
40|$|International audienceThis paper {{presents}} {{an investigation into}} the detection and classification of drum sounds in polyphonic music and drum loops using non-negative matrix deconvolution (NMD) and the Itakura Saito divergence. The Itakura Saito divergence has recently been proposed as especially appropriate for decomposing <b>audio</b> <b>spectra</b> {{due to the fact that}} it is scale invariant, but it has not yet been widely adopted. The article studies new contributions for audio event detection methods using the Itakura Saito divergence that improve efficiency and numerical stability, and simplify the generation of target pattern sets. A new approach for handling background sounds is proposed and moreover, a new detection criteria based on estimating the perceptual presence of the target class sources is introduced. Experimental results obtained for drum detection in polyphonic music and drum soli demonstrate the beneficial effects of the proposed extensions...|$|R
40|$|Inspired by {{a formal}} analogy {{between the two}} {{dimensional}} version of Laplace’s partial differential equation and the two dimensions (time and fre-quency) of a spectrogram, this paper explores a variety of density and kernel-based techniques that can smoothly connect (morph between) two functions. When the functions represent <b>audio</b> <b>spectra,</b> this presents {{a solution to the}} problem of audio morphing, providing a concrete way of adjusting the over-tones of a sound while smoothly interpolating between existing sounds. The approach can be applied to both interpolation morphing (where the morph connects two different sounds over some specified duration) and to repetitive morphing (where a series of sounds are generated, each containing progres-sively more features of one sound and fewer of the other). When successful, the timbre of the sounds is changed dynamically in a plausible way. A se-ries of sound examples demonstrate the strengths and weaknesses of the approach. ...|$|R
