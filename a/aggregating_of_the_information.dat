0|10000|Public
40|$|In this paper, {{we propose}} {{a method to}} create <b>aggregated</b> {{representations}} <b>of</b> <b>the</b> <b>information</b> needs <b>of</b> Web users when searching for particular types of objects. We suggest this method {{as a way to}} investigate the gap between what Web search users are expecting to find and <b>the</b> kind <b>of</b> <b>information</b> that is provided by Semantic Web datasets formatted according to a particular ontology. We evaluate our method qualitatively by measuring its power as a query completion mechanism. Last, we perform a qualitative evaluation com- paring <b>the</b> <b>information</b> Web users search for with <b>the</b> <b>information</b> available in Dbpedia, the structured data representation of Wikipedia...|$|R
40|$|UnrestrictedThis {{study used}} {{cognitive}} task analysis (CTA) knowledge elicitation strategies {{to find the}} percentage and type of information that experts omit when describing how to perform a surgical procedure. CTA is a method by which a trained analyst can extract and capture information that has been automated and is non-conscious to an expert. This information includes critical decision points and judgments involved in <b>the</b> expert’s performance <b>of</b> <b>the</b> procedure. Based on the current research literature, the hypothesis {{for this study was}} that surgical experts would omit approximately 70 % <b>of</b> <b>the</b> critical decision steps necessary to perform the Open Cricothyrotomy and Central Venous Catheter surgical procedures. More specifically, this study sought to determine if there is a difference in knowledge omissions based on the experts’ prior knowledge <b>of</b> <b>the</b> procedures.; This descriptive study took a mixed-methods approach. Qualitative methods were used to conduct semi-structured interviews while quantitative methods were used. to analyze the data by using frequency counts to determine how much information was omitted when compared with the final, expert-approved, “gold standard. ” The “gold standard” is an <b>aggregate</b> <b>of</b> <b>the</b> <b>information</b> elicited from six medical faculty at <b>the</b> University <b>of</b> Southern California, Keck School of Medicine. Results showed that experts for the Open Cricothyrotomy surgical procedure omitted 76. 92 % <b>of</b> <b>the</b> decision steps, while experts for the Central Venous Catheter procedure omitted 34. 52 % <b>of</b> <b>the</b> decision steps. Limitations <b>of</b> <b>the</b> study and implications for future research and task complexity are discussed...|$|R
30|$|Certain studies focused {{specifically}} on <b>the</b> task <b>of</b> detecting events and tagging their relevant geolocations. In particular, some works targeted <b>the</b> detection <b>of</b> localized events [21 – 25], others <b>the</b> detection <b>of</b> global events [26], and <b>the</b> detection <b>of</b> critical events [5, 27]. Dong et al. [28], specifically, considered that events had different {{temporal and spatial}} scales and proposed a multi-scale event detection approach for social media. This approach focuses on detecting and reporting events with geolocalization. Our current approach differs from existing work, in that we create an <b>aggregated</b> representation <b>of</b> <b>the</b> <b>information</b> about real-world events, producing a high-level representation that includes the event’s geographical context, which is extracted from social media. In addition, we enrich <b>the</b> <b>information</b> about an event by using <b>the</b> locations <b>of</b> <b>the</b> users that post information about it.|$|R
40|$|This Comment {{focuses on}} {{sections}} 302 and 906 <b>of</b> <b>the</b> Sarbanes-Oxley Act. Section 302 requires Chief Executive Officers (CEOs) and Chief Financial Officers (CFOs), or their equivalents, to personally certify <b>the</b> accuracy <b>of</b> financial disclosure filings {{required by the}} SEC and to vouch for <b>the</b> reliability <b>of</b> <b>the</b> internal corporate controls that produce that information. 2 ̆ 74 Section 906 contains an additional certification requirement and provides specific criminal penalties for willful or knowing violations of that requirement. 2 ̆ 72 ̆ 2 An efficiency-based analysis of these two sections <b>of</b> <b>the</b> Sarbanes-Oxley Act suggests that including a recklessness standard of intent {{would be more likely}} to increase <b>the</b> accuracy <b>of</b> <b>the</b> <b>information,</b> reduce <b>the</b> <b>aggregate</b> costs <b>of</b> obtaining <b>the</b> <b>information,</b> and restore much-needed investor confidence. As a result, Congress should amend the Sarbanes-Oxley Act to create a single, coherent certification requirement with criminal penalty provisions that incorporate recklessness as a standard of intent giving rise to criminal culpability...|$|R
40|$|This paper aims to {{investigate}} <b>the</b> response <b>of</b> {{higher education institutions}} to stage 1 <b>of</b> <b>the</b> Learning and Teaching Performance Fund, specifically the condition stating "Evidence that student evaluations of subjects are publicly available on the University's website". A list of all universities and other self accrediting higher education institutions {{was obtained from the}} Australian Government education web site. Each <b>of</b> <b>the</b> web sites hosted by these institutions was visited for information using a pre-determined method. Whilst many universities provide publicly available versions <b>of</b> <b>aggregate</b> <b>information,</b> <b>the</b> definition <b>of</b> 'publicly' has been treated rather liberally. The people who may find this information of most use, current and prospective students, have been largely ignored. This paper suggests that universities should provide information on course evaluations not only in a central section but associated with <b>the</b> general course <b>information.</b> Edward Palmer and Geoffrey Crisp[URL]...|$|R
40|$|We {{make the}} case for {{developing}} a web of concepts by starting with <b>the</b> current view <b>of</b> web (comprised of hyperlinked pages, or documents, each seen as a bag of words), extracting concept-centric metadata, and stitching it together to create a semantically rich <b>aggregate</b> view <b>of</b> all <b>the</b> <b>information</b> available on <b>the</b> web for each concept instance. <b>The</b> goal <b>of</b> building and maintaining such a web of concepts presents many challenges, but also offers <b>the</b> promise <b>of</b> enabling many powerful applications, including novel search and information discovery paradigms. We present the goal, motivate it with example usage scenarios and some analysis of Yahoo! logs, and discuss the challenges in building and leveraging such a web of concepts. We place this ambitious research agenda in <b>the</b> context <b>of</b> <b>the</b> state <b>of</b> <b>the</b> art in the literature, and describe various ongoing efforts at Yahoo! Research that are related...|$|R
30|$|The {{expression}} “Actionable data” {{has been}} used in <b>the</b> context <b>of</b> quality improvement initiatives. Let’s use the low-tidal volume (Vt) in ARDS, a practice associated with reduced mortality and shorter ICU length of stay (LOS), as an example. At patient level, daily checklists using mobile devices could show the current recommendation (Vt ≤  6  mL/Kg IBW) and capture the patients’ current tidal volume, as well as the average data in the ICU and in the country/region thus helping to improve adherence to good standards <b>of</b> care. <b>The</b> <b>aggregate</b> <b>of</b> all <b>the</b> <b>information</b> captured by <b>the</b> checklist could be used at unit level for a better understanding of its overall adherence rate and comparing it with similar ICUs and ICU populations. Data available in a dashboard allows ICUs to compare the overall rates and specific outcomes (ICU LOS, duration of MV, VAP rates) and also to analyze what are <b>the</b> patterns <b>of</b> ICUs that are top ranked. These positive outliers could be considered as “positive deviants.” This methodology is used with success in other medical areas and briefly consists of understanding what are <b>the</b> characteristics <b>of</b> patients (e.g., case-mix, severity, etiology of ARF), structure (e.g., staffing patterns, types of ICU) and processes of care (e.g., sedation practices, weaning protocols, ventilator settings) of those that achieve better results. This may provide a road map for a PDCA cycle based on benchmarking of practices that are associated with better performance.|$|R
40|$|In Hungary {{a general}} {{agricultural}} census (AC) {{was carried out}} in 2000, followed in 2001 by the population and housing census. The two censuses had been designed separately. Originally the Hungarian Central Statistical Office (HCSO) did not plan <b>the</b> joint analysis <b>of</b> <b>the</b> data <b>of</b> <b>the</b> two censuses. Following the censuses users and researchers expressed the view that linking <b>the</b> data <b>of</b> <b>the</b> two databases would represent a value-added in <b>the</b> use <b>of</b> <b>the</b> data and <b>the</b> joint utilization <b>of</b> <b>the</b> databases <b>of</b> <b>the</b> two censuses was examined. The databases were matched and <b>the</b> <b>aggregated</b> handling <b>of</b> <b>the</b> <b>information</b> increased <b>the</b> potential for analysing both censuses and allowed further, more sophisticated investigations. By means <b>of</b> <b>the</b> databases <b>of</b> <b>the</b> two censuses, the first opportunity arose for matching <b>the</b> discrete data <b>of</b> <b>the</b> surveys. <b>The</b> precondition <b>of</b> <b>the</b> matching <b>of</b> <b>the</b> data was <b>the</b> conformity <b>of</b> <b>the</b> respective metadata <b>of</b> <b>the</b> two operations. „Private holding ” and „dwelling-household ” were the categories applicable as the smallest unit for the matching. The links between the private holdings and the households could be based on <b>the</b> identity <b>of</b> <b>the</b> persons living in the dwelling. <b>The</b> matching <b>of</b> <b>the</b> data required <b>the</b> use <b>of</b> individual identity codes. With the matching process used a joint database <b>of</b> <b>the</b> agricultural and population censuses was set up providing new approaches for gender disaggregated analysis. By using the linked database, the HCSO issued a series <b>of</b> publications on <b>the</b> households living in agricultural private holdings in the countryside. This presentation describes <b>the</b> method <b>of</b> matching <b>the</b> databases <b>of</b> <b>the</b> two censuses...|$|R
40|$|<b>The</b> aim <b>of</b> {{this paper}} is to propose a class of {{composite}} indicators for measuring well-being at the local level, which takes into account the variability between and within the local units. Although we believe that well-being is a multidimensional concept and cannot be reduced to a single measure, we also stress <b>the</b> importance <b>of</b> <b>aggregating</b> <b>the</b> <b>information</b> <b>of</b> several well-being indicators into a reduced number of composite indicators, one for each well-being domain, which {{play a crucial role in}} policymaking and benchmarking. As an application we focus on the Equitable and Sustainable Well-being <b>of</b> <b>the</b> Italian Provinces. In particular, based on a dataset containing 41 elementary indicators, we aggregate them by domain, comparing different aggregative approaches and illustrating the difference in <b>the</b> rankings <b>of</b> <b>the</b> Italian Provinces they produce. Finally, as an illustrative example, we focus on a member <b>of</b> <b>the</b> class <b>of</b> composite indicators that accounts both for vertical variability, which is the between component and horizontal variability, which is the within component. <b>The</b> construction <b>of</b> a composite index for each domain allows us to evaluate and compare multidimensional well-being among the Italian Provinces...|$|R
40|$|A new {{framework}} for asset price dynamics is introduced in which <b>the</b> concept <b>of</b> noisy <b>information</b> about future cash flows {{is used to}} derive the corresponding price processes. In this framework an asset is defined by its cash-flow structure. Each cash flow is modelled by a random variable that can be expressed {{as a function of}} a collection of independent random variables called market factors. With each such "X-factor" we associate a market <b>information</b> process, <b>the</b> values <b>of</b> which we assume are accessible to market participants. Each information process consists of a sum of two terms; one contains true <b>information</b> about <b>the</b> value <b>of</b> <b>the</b> associated market factor, and the other represents "noise". The noise term is modelled by an independent Brownian bridge that spans the interval from the present to the time at which <b>the</b> value <b>of</b> <b>the</b> factor is revealed. The market filtration is assumed to be that generated by <b>the</b> <b>aggregate</b> <b>of</b> <b>the</b> independent <b>information</b> processes. <b>The</b> price <b>of</b> an asset is given by <b>the</b> expectation <b>of</b> <b>the</b> discounted cash flows in the risk-neutral measure, conditional on <b>the</b> <b>information</b> provided by <b>the</b> market filtration. In the case where the cash flows are the dividend payments associated with equities, an explicit model is obtained for the share-price process. Dividend growth is taken into account by introducing appropriate structure on the market factors. <b>The</b> prices <b>of</b> options on dividend-paying assets are derived. Remarkably, the resulting formula for <b>the</b> price <b>of</b> a European-style call option is <b>of</b> <b>the</b> Black–Scholes–Merton type. We consider the case where the rate at which information is revealed to the market is constant, and the case where <b>the</b> <b>information</b> rate varies in time. Option pricing formulae are obtained for both cases. The information-based framework generates a natural explanation for <b>the</b> origin <b>of</b> stochastic volatility in financial markets, without the need for specifying on an ad hoc basis <b>the</b> dynamics <b>of</b> <b>the</b> volatility. Asset pricing, partial information, stochastic volatility, correlation, dividend growth, Brownian bridge, nonlinear filtering, market microstructure...|$|R
40|$|While more {{developed}} countries have a well-established systems to develop {{water quality criteria}} (WQC), {{little research has been}} done on <b>the</b> adequacy <b>of</b> <b>the</b> current WQC to protect endemic species of China. In order to maintain <b>the</b> health <b>of</b> aquatic ecosystems in China, a series of projects to establish national WQC based on regional characteristics has recently been initiated. However, <b>the</b> establishment <b>of</b> a completely novel methodology would be costly and time consuming. Also, due to the similarities in physiologies and natural histories of classes of aquatic organisms, {{there is no reason to}} believe that WQC would not be sufficient to protect unique species in China. This review was undertaken to identify key outstanding issues regarding establishment of aquatic life criteria (ALC) to be applied in China, including prioritization of chemicals, test species, mode of action, field/semi-field data, and methods <b>of</b> <b>aggregating</b> <b>the</b> <b>information</b> and calculating <b>the</b> ALC. This was used to identify the principle issues that need to be addressed in order to better understand the methods for development <b>of</b> criteria for <b>the</b> protection <b>of</b> aquatic life and provide a reference to China and other developing countries committed to <b>the</b> establishment <b>of</b> their own WQC system...|$|R
40|$|In {{any group}} {{decision-making}} environment, each participant can contribute {{two types of}} decision-relevant information. One type is Shared Information, i. e., information known to all group partici-pants. In a command and control environment, shared information items might include rules of engagement, order of battle, Commander's Intent, the OPLAN, etc. The other type is Unshared Information, i. e., decision-relevant information that is uniquely held by one (or more, but not all) <b>of</b> <b>the</b> group participants. Unshared information can result from either a unique information search path used by a participant during the decision-making task, or from <b>the</b> <b>aggregate</b> <b>of</b> <b>information</b> <b>the</b> participant has acquired from his past experiences and personal contacts. Potentially, unshared infor-mation can impact <b>the</b> pool <b>of</b> shared <b>information</b> by either adding new relevant items to the pool, or by modifying (positively or negatively) the credibility, importance, timeliness, etc., of information items that {{are already in the}} pool. Note that <b>the</b> total amount <b>of</b> <b>information</b> available to <b>the</b> decision-making group is a function of shared information plus unshared information. This is an important point because, as will be demonstrated below, given <b>the</b> existence <b>of</b> unshared <b>information,</b> a rational group choice made without consideration <b>of</b> <b>the</b> unshared <b>information</b> may in fact be dramatically different from the rational choice the group would make if all <b>the</b> unshared <b>information</b> were actuall...|$|R
40|$|The {{ability to}} {{retrieve}} relevant <b>information</b> is at <b>the</b> heart <b>of</b> {{every aspect of}} research and development in the life sciences industry. Information is often distributed across multiple systems and recorded {{in a way that makes}} it difficult to piece together the complete picture. Differences in data formats, naming schemes and network proto-cols amongst information sources, both public and private, must be overcome, and user interfaces not only need to be able to tap into these diverse information sources but must also assist users in filtering out extraneous informa-tion and highlighting the key relationships hidden within an <b>aggregated</b> set <b>of</b> <b>information.</b> <b>The</b> Semantic Web community has made great strides in proposing solutions to these problems, and many efforts are underway to apply Semantic Web techniques to <b>the</b> problem <b>of</b> <b>information</b> retrieval in <b>the</b> life sciences space. This article gives an overview <b>of</b> <b>the</b> principles underlying a Semantic Web-enabled information retrieval system: creating a unified abstraction for knowledge using the RDF semantic network model; designing semantic lenses that extract contex-tually relevant subsets of information; and assembling semantic lenses into powerful information displays. Furthermore, concrete examples of how these principles can be applied to life science problems including a scenario involving a drug discovery dashboard prototype called BioDash are provided...|$|R
40|$|The fuzzy {{integral}} (FI) {{with respect}} to a fuzzy measure (FM) is a powerful means <b>of</b> <b>aggregating</b> <b>information.</b> <b>The</b> most popular FIs are the Choquet and Sugeno, and most research focuses on these two variants. <b>The</b> arena <b>of</b> <b>the</b> FM is much more populated, including numerically derived FMs such as the Sugeno λ-measure and decomposable measure, expert-defined FMs, and data-informed FMs. <b>The</b> drawback <b>of</b> numerically derived and expert-defined FMs is that one must know something about <b>the</b> relative values <b>of</b> <b>the</b> input sources. However, there are many problems where this information is unavailable, such as crowdsourcing. This paper focuses on data-informed FMs, or those FMs that are computed by an algorithm that analyzes some property <b>of</b> <b>the</b> input data itself, gleaning <b>the</b> importance <b>of</b> each input source by the data they provide. <b>The</b> original instantiation <b>of</b> a data-informed FM is the agreement FM, which assigns high confidence to combinations of sources that numerically agree with one another. This paper extends upon our previous work in datainformed FMs by proposing the uniqueness measure and additive measure of agreement for interval-valued evidence. We then extend data-informed FMs to fuzzy number (FN) -valued inputs. We demonstrate the proposed FMs by aggregating interval and FN evidence with the Choquet and Sugeno FIs for both synthetic and real-world data...|$|R
40|$|We {{propose a}} model of {{inference}} and heuristic decision-making in groups that {{is rooted in the}} Bayes rule but avoids <b>the</b> complexities <b>of</b> rational inference in partially observed environments with incomplete information, which are characteristic of group interactions. Our model is also consistent with a dual-process psychological theory <b>of</b> thinking: <b>the</b> group members behave rationally at <b>the</b> initiation <b>of</b> their interactions with each other (the slow and deliberative mode); however, in the ensuing decision epochs, they rely on a heuristic that replicates their experiences from the first stage (the fast automatic mode). We specialize this model to a group decision scenario where private observations are received at the beginning, and agents aim to take the best action given <b>the</b> <b>aggregate</b> observations <b>of</b> all group members. We study <b>the</b> implications <b>of</b> <b>the</b> <b>information</b> structure together with <b>the</b> properties <b>of</b> <b>the</b> probability distributions which determine <b>the</b> structure <b>of</b> <b>the</b> so-called "Bayesian heuristics" that the agents follow in our model. We also analyze the group decision outcomes in two classes of linear action updates and log-linear belief updates and show that many inefficiencies arise in group decisions as a result of repeated interactions between individuals, leading to overconfident beliefs as well as choice-shifts toward extremes. Nevertheless, balanced regular structures demonstrate a measure of efficiency in terms <b>of</b> <b>aggregating</b> <b>the</b> initial <b>information</b> <b>of</b> individuals. These results not only verify some well-known insights about group decision-making but also complement these insights by revealing additional mechanistic interpretations for the group declension-process, as well as psychological and cognitive intuitions about the group interaction model...|$|R
40|$|Abstract—The fuzzy {{integral}} (FI) {{with respect}} to a fuzzy measure (FM) is a powerful means <b>of</b> <b>aggregating</b> <b>information.</b> <b>The</b> most popular FIs are the Choquet and Sugeno and most research focuses on these two variants. <b>The</b> arena <b>of</b> <b>the</b> FM is much more populated, including numerically-derived FMs such as the Sugeno λ-measure and decomposable measure, expert-defined FMs, and data-informed FMs. <b>The</b> drawback <b>of</b> numerically-derived and expert-defined FMs is that one must know something about <b>the</b> relative values <b>of</b> <b>the</b> input sources. However, there are many problems where this information is unavailable, such as crowd-sourcing. This paper focuses on data-informed FMs, or those FMs that are computed by an algorithm that analyzes some property <b>of</b> <b>the</b> input data itself, gleaning <b>the</b> importance <b>of</b> each input source by the data they provide. <b>The</b> original instantiation <b>of</b> a data-informed FM is the agreement FM, which assigns high confidence to combinations of sources that numerically agree with one another. This paper extends upon our previous work in data-informed FMs by proposing the uniqueness measure and additive measure of agreement for interval-valued evidence. We then extend data-informed FMs to fuzzy number (FN) -valued inputs. We demonstrate the proposed FMs by aggregating interval and FN evidence with the Choquet and Sugeno FIs for both synthetic and real-world data. Index Terms—fuzzy measure; fuzzy integral; data fusion; sensor fusion; Sugeno integral; Choquet integral I...|$|R
40|$|This {{paper is}} {{focusing}} on <b>the</b> presentation <b>of</b> statistic exploratory procedures enabling <b>the</b> evaluation <b>of</b> <b>the</b> disparities in regional labour markets in the Czech Republic. Most <b>of</b> <b>the</b> data on labour markets are of multidimensional nature since both employment and unemployment can be described {{by a lot of}} various indicators offered by <b>the</b> Ministry <b>of</b> Labour and Social Affairs <b>of</b> <b>the</b> Czech Republic and by the Czech Statistical Office. An analysis <b>of</b> <b>the</b> data collected hence, has to employ multivariate statistical procedures. <b>The</b> choice <b>of</b> indicators in <b>the</b> study presented has been carried out such that it can represent the phenomena basically affecting <b>the</b> economic position <b>of</b> separate regions. <b>The</b> number <b>of</b> indicators analyzed has been limited by <b>the</b> level <b>of</b> applicability <b>of</b> <b>the</b> multivariate methods <b>of</b> statistical processing chosen. In order to reach <b>the</b> target <b>of</b> <b>the</b> paper <b>the</b> indicators <b>of</b> employment and unemployment have been applied to order the separate CR regions and to identify the regions outlying. To this end a composite indicator has been constructed by the so-called point method, one that is capable <b>of</b> <b>aggregating</b> <b>the</b> <b>information</b> supplied by all the separate indicators considered. <b>The</b> first section <b>of</b> <b>the</b> paper describes <b>the</b> way <b>of</b> construction <b>of</b> this <b>aggregate</b> indicator. In the next section then, some algorithms <b>of</b> <b>the</b> cluster analysis are introduced that have been employed to classify regional labour markets <b>of</b> <b>the</b> CR in more detail...|$|R
40|$|This paper {{introduces}} a vision processing architecture that is directly mappable on a 3 D chip integration technology. Due to <b>the</b> <b>aggregated</b> nature <b>of</b> <b>the</b> <b>information</b> contained in <b>the</b> visual stimulus, adapted architectures are {{more efficient than}} conventional processing schemes. Given the relatively minor importance <b>of</b> <b>the</b> value <b>of</b> an isolated pixel, converting {{every one of them}} to digital prior to any processing is inefficient. Instead of this, our system relies on focal-plane image filtering and key point detection for feature extraction. The originally large amount <b>of</b> data representing <b>the</b> image is now reduced to a smaller number of abstracted entities, simplifying <b>the</b> operation <b>of</b> <b>the</b> subsequent digital processor. There are certain limitations to <b>the</b> implementation <b>of</b> such hierarchical scheme. <b>The</b> incorporation <b>of</b> processing elements close to the photo-sensing devices in a planar technology has a negative influence in the fill factor, pixel pitch and image size. It therefore affects the sensitivity and spatial resolution <b>of</b> <b>the</b> image sensor. A fundamental tradeoff needs to be solved. The larger <b>the</b> amount <b>of</b> processing conveyed to the sensor plane, the larger the pixel pitch. On the contrary, using a smaller pixel pitch sends more processing circuitry to <b>the</b> periphery <b>of</b> <b>the</b> sensor and tightens the data bottleneck between the sensor plane and the memory plane. 3 D integration technologies with a high density of through-silicon-vias can help overcome these limitations. Vertical integration <b>of</b> <b>the</b> sensor plane and the processing and memory planes with a fully parallel connection eliminates data bottlenecks without compromising fill factor and pixel pitch. A case study is presented: a smart vision chip designed on a 3 D integration technology provided by MIT Lincoln Labs, whose base process is 0. 15 μm FD-SOI. Simulation results advance performance improvements with respect to the state-of-the-art in smart vision chips. © 2013 Elsevier B. V. All rights reserved. This work has been supported by <b>the</b> Office <b>of</b> Naval Research (USA) through contracts N 00173 - 08 -C- 4005 and N 000141110312; by <b>the</b> Ministry <b>of</b> Science and Innovation and Ministry of Economy and Competitivity (Spain) through projects TEC 2009 - 11812, TEC 2009 - 12686, IPT- 2011 - 1625 - 430000 and TEC 2012 - 38921 -C 02 - 01, - 02, co-funded by the European Fund for Regional Development; and by Xunta de Galicia (Spain) via project 10 PXIB 206037 PR. Peer Reviewe...|$|R
40|$|Capitulo de livroThe {{knowledge}} management regarding scientific production <b>of</b> <b>the</b> fully employed professors and contributing lecturers of renowned universities is a well-established {{practice in the}} major developed countries. Still, substantial improvements in this field are desirable for high polytechnic schools of Southern Europe. This chapter presents a study on {{knowledge management}} and analyses trends of a scientific production in the economics and finance area at one <b>of</b> <b>the</b> Portuguese high polytechnic school, namely Lisbon Accounting and Business School (LABS). The data collection methodology regarding scientific research outcomes firstly was proposed and implemented at the economics and finance area. This data collection {{was based on the}} direct mail messages addressed to the effective teaching staff members followed by the individual and <b>aggregate</b> analyses <b>of</b> <b>the</b> obtained <b>information</b> regarding published works in <b>the</b> field <b>of</b> economics and finance. <b>The</b> time frame <b>of</b> scientific publications analyses spans over <b>the</b> period <b>of</b> 20 years, namely 1997 - 2016. Later the same methodology was also extended to cover the entire institution. The knowledge management system was implemented in all <b>the</b> knowledge-producing units <b>of</b> LABS. A special database was created to keep the records. It now allows for timely consultation by <b>the</b> administrative bodies <b>of</b> <b>the</b> institution. <b>The</b> main contribution <b>of</b> this study is to demonstrate that the right knowledge management in polytechnic schools is able to unleash hidden potentialities <b>of</b> <b>the</b> capacities evidenced through <b>the</b> implementation <b>of</b> <b>the</b> system <b>of</b> knowledge management. In practical terms, the aggregate results were presented in <b>the</b> form <b>of</b> a report entitled "Creating Knowledge", which was published on <b>the</b> Internet site <b>of</b> <b>the</b> institution. <b>The</b> main findings <b>of</b> this report "Creating Knowledge" were used in <b>the</b> promotion <b>of</b> <b>the</b> LABS towards potential students and represented one <b>of</b> <b>the</b> main factors <b>of</b> fully accomplished enrollment of students for all graduate courses <b>of</b> <b>the</b> LABS for the new academic year beginning in September 2016 at <b>the</b> first stage <b>of</b> <b>the</b> enrollment process. info:eu-repo/semantics/publishedVersio...|$|R
40|$|Traditional studies <b>of</b> {{algorithms}} consider <b>the</b> sequential setting, {{where the}} whole input data is fed {{into a single}} device that computes the solution. Today, the network, such as <b>the</b> Internet, contains <b>of</b> a vast amount <b>of</b> <b>information.</b> <b>The</b> overhead <b>of</b> <b>aggregating</b> all <b>the</b> <b>information</b> into a single device is too expensive, so a distributed approach {{to solve the problem}} is often preferable. In this thesis, we aim to develop efficient algorithms for the following fundamental graph problems that arise in networks, in both sequential and distributed settings. Graph coloring is a basic symmetry breaking problem in distributed computing. Each node is to be assigned a color such that adjacent nodes are assigned different colors. Both the efficiency and <b>the</b> quality <b>of</b> coloring are important measures of an algorithm. One of our main contributions is providing tools for obtaining colorings of good quality whose existence are non-trivial. We also consider other optimization problems in the distributed setting. For example, we investigate efficient methods for identifying the connectivity as well as the bottleneck edges in a distributed network. Our approximation algorithm is almost-tight {{in the sense that the}} running time matches the known lower bound up to a poly-logarithmic factor. For another example, we model how the task allocation can be done in ant colonies, when the ants may have different capabilities in doing different tasks. The matching problems are one <b>of</b> <b>the</b> classic combinatorial optimization problems. We study the weighted matching problems in the sequential setting. We give a new scaling algorithm for finding the maximum weight perfect matching in general graphs, which improves the long-standing Gabow-Tarjan's algorithm (1991) and matches <b>the</b> running time <b>of</b> <b>the</b> best weighted bipartite perfect matching algorithm (Gabow and Tarjan, 1989). Furthermore, for the maximum weight matching problem in bipartite graphs, we give a faster scaling algorithm whose running time is faster than Gabow and Tarjan's weighted bipartite {it perfect} matching algorithm...|$|R
25|$|Automated {{computation}} <b>of</b> {{higher level}} <b>aggregates</b> <b>of</b> <b>the</b> data.|$|R
30|$|Monitoring data {{collected}} by the collection service. Raw data is sent to storage service instances in the same sub-region, <b>aggregates</b> values <b>of</b> <b>the</b> sub-regions resource are sent to neighbouring regions and <b>aggregates</b> <b>of</b> <b>the</b> entire region are sent to other regions.|$|R
5000|$|The {{race was}} run over 2 heats of 26 laps each, {{the final results}} being an <b>aggregate</b> <b>of</b> <b>the</b> two.|$|R
5000|$|In {{frequency-division}} multiplexing, {{the frequency}} band occupied by <b>the</b> <b>aggregate</b> <b>of</b> <b>the</b> signals {{in the line}} interconnecting the multiplexing and radio or line equipment.|$|R
50|$|Living in Buenos Aires, Argentina, {{where he}} {{performed}} diplomatic shows in <b>the</b> Cultural <b>Aggregate</b> <b>of</b> <b>the</b> Paraguayan Embassy in Buenos Aires, {{he died in}} May 2004.|$|R
50|$|Final (1 August) - Divers {{performed}} four voluntary dives {{without any}} limits <b>of</b> difficulty. <b>The</b> final score was <b>the</b> <b>aggregate</b> <b>of</b> <b>the</b> preliminary and final rounds' points.|$|R
50|$|In 1884 Condell was {{designated}} as an <b>aggregate</b> <b>of</b> <b>the</b> Ministry <b>of</b> <b>the</b> Seas (Ministerio de Marina) {{and put in}} charge <b>of</b> <b>the</b> armoured frigate Cochrane as Commodore.|$|R
50|$|The 1992 Ashes {{series was}} the final Ashes series to date played in Australia and {{attracted}} 103,459 spectators over the three tests. This compared favourably to <b>the</b> 75,480 <b>aggregate</b> <b>of</b> <b>the</b> 1984 Ashes series in Australia and <b>the</b> 67,554 <b>aggregate</b> <b>of</b> <b>the</b> 1988 series in Australia. A large number of English fans followed their team on the tour, but with Great Britain's wins in <b>the</b> final test <b>of</b> 1988 and <b>the</b> first test <b>of</b> <b>the</b> 1990 series, public interest had risen with Australia, although still winning, proving less dominant than during the 1980's.|$|R
50|$|Petty, S.A. and Decatur, S.M. (2005) “Experimental Evidence for <b>the</b> Reorganization <b>of</b> β-Strands within <b>Aggregates</b> <b>of</b> <b>the</b> Aβ (16-22) Peptide,” <b>The</b> Journal <b>of</b> <b>the</b> American Chemical Society 127: 13488-13489.|$|R
50|$|Section 7 {{provides}} that <b>the</b> rateable value <b>of</b> <b>the</b> land leased under an applicable lease is an <b>aggregate</b> <b>of</b> <b>the</b> rateable values <b>of</b> <b>the</b> tenements comprised {{in the land}} leased.|$|R
30|$|Cd and Pb existed {{mainly in}} the {{micro-aggregate}} and colloid and that their chemical fractions were {{closely related to the}} chemical properties in soil <b>aggregates</b> <b>of</b> <b>the</b> polluted farmland.|$|R
50|$|Capt Barclay {{had a large}} sum {{depending}} upon his undertaking. <b>The</b> <b>aggregate</b> <b>of</b> <b>the</b> bets is supposed to amount to £100,000.—He commenced his feat on <b>the</b> first <b>of</b> June.|$|R
40|$|An {{in vitro}} model is {{presented}} to test <b>the</b> invasiveness <b>of</b> human brain tumour derived cells. Spheroids of brain tumours are confronted with autologous spheroids of human dermal fibroblasts. <b>Aggregates</b> <b>of</b> seven tested brain tumours, respectively 5 benign and 2 malignant ones are confronted for 7 days in vitro. <b>The</b> <b>aggregates</b> <b>of</b> <b>the</b> malignant tumours do invade into the dermal spheroids and progressive replacement <b>of</b> <b>the</b> dermal <b>aggregate</b> is observed. <b>The</b> <b>aggregates</b> <b>of</b> <b>the</b> benign tumours do not invade, a clearcut border between the tumour compartment and the dermal one is seen. This model will be applied for clinical testing <b>of</b> <b>the</b> invasiveness <b>of</b> selected tumours and will offer a good model to study mechanisms of invasion...|$|R
50|$|In {{addition}} to each individual match, {{there are several}} aggregate matches, including aggregates {{for each type of}} arm, as well as <b>the</b> Grand <b>Aggregate</b> <b>of</b> <b>the</b> musket, carbine, and revolver matches.|$|R
50|$|Two {{different}} methods are explained as being right-hand (the amount you directly attribute to an action) and left-hand (an <b>aggregate</b> <b>of</b> <b>the</b> right-hand Whuffie <b>of</b> <b>the</b> {{people who have}} given you left-hand).|$|R
5000|$|The most simple {{representation}} for availability is as a ratio <b>of</b> <b>the</b> {{expected value}} <b>of</b> <b>the</b> uptime <b>of</b> {{a system to}} <b>the</b> <b>aggregate</b> <b>of</b> <b>the</b> expected values <b>of</b> up and down time, or ...|$|R
