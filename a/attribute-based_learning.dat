8|11|Public
40|$|Techniques {{of machine}} {{learning}} {{have been successfully}} applied to various problems [1, 12]. Most of these applications rely on <b>attribute-based</b> <b>learning,</b> exemplified by the induction of decision trees as in the pro-gram C 4. 5 [20]. Broadly speaking, <b>attribute-based</b> <b>learning</b> also includes such approaches to learning as neural networks and nearest neighbor techniques. The advantages of <b>attribute-based</b> <b>learning</b> are: relative simplicity, efficiency, and existence of effective techniques for handling noisy data. However, <b>attribute-based</b> <b>learning</b> is limited to non-relational descriptions of objects {{in the sense that}} the learned descriptions do not specify relations among the objects ’ parts. <b>Attribute-based</b> <b>learning</b> thus has two strong limitations: • the background knowledge can be expressed in rather limited form, and • the lack of relations makes the concept description language inappropri-ate for some domains. Examples of such domains are presented in this article. An attempt to overcome the limitations of <b>attribute-based</b> <b>learning</b> has led to recent development of a number of programs that learn at the level of first-order predicate logic. These include FOIL [19], Golem [17], and Progol [22], with Shapiro’s program MIS as one of their early predecessors [21]. This has led to the inception of a new area of machine learning called Inductive Logic Programming [13]. For recent developments see [14]. ILP benefits from the solid theoretical framework provided by logic and logic programming. The learning problem in ILP is normally stated as follows: given back-ground knowledge B, expressed as a set of predicate definitions, positive exam-AIadvances in traditional A...|$|E
40|$|A {{cognitive}} robot {{may face}} failures during {{the execution of}} its actions in the physical world. In this paper, we investi-gate how robots can ensure robustness by gaining experience on action executions, and we propose a lifelong experimen-tal learning method. We use Inductive Logic Programming (ILP) as the learning method to frame new hypotheses. ILP provides first-order logic representations of the derived hy-potheses that are useful for reasoning and planning processes. Furthermore, it can use background knowledge to represent more advanced rules. Partially specified world states can also be easily represented in these rules. All these advantages of ILP make this approach superior to <b>attribute-based</b> <b>learning</b> approaches. Experience gained through incremental learning {{is used as a}} guide to future decisions of the robot for robust execution. The results on our Pioneer 3 DX robot reveal that the hypotheses framed for failure cases are sound and ensure safety in future tasks of the robot...|$|E
40|$|International audienceProbabilistic Relational Models (PRMs) are {{directed}} probabilistic graphical models representing a factored joint distribution over {{a set of}} random variables for relational datasets. While regular PRMs define probabilistic dependencies be- tween classes’ descriptive attributes, an extension called PRM with Reference Uncertainty (PRM-RU) allows in addition to manage link uncertainty between them, by adding random variables called selectors. In order to avoid variables with large domains, selectors are associated with partition functions, mapping objects {{to a set of}} clusters, and selectors’ distributions are defined over the set of clusters. In PRM-RU, the definition of partition functions constrains us to learn them only from concerned individuals entity attributes and to assign the same cluster to a pair of individuals having the same attributes values. This constraint is actually based on a strong assumption which is not generalizable and can lead to an under usage of relationship data for learning. For these reasons, we relax this constraint in this paper and propose a different partition function learning approach based on relationship data clustering. We empirically show that this approach provides better results than <b>attribute-based</b> <b>learning</b> in the case where relationship topology is independent from involved entity attributes values, and that it gives close results whenever the attributes assumption is correct...|$|E
40|$|One {{transfer}} learning {{approach that}} {{has gained a}} wide popularity lately is <b>attribute-based</b> zero-shot <b>learning.</b> Its goal is to learn novel classes that were never seen during the training stage. The classical route towards realizing this goal is to incorporate a prior knowledge, {{in the form of}} a semantic embedding of classes, and to learn to predict classes indirectly via their semantic attributes. Despite the amount of research devoted to this subject lately, no known algorithm has yet reported a predictive accuracy that could exceed the accuracy of supervised learning with very few training examples. For instance, the direct attribute prediction (DAP) algorithm, which forms a standard baseline for the task, is known to be as accurate as supervised learning when as few as two examples from each hidden class are used for training on some popular benchmark datasets! In this paper, we argue that this lack of significant results in the literature is not a coincidence; <b>attribute-based</b> zero-shot <b>learning</b> is fundamentally an ill-posed strategy. The key insight is the observation that the mechanical task of predicting an attribute is, in fact, quite different from the epistemological task of learning the “correct meaning” of the attribute itself. This renders <b>attribute-based</b> zero-shot <b>learning</b> fundamentally ill-posed. In more precise mathematical terms, <b>attribute-based</b> zero-shot <b>learning</b> is equivalent to the mirage goal of learning with respect to one distribution of instances, with the hope of being able to predict with respect to any arbitrary distribution. We demonstrate this overlooked fact on some synthetic and real datasets. The data and software related to this paper are available at [URL] kaust. edu. sa/Pages/zero-shot-learning. aspx. © Springer International Publishing AG 2016...|$|R
30|$|Moreover, as novel problems, {{we attempt}} tasks of {{predicting}} and classifying vessel attributes: draught, gross tonnage, length, and summer deadweight. The objective {{here is to}} quantify these attributes based on 2 -D visual content only, which may ameliorate the practicality of coastal surveillance systems, since that avoids the need for retaining meta-data for optical systems, namely camera parameters, camera position, and distance to the vessel, while estimating physical dimensions of a vessel based on its appearance. Another beneficial use of this task may be for safe marine traffic routing {{as well as for}} the calculation of port access and transit fees, when vessel dimensions need to be known. Furthermore, there are studies, proving that presence of attribute-based representations are helpful for several computer vision tasks including object recognition [16], detection [17], and identification [18]. The <b>attribute-based</b> <b>learned</b> representations for marine vessels in this work may be utilized in a similar fashion aiding other visual analysis tasks.|$|R
40|$|Most of {{the data}} mining methods in {{real-world}} intelligent systems are <b>attribute-based</b> machine <b>learning</b> methods such as neural networks, nearest neighbors and decision trees. They are relatively simple,- efficient, and can handle noisy data. However, these methods have two strong limitations: (1) the background knowledge can be expressed in rather limited form and (2) the lack of relations other than “object-attribute ” makes the concept description language inappropriate for some applications. Relational and hybrid data mining methods based on first-order logic are compared with Neural Networks and other benchmark methods on different data sets. These computational experiments show several advantages of relational and hybrid methods...|$|R
40|$|Attribute-based {{recognition}} models, due {{to their}} impressive performance {{and their ability to}} generalize well on novel categories, have been widely adopted for many computer vision applications. However, usually both the attribute vocabulary and the class-attribute associations have to be provided manually by domain experts or large number of annotators. This is very costly and not necessarily optimal regarding recognition performance, and most importantly, it limits the applicability of attribute-based models to large scale data sets. To tackle this problem, we propose an end-to-end unsupervised attribute learning approach. We utilize online text corpora to automatically discover a salient and discriminative vocabulary that correlates well with the human concept of semantic attributes. Moreover, we propose a deep convolutional model to optimize class-attribute associations with a linguistic prior that accounts for noise and missing data in text. In a thorough evaluation on ImageNet, we demonstrate that our model is able to efficiently discover and learn semantic attributes at a large scale. Furthermore, we demonstrate that our model outperforms the state-of-the-art in zero-shot learning on three data sets: ImageNet, Animals with Attributes and aPascal/aYahoo. Finally, we enable <b>attribute-based</b> <b>learning</b> on ImageNet and will share the attributes and associations for future research. Comment: Accepted as a conference paper at CVPR 201...|$|E
40|$|Understanding {{image and}} video {{is one of}} the {{fundamental}} problems in the field of computer vision. Traditionally, the research in this area focused on extracting low level features from images and videos and learning classifiers to categorize these features to pre-defined classes of objects, scenes or activities. However, {{it is well known that}} there exists a ``semantic gap'' between low level features and high level semantic concepts, which greatly obstructs the progress of research on image and video understanding. Our work departs from the traditional view of image and video understanding in that we add a middle layer between high level concepts and low level features, which is called as attribute, and use this layer to facilitate the description of concepts and detection of entities from images and videos. On one hand, attributes are relatively simple and thus can be more reliably detected from the low level features; on the other hand, we can exploit high level knowledge about the relationship between the attributes and the high level concepts and the relationship among attributes, and therefore reduce the semantic gap. Our ideas are demonstrates in three applications as follows: First, we presented an <b>attribute-based</b> <b>learning</b> approach for object recognition, where attributes are used to transfer knowledge on object properties from known classes to unknown classes and consequently reduce the number of training examples needed to learn the new object classes. Next, we illustrate an active framework to recognize scenes based on the objects therein, which are considered as the attributes of the scenes. The active framework utilizes the correlation among objects in a scene and thus significantly reduces the number of objects to be detected in order to recognize the scene. Finally, we propose a novel approach to detect the activity attributes from sports videos, where the contextual constraints are explored to decrease the ambiguity in attribute detection. The activity attributes enable us to go beyond naming the activity categories and achieve a fine-grained description of the activities in the videos...|$|E
40|$|Both the {{learning}} model and {{the learning}} process of CSPL are customized to different query instances. CSPL can {{make use of the}} characteristics of the query instance to explore a focused hypothesis space effectively during classification. Unlike many existing learning methods, CSPL conducts learning from specific to general, effectively avoiding the horizon effect. Empirical investigation demonstrates that learning from specific to general can discover more useful patterns for learning. Experimental results on benchmark data sets and real-world problems demonstrate that our CSPL framework has a prominent learning performance in comparison with existing learning rnethods. CSPL integrates the attributes and instances in a query matrix model under customized learning framework. Within this query matrix model, it can be demonstrated that attributes and instances have a useful symmetry property for learning. This symmetry property leads to a solution for counteracting the negative factor of sparse instances with the abundance of attribute information, which was previously viewed as a kind of dimension curse for common learning methods. Given this symmetry property, we propose to use support patterns as the basic learning unit of CSPL, i. e., the patterns to be explored. Generally, a support pattern {{can be viewed as a}} sub-matrix of the query matrix, considering its associated support instances and attribute values. CSPL discovers useful support patterns and combines their statistics for classifying unseen instances. The developing of machine learning techniques still has a number of challenges. Real world problems often require a more flexible and dynamic learning method, which is customized to the learning scenario and user demand. For example, it is quite often in real-world applications to make a critical decision with only limited data but huge amount of potentially relevant attributes. Therefore, we propose a novel customized learning framework called Customized Support Pattern Learner (CSPL), which exploits a tradeoff between instance-based learning and <b>attribute-based</b> <b>learning.</b> Han Yiqiu. "October 2005. "Adviser: Wai Lam. Source: Dissertation Abstracts International, Volume: 67 - 07, Section: B, page: 3898. Thesis (Ph. D.) [...] Chinese University of Hong Kong, 2005. Includes bibliographical references (p. 99 - 104). Electronic reproduction. Hong Kong : Chinese University of Hong Kong, [2012] System requirements: Adobe Acrobat Reader. Available via World Wide Web. Electronic reproduction. [Ann Arbor, MI] : ProQuest Information and Learning, [200 -] System requirements: Adobe Acrobat Reader. Available via World Wide Web. Abstract in English and Chinese. School code: 1307...|$|E
40|$|We {{review the}} notion of {{polynomial}} learnability (Valiant, 1984) for unrestricted DNF and present an alternative notion of the problem-specific incremental learnability (Oblow, 1992) of unrestricted DNF. We then present an incremental, polynomial-time algorithm for inducing disjunctive normal form representations, for propositional concepts, from positive and negative examples described in an attribute-based formalism, and show that this satisfies learnability criteria for distribution-specific problems as examples are sampled. Having established a theoretical basis for learnability we then describe a learning system that uses this algorithm to learn DNF from noisy, and inconsistent data, which may be {{described in terms of}} both Boolean and symbolic attributes. We empirically compare our system with a number of well known inductive classifier systems on some benchmark problems. 1 Contents 1 Introduction 3 2 Research Goals 3 3 The Problem 3 3. 1 <b>Attribute-based</b> Inductive <b>Learn</b> [...] ...|$|R
40|$|Machine {{learning}} {{is the basis}} of important advances in artificial intelligence. Unlike the general methods of machine learning, which use the same tasks for training and testing, the method of transfer learning uses different tasks to learn a new task. Among the various transfer learning algorithms in the literature, we focus on the <b>attribute-based</b> transfer <b>learning.</b> This algorithm realizes transfer learning by introducing attributes and transferring the results of training to another task with the common attributes. However, the existing method does not consider the frequency in which each attribute appears in feature vectors (called the observation probability). In this paper, we present a generative model with the observation probability. By the experiments, we show that the proposed method has achieved a higher accuracy rate than the existing method. Moreover, we see that it makes possible the incremental learning that was impossible in the existing method...|$|R
40|$|Abstract. There is much {{empirical}} {{evidence about the}} success of naive Bayesian classification (NBC) in medical applications of <b>attribute-based</b> machine <b>learning.</b> NBC assumes conditional independence between attributes. In classification, such classifiers sum up the pieces of classrelated evidence from individual attributes, independently of other attributes. The performance, however, deteriorates significantly when the “interactions ” between attributes become critical. We propose an approach to handling attribute interactions {{within the framework of}} “voting” classifiers, such as NBC. We propose an operational test for detecting interactions in learning data and a procedure that takes the detected interactions into account while learning. This approach induces a structuring of the domain of attributes, it may lead to improved classifier’s performance and may provide useful novel information for the domain expert when interpreting the results of learning. We report on its application in data analysis and model construction for the prediction of clinical outcome in hip arthroplasty. ...|$|R
40|$|The {{mission of}} the {{research}} presented in this thesis is to give computers the power to sense and react to human activities. Without the ability to sense the surroundings and understand what humans are doing, computers {{will not be able}} to provide active, timely, appropriate, and considerate services to the humans. To accomplish this mission, the work stands on the shoulders of two giants: Machine learning and ubiquitous computing. Because of the ubiquity of sensor-enabled mobile and wearable devices, there has been an emerging opportunity to sense, learn, and infer human activities from the sensor data by leveraging state-of-the-art machine learning algorithms. While having shown promising results in human activity recognition, most existing approaches using supervised or semi-supervised learning have two fundamental problems. Firstly, most existing approaches require a large set of labeled sensor data for every target class, which requires a costly effort from human annotators. Secondly, an unseen new activity cannot be recognized if no training samples of that activity are available in the dataset. In light of these problems, a new approach in this area is proposed in our research. This thesis presents our novel approach to address the problem of human activity recognition when few or no training samples of the target activities are available. The main hypothesis is that the problem can be solved by the proposed NuActiv activity recognition framework, which consists of modeling the hierarchical and sequential structure of human activities, as well as bringing humans in the loop of model training. By injecting human knowledge about the hierarchical nature of human activities, a semantic attribute representation and a two-layer <b>attribute-based</b> <b>learning</b> approach are designed. To model the sequential structure, a probabilistic graphical model is further proposed to take into account the temporal dependency of activities and attributes. Finally, an active learning algorithm is developed to reinforce the recognition accuracy using minimal user feedback. The hypothesis and approaches presented in this thesis are validated by two case studies and real-world experiments on exercise activities and daily life activities. Experimental results show that the NuActiv framework can effectively recognize unseen new activities even without any training data, with up to 70 - 80 % precision and recall rate. It also outperforms supervised learning with limited labeled data for the new classes. The results significantly advance the state of the art in human activity recognition, and represent a promising step towards bridging the gap between computers and humans...|$|E
40|$|The {{merits of}} {{incorporating}} feature construction to assist selective induction in learning hard concepts are well documented. This paper introduces {{the notion of}} function attributes and reports a method of incorporating functional regularities in classifiers. Training sets are preprocessed with this method before submission to a selective induction classification learning system. The method, referred to as FAFA (function attribute finding), is characterised by finding bivariate functions {{that contribute to the}} discrimination between classes and then transforming them to function attributes as additional attributes of the data set. The value of each function attribute equals the deviation of each example from the value obtained by applying that function to the example. The expanded data set is then submitted to classification learning. Evaluation with published and artificial data shows that this method can improve classifiers in terms of predictive accuracy and complexity. Selective-induction or <b>attribute-based</b> classification <b>learning</b> techniques perform poorly when the attributes are inappropriate for the target classifiers. One solution is to have the learning syste...|$|R
40|$|We {{present a}} new {{approach}} to <b>learning</b> <b>attribute-based</b> descriptions of objects. Unlike earlier works, we do not assume that the descriptions are hand-labeled. Instead, our approach jointly learns both the attribute classifiers and the descriptions from data. By incorporating class information into the attribute classifier learning, we get an attributelevel representation that generalizes well to both unseen examples of known classes and unseen classes. We consider two different settings, one with unlabeled images available for learning, and another without. The former corresponds to a novel transductive setting where the unlabeled images can come from new classes. Results from Animals with Attributes and a-Yahoo, a-Pascal benchmark datasets show that the learned representations give similar or even better accuracy than the hand-labeled descriptions. 1...|$|R
40|$|In this diploma thesis {{we tried}} to create rain {{forecasts}} {{with the use of}} data obtained by combining numerical meteorological information with information gathered from radar images of rain activity. We have combined the two groups of data by partitioning the radar images into equally sized cells, which were then assigned a numerical value based on the prevailing degree of rainfall inside the cells. This is in an appropriate format of attributes in the models used to make the forecasts. The combined set of data was then split into a learning and a testing set and we have tried to make the most accurate forecasts possible with the use of selected <b>attribute-based</b> machine <b>learning</b> methods. The following methods were used: decision trees, KNN, naive Bayesan classifier and regression trees. The best results were obtained by the decision trees and by the KNN algorithm. Regression trees were compared with other methods by discretizing their results which revealed that they were not as accurate as decision trees and the KNN algorithm. The naive Bayesan classifier also proved to be less adequate for use on this type of data. Beside the already existing methods of machine learning we also developed a set of methods which divide the area covered by the radar images into regions, thus enabling us {{to take into account the}} local weather characteristics of various parts of Slovenia. We assess the results of regional division as good, but there are still many possibilities for improvement to be researched in the future. ...|$|R
40|$|A visual {{instance}} is a visually unique entity (e. g., Brooklyn bridge), or {{a set of}} entities with identical visual {{appearance and}} hence not visually distinguishable (e. g., a Miffy doll with many identical copies). The same instance may vary tremendously in appearance in different images due to self-deformation, occlusion, illumination variations, viewpoint change and other recording factors. This thesis is dedicated to visual instance search from one example. Given one image of an instance, {{the goal is to}} retrieve all the images of the same instance, regardless of the appearance variations in different recordings. The main findings are as follows. 1) Localized search by evaluating multiple local boxes in the image is advantageous, as the spatial extent of an instance is often limited to a portion of an image and the signal-to-noise ratio within the box is higher than in the entire image. 2) A strict matching on local details is helpful for one-sided instances with limited viewpoint variations, e. g., logos, but not suited for multi-sided instances like shoes, when photographed from every possible viewing angle. 3) The <b>attribute-based</b> method, which <b>learns</b> a set of visual aspects, is generically applicable to both one-sided and multi-sided instances. The learned aspects are invariant to recording factors and discriminative among different instances. These aspects are generalizable to previously unseen instances. 4) Tracking, when provided with a powerful similarity metric, can be addressed as an instance search problem where the initial target in the starting frame is considered as the query...|$|R

