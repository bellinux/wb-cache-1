1850|3611|Public
25|$|A full ToBI {{transcription}} {{includes not}} only the above phonological elements, but also the <b>acoustic</b> <b>signal</b> on which the transcription is based. The ToBI system {{is intended to be}} used in computer-based transcription.|$|E
25|$|The sensory {{part of a}} neurocomputational {{model of}} speech {{processing}} starts with an <b>acoustic</b> <b>signal</b> of a speech item (acoustic speech signal), generates an auditory representation for that signal and activates a phonemic representations for that speech item.|$|E
25|$|The {{process of}} speech {{perception}} {{is not necessarily}} uni-directional. That is, higher-level language processes connected with morphology, syntax, or semantics may interact with basic speech perception processes to aid in recognition of speech sounds. It {{may be the case}} that it is not necessary and maybe even not possible for a listener to recognize phonemes before recognizing higher units, like words for example. After obtaining at least a fundamental piece of information about phonemic structure of the perceived entity from the <b>acoustic</b> <b>signal,</b> listeners can compensate for missing or noise-masked phonemes using their knowledge of the spoken language.|$|E
40|$|Social {{interactions}} among individuals are often mediated through <b>acoustic</b> <b>signals.</b> If <b>acoustic</b> <b>signals</b> are consistent {{and related to}} an individual’s personality, these consistent individual differences in signalling {{may be an important}} driver in social interactions. However, few studies in nonhuman mammals have investigated the relationship between <b>acoustic</b> <b>signalling</b> and personality. Here we show that <b>acoustic</b> <b>signalling</b> rate is repeatable and strongly related to personality in a highly social mammal, the domestic pig (Sus scrofa domestica). Furthermore, <b>acoustic</b> <b>signalling</b> varied between environments of differing quality, with males from a poor-quality environment having a reduced vocalization rate compared with females and males from an enriched environment. Such differences may be mediated by personality with pigs from a poor-quality environment having more reactive and more extreme personality scores compared with pigs from an enriched environment. Our results add to the evidence that <b>acoustic</b> <b>signalling</b> reﬂects personality in a nonhuman mammal. Signals reﬂecting personalities may have far reaching consequences in shaping the evolution of social behaviours as acoustic communication forms an integral part of animal societies...|$|R
40|$|Vibration and <b>acoustic</b> <b>signals</b> {{generated}} by turbochargers need different signal processing methods {{to be effective}} and faultless in turbochargers diagnostics. Diagnostic methods which based on vibration and <b>acoustic</b> <b>signals</b> analysis are sensitive on engine load and speed changes. Methods {{presented in this paper}} based on vibration and <b>acoustic</b> <b>signals</b> processing in time and frequency domain. Using this methods checking technical condition of the turbochargers and its rotors and bearings without stopping the engine and dismantling it is possible...|$|R
40|$|This paper proposes an {{underwater}} positioning system built with sensors distributed over the submarine infrastructure {{responsible for the}} oil production, which will be located by trilateration of <b>acoustic</b> <b>signals</b> emitted by units (vessels and platforms) with known coordinates. However, the <b>acoustic</b> <b>signals</b> needed to the calculation of the position depend on the vessels within sensors range. Thus, this work investigates the system behavior, analyzing the <b>acoustic</b> <b>signals</b> available for sensors using the ONE (Opportunistic Network Environment) simulator and scenarios based on the Brazilian offshore oil exploration area...|$|R
25|$|For speech perception, {{the model}} starts with an {{external}} <b>acoustic</b> <b>signal</b> (e.g. produced by an external speaker). This signal is preprocessed, passes the auditory map, {{and leads to}} an activation pattern for each syllable or word {{on the level of}} the auditory-phonetic processing module (ES: external signal, see Fig. 5). The ventral path of speech perception (see Hickok and Poeppel 2007) would directly activate a lexical item, but is not implemented in ACT. Rather, in ACT the activation of a phonemic state occurs via the phonemic map and thus may lead to a coactivation of motor representations for that speech item (i.e. dorsal pathway of speech perception; ibid.).|$|E
25|$|The direct realist {{theory of}} speech {{perception}} (mostly associated with Carol Fowler) {{is a part}} of the more general theory of direct realism, which postulates that perception allows us to have direct awareness of the world because it involves direct recovery of the distal source of the event that is perceived. For speech perception, the theory asserts that the objects of perception are actual vocal tract movements, or gestures, and not abstract phonemes or (as in the Motor Theory) events that are causally antecedent to these movements, i.e. intended gestures. Listeners perceive gestures not by means of a specialized decoder (as in the Motor Theory) but because information in the <b>acoustic</b> <b>signal</b> specifies the gestures that form it. By claiming that the actual articulatory gestures that produce different speech sounds are themselves the units of speech perception, the theory bypasses the problem of lack of invariance.|$|E
25|$|In general {{there are}} two ways to set up a {{transducer}} system to measure the sound velocity in a solid. One is a setup with two or more transducers where one is acting as a transmitter, while the other(s) is acting as a receiver. The sound velocity measurement can then be done by measuring the time between a signal is generated at the transmitter and when it is recorded at the receiver while assuming to know (or measure) the distance the <b>acoustic</b> <b>signal</b> have traveled between the transducers, or conversely to measure the resonance frequency knowing the thickness over which the wave resonate. The other type of setup is often called a pulse-echo system. Here one transducer is placed in the vicinity of the specimen acting both as transmitter and receiver. This requires a reflective interface where the generated signal can be reflected back toward the transducer which then act as a receiver recording the reflected signal. See ultrasonic testing for some measurement systems.|$|E
40|$|This article {{discusses}} {{a system}} of recognition of <b>acoustic</b> <b>signals</b> of loaded synchronous motor. This software can recognize various types of incipient failures by means of analysis of the <b>acoustic</b> <b>signals.</b> Proposed approach uses the <b>acoustic</b> <b>signals</b> generated by loaded synchronous motor. A plan of study of the <b>acoustic</b> <b>signals</b> of loaded synchronous motor is proposed. Studies include following states: healthy loaded synchronous motor, loaded synchronous motor with shorted stator coil, loaded synchronous motor with shorted stator coil and broken coil, loaded synchronous motor with shorted stator coil and two broken coils. The methods such as FFT, method of selection of amplitudes of frequencies (MSAF- 5), Linear Support Vector Machine were used to identify specific state of the motor. The proposed approach can keep high recognition rate and reduce the maintenance cost of synchronous motors...|$|R
40|$|High-Level music {{descriptors}} are key {{ingredients for}} music information retrieval systems. Although {{there is a}} long tradition in extracting information from <b>acoustic</b> <b>signals,</b> the field of music information extraction is largely heuristic in nature. We present here a heuristic-based generic approach for extracting automatically high-level music descriptors from <b>acoustic</b> <b>signals...</b>|$|R
50|$|Orifice plate {{which can}} {{function}} as a mechanical clipper for <b>acoustic</b> <b>signals.</b>|$|R
25|$|Cochlear {{implantation}} restores {{access to}} the <b>acoustic</b> <b>signal</b> in individuals with sensorineural hearing loss. The acoustic information conveyed by an implant is usually sufficient for implant users to properly recognize speech of people they know even without visual clues. For cochlear implant users, {{it is more difficult}} to understand unknown speakers and sounds. The perceptual abilities of children that received an implant after the age of two are significantly better than of those who were implanted in adulthood. A number of factors have been shown to influence perceptual performance, specifically: duration of deafness prior to implantation, age of onset of deafness, age at implantation (such age effects {{may be related to the}} Critical period hypothesis) and the duration of using an implant. There are differences between children with congenital and acquired deafness. Postlingually deaf children have better results than the prelingually deaf and adapt to a cochlear implant faster. In both children with cochlear implants and normal hearing, vowels and voice onset time becomes prevalent in development before the ability to discriminate the place of articulation. Several months following implantation, children with cochlear implants can normalize speech perception.|$|E
2500|$|This is an {{electronic}} or fiberoptic sensor to provide continuous monitoring of downhole pressure and temperature. Gauges either use a 1/4" [...] control line clamped onto {{the outside of}} the tubing string to provide an electrical or fiberoptic communication to surface, or transmit measured data to surface by <b>acoustic</b> <b>signal</b> in the tubing wall.|$|E
2500|$|A {{source of}} {{evidence}} to assist in locating the final resting place of the aircraft is analysis of underwater sound recordings. If the aircraft hit the ocean hard, hydroacoustic recordings could have potentially recorded an impact event. Furthermore, the aircraft's flight data recorders were fitted with underwater [...] "pingers", which emit a detectable, pulsating <b>acoustic</b> <b>signal</b> that could have potentially led searchers to their locations.|$|E
500|$|Whales emit two {{distinct}} kinds of <b>acoustic</b> <b>signals,</b> which are called whistles and clicks: ...|$|R
30|$|This section {{provides}} an introduction into {{the problem of}} blind separation of <b>acoustic</b> <b>signals.</b>|$|R
2500|$|Dolphins emit two {{distinct}} kinds of <b>acoustic</b> <b>signals,</b> which are called whistles and clicks: ...|$|R
2500|$|ADVOceanShield {{was sent}} to the search area with two Phoenix International TPL-25 towed pinger {{locators}} (also known as [...] "towfish"). Shortly after one of the towfish was deployed, while descending, an <b>acoustic</b> <b>signal</b> was detected at a frequency of 33kHz on 5 April. Further detections were made on 5 April and on 8 April, but none could be detected when the ship passed the same location on an opposing heading.|$|E
2500|$|During {{babbling}} the synaptic projections between sensory error {{maps and}} motor map are tuned. This training {{is done by}} generating an amount of semi-random feedforward commands, i.e. the DIVA model [...] "babbles". Each of these babbling commands leads {{to the production of}} an [...] "articulatory item", also labeled as [...] "pre-linguistic (i.e. non language-specific) speech item" [...] (i.e. the articulatory model generates an articulatory movement pattern {{on the basis of the}} babbling motor command). Subsequently an <b>acoustic</b> <b>signal</b> is generated.|$|E
2500|$|On {{the basis}} of the articulatory and <b>acoustic</b> <b>signal,</b> a {{specific}} auditory and somatosensory state pattern is activated {{at the level of the}} sensory state maps (see Fig. 4) for each (pre-linguistic) speech item. At this point the DIVA model has available [...] the sensory and associated motor activation pattern for different speech items, which enables the model to tune the synaptic projections between sensory error maps and motor map. Thus, during babbling the DIVA model learns feedback commands (i.e. how to produce a proper (feedback) motor command for a specific sensory input).|$|E
50|$|Bats may detect <b>acoustic</b> <b>signals</b> from dish-shaped bracts such {{as those}} of Marcgravia evenia.|$|R
5000|$|Dolphins emit two {{distinct}} kinds of <b>acoustic</b> <b>signals,</b> which are called whistles and clicks: ...|$|R
30|$|For <b>acoustic</b> <b>signals,</b> {{we noticed}} good results for {{instantaneous}} mixture and bad ones for convolutive mixtures.|$|R
2500|$|Other {{acoustics}} {{activities in}} the ocean {{may not be so}} benign insofar as marine mammals are concerned. [...] Various types of man-made sounds have been studied as potential threats to marine mammals, such as airgun shots for geophysical surveys, or transmissions by the U.S. Navy for various purposes. [...] The actual threat depends on a variety of factors beyond noise levels: [...] sound frequency, frequency and duration of transmissions, the nature of the <b>acoustic</b> <b>signal</b> (e.g., a sudden pulse, or coded sequence), depth of the sound source, directionality of the sound source, water depth and local topography, reverberation, etc.|$|E
2500|$|To be able {{to measure}} the sound velocity, and more {{specifically}} the change in sound velocity, in a material subjected to some stress state, one can measure the velocity of an <b>acoustic</b> <b>signal</b> propagating through the material in question. There are several methods to do this {{but all of them}} utilise one of two physical relations of the sound velocity. The first relation is related to the time it takes a signal to propagate from one point to another (typically the distance between two acoustic transducers or two times the distance from one transducer to a reflective surface). This {{is often referred to as}} [...] "Time-of-flight" [...] (TOF) measurements, and utilise the relation ...|$|E
2500|$|Acoustics. This system {{consists}} {{of one or}} more transponders placed on the seabed and a transducer placed in the ship's hull. The transducer sends an <b>acoustic</b> <b>signal</b> (by means of piezoelectric elements) to the transponder, which is triggered to reply. As the velocity of sound through water is known (preferably a soundprofile is taken regularly), the distance is known. Because there are many elements on the transducer, the direction of the signal from the transponder can be determined. Now the position of the ship relative to the transponder can be calculated. Disadvantages are the vulnerability to noise by thrusters or other acoustic systems. The use is limited in shallow waters because of ray bending that occurs when sound travels through water horizontally. Three types of HPR systems are commonly used: ...|$|E
40|$|MS. number: A 12 - 00758 R etw als is <b>Acoustic</b> <b>signals</b> {{have been}} {{particularly}} well studied as a species recognition signal, yet research on species discrimination via <b>acoustic</b> <b>signals</b> has focused almost exclusively on the songs Manser 2009; Bradbury & Vehrencamp 2011); these other types of signals may also include species-specific elements. Therefore, to understand the role of these others <b>acoustic</b> <b>signals</b> in conspecific and heterospecific discrimination, it is worthwhile to conduct comparative studies between different categories of acoustic sig-nals, {{rather than focusing on}} a single signal type. Given the complexity and diversity of their vocalizations (Catchpole & Slater 2008), birds provide an excellent model for studying conspecific and heterospecific discrimination. The mos...|$|R
5000|$|... 2014 - Sheila E. Blumstein - for {{contributions}} to understanding how <b>acoustic</b> <b>signals</b> are transformed into linguistic representations ...|$|R
40|$|We {{describe}} experimental {{observations of}} slugging bed dynamics with passive acoustic sensors. Our {{results indicate that}} <b>acoustic</b> <b>signals</b> contain both similar and complementary information relative to dynamic pressure signals. We find that selective preprocessing of <b>acoustic</b> <b>signals</b> is a key step in separating information about microscale and macroscale processes. With such preprocessing, both linear and nonlinear dynamical features are apparent. Nonlinear features appear to be especially useful for practical diagnostics. 1...|$|R
2500|$|One of the {{intriguing}} aspects of tomography {{is that it}} exploits the fact that acoustic signals travel along [...] a set of generally stable ray paths. [...] From a single transmitted <b>acoustic</b> <b>signal,</b> this set of rays gives rise to multiple arrivals at the receiver, the travel time of each arrival corresponding to a particular ray path. [...] The earliest arrivals correspond to the deeper-traveling rays, since these rays travel where sound speed is greatest. [...] The ray paths are easily calculated using computers ("ray tracing"), and each ray path can generally be identified with a particular travel time. [...] The multiple travel times measure the sound speed averaged over each of the multiple acoustic paths. [...] These measurements {{make it possible to}} infer aspects of the structure of temperature or current variations as a function of depth. [...] The solution for sound speed, hence temperature, from the acoustic travel times is an inverse problem.|$|E
5000|$|... 10.41.28 Intermittent <b>acoustic</b> <b>signal</b> of {{autopilot}} disengagement ...|$|E
5000|$|The {{algorithm}} {{has found}} universal application in decoding the convolutional codes {{used in both}} CDMA and GSM digital cellular, dial-up modems, satellite, deep-space communications, and 802.11 wireless LANs. It is now also commonly used in speech recognition, speech synthesis, diarization, keyword spotting, computational linguistics, and bioinformatics. For example, in speech-to-text (speech recognition), the <b>acoustic</b> <b>signal</b> is treated as the observed sequence of events, {{and a string of}} text is considered to be the [...] "hidden cause" [...] of the <b>acoustic</b> <b>signal.</b> The Viterbi algorithm finds the most likely string of text given the <b>acoustic</b> <b>signal.</b>|$|E
40|$|The {{condition}} of locomotive bearings, which are essential components in trains, {{is crucial to}} train safety. The Doppler effect significantly distorts <b>acoustic</b> <b>signals</b> during high movement speeds, substantially increasing the difficulty of monitoring locomotive bearings online. In this study, a new Doppler transient model based on the acoustic theory and the Laplace wavelet is presented for the identification of fault-related impact intervals embedded in <b>acoustic</b> <b>signals.</b> An envelope spectrum correlation assessment is conducted between the transient model and the real fault signal in the frequency domain to optimize the model parameters. The proposed method can identify the parameters used for simulated transients (periods in simulated transients) from <b>acoustic</b> <b>signals.</b> Thus, localized bearing faults can be detected successfully based on identified parameters, particularly period intervals. The performance of the proposed method is tested on a simulated signal suffering from the Doppler effect. Besides, the proposed method is used to analyze real <b>acoustic</b> <b>signals</b> of locomotive bearings with inner race and outer race faults, respectively. The results confirm that the periods between the transients, which represent locomotive bearing fault characteristics, can be detected successfully...|$|R
40|$|AbstractIn this paper, {{details on}} the {{techniques}} used towards analyzing the <b>acoustic</b> <b>signals</b> generated by Red Palm Weevil RPW are presented. Besides, the <b>acoustic</b> <b>signals</b> generated by RPW in the palm and in the laboratory have been taken for this analysis. This paper describes in detail the great significance pertaining {{to the analysis of}} <b>acoustic</b> <b>signals</b> of red palm weevil recorded. The spectrum obtained for RPW is stored for analysis. The frequency in Hz and sound level in dB for both signals are determined. The frequencies are also of low range. Adequate number of spectrum has been displayed for easy understanding. Movement of RPW signal could not be compared with that of the eating and biting signature since no evenness existed for evaluation...|$|R
40|$|Background and Aim: The {{increasing}} {{cases of}} the cervical epidural but the practitioners in {{need for a new}} method to decrease the safety of the injection and to improve the learning curve of the trainee. Furthermore, it should replace the potentially hazards, conventional one, which is the fluoroscope. <b>Acoustic</b> <b>signals</b> were tested for this purpose. Methods: Thirty-two patients were assigned to have a cervical epidural for pain management using both <b>acoustic</b> <b>signals</b> and fluoroscopy simultaneously. Results: The incidence of success was 100 % with no complications. Likewise, the decrease in fluoroscopy shots number was 70 %. Conclusions: <b>Acoustic</b> <b>signals</b> are a simple, effective method of cervical epidural insertion. It reduces the usage of fluoroscopy and {{can be used as a}} learning tool...|$|R
