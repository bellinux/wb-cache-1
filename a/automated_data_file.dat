3|10000|Public
40|$|Transportation Department, Office of the Assistant Secretary for Policy and International Affairs, Washington, D. C. Mode of access: Internet. COP: 2 Author {{corporate}} affiliation: Transportation Systems Center, Cambridge, Mass. Users {{guide to}} "Summary of National Transportation Statistics," <b>automated</b> <b>data</b> <b>file.</b> Report covers the period Oct 1974 to Feb 1975 Subject code: IJSubject code: SDBFJSubject code: WMDHSubject code: XL...|$|E
40|$|The present {{invention}} {{provides a}} fail-over file transfer process to handle data file transfer when the transfer is unsuccessful {{in order to}} avoid unnecessary network congestion and enhance reliability in an <b>automated</b> <b>data</b> <b>file</b> transfer system. If a file cannot be delivered after attempting to send the file to a receiver up to a preset number of times, and the receiver has indicated the availability of other backup receiving locations, then the file delivery is automatically attempted to one of the backup receiving locations up to the preset number of times. Failure of the file transfer to one of the backup receiving locations results in a failure notification being sent to the receiver, and the receiver may retrieve the file from the location indicated in the failure notification when ready...|$|E
40|$|Until the mid- 1980 s, {{records of}} {{intersection}} and midblock accidents in Kansas City, Missouri, were manually filed by location. Although {{the staff of}} the Kansas City Public Works Department had worked with data processing personnel to develop an accident recordkeeping system utilizing the mainframe computer, those efforts were not successful because of other, higher priority projects and manpower shortages. The manual recordkeeping system and the large number of accidents (about 25, 000 a year) made it difficult and timeconsuming to prepare comprehensive reports identifying high-accident locations and describing the number, rates, and types of collisions occurring at these locations. Overall information on accident frequency distribution curves, statistics (such as means and standard deviations), classification of accidents by type of collision, and classification of accidents by severity was not readily available. In 1986, staff members began entering pertinent information from accident reports into an <b>automated</b> <b>data</b> <b>file</b> on a personal computer, using a database program. It then became possible to prepare comprehensive intersection, midblock, and pedestrian accident reports on an annual basis using less time and effort. These reports enable the staff to study high-accident locations in detail, to determine traffic operational and capital investment solutions, and to establish priorities for improvements on a more frequent basis. Furthermore, the information provided in the reports enables the staff members to respond appropriately to citizens ’ complaints, to develop educational programs, and to better perform their day-to-day duties. This article summarizes the accident statistics and characteristics observed in Kansas City in 1989. Kansas City has an area of 317 square miles and a population of 428, 000. The information provided, especially that on accident characteristics and their uses in improving safety, should be of use to urban traffic engineers...|$|E
5000|$|The actions {{necessary}} to restore an <b>automated</b> information system's <b>data</b> <b>files</b> and computational capability after a system failure.|$|R
40|$|Headwater {{benefits}} at a downstream hydropower project are energy gains that {{are derived from}} the installation of upstream reservoirs. The Federal Energy Regulatory Commission is {{required by law to}} assess charges of such energy gains to downstream owners of non-federal hydropower projects. The high costs of determining headwater benefits prohibit the use of a complicated model in basins where the magnitude of the benefits is expected to be small. This paper presents a new user-friendly computer model, EFDAM (Enhanced Flow Duration Analysis Method), that not only improves the accuracy of the standard flow duration method but also reduces costs for determining headwater benefits. The EFDAM model includes a MS Windows-based interface module to provide tools for <b>automating</b> input <b>data</b> <b>file</b> preparation, linking and executing of a generic program, editing/viewing of input/output files, and application guidance. The EDFAM was applied to various river basins. An example was given to illustrate the main features of EFDAM application for creating input files and assessing headwater {{benefits at}} the Tulloch Hydropower Plant on the Stanislaus River Basin, California...|$|R
40|$|Large databases, {{by their}} very nature, often serve as {{repositories}} of data which may be needed by other systems. The transmission of this data to other systems {{has in the past}} involved several layers of human intervention. The Integrated Cargo Data Base (ICDB) developed by Martin Marietta Energy Systems for the Military Traffic Management Command as part of the Worldwide Port System provides data integration and worldwide tracking of cargo that passes through common-user ocean cargo ports. One of the key functions of ICDB is data distribution of a variety of <b>data</b> <b>files</b> to a number of other systems. Development of <b>automated</b> <b>data</b> distribution procedures {{had to deal with the}} following constraints: (1) variable generation time for <b>data</b> <b>files,</b> (2) use of only current <b>data</b> for <b>data</b> <b>files,</b> (3) use of a minimum number of select statements, (4) creation of unique <b>data</b> <b>files</b> for multiple recipients, (5) automatic transmission of <b>data</b> <b>files</b> to recipients, and (6) avoidance of extensive and long-term data storage...|$|R
40|$|A {{letter report}} {{issued by the}} Government Accountability Office with an {{abstract}} that begins "As the insurer of over 29, 000 private sector defined benefit plans, the Pension Benefit Guaranty Corporation (PBGC) {{may be required to}} assume responsibility for the plans {{of a growing number of}} companies filing bankruptcy due to the recession. Concerns about PBGC's benefit determination process, reductions in benefits due to guarantee limits, and workers' retirement security overall led the chairmen and ranking members of the Senate Health, Education, Labor, and Pensions Committee and the Senate Finance Committee, among others, to ask GAO to study: (1) how long it takes PBGC to make benefit determinations; (2) the extent of overpayments on retirees' benefits; (3) how well PBGC communicates with participants; and (4) the timeliness and accessibility of the appeals process. To conduct this study, GAO reviewed PBGC policies and procedures, analyzed <b>automated</b> <b>data</b> and case <b>files,</b> and interviewed PBGC officials and certain associations, participants, and their representatives from among those most affected by the process. ...|$|R
40|$|RADARS, a {{bioinformatics}} {{solution that}} automates proteome mass spectral analysis, optimises protein identification, and archives {{data in a}} relational database RADARS, a rapid, <b>automated,</b> <b>data</b> archiving and retrieval software system for high-throughput proteomic mass spectral data processing and storage, is described. The majority of mass spectrometer <b>data</b> <b>files</b> are compatible with RADARS, for consistent processing. The system automatically takes unprocessed <b>data</b> <b>files,</b> identifies proteins via in silico database searching, then stores the processed data and search results in a relational database suitable for customized reporting. The system is robust, used in 24 / 7 operation, accessible to multiple users of an intranet through a web browser, may be monitored by Virtual Private Network, and is secure. RADARS is scalable for use on one or many computers, and is suited to multiple processor systems. It can incorporate any local database in FASTA format, and can search protein and DNA databases online. A key feature is a suite of visualisation tools (many available gratis) ...|$|R
40|$|A {{missile range}} is {{essentially}} a large-scale job-shop, involving prodigious amounts of test equipment and formidable problems of coordination. Because of its characteristics, a missile range {{can be considered a}} one-machine, N-job situation. For this problem the major scheduling methods were examined and tested, but all were discarded as unfeasible except one which used a Monte Carlo scheduling procedure adjoined with statistical stopping rules. An algorithm based on these ideas was constructed, and it has proven to be flexible and workable, providing predictably near optimum schedules for the missile range within a probabilistic and statistical framework. Even though there is not total implementation yet, considerable benefits to the missile range have already been experienced. For example, in order to automate the scheduling process, it was necessary to codify the goals of the range, something that had never been formalized before. This involved an unprecedented scrutiny and precision of definition of these goals, and from this study a reasonable numerical optimization criterion was constructed. Also, in order to use any <b>automated</b> scheduling algorithm, <b>data</b> <b>files</b> had to be stored on tape for ready access, which in turn has improved other operations on the missile range that were dependent on these data. Furthermore, the scheduling algorithm is providing conflict-free schedules in a few minutes of computer time. ...|$|R
40|$|The DORCA Applications {{study has}} been {{directed}} at development of a data bank management computer program identified as DORMAN. Because {{of the size of}} the DORCA <b>data</b> <b>files</b> and the manipulations required on that data to support analyses with the DORCA program, <b>automated</b> <b>data</b> techniques to replace time-consuming manual input generation are required. The Dynamic Operations Requirements and Cost Analysis (DORCA) program was developed for use by NASA in planning future space programs. Both programs are designed for implementation on the UNIVAC 1108 computing system. The purpose of this Executive Summary Report is to define for the NASA management the basic functions of the DORMAN program and its capabilities...|$|R
40|$|We {{present a}} fast, simple method for <b>automated</b> <b>data</b> {{acquisition}} and visualization of sound directivity, made convenient and accessible via a smartphone app, "Polar Pattern Plotter. " The app synchronizes measurements of sound volume with the phone's angular orientation obtained from either compass, gyroscope or accelerometer sensors and produces a graph and exportable <b>data</b> <b>file.</b> It is generalizable to various sound sources and receivers via {{the use of}} an input-jack-adaptor to supplant the smartphone's (omnidirectional) microphone. Results provide both a visual and quantitative representation of sound fields and device responses, adequate for introductory physics experiments. Comment: 8 pages, 6 figures, accepted for publication in The Physics Teacher (revision 1 : fixed typo...|$|R
30|$|For <b>data</b> <b>file</b> preservation, a {{standardized}} <b>data</b> <b>file</b> containing {{all types of}} necessary information can contribute to this issue because a single <b>data</b> <b>file</b> carries all the necessary information for scientific analysis. The practical information contained in <b>data</b> <b>files,</b> such as file names with version numbers of the source <b>data</b> <b>files,</b> and computer codes to generate <b>data</b> <b>files,</b> enables automatic processing of <b>data</b> <b>files</b> in many tasks for maintenance of the data archive. In addition to these efforts, the <b>data</b> <b>files</b> are synchronized between the ERG-SC at Nagoya University and ISAS/JAXA for redundancy.|$|R
40|$|User needs, data types, data automation, and {{preliminary}} {{applications are}} described for {{an effort to}} assemble a single data base for San Bernardino County from data bases which exist at several administrative levels. Each of the data bases used was registered and converted to a grid-based <b>data</b> <b>file</b> at a resolution of 4 acres and {{used to create a}} multivariable data base for the entire study area. To this data base were added classified LANDSAT data from 1976 and 1979. The resulting data base thus integrated in a uniform format all of the separately <b>automated</b> <b>data</b> within the study area. Several possible interactions between existing geocoded data bases and LANDSAT data were tested. The use of LANDSAT to update existing data base is to be tested...|$|R
40|$|Point {{cross-section}} <b>data</b> <b>files</b> {{derived from}} ENDF/B- 6 basic <b>data</b> <b>files</b> S. Ganesan, D. W. Muir and P. K. McLaughlin This document summarizes PEND-B 6, {{a collection of}} resonance reconstructed (point) <b>data</b> <b>files</b> derived from ENDF/B- 6 basic <b>data</b> <b>files.</b> The files are available free of charge from the IAEA Nuclear Data Section upon request...|$|R
5000|$|...Package (Data {{provided}} with The Sims 2, user downloadable plugins/mods for The Sims 2, <b>data</b> <b>files</b> for SPORE, <b>data</b> <b>files</b> for The Sims 3 and <b>data</b> <b>files</b> for SimCity) ...|$|R
2500|$|Output of {{the digital}} tools (copper patterns, solder resist image, legend image, drill <b>files,</b> <b>automated</b> optical {{inspection}} <b>data,</b> electrical test <b>files,...)</b> ...|$|R
50|$|Cox et al. {{combines}} human {{pattern recognition}} skills with <b>automated</b> <b>data</b> algorithms. In their work, information is presented visually by domain-specific interfaces, combining human pattern recognition skills with <b>automated</b> <b>data</b> algorithms (Jans et al.).|$|R
5000|$|Reader+ - a <b>data</b> <b>file</b> {{processing}} service which deciphers {{the contents}} of billing and usage <b>data</b> <b>files.</b> Processes over 750 vendor <b>data</b> <b>file</b> formats for invoices and usage and presents the data in clear formats for further reporting and analysis ...|$|R
40|$|Keywords:data recovery; data files; the {{physical}} structure of files; page Abstract. Through {{the analysis of}} oracle database files on the ext 3 with Linux documentation system research, propose {{the physical}} structure of oracle’s <b>data</b> <b>files,</b> make oracle <b>data</b> <b>files</b> in Linux could be spelled to original <b>data</b> <b>files</b> when they were deleted by mistake, so as to achieve the aim to recover the <b>data</b> <b>files...</b>|$|R
40|$|Development of {{a scheme}} for {{utilizing}} remote sensing technology in an operational program for regional {{land use planning}} and land resource management program applications. The scheme utilizes remote sensing imagery as one of several potential inputs to derive desired and necessary data, and considers several alternative approaches to the expansion and/or reduction and analysis of <b>data,</b> using <b>automated</b> <b>data</b> handling techniques. Within this scheme is a five-stage program development which includes: (1) preliminary coordination, (2) interpretation and encoding, (3) creation of <b>data</b> base <b>files,</b> (4) <b>data</b> analysis and generation of desired products, and (5) applications...|$|R
5000|$|The tools include <b>data</b> networks, <b>file</b> systems, a <b>data</b> warehouse, data marts, an {{operational}} data store, data mining, data analysis, data visualization, data federation and data virtualization. One {{of the newest}} tools, virtual master data management utilizes data virtualization and a persistent metadata server to implement a multi-level <b>automated</b> master <b>data</b> management hierarchy[...].|$|R
50|$|Fully <b>automated</b> <b>data</b> {{collection}} protocols.|$|R
40|$|A {{method of}} {{processing}} {{a plurality of}} digital <b>data</b> <b>files</b> including at least one group of medium <b>data</b> <b>files</b> for constituting a sequence of events or activities of a time interval for secure delivery of the digital <b>data</b> <b>files,</b> the method comprising the steps of: (a) processing a plurality of digital <b>data</b> <b>files</b> so as to generate a file identification value for each digital <b>data</b> <b>file,</b> wherein the file identification value of a digital <b>data</b> <b>file</b> is an one-way arithmetic value characteristic of the data content of the digital data file; (b) processing the file identification values to generate an authentication root value, the authentication root value being an one-way arithmetic value characteristic of the plurality of file identification values; (c) encrypting the root value; and (d) grouping the encrypted authentication root value and a selected plurality of digital <b>data</b> <b>files</b> {{with a set of}} authentication information for delivery, wherein the set of authentication information is derived from the file identification values and is for deriving a test root value when in combination with said selected plurality of digital <b>data</b> <b>files,</b> and wherein the test root value is for comparison with the authentication root value to detect tampering of said selected plurality of <b>data</b> <b>files.</b> published_or_final_versio...|$|R
5000|$|...o {{directory}}|file (--object-directory directory or --object-file file): Specify {{either the}} directory containing the gcov <b>data</b> <b>files,</b> or the object path name. The [...]gcno, and [...]gcda <b>data</b> <b>files</b> are searched for using this option. If a directory is specified, the <b>data</b> <b>files</b> {{are in that}} directory and named after the input file name, without its extension. If a file is specified here, the <b>data</b> <b>files</b> are named after that file, without its extension.|$|R
50|$|At the {{physical}} level, <b>data</b> <b>files</b> comprise {{one or more}} data blocks, where the block size can vary between <b>data</b> <b>files.</b>|$|R
5000|$|Related {{electronic}} <b>data</b> <b>files</b> {{may also}} be used to help verify Proposition 218 compliance. In particular, use of geographic information system (GIS) <b>data</b> <b>files.</b> GIS <b>data</b> <b>files</b> containing location-based information relating to a proposed assessment for each parcel within an assessment district {{may also be}} available. In addition, separate GIS <b>data</b> <b>files</b> may have also been used as part of the assessment calculation process such as GIS <b>data</b> <b>files</b> containing the location and attributes of streetlights and parcels within an assessment district. GIS <b>data</b> <b>files</b> may also be used in connection with the calculation of property-related fees and charges under Proposition 218 such as utility or stormwater fees. The California Supreme Court has ruled that GIS database files are generally deemed “public records” subject to disclosure under the California Public Records Act.|$|R
40|$|The Data Transfer and Data Centers session {{will present}} papers on current data center {{activities}} {{as well as}} various topics geared towards enhancing the availability and acquisition of International Global Positions System Service (IGS) data and products. These topics include: strategies for reducing <b>data</b> <b>file</b> latency at IGS Data Centers, standardization of <b>data</b> <b>file</b> replacement notification methods, improving the efficiency of <b>data</b> <b>file</b> transfer among IGS Data Centers, and defining a network topology for GPS <b>data</b> <b>files</b> for use in applications...|$|R
2500|$|Related {{electronic}} <b>data</b> <b>files</b> {{may also}} be used to help verify Proposition 218 compliance. [...] In particular, use of geographic information system (GIS) <b>data</b> <b>files.</b> [...] GIS <b>data</b> <b>files</b> containing location-based information relating to a proposed assessment for each parcel within an assessment district {{may also be}} available. [...] In addition, separate GIS <b>data</b> <b>files</b> may have also been used as part of the assessment calculation process such as GIS <b>data</b> <b>files</b> containing the location and attributes of streetlights and parcels within an assessment district. [...] GIS <b>data</b> <b>files</b> may also be used in connection with the calculation of property-related fees and charges under Proposition 218 such as utility or stormwater fees. [...] The California Supreme Court has ruled that GIS database files are generally deemed “public records” subject to disclosure under the California Public Records Act.|$|R
40|$|The {{goal of this}} {{document}} is to clarify how Synphot uses instrument <b>data</b> <b>files,</b> {{in conjunction with the}} software, to make predictions about HST observations. This document discusses the most important aspects of Synphot <b>data</b> <b>files.</b> It also covers in detail the procedures for the creation, testing, and delivery of STIS Synphot <b>data</b> <b>files...</b>|$|R
50|$|Machine-readable <b>data</b> <b>files</b> are {{provided}} by the registration authority. Mappings from ISO 639-1 or ISO 639-2 to ISO 639-3 can be done using these <b>data</b> <b>files.</b>|$|R
5000|$|Useful {{functions}} {{that use the}} class row are: void write(table &t, row &r, int idx); //write the data in the <b>data</b> <b>file</b> of the table void read(table &t, row &r, int idx); //read {{the data from the}} <b>data</b> <b>file</b> of the table void del(char *file, table &t, int idx); //delete the data from the <b>data</b> <b>file</b> of the table ...|$|R
40|$|In {{the study}} of solar-terrestrial physics there is {{frequently}} a requirement to combine and compare data from different instruments, of either the same type or of different types. This paper presents a Multi-Instrument Analysis (MIA) toolbox for Matlab. By using object-oriented programming techniques it is shown that the same tools {{can be applied to}} data from different instruments, or even instruments of different types. A coherent structure enables MIA to display image plots, keograms and movies for all imaging instruments, regardless of type. <b>Data</b> <b>files</b> are joined automatically so that file boundaries do not interrupt data processing. Although a graphical user interface is available all operations can be performed by scripts, thereby permitting <b>automated</b> <b>data</b> processing. By simplifying data processing MIA aids the creation of new data products such as energy maps and event databases. MIA currently supports riometers and imaging riometers, magnetometers and all-sky cameras...|$|R
50|$|Files {{are made}} of two parts: a <b>data</b> <b>file</b> and a file {{dictionary}} (DICT). The <b>data</b> <b>file</b> contains records that store the actual <b>data.</b> The <b>file</b> dictionary may contain metadata to describe the contents or to output {{the contents of a}} file.|$|R
5000|$|Merge {{multiple}} plate {{files to}} allow for cross-plate analyses (an example {{of this would be}} to use standards from one <b>data</b> <b>file</b> for analysis on another <b>data</b> <b>file)</b> ...|$|R
5000|$|Method {{and system}} of <b>automating</b> <b>data</b> capture from {{electronic}} correspondence ...|$|R
40|$|SFPO) {{requested}} that we provide {{copies of the}} <b>data</b> <b>files</b> listed in Appendix B to Revision I of Holtec International report HI- 2043285. The stated purpose of this request was to permit review of these <b>data</b> <b>files</b> by the SFPO staff {{as part of their}} ongoing review of our third request to amend the HI-STORM 100 Certificate of Compliance (Reference 3). Enclosed, please find the requested <b>data</b> <b>files,</b> provided as electronic <b>files</b> on a <b>data</b> DVD. These <b>data</b> <b>files</b> are considered proprietary by Holtec International, and as such we have prepared an affidavit pursuant to 10 CFR 2. 390 requesting that they be withheld from public disclosure. Please contact us {{if you have any questions}} related to these <b>data</b> <b>files.</b> Sincerely...|$|R
