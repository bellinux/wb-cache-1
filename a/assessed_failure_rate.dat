0|10000|Public
40|$|The paper {{develops}} a procedure {{for analysis of}} PLC-controlled system risk due to component failure and for derivation of safety integrity requirements for components, focusing on software requirements. The approach allows fully integrated treatment of random and systematic failure. It can be applied {{at different levels of}} design detail and at different stages of the system development lifecycle. The procedure does not address how to <b>assess</b> <b>failure</b> <b>rates,</b> but provides a foundation for integrating PLC software assessment into system riskassessment and for making trade-offs in design...|$|R
40|$|D-dimer {{testing to}} exclude {{pulmonary}} embolism (PE). Purpose: To compare the test characteristics of gestalt (a physi-cian’s unstructured estimate) and clinical decision rules for evaluat-ing adults with suspected PE and <b>assess</b> the <b>failure</b> <b>rate</b> of gestalt and rules {{when used in}} combination with D-dimer testing...|$|R
40|$|International audienceElectro{{mechanical}} {{and mechanical}} equipment reliability databases {{do not seem}} as widespread as those of electronic which are well established and commonly used by the whole industrial actors. This statement explains itself {{by the nature of}} its which do not propose prediction reliability model but present some similar categories of equipment. Indeed, no method was still commonly allowed for the prediction of the reliability of (electro-) mechanical equipment and the dispersion of <b>failure</b> <b>rates</b> for apparently similar system is significant. In order to <b>assess</b> the <b>failure</b> <b>rates,</b> we propose a method taking into account influential factors. A small application is presented in this article for spring-loaded safety valves and show the impact of these contributors on <b>failure</b> <b>rates.</b> The example takes into account two factors, among those deterministically chosen by expert judgment...|$|R
40|$|We study a continuous-time game of {{strategic}} experimentation {{in which the}} players try to <b>assess</b> the <b>failure</b> <b>rate</b> of some new equipment or technology. Breakdowns occur at the jump times of a Poisson process whose unknown intensity is either high or low. In marked contrast to existing models, {{we find that the}} cooperative value function does not exhibit smooth pasting at the efficient cut-off belief. This finding extends to the boundaries between continuation and stopping regions in Markov perfect equilibria. We characterize the unique symmetric equilibrium, construct a class of asymmetric equilibria, and elucidate the impact of bad versus good Poisson news on equilibrium outcomes. ...|$|R
40|$|Background: The {{performance}} of different diagnostic strategies for pulmonary embolism (PE) in patient subgroups is unclear. Purpose: To evaluate {{and compare the}} efficiency and safety of the Wells rule with fixed or age-adjusted D-dimer testing overall and in inpatients and persons with cancer, chronic obstructive pulmonary disease, previous venous thromboembolism, delayed presentation, and age 75 years or older. Data Sources: MEDLINE and EMBASE from 1 January 1988 to 13 February 2016. Study Selection: 6 prospective studies in which the diagnostic management of PE was guided by the dichotomized Wells rule and quantitative D-dimer testing. Data Extraction: Individual data of 7268 patients; risk of bias assessed by 2 investigators with the QUADAS- 2 (Quality Assessment of Diagnostic Accuracy Studies 2) tool. Data Synthesis: The proportion of patients in whom imaging could be withheld based on a "PE-unlikely" Wells score and a negative D-dimer test result (efficiency) was estimated using fixed (50 years) D-dimer thresholds; their 3 -month incidence of symptomatic venous thromboembolism (<b>failure</b> <b>rate)</b> was also estimated. Overall, efficiency increased from 28 % to 33 % when the age-adjusted (instead of the fixed) D-dimer threshold was applied. This increase was more prominent in elderly patients (12 %) but less so in inpatients (2. 6 %). The <b>failure</b> <b>rate</b> of age-adjusted D-dimer testing was less than 3 % in all examined subgroups. Limitation: Post hoc analysis, between-study differences in patient characteristics, use of various D-dimer assays, and limited statistical power to <b>assess</b> <b>failure</b> <b>rate.</b> Conclusion: Age-adjusted D-dimer testing {{is associated with a}} 5 % absolute increase in the proportion of patients with suspected PE in whom imaging can be safely withheld compared with fixed D-dimer testing. This strategy seems safe across different high-risk subgroups, but its efficiency varies...|$|R
40|$|This paper {{presents}} the results of predicting the <b>failure</b> <b>rate</b> of water distribution pipes and house connections in a selected city in Poland by means of regression trees. Several regression tree models were built as part of modelling. Optimal models were selected (separately for each of the water conduit types) via an analysis of the so–called costs. The regression tree structure comprised independent variables, i. e. predictors (length, diameter, year of construction and material). The <b>failure</b> <b>rates</b> of the two types of water conduits were the dependent variable. The optimal models were characterized by the lowest costs and a relatively simple tree architecture. Operational data from the years 2001 – 2012 were used to determine the experimental (real) values of the <b>failure</b> <b>rate</b> and to build regression tree models. The optimal models included eight divided nodes and nine end nodes. The ranking of the significance of the parameters showed that length was the predictor responsible for division on the successive tree levels. The obtained high consistency (0. 99) of the real data with the predicted ones indicates that the regression tree method can be used to analyze and <b>assess</b> the <b>failure</b> <b>rate</b> of water conduits...|$|R
40|$|Introduction: In {{resource}} limited settings, patients entering an antiretroviral therapy (ART) program comprise ART {{naive and}} ART pre-treated patients who may show differential virological outcomes. Methods: This retrospective study, conducted in 2010 – 2012 in the HIV clinic of Calmette Hospital located in Phnom Penh (Cambodia) <b>assessed</b> virological <b>failure</b> (VF) <b>rates</b> {{and patterns of}} drug resistance of naive and pre-treated patients. Naive and ART pre-treated patients were included when a Viral Load (VL) was performed {{during the first year}} of ART for naiv...|$|R
40|$|This paper {{presents}} {{a method for}} <b>assessing</b> the instant <b>failure</b> <b>rate</b> of a power transformer under different working conditions. The method {{can be applied to}} a dataset of a power transformer under periodic inspections and maintenance. We use a Poisson-fault model to describe failures of a power transformer. When investigating a Bayes estimate of the instant <b>failure</b> <b>rate</b> under the model, we find that complexities of a classical method and a Monte Carlo simulation are unacceptable. Through establishing a new filtered estimate of Poisson process observations, we propose a quick algorithm of the Bayes estimate of the instant <b>failure</b> <b>rate.</b> The proposed algorithm is tested by simulation datasets of a power transformer. For these datasets, the proposed estimators of parameters of the model have better performance than other estimators. The simulation results reveal the suggested algorithms are quickest among three candidates...|$|R
40|$|A {{systematic}} assessment, {{based on}} an extensive literature review, {{of the impact of}} gaps and uncertainties on the results of quantitative risk assessments (QRAs) for CO 2 pipelines is presented. Sources of uncertainties that have been <b>assessed</b> are: <b>failure</b> <b>rates,</b> pipeline pressure, temperature, section length, diameter, orifice size, type and direction of release, meteorological conditions, jet diameter, vapour mass fraction in the release and the dose–effect relationship for CO 2. A sensitivity analysis with these parameters is performed using release, dispersion and impact models. The results show that the knowledge gaps and uncertainties have a large effect on the accuracy of the assessed risks of CO 2 pipelines. In this study it is found that the individual risk contour can vary between 0 and 204 m from the pipeline depending on assumptions made. In existing studies this range is found to be betwee...|$|R
40|$|Patients with {{osteoarthritis}} {{secondary to}} developmental dysplasia {{of the hip}} (DDH) typically are young and active, which might affect functional ratings or <b>failure</b> <b>rates</b> after resurfacing arthroplasty. We therefore evaluated 24 patients (32 hips; mean age, 44. 2  years) after hip resurfacing performed for osteoarthritis secondary to DDH. We used the Harris hip score (HHS), the University of California, Los Angeles (UCLA) activity scale, and a sports and activity questionnaire. A radiographic analysis also was performed. We followed patients a minimum of 28  months (mean, 43  months; range 28 – 60  months). The HHS improved from a mean of 54. 7 to 97. 3 and UCLA activity levels increased from a mean of 5. 3 to 8. 6. All patients returned to sports activity at a mean of 11  weeks after surface replacement. There were no major differences in preoperative and postoperative participation in the most common sports and activities. Two of the 32 replacements (6 %) failed. We detected femoral radiolucencies in 10 of the remaining 30 hips. Despite satisfactory outcomes in clinical scores, return to sports, and hip biomechanics, the <b>failure</b> <b>rate</b> of 6 % was disappointing. Additional followup is important to <b>assess</b> if <b>failure</b> <b>rates</b> increase in these young, active patients...|$|R
40|$|Purpose: The {{purpose of}} this study was to {{investigate}} the reliability and the clinical applicability of the adenosine-triphosphate-based chemotherapy response assay (ATP-CRA) as a method of determining in vitro chemosensitivity in patients with gastric cancer. Materials and Methods: A total of 243 gastric cancer tissue samples were obtained from gastrectomies performed between February 2007 and January 2010. We evaluated the effectiveness of the ATP-CRA assay in determining the chemosensitivity of gastric cancer specimens using eleven chemotherapeutic agents – etoposide, doxorubicin, epirubicin, mytomicin, 5 -fluorouracil, oxaliplatin, irinotecan, docetaxel, paclitaxel, methotraxate, and cisplatin – for chemosensitivity studies using ATP-CRA. We <b>assessed</b> the <b>failure</b> <b>rate,</b> the cell death rate, and the chemosensitivity index. Results: The <b>failure</b> <b>rate</b> of ATP-CRA was 1. 6 % (4 / 243). The mean coefficient of variation for triplicate ATP measurements was 6. 5 %. Etoposide showed the highest cell death rate (35. 9 %) while methotrexate showed the lowest (16. 6 %). The most active chemothera-peutic agent was etoposide, which most frequently ranked highest in the chemosensitivity test: 31. 9 % (51 / 160). Oxaliplatin was more active against early gastric cancers than advanced gastric cancers, whereas docetaxel was more active against advanced cancers. The lymph node negative group showed a significantly higher cell death rate than the lymph node positive group when treated with doxoru-bicin, epirubicin, and mitomycin. Conclusions: ATP-CRA is a stable and clinically applicable in vitro chemosensitivity test with a low <b>failure</b> <b>rate.</b> The clinical usefulness o...|$|R
40|$|International audienceAccording to IEC 61508, a safety-related {{system is}} {{regarded}} as type B if it presents a high complexity (i. e. the failure mode {{of at least one}} component is not well defined, or the behaviour under fault conditions cannot be completely determined), or if there is insufficient data to support claims for <b>failure</b> <b>rates.</b> This paper proposes a modelling method adapted to the evaluation of failure probabilities for systems with uncertain behaviour under fault conditions. To this aim, weighted “continuous gates” are introduced in a fault tree framework. By acting on weight values, it is then allowed to continuously graduate system part architectures between series and parallel structures. An intelligent transmitter is used as example. Probabilities of failure on demand are <b>assessed,</b> with both <b>failure</b> <b>rates</b> and behaviour uncertainty analyses. Results tend to show that the lack of knowledge in system behaviour can be partially handled by this kind of approach...|$|R
40|$|Objective: To {{comparatively}} <b>assess</b> {{the long-term}} <b>failure</b> <b>rate</b> of brackets bonded with a plasma or a high-intensity light-emitting diode (LED) curing light. Materials and Methods: Twenty-five patients with complete permanent dentitions with similar treatment planning and mechanotherapy {{were selected for}} the study. Brackets were bonded ac-cording to a split-mouth design with the 3 M Ortholite Plasma or the high-power Satelec mini LED Ortho curing light. Irradiation with the two curing lights was performed for 9 seconds at an alternate quadrant sequence so that the bonded brackets cured with either light were equally distributed on the maxillary and mandibular right and left quadrants. First-time bracket failures were recorded for a mean period of 15 months (range 13 – 18 months) {{and the results were}} analyzed with the chi-square test and binary logistic regression. Results: The <b>failure</b> <b>rate</b> for brackets was 2. 8 % for the plasma light and 6. 7 % for the LED light source. Although significantly more failures were found for the mandibular arch, no difference was identified in <b>failure</b> <b>rate</b> between anterior and posterior teeth. Conclusions: High-intensity LED curing lights present a 2. 5 times higher <b>failure</b> <b>rate</b> relative to plasma lamps for nominally identical irradiation time. Mandibular teeth show almost 150 % higher failure incidence compared with maxillary teeth. No effect from the arch side (right vs left) and location (anterior vs posterior) was identified in this study...|$|R
40|$|Purpose: Nonoperative {{management}} (NOM) is {{the treatment}} of choice for hemodymically stable pediatric patients with spleen or liver trauma. The {{aim of this study}} was to <b>assess</b> the <b>failure</b> <b>rate</b> of NOM in children with blunt liver and/or splenic injury when a contrast blush is present on a computed tomography (CT) scan. Methods: A systematic review of the literature published between 1985 and 2009 was performed by searching the EMBASE and MEDLINE database for English and German articles. Articles were eligible if they reported the <b>failure</b> <b>rate</b> of NOM with or without angioembolization (AE) in pediatric patients with splenic and/or liver injuries with a contrast blush on CT and included 2 or more trauma patients. Two reviewers independently assessed the eligibility and the quality of the articles and performed the data extraction. Interrater differences were resolved by discussion. Results: Nine studies were included describing 117 pediatric patients. The median sample size was 5 (range, 2 - 44). Seven studies (including 71 patients) reported a total of 16 patients with failure after NOM without AE. <b>Failure</b> <b>rates</b> across these studies ranged from 4. 5 % to 100 %; the pooled percentage was 28. 2 % (95 % confidence interval, 8. 9 %- 61. 3 %). The failure percentages after NOM with or without AE ranged from 0 to 100 %; the pooled percentage was 21 % (95 % confidence interval, 7. 5 %- 46. 8 %). Two studies (including 46 patients) reported a total of 3 patients (6. 5 %) with failure after NOM with primary AE. Conclusion: Despite the current low level of evidence on <b>failure</b> <b>rate</b> of NOM when a contrast blush is present on CT, we emphasize that there is a significant number of patients in whom NOM fails. We therefore recommend that the management of splenic and hepatic injury in children should not only be based on the physiologic response but should include consideration of the presence of a contrast blush. Crown Copyright (C) 2010 Published by Elsevier Inc. All rights reserve...|$|R
40|$|This is {{the author}} {{accepted}} manuscript. Accurately quantifying and assessing the reliability of Offshore Renewable Energy (ORE) devices is critical for the successful commercialisation of the industry. At present, due to the nascent stage of the industry and commercial sensitivities {{there is very little}} available reliability field data. This presents an issue: how can the reliability of ORE’s be accurately assessed and predicted with a lack of specific reliability data? ORE devices largely rely on the assessment of surrogate data sources for their reliability assessment. To date there are very few published studies that empirically <b>assess</b> the <b>failure</b> <b>rates</b> of offshore renewable energy devices [1]. The applicability of surrogate data sources to the ORE environment is critical and needs to be more thoroughly evaluated for a robust ORE device reliability assessment. This paper tests two commonly held assumptions used in the reliability assessment of ORE devices. Firstly, the constant <b>failure</b> <b>rate</b> assumption that underpins ORE component <b>failure</b> <b>rate</b> estimations is addressed. Secondly, a model that is often used to assess the reliability of onshore wind components, the Non-Homogeneous Poisson Power Law Process (PLP) model is empirically assessed and trend tested to determine its suitability for use in ORE reliability prediction. This paper suggests that pitch systems, generators and frequency converters cannot be considered to have constant <b>failure</b> <b>rates</b> when analysed via nonrepairable methods. Thus, when performing a reliability assessment of an ORE device using non-repairable surrogate data it cannot always be assumed that these components will exhibit random failures. Secondly, this paper suggests when using repairable system methods, the PLP model is not always accurate at describing the failure behaviour of onshore wind pitch systems, generators and frequency converters whether they are assessed as groups of turbines or individually. Thus, when performing a reliability assessment of an ORE device using repairable surrogate data both model choice and assumptions should be carefully considered. The support of the ETI and RCUK Energy Program funding for IDCORE (EP/J 500847 / 1) is gratefully acknowledged...|$|R
40|$|Sieck. Temporal {{relationships}} of ventilatory failure, pump failure, and diaphragm fatigue. J. Appl. Physiol. 81 (l) : 238 245, 1996. -The time course of ventilatory failure, pump failure, and diaphragm peripheral fatigue was determined during {{the application of}} external inspiratory resistive loads (IRL) in anesthetized rabbits. Pump failure {{is defined as the}} inability of the diaphragm to sustain the expected force under IRL. To assess contractile fatigue, transdiaphragmatic pres-sures (Pdi) generated by bilateral phrenic nerve stimulation at 75 Hz (Pdi- 75) and 20 Hz (Pdi- 20) were measured. The amplitude of evoked diaphragm electromyographic (EMG) signals was measured to <b>assess</b> neurotransmission <b>failure.</b> The <b>rate</b> of rise of spontaneous diaphragm EMG was used as an index of respiratory drive. Ventilation was evaluated together with arterial blood gases. During IRL the rate of ris...|$|R
40|$|There is {{a concern}} that the {{continuing}} trend on miniaturization (Moore 2 ̆ 7 s law) in IC design and fabrication might {{have a negative impact}} on the device reliability. To understand and to possibly quantify the physics underlying this concern and phenomenon, it is natural to proceed from the experimental bathtub curve (BTC) - reliability “passport” of the device. This curve reflects the combined effect of two major irreversible governing processes: statistics-related mass-production process that results in a decreasing <b>failure</b> <b>rate</b> with time, and reliability-physics-related degradation (aging) process that leads to an increasing <b>failure</b> <b>rate.</b> It is the latter process that is of major concern of a device designer and manufacturer. The statistical process can be evaluated theoretically, using a rather simple predictive model. Owing to that and assuming that the two processes of interest are statistically independent one can <b>assess</b> the <b>failure</b> <b>rates</b> associated with the aging process from the BTC data by simply subtracting the predicted ordinates of the statistical <b>failure</b> <b>rates</b> (SFR) from the BTC ordinates. The objective of this analysis is to show how this could be done. The suggested methodology proceeds from the concepts that the actual (“instantaneous”) SFR is a random variable with a known (assumed, established) probability distribution, that the experimental BTC can be represented by its infant mortality and the wear-out portions only (the steady-state portion in this case is simply the boundary between the infant mortality and wear-out portions) and that the two BTC portions considered can be approximated analytically. The cases, when the “instantaneous” SFR is distributed normally and in accordance with the Rayleigh law are used as suitable illustrations of the general concept. The developed methodology can be employed when there is a need to better understand the relative roles of the statistics-related and physics-of-failure-related processes in reliability evaluations of electronic products. The methodology can be used also beyond the field of IC engineering, when there is a need to understand and, hence, to separate the roles of the two irreversible processes in question. One of the major challenges of the future work is to determine the probability distributions of the actual (“instantaneous”) SFRs for particular products and applications...|$|R
40|$|Background: Four {{different}} clinical decision rules (CDRs) (Wells score, Revised Geneva score (RGS), simplified Wells {{score and}} simplified RGS) safely exclude pulmonary embolism (PE), {{when combined with}} a normal D-dimer test. Recently, an age adjusted cut-off of the D-dimer (patient's age x 10 ig/L) greatly {{increased the number of}} patients in whom PE could safely be excluded. We validated the age-adjusted D-dimer test and assessed its performance in combination with the four CDRs in patients with suspected PE. Methods: Eight hundred and thirty-four consecutive patients with suspected PE were included of whom 414 were > 50 years (50 %). The proportion of patients in whom PE could be excluded with an unlikely CDR combined with a normal age-adjusted D-dimer test was calculated and compared with the conventional D-dimer cut-off. We <b>assessed</b> VTE <b>failure</b> <b>rates</b> during 3 -months follow-up. Results: Compared to the conventional D-dimer cut-off level, a normal age-adjusted D-dimer level substantially increased the number of patients in whom PE could be safely excluded. All CDRs performed equally well. This difference was nearly fourfold in patients > 70 years, where the Wells rule excluded more patients than the other CDRs. Conclusion: The age-adjusted D-dimer increases the number of older patients in whom PE can be safely excluded, irrespective of the Wells score or RGS, thereby avoiding unnecessary imaging tests...|$|R
40|$|Traditional Statistical Machine Translation (SMT) models account poorly {{for many}} {{linguistic}} phenomena, such as subject-verb agreement {{and differences in}} word-order between languages. Recent work, such as that in factored phrase-based models, has shown promising improvements in translation quality {{through the use of}} linguistically-richer models. Uniﬁcation-based approaches to grammar offer a framework for modelling agreement, a particular problem in generating morphologically-rich languages, and so in order to gauge the potential gains available from their application to SMT we ﬁrst consider how to automatically recognise and measure agreement failure. We focus upon the speciﬁc issue of declension in German noun phrases and propose a simple uniﬁcation-based approach to the problem. We develop an agreement checker based on this approach and use it to <b>assess</b> the agreement <b>failure</b> <b>rate</b> of a hierachical phrase-based translation system trained on the small News Commentary corpus. Initially we ﬁnd that our checker reports unreasonably high <b>failure</b> <b>rates</b> on the ﬂuent training data, and through an incremental process of failure analysis and lexicon reﬁnement we signiﬁcantly reduce the number of spurious failures. We then apply the agreement checker directly to machine translation by incorporating it as a feature function of the log-linear model. We train our baseline system on the larger Europarl corpus and again measure <b>failure</b> <b>rates</b> before applying the agreement check as both a hard and soft constraint. The effects on translation are not large enough to reliably measure using standard automatic evaluation techniques and so we perform a manual analysis of the types of change introduced...|$|R
40|$|Background: Transcatheter {{occlusion}} of {{patent ductus arteriosus}} (PDA) {{is usually}} performed by fluoroscopy alone or together with transesophageal echocardiography (TEE). Transthoracic echocardiography (TTE) guidance {{has been used for}} deployment of Amplatz Canine Ductal Occluder (ACDO), but sometimes is limited by suboptimal acoustic windows. Transesophageal echocardiography can overcome such issues and provides higher image resolution {{at the level of the}} great vessels. Objectives: To determine if TEE without fluoroscopy could be used to successfully perform ductal occlusion for the treatment of PDA in dogs. Animals: Twenty client-owned dogs with PDA. Methods: A prospective consecutive case series of PDA occlusion was performed using only TEE guidance. Dogs were positioned in right lateral recumbency and the TEE probe was positioned to visualize the descending aorta, PDA, and pulmonary artery. The guide wire, long introducer sheath, and ACDO were imaged by TEE to direct deployment. Results: Ductal occlusion was performed successfully without need for fluoroscopy and without complications in 19 dogs. One dog required a second larger ACDO because of embolization of the first device 18 hours after positioning. Conclusions and Clinical Importance: We have demonstrated that TEE monitoring without concurrent fluoroscopy can guide each step of transcatheter ACDO embolization thereby providing an alternate method of visualization for this procedure. Use of TEE alone can reduce radiation exposure or is an option when fluoroscopy is not available, and, therefore, should be evaluated in a larger case series to better <b>assess</b> procedural <b>failure</b> <b>rates...</b>|$|R
40|$|Patients with Type 2 (non-insulin-dependent) {{diabetes}} mellitus (DM) on sulphonylurea therapy convert to insulin progressively as the sulphonylureas 'fail'. The <b>rate</b> of <b>failure</b> and {{the features of}} those who fail have been poorly described. To <b>assess</b> secondary <b>failure</b> <b>rates</b> of sulphonylureas, {{we report on the}} responses in 1305 patients with newly diagnosed Type 2 DM randomly allocated to therapy with either chlorpropamide or glibenclamide in the UK Prospective Diabetes Study (UKPDS). These patients were initially treated by diet for 3 months and had a fasting plasma glucose > 6 mmol l- 1; mean age 53 (SD 9) years; BMI 26. 8 (SD 5. 0) kg m- 2; and median fasting plasma glucose 9. 1 (7. 6 - 12. 5 quartiles) mmol l- 1. If their fasting plasma glucose subsequently rose above 15. 0 mmol l- 1, or they developed hyperglycaemic symptoms, additional hypoglycaemic therapy was given: metformin, ultratard insulin, and soluble insulin as required. By 6 years, 44 % had required additional therapy. Of those randomized to glibenclamide, 48 % required additional therapy by 6 years, compared with 40 % of those allocated to chlorpropamide (p < 0. 01). Sixty-one per cent, 39 %, and 23 %, respectively, of patients with fasting plasma glucose ≤ 10. 0 mmol- 1, ≤ 7. 8 mmol- 1 to < 10. 0 mmol- 1 and < 7. 8 mmol- 1 at randomization required additional therapy (p < 0. 001). In the initial 3 years, non-obese subjects (BMI < 30 kg m- 2) were more likely to require additional therapy than obese patients (BMI ≤ 30 kgm- 2) (43 % vs 53 % at 6 years; p < 0. 001). Modelled beta-cell function showed that those with lower function were more likely to fail (p < 0. 0001). Thus sulphonylureas fail as a therapeutic agent at rates which are dependent both on the phenotype at presentation and perhaps on the agent used initially. Higher <b>failure</b> <b>rates</b> were found in those with higher glucose concentrations, those who were younger, those with lower beta-cell reserve and those randomized to glibenclamide compared with chlorpropamide...|$|R
40|$|A set {{of general}} {{formulas}} is {{proposed for the}} probability of failure on demand (PFD) assessment of MooN architecture (i. e. k-out-of-n) systems subject to proof tests. The proof tests can be partial or full. The partial tests (e. g. visual inspections, partial stroke testing) are able to detect only some system failures and leave the others latent, whereas the full tests refer to overhauls which restore the system to an as good as new condition. Partial tests may occur at different time instants (periodic or not), up to the full test. The system performances which are investigated are the system availability according to time, the PFD average in each partial test time interval, and the total PFD average calculated on the full test time interval. Following the given expressions, parameter estimations are proposed to <b>assess</b> the system <b>failure</b> <b>rates</b> and the partial test effectiveness according to feedback data from previous test policies. Subsequently, an optimization of the partial test strategy is presented. In the 2 oo 6 system given as example, an improvement of about 10 % of the total PFD average has been obtained, just by a better (non-periodic) distribution of {{the same number of}} partial tests, in the full test time interval...|$|R
40|$|Background: Very {{long-term}} {{follow-up of}} oral implants is seldom {{reported in the}} literature. Purpose: To <b>assess</b> oral implant <b>failure</b> <b>rates</b> and marginal bone loss (MBL) of patients followed up {{for a minimum of}} 20 years. Materials and Methods: Implants placed in patients followed up for 20 + years were included. Descriptive statistics, survival analyses, generalized estimating equations were performed. Three-hundred implants were randomly selected for MBL. Results: 1, 045 implants (227 patients) were included. Implant location, irradiation, and bruxism affected the implant survival rate. Thirty-five percent of the failures occurred within the first year after implantation, and another 26. 8 % in the second/third year. There was a cumulative survival rate of 87. 8 % after 36 years of follow-up. In the last radiological follow up, 35 implants (11. 7 %) had bone gain, and 35 implants (11. 7 %) presented at least 3 mm of MBL. Twenty-six out of 86 failed implants with available radiograms presented severe MBL in the last radiological register before implant failure. Conclusions: Most of the implant failures occurred at the first few years after implantation, regardless of a very long follow up. MBL can be insignificant in long-term observations, but it may, nevertheless, be the cause of secondary failure of oral implants in some cases...|$|R
40|$|AbstractFailure rate {{estimation}} of wires in electrical wire interconnect system (EWIS) is virtual to aircraft safety assessment {{for lack of}} large realistic data. Using some environment, we can estimate the relative <b>failure</b> <b>rate</b> through the help of experts’ experiment, and then get the real <b>failure</b> <b>rate</b> for wires. To analysis the effect of environment on EWIS <b>failure</b> <b>rate,</b> we compared the relative <b>failure</b> <b>rate</b> for different environment groups. The result of comparisons shows that non-realistic <b>failure</b> <b>rates</b> may improve the estimate conservative of relative EWIS <b>failure</b> <b>rate...</b>|$|R
5000|$|Passive <b>failure</b> <b>rate</b> factor: Factor {{by which}} the element <b>failure</b> <b>rate</b> is multiplied when {{operating}} in the passive state {{as opposed to the}} active state. By default this factor will be one and typically between zero and one, indicating a lower passive <b>failure</b> <b>rate</b> than active <b>failure</b> <b>rate.</b>|$|R
40|$|Adverse weather such as hurricanes can {{significantly}} affect {{the reliability of}} composite power systems. Predicting the impact of hurricanes can help utilities for better preparedness and make appropriate restoration arrangements. In this dissertation, the impact of hurricanes on the reliability of composite power systems is investigated. Firstly, the impact of adverse weather on the long-term reliability of composite power systems is investigated by using Markov cut-set method. The Algorithms for the implementation is developed. Here, two-state weather model is used. An algorithm for sequential simulation is also developed {{to achieve the same}} goal. The results obtained by using the two methods are compared. The comparison shows that the analytical method can obtain comparable results and meantime it can be faster than the simulation method. Secondly, the impact of hurricanes on the short-term reliability of composite power systems is investigated. A fuzzy inference system is used to <b>assess</b> the <b>failure</b> <b>rate</b> increment of system components. Here, different methods are used to build two types of fuzzy inference systems. Considering the fact that hurricanes usually last only a few days, short-term minimal cut-set method is proposed to compute the time-specific system and nodal reliability indices of composite power systems. The implementation demonstrates that the proposed methodology is effective and efficient and is flexible in its applications. Thirdly, the impact of hurricanes on the short-term reliability of composite power systems including common-cause failures is investigated. Here, two methods are proposed to archive this goal. One of them uses a Bayesian network to alleviate the dimensionality problem of conditional probability method. Another method extends minimal cut-set method to accommodate common-cause failures. The implementation results obtained by using the two methods are compared and their discrepancy is analyzed. Finally, the proposed methods in this dissertation are also applicable to other applications in power systems...|$|R
40|$|AIMS: Durability of good {{glycaemic}} control (HbA 1 c) is {{of importance}} {{as it can}} be the foundation for delaying diabetic complications. It has been hypothesized that early initiation of treatment with the combination of oral anti-diabetes agents with complementary mechanisms of action can increase the durability of glycaemic control compared with metformin monotherapy followed by a stepwise addition of oral agents. Dipeptidyl peptidase- 4 inhibitors are good candidates for early use as they are efficacious in combination with metformin, show weight neutrality and a low risk of hypoglycaemia. We aimed to test the hypothesis that early combined treatment of metformin and vildagliptin slows β-cell deterioration as measured by HbA 1 c. METHODS: Approximately 2000 people with Type 2 diabetes mellitus who were drug-naive or who were treated with metformin for less than 1 month, and who have HbA 1 c of 48 - 58 mmol/mol (6. 5 - 7. 5 %), will be randomized in a 1 : 1 ratio in VERIFY, a 5 -year multinational, double-blind, parallel-group study designed to compare early initiation of a vildagliptin-metformin combination with standard-of-care initiation of metformin monotherapy, followed by the stepwise addition of vildagliptin when glycaemia deteriorates. Further deterioration will be treated with insulin. The primary analysis for treatment failure will be from a Cox proportional hazard regression model and the durability of glycaemic control will be evaluated by <b>assessing</b> treatment <b>failure</b> <b>rate</b> and the rate of loss in glycaemic control over time as co-primary endpoints. SUMMARY: VERIFY is the first study to investigate the long-term clinical benefits of early combination treatment vs. the standard-of-care metformin monotherapy with a second agent added by threshold criteria. © 2014 The Authors. Diabetic Medicine published by John Wiley & Sons Ltd on behalf of Diabetes U...|$|R
40|$|In the {{hospitality}} {{sector of the}} economy, restaurants account for {{the largest number of}} businesses. The financial <b>failure</b> <b>rate</b> of businesses in the general economy are sometimes reported with variations in the business cycle, but the specific <b>failure</b> <b>rate</b> of restaurant establishments has not been examined. In addition, <b>failure</b> <b>rates</b> for hospitality related businesses reported across geographic regions of the U. S. are not known. A review of related literature suggests that studies with a focus on the <b>failure</b> <b>rate</b> of hospitality related businesses have not used official business bankruptcy data recorded by the U. S. Bankruptcy Court System. Using these data, regional differences for the <b>failure</b> <b>rate</b> of restaurants are examined using ANOVA between regions based on <b>failure</b> <b>rates.</b> Results found that for restaurant <b>failure</b> <b>rates,</b> the New England region was found to have more differences with <b>failure</b> <b>rates</b> of restaurants in other regions. Significant differences in restaurant <b>failure</b> <b>rates</b> exist in six out of nine regions of the U. S...|$|R
40|$|In {{this paper}} the <b>failure</b> <b>rate</b> of the Weibull-Weibull length-biased mixture {{distribution}} which {{is characterized by}} five parameters is studied. Depending on the parameter values, it is shown that this <b>failure</b> <b>rate</b> can have one of six shapes, which are increasing <b>failure</b> <b>rate</b> (IFR), decreasing <b>failure</b> <b>rate</b> (DFR), upside down bathtub (UBT), modified upside down bathtub (MUBT), bathtub (BT), and modified bathtub (MBT) <b>failure</b> <b>rates,</b> by consequence it has zero, one or two turning points...|$|R
50|$|Under certain {{engineering}} assumptions (e.g. {{besides the}} above assumptions for a constant <b>failure</b> <b>rate,</b> {{the assumption that}} the considered system has no relevant redundancies), the <b>failure</b> <b>rate</b> for a complex system is simply the sum of the individual <b>failure</b> <b>rates</b> of its components, as long as the units are consistent, e.g. failures per million hours. This permits testing of individual components or subsystems, whose <b>failure</b> <b>rates</b> are then added to obtain the total system <b>failure</b> <b>rate.</b>|$|R
40|$|Statistical {{analysis}} and prediction of <b>failure</b> <b>rates</b> of water distribution pipes are usually performed using parametric lifetime models. In this paper, a new probabilistic measure for the <b>failure</b> <b>rate,</b> called the 'likelihood of number of failures', is defined and formulated for {{cases where the}} pipe lifetimes follow parametric models. The resulting theoretical <b>failure</b> <b>rates</b> are time-invariant and, therefore, the parametric models would be useful only if the <b>failure</b> <b>rates</b> of water distribution pipes are stationary random processes. This paper then examines the stationarity of pipe <b>failure</b> <b>rates</b> in practice. For the water pipes in the western district of Melbourne (Australia), the <b>failure</b> <b>rates</b> are empirically calculated using a 4 -year failure history, and {{it is observed that}} the distribution of empirical <b>failure</b> <b>rates</b> varies with time. In order to explain these variations, the pattern of rainfall in the region is compared with the pattern of <b>failure</b> <b>rate</b> variations, and in 70 % of the times the two patterns are observed to be consistent. Two approaches are proposed to tackle the time-varying nature of pipe <b>failure</b> <b>rate</b> processes: regular updating of the parameters of lifetime models or developing a non-parametric technique for modelling of pipe <b>failure</b> <b>rates...</b>|$|R
50|$|Government and {{commercial}} <b>failure</b> <b>rate</b> data: Handbooks of <b>failure</b> <b>rate</b> data for various components {{are available from}} government {{and commercial}} sources. MIL-HDBK-217F, Reliability Prediction of Electronic Equipment, is a military standard that provides <b>failure</b> <b>rate</b> data for many military electronic components. Several <b>failure</b> <b>rate</b> data sources are available commercially that focus on commercial components, including some non-electronic components.|$|R
40|$|The two-parameter linear <b>failure</b> <b>rate</b> {{distribution}} {{has been}} used quite successfully to analyze lifetime data. Recently, a new three-parameter distribution, known as the generalized linear <b>failure</b> <b>rate</b> distribution, has been introduced by exponentiating the linear <b>failure</b> <b>rate</b> distribution. The generalized linear <b>failure</b> <b>rate</b> distribution is a very flexible lifetime distribution, and the probability density function of the generalized linear <b>failure</b> <b>rate</b> distribution can take different shapes. Its hazard function also can be increasing, decreasing and bathtub shaped. The main aim {{of this paper is}} to introduce a bivariate generalized linear <b>failure</b> <b>rate</b> distribution, whose marginals are generalized linear <b>failure</b> <b>rate</b> distributions. It is obtained using the same approach as was adopted to obtain the Marshall-Olkin bivariate exponential distribution. Different properties of this new distribution are established. The bivariate generalized linear <b>failure</b> <b>rate</b> distribution has five parameters and the maximum likelihood estimators are obtained using the EM algorithm. A data set is analyzed for illustrative purposes. Finally, some generalizations to the multivariate case are proposed. Marshall-Olkin copula Maximum likelihood estimator <b>Failure</b> <b>rate</b> EM algorithm Fisher information matrix...|$|R
3000|$|The {{primary unit}} has a <b>failure</b> <b>rate</b> λ 1 and {{constant}} repair rate ‘µ’ whereas the standby unit {{is having a}} <b>failure</b> <b>rate</b> λ 1 when it is in online and a <b>failure</b> <b>rate</b> [...]...|$|R
40|$|The new {{better than}} used <b>failure</b> <b>rate</b> (NBUFR) and new {{better than average}} <b>failure</b> <b>rate</b> (NBAFR) classes of life {{distributions}} which are generalizations of the new better than used (NBU) class, and their dual classes the new worse than used <b>failure</b> <b>rate</b> (NWUFR) and the new worse average <b>failure</b> <b>rate</b> (nwafr), have been considered in the literature sa natural weakings of NBU(NWU) proberty...|$|R
50|$|When the <b>failure</b> <b>rate</b> is {{decreasing}} {{the coefficient of}} variation is ⩾ 1, and when the <b>failure</b> <b>rate</b> is increasing the coefficient of variation is ⩽ 1. Note that this result only holds when the <b>failure</b> <b>rate</b> is defined for all t ⩾ 0 and that the converse result (coefficient of variation determining nature of <b>failure</b> <b>rate)</b> does not hold.|$|R
