0|55|Public
2500|$|... 44 (7) – (<b>adjusted)</b> <b>commands</b> (direction indicators, braking light, etc.) ...|$|R
25|$|Staff {{meetings}} to <b>adjust</b> <b>command</b> structure were nearly a daily event in Alexander's army. They created an ongoing expectation among the Hetairoi of receiving {{an important and}} powerful command, {{if only for a}} short term. At the moment of Alexander's death, all possibilities were suddenly suspended. The Hetairoi vanished with Alexander, to be replaced instantaneously by the Diadochi, men who knew where they had stood, but not where they would stand now. As there had been no definite ranks or positions of Hetairoi, there were no ranks of Diadochi. They expected appointments, but without Alexander they would have to make their own.|$|R
40|$|SummaryTo execute {{accurate}} movements, animals must continuously adapt {{their behavior}} {{to changes in}} their bodies and environments. Animals can learn changes {{in the relationship between}} their locomotor commands and the resulting distance moved, then <b>adjust</b> <b>command</b> strength to achieve a desired travel distance. It is largely unknown which circuits implement this form of motor learning, or how. Using whole-brain neuronal imaging and circuit manipulations in larval zebrafish, we discovered that the serotonergic dorsal raphe nucleus (DRN) mediates short-term locomotor learning. Serotonergic DRN neurons respond phasically to swim-induced visual motion, but little to motion that is not self-generated. During prolonged exposure to a given motosensory gain, persistent DRN activity emerges that stores the learned efficacy of motor commands and adapts future locomotor drive for tens of seconds. The DRN’s ability to track the effectiveness of motor intent may constitute a computational building block for the broader functions of the serotonergic system. Video Abstrac...|$|R
40|$|This {{study was}} {{supported}} by the Howard Hughes Medical Institute and by the Simons Foundation award 325171. To execute accurate movements, animals must continuously adapt their behavior to changes in their bodies and environments. Animals can learn changes in the relationship between their locomotor commands and the resulting distance moved, then <b>adjust</b> <b>command</b> strength to achieve a desired travel distance. It is largely unknown which circuits implement this form of motor learning, or how. Using whole-brain neuronal imaging and circuit manipulations in larval zebrafish, we discovered that the serotonergic dorsal raphe nucleus (DRN) mediates short-term locomotor learning. Serotonergic DRN neurons respond phasically to swim-induced visual motion, but little to motion that is not self-generated. During prolonged exposure to a given motosensory gain, persistent DRN activity emerges that stores the learned efficacy of motor commands and adapts future locomotor drive for tens of seconds. The DRN’s ability to track the effectiveness of motor intent may constitute a computational building block for the broader functions of the serotonergic system. Publisher PDFPeer reviewe...|$|R
40|$|Successful {{interaction}} with a changing environment requires learning from previous experience and applying such knowledge in <b>adjusting</b> motor <b>commands</b> in a predictive way. To investigate how control strategies {{are affected by}} internal models of the statistical properties of the environment, we tested subjects in reaching movements using a virtual reality system and perturbed the target in non-random ways during the movement. Perturbation time and dynamic environments were experimentally controlled to vary the necessity of using prediction of perturbations to make full corrections. We show that prediction of perturbations is used in on-line corrections only if {{it can lead to}} better endpoint positional accuracy and less energy consumptions. These results are well fit by an optimal feedback control model that enables us to handle non-Gaussian perturbation statistics and non-quadratic cost functions. In addition to demonstrating the flexible use of internal models in generating control strategies, we also show that different learning mechanisms are involved during motor learning, some of which are more complex than <b>adjusting</b> motor <b>commands</b> based on previous errors in a trial-by-trial manner...|$|R
50|$|Research in {{individuals}} with complete peripheral deafferentation {{with and without}} vision of their writing hand finds increase of number of pen touches, increase in number of inversions in velocity, decrease of mean stroke frequency and longer writing movement duration. The changes show that cutaneous and proprioceptive feedback {{play a critical role}} in updating the motor memories and internal models that underlie handwriting. In contrast, sight provides only a secondary role in <b>adjusting</b> motor <b>commands.</b>|$|R
40|$|Empirical and {{modelling}} {{studies are}} reported which explore {{ways in which}} the central nervous system might consider musculo-skeletal geometry when generating commands for single degree of freedom elbow flexion and extension movements. In a series of experiments it is shown that subjects do not perform rapid, goal-directed flexion and extension movements equally accurately {{in different parts of the}} elbow's workspace. In these experiments, movements of 10, 20 and 30 degrees in amplitude were tested using up to five different initial elbow angles. When performing flexions, subjects tended to overshoot targets when starting from extended positions, to undershoot targets when starting from more flexed positions, and to perform relatively accurate movements when starting from the centre of the workspace. Final position accuracy was more variable for extensions. When reliable differences existed for extensions, subjects tended to produce a pattern of results opposite to that of flexions: subjects overshot targets when starting from flexed positions and undershot targets when starting from more extended positions. A model of elbow movement based on the $ lambda$ version of the equilibrium-point hypothesis was used to assess the extent to which the pattern of errors obtained in the empirical studies could be reproduced by a control scheme that does not <b>adjust</b> <b>commands</b> in response to changing musculo-skeletal geometry, but rather uses one single invariant command throughout the workspace. The motivation for testing the invariant command notion was to explore the possibility that motion planning might be achieved without an explicit representation of musculo-skeletal geometry. Predicted patterns of final position errors across the workspace matched empirically obtained error patterns for flexions, but the model performed less well when predicting the pattern of errors observed for extension movements...|$|R
40|$|We {{propose a}} new model of motor {{learning}} to explain the exceptional dexterity and rapid adaptation to change, which characterize human motor control. It is based on the brain simultaneously optimizing stability, accuracy and efficiency. Formulated as a V-shaped learning function, it stipulates precisely how feedforward commands to individual muscles are adjusted based on error. Changes in muscle activation patterns recorded in experiments provide direct support for this control scheme. In simulatedmotor learning of novel environmental interactions,muscle activation, force and impedance evolved in amanner similar to humans, demonstrating its efficiency and plausibility. This model of motor learning offers new insights as to how the brain controls the complex musculoskeletal system and iteratively <b>adjusts</b> motor <b>commands</b> to improve motor skills with practice. Keywords:motor control;motor learning; impedance control; internalmodel; computational algorithm;muscle cocontraction; stability; stiffnes...|$|R
500|$|Still too junior to be {{considered}} for command of an aircraft carrier, he received command of a seaplane tender, [...] He then returned to the Office of the Chief of Naval Operations as head of Special Weapons Plans (OP-604) in July 1961. He was awarded a Master of Arts degree from George Washington University in 1963. [...] In July 1963, he received command of an aircraft carrier, the [...] Despite having limited experience with ships, Ramage had no trouble <b>adjusting</b> to <b>commanding</b> one. He never felt though, that commanding a ship was an enjoyable as flying an aircraft. The ship won the Arleigh Burke award for most improved crew. Around this time, his marriage broke up, and he became divorced. He was remarried in Rome on 14 August 1964, to Virginia (Ginger) Keesling Cordes. She had two children, Randy and Karen Cordes.|$|R
40|$|We are {{investigating}} how to program robots {{so that they}} learn from experience. Our goal is to develop principled methods of learning that can improve a robot's performance {{of a wide range}} of dynamic tasks. We have developed task-level learning that successfully improves a robot's performance of two complex tasks, ball-throwing and juggling. With task- level learning, a robot practices a task, monitors its own performance, and uses that experience to <b>adjust</b> its task-level <b>commands.</b> This learning method serves to complement other approaches, such as model calibration, for improving robot performance...|$|R
50|$|Upper air observing {{systems are}} {{normally}} subject to latency {{based on the}} communication networks used and quality assurance protocol. TAMDAR observations are typically received, processed, quality controlled, and available for distribution or model assimilation in less than one minute from the sampling time. The sensor requires no flight crew involvement; it operates automatically and sampling rates and calibration constants can be <b>adjusted</b> by remote <b>command</b> from a US-based operations center. TAMDAR sensors continuously transmit atmospheric observations via a global satellite network in real-time as the aircraft climbs, cruises, and descends.|$|R
40|$|When {{exposed to}} novel {{dynamical}} conditions (e. g., externally imposed forces), neurologically intact subjects easily <b>adjust</b> motor <b>commands</b> {{on the basis}} of their own reaching errors. Subjects can also benefit from visual observation of others ʼ kinematic errors. Here, using fMRI, we scanned subjects watching movies depict-ing another person learning to reach in a novel dynamic environ-ment created by a robotic device. Passive observation of reaching movements (whether or not they were perturbed by the robot) was associated with increased activation in fronto-parietal re-gions that are normally recruited in active reaching. We found significant clusters in parieto-occipital cortex, intraparietal sulcus, as well as in dorsal premotor cortex. Moreover, it appeared that part of the network that has been shown to be engaged in pro-cessing self-generated reach error is also involved in observing reach errors committed by others. Specifically, activity in left intraparietal sulcus and left dorsal premotor cortex, as well as in right cerebellar cortex, was modulated by the amplitude of observed kinematic errors. ...|$|R
40|$|Permanent magnet {{synchronous}} machines (PMSMs) {{are widely}} used in electric vehicles and hybrid electric vehicles to propel the wheels. Various control strategies {{have been developed for}} PMSM drive systems to achieve both high efficiency and safe operation. In a PMSM drive system, generally the high voltage battery and the power converters are connected by a relay. In vehicle key-off events, although the battery is isolated immediately from the relay, the DC bus filter capacitor has to be discharged as quickly as possible to avoid an electrical hazard. This research explores the DC bus capacitor discharge of PMSM drive systems for hybrid/electric vehicles. Based on analyzing the power flow during discharge, a three-stage discharge algorithm has been developed, including a fast discharge stage, a DC bus voltage closed-loop regulation stage, and an inverter shutdown stage. The DC bus capacitor is quickly and safely discharged by dynamically <b>adjusting</b> the <b>command</b> currents for the current vector control of PMSMs. Both simulation and experimental results show the feasibility and performance of the proposed discharge technique...|$|R
40|$|Iterative {{learning}} control (ILC) develops controllers that iteratively <b>adjust</b> the <b>command</b> to a {{feedback control system}} in order to converge to zero tracking error following a specific desired trajectory. Unlike optimal control and other control methods, the iterations are made using the real world {{in place of a}} computer model. If desired, the learning process can be conducted both in the time domain during each iteration and in repetitions, making ILC a 2 D system. Because ILC iterates with the real world, and aims for zero error, the field pushes the limits of theory, modeling, and simulation, to predict the behavior when applied in the real world. It is the thesis of this paper that in order to make significant progress in this field it is essential that the research effort employ a coordinated simultaneous synergistic effort involving theory, experiments, and serious simulations. Otherwise, one very easily expends effort on something that seems fundamental from the theoretical perspective, but in fact has very little relevance to the performance in real world applications...|$|R
40|$|Abstract—Iterative {{learning}} control aims to achieve zero tracking error {{of a specific}} command. This is accomplished by iteratively <b>adjusting</b> the <b>command</b> given to a feedback control system, based on the tracking error observed in the previous iteration. One would like the iterations to converge to zero tracking error in spite of any error present in the model used to design the learning law. First, this need for stability robustness is discussed, and then the need for robustness of the property that the transients are well behaved. Methods of producing the needed robustness to parameter variations and to singular perturbations are presented. Then a method involving reverse time runs is given that lets the world behavior produce the ILC gains {{in such a way}} as to eliminate the need for a mathematical model. Since the real world is producing the gains, there is no issue of model error. Provided the world behaves linearly, the approach gives an ILC law with both stability robustness and good transient robustness, without the need to generate a model. Keywords—Iterative {{learning control}}, stability robustness, monotonic convergence. I I...|$|R
40|$|Graduation date: 2015 Permanent magnet {{synchronous}} machines (PMSMs) {{are widely}} used in electric vehicles and hybrid electric vehicles to propel the wheels. Various control strategies {{have been developed for}} PMSM drive systems to achieve both high efficiency and safe operation. In a PMSM drive system, generally the high voltage battery and the power converters are connected by a relay. In vehicle key-off events, although the battery is isolated immediately from the relay, the DC bus filter capacitor has to be discharged as quickly as possible to avoid an electrical hazard. This research explores the DC bus capacitor discharge of PMSM drive systems for hybrid/electric vehicles. Based on analyzing the power flow during discharge, a three-stage discharge algorithm has been developed, including a fast discharge stage, a DC bus voltage closed-loop regulation stage, and an inverter shutdown stage. The DC bus capacitor is quickly and safely discharged by dynamically <b>adjusting</b> the <b>command</b> currents for the current vector control of PMSMs. Both simulation and experimental results show the feasibility and performance of the proposed discharge technique...|$|R
40|$|After an {{estimation}} <b>command</b> <b>adjust</b> provides adjusted {{predictions of}} xbeta (the means in a linear-regression setting) or probabilities (available after certain estimation commands). The estimate is computed for {{each level of}} the by variable(s) setting the variable(s) specified in var[= #] [var[= #] [...] . ] to their mean or to the specified number if the = # part is used. Variables used in the estimation command but not included in either the by variable list or the adjust variable list are left at their current values, observation by observation. In this case adjust displays the average estimated prediction or probability for each level of the by variables. This is version 1. 3. 0, which will appear in STB- 46. ...|$|R
40|$|Abstract: In this paper, {{an online}} self-tuning precompensation for a Proportional-Integral-Derivative (PID) {{controller}} is proposed to control heading {{direction of a}} flying robot. The flying robot is a highly nonlinear plant, it is a modified X-Cell 60 radio-controlled helicopter. Heading direction is controlled to evaluate efficiency of the proposed precompensation algorithm. The heading control {{is based on the}} conventional PID control combined with an online self-tuning precompensation so that both the desired transient and steady state responses can be achieved. The precompensation is applied to compensate unsatisfied performances of the conventional PID controller by <b>adjusting</b> reference <b>command.</b> The precompensator is based on Takagi-Sugeno’s type fuzzy model, which learns to tune itself online. The main contribution of the proposed controller is to enhance the controlled performance of the conventional PID controller by adding a self-tuning precompensator on the existing conventional PID controller. The results show that the conventional PID controller with an online self-tuning precompensation has a superior performance than the conventional PID controller. In addition, the online self-tuning precompensation algorithm is implemented simply by adding the precompensator to the existing conventional PID controller and letting the self-tuning mechanism tune itself online...|$|R
40|$|International audienceAnimals {{continuously}} rely on sensory {{feedback to}} <b>adjust</b> motor <b>commands.</b> In order {{to study the}} role of visual feedback in goal-driven navigation, we developed a 2 D visual virtual reality system for zebrafish larvae. The visual feedback can be set {{to be similar to}} what the animal experiences in natural conditions. Alternatively, modification of the visual feedback can be used to study how the brain adapts to perturbations. For this purpose, we first generated a library of free-swimming behaviors from which we learned the relationship between the trajectory of the larva and the shape of its tail. Then, we used this technique to infer the intended displacements of head-fixed larvae, and updated the visual environment accordingly. Under these conditions, larvae were capable of aligning and swimming {{in the direction of a}} whole-field moving stimulus and produced the fine changes in orientation and position required to capture virtual prey. We demonstrate the sensitivity of larvae to visual feedback by updating the visual world in real-time or only at the end of the discrete swimming episodes. This visual feedback perturbation caused impaired performance of prey-capture behavior, suggesting that larvae rely on continuous visual feedback during swimming...|$|R
40|$|The {{cortical}} nucleus LMAN {{provides the}} output of a basal ganglia pathway that is necessary for vocal learning in juvenile songbirds. The shell subregion of LMAN gives rise to recurrent loops that may subserve specific learning-related functions. We report here that lesions within the LMANshell pathway cause no immediate disruption of vocal behavior, but prevent the development of stable vocal sequences {{as well as the}} ability to imitate vocal sounds. In both songbirds and humans, vocal learning entails forming a memory of vocal sounds from adult “tutors ” based on auditory experience during development, and then using feedback of self-produced vocalizations to <b>adjust</b> motor <b>commands</b> until vocal output matches the neural memory of those sounds 1. LMAN is composed of separate core and shell subregions, which give rise to independent parallel pathways that traverse the basal ganglia and thalamus (Fig. S 1 A) 2. LMANcore projects to vocal motor cortex (RA) and thence to hindbrain vocal motor and respiratory circuits. In contrast, LMANshell projects to Ad, an area of motor cortex adjacent to RA; Ad makes a prominent projection to a dorsal thalamic zone (DTZ) that sends projections back to LMAN {{as well as to the}} cortical motor-contro...|$|R
40|$|A {{pitch and}} surge coupled dynamic {{model of a}} {{high-speed}} craft is not available for dynamic trim control applications in the literature. The existing fluid-structure interaction models of a high-speed craft are not adequate for simulations and control applications, since they require {{a great deal of}} computation time, for example more than 20 - 40 sec. depending on a vessel particulars. Hence, in this work, we aimed to obtain a dynamic model of a high-speed craft for surge and pitch motions. Then the obtained model will be utilized to design an automatic controller which <b>adjust</b> the <b>command</b> signal on a high-speed craft to increase fuel efficiency, safety and comfort of passengers in a vessel. The coupled pitch and surge motion of a high-speed craft with trim tabs/interceptors was modelled by using full scale sea trial data. The linear parametric modelling using System Identification (SI) Methods and Artificial Neural Network (ANN) modelling were carried out and the comparisons of both the training and validation results are given. High correlation coefficients and low average values of absolute errors in surge and pitch dynamics were obtained by using ANN Method. The ANN model can be improved for further control designs on a marine vessel’s operations...|$|R
40|$|Electroactive polymer {{actuators}} {{are important}} for soft robotics, but {{can be difficult to}} control because of compliance, creep and nonlinearities. Because biological control mechanisms have evolved to deal with such problems, we investigated whether a control scheme based on the cerebellum would be useful for controlling a nonlinear dielectric elastomer actuator, a class of artificial muscle. The cerebellum was represented by the adaptive filter model, and acted in parallel with a brainstem, an approximate inverse plant model. The recurrent connections between the two allowed for direct use of sensory error to <b>adjust</b> motor <b>commands.</b> Accurate tracking of a displacement command in the actuator’s nonlinear range was achieved by either semi-linear basis functions in the cerebellar model or semi-linear functions in the brainstem corresponding to recruitment in biological muscle. In addition, allowing transfer of training between cerebellum and brainstem as has been observed in the vestibulo-ocular reflex prevented the steady increase in cerebellar output otherwise required to deal with creep. The extensibility and relative simplicity of the cerebellar-based adaptive-inverse control scheme suggests that it is a plausible candidate for controlling this type of actuator. Moreover, its performance highlights important features of biological control, particularly nonlinear basis functions, recruitment and transfer of training...|$|R
2500|$|As {{an example}} of {{negative}} feedback, the diagram might represent a cruise control system in a car, for example, that matches a target speed such as the speed limit. The controlled system is the car; its input includes the combined torque from the engine and from the changing slope of the road (the disturbance). The car's speed (status) is measured by a speedometer. [...] The error signal is {{the departure of the}} speed as measured by the speedometer from the target speed (set point). This measured error is interpreted by the controller to <b>adjust</b> the accelerator, <b>commanding</b> the fuel flow to the engine (the effector). The resulting change in engine torque, the feedback, combines with the torque exerted by the changing road grade to reduce the error in speed, minimizing the road disturbance.|$|R
40|$|In many applications, {{control systems}} {{are asked to}} perform the same task repeatedly. Learning control laws have been {{developed}} {{over the last few}} years that allow the controller to improve its performance each repetition, and to converge to zero error in tracking a desired trajectory. This paper generates a new type of learning control law that learns to minimize a quadratic cost function for tracking. Besides being of interest in its own right, this objective alleviates the need to specify a desired trajectory that can actually be performed by the system. The approach used here is to adapt appropriate methods from numerical optimization theory in order to produce learning control algorithms that <b>adjust</b> the system <b>command</b> from repetition to repetition in order to converge to the quadratic cost optimal trajectory...|$|R
5000|$|The Reeves AN/MSQ-77 Bomb Directing Central, Radar (nickname [...] "Miscue 77") was a USAF {{automatic}} tracking radar/computer system for command guidance of military aircraft during Vietnam War bomb runs at nighttime and during bad weather. Developed from the Reeves AN/MSQ-35, the AN/MSQ-77 reversed {{the process of}} Radar Bomb Scoring by continually estimating the bomb impact point before bomb release with a vacuum tube ballistic computer. Unlike [...] "Course Directing Centrals" [...] which guided aircraft to a predetermined release point, the AN/MSQ-77 algorithm continuously predicted bomb impact points during the radar track while the AN/MSQ-77's control <b>commands</b> <b>adjusted</b> the aircraft course. A close air support regulation prohibited AN/MSQ-77 Combat Skyspot bombing within 1000 yd of friendly forces unless authorized by a Forward Air Controller, and [...] "on several occasions" [...] strikes were as close as [...]|$|R
40|$|During a {{constant}} depth maneuver of an {{autonomous underwater vehicle}} (AUV), its pitch attitude and stern plane deflections create forces and moments to achieve equilibrium in the vertical plane. If an AUV has a proportional controller only in its depth control loop, then different weights or centers of gravity will cause different steady-state depth errors at trimmed conditions. In general, a steady-state depth error can be eliminated by adding an integral controller in the depth control loop. However, an improper integrator {{may lead to a}} bad transient response, even though the steady-state depth error can finally be eliminated. To remove the steady-state depth error, this study proposes methods that <b>adjust</b> the depth <b>command</b> and add a switching integral controller in the depth control loop. Simulation results demonstrate that the steady-state depth error can be eliminated and the transient response can be improved...|$|R
40|$|ABSTRACT: It is {{challenging}} {{to control the}} damping forces of magnetorheological (MR) fluid dampers because of the strong nonlinearity between the damping force of an MR fluid damper and the velocity across the damper, and the semiactive relationship between the damping force and the applied voltage/current. Hence, the desired damping force ought to be generated by an MR fluid damper cannot be commanded directly, only the command voltage applied to the current driver for the MR damper can be directly controlled. In this article, the configuration of a semiactive control system with MR fluid dampers is discussed and a damper controller based on signum function for MR fluid dampers is proposed. The damper controller is used to generate and <b>adjust</b> the <b>command</b> voltage to track the desired damping force determined by the system controller based on the desired and the actual damping forces. Two key factors for controlling the damping force of an MR fluid damper through a damper controller are considered in this article: (1) tracking ability of the controlled damping force to the desired damping force, and (2) energy requirement for the MR fluid damper. The characteristics of the controlled damping force and its corresponding command voltage are analyzed and compared with the Heaviside function damper controller. The simulation {{results show that the}} signum function controller outperforms the Heaviside function controller for better damping tracking ability while requiring less energy for the MR damper. Key Words: magnetorheological fluid damper, damper controller, semiactive control, signum function...|$|R
40|$|Regulation of {{exercise}} intensity {{is important for}} aerobic training and for exercise testing. Automatic control of oxygen uptake therefore has potential for use in exercise prescription and in tests to establish markers of cardiopulmonary status. The {{aim of this study}} was to investigate the feasibility of automatic feedback control of oxygen uptake during submaximal treadmill exercise. Six healthy male subjects aged 36. 0 plusmn 12. 2 years (mean plusmn standard deviation) ran on a computer-controlled treadmill while oxygen uptake was measured in real time using a breath-by-breath cardiopulmonary monitoring system. Linear dynamic models of oxygen-uptake response to changes in treadmill speed were obtained empirically using least squares optimization, and the models subjected to a cross-validation procedure. This resulted in selection of a first-order model with a time constant of 47 s. This model was used to design linear feedback controllers with a range of closed-loop bandwidth specifications. When implemented, each controller continuously monitored oxygen uptake and <b>adjusted</b> the <b>commanded</b> treadmill speed in real time in order to track a prespecified oxygen uptake profile. A series of closed-loop control tests illustrate that a single, fixed-parameter controller designed using a dynamic model from just one subject is robust enough to provide satisfactory control of a desired oxygen uptake profile for all subjects tested. Our results confirm the feasibility and robustness of automatic feedback control of oxygen uptake during treadmill exercise. Feedback regulation {{of exercise}} intensity via oxygen uptake may contribute to prescription of optimal training and testing programmes...|$|R
40|$|The study {{aimed to}} {{investigate}} the role that four populations of spinocerebellar neurones play in forwarding information on descending commands relayed by feline reticulospinal neurones. Both intracellular and extracellular recording was used from medially located ventral spinocerebellar tract (VSCT) neurones {{as well as from}} spinal border (SB) subpopulation of VSCT neurones and from dorsal spinocerebellar tract neurones located in Clarke's column (CC DSCT) and in the dorsal horn (dh DSCT) in the lumbosacral enlargement. Axons of reticulospinal neurones were stimulated within the ipsilateral and contralateral medial longitudinal fascicle (MLF). We found striking differences in synaptic input from reticulospinal neurones to these four populations of spinocerebellar neurones. Both monosynaptic and disynaptic excitatory input was found in VSCT and SB neurones, only disynaptic in CC DSCT neurones and none in dh DSCT neurones. Discharges of VSCT and SB neurones were potently modulated by inhibitory actions of group I and II afferents. Following application of single stimuli to peripheral nerves these neurones ceased to respond for about 5 ms and thereafter discharged at a lower incidence rate. As inhibition of spinocerebellar neurones and of α-motoneurones is evoked by the same premotor interneurones, VSCT neurones may provide the cerebellum with information on the likely outcome of reticulospinal actions on motoneurones depending on {{the degree to which they}} are inhibited. They may thereby enable the cerebellum to <b>adjust</b> descending <b>commands</b> relayed by reticulospinal neurones to the requirements of a given situation and thus prevent errors in the centrally initiated movements...|$|R
40|$|Abstract — This article {{analyzes}} and {{evaluates the}} stability of the biologically inspired gait of the DLR Crawler, a walking hexapod robot, with respect to leg loss. Using a kinematic simulation, ranges of velocity commands that result in stable gait coordination are determined for both cases, the undamaged robot and the robot experiencing the loss of a single leg. The results give insight how to <b>adjust</b> the motion <b>commands</b> after the loss of a leg. Further, a simplified dynamic simulation is used to analyze the effect of leg loss on the walking stability. Heuristic measures like curvature and length of the traveled path, roll and pitch angles are employed to evaluate the walking stability and performance. Some methods like shifting the COG or stiffening the variably compliant joints are proposed and discussed with respect to their ability to improve the walking performance in case of leg loss. In the end, the presented concepts are extended {{and for the first time}} applied to a simulated eight-legged robot. I...|$|R
40|$|License, which permits {{unrestricted}} use, distribution, {{and reproduction}} in any medium, provided the original work is properly cited. During a constant depthmaneuver of an {{autonomous underwater vehicle}} (AUV), its pitch attitude and stern plane deflections create forces and moments to achieve equilibrium in the vertical plane. If an AUV has a proportional controller only in its depth control loop, then different weights or centers of gravity will cause different steady-state depth errors at trimmed conditions. In general, a steady-state depth error can be eliminated by adding an integral controller in the depth control loop. However, an improper integrator {{may lead to a}} bad transient response, even though the steady-state depth error can finally be eliminated. To remove the steady-state depth error, this study proposes methods that <b>adjust</b> the depth <b>command</b> and add a switching integral controller in the depth control loop. Simulation results demonstrate that the steady-state depth error can be eliminated and the transient response can be improved. 1...|$|R
40|$|Abstract: This paper {{addresses}} {{the problem of}} steering a group of underactuated Autonomous Underwater Vehicles (AUVs) along given spatial paths, while holding a desired inter-vehicle formation pattern. We show how Lyapunov-based techniques and graph theory can be brought together to yield a decentralized control structure where {{the dynamics of the}} cooperating vehicles and the constraints imposed by the topology of the inter-vehicle communications network are explicitly taken into account. Path-following for each vehicle amounts to reducing an appropriately defined geometric error to a small neighborhood of the origin. Vehicle coordination is achieved by <b>adjusting</b> the speed <b>command</b> of each vehicle along its path according to information on the positions of a subset of the other vehicles, as determined by the communications topology adopted. Convergence and stability of the overall system are proved formally. This holds true in the presence of arbitrary bounded communication delays as well as communication failures under some mild condition {{on the nature of the}} failures. Simulations results are presented and discussed...|$|R
40|$|This article {{analyzes}} and {{evaluates the}} stability of the biologically inspired gait of the DLR Crawler, a walking hexapod robot, with respect to leg loss. Using a kinematic simulation, ranges of velocity commands that result in stable gait coordination are determined for both cases, the undamaged robot and the robot experiencing the loss of a single leg. The results give insight how to <b>adjust</b> the motion <b>commands</b> after the loss of a leg. Further, a simplified dynamic simulation is used to analyze the effect of leg loss on the walking stability. Heuristic measures like curvature and length of the traveled path, roll and pitch angles are employed to evaluate the walking stability and performance. Some methods like shifting the COG or stiffening the variably compliant joints are proposed and discussed with respect to their ability to improve the walking performance in case of leg loss. In the end, the presented concepts are extended {{and for the first time}} applied to a simulated eight-legged robot...|$|R
50|$|The {{collapse}} of communism, dismantlement of the Soviet Union, and {{disintegration of the}} Soviet Union introduced a new international world and prompted an Army-wide drawdown. This resulted in changes to military policy during the late 1980s and early 1990s. Warming superpower relations induced a period of adjustment and 5th Signal <b>Command</b> <b>adjusted</b> accordingly by: inactivating the 160th Signal Brigade and consolidating its units into the 2nd Signal Brigade; inactivating the 1st Signal Battalion of 7th Signal Brigade; and relocating the US 63rd Signal Battalion to Fort Gordon Georgia. The resulting organizational structure remains essentially intact today. The 2d Signal Brigade comprises the 39th, 43d, 52d, 69th, 102d, and 509th Signal Battalions. The 7th Signal Brigade comprised the 44th Signal Battalion and 72nd Signal Battalions until inactivation on 16 May 2014. In addition, the 22d Signal Brigade and its subordinate units were briefly assigned to 5th Signal Command prior to the brigade's inactivation on 22 May 2007.|$|R
40|$|During {{dexterous}} manipulation the basal relationships {{expressed in}} the employed fundamental muscle synergies are tuned precisely {{not only to the}} manipulative intent, but also to the physical properties of the object. Recent findings indicate that the sensorimotor mechanisms involved depend largely on predictive rather than servo-control mechanisms: The CNS monitors specific, more-or-less expected, peripheral sensory events and use these to directly apply control signals that are appropriate for the current task and its phase. On a fast time scale, discrete mechanical events encoded in populations of somatosensory afferents trigger compensatory actions to task pertur-bations, and allow task progress to be monitored for timing the release of motor commands related to the serial manipulative phases. This type of predictive feed-forward sensory control is termed 'sensory discrete-event driven control'. On an extended time scale, previous experience with the object at hand or similar objects is used to <b>adjust</b> the motor <b>commands</b> parametrically in advance of the movement, e. g. for the object's weight and surface friction. Through vision, for instance, common object...|$|R
40|$|The {{concept of}} {{multiple}} Autonomous Underwater Vehicles (AUVs) cooperatively performing a mission offers several advantages over single vehicles {{working in a}} non-cooperative manner such as in-creased efficiency, performance, reconfigurability, robustness {{and the emergence of}} new capabilities. This paper introduces the concept of coordinated path-following control of multiple AUVs. The vehicles are required to follow pre-specified spatial paths while keeping a de-sired inter-vehicle formation pattern in time. We show how Lyapunov-based techniques and graph theory can be brought together to yield a decentralized control structure where the dynamics of the cooperating vehicles and the constraints imposed by the topology of the inter-vehicle communications network are explicitly taken into account. Path-following for each vehicle amounts to reducing an appropriately defined geometric error to a small neighborhood of the origin. Vehicle coordination is achieved by <b>adjusting</b> the speed <b>command</b> of each vehicle along its path according to information on the positions of a subset of the other vehicles, as determined by the communications topology adopted. We illustrate our design procedure for underwater vehicles moving in three-dimensional space. Simulations results are presented and discussed...|$|R
