0|10000|Public
30|$|Centering {{decreases}} the <b>absolute</b> <b>standard</b> <b>deviations</b> of the extracted components. Yet the variance percentages {{of the higher}} order components increase substantially. This signifies that important amounts of the initial variation are redistributed among the higher order components 2, 3 and 4. On the contrary, performing the analysis without centering results in higher <b>absolute</b> <b>standard</b> <b>deviations.</b> Nonetheless, the variance percentages of the higher order components are substantially reduced {{in comparison to the}} 1 st component. We then observe that centering relocates a lot of the information included in postfire band 2 in the 2 nd component (eigenvector increases from 0.53 in case A to 0.73 in case C).|$|R
40|$|Similarity or {{distance}} measures play {{an important}} role in various pattern recognition applications such as classification, clustering, change detection, information retrieval, energy minimization and optimization problems. We shall analyze theoretically the two most popular quality measures MSE and SSIM used in image processing by showing their origin, similarities/differences and advantages/drawbacks. Both measures depend on the same parameters: sample means, <b>standard</b> <b>deviations</b> and correlation coefficient. It is shown that SSIM originates from two Dice measures and thus inherit their main drawback - dependence on the <b>absolute</b> mean and <b>standard</b> <b>deviation</b> values. Similarly, MSE depends on the <b>absolute</b> <b>standard</b> <b>deviation</b> values. A new similarity measure Composite quality index based on Means, <b>Standard</b> <b>deviations</b> and Correlation coefficient (CMSC) is proposed inheriting advantages of the both measures but at the same time avoiding their drawbacks...|$|R
40|$|Using {{aggregate}} data from DJIA since 1987, this paper attempts to address two potential co-directional behaviors of investors: Herding and positive feedback trading. These behavioral patterns bear interesting implications for market price {{as they may}} lead to excess volatility and mispricing. To empirically test for herding behavior, we employ two econometric techniques: the Cross Sectional <b>Standard</b> <b>Deviation</b> (CSSD) and the cross sectional <b>absolute</b> <b>standard</b> <b>deviation</b> (CSAD), while we employ the model formally introduced by Sentana and Wadhwani (1992) to empirically test for positive feedback trading. Our results support the joint significant presence of herding and positive feedback trading behaviors during periods of relatively large market price movements. </p...|$|R
50|$|Alternate {{optimization}} criteria {{have been}} used as well, such as <b>standard</b> <b>absolute</b> <b>deviations</b> and mean absolute deviations.|$|R
40|$|Similarity/distance {{measures}} play {{an important}} role in various signal/image processing applications such as classification, clustering, change detection and matching. In most cases, maybe excluding visual perception, the distance measure should be amplitude/intensity translation invariant what means that it depends only on the relative difference of compared variables/parameters, but not on their absolute values. The two most popular measures: mean squared error (MSE) and structural similarity (SSIM) index used in image processing have been analysed theoretically and experimentally by showing their origin, similarities/differences and main properties. Both measures depend on the same parameters: sample means, <b>standard</b> <b>deviations</b> and correlation coefficient. It has been shown that SSIM originates from the two generalised Dice measures and thus inherit their main property scale invariance. Consequently, this property leads to the dependence of the measure on <b>absolute</b> mean and <b>standard</b> <b>deviation</b> values. Similarly, MSE depends on the <b>absolute</b> <b>standard</b> <b>deviation</b> values. A new composite similarity/distance measure based on means, <b>standard</b> <b>deviations</b> and correlation coefficient (CMSC) which has been proposed recently exhibits translation invariance property with respect to means and <b>standard</b> <b>deviations.</b> Experiments on simulated and real data corrupted with various types of distortions: mean shift, contrast stretching, noise (additive/multiplicative, impulsive) and blurring, supported theoretical results...|$|R
40|$|The {{utility of}} {{analytical}} chemistry measurements in most applications {{is dependent on}} an assessment of measurement error. This paper demonstrates {{the use of a}} two-component error model in setting limits of detection and related concepts and introduces two goodness-of-fit statistics for assessing the appropriateness of the model for the data at hand. The model is applicable to analytical methods in which high concentrations are measured with approximately constant relative <b>standard</b> <b>deviation.</b> At low levels, the relative <b>standard</b> <b>deviation</b> cannot stay constant, since this implies vanishingly small <b>absolute</b> <b>standard</b> <b>deviation.</b> The two-component model has approximately constant <b>standard</b> <b>deviation</b> near zero concentration, and approximately constant relative <b>standard</b> <b>deviation</b> at high concentrations, a pattern that is frequently observed in practice. Here we discuss several important applications of the model to environmental monitoring and also introduce two goodness-of-fit statistics, to ascertain whether the data exhibit the error structure assumed by the model, as well as to look for problems with experimental design...|$|R
5000|$|For {{the normal}} distribution, {{the ratio of}} mean <b>absolute</b> <b>deviation</b> to <b>standard</b> <b>deviation</b> is [...] Thus if X is a {{normally}} distributed random variable with expected value 0 then, see Geary (1935): ...|$|R
40|$|This paper {{examines}} {{the existence of}} behavioral bias labeled “Herding ” in the U. S. market. We studied the turnover effect on herding movement by modifying the Cross Sectional <b>Standard</b> <b>Deviation</b> (CSSD) model and the Cross Sectional <b>Absolute</b> <b>Standard</b> <b>Deviation</b> (CSAD) model. The results indicate that herding is present and is a long-lived phenomenon in the American financial market. We find also that herding is stronger in the S&P 100 index than in the DJIA index. We also find that trading volume contributes in increasing asymmetric herding. By applying VAR and Granger causality test, we find causal link of herding – trading volume. More particularly, we find that trading volume cannot generate herding behavior, except for liquid market. However, contemporaneous herding is a deterministic factor for increasing trading volume. Over the sample period, we examine the herd behavior during Subprime crisis. We find that herding is more intensified during subprime crisis, which contributes to accentuate and elongate it...|$|R
40|$|The {{performance}} of the standard hierarchy of ab initio models—that is, Hartree–Fock theory, second-order Møller–Plesset theory, coupled-cluster singles-and-doubles theory, and coupled-cluster singles-doubles-approximate-triples theory—in combination with correlation-consistent basis sets is investigated for equilibrium geometries of molecules containing second-row elements. From an analysis on a collection of 31 molecules yielding statistical samples of 41 bond distances and 13 bond angles, the statistical errors mean <b>deviation,</b> mean <b>absolute</b> <b>deviation,</b> <b>standard</b> <b>deviation,</b> and maximum <b>absolute</b> deviation are established at each level of theory. The importance of core correlation is examined by comparing calculations in the frozen-core approximation with calculations where all electrons are correlate...|$|R
40|$|It {{is known}} that electromyostimulation (EMS) alone or {{superimposed}} over voluntary contraction (EV) can effectively improve muscle strength. However, {{the effect of this}} type of training on the ability to control force production at submaximal levels is unknown. The authors examined the effects of EV training on steadiness in force production of knee extensors and flexors in older adults. Forty participants, including 20 men and 20 women, 60 – 77 years of age, were randomly allocated into a control group (CG) and an electromyostimulation superimposed over voluntary contraction (EVG) group. The EVG performed 30 bilateral isometric knee extension and flexion contractions per session, 3 training sessions per week, for 6 weeks. The variations in force production, expressed in <b>absolute</b> (<b>standard</b> <b>deviation</b> [SD]) and relative (coefficient of variation [CV]) terms, were assessed in isometric contractions at 5...|$|R
40|$|Monod kinetic {{parameters}} (Ks, µmax, and Y) {{that are}} estimated from batch experimental data can have large uncertainties due to linear correlations between them. The {{degree of correlation}} and the resulting uncertainties of the Monod parameters are functions of the initial experimental conditions, {{the values of the}} parameters, the type and magnitude of measurement errors, and the sampling number. Careful manipulation of experimental conditions can reduce the correlations between Monod parameters allowing for the estimation of Monod kinetic parameters with the lowest degree of uncertainty. By dimensionless analysis, the correlation and relative <b>standard</b> <b>deviations</b> of Monod parameters were found to be functions of a few dimensionless variables involving the initial substrate (S 0) and cell (X 0) concentrations. Quantitative relationships were analyzed between the dimensionless variables and the correlation and the uncertainties of the Monod parameters. This analysis allowed for identification of the optimal experimental conditions for estimating Monod parameters under both no growth and growth conditions coupled with two kinds of measurement errors: those with constant <b>absolute</b> <b>standard</b> <b>deviation</b> and those with constant relative <b>standard</b> <b>deviation.</b> Examples involving the microbial reduction of iron (III) as an electron acceptor are used to illustrate the application of the developed technique...|$|R
40|$|A high-precision vision {{detection}} and measurement system using mobile robot is {{established for the}} industry field detection of motorcycle frame hole and its diameter measurement. The robot path planning method is researched, and the non-contact measurement method with high precision based on visual digital image edge extraction and hole spatial circle fitting is presented. The Canny operator is used to extract the edge of captured image, the Lagrange interpolation algorithm is utilized to determine the missing image edge points and calculate the centroid, and the least squares fitting method is adopted to fit the image edge points. Experimental {{results show that the}} system can be used for the high-precision real-time measurement of hole on motorcycle frame. The <b>absolute</b> <b>standard</b> <b>deviation</b> of the proposed method is 0. 026 7 mm. The proposed method can not only improve the measurement speed and precision, but also reduce the measurement error...|$|R
40|$|Graduation date: 1966 Aromatic Nitro Compounds. The n-values for the {{reduction}} of the isomers of nitrophenol and nitrobenzoic acid and for several other nitro compounds are determined in dimethylsulfoxide by controlled potential coulometry. A procedure is given in which one mole of nitro compound may be determined with errors of less than one percent. The associated background currents are quantitatively evaluated, and electrolysis conditions for their minimization are discussed. Controlled potential polarographic determinations are given for these nitro compounds in dimethylsulfoxide, and reaction schemes are proposed for the stepwise reductions. Water. Microgram quantities of water are determined by rapid, controlled potential coulometry. Excess iodine is produced and removed coulometrically in a Karl Fischer system. By means of a special cell design, two μmoles of iodine in methanol may be reduced in 96 seconds. Ten to 74 μg. of water in methanol and 18 to 82 μg. of water in dimethylsulfoxide may be determined with an <b>absolute</b> <b>standard</b> <b>deviation</b> of ± 0. 2 and 0. 3 μg. of water, respectively...|$|R
40|$|Colour and {{brightness}} of the captured images from low cost digital cameras are usually different from the colour and {{brightness of}} the original scene. Many factors {{are responsible for the}} low contrast images such as non uniform illumination, large or small exposure of some specific regions, and the unwanted movements of camera users. Due to these reasons the captured image to looks annoying to human visual system. Thus, contrast enhancement methods are required for improving the visual appearance of the colour images. In this paper the performance of contrast limited adaptive histogram equalization (CLAHE) method is compared with method of DC coefficient scaling in the compressed DCT domain for enhancing the contrast of colour images. In addition, as a modification DC coefficient scaling is also implemented in the CIE-Lab colour space. The contrast is only enhanced in L component and keeping the colour information preserved. This improves the entropy of standard method. For comparing the performance along with SNR and entropy the <b>absolute</b> <b>standard</b> <b>deviation</b> difference is also used as parameters. The methods are tested on various true colour images from different environment...|$|R
40|$|The {{objective}} {{of this study is}} to explore the Europe 2020 development strategy, from Romania, trough qualitative methods and the corelation analysis trough quantitative methods of the European Funds present in Romania in the period 2007 - 2010 with the strategy's indicators. From the indicators presented by the European Uniun for the Europe 2020 development strategy,t the following indicators were chosen: "Total expenses for Research and Development as % of GDP) ", "Renewable energy share of the total energy consumption", "Early school leavers rate" and an alaysis of the correlation with the "Total available allocated budget of the European Union financed projects, arithmetic mean per project" indicator, using Pearson's correlation coefficient and determining also the algebraic average, range, absolute <b>deviation,</b> mean <b>absolute</b> <b>deviation,</b> <b>standard</b> <b>deviation,</b> skewness and kurtosis...|$|R
40|$|Purpose: Using a model tablet, the {{influence}} of breakability methodology on mass uniformity of half- and quarter-tablets {{as well as the}} comparison of different data acquisition and evaluation approaches were investigated. Moreover, different breakability evaluation criteria were compared based upon distribution as well as distribution-free models. Methods: A cross-scored tablet, i. e. having two break-marks, was broken by different methods by different persons, and the masses determined for the whole (unbroken) tablets, the half- tablets and quarter-tablets. Results: Beside the possible interaction between the methodology and the person breaking the tablets, the major factor significantly influencing the mass uniformity of broken tablets is the breakability methodology. The best results, i. e. smallest loss and smallest variability, are obtained when the breaking force applied by the thumbs is directed towards the score side of the tablet, i. e. by "opening" the score. Using our model tablet, significant differences between the different evaluation criteria are observed, with the USP/NF approach being best in line with the detailed analysis of all broken tablets. Conclusions: Assuming that for this model tablet the variance is a linear function of the break-line length, the <b>standard</b> <b>deviation</b> of quarter-tablets is theoretically calculated to be 0. 87 times the <b>standard</b> <b>deviation</b> of the half- tablets. As the <b>absolute</b> <b>standard</b> <b>deviation,</b> expressed in mass units, will thus remain approximately identical, the relative <b>standard</b> <b>deviation</b> will nearly double as the mean mass of the quarter-tablets will be half of the mean mass of the half- tablets. This was experimentally confirmed...|$|R
40|$|The UNIQUAC {{activity}} coefficient model and fugacity coefficient model of modified Redlich-Kwong predicted vapor-liquid equilibrium between {{carbon dioxide and}} water efficiently. The {{activity coefficient}} model needed the energy interaction parameters between molecules {{of carbon dioxide and}} water. Those parameters can be obtained by non-linear regression method of the experimental data of the vapor-liquid equilibria of carbon dioxide and water (Lide, 1992). The fugacity coefficient model of modified Redlich- Kwong needed only some physical properties of carbon dioxide and water without any interaction parameters. The experimental data had ranges of temperature and partial pressure of carbon dioxide between 10 to 100 ºC and 5 to 1, 200 kPa, respectively. The parameters for the activity coefficient model are temperature dependent but are not concentration dependent. The regression results gave good agreements with the experimental data in which the mean absolute error (MAE) between experiment and calculated partial pressure of carbon dioxide was 2. 72 % and the mean <b>absolute</b> <b>standard</b> <b>deviation</b> (MAD) of that error was 1. 35 %. Comparing the effects of activity coefficients and fugacity coefficients, we found that the non-ideality in vapor phase was more influential than the non-ideality in liquid phase...|$|R
40|$|Emotion-aware {{consumer}} products require reliable, short-term emotion assessment (i. e., unobtrusive, robust, and lacking calibration). To explore {{the feasibility of}} this, an experiment was conducted where the galvanic skin response (GSR) and three electromyography (EMG) signals (frontalis, corrugator supercilii, and zygomaticus major) were recorded on 24 participants who watched eight 2 -min emotion inducing film fragments. The unfiltered psychophysiological signals were processed and six statistical parameters (i. e., mean, <b>absolute</b> <b>deviation,</b> <b>standard</b> <b>deviation,</b> variance, skewness, and kurtosis) were derived for each 10 -s interval of the film fragment. For each physiological signal, skewness and kurtosis discriminated among affective states, accompanied by other parameters, depending on the signal. The skewness parameter also showed to indicate mixed emotions. Moreover, a mapping {{of events in the}} fragments on the signals showed the importance of short-term emotion assessment. Hence, this research identified generic features, denoted important considerations, and illustrated the feasibility of emotion-aware {{consumer products}}...|$|R
40|$|A {{close range}} photogrammetric (CRP) model of an {{as-built}} 40 m anchor handling tug hull {{located in an}} open space shipyard was constructed in this study {{through the use of}} a low cost amateur digital single-lens reflex camera, together with a modestly priced photogrammetric software. Through a series of comprehensive statistical tests, the constructed CRP tug hull model was quantitatively evaluated and analyzed by comparing the CRP measurements with the manually measured tug hull offset data from a lines-plan drawing. The statistical tests showed that most of the measured target coordinates were considerably accurate in this study, with absolute mean of error 4. 1 mm and <b>absolute</b> <b>standard</b> <b>deviation</b> of error ± 4. 5 mm. Paired Student t-test showed that the modeled CRP Z-offset data (ZCRP) is not statistically different from the actual Z-offset data, ZOFF (p> 0. 05). Linear regression analysis also illustrates a near perfect linear relationship between these two variables. The accuracy achieved in this study is considerably good and sufficient for usual metrological measurement in small- or medium-sized shipbuilding industry, despites the presence of disturbances related to the characteristics of the open space shipyard. In future, a better targeting approach or target material should be used to further improve the CRP measurement accuracy...|$|R
40|$|Finance professionals, who are {{regularly}} exposed to notions of volatility, seem to confuse mean <b>absolute</b> <b>deviation</b> with <b>standard</b> <b>deviation,</b> causing an underestimation of 25 % with theoretical Gaussian variables. In some “fat tailed ” markets the underestimation can {{be up to}} 90 %. The mental substitution of the two measures is consequential for decision making {{and the perception of}} market variability. Electronic copy of this paper is available at...|$|R
40|$|This paper {{presents}} {{neural network}} based {{models for the}} prediction of propagation path loss in urban environment. The neural networks are designed separately for line-of-sight (LOS) and non-line-of-sight (NLOS) cases. The performance of the neural model is {{compared to that of}} the COST 231 -Walfisch-Ikegami model, the Walfisch-Bertoni model and the single regression model, based on the <b>absolute</b> mean error, <b>standard</b> <b>deviation</b> and the root mean squared error between predicted and measured values...|$|R
40|$|A {{versatile}} potentiometer {{that works}} with electrode arrays in flow injection and/or monosegmented flow systems is described. The potentiometer is controlled by a microcomputer that allows individual, sequential multiplexed or random accesses to eight electrodes while employing only one reference electrode. The instrument was demonstrated by monitoring an array of seven flow-through ion-selective electrodes for Ag+ and for three electrodes for Cl(-), Ca 2 + and K+. The figures of merit {{of the individual and}} multiplexed (summed) readings of the electrode array were compared. The <b>absolute</b> <b>standard</b> <b>deviation</b> of the measurements made by summing the potential of two or more electrodes was maintained constant, thus improving the precision of the measurements. This result shows that an attempt to combine the signals of the electrodes to produce a more intense signal in the Hadamard strategy is feasible and accompanied by a proportional improvement in the precision of individual measurements. The preliminary tests suggest that the system can allow for 270 determinations per hour, with a linear range from 1. 0 x 10 (- 2) to 1. 0 x 10 (- 4) mol l(- 1) for the three different analytes. Detection limits were estimated as 3. 1 x 10 (- 5), 3. 0 x 10 (- 6) and 1. 0 x 10 (- 5) mol l(- 1) for Cl(-), Ca 2 + and K+, respectively...|$|R
40|$|Abstract. To improve human-computer {{interaction}} (HCI), computers {{need to recognize}} and respond properly to their user's emotional state. This is a fun-damental application of affective computing, which relates to, arises from, or deliberately inuences emotion. As a rst step to a system that recognizes emo-tions of individual users, this research focuses on how emotional experiences are expressed in six parameters (i. e., mean, <b>absolute</b> <b>deviation,</b> <b>standard</b> <b>deviation,</b> variance, skewness, and kurtosis) of physiological measurements of three elec-tromyography signals: frontalis (EMG 1), corrugator supercilii (EMG 2), and zy-gomaticus major (EMG 3). The 24 {{participants were asked to}} watch lm scenes of 120 seconds, which they rated afterward. These ratings enabled us to distinguish four categories of emotions: negative, positive, mixed, and neutral. The skewness of the EMG 2 and four parameters of EMG 3, discriminate between the four emo-tion categories. This, despite the coarse time windows that were used. Moreover, rapid processing of the signals proved to be possible. This enables tailored HCI facilitated by an emotional awareness of systems. ...|$|R
40|$|The paper {{deals with}} the {{construction}} and determination of coordinates of the absoluteEDMs baseline in a laboratory with 16 pillars with forced centring. Leica <b>Absolute</b> TrackerAT 401 (<b>standard</b> <b>deviation</b> of distance measurement: 5 μ m, <b>standard</b> <b>deviation</b> of anglemeasurement: 0. 15 mgon), which is designed for very accurate industrial measurements,was used for our purpose. Lengths between the baseline points were determined with astandard deviation of 0. 02 mm. The baseline is used for determining systematic and randomerrors of distance meters and for accuracy of distance meters at short distances commonin engineering surveying for purposes of mechanical engineering...|$|R
40|$|Study Design. Automatic {{measurement}} of Cobb angle {{in patients with}} scoliosis. Objective. To test the accuracy of an automatic Cobb angle determination method from frontal radiographical images. Summary of Background Data. Thirty-six frontal radiographical images of patients with scoliosis. Methods. A modifi ed charged particle model is {{used to determine the}} curvature on radiographical spinal images. Three curve fitting methods, piece-wise linear, splines, and polynomials, each with 3 variants were used and evaluated for the best fit. The Cobb angle was calculated out of these curve fit lines and compared with a manually determined Cobb angle. The best-automated method is determined {{on the basis of the}} lowest mean <b>absolute</b> error and <b>standard</b> <b>deviation,</b> and the highest R^ 2. Results. The error of the manual Cobb angle determination among the 3 observers, determined as the mean of the <b>standard</b> <b>deviations</b> of all sets of measurements, was 3. 37 °. For the automatic method, the best piece-wise linear method is the 3 -segments method. The best spline method is the 10 -steps method. The best polynomial method is poly 6. Overall, the best automatic methods are the piece-wise linear method using 3 segments and the polynomial method using poly 6, with a mean absolute error of 4, 26 ° and 3, 91 ° a <b>standard</b> <b>deviation</b> of 3, 44 ° and 3, 60 °, and a R^ 2 of 0. 9124 and 0. 9175. The standard measurement error is significantly lower than the upper bound found in the literature (11. 8 °). Conclusion. The automatic Cobb angle method seemed to be better than the manual methods described in the literature. The piece-wise linear method using 3 segments and the polynomial method using poly 6 yield the 2 best results because the mean <b>absolute</b> error, <b>standard</b> <b>deviation,</b> and R^ 2 are the best of all methods. ...|$|R
40|$|AbstractRecommender {{systems are}} {{information}} filtering tools that aspire {{to predict the}} rating for users and items, predominantly from big data to recommend their likes. Movie recommendation systems provide a mechanism to assist users in classifying users with similar interests. This makes recommender systems essentially {{a central part of}} websites and e-commerce applications. This article focuses on the movie recommendation systems whose primary objective is to suggest a recommender system through data clustering and computational intelligence. In this research article, a novel recommender system has been discussed which makes use of k-means clustering by adopting cuckoo search optimization algorithm applied on the Movielens dataset. Our approach has been explained systematically, and the subsequent results have been discussed. It is also compared with existing approaches, and the results have been analyzed and interpreted. Evaluation metrics such as mean <b>absolute</b> error (MAE), <b>standard</b> <b>deviation</b> (SD), root mean square error (RMSE) and t-value for the movie recommender system delivers better results as our approach offers lesser value of the mean <b>absolute</b> error, <b>standard</b> <b>deviation,</b> and root mean square error. The experiment results obtained on Movielens dataset stipulate that the proposed approach may provide high performance regarding reliability, efficiency and delivers accurate personalized movie recommendations when compared with existing methods. Our proposed system (K-mean Cuckoo) has 0. 68 MAE, which is superior to existing work (0. 78 MAE) [1] and also has improvement of our previous work (0. 75 MAE) [2]...|$|R
40|$|We {{carry out}} the {{calibration}} of an ultraviolet spectrometer by using a cryogenic electrical-substitution radiometer and intensity-stabilized laser sources. A comparison of the error budgets for the laser-based calibration described here and for a calibration using a type-FEL tungsten spectral-irradiance standard indicates that this technique could provide an improvement of a factor of about three in {{the uncertainty of the}} spectrometer calibration, resulting in an <b>absolute</b> accuracy (<b>standard</b> <b>deviation</b> of three) of about 1 percent at 257 nm. The technique described here might significantly improve the accuracy of calibrations on NASA ozone-monitoring and solar ultraviolet-monitoring spectrophotometers when used to complement present procedures that employ lamps and the SURF II synchrotron ultraviolet radiation facility at the National Institute of Standards and Technology...|$|R
40|$|Conventional {{overnight}} polysomnography (PSG) used {{to determine}} the respiratory behaviour during sleep can be a complex and expensive procedure. Pulse transit time analysis (PTT) has shown potential to detect obstructive apnoeic and hypopnoeic events (OE) in adults. Due to abnormalities in central ventilatory control, recurring OE may occur. This study was undertaken to determine the potential of PTT to differentiate responses during upper airway obstruction in the paediatric population. This preliminary study included 11 children (10 male; aged 7. 5 ± 3. 8 year) recruited to investigate PTT trend during single and recurrent OE. PTT measurements were evaluated against the corresponding PSG results pre-scored by two blinded obsercvers. A total of 110 valid OE (47 single and 63 recurrent) were observed during these PSG studies. There were distinct PTT responses observed for these two types of OE with respect to those of tidal breathing (P < 0. 05). For the tidal breathing events, the mean <b>absolute</b> <b>standard</b> <b>deviation</b> (SD) and maximal percentage (%) decrease (MAX) were 7. 71 ms and 3. 88 % respectively. For the recurrent OE, the absolute SD, SD (%) and MAX were 52. 21 ms, 8. 52 % and 55. 08 % accordingly while for the single OE, the absolute SD, SD (%) and MAX were 12. 23 ms, 5. 27 % and 13. 56 % respectively. The findings herein can suggest that PTT can be a valuable clinical tool in the paediatric respiratory sleep studies. © Springer Science+Business Media, LLC 2008...|$|R
40|$|To improve human-computer {{interaction}} (HCI), computers {{need to recognize}} and respond properly to their user’s emotional state. This is a fundamental application of affective computing, which relates to, arises from, or deliberately influences emotion. As a first step to a system that recognizes emotions of individual users, this research focuses on how emotional experiences are expressed in six parameters (i. e., mean, <b>absolute</b> <b>deviation,</b> <b>standard</b> <b>deviation,</b> variance, skewness, and kurtosis) of not baseline-corrected physiological measurements of the galvanic skin response (GSR) and of three electromyography signals: frontalis (EMG 1), corrugator supercilii (EMG 2), and zygomaticus major (EMG 3). The 24 {{participants were asked to}} watch film scenes of 120 seconds, which they rated afterward. These ratings enabled us to distinguish four categories of emotions: negative, positive, mixed, and neutral. The skewness and kurtosis of the GSR, the skewness of the EMG 2, and four parameters of EMG 3, discriminate between the four emotion categories. This, despite the coarse time windows that were used. Moreover, rapid processing of the signals proved to be possible. This enables tailored HCI facilitated by an emotional awareness of systems...|$|R
40|$|Supplementary ResultsRefinement for Gene Loss and DuplicationEstimates under Opal Stop Codon RecodingsSupplementary MethodsIdentification of Trusted Reference GenomesRefining Marker Sets for Lineage-specific Gene Loss and DuplicationDetermination of Coding TableSystematic Bias of Completeness and Contamination EstimatesSupplemental Figure S 1. Distribution of the 104 {{bacterial}} and 281 gammaproteobacterial marker genes {{around the}} E. coli K 12 genome. Supplemental Figure S 2. Error in completeness and contamination estimates on simulated genomes with {{varying levels of}} completeness and contamination generated under the random contig model. Supplemental Figure S 3. Error in completeness and contamination estimates on simulated genomes with varying levels of completeness and contamination generated under the inverse length model. Supplemental Figure S 4. Maximum-likelihood genome tree inferred from 5656 reference genomes. Supplemental Figure S 5. Error in completeness and contamination estimates on simulated genomes with varying levels of completeness and contamination generated under the random fragment model using a window size of 20 kbp. Supplemental Figure S 6. Error in completeness and contamination estimates on simulated genomes with varying levels of completeness and contamination generated under the inverse length model. Supplemental Figure S 7. Error in completeness and contamination estimates on simulated genomes from different phyla. Supplemental Figure S 8. Bias in completeness and contamination estimates when modelled as a binomial distribution. Supplemental Figure S 9. GC-distribution plots of the HMP Capnocytophaga sp. oral taxon 329 genome. Supplemental Figure S 10. Phylogenetic placement of the two genomes (Cluster 0 and Cluster 1) identified within the HMP Capnocytophaga sp. oral taxon 329 genome. Supplemental Figure S 11. Completeness estimates for 90 putative population genomes recovered from an acetate-amended aquifer. Supplemental Figure S 12. Contamination estimates for 90 putative population genomes recovered from an acetate-amended aquifer. Supplemental Figure S 13. Identification of the 213 marker genes within the Meyerdierks et al. (2010) ANME- 1 genome. Supplemental Figure S 14. Refining a marker set for lineage-specific gene loss and duplication. Supplemental TablesSupplemental Table S 1. Mean absolute error of completeness (comp.) and contamination (cont.) estimates determined using different universal- and domain-specific marker gene sets. Supplemental Table S 2. Number of marker genes and marker sets for taxonomic groups with ≥ 20 reference genomes. Supplemental Table S 3. Mean absolute error of completeness (comp.) and contamination (cont.) estimates determined using domain-specific marker genes treated individually (IM) or organized into collocated marker sets (MS). Supplemental Table S 4. Mean <b>absolute</b> error and <b>standard</b> <b>deviation</b> of completeness (comp.) and contamination (cont.) estimates determined using domain-specific marker genes treated individually (IM) or organized into collocated marker sets (MS). Supplemental Table S 5. Mean <b>absolute</b> error and <b>standard</b> <b>deviation</b> of completeness (comp.) and contamination (cont.) estimates determined using domain-specific marker genes treated individually (IM) or organized into collocated marker sets (MS). Supplemental Table S 6. Phylogenetically informative marker genes used to infer the reference genome tree along with matching PhyloSift genes. Supplemental Table S 7. Phylogenetically informative genes used in PhyloSift without a matching CheckM gene. Supplemental Table S 8. Mean absolute error of completeness (comp.) and contamination (cont.) estimates determined using domain-specific marker sets (dms), the lineage-specific marker set selected by CheckM (sms), and the best performing lineage-specific marker set (bms). Supplemental Table S 9. Mean <b>absolute</b> error and <b>standard</b> <b>deviation</b> of completeness (comp.) and contamination (cont.) estimates determined using domain-specific marker sets (dms), the lineage-specific marker set selected by CheckM (sms), and the best performing lineage-specific marker set (bms). Supplemental Table S 10. Mean <b>absolute</b> error and <b>standard</b> <b>deviation</b> of completeness (comp.) and contamination (cont.) estimates determined using domain-specific marker sets (dms), the lineage-specific marker set selected by CheckM (sms), and the best performing lineage-specific marker set (bms). Supplemental Table S 11. Mean <b>absolute</b> error and <b>standard</b> <b>deviation</b> of completeness (comp.) and contamination (cont.) estimates determined using domain-specific marker sets (dms) and the lineage-specific marker set selected by CheckM (sms). Supplemental Table S 12. Mean <b>absolute</b> error and <b>standard</b> <b>deviation</b> of completeness (comp.) and contamination (cont.) estimates determined using domain-specific marker sets (dms) and the lineage-specific marker sets selected by CheckM (sms). Supplemental Table S 13. Mean <b>absolute</b> error and <b>standard</b> <b>deviation</b> of completeness (comp.) and contamination (cont.) estimates determined using domain-specific marker sets (dms) and the lineage-specific marker sets selected by CheckM (sms). Supplemental Table S 14. Taxonomic rank of the selected lineage-specific marker set used for {{evaluating the quality of}} genomes at different degrees of taxonomic novelty. Supplemental Table S 15. Mean <b>absolute</b> error and <b>standard</b> <b>deviation</b> of completeness (comp.) and contamination (cont.) estimates for simulated genomes at different degrees of taxonomic novelty. Supplemental Table S 16. Lineage-specific completeness and contamination estimates for isolate genomes from large-scale sequencing initiatives. (see Excel file) Supplemental Table S 17. Completeness and contamination estimates of the Lactobacillus gasseri MV- 22 genome for increasingly basal lineage-specific marker sets. Supplemental Table S 18. Bacterial marker genes identified within the HMP Lactobacillus gasseri genomes. Markers missing from a genome or present in multiple copies are highlighted with a grey background. Supplemental Table S 19. Lineage-specific completeness and contamination estimates for genomes annotated as finished at IMG, along with predicted translation tables and calculated coding density. (see Excel file) Supplemental Table S 20 : Lineage-specific completeness and contamination estimates for single-cell genomes from the GEBA-MDM initiative along with traditional assembly statistics. (see Excel file) Supplemental Table S 21 : Lineage-specific completeness and contamination estimates for population genomes, plasmids, and phage recovered from metagenomic datasets along with traditional assembly statistics. (see Excel file) Supplemental Table S 22 : Completeness and contamination estimates for population genomes recovered from an acetate-amended aquifer determined using domain-level and lineage-specific marker sets. (see Excel file...|$|R
30|$|Samiee et al. [49] Proposed a {{new method}} of feature {{extraction}} in time–frequency domain called MT rational DSTFT which relies on rational function, {{and it is}} adaptive in nature. Their method proposed a sparse representation of the signal while the components remain orthogonal. They investigated that the best window and coefficients size are 256 samples (1.5  s) and first 32 coefficients of the proposed transform. Authors applied stochastic hyperbolic particle swarm optimization (PSO) algorithm to find the optimal position of the pole of each EEG epoch which gives the compact t–f representation of the proposed system. For seizure detection, features used are absolute mean value, absolute median value, <b>absolute</b> <b>standard</b> <b>deviation,</b> <b>absolute</b> maximum value, absolute minimum value of the coefficients. The performance of the proposed method is evaluated on Bonn database and showed that the algorithm has more accuracy (in terms of sensitivity keeping specificity fixed) than other t–f transforms like DSTFT and 13 Cohen’s transforms with {{the same number of}} nonzero coefficients and achieved an accuracy of 99.8 and 99.3 for the combination of E–A and E–B datasets, respectively. They also showed that the inverse rational DSTFT has smaller MSEs as compared to classical inverse DSTFT. But reliability of the algorithm needs to be checked for long EEG data. They investigated various algorithms and found feed-forward MLP as optimal classifier. Their proposed future work is to improve this proposed algorithm by using multidimensional (MD) PSO to determine the optimal number of unique poles so that rational DSTFT can be used in multichannel long-term epileptic seizure detection algorithm.|$|R
40|$|This paper {{presents}} the results of our studies concerning the applications of feedforward artificial neural networks to the propagation path loss prediction in outdoor environment. An error correction model is proposed, based on the combination between a theoretical model and a neural network. The performances of the proposed artificial neural network models are compared to the measured path loss values, based on the <b>absolute</b> mean error, <b>standard</b> <b>deviation</b> and root mean square error. Also, the proposed neural network models are compared {{to each other and to}} the COST 231 -Walfisch-Ikegami. © 2006 IEEE...|$|R
40|$|This paper {{presents}} the results of the General Regression Neural Networks applications for the prediction of propagation path loss in a specific urban environment. We have studied two neural network models; the first one is used for path loss prediction while the second one is a prediction model using error control. The performances of the neural models are compared to the path loss values measured in the city of Kavala, Greece, based on the <b>absolute</b> mean error, <b>standard</b> <b>deviation</b> and root mean square error between predicted and measured values...|$|R
40|$|Abstract- As the {{customers}} in wireless communication becoming crowdy {{and it becomes}} an important to tackle the spectrum scarcity problem. Most of TV licensed spectrum band, users only utilize their chosen resources partially, thus force the need of cognitive radios (CR) which offers the capable feature of accessing the unused spectrum by dynamic spectrum. In this paper, we are presenting the cyclostationary detection method for estimation and spectral autocorrelation function technique to analyze the spectrum. We used cyclostationary feature detection under modulation scheme to detect the primary users at very low SNR and enhancing cyclostationary feature detection with peak detection algorithm for effective performance. To reduce the noise peaks in the cyclostationary output <b>absolute</b> threshold, <b>standard</b> <b>deviation</b> and filtfilt are the techniques used {{to get a better}} efficiency for signal detection. Keywords- Cyclostationary, Correlation Function, autocorrelation functions, cyclic frequency, Spectral Coherence...|$|R
30|$|The {{determination}} of the alcoholic strength in spirits and liqueurs is required to control the labelling of alcoholic beverages. The reference methodology prescribes a distillation step followed by densimetric measurement. The classic distillation using a Vigreux rectifying column and a West condenser is time consuming and error-prone, especially for liqueurs that may have problems with entrainment and charring. For this reason, this methodology suggests {{the use of an}} automated steam distillation device as alternative. The novel instrument comprises an increased steam power, a redesigned geometry of the condenser and a larger cooling coil with controllable flow, compared to previously available devices. Method optimization applying D-optimal and central composite designs showed significant influence of sample volume, distillation time and coolant flow, while other investigated parameters such as steam power, receiver volume, or the use of pipettes or flasks for sample measurement did not significantly influence the results. The method validation was conducted using the following settings: steam power 70  %, sample volume 25  mL transferred using pipettes, receiver volume 50  mL, coolant flow 7 L/min, and distillation time as long as possible just below the calibration mark. For four different liqueurs covering the typical range of these products between 15 and 35  % vol, the method showed an adequate precision, with relative <b>standard</b> <b>deviations</b> below 0.4  % (intraday) and below 0.6  % (interday). The <b>absolute</b> <b>standard</b> <b>deviations</b> were between 0.06  % vol and 0.08  % vol (intraday) and between 0.07  % vol and 0.10  % vol (interday). The improved automatic steam distillation devices offer an excellent alternative for sample cleanup of volatiles from complex matrices. A major advantage are the low costs for consumables per analysis (only distilled water is needed). For alcoholic strength determination, the method has become more rugged than before, and there are only few influences that would lead to incomplete distillation. Our validation parameters have shown that the performance of the method corresponds to the data presented for the reference method and we believe that automated steam distillation, can be used for the purpose of labelling control of alcoholic beverages.|$|R
40|$|To improve human-computer interaction, {{computers}} need {{to recognize}} and respond properly to their users’ emotional state. As a first step to such systems, we investigated how emotional experiences are expressed in various statistical parameters of facial EMG signals. 22 Subjects were presented with 8 emotional film fragments while a TMS Portilab system {{was used to measure}} the activity of frontalis above the left eye (EMG 1), right corrugator supercilii (EMG 2), and left zygomaticus major (EMG 3). Additionally, subjects rated the intensity of both their positive and negative feelings for each film. Based on average positive and negative ratings, films were classified into 4 emotion categories (with 2 films each) : Mixed, Neutral, Positive, and Negative. From each EMG signal, 6 statistical parameters were derived: mean, <b>absolute</b> <b>deviation,</b> <b>standard</b> <b>deviation,</b> variance, skewness and kurtosis. For each of the resulting 18 parameters, a REMANOVA was conducted, with the 4 emotions and 2 films as within-subject factors. The effect of emotion was significant for EMG 2 skewness (F(3, 18) 53. 500, p=. 037), EMG 3 mean (F(3, 18) 59. 711, p<. 001), EMG 3 absolute deviation (F(3, 18) 58. 369, p<. 001), EMG 3 <b>standard</b> <b>deviation</b> (F(3, 18) 55. 837, p=. 006) and EMG 3 variance (F(3, 18) 54. 064, p=. 023). Thus, only few of the EMG parameters reached significance, possibly because mimicking a potential human-computer situation we did not correct our data for baseline values and averaged over a period as long as 120 s. Nevertheless, the EMG 3 signal remains promising in its differentiation among emotion categories...|$|R
