5|15|Public
50|$|Some {{computer}} languages include run-time libraries {{which include}} additional functionality for particular filesystems. The open (or some <b>auxiliary</b> <b>routine)</b> may include specifications for key size, record size, connection speed. Some open routines include specification {{of the program}} code to be executed {{in the event of}} an error.|$|E
40|$|We {{describe}} a new code (SLEUTH) for numerical solution of regular two-point fourthorder Sturm-Liouville eigenvalue problems. Eigenvalues are computed according to index: the user specifies an integer k 0 and the code computes an approximation to the kth eigenvalue. Eigenfunctions {{are also available}} through an <b>auxiliary</b> <b>routine,</b> called after the eigenvalue has been determined. The code will be made available through netlib. ...|$|E
40|$|Abstract: Imagery {{training}} is currently an emerging training method as an <b>auxiliary</b> <b>routine</b> training exercises, it is mainly depends on psychological training {{and is more}} suitable for difficulty & beauty events, such as gymnastics, aerobics, martial arts. Imagery Training is easy to operate and does not require any special requirements, only a relatively quiet environment and body relatively relaxed time. Therefore, this article explore the imagery training in aerobics amateur training effect, provide a theoretical basis for the training...|$|E
40|$|Abstract — Marshaling or {{serialization}} {{of objects}} {{is an important}} component of both distributed and parallel computing. Current systems impose a significant burden on the programmer for describing the marshaling of complex, recursive data structures. Marshalgen provides a semi-automatic process for marshaling in C and C++. Marshalgen avoids the need for complex IDLs and <b>auxiliary</b> <b>routines.</b> It is based on annotations of the existing source code. I...|$|R
40|$|INFORM program {{designed}} to aid assembly language programers of SEL 810 B computers in working with scaled-integer applications. INFORM {{was developed to meet}} needs of engineers designing real-time digital controls using SEL 810 B where time and hardware constraints make use of integer arithmetic and scaled integers necessary. Package includes <b>auxiliary</b> <b>routines</b> that add dynamic data acquisition and high-speed dynamic display to INFORM capabilities...|$|R
40|$|Marshaling or {{serialization}} {{of objects}} {{is an important}} component of both distributed and parallel computing. Current systems impose a significant burden on the programmer for describing the marshaling of complex, recursive data structures. Marshalgen provides a semi-automatic process for marshaling in C and C++. Marshalgen avoids the need for complex IDLs and <b>auxiliary</b> <b>routines.</b> It is based on annotations of the existing source code...|$|R
40|$|We {{describe}} {{double precision}} and complex* 16 Fortran 77 implementations, in LAPACK style, of a block matrix 1 -norm estimator of Higham and Tisseur. This estimator {{differs from that}} underlying the existing LAPACK code, xLACON, in that it iterates with a matrix with t columns, where t ≥ 1 is a parameter, rather than with a vector, and so the basic computational kernel is level 3 BLAS operations. Our experiments with random matrices on a Sun SPARCStation Ultra- 5 show that with t = 2 or 4 the new code offers better estimates than xLACON with a similar execution time. Moreover, with t> 2, estimates exact over 95 % and 75 % of the time are achieved for the real and complex version respectively, with execution time growing much slower than t. We recommend this new code be included as an <b>auxiliary</b> <b>routine</b> in LAPACK to complement the existing LAPACK routine xLACON, upon which the various drivers should still be based for compatibility reasons. ...|$|E
40|$|In {{addition}} to those Library routines which are documented and are intended to be called by users, the Library also contains many auxiliary routines. In general, you need not be concerned with them at all, although you may {{be made aware of}} their existence if, for example, you examine a memory map of an executable program which calls NAG routines. NAG auxiliary routines have names which are similar to the name of the documented routine(s) to which they are related, but with the sixth letter ‘Z’, ‘Y’, and so on, e. g. D 01 AUTP is an <b>auxiliary</b> <b>routine</b> called by D 01 AUFP. The Library also calls a number of de facto standard routines such as the BLACS, PBLAS (see [2]) and BLAS (see for example [1] and the references contained therein). Depending on which version of the Library is used, a few MPI or PVM routines are also called. MPI routines that are called by the MPI-based version of the Library have names that start with MPI, and PVM routines called by the PVM-based version have names that start with PVM or LPVM; to avoid unintentional clashes with MPI or PVM names you should not declare names that start with these characters. Similarly, a number of the BLACS routines start with the characters BLACS. Additional reserved names to avoid, including furthe...|$|E
40|$|We {{consider}} the ecient and accurate computation of Givens rotations. When f and g are positive real numbers, this simply amounts to computing {{the values of}} c = f= p f 2 + g 2, s = g= p f 2 + g 2, and r = p f 2 + g 2. This apparently trivial computation merits closer consideration for the following three reasons. First, while the denitions of c, s and r seem obvious {{in the case of}} two nonnegative arguments f and g, there is enough freedom of choice when one or more of f and g are negative, zero or complex that LAPACK <b>auxiliary</b> <b>routines</b> SLARTG, CLARTG, SLARGV and CLARGV can compute rather dierent values of c, s and r for mathematically identical values of f and g. To eliminate this unnecessary ambiguity, the BLAS Technical Forum chose a single consistent denition of Givens rotations that we will justify here. Second, computing accurate values of c, s and r as eciently as possible and reliably despite over/underow is surprisingly complicated. For complex Givens rota [...] ...|$|R
40|$|MIRKDC is a FORTRAN 77 code {{widely used}} to solve {{boundary}} value problems (BVPs) for ordinary differential equations (ODEs). A significant issue with this package and similar packages {{is that the}} user interfaces are so complicated that potential users {{may be reluctant to}} invest the time needed {{to learn how to use}} them properly. We have applied our experience in writing user interfaces for ODE solvers in Matlab and Fortran 90 / 95 to develop a user-friendly Fortran 90 / 95 BVP solver from MIRKDC. In the course of developing a completely new user interface, we added signif-icantly to the algorithmic capabilities of MIRKDC. In particular, the new solver, BVP SOLVER, extends the class of BVPs solved by MIRKDC to problems with unknown parameters and problems with ODEs having a singular coefficient. It uses more effective Runge-Kutta formulas and con-tinuous extensions. We have also written a number of <b>auxiliary</b> <b>routines</b> to provide further convenience to users of this package. For instance, there are routines for evaluating the solution and its derivative, routines for saving and retrieving solution information, and a routine that facilitates continuation in the length of the interval. ...|$|R
40|$|Detailed {{information}} for performance analysis of parallel {{programs can be}} collected through trace files. Generally, trace files contain a register of individual events that occurred during program execution. Considering that the events traced are commonly of low level, like communication operations in a parallel system, {{and that it is}} increasingly common for the application programmer to use higher level abstractions (e. g., a parallel eigenvalues routine), a semantic gap exists between the collected information and the concepts used {{for the development of the}} application, hindering an effective use of that information. In this work, a new approach to trace files is proposed, where the files retain information about the different hierarchical levels in the application. The files follow an XML format, where routines are XML tags, with <b>auxiliary</b> <b>routines</b> called during its execution as child tags. The approach is demonstrated by its implementation for the MPI library level and the OOPS level, this last one being an objectoriented framework with higher level abstractions for the development of parallel programs that uses MPI for its implementation. To complement the work, some analysis tools using the file format are presented. CNPq 140453 / 2003 -...|$|R
40|$|Certain {{residues}} have {{no known}} function yet are co-conserved across distantly related protein families and diverse organisms, {{suggesting that they}} perform critical roles associated with as-yet-unidentified molecular properties and mechanisms. This {{raises the question of}} how to obtain additional clues regarding these mysterious biochemical phenomena with a view to formulating experimentally testable hypotheses. One approach is to access the implicit biochemical information encoded within the vast amount of genomic sequence data now becoming available. Here, a new Gibbs sampling strategy is formulated and implemented that can partition hundreds of thousands of sequences within a major protein class into multiple, functionally-divergent categories based on those pattern residues that best discriminate between categories. The sampler precisely defines the partition and pattern for each category by explicitly modeling unrelated, non-functional and related-yet-divergent proteins that would otherwise obscure the analysis. To aid biological interpretation, <b>auxiliary</b> <b>routines</b> can characterize pattern residues within available crystal structures and identify those structures most likely to shed light on the roles of pattern residues. This approach can be used to define and annotate automatically subgroup-specific conserved domain profiles based on statistically-rigorous empirical criteria rather than on the subjective and labor-intensive process of manual curation. Incorporating such profiles into domain database search sites (such as the NCBI BLAST site) will provide biologists with previously inaccessible molecular information useful for hypothesis generation and experimental design. Analyses of P-loop GTPases and of AAA+ ATPases illustrate the sampler’s ability to obtain such information. ...|$|R
40|$|In {{this work}} was {{investigated}} the marine topography influence in the Vitória eddy. The Vitória eddy was first described in 1995 (Schmid et al., 1995), during an oceanographic cruise that included Vitória-Trindade chain. Generally it is observed about 100 Km offshore Vitória city with cyclonic vortices characteristics and cold core. The study region is situated 10 &# 730;S to 27 &# 730;S latitude and 30 &# 730;W to 50 &# 730;W longitude, including Caravelas city, in Northeast region until Itajaí in South region of Brazil coast (Southwest Atlantic Bight). A coupled modeling system atmosphere and ocean, that includes MM 5 (Mesoscale Modelling System 5 th Generation), Princeton Ocean Model (POM) and <b>auxiliary</b> <b>routines</b> has been used aiming to simulate the hydrodynamics of that area, using as initial and boundary condition for ocean temperature, salinity and horizontal velocity components, results obtained from Ocean Data Assimilation (ODA) Experiment developed by the Geophysical Fluids Dynamics Laboratory (GFDL) using the Modular Ocean Model (MOM). The Global Forecast System Model (National Centers for Environmental Prediction - NCEP) analysis {{has been used as}} initial and boundary conditions, updated every six hours, in MM 5. In order to investigate the marine topography influence in the Vitória eddy, the bathymetry has been changed, including a barrier between two highs under ocean in Vitória-Trindade chain. Results were obtained both for marine topography changed and not changed. Differences found have shown that are some influence from topography in the ocean circulation, mostly related to eddy formation, in the Vitória Trindade chain. Observations collected near this area were used to compare to model results. Pages: 1315 - 132...|$|R
40|$|We {{present a}} simple and output optimal {{algorithm}} for accelerated isosurface extraction from volumetric data sets. Output optimal extraction algorithms perform an amount of work dominated {{by the size of}} the (output) isosurface rather than the size of the (input) data set. While several optimal methods have been proposed to accelerate isosurface extraction, these algorithms are relatively complicated to implement or require quantized values as input. Our method is based on a straightforward array data structure that only requires an <b>auxiliary</b> sorting <b>routine</b> for construction. The method works equally well for floating point data as it does for quantized data sets. We demonstrate how the data structure can exploit coherence between isosurfaces by performing searches incrementally. We show results for real application data validating the method’s optimality. 1...|$|R
50|$|Following {{the closure}} of the workhouse in 1947, the {{buildings}} passed to the National Health Service, and were re-opened as St Mary's Hospital, specialising in geriatric care. There was also a hospital annexe providing isolation facilities for patients with highly infectious diseases. The hospital was helped by community volunteers who included hospital visitors (who befriended patients), the local St. John Ambulance (who provided qualified <b>auxiliary</b> nurses for <b>routine</b> nursing and bed making duties throughout the 1980s), and a very active League of Friends (who raised money to provide many additional comforts for the residents), active from 1962 until the hospital's closure.|$|R
40|$|Abstract This {{paper is}} about tool support for knowledge-intensive {{engineering}} tasks. In particular, it introduces soft-ware technology {{to assist the}} design of complex technical systems. There is a long tradition in automated design pro-blem solving {{in the field of}} artificial intelligence, where, especially in the early stages, the search paradigm dictated many approaches. Later, in the so-called modern period, a better problem understanding {{led to the development of}} more adequate problem solving techniques. However, search still constitutes an indispensable part in computer-based design problem solving—albeit many human problem solvers get by without (almost). We tried to learn lessons from this observa-tion, and one is presented in this paper. We introduce design problem solving by functional abstraction which follows the motto: construct a poor solution with little search, which then must be repaired. For the domain of fluidic engineering we have operationalized the paradigm by the combination of several high-level techniques. The red thread of this paper is design automation, but the presented technology does also contribute in the following respects: (a) productivity enhan-cement by relieving experts from <b>auxiliary</b> and <b>routine</b> tasks; (b) formulation, exchange, and documentation of knowledge about design; (c) requirements engineering, feasibility ana-lysis, and validation...|$|R
40|$|Karyotype {{analysis}} {{was carried out}} on gill cells of three species of octopods using a conventional air-drying method. The karyotype results showed that all the three species have the same diploid chromosome number, 2 n= 60, but with different karyograms as 2 n= 38 M+ 6 SM+ 8 ST+ 8 T, FN (fundamental number) = 104 (Cistopus chinensis Zheng et al., 2012), 2 n= 42 M+ 6 SM+ 4 ST+ 8 T, FN= 108 (Octopus minor (Sasaki, 1920)) and 2 n= 32 M+ 16 SM+ 12 T, FN= 108 (Amphioctopus fangsiao (d’Orbigny, 1839 – 1841)). These findings were combined with data from earlier studies to infer the genetic relationships between nine species via cluster analysis using the karyotype evolutionary distance (De) and resemblance-near coefficient (λ). The resulting tree revealed {{a clear distinction between}} different families and orders which was substantially consistent with molecular phylogenies. The smallest intraspecific evolutionary distance (De= 0. 2013, 0. 2399) and largest resemblance-near coefficient (λ= 0. 8184, 0. 7871) appeared between O. minor and C. chinensis, and Sepia esculenta Hoyle, 1885 and S. lycidas Gray, 1849, respectively, indicating that these species have the closest relationship. The largest evolutionary gap appeared between species with complicated karyotypes and species with simple karyotypes. Cluster analysis of De and λ provides information to supplement traditional taxonomy and molecular systematics, and it would serve as an important <b>auxiliary</b> for <b>routine</b> phylogenetic study...|$|R
40|$|We {{propose a}} new library of {{routines}} for performing dense linear algebra computations on block-partitioned matrices. The routines {{are referred to}} as the Block Basic Linear Algebra Subprograms, and their use is restricted to computations in which {{one or more of the}} matrices involved consists of a single row or column of blocks, and in which no more than one of the matrices consists of an unrestricted two-dimensional array of blocks. The functionality of the block BLAS routines can also be provided by Level 2 and 3 BLAS routines. However, for Non-Uniform Memory Access machines the use of the block BLAS permit certain optimizations in memory access to be taken advantage of. This is particularly true for distributed memory machines, for which the block BLAS {{are referred to as}} the Parallel Block Basic Linear Algebra Subprograms (PB-BLAS). The PB-BLAS are the main focus of this paper, and for a block-cyclic data distribution, a single row or column of blocks lies in a single row or column of the processor template. The PB-BLAS consist of calls to the sequential BLAS for local computations, and calls to the BLACS for communication. The PB-BLAS are the building blocks for implementing ScaLAPACK, the distributed-memory version of LAPACK, and provide the same ease-of-use and portability for ScaLAPACK that the BLAS provide for LAPACK. The PB-BLAS consists of all nine Level 3 BLAS routines, four of the Level- 2 BLAS <b>routines,</b> and 2 <b>auxiliary</b> transpose <b>routines.</b> The PB-BLAS are currently available for all numeric data types, i. e., single and double precision real and complex...|$|R
40|$|The {{identification}} of mycobacteria is essential because tuberculosis (TB) and mycobacteriosis are clinically indistinguishable and require different therapeutic regimens. The traditional phenotypic method is time consuming and may {{last up to}} 60 days. Indeed, rapid, affordable, specific and easy-to-perform identification methods are needed. We have previously described a polymerase chain reaction-based method called a mycobacteria mobility shift assay (MMSA) that was designed for Mycobacterium tuberculosis complex (MTC) and nontuberculous mycobacteria (NTM) species identification. The {{aim of this study}} was to assess the MMSA for the {{identification of}} MTC and NTM clinical isolates and to compare its performance with that of the PRA-hsp 65 method. A total of 204 clinical isolates (102 NTM and 102 MTC) were identified by the MMSA and PRA-hsp 65. For isolates for which these methods gave discordant results, definitive species identification was obtained by sequencing fragments of the 16 S rRNA and hsp 65 genes. Both methods correctly identified all MTC isolates. Among the NTM isolates, the MMSA alone assigned 94 (92. 2 %) to a complex or species, whereas the PRA-hsp 65 method assigned 100 % to a species. A 91. 5 % agreement was observed for the 94 NTM isolates identified by both methods. The MMSA provided correct identification for 96. 8 % of the NTM isolates compared with 94. 7 % for PRA-hsp 65. The MMSA is a suitable <b>auxiliary</b> method for <b>routine</b> use for the rapid identification of mycobacteri...|$|R
40|$|Context: After {{fundamental}} ground-based, balloon-born, {{and space}} experiments, and, in particular, after the COBE/FIRAS results, confirming that only very small deviations from a Planckian shape can {{be present in}} the CMB spectrum, current and future CMB absolute temperature experiments aim at discovering very small distortions such as those associated with the cosmological reionization process or that could be generated by different kinds of earlier processes. Aims: Interpretation of future data calls for a continuous improvement in the theoretical modeling of CMB spectrum. In this work we describe the fundamental approach and, in particular, the update to recent NAG versions of a numerical code, KYPRIX, specifically written to solve the Kompaneets equation in a cosmological context. It was first implemented in the years 1989 - 1991 to accurately compute the CMB spectral distortions under general assumptions. Methods: Specifically, we describe the structure and the main subdivisions of the code and discuss the most relevant aspects of its technical implementation. After a presentation of the equation formalism and of the boundary conditions added to the set of ordinary differential equations derived from the original parabolic partial differential equation, we provide details on the adopted space variable (i. e. dimensionless frequency) and space discretization, on time variables, on the output results, on the accuracy parameters, and on the used <b>auxiliary</b> integration <b>routines.</b> The problem with introducing the time dependence of the ratio between electron and photon temperatures and of the radiative Compton scattering term, both of them introducing integral terms into the Kompaneets equation, is addressed in the specific context of the recent NAG versions. We describe the introduction of the cosmological constant in the terms controlling the general expansion of the Universe in agreement with the current concordance model, of the relevant chemical abundances, and on the ionization history, from recombination to cosmological reionization. The global computational time, the impact of the various aspects of the code on it, and the accuracy of the numerical integration are also discussed. Results: We present some of fundamental tests we carried out to verify the accuracy, reliability, and performance of the code. We focus on some quantitative tests of energy conservation and the time behavior of electron temperature. A comparison of the results obtained with the update and the original version of the code is presented for some representative cases. Finally, we focus on some properties of the free-free distortions relevant for the long wavelength region of the CMB spectrum. Conclusions: All the tests demonstrate the reliability and versatility of the new code version and its accuracy and applicability to the scientific analysis of current CMB spectrum data and of much more precise measurements that will be available in the future. The recipes and tests described in this work can also be useful for implementing accurate numerical codes for other scientific purposes using the same or similar numerical libraries or for verifying the validity of different codes aimed at the same problem or similar ones...|$|R

