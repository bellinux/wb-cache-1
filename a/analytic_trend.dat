1|31|Public
50|$|An <b>analytic</b> <b>trend</b> can be {{observed}} in Dalmatian: nouns and adjectives began to lose their gender and number inflexions, the noun declension disappeared completely, and the verb conjugations began to follow the same path, but the verb maintained a person and number distinction except in the third person (in common with Romanian and several dialects of Italy).|$|E
5000|$|Compliance Intelligence (CI) {{is also a}} {{methodology}} by which organizations create a holistic view of their measurement against a set of harmonized compliance requirements. Through the application of <b>analytics,</b> <b>trending</b> across the applicable compliance requirements can be identified and used to prioritize high-risk areas of non-compliance. CI is used by complex organizations to: ...|$|R
5000|$|Meta-analysis (building {{an organic}} {{taxonomy}} of the content, and providing <b>analytics</b> on <b>trends)</b> ...|$|R
5000|$|In 1959, {{a double}} issue of The Journal of Philosophy {{was devoted to}} Buchler's work. Since {{original}} publication, however, Buchler's work has been considered to be outside the dominant <b>analytic</b> <b>trends</b> in philosophy. In Creativity in American Philosophy (1984), Charles Hartshorne comments on Buchler's central concept of natural complexes: [...] "I think almost {{the entire history of}} philosophy is against such an idea. Only considerable courage could have made it seem worth while to challenge this tradition." ...|$|R
5000|$|Monitoring latest <b>trends,</b> <b>analytic</b> design, giving {{direction}} to the company’s design politic ...|$|R
5000|$|Access to {{specialized}} {{data and}} capabilities, such as syndicated marketing data and associated <b>trend</b> <b>analytics</b> ...|$|R
50|$|K. Slavakis, S. J. Kim, G. Mateos, and G. B. Giannakis, Modeling and Optimization for Big Data <b>Analytics,</b> Foundations and <b>Trends</b> in Signal Processing, 2017.|$|R
50|$|On May 10, 2012, Clearspring {{changed its}} name to AddThis, its most widely used product. The company {{launched}} three sharing and <b>analytics</b> tools: <b>Trending</b> Content Box, Follow Tools, and Welcome Bar, as well as supporting content sharing for Pinterest and Web Intents. In August, the company began offering social login. In September, CFO Richard Harris took over as CEO.|$|R
40|$|Abstract — Fueled by {{advances}} in microelectronics, wireless communications {{and the availability}} of affordable mobile connectivity, the last decade has seen an unprecedented proliferation in the number of interconnected devices. This evolution is part of the transition to the Internet of Things (IoT), which envisions connecting anything at any time and place. While it can be argued we are already living in the IoT era, the next paradigm shift is already emerging on the horizon, targeting yet another order of magnitude {{increase in the number of}} interconnected devices and promising to bring people and processes in the equation. This is particularly important towards the vision of Smart Cities, where physical infrastructure is complemented by the availability of intellectual and social capital, increasing both urban competitiveness and quality of life. However, before such a paradigm shift can be realized, significant challenges with respect to scalability, cooperative communications, energy consumption, as well as convergence of sensor and <b>analytics</b> <b>trends</b> have to be resolved. In this paper we elaborate on the different trends, as well as the remaining open problems and we show how Sensor Virtualization Technology, capturing both the Virtual Sensors and Virtual Sensors Networks aspects, promises to alleviate or resolve these challenges, and pave the way towards the evolution of the Internet of Things...|$|R
40|$|Analyzing and {{aggregating}} large-scale broadband measurements {{is essential}} to study trends and derive network <b>analytics.</b> These <b>trends</b> and analyses could be made available through well defined protocols such as the Application Layer Traffic Optimization (ALTO) protocol. However, ALTO requires network information to be distilled and abstracted in form of a network map and a cost map. We describe our methodology for analyzing the United States Federal Communication Commission’s (FCC) Measuring Broadband America (MBA) dataset to derive required topology and cost maps suitable for consumption by an ALTO server...|$|R
40|$|Following {{the current}} <b>analytics</b> <b>trend</b> in the NBA, {{the focus of}} this project is the {{implementation}} of a system capable of analyzing NBA games and out-putting relevant statistics on all the unique lineups that occurred throughout the games for any number of teams. The system, coded in Python and using the Beautiful Soup library, scrapes ESPN. com data and generates data structures containing all of a game's events (including substitutions) and the times at which those events occurred. From this data, the system is able to build out the lineups playing at any given time in a game and track the cumulative statistics for those lineups. For this analysis, we analyze another NBA trend: "small ball. " We create two scores to classify lineups: position score, which takes into account the biggest two players on the court, and sb score, which combines position score and the shooting tendencies of the lineup. Applying these classifications to the system's outputted data shows that there is no correlation between sb score and the effectiveness or efficiency of lineups. However, further statistical analysis indicates that lineups classified as small ball are significantly better on offense as compared to traditional lineups. We hope to further develop the underlying system in order to analyze different datasets and generate output that will allow for further novel analysis...|$|R
30|$|The <b>analytic</b> tool, Google <b>trends</b> (www. Googletrends.com) {{describes}} {{the intensity of}} search query terms among total searches. It reveals that the search intensity of the term “big data” grew 10 times from Sept 2011 to March 2015. Meanwhile, total searches had grown by a compound rate of 10 % a year (see www.internetlivestats.com; accessed on March 19 2015).|$|R
40|$|This {{article focuses}} on the {{development}} of argumentation studies in France and their complex relations with discourse analysis. First, the meanings of the basic word 'argument' in French and in American English are discussed and contrasted. Second, a brief historical section summarizes the complex history of rhetorical argumentation in France up until the late 1980 s and the Perelmanian revival. Third, Grize 'natural logic' and Anscombre and Ducrot 'argumentation within language' are briefly discussed from the discourse analysis point of view. These programmes have restored argumentation study to favour in France, where it is currently the research paradigm most referred to in recent work. The fourth section examines the present situation in France which is characterized by a strong new interest in argumentation in all disciplines; this is fuelling a tendency towards the use of argumentation theories - classical or modern - for practical, short-term analysis purposes. Fifth, a proposal is made for a better integration of argumentation studies in discourse analysis, based on the conception of argumentation as opposite points of view, either in face-to-face disputes or in written arguments, sometimes lasting for several centuries. This article is {{based on the premise that}} research into the history of rhetoric and argumentation, as well as in specific discourse <b>analytic</b> <b>trends</b> that emerged in France during the 1970 s, has some permanent value in that a better understanding of an academic discipline's historical development can be a good introduction to its current problems...|$|R
40|$|Abstract — Apache hadoop {{is a major}} {{innovation}} in the IT market place last decade. From humble beginnings Apache Hadoop has become a world-wide adoption in data centers. It brings parallel processing in hands of average programmer. As more data centers supports hadoop platform, it becomes imperative to migrate existing data mining algorithms onto hadoop platform for increased parallel processing efficiency. With the introduction of big data <b>analytics,</b> this <b>trend</b> of migration of the existing data mining algorithms to hadoop platform has become rampant. In this survey paper, we explore the current migration activities and challenges in migration. This paper will guide the readers to propose solutions for the current challenges in the migration. I...|$|R
50|$|Crucial in {{effective}} CPV implementation {{is an appropriate}} data collection procedure. Data must allow for statistical <b>analytics</b> and <b>trend</b> analysis of process consistency and capability. A correctly implemented procedure will minimize overreactions to individual production outlier events and guarantee genuine process inconsistency are detected. While production variability can sometimes be obvious and even casually identified the FDA recommends using statistical tools to quantitatively detect problems and identify root causes. Initially, continued process verification {{should be based on}} quality standards established in the design phase. After a period of time variations can be detected by identifying deviation from historical data using statistical tools. Furthermore, these same tools {{can also be used to}} identify opportunities to optimize processes that may pre-emptively increase quality reliability.|$|R
40|$|E-learning is {{becoming}} increasingly important for the competitive advantage of economic organizations and higher education institutions. Therefore, it {{is becoming}} a significant aspect of quality which has to {{be integrated into the}} management system of every organization or institution. The paper examines e-learning quality characteristics, standards, criteria and indicators and presents a multi-criteria hybrid model for e-learning quality evaluation based on the method of <b>Analytic</b> Hierarchy Process, <b>trend</b> analysis, and data comparison...|$|R
40|$|Cloud {{computing}} has revolutionized healthcare in today’s {{world as}} it can be seamlessly integrated into a mobile application and sensor devices. The sensory data is then transferred from these devices to the public and private clouds. In this paper, a hybrid and distributed environment is built which is capable of collecting data from the mobile phone application and store it in the cloud. We developed an activity recognition application and transfer the data to the cloud for further processing. Big data technology Hadoop MapReduce is employed to analyze the data and create user timeline of user’s activities. These activities are visualized to find useful health <b>analytics</b> and <b>trends.</b> In this paper a big data solution is proposed to analyze the sensory data and give insights into user behavior and lifestyle trends...|$|R
40|$|Real-time geoparsing {{of social}} media streams (e. g. Twitter, YouTube, Instagram, Flickr, FourSquare) is {{providing}} a new 'virtual sensor' capability to end users such as emergency response agencies (e. g. Tsunami early warning centres, Civil protection authorities) and news agencies (e. g. Deutsche Welle, BBC News). Challenges {{in this area}} include scaling up natural language processing (NLP) and information retrieval (IR) approaches to handle real-time traffic volumes, reducing false positives, creating real-time infographic displays useful for effective decision support and providing support for trust and credibility analysis using geosemantics. I will present in this seminar on-going work by the IT Innovation Centre over the last 4 years (TRIDEC and REVEAL FP 7 projects) in building such systems, and highlights our research towards improving trustworthy and credible of crisis map displays and real-time <b>analytics</b> for <b>trending</b> topics and influential social networks during major news worthy events...|$|R
50|$|TREND is a {{database}} developped at the Canada Research Chair in International Political Economy in Laval University that lists more than 300 environmental provisions in nearly 700 international (bilateral and multilateral) free trade agreements. Several scientific publications published in periodicals {{such as the}} British Journal of Politics and International Relations are derived from the data collected in this database. Created {{in collaboration with the}} German Development Institute (DIE) in Bonn, Germany, an interactive website (<b>TREND</b> <b>Analytics)</b> listing the results of the TREND database has recently been released to provide quality information to researchers in political science, international law, and public decision-makers.|$|R
50|$|Wingard also {{garnered}} {{national media}} attention {{as a student}} athlete when he played for Stanford's football team. Since then, he has attracted significant coverage from outlets including USA Today, Black Enterprise, and the NY Daily News for his consulting work with professional sports organizations and players. His engagements and activities have included research and <b>analytics</b> on <b>trends</b> and performance {{in collaboration with the}} Wharton Sports Business Initiative, as well as the design and delivery of advisory services and training programs related to preparing professional athletes for life after their playing careers—most notably the development of the NFL Business Management and Entrepreneurship Program with colleague Kenneth Shropshire and former player and NFL Executive Vice President of Football Operations Troy Vincent for football players. As Dean of the Columbia University School of Professional Studies, he also oversees, and teaches students in, one of the world's top ranked Sports Management graduate degree programs and is often solicited for commentary and insights related to strategy, leadership, and best practices in the sports industry.|$|R
5000|$|The book {{argues that}} the old sources of {{competitive}} advantage -technology, labor, and capital - are fading and that new sources are emerging. Prahalad and Krishnan suggest an internal capacity to reconfigure resources in real time by focusing on clearly documented, transparent, and resilient business processes (the link between strategy, business models and operations) has become a strong differentiator. They also argue that a focus on co-creation, by developing an R=G supply network and emphasizing <b>analytics</b> which identify <b>trends</b> and unique opportunities can create a strong competitive advantage. The technical architecture required to develop these flexible and resilient business processes and strong analytics capabilities is outlined in the book.|$|R
5000|$|The {{field of}} {{visualization}} has undergone considerable changes {{since its founding}} in the late 1980s. From its origins in scientific visualization, new areas have arisen in the new Millennium [...] These include information visualization and, more recently, mobile visualization including location-aware computing, and visual <b>analytics.</b> Several new <b>trends</b> are emerging. The most important is the fusion of visualization techniques with other areas such as computer vision, data mining and data bases to promote broad-based advances. Another trend, which has not been well met to date by visualization researchers, is for algorithms to be combined with usability studies to assure that techniques and systems are well designed and that their value is quantified. This presentation will discuss current research trends in visualization as well as briefly discuss trends in U.S. research funding.|$|R
40|$|Autism Spectrum Disorder (ASD) is a {{pervasive}} developmental disorder characterized by difficulties in communication and social integration. Many research studies {{provide evidence that}} early and intensive intervention (preschool age 4 - 6 hours/day) leads to great progress in skills, {{and in some cases}} brings the child to a developmental level equal to his/her peers. Since traditional educational methods are rarely effective in ASD, new teaching approaches aimed at better exploiting the subject’s abilities are currently adopted. Among these, early intervention based on Applied Behavior Analysis (ABA) offers children with autism the possibility of learning in an accessible structured way, adapting pace, format and feedback to the subject’s abilities. Considering technology-enhanced learning, several studies have shown the effectiveness of computer-assisted programs for special education of autistic children due to the intrinsic ‘distance’ between the PC and the child that does not require emotional involvement (a computer does not require interpretation of emotion) allowing the repeatability of answers (reducing anxiety). Although there is a great availability of educational software programs, few of them apply ABA principles. Most of them are commercial products having additional costs for families. Moreover, there are still no formal protocols for testing the learning software for autistic subjects and further studies are necessary in the field of human-computer interaction when the interaction is performed by an individual with autism. In this thesis, I describe the design and implementation of a set of software tools that comprise ABCD SW (Autistic Behavior & Computer-based Didactic SoftWare), an ABA compliant application, designed to support children and tutors in a 1 -to- 1 learning process. ABCD SW is an open-source adaptive software based on Augmentative and Alternative Communication (AAC) and Discrete Trial Training (DTT), specifically developed for an early intervention (2 - 6 years old). The software allows children to perform ABA trials, automatically storing all data of the sessions. The tutor must integrate the evaluation data (prompt provided, behavior) by pressing just one key. A learning analytic tool extracts data, offering real-time monitoring of children’s learning for assessing at a glance progress or problems experienced by each child. The effectiveness of ABA intervention supported by ABCD SW has been tested via a pilot study with seven autistic children. The efficacy was evaluated through two data sources: 1) subjective feedback collected through an online survey proposed to the ABA team of the children involved in the user test; 2) an objective assessment based on learning <b>analytics</b> <b>trends</b> highlighted by the ABCD software correlated with the children’s evaluations. These evaluations were made by a psychologist before and after the user test, through Vineland adaptive behavior scales for measuring personal and social skills. Results show that children manifested improvement in communication, especially in the expressive communication sub-category (p < 0. 05). Furthermore, the ABA team observed that children improved in communication, socialization and behavior. The pilot study suggests effectiveness of rehabilitation of autistic children using this ABA technology-enhanced intervention...|$|R
40|$|AbstractManagerial {{decisions}} {{are based on}} accurate information and in today's time raw data is produced even with a stroke of a key. Regardless of the data creating process one needs {{to know how the}} information was extracted and which pool of data was used. One important factor is time therefore we need to structure it in layers of data history {{in such a way that}} it can be analyzed, (post) process, in order to be able to retrieve valuable information. The simplest way is to use a Database Management System (DBMS), but even with such a management system we face the issue of making it a self-contained database on each version of data added. Our proposed system, a continuation of previous work, aims toward creating a database versioning system which keeps the natural dependency between data on each internal revision, a basis of security and alteration control mechanism, <b>trend</b> <b>analytics,</b> without sacrificing(within acceptable levels) speed, flexibility and the cost of implementation be kept as minimal as possible...|$|R
40|$|In {{recent years}} a sea-change in both {{theoretical}} and {{technical aspects of}} psychoanalysis has emerged at the interface between conventional psychoanalytic concepts and other disciplines that were traditionally held at arm’s length by the <b>analytic</b> community. These <b>trends</b> have primarily occurred in the United States {{under the rubric of}} so-called relational theory, an amalgam of disparate and even contradictory perspectives including hermeneutics, constructivism, deconstructionism, intersubjectivity, and postmodernism. Largely a creature of the American psychoanalytic community, virtually all of these theories filtered into American culture from Europeans, including the French psychoanalyst Jacques Lacan, who identified the linguistic element of psychoanalysis with structuralism, and French philosophers such as Jacques Derrida (deconstructivism), Jean Francois Lyotard (postmodernism), and Michel Foucault (poststructuralism). American analysts who are identified with the relational perspective have tended to eschew the more theoretical preoccupations of the French school and focus instead on a relaxation of classical psychoanalytic technique (e. g., neutrality and abstinence) emphasizing the so-called real and personal aspects of the analyst-patient relationship...|$|R
40|$|The {{increasing}} {{application of}} social and human-enabled systems in people's daily life from one side and {{from the other side}} the fast growth of mobile and smart phones technologies have resulted in generating tremendous amount of data, also referred to as big data, and a need for analyzing these data, i. e., big data <b>analytics.</b> Recently a <b>trend</b> has emerged to incorporate human computing power into big data analytics to solve some shortcomings of existing big data analytics such as dealing with semi or unstructured data. Including crowd into big data analytics creates some new challenges such as security, privacy and availability issues. In this paper study hybrid human-machine big data analytics and propose a framework to study these systems from crowd involvement point of view. We identify some open issues in the area and propose a set of research directions for the future of big data analytics area. Comment: 19 pages, 1 figure. CSE UNSW Technical repor...|$|R
30|$|In the following, the M&A {{profile of}} the {{acquirer}} is outlined. This profile is targeted to show the extent of a company’s activity in sourcing companies; the size, industry and country of origin of target companies; the character of acquisitions. Most strategic investments are normally made in companies from related industry sectors [19]. An acquisition from another sector (“non-related acquisition”) might indicate the wish of the acquirer to enter a new market or extend its existing capabilities through new applications of technologies. It might also mean that the target technology is undergoing a growth stage where a successful diffusion is possible. We applied a qualitative media content analysis to assess information from mergermarket, 1 an online analytic tool aggregating data about reported mergers and acquisitions. The business intelligence tool has been developed by economic journalists in cooperation with M&A advisors and experts to provide analytics on M&A deals and corporate strategy – in general based on global media content analysis, historical data and <b>trend</b> <b>analytics</b> by industrial segments. For {{the purposes of this}} research mergermarket has been used to illustrate the acquisition dynamics, reveal deal patterns and identify emerging paths in sourcing technologies by the focal companies.|$|R
40|$|As {{the first}} autonomous, public-funded {{university}} in Singapore, SMU has been constantly reinventing both its pedagogy and curriculum {{to keep up}} with the times and to remain relevant in a knowledge-based economy. The University is aiming to become an Asian knowledge hub for business and management; one of the areas in which SMU is making global impact and has projected thought leadership is its work on Big Data <b>Analytics</b> on social <b>trends.</b> This is an area where much multi-disciplinary research has been carried out by SMU’s School of Information Systems, involving the University’s five other schools of accountancy, business, economics, law and social sciences. Big Data Analytics is the process of analysing and examining large volumes of data of a variety of types to uncover hidden patterns, unknown correlations and other useful information. The findings from such analysis can help organisations better understand their consumers and markets, or help companies make better decisions and possibly gain competitive advantages. In this podcast, Professor Steven Miller, who is SMU’s Vice Provost for Research and Dean of the School of Information Systems, shares his insights on the Analytics Area of Excellence across SMU...|$|R
40|$|Purpose – In recent years, the {{academic}} world has seen the spread of a growing interest in understanding the dynamics characterizing studies conducted in different research areas (Golinelli et al. 2015; Gummesson et al., 2011; Barile and Polese, 2010; Lusch et al, 2008). This trend {{seems to have taken}} hold also in the scientific community interested in issues related to Service Science Management Engineering and Design (Spohrer et al., 2017, Maglio et al., 2015; Polese and Di Nauta, 2013). In this regard, the present study aims to investigate whether the multidisciplinary nature of SSMED, theoretically recognized, implies an effective orientation of academics towards manifold research areas. Design/Methodology/approach – The work is based on an automatic literature review, conducted by using knowledge extraction techniques integrated in an IT tool developed for the objective pursued with this research. The tool has been applied on several databases (such as Wiley, etc.), enabling the analysis of different studies about SSMED and the extraction of the main trend characterizing the evolution of this science known as multidisciplinary along the time line. Findings – The results emerging from the analysis show that, despite SSMED has progressively developed as a multidisciplinary science, actually, most of the studies related to it focuses on topics linked mainly to business management. However, the consideration of the time variable allows understanding that, within SSMED, especially in recent years, the number of contributions linkable to topics belonging to other research areas is progressively growing up (Polese et al., 2016; Russo Spena et al., 2013; Barile and Saviano, 2010). Research limitations/implications – The research involves considerable theoretical implications, fostering an important advancement in the state of art in terms of more concrete and greater awareness of the multidisciplinary nature of SSMED. However, the study presents the limit of considering not all available databases. In fact, the involvement of additional databases, perhaps, would have been capable of leading to potentially different findings. Originality/value – The work proposes a novel approach to carry out conceptual <b>analytics</b> summarizing <b>trends</b> along the timeline. It allows going far beyond the traditional techniques used in science mapping through the evaluation of scientific publications indexed or stored in big databases (such as systematic literature review, bibliometrics, and research performance analysis), enabling the assessment of the (chrono) logical evolution of the studies dedicated to SSMED. Moreover, unlike what occurs with other techniques (e. g. systematic literature review, bibliometrics, and research performance analysis), the development and the subsequent use of a specific IT tool for the analysis guarantees the advantage to automatically consider, extract and analyze in real time all contributions available on the selected databases...|$|R
30|$|Social {{networks}} are graphs created {{by members of}} social media. These graphs are made from social media members and the relationships between them in forms of nodes and edges respectively. A friendship on the Facebook {{is an example of}} a two-sided (undirected) connection and following somebody’s page Instagram or tweeter {{is an example of a}} one-sided (directed) connection and a connections in DBLP (Digital Bibliography & Library Project) network is an example of a weighed edge. In social networks, connections between people reveal a lot of information about the graph and communities existing in the graph. A community is a group of people with mutual interest. As same as real life in every social-media, there exist various communities. This communities are made from members of social media and their pages. Example of communities could be friendship groups or groups of people with same occupations or simply groups of people with same interests. In social graphs, relationship inside the community and relationships outside are respectively shown by internal edges and external edges. Number of internal-edges are dense within a community where number of external edges are low. In contrast between two separate communities there is no internal edge but a small number of external edges are existed. Among all the communities that exist in social media, there is a need to distinguish those who are active and more important in the graph. Figuring out the active communities can help with advertisings tasks, statistics and analyses needed for suggestions, searches and <b>trend</b> <b>analytics.</b> In addition, finding the ranking list of communities shows how important each community is. Communities with higher ranks have a better communication inside and outside the community. Local computations are good for big graphs. Community detection methods are divided into two subgroups. The first well known method is to cluster vertexes based on their similarity. And the second method is graph partitioning base on sparse cut.|$|R
30|$|Quasi-markets {{assure the}} {{universality}} {{and quality of}} service while featuring the advantages of a conventional market. When the profit model {{is based on the}} quasi-market principle, the externalities experienced by third parties also become internal gains that can sustain the metro enterprise’s inputs. To a great extent, the profit model formulation for metro enterprises is based on the comprehensive analysis of the attributes of metro enterprises within unique environments as well as profound studies on the utilization and integration of resources. The environment of Shenzhen Metro is considerably lenient to the authorization of land use and cohesive cooperation between various industries; whereas the scope of authority of other metro enterprises in the global community is less due to the present contractual arrangements of most public–private partnerships. Although the majority of metro enterprises are in deficit at present, this research carried out an empirical analysis on the real operation status and profit composition of Shenzhen Metro Co. Ltd. in 2014, and confirmed the feasibility and relativity of the profit model with the case study put forward by this paper, which provides an applicable reference and experience for metro enterprises around the world. This paper presents the process in forming a profit model which includes the analysis of metro attributes under a unique environment. The case study demonstrates the advantages of quasi-marketing in the optimization of resources while ensuring accessible provisions of metro service. Studies around the world have elaborated on the importance of technological innovations and thorough planning in shaping smart transportation. Scientists, governments and enterprises are united by the attempts to solve the various setbacks faced by the transport sector through new and universal endeavors. Although few studies explicitly model profit in metro, the current initiatives accentuate the need to generate present benefits in order to support future enhancements. This paper fills the gap by presenting the fundamental coherent steps for enterprises to form a unique metro profit model by the means of a comprehensive integration of socioeconomic scheme. The utilization of a quasi-market-based profit model aims to promote a resolution to fellow deficit challenges faced by the global metro community. Through the wide <b>analytic</b> spectrum of <b>trends</b> in the metro industry and initiatives from the case study, a new era of positive growth and sustainable development is initiated in the metro enterprises.|$|R
40|$|Today {{it is more}} {{difficult}} than ever to isolate the reproduction of buildings and landscapes from a growing and ever more all-embracing “economy of images and signs” (Lash and Urry, 1994). Even though repeated attempts are being made from within the spatial professions to develop a tectonically or geo-morphologically formulated immunity to these changes, the built environment appears as a subject matter in an increasing number of fields, from <b>trend</b> <b>analytics</b> and economic forecasting to environmental science and health care. One of these new and increasingly important fields of architectonical practice is film production. As a “micro-environment with global span” (Sassen 2003), this spatio-temporal domain has developed its own platforms and tools for commissioning and curating architectural environments, thus providing a new and increasingly important cartography of contemporary space (Abbas, 2003). Here, the emerging film commissions play an active role, engaging not only in promotion of the architectural environment, but furthermore also in its categorization, assessment and reproduction. What we have to ask, however, is what are the premises for this new spatial production, and how does it affect the further intermediation of architectural knowledge? Through a case study of the Oresund Film Commission and its web based “location database”, this paper aims to discuss these and related issues. A compilation of more than five hundred still images of potential locations for film production, covering anything from “fairytale scenery and medieval villages tucked in lush fields” to “contemporary European settings” (www. oresundfilm. com), the database provokingly actualizes the ambiguities of architectural typologization and archival practices – on the one hand its dependency upon an often unarticulated aesthetic narrative or naturalized voice-over {{and on the other hand}} its inclination to blend with a global branding culture. Together with a number of similar location databases, it is, however, also an example of the changing representational and reproductive conditions characterizing a mediatized architectural arena, rendering to the place-specific and local a new and extended role as enunciative entrances in a geo-political play. The paper interrogates and examines this new cinematographically driven locality production as well as the expectations, both for adaptation and change, to which it gives rise. The argument developed is that neither urban design nor architectural curatorship can consider themselves independent of processes of mediatization. Nevertheless, it is not a curatorial assignment to uncritically provide an increasingly powerful media industry with a legitimizing voice-over. Instead, what is needed is rather a new attention to the urban narrative that goes beyond passive commentary, taking into account the discursive potentials that an expanded architectural media-geography eventually holds...|$|R

