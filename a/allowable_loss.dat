15|59|Public
2500|$|... {{the company}} does not {{currently}} have an accounting period and has a chargeable gain or <b>allowable</b> <b>loss.</b> Chargeable gains and allowable losses are taxable gains and tax relievable losses that arise on the disposal of certain capital assets, for example on the disposal of the company's head office.|$|E
5000|$|This is {{an appeal}} by W. T. Ramsay Ltd., a farming company. In its {{accounting}} period ending May 31, 1973, {{it made a}} [...] "chargeable gain" [...] {{for the purposes of}} corporation tax by a sale-leaseback transaction. This gain it desired to counteract, so as to avoid the tax, by establishing an <b>allowable</b> <b>loss.</b> The method chosen was to purchase from a company specialising in such matters a ready-made scheme. The general nature of this was to create out of a neutral situation two assets one of which would decrease in value {{for the benefit of the}} other. The decreasing asset would be sold, so as to create the desired loss; the increasing asset would be sold, yielding a gain that it was hoped would be exempt from tax.|$|E
40|$|Abstract—In this paper, {{we propose}} a new {{framework}} {{for the design of}} sparse finite impulse response (FIR) equalizers. We start by formulating greedy and convex-optimization-based solutions for sparse FIR linear equalizer tap vectors given a maximum <b>allowable</b> <b>loss</b> in the decision-point signal-to-noise ratio. Then, we extend our formulation to decision feedback equalizers and multiple-antenna systems. This is followed by further generalization to the channel shortening setup which is important for communication systems operating over broadband channels with long channel impulse responses. We propose a novel approach to design a sparse target impulse response. Finally, as an application of current practical interest, we consider self far-end crosstalk cancellation on vectored very high-speed digital subscriber line systems for cellular backhaul networks. Index Terms—Sparse FIR filter, MIMO equalizer, DFE, channel shortening, crosstalk...|$|E
50|$|Chargeable gains (or <b>allowable</b> <b>losses)</b> are {{calculated}} as gross proceeds, less direct selling costs, less base cost, less indexation allowance. Indexation allowance is base cost {{multiplied by the}} change in the Retail Prices Index movement between the month of purchase and month of sale. Indexation allowance cannot create or increase a loss. Losses may only be set off against chargeable gains of the same or a future accounting period (except certain <b>allowable</b> <b>losses</b> of life assurance companies (see: I minus E basis).|$|R
3000|$|... {{in which}} the integer n {{is the number of}} <b>allowable</b> hello <b>loss.</b> n = 1 means that all hello packets can be {{received}} correctly, remarked as LAH- 1 otherwise it has hello loss. If n = 2, the scheme is described as LAH- 2.|$|R
40|$|Photoresist {{stripping}} in IC manufacturing {{has become more}} challenging. The number of photoresist levels has increased while the <b>allowable</b> material <b>loss</b> and <b>allowable</b> surface damage has decreased. Heavily implanted photoresist is especially challenging due to the dehydrogenated, amorphous carbon layer that forms on th...|$|R
40|$|Figure 3 Maximum {{value of}} the image {{impedance}} {{as a function of}} the odd-mode characteristic impedance for srt s 2. 6. Figure 4 Insertion loss IL of the coupler {{as a function of the}} normalized strip-line thickness w xwave moment method calculations 4. The agreement be-tween the results is remarkably good. Figure 4 can be used to guide the coupler design. After. the selection of the frequency, substrate material e, andr determination of the maximum <b>allowable</b> <b>loss,</b> the appropri-ate maximum substrate thickness is found from Figure 4. The aperture width is calculated using the fact that srt s 2. 6. Since the IL is almost independent of Z, the designer haso the freedom to choose its value, thereby also ®xing Z. Thisi step can be guided by Figure 3...|$|E
40|$|The aim of {{the thesis}} "Soil {{protection}} against water erosion in the cadastral Jinačovice" is to evaluate the problems of soil erosion and erosion prevention. The work consists of two parts. In the first part the issue of erosion is expressed using relevant printed and electronic sources. The second part deals with the analysis of current conditions and {{the current status of}} land use in terms of susceptibility to water erosion. All the erosion factors will be assessed based on the findings. The average long-term loss of land will be evaluated using the universal equation for calculating the USLE soil loss and the degree of erosion hazard to lands will be determined. As a result an erosion control measure (organizational, argi-technical and technical) will be designed and their effectiveness with regard to <b>allowable</b> <b>loss</b> will be assessed...|$|E
40|$|We {{investigate}} {{a method for}} supporting diverse quality-of-service requirements in broadband networks based on ATM technology. The method uses deterministic bandwidth reservation at the Virtual Path (VP) level and statistical multiplexing within each VP. A deterministic server such as a Weighted Round Robin (WRR) server is used to enforce bandwidth reservations among the VPs. We develop a connection admission algorithm which accounts for end-to-end delay and loss guarantees for Virtual Circuits which traverse a single VP. We show that under certain conditions the amount of network bandwidth required by a VP is minimized by incurring all the <b>allowable</b> <b>loss</b> at the first link of a VP. Achievable utilization is demonstrated using simulation. The effect of {{the parameters of the}} WRR server (i. e., the vacation time) on the cell loss probability is also studied using simulation. Keyword Codes: C. 2. 1, C. 2. 2, C. 4 Keywords: Network Architecture and Design, Network Protocols, Performance of Systems [...] ...|$|E
40|$|Applications have {{to chose}} between the slow TCP and the {{unreliable}} UDP. There {{is now an}} alternative: the Variable Reliability Protocol. The applications can specify what are the <b>allowable</b> <b>losses</b> in the data, and the protocols guarantees that the given loss tolerance parameters will be respected. It should result in a faster throughput over WAN which have typically a higher loss rate. VRP was proposed by Robin Kravets from the GaTech. In this paper we describe how it has been improved, implemented, and integrated to Nexus, the communication library of the meta-computing environment Globus. Contents 1 Introduction 5 1. 1 Globus and Nexus.......................... 5 1. 2 Variable reliability.......................... 6 1. 2. 1 Aim of variable reliability.................. 6 1. 2. 2 Loss tolerance......................... 6 2 The Variable Reliability Protocol 7 2. 1 General principle..... [...] ...|$|R
50|$|On 17 June, it was {{announced}} that former Manchester United chief executive David Gill had been appointed chairman of UEFA’s influential Club Licensing Committee (CLC), the body which decides which clubs are entitled to licenses to play in Europe, (on 25 June the committee banned leading Turkish sides Fenerbahçe and Beşiktaş, who had been due to play Champions League and Europa League football for involvement in match fixing) and which will be responsible for recommending sanctions against any clubs who fail to comply with FFP. Although the CLC has no involvement in assessing club accounts, the appointment was queried by some because Gill, a strong advocate of FFP was due to remain a Manchester United director, leading to concerns about a lack of impartiality in the event of any English clubs exceeding the £38 million <b>allowable</b> <b>losses</b> {{at the end of the}} first accounting period.|$|R
3000|$|Based on {{the above}} path loss model {{and using a}} maximum <b>allowable</b> path <b>loss</b> of 140 dB, the {{estimated}} wireless range for the extra-container communication frequencies are ±[*] 3 km. Because this distance is obtained after extrapolating path loss data collected up to 63 m, it only serves as an indication for the communication range. In the following, we assume that [...]...|$|R
40|$|Abstract—Fast Fourier {{transform}} (FFT) is the demodulation kernel in the DVB-H system. In this paper, we firstly propose an FFT processor {{that reduces}} the power consumption by decreasing the usage of main memory, and timely turning off the unused memory partitions in different sizes of the FFT. Second, the triple-mode conflict-free address generator is proposed to handle the address mapping of all storages in the three-size FFT computations. Then two cost-efficient twiddlefactor coefficient design methods, “Sharing ” and “Interpolation-then-Sharing”, are proposed to reduce the area of coefficient storages within the <b>allowable</b> <b>loss</b> of SQNR. These methods can reduce 67 % area occupied by coefficient storage at a price of 0. 6 dB loss of SQNR in our design. Finally, our proposed FFT processor for DVB-H system is implemented by using TSMC 0. 18 μm 1 P 6 M CMOS technology with core size of 1. 886 × 1. 886 mm 2. The minimum latency to operate 8192 -poin...|$|E
40|$|Abstract: Total Artificial Hearts (TAHs) are {{required}} for the therapy of terminal heart diseases as heart transplants are only a limited option due to the available number of donor hearts. For implantation TAHs have to meet constraints regarding its dimensions, weight, perfusions and electrical losses. An innovative linear driven TAH is presented, which meets all constraints except weight. Therefore the geometry of the linear drive is optimised to reduce its weights while simultaneously limiting the electrical losses as much as possible. In order to calculate the losses, this paper introduced a combined calculation chain consisting of FEM simulations and analytical equations. Based on this chain the linear drive is optmised by the method of parameter variations. The results yield a hierachic order of parameters which are most suitable for the weight reduction of the drive for low losses. By this {{the weight of the}} linear drive is reduced by 25 %. As the <b>allowable</b> <b>loss</b> limit is not exceeded yet, room for further weight reduction achieved by an optimisation of the axial geomtry parameters is given...|$|E
40|$|The {{problem of}} {{scheduling}} multiple streams of realtime customers is {{addressed in this}} paper. The paper first introduces the notion of (m; k) -firm deadlines to better characterize the timing constraints of real-time streams. More specifically, a stream {{is said to have}} (m; k) -firm deadlines if at least m out of any k consecutive customers must meet their deadlines. Note that, the notion of (m; k) -firm deadlines is a generalization of firm and soft deadlines. In particular, m = k = 1 characterizes a stream with firm deadlines. A large value for k with (k Γ m) =k equal to the maximum <b>allowable</b> <b>loss</b> rate can be used to represent a stream with soft deadlines. A stream with (m; k) -firm deadlines will experience a dynamic failure if fewer than m out of any k consecutive customers meet their deadlines. The paper proposes a policy for scheduling N such streams on a single server to reduce the probability of dynamic failure. The basic idea of the proposed policy is to assign higher prioritie [...] ...|$|E
30|$|To {{estimate}} the cell size {{covered by a}} base station, a link budget has to be determined. The link budget takes all the gains and the losses that occur during the propagation through the medium from the transmitter to the receiver into account. The link budget is needed to calculate the maximum <b>allowable</b> path <b>loss</b> PLmax (in dB) to which a transmitted signal can be subjected while still being detectable by a receiver. Once the maximum <b>allowable</b> path <b>loss</b> PLmax is known, the maximum cell size (in meters) covered by a base station can be determined via a path loss model (PLM). A PLM takes into account PLmax, the shadowing margin, the frequency, {{the height of the}} base station and the height of the mobile base station. Further, we apply a Doppler margin of 3 dB [9] in order to take speeds up to 150 km/h into account. Here, the Erceg B path loss model [33] is assumed to determine PLmax and the cell size.|$|R
30|$|To {{determine}} {{the range of}} a base station, first the maximum <b>allowable</b> path <b>loss</b> to which a transmitted signal can be subjected while still being detectable at the receiver, is calculated [22]. Therefore, a link budget has to be set up. A link budget takes all the gains and the losses from the transmitter through the medium to the receiver into account. When the maximum <b>allowable</b> path <b>loss</b> is known, the range can be determined by using a propagation model. Different propagation models exist and the propagation model used depends on the design parameters (e.g. indoor vs. outdoor, macrocell vs. femtocell base station, urban vs. suburban vs. rural area, etc.). In this study, we focus on macrocell and femtocell base stations. For the macrocell base station we used the Erceg C model [24], while for the femtocell base station the ITU-R P. 1238 model is used [25]. For both the macrocell and the femtocell we assume a frequency of 2.6 GHz as defined in the LTE standard. We assume the macrocell to transmit at 43 dBm, whereas femtocells transmit at 21 dBm.|$|R
40|$|SUMMARYThis article {{proposes a}} simple, mathematically-derived formula {{which could be}} used for calculating <b>allowable</b> blood <b>loss.</b> Authors have used lineal {{approaches}} in many models found in the medical literature; this introduces an important inaccuracy into such prediction. An exponential approach is deduced and explained in the model proposed here which is considered to be much closer to reality than that obtained with the lineal model. More emphasis is placed on the fact that while a patient is losing blood, he/she is simultaneously receiving fluids to keep total blood volume almost constant...|$|R
40|$|The {{title of}} my thesis is "The use and {{protection}} of a territory by means of land adjustments". I focused on the cadastral area of Kněžpole near Uherské Hradiště which is situated close to my domicile. The {{first part of the}} thesis comprises of a literary research and it tackles the issue of land resources and land adjustments in general. It also describes the historical development of land resources, their composition and protection. The second part consists of an analysis of the aforesaid area, focusing on the particular natural characteristics, the current status and the evaluation of the particular factors influencing erosion and drainage. Water erosion is handled according to the handbook "Anti-erosion protection of land" published in 2005 and according to the methodology described in "Protection of agricultural land against erosion", published in 2012. Having discovered that the <b>allowable</b> <b>loss</b> of soil has been exceeded, we have suggested several anti-erosion measures to protect the most endangered land blocks. Furthermore, the effectiveness of the suggested measures has been assessed. The final part of the thesis offers an evaluation {{of the impact of the}} suggested measures on areas used in agriculture...|$|E
40|$|Taxpayers filed 120. 4 million U. S. individualincome {{tax returns}} for Tax Year 1996, 1. 8 {{percent more than}} for the {{previous}} year. For 1996, adjusted gross income (less deficit) (AGI) increased 8. 3 percent to $ 4. 5 trillion. Total income tax rose 11. 9 percent to $ 658. 2 billion, and the average tax rate increased 0. 5 percentage points to 14. 5 percent. For 1996, tax represented 6. 0 {{percent of gross domestic}} product (GDP), in contrast to the 6. 6 percent shown for 1981. Net capital gain (less <b>allowable</b> <b>loss)</b> increased 47. 8 percent to $ 251. 8 billion, the largest percentage increase since the Tax Reform Act of 1986 (TRA 86). Itemized deductions for charitable contributions increased 14. 9 percent to $ 86. 2 billion. In constant dollars, charitable contri-butions showed the largest percentage increase since 1956. Two of the largest components of AGI, salaries and wages and taxable pensions and annuities, in-creased 5. 5 percent and 8. 0 percent, respectively. Other components of AGI with sizable increases were taxable Individual Retirement Arrangement distributions (22. 0 percent) and partnership and S Corporation net income (less loss) (16. 7 percent). The total deduction for personal exemptions in-creased 2. 5 percent to $ 598. 9 billion, and total de-ductions (itemized and standard) increased 4. 1 per-cent to $ 979. 6 billion. Taxable income increased 9. 8 percent to $ 3. 1 trillion. Total tax credits (including only the portion of the earned income credit used to offset income tax before credits) increased 12. 6 percent to $ 11. 3 billion, while the total earned in-come credit increased 11. 1 percent to $ 28. 8 billion...|$|E
40|$|Open {{distribution}} line access and economic uncertainties {{are the reasons}} why many utilities are operating their lines at much higher loads than they were initially designed for. Because of this, the effects of higher operating temperatures on the safety and reliability of overheads lines were studied in this dissertation. It is observed that overloading of conductor usually occur during peak hours in according to the average daily load pattern of Sri Lanka. During this time conductor temperature reaches to its maximum. However, conductor temperature may not increase due to the cooling effect on availability of wind. The over temperature causes reduction of the tensile strength of the conductor. The work has been identified in significant areas where improved analytical methods are relevant. Several such methods have been created and their impact is discussed in this report. As such, present conductor ratings are studied in accordance to IEC standard [7] and IEEE standard [5, 6]. Wind data at four different sites have been collected and are used for the analysis. Current variations of three different sites are taken for the study. The probability of over temperature could be determined by applying Rayleigh distribution and cumulative frequency distribution respectively when the wind speed is below 1 mls and the current rating is more than 202 A. At the second stage, sag at maximum temperature has been calculated for each span. Finally,. Economical optimizations of losses are analyzed. In the first part, <b>allowable</b> <b>loss</b> of strength of Aluminium is analyzed through a probabilistic approach. Accordingly, {{it is observed that}} strength of Aluminium is not ever reduced below 90 % of its original strength during the conductor lifetime of 50 years. This reduction of strength is negligible. Therefore, effective wind speed can be taken as 1 m/s. In the second part, sag variations were analyzed for each span which is presently used in CEB against maximum allowable temperature (90 °C) in the absence of wind speed. It is observed that ground clearance is not violated when it is operated at maximum allowable temperature (90 °C). Finally, under this method costs and benefits are evaluated with increase of losses against investment incurred in strengthening of the, CEB network. Net present value is analyzed considering present value of expenses (increase of losses of existing system) and present value of savings (investment incurred in strengthening of the CEB network). Net present value is positive for load patterns of Omara, Ratmalwala and Kudagammana. Therefore those projects are financially viable...|$|E
40|$|Abstract – Infrared {{wireless}} communication possesses two main attractive advantages over its radio frequency counterpart, namely {{the abundance of}} unregulated spectrum in 1. 3 µm– 1. 55 µm region and {{the ease with which}} the infrared radiation can be confined. Integrating microwave electronics and optics, it is possible to provide wideband communication services but {{it is well known that}} the signal level in an optical wireless receiver is weakest at the front end. This paper presented <b>allowable</b> signal <b>losses</b> and optical received power prediction based on different visibilities for optical {{wireless communication}} links over wide range of the affecting parameters...|$|R
40|$|AbstractExplosive waste widely {{exists in}} people's lives, and burnout is an {{effective}} technology for its disposal. A new destruction furnace is presented according to the characteristics of explosive waste burnout, which could control the destruction of it. The analysis for design requirement indicates the furnace body and insulating layer are the critical components. The thickness of furnace body which decides the endurance for blast shock wave can be calculated though the dynamic coefficient method. Based on the maximum <b>allowable</b> radiation <b>loss</b> model, the thickness of insulation material is optimized. The design meets technical requirements and makes burning work more secure...|$|R
40|$|In {{a voltage}} source {{converter}} (VSC) based HVDC system, the modulation scheme used {{is an important}} factor in achieving a desired harmonic performance with <b>allowable</b> semiconductor <b>losses.</b> In this paper, the use of selective Harmonic Elimination Pulse Width Modulation (HEPWM) for a three-level Neutral Point Clamped (NPC) converter in VSC based HVDC application will be discussed. Steady state performance of the converter system in terms of harmonics and losses will be evaluated using MATLAB and PSCAD/EMTDC simulation. Simulation results show a 37 % improvement in total semiconductor loss with better harmonic performance by using the three-level solution compared to the two-level solution with the stated modulation scheme...|$|R
40|$|This report {{presents}} a {{step by step}} guide {{on how to use}} the Ecological Impact Assessment (EIA) tools for fluvial flooding (EIA F tool) and coastal inundation (EIA C tool). These tools have been developed within the Ecological Consequences of Flooding (ECF) project and may be used to support an environmental risk assessment (Old et al., 2010). When developing plans to manage flood risk, economic, social and environmental impacts are considered. There are many tools that help to estimate the economic impacts. However, there is currently no standard approach for evaluating the impacts on the natural environment within a flood risk assessment. Impacts of floods on the natural environment are often complex and include benefits and disbenefits. The Broad Scale Ecosystem Assessment (BSEA) toolkit is based on GIS data sets (existing or producible) that already exist or can be easily created and that have an apparent relationship with ecological characteristics. It is largely left to experts to interpret the ecological implications of these data. The GIS based tools presented here build on this work by introducing more scientific knowledge and objectivity to the assessment of ecological impact. The prototype tools will be used to provide an initial assessment of environmental assets at risk of fluvial flooding and coastal inundation. In this way it will help the authorities responsible for Flood and Coastal Risk Management to fulfil their duties under the EU Floods Directive, Habitats Directive, Bird’s Directive and Water Framework Directive. In the future it is envisioned that the tools will be embedded within software and made available to general users through an application like the Modelling Decision Support Framework that is currently in use by the Environment Agency. This will support Environmental Impact Assessments and Strategic Environmental Assessments for flood risk management activities. The prototype tools guide the user in making an objective and quantitative (where appropriate) assessment of the impacts of floods on the environment using ARC GIS 9. 3 with its standard toolbox supplemented with Spatial Analyst. Although GIS based, they are spreadsheet tools that assesses the environmental impact of a given hydrological scenario by comparing this to the sensitivities of mapped environmental assets. The tools would support anyone undertaking an ecological flood risk assessment. They represent a tiered approach (comparable to the BSEA) to environmental impact assessment which is necessary to ensure that an appropriate level of analysis is adopted which is justified by the importance of the decision. Step by step guidance in using the tools is presented and supplemented with screenshots of the required GIS tasks. The environmental assessment is made using spreadsheet based scorecards. Ecological sensitivities to flooding/inundation are captured on the scorecards. The user must define the current flooding/relative sea level rise scenario and undertake a series of defined spatial data queries before assessing the impacts of flooding. The user must specify the impact assessment criteria as these are likely to change with time and with the specific objectives of a given assessment (e. g. what is an <b>allowable</b> <b>loss</b> of bird habitat?). The impacts of flooding are then evaluated by comparing the sensitivities of flooding to the flood characteristics. Given that the prototype tools use many spatial datasets of varying resolution, accuracy, age and completeness several areas of uncertainty must be acknowledged in any assessment and a decision must be made as to which need quantifying in a given study. The prototype tools have been tested in two fluvial and two coastal regions (see Technical Report). Test of both tools were successful and demonstrated the applicability of the tools. A degree of verification was presented by expert assessment {{of the results of the}} pilot tests. The limitations of both tools are considered and these mostly relate to knowledge on the sensitivities of environmental assets to flooding/inundation and the availability of data. The relevance of both tools to strategy and legislation is also considered. The method is currently ‘high level’, suitable for strategic planning but possibly not detailed enough for specific local decisions associated with flood risk management schemes and watercourse maintenance. Recommendations are made in the project Technical Report for moving towards a more detailed level of assessment. ...|$|E
40|$|This report {{presents}} the scientific basis {{and development of}} the Ecological Impact Assessment (EIA) tools for fluvial flooding (EIA F tool) and coastal inundation (EIA C tool). These tools have been developed within the Ecological Consequences of Flooding (ECF) project and may be used to support an environmental risk assessment. When developing plans to manage flood risk, economic, social and environmental impacts are considered. There are many tools that help to estimate the economic impacts. However, there is currently no standard approach for evaluating the impacts on the natural environment within a flood risk assessment. Impacts of floods on the natural environment are often complex and include benefits and disbenefits. The Broad Scale Ecosystem Assessment (BSEA) toolkit is based on GIS data sets (existing or producible) that already exist or can be easily created and that have an apparent relationship with ecological characteristics. It is largely left to experts to interpret the ecological implications of these data. The project reported here builds on this work by introducing more scientific knowledge and objectivity to the assessment of ecological impact by developing prototype GIS based tools that will support decision making. The prototype tools developed here will be used to provide an initial assessment of ecological assets at risk of fluvial flooding and coastal inundation. In this way it will help all Flood and Coastal Risk Management (FCRM) authorites fulfil their duties under the EU Floods Directive, Habitats Directive, Bird’s Directive and Water Framework Directive. In the future it is envisioned that the tool will be embedded within software and made available to general users through an application like the Modelling Decision Support Framework that is used by the Environment Agency in the preparation of Catchment Flood Management Plans. The tools will thus support Environmental Impact Assessments and Strategic Environmental Assessments for flood risk management activities. The scoping study that underpins this project (Ramsbottom et al., 2005) concluded that although gaps exist in scientific understanding of ecological impacts and data coverage and resolution, it was feasible to integrate the available information within a Geographical Information System (GIS), and to produce prototype tools. Aim and Objectives The overall aim of the project is to develop, test and disseminate prototype methods for assessing and mapping the ecological risk, including harmful and beneficial effects, resulting from flooding. The aim was achieved through the following objectives. •	Reviewing literature and consulting experts to identify current requirements, tools and knowledge •	Defining the scope of the tool and ecologically significant hydrological indices •	Deciding on the resolution of impact assessment •	Specifying the methodology •	Defining ecological sensitivities to flooding o	Using scientific literature, empirical assessment and expert opinion •	Preparing scorecards as frameworks for impact assessment •	Producing guidance for the prototype tools •	Pilot testing o	Calibrating, verifying and assessing applicability of the proposed methods •	Disseminating findings – including a scientific paper and good practice guidance. The prototype tools and their application The prototype tools described in this report guide the user in making an objective and quantitative (where appropriate) assessment of the ecological impact of floods on the environment using ARC GIS 9. 3 with its standard toolbox supplemented with Spatial Analyst. Although GIS based, they are spreadsheet tools that assesses the ecological impact of a given hydrological scenario by comparing this to the sensitivities of mapped ecological assets. The tools would support anyone undertaking an ecological flood risk assessment. They represent a tiered approach (comparable to the BSEA) to ecological impact assessment which is necessary to ensure that an appropriate level of analysis is adopted which is justified by the importance of the decision. Step by step guidance in using the tools is available (Guidance Report). The ecological assessment is made using spreadsheet based scorecards. The ecological sensitivities defined above for impact assessment are captured on the scorecards. The user must define the current flooding/relative sea level rise scenario and undertake a series of defined spatial data queries before assessing the impacts of flooding. The user must specify the impact assessment criteria as these are likely to change with time and with the specific objectives of a given assessment (e. g. what is an <b>allowable</b> <b>loss</b> of bird habitat?). The impacts of flooding are then evaluated by comparing the sensitivities of flooding to the flood characteristics. Given that the prototype tools use many spatial datasets of varying resolution, accuracy, age and completeness several areas of uncertainty are identified and discussed. These must be acknowledged in any assessment and a decision must be made as to which need quantifying in a given study. The prototype tools have been tested in two fluvial and two coastal regions. Test of both tools were successful and demonstrated the applicability of the tools. A degree of verification was presented by expert assessment {{of the results of the}} pilot tests. Relevance to strategy and legislation The ECF method supports activities throughout the tiered approach to fluvial flood risk management planning. In particular, it supports catchment flood management planning, shoreline management planning, strategy planning and PFRAs (required under the Flood Risk Regulations 2009). The tools could also support the assessment of outcome measures, spatial planning and appraisal. They provide a framework for assessment although the level of detail would change from the high level CFMP/SMP to the more detailed Strategy Plan. The application of the tools at the more detailed scheme level requires further consideration and would need to include site specific information. The way the ECF tools link to existing tools and methods is considered as this is key to its successful integration to flood risk management. Conclusions and recommendations The prototype tools successfully integrate current scientific knowledge, expert opinion and available data in a framework that allows a more objective assessment of the ecological impacts of flooding. This was demonstrated through pilot testing. Our ability to assess the impacts of flooding on ecology would be greatly enhanced by the following: •	Developing NAFRA data to include more ecologically relevant data (frequent floods, seasonality and duration) •	Increasing coverage of up to date high resolution habitat mapping (e. g. National Vegetation Classification data) •	Increasing scientific understanding of the sensitivities of environmental assets to flooding/inundation. The relevance of the methods to current strategy and legislation has been demonstrated by considering specific activities within flood risk management. ...|$|E
30|$|Because of the {{proximity}} of the human body, antennas cannot be separated from the wireless propagation loss. Therefore, using the method of [28], one can calculate the maximum <b>allowable</b> path <b>loss</b> for sensor modules operating in the MICS band. With the maximum permitted level of − 16 dBm EIRP (equivalent isotropically radiated power) or 25 μ W and a sensitivity level of − 90 dBm for 152 kbps and − 99 dBm for 51 kbps [29], a nominal maximum path loss (PLmax) of 74 dB for 152 kbps and 83 dB for 51 kbps is obtained, respectively. When comparing these maximum <b>allowable</b> path <b>losses</b> with the path loss models obtained in Figure 10, one can conclude that up to 400 -mm separation wireless communication for the heterogeneous phantoms (adult and child) is possible for both data rates for the considered configurations (for the adult configuration higher separations can be difficult). However, for misalignment in the esophagus tissue, separations up to about 293 mm are possible for 152 kbps. The provided models of Table 2 can be used for further link budget calculations accounting for misalignment and rotation of the endoscopy capsule. To specifically account for the rotation, one can add a margin of 4 dB (x-axis) or 10 dB (y-axis) in the link budget. Also the application of the model with misaligned antennas is a possibility. A rotation of the capsule can result in a variation of the path loss up to 14 dB (10 and 4 dB margins).|$|R
40|$|Severe {{limits are}} put on <b>allowable</b> beam <b>loss</b> during {{extraction}} and transport of a 2. 3 MW primary proton beam for the Long Baseline Neutrino Experiment (LBNE) at Fermilab. Detailed simulations with the STRUCT and MARS codes have evaluated the impact of beam loss of 1. 6 x 10 {sup 14 } protons per pulse at 120 GeV, ranging from a single pulse full loss to sustained small fractional loss. It is shown that loss of a single beam pulse at 2. 3 MW {{will result in a}} catastrophic event: beam pipe destruction, damaged magnets and very high levels of residual radiation inside and outside the tunnel. Acceptable beam loss limits have been determined and robust solutions developed to enable efficient proton beam operation under these constraints...|$|R
40|$|Paediatric {{patients}} undergoing {{surgical procedures}} commonly require some volume of blood or blood component replacement in the perioperative period. Paediatric patients undergoing major surgery associated with substantial blood loss {{should be evaluated}} pre-operatively. Pre-operative correction of anaemia may be done considering the age, plasma volume status, clinical status and comorbidities. Maximum <b>allowable</b> blood <b>loss</b> (MABL) for surgery must be calculated, and appropriate quantity of blood and blood components should be arranged. Intraoperative monitoring of blood loss should be done, and volume of transfusion should be calculated in a protocol based manner considering the volemia and the trigger threshold for transfusion for {{the patient and the}} MABL. Early haemostasis should be achieved by judicious administration of red blood cells, blood components and pharmacological agents...|$|R
40|$|Tritium {{recovery}} and containment {{are some of}} the key issues associated with breeding blanket design. The tritium inventory has to be kept low for safety considerations. Also, the tritium loss rate has to be kept below design limit. The severity of the issues associated with the tritium inventory and tritium containment depends on the blanket design, the breeding material to be used, the blanket temperature, and the structural material to be used for the power conversion system. ITER defines that the maximum allowable tritium inventory in an individual system to be less than 200 g. Also, the <b>allowable</b> tritium <b>loss</b> rate has been assumed to be less than 10 Ci/FPD. Although these limits have been debated within the fusion community, they are the most commonly accepted limits...|$|R
40|$|In next {{generation}} wireless networks, the most tempting {{feature is the}} ability of the user to move smoothly over different access networks regardless of the network access technology. In this paper we study the benefit of Multiple Attribute Decision Making (MADM) strategies for network selection. We compare three of these methods naming Simple Additive Weighting (SAW), Multiplicative Exponential Weighting (MEW) and Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS) in a realtime ns- 3 simulation. Analytic Hierarchy Process (AHP) provides the weights of attributes which allow the comparison in different types of applications. Therefore, we propose a performance evaluation model with a reconfiguration of AHP parameters used in the literature. Simulation results show that the proposed parameters provide an improvement of Delay and offer <b>allowable</b> Packet <b>loss</b> in different types of applications...|$|R
40|$|The {{influence}} of orthotropic wall materials, which have enhanced thermal conductivity in the axial direction, on the flame speed is explored via an analytical model {{in a parallel}} plate microcombustor. The model accounts for 2 D conjugate heat transfer (both in wall and gas) and fuel species transport in the micro-channel. The effects of heat loss, orthotropic wall thermal conductivities, and wall thickness on the flame speed are explored. The results indicate that as the axial thermal conductivity of the wall is increased, the <b>allowable</b> heat <b>losses</b> to the ambient by the burner also increased. Thicker walls showed increased benefit to the thermal conductivity tailoring than thinner wall designs; both in increased flame speeds {{as well as the}} ability to tolerate higher heat losses without extinction. Total heat recirculation is shown to be the primary parameter to control the flame speed...|$|R
40|$|The 120 GeV primary proton beamline for the NuMI-MINOS [1] {{experiment}} at Fermilab will transport one of {{the most}} intense high-energy beams ever constructed. in parallel operation with the Collider program, 80 % of the intensity capability of the Fermilab Main Injector can be sent to NuMI. Radiation safety pertaining to residual activity, damage of equipment and irradiation of groundwater is a primary concern. A particular challenge is that this beam will be transported to and targeted in a cavern excavated in rock in an aquifer region. A model of the beamline, including transport elements and excavated enclosures, has been built in the radiation simulation program MARS. This model has been used to determine limits for <b>allowable</b> beam <b>loss,</b> and to study effects of instabilities and of various failure types. Some results obtained with this model are presented...|$|R
40|$|Applications {{often have}} to chose between the slow TCP and the {{unreliable}} UDP. Robin Kravets from the GaTech has proposed an alternative: the Variable Reliability Protocol (VRP). The applications can specify what the <b>allowable</b> data <b>losses</b> are, and the protocol guarantees that the given loss tolerance parameters are respected. It should result in a faster throughput over WAN which have typically a higher loss rate. In this paper we describe how VRP has been improved, implemented, and integrated into Nexus, the communication library of the metacomputing environment Globus. Keywords: TCP, UDP, loss tolerance, network protocol, Globus, Nexus, WAN, Internet Rsum Les applications doivent jusqu' prsent choisir entre TCP, fiable mais lent, et UDP, rapide mais non-fiable. Robin Kravets du GaTech a propos une alternative : le protocole fiabilit variable (Variable Reliability Protocol [...] VRP). Les applications peuvent spcifier quelles sont les pertes tolrables dans les donnes, et [...] ...|$|R
40|$|The {{trajectory}} {{feedback of}} the Compact Linear Collider (CLIC) {{is an essential}} mitigation method for ground motion effects at CLIC. In this paper signicant improvements of the design of this feedback are presented. The new controller {{is based on a}} singular value decomposition (SVD) of the orbit response matrix to decouple the in- and outputs of the accelerator. For each decoupled channel one independent controller is designed by utilising ground motion and noise models. This new design allows a relaxation of the required resolution of the beam position monitor from 10 to 50 nm. At the same time the suppression of ground motion effects is improved. As a consequence, the tight tolerances for the <b>allowable</b> luminosity <b>loss</b> due to ground motion effects in CLIC can be met. The presented methods can be easily adapted to other accelerators in order to loosen sensor tolerances and to efciently suppress ground motion effects...|$|R
40|$|A deep-space optical {{communications}} {{channel is}} subject to fading losses due to pointing and tracking errors. Barron and Boroson [1] illustrated that these losses may be mitigated by introducing an interleaver that spreads a pointing-induced fade over many codewords of an error-correction code. Several approximations to determine the interleaver gain, which can be computationally prohibitive, are introduced in [1]. However, the methods are accurate only {{for a range of}} code rates and interleaver depths. We extend these methods, using a nonlinear fit to capacity, to allow the analysis of any code rate and fading depth. We also develop an efficient and accurate approximation of the finite-interleaving losses by an inversion of the Marcum Q-function, and provide expressions relating the interleaver memory to the finite-interleaver losses. The resulting expressions provide an accurate tool for a system engineer to size the interleaver memory {{as a function of the}} data rate and the <b>allowable</b> pointing <b>loss.</b> I...|$|R
