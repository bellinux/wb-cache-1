0|218|Public
5000|$|Temporal lobe signs usually involve <b>auditory</b> <b>sensation</b> and memory, and may include: ...|$|R
50|$|The {{neuronal}} encoding {{of sound}} is {{the representation of}} <b>auditory</b> <b>sensation</b> and perception in the nervous system.|$|R
50|$|Studies of {{the central}} nervous system {{processing}} of <b>auditory</b> <b>sensation,</b> aspects of which has been linked to prenatal androgen exposure, to click-stimuli have shown that homosexual women have masculinized responses while homosexual men have hyper-masculinized responses.|$|R
5000|$|Hypnagogic {{hallucinations}} are vivid, often frightening, dreamlike {{experiences that}} occur while dozing or falling asleep. Hypnopompic hallucinations {{refer to the}} same sensations while awakening from sleep. These hallucinations may manifest {{in the form of}} visual or <b>auditory</b> <b>sensations.</b>|$|R
50|$|Pulsed {{microwave}} radiation {{can be heard}} by some workers; the irradiated personnel perceive <b>auditory</b> <b>sensations</b> of clicking or buzzing. The cause {{is thought to be}} thermoelastic expansion of portions of the auditory apparatus. Competing theories explain the results of interferometric holography tests differently.|$|R
5000|$|Sound {{is defined}} as [...] "(a) Oscillation in pressure, stress, {{particle}} displacement, particle velocity, etc., propagated in a medium with internal forces (e.g., elastic or viscous), or the superposition of such propagated oscillation. (b) <b>Auditory</b> <b>sensation</b> evoked by the oscillation described in (a)." ...|$|R
50|$|The upper {{frequency}} limit in humans (approximately 20 kHz) {{is due to}} limitations of the middle ear. <b>Auditory</b> <b>sensation</b> can occur if high‐intensity ultrasound is fed directly into the human skull and reaches the cochlea through bone conduction, without passing through the middle ear.|$|R
40|$|With {{the aim of}} augmenting <b>auditory</b> <b>sensation</b> by tactile stimuli, we {{investigated}} cross-modal relationships between the two modalities, focusing on frequency. The results showed that frequency consonance between tactile and audio stimuli depends {{on the relationship between}} harmonics, {{in a manner similar to}} auditory waves, but with broader peaks...|$|R
50|$|Damage to the {{temporal}} lobe can affect an individual in {{a litany of}} ways ranging from: disturbance of <b>auditory</b> <b>sensation</b> and perception, disturbance of selective attention of auditory and visual input, disorders of visual perception, impaired organization and categorization of verbal material, disturbance of language comprehension, and altered personality.|$|R
40|$|The review {{analyzes}} the experiments on perceptual isolation with special {{reference to the}} phenomena of reported visual and <b>auditory</b> <b>sensations.</b> Variables analyzed include: methods of confinement and restriction, conditions of illumination, duration of isolation, set, instructions and suggestions, reporting or verbalization instructions, sleep, subject populations, prior knowledge and expectations, intelligence and personality characteristics of Ss, stress response, and methods of obtaining reported visual and <b>auditory</b> <b>sensations.</b> The relevance {{of some of the}} findings to physiological, psychoanalytic, cognitive, and social psychological theories of perceptual isolation are discussed. Variables which seem important in the phenomena discussed are set, verbalization instructions, S's alertness, and E's methods of obtaining responses. The unexpected reports of hallucinations in the first perceptual-isolation report (Heron, Bexton, & Hebb, 19 S 3) fascinated clinicians, theoreticians, and experimentalists, and stimulated widespread interest in other responses to isolation. From the reports at symposi...|$|R
40|$|The rate {{of decay}} of <b>auditory</b> <b>sensation</b> was {{investigated}} by measuring the minimum silent interval that must be introduced between two noise pulses to be perceived. The value of this critical time Δt was determined for difierent intensity levels of both {{the first and the}} second pulse. It is shown that in this case the sensation level of the second pulse may be considered as a very good approximation of the level of <b>auditory</b> <b>sensation</b> after Δt, due to the first pulse. From the experiments, we may conclude (1) expressed in dB as a function of log t, the decay of sensation is represented by a straight line; (2) independent of the sensation level of the stimulating sound, the hearing threshold is reached at the same time of about 200 - 300 msec. These results are compared with other experiments and the differences are discussed...|$|R
25|$|In {{theory of}} hearing physiology, the {{traveling}} wave (TW) of Von Bekesy, resulted from an acoustic surface {{wave of the}} basilar membrane into the cochlear duct. His theory pretended to explain every feature of the <b>auditory</b> <b>sensation</b> owing to these passive mechanical phenomena. Jozef Zwislocki, and later David Kemp, showed that that is unrealistic and that active feedback is necessary.|$|R
5000|$|Loudness is the {{characteristic}} of a sound that is primarily a psycho-physiological correlate of amplitude. More formally, it is defined as, [...] "That attribute of <b>auditory</b> <b>sensation</b> in terms of which sounds can be ordered on a scale extending from quiet to loud." [...] The relation of physical attributes of sound to perceived loudness consists of physical, physiological and psychological components.|$|R
5000|$|The Acoustical Society of America (ASA) Acoustical Terminology {{definition}} 12.09 of timbre {{describes it}} as [...] "that attribute of <b>auditory</b> <b>sensation</b> which enables a listener to judge that two nonidentical sounds, similarly presented and having the same loudness and pitch, are dissimilar", adding, [...] "Timbre depends primarily upon the frequency spectrum, although it also depends upon the sound pressure and the temporal characteristics of the sound" [...]|$|R
30|$|The {{final step}} of a timbre {{study is to}} give a {{physical}} interpretation of the perceptual dimensions revealed by the MDS analysis. This is usually done by submitting the perceptual dimensions to linear regression analyses with relevant acoustic features. Some of them are psychoacoustic descriptors, that is, acoustic features {{that have been found}} to correspond to <b>auditory</b> <b>sensations.</b> Models that compute psychoacoustic descriptors are usually based on a model of the peripheral auditory system.|$|R
5000|$|Mutations in {{this gene}} have been {{associated}} with progressive postlingual hearing loss, [...] and profound prelingual deafness. TMC1 mutations are not associated with other symptoms or abnormalities, which is known as Nonsyndromic hearing loss and indicates that TMC1 functions mainly in <b>auditory</b> <b>sensation.</b> Additionally, recessive mutations of the gene result in both a loss of TMC1 function as well as profound deafness indicating TMC1 function is necessary for the processing of auditory signals.|$|R
30|$|Pitch is an <b>auditory</b> <b>sensation</b> {{in which}} a {{listener}} assigns musical tones to relative positions. It is measured in hertz. Pitch [16, 17] content is given by a “chroma” vector, corresponding to the 12 pitch classes C, C#, D to B, with values ranging from 0 to 1 that describe the relative dominance of every pitch in the chromatic scale [18]. Twelve audio features (× 13 to × 24) are computed for each segment by 12 pitch classes.|$|R
5000|$|Brain Stem Reflex: 'This {{refers to}} a process whereby an emotion is induced by music because one or more {{fundamental}} acoustical characteristics of the music are taken by the brain stem to signal a potentially important and urgent event. All other things being equal, sounds that are sudden, loud, dissonant, or feature fast temporal patterns induce arousal or feelings of unpleasantness in listeners...Such responses reflect the impact of <b>auditory</b> <b>sensations</b> - music as sound in the most basic sense.' ...|$|R
40|$|ABSTRACT: Multichannel {{auditory}} brainstem implants (ABI) {{are currently}} indicated {{for patients with}} neurofibromatosis type II (NF 2) involving both vestibulocochlear nerves. The ABI helps bypass the damaged cochlear nerves and restores a level of <b>auditory</b> <b>sensation</b> via the electrical stimulation of the cochlear nucleus. The implant is usually placed in the lateral recess of the fourth ventricle {{at the time of}} tumor resection to stimulate the cochlear nucleus. We report a case of ABI done on a 15 -year-old girl with bilateral vestibular schwannomas...|$|R
40|$|The {{process of}} forming the witnesses’ {{declarations}} involves {{a moment of}} achieving the information circumscribed to the crime or to its author, a moment of keeping the perceived information in memory and, finally, the moment of communicating this information to the judicial organs, by reproducing or acknowledging. To this process forming, all the sensations categories compete, in some way. Some {{of them have a}} prevailing role (visual and <b>auditory</b> <b>sensations),</b> others have a subsequent role (tactile, olfactory and gustatory sensations). witness, harmed person, testimony, crime...|$|R
50|$|In one 1997 {{study of}} white cats {{with varying degrees}} of hearing deficiency, 72% of the animals were found to be totally deaf. The entire organ of Corti was found to have {{degenerated}} within the first few weeks after birth; however, even during these weeks no brain stem responses could be evoked by auditory stimuli, suggesting that these animals had never experienced any <b>auditory</b> <b>sensations.</b> It was found that some months after the organ of Corti had degenerated, the spiral ganglion also began to degenerate.|$|R
50|$|Pitch is an <b>auditory</b> <b>sensation</b> {{in which}} a {{listener}} assigns musical tones to relative positions on a musical scale based primarily on {{their perception of the}} frequency of vibration. Pitch is closely related to frequency, but the two are not equivalent. Frequency is an objective, scientific attribute that can be measured. Pitch is each person's subjective perception of a sound wave, which cannot be directly measured. However, this {{does not necessarily mean that}} most people won't agree on which notes are higher and lower.|$|R
2500|$|Sound {{is defined}} [...] as [...] "(a) Oscillation in pressure, stress, {{particle}} displacement, particle velocity, etc., propagated {{in a medium}} with internal forces (e.g., elastic or viscous), or the superposition of such propagated oscillation. (b) <b>Auditory</b> <b>sensation</b> evoked by the oscillation described in (a). [...] " [...] Sound {{can be viewed as}} a wave motion in air or other elastic media. In this case, sound is a stimulus. Sound can also be viewed as an excitation of the hearing mechanism that results in the perception of sound. In this case, sound is a sensation.|$|R
30|$|In {{order to}} obtain the {{transcription}} of a particular piece, {{it is necessary to}} define the symbols that best describe the piece considering the desired notation. When the transcription process is performed by a device without human interference, it is called automatic transcription. Transcription of music is only possible because <b>auditory</b> <b>sensations</b> related to different musical gestures are distinguishable. To build an automatic transcriber, it is necessary to understand the relationship between these sensations and particular signal models, as well as the conditions under which these models work.|$|R
40|$|AbstractPalinacousis is a rarely {{reported}} {{symptom of}} temporal lobe dysfunction. Especially in psychiatric patients {{it may be}} misdiagnosed {{if it is not}} differentiated from the auditory hallucinations of psychotic illness. We report the case of a 20 -year-old patient with the previously established diagnosis of paranoid schizophrenia who presented with the symptom of palinacousis. She was not psychotic at that time, her only complaints being recurrent <b>auditory</b> <b>sensations.</b> Repeated EEG recordings showed a left temporal theta focus with spikes. The diagnosis of temporal lobe seizures was made. Treatment with carbamazepine led to complete recovery...|$|R
50|$|The {{principle}} of bone conduction {{has been used}} for many years to treat patients with single-sided deafness and conductive hearing loss. The principle is based on decades of research showing that bone conduction stimulation of the teeth initiates <b>auditory</b> <b>sensations.</b> Evidence shows that teeth vibrations lead to audio-frequency vibration transmissions via soft tissue. Those transmissions then travel through skull foramina into the skull cavity. From there, they channel into the inner ear fluids, stimulating the cochlea. Subsequently, Sonitus Medical developed SoundBite Hearing System to use those principles in a non-surgical, removable hearing system.|$|R
40|$|Biosolids {{distributed}} to reuse fields for recycling and beneficial purposes can potentially create nuisance condition to surrounding community and possibly lead to odor complaints. Consequently, the public’s {{lack of understanding}} of biosolids can limit the implementation of a worthwhile beneficial reuse program. This study developed a GIS-Based odor dispersion model as an alternative method for biosolids manager to measure the impact of biosolids odorants in the reuse fields by using the DCWASA biosolids fields as the case study. The results show the prediction maps expressed as concentration contours of predicted odorant <b>area</b> so-called <b>sensation</b> <b>area</b> or the area that concentration above the detection threshold (DT) or 1 3 /g m. The results show that the <b>sensation</b> <b>area</b> usually occurs at low wind speed condition especially in early morning and night. The <b>sensation</b> <b>area,</b> moreover, is also sensitive to topographic features particularly elevated terrain...|$|R
40|$|International audienceOBJECTIVES: Mutations of GJB 2 {{encoding}} connexin 26 are {{the most}} common cause of hearing loss. They are responsible for up to 50 % of ARNSHL. The pathogenic mutations in this gene are generally inherited recessively. Dominant mutations in GJB 2 also cause hearing loss, either in isolated non-syndromic form or as part of a syndrome associated with various skin disorders. METHODS: We screened a Tunisian child affected by congenital, bilateral, profound, sensorineural hearing loss for mutations in GJB 2 gene using PCR and direct sequencing. RESULTS: The proband was found to be compound heterozygous for recessive and dominant GJB 2 mutations respectively p. V 37 I (c. 109 G>A) and p. R 143 Q (c. 428 G>A). Surprisingly the hearing mother is a carrier for this dominant GJB 2 mutation. This proband underwent a cochlear implant at four years old. The evaluation using APCEI and IT-MAIS tests at six months post implantation indicates a successful cochlear implant outcome since the deaf child began to acquire language abilities and <b>auditory</b> <b>sensation.</b> CONCLUSIONS: The p. R 143 Q mutation was described for the first time in Tunisia. We confirm the low penetrance of this mutation since the proband mother is a carrier despite her normal hearing. We show the effectiveness of cochlear implant to restore the communication abilities and <b>auditory</b> <b>sensation</b> for our patient...|$|R
30|$|The {{present study}} {{assessed}} rehabilitation {{in children who}} used CIs to improve hearing function and establish oral language (Svirsky et al., 2000; Tobey, Geers, Brenner, Altuna, & Gabbert, 2003). Cochlear implants work through electrodes that are inserted in the cochlea where they electrically stimulate auditory nerve fibers. This stimulation provides <b>auditory</b> <b>sensations</b> of the frequency of speech and acoustic feedback for oral speech production (Spencer & Oleson, 2008). These conditions are important for learning that involves hearing and speech skills (Levine, Stother-Garcia, Golinkhoff, & Hirsh-Pasek, 2016; Svirsky et al., 2000), which can be operationalized as listening and speaking behaviors (Skinner, 1957).|$|R
50|$|As {{with other}} primary sensory {{cortical}} <b>areas,</b> <b>auditory</b> <b>sensations</b> reach perception only if received and processed by a cortical area. Evidence for {{this comes from}} lesion studies in human patients who have sustained damage to cortical areas through tumors or strokes, or from animal experiments in which cortical areas were deactivated by surgical lesions or other methods. Damage to the Primary Auditory Cortex in humans leads {{to a loss of}} any awareness of sound, but an ability to react reflexively to sounds remains as {{there is a great deal}} of subcortical processing in the auditory brainstem and midbrain.|$|R
30|$|This {{paper has}} {{presented}} an overview on automatic transcription of music. Discussion was conducted {{so that the}} two different stages—the digital signal processing, which calculates clues to characterize notes, and the classification process, which ultimately determines note onsets, offsets and pitches—can be properly understood, and what features are desirable in solutions for both stages. It also presents historical remarks on how techniques have evolved in the last 20 years, and the concepts and inspirations behind {{the most commonly used}} techniques. The general models that relate physical characteristics of a signal to <b>auditory</b> <b>sensations</b> were also discussed, as well as the specific transcription tasks that are dealt with by most AMT systems.|$|R
40|$|Insoles {{are known}} to alter plantar loads and thus plantar sensory input. We {{therefore}} hypothesised that plantar somatosensory sensation could be modified over time by use of hard metatarsal pads. A sample of 12 healthy female participants was randomly allocated to either soft metatarsal pads (n = 6, latex foam, Shore A 11) or hard metatarsal pads groups (n = 6, thermoplastic, ShoreA 65). All wore the same shoe type and pedometers measured daily activities. Using a bespoke actuated device, multiple mechanical stimuli were applied to the forefoot and rearfoot before and after 8 and 30 days of wearing the pads. A control test comprised estimation of multiple <b>auditory</b> <b>sensations</b> at day 0, 8 and 30. Changes in detection of the mechanical and sound stimuli were estimated using the Stevens power function, Ψ = k × Φn (estimate = Ψ; stimulus = Φ). The k coefficient measured the sensitivity, i. e. the lowest detectable load/sound, and the n coefficient the gain in perception over time. After 30 days, hard metatarsal pads group had increased plantar sensitivity in the forefoot but not the rearfoot. The soft metatarsal pads group showed no changes in plantar sensitivity and the detection of <b>auditory</b> <b>sensation</b> remained stable over the 30 days. Metatarsal pads with relatively high hardness increased {{the perception of the}} lowest mechanical stimulus in the forefoot compared to soft metatarsal pads. This provides initial evidence of the potential for changes in plantar somatosensory sensation due to choice of orthotic designs in patients with foot-related problems...|$|R
30|$|The {{organization}} {{of this paper}} is as follows. Section 2 brings some remarks on psycho-acoustics, on how basic models are related to simple <b>auditory</b> <b>sensations</b> and on conventions used for music notation. In Sect. 3, digital signal processing techniques for obtaining proper representations of the signal, allowing further classification, are discussed. Section 4 addresses the problem of finding discrete notes using the previously obtained data. Section 5 shows the different transcription problems tackled in the literature, and how their different characteristics are important in order to build an automatic transcriber. The evaluation of automatic transcription systems is approached in Sect. 6. Further discussions are conducted in Sects. 7 and 8 concludes the text.|$|R
40|$|The MaxxBass signal {{processing}} algorithm is introduced {{as a new}} factor in low frequency loudspeaker design. Exploiting {{the phenomenon of the}} ‘missing fundamental’, MaxxBass stimulates a low frequency <b>auditory</b> <b>sensation</b> without the need to produce the whole low frequency range. A brief review is made of the performance limitations in the bass reproduction of small speakers with emphasis upon the difficulty of efficiently lowering the resonant frequency. The breakdown in the ear’s logarithmic sensitivity at low frequencies is identified as a factor for satisfactory bass performance. With MaxxBass correctly implemented, gains in apparent low frequency extension of up to one and a half octaves are reported. Example applications of MaxxBass are explored...|$|R
50|$|MEDUSA (Mob Excess Deterrent Using Silent Audio) is a directed-energy {{non-lethal}} weapon designed by WaveBand Corporation in 2003-2004 for temporary personnel incapacitation. The weapon {{is based on}} the microwave auditory effect resulting in a strong sound sensation in the human head when it is subject to certain kinds of pulsed/modulated microwave radiation. The developers claimed that through the combination of pulse parameters and pulse power, it is possible to raise the <b>auditory</b> <b>sensation</b> to a “discomfort” level, deterring personnel from entering a protected perimeter or, if necessary, temporarily incapacitating particular individuals. In 2005, Sierra Nevada Corporation acquired WaveBand Corporation and ceased all work on the MEDUSA technology and did not pursue the technology further.|$|R
5000|$|Vibration of {{the skull}} results in <b>auditory</b> <b>sensation.</b> This {{is a way to}} {{somewhat}} bypass the outer and middle ears to stimulate the cochlea. Von Bekesy is credited with the discovery that {{at the level of the}} cochlea, phase shifted bone-conduction signals cancel out air conduction signals. Bone-conduction works because all of the bones {{of the skull}} are connected, including the temporal bone, which in turn stimulates the cochlea. Barany (1938) and Herzog & Krainz (1926) were some of the first researchers to examine the different components of bone-conduction hearing. Tonndorf (1968) found that there are three different forces that contribute to the forces needed to stimulate the cochlea: Distortional, Inertial (Ossicular), and External canal (Osseotympanic) ...|$|R
