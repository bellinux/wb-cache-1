0|168|Public
40|$|This paper {{presents}} novel {{unit cell}} architecture for short wave infrared (SWIR) imaging applications. It has two input stages which are CTIA and SFD covering for both respectively {{low and high}} light levels and <b>automatic</b> <b>input</b> stage selection circuitry that chooses best input stage. A user can select 2 modes for FPA manual and automatic mode. In manual mode, user can set CTIA or SFD for all pixels according to user needs. In automatic mode, each pixel selects input stage itself according to light level. <b>Automatic</b> <b>input</b> stage selection for each pixel brings high SNR level and low noise along with highest possible dynamic range. Standard CMOS 0. 18 mu m TSMC technology is used to realize unit cell. In the architecture of unit cell, circuit level techniques are used to optimize layout size. ...|$|R
40|$|The {{distinct}} element {{method is}} adapted {{in this study}} as a numerical tool to provide a simulation of pack ice interaction with ships and icebreakers. Several special enhancements are implemented to a software package, {{which is used to}} deal with the environmental driving forces and <b>automatic</b> <b>input</b> data generation of pack ice field. Peer reviewed: NoNRC publication: Ye...|$|R
40|$|Data {{conventions}} for the <b>automatic</b> <b>input</b> of multiperiod stochastic linear {{programs are}} described. The input format {{is based on}} the MPSX standard and is designed to promote the efficient conversion of originally deterministic problems by introducing stochastic variants in separate files. A flexible "header" syntax generates a useful variety of stochastic dependencies. An extension using the NETGEN format is proposed for stochastic network programs...|$|R
40|$|In recent years, rapid {{progress}} has been made in computer processing of oriental languages, and the research developments in this area have resulted in tremendous changes in handwriting processing, printed oriental character recognition, document analysis and recognition, <b>automatic</b> <b>input</b> methodologies for oriental languages, etc. Advances in computer processing of oriental languages can also be seen in multimedia computing and the World Wide Web. Many of the results in those domains are presented in this book...|$|R
40|$|Pilot {{project of}} {{traceability}} and meat labelling system {{was used to}} build up database of Cattle Breeding Service of Slovenia. We have developed software for identification of beef carcasses on the slaughter line and the comparison between central data base and slaughterhouse database. The software enables <b>automatic</b> <b>input</b> of carcass weights, conformation scores and printing of labels. The system is involved in WEB and enables the consumers to check up the origin of meat they had bought...|$|R
40|$|The ATLAS {{data quality}} {{software}} infrastructure provides tools for prompt investigation of and feedback on collected data and propagation {{of these results}} to analysis users. Both manual and <b>automatic</b> <b>inputs</b> are used in this system. In 2009 and 2010 we have gained significant experience with collision data operations and analysis; we have used this experience to improve the data quality system, particularly in areas of scaling and user interface. This talk desecribes the commissioning experience and subsequent improvements...|$|R
40|$|With some {{intelligent}} algorithms, such as Genetic Algorithms (GA) and Kohonen Neural Network (NN), {{in addition}} to traditional digital image processing algorithms, a color map <b>automatic</b> <b>input</b> algorithm is proposed in this paper which {{is important for the}} data acquiring of CAD and GIS, etc. These have been realized in our Digital Map System (DMS) successfully. In this paper, a new color image segmentation algorithm based on color space transformation and vectorization algorithm based on GA are presented in detail...|$|R
40|$|In {{the paper}} {{the model of}} voice interface, which {{provides}} <b>automatic</b> <b>input</b> of Russian speech is proposed. The morphemes level of speech representation is introduced {{and as a result}} the size of vocabulary is significantly decreased. The developed morphemes databases are used for collecting the statistics of morphemes co-ordination by text corpuses. At that during recognition the degree of co-ordination between root morphemes has main significance. As a result of such processing the invariance to grammatical deviations is provided and also the speed of recognition of Russian speech and other languages with complex mechanism of word formation is improved. 1...|$|R
50|$|Some Armenian {{letters are}} entered as Latin digraphs, {{and may also}} be {{followed}} by the input of an ASCII single quote (which acts as the only letter modifier recognized) but this quote does not always mean that the intended Armenian letter should be aspirated (this may be the reverse for the input ch), it is also used as a vowel modifier. Due to ambiguities, texts must be corrected by entering an intermediate dummy character before entering the second Latin letter or quote, then removing the dummy character, so that the <b>automatic</b> <b>input</b> converter keeps the Armenian letters distinct.|$|R
40|$|Assertions {{can be used}} to {{automate}} the process of testing software. Two methods for automating the generation of input test data are described in this paper. One method selects the input values of variables at regular intervals in a 'grid'. The other, adaptive testing, uses assertion violations as a measure of errors detected and generates new test cases based on test results. The important features of assertion testing are that: it can be used throughout the entire testing cycle; it provides automatic notification of error conditions; and it can be used with <b>automatic</b> <b>input</b> generation techniques which eliminate the subjectivity in choosing test data...|$|R
5000|$|Introduced the AudioBox AB1616 {{including}} 16 {{digital audio}} playback channels {{on board with}} <b>automatic</b> <b>input</b> switching between live and playback on the first eight channels. On September 16 in Los Angeles, the Ride Vehicle version of the AudioBox (used in every ride vehicle on the Spider-Man ride at the Universal Studios Florida Islands of Adventure theme park) was awarded the Thea Award 2000 for Outstanding Achievement {{in the area of}} 'Breakthrough Technology' by the Themed Entertainment Association (TEA). The award states, [...] "Having been judged to represent the highest standards of excellence and creative achievement in the arts and sciences of the Themed Entertainment Industry." ...|$|R
5000|$|Features: Interlace mode, {{horizontal}} & vertical scrolling, Light pen <b>input,</b> hardware cursor, <b>underline,</b> blink, reverse video, 2 {{character sets}} of 256 each, update ready interrupt ...|$|R
50|$|<b>Automatic</b> form <b>input</b> systems use {{different}} types of recognition methods such as optical character recognition (OCR) for machine print, optical mark reading (OMR) for check/mark sense boxes, bar code recognition (BCR) for barcodes, and intelligent character recognition (ICR) for hand print.|$|R
40|$|Abstract. Techniques {{have been}} {{proposed}} to find the semantic differ-ences between two binary programs when the source code is not available. Analyzing control flow, and in particular, intra-procedural control flow, has become an attractive technique in the latest binary diffing tools since it is more resistant to syntactic, but non-semantic, differences. However, this makes such techniques vulnerable to simple function obfuscation techniques (e. g., function inlining) attackers any malware writers could use. In this paper, we first show function obfuscation as an attack to such binary diffing techniques, and then propose iBinHunt which uses deep taint and <b>automatic</b> <b>input</b> generation to find semantic differences in inter-procedural control flows. Evaluation on comparing various ver-sions of...|$|R
40|$|A Mach-Zehnder {{interferometer}} is {{used for}} optical flow measurements in a transonic wind tunnel. Holographic interferograms are reconstructed by illumination with a He-Ne-laser and viewed by a video camera through wide angle optics. This setup was used for investigating industrial double exposure holograms of truck tires {{in order to develop}} methods of automatic recognition of certain manufacturing faults. <b>Automatic</b> <b>input</b> is achieved by a transient recorder digitizing the output of a TV camera and transferring the digitized data to a PDP 11 - 34. Interest centered around sequences of interferograms showing the interaction of vortices with a profile and subsequent emission of sound generated by this process. The objective is the extraction of quantitative data which relates to the emission of noise...|$|R
40|$|International audienceIn recent years, {{more and}} more {{attention}} has been given to the safety of agricultural products, whose demands for the traceability system are increasingly urgent. This paper, in response to the demands, by using the C# programming language, database technology, IOT technology and RFID technology, realized the traceability system of agricultural products, and explained the implementation of network technology and RFID technology in detail. The traceability system can complete the functions of data collection, early warning, control and data <b>automatic</b> <b>input</b> & management during the production process. This system can well solve the problem of data entry in the farming operation, timely and effectively record the information involved in the production of agricultural products, which can ensure the authenticity of the data in the traceability system...|$|R
40|$|The {{accommodations}} (3) hold releasable fixing components (4) each {{of which}} is provided with fixture devices for the small part. The accommodations are openings, in which the fixing components are inserted. In each accommodation, several fixing components or a group of them are inserted. The accommodation openings fully penetrate the magazine round carrier (1). The accommodations are arranged on the round carrier in a regular manner and especially in a form which allows a simple programming of a control unit for the input, handling and/or removal of the stored small parts. ADVANTAGE - Each small part has a defined location in the magazine so that apart from a manual input and removal an <b>automatic</b> <b>input</b> and removal in arbitrary sequence is possible...|$|R
40|$|The paper {{describes}} the developed <b>automatic</b> data <b>input</b> algorithm (VBA - program), that allows significant simplification and fastening of calculation brushless DC motor magnetic field {{and analysis of}} its results in accordance with geometric size of the magnetic circuit separate elements and properties of the materials...|$|R
40|$|Abstract: The {{conventional}} marking {{and identification}} of animals {{can be done in}} several different ways. With the application of modern informatics and electronics solutions, it is possible to substitute conventional ways with the different types of the electronic marking and identification. All types of electronic identification for transferring data are using the technology of the radio frequency (RFDI). With application of electronic marking, it is possible to achieve a great number of advantages of which the most important are the high precision of reading the data, individual supervision for every animal, <b>automatic</b> <b>input</b> of data, processing and keeping the information as a permanent actualization of data base. It is necessary to remove all existing defects and in future to work on the improvement of existing types of the electronic marking of animals...|$|R
40|$|The final {{publication}} {{is available}} at Springer via [URL] methodology to integrate geographical information system (GIS) data with large-scale pedestrian simulations has been developed. Advances in automatic data acquisition and archiving from GIS databases, <b>automatic</b> <b>input</b> for pedestrian simulations, as well as scalable pedestrian simulation tools {{have made it possible}} to simulate pedestrians at the individual level for complete cities in real time. An example that simulates the evacuation of the city of Barcelona demonstrates that this is now possible. This is the first step towards a fully integrated crowd prediction and management tool that takes into account not only data gathered in real time from cameras, cell phones or other sensors, but also merges these with advanced simulation tools to predict the future state of the crowd. Peer ReviewedPostprint (author's final draft...|$|R
40|$|In present days, most of {{the design}} {{activity}} is performed {{at a high level}} of abstraction, thus designers need to be sure that their designs are syntactically and semantically correct before starting the automatic synthesis process. The goal {{of this paper is to}} propose an <b>automatic</b> <b>input</b> pattern generation tool able to assist designers in the generation of a test bench for difficult parts of small- or medium- sized digital protocol interfaces. The proposed approach exploit a Genetic Algorithm connected to a commercial simulator for cultivating a set of input sequence able to execute given statements in the interface description. The proposed approach has been evaluated on the new ITC' 99 benchmark set, a collection of circuits offering a wide spectrum of complexity. Experimental results show that some portions of the circuits remained uncovered, and the subsequent manual analysis allowed identifying design redundancies...|$|R
40|$|Techniques {{have been}} {{proposed}} to find the semantic differences between two binary programs when the source code is not available. Analyzing control flow, and in particular, intra-procedural control flow, has become an attractive technique in the latest binary diffing tools since it is more resistant to syntactic, but non-semantic, differences. However, this makes such techniques vulnerable to simple function obfuscation techniques (e. g., function inlining) attackers any malware writers could use. In this paper, we first show function obfuscation as an attack to such binary diffing techniques, and then propose iBinHunt which uses deep taint and <b>automatic</b> <b>input</b> generation to find semantic differences in inter-procedural control flows. Evaluation on comparing various versions of a http server and gzip shows that iBinHunt not only is capable of comparing inter-procedural control flows of two programs, but offers substantially better accuracy and efficiency in binary diffing...|$|R
40|$|Reduction of chip {{packaging}} and cooling costs for deep sub-micron System-On-Chip (SOC) designs is an emerging issue. We present a simulationbased methodology able to realistically model the complex {{environment in which}} a SOC design operates {{in order to provide}} early and accurate power consumption estimation. We show that a rich functional test bench provided by a designer with a deep knowledge of a complex system is very often not appropriate for power analysis and can lead to power estimation errors of some orders of magnitude. To address this issue, we propose an <b>automatic</b> <b>input</b> sequence generation approach based on a heuristic algorithm able to upgrade a set of test vectors provided by the designer. The obtained sequence closely reflects the worst-case power consumption for the chip and allows looking at how the chip is going to work over time...|$|R
40|$|We {{propose a}} theory of the {{development}} of speeded responding in choice tasks. Non-decision processing is performed by a cascade of linear accumulators, with accumulation beginning a fixed time after stimulus presentation (perceptual delay). The output of the non-decision stages feed into a decision stage consisting of an accumulator representing each choice. The first choice-accumulator to exceed its criterion, where criteria vary randomly and independently from trial-to-trial between accumulators, initiates a response after a fixed motor delay. The rates of all stages also vary randomly and independently from trial-to-trial. For almost any distributions of log-criteria and log-rates, response time (RT) has a Lognormal distribution with a lower bound determined by the sum of delays. Automaticity develops because the input to the correct accumulator increases exponentially with practice due to the formation of links to the choice stage with weights that interact multiplicatively. The mean log-rate of accumulation of each choice unit is determined by its input relative to inputs to other choice units, and so the rate for the correct response approaches an upper bound of with practice. The theory provided an accurate account of the effect of consistent-mapping practice on correct RT distribution in memory search (Kramer, Strayer & Buckley, 1990), mental rotation (Sutton & Heathcote, 2003), visual search (Heathcote & Mewhort, 2003) and categorization (Palmeri, 1997), including the effects of within- and between-category similarity in the latter data set. To account for the effect of algorithmic processing the correct choice unit was provided with an input from controlled-processing that does not change with practice. In cases where the controlled-processing input is initially larger than the <b>automatic</b> <b>input</b> a sigmoid (slow-fast-slow) decrease in RT is produced, whereas a smooth exponential decrease occurs when <b>automatic</b> <b>inputs</b> dominate. Strong control inputs accounted for sigmoid speedups prominent in Rickard’s (2004) data from an alphabet-arithmetic task, as well for some participants and conditions in Palmeri and Heathcote and Mewhort...|$|R
40|$|We {{describe}} an approach and tool for analyzing {{the vulnerability of}} software applications to anomalous events and malicious threats during software development. Traditionally, security analysis has been applied at the network system level, after release, using tiger team approaches. After a successful tiger team penetration, specific system vulnerabilities are patched. We {{make a case for}} applying software engineering analysis techniques that have proven successful in the software safety arena to security-critical software code. This work is based on the generally held belief that a large proportion of security violations result from errors introduced during software development. Our methodology employs software fault injection and <b>automatic</b> <b>input</b> generation to force anomalous program states while a piece of software is executing, in order to determine where it is most vulnerable. A software developer or security analyst can specify what constitutes a security policy violation for the s [...] ...|$|R
40|$|Introduction We {{describe}} a neural-network-based {{aid to the}} financial analysis of companies, which is in current use for portfolio management {{with a view to}} long-term investments, within the Groupe Caisse des Dépôts. The system rates companies into three classes, based on financial ratios. The choice of the relevant inputs, which is a crucial step in the design of a neural network, has been performed in two different ways: heuristically, based on a statistical analysis of the financial data, and through an <b>automatic</b> <b>input</b> selection technique. Interestingly, both methods lead to similar results. 2. Analysis of the available data Before buying or selling stock of a given company, the portfolio manager performs a financial analysis of the company in order to assess its profitability 1. The assessment is based on a set of fifteen financial ratios (e. g. working capital/fixed assets, profit after taxes and interest/net worth, etc.) per year from a...|$|R
40|$|Grid environments {{are ideal}} for {{executing}} applications that require {{a huge amount of}} computational work, both due to the big number of tasks to execute and to the large amount of data to be analysed. Unfortunately, current tools may require that users deal themselves with corrupted outputs or early termination of tasks. This becomes incovenient as the number of parallel runs grows to easily exceed the thousands. ReGS is a user-level software designed to provide automatic detection and restart of corrupted or early terminated tasks. ReGS uses a web interface to allow the setup and control of grid execution, and provides <b>automatic</b> <b>input</b> data setup. ReGS allows the automatic detection of job dependencies, through the GRID-ADL task management language. Our results show that besides automatically and effectively managing a huge number of tasks in grid environments, ReGS is also a good monitoring tool to spot grid nodes pitfalls. 1...|$|R
40|$|Despite {{the promise}} of {{research}} conducted {{at the intersection of}} computer-assisted language learning (CALL), natural language processing, and second language acquisition, few studies have explored the potential benefits of using intelligent CALL systems to deepen our understanding of the process and products of second language (L 2) learning. The strategic use of technology offers researchers novel methodological opportunities to examine how incremental changes in L 2 development occur during treatment as well as how the longitudinal impacts of experimental interventions on L 2 learning outcomes occur on a case-by-case basis. Drawing on the pilot results from a project examining the effects of <b>automatic</b> <b>input</b> enhancement on L 2 learners’ development, this article explores how the use of technology offers additional methodological and analytical choices for the investigation of the process and outcomes of L 2 development, illustrating the opportunities to study what learners do during visually enhanced instructional activities...|$|R
40|$|The ATLAS {{data quality}} {{software}} infrastructure provides tools for prompt investigation of and feedback on collected data and propagation {{of these results}} to analysis users. Both manual and <b>automatic</b> <b>inputs</b> are used in this system. In 2011, we upgraded our framework to record all issues affecting {{the quality of the}} data in a manner which allows users to extract as much information (of the data) for their particular analyses as possible. By improved recording of issues, we are allowed the ability to reassess the impact {{of the quality of the}} data on different physics measurements and adapt accordingly. We have gained significant experience with collision data operations and analysis; we have used this experience to improve the data quality system, particularly in areas of scaling and user interface. This document describes the experience gained in assessing and recording of the data quality of ATLAS and subsequent benefits to the analysis users...|$|R
40|$|THE {{proposed}} {{procedure for}} automatic translation of a Japanese linear text into English {{can be divided}} into four stages: 1) <b>automatic</b> <b>input</b> editing, 2) <b>automatic</b> segmentation with morphological analysis, 3) syn-tactical analysis, and 4) transformation with output editing, including semantic transfer. 2. FORMS OF INPUT TEXTS It is apparent that input texts which are in accord with a commonly accepted writing system are better {{in the sense that they}} need less pre-editing before they are fed into a machine. Because the standard vernac-ular writing system of Japanese makes no use of spaces between words and because kanas (syllable Japanese characters) and kanjis (ideographic Chinese characters) are used instead of roman letters, it is necessary to devise a method of automatically cutting into its components the unseg-mented sentence, written in kanas and kanjis, In the standard writing system, 71 kanas and 1850 kanjis are used...|$|R
50|$|This method can {{automate}} {{data processing}} by using pre-defined templates and configurations. A template in this case, {{would be a}} map of the document, detailing where the data fields are located within the form or document. As compared to the manual data entry process, <b>automatic</b> form <b>input</b> systems are more preferable, since they help reduce the problems faced during manual data processing.|$|R
40|$|International audienceWe {{developed}} at CeSAM (Centre de donnees Astrophysiques de Marseille) ETC- 42, an Exposure Time Calculator compliant with Virtual Observatory standards. ETC- 42 {{has been designed}} to facilitate the integration of new sites, instruments and sources by the user. It is not instrument-specific, but is based on generic XML input data. It is used in several project implementations (EUCLID, PFS, IRIS, WISH, EELTs) covering a wide wavelength range, from NIR to UV. The previous release has been optimized to achieve gain of computation time. New functionalities for <b>automatic</b> <b>input</b> parameterization have been added to target specific instrumental configuration and to give an increased level of user-friendliness. This article describes the new functionalities : fixtures, sdaptive optics, Fabry Perot implementation and two new builder tools to create Telescope transmission curves and sky brightness tables. And, in order to facilitate the integration to the Virtual Observatory environment, VO drag and drop functionality is now available...|$|R
40|$|Abstract. The paper {{describes}} {{the process of}} designing a natural language dialogue interface for querying large databases with time data about electrical power network failures. The first stage of implementation of such dialogue interface consists of creation and preparation of several auxiliary resources that are required for natural language processing of texts over this specific domain. All modern methods of <b>automatic</b> <b>input</b> analysis of texts covering a domain with special terminology {{are based on a}} collection of large amount of texts from the field, so called textual corpus. We describe the process and statistical results of creation of a corpus of electrical power networks texts consisting of more than 100. 000 of positions (words and marks). We also offer some preliminary results of syntactical analysis of these texts. In the last part of this paper, we present the design of a dialogue system based on the analysis techniques using the corpus data that will allow natural language queries (in Czech) over the database of power networks failures. ...|$|R
40|$|The Hybrid Automated Reliability Predictor (HARP) {{integrated}} reliability (HiREL) workstation tool system marks {{another step}} toward the goal of producing a totally integrated computer aided design (CAD) workstation design capability. Since a reliability engineer must generally graphically represent a reliability model before he can solve it, {{the use of a}} graphical input description language increases productivity and decreases the incidence of error. The captured image displayed on a cathode ray tube (CRT) screen serves as a documented copy of the model and provides the data for <b>automatic</b> <b>input</b> to the HARP reliability model solver. The introduction of dependency gates to a fault tree notation allows the modeling of very large fault tolerant system models using a concise and visually recognizable and familiar graphical language. In addition to aiding in the validation of the reliability model, the concise graphical representation presents company management, regulatory agencies, and company customers a means of expressing a complex model that is readily understandable. The graphical postprocessor computer program HARPO (HARP Output) makes it possible for reliability engineers to quickly analyze huge amounts of reliability/availability data to observe trends due to exploratory design changes...|$|R
40|$|Abstract: The {{adjustment}} {{of the primary}} and secondary air speed and air quantity in thermal power plant is generally based on the measurement of static meter to show its working condition. It is difficult to adjust the air-coal parameter of each combustor to a reasonable value according to the static value for no certain relationship between the static value and the air speed is available to calculate the air speed and air quantity. The on-line monitoring system of boiler air-powder computer for real-time monitoring is adopted to keep the boiler {{in a state of}} balanced and steady combustion. The steady and accurate monitoring system and the <b>automatic</b> <b>input</b> rate of boiler (100 %), which could detect the load distribution, pipe blockage, powder interruption and spontaneous combustion accurately, shows considerable value in energy conservation and great practical value in regard to combustion adjustment and reasonable distribution of air and powder. System Overview It is well known that the combustion condition and efficiency of boiler is directly influenced by the primary and secondary air speed, air quantity, coal-powder flow and air-powder ratio of each combustor. During the operation of boiler, the following conditions are frequent: a high content of combustibles in fly ash, coking in the hearth, burnout of combustor and instable combustion. I...|$|R
40|$|Microsaccades are {{miniature}} involuntary eye movements which occur {{even during}} fixation. The {{rate of occurrence}} of microsaccades is typified by a decrease immediately after stimulus onset and a subsequent peak; many results in the EEG gamma band may be attributable to this peak, which occurs approximately 200 ms to 300 ms after stimulus onset in object recognition tasks. This rate may be modulated {{by a number of}} stimulus and task factors. While recording eye movements, we presented images of living and non-living objects and phase scrambled textural patches produced from those objects, as either broadband unfiltered (BB), high-pass filtered (HP), or low-pass filtered (LP) images. Participants classified objects as living or non-living. We observed a bimodal distribution of eye movements during fixation. Only the rate of occurrence of the larger eye movements (∼ 1 deg or more) was modulated by our manipulations. These larger movements were present only for objects, and showed a smaller peak for LP images. In contrast, the rate of the smallest population of eye movements (less than 0. 4 deg) was unaffected by spatial frequency or object presence. The results imply an early and <b>automatic</b> <b>input</b> of high-level information into eye movement control during fixation, probably driven by information on edges and lines present in BB and HP images...|$|R
