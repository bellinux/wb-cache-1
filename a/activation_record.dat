27|253|Public
50|$|A {{subprogram}} {{may find}} it useful {{to make use of}} a certain amount of scratch space; that is, memory used during the execution of that subprogram to hold intermediate results. Variables stored in this scratch space are termed local variables, and the scratch space is termed an <b>activation</b> <b>record.</b> An <b>activation</b> <b>record</b> typically has a return address that tells it where to pass control back to when the subprogram finishes.|$|E
50|$|Modern {{languages}} after ALGOL such as PL/1 and C {{almost invariably}} use a stack, usually supported by most modern computer instruction sets {{to provide a}} fresh <b>activation</b> <b>record</b> for every execution of a subprogram. That way, the nested execution is free to modify its local variables without concern for the effect on other suspended executions in progress. As nested calls accumulate, a call stack structure is formed, consisting of one <b>activation</b> <b>record</b> for each suspended subprogram. In fact, this stack structure is virtually ubiquitous, and so activation records are commonly termed stack frames.|$|E
50|$|Some {{languages}} such as Pascal and Ada {{also support}} nested subroutines, which are subroutines callable {{only within the}} scope of an outer (parent) subroutine. Inner subroutines have access to the local variables of the outer subroutine that called them. This is accomplished by storing extra context information within the <b>activation</b> <b>record,</b> also termed a display.|$|E
5000|$|Due to {{concurrent}} {{execution of}} agent procedures, a conventional sequential stack allocation scheme {{cannot be used}} as the <b>activation</b> <b>records</b> of the agent calls do not follow a last-in first-out pattern. Instead, the creator-subagent relationships form a tree-structured stack. A simple scheme is used to implement this behaviour, which works by allocating new <b>activation</b> <b>records</b> {{at the top of the}} stack, and linking subagents' <b>activation</b> <b>records</b> to their creator's record. These records are freed only when the agent has terminated and they are at the top of the stack. [...] The effectiveness of this scheme depends on the structure and behaviour of a program, which in some cases will result in poor memory usage. A more effective scheme was implemented in the SuperPascal language.|$|R
40|$|This paper {{presents}} {{two techniques}} for improving garbage collection performance: generational stack collection and profile-driven pretenuring. The first is applicable to stackbased implementations of functional languages {{while the second}} is useful for any generational collector. We have implemented both techniques in a generational collector used by the TIL compiler (Tarditi, Morrisett, Cheng, Stone, Harper, and Lee 1996), and have observed decreases in garbage collection times {{of as much as}} 70 % and 30 %, respectively. Functional languages encourage the use of recursion which can lead to a long chain of <b>activation</b> <b>records.</b> When a collection occurs, these <b>activation</b> <b>records</b> must be scanned for roots. We show that scanning many <b>activation</b> <b>records</b> can take so long as to become the dominant cost of garbage collection. However, most deep stacks unwind very infrequently, so most of the root information obtained from the stack remains unchanged across successive garbage collections. Generatio [...] ...|$|R
50|$|In a multi-threaded environment, {{there is}} {{generally}} {{more than one}} stack. An environment that fully supports coroutines or lazy evaluation may use data structures other than stacks to store their <b>activation</b> <b>records.</b>|$|R
50|$|In computing, a {{stack trace}} (also called stack backtrace or stack traceback) {{is a report}} of the active stack frames at a certain point in time during the {{execution}} of a program. When a program is run, memory is often dynamically allocated in two places; the stack and the heap. Memory is contiguously allocated on a stack but not on a heap, thus reflective of their names. Stack also refers to a programming construct, thus to differentiate it, this stack is referred as the program's runtime stack. Technically, once a block of memory has been allocated on the stack, it cannot be easily removed as there can be other blocks of memory that were allocated before it. Each time a function is called in a program, a block of memory is allocated on top of the runtime stack called the <b>activation</b> <b>record.</b> At a high level, an <b>activation</b> <b>record</b> allocates memory for the function's parameters and local variables declared in the function.|$|E
50|$|The {{parameters}} of a function or procedure {{can often be}} viewed as the fields of a record variable; and the arguments passed to that function {{can be viewed as a}} record value that gets assigned to that variable at the time of the call. Also, in the call stack that is often used to implement procedure calls, each entry is an <b>activation</b> <b>record</b> or call frame, containing the procedure parameters and local variables, the return address, and other internal fields.|$|E
50|$|In a {{traditional}} RISC design, better {{referred to as}} load-store architecture, memory is accessed explicitly through commands that load data into registers and back out to memory. Instructions that manipulate those data generally work solely on the registers. This allows the processor to clearly separate the movement of data from the processing done on it, {{making it easier to}} tune the instruction pipelines and add superscalar support. However, programming languages do not actually operate in this fashion. Generally they use a stack containing local variables and other information for subroutines known as a stack frame or <b>activation</b> <b>record.</b> The compiler writes code to create activation records using the underlying processor's load-store design.|$|E
50|$|The {{implementation}} of these scoping rules is not trivial. By {{the time that}} actf is finally executed, the <b>activation</b> <b>records</b> where its environment variables live may be arbitrarily deep in the stack. This is the so-called downwards funarg problem.|$|R
40|$|The report {{describes}} {{the process of}} designing, building and evaluating a Simula compiler based directly on the multi-platform optimization and code generation framework of the GNU Compiler Collection (GCC). Utilization of this framework, known as the GCC back-end, enables this Simula implementation to generate good-quality assembler code for the variety of machine platforms that are supported by GCC. The interface provided by the GCC back-end is more flexible than the C language and therefore provides certain advantages when expressing the semantics of Simula to the low-level optimization machinery of the GCC back-end. Accommodation of Simula's coroutine feature poses a particular challenges on the GCC back-end {{with respect to the}} heap-based <b>activation</b> <b>records</b> that become necessary. Extensive preallocation of <b>activation</b> <b>records</b> reduces the number of heap allocations and improves run-time performance at the expense of memory parsimony...|$|R
40|$|International audienceInterprocedural program {{analysis}} is often performed by computing procedure summaries. While possible, computing adequate summaries is difficult, {{particularly in the}} presence of recursive procedures. In this paper, we propose a complementary framework for interprocedural analysis based on a direct abstraction of the calling context. Specifically, our approach exploits the inductive structure of a calling context by treating it directly as a stack of <b>activation</b> <b>records.</b> We then build an abstraction based on separation logic with inductive definitions. A key element of this abstract domain is the use of parameters to refine the meaning of such call stack summaries and thus express relations across <b>activation</b> <b>records</b> and with the heap. In essence, we define an abstract interpretation-based analysis framework for recursive programs that permits a fluid per call site abstraction of the call stack [...] much like how shape analyzers enable a fluid per program point abstraction of the heap...|$|R
50|$|When one {{function}} calls another {{during a}} typical program's execution, the local {{state of the}} caller (including parameters and local variables) must be preserved in order for execution to proceed after the callee returns. In most compiled programs, this local state is stored on the call stack in a data structure called a stack frame or <b>activation</b> <b>record.</b> This stack frame is pushed, or allocated, as prelude to calling another function, and is popped, or deallocated, when the other function returns to the function that did the call. The upwards funarg problem arises when the calling function refers to the called/exited function's state after that function has returned. Therefore, the stack frame containing the called function's state variables must not be deallocated when the function returns, violating the stack-based function call paradigm.|$|E
50|$|The {{idea was}} to make one {{particularly}} common instruction, the procedure call, extremely easy to implement in the compilers. Almost all computer languages use a system known as an <b>activation</b> <b>record</b> or stack frame for each procedure—a modular unit of execution—that contains the address from which the procedure was called, the data (parameters) that were passed in, and space for any result values {{that need to be}} returned. In the vast majority of cases these frames are small, typically with three or fewer inputs and one or no outputs (and sometimes an input is reused as an output). In the Berkeley design, then, a register window was a set of several registers, enough of them that the entire procedure stack frame would most likely fit entirely within the register window.|$|E
50|$|Dynamic scoping {{is fairly}} easy to implement. To find an identifier's value, the program could {{traverse}} the runtime stack, checking each <b>activation</b> <b>record</b> (each function's stack frame) for a value for the identifier. In practice, this is made more efficient via {{the use of an}} association list, which is a stack of name/value pairs. Pairs are pushed onto this stack whenever declarations are made, and popped whenever variables go out of scope. Shallow binding is an alternative strategy that is considerably faster, making use of a central reference table, which associates each name with its own stack of meanings. This avoids a linear search during run-time to find a particular name, but care should be taken to properly maintain this table. Note that both of these strategies assume a last-in-first-out (LIFO) ordering to bindings for any one variable; in practice all bindings are so ordered.|$|E
40|$|Abstract. The {{intensional}} {{transformation is}} a technique {{that can be used}} in order to eliminate higher-order functions from a functional program by introducing appropriate context manipulation operators. The transformation can be applied to a significant class of higher-order programs and results in equivalent zero-order intensional programs that can be executed in a simple demand-driven way. Despite its simplicity, the transformation has never been seriously evaluated with respect to its efficiency and potential. Certain simple implementations of the technique have been performed, but the questions regarding the merits of the method have remained inconclusive. In this paper we demonstrate that the transformation can be efficiently implemented by using what we call lazy <b>activation</b> <b>records,</b> namely <b>activation</b> <b>records</b> in which some entries are filled on-demand. An evaluation of our implementation demonstrates that the technique outperforms some of the most well-known functional programming systems, for the class of programs that can be transformed. ...|$|R
40|$|It {{has been}} {{proposed}} that allocating procedure <b>activation</b> <b>records</b> on a garbage collected heap is more efficient than stack allocation. However, previous comparisons of heap vs. stack allocation have been over-simplistic, neglecting (for example) frame pointers, or the better locality of reference of stacks. We present a comprehensive analysis of all the components of creation, access, and disposal of heap-allocated and stack-allocated <b>activation</b> <b>records.</b> Among our results are: ffl Although stack frames {{are known to have}} a better cache read-miss rate than heap frames, our simple analytical model (backed up by simulation results) shows that the difference is too trivial to matter. ffl The cache write-miss rate of heap frames is very high; we show that a variety of miss-handling strategies (exemplified by specific modern machines) can give good performance, but not all can. ffl The write-miss policy of the primary cache is much more important than the write-miss policy of the second [...] ...|$|R
40|$|Languages such as Scheme and Smalltalk {{that provide}} continuations as {{first-class}} data objects present {{a challenge to}} efficient implementation. Allocating <b>activation</b> <b>records</b> in a heap has proven unsatisfactory because of increased frame linkage costs, increased garbage collection overhead, and decreased locality of reference. However, simply allocating <b>activation</b> <b>records</b> on a stack and copying them when a continuation is created results in unbounded copying overhead. This paper describes a new approach based on stack allocation that {{does not require the}} stack to be copied when a continuation is created and that allows us to place a small upper bound on the amount copied when a continuation is reinstated. This new approach is faster than the naive stack allocation approach, and it does not suffer from the problems associated with unbounded copying. For continuationintensive programs, our approach is at worst a constant factor slower than the heap allocation approach, and for typical prog [...] ...|$|R
5000|$|Smalltalk-80 syntax {{is rather}} minimalist, based on {{only a handful}} of {{declarations}} and reserved words. In fact, only six [...] "keywords" [...] are reserved in Smalltalk: , , , , , and [...] These are actually called pseudo-variables, identifiers that follow the rules for variable identifiers but denote bindings that the programmer cannot change. The , , and [...] pseudo-variables are singleton instances. [...] and [...] refer to the receiver of a message within a method activated in response to that message, but sends to [...] are looked up in the superclass of the method's defining class rather than the class of the receiver, which allows methods in subclasses to invoke methods of the same name in superclasses. [...] refers to the current <b>activation</b> <b>record.</b> The only built-in language constructs are message sends, assignment, method return and literal syntax for some objects. From its origins as a language for children of all ages, standard Smalltalk syntax uses punctuation in a manner more like English than mainstream coding languages. The remainder of the language, including control structures for conditional evaluation and iteration, is implemented on top of the built-in constructs by the standard Smalltalk class library. (For performance reasons, implementations may recognize and treat as special some of those messages; however, this is only an optimization and is not hardwired into the language syntax.) ...|$|E
40|$|For call {{intensive}} programs, function {{calls are}} major bottlenecks during program execution since they usually force register contents to be spilled into memory. Such register to memory spills {{are much more}} pronounced in presence of recursion. A function call is usually accompanied by the creation of its <b>activation</b> <b>record</b> at function entry. In this paper, we will deviate from this usual practice; we create an <b>activation</b> <b>record</b> only when we find it necessary. The result is that on many occasions we can execute a function call without actually creating its <b>activation</b> <b>record.</b> We call our strategy lazy <b>activation</b> <b>record</b> strategy (LARS) and show how this strategy is particularly important for call [...] intensive programs. The LARS subsumes many traditional techniques like leaf-call optimization and tailrecursion optimization, and in addition, it extends Chow's shrink-wrapping in terms of scope and granularity...|$|E
40|$|For memory {{constrained}} environments like embedded systems, optimization {{for program}} size is often as important, {{if not more}} important, as optimization for execution speed. Commonly, compilers try to reduce the code segment and neglect the stack segment, although the stack can significantly grow during the execution of recursive functions as a separate <b>activation</b> <b>record</b> is required for each recursive call. An <b>activation</b> <b>record</b> holds administrative data like the return address and the frame pointer but also the function’s formal parameter list and local variables. If a formal parameter or local variable is dead at all recursive calls, then it can be declared globally so that only one instance exists independent of the call depth. We found that in 70 % of popular recursive algorithms and in all our real world benchmarks, {{it is possible to}} reduce the stack size by declaring formal parameters and local variables globally. Architectures might impose a penalty in code size for accessing global data. On IA 32, this stack size reduction starts to materialize for our benchmarks no later than in the fifth recursion...|$|E
40|$|The {{intensional}} {{transformation is}} a technique {{that can be used}} in order to eliminate higher-order functions from a functional program by introducing appropriate context-manipulation operators. The transformation can be applied to a significant class of higher-order programs and results in equivalent zero-order intensional programs that can be executed in a simple demand-driven way. Despite its simplicity, the transformation has never been seriously evaluated with respect to its efficiency and potential. Certain simple implementations of the technique have been performed, but questions regarding the merits of the method have remained inconclusive. In this paper we demonstrate that the transformation can be efficiently implemented by using what we call lazy <b>activation</b> <b>records,</b> namely <b>activation</b> <b>records</b> in which some entries are filled on-demand. An evaluation of our implementation demonstrates that the technique outperforms some of the most well-known functional programming systems, for the class of programs that can be transformed. © 2008 Birkhäuser Verlag Basel/Switzerland...|$|R
50|$|If the nested {{function}} or {{functions are}} (mutually) recursive, it becomes {{hard for the}} compiler to know exactly where on the call stack the non-local variable was allocated, as the frame pointer only points to the local variable of the nested function itself and there can be an arbitrary number of <b>activation</b> <b>records</b> on the stack in between. This is generally solved using access links or display registers.|$|R
40|$|This paper {{reports on}} {{preliminary}} results of finding sensorimotor cortex spatio-temporal residual activation during attempted motion of paralysed limbs in spinal cord injured (SCI) patients. Our {{aim is to}} make use of such activity to control non-invasive brain-computer interfaces where the association of movement imagery and device control should lead to reduced device training times. Application of a continuous wavelet transform to EEG records is used to illustrate the spatio-temporal cortical <b>activation</b> <b>recorded</b> when the subjects with SCI performed imaginary movements...|$|R
40|$|Writes via {{unchecked}} pointer dereferences rank {{high among}} vulnerabilities most often exploited by malicious code. The most common attacks use an unchecked string copy {{to cause a}} bu#er overrun, thereby overwriting the return address in the function's <b>activation</b> <b>record.</b> Then, when the function "returns", control is actually transferred to the attacker's code. Other attacks may overwrite function pointers, setjmp bu#ers, system-call arguments, or simply corrupt data to cause a denial of service...|$|E
40|$|We present BC-ε {{which is}} a {{function}} algebra that is sound and complete for LOGSPACE. It {{is based on the}} novel recursion-theoretic principle of generalized recursion where the step length of primitive recursion can be varied at each step. This allows elegant representations of functions like logarithm and division. Unlike characterizations found in the literature, it is noticeable that there {{does not appear to be}} a way to represent pairs in the algebra. The soundness proof uses a simulation based on “computational amnesia ” where, analogously to tail recursion optimization, a recursive call replaces its own <b>activation</b> <b>record.</b> Even though the call is not necessarily tail, we recover the full recursion by repeatedly restarting the computation. ...|$|E
40|$|Writes via {{unchecked}} pointer dereferences rank {{high among}} vulnerabilities most often exploited by malicious code. The most common attacks use an unchecked string copy {{to cause a}} buffer overrun, thereby overwriting the return address in the function's <b>activation</b> <b>record.</b> Then, when the function &quot;returns&quot;, control is actually transferred to the attacker's code. Other attacks may overwrite function pointers, setjmp buffers, system-call arguments, or simply corrupt data to cause a denial of service. A number of techniques have been proposed to address such attacks. Some are limited to protecting the return address only; others are more general, but have undesirable properties such as having a high runtime overhead, requiring manual changes to the source code, or forcing programmers to give up control of data representations and memory management...|$|E
40|$|Monitoring {{cellular}} calcium concentration using fluorescent reporters {{can provide}} a rapid, proportional assay of G-protein-coupled receptor <b>activation.</b> <b>Recording</b> calcium changes in single cells, or cell populations, is relatively straightforward, but requires careful deliberation regarding the appropriate calcium reporter and experimental approach. Here, we describe strategies to ensure that calcium changes are recorded with good fidelity and minimal invasiveness. We highlight {{a range of issues}} that need to be considered within the design of an experiment to measure cellular calcium, and suggest strategies to avoid common pit-falls...|$|R
5000|$|A {{call stack}} is {{composed}} of stack frames (also called <b>activation</b> <b>records</b> or <b>activation</b> frames). These are machine dependent and ABI-dependent data structures containing subroutine state information. This data is {{sometimes referred to as}} CFI (Call Frame Information). [...] Each stack frame corresponds to a call to a subroutine which has not yet terminated with a return. For example, if a subroutine named [...] is currently running, having been called by a subroutine , the top part of the call stack might be laid out like in the picture on the right.|$|R
40|$|We have {{developed}} an instrument for non-invasive optical imaging {{of the human brain}} that produces on-line images with a temporal resolution of 160 ms. The imaged quantities are the temporal changes in cerebral oxy-hemoglobin and deoxy-hemoglobin concentrations. We report real-time videos of the arterial pulsation and motor <b>activation</b> <b>recorded</b> on a 4 × 9 cm 2 area of the cerebral cortex in a healthy human subject. This approach to optical brain imaging is a powerful tool for the investigation of the spatial and temporal features of the optical signals collected on the brain. © 2000 Optical Society of America...|$|R
40|$|The EEG of the baboon was studied {{under two}} very {{different}} sets of conditions: 37 were totally immobolized while 12 were studied in their free movements with 4 channel telemetry. For the immobilzed, 3 stages were described: (1) <b>activation,</b> <b>record</b> desynchronized; (2) rest with 13 - 15 cm/sec rhythm, like the human alpha rhythm stage but with eyes open or closed; (3) relaxation with a decrease in 13 - 15 rhythm {{and the appearance of}} 5 - 7 cm/sec theta waves, eyelids closed, animal apparently sleeping. For the free animals the rest stage appeared when the animal's attention was not directed anywhere and there was no relaxation stage. It is concluded that the EEG pattern of the immobilized animal that was described as the "relaxation" stage really represents a special functional state which one must distinguish clearly from the physiological stages of sleep...|$|E
40|$|Ez is a language-based {{programming}} environ-ment {{that offers}} the services provided separately by programming languages and operating systems in traditional environments. These services are pro-vided as facilities of a high-level string processing language with a ‘persistent ’ memory in which values exist indefinitely or until changed. In EZ, strings and associative tables provide traditional file and direc-tory services. This paper {{concentrates on the}} use of EZ procedures and their activations, which, like other values, have indefinite lifetimes, In EZ, the low-level aspects of procedure execution, such as <b>activation</b> <b>record</b> creation, references to local variables, and access to state information, are accessible via high-level language constructs. As a result, traditiona!ly distinct services can be provided by a single service in the EZ environment. Furthermore, such services can be written in EZ itself. An editor / debugger that illus-trates the details of this approach is described. 1...|$|E
40|$|Although many defense {{mechanisms}} against {{buffer overflow}} attacks have been proposed, buffer overflow vulnerability in software {{is still one}} of the most prevalent vulnerabilities exploited. This paper proposes a micro-architecture based defense mechanism against buffer overflow attacks. As buffer overflow attack leads to a compromised return address, our approach is to provide a software transparent micro-architectural support for return address integrity checking. By keeping an uncompromised copy of the return address separate from the <b>activation</b> <b>record</b> in run-time stack, the return address compromised by a buffer overflow attack can be detected at run time. Since extra copies of return addresses are already found in the return address stack (RAS) for return address prediction in most high-performance microprocessors, this paper considers augmenting the RAS in speculative superscalar processors for return address integrity checking. The new mechanism provides 100 % accurate return address prediction as well as integrity checking for return addresses. Hence, it enhances system performance in addition to preventing a buffer overflow attack...|$|E
40|$|Psychology {{moved beyond}} the {{stimulus}} response mapping of behaviorism by adopting an information processing framework. This shift from behavioral to cognitive science was partly inspired by work demonstrating {{that the concept}} of information could be defined and quantified (Shannon, 1948). This transition developed further from cognitive science into cognitive neuroscience, in an attempt to measure information in the brain. In the cognitive neurosciences, however, the term information is often used without a clear definition. This paper will argue that, if the formulation proposed by Shannon is applied to modern neuroimaging, then numerous results would be interpreted differently. More specifically, we argue that much modern cognitive neuroscience implicitly focuses on the question of how we can interpret the <b>activations</b> we <b>record</b> in the brain (experimenter-as-receiver), rather than on the core question of how the rest of the brain can interpret those activations (cortex-as-receiver). A clearer focus on whether <b>activations</b> <b>recorded</b> via neuroimaging can actually act as information in the brain would not only change how findings are interpreted but should also change the direction of empirical research in cognitive neuroscience. status: publishe...|$|R
30|$|Staff found {{identification}} of eligible EL patients easier if the site lead was {{also involved in}} the national clinical audit. Identification was facilitated by combining their NELA register, emergency theatre lists and consultants’ knowledge of patients. This was easiest in sites with a real time NELA register and electronic patient trackers. Similarly, for STEMI identification was aided by the existence of pathway <b>activation</b> <b>records.</b> Conversely, for EL the relocation of patients (such as from ITU to ward) could delay identification as a patient could be temporarily ‘lost’. This was rarely a problem for STEMI as patients were admitted to a designated ward or coronary care unit and rarely moved to other locations.|$|R
40|$|BACKGROUND Atrial tachycardias (AT) {{during or}} after {{ablation}} of atrial fibrillation frequently pose a diagnostic challenge. We hypothesized that both the patterns and the timing of coronary sinus (CS) activation could facilitate AT mapping. METHODS AND RESULTS A total of 140 consecutive postpersistent atrial fibrillation ablation patients with sustained AT were investigated by conventional mapping. CS activation pattern was defined as chevron or reverse chevron when the <b>activations</b> <b>recorded</b> on both the proximal and the distal CS dipoles were latest or earliest, respectively. The local activation of mid-CS was timed with reference to Ppeak-Ppeak (P-P) interval in lead V 1. A ratio, mid-CS activation time to AT cycle length, was computed. Of 223 diagnosed ATs, 124 were macroreentrant (56...|$|R
