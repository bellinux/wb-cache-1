7|79|Public
40|$|By {{establishing}} a relation between information erasure and continuous phase transitions we generalise the Landauer bound to analog computing systems. The entropy production per {{degree of freedom}} during erasure of an <b>analog</b> <b>variable</b> (reset to standard value) is given by the logarithm of the configurational volume measured in units of its minimal quantum. As a consequence every computation has to be carried on with {{a finite number of}} bits and infinite precision is forbidden by the fundamental laws of physics, since it would require an infinite amount of energy. Comment: 5 pages, no figures, to appear in Phys. Rev. ...|$|E
40|$|To {{enhance the}} {{identification}} {{capacity of the}} skin-hearing aid for voice signals, the four-channel skin-hearing aid based on Morse encoding method is proposed in this article, which can overcome many disadvantages such as low identification rate and bad anti-jamming capability existing in <b>analog</b> <b>variable</b> pressure skin-hearing aid. By processing voices, seeking the corresponding Morse code of voice signals, establishing the skin response voltage sequence by the Morse encoding, stimulating the skins by this voltage sequence, and making the skins to more clearly feel different signals of voice, the identification rate of skin hearing can be enhanced obviously. <br /...|$|E
40|$|Information {{processing}} in {{the presence}} of noise has been a key challenge in multiple disciplines including computer science, communications, and neuroscience. Among such noise-reduction mechanisms, the shift-map code represents an <b>analog</b> <b>variable</b> by its residues with respect to distinct moduli (that are chosen as geometric scalings of an integer). Motivated by the multi-periodic neural code in the entorhinal cortex, i. e., the coding mechanism of grid cells, this work extends the shift-map code by generalizing the choices of moduli. In particular, it is shown that using similarly sized moduli (for instance, evenly and closely spaced integers, which tend to have large co-prime factors) results in a code whose codewords are separated in an interleaving way such that when the decoder has side information regarding the source, then error control is significantly improved (compared to the original shift map code). This novel structure allows the system to dynamically adapt to the side information at the decoder, even if the encoder is not privy to the side information. A geometrical interpretation of the proposed coding scheme and a method to find such codes are detailed. As an extension, it is shown that this novel code also adapts to scenarios when only a fraction of codeword symbols is available at the decoder...|$|E
40|$|It {{has been}} {{proposed}} that populations of neurons process information in terms of probability density functions (PDFs) of <b>analog</b> <b>variables.</b> Such <b>analog</b> <b>variables</b> range, for example, from target luminance and depth on the sensory interface to eye position and joint angles on the motor output side. The requirement that <b>analog</b> <b>variables</b> must be processed leads inevitably to a probabilistic description, while the limited precision and lifetime of the neuronal processing units leads naturally to a population representation of information. By encoding the probability density over the relevant <b>analog</b> <b>variables,</b> the neural ensemble can in principle answer any meaningful question about these <b>analog</b> <b>variables,</b> by implementing the Bayesian rules for information propagation. We show how a time-dependent probability density ρ(x; t) over variable x, residing in a specified function space of dimension D, may be decoded from the neuronal activities in a population as a linear combination of certain decoding functions φi(x), with coefficients given by the N firing rates ai(t) (generally with D << N). We show how the neuronal encoding process may be described by projecting a set of complementary encoding functions ˆ φi(x) on the probability density ρ(x; t), and passing the result through a rectifying nonlinear activation function. We show how both encoders ˆ φi(x) and decoders φi(x) may be determined by minimizing cost functions that quantify the inaccuracy of the representation. Expressing a given computation in terms of manipulation and transformation of probabilities, we show how this representation leads to a neural circuit that can carry out the required computation within a consistent Bayesian framework, with explicit construction of the synaptic weights in terms of encoders...|$|R
40|$|We {{continue}} {{to explore the}} hypothesis that neuronal populations represent and process <b>analog</b> <b>variables</b> in terms of probability density functions (PDFs). A neural assembly encoding the joint probability density over relevant <b>analog</b> <b>variables</b> can in principle answer any meaningful question about these variables by implementing the Bayesian rules of inference. Aided by an intermediate representation of the probability density based on orthogonal functions spanning an underlying low-dimensional function space, we show how neural circuits may be generated from Bayesian belief networks. The ideas and the formalism of this PDF approach are illustrated and tested with several elementary examples, and in particular through a problem in which model-driven top-down information flow influences the processing of bottom-up sensory input. Comment: 22 pages, 5 figures, submitted to Neural Computation, v 2. significant structural change...|$|R
30|$|The {{definition}} {{of how the}} primitives elements are implemented {{is one of the}} most important steps of behavioral modelling. It is necessary to pay special attention to the possible discontinuities in the analog domain of the mixed-mode circuit, because the discontinuities can cause convergence problems and instability. Therefore, smooth transitions of the <b>analog</b> <b>variables</b> should be used.|$|R
40|$|An Analog Electro-Optical Multiplier, {{a simple}} and compact buiid state device with no moving parts, has been designed, constructed, and tested. Functionally, this device is the direct analog of the {{familiar}} servo-multiplier, being capable of multiplying one <b>analog</b> <b>variable</b> by up to seven other individual analog variables. The servo-driven potentiometer arm {{has been replaced by}} a photoconductive cell, illuminated by a low-power lamp, connected in a bridge circuit with two fixed resistors. The servomechanism driving the potentiometer arm {{has been replaced by a}} solid state operational amplifier driving the lamp in response to the value of the multiplicand. Accuracies of 0. 62 per cent of full scale have been obtained with this multiplier which has a dynamic range of 4 cps. An important advantage of this multiplier is the appreciable reduction in the number of operational amplifiers required compared to analog multipliers currently on the market, both for four quadrant and two quadrant multiplication. Initial experiments were conducted using the Raytheon Raysistor, an electro -optical device consisting of a light source and a CdSe photoconductive cell. The effects of signal heating, hysteresis, and signal voltage across these cells is discussed and compared with the improved characteristics of the CdS photocells which were used in the final design. The problem of uniformly illuminating several of these cells with a single lamp is discussed. In addition, the properties of miniature lamps with regard to light output, power requirements, and speed of response is considered. [URL]...|$|E
40|$|This paper {{presents}} a novel type of nanoarchitecture {{which is both}} device and circuit independent. The starting idea is that computations can be performed in three fundamentally different ways: entirely digital (using Boolean gates), entirely analog (using high precision analog circuits), or mixed (using both digital and low precision analog circuits). The boundaries between these are sometimes very thin. As an example, a threshold logic gate is already mixed, i. e. even if the inputs and the output are Boolean, the weighted sum of its inputs is a (low-precision) <b>analog</b> <b>variable.</b> It has already been suggested {{that one of the}} possible mixed approaches will be the most power efficient solution. Still, the main disadvantages of using analog circuits are: (i) their more complex (handcrafted) design, and (ii) their (expected) lower reliability (signal-to-noise / precision). These will be exacerbated by scaling. We will show here how both disadvantages could be tackled. A constructive solution for Kolmogorov’s superposition or a (multi-threshold) threshold logic synthesis, could be used for the automatic synthesis of the (very) low-precision analog parts. Digital or threshold logic circuits could be used to compensate for the accumulation of noise in the cascaded (very) low precision analog circuits. These digital or threshold logic circuits will also contribute to von Neumann’s multiplexing schemes, hence not only compensating for the accumulation of noise, but also increasing the overall fault-tolerance of the system. A few examples will show how this architectural approach could be mapped on top of a given (nano) technology. 1...|$|E
40|$|The {{bandwidth}} of a phased-locked loop (PLL) {{is dependent}} on several analog parameters that are subject to process, temperature and voltage spreads, {{as well as to}} variations along the frequency-tuning range. Even in digital PLLs, which rely on a digital loop filter, the bandwidth still depends on the gains of two mixed-signal building blocks, namely the time/digital converter (TDC) and the digitally-controlled oscillator (DCO), that have conversion characteristics that are not well-controlled. The situation is even more cumbersome employing a singlebit TDC, often referred to as bang-bang phase detector (BBPD), where the linearized gain is inversely proportional to the input jitter [1]. An accurate and repeatable value of the PLL bandwidth, and in the general of the frequency response, is essential to meet several specifications, such as stability margin, settling time, jitter and spur level. When the PLL is operated as a direct frequency modulator with pre-emphasis of the modulation signal, the accuracy requirement of the frequency response is even more demanding [2]. Previously disclosed methods to control PLL bandwidth require a modulation signal to be injected into the loop [2], compensate the gain variations of just a single block (e. g., VCO [3] or BBPD [4]), or operate in the foreground [5]. This paper presents a digital PLL employing a digital background normalization of loop gain, which makes it independent of any <b>analog</b> <b>variable</b> (except for the reference frequency, which often is available from an accurate source). This method requires no injection of additional test signals and operates at a low rate, achieving low-noise and low-power operation, and also is suitable even for bang bang PLLs...|$|E
40|$|We {{show that}} {{networks}} of relatively realistic mathematical models for biological neurons can in principle simulate arbitrary feedforward sigmoidal neural nets {{in a way}} which has previously not been considered. This new approach is based on temporal coding by single spikes (respectively by the timing of synchronous firing in pools of neurons), rather than on the traditional interpretation of <b>analog</b> <b>variables</b> in terms of firing rates. The resulting new simulation is substantially faster and hence more consistent with experimental results about the maximal speed of information processing in cortical neural systems. As a consequence we can show that networks of noisy spiking neurons are "universal approximators" {{in the sense that they}} can approximate with regard to temporal coding any given continuous function of several variables. This result holds for a fairly large class of schemes for coding <b>analog</b> <b>variables</b> by firing times of spiking neurons. Our new proposal for the possible organiza [...] ...|$|R
40|$|We {{investigate}} through theoretical {{analysis and}} computer simulations {{the consequences of}} unreliable synapses for fast analog computations in networks of spiking neurons, with <b>analog</b> <b>variables</b> encoded by the current firing activities of pools of spiking neurons. Our results suggest a possible functional role for the well-established unreliability of synaptic transmission on the network level. We also investigate computations on time series and Hebbian learning in this context of space-rate coding in networks of spiking neurons with unreliable synapses. ...|$|R
40|$|We {{investigate}} through theoretical {{analysis and}} computer simulations {{the consequences of}} unreliable synapses for fast analog computations in networks of spiking neurons, with <b>analog</b> <b>variables</b> encoded by the ring activities of pools of spiking neurons. Our {{results suggest that the}} known unreliability of synaptic transmission may be viewed as a useful tool for analog computing, rather than as a "bug" in neuronal hardware. We also investigate computations on analog time series encoded by the ring activities of pools of spiking neurons...|$|R
40|$|The {{increase}} in unit capacity of electric equipment {{as well as}} complication of technological processes, devices control {{and management of the}} latter in power plants and substations demonstrate the need to improve the reliability and accuracy of measurement information characterizing the state of the objects being managed. The mentioned objective is particularly important for nuclear power plants, where the price of inaccuracy of measurement responsible process variables is particularly high and the error might lead to irreparable consequences. Improving the reliability and accuracy of measurements along with the improvement of the element base is provided by methods of operational validation. These methods are based on the use of information redundancy (structural, topological, temporal). In particular, information redundancy can be achieved by the simultaneous measurement of one <b>analog</b> <b>variable</b> by two (duplication) or three devices (triplication i. e., triple redundancy). The problem of operational control of the triple redundant system of measurement of electrical analog variables (currents, voltages, active and reactive power and energy) is considered as a special case of signal processing by an orderly sampling on the basis of majority transformation and transformation being close to majority one. Difficulties in monitoring the reliability of measurements are associated with the two tasks. First, one needs to justify the degree of truncation of the distributions of random errors of measurements and allowable residuals of the pairwise differences of the measurement results. The second task consists in formation of the algorithm of joint processing of a set of separate measurements determined as valid. The quality of control is characterized by the reliability, which adopted the synonym of validity, and accuracy of the measuring system. Taken separately, these indicators might lead to opposite results. A compromise solution is therefore proposed. The quality of the evaluation of the measured signal is characterized by a single comprehensive measure that takes account of both reliability and accuracy properties of the system. This indicator is the average precision measure which is the weighted average error of the various possible states of a group of three devices.  </p...|$|E
40|$|We {{deal with}} the problem of {{designing}} suitable languages for the modeling and the automatic verification of properties over analog circuits. To this purpose, we suitably enrich classical temporal logics with basic formulæ allowing to model arbitrary functions relating <b>analog</b> <b>variables.</b> We show how to accomplish the task of automatically check the resulting CTLf formulæ on analog circuits. To this purpose, we extend to the analog context a number of techniques for the abstraction and the verification of digital systems, based on three-valued temporal logics. 1...|$|R
50|$|The main {{difference}} from most other computing devices is that PLCs are intended-for and therefore tolerant-of more severe conditions (such as dust, moisture, heat, cold), while offering extensive input/output (I/O) {{to connect the}} PLC to sensors and actuators. PLC input can include simple digital elements such as limit switches, <b>analog</b> <b>variables</b> from process sensors (such as temperature and pressure), and more complex data such as that from positioning or machine vision systems. PLC output can include elements such as indicator lamps, sirens, electric motors, pneumatic or hydraulic cylinders, magnetic relays, solenoids, or analog outputs. The input/output arrangements may be built into a simple PLC, or the PLC may have external I/O modules attached to a computer network that plugs into the PLC.|$|R
40|$|Abstract — A SiGe BiCMOS mixed-signal {{adaptive}} controlleron-chip {{is presented}} that implements gradient descent of a supplied analog control objective. Eight <b>analog</b> <b>variables</b> controlling the external plant are perturbed in parallel using sinusoidal dithers, and their gradient components are estimated by parallel synchronous detection of the dithers {{in the control}} objective. Translinear all-NPN bipolar circuits achieve linear tuning of frequency and amplitude in the oscillators and synchronous detectors, covering a 4 kHz- 600 MHz range in dither frequencies with- 30 dB/octave suppression of inter-modulation products. Experimental results demonstrate adaptive optimization of a 3 -variable nonlinear plant within 1 µs, for dithers in the 100 - 200 MHz frequency range. The chip measures 3 mm× 3 mm in 0. 5 µm SiGe and consumes 110 mW at 3. 3 V supply. I...|$|R
40|$|Introduction A {{new class}} of connectionist {{architectures}} is presented called ASOCS (Adaptive Self-Organizing Concurrent Systems) [3, 4]. ASOCS models support efficient computation through self-organized learning and parallel execution. Learning is done through the incremental presentation of rules and/or examples. Data types include Boolean and multi-state variables; recent models support <b>analog</b> <b>variables.</b> The model incorporates rules into an adaptive logic network in a parallel and self organizing fashion. The system itself resolves inconsistencies and generalizes as the rules are presented. After {{an introduction to the}} ASOCS paradigm, the abstract introduces current research thrusts which significantly increase the power and applicability of ASOCS models. For simplicity, we discuss only boolean mappings in the ASOCS overview. ASOCS Overview In processing mode, ASOCS supports fully parallel execution on actual inputs according to the learned rules. The adapti...|$|R
40|$|Hybrid automata model {{systems with}} both digital and analog components, such as {{embedded}} control programs. Many verification tasks for such {{programs can be}} expressed as reachability problems for hybrid automata. By improving on previous decidability and undecidability results, we identify a boundary between decidability and undecidability for the reachability problem of hybrid automata. On the positive side, we give an (optimal) PSPACE reachability algorithm for the case of initialized rectangular automata, where all <b>analog</b> <b>variables</b> follow independent trajectories within piecewise-linear envelopes and are reinitialized whenever the envelope changes. Our algorithm {{is based on the}} construction of a timed automaton that contains all reachability information about a given initialized rectangular automaton. The translation has practical significance for verification, because it guarantees the termination of symbolic procedures for the reachability analysis of initialized rectangular autom [...] ...|$|R
40|$|We {{present an}} {{algorithmic}} analog-to-digital converter (ADC) architecture for large-scale parallel quantization of internally <b>analog</b> <b>variables</b> in externally digital array processors. The converter quantizes and accumulates a binary weighted sequence of partial binary-binary matrix-vector products computed on the analog array, under presentation of bit-serial inputs in descending binary order. The architecture combines algorithmic {{conversion of the}} residue, as in a standard algorithmic ADC, with synchronous accumulation of the partial products from the array. In conjunction with row-parallel digital storage of matrix elements in the array, two pipelined architectures are presented to accumulate partial products with common binary weight across rows: row-parallel ADC with digital post-accumulation, and row-cumulative ADC with analog pre-accumulation. Simulation results are presented to quantify the trade-off in precision and area for full-parallel flash, and row-parallel and row-cumulative partial algorithmic, analogto-digital conversion on the array. 1...|$|R
40|$|Introduction In {{standard}} {{neural network}} theory, neurons {{are described in}} terms of mean firing rates. The <b>analog</b> input <b>variable</b> I is mapped via a nonlinear gain function g to an <b>analog</b> output <b>variable</b> = g(I) which may be interpreted as the mean firing rate. If the input consists of output rates j of other neurons weighted by a factor w ij, we arrive at the standard formula i = g(X j w ij j) (10. 1) which is the starting point of most neural network theories. As we have seen in Chapter 1, the firing rate defined by a temporal average over many spikes of a single neuron is a concept which works well if the input is constant or changes on a time scale which is slow with respect {{to the size of the}} temporal averaging window. Sensory inp...|$|R
40|$|This thesis {{presents}} a modular hardware {{artificial neural network}} architecture using the random pulse data representation and processing. In random pulse machine, continuous variables can be represented as a probability of a pulse occurrence at a certain sampling time. Random pulse machines deal with <b>analog</b> <b>variables</b> while using digital technology to perform arithmetic and logic operations on binary pulses which are the information carries. Thus, large systems can be built to perform parallel analog computation on large amounts of input data using this technique. This is a good trade-off between the electronic circuit complexity and the computational accuracy and well suited for VLSI neural network. Simulations have been conducted to validate the performance of both 1 -bit and 2 -bit random pulse neural network. Perception application for linear classification and autoassociative memory for digit recognition are finally presented to illustrate {{the behavior of the}} developed artificial neural network...|$|R
40|$|Recently one {{has started}} to {{investigate}} the computational power of spiking neurons (also called "integrate and fire neurons"). These are neuron models that are substantially more realistic from the biological point of view than the ones which are traditionally employed in artificial neural nets. It has {{turned out that the}} computational power of networks of spiking neurons is quite large. In particular they have the ability to communicate and manipulate <b>analog</b> <b>variables</b> in spatio-temporal coding, i. e. encoded in the time points when specific neurons "fire" (and thus send a "spike" to other neurons). These preceding results have motivated the question which details of the firing mechanism of spiking neurons are essential for their computational power, and which details are "accidental" aspects of their realization in biological "wetware". Obviously this question becomes important if one wants to capture some of the advantages of computing and learning with spatio-temporal c [...] ...|$|R
50|$|A {{variable}} in the VFSM environment may be activated by actions - {{in such a case}} it is an output variable. For instance, a digital output has two actions: True and False. A numerical (<b>analog)</b> output <b>variable</b> has an action: Set. A timer which is both: an input and output variable can be triggered by actions like: Start, Stop or Reset.|$|R
40|$|A fast quantum search {{algorithm}} {{for continuous}} variables is presented. The {{result is the}} quantum continuous <b>variable</b> <b>analog</b> of Grover's algorithm originally proposed for qubits. A continuous <b>variable</b> <b>analog</b> of the Hadamard (i. e., Fourier transform) operation is {{used in conjunction with}} inversion about the average of quantum states to allow the approximate identification of an unknown quantum state in a way that gives a square-root speed-up over search algorithms using classical continuous variables. Also, we show that this quantum search algorithm is robust for a generalised Fourier transformation on continuous variables. Comment: 4 pages, few change...|$|R
40|$|Intelligence is {{our ability}} to learn {{appropriate}} responses to new stimuli and situations. Neu-rons in association cortex {{are thought to be}} essential for this ability. During learning these neurons become tuned to relevant features and start to represent them with persistent activ-ity during memory delays. This learning process is not well understood. Here we develop a biologically plausible learning scheme that explains how trial-and-error learning induces neuronal selectivity and working memory representations for task-relevant information. We propose that the response selection stage sends attentional feedback signals to earlier pro-cessing levels, forming synaptic tags at those connections responsible for the stimulus-re-sponse mapping. Globally released neuromodulators then interact with tagged synapses to determine their plasticity. The resulting learning rule endows neural networks with the ca-pacity to create new working memory representations of task relevant information as persis-tent activity. It is remarkably generic: it explains how association neurons learn to store task-relevant information for linear as well as non-linear stimulus-response mappings, how they become tuned to category boundaries or <b>analog</b> <b>variables,</b> depending on the task de...|$|R
40|$|AbstractHybrid automata model {{systems with}} both digital and analog components, such as {{embedded}} control programs. Many verification tasks for such {{programs can be}} expressed as reachability problems for hybrid automata. By improving on previous decidability and undecidability results, we identify a boundary between decidability and undecidability for the reachability problem of hybrid automata. On the positive side, we give an (optimal) PSPACE reachability algorithm for the case of initialized rectangular automata, where all <b>analog</b> <b>variables</b> follow independent trajectories within piecewise-linear envelopes and are reinitialized whenever the envelope changes. Our algorithm {{is based on the}} construction of a timed automaton that contains all reachability information about a given initialized rectangular automaton. The translation has practical significance for verification, because it guarantees the termination of symbolic procedures for the reachability analysis of initialized rectangular automata. The translation also preserves theω-languages of initialized rectangular automata with bounded nondeterminism. On the negative side, we show that several slight generalizations of initialized rectangular automata lead to an undecidable reachability problem. In particular, we prove that the reachability problem is undecidable for timed automata augmented with a single stopwatch...|$|R
40|$|An {{automated}} a i r i n f i l t r a t i o {{n measurement}} system f o r large buildings i s described. The system {{consists of a}} micro-computer, electron capture gas chromatograph, a ten po r t sampling manifold, and f i v e tracer gas i n jec t i on units. The system controls the i n jec t i on and sampling o f t racer gas i n a multi-zone building, calculates the a i r i n f i l t r a t i o n rates o f each zone, and measures the on-time o f events such as HVAC fan operation, exhaust fan oper-ation, and door/window openings. The measurements a 1 so i n c l ude such <b>analog</b> <b>variables</b> as i n t e r i o r and exter ior temperatures, wind speed, wind d i rec t ion and pressure d i f f e r e n t i a l s across the bui ld ing envelope. The data col lecte...|$|R
40|$|Abstract. Hybrid automata model {{systems with}} both digital and analog components, such asembedded control {{programs}}. Many veri cation tasks for such {{programs can be}} expressed as reachability problems for hybrid automata. By improving on previous decidability and undecidability results, we identify a boundary between decidability and undecidability for the reachability problem of hybrid automata. On the positive side, we give an (optimal) PSPACE reachability algorithm for the case of initialized rectangular automata, where all <b>analog</b> <b>variables</b> follow independent trajectories within piecewise-linear envelopes and are reinitialized whenever the envelope changes. Our algorithm {{is based on the}} construction of a timed automaton that contains all reachability information about a given initialized rectangular automaton. The translation has practical signi cance for veri cation, because it guarantees the termination of symbolic procedures for the reachability analysis of initialized rectangular automata. The translation also preserves the!-languages of initialized rectangular automata with bounded nondeterminism. On the negative side, weshow that several slight generalizations of initialized rectangular automata lead to an undecidable reachability problem. In particular, we prove that the reachability problem is undecidable for timed automata augmented with a single stopwatch. ...|$|R
40|$|Abstract: - It {{is offered}} to {{implement}} fuzzy devices as multi-valued logic functions, using directly <b>analog</b> input <b>variables</b> and forming the output <b>variables</b> as <b>analog</b> ones as well. It is offered to use CMOS summing amplifiers as basic elements for designing appropriate circuits. It {{has been proved}} that a CMOS summing amplifier is a functionally complete element in arbitrary-valued logic. In a plenty of cases this approach enables principally simplification of fuzzy logic controllers for a broad class of applications. All mentioned above is illustrated by examples...|$|R
40|$|The {{technique}} {{originating from}} the study of ecological systems for the examination of dynamic educational systems over time is utilized. The technique is based on the theory of energy exchanges in interactions between variables, Using this technique, interactions among variables can be specified and simulated over time using an <b>analog</b> computer. <b>Variables</b> can then be examined under controlled conditions. The procedure was found to duplicate known findings from Atkinsongs achievement motivation theory. Over long time periods, changes not hypothesized appear among variables which may have ramifications for empirical research procedures. (Author...|$|R
40|$|AbstractIn {{the present}} paper we {{establish}} some new integral inequalities involving realvalued functions of two independent variables and their partial derivatives. Our results in the special cases yield the two independent <b>variable</b> <b>analogs</b> of the Wirtinger and Opial type inequalities established by the present author and Traple in one independent variable...|$|R
40|$|Abstract — In this paper, the VHDL {{design and}} {{implementation}} of BPSK, BASK and BFSK modulator and demodulator with mixed domain performance analysis under different software are presented. The modulators are widely used in communication system either wired or wireless also the applications of these devices are ranging from personal to industrial. Because the every techniques has their own advantages and disadvantages and hence designer chooses the best depending upon the applications requirement this creates {{the problem for the}} applications with time changing requirements. The design presented in this paper provides a solution for such cases by providing simple programmable interface for switching among different techniques with low power and FPGA resource consumption also the proposed design architecture maintains the simplicity without compromising the performance and through simulation we check that with the considerable gain in signal to noise ratio (SNR) and there is minimization of bit error rate (BER). Final the design is synthesized using Xilinx software and because the performance analysis under application domain which contains several <b>analog</b> <b>variables</b> is not possible with Xilinx the system is also analyzed in Matlab/Simulink software and the measured results shows that the proposed design architecture provides expected results furthermore the analysis results can be used in field for choosing the correct device to properly match the requirements...|$|R
40|$|International audienceA novel <b>analog</b> tuning MEMS <b>variable</b> {{capacitor}} is presented. By {{using an}} inverted-gap configuration, the mechanical effects of large RF-signals can be cancelled. Fabricated devices could handle 250 mW of power, with measured 2. 2 : 1 capacitance variation, very high Q, and extremely low parasitic series inductance up to 10 GHz...|$|R
40|$|We {{present an}} analog VLSI neural network for texture analysis; in {{particular}} {{we show that}} the filtering block, {{which is the most}} critical block of the architecture for precision of computation, can be implemented using simple and compact analog circuits, without significant loss in classification performance. Through an accurate analysis of the circuits it is possible to model the real circuit characteristics in the software simulation environment; the weights calculated in the learning phase (which is performed off-line using the adaptive simulated annealing algorithm), can be properly coded into <b>analog</b> circuit <b>variables</b> in order to implement the correct operation of the networ...|$|R
5000|$|ARP Instruments made a {{multifunction}} {{voltage-controlled filter}} module capable of stable operation at a Q greater than 100; {{it could be}} shock-excited to ring like a vibraphone bar. Q was voltage-controllable, {{in part by a}} panel-mounted control. Its internal circuit was a classic <b>analog</b> computer state <b>variable</b> [...] "loop", which provided outputs in quadrature.|$|R
40|$|Temporal spike codes play {{a crucial}} role in neural {{information}} processing. In particular, there is strong experimental evidence that interspike intervals (ISIs) are used for stimulus representation in neural systems. However, there are very few algorithmic principles that exploit the benefits of such temporal codes for probabilistic inference of stimuli or decisions. Here, we describe and rigorously prove the functional properties of a spike-based processor that uses ISI distributions to perform probabilistic inference. The abstract processor architecture serves as a building block for more concrete, neu-ral implementations of the Belief-Propagation (BP) algorithm in arbitrary graphical models (e. g. Bayesian Networks and Factor Graphs). The distributed nature of graphical models matches well with the architectural and functional constraints imposed by biology. In our model, ISI distributions represent the BP-messages exchanged between factor nodes, leading to the interpretation of a single spike as a random sample that follows such a distribution. We verify the abstract processor model by numerical simulation in full graphs, and demonstrate that it can be applied even in presence of <b>analog</b> <b>variables.</b> As a particular example, we also show results of a concrete, neural implementation of the processor, although in principle our approach is more flexible and allows for different neurobiological interpretations. Furthermore, electrophysiological data from area LIP during behavioral experiments is assessed in the light of ISI coding, leading to concrete testable, quantitative predictions and a more accurate description of these data compared to hitherto existing models...|$|R
