185|1084|Public
5000|$|Customizable data grid, {{with support}} of {{automatic}} generation of columns based on <b>automatically</b> <b>discovered</b> database schema ...|$|E
50|$|CUPS 1.2 {{and later}} provide a revamped web {{interface}} which features improved readability and design, support for <b>automatically</b> <b>discovered</b> printers, {{and a better}} access to system logs and advanced settings.|$|E
5000|$|The {{analysis}} of {{vast quantities of}} historical newspaper content has been pioneered by, which showed how periodic structures can be <b>automatically</b> <b>discovered</b> in historical newspapers. A similar analysis was performed on social media, again revealing strongly periodic structures.|$|E
5000|$|<b>Automatically</b> <b>discovers</b> network {{resources}} {{and changes in}} network configuration ...|$|R
30|$|Use MIH Discovery {{method for}} <b>automatically</b> <b>discovering</b> the target MIH endpoint.|$|R
5000|$|Auto Discovery : The {{software}} <b>automatically</b> <b>discovers</b> hosts or {{network devices}} it is connected to.|$|R
50|$|Some {{systems have}} also <b>automatically</b> <b>discovered</b> power pins in the {{integrated}} circuits, and generate netlists connecting {{them to the}} nearest power pins of the board. If this is done, any special annotations or colors (e.g. white for clock signals or red for power) can be assigned, because these programs have intimate knowledge of the integrated circuit pins.|$|E
50|$|GWT uses or {{supports}} Java, Apache Tomcat (or similar web container), Eclipse IDE, Internet Explorer, and Internationalization and Localization. Java-based GWT RIAs can {{be tested}} using JUnit testing framework and code coverage tools. Because GWT allows compile time verification of images, CSS, and business logic, many common development defects are <b>automatically</b> <b>discovered</b> without need of the manual testing commonly required by RIAs.|$|E
5000|$|The IETF {{has defined}} an {{architecture}} and protocols for acquiring location {{information from a}} LIS. A LIS in the immediate access network is <b>automatically</b> <b>discovered</b> and location information is retrieved using the HELD protocol. [...] Location information can be retrieved directly—known as by value—or the LIS can generate a temporary URI {{that can be used}} to provide location indirectly—known as a location URI.|$|E
5000|$|... c. Tactical radios that <b>automatically</b> <b>discover</b> {{and operate}} in unused {{portions}} {{of the electromagnetic spectrum}} ...|$|R
5000|$|Device-specific Template Generation. Readiness tests <b>automatically</b> <b>discover</b> device {{capabilities}} and user can generate configuration templates based on readiness results ...|$|R
50|$|A key success {{factor in}} {{implementing}} a CMDB {{is the ability}} to <b>automatically</b> <b>discover</b> information about the CI's (auto-discovery) and track changes as they happen.|$|R
50|$|Digital {{humanities}} scholars use computational methods {{either to}} answer existing research questions or to challenge existing theoretical paradigms, generating new questions and pioneering new approaches. One {{goal is to}} systematically integrate computer technology into the activities of humanities scholars, as is done in contemporary empirical social sciences. Yet despite the significant trend in digital humanities towards networked and multimodal forms of knowledge, {{a substantial amount of}} digital humanities focuses on documents and text in ways that differentiate the field's work from digital research in Media studies, Information studies, Communication studies, and Sociology. Another goal of digital humanities is to create scholarship that transcends textual sources. This includes the integration of multimedia, metadata, and dynamic environments (see The Valley of the Shadow project at the University of Virginia, the Vectors Journal of Culture and Technology in a Dynamic Vernacular at University of Southern California, or Digital Pioneers projects at Harvard). A growing number of researchers in digital humanities are using computational methods for the analysis of large cultural data sets such as the Google Books corpus. Examples of such projects were highlighted by the Humanities High Performance Computing competition sponsored by the Office of Digital Humanities in 2008, and also by the Digging Into Data challenge organized in 2009 and 2011 by NEH in collaboration with NSF, and in partnership with JISC in the UK, and SSHRC in Canada. In addition to books, historical newspapers can also be analyzed with big data methods. The analysis of vast quantities of historical newspaper content has showed how periodic structures can be <b>automatically</b> <b>discovered,</b> and a similar analysis was performed on social media. As part of the big data revolution, Gender bias, readability, content similarity, reader preferences, and even mood have been analyzed based on text mining methods over millions of documents and historical documents written in literary Chinese.|$|E
40|$|Real-time detection, tracking, and {{monitoring}} of <b>automatically</b> <b>discovered</b> events {{in social media}} This item was submitted to Loughborough University’s Institutional Repository by the/an author. Citation: OSBORNE, M [...] et al, 2014. Real-time detection, tracking, {{and monitoring}} of <b>automatically</b> <b>discovered</b> events in social media. IN: Proceeding...|$|E
30|$|Various subword unit types (syllable, phone, grapheme, and <b>automatically</b> <b>discovered)</b> were {{investigated}} in [85] {{in the framework}} of lattice- and consensus network-based exact match term detection. Experimental results showed that (1) the <b>automatically</b> <b>discovered</b> units performed the best in isolation, (2) the combination of all the subword unit types for detection fusion significantly outperformed each subword unit type, and (3) fusion of the phone- and grapheme-based systems performed better than each individual system.|$|E
50|$|Mopria Print Service uses mDNS to <b>automatically</b> <b>discover</b> your printer {{through the}} local 802.11 {{wireless}} network. The printer must be either wirelessly {{connected to the}} network router or with an Ethernet cable.|$|R
30|$|Another {{interesting}} line {{of research}} for future work is that of studying how pairwise similarities between countries evolve over time. This could be useful to <b>automatically</b> <b>discover</b> when new relationships arise and when deviations from normal patterns occur.|$|R
25|$|In {{addition}} Boxee Beta {{and later}} has {{the option of}} monitoring Twitter and Facebook news feeds to <b>automatically</b> <b>discover</b> links to videos, Boxee will then add those videos to a watch queue in Boxee {{so they can be}} later viewed.|$|R
40|$|Semantic Web Services (SWS) are {{distributed}} and reusable software components that are described using standard formal languages like SWDL or OWL-S. SWS can be <b>automatically</b> <b>discovered,</b> invoked and combined. Complex applications {{can be built}} combining different Web Services and therefore, it is important t...|$|E
40|$|The ever-growing {{number of}} {{services}} on the WWW provides enormous business opportunities. Services can be <b>automatically</b> <b>discovered</b> and invoked, or even be dynamically composed from more simples ones. Agent technology provides designers with an interaction-oriented way of designing open software systems [3]. In this paper we {{concentrate on the}} problem of dynamic service discovery i...|$|E
40|$|This paper {{presents}} {{a novel approach}} for enhancing the multiple sets of acoustic patterns <b>automatically</b> <b>discovered</b> from a given corpus. In a previous work it was proposed that different HMM configurations (number of states per model, number of distinct models) for the acoustic patterns form a two-dimensional space. Multiple sets of acoustic patterns <b>automatically</b> <b>discovered</b> with the HMM configurations properly located on different points over this two-dimensional space were shown to be complementary to one another, jointly capturing {{the characteristics of the}} given corpus. By representing the given corpus as sequences of acoustic patterns on different HMM sets, the pattern indices in these sequences can be relabeled considering the context consistency across the different sequences. Good improvements were observed in preliminary experiments of pattern spoken term detection (STD) performed on both TIMIT and Mandarin Broadcast News with such enhanced patterns. Comment: Accepted by ICASSP 201...|$|E
50|$|NodeXL {{contains}} {{a library of}} commonly used graph metrics: centrality, clustering coefficient, diameter. NodeXL differentiates between directed and undirected networks. NodeXL implements a variety of community detection algorithms to allow the user to <b>automatically</b> <b>discover</b> clusters in their social networks.|$|R
40|$|Much work in Information Integration and the Semantic Web {{assumes that}} rich {{semantic}} models of sources exist. In practice, {{there is a}} tremendous amount of data on the Web, but it is typically hard to find, has little or no explicit structure, and there is rarely any semantic description of the data. We describe an integrated end-to-end system that can <b>automatically</b> <b>discover</b> web sources, invoke and extract the data from them, and build their semantic models. We describe the challenges in integrating the component technologies into a unified approach to discovering, extracting and modeling new online sources. We evaluate the integrated system in three different domains and demonstrate that it can <b>automatically</b> <b>discover</b> and model new data sources. ...|$|R
40|$|<b>Automatically</b> <b>discovering</b> {{semantic}} links among documents is {{the basis}} of developing advanced applications on large-scale documentary resources. This paper proposes an approach to <b>automatically</b> <b>discover</b> semantic links in a given document set. It has the following advantages: (1) It does not rely on any predefined ontology. (2) The semantic link networks and relevant rules automatically evolve. (3) It can adapt to the update of the adopted techniques. Experiments on document sets of different types (scientific papers and Web pages on Dunhuang culture) and different scales show the proposed approach feasible. The approach can be used to automatically construct semantic overlays on large document sets to support advanced applications like various relation queries on documents...|$|R
40|$|Adaptive {{web sites}} {{automatically}} improve their organization and presentation to satisfy needs of individual web users. Typically, such improvement {{is achieved by}} automatic link generation. AdAgent is our prototype adaptive extension to a web server, which provides web users with <b>automatically</b> <b>discovered</b> recommended links. In this paper we focus on our template-based method for creating adaptive web pages by using extended HTML tags. 1...|$|E
40|$|In {{this paper}} we present an {{approach}} aimed at enriching the Open Information Extraction paradigm with semantic relation ontologization by integrating syntactic and semantic features into its workflow. To achieve this goal, we combine deep syntactic analysis and distributional semantics using a shortest path kernel method and soft clustering. The output {{of our system}} {{is a set of}} <b>automatically</b> <b>discovered</b> and ontologized semantic relations...|$|E
40|$|This thesis {{presents}} {{new methods}} for classification and thematic grouping {{of billions of}} web pages, at scales previously not achievable. This process {{is also known as}} document clustering, where similar documents are automatically associated with clusters that represent various distinct topic. These <b>automatically</b> <b>discovered</b> topics are in turn used to improve search engine performance by only searching the topics that are deemed relevant to particular user queries...|$|E
40|$|Session 1 A: Testing and Characterization of Embedded SoftwareInternational audienceIncreasing {{complexity}} {{in both the}} software and the underlying hardware, and ever tighter time-to-market pressures {{are some of the}} key challenges faced when designing multimedia embedded systems. Optimizing the debugging phase can help to reduce development time significantly. A powerful approach used extensively during this phase is the analysis of execution traces. However, huge trace volumes make manual trace analysis unmanageable. In such situations, Data Mining can help by <b>automatically</b> <b>discovering</b> interesting patterns in large amounts of data. In this paper, we are interested in discovering periodic behaviors in multimedia applications. Therefore, we propose a new pattern mining approach for <b>automatically</b> <b>discovering</b> all periodic patterns occurring in a multimedia application execution trace...|$|R
40|$|In this paper, {{we propose}} a Web service mining {{approach}} to <b>automatically</b> <b>discover</b> pathways from biological entities and processes modeled as Web services. We present a preliminary experiment using Web service models of entities such as COX and Aspirin {{to illustrate the}} effectiveness of this mining approach...|$|R
50|$|In 2014, ScienceLogic {{introduced}} CloudMapper which <b>automatically</b> <b>discovers</b> {{and maps}} {{the relationships between}} IT assets in public cloud services, such as AWS, {{as well as on}} the customers own premises in a hybrid IT environment. This dependency mapping enables customers to identify non-performing assets in both environments.|$|R
40|$|This article {{presents}} a novel Chinese class n-gram model for contextual postprocessing of handwriting recognition results. The word classcs in the modcl are <b>automatically</b> <b>discovered</b> by a corpus-based simn latcd annealing procedure. Three other language models, least-word, wordfreqnency, and the powerlift interword character bigram model, have been constrncted for comparison. Extensive cxperiments on large text corpora {{show that the}} discovered class bigram model outperforms the other three competing modcl...|$|E
40|$|The paper {{presents}} the results of experiments of usage of LSA for analysis of textual data. The method is explained in brief and special attention is pointed on its potential for comparison and investigation of German literature texts. Two hypotheses are tested: 1) the texts by the same author are alike and can be distinguished from the ones by different person; 2) the prose and poetry can be <b>automatically</b> <b>discovered...</b>|$|E
40|$|This paper {{presents}} {{a new approach}} for unsupervised Spoken Term Detection with spoken queries using multiple sets of acoustic patterns <b>automatically</b> <b>discovered</b> from the target corpus. The different pattern HMM configurations(number of states per model, number of distinct models, number of Gaussians per state) form a three-dimensional model granularity space. Different sets of acoustic patterns <b>automatically</b> <b>discovered</b> on different points properly distributed over this three-dimensional space are complementary to one another, thus can jointly capture {{the characteristics of the}} spoken terms. By representing the spoken content and spoken query as sequences of acoustic patterns, a series of approaches for matching the pattern index sequences while considering the signal variations are developed. In this way, not only the on-line computation load can be reduced, but the signal distributions caused by different speakers and acoustic conditions can be reasonably taken care of. The results indicate that this approach significantly outperformed the unsupervised feature-based DTW baseline by 16. 16 % in mean average precision on the TIMIT corpus. Comment: Accepted by ICASSP 201...|$|E
50|$|Codex uses {{statistical}} linting to find poorly written code, or code {{which is}} syntactically different from well written code, and warn the user, pattern annotation to <b>automatically</b> <b>discover</b> common programming idioms and annotate them with metadata using crowdsourcing, and library generation {{to construct a}} utility package that encapsulates emergent software practice.|$|R
40|$|This paper {{describes}} a categorized thresholding strategy to <b>automatically</b> <b>discover</b> the optimal thresholds during requirements tracing process. An objective function is proposed {{as a critical}} measurement in evaluating the performance of thresholding methods. Also, this paper reports early experimental results for this strategy and illustrates its satisfying performance over training dataset...|$|R
50|$|The {{component}} WSDMON in Windows 7 {{and later}} uses WS-Discovery to <b>automatically</b> <b>discover</b> WSD-enabled network printers, which show in Network in Windows Explorer, {{and can be}} installed by double-clicking on them. In Windows 8 or later installation is automatic. WS-Discovery is enabled by default in networked HP printers since circa 2008.|$|R
