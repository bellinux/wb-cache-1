10|69|Public
2500|$|Public outrage was {{concentrated}} in Twitter and Facebook, where the hashtags [...] and #Danielgate {{were used to}} denounce the monarch's decision. Several <b>automated</b> <b>bot</b> accounts flooded these hashtags with tweets which repeated excerpts from the official communiqué of Mohammed VI. A number of these bot accounts were used {{a few months earlier}} to promote Mounir Majidi's case in a lawsuit he filed in Paris against Moroccan independent journalist Ahmed Benchemsi.|$|E
5000|$|... limit free speech: {{important}} messages can {{be pushed}} out of sight by a deluge of <b>automated</b> <b>bot</b> messages ...|$|E
5000|$|In August 2005 the Italian Wikipedia overtook the Spanish and Portuguese {{language}} editions, {{becoming the}} 8th largest edition by article count. The {{primary reason for}} the rapid leap from 56,000 to 64,000 articles was an <b>automated</b> <b>bot</b> which created stub articles on more than 8,000 municipalities of Spain in an operation dubbed [...] "Comuni spagnoli".|$|E
50|$|In early February 2015 an Internet bot that Long {{developed}} to intelligently automate the Tinder dating app went viral worldwide. The project, named Tinderbox, was more intelligent than previous attempts to build <b>automated</b> <b>bots</b> on Tinder since it used the Eigenfaces algorithm and machine learning techniques to learn who Long found attractive. Additionally, the <b>bot</b> <b>automated</b> chats to help filter conversations {{of interest and}} determine which Tinder matches were truly interested.|$|R
50|$|The Google AI Challenge was a bi-annual online contest {{organized}} by the University of Waterloo Computer Science Club and sponsored by Google that ran from 2009 to 2011. Each year a game was chosen and contestants submitted specialized <b>automated</b> <b>bots</b> to play against other competing bots.|$|R
50|$|Programmers have {{developed}} various browser extensions and scripts designed {{to simplify the}} process of completing jobs. According to the Amazon Web Services Blog, however, Amazon appears to disapprove {{of the ones that}} completely automate the process and preclude the human element. Accounts using so-called <b>automated</b> <b>bots</b> have been banned. There are services that extend the capabilities to MTurk.|$|R
5000|$|Public outrage was {{concentrated}} in Twitter and Facebook, where the hashtags [...] and #Danielgate {{were used to}} denounce the monarch's decision. Several <b>automated</b> <b>bot</b> accounts flooded these hashtags with tweets which repeated excerpts from the official communiqué of Mohammed VI. A number of these bot accounts were used {{a few months earlier}} to promote Mounir Majidi's case in a lawsuit he filed in Paris against Moroccan independent journalist Ahmed Benchemsi.|$|E
5000|$|Google {{is testing}} the User-Agent (Browser type) of HTTP {{requests}} and serves a different page {{depending on the}} User-Agent. Google is automatically rejecting User-Agents that seem to originate from a possible <b>automated</b> <b>bot.</b> of the Google error page: Please see Google's Terms of Service posted at [...] A typical example would be using the command line browser cURL, Google will directly reject to serve any pages to it while Bing {{is a bit more}} forgiving, Bing does not seem to care about User-Agents.|$|E
5000|$|Serdar Argic - alias used {{in one of}} {{the first}} {{automated}} newsgroup spam incidents on Usenet, with the objective of denying the Armenian Genocide, it was an <b>automated</b> <b>bot</b> that made thousands of posts to several newsgroups (especially [...] "soc.history", [...] "soc.culture.turkish", and [...] "misc.headlines") in 1994. The deluge of posts suddenly disappeared in April, 1994, after Stefan Chakerian created a specific newsgroup ("alt.cancel.bots") to carry only cancel messages specifically for any post from any machine downstream from the UUNET feed which carried Serdar Argic's messages.|$|E
5000|$|The {{organization}} is active on social media, most notably Twitter. It runs an isolated cluster of apparently [...] "full-time activists" [...] and spambots, which interact only with each other. The cluster makes efforts to position {{itself as an}} organisation of human rights defenders. However, these efforts are rarely reciprocated, signaling their insularity. According to digital research by the UK-based Small Media Foundation, the cluster's [...] "dependence on <b>automated</b> <b>bots</b> to disseminate information demonstrates that although the MEK is taking social media sites seriously as a platform for broadcasting news and propaganda, they lack the supporter network necessary to make a significant impact within the Iranian Twittersphere. As a result, the MEK is making use of <b>automated</b> <b>bots</b> to artificially inflate its follower count, and create an illusion of influence amongst Iranian Twitter users". National Council of Resistance of Iran, Mohajedin.org, Maryam-Rajavi.com,Hambastegi Meli, Iran News Update and Iran Efshagari are among accounts openly affiliated with the group.|$|R
50|$|Internet Relay Chat {{services}} (usually called IRC services) is a {{name for}} a set of features implemented on many modern Internet Relay Chat networks. Services are <b>automated</b> <b>bots</b> with special status which are generally used to provide users with access with certain privileges and protection. They usually implement some sort of login system so that only people on the access control list can obtain these services.|$|R
30|$|This {{model is}} also highly {{relevant}} to security. For example, cyberstalkers {{might be interested}} in spreading rumors, gossips, news, or pictures through social networks to damage their victims’ (e.g., celebrity, political party, company, or country) reputation. The same model works in social media campaign where spammers and propagandists want to share their advertisements on online social networks; fake accounts with <b>automated</b> <b>bots</b> are often used to amplify advertising campaigns in social media [3 - 5].|$|R
5000|$|The use {{of social}} bots and chatbots {{has created an}} {{analytical}} crisis in the marketing industry. Companies use social and chat bots to automate their social marketing that appears to consumers and other companies to be real interaction. The ability for bots to mimic human interaction {{makes it difficult for}} marketers and data analysts to differentiate between human interactions and <b>automated</b> <b>bot</b> interactions; having implications for quality of data. Companies continue to use bots to automate their social media interactions although the same bots are negatively affecting their marketing data causing a [...] "digital cannibalism" [...] in social media marketing. Additionally, bots violate the terms of use on many social mediums such as Instagram. This can result in profiles being taken down and banned.|$|E
40|$|In {{this paper}} we propose to built anE-Voting system which is {{basically}} an online voting system through which people can cast their vote through their smart phones or by using an e-voting website. To maintain the security we are using Captcha code. CAPTCHA stands for Completely Automated public Turing test to tell Computers and Humans Apart. This technology is used most commonly on the web {{to tell the difference}} between a human using a web service and an <b>automated</b> <b>bot</b> thus making the website more secure against spam-bot attacks...|$|E
40|$|Abstract CAPTCHAs are {{security}} tests {{designed to}} allow users to easily identify themselves as humans; however, as research shows (Bursztein et al. 2010) these test aren’t necessarily easy for humans to pass. As a result a new test, which requests users to identify images of real humans among those of 3 D virtual avatars, is proposed that would create a potentially unsolvable obstacle for computers and a quick, easy verification for humans. In order to provide test cases for this new test, an <b>automated</b> <b>bot</b> is used to collect images of 3 D avatars from Evolver. com...|$|E
50|$|Detecting {{non-human}} Twitter users {{has been}} of interests to academics. Indiana University has developed a BotOrNot free service, which scores Twitter handles based on their likelihood of being a Twitterbot. One significant academic study estimated that up to 15% of Twitter users were accounts <b>automated</b> <b>bots.</b> The prevalence of Twitter Bots coupled with the ability of some bots to give seemingly human responses has enabled these non-human accounts to garner widespread influence.|$|R
40|$|AbstractCaptcha is {{stands for}} Completely Automated Public Turing test to tell Computer and Human Apart. As the {{increase}} of <b>automated</b> <b>bots</b> systems or software that misuse and corrupt the public web services, the user must required going through and solving a Turing test problem, before they are use web services. This Turing test is called Captcha. In this paper we have discuss an improved text-based captcha which is more secure, and more robust as compared to another Captchas...|$|R
5000|$|The {{process of}} {{entering}} a website and extracting data in an automated fashion is also often called [...] "crawling". Search engines like Google, Bing or Yahoo are getting almost all their data from <b>automated</b> crawling <b>bots.</b>|$|R
40|$|CAPTCHA – Completely Automated Public Turing test to tell Computer and Humans Apart, CAPTCHAs, on web {{employed}} as automated filters to distinguish humans and automated bots to prevent fraud and vandalistic {{activities such as}} spamming, automated bot-based account creation and corrupting websites by reducing the availability of site resources to legitimate users. At the moment, Captcha such as Text or image based, Math, and Audio have been broken accurately by bots and proven as less robust. Up recent, to address <b>automated</b> <b>bot</b> fraud activities and attacks a more robust CAPTCHA introduced called Video CAPTCHA. The Video Captcha is a captcha with moving letters and challenge will be given as to enter only few letters with specified color (for example enter only red color letters from moving letters) from moving letters. That means, breaking...|$|E
40|$|The Completely Automated Public Turing test to tell Computers and Humans Apart (CAPTCHA) is used {{to believe}} that a human is using the web service [1]. For the online {{services}} which are been provided in web services is been abused by <b>automated</b> <b>bots</b> over the internet. So CAPTCHA is used as a protection from these malicious programs for web security. But the bots are intelligent enough to break through these CAPTCHA. To increase the security, there are several CAPTCHA techniques has been proposed. In this paper various types of CAPTCHA techniques has been discussed and more secure techniques for the bot protection were discussed...|$|R
40|$|Abstract—With {{the growing}} {{popularity}} of massive multiplayer online games (MMOG), the demand to protect these games and especially the participating players is increasing likewise. In this paper, we discuss a sequence-based solution to protect online games from being exploited by fully <b>automated</b> <b>bots.</b> Our research is based on various commercial and non-commercial bot implementations for the renowned game World of Warcraft. Our evaluation suggests, that a sequence-based detection technique is applicable even for mildly skilled players and effectively protects online games from a negative impact on game economics that causes both, grief to casual gamers and destroys game balance. Our implementation is fit to be deployed on either client- or server side, posing the first player-usable bot detection tool for World of Warcraft. I...|$|R
40|$|Abstract. Captchas are {{challenge-response}} tests {{used in many}} online {{systems to}} prevent attacks by <b>automated</b> <b>bots.</b> Avatar Captchas are a recently-proposed variant in which users are asked to classify between human faces and computer-generated avatar faces, and {{have been shown to}} be secure if bots employ random guessing. We test a variety of modern object recognition and machine learning approaches on the problem of avatar versus human face classification. Our results show that using these techniques, a bot can successfully solve Avatar Captchas as often as humans can. These experiments suggest that this high performance is caused more by biases in the facial datasets used by Avatar Captchas and not by a fundamental flaw in the concept itself, but nevertheless our results highlight the difficulty in creating Captcha tasks that are immune to automatic solution. ...|$|R
40|$|AbstractWith the {{expansion}} of Web services, denial of service (DoS) attacks by malicious automated programs (e. g., web bots) is becoming a serious problem of web service accounts. CAPTCHA (Completely Automated Public Turing test to tell Computers and Humans Apart) is a human authentication mechanism that generates and grades tests {{to determine whether the}} user is a human or a malicious computer program. These tests are easier for humans to solve and tough for <b>automated</b> <b>bots.</b> We present a novel video CAPTCHA technique based on advertisement recognition. Our CAPTCHA provides a video which contains a predefined advertisement. The user has to identify the product that relates with the advertisement presented in the video by selecting the multiple choice options provided. If the user chooses the right option we can guess that the user is a human and not a bot...|$|R
40|$|Part 5 : Security Management and Human Aspects of SecurityInternational audienceText based CAPTCHAs are the {{de facto}} method of choice to ensure that humans (rather than <b>automated</b> <b>bots)</b> are {{interacting}} with websites. Unfortunately, users often find it inconvenient to read characters and type them in. Image CAPTCHAs provide an alternative that is often preferred to text-based implementations. However, Image CAPTCHAs have their own set of security and usability problems. A key issue is their susceptibility to Reverse Image Search (RIS) and Computer Vision (CV) attacks. In this paper, we present a generalized methodology to transform existing images by applying various noise generation algorithms into variants that are resilient to such attacks. To evaluate the usability/security tradeoff, we conduct a user study {{to determine if the}} method can provide “usable” images that meet our security requirements – thus improving the overall security provided by Image CAPTCHAs...|$|R
40|$|Abstract—Captchas are {{frequently}} {{used on the}} modern world wide web to differentiate human users from <b>automated</b> <b>bots</b> by giving tests that are easy for humans to answer but difficult or impossible for algorithms. As artificial intelligence algorithms have improved, new types of Captchas {{have had to be}} developed. Recent work has proposed a new system called Avatar Captcha, in which a user is asked to distinguish between facial images of real humans and those of avatars generated by computer graphics. This novel system has been proposed on the assumption that this Captcha is very difficult for computers to break. In this paper we test a variety of modern visual features and learning algorithms on this avatar recognition task. We find that relatively simple techniques can perform very well on this task, and in some cases can even surpass human performance. Keywords-Avatar Captcha; defeating Captchas; face recog-nition; GIST; HOG I...|$|R
5000|$|Child {{exploitation}} is prominent on Kik Messenger, causing {{law enforcement}} and the media to frequently express concerns about the app. <b>Automated</b> spam <b>bots</b> have also been used to distribute explicit images and text over Kik Messenger. A state law enforcement official interviewed by The New York Times in February 2016 identified Kik as [...] "the problem app of the moment".|$|R
40|$|Automated Social Engineering (ASE) is {{how social}} {{networking}} sites (SNSs) are exploited for Social Engineering by <b>automated</b> <b>bots.</b> Classical social engineering is {{an attack on the}} security of systems, based on exploiting human factors. ASE is an automated form of traditional social engineering which makes use of bots to attack SNS. One such bot is KOOBFACE [1] that infected Facebook for a long time until it was detected in mid of 2011 by Sophos lab. ASE bots can be developed easily using open source web automation and web scrapping tools. These tools combined with appropriate chat logic with enhanced intelligence pose a great threat to the security of SNSs. Countermeasures like Captchas have proved ineffective in preventing bots from infiltrating SNS’s. New techniques like Multi Modal Captchas (MMC), and Fast Flux Network (FFN) detection are the future of the ASE prevention. In this paper we present a survey of vulnerabilities, threats and propose some countermeasures fo...|$|R
40|$|Abstract: Bots are {{programs}} that crawl through {{the web site}} and make auto registrations. CAPTCHAs, using Latin script, are widely used to prevent <b>automated</b> <b>bots</b> from abusing online services on the World Wide Web. However, many of the existing English based CAPTCHAs have some inherent problems and cannot assure the security of these websites. This paper proposes a method {{that focuses on the}} use of Arabic script in the generation of CAPTCHA. The proposed scheme uses specific Arabic font types in CAPTCHA generation. Such CAPTCHA exploits the limitations of Arabic OCRs in reading Arabic text. The proposed scheme is beneficial in Arabic speaking countries and is very useful in protecting internet resources. A survey has been conducted to find the usability of the scheme, which was satisfactory. In addition, experiments were carried out to find the robustness of the scheme against OCR. The results were encouraging. Moreover, a comparative study of our CAPTCHA and Persian CAPTCHA scheme shows its advancement over Persian CAPTCHA...|$|R
40|$|This paper aims to {{contribute}} to recent innovations in social scientific methodology that aspire to address the complex, iterative and performative dimensions of method. In particular, {{we focus on the}} becoming-with character of social events, and propose a speculative method for engaging with the not-as-yet. This work, being part of a larger project that uses Speculative Design and ethnographic methods to explore energy-demand reduction, specifically considers the ways in which energy-demand reduction features in the Twitter-sphere. Developing and deploying three <b>automated</b> <b>Bots</b> whose function and communications are at best obscure, and not uncommonly nonsensical, we trace some of ways in which they intervene and provoke. Heuristically, we draw on the ‘conceptual characters’ of idiot, parasite and diplomat in order to grasp how the Bots act within Twitter to evoke the instability and emergent eventuations of energy-demand reduction, community and related practices. We conclude by drawing out some of the wider implications of this particular enactment of speculative method...|$|R
5000|$|As {{an online}} {{encyclopedia}} which almost anyone can edit, Wikipedia {{has long had}} problems with vandalism of articles, which range from [...] "blanking" [...] articles to inserting profanities, hoaxes or nonsense. Wikipedia has a range of tools available to users and administrators in order to fight against vandalism, including blocking and banning of vandals and <b>automated</b> <b>bots</b> that detect and repair vandalism. Supporters of the project argue {{that the vast majority}} of vandalism on Wikipedia is reverted within a short time, and a study by Fernanda Viégas of the MIT Media Lab and Martin Wattenberg and Kushal Dave of IBM Research found that most vandal edits were reverted within around five minutes; however they state that [...] "it is essentially impossible to find a crisp definition of vandalism". While most instances of page blanking or the addition of offensive material are soon reverted, less obvious vandalism, or vandalism to a little viewed article, has remained for longer periods.|$|R
5000|$|No {{previous}} government petition {{had attracted}} as many signatures, {{but it was}} reported that the House of Commons Petitions Committee were investigating allegations of fraud. Chair of that committee, Helen Jones, said that the allegations were being taken seriously, and any signatures found to be fraudulent would be removed from the petition: [...] "People adding fraudulent signatures to this petition should know that they undermine the cause they pretend to support." [...] By the afternoon of 26 June the House of Commons' petitions committee said that it had removed [...] "about 77,000 signatures which were added fraudulently" [...] and that it would continue to monitor the petition for [...] "suspicious activity"; almost 40,000 signatures seemed to have come from the Vatican City, which has a population of under 1,000. Hackers from 4chan claimed that they had added the signatures with the use of <b>automated</b> <b>bots,</b> and that it was done as a prank.|$|R
40|$|The {{popularity}} of social media platforms such as Twitter {{has led to}} the proliferation of <b>automated</b> <b>bots,</b> creating both opportunities and challenges in information dissemination, user engagements, and quality of services. Past works on profiling bots had been focused largely on malicious bots, with the assumption that these bots should be removed. In this work, however, we find many bots that are benign, and propose a new, broader categorization of bots based on their behaviors. This includes broadcast, consumption, and spam bots. To facilitate comprehensive analyses of bots and how they compare to human accounts, we develop a systematic profiling framework that includes a rich set of features and classifier bank. We conduct extensive experiments to evaluate the performances of different classifiers under varying time windows, identify the key features of bots, and infer about bots in a larger Twitter population. Our analysis encompasses more than 159 K bot and human (non-bot) accounts in Twitter. The results provide interesting insights on the behavioral traits of both benign and malicious bot...|$|R
50|$|In Deus Ex, {{the player}} {{is able to}} {{activate}} an invisibility cloak, which is effective against human NPCs. There is also a cloak which diverts microwaves, rendering the player invisible to cameras, <b>automated</b> turrets and <b>bots.</b>|$|R
5000|$|As email spam filters {{became more}} effective, {{catching}} over 95% of these messages, spammers {{have moved to}} a new target - the social web. [...] Over 90% of social network users have experienced social spam in some form. Those doing the “spamming” can be <b>automated</b> spambots/social <b>bots,</b> fake accounts, or real people. Social spammers often capitalize on breaking news stories to plant malicious links or dominate the comment sections of websites with disruptive or offensive content.|$|R
5000|$|The same venues that fomented {{the false}} Pizzagate {{conspiracy}} theory helped to promulgate the Seth Rich murder conspiracy theories, and each shared similar features. Both were promoted by individuals subscribing to far-right politics, and by campaign officials and individuals appointed to senior-level national security roles by Donald Trump. After prior coordination on Facebook, each theory was spread on Twitter by <b>automated</b> <b>bots</b> using a branded hashtag, {{with the goal}} of becoming a trending topic. Both the Pizzagate conspiracy theory and the Seth Rich murder conspiracy theory were spread in the sub reddit forum promoting Donald Trump, called [...] "The Donald". In both conspiracy theories, the promoters attempted to shift the burden of proof [...] - [...] asking others to attempt to disprove their claims, without citing substantiated evidence. Slate called the claims about Seth Rich a [...] "PizzaGate-like conspiracy theory surrounding Rich’s death", The Huffington Post described it as [...] "the 'alt-right' idiocy of Pizzagate all over again", NPR's David Folkenflik said Fox News coverage of it [...] "evokes the pizza-gate terrible allegations utterly unfounded", and Margaret Sullivan wrote for The Washington Post: [...] "The Seth Rich lie has become the new Comet Ping Pong ... Crazy, baseless and dangerous." ...|$|R
40|$|Abstract — Nowadays, due to {{enormous}} {{growth of}} web users many {{services in the}} internet including Email, search engine, social networking are provided with free of charge. With the expansion of Web services, denial of service (DoS) attacks by malicious automated programs (e. g., web bots) is becoming a serious problem of web service accounts. CAPTCHA (Completely Automated Public Turing test to tell Computers and Humans Apart) is a human authentication mechanism that generates and grades tests {{to determine whether the}} user is a human or a malicious computer program. These tests are easier for humans to solve and tough for <b>automated</b> <b>bots.</b> According to our study, the existing CAPTCHA techniques tried to maximize the difficulty for automated programs to pass tests by increasing distortion or noise. Consequently, it has also become difficult for humans too. In our proposed solution, we try to make use of human cognitive processing abilities into our CAPTCHA design. The suggested approach move and select is a 2 -layer test, desired to improve security and reduce the solving time of human. In the result section we have studied both the usability and security issues of our design. The user studies indicate that this CAPTCHA can be solved with 99. 04 % average success rate in less than 10 seconds...|$|R
