0|10|Public
5000|$|In 1984, he {{introduced}} a telephone branching technology that recorded voice interactive messaging system, a process where callers hear menu options provided by an automated <b>telephone</b> <b>attendant</b> when a business is reached. The technology is officially called [...] "automated phone menus" [...] or [...] "telephone branching." ...|$|R
50|$|Fonix speech {{recognition}} technologies are currently available for many major products and systems, including Microsoft Xbox and Xbox 360, Sony PlayStation 2, PlayStation 3, PC, Seiko Epson semiconductor chips, Pocket PC and smartphone devices, and others. Casio and other Asian manufacturers currently offer several handheld electronic dictionaries featuring Fonix text-to-speech. Many mid-sized businesses use Fonix’s telephony product as a 24-hour {{speech recognition}} <b>telephone</b> <b>attendant.</b>|$|R
5000|$|While he was {{studying}} he served as <b>telephone</b> <b>attendant</b> and then Seminar Incharge in Department of Sociology, University of Sindh about one year. In 1989 he was appointed in Sindhi Adabi Board as Sub Editor of quarterly Mehran. He worked {{as secretary of the}} board for limited time. Later on he had also worked as editor of [...] "Gul Phul" [...] a monthly magazine for children.|$|R
5|$|Charles Lloyd {{was born}} on 2 February 1899 at South Fremantle, Western Australia, the second and only {{surviving}} child of Thomas Edward Lloyd, a postmaster, and his wife Edith, née Lock. His parents separated in 1901 {{and two years later}} his father committed suicide. He was subsequently raised by his mother who worked as a <b>telephone</b> <b>attendant</b> at Coolgardie, and then in Fremantle from 1909. Lloyd was educated at Beaconsfield, Fremantle Boys' Central and Perth Modern schools.|$|R
5000|$|In larger hotels, night {{auditors}} {{may work}} alongside other nighttime employees {{such as the}} night manager, the hotel security guards, <b>telephone</b> <b>attendants,</b> room service attendants, and bellhops. In smaller hotels and motels, the night auditor may work alone, and may even only be [...] "on-call", meaning that once he or she completes running the daily reports, the auditor retires to an area away from the desk while remaining available to attend to unexpected requests from guests.|$|R
6000|$|He reached Brown's {{at twenty}} minutes past two {{and left it}} again at twenty-three minutes past; for, {{directly}} he entered, the hall porter had handed him a telephone message. The <b>telephone</b> <b>attendants</b> at London clubs are masters of suggestive brevity. The one {{in the basement of}} Brown's had written on Bill's slip of paper the words: '1 p.m. Will Lord Dawlish as soon as possible call upon Mr Gerald Nichols at his office?' To this was appended a message consisting of two words: 'Good news.' ...|$|R
25|$|The {{original}} {{communication between}} diver and attendant was by pulls on the diver's lifeline. Later a speaking tube system was tried, {{but it was}} not very successful. A small number were made by Seibe-Gorman, but the telephone system was introduced soon after this and since it worked better and was safer, the speaking tube was soon obsolete, and most helmets which had them were returned to the factory and converted. In the early 20th century electrical telephone systems were developed which improved the quality of voice communication. These used wires incorporated into the lifeline or air line, and used either headsets worn inside the helmet or speakers mounted inside the helmet. The microphone could be mounted {{in the front of the}} helmet or a contact throat-microphone could be used. At first it was only possible for the diver to talk to the surface telephonist, but later double telephone systems were introduced which allowed two-divers to speak directly to each other, while being monitored by the <b>attendant.</b> Diver <b>telephones</b> were manufactured by Siebe-Gorman, Heinke, Rene Piel, Morse, Eriksson, Draeger and others. This system was well-established by the mid-20th century, and has been technologically improved, but is still in common use for surface-supplied divers using lightweight demand helmets and full-face masks.|$|R
40|$|Zhang X., ''Rapid {{speaker and}} {{environment}} adaptation in {{automatic speech recognition}} - Part I: Parametric normalization; Part II: Latent variable approaches'', Proefschrift voorgedragen tot het behalen van het doctoraat in de ingenieurswetenschappen, KU Leuven, September 2014, Leuven, Belgium. The progress made in automatic speech recognition (ASR) during thelast few decades has allowed ASR techniques to be introduced intovarious application fields. With the growing use of ASR in fields such asintelligent voice driven personal assistants in smart phones, query by voice automatic <b>telephone</b> <b>attendants,</b> or voice driven user interfaces like those used in car navigation systems, the requirements {{for the performance of}} speech recognition systems have also increased. One of the demands of ASR systems is robustness against variability present in the speech signal. Different from speech recognition by humans, the performance of an ASR system degrades more severely when there are variability in the speech signal. Two of the main variability in the speech signal that deteriorate the performance of an ASR system are environmental variability and speaker variability. In this thesis, we focus on compensating for the variability caused by these two main factors. Additive background noise causes mismatches between the distributionsthat the automatic speech recognition system learned from the trainingdata and the distribution of the test data feature vectors. To compensatefor the variability introduced by additive background noise, we proposea parametric histogram equalization (pHEQ) algorithm which maps thedistributions of the feature vectors of both the training and testing datato a common target distribution. A unique property of the proposedmapping is that the noise in the input signal is tracked, allowing thenoise distribution observed in the input signal to be mapped to its ownnormalized distribution located at a fixed number of decibels below thetarget speech distribution. In other words, the pHEQ algorithm triesto normalize both the noise distribution and the speech distributionwhile maintaining a fixed distance between the two distributions. As aresult, the signal-to-noise ratio (SNR) of clean speech (e. g. the trainingdata) will be lowered by injecting extra noise, a process called noisemasking. When facing noisy speech on the other hand (e. g. the testdata), the algorithm will transform the data to reach a target SNR. Anoise power spectrum tracking algorithm allows the pHEQ algorithm toestimate and map the noise distribution even when facing non-stationarynoise. By applying pHEQ both during training and testing, the algorithmeffectively compensates for non-linear distortions in the speech featurevectors introduced by additive noise. The second main factor which deteriorates the performance of anautomatic speech recognition system is speaker variability. Speakervariability is caused by the differences among speaker characteristics,for example gender, age or dialect region the person grew up in. Theproposed algorithm handles speaker variability by adjusting the acousticmodel. More specifically, our model-based algorithm adjusts the stateemission density functionsGaussian mixture models (GMMs) in a hidden Markov model (HMM)  to better fit the observations of a target speaker. Unique to our method is that the speaker independent (SI) Gaussianmixture weights are adapted towards speaker-dependent (SD) weights. By expressing the SD weights as a linear combination of a set of latent speaker vectors, the Gaussian mixture weights can be adapted rapidly, given limited amounts of adaptation or enrollment data. Non-negative matrix factorization (NMF) is used to estimate the latent speaker vectors. The NMF-based weight adaptation technique can be combined with existing mean (and variance) based speaker adaptation techniques, for example, speaker adaptive training (SAT) and eigenvoice speaker adaptation, to further improve the state emission probabilities by adapting both the Gaussian mixture weights and means (and variances). Replacing the non-negative matrix factorization by an non-negative tensordecomposition allows the adaptation of the Gaussian mixture weights tocompensate for both speaker and noise variability. Since weight-basedspeaker adaptation was already shown to work, the experiment focused on compensating the noise variability by estimating noise-dependent (ND) mixture weights in the model-space. Considering the non-stationarity ofthe noise, a set of Gaussian mixture weights is estimated for each frameduring evaluation. The proposed techniques are evaluated and analyzed on large vocabularycontinuous speech recognition benchmark tasks: the Wall Street Journal(WSJ) benchmark and the Aurora 4 benchmark. The Aurora 4 task wasconstructed by artificially adding different types of noise with differentsignal-to-noise ratios (SNRs) to the clean WSJ database. The result showthat the proposed algorithms can significantly improve the performanceof ASR systems. status: publishe...|$|R

