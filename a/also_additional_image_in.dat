0|10000|Public
2500|$|For the July 2014 {{issue of}} S-Pop magazine, two {{different}} covers were published with the lead actors of [...] "Pleasantly Surprised" [...] on the cover. Both covers has Jasper Liu and Puff Kuo in couple poses with different outfits. One is the regular newsstand edition {{and the other}} is a limited special edition that includes one out of four random poly folders with drama promotional images. The limited special edition <b>also</b> contains <b>additional</b> <b>images</b> not published <b>in</b> the regular version.|$|R
40|$|The {{appendix}} provides {{further details}} about the results of Prec refinement cycles, the effect of <b>additional</b> <b>images</b> <b>in</b> conventional reconstructions on the Ewald sphere resolution limit, and a comparison of Ewald sphere resolution limit predictions with reconstructions from simulated data {{in the first three}} sections. This information could no...|$|R
40|$|Herbert Brown at Board of Regents awards ceremony. <b>Additional</b> <b>images</b> <b>in</b> folder; In Verso: Bd. {{of regents}} awards presentation- 81 -F 1 - 5. Louis L. Kaplan-Interim Chancellor UMBC 1976 -B. Herbert Brown-Chrman. Bd. of Regents (Brown, l., kaplan r.); Eugene E Watts Scholarship Award by Members of Local # 130 of the AFL CLO to Student Mardel AMn MIller (PRess Release # 1335...|$|R
5000|$|The {{sculptures of}} Drora Domini as well {{dealt with the}} {{construction}} and deconstruction of structures with a domestic connection. Many of them featured disassembled images of furniture. The abstract structures she built, on a relatively small scale, contained absurd connections between them. Towards {{the end of the}} decade Domini began to combine <b>additional</b> <b>images</b> <b>in</b> her works from compositions in the [...] "ars poetica" [...] style.|$|R
40|$|Portrait of Dr. Louis L. Kaplan and Herbert Brown, {{chairman}} or Board of Regents, at Board of Regents awards ceremony. <b>Additional</b> <b>images</b> <b>in</b> folder; In Verso: Bd. {{of regents}} awards presentation- 81 -F 1 - 5. Louis L. Kaplan-Interim Chancellor UMBC 1976 -B. Herbert Brown-Chrman. Bd. of Regents (Brown, l., kaplan r.); Eugene E Watts Scholarship Award by Members of Local # 130 of the AFL CLO to Student Mardel AMn MIller (PRess Release # 1335...|$|R
40|$|Description {{based on}} t. p. screen of 2007 - 11 - 05. "This {{electronic}} book contains the following additional features {{not available in}} the print version: 19 <b>additional</b> <b>images</b> (5 <b>in</b> color), transcriptions of film scripts and poems, 17 samples of scanned script pages, 6 film clips. " [...] Copyright and Permissions. Electronic access restricted; authentication may be required...|$|R
40|$|The Lindley & Warren {{photographs}} are albumen prints of buildings in India's Gujarat region. The Lindley & Warren {{photographs are}} albumen prints of buildings in India's Gujarat region. Mode of access: Internet. List of <b>additional</b> <b>images</b> available <b>in</b> the repository. Sloan candidatetransferred from Library, 87 -B 5205 Repository's copy extra-illustrated {{with an additional}} 19 albumen photographs that are pasted to the versos of the host volume's plates...|$|R
50|$|In 1909, {{two more}} of his gravures were {{published}} in Camera Work, No. 25 (January). In 1910, twenty-seven of his photographs were exhibited at a major exhibition in Buffalo, New York. The catalog for this show described Eugene as the first photographer to make successful platinum prints on Japan tissue. Ten {{more of his}} gravures published in Camera Work, No.30 (April), and fourteen <b>additional</b> <b>images</b> appear <b>in</b> No.31 (July).|$|R
5|$|Final Fantasy VIII Original Soundtrack is a {{soundtrack of}} the music from Final Fantasy VIII; {{composed}} and produced by Nobuo Uematsu. The soundtrack spans four discs and 74 tracks, covering a duration of 4 hours and 9 minutes. It was first published by DigiCube on March 10, 1999 with the catalog number SSCX-10028, and subsequently published by Square Enix on May 10, 2004 with the catalog numbers SQEX-10005~8. Unlike most other Final Fantasy soundtracks, Final Fantasy VIII Original Soundtrack is composed completely of English track names. The album was also released in North America under the title Final Fantasy VIII Music Collection: Music From The Final Fantasy VIII Video Game. It features changes such as packaging design, translation, and <b>additional</b> <b>images.</b> <b>In</b> addition, a limited edition was produced, which has a beige background instead of a full motion video montage.|$|R
5000|$|The {{first edition}} was 190 mm high and 125 mm wide, {{weighing}} 575 grams. In this edition Morten Strange {{was credited with}} both text and photos. It covered 686 species; most were illustrated by the author; some 30 other bird photographers provided <b>additional</b> <b>images.</b> <b>In</b> both {{the first and the}} second edition of the book there are two bird species featured per page, each with one or more photographs as well as a distribution map. The taxonomy and nomenclature in the first edition followed The Birds of Indonesia: a Checklist by Peter Andrew from 1992; this was the most used checklist at the time, using the so-called ‘crows-last’ sequence. The book was a companion to A Photographic Guide to the Birds of Southeast Asia which was published the previous year, in 2000. However, this volume used a different checklist as a reference with a ‘buntings last’ sequence.|$|R
50|$|The Einstein Cross (Q2237+030 or QSO 2237+0305) is a {{gravitational}} lensed quasar {{that sits}} directly behind ZW 2237+030, Huchra's Lens. Four {{images of the}} same distant quasar (an <b>additional</b> <b>image</b> is present <b>in</b> the center, but it can't be seen with the naked eye) appear around a foreground galaxy due to strong gravitational lensing.|$|R
50|$|Surfaces that {{we usually}} {{consider}} rough will, if that roughness consists of relief {{less than the}} radar wavelength, behave as smooth mirrors, showing, beyond such a surface, <b>additional</b> <b>images</b> of items <b>in</b> front of it. Those mirror images will appear within {{the shadow of the}} mirroring surface, sometimes filling the entire shadow, thus preventing recognition of the shadow.|$|R
40|$|This paper {{presents}} a demosaicing approach which combines the Bayer patterns of multiple overlapping images. Multiple {{images of the}} same subject are taken, where the camera is free to pan, tilt, and rotate around its optical axis. The images are spatially registered and a Bayer pattern mosaic is created by combining each <b>image’s</b> Bayer pattern. <b>In</b> the region of overlap, each <b>additional</b> <b>image</b> “fills <b>in</b> ” the gaps in the Bayer pattern for each color channel, creating a completely filled Bayer mosaic. The presented method is implemented in graphics hardware, which provides hardware acceleration. Results are shown in which increased color channel resolution is achieved in the overlapping regions of multiple images. 1...|$|R
40|$|We present two new {{approaches}} to extending existing light fields with <b>additional</b> <b>image</b> data. <b>In</b> this case a light field is initially constructed from an image sequence taken by a hand-held camera, and pose parameters of this camera obtained through structure-from-motion approaches. To extend such a light field, point correspondences are necessary from one <b>image</b> <b>in</b> the original sequence to the new images to estimate their relative poses. The two introduced approaches assist in finding the original image closest to the new image, and provide initial motion estimates. A SIFT feature based method is {{used to determine the}} closest image and an imagespace motion homography. The second approach uses images rendered from the light field to estimate the camera pose of the image to be added using adaptive random search or a particle filter. ...|$|R
50|$|Bright is the self-titled fourth album by Japanese girl group Bright. The girls {{adopted a}} sexier image for the album, posing nude {{for the cover}} as well as {{additional}} pictures in the album booklet. <b>Additional</b> changes <b>in</b> <b>image</b> were Nagi dying her hair red, and Nanaka and Meg dying theirs blonde.|$|R
30|$|<b>In</b> our opinion, <b>image</b> {{reconstruction}} techniques {{based on}} joint noise modeling techniques will (in the long term) significantly further improve the image quality, especially when physical {{limits of the}} image sensors are reached. For example, the minimal sensor size of a digital camera is limited by signal-to-noise considerations: if one {{would like to have}} a higher image resolution, one would also have to deal with a higher level of noise <b>in</b> the <b>image,</b> even up to such a degree that further increasing the image resolution does not bring any gain <b>in</b> <b>image</b> quality. Besides this, the dynamic range of a camera sensor is still many orders lower than the dynamic range that the human visual system can deal with, and improving the dynamic range will <b>also</b> bring an <b>additional</b> <b>image</b> quality increase.|$|R
30|$|Through-the-wall imaging (TWI) is a {{difficult}} but important task for both law enforcement and military missions. Acquiring information on both the internal features of a structure {{and the location of}} people inside {{plays an important role in}} many fields such as antiterrorism, hostage search and rescue, and barricade situations. Up to now, a number of promising experimental systems have been developed to validate and evaluate diverse imaging methods, most of which are based on a linear antenna array to obtain an image of the objects. However, these methods typically use the backward projection (BP) algorithm based on ellipse curves, which usually generates <b>additional</b> ghost <b>images.</b> <b>In</b> this paper, the algorithm using the location inverse solution (LIS) to reduce the ghost images is proposed and simulated. The results of simulation show that this approach is feasible.|$|R
40|$|Despite {{tremendous}} {{advances in}} modern imaging technology, both {{early detection and}} accurate diagnosis of breast cancer are still unresolved challenges. Today, a variety of imaging modalities and image-guided biopsy procedures exist to identify and characterize morphology and function of suspicious breast tissue. However, a clinically feasible solution for breast imaging, which is both highly sensitive and specific with respect to breast cancer, is still missing. As a consequence, unnecessary biopsies are taken and tumours frequently go undetected until a stage where therapy is costly or unsuccessful. Currently, the exact diagnosis of suspicious breast tissue is ambiguous in many cases. To resolve this, computer aided diagnosis methods are developed which use knowledge extracted from large multimodal case databases. Clinical workstations must be developed to allow clinicians to use <b>additional</b> <b>image</b> modalities <b>in</b> an optimal way. Dedicated tools are required to guide clini cians in establishing a diagnosis,and should ultimately lead to more specific and accurate diagnostic decisions...|$|R
40|$|Through-the-wall imaging (TWI) is a {{difficult}} but important task for both law enforcement and military missions. Acquiring information on both the internal features of a structure {{and the location of}} people inside {{plays an important role in}} many fields such as antiterrorism, hostage search and rescue, and barricade situations. Up to now, a number of promising experimental systems have been developed to validate and evaluate diverse imaging methods, most of which are based on a linear antenna array to obtain an image of the objects. However, these methods typically use the backward projection (BP) algorithm based on ellipse curves, which usually generates <b>additional</b> ghost <b>images.</b> <b>In</b> this paper, the algorithm using the location inverse solution (LIS) to reduce the ghost images is proposed and simulated. The results of simulation show that this approach is feasible. </p...|$|R
40|$|The {{pharmacopeia}} of Pedanius Dioscorides (20 - 70 ce), entitled Peri Ylis Ialikis (latinized as De Materia Medica, On Medical Matters) {{was written}} in Greek about the year 65. It {{was destined to be}} one of the most famous books on pharmacology and medicine but is also richin horticulture and plant ecology. An illustrated alphabetical version of Dioscorides’ manuscript was completed in Constantinople about 512. This magnificent volume was prepared and presented to the imperial Princess Juliana Anicia (462 - 527), daughter of the EmperorAnicius Olybrius, Emperor of the Western Roman Empire. The bound manuscript stored in Ōsterreichische Nationalbibliothek inVienna is available in facsimile and is now referred to as the Juliana Anicia Codex (JAC) or the Codex Vindobonensis Dioscorides. The JACcontains 383 paintings of plants including many horticultural crops, many of which can still be recognized in modern day examples. Ananalysis of the illustrations indicates that they were made by numerous artists of varying skills and it is probable that some were derivedfrom an earlier lost version. The Codex Neapolitanus (NAP) (late 6 th or early 7 th century) which now contains 406 plant images on 172 folios resides in the Biblioteca Nazionale, Naples is closely related to JAC, and is also available in facsimile editions. A comparison ofthe 352 common illustrations contained in both NAP and JAC suggests that many of the illustrations derived from a common source,perhaps an illustrated collection owned by Theodosius II, but the possibility also exists that some of the NAP images are direct copies ofJAC images. There are 31 <b>images</b> <b>in</b> JAC which do not appear in NAP, 1 is a 13 th century addition, 4 are images that can be assigned to 2 torn pages. and 26 can be assigned to 11 missing leaves of the NAP. Of the 54 <b>images</b> <b>in</b> NAP which do not appear in JAC, 2 are likelyto have been Mandragora included in lost folios in JAC, but the other 52 may include other <b>images</b> that existed <b>in</b> the common source. While common <b>images</b> <b>in</b> NAP and JAC are often very similar, 11. 6 % show substantially differences including variants of the sameplant <b>in</b> different stages. <b>Additional</b> <b>images</b> <b>in</b> the archetypic source including different stages of the same plant could have provided thecopyists working on JAC and NAP the opportunity to select different images to fulfill their commissions...|$|R
25|$|Recent closeup {{images from}} the Cassini probe show that the F Ring {{consists}} of one core ring and a spiral strand around it. They also show that when Prometheus encounters the ring at its apoapsis, its gravitational attraction creates kinks and knots in the F Ring as the moon 'steals' material from it, leaving a dark channel in the inner part of the ring (see video link and <b>additional</b> F Ring <b>images</b> <b>in</b> gallery). Since Prometheus orbits Saturn more rapidly than the material in the F ring, each new channel is carved about 3.2 degrees {{in front of the}} previous one.|$|R
40|$|A {{concept of}} virtual {{subspace}} is introduced for realizing a robust face recognition {{independent of the}} lighting conditions. The virtual subspace is a paradoxical concept {{because it can be}} constructed even if only one image is taken. Furthermore, the virtual subspace is gradually converged to the real subspace when face images are subsequently taken. The virtual subspace is defined as an eigenspace composed from a synthesized image set which are supposed to be taken in a variety of lighting conditions. - 4 n integration algorithm is also proposed for updating the virtual subspace when <b>additional</b> <b>images</b> are available. <b>In</b> the experiments, we show the effectiveness of the virtual subspace method in comparison with both the conventional subspace method and the nearest neighbor discrimination. 1...|$|R
40|$|An {{asymmetric}} lens {{made of a}} spherically symmetric {{galaxy and}} a quadrupole tidal part allows a very simple pictorial examination of the multiplicity and positions of the images, for any mass density profile. The lens equations {{can be reduced to}} one equation in one variable. In the special case of a singular isothermal sphere with a tide (SIST), the lens properties are described by five parameters. Two parameters determine the angular scale and orientation, while three determine the configuration of the images. A comprehensive investigation of the SIST lens is performed, including the variation of the configurations with the parameter values, the critical surfaces in the parameter space, and the extremal solutions. Analytic expressions are derived for the SIST parameters, and <b>additional</b> <b>image</b> positions, <b>in</b> the case when the intensity ratio and positions relative to the galaxy for two of the images are given as input. Quadrupole lenses with a point mass and a pseudoisothermal sphere as the main part are also described in terms of direction diagrams. A direct relation between deflection profile and rotational velocity is derived...|$|R
40|$|License, which permits {{unrestricted}} use, distribution, {{and reproduction}} in any medium, provided the original work is properly cited. Through-the-wall imaging (TWI) {{is a difficult}} but important task for both law enforcement and military missions. Acquiring information on both the internal features of a structure {{and the location of}} people inside {{plays an important role in}} many fields such as antiterrorism, hostage search and rescue, and barricade situations. Up to now, a number of promising experimental systems have been developed to validate and evaluate diverse imaging methods, most of which are based on a linear antenna array to obtain an image of the objects. However, these methods typically use the backward projection (BP) algorithm based on ellipse curves, which usually generates <b>additional</b> ghost <b>images.</b> <b>In</b> this paper, the algorithm using the location inverse solution (LIS) to reduce the ghost images is proposed and simulated. The results of simulation show that this approach is feasible. 1...|$|R
40|$|One of {{the input}} image for an {{inscription}} on {{a column of}} the Parthenon. The light-capturing frame (Fig. 1) consists of fiducials and MacBeth color checker chart samples, from which the camera's position and the incident radiant intensity can be estimated, {{as well as two}} glossy black spheres used to indicate the position of the light source. To reconstruct each object, we re-adjusted the size of the frame and placed it around the geometry. We took approximately ten images, each lit with a remotely mounted camera flash at a different position pointed towards the center of the frame. For each set of images, we <b>also</b> took an <b>additional</b> <b>image</b> without the flash, which was subtracted from the other images to remove any ambient # e-mail:einarsson, timh, debevec@ict. usc. edu lighting. The full process including setup took approximately 20 minutes for each inscription. To compute a surface normal map, we first determine the light vector l by shooting rays from the camera's center toward the...|$|R
40|$|Our {{purpose in}} this work is to boost the {{performance}} of object classifiers learned using the self-training paradigm. We exploit the multi-modal nature of tagged <b>images</b> found <b>in</b> social networks, to optimize the process of region selec-tion when retraining the initial model. More specifically, the proposed approach uses {{a small number of}} manually labelled regions to train the initial object detection classifiers. Then, a large number of loosely tagged images, pre-segmented by an automatic segmentation algorithm, is used to enhance the initial training set with <b>additional</b> <b>image</b> regions. How-ever, <b>in</b> contrast to the typical case of self-training where the image regions are selected based solely on how well they fit to the original classification model, our approach aims at optimizing this selection by making combined use of both visual and textual information. The experimental results show that the object detection classifiers generated using the proposed approach outperform the classifiers generated using the typical self-training paradigm...|$|R
40|$|In deep learning, data {{augmentation}} {{is important}} {{to increase the amount}} of training images to obtain higher classification accuracies. Most data-augmentation methods adopt the use of the following techniques: cropping, mirroring, color casting, scaling and rotation for creating <b>additional</b> training <b>images.</b> <b>In</b> this paper, we propose a novel data-augmentation method that transforms an image into a new image containing multiple rotated copies of the original <b>image</b> <b>in</b> the operational classification stage. The proposed method creates a grid of n × n cells, in which each cell contains a different randomly rotated image and introduces a natural background in the newly created image. This algorithm is used for creating new training and testing images, and enhances the amount of information <b>in</b> an <b>image.</b> For the experiments, we created a novel dataset with aerial images of cows and natural scene backgrounds using an unmanned aerial vehicle, resulting in a binary classification problem. To classify the images, we used a convolutional neural network (CNN) architecture and compared two loss functions (Hinge loss and cross-entropy loss). Additionally, we compare the CNN to classical feature-based techniques combined with a k-nearest neighbor classifier or a support vector machine. The results show that the pre-trained CNN with our proposed data- augmentation technique yields significantly higher accuracies than all other approaches...|$|R
2500|$|In {{the third}} quatrain, the key rhyming words {{given by the}} speaker are: [...] "ornament" [...] and [...] "content", and [...] "spring" [...] and [...] "niggarding"; <b>additional</b> <b>images</b> are {{presented}} <b>in</b> this quatrain, such as [...] "fresh", [...] "herald", [...] "bud", [...] "burial", and the oxymoron [...] "tender churl". Other words and themes the speaker uses are explained by Helen Vendler: [...] "The concepts – because Shakespeare's mind works by contrastive taxonomy – tend to be summoned in pairs: increase and decrease, ripening and dying; beauty and immortality versus memory and inheritance; expansion and contraction; inner spirit (eyes) and outward show (bud); self-consumption and dispersal, famine and abundance". Shakespeare uses these words to make [...] "an aesthetic investment in profusion". The meaning found in these lines and words shows how the young man's refusal to procreate is a refusal of his flesh, a wasting of it.|$|R
40|$|Light-field imaging {{systems have}} got much {{attention}} {{recently as the}} next generation camera model. A light-field imaging system consists of three parts: data acquisition, manipulation, and application. Given an acquisition system, {{it is important to}} understand how a light-field camera converts from its raw image to its resulting refocused <b>image.</b> <b>In</b> this paper, using the Lytro camera as an example, we describe step-by-step procedures to calibrate a raw light-field <b>image.</b> <b>In</b> particular, we are interested in knowing the spatial and angular coordinates of the micro lens array and the resampling process for image reconstruction. Since Lytro uses a hexagonal arrangement of a micro lens <b>image,</b> <b>additional</b> treatments <b>in</b> calibration are required. After calibration, we analyze and compare the performances of several resampling methods for image reconstruction with and without calibration. Finally, a learning based interpolation method is proposed which demonstrates a higher quality image reconstruction than previous interpolation methods including a method used in Lytro software. 1...|$|R
40|$|The rod photoreceptors are {{implicated in}} a number of devastating retinal diseases. However, routine imaging of these cells has {{remained}} elusive, even with the advent of adaptive optics imaging. Here, we present the first <b>in</b> vivo <b>images</b> of the contiguous rod photoreceptor mosaic in nine healthy human subjects. The images were collected with three different confocal adaptive optics scanning ophthalmoscopes at two different institutions, using 680 and 775 nm superluminescent diodes for illumination. Estimates of photoreceptor density and rod:cone ratios in the 5 °– 15 ° retinal eccentricity range are consistent with histological findings, confirming our ability to resolve the rod mosaic by averaging multiple registered images, without the need for <b>additional</b> <b>image</b> processing. <b>In</b> one subject, we were able to identify the emergence of the first rods at approximately 190 μm from the foveal center, in agreement with previous histological studies. The rod and cone photoreceptor mosaics appear in focus at different retinal depths, with the rod mosaic best focus (i. e., brightest and sharpest) being at least 10 μm shallower than the cones at retinal eccentricities larger than 8 °. This study represents an important step in bringing high-resolution imaging to bear on the study of rod disorders...|$|R
40|$|Problem {{description}} The {{ability to}} perceive the surrounding environment visually opens a path to solving many robotics perception problems such as object detection, obstacle avoidance etc. Typical algorithms are targeting standard cameras and {{they are based on}} well established engineered methods of processing data. Opposite from standard cameras which provide a time sequenced stream of frames the dynamic vision sensor provides only relative changes in a scene, given by individual events at the pixel level. Using this different encoding scheme the dynamic vision sensor brings advantages over standard cameras. First, there is no redundancy in the data received from the sensor, only changes are reported. Second, as only events are considered the eDVS data rate is high. Third, the power consumption of the overall system is small, as just a low-end microcontroller is used to fetch events from the sensor and forward them to a PC for processing. Recently {{a new version of the}} dynamic vision sensor ApsDVS was developed. The new sensor provides a higher resolution of 240 x 180 pixels and an <b>additional</b> grayscale <b>image</b> <b>in</b> parallel to the pixel events, which extends the usage also for static scenes. Opposite to the first setup (eDV...|$|R
40|$|PET/CT {{guidance}} for percutaneous interventions allows biopsy of suspicious metabolically active bone lesions even when no morphological correlation is delineable <b>in</b> the CT <b>images.</b> Clinical use of PET/CT guidance with conventional step-by-step technique is time consuming and complicated especially in {{cases in which}} the target lesion is not shown <b>in</b> the CT <b>image.</b> Our recently developed multimodal instrument guidance system (IGS) for PET/CT improved this situation. Nevertheless, bone biopsies even with IGS have a trade-off between precision and intervention duration which is proportional to patient and personnel exposure to radiation. As image acquisition and reconstruction of PET may take up to 10 minutes, preferably only one time consuming combined PET/CT acquisition should be needed during an intervention. In case of required <b>additional</b> control <b>images</b> <b>in</b> order to check for possible patient movements/deformations, or to verify the final needle position in the target, only fast CT acquisitions should be performed. However, for precise instrument guidance accounting for patient movement and/or deformation without having a control PET image, it is essential to be able to transfer the position of the target as identified in the original PET/CT to a changed situation as shown in the control CT...|$|R
40|$|Abstract. We {{present a}} general method for blind image {{deconvolution}} using Bayesian inference with super-Gaussian sparse image priors. We consider {{a large family}} of priors suitable for modeling natural images, and develop the general procedure for estimating the unknown image and the blur. Our formulation includes a number of existing modeling and inference methods as special cases while providing <b>additional</b> flexibility <b>in</b> <b>image</b> modeling and algorithm design. We also present {{an analysis of the}} proposed inference compared to other methods and discuss its advantages. Theoretical and experimental results demonstrate that the proposed formulation is very effective, efficient, and flexible. ...|$|R
40|$|Abstract — Taking videos with a {{hand-held}} camera introduces shaking, which incontrovertibly reduces video quality. Digital video stabilization {{is a process}} to compensate for camera motion by means of <b>image</b> processing. <b>In</b> the best case, it does not only remove the unintentional motion, but also reduces image distortion caused by the motion. In practice, removing all but nothing more than unwanted jitter is not achieved precisely. Furthermore, a stabilization process itself often introduces some <b>additional</b> distortion <b>in</b> <b>images</b> instead of removing it. In this paper, means to automatically evaluate the performance of video stabilization process are proposed, based on measuring divergence and jitter of motion error and blurring via point spread function. This helps to tune the system parameters for better quality. I...|$|R
40|$|BACKGROUND AND PURPOSE: Qualitative {{decreases}} in maternal brain size {{have been observed}} late in pregnancy. The {{aim of this study}} was to quantitatively evaluate changes to the maternal brain during and after healthy pregnancy and to compare these changes with those observed in cases of preeclampsia. METHODS: Three-dimensional T 1 -weighted MR volume <b>images</b> were obtained <b>in</b> nine healthy participants before and after delivery. <b>Additional</b> <b>images</b> were obtained <b>in</b> some of these participants before pregnancy, during pregnancy, and within 52 weeks after delivery. Five women with preeclampsia were examined before delivery and 6 weeks after delivery. Three of these patients were examined within 52 weeks after delivery. Images were registered, and both brain and ventricular volumes were calculated by using a semiautomated computer program. RESULTS: Both the healthy and preeclamptic groups had a reduction in brain size during pregnancy that was maximal at term and that reversed by 6 months after delivery. The ventricular size showed a corresponding increase in size during pregnancy and a decrease in size after delivery. In the preeclamptic patients, brain size was significantly smaller (P. 05) than in healthy participants, both before and after delivery...|$|R
40|$|In {{this work}} we {{establish}} a theoretical {{relation between the}} notions of scale and a discrete Finsler-Haantjes curvature. Based on this connection we demonstrate {{the applicability of the}} interpretation of scale in terms of curvature, to signal processing in the context of analysis and segmentation of textures <b>in</b> <b>images.</b> The outcome of this procedure is a novel scheme for texture segmentation that is based on scaled metric curvature. The presented method proves itself to be efficient even when the multiscale analysis is done up to scales of 19 and more. Our main conclusions are that the discrete curvature calculated on sampled images can give us an indication on the local scale within the image, and therefore can be used for many <b>additional</b> tasks <b>in</b> <b>image</b> analysis...|$|R
