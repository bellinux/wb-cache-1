0|31|Public
50|$|Furthermore, page title {{conversion}} is {{used for}} <b>automatic</b> <b>page</b> <b>redirection.</b> Those articles previously named in different characters or different translations have been merged, and {{can be reached by}} means of both Traditional and Simplified Chinese titles.|$|R
50|$|HttpUnit is an {{open source}} {{software}} testing framework used to perform testing of web sites {{without the need for}} a web browser. HttpUnit supports HTML form submission, JavaScript, HTTP basic access authentication, <b>automatic</b> <b>page</b> <b>redirection,</b> and cookies. Written in Java, HttpUnit allows Java test code to process returned pages as text, XML DOM, or containers of forms, tables and links. HttpUnit is well suited to be used in combination with JUnit, in order to easily write tests that verify the proper behaviour of a web site.|$|R
5000|$|HtmlUnit is a {{headless}} {{web browser}} written in Java. It allows high-level manipulation of websites from other Java code, including filling and submitting forms and clicking hyperlinks. It also {{provides access to}} the structure and the details within received web pages. HtmlUnit emulates parts of browser behaviour including the lower-level aspects of TCP/IP and HTTP. A sequence such as , , [...] allows a user to navigate through hypertext and obtain web pages that include HTML, JavaScript, Ajax and cookies. This headless browser can deal with HTTPS security, basic HTTP authentication, <b>automatic</b> <b>page</b> <b>redirection</b> and other HTTP headers. It allows Java test code to examine returned pages either as text, an XML DOM, or as collections of forms, tables, and links.|$|R
5000|$|... <b>automatic</b> <b>redirection</b> of {{standard}} input, output and error from/to regular files; ...|$|R
50|$|The above example {{does not}} check who called it (e.g. by referrer, {{although}} {{that could be}} spoofed). Also, it does not check the url provided. This means that a malicious person could link to the <b>redirection</b> <b>page</b> using a url parameter of his/her own selection, from any page, which uses the web server's resources.|$|R
40|$|Web-based {{malicious}} software (malware) {{has been increasing}} over the Internet. It poses threats tocomputer users through web sites. Computers are infected with Web-based malware by drive-by-downloadattacks. Drive-by-download attacks force users to download and install the Web-based malware without beingaware of it. these attacks evade detection by using <b>automatic</b> <b>redirections</b> to various websites. It is difficult todetect these attacks because each redirection uses the obfuscation technique. This paper analyzes the HTTPcommunication data of drive-by-download attacks. The results show significant features of the maliciousredirections that are used effectively when we detect malware...|$|R
50|$|The only non-controversial {{counter-argument}} {{to using}} user-friendly URLs {{is that they}} would be leaked in the HTTP referer header field when a user clicks on an external link from a post, which is undesirable for private (sub)forums, since a URL derived from the topic title could convey sensitive information. This issue can be resolved by rewriting external links to point to a <b>redirection</b> <b>page</b> that performs referer hiding.|$|R
50|$|The {{physiological}} response of surprise {{falls under the}} category of the startle response. The main function of surprise or the startle response is to interrupt an ongoing action and reorient attention to a new, possibly significant event. There is an <b>automatic</b> <b>redirection</b> of focus to the new stimuli and, for a brief moment, this causes tenseness in the muscles, especially the neck muscles. Studies show that this response happens extremely fast, with information (in this case a loud noise) reaching the pons within 3 to 8 ms and the full startle reflex occurring in less than two tenths of a second.|$|R
50|$|In {{the past}} when Fox Sports {{broadcast}} tournaments in the United States, the logos for betting houses such as Ladbrokes were pixelated out and digitally obscured, along with any audible references to them, because of American laws and policies against online gambling; however other US broadcasters usually carry overseas darts tournaments without any edits other than for timing and narrative purposes, and Americans usually cannot visit the sites for betting houses outside of <b>redirection</b> <b>pages.</b>|$|R
5000|$|Other {{features}} include community-wide spam filters, {{in which many}} b2evolution sites aggregate and tag spammer IPs into a central blacklist {{for the benefit of}} all b2evolution blogs, a button to declare [...] "comment spam bankruptcy" [...] - which deletes all comments across an entire b2evolution installation, a fully skinnable interface, strong SEO features including <b>automatic</b> <b>redirection</b> of renamed articles and insertion of canonical link tags, url shortening, localization into a dozen language packs, and a fully exposed API for plugin developers to add new functionality. b2evolution's code is factored into the blog application itself and a framework called EvoCore. EvoCore can be used on its own to build non-blog web applications.|$|R
5000|$|Historically, {{to create}} a link to a Web server, [...] "GET /" [...] {{was used as a}} pseudo-selector to emulate an HTTP GET request. John Goerzen created an {{addition}} to the Gopher protocol, commonly referred to as [...] "URL links", that allows links to any protocol that supports URLs. For example, {{to create a}} link to http://gopher.quux.org/, the item type is , the display string is the title of the link, the item selector is [...] "", and the domain and port are that of the originating Gopher server (so that clients that do not support URL links will query the server and receive an HTML <b>redirection</b> <b>page).</b>|$|R
5000|$|Between 2004 and 2008 the UKGWA mainly held {{copies of}} {{websites}} created by departments {{of state and}} those of UK Public Inquiries. During 2007, Members of Parliament {{became aware of the}} increasing problem of link rot on UK government web sites. In particular many links from Hansard were found to have stopped working. The response was the Web Continuity programme, [...] which provides <b>automatic</b> <b>redirection</b> to the UKGWA of links from UK Government web sites, in cases where the linked material has been retired. Web Continuity required UK Government website managers to work with the UKGWA to capture copies of any material about to be removed. As a result, the UKGWA captures almost all of the UK Government web estate. This became significant during periods of government website closures, initially with the Directgov programme; and more recently with the convergence of UK government content onto the Gov.uk website.|$|R
40|$|Abstract. Session cookies {{constitute}} one of {{the main}} attack targets against client authentication on the Web. To counter that, modern web browsers implement native cookie protection mechanisms based on the Secure and HttpOnly flags. While there is a general understanding about the effectiveness of these defenses, no formal result has so far been proved about the security guarantees they convey. With the present paper we provide the first such result, with a mechanized proof of noninterfer-ence assessing the robustness of the Secure and HttpOnly cookie flags against both web and network attacks. We then develop CookiExt, a browser extension that provides client-side protection against session hi-jacking based on appropriate flagging of session cookies and <b>automatic</b> <b>redirection</b> over HTTPS for HTTP requests carrying such cookies. Our solution improves over existing client-side defenses by combining protec-tion against both web and network attacks, {{while at the same time}} being designed so as to minimise its effects on the user’s browsing experience. ...|$|R
5000|$|When a link is clicked, {{the browser}} sends {{along in the}} HTTP request a field called referer which {{indicates}} {{the source of the}} link. This field is populated with the URL of the current web page, and will end up in the logs of the server serving the external link. Since sensitive pages may have sensitive URLs (for example, [...] ), it is not desirable for the [...] URL to leave the organization. A <b>redirection</b> <b>page</b> that performs referrer hiding could be embedded in all external URLs, transforming for example [...] into [...] This technique also eliminates other potentially sensitive information from the referer URL, such as the session ID, and can reduce the chance of phishing by indicating to the end user that they passed a clear gateway to another site.|$|R
40|$|Abstract. Since a {{few years}} there has been an {{explosion}} of communication possibilities. The wide number of communication channels available nowadays brings, with no question, enormous benefits for the users, however it brings new challenges as well. The choice of the best communication channel not only depends on the characteristics related to the channel itself (QoS, rates, etc.); the user context (location, personal agenda, etc.) affects the decision as well. The combination of all the factors generates a list of variables impossible to handle by the human being. The information available about channels, together with the information that smart devices are able to extract from the user context, make possible to introduce a computing system to help the user in selecting the most appropriate communication channel. In this paper we present RING, a context-aware ruled-based recommender system for the <b>automatic</b> <b>Redirection</b> of incomING communications based on Semantic Web, that allows users to receive any kind of communication through the best channel available depending on his context and personal preferences...|$|R
40|$|Redirection spam {{presents}} a web page with false content to a crawler for indexing, but automatically redirects the browser {{to a different}} web <b>page.</b> <b>Redirection</b> is usually immediate (on page load) but may also be triggered by a timer or a harmless user event such as a mouse move. JavaScript redirection is the most notorious of redirection techniques and is hard to detect {{as many of the}} prevalent crawlers are script-agnostic. In this paper, we study common JavaScript redirection spam techniques on the web. Our findings indicate that obfuscation techniques are very prevalent among JavaScript <b>redirection</b> spam <b>pages.</b> These obfuscation techniques limit the effectiveness of static analysis and static feature based systems. Based on our findings, we recommend a robust counter measure using a light weight JavaScript parser and engine...|$|R
40|$|Structural {{details of}} protein–protein {{interactions}} are invaluable for understanding and deciphering biological mechanisms. Computational docking methods aim {{to predict the}} structure of a protein–protein complex given the structures of its single components. Protein flexibility and the absence of robust scoring functions pose a great challenge in the docking field. Due to these difficulties most of the docking methods involve a two-tier approach: coarse global search for feasible orientations that treats proteins as rigid bodies, followed by an accurate refinement stage that aims to introduce flexibility into the process. The FireDock web server, presented here, is the first web server for flexible refinement and scoring of protein–protein docking solutions. It includes optimization of side-chain conformations and rigid-body orientation and allows a high-throughput refinement. The server provides a user-friendly interface and a 3 D visualization of the results. A docking protocol consisting of a global search by PatchDock and a refinement by FireDock was extensively tested. The protocol was successful in refining and scoring docking solution candidates for cases taken from docking benchmarks. We provide an option for using this protocol by <b>automatic</b> <b>redirection</b> of PatchDock candidate solutions to the FireDock web server for refinement. The FireDock web server is available at [URL]...|$|R
40|$|Gaining an {{accurate}} mental representation of real environments and realistic Virtual Environments is a gradual process. Significant aspects of an environment may be obvious to a trained expert, {{but not to}} the novice trainee. If a user does not know where to look, he or she may concentrate on irrelevant objects. This detracts from learning the locations of truly prominent landmarks. This paper explores attentive camera navigation, a technique that guides the user to focus on certain objects through <b>automatic</b> gaze <b>redirection.</b> Results of a user study suggest that this technique can help filter out unnecessary objects, and allow users to quickly understand the configuration of a selected subset of landmarks...|$|R
40|$|Constructing {{ontology}} manually is a time-consuming, error-prone, and tedious task. We present SSCO, a self-supervised learning based chinese ontology, {{which contains}} about 255 thousand concepts, 5 million entities, and 40 million facts. We explore the three largest online Chinese encyclopedias for ontology learning and describe how {{to transfer the}} structured knowledge in encyclopedias, including article titles, category labels, <b>redirection</b> <b>pages,</b> taxonomy systems, and InfoBox modules, into ontological form. In {{order to avoid the}} errors in encyclopedias and enrich the learnt ontology, we also apply some machine learning based methods. First, we proof that the self-supervised machine learning method is practicable in Chinese relation extraction (at least for synonymy and hyponymy) statistically and experimentally and train some self-supervised models (SVMs and CRFs) for synonymy extraction, concept-subconcept relation extraction, and concept-instance relation extraction; the advantages of our methods are that all training examples are automatically generated from the structural information of encyclopedias and a few general heuristic rules. Finally, we evaluate SSCO in two aspects, scale and precision; manual evaluation results show that the ontology has excellent precision, and high coverage is concluded by comparing SSCO with other famous ontologies and knowledge bases; the experiment results also indicate that the self-supervised models obviously enrich SSCO...|$|R
50|$|The Google service also {{addresses}} DNS security. A common {{attack vector}} is {{to interfere with}} a DNS service to achieve <b>redirection</b> of web <b>pages</b> from legitimate to malicious servers. Google documents efforts to be resistant to DNS cache poisoning, including “Kaminsky Flaw” attacks as well as denial-of-service attacks.|$|R
40|$|We outline a {{methodology}} for the modular specification of telephone services within first-order linear-time temporal logic. Typically, the services {{offered by a}} telephone system consist of a basic service and several optional additional services, such as <b>automatic</b> callback, <b>redirection,</b> etc. We argue informally that temporal logic provides a flexible formalism for the specification of individual services, and for the composition of different services. We present a style of specification, in which the expected behavior of each additional service can be specified independently of other services. In this style, it is straight-forward to compose noninteracting services. We outline, by means of examples, how certain interactions between services that prescribe conflicting behavior can manifest themselves as inconsistencies when the services are composed. We then outline how the resolution of such interactions {{can be described in}} the formalism. 1 Introduction The difficulty of designing [...] ...|$|R
40|$|Abstract. The {{ubiquitous}} computing rooms and interactive workspaces currently being researched and deployed typically have several large screens {{and dozens of}} machines which can display to them. Providing convenient and intuitive pointer and keyboard access in such spaces is a challenge. The room should function as a large virtual desktop, and input should automatically be routed to whichever machine is currently displaying to a screen. Unfortunately, existing software and pointer redirection systems are limited to controlling a few dedicated machines with a single keyboard and mouse. PointRight provides intuitive, <b>automatic</b> pointer/keyboard <b>redirection</b> for interactive workspaces. It supports flexible topologies, dynamic changes in machine and screen state, multi-screen machines and can be installed on both permanent and transient machines in an interactive workspace. Versions of the system have been continuously deployed in our prototype interactive workspace over the last 18 months, and a public version is planned for September 2001. ...|$|R
30|$|Search Engine: The {{second most}} useful data source in our arsenal was {{the output of}} our {{automated}} search engine queries. In 54.5 % of the cases, query results were a valuable resource providing critical information for the analysis. This information was in most cases complementary {{to the content of}} IDS alerts, providing knowledge about active C&C hosts, botnet communication channels, malware landing <b>pages,</b> <b>redirections</b> to malicious domains, malware download pages, and phishing forms.|$|R
40|$|A {{soft error}} {{redirection}} is a URL <b>redirection</b> to a <b>page</b> that returns the HTTP status code 200 (OK) but has actually no relevant content {{to the client}} request. Since such redirections degrade the performance of web search engines in many ways, it is highly desirable to remove {{as many of them}} as possible. We propose a novel approach to detect soft error redirections by analyzing redirection logs collected during crawling operation. Experimental results on huge crawl data show that our measure can classify soft error redirections effectively...|$|R
2500|$|In the past, the PageRank {{shown in}} the Toolbar was easily manipulated. <b>Redirection</b> from one <b>page</b> to another, either via a HTTP 302 {{response}} or a [...] "Refresh" [...] meta tag, caused the source page to acquire the PageRank of the destination page. Hence, a new page with PR 0 and no incoming links could have acquired PR 10 by redirecting to the Google home page. This spoofing technique was a known vulnerability. Spoofing can generally be detected by performing a Google search for a source URL; if the URL of an entirely different site is displayed in the results, the latter URL may represent the destination of a redirection.|$|R
40|$|Algebraic {{effects are}} {{computational}} effects {{that can be}} represented by an equational theory whose operations produce the effects at hand. The free model of this theory induces the expected computational monad for the corresponding effect. Algebraic effects include exceptions, state, nondeterminism, interactive input/output, and time, and their combinations. Exception handling, however, has so far received no algebraic treatment. We present such a treatment, in which each handler yields {{a model of the}} theory for exceptions, and each handling construct yields the homomorphism induced by the universal property of the free model. We further generalise exception handlers to arbitrary algebraic effects. The resulting programming construct includes many previously unrelated examples from both theory and practice, including relabelling and restriction in Milner's CCS, timeout, rollback, and stream <b>redirection.</b> Comment: 36 <b>page...</b>|$|R
5000|$|The exploit employs scripts {{on a page}} {{of average}} interest, which rewrite the page with an {{impersonation}} of a well-known website, after the page has been left unattended for some time. A user who returns after a while and sees the rewritten page may be induced to believe the page is legitimate and enter their login, password and other details {{that will be used}} for improper purposes. The attack can be made more likely to succeed if the script checks for well known Web sites the user has loaded in the past or in other tabs, and loads a simulation of the same sites. This attack can be done even if JavaScript is disabled, using the [...] "meta refresh" [...] meta element, an HTML attribute used for <b>page</b> <b>redirection</b> that causes a reload of a specified new page after a given time interval.|$|R
40|$|Use of HVDC links {{for direct}} {{connection}} {{of a large}} nuclear power station to the existing power grid is unprecedented. Control of such HVDC connection for stable and secure operation of the nuclear power station is challenging and untested. For the Moorside nuclear power station planned close to the Lake District in Great Britain, there is tremendous pressure to use HVDC cables for the southern connection route (which would pass through the picturesque landscape) to avoid the visual impact of overhead lines. This paper shows that it is feasible to connect a large nuclear power station, such as Moorside, through a VSC-HVDC cable route alongside a northern AC route {{where there are no}} objections to overhead transmission. Use of a proposed control of the VSC-HVDC is shown to achieve <b>automatic</b> and rapid <b>redirection</b> of power on to the VSC-HVDC link following sudden outage of the AC route. Moreover, if the generators at Moorside were to shut down accidentally, the same control strategy for VSC-HVDC can back feed the power station auxiliaries which is essential for nuclear safety. Thus, a mix of AC and HVDC connection routes achieves similar (if not better) transient responses as compared to using both AC routes which in this case faces serious opposition...|$|R
40|$|As the Semantic Web grows, so {{does the}} number of ontologies used to {{structure}} the data within it. Aligning these ontologies is critical to fully realizing {{the potential of the}} web. Previous work in ontology alignment has shown that even alignment systems utilizing basic string similarity metrics can produce useful matches. Researchers speculate that including semantic as well as syntactic information inherent in entity labels can further improve alignment results. This paper examines that hypothesis by exploring the utility of using Wikipedia as a source of semantic information. Various elements of Wikipedia are considered, including article content, page terms, and search snippets. The utility of each information source is analyzed and a composite system, WikiMatcher, is created based on this analysis. The performance of WikiMatcher is compared to that of a basic string-based alignment system on two established alignment benchmarks and two other real-world datasets. The extensive evaluation shows that although WikiMatcher performs similarly to that of the string metric overall, it is able to find many matches with no syntactic similarity between labels. This performance seems to be driven by Wikipedia 2 ̆ 7 s query resolution and <b>page</b> <b>redirection</b> system, rather than by the particular information from Wikipedia that is used to compare entities...|$|R

