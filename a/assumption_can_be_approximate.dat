0|10000|Public
50|$|The Earth {{frame is}} a {{convenient}} frame to express aircraft translational and rotational kinematics. The Earth frame is also useful in that, under certain <b>assumptions,</b> it <b>can</b> <b>be</b> <b>approximated</b> as inertial. Additionally, one force {{acting on the}} aircraft, weight, is fixed in the +zE direction.|$|R
40|$|Let X be {{a compact}} nonsingular real {{algebraic}} variety. We prove {{that if a}} continuous map from X into the unit p-sphere is homotopic to a continuous rational map, then, under certain <b>assumptions,</b> it <b>can</b> <b>be</b> <b>approximated</b> in the compact-open topology by continuous rational maps. As a byproduct, we also obtain some results on approximation of smooth submanifolds by nonsingular subvarieties. Comment: To appear in Mathematische Zeitschrif...|$|R
40|$|Abstract—The {{statistical}} {{modeling of}} large multi-relational datasets has increasingly gained attention in recent years. Typ-ical applications involve large knowledge bases like DBpedia, Freebase, YAGO and the recently introduced Google Knowledge Graph that contain millions of entities, hundreds {{and thousands of}} relations, and billions of relational tuples. Collective factoriza-tion methods {{have been shown to}} scale up to these large multi-relational datasets, in particular in form of tensor approaches that can exploit the highly scalable alternating least squares (ALS) algorithms for calculating the factors. In this paper we extend the recently proposed state-of-the-art RESCAL tensor factorization to consider relational type-constraints. Relational type-constraints explicitly define the logic of relations by excluding entities from the subject or object role. In addition we will show that in absence of prior knowledge about type-constraints, local closed-world <b>assumptions</b> <b>can</b> <b>be</b> <b>approximated</b> for each relation by ignoring unobserved subject or object entities in a relation. In our experiments on representative large datasets (Cora, DBpedia), that contain up to millions of entities and hundreds of type-constrained relations, we show that the proposed approach is scalable. It further significantly outperforms RESCAL without type-constraints in both, runtime and prediction quality. I...|$|R
40|$|AbstractA {{new model}} for point {{processes}} is developed which {{assumes that the}} interarrival times are exponentially distributed and follow joint multivariate extreme value distributions. It is shown that such processes may arise via natural generating procedures, and that, under very weak <b>assumptions,</b> that they <b>can</b> <b>be</b> <b>approximated</b> as closely as desired by appropriate finite models...|$|R
40|$|A {{new model}} for point {{processes}} is developed which {{assumes that the}} interarrival times are exponentially distributed and follow joint multivariate extreme value distributions. It is shown that such processes may arise via natural generating procedures, and that, under very weak <b>assumptions,</b> that they <b>can</b> <b>be</b> <b>approximated</b> as closely as desired by appropriate finite models. Point processes extreme values order statistics Multivariate distributions...|$|R
40|$|We {{consider}} {{solutions to}} so-called stochastic fixed point equation R d=Ψ(R), where Ψ is a random Lipschitz function and R is a random variable independent of Ψ. Under the <b>assumption</b> that Ψ <b>can</b> <b>be</b> <b>approximated</b> by the function x Ax+B {{we show that}} the tail of R is comparable with the one of A, provided that the distribution of (A∨ 1) is tail equivalent. In particular we obtain new results for the random difference equation. Comment: 19 page...|$|R
40|$|We {{present a}} method for {{evaluating}} the biasing function of galaxies, delta (g) (delta), from a redshift survey from the cumulative distribution functions of galaxies and mass, C-g(delta (g)) and C(delta), respectively. Using a suite of N-body simulations of different cosmological models, we show how the nonlinear biasing function <b>can</b> <b>be</b> obtained with adequate accuracy directly from the observed counts in cells in redshift space under the <b>assumption</b> that C(delta) <b>can</b> <b>be</b> <b>approximated</b> by a cumulative log-normal distribution in 1 +delta, Once applied to redshift surveys such as PSCz, 2 dF, or SDSS the biasing function carl provide valuable constraints on galaxy formation and structure evolution...|$|R
40|$|Spherical {{harmonic}} analysis and numerical simulations {{are used to}} study the rotational properties of the coronal magnetic field under the <b>assumption</b> that it <b>can</b> <b>be</b> <b>approximated</b> by a current-free extension of the photospheric field. It is found that the rotation rate in the outer corona is determined, principally, by coronal filtering, the global averages of the photospheric rotation rate, and ongoing source eruptions. The present model is able to account for observationally inferred rotational properties. It is suggested that the coronal rotation rate accelerates gradually due to the equatorward migration of sunspots, and that the 27 -day equatorial period is approached toward sunspot minimum as the decaying photospheric flux becomes localized near the equator...|$|R
40|$|The {{duration}} of the lag phase of growth () has been estimated from the logistic function (y) {{in at least three}} ways. While they differ substantially from one another, none of them is particularly stringent. The central estimate of  is based on {{the point at which the}} curvature () of y is maximal. Unfortunately, the expression given for this estimate is based on the <b>assumption</b> that  <b>can</b> <b>be</b> <b>approximated</b> by the second derivative of y. This is equivalent to assuming that the rate of growth is zero, leading to relatively large values of . Avoiding this assumption yields a simple expression for a more stringent estimate of  The new estimate might be of particular value when only very limited growth <b>can</b> <b>be</b> tolerated...|$|R
40|$|Abstract. We {{consider}} a nonparametric model En, generated by independent ob-servations Xi, i = 1, [...] ., n, with densities p(x, θi), i = 1, [...] ., n, {{the parameters of}} which θi = f(i/n) ∈ Θ are driven by the values of an unknown function f: [0, 1] → Θ in a smoothness class. The main result of the paper is that, under regularity <b>assumptions,</b> this model <b>can</b> <b>be</b> <b>approximated,</b> {{in the sense of}} the Le Cam deficiency pseudodis-tance, by a nonparametric Gaussian shift model Yi = Γ(f(i/n)) + εi, where ε 1, [...] ., εn are i. i. d. standard normal r. v. ’s, the function Γ(θ) : Θ → R satisfies Γ′(θ) = √I(θ) and I(θ) is the Fisher information corresponding to the density p(x, θ). 1...|$|R
40|$|We {{consider}} a discrete-time capacity expansion problem involving multiple product families, multiple machine types, and non-stationary stochastic demand. Capacity expansion {{decisions are made}} to strike an optimal balance between investment costs and lost sales costs. Motivated by current practices in the semiconductor and other high-tech industries, we assume that only minimal amounts of finished-goods inventories are held, due {{to the risk of}} obsolescence. We assume that when capacity is in short supply, management desires to ensure that a minimal service level for all product families is obtained. Our approach uses a novel <b>assumption</b> that demand <b>can</b> <b>be</b> <b>approximated</b> by a distribution whose support is a collection of rays emanating from a point and contained in real multi-dimensional space. These assumptions allow us to solve the problem as a max-flow, min-cut problem. Computational experiments show that large problems <b>can</b> <b>be</b> solved efficiently. 1...|$|R
40|$|Let (X,d) be {{a locally}} compact {{separable}} ultrametric space. Given a measure m on X and a function C defined {{on the set}} B of all balls B⊂ X we consider the hierarchical Laplacian L=L_C. The operator L acts in L^ 2 (X,m), is essentially self-adjoint, and has a purely point spectrum. Choosing a family {ε(B) }_B∈B of i. i. d. random variables, we define the perturbed function C(B) =C(B) (1 +ε(B)) and the perturbed hierarchical Laplacian L=L_C. All outcomes of the perturbed operator L are hierarchical Laplacians. In particular they all have purely point spectrum. We study the empirical point process M {{defined in terms of}} L-eigenvalues. Under some natural <b>assumptions</b> M <b>can</b> <b>be</b> <b>approximated</b> by a Poisson point process. Using a result of Arratia, Goldstein, and Gordon based on the Chen-Stein method, we provide total variation convergence rates for the Poisson approximation. We apply our theory to random perturbations of the operator D^α, the p-adic fractional derivative of order α > 0. This operator, related to the concept of p-adic Quantum Mechanics, is a hierarchical Laplacian which acts in L^ 2 (X,m) where X=Q_p is the field of p-adic numbers and m is Haar measure. It is translation invariant and the set Spec(D^α) consists of eigenvalues p^α k, k∈Z, each of which has infinite multiplicity...|$|R
40|$|International audienceThis {{contribution}} {{talks about}} the problem of the estimation of boundary conditions in beam structures. Boundary stiffness has {{an important role in the}} dynamic behavior of the structure. In various fields as modal active control, in case of a time-varying boundary, it is necessary to estimate this stiffness to update the controller model in order to guaranty its stability. In practice, this kind of identification problems <b>can</b> <b>be</b> understood as a determination of various spatial derivatives of transverse displacements. These quantities are difficult to estimate at boundaries mainly due to their high sensitivity to noise. The proposed method uses the <b>assumption</b> that displacements <b>can</b> <b>be</b> <b>approximated</b> by Taylor expansions on a domain near its boundaries. Then, spatial derivatives are estimated using particular pointwise derivatives estimators with annihilators. Annihilators are linear differential operators tuned to cancel undesired derivatives. Consequently, this approach enables the extraction of these quantities using a weighted spatial integration of the displacement field. Numerical simulations using exact and noisy data are shown in order to illustrate the main advantages of the proposed method...|$|R
40|$|Let f be a {{continuous}} function defined on Ω: = [0, 1] N which depends on only ℓ coordinate variables, f(x 1, [...] ., xN) = g(xi 1, [...] ., xiℓ). We {{assume that we}} are given m and are allowed {{to ask for the}} values of f at m points in Ω. If g is in Lip 1 and the coordinates i 1, [...] ., iℓ are known to us, then by asking for the values of f at m = L ℓ uniformly spaced points, we could recover f to the accuracy |g|Lip 1 L − 1 in the norm of C(Ω). This paper studies whether we can obtain similar results when the coordinates i 1, [...] ., iℓ are not known to us. A prototypical result of this paper is that by asking for C(ℓ) L ℓ (log 2 N) adaptively chosen point values of f, we can recover f in the uniform norm to accuracy |g|Lip 1 L − 1 when g ∈ Lip 1. Similar results are proven for more general smoothness conditions on g. Results are also proven under the <b>assumption</b> that f <b>can</b> <b>be</b> <b>approximated</b> to some tolerance ɛ (which is not known) by functions of ℓ variables. ...|$|R
40|$|Abstract: Let N be {{a compact}} simply {{connected}} smooth Riemannian manifold and p an arbitrary positive integer. For any map u from Rp+ 1 into N whose gradient is in Lp (Rp+ 1), the restriction of u to almost every p dimensional sphere in Rp+ 1 defines an homotopy class in πp(N) ([Wh]). Evaluating a fixed element z of Hom(πp(N), R) on this homotopy class thus gives amapΦz,u {{from the space}} of “generic ” p-spheres into R. The main result of the paper is to show that, under the <b>assumption</b> that u <b>can</b> <b>be</b> <b>approximated</b> by a W 1,p weakly convergent sequences of smooth maps in C ∞ (Rp+ 1,N), there exists a rectifiable Poincaré dualofΦz,u: a countable union Γ of C 1 curves in Rp+ 1 together with a Hausdorff H 1 −measurable real multiplicity function θ and orientation �Γ on Γ such that the intersection number between any “generic ” sphere S and this Poincaré dual equals Φz,u(S). More-over, we exhibit a nonnegative integer nz, depending only on z, such that Γ |θ|p(p+nz) − 1 dH 1 < ∞. We give cases of N, p and z for which this rational number p(p + nz) − 1 in the above integral is optimal. The construction of this Poincaré dual is based on 1 dimensional “bubbling ” described by the notion of “scans ” which was introduced in [HR 1]. ...|$|R
40|$|A {{major problem}} in the {{extraction}} of the reaction probability in bimolecular processes is the disentanglement from the influence of molecular diffusion. One of the strategies to overcome it makes use of reactive solvents in which the reactants {{do not need to}} diffuse to encounter each other. However, most of our quantitative understanding of chemical reactions in solution between free partners is based on the <b>assumption</b> that they <b>can</b> <b>be</b> <b>approximated</b> by spheres because rotation averages their mutual orientations. This condition may not be fulfilled when the reaction takes place on time scales faster than that of molecular reorientation. In this work, the fluorescence quenching of two very similar polyaromatic hydrocarbons with different electric dipole moments is measured. The concentration of a liquid electron-donating quencher is varied from very dilute solutions to pure quencher solutions. In both cases, the thermodynamics of the reactions are very similar and, according to the Marcus expression, the kinetics are expected to proceed at similar rates. However, one of them is 10 times faster in the pure quencher solution. This difference starts at relatively low quencher concentrations. An explanation based on the fluorophore–solvent dipole–dipole interaction and the consequent orientational solvent structure is provided. The orientational correlation between fluorophore and quencher is calculated by means of computer simulations. Important differences depending on the fluorophore dipole moment are found. The kinetics <b>can</b> <b>be</b> explained quantitatively with a reaction–diffusion model that incorporates the effects of the presence of the dipole moment and the rotational diffusion, only in the highest quencher concentration case, but not in dilute solutions, most likely due to fundamental limitations of the kinetic theory...|$|R
40|$|Hypercoulometry in electron-capture {{detectors}} (ECDs) {{has been}} repeatedly {{described in the}} literature and {{has been attributed to}} the space charge effect of analyte-derived anions migrating to the anode beyond the radioactive plasma [W. A. Aue and S. Kapila, J. Chromatogr., 188 (1980) 1]. However, the existence of a different kind ofhypercoulometry has recently been suggested by experiments using clean pulse conditions in a small-volume electron-capture detector [K. W. M. Siu, G. J. Gardner and S. S. Berman, J. Chromatogr., 330 (1985) 87]. The present study provides a speculative explanation of this 2 ̆ 2 second kind 2 ̆ 2 of hypercoulometry by relying on computer-aided simulation, and by using apparent rate constants from a measurement of ECD steady states under unipolar and bipolar drive conditions [K. W. M. Siu, S. S. Berman and W. A. Aue, J. Chromatogr., 408 (1987) 53]. Two salient features of this hypercoulometric response (vis-a-vis conventional ECD mechanisms) are that the rate constant for anion-cation neutralization is significantly smaller than the one for electron-cation recombination and that overall electrical neutrality prevails. As one of the consequences, steady state takes a much longer time to reach than in conventional model systems. The simulation characterizes 2 ̆ 2 hypercoulometry of the second kind 2 ̆ 2 as the charge effect of non-collected, analyte-derived anions in or near the radioactive plasma, which causes a larger cation concentration and hence a higher electron-cation recombination rate. Given certain simplifying <b>assumptions,</b> the effect <b>can</b> <b>be</b> <b>approximated</b> to a large extent by conventional, i. e. 2 ̆ 2 stirred reactor 2 ̆ 2 type kinetic modelling. The model is capable of producing strongly hypercoulometric response profiles that agree well with the experimental profiles measured earlier in the same detector [K. W. M. Siu, G. J. Gardner and S. S. Berman, J. Chromatogr., 330 (1985) 87]. Even when hypercoulometry is not observed, the internal detector processes remain the same. It is therefore suggested that a large proportion of hypocoulometric response in well-performing detectors also results from a protracted presence of anions and, in turn, an increase in the electron-cation recombination rate. © 1990...|$|R
5000|$|The noise <b>can</b> <b>be</b> <b>approximated</b> by a zero-mean Gaussian {{random process}} of {{variance}} [...] which is uncorrelated between trials and not time-locked {{to the event}} (this <b>assumption</b> <b>can</b> <b>be</b> easily violated, for example {{in the case of}} a subject doing little tongue movements while mentally counting the targets in an oddball paradigm).|$|R
5000|$|... <b>can</b> <b>be</b> <b>approximated</b> to {{the flame}} {{temperature}} of the fuel used. The flame temperature <b>can</b> <b>be</b> <b>approximated</b> to the adiabatic flame {{temperature of the}} fuel with corresponding air-to-fuel ratio and compression pressure, [...] <b>can</b> <b>be</b> <b>approximated</b> to the inlet air temperature.|$|R
50|$|The last <b>assumption</b> <b>can</b> <b>be</b> {{weakened}} {{by using the}} theory of distributions.The first two <b>assumptions</b> <b>can</b> <b>be</b> weakened as follows.|$|R
40|$|The {{magnetoencephalography}} (MEG) aims at {{reconstructing the}} unknown electric {{activity in the}} brain from the measurements of the magnetic field in the outer space. The MEG inverse problem is ill-posed and/or ill-conditioned thus further constraints are needed to guarantee a unique and stable solution. Assuming that neural sources are confined in small regions of the brain, the sparsity <b>assumption</b> <b>can</b> <b>be</b> used as a regularization term. Thus, {{the solution of the}} inverse problem <b>can</b> <b>be</b> <b>approximated</b> by iterative thresholding algorithms. In order to identify an efficient inversion method for the MEG problem, we compare the performance -efficiency, accuracy, computational load- of some thresholding algorithms when localizing a single neural source. The numerical tests will give some suggestions on the construction of an efficient algorithm to be used in real life applications...|$|R
25|$|Regression {{analysis}} {{and in particular}} ordinary least squares specifies that a dependent variable depends according to some function upon one or more independent variables, with an additive error term. Various types of statistical inference on the regression assume that the error term is normally distributed. This <b>assumption</b> <b>can</b> <b>be</b> justified by assuming that the error term is actually the sum {{of a large number}} of independent error terms; even if the individual error terms are not normally distributed, by the central limit theorem their sum <b>can</b> <b>be</b> well <b>approximated</b> by a normal distribution.|$|R
5000|$|Any {{continuous}} real {{function with}} compact support <b>can</b> <b>be</b> <b>approximated</b> uniformly by linear combinations of [...] and their shifted functions. This extends to those function spaces where any function therein <b>can</b> <b>be</b> <b>approximated</b> by continuous functions.|$|R
50|$|However, {{the problem}} {{does have a}} variant which is more {{tractable}}: if we assume no subset exceeds k≥3 elements, the answer <b>can</b> <b>be</b> <b>approximated</b> within a factor of k/2 + ε for any ε > 0; in particular, the problem with 3-element sets <b>can</b> <b>be</b> <b>approximated</b> within about 50%. In another more tractable variant, if no element occurs in more than k of the subsets, the answer <b>can</b> <b>be</b> <b>approximated</b> within a factor of k. This is also true for the weighted version.|$|R
25|$|Usually, the {{correction}} factor <b>can</b> <b>be</b> <b>approximated</b> as unity.|$|R
30|$|When N≫L, nk,e <b>can</b> <b>be</b> <b>approximated</b> {{as white}} noise.|$|R
50|$|Usually, the {{correction}} factor <b>can</b> <b>be</b> <b>approximated</b> as unity.|$|R
5000|$|For non-relativistic betas (...) , this {{expression}} <b>can</b> <b>be</b> <b>approximated</b> by: ...|$|R
5000|$|In comparison, {{the lateral}} {{resolution}} <b>can</b> <b>be</b> <b>approximated</b> as: ...|$|R
5000|$|The free {{electron}} concentration n <b>can</b> <b>be</b> <b>approximated</b> bywhere ...|$|R
5000|$|In many applications, a third {{simplifying}} <b>assumption</b> <b>can</b> <b>be</b> made: ...|$|R
5000|$|Consequentially, {{the forces}} of the snake <b>can</b> <b>be</b> <b>approximated</b> as ...|$|R
5000|$|The knudsen layer {{thickness}} <b>can</b> <b>be</b> <b>approximated</b> by , given by ...|$|R
2500|$|It <b>can</b> <b>be</b> <b>approximated</b> {{both from}} partial {{pressure}} and molar fraction: ...|$|R
2500|$|More generally, {{the rate}} of orbital decay <b>can</b> <b>be</b> <b>approximated</b> by ...|$|R
5000|$|For a gas, , so the molar {{refractivity}} <b>can</b> <b>be</b> <b>approximated</b> by ...|$|R
