877|232|Public
5|$|Allocators {{should be}} copy-constructible. An <b>allocator</b> for objects of type T can be {{constructed}} from an <b>allocator</b> for objects of type U. If an <b>allocator,</b> A, allocates a region of memory, R, then R can only be deallocated by an <b>allocator</b> that compares equal to A.|$|E
5|$|Allocators are {{required}} to supply a template class member template [CODE] which enables the possibility of obtaining a related <b>allocator,</b> parameterized {{in terms of a}} different type. For example, given an <b>allocator</b> type IntAllocator for objects of type int, a related <b>allocator</b> type for objects of type long could be obtained using IntAllocator::rebind::other.|$|E
5|$|Another viable use {{of custom}} allocators is for {{debugging}} memory-related errors. This {{could be achieved}} by writing an <b>allocator</b> that allocates extra memory in which it places debugging information. Such an <b>allocator</b> {{could be used to}} ensure that memory is allocated and deallocated by the same type of <b>allocator,</b> and also provide limited protection against overruns.|$|E
40|$|Scalable and locality-aware {{multiprocessor}} memory <b>allocators</b> {{are critical}} for harnessing the potential of emerging multithreaded and multicore architectures. This paper evaluates two state-of-the-art generic multithreaded <b>allocators</b> designed for both scalability and locality, against custom <b>allocators,</b> written to optimize the multithreaded implementation of parallel mesh generation algorithms. We use three different algorithms in terms of communication/synchronization requirements. The implementations of all three algorithms are heavily dependent on dynamically allocated pointer-based data structures and all three use optimized internal memory <b>allocators</b> based on application-specific knowledge. For our study we used memory <b>allocators</b> which are implemented and evaluated on two real multiprocessors with a multi-SMT (quad Hyperthreaded Intel) and a multi-CMP/SMT (dual IBM Power 5) organization. Our results indicate that properly engineered generic memory <b>allocators</b> can come close or sometimes exceed (in sequential allocation) the performance of custom multi-threaded <b>allocators.</b> These results suggest that {{in the near future}} {{we should be able to}} develop generic multi-threaded <b>allocators</b> that can adapt to application charac-teristics and increase productivity without compromising performance...|$|R
500|$|The 2011 {{revision}} of the C++ Standard removed the weasel words requiring that <b>allocators</b> of a given type always compare equal and use normal pointers. [...] These changes make stateful <b>allocators</b> much more useful and allow <b>allocators</b> to manage out-of-process shared memory. The current purpose of <b>allocators</b> {{is to give the}} programmer control over memory allocation within containers, rather than to adapt the address model of the underlying hardware. [...] In fact, the revised standard eliminated the ability of <b>allocators</b> to represent extensions to the C++ address model, formally (and deliberately) eliminating their original purpose.|$|R
5000|$|Although a {{conforming}} standard library implementation {{is allowed}} {{to assume that the}} <b>allocator's</b> [...] and [...] are simply typedefs for [...] and , library implementors are encouraged to support more general <b>allocators.</b>|$|R
5|$|Like all C++ class templates, instantiations of {{standard}} library containers with different <b>allocator</b> arguments are distinct types. A function expecting an std::vector argument will therefore only accept a vector instantiated with the default <b>allocator.</b>|$|E
5|$|While Stepanov had {{originally}} intended allocators to completely encapsulate the memory model, the standards committee {{realized that this}} approach would lead to unacceptable efficiency degradations. To remedy this, additional wording {{was added to the}} <b>allocator</b> requirements. In particular, container implementations may assume that the allocator's type definitions for pointers and related integral types are equivalent to those provided by the default <b>allocator,</b> and that all instances of a given <b>allocator</b> type always compare equal, effectively contradicting the original design goals for allocators and limiting the usefulness of allocators that carry state.|$|E
5|$|A popular {{approach}} {{to improve performance}} {{is to create a}} memory pool-based <b>allocator.</b> Instead of allocating memory every time an item is inserted or removed from a container, a large block of memory (the memory pool) is allocated beforehand, possibly at the startup of the program. The custom <b>allocator</b> will serve individual allocation requests by simply returning a pointer to memory from the pool. Actual deallocation of memory can be deferred until the lifetime of the memory pool ends. An example of memory pool-based allocators {{can be found in the}} Boost C++ Libraries.|$|E
40|$|The {{bachelor}} thesis describes memory allocation. Work {{begins with}} description of mechanism, system calls and data structures used in memory <b>allocators.</b> Goals of memory allocation ares listed along with problems {{which must be}} avoided. Afterwards construction and allocating of popular memory <b>allocators</b> is described. Work ends with comparison of memory <b>allocators</b> based on time of execution of programs and memory usage, on which conclusion is based...|$|R
5|$|In C++ {{computer}} programming, <b>allocators</b> are {{an important}} component of the C++ Standard Library. The standard library provides several data structures, such as list and set, commonly referred to as containers. A common trait among these containers is their ability to change size during the execution of the program. To achieve this, some form of dynamic memory allocation is usually required. <b>Allocators</b> handle all the requests for allocation and deallocation of memory for a given container. The C++ Standard Library provides general-purpose <b>allocators</b> that are used by default, however, custom <b>allocators</b> may also be supplied by the programmer.|$|R
5|$|Although a {{conforming}} standard library implementation {{is allowed}} {{to assume that the}} <b>allocator's</b> A::pointer and A::const_pointer are simply typedefs for T* and T const*, library implementors are encouraged to support more general <b>allocators.</b>|$|R
5|$|Any {{class that}} {{fulfills}} the <b>allocator</b> requirements {{can be used}} as an <b>allocator.</b> In particular, a class A capable of allocating memory for an object of type T must provide the types A::pointer, A::const_pointer, A::reference, A::const_reference, and A::value_type for generically declaring objects and references (or pointers) to objects of type T. It should also provide type A::size_type, an unsigned type which can represent the largest size for an object in the allocation model defined by A, and similarly, a signed integral A::difference_type that can represent the difference between any two pointers in the allocation model.|$|E
5|$|DragonFly {{switched}} to multiprocessor safe slab <b>allocator,</b> which requires neither mutexes nor blocking operations for memory assignment tasks. It was eventually ported into standard C library in the userland, where it replaced FreeBSD's malloc implementation.|$|E
5|$|Much of the system's core, {{including}} the LWKT subsystem, the IPI messaging subsystem {{and the new}} kernel memory <b>allocator,</b> are lockless, meaning that they work without using mutexes, with each process operating on a single CPU. Critical sections are used to protect against local interrupts, individually for each CPU, guaranteeing that a thread currently being executed will not be preempted.|$|E
5|$|Nevertheless, {{there are}} many {{scenarios}} where customized <b>allocators</b> are desirable. Some {{of the most common}} reasons for writing custom <b>allocators</b> include improving performance of allocations by using memory pools, and encapsulating access to different types of memory, like shared memory or garbage-collected memory. In particular, programs with many frequent allocations of small amounts of memory may benefit greatly from specialized <b>allocators,</b> both in terms of running time and memory footprint.|$|R
500|$|Stepanov later commented that, while <b>allocators</b> [...] "are {{not such}} a bad [...] in theory (...) nfortunately they cannot work in practice". He {{observed}} that to make <b>allocators</b> really useful, a change to the core language with regards to references was necessary.|$|R
40|$|Scratch-Pad memory (SPM) <b>allocators</b> that {{exploit the}} {{presence}} of affine references to arrays are important for scientific benchmarks. On the other hand, such <b>allocators</b> have so far been limited in their general applicability. In this paper we propose an integrated scheme {{that for the first}} time combines the specialized solution for affine program allocation with a general framework for other code. We find that our integrated framework does as well or outperforms other <b>allocators</b> for a variety of SPM sizes. 1...|$|R
5|$|An <b>allocator,</b> A, for {{objects of}} type T {{must have a}} member {{function}} with the signature A::pointer A::allocate(size_type n, A::const_pointer hint = 0). This function returns a pointer to the first element of a newly allocated array large enough to contain n objects of type T; only the memory is allocated, and the objects are not constructed. Moreover, an optional pointer argument (that points to an object already allocated by A) {{can be used as}} a hint to the implementation about where the new memory should be allocated in order to improve locality. However, the implementation is free to ignore the argument.|$|E
5|$|Improved {{reliability}} for on-disk structures: ReFS uses B+ trees for all on-disk structures including metadata and file data. Metadata and file data are organized into tables {{similar to a}} relational database. The file size, number of files in a folder, total volume size and number of folders in a volume are limited by 64-bit numbers; as a result ReFS supports a maximum file size of 16 exabytes, a maximum of 18.4 × 1018 folders and a maximum volume size of 1 yottabyte (with 64 KB clusters) which allows large scalability with no practical limits on file and folder size (hardware restrictions still apply). Free space is counted by a hierarchical <b>allocator</b> which includes three separate tables for large, medium, and small chunks. File names and file paths are each limited to a 32 KB Unicode text string.|$|E
25|$|The trust game, an {{extension}} of the dictator game, provides additional evidence for strong reciprocity. The trust game extends the dictator game by multiplying the amount given by the <b>allocator</b> to the recipient by some value greater than one, and then allowing the recipient to give some amount back to the <b>allocator.</b> Once again in this case, if participants are trying to maximize their payoff, recipient should give nothing back to the <b>allocator,</b> and the <b>allocator</b> should assign nothing to the recipient. A 2009 meta analysis of 84 trust game studies revealed that the <b>allocator</b> gave an average of 51% and that the receiver returned an average of 37%.|$|E
40|$|Heterogeneous multi-processors {{platforms}} are {{an interesting}} option to satisfy the computational performance of dynamic multi-media applications at a reasonable energy cost. Today, almost no support exists to energy-efficiently manage the data of a multi-threaded application on these platforms. In this paper we show that the assignment of data of dynamically created /deleted tasks to the shared memory has a large impact on the energy consumption. We present two dynamic memory <b>allocators</b> which solve the bank assignment problem for shared multi-banked SDRAM memories. Both <b>allocators</b> assign the tasks' data to the available SDRAM banks such {{that the number of}} page-misses is reduced. We have measured large energy savings with these <b>allocators</b> compared to existing dynamic memory <b>allocators</b> for several task-sets based on MediaBench[5]. ...|$|R
50|$|Thread-safe memory heap {{and memory}} pool <b>allocators.</b>|$|R
40|$|We {{test the}} {{robustness}} of behavior in dictator games by offering <b>allocators</b> {{the choice to}} play an unattractive lottery. With this lottery option, mean transfers from <b>allocators</b> to recipients substantially decline, partly because many <b>allocators</b> now keep the entire endowment for themselves (without playing the lottery). In our standard dictator game, the median transfer amounts to 41 % of the dictators' endowment. Once the lottery option is present, the median transfer falls to zero. Introducing an additional unattractive choice thus leads subjects to violate the weak axiom of revealed preference (WARP). ...|$|R
25|$|One {{experimental}} game used {{to measure}} levels of cooperation is the dictator game. In the standard form of the dictator game, there are two anonymous unrelated participants. One participant is assigned {{the role of the}} <b>allocator</b> and the other the role of the recipient. The <b>allocator</b> is assigned some amount of money, which they can divide in any way they choose. If a participant is trying to maximize their payoff, the rational solution (nash equilibrium) for the <b>allocator</b> to assign nothing to the recipient. In a 2011 meta study of 616 dictator game studies, Engel found an average allocation of 28.3%, with 36% of participants giving nothing, 17% choosing the equal split, and 5.44% give the recipient everything.|$|E
25|$|Manages virtual memory, {{controlling}} {{memory protection}} and the paging of memory {{in and out}} of physical memory to secondary storage, and implements a general-purpose <b>allocator</b> of physical memory. It also implements a parser of PE executables that lets an executable be mapped or unmapped in a single, atomic step.|$|E
25|$|The {{placement}} delete {{functions are}} called from placement new expressions. In particular, {{they are called}} if the constructor of the object throws an exception. In such a circumstance, {{in order to ensure}} that the program does not incur a memory leak, the placement delete functions are called. A placement new expression first calls the placement operator new function, then calls the constructor of the object upon the raw storage returned from the <b>allocator</b> function. If the constructor throws an exception, it is necessary to deallocate that storage before propagating the exception back to the code that executed the placement new expression, and that is the purpose of the placement delete functions.|$|E
50|$|Further, {{much time}} has passed since the prior C++ {{standard}}. Much code using the standard library has been written. This has revealed parts of the standard libraries that could use some improving. Among the many areas of improvement considered were standard library <b>allocators.</b> A new scope-based model of <b>allocators</b> was included in C++11 to supplement the prior model.|$|R
5|$|<b>Allocators</b> {{were invented}} by Alexander Stepanov {{as part of}} the Standard Template Library (STL). They were {{originally}} intended as a means to make the library more flexible and independent of the underlying memory model, allowing programmers to utilize custom pointer and reference types with the library. However, in the process of adopting STL into the C++ standard, the C++ standardization committee realized that a complete abstraction of the memory model would incur unacceptable performance penalties. To remedy this, the requirements of <b>allocators</b> were made more restrictive. As a result, the level of customization provided by <b>allocators</b> is more limited than was originally envisioned by Stepanov.|$|R
25|$|Placement syntax {{has four}} main uses: default placement, {{preventing}} exceptions, custom <b>allocators,</b> and debugging.|$|R
25|$|Although {{this process}} might sound slow, {{it is very}} cache-local and highly {{parallelizable}} {{due to the lack}} of register dependencies and therefore in fact has excellent performance on modern out-of-order execution CPUs. A red-black tree for example performs much better on paper, but is highly cache-unfriendly and causes multiple pipeline and TLB stalls on modern CPUs which makes that algorithm bound by memory latency rather than CPU speed. In comparison, a bitwise trie rarely accesses memory, and when it does, it does so only to read, thus avoiding SMP cache coherency overhead. Hence, it is increasingly becoming the algorithm of choice for code that performs many rapid insertions and deletions, such as memory allocators (e.g., recent versions of the famous Doug Lea's <b>allocator</b> (dlmalloc) and its descendents).|$|E
500|$|One of {{the main}} reasons for writing a custom <b>allocator</b> is performance. Utilizing a {{specialized}} custom <b>allocator</b> may substantially improve the performance or memory usage, or both, of the program. [...] The default <b>allocator</b> uses operator new to allocate memory. This is often implemented as a thin layer around the C heap allocation functions, which are usually optimized for infrequent allocation of large memory blocks. This approach may work well with containers that mostly allocate large chunks of memory, like vector and deque. However, for containers that require frequent allocations of small objects, such as map and list, using the default <b>allocator</b> is generally slow. Other common problems with a malloc-based <b>allocator</b> include poor locality of reference, and excessive memory fragmentation.|$|E
500|$|The C++11 {{standard}} has {{enhanced the}} <b>allocator</b> interface to allow [...] "scoped" [...] allocators, so that containers with [...] "nested" [...] memory allocations, such as vector of strings or {{a map of}} lists of sets of user-defined types, can ensure that all memory is sourced from the container's <b>allocator.</b>|$|E
40|$|This paper compares {{a set of}} Virtual Machine (VM) <b>allocators</b> for Cloud Data Centers (DCs) that {{perform the}} joint {{allocation}} of computing and network resources. VM requests are {{defined in terms of}} system (CPU, RAM and Disk) and network (Bandwidth) resources. As concerns the first ones, we allocate VM resources following two different policies, namely Best Fit and Worst Fit, corresponding to consolidation and spreading strategies respectively. For each server, the <b>allocators</b> choose the network path that minimizes electrical power consumption, evaluated according to a precise model, specifically designed for network switches. More specifically, we implemented different allocation algorithms based on Fuzzy Logic, Single and Multi-Objective optimization. Simulation tests have been carried out to evaluate the performance of the <b>allocators</b> in terms of number of allocated VMs for each policy. Finally, it is worth mentioning that we have designed the proposed <b>allocators</b> as a building block of a Software Defined Networking (SDN) orchestrator...|$|R
40|$|We {{experimentally}} {{investigate the}} e¤ect of endowment allocation procedures on social preferences using a two-stage dictator game. In the …rst stage, {{participants who were}} randomly selected as <b>allocators</b> had to perform a task in order to earn money. Better performance on the task resulted in higher earnings. In our baseline meritocratic treatment, the allocators’initial endowment was set equal to their individual earnings. We compared this with an egalitarian treatment whereby the allocators’ initial endowment was set equal to the average earnings of all <b>allocators.</b> Essentially, high performers were taxed and underperformers were subsidized by the high performers. In the second stage, the <b>allocators</b> had to divide their endowment with the recipients. We show that the <b>allocators</b> were more generous in the egalitarian treatment than in the meritocratic treatment. Interestingly, being taxed did not reduce the high performers’generosity but being subsidized did signi…cantly increase the underperformers’generosity. Thus, being treated kindly induced the underperformers to reciprocate forward to other people...|$|R
40|$|We {{experimentally}} {{investigate the}} effect of endowment allocation procedures on social preferences using a two-stage dictator game. In the first stage, participants who were randomly selected as <b>allocators</b> had to perform a task in order to earn money. Better performance on the task resulted in higher earnings. In our baseline meritocratic treatment, the allocators' initial endowment was set equal to their individual earnings. We compared this with an egalitarian treatment whereby the allocators' initial endowment was set equal to the average earnings of all <b>allocators.</b> Essentially, high performers were taxed and under performers were subsidized by the high performers. In the second stage, the <b>allocators</b> had to divide their endowment with the recipients. We show that the <b>allocators</b> were more generous in the egalitarian treatment than in the meritocratic treatment. Interestingly, being taxed did not reduce the high performers' generosity but being subsidized did significantly increase the under performers' generosity. Thus, being treated kindly induced the under performers to reciprocate forward to other people. ...|$|R
