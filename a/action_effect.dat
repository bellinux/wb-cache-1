104|2937|Public
5000|$|Graded Hammer Standard (GHS), {{formerly}} Hammer Effect (HE) or <b>Action</b> <b>Effect</b> (AE) ...|$|E
50|$|Be {{careful when}} tasting for {{identification}} purposes, and {{only take a}} tiny piece. The delayed <b>action</b> <b>effect</b> masks an extremely hot (maybe the hottest) mushroom.|$|E
50|$|Characters {{have a set}} of Attributes, Powers, and Skills. Attributes are {{the nine}} qualities every {{character}} has. Powers and Skills reflect innate ability or training. Attributes are divided into three categories (Physical, Mental, and Spiritual) and three attribute types (<b>Action,</b> <b>Effect,</b> and Resistance). For example, when Superman punches someone, he uses Dexterity to see if he connects, Strength to see how hard he hits, and the opposing character's Body to see how much damage he did. The value of a Power usually serves as both Active Value (AV) and Effect Value (EV) resisted by the target's Resistance Value (RV). All actions taken, even against inanimate objects, use that system. For example, investigators use AV and EV against a RV to determine the quality of information their efforts gather.|$|E
3000|$|... a {{retrospective}} ownership state is activated based on co-occurrence of predicted <b>action</b> <b>effects</b> and <b>action</b> <b>effects</b> sensed afterwards [...]...|$|R
40|$|According to ideomotor theories, {{intended}} effects {{caused by a}} certain action are anticipated before action execution. In the present study, we examined {{the question of whether}} <b>action</b> <b>effects</b> play a role in cued task switching. In our study, the participants practiced task-response-effect mappings in an acquisition phase, in which <b>action</b> <b>effects</b> occur after a response in a certain task context. In the ensuing transfer phase, the previously practiced mappings were changed in a random, unpredictable task-response-effect mapping. When changed into unpredictable <b>action</b> <b>effects,</b> RT as well as switch costs increased, but this occurred mainly in trials with short preparation time and not with long preparation time. Moreover, switch costs were generally smaller with predictable <b>action</b> <b>effects</b> than with unpredictable <b>action</b> <b>effects.</b> This suggests that anticipated task-specific <b>action</b> <b>effects</b> help to activate the relevant task set before task execution when the task is not yet already prepared based on the cue...|$|R
40|$|In {{everyday}} {{cases of}} tool use, proximal <b>action</b> <b>effects</b> (i. e. operating {{the navigation system}} of vehicle via a multi-functional control button) and distal <b>action</b> <b>effects</b> (i. e. resulting effects on the medium´s display) often diverge or are even conflicting. In other words, the human information processing system is often confronted with more or less distinct <b>action</b> <b>effects,</b> like bodily related consequences of manual actions vs. medium related <b>action</b> <b>effects.</b> Nevertheless - referring to the navigation system example - {{in some cases the}} destination selection process seems to operate flawlessly, whereas in some cases it does not. Due to this phenomenon the question on how the human information processing system solves these kinds of scenarios may arise. According to theories of common coding, the present work considers proprioceptive as well as visual information to be represented within a common cognitive domain. It is assumed that both sources of information interact on this domain. The following sections provide a brief overview of the studies comprised in this dissertation. Experiments reported in study 1 examine the role of proximal and distal <b>action</b> <b>effects</b> in a closed loop task of sensorimotor control. Particularly interesting in this study is the introduction of different gain factors that systematically perturb the relation between covert hand movements on a digitizer tablet and resulting cursor movements on a screen. This scenario comes along with a second perturbation in the form of rotated visual feedback. Results were discussed with respect to theories of common coding and against the background of beneficial or detrimental effects of feature overlap. For instance, when participants are asked to replicate an initial hand movement without visual feedback, hand amplitudes vary in accordance with predecessing display amplitudes. Adding a second perturbation (Experiment 1 (2) : 90 ° (180 °) rotation of visual feedback) reduces these aftereffects only when the discrepancy between hand and display movement is obvious. In summary, distal <b>action</b> <b>effects</b> do assimilate proximal <b>action</b> <b>effects</b> when the proprioceptive/tactile feedback show feature overlap with former presented visual feedback on the display. Since the first study examines the effects of perturbed visual <b>action</b> <b>effects</b> on proximal <b>action</b> <b>effects</b> by employing a motor replication task, experiments reported in study 2 attempt to assess the inverse question by introducing conditions containing a motor replication task {{on the one hand and}} a visual replication task on the other hand. Herein, ask about intra- and inter-modal recall of either proprioceptive or visual information, and whether there are any differences between proximal and distal <b>action</b> <b>effects.</b> At first, mechanisms of information processing seem to depend on the output modality. That is, both, proprioceptive and visual <b>action</b> <b>effects</b> interfere with the motor modality whilst visual but not proprioceptive <b>action</b> <b>effects</b> exhibit effects on the visual modality. Second, however, inter-modal information processing shows higher susceptibility to interference, which seems to depend on the output modality. In a nutshell, the results provide useful implications for tool use, since the optimized processing of conflicting <b>action</b> <b>effects</b> is a precondition for successful tool use. This work generally aims at extending the present body of research on multimodal information processing in tool use by referring to a working model which will guide through this thesis and practically illustrate complex coherencies in the field of multimodal information processing...|$|R
40|$|It is well {{established}} that we can pick up <b>action</b> <b>effect</b> associations when acting in a free-choice intentional mode. However, it is less clear whether and when <b>action</b> <b>effect</b> associations are learnt and actually affect behavior if we are acting in a forced-choice mode, applying a specific stimulus-response (S-R) rule. In the present study, we investigated whether response selection difficulty imposed by S-R rules influences the initial rapid learning and the behavioral expression of previously learnt but weakly practiced <b>action</b> <b>effect</b> associations when those are re-activated by effect exposure. Experiment 1 showed that the rapid acquisition of <b>action</b> <b>effect</b> associations is not directly influenced by response selection difficulty. By contrast, the behavioral expression of re-activated <b>action</b> <b>effect</b> associations is prevented when actions are directly activated by highly over-learnt response cues and thus response selection difficulty is low. However, all three experiments showed that if response selection difficulty is sufficiently high during re-activation, the same <b>action</b> <b>effect</b> associations do influence behavior. Experiment 2 and 3 revealed {{that the effect of}} response selection difficulty cannot be fully reduced to giving action effects more time to prime an action, but seems to reflect competition during response selection. Finally, the present data suggest that when multiple novel rules are rapidly learnt in succession, which requires a lot of flexibility, <b>action</b> <b>effect</b> associations continue to influence behavior only if response selection difficulty is sufficiently high. Thus, response selection difficulty might modulate the impact of experiencing multiple learning episodes on <b>action</b> <b>effect</b> expression and learning, possibly via inducing different strategies...|$|E
40|$|Automatic {{acquisition}} of <b>action</b> <b>effect</b> associations {{may serve as}} a parsimonious account of how people acquire the basis for intentionally controlled action. However, recent research suggests that learning or the expression of <b>action</b> <b>effect</b> links might depend on whether task demands impose either a stimulus based mode of action control or an intention based action control mode. In the current study we develop a paradigm that allows the mode of action control to be varied via instructions while keeping stimuli identical. Participants were to respond to the location of a cloud of dots. Their actions were followed by predictable visual effects, either consistently congruent or incongruent with the location of the action. In Experiment 1, a displaced new cloud of random dots was presented as a spatial <b>action</b> <b>effect.</b> In Experiment 2 an arrow was presented as effect with a pointing direction congruent or incongruent to the response position. The location of the stimulus in the reference frame was easy to detect in some of the trials while the location of the cloud of dots was completely ambiguous in others. The instruction manipulation targeted the latter trials, suggesting to one group of participants to freely choose a key in a difficult trial, while asking another group to react to their spontaneous impression {{in the event of a}} difficult stimulus. In this way, we aimed at rendering actions either as stimulus driven or internally generated. By this we could investigate how effect anticipation changed with practice depending on action mode. We employed the impact of <b>action</b> <b>effect</b> compatibility on speed and choice of action as a measure for <b>action</b> <b>effect</b> anticipation. Our results suggest that <b>action</b> <b>effect</b> associations can be acquired when instructions suggest stimulus based action control or intention based action control. Instructions aiming at the mode of task processing can influence when and how <b>action</b> <b>effect</b> links influence behavior...|$|E
40|$|Voluntary {{actions are}} thought to be {{selected}} with respect to their intended goal. Converging data suggests that medial frontal cortex plays a crucial role in linking actions to their predicted effects. Recent neuroimaging data also suggests that during action selection, the brain pre-activities the representation of the predicted <b>action</b> <b>effect.</b> We review evidence of <b>action</b> <b>effect</b> prediction, both in terms of its neurophysiological basis as well as its functional consequences. By assuming that action preparation includes activation of the predicted sensory consequences of the action, we provide a mechanism to understand sensory attenuation and intentional binding. In this account, sensory attenuation results from more difficult discrimination between the observed <b>action</b> <b>effect</b> and the pre-activation of the predicted effect, as compared to when no (or incorrect) prediction is present. Similarly, a predicted <b>action</b> <b>effect</b> should also reach the threshold of awareness faster (intentional binding), if its perceptual representation is pre-activated. By comparing this potential mechanism to mental imagery and repetition suppression we propose a possible neural basis for the processing of predicted action effects. © 2011 Elsevier Ltd...|$|E
40|$|The {{implications}} of an ideomotor approach to action control were investigated. In Experiment 1, participants made manual responses to letter stimuli {{and they were}} presented with response-contingent color patches, i. e., colored <b>action</b> <b>effects.</b> This rendered stimuli of {{the same color as}} an action's effect effective primes of that action, suggesting that bilateral associations were created between <b>actions</b> and the <b>effects</b> they produced. Experiment 2 combined this set-up with a manual Stroop task, i. e., participants responded to congruent, neutral, or incongruent color-word compounds. Standard Stroop effects were observed in a control group without <b>action</b> <b>effects</b> and in a group with target-incompatible <b>action</b> <b>effects,</b> but the reaction time Stroop effect was eliminated if actions produced target-compatible color effects (e. g., blue word fi left key fi blue patch). Experiment 3 did not replicate this interaction between target-effect compatibility and color-word congruency with color words as <b>action</b> <b>effects,</b> which rules out semantically based accounts. Theoretical implications for both action-effect acquisition and the Stroop effect are discussed. It is suggested that learning <b>action</b> <b>effects,</b> the features of which overlap with the target, allows and motivates people to recode their actions in ways that make them more stimulus-compatible. This provides a processing shortcut for translating the relevant stimulus into the correct response and, thus, shields processing from the impact of competing word distractors...|$|R
5000|$|Molecular Biology of Diabetes, Part II: Insulin <b>Action,</b> <b>Effects</b> on Gene Expression and Regulation, and Glucose Transport, Boris Draznin (Editor), Derek LeRoith (Editor), 1994, ...|$|R
40|$|This paper {{presents}} {{the development of}} a method for determining the probability distribution of extreme traffic <b>action</b> <b>effects</b> as a function of parameters describing a bridge and traffic, referred to as site characteristics. This method is {{based on the results of}} computer simulations of traffic <b>action</b> <b>effects.</b> The simulation program generates random traffic actions for defined traffic conditions and determines the frequency distribution of maximum static effects. The paper describes in detail the simulation of traffic <b>action</b> <b>effects</b> and the general statistical model of traffic actions which is used. Simulation results have been used to derive semi-empirical relationships between site characteristics and the parameters of a type III extreme value distribution of maximum effects. The paper {{presents the}}se relationships and explains how this probabilistic model can be used for considering site specific traffic actions. INTRODUCTION Background The static effects of traffic result from th [...] ...|$|R
40|$|Research on {{embodied}} {{approaches to}} language comprehension {{suggests that we}} understand linguistic descriptions of actions by mentally simulating these actions. Evidence {{is provided by the}} action-sentence compatibility effect (ACE) which shows that sensibility judgments for sentences are faster when the direction of the described action matches the response direction. In two experiments, we investigated whether the ACE relies on actions or on intended action effects. Participants gave sensibility judgments of auditorily presented sentences by producing an <b>action</b> <b>effect</b> on a screen at a location near the body or far from the body. These action effects were achieved by pressing a response button that was located in either the same spatial direction as the <b>action</b> <b>effect,</b> or in the opposite direction. We used a go/no-go task in which the direction of the to-be-produced <b>action</b> <b>effect</b> was either cued at the onset of each sentence (Experiment 1) or at different points in time before and after sentence onset (Experiment 2). Overall, results showed a relationship between the direction of the described action and the direction of the <b>action</b> <b>effect.</b> Furthermore, Experiment 2 indicated that depending on the timing between cue presentation and sentence onset, participants responded either faster when the direction of the described action matched the direction of the <b>action</b> <b>effect</b> (positive ACE), or slower (negative ACE). These results provide evidence that the comprehension of action sentences involves the activation of representations of action effects. Concurrently activated representations in sentence comprehension and action planning can lead to both priming and interference, which is discussed {{in the context of the}} theory of event coding...|$|E
40|$|The {{commonly}} held {{view that the}} mechanism of osmotic pressure is a mass <b>action</b> <b>effect</b> at the semi-permeable membrane has recently been challenged by several authors who propose that solute molecules, in bombarding the free surface of the solution, subject the solvent to a negative hydrostatic pressure. Thus, they argue that osmotic pressure is a purely hydrostatic phenomenon. Experimental findings that they cite in support of their concept are here analyzed and shown {{to be consistent with}} the mechanism of a mass <b>action</b> <b>effect</b> at the semipermeable membrane...|$|E
40|$|Summary. The Simon effect {{indicates}} that choice reac-tions {{can be performed}} more quickly if the response corre-sponds spatially to the stimulus- even when stimulus location is irrelevant to the task. Two experiments tested an intentional approach to the Simon effect that assigns a critical role to the cognitively represented action goal (i. e., the intended <b>action</b> <b>effect).</b> It was assumed that the direc-tion of the Simon effect depends on stimulus-goal corre-spondence, that is, that responses are faster with spatial correspondence of stimulus and intended <b>action</b> <b>effect.</b> Ex-periment 1 confirmed that {{the direction of the}} Simon effect was determined by spatial correspondence of stimulus and intended <b>action</b> <b>effect,</b> the latter having been manipulated by different instructions. Experiment 2 indicated that ef-fects of correspondences unrelated to the action goal (i. e., stimulus to hand location or to anatomical mapping of the hand), contributed additively to the resulting Simon effect. It is discussed how current approaches to the Simon effect can be elaborated to account for these results...|$|E
40|$|AbstractProbabilistic {{modeling}} {{of the failure}} process of a structural multi-element system with brittle behavior of the elements {{is much more difficult}} as compared with rigid-ideal-plastic structures. The basic reason for this is the redistribution of <b>action</b> <b>effects</b> and possible influence of the load-path history on the sequence of failures of individual elements, which strengths are considered as random variables. In the paper, a certain concept of systems with no-unloading is applied in a self-consistent way for probabilistic study of such systems. It is proved for the system with no-unloading that, within the well-defined assumptions on the <b>action</b> <b>effects</b> rule, the probability of system failure under a given action can be calculated via a fit-for-purpose analytical formula. For systems allowing unloading, a set of the so-called majorant <b>action</b> <b>effects</b> is introduced, which makes it possible to find an effective upper bound for the failure probability of the system with unloading...|$|R
40|$|Goal-directed action presupposes the {{previous}} integration of actions and their perceptual consequences (action-effect binding). One function of action-effect bindings is to select actions by anticipating their consequences. Another, not yet well understood function is {{the prediction of}} action-contingent feedback. We used a probabilistic learning task and ERP analyses to compare the processing of explicit, performance-related feedback with the processing of task-irrelevant response-contingent stimuli. Replicating earlier findings, we found that negative performance feedback produced a feedback-related negativity (NFB), presumably related to response outcome evaluation. Interestingly, low-probability but task-irrelevant <b>action</b> <b>effects</b> elicited a signal similar to the NFB, {{even though it had}} a shorter duration. Response delays on trials following negative feedback and following low-probability <b>action</b> <b>effects</b> were correlated with one another. These observations suggest that automatically acquired action-effect relations are exploited for anticipating upcoming events. Like task-relevant performance feedback, task-irrelevant <b>action</b> <b>effects</b> serve as a basis for action monitoring processes, presumably mediated by medial frontal cortex...|$|R
40|$|Voluntary actions affect {{subsequent}} perception. For example, {{an action}} that precedes an auditory stimulus is perceived to have occurred later in time than is actually the case, while the auditory stimulus is perceived earlier in time. This effect is known as intentional binding. Current literature regarding <b>action</b> <b>effects</b> focuses on perception of a single sensory modality while the effects on perception of multiple modalities remain largely unknown. The present thesis explored how actions influenced the timing of perceived multisensory events. Additionally, this thesis investigated differences in voluntary compared to involuntary actions on subsequent perception. In Chapter 2, <b>action</b> <b>effects</b> on perceived onsets of visual and tactile stimuli were explored. This question was extended to other bimodal pairs, including audiovisual and audiotactile, in Chapter 3. Lastly, in Chapter 4, <b>action</b> <b>effects</b> on temporal resolution were investigated. In all the experiments, participants performed a chosen or a fixed button press that followed a bimodal temporal order judgment (TOJ) task. To investigate the influence of spatial proximity between actions and stimuli on binding, in Chapters 2 and 3, eac...|$|R
40|$|Sensory {{attenuation}} {{of voluntary}} action effects {{has been widely}} reported in both somatosensory and auditory domains. However, relatively little {{research has focused on}} physiological measures of sensory attenuation of visual action effects. One previous study found, perhaps surprisingly, that both auditory and visual sensory attenuation were manifested as decreased ERP amplitude over the vertex. The present study aimed to extend these findings using a novel paradigm in which voluntary actions were either associated with a visual <b>action</b> <b>effect</b> or to no effect. Crucially, this allowed us to explore both sensory attenuation (by comparing ERPs to action-triggered versus externally triggered stimuli) and <b>action</b> <b>effect</b> prediction (by comparing actions that triggered a stimulus with actions that did not). With regard to sensory attenuation, we found that attenuation of cortical responses to visual action effects was manifested in a reduced activation of a frontoparietal network, from 150 ms after stimulus. Differences between actions that produced an effect and those that did not were observed in lateralized motor potentials and may reflect the cortical correlates of the <b>action</b> <b>effect</b> prediction. We also observed a re-activation of lateralized motor activity following onset of the <b>action</b> <b>effect,</b> suggesting a common representation of action effects in visual and motor cortices. Taken together, these findings help to elucidate the cortical mechanisms of voluntary action as well as their sensory consequences and inform how our interaction with the external world is processed and controlled. © 2011 Elsevier Inc...|$|E
40|$|Reaction time to stimuli offset {{is usually}} longer than to stimuli onset (offset {{disadvantage}}). According to V. Di Lollo et al. (2000), such disadvantage {{arises from the}} need to suppress the automatically arisen response to stimulus onset that necessarily precedes the offset. If such is the case, one expects the onset– offset difference to decrease as the delay between stimulus onset and offset (i. e. foreperiod) increases. Results of the first experiment confirmed this hypothesis. A potential confounding factor was identified, however, related to different sensory consequences after response (i. e. light offset vs. light onset in the reaction time to stimulus onset and offset tasks, respectively). We thus reasoned that, besides suppres-sion, the <b>action</b> <b>effect</b> could influence the results. Results of the second experiment in which the sensory consequences were equalized confirmed {{the role of the}} <b>action</b> <b>effect</b> and suggest that, when such effect is removed, suppression plays a little role in offset disadvantage. Key words: reaction time, stimulus onset, stimulus offse...|$|E
40|$|The Simon effect {{refers to}} an {{advantage}} when a stimulus 2 ̆ 7 spatial location corresponds to that of its response, even though stimulus location is irrelevant to the task. The Simon effect is typically attributed to spatial coding of the stimuli and responses. It is assumed that a stimulus automatically activates its spatially corresponding response, with this activation facilitating responding when that response is correct and interfering when it is not. Though the instructed <b>action</b> <b>effect</b> is usually produced {{in response to a}} stimulus, multiple irrelevant/unintended action effects associated with other response features may be activated as well, and the spatial codes of these actions can be in opposition. ^ Five experiments were conducted to investigate how irrelevant action effects influence response selection with a wheel in an auditory Simon task. Experiment 1 showed that a cursor triggered by the wheel response did not yield an overall Simon effect even with instructions emphasizing the cursor. Experiment 2 indicated that experience with a controlled cursor yielded an overall Simon effect even when the cursor was triggered by the wheel response, suggesting that subjects coded their responses in terms of cursor movement. A combined <b>action</b> <b>effect</b> hypothesis was proposed to account for the size change of the Simon effect with an opposite <b>action</b> <b>effect.</b> ^ Experiments 3, 4, and 5 were designed to test the hypothesis that the combined result of the action effects (relevant hand-movement and irrelevant cursor-movement) determines the direction {{and the size of the}} Simon effect. In Experiment 3, all six sequences of three display conditions were used, and a carryover effect from the controlled cursor to the triggered cursor was found. Thus, a sequence with increasing cursor involvement (no-cursor, triggered-cursor, and controlled-cursor) was selected for Experiments 4 and 5. The Simon effect was reduced in both experiments when there was a conflicting <b>action</b> <b>effect.</b> In Experiment 4, the reduction was due in part to individual differences in response-selection strategy. However, in Experiment 5, the reduction was due to the combination of conflicting action effects, supporting the hypothesis that this combination determines the direction and size of the Simon effect. ...|$|E
40|$|The {{ability to}} {{recognize}} oneself in voluntary action is called the sense of agency and refers {{to the experience of}} causing one's own actions and their sensory consequences. This form of self-awareness is important not only for motor control but also for social interactions and the ascription of causal responsibility. Here, we examined the sense of agency at early and prereflective stages of action perception using ERPs. Subjects performed a visual forced-choice response task in which <b>action</b> <b>effects</b> were either caused by the subject or by the computer. In addition, to modulate the conscious experience of agency, <b>action</b> <b>effects</b> were subliminally primed by the presentation of congruent, incongruent, or neutral effect stimuli before the action. First, we observed sensorimotor attenuation in the visual ERP selectively for self-generated <b>action</b> <b>effects.</b> That is, the N 1 component, a negative deflection around 100 msec after a visual stimulus, was smaller in amplitude for visual effects caused by the subject as compared with effects caused by the computer. Second, congruent effect priming enhanced the explicit judgment of agency and further reduced the N 1 amplitude for self-generated effects, although effect primes were not consciously processed. Taken together, these results provide evidence of a top–down modulation of sensory processing of <b>action</b> <b>effects</b> by prior effect information and support the neurophysiological mechanism of sensorimotor attenuation as underlying self-registration in action. Our findings suggest that both efferent information and prior thoughts about the action consequence provide important cues for a prereflective form of the experience of being an agent...|$|R
50|$|The series used puppets made of plasticine, foam latex {{and solid}} plastic {{replacement}} style puppets. CG {{was used in}} some scenes as in addition to chroma key, matte paintings, hanging miniatures, double exposures, peppers ghost, live <b>action</b> <b>effects</b> and rod puppetry.|$|R
40|$|This article {{presents}} the event calculus, a logic-based formalism for representing <b>actions</b> and their <b>effects.</b> A circumscriptive {{solution to the}} frame problem is deployed which reduces to monotonic predicate completion. Using a number of benchmark examples from the literature, the formalism is shown to apply {{to a variety of}} domains, including those featuring <b>actions</b> with indirect <b>effects,</b> <b>actions</b> with non-deterministic <b>effects,</b> concurrent <b>actions,</b> and continuous change...|$|R
40|$|We define an {{extension}} of stit logic that encompasses subjective probabilities representing beliefs about simultaneous choice exertion of other agents. The formalism enables us to express the notion of ‘attempt ’ as a choice exertion that maximizes the chance of success with respect to an <b>action</b> <b>effect.</b> The notion of attempt (or effort) is central in philosophical and legal discussions on responsibility and liability. ...|$|E
40|$|A co-actor’s {{intentionality}} {{has been}} suggested {{to be a key}} modulating factor for joint action effects like the joint Simon effect (JSE). However, in previous studies intentionality has often been confounded with agency defined as perceiving the initiator of an action as being the causal source of the action. The aim {{of the present study was}} to disentangle the role of agency and intentionality as modulating factors of the JSE. In Experiment 1, participants performed a joint go/nogo Simon task next to a co-actor who either intentionally controlled a response button with own finger movements (agency+/intentionality+) or who passively placed the hand on a response button that moved up and down on its own as triggered by computer signals (agency-/intentionality-). In Experiment 2, we included a condition in which participants believed that the co-actor intentionally controlled the response button with a Brain-Computer Interface while placing the response finger clearly besides the response button, so that the causal relationship between agent and <b>action</b> <b>effect</b> was perceptually disrupted (agency-/intentionality+). As a control condition, the response button was computer controlled while the co-actor placed the response finger besides the response button (agency-/intentionality-). We observed a JSE when the co-actor responded intentionally and the causal relationship between co-actor and <b>action</b> <b>effect</b> could be perceived, but not when the co-actor did not respond intentionally and the causal relationship was disrupted (Experiment 1). When the intentionality of the co-actor was maintained but the perception of the causal relationship between co-actor and <b>action</b> <b>effect</b> destroyed, the JSE was absent (Experiment 2). Our findings clearly indicate a vital role of a co-actor’s agency for the JSE and suggest that the ascription of agency is strongly perceptually grounded...|$|E
30|$|The fourth {{scenario}} simulated {{describes a}} situation where a poor action prediction capability is modelled: the <b>action</b> <b>effect</b> is falsely predicted as satisfactory. This leads to a prior ownership state, which is sufficient to actually execute the prepared action. In this case, a low retrospective ownership state and almost absent retrospective awareness state will occur, as the sensory representation of the effect stays low. This simulation is used to explain the basic cognition and behaviour of a schizophrenic patient.|$|E
40|$|Controlling {{tools in}} {{technical}} environments bears {{a lot of}} challenges for the human information processing system, as locations of tool manipulation and effect appearance are spatially separated, and distal <b>action</b> <b>effects</b> are often not generated in a 1 : 1 manner. In this study we investigated the susceptibility of older adults to distal <b>action</b> <b>effects.</b> Younger and older participants performed a Fitts’ task on a digitizer tablet without seeing their hand and the tablet directly. Visual feedback was presented on a display in that way, that cursor amplitude and visual target size varied while the pre-determined hand amplitude remained constant. In accordance with distal <b>action</b> <b>effects</b> being predominant in controlling tool actions we found an increase in hand movement times and perceptual errors {{as a function of}} visual task characteristics. Middle-aged adults more intensely relied on visual feedback than younger adults. Age-related differences in speed-accuracy trade-off are not likely to account for this finding. However, {{it is well known that}} proprioceptive acuity declines with age. This might be one reason for middle-aged adults to stronger rely on the visual information instead of the proprioceptive information. Consequently, design and application of tools for elderly should account for this...|$|R
40|$|The {{auditory}} N 1 event-related potential {{has previously}} been observed to be attenuated for tones that are triggered by human actions. This attenuation {{is thought to be}} generated by motor prediction mechanisms and is considered to be important for agency attribution. The present study was designed to rigorously test the notion of action prediction-based sensory attenuation. Participants performed one of four voluntary actions on each trial, with each button associated with either predictable or unpredictable <b>action</b> <b>effects.</b> In addition, <b>actions</b> with each hand could result in <b>action</b> <b>effects</b> that were either congruent or incongruent with hand-specific prediction. We observed no significant differences in N 1 amplitude between predictable and unpredictable tones. When contrasting <b>action</b> <b>effects</b> that were congruent or incongruent with hand-specific prediction, we observed significant attenuation for prediction-congruent compared to prediction-incongruent action-effects. These novel findings suggest that accurate action-effect prediction drives sensory attenuation of auditory stimuli. These findings have important implications for understanding the mechanisms of action-effect prediction and sensory attenuation, and may have clinical implications for studies investigating action awareness and agency in schizophrenia. © 2013 Federation of European Neuroscience Societies and Blackwell Publishing Ltd...|$|R
40|$|The present {{contribution}} {{deals with}} the relationship between perception and action or, more precisely, with how the perception of action affects <b>action</b> control. <b>Action</b> <b>effects,</b> that is, the specific impact a particular action has on the actor-environment relationship, are what actions are good formthey represent th...|$|R
40|$|Abstract. In modern {{machine tool}} design, {{it is an}} {{important}} precondition of precision control to forecast accurately the relation between the final output precision of machine tool and its error cell. In this paper, the error cell characteristic of machine tool is described as the change of value and direction during the source error transfer. By supposing the source error of error cell as unit error, and forecasting their <b>action</b> <b>effect,</b> the characteristic of every error cell can be contained and compared. An example is provided lastly...|$|E
40|$|People tend to {{attribute}} more regret to {{a character who}} has decided to take action and experienced a negative outcome than to one who {{has decided not to}} act and experienced a negative outcome. For some decisions, however, this finding is not observed in a between-participants design and thus appears to rely on comparisons between people's representations of action and their representations of inaction. In this article, we outline a mental models account that explains findings from studies that have used within- and between-participants designs, and we suggest that, for decisions with uncertain counterfactual outcomes, information about the consequences of a decision to act causes people to flesh out their representation of the counterfactual states of affairs for inaction. In three experiments, we confirm our predictions about participants' fleshing out of representations, demonstrating that an <b>action</b> <b>effect</b> occurs only when information about the consequences of action is available to participants as they rate the nonactor and when this information about action is informative with respect to judgments about inaction. It {{is important to note that}} the <b>action</b> <b>effect</b> always occurs when the decision scenario specifies certain counterfactual outcomes. These results suggest that people sometimes base their attributions of regret on comparisons among different sets of mental models. 9 page(s...|$|E
40|$|This paper investigates a {{two-stage}} {{model of}} infants' imitative learning from observed actions and their effects. According to this model, {{the observation of}} another person's action activates the corresponding motor code in the infants motor repertoire (i. e. leads to motor resonance). The second process guiding imitative behavior results from the observed action effects. If the modeled action {{is followed by a}} salient <b>action</b> <b>effect,</b> the representation of this effect (i. e. perceptual code) will be associated with the activated motor code. If the infant later aims to obtain the same effect, the corresponding motor program will be activated and the model's action will therefore be imitated. Accordingly, the model assumes that for the imitation of novel actions the modeled action needs to elicit sufficient motor resonance and must be followed by a salient <b>action</b> <b>effect.</b> Using the head touch imitation paradigm, we tested these two assumptions derived from the model. To this end, we manipulated whether the actions demonstrated to the infants were or were not in the motor repertoire, i. e. elicited stronger or less strong motor resonance, and whether they were followed by salient action effects or not. The results were in line with the proposed two-stage model of infants' imitative learning and suggest that motor resonance is necessary, but not sufficient for infants' imitative learning from others' actions and their effects...|$|E
40|$|The {{influence}} of increased train loads on the dynamic amplification for bridge <b>action</b> <b>effects</b> are investigated using simple models such as two-mass oscillators. The results show, the bridge dynamic amplification factor decreases when carriage weights are increased. This procedure facilitates more accurate calculation of fatigue stresses...|$|R
40|$|There is {{increasing}} evidence that <b>action</b> <b>effects</b> {{play a crucial}} role in action understanding and action control not only in adults but also in infants. Most of the research in infants focused on the learning of action–effect contingencies or how <b>action</b> <b>effects</b> help infants to infer goals in other persons’ actions. In contrast, the present research aimed at demonstrating that infants control their own actions by action–effect anticipation once they know about specific action–effect relations. About 7 and 9 -month olds observed an experimenter demonstrating two actions that differed regarding the action–effect assignment. Either a red-button press or a blue-button press or no button press elicited interesting acoustical and visual effects. The 9 -month olds produced the <b>effect</b> <b>action</b> at first, with shorter latency and longer duration sustaining a direct impact of action–effect anticipation on action control. In 7 -month olds the differences due to action–effect manipulation were less profound indicating developmental changes at this age...|$|R
40|$|Goal: control an {{autonomous}} agent in an unknown environment for varying goals Model-based approach: learn a world model and use this model to plan actions Requirements for world models: – Noise – Stochastic <b>action</b> <b>effects</b> – Generalize to new situations – Learned from experience Requirements for planning: – Fas...|$|R
