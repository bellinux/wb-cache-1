2|5181|Public
40|$|Renal {{excretion}} is {{an important}} route of elimination for xenobiotics and three processes determine the renal clearance of a compound [glomerular filtration (about 120 ml/min), active renal tubular secretion (> 120 ml/min) and passive reabsorption ( 60 % of a dose) to develop renal-excretion related uncertainty factors for the risk assessment of environmental contaminants handled via this route. Data were analysed from published pharmacokinetic studies (after oral and intravenous dosing) in healthy adults and other subgroups using parameters relating primarily to chronic exposure [renal and total clearances, area under the plasma concentration time-curve (AUC) ] and acute exposure (Cmax). Interindividual variability in kinetics was low for both routes of exposure, with coefficients of variation of 21 % (oral) and 24 % (intravenous) that were largely independent of the renal processes involved. Renal-excretion related uncertainty factors were below the default kinetic uncertainty factor of 3. 16 for most subgroups analysed {{with the exception of}} the elderly (oral data) and neonates (intravenous data) for whom renal excretion-related factors of 4. 2 and 3. 2 would be required to cover up to 99 % of these subgroups respectively. CLr Renal clearance CL Total clearance AUC Area under the plasma-concentration-time-curve Cmax Maximum plasma concentration Ns Number of studies Np Number of publications n number of subjects XW <b>Arithmetic</b> <b>weighted</b> <b>mean</b> (normal distribution) SDw Weighted standard deviation (normal distribution) CVN Coefficient of variation (normal distribution) GMW Geometric weighted mean (lognormal distribution) GSDw Weighted geometric standard deviation (lognormal distribution) CVLN Coefficient of variation (lognormal distribution) GF Glomerular filtration TS Tubular secretio...|$|E
40|$|ABsTRAcT Sorting tor certain Oklahoma river sands {{is similar}} to that found in dune, beach aim marine ottshore smlds. Uninlodal histograms have been re-ported from water-deposited sand sam-pies from the North and South Canadian rivers of central Oklahoma. To verify this, a {{detailed}} study of a single river sand bar in the North Cana-dian was made during the fall and winter of 1949 - 50. Twenty-four samples were collected in a grid pattern from a river-bank bar about 200 feet long. This sand bar was located immediately west of the State Highway 18 bridge at the southern city limits of Shawnee. The sand was beginning to dr?? " follow-lug a high water stage. The northern edge of the bar (parallel with the current) had already been eroded slightly; a few days later the bar had been removed entirely. Sorting coefficients varied from 1. 15 to 1. 60. The average (<b>arithmetic,</b> <b>weighted</b> <b>mean)</b> was 1. 28333, the median 1. 27 _+ 0. 03. A value of 2. 5 has been listed as excel-lent sorting (Trask, 1932). Near-shore marine sands have a sorting coefficient of 1. 0 to 2. 0, with an average of 1. 45 (Hough, 1940). Beach sands have been reported by Krflmbein (1936) with a sorting coefficient of 1. 22. Sidwell and Tanner (1939), in a stud 5 ' of 34 samples from West Texas sand dunes, found the average sorting to be 1. 24. A "typical" river sand analyzed by Udden appears to have a sorting coefficient of 1. 6 (Twen-hofel, 1932). With a single exception, the Canadian river bar sands had sorting coefficients below 1. 40. The highest frequency en-countered was 68 per cent, on the s ~ mm screen. The average maximum frequency was 52. 4 per cent. Curves were skewed toward both coarse and fine sizes. The highest sym-metry appeared in a curve with skewnes...|$|E
3000|$|... (f) will denote a <b>weighted</b> <b>arithmetic</b> <b>mean,</b> a <b>weighted</b> {{geometric}} <b>mean,</b> a <b>weighted</b> harmonic <b>mean,</b> etc. of {f(ω 1), [...]..., f(ω [...]...|$|R
40|$|The {{most often}} used {{operator}} to aggregate criteria in decision making problems is the classical <b>weighted</b> <b>arithmetic</b> <b>mean.</b> In many problems however, the criteria considered interact, and a substitute to the <b>weighted</b> <b>arithmetic</b> <b>mean</b> has to be adopted. Under rather natural conditions, the discrete Choquet integral is {{proved to be an}} adequate aggregation operator that extends the <b>weighted</b> <b>arithmetic</b> <b>mean</b> by the taking into consideration of the interaction among criteria. The axiomatic that supports the Choquet integral is presented and some subfamilies are studied...|$|R
40|$|Abstract—In this paper, we {{describe}} how several existing software reliability growth models based on Nonhomogeneous Poisson processes (NHPPs) can be comprehensively derived {{by applying the}} concept of <b>weighted</b> <b>arithmetic,</b> <b>weighted</b> geometric, or <b>weighted</b> harmonic <b>mean.</b> Furthermore, based on these three <b>weighted</b> <b>means,</b> we thus propose a more general NHPP model from the quasi arithmetic viewpoint. In addition to the above three means, we formulate a more general transformation that includes a parametric family of power transformations. Under this general framework, we verify the existing NHPP models and derive several new NHPP models. We show that these approaches cover a number of well-known models under different conditions. Index Terms—Software reliability growth model (SRGM), <b>weighted</b> <b>arithmetic</b> <b>mean,</b> <b>weighted</b> geometric <b>mean,</b> <b>weighted</b> harmonic <b>mean,</b> mean value function (MVF), power transformation, nonhomogeneous Poisson process (NHPP). ...|$|R
40|$|Revised version The {{most often}} used {{operator}} to aggregate criteria in decision making problems is the classical <b>weighted</b> <b>arithmetic</b> <b>mean.</b> In many problems however, the criteria considered interact, and a substitute to the <b>weighted</b> <b>arithmetic</b> <b>mean</b> has to be adopted. Under rather natural conditions, the discrete Choquet integral is {{proved to be an}} adequate aggregation operator that extends the <b>weighted</b> <b>arithmetic</b> <b>mean</b> by the taking into consideration of the interaction among criteria. The axiomatic that supports the Choquet integral is presented and some subfamilies are studied. Index Terms: multicriteria decision making, interacting criteria, Choquet integral. ...|$|R
5000|$|Trimean: the <b>weighted</b> <b>arithmetic</b> <b>mean</b> of {{the median}} and two quartiles.|$|R
30|$|In this study, the <b>weighted</b> <b>arithmetic</b> <b>mean</b> {{method for}} WQI is used.|$|R
30|$|Let us see {{now that}} Theorem  1, for the <b>weighted</b> {{harmonic}} <b>mean,</b> also holds for the <b>weighted</b> <b>arithmetic</b> <b>mean.</b>|$|R
5000|$|There is {{a similar}} {{inequality}} for the <b>weighted</b> <b>arithmetic</b> <b>mean</b> and <b>weighted</b> geometric <b>mean.</b> Specifically, let the nonnegative numbers [...] and the nonnegative weights [...] be given. Set [...] If , then the inequality ...|$|R
2500|$|The <b>weighted</b> <b>arithmetic</b> <b>mean</b> (or <b>weighted</b> average) is used if {{one wants}} to combine average values from samples of the same {{population}} with different sample sizes: ...|$|R
5000|$|... where [...] is {{richness}} (the {{total number}} of types in the dataset). This equation is also equal to the <b>weighted</b> <b>arithmetic</b> <b>mean</b> of the proportional abundances [...] {{of the types of}} interest, with the proportional abundances themselves being used as the weights. Proportional abundances are by definition constrained to values between zero and unity, but it is a <b>weighted</b> <b>arithmetic</b> <b>mean,</b> hence , which is reached when all types are equally abundant.|$|R
50|$|Weighted {{versions}} of other means {{can also be}} calculated. Probably the best known <b>weighted</b> <b>mean</b> is the <b>weighted</b> <b>arithmetic</b> <b>mean,</b> usually simply called the <b>weighted</b> <b>mean.</b> Another example of a <b>weighted</b> <b>mean</b> is the <b>weighted</b> harmonic <b>mean.</b>|$|R
5000|$|Laspeyres Formula : It is the <b>weighted</b> <b>arithmetic</b> <b>mean</b> {{based on}} the fixed {{value-based}} weights for the base period.|$|R
50|$|Thus, {{the correct}} P/E of 93.46 of this index {{can only be}} found using the <b>weighted</b> {{harmonic}} <b>mean,</b> while the <b>weighted</b> <b>arithmetic</b> <b>mean</b> will significantly overestimate it.|$|R
50|$|Using {{the finite}} form of Jensen's {{inequality}} {{for the natural}} logarithm, we can prove the inequality between the <b>weighted</b> <b>arithmetic</b> <b>mean</b> and the <b>weighted</b> geometric <b>mean</b> stated above.|$|R
3000|$|... where (y^ 1 -tx^t) and (1 -t)f(y)+t(f(x)) are the <b>weighted</b> {{geometric}} <b>mean</b> of two positive numbers x and y and the <b>weighted</b> <b>arithmetic</b> <b>mean</b> of f(x) and f(y), respectively.|$|R
50|$|The second {{form above}} {{illustrates}} that the logarithm of the geometric <b>mean</b> is the <b>weighted</b> <b>arithmetic</b> <b>mean</b> of the logarithms {{of the individual}} values.|$|R
50|$|If all {{the weights}} are equal, then the <b>weighted</b> <b>mean</b> {{is the same}} as the <b>arithmetic</b> <b>mean.</b> While <b>weighted</b> <b>means</b> {{generally}} behave in a similar fashion to arithmetic means, they do have a few counterintuitive properties, as captured for instance in Simpson's paradox.|$|R
30|$|This can be {{regarded}} as a φ-mean of {x, y} with respect to a probability measure which represents a <b>weighted</b> <b>arithmetic</b> <b>mean</b> (1 -t) x + ty.|$|R
50|$|The <b>weighted</b> {{harmonic}} <b>mean</b> is the preferable {{method for}} averaging multiples, {{such as the}} price-earnings ratio (P/E), in which price is in the numerator. If these ratios are averaged using a <b>weighted</b> <b>arithmetic</b> <b>mean</b> (a common error), high data points are given greater weights than low data points. The <b>weighted</b> harmonic <b>mean,</b> on the other hand, gives equal weight to each data point. The simple <b>weighted</b> <b>arithmetic</b> <b>mean</b> when applied to non-price normalized ratios such as the P/E is biased upwards and cannot be numerically justified, since {{it is based on}} equalized earnings; just as vehicles speeds cannot be averaged for a roundtrip journey.|$|R
40|$|The {{most often}} used {{operator}} to aggregate criteria in decision making problems is the classical <b>weighted</b> <b>arithmetic</b> <b>mean.</b> In many problems however, the criteria considered interact, and a substitute to the <b>weighted</b> <b>arithmetic</b> <b>mean</b> has to be adopted. It was shown that, under rather natural conditions, the discrete Choquet integral is an adequate aggregation operator that extends the <b>weighted</b> <b>arithmetic</b> <b>mean</b> by the taking into consideration of the interaction among criteria. However, since this operator is constructed from coefficients (weights) whose meaning is not always very clear for the decision maker, {{it is useful to}} define from these coefficients some indices that offer {{a better understanding of the}} behavioral properties of the aggregation. We present and discuss the following indices: the global importance of criteria, the interaction among criteria, the influence of the criteria on the aggregation, the tolerance of the decision maker, and the dispersion of the weights on the criteria. ...|$|R
3000|$|... [...]. Also, due to {{the fact}} that the <b>weighted</b> {{geometric}} <b>mean</b> is less than the <b>weighted</b> <b>arithmetic</b> <b>mean,</b> it follows that any log-convex function is a convex function. However, obviously, there are functions that are convex but not log-convex.|$|R
50|$|Similarly, if {{one wishes}} to {{estimate}} the density of an alloy given the densities of its constituent elements and their mass fractions (or, equivalently, percentages by mass), then the predicted density of the alloy (exclusive of typically minor volume changes due to atom packing effects) is the <b>weighted</b> harmonic <b>mean</b> of the individual densities, weighted by mass, rather than the <b>weighted</b> <b>arithmetic</b> <b>mean</b> as one might at first expect. To use the <b>weighted</b> <b>arithmetic</b> <b>mean,</b> the densities {{would have to be}} weighted by volume. Applying dimensional analysis to the problem, while labeling the mass units by element and making sure that only like element-masses cancel, makes this clear.|$|R
30|$|It {{is worth}} {{mentioning}} {{that in the}} previous relationship A_λ^σ_k=H_ 1 -λ, k∈K is arbitrary. This could be coming {{from the fact that}} the <b>weighted</b> <b>arithmetic</b> <b>mean</b> A_λ has a linear affine character.|$|R
50|$|This simply equals true {{diversity}} of order 2, i.e. the effective number of types that is obtained when the <b>weighted</b> <b>arithmetic</b> <b>mean</b> {{is used to}} quantify average proportional abundance of types in the dataset of interest.|$|R
40|$|The {{proportional}} weight view in epistemology {{of disagreement}} generalizes the equal weight view and proposes that we assign to the judgments {{of different people}} weights that are proportional to their epistemic qualifications. It is known that (under the plausible Context-Free Assumption) if the resulting aggregate degrees of confidence are to constitute a probability function, they must be the <b>weighted</b> <b>arithmetic</b> <b>means</b> of individual degrees of confidence, but aggregation by the <b>weighted</b> <b>arithmetic</b> <b>means</b> violates the Bayesian rule of conditionalization. The double bind entails that the proportional weight view is inconsistent with Bayesianism. The paper explores various ways {{to respond to this}} challenge to the proportional weight view...|$|R
40|$|In this article, the Schur-convexities of the <b>weighted</b> <b>arithmetic</b> <b>mean</b> of {{function}} and the extended mean values are proved. Moreover, some inequalities involving the arithmetic mean, the harmonic mean, the logarithmic mean, and {{comparison between the}} extended mean values and the generalized <b>weighted</b> <b>mean</b> with two parameters and constant weight are obtained...|$|R
5000|$|FIBA uses <b>weighted</b> <b>arithmetic</b> <b>mean</b> to {{determine}} the statistical weight {{of each of the}} tournaments. Each event is assigned point weight that is based partly on how competitive the tournament is and partly on which national teams are participating: ...|$|R
5000|$|Then, the {{equilibrium}} {{conditions in the}} Fisher model can be written as solutions to a convex optimization program called the Eisenberg-Gale convex program. This program finds an allocation that maximizes the <b>weighted</b> geometric <b>mean</b> of the buyers' utilities, where the weights {{are determined by the}} budgets. Equivalently, it maximizes the <b>weighted</b> <b>arithmetic</b> <b>mean</b> of the logarithms of the utilities: ...|$|R
50|$|The <b>weighted</b> <b>arithmetic</b> <b>mean</b> {{is similar}} to an {{ordinary}} arithmetic mean (the {{most common type of}} average), except that instead of each of the data points contributing equally to the final average, some data points contribute more than others. The notion of <b>weighted</b> <b>mean</b> plays a role in descriptive statistics and also occurs in a more general form in several other areas of mathematics.|$|R
40|$|The aim of {{this paper}} is to {{investigate}} the influence of the degree of coverage, survey design, and method of calculation on fish abundance estimation results. Measurements were performed in deep, mesotrophic lake, containing fish community dominated by vendace (Coregonus albula L.). Two types of survey design were applied: the regular parallel transects with constant distance between them and the triangular (zig-zag) transects. It has been shown that at high enough degree of coverage both designs give equivalent estimates of fish abundance and similar fish distribution, however at lower coverage the parallel transects are preferable. With increasing degree of coverage the fish abundance increases as well until some asymptotic value, which is reached at degree of coverage equal to 0. 8. The three different methods of estimating total stock have been applied: <b>arithmetic</b> <b>mean,</b> <b>weighted</b> <b>mean,</b> and kriging. The estimates of fish abundance received by the first two methods were very similar, while the third one was significantly lower...|$|R
40|$|This paper {{shows how}} median may be {{computed}} as a <b>weighted</b> <b>arithmetic</b> <b>mean</b> of all sample observations, unlike the conventional method that obtains median {{as the middle}} value (odd observations) or a simple mean of the two middlemost values (even observations). Monte Carlo experiments {{have been carried out}} to investigate the bias, efficiency and consistency of the alternative methods. ...|$|R
30|$|The CBH {{predicted}} by ALS had RMSEs of 1.58 and 1.47  m and biases of − 0.93 and 0.07  m, when evaluated against the <b>arithmetic</b> and basal-area <b>weighted</b> <b>means</b> {{of the field}} measurements, respectively. These accuracies suggest that the area-based prediction of the CBH is a reliable estimate of this measure {{particularly with respect to}} the largest trees. The results are on the same accuracy level as in the earlier studies (see Maltamo et al. 2012).|$|R
30|$|For {{some of the}} {{candidate}} models submitted for the IGRF- 12, systematic deviation to the <b>weighted</b> <b>arithmetic</b> <b>mean</b> could be understood {{in the light of}} the model descriptions as coming from the scientific choices made during their construction. As a result, a majority of the task force thought that the internal discrepancies between different groups of models were not sufficient to reject any of the models.|$|R
3000|$|Let {{the number}} of factors used for {{prediction}} be M, and these factors’ set is written as {X_i,i = 1, 2, [...]...,M}, X_i = [x_ 1,x_ 2, [...]...,x_N] ∈R_ 1 × N. The predicted value is Y_i = [y_ 1,y_ 2, [...]...,y_T] ∈R_ 1 × T. A <b>weighted</b> <b>arithmetic</b> <b>mean</b> based sample distribution method is designed to handle multi-source heterogeneous features of input data.|$|R
