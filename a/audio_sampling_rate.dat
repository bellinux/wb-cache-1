9|10000|Public
5000|$|KMixer <b>audio</b> <b>sampling</b> <b>rate</b> {{supports}} {{a maximum of}} 200 kHz beginning with Windows XP SP1 compared to earlier versions of Windows.|$|E
50|$|In Windows 98, Windows 2000 and Windows Me, the KMixer maximum {{sample rate}} is 100 kHz. In Windows XP SP1 and later, KMixer <b>audio</b> <b>sampling</b> <b>rate</b> {{supports}} {{a maximum of}} 200 kHz.|$|E
50|$|The {{method for}} {{recording}} audio data is the same, {{except that the}} command is AT+VRX or AT#VRX, and the modem transmits audio data while the computer receives it. The RTS/CTS flow control are not used here (the computer must accept all the audio data it receives, and the modem automatically paces its transmission to match the <b>audio</b> <b>sampling</b> <b>rate).</b>|$|E
50|$|Flash Audio is most {{commonly}} encoded in MP3 or AAC (Advanced Audio Coding) however {{it can also}} use ADPCM, Nellymoser (Nellymoser Asao Codec) and Speex audio codecs. Flash allows <b>sample</b> <b>rates</b> of 11, 22 and 44.1 kHz. It cannot have 48 kHz <b>audio</b> <b>sample</b> <b>rate,</b> which is the standard TV and DVD <b>sample</b> <b>rate.</b>|$|R
5000|$|The {{basic data}} rate is 100 Mbit/s {{of data using}} 4B5B {{encoding}} to produce a 125 MHz physical baud rate. Unlike AES3, this clock is not synchronized to the <b>audio</b> <b>sample</b> <b>rate,</b> and the <b>audio</b> data payload is padded using [...] "JK" [...] sync symbols.|$|R
50|$|G.719 is an ITU-T {{standard}} audio {{coding format}} providing high quality, moderate bit rate (32 to 128 kbit/s) wideband (20 Hz - 20 kHz audio bandwidth, 48 kHz <b>audio</b> <b>sample</b> <b>rate)</b> <b>audio</b> coding at low computational load. It was produced through {{a collaboration between}} Polycom and Ericsson.|$|R
50|$|Also, {{throughout}} the years, soundcards have evolved {{in terms of}} digital <b>audio</b> <b>sampling</b> <b>rate</b> (starting from 8-bit 11025 Hz, to 32-bit, 192 kHz that the latest solutions support). Along the way, some cards started offering 'wavetable' sample-based synthesis, which provides superior MIDI synthesis quality relative to the earlier OPL-based solutions, which uses FM-synthesis. Also, some higher end cards started having their own RAM and processor for user-definable sound samples and MIDI instruments {{as well as to}} offload audio processing from the CPU.|$|E
5000|$|DSD uses pulse-density {{modulation}} encoding—a {{technology to}} store audio signals on {{digital storage media}} that are used for the SACD. The signal is stored as delta-sigma modulated digital audio; a sequence of single-bit values at a sampling rate of 2.8224 MHz (64 times the CD <b>audio</b> <b>sampling</b> <b>rate</b> of 44.1 kHz, but only at [...] of its 16-bit resolution). Noise shaping occurs by use of the 64-timed oversampled signal to reduce noise and distortion caused by the inaccuracy of quantization of the audio signal to a single bit. Therefore, it is a topic of discussion whether {{it is possible to}} eliminate distortion in one-bit delta-sigma conversion.|$|E
50|$|MPEG-4 and AVC video formats {{are also}} {{compatible}} with PSP. With reasonable {{video and audio}} bit-rate settings (a resolution of 320×240, a video bit rate of 500 Kbit per second, and an <b>audio</b> <b>sampling</b> <b>rate</b> of 22050 Hz) a 22-minute video file is roughly 55 MB, enough to fit on a Memory Stick Duo {{as small as a}} 64 MB. At the same rate, a hundred-minute feature film can fit on a 256 MB Memory Stick. As of firmware update version 3.30, H.264/MPEG-4 AVC Main Profile video files of the following sizes can be played: 720×480, 352×480, and 480×272. Many video files, both free-to-distribute and copyrighted, have been encoded for the PSP and are available on the Internet. Game and movie trailers are increasingly available, even from studios' official websites.|$|E
3000|$|In Appendix Table 7, {{we report}} for each device some {{statistical}} information computed over the recorded videos. The metadata tags {{gathered from the}} native videos by means of Exiftool were file type, major brand, video frame rate, media duration, <b>audio</b> channels, <b>audio</b> <b>sample</b> <b>rate,</b> image size, and rotation [...]...|$|R
50|$|A typical bitcrusher uses {{two methods}} to reduce <b>audio</b> fidelity: <b>sample</b> <b>rate</b> {{reduction}} and resolution reduction.|$|R
50|$|Super Audio CD/CD hybrid discs contain both an SACD {{layer and}} a {{standard}} CD layer. For the SACD layer, the recording is converted into a DSD file instead of the PCM Linear that ordinary CDs use. The DSD coding has a <b>sampling</b> <b>rate</b> of 64 times the CD <b>Audio</b> <b>sampling</b> <b>rates</b> of 44.1 kHz, for a rate of 2.8224 MHz (1 bit times 64 times 44.1 kHz).|$|R
5000|$|The command AT+VSM=? or AT#VSM=? usually returns a list {{of audio}} data formats {{supported}} by the modem. Each format includes a name (such as PCM, ADPCM, μ-law, A-law), a number of bits per sample (usually 2, 3, 4, 8, or 16) and an <b>audio</b> <b>sampling</b> <b>rate</b> (usually 7200, 8000, or 11025 Hertz). These are industry-standard audio codecs whose implementations are well published. The ADPCM standard is an exception. Modems claiming to support ADPCM almost always support Dialogic ADPCM, also known as [...] "VOX", which is similar but not compatible with other ADPCM implementations, including Interactive Multimedia Association (IMA) ADPCM as well as MS ADPCM (a Microsoft implementation used in WAV files). Modems may support these as well, if a qualifier is listed - otherwise, by default, ADPCM means Dialogic.|$|E
40|$|This paper {{presents}} a digital <b>audio</b> <b>sampling</b> <b>rate</b> conversion library that converts between arbitrary sampling frequencies. The library is implemented as a time-varying fractional delay filter with coefficients {{stored in a}} lookup table. It is designed for use by real-time applications and optimized for execution on Intel's StrongARM microprocessor...|$|E
30|$|Parameters for {{audio-video}} quality {{have been}} optimized {{in order for}} the system to adapt the users’ network environment without suffering from bad audio-video quality. These parameters include video resolution, video frame rate, video encoding quality, and <b>audio</b> <b>sampling</b> <b>rate</b> are used to provide three video quality settings such as low, medium and high, which can be selected in manual or automatic mode.|$|E
50|$|AVI cannot {{contain some}} {{specific}} types of variable bitrate (VBR) data reliably (such as MP3 <b>audio</b> at <b>sample</b> <b>rates</b> below 32 kHz).|$|R
5000|$|Optional 8-channel <b>audio</b> with <b>sampling</b> <b>rates</b> up to 24bit 192kHz, {{encapsulation}} {{of audio}} compression formats (including Dolby TrueHD and DTS-HD Master Audio from v1.2) ...|$|R
50|$|G.722.1 Annex C (or G.722.1C) is a low-complexity {{extension}} mode to G.722.1, which doubles {{the algorithm}} to permit 14 kHz audio bandwidth using a 32 kHz <b>audio</b> <b>sample</b> <b>rate,</b> at 24, 32, and 48 kbit/s. It {{is included in}} the official ITU-T Recommendation G.722.1. The name of this annex is Annex C - 14 kHz mode at 24, 32, and 48 kbit/s. It is an implementation of the mono version of Polycom's Siren 14 audio coding format.|$|R
50|$|Codec 2 {{consists}} of 3200, 2400, 1600, 1400, 1300, 1200, and 700 bit/s codec modes. It outperforms most other low-bitrate speech codecs. For example, it uses half the bandwidth of Advanced Multi-Band Excitation to encode speech with similar quality. The speech codec uses 16-bit PCM <b>sampled</b> <b>audio,</b> and outputs packed digital bytes. Likewise, you send it packed digital bytes, and it outputs PCM <b>sampled</b> <b>audio.</b> The <b>audio</b> <b>sample</b> <b>rate</b> is fixed at 8 kHz. Internally, the codec algorithms operate on 10 ms PCM frames, {{with each of}} these audio segments declared voiced (vowel) or unvoiced (consonant).|$|R
50|$|AIX Records has not {{released}} any CDs. Instead it focuses exclusively on high definition <b>audio,</b> using <b>sample</b> <b>rates</b> of 96 kHz, 24 bits of audio bit depth, and 5.1 channels in its surround mixes.|$|R
50|$|Dolby TrueHD uses Meridian Lossless Packing (MLP) as its {{mathematical}} {{basis for}} compressing <b>audio</b> <b>samples.</b> MLP {{is also used}} in the DVD-Audio format, but details of Dolby TrueHD and the MLP Lossless format as used on DVD-Audio differ substantially. A Dolby TrueHD bitstream can carry up to 16 discrete <b>audio</b> channels. <b>Sample</b> depths up to 24 bits/sample and <b>audio</b> <b>sample</b> <b>rates</b> up to 192 kHz are supported. Like the more common legacy codec Dolby Digital, Dolby TrueHD bitstreams carry program metadata. Metadata is separate from the coding format and compressed <b>audio</b> <b>samples,</b> but stores relevant information about the audio waveform and provides control over the decoding process. For example, dialog normalization and dynamic range compression are controlled by metadata embedded in the Dolby TrueHD bitstream. Similarly, a Dolby Atmos encoded Dolby TrueHD stream contains metadata to extract and place the objects in relevant positions. Dolby TrueHD is a variable bit-rate codec.|$|R
5000|$|Supports 16- and 24-bit <b>audio</b> with a <b>sampling</b> <b>rate</b> {{of up to}} 96 kHz (or up to 192 kHz, enabled by use of a free {{third-party}} plug-in.) ...|$|R
50|$|In 1968 he left MIT for the University of Utah, and in 1975 founded Soundstream, Inc. The company {{developed}} a 16-bit digital audio recording system using a 16-track Honeywell instrumentation tape recorder as a transport, connected to digital audio {{recording and playback}} hardware of Stockham's design. It ran at a <b>sampling</b> <b>rate</b> of 50 kHz, {{as opposed to the}} <b>audio</b> CD <b>sampling</b> <b>rate</b> of 44.1 kHz.|$|R
50|$|The term {{is often}} used to {{describe}} the scanning of analog sources (such as printed photos or taped videos) into computers for editing, but it also can refer to <b>audio</b> (where <b>sampling</b> <b>rate</b> is often measured in kilohertz) and texture map transformations. In this last case, as in normal photos, the <b>sampling</b> <b>rate</b> refers to the resolution of the image, often measured in pixels per inch.|$|R
40|$|We {{present the}} results of our quality {{assessment}} of Peak Pro 5 ’s new <b>sample</b> <b>rate</b> converter (SRC). Eleven audio applications were compared with BIAS Peak Pro 5 in terms of <b>sample</b> <b>rate</b> conversion quality. A set of test signals was converted with all applications and spectral analysis was performed to detect artifacts in the converted signals. Results consistently show that the SRC algorithm in Peak Pro 5 provides topquality conversion in today’s market. We provide here all the information necessary for other parties to reproduce our quality evaluation tests: test signals, conversion parameters specific to each application, and spectrogram analysis parameters. <b>SAMPLE</b> <b>RATE</b> CONVERSION <b>Sample</b> <b>Rate</b> Conversion (SRC) is a process by which the <b>audio</b> <b>sample</b> <b>rate</b> gets changed without affecting the pitch of the audio. This process is necessary in different situations: Digital Audio Workstation (DAW) users often record and edit at a high <b>sample</b> <b>rate,</b> and then down-sample the audio to get it onto various media. This <b>sample</b> <b>rate</b> conversion can either be done by the DAW during or after the bounce, or in a separate application after bouncing. In another scenario, <b>sample</b> <b>rate</b> conversion is necessary when audio materia...|$|R
40|$|Corresponding author) Abstract — We present two physics-based analysis, synthesis, {{and control}} systems for synthesizing hand {{clapping}} sounds. They both {{rely on the}} separation of the sound synthesis and event generation, and both are capable of producing individual hand-claps, or mimicking the asynchronous/synchronized applause of a group of clappers. The synthesis models consist of resonator filters, whose coefficients are derived from experimental measurements. The difference between these systems is mainly in the statistical event generation. While the first system allows an efficient parametric synthesis of large audiences, as well as flocking and synchronization by simple rules, the second one provides parametric extensions for synthesis of various clapping styles and enhanced control strategies. The synthesis and the control models of both systems are implemented as software running in real time at the <b>audio</b> <b>sample</b> <b>rate,</b> and they are available for download a...|$|R
40|$|This paper {{describes}} the low-complexity 14 kHz bandwidth audio coding algorithm {{which has been}} recently standardized by ITU-T as Recommendation G. 722. 1 Annex C (“G. 722. 1 C”). The algorithm is an extension to ITU-T Recommendation G. 722. 1 and a doubled form of the G. 722. 1 algorithm to permit 14 kHz audio bandwidth using a 32 kHz <b>audio</b> <b>sample</b> <b>rate,</b> at 24, 32, and 48 kbit/s. The G. 722. 1 C codec features very high audio quality, extremely low computational complexity, and low algorithmic delay compared to other state-of-the-art audio coding algorithms. This codec is suitable for use in video conferencing and teleconferencing, and Internet streaming applications {{as well as a}} general-purpose 14 kHz audio codec. Subjective test results from the Characterization phase of G 722. 1 C are also presented in the paper. </p...|$|R
50|$|There is no {{standard}} {{definition for}} what constitutes high-resolution audio, {{but it is}} generally used to describe audio signals with bandwidth and/or dynamic range {{greater than that of}} Compact Disc Digital Audio (CD-DA, informally CDs).This includes pulse-code modulation (PCM) encoded <b>audio</b> with <b>sampling</b> <b>rates</b> greater than 44,100 Hz and with bit-depths greater than 16, or their equivalents using other encoding techniques such as pulse-density modulation (PDM).|$|R
40|$|Abstract — This paper {{describes}} the low-complexity 14 kHz bandwidth audio coding algorithm {{which has been}} recently standardized by ITU-T as Recommendation G. 722. 1 Annex C (“G. 722. 1 C”). The algorithm is an extension to ITU-T Recommendation G. 722. 1 and a doubled form of the G. 722. 1 algorithm to permit 14 kHz audio bandwidth using a 32 kHz <b>audio</b> <b>sample</b> <b>rate,</b> at 24, 32, and 48 kbit/s. The G. 722. 1 C codec features very high audio quality, extremely low computational complexity, and low algorithmic delay compared to other state-of-the-art audio coding algorithms. This codec is suitable for use in video conferencing and teleconferencing, and Internet streaming applications {{as well as a}} general-purpose 14 kHz audio codec. Subjective test results from the Characterization phase of G. 722. 1 C are also presented in the paper. Index Terms — Audio coding, low complexity, superwideband, transform codin...|$|R
50|$|Another {{important}} {{use of the}} 6500 {{family was}} in video games. The first {{to make use of}} the processor design was the Atari 2600 video game console. The 2600 used an offshoot of the 6502 called the 6507, which had fewer pins and, as a result, could address only 8 KB of memory. Millions of the Atari consoles would be sold, each with a MOS processor. Another significant use was by the Nintendo Entertainment System and Famicom. The 6502 used in the NES was a second source version by Ricoh, a partial system-on-a-chip, that lacked the binary-coded decimal mode but added 22 memory-mapped registers (and on-die hardware) for sound generation, joypad reading, and sprite list DMA. Called 2A03 in NTSC consoles and 2A07 in PAL consoles (the difference being the memory divider ratio and a lookup table for <b>audio</b> <b>sample</b> <b>rates),</b> this processor was produced exclusively for Nintendo.|$|R
25|$|The encoder and decoder support MPEG-4 AAC LC, HE-AAC (AAC LC + SBR), and HE-AACv2 (LC + SBR + PS) <b>Audio</b> Object Types. <b>Sample</b> <b>rates</b> up to 96kHz, and {{multichannel}} audio {{up to six}} channels (5.1 surround) are supported.|$|R
40|$|Although {{there have}} been {{numerous}} investigations of 				laryngeal muscle activity during phonation in the chest and 				falsetto/head registers in trained and untrained classical 				singers and non-singers, no research has been conducted 				examining laryngeal muscle activity during phonation in the 				chestmix register, a register used extensively by many female 				commercial singers, particularly for the production of higher 				frequencies. The {{purpose of this study was}} to test the 				hypothesis that commercial singers produce chestmix by 				maintaining or increasing adduction of the vocal processes and 				by engaging the thyroarytenoid muscle to a greater degree than 				they would to produce a head register sound. Simultaneous 				recordings of thyroarytenoid and cricothyroid muscle activity, 				videonasendosopy, and audio were obtained from seven female 				commercial singers (5 trained, 2 untrained) during sustained 				phonation and song phrases produced in chest, chestmix, headmix, 				and head registers. Thryoarytenoid and cricothyroid muscle 				activity was normalized to a percent of mean maximum activity 				and compared across registers and frequencies both within 				subjects and across subjects. Video stills of vocal processes 				adduction patterns were rated for degree of vocal processes 				adduction and also compared across register and frequency within 				and across subjects. All <b>audio</b> <b>samples</b> were <b>rated</b> for register 				by two singing teachers and <b>audio</b> <b>samples</b> of sustained phonation 				were analyzed via Fast Fourier Transform to measure the number 				and energy of the harmonics present in each sample. Interjudge 				and intrajudge reliability tests were performed for both the 				vocal processes adduction <b>rating</b> and <b>audio</b> <b>sample</b> <b>rating</b> tasks. 				Results from the study confirmed the hypothesis and showed that 				thyroarytenoid activity and adduction of the vocal processes was 				greater for chestmix than headmix or head, particularly during 				production of higher frequencies, but less than for chest 				productions. Cricothyroid activity was similar for chestmix, 				headmix and head during production of lower frequencies, but 				greater for chestmix during production of higher 			frequencies...|$|R
40|$|Modal {{representations}} {{have been}} used successfully {{in the context of}} musical sound synthesis based on linear and time-invariant physical models. It is also particularly simple, from such a representation, to deduce estimates of computational complexity in a discrete time simulation from modal density: the operation count, as well as memory requirements may be related directly to the <b>audio</b> <b>sample</b> <b>rate</b> and the defining parameters of the model under consideration. It is intuitively obvious, but interesting nonetheless to note that for general LTI systems, these estimates hold not merely for modal representations, but for any numerical method, including time domain techniques: there are fundamental limits on how much computational work is required to simulate a given instrument, and one should not expect {{to be able to do}} better. Special cases, including digital waveguides, are discussed in this light. Questions are raised regarding the possibility of deducing similar performance bounds using nonlinear modal representations...|$|R
40|$|It is {{anticipated}} that 3 -D sound {{will become a}} major component in virtual reality environments. In this thesis, we investigate {{the development of a}} Windows(TM) 3 -D sound system using binaural technology. This work should eventually be integrated in complex virtual environment software. The 3 -D sound effects are achieved by applying a filter pair representing audio cues from a specific point in space to the left and right channels of headphones. As a first step, an offline 3 -D audio file generation system is developed, and effects such as sound reflections in a virtual rectangular room are added to this system. The real-time implementation is considered next. The first approach tested for the real-time implementation uses the time domain convolution of a sound source signal with head-related transfer functions, but the computational load of this approach is such that it cannot run in real-time at <b>audio</b> <b>sampling</b> <b>rates.</b> As an alternative, a second approach with a Fast Fourier Transform overlap and save technique is used to reduce the computational load, and a real-time implementation at audio frequencies is therefore successfully achieved...|$|R
30|$|The {{format of}} the source audio clips is stereo <b>audio</b> with a <b>sample</b> <b>rate</b> of 44.1 ks/s. The {{pre-processing}} steps for the clips include down-mixing to one channel (mono) and downsampling to 16 ks/s. After the pre-processing, different types of features are extracted according to the used network models given previously.|$|R
50|$|The 501ES could encode 16-bit digital <b>audio</b> at a <b>sample</b> <b>rate</b> of 44,1 kHz. 14-bit {{encoding}} {{was also}} possible, {{which made the}} device compatible with the similar products from Matsushita Technics. As with all PCM adaptors standardized by the EIAJ, the 501 incorporated a single converter that was time-domain multiplexed between channels.|$|R
