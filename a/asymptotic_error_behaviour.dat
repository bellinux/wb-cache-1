0|1254|Public
40|$|This paper {{investigates the}} <b>asymptotic</b> <b>error</b> rate <b>behaviour</b> for {{noncoherent}} OOK signalling scheme {{in the presence}} of Nakagami-m fading. A transcendental equation to compute the optimum threshold level is also derived. Comparison on trends in optimum threshold level and its corresponding ratio of the Mark and Space error probabilities between different channels are presented. link_to_subscribed_fulltex...|$|R
50|$|Discriminative {{classifiers}} {{have lower}} <b>asymptotic</b> <b>error</b> than generative ones; however, research by Ng and Jordan {{has shown that}} in some practical cases naive Bayes can outperform logistic regression because it reaches its <b>asymptotic</b> <b>error</b> faster.|$|R
40|$|We study a {{diffusion}} model of phase field type, {{which consists of}} a system of two partial differential equations involving as variables the thermal displacement, that is basically the time integration of temperature, and the order parameter. Our analysis covers the case of a non-smooth (maximal monotone) graph along with a smooth anti-monotone function in the phase equation. Thus, the system turns out a generalization of the well-known Caginalp phase field model for phase transitions when including a diffusive term for the thermal displacement in the balance equation. Systems of this kind have been extensively studied by Miranville and Quintanilla. We prove existence and uniqueness of a weak solution to the initial-boundary value problem, as well as various regularity results ensuring that the solution is strong and with bounded components. Then we investigate the asymptotic behaviour of the solutions as the coefficient of the diffusive term for the thermal displacement tends to 0 and prove convergence to the Caginalp phase field system as well as error estimates for the difference of the solutions. Comment: Key words: phase field model, well-posedness, regularity, <b>asymptotic</b> <b>behaviour,</b> <b>error</b> estimate...|$|R
40|$|AbstractThe Laguerre {{family of}} {{iteration}} functions for finding multiple zeros is considered. This family is algebraically {{equivalent to the}} multiple zero counterpart of Hansen–Patrick family. The <b>asymptotic</b> <b>error</b> constant for the Laguerre family is given. The magnitude of <b>asymptotic</b> <b>error</b> constants for cubically convergent iteration functions for finding multiple real zeros of real functions are compared. Numerical examples are given...|$|R
40|$|AbstractIn this paper, the {{eigenvalue}} {{approximation of}} a compact integral operator {{with a smooth}} kernel is discussed. We propose <b>asymptotic</b> <b>error</b> expansions of the iterated discrete Galerkin and iterated discrete collocation methods, and <b>asymptotic</b> <b>error</b> expansion of approximate eigenvalues. We then apply Richardson extrapolation to obtain higher order super-convergence of eigenvalue approximations. Numerical examples are presented to illustrate the theoretical estimate...|$|R
2500|$|... then [...] as [...] {{goes from}} [...] to [...] converges to [...] of order , with <b>asymptotic</b> <b>error</b> {{constant}} ...|$|R
30|$|In our work, {{we first}} present a {{theoretical}} {{comparison of the}} mean-squared error of MH-MCMC and RDS estimators. It was observed that in many practical cases RDS outperforms MH-MCMC in terms of <b>asymptotic</b> <b>error.</b> We confirm this observation here using theoretical expressions for the <b>asymptotic</b> mean-squared <b>errors</b> of the two estimators. Then, we introduce a novel estimator for the network average based on reinforcement learning (RL). By way of simulations on real networks, we demonstrate that, with a good choice of cooling schedule, RL can achieve similar <b>asymptotic</b> <b>error</b> performance to RDS but its trajectories have smaller fluctuations.|$|R
40|$|AbstractGiven {{alternative}} methods with identical order of convergence for solving the polynomial equation -(z) = 0, the method with the smaller <b>asymptotic</b> <b>error</b> constant might {{be assumed to}} be superior {{in terms of the}} number of iterations required for convergence. We present empirical evidence for a parameterized class of methods of second order showing that a parameter choice which does not correspond to the minimal <b>asymptotic</b> <b>error</b> constant may nevertheless be superior in practice...|$|R
40|$|AbstractWe study <b>asymptotic</b> <b>errors</b> of {{algorithms}} for computing {{the global}} maximum {{of any real}} function defined on the s-dimensional unit cube whose (r − 1) st derivative exists and satisfies a Lipschitz condition. We prove that the <b>asymptotic</b> <b>error</b> of any algorithm that uses adaptive linear information cannot tend to zero essentially faster than n−r/s. This rate of convergence {{can be achieved by}} spline-type algorithms which use nonadaptive function evaluations at equispaced points...|$|R
40|$|A {{framework}} for Iterative Learning Control (ILC) is {{proposed for the}} situation when the ILC algorithm {{is based on an}} estimate of the controlled variable obtained from an observer-based estimation procedure. Under the assumption that the ILC input converges to a bounded signal, a general expression for the <b>asymptotic</b> <b>error</b> of the controlled variable is given. The <b>asymptotic</b> <b>error</b> is then exemplified by an ILC algorithm applied to a flexible two-mass model of a robot joint...|$|R
40|$|AbstractWe {{consider}} integral approximations using equidistributed point sequences, which converge for Riemann integrable functions. Under certain conditions, Sobol (Soviet Math. Dokl. 14 (1973) 734) and Klinger (Computing 59 (1997) 223) showed convergence {{for some}} classes of singular functions. We focus on <b>asymptotic</b> <b>error</b> bounds {{and give a}} scheme for extensions of Sobol's results, thereby obtaining insight in the <b>asymptotic</b> <b>error</b> structure. Numerical examples are presented, validating the principle of “ignoring the singularity” and illustrating the use of extrapolation...|$|R
50|$|An <b>asymptotic</b> <b>error</b> {{estimate}} for N → ∞ is given byFurther terms in this error estimate are {{given by the}} Euler-Maclaurin summation formula.|$|R
40|$|We compare discriminative and {{generative}} {{learning as}} typied by logistic regression and naive Bayes. We show, contrary to a widelyheld belief that discriminative classiers {{are almost always}} to be preferred, that there can often be two distinct regimes of performance as the training set size is increased, one in which each algorithm does better. This stems from the observation|which is borne out in repeated experiments|that while discriminative learning has lower <b>asymptotic</b> <b>error,</b> a generative classier may also approach its (higher) <b>asymptotic</b> <b>error</b> much faster. ...|$|R
40|$|A regularized {{classifier}} {{is proposed}} for a two-population classification problem of mixed continuous and categorical variables {{in a general}} location model(GLOM). The limiting overall expected error for the classifier is given. It {{can be used in}} an optimization search for the regularization parameters. For a heteroscedastic spherical dispersion across all locations, an <b>asymptotic</b> <b>error</b> is available which provides an alternative criterion for the optimization search. In addition, the <b>asymptotic</b> <b>error</b> can serve as a baseline for practical comparisons with other classifiers. Results based on a simulation and two real datasets are presented. Regularized discrimination Location linear discriminant function Spherically symmetric across-location dispersion Limiting expected overall <b>error</b> <b>Asymptotic</b> expansion...|$|R
40|$|AbstractA regularized {{classifier}} {{is proposed}} for a two-population classification problem of mixed continuous and categorical variables {{in a general}} location model(GLOM). The limiting overall expected error for the classifier is given. It {{can be used in}} an optimization search for the regularization parameters. For a heteroscedastic spherical dispersion across all locations, an <b>asymptotic</b> <b>error</b> is available which provides an alternative criterion for the optimization search. In addition, the <b>asymptotic</b> <b>error</b> can serve as a baseline for practical comparisons with other classifiers. Results based on a simulation and two real datasets are presented...|$|R
40|$|This article {{considers}} {{the use of}} adaptive ridge classification rules for classifying an observation as coming from one of two multivariate normal distributionsN([mu](1),Â [Sigma]) andN([mu](2),Â [Sigma]). In particular, the <b>asymptotic</b> expected <b>error</b> rates for a general class of these rules are obtained and are {{compared with that of}} the usual linear discriminant rule. adaptive ridge classification rule <b>asymptotic</b> <b>error</b> rate expansion linear discrimination multivariate normal distribution...|$|R
40|$|In [14, 8] Kurtz and Protter resp. Jacod and Protter {{specify the}} <b>asymptotic</b> <b>error</b> {{distribution}} of the Euler method for stochastic differential equations (SDEs) with smooth coefficients growing at most linearly. The required differentiability and linear growth of the coefficients rule out some popular SDEs as for instance the Cox-Ingersoll-Ross (CIR) model, the Heston model, or the stochastic Brusselator. In this article, we partially extend {{one of the fundamental}} results in [8], so that also the mentioned examples are covered. Moreover, we compare by means of simulations the <b>asymptotic</b> <b>error</b> distributions of the CIR model and the geometric Brownian motion with mean reversion...|$|R
40|$|<b>Asymptotic</b> <b>error</b> {{distribution}} for approximation of a stochastic integral {{with respect to}} continuous semimartingale by Riemann sum with general stochastic partition is studied. Effective discretization schemes of which <b>asymptotic</b> conditional mean-squared <b>error</b> attains a lower bound are constructed. Two applications are given; efficient delta hedging strategies with transaction costs and effective discretization schemes for the Euler-Maruyama approximation are constructed. ...|$|R
40|$|Abstract — In this work, {{we study}} the {{convergence}} {{behavior of a}} modified Newton's method based on Simpson integral rule. The convergence properties of this method for solving equations which have simple roots have been discussed {{and it has been}} shown that it converges cubically to simple roots. And the values of the corresponding <b>asymptotic</b> <b>error</b> constants of convergence are determined. Theoretical results have been verified on the relevant numerical problems. A comparison of the efficiency of this method with other mean-based Newton's methods, based on the arithmetic, harmonic means and geometric means, is also included. Index Terms—Newton's method, mean-based method, order of convergence, <b>asymptotic</b> <b>error</b> constant, Simpson integral rule I...|$|R
40|$|AbstractIn this paper, {{we first}} discuss the constructions of three-point finite-difference {{approximation}} and a spline approximation {{for a class}} of singular two-point boundary value problems: x−α(xαu′) ′=f(x,u),u′(0 +) = 0,u(1) =A,α⩾ 1. The <b>asymptotic</b> <b>error</b> expansions of the numerical solutions of these problems are obtained. From these <b>asymptotic</b> <b>error</b> expansions {{we find that the}} finite-difference solution and the spline approximation solution approximate the exact solution from two sides. So we can obtain correct solution of high-order accuracy. Richardson's extrapolation can also be done and the accuracy of numerical solution can be improved greatly. We also present numerical examples which show the performance and efficiency of our methods...|$|R
40|$|The polynomial-trigonometric {{interpolation}} {{based on}} the Krylov approach for a smooth function given on [- 1, 1] is defined on the union of m shifted each other uniform grids with the equal number of points. The <b>asymptotic</b> <b>errors</b> of the interpolation in both uniform and L 2 metrics are investigated. It {{turned out that the}} corresponding errors can be minimized due to an optimal choice of the shift parameters. The study of <b>asymptotic</b> <b>errors</b> is {{based on the}} concept of the ”limit function ” proposed by Vallee-Poussin. In particular cases of unions of two and three uniform grids the limit functions are found explicitly and the optimal shift parameters are calculated using MATHEMATICA 4. 1 computer system. The parallel processing is investigated...|$|R
40|$|In {{this paper}} we study the performance, {{in terms of}} the <b>asymptotic</b> <b>error</b> probability, of a user which {{communicates}} with a destination {{with the aid of a}} full-duplex in-band relay. We consider that the network is interference-limited and interfering users are distributed as a Poisson point process. In this case the <b>asymptotic</b> <b>error</b> probability is upper bounded by the outage probability (OP). We investigate the outage behavior for well-known cooperative schemes, namely, decode-and-forward (DF) and compress-and-forward (CF) considering fading and path loss. For DF we determine the exact OP and develop upper bounds which are tight in typical operating conditions. Also, we find the correlation coefficient between source and relay signals which minimizes the OP when the density of interferers is small. For CF, the achievable rates are determined by the spatial correlation of the interferences, and a straightforward analysis isn’t possible. To handle this issue, we show the rate with correlated noises is at most one bit worse than with uncorrelated noises, and thus find an upper bound on the performance of CF. These results are useful to evaluate the performance and to optimize relaying schemes in the context of full-duplex wireless networks. Index Terms Cooperative communication, interference, <b>asymptotic</b> <b>error</b> probability, outage probability, decod...|$|R
40|$|A multi-parameter {{family of}} three-step eighth-order {{iterative}} methods free from second derivatives are proposed {{in this paper}} to find a simple root of nonlinear algebraic equations. Convergence analysis as well as numerical experiments confirms the eighth-order convergence and <b>asymptotic</b> <b>error</b> constants. (C) 2009 Elsevier Inc. All rights reserved...|$|R
40|$|Abstract—A {{generalized}} {{concept of}} interference suppression is introduced for multiuser systems with a known memoryless transmit non-linearity, {{such as in}} the downlink amplifier of a satellite communication system. By considering the operation of commonly used multiuser detection techniques from a viewpoint of constellation structure, we extend these notions to nonlinear multiuser systems. We also analyze the performance of such multiuser detectors in terms of their <b>asymptotic</b> multiuser <b>error</b> exponents, which reduce to the asymptotic multiuser effective energies for the respective detectors in the absence of nonlinearity. The <b>asymptotic</b> conditional <b>error</b> exponent is introduced as a quantitative measure for evaluating nonlinear multiuser detectors based on the conditional probability of error at high signal-to-noise ratio (SNR). The optimal affine detector that maximizes the <b>asymptotic</b> <b>error</b> exponent for a given user is derive...|$|R
40|$|The CFC# {{algorithm}} is a recently introduced analytical {{solution for the}} blind MIMO channel identification problem, provided a certain spectral diversity holds for the stochastic inputs of the MIMO system. Here, we develop a theoretical study to derive the asymptotic performance of the CFC# algorithm, in terms of meansquare <b>error.</b> <b>Asymptotic</b> normality of the MIMO channel estimate is proved, and the <b>asymptotic</b> <b>error</b> covariance matrix derived. Computer simulation results are included to validate the theoretical expressions...|$|R
40|$|Abstract. A {{symmetric}} {{finite volume}} element scheme on quadrilateral grids is established {{for a class}} of elliptic problems. The <b>asymptotic</b> <b>error</b> expan-sion of finite volume element approximation is obtained under rectangle grids, which in turn yields the error estimates and superconvergence of the averaged derivatives. Numerical examples confirm our theoretical analysis...|$|R
40|$|AbstractWe propose an IMT-type {{quadrature}} formula which achieves {{the same}} <b>asymptotic</b> <b>error</b> estimate as the DE formula. The {{point of the}} idea is to optimize the parameters of the IMT-type transformation depending on the number of sampling points. We also show the performance of our IMT-type quadrature formula by numerical examples...|$|R
40|$|This paper {{shows how}} to compute <b>asymptotic</b> {{standard}} <b>errors</b> of the characteristic roots of a nonlinear econometric model. The system of simultaneous equations is linearized {{in the neighborhood}} of a given point, then characteristic roots and related standard errors are computed. Nonlinear econometric models; characteristic roots; eigenvalues; <b>asymptotic</b> standard <b>errors...</b>|$|R
40|$|We {{construct}} a biparametric family of fourth-order iterative methods to compute multiple roots of nonlinear equations. This method is verified to be optimally convergent. Various nonlinear equations confirm our proposed method with order of convergence {{of four and}} show that the computed <b>asymptotic</b> <b>error</b> constant agrees with the theoretical one...|$|R
40|$|Some upper bounds for MISE of multivariate kernel density estimators are obtained. It is shown, in particular, {{that under}} some {{regularity}} conditions, the actual error is always {{less than the}} <b>asymptotic</b> <b>error.</b> Key words: Density estimation, multivariate kernel estimator, mean integrated squared error, inequalities for characteristic functions, empirical characteristic functio...|$|R
40|$|The various {{configurations}} {{in series}} of Hebb-Williams type of mazes, {{which are used}} to measure problem solving behaviour in rats, differ markedly in structure. The relationship between <b>error</b> <b>behaviour</b> and spatial maze structure in control rats tested {{in a number of}} pharmacological experiments is described in this paper. The spatial structure of <b>error</b> <b>behaviour</b> of rats was found to correlate with maze structure. Knowledge of these correlations can be used to predict error patterns in new mazes. Furthermore, aspecific experience acquired by running {{in a number of different}} configurations, affected <b>error</b> <b>behaviour</b> in a particular test configuration. This effect of aspecific experience was different from that of specific experience acquired in the same test configuration. In studies investigating effects of (e. g. pharmacological) treatments on maze behaviour of rats, changes in the structure of errors may be useful to determine the nature of the behavioural alterations. ...|$|R
40|$|AbstractHan's ‘multinode higher-order {{expansion}}’ in [H] {{is shown}} to be a special case of an <b>asymptotic</b> <b>error</b> expansion available for any bounded linear map on C([a [...] b]) that reproduces polynomials of a certain order. The key is the formula for the divided difference at a sequence containing just two distinct points...|$|R
40|$|The {{numerical}} {{integration of}} many geometric partial differential equations involve discrete approximations of some differential geometric operators. In this paper, we consider consistent discretized approximations of these operators {{based on a}} quadratic fitting scheme. <b>Asymptotic</b> <b>error</b> analysis on the quadratic fitting are conducted. The experiments show that the proposed approach is effective...|$|R
40|$|Root-mean-squared <b>errors</b> and <b>asymptotic</b> {{standard}} <b>errors</b> of ML coefficient {{estimates are}} compared for equation systems of different size, using normal and discrete bootstrap. It appears that exploiting normality does not yield any gain. Suggestions {{are made for}} correcting the downward bias of bootstrap RMSEs. <b>asymptotic</b> standard <b>error</b> bootstrap equation system maximum likelihood...|$|R
40|$|Abstract — Bit-interleaved coded {{modulation}} with iterative decoding (BICM-ID) using signal {{space diversity}} (SSD) is considered for cascaded Rayleigh fading channels. A tight bound on the <b>asymptotic</b> <b>error</b> probability is derived {{to determine the}} optimal rotation matrix for SSD design and to identify the key parameters that influence the system performance. It is shown that, for small modulation constellation, a cascaded Rayleigh fading causes a much more severe performance degradation than a conventional Rayleigh fading. However, BICM-ID employing SSD with a sufficiently large constellation can close the performance gap between the conventional and cascaded Rayleigh fading channels, and their performance can closely approach that over an AWGN channel. Illustrative simulation results for various scenarios are in a good agreement with analytical derivations. Index Terms — Bit-interleaved coded modulation (BICM), iterative decoding, signal space diversity, Rayleigh fading, cascaded Rayleigh fading, <b>asymptotic</b> <b>error</b> bound. I...|$|R
40|$|We empirically {{characterize}} {{the performance of}} discriminative and generative LSTM models for text classification. We find that although RNN-based generative models are more powerful than their bag-of-words ancestors (e. g., they account for conditional dependencies across words in a document), they have higher <b>asymptotic</b> <b>error</b> rates than discriminatively trained RNN models. However we also find that generative models approach their <b>asymptotic</b> <b>error</b> rate more rapidly than their discriminative counterparts [...] -the same pattern that Ng & Jordan (2001) proved holds for linear classification models that make more naive conditional independence assumptions. Building on this finding, we hypothesize that RNN-based generative classification models will be more robust to shifts in the data distribution. This hypothesis is confirmed {{in a series of}} experiments in zero-shot and continual learning settings that show that generative models substantially outperform discriminative models...|$|R
