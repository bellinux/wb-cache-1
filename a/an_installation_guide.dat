21|10000|Public
40|$|A {{revised version}} of Hydra, an {{adaptive}} particle-particle, particle-mesh plus smoothed particle hydrodynamics code developed by; Hugh Couchman, University of Western Ontario, Frazer Pearce, University of Durham, Peter Thomas, University of Sussex, is now available as a tar file from; [URL] or [URL]. Comment: A {{new version of the}} AP 3 M-SPH code, Hydra, is now available as a tar file from the following sites; [URL], [URL]. The release now also contains a cosmological initial conditions generator, documentation, <b>an</b> <b>installation</b> <b>guide</b> and installation tests. A LaTex version of the documentation is included her...|$|E
40|$|AMALACH project {{component}} TMODS:ENG-CZE; {{machine translation}} of queries from Czech to English. This archive contains {{models for the}} Moses decoder (binarized, pruned to allow for real-time translation) and configuration files for the MTMonkey toolkit. The aim of this package {{is to provide a}} full service for Czech->English translation which can be easily utilized as a component in a larger software solution. (The required tools are freely available and <b>an</b> <b>installation</b> <b>guide</b> is included in the package.) The translation models were trained on CzEng 1. 0 corpus and Europarl. Monolingual data for LM estimation additionally contains WMT news crawls until 2013...|$|E
40|$|This {{document}} is <b>an</b> <b>installation</b> <b>guide</b> and user manual for Version 1. 0 of the CO 2 P 3 S parallel programming system. CO 2 P 3 S is a programming system for designing, coding, and executing parallel programs that execute in a shared memory environment. CO 2 P 3 S generates framework code from a design pattern {{description of the}} structure of a program. The frame-work code contains all of the necessary communication and synchronization for the selected program structure. Application code is inserted by implementing sequential hook methods that are called by the larger framework structure...|$|E
40|$|The report {{contains}} the user's manual of the visualization system ISVAS (Interactive Software for the Visual Analysis of fracture mechanics), {{which has been}} developed for the visualization {{of the results of}} three-dimensional finite element analysis. The manual describes how to use ISVAS, the command language, the data formats and <b>a</b> brief <b>installation</b> <b>guide...</b>|$|R
5000|$|An {{installation}} PHP {{script is}} accessed via {{a web browser}} to initialize the wiki's settings. It prompts the user for a minimal set of required parameters, leaving further changes, such as enabling uploads, adding a site logo, and installing extensions, {{to be made by}} modifying configuration settings contained in a file called [...] Some aspects of MediaWiki can be configured through special pages or by editing certain pages; for instance, abuse filters can be configured through a special page, and certain gadgets can be added by creating JavaScript pages in the MediaWiki namespace. The MediaWiki community publishes <b>a</b> comprehensive <b>installation</b> <b>guide.</b>|$|R
40|$|This {{paper is}} from the SANS Institute Reading Room site. Reposting is not {{permitted}} without express written permission. Deploying a Vyatta Core Firewall This paper is intended to provide <b>a</b> practical <b>installation</b> <b>guide</b> for deploying <b>a</b> network firewall utilizing Vyatta Core 6. 0, an open source network security product. Vyatta systems are intended as a lower cost replacement for Cisco routers and security appliances. This paper is ideal for small or medium sized organizations that have IT support and desire to replace or enhance existing security appliances but are faced with ever tightening budgets. Although {{the scope of this}} paper will focus on protecting a development [...] ...|$|R
40|$|Round {{guardrail}} posts {{may provide}} an important value-added option for small-diameter thinnings. Such posts require minimum processing and {{are believed to}} have higher strength for the equivalent rectangular volume. The resulting value-added product may bring a higher return compared to lumber. The obstacles to immediate utilization of ponderosa pine and Douglas-fir guardrail posts are the need for full-scale crash testing, a visual grading rule, and <b>an</b> <b>installation</b> <b>guide.</b> This paper reports on tests and Barrier VII computer simulations at the Midwest Roadside Safety Facility and the Forest Products Laboratory to determine dynamic and static material properties and correct embedment depths. Grading practices are recommended for round ponderosa pine and Douglas-fir guardrail posts for the new Midwest Guardrail System. 1...|$|E
40|$|Hydra is an {{adaptive}} particle-particle, particle-mesh plus smoothed particle hydrodynamics N-body simulation program. It {{can be used}} with either periodic or isolated boundary conditions. A compiler flag allows the gas calculation to be turned off, converting Hydra to a collisionless mode. <b>An</b> <b>installation</b> <b>guide</b> comes with the release which provides information about how to set up and compile Hydra with parameters appropriate for your particular problem. This documentation describes the Hydra input files in more detail. In what follows code extracts and variables will be written in typewriter font. Program and subroutine names will appear in bold face and directory names will be bracketed . 1. 1 Data format The structure of data files is defined in dumpdata. f: real rm(N),r(3,N),v(3,N),dn(N),e(N),h(N) integer itype(N) write(8) ibuf,ibuf 1,ibuf 2 write(8) rm write(8) r write(8) ...|$|E
40|$|This {{document}} contains {{details about}} {{the implementation of the}} 2 nd prototype of the casmacat workbench and the Translation Process Research Database (TPR-DB). It outlines the major components of the workbench and their usage (Sections 1, 2, 3 and 6), as well as the structure and feature of the TPR-DB (Section 7). Since gaze information is the most valuable source for tracking translator e ort in text understanding, and due to the noise inherent in current head-free eye-tracking technology, Sections 4 and 5 report attempts to implement solutions for obtaining better gaze-to-word mapping accuracy. At the time of this writing, <b>an</b> <b>installation</b> <b>guide</b> 1 has been written and made available to a select group of alpha testers (researchers from universities and research laboratories) to prepare a wider release of the prototype...|$|E
40|$|This report {{describes}} the 2005 {{version of the}} Fluka particle transport code. The first part introduces the basic notions, {{describes the}} modular structure of the system, and contains <b>an</b> <b>installation</b> and beginner’s <b>guide.</b> The second part complements this initial information with details about the various components of Fluka {{and how to use}} them. It concludes with a detailed history and bibliography...|$|R
40|$|This report {{presents}} <b>an</b> <b>installation</b> and configuration <b>guide</b> {{to setting}} up a Cacti network traffic graphing solution with particular reference to {{how to set up}} Cacti for use at the Institute for Ocean Technology. This is the final work report for Memorial University Electrical-Computer Work Term Two student Chris Conway. This represents the outcome of a term project that {{can be used as a}} guide for further system development and deployment. Peer reviewed: NoNRC publication: Ye...|$|R
40|$|CosmoMC is a Fortran 95 Markov-Chain Monte-Carlo (MCMC) {{engine to}} explore the cosmological {{parameter}} space, plus a Python suite for plotting and presenting results (see [URL] This document describes {{the installation of the}} CosmoMC on a Linux system (Ubuntu 14. 04. 1 LTS 64 -bit version). It is written {{for those who want to}} use it in their scientific research but without much training on Linux and the program. Besides <b>a</b> step-by-step <b>installation</b> <b>guide,</b> we also give a brief introduction of how to run the program on both a desktop and a cluster. We share our way to generate the plots that are commonly used in the references of cosmology. For more information, one can refer to the CosmoCoffee forum ([URL] or contact the authors of this document. Questions and comments would be much appreciated. Comment: 10 pages, 0 figures. Publicly distributed and availabl...|$|R
40|$|We present here <b>an</b> <b>installation</b> <b>guide,</b> a hand-on mini-tutorial through examples, and the {{theoretical}} {{foundations of the}} Hilbert++ code. 1 INSTALLATION The code is provided in both souce and binary forms. The binaries are meant to run under the Linux-i 386 system. The distribution package is composed of two archives. The first one (let’s call it installation archive) which provides all the necessary libraries that Hilbert++ needs, and a second one, Hilbert++ itself, which comprises sources, binaries, and examples. Hilbert++ loads dynamically the libraries of the installation archive and {{does not depend on}} which Linux-packages are installed on your system with the exception of libc and libX 11. As these libraries are quite stable one should be able to run Hilbert++ on any Linux system without recompiling it. The current installation archive and the Hilbert++ packages can be retrieved from these addresses...|$|E
40|$|We {{provide an}} {{overview}} of UNICOM, an inductive theorem prover for equational logic which is based on refined rewriting and completion techniques. The architecture of the system as well as its functionality are described. Moreover, an insight into the most important aspects of the internal proof process is provided. This knowledge about how the central inductive proof component of the system essentially works is crucial for human users who want to solve non-trivial proof tasks with UNICOM and thoroughly analyse potential failures. The presentation is focussed on practical aspects of understanding and using UNICOM. A brief but complete description of the command interface, <b>an</b> <b>installation</b> <b>guide,</b> an example session, a detailed extended example illustrating various special features and a collection of successfully handled examples are also included. This work was supported by the 'Deutsche Forschungsgemeinschaft, SFB 314 (D 4 -Projekt) '. Contents 1 Introduction and Overview 4 2 The User [...] ...|$|E
40|$|This note {{presents}} a graphical setup, {{based on the}} Java Server Pages technology, intended to populate, delete and visualize the different databases involved in {{the configuration of the}} CMS Level- 1 Trigger. This has been developed {{in the context of the}} Trigger Supervisor project. This interface has been designed to be used both as a standalone tool and as a component of the Trigger Supervisor graphical user interface. <b>An</b> <b>installation</b> <b>guide</b> and The Trigger Supervisor (TS, [1]) is an on-line software system designed for the CMS experiment at CERN. Its purpose is to provide a framework to set up, test, operate and monitor the trigger components on one hand and to manage their interplay and the information exchange with the run control part of the data acquisition system on the other. The TS is conceived to provide a simple and homogeneous client interface to the online softwar...|$|E
40|$|In this {{technical}} report, {{we describe}} {{the use of a}} machine learning approach for detecting the realistic black and white ball currently in use in the RoboCup Standard Platform League. Our aim is to provide a ready-to-use software module that can be useful for the RoboCup SPL community. To this end, the approach is integrated within the official B-Human code release 2016. The complete code for the approach presented in this work can be downloaded from the SPQR Team homepage at [URL] and from the SPQR Team GitHub repository at [URL] The approach has been tested in multiple environments, both indoor and outdoor. Furthermore, the ball detector described in this technical report has been used by the SPQR Robot Soccer Team during the competitions of the Robocup German Open 2017. To facilitate the use of our code by other teams, we have prepared <b>a</b> step-by-step <b>installation</b> <b>guide...</b>|$|R
40|$|<b>A</b> {{site-specific}} <b>installation</b> {{and performance}} {{located in the}} Colyer-Fergusson Hall and an outdoor space. Softly Softly is <b>an</b> <b>installation</b> and <b>a</b> <b>guided</b> experience, making a link between play and meditation or reflection, relating materials and spatial or sensory awareness to audience members. Richard Layzell hosted tours, taking people through a guided participatory performance where adults were invited to welcome their inner children and children were invited to welcome their inner adults. It included sculptural forms, soft toys, paper planes of advanced design, ambient music, coloured lighting and very large balloons. The work explored the architectural subtleties of the new Colyer-Fergusson building at the University of Kent...|$|R
40|$|The {{reliability}} {{and performance of}} a steam generator (SG) {{is one of the}} serious concerns in the operation of pressurized water nuclear power plants. Because of high levels of radiation, robotic systems have been used to inspect and repair SG tubes. In this paper, we present a mobile robotic system that positions the inspection and repair tools while hanging down from the tube sheets where the tubes are fixed. All of the driving mechanisms of the mobile robot are actuated by electric motors to start its works, providing that the electric power is prepared without the additional need for an on-site air services. A special tube-holding mechanism with a high holding force has been developed to prevent falling from the tube sheets, even {{in the case of an}} electric power failure. We have also developed <b>a</b> quick <b>installation</b> <b>guide</b> device that guides the mobile robot to desired initial positions in the tube sheet exactly and quickly, which helps to reduce the radiation exposure of human workers during the installation work. This paper also provides on-site experimental results and lessons learned...|$|R
40|$|The U. S. EPA's Model Standards and Techniques for Control of Radon in New Residential Buildings has {{provided}} an excellent {{basis for the}} application of radon resisitant techniques for new homes. Since these methods were developed in 1994, innovations by the radon and building industry along with local construction practices have provided an additional base of experience to enhance the US EPA's original approach. The Western Regional Radon Training Center has assembled this information into a design guidance document for use by architects and as <b>an</b> <b>installation</b> <b>guide</b> for builders and their crews to follow during {{the construction of a new}} building. This new document includes mechanical soil gas collection techniques as alternatives to washed gravel; effective stack routing for passive systems; and the application of these techniques to large footprint structures. The document follows this abstract in its entirety for use by radon professionals and public health officials. It has been modified for the State of Colorado and can be found on th...|$|E
40|$|DSpace is an {{open source}} {{software}} platform that enables organizations to: - Capture and describe digital material using a submission workflow module, or a variety of programmatic ingest options - Distribute an organization's digital assets over the web through a search and retrieval system - Preserve digital assets {{over the long term}} This system documentation includes a functional overview of the system, which is a good introduction to the capabilities of the system, and should be readable by nontechnical personnel. Everyone should read this section first because it introduces some terminology used {{throughout the rest of the}} documentation. For people actually running a DSpace service, there is <b>an</b> <b>installation</b> <b>guide,</b> and sections on configuration and the directory structure. Note that as of DSpace 1. 2, the administration user interface guide is now on-line help available from within the DSpace system. Finally, for those interested in the details of how DSpace works, and those potentially interested in modifying the code for their own purposes, there is a detailed architecture and design section...|$|E
40|$|Recent {{advances}} in multi-core and many-core processors requires programmers to exploit an increasing amount of parallelism from their applications. Data parallel languages such as CUDA and OpenCL {{make it possible}} to take advantage of such processors, but still require a large amount of effort from programmers. To address the challenge of parallel programming, we introduce Bones. Bones is a source-to-source compiler based on algorithmic skeletons and a new algorithm classification. The compiler takes C-code annotated with class information as input and generates parallelized target code. Targets include NVIDIA GPUs (through CUDA), AMD GPUs (through OpenCL) and x 86 CPUs (through OpenCL and OpenMP). Bones is open-source, written in the Ruby programming language, and is available through our website. The compiler is based on the C-parser CAST, which is used to parse the input code into an abstract syntax tree (AST) and to generate the target code from a transformed AST. This document is meant as a manual for users of Bones. It includes usage instructions, <b>an</b> <b>installation</b> <b>guide</b> and pointers to further documentation. It furthermore contains an overview of the tool itself and the skeletons, a mandatory read for users that plan on modifying or extending the skeletons and/o...|$|E
40|$|Motivation: The program MBBC 2. 0 {{clusters}} time course microarray data using a Bayesian product partition model (Booth et al. 2007). Results: The Bayesian product partition {{model in}} Booth et al. (2007) simultaneously {{searches for the}} optimal number of clusters, and assigns cluster memberships based on temporal changes of gene expressions. MBBC 2. 0 to makes this method easily available for statisticians and scientists, and is built with three free computer language software packages: Ox, R, and C++, {{taking advantage of the}} strengths of each language. Within MBBC, the search algorithm is implemented with Ox and resulting graphs are drawn with R. A user-friendly graphical interface is built with C++ to run the Ox and R programs internally. Thus, MBBC users are not required to know how to useOx,R, orC++, but they must be pre-installed. Availability: A self-extractable zip file, MBBC 20 zip. exe, is available at the MBBC webpage www. stat. ufl. edu/∼casella/mbbc/, which contains MBBC. exe, source files, and all other related files. The current version works only in Windows operating system. <b>A</b> free <b>installation</b> program and overview for Ox is available at www. doornik. com. <b>A</b> detailed <b>installation</b> <b>guide</b> for Ox is provided by MBBC, and is accessible without installing Ox. R is available at www. r-project. org/. Contact...|$|R
5000|$|Virtualization Host Configuration and Guest <b>Installation</b> <b>Guide</b> ...|$|R
40|$|Background Statistical {{analysis}} and data visualization are two crucial aspects in molecular biology and biology. For analyses that compare one dependent variable between standard (e. g., control) {{and one or}} multiple independent variables, a comprehensive yet highly streamlined solution is valuable. The computer programming language R is a popular platform for researchers to develop tools that are tailored specifically for their research needs. Here we present an R package RBioplot that takes raw input data for automated statistical {{analysis and}} plotting, highly compatible with various molecular biology and biochemistry lab techniques, such as, but not limited to, western blotting, PCR, and enzyme activity assays. Method The package {{is built based on}} workflows operating on a simple raw data layout, with minimum user input or data manipulation required. The package is distributed through GitHub, which can be easily installed through one single-line R command. <b>A</b> detailed <b>installation</b> <b>guide</b> is available at [URL] Users can also download demo datasets from the same website. Results and Discussion By integrating selected functions from existing statistical and data visualization packages with extensive customization, RBioplot features both statistical analysis and data visualization functionalities. Key properties of RBioplot include: -Fully automated and comprehensive statistical analysis, including normality test, equal variance test, Student’s t-test and ANOVA (with post-hoc tests); -Fully automated histogram, heatmap and joint-point curve plotting modules; -Detailed output files for statistical analysis, data manipulation and high quality graphs; -Axis range finding and user customizable tick settings; -High user-customizability...|$|R
40|$|Abstract Background The Ambiguous Restraints for Iterative Assignment (ARIA) {{approach}} {{is widely used}} for NMR structure determination. It is based on simultaneously calculating structures and assigning NOE through an iterative protocol. The final solution consists {{of a set of}} conformers and a list of most probable assignments for the input NOE peak list. Results ARIA was extended with a series of graphical tools to facilitate a detailed analysis of the intermediate and final results of the ARIA protocol. These additional features provide (i) an interactive contact map, serving as a tool for the analysis of assignments, and (ii) graphical representations of structure quality scores and restraint statistics. The interactive contact map between residues can be clicked to obtain information about the restraints and their contributions. Profiles of quality scores are plotted along the protein sequence, and contact maps provide information of the agreement with the data on a residue pair level. Conclusion The graphical tools and outputs described here significantly extend the validation and analysis possibilities of NOE assignments given by ARIA as well as the analysis {{of the quality of the}} final structure ensemble. These tools are included in the latest version of ARIA, which is available at [URL]. The Web site also contains <b>an</b> <b>installation</b> <b>guide,</b> a user manual and example calculations. </p...|$|E
40|$|This report {{describes}} the Description Logic (DL) system FLEX. It {{consists of a}} brief overview over the field of Description Logics {{in general and the}} characteristics of FLEX, a tutorial for the FLEX system, {{a brief description of the}} inference algorithms, and an appendix containing a syntax overview, the formal semantics, a reference manual, and <b>an</b> <b>installation</b> <b>guide.</b> In a sense, the FLEX system can be seen as a extension of the DL system BACK. The main differences are that FLEX supports full disjunction and negation, weighted defaults, situated object descriptions, term-valued features, and flexible inference strategies. On the other hand, FLEX does not support some of the functionality provided by the BACK system, such as revision, for example. The FLEX system is developed in the project KIT-VM 11, which is part of the VERBMOBIL project, a project concerned with face-to-face dialogue interpreting funded by the German Ministry of Education, Science, Research and Technology. Our main criteria for designing the FLEX system are therefore based on requirements arising from the application of semantic disambiguation in Machine Translation. (orig.) SIGLEAvailable from TIB Hannover: RO 11 (124) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekBundesministerium fuer Bildung, Wissenschaft, Forschung und Technologie, Bonn (Germany) DEGerman...|$|E
40|$|The aim of {{this project}} {{is to provide a}} {{solution}} to two scalability issues that arise in big computation infraestructures: Inefficient resources utilization in the data center and the increase of the management complexity. Regarding fleets of servers, you don't have to go back far in time to verify that both configuration management and resources allocation polices have evolved very fast. The server is no longer the gravitation center and the data center consolidates as the new abstraction layer where computation happens. This project presents two platforms in simbiosis, the bootstrapping platform and the exploitation platform. The former is used to bootstrapp and manage the latter, which in turn unifies the data center resources and performs dynamic resources allocation based on demand. The project has a balanced effort of design, development and integration phases. The exploitation platform is larger in terms of number of components however, it just required an integration effort. All the building blocks are detailed in the project as well as its functions and its interactions. Despite being the smaller one, the bootstrapping platform requires the higher design and development efforts. All the building blocks are detailed in the project as well as its functions, building recips and full structural and procedural diagrams. The project ends with <b>an</b> <b>installation</b> <b>guide</b> that helps the reader to deploy a bootstrapping platform which in turn can be used to deploy an exploitation platform...|$|E
2500|$|...information on {{installing}} {{harp string}}s, harp string <b>installation</b> <b>guide</b> ...|$|R
2500|$|... (Allen Tang), <b>installation</b> <b>guide</b> for the Windows drivers [...] and ...|$|R
5000|$|Worcester Bosch Group - Energy House, Boiler <b>Installation</b> <b>Guides</b> and Guide to Energy Efficiency ...|$|R
40|$|I {{have worked}} on my {{examination}} project at Turnhill AB [1], Skellefteå. The purpose {{of the project was}} to document the network, to tidy up among the network cables in the network room, and to come up with two solutions for a VPN-solution. In the documenting phase I first encountered problems when trying to figure out which devices were plugged in to which ports of the firewall and switch. However, this was solved with time and patience. To simplify this process for future changes, I made two documents, one of which explains what devices are plugged in to which ports on the firewall/switch, and the other explains where the cables plugged in to the patch panel are plugged in to the firewall/switch. With future updates of these lists when changes are made, there should not be any trouble keeping the network neat and tidy. In my research for suitable VPN-solutions I stumbled upon the freeware Logmein Hamachi, which satisfied the needs by far. In consultation with my supervisor we chose to implement it, which did not cause any trouble. For this solution to be available when I am not longer accessible, I made <b>an</b> <b>installation</b> <b>guide</b> so that the employees of the company can use it on their own. When I was to tidy up among the cables I replaced some of the poor cables and shortened some with the help of cable ties, and I also used those to fix the cables in a neat fashion. My conclusions while working on this project were that if Turnhill were to expand their network they will need more switches. Also, if expansion is relevant there should be a reorganization of the cables in the firewall/switch ports, since the network does not look organized at this moment. Validerat; 20120627 (anonymous...|$|E
40|$|The {{original}} {{software package}} TRLan, [TRLan User Guide], page 24, implements the thick restart Lanczos method, [Wu and Simon 2001], page 24, for computing eigenvalues {lambda} and their corresponding eigenvectors v of a symmetric matrix A: Av = {lambda}v. Its effectiveness in computing the exterior eigenvalues {{of a large}} matrix has been demonstrated, [LBNL- 42982], page 24. However, its performance strongly depends on the user-specified dimension of a projection subspace. If the dimension is too small, TRLan suffers from slow convergence. If it is too large, the computational and memory costs become expensive. Therefore, to balance the solution convergence and costs, users must select an appropriate subspace dimension for each eigenvalue problem at hand. To free users from this difficult task, nu-TRLan, [LNBL- 1059 E], page 23, adjusts the subspace dimension at every restart such that optimal performance in solving the eigenvalue problem is automatically obtained. This document provides a user guide to the nu-TRLan software package. The original TRLan software package was implemented in Fortran 90 to solve symmetric eigenvalue problems using static projection subspace dimensions. nu-TRLan was developed in C and extended to solve Hermitian eigenvalue problems. It can be invoked using either a static or an adaptive subspace dimension. In order to simplify its use for TRLan users, nu-TRLan has interfaces and features {{similar to those of}} TRLan: (1) Solver parameters are stored in a single data structure called trl-info, Chapter 4 [trl-info structure], page 7. (2) Most of the numerical computations are performed by BLAS, [BLAS], page 23, and LAPACK, [LAPACK], page 23, subroutines, which allow nu-TRLan to achieve optimized performance across a wide range of platforms. (3) To solve eigenvalue problems on distributed memory systems, the message passing interface (MPI), [MPI forum], page 23, is used. The rest of this document is organized as follows. In Chapter 2 [Installation], page 2, we provide <b>an</b> <b>installation</b> <b>guide</b> of the nu-TRLan software package. In Chapter 3 [Example], page 3, we present a simple nu-TRLan example program. In Chapter 4 [trl-info structure], page 7, and Chapter 5 [trlan subroutine], page 14, we describe the solver parameters and interfaces in detail. In Chapter 6 [Solver parameters], page 21, we discuss the selection of the user-specified parameters. In Chapter 7 [Contact information], page 22, we give the acknowledgements and contact information of the authors. In Chapter 8 [References], page 23, we list reference to related works...|$|E
40|$|El propósito de este {{proyecto}} es proponer un conjunto de herramientas de soporte para los procesos de la norma ISO/IEC 29110, para que sean implementadas por las pequeñas organizaciones que desarrollen proyectos de software, ya que en la actualidad se reconoce el aporte que realizan estas con respecto a la producción de software, pues cumplen el rol de proveedores de software para medianas y grandes empresas. Por ello, las pequeñas organizaciones deben desarrollar un software eficiente y que cumpla con altos estándares de calidad. Ante este problema se creó la norma ISO / IEC 29110, un estándar que ayuda a desarrollar de manera eficiente un proyecto de desarrollo de software. La finalidad de este proyecto de investigación es apoyar mediante herramientas soporte la aplicación de la norma ISO/IEC 29110; se comprende de cinco fases: investigación de herramientas de soporte candidatas para los procesos de la norma, seleccionar una herramienta entre todas las posibles candidatas fundamentada en ciertos criterios de evaluación, documentar guías de instalación y manuales de usuario de la herramienta seleccionada, instalación de dicha herramienta en el servidor de la Universidad Peruana de Ciencias Aplicadas para uso educativo e implementar la herramienta en un proyecto de desarrollo de software para la certificación en la norma. This document {{belongs to}} the memory of the "Implementation Support Tools for process ISO / IEC 29110 - Basic Profile" with which to seek to obtain the Bachelor degree in the Engineering Information Systems career. The purpose of this project is to propose a set of support tools to the process of ISO / IEC 29110 standard to be used by small organizations that develop software projects as nowadays it’s recognized the contribution that these make with respect to the software production since fulfill the role of software suppliers for small and median companies. For that reason, small organizations have to develop efficient software that meets the high quality standards. To the problem was created the ISO / IEC 29110 standard, a working program that helps to develop of an efficient way a software development project. However, that norm is not applied by these software entities, and found that the complex to understand and apply The purpose of this research project is to support using tools support the implementation of ISO / IEC 29110 standard, it comprises five phases: First one is to Research support tools for process. Second one is to select one tool among all possible candidates based on certain evaluation criteria. Three one is to create a document that contains <b>an</b> <b>installation</b> <b>guide</b> and user guide of the tool selected. The last one is installation of this tool at Peruvian University of Applied Sciences for educational use and to implement this tool in a software development project to certification to ISO/IEC 29110. Finally, to finish the project we expect that these tools selected serve as a guide and are implemented for Small Organizations in their software develop project, resulting a successful completion of the project and proving a software that make the functional and nonfunctional requirements of the customer...|$|E
3000|$|... 1980 First VESDA System Equipment Manual {{developed}} by Cole at IEI, and VESDA <b>Installation</b> <b>Guide</b> {{developed by}} Petersen at IEI.|$|R
40|$|This {{document}} {{contains the}} manuals {{of the first}} software releases of the 5 G security enablers that are developed within the 5 G-ENSURE project. Each enabler has its own separate manual, which comprises the following three main parts: (1) <b>an</b> <b>installation</b> and administration <b>guide,</b> (2) a user and programmer guide, and (3) a description of unit tests for the enabler’s software. The enablers’ manuals are an important input for the enablers’ deployment in the project’s testbed (WP 4), where the enablers will be analyzed and evaluated. Note that the software of the project’s security enablers {{is part of the}} accompanying deliverable D 3. 3 “ 5 GPPP security enablers sw release (v 1. 0) : reference implementations for the first set of the enablers. ” Both deliverables D 3. 3 and D 3. 4 complete the prior WP 3 deliverables of {{the first year of the}} project, namely, D 3. 1 “ 5 G-PPP security enablers technical roadmap (early vision) ” and D 3. 2 “ 5 G-PPP security enablers open specifications (v 1. 0) ”...|$|R
50|$|ArchBang {{comes with}} a {{modified}} Arch Linux graphical installation script for installation and also provides a simple, easy to follow, step-by-step <b>installation</b> <b>guide.</b>|$|R
