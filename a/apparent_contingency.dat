2|8|Public
40|$|Altruistic food giving among genetically {{unrelated}} {{individuals is}} rare in nature. The few examples that exist suggest that when animals give food to unrelated others, they may do so {{on the basis of}} mutualistic or reciprocally altruistic relationships. We present the results of four experiments designed to tease apart the factors mediating food giving among genetically unrelated cotton-top tamarins (Saguinus oedipus), a cooperatively breeding New World primate. In experiment 1 we show that individuals give significantly more food to a trained conspecific who unilaterally gives food than to a conspecific who unilaterally never gives food. The <b>apparent</b> <b>contingency</b> of the tamarins' food-giving behaviour motivated the design of experiments 2 - 4. Results from all three experiments show that altruistic food giving is mediated by prior acts of altruistic food giving by a conspecific. Specifically, tamarins do not give food to unrelated others when the food received in the past represents the by-product of another's selfish actions (experiments 2 and 3) or when a human experimenter gives them food (experiment 4) as did the unilateral altruist in experiment 1. By contrast, if one tamarin gives another food without obtaining any immediate benefit, then the recipient is more likely to give food in return. Overall, results show that tamarins altruistically give food to genetically unrelated conspecifics, discriminate between altruistic and selfish actions, and give more food to those who give food back. Tamarins therefore have the psychological capacity for reciprocally mediated altruism...|$|E
40|$|The Galactic {{center has}} some of the highest stellar densities in the Galaxy and a range of {{interstellar}} scattering properties that may aid in the detection of new radio-selected transient events. Here we describe a search for radio transients in the Galactic center using over 200 hours of archival data from the Very Large Array (VLA) at 5 and 8. 4 GHz. Every observation of SgrA* from 1985 - 2005 has been searched using an automated processing and detection pipeline sensitive to transients with timescales between 30 seconds and five minutes with a typical detection threshold of ∼ 100 mJy. Eight possible candidates pass tests to filter false-positives from radio-frequency interference, calibration errors, and imaging artifacts. Two events are identified as promising candidates based on the smoothness of their light curves. Despite the high quality of their light curves, these detections remain suspect due to evidence of incomplete subtraction of the complex structure in the Galactic center, and <b>apparent</b> <b>contingency</b> of one detection on reduction routines. Events of this intensity (∼ 100 mJy) and duration (∼ 100 s) are not obviously associated with known astrophysical sources, and no counterparts are found in data at other wavelengths. We consider potential sources, including Galactic center pulsars, dwarf stars, sources like GCRT J 1745 - 3009, and bursts from X-ray binaries. None can fully explain the observed transients, suggesting either a new astrophysical source or a subtle imaging artifact. More sensitive multiwavelength studies are necessary to characterize these events which, if real, occur with a rate of 14 ^+ 32 _- 12 hr^- 1 deg^- 2 in the Galactic center. Comment: 15 pages, 14 figures, 4 tables. Accepted for publication in the Astrophysical Journa...|$|E
40|$|Complexity {{originates}} {{from the}} tendency of large dynamical systems to organize themselves into a critical state, with avalanches or "punctuations" of all sizes. In the critical state, events which would otherwise be uncoupled become correlated. The <b>apparent,</b> historical <b>contingency</b> in many sciences, including geology, biology, and economics, finds a natural interpretation as a self-organized critical phenomenon. These ideas {{are discussed in the}} context of simple mathematical models of sandpiles and biological evolution. Insights are gained not only from numerical simulations but also from rigorous mathematical analysis...|$|R
40|$|This thesis {{proposes to}} {{supplement}} the philosophy of Alain Badiou with an existentialist account of anxiety. After identifying a “phenomenological deficit” in Badiou’s thought, I argue that Kierkegaard, Heidegger, and Sartre provide the conceptual resources for theorizing the affective emergence of subjectivity from {{within the confines of}} a determinant situation. My contention, simply, is that anxiety is a rare and unsettling experience of nothing that makes <b>apparent</b> the underlying <b>contingency</b> of all situations, thereby prompting new modes of subjective behavior. In this sense, I treat anxiety as the in-situation experience of an event that may occasion the transition from a determined-individual to a determining-subject...|$|R
40|$|Five {{experiments}} {{investigated the}} roles of contingency and temporal contiguity in causal reasoning, and the trade-off between them. Participants observed an ongoing, continuous stream of events, which was not segmented into discrete learning trials. Four potential candidate causes competed for explanatory strength {{with respect to a}} single dichotomous effect. The effect was contingent on two of these causes, with one of these (A) having a higher probability of producing the effect compared to the other (B), while B was more contiguous to the effect than A. When asked to identify the strongest cause of the effect, participants consistently and reliably selected A, {{as long as it was}} not separated from the effect by more than 2. 5 s. The extent of preference diminished, however, as the contiguity gradient between A and B increased. Beyond 2. 5 s, the high-probability, but low-contiguity cause A was seen as equally strong as the low-probability, but high-contiguity cause B, and both reliably stood out compared to the remaining two non-contingent distracter items. This <b>apparent</b> trade-offbetween <b>contingency</b> and contiguity, rooted in contrasting two of David Hume’s (1739 / 1888) fundamental cues to causality, has important implications for psychological and statistical models of causal discovery, learning theory, and artificial intelligence...|$|R
40|$|Electrical grids {{have been}} {{developed}} over a century, which are considered {{as one of the}} most important infrastructures on the earth. In the past decade, the emergence of the Smart Grid, referred to the next generation of power grid, makes existing systems more complicated and vulnerable. Cyber-physical attacks against existing systems and future smart grids have drawn increasing attention, because such attacks could trigger large-scale cascading failures and result in major blackouts. In the traditional power society, contingencies are widely considered as the causes that result in power outages. The contingency analysis is the predominant method to investigate the vulnerability of power grids. With the increasing ma-licious attacks against power transmission systems, however, studying the grid’s security and reliability only from the contingency analysis perspective has <b>apparent</b> limitations. First, <b>contingencies</b> happen randomly and unintentionally; malicious attacks are mostly intentional. Second, it is rare that multiple contingencies hap...|$|R
40|$|Research {{on trade}} credit {{has been growing}} in recent years, {{contributing}} {{to our understanding of}} the phenomenon. However, the main problem is probably the impact of the contingent nature of the payment practices used by companies. The purpose of this paper is to address the determinants of trade credit in the Cameroonian context. Based on a sample of 65 Cameroonian companies observed in 2006, the econometric investigations highlight a genuine financial intermediation business close to productive activity. We used a general model incorporating both financial variables, transactional and sociocultural in order to estimate the joint effect of all explanatory variables on the trade credit which is a kind of investment in business relationship. Logistic regression results confirmed the positive and significant correlation between rationing and trade credit. There is also <b>apparent</b> influence of <b>contingency</b> factors on sociocultural commercial time through social capital and ethnicity of trade and investment partners. Moreover the manager share of capital positively influences the duration of the trade credit where as the financial motive is one that mostly influences to the companies’ behavior. </p...|$|R
40|$|Quality of worklife {{issues have}} often been {{overlooked}} by corporate management who have typically focused on 2 ̆ 2 bottom line 2 ̆ 2 issues such as quarterly productivity. Recently, however, corporations are realizing the importance of establishing a work environment that promotes the needs of its employees. This dissertation examined the relation between procedural justice and intrinsic motivation, two qualities of worklife critical to employees 2 ̆ 7 well-being. ^ Procedural justice theory posits that the fairness of organizational procedures has important ramifications for both management and employees. For instance, research suggests that giving employees an opportunity to express opinions regarding outcomes or procedures (i. e., procedural fairness) increases perceptions of fairness (Lind 2 ̆ 6 Tyler, 1988). In addition, providing respectful interpersonal treatment of employees (i. e., interactional fairness) also serves to heighten fairness perceptions (Tyler 2 ̆ 6 Bies, 1989). ^ Intrinsic motivation theory postulates {{the conditions in which}} individuals will freely engage in particular behaviors with no <b>apparent</b> external <b>contingencies.</b> Deci and Ryan (1985) have shown that perceptions of competence and self-determination are two primary determinants of intrinsic motivation. ^ Examination of the theories revealed striking parallels. A theoretical model of the relationship between procedural justice and intrinsic motivation was developed. In general, it was hypothesized that procedural justice and interactional fairness would promote intrinsic motivation through competence and self-determination. ^ The model and hypotheses were tested in a laboratory experiment that simulated a performance appraisal. One-hundred and sixty-one subjects participated. They were asked to generate brand names for new consumer products and were evaluated on their performance. Independent variables were the fairness of the performance appraisal procedures (procedural justice), the fair treatment of the subject (interactional fairness) by the supervisor (experimenter), and the sign of the performance feedback. The principal dependent variable was intrinsic motivation. ^ Results revealed that the model accounted for 74...|$|R
40|$|Two {{experiments}} {{investigated the}} roles of contingency and temporal contiguity in causal reasoning, and the trade-off between them. Participants observed an ongoing, continuous stream of events, which was not segmented into discrete learning trials. Four potential candidate causes competed for explanatory strength {{with respect to a}} single dichotomous effect. The effect was contingent on two of these causes, with one of these (A) having a higher probability of producing the effect compared to the other (B), while B was more contiguous to the effect than A. When asked to identify the strongest cause of the effect, participants consistently and reliably selected A, {{as long as it was}} not separated from the effect by more than 2. 5 s. The extent of preference diminished, however, as the contiguity gradient between A and B increased. Beyond 2. 5 s, the high-probability, but low-contiguity cause A was seen as equally strong as the low-probability, but high-contiguity cause B, and both reliably stood out compared to the remaining two non-contingent distracter items. This <b>apparent</b> trade-off between <b>contingency</b> and contiguity, rooted in contrasting two of David Hume’s (1739 / 1888) fundamental cues to causality, has important implications for psychological and statistical models of causal discovery, learning theory, and artificial intelligence...|$|R
40|$|Electrical grids {{have been}} {{developed}} over a century, which are considered {{as one of the}} most important infrastructures on the earth. In the past decade, the emergence of the Smart Grid, referred to the next generation of power grid, makes existing systems more complicated and vulnerable. Cyber-physical attacks against existing systems and future smart grids have drawn increasing attention, because such attacks could trigger large-scale cascading failures and result in major blackouts. ^ In the traditional power society, contingencies are widely considered as the causes that result in power outages. The contingency analysis is the predominant method to investigate the vulnerability of power grids. With the increasing malicious attacks against power transmission systems, however, studying the grid 2 ̆ 7 s security and reliability only from the contingency analysis perspective has <b>apparent</b> limitations. First, <b>contingencies</b> happen randomly and unintentionally; malicious attacks are mostly intentional. Second, it is rare that multiple contingencies happen simultaneously. Malicious attacks, however, can likely occur on a few, even more, the power grid components. ^ In this dissertation, the security and reliability of power grids is investigated. Briefly speaking, the attackers identify a few components in the grid as targets (e. g., substations, transmission lines, or both). Then, the attackers take down these targets by either physical sabotages or cyber intrusions, hoping that the initial failures can trigger large-scale cascading failures. The goal of the attackers is to find a group of targets, attacking on which can yield large damage to the power grid. ^ In particular, this dissertation investigates the attacks against the power system from the following aspects. ^ It is a nature question that why attacking a few, even one, critical components can severely weaken the system. In manuscript 1 (i. e., chapter 2), the cascading process is visualized to help people under such complicated phenomena, as well as discovering different types of failure propagation. ^ Attackers might only know the topological connection of the power grid, e. g., the topology. In manuscript 2 (i. e., chapter 3), a topology-based cascading model is adopted to study cascading failures. The metric load distribution vector (LDV) and LDV-based attack strategy are proposed and investigated. ^ Attackers can possibly know some general information of the power grid, e. g., the topology, types of substations and length of transmission lines. In manuscript 3 (i. e., chapter 4), the extended topological model is used to mimic cascading failures. A novel metric, called the risk graph, is proposed to reveal the hidden relationship among critical substations/transmission lines. In addition, the risk-graph based attack strategies are developed regarding substations and transmission lines, respectively. ^ Attacks can occur on substations and transmission lines simultaneously. In manuscript 4 (i. e., chapter 5), both the vulnerability analysis and the attacks are investigated from the joint substation-transmission line perspective. Attacks can be conducted not only synchronously but sequentially. In manuscript 5 (i. e., chapter 6), the sequential attack is introduced; the metric sequential attack graph(SAG) is constructed; the SAG-based sequential attack strategy is developed and evaluated. ...|$|R

