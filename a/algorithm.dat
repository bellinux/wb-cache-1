10000|10000|Public
5|$|Calculating a {{greatest}} common divisor is {{an essential}} step in several integer factorization algorithms, such as Pollard's rho <b>algorithm,</b> Shor's <b>algorithm,</b> Dixon's factorization method and the Lenstra elliptic curve factorization. The Euclidean <b>algorithm</b> {{may be used to}} find this GCD efficiently. Continued fraction factorization uses continued fractions, which are determined using Euclid's <b>algorithm.</b>|$|E
5|$|In {{computer}} science, Putnam {{is known}} for the Davis–Putnam <b>algorithm</b> for the Boolean satisfiability problem (SAT), developed with Martin Davis in 1960. The <b>algorithm</b> finds {{if there is a}} set of true or false values that satisfies a given Boolean expression so that the entire expression becomes true. In 1962, they further refined the <b>algorithm</b> with the help of George Logemann and Donald W. Loveland. It became known as the DPLL <b>algorithm.</b> This <b>algorithm</b> is efficient and still forms the basis of most complete SAT solvers.|$|E
5|$|The Euclidean <b>algorithm</b> was {{the first}} integer {{relation}} <b>algorithm,</b> which is a method for finding integer relations between commensurate real numbers. Several novel integer relation algorithms have been developed, such as the <b>algorithm</b> of Helaman Ferguson and R.W. Forcade (1979) and the LLL <b>algorithm.</b>|$|E
25|$|Every {{field of}} science has its own {{problems}} and needs efficient <b>algorithms.</b> Related problems in one field are often studied together. Some example classes are search <b>algorithms,</b> sorting <b>algorithms,</b> merge <b>algorithms,</b> numerical <b>algorithms,</b> graph <b>algorithms,</b> string <b>algorithms,</b> computational geometric <b>algorithms,</b> combinatorial <b>algorithms,</b> medical <b>algorithms,</b> machine learning, cryptography, data compression <b>algorithms</b> and parsing techniques.|$|R
30|$|Generally speaking, {{incremental}} <b>algorithms</b> {{is faster}} and has better anti-noise capacity than ensemble <b>algorithms.</b> While ensemble <b>algorithms</b> is more flexible and adapt itself better to concept drift. Moreover, incremental <b>algorithms</b> has more restrictions than ensemble <b>algorithms.</b> Not all classification <b>algorithms</b> {{can be used}} in incremental learning, but almost every classification <b>algorithms</b> {{can be used in}} an ensemble <b>algorithms.</b>|$|R
50|$|Two {{other common}} classes of {{probabilistic}} <b>algorithms</b> are Monte Carlo <b>algorithms</b> and Las Vegas <b>algorithms.</b> Monte Carlo <b>algorithms</b> are always fast, but only probably correct. On the other hand, Las Vegas <b>algorithms</b> are always correct, but only probably fast. The Atlantic City <b>algorithms</b> which are bounded probabilistic polynomial time <b>algorithms</b> are probably correct and probably fast.|$|R
5|$|This {{equation}} can {{be solved}} by the Euclidean <b>algorithm,</b> as described above. Finding multiplicative inverses is an essential step in the RSA <b>algorithm,</b> which is widely used in electronic commerce; specifically, the equation determines the integer used to decrypt the message. Note that although the RSA <b>algorithm</b> uses rings rather than fields, the Euclidean <b>algorithm</b> can still be used to find a multiplicative inverse where one exists. The Euclidean <b>algorithm</b> also has other applications in error-correcting codes; for example, {{it can be used}} {{as an alternative to the}} Berlekamp–Massey <b>algorithm</b> for decoding BCH and Reed–Solomon codes, which are based on Galois fields.|$|E
5|$|The binary GCD <b>algorithm</b> is an {{efficient}} alternative that substitutes division with faster operations by exploiting the binary representation used by computers. However, this alternative also scales like O(h²). It is generally {{faster than the}} Euclidean <b>algorithm</b> on real computers, even though it scales in the same way. Additional efficiency can be gleaned by examining only the leading digits of the two numbers a and b. The binary <b>algorithm</b> can be extended to other bases (k-ary algorithms), with up to fivefold increases in speed. Lehmer's GCD <b>algorithm</b> uses the same general principle as the binary <b>algorithm</b> to speed up GCD computations in arbitrary bases.|$|E
25|$|The <b>algorithm</b> is {{also known}} as Floyd's <b>algorithm,</b> the Roy–Warshall <b>algorithm,</b> the Roy–Floyd <b>algorithm,</b> or the WFI <b>algorithm.</b>|$|E
5000|$|Only <b>algorithms</b> {{that are}} provable {{boosting}} <b>algorithms</b> in the probably approximately correct learning formulation can accurately be called boosting <b>algorithms.</b> Other <b>algorithms</b> {{that are similar}} in spirit to boosting <b>algorithms</b> are sometimes called [...] "leveraging algorithms", although they are also sometimes incorrectly called boosting <b>algorithms.</b>|$|R
40|$|This paper {{shows how}} {{evolutionary}} <b>algorithms</b> {{can be described}} in a concise, yet comprehensive and accurate way. A classification scheme is introduced and presented in a tabular form called TEA (Table of Evolutionary <b>Algorithms).</b> It distinguishes between different classes of evolutionary <b>algorithms</b> (e. g., genetic <b>algorithms,</b> ant systems) by enumerating the fundamental ingredients of each of these <b>algorithms.</b> At the end, possible uses of the TEA are illustrated on classical evolutionary <b>algorithms.</b> Key Words: evolutionary <b>algorithms,</b> genetic <b>algorithms,</b> taxonom...|$|R
50|$|The {{scientific}} literature describes numerous <b>algorithms</b> for solving the PMS problem. These <b>algorithms</b> {{can be classified}} into two major types. Those <b>algorithms</b> that may not return the optimal answer(s) {{are referred to as}} approximation <b>algorithms</b> (or heuristic <b>algorithms)</b> and those that always return the optimal answer(s) are called exact <b>algorithms.</b>|$|R
25|$|Other {{algorithms}} {{for solving}} linear-programming problems {{are described in}} the linear-programming article. Another basis-exchange pivoting <b>algorithm</b> is the criss-cross <b>algorithm.</b> There are polynomial-time algorithms for linear programming that use interior point methods: these include Khachiyan's ellipsoidal <b>algorithm,</b> Karmarkar's projective <b>algorithm,</b> and path-following algorithms.|$|E
25|$|For {{more details}} on the {{sequences}} of operations used for various quantum algorithms, see universal quantum computer, Shor's <b>algorithm,</b> Grover's <b>algorithm,</b> Deutsch–Jozsa <b>algorithm,</b> amplitude amplification, quantum Fourier transform, quantum gate, quantum adiabatic <b>algorithm</b> and quantum error correction.|$|E
25|$|Different {{variants}} exist, see Smith–Waterman <b>algorithm</b> and Needleman–Wunsch <b>algorithm.</b>|$|E
50|$|<b>Algorithms</b> {{described}} in the transactions are generally published in Collected <b>Algorithms.</b> <b>Algorithms</b> published in Collected <b>Algorithms</b> since 1975 (and some earlier ones) are available.|$|R
3000|$|Remark 4.5. <b>Algorithms</b> 2.1 - 2.4 in [20], <b>Algorithms</b> 3.1 - 3.7 in [28], <b>Algorithms</b> 2.1 - 2.3 in [32], <b>Algorithms</b> 2.1 and 2.2 in [33] and <b>Algorithms</b> 2.1 - 2.4 in [34] {{are special}} cases of <b>Algorithms</b> 4.1 - 4.4. In brief, for a {{suitable}} and appropriate {{choice of the}} operators S [...]...|$|R
40|$|<b>Algorithms</b> {{are aimed}} at {{optimizing}} everything. They can save lives, make things easier and conquer chaos. Still, experts worry they can also put too much control {{in the hands of}} corporations and governments, perpetuate bias, create filter bubbles, cut choices, creativity and serendipity, and could result in greater unemployment. <b>Algorithms</b> are instructions for solving a problem or completing a task. Recipes are <b>algorithms,</b> as are math equations. Computer code is algorithmic. The internet runs on <b>algorithms</b> and all online searching is accomplished through them. Email knows where to go thanks to <b>algorithms.</b> Smartphone apps are nothing but <b>algorithms.</b> Computer and video games are algorithmic storytelling. Online dating and book-recommendation and travel websites would not function without <b>algorithms.</b> GPS mapping systems get people from point A to point B via <b>algorithms.</b> Artificial intelligence (AI) is naught but <b>algorithms.</b> The material people see on social media is brought to them by <b>algorithms.</b> In fact, everything people see and do on the web is a product of <b>algorithms.</b> Every time someone sorts a column in a spreadsheet, <b>algorithms</b> are at play, and most financial transactions today are accomplished by <b>algorithms.</b> <b>Algorithms</b> help gadgets respond to voice commands, recognize faces, sort photos and build and drive cars. Hacking, cyberattacks and cryptographic code-breaking exploit <b>algorithms.</b> Self-learning and self-programming <b>algorithms</b> are now emerging, so it is possible that in the future <b>algorithms</b> will write many if not most <b>algorithms...</b>|$|R
25|$|In 1962 or 1963 Dijkstra {{proposed}} the semaphore mechanism for mutual exclusion <b>algorithm</b> for n processes (a generalization of Dekker's <b>algorithm),</b> {{which was probably}} the first published concurrent <b>algorithm</b> and which introduced a new area of algorithmic research. He also identified the deadlock problem and {{proposed the}} banker's <b>algorithm</b> that prevents deadlock.|$|E
25|$|Like the simplex <b>algorithm</b> of Dantzig, the {{criss-cross}} <b>algorithm</b> is a basis-exchange <b>algorithm</b> that pivots between bases. However, the criss-cross <b>algorithm</b> {{need not}} maintain feasibility, but can pivot rather from a feasible basis to an infeasible basis. The criss-cross <b>algorithm</b> {{does not have}} polynomial time-complexity for linear programming. Both algorithms visit all2Dcorners of a (perturbed) cube in dimensionD, the Klee–Minty cube, in the worst case.|$|E
25|$|The <b>algorithm</b> {{requires}} O(m) memory. It {{is possible}} to use less memory by choosing a smaller m in {{the first step of}} the <b>algorithm.</b> Doing so increases the running time, which then is O(n/m). Alternatively one can use Pollard's rho <b>algorithm</b> for logarithms, which has about the same running time as the baby-step giant-step <b>algorithm,</b> but only a small memory requirement.|$|E
40|$|Hilbert {{order is}} widely applied in many areas. However, {{most of the}} <b>algorithms</b> are {{confined}} to low dimensional cases. In this paper, <b>algorithms</b> for encoding and decoding arbitrary dimensional Hilbert order are presented. Eight <b>algorithms</b> are proposed. Four <b>algorithms</b> are based on arithmetic operations and the other four <b>algorithms</b> are based on bit operations. For the <b>algorithms</b> complexities, four of them are linear and the other four are constant for given inputs. In {{the end of the}} paper, <b>algorithms</b> for two dimensional Hilbert order are presented to demonstrate the usage of the <b>algorithms</b> introduced...|$|R
40|$|Abstract—Logging system {{behavior}} is a staple development practice. Numerous powerful model inference <b>algorithms</b> {{have been proposed}} to aid developers in log analysis and system understanding. Unfortunately, existing <b>algorithms</b> are difficult to understand, extend, and compare. This paper presents InvariMint, an approach to specify model inference <b>algorithms</b> declaratively. We applied InvariMint to two model inference <b>algorithms</b> and present evaluation results to illustrate that InvariMint (1) leads to new fundamental insights and better understanding of existing <b>algorithms,</b> (2) simplifies creation of new <b>algorithms,</b> including hybrids that extend existing <b>algorithms,</b> and (3) {{makes it easy to}} compare and contrast previously published <b>algorithms.</b> Finally, <b>algorithms</b> specified with InvariMint can outperform their procedural versions. I...|$|R
50|$|Another {{class of}} direct search <b>algorithms</b> are the various {{evolutionary}} <b>algorithms,</b> e.g. genetic <b>algorithms.</b>|$|R
25|$|The baby-step giant-step <b>algorithm</b> is {{a generic}} <b>algorithm.</b> It works for every finite cyclic group.|$|E
25|$|Data mining {{specific}} functionality {{is exposed}} via the DMX query language. Analysis Services includes various algorithms—Decision trees, clustering <b>algorithm,</b> Naive Bayes <b>algorithm,</b> time series analysis, sequence clustering <b>algorithm,</b> linear and logistic regression analysis, and neural networks—for use in data mining.|$|E
25|$|In {{mathematical}} optimization, Dantzig's simplex <b>algorithm</b> (or simplex method) is {{a popular}} <b>algorithm</b> for linear programming.|$|E
40|$|Abstract—In {{this paper}} we develop array <b>algorithms</b> for filtering. These <b>algorithms</b> can be {{regarded}} as the Krein space generalizations of array <b>algorithms,</b> which are currently the preferred method for implementing filters. The array <b>algorithms</b> considered include two main families: square-root array <b>algorithms,</b> which are typically numerically more stable than conventional ones, and fast array <b>algorithms</b> which, when the system is time-invariant, typically offer an order of magnitude reduction in the computational effort. Both have the interesting feature that one does not need to explicitly check for the positivity conditions required for the existence of filters, as these conditions are built into the <b>algorithms</b> themselves. However, since square-root <b>algorithms</b> predominantly use-unitary transformations, rather than the unitary transformations required in the case, further investigation is needed to determine the numerical behavior of such <b>algorithms.</b> Index Terms—Array <b>algorithms,</b> estimation, fast <b>algorithms,</b> robustness, I...|$|R
30|$|In this section, {{we review}} the {{classical}} <b>algorithms</b> for constructing CDS. For more comprehensive approximation <b>algorithms</b> for CDS construction, one {{can refer to}} Du and Wan and Yu et al. [16, 17]. Since the MCDS problem in unit disk graph is NP-hard, many <b>algorithms</b> are proposed to compute approximation solutions. CDS construction <b>algorithms</b> {{can be divided into}} distributed <b>algorithms</b> and centralized <b>algorithms.</b>|$|R
40|$|Abstract—There {{has been}} {{significant}} progress in improving the performance of computer-based face recognition <b>algorithms</b> over the last decade. Although <b>algorithms</b> have been tested and compared extensively with each other, there has been remarkably little work comparing the accuracy of computer-based face recognition systems with humans. We compared seven state-of-the-art face recognition <b>algorithms</b> with humans on a facematching task. Humans and <b>algorithms</b> determined whether pairs of face images, taken under different illumination conditions, were pictures of the same person or of different people. Three <b>algorithms</b> surpassed human performance matching face pairs prescreened to be “difficult ” and six <b>algorithms</b> surpassed humans on “easy ” face pairs. Although illumination variation continues to challenge face recognition <b>algorithms,</b> current <b>algorithms</b> compete favorably with humans. The superior performance of the best <b>algorithms</b> over humans, {{in light of the}} absolute performance levels of the <b>algorithms,</b> underscores the need to compare <b>algorithms</b> with the best current control—humans. Index Terms—face and gesture recognition, performance evaluation of <b>algorithms</b> and systems, human information processing I...|$|R
25|$|The {{time for}} the two {{recursive}} calls to A and B in this <b>algorithm</b> {{is dominated by the}} time to perform the O(√n) calls to Dijkstra's <b>algorithm,</b> so this <b>algorithm</b> finds the shortest cycle in O(n3/2nbsp&lognbsp&n) time.|$|E
25|$|The BHHH <b>algorithm</b> is a {{non-linear}} optimization <b>algorithm</b> that {{is popular}} for Maximum Likelihood estimations.|$|E
25|$|The Levenberg–Marquardt <b>algorithm,</b> a {{modified}} Gauss–Newton <b>algorithm,</b> {{is often used}} to fit these equations to voltage-clamp data.|$|E
40|$|The {{problem of}} {{real-time}} scheduling spans {{a broad spectrum}} of <b>algorithms</b> from simple uniprocessor to highly sophisticated multiprocessor scheduling <b>algorithms.</b> In this paper, we study the characteristics and constraints of real-time tasks which should be scheduled to be executed. Analysis methods and the concept of optimality criteria, which leads to design appropriate scheduling <b>algorithms,</b> will also be addressed. Then, we study real-time scheduling <b>algorithms</b> for uniprocessor systems, which can be divided into two major classes: off-line and on-line. On-line <b>algorithms</b> are partitioned into either static or dynamic-priority based <b>algorithms.</b> We discuss both preemptive and non-preemptive static-priority based <b>algorithms.</b> For dynamic-priority based <b>algorithms,</b> we study the two subsets; namely, planning based and best effort scheduling <b>algorithms.</b> Some of the uniprocessor scheduling <b>algorithms</b> are illustrated by examples in the Appendix. Multiprocessor scheduling <b>algorithms</b> is another class of real-time scheduling <b>algorithms</b> which is discussed in the paper as well. We also describe techniques to deal with aperiodic and sporadic tasks, precedence constraints, and priority inversion...|$|R
40|$|Abstract 1 In this paper, we survey <b>algorithms</b> that {{allocate}} {{a parallel}} program represented by an edge-weighted {{directed acyclic graph}} (DAG), also called a task graph or macrodataflow graph, {{to a set of}} homogeneous processors, with the objective of minimizing the completion time. We analyze 21 such <b>algorithms</b> and classify them into four groups. The first group includes <b>algorithms</b> that schedule the DAG to a bounded number of processors directly. These <b>algorithms</b> are called the bounded number of processors (BNP) scheduling <b>algorithms.</b> The <b>algorithms</b> in the second group schedule the DAG to an unbounded number of clusters and are called the unbounded number of clusters (UNC) scheduling <b>algorithms.</b> The <b>algorithms</b> in the third group schedule the DAG using task duplication and are called the task duplication based (TDB) scheduling <b>algorithms.</b> The <b>algorithms</b> in the fourth group perform allocation and mapping on arbitrary processor network topologies. These <b>algorithms</b> are called the arbitrary processor network (APN) scheduling <b>algorithms.</b> The design philosophies and principles behind these <b>algorithms</b> are discussed, and the performance of all of the <b>algorithms</b> is evaluated and compared against each other on a unified basis by using various scheduling parameters...|$|R
40|$|In this paper, a {{class of}} {{interactive}} consistency <b>algorithms</b> is described, based on authentication and error-correcting codes. These <b>algorithms</b> require considerably less data communication than existing <b>algorithms,</b> whereas the required number of modules and communication rounds meet the minimum bounds. The <b>algorithms</b> based on authentication and error-correcting codes are defined and proved on basis of {{a class of}} <b>algorithms</b> called the Authenticated Dispersed Joined Communication <b>Algorithms...</b>|$|R
