186|320|Public
2500|$|Money {{market funds}} seek a stable net asset value, or NAV per share (which is {{generally}} [...] $1.00 in the United States); they aim to never lose money. The $1.00 is maintained through {{the declaration of}} dividends to shareholders, typically daily, at an amount equal to the fund's net income. If a fund's NAV drops below $1.00, {{it is said that}} the fund [...] "broke the buck." [...] For SEC registered money funds, maintaining the $1.00 flat NAV is usually accomplished under a provision under Rule 2a-7 of the 40 Act that allows a fund to value its investments at <b>amortized</b> <b>cost</b> rather than market value, provided that certain conditions are maintained. One such condition involves a side-test calculation of the NAV that uses the market value of the fund's investments. The fund's published, amortized value may not exceed this market value by more than 1/2 cent per share, a comparison that is generally made weekly. If the variance does exceed $0.005 per share, the fund could be considered to have broken the buck, and regulators may force it into liquidation.|$|E
5000|$|... the <b>amortized</b> <b>cost</b> of {{resizing}} {{a dynamic}} array does not significantly affect performance or responsiveness ...|$|E
5000|$|By {{choice of}} the {{threshold}} function, we thus obtain that the <b>amortized</b> <b>cost</b> of insertion is: ...|$|E
50|$|The {{movie was}} shot in Deadwood in the Black Hills over ten days. To <b>amortize</b> <b>costs,</b> Corman's brother Gene {{produced}} another film, Beast from Haunted Cave {{at the same time}} on the same location. Roger Corman hired ski teams from Deadwood and Lead High Schools; one played the Germans and one played the Americans.|$|R
40|$|Pairing heaps were {{introduced}} as a self-adjusting alternative to Fibonacci heaps. They provably enjoy log n <b>amortized</b> <b>costs</b> {{for the standard}} heap operations. Although {{it has not been}} verified that pairing heaps perform the decrease key operation in constant amortized time, this has been conjectured and extensive experimental evidence supports this conjecture. Moreover, pairing heaps have been observed to be superior to Fibonacci heaps in practice. However, as demonstrated in this paper, pairing heaps do not accommodate decrease key operations in constant amortized time. 1 Introduction Pairing heaps {{were introduced}} [1] as a self-adjusting alternative to Fibonacci heaps [2]. They are easy to code and provably enjoy log n <b>amortized</b> <b>costs</b> for the standard heap operations. Although it had not been verified that pairing heaps perform the decrease key operation in constant amortized time (the raison d'etre of Fibonacci heaps), this has been conjectured [1] and extensive experimental eviden [...] ...|$|R
40|$|Random hashing is a {{standard}} method to balance loads among nodes in Peer-to-Peer networks. However, hashing destroys locality properties of object keys, the critical properties to many applications, more specifically, those that require range searching. To preserve a key order while keeping loads balanced, Ganesan, Bawa and Garcia-Molina proposed a load-balancing algorithm that supports both object insertion and deletion that guarantees a ratio of 4. 237 between the maximum and minimum loads among nodes in the network using constant <b>amortized</b> <b>costs.</b> However, their algorithm is not straightforward to implement in real networks because it is recursive. Their algorithm mostly uses local operations with global max-min load information. In this work, we present a simple non-recursive algorithm using essentially the same primitive operations as in Ganesan et al. 's work. We prove that for insertion and deletion, our algorithm guarantees a constant max-min load ratio of 7. 464 with constant <b>amortized</b> <b>costs.</b> Comment: (21 pages, 3 figures...|$|R
5000|$|Here, the {{potential}} [...] is unchanged, so the <b>amortized</b> <b>cost</b> of creation is , the actual cost.|$|E
5000|$|We {{use this}} {{inequality}} and the <b>amortized</b> <b>cost</b> {{of access to}} achieve a telescoping sum that is bounded by: ...|$|E
50|$|Minimum(Q): The {{operation}} {{does not}} alter the data structure so the <b>amortized</b> <b>cost</b> is equal to its actual cost, O(1).|$|E
5000|$|Reuse: <b>Amortize</b> the <b>cost</b> {{of energy}} generation, storage, and {{delivery}} by sharing energy and its infrastructure among different loads.|$|R
50|$|In {{the dynamic}} case, when a key is {{inserted}} into the hash table, if its entry in its respective subtable is occupied, then a collision is said to occur and the subtable is rebuilt based on its new total entry count and randomly selected hash function. Because the load factor of the second-level table is kept low (1/k), rebuilding is infrequent, and the <b>amortized</b> expected <b>cost</b> of insertions is O(1). Similarly, the <b>amortized</b> expected <b>cost</b> of deletions is O(1).|$|R
5000|$|It {{is used on}} {{expensive}} {{classes of}} computers to help <b>amortize</b> the <b>cost</b> by keeping high rates of utilization of those expensive resources ...|$|R
50|$|The same {{analysis}} applies and the <b>amortized</b> <b>cost</b> of a splaying {{operation is}} again:where W {{is the sum}} of all weights.|$|E
5000|$|The cost of {{acquisition}} occurs only at {{the beginning}} of a relationship: the longer the relationship, the lower the <b>amortized</b> <b>cost.</b>|$|E
5000|$|If {{the asset}} passes the {{contractual}} cash flows test, the business model assessment determines how the instrument is classified. If the instrument {{is being held}} to collect contractual cash flows, i.e., it {{is not expected to}} be sold, it is classified as <b>amortized</b> <b>cost.</b> [...] If the business model for the instrument is to both collect contractual cash flows and potentially sell the asset, it is reported at FVOCI. [...] For a FVOCI asset, the <b>amortized</b> <b>cost</b> basis is used to determine profit and loss, but the asset is reported at fair value on the balance sheet, with the difference between <b>amortized</b> <b>cost</b> and fair value reported in other comprehensive income. [...] For any other business model, such as holding the asset for trading, the asset is reported at FVPL.|$|E
40|$|We {{describe}} Trellis, {{a platform}} for hosting virtual networks on shared commodity hardware. Trellis allows each virtual network to define its own topology, control protocols, and forwarding tables, while <b>amortizing</b> <b>costs</b> by sharing the physical infrastructure. Trellis synthesizes two containerbased virtualization technologies, VServer and NetNS, {{as well as a}} new tunneling mechanism, EGRE, into a coherent platform that enables high-speed virtual networks. We describe the design and implementation of Trellis and evaluate its packet-forwarding rates relative to other virtualization technologies and native kernel forwarding performance. 1...|$|R
50|$|Finally, limited utility {{has kept}} {{production}} levels low {{enough that it}} has been impossible to <b>amortize</b> development <b>costs</b> sufficiently to make ground effect vehicles competitive with conventional aircraft.|$|R
30|$|Licensing Agreement – these engagements are {{forms of}} out-tasking and used when {{sourcing}} a tangible asset, {{such as a}} technology or real estate. Licensing agreements for technology usually {{take the form of}} software as a service (SaaS) contracts (Harward 2010). When the cost of implementation and set-up are high, these deals are often times multi-year. This allows the client to <b>amortize</b> <b>costs</b> over longer periods of time. When these costs are low, deals often take the shape of month to month. Contracts for license agreements are generally purchase orders with defined terms and a unit price in the form of price per time.|$|R
5000|$|The cost of {{acquisition}} occurs only at {{the beginning}} of a relationship, so the longer the relationship, the lower the <b>amortized</b> <b>cost.</b>|$|E
50|$|Aggregate {{analysis}} {{determines the}} upper bound T(n) {{on the total}} cost of a sequence of n operations, then calculates the <b>amortized</b> <b>cost</b> to be T(n) / n.|$|E
5000|$|If the merge is employed, {{then the}} drop in the {{potential}} function is exactly the actual cost of merging [...] and , so the <b>amortized</b> <b>cost</b> is [...]|$|E
40|$|Abstract. We present D 3 -Tree, {{a dynamic}} {{deterministic}} structure for data management in decentralized networks, by engineering and further extending an existing decentralized structure. D 3 -Tree achieves O(logN) worst-case search cost (N {{is the number}} of nodes in the network),O(logN) <b>amortized</b> load-balancing <b>cost,</b> and it is highly fault-tolerant. A particu-lar strength of D 3 -Tree is that it achieves O(logN) <b>amortized</b> search <b>cost</b> under massive node failures. We conduct an extensive experimental study verifying that D 3 -Tree outperforms other well-known structures and that it achieves a significant success rate in element queries in case of massive node failures. ...|$|R
50|$|The {{provision}} allows {{taxpayers to}} elect to <b>amortize</b> the <b>costs</b> of creating or acquiring a musical composition over five years. This election {{would be made}} {{in lieu of the}} income forecast method for these advances.|$|R
5000|$|After the {{transaction}} on 28 January, {{he did not}} play any game for Triestina and the club relegated, only re-admitted to 2010-11 Serie B due to the expel of A.C. Ancona. However, D'Ambrosio and Cottafava, who carried a high accounting value which generated high <b>amortize</b> <b>cost,</b> {{as well as other}} financial problem limited the club to sign player, which the club relegated again in 2011, and ultimately declared bankruptcy in mid of 2011-12 Lega Pro Prima Divisione. The creditor got nothing from Cottafava nor D'Ambrosio's contract, which [...] "worth" [...] €440,000 in August 2010 and €850,000 in January 2010 respectively and released as free agent in 2011 and 2012 respectively.|$|R
5000|$|Certain {{elements}} of IFRS 9 as issued were criticized by some key IASB constituents. The model for classifying debt instrument assets permitted only two approaches, fair value with all changes in fair value reported in {{profit and loss}} (FVPL), or <b>amortized</b> <b>cost.</b> [...] This represented a significant deviation from FASB decisions, which would also have a category of fair value with certain changes in fair value reported in other comprehensive income (FVOCI). [...] In addition to creating significant divergence with FASB, {{the lack of a}} FVOCI category would have been inconsistent with the accounting model being developed by the IASB for insurance contracts. [...] There were also concerns that the criteria for qualifying for the <b>amortized</b> <b>cost</b> category were overly stringent and would force many financial instruments to be reported at fair value even though they could be appropriately accounted for at <b>amortized</b> <b>cost.</b> [...] To address these concerns, IASB issued an exposure draft in 2012 proposing limited amendments to the classification and measurement of financial instruments.|$|E
50|$|When summed {{over the}} entire splay {{operation}}, this telescopes to 3(rank(root)−rank(x)) which is O(log n). The Zig operation adds an <b>amortized</b> <b>cost</b> of 1, but there's at most one such operation.|$|E
50|$|Certain {{financial}} instruments may be recorded at historical cost. Any initial premium or discount is amortized into interest over time, {{and so the}} resulting value {{is often described as}} <b>amortized</b> <b>cost.</b>|$|E
50|$|The costs {{associated}} with each technique are difficult to compare given the vast choices of designs and experimental conditions. However, for every technique, attaining a high multiplexing level where many loci are assayed simultaneously <b>amortizes</b> the <b>costs.</b>|$|R
40|$|International audienceInfiniBand high {{performance}} networks {{require that the}} buffers used for sending or receiving data are registered. Since memory registration is an expensive operation, some communication libraries use caching (rcache) to <b>amortize</b> its <b>cost,</b> and copy data into pre-registered buffers for small messages. In this paper, we present a software protocol for InfiniBand that always uses a memory copy, and <b>amortizes</b> the <b>cost</b> of this copy with a superpipeline to overlap the memory copy and the RDMA. We propose a performance model of our protocol to study its behavior and optimize its parameters. We have implemented our protocol in the NewMadeleine communication library. The results of MPI benchmarks show a significant improvement in cache-unfriendly applications that do not reuse the same memory blocks all over the time, without degradation for cache-friendly applications...|$|R
40|$|Sliding window {{detection}} {{is inherently}} slow {{because of the}} large number of windows to classify [...] especially with many object classes to detect Goal: use segmentation to propose windows likely to contain objects to avoid exhaustive search However: (1) Segmentation takes time (2) Different segmentations work for different objects Want to <b>amortize</b> <b>cost</b> of segmentation across object classes Detection of 9 indoor objects (LabelMe [4] + Stanford office scenes) Compared to sliding window, we classify two orders of magnitude fewer windows and obtain a 10 x runtime speedup while maintaining the same detection accuracy. Detection of 2 outdoor objects (StreetScenes [5]) Compared to sliding window, we classify 60. 4 x fewer windows and obtain a 15. 2 x runtime speedup. A Steiner tree approach to efficient object detectio...|$|R
5000|$|Let s(v) be {{the number}} of nodes under v in the tree of {{auxiliary}} trees. Then the potential function [...] We know that the <b>amortized</b> <b>cost</b> of splaying is bounded by: ...|$|E
5000|$|If x is in list L, {{then all}} the {{elements}} from L are inserted in T. This has a cost of [...] of some constant a, amortized over the 2-4 tree. After inserting and updating the [...] and [...] pointers, the total time spent is bounded by [...]The second operation is to delete x from T, and {{to walk on the}} path from x to , correcting [...] and [...] values. The time is spent at most [...] If , then the <b>amortized</b> <b>cost</b> will be [...]Delete(Q, x): is the addition of the <b>amortized</b> <b>cost</b> of Minimum(Q) and Delete(Q, x), which is [...]|$|E
50|$|Operation find minimum is now trivial {{because we}} keep the pointer to the node {{containing}} it. It {{does not change the}} potential of the heap, therefore both actual and <b>amortized</b> <b>cost</b> are constant.|$|E
40|$|We {{present a}} {{distributed}} self-adjusting algorithm for skip graphs that minimizes the average routing costs between arbitrary communication pairs by performing topological {{adaptation to the}} communication pattern. Our algorithm is fully decentralized, conforms to the CONGEST model (i. e. uses O(n) bit messages), and requires O(n) bits of memory for each node, where n is {{the total number of}} nodes. Upon each communication request, our algorithm first establishes communication by using the standard skip graph routing, and then locally and partially reconstructs the skip graph topology to perform topological adaptation. We propose a computational model for such algorithms, as well as a yardstick (working set property) to evaluate them. Our working set property {{can also be used to}} evaluate self-adjusting algorithms for other graph classes where multiple tree-like subgraphs overlap (e. g. hypercube networks). We derive a lower bound of the <b>amortized</b> routing <b>cost</b> for any algorithm that follows our model and serves an unknown sequence of communication requests. We show that the routing cost of our algorithm is at most a constant factor more than the <b>amortized</b> routing <b>cost</b> of any algorithm conforming to our computational model. We also show that the expected transformation cost for our algorithm is at most a logarithmic factor more than the <b>amortized</b> routing <b>cost</b> of any algorithm conforming to our computational model...|$|R
40|$|Abstract. We {{describe}} {{public key}} encryption schemes with security provably based on the worst case hardness of the approximate Shortest Vector Problem in some structured lattices, called ideal lattices. Under {{the assumption that the}} latter is exponentially hard to solve even with a quantum computer, we achieve CPA-security against subexponential at-tacks, with (quasi-) optimal asymptotic performance: if n is the security parameter, both keys are of bit-length Õ(n) and the <b>amortized</b> <b>costs</b> of both encryption and decryption are Õ(1) per message bit. Our construc-tion adapts the trapdoor one-way function of Gentry et al. (STOC' 08), based on the Learning With Errors problem, to structured lattices. Our main technical tools are an adaptation of Ajtai's trapdoor key genera-tion algorithm (ICALP' 99) and a re-interpretation of Regev's quantum reduction between the Bounded Distance Decoding problem and sam-pling short lattice vectors. ...|$|R
40|$|Deterministic fully dynamic graph {{algorithms}} {{are presented}} for connectivity, minimum spanning tree, 2 -edge connectivity, and biconnectivity. Assuming that {{we start with}} no edges in a graph with n vertices, the <b>amortized</b> operation <b>costs</b> are O(log 2 n) for connectivity, O(log 4 n) for minimum spanning forest, 2 -edge connectivity, and O(log 5 n) biconnectivity...|$|R
