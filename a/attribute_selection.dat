465|465|Public
5000|$|In machine {{learning}} and statistics, feature selection, {{also known as}} variable selection, <b>attribute</b> <b>selection</b> or variable subset selection, {{is the process of}} selecting a subset of relevant features (variables, predictors) for use in model construction. Feature selection techniques are used for four reasons: ...|$|E
50|$|Data Preparation: The data {{preparation}} phase covers all activities {{to construct the}} final dataset (data that will be fed into the modeling tool(s)) from the initial raw data. Data preparation tasks {{are likely to be}} performed multiple times, and not in any prescribed order. Tasks include table, record, and <b>attribute</b> <b>selection</b> as well as transformation and cleaning of data for modeling tools.|$|E
5000|$|Guild Wars {{is similar}} to {{collectible}} card games such as Magic: The Gathering {{because of the way}} the different skills interact. While in a town or staging area, a character's skill and <b>attribute</b> <b>selection</b> can be freely modified to construct a [...] "build". Once in a combat zone (such as an explorable area or a PvP arena), the build becomes immutable until the character exits the combat zone and returns to a staging area. Players generally either choose a specific build for a given area or role, or use builds that synergize with the builds of other characters in the party.|$|E
40|$|The principles, {{methods and}} {{algorithms}} of informative <b>attributes</b> <b>selection</b> were developed for optimization of description and representation for {{the objects in}} systems of adaptive data processing, where data are non-stationary by nature. The proposed algorithms of informative <b>attributes</b> <b>selection</b> for one-dimensional time series {{are based on the}} simplified ratings of correlation, mathematical expectation, dispersion of attributes. The algorithms have been developed using dynamic properties of information, i. e. control of conditional moments and parameters of regression model on confidential intervals. The methods and algorithms of adaptive data processing were tested on an example of extensive data represented for forecasting in systems of electro-supply...|$|R
40|$|Purpose: The main aim of {{research}} was to analyze the selection process of quantitative constructional attributes in construction series of types. Design/methodology/approach: The quantitative constructional <b>attributes</b> <b>selection</b> process is based on constructional similarity theory. Findings: The constructional similarity theory allows to select the quantitative constructional attributes. Research limitations/implications: The final construction similarity is not complete because of adjusting the dimension values to preferred numbers, catalogue and standardized elements dimensions etc. Practical implications: Presented method was applied to generate the constructions series of types {{with the use of}} quantitative constructional <b>attributes</b> <b>selection</b> process. Originality/value: Described analysis presents the process of selecting the quantitative constructional attributes with computer aid...|$|R
5000|$|Selection: by point, by rectangle, by <b>attributes,</b> clear <b>selection.</b>|$|R
40|$|In {{this paper}} we {{describe}} a cross-linguistic experiment in <b>attribute</b> <b>selection</b> for referring expression generation. We used a graph-based <b>attribute</b> <b>selection</b> algorithm that was trained and cross-evaluated on English and Dutch data. The {{results indicate that}} <b>attribute</b> <b>selection</b> {{can be done in}} a largely language independent way. ...|$|E
40|$|At present, in {{the fault}} {{diagnosis}} database of submarine optical fiber network, the <b>attribute</b> <b>selection</b> of large data is completed by detecting {{the attributes of}} the data, the accuracy of large data <b>attribute</b> <b>selection</b> cannot be guaranteed. In this paper, a large data <b>attribute</b> <b>selection</b> method based on support vector machines (SVM) for fault diagnosis database of submarine optical fiber network is proposed. Mining large data in the database of optical fiber network fault diagnosis, and calculate its attribute weight, attribute classification is completed according to attribute weight, so as to complete <b>attribute</b> <b>selection</b> of large data. Experimental results prove that,the proposed method can improve the accuracy of large data <b>attribute</b> <b>selection</b> in fault diagnosis database of submarine optical fiber network, and has high use value...|$|E
40|$|We {{describe}} a graph-based generation system {{that participated in}} the TUNA <b>attribute</b> <b>selection</b> and realisation task of the REG 2008 Challenge. Using a stochastic cost function (with certain properties for free), and trying attributes from cheapest to more expensive, the system achieves overall. 76 DICE and. 54 MASI scores for <b>attribute</b> <b>selection</b> on the development set. For realisation, {{it turns out that}} in some cases higher <b>attribute</b> <b>selection</b> accuracy leads to larger differences between system-generated and human descriptions. ...|$|E
40|$|Data Mining {{represents}} the extraction previously unknown, and potentially useful information from data. Using Data Mining Decision Trees techniques our investigation tries {{to illustrate how}} to extract meaningful socio-economical knowledge from large data sets. Our tests find 5 <b>attributes</b> <b>selection</b> measures that perform more accurate then the best performance of the 17 algorithms presented in literature. ...|$|R
40|$|A trade {{study was}} {{initiated}} at the NASA/Johnson Space Center in May of 1992 {{to develop and}} evaluate main propulsion system alternative configurations for the First Lunar Outpost (FLO) lander and return vehicles. This paper outlines the trade methodology utilized in the FLO vehicle study. Emphasis {{is placed on the}} trade <b>attributes,</b> <b>selection</b> criteria, and evaluation process established to perform the comprehensive analysis required to rank the diverse alternative vehicle configurations considered. The use of sensitivity analyses to determine the relative importance of each <b>attribute</b> and <b>selection</b> criteria on the trade results is also presented. Lastly, the paper discusses FLO vehicle configuration recommendations and general vehicle design conclusions which can be drawn from the trade study results...|$|R
30|$|In a {{transport}} network, {{represented in}} the form of nodes (junctions) and links (roads), there could be multiple routes between a given source and destination. It might be difficult for travelers to determine the optimal route because of complex and multiple criteria evaluation process involved in route choice. The optimal route among multiple alternatives can be defined as the alternative with high performance on its associated <b>attributes</b> (<b>selection</b> criteria).|$|R
40|$|Many {{learning}} algorithms make {{an implicit}} assumption {{that all the}} attributes of the presented data are relevant to a learning task. However, several studies on <b>attribute</b> <b>selection</b> have demonstrated that this assumption rarely holds. In addition, for many supervised learning algorithms such as nearest neighbour algorithms, the inclusion of irrelevant attributes {{can result in a}} degradation in the classification accuracy of the learning algorithm. Whilst a number of different methods for <b>attribute</b> <b>selection</b> exist, many of these are only appropriate for datasets which contain a small number of attributes (e. g. < 20). This paper presents an alternative approach to <b>attribute</b> <b>selection,</b> which can be applied to datasets with a greater number of attributes. We present an evaluation of the approach which contrasts its performance with one other <b>attribute</b> <b>selection</b> technique...|$|E
40|$|<b>Attribute</b> <b>selection</b> is a data {{preprocessing}} step {{which aims}} at identifying relevant attributes for the target machine learning task – namely classification in this paper. In this paper, we propose a new <b>attribute</b> <b>selection</b> strategy – {{based on a}} lazy learning approach – which postpones the identification of relevant attributes until an instance is submitted for classification. Our strategy relies on the hypothesis that {{taking into account the}} attribute values of an instance to be classified may contribute to identifying the best attributes for the correct classification of that particular instance. Experimental results using the k-NN and Naive Bayes classifiers, over 40 different data sets from the UCI Machine Learning Repository and five large data sets from the NIPS 2003 feature selection challenge, show the effectiveness of delaying <b>attribute</b> <b>selection</b> to classification time. The proposed lazy technique in most cases improves the accuracy of classification, when compared with the analogous <b>attribute</b> <b>selection</b> approach performed as a data preprocessing step. We also propose a metric to estimate when a specific data set can benefit from the lazy <b>attribute</b> <b>selection</b> approach...|$|E
40|$|This paper {{presents}} a new <b>attribute</b> <b>selection</b> measure-variable <b>attribute</b> <b>selection,</b> {{based on an}} extended version of discernibility matrix. The new measure has an advantage for users to acquire knowledge of different levels of granularity, for example, discriminant rules or characteristic rules. It {{can also be used}} for handling continuous-valued attributes. Empirical results demonstrate that applying the variable <b>attribute</b> <b>selection</b> method to continuousvalued attributes datasets can produce simpler rules than using discretization as a preprocessing in rough set induction. Keywords: rough set, rule induction, <b>attribute</b> <b>selection</b> 1 Introduction In the area of machine learning, especially of rule induction, there has been considerable interest in rough set theory. Applying rough set-based methods to rule induction has several advantages: (1) introducing theoretical basis for rule induction or machine learning; (2) easily handling missing values without additional preprocess work; (3) in [...] ...|$|E
40|$|A new {{approach}} towards solving the pattern recognition problems in hybrid optical/digital correlators is suggested. The method {{is based on}} the authors' know-how-principle of transforming the field intensity or amplitude data on the identified object assuming that these data may be entered into a computer by ordinary methods. This principle allows to solve the unification of the correlation functions and recognition <b>attributes</b> <b>selection</b> problem using a unified, identified object's class-independent method. Presented experimental results confirm applicability of this approach...|$|R
40|$|IEEE, IEEE Comp Soc, Tech Council Software EngnData {{transformation}} and <b>attribute</b> subset <b>selection</b> {{have been adopted}} in improving software defect/failure prediction methods. However, little consensus was achieved on their effectiveness. This paper reports a comparative study on these two kinds of techniques combined with four classifier and datasets from two projects. The results indicate that data transformation displays unobvious influence on improving the performance, while <b>attribute</b> subset <b>selection</b> methods show distinguishably inconsistent output. Besides, consistency across releases and discrepancy between the open-source and in-house maintenance projects {{in the evaluation of}} these methods are discussed...|$|R
2500|$|It is {{apparent}} that different <b>attribute</b> subset <b>selections</b> will in general lead to different indiscernibility classes. For example, if attribute [...] alone is selected, we obtain the following, much coarser, equivalence-class structure: ...|$|R
40|$|This paper {{presents}} {{a study on}} the performance of <b>attribute</b> <b>selection</b> methods to be used with Ant-Miner algorithm for web text categorization. The new generated data set by each <b>attribute</b> <b>selection</b> method was classified with Ant-Miner to see the performance in terms of predictive accuracy and the number of rules generated. The results of classification were also compared to C 4. 5 algorithm...|$|E
40|$|The {{application}} of text mining in organizations is growing. Text classification, an important type of text mining problem, {{is characterized by}} a large attribute space and entails an efficient and effective <b>attribute</b> <b>selection</b> procedure. There are two general <b>attribute</b> <b>selection</b> approaches: the filter approach and the wrapper approach. While the wrapper approach is potentially more effective in finding the best attribute subset, it is cost-prohibitive in most text classification applications. In this paper, we propose a hybrid <b>attribute</b> <b>selection</b> approach that is both efficient and effective for text classification problems. We apply the proposed approach to detect and prevent Internet abuse in the workplace, which is becoming a major problem in modern organizations. The empirical evaluations we conducted using a variety of classification algorithms, indexing schemes, and <b>attribute</b> <b>selection</b> methods demonstrate the utility of the proposed approach. We found that combining the filter and wrapper approaches not only boosts the accuracies of text classifiers but also brings down the computational costs significantly...|$|E
30|$|From {{a machine}} {{learning}} viewpoint, {{the identification of}} causative SNPs among available SNPs in genetic association studies can be treated as an <b>attribute</b> <b>selection</b> problem. The aim of <b>attribute</b> <b>selection</b> is to identify informative attributes necessary for the correct classification of recruited samples. Saeys et al. (2007) categorise <b>attribute</b> <b>selection</b> techniques into three main approaches: filter, wrapper and embedded approaches. The filter approach interests in identifying SNPs associated with the disease according to a statistical or mathematical measure. The wrapper approach attempts {{to search for the}} best SNP combination that provides the highest prediction accuracy dictated by a classifier. The embedded approach uses available SNPs to construct a prediction model while simultaneously prioritises informative SNPs.|$|E
40|$|AbstractViewpoints {{of various}} {{interest}} groups {{should be addressed}} in any public service appraisal. Urban public transportation development and services have diverse impacts on users, operators and the community. The impacts can be characterized by {{a wide range of}} perspectives including: efficiency, effectiveness, and efficacy, economic, social and environmental dimensions. The objective of the study summarized herein was to shed some light on the perceived attributes pertinent to the Tehran regular transit service appraisal. The research revealed interesting results regarding the key perceived attributes and criteria. The surveyed groups showed interesting similarities and differences in their <b>attributes,</b> <b>selections</b> and choices...|$|R
40|$|AbstractThis paper {{discusses}} the general concept of Bayesian Network classifier and the optimisation of a predictive spatial model using Naive Bayes (NB) on secondary mineral deposit data. A different NB modelling approaches to mineral distribution data {{was used to}} predict the occurrence of a particular mineral deposit in a given area, which include; predictive attributes sub-selection, normalised <b>attributes</b> <b>selection,</b> NB dependent <b>attributes</b> and the strictness to NB model assumptions of <b>attributes</b> independence <b>selection.</b> The performance of the model was determined by selecting a model with the best predictive accuracy. The NB classifier that violates assumptions of attributes independence {{was used to compare}} with other forms of NB. The aim is to improve the general performance of the model through the best <b>selection</b> of predictive <b>attribute</b> data. The paper elaborates the workings of a Bayesian Network learning model, the concept of NB and its application to predicting mineral deposit potentials. The result of the optimised NB model based on predictive accuracies and the Receivr Operating Characteristics (ROC) value is also determined...|$|R
40|$|AbstractThe {{combination}} of case-based reasoning (CBR) and genetic algorithm (GA) is {{considered in the}} problem of failure mode identification in aeronautical component failure analysis. Several implementation issues such as matching <b>attributes</b> <b>selection,</b> similarity measure calculation, weights learning and training evaluation policies are carefully studied. The testing applications illustrate that an accuracy of 74. 67 % can be achieved with 75 balanced distributed failure cases covering 3 failure modes, and that the resulting learning weight vector can be well applied to the other 2 failure modes, achieving 73. 3 % of recognition accuracy. It is also proved that its popularizing capability is good to the recognition of even more mixed failure modes...|$|R
3000|$|<b>Attribute</b> <b>Selection</b> using Information Gain {{based on}} the rank values of zero and more (column 4, Attributes Selection) [...]...|$|E
40|$|<b>Attribute</b> <b>selection</b> (Feature Selection) is a {{significant}} technique for data preprocessing and dimensionality reduction. Rough set {{has been used for}} <b>attribute</b> <b>selection</b> with great success. The optimal solution of rough set <b>attribute</b> <b>selection</b> is a subset of attributes called a reduct. Rough set uses approximation during reduction process to handle information inconsistency. However, some rough set approaches to <b>attribute</b> <b>selection</b> are inadequate at finding optimal reductions as no perfect heuristic can ensure optimality. Applying rough set for selecting the optimal subset of KDD Cup 1999 does not guarantee finding the optimal reduct of each class of this dataset due to the overlap between the lower and upper approximation of each class and the overlap between the reducts of all classes. This paper introduces a new approach to enhance the reduct of all classes by overcoming the overlap problem of rough set through adding union and voting attributes of all dataset classes as new reducts in addition to the normal reduct. The all reducts were evaluated by using different classification algorithms. The approach led to generate two generic attributes sets that achieved high and comparable accuracy rates as the normal attributes of rough set for the same dataset...|$|E
30|$|The chosen <b>attribute</b> <b>selection</b> {{technique}} was {{applied only to}} the training set (Evaluation, Step- 5) and the best subset of attributes was selected.|$|E
40|$|A {{structural}} probit {{model is}} estimated to determine {{the change in the}} probability of selecting a milk handler. Cooperatives are thought to have lower prices and higher deductions than independent milk handlers and these factors reduce the probability that a farmer will select a cooperative by 0. 39 and 0. 32. Cooperatives are thought to have better services and an assured market and payment than independent mile handlers and these factors increase the probability that a farmer will select a cooperative by 0. 20 and 0. 26. This indicates that many cooperative members value monetary characteristics over non-monetary characteristics. Cooperatives, Processors, <b>Attributes,</b> <b>Selection,</b> Probit, Dairy, Livestock Production/Industries,...|$|R
40|$|The yeast Cryptococcus neoformans {{can cause}} fatal infections such as meningitis. Its capsule size {{presents}} great variance under infection and different culture medium. We developed automated supervised classifications for 3 culture medium and <b>attributes</b> <b>selection,</b> which simulates the infection conditions for variances of morphologies of capsules. Different data mining techniques have been investigated, neural networks, decision tree, decision table, naive bayes etc. The {{results show that}} five approaches perform well obtaining success rate around 80 %. Attributes such as ratio of area, diameter, first order and second order moments invariants of capsule and inner part of cells, do really have the better prediction ability. ...|$|R
40|$|AbstractPractical {{application}} of data mining in scientific and engineering domains, when explored, pose many problems and provide interesting results. In this paper, {{we attempt to}} mine out association rules from 37 (1969 – 2005) years of Indian summer monsoon rainfall data and try its applicability in helping better prediction of Indian summer monsoon rainfall. We shortlist 36 variables as possible predictors of Indian summer monsoon rainfall based on previous literature and compare prediction using all 36 variables and prediction by selected attributes from derived association rules. Results show better performance in prediction of All India region, West central region and Peninsular region rainfall when <b>attributes</b> <b>selection</b> is employed as compared to all 36 variables used for prediction...|$|R
40|$|International audienceWe {{propose a}} new methodology, called BUST, for the {{extraction}} of joint relationships using induction of decision trees. BUST is the acronym of “Bottom-Up <b>attribute</b> <b>Selection</b> for the induction of decision Trees”: at each node of the tree, a bottom-up approach of <b>attribute</b> <b>selection</b> is used, {{as opposed to the}} classical Top-Down approach. This methodology has been developed to solve functional separability problem: the irrelevant or redundant attributes, which should be the last attributes tested in the tree, are rejected...|$|E
40|$|<b>Attribute</b> <b>selection</b> is {{generally}} considered as a challenging work {{in the development of}} image data mining oriented applications. Attribute subset selection is mainly an optimization problem, which involves searching the space of possible feature subsets to select the one that is optimal or nearly optimal with respect to the performance measures accuracy, complexity etc., of the application. This paper presents a comparative evaluation of several <b>attribute</b> <b>selection</b> methods based on the performance accuracy of different tree based supervised classification for mammogram images of MIAS database...|$|E
40|$|It {{has been}} shown that user {{modelling}} has the potential to improve the performance of conversational search systems, particularly in what concerns the problem of <b>attribute</b> <b>selection,</b> i. e., determining which attribute to ask the user at each step of the dialogue. In this paper we present a novel framework for <b>attribute</b> <b>selection</b> which allows the fine-tuning of the relative importance of profile-based and entropy-based heuristics. Based on this framework, we describe a number of experiments which allow us to quantify the bounds to such improvements...|$|E
40|$|This {{study was}} {{designed}} to identify distinct segments within the senior motorcoach traveler market. Data were collected from 817 motorcoach travelers aged 55 and older. A questionnaire containing 55 motorcoach tour <b>selection</b> <b>attributes</b> was used. Market segments were derived from factor and cluster analyses and verified by PC plots and discriminant analysis. Respondents were successfully di-vided into three groups based on motorcoach tour <b>selection</b> <b>attributes.</b> The dependents, sociables, and independents rep-resented 51 %, 19 %, and 30 % of the respondents, respec-tively. Thirteen tour <b>selection</b> <b>attributes</b> were identified as the discriminating characteristics among groups. The three market segments also had significantly different age, retire-ment status, education, and income. Appropriate marketing strategies were recommended for tour operators to targe...|$|R
40|$|The {{evaluation}} and selection of energy technologies involve {{a large number}} of <b>attributes</b> whose <b>selection</b> and weighting is decided in accordance with the social, environmental, technical and economic framework. In the present work an integrated multiple attribute decision making methodology is developed by combining graph theory and analytic hierarchy process methods to deal with the {{evaluation and}} selection of energy technologies. The energy technology <b>selection</b> <b>attributes</b> digraph enables a quick visual appraisal of the energy technology <b>selection</b> <b>attributes</b> and their interrelationships. The preference index provides a total objective score for comparison of energy technologies alternatives. Application of matrix permanent offers a better appreciation of the considered attributes and helps to analyze the different alternatives from combinatorial viewpoint. The AHP is used to assign relative weights to the attributes. Four examples of evaluation and selection of energy technologies are considered in order to demonstrate and validate the proposed method...|$|R
40|$|The use of {{data mining}} {{approaches}} in medical domains is increasing rapidly. This is mainly because {{the effectiveness of}} these approaches to classification and prediction systems has improved, particularly in relation to helping medical practitioners in their decision making. This type of research has become important for finding ways to improve patient outcomes, reduce the cost of medicine, and further advance clinical studies. Therefore, in this paper, data pre-processing RELIEF <b>attributes</b> <b>selection,</b> and Modest AdaBoost algorithms, are used to extract knowledge from the breast cancer survival databases in Thailand. The performance of these algorithms is examined by using classification accuracy, sensitivity and specificity, confusion matrix and stratified 10 -fold cross-validation method. Computational results showed that Modest AdaBoost outperforms Real and Gentle AdaBoosts...|$|R
