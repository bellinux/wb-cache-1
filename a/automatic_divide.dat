0|13|Public
40|$|A new {{formation}} {{framework of}} large-scale intelligent autonomous vehicles is developed, which can realize complex formations while reducing data exchange. Using the proposed hierarchy formation method and the <b>automatic</b> <b>dividing</b> algorithm, vehicles are automatically divided into leaders and followers by exchanging information via wireless network at initial time. Then, leaders form formation geometric shape by global formation information and followers track their own virtual leaders to form line formation by local information. The formation control laws of leaders and followers are designed based on consensus algorithms. Moreover, collision-avoiding problems are considered and solved using artificial potential functions. Finally, a simulation example {{that consists of}} 25 vehicles shows the effectiveness of theory...|$|R
40|$|This paper {{describes}} the Interactive Systems Laboratories’ automatic lecture transcription {{system for the}} Translanguage English Database (TED) corpus, which provides text-hypothesis for the International Workshop on Speech Summarization for Information Extraction and Machine Translation. Furthermore the paper gives a short analysis of speaking style characteristics, in particular addressing native vs. non-native speech. The data for <b>automatic</b> transcription is <b>divided</b> into a native and a nonnative test set. The best word error rate for the native data set is 28. 5 % while for the non-native set the best result shows 31. 0 %. 1...|$|R
40|$|Target of {{research}} is to know motorbike segmentation of automatic Yamaha Mio in District Sukun Malang Town. Analysis used to know market segmentation consumer of motorbike of Automatic Yamaha Mio used by analyzer of cluster centroid. Pursuant to result of solution and research which have been hence motorbike market segmentation of <b>automatic</b> Yamaha Mio <b>divided</b> to become three segment. At group/ cluster 1 that is covering to consider benefit, work as housewife, responder age that is gyrating 24 until 30 year and consider life style. At or group of cluster this there are counted 30 responder or 30...|$|R
40|$|Automatic {{differentiation}} is {{a technique}} for computing derivatives accurately and efficiently with minimal human effort. We employed this technique to generate derivative information of FCAP 2 (2 -D) and FCAP 3 (3 -D) programs that simulate the parasitic effects of interconnects and devices. This derivative information {{is used in the}} statistical modeling of worst-case interconnect delays and on-chip crosstalks. The ADIC (Automatic Differentiation in C) tool generated new versions of FCAP 2 and FCAP 3 programs that compute both the original results and the derivative information. Given the ANSI C source code for the function, ADIC generates new code that computes derivatives of the model output with respect to the input parameters. We report on the use of <b>automatic</b> differentiation and <b>divided</b> difference approaches for computing derivatives for FCAP 3 programs. The results show that ADIC-generated code computes derivatives more accurately, more robustly, and faster than the divided difference a [...] ...|$|R
40|$|We {{aimed to}} {{delineate}} key constructs from {{two forms of}} cognitive-behavioral therapy: cognitive therapy and rational-emotive behavior therapy. Furthermore, we aimed to investigate the interrelations among {{each other and with}} emotional distress. The key constructs of the underlying theories of these therapies (i. e., descriptive/inferential beliefs, evaluative beliefs) are often treated together as distorted cognitions and included as such in various scales. We used a cross-sectional design. Seventy-four undergraduate students (mean age = 24. 68) completed measures of automatic thoughts and emotional distress. Three therapists trained in cognitive-behavioral therapy <b>divided</b> <b>automatic</b> thoughts into descriptive/inferential beliefs and evaluative beliefs by consensus. Correlation and mediation analyses were performed. These constructs showed medium to high associations {{to each other and to}} distress. The relationship between descriptive/inferential beliefs and distress was mediated by evaluative beliefs. Descriptive and inferential cognitions may not produce emotions without first being appraised in terms of personal relevance...|$|R
40|$|Automatic {{differentiation}} is {{a technique}} for computing derivatives accurately and efficiently with minimal human effort. The calculation of derivatives of numerical models is necessary for gradient based optimization of reservoir systems to determine optimal sizes for reservoirs. We report {{on the use of}} <b>automatic</b> differentiation and <b>divided</b> difference approaches for computing derivatives for a single- and multiple-reservoir yield model. In our experiments, the ADIFOR (Automatic Differentiation of Fortran) tool is employed. The results show that, for both the single- or multiple-reservoir model, automatic differentiation computes derivatives exactly and more efficiently than the divided difference implementation. We also discuss postoptimization of the ADIFORgenerated derivative code by exploiting the model structure. We observe that the availability of exact derivatives significantly benefits the convergence of the optimization algorithm: The solution of the multireservoir problem, which took 10. 5 hours with divided difference derivatives, is decreased to less than two hours with ADIFOR “out of the box ” derivatives, and to less than an hour using the postoptimized ADIFOR derivative code...|$|R
40|$|This paper {{introduces}} {{a new approach}} to solving the problem of representing planar curves. We describe the 2 -D curve C not at all different scales oe, but each curve part C i of C, isolating a different structure at its single scale oe i. Therefore, we represent the planar curve at a scale vector (oe 1; ΔΔΔ; oe L) supposing that the curve is partitioned in L parts C 1; ΔΔΔ; CL. We propose an <b>automatic</b> method to <b>divide</b> the contour into the number of nonoverlappings parts C 1; ΔΔΔ; CL, each of them showing a different underlying structure. This process requires neither the number of parts in the curve nor the minimum level of homogeneity for the entities within a particular part. The partition is based on three elements: a vector OE of statistical measures calculated to each class, a distance funtion d(OE i; OE j) between vectors corresponding to two different classes, and a halt criterion based on a measure of the improveme [...] ...|$|R
40|$|This article {{presents}} a research {{work in the}} field of content-based image retrieval in large databases applied to the Paleontology image database of the Université de Bourgogne, Dijon, France called “TRANS’TYFIPAL”. Our indexing method is based on multiresolution decomposition of database images using wavelets. For each family of paleontology images we try to find a model image representing it. The K-means <b>automatic</b> classification algorithm <b>divides</b> the space of parameters into several clusters. A model image for each cluster is computed from the wavelet transform of each image of the cluster. Then a search tree is built to offer users a graphic interface for retrieving images. So that users have to navigate through this tree of model images to find an image similar to that of their request. Our contribution in the field is the building of the model and of the search tree to make user access easier and faster. This paper ends with a conclusion on experimental results and a description of future work to be done to enhance our indexing and retrieval method...|$|R
40|$|The idea of Zero Configuration is {{very popular}} today. The {{reason for this is}} the need to reduce human work at {{configuration}} of the computer. The concept of Zero Configuration is however, not very clear. In everyday language it is understood almost as a synonym to automatic configuration or Plug and Play in the words of Microsoft. In the IETF, the concept of Zero Configuration is seen very limited in opposite to common ideas. The concept is limited strictly into the configuration cases where no pre-configured server is needed to perform a configuration transaction. The difference of domain between common ideas and the ideas of IETF makes also the requirements of security quite different. Security considerations in the requirement paper of Zero Configuration are also very limited. They cover only the idea of availability. When we are talking about automatic configuration, it covers every type of configuration over the network from empty machine up to practically fully configured machine. In this paper the area of <b>automatic</b> configuration is <b>divided</b> into three levels of pre-configuration. The networks are also divided into three types and looked at the security requirements with a matrix method. ...|$|R
40|$|Nine Mora Romagnola and 10 Large White x Mora Romagnola growing pigs were reared outdoors. In {{both groups}} ad libitum feed was provided. Conventional pigs {{received}} it twice a day, distributed in two long troughs. Inside the corral {{of the second}} group, an automatic station was set up for: feed distribution, pigs weighing, and control by an analog camera. Thus the self-feeders received feed ad libitum individually by the <b>automatic</b> system, <b>divided</b> into small quantities at meal times. During the experiment the analog camera was used over 24 hours each day, to collect pictures of pigs in order to investigate their behaviours. For each picture the day and hour, the number of visible pigs and their behaviours were recorded and a statistical analysis of data, which was expressed as hourly frequencies of behavioural elements, was performed. Moreover to highlight “active” and “passive” behaviours between the groups, two categories “Move” and “Rest” were created grouping some behavioural elements. With regard to performance, conventional pigs reached a higher total weight gain (56. 1 ± 2. 42 kg vs 46. 7 ± 2. 42 kg; P= 0. 0117). But the feed conversion index (FCI) of both groups was similar. The self-feeders had consumed less feed than conventional animals. The feeding system seems to influence behaviours. The percentage {{of time spent in}} Eating activity differs (P< 0. 0001) between the self-fed (median 24. 6 %) and conventional pigs (median 10. 9 %). The resulting more regular eating trend of self-feeders influenced the daily activities distribution. The behavioural category Rest (median: self-feeders 55. 0 % vs 71. 4 % conventional pigs) was dominant, with conventional pigs becoming more restless, particularly at meal times. This type of feeding competition and aggressive behaviour did not happen in the self-feeders due to the feed distribution system. The self-feeder results showed that pigs eat at the automatic station both day and night. The animals perform on average 3 visits per hour at night and 10 during the day, with an average duration of some minutes (from 3 to 5 approximately) ...|$|R
40|$|The octopus example. Our {{constrained}} partitioning optimization system automatically {{generates the}} partitioning of this octopus model, which contains nine pieces {{as shown in}} (a) and (c). These nine pieces can be packed into a box container as shown in (b) and (d), which occupies only 10. 4 percent of its original container volume. As the 3 D printing technology starts to revolutionize our daily life and the manufacturing industries, a critical problem is about to e-merge: how can we find an <b>automatic</b> way to <b>divide</b> a 3 D model into multiple printable pieces, so as to save the space, to reduce the printing time, or to make a large model printable by small printers. In this paper, we present a systematic study on the partitioning and packing of 3 D models under the multi-phase level set framework. We first construct analysis tools to evaluate the qualities of a parti-tioning using six metrics: stress load, surface details, interface area, packed size, printability, and assembling. Based on this analysis, we then formulate level set methods to improve the qualities of the partitioning according to the metrics. These methods are integrated into an automatic system, which repetitively and locally optimizes the partitioning. Given the optimized partitioning result, we further provide a container structure modeling algorithm to facilitate the packing process of the printed pieces. Our experiment shows that the system can generate quality partitioning of various 3 D models for space saving and fast production purposes...|$|R
40|$|Cell {{population}} balance models {{can account for}} the phenotypic heterogeneity that characterizes isogenic cell populations. To utilize the predictive power of these models, however, we must determine the single-cell reaction and division rates {{as well as the}} partition probability density function of the cell population. These functions (collectively called Intrinsic Physiological State or IPS functions) can be obtained through the Collins-Richmond inverse cell {{population balance}} modeling methodology, if we know the phenotypic distributions of (a) the overall cell population, (b) the dividing cell subpopulation and (c) the newborn cell subpopulation. This first part of this thesis presents the development of a novel assay that combines fluorescence microscopy and image processing to determine these phenotypic distributions. Morphological criteria were developed for the <b>automatic</b> identification of <b>dividing</b> cells and validated through direct comparison with manually obtained measurements. The newborn cell subpopulation was obtained from the corresponding dividing cell subpopulation by collecting information from the two compartments separated by the constriction. Finally, we applied the assay to quantify the heterogeneity of E. coli cells carrying the genetic toggle network with a green fluorescent marker. Our measurements for the overall cell population were in excellent agreement with the distributions obtained via flow cytometry. In {{the second part of the}} thesis, we develop and test a robust computational procedure for solving the inverse problem that yields the IPS functions. We employed numerical simulations in conjunction with a thorough parametric analysis to investigate the effect of various factors on the accurate recovery of the IPS functions. We also formulated and solved a minimization problem to obtain the bivariate partition probability density function (PPDF), which presents the most computational challenges of all three IPS functions. We successfully tested our method against uncertainty stemming from both finite sampling and measurements errors in the experimental data. We also investigated the feasibility of a more general solution for the PPDF and proposed methods to extend and solve the inverse problem in 2 -D. Finally, we demonstrated the abilities and potential of our method by applying it to a model biological system involving E. coli cells carrying the toggle artificial regulatory network...|$|R
30|$|Large file {{dissemination}} is {{a prospective}} trend in vehicular networks. For example, in [14], the authors study querying multimedia data such as video and voice clips in hybrid vehicular networks which consist of vehicles that {{are capable of}} both infrastructure-less short-range communication and infrastructure communication. Also, in [15], the authors study querying binary large objects (blobs) such as video and voice clips in a network of vehicles communicating wirelessly. They focus on the efficient query of the content while none of them considered the data dissemination problem. Ref. [16] uses dynamic network topology graph to model the content downloading problem in vehicular networks. However, it needs the preemptive knowledge of vehicular trajectories and perfect scheduling of data transmissions, which is impractical in highly dynamical VANET since DNTG will become very complicated. Ref. [17, 18] prove that vehicle mobility follows certain patterns and can be used to predict the encountering of vehicles. One way to support large data chunk is to split, such as SADF [19], it is an <b>automatic</b> data packet <b>dividing</b> algorithm. To improve the delivery ratio, it cuts the large file into small segments according to the network quality and duration of contacts. In [20], large files are divided into data chunks. However, the relay-to-relay transmission is not considered. The carrier vehicle can only deliver the data chunk to the downloader directly. Another way is to add more storage, METhoD [21] implements a platform for distributing multimedia contents in delay-tolerant networks. It does not give solution on how to prevent memory overflow but adding a lot of external storage to help the big data application. Abdelmoumen et al. [22] analyze the adverse effect brought by the insufficiency of nodes’ storage. By adding some fixed nodes with large storage space, the problem can be solve to some extent. However, in many cases, the data file is not allowed to be portioned and additional infrastructure is costly. Again, improving the data exchange efficiency would be another option. Zhao et al. [23] turn the problem of global optimizing of forwarding utility into the local optimizing of forwarding utility upon nodes’ encounter. The proposed cooperative forwarding is modeled as a 0 − 1 knapsack problem and solved by a greedy algorithm. In [24], the authors propose a dynamic segmented network coding scheme to efficiently exploit the transmission opportunity that is scarce in DTNs. In particular, they adopt a dynamic segment size control mechanism, which makes the segmentation adapt to the dynamics of the network.|$|R

