0|10000|Public
40|$|The {{design and}} {{development}} of wearable biosensor systems for health and wellness monitoring has garnered lots of attention in the scientiﬁc community and the industry during the past decade. When it comes to health and wellness monitoring, accurate measurements, analysis and estimations would be vital. One major challenge in achieving a high performance wearable health monitoring system is motion <b>and</b> <b>noise</b> <b>artifacts.</b> This consideration {{was the basis for}} this dissertation. This study presents different algorithms and signal processing techniques to address motion <b>and</b> <b>noise</b> <b>artifact</b> detection <b>and</b> vital signal reconstruction from electrocardiogram/photoplethysmogram recordings. Five vital signals including ECG, PPG, Heart Rate, HRV and SpO 2 are in the scope of the present dissertation. Accurate estimation of Heart Rates and Oxygen Saturation from photoplethysmogram (PPG) and Heart Rate from electrocardiogram (ECG) signals during daily physical activity is a very challenging problem. On the other hand motion <b>and</b> <b>noise</b> <b>artifact</b> in PPG <b>and</b> ECG recordings introduce challenges in early detection of heart failure diseases including Atrial Fibrillation and congestive heart failure. We address the problem of motion <b>and</b> <b>noise</b> <b>artifact</b> in three levels (1) “Motion <b>and</b> <b>Noise</b> Corrupted Data Removal”, and (2) “MA Corrupted Signal Usability Index Measurement” and (3) “Motion <b>and</b> <b>Noise</b> Corrupted Data Reconstruction”. Nine novel signal processing techniques (TDV, RepMA, RAFMA, IMAR, DyParaM, TifMA, OxiMA, SpaMa and SegMA) are introduced in this study to cope with the motion <b>and</b> <b>noise</b> <b>artifact</b> in PPG <b>and</b> ECG based wearable sensors. It will be shown that the proposed techniques are able to meet major aims of this study and {{to address the problem of}} motion <b>and</b> <b>noise</b> <b>artifacts</b> corresponding to each of the three scenarios. The results show that the algorithms presented in this study have potential for PPG or ECG based HR or SpO 2 monitoring in wearable devices for ﬁtness tracking and health monitoring during daily physical activities...|$|R
3000|$|..., the {{intensity}} gradient is strongly {{constrained by the}} LR frame. Since the LR frame {{does not have any}} ringing <b>and</b> <b>noise</b> <b>artifacts,</b> increasing of {{the intensity}} gradient is prevented in the estimated HR frame, and those artifacts can be suppressed.|$|R
40|$|In this thesis, {{analysis}} and classification of alcoholics is conducted using single trials of Visual Evoked Potential (VEP) signals {{extracted from the}} scalp during the perception of visual stimulus. A problem with the analysis of VEP signals is the corruption from ongoing electroencephalogram (EEG) <b>and</b> <b>noise</b> <b>artifacts.</b> VEP signals are relatively lower in signal strength as compared to EEG and therefore, the EEG distorts the VEP signal...|$|R
40|$|ECG {{signals are}} {{corrupted}} by {{various kinds of}} <b>noise</b> <b>and</b> <b>artifacts</b> that may negatively affect any subsequent analysis. In particular, narrowband artifacts include power-line interference <b>and</b> harmonic <b>artifacts.</b> Customarily, <b>noise</b> reduction <b>and</b> <b>artifact</b> rejection are tackled as two distinct problems. In this paper, we propose a joint approach to de- <b>noising</b> <b>and</b> narrowband <b>artifact</b> rejection that exploits the local structure of a noisy ECG. Simulation results confirm {{the effectiveness of the}} approach and highlight a notable ability to remove both <b>noise</b> <b>and</b> narrowband <b>artifacts</b> in ECG signals...|$|R
40|$|In {{this paper}} we {{describe}} a Bayesian Model Averaging (BMA) methodology developed for detecting artifacts in electroencephalograms (EEGs). The EEGs can be heavily corrupted by cardiac, eye movement, muscle <b>and</b> <b>noise</b> <b>artifacts,</b> so that EEG experts need to automatically detect {{them with a}} given level of confidence. In theory, the BMA methodology allows experts to evaluate the confidence in decision making most accurately. However, the non- stationary nature of EEGs makes {{the use of this}} methodology difficult. In our experiments with the sleep EEGs, the proposed BMA technique is shown to provide a better performance in terms of predictive accuracy...|$|R
40|$|In {{this paper}} we {{describe}} a new method combining the polynomial neural network and decision tree techniques {{in order to}} derive comprehensible classification rules from clinical electroencephalograms (EEGs) recorded from sleeping newborns. These EEGs are heavily corrupted by cardiac, eye movement, muscle <b>and</b> <b>noise</b> <b>artifacts</b> <b>and</b> as a consequence some EEG features are irrelevant to classification problems. Combining the polynomial network and decision tree techniques, we discover comprehensible classification rules whilst also attempting to keep their classification error down. This technique is shown to outperform a number of commonly used machine learning technique applied to automatically recognize artifacts in the sleep EEGs...|$|R
40|$|Automated or semiautomated pattern {{recognition}} in multidimensional NMR spectroscopy is strongly {{hampered by the}} large number of <b>noise</b> <b>and</b> <b>artifact</b> peaks occurring under practical conditions. A general Bayesian method which is able to assign probabilities that observed peaks are members of given signal classes (e. g., the class of true resonance peaks or the class of <b>noise</b> <b>and</b> <b>artifact</b> peaks) was proposed previously. The discriminative power of this approach is dependent on the choice of the properties characterizing the peaks. The automated class recognition is improved by the addition of a nonlocal feature, the similarities of peak shapes in symmetry-related positions. It turns out that this additional property strongly decreases the overlap of the multivariate probability distributions for true signals <b>and</b> <b>noise</b> <b>and</b> hence largely increases the discrimination of true resonance peaks from <b>noise</b> <b>and</b> <b>artifact...</b>|$|R
30|$|The above {{indicates}} {{that there is a}} choice of several algorithms for denoising methods which reduce <b>noise</b> <b>and</b> <b>artifacts</b> in the EEG signals from their TFDs considered as images. The power of <b>noise</b> <b>and</b> <b>artifact</b> in the signal resulting from reconstructing the enhanced TFDs are expected to be much less than those in the original signals. This in turn can significantly improve the performance of any newborn EEG classification/source localization method.|$|R
40|$|Abstract — This paper formulates a novel {{probabilistic}} {{graphical model}} for stimulus-evoked MEG and EEG sensor data {{obtained in the}} presence of large background brain activity. The model describes the observed data in terms of unobserved evoked and background sources. We present an expectation maximization algorithm that estimates the model parameters from data. Using the model, the algorithm cleans the stimulus-evoked data by removing interference from background sources <b>and</b> <b>noise</b> <b>artifacts,</b> <b>and</b> separates those data into contributions from independent factors. We demonstrate on real and simulated data that the algorithm outperforms benchmark methods for denoising and separation. We also show that the algorithm improves the performance of existing localization techniques...|$|R
40|$|Existing sinogram {{restoration}} methods cannot handle <b>noises</b> <b>and</b> nonstationary <b>artifacts</b> simultaneously. Although bilateral filter {{provides an}} {{efficient way to}} preserve image details while denoising, its performance in sinogram restoration for low-dosed X-ray computed tomography (LDCT) is unsatisfied. The main reason for this situation is that the range filter of the bilateral filter measures similarity by sinogram values, which are polluted seriously by <b>noises</b> <b>and</b> nonstationary <b>artifacts</b> of LDCT. In this paper, we propose a simple method to obtain satisfied restoration results for sinogram of LDCT. That is, the range filter weighs the similarity by Gaussian smoothed sinogram. Since smoothed sinogram can reduce the influence of both <b>noises</b> <b>and</b> nonstationary <b>artifacts</b> for similarity measurement greatly, our new method can provide more satisfied denoising results for sinogram restoration of LDCT. Experimental results show that our method has good visual quality and can preserve anatomy details in sinogram restoration even in both <b>noises</b> <b>and</b> non-stationary <b>artifacts...</b>|$|R
40|$|This paper formulates a novel {{probabilistic}} {{graphical model}} for noisy stimulus-evoked MEG and EEG sensor data {{obtained in the}} presence of large background brain activity. The model describes the observed data in terms of unobserved evoked and background factors with additive sensor noise. We present an Expectation-Maximization (EM) algorithm that estimates the model parameters from data. Using the model, the algorithm cleans the stimulus-evoked data by removing interference from background factors <b>and</b> <b>noise</b> <b>artifacts,</b> <b>and</b> separates those data into contributions from independent factors. We demonstrate on real and simulated data that the algorithm outperforms benchmark methods for denoising and separation. We also show that the algorithm improves the performance of localization with beamforming algorithms...|$|R
40|$|Abstract – Iterative CT {{algorithms}} {{are becoming}} increasingly popular in recent years, and have been found useful when the projections are limited in number, irregularly spaced, or noisy, which are imaging scenarios often encountered in low-dose imaging and compressed sensing. One way {{to cope with the}} associated streak <b>and</b> <b>noise</b> <b>artifacts</b> in these settings is either to incorporate or to interleave a regularization objective into the iterative reconstruction framework. In this paper we explore possible techniques for the latter. We investigate a number of non-linear filters popular in the image processing literature for their suitability in iterative CT application, here OS-SIRT. I I. INTRODUCTION AND RELATED WORKS n image processing and computer vision, edge-preserving image smoothing is widely used for visual appearancepreservin...|$|R
40|$|ECG {{signals are}} {{corrupted}} by {{several kinds of}} <b>noise</b> <b>and</b> <b>artifacts,</b> which negatively affect any subsequent analysis. In the literature, the only approach that can handle any <b>noise</b> <b>and</b> <b>artifacts</b> corrupting the ECG is linear time-invariant filtering. However, it suffers from some important limitations regarding effectiveness and computational complexity. In this {{paper we propose a}} novel frame- work for ECG signal preprocessing based on the notion of quadratic variation reduction. The framework is very general, since it can cope with all the different kinds of <b>noise</b> <b>and</b> <b>artifacts</b> that corrupt ECG records. It relies on a single algorithmic structure, thus enjoying an easy and robust implementation. Results show that the framework is effective in improving the quality of ECG, while preserving signal morphology. Moreover, it is very fast, even on long recordings, thus being perfectly suited for real-time applications and implementation on devices with reduced computational power, such as handheld devices...|$|R
30|$|MBIR {{significantly}} improves image <b>noise</b> <b>and</b> streak <b>artifacts</b> {{compared to}} ASIR, and can achieve radiation dose reduction without severely compromising image quality.|$|R
30|$|We {{performed}} evaluations {{in a set}} of 150 different images: {{from the}} Berkeley database [21], video sequences frames, and images commonly evaluated on denoising; all of them present natural <b>noise</b> <b>and</b> <b>artifacts.</b>|$|R
3000|$|..., which {{represent}} the distribution shape, in Equation (17) and derives the new prior probability {{to suppress the}} occurrence of <b>noises</b> <b>and</b> ringing <b>artifacts</b> in smooth regions.|$|R
30|$|If {{we had a}} {{model of}} the source, the signal quality {{assessment}} would be straightforward, the signal to noise ratio (SNR) gives an estimate of the signal quality. However, for physiological signals, the source characteristics vary significantly over the time. Therefore, researchers use indirect measures to estimate the signal quality of the physiological signals. These methods assume that some characteristics of the signals are known a priori, <b>and</b> the <b>noise</b> <b>artifacts</b> cause any deviation present in the signal.|$|R
30|$|Edge <b>and</b> <b>noise</b> <b>artifacts</b> in maximum {{likelihood}} reconstructions {{have been observed}} and studied {{for a long time}} [13, 14, 33]. Noise was said to result from {{maximum likelihood}} expectation maximization (MLEM) doing a too good job [33]: ‘MLEM is so successful in producing images that are consistent with the acquired data that the noise is also fully reproduced.’ Edge artifacts seemed to result from the impossibility to recover frequencies whose amplitudes are too low [33]. Therefore, the frequency content of the images is incomplete. This becomes dramatic at edges where representations are made of a very wide frequency range (infinite range for a sharp edge) and result in the observed overshoots [33]. The link between the edge and oscillation artifacts seems not to have been clearly established. However, it was observed that techniques tailored to reduce or suppress the edge artifacts also reduced or suppressed the oscillation artifacts [33].|$|R
40|$|In image {{restoration}} tasks, a heavy-tailed gradient distribution of natural images {{has been extensively}} exploited as an image prior. Most {{image restoration}} algorithms impose a sparse gradient prior on the whole image, reconstructing an image with piecewise smooth characteristics. While the sparse gradient prior removes ringing <b>and</b> <b>noise</b> <b>artifacts,</b> it also tends to remove mid-frequency textures, degrading the visual quality. We can attribute such degradations to imposing an incorrect image prior. The gradient profile in fractal-like textures, such as trees, is close to a Gaussian distribution, and small gradients from such regions are severely penalized by the sparse gradient prior. To address this issue, we introduce an image restoration algorithm that adapts the image prior to the underlying texture. We adapt the prior to both low-level local structures as well as mid-level textural characteristics. Improvements in visual quality is demonstrated on deconvolution and denoising tasks. Orthogonal gradient...|$|R
30|$|For ECG {{with high}} {{frequency}} <b>noise</b> <b>and</b> <b>artifact,</b> most existing methods produced more missing and false detections. However, the presented method illustrates an excellent detection performance {{as shown in}} Fig.  4 for ECG recording 200.|$|R
30|$|Recorded EEG {{signal is}} {{contaminated}} by <b>noises</b> <b>and</b> <b>artifacts.</b> These <b>noises</b> must be suppressed {{in order to}} get correct required information from the signal and prepare the signal for further processing. Therefore, the data were band-pass filtered between 0.1 and 60  Hz.|$|R
3000|$|In {{order to}} {{evaluate}} the robustness of the slope algorithm {{in the presence of}} <b>artifacts</b> <b>and</b> <b>noise,</b> the ECG signals in the MIT-BIH data set were degraded with clipping <b>artifacts</b> <b>and</b> Gaussian <b>noise.</b> Clipping <b>artifacts</b> were introduced to simulate saturation artifacts (Venkatachalam et al. 2011) and digital clipping. The following procedure was used: [...]...|$|R
40|$|International audience–Low-dose CT (LDCT) {{images are}} often {{severely}} degraded by amplified mottle <b>noise</b> <b>and</b> streak <b>artifacts.</b> These artifacts are often hard to suppress without introducing tissue blurring effects. In this paper, we propose to process LDCT images using a novel image-domain algorithm called "artifact suppressed dictionary learning (ASDL) ". In this ASDL method, orientation and scale information on artifacts is exploited to train artifact atoms, {{which are then}} combined with tissue feature atoms to build three discriminative dictionaries. The streak artifacts are cancelled via a discriminative sparse representation (DSR) operation based on these dictionaries. Then, a general dictionary learning (DL) processing is applied to further reduce the <b>noise</b> <b>and</b> residual <b>artifacts.</b> Qualitative and quantitative evaluations on a large set of abdominal and mediastinum CT images are carried out and {{the results show that}} the proposed method can be efficiently applied in most current CT systems. Index Terms—Low-dose CT (LDCT), dictionary learning, <b>noise,</b> <b>artifact</b> suppression, artifact suppressed dictionary learning algorithm (ASDL...|$|R
40|$|Analyzing brain {{states that}} {{correspond}} to event related potentials (ERPs) on a single trial basis is a hard problem due to the high trial-to-trial variability and the unfavorable ratio between signal (ERP) <b>and</b> <b>noise</b> (<b>artifacts</b> <b>and</b> neural background activity). In this tutorial, we provide a comprehensive framework for decoding ERPs, elaborating on linear concepts, namely spatio-temporal patterns and filters as well as linear ERP classification. However, the bottleneck of these techniques is that they require an accurate covariance matrix estimation in high dimensional sensor spaces which is a highly intricate problem. As a remedy, we propose to use shrinkage estimators and show that appropriate regularization of linear discriminant analysis (LDA) by shrinkage yields excellent results for single-trial ERP classification that are far superior to classical LDA classification. Furthermore, we give practical hints on the interpretation of what classifiers learned from the dat a and demonstrate in particular that the trade-off between goodness-of-fit and model complexity in regularized LDA relates to a morphing between a difference pattern of ERPs and a spatial filter which cancels non task-related brain activity...|$|R
30|$|In conclusion, MBIR {{significantly}} improves image <b>noise</b> <b>and</b> streak <b>artifacts</b> {{compared to}} ASIR in abdominopelvic CT. MBIR shows greater potential than ASIR for achieving further radiation dose reductions over ASIR without severely compromising image quality.|$|R
3000|$|The {{pipeline}} takes a video feed as an input, subtracts the background, filters each {{frame for}} <b>noise</b> <b>and</b> <b>artifacts,</b> and outputs {{the moving parts}} as binary blobs of pixels. Figure  2 illustrates this process. The following is {{a description of the}} individual steps: [...]...|$|R
40|$|International audienceLow-dose CT is an {{effective}} solution to alleviate radiation risk to patients, it also introduces additional <b>noise</b> <b>and</b> streak <b>artifacts.</b> In order to maintain a high image quality for low-dose scanned CT data, we propose a post-processing method based on deep learning and using 2 -D and 3 -D residual convolutional networks. Experimental results and comparisons with other competing methods show that the proposed approach c{{an effective}}ly reduce the low-dose <b>noise</b> <b>and</b> <b>artifacts</b> while preserving tissue details. It is {{also pointed out that}} the 3 -D model can achieve better performance in both edge-preservation and noise-artifact suppression. Factors that may influence the model performance, such as model width, depth, and dropout, are also examined...|$|R
40|$|Abstract—This paper {{presents}} an automated multi-step algorithm for segmenting the prostate boundary from ultrasound images. As the acquired ultrasound images are usually affected {{due to the}} presence of Speckle <b>and</b> other <b>noise</b> <b>artifacts,</b> {{the first step is to}} pre-process these images using Sticks Filtering. Further, in stage two an initial contour is determined from these pre-processed images. Finally, Ant Colony Optimization is used to segment the prostate boundary to determine the volume of the prostate. In the last section the performance of both pre-processing stage as well as segmentation stage is presented and is compared with existing algorithms. Index Terms—Prostate, TRUS, ACO I...|$|R
30|$|Masking. The non-interesting {{parts of}} the image are removed to ease {{the task of the}} {{tracking}} algorithm <b>and</b> remove unwanted <b>noise</b> <b>and</b> <b>artifacts.</b> For example, if the experimenter is using a marked experimental arena to conduct the experiments, the surroundings can be removed. The mask has to be manually updated whenever the camera or subject position changes.|$|R
40|$|This {{bachelor}} thesis {{deals with}} the measurement of ECG data. The main theme is digital filtering desired signals from <b>noise</b> <b>and</b> <b>artifacts,</b> which arises mainly {{to interfere with the}} power grid, moving the measured entity or electromagnetic interference. A secondary objective is the issue of compression for data transmission...|$|R
30|$|Noise removal. There {{were several}} noises {{randomly}} {{distributed in the}} original CT images and some slight ring artifacts, which caused great difficulty in recognizing detailed SRM information. Therefore, a Gaussian filter {{was used to remove}} <b>noises</b> <b>and</b> ring <b>artifacts</b> first.|$|R
40|$|International audienceGeostatistical {{filtering}} aims at removing <b>noise</b> <b>and</b> <b>artifacts</b> on seismic volumes by decomposing {{a signal}} into spatially independent structures (signal + <b>artifact(s)</b> + <b>noise)</b> <b>and</b> filtering out the undesirable one(s). Multivariate methods allow {{the identification of}} common spatial behavior between different seismic volumes, as time-lapse seismic. This paper shows the methodology and benefits of using geostatistical filtering on 4 D vintages...|$|R
30|$|Noise filtering. The {{frame is}} {{processed}} to remove unwanted <b>noise</b> <b>and</b> <b>artifacts.</b> We first apply a Median Blur filter to remove ‘salt and pepper noise’ [23]. To further smooth, the video feed is blurred using a 3 × 3 Gaussian kernel, {{after which the}} frame is thresholded to obtain a binary image.|$|R
50|$|Harmonic mode: In {{this mode}} a deep {{penetrating}} fundamental frequency is emitted {{into the body}} and a harmonic overtone is detected. This way <b>noise</b> <b>and</b> <b>artifacts</b> due to reverberation and aberration are greatly reduced. Some also believe that penetration depth can be gained with improved lateral resolution; however, this is not well documented.|$|R
5000|$|In {{the figure}} shown below, P1 {{refers to the}} first-step of the {{iterative}} reconstruction process, of the projection matrix P of the fan-beam geometry, which is constrained by the data fidelity term. This may contain <b>noise</b> <b>and</b> <b>artifacts</b> as no regularization is performed. The minimization of P1 is solved through the conjugate gradient least squares method. P2 refers to the second step of the iterative reconstruction process wherein it utilizes the edge-preserving total variation regularization term to remove <b>noise</b> <b>and</b> <b>artifacts,</b> and thus {{improve the quality of}} the reconstructed image/signal. The minimization of P2 is done through a simple gradient descent method. Convergence is determined by testing, after each iteration, for image positivity, by checking if [...] for the case when [...] (Note that [...] refers to the different x-ray linear attenuation coefficients at different voxels of the patient image).|$|R
30|$|Robustness - the {{algorithm}} should be robust {{to the presence}} of <b>noise</b> <b>and</b> movement <b>artifacts,</b> to enable its application in recordings performed in uncontrolled (non-laboratory) conditions; in addition, {{the algorithm}} should handle signal clipping, a common occurrence in recordings during sleep (Redmond and Heneghan 2006).|$|R
