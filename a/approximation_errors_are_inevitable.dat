0|10000|Public
40|$|It {{is known}} that Tardos's collusion-secure {{probabilistic}} fingerprinting code (Tardos code; STOC' 03) has length of theoretically minimal order {{with respect to the}} number of colluding users. However, Tardos code uses certain continuous probability distribution in codeword generation, which creates some problems for practical use, in particular, it requires large extra memory. A solution proposed so far is to use some finite probability distributions instead. In this paper, we determine the optimal finite distribution in order to decrease extra memory amount. By our result, the extra memory is reduced to 1 / 32 of the original, or even becomes needless, in some practical setting. Moreover, the code length is also reduced, e. g. to about 20. 6 % of Tardos code asymptotically. Finally, we address some other practical issues such as <b>approximation</b> <b>errors</b> which <b>are</b> <b>inevitable</b> in any real implementation. Comment: 12 pages, 1 figure; (v 2) tables revised, typos corrected, comments on some recent works added; (v 3) submitted version, title changed from "Optimal probabilistic fingerprinting codes using optimal finite random variables related to numerical quadrature...|$|R
5000|$|The <b>approximation</b> <b>error</b> <b>is</b> {{the sum of}} the {{remaining}} coefficients ...|$|R
40|$|Abstract. This paper {{investigates the}} rate of {{convergence}} of an alternative approximation method for stochastic differential equations. The rates of convergence of the one-step and multi-step <b>approximation</b> <b>errors</b> <b>are</b> proved to be O((∆t) 2) andO(∆t) intheLp sense respectively, where ∆t is discrete time interval. The rate of convergence of the one-step <b>approximation</b> <b>error</b> <b>is</b> improved as compared with methods assuming the value of Brownian motion to be known only at discrete time. Through numerical experiments, {{the rate of}} convergence of the multi-step <b>approximation</b> <b>error</b> <b>is</b> seen to be much faster than in the conventional method. 1...|$|R
5000|$|Fifth {{generation}} (current): {{acknowledges that}} human <b>error</b> <b>is</b> <b>inevitable</b> and provides information to improve safety standards.|$|R
3000|$|... {{denote the}} clean and the denoised images. The {{root mean square}} (rms) of the <b>approximation</b> <b>error</b> <b>is</b> {{computed}} by [...]...|$|R
3000|$|... {{generates a}} good {{approximation}} of the logarithm of the HDR image [23, 24]. The <b>approximation</b> <b>error</b> <b>is</b> relatively small, as ε [...]...|$|R
30|$|The {{algorithm}} {{for constructing}} {{the network and}} choosing {{the level of the}} wavelet decomposition, based on minimization of the <b>approximation</b> <b>error,</b> <b>is</b> listed below.|$|R
40|$|The {{approximation}} of a discrete probability distribution t by an M-type distribution p <b>is</b> considered. The <b>approximation</b> <b>error</b> <b>is</b> {{measured by the}} informational divergence D(tp), which is an appropriate measure, e. g., {{in the context of}} data compression. Properties of the optimal approximation are derived and bounds on the <b>approximation</b> <b>error</b> <b>are</b> presented, which are asymptotically tight. It is shown that M-type approximations that minimize either D(tp), or D(pt), or the variational distance p-t_ 1 can all be found by using specific instances of the same general greedy algorithm. Comment: 5 page...|$|R
30|$|Medical errors {{represent}} a serious {{public health problem}} and {{pose a threat to}} patient safety. <b>Error</b> <b>is</b> <b>inevitable</b> in medicine. <b>Errors</b> <b>are</b> common in radiological diagnosis. They can arise during acquisition of images, processing, and interpretation [38 – 40].|$|R
3000|$|... (Compressible vectors) A vector x∈R^n is {{compressible}} if, denoted ϱ _k(x):= _z_ 0 ≤ kz-x, {{the relative}} best k-term <b>approximation</b> <b>error</b> <b>is</b> ϱ_k(x): =ϱ _k(x)/x<< 1 for some k< <n.|$|R
40|$|The {{approximation}} of a discrete probability distribution t by an M-type distribution p <b>is</b> considered. The <b>approximation</b> <b>error</b> <b>is</b> {{measured by the}} informational divergence D (t ∥ p), which is an appropriate measure, e. g., {{in the context of}} data compression. Properties of the optimal approximation are derived and bounds on the <b>approximation</b> <b>error</b> <b>are</b> presented, which are asymptotically tight. A greedy algorithm is proposed that solves this M-type approximation problem optimally. Finally, it is shown that different instantiations of this algorithm minimize the informational divergence D (p ∥ t) or the variational distance ∥ p − t ∥ 1...|$|R
5000|$|... #Caption: Graph of [...] (blue) {{with its}} linear {{approximation}} [...] (red) at a = 0. The <b>approximation</b> <b>error</b> <b>is</b> {{the gap between}} the curves, and it increases for x values further from 0.|$|R
40|$|An {{important}} question in evolutionary computation is how good solutions evolutionary algorithms can produce. This paper aims {{to provide an}} analytic analysis of solution quality {{in terms of the}} relative <b>approximation</b> <b>error,</b> which <b>is</b> defined by the error between 1 and the approximation ratio of the solution found by an evolutionary algorithm. Since evolutionary algorithms are iterative methods, the relative <b>approximation</b> <b>error</b> <b>is</b> a function of generations. With the help of matrix analysis, it is possible to obtain an exact expression of such a function. In this paper, an analytic expression for calculating the relative <b>approximation</b> <b>error</b> <b>is</b> presented for a class of evolutionary algorithms, that is, (1 + 1) strictly elitist evolution algorithms. Furthermore, analytic expressions of the fitness value and the average convergence rate in each generation are also derived for this class of evolutionary algorithms. The approach is promising, and it can be extended to non-elitist or population-based algorithms too. authorsversionPeer reviewe...|$|R
30|$|Though {{there are}} many methods to improve the {{accuracy}} of recommendation, all methods {{did not use the}} similarity set of users and items for personalized recommendation. Furthermore, the prediction <b>errors</b> <b>are</b> <b>inevitable</b> and deviation adjustment is not involved to improve accuracy in these methods.|$|R
50|$|Shingo {{argued that}} <b>errors</b> <b>are</b> <b>inevitable</b> in any {{manufacturing}} process, but that if appropriate poka-yokes are implemented, then mistakes can be caught quickly and prevented from resulting in defects. By eliminating defects at the source, {{the cost of}} mistakes within a company is reduced.|$|R
3000|$|... and M {{we have to}} {{determine}} areas to which these measurements belong to, such that the <b>approximation</b> <b>error</b> <b>is</b> minimized. To determine areas we propose to use {{a division of the}} cell into areas whose vertexes are measurement points (x [...]...|$|R
40|$|AbstractThe crude {{global search}} {{that is used}} in {{parameter}} space investigation provides approximations to the set of efficient points. Estimates of <b>approximation</b> <b>errors</b> <b>are</b> established and numerical examples confirm these estimates. The investigated examples {{can be used as}} tests for various numerical methods...|$|R
30|$|Regardless of {{the used}} sensing algorithm, sensing <b>errors</b> <b>are</b> <b>inevitable</b> due to {{additive}} noise, limited observations, and the inherent randomness {{of the observed}} data. Next, we present {{an overview of the}} ED and the blind spectrum sensing algorithm based on the detection of the cyclostationarity feature of a PU introduced in[6].|$|R
50|$|It {{possible}} {{to construct a}} data structure using ε-nets that can approximate the simplicial depth of a query point (given either a fixed set of samples, or a set of samples undergoing point insertions) in near-constant time per query, in any dimension, with an <b>approximation</b> whose <b>error</b> <b>is</b> {{a small fraction of}} the total number of triangles determined by the samples. In two dimensions, a more accurate approximation algorithm is known, for which the <b>approximation</b> <b>error</b> <b>is</b> a small multiple of the simplicial depth itself. The same methods also lead to fast approximation algorithms in higher dimensions.|$|R
40|$|In {{stochastic}} optimization problems, {{expectation of}} random function is often being minimized. Since the expectation can rarely be evaluated exactly an approximation {{has to be}} done. In the present paper, three types of approximation are dealt with: discretization, Monte Carlo and Quasi Monte Carlo. Convergence rate of the <b>approximation</b> <b>error</b> <b>is</b> evaluated and some upper bounds of the <b>error</b> <b>are</b> given...|$|R
40|$|We {{revisit the}} problem of {{approximating}} a multiple-input multiple-output $p imes m$ rational transfer function $H(s) $ of high degree by another $p imes m$ rational transfer function $widehat{H}(s) $ of much smaller degree, so that the $mathcal{H}_ 2 $-norm of the <b>approximation</b> <b>error</b> <b>is</b> minimized. We show that in the general case of higher-order poles in the reduced-order model, called the defective case, the stationary points of the $mathcal{H}_ 2 $-norm of the <b>approximation</b> <b>error</b> can still <b>be</b> characterized by tangential interpolation conditions. We also indicate that {{the sensitivity of the}} solution of this problem depends on the parameterization used. UC...|$|R
40|$|International audienceThis paper {{describes}} {{a method for}} computing approximate statistics for large data sets. Such situations arise in applications such as climatology, data mining and information retrieval. A modular approximation to the CDF enables the reduction of a potentially overwhelming computational exercise into smaller, manageable modules. We illustrate the properties of this algorithm using a simulated data set. It is shown that the maximum error between the approximate CDF and actual CDF is never more than 1 %. Under smoothness assumptions, the expected <b>approximation</b> <b>error</b> <b>is</b> much lower. Bounds for the <b>approximation</b> <b>error</b> of percentiles <b>are</b> also derived...|$|R
30|$|The <b>approximation</b> <b>errors</b> <b>are</b> {{higher in}} the second plot than in the third plot. This remark justifies the {{utilization}} of both weights β and γ. The approximation in the second plot is smoother than the approximation in the third plot. So, the utilization of the weight γ diminishes the high-frequency components of the errors.|$|R
40|$|This paper proves, in a {{constructive}} manner, {{that the general}} n-dimensional hierarchical fuzzy systems are universal approximators. It {{is an extension of}} the results in [L. X. Wang, Fuzzy Sets and Systems 93 (1998) 223 - 230]. An upper bound of <b>approximation</b> <b>error</b> <b>is</b> also given. (C) 2000 Elsevier Science Inc. All rights reserved...|$|R
40|$|A new {{algorithm}} is introduced for broadband macromodelling of passive electronic components from frequency response data. It modifies the vector fitting algorithm {{in such a}} way that the L 1 norm of the <b>approximation</b> <b>error</b> <b>is</b> minimised, rather than the L 2 norm. It is shown that this approach is more robust towards outliers in the data...|$|R
30|$|From {{the main}} theorem, {{we can see}} that if D=A, then D - A = 0. However, in the problem of {{low-rank}} matrix approximation, D is not necessarily equal to A, so the <b>approximation</b> <b>error</b> <b>is</b> present. Furthermore, when D is close to A, simulations demonstrate that the error has a very small magnitude (see Section  4).|$|R
40|$|AbstractThis paper {{deals with}} the {{construction}} of accurate analytic-numerical approximations of coupled parabolic mixed systems. Using sine Fourier transforms, an exact expression of the exact solution is given. Then, given an admissible error e and a time bounded subdomain Ω an analytic numerical solution is constructed so that the <b>approximation</b> <b>error</b> <b>is</b> less than e in Ω...|$|R
40|$|We {{consider}} a generalised Webster’s equation for describing wave propagation in curved tubular {{structures such as}} variable diameter acoustic wave guides. Webster’s equation in generalised form has been rigorously derived in a previous article starting from the wave equation, and it approximates cross-sectional averages of the propagating wave. Here, the <b>approximation</b> <b>error</b> <b>is</b> estimated by an a posteriori technique...|$|R
40|$|We {{consider}} approximations of 1 D Lipschitz functions by deep ReLU {{networks of}} a fixed width. We prove {{that without the}} assumption of continuous weight selection the uniform <b>approximation</b> <b>error</b> <b>is</b> lower than with this assumption at least by a factor logarithmic {{in the size of}} the network. Comment: 12 pages, submitted to J. Approx. Theor...|$|R
40|$|Some inequalities for the Stieltjes {{integral}} {{and applications}} in numerical integration are given. The Stieltjes integral is approximated by {{the product of}} the divided difference of the integrator and the Lebesgue integral of the integrand. Bounds on the <b>approximation</b> <b>error</b> <b>are</b> provided. Applications for the Fourier Sine and Cosine transforms on finite intervals are mentioned as well...|$|R
40|$|In {{this paper}} {{we show that}} the <b>approximation</b> <b>error</b> of the optimal policy {{function}} in the stochastic dynamic programing problem using the policies defined by the Bellman contraction method is lower than a constant (which depends on the modulus of strong concavity of the one-period return function) times the square root of the value function <b>approximation</b> <b>error.</b> Since the Bellman's method is a contraction it results that we can control the <b>approximation</b> <b>error</b> of the policy function. This method for estimating the <b>approximation</b> <b>error</b> <b>is</b> robust under small numerical errors in the computation of value and policy functions. ...|$|R
40|$|The {{mechanical}} properties of natural {{materials such as}} rocks and soils vary spatially. This randomness is usually modelled by random field theory so that the material properties can be specified at each point in space. When these point-wise material properties are mapped onto a finite element mesh, discretization <b>errors</b> <b>are</b> <b>inevitable.</b> In this study, the discretization <b>errors</b> <b>are</b> studied and suggestions for element sizes in relation with spatial correlation lengths are given...|$|R
30|$|Moreover, a pointwise <b>approximation</b> <b>error</b> {{estimate}} can <b>be</b> deduced.|$|R
30|$|In {{this paper}} we provide a {{rigorous}} {{analysis of the}} time-dependent evolution of Hamiltonian-varying quantum systems. As we calculated, the adiabatic <b>approximation</b> <b>error</b> <b>is</b> not proportional to the average speed of the variation of the system Hamiltonian and the inverse of the energy gaps in many cases. The results in this paper may provide guidelines when applying complicated interpolation for adiabatic evolution.|$|R
40|$|Impedance {{boundary}} conditions (IBC) {{are added to}} a Robust Maxwell Formulation (Hiptmair et al. [2008]) and implemented in the three dimensional finite element code HADAPT. The IBC lead to a substantial {{decrease in the number}} of unknowns which allows for an efficient but approximative solution of boundary layer problems. The <b>approximation</b> <b>error</b> <b>is</b> determined and analyzed for simple test geometries. Content...|$|R
40|$|Two {{methods to}} {{approximate}} infinitely divisible random fields are presented. The methods {{are based on}} approximating the kernel function in the spectral representation of such fields, leading to numerical integration of the respective integrals. Error bounds for the <b>approximation</b> <b>error</b> <b>are</b> derived and the approximations are used to simulate certain classes of infinitely divisible random fields. Comment: 41 pages, 3 figure...|$|R
