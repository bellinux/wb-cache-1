36|7|Public
5000|$|The <b>arithmetic</b> <b>decoder</b> is {{described}} in some detail in the Standard. It has three distinct properties: ...|$|E
30|$|This {{article is}} devoted to a {{different}} decoding algorithm, with low-complexity, for soft-input decoding of ACs {{in the case of}} transmission over a noisy channel. The main objective is the development of a SISO <b>arithmetic</b> <b>decoder</b> that is able to improve the error correction performance with a reasonable complexity and efficient compression behavior. First, we propose a new low-complexity <b>arithmetic</b> <b>decoder</b> that supposes the decoder to know the source symbol sequence length L and the compressed bit-stream size l. Then, the decoding task is based on the search of the MAP sequence among length-valid sequences (bit-streams of length l decoding exactly L symbols). The proposed algorithm is inspired from the Chase algorithm [21] and called Chase-like <b>arithmetic</b> <b>decoder.</b> The second contribution of this study is a new scheme for SISO arithmetic decoding. The latter is obtained through a slight modification of the Chase-like <b>arithmetic</b> <b>decoder</b> and generates additional bits reliability measure. Results corresponding to iterative decoding in the case of serial concatenation of an AC with a RSCC are presented and compared to the tandem decoding and to a trellis-based iterative decoding scheme [17, 18]. The last major contribution of the article is the implementation of the proposed SISO <b>arithmetic</b> <b>decoder</b> within the JPEG 2000 decoder and the analysis of the improvements obtained by iterative JSC decoding. In fact, the proposed SISO <b>arithmetic</b> <b>decoder</b> is applied to the JPEG 2000 entropy encoding stage which uses an adaptive binary AC (MQ coder).|$|E
40|$|This paper {{describes}} {{implementation of}} a part of JPEG 2000 algorithm (MQ-Decoder and <b>arithmetic</b> <b>decoder)</b> on a FPGA board using dynamic reconfiguration. Comparison between static and dynamic reconfiguration is presented and new analysis criteria (time performance, logic cost, spatio-temporal efficiency) are defined. MQ-decoder and <b>arithmetic</b> <b>decoder</b> can be classified in the most attractive case for dynamic reconfiguration implementation: applications without parallelism by functions. This implementation is done on an architecture designed to study dynamic reconfiguration of FPGAs: the ARDOISE architecture. The implementation obtained, based on four partial configurations of <b>arithmetic</b> <b>decoder</b> allows reducing significantly the number of logic cells (57 %) in comparison with static implementation. 1...|$|E
30|$|The <b>arithmetic</b> coding <b>decoder</b> recovers {{a message}} from an {{interval}} [a, b), where 0 < a, b < 1, through a procedure {{similar to that of}} the encoder. The decoder begins with the unit half-open interval [0.0,  1.0) and divides it into the same subintervals as the encoder. The first symbol is recovered by locating the subinterval in which the destination interval [a, b) resides. The subinterval is further divided in the same manner to recover the subsequent symbols. The procedure terminates when the current interval is equal to [a, b). for details about arithmetic coding, we refer the readers to [20, 26].|$|R
40|$|International audienceThis paper {{describes}} {{the implementation of}} the MPEG AVC CABAC entropy decoder using the RVC-CAL dataflow programming language. CABAC is the Context based Adaptive Binary <b>Arithmetic</b> Coding entropy <b>decoder</b> that is used by the MPEG AVC/H. 264 main and high profile video standard. CABAC algorithm provides increased compression efficiency, however presents a higher complexity compared to other entropy coding algorithms. This implementation of the CABAC entropy decoder using RVC-CAL proofs that complex algorithms can be implemented using a high level design language. This paper analyzes in detail two possible methods of implementing the CABAC entropy decoder in the dataflow paradigm...|$|R
40|$|In this paper, four {{important}} and interrelated issues are discussed which {{relate to the}} performance of Turbo codes for low latency and low power applications: (1) interleaving, (2) trellis termination, (3) estimation of the channel noise variance, and (4) fixed point <b>arithmetic</b> effects on <b>decoder</b> performance. We give a method for terminating both constituent convolutional encoders in a known (all zero) state by assigning specific bits within the information sequence binary values that are dependent upon the user input information bits. This method causes a slight restriction on the set of allowable interleavers that can be chosen for the scheme but does not compromise performance. Also, we give a robust method for estimating the conditional channel variance given pre-thresholded random variable samples measured directly from the channel. Finally, performance results are shown for fixed-point number representations and arithmetic...|$|R
40|$|An {{audio decoder}} {{comprises}} an <b>arithmetic</b> <b>decoder</b> for providing {{a plurality of}} decoded spectral values {{on the basis of}} an arithmetically-encoded representation of the spectral values and a frequency-domain to time-domain converter for providing a time-domain audio representation using the decoded spectral values, in order to obtain a decoded audio information. The <b>arithmetic</b> <b>decoder</b> is configured to derive a group index from a variable-length-codeword representing the group index in dependence on a state index. The <b>arithmetic</b> <b>decoder</b> is configured to derive the values of a most-significant bit-plane of a tuple of spectral values using the group index and an element index, and to provide a tuple of decoded spectral values using the values of the most-significant bit-plane of the tuple of spectral values. The <b>arithmetic</b> <b>decoder</b> is configured to select a cumulative-frequencies-table out of a set of 32 cumulative-frequencies-tables in dependence on the state index, and to apply the selected cumulative-frequencies-table to derive the group index from the variable-length codeword representing the group index...|$|E
3000|$|Figure 2 {{shows that}} the {{proposed}} soft-input <b>arithmetic</b> <b>decoder</b> improves the performance compared to the classical <b>arithmetic</b> <b>decoder.</b> In fact, with one additional AC decoding test sequence (q = 1 bit), we achieve a gain of 1.2 dB at a PER = 10 - 3. Increasing {{the value of the}} test pattern weight q induces an improvement in performance reaching 2 dB at PER = 10 [...]...|$|E
40|$|An {{audio decoder}} (200) for {{providing}} a decoded audio information (212) {{on the basis}} of an encoded audio information (210) comprises a <b>arithmetic</b> <b>decoder</b> (230) for providing a plurality of decoded spectral values (232) {{on the basis of}} an arithmetically-encoded representation (222) of the spectral values and a frequency-domain-to-time-domain converter (260) for providing a time-domain audio representation (262) using the decoded spectral values, in order to obtain the decoded audio information. The <b>arithmetic</b> <b>decoder</b> (230) is configured to select a mapping rule describing a mapping of a code value onto a symbol code in dependence on a context state. The <b>arithmetic</b> <b>decoder</b> is configured to determine or modify the current context state in dependence on a plurality of previously-decoded spectral values. The <b>arithmetic</b> <b>decoder</b> is configured to detect a group of a plurality of previously-decoded spectral values, which fulfill, individually or taken together, a predetermined condition regarding their magnitudes, and to determine the current context state in dependence on a result of the detection. An audio encoder uses similar principles...|$|E
40|$|Abstract—We {{study the}} problem of {{compressing}} a block of symbols (a block quantum state) emitted by a memoryless quantum Bernoulli source. We present a simple-to-implement quantum algorithm for projecting, with high probability, the block quantum state onto the typical subspace spanned by the leading eigenstates of its density matrix. We propose a fixed-rate quantum Shannon–Fano code to compress the projected block quantum state using a per-symbol code rate that is slightly higher than the von Neumann entropy limit. Finally, we propose quantum arithmetic codes to efficiently implement quantum Shannon–Fano codes. Our <b>arithmetic</b> encoder and <b>decoder</b> have a cubic circuit and a cubic computational complexity in the block size. Both the encoder and decoder are quantum-mechanical inverses of each other, and constitute an elegant example of reversible quantum computation. Index Terms—Arithmetic coding, noiseless coding, quantum communication, quantum computation, quantum information theory, quantum measurement, reversible computation, Schumacher coding. I...|$|R
40|$|A new {{lossless}} predictive image coder {{is introduced}} and tested. The predictions {{are made with}} a nonlinear, vector quantizer based, adaptive predictor. The prediction errors are losslessly compressed with an arithmetic coder that presumes they are Laplacian distributed with variances that are estimated during the prediction process, as in the approach of Howard and Vitter. I. Introduction Predictive coding is a common way of losslessly compressing originally analog data. A block diagram of a typical system is shown in Figure 1. predictor Lossless Encoder Image Prediction Error Prediction Bits Figure 1 : A Predictive Lossless Image Coder In such systems, a prediction for each sample to be coded is generated using the sample values previously transmitted to the decoder. This prediction is subtracted from the sample to produce an error value, which is then compressed with a lossless encoder such as a Huffman coder or an <b>arithmetic</b> coder. The <b>decoder</b> can make the same prediction as the coder [...] ...|$|R
40|$|The context-tree {{weighting}} algorithm [6] is {{an efficient}} universal source coding method for tree sources. Although a finite accuracy {{version of this}} algorithm has been analysed in [8], {{it is better to}} implement the algorithm as proposed in [7]. There it was suggested to store in each node s of the context tree, instead of an estimated probability P s e and a weighted probability P s w, the (logarithm of the) ratio P s e =P 0 s w P 1 s w. This leads to a considerable storage reduction. Here we present the arithmetic coding procedure that matches to this implementation. It is based on Tjalkens' Ph. D. thesis [4] in which tables are used to circumvent multiplications. We also present a very simple carry-blocking procedure and briefly analyse it. 1. The Rissanen-Langdon approach to arithmetic coding 1. 1. Introduction. First we investigate the structure consisting of a Context-Tree Weighting (CTW) modeler followed by an <b>arithmetic</b> encoder or <b>decoder.</b> Suppose that the CTW modeler p [...] ...|$|R
3000|$|... the {{embedded}} {{message is}} processed by the <b>arithmetic</b> <b>decoder</b> illustrated in [5, 9] {{according to the}} order established above; [...]...|$|E
3000|$|At the {{receiver}} side, we apply the iterative decoding, {{described in the}} previous section, based on information transfer between the JPEG 2000 decoder and the channel decoder. The JPEG 2000 decoder uses the proposed SISO <b>arithmetic</b> <b>decoder</b> described in Section 4.2. The test pattern weight q is fixed to 4 bits. The value of the extrinsic information β given by the SISO <b>arithmetic</b> <b>decoder</b> is experimentally optimized and we used, for [...]...|$|E
3000|$|... values, the Chase-like <b>arithmetic</b> <b>decoder</b> is less {{efficient}} than the trellis-based decoder with ε = 0.2. However, for medium to high [...]...|$|E
3000|$|We {{have seen}} in the {{previous}} section that the proposed Chase-like <b>arithmetic</b> <b>decoder</b> calculates the J (J ≤ Q) most likely length-valid compressed bit-streams [...]...|$|E
30|$|In this section, {{we propose}} {{to compare the}} {{proposed}} soft-input <b>arithmetic</b> <b>decoder</b> with a trellis-based arithmetic decoding scheme using the forbidden symbol technique with probability ε.|$|E
3000|$|... values, the Chase-like soft-input <b>arithmetic</b> <b>decoder</b> {{presents}} the best performance. In fact, it exhibits a considerable gain of about 1.1 dB over the best {{configuration of the}} trellis-based Viterbi decoding with ε = 0.2.|$|E
3000|$|The {{considered}} system {{consists of}} a finite alphabet source, a classical arithmetic encoder, an Additive White Gaussian Noise (AWGN) channel and an <b>arithmetic</b> <b>decoder.</b> The source generates packets of L symbols s = (s 1,..., s [...]...|$|E
30|$|Thus, it is {{necessary}} to use a suboptimal decoding algorithm to reduce the search space size. In the following, we describe a suboptimal soft-input <b>arithmetic</b> <b>decoder,</b> inspired from the Chase algorithm [21] which was initially proposed for soft-input decoding of linear block codes.|$|E
30|$|As {{mentioned}} in the previous section, the proposed soft-input <b>arithmetic</b> <b>decoder</b> does not use a finite-state machine to model the AC. Thus, BCJR [23] or SOVA [22] algorithms are not applicable. The main idea is not to generate bits a posteriori LLRs exact estimation but to define bits reliability factor.|$|E
3000|$|... [...]. In {{the case}} of the {{evaluated}} scheme we have q = 4 bits, and 16 classical arithmetic decoding operations are required, and which results in a reasonable complexity. On the other hand, the Chase-like algorithm is very simple and can be easily implemented for different types of ACs such as the contextual adaptive AC. However, the trellis-based <b>arithmetic</b> <b>decoder</b> is very hard to implement with such type of ACs.|$|E
30|$|Arithmetic Coding [1, 2] is {{currently}} being deployed in {{a growing number of}} compression standards such as JPEG 2000 [3] for still pictures and H 264 [4] for video sequences. Arithmetic coding yields higher compression performance when compared to other lossless compression methods since it can allocate fractional numbers of bits to input symbols. How-ever, the <b>arithmetic</b> <b>decoder</b> has poor resynchronization properties which motivated the development of JSC techniques based on ACs.|$|E
40|$|National audienceThis work aims {{to improve}} the {{performance}} of an image transmission system over a highly noisy wireless channel. To this end, we propose a joint source-channel decoding based on soft-inputs decoding techniques. This scheme involves the serial concatenation of a Soft-In Soft-Out Reed Solomon decoder and a Soft-Input <b>arithmetic</b> <b>decoder</b> that were integrated into the JPWL (JPEG 2000 Wireless) decoder. Simulation results illustrate good performance improvements compared to classical decoding schemes...|$|E
3000|$|The mode {{selection}} information determines whether a band is skipped or not {{and in the}} latter case decides whether a bit-plane is passed to the LDPCA or binary <b>arithmetic</b> <b>decoder.</b> For every bit-plane, a CCE is performed to generate soft-input information to enable SW decoding or simply to update the CCE algorithm for the next bit-plane. When all bit-planes have been processed, the coefficients in the band are reconstructed given the current SI Y [...]...|$|E
3000|$|... {{arithmetic}} classical decoding {{operations and}} depends only on q. The states number representing the arithmetic encoding machine of [15] increases for bigger values of L and U. Furthermore, the trellis construction needs {{the transmission of}} the source statistics as side information. Consequently, trellis-based decoding {{is very hard to}} apply with adaptive AC (the trellis changes with symbol probabilities). The proposed soft-input <b>arithmetic</b> <b>decoder</b> is very simple and can easily be extended to the adaptive context-based ACs.|$|E
30|$|In the {{previous}} section, {{we showed that}} the proposed soft-input <b>arithmetic</b> <b>decoder</b> takes profit from the bits' reliability at {{the output of the}} channel, which resulted in reducing the PER with respect to classical arithmetic decoding. In this section, it is modified in order to offer additional information concerning the compressed bit-stream components' reliability. Then, it is applied in an iterative decoding scheme composed of an AC and an RSCC. The system performance are evaluated in terms of PER.|$|E
3000|$|We notify that {{a similar}} {{reliability}} definition was proposed in [24] for SISO decoding of linear block codes and {{that the value of}} β is determined experimentally. All the other bits are supposed non-reliable and we assign to them an extrinsic information equal to zero. It is worth noticing that in some cases, especially with a relatively noisy channel, the Chase-like <b>arithmetic</b> <b>decoder</b> is not able to find a length-valid codeword among the Q test sequences. In this case, we propose the decoding rule [...]...|$|E
30|$|In this article, we have {{proposed}} novel low-complexity decoding algorithms for ACs {{based on the}} Chase algorithm. The schemes were tested for transmission across an AWGN channel with BPSK signaling and shows numerous significant advantages. First, we showed that the soft-input <b>arithmetic</b> <b>decoder</b> achieves good error correction performance, has low complexity and can be easily extended to adaptive ACs, unlike the trellis-based arithmetic decoders. Second, we showed that the Chase-like algorithm can be slightly modified to generate additional information regarding {{the reliability of the}} decoded bits. Such improvement allow iterative decoding {{in the case of the}} serial concatenation of an AC with a channel code. As a second experiment, the concatenation of an AC with a RSCC was considered and iterative decoding results were investigated. The scheme is a JSC decoding approach where AC embeds compression and error correction in a single stage. Simulation results shows significant performance improvement when compared to tandem decoding and to our previous iterative decoding scheme using a trellis-based SISO <b>arithmetic</b> <b>decoder.</b> Moreover, the presented iterative system has profitably been exploited in the case of JPEG 2000 image transmission. In fact, improvements in terms of average PSNR, and visual quality were observed compared to standard JPEG 2000 decoding.|$|E
40|$|In {{this paper}} we present an {{innovative}} hardware {{implementation of the}} H. 264 /AVC CABAC binary <b>arithmetic</b> <b>decoder</b> and context modeler capable of decoding one symbol per clock cycle at high clock frequencies while maintaining a slim hardware footprint. This was achieved by substantially decreasing the latency of the central feedback loop through extensive use of speculative prefetching and aggressive pipelining. Actual synthesis results targeted at the state-of-the-art FPGA families show that our approach results in a fast and compact IP core, ideal for a SoC H. 264 /AVC implementation...|$|E
30|$|The {{article is}} {{organized}} as follows. Section 2 briefly introduces {{the principles of}} arithmetic coding. In Section 3, the system model and the MAP sequence decoding metric are reported. The Chase-like <b>arithmetic</b> <b>decoder</b> is also detailed in this section and its performances are compared with a recent solution using a trellis representation of the AC with Viterbi-like decoding [15]. Section 4 addresses a new scheme for low-complexity SISO arithmetic decoding. Numerical results corresponding to iterative JSC are discussed and compared to tandem decoding and trellis-based arithmetic decoding presented in [17, 18]. In Section 5, {{the application of the}} proposed iterative decoding approach to a JPEG 2000 image communication system is described. Finally, Section 6 draws our conclusions and offers directions for future work.|$|E
30|$|At the receiver, {{we apply}} an {{iterative}} decoding {{based on information}} exchange between a low-complexity SISO Chase-like <b>arithmetic</b> <b>decoder,</b> detailed below, and the RSCC decoder using the optimal MAP algorithm. Performances of the iterative decoding scheme involving the Chase-like algorithm are evaluated and compared to tandem decoding results. As mentioned, major JSC iterative decoding contributions consider trellis-based algorithms for arithmetic SISO decoding. To evaluate the efficiency of our decoder with respect to such schemes, a comparison to an iterative decoding scheme with an arithmetic trellis-based de-coder is proposed. The reference decoder was presented in [17, 18], and the authors used a bi-dimensional bit-clock trellis to model the arithmetic encoding machine. Then, to generate soft bit-reliability estimates, a modified SOVA [22] algorithm was proposed.|$|E
40|$|This paper {{presents}} a high-throughput decoder of HEVC context-based adaptive binary arithmetic coding (CABAC). A multi-sub-engine <b>arithmetic</b> <b>decoder</b> (MSE-AD) design is proposed {{to increase the}} average number of bins delivered per clock cycle by adaptively processing different patterns of upcoming bins with balanced critical path delay. A syntax element (SE) grouping scheme is proposed to maximize the utilization of MSE-AD under the SE parsing order specified in the standard. We also employ a prediction-based pipeline to alleviate the data hazard problem. The proposed CABAC decoder delivers 2. 36 bins per clock cycle and achieves a maximum clock frequency of 258 MHz in 90 nm technology. The resulting performance is 610 Mbin/s which is enough for H. 265 /HEVC level 6. ...|$|E
30|$|We {{recall that}} the {{arithmetic}} decoding machine {{is based on a}} recursive procedure which terminates when all l bits are processed or when L symbols are obtained in the decoded sequence. However, the proposed decoder has to use information about L to detect erroneous sequences and improve decoding performance. To address this requirement, a proper AC termination strategy is implemented. In fact, the arithmetic encoder terminated each input sequence with an End-of-Block (EoB) symbol. The same rule is enforced at the decoder and only sequences that decode exactly L symbols and whose EoB symbol is determined by the last two bits is considered to be correct. This supplementary error detection tool can ameliorate the <b>arithmetic</b> <b>decoder</b> performance since it reduces the size of the search space and consequently, increases the Hamming distance between candidates.|$|E
40|$|The {{recently}} emerging {{probability interval}} partitioning entropy (PIPE) coding scheme offers high coding efficiency at a comparably low complexity level. In this paper, {{a new set}} of systematic variable-to-variable length (v 2 v) codes is proposed for use within the PIPE coding concept that allows the complexity requirements to be reduced even further. The proposed systematic v 2 v codes can be efficiently implemented by using simple counters instead of memory consuming tables. At the same time, the average number of operations per decoded binary symbol can be reduced by more than a factor of 2 relative to a fast multiplication-free binary <b>arithmetic</b> <b>decoder.</b> In terms of coding efficiency, experimental results show that in a typical video coding environment the average Bjontegaard delta (BD) rate increase is typically less than 0. 5 % when compared to the use of nearly optimal binary arithmetic codes...|$|E
40|$|International audienceThe {{design and}} {{implementation}} of a hardware accelerator dedicated to Binary Arithmetic Decoding Engine (BADE) is presented. This is the main module of the Context-Adaptive Binary <b>Arithmetic</b> <b>Decoder</b> (CABAD), as used in the H. 264 /AVC on-chip video decoders. We propose and implement a new approach for accelerating the decoding hardware of the significance map by providing the correct context for the regular hardware engine of the (CABAD). The design development {{was based on a}} large set of software experiments, which aimed at exploiting the characteristic behavior of the bitstream during decoding. The analysis gave new insights to propose a new hardware architecture to improve throughput of regular engines for significance map with low silicon area overhead. The proposed solution was described in VHDL and synthesized to standard cells in IBM 0. 18 μm CMOS process. The results show that the developed architecture reaches 187 MHz with a non optimized physical synthesis...|$|E
