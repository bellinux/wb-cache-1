7|11|Public
50|$|Personal's {{consumer}} products included: the Data Vault with Cloud Sync for secure management and sharing {{of data and}} documents between an individual and other individuals, companies, sites, apps and devices; and Data Imports to import information from third parties, including social media services, companies and the U.S. Department of Education, and the Fill It App for <b>automated</b> <b>completion</b> of web and mobile forms, logins and checkouts.|$|E
40|$|Abstract. Among e-Government systems, the Korea ON-line E-Procurement System (KONEPS) {{is unique}} in that it {{requires}} the <b>automated</b> <b>completion</b> {{of a wide variety}} of jobs across the entire procurement process: from exchanging documents, opening bids, contracting, and shopping and paying electronically to sharing information on goods, services, and participants. KONEPS is also a rare example of a successful government-administered e-procurement system that has saved a great deal of money and time in the Government-to-Business procurement process. Most e-procurement system studies focus on a rhetorical analysis of case studies and do not employ rigorous methods, making them un-suitable for assessment by potential customer countries. This study proposes a generalized approach to estimating the performance of e-procurement systems by integrating the Monte Carlo-Assisted Causal Mapping Simulation (MOCA-CAMS). Simulations in which MOCA-CAMS is applied to KONEPS indicate a very promising performance for KONEPS under uncertain conditions in cus-tomer countries. This study will provide a foundation for further discussion of this increasingly important area of e-procurement research and practice...|$|E
40|$|Assessment and {{management}} of risk is needed for sustainable use of genetically modified aquatic organisms (aquatic GMOs). A computer software package for safely conducting research with genetically modified fish and shellfish is described. By answering {{a series of questions}} about the organism and the accessible aquatic ecosystem, a researcher or oversight authority can either identify specific risks or conclude that there is a specific reason for safety of the experiment. Risk assessment protocols with examples involving transgenic coho salmon, triploid grass carp and hybrid tilapia are described. In case a specific risk is identified, the user is led to consider risk management measures, involving culture methods, facilities design and operations management, to minimize the risk. Key features of the software are its user-friendly organization; easy access to explanatory text, literature citations and glossary; and <b>automated</b> <b>completion</b> of a worksheet. Documented completion of the Performance Standards can facilitate approval of a well designed experiment by oversight authorities...|$|E
5000|$|In 2010, Sy.Med {{released}} OneApp Pro 6.1 with Adobe Acrobat integration {{that allows}} <b>automated</b> form <b>completion</b> to PDF format.|$|R
50|$|Sy.Med Development, Inc. (also {{referred}} to as SyMed) develops and licenses software that manages credentialing-related tasks for healthcare providers and payers. Sy.Med’s software, OneApp Pro, uses a data management system that <b>automates</b> form <b>completion</b> for the credentialing process.|$|R
40|$|A {{method that}} <b>automates</b> {{hypotheses}} <b>completion</b> in 3 D-Geometry is presented. It {{consists of three}} processes: defi ning the geometric objects in the confi guration; determining the hypothesis conditions of the confi guration (through a point-on-object declaration method); and applying an algebraic automatic theorem proving method to obtain and prove the sufficiency of complementary hypothesis conditions. To avoid {{as much as possible}} the appearance of rational expressions, projective coordinates are used (although affine and Euclidean problems can also be treated). A Maple implementation of the method has been used to extend to 3 D classic 2 D geometric theorems like Ceva's and Menelaus'...|$|R
40|$|Abstract. One {{driver of}} {{business}} process management {{is the opportunity}} to reduce costs by outsourcing certain tasks to third-party organizations. At the same time, it is undesirable that delicate information (e. g., trade secrets) “leak ” to the involved third parties, be it for legal or economic reasons. The absence of such leaks — called noninterference — can be checked automatically. Such a check requires an assignment of each task of the business process as either confidential or public. Drawbacks of this method are that (1) this assignment of every task is cumbersome, (2) an unsuccessful check requires a corrected confidentiality assignment although (3) the diagnosis and correction of information leaks is a nontrivial task. This paper presents a modeling prototype that integrates the noninterference check into the early design phase of an interorganizational business process. It not only allows for instant feedback on confidentiality assignments, but also for an <b>automated</b> <b>completion</b> of partial assignments toward guaranteed noninterference. ...|$|E
40|$|Phaser is {{a program}} that {{implements}} likelihood-based methods to solve macromolecular crystal structures, currently by molecular replacement or single-wavelength anomalous diffraction (SAD). SAD phasing {{is based on a}} likelihood target derived from the joint probability distribution of observed and calculated pairs of Friedel-related structure factors. This target combines information from the total structure factor (primarily non-anomalous scattering) and the difference between the Friedel mates (anomalous scattering). Phasing starts from a substructure, which is usually but not necessarily a set of anomalous scatterers. The substructure can also be a protein model, such as one obtained by molecular replacement. Additional atoms are found using a log-likelihood gradient map, which shows the sites where the addition of scattering from a particular atom type would improve the likelihood score. An <b>automated</b> <b>completion</b> algorithm adds new sites, choosing optionally among different atom types, adds anisotropic B-factor parameters if appropriate and deletes atoms that refine to low occupancy. Log-likelihood gradient maps can also identify which atoms in a refined protein structure are anomalous scatterers, such as metal or halide ions. These maps are more sensitive than conventional model-phased anomalous difference Fouriers and the iterative completion algorithm is able to find a significantly larger number of convincing sites...|$|E
40|$|Institute of Perception, Action and BehaviourAs the {{requirement}} for more realistic 3 D environments is pushed forward by the computer graphics | movie | simulation | games industry, attention {{turns away from the}} creation of purely synthetic, artist derived environments towards the use of real world captures from the 3 D world in which we live. However, common 3 D acquisition techniques, such as laser scanning and stereo capture, are realistically only 2. 5 D in nature - such that the backs and occluded portions of objects cannot be realised from a single uni-directional viewpoint. Although multi-directional capture has existed for sometime, this incurs additional temporal and computational cost with no existing guarantee that the resulting acquisition will be free of minor holes, missing surfaces and alike. Drawing inspiration from the study of human abilities in 3 D visual completion, we consider the <b>automated</b> <b>completion</b> of these hidden or missing portions in 3 D scenes originally acquired from 2. 5 D (or 3 D) capture. We propose an approach based on the visual propagation of available scene knowledge from the known (visible) scene areas to these unknown (invisible) 3 D regions (i. e. the completion of unknown volumes via visual propagation - the concept of volume completion). Our proposed approach uses a combination of global surface fitting, to derive an initial underlying geometric surface completion, together with a 3 D extension of nonparametric texture synthesis in order to provide the propagation of localised structural 3 D surface detail (i. e. surface relief). We further extend our technique both to the combined completion of 3 D surface relief and colour and additionally to hierarchical surface completion that offers both improved structural results and computational efficiency gains over our initial non-hierarchical technique. To validate the success of these approaches we present the completion and extension of numerous 2. 5 D (and 3 D) surface examples with relief ranging in natural, man-made, stochastic, regular and irregular forms. These results are evaluated both subjectively within our definition of plausible completion and quantitatively by statistical analysis in the geometric and colour domains...|$|E
50|$|In September 1972 the {{headland}} {{on which}} the lighthouse stood subsided making the structure dangerous.Trinity House used an old light tower from elsewhere for two years whilst a new structure was rebuilt further inland.This was completed in 1974 {{at a cost of}} £71,000 and is currently in use.It was fully <b>automated</b> from <b>completion,</b> stands 11 metres tall, has a light intensity of 800,000 candelas and can be seen for 24 nmi km.The diaphone foghorn was switched off in 1988, apparently the redundant equipment remains inside.The lighthouse was automated in 1995.The site can be visited by an adjacent public footpath.The old lighthouse keepers' cottages are now being let out to tourists as self-catering holiday establishments.|$|R
30|$|The {{next steps}} involve the {{implementation}} of <b>automated</b> planning for <b>completions</b> and workover operations by selecting EDS. Another possibility is to compare the EDS selected during the operation with the simulation by the system, allowing alarms and avoiding human failure. To better {{understand the importance of}} the proposed approach, new research can be carried out in the future to compare the performance in the company studied. These initiatives are mandatory for the safe and efficient development of new Petrobras discoveries.|$|R
40|$|The current {{state-of-the-art}} in many {{natural language}} processing and <b>automated</b> knowledge base <b>completion</b> tasks is held by representation learning methods which learn distributed vector representations of symbols via gradient-based optimization. They require little or no hand-crafted features, thus avoiding the need for most preprocessing steps and task-specific assumptions. However, in many cases representation learning requires {{a large amount of}} annotated training data to generalize well to unseen data. Such labeled training data is provided by human annotators who often use formal logic as the language for specifying annotations. This thesis investigates different combinations of representation learning methods with logic for reducing the need for annotated training data, and for improving generalization. Comment: PhD Thesis, University College London, Submitted and accepted in 201...|$|R
40|$|In {{application}} domains {{that store}} {{data in a}} tabular format, a common task is to fill the values of some cells using values stored in other cells. For instance, such data completion tasks arise {{in the context of}} missing value imputation in data science and derived data computation in spreadsheets and relational databases. Unfortunately, end-users and data scientists typically struggle with many data completion tasks that require non-trivial programming expertise. This paper presents a synthesis technique for <b>automating</b> data <b>completion</b> tasks using programming-by-example (PBE) and a very lightweight sketching approach. Given a formula sketch (e. g., AVG($?_ 1 $, $?_ 2 $)) and a few input-output examples for each hole, our technique synthesizes a program to automate the desired data completion task. Towards this goal, we propose a domain-specific language (DSL) that combines spatial and relational reasoning over tabular data and a novel synthesis algorithm that can generate DSL programs that are consistent with the input-output examples. The key technical novelty of our approach is a new version space learning algorithm that is based on finite tree automata (FTA). The use of FTAs in the learning algorithm leads to a more compact representation that allows more sharing between programs that are consistent with the examples. We have implemented the proposed approach in a tool called DACE and evaluate it on 84 benchmarks taken from online help forums. We also illustrate the advantages of our approach by comparing our technique against two existing synthesizers, namely PROSE and SKETCH...|$|R
40|$|The {{completion}} of a risk assessment form is a sequence of three events: chemical information discovery and acquisition; chemical information manipulation; and, assessment form template interpolation. For organisations, {{the costs associated with}} manual risk assessment are very significant; ranging from the wages of those who complete and review the forms, to the damages paid to those who are affected by any errors. We present a software system that uses Semantic Web technologies to assist with and <b>automate</b> the <b>completion</b> of COSHH risk assessment forms. We use an RDF representation of the GHS and CLP regulation to describe the hazards and precautionary statements that are associated with a library of chemical substances. Aggregating the RDF data for a collection of chemical substances enables the automatic generation of a ready-to-use, human- and machine-readable risk assessment form. The software system is backed by an RDF triple-store and SPARQL endpoint, and fronted by a lightweight, mobile-friendly Web application. We find that the introduction of software systems for automated risk assessment is, on the whole, beneficial to organisations. However, we also encounter a number of new risks, including: the risk that users obtain and utilise the “correct” answer to an “incorrect” question; the risk that users implicitly trust and/or rely upon the software system; and, the risk that the data gathered by the software system could be used to infer the research agendas of both individual users and organisations as a whole. Finally, we report on recent work to implement our software system using the Sigma-Aldrich catalogue as the primary data sourc...|$|R
40|$|BACKGROUND: Keyboard entry or {{correction}} of reports by radiologists and transcriptionists remains necessary in many settings despite advances in computerized speech recognition. PURPOSE: To develop and test a report entry system that implements an <b>automated</b> phrase <b>completion</b> feature based on language modeling. MATERIALS AND METHODS: We developed a special text editor that uses context {{to predict the}} full word or phrase being typed, updating the displayed prediction after each keystroke. At any point, pressing the tab key inserts the predicted phrase without having to type the phrase's remaining characters. Successive words of the phrase are predicted by a trigram language model trained {{on a set of}} general radiography reports consecutively generated by the first author. Phrase lengths are chosen to minimize the expected number of keystrokes as predicted by the language model. Performance was tested on 200 randomly selected reports outside of the training set. RESULTS: The language model was trained on 36, 843 reports containing 1. 48 million words. When applied to the 200 test reports, the phrase completion technique reduced the average number of keystrokes per report from 194 to 58, with the average reduction factor being 3. 3 (geometric mean; 95 % confidence interval, 3. 2 [...] 3. 5), a statistically significant reduction (P < 0. 00005). CONCLUSION: An algorithm for minimizing the expected number of keystrokes with userspecific language modeling significantly reduces the keystrokes required to generate a radiography report. Operation is highly and automatically customized to each user without the burden of creating and memorizing a complex system of text macros. Summary Statement Language modeling, a technology found in many computerized speech recognition systems, can also be us [...] ...|$|R
40|$|Model-driven {{performance}} prediction methods require {{detailed design}} models {{to evaluate the}} performance of software sys-tems during early development stages. However, the complexity of detailed prediction models and the semantic gap between modelled performance concerns and functional concerns prevents many developers to address performance. As {{a solution to this}} problem, systematic model refinements, called completions, hide low-level details from developers. Completions auto-matically integrate performance-relevant details into component-based architectures using model-to-model transformations. In such scenarios, conflicts between different completions are likely. Therefore, the application order of completions must be determined unambiguously in order to reduce such conflicts. Many existing approaches employ the concept of performance completions to include performance-relevant details to the prediction model. So far researcher only address the application of a single completion on an architectural model. The reduction of conflicting completions have not yet been considered. In this paper, we present a systematic approach to reduce and avoid conflicts between completions that are applied to the same model. The method presented in this paper is essential for the <b>automated</b> integration of <b>completions</b> in software performance engineering. Furthermore, we apply our approach to reduce conflicts of a set of completions based on design patterns for concurrent software systems...|$|R

