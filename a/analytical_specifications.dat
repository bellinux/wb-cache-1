10|50|Public
40|$|In {{this paper}} we study risk and {{liquidity}} management decisions within an insurance firm. Risk management corresponds to decisions regarding proportional reinsurance, whereas liquidity management has two components: distribution of dividends and costly equity issuance. Contingent on whether proportional or fixed costs of reinvestment are considered, singular stochastic control or stochastic impulse control techniques {{are used to}} seek strategies that maximize the firm value. We find that, in a proportional-costs setting, the optimal strategies are always mixed in terms of risk management and refinancing. In contrast, when fixed issuance costs are too high relative to the firm’s profitability, optimal management does not involve refinancing. We provide <b>analytical</b> <b>specifications</b> of the optimal strategies, {{as well as a}} qualitative analysis of the interaction between refinancing and risk management...|$|E
40|$|Comprehensive {{analytical}} methodologies are exceedingly {{needed in}} order to evaluate product quality and raw material specifications especially for botanical preparations. Advances in teaming up statistical (PCA, CA & pattern recognition techniques) and spectroscopic (UV, IR, MS & NMR) methods of analysis have generated a substantial impact on how to use spectroscopic instruments as intelligent modules capable of identifying and classifying the composition of a variety of natural products. Cymbopogon proximus, a traditionally used medicinal herb claimed to be an effective remedy for renal spasms, lacks appropriate evaluation procedures. UV assisted-PCA and PLS analysis were exercised herein to maximize the usefulness and applicability of some previously established <b>analytical</b> <b>specifications</b> for herbal materials (e. g. solvent extractive values). Hierarchical cluster analysis was also attempted to categorize and associate the generated solvent-extracts. In addition, DE-TLC and GC were used to examine the different plant fractions in a qualitative and quantitative manner...|$|E
40|$|This diploma thesis {{deals with}} the methods of desedimenting wine juice, and the {{influence}} of desedimentation upon the sensoric and analytic profiles of individual wines. The theoretical part {{deals with the}} substances contained in wine juice, the process of desedimentation, the clarity of wine, effect of bentonite and the importance of sulphur dioxide in wine. In the practical part, an experiment was conducted during which seven samples were produced out of two varieties of wine, using different desedimentation intensities. Afterwards, the amount of sulphur dioxide was measured, {{while at the same time}} the gas was being supplied at given intervals. The wines were evaluated according to <b>analytical</b> <b>specifications</b> and also with the assistance of sensoric assessment, using a hundred point scale and the aromatic profile of individual wines was also evaluated. An appropriate method of statistical evaluation as well as an interpreted conclusion were chosen to provide results, detailing the characteristics of individual samples produced within the experiment...|$|E
40|$|A {{monograph}} {{on problems}} of stability of equilibrium of mechanical systems with follower forces is presented. Concepts {{of stability and}} criteria of stability are reviewed briefly, together with means of <b>analytical</b> <b>specification</b> of follower forces. Nondissipative systems with {{two degrees of freedom}} are discussed, and destabilizing effects due to various types of dissipative forces both in discrete and continuous systems, are treated. The analyses are accompanied by some quantative experiments and observations on demonstrational laboratory models...|$|R
40|$|There is a {{wide range}} of {{visualization}} techniques for dynamical systems. These methods are used to visualize certain properties as, e. g., stability of fixed points, characteristic changes of velocity, and bifurcations. This paper gives a short introduction to dynamical systems and describes several visualization techniques. Some of those are applied to three different dynamical systems. The application of different visualization methods to dynamical systems shows, how scientific visualization can be used for analyzing the behavior of dynamical systems, and how visualization can make analysis of a dynamical system fast and efficient. Keywords: visualization, dynamical systems. 1. INTRODUCTION Dynamical systems 1 are found in various fields of research, e. g., economy physics, chemistry, and mathematics. They are given by an <b>analytical</b> <b>specification</b> (differential or difference equation) or as sampled data. There are several ways to analyze a dynamical system. One approach is to analy [...] ...|$|R
40|$|The Fire, Explosion, Compatibility and Safety Hazards of Hydrogen Peroxide NASA {{technical}} manual was {{developed at the}} NASA Johnson Space Center White Sands Test Facility. NASA Technical Memorandum TM- 2004 - 213151 covers topics concerning high concentration hydrogen peroxide including fire and explosion hazards, material and fluid reactivity, materials selection information, personnel and environmental hazards, physical and chemical properties, <b>analytical</b> spectroscopy, <b>specifications,</b> <b>analytical</b> methods, and material compatibility data. A summary of hydrogen peroxide-related accidents, incidents, dose calls, mishaps and lessons learned is included. The manual draws from art extensive literature base and includes recent applicable regulatory compliance documentation. The manual may be obtained by United States government agencies from NASA Johnson Space Center and used as a reference source for hazards and safe handling of hydrogen peroxide...|$|R
40|$|Background: In {{recent years}} {{a number of}} point of care testing (POCT) glucometers were {{introduced}} on the market. We investigated the analytical variability (lot-to-lot variation, calibration error, inter-instrument and inter-operator variability) of glucose POCT systems in a university hospital environment and compared these results with the analytical needs required for tight glucose monitoring. Methods: The reference hexokinase method was compared to different POCT systems based on glucose oxidase (blood gas instruments) or glucose dehydrogenase (handheld glucometers). Based upon daily internal quality control data, total errors were calculated for the various glucose methods and the analytical variability of the glucometers was estimated. Results: The total error of the glucometers exceeded by far the desirable <b>analytical</b> <b>specifications</b> (based on a biological variability model). Lot-to-lot variation, inter-instrument variation and inter-operator variability contributed approximately equally to total variance. As in a hospital environment, distribution of hematocrit values is broad, converting blood glucose into plasma values using a fixed factor further increases variance. The percentage of outliers exceeded the ISO 15197 criteria in a broad glucose concentration range. Conclusions: Total analytical variation of handheld glucometers is larger than expected. Clinicians {{should be aware that}} the variability of glucose measurements obtained by blood gas instruments is lower than results obtained with handheld glucometers on capillary blood...|$|E
40|$|Laboratory and {{clinical}} medicine groups are actively collaborating and optimizing their individual expertise to potentially prove standardized biomarker assays that will optimize patient care. It is critical as new biomarkers are discovered, that quality specifications be developed prior to approval by regulatory agencies that give supported endorsement for the worldwide marketplace. The laboratory medicine {{and clinical}} communities of scientists continues {{to challenge the}} biomarker field, working towards developing standard reference materials, and providing quality <b>analytical</b> <b>specifications</b> that, hopefully, will be endorsed by our clinical, in vitro diagnostic and pharmaceutical industry colleagues. This paper will specifically address cardiac troponins and natriuretic peptides. Keywords. Cardiac troponin; immunoassays; natriuretic peptides; myocardial infarction; diagnostics; risk stratification; standardization. In 2005, academics, industry, and regulatory agencies are challenged to provide quality assays for cardiac biomarkers; specifically cardiac troponin (cTn) and natriuretic peptides (NP). In part this includes developing primary reference ma-terials to standardize these assays, specifically cardiac tro-ponin I (cTnI) and B-type natriuretic peptide (BNP); both goals of the AACC and IFCC (Panteghini et al., 2001; Apple et al., 2005). The use of biomarkers in clinical prac-tice, whether for diagnostics or risk assessment, requires that measures should be reproducible, and be highly sen-sitive and specific (Manolio, 2003). When a biomarker test is in use worldwide, or crossing from research to clinical practice, requires it to be replicated in multiple settings. Standardization efforts have been underway for the past 8 years by the International Federation for Clinical Chem...|$|E
40|$|Manuscript Type: Empirical Research Question/Issue: Considering {{the recent}} {{financial}} and economic crisis {{as a unique}} exogenous shock, our study investigates the financial performance of family-controlled firms in “steady-state” conditions as opposed to situations of severe economic distress. In addition, we focus our attention within family firms in order to tease out the leadership (family or non-family CEO) and family ownership (family ownership concentration or dispersion) conditions that allow some governance arrangements to perform better than others during an economic downturn. Research Findings/Insights: Examining {{the entire population of}} Italian industrial family and non-family publicly listed companies over the period 2002 – 2012, we observe a significantly and consistently better performance of family-controlled firms during the financial and economic crisis, a finding that proves to be robust to several <b>analytical</b> <b>specifications,</b> as well as to different performance measures (ROA, ROE). Then, focusing on family firms only, we find that mixed configurations (family CEOs with relatively lower family ownership concentration) produce better performance {{in the face of an}} external hazard. Theoretical/Academic Implications: Our study confirms the pivotal assumption of the socioemotional wealth perspective that the advantages of family firms showup exactly when ownership is at stake. Our results also add to the growing literature on the resilience of family firms, showing that they are more able than others to absorb exogenous shocks. Practitioner/Policy Implications: Our findings suggest the importance of crafting governance structures well in advance of a crisis. Our research speaks to policymakers, indicating the importance of family firms for national economies, and the political opportunity to sustain their growth and managerial development...|$|E
40|$|In {{recent years}} growing sociological {{interest}} in {{new forms of}} cultural distinction has led some {{to argue that the}} advantages previously conveyed by the consumption of ‘high’ culture ‘or ‘omnivorousness’ are being overwritten by the possession of what has been termed ‘emerging cultural capital’. So far, though, this term has only been discussed in passing within empirical work and remains in need of further <b>analytical</b> <b>specification.</b> This special issue seeks to both critically interrogate and develop this concept by bringing together the work of leading cultural sociologists around four key themes: the role of age and generation in the formation of cultural capital; the power of visual display for distinction; the significance of new elite cultures; and the need for methodological pluralism to apprehend the expressions and mechanisms of distinction. This editorial introduction outlines the descriptive terrain on which the concept of emerging cultural capital has rested until now before exploring the common themes that sit across all five papers in the special issue...|$|R
40|$|It {{typically}} can {{be difficult}} to create and solve optimization models for large-scale sequential decision problems, examples of which include applications such as communications networks, inventory problems, and portfolio selection problems. Monte Carlo simulation modeling allows for the creation and evaluation of these large-scale models without requiring a complete <b>analytical</b> <b>specification.</b> Unfortunately, optimization of such simulation models is especially difficult given the large state spaces that often produce a combinatorially explosive number of potential solution policies. In this paper we introduce a new technique, Simulation for Model Generation (SMG), that begins with a simulation model of the system of interest and then automatically builds and solves an underlying stochastic sequential decision model of the system. Since construction and implementation of the created model requires approximation techniques, we also discuss several types of error that are induced into the decision process. Fortunately, the decision policies produced by the SMG approach can be directly evaluated in the original simulation model- thus the results of the SMG model can be compared against any other possible strategies, including any decision policies currently in use. ...|$|R
40|$|The definition, {{implementation}} and monitoring of valuable <b>analytical</b> quality <b>specifications</b> {{have played a}} fundamental role in improving the quality of laboratory services and reducing the rates of analytical errors. However, a body of evidence has been accumulated on the relevance of the extra-analytical phases, namely the pre-analytical steps, their vulnerability and impact on the overall quality of the laboratory information. The identification and establishment of valueable quality indicators (QIs) represents a promising strategy for collecting data on quality in the total testing process (TTP) and, particularly, for detecting any mistakes made in the individual steps of the pre-analytical phase, thus providing useful information for quality improvement projects. The consensus achieved on the developed list of harmonized QIs is a premise for the further step: the identification of achievable and realistic performance targets based on the knowledge of the state-of-the-art. Data collected by several clinical laboratories worldwide allow the classification of performances for available QIs into three levels: optimum, desirable and minimum, in agreement with the widely accepted proposal for <b>analytical</b> quality <b>specifications...</b>|$|R
40|$|PURPOSE: To {{assess the}} impact of a variety of methodological {{parameters}} on the association between six drug classes and five key adverse events in multiple databases. METHODS: The selection of Drug-Adverse Event pairs was based on public health impact, regulatory relevance, and the possibility to study a broad range of methodological issues. Common protocols and data <b>analytical</b> <b>specifications</b> were jointly developed and independently and blindly executed in different databases in Europe with replications in the same and different databases. RESULTS: The association between antibiotics and acute liver injury, benzodiazepines and hip fracture, antidepressants and hip fracture, inhaled long-acting beta 2 -agonists and acute myocardial infarction was consistent in direction across multiple designs, databases and methods to control for confounding. Some variation in magnitude of the associations was observed depending on design, exposure and outcome definitions, but none of the differences were statistically significant. The association between anti-epileptics and suicidality was inconsistent across the UK CPRD, Danish National registries and the French PGRx system. Calcium channel blockers were not associated with the risk of cancer in the UK CPRD, and this was consistent across different classes of calcium channel blockers, cumulative durations of use up to > 10 [*]years and different types of cancer. CONCLUSIONS: A network for observational drug effect studies allowing the execution of common protocols in multiple databases was created. Increased consistency of findings across multiple designs and databases in different countries will increase confidence in findings from observational drug research and benefit/risk assessment of medicines. ...|$|E
40|$|Partnership and Community Development {{is one of}} CSR {{that must}} be {{implemented}} State-Owned Enterprises. In Article 2 of the state, requiring the State-Owned Enterprises to provide guidance and assistance to the economically weak entrepreneurs, cooperatives and communities. Based on this background, the authors do legal research entitled Implementation of the Partnership and Community Development at PT. PLN (Persero) Semarang area with problems: 1). How is {{the implementation of the}} Partnership and Community Development at PT. PLN (Persero) Semarang area, 2). What are the obstacles that arise in implementing the Partnership and Community Development at PT. PLN (Persero) Semarang area, and how to overcome them. The method used is the juridical empirical research using descriptive <b>analytical</b> <b>specifications.</b> The type of data in this study is primary data and secondary data. The method of data collection using interviews with a purposive sampling technique. The method of data analysis using qualitative methods. The results of the study implementation of the Partnership and Community Development at PT. PLN (Persero) Semarang area, governed by the Board of Directors Decision PT. PLN (Persero) No. 336. K/DIR/ 2007 of Standard Operation Procedure (SOP) Implementation Program Partnership with Small Business Enterprises and Community Development Program/​​Environmental Empowerment Program Participation (PKBL/P 3 L), in accordance with what is stipulated in minister of state-owned enterprises No. :Per- 05 /MBU/ 2007 about SOE Partnership Program with the Small Business and Community Development Program. Obstacles that arise in the implementation of CSR is that many of them are stuck in the Patronage Partners timeliness principal payment and loan administration services, the number of proposals, but funds are limited. Handling cases of bad loans through rescheduling (rescheduling). While the proposals and deserves to receive aid distribution fund PBL but not sufficient, be included in the PBL next semester...|$|E
40|$|Company as {{a symbol}} of the {{dominant}} economic system, became inherently clear, structure and function is anti-thesis to the legal protection of workers/laborers, both contradictory, always found the gap between das sollen (should be) and das science (reality) and always appear discrepancy between the law in the books and law in action. In fact the economic life of the financial capitalist hegemony has been operating through the "dis-solution subject" who tidakmemandang workers/laborers as production subject that should be protected, but rather as an object that can be exploited, this is what happens in the practice of outsourcing in Indonesia, so legalization outsourcing pursuant Law Number 13 Year 2003 concerning Manpower controversy. For those who disagree argue useful in outsourced business development and create new jobs. For those who refused to believe the practice of outsourcing is a modern style of capitalism that brought misery to the workers/laborers. Based on the fact that the authors formulate the problem, how the legality of the practice of outsourcing in Yogyakarta?, How employers provide employment protection and working conditions for workers/laborers outsourcing?, How legal protection for workers/laborers outsourcing and what efforts should be made by the Government Yogyakarta city to provide legal protection for workers/laborers outsourcing. The aim is to conduct an analysis of the practice of outsourcing, knowing the implementation of job protection and working conditions for workers/laborers, knowing and analyzing the implementation of the legal protection of the laws by the government's efforts to protect the city of Yogyakarta. To answer the problems and research objectives, juridical approach used empirical/sociological research Descriptive <b>Analytical</b> <b>specifications.</b> Data types include Primary Data and Secondary Data collected through library research and documentation (library and documentation) as well as field research (field research), while the sampling was done by using non-random sampling with purposive sampling method. From the discussion, note that the legality of many violations of outsourcing in terms of the city of Yogyakarta, employment protection and working conditions for workers/laborers outsourcing is not given by the employer to the fullest, while legal protection for workers/laborers are constrained because of the weaknesses in the system employment law, good substance, structure and culture. Therefore, it is necessary revision of labor legislation, the government needs to increase the number of Yogyakarta City personnel labor inspectors, provide facilities and an adequate budget for the operation of the labor inspection in order to carry out its duties and functions to the fullest and to empower Union/workers to be able to carry out the purposes and functions well. ...|$|E
40|$|Information is {{presented}} on purification and reconcentration of heavy {{water at the}} Savannah River Plant. Process and equipment descriptions, typical operating costs, procedures for control of health hazards, standard <b>analytical</b> methods, and <b>specifications</b> for receipt of degraded heavy water for recovery at the Savannah River Plant are included. (auth...|$|R
40|$|This paper proposes an econometric {{procedure}} {{that allows the}} estimation of the pricing kernel without either any assumptions about the investors preferences {{or the use of}} the consumption data. We propose a model of equity price dynamics that allows for (i) simultaneous consideration of multiple stock prices, (ii) analytical formulas for derivatives such as futures, options and bonds, and (iii) a realistic description of all of these assets. The <b>analytical</b> <b>specification</b> of the model allows us to infer the dynamics of the pricing kernel. The model, calibrated to a comprehensive dataset including the S&P 500 index, individual equities, T-bills and gold futures, yields the conditional filter of the unobservable pricing kernel. As a result we obtain the estimate of the kernel that is positive almost surely (i. e. precludes arbitrage), consistent with the equity risk premium, the risk-free discounting, and with the observed asset prices by construction. The pricing kernel estimate involves a highly nonlinear function of the contemporaneous and lagged returns on the S&P 500 index. This contradicts typical implementations of CAPM that use a linear function of the market proxy return as the pricing kernel. Hence, the S&P 500 index does not have to coincide with the market portfolio if it is used in conjunction with nonlinear asset previous termpricingnext term models. We also find that our best estimate of the pricing kernel is not consistent with the standard time-separable utilities, but potentially could be cast into the stochastic habit formation framework of Campbell and Cochrane (J. Political Economy 107 (1999) 205) ...|$|R
40|$|To permit {{comparison}} between growth hormone (GH) results obtained using the Pharmacia polyclonal assay and the Delfia monoclonal assay, we used both methods to measure GH concentrations in peak GH {{responses to the}} pyridostigmine-growth-hormone-releasing-hormone (PD-GHRH) test and in unstimulated samples from 40 healthy adults and 31 patients with suspected GH defi-ciency. Ratio plots {{were used for the}} comparison, and acceptability criteria were based on inherent analytical imprecision and on <b>analytical</b> quality <b>specifications.</b> The mean ratio (r; Pharmacia/Delfia) for the peak GH responses in 40 healthy adults was calculated to be 1. 59, and the 95 % prediction interval for ratios fulfilling the imprecision criterion was applied. For GH values> 1 mIU/L, the peak and unstimulated GH ratios in health...|$|R
40|$|Arsenic {{contamination}} was {{studied in}} the Clinch River/Watts Bar Reservoir (CR/WBR) system downstream from the U. S. Department of Energy's Oak Ridge Reservation (ORR). Arsenic {{is of particular interest}} and concern because (1) it occurs commonly in coal-bearing rock and waste products such as fly ash associated with the burning of coal, (2) it is classified as a Class A carcinogen by the U. S. Environmental Protection Agency, and (3) disposal of fly ash, {{both on and off the}} ORR, may have contaminated surface water and sediments in the Clinch River and Watts Bar Reservoir. The present study differs from previous reports on arsenic concentrations in the CR/WBR system in the use of much more sensitive and precise processing and analytical techniques to measure arsenic species (arsenate, arsenite, and organic arsenic) at levels well below the ecological and human health risk screening criteria. The absolute detection limits using these techniques are approximately 20 to 40 pmol/L, or 0. 0015 to 0. 003 {micro}g/L. Four main sites were sampled quarterly over a 3 -year period (1990 through 1992). Sites investigated included Lower Watts Bar Reservoir near the Watts Bar Dam (Tennessee River kilometer 849. 6), the Kingston area (Clinch River kilometer 1. 6), Poplar Creek (Poplar Creek kilometer 1. 6), and the McCoy Branch Embayment (McCoy Branch kilometer 0. 3). Additional sites were investigated in the vicinity of these main stations to determine the distribution of contamination and to identify possible alternative or additional sources of arsenic. Detection limits that were a factor of 20 below the minimum risk screening criteria were achieved for 100 % of arsenic speciation data. However, 118 samples for inductively coupled plasma metals analysis were not preserved to <b>analytical</b> <b>specifications,</b> and the analytical holding times for 180 ion chromatography samples were not met. More rigorous preservative testing protocols and more tightly defined analytical statements of work will prevent these problems in the future. Introduction, background, materials and methods, results, discussion, and conclusions are presented in Volume 1. The Quality Assurance/Quality Control Summary Report; the listing of water quality and surface water arsenic speciation data by source and site; and the listing of pore water arsenic speciation and particle-to-water distribution coefficients for As, Fe, and Mn by source, site, and season are presented in Volume 2. The Clinch River Environmental Restoration Program is currently completing the second phase of the Clinch River Remedial Investigation, with the intent of performing a baseline risk assessment on collected data. The data collected for this report will contribute to the baseline risk assessment for the Clinch River. Many of the goals of the Clinch River Remedial Investigation were refined using the results of this study...|$|E
40|$|This {{brochure}} {{summarizes the}} test protocols {{used in the}} NREL Hydrogen Sensor Test Laboratory for the quantitative assessment of critical <b>analytical</b> performance <b>specifications</b> for hydrogen sensors. Researchers at the NREL Hydrogen Safety Sensor Test Laboratory developed a variety of test protocols to quantitatively assess critical <b>analytical</b> performance <b>specifications</b> for hydrogen sensors. Many are similar to, but typically more rigorous than, the test procedures mandated by ISO Standard 26142 (Hydrogen Detector for Stationary Applications). Specific protocols were developed for linear range, short-term stability, {{and the impact of}} fluctuations in temperature (T), pressure (P), relative humidity (RH), and chemical environment. Specialized tests (e. g., oxygen requirement) may also be performed. Hydrogen safety sensors selected for evaluation are subjected to a thorough regimen of test protocols, as described. Sensor testing is performed at NREL on custom-built sensor test fixtures. Environmental parameters such as T, P, RH, and gas composition are rigorously controlled and monitored. The NREL evaluations are performed on commercial hydrogen detectors, on emerging sensing technologies, and for end users to validate sensor performance for specific application needs. Test results and data are shared with the manufacturer or client via summary reports, teleconference phone calls, and, when appropriate, site visits to manufacturer facilities. Client representatives may also monitor NREL's operation while their technologies are being tested. Manufacturers may use test data to illustrate the analytical capability of their technologies and, more importantly, to guide future developments. NREL uses the data to assess technology gaps and deployment considerations. Per NREL Sensor Testing Laboratory policy, test results are treated as proprietary and are not shared with other manufacturers or other entities without permission. The data may be used by NREL in open publications (journal articles, presentations, outreach support, and other reports), but will not be attributed to a specific vendor...|$|R
40|$|<b>Analytical</b> quality <b>specifications</b> play a {{key role}} in assuring and {{continuously}} improving high-quality laboratory services. However, I believe, that there are two "missing links" in the effective management of quality specifications in the delivery of laboratory services. The first is the evidence that pre-analytical variation and related problems are not taken into great consideration by laboratory professionals. The second missing link is the communication of quality specifications to clinicians and other possible stake-holders. If quality specifications represent "the level of performance required to facilitate clinical decision-making", they cannot be used only for internal quality management procedures but must be communicated to facilitate clinical reasoning, decision-making and patient management. A consensus should be achieved in the scientific community on these issues to assure better utilization of laboratory data and, ultimately, improved clinical outcomes...|$|R
40|$|We {{present a}} simple neoclassical {{life-cycle}} model in continuous time, {{in which the}} effects of endogenous labor supply, uncertain lifetime, and family composition on consumption and income profiles are jointly analyzed. Due to a parsimonious <b>specification,</b> <b>analytical</b> solutions for consumption growth are available for constant intertemporal elasticity of substitution preferences. Without relying on borrowing constraints, the model can generate a hump in the consumption profile, and a comovement of consumption and income during working life. Life-cycle consumption profiles, Consumption-income correlation. ...|$|R
40|$|This thesis aims to be a {{practical}} manual {{that helps to}} choose the optimal ERP system for a small non manufacturing company. Intercompany systems are very complex and differ {{in relation to the}} size of companies and their activities. Therefore, this the-sis is written for purposes of a chosen company. The question that I would like to answer during the process is whether open-source systems can fully substitute commercial ERP systems in smaller companies. To achieve the goal, I designed a new customer oriented model. At the second part of this thesis, I test the model and its parts. After the <b>analytical</b> phase, <b>specification</b> and validation, I deal with a multi-ple criteria decision making process that helps to choose the optimal ERP system within budget constraints. Representatives of COTS, open source and newly build systems were considered among demanded systems...|$|R
40|$|The HINT {{benchmark}} {{was developed}} to provide a broad-spectrum metric for computers and to measure performance over {{the full range of}} memory sizes and time scales. We have extended our understanding of why HINT performance curves look the way they do and can now predict the curves using an analytical model based on simple hardware specifications as input parameters. Conversely, by fitting the experimental curves with the <b>analytical</b> model, hardware <b>specifications</b> such as memory performance can be inferred to provide insight into the nature of a given computer system...|$|R
40|$|Qualitative and {{quantitative}} laboratory results {{are important to}} the decision-making process. In some cases, they may represent the only basis for deciding between two or more given options or processes. Therefore, it is essential that handling of laboratory samples and analytical operations employed are performed at a deliberate level of conscientious effort. Reporting erroneous results can lead to faulty interpretations and result in misinformed decisions. This document provides <b>analytical</b> control <b>specifications</b> which will govern future test procedures related to all Water Recovery Test (WRT) Phase 3 activities to be conducted at the National Aeronautics and Space Administration/Marshall Space Flight Center (NASA/MSFC). This document addresses the process which will be used to verify analytical data generated throughout the test period, and to identify responsibilities of key personnel and participating laboratories, the chains of communication to be followed, and ensure that approved methodology and procedures are used during WRT activities. This document does not outline specifics, but provides a minimum guideline by which sampling protocols, analysis methodologies, test site operations, and laboratory operations should be developed...|$|R
40|$|During {{the last}} few years, {{a large number of}} new {{procurement}} business models has been developed, mostly concerning companies operating in the private sector. Their main objective is the introduction of new technologies such as e-business for the fulfilment of the procurement process of indirect goods. Lately, such models are also developed for organisations operating in the public sector all over Europe. This paper presents a case study concerning the analysis of the Greek governmental purchasing process carried out from the General Secretariat of Commerce, part of the Ministry of Development and the functions' definition of the new e-procurement system. The methodological approach as well as the tools used are analysed and the achieved results are presented. The objective of the analysis is the identification of potential problematic areas and the design of new processes in order to maximise the possibilities of a successful implementation of a new e-procurement system. The outcome of the new process design enabled the definition of the <b>analytical</b> functional <b>specifications</b> of the appropriate solution. (C) 2003 Published by Elsevier Science B. V...|$|R
40|$|The last 50 {{years have}} seen {{substantial}} changes in the landscape of laboratory medicine: its role in modern medicine is in evolution {{and the quality of}} laboratory services is changing. The need to control and improve quality in clinical laboratories has grown {{hand in hand with the}} growth in technological developments leading to an impressive reduction of analytical errors over time. An essential cause of this impressive improvement has been the introduction and monitoring of quality indicators (QIs) such as the <b>analytical</b> performance <b>specifications</b> (in particular bias and imprecision) based on well-established goals. The evolving landscape of quality and errors in clinical laboratories moved first from analytical errors to all errors performed within the laboratory walls, subsequently to errors in laboratory medicine (including errors in test requesting and result interpretation), and finally, to a focus on errors more frequently associated with adverse events (laboratory-associated errors). After decades in which clinical laboratories have focused on monitoring and improving internal indicators of analytical quality, efficiency and productivity, it is time to shift toward indicators of total quality, clinical effectiveness and patient outcomes...|$|R
40|$|Background: The aim of {{this study}} was to develop new and useful {{criteria}} for partitioning reference values into subgroups applicable to gaussian distributions and to distributions that can be transformed to gaussian distri-butions. Methods: The proposed criteria relate to percentages of the subgroups outside each of the reference limits of the combined distribution. Critical values suggested as par-titioning criteria for these percentages were derived from <b>analytical</b> bias quality <b>specifications</b> for using common reference intervals throughout a geographic area. As alternative partitioning criteria to the actual percentages, these were transformed mathematically to critical distances between the reference limits of the subgroup distributions, to be applied to each pair o...|$|R
40|$|This {{article was}} {{prepared}} at the Invitation of the Clinical Sciences Reviews Committee (CSRC) of the Association for Clinical Biochemistry. In this review {{we discuss the}} analytical inadequacies of oestradiol assays {{in relation to the}} clinical requirements for performing them, and make recommendations for their improvement. The measurement of oestradiol can be requested in a number of clinical scenarios (precocious puberty, infertility, assisted conception, hormone replacement therapy). The very wide dynamic range of oestradiol concentrations is a huge challenge for routine assays, which they are unlikely to meet on theoretical as well as practical grounds. The EQA performance of oestradiol assays in terms of trueness, comparability, recovery and analytical sensitivity leaves much to be desired and indicates that calibration is compromised by poor analytical specificity. To make oestradiol assays fit for purpose requires concerted action by all stakeholders to define <b>analytical</b> quality <b>specifications</b> for the various clinical scenarios involved, and then to encourage concerted action by the diagnostic industry to use the steroid reference measurement system to improve specificity, trueness and traceability. Ann Clin Biochem 2009; 46 : 441 – 456. DOI: 10. 1258 /acb. 2009. 00910...|$|R
40|$|A {{recently}} developed analytical simulation package {{makes it possible}} to obtain an analytical verification of data transmission performance through Tracking and Data Relay Satellite System (TDRSS) satellites. The development of this simulation package has required performing an analytical evaluation of several key communication features of the TDRSS services in order to ensure the consistency of TDRSS and Shuttle user spacecraft transponder performance <b>specifications.</b> <b>Analytical</b> models of the Shuttle transponder, TDRS, TDRSS ground terminal, and link dynamics have been developed for the forward and return links. The models used for the signals and the transmission path are discussed, giving attention to the general set-up of the program and the analytical approach used. Some of the results obtained by using the program are also considered...|$|R
40|$|ABSTRACT The {{advance of}} {{information}} technology has affected the revolution of the crime where the conventional one becomes more modern. The lack of knowlegde of cybercrime from the investigator makes it longer {{and more difficult to}} determine the offender. The crimes often related to the internet, one of which, is the spread of obscene pictures, pornography, and defamation through social media. The difficulties in the mechanism of investigation in the handling of blackmailing case on social media are the difficulties in finding the evidence of the blackmailing done since the evidence of the blackmail was not visible. However, the threat of spreading the photo was done because the blackmail was committed verbally by the offender to the victim, therefore in the mechanism of the investigation often the evidence needs the offender confession. The problems identification were the mechanism of investigation against the blackmail through social media by spreading the pornographic photo of the victim and the obstacles in enforcing the criminal law upon the blackmail through social media by spreading the pornographic photo in practice and the measures to be taken by the investigator in enforcing the criminal law upon the blackmail through social media by spreading the pornographic photo of the victim under the Code of Criminal Procedure related to the Law No. 11, 2008 concerning the Information and Electronic Transaction? The method of research used was descriptive <b>analytical</b> <b>specification</b> of research with juridical normative method of approach. Data collecting technique was library study. In analyzing data, analysis qualitative method was used using deductive method meaning that things in general leading to the specific things without using statistical data. From the research, it can be concluded that the investigation mechanism in the offense of blackmailing through media social by spreading the photo of the victim was by using Police Investigation Standard Operational Procedure by doing acquiring and imaging process, followed by analyzing the content then the result of digital evidence were brought to the attorney to be brought before the court. The difficulties dealt by the investigator in handling the blackmail through social media was the private data of the offender were difficult to obtain, lack of information about the offender also made it difficult for the investigator to catch the offender. The measure to be taken to handle the difficulties dealt by the investigator in this blackmailing case through social media was by training for the police investigator about the cyber crime getting more developed and more complex and {{with the support of the}} better facilities and infrastructure of technology for the investigator to be easier to handle an offense and cybercrime. Keywords: Investigator, photo, social media, blackmai...|$|R
40|$|A new {{procedure}} for the screening of total N-methylcarbamate (NMCs) content in water at different concentration levels is here presented. It {{is based on}} a previous off-line alkaline hydrolysis of the NMCs, for the production of methylamine (MA), and its subsequent derivatisation with o-phthalaldehyde (OPA). After that, the obtained derivative is involved in the peroxyoxalate chemiluminescent (PO-CL) reaction using imidazole as a catalyst being the CL emission proportional to the total NMC content. The chemiluminescent reaction is carried out in a flow injection analysis (FIA) manifold, employing sodium dodecyl sulphate micellar medium as carrier, which avoids the rapid degradation of POs in water solution. The applicability of the screening method is shown for the monitoring of NMCs in natural waters. <b>Analytical</b> features, as <b>specification</b> limit signal, screening uncertainty, sensitivity and specificity, are calculated...|$|R
40|$|Savannah River National Laboratory (SRNL) {{analyzed}} solvent {{samples from}} Modular Caustic-Side Solvent Extraction Unit (MCU) {{in support of}} continuing operations. A quarterly analysis of the solvent is required to maintain solvent composition within <b>specifications.</b> <b>Analytical</b> results of the analyses of Solvent Hold Tank (SHT) samples MCU- 12 - 488, MCU- 12 - 489, MCU- 12 - 490, MCU- 12 - 491, MCU- 12 - 492 and MCU- 12 - 493 received 24 October 2012 are reported. The {{results show that the}} solvent at MCU does not require an Isopar® L addition, but it will require addition of trioctylamine. SRNL also analyzed the SHT sample for {sup 137 }Cs content and determined the measured value is within tolerance but is trending upward compared to the {sup 137 }Cs measurement made last year...|$|R
40|$|The {{recommended}} {{standard is}} given limiting employee exposure {{to less than}} 15 milligrams of hydrogen-sulfide (7783064) per cubic meter of air (10 ppm) during a 10 minute sampling period {{for up to a}} 10 -hour work shift in a 40 -hour workweek with evacuation of the area if the concentration equals or exceeds 70 milligrams per cubic meter. In addition, standards are given for medical surveillance, labeling and posting, personal protective equipment, work practices, sanitation, and monitoring and recordkeeping. The criteria for the standards are also given, including extent of exposure in the United States, historical reports of exposure, effects on humans, epidemiological studies, animal toxicity, correlation of exposure and effect, carcinogenicity, mutagenicity, teratogenicity, effects on reproduction, environmental concentrations to which workers have been exposed, various attempts at controlling exposure, environmental sampling and analytical methods, biological monitoring, work practices and safety precautions for handling carbon-disulfide, the bases upon which previous and the present standards are recommended, and research needs. Appendices give the recommended air sampling method, <b>analytical</b> method, <b>specifications</b> for monitors, material safety data sheet, and NIOSH interim work practice recommendations for the gas and oil industry issued in August, 1976. Tables give physical and chemical properties, occupations with potential exposure, and calibration setup for personal sampling pump. (Contract No. 099 - 74 - 0031) " - NIOSHTIC- 2 CurrentPrevention and ControlEnvironmental HealthNIOSH Contract 099 - 74 - 003...|$|R
40|$|Savannah River National Laboratory (SRNL) {{analyzed}} solvent {{samples from}} Modular Caustic-Side Solvent Extraction Unit (MCU) {{in support of}} continuing operations. A quarterly analysis of the solvent is required to maintain solvent composition within <b>specifications.</b> <b>Analytical</b> results of the analyses of Solvent Hold Tank (SHT) samples MCU- 13 - 189, MCU- 13 - 190, and MCU- 13 - 191 received on September 4, 2013 are reported. The {{results show that the}} solvent (remaining heel in the SHT tank) at MCU contains excess Isopar� L and a deficit concentration of modifier and trioctylamine when compared to the standard MCU solvent. As with the previous solvent sample results, these analyses indicate that the solvent does not require Isopar� L trimming at this time. Since MCU is switching to NGS, {{there is no need to}} add TOA nor modifier. SRNL also analyzed the SHT sample for {{sup 137 }Cs content and determined the measured value is within tolerance and the value has returned to levels observed in 2011...|$|R
40|$|Background: Pathology {{laboratories}} {{are required}} to immediately report results which indicate a patient is at critical risk, {{but there is little}} consensus about what values are deemed critical. The aim of this review was to systematically review the literature on alert thresholds for common chemistry and hematology tests in adults and to provide an explicit and ranked source of this evidence. Methods: The literature search covered the period of 1995 - 2014. Evidence sources were critically appraised and ranked using the 1999 Stockholm hierarchy for <b>analytical</b> performance <b>specifications</b> in laboratory medicine modified for establishing decision limits. Results: The 30 most frequently reported laboratory tests with alert thresholds are presented with evidence rankings. Similar thresholds were reported in North America, Europe and Asia. Seventy percent of papers reported thresholds set by individual institutions, while 18 % contained thresholds from surveys of laboratories or clinicians. Forty-six percent of the papers referred to 1 or both of the 2 American laboratory surveys from the early 1990 s. "Starter sets" of alert thresholds were recommended by 6 professional bodies, 3 of which were collaborations between pathologists and clinicians. None of the 9 outcome studies identified dealt with confounding factors. Conclusions: Recommendations by professional bodies based on outdated surveys of the former state of the art or consensus are currently the best sources of evidence for laboratories to build their alert list. Well-designed outcome studies and greater collaboration between clinicians and the laboratory are needed to identify the most appropriate alert thresholds that signify actionable, critical or significant risk to patient well-being. 13 page(s...|$|R
