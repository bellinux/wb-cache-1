135|18|Public
5000|$|<b>Axiomatic</b> <b>semantics,</b> whereby one gives {{meaning to}} phrases by {{describing}} the logical axioms {{that apply to}} them. <b>Axiomatic</b> <b>semantics</b> makes no distinction between a phrase's meaning and the logical formulas that describe it; its meaning is exactly what can be proven about it in some logic. The canonical example of <b>axiomatic</b> <b>semantics</b> is Hoare logic.|$|E
5000|$|<b>Axiomatic</b> <b>semantics</b> - {{includes}} predicate transformer semantics ...|$|E
5000|$|In 1969, Tony Hoare {{introduces}} the Hoare logic, {{a form of}} <b>axiomatic</b> <b>semantics.</b>|$|E
40|$|In {{this paper}} we study {{the problem of}} {{integrating}} heterogeneous formal notations, emphasising {{the integration of the}} <b>axiomatic</b> (logical) <b>semantics.</b> We present a general method for integrating the consequence systems of interrelated heterogeneous formal notations and explain why and when the resulting compound muiltilogical consequence system may need the additional support of structural (&quot;locality&quot;) axioms in order to incorporate the interrelations between the components. We illustrate the use of this method as a basis for the integration of VDM and B formalisms based on LPF and Classical logic...|$|R
40|$|Dynamic Epistemic Logic is {{the study}} of how to reason about knowledge, belief, and communication. This paper surveys this fast-growing field, {{covering}} syntax, <b>semantics,</b> <b>axiomatics,</b> bisimulation and action emulation, expressivity results, extension and embedding results, and issues of truth persistence and paradox that result from doxastic change. Along the way, we identify a number of open problems and areas fo...|$|R
40|$|We {{present an}} <b>axiomatic</b> {{framework}} for <b>semantics</b> {{that can be}} ap-plied to natural and formal languages. Our main goal is to suggest a very simple mathematical model that describes fundamental cognitive aspects {{of the human brain}} and that can still be applied to articial intelligence. One of our main results is a theorem that allows us to infer syntactical properties of a language out of its corresponding se-mantics. The role of pragmatics in semantics in our mathematical framework is also discussed...|$|R
50|$|<b>Axiomatic</b> <b>semantics</b> is an {{approach}} based on mathematical logic for proving the correctness of computer programs. It {{is closely related}} to Hoare logic.|$|E
5000|$|Algebraic {{semantics}} {{is a form}} of <b>axiomatic</b> <b>semantics</b> {{based on}} algebraic laws for describing and reasoning about program semantics in a formal manner; ...|$|E
5000|$|If {{the formal}} {{specification}} {{is in an}} <b>axiomatic</b> <b>semantics,</b> the preconditions and postconditions of the specification may become assertions in the executable code.|$|E
40|$|We {{introduce}} hybrid Ockhamist temporal logic, {{which combines}} {{the mechanisms of}} hybrid logic with Ockhamist semantics by employing nominals, satisfaction operators, binders, and quantifiers over branches. We provide a complete (with respect to bundled trees <b>semantics)</b> <b>axiomatic</b> system for the basic hybrid Ockhamist temporal logic (HOT) and for some of its extensions, including the full hybrid Ockhamist temporal logic. The full system is expressively equivalent to the first-order logic over trees extended with branch quantifiers which was proved decidable by Gurevich and Shelah. 1...|$|R
40|$|It {{often happens}} that several {{different}} regulations {{apply to a}} given organization. And sometimes, these regulations are conflicting, that is, for instance, one regulation {{says that it is}} forbidden to do some action while another says it is permitted to do the same action. In this paper, we present a logic, called FUSION, to reason when several regulations are merged together. Our approach is to solve the conflicts by giving an order of priority between the regulations to be merged. We present the <b>axiomatics</b> and <b>semantics</b> of FUSION and prove some "good" properties enforced by this logic. 1 Introduction The work presented in this paper applies to the analysis of norm-governed organizations, that is organizations in which all or a portion of the activity is controlled by some regulations which define what is permitted, forbidden or obligatory. In such organizations, it often happens that several possibly conflicting regulations apply. For instance, let us consider an organiza [...] ...|$|R
40|$|In {{this report}} {{we discuss the}} {{typology}} of dialogues given by Walton and Krabbe and offer a precise interpretation of them. We go on to discuss one of these dialogue types - persuasion - {{in the context of}} practical reasoning and the problems associated with such reasoning. We propose a perspective on practical reasoning as presumptive justification and critical questions, giving an extension to the account proposed by Walton [24]. This provides us with a foundation for a protocol, named PARMA, for a dialogue game based on this theory. We go on to give an <b>axiomatic</b> and denotational <b>semantics</b> for PARMA and discuss two implementations based on PARMA...|$|R
50|$|In {{computer}} science, algebraic semantics {{is a form}} of <b>axiomatic</b> <b>semantics</b> {{based on}} algebraic laws for describing and reasoning about program semantics in a formal manner.|$|E
50|$|<b>Axiomatic</b> <b>semantics</b> {{define the}} meaning of a command in a program by {{describing}} its effect on assertions about the program state. The assertions are logical statements—predicates with variables, where the variables define the state of the program.|$|E
5000|$|Formal {{semantics}} is {{the formal}} specification of the behaviour of computer programs and programming languages. Three common approaches {{to describe the}} semantics or [...] "meaning" [...] of a computer program are denotational semantics, operational semantics and <b>axiomatic</b> <b>semantics.</b>|$|E
40|$|Formal {{semantic}} {{description is}} significant for design, reasoning and standardization of programming languages, and it {{plays an important}} part in the optimization of the compiler. However, compared to the amount of effort that has been made to the research of various semantic frameworks over more than forty years, their actual applications are definitely frustrating. This survey reviews the history of developments on semantic description frame- works for programming languages. It also illustrates features and actual applications of the main frameworks (including operational, deno- tational, <b>axiomatic</b> and hybrid <b>semantics).</b> In some practical aspects, such as comprehensibility, extensibility and applicability, the qualitative comparisons of these frameworks are given distinctly. It suggests that a more popular formal semantic description should behave more elegantly in readability, modularity, abstractness, comparability, reasonability, applicability and tool-support...|$|R
5000|$|Dynamic logic was {{developed}} by Vaughan Pratt in 1974 in notes for a class on program verification as an approach to assigning meaning to Hoare logic by expressing the Hoare formula [...] as [...] The approach was later published in 1976 as a logical system in its own right. The system parallels A. Salwicki's system of algorithmic logic [...] and Edsger Dijkstra's notion of weakest-precondition predicate transformer , with [...] corresponding to Dijkstra's , weakest liberal precondition. Those logics however made no connection with either modal logic, Kripke semantics, regular expressions, or the calculus of binary relations; dynamic logic therefore {{can be viewed as}} a refinement of algorithmic logic and predicate transformers that connects them up to the <b>axiomatics</b> and Kripke <b>semantics</b> of modal logic as well as to the calculi of binary relations and regular expressions.|$|R
40|$|AbstractTwo ways of {{describing}} the behaviour of concurrent systems have widely been suggested: arbitrary interleaving and partial orders. Sometimes {{the latter has}} been claimed superior because concurrency is represented in a ‘true’ way; on the other hand, some authors have claimed that the former is sufficient for all practical purposes. Petri net theory offers a framework in which both kinds of semantics can be defined formally and hence compared with each other. Occurence sequences correspond to interleaved behaviour while {{the notion of a}} process is used to capture partial-order semantics. This paper aims at obtaining formal results about the relationship between various classes of processes and occurence sequences in net theory. We shall compare an axiomatic approach to the definition of processes with an inductive approach which relates processes to occurence sequences (and generalisations thereof). We shall show that, in general, <b>axiomatic</b> process <b>semantics</b> is more powerful than inductive semantics using occurence sequences. However, we shall also show that the latter can be generalised, or the former be restricted, to yield various equivalence results. The structure of the relation between sequences and processes will also be explored, exhibiting two meaningful relations, one on the sequences and one on the processes, which correspond to each other bijectively. We shall apply and simplify the theory to the practically important case of nets which are of finite synchronisation and 1 -safe...|$|R
50|$|Formal methods is {{the term}} applied to the {{analysis}} of software (and computer hardware) whose results are obtained purely through the use of rigorous mathematical methods. The mathematical techniques used include denotational semantics, <b>axiomatic</b> <b>semantics,</b> operational semantics, and abstract interpretation.|$|E
5000|$|To {{prove that}} a {{particular}} operational semantics for a language satisfies the logical formulas of an <b>axiomatic</b> <b>semantics</b> for that language. Such a proof demonstrates that it is [...] "sound" [...] to reason about a particular (operational) interpretation strategy using a particular (axiomatic) proof system.|$|E
50|$|In {{computer}} science, {{denotational semantics}} (initially known as mathematical semantics or Scott-Strachey semantics) is an approach of formalizing {{the meanings of}} programming languages by constructing mathematical objects (called denotations) that describe the meanings of expressions from the languages. Other approaches to providing formal semantics of programming languages include <b>axiomatic</b> <b>semantics</b> and operational semantics.|$|E
40|$|Abstract. This paper {{introduces}} new logical systems which axiomatize {{a formal}} representation of inconsistency (here {{taken to be}} equivalent to contradictoriness) in classical logic. We start from an intuitive semantical account of inconsistent data, fixing some basic requirements, and provide two distinct sound and complete <b>axiomatics</b> for such <b>semantics,</b> LFI 1 and LFI 2, {{as well as their}} first-order extensions, LFI 1 * and LFI 2 *, depending on which additional requirements are considered. These formal systems are examples of what we dub Logics of Formal Inconsistency (LFI) and form part of a much larger family of similar logics. We also show that there are translations from classical and paraconsistent first-order logics into LFI 1 * and LFI 2 *, and back. Hence, despite their status as subsystems of classical logic, LFI 1 * and LFI 2 * can codify any classical or paraconsistent reasoning. 1. Introduction an...|$|R
40|$|Two ways of {{describing}} the behaviour of concurrent systems have widely been suggested: arbitrary interleaving and partial orders. Sometimes {{the latter has}} been claimed superior because concurrency is represented in a 'true' way; on the other hand, some authors have claimed that the former is sufficient for all practical purposes. Petri net theory offers a framework in which both kinds of semantics can be defined formally and hence compared with each other. Occurence sequences correspond to interleaved behaviour while {{the notion of a}} process is used to capture partial-order semantics. This paper aims at obtaining formal results about the relationship between various classes of processes and occurence sequences in net theory. We shall compare an axiomatic approach to the definition of processes with an inductive approach which relates processes to occurence sequences (and generalisations thereof). We shall show that, in general, <b>axiomatic</b> process <b>semantics</b> is more powerful than inductive semantics using occurence sequences. However, we shall also show that the latter can be generalised, or the former be restricted, to yield various equivalence results. The structure of the relation between sequences and processes will also be explored, exhibiting two meaningful relations, one on the sequences and one on the processes, which correspond to each other bijectively. We shall apply and simplify the theory to the practically important case of nets which are of finite synchronisation and 1 -safe. © 1987. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|R
40|$|Abstract. The formal axiomatic method {{stemming}} from Hilbert and recently defended by Hintikka {{is not fully}} adequate to the recent successful practice of axiomatizing mathe-matical theories. The axiomatic architecture of Topos theory and Homotopy type theory does not quite fit {{the pattern of the}} formal axiomatic theory in the standard sense of the word. However these theories fall under a more general and in some respects more traditional notion of axiomatic theory, which I call after Hilbert and Bernays constructive and demonstrate using the Classical example of the First Book of Euclid’s Elements. On the basis of these modern and ancient examples I claim that Hintikka’s semantic-oriented formal axiomatic method is not self-sustained but requires a support of some more basic constructive method. I provide an independent epistemological grounding for this claim by showing the need to complement Hintikka’s account of axiomatic method with a con-structive notion of formal <b>semantics.</b> <b>Axiomatic</b> method and Constructive Mathematics and Euclid and Topos theory and Homotopy Type theory 1...|$|R
5000|$|<b>Axiomatic</b> <b>semantics,</b> {{in which}} {{the meaning of the}} system is {{expressed}} in terms of preconditions and postconditions which are true before and after the system performs a task, respectively. Proponents note the connection to classical logic; critics note that such semantics never really describe what a system does (merely what is true before and afterwards).|$|E
50|$|The {{verification}} {{of these systems}} is done by providing a formal proof on an abstract mathematical model of the system, the correspondence between the mathematical model {{and the nature of}} the system being otherwise known by construction. Examples of mathematical objects often used to model systems are: finite state machines, labelled transition systems, Petri nets, vector addition systems, timed automata, hybrid automata, process algebra, formal semantics of programming languages such as operational semantics, denotational semantics, <b>axiomatic</b> <b>semantics</b> and Hoare logic.|$|E
50|$|Operational {{semantics}} is {{a category}} of formal programming language semantics in which certain desired properties of a program, such as correctness, safety or security, are verified by constructing proofs from logical statements about its execution and procedures, rather than by attaching mathematical meanings to its terms (denotational semantics). Operational semantics are classified in two categories: structural operational semantics (or small-step semantics) formally describe how the individual steps of a computation {{take place in a}} computer-based system. By opposition natural semantics (or big-step semantics) describe how the overall results of the executions are obtained. Other approaches to providing a formal semantics of programming languages include <b>axiomatic</b> <b>semantics</b> and denotational semantics.|$|E
40|$|From {{a purely}} {{scientific}} viewpoint, {{the members of}} the various working groups concerned with programming language standardization really ought to report to their parent committees that their assigned task is impossible without a major prior effort by the technical community; and that this prior effort would have to produce an effective procedure for describing the languages that are of concern. Thomas B. Steel, Jr., 1967 [$ 4] The current use of formal definitions of programming languages is very limited, largely {{because of a lack of}} fully developed techniques and because of user resistance to the poor human engineering of the definitions themselves. Nevertheless, usable formal definitions are essential for the effective design of programming languages and their orderly development and standardization. We present four well-known formal definition techniques: W-grammars, Production Systems with an <b>axiomatic</b> approach to <b>semantics,</b> the Vienna Definition Language, and Attribute Grammars. Each technique is described tutorially and examples are given; then each technique is applied to define the sam...|$|R
40|$|The Unified Modeling Language is extensible, {{and so can}} be {{regarded}} as a family of languages. Implicitly or explicitly, any particular UML model should be accompanied by a definition of the particular UML family member used for the model. The definition should cover syntactic and semantic issues. This paper proposes a mechanism for associating models with such definitions. Any particular definition would form what we call a preface. The name is intended to suggest that the definition of a particular UML family member must conceptually come before any model built using that family member. A preface would be large, and should be organised using packages. This would allow large amounts of sharing between different prefaces. The paper proposes that prefaces should have an <b>axiomatic</b> style of <b>semantics,</b> though not necessarily fully formal, and it offers a general approach to semantics that would reduce problems of inconsistency within a large preface, based on the idea of general cases and s [...] ...|$|R
40|$|The pattern {{matching}} calculi {{introduced by the}} first author are a refinement of the λ-calculus that integrates mechanisms appropriate for fine-grained modelling of non-strict {{pattern matching}}. While related work in the literature only uses a single monad, typically Maybe, for matchings, we present an <b>axiomatic</b> approach to <b>semantics</b> of these pattern matching calculi using two monads, one for expressions and one for matchings. Although these two monads only need to be relatively lightly coupled, this semantics implies soundness of all core PMC rules, and is {{a useful tool for}} exploration of the design space for pattern matching calculi. Using lifting and Maybe monads, we obtain standard Haskell semantics, and by adding another level of Maybe to both, we obtain a denotational semantics of the “matching failure as exceptions” approach of Erwig and Peyton Jones. Using list-like monads opens up interesting extensions in the direction of functional-logic programming. A short version of this report appears as [Kahl, Carette + 2006]...|$|R
5000|$|Formally, an ADT may {{be defined}} as a [...] "class of objects whose logical {{behavior}} is defined by a set of values and a set of operations"; this is analogous to an algebraic structure in mathematics. What is meant by [...] "behavior" [...] varies by author, with the two main types of formal specifications for behavior being axiomatic (algebraic) specification and an abstract model; these correspond to <b>axiomatic</b> <b>semantics</b> and operational semantics of an abstract machine, respectively. Some authors also include the computational complexity ("cost"), both in terms of time (for computing operations) and space (for representing values). In practice many common data types are not ADTs, as the abstraction is not perfect, and users must be aware of issues like arithmetic overflow that are due to the representation. For example, integers are often stored as fixed width values (32-bit or 64-bit binary numbers), and thus experience integer overflow if the maximum value is exceeded.|$|E
40|$|Abstract. We are {{developing}} {{a new approach to}} sequential object-oriented program verification for a significant C # subset called C#-light. The approach is based on translation of C#-light into an intermediate language called C#-kernel and a Hoare-like <b>axiomatic</b> <b>semantics</b> of C#-kernel. In this paper we describe C#-kernel and its <b>axiomatic</b> <b>semantics.</b> Unlike standard <b>axiomatic</b> <b>semantics,</b> our rules can generate lazy verification conditions which include functional symbols denoting postponed extractions of invariants of labelled statements as well as postponed invocations of methods and delegates. We also present refinement algoritms which eliminate these symbols. ...|$|E
40|$|We define an <b>axiomatic</b> <b>semantics</b> for {{a common}} kernel of {{existing}} data-parallel languages. We introduce an assertional language which enables us to define a weakest liberal precondition calculus which has the Definability Property, and a proof system (`a la Hoare) which has the Completeness Property. Moreover, our <b>axiomatic</b> <b>semantics</b> integrates two previous works {{in the definition of}} proof systems for data-parallel programs. This work sheds a new light on the logical complexity of proving data-parallel programs...|$|E
40|$|Excerpted {{from the}} longer Roy, Symbolic Logic, {{including}} chapter 1 {{and just the}} first parts of chapters 2 - 7. From the preface: There is, I think, a gap between what many students learn in their first course in formal logic, {{and what they are}} expected to know for their second. While courses in mathematical logic with metalogical components often cast only the barest glance at mathematical induction or even the very idea of reasoning from definitions, a first course may also leave these untreated, and fail explicitly to lay down the definitions upon which the second course is based. The aim of this text is to integrate material from these courses and, in particular, to make serious mathematical logic accessible to students I teach. The first parts introduce classical symbolic logic as appropriate for beginning students; the last parts build to Gödel’s adequacy and incompleteness results. A distinctive feature of the last section is a complete development of Gödel’s second incompleteness theorem. Contents Front Matter I The Elements: Four Notions of Validity 1 Logical Validity and Soundness 2 Formal Languages 3 <b>Axiomatic</b> Deduction 4 <b>Semantics</b> 5 Translation 6 Natural Deduction II Transition: Reasoning About Logic 7 Direct Semantic Reasoning Answers to Selected Exercises Bibliography[URL]...|$|R
40|$|From the preface: There is, I think, a {{gap between}} what many {{students}} learn in their first course in formal logic, {{and what they are}} expected to know for their second. While courses in mathematical logic with metalogical components often cast only the barest glance at mathematical induction or even the very idea of reasoning from definitions, a first course may also leave these untreated, and fail explicitly to lay down the definitions upon which the second course is based. The aim of this text is to integrate material from these courses and, in particular, to make serious mathematical logic accessible to students I teach. The first parts introduce classical symbolic logic as appropriate for beginning students; the last parts build to Gödel’s adequacy and incompleteness results. A distinctive feature of the last section is a complete development of Gödel’s second incompleteness theorem. Contents Front Matter I The Elements: Four Notions of Validity 1 Logical Validity and Soundness 2 Formal Languages 3 <b>Axiomatic</b> Deduction 4 <b>Semantics</b> 5 Translation 6 Natural Deduction II Transition: Reasoning About Logic 7 Direct Semantic Reasoning 8 Mathematical Induction III Classical Metalogic: Soundness and Adequacy 9 Preliminary Results 10 Main Results 11 More Main Results IV Logic and Arithmetic: Incompleteness and Computability 12 Recursive Functions and Q 13 Gödel’s Theorems 14 Logic and Computability Concluding Remarks Answers to Selected Exercises Bibliography[URL]...|$|R
40|$|When {{considering}} the correctness of programs, the only absolute demonstration of quality is mathematical proof. Yet {{the complexity of}} these proofs makes them all but impossible both to construct and read, and the correctness of the proofs themselves come into question. We take an approach {{to the creation of}} these proofs based on specifying an <b>axiomatic</b> <b>semantics</b> for the programming language, and using that semantics to automatically create a Verification Condition Generator, a program that takes a general program written in the language and creates the proof of that program, modulo a set of verification conditions, to be proven by hand. This automates much of the detailed work of creating the proof. Yet even this VCG technique depends on the soundness of the <b>axiomatic</b> <b>semantics,</b> and in fact, many proposed <b>axiomatic</b> <b>semantics</b> have suffered from unsoundness. We take the difficult but secure approach of foundationally defining an operational semantics of the programming language, including concurrency, and then proving the axioms and rules of inference of the <b>axiomatic</b> <b>semantics</b> from the operational semantics as theorems. Once this is done, the correctness of the VCG function itself can be proven, so the proofs of concurrent programs as constructed by the VCG {{in a way that is}} known to be sound, modulo the truth of th...|$|E
