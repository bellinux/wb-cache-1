14|49|Public
2500|$|Like {{the case}} for regular spin, the isospin {{operator}} I is vector-valued: it has three components Ix, Iy, Iz which are coordinates in the same 3-dimensional vector space where the 3 representation acts. Note that {{it has nothing to}} do with the physical space, except similar mathematical formalism. Isospin is described by two quantum numbers: I, the total isospin, and I3, an eigenvalue of the Iz projection for which flavor states are eigenstates, not an <b>arbitrary</b> <b>projection</b> as in the case of spin. In other words, each I3 state specifies certain flavor state of a multiplet. The third coordinate (z), to which the [...] "3" [...] subscript refers, is chosen due to notational conventions which relate bases in 2 and 3 representation spaces. Namely, for the spin- case, components of I are equal to Pauli matrices divided by 2 and Iz = [...] τ3, where ...|$|E
30|$|For each {{data set}} given in Table 1 we learned several basis vector sets or dictionaries. The sets sizes K are: 100, 200, 300 and 500. Contrary to the {{conventional}} sparse coding scheme, where the dictionary size is {{much bigger than the}} vectors dimension (for over-complete representation), in our case we in fact do dimension reduction. This is motivated by the fact that our super-vectors are highly redundant and that the basis vectors actually represent higher level spectral image features, not just <b>arbitrary</b> <b>projection</b> directions.|$|E
40|$|Generating {{images of}} texture mapped {{geometry}} requires projecting surfaces onto a two-dimensional screen. If this projection involves perspective, then a division must be performed at each pixel {{of the projected}} surface in order to correctly calculate texture map coordinates. We show how a simple extension to perspective-comect texture mapping {{can be used to}} create various lighting effects, These include <b>arbitrary</b> <b>projection</b> of two-dimensional images onto geometry, realistic spotlights, and generation of shadows using shadow maps [10]. These effects are obtained in real time using hardware that performs correct texture mapping...|$|E
50|$|For <b>arbitrary</b> <b>projections,</b> {{neither the}} shape nor {{the area of}} the ellipses are related to each other in general.|$|R
40|$|Abstract – In {{this paper}} tomographic {{reconstruction}} {{based on the}} concept of ridge functions (Logan and Shepp) is considered. A reconstruction approach for the ridge functions from a finite number of <b>arbitrary</b> <b>projections</b> is suggested within the framework of parallel beam geometry. The method deals with images that can be presented as a sum of ridge functions. We derive a formula to calculate the ridge functions from the set of <b>arbitrary</b> <b>projections.</b> In the case of few projections an approach for detection of ridge functions with unknown directions is suggested. Results of numerical simulation are presented...|$|R
40|$|Tyt. z nagłówka. Bibliogr. s. 271. A {{steering}} <b>projection</b> of an <b>arbitrary</b> von Neumann algebra is introduced. It {{is shown}} that a steering projection always exists and is unique (up to Murray-von Neumann equivalence). A general decomposition of <b>arbitrary</b> <b>projections</b> {{with respect to a}} steering projection is established. Dostępny również w formie drukowanej. KEYWORDS: Murray-von Neumann order, central projection, steering projection...|$|R
40|$|We prove sharp upper bounds for sums of {{eigenvalues}} (and other spectral functionals) of Laplace-like operators, including bi-Laplacian and fractional Laplacian. We {{show that}} among linear {{images of a}} highly symmetric domain, our spectral functionals are maximal on the original domain. We exploit the symmetries of the domain, and the operator, avoiding necessity of finding good test functions for variational problems. This {{is especially important for}} fractional Laplacian, since exact solutions are not even known on intervals, making it hard to find good test functions. To achieve our goals we generalize tight $p$-fusion frames, to extract the best possible geometric results for domains with isometry groups admitting tight $p$-frames. Any such group generates a tight $p$-fusion frame via conjugation of <b>arbitrary</b> <b>projection</b> matrix. We show that generalized tight $p$-frames can also be obtained by conjugation of arbitrary rectangular matrix, with frame constant depending on the singular values of the matrix...|$|E
40|$|Associated {{with every}} {{projection}} ß : P ! ß(P) of a polytope P {{one has a}} partially ordered set of all "locally coherent strings": the families of proper faces of P that project to valid subdivisions of ß(P), partially ordered by the natural inclusion relation. The "Generalized Baues Conjecture" posed by Billera, Kapranov & Sturmfels [4] asked whether this partially ordered set always has the homotopy type of a sphere of dimension dim(P) Γ dim(ß(P)) Γ 1. We show that this is true in the cases when dim(ß(P)) = 1 (see [4]) and when dim(P) Γ dim(ß(P)) 2, but fails otherwise. For an explicit counterexample we produce a non-degenerate projection of a 5 -dimensional, simplicial, 2 -neighborly polytope P with 10 vertices and 42 facets to a hexagon ß(P) ` R 2. The construction of the counterexample is motivated by a geometric analysis {{of the relation between}} the fibers in an <b>arbitrary</b> <b>projection</b> of polytopes...|$|E
40|$|The quantum {{mechanical}} measurement {{problem is}} the difficulty {{of dealing with the}} indefiniteness of the pointer observable at the conclusion of a measurement process governed by unitary quantum dynamics. There has been hope to solve this problem by eliminating idealizations from the characterization of measurement. We state and prove two `insolubility theorems' that disappoint this hope. In both the initial state of the apparatus is taken to be mixed rather than pure, and the correlation of the object observable and the pointer observable is allowed to be imperfect. In the insolubility theorem for sharp observables, which is only a modest extension of previous results, the object observable is taken to be an <b>arbitrary</b> <b>projection</b> valued measure. In the insolubility theorem for unsharp observables, which is essentially new, the object observable is taken to be a positive operator v alued measure. Both theorems show that the measurement problem is not the consequence of neglecting the ever-present imperfections of actual measurements. Comment: plain TeX, 10 page...|$|E
40|$|We {{introduce}} {{an extension}} of the n-ary description logic DLR to deal with attribute-labelled tuples (generalising the positional notation), with <b>arbitrary</b> <b>projections</b> of relations (inclusion dependencies), generic functional dependencies and with global and local objectification (reifying relations or their projections). We show how a simple syntactic condition on the appearance of projections and functional dependencies in a knowledge base makes the language decidable without increasing the computational complexity of the basic DLR language...|$|R
50|$|In {{conformal}} maps, {{where each}} point preserves angles projected from the geometric model, the Tissot's indicatrices are all circles of size varying by location, possibly also with varying orientation (given the four circle quadrants split by meridians and parallels). In equal-area projections, where area proportions between objects are conserved, the Tissot's indicatrices {{all have the}} same area, though their shapes and orientations vary with location. In <b>arbitrary</b> <b>projections,</b> both area and shape vary across the map.|$|R
40|$|Abstract. We give a {{detailed}} account of the classical Van Kampen method for computing presentations of fundamental groups of complements of complex algebraic curves, and of a variant of this method, working with <b>arbitrary</b> <b>projections</b> (even with vertical asymptotes). Introduction In the 1930 ’s, Van Kampen described a general technique for computing presentations of fundamental groups of complements of complex algebraic curves. Though Van Kampen’s original approach was essentially valid, some technical details were not entirely clear and were later reformulated in more modern and rigorous term...|$|R
40|$|Abstract. This study {{describes}} 3 D X-ray laminography using {{a projection}} method for reconstruction of arbitrary cross-sectional images. The X-ray inspection images acquired {{from a single}} focal plane include information of the other focal planes as well. Hence projection images of the other focal planes {{can be obtained by}} the geometric projection method for arbitrary height and angle. This paper provides the reconstruction methods of arbitrary cross-sectional image for parallel and cone-beam X-ray and visualization of the object in three dimensions using 3 D laminography. 2 D <b>arbitrary</b> <b>projection</b> images for the other focal planes were obtained by deriving the geometric projection formulae for arbitrary height and angle images. After arbitrary cross-sectional images had been reconstructed by 2 D laminography using projection image sets of all focal planes, 3 D laminography was realized so that the object of ball grid array package was three-dimensionally visualized. For demonstrating 3 D NDT (Non-destruction testing) method, we developed laminography system with CMOS image sensor. Finally, it was shown by experimental results that 3 D laminography of object could be reconstructed correctly by the geometric projection method...|$|E
40|$|Abstract. The scalar {{curvature}} for the noncommutative four torus T 4 Θ, {{where its}} flat geometry is conformally perturbed by a Weyl factor, {{is computed by}} making {{the use of a}} noncommutative residue that involves integration over the 3 -sphere. This method is more convenient since it does not require the rearrangement lemma and it is advantageous as it explains the simplicity of the final functions of one and two variables, which describe the curvature {{with the help of a}} modular automorphism. In particular, it readily allows to write the function of two variables as the sum of a finite difference and a finite product of the one variable function. The curvature formula is simplified for dilatons of the form sp, where s is a real parameter and p ∈ C∞(T 4 Θ) is an <b>arbitrary</b> <b>projection,</b> and it is observed that, in contrast to the two dimensional case studied by A. Connes and H. Moscovici, unbounded functions of the parameter s appear in the final formula. An explicit formula for the gradient of the analo...|$|E
40|$|The {{image quality}} of cone-beam CT systems depends {{directly}} on the precise knowledge of position and orientation of the X-ray source and the detector. The current methods to determine this geometric information are mainly focused on conventional cone-beam CTs with planar or near-planar scanning trajectories. Due to the fixed alignment of X-ray source and detector, such systems have disadvantages in intraoperative use. Therefore, we develop a first prototype for cone-beam CT characterized by a free alignment of X-ray source and detector. This results in an open system allowing an intraoperative access to {{the patient and the}} implementation of non-planar scanning trajectories in the operating room. In this paper, we present a geometric calibration method to determine the position and orientation of X-ray source and detector for any <b>arbitrary</b> <b>projection.</b> Enhancing the theoretical method proposed in Mennessier et al. [1] by introducing an asymmetrical marker arrangement, we realized a calibration method suitable for practical use. We analyzed the resulting accuracy and applied our approach to the open cone-beam CT prototype...|$|E
40|$|We {{address the}} local {{spectral}} {{behavior of the}} random matrix Π_ 1 U^(⊗k) Π_ 2 U^(⊗k∗) Π_ 1 	 where U is a Haar distributed unitary matrix of size n × n, the factor k is at most c 0 lgn for a small constant c_ 0 > 0, and Π_ 1, Π_ 2 are <b>arbitrary</b> <b>projections</b> on ℓ^n^k_ 2 of ranks proportional to n^k. We prove that in this setting the k-fold Kronecker product behaves similarly to the well-studied case when k = 1...|$|R
40|$|Abstract. The {{development}} of a novel system for the generation and representation of haptic information in virtual reality is described. With this system the stiffness distribution of mechanically inhomogeneous objects can be detected and made perceivable for users at distant locations. The sensor part is based on ultrasonic elastography and the actuator part utilizes the ability of electrorheological fluids to change their consistency in electric fields reversibly. Two-dimensional elastographic images or <b>arbitrary</b> <b>projections</b> of threedimensional objects generated in the sensor part can principally be represented by the actuator part, which has a flat surface above a two-dimensional array of actuator elements with individually addressable stiffness. ...|$|R
40|$|We {{settle the}} {{computational}} complexity of fundamental {{questions related to}} multicriteria integer linear programs, when {{the dimensions of the}} strategy space and of the outcome space are considered fixed constants. In particular we construct: 1. polynomial-time algorithms to exactly determine the number of Pareto optima and Pareto strategies; 2. a polynomial-space polynomial-delay prescribed-order enumeration algorithm for <b>arbitrary</b> <b>projections</b> of the Pareto set; 3. a polynomial-time algorithm to minimize the distance of a Pareto optimum from a prescribed comparison point with respect to arbitrary polyhedral norms; 4. a fully polynomial-time approximation scheme for the problem of minimizing the distance of a Pareto optimum from a prescribed comparison point with respect to the Euclidean norm...|$|R
40|$|The scalar {{curvature}} for noncommutative four tori T^ 4 _Θ, {{where their}} flat geometries are conformally perturbed by a Weyl factor, {{is computed by}} making {{the use of a}} noncommutative residue that involves integration over the 3 -sphere. This method is more convenient since it does not require the rearrangement lemma and it is advantageous as it explains the simplicity of the final functions of one and two variables, which describe the curvature {{with the help of a}} modular automorphism. In particular, it readily allows to write the function of two variables as the sum of a finite difference and a finite product of the one variable function. The curvature formula is simplified for dilatons of the form sp, where s is a real parameter and p∈C∞(T^ 4 _Θ) is an <b>arbitrary</b> <b>projection,</b> and it is observed that, in contrast to the two dimensional case studied by Connes and Moscovici, J. Am. Math. Soc. 27 (3), 639 - 684 (2014), unbounded functions of the parameter s appear in the final formula. An explicit formula for the gradient of the analog of the Einstein-Hilbert action is also calculated...|$|E
40|$|Atom probe {{tomography}} is {{an accurate}} analytical and imaging technique which can reconstruct the complex structure and composition of a specimen in three dimensions. Despite providing locally high spatial resolution, atom probe tomography suffers from global distortions due to a complex projection function between the specimen and detector which is different for each experiment and can change during a single run. To aid characterization of this projection function, this work demonstrates a method for the reverse projection of ions from an <b>arbitrary</b> <b>projection</b> surface in 3 D space back to an atom probe tomography specimen surface. Experimental data from transmission electron microscopy tilt tomography are combined with point cloud surface reconstruction algorithms and finite element modelling to generate a mapping {{back to the original}} tip surface in a physically and experimentally motivated manner. As a case study, aluminium tips are imaged using transmission electron microscopy before and after atom probe tomography, and the specimen profiles used as input in surface reconstruction methods. This reconstruction method is a general procedure {{that can be used to}} generate mappings between a selected surface and a known tip shape using numerical solutions to the electrostatic equation, with quantitative solutions to the projection problem readily achievable in tens of minutes on a contemporary workstation...|$|E
40|$|Discrete {{tomography}} {{deals with}} the problem of reconstructing a an image, with a few number of different grey values, from its projections. In particular, there is a focus on highly underdetermined reconstruction problems for which many solutions may exist. In such cases, {{it is important to have}} a quality measure for the reconstruction with respect to the unknown original image. In this thesis, we derive a series of computable upper bounds that can be used to guarantee the quality of a reconstructed binary image. This technique can be used with <b>arbitrary</b> <b>projection</b> model, number of projections and direction. This technique is also valid for bounding the error on higher resolution binary reconstructions from low resolution scans. When studying the problem of generating error bounds for binary tomography, we obtained a sufficient condition for the existence of binary solutions for the reconstruction problem. This condition allowed us to create a feature detection technique which is independent of a particular recontruction. We also developed and experimented a discrete reconstruction algorithm which guarantees that the projections of the reconstructed discrete image are close to the given set of projections. Promotores: K. J. Batenburg, B. KorenWith Summary in DutchErasmus Mundus Programme and Leiden Universit...|$|E
40|$|This paper {{presents}} {{two approaches}} for the representation {{and recognition of}} human action in video, aiming for viewpoint invariance. The paper first presents new results using a 2 D approach presented earlier. Inherent limitations of the 2 D approach are discussed and a new 3 D approach that builds on recent work on 3 D model-based invariants, is presented. Each action is represented as a unique curve in a 3 D invariance-space, surrounded by an acceptance volume (‘action-volume’). Given a video sequence, 2 D quantities from the image are calculated and matched against candidate action volumes in a probabilistic framework. The theory is presented followed by results on <b>arbitrary</b> <b>projections</b> of motion-capture data which demonstrate {{a high degree of}} tolerance to viewpoint change. 1...|$|R
40|$|A novel {{system for}} the {{generation}} and representation of haptic information in virtual reality is described. With this system the stiffness distribution of mechanically inhomogeneous objects can be detected and made perceivable for users at distant locations. The sensor part is based on ultrasonic elastography and the actuator part utilizes the ability of electrorheological fluids to change their consistency in electric fields reversibly. Two-dimensional elastographic images or <b>arbitrary</b> <b>projections</b> of three-dimensional objects generated in the sensor part can be represented by the actuator part, which has a flat surface above a two-dimensional array of actuator elements with individually addressable stiffness. Due {{to the lack of}} established technologies, several innovative technological approaches have been introduced {{for the development of the}} haptic system. The haptic sensor-actuator system can serve as a technology platform for the subsequent development of new products in various fields of applications such as medicine, entertainment or education. 1...|$|R
40|$|Abstract—In the Cognitive Compressive Sensing (CCS) prob-lem, a Cognitive Receiver (CR) {{seeks to}} {{optimize}} the reward obtained by sensing an underlying N dimensional random vector, by collecting at most K <b>arbitrary</b> <b>projections</b> of it. The N components of the latent vector represent sub-channels states, that change dynamically from “busy ” to “idle ” and vice versa, as a Markov chain that is biased towards producing sparse vectors. To identify the optimal strategy we formulate the Multi-Armed Bandit Compressive Sensing (MAB-CS) problem, generalizing the popular Cognitive Spectrum Sensing model, in which the CR can sense K out of the N sub-channels, {{as well as the}} typical static setting of Compressive Sensing, in which the CR observes K linear combinations of the N dimensional sparse vector. The CR opportunistic choice of the sensing matrix should balance the desire of revealing the state of as many dimensions of the latent vector as possible, while not exceeding the limits beyond which the vector support is no longer uniquely identifiable. Index Terms—Opportunistic access, multi-channel sensing, cognitive radio, compressive sensing, myopic policy. I...|$|R
40|$|This thesis {{develops}} econometric {{methods for}} implementing data-based decisions. Decisions {{are viewed as}} functions of parameters which are estimated from the data. Standard methods focus on providing precise estimates of parameters ignoring intention to use them in decisions. My thesis focuses on designing methods to minimize the expected error in decision functions. The first chapter develops model averaging estimators in multiple regressions that minimize the mean squared error (MSE) of a chosen decision function. Our motivating example is implementing a portfolio choice rule that depends on variables included in assets' returns specification. We characterize the asymptotic MSE of decisions functions based on different models and then describe model-selection and averaging estimators that enable improvements in the MSE. The performance of our method is demonstrated with extensive simulations and empirical applications to futures data. The second chapter describes the risk improvements for a model averaging using two models. This type of averaging is known as shrinkage. Since the risk improvement is over the function of parameters, this shrinkage {{is referred to as}} focused shrinkage. The estimator is a weighted average between unrestricted and restricted models. The latter is a minimum distance estimator and requires selecting a projection matrix. The risk improvement of our shrinkage estimator over maximum-likelihood for <b>arbitrary</b> <b>projection</b> matrices is derived. I then show in an application to portfolio choice, that for a specific choice of projection matrix, this improvement can be substantial. The third chapter considers an application of the focused shrinkage estimator to the Global Minimum Variance (GMV) portfolio. Implementing the GMV portfolio requires estimating a covariance matrix and the literature has offered several estimators. Focused shrinkage is particularly suitable here because {{it can be used to}} directly minimize the MSE of the GMV portfolio. We illustrate the benefits of our estimator by conducting extensive simulations and empirical applications. </p...|$|E
40|$|In the Cognitive Compressive Sensing (CCS) problem, a Cognitive Receiver (CR) {{seeks to}} {{optimize}} the reward obtained by sensing an underlying $N$ dimensional random vector, by collecting at most $K$ <b>arbitrary</b> <b>projections</b> of it. The $N$ components of the latent vector represent sub-channels states, that change dynamically from "busy" to "idle" and vice versa, as a Markov chain that is biased towards producing sparse vectors. To identify the optimal strategy we formulate the Multi-Armed Bandit Compressive Sensing (MAB-CS) problem, generalizing the popular Cognitive Spectrum Sensing model, in which the CR can sense $K$ out of the $N$ sub-channels, {{as well as the}} typical static setting of Compressive Sensing, in which the CR observes $K$ linear combinations of the $N$ dimensional sparse vector. The CR opportunistic choice of the sensing matrix should balance the desire of revealing the state of as many dimensions of the latent vector as possible, while not exceeding the limits beyond which the vector support is no longer uniquely identifiable. Comment: 8 pages, 2 figure...|$|R
40|$|We study multivariate normal {{models that}} are {{described}} by linear {{constraints on the}} inverse of the covariance matrix. Maximum likelihood estimation for such models leads {{to the problem of}} maximizing the determinant function over a spectrahedron, and to the problem of characterizing the image of the positive definite cone under an <b>arbitrary</b> linear <b>projection.</b> These problems at the interface of statistics and optimization are here examined from the perspective of convex algebraic geometry...|$|R
40|$|In {{the context}} of an {{idealized}} model describing an atom coupled to black-body radiation at an arbitrarily small, but positive temperature, we show that the atom will end up being ionized in the limit of large times. Mathematically, this is translated into the statement that the coupled system does not have any time-translation invariant state of positive (asymptotic) temperature, and that the expectation value of an <b>arbitrary</b> finite-dimensional <b>projection</b> in an <b>arbitrary</b> initial state of positive (asymptotic) temperature tends to zero, as time tends to infinity...|$|R
40|$|We propose and {{evaluate}} a novel methodology {{to identify the}} rolling shutter parameters of a real camera. We also present {{a model for the}} geometric distortion introduced when a moving camera with a rolling shutter views a scene. Unlike previous work this model allows for arbitrary camera motion, including accelerations, is exact rather than a linearization and allows for <b>arbitrary</b> camera <b>projection</b> models, for example fisheye or panoramic. We show the significance of the errors introduced by a rolling shutter for typical robot vision problems such as structure from motion, visual odometry and pose estimation...|$|R
40|$|This paper {{presents}} {{a method for}} efficiently maintaining and searching a database of three-dimensional models {{so they can be}} reliable recognized from <b>arbitrary</b> two-dimensional <b>projections</b> in the presence of noise and occlusion. The core of the process is the topologically-defined network of invariants which breaks three-dimensional models down into small, local groups of features and indexes these groups using translation, rotation, scaling, and orthographic projection invariant functions. The network encodes the geometrical relationships between these groups so that grouping information can be used to increase the speed of matching...|$|R
40|$|The issues {{involved}} in the reconstruction of a quadratic curve in 3 -D space from <b>arbitrary</b> perspective <b>projections</b> are described in this paper. Correspondence between the projections of the curve on the image planes {{is assumed to be}} established. Equations for reconstruction of the 3 -D curve, which give the parameters of the 3 -D quadratic curve are determined. Uniqueness of the solution in the process of reconstruction is addressed and solved using additional constraints. As practical examples, reconstruction of circles, parabolas and pair of straight lines in 3 -D space are demonstrated. </p...|$|R
40|$|In {{preparation}} for the extraction of pseudoscalar meson photo-production amplitudes from {{a new generation of}} complete experiments, we assemble the relations between experimental observables and the Chew-Goldberger-Low-Nambu amplitudes. We present expressions that allow the direct calculation of matrix elements with <b>arbitrary</b> spin <b>projections</b> and uses these to clarify sign differences that exist in the literature. Comparing to the MAID and SAID analysis codes, we have found that the implied definitions of six double-polarization observables are the negative of what has been used in comparing to recent experimental data. Comment: 21 pages, 3 figures. Eq. (6) is correcte...|$|R
40|$|In {{this paper}} we {{introduce}} frames of submodules for countably generated Hilbert K(H) -modules. We show the correspondence between frames of submodules for a Hilbert K(H) -module V and frames of subspaces for the Hilbert space Ve ⊂ V, where e ∈ K(H) is an <b>arbitrary</b> orthogonal one-dimensional <b>projection.</b> We also establish a relation between their frame operators...|$|R
40|$|We {{discuss the}} {{analogue}} in the Brunn-Minkowski {{theory of the}} inequalities of Marcus-Lopes and Bergstrom about symmetric functions of positive reals and determinants of symmetric positive matrices respectively. We obtain a local version of the Aleksandrov-Fenchel inequality W W i 1 W i+ 1 which relates the quermassintegrals of a convex body K to those of an <b>arbitrary</b> hyperplane <b>projection</b> of K. A consequence is the following fact: for any convex body K, for any (n 1) -dimensional subspace E of R and any t > 0, jK + 2 tDn j where D denotes the Euclidean unit ball and j j denotes volume in the appropriate dimension. 1...|$|R
40|$|Exploratory {{analysis}} of data seeks to find common patterns to gain insights into the structure and distribution of the data. In geochemistry it is a valuable means to gain insights into the complicated processes making up a petroleum system. Typically linear visualisation methods like principal components analysis, linked plots, or brushing are used. These methods can not directly be employed when dealing with missing data and they struggle to capture global non-linear structures in the data, however they can do so locally. This thesis discusses a complementary approach based on a non-linear probabilistic model. The generative topographic mapping (GTM) enables the visualisation {{of the effects of}} very many variables on a single plot, which is able to incorporate more structure than a two dimensional principal components plot. The model can deal with uncertainty, missing data and allows for the exploration of the non-linear structure in the data. In this thesis a novel approach to initialise the GTM with <b>arbitrary</b> <b>projections</b> is developed. This makes it possible to combine GTM with algorithms like Isomap and fit complex non-linear structure like the Swiss-roll. Another novel extension is the incorporation of prior knowledge about the structure of the covariance matrix. This extension greatly enhances the modelling capabilities of the algorithm resulting in better fit to the data and better imputation capabilities for missing data. Additionally an extensive benchmark study of the missing data imputation capabilities of GTM is performed. Further a novel approach, based on missing data, will be introduced to benchmark the fit of probabilistic visualisation algorithms on unlabelled data. Finally the work is complemented by evaluating the algorithms on real-life datasets from geochemical projects. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|Fig. 1. The {{planetary}} nebula M 2 - 9 {{is a typical}} example of a bipolar nebula. Its quasi-symmetric twin lobes of ionized material emanate from a binary star system in its center. Assuming axial symmetry, our reconstruction algorithm uses a single input image (a) to produce a high-resolution 3 D visualization that closely resembles the original image when rendered from the same viewpoint (b). From a novel vantage point, the emission along the principal axis of the nebula accumulates and creates a luminous halo (c). As the vantage point approaches the symmetry axis, the received intensity further increases and the perceived shape of the nebula changes toward two entangled rings (d). The resolution of the reconstructed volume is 512 3 voxels. Original image: Bruce Balick (University of Washington), Vincent Icke (Leiden University, The Netherlands), Garrelt Mellema (Stockholm University), and NASA. Abstract—The 3 D visualization of astronomical nebulae is a challenging problem since only a single 2 D projection is observable from our fixed vantage point on Earth. We attempt to generate plausible and realistic looking volumetric visualizations via a tomographic approach that exploits the spherical or axial symmetry prevalent in some relevant types of nebulae. Different types of symmetry can be implemented by using different randomized distributions of virtual cameras. Our approach {{is based on an}} iterative compressed sensing reconstruction algorithm that we extend with support for position-dependent volumetric regularization and linear equality constraints. We present a distributed multi-GPU implementation that is capable of reconstructing high-resolution datasets from <b>arbitrary</b> <b>projections.</b> Its robustness and scalability are demonstrated for astronomical imagery from the Hubble Space Telescope. The resulting volumetric data is visualized using direct volume rendering. Compared to previous approaches, our method preserves a muc...|$|R
