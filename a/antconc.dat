93|0|Public
5000|$|<b>AntConc</b> - corpus {{analysis}} toolkit for concordancing {{and text}} analysis ...|$|E
40|$|<b>AntConc</b> (Anthony 2012) besides WordSmith, since <b>AntConc</b> {{performs}} most {{functions as}} WordSmith does, and more importantly, it is a freeware {{rather than a}} commercial software as WordSmith is. For all the foregoing critical comments, the book under review is of particular value to postgraduate students in applied linguistics and ELT instructors {{who would like to}} explore the use of corpus in their teaching practice. The book is also highly recommended to researchers who are new to corpus linguistics. Not...|$|E
40|$|This paper {{describes}} {{the development of}} the <b>AntConc</b> corpus analysis toolkit, originally designed for use in a technical writing course at Osaka University, Japan, but now adopted in institutions throughout the world as an easy-to-use, freeware, multiplatform alternative to the many commercial concordance programs. First, I will explain how the software was originally tailored to the needs of students in the Osaka writing course and later to a general audience through the requests and feedback from teachers and students around the world. Then, I will give an overview of tools in the most recent version of <b>AntConc</b> and explain their value using examples from the classroom. Finally, I will discuss some of the software's limitations and future developments, and suggest applications in professional communicatio...|$|E
40|$|AbstractOur study {{presents}} an on-going project on corpus linguistics {{held at the}} University of Cádiz (UCA) which tries to identify discourse proficiency of B 1, B 2 and C 1 CEFR levels in the CLEC (CEFR-Labeled English Corpus) with a corpus-based quantitative and qualitative approach. The CLEC is a corpus of CEFR-labeled texts developed using CEFR-labeled teaching materials. The softwares <b>AntConc,</b> TagAnt and USAS {{have been used to}} analyze data...|$|E
40|$|Abstract—This paper {{describes}} {{the development of}} the <b>AntConc</b> corpus analysis toolkit, originally designed for use in a technical writing course at Osaka University, Japan, but now adopted in institutions throughout the world as an easy-to-use, freeware, multiplatform alternative to the many commercial concordance programs. First, I will explain how the software was originally tailored to the needs of students in the Osaka writing course and later to a general audience through the requests and feedback from teachers and students around the world. Then, I will give an overview of tools in the most recent version of <b>AntConc</b> and explain their value using examples from the classroom. Finally, I will discuss some of the software’s limitations and future developments, and suggest applications in professional communication. Index Terms—Corpus linguistics, educational technology, software, technical writing. Since the early 1990 s, corpora have played an increasingly important role in determining how languages are taught [1]. As Chapelle describes, {{there appears to be a}} “corpus revolution ” under way [2, p. 38]. Corpora are now being applied in a wide range of areas, including translation studies, stylistics...|$|E
40|$|<b>AntConc</b> is a freeware, multi-platform, {{multi-purpose}} corpus analysis toolkit, {{designed specifically}} {{for use in the}} classroom. It hosts a comprehensive set of tools including a powerful concordancer, word and keyword frequency generators, tools for cluster and lexical bundle analysis, and a word distribution plot. In this paper, I will describe each of these tools, and explain their value to learners. Then, I will discuss the current limitations of the software, before explaining how I hope it will be improved in future releases...|$|E
40|$|AbstractLexical bundles {{defined as}} {{recurrent}} sequences of words are considered as important {{building blocks of}} written and spoken academic discourse. This study investigated the use of four-word lexical bundles in introduction section of published research articles in medicine. For identifying lexical bundles, a number of computer softwares such as <b>Antconc</b> 3. 2. 3, and WordSmith Tools 5 were used. The {{results of the study}} showed that 161 lexical bundles differ structurally and most of the writers of medical research articles rely on noun phrases and phrasal bundles for establishing their written academic discourse...|$|E
40|$|This paper {{discusses}} three researches involving Corpus Linguistics and Terminology German/Portuguese using program <b>AntConc.</b> The first {{aimed to}} extract terms related to Economics in German electronic newspapers. The {{second and third}} aimed to extract terms related to the Indian material culture in works by Koch-Grünberg; the purpose: compile a bilingual glossary.   The first and second researches, using tools Word List, Concordance, and File View, shortly allowed extraction of large number of terms, whose frequency was reliably established. The third, in initial phase, {{will allow us to}} enlarge the results produced with the second, presently with 257 terms and their translation...|$|E
40|$|The {{main goal}} of the methodologicaltext is to {{characterize}} the multidisciplinary appliedinductive analysis of large textual corporawith the stress on metaphor analysis. Metaphorscould serve two purposes in the text: (1) conceptualizationof the discussed issue and (2) persuasiveoffering of the specific metaphors that shouldhelp the recipients to understand the issue in thedesired way {{as well as to}} put aside the alternativemetaphors and interpretations. In this regard,metaphor analysis is a suitable instrument forthe interpretation of public, political, and mediadiscourses, especially {{in the context of the}} socalledsocial problems. We offer an analyticalmethodologicalapproach based on corpus analysisand implemention of the computer software(MAXQDA and <b>Antconc),</b> and apply it to thehomelessness issue...|$|E
40|$|Terdapat banyak kajian yang telah meneliti pemaparan media tentang pelarian di negara tuan rumah. Namun begitu, tidak banyak kajian yang memberikan perhatian kepada pemaparan ini di negara bukan tuan rumah. Kajian ini memanfaatkan teori kategori sosial wacana oleh Van Leeuwen (2008) khasnya “role allocation”, “genericisation dan specification”, “assimilation”, “association”, “indetermination”, dan “identification” serta metafora konsepsi saranan Lakoff dan Johnson (2003) untuk mengkaji pemaparan media tentang pelarian Syria di negara tuan rumah dan di negara bukan tuan rumah. Linguistik korpus diguna pakai untuk memastikan hasil kajian ini menyeluruh, sah dan saksama. Korpora kajian ini mengandungi 3082130 perkataan. Program Anthony <b>AntConc</b> (versi 3. 2. 4) digunakan untuk menganalisis korpora ini. Untuk menghitung signifikan statistik pula, Ujian Ketepatan Fisher (Fisher Exact Test) dimanfaatkan. There is a {{substantial}} body of research that has examined the media representation of refugees in their host countries. However, scant {{attention has been paid}} to their depiction in the media discourse of non-host countries. This study uses Van Leeuwen‟s (2008) sociological categories of discourse, namely role allocation, genericisation and specification, assimilation, association, indetermination, and identification, as well as Lakoff and Johnson‟s (2003) conceptual metaphor theory to examine the representation of Syrian refugees in the online media news reports of both their host and non-host countries. Corpus linguistics is used to ensure that the results are generalizable, valid, and impartial. The two corpora of this research consist of 3082130 words. Anthony‟s <b>AntConc</b> programme (version 3. 2. 4) was used to analyse the corpora. To calculate the statistical significance in comparing both corpora, Fisher‟s exact test is used...|$|E
40|$|Making a Tibetan Speech Corpus" [...] སྐད་ཕུང་སྒྲུབ་སྟངས་ཀྱི་ལག་དེབ། [...] is a beginner’s {{guide and}} {{training}} manual for collecting & transcribing natural speech data. While {{it was written}} specifically with the Tibetan language in mind, the principles within are generally applicable. The first chapter introduces linguistics, corpora, and practical applications (like education, readability, and plain language); it then describes the step-by-step of how to record and transcribe speech data. Tutorials on using Audacity and SayMore for audio splitting and transcription are presented, followed by guidelines, forms, and other proposed standards. Finally, {{with an eye toward}} the future of Tibetan corpus applications, links and descriptions of corpus analysis, visualization, lexical, and translation tools (Voyant, <b>AntConc,</b> SketchEngine, & SmartCAT) are briefly introduced [...] ...|$|E
40|$|Article of the HDSKD Journal, vol 02 issue 02, 2016. Abstract— This work compares firstly, the {{differences}} that occur in “The Mystery of Edwin Drood” which was written by two different authors, Garfield and Dickens. And, secondly, {{the differences}} of the original text of the Quran and a translated version of it by Abdullah Yusuf Ali. In translation there are differences which occur {{in the frequency of}} the prophets’ names. Thus, this work seeks to find the occurrences of Moses and Jesus in the Arabic text and compare them to the translated text. Both of the goals in this project are achieved using <b>Antconc</b> and Aconcord, tools provided with many features that help the computation of words frequencies...|$|E
40|$|AbstractThis action research, {{conducted}} at Istanbul Sehir University, {{was designed to}} find out how students can be autonomous learners if they are given a chance outside the classroom to reflect on their learning process via keeping a learning journal. The questions of the study were “How do students perceive the role of the teacher? “How do they perceive the role of themselves?” and “Is it possible to make them more autonomous learners?” The participants of the study were 20 high school graduates, who recently started their university degree programs. They were asked to keep a learning journal on daily basis. At the completion of the module (seven weeks), the journals were collected and the entries were analyzed. A concordance program- <b>Antconc,</b> was used for text analysis...|$|E
40|$|As Verb-Particle Constructions (VPCs) s??o constru????es verbais caracter??sticas da l??ngua inglesa constitu??das por um verbo e uma ou duas part??culas. Tais estruturas s??o sint??tica e semanticamente complexas, uma vez que n??o se enquadram em regras l??gicas e homog??neas. Esta pesquisa visa fazer uma reflex??o sobre a sem??ntica das part??culas nas VPCs apoiada em conceitos te??ricos da Gram??tica Cognitiva e da Ling????stica Cognitiva. A contribui????o sem??ntica das part??culas away, out e over ?? discutida valendo-se de esquemas imag??ticos que permitem fazer rela????es entre os diferentes significados das part??culas encontrados nas VPCs selecionadas para a an??lise. Atrav??s das ferramentas da Ling????stica de Corpus, mais especificamente um concordanciador gratuito chamado <b>AntConc</b> 3. 2. 1 w, foram selecionadas para a an??lise as cinco VPCs mais freq??entes do American National Corpus com cada part??cula. Como resultado, percebeu-se que as part??culas contribuem em diferentes graus para o significado total das VPCs, podendo apresentar sVerb-Particle Constructions (VPCs) are verbal constructions {{typical of}} the English {{language}} formed by a verb {{and one or two}} particles. Such structures are syntactically and semantically complex {{due to the fact that}} they do not fit into logical and homogeneous rules. This research aims at examining the semantics of particles in VPCs within the framework of Cognitive Grammar and Cognitive Linguistics. The discussion of the semantic contribution of the particles away, out and ???over??? is grounded in image schemas which allow establishing relations among the different meanings of particles found in the VPCs selected for the analysis. By using Corpus Linguistics tools, namely a concordancer called <b>AntConc</b> 3. 2. 1 w, the five most frequent VPCs with each particle in the American National Corpus were selected for the analysis. The results showed that the particles contribute to the overall meaning of VPCs in different degrees, with more and less metaphorical sense...|$|E
40|$|URL] paper {{analyses}} participants ‘você’ and ‘you’ in {{the short}} story ‘Days of wine and roses’ (‘Dias de vinho e rosas’), originally written in Brazilian Portuguese by Silviano Santiago, and its translation into English by a student translator. It aims to investigate some features of the linguistic systems involved {{from the perspective of}} the experiential component of the ideational metafunction (Halliday & Matthiessen, 2004). The participants were annotated and their tags were used on <b>AntConc</b> to obtain data quantification. Results show that these participants are realised in five types of ideational clauses, being the material, mental, and verbal clauses the more frequent ones. It is concluded that these participants are realised more often functioning as Logical Subjects with respect to the various ideational meanings, which points to their configuration as doers of action...|$|E
40|$|After the {{dissemination}} of Luis de Góngora’s Fábula de Polifemo y Galatea in 1613, a number of Spanish poets expanded the treatment of myths and established a dialogue with Ovid’s Metamorphoses. As {{a result of this}} process, a great amount of short epic poems was composed in the following years. This article aims to achieve three objectives: firstly, to describe in quantitative terms a corpus of 25 epyllia written by poets such as Luis de Góngora, Lope de Vega, Francisco de Quevedo, Juan de Jáuregui and Villamediana, among others. Secondly, the texts are classified using the Stylo package, which takes into account the most frequent words in an attempt to verify the traditional division between “dark” poets and “light” poets. Finally, the lexicon of these works is analyzed taking into consideration the keywords generated with <b>AntConc,</b> and the relative frequency of learned borrowings obtained using R...|$|E
40|$|Writing {{traditions of}} {{different}} disciplines of study are linguistically uniquely ritualized {{in the way}} writers present their arguments. Claims in other subjects are strengthened by showing commitment through boosting devices while other subjects recommending detached way of writing through hedging. The present study was undertaken to investigate the culture of writing in literature subject by analyzing dissertation abstracts of PhD candidates in the field using Hyland’s (2005) metadiscourse taxonomy. Sixty abstracts, from 2007 to 2012, were selected and analysed using <b>AntConc</b> concordance tool supplemented by manual analysis. The study discovers that literature PhD candidates hedge three times more than they use boosters favoring the use of low commitment modal auxiliary can and solidarity phrases. They boost only when they are convinced that their claims share some universal understanding. The study recommends that lessons on hedging and boosting need {{to be included in}} the research writing subjects of novice writers for them to be more conversant with the conventions of research writing that strictly obeys the required formality...|$|E
40|$|The aim of {{the study}} is to carry out a {{comparative}} corpus driven stylistic analysis of modal verbs in Pakistani and British English fictions. For this purpose, corpora of Pakistani English fiction (PEF) and British English fiction (BEF), consisting of one million words each has been compiled. POS tagging has been done on both the corpora, using software CLAWS tag set C 7. With the help of software <b>Antconc</b> 3. 2. 4, concordance lines of the tagged data have been manually explored for detailed study of modal verbs. The research is important as it helps to identify various insights that have been conveyed through the use of modal verbs in PEF and BEF. The study also assists in the stylistic interpretation of other word classes. This research has opened new horizons for the future researcher. It is also helpful for the teachers as well as the students of literature to {{have a better understanding of}} literature...|$|E
40|$|The {{investigation}} of specific features of Irish English {{has a long}} tradition. Yet, {{with the arrival of}} large corpora and corpus tools, new avenues of research have opened up for the discipline. The present paper investigates features commonly ascribed to Irish English {{on the basis of the}} ICE Ireland corpus in comparison with ICE corpora representing other varieties of English. We use several corpus tools to access the ICE corpora. First, an offline concordance program, <b>AntConc</b> V 3. 3 (Anthony 2004). Second, Corpus Navigator, an online corpus query tool allowing researchers to query regular expressions on the surface texts. Third, we are in the process of writing a version of Dependency Bank (Lehmann and Schneider 2012) which contains a selection of ICE corpora, and which will be called ICE online. This research methodology allows us to reassess how specific features found in Irish English are in comparison with other international varieties of English and illustrates that even simple corpus-based search patterns can produce powerful results...|$|E
40|$|Research on how {{jazz musicians}} improvise {{suggests}} that learned patterns or “licks” inserted during improvisations are ubiquitous, especially among those playing bebop. Analysis of saxophonist Charlie Parker’s solos reveals his reliance on distinct patterns {{that he often}} repeated multiple times in a single solo. Due to Parker 2 ̆ 7 s iconic status as a bebop progenitor and his influence on the dissemination of mainstream bebop vocabulary, one can argue that bebop improvisation {{is dependent on the}} use of licks and that they are fundamental to bebop syntax and vocabulary. This claim is supported by a myriad of improvisation manuals advocating the practice of licks as integral to the acquisition and development of bebop vocabulary. ^ Saxophonists Lee Konitz and Warne Marsh were both contemporaries of Parker who matured as improvisers under the direction of teacher Lennie Tristano. Though he and his students revered Parker, Tristano’s pedagogical method rejected the imitation of other bebop improvisers by specifically avoiding the inclusion of licks, thus encouraging more melodic spontaneity. The results of Tristano 2 ̆ 7 s method are exemplified by the work of Konitz and Marsh during the late 1940 s and early 1950 s. ^ This paper addresses the relative merits of these two approaches to bebop by investigating the stylistic differences between Parker and Tristano’s students Konitz and Marsh. Chapter 1 discusses Parker 2 ̆ 7 s approach to improvisation, specifically his use of licks, and his influence on mainstream jazz pedagogy. Chapter 2 outlines Tristano 2 ̆ 7 s pedagogical method and discusses the differences between his approach and the mainstream approach to teaching bebop. Chapter 3 explores the cognitive and neurological necessity of using licks in bebop, and discusses current music cognition literature and fMRI studies conducted on improvisers. Chapter 4 presents an analysis of licks by Parker, Konitz, and Marsh, and their effect on improvisational outcomes. As there is a rhetorical quality to jazz improvisation, linguistic concordance software called <b>AntConc</b> was used to locate patterns in the transcriptions. <b>AntConc</b> analysis reveals a greater volume and frequency of patterns in the playing of Parker than in the playing of Konitz and Marsh. ...|$|E
40|$|The {{following}} {{study is}} part of a work in progress on the dissemination of mental health care with a special focus on language barriers. It is an attempt to answer the following research question: How does the EU legislation contribute to the implementation of policies and plans towards passing laws that place them in the context of internationally accepted human rights standards and good practices? The investigation is a quantitative-qualitative analysis of the text types ad hoc collected from the Health-EU Portal (ec. europa. eu › [...] . › Health Problems) and is supported by <b>AntConc</b> software 3. 2. The study {{is based on the assumption}} of the important role of effective communication in contexts of institutional public services to avoid miscommunication, intercultural conflicts and social exclusion and aiming at the accessibility for people despite their geographical, social or other differences to overcome cultural and language barriers. The findings have revealed a type of communication: - goal-oriented (medium/high level target audience) and 		 - use of lexical items from specialised (legal and corporate) and lack of information accessible to common people, specifically patients...|$|E
40|$|Prihantoro Universitas Diponegoro prihantoro 2001 @yahoo. com, prihantoro@undip. ac. id Abstract One of the {{fundamental}} issues in corpus processing begins with how the corpus processing tools can recognize {{the characters in the}} documents. This issue is considered trivial for romanized languages, which adopt the same writing system as English (such as Indonesian). While most corpus processing tools are designed to process English, or the romanized version of the documents, tools to handle languages with their own writing systems needs to be built. Consider Korean, a language with syllable block writing system, or Arabic, a language with consonant skeleton writing system. The organization of the characters in these languages is not completely concatenative like English. The description of the writing system in these languages must underlie the design of the tools. Character recognition issue can be solved and much more complex processing tasks can be performed. This paper will demonstrate <b>AntConc,</b> Geuljabi and Unitex and show how these tools recognize characters in these languages. Keywords: Corpus Processing Tools, writing system, character recognition, automatic retrieval...|$|E
40|$|Small bilingual text corpora from {{a source}} and target {{language}} can be important sources of specialized language tracking for translators. A corpus platform can supplement or replace traditional reference works such as dictionaries and encyclopedia, which are rarely sufficient for the professional translator who has to get a cross-linguistic overview of a new area or {{a new line of}} business.   Relevant internet texts can be compiled ‘on the fly’, but internet data needs to be sorted and analyzed for rational use.   Today, such sorting and analysis can be made by a low-tech, analytical software tool.   This article demonstrates how strategic steps of compiling and retrieving linguistic data by means of specific search strategies {{can be used to make}} electronic corpora an efficient tool in translators’ daily work with fields that involve new terminology, but where the skills requested to work correspond to being able to perform an advanced Google search. We show the different steps in setting up and working with an ad-hoc corpus, illustrated by means of the software <b>AntConc</b> applied on the SEO area. </p...|$|E
40|$|Abstract—The {{present study}} is a corpus-based study which aims to {{investigate}} the occurrence of salient first language (Chinese 1) features found in learners ’ second language (English) written productions. <b>AntConc</b> (version 3. 2. 4) was adopted to analyze the learners ’ written data and to establish various categories of preposition misuses and L 1 features. Tango 2 was employed to provide suggestions for correction. Essentially, findings demonstrate that EFL learners may unconsciously produce L 2 writings with L 1 characteristics in their sentence productions. Results showed that the ten most frequently misused prepositions were by, at, in, to, for, on, about, of, with, and as. According to the results, it is suggested that, in regard to writing, teachers and educators can teach the use of prepositions through collocations to facilitate learners ’ knowledge and understanding for different prepositions through different contexts. The significance {{of the study is}} to raise learners ’ awareness as well as to provide reference for instruction for language teachers and educators. Index Terms—first language (L 1) transfer, preposition, interlanguage, written production I...|$|E
40|$|AbstractThe {{aim of the}} {{experimental}} work is statistical analysis of the novels by observing the frequency of letters, words, and n-grams of four books: two books by Dino Buzzati a) The Tartar steppe (Il deserto dei Tartari) and b) The Colomber (Il colombre); and two books by Oscar Wilde a) The portrait of Dorian Gray and b) The ballad of Reading Gaol. Books have been received in the original versions written by its authors and their respective English – Italian translations and vice versa. For statistical analysis are used two programs: Firstly, it is a program built by us which analyzes the text in English and Italian {{and at the end}} gives the frequency of each of the letters; Secondly, it is used <b>antconc,</b> a concordance and n-grams program. Such analysis can lead us to the identification of any logical fact or not (a-logical) fact between connections that might have the basic material and its translation, in Literature knowledge and inter cultural communication; which is a fundamental key of today's society relationships...|$|E
40|$|I {{dedicated}} in {{my thesis}} {{on the system}} of Spanish terminative verbal periphrases {{and at the same}} time to explore its potential equivalents in Czech. Because of the fact, that we move on the field of the caracter of verbal action, I found it necessary to make clear that we know, what does the term caracter of verbal action and terminativity mean. In the theoretical part of my work I deal with each terminative periphrase, the division of them according to several types of terminativity, and I describe its characteristics. I also deal with the situation in Czech, I try to match possibilities of creating equivalents to these spanish periphrases. In the practical part, I tried to analyse chosen periphrases in monolingual corpus CREA, I also used another corpus programme <b>AntConc</b> to the analysis. Then I analysed the Czech equivalents of these periphrases using the paralel corpus InterCorp. I hope I managed to make a vision of the system of Spanish terminative verbal periphrases and of the possibilities of their translation to Czech...|$|E
40|$|Corpus {{investigation}} {{in the field of}} Applied Linguistics has revolutionized the study of written and spoken language to inform pedagogical approaches of language; however, there are few corpus linguistic studies investigating the use of language and sentence structure in short story literature. To address this gap, the present study will explore words, phrases, voice, and slang in order to investigate rhetorical functions within the framework of short story writing. I compiled a small corpus of fourteen fiction and non-fiction short stories from ten authors. Using a software program, <b>AntConc,</b> to investigate this Short Story Corpus, patterns of frequently used words and phrases will be identified, as well as reveal co-occurring words and grammatical structures. This study will investigate the use of voice in first-person and third-person narration and explore how the use of voice affects other features of sentence structure. Additionally, this study will show how words, phrases, and voice are used as rhetorical tools that serve nuances of the short story genre: summary, backstory, rising action, climax, penultimate, denouement, and resolution...|$|E
40|$|This study {{aimed to}} {{investigate}} gender representation in an English textbook series used in Hong Kong schools. The corpus software <b>AntConc</b> {{was used to}} analyse the collocations of gendered terms He/he, She/she, Man/man, Woman/woman, women, Boy/boy, Boys/boys, Girl, and Girls/girls in the textbook series {{in order to find}} out if gender stereotyping, which was a problem in previous studies (e. g., Cincotta, 1978; Sakita, 1995), is still an issue. The results of the study showed that females were no longer regarded as delicate or weak but stronger than males. In occupational roles, females were no longer portrayed only as housewives in the family, but they also worked in society. On the other hand, the stereotyped images of males wearing shorts, jeans or shirts and females putting on skirts or dresses still exist. In addition, while {{it was found that the}} male terms have more collocates and both males and females were imbued with positive characteristics, negative adjectives were only used to describe males and males were never described in terms of their physical attractiveness...|$|E
40|$|This paper systematizes {{the results}} {{found in an}} {{exploratory}} study about relative clauses found in an informationally tagged, balanced sample extracted from the C-ORAL-BRASIL corpus. The data selection focused on the identification of utterances which contain relative clauses which was carried through the DB-IPIC platform (Panunzi & Gregori, 2011). The sorting out of relative clauses {{was done with the}} <b>AntConc</b> computational toolset (Anthony, 2013). In order to verify the informational structure of the chosen utterances, the WinPitch software was employed (Martin, 2004). The results found: (i) prosodically corroborate the differences between restrictive and non-restrictive relative clauses, whereby the former occur as linearized structures within one informational unit, whereas the latter are patterned through more than one informational unit; and (ii) demonstrate that in Brazilian Portuguese, both relative clause types prefer the Comment information unit as their default carrier. The paper also presents a description of relative clauses through a diagrammatic representation model that allows showing the relationship between main and relative clause, as well as informational structure within an utterance that stands for the realization scope of relative clauses...|$|E
40|$|This paper aims {{to employ}} {{one of the}} corpus stylistic methods to analyze Thomas Harris's novel, The Silence of the Lambs. Recently, {{technology}} has invaded our lives. To put it differently, researchers depend highly on computers to access and gain information about certain data. Thus, {{it is crucial to}} keep up with the up-to-date developments concerning computational methodologies and toolkits. Corpus stylistics helps to find certain features that cannot be understood without using the techniques of computers. In order to achieve this goal, a quantitative and qualitative methodology is applied. Corpus stylistics helps to analyze lengthy texts more efficiently. This is not to say that it substitutes the manual stylistic one. In fact, both the corpus and manual stylistic analyses work hand in glove, and they complement each other. The tool that is used to conduct the analysis by examining keywords and key semantic domains is Wmatrix 3. In addition to the previous tool, <b>AntConc</b> is a complementary tool to investigate n- grams in the novel and to point out their significance to the overall interpretation...|$|E
40|$|This article {{deals with}} the problem of intercultural {{business}} communication between Spaniards and Russians and aims at identifying the possible points of misunderstanding between the representatives of the two countries at the moment of introducing their companies, and designing a set of strategies to avoid them. It compares the Spanish and the Russian cultures through the contrast of the linguistic patterns used by Spaniards and Russians to introduce business companies on their official websites. Geert Hofstede’s five value dimension model (2001 / 1980) has been taken as a basis for the analysis, and the two cultures have been compared in five aspects: individualism index, power distance index, masculinity index, uncertainty avoidance index, and long-term orientation index. For the purposes of the study two corpora were created which consisted of 30 web presentations of Spanish and Russian companies respectively: 10 belonged to travel agencies, 10 to real estate agencies, and 10 to food companies. The analysis was done {{with the help of the}} concordance programme <b>AntConc</b> 3. 2. 4 w and SPSS Statistics Software Package version 20. 0. 0...|$|E
40|$|The aim of {{this study}} was to {{investigate}} the discourse markers used by 104 elementary-level prep class students studying at Namık Kemal University in Turkey. Students were required to write a paragraph with 80 - 100 words as part of their mid-term exam in the academic year of 2013 - 2014. A small-size corpus was constructed by using these writings. The corpus was analyzed via a software program called as <b>AntConc</b> 3. 2. 4. in order to find out the types and frequency of discourse markers. It was revealed that 180 discourse markers were used by elementary-level students: ‘and’ was used 98 times, but occurred 51 times, ‘because’ was written 18 times and other discourse markers of ‘then’, ‘so’, ‘also’, ‘too’ and ‘still’ were used 7, 2, 2, 1, 1 times respectively. Furthermore, according to Fraser’s (1999) taxonomy of discourse markers, 180 discourse markers were grouped into four categories. It was found out that 101 markers were elaborative markers, 52 were contrastive markers, 18 were causative markers and 9 were inferential markers...|$|E
40|$|The {{present study}} aims at {{discussing}} {{the use of}} the Old English ÆFTER in the glosses to the Lindisfarne Gospels, in order to establish patterns of equivalence between the OE gloss and an array of Latin source terms it renders. We are particularly interested in examining the consistency of such glossing, which would allow us to demonstrate the basic and peripheral senses of ÆFTER as well as its synonyms used in the collection. In an attempt to provide ground for a wider discussion of possible patterns in Old English gloss translation, the study compares the Aldredian employment of æfter and its forms with their use in the Rushworth Gospels, reportedly based on the Lindisfarne collection. The data for the present study come from the Dictionary of Old English Corpus (henceforth DOEC), analyzed with <b>AntConc,</b> a corpus analysis toolkit developed by Laurence Anthony. The findings are further supplemented with a close analysis of the editions by Skeat (1970), as well as the digitalized manuscript of the Lindisfarne Gospels available at Turning The Pages™, British Library. Anna Wojty...|$|E
40|$|The {{present study}} explores the politeness {{strategies}} used in Pakistani business letters written in English. It benefits from {{qualitative and quantitative}} approach of research. The specialized corpus has been compiled on business correspondence and named ‘Pakistani Business English Letters ’ (PBEL). PBEL consists of 1000 Pakistani business English letters collected from government and semi-government institutes e. g. banks, universities, private companies, factories etc in 2011. This study investigates the differences between Pakistani and American ways of using politeness strategies in external parts of business letters e. g. Opening and Closing of the letter. The Brown and Levinson (1987) model of politeness strategies has been adapted according to PBEL instances. The software <b>ANTCONC</b> 3. 2. 4 {{has been used as}} research tool in this study to calculate the frequent politeness strategies used within Pakistani Business English letters. This study is very insightful for teachers and learners regarding the usage of politeness strategies in business communication. It will also lend a helping hand to the textbook writers as it will acquaints them with the differences of using politeness strategies for intra-national and international business communication...|$|E
40|$|Internet {{usage of}} {{language}} (e. g., on Facebook, Reddit, 4 chan) {{has become an}} important means of communication, but research involving an analysis of large collections of internet-sourced text is limited. This project seeks to examine how the unique characteristics of internet language use create a register distinct from in-person conversation. This question will be examined {{through the use of}} a large collection of texts (currently 13, 523 words) pulled from online discussions from sites with different rules, levels of anonymity, and communities. These texts will be analyzed using <b>AntConc,</b> a program designed for the analysis of large collections of text (corpora). Lists of the most frequently occurring words, lists of frequently co-occurring words, and other tools will be used to determine linguistic characteristics of this register. Although not complete, a preliminary analysis of the corpus shows the presence of vulgar words is in a positive correlation with the level of anonymity of the site. This project will be useful in characterizing a register of language that is widely used. It also may shed light on how anonymity and membership in online communities impacts language choice...|$|E
40|$|Citing {{previous}} works {{is an important}} rhetorical feature of academic writing and it is challenging for novice writers, especially non-native English writers (NNEWs). However, {{little is known about}} how NNEWs cite in each chapter of their master’s (M. A.) theses. This paper thus reports on the citation practice in 24 TESOL M. A. theses written by Vietnamese students. Citation types were first searched on the <b>Antconc</b> software {{with the use of the}} Regular Expressions (Regex) written for both conventional and ‘invented’ citing ways by this group of writers, and then based on Thompson and Tribble’s (2001) framework, citation functions were investigated and classified. Semi-structured interviews were also conducted with thesis writers and thesis supervisors. Besides the general citation practice by this group of NNEWs, and the different citation functions and types in different chapters of their theses, the study also found that these writers were not fully aware of the significance of citations as a rhetorical device in their thesis writing, and insufficient attention was paid to the in-text citations in the TESOL discourse community in Vietnam. These findings suggest explicit instructions on citations in order to help novice writers to fully acquire the citation use...|$|E
