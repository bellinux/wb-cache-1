0|10000|Public
40|$|In {{this paper}} we propose a novel {{approach}} to HEp- 2 cell segmentation based on the framework of verification-based multithreshold probing. Cell hypotheses are generated by binarization using hypothetic thresholds and accepted/rejected by <b>a</b> <b>verification</b> <b>procedure.</b> The proposed method has the nice property of combining both adaptive local thresholding and involvement of high-level knowledge. We have realized a prototype implementation using <b>a</b> simple rule-based <b>verification</b> <b>procedure.</b> Experimental evaluation has been performed on two public databases. It is shown that our approach outperforms a number of existing methods...|$|R
5000|$|Each {{identified}} {{cluster is}} then subject to <b>a</b> <b>verification</b> <b>procedure</b> in which <b>a</b> linear least squares solution is performed for {{the parameters of}} the affine transformation relating the model to the image. The affine transformation of a model point yT to an image point vT can be written as below ...|$|R
40|$|Improvement of {{positioning}} accuracy {{is necessary for}} advanced robotic applications. The results and the procedure for model parameter identification of robots is presented. As measuring device an automatic theodolite system is used. Identification of kinematic-geometric parameters, gear parameters; elasticity parameters is possible. Improvement of {{positioning accuracy}} up to the limits set by repeatability is show through <b>a</b> <b>verification</b> <b>procedure...</b>|$|R
40|$|We provide {{techniques}} to integrate resolution logic with equality in type theory. The {{results may be}} rendered as follows. - A clausification procedure in type theory, equipped with a correctness proof, all encoded using higher-order primitive recursion. - A translation of resolution proofs into lambda terms, yielding <b>a</b> <b>verification</b> <b>procedure</b> for those proofs. - The power of resolution theorem provers becomes available in interactive proof construction systems based on type theory...|$|R
40|$|We employ static {{analysis}} to examine monotonicity of functions defined over lattices in a #-calculus augmented with constants, branching, meets, joins and recursive definitions. The {{need for such}} <b>a</b> <b>verification</b> <b>procedure</b> has recently arisen in our work on a static analyzer generator called Zoo, in which the specification of {{static analysis}} (input to Zoo) consists of finite-height lattice definitions and function definitions over the lattices. Once monotonicity of the functions is ascertained, the generated analyzer is guaranteed to terminate...|$|R
50|$|Internet {{pornography}} will {{be prohibited}} if it {{falls within the}} ‘RC’ or ‘X18+’ classifications or, for content hosted in Australia that is not restricted by <b>an</b> adult <b>verification</b> <b>procedure,</b> if it falls within the ‘R18+’ classification.|$|R
40|$|A {{method for}} obtaining word and frame {{synchronization}} in pulse position modulated optical communication systems is described. The method uses a short sync sequence inserted {{at the beginning}} of each data frame and <b>a</b> <b>verification</b> <b>procedure</b> to distinguish between inserted and randomly occurring sequences at the receiver. This results in an easy to implement sync system which provides reliable synchronization even at high symbol error rates. Results are given for the application of this approach to a highly energy efficient 256 -ary PPM test system...|$|R
50|$|By 2001, GEN had {{obtained}} consultative status at the United Nations Economic and Social Council (ECOSOC). In October 2005, {{at the conference}} to celebrate the tenth anniversary of GEN, {{a group of young}} adults joined together to found NextGEN (the Next Generation of the Global Ecovillage Network). GEN does not have <b>a</b> <b>verification</b> <b>procedure</b> to select ecovillages or member subscriptions on their website. A Community Sustainability Assessment tool has been developed that provides a means to assess how successful a particular ecovillage is at improving its sustainability.|$|R
30|$|In {{the context}} of the Finite Element Method, <b>verification</b> <b>procedures</b> have been {{introduced}} since the late 1970 s [60 – 62]. They enable a posteriori discretization error estimates to be computed and mesh adaptivity to be driven. In this work, <b>a</b> <b>verification</b> <b>procedure</b> based on the concept of constitutive relation error (CRE) [61] is implemented. It leads to robust error estimates for both linear and nonlinear time-dependent problems [63 – 66]. The CRE concept, which is particularly suited to Computational Mechanics models, is based on duality and rests on a simple idea, namely, after constructing so-called admissible fields satisfying all equations of the model except (part of) the constitutive law, the residual associated with the constitutive relationship is evaluated.|$|R
50|$|After {{the changes}} of 1989 the Służba Bezpieczeństwa was disbanded {{by the first}} free {{government}} under the prime minister, Tadeusz Mazowiecki. A new agency, called the State Protection Office (Urząd Ochrony Państwa, or UOP) was formed and staffed mainly by the former SB officers who successfully passed <b>a</b> <b>verification</b> <b>procedure.</b> Its mission was primarily general espionage and intelligence gathering as well as counter-espionage and fighting against high ranked organized crime. It was commanded by a career intelligence officer but was directly supervised by a civilian government official, Coordinator for the Special Services.|$|R
40|$|International audienceWe {{propose a}} {{decentralized}} protocol {{for a large}} set of users to privately compute averages over their joint data, which can later be used to learn more complex models. Our protocol can find a solution of arbitrary accuracy, does not rely on a trusted third party and preserves the privacy of users throughout the execution in both the honest-but-curious and malicious adversary models. Furthermore, we design <b>a</b> <b>verification</b> <b>procedure</b> which offers protection against malicious users joining the service {{with the goal of}} manipulating the outcome of the algorithm...|$|R
40|$|Several {{modifications}} in technique {{were incorporated into}} the standard agglutination test for Pasteurella tularensis. Reciprocal shaking of all tubes in a Kahn shaker was introduced to increase the rate of agglutination and quantity of agglutinated cell mass, {{making it possible to}} report preliminary results within 4 hr. Increased incubation time at a higher temperature was used to favor the rate of agglutination. A serum control for each serum tested was necessary to detect false positive tests. Finally, <b>a</b> <b>verification</b> <b>procedure</b> with 5 % NaCl used as the diluent was instituted to prevent these false positive reactions...|$|R
40|$|Abstract. We provide {{techniques}} to integrate resolution logic with equality in type theory. The {{results may be}} rendered as follows. − A clausification procedure in type theory, equipped with a correctness proof, all encoded using higher-order primitive recursion. − A novel representation of clauses in minimal logic such that the λ-representation of resolution steps is linear {{in the size of}} the premisses. − A translation of resolution proofs into lambda terms, yielding <b>a</b> <b>verification</b> <b>procedure</b> for those proofs. − The power of resolution theorem provers becomes available in interactive proof construction systems based on type theory. 1...|$|R
40|$|The paper {{presents}} the approach for the verification of the lemma {{used for the}} model for reputation risk for subsidiaries of non-public group with reciprocal shareholding as proposed by the author in priory works. For all entities with the absolute value of the reputation risk greater than the entity’s materiality the reputation risk management system should be in place. The entire population of the Polish broker-dealers market was investigated. Based on the accounting assessment of the materiality, {{market value of the}} consolidated equity for listed groups and BASEL II disclosure <b>a</b> <b>verification</b> <b>procedure</b> was designed. Based on the procedure, the lemma was confirmed. ...|$|R
40|$|International audienceIn this work, {{we define}} <b>a</b> <b>verification</b> <b>procedure</b> that enables to build {{guaranteed}} PGD-reduced models for linear elliptic or parabolic problems depending on many parameters. It {{is based on}} the general concept of constitutive relation error and provides for strict bounds on both global error and error on outputs of interest. Furthermore, it helps driving adaptive strategies by assessing contributions of various error sources. Consequently, virtual charts that may be constructed from the PGD approximate solution can be certified. Technicalities and performances of the control approach, in particular when dealing with a large set of model parameters, are detailed on a transient thermal problem...|$|R
40|$|International audienceThis paper {{presents}} several algorithms {{to detect}} the cable interferences for a general spatial Cable-Driven Parallel Robot (CDPR). Two types of cable interferences are considered. The first type is the collisions between cables and cables. The second type is the interferences between cables and the CDPR mobile platform. In each case, an algorithm is proposed to efficiently verify the cable interferences. The use of the proposed algorithms is then illustrated by <b>a</b> <b>verification</b> <b>procedure</b> of the collision free condition over a given Cartesian workspace and orientation workspace of a CDPR. These tools {{can be used in}} the design or planning phase of a general CDPR...|$|R
40|$|This paper {{presents}} {{recent work}} on iconic model-matching. The idea of iconic feature evaluation is reviewed, and methods for setting adaptive noise thresholds {{for use in}} feature combination are described. Extensions to the adaptive thresholding technique are explained and illustrated, and the relevance of this technique to feature combination is discussed. Finally demonstrations {{of the performance of}} the system are shown, with particular reference to the discrimination ability of the method with multiple models. This paper describes a method of model-matching, applicable as <b>a</b> <b>verification</b> <b>procedure</b> within <b>a</b> knowledge-based vision systems containing three-dimensional geometric models. Most approaches to object verification in model-based vision merely exten...|$|R
40|$|Real-time face {{alignment}} {{in video}} is very critical in many {{applications such as}} facial expression analysis, driver fatigue monitoring, etc. This paper presents a real time algorithm for face alignment in video that combines Active Shape Model (ASM) based face alignment and spatial-temporal continuity based tracking strategy. To guarantee the correctness of the tracked shape in each frame, <b>a</b> <b>verification</b> <b>procedure</b> is introduced so that when inter-frame shape tracking failed the intra-frame ASM algorithm can be restored to initialize a new shape for tracking. Experiments show that the implemented system can run totally automatic with a quite good accuracy that may have many practical applications. Index Terms — Face alignment, tracking, ASM 1...|$|R
40|$|Abstract. We employ static {{analysis}} to examine extensionality (∀x: x ≤ f(x)) of functions defined over lattices in a λ-calculus augmented with constants, branching, meets, joins and recursive definitions. The {{need for such}} <b>a</b> <b>verification</b> <b>procedure</b> has arisen in our work with a static analyzer generator called Zoo, in which the specification of {{static analysis}} (input to Zoo) consists of finite-height lattice definitions and function definitions over the lattices. Once extensionality of the func-tions is ascertained, the generated analyzer is guaranteed to terminate. In a disjunctive combination with the previous work [MY 02] on the static monotonicity analysis (checking ∀x ≤ y: f(x) ≤ f(y)), the extensional-ity analysis will enlarge the set of input programs accepted by Zoo. ...|$|R
40|$|Various {{types of}} {{probabilistic}} proof systems {{have played a}} central role in the development of computer science in the last decade. In this exposition, we concentrate on three such proof systems [...] - interactive proofs, zero-knowledge proofs, and probabilistic checkable proofs [...] - stressing the essential role of randomness in each of them. 1 Introduction The glory given to the creativity required to find proofs, makes us forget that it is the less glorified <b>procedure</b> of <b>verification</b> which gives proofs their value. Philosophically speaking, proofs are secondary to the verification procedure; whereas technically speaking, proof systems are defined in terms of their <b>verification</b> <b>procedures.</b> The notion of <b>a</b> <b>verification</b> <b>procedure</b> assumes the notion of computation and furthermore the notion of efficient computation. This implicit assumption is made explicit in the definition of NP, in which efficient computation is associated with (deterministic) polynomial-time algorithms. Definition 1 (NP [...] ...|$|R
40|$|Abstract. We present <b>an</b> {{automatic}} <b>verification</b> <b>procedure</b> {{based on}} RGSep that {{is suitable for}} reasoning about fine-grained concurrent heapmanipulating programs. The procedure computes a set of RGSep actions overapproximating the interference that each thread causes to its concurrent environment. These inferred actions allow us to verify safety, liveness, and functional correctness properties {{of a collection of}} practical concurrent algorithms from the literature. ...|$|R
40|$|We {{investigate}} the computational complexity of languages which have interactive proof systems of bounded message complexity. In particular, denoting {{the length of}} the input by n, we show that ffl If L has an interactive proof in which the total communication is bounded by c(n) bits then L can be recognized by a probabilistic machine in time exponential in O(c(n) + log(n)). ffl If L has a public-coin interactive proof in which the prover sends c(n) bits then L can be recognized by a probabilistic machine in time exponential in O(c(n) Δ log(c(n)) + log(n)). ffl If L has an interactive proof in which the prover sends c(n) bits then L can be recognized by a probabilistic machine with an NP-oracle in time exponential in O(c(n) Δ log(c(n)) +log(n)). Work done while being on a sabbatical leave at LCS, MIT. 1 Introduction Proof systems are defined in terms of their <b>verification</b> <b>procedures.</b> The notion of <b>a</b> <b>verification</b> <b>procedure</b> assumes the notion of computation and furthermor [...] ...|$|R
40|$|Flood {{forecast}} verification {{is crucial}} to assess Flood Warning System performance. However, how forecasts should be verified is still an open question. This paper is grounded {{on the idea that}} flood forecast verification should not be seen as a universal process, instead it should be tailored to the particular context in which forecasts are implemented. Accordingly, by means of a case study, <b>a</b> <b>verification</b> <b>procedure</b> is proposed. It comprises three steps that can be partially or totally implemented depending on the specific aim of the analysis (that is the context) allowing, this way, to evaluate forecasts at different perspectives or according to different points of view. Specifically, the procedure extends the common practice of flood forecast verification by including analytical tools from meteorology...|$|R
40|$|In this paper, RANS CFD {{simulations}} of steady and unsteady upwind sail aerodynamics are verified and validated against wind tunnel experiments previously performed at Politecnico di Milano. Experimental data is presented, and the experimental results are analysed to estimate repeatability. Blockage effects caused by tunnel boundary layers and measurement equipment are estimated using detailed CFD simulations, allowing such effects to be accounted for. <b>A</b> <b>verification</b> <b>procedure</b> is performed, resulting in very low numerical uncertainties. The force predictions are then validated for both steady and unsteady conditions. The steady results show very good agreement, {{with a maximum}} error of 3. 1 %. For the unsteady conditions, good agreement is found for the force mean values, whilst the prediction of force amplitudes is less satisfactory...|$|R
40|$|Parallel sessionInternational audienceThe goal of {{the talk}} is to present <b>a</b> <b>verification</b> <b>procedure</b> for car {{collision}} avoidance algorithms using reachable set information and optimal control techniques. After defining the car models and the scenarios with avoidable objects, consistent with the measured data provided by Volkswagen, we create an algorithm which is able to give an output data comparable with the ones of the Volkswagen algorithms. To do this it is needs to define mathematically when a collision will occur or not. This definition is based on reachable set information and optimal control problem solutions. Moreover we take into account sensor perturbations {{in relation to their}} mathematical model. The task is to find sensor tolerance ranges guaranteeing that a certain failure rate probability is not exceeded. Speaker: Ilaria Xaus...|$|R
40|$|This paper {{describes}} three {{variants of}} a counterexample guided inductive optimization (CEGIO) approach based on Satisfiability Modulo Theories (SMT) solvers. In particular, CEGIO relies on iterative executions to constrain <b>a</b> <b>verification</b> <b>procedure,</b> {{in order to}} perform inductive generalization, based on counterexamples extracted from SMT solvers. CEGIO is able to successfully optimize {{a wide range of}} functions, including non-linear and non-convex optimization problems based on SMT solvers, in which data provided by counterexamples are employed to guide the verification engine, thus reducing the optimization domain. The present algorithms are evaluated using a large set of benchmarks typically employed for evaluating optimization techniques. Experimental results show the efficiency and effectiveness of the proposed algorithms, which find the optimal solution in all evaluated benchmarks, while traditional techniques are usually trapped by local minima...|$|R
40|$|The {{verification}} of sequential circuits with complex datapaths and non-trivial timing behavior {{is a difficult}} task. A multifunctional pipline is described {{as an example of}} such a circuit automatically verified by <b>a</b> <b>verification</b> <b>procedure.</b> The paper aims at presenting a possible target for hardware verification methods both for hardware designers interested in applying such methods and researchers developing such methods. 1. INTRODUCTION There is much doubt by designers concerning the practicability of current verification systems in hardware design. There are only a few examples of circuits verified on the basis of formal methods, which in principle also (but possibly not in practice) could be validated by simulation. Of course, there are some examples, e. g. [Joy 88]. Indeed, verification methods and simulation often significantly differ, especially when a partial specification is verified or when a correctness proof is established within <b>a</b> formal framework. <b>Verification</b> means to compa [...] ...|$|R
40|$|A {{system is}} {{described}} that integrates vision and tactile sensing in a robotics environment to perform object recognition tasks. It uses multiple sensor systems (active touch and passive stereo vision) to compute three dimensional primitives {{that can be}} matched against a model data base of complex curved surface objects containing holes and cavities. The low level sensing elements provide local surface and feature matches which arc constrained by relational criteria embedded in the models. Once a model has been invoked, <b>a</b> <b>verification</b> <b>procedure</b> establishes confidence measures for a correct recognition. The three dimen* sional nature of the sensed data makes the matching process more robust as does the system's ability to sense visually occluded areas with touch. The model is hierarchic in nature and allows matching at different levels to provide support or inhibition for recognition...|$|R
40|$|Abstract. We {{address the}} issue of {{updating}} privileges in a dynamic environment by introducing authority cerrtificates in a Privilege Management Infrastructure. These certificates can be used to create access-level permissions but also to delegate authority to other agents, thereby providing a mechanism for creating management structures and for changing these structures over time. We present a semantic framework for privileges and certificates and an associated calculus, encoded as a logic program, for reasoning about them. The framework distinguishes between the time a certificate is issued or revoked and the time for which the associated privilege is created. This enables certificates to have prospective and retrospective effects, and allows us to reason about privileges and their consequences in the past, present, and future. The calculus provides <b>a</b> <b>verification</b> <b>procedure</b> for determining, given a set of declaration and revocation certificates, whether a certain privilege holds. ...|$|R
40|$|The DOVE tool {{supports}} high-level system modelling and design, and for-mal reasoning about critical properties. DOVE uses state-machine graphs {{to illustrate}} designs, thus {{building on a}} familiar and effective means of commu-nicating system designs to a wide audience. DOVE employs a propositional temporal logic to express desirable behavioural properties of the design, and presents it in a sequent calculus syntax for ease of manipulation. <b>A</b> <b>verification</b> <b>procedure</b> which can handle temporal properties of DOVE state machines is included through high level tactics in a graphical proof tool interface. The DOVE program is committed to developing proof visualization techniques to complement {{the power of this}} proof scheme. This paper presents the theoretical structure underlying the DOVE tool. APPROVED FOR PUBLIC RELEASE ^Current address: Praxis Critical Systems Limited, 20 Manvers Street, Bath BAl IPX, United King-dom. ^Q foS-a-^s-...|$|R
40|$|This paper {{presents}} <b>a</b> practical automatic <b>verification</b> <b>procedure</b> for proving linearizability (i. e., atomicity {{and functional}} correctness) of concurrent data structure implementations. The procedure employs a novel instrumentation to verify logically pure executions, and is evaluated {{on a number}} of standard concurrent stack, queue and set algorithms. ...|$|R
30|$|In “A {{procedure}} {{to locate the}} eyelid position in noisy videokeratoscopic images,” T. Schäck, M. Muma, W. Alkhaldi, and A. M. Zoubir proposes a novel {{procedure to}} robustly determine the eyelid position in high-speed videokeratoscopic images. The eyelid position is an important information in such images, since the eyelids affect {{the state of the}} cornea and the tear film dynamics. The very low contrast of videokeratoscopic images and the occlusions caused by the eyelashes cause difficulties in solving this problem. In this paper’s approach, nonlinear image filtering is first performed to remove the eyelashes. Then, an image segmentation approach based on morphological operations and active contours is used to provide a set of candidate pixels. <b>A</b> <b>verification</b> <b>procedure</b> reduces the set to those pixels that are likely to contribute to accurately locate the eyelid edge. Finally, the authors use robust M-estimation to fit a parametric model to the selected candidate pixels.|$|R
40|$|We present <b>a</b> <b>verification</b> <b>procedure</b> {{for pure}} higher-order {{functional}} Scala programs with parametric types. We show that our procedure is sound for proofs, {{as well as}} sound and complete for counter-examples. The procedure reduces the analysis of higher-order programs to checking satisfiability of a sequence of quantifier-free formulas over theories such as algebraic data types, integer linear arithmetic, and unin-terpreted function symbols, thus enabling the use of efficient satisfiability modulo theory (SMT) solvers. Our solution supports arbitrary function types and arbi-trarily nested anonymous functions (which {{can be stored in}} data structures, passed as arguments, returned, and applied). Among the contributions of this work is supporting even those cases when anonymous functions cannot be statically traced back to their definition, ensuring completeness of the approach for finding counter-examples. We provide a proof of soundness and counter-example completeness for our system as well as initial evaluation in the Leon verifier...|$|R
40|$|Abstract Vulnerability {{analysis}} {{is concerned with}} the problem of identifying weaknesses in com-puter systems that can be exploited to compromise their security. In this paper we describe a new approach to vulnerability analysis based on model checking. Our approach involves: ffl Formal specification of desired security properties. An example of such a property is &quot;noordinary user can overwrite system log files. &quot; ffl An abstract model of the system that captures its security-related behaviors. This modelis obtained by composing models of system components such as the file system, privileged processes, etc. ffl <b>A</b> <b>verification</b> <b>procedure</b> that checks whether the abstract model satisfies the securityproperties, and if not, produces execution sequences (also called exploit scenarios) that lead to a violation of these properties. An important benefit of a model-based approach is that {{it can be used to}} detect known andas-yet-unknown vulnerabilities. This capability contrasts with previous approaches (such a...|$|R
40|$|This paper {{proposes to}} {{incorporate}} full covariance matrices into the radial basis function (RBF) networks {{and to use}} the expectation-maximization (EM) algorithm to estimate the basis function parameters. The resulting networks, referred to as elliptical basis function (EBF) networks, are evaluated through a series of text-independent speaker verification experiments involving 258 speakers from a phonetically balanced, continuous speech corpus (TIMIT). We propose <b>a</b> <b>verification</b> <b>procedure</b> using RBF and EBF networks as speaker models and show that the networks are readily applicable to verifying speakers using LP-derived cepstral coefficients as features. Experimental results show that small EBF networks with basis function parameters estimated by the EM algorithm outperform the large RBF networks trained in the conventional approach. The results also show that the equal error rate achieved by the EBF networks is about two-third of that achieved by the vetor quantization (VQ) -based speaker models. Department of Electronic and Information Engineerin...|$|R
40|$|This paper {{deals with}} Real Time Operating System (RTOS) based secure {{wormhole}} detection and prevention in ad hoc networks. The wormhole attack can form {{a serious threat}} to wireless networks, especially against many ad hoc network routing protocols and location based wireless security systems. A wormhole is created in the ad hoc network by introducing two malicious nodes. These two nodes form a worm hole link and message is transmitted through this link. The next part of the work is to detect the wormhole link by defining worm hole detection and prevention algorithm. After detecting suspicious links, one node performs <b>a</b> <b>verification</b> <b>procedure</b> for each suspicious link. The detection procedure and verifying procedure of suspicious worm link are used for further prevention of wormhole attack in the ad hoc network. Index Terms: An algorithm to detect worm hole attack in a wireless network… 1...|$|R
