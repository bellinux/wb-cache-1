0|2018|Public
40|$|Abstract: This {{paper is}} {{dedicated}} to bounded <b>error</b> <b>identification</b> with complex valued non-linear models. Complex intervals are characterized by using polar forms and a new inclusion function is given for the addition of sectors. The latter is expressed as an optimization problem solved analytically. The new complex interval arithmetic is used with actual data and a complex valued non-linear model for the bounded <b>error</b> <b>identification</b> of the thermal properties of materials. Copyright © 2005 IFAC...|$|R
50|$|There exist {{three primary}} reasons for {{conducting}} a HRA; <b>error</b> <b>identification,</b> <b>error</b> quantification and error reduction. As there exist {{a number of}} techniques used for such purposes, they can be split into one of two classifications; first generation techniques and second generation techniques.|$|R
40|$|Human <b>Error</b> <b>Identification</b> (HEI) {{techniques}} {{have been used}} to predict human error in high risk environments for the past two decades. Despite the lack of supportive evidence for their efficacy, their popularity remains unabated. The application of these approaches is ever-increasing, to include product assessment. The authors feel {{that it is necessary to}} prove that the predictions are both reliable and valid before the approaches can be recommended with any confidence. This paper provides evidence to suggest that human <b>error</b> <b>identification</b> techniques in general, and SHERPA in particular, may be acquired with relative ease and can provide reasonable error predictions...|$|R
40|$|The Lagrange multiplier-based {{method is}} an {{effective}} network parameter <b>error</b> <b>identification</b> method. However, two full matrices with high-dimensions {{are involved in the}} calculation procedure; these create huge computational burdens for large-scale power systems. To solve this problem, a fast solution is proposed in this paper, where special treatment techniques for full matrices are used to dramatically improve the calculation efficiency. A practical parameter <b>error</b> <b>identification</b> program has been developed and used in many electric power control centers. In this paper, the results for test systems and on-site applications are given, which show that the proposed approach is very efficient...|$|R
5000|$|... #Subtitle level 3: Investigation or {{analysis}} of <b>application</b> <b>errors</b> ...|$|R
40|$|Web-based {{applications}} {{are one of}} the most widely used types of software and have become the backbone of the e-commerce and communications businesses. These {{applications are}} often missioncritical for many organizations, but generally suffer from low customer loyalty and approval. Although such concerns would normally motivate the need for highly-reliable and well-tested systems, web-based applications are subject to constraints in their development lifecycles that often preclude complete testing. To address these constraints, this research explores user-visible web-based <b>application</b> <b>errors</b> in the context of web-based <b>application</b> <b>error</b> detection and classification. The main thesis of this work is that user-visible web-based <b>application</b> <b>errors</b> have special properties that can be exploited to improve the current state of web <b>application</b> <b>error</b> detection, testing, and development. This thesis is evaluated using seven specific falsifiable hypotheses. This research presents highly-precise, automated approaches to the testing of web-based applications that reduce the cost of such testing, making its adoption more feasible for developers. Additionally, a model of user-visible web <b>application</b> <b>error</b> severity is constructed, backed by a human study, to refute the current underlying assumption of error severity uniformity in defect seeding for this domain, as well as to propos...|$|R
40|$|In this paper, we {{consider}} the use of human <b>error</b> <b>identification</b> (HEI) techniques as a possible alternative to observation studies for product evaluation. The HEI techniques used were Task Analysis for <b>Error</b> <b>Identification</b> (TAFEI) and Predictive Human Error Analysis (PHEA). The comparison was undertaken {{in connection with the}} prediction of errors in the use of a ticket vending machine. Two main findings emerged from the study. First, predictions derived from the HEI techniques compared favourably with errors observed in actual machine use. Second, the HEI techniques took far less time than direct observation to reach comparable levels of performance. Such rates suggest that these techniques can be usefully applied to the study of consumer products. <br/...|$|R
5000|$|<b>Error</b> message <b>identification,</b> {{categorization}} and troubleshooting ...|$|R
40|$|We {{demonstrate}} that an attention-based encoder-decoder {{model can be}} used for sentence-level grammatical <b>error</b> <b>identification</b> for the Automated Evaluation of Scientific Writing (AESW) Shared Task 2016. The attention-based encoder-decoder models {{can be used for}} the generation of corrections, in addition to <b>error</b> <b>identification,</b> which is of interest for certain end-user applications. We show that a character-based encoder-decoder model is particularly effective, outperforming other results on the AESW Shared Task on its own, and showing gains over a word-based counterpart. Our final model [...] a combination of three character-based encoder-decoder models, one word-based encoder-decoder model, and a sentence-level CNN [...] is the highest performing system on the AESW 2016 binary prediction Shared Task. Comment: To appear at BEA 11, as part of the AESW 2016 Shared Tas...|$|R
40|$|Human factors {{certification}} {{criteria are}} being developed for large civil aircraft. The objective {{is to reduce the}} incidence of design induced error on the flight deck. Many formal <b>error</b> <b>identification</b> techniques currently exist, however none of these have been validated for their use in an aviation context. This paper evaluates SHERPA (Systematic Human Error Reduction and Prediction Approach) as a means for predicting design induced pilot error. Since SHERPA was developed for predicting human error in the petrochemical and nuclear industries, a series of validation studies have suggested that it is amongst the best human error prediction tools available. This study provides some evidence for {{the reliability and validity of}} SHERPA in a flight deck context and concludes that it may form the basis for a successful human <b>error</b> <b>identification</b> tool...|$|R
40|$|Whilst Human Reliability Analysis (HRA) {{has been}} well-accepted and {{integrated}} into the safety management process in other industries, the <b>application</b> of such <b>error</b> analysis techniques {{to the problem of}} complication and reaction to treatment and the associated risks in healthcare is rare. Though the scarcity of HRA techniques in health-care is likely to be due in some part to the safety culture, much is likely to be {{due to a lack of}} awareness of the usefulness of the techniques and their applicability to the problem of human error in the clinical context. This review attempts to look at the popular HRA techniques used in high-reliability industries, such as petro-chemical, nuclear and aviation, and consider their feasibility for use in healthcare. Techniques vary in their scope and have been grouped into those that focus on: data collection, task description, task simulation, human <b>error</b> <b>identification</b> and analysis, and human error quantification. Techniques may cover one or more of these aspects, for example, THERP, HEART and SHERPA include both human <b>error</b> <b>identification</b> and analysis, and human error quantification tools. While some areas of healthcare have used certain HRA techniques, there is considerable scope to use others and to apply techniques to other aspects of healthcare not yet explored. © 2004 - IOS Press and the authors. All rights reserved...|$|R
3000|$|... 2) Reference [24] {{suggests}} a comprehensive RSE approach that simultaneously considers bad measurement identification, parameter estimation and topology <b>errors</b> <b>identification.</b> When (6) {{are applied to}} the generalized SE model presented in [24], only the inequalities corresponding to the measurements related to suspicious parameters are nonlinear, while all other inequalities are linear.|$|R
40|$|Class of 2009 AbstractOBJECTIVES: To {{assess the}} ability of pharmacy, medicine, and nursing {{students}} to identify prescribing errors METHODS: Pharmacy, medicine, and nursing students from the University of Arizona were asked {{to participate in this}} prospective, descriptive study. Pharmacy and medical students in the last didactic year of their program and traditional bachelor of nursing students in the fourth semester of their program were eligible to participate. Subjects were asked to assess a questionnaire containing three sample prescriptions, evaluate if each was correct and indicate the type of error found, if any. The primary outcome measure was the number of correctly identified prescribing errors. The secondary outcome measure was the number of correct types of <b>error</b> found. <b>Error</b> <b>identification</b> rates for each group were calculated. Comparisons in these rates were made between pharmacy, medicine and nursing students. Chi square tests were used to analyze the nominal data gathered from various groups. RESULTS: Pharmacy students were significantly better able to identify errors than medical and nursing students (p< 0. 001). Pharmacy students were significantly better able to determine the type of error (p< 0. 001). CONCLUSIONS: Overall, pharmacy students had higher prescribing <b>error</b> <b>identification</b> rates than medical and nursing students. More studies need to be done to determine the most appropriate way to increase prescribing <b>error</b> <b>identification</b> rates...|$|R
40|$|In this paper, {{we suggest}} a scheme for <b>error</b> <b>identification</b> in human skills {{transfer}} {{when using the}} Programming by Demonstration (PbD) in adding a set of skills from a human operator to the force- controlled robotic tasks. Such errors in human skills transfer is majorly caused from the difficulty of properly synchronizing the human and machine responses. Based on the captured Cartesian forces and torques signals of the manipulated object, we present an approach of identifying the errors stemmed from human wrong skills transfer in a PbD process. The scheme is composed of using the Gravitational Search- Fuzzy Clustering Algorithm (GS-FSA) in finding the centroid of the captured forces and torques signals for each Contact Formation (CF). Then using a distance- based outlier identification approach along with the centroid of each signal, the human errors can be identified {{in the framework of}} data outlier identification. In order to validate the approach, a test stand, composed of a KUKA Light Weight Robot manipulating a rigid cube object, is built. The manipulated object is assumed to interact with an environment composed of three orthogonal planes. <b>Error</b> <b>identification</b> for two case studies will be considered and other cases can be dealt with in a similar manner. From the experimental results, excellent human <b>error</b> <b>identification</b> is shown when using the suggested approach...|$|R
30|$|Patient {{identification}} is still performed manually by many public healthcare providers. This method of patient identification should be replaced, {{because it is}} very likely to lead to anthropogenic <b>errors.</b> <b>Identification</b> <b>errors</b> can lead to severe problems with medical procedures, such as medication administration, blood transfusions, clinical trials, and surgery (García-Betances and Huerta 2012).|$|R
40|$|Individual source {{errors and}} their effects on the {{accuracy}} of the Gravity Probe B (GP-B) experiment were investigated. Emphasis was placed on: (1) the refinement of source <b>error</b> <b>identification</b> and classifications of error according to their physical nature; (2) error analysis for the GP-B data processing; and (3) measurement geometry for the experiment...|$|R
40|$|International audienceIn {{this paper}} we {{consider}} the identification of a linear module that is embedded in a dynamic network using noisy measurements of the internal variables of the network. This {{is an extension of}} the errors-in-variables (EIV) identification framework to the case of dynamic networks. The consequence of measuring the variables with sensor noise is that some prediction <b>error</b> <b>identification</b> methods no longer result in consistent estimates. The method developed in this paper is based on a combination of the instrumental variable philosophy and closed-loop prediction <b>error</b> <b>identification</b> methods, and leads to consistent estimates of modules in a dynamic network. We consider a flexible choice of which internal variables need to be measured in order to identify the module of interest. This allows for a flexible sensor placement scheme. We also present a method {{that can be used to}} validate the identified model...|$|R
40|$|Abstract- This paper {{addresses}} {{the problem of}} topology <b>error</b> <b>identification</b> for generalized orthogonal state estima-tors based on fast Givens rotations. Attention is focused on two issues: avoiding observability/criticality problems dur-ing topology error processing, and improving the perfor-mance of the <b>error</b> <b>identification</b> procedure. The former ob-jective is attained by endowing the orthogonal estimator with a priori information processing capabilities. It {{is shown in the}} paper that prior knowledge on the states is easily accom-modated in the three-multiplier Givens rotations framework, requiring no extra computational cost. To accomplish the second goal, we advocate the application of a geometric test to ensure that all devices with wrong status are duly selected as suspect. The effectiveness of the resulting identification method is assessed through its application to distinct situa-tions involving topology errors simulated on the IEEE 24 -bus test system...|$|R
40|$|In {{this paper}} we {{consider}} the identification of a linear module that is embedded in a dynamic network using noisy measurements of the internal variables of the network. This {{is an extension of}} the errors-in-variables (EIV) identification framework to the case of dynamic networks. The consequence of measuring the variables with sensor noise is that some prediction <b>error</b> <b>identification</b> methods no longer result in consistent estimates. The method developed in this paper is based on a combination of the instrumental variable philosophy and closed-loop prediction <b>error</b> <b>identification</b> methods, and leads to consistent estimates of modules in a dynamic network. We consider a flexible choice of which internal variables need to be measured in order to identify the module of interest. This allows for a flexible sensor placement scheme. We also present a method {{that can be used to}} validate the identified model...|$|R
40|$|The {{research}} {{presented in}} this paper establishes a valid, and simplified, revision of previous spreadsheet error classifications. This investigation is concerned with the results of a web survey and two web-based gender and domain-knowledge free spreadsheet <b>error</b> <b>identification</b> exercises. The participants of the survey and exercises were a test group of professionals (all of whom regularly use spreadsheets) and a control group of students from the University of Greenwich (UK). The findings show that over 85 % of users are also the spreadsheet's developer, supporting the revised spreadsheet error classification. The findings also show that spreadsheet <b>error</b> <b>identification</b> ability is directly affected both by spreadsheet experience and by error-type awareness. In particular, that spreadsheet error-type awareness significantly improves the user's ability to identify, the more surreptitious, qualitative error. Comment: 20 Pages, 14 Tables and Figures, many in colou...|$|R
40|$|This paper {{discusses}} an optimization {{method for}} the spreading performed by centrifugal spreaders {{in order to}} minimize adverse environmental effects owing to <b>application</b> <b>errors.</b> A cost functional relying on a conventional simplified spread pattern model is proposed. In order {{to take into account the}} mechanical limits of the device, constraints are introduced. An augmented Lagrangian algorithm is implemented to compute an approximate solution. Numerical experiments show that <b>application</b> <b>errors</b> can be significantly reduced for parallel tracks within a main field body...|$|R
50|$|CREAM is a {{technique}} used {{in the field of}} human reliability assessment (HRA), for the purposes of evaluating the probability of a human error occurring throughout the completion of a specific task. From such analyses measures can then be taken to reduce the likelihood of errors occurring within a system and therefore lead to an improvement in the overall levels of safety. There exist three primary reasons for conducting an HRA; <b>error</b> <b>identification,</b> <b>error</b> quantification and error reduction. As there exist a number of techniques used for such purposes, they can be split into one of two classifications; first generation techniques and second generation techniques. First generation techniques work {{on the basis of the}} simple dichotomy of ‘fits/doesn’t fit’ in the matching of the error situation in context with related <b>error</b> <b>identification</b> and quantification and second generation techniques are more theory based in their assessment and quantification of errors. HRA techniques have been utilised in a range of industries including healthcare, engineering, nuclear, transportation and business sector; each technique has varying uses within different disciplines.|$|R
50|$|Business {{applications}} {{can fail}} when an unexpected error occurs. This error could occur {{due to a}} data error (an unexpected data input or a wrong data input), an environment error (an in frastructure related error), a programming error, a human error or a work flow error. When a business application fails one needs to fix the business <b>application</b> <b>error</b> {{as soon as possible}} so that the business users can resume their work. This work of resolving business <b>application</b> <b>errors</b> is known as business application support.|$|R
40|$|We {{consider}} general stochastic parallel model {{adaptation problems}} which consist {{of an unknown}} linear time invariant system and a partially or wholly tunable system connected in parallel, with a common input. The goal of adaptation is to tune the partially tunable system so that its output matches that of the unknown system, {{despite the presence of}} any disturbance which is stochastically uncorrelated with the input. Our general formulation of stochastic parallel adaptation schemes allows applications to adaptive feedforward control and adaptive active noise canceling with input contamination, in addition to output <b>error</b> <b>identification</b> and adaptive IIR filtering. We show that in all the applications, the goal of adaptation is met, whenever a matching condition and a positive real condition are satisfied. A special case of our results therefore resolves the long standing problem of the convergence and the unbiasedness of output <b>error</b> <b>identification</b> scheme in the presence of colored noise [...] . ...|$|R
50|$|The website {{has been}} down, {{throwing}} an Phusion Passenger (Ruby on Rails deployment) <b>application</b> <b>error,</b> since 2.00 GMT on 07/11/13 - this date may be considerably longer.|$|R
5000|$|... ? - {{indicates}} that the user is to be prompted before continuing (results in an <b>application</b> <b>error</b> since the API has no means to implement a user prompt); ...|$|R
50|$|Repairing disk permissions is a {{troubleshooting}} activity {{commonly associated}} with the macOS operating system by Apple. The efficacy of repairing permissions to troubleshoot <b>application</b> <b>errors</b> has been debated.|$|R
40|$|The paper {{presents}} {{a method of}} error analysis {{as one of the}} possible approaches in analysing and interpreting the language production of learners ofa foreign language, in this case and, as illustrated by examples, Slovene. The error is defined as a failed part of language and as a form or a combination of forms produced by the learner. These forms would not have been produces by native speaker in the same context and the same sort of circumstances. Steps in error analysis are presented briefly: from data collection, <b>error</b> <b>identification,</b> <b>error</b> description, classification, to evaluation...|$|R
40|$|Abstract:- In {{this paper}} we propose a new {{modeling}} technique for LTI multivariable systems using the generalized Orthonormal basis functions with ordinary poles. Once the model structure is built we proceed to update the membership set of the resulting model parameters through the execution of unknown but bounded <b>error</b> <b>identification</b> algorithms. This updating aims to synthesize a robust control strategy...|$|R
40|$|Closed loop output <b>error</b> <b>identification</b> {{algorithms}} [7, 9]and {{recently developed}} algorithms for direct closed loop estimation of reduced order controllers [8] despite their diversity {{have in fact}} a unifying basic ground which will be enhanced. In this paper it is shown that the plant model identification in closed loop using closed loop output <b>error</b> <b>identification</b> algorithms and the direct estimation in closed loop of a reduced order controller feature a duality character. Basic schemes, algorithms and properties of the algorithms can be directly obtained by interchanging the plant model and the controller. Additional schemes and algorithms allowing a full coverage of the various possible identification and reduction criteria are given. The paper also will explore the coherence aspects in using closed loop plant model identification and direct estimation in closed loop of reduced order controllers. The following problem will be addressed: what closed loop plant model identification should be used when a criterion for controller reduction is given...|$|R
40|$|Human factors {{certification}} {{criteria are}} being developed for large civil aircraft {{with the objective of}} reducing the incidence of design-induced error on the flight deck. Many formal <b>error</b> <b>identification</b> techniques currently exist which have been developed in non-aviation contexts but none have been validated for use to this end. This paper describes a new human <b>error</b> <b>identification</b> technique (HET – Human Error Template) designed specifically as a diagnostic tool for the identification of design induced error on the flight deck. HET is benchmarked against three existing techniques (SHERPA – Systematic Human Error Reduction and Prediction Approach; Human Error HAZOP – Hazard and Operability study; and HEIST – Human Error In Systems Tool). HET outperforms all three existing techniques in a validation study comparing predicted errors to actual errors reported during an approach and landing task in a modern, highly automated commercial aircraft. It is concluded that HET should provide a useful tool as a adjunct to the proposed human factors certification process...|$|R
40|$|High {{accurate}} absolute robot positioning is a requirement, {{and still}} a challenge, in many applications, such as drilling in the aerospace industry. The accuracy is affected due to many sources of errors from robot model, tool calibration, sensor and product uncertainties. While model-based error compensation cannot reach the desired accuracy, sensor-based compensation appears as the practical solution to increase the robot positioning accuracy. A structured analysis of the error sources in robotic manufacturing processes can facilitate <b>error</b> <b>identification</b> and further compensation. This paper describes an error source breaking down approach for analyzing robotic manufacturing processes. Moreover, an external sensor-based compensation is proposed for error reduction and <b>error</b> <b>identification.</b> Comparison with a compliance model-based compensation is performed. The proposed approach is applied to a robotic drilling process for aircraft manufacturing, considered a general and real industrial application. Further validation through experimentation is performed. The validation revealed a clear improvement in robot positioning accuracy {{and the benefits of}} the proposed error source structure for analysis...|$|R
40|$|This paper {{demonstrates}} how the human <b>error</b> <b>identification</b> technique SHERPA {{can be applied}} to the task of administering drugs to hospital patients. Human <b>error</b> <b>identification</b> techniques have been used in high-risk environments for some time. Drugs administration is a complex and risky process with many opportunities for error. The purpose of using SHERPA is to identify where in the process errors occur and to suggest the most suitable design solutions to mitigate these errors. Medical Error Improving the quality and safety of patient care has become an increasingly high priority in both UK and across the world (Department of Health, 2001). Medical errors affect 850, 000 people in the UK each year often leading to patients spending extended time in hospital or in community care. These errors cost the NHS up to £ 2 billion in additional treatment and the cost of clinical negligence settlements is about £ 400 million (DOH, 2000). Medical error is also a significant cause of death in the United States. The Harvar...|$|R
40|$|The {{significance}} of errors in explicating Second Language Acquisition (SLA) processes {{led to the}} growth of error analysis in the 1970 s which has since maintained its prominence in English as a second/ foreign language (L 2) research. However, one problem with this research is errors are often taken for granted, without problematising them and their identification. Against this background, the present study aimed to: (a) measure L 2 English teachers 2 ̆ 7 ability to interpret L 2 learner intentions in idiosyncratic expressions, and (b) bring to light factors that facilitate <b>error</b> <b>identification.</b> Findings show that: (1) there is a significant difference between L 2 students 2 ̆ 7 intentions and teachers 2 ̆ 7 interpretations of those intentions; and (2) L 2 English teachers 2 ̆ 7 knowledge of students 2 ̆ 7 L 1 is not an advantage in error detection. Teacher interview data were drawn on to explicate text interpretation, reconstruction and <b>error</b> <b>identification,</b> suggesting implications for L 2 research and pedagogy...|$|R
50|$|If any similar {{business}} <b>application</b> <b>errors</b> {{occurred in}} the past then the issue resolution steps are retrieved from the support knowledge base and the error is resolved using those steps. If it is a new support error, then new issue resolution steps are created and the error is resolved. The new support error resolution steps are recorded in the knowledge base for future use. For major business <b>application</b> <b>errors</b> (critical infrastructure or application failures), a phone conference call is initiated and all required support persons/teams join the call and they all work together to resolve the error.|$|R
40|$|This paper {{presents}} two off-line output <b>error</b> <b>identification</b> algorithms for linear continuous-time {{systems with}} unknown time delay from sampled data. The proposed methods (for open and closed loop systems) use a Nonlinear Programming algorithm and needs an initialization step {{that is also}} proposed from a modication of the Yang algorithm. Simulations, as illustrated by Monte-Carlo runs, show that the obtained parameters are unbiased and very accurate...|$|R
