0|10000|Public
30|$|The {{cleansing}} algorithm of Cong et al.’s BatchRepair and IncRepair is, {{just like}} their predecessor [14], <b>a</b> <b>cost-based</b> algorithm where the optimal repair is chosen {{based on the}} editing cost from the original data [2], measured in Levenstein’s edit distance [15], or measured {{by the number of}} tuples to be removed [16]. Note that all <b>cost-based</b> <b>methods</b> follow “majority policy”. Beskales et al. proposed a sampling-based method that generates repairs from among repairs with minimal changes [7], which can also be categorized as <b>a</b> <b>cost-based</b> <b>method.</b>|$|R
50|$|Cost plus pricing is <b>a</b> <b>cost-based</b> <b>method</b> {{for setting}} {{the prices of}} goods and services. Under this approach, the direct {{material}} cost, direct labor cost, and overhead costs for a product are added up and added to a markup percentage (to create a profit margin) in order to derive {{the price of the}} product.|$|R
5000|$|Devise <b>a</b> new <b>cost-based</b> {{targeting}} <b>method,</b> {{that takes}} {{population growth and}} needs, budget constraints and the program’s operation capacity into consideration.|$|R
5000|$|Based on the Telecommunications Act of 1996, the FCC could require LECs {{to provide}} UNEs <b>at</b> <b>a</b> <b>cost-based</b> price, which may include a [...] "reasonable profit". The FCC has {{determined}} that [...] "cost" [...] means forward-looking economic cost and has required the states to use a methodology called total element long-run incremental cost (TELRIC).|$|R
40|$|A {{methodology}} recently {{proposed to}} improve processing of star queries on data warehouses is the clustering and indexing of fact tables using their multidimensional hierarchies [DRSN 98, MRB 99, KS 01]. Due to this improved organization schema, processing of aggregation star queries changes dramatically creating new optimization opportunities. An important optimization technique is the so-called pre-grouping transformation. Although this transformation is expected to improve the query-processing plan in most cases, there are several cases where it is not beneficial. In this paper we attempt to apply <b>a</b> <b>cost-based</b> <b>method</b> for the optimal application of the pre-grouping transformation. Taking into consideration the special characteristics of our domain we identify the most suitable algorithms for the operations related to pre-grouping and derive detailed cost formulas for them. When proper statistical information is available the method can decide (1) {{whether or not to}} use the pre-grouping transformation and (2) which combination of algorithms to use for the various operations involved. 1...|$|R
40|$|We {{propose a}} new {{approach}} to optimize storage classes for a unit-load warehouse with a general layout. Under this approach, the 2 ̆ 2 attractiveness 2 ̆ 2 of each storage location is determined by the frequency of visits to the location. We estimate this frequency by solving a linear programming model, which considers the warehouse 2 ̆ 7 s layout and the products 2 ̆ 7 arrivals and mean demands. We compare our frequency-based class formation <b>method</b> with <b>a</b> <b>cost-based</b> <b>method</b> and <b>a</b> grid-based method. Our numerical results suggest that if the warehouse utilization is low, different class formation methods may give rise to very different travel costs. Specifically, the frequency-based method outperforms the other two methods if demand variability is sufficiently low. This implies that both the layout and the product flow information is useful for class formation in this situation. We also refine the frequency-based method using the information of demand supports. The refined method outperforms all the other methods when demand variability is high...|$|R
40|$|In this paper, {{we provide}} an {{empirical}} {{study of the}} association between the management 2 ̆ 7 s perception {{of the importance of}} environmental variables and their choice of international transfer-pricing methods {{in the context of a}} developing economy. Given the sizable investment flowing to developing countries and the amount of economic exchange that occurs through foreign investment in these countries, we believe this is a significant issue. For this study, we collected the data from field interviews with the management of large foreign investment enterprises (FIEs) in China. These FIEs include mainly investors from the United States, Japan, and Europe. Our evidence indicates that the more important management perceives the interests of local partners and the maintenance of a good relationship with host government to be, the more likely that the FIE will use a market-based transfer-pricing method. On the other hand, the more important the management perceives foreign exchange controls in transfer-pricing decisions, the more likely the FIE will choose <b>a</b> <b>cost-based</b> <b>method.</b> Finally, there is a moderate agreement between U. S. and non-U. S. FIEs on the relative importance of the environmental variables...|$|R
40|$|Abstract. An {{interesting}} {{class of}} production/inventory control problems considers a single product {{and a single}} stocking location, given a stochastic demand with a known non-stationary probability distribution. Under a widely-used control policy {{for this type of}} inventory system, the objective is to find the optimal number of replenishments, their timings and their respective order-up-to-levels that meet customer demands to a required service level. We extend a known CP approach for this problem using <b>a</b> <b>cost-based</b> filtering <b>method.</b> Our algorithm can solve to optimality instances of realistic size much more efficiently than previous approaches, often with no search effort at all. ...|$|R
40|$|Abstract: The {{potential}} of <b>a</b> <b>cost-based</b> optimization <b>method</b> is experimentally demonstrated on a Euro-VI heavy-duty diesel engine. Based {{on the actual}} engine-aftertreatment state, this model-based Integrated Emission Management (IEM) strategy minimizes operational (fuel and AdBlue) costs within emission constraints by real-time computation of optimal air management set points. This work discusses the control design in detail. By EGR-SCR balancing, fuel consumption and operational costs are reduced by 2. 1 % and 1. 5 %, respectively, compared to the baseline strategy over the hot World Harmonized Transient Cycle. Due to its adaptation characteristics, the IEM strategy is robust for varying conditions during real-world operation...|$|R
50|$|In October 2004, the U.S. Supreme Court {{allowed a}} lower court's ruling to stand (by refusing {{to hear the}} appeal) that voided rules {{requiring}} ILECs to lease certain network elements (such as local switching or the high-frequency portion of the loop) <b>at</b> <b>a</b> <b>cost-based</b> regulated wholesale price to CLECs. The FCC agreed {{earlier in the year}} to rewrite rather than appeal the validity of the rules. In December 2004, the FCC released another set of rules which phase out, over a year, all CLEC leasing of ILEC local switching, while preserving access to most copper local loops and some interoffice facilities.|$|R
40|$|In {{order to}} {{guarantee}} efficient query processing together with industrial strength, spatial index structures {{have to be}} integrated into fully-fledged object-relational database management systems (ORDBMSs). A promising way to cope with spatial data can be found somewhere in between replicating and non-replicating spatial index structures. In this paper, we use the concept of gray intervals which helps to range between these two extremes. Based on the gray intervals, we introduce <b>a</b> <b>cost-based</b> decomposition <b>method</b> for accelerating the Relational Interval Tree (RI-tree). Our approach uses compression algorithms for the effective storage of the decomposed spatial objects. The experimental evaluation on real-world test data points out that our new concept outperforms the RI-tree by up to two orders of magnitude with respect to overall query response time and secondary storage space...|$|R
40|$|Abstract — This paper {{addresses}} the motion planning problem while considering Human-Robot Interaction (HRI) constraints. The proposed planner generates collision-free paths that are acceptable and legible to the human. The method extends our previous work on human-aware path planning to cluttered environments. <b>A</b> randomized <b>cost-based</b> exploration <b>method</b> provides <b>an</b> initial path that is relevant {{with respect to}} HRI and workspace constraints. The quality of the path is further improved with a local path-optimization method. Simulation results on mobile manipulators {{in the presence of}} humans demonstrate the overall efficacy of the approach. I...|$|R
40|$|An {{important}} {{issue in the}} design of a mobile computing system is how to manage the location information of mobile clients. In the existing commercial cellular mobile computing systems, a twotier architecture is adopted (Mouly and Pautet, 1992). However, the two-tier architecture is not scalable. In the literatures (Pitoura and Samaras, 2001; Pitoura and Fudos, 1998), a hierarchical database structure is proposed in which the location information of mobile clients within a cell is managed by the location database responsible for the cell. The location databases of different cells are organized into a tree-like structure to facilitate the search of mobile clients. Although this architecture can distribute the updates and the searching workload amongst the location databases in the system, location update overheads can be very expensive when the mobility of clients is high. In this paper, we study the issues on how to generate location updates under the distance-based method for systems using hierarchical location databases. <b>A</b> <b>cost-based</b> <b>method</b> is proposed for calculating the optimal distance threshold with the objective to minimize the total location management cost. Furthermore, under the existing hierarchical location database scheme, the tree structure of the location databases is static. It cannot adapt to the changes in mobility patterns of mobile clients. This will affect the total location management cost in the system. In {{the second part of the}} paper, we present a re-organization strategy to re-structure the hierarchical tree of location databases according to the mobility patterns of the clients with the objective to minimize the location management cost. Extensive simulation experiments have been performed to investigate the re-organization strategy when our [...] ...|$|R
40|$|A {{letter report}} {{issued by the}} Government Accountability Office with an {{abstract}} that begins "Under Medicare's inpatient prospective payment system (IPPS), hospitals generally receive fixed payments for hospital stays based on diagnosis-related groups (DRG), a system that classifies stays by patient diagnosis and procedures. CMS is required to at least annually update DRG payments to address changes {{in the cost of}} inpatient care. CMS uses charge-based weights to update these payments. Cost-based weights are used to set payments in the outpatient prospective payment system (OPPS). The Medicare Prescription Drug, Improvement, and Modernization Act of 2003 required GAO to study IPPS payments in relation to costs. During the course of GAO's work, CMS proposed <b>a</b> new <b>cost-based</b> <b>method</b> for determining DRG weights. This report (1) examines the applicability of CMS's <b>cost-based</b> <b>method</b> [...] used for the OPPS [...] to weight DRGs in the IPPS and (2) evaluates whether CMS's proposed approach is an improvement over its OPPS <b>method</b> for setting <b>cost-based</b> weights. Using fiscal year 2002 cost reports and claims from 2001, 2002, and 2003 to examine the applicability of the OPPS method, GAO estimated costs for 1, 025 IPPS hospitals whose Medicare cost reports most consistently reflected the total charges and number of Medicare stays that these hospitals reported on their claims. To evaluate CMS's proposed approach, GAO analyzed fiscal year 2003 cost reports and 2003 claims for 3, 558 hospitals. ...|$|R
40|$|Wood {{charcoal}} production provides affordable {{energy in}} many developing countries and has substantially contributed to the economy through the provision of rural incomes. In several countries, charcoal production leads to overexploitation of forests due to inefficiencies in processing. This study was undertaken in central Laos to (1) examine and document traditional charcoal production systems; (2) investigate the production capacity, recovery efficiencies and economic gains of existing traditional charcoal production methods; (3) characterize the chemical properties of wood charcoal and investigate the potential for soil restoration and (4) investigate local charcoal producers' perception on forest degradation and their species preferences. Through a socio-economic survey, <b>a</b> <b>cost-based</b> <b>method</b> for economic valuation was undertaken on a range of charcoal production methods currently being used. Laboratory chemical analyses were performed on wood charcoal samples. Results indicated that the traditional mud charcoal mound was used by the majority (82 %) of charcoal producers. Total charcoal production per production cycle varied between 400 (produced from 2. 7 m 3 of wood) and 1600 kg (produced from 18 m 3 of wood), with a mean of 938 kg (� 120) for traditional mud charcoal mounds. The volume of the traditional mud charcoal mounds correlated positively and significantly with total charcoal production (R 2 = 0. 45, p?=? 0. 03), whereas correlated negatively and significantly with the recovery efficiency (R 2 = 0. 58, p?=? 0. 01). On average, the local producers receive a total net benefit of 457, 272 Lao kip (USD 57. 2) in 17 days. We also identified a rice husk mound method of charcoal production, which may not encourage further deforestation while producing rice husk biochar {{that can be used for}} soil restoration. Furthermore, we found that there are significant differences (p < 0. 05) between the sampled wood charcoals in chemical properties, indicating that the potential of using wood charcoal for the restoration of degraded soils varies from charcoal to charcoal...|$|R
40|$|The {{acquisition}} of weapon systems in Major Defense Acquisition Programs (MDAPs) {{is an extremely}} complex procedure involving {{hundreds of thousands of}} individuals, right from contracting through design and manufacturing to the sustainment and finally the disposal of the system. The complete acquisitions process involves a number of milestones spanning the entire life of the program. Traditionally, all defense acquisition programs follow a requirements-driven systems engineering approach, where requirements are formed by the buyer or the Department of Defense (DoD), and <b>a</b> <b>cost-based</b> <b>method</b> is generally used to award contracts and develop systems in a bid to minimize costs. However, even with an approach that focuses on cost, there usually exist tremendous budget overruns and time delays in the development of such large scale complex weapon systems, which has been a major concern for the government in recent times. Recently, there has been a shift of focus from <b>cost-based</b> acquisitions to <b>a</b> price-based and performance-based approach, however, the underlying idea behind these methods is still the fulfillment of requirements. These approaches have their own shortcomings, and problems with MDAPs still persist. Value-Driven Design is a new design philosophy that intends to capture the true preferences of stakeholders by means of a meaningful mathematical function called value function as opposed to using requirements which only serve as proxies to the true preferences. Researchers have proposed the use of value-based approaches for the {{acquisition of}} weapon systems in recent times. This thesis exploits the use of these new approaches in the negotiations phase of defense acquisition, which forms a crucial phase just before the final contract is written. The first part of this research looks <b>at</b> <b>a</b> transition from requirements to value, by proposing a price and performance-based value approach to defense acquisitions, whereas the second part is based completely on value. The aim of the research is to maximize the payoffs to both the government and the contractor developing the weapon system for the government. In this research, the ideas of bargaining from game theory have been proposed in an effort to provide a mathematical foundation to negotiations...|$|R
40|$|Abstract. We present <b>a</b> <b>cost-based</b> {{adaptive}} clustering <b>method</b> {{to improve}} average performance of spatial queries (intersection, containment, enclosure queries) over large collections of multidimensional extended objects (hyper-intervals or hyper-rectangles). Our object clustering strategy {{is based on}} a cost model which takes into account the spatial object distribution, the query distribution, and a set of database and system parameters affecting the query performance: object size, access time, transfer and verification costs. We also employ a new grouping criterion to group objects in clusters, more efficient than traditional approaches based on minimum bounding in all dimensions. Our cost model is flexible and can accommodate different storage scenarios: in-memory or disk-based. Experimental evaluations show that our approach is efficient in a number of situations involving large spatial databases with many dimensions. ...|$|R
40|$|This thesis {{examined}} two research projects: probabilistic {{information retrieval}} modeling and third-order inference on reliability. In {{the first part}} of this dissertation, two research topics in the information retrieval are carried out and experimented on large-scale text data set. First, we conduct an in-depth study of relationship between information of document length and document relevance to user need. Two statistical methods are proposed which incorporates document length as a substantial weighting factor to achieve higher retrieval performance. Second, we utilize the property of survival function to propose <b>a</b> <b>cost-based</b> re-ranking <b>method</b> to promote ranking diversity for biomedical information retrieval, and to model the proximity between query terms to improve retrieval performance. Through extensive experiments on standard TREC collections, our proposed models perform significantly better than the classical probabilistic information retrieval models. In the second part of this dissertation, a small sample asymptotic method is proposed for higher order inference in the stress-strength reliability model, R=P(Y<X), where X and Y are independently distributed. A penalized likelihood method is proposed to handle the numerical complications of maximizing the constrained likelihood model. Simulation studies are conducted on two distributions: Burr type X distribution and exponentiated exponential distribution. Results from simulation studies show that the proposed method is very accurate even when the sample sizes are small...|$|R
40|$|Conventional {{models for}} the {{business}} valuation of technology are usually financially oriented and only measure economic value. Several of these financially oriented approaches have been reviewed by Leloux and Groen (2007). Current monetary (financial) valuation methods for technology include <b>cost-based</b> <b>methods,</b> income-based methods and market-based method...|$|R
40|$|In this paper, {{we develop}} two novel pricing methods for solving an integer program. We {{demonstrate}} the methods by solving an integrated commercial fishery planning model (IFPM). In this problem, a fishery manager must schedule fishing trawlers (determine {{when and where}} the trawlers should go fishing, and when the trawlers should return the caught fish to the factory). The manager must then decide how to process the fish into products at the factory. The objective is to maximise profit. The problem may be modelled as a single integer program, with both the trawler scheduling and production planning parts integrated. Inventory constraints connect the {{two parts of the}} problem. Production planning alone would result in an easy linear program, but due to the trawler scheduling aspect, the IFPM is a hard integer program in the sense that traditional solution methods result in computation times that are far too long to be practical. The two pricing methods developed in this paper are a decomposition-based O'Neill pricing <b>method</b> and <b>a</b> reduced <b>cost-based</b> pricing <b>method.</b> We demonstrate the methods by means of numerical examples for different planning horizons, corresponding to differently sized problems...|$|R
50|$|Rdb {{featured}} one of {{the first}} cost-based optimizers, and after acquisition Oracle introduced <b>a</b> <b>cost-based</b> optimizer in its regular Oracle RDBMS product.|$|R
40|$|This paper studies {{optimizing}} top-k queries in middlewares. While many assorted algorithms {{have been}} proposed, none is generally applicable {{to a wide}} range of possible scenarios. Existing algorithms lack “generality” to support a wide range of access scenarios and systematic “adaptivity” to account for runtime specifics. To fulfill this critical lacking, we aim <b>at</b> taking <b>a</b> <b>cost-based</b> optimization approach: By runtime search over a space of algorithms, cost-based optimization is general across a wide range of access scenarios, yet adaptive to the specific access costs at runtime. While such optimization has been taken for granted for relational queries from early on, it has been clearly lacking for ranked queries. In this paper, we thus identify and address the barriers to realizing such a unified framework. As the first barrier, we need to define a “comprehensive” space encompassing all possibly optimal algorithms to search over. As the second barrier, as a conflicting goal, such a space should also be “focused ” enough to enable efficient search. For SQL queries that are explicitly composed of relational operators, such a space by definition consists of schedules of such operators (or “query plans”). In contrast, top-k queries have no such notion of logical tasks as a unit of scheduling. We thus define logical tasks of top-k queries as building blocks to identify a comprehensive and focused space for top-k queries. We then develop efficient search schemes over such space for identifying the optimal algorithm. Our study indicates that our framework not only unifies but also outperforms existing algorithms specifically designed for their scenarios...|$|R
40|$|Recent scandals {{involving}} {{related party}} transactions (RPTs) have attracted researchers’ and governments’ attention. Because imperfections exist in the legislation of RPTs, business groups might abuse transfer pricing of such transactions for certain purposes. These purposes include earnings management of listed companies that seek to attract investors and profit shifting from subsidiaries to parent companies. This study investigates the impact of corporate governance on the choice of transfer pricing methods in China. I classify transfer pricing methods into two major groups (i. e., market-based and <b>cost-based</b> <b>methods).</b> I hypothesize that companies with weak corporate governance {{are more likely to}} use <b>cost-based</b> pricing <b>methods,</b> which are regarded as subjective and more easily manipulated. According to previous studies on corporate governance, a smaller board size, CEO-Chairman duality (i. e. the CEO and the Chairman of the company are the same person), and a lower percentage of independent directors on the board are indicators of weak corporate governance. Using data collected from annual reports of Chinese listed firms in the Shanghai and Shenzhen Stock Markets from 2003 to 2005, I find that government-controlled companies are more likely to use market-based methods than others. It is consistent with the hypothesis that ownership has an impact on the choice of transfer pricing methods. The results also show that when {{the chairman of the board}} and the CEO of the company is the same person, companies are more likely to use <b>cost-based</b> <b>methods.</b> However, inconsistent with my hypothesis, the results indicate that firms with small boards are more likely to choose <b>cost-based</b> <b>methods</b> than firms with large boards. This study extends prior research on transfer pricing by focusing on the impact of corporate governance. Furthermore, this study suggests that regulators might limit transfer pricing manipulations by stipulating a firm’s corporate governance structure. This research also draws both regulators’ and investors’ attention to the impact of corporate governance on transfer pricing methods...|$|R
30|$|These {{patterns}} {{can then}} {{be used in the}} following way. In a top-down approach, we take a QoS requirement and determine suitable workload-oriented configurations that maintain required values. Furthermore, we enhance this with <b>a</b> <b>cost-based</b> selection function, applicable if many candidate configurations emerge.|$|R
30|$|Firstly, <b>a</b> <b>cost-based</b> {{enumeration}} may be {{very expensive}} in terms of computation resources. Thus, a continuous re-run of the optimization routines is impossible. One may {{have to resort to}} query plan caching schemes or other types of result reuse. However, the application of this approach is hindered by the following considerations.|$|R
40|$|The paper investigates, in a non-technical fashion, the {{economic}} determinants of interchange fees in payment card {{systems and the}} potential need for their regulation. Among other things, it demonstrates that the proposal for <b>a</b> <b>cost-based</b> regulation of interchange fees relies on an erroneous, vertically organized, model of the payment card industry. ...|$|R
30|$|This paper {{presents}} {{basic information}} on the research, classification, and application of the functions of tree species and their communities (mainly forest) in Slovakia. The main aim is a scientific assessment of acquired knowledge regarding the functional effects of forests under real ecological, forest management and socio-economic conditions from various regions in Slovakia; the most up-to-date findings concerning the ecology and economics of natural resources will be applied here. The {{second part of the}} paper presents methodological possibilities for valuation of outdoor recreation in forests. Different methods and methodological approaches suitable to a valuation of recreation based on various principles and criteria (preference and non-preference <b>methods,</b> <b>cost-based</b> <b>methods,</b> revenue-based methods, and direct and indirect methods) are analyzed. A practical application of one indirect preference method (travel cost method) is made to evaluate outdoor recreation in forests in Slovakia.|$|R
30|$|<b>A</b> <b>cost-based</b> {{optimization}} for <b>a</b> particular query or {{a set of}} queries. This is {{the classic}} approach used since 70 s {{in the area of}} physical design tuning. Nowadays, it is the mainstream approach used almost in every industrial database [21, 28, 30, 33, 70] and in a majority of academic studies.|$|R
40|$|We {{address the}} problem of {{combining}} <b>a</b> <b>cost-based</b> simulation model, which makes decisions over time by minimizing a cost model, and rule-based policies, where a knowledgeable user would like certain types of decisions to happen with a specified frequency when averaged over the entire simulation. These rules are designed to capture issues that are difficult to quantify as costs, but which produce more realistic behaviors in the judgment of a knowledgeable user. We consider patterns that are specified as averages over time, which have to be enforced in a model that makes decisions while stepping through time (for example, while optimizing the assignment of resources to tasks). We show how an existing simulation, as long as it uses <b>a</b> <b>cost-based</b> optimization model while stepping through time, can be modified to more closely match exogenously specified patterns...|$|R
50|$|The federal {{government}} adopted feed-in tariffs to offer <b>a</b> <b>cost-based</b> compensation to renewable energy producers. The feed-in remuneration at cost (KEV, Kostendeckende Einspeisevergütung, Rétribution à prix coûtant du courant injecté, Rimunerazione a copertura dei costi per l'immissione in rete di energia elettrica) {{is the primary}} instrument for promoting the deployment of power systems using renewable energy sources.|$|R
5000|$|Under a feed-in tariff, {{eligible}} renewable electricity generators, including homeowners, business owners, {{farmers and}} private investors, are paid <b>a</b> <b>cost-based</b> {{price for the}} renewable electricity they supply to the grid. This enables diverse technologies (wind, solar, biogas, etc.) to be developed and provides investors a reasonable return. This principle was explained in Germany's 2000 Renewable Energy Sources Act: ...|$|R
40|$|The {{purpose of}} the paper is (1) to analyze the {{potential}} and the incentives for a vertically integrated input monopolist to engage in price-discrimination when there is downstream entry, and (2) to examine the question, whether <b>a</b> <b>cost-based</b> regulation of access charges for electricity grids enhances competition in the downstream-market. The paper shows that the incumbent will never block entry if the entrant is more efficient than the incumbent. The {{reason is that the}} input-monopolist can make more profit through input sales than it could generate by producing the downstream product itself. If the entrant does not have a cost advantage either the incumbent or the entrant gets a monopoly position. Providing for a level playing field by means of <b>a</b> <b>cost-based</b> regulation of access charges always creates competition in the downstream-market. The paper also derives the welfare effects of both the liberalization of the downstream-market and the cost-based regulation. discrimination, regulation, vertical integration, electricity, access charges, sabotage,...|$|R
40|$|Nowadays {{learning}} from imbalanced data sets are a relatively a very critical task for many data mining {{applications such as}} fraud detection, anomaly detection, medical diagnosis, information retrieval systems. The imbalanced learning problem is nothing but unequal distribution of data between the classes where one class contains more and more samples while another contains very little. Because of imbalance learning problems, it becomes hard for the classifier to learn the minority class samples. The Aim {{of this paper is}} to review on various techniques which are used for resolving imbalanced learning problem. This paper proposes a taxonomy for various methods used forhandling the class imbalance problem where each method can be categorized depending on the techniques it uses. To handle imbalanced learning problem significant work has been done, which can be categorized into four categories: sampling-based <b>methods,</b> <b>cost-based</b> <b>methods,</b> kernel-based methods, and active learning-based methods. All these methods resolve the imbalanced learning problem efficiently...|$|R
40|$|The {{present study}} was {{undertaken}} in Lao PDR to investigate the impacts of organic and clay-based soil amendments on maize yield, total nutrient uptake and crop water productivity (CWP), and analyze the economic return of such interventions. Structured field experiments were established over two consecutive years (2011 and 2012) with maize as the test crop at the Veunkham and Naphok sites. Ten treatments were applied in a Randomized Complete Block Design with three replications. The treatments were control, rice husk biochar (applied <b>at</b> <b>a</b> rate of 10 t ha- 1), bentonite clay (10 t ha- 1), compost (4 t ha- 1), clay-manure compost (10 t ha- 1), rice husk biochar compost (10 t ha- 1), and their combinations. All treatments were applied in 2011. CWP and the soil water balance of the various treatments were determined using the AquaCrop model. To determine {{the costs and benefits}} of soil amendments over the two cropping seasons <b>a</b> <b>cost-based</b> valuation <b>method</b> was applied. Significant (p < 0. 05) treatment effects in maize grain yields, total nutrient uptake and CWP were observed. At Veunkham, differences in yield between the control and amended soils ranged from 0. 9 to 3. 3 t ha- 1 in 2011 and from 0. 2 to 1. 3 t ha- 1 in 2012, whereas differences at Naphok varied between 0. 2 and 2. 2 t ha- 1 in 2011 and from 0. 2 to 1. 7 t ha- 1 in 2012. Differences in CWP between the amended and control plots at Veunkham varied between 0. 3 and 1. 0 kg m- 3 in 2011 and from 0. 05 to 0. 29 kg m- 3 in 2012, whereas differences at Naphok varied between 0. 1 and 0. 6 kg m- 3 in 2011 and from 0. 1 to 0. 4 kg m- 3 in 2012. Differences between the control and amended soils in yield and the associated CWP can be attributed to the improvements in total N and P uptake, soil pH, exchangeable Ca++ and Mg++, and CEC following the application of soil amendments. At both sites, in most of the treatments, yields and CWP in 2012 were significantly (p < 0. 05) lower than 2011. This difference can be attributed to late season drought. Over the two cropping seasons, the enhancement of maize yield due to soil amendments resulted in net revenues ranging from - 794 to 841 and - 331 to 1391 US$ ha- 1 at Naphok and Veunkham, respectively. The study found that soils amended with low-cost amendments such as compost, rice husk biochar, rice husk biochar compost, and clay-manure compost were economically viable within the first cropping season. In contrast, soils amended with higher-cost amendments such as bentonite clay required up to 5 years to be economically viable. Such variations indicate that maize yield revenues alone are an insufficient incentive for farmers to adopt higher-cost soil amendments. The results of this study confirm that soil amendments can be effective in improving crop yield and the associated CWP. In addition, the income of smallholders can be improved using locally available low-cost soil amendments. These findings provide important information for decision makers wishing to improve agricultural productivity and food security through sustainable intensification...|$|R
30|$|Not all queries may {{be known}} in advance. A good self-tuning {{system should be}} capable to cope with such a situation. Using <b>a</b> <b>cost-based</b> approach, {{we may not be}} able to decide on any {{required}} action at all. At the same time, a strategy may offer a reasonable action before the arrival of such a query, employing some rational assumptions regarding the data distribution.|$|R
40|$|This paper {{addresses}} a novel task of detecting sub-topic correspondence {{in a pair}} of text fragments, enhancing common notions of text similarity. This task is addressed by coupling corresponding term subsets through bipartite clustering. The paper presents <b>a</b> <b>cost-based</b> clustering scheme and compares it with a bipartite version of the single-link method, providing illustrating results. Comment: html with 3 gif figures; generated from 7 pages MS-Word fil...|$|R
