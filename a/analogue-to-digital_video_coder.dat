0|334|Public
40|$|A motion {{compensated}} lifting (MCLIFT) {{framework is}} {{proposed for the}} 3 D wavelet <b>video</b> <b>coder.</b> By using bi-directional motion compensation in each lifting step of the temporal direction, the video frames are effectively de-correlated. With proper entropy coding and bitstream packaging schemes, the MCLIFT wavelet <b>video</b> <b>coder</b> can be scalable in frame rate and quality level. Experimental {{results show that the}} MCLIFT <b>video</b> <b>coder</b> outperforms the 3 D wavelet <b>video</b> <b>coder</b> with the same entropy coding scheme by an average of 1. 1 - 1. 6 dB, and outperforms MPEG- 4 coder by an average of 0. 9 - 1. 4 dB...|$|R
3000|$|To {{overcome}} the limitation, subsampling technique is applied, {{such as the}} MD <b>video</b> <b>coder</b> based on spatial sub-sampling [6] and the MD <b>video</b> <b>coder</b> based on temporal sub-sampling [7]. Furthermore, {{a new approach to}} MDC is proposed in [8], suitable for block-transform coders, which are the basis of current video coding standards. In [9], multiple scalable descriptions are generated from a single SVC-compliant bitstream by mapping scalability layers of different frames to different descriptions. And the new schemes of MD video coding are also presented in [10, 11] based on [...]...|$|R
3000|$|... {{and each}} {{compressed}} GOF, {{the output of}} the <b>video</b> <b>coder</b> is a layered source message x(i) that contains K(i)source packets, each of length b bits, organized into L layers, where the l-th layer contains [...]...|$|R
3000|$|In our scenario, every user {{continuously}} segments its own {{video stream}} into groups of frames (GOF), where each GOF contains Ngofframes, and compresses every GOF using a scalable <b>video</b> <b>coder.</b> For each user U [...]...|$|R
40|$|A <b>video</b> <b>coder</b> is {{presented}} that combines mesh-based motion-com-pensated temporal ltering, phase-diversity multihypothesis mo-tion compensation, and an embedded 3 D wavelet-coefcient coder. The key contribution {{of this work}} is {{the introduction of the}} phase-diversity multihypothesis paradigm into motion-compensated tem-poral ltering, which is achieved by deploying temporal ltering in the domain of a spatially redundant wavelet transform. A regu-lar triangle mesh is used to track motion between frames, and an afne transform between mesh triangles implements motion com-pensation within a lifting-based temporal transform. Experimental results reveal that the incorporation of phase-diversity multihy-pothesis into mesh-based motion-compensated temporal ltering signicantly improves the rate-distortion performance of the 3 D <b>video</b> <b>coder.</b> 1...|$|R
40|$|Abstract—A {{scalable}} <b>video</b> <b>coder</b> {{consisting of}} motion-compensated temporal filtering coupled with structured vector quantization plus a linear mapping of quantizer indexes that minimizes simultaneously source and channel distortions is presented. The linear index assignment {{takes the form}} of either a direct, uncoded mapping or a coded mapping via Reed–Muller codes. Experimental results compare the proposed system to a similar scheme using unstructured vector quantization as well as to a prominent scalable <b>video</b> <b>coder</b> protected by more traditional convolutional codes. The proposed system consistently outperforms the other two schemes by a significant margin for very noisy channel conditions. Index Terms—Joint source-channel coding (JSCC), scalable video coding. I...|$|R
40|$|Abstract: This paper {{presents}} a new video coding technique using multiwavelet transform and multi-stage vector quantization. Three types of redundancies {{that are common}} in video sequence are spatial, temporal and psycho visual redundancies. In this work, the spatial redundancy in the video is minimized using multiwavelet transform. The transform coefficients are then quantized using multi-stage vector quantization scheme. Motion estimation / compensation reduce temporal redundancy by exploiting interpicture correlation. Kite cross diamond search is the block matching algorithm used for motion estimation. The objective is to develop low bit rate <b>video</b> <b>coder</b> with acceptable visual quality. The performance of the proposed method is compared with wavelet based <b>video</b> <b>coder...</b>|$|R
40|$|Abstract A {{scalable}} <b>video</b> <b>coder</b> {{consisting of}} motion-compensated temporal ltering coupled with structured vector quantization plus a linear mapping of quantizer indices that minimizes simultaneously source and channel distortions is pre-sented. The linear index assignment {{takes the form}} of either a direct, uncoded mapping or a coded mapping via Reed-Muller codes. Experimental results compare the proposed system to a similar scheme using unstructured vector quantization as well as to a prominent scalable <b>video</b> <b>coder</b> protected by more traditional convolutional codes. The proposed system consistently outperforms the other two schemes by a signicant margin for very noisy channel conditions. Index Terms joint source-channel coding, scalable video cod-ing I...|$|R
40|$|In 3 D multi-view video coding (MVC), {{disparity}} estimation (DE) {{are used}} to exploit the correlation among different view sequences. The DE process greatly increases the computational complexity of the MVC. In this paper, a novel independent low complexity multiview <b>video</b> <b>coder</b> (I-MVC) is introduced. In the proposed MVC, the coding complexity is shifted from the encoder side to the decoder side. Instead of disparity estimation, the proposed I-MVC deploys independent component analysis (ICA) on the video streams to remove {{the correlation between the}} view sequences. The correlated (dependent) video sequences are decomposed into uncorrelated (independent) sequences and a mixing matrix. Each independent sequence is independently encoded by the H. 264 /AVC <b>video</b> <b>coder.</b> Then the mixing matrix is used at decoder to jointly decode the received independent sequences. Our experimental results show that the proposed I-MVC has better coding efficiency than conventional 3 D multi-view <b>video</b> <b>coder.</b> The IMVC gives more than 21 % savings in overall bit rate and reduces the MVC computational complexity by 49 % with less than 0. 2 dB loss in the video peak signal to noise ratio...|$|R
40|$|Model-based video {{synthesis}} {{is combined}} with block-based motion-compensated video coding for ratedistortion efficient transmission of head-and-shoulder sequences. Two frames are utilized for block-based motioncompensated prediction of the current video frame where one frame is the previously reconstructed one and the other frame is provided by a model-based coder. The model-based coder uses a parameterized 3 -D head model for the estimation of the motion {{as well as the}} facial expressions of a person. A synthetic output frame is rendered serving as a second reference frame for block-based motion compensation of a <b>video</b> <b>coder.</b> The coder is based on the H. 263 syntax which is extended to multi-frame motion-compensated prediction incorporating a picture reference parameter. Ratedistortion optimization is employed for the coding control of the <b>video</b> <b>coder</b> providing robustness against model failures. Hence, the coding efficiency of the proposed combined codec never degrades below what is achie [...] ...|$|R
40|$|The {{feedback}} loop for temporal prediction of traditional implementations of an MPEG-compliant <b>video</b> <b>coder</b> requires conversion of {{images from the}} spatial domain to the transform domain {{and then back to}} the spatial domain due to the restriction of motion estimation schemes performed only in the spatial domain, severely limiting the throughput of the coder. However, it was shown that the low-complexity DCTbased motion estimation scheme (DXT-ME) can remove this bottleneck and thus reduce the overall coder complexity. In this paper, we develop efficient DCTbased motion compensation algorithms to complete the fully DCT-based motion compensated <b>video</b> <b>coder.</b> We demonstrate that the performance of this new coder structure is comparable to the conventional one while the overall coder complexity is lower. 1...|$|R
30|$|Since our {{proposed}} model targets video service, {{it takes}} advantage of one characteristic of videos: their similarity between temporally close frames. In our method, referenced frames for complexity can be searched using the GOP size and the intra-period, which are parameters of the <b>video</b> <b>coder</b> according to [9, 10].|$|R
40|$|Recent {{algorithms}} {{for video}} coding achieve a high-quality transmission at moderate bit rates. On the other hand, those coders {{are very sensitive}} to transmission errors. Many research projects focus on methods to conceal such errors in the decoded video sequence. Motion compensated prediction is commonly used in video coding to achieve a high compression ratio. This thesis proposes an algorithm which uses the motion compensated prediction of a given <b>video</b> <b>coder</b> to predict a sequence of several complete frames, based on the last correctly decoded images, during a transmission interruption. The proposed algorithm is evaluated on a <b>video</b> <b>coder</b> which uses a dense motion field for motion compensation. A drawback of predicting lost fields is the perceived discontinuity when the decoder switches back from the prediction to a normal mode of operation. Various approaches to reduce this discontinuity are investigated...|$|R
40|$|For a {{scalable}} <b>video</b> <b>coder</b> {{to remain}} efficient {{over a wide}} range of bit-rates, some form of scalability must exist in the motion information. We propose a wavelet-based highly scalable <b>video</b> <b>coder</b> with scalable motion coding. Our proposed method involves the construction of quality layers for the coded wavelet sample data and a separate set of quality layers for scalably coded motion parameters. When the motion layers are truncated, the decoder receives a quantized version of the motion parameters used to gen-erate the wavelet sample data. A linear model is used to infer the impact of motion quantization on reconstructed video distortion. An optimal tradeoff between the motion and subband bit-rates may then be found. Experimental results indicate that the cost of scal-ability is small. At low bit-rates, significant improvements are ob-served relative to lossless coding of the motion information. 1...|$|R
40|$|For a {{scalable}} <b>video</b> <b>coder</b> {{to remain}} efficient {{over a wide}} range of bitrates, the motion information should be represented in a scalable manner. Indeed, especially at low bitrates tradeoffs should be made between motion information representation and texture information accuracy. Consequently, motion vector scalability has emerged as an important research topic, in conjunction with fully scalable video compression schemes. In this paper, a new scheme providing motion vector scalability is proposed. Starting from the MC-EZBC scalable wavelet <b>video</b> <b>coder</b> [1], multiple motion layers are constructed according to the importance of motion information. The overhead associated with this layered representation is proven to be negligible. Hence, the rate-distortion performance at high bit-rates is about {{the same as that of}} the scheme without motion information scalability, while at low bitrates the scheme benefits from this scalable coding strategy...|$|R
40|$|In current video codecs, the {{temporal}} correlation between successive frames {{of a video}} sequence is exploited by means of predictive coding. Successful utilization of this paradigm in a wireless and mobile scenario is impaired due to both the computationally-demanding encoder-side motioncompensation procedure and the severe degradation of the decoded video quality when losses of encoder-decoder synchronization occur. The application of distributed source coding principles has been recently proposed as solution to both problems. In this paper, a wavelet-domain <b>video</b> <b>coder</b> is investigated that uses continuous-valued syndromes to efficiently code the coefficients at the encoder. Motion compensation, to form the side-information that allows for reconstruction, takes instead place at the decoder. The proposed <b>video</b> <b>coder,</b> whose performance is similar to other distributed video coders found in literature, does not require any feedback channel and produces a spatial-quality scalable stream. 1...|$|R
40|$|We {{focus on}} all-IP UMTS cell {{capacity}} evaluation, considering two real-time services: telephony and video telephony. For each service, we introduce {{two levels of}} quality: standard and premium. This differentiation is achieved by using the two-layers SNR scalability featured by H. 263 <b>video</b> <b>coder</b> and two different bit-rate modes for Adaptive Multi-Rate (AMR) speech coder...|$|R
40|$|A novel robust {{scheme is}} presented, for the {{efficient}} transmission of image sequences over unreliable channels. The proposed scheme {{is based on}} an efficient error-resilient wavelet <b>video</b> <b>coder</b> and is able to produce embedded bitstreams. The robust coder is evaluated for the transmission of image sequences over binary symmetric channels and is shown to have very promising performance. 1...|$|R
40|$|This paper {{presents}} a new structure for a {{low bit rate}} <b>video</b> <b>coder.</b> The new structure uses quadtree decomposition for motion estimation and compensation. This significantly reduces the computational complexity of the coding operation. The new coding scheme yields high subjective quality at bit rates compatible with RDSI channels. Simulations results demonstrate {{the effectiveness of the}} new coder...|$|R
40|$|A video {{communication}} {{system based on}} combined source- and channel coding is proposed. The proposed system uses a subband <b>video</b> <b>coder</b> structure in combination with powerconstrained channel-optimized vector quantization (PCCOVQ) to achieve efficient and robust transmission of the video signal over a channel with multidimensional PAM signaling. The side information is protected by using a sufficiently large minimum distance of the PAM signal constellation. This ensures error free transmission for the channel-optimized case, and graceful degradation for channel mismatch situations. For the main information, however, PCCOVQ with direct mapping from the source parameter space to the channel (modulation) space is used. A {{video communication}} system based on the H. 263 <b>video</b> <b>coder</b> {{is used as a}} reference. The proposed system compares favorably to the reference system, and offers graceful degradation for channel mismatch situations. 1. INTRODUCTION Combined source and channel coding systems have [...] ...|$|R
40|$|Overcomplete signal {{decomposition}} using matching pursuits {{has been}} shown to be an efficient technique for coding motion residual images in a hybrid <b>video</b> <b>coder.</b> Unlike orthogonal decomposition, matching pursuit uses an in-the-loop modulus quantizer which must be specified before coding begins. This complicates the quantizer design, since the optimal quantizer depends on the statistics of the matching pursuit coefficients which in turn depend on the in-loop quantizer actually used. In this paper, we address the modulus quantizer design issue, specifically developing frame-adaptive quantization schemes for the matching pursuit <b>video</b> <b>coder.</b> Adaptive dead-zone subtraction is shown to reduce the information content of the modulus source, and a uniform threshhold quantizer is shown to be optimal for the resulting source. Practical 2 -pass and 1 -pass algorithms are developed to jointly determine the quantizer parameters and the number of coded basis functions in order to minimize coding distor [...] ...|$|R
40|$|In this paper, {{we propose}} a low bit-rate {{embedded}} video coding scheme that utilizes a threedimensional (3 D) {{extension of the}} set partitioning in hierarchical trees (SPIHT) algorithm which has proved so successful in still image coding. Three-dimensional spatio-temporal orientation trees coupled with powerful SPIHT sorting and refinement renders 3 D SPIHT <b>video</b> <b>coder</b> so efficient that it provides comparable performance to H. 263 objectively and subjectively when operated at the bit-rates of 30 to 60 kilobits per second with minimal system complexity. Extension to color-embedded video coding is accomplished without explicit bit allocation, {{and can be used}} for any color plane representation. In addition to being rate scalable, the proposed <b>video</b> <b>coder</b> allows multiresolutional scalability in encoding and decoding in both time and space from one bit-stream. This added functionality along with many desirable attributes, such as full embeddedness for progressive transmission, precise [...] ...|$|R
40|$|This paper {{describes}} a transmission scheme for Internet video streaming that provides an acceptable video quality {{over a wide}} range of connection qualities. The proposed system consists of a scalable <b>video</b> <b>coder</b> which uses a fully standard compatible H. 263 coder in its base layer. The scalable <b>video</b> <b>coder</b> is combined with unequal error protection using Reed-Solomon codes applied across packets. We present and verify a two-state Markov model for packet losses over Internet connections. The relation between packet loss and picture quality at the decoder for an unequally protected layered video stream is derived. Experimental results show that, with our approach, the picture quality of a streamed video degrades gracefully as the packet loss probability of an Internet connection increases. Keywords: Scalable video coding, unequal error protection, erasure decoding, graceful degradation, Internet model SPIE Visual Communications and Image Processing 99, January 1999, San Jose, CA 1. INTRO [...] ...|$|R
40|$|Abstract: Problem statement: Motion {{estimation}} {{and compensation}} {{is the most}} computationally complex module of <b>video</b> <b>coder.</b> In this study, an innovative algorithm was proposed for a further complexity reduction of the Motion Estimation (ME) module of <b>video</b> <b>coder</b> by employing motion detection prior to motion compensation. Approach: A Motion Detection (MD) module {{can be added to}} the <b>video</b> <b>coder</b> in order to decide whether the current block contains motion or is with zero motion. This study propounded a MD module that depends on motion activity. Generally, the correlation of the two consecutive frames is a good criterion to measure motion activity. We applied the correlation as a threshold to detect the motion activity. To assure the correct motion vector and thus better video quality, to calculate motion vector of motion blocks this study also proposed a new block matching motion estimation criterion based on the Radon transform using projection-matching method. However, computationally complex, the method had the ability to be implemented in real time by using pipeline architecture. Results: A comparative result showed that the MD module reduced the number of search points for motion estimation and compared with some well-known algorithm that uses minimum absolute difference criterion, the new criterion can provide much higher performance. Conclusion: The result showed that this proposed scheme can simplify the encoder complexity maintaining good video quality. Key words: Motion detection, block motion estimation, radon transfor...|$|R
40|$|This paper {{focuses on}} the problem of {{estimating}} the distortion for coded and non-coded frames in a <b>video</b> <b>coder</b> that employs variable frameskip. The distortion for coded frames is given by classic rate-distortion models, however the distortion for non-coded frames has not been considered. Based on the optical flow equation, we formulate a method for estimating the distortion of the non-coded frames...|$|R
40|$|We {{present a}} {{transmission}} scheme for Internet video streaming that provides an acceptable video quality {{over a wide}} range of connection qualities. The proposed system consists of a scalable <b>video</b> <b>coder</b> which uses a fully standard compatible H. 263 coder in its base layer. The scalable <b>video</b> <b>coder</b> is combined with unequal error protection using Reed-Solomon codes applied across packets. A theoretical framework which relates packet loss of an unequally protected layered video stream to picture quality at the decoder is presented. Simulation results show that, with our approach, the picture quality of a streamed video degrades gracefully as the packet loss probability of an Internet connection increases. Packet Video Workshop 99, April 1999, New York 1 Introduction The demand for Internet video streaming services has rapidly grown over the past few years. Since the Internet supports real-time services only in a best-effort manner, it remains to be a challenging task to design high-qualit [...] ...|$|R
40|$|Abstract—Embedded coders {{provide a}} better {{rate-distortion}} tradeoff while the coded bit stream can be truncated at any point without a significant perceptible distortion. In this work, we investigate rate control for an embedded wavelet <b>video</b> <b>coder</b> by converting the rate control problem to a bit allocation problem for each frame. Then, a computationally efficient rate control algorithm is derived by exploiting the rate-distortion performance of the embedded wavelet coder and the frame dependency between the reference frame and the predictive frame. Experiments are performed to demonstrate the superior performance of the embedded wavelet <b>video</b> <b>coder</b> with the proposed rate control scheme. It is shown that the proposed rate control strategy outperforms the fixed allocation rate control by 0. 1 – 0. 4 dB {{for a variety of}} sequences, and the performance gain can be as large as 1. 3 – 2. 7 dB around scene changes. Index Terms — Embedded coding, MPEG, multimedia, rate control, video coding, video compression, wavelet transform...|$|R
40|$|In this paper, a {{fast and}} {{efficient}} method for selecting the encoding modes and the quantizers for the ITU H. 263 1 standard is presented. H. 263 {{is a very}} low bit rate <b>video</b> <b>coder</b> which produces satisfactory results at bit rates around 24 kbits/second for low motion quarter common intermediate format (QCIF) color sequences such as "Mother and Daughter". Two major target applications for H. 263 are video telephony using {{public switched telephone network}} lines and video telephony over wireless channels. In both cases, the channel bandwidth is very small, hence the efficiency of the <b>video</b> <b>coder</b> needs to be as high as possible. The presented algorithm addresses this problem by finding the smallest frame distortion for a given frame bit budget. The presented scheme is based on Lagrangian Relaxation and Dynamic Programming (DP). It employees a fast evaluation of the operational rate distortion curve in the DCT domain and a fast iterative search which is based on a Bezier function. Keywords: [...] ...|$|R
40|$|In {{this paper}} we {{describe}} the ongoing work on a new par-adigm for compressing the motion predicted error in a <b>video</b> <b>coder,</b> referred to as MMP-Video. This new coding algorithm uses the MultidimensionalMultiscale Parser image coding al-gorithm to encode the residue error, in a H. 264 /AVC based <b>video</b> <b>coder.</b> MMP has shown to perform very well as a universal still image coding method, particularly when it is combined with Intra prediction schemes. In addition, previously published preliminary results have also presented MMP as a promising video coding method. In this paper, we propose new dictionary updating tech-niques for MMP-video. Along with other functional opti-mizations, these techniques allow for a significant improve-ment in the encoder performance. Thus, {{we were able to}} achieve considerable gains over H. 264 /AVC for B slices, spe-cially formedium and high bit-rates, while maintaining equiv-alent performance for the P slices. Index Terms — Video coding, approximate patternmatch-ing, Multidimensional Multiscale Parse...|$|R
40|$|We {{consider}} {{the problem of}} full-duplex video transmission over the Internet, under real-time delay constraints. In this work we present {{the design of a}} complete communications system, whose salient features are: (a) a soft real-time transport protocol, whose generated trac characteristics are identical to those of bulk transfers using TCP/IP, thus ensuring complete fairness to other ows in the network; (b) a <b>video</b> <b>coder</b> resilient to moderate amounts of loss of data that are induced by the soft real-time constraint, and also by a continuous probing of the available channel capacity; (c) a unied control module, responsible for both congestion avoidance as well as coder conguration tasks; and (d) very low computational complexity. A key component of our system design is a predictive multiple description <b>video</b> <b>coder</b> working under feedback control. The whole system is implemented on a Linux PC, only in software, without making use of priviliged system calls (e. g., to raise the [...] ...|$|R
40|$|The Bath University Matching Pursuit (BUMP) project aims at {{developing}} new matching pursuit (MP) algorithms for still image and video compression. Compared to traditional MP coding, BUMP has many new features {{that have been}} designed {{with the aim of}} producing an efficient MP representation with reduced complexity. In this paper, we study in depth the characteristics the of bit rate change along the coding process of BUMP coder, and then propose a mathematical framework for describing the relationship between the number of coded atoms and the resultant bit rate. The framework has a very simple form and demonstrates very high modeling accuracy, which allows a precise estimation of the number of bits to be used throughout the coding process. We then present an adaptive algorithm for predicting the number of bits for use in our hybrid wavelet/MP <b>video</b> <b>coder.</b> Experiments show that the proposed rate estimation scheme is able to provide an extremely accurate estimation for the BUMP based <b>video</b> <b>coder.</b> </p...|$|R
40|$|Lossy {{compression}} {{is widely}} applied for coding visual information in {{applications such as}} entertainment {{in order to achieve}} a high compression ratio. In this case, the video quality worsens as the compression ratio increases. Rate control tries to use the bit budget properly so the visual distortion is minimized. Rate control for H. 264, the state-of-the-art hybrid <b>video</b> <b>coder,</b> is investigated. Based on the Rate-Distortion (R-D) slope analysis, an operational rate distortion optimization scheme for H. 264 using Lagrangian multiplier method is proposed. The scheme tries to find the best path of quantization parameter (OP) options at each macroblock. The proposed scheme provides a smoother rate control that is able to cover a wider range of bit rates and for many sequences it outperforms the H. 264 (JM 92 version) rate control scheme in the sense of PSNR. The Bath University Matching Pursuit (BUMP) project develops a new matching pursuit (MP) technique as an alternative to transform video coders. By combining MP with precision limited quantization (PLO) and multi-pass embedded residual group encoder (MERGE), a very efficient coder is built that is able to produce an embedded bit stream, which is highly desirable for rate control. The problem of optimal bit allocation with a BUMP based <b>video</b> <b>coder</b> is investigated. An ad hoc scheme of simply limiting the maximum atom number shows an obvious performance improvement, which indicates a potential of efficiency improvement. An in depth study on the bit Rate-Atom character has been carried out and a rate estimation model has been proposed. The model gives a theoretical description of how the oit number changes. An adaptive rate estimation algorithm has been proposed. Experiments show that the algorithm provides extremely high estimation accuracy. The proposed R-D source model is then applied to bit allocation in the BUMP based <b>video</b> <b>coder.</b> An R-D slope unifying scheme was applied to optimize the performance of the coder'. It adopts the R-D model and fits well within the BUMP coder. The optimization can be performed in a straightforward way. Experiments show that the proposed method greatly improved performance of BUMP <b>video</b> <b>coder,</b> and outperforms H. 264 in low and medium bit rates by up to 2 dB. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
30|$|The {{proposed}} <b>video</b> <b>coder</b> {{is based}} on the LTW image coding algorithm[16]. As in LTW encoder, the proposed video codec uses a scalar uniform quantization by means of two quantization parameters: rplanes and Q. The finer quantization consists in applying a scalar uniform quantization, Q, to all wavelet coefficients. The coarser quantization {{is based on}} removing the least significant bit planes, rplanes, from wavelet coefficients.|$|R
40|$|In {{this paper}} {{we present a}} novel object based <b>video</b> <b>coder.</b> This coder {{is based on an}} analysis-synthesis {{approach}} which allows for decoupling shape, motion and texture informations. These informations are then coded using wavelets decomposition and progressive coding allowing to have full scalability (object, SNR, temporal, and bitstream scalabilities). Experimental results show the benefits of proposed scheme providing performances close to state of the art video coders while providing scalability...|$|R
40|$|Wavelet {{transform}} is {{a powerful}} instrument in catching zero-dimensional singularities. Ridgelets are a powerful instrument in catching and representing monodimensional singularities in bidimensional space. In this {{paper we propose a}} hybrid <b>video</b> <b>coder</b> scheme using ridgelet transform for the first approximation of line-edge singularities in displaced frame difference images. We demonstrate the potential of ridgelets and results show substantial improvements when compared to wavelet only. based coder. 1...|$|R
40|$|Over {{the past}} decade, the growing {{interests}} in realistic visual communication systems have {{lead to the}} rapid development of 3 D visual compression techniques. A stereoscopic system {{is one way of}} stimulating 3 D perception. Without exploiting the high redundancy in a stereo pair, the amount of data required to store or transmit it is doubled, when compared to the same in monocular images. In this paper, we present a new technique for coding stereo video sequences based on Discrete Wavelet Transform (DWT). The proposed technique exploits Zerotree Entropy Coding (ZTE) that makes use of the wavelet block concept to achieve low bit rate stereo video coding. One of the two image streams, namely the main stream, is independently coded by a modified Zerotree <b>video</b> <b>coder</b> and the second stream, namely the auxiliary stream, is predicted based on disparity compensation. The residual image of auxiliary stream is then coded by a modified Zerotree <b>video</b> <b>coder.</b> Results show that the proposed encoder can achieve 50 % bandwidth reduction compared to the ZTE based monoscopic compression encoder...|$|R
