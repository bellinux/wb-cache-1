19|10000|Public
50|$|<b>Another</b> <b>topic</b> <b>of</b> <b>interest</b> for Borkenau was {{engaging}} in an intellectual critique of Toynbee and Oswald Spengler's work about when and why civilizations weaken and end. The latter critique was published posthumously by his friend, Richard Löwenthal. Borkenau became increasingly active {{as a freelance}} author living in Paris, Rome and Zurich, where he died suddenly of heart failure in 1957.|$|E
5000|$|Energy {{consumption}} and efficiency is <b>another</b> <b>topic</b> <b>of</b> <b>interest</b> in archaeometallurgy. Tree felling and land clearing experiments involving comparison of stone, bronze, and steel axes are popular {{with a number}} of archaeologists [...] In these types of experiments, factors such as time spent and oxygen intake of the researchers are taken into account to try to find similarities in past life ways use of energy.|$|E
5000|$|The {{principal}} subjects {{studied in}} this early development {{of his research}} program was electrode kinetics which has a connection to Bockris’ thesis work; then a new topic, very high temperature chemistry, some of it remains cogent to this day. <b>Another</b> <b>topic</b> <b>of</b> <b>interest</b> is salting out and salting in changes in solubility in solution due {{to the presence of}} electrolytes. [...] In this early crop of students Roger Parsons became an eminent electrochemist and received appointments as chairman of the Faraday Division of the Chemical Society and a Fellow of the Royal Society.|$|E
5000|$|The CPNP Board of Directors may appoint {{committees}} {{to fulfill a}} defined purpose for the organization, in line with its missions and vision. The committees {{also serve as a}} platform for CPNP members to engage with one <b>another</b> on <b>topics</b> <b>of</b> <b>interest</b> to them. As of April 2017, CPNP has appointed 15 committees: ...|$|R
40|$|The {{starting}} material {{used for the}} synthesis of the derivatives presented in this Thesis is the ring compound hexachlorocyclotriphosphazene, (NPCI 2) 3 (Figure 1). Because the chlorine atoms on the phosphorus atom can be replaced easily by other groups this molecule {{has been the subject}} of extensive research. <b>Another</b> important <b>topic</b> <b>of</b> <b>interest</b> is the thermal ringopening polymerization of (NPCI 2) 3 which affords a reactive linear poly(dichlorophosphazene) (IPCI 2) n. [...] . Zie: Summary. ...|$|R
50|$|The inter-limb {{coordination}} {{in human}} locomotion, questioning whether the human gait {{is based on}} quadruped locomotion, is <b>another</b> major <b>topic</b> <b>of</b> <b>interest.</b> A recent research indicates that inter-limb coordination during human locomotion is organized {{in a similar way}} to that in the cat, promoting the view that the arm swing may be a residual function from quadruped gait. Another work on the control mechanisms of arm movements during walking corroborated the former findings, showing that central pattern generator (CPG) might be involved in cyclic arm swing. However, these findings do not imply vestigiality of arm swing, which appears to be debateful after the 2003 evidences on the function of arm swing in bipedal locomotion.|$|R
50|$|Research on {{how exactly}} {{learners}} acquire {{a new language}} spans {{a number of different}} areas. Focus is directed toward providing proof of whether basic linguistic skills are innate (nature), acquired (nurture), or {{a combination of the two}} attributes. Cognitive approaches to SLA research deal with the processes in the brain that underpin language acquisition, for example how paying attention to language affects the ability to learn it, or how language acquisition is related to short-term and long-term memory. Sociocultural approaches reject the notion that SLA is a purely psychological phenomenon, and attempt to explain it in a social context. Some key social factors that influence SLA are the level of immersion, connection to the L2 community, and gender. Linguistic approaches consider language separately from other kinds of knowledge, and attempt to use findings from the wider study of linguistics to explain SLA. There is also a considerable body of research about how SLA can be affected by individual factors such as age, learning strategies, and affective factors. A commonly discussed topic regarding age in SLA is the critical period hypothesis, which suggests that individuals lose the ability to fully learn a language after a particular age in childhood. <b>Another</b> <b>topic</b> <b>of</b> <b>interest</b> in SLA is the differences between adult and child learners. Learning strategies are commonly categorized as learning or communicative strategies, and are developed to improve their respective acquisition skills. Affective factors are emotional factors that influence an individual's ability to learn a new language. Common affective factors that influence acquisition are anxiety, personality, social attitudes, and motivation.|$|E
40|$|Theory of Viscoelasticity: An Introduction, Second Edition {{discusses}} the integral form of stress strain constitutive relations. The book presents {{the formulation of}} the boundary value problem and demonstrates the separation of variables condition. The text describes the mathematical framework to predict material behavior. It {{discusses the}} problems to which integral transform methods do not apply. <b>Another</b> <b>topic</b> <b>of</b> <b>interest</b> is the thermoviscoelastic stress analysis. The section that follows describes the heat conduction, glass transition criterion, viscoelastic Rayleigh waves, optimal st...|$|E
40|$|Most {{research}} into lexical pattern extraction has been performed on general corpora, but recently {{research into}} extracting patterns from biomedical texts has become <b>another</b> <b>topic</b> <b>of</b> <b>interest.</b> I present an algorithm for extracting meronym pairs (part-whole relationship, e. g. finger and hand) from biomedical texts. This algorithm {{is based upon}} a method for the extraction of meronym pairs from general corpora. I evaluate the validity of using methods developed for general corpora on more domain-specific texts {{by comparing the results}} of the original method with our algorithm. My findings suggest that the type of corpus is not the main factor in performance, but the specific difficulty of using simple methods is. ...|$|E
50|$|Likhterman {{also wrote}} over 100 other {{scientific}} {{works on the}} role of the nervous system, with an emphasis on matters relating to balneology and physiotherapy in the treatment and prevention of nervous and endocrine disorders. <b>Another</b> important <b>topic</b> <b>of</b> <b>interest</b> for Likhterman was the effects of high and ultrahigh frequency currents on healthy and diseased organisms, research which resulted in the development of various methods for the direct and indirect applications of such electrical energy for medical treatment. In particular, he developed a calcium collar electrode method and studied reflex effects of electrophoresis. He also studied the effect of energy treatment upon the brain, including the use of such therapies in conjunction with spa treatment, for treatment of neurasthenic syndromes, trauma and other disorders.|$|R
50|$|The Centre for Theoretical and Computational Chemistry (CTCC) {{was founded}} by the Norwegian Research Council in 2007. The {{duration}} of the project is ten years. The CTCC is split in two units. One unit {{is located at the}} Department of Chemistry, University of Oslo(Leader: Prof. Trygve Helgaker), the other part is based at the Department of Chemistry, University of Tromsø (Leader: Prof. Kenneth Ruud). The CTCC is devoted {{to a wide range of}} research in the fields of theoretical and computational chemistry. One main focus is on method development in electronic structure theory. The CTCC is a key contributor to the Dalton (program) electronic structure program system. <b>Another</b> important <b>topic</b> <b>of</b> <b>interest</b> is the description of molecular dynamics with considerationof quantum effects. Applications of the electronic structure and molecular dynamics methods to chemical problems is another main occupation of researchers working at the CTCC.|$|R
30|$|Digital {{beamforming}} (DBF) {{technology offers}} {{a significant improvement}} in performance over analog beamforming technology [1]. Many applications, including modern wireless communications, radar systems, surveillance, radio astronomy, and sonar, {{take advantage of this}} technology to gain benefits in terms of beam steering, improved signal-to-interference ratio (SIR), and interference rejection [2]. Recently, multi-input multi-output (MIMO) technology has attracted the attention of many researchers because it offers the ability to transmit multiple probe signals via transmit antennas, thereby providing additional diversity [3]. At the receiving end, DBF technology has been applied to sample combinations of reflected array signals from each element of an array to achieve different functions [4, 5]. <b>Another</b> research <b>topic</b> <b>of</b> <b>interest</b> is a type of flexible array called a frequency diverse array (FDA), which was proposed in [6, 7]. A small frequency increment is applied across all array elements to obtain a range-angle-dependent beam pattern. DBF technology has thus been used to enhance beamforming performance [8 – 10].|$|R
40|$|This {{paper is}} based on an hour address given at the Sixth Conference on Formal Power Series and Algebraic Combinatorics, held at DIMACS in 1994. It is written {{primarily}} for an audience of combinatorialists. Our hope is to publicise some intriguing enumerative conjectures which arise {{in the study of the}} homology representations of the poset of (set) partitions with an even number of blocks. The conjectures themselves are completely elementary, and can be stated without reference to the representation-theoretic context in which they arose. These conjectures seem to have connections to the theory of Andre permutations, which is currently enjoying a renewed attention in the literature, and questions concerning the cd-index, <b>another</b> <b>topic</b> <b>of</b> <b>interest</b> in recent research. Homology representations of posets of partitions are more elegantly computed by exploiting the machinery of symmetric functions, and in particular the role of the plethysm operation in describing wreath product representati [...] ...|$|E
30|$|Studying {{concrete}} nonlinear difference equations {{and systems}} {{is a topic}} of a great recent interest (see, e.g., [1 – 46] and the references therein). Studying systems of difference equations, especially symmetric and close to symmetric ones, is a topic of considerable interest (see, e.g., [2, 6, 7, 10, 12 – 16, 18, 19, 23, 24, 26 – 29, 31 – 38, 40, 41, 44, 46]). <b>Another</b> <b>topic</b> <b>of</b> <b>interest</b> is solvable difference equations and systems and their applications (see, e.g., [1 – 5, 7, 17, 20, 21, 23 – 27, 29 – 37, 39 – 46]). Renewed interest in the area started {{after the publication of}} [20] where a formula for a solution of a difference equation was theoretically explained. The most interesting thing in [20] was a change of variables which reduced the equation to a linear one with constant coefficients. Related ideas were later used, e.g., in [1, 4, 7, 17, 21, 23 – 27, 29 – 37, 39 – 45].|$|E
40|$|New {{computational}} {{methods are}} continuously developed {{in order to}} solve problems in different engineering fields. One of these fields is gas turbines, where {{the challenge is to}} make gas turbines more efficient and to reduce emissions that are bad for the environment. One of the main parts of a gas turbine that can be improved is the combustion chamber. In order to optimize the combustion chamber, both experimental and numerical methods are called for. Numerical optimization implies the necessity to model the most important phenomena in combustion chambers such as turbulent swirling flow, chemical reactions, heat transfer, and so on. In this project we try to design a simple yet accurate model, for a generic combustor of industrial interest, that may be tested in a relatively short time and that yields reliable results. An important topic is here to perform grid sensitivity studies {{to make sure that the}} model yields mesh independent results. <b>Another</b> <b>topic</b> <b>of</b> <b>interest</b> is the choice of turbulence model and how this choice affects the grid sensitivity. Heat transfer models are also important to evaluate. Different turbulence models and heat transfer models done with this generic geometry and results will be discussed. After this project we made a model that is numerically reliable, mesh independent and fast...|$|E
40|$|PURPOSE OF REVIEW: In {{the past}} year, many studies were {{published}} in which new and relevant information on small intestinal motility in humans and laboratory animals was obtained. RECENT FINDINGS: Although the reported findings are heterogeneous, some themes appear to be particularly interesting and novel. Among these is the association between disordered small intestinal motility and bacterial overgrowth of the small intestine. Studies in patients with portal hypertension, in patients with chronic renal failure, and in a rat model of experimental acute pancreatitis all point in the same direction. <b>Another</b> <b>topic</b> <b>of</b> particular <b>interest</b> is the relation between duodenal motility and glucose absorption; propagated duodenal pressure wave sequences are positively related to glucose absorption. Finally, many studies addressed the mechanisms involved in the regulation of interdigestive and postprandial small intestinal motility. These confirmed the key role of cholecystokinin and provided new information {{on the role of}} orexin A and leptin. SUMMARY: The new information on intestinal motility gathered in the past year provides a greater insight in the pathophysiology of a number of diseases and will stimulate further studies in laboratory animals and in human subject...|$|R
40|$|Optogenetics {{is a novel}} {{technology}} that combines optics and genetics by optical control of microbial opsins, targeted to living cell membranes. The versatility and the electrophysiologic characteristics of the light-sensitive ion-channels channelrhodopsin- 2 (ChR 2), halorhodopsin (NpHR), and the light-sensitive proton pump archaerhodopsin- 3 (Arch) make these optogenetic tools potent candidates in controlling neuronal firing in models of epilepsy and in providing insights into the physiology and pathology of neuronal network organization and synchronization. Opsins allow selective activation of excitatory neurons and inhibitory interneurons, or subclasses of interneurons, to study their activity patterns in distinct brain-states in vivo and to dissect their role in generation of synchrony and seizures. The influence of gliotransmission on epileptic network function is <b>another</b> <b>topic</b> <b>of</b> great <b>interest</b> that can be further explored by using light-activated Gq protein-coupled opsins for selective activation of astrocytes. The ever-growing optogenetic toolbox can also be combined with emerging techniques that have greatly expanded our ability to record specific subtypes of cortical and hippocampal neurons in awake behaving animals such as juxtacellular recording and two-photon guided whole-cell recording, to identify the specific subtypes of neurons that are altered in epileptic networks. Finally, optogenetic tools allow rapid and reversible suppression of epileptic electroencephalography (EEG) activity upon photoactivation. This review outlines the most recent advances achieved with optogenetic techniques {{in the field of}} epilepsy by summarizing the presentations contributed to the 13 th ILAE WONOEP meeting held in the Laurentian Mountains, Quebec, in June 2013...|$|R
40|$|The spatial {{resolution}} of SRTM (Shuttle Radar Topographic Mission) digital elevation models, currently available {{is set at}} 90 m (or ~ 3 ") and ~ 30 m (or ~ 1 ") for the USA territory. Refining the 90 m grid through geostatistic methods has been an approach adopted by several users. However, models based on semivariograms generally exhibit distinct parameters for each sampled area. These particularities raise questions over {{the application of the}} same model thoughtout larger scales. The assessment of the interpolation effectiveness is <b>another</b> research <b>topic</b> <b>of</b> <b>interest.</b> This paper presents a methodology to measure the strength of SRTM data interpolation from 90 m to 30 m, and the feasibility to apply a single variogram model to larger areas. The study region lies near the Rocky Mountains in Montana State, USA. Initially, the SRTM was resampled from 30 m to 90 m, and then kriged to 30 m. This interpolated data was compared with the 30 m original grid through map algebra. The results from layers subtraction were evaluated with descriptive statistics and linear regression, and hypothesis test for ß 1 = 1 e ß 0 = 0. The regression residuals shows a submetric mean and the regression test accept the null hypothesis for both tests. These outcomes support the adoption of the kriging method for interpolation of SRTM- 90 m {{and the use of the}} same model adjusted for a sampled area to larger regions. Pages: 3927 - 393...|$|R
40|$|This thesis {{deals with}} graphology and its {{possible}} use in personnel management. Its {{aim is to}} handle this projective method from both theoretical and practical points of view - both to define graphology and explain related terms, and to consider the possible practical contribution of this method to HR. In this thesis, the tasks of a graphologist are introduced, {{as well as the}} nature and way of his or her work with handwriting. Global impression signs, measuring signs and description signs are also mentioned as means of interpretation and graphological analysis. Attention is also paid to the formation of individual handwriting, which is greatly influenced by school handwriting models. In this connection, the thesis also handles the newly coined Comenia Script handwriting model. <b>Another</b> <b>topic</b> <b>of</b> <b>interest</b> are graphological expert opinions being closely connected with ethical principles of graphology. The final part is devoted to the practical use of graphology as a method of recruiting workers in personnel management. This thesis is to provide a basic overview of graphology and principles of work with handwriting. Some knowledge in this field can be of use for personnel managers, recruitment consultants, educational consultants, psychologists, andragogists or all those interested in this discipline [...] . ...|$|E
40|$|These {{lecture notes}} provide a {{tutorial}} review of non-Abelian discrete groups and show some applications to issues in physics where discrete symmetries constitute an important principle for model building in particle physics. While Abelian discrete symmetries are often imposed {{in order to}} control couplings for particle physics - in particular model building beyond the standard model - non-Abelian discrete symmetries have been applied to understand the three-generation flavor structure in particular. Indeed, non-Abelian discrete symmetries are considered to be the most attractive choice for the flavor sector: model builders have tried to derive experimental values of quark and lepton masses, and mixing angles by assuming non-Abelian discrete flavor symmetries of quarks and leptons, yet, lepton mixing has already been intensively discussed in this context, as well. The possible origins of the non-Abelian discrete symmetry for flavors is <b>another</b> <b>topic</b> <b>of</b> <b>interest,</b> as they can arise from an underlying theory - e. g. the string theory or compactification via orbifolding – thereby providing a possible bridge between the underlying theory and the corresponding low-energy sector of particle physics. This text explicitly introduces and studies the group-theoretical aspects of many concrete groups and shows how to derive conjugacy classes, characters, representations, and tensor products for these groups (with a finite number) when algebraic relations are given, thereby enabling readers to apply this to other groups of interest...|$|E
40|$|In {{this thesis}} {{the topic of}} {{research}} was homelessness among women. For defining the phenomenon of homelessness {{the definition of the}} European observatory on homelessness – ETHOS was used. Besides the more visible types of homelessness, I have also paid attention to the areas of hidden and potential homelessness among women. The understanding of the connection between those forms is important because visible homelessness arises from the hidden homelessness. The structural, institutional, relational and individual factors, which increase the risk of development of homelessness were analysed. The different aspects of violence were also analysed. <b>Another</b> <b>topic</b> <b>of</b> <b>interest</b> was the influence of homelessness on motherhood. The empirical part of the thesis contains a qualitative research. A half-structured interview was used for data collection. A sample of four women with homelessness experience was analysed. Contact with them was established through »Kralji ulice« association, a safehouse for mothers, a women's safehouse and a homeless shelter. The foremost purpose of the research was deeper understanding of homelessness among women, with special attention on recognition of different types of homelessness, violence, risk factors, as well as different types of support and motherhood. The main conclusions are that mostly hidden types of homelessness are present among women and they are not recognized by society or the institutions. The findings in this thesis contribute to raising awareness on the topic of homelessness among women, which is of crucial importance for the institutions engaging them...|$|E
40|$|Non-Boltzmann {{sampling}} (NBS) {{methods are}} usually {{able to overcome}} ergodicity issues which conventional Monte Carlo methods often undergo. In short, NBS methods are meant to broaden the sampling range of some suitable order parameter (e. g., energy). For many years, a standard for their development has been the choice of sampling weights that yield uniform sampling of a predefined parameter range. However, Trebst et al. [Phys. Rev. E 70, 046701 (2004) ] demonstrated that better results are obtained by choosing weights that reduce {{as much as possible}} the average number of steps needed to complete a roundtrip in that range. In the present work, we prove that the method they developed to minimize roundtrip times also equalizes downtrip and uptrip times. Then, we propose a discrete-parameter extension using such isochronal character as our main goal. To assess the features of the new method, we carry out simulations of a spin system and of lattice chains designed to exhibit folding transition, thus being suitable models for proteins. Our results show that the new method performs {{on a par with the}} original method when the latter is applicable. However, there are cases in which the method of Trebst et al. becomes inapplicable, depending on the chosen order parameter and on the employed Monte Carlo moves. With a practical example, we demonstrate that our method can naturally handle these cases, thus being more robust than the original one. Finally, we find an interesting correspondence between the kind of approach dealt with here and the committor analysis of reaction coordinates, which is <b>another</b> <b>topic</b> <b>of</b> rising <b>interest</b> in the field of molecular simulation. (C) 2009 American Institute of Physics. [doi: 10. 1063 / 1. 3245304...|$|R
40|$|This paper studies how to optimally embed {{a general}} metric, {{represented}} by a graph, into a target space while preserving the relative magnitudes of most distances. More precisely, in an ordinal embedding, we must preserve the relative order between pairs of distances (which pairs are larger or smaller), and not necessarily {{the values of the}} distances themselves. The relaxation of an ordinal embedding is the maximum ratio between two distances whose relative order is inverted by the embedding. We develop polynomial-time constant-factor approximation algorithms for minimizing the relaxation in an embedding of an unweighted graph into a line metric and into a tree metric. These two basic target metrics are particularly important for representing a graph by a structure that is easy for humans to understand, with applications to visualization, compression, clustering, and nearest-neighbor searching. Along the way, we improve the best known approximation factor for ordinally embedding unweighted trees into the line down to 2. Our results illustrate an important contrast to optimal-distortion metric embeddings, where the best approximation factor for unweighted graphs into the line is O(n 1 / 2), and even for unweighted trees into the line the best is Õ(n 1 / 3). <b>Another</b> <b>topic</b> <b>of</b> recent <b>interest</b> is dimensionality reduction. The famous Johnson-Lindenstrauss Theorem guarantees low-distortion reduction to logarithmic dimension for arbitrary ℓ 2 metrics, but recently it was shown that the same is impossible without significant distortion for ℓ 1 metrics (despite their usefulness and flexibility for representation). In contrast, we show that arbitrary ℓ 1 metrics can be ordinally embedded into logarithmic-dimension ℓ 1 space with arbitrarily small relaxation, which has many potential applications to approximation algorithms. More generally, our analog of the Johnson-Lindenstrauss Theorem applies to ℓp metrics with 1 ≤ p ≤ 2. ...|$|R
40|$|Organisms {{must be able}} to {{selectively}} tailor {{their ability}} to use the macronutrients of carbohydrate, protein, and fat based on their availability. In different cell types, how the nutrient fluctuations are sensed and themechanisms by which the pathways of central metabolism are switched to favor the use of one particular nutrient type over <b>another</b> are <b>topics</b> <b>of</b> intense <b>interest.</b> Protein acetylation is one major evolutionary conserved mechanism by which nutrient fluctuations are sensed within cells and subsequently coupled with metabolic switching. In this review, we present the case of PGC- 1 a acetylation and how the control of PGC- 1 a’s activity by acetylation sets into motion a wide range of metabolic adaptations that makes this protein an exemplary model for acetylation-mediated mechanisms of nutrient sensing and communication. In response to the inherently unpredictable nature of nutrient and energy availability, mammalian cells have evolved a complex regulatory system for controlling their rates of mass accretion and energy flux through fuel/ macronutrient utilization pathways. Often, this requires a “metabolic switch ” wherein a given cell type is forced to stop using one type of macronutrient as a fuel source and convert to the use of another. Under energy-demand...|$|R
40|$|Much {{attention}} has been devoted recently to the matter of pasture degradation and the identification of such areas. The main interests in degraded pastures {{are related to the}} fact that the recovery of such areas could be used to increase beef cattle production and thus reduce the need for the establishment of new agricultural fields, lowering deforestation pressure. <b>Another</b> <b>topic</b> <b>of</b> <b>interest</b> related to degraded pastures is the Brazilian National Climate Change Policy and the Low Carbon Agriculture Program (Programa ABC ? Agricultura de Baixo Carbono) which aims to reduce national carbon dioxide emissions. The recovery of degraded pasture is one of the objectives of this program, which increases the amount of carbon stored in the soil, acting as a carbon sink. However, the identification of degraded pastures through the use of remote sensing is still in development. Here we present a method based on the use of hyperespectral classification and images from the EO 1 -Hyperion hyperspectral sensor in order to map the occurrence of pasture areas among the cerrado region. The method is based on a linear spectral unmixing model that can be linked to vegetation characteristics and was capable of discriminating the signals of natural savanna vegetation from pasture and bare soil. The procedure used was able to map pasture areas in the Brazilian Pantanal region and estimate biophysical parameters associated to non-photosynthetic vegetation (ANPV ? dry matter). As future research, spectral mixture analysis approache similar to the ones obtained from Hyperion will be developed based on different orbital sensors, in order to evaluate pasture areas in larger regions. 201...|$|E
40|$|These are the {{proceedings}} of the Second Workshop on GRAPH Inspection and Traversal Engineering (GRAPHITE 2013), which took place on March 24, 2013 in Rome, Italy, as a satellite event of the 16 th European Joint Conferences on Theory and Practice of Software (ETAPS 2013). The topic of the GRAPHITE workshop is graph analysis in all its forms in computer science. Graphs are used to represent data in many application areas, and they are subjected to various computational algorithms in order to acquire the desired information. These graph algorithms tend to have common characteristics, such as duplicate detection to guarantee their termination, independent of their application domain. Over the past few years, {{it has been shown that}} the scalability of such algorithms can be dramatically improved by using, e. g., external memory, by exploiting parallel architectures, such as clusters, multi-core CPUs, and graphics processing units, and by using heuristics to guide the search. Novel techniques to further scale graph search algorithms, and new applications of graph search are within the scope of this workshop. <b>Another</b> <b>topic</b> <b>of</b> <b>interest</b> of the event is more related to the structural properties of graphs: which kind of graph characteristics are relevant for a particular application area, and how can these be measured? Finally, any novel way of using graphs for a particular application area is on topic. The goal of this event is to gather scientists from different communities, such as model checking, artificial intelligence planning, game playing, and algorithm engineering, who do research on graph search algorithms, such that awareness of each others' work is increased...|$|E
40|$|Today, ever {{changing}} and advancing techniques of construction are constantly {{pushing the envelope}} of structural possibilities in the built environment. Although not new, the concept of Double-Skin Façades (DSF) finds increasing implementation {{with the advent of}} sustainable construction, aiming to reduce energy consumption to condition buildings whilst improving indoor air quality. As is the case with the traditional concept of the compartment fire, methodologies and assumptions on which our general understanding of the fire problem is based, did fundamentally not change. Inherently bound to this, is the concept of compartmentalisation, prescribing measures to avoid horizontal and vertical fire spread in buildings. A DSF, most commonly featuring a ventilated cavity between curtain wall and the secondary glass façade at an offset, is prone to drastically alter fire and smoke behaviour once able to enter. Unlike curtain walls, the chimney-like aspect ratio of such façades is able to trap fire and combustion gases within the cavity, potentially compromising the integrity of the building perimeter above the fire. The current approach to this issue tends to focus on using non-combustible construction materials and the installation of sprinkler systems to avoid breakage of window panes in the first place. <b>Another</b> <b>topic</b> <b>of</b> <b>interest</b> is the weak connection between floor slab and curtain wall which can allow vertical fire spread to adjacent floors. Research has also been discussing the use of mullions to deflect the fire plume away from the façade. Even if useful in DSF’s, aesthetics and problems with functionality will most likely prevent mullions from being introduced into the DSF. However, very little relevant research actually investigated the fire-induced flow structure under these conditions so that properly informed design decisions can be made. The project at hand aims to understand hazards to the floors above and below the fire floor by experimentally investigating the governing processes by means of large-scale fire testing and small-scale salt-water modelling (SWM). The gathered data shall serve as a basis to discuss current spandrel and cavity design decisions. Results have been compared in terms of dimensionless numbers and demonstrate complex interactions between DSF cavity width and spandrel height, encouraging a discussion about the need of further research of this topic...|$|E
40|$|During {{the last}} decade, {{there has been}} an {{increasing}} interest in the physics of solid-state systems whose low-energy excitations can be treated as Dirac fermions, that is, fermions described by the Dirac equation. Nowadays, the prime examples for such systems are graphene, whose band structure can be approximated by a two-dimensional (2 D) Dirac-like Hamiltonian {{in the vicinity of the}} K and K' points, and topological insulators, which possess edge states with a linear, one-dimensional (1 D) spectrum in the case of 2 D systems and surface states described by a single Dirac cone in the case of three-dimensional (3 D) topological insulators. One of the main reasons for the enormous interest in these materials is that they offer the possibility to study quantum electrodynamical phenomena in solid-state systems. In the first part of this thesis, we theoretically study magnetic properties of inverted HgTe/CdTe quantum wells, a system which constitutes a 2 D topological insulator. In particular, we study the crossover between the quantum spin Hall and quantum Hall states in those structures using analytical as well as numerical methods. Moreover, the bulk magnetic susceptibility is investigated and found to exhibit characteristic de Haas-van Alphen oscillations. Finally, the bulk magneto-optical conductivity is calculated. Here, we find that for large magnetic fields, when the spacing between neighboring Landau levels is large compared to the lifetime broadening, one can observe pronounced peaks and oscillations in the magneto-optical conductivity. In the second part the thesis, we investigate the effect that intrinsic graphene optical as well as surface polar phonons (SPPs) have on the optical conductivity in graphene using the Kubo linear response formalism. Here, we observe an increase of the absorption in the optical gap due to electron-phonon coupling. The third part of this thesis is devoted to <b>another</b> <b>topic</b> <b>of</b> recent <b>interest</b> in solid-state physics, namely the field of spin caloritronics. Here, we generalize the standard model of spin injection to describe the coupling between charge, spin, and heat transport in metals. The formalism is then used to analyze several different structures consisting of ferromagnetic (F) and normal (N) metals, such as F/N and F/N/F junctions...|$|R
40|$|When {{electrons}} {{are subject}} to a large external magnetic field, the conventional charge quantum Hall effect dictates that an electronic excitation gap is generated in the sample bulk, but metallic conduction is permitted at the boundary. Recent theoretical models suggest that certain bulk insulators with large spin–orbit interactions may also naturally support conducting topological boundary states in the quantum limit, which opens up the possibility for studying unusual quantum Hall-like phenomena in zero external magnetic fields. Bulk Bi_(1 -x) Sb_x single crystals are predicted to be prime candidates for one such unusual Hall phase of matter known as the topological insulator. The hallmark of a topological insulator is the existence of metallic surface states that are higher-dimensional analogues of the edge states that characterize a quantum spin Hall insulator. In addition to its interesting boundary states, the bulk of Bi_(1 -x) Sb_x is predicted to exhibit three-dimensional Dirac particles, <b>another</b> <b>topic</b> <b>of</b> heightened current <b>interest</b> following the new findings in two-dimensional graphene and charge quantum Hall fractionalization observed in pure bismuth. However, despite numerous transport and magnetic measurements on the Bi_(1 -x) Sb_x family since the 1960 s, no direct evidence of either topological Hall states or bulk Dirac particles has been found. Here, using incident-photon-energy-modulated angle-resolved photoemission spectroscopy (IPEM-ARPES), we report the direct observation of massive Dirac particles in the bulk of Bi_(0. 9) Sb_(0. 1), locate the Kramers points at the sample's boundary and provide a comprehensive mapping of the Dirac insulator's gapless surface electron bands. These findings taken together suggest that the observed surface state on the boundary of the bulk insulator is a realization of the 'topological metal'. They also suggest that this material has potential application in developing next-generation quantum computing devices that may incorporate 'light-like' bulk carriers and spin-textured surface currents...|$|R
40|$|The {{necessity}} to explore nanoscopic systems is ever increasing {{in the world}} of science and technology. This evolving need to study such physically small systems demands new experimental techniques and methodologies. Atomic force microscopy (AFM) is a versatile technique that can overcome many nanoscopic size limitations. AFM has been utilized {{in the world of}} nanotechnology to study physiochemical properties of particles, materials, and biomolecules through characterization of morphology, electrical and mechanical properties, binding interactions, and surface tension, among others. The work discussed herein is largely a report of several novel AFM methodologies that were developed to allow new characterization techniques of individual submicrometer particles and single biomolecular interactions. The effects of atmospheric aerosols on the radiative budget of the earth and climate are largely unknown. For this reason, characterizing the physiochemical properties of aerosols is vital. Since the particles that have relatively long lifetimes in the atmosphere are smaller than one micrometer in size, high resolution microscopy techniques are required to study them. AFM is a suitable technique for single particle studies because it has nanometer spatial resolution, can perform experiments under ambient pressure and variable relative humidity and temperature. These advantages were utilized here and AFM was used to study morphology, organic volume fraction, water uptake, and surface tension of nascent sea spray aerosol (SSA) particles as well as laboratory generated aerosols composed of relevant chemical model systems. The morphology of SSA was found, often times, to be composed of core-shell structure. With complementary microscopy techniques, the composition of the core and the shell was found to be inorganic and organic in nature, respectively. Novel methodology to measure water uptake and surface tension of single substrate deposited particles with AFM was established using chemical model systems. Furthermore, these methodologies were employed on nascent chemically complex SSA particles collected from a biologically active oceanic waveflume experiment. Finally, phase imaging was used to measure organic volume fraction on a single particle basis and was correlated with biological activity. Overall, this suite of single (submicrometer) particle AFM analysis techniques have been established, allowing future systematic studies of increasing complexity aimed at bridging the gap between the simplicity of laboratory generated particles and the complexity <b>of</b> nature. <b>Another</b> nanotechnology <b>topic</b> <b>of</b> <b>interest</b> is studying single biomolecular interactions. Virtually every biological process involves some amount of minute forces that are required for the biomolecular system to function properly. For example, there are picoNewton forces associated with enzymatic motions that are important for enzyme catalysis. The AFM studies reported here use a model enzyme/drug system to measure the forces associated with single molecule adhesion events. Escherichia Dihydrofolate Reductase (DHFR) is a target of cancer therapeutic studies because it can be inhibited by drugs like methotrexate (MTX) that are structurally similar to the natural folate binder but have much higher binding affinity. One of the obstacles of single molecular recognition force spectroscopy (MRFS) studies is the contribution of non-specific forces that create a source of uncertainty. In this study, DHFR and MTX are bound to the surface and the AFM tip, respectively, using several different linking molecules. These linking molecules included polyethylene glycol (PEG) and double stranded DNA (dsDNA) and the distribution of forces was compared to scenarios were a linker was not employed. We discovered that dsDNA and PEG both allow identification and removal of non-specific interaction forces from specific forces <b>of</b> <b>interest,</b> which increases the accuracy of the measurement compared to directly bound constructs. Traditionally, the linker of choice in the MRFS community is PEG. Here, we introduce dsDNA as a viable linker that offers more rigidity than PEG, which may be desirable in future molecular constructs. The majority of the work and data presented in this dissertation supports the establishment of new AFM methodologies {{that can be used to}} better explore single biomolecular interactions and individual submicrometer particles on the nanoscale...|$|R
40|$|In this thesis, {{a scheme}} for calculating the {{dynamics}} of two coupled dissipative spins is developed, where each of the spins is coupled to its own boson bath. We derive analytic path sum results both in the Markov-regime and in the one-boson exchange regime. The analysis is also performed with the Bloch-Redfield method. It is shown that the two different approaches lead to identical results for the dynamics. This is not obvious a priori because both methods are based on different procedures. The path sum method gives detailed insight into the internal dynamics of two coupled spins because we consider every path sequence {{that contributes to the}} time evolution. While most studies of coupled spins are restricted to one type of coupling, e. g., Ising type, we will generalize here to linear combinations of possible couplings. Especially interesting is the occurrence of a frustration of decoherence, if the spins are interacting via a linear combination of longitudinal and transverse coupling and, when in addition, some of the eigenfrequencies become degenerate. Our analysis shows that degenerate but mutual exclusive ground states lead to increased coherence times. Maximization of coherence is one of the crucial goals of quantum state engineering. <b>Another</b> <b>topic</b> <b>of</b> <b>interest</b> is the impact of non-linear quantum environments, formed by surrounding dissipative spins. A distribution of bistable background charges is known to be responsible for $ 1 /f$ noise in solid state devices, like the superconducting quantum interference devices. Since $ 1 /f$ noise is seemingly the dominating source of decoherence at very low temperature, there is a profound theoretical interest in modeling it. Therefore, we analyze two interacting spins, where one of them is coupled to a boson bath and thereby represents a resonant non-linear quantum environment. We study the crossover from a non-linear to a linear bath and study the corresponding time scale for the relevant bath correlations. Interestingly, for large and increasing temperature we find a decreasing decoherence for the central spin. In dieser Arbeit wird ein Verfahren zur Berechnung der Dynamik zweier gekoppelter Spins entwickelt, welche jeweils an ein bosonisches Wärmebad gekoppelt sind. Zuerst berechnen wir analytische Pfadsummenergebnisse sowohl im Markov-Regime, wie auch im Ein-Boson Austausch-Regime. Die Untersuchung wird anschließend auch mit der Bloch-Redfield-Methode durchgeführt. Es wird gezeigt, dass die beiden unterschiedlichen Methoden zu identischen Ergebnissen führen. Dies ist nicht von vornherein offensichtlich, da die Methoden auf unterschiedlichen Vorgehensweisen basieren...|$|E
40|$|The {{primary goal}} of the ARROWS project {{consists}} {{in the development of}} multi-disciplinary methods and techniques to detect, record and report about underwater handmade objects and wrecks that feature relevant importance to archaeologists and ethno-anthropologists. Due to that, the ARROWS informative system is in charge of merging data captured by employing advanced technologies for the seafloors survey as well as data coming from historical, artistic, archaeological and documentary sources. It is fundamental to analyse carefully every expected typology of data in order to implement a system able to properly capture and integrate all the available information. This document addresses these latter issues by identifying the requirements and the technical specifications concerning the data acquisition and integration system. After a brief review about {{the current state of the}} art in terms of data management and technologies concerning systems for knowledge representation, a detailed description follows, focusing on the data that will be fed into the ARROWS informative system. Because of the complexity and the large number of the involved data classes, the data is here presented by briefly running over their main categories. A first category concerns the historical and archival information that is collected by merging the data available from the currently existing databases, supported by the cultural institution partners of the project (the Estonian Maritime Museum and the Cultural Heritage Superintendence of Sicily). A second important class refers to the amount of data captured during the underwater survey missions. This class may concern raw data directly collected by the on-board sensor devices as well as the output results obtained by online (during the mission) and offline (after the end of the mission) processing algorithms. Specific attention will be paid to the description of the navigation data captured by auxiliary sensor devices (such as IMU systems), data that is exploited for the registration and geo-referencing of the optical and acoustic payload data. Eventually these data can be further processed by means of the scene understanding procedures described in the previous deliverables (work packages WP 4 and WP 5). Every data typology is described in terms of its format specification and, whenever available or predictable, an analysis of the computational and memory requirement is presented. <b>Another</b> <b>topic</b> <b>of</b> <b>interest</b> in the project concerns the dissemination channels exploited to spread the collected information about the sunken heritage towards the generic user. To that purpose, a relevant outcome of the project is the design and implementation of an interactive environment devoted to the virtual navigation of interesting underwater environments, simulated by processing the real captured data. This result will be available for access to the technical and generic user and will exploit the connection with the informative system by providing not only the information referring to the captured payload data but also, if available, further information concerning historical or archival details about the object of interest...|$|E
40|$|Currently it {{has become}} {{recognized}} that to successfully manage the crisis situation {{it is necessary to}} ensure the basic transport, particularly transport infrastructure impassable. One of the many problem areas while ensuring operation in transport is critical to ensure the functionality of artificial structures, and thus become very important just bridges that we in most cases considered by the throat on the roads. Bridges must be kept sufficiently passable,and failing this, just need to take action in the form of construction of a temporary replacement bridge. The general aim of my thesis was to analyze the usefulness of temporary bridge construction kits in crisis situations. The theoretical part describes issues related legislation with crisis management, basic concepts related to crisis management, bridge set MS, heavy bridge set TMS {{and the use of the}} Czech Army in crisis situations. Crisis management was essential after the floods in 1997 and 2002 given special attention. It was gradually ascertained that five years after the floods in Moravia in 1997, the Army increasingly lack a global perspective on the overall topic of crisis management. The focus is on bridge set MS. This is a releasable steel bridge construction, which was initially designed for the military sector to the possibility of fast implementation of temporary bypass obstacles. <b>Another</b> <b>topic</b> <b>of</b> <b>interest</b> is becoming difficult bridge kit. Heavy bridge system is normalized steel folding bridge for only one lane of the lower deck, which is designed to build bridges with one or more fields of bridges and overpasses for the construction of the railway. The use of the Czech Army is further defined as a task of the integrated rescue system in the area of internal security, where the individual components of the Integrated Rescue System and other bodies involved in internal security and civil protection must be able to respond professionally and in cooperation with other stakeholders to intervene effectively in an emergency or crisis caused by terrorist attacks, natural and environmental disasters, industrial accidents, and other dangers that threaten the lives, health, property, the environment, internal security and public order in the Czech Republic. The Czech army is used for temporary organized deployment of military units and military installations with the necessary military equipment and under the control of the appropriate commander. Military assistance becomes necessary when the designated administrative authorities, local authorities or a fire protection can no longer ensure the rescue work on their own. The use of the army for rescue operations can be done at the request of regional governors, mayors and mayors of municipalities or the Ministry of the Interior through the Operational and Information Centre Fire and Rescue through the permanent operations center of the Army of the Czech Republic. In the practical part I am focused on gathering the available general and internal information,reports and documentation on the use of temporary bridge kits in crisis situations and analysis of documents,regulations and methodologies relating to the construction of temporary bridge kits in crisis situations. Practical application of new trends and technologies, based on experience with engineer bridge company Czech Army. Processing and evaluation of the results was done in MS Word and MS Excel...|$|E
40|$|The region {{between the}} {{infrared}} and microwave {{region in the}} electromagnetic spectrum, the Terahertz (THz) gap, provides an exciting opportunity for future wireless communications as this band has been under utilised. This doctoral work takes a two-pronged approach into closing the THz gap with low-dimensional materials. The first attempt addresses {{the need for a}} compact THz source that can operate at room temperature. The second approach addresses the need to build optical elements such as filters and modulators in the THz spectrum. Terahertz quantum cascade lasers (THz QCLs) {{are one of the most}} compact, powerful sources of coherent radiation that bridge the terahertz gap. However, their cryogenic requirements for operation limit the scope of the applications. This is because of the electron-electron scattering and heating of the 2 -dimensional free electron gas which leads to significant optical phonon scattering of the hot electrons. Theoretical studies in laterally confined QCL structures have predicted enhanced lifetime of the upper state through suppression of the non-radiative intersubband relaxation of carriers, which leads to lower threshold, and higher temperature performance. Lithographically defined vertical nanopillar arrays with electrostatic radius less than tens of nm offer a possible route to achieve lateral confinement, which can be integrated into QCL structures. A typical gain medium in a QCL consists of at least 100 repeat periods, with a thickness of 6 - 14 micron. For practical implementation of the top-down approach, restrictions are imposed by aspect ratios that can be achieved in present dry-etching systems. Typically, for sub- 200 nm radius pillars, the thickness ranges from 1 - 3. 5 micron. It is therefore necessary to work with THz QCLs based on 3 - 4 quantum well active regions, so as to maximise the number of repeat periods (hence gain) within an ultra-thin active region. After an introductory chapter, Chapter 2 presents a theoretical treatise on the realistic electrostatic potential in a lithographically defined nanopillar by scaling from a single quantum well (resonant tunnelling diode) to a THz QCL. Chapter 2 also discusses, the effect of lateral confinement on the intersubband states and the plasmonic mode in a THz QCL. One of the key experimental challenges in scaling down from QCLs to quantum-dot cascade lasers is the electrical injection into the nanopillars. This involves insulation and planarisation of the high aspect-ratio nanopillar arrays. Furthermore, the choice of the planarising layer is critical since it determines the loss of any optical mode. This experimental challenge is solved in Chapter 3. Chapter 4 presents the electro-optic performance of low-repeat period QCLs with an active region thickness that is less than 3. 5 micron. <b>Another</b> <b>topic</b> <b>of</b> recent <b>interest</b> in the THz optics community is plasmonics in graphene. This is because the bound electromagnetic modes (plasmons) are tightly confined to the surface and can also be tuned with carrier concentration. Plasmonic resonance at terahertz frequencies can be achieved by gating graphene grown via chemical vapour deposition (CVD) to a high carrier concentration. THz time domain spectroscopy of such gated monolayer graphene shows resonance features around 1. 6 THz superimposed on the Drude-like frequency response of graphene which may be related to the inherent poly-crystallinity of CVD graphene. Chapter 5 discusses these results, as an understanding of these features is necessary for the development of future THz optical elements based on CVD graphene. Chapter 5 finally describes how the gate tunability of THz transmission through graphene can be exploited to indirectly modulate a THz QCL. Chapter 6 presents ideas from this doctoral work, which can be developed in future to address the issues of enhanced temperature performance of THz QCLs and to realise realistic THz devices based on graphene...|$|R
30|$|The {{aggregator}} {{publishes the}} result {{obtained in the}} same or <b>another</b> <b>topic</b> <b>of</b> the message bus, {{so that it is}} available to potential consumers.|$|R
40|$|Search engines {{give the}} same results for the same query. They do not {{consider}} that a user 2 ̆ 019 s <b>topics</b> <b>of</b> <b>interest</b> may diverge at different times even if the query terms are the same. This paper presents {{the findings of a}} study into how different <b>topics</b> <b>of</b> <b>interest</b> <b>of</b> a user are influenced by time. The results show that most of the users have time sensitive search patterns, indicating that they have different <b>topics</b> <b>of</b> <b>interest</b> that are dominant at different times...|$|R
