11|3106|Public
40|$|Abduction Is a {{basic form}} of logical inference, which {{is said to}} engender the use of plans, perceptual models, intuitions, and analogical reasoning-all aspects of Intelligent {{behavior}} that have so far failed to find representation in existing formal deductive systems. This paper explores the <b>abductive</b> <b>reasoning</b> <b>process</b> and develops a model for its mechanization,. which consists of an embedding of deductive logic in an iterative hypothesis and test procedure. An application of the method {{to the problem of}} medical diagnosis is discussed. Key Word...|$|E
40|$|A {{focus on}} {{needs and the}} ability to {{generate}} knowledge about needs is highly valuable for organizations because it extends the range of possible solutions and therefore enables them to create more innovative and sustainable products and services. Our paper will explore how a framework based on an <b>abductive</b> <b>reasoning</b> <b>process</b> for the creation and discovery of knowledge about needs in organizations can look like and what the main steps of such a framework are, in order to integrate this approach into the model of the knowledge-based firm. Moreover we will present empirical findings from a project with Austrian companies where this framework has been used...|$|E
40|$|Abstract. In {{this paper}} we {{describe}} our on-going research project on resolving semantic difference for multi-agent systems (MAS) in electronic commerce. The approach {{we are taking}} can be characterized by the following: 1) agents in a MAS are allowed {{to have their own}} specific ontologies, which are defined on top of a shared base ontology; 2) concepts and their classes in these ontologies are represented as frame-like structures based on DAML+OIL semantic markup language; 3) the semantic differences between heterogeneous agents are resolved in runtime through inter-agent communication; and 4) the resolution is viewed as an <b>abductive</b> <b>reasoning</b> <b>process,</b> and thus necessarily involves approximation and default reasoning. ...|$|E
5000|$|<b>Abductive</b> <b>reasoning,</b> the <b>process</b> of {{deriving}} {{the most}} likely explanations of the known facts.|$|R
30|$|Triangulation {{will be used}} in the Theory Construction Phase in its {{original}} trigonometrical sense pulling together micro and macro analysis and {{as the basis for the}} <b>abductive</b> and retroductive <b>reasoning</b> <b>processes</b> of theory construction.|$|R
50|$|<b>Abductive</b> <b>reasoning</b> is the <b>process</b> of {{deriving}} {{the most}} likely explanations of the known facts. An abductive logic should not be monotonic because {{the most likely}} explanations are not necessarily correct. For example, the most likely explanation for seeing wet grass is that it rained; however, this explanation has to be retracted when learning that the real cause of the grass being wet was a sprinkler. Since the old explanation (it rained) is retracted because of {{the addition of a}} piece of knowledge (a sprinkler was active), any logic that models explanations is non-monotonic.|$|R
40|$|In this {{position}} statement, we describe our on-going research project on resolving semantic differences for multi-agent systems in electronic commerce. The approach {{we are taking}} can be characterized by the following: 1) the semantic differences between heterogeneous agents are resolved at runtime and in an incremental fashion; 2) concepts and their classes are represented as frames based on daml+oil semantic markup language; and 3) the resolution is viewed as an <b>abductive</b> <b>reasoning</b> <b>process</b> and thus necessarily involves approximation and default reasoning. Categories and Subject Descriptors I. 2. 4. [Artificial Intelligence]: Knowledge Representation Formalisms And Methods [...] frames and scripts, representation languages, semantic networks. General Terms Design, Standardization, Languages. Keywords Ontology, semantic difference, software agents, agent communication languages, electronic commerce. 1...|$|E
40|$|Abductive Logic Programming is a {{computationally}} founded {{representation of}} abductive reasoning. In most ALP frameworks, integrity constraints express domain-specic logical relationships that abductive answers {{are required to}} satisfy. Integrity constraints are usually known a priori. However, in some applications (such as interactive abductive logic programming, multi-agent interactions, contracting) {{it makes sense to}} relax this assumption, in order to let the abductive reasoning start with incomplete knowledge of integrity constraints, and to continue without restarting when new integrity constraints become known. In this paper, we propose a declarative semantics for abductive logic programming with addition of integrity constraints during the <b>abductive</b> <b>reasoning</b> <b>process.</b> We propose an operational instantiation (with formal termination, soundness and completeness properties) and an implementation of such a framework based on the SCIFF language and proof procedure...|$|E
40|$|Abduction {{is a form}} of {{reasoning}} posited by Charles Sanders Peirce. It is the most relevant reasoning process within the developmental framework. Abductive reasoning is an epistemological process that allows for the production and alteration of hypotheses and beliefs due to the continuous dialogue between the particular and the general. Abduction is bounded reasoning in which induction, deduction, and hypothesis construction are interrelated within the reasoning process. By combining the Peircian and Freudian models, the process of abductive reasoning can be clarified and extended. Peirce (1887) describes beliefs as premises for actions. The relationship between beliefs and actions of an individual sets the foundation for the <b>abductive</b> <b>reasoning</b> <b>process</b> in everyday inquiries. Freud (1908) described a child‘s action in the search to solve the riddles of childbirth. Using Freud‘s study on the sexual researches of children, this paper will examine the intricate microgenetic processes associated with abductive reasoning, and the developing beliefs that result...|$|E
40|$|<b>Abductive</b> <b>reasoning</b> is the <b>process</b> {{of finding}} a best {{explanation}} {{for a set of}} observations. In many abductive problems, like medical diagnosis, scientific discovery, debugging or troubleshooting, an amount of information far beyond the capacity limits of working memory (WM) must be processed. Although WM plays a central role in theories of human cognition, theories of <b>abductive</b> <b>reasoning</b> do not specify WM processes during the generation of explanations. On the basis of a computational model of <b>abductive</b> <b>reasoning</b> and of theories of text comprehension a mechanism is proposed that reduces WM load during <b>abductive</b> <b>reasoning.</b> The computational model views <b>abductive</b> <b>reasoning</b> as the sequential comprehension and integration of observations into a situation model that represents the current best explanation for the observations. The proposed WM mechanism assumes that the situation model is only partly kept in WM, whereas other pieces are stored in long-term memory. These long-term representation part can be reliably accessed through retrieval structures to reinstatiate information in WM during <b>abductive</b> <b>reasoning.</b> It is assumed that unexplained observations are actively maintained in WM until an explanation for them could be generated. Thereafter their representation is lost from WM. But these explained observations can be recalled from long-term memory via their integration into the situation model. This mechanism makes predictions about the availability of the mental representation of explained and unexplained observations. These predictions were tested in four experiments, using different memory tests for observations. In Experiments 1 and 2 a recognition test was used, in Experiment 3 an implicit menory test was used and in Experiment 4 the participants had to perform an unexpected recall after task interruption. The results show that unexplained observations are accessed faster than explained ones during <b>abductive</b> <b>reasoning.</b> This confirms the mechanism's assumption that unexplained observations are kept in WM and explained ones not. But explained observations seem not to be represented in long-term memory. Rather, it seems that observations are rapidly forgotten afer they are explained. Different possible reasons for this pattern of result are discussed...|$|R
40|$|Summary. We {{discuss the}} {{adoption}} of a three-valued setting for inductive concept learning. Distinguishing between what is true, what is false and what is unknown can be useful in situations where decisions have to be taken on the basis of scarce, ambiguous, or downright contradictory information. In a three-valued setting, we learn a definition for both the target concept and its opposite, considering positive and negative examples as instances of two disjoint classes. Explicit negation is used to represent the opposite concept, while default negation is used to ensure consistency and to handle exceptions to general rules. Exceptions are represented by examples covered by the definition for a concept that belong to the training set for the opposite concept. After obtaining the knowledge resulting from this learning process, an agent can then interact with the environment by perceiving it and acting upon it. However, in order to know what is the best course of action to take the agent must know the causes or explanations of the observed phenomena. Abduction, or <b>abductive</b> <b>reasoning,</b> is the <b>process</b> of <b>reasoning</b> to the best explanations...|$|R
5000|$|<b>Abductive</b> <b>reasoning</b> {{is a form}} of {{inference}} {{which goes}} from an observation to a theory which accounts for the observation, ideally seeking to find the simplest and most likely explanation. In <b>abductive</b> <b>reasoning,</b> unlike in deductive reasoning, the premises do not guarantee the conclusion. One can understand <b>abductive</b> <b>reasoning</b> as [...] "inference to the best explanation".|$|R
40|$|International audienceIn this paper, {{we propose}} an {{original}} way of enriching description logics with abduction reasoning services. Under {{the aegis of}} set and lattice theories, we put together ingredients from mathematical morphology, description logics, and formal concept analysis. We propose computing the best explanations of an observation through algebraic erosion over the concept lattice of a background theory that is efficiently constructed using tools from formal concept analysis. We show that the defined operators are sound and complete and satisfy important rationality postulates of abductive reasoning. As a typical illustration, we consider a scene understanding problem. In fact, scene understanding can benefit from prior structural knowledge represented as an ontology and the reasoning tools of description logics. We formulate model based scene understanding as an <b>abductive</b> <b>reasoning</b> <b>process.</b> A scene is viewed as an observation and the interpretation {{is defined as the}} best explanation, considering the terminological knowledge part of a description logic about the scene context. This explanation is obtained from morphological operators applied on the corresponding concept lattice...|$|E
40|$|Diagrammatic {{reasoning}} is ubiquitous in Army reasoning: situation understanding and planning in the Army both involve representing {{aspects of the}} situation and plans in the form of diagrams. We have been developing a general architecture to support diagrammatic reasoning for Army applications, and in an earlier report [1] we discussed an application in simple maneuver recognition. Our research strategy has been to investigate a variety of applications, each bringing additional requirements for perception and diagrammatic object creating capabilities that can assist the army. One such area is the army’s All Source Analysis System (ASAS) that is designed to automate the processing and analysis of intelligence data from all possible sources. One of its purposes is to keep track of various enemy assets, based on a variety of sensors and reports, including direct sightings of entities. In order to maintain a coherent view, the system has to decide whether a new sighting refers to a new entity, a previously known entity that has since moved (re-identification) or is erroneous. This is the entity re-identification task. We have a built a system that uses an <b>abductive</b> <b>reasoning</b> <b>process</b> together with a diagrammatic reasoning system to solve this problem. In this paper, we {{look at some of the}} issues that the entity re-identification task poses for diagrammatic reasoning. Whe...|$|E
40|$|This thesis {{describes}} {{and analyses}} the trends and developments of actors along distribution channel. In particular, the study focuses on resellers and manufacturer {{based on the}} empirical material from one particular case study. The study has three main goals: (1) to investigate the challenges arising from channel actor developments, {{the effects of these}} developments on the structure of the retailer supply chain and their implications for manufacturers and suppliers, (2) to identify explanations for manufacturer’s vertical integration of distribution and the resulting impacts and, (3) to conduct a preliminary customer value analysis relating to the distribution channel of solid wood products. The study has taken an exploratory and qualitative research approach with an <b>abductive</b> <b>reasoning</b> <b>process.</b> A case study strategy was adopted, which studied a distribution channel consisting of a Sweden-based timber manufacturer that vertically integrated a distributor in the UK. Semi-structured interviews comprised the primary data collection technique in this study. A two-step data collection process was conducted between May 2009 and April 2010, including 29 interviews with 24 interviewees from eight organizations, representing the manufacturer, distributor and reseller in the distribution channel. Non-participating observations were carried out by attending sales meeting and joining account managers on store visits. All interviews were documented and transcribed and the information was collated into case units, along with any supporting secondary data, such as company magazines, web resources, annual reports, sales reports, meeting presentations, etc. This thesis has produced several findings. Reseller developments have promoted the formation of reseller demands, such as integrated solutions with respects to logistics, marketing, merchandising, innovation, etc. Retailer developments have driven the change of a retailer supply chain structure, and have opened up a number of new questions to be posed on manufacturer and its positioning in the supply chain. The most important factors driving the manufacturer’s vertical integration of distribution are customer demands, the manufacturer’s repositioning strategy with regard to its business focus and its positioning in the supply chain. The vertical integration of distribution transforms the manufacturer into a direct supplier to large timber product resellers. It also offers the supplier a great opportunity to enhance offerings and establish strategic relationship with customers. The output of suppliers has expanded from solely manufacturing goods to also include services and knowledge associated with goods. In practice, it can be complicated for a supplier to create and communicate value. A full understanding of what timber product customers seek in terms of value elements has not yet been achieved. This study has assisted in terms of understanding the differing value that channel actors place on a range of product, physical distribution, service and supplier value elements by developing a value analysis framework. Suppliers can use this framework when designing, customizing and marketing offerings for customers...|$|E
40|$|This paper {{explores the}} {{uncertainty}} {{aspects of human}} <b>abductive</b> <b>reasoning.</b> Echo, a model of abduction based on the Theory of Explanatory Coherence (Thagard, 1992 a), captures many aspects of human <b>abductive</b> <b>reasoning,</b> but fails to sufficiently manage the uncertainty in abduction. In particular, Echo does not handle belief acquisition and dynamic belief revision, two essential components of human <b>abductive</b> <b>reasoning...</b>|$|R
40|$|The aim of {{this paper}} is to {{describe}} the ADAPtER system, a diagnostic architecture combining case-based <b>reasoning</b> with <b>abductive</b> <b>reasoning</b> and exploiting the adaptation of the solution of old episodes, in order to focus the <b>reasoning</b> <b>process.</b> Domain knowledge is represented via a logical model and basic mechanisms, based on <b>abductive</b> <b>reasoning</b> with consistency constraints, have been defined for solving complex diagnostic problems involving multiple faults. The model-based component has been supplemented with a case memory and adaptation mechanisms have been developed, in order to make the diagnostic system able to exploit past experience in solving new cases. A heuristic function is proposed, able to rank the solutions associated to retrieved cases with respect to the adaptation effort needed to transform such solutions into possible solutions for the current case. We will discuss some preliminary experiments showing the validity of the above heuristic and the convenience of solving [...] ...|$|R
50|$|<b>Abductive</b> <b>reasoning</b> (also called abduction, abductive {{inference}}, or retroduction) {{is a form}} {{of logical}} inference which starts with an observation then seeks to find the simplest and most likely explanation. In <b>abductive</b> <b>reasoning,</b> unlike in deductive reasoning, the premises do not guarantee the conclusion. One can understand <b>abductive</b> <b>reasoning</b> as inference to the best explanation, although not all uses of the terms abduction and inference to the best explanation are exactly equivalent.|$|R
40|$|The {{intent of}} this {{dissertation}} {{is to make}} a contribution to the field of pharmacovigilance. Pharmacovigilance, also known as post-marketing drug surveillance, is the process of continued monitoring for adverse drug reactions (ADRs) after drugs are released into the market. An ADR is a harmful or unpleasant reaction related to the use of a medical product. ADRs were reported to be between the fourth and sixth leading cause of death in the United States in 1994, accounting for 3 - 7 % of medical hospital admissions. On account of the practice of pharmacovigilance, Vioxx (Rofecoxib) and Avandia (Rosiglitazone) are examples of high profile drugs that were suspended from the American or European market. To prevent these effects on human health, pre-marketing clinical trials are designed to test drug safety and efficacy. Although clinical trials are extensive and last multiple years, rare ADRs may not be detected, and others may occur on account of idiosyncratic characteristics of individuals excluded from the evaluated sample. To aid the pharmacovigilance process, automated methods for the identification of strongly correlated drug/ADR pairs from data sources such as adverse event reporting systems, or Electronic Health Records (EHRs), have been developed. These methods however are generally statistical in nature, and do not draw upon the large volumes of knowledge embedded in the biomedical literature. In this dissertation I investigate the ability of scalable Literature Based Discovery (LBD) methods to identify side effects of pharmaceutical agents in a computationally automated manner. LBD methods can provide evidence from the literature to support the plausibility of a drug/ADR association, thereby assisting human review to validate the signal, which is an essential component of pharmacovigilance. The hypothesis underlying this work is that by combining signals mined from EHR data with biomedical domain knowledge, the accuracy of side effects detection may be improved. This also addresses the lack of causality assessment in existing statistical methods in pharmacovigilance practice. My theoretical contribution is that by conducting automated abductive reasoning and by estimating the strength of generated explanatory hypotheses the plausibility of a drug/ADR signal can be assessed. I adapt and extend the original <b>abductive</b> <b>reasoning</b> <b>process</b> as defined by Peirce in 19 th century by stating that the strength of the explanations found for an observation is a measure for its plausibility, rather than taking an observation as given. Practical contributions to pharmacovigilance and informatics include the development of methods to leverage the knowledge from biomedical literature, the detection of signals from the EHR data and the subsequent evaluation using supporting evidence from the literature on a large scale in an automated way, and the development of an improved drug/ADR reference set. My contributions are not restricted to pharmacovigilance and as such constitute a contribution to the field of informatics in general. I demonstrate that my work has extended {{the state of the art}} in EHR-based pharmacovigilance and contribute new ideas that pave the way for further studies with the potential to further enhance the field of pharmacovigilance and drug safety...|$|E
40|$|A {{framework}} for ecological display design is presented from the cognitive systems engineering perspective. This triadic approach views the interface {{as a medium}} that stands between the domain (situations) and the human (awareness); effective displays “close the loop” of this dynamical system, thereby supporting <b>abductive</b> learning and <b>reasoning</b> <b>processes.</b> All three of these system components (domain, interface, agent) and the interactions between them are incorporated into a single {{framework for}} display design. Analogical representations (i. e., configural displays) will typically provide good solutions for law-driven domains (e. g., process control); the visual properties (i. e., emergent features) should reflect {{the constraints of the}} underlying work domain. Metaphorical representations (i. e., pictorial displays) will typically provide the best options for intent-driven domains (e. g., mobile phones); the visual properties (icons) should leverage existing knowledge and support the processes of assimilation and accommodation. The role of CSE work domain analysis tools in obtaining the information needed to implement these alternative designs is described...|$|R
40|$|Atocha Aliseda {{gives in}} <b>Abductive</b> <b>Reasoning</b> (2006) a {{structural}} {{characterization of the}} forward explanatory reasoning from a theory to observational data. This paper discusses the converse problem of giving structural rules for the backward <b>abductive</b> <b>reasoning</b> from observations to explanatory theories...|$|R
40|$|AbstractAbduction is an {{inference}} mechanism where given {{a knowledge}} base and some observations, the reasoner {{tries to find}} hypotheses which together with the knowledge base explain the observations. A reasoning based on such an inference mechanism {{is referred to as}} <b>abductive</b> <b>reasoning.</b> Given a theory and some observations, by filtering the theory with the observations, we mean selecting only those models of the theory that entail the observations. Entailment with respect to these selected models is referred to as filter entailment. In this paper we give necessary and sufficient conditions when <b>abductive</b> <b>reasoning</b> with respect to a theory and some observations is equivalent to the corresponding filter entailment. We then give sufficiency conditions for particular knowledge representation formalisms that guarantee that <b>abductive</b> <b>reasoning</b> can indeed be done through filtering and present examples from the knowledge representation literature where <b>abductive</b> <b>reasoning</b> is done through filtering. We extend the notions of <b>abductive</b> <b>reasoning</b> and filter entailment to allow preferences among explanations and models respectively and give conditions when they are equivalent. Finally, we give a weaker notion of abduction and <b>abductive</b> <b>reasoning</b> and show the later to be equivalent to filter entailment under less restrictive conditions...|$|R
40|$|This work proposes an {{understanding}} of deductive, default and <b>abductive</b> <b>reasoning</b> as different instances of the same phenomenon: epistemic dynamics. It discusses the main intuitions behind {{each one of these}} <b>reasoning</b> <b>processes,</b> and suggest how they can be understood as different epistemic actions that modify an agent’s knowledge and/or beliefs in a different way, making formal the discussion {{with the use of the}} dynamic epistemic logic framework. The ideas in this paper put the studied processes under the same umbrella, thus highlighting their relationship and allowing a better understanding of how they interact together...|$|R
40|$|This {{paper offers}} first steps towards a {{typology}} of forms and uses of <b>abductive</b> <b>reasoning</b> in mathematics education. It organises several descriptions of <b>abductive</b> <b>reasoning</b> {{found in the}} literature in terms of their logical forms, the relation between specifics and generalities found in them, and the uses suggested for <b>abductive</b> <b>reasoning.</b> Examples are then given of <b>abductive</b> <b>reasoning</b> in mathematics classrooms, and these examples are described making use of the typology developed. Most people, if you describe a train of events to them, will tell you what the result would be. They can put those events together in their minds, and argue from them that something will come to pass. There are few people, however, who, if you told them the result, would be able to evolve from their own inner consciousness what the steps were which led up to that result. This power is what I mean when I talk of reasoning backward. Sherlock Holmes in Study in Scarlet There is a growing literature on the importance of <b>abductive</b> <b>reasoning</b> i...|$|R
50|$|For a {{good example}} of <b>abductive</b> <b>reasoning,</b> look at logical reasoning.|$|R
5000|$|<b>Abductive</b> <b>reasoning</b> allows {{inferring}} [...] as {{an explanation}} of [...] As {{a result of this}} inference, abduction allows the precondition [...] to be abduced from the consequence [...] Deductive <b>reasoning</b> and <b>abductive</b> <b>reasoning</b> thus differ in the direction in which a rule like [...] " [...] entails [...] " [...] is used for inference.|$|R
40|$|This paper {{shows some}} {{interesting}} properties of Kleene's three-valued logic {{in relation to}} <b>abductive</b> <b>reasoning.</b> A semantical characterization of abductive explanations is proposed, based {{on the notion of}} minimal three-valued model. This establishes a relation between the minimization problem in <b>abductive</b> <b>reasoning</b> and three-valued semantics, in the same sense as non-monotonic reasoning deals with minimization in two-valued semantic...|$|R
40|$|Abduction is an {{inference}} mechanism where given {{a knowledge}} base and some observations, the reasoner {{tries to find}} hypotheses which together with the knowledge base explain the observations. A reasoning based on such an inference mechanism {{is referred to as}} <b>abductive</b> <b>reasoning.</b> Given a theory and some observations, by filtering the theory with the observations, we mean selecting only those models of the theory that entail the observations. Entailment with respect to these selected models is referred to as filter entailment. In this paper we give necessary and sufficient conditions when <b>abductive</b> <b>reasoning</b> with respect to a theory and some observations is equivalent to the corresponding filter entailment. We then give sufficiency conditions for particular knowledge representation formalisms that guarantee that <b>abductive</b> <b>reasoning</b> can indeed be done through filtering and present examples from the knowledge representation literature where <b>abductive</b> <b>reasoning</b> is done through filtering. We [...] ...|$|R
40|$|When {{dealing with}} <b>abductive</b> <b>reasoning</b> in {{scientific}} discovery, historical case studies are focused {{mostly on the}} physical sciences, as with the discoveries of Kepler, Galilei and Newton. We will present {{a case study of}} <b>abductive</b> <b>reasoning</b> in early algebra. Two new concepts introduced by Cardano in his Ars Magna, imaginary numbers and a negative solution to a linear problem, can be explained {{as a result of a}} process of abduction. We will show that the first appearance of these new concepts fits very well Peirce’s original description of <b>abductive</b> <b>reasoning.</b> Abduction may be regarded as one important strategy for the formation of new concepts in mathematics...|$|R
40|$|In {{this paper}} {{we are going}} to {{investigate}} the role of <b>abductive</b> <b>reasoning</b> in the interpretation of natural language, arguing that the similarities go deeper than the ones shown in other works, and that we can derive from this parallel some enrichment of the notion of <b>abductive</b> <b>reasoning.</b> In talking about the interpretation of natural language, we refer specifically to the work of Donal...|$|R
40|$|Arti cial {{intelligence}} {{researchers have}} been designing representation systems for default and <b>abductive</b> <b>reasoning.</b> Logic Programming {{researchers have been}} working on techniques to improve the e ciency of Horn Clause deduction systems. This paper describes how one such default and <b>abductive</b> <b>reasoning</b> system (namely Theorist) can be translated into Horn clauses (with negation as failure), so that we can use the clarity of <b>abductive</b> <b>reasoning</b> systems and the e ciency of Horn clause deduction systems. We thus show howadvances in expressive power that arti cial intelligence workers are working on can directly utilise advances in e ciency that logic programming researchers are working on. Actual code from a running system is given. ...|$|R
500|$|... Harrowitz {{discusses}} Dupin's {{method in}} the light of Charles Sanders Peirce's logic of making good guesses or <b>abductive</b> <b>reasoning.</b>|$|R
5000|$|Model-based {{diagnosis}} {{is an example}} of <b>abductive</b> <b>reasoning</b> using a model of the system. In general, it works as follows: ...|$|R
5000|$|Abductive {{inference}} [...] {{starts with}} a set of facts F which is a statement (Boolean expression). <b>Abductive</b> <b>reasoning</b> is of the form, ...|$|R
40|$|Abductive {{inference}} {{has many}} known applications in multiagent systems. However, most abductive frameworks {{rely on a}} centrally executed proof procedure whereas many of the application problems are distributed by nature. Confidentiality and communication overhead concerns often preclude transmitting all the knowledge required for centralised reasoning. We present in this paper a novel multi-agent <b>abductive</b> <b>reasoning</b> framework underpinned by a flexible and extensible distributed proof procedure that permits collaborative <b>abductive</b> <b>reasoning</b> with constraints between agents over decentralised knowledge...|$|R
500|$|... Harrowitz {{discusses}} Poe's [...] "tales of ratiocination" [...] in {{the light}} of Charles Sanders Peirce's logic of making good guesses or <b>abductive</b> <b>reasoning.</b>|$|R
