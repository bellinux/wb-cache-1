18|85|Public
5000|$|Many storage heaters {{also have}} a mechanically-controlled <b>automatic</b> <b>output</b> switch. In this case, if the manual output switch is not set to minimum overnight, the damper will {{automatically}} close (as if the output switch had been set to minimum), and then the damper will re-open after a time delay; this time delay {{is measured by the}} gradual drop in the heater's core temperature, and is therefore longer if the core temperature started higher due to more charge. The delay can also be biased by the output switch's setting. [...] Some output switches that are set up this way are marked [...] "early" [...] and [...] "late" [...] as well as [...] "closed" [...] and [...] "open"; the minimum [...] "closed" [...] setting corresponds with [...] "early" [...] and the maximum [...] "open" [...] setting corresponds with [...] "late". These output switches can be controlled manually by ensuring they are closed at night and opened when desired, or they can be left to automatic operation by not closing at night.|$|E
40|$|In China, {{there has}} been a common {{phenomenon}} in English grammar teaching that much emphasis has been laid on the input of students’ English grammatical knowledge while little has been paid on the improvement of their grammatical competence, which directly leads to an obvious gap between students’ English grammatical knowledge and their grammatical competence. According to Anderson’s cognitive theory of ACT, learners will go through three stages (cognitive, associative and automatic stage) from declarative knowledge to procedural knowledge in acquiring the automatic skills. This paper studies the implication of cognitive theory of ACT in English Grammar acquisition, internalization and <b>automatic</b> <b>output.</b> Basing on the integration between explicit grammatical knowledge and implicit grammatical competence in grammar acquisition, we put forward an English grammar <b>automatic</b> <b>output</b> model, aiming at helping foreign language learners narrow down the gap between their grammatical knowledge and grammatical competence under non-native environment...|$|E
40|$|Several {{improvements}} and enhancements recently made to NASTRAN are described. Some {{of the more}} important features are: streamlined rigid formats; improved rigid formats; changes related to plotting; checking of required PARAM bulk data cards; checkpoint/restart capability; unsorted and sorted bulk data deck echo; <b>automatic</b> <b>output</b> of the DMAP source listing; elimination of link switching caused by use of utility modules; paging the NASTRAN output; processing of mixed record data blocks by INPUT 2 /OUTPUT 2 modules; module execute flag included in the OSCAR listing; and use of the multiple XDMAP cards in the DMAP. It is concluded that these changes increase the usefulness of the program...|$|E
50|$|This six-door {{limousine}} {{is powered}} by a 7.7-liter fuel-injection gasoline engine connected to a 6-speed <b>automatic</b> transmission.It <b>outputs</b> 400 hp (298 kW).|$|R
40|$|International audienceThis paper {{presents}} an <b>automatic</b> <b>outputs</b> generation based on XML description of intelligent instruments. This description uses the service based approach called INOMs. The XML representation of intelligent instruments enables three different outputs: user informations output in html format, supervisor information output, and source code output for selected field bus network target. The intelligent instrument model is briefly described {{and the area}} of interest consists in the automatic code generation. A basic example is presented in order to illustrate the different steps and to show {{the simplicity of the}} operational implementation...|$|R
5000|$|The GE series Sigma was {{the first}} to {{introduce}} the Australian market to the Astron engine range. The 1.6-litre Saturn engine with four-speed manual transmission was also available in the base model, badged Sigma Galant. The Saturn engine was good for [...] of power and 117 Nm of torque. The mid-range model, the Sigma GL, came standard with the 1.85-litre Astron and four-speed manual, providing [...] and 145 Nm. Both Galant and GL had an upgrade option to the 2.0-litre Astron engine—standard with four-speed manual or optional five-speed manual or three-speed <b>automatic.</b> <b>Outputs</b> for the 2.0-litre were [...] and 145 Nm. The top-line model, the Sigma SE, offered the 2.0-litre and five-speed standard—automatic remained an option. The Astron engines were initially imported, with the Lonsdale, South Australia engine plant producing the Astron from October 1979.|$|R
40|$|We {{present a}} new model format for automatized matrix-element generators, the so- called Universal FeynRules Output (UFO). The format is {{universal}} {{in the sense that}} it features compatibility with more than one single generator and is designed to be flexible, modular and agnostic of any assumption such as the number of particles or the color and Lorentz structures appearing in the interaction vertices. Unlike other model formats where text files need to be parsed, the information on the model is encoded into a Python module that can easily be linked to other computer codes. We then describe an interface for the Mathematica package FeynRules that allows for an <b>automatic</b> <b>output</b> of models in the UFO format. Comment: 30 pages, 2 figures, version accepted by CP...|$|E
40|$|The {{idea that}} people can {{entertain}} propositions without believing them is widespread, intuitive, and most probably false. The main goal of this essay is to argue against the claim that people can entertain a proposition without believing it. Evidence is presented demonstrating that we cannot withhold assent from any proposition we happen to consider. A model of belief fixation is then sketched and used to explain hitherto disparate, recalcitrant, and somewhat mysterious psychological phenomena. The proposed model is one where beliefs are the <b>automatic</b> <b>output</b> of a computationally null belief acquisition reflex. In short, the model holds that the mere tokening of a mentally represented truth apt proposition leads to immediately believing it. The essay concludes by considering some consequences that the proposed model of belief acquisition has for our concept o...|$|E
40|$|Oxford University Library Services (OULS) {{is using}} Ulrich's Serials Analysis System (USAS) {{to manage and}} {{rationalize}} periodical holdings across 36 libraries. With the exact level of duplication having been identified through USAS, OULS has access {{to a range of}} reports and analyses which have been utilized in a variety of ways. This article explores some of the main practical purposes which USAS has served at Oxford. It shows how the system can be used in conjunction with an electronic database of library holdings in order to create increasingly versatile reports. Although USAS has flaws, its main strength is its ability to process large amounts of data and present output in a very usable format. The fact that this <b>automatic</b> <b>output</b> still needs manual manipulation does not alter the system's essential efficiency. Citation: Martinsen, D. (2006). 'Putting Ulrich's Serials Analysis System to work: experiences at Oxford University Library Services', Serials 19 (3), 208 - 213. [Available at [URL]...|$|E
40|$|The paper {{deals with}} the problem of <b>automatic</b> {{labeling}} <b>output</b> variables in Mamdani-type fuzzy rules generated by using heuristic algorithms of possibilistic clustering. The labeling problem in fuzzy clustering and basic concepts the heuristic approach to possibilistic clustering are considered in brief. Labeling consequents procedure is proposed. Experimental results are presented shortly and some preliminary conclusions are made...|$|R
40|$|When {{the vessels}} of the bulbar {{conjunctiva}} get congested with blood, a characteristic red hue {{appears in the}} area. This symptom is known as hyperemia, and can be an early indicator of certain pathologies. Therefore, a prompt diagnosis is desirable {{in order to minimize}} both medical and economic repercussions. A fully automatic methodology for hyperemia grading in the bulbar conjunctiva was developed, by means of image processing and machine learning techniques. As there is a wide range of illumination, contrast, and focus issues in the images that specialists use to perform the grading, a repeatability analysis is necessary. Thus, the validation of each step of the methodology was performed, analyzing how variations in the images are translated to the results, and comparing them to the optometrist's measurements. Our results prove the robustness of our methodology to various conditions. Moreover, the differences in the <b>automatic</b> <b>outputs</b> are similar to the optometrist's ones...|$|R
40|$|Word {{co-occurrences}} form a graph, regarding {{words as}} nodes and co-occurrence relations as branches. Ambiguous words connect subgraphs of different topics {{to make a}} huge connected graph. For clustering, therefore, the ambiguous words should be detected to decompose this connected graph apart. We observed that the ambiguous words has structural feature in transitivity of co-occurrence relation: two cooccurring words of an ambiguous word don't cooccur. Here we show the clustering method using transitivity and discuss its effectiveness by an experiment using actual co-occurrence obtained from a 20 M corpus. 1 Introduction Clustering is the operation to group words by some criterion. Thesauri, synonym dictionaries are some examples of manual <b>outputs.</b> <b>Automatic</b> <b>outputs</b> can be used not only to revise them, but also to aid ambiguity resolution, an essential problem in natural language processing. For instance, the meaning of an ambiguous word can be decided by examing in which cluster it belo [...] ...|$|R
40|$|AbstractA {{non-deterministic}} evolutionary {{approach for}} approximating {{the outlines of}} planar shapes has been developed. Non-uniform Rational B-splines (NURBS) have been utilized as an underlying approximation curve scheme. Simulated Annealing heuristic is used as an evolutionary methodology. In addition to independent studies of the optimization of weight and knot parameters of the NURBS, a separate scheme has also been developed for the optimization of weights and knots simultaneously. The optimized NURBS models have been fitted over the contour data of the planar shapes for the ultimate and <b>automatic</b> <b>output.</b> The output results are visually pleasing {{with respect to the}} threshold provided by the user. A web-based system has also been developed for the effective and worldwide utilization. The objective of this system is to provide the facility to visualize the output to the whole world through internet by providing the freedom to the user for various desired input parameters setting in the algorithm designed...|$|E
40|$|Abstract. Steel {{portal frames}} {{have been widely}} {{designed}} and constructed in China {{since the end of}} the last century, and in recent years ERP management software systems have been used by more and more steel structure fabricators/constructors. This paper introduces the program principles and techniques of the development of integrated CAD software with ERP interface for the detailing design of steel portal frame structure, including the frame work, data structure, 3 D modeling algorithm and <b>automatic</b> <b>output</b> of 2 D drawings/ERP source data. In the system, steel members and connectors are modeled and visualized as 3 D objects. All information, involving geometry, material, manufacturing, fabrication, installation, ERP data requirements and so on, are embedded in these 3 D objects for the purpose of parametric modeling and subsequent data output. 3 D solid model acts as the kernel of the system. Connectors of joints are classified and organized by way of logic hierarchy, 3 D model of joint are assembled abide by the structural and geometric dependency relationship between connectors. The ERP data interface is embedded in the system. The raw data are directly extracted from the 3 D model, then formatted and fed to certain ERP system...|$|E
40|$|For {{a couple}} of years, access to {{microdata}} in Germany has been possible through different ways of access. The researcher can use so called scientific use files, even for business microdata, {{in his or her}} own institution, he or she can visit the safe centre or can use remote data execution. There are still reservations in the scientific community concerning the data perturbation methods for business microdata. The user needs are developing towards on-site data access, because most often researchers would like to work with original data. On the one hand this leads to a higher burden for the employees of the research data centre (RDC) because they have to apply the analysis programs and have to deal with the manual output checking of the results. On the other hand the researchers themselves have to wait longer to get their results. The project "An informational infrastructure for the E-Science Age " deals with the improvement of remote access in the National Statistical Institutes (NSIs). The project aims to find solutions for better remote access in Germany through so called data structure files and <b>automatic</b> <b>output</b> checking procedures...|$|E
50|$|Results of {{supervised}} {{methods can}} be validated by drawing a distinct sub-sample of the corpus, called a 'validation set'. Documents in the validation set can be hand-coded and {{compared to the}} <b>automatic</b> coding <b>output</b> to evaluate how well the algorithm replicated human coding. This comparison can {{take the form of}} inter-coder reliability scores like those used to validate the consistency of human coders in traditional textual analysis.|$|R
25|$|Thus, {{a central}} {{conclusion}} of Keynesian economics is that, in some situations, no strong <b>automatic</b> mechanism moves <b>output</b> and employment towards full employment levels. John Hicks' IS/LM {{model has been}} the most influential interpretation of The General Theory.|$|R
40|$|<b>Automatic</b> {{evaluation}} of <b>output</b> quality for machine translation systems {{is a difficult}} task. The Institute of Computational Linguistics of Peking University has developed an automatic evaluation system called MTE. This paper introduces {{the basic principles of}} MTE, its implementation techniques and the practice experiences...|$|R
40|$|Releasing {{business}} microdata is {{a challenging}} problem for many statistical agencies. Businesses with distinct continuous {{characteristics such as}} extremely high income could easily be identified while these businesses are normally included in surveys representing the population. In order to provide data users with useful statistics while maintaining confidentiality, some statistical agencies have developed online based tools to allow users to specify and request tables created from microdata. These tools only release perturbed cell values generated from <b>automatic</b> <b>output</b> perturbation algorithms {{in order to protect}} each underlying observation against various attacks, such as differencing attacks. An example of the perturbation algorithms has been proposed by Thompson et al. (2013). The algorithm focuses largely on reducing disclosure risks without addressing much on data utility. As a result, the algorithm has limitations, including a limited scope of applicable cells and uncontrolled utility loss. In this paper we introduce a new algorithm for generating perturbed cell values. As a comparison, The new algorithm allows more control over utility loss, while it could also achieve better utility-disclosure tradeoffs in many cases, and is conjectured to be applicable to a wider scope of cells...|$|E
40|$|The aim of {{this paper}} is to explore {{grammatical}} variation between early Modern and Present-day English by means of computational devices. To that end, we compare the <b>automatic</b> <b>output</b> which the English Constraint Grammar Parser offers of an updated corpus of Renaissance texts and its corresponding modern version. In the first half of the paper we give information about the technical process; in particular, we focus on the description of the parser. The software parses every constituent and associates it with a tag which provides morphological information and dependency links (head-modifier/complement syntactic relations). It is also equipped with a disambiguation tool which reduces the number of the alternative morphosyntactic analyses of each lexical entry. The second half of the paper is devoted to the evaluation of the results obtained after the application of the parser to the Renaissance and the contemporary passages. Since the parser’s lexicon is designed to cope with only contemporary English, orthographic, lexical and morphological pre-edition has been necessary so that the parser can deal with (an adaptation of) the Renaissance source. By examining the instances exhibiting either unjustified ambiguity or parsing failure we determine to what extent the morphosyntactic rules designed for Present-day English can be suitably applied to earlier stages of the language. ...|$|E
40|$|This {{is a brief}} {{description}} of the evolution, of sofware as well as hardware, in the world of personal computer, PC. It has thoroughly put into practice the automatic generation of drawings using this equipment, emphasizing in the software, data input moduli, calculations, reinforcement and drawing. In the last item it's deepened for Autocad specifically and it has explained the DXF files generation. &# 13; Attached are two addenda, with the programs made in QuickBasic, for the generation of a drawing library, and another program of <b>automatic</b> <b>output</b> of a group of drawings to a plotter. &# 13; In the same way are presented some examples of printer and plotter out-puts. Se realiza una breve descripción de la evolución, tanto en el aspecto del software como del hardware, en el mundo del ordenador personal, el PC. Se define como perfectamente realizable la generación automática de planos utilizando estos equipos, haciendo hincapié en el aspecto del software, módulos de entrada de datos, cálculo, armado y dibujo. Sobre este último se profundiza, para el caso específico de Autocad, y se explica la generación de ficheros DXF. &# 13; Se acompañan dos anexos, con la programación realizada en QuickBasic, para la generación de una librería de dibujo y de un programa de volcado automático de una serie de planos a plotter. &# 13; Igualmente se presentan ejemplos de salida impresa de ordenador y plotte...|$|E
40|$|The Idiap {{system for}} Search and Hyperlinking Task uses topic-based segmentation, {{content-based}} recommendation algorithms, and multimodal re-ranking. For both sub-tasks, our system performs better with <b>automatic</b> speech recognition <b>output</b> than with manual subtitles. For linking, the results {{benefit from the}} fusion of text and visual concepts detected in the anchors...|$|R
40|$|In {{the article}} is given the {{mathematical}} model of the table of swinging with hydroelectric drive of the crystallizer of the slugs continuous casting machine. The mathematical model is received by methods {{of the theory of}} <b>automatic</b> operating with <b>outputting</b> in dimensionless form of transfer functions of the system several elements. </p...|$|R
40|$|A novel {{method of}} {{predicting}} the multiaxial high-cycle fatigue strength of metallic components is proposed and verified for various steel, aluminium and cast iron alloys. The proposed Fatigue Damage Function shows superior multiaxial fatigue strength prediction {{compared to the}} established methods of Gough and Pollard, McDiarmid and Carpinteri and Spagnoli. A new material property, the Normal Stress Sensitivity Factor, is also introduced and its applicability is verified according to published test results of sixteen different structural alloys. To highlight {{the effectiveness of the}} proposed criterion, for industrial applications, a case study has been conducted on heat-treated and not heat-treated <b>automatic</b> transmission <b>output</b> shafts...|$|R
40|$|When a drug is {{prescribed}} {{for a patient}} with a permanent pacemaker or an implantable cardioverter defibrillator (ICD), consideration {{must be given to}} the potential interactions. Drug effect on pacemaker performance is usually thought to cause an increase or decrease in pacing threshold. From a practical view, Class IC drugs must be used cautiously in pacemaker patients, especially in those who are pacemaker-dependent. The possibility of a rise in threshold should always be considered in these patients, and the pacemaker output should be programmed to allow an adequate pacing margin of safety. In such patients, <b>automatic</b> <b>output</b> regulation would be particularly useful. Two-third of ICD recipients are treated with antiarrhythmic drugs to reduce the frequency of ventricular tachycardia/ventricular fibrillation (VT/VF) recurrences and enhance quality of life. However, antiarrhythmic drugs may alter ventricular defibrillation threshold (DFT). Class I agents that work primarily by slowing ventricular conduction velocity increase DFT. Class III agents that work primarily by prolonging ventricular action potential duration decrease DFT. Antiarrhythmic drugs with a balance of class I and class III actions (such as amiodarone) may increase or decrease DFT. Besides affecting DFT, antiarrhythmic drugs may also alter arrhythmia cycle length and frequency, pacing thresholds, and post-shock excitability. Finally, interactions between the ICD and the pacemaker may result in sensing problems, leading to multiple counting and inappropriate shocks, VF nondetection, sensing or capture failure post defibrillation, and pacemaker reprogramming induced by defibrillator discharge...|$|E
40|$|International audiencePerceptual {{evaluation}} {{is still the}} most common method in clinical practice for diagnosing and following the progression of the condition of people with speech disorders. Although {{a number of studies have}} addressed the acoustic analysis of speech productions exhibiting impairments, additional descriptive analysis is required to manage interperson variability, considering speakers with the same condition or across different conditions. In this context, this article investigates automatic speech processing approaches dedicated to the detection and localization of abnormal acoustic phenomena in speech signal produced by people with speech disorders. This automatic process aims at enhancing the manual investigation of human experts while at the same time reducing the extent of their intervention by calling their attention to specific parts of the speech considered as atypical from an acoustical point of view. Two different approaches are proposed in this article. The first approach models only the normal speech, whereas the second models both normal and dysarthric speech. Both approaches are evaluated following two strategies: one consists of a strict phone comparison between a human annotation of abnormal phones and the <b>automatic</b> <b>output,</b> while the other uses a “one-phone delay” for the comparison. The experimental evaluation of both approaches for the task of detecting acoustic anomalies was conducted on two different corpora composed of French dysarthric speakers and control speakers. These approaches obtain very encouraging results and their potential for clinical uses with different types of dysarthria and neurological diseases is quite promising...|$|E
40|$|Abstract—Heart rate is a non-stationary {{signal and}} varies {{continuously}} {{in health and}} in disease. The pattern alteration in its variation contains indicators of current or impending diseases. Heart rate variability (HRV), a popular noninvasive tool is the variation over timeperiod between consecutive heartbeats. It assesses {{the activities of the}} autonomic nervous system and is highly useful in diagnostics, and as prognosis and research tool. As R wave is usually the tallest and most conspicuous component of ECG, for assessment of the beat to beat interval, detection of R to R interval is the standard practice. The conventional, industry derived fully automated R-R detection system are closed and compact and provides <b>automatic</b> <b>output</b> in the form of interpreted results, gives hardly any scope of innovation and independence in research. There is risk of error in case of low amplitude R waves, high amplitude T wave, arrhythmia, block, ectopic beats and also loss of valuable physiological information during the pre-processing. Instead of a fully automated computer algorithm using complex mathematical models, in the present project, a simple and user friendly tool to determine R-R intervals is developed, and use them for evaluation of Cardiac Electrophysiology, ANS profile etc. The semi-automated interactive algorithm, for which a preliminary understanding of ECG tracing is sufficient; is based upon the amplitude based technique (ABT), where simple comparison is performed with the ranges of sample ECG points falling beyond an amplitude threshold are determined to be R wave candidate. Index Terms—Amplitude based IJSE...|$|E
40|$|In {{recent years}} <b>automatic</b> voice <b>output</b> {{has become a}} new {{component}} {{in the field of}} man-machine communication. An important factor for the acceptance of voice output is its intelligibility. A comparison of the intelligibility of voice output modules shows that good voice intelligibility can be achieved by full synthetic speech as well as by parametric coding or waveform coding techniques. The decisive factors are the effort required to create a vocabulary and for the latter two approaches the choice of a suitable speaker. However, parametric coded and fully synthetic speech are still clearly felt by test persons to be unnatural. (IITB...|$|R
40|$|Prosodic {{trees as}} a {{hierarchical}} representation of prosodic organization in French {{proved to be}} efficient for automatic processing of continuous speech. We applied this technique to the prosodic boundary detection on the output of a speech recognition application {{in order to test}} whether prosodic boundaries of different levels in tree confirm or not recognition hypotheses. Two types of tree construction algorithms were tested: one using lexical information (word hypotheses), and another using only phonemic information (phoneme hypotheses). Both were successively used on the <b>automatic</b> alignment <b>output</b> ("perfect recognition " conditions) and on the ASR application output for the same spontaneous speech database so as to compare their applicability. 1...|$|R
40|$|This paper investigates empirically {{the effect}} of {{personal}} income tax progressivity on output volatility {{in a sample of}} OECD countries over the period 1982 - 2009. Our measure of tax progressivity is based on the difference between the marginal and the average income tax rate for the average production worker. We find supportive empirical evidence for the hypothesis that higher personal income tax progressivity leads to lower output volatility. All other factors constant, countries with more progressive personal income tax systems seem to benefit from stronger automatic stabilisers. JEL Classification: E 63, E 32, H 10 <b>automatic</b> stabilisers, <b>output</b> volatility, personal income taxes, Progressivity...|$|R
40|$|JRC {{started the}} design of the global human {{settlement}} layer (GHSL) concept during 2010 - 2011, together with the development of an image query (IQ) system able to generate and manage geoinformation in an integrated way. The IQ system aggregated the experiences related to automatic information extraction from meter and sub-metre resolution satellite image data in the disaster and crisis management scenarios supported by JRC since 2003 - 2004. The first alpha-test of the IQ system was delivered in Dec 2011, performing a GHSL image information query task over high and very-high resolution satellite image data covering more than 615 billions of square kilometres of global earth surface, mostly placed in populated regions of Europe, Africa, Asia and South America. During 2011, first contacts with DGREGIO were made in order to understand if the JRC IQ technology and the derived GHSL information layers may be of interest {{in the context of the}} “European Urban Atlas” (UA) implementation and in general, in pan-European mapping and characterization of European settlements. This feasibility report describes the application of the GHSL protocol according to the Urban Atlas product specifications and more specifically the comparison between SSL output information with the GHSL built-up information extraction in the context of the Urban Atlas 2012 - 2013. The objectives of the work described in this report were i) to test the processing capacity of the JRC IQ system in order to assess the feasibility of a pan-European GHSL coverage or “built-upareas detection” using the image data prepared for the UA 2012 - 2013, ii) to assess the reliability and added value of the automatic image information retrieval by systematic comparison of the <b>automatic</b> <b>output</b> with a known reference layer reporting about similar information, namely, the European soil sealing layer. JRC. G. 2 -Global security and crisis managemen...|$|E
40|$|Background: We studied {{long-term}} right ventricular (RV) pacing threshold (RVPT) {{behavior in}} patients consecutively implanted with pacemakers capable of <b>automatic</b> <b>output</b> reprogramming tracked by automatic RV threshold measurement (automatic verification of capture [AVC]). Methods: All the patients had state-of-the art steroid-eluting bipolar pacing leads and were RV-paced by an AVC algorithm {{from the three}} American manufacturers. Follow-up occurred twice {{in the first year}} after implantation, then yearly until approaching elective replacement indicator. Results: Three hundred and twenty-one patients aged 73 Â± 12 years were observed for 49 Â± 26 months on average. At implantation, RVPT was 0. 54 Â± 0. 2 V at 0. 4 ms at an average 774 Â± 217 Î© impedance. Forty-one of the 321 patients (12. 8 %) had a permanent RVPT increase above 1. 5 V at 0. 4 ms: RVPT was between 1. 6 and 2. 5 V in 29 of 321 (9 %) patients, whereas it was between 2. 6 and 3. 5 V in seven of 321 (2. 2 %) patients, and > 3. 5 V in five of 321 (1. 5 %) patients. No exit block occurred because of automatic RV output adjustment by AVC algorithms. No predictor of RVPT increase was found at multivariable analysis. The maximum RVPT increase occurred within 12 months from implantation in 19 of 321 (5. 9 %) patients, between the first and the second year in 12 of 321 (3. 7 %), between the second and the sixth year in eight of 321 (2. 5 %), and after the sixth year in two of 321 (0. 6 %). Conclusion: Despite technologic improvement in lead manufacturing, long-term increase of the RVPT occurs in about 13 % of patients, possibly representing a serious safety issue in 3. 7 % when 2. 5 V at 0. 4 ms is exceeded. AVC algorithms can improve patients' safety by automatic tailoring of the pacing output to threshold fluctuations, while maximizing device longevit...|$|E
40|$|This thesis {{presents}} scientific {{contributions to}} the field of multimodal interac- tive structured prediction (MISP). The aim of MISP is to reduce the human effort required to supervise an <b>automatic</b> <b>output,</b> in an efficient and ergonomic way. Hence, this thesis focuses on the two aspects of MISP systems. The first aspect, which refers to the interactive part of MISP, is the study of strate- gies for efficient human¿computer collaboration to produce error-free outputs. Multimodality, the second aspect, deals with other more ergonomic modalities of communication with the computer rather than keyboard and mouse. To begin with, in sequential interaction the user is assumed to supervise the output from left-to-right so that errors are corrected in sequential order. We study the problem under the decision theory framework and define an optimum decoding algorithm. The optimum algorithm is compared to the usually ap- plied, standard approach. Experimental results on several tasks suggests that the optimum algorithm is slightly better than the standard algorithm. In contrast to sequential interaction, in active interaction it is the system that decides what should be given to the user for supervision. On the one hand, user supervision can be reduced if the user is required to supervise only the outputs that the system expects to be erroneous. In this respect, we define a strategy that retrieves first the outputs with highest expected error first. Moreover, we prove that this strategy is optimum under certain conditions, which is validated by experimental results. On the other hand, if the goal is {{to reduce the number of}} corrections, active interaction works by selecting elements, one by one, e. g., words of a given output to be supervised by the user. For this case, several strategies are compared. Unlike the previous case, the strategy that performs better is to choose the element with highest confidence, which coincides with the findings of the optimum algorithm for sequential interaction. However, this also suggests that minimizing effort and supervision are contradictory goals. With respect to the multimodality aspect, this thesis delves into techniques to make multimodal systems more robust. To achieve that, multimodal systems are improved by providing contextual information of the application at hand. First, we study how to integrate e-pen interaction in a machine translation task. We contribute to the state-of-the-art by leveraging the information from the source sentence. Several strategies are compared basically grouped into two approaches: inspired by word-based translation models and n-grams generated from a phrase-based system. The experiments show that the former outper- forms the latter for this task. Furthermore, the results present remarkable improvements against not using contextual information. Second, similar ex- periments are conducted on a speech-enabled interface for interactive machine translation. The improvements over the baseline are also noticeable. How- ever, in this case, phrase-based models perform much better than word-based models. We attribute that to the fact that acoustic models are poorer estima- tions than morphologic models and, thus, they benefit more from the language model. Finally, similar techniques are proposed for dictation of handwritten documents. The results show that speech and handwritten recognition can be combined in an effective way. Finally, an evaluation with real users is carried out to compare an interactive machine translation prototype with a post-editing prototype. The results of the study reveal that users are very sensitive to the usability aspects of the user interface. Therefore, usability is a crucial aspect to consider in an human evaluation that can hinder the real benefits of the technology being evaluated. Hopefully, once usability problems are fixed, the evaluation indicates that users are more favorable to work with the interactive machine translation system than to the post-editing system. Alabau Gonzalvo, V. (2014). Multimodal interactive structured prediction [Tesis doctoral no publicada]. Universitat Politècnica de València. doi: 10. 4995 /Thesis/ 10251 / 35135. Alfresc...|$|E
40|$|To enable {{downstream}} language processing, <b>automatic</b> {{speech recognition}} <b>output</b> must be segmented into its individual sentences. Previous sentence segmentation systems have typically been very local, using low-level prosodic and lexical features to independently {{decide whether or}} not to segment at each word boundary position. In this work, we leverage global syntactic information from a syntactic parser, which is better able to capture long distance dependencies. While some previous work has included syntactic features, ours is the first to do so in a tractable, lattice-based way, which is crucial for scaling up to long-sentence contexts. Specifically, an initial hypothesis lattice is constructed using local features. Candidate sentences are then assigned syntactic language model scores. These global syntactic scores are combined with local low-level scores in a log-linear model. The resulting system significantly outperforms the most popular long-span model for sentence segmentation (the hidden event language model) on both reference text and <b>automatic</b> speech recognizer <b>output</b> from news broadcasts. Index Terms — Speech processing 1...|$|R
50|$|He {{therefore}} advocated {{active policy}} responses {{by the public}} sector, including monetary policy actions by the central bank and fiscal policy actions {{by the government to}} stabilize output over the business cycle.Thus, a central conclusion of Keynesian economics is that, in some situations, no strong <b>automatic</b> mechanism moves <b>output</b> and employment towards full employment levels. John Hicks' IS/LM model has been the most influential interpretation of The General Theory.|$|R
40|$|Abstract. The {{frequency}} {{speed control}} system in flow control based on SENLAN SB 60 frequency converter {{is made up}} of input set value and actual value which is the feedback voltage signal given by flow sensor, then adjusted by process PID <b>automatic</b> control, changes <b>output</b> frequency to regulate the speed of three-phase asynchronous motor to achieve the purpose of speed regulation, thus the tank's flow control can be obtained...|$|R
