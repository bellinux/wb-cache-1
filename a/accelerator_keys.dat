6|48|Public
25|$|Called by the {{outermost}} container {{of an object}} to interact with it while it's active, e.g. to process <b>accelerator</b> <b>keys</b> in the container's message queue that are meant for the contained object.|$|E
25|$|Allows {{the caller}} {{to ask the}} {{container}} to insert its menu items in an empty menu that will become the cooperative menu. Also allows the caller to ask the container to show or hide this menu, to show or hide dialog boxes, and to process <b>accelerator</b> <b>keys</b> received by the contained object intended for the container.|$|E
50|$|Called by the {{outermost}} container {{of an object}} to interact with it while it's active, e.g. to process <b>accelerator</b> <b>keys</b> in the container's message queue that are meant for the contained object.|$|E
40|$|At {{the present}} paper new {{mathematical}} models for optimization of the intense beam dynamics in injec-tion systems are suggested. The real geometry of the accelerating-focusing structure is considered. Opti-mization technique for beam formation systems is pro-posed. Investigations have been made for low-energy beam injection system in linear RFQ <b>accelerator.</b> <b>Key</b> word...|$|R
40|$|Subject of inquiry: {{dynamics}} of plasma stream generated by quasi-stationary plasma accelerator. The {{aim of the}} work is to carry out experimental study of integral and local characteristics of plasma flow in streams generated by quasi-stationary plasma <b>accelerators.</b> <b>Key</b> properties of plasma flow in streams, generated by quasi-stationary plasma accelerators, have been investigated. Influence of accelerator initial and boundary operating conditions on plasma flow dynamics has been presentedAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|R
40|$|This paper {{deals with}} the {{rendering}} issues {{of the problem of}} producing a real-time convincing surgery simulation. The main scope of our project is to simulate laparoscopic liver surgery. Nevertheless large parts of the technique apply to other organs. We address three aspects of the appearance of the organ surface: the organ skin texture, the specular highlights, and the reactions of the organ to the instruments. For this last aspect we address three effects: blood drops rolling on the surface, clear or deep cauterization, and whitening of the surface under local pressure. To meet the real-time constraint we use advanced graphics features such as multipass rendering, OpenGL texture extensions and lookup-tables. Our target hardware are high-end graphics accelerators such as the SGI Infinite Reality. Nevertheless most of the technique apply to low-end graphics <b>accelerators.</b> <b>Key</b> words: Real-time rendering, multipass, simulator, medical applications, textures. ...|$|R
50|$|Whitewater Resource Editor was {{an early}} {{resource}} editor developed by the Whitewater Group for Microsoft Windows 3.11. The WYSIWYG editor allowed resources to be edited, created, and managed including <b>accelerator</b> <b>keys,</b> bit maps, cursor shapes, icons, dialog boxes, menus, and more.|$|E
50|$|Allows {{the caller}} {{to ask the}} {{container}} to insert its menu items in an empty menu that will become the cooperative menu. Also allows the caller to ask the container to show or hide this menu, to show or hide dialog boxes, and to process <b>accelerator</b> <b>keys</b> received by the contained object intended for the container.|$|E
40|$|The {{proliferation}} of multiple toolbars and UI widgets {{around the perimeter}} of application windows is an indica-tion that the traditional GUI design of a single menubar is not sufficient to support large scale applications with numerous functions. In this paper we describe a new widget which is an enhancement of the traditional menub r which dramatically increases menu-item capacity. This widget, called the “Hotbox ” combines several GUI techniques which are generally used independently: <b>accelerator</b> <b>keys,</b> modal dialogs, pop-up/pull down menus, radial menus, marking menus and menubars. These techniques are fitted together to create a single, easy to learn yet fast to operate GUI widget which can handle significantly more menu-items than the traditional GUI menubar. We describe the design rationale of the Hotbox and its effectiveness in a large scale commercial application. While the Hotbox was developed for a particular application domain, the widget itself and the design rationale are potentially useful in other domains...|$|E
40|$|In {{the beam}} pipe of high-energy proton or {{positron}} accelerators an “electron cloud” {{can be generated}} {{by a variety of}} processes, e. g. by residual-gas ionization, by photoemission from synchrotron radiation, and, most importantly, by secondary emission via a beam-induced multipactoring process. The electron cloud commonly leads to a degradation of the beam vacuum by several orders of magnitude, to fast beam instabilities, to beam-size increases, and to fast or slow beam losses. At the Large Hadron Collider (LHC), the cloud electrons could also give rise to an additional heat load inside cold superconducting magnets. In addition to the direct heat deposition from incoherently moving electrons, a potential “magnetron effect” has been conjectured, where electrons would radiate coherently when moving in a strong magnetic field under the simultaneous influence of a beam-induced electric “wake” field that may become resonant with the cyclotron frequency. Electron-cloud effects are already being observed with LHC-type beam in the lower-energy LHC injector complex. In this paper, we review the characteristics of electron clouds in particle <b>accelerators,</b> <b>key</b> surface properties, electron-cloud diagnostics and observations, microwave transmission measurements and magnetron effect, electron-cloud mitigation, simulations, and open questions...|$|R
50|$|The i.MX 6 Quad {{processor}} {{makes use}} of dedicated Hardware accelerators {{in order to meet}} the targeted multimedia performance. The use of HW <b>accelerators</b> is a <b>key</b> factor inobtaining high performance at low power consumption numbers, while keeping the CPU core relatively free to perform other tasks.|$|R
40|$|We {{consider}} the nonlinear transverse motion {{in a circular}} particle <b>accelerator.</b> A <b>key</b> parameter for <b>accelerator</b> performance is the so-called dynamic aperture. This quantity {{is defined as the}} volume in phase space of the stable initial conditions. The accurate numerical computation of such a volume is very CPU-time consuming. In this paper we present some original parallel algorithms to speed-up the evaluation of the dynamic aperture. A detailed analysis of different algorithms implemented is carried out. Furthermore, we studied the dependence of the CPU-time on the phase space parameters as well as the load balancing of the proposed techniques...|$|R
40|$|<b>Accelerators</b> are <b>key</b> {{instruments}} for fundamental research, health and industry applications. International collaboration {{is very important}} for their continued optimisation. To address this oPAC is organising this two-day international workshop on Grand Challenges in Accelerator Optimisation. The workshop will provide an overview of {{the current state of the}} art in beam physics, numerical simulations and beam instrumentation and highlight existing limitations. It will discuss research and development being undertaken and ambitions to further improve the performance of existing and future facilities. In addition to invited talks, there will be industry displays and a special seminar covering recent LHC discoveries. All participants will have an opportunity to contribute a poster...|$|R
40|$|Hardware {{specialization}} {{is becoming}} an increasingly com-mon technique to enable improved performance and effi-ciency {{in spite of the}} diminished benefits of technology scal-ing. Meanwhile, computer architects have long realized the importance of focusing on the key loops that often dominate application performance. These two trends have led to a di-verse array of loop-level specialized hardware, such as SIMD engines, vector processors, GPUs, and custom <b>accelerators.</b> A <b>key</b> research challenge for these heterogeneous engines in-volves creating clean hardware/software abstractions that are highly programmable, yet still enable efficient exe-cution on both traditional and specialized microarchitec-tures. To address this challenge, this poster will present ongoing work on a new approach called explicit loop specializatio...|$|R
40|$|For the {{development}} of <b>accelerators</b> the <b>key</b> problem is the maintenance of radial and phase stability of the flow. Wide opportunities in this direction are opened by the application of superconductive systems with using the effects of magnetic potential well. Without restricting the generality of the problem, as a particular case, we have considered the stability and stationary motion conditions for charged particles in the electromagnetic fields of ideally conductive rings. Results of theoretical analysis, based on Lyapunov’s stability theory, of the radial and longitudinal particles motion in the superconductive magnetic system are presented. The estimation of criterion and conditions of beam stability is given...|$|R
40|$|Studies {{are going}} on of a new wire scanner concept. All moving parts are inside the beam vacuum and it is {{specified}} for use in all the machines across the CERN <b>accelerator</b> complex. <b>Key</b> components have been developed and tested. Work is now focussing on the installation of a prototype for test in the Super Proton Synchrotron (SPS) accelerator. This article presents the specification of the device and constraints on the design for integration in the different accelerators at CERN. The design issues of the mechanical components are discussed and optimisation work shown. Finally, the prototype design, integrating the several components into the vacuum tank is presented...|$|R
5000|$|SPEAR (originally Stanford Positron Electron Asymmetric Rings, now {{simply a}} name) was a {{collider}} at the SLAC National Accelerator Laboratory. It began running in 1972, colliding electrons and positrons with an energy of [...] During the 1970s, experiments at the <b>accelerator</b> played a <b>key</b> role in particle physics research, including {{the discovery of}} the [...] meson (awarded the 1976 Nobel Prize in physics), many charmonium states, and {{the discovery of the}} tau (awarded the 1995 Nobel Prize in physics).|$|R
40|$|The {{proposed}} polarized electron-ion collider (EIC) {{facility will}} allow for precision exploration of various novel aspects of QCD including low-x phenomena and the spin structure of the proton. As this project gains momentum, it is increasingly important for the QCD community to understand quantitatively the kinematic reach and expected sensitivities for various measurements. We briefly summarize <b>key</b> <b>accelerator</b> design parameters and then focus on expected measurement sensitivities, thus exposing how the EIC will allow {{an extension of the}} successful HERA program into exciting new regimes...|$|R
40|$|Project X, a multi-megawatt proton source under {{development}} at Fermi National <b>Accelerator</b> Laboratory. The <b>key</b> {{element of the}} project is a superconducting (SC) 3 GV continuous wave (CW) proton linac. The linac includes 5 types of SC accelerating cavities of two frequencies. (325 and 650 MHz) The cavities consume up to 30 kW average RF power and need proper main couplers. Requirements and approach to the coupler design {{are discussed in the}} report. New cost effective schemes are described. Results of electrodynamics and thermal simulations are presented...|$|R
40|$|The {{principle}} of Self-Amplified Spontaneous Emission (SASE) is presently {{the most promising}} concept to extend the working {{principle of}} Free Electron Lasers (FEL) to the VUV and X-ray wavelength regime. Several laboratories (e. g. SLAC, ANL, DESY, Spring 8) are considering large-scale installations which may be regarded as truly fourth-generation light sources, providing full transverse coherence and brilliance performance many orders of magnitude above present-day synchrotron radiation sources. The paper discusses <b>key</b> <b>accelerator</b> physics challenges to be met for achieving SASE FEL gain and power saturation as well as recent SASE demonstration experiments pursue...|$|R
40|$|Motion Compensation {{for video}} {{decoding}} in standards like H. 264 requires {{significant amount of}} computation. This is primarily because of H. 264 six-tap FIR filtering for sub-sample computation. These algorithms typically take more than 50 % of the computational time on a RISC processor like ARM. Novel algorithms proposed through this paper can be employed for systems which use vector processors as video decode accelerators to accelerate this process. The proposed algorithms are implemented on H 264 video decode system with ARM 9 host-processor and RSVP vector processor as an <b>accelerator</b> for <b>key</b> decode algorithms. By employing the proposed algorithms {{we were able to}} accelerate the motion compensation module by more than 4 times as compared to plain RISC implementation. This is achieved by efficiently vectorizing data on which FIR-filtering and reconstruction algorithm is operated on, together with optimal representation of FIR-filtering and reconstruction algorithm itself on vector processor. QC 20130610 </p...|$|R
40|$|Prior {{research}} {{hints at}} the accelerator as a new generation incubation model. Accelerators have become an umbrella term for any program providing a service structure of mentorship, networking opportunities and access to funding. The challenge, however, is to understand their distinctive characteristics and profiles geared towards reinforcing business start-ups. How do accelerators operate as a new generation incubation model {{and how do they}} differ from existing incubation mechanisms? This inductive study investigates 13 accelerators across Europe and adopts a design lens to identify the <b>accelerator</b> model’s <b>key</b> design parameters. We identify five key building blocks and distinguish between three different types of accelerators, taking the primary design theme of the accelerator into account. We contribute to the incubation literature by extending recognition of the heterogeneity of incubation models, by delineating the accelerator as a distinctive incubation model and by introducing the design lens as a useful theoretical framework to investigate incubation models and their evolution...|$|R
40|$|The {{main goal}} of the NA 62 {{experiment}} at CERN is to measure the Branching Ratio (BR) of the ultra-rare decay of a charged kaon into a charged pion and two neutrinos (K+ → pi+νν). The experiment aims to collect about 100 events in two years of data taking and to test the Standard Model of Particle Physics (SM), using a secondary hadron beam obtained by the SPS <b>accelerator.</b> The <b>key</b> issues for the Trigger and Data Acquisition system (TDAQ) are readout uniformity of sub-detectors, scalability, efficient online selection and lossless high-rate readout. The TDCB and the TEL 62 boards are the common blocks of the fully digital TDAQ {{and they will be}} used for several sub-detectors in this high-flux rare decay experiment. TDCBs measure hit times for sub-detectors, TEL 62 s process and store them in a buffer, extracting only those requested by the trigger system, which merges trigger primitives also produced by TEL 62 s. The complete dataflow and firmware organization are described...|$|R
40|$|In {{the design}} of the Next Linear Collider (NLC), multi-bunch {{operation}} is employed to improve efficiency at the cost of substantial beam loading. The RF pulse that powers the accelerator structures will be shaped to compensate for the effect of the transient loading along the bunch train. This scheme has been implemented in the Next Linear Collider Test Accelerator (NLCTA), a facility built to test the <b>key</b> <b>accelerator</b> technology of the NLC. In this paper the authors describe the compensation method, the techniques used to measure the energy variation along the bunch train, and results from tests with NLC-like beam currents...|$|R
40|$|The fine {{microstructure}} of nacre (mother of pearl) {{illustrates the}} beauty of nature. Proteins found in nacre {{were believed to be}} "natural hands" that control nacre formation. In the classical view of nacre formation, nucleation of the main minerals, calcium carbonate, is induced on and by the acidic proteins in nacre. However, the basic proteins were not expected to be components of nacre. Here, we reported that a novel basic protein, PfN 23, was a <b>key</b> <b>accelerator</b> in the control over crystal growth in nacre. The expression profile, in situ immunostaining, and in vitro immunodetection assays showed that PfN 23 was localized within calcium carbonate crystals in the nacre. Knocking down the expression of PfN 23 in adults via double-stranded RNA injection led to a disordered nacre surface in adults. Blocking the translation of PfN 23 in embryos using morpholino oligomers led to the arrest of larval development. The in vitro crystallization assay showed that PfN 23 increases the rate of calcium carbonate deposition and induced the formation of aragonite crystals with characteristics close to nacre. In addition, we constructed the peptides and truncations of different regions of this protein and found that the positively charged C-terminal region was a key region for the function of PfN 23 Taken together, the basic protein PfN 23 may be a <b>key</b> <b>accelerator</b> in the control of crystal growth in nacre. This provides a valuable balance to the classic view that acidic proteins control calcium carbonate deposition in nacre...|$|R
40|$|Objectives: To {{identify}} retrospectively through {{chart analysis}} the biochemical recurrence frequency of localized prostate cancer at diagnosis of patients submitted to surgery or radiotherapy; to correlate diagnostic characteristics {{associated with higher}} risk of bio-chemical recurrence. Materials and Methods: Retrospective analysis of 483 patients treated in a single center, from March 2000 to December 2009 in order to verify factors associated with bioche-mical recurrence. Results: Biochemical recurrence was more frequent in patients with higher initial PSA levels and those with higher risk disease. Recurrence was more frequent in patients with high risk (25. 9 %) than those with intermediate risk (10. 7 %) and low risk (5. 5 %). There was no significant statistical difference of biochemical recurrence between pa-tients submitted to radiotherapy or radical prostatectomy. Biochemical recurrence was diagnosed in only 11 of 73 patients (15 %) submitted to conformal radiotherapy using tridimensional technique. Conclusion: Radiotherapy and radical prostatectomy have similar treatment results. Tri-dimensional conformal radiotherapy used nowadays is more efficient than earlier forms of radiation therapy (cobalt therapy and bidimensional linear <b>accelerator</b> therapy). <b>Key</b> words...|$|R
40|$|The {{large-scale}} coordinate-tracking detector TREK for {{registration of}} inclined EAS {{is being developed}} in MEPhI. The detector is based on multiwire drift chambers from the neutrino experiment at the IHEP U- 70 <b>accelerator.</b> Their <b>key</b> advantages are a large effective area (1. 85 [*]m 2), a good coordinate and angular resolution with {{a small number of}} measuring channels. The detector will be operated as part of the experimental complex NEVOD, in particular, jointly with a Cherenkov water detector (CWD) with a volume of 2000 cubic meters and the coordinate detector DECOR. The first part of the detector named Coordinate-Tracking Unit based on the Drift Chambers (CTUDC), representing two coordinate planes of 8 drift chambers in each, has been developed and mounted {{on opposite sides of the}} CWD. It has the same principle of joint operation with the NEVOD-DECOR triggering system and the same drift chambers alignment, so the main features of the TREK detector will be examined. Results of the CTUDC development and a joint operation with NEVOD-DECOR complex are presented...|$|R
40|$|Silicon woodpile {{photonic}} crystals {{provide a}} base structure {{with which to}} build a three-dimensional dielectric waveguide system for high-gradient laser-driven acceleration. To realize an on-chip woodpile laser <b>accelerator,</b> a <b>key</b> component is the power coupler to deliver laser power to the fundamental accelerating mode. The woodpile waveguide is periodically loaded in the longitudinal direction; therefore simple cross-sectional mode profile matching {{is not sufficient to}} launch the accelerating mode appropriately and will result in significant scattering loss. Several traveling-wave coupler design schemes developed for multicell radio frequency cavity accelerators can be adapted to the woodpile accelerator coupler design. This paper presents design procedures and results using these methods. We present simulations indicating near 100 % power transmission between the transverse electric mode of a silicon-guide side coupler and the transverse–magnetic-like accelerating mode of a woodpile waveguide. The coupler launches a full traveling-wave propagation of the accelerating mode, which maintains its propagation quality over long waveguide structures, and provides better tolerance on the structure fabrication uncertainty and material breakdown than standing-wave coupling...|$|R
40|$|As {{the highest}} energy {{collider}} in the world, the Tevatron {{has been the}} centerpiece of Fermilab’s physics program for more than 20 years. This will all change with the imminent startup of CERN’s LHC. This note describes the lab’s plans to redefine its mission {{in terms of the}} “intensity frontier”, with a program focusing on neutrino physics, precision measurements and cutting edge <b>accelerator</b> R&D. The <b>key</b> component of this plan is an intense new proton source, referred to as “Project X”. Project X and its associated physics program will be described and compared to related programs worldwide. Also discussed will be intermediate plans which will support that lab’s physics programs while Project X is being designed and constructed...|$|R
40|$|Figure 1 : Snapshots of two {{simulation}} {{runs with}} the same initial conditions. The simulation results shown on top is the baseline, and the bottom row is simulation computed with 7 -bit mantissa floating-point computation in Narrowphase and LCP. The results are different but both are visually correct. The error tolerance of human perception offers a range of opportunities to trade numerical accuracy for performance in physics-based simulation. However, most previous approaches either focus exclusively on understanding the tolerance of the human visual system or burden the application developer with case-specific implementations. In this paper, based on a detailed set of perceptual metrics, we propose a methodology to identify the maximum error tolerance of physics simulation. Then, we apply this methodology {{in the evaluation of}} two techniques. The first is the hardware optimization technique of precision reduction which reduces the size of floating point units (FPUs), allowing more of them to occupy the same silicon area. The increased number of FPUs can significantly improve the performance of future physics <b>accelerators.</b> A <b>key</b> benefit of our approach is that it is transparent to the application developer. The second is the software optimization of choosing the largest timestep for simulation...|$|R
40|$|Electricity is very {{important}} for human settlements and a <b>key</b> <b>accelerator</b> for development and prosperity. As heat waves become more frequent and intense the reliability and efficiency of the electricity systems is threatened. Increased temperatures have adverse effects on electricity generation, transmission, distribution and demand. The high temperatures cause intentional or unintentional brownouts and blackouts, which come at high costs for people and economies. The case studies in this analysis highlight the importance of heat wave impacts to the electricity sector and the need for adaptation. The electricity sector requires a holistic approach for adaptation that comprises technological, behavioral and institutional approaches. All actors, governments, electricity companies and individuals need to collaborate in order to secure electricity supply in future heat waves...|$|R
40|$|The MONALISA group {{develops}} novel, accurate, nanometre resolution, interferometric sys-tems {{to monitor}} relative motions between <b>key</b> <b>accelerator</b> components. We use cost-eective technology {{developed for the}} telecommunications market, providing readily scalable, adaptable solutions. Key magnets and diagnostics in the beam-delivery section of the International Linear Collider (ILC) will need to maintain stable relative positions. In particular, nanometre level stabilities for the nal focus quadrupole magnets would be desirable. Even greater stability requirements will be placed on components for the Compact Linear Accelerator (CLIC). In-terferometers provide {{the only means of}} monitoring relative positions over long timescales, at the nanometre and sub-nanometre level. The latest results from our novel design, bre-coupled interferometers will be presented. PACS: 06. 30. Bp, 07. 60. Ly, 42. 62 -b...|$|R
40|$|In this paper, {{we present}} a {{flexible}} accelerator designed for networking applications. The accelerator can be utilized efficiently {{by a variety of}} Network Processor designs. Most Network Processors employ hardware <b>accelerators</b> for implementing <b>key</b> tasks. New applications require new tasks, such as pattern matching, to be performed on the packets in real-time. Using our proposed accelerator, we have implemented several such tasks and measured their performance. Specifically, the accelerator achieves 25 -fold improvement on the performance of pattern matching, and 10 -fold improvement for tree lookup, over optimized software solutions. Since the accelerator is used for different tasks, the hardware requirements are small compared to an accelerator group that implements the same set of tasks. We also present accurate analytic models to estimate the execution time of these networking tasks...|$|R
40|$|Mitochondrial {{oxidative}} stress is {{considered as a}} <b>key</b> <b>accelerator</b> of fibrosis in various organs including the liver. However, the production of {{oxidative stress}} and progression of liver fibrosis may merely represent the independent consequences of hepatocellular injury caused by the primary disease. Because {{of a lack of}} appropriate experimental models to evaluate the sole effects of oxidative stress, it is virtually unknown whether this stress is causatively linked to the progression of liver fibrosis. Here, we examined the direct effects of mitochondrial reactive oxygen species (ROS) on the progression of high fat/calorie diet-induced steatohepatitis using Tet-mev- 1 mice, in which a mutated succinate dehydroge-nase transgene impairs the mitochondrial electron transport and generates an excess amount of ROS in response to doxycycline administration. Wild type and Tet-mev- 1 mice that had been continuously given doxycycline-containing water were subsequently fe...|$|R
40|$|The LHC Software Architecture (LSA), used {{to operate}} the {{particle}} accelerators at CERN, is dependent on an on-line database to manage both high and low level parameter settings, including their evolution over time. Accelerator optics models, control sequences, reference values, are amongst the other entities being managed within the database. The LSA database {{can be considered as}} being located between the operators and the accelerators; therefore performance, availability, and security of the service as well as data integrity are paramount. To meet these requirements the LSA database model has been carefully developed, all database access is tightly controlled and instrumented, business logic is implemented within the database, and there is a semi-automatic integration with other <b>key</b> <b>accelerator</b> databases. Currently 8. 6 million settings for some 40 thousand devices of the LEIR, SPS, and LHC accelerators are being effectively managed...|$|R
40|$|This paper {{presents}} a hybrid algorithm for the petascale global simulation of atmospheric dynamics on Tianhe- 2, the world's current top-ranked supercomputer developed by China's National University of Defense Technology (NUDT). Tianhe- 2 {{is equipped with}} both Intel Xeon CPUs and Intel Xeon Phi <b>accelerators.</b> A <b>key</b> idea of the hybrid algorithm is to enable flexible domain partition between an arbitrary number of processors and accelerators, so as to achieve a balanced and efficient utilization of the entire system. We also present an asynchronous and concurrent data transfer scheme to reduce the communication overhead between CPU and accelerators. The acceleration of our global atmospheric model is conducted to improve {{the use of the}} Intel MIC architecture. For the single-node test on Tianhe- 2 against two Intel Ivy Bridge CPUs (24 cores), we can achieve 2. 07 x, 3. 18 x, and 4. 35 x speedups when using one, two, and three Intel Xeon Phi accelerators respectively. The average performance gain from SIMD vectorization on the Intel Xeon Phi processors is around 5 x (out of the 8 x theoretical case). Based on successful computation-communication overlapping, large-scale tests indicate that a nearly ideal weak-scaling efficiency of 93. 5 % is obtained when we gradually increase the number of nodes from 6 to 8, 664 (nearly 1. 7 million cores). In the strong-scaling test, the parallel efficiency is about 77 % when the number of nodes increases from 1, 536 to 8, 664 for a fixed 65, 664 × 5, 664 × 6 mesh with 77. 6 billion unknowns. © 2014 IEEE. This paper {{presents a}} hybrid algorithm for the petascale global simulation of atmospheric dynamics on Tianhe- 2, the world's current top-ranked supercomputer developed by China's National University of Defense Technology (NUDT). Tianhe- 2 is equipped with both Intel Xeon CPUs and Intel Xeon Phi <b>accelerators.</b> A <b>key</b> idea of the hybrid algorithm is to enable flexible domain partition between an arbitrary number of processors and accelerators, so as to achieve a balanced and efficient utilization of the entire system. We also present an asynchronous and concurrent data transfer scheme to reduce the communication overhead between CPU and accelerators. The acceleration of our global atmospheric model is conducted to improve the use of the Intel MIC architecture. For the single-node test on Tianhe- 2 against two Intel Ivy Bridge CPUs (24 cores), we can achieve 2. 07 x, 3. 18 x, and 4. 35 x speedups when using one, two, and three Intel Xeon Phi accelerators respectively. The average performance gain from SIMD vectorization on the Intel Xeon Phi processors is around 5 x (out of the 8 x theoretical case). Based on successful computation-communication overlapping, large-scale tests indicate that a nearly ideal weak-scaling efficiency of 93. 5 % is obtained when we gradually increase the number of nodes from 6 to 8, 664 (nearly 1. 7 million cores). In the strong-scaling test, the parallel efficiency is about 77 % when the number of nodes increases from 1, 536 to 8, 664 for a fixed 65, 664 × 5, 664 × 6 mesh with 77. 6 billion unknowns. © 2014 IEEE...|$|R
