0|490|Public
50|$|Sound {{processing}} {{of the human}} auditory system is performed in so-called <b>critical</b> <b>bands.</b> The hearing range is segmented into 24 <b>critical</b> <b>bands,</b> each with a width of 1 Bark or 100 Mel. For a directional analysis the signals inside the <b>critical</b> <b>band</b> are analyzed together.|$|R
40|$|Accuracy of an {{automatic}} speaker recognition system predominantly depends on speaker models and {{features that are}} used. An influence of the shape of auditory <b>critical</b> <b>bands</b> and a contribution of individual components of MFCC-based feature vectors are investigated in the paper and some experimental results are presented and showed {{their impact on the}} accuracy of automatic speaker recognition. The speaker-discrimination capability of the MFCCs was experimentally determined by comparing training and test models for the same speaker. The experiments are conducted with three speech databases and showed that 0 th and 19 th (the last one) MFCCs are non speaker discriminative. The values of MFCCs are determined by the type of applied auditory <b>critical</b> <b>band.</b> The exponential auditory <b>critical</b> <b>bands</b> based on the lower part of exponential function have outperformed the speaker recognition accuracy of other auditory <b>critical</b> <b>bands</b> such as rectangular or triangular shape...|$|R
40|$|This paper {{introduces}} {{the design of}} a critically sampled, third octave filter bank. Filter design methods are shown for the octave band filter bank and the third octave sections. In addition, the trade-offs in the design are explained among frequency selectivity, regularity, complexity and memory. 1 Introduction The front end of most current audio data compression algorithms use some sort of time-frequency representation to transform the time domain signal to some other domain more closely matched to the human ear. One accepted model is often called the <b>critical</b> <b>band</b> model, which shows how signals psychoacoustically mask one another, {{as long as they are}} within a <b>critical</b> <b>band</b> [Zwicker, 1990]. A close approximation to the <b>critical</b> <b>bands</b> of hearing is a third octave filter bank, which is designed in this paper. Thus, if a signal were bandlimited within a <b>critical</b> <b>band,</b> and then quantized, the resultant quantization noise would remain within the band and would be perceptually masked by t [...] ...|$|R
5000|$|... 2) Composing & Rehearsing - Students {{solve the}} musical problem in group {{composition}} projects {{by developing a}} musical hypothesis and testing it using <b>aural</b> logic. <b>Critical</b> thought {{should be used in}} solving the problem, and all students are encouraged to experiment.|$|R
50|$|The scale {{ranges from}} 1 to 24 and {{corresponds}} to the first 24 <b>critical</b> <b>bands</b> of hearing.|$|R
5000|$|In {{audiology}} and psychoacoustics {{the concept}} of <b>critical</b> <b>bands,</b> introduced by Harvey Fletcher in 1933 and refined in 1940, describes the frequency bandwidth of the [...] "auditory filter" [...] created by the cochlea, the sense organ of hearing within the inner ear. Roughly, the <b>critical</b> <b>band</b> is the band of audio frequencies within which a second tone will interfere with {{the perception of the}} first tone by auditory masking.|$|R
3000|$|... is {{the number}} of {{considered}} <b>critical</b> <b>bands.</b> The global BSD for the whole signal is the mean of the local BSDs.|$|R
50|$|Since {{the direct}} {{measurements}} of the <b>critical</b> <b>bands</b> are subject to error, the values in this table have been generously rounded.|$|R
5000|$|In {{his letter}} [...] "Subdivision of the Audible Frequency Range into Critical Bands", Zwicker states:"These bands have been {{directly}} measured in experiments {{on the threshold}} for complex sounds, on masking, on the perception of phase, and most often on the loudness of complex sounds. In all these phenomena, the <b>critical</b> <b>band</b> seems {{to play an important}} role. It must be pointed out that the measurements taken so far indicate that the <b>critical</b> <b>bands</b> have a certain width, but that their position on the frequency scale is not fixed; rather, the position can be changed continuously, perhaps by the ear itself."Thus the important attribute of the Bark scale is the width of the <b>critical</b> <b>band</b> at any given frequency, not the exact values of the edges or centers of any band.|$|R
30|$|This article {{presented}} a psychoacoustical masking and <b>critical</b> <b>band</b> variance normalization based spectral subtraction approach {{to improve the}} speech recognition performance in noisy environments.|$|R
50|$|These {{formulas}} are for single-frequency sine waves or narrowband signals. For multi-component or broadband signals, a {{more elaborate}} loudness model is required, accounting for <b>critical</b> <b>bands.</b>|$|R
3000|$|... (z) is the correponding {{threshold}} of intensity in quiet enviroment. The total loudness L {{of the frame}} is given by the summation of every <b>critical</b> <b>band</b> loudness [...]...|$|R
5000|$|The phon {{model can}} be {{extended}} with a time-varying transient model which accounts for [...] "turn-on" [...] (initial transient) and long-term, listener fatigue effects. This time-varying behavior {{is the result of}} psychological and physiological audio processing. The equal-loudness contours on which the phon is based apply only to the perception of pure steady tones: tests using octave or third-octave bands of noise reveal a different set of curves, owing {{to the way in which}} the <b>critical</b> <b>bands</b> of our hearing integrate power over varying bandwidths and our brain sums the various <b>critical</b> <b>bands</b> ...|$|R
40|$|This paper {{presents}} a fixed- and low-dimensional, perceptually based dynamic sinusoidal model of speech {{referred to as}} PDM (Perceptual Dynamic Model). To decrease and fix the number of sinusoidal components typically used in the standard sinusoidal model, we propose to use only one dynamic sinusoidal component per <b>critical</b> <b>band.</b> For each band, the sinusoid with the maximum spectral amplitude is selected and associated with the centre frequency of that <b>critical</b> <b>band.</b> The model is expanded at low frequencies by incorporating sinusoids at {{the boundaries of the}} corresponding bands while at the higher frequencies a modulated noise component is used. A listening test is conducted to compare speech reconstructed with PDM and state-of-the-art models of speech, where all models are constrained to use an equal number of parameters. The results show that PDM is clearly preferred in terms of quality over the other systems. Index Terms — Sinusoidal Model, <b>Critical</b> <b>band,</b> Vocoder 1...|$|R
50|$|In {{order to}} {{determine}} the time periods, where the direct sound prevails and which can be used for directional evaluation, the auditory system analyzes loudness changes in different <b>critical</b> <b>bands</b> and also the stability of the perceived direction. If there is a strong attack of the loudness in several <b>critical</b> <b>bands</b> and if the perceived direction is stable, this attack is in all probability caused by the direct sound of a sound source, which is entering newly or which is changing its signal characteristics. This short time period is used by the auditory system for directional and loudness analysis of this sound. When reflections arrive a little bit later, they do not enhance the loudness inside the <b>critical</b> <b>bands</b> in such a strong way, but the directional cues become unstable, because there is a mix of sound of several reflection directions. As a result, no new directional analysis is triggered by the auditory system.|$|R
25|$|The {{beating and}} {{roughness}} sensations associated with certain complex signals are therefore usually {{understood in terms}} of sine-component interaction within the same frequency band of the hypothesized auditory filter, called <b>critical</b> <b>band.</b>|$|R
5000|$|The Chicago math {{rock band}} 90 Day Men wrote and {{recorded}} a song entitled [...] "Hans Lucas" [...] that {{pays homage to}} Godard for their 2000 album (it (is) it) <b>critical</b> <b>band.</b>|$|R
40|$|Studies of the {{responses}} of human observers to bands of noise and other complex sounds {{have led to the}} meas-ure of {{what appears to be a}} basic unit of hearing, the <b>critical</b> <b>band.</b> When the frequency spectrum of a stimu-lating sound is narrower than the <b>critical</b> <b>band,</b> the ear reacts one way; when the spectrum is wider, it reacts another way. For example, experi-ments show that at values less than the critical bandwidth, both loud-ness and absolute threshold are in-dependent of bandwidth; only when the critical bandwidth is exceeded do the loudness and the absolute threshold increase with the widt...|$|R
40|$|Motivated by the {{temporal}} processing properties of human hearing, researchers have explored various methods to incorporate temporal and contextual information in ASR systems. One such approach, TempoRAl PatternS (TRAPS), takes temporal processing {{to the extreme}} and analyzes the energy pattern {{over long periods of}} time (500 ms to 1000 ms) within separate <b>critical</b> <b>bands</b> of speech. In this paper we extend the work on TRAPS by experimenting with two novel variants of TRAPS developed to address some shortcomings of the TRAPS classifiers. Both the Hidden Activation TRAPS (HATS) and Tonotopic Multi-Layer Perceptrons (TMLP) require 84 % less parameters than TRAPS but can achieve significant phone recognition error reduction when tested on the TIMIT corpus under clean, reverberant, and several noise conditions. In addition, the TMLP performs training in a single stage and does not require <b>critical</b> <b>band</b> level training targets. Using these variants, we find that approximately 20 discriminative temporal patterns per <b>critical</b> <b>band</b> is sufficient for good recognition performance. In combination with a conventional PLP system, these TRAPS variants achieve significant additional performance improvements. 1...|$|R
40|$|It {{has been}} found that second‐order {{harmonic}} smoothing of musical instrument spectral data can {{have a significant effect on}} timbral perception, depending on the instrument tested [McAdams et al., J. Acoust. Soc. Am. 102, 882 – 897 (1999) ]. With critical‐band smoothing, the lower harmonics, since they are in different <b>critical</b> <b>bands,</b> retain their individual amplitudes and temporal envelopes. Thus, it is hypothesized that critical‐band smoothing has a lesser perceptual effect on most instrument tones than harmonic smoothing. On the other hand, upper <b>critical</b> <b>bands</b> consist of groups of harmonics. It is hypothesized that it is difficult to hear out individual harmonics within <b>critical</b> <b>bands.</b> Thus, for each band the independent harmonic temporal envelopes can be replaced by a composite rms‐amplitude envelope. Spectra within bands can be replaced by time‐averaged spectra. Alternatively, time‐dependent amplitude versus Bark‐frequency spectral envelopes can be smoothed for each individual analysis frame. Further, amplitudes can be averaged in dB or linear units. Results for various processing combinations and various musical instrument sounds will be given and demonstrated...|$|R
30|$|We first {{review the}} psychoacoustic {{foundation}} of PE, mainly the nonlinear frequency resolution (<b>Critical</b> <b>Band,</b> CB [50, 51]) of our hearing system, spreading {{functions in the}} frequency domain for noises and tones and tonality estimation.|$|R
5000|$|Psychophysiologically, {{beating and}} {{auditory}} roughness sensations {{can be linked}} to the inability of the auditory frequency-analysis mechanism to resolve inputs whose frequency difference is smaller than the critical bandwidth and to the resulting irregular [...] "tickling"of the mechanical system (basilar membrane) that resonates in response to such inputs. <b>Critical</b> <b>bands</b> are also closely related to auditory masking phenomena - reduced audibility of a sound signal when {{in the presence of a}} second signal of higher intensity within the same <b>critical</b> <b>band.</b> Masking phenomena have wide implications, ranging from a complex relationship between loudness (perceptual frame of reference) and intensity (physical frame of reference) to sound compression algorithms.|$|R
3000|$|... into Equation (20) renders a {{modified}} matrix M′ with new DWPT coefficients. Once the processes {{in all the}} involved <b>critical</b> <b>bands</b> are completed, the watermarked signal is attained by taking inverse DWPT {{with respect to the}} modified DWPT coefficients.|$|R
3000|$|Decompose {{the audio}} signal using the DWPT {{according}} to the specification given in Table  1, in which each packet node approximately corresponds to a <b>critical</b> <b>band.</b> The decomposition is carried out using the Daubechies- 8 wavelet. Let c [...]...|$|R
2500|$|Dissonance is more {{generally}} {{defined by the}} amount of beating between partials (called harmonics or overtones when occurring in harmonic timbres) ( [...] , [...] ). , [...] calls this [...] "sensory dissonance". By this definition, dissonance is dependent not only on the width of the interval between two notes' fundamental frequencies, but also on the widths of the intervals between the two notes' non-fundamental partials. Sensory dissonance (i.e., presence of beating and/or roughness in a sound) is associated with the inner ear's inability to fully resolve spectral components with excitation patterns whose <b>critical</b> <b>bands</b> overlap. If two pure sine waves, without harmonics, are played together, people tend to perceive maximum dissonance when the frequencies are within the <b>critical</b> <b>band</b> for those frequencies, which is as wide as a minor third for low frequencies and as narrow as a minor second for high frequencies (relative to the range of human hearing) [...] If harmonic tones with larger intervals are played, the perceived dissonance is due, at least in part, to the presence of intervals between the harmonics of the two notes that fall within the <b>critical</b> <b>band</b> [...]|$|R
30|$|Tonal maskers {{are removed}} from the power {{spectrum}} P[k], by setting all frequency lines within the examined range to −∞. The sound pressure levels of noise maskers are obtained by summing the energies of spectral lines within each <b>critical</b> <b>band</b> to compute PTM(z).|$|R
3000|$|... (513 for 1024 -point DFT) {{spectral}} bins {{are divided}} into subbands. In this paper, we use 27 subbands to approximate the psychoacoustic <b>critical</b> <b>bands.</b> Table 1 shows the number of spectral bins and the index of the first spectral bins in each subband.|$|R
40|$|Many noise {{suppression}} algorithms employ simultaneous masking, however {{only a few}} exploit the temporal masking properties of the human auditory system. In this paper, both types of masking thresholds are analysed experimentally in noisy conditions. Here, <b>critical</b> <b>band</b> threshold calculation in the Fast Fourier Transform (FFT) domain, suitable for cochlear implant simulation, is employed. Noise power in each <b>critical</b> <b>band</b> is estimated using a minimum statistics noise tracking algorithm. Preliminary results show that temporal masking thresholds are less susceptible to noise than simultaneous masking threshold. The {{noise suppression}} algorithms were evaluated using objective evaluation (PESQ, ITU-T P. 862) and subjective evaluation (ITU-T P. 835), in which the temporal masking based noise suppression algorithm performs better than the algorithm exploit simultaneous masking. 1...|$|R
40|$|This is a publisher’s {{version of}} an article {{published}} in IRCS Medical Research 1977. This version is reproduced with permission from Lippincott Williams & Wilkins. The role of the inner and outer hair cells of the cochlea in frequency discrimination and <b>critical</b> <b>band</b> measurements is not clearly understood. There is, however, evidence for an interaction between the hair cells in threshold determinations (1) and frequency selectivity (2). Furthermore, although there is increasing evidence that a place theory is more importance than a periodicity theory in frequency coding the situation is still not clear, {{and the role of the}} inner and outer hair cells in frequency discrimination and <b>critical</b> <b>band</b> measurements should provide additional evidence to help clarify the situation. Open Acces...|$|R
40|$|Temporal masking {{models have}} not been {{previously}} applied in the Fast Fourier Transform (FFT) domain for speech enhancement applications. This paper presents a novel speech enhancement algorithm using temporal masking in the FFT domain. The proposed algorithm is suitable for the cochlear speech processor and for other speech applications. The input signal is analysed using FFT and then grouped into 22 <b>critical</b> <b>bands.</b> The noise power is estimated using a minimum statistics noise tracking algorithm. A short-term temporal masking threshold is then calculated for each <b>critical</b> <b>band</b> and a gain factor for each band is then computed. The objective and subjective evaluations show that the temporal masking model based speech enhancement scheme outperforms the traditional Wiener filtering approach in the FFT domain. 1...|$|R
50|$|This {{experience}} led to {{the idea}} of engaging in some kind of research and training programme for instrumentalists in microtonal performance, and so in 1990 Wood founded London's first Centre for Microtonal Music, and its ensemble, <b>Critical</b> <b>Band.</b> The purpose of the Microtonal Centre was to research instrumental microtonal playing techniques, to teach these to young musicians whilst at the same time educating composers in the historical, theoretical, emotional and practical implications of microtonality. The initiative involved the collaboration of the Society for the Promotion of New Music (SPNM), the Guildhall School of Music and Drama, and the Barbican Centre in London, which held a Weekend of Microtonal Music, 'In Tune?', in 1990, 1991 and 1992. Aside from its presence at the 'In Tune?' Festivals, the ensemble 'Critical Band' undertook several recordings, concerts and tours, including a CD of three of Wood's own compositions: Venancio Mbande talking with the Trees, Phainomena and Two men meet, each presuming the other to be from a distant planet (NMC-D044). This latter work was also premiered by <b>Critical</b> <b>Band</b> at the 1995 BBC Proms (September 11). But since the late 1990s both the Centre for Microtonal Music and <b>Critical</b> <b>Band</b> became disbanded through lack of funding.|$|R
50|$|The {{coefficients}} {{are grouped}} {{to resemble the}} <b>critical</b> <b>bands</b> of the human auditory system. The entire amount of energy of each group is analysed and the values quantised for data reduction and compressed through prediction by only transmitting the difference to the predicted values (delta encoding).|$|R
40|$|We {{propose a}} novel {{application}} of the vocoder postfilter to increase perceived loudness of clean speech without increasing signal energy or degrading intelligibility. The <b>critical</b> <b>band</b> concept in auditory theory states that perceived loudness of a narrow-band signal will increase when the bandwidth of that signal increases beyond a <b>critical</b> <b>band,</b> even though the energy remains constant. Our post-filter technique applies formant bandwidth expansion to the vowel regions of speech without changing the vowel power to elevate perceived loudness. Vowels are known to contain the highest energy, have a smooth spectral envelope, long temporal sustenance, {{and for this reason}} are suitable candidates to target for a loudness enhancement technique. ISO- 532 B loudness analysis patterns and listening tests are provided to demonstrate a perceptual loudness improve-ment corresponding to a 2 dB power gain. 1...|$|R
30|$|Hansen, Kim and Rahurkar {{demonstrate}} {{examples of}} substantial improvements to emotion recognition by subband weighting of the Teager energy operator-based <b>critical</b> <b>band</b> autocorrelation envelope feature. The empirically derived subband weights {{were also found}} to reduce speaker dependency, when evaluated on a novel speech under stress database with physiological ground truth.|$|R
50|$|In 1961, Professor Donald D. Greenwood {{utilized}} {{experimental methods}} {{within the field}} of psychoacoustics to measure the frequency resolution between <b>critical</b> <b>bands</b> within the human cochlea and develop a function correlating the anatomic location of the inner ear hair cells and the frequencies at which they are stimulated (Greenwood 1961a,b).|$|R
40|$|Two-hundred English sentences, each {{spoken by}} 10 native {{speakers}} (5 females and 5 males) of British English, were analyzed with {{a bank of}} 20 critical-band filters. Principal component analysis {{was applied to the}} power fluctuation of filter outputs. The first three components accounted for 35. 3 % of the total variance. A varimax rotated solution of the components was obtained. The first component was interpreted as a "sonority filter " that is closely related to the first and the second formants of vowels. The second component seemed to be related with nasalization, and the third component with fricatives, affricates, and stops. The existence of common frequency channels in perceiving normal speech and noise-vocoded speech were suggested. The concept of <b>critical</b> <b>band</b> is one of the successful simplifications of an aspect of our auditory functions. The concept is originally proposed by Fletcher (1940). He proposed that <b>critical</b> <b>band</b> is dependent on the auditory periphery, particularly on the excitation patterns of the basilar membrane in the cochlea. The concept had been further simplified to be modeled as a bank of band-pass filters that do not overlap each other (e. g., Fastl & Zwicker, 2007). This model is well matched with the essential parts of the experimental facts of auditory masking and loudness perception. The concept of <b>critical</b> <b>band</b> has been also applied to the research on speec...|$|R
