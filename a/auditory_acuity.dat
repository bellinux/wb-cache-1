65|20|Public
5000|$|Low-level {{processing}} (visual and <b>auditory</b> <b>acuity,</b> gender, age, mood, …) ...|$|E
5000|$|H — The [...] "H" [...] {{stands for}} [...] "Hearing and Ears". This factor {{concerns}} <b>auditory</b> <b>acuity</b> and disease and defects of the ear.|$|E
5000|$|Human {{factors in}} vehicle {{collisions}} include all {{factors related to}} drivers and other road users that may contribute to a collision. Examples include driver behavior, visual and <b>auditory</b> <b>acuity,</b> decision-making ability, and reaction speed.|$|E
40|$|We have {{examined}} the effects on <b>auditory</b> spatial <b>acuity</b> in the horizontal plane of depriving ferrets of patterned visual cues by binocular eyelid suture in infancy or for a comparable period in adulthood. Minimum audible angles (MAAs) were measured for 500 -, 100 - and 40 -ms broadband noise bursts at the midline and at 45 degrees to one side. A logistic regression analysis revealed no consistent difference between the midline MAAs of normal and infant lid-sutured ferrets. However, the lateral field MAAs of the infant-deprived group were significantly smaller and showed less inter-subject variability than those of normal-sighted ferrets. The animals deprived in adulthood were tested in the lateral field only, firstly 6 months after binocular eyelid suture and again after a further 10 months. For the first test, the MAAs achieved by these animals with 500 - and 100 -ms noise bursts were significantly smaller than the normal values and no {{different from those of}} the infant-deprived group. A significant improvement in performance at the two shortest stimulus durations (100 and 40 ms) was observed when the adult-deprived animals were re-tested. Their second-test MAAs did not differ from those of the infant-deprived group at any of the three stimulus durations used, and both groups achieved significantly better scores than the normal-sighted control animals. These results show that prolonged visual deprivation in both juvenile and adult ferrets can lead to a significant improvement in <b>auditory</b> spatial <b>acuity</b> in the lateral sound field. This is consistent with reports that congenitally blind humans can localize peripheral sounds more accurately than normal controls...|$|R
30|$|The actual Twhirleds {{experience}} is currently {{more interesting than}} entertaining, more academic than fun. Readers are encouraged to download collateral software, 50 install the app, and try it themselves. In the future, we hope make it more recreational, exploring the interplay of interaction and display (both visual and auditory) of mutual phase, using extended groupware deployment, including collaborative musical performance. Besides whatever graphical, auditory, and vibratory output, separately displayed or embedded in twirling affordances themselves, we continue to explore embodied interaction, the expressiveness and potential of the happy alignment of gravity-oriented horizontal twirling gestures, horizontal inspection gestures, the geomagnetic field, and horizontally favored <b>auditory</b> directionalization <b>acuity.</b> In particular, the Twhirleds application leverages the alignment of the horizontal orientation of a normal pano or turno and its corresponding inspection or spin-around gesture, the horizontal orientation of compass-derived yaw data, and the symmetrically bilateral anatomy of humans and figurative avatars.|$|R
40|$|SummaryDegraded sensory {{experience}} during critical periods of development can have {{adverse effects on}} brain function. In the auditory system, conductive hearing loss associated with childhood ear infections can produce long-lasting deficits in <b>auditory</b> perceptual <b>acuity,</b> much like amblyopia in the visual system. Here we explore the neural mechanisms that may underlie “amblyaudio” by inducing reversible monaural deprivation (MD) in infant, juvenile, and adult rats. MD distorted tonotopic maps, weakened the deprived ear's representation, strengthened the open ear's representation, and disrupted binaural integration of interaural level differences (ILD). Bidirectional plasticity effects were strictly governed by critical periods, were more strongly expressed in primary auditory cortex than inferior colliculus, and directly impacted neural coding accuracy. These findings highlight a remarkable degree of competitive plasticity between aural representations and suggest that the enduring perceptual sequelae of childhood hearing loss might be traced to maladaptive plasticity during critical periods of auditory cortex development...|$|R
50|$|A more poignant example exists through {{examining}} auditory perception. Generally speaking {{the greater the}} distance between the ears, the greater the possible <b>auditory</b> <b>acuity.</b> Also relevant is the amount of density in between the ears, for the strength of the frequency wave alters as it passes through a given medium. The brain's auditory system takes these factors into account as it process information, but again without any need for a symbolic manipulation system. This is because {{the distance between the}} ears for example does not need symbols to represent it. The distance itself creates the necessary opportunity for greater <b>auditory</b> <b>acuity.</b> The amount of density between the ears is similar, in that it is the actual amount itself that simply forms the opportunity for frequency alteration. Thus under consideration of the physical properties of the body, a symbolic system is unnecessary and an unhelpful metaphor.|$|E
50|$|Examinations {{that can}} be done include the Rinne test and the Weber test.Rinne's test {{involves}} Rinne's Right Test and Rinne's Left Test since <b>auditory</b> <b>acuity</b> is equal in both ears. If Bone Conduction(BC) is more than Air Conduction(AC) i.e BC>AC indicates Rinne Test is negative or abnormal. If AC>BC Rinne test is normal or positive. If BC>AC and Weber's test lateralizes to abnormal side then it is Conductive hearing loss. If AC>BC and Weber's test lateralizes to normal side then it concludes Sensorineural hearing loss.|$|E
5000|$|This {{uncommon}} tumor {{accounts for}} less than 2% of all ear tumors. While patients present with symptoms related to the middle ear cavity location of the tumor, the tumor may expand into the adjacent structures (external auditory canal, mastoid bone, and eustachian tube). [...] Patients come to clinical attention with unilateral (one sided) hearing loss, usually associated with decreased <b>auditory</b> <b>acuity,</b> and particularly conductive hearing loss if the ossicular bone chain (middle ear bones) is involved. Tinnitus (ringing), otitis media, pressure or occasionally ear discharge are seen. At the time of otoscopic exam, the tympanic membrane is usually intact, with a fluid level or mass noted behind the ear drum. Even though this is a [...] "neuroendocrine" [...] type tumor, there is almost never evidence of neuroendocrine function clinically or by laboratory examination.|$|E
40|$|The {{full text}} {{of this article is}} not {{available}} in SOAR. Check the journal record [URL] for the paper version of the article in the library. It has been reported that many elderly persons exhibit problems in identifying the location of fused auditory images in a test of the precedence effect in sound localization. The precedence effect involves the neural integration of multiple competing binaural temporal cues, and may reflect subtle age-related neural timing or integration problems. This study investigated whether elderly persons who have difficulty with this test also exhibit problems with speech understanding. The speech measures involved a comparison of performance-intensity functions for phonetically balanced (PB) words and for synthetic sentences presented with ipsilateral speech competition (SSI-ICM). The performance of the elderly subjects on the precedence effect test was significantly correlated with the SSI-max scores but not with PB-max. These findings suggest that age-related difficulties in speech understanding may reflect, at least in part, breakdowns in <b>auditory</b> temporal <b>acuity</b> or resolution. peer reviewe...|$|R
40|$|Investigating {{the time}} and spatial {{constraints}} under which visual and auditory stimuli are perceived as a unique percept or as spatially coincident has been a topic of numerous researches. However, these findings have been derived up to now in extremely simplified stimulation context consisting in the combination of elementary auditory and visual stimuli usually displayed in dark and anechoic conditions. The present experiment is conducted in a VR environment using a passive stereoscopic display and binaural audio rendering. Subjects have to indicate the point of subjective spatial alignment (PSSA) between a horizontally moving visual stimulus that crosses {{the direction of a}} stationary sound. Auditory stimuli are displayed on headphones using individualized head-related transfer functions and the visual stimulus is integrated in a visual background texture in order to convey visual perspective. Two types of audio stimuli are used to evaluate the influence of <b>auditory</b> localisation <b>acuity</b> on the auditory-visual integration: periodic white noise bursts providing optimal localisation cues and periodic 1 kHz tone bursts. The present study will indicate whether previous findings (Lewald et al., Behavioural Brain Research, 2001) still hold in more complex audio-visual contexts such as those offered by cutting edge VR environments...|$|R
40|$|Psychophysiological {{evidence}} suggests that music and language are intimately coupled such that experience/training in one domain can influence processing required in the other domain. While the influence of music on language processing is now well-documented, evidence of language-to-music effects {{have yet to be}} firmly established. Here, using a cross-sectional design, we compared the performance of musicians to that of tone-language (Cantonese) speakers on tasks of <b>auditory</b> pitch <b>acuity,</b> music perception, and general cognitive ability (e. g., fluid intelligence, working memory). While musicians demonstrated superior performance on all auditory measures, comparable perceptual enhancements were observed for Cantonese participants, relative to English-speaking nonmusicians. These results provide evidence that tone-language background is associated with higher auditory perceptual performance for music listening. Musicians and Cantonese speakers also showed superior working memory capacity relative to nonmusician controls, suggesting that in addition to basic perceptual enhancements, tone-language background and music training might also be associated with enhanced general cognitive abilities. Our findings support the notion that tone language speakers and musically trained individuals have higher performance than English-speaking listeners for the perceptual-cognitive processing necessary for basic auditory as well as complex music perception. These results illustrate bidirectional influences between the domains o...|$|R
40|$|The {{relation}} between <b>auditory</b> <b>acuity,</b> somatosensory acuity and {{the magnitude of}} produced sibilant contrast was investigated with data from 18 participants. To measure <b>auditory</b> <b>acuity,</b> stimuli from a synthetic sibilant continuum ([s]-[ʃ]) were used in a four-interval, two-alternative forced choice adaptive-staircase discrimination task. To measure somatosensory acuity, small plastic domes with grooves of different spacing were pressed against each participant’s tongue tip and the participant was asked to identify one of four possible orientations of the grooves. Sibilant contrast magnitudes were estimated from productions of the words ‘said,’ ‘shed,’ ‘sid,’ and ‘shid’. Multiple linear regression revealed a significant relation indicating {{that a combination of}} somatosensory and <b>auditory</b> <b>acuity</b> measures predicts produced acoustic contrast. When the participants were divided into high- and low-acuity groups based on their median somatosensory and <b>auditory</b> <b>acuity</b> measures, separate ANOVA analyses with sibilant contrast as the dependent variable yielded {{a significant main effect for}} each acuity group. These results provide evidence that sibilant productions have auditory as well as somatosensory goals and are consistent with prior results and the theoretical framework underlying the DIVA model of speech production...|$|E
40|$|An {{important}} part of understanding speech motor control consists of capturing the interaction between speech production and speech perception. This study tests a prediction of theoretical frameworks that have tried to account for these interactions: if speech production targets are specified in auditory terms, individuals with better <b>auditory</b> <b>acuity</b> should have more precise speech targets, evidenced by decreased within-phoneme variability and increased between-phoneme distance. A study was carried out consisting of perception and production tasks in counterbalanced order. <b>Auditory</b> <b>acuity</b> was assessed using an adaptive speech discrimination task, while production variability was determined using a pseudo-word reading task. Analyses of the production data were carried out to quantify average within-phoneme variability as well as average between-phoneme contrasts. Results show that individuals not only vary in their production and perceptual abilities, but that better discriminators have more distinctive vowel production targets (that is, targets with less within-phoneme variability and greater between-phoneme distances), confirming the initial hypothesis. This association between speech production and perception did not depend on local phoneme density in vowel space. This study suggests that better <b>auditory</b> <b>acuity</b> leads to more precise speech production targets, which may be a consequence of auditory feedback affecting speech production over time...|$|E
40|$|Purpose: To {{evaluate}} whether helmets increase the incidence and/or severity of cervical spine injury; decrease {{the incidence of}} head injury; and/or increase the incidence of collisions (as a reflection of adverse effects on peripheral vision and/or <b>auditory</b> <b>acuity)</b> among young skiers and snowboarders...|$|E
40|$|The {{process of}} aging {{is a process}} of declin-ing capacities, a decline which for some func-tions may begin very early in life. Visual, <b>auditory,</b> and tactual <b>acuity,</b> for example, show a gradual {{decrease}} from the twenties until the late sixties, followed by a precipitous drop in the next two decades (Miles, 1933). Similarly, physical strength (Dennis, 1952), speed of re-action (Birren, 1956; Miles, 1931), motor dex-terity (Barker, 1934), and certain manual skills (Welford, 1951) reach a peak in the late twenties and early thirties, declining progres-sively thereafter. In addition, certain kinds of intellectual capacities seem to diminish with age. The ability to learn complex material seems to deteriorate (Ruch, 1933, 1934; Holl-ingworth, 1930; Thorndike, 1928), and defec-tive memory frequently accompanies extreme old age (Shakow, Dolkert, & Goldman, 1941...|$|R
40|$|In this study, we {{examined}} whether good auditory and good visual temporal processors {{were better than}} their poor counterparts on certain reading measures. Various visual and auditory temporal tasks were administered to 105 undergraduates. They read some phonologically regular pseudowords and irregular words that were presented sequentially in the same ("word" condition) and in different ("line" condition) locations. Results indicated that <b>auditory</b> temporal <b>acuity</b> was more relevant to reading, whereas visual temporal acuity was more relevant to spelling. Good auditory temporal processors {{did not have the}} advantage in processing pseudowords, even though pseudoword reading correlated significantly with auditory temporal processing. These results suggested that some higher cognitive or phonological processes mediated the relationship between auditory temporal processing and pseudoword reading. Good visual temporal processors did not have the advantage in processing irregular words. They also did not process the line condition more accurately than the word condition. The discrepancy might be attributed to the use of normal adults and the unnatural reading situation that did not fully capture the function of the visual temporal processes. The distributions of auditory and visual temporal processing abilities were co-occurring to some degree, but they maintained considerable independence. There was also a lack of a relationship between the type and severity of reading deficits and the type and number of temporal deficits...|$|R
40|$|This manual is {{intended}} to provide information leading to reliable assessment of vision and hearing capabilities of children considered to have dual sensory impairments. Ongoing sensory assessment is necessary {{to determine the extent}} of residual sensory abilities that should be considered in educational programming decisions and to determine any changes in those abilities. The visual assessment involves review of relevant medical reports and previous assessment results, and assessment in the areas of reflexive visual processes, field of vision, ocular motility, and visual <b>acuity.</b> <b>Auditory</b> assessment may involve such alternative procedures as tangible reinforcement operant conditioning audiometry and visual reinforcement audiometry. The importance of naturalistic observations is emphasized. A list of 8 references and 11 recommended readings is included. (1 M) Reproductions supplied by EDRS are the best that can be made from the original document. rA. 1) SENSORY ASSESSMENT MANUA...|$|R
40|$|Serial {{audiometry}} {{was performed}} in ten patients receiving quinine treatment for acute falciparum malaria. Quinine reduced high tone <b>auditory</b> <b>acuity</b> in all patients, resulting in flattening of the audiograms. The effect was rapid in onset, usually unnoticed (although tinnitus was reported in seven patients), and resolved completely after treatment was completed...|$|E
40|$|Bibliography: pages [70]- 77 The {{effects of}} hearing loss on {{outcomes}} of two brief tests of mental status, the Mental Status Questionnaire and the Short Portable Mental Status Questionnaire, were studied in an institutionalized elderly population. The {{findings indicate that}} there is indeed a relationship between <b>auditory</b> <b>acuity</b> and mental status. Elderly persons with decrements in <b>auditory</b> <b>acuity</b> score significantly lower than those with better auditory abilities on these brief measures of mental status. The study raises {{the issue of whether}} this association {{is the result of a}} lack of information base due to the auditory restriction and therefore representative of a confounding factor in the measurement procedure. The results do not support this informational postulation, and the plausibility of alternative hypotheses is explored. Results are suggestive of factors which may indicate a concomitant cognitive and auditory degeneration process. Further investigation into this question is warranted. M. A. (Master of Arts...|$|E
40|$|This study aims to test recent {{theoretical}} frameworks {{in speech}} motor control which claim that speech production targets are specified in auditory terms. According to such frameworks, people with better <b>auditory</b> <b>acuity</b> {{should have more}} precise speech targets. Participants performed speech perception and production tasks in a counterbalanced order. Speech perception acuity was assessed using an adaptive speech discrimination task, where participants discriminated between stimuli on a /ɪ/-/ɛ/ and a /ɑ/-/ɔ/ continuum. To assess variability in speech production, participants performed a pseudo-word reading task; formant values were measured for each recording of the vowels /ɪ/, /ɛ/, /ɑ/ and /ɔ/ in 288 pseudowords (18 per vowel, each of which was repeated 4 times). We predicted that speech production variability would correlate inversely with discrimination performance. Results confirmed this prediction as better discriminators had more distinctive vowel production targets. In addition, participants with higher <b>auditory</b> <b>acuity</b> produced vowels with smaller within-phoneme variability but spaced farther apart in vowel space. This study {{highlights the importance of}} individual differences in the study of speech motor control, and sheds light on speech production-perception interactions...|$|E
40|$|Modern {{smartphones}} and tablets have magnetometers {{that can}} be used to detect yaw, which data can be distributed to modulate ambient media. We have implemented such functionality for both a Google Android smartphone and Apple iOS iPhone & iPad. A client-server architecture synchronizes distributed displays across shared channels, including image-based renderings of panoramic photos and object movies, spatial sound (periphonic) speaker arrays, rotary motion platforms [4], and the position of avatars or other objects in virtual environments such as Alice 1 [5] and Open Wonderland. 2 Embedding such devices into a spinnable affordance allows a “spinning plate”-style interface, a novel interaction technique [1] [2]. Broad configurability allows flexible deployment. Transmission may be one-shot or continuous, including thresholded filtering for choked bandwidth, azimuthal (rotation) and/or circumferential (revolution), and azimuthal transmissions may be wrapped or unwrapped. Device vertical orientation may be upright or inverted. and a modal loop disables multitouch control for duration of play, preventing accidental change of the parameters. A soft transmission can scale the control:display ratio, allowing fast whirling to be shared as more leisurely turning (or even “overdriven ” to exaggerate such torque). Such interfaces suggest the potential for embodied interaction exploiting the happy alignment of a gravityoriented horizontal spinning gesture, the latitudinal magnetic field, and the horizontally favored visual field and <b>auditory</b> directionalization <b>acuity.</b> It’s a “come as you are ” interface, requiring no special markers or clothing. A video of our new system is posted t...|$|R
40|$|Sound {{localization}} {{relies on}} the neural processing of monaural and binaural spatial cues that arise from the way sounds interact with the head and external ears. Neurophysiological studies of animals raised with abnormal sensory inputs show that the map of auditory space in the superior colliculus is shaped during development by both auditory and visual experience. An example of this plasticity is provided by monaural occlusion during infancy, which leads to compensatory changes in auditory spatial tuning that tend to preserve the alignment between the neural representations of visual and auditory space. Adaptive changes also take place in sound localization behavior, {{as demonstrated by the}} fact that ferrets raised and tested with one ear plugged learn to localize as accurately as control animals. In both cases, these adjustments may involve greater use of monaural spectral cues provided by the other ear. Although plasticity in the auditory space map seems to be restricted to development, adult ferrets show some recovery of sound localization behavior after long-term monaural occlusion. The capacity for behavioral adaptation is, however, task dependent, because <b>auditory</b> spatial <b>acuity</b> and binaural unmasking (a measure of the spatial contribution to the "cocktail party effect") are permanently impaired by chronically plugging one ear, both in infancy but especially in adulthood. Experience-induced plasticity allows the neural circuitry underlying sound localization to be customized to individual characteristics, such as {{the size and shape of}} the head and ears, and to compensate for natural conductive hearing losses, including those associated with middle ear disease in infancy...|$|R
40|$|<b>Auditory</b> spatial <b>acuity</b> was {{measured}} in mice using prepulse inhibition (PPI) of the acoustic startle reflex as the indicator response for stimulus detection. The prepulse was a “speaker swap ” (SSwap), shifting a noise between two speakers located along the azimuth. Their angular separation, and the spectral composition and sound level of the noise were varied, as was the interstimulus interval (ISI) between SSwap and acoustic startle reflex elicitation. In Experiment 1 a 180 ° SSwap of wide band noise (WBN) was compared with WBN Onset and Offset. SSwap and WBN Onset had near equal effects, but less than Offset. In Experiment 2 WBN SSwap {{was measured}} with speaker separations of 15, 22. 5, 45, and 90 °. Asymptotic level and {{the growth rate of}} PPI increased with increased separation from 15 to 90 °, but even the 15 ° SSwap provided significant PPI for the mean performance of the group. SSwap in Experiment 3 used octave band noise (2 – 4, 4 – 8, 8 – 16, or 16 – 32 kHz) and separations of 7. 5 to 180 °. SSwap was most effective for the highest frequencies, with no significant PPI for SSwap below 8 – 16 kHz, or for separations of 7. 5 °. In Experiment 4 SSwap had WBN sound levels from 40 to 78 dB SPL, and separations of 22. 5, 45, 90, and 180 °: PPI increased with level, this effect varying with ISI and angular separation. These experiments extend the prior findings on sound localization in mice, and the dependence of PPI on ISI adds a reaction time-like dimension to this behavioral analysis...|$|R
30|$|Fifteen naive {{subjects}} {{participated in}} this study (eight female, seven male; mean age =  23.27 years; SD =  3.57; range =  18 – 30); all of them were fluent English speakers (participants for whom their first or second language was English). All participants reported normal <b>auditory</b> <b>acuity</b> and no medical problems. Participants gave informed consent and received monetary compensation for their participation. The study protocol was approved by the Research Ethics Office at INRS-EMT and at McGill University (Montreal, Canada).|$|E
40|$|The first {{documented}} case {{of improved}} hearing following chiropractic adjustment was by D. D. Palmer in 1895 {{in which he}} restored Harvey Lillard’s hearing. Mr Lillard had been deaf for seventeen years. This brought about {{the birth of a}} new profession called chiropractic (Terrett 2002). It has been postulated that dysfunction or spinal joint motion restrictions of the cervical spine may lead to irritation of the sympathetic nervous system which may cause decreased blood flow to the auditory nerve via the labyrinthine artery (also known as the internal acoustic artery or internal auditory artery), which in turn may lead to a decrease in hearing acuity (Hawley 1964). The purpose of the dissertation was to determine whether cervical spine joint adjustment had an effect on the hearing acuity in individuals with some level of sensorineural hearing loss. Thirty symptomatic patients of either gender participated in this study. These patients were recruited by the use of advertisements placed in the Chiropractic Day Clinic, University of Johannesburg, Doornfontein Campus and by word of mouth. The inclusion criteria required the patients to present with some level of sensorineural hearing loss, be over the age of fifty years and have no contra-indications to chiropractic adjustments. Objective data was obtained by the Interacoustics Diagnostics Audiometer AD 229 b, which determined the level of <b>auditory</b> <b>acuity</b> before and after chiropractic treatment was administered. Middle ear function and acoustic reflex was also tested with the GSI 38 Auto Tymp acoustic reflex machine. The objective results demonstrated that there was no statistically significant increase in <b>auditory</b> <b>acuity</b> following either the chiropractic treatment, or the detuned ultrasound treatment. In conclusion, it was shown that chiropractic adjustments in some patients presenting with sensorineural hearing loss, in the same subjects, exhibited a clinical improvement in hearing acuity however, not a statistically significant improvement following the treatment protocol discussed in the chapters that follow. These improvements suggested that the adjustment resulted in a decrease in sympathetic nervous system stimulation and an increase in blood flow through the labyrinthine artery, and therefore an increase in <b>auditory</b> <b>acuity.</b> These improvements were noted to a larger degree in individuals with a greater sensorineural hearing loss and not across the entire sample population. Dr. M. Moodley Dr. S. M. Wilco...|$|E
40|$|Objective. To {{describe}} {{the prevalence of}} visual and auditory impairment in frail older persons and to evaluate the associ-ation between sensory impairments and overall functional status. Design. Prospective patient evaluation combined with retro-spective analysis of data. Setting and participants. 576 consecutive outpatients ob-served at an academic medical center outpatient geriatric assessment clinic in Nebraska from 1986 to 1992 for whom data on both vision and hearing were available. Subjects were elderly, primarily female, and community-dwelling. Main outcome measures. Visual acuity {{was measured by the}} Lighthouse Near Visual Acuity Test, and <b>auditory</b> <b>acuity</b> was evaluated with the whisper test. Functional status was determined by Lawton-Brody activities of daily livin...|$|E
40|$|The {{function}} of ultrasonic vocalizations (USVs) produced by mice (Mus musculus) {{is a topic}} of broad interest to many researchers. These USVs differ widely in spectrotemporal characteristics, suggesting different categories of vocalizations, although this has never been behaviorally demonstrated. Although electrophysiological studies indicate that neurons can discriminate among vocalizations {{at the level of}} the <b>auditory</b> midbrain, perceptual <b>acuity</b> for vocalizations has yet to be determined. Here, we trained CBA/CaJ mice using operant conditioning to discriminate between different vocalizations and between a spectrotemporally modified vocalization and its original version. Mice were able to discriminate between vocalization types and between manipulated vocalizations, with performance negatively correlating with spectrotemporal similarity. That is, discrimination performance was higher for dissimilar vocalizations and much lower for similar vocalizations. The behavioral data match previous neurophysiological results in the inferior colliculus (IC), using the same stimuli. These findings suggest that the different vocalizations could carry different meanings for the mice. Furthermore, the finding that behavioral discrimination matched neural discrimination in the IC suggests that the IC plays an important role in the perceptual discrimination of vocalizations...|$|R
40|$|Research in {{audiovisual}} speech perception {{has demonstrated}} that sensory factors such as <b>auditory</b> and visual <b>acuity</b> {{are associated with a}} listener’s ability to extract and combine auditory and visual speech cues. This case study report examined audiovisual integration using a newly developed measure of capacity in a sample of hearing-impaired listeners. Capacity assessments are unique because they examine the contribution of reaction-time (RT) as well as accuracy {{to determine the extent to}} which a listener efficiently combines auditory and visual speech cues relative to independent race model predictions. Multisensory speech integration ability was examined in two experiments: An open-set sentence recognition and a closed set speeded-word recognition study that measured capacity. Most germane to our approach, capacity illustrated speed-accuracy tradeoffs that may be predicted by audiometric configuration. Results revealed that some listeners benefit from increased accuracy, but fail to benefit in terms of speed on audiovisual relative to unisensory trials. Conversely, other listeners may not benefit in the accuracy domain but instead show an audiovisual processing time benefit...|$|R
40|$|The {{encoding}} of <b>auditory</b> spatial <b>acuity</b> (measured as {{the precision}} {{to distinguish between}} two spatially distinct stimuli) by neural circuits in both auditory cortices {{is a matter of}} ongoing research. Here, the event-related potential mismatch negativity (MMN), a sensitive indicator of preattentive auditory change detection, was used to tap into the underlying mechanism of cortical representation of auditory spatial information. We characterized the MMN response affected by the degree of spatial deviance in lateral acoustic space using a passive oddball paradigm. Two stimulation conditions specifically focusing on the investigation of the mid- and far-lateral acoustic spcace were considered: (i) 65 &# 176; left standard position with deviant positions at 70 &# 176;, 75 &# 176;, and 80 &# 176;; and (ii) 95 &# 176; left standard position with deviant positions at 90 &# 176;, 85 &# 176;, and 80 &# 176;. Additonally, behavioral data on the minimum audible angle (MAA) were acquired for the respective standard positions (65 &# 176;, 95 &# 176; left) to quantify spatial discrimination in separating disctinct sound sources. The two measurements disclosed the linkage between the (preattentive) MMN response and the (attentive) behavioral threshold. At 65 &# 176; spatial deviations as small as 5 &# 176; reliably elicited MMNs. Thereby, the MMN amplitudes monotonously increased as a function of spatial deviation. At 95 &# 176;, spatial deviations of 15 &# 176; were necessary to elicit a valid MMN. The behavioral data, however, yielded no difference in mean MAA thresholds for position 65 &# 176; and 95 &# 176;. The different effects of laterality on MMN responses and MAA thresholds suggest a role of spatial selective attention mechanisms particulary relevant in active discrimination of neighbouring sound sources, especially in the lateral acoustic space...|$|R
40|$|The {{effects of}} light {{aircraft}} noise on six subjects during flight operations were investigated. The noise {{environment in the}} Piper Apache light aircraft {{was found to be}} capable of producing hearing threshold shifts. The following are the principal findings and conclusions: (1) Through most of the frequency range for which measurements were taken (500 to 6000 Hz), there was a regular progression showing increased loss of <b>auditory</b> <b>acuity</b> as a function of increased exposure time. (2) Extensive variability was found in the results among subjects, and in the measured loss at discrete frequencies for each subject. (3) The principal loss of hearing occurred at the low frequencies, around 500 Hz...|$|E
40|$|This study {{sought to}} {{determine}} if there are any 2 ̆ 2 cultural 2 ̆ 2 or economic level patterns of behavior in responding to tasks involving categorizing pictures and recalling general knowledge. The Daberon School Headiness Device (1972), which contains subtests for general knowledge and categorization, was used to assess four groups of children: 1) lower-SES white, 2) lower-SES black, 3) middle-SES white, and 4) middle-SES black. This study involved thirty black and thirty white {{children between the ages of}} five years and five years, eleven months. All subjects were screened to determine race, age, <b>auditory</b> <b>acuity,</b> speech intelligibility, subject cooperation, and socioeconomic status (SES). Testing for intelligence was performed at the beginning of the testing situation...|$|E
40|$|Recently, {{however, the}} photon {{absorption}} m I method {{has been used}} to estimate bone mineral in large numbers of people (25, 26). In a comparability trial to evaluate bone mass, the photon absorption method demonstrated that women with sympto-matic vertebral osteoporosis have significantly less mineral at the distal radius than normal women (7). Using the U 6 I method we examined 3, 515 persons of three skin colors to investigate whether, in the general population, low concentration of bone mineral at the distal radius is associated with high fracture rates, aortic calcification, vertebral osteoporosis, and diminished <b>auditory</b> <b>acuity.</b> SUBJECTS AND METHODS The tested population comprised insured workers and their families who came to multiphasic clinics of the Kaiser-Permanente Medical Center, Oakland, California, for annual medical check-up betwee...|$|E
40|$|We {{investigated}} {{comprehension of}} and adaptation to speech {{in an unfamiliar}} accent in older adults. Participants performed a speeded sentence verification task for accented sentences: one group upon auditory-only presentation, and the other group upon audiovisual presentation. Our questions were whether audiovisual presentation would facilitate adaptation to the novel accent, and which cognitive and linguistic measures would predict adaptation. Participants were therefore tested {{on a range of}} background tests: hearing <b>acuity,</b> <b>auditory</b> verbal short-term memory, working memory, attention-switching control, selective attention, and vocabulary knowledge. Both auditory-only and audiovisual groups showed improved accuracy and decreasing response times {{over the course of the}} experiment, effectively showing accent adaptation. Even though the total amount of improvement was similar for the auditory-only and audiovisual groups, initial rate of adaptation was faster in the audiovisual group. Hearing sensitivity and short-term and working memory measures were associated with efficient processing of the novel accent. Analysis of the relationship between accent comprehension and the background tests revealed furthermore that selective attention and vocabulary size predicted the amount of adaptation over the course of the experiment. These results suggest that vocabulary knowledge and attentional abilities facilitate the attention-shifting strategies proposed to be required for perceptual learning...|$|R
40|$|Previous {{characterizations}} of arithmetic disabled children with intact reading skills have been rather discrepant. The {{purpose of the}} present study was to first determine whether or not a sample of arithmetric disabled children with intact reading skills was, in fact, heterogeneous with respect to their patterns of academic performances on the Wide Range Achievement Test (WRAT) Reading, Spelling, and Arithmetic subtests. If this sample of children was indeed heterogeneous, would the resulting subtypes of children differ with respect to their patterns of neurocognitive skills and their ratings on a measure of personality functioning (i. e., PIC: Personality Inventory for Children). A group of 156 children exhibiting WRAT Arithmetic centile scores less than 27 and Reading centile scores greater than 40 were culled from a database of over 4800 children who had been referred to a multi-servive mental health clinic because of suspected central processing deficiencies. All 156 children were between the ages of 9 - 14 years, obtained Full Scale IQ 2 ̆ 7 s between 85 - 115 on the Wechsler Intelligence Scale for Children (WISC), and were free from any visual or <b>auditory</b> perceptual <b>acuity</b> deficiencies and environmental deprivation. All children spoke English as their primary language. In order to determine if this sample of children was indeed heterogeneous with respect to academic performances, WRAT Reading, Spelling and Arithmetic scores were subjected to several hierarchical clustering procedures. Concurrent validation of the cluster solutions was provided by multivariate and univariate analysis of variance using variables not included in the initial classification: 22 neuropsychological measures and selected PIC scales. Application of the initial cluster analytic techniques and subsequent validation procedures suggested the presence of four subtypes which were differentiated significantly on academic, neurocognitive and personality measures. Dept. of Psychology. Paper copy at Leddy Library: Theses 2 ̆ 6 Major Papers - Basement, West Bldg. / Call Number: Thesis 1986. D 458. Source: Dissertation Abstracts International, Volume: 48 - 07, Section: B, page: 2115. Thesis (Ph. D.) [...] University of Windsor (Canada), 1987...|$|R
40|$|The {{sense of}} hearing depends on many {{physical}} and biological processes. Much research {{is focused on}} different aspects of hearing loss and {{ways to improve the}} lives of those with this disability. Auditory neuropathy (AN) is a relatively newly discovered hearing disorder and has been related to damage in the auditory nerve synapses, both pre- and post-synaptic transmission, and the nerve itself. This damage ranges from demyelination to axonal and cell loss. One of the significant deficits that people with AN suffer is their inability to understand speech in a noisy environment. Understanding speech depends on the listener’s ability to extract the temporal envelope of the spoken language. Since AN patients have a significant temporal processing deficit, it is difficult for them to understand speech despite the fact that they can hear it. Gap detection and temporal modulation transfer function (TMTF) have been the most common psychophysical tests that are used to measure the severity of impairment in patients with AN. These two subjective tests have frequently been used to evaluate the temporal acuity of patients with auditory neuropathy. However, these tests rely on subjects’ active responses to stimuli, which means that they are not feasible for examining infants and patients with some cognitive disabilities that limit their understanding of the task. Therefore, finding an alternative test that can reliably and objectively measure temporal acuity is crucial. Recent studies suggest that cortical evoked potentials may be used to assess both the severity and lesion sites of AN. However, these cortical potentials are limited to adults and are not easily implemented in an everyday clinical setting. The present research proposed a new technique that will allow clinicians to objectively measure the <b>auditory</b> temporal processing <b>acuity</b> for patients with auditory neuropathy. The <b>auditory</b> temporal processing <b>acuity</b> for five different groups has been studied using both the conventional subjective test and a newly proposed objective technique. The five groups included 12 younger normal-hearing subjects (18 - 28 years), 12 older subjects (41 - 63 years), 12 elderly subjects (67 - 82 years), two normal-hearing children (10 - 14), and seven subjects who have been diagnosed with auditory neuropathy (11 - 43). Some of the subjects in the older and elderly groups had normal hearing thresholds, and some had hearing loss. The newly developed objective technique used a modulated noise in which its amplitude or frequency rate was varied over time to elicit the envelope following response (EFR). Data from the five groups showed a significant correlation between the modulation detection threshold estimated by the EFR and that by behavioral modulation transfer function (MTF). This significant correlation suggests that the EFR can serve as an objective novel technique to evaluate the severity of auditory neuropathy. Together, the EFR-MTF profiles can be related to known sites of lesions in AN. The EFR profile can be used as a bio-marker to objectively diagnose auditory processing disorders and to help make treatment options...|$|R
