0|1493|Public
40|$|We {{introduce}} a new formal semantics for active databases that relies on a transaction rewriting technique. A user defined transaction, which is viewed here as a sequence of <b>atomic</b> <b>database</b> updates forming a semantic unit, is translated by means of active rules into induced one(s). Those transactions embody active rule semantics which can be either immediate or deferred. Rule semantics, confluence, equivalence and optimization are then formally investigated and characterized in a solid framework that naturally extends a known model for relational <b>database</b> <b>transactions.</b> Keywords: Active <b>databases,</b> rule semantics, <b>transaction</b> equivalence, confluence, optimization. 2 1 Introduction Active databases are based on rules {{that allow us to}} specify actions to be taken by the system automatically, when certain events occur and some conditions are met. It is widely recognized that these active rules provide a powerful mechanism for the management of several important database activities (e. g., c [...] ...|$|R
5000|$|A {{long-lived}} transaction is {{a transaction}} that spans multiple <b>database</b> <b>transactions.</b> The transaction is considered [...] "long-lived" [...] because its boundaries must, by necessity of business logic, extend past a single <b>database</b> <b>transaction.</b> A long-lived transaction {{can be thought}} of as a sequence of <b>database</b> <b>transactions</b> grouped to achieve a single atomic result.|$|R
50|$|A <b>database</b> <b>transaction,</b> by definition, must be atomic, consistent, {{isolated}} and durable. Database practitioners often refer to these properties of <b>database</b> <b>transactions</b> using the acronym ACID.|$|R
40|$|In a {{computing}} environment where access to system resources {{is controlled by}} an access control policy and execution of <b>database</b> <b>transactions</b> is dictated by database locking policy, interaction between the two policies can result in constraints restricting execution of transactions. We present a methodology for the verification of <b>database</b> <b>transaction</b> requirements in a Role Based Access Control (RBAC) environment. Specifically, we propose a step by step approach for the extraction of implicit requirements of a <b>database</b> <b>transaction,</b> and present a mechanism whereby these requirements can be verified against an RBAC policy representation. Based on the requirements of <b>database</b> <b>transaction,</b> we define feasible states of the access control policy which allow the transaction to be executed. We also illustrate the interaction of multiple <b>database</b> <b>transactions</b> executing in a single security environment. Finally, we define conditions in an access control policy, which allow the execution of a <b>database</b> <b>transaction</b> without relying on the underlying database locking policy for serializability and deadlock avoidance. 1...|$|R
40|$|We {{propose a}} new formal {{semantics}} of active databases {{based on a}} transaction rewriting technique {{in the context of}} the relational model. A user defined transaction, which is viewed here as a sequence of <b>atomic</b> <b>database</b> updates forming a semantic unit, is translated by means of active rules into induced one(s). Those transactions embody active rule semantics which can be either immediate or deferred. Rule semantics, confluence, equivalence and optimization are then formally investigated and characterized in a solid framework that naturally extends a known setting for relational <b>database</b> <b>transactions.</b> 1 Introduction Active databases are based on rules that allow us to specify actions to be taken by the system automatically, when certain events occur and some conditions are met. It is widely recognized that these active rules provide a powerful mechanism for the management of several important database activities (e. g., constraint maintenance and view matherialization [4, 5]), [...] ...|$|R
40|$|Snapshot Isolation (SI) {{protocol}} is a <b>database</b> <b>transaction</b> processing algorithm {{used by some}} {{of commercial}} database systems to manage the concurrent executions of <b>database</b> <b>transactions.</b> SI protocol is a special case of multi-version algorithm. It avoids many of the anomalies typical for the concurrent processing of <b>database</b> <b>transactions.</b> Unfortunately, SI protocol does not guarantee correct serialization of <b>database</b> <b>transactions</b> under certain conditions. A recent work [3] proposed a formal solution, which characterizes the correctness of transactions running under SI protocoL However, the protocol is inefficient {{when it comes to}} processing long transactions. In this paper, we show that the limitations imposed on the structures of long transactions improve performance of SI protocol. A different way to characterize the serializability of schedule under SI dynamically is proposed and proved...|$|R
5000|$|Transaction Replayer - Recorder and replayer of <b>database</b> <b>transactions.</b>|$|R
50|$|Transaction ID number: A {{reference}} to the <b>database</b> <b>transaction</b> generating the log record.|$|R
5000|$|Extra {{overhead}} {{is involved}} {{in order to determine}} the state of the <b>database</b> <b>transactions.</b>|$|R
5000|$|Durability (database systems), {{one of the}} ACID {{properties}} that guarantee that <b>database</b> <b>transactions</b> are processed reliably ...|$|R
5000|$|<b>Database</b> <b>{{transaction}}s</b> where {{a transaction}} atomically includes perhaps a write, a read and a matching delete operation.|$|R
5000|$|Elmagarmid, A.K. (Editor). <b>Database</b> <b>Transaction</b> Models for Advanced Applications. Published by Morgan Kauffman Press, Mar. 1992, 611 pages[...]|$|R
50|$|The Telecommunication Application Transaction Processing Benchmark (TATP) is a {{benchmark}} {{designed to measure}} performance of in-memory <b>database</b> <b>transaction</b> systems.|$|R
40|$|We {{describe}} an E-Learning tool, DTST, {{that is designed}} to assist undergraduate computer science students to learn about <b>database</b> <b>transaction</b> processing, in general, and CRAS property satisfaction, in particular. DTST is written primarily in PROLOG, and includes an Internet interface for ease of use and access. Testing of DTST suggests that the learning tool is of value in helping computer science students to learn about some important aspects of <b>database</b> <b>transaction</b> processing...|$|R
50|$|A nested <b>transaction</b> is a <b>database</b> <b>transaction</b> that {{is started}} by an {{instruction}} {{within the scope}} of an already started transaction.|$|R
50|$|CRM module allows {{maintaining}} client <b>database,</b> <b>transactions</b> {{and potential}} sales, tasks, client relationship history. This module also provides online billing feature.|$|R
5000|$|... (or , or , {{depending}} on SQL dialect) marks {{the start of}} a <b>database</b> <b>transaction,</b> which either completes entirely or not at all.|$|R
5000|$|... redo log buffer: {{contains}} {{information about}} <b>database</b> <b>transactions,</b> both committed and uncommitted, {{in preparation for}} writing to online redo log files ...|$|R
5000|$|The {{concept of}} a <b>database</b> <b>transaction</b> (or <b>atomic</b> transaction) has evolved in order to enable both a well {{understood}} database system behavior in a faulty environment where crashes can happen any time, and recovery from a crash to a well understood database state. A <b>database</b> <b>transaction</b> is a unit of work, typically encapsulating a number of operations over a database (e.g., reading a database object, writing, acquiring lock, etc.), an abstraction supported in database and also other systems. Each transaction has well defined boundaries in terms of which program/code executions are included in that transaction (determined by the transaction's programmer via special <b>transaction</b> commands). Every <b>database</b> <b>transaction</b> obeys the following rules (by support in the database system; i.e., a database system is designed to guarantee them for the transactions it runs): ...|$|R
50|$|A {{promising}} {{hybrid of}} these two {{is to provide a}} transactional memory abstraction. As with critical sections, the user marks sequential code that must be run in isolation from other threads. The implementation then ensures the code executes atomically. This style of abstraction is common when interacting with databases; for instance, when using the Spring Framework, annotating a method with @Transactional will ensure all enclosed database interactions occur in a single <b>database</b> <b>transaction.</b> Transactional memory goes a step further, ensuring that all memory interactions occur atomically. As with <b>database</b> <b>transactions,</b> issues arise regarding composition of <b>transactions,</b> especially <b>database</b> and in-memory <b>transactions.</b>|$|R
40|$|A {{new type}} of {{database}} anomaly is described by addressing the concept of Cumulated Anomaly in this paper. Dubiety-Determining Model (DDM), which is a detection model basing on statistical and fuzzy set theories for Cumulated Anomaly, is proposed. DDM can measure the dubiety degree of each <b>database</b> <b>transaction</b> quantitatively. Software system architecture to support the DDM for monitoring <b>database</b> <b>transactions</b> is designed. We also implemented the system and tested it. Our experimental {{results show that the}} DDM method is feasible and effective. 1...|$|R
50|$|<b>Database</b> <b>transactions</b> {{can be used}} to {{introduce}} some level of fault tolerance and data integrity after recovery from a crash. A <b>database</b> <b>transaction</b> is a unit of work, typically encapsulating a number of operations over a database (e.g., reading a database object, writing, acquiring lock, etc.), an abstraction supported in database and also other systems. Each transaction has well defined boundaries in terms of which program/code executions are included in that transaction (determined by the transaction's programmer via special transaction commands).|$|R
5000|$|Transactions are {{transparent}} — each <b>transaction</b> {{must maintain}} <b>database</b> integrity across multiple <b>databases.</b> <b>Transactions</b> {{must also be}} divided into sub-transactions, each sub-transaction affecting one database system.|$|R
50|$|In <b>databases</b> and <b>transaction</b> processing, {{two-phase}} locking (2PL) is a {{concurrency control}} method that guarantees serializability.It {{is also the}} name of the resulting set of <b>database</b> <b>transaction</b> schedules (histories). The protocol utilizes locks, applied by a transaction to data, which may block (interpreted as signals to stop) other transactions from accessing the same data during the transaction's life.|$|R
50|$|Fully transactional: {{supports}} ACID transactions guaranteeing {{that all}} <b>database</b> <b>transactions</b> are processed reliably {{and in the}} event of a crash all pending documents are recovered and committed.|$|R
5000|$|Complete {{coverage}} of all <b>database</b> <b>transactions</b> — the sensor covers traffic {{coming from the}} network, from the host, {{as well as from}} back-doors (stored procedures, triggers, views) ...|$|R
30|$|The {{attributes}} {{that are part}} of the vision of <b>database</b> <b>transactions</b> were CustomerID, and ProductID Order Date, and that will be part of world knowledge are ProductID and CategoryID.|$|R
5000|$|In a <b>database</b> <b>{{transaction}},</b> if {{the transaction}} cannot be completed {{due to a}} concurrent operation (e.g. in a deadlock), the transaction will be aborted and the user must try again.|$|R
40|$|HUANG-CHENG KUO This thesis {{proposes a}} model for <b>database</b> <b>transactions</b> to {{cooperate}} through rules, task communication and synchronization. <b>Database</b> <b>transactions</b> manipulate persistent and transient data objects. With event-conditionaction (ECA) rules from active databases, the model provides transactions with {{a new way of}} cooperation. Task communication and synchronization can be specified not only statically inside transactions, but also dynamically through rules. Statically specified task communication and synchronization cannot handle dynamic changes, which provides the motivation for using rules. A transaction manager is involved in transaction cooperation by invoking transaction manipulation operations, e. g., start a transaction {{as a result of an}} event...|$|R
50|$|Multi-tier {{enterprise}} {{applications such as}} Oracle EBS, PeopleSoft, JD Edwards, SAP, Siebel Systems, Business Intelligence, and custom applications built on standard middle-tier servers such as IBM WebSphere and Oracle WebLogic Server mask the identity of end-users at the <b>database</b> <b>transaction</b> level. This is done with an optimization mechanism known as “connection pooling.” Using pooled connections, the application aggregates all user traffic within a few database connections that are identified only by a generic service account name. Application activity monitoring allows organizations to associate specific <b>database</b> <b>transactions</b> with particular application end-users, {{in order to identify}} unauthorized or suspicious activities.|$|R
50|$|Serializability {{is used to}} {{keep the}} data in the data item in a {{consistent}} state. Serializability is a property of a transaction schedule (history). It relates to the isolation property of a <b>database</b> <b>transaction.</b>|$|R
50|$|Tibero {{guarantees}} reliable <b>database</b> <b>transactions,</b> {{which are}} logical sets of SQL statements, by supporting ACID (Atomicity, Consistency, Isolation, and Durability). Providing enhanced synchronization between databases, Tibero 5 enables reliable database service operation in a multi node environment.|$|R
30|$|To {{turn it into}} a <b>database</b> <b>transaction,</b> {{which allows}} data mining of user behavior, it was {{necessary}} to create an adequate view. Data on the purchasing habits of users are recorded in Order Details, Customers and Orders tables.|$|R
50|$|Despite the {{disparate}} names, {{many of the}} same mathematical operations, queries, or <b>database</b> <b>transactions</b> are useful for analysing all of them. The implementation of a database that can correctly, reliably, and efficiently implement these operations must be specialized for time-series data.|$|R
50|$|McGoveran {{has written}} {{articles}} {{in the fields of}} relational <b>databases,</b> <b>transaction</b> processing, business intelligence, enterprise application integration, business process management, mathematics, and physics, including over 100 monthly columns for eAI Journal (a.k.a. Business Integration Journal) throughout the life of the journal.|$|R
5000|$|DBMSs {{need to deal}} {{also with}} {{concurrency}} control issues not typical just to <b>database</b> <b>transactions</b> but rather to operating systems in general. These issues (e.g., see Concurrency control in operating systems below) {{are out of the}} scope of this section.|$|R
