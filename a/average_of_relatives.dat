0|10000|Public
40|$|The paper {{shows that}} due to the {{features}} of SKU (stock-keeping unit) demand data wellknown error measures previously used to analyse the accuracy of adjustments are generally not advisable for the task. In particular, percentage errors are affected by outliers and biases arising from {{a large number of}} low actual demand values and correlation between forecast errors and actual outcomes. It is also shown that MASE is equivalent to the arithmetic <b>average</b> <b>of</b> <b>relative</b> mean absolute errors (MAEs) and inherently is biased towards overrating the benchmark method. Therefore existing measures cannot deliver easily interpretable and unambiguous results. To overcome the imperfections of existing schemes a new measure is introduced which indicates <b>average</b> <b>relative</b> improvement <b>of</b> MAE. In contrast to MASE the proposed scheme is based on finding the geometric <b>average</b> <b>of</b> <b>relative</b> MAEs. This allows objective evaluation <b>of</b> <b>relative</b> change in forecasting accuracy yielded by the use of adjustments. Empirical analysis employed a large number of observations collected from a company specialising on manufacturing of fast-moving consumer goods (FMCG). The results suggest that adjustments reduced MAE of baseline statistical forecast on average by approximately 10 %. Using a binomial test it was confirmed that adjustments improved the accuracy of forecasts significantly more frequently rather than they reduced it...|$|R
40|$|In {{this paper}} we {{address the problem of}} robust and {{efficient}} <b>averaging</b> <b>of</b> <b>relative</b> 3 D rotations. Apart from having an interesting geometric structure, robust rotation averaging addresses the need for a good initialization for large-scale optimization used in structure-from-motion pipelines. Such pipelines often use unstructured image datasets harvested from the internet thereby requiring an initialization method that is robust to outliers. Our approach works on the Lie group structure of 3 D rotations and solves the problem of large-scale robust rotation averaging in two ways. Firstly, we use modern l(1) optimizers to carry out robust <b>averaging</b> <b>of</b> <b>relative</b> rotations that is efficient, scalable and robust to outliers. In addition, we also develop a two-step method that uses the l(1) solution as an initialisation for an iteratively reweighted least squares (IRLS) approach. These methods achieve excellent results on large-scale, real world datasets and significantly outperform existing methods, i. e. the state-of-the-art discrete-continuous optimization method of 3] as well as the Weiszfeld method of 8]. We demonstrate the efficacy of our method on two large-scale real world datasets and also provide the results of the two aforementioned methods for comparison...|$|R
40|$|Liquid-phase microextraction (LPME) {{followed}} by gas chromatography (GC) {{coupled with an}} electron capture detector (ECD) was applied {{for the analysis of}} pentachlorophenol (PCP) in aqueous samples. After alkalization with Na 2 CO 3 solution, PCP was acetylated with acetic anhydride. The pentachlorophenyl acetate derivative was then extracted with n-hexane by LPME. 1. 5 muL organic drop exposed to the aqueous sample solution at 15 degreesC for 5 min, stirring rate at 100 r/min was chosen as the optimum extraction condition. Under this condition, LPME provided a very simple, fast and solvent-less procedure to collect PCP from aqueous sample for GC determination. The linearity of LPME/GC-ECD for PCP in distilled water was investigated at the range of 2 - 200 mug/L with a coefficient of correlation 0. 998. The repeatability of this method was determined at the level of 50 mug/L with the <b>average</b> <b>of</b> <b>relative</b> standard deviations (RSDs) 7 %. Detection limit was obtained at less than 0. 5 mug/L levels. When LPME/GC-ECD was applied to the determination of PCP in municipal sewage, the <b>average</b> <b>of</b> <b>relative</b> recoveries and RSDs were 70 % and 6. 5 %, respectively...|$|R
40|$|In {{this paper}} we {{assemble}} a measure <b>of</b> international <b>relative</b> prices {{to gauge the}} average amount by which prices in China and the USA differ from the prices of their trading partners. Our estimated weighted <b>average</b> <b>of</b> <b>relative</b> prices for China and the USA {{are the first to}} use the significantly revised purchasing power parities embodied in the price data from the World Bank's World Development Indicators. Our analysis reveals several findings of interest. First, interactions between the structure of trade and the levels <b>of</b> <b>relative</b> prices are sufficiently important to induce divergences between the weighted <b>average</b> <b>of</b> <b>relative</b> prices and conventional real effective exchange-rate indexes. Second, revisions embodied in World Development Indicators price data generally lower the estimate <b>of</b> US international <b>relative</b> prices. Third, net exports are inversely related to the estimate <b>of</b> US international <b>relative</b> price, but, for China, the correlation is positive. Estimating this correlation for other countries reveals no systematic pattern related to the level of development alone. Fourth, unlike previous work, using our price measures we find that an increase in US prices relative to Chinese prices raises the share of China's exports to the USA. Finally, there is a distinct possibility of eliminating the long-standing differential in income elasticities of US trade in empirical applications. Copyright 2009 The Authors. Journal compilation 2009 Blackwell Publishing Asia Pty Ltd...|$|R
5000|$|... is {{computed}} as {{a weighted}} <b>average</b> <b>of</b> the <b>relative</b> permittivity <b>of</b> free space (1) {{and that of}} the dielectric:where the fill factor F expresses the effective proportion of space so affected by the dielectric.|$|R
40|$|We revisit cosmic {{microwave}} background (CMB) constraints on primordial black hole dark matter. Spectral distortion limits from COBE/FIRAS do not impose a relevant constraint. Planck CMB anisotropy power spectra imply that primordial black holes with m_BH≳ 5 M_ are disfavored. However, this is susceptible to sizeable uncertainties due {{to the treatment of}} the black hole accretion process. These constraints are weaker than those quoted in earlier literature for the same observables. Comment: 4 pages. v 2 : changed treatment <b>of</b> statistical <b>averaging</b> <b>of</b> <b>relative</b> bulk motion between pBHs and baryonic plasm...|$|R
30|$|According to the {{climatic data}} (Fig.  10), the {{measured}} stream flow, the soil moisture {{and the other}} hydrological parameters, the hydrological budget of the gaged part of the Lottentalbach catchment area {{can be described as}} follows; the annual precipitation during the study period is 944.5  mm, <b>average</b> <b>of</b> <b>relative</b> humidity is 61.74  %, <b>average</b> <b>of</b> air temperature at 14 : 00  h is 14.09  °C, the <b>average</b> <b>of</b> T max is 16.36  °C, the <b>average</b> <b>of</b> the T min is 7.2  °C and the <b>average</b> <b>of</b> mean temperature is 11.55  °C. The minimal air temperature value of − 14.5  °C was measured in the winter, and the maximal value of 34  °C was measured in the summer. The actual evapotranspiration value during the study period, resulted by integration of Renger and Wessolek and Bagrov and Glugla methods, is 301.25  mm.|$|R
50|$|A Törnqvist or Törnqvist-Theil {{price index}} is the {{weighted}} geometric <b>average</b> <b>of</b> the price <b>relatives</b> using arithmetic <b>averages</b> <b>of</b> the value {{shares in the}} two periods as weights.|$|R
30|$|Basic {{statistics}} <b>of</b> the <b>average</b> amount <b>of</b> the <b>relative</b> {{accuracy in}} sampling and the <b>average</b> amount <b>of</b> {{the percentage of}} duplicate trends, are reported in Table 3.|$|R
50|$|Batumi's {{average annual}} {{precipitation}} is 2392 mm. December is the wettest month with an <b>average</b> <b>of</b> 303 mm of precipitation, while May is the driest, averaging 84 mm. Batumi generally does not receive {{significant amounts of}} snow (accumulating snowfall of more than 30 cm), {{and the number of}} days with snow cover for the year is 12. The <b>average</b> level <b>of</b> <b>relative</b> humidity ranges from 70-80%.|$|R
40|$|Laws of {{formation}} of {{the form of a}} processed flat surface of a precision optical detail in the course of diamond grinding with reference to the offered model in which only compulsory rotation of a detail is provided are investigated. On the basis of physic and statistical model of formation and removal of particles slime, and also a method <b>of</b> <b>averaging</b> <b>of</b> <b>relative</b> speed <b>of</b> moving on coordinate variables dependences of size removal the processed material, forms characterising evolution grinding a surface and size of a deviation from flatness are received. The most rational values eccentricity and distances between axes of rotation of a detail and the tool at which demanded accuracy formation is reached are defined...|$|R
40|$|For all one-hit {{detectors}} the <b>relative</b> effectiveness <b>of</b> a {{mixed radiation}} field {{may be found}} as the dose-weighted <b>average</b> <b>of</b> the <b>relative</b> effectiveness <b>of</b> its components, segregated according to the atomic number Z and the energy T. We emphasize that this procedure is incorrect for mammalian cells, whatever {{the nature of the}} segregation...|$|R
40|$|Abstract- in {{this paper}} we study {{divisible}} load scheduling with result collection on heterogeneous system. Divisible loads represent computations which can be arbitrarily divided into parts and performed independently parallel. The scheduling problem consists in distributing the load in a heterogeneous system taking into account communication and computation times, so that the whole processing time is as short as possible. Since our scheduling problem is computationally hard, we propose a Branch & Bound algorithm. By simulating and comparing results, it is observed which this result produces better answers than other methods, it means that, branch & bound algorithm have less total <b>average</b> <b>of</b> <b>relative</b> error percentage in the variety Heuristic functions. Keywords- divisible load scheduling; Heterogeneous System; Branch & bound algorithm. I...|$|R
40|$|Relative {{mobility}} {{was taken}} {{as a tool to}} investigate the peak identification in micellar electrokinetic capillary chromatography (MEKC). The precision (<b>average</b> RSD) <b>of</b> <b>relative</b> mobility was 1. 5 %, which was, much better than the peak identification with migration time. The reliability of the identification with the relative mobility was 16 times better than that with migration time...|$|R
30|$|In {{the early}} stages of SFM development, there were more studies on {{relative}} pose solving. One of the useful studies is the algorithm for five-point relative pose problem in [157], which has less degeneracies than other relative pose solvers. Lee et al. [158] studied relative pose estimation for a multi-camera system with known vertical direction. Kneip and Li [159] presented a novel solution to compute the <b>relative</b> pose <b>of</b> a generalized camera. Chatterjee and Govindu [160] presented efficient and robust large-scale <b>averaging</b> <b>of</b> <b>relative</b> 3 D rotations. Ventura et al. [161] proposed an efficient method for estimating the <b>relative</b> motion <b>of</b> a multi-camera rig from a minimal set of feature correspondences. Fredriksson et al. [162] estimated the relative translation between two cameras and simultaneously maximized the number of inlier correspondences.|$|R
40|$|Abstract- in {{this paper}} we propose a new {{heuristic}} function, for Branch & Bound algorithm. By this function we can increase the efficiency of Branch & bound algorithm. Divisible loads represent computations which can be arbitrarily divided into parts and performed independently parallel. The scheduling problem consists in distributing the load in a heterogeneous system taking into account communication and computation times, so that the whole processing time is as short as possible. Since our scheduling problem is computationally hard, we propose a Branch & Bound algorithm. By simulating and comparing results, it is observed which this result produces better answers than other methods, it means that, branch & bound algorithm have less total <b>average</b> <b>of</b> <b>relative</b> error percentage in the variety Heuristic functions. Keywords- divisible load scheduling; Heterogeneous System; Branch & bound algorithm. I...|$|R
40|$|SeaWiFS, MODIS and MERIS {{remote sensing}} radiometric {{products}} were assessed using in situ data collected at a coastal {{site in the}} northern Adriatic Sea from May 2002 to September 2005. The analysis was restricted to satellite and in situ data taken within ± 1 hour to minimize the effects of temporal variability of atmosphere and seawater around the measurement site. The comparison of SeaWiFS and MODIS with in situ normalized water leaving radiances showed <b>averages</b> <b>of</b> <b>relative</b> percent differences varying from 0 % to - 9 % in the 443 - 555 nm spectral range. Higher values ranging from + 18 to + 43 % were shown for the MERIS data in the equivalent spectral range (i. e., 443 - 560 nm). JRC. H. 3 -Global environement monitorin...|$|R
50|$|A {{price index}} (plural: “price indices” or “price indexes”) is a {{normalized}} average (typically a weighted <b>average)</b> <b>of</b> price <b>relatives</b> {{for a given}} class of goods or services in a given region, during a given interval of time. It is a statistic designed to help to compare how these price relatives, taken as a whole, differ between time periods or geographical locations.|$|R
40|$|Experiment of {{free fall}} motion {{is one of}} {{phenomena}} in physic. Parameters of free fall motion still measured by stopwatch and meter. The purpose of research is development of free fall motion experiment set based on microcontroller with personal computer display. This instrument have highest precision and accuration. <b>Average</b> <b>of</b> measured result is 9, 821 ± 0, 025 with <b>average</b> <b>of</b> precicion <b>relative</b> is 98, 3 % and average accuration is 0, 992...|$|R
2500|$|A {{price index}} (plural: “price indices” or “price indexes”) is a {{normalized}} average (typically a weighted <b>average)</b> <b>of</b> price <b>relatives</b> {{for a given}} class of goods or [...] services in a given region, during a given interval of time. [...] It is a statistic designed to help to compare how these price relatives, taken as a whole, differ between time periods or geographical locations.|$|R
30|$|Figure  15 {{represents}} additional {{comparison between}} NN and SVM models in terms <b>of</b> <b>average</b> <b>relative</b> error percent against pressure range. It was shown that SVM {{is much better}} than NN.|$|R
40|$|Induction motors (IMs) {{are widely}} used in {{industry}} including it be an electrical or not. However during starting period, their starting currents are so large that can damage equipment. Therefore, this current should be estimated accurately to prevent hazards caused by it. In this paper, the artificial neural network (ANN) as an intelligent tool is used to evaluate starting current peak of IMs. Both Multilayer Perceptron (MLP) and Radial Basis Function (RBF) structures have been analyzed. Six learning algorithms, backpropagation (BP), delta-bar-delta (DBD), extended delta-bar-delta (EDBD), directed random search (DRS), quick propagation (QP), and levenberg marquardt (LM) were used to train the MLP. The simulation results using MATLAB show that most developed ANNs can estimate the starting current peak of IMs with good accuracy. However, it is proven that LM and EDBD algorithms present better performance for starting current evaluation based on <b>average</b> <b>of</b> <b>relative</b> and absolute errors...|$|R
40|$|The {{aim of this}} {{research}} is invention probabilistic approach to analyze the recession curve for mean monthly inflows to lakes of Dokan dam at Lesser Zab river and Derbendikan dam  at the Diyalah river by dividing the recession curve to many class interval and finding the mathematical equations which controls each class interval by using finite mathematics, and using Markov chain to calculated the transition probability matrix for the classes intervals. A computer program in Visual basic language with visual application interface in Excel software which be developed to generate recession curve. The results indicated that recession curve consist of five class intervals and each class interval have a power regression equation, the statistical analysis indicated a good confidence to use a computer program to generate the recession curve because that <b>average</b> <b>of</b> <b>relative</b> percentage error wasn’t greater than      8 %  for Dokan dam and 9 % for Derbendikan dam...|$|R
30|$|In Fig.  6 X-axis {{represents}} the % relative difference (between data set instances and achieved AUC performance) and Y-axis {{represents the}} over_sampling techniques. The graph states the <b>average</b> values <b>of</b> % <b>relative</b> difference from Table  9.|$|R
40|$|In this paper, {{we present}} an {{extension}} of the iterative closest point (ICP) algorithm that simultaneously registers multiple 3 D scans. While ICP fails to utilize the multiview constraints available, our method exploits the information redundancy in a set of 3 D scans by using the <b>averaging</b> <b>of</b> <b>relative</b> motions. This <b>averaging</b> method utilizes the Lie group structure of motions, resulting in a 3 D registration method that is both efficient and accurate. In addition, we present two variants of our approach, i. e., a method that solves for multiview 3 D registration while obeying causality and a transitive correspondence variant that efficiently solves the correspondence problem across multiple scans. We present experimental results to characterize our method and explain its behavior {{as well as those of}} some other multiview registration methods in the literature. We establish the superior accuracy of our method in comparison to these multiview methods with registration results on a set of well-known real datasets of 3 D scans...|$|R
40|$|Thesis (M. S.) [...] Humboldt State University, Natural Resources: Fisheries, 2009 Standard weight {{equations}} were developed for juvenile steelhead using the regression line percentile and empirical methods. The equation developed using the empirical method better represented juvenile steelhead lengths and weights and {{was free of}} length bias. Standard weight was used to estimate average relative weights for juvenile steelhead trout populations in northern California streams. Population <b>averages</b> <b>of</b> <b>relative</b> weight, estimated by the empirical equation, were then modeled against turbidity, temperature, and juvenile steelhead trout density to determine if these variables had meaningful relationships with condition. Average relative weight measured in the fall {{was positively related to}} degree day accumulation during late winter and early spring. Turbidity and biomass metrics were not found to be significantly related to juvenile steelhead trout condition. Further {{research is needed to determine}} if relative weight accurately represents the effects of physiological, population and environmental variables on juvenile steelhead trout condition...|$|R
30|$|For the Peak scenario, {{the use of}} near-optimal {{categorization}} method {{suggested an}} average relative safety benefit (i.e. improvement in safety) of 44.3 %. The use of ad hoc categorization method, with all {{other aspects of the}} analysis unchanged, estimates an <b>average</b> <b>relative</b> safety benefit <b>of</b> 40.1 %. These estimates are relatively similar (with the absolute difference being only approximately 10.1 % <b>of</b> the <b>average</b> <b>of</b> the <b>relative</b> safety benefits associated with different methods).|$|R
40|$|Abstract—Delay is an {{important}} metric to understand and improve system performance. While existing approaches focus on aggregate delay statistics in pre-programmed granularity, providing only statistical results such as averages and deviations, those approaches fail to provide fine-grained delay measurement at a flexible level and thus may miss important delay character-istics. For example, delay anomalies, which are critical system performance indicators, may not be captured by existing coarse-grained approaches. In this work, we propose a fine-grained delay measurement approach based on a new measurement structure design called order preserving aggregator (OPA). OPA can efficiently encode the ordering and loss information by exploiting inherent data characteristics. Based on OPA, we propose a two-layer design to convey both ordering and time stamp information, and then derive per-packet delay/loss measurement with a small overhead. We evaluate our approach both analytically and experimentally with widely used real-world data sets. The results show that our approach can achieve accurate per-packet delay measurement with an <b>average</b> <b>of</b> per-packet <b>relative</b> error at 2 %, and an <b>average</b> <b>of</b> aggregated <b>relative</b> error at 10 − 5, while introducing less than 4 × 10 − 4 additional overhead. I...|$|R
30|$|From December 2014 to January 2016, 81 donors’ {{relatives}} were included. An <b>average</b> <b>of</b> 3.24 <b>relatives</b> per donor was included. 16 <b>of</b> the 29 <b>relatives</b> who responded at 6  months had an ICG >  25. The prevalence of complicated grief is 55.2 % [95 CI =  37 – 73]. The prevalence of {{major depressive disorder}} and PTSD are respectively 72 % [95 CI =  55.7 – 88.3] and 31 % [95 CI =  14.2 – 47.8] (Table  1). No variable {{were significantly associated with}} a complicated grief at 6  months from the death.|$|R
40|$|The paper reviews some of {{the main}} site {{diversity}} prediction models published in literature and presents the results of a test carried out with data from 90 experiments, in the frequency range between 10 and 30 GHz. The results, which are presented in terms <b>of</b> <b>average</b> and rms <b>of</b> <b>relative</b> gain error, show that Hodge, EXCELL and Matricciani are the best performing models...|$|R
40|$|Patient {{safety is}} one of the most {{important}} points to consider in healthcare. As such, various programs are entered by healthcare institutions to monitor their services including patient safety procedures. One of these programs is accreditation. Accreditation is an internationally recognized evaluation process used to assess, promote and guarantee efficient and effective quality of patient care and patient safety. This study will provide valuable information regarding the impact and limitations of the accreditation process found by other researchers as well as the experience of King Abdul-Aziz University Hospital in Saudi Arabia. The 28 out of 81 (34. 57 %) patient safely indicators significantly improved during accreditation process at King Abdulaziz University Hospital. Survey results show that the overall <b>average</b> <b>of</b> <b>relative</b> improvement percent is 34. 43 %. Both results are similar to other findings. The accreditation process as experienced by King Abdulaziz University Hospital has significantly improved 1 / 3 of patient safety indicators and perception of nursing staffs is correlated with statistical findings. Those findings are supported by international literature. © Medwell Journals, 2011. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|R
40|$|The {{consumer}} price indexes {{for the entire}} country and those for individual households are weighted arithmetic <b>averages</b> <b>of</b> <b>relative</b> prices, and they differ essentially {{in terms of their}} weighting systems. Whereas the former use the proportions of total expenditure on goods and services, the latter use the proportions of expenditure by each household. In the usual calculation of the index for the entire country, each household contributes to determining the national index with a weight proportional to its expenditure. In other words, the households that spend more - that is, the wealthier ones - are represented in calculation of the national index to a greater extent, and this explains why the latter is termed the 'plutocratic index'. In contraposition to plutocratic indexes are the 'democratic' ones in which the same weight is assigned to each household.;The paper presents a first estimation of the democratic price indexes for Italy in the period 1995 - 2002. The results show {{significant differences between the two}} calculation methods. {{consumer price}} indexes, inflation, plutocratic and democratic indexes, price policy...|$|R
40|$|We {{describe}} new heuristics {{to construct}} decision rules for decision tables with many-valued decisions {{from the point}} of view of length and coverage which are enough good. We use statistical test to find leaders among the heuristics. After that, we compare our results with optimal result obtained by dynamic programming algorithms. The <b>average</b> percentage <b>of</b> <b>relative</b> difference between length (coverage) of constructed and optimal rules is at most 6. 89 % (15. 89 %, respectively) for leaders which seems to be a promising result. © 2013 IEEE...|$|R
40|$|Diaporthe helianthi Munt. Cvet. et al. (anamorph: Phomopsis) is a {{dangerous}} pathogen of sunflower, causing important yield losses. No information is as yet available, however, on the {{changes taking place in}} the achene yield-forming process, which eventually lead to the reduction in yield. The basic assumption was that by tracing the growth of the achene yield - using the growth analysis method - {{it would be possible to}} determine how the pathogenic fungus Diaporthe (=D.) helianthi - affected the dry matter accumulation process. The achene dry matter mass per head (ADM) was recorded at nine sampling dates during the achene filling period in five sunflower hybrids, in plants inoculated with the pathogen or treated with fungicide. Simultaneously with sampling, scoring was carried out for symptom dynamics. The results proved that, as the result of inoculation with D. helianthi, considerable changes took place in the achene dry matter accumulation process. The estimated growth characteristics of a second-order polynomial fitted to the ADM mass data: maximum yield per head (YMAX), <b>average</b> <b>of</b> absolute growth rate (AGRAVG), maximum of absolute growth rate (AGRMAX), maximum point of the absolute growth rate (XAGRMAX) and <b>average</b> <b>of</b> <b>relative</b> growth rate (RGRAVG), were considerably smaller in the inoculated treatment than in the sprayed treatment...|$|R
40|$|The study {{included}} detection {{of the sites}} of ossification centers and their sequence of appearance in the forelimb bones of indigenous sheep fetuses by using double staining method with younger specimens and radiography or maceration methods with old specimens, as well as, histological study with some ages. The {{results showed that the}} primary ossification centers of the forelimb in indigenous sheep fetuses appeared firstly in the diaphyses of radius and ulna, humerus, scapula, metacarpus, phalanges and lastly in the carpal bone at an estimated age of 43, 45, 46, 47, 49 - 56 and 90 - 118 days old respectively. The results of statistical analysis of the total lengths of scapula, humerus, radius, ulna and metacarpus with the lengths of their ossified parts through the 7 th – 15 th weeks of fetus age, showed presence of significant differences in the <b>average</b> <b>of</b> these measurements among most of studied weeks. Also there was a significant differences in the <b>average</b> <b>of</b> <b>relative</b> increase in the total length and length of ossified part of diaphysis of studied bones during the 7 th week in comparison to the same average in the other studied weeks (8 th- 15 th week) of indigenous sheep fetuses age...|$|R
30|$|After {{densitometry}} {{analysis of}} the spots, the <b>relative</b> density <b>of</b> the hydrolysis spots to control can be obtained. A plot <b>of</b> <b>average</b> <b>relative</b> density <b>of</b> hydrolysis spots versus concentration was plotted {{in order to obtain}} a model for the effect of enzyme concentration on the density of hydrolysis spots on the polymer film.|$|R
