465|135|Public
25|$|Some {{strands of}} {{computer}} vision research {{are closely related}} to the study of biological vision – indeed, just as many strands of AI research are closely tied with research into human consciousness, and the use of stored knowledge to interpret, integrate and utilize visual information. The field of biological vision studies and models the physiological processes behind visual perception in humans and other animals. Computer vision, on the other hand, studies and describes the processes implemented in software and hardware behind <b>artificial</b> <b>vision</b> systems. Interdisciplinary exchange between biological and computer vision has proven fruitful for both fields.|$|E
2500|$|In 2002, Jens Naumann, also blinded in adulthood, {{became the}} first in a series of 16 paying {{patients}} to receive Dobelle’s second generation implant, marking one of the earliest commercial uses of BCIs. The second generation device used a more sophisticated implant enabling better mapping of phosphenes into coherent vision. Phosphenes are spread out across the visual field in what researchers call [...] "the starry-night effect". Immediately after his implant, Jens was able to use his imperfectly restored vision to drive an automobile slowly around the parking area of the research institute. Unfortunately, Dobelle died in 2004 before his processes and developments were documented. Subsequently, when Mr. Naumann and the other patients in the program began having problems with their vision, there was no relief and they eventually lost their [...] "sight" [...] again. Naumann wrote about his experience with Dobelle's work in Search for Paradise: A Patient's Account of the <b>Artificial</b> <b>Vision</b> Experiment and has returned to his farm in Southeast Ontario, Canada, to resume his normal activities.|$|E
5000|$|From 1984/01/02 1985/08/30 {{he was a}} Visiting Fellow at the Stanford Research Institute (SRI) in California (United States), {{where he}} focused on {{research}} in the field of artificial intelligence and <b>artificial</b> <b>vision.</b> This work was the basis of his doctoral thesis, entitled [...] "Partially Visible Part Recognition via <b>Artificial</b> <b>Vision</b> in Industrial Environments" [...] in 1987. It was written in Basque language.|$|E
5000|$|The Leaf Project {{is a group}} robot {{development}} program {{whose objective is to}} develop a robot platform that supports experiments with <b>artificial</b> intelligence, <b>vision,</b> navigation, etc.|$|R
40|$|Can vision be {{restored}} to the blind? As early as 1929 {{it was discovered that}} stimulating the visual cortex of an individual led to the perception of spots of light, known as phosphenes. The aim of <b>artificial</b> human <b>vision</b> systems is to attempt to utilize the perception of phosphenes to provide a useful substitute for normal vision. Currently, four locations for electrical stimulation are being investigated; behind the retina (subretinal), in front of the retina (epiretinal), the optic nerve and the visual cortex (using intra- and surface electrodes). This review discusses <b>artificial</b> human <b>vision</b> technology and requirements and reviews the current development projects...|$|R
5000|$|AImotive - an ADAS and {{autonomous}} driving software for self-driving cars, based on <b>artificial</b> intelligence, computer <b>vision</b> and sensor fusion ...|$|R
5000|$|William H. Dobelle, 62, American {{biomedical}} researcher, eye {{doctor and}} inventor (<b>artificial</b> <b>vision</b> research), complications of diabetes. https://www.nytimes.com/2004/11/01/obituaries/01dobelle.html ...|$|E
50|$|In 1986 {{he set up}} {{the company}} Adicorp, S.A. {{with a view to}} commercially {{exploiting}} the results of his doctoral thesis in the field of <b>artificial</b> <b>vision.</b> The company did business until 1993, in the field of industrial applications of <b>artificial</b> <b>vision.</b> When Adicorp, S.A. was wound up the workers set up a new company under the name IKUSMEN, S.L. which continues to do business in the same market today.|$|E
50|$|Dobelle was the CEO of the Dobelle Institute, {{headquartered}} in Lisbon, Portugal, which concentrates on <b>artificial</b> <b>vision</b> for the blind.|$|E
50|$|Color {{normalization}} is a {{topic in}} computer <b>vision</b> concerned with <b>artificial</b> color <b>vision</b> and object recognition. In general, the distribution of color values in an image depends on the illumination, which may vary depending on lighting conditions, cameras, and other factors. Colour normalisation allows for object recognition techniques based on colour to compensate for these variations.|$|R
5000|$|Peripheral prism {{spectacles}} {{expand the}} visual field {{of patients with}} hemifield visual defects and {{have the potential to}} improve visual function and mobility.4 [...] Prism spectacles incorporate higher power prisms, with variable shapes and designs. The Gottlieb button prism, and the Peli superior and inferior horizontal bands are some proprietary examples of prism glasses. These high power prisms [...] "create" [...] <b>artificial</b> peripheral <b>vision</b> into the non-blind field for obstacle avoidance and motion detection.|$|R
40|$|An <b>artificial</b> {{high-level}} <b>vision</b> {{agent for}} the localisation and description of {{the movements of the}} SPIDER robot arm of the EUROPA/PAT systems during its operations is presented. The agent uses real-time image processing operations implemented on SIMPiL (SIMD Pixel Processor) to manage the large computational workloads and I/O throughput requirements. The vision agent, which includes a description agent, generates the perception grounded predicates obtained by image sequences and provides a 3 D estimation of the arm movements...|$|R
5000|$|D.O. Gorodnichy, W.W. Armstrong, A Parametrical Alternative for Grids in Occupancy Based World Modeling, Proc. Quality Control by <b>Artificial</b> <b>Vision</b> Conference (QCAV'99), Trois Rivieres, 125-132, 1999.|$|E
50|$|VisLab (i.e. the <b>Artificial</b> <b>Vision</b> and Intelligent Systems Laboratory) {{was funded}} {{in the early}} 90s as a {{research}} laboratory of University of Parma, Dipartimento di Ingegneria dell'Informazione.|$|E
5000|$|Dobelle's early {{research}} and final accomplishments {{in the field}} of <b>artificial</b> <b>vision</b> are extensively examined throughout the textbook Visual Prosthetics: Physiology, Bioengineering, Rehabilitation (edited by Gislin Dagnelie).|$|E
40|$|We {{describe}} an <b>artificial</b> high-level <b>vision</b> {{system for the}} symbolic interpretation of data coming from a video camera that acquires the image sequences of moving scenes. The system is based on ARSOM Neural Networks that learn to generate the perception grounded predicates obtained by image sequences. The ARSOM Neural Networks also provide a 3 D estimation of {{the movements of the}} relevant objects in the scene. The vision systems has been employed in two scenarios: the monitoring of a robot arm suitable for space operations, and the surveillance of a EDP center. ...|$|R
40|$|This work {{is focused}} on the {{possible}} applications of Deep Learning in retinal fundus images analysis. Deep Learning is an advanced machine learning technique that is revolutionizing all data-based disciplines with unheard-of performances in signal analysis. In particular <b>Artificial</b> Intelligence, Computer <b>Vision</b> and Image Analysis are benefiting from huge improvement in image and sound classification, segmentation and pattern recognitio...|$|R
40|$|Much recent {{research}} attention {{has focused on}} providing some form of visually meaningful information to blind people through electrical stimulation of {{a component of the}} visual system. Current technology limits the number of perceived points of light (phosphenes) that can be provided to a user and methods are required to optimize the amount of presented information. This paper describes a PDA based <b>artificial</b> human <b>vision</b> simulator, and proposes a method for alerting a user of possible looming obstacles. Experimental results indicate that obstacle alerts can be successfully provided, however with the current simulator components, high-quality lighting and accurate image segmentation is critical for reducing the number of false alerts...|$|R
5000|$|Neurologist Richard Restak explores how Dobelle's {{design has}} shaped {{the future of}} <b>artificial</b> <b>vision</b> in The New Brain: How the Modern Age is Rewiring Your Mind (Rodale Books, 2004) ...|$|E
50|$|The OrCam MyEye is a portable, <b>artificial</b> <b>vision</b> {{device that}} allows the {{visually}} impaired to understand text and identify objects. The device was developed by Israeli-based company OrCam Technologies Limited, and was released as a prototype in September 2013.|$|E
50|$|The {{experience}} on Mob-Lab not only provided {{the ground for}} new ideason computer vision techniques, but the typical problems of the automotive environment were also investigated, creating a strong know-how on the application of <b>artificial</b> <b>vision</b> in the real world.|$|E
40|$|Recent {{research}} on <b>Artificial</b> Human <b>Vision</b> (AHV, or visual prostheses) {{has focused on}} providing visually meaningful information to the blind through electrical stimulation of a visual system component. This paper reports {{on the use of}} a programmable PDA-based AHV simulator which can be used by normally sighted participants. Using three different display types, mobility performance on an indoor artificial mobility course was assessed using Percentage of Preferred Walking Speed (PPWS) and mobility errors. A looming obstacle alert display was not found to assist with mobility performance. Mobility performance increased as participants learned to use the simulation effectively. Posture, head movements and gait were affected by use of the simulation...|$|R
40|$|Includes bibliographical {{references}} (leaves 123 - 129) Support Vector Machines (SVMs) {{are a new}} {{supervised classification}} technique that {{has its roots in}} statistical learning theory. It has gained popularity in fields such as machine <b>vision,</b> <b>artificial</b> intelligence, digital image processing and more recently remote sensing. The three commonly used SVMs include linear, polynomial and radial basis function (i. e. Gaussian) classifiers...|$|R
50|$|In 1985, the McGill Research Centre for Intelligent Machines (McRCIM) {{was formed}} by four {{researchers}} - Martin Levine, Steve Zucker, Pierre Bélanger, and George Zames. Today, it {{is known as the}} Centre for Intelligent Machines, and seeks to advance the state of knowledge in such domains as robotics, automation, <b>artificial</b> intelligence, computer <b>vision,</b> systems and control theory, and speech recognition.|$|R
50|$|Broggi's {{research}} activitiesstarted in {{the early}} ’90s, when very few laboratories worldwide were investigating the applicability of <b>artificial</b> <b>vision</b> on board of moving vehicles. At that time no hardware architecture was able to deliver sufficient processing power to run real-time image processing algorithms.|$|E
50|$|Most initial uses of this {{technology}} are advertising-related, such as shop windows. An interactive holographic screen can be mounted on the shop windows so that passersby can interact with it. Non-interactive holographic screens in shop windows can be coupled with <b>artificial</b> <b>vision</b> software to adapt ads based on the viewer's characteristics (age, sex, etc.).|$|E
50|$|The Manchester Royal Infirmary and Prof Paulo E Stanga {{announced}} on July 22, 2015 {{the first successful}} implantation of Second Sight's Argus II in patients suffering from severe Age Related Macular Degeneration. These results are very impressive as {{it appears that the}} patients integrate the residual vision and the <b>artificial</b> <b>vision.</b> It potentially opens the use of retinal implants to millions of patients suffering from AMD.|$|E
40|$|This {{contribution}} {{addresses the}} incorporation of a module for advanced user interaction into an <b>artificial</b> cognitive <b>vision</b> system to include the human-in-the-loop. Specifically, the document describes a method to automatically generate natural language textual descriptions of meaningful events and behaviors, in a controlled scenario. One {{of the goals of}} the system is to be capable of producing these descriptions in multiple languages. We will introduce some relevant stages of the whole system, and concentrate on the linguistic aspects which have been taken into account to derive final text from conceptual predicates. Some experimental results are provided for the description of simple and complex behaviors of pedestrians in an intercity crosswalk, for Catalan, English, Italian, and Spanis...|$|R
40|$|Part I of {{this paper}} {{describes}} {{some of the new}} functions in the system. The discussion is seasoned here and there with parenthetical code fragments that may be ignored by readers unfamiliar with PLANNER. Part II discussed the scenario evoked in a simple sample copy effort and Part III provides some technical notes helpful to those who wish to use the system. MIT <b>Artificial</b> Intelligence Laboratory <b>Vision</b> Grou...|$|R
50|$|Sweeney joined Philip Morris in 1978 {{directly}} after graduating, {{he began}} work in advanced digital process control, became {{a leader in}} human-machine interface, distributed network-centric control systems, <b>artificial</b> intelligence, machine <b>vision</b> systems and later was the principal technical lead in Digital Marketing Technology and the Identification Technologies R&D effort at Philip Morris USA. He has obtained at least 18 patents in his field while working at Philip Morris.|$|R
5000|$|In Susanne D. Coates' Neural Interfacing: Forging the Human Machine Connection (Synthesis Lectures on Biomedical Engineering), {{she claims}} [...] "with {{the passing of}} Dobelle in 2004, 30 years of work {{developing}} the [...] "Dobelle <b>Artificial</b> <b>Vision</b> System" [...] came to a halt. There are a few groups who continue to experiment with cortical vision implants 51 but no system like Dobelle's is presently available" [...] (40).|$|E
50|$|In October 2005 a second-generation TerraMax {{was one of}} five {{vehicles}} to complete the 2005 DARPA Grand Challenge 132-mile desert course. Unofficial run time was 12 hours and 51 minutes, this outside of the 10-hour limit {{to qualify for the}} $2 million prize money. The 2005 Team TerraMax consisted of Oshkosh Truck, Rockwell Collins, University of Parma's <b>Artificial</b> <b>Vision</b> and Intelligent Systems Laboratory (VisLab) and several financial sponsors.|$|E
50|$|In {{computer}} science, computation offloading {{refers to}} the transfer of certain computing tasks to an external platform, such as a cluster, grid, or a cloud. Offloading may be necessary due to hardware limitations of a computer system handling a particular task on its own. These intensive computing tasks {{may be used in}} artificial intelligence, <b>artificial</b> <b>vision</b> and object tracking, or computational decision making. Computation offloading may also be used to save energy.|$|E
40|$|Keywords:Robot navigation, Potential field, Inverse {{perspective}} transformation. Abstract. In {{this paper}} a navigation system for autonomous mobile robots that move into unknown environments based on artificial potential field is presented. The robot {{moves to a}} predefined target point while detects and maps every encounter object using its <b>artificial</b> monocular <b>vision</b> system based on intrinsic camera parameters. During navigation, every obstacle {{is associated with a}} repulsive field depending on the distance and relative position to the robot, while the target point has an attractive field. Combining those values of potential field defines the direction of the next step of the robot. The results reported are showing the behavior of the method in three scenarios, avoiding obstacles, going through a narrow corridor and escaping from a minimum local trap...|$|R
40|$|Animate vision systems, {{biological}} or robotic, employ gaze control systems to acquire, fixate, and stabilize images. Our {{goal is to}} guild robust gaze control behaviour from cooperating lower-level visual reflexes. Predictive control strategies can cope with time delayed, multi-rate, and interacting controls. Solutions are explored through simulation incorporating ten primitive gaze control capabilities, more or less comparable to subsystems in primate gaze and head control. Versions {{of several of the}} subsystems have been implemented on a binocular robot. Smith prediction is the basic paradigm, using kinematic simulation of the agent and optimal filtering to predict world state. One of the goals of <b>artificial</b> animate <b>vision</b> [2, 3] is to design a systems architecture in which multiple objectives (such as moving and observing) can proceed in parallel. One commo...|$|R
40|$|Abstract — Facial Expression Recognition (FER) is {{a rapidly}} growing and ever green {{research}} field {{in the area of}} Computer <b>Vision,</b> <b>Artificial</b> Intelligent and Automation. There are many application which uses Facial Expression to evaluate human nature, feelings, judgment, opinion. Recognizing Human Facial Expression is not a simple task because of some circumstances due to illumination, facial occlusions, face color/shape etc. In these paper, we present some method/techniques such as Principal Component Analysis (PCA), Linear Discriminate Analysis (LDA) ...|$|R
