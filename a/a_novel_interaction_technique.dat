55|10000|Public
30|$|Kray, C., et al., Bridging the {{gap between}} the Kodak and the Flickr generations: <b>A</b> <b>novel</b> <b>interaction</b> <b>technique</b> for {{collocated}} photo sharing. Int. J. Hum.-Comput. Stud., 2009. 67 (12): p. 1060 – 1072.|$|E
40|$|Huazhong Univ Sci & Technol, Natl Sci Fdn China, Int Federat Informat Proc, IEEE Comp Soc, Lecture Notes Comp Sci SpringerThis paper {{presents}} <b>a</b> <b>novel</b> <b>interaction</b> <b>technique</b> {{with multiple}} large displays in smart space. We call it D 2 LP, short for Drag and Drop by Laser Pointer, where {{a specially designed}} laser pointer uPen is a handheld interactive device for users...|$|E
40|$|We have {{implemented}} an augmented reality videoconferencing system that inserts virtual graphics overlays into the live video stream of remote conference participants. The virtual objects are manipulated using <b>a</b> <b>novel</b> <b>interaction</b> <b>technique</b> cascading bimanual tangible interaction and eye tracking. User studies prove that our user interface enriches remote collaboration by offering hitherto unexplored ways for collaborative object manipulation such as gaze controlled raypicking of remote physical and virtual objects...|$|E
40|$|The present {{steady and}} {{unsteady}} quasi- 1 D internal supersonic flowfield calculations employs <b>a</b> <b>novel</b> viscous-inviscid <b>interaction</b> <b>technique</b> directly coupling and simultaneously solving the inviscid and viscous equations. The coupled system is numerically solved using a two-stage Runge-Kutta scheme with first-order one-sided spatial differencing. Simple supersonic internal flow test cases are computed {{to demonstrate the}} capabilities of the computational procedure...|$|R
40|$|MT (Multi-touch) screens are {{platforms}} {{that enhance}} multiuser collaboration. In this work, we underline {{the need for}} <b>novel</b> <b>interaction</b> <b>techniques</b> and toolkits that allow multi-user collaboration on larger MT surfaces. We present ChordiAction toolkit that makes use of <b>a</b> <b>novel</b> chorded <b>interaction</b> <b>technique</b> allowing simultaneous multi-user interaction on scalable MT applications. We describe the design, the architecture and some efficient customizations practices of the toolkit and show {{how it can be}} effectively embedded in an application for multiuser interaction. As a proof of Copyright is held by the author/owner(s) ...|$|R
40|$|Abstract: This work {{introduces}} <b>a</b> <b>novel</b> information visualization {{technique for}} mobile devices through Augmented Reality (AR). A painting boundary detector and a features extraction modules {{have been implemented}} to compute paintings signatures. The computed signatures are matched using a linear weighted combination of the extracted features. The detected boundaries and the features are exploited to compute the homography transformations. The homography transformations are used to introduce <b>a</b> <b>novel</b> user <b>interaction</b> <b>technique</b> for AR. Three different user interfaces have been evaluated using standard usability methods. ...|$|R
40|$|Whilst {{techniques}} for narrative generation and agent behaviour have made {{significant progress in}} recent years, natural language processing remains a bottleneck hampering the scalability of Interactive Storytelling systems. This demonstrator introduces <b>a</b> <b>novel</b> <b>interaction</b> <b>technique</b> based solely on emotional speech recognition. It allows the user to use speech to interact with virtual actors without any constraints on style or expressivity, by mapping the recognised emotional categories to narrative situations and virtual characters feelings...|$|E
40|$|In {{this paper}} we {{describe}} <b>a</b> <b>novel</b> <b>interaction</b> <b>technique</b> that {{allows users to}} access and share rich multi-media content via a large, situated public display and their own Bluetooth enabled camera phone. The proposed system differs from other solutions in {{that it does not}} require any client software to be installed on the user's device. We believe that our solution provides a practical and holistic approach for device-based interactions with a public multi-media information system...|$|E
40|$|We present <b>a</b> <b>novel</b> <b>interaction</b> <b>technique</b> called Immersive Navidget for {{navigation}} in immersive virtual environments (VE), see Figure 1. This technique, {{based on}} Navidget, allows fast and easy 3 D camera positioning from simple controls. In this paper, {{we focus on}} the technical issues that are induced by the VR setups and we propose solutions to adapt Navidget to the immersive context. We show that this new approach has many advantages for navigation in immersive VEs...|$|E
40|$|In {{this paper}} we {{demonstrate}} Orbits, <b>a</b> <b>novel</b> gaze <b>interaction</b> <b>technique</b> {{that accounts for}} both the reduced size of smart watch displays and the hands-free nature of conventional watches. Orbits combines graphical controls that display one or multiple targets moving on a circular path, with input that is provided by users as they follow any of the targets briefly with their eyes. This gaze input triggers the functionality associated with the followed target – be it answering a call, playing a song or managing multiple notifications. Author Keywords Eye tracking; smart watches; small devices; small displays; pursuits; gaze interaction; gaze input; wearable computing. ACM Classification Keywords H. 5. m. Information interfaces and presentation (e. g. ...|$|R
40|$|This paper {{introduces}} <b>a</b> <b>novel</b> kinesthetic <b>interaction</b> <b>technique</b> for interactive floors. The <b>interaction</b> <b>techniques</b> utilize vision-based limb tracking on {{an interactive}} floor – a 12 m² glass surface with bottom projection. The kinesthetic <b>interaction</b> <b>technique</b> {{has been developed}} for an interactive floor implemented in a school square. The paper discusses the kinesthetic <b>interaction</b> <b>technique</b> and its potentials {{in the domain of}} learning applications: Kinesthetic interaction supports body-kinesthetic learning as argued in the learning literature. Kinesthetic interaction is fun and motivating thus encourages children to explore and learn. Kinesthetic interaction on large display surfaces supports collaborative, co-located play and learning through communication and negotiation among the participants. Finally, the paper discusses prospects and challenges in development of kinesthetic interaction for interactive floors...|$|R
40|$|We {{present a}} system for {{creating}} appealing illustrative cutaway renderings. This system bases on simple sketch-based interfaces and stylized rendering techniques {{for the study of}} elaborate 3 D models. Since interactive visualization technology found its way to the general public, there is <b>a</b> demand for <b>novel</b> <b>interaction</b> <b>techniques</b> that allow easy exploration of the displayed illustrations. Hence, our system lets users create individual cutaway views to focus on hidden objects. At the same time, important contextual information is emphasized by illustrative rendering techniques...|$|R
40|$|This {{paper will}} {{describe}} <b>a</b> <b>novel</b> <b>interaction</b> <b>technique</b> that allows mobile phone users {{to create and}} share contextualised media packages between their personal, BlueTooth enabled camera phones, and situated public displays. Unlike other solutions to this problem, the one {{presented in this paper}} does not require any specialist software or hardware on the user 2 ̆ 019 s handset. We believe this technique has the potential to revolutionise how people donate and retrieve digital media files without incurring any direct cost...|$|E
40|$|We {{present the}} design and {{implementation}} of mailVis, an interactive visual interface for email boxes that facilitates re-finding of emails. Email re-finding tasks can be challenging, involving scanning of many emails and modifying the query as the search progresses. We designed mailVis for such tasks in which the user would benefit from having memory clues and multiple options to direct the search. During the design process, we devised <b>a</b> <b>novel</b> <b>interaction</b> <b>technique,</b> filter swipe, that combines filtering and selection into one action for rapidly skimming individual items in a data set...|$|E
40|$|This TechNote {{introduces}} <b>a</b> <b>novel</b> <b>interaction</b> <b>technique</b> {{for small}} screen {{devices such as}} palmtop computers or hand-held electric devices, including pagers and cellular phones. Our proposed method uses the tilt of the device itself as input. Using both tilt and buttons, {{it is possible to}} build several interaction techniques ranging from menus and scroll bars, to more complicated examples such as a map browsing system and a 3 D object viewer. During operation, only one hand is required to both hold and control the device. This feature is especially useful for field workers...|$|E
40|$|INSPECT is <b>a</b> <b>novel</b> set of <b>interaction</b> <b>techniques</b> for 3 D object ma-nipulation using a rotation-only tracked touch panel. Motivated by the {{applicability}} of the techniques on smartphones, we explore this design space by introducing a way to map the available degrees of freedom and discuss the design decisions that were made. We subjected the techniques to a comparative user study in which IN-SPECT was preferred by the users overall...|$|R
40|$|We {{designed}} <b>a</b> <b>novel</b> {{and simple}} <b>interaction</b> <b>technique</b> for handheld devices {{by using a}} stylus. A stylus is ordinarily utilized {{as a tool for}} tapping on a touch-sensitive screen. We employ the physical movement of a stylus as input. Both ro-tation and slide movement of stylus where the inside of the stylus holder can be used to adjust two parameters simulta-neously. Below we describe the merits and applications of RodDirect interaction...|$|R
40|$|This paper {{explores the}} impact of Enforced Collaborative Agreement (ECA) on teenagers’ game play experience. A child-centered {{approach}} involving methods such as Fun toolkit and Children’s IMI were adapted to study teenagers’ game enjoyment. Studies were conducted on 11 - 16 yrs olds who interacted with a digital game that enforced collaboration in a co-located setting using <b>a</b> range of <b>novel</b> <b>interaction</b> <b>techniques.</b> The key contribution of the paper is an insight into the effect of ECA on teenagers’ gameplay experience which could inform interaction designers {{in the creation of}} products for the user group...|$|R
40|$|Abstract. This paper {{presents}} <b>a</b> <b>novel</b> <b>interaction</b> <b>technique</b> called Follow my Finger (FmF) for navigation in 3 D virtual environments using a 2 D interactive view on a table-top device. FmF {{consists in}} moving a camera icon {{that represents the}} 2 D subjective position and orientation of a viewpoint in the 3 D world. Planar, tactile, and direct manipulation of the camera icon facilitates navigation in the 3 D environment. From the user’s perspective the camera icon follows her/his finger trajectory to interactively modify the horizontal location, inclination, and orientation of the 3 D point of view...|$|E
40|$|In {{this paper}} we present <b>a</b> <b>novel</b> <b>interaction</b> <b>technique</b> {{that helps to}} make textual {{information}} more accessible to those with low or no textual literacy skills. AudioCanvas allows cameraphone users to interact directly with their own photos of printed media to receive audio feedback or narration. The use of a remote telephone-based service also allows our design to be used over a standard phone line, removing the need for data connections, which can be problematic in developing regions. We show {{the value of the}} technique via user evaluations in both a rural Indian village and a South African township...|$|E
40|$|This paper {{introduces}} <b>a</b> <b>novel</b> <b>interaction</b> <b>technique</b> for handheld mobile devices {{which enables}} the user interface {{to be controlled}} by the motion of the user’s hand. A feature-based approach is proposed for global motion estimation that exploits gradient measures for both feature selection and feature motion uncertainty analysis. A voting-based scheme is presented for outlier removal. A Kalman filter is applied for smoothing motion trajectories. A fixed-point implementation of the method was developed {{due to the lack of}} floating-point hardware. Experiments testify the effectiveness of the approach on a camera-enabled mobile phone. Key words: user interfaces, handheld devices, global motion estimation...|$|E
40|$|In {{this paper}} we debut Photohelix, <b>a</b> <b>novel</b> {{interactive}} system for browsing, sorting and sharing digital images. We present our design rationale {{for such a}} system and introduce Photohelix as a prototype application featuring <b>a</b> <b>novel</b> visualization and <b>interaction</b> <b>technique</b> for media browsing on interactive tabletops. We conducted a user study in order to evaluate and verify our design. We will present our findings in this paper and discuss further implications for future development of such systems derived from our experiences with Photohelix...|$|R
40|$|Abstract. This paper {{presents}} <b>a</b> <b>novel</b> tangible <b>interaction</b> <b>technique</b> leveraging Near Field Communication (NFC) enabled Magnetic Cards {{to empower}} elderly end-users in programming their pervasive computing environment. Following a user-centric design approach through cultural probes, we have explored the design space of possible programming opportunities for elderly users. Accordingly {{we have identified}} <b>interaction</b> <b>techniques</b> and candidate artefacts that could offer this user group a seamless programming experience for augmenting their ambient environment with software driven personalized behavior. Three aspects of programming- behavior generation, modification and (de) activation are addressed using two tangible user interfaces- i) NFC cards for smart behavior creation and modification and ii) a digital memo board as a placeholder for (de) activation of intelligent behavior. A qualitative feasibility study suggests that the proposed approach is simple, comprehensive and {{has the potential to}} be easily incorporated in the everyday routines of the elderly end-users. ...|$|R
40|$|We {{present a}} device concept and a {{prototype}} of a future mobile device. By featuring a rollable display, its display size and its form factor can be dynamically changed. Moreover, we investigate how physical resizing of the display {{can be used as}} an input technique for interacting with digital contents and present <b>a</b> set of <b>novel</b> <b>interaction</b> <b>techniques.</b> Evaluation results show that physical resizing of the display can improve the way we interact with digital contents on mobile devices. Author Keywords Tangible interaction, mobile device, rollable display, screen, scroll, resizing, input technique. ACM Classification Keywords H 5. 2. User interfaces: Graphical user interfaces (GUI) ...|$|R
40|$|We {{introduce}} the Expandable Grid, <b>a</b> <b>novel</b> <b>interaction</b> <b>technique</b> for creating, editing, and viewing {{many types of}} security policies. Security policies, such as file permissions policies, have traditionally been displayed and edited in user interfaces based {{on a list of}} rules, each of which can only be viewed or edited in isolation. These list-of-rules interfaces cause problems for users when multiple rules interact, because the interfaces have no means of conveying the interactions amongst rules to users. Instead, users are left to figure out these rule interactions themselves. An Expandable Grid is an interactive matrix visualization designed to address the problems that list-of-rules interfaces have in conveying policie...|$|E
40|$|In this paper, {{we first}} {{describe}} a formative empirical study {{to inform the}} design of CSCW tools to support idea finding in co-located groups. Groups of students worked on creative problems with mapping and whiteboard tools in different work modes. Concluding {{from the results of}} the study, requirements are derived. A suite of tools that are informed by these requirements is presented along with typical scenarios of their usage. The suite consists of three software components covering a Mind-Mapping system (BeachMap), <b>a</b> <b>novel</b> <b>interaction</b> <b>technique</b> for successive bottom-up structuring of ideas (MagNets), and a PDA tool for asynchronous idea generation "on the road" (PalmBeach) ...|$|E
40|$|In this paper, {{we present}} <b>a</b> <b>novel</b> <b>interaction</b> <b>technique</b> – {{combining}} mobile projection and visible, fiducial marker based information display. We vision {{it to be}} suitable for small groups e. g. for narrative playful experiences and guided on places, where physical tags would be disturbing. This interaction technique, where one person (guide) is projecting a marker and other users can read it with their mobile devices, enables in situ information delivery while the guide can control {{the dynamics of the}} situation. We present an example use case of using the interaction technique on a guided tour, and a preliminary results from the user evaluatio...|$|E
40|$|Natural {{forms of}} {{interaction}} have evolved for personal devices that we carry with us (mobiles) {{as well as}} for shared interactive displays around us (surfaces) but interaction across the two remains cumbersome in practice. We propose <b>a</b> <b>novel</b> crossdevice <b>interaction</b> style for mobiles and surfaces that uses the mobile for tangible input on the surface in a stylus-like fashion. Building on the direct manipulation that we can perform on either device, it facilitates fluid and seamless interaction spanning across device boundaries. We provide a characterization of the combined interaction style in terms of input, output, and contextual attributes, and demonstrate its versatility by implementation of <b>a</b> range of <b>novel</b> <b>interaction</b> <b>techniques</b> for mobile devices on interactive surfaces. Author Keywords Interactive tabletops, surface computing, mobile phones, personal devices, <b>interaction</b> <b>techniques...</b>|$|R
40|$|In {{this paper}} we explore human-computer {{interaction}} for carving, building upon our previous work with the FreeD digital sculpting device. We contribute a new tool design (FreeD V 2), with <b>a</b> <b>novel</b> set of <b>interaction</b> <b>techniques</b> for the fabrication of static models: personalized toolpaths, manual overriding, and physical merging of virtual models. We also present techniques for fabricating dynamic models, which may be altered directly or parametrically during fabrication. We demonstrate a semi-autonomous operation and evaluate {{the performance of the}} tool. We end by discussing synergistic cooperation between human and machine to ensure accuracy while preserving the expressiveness of manual practice...|$|R
30|$|This work {{builds on}} the work of Katzakis et al. [10] on 3 D {{translation}} using a tracked touch-panel, motivated by its applicability on smartphones. Plane-casting offers isotonic position control without using any external position trackers, save for the orientation sensors in the device. We extend plane-casting and introduce INSPECT, <b>a</b> set of <b>novel</b> <b>interaction</b> <b>techniques</b> for off-screen virtual object manipulation using a smartphone. INSPECT stands for INdirect Six-DOF PlanE Control Technique, and it was designed for the purpose of inspecting a 3 D object. We demonstrate that by using INSPECT it is possible, with a low-cost mode change, to perform 6 -DOF virtual object selection and manipulation using a 3 -DOF orientation-tracked touch panel and the 2 -DOF per finger from the touch points.|$|R
40|$|Cursive: <b>A</b> <b>novel</b> <b>interaction</b> <b>technique</b> for {{controlling}} expressive avatar gesture We are developing an interaction technique for rich nonverbal communication through an avatar. By writing a single letter on a pen tablet device, a user can express their ideas or intentions, nonverbally, using their avatar body. Our system solves the difficult problem {{of controlling the}} movements of a highly articulated, 3 D avatar model using a common input device {{within the context of}} an office environment. We believe that writing is a richly expressive and natural means {{for controlling}} expressive avatar gesture. KEYWORDS:Avatars, computer-mediated communication, virtual environments, gesture, novel interaction technique, pen gesture, nonverbal...|$|E
40|$|International audienceThis article {{introduces}} the OrthoZoom Scroller, <b>a</b> <b>novel</b> <b>interaction</b> <b>technique</b> that improves target acquisition in very large one-dimensional spaces. The OrthoZoom Scroller requires only a mouse to perform panning and zooming in a 1 D space. Panning is performed along the slider dimension while zooming is performed along the orthogonal one. We present a controlled experiment {{showing that the}} OrthoZoom Scroller is about {{twice as fast as}} Speed Dependant Automatic Zooming to perform pointing tasks whose index of difficulty is in the 10 - 30 bits range. We also present an application to browse large textual documents with the OrthoZoom Scroller that uses semantic zooming and snapping on the structure...|$|E
30|$|INSPECT is <b>a</b> <b>novel</b> <b>interaction</b> <b>technique</b> for 3 D object {{manipulation}} using a rotation-only tracked touch panel. Motivated by {{the applicability}} of the technique on smartphones, we explore this design space by introducing a way to map the available degrees of freedom and discuss the design decisions that were made. We subjected INSPECT to a formal user study against a baseline wand interaction technique using a Polhemus tracker. Results show that INSPECT is 12 % faster in a 3 D translation task {{while at the same time}} being 40 % more accurate. INSPECT also performed similar to the wand at a 3 D rotation task and was preferred by the users overall.|$|E
40|$|This paper explores using non-linguistic vocalization as an {{additional}} modality to augment digital pen input on a tablet computer. We investigated this through <b>a</b> set of <b>novel</b> <b>interaction</b> <b>techniques</b> and <b>a</b> feasibility study. Typically, digital pen users control one or two parameters using stylus position and sometimes pen pressure. However, in many scenarios the user can benefit from the ability to continuously vary additional parameters. Non-linguistic vocalizations, such as vowel sounds, variation of pitch, or control of loudness {{have the potential to}} provide fluid continuous input concurrently with pen interaction. We present a set of <b>interaction</b> <b>techniques</b> that leverage the combination of voice and pen input when performing both creative drawing and object manipulation tasks. Our feasibility evaluation suggests that with little training people can use nonlinguistic vocalization to productively augment digital pen interaction...|$|R
40|$|We {{introduce}} Orbits, <b>a</b> <b>novel</b> gaze <b>interaction</b> <b>technique</b> {{that enables}} hands-free input on smart watches. The technique relies on moving controls to leverage the smooth pursuit {{movements of the}} eyes and detect whether and at which control the user is looking at. In Orbits, controls include targets that move in a circular trajectory {{in the face of}} the watch, and can be selected by following the desired one for a small amount of time. We conducted two user studies to assess the technique’s recognition and robustness, which demonstrated how Orbits is robust against false positives triggered by natural eye movements and how it presents a hands-free, high accuracy way of interacting with smart watches using off-the-shelf devices. Finally, we developed three example interfaces built with Orbits: a music player, a notifications face plate and a missed call menu. Despite relying on moving controls – very unusual in current HCI interfaces – these were generally well received by participants in a third and final study. Author Keywords Eye tracking; smart watches; small devices; small displays; pursuits; gaze interaction; gaze input; wearable computing. ACM Classification Keywords H. 5. m. Information interfaces and presentation (e. g., HCI) ...|$|R
40|$|We present Magic Finger, a small device worn on the fingertip, which {{supports}} always-available input. Magic Finger inverts the typical {{relationship between the}} finger and an interactive surface: with Magic Finger, we instrument the user’s finger itself, rather than the surface it is touching. Magic Finger senses touch through an optical mouse sensor, enabling any surface {{to act as a}} touch screen. Magic Finger also senses texture through a micro RGB camera, allowing contextual actions to be carried out based on the particular surface being touched. A technical evaluation shows that Magic Finger can accurately sense 22 textures with an accuracy of 98. 9 %. We explore the interaction design space enabled by Magic Finger, and implement <b>a</b> number of <b>novel</b> <b>interaction</b> <b>techniques</b> that leverage its unique capabilities. ACM Classification: H 5. 2 [Information interfaces an...|$|R
