62|10000|Public
3000|$|... eThe Hesmer and Lemeshow (H & L) {{goodness}} of fit is shown in Table  3. Note that in the H & L {{goodness of}} fit test a non-significant p value indicates <b>a</b> <b>better</b> <b>model</b> <b>fit.</b>|$|E
30|$|QICC is the {{corrected}} {{version of}} the quasi-likelihood under the independence criterion, which penalizes for model complexity. QICC {{can be used to}} choose the best model and, therefore, the best subset of predictors. A smaller QICC value indicates <b>a</b> <b>better</b> <b>model</b> <b>fit.</b>|$|E
30|$|The {{quality of}} fit for the models using {{convergence}} adoption rate as the response variable (model 1 in Table  2, 7, 8, and 9) is low. Other factors or non-linear structures could provide <b>a</b> <b>better</b> <b>model</b> <b>fit.</b> However, in here, we have focused on specific models, and {{the exploration of the}} best fitted models {{is beyond the scope of}} the study.|$|E
30|$|Hypothesis (1), that CBA {{displays}} <b>a</b> significantly <b>better</b> <b>model</b> <b>fit</b> than PBA, is rejected.|$|R
40|$|This {{study was}} {{conducted}} to analyze and quantify the impact of weather factors on road accident severity, based on Maryland accident data during 2007 - 2010. In order to find <b>a</b> <b>better</b> <b>model</b> <b>fitted</b> related variables, three candidate models multinomial logit (MNL), ordered probit logit (OP), and neural networks were chosen to examine in SAS. The results showed that the Multilayer Perceptron Model in neural networks performed the best and is the accident severity model of choice. During the model construction, eight factors related to weather condition were considered. They were: air temperature, average wind speed, total precipitation in the past 24 hours, visibility, slight, moderate, heavy precipitation and relative humidity. Based on the comparison criteria, we concluded that MNL regression is more interpretive than OP and Neural Networks models. All factors except visibility and heavy precipitation had significant impact on accident severity when considering the data from the entire Maryland highway system. Using MNL, a data subset with accident records only in a section of US route 50 was examined. After excluding the impact factors other than weather, a narrow significant variable set was obtained...|$|R
40|$|The {{validity}} of inferences based on achievement test scores {{is dependent on}} the amount of effort that examinees put forth while taking the test. With low-stakes tests, for which this problem is particularly prevalent, there is a consequent need for psychometric models that can take into account different levels of examinee effort. This article introduces the effort-moderated IRT model, which incorporates item response time into proficiency estimation and item parameter estimation. In two studies of the effort-moderated model when rapid guessing (i. e., reflecting low examinee effort) was present, one based on real data and the other on simulated data, the effort-moderated <b>model</b> performed <b>better</b> than the standard 3 PL model. Specifically, {{it was found that the}} effort-moderated <b>model</b> (<b>a)</b> showed <b>better</b> <b>model</b> <b>fit,</b> (b) yielded more accurate item parameter estimates, (c) more accurately estimated test information, and (d) yielded proficiency estimates with higher convergent validity. Whenever we administer an achievement test to an examinee, we tacitly assum...|$|R
40|$|This article generalizes {{a multivariate}} skew-elliptical {{distribution}} and describes its many interesting properties. The univariate {{version of the}} new distribution is compared with two other currently used distributions. The use of the new distribution is illustrated with a real data example suitable for regression modelling. The new model provides <b>a</b> <b>better</b> <b>model</b> <b>fit</b> than its two rivals as evaluated by some suitable Bayesian model selection criteria...|$|E
40|$|Refitting {{the penguin}} model to {{adjusted}} data {{taking into consideration}} possible undercounting of moulters in recent years, {{we have been able}} to obtain <b>a</b> <b>better</b> <b>model</b> <b>fit.</b> Also, analysis indicates that the depletion of penguins (expressed as abundance in 2008 relative to 2002) is about 5 % less than previously estimated at the colony assumed to be the origin of the extra moulters at Stony Point. The calculated model likelihoods suggest that these birds are more likely to come from Dassen Island...|$|E
30|$|The BMA weight can be {{interpreted}} as the weight of the evidence that model s[*]is true model given a set of S[*]models. For the case {{in which there is no}} information about prior probabilities, we can let p(S[*]=[*]s) be equal for all candidate models (1 /S), indicating no prior preference for any of the models (Jackson et al. 2009; Pramana et al. 2012). The model with the largest BMA weight will be considered as the best model. Therefore, p(S[*]=[*]s[*]∣[*]D) is also an approximation to the posterior probability of the model s[*]being correct (Schwarz 1978). A smaller BIC value indicates <b>a</b> <b>better</b> <b>model</b> <b>fit,</b> accounting for model complexity.|$|E
3000|$|Akaike and Bayesian {{information}} criteria (AIC and BIC) {{are further}} {{used to determine}} the lag structure. AIC and BIC provide estimates of the information lost when a given model is used to represent the process that generates a given dataset. Smaller AIC and BIC values indicate <b>a</b> <b>better</b> relative <b>model</b> <b>fit</b> to the data. Due to the extreme size (and computational burden) of a 61 -location VAR model, AICs and BICs are calculated for single-location VAR models. A single-location VAR model only has three response variables, as opposed to 183 for a 61 -location VAR model. The single-location models are estimated using two years of hourly weather data. The lag structures that are estimated, which are listed in Table  4, are VAR(24), VAR(48), VAR(72), VAR(96), VAR(120), VAR(168), VAR(1 - 24, [...] 48, [...] 72, [...] 96, [...] 120, [...] 144, [...] 168). Table  4 summarizes AIC and BIC values of these VAR models using weather data from Los Angeles, CA.|$|R
40|$|This {{represents}} {{the first stage}} of “research in progress ” into the construct definition and validation of the mental toughness construct. The study evaluated the construct validity of responses to Loehr’s (1986) mental toughness test, the Psychological Performance Inventory (PPI), by 263 student-athletes from an elite sports high school. As confirmatory factor analysis (CFA) yielded poor <b>model</b> <b>fit</b> and an improper solution for the a priori model, exploratory factor analysis was carried out using all the original PPI items. Item deletion and exploration of three through to ten alternative factor structures yielded a five-factor <b>model</b> that <b>fitted</b> the data well. Whereas the alternative structure yielded <b>a</b> much <b>better</b> <b>model</b> <b>fit</b> than the original PPI structure, further analyses showed that a variety of key correlates of mental toughness were more strongly correlated with the factors based on the original structure than factors based on the alternative structure. In conclusion, neither the original PPI nor the subset of PPI items in the better-fitting alternative model were sound measures of mental toughness, indicating that a good fit is a necessary but not sufficient condition for construct validation. Good instrumentation must be strong in terms conceptual/theoretical considerations, psychometric properties, and relationships to key correlates hypothesised t...|$|R
40|$|The {{purpose of}} this thesis has been to {{estimate}} the New Keynesian Phillips curve relation using Norwegian data, and more precisely using survey expectations as instruments for the expected inflation term in the NPC {{to see how this}} would influence the results. As a comparison to the survey estimates I have estimated a replication of the Galí and Gertler (1999) study. The estimations using both survey expectations and the Galí and Gertler instruments turned out to be significant, and with the size and sign of the coefficients as expected. Based on my estimation the Galí and Gertler instruments provide <b>a</b> <b>better</b> <b>fit</b> <b>model</b> of the NPC than using survey expectations, however both methods are valid to estimate the NPC...|$|R
40|$|This paper {{compared}} {{two versions}} of technology acceptance model (TAM) in understanding the determinants of user intention to use wireless technology in the workplace. The first model is derived from original TAM that includes perceived usefulness, perceived ease of use, attitude and behavioral intention, while the alternative model is a parsimonious version in which the attitude was taken out. The results indicated that TAM, either original or parsimonious, is successful in explaining user intention to use wireless technology in organizations. In addition, the parsimonious model showed <b>a</b> <b>better</b> <b>model</b> <b>fit</b> {{than that of the}} original model. (c) 2010 Elsevier B. V. All rights reserved...|$|E
30|$|For {{the factor}} of trustworthiness, the {{modification}} indices indicated a covariance between error term of PP and error term of IQ. Connecting these two error terms gave <b>a</b> <b>better</b> <b>model</b> <b>fit</b> without changing anymore. The modified model showed 2.098 normal Chi square (P value: 0.078) indicating good model fit. The fit Indies of GFI (0.996), AGFI (0.986), CFI (0.996), NFI (0.993), and TLI (0.991) {{were more than}} 0.9. Furthermore, {{root mean square error}} of approximation (RMSEA) was 0.035 and root mean square residual (RMR) was 0.007, which both RMSEA and RMR values should closer to zero for better fit a model (Hair et al. 2006). Consequently, modified trustworthiness model can be used for the proposed final model.|$|E
30|$|Model {{selection}} was performed {{based on the}} Dias guidelines for evaluating linear models. Dbar indicates the posterior mean of the residual deviance, pD indicates the effective number of parameters (leverage), and DIC indicates the “deviance information criterion”. Lower Dbar and DIC values indicate <b>a</b> <b>better</b> <b>model</b> <b>fit.</b> Differences between models of less than 3 – 5 were not considered significant. The models were run for 150, 000 iterations, and convergence was assessed using the Brooks–Gelman–Rubin diagnostic. We used a technique known as “back calculation” to evaluate consistency in {{the findings of the}} network meta-analysis based on direct versus indirect evidence. During this process, three types of models were estimated: unrelated study effects, unrelated mean effects, and consistency.|$|E
40|$|Distributed {{source coding}} {{principles}} have been recently applied to video coding {{in order to}} achieve a flexible distribution of the complexity burden between the encoder and the decoder. In this paper we elaborate on a pixel based Wyner-Ziv video codec that shifts all the complexity of the motion estimation phase to the decoder, thus achieving light encoding. In the literature, the statistics of correlation noise between the frame to be encoded and the motion-compensated side information available at the decoder is modeled as a Laplacian distribution. In this paper we elaborate on this topic and we show that <b>a</b> <b>better</b> <b>model</b> can be <b>fitted,</b> achieving a substantial coding efficiency gain. Moreover we discuss the effect of using a side information computed either from perfectly reconstructed (lossless) or from quantized neighboring frames. ...|$|R
40|$|The {{main study}} {{objective}} was to develop robust processing and analysis techniques to facilitate the use of small-footprint lidar data for estimating plot-level tree height by measuring individual trees identifiable on the three-dimensional lidar surface. Lidar processing techniques included data fusion with multispectral optical data and local filtering with both square and circular windows of variable size. The lidar system {{used for this study}} produced an average footprint of 0. 65 m and an average distance between laser shots of 0. 7 m. The lidar data set was acquired over deciduous and conifer-ous stands with settings typical of the southeastern United States. The lidar-derived tree measurements were used with regression models and cross-validation to estimate tree height on 0. 017 -ha plots. For the pine plots, lidar measurements explained 97 percent of the variance associated with the mean height of dominant trees. For deciduous plots, regres-sion models explained 79 percent of the mean height variance for dominant trees. Filtering for local maximum with circular windows gave <b>better</b> fitting <b>models</b> for pines, while for decidu-ous trees, filtering with square windows provided <b>a</b> slightly <b>better</b> <b>model</b> <b>fit.</b> Using lidar and optical data fusion to differ-entiate between forest types provided better results for estimating average plot height for pines. Estimating tree height for deciduous plots gave superior results without calibrating the search window size based on forest type...|$|R
40|$|The {{relative}} annual {{basal area}} increment of mature Norway spruce trees in south-central Sweden during 9 years {{was used as}} the response variable and analysed in relation to ozone exposure, meteorological conditions, soil moisture and stand characteristics. The method used was a modified multiple regression analysis, allowing for dependencies between observations from the same plots. The selected statistical model explained 91 % of the variation in the annual relative basal area increment. The strongest explanatory variable was the stand basal area, followed by the temperature sum and the soil moisture index. After these three variables, the ozone index was the most important variable. Its effect was negative and highly significant. The average daylight ozone concentration gave <b>a</b> slightly <b>better</b> <b>model</b> <b>fit</b> as compared to the accumulated exposure during daylight hours above a threshold of 40 nmol mol&# 8722; 1 (AOT 40). The predicted effect of ozone within the range of annual ozone exposures found in this study (1800  8700 nmol mol&# 8722; 1 h AOT 40), was in absolute values a 0. 8 % decrease in the relative annual basal area increment. This could be compared with the mean relative annual increment measured during the study period of 4. 6 %. Our results provide statistical evidence that ground level ozone can {{have a negative impact on}} the stem growth of mature Norway spruce trees under field conditions...|$|R
40|$|Infectious disease {{data from}} {{surveillance}} systems are typically available as multivariate times series of disease counts in specific administrative geographical regions. Such databases are useful resources to infer temporal and spatiotemporal transmission parameters {{to better understand}} and predict disease spread. However, seasonal variation in disease notification is a common feature of surveillance data {{and needs to be}} taken into account appropriately. In this paper, we extend a time series model for spatiotemporal surveillance counts to incorporate seasonal variation in three distinct components. A simulation study confirms that the different types of seasonality are identifiable and that a predictive approach suggested for model selection performs well. Application to surveillance data on influenza in Southern Germany reveals <b>a</b> <b>better</b> <b>model</b> <b>fit</b> and improved one-step-ahead predictions if all three components allow for seasonal variation...|$|E
40|$|Farmland can confer {{significant}} {{public good}} benefits to society aside from {{its role in}} agricultural production. In this article, we investigate preferences of rural residents {{for the use of}} farmland as a recreational resource. In particular, we use a choice experiment to determine preferences for the development of farmland walking trails. Our modelling approach uses a series of mixed logit models {{to assess the impact of}} alternative distributional assumptions for the cost coefficient on the welfare estimates associated with the provision of the trails. Our results reveal that using a mixture of discrete and continuous distributions to represent cost heterogeneity leads to <b>a</b> <b>better</b> <b>model</b> <b>fit</b> and lower welfare estimates. Our results further reveal that Irish rural residents show positive preferences for the development of farmland walking trails in the Irish countryside...|$|E
3000|$|To {{test the}} {{structure}} hypothesis, we used multidimensional scaling (MDS), proceeding from a similarity matrix between the 24 values, {{and used the}} squared Euclidean distances (ALSCAL algorithm). The raw scores were transformed into Z scores before creating the distance matrix. The analyses were performed at the ordinal level fixing the extraction of two dimensions. Stress and RSQ (squared correlation coefficient) values were {{used to evaluate the}} model fit. These indices covary inversely, which means that the dimensionality of the space is evaluated by a decrease {{in the value of the}} stress and a corresponding increase in RSQ. A stress value closer to 0 and a RSQ value closer to 1 indicate <b>a</b> <b>better</b> <b>model</b> <b>fit,</b> but values up to [...]. 20 and equal to or greater than [...]. 60, respectively, are acceptable (Schiffman et al. 1981).|$|E
40|$|Segmented mesocosms (n = 3) {{packed with}} sand, sandy loam or clay loam soil {{were used to}} {{determine}} the effect of soil texture and depth on transport of two septic tank effluent (STE) -borne microbial pathogen surrogates—green fluorescent protein-labeled E. coli (GFPE) and MS- 2 coliphage—in soil treatment units. HYDRUS 2 D/ 3 D software was used to model the transport of these microbes from the infiltrative surface. Mesocosms were spiked with GFPE and MS- 2 coliphage at 105 cfu/mL STE and 105 – 106 pfu/mL STE, respectively. In all soils, removal rates were > 99. 99 % at 25 cm. The transport simulation compared (1) optimization; and (2) trial-and-error modeling approaches. Only slight differences between the transport parameters were observed between these approaches. Treating both the die-off rates and attachment/detachment rates as variables resulted in <b>an</b> overall <b>better</b> <b>model</b> <b>fit,</b> particularly for the tailing phase of the experiments. Independent of the fitting procedure, attachment rates computed by the model were higher in sandy and sandy loam soils than clay, which was attributed to unsaturated flow conditions at lower water content in the coarser-textured soils. Early breakthrough of the bacteria and virus indicated the presence of preferential flow in the system in the structured clay loam soil, resulting in faster movement of water and microbes through the soil relative to a conservative tracer (bromide) ...|$|R
40|$|This paper {{describes}} a clustering methodology for temporal data using hidden Markov model(HMM) representation. The proposed method improves upon existing HMM based clustering methods in two ways: (i) it enables HMMs to dynamically change its model structure to obtain <b>a</b> <b>better</b> <b>fit</b> <b>model</b> for data during clustering process, and (ii) it provides objective criterion function to automatically select the optimal clustering partition. The algorithm {{is presented in}} terms of four nested levels of searches: (i) {{the search for the}} optimal number of clusters in a partition, (ii) the search for the optimal partition structure, (iii) the search for the optimal HMM structure for each cluster, and (iv) the search for the optimal parameter values for each HMM. Preliminary experiments with artificially generated data demonstrate the effectiveness of the proposed methodology...|$|R
40|$|The Laplacian {{model is}} the {{standard}} distribution for correlation noise estimation at the turbodecoder in Wyner-Ziv coding schemes. In practice, this hypothesis is not always satisfied and, regularly, the estimated model sensibly differs from the error distribution. In this work, we prove that using <b>a</b> <b>model</b> <b>better</b> <b>fitted</b> to the true distribu-tion improves the performances, and we thus propose to use the more general exponential power distribution (EPD) which has never been tested in a distributed video coding context. Gains in rate-distortion over the Laplacian model are illustrated by results on several video sequences, showing that the EPD model outperforms the Laplacian one in off-line (oracle) {{as well as in}} on-line (practical implementa-tion) modes. These results also indicate that, in some cases, the on-line EPD model reduces the bitrate even over the off-line Laplacian model...|$|R
40|$|As {{with earlier}} social disparities in {{educational}} achievement, re-enrolment in college education {{can depend on}} parental social background. We link this finding with gender differences {{using data from the}} US National Longitudinal Study of Youth 79 and ask if the decision to re-enrol in college is influenced by parental social class in a gender-specific way. The results show that adding maternal class position to the operationalisation of social origin can be beneficial and result in <b>a</b> <b>better</b> <b>model</b> <b>fit.</b> Moreover, there are gender differences {{on the part of the}} child. Working-class men are constantly disadvantaged in their chances to re-enrol in education throughout their lives compared to men with more privileged family backgrounds, while working-class women are only disadvantaged among early re-entrants. This result is reversed in later years and women with working-class parents re-enrol more often...|$|E
40|$|In {{many areas}} of {{economic}} analysis, economic theory restricts the shape of functions. Examples are the monotonicity and curvature conditions that apply to utility, profit, and cost functions. Here we extend upon a currently available estimation method (Terrell, 1996) for imposing regularity regionally on a connected subset of the regressor space. This method offers important advantages by imposing theoretical consistency not only locally, at a given evaluation point but also within the whole empirically relevant region of the domain associated with the function being estimated. The method also provides benefits through higher flexibility, which generally leads to <b>a</b> <b>better</b> <b>model</b> <b>fit</b> to the sample data. Specific contributions of this paper are (a) to increase the computational speed, (b) to provide regularity preserving point estimates, and (c) to illustrate the benefits of this revised regional approach via numerical simulation results...|$|E
40|$|The heat {{transfer}} from the bulk gases to the combustion chamber walls {{has a strong}} effect on the combustion and emission formation process in an HCCI engine. In this work, the empirical {{heat transfer}} models of Annand, Woschni, Hohenberg, Bargende, Chang et al. and Hensel et al. are evaluated at various engine operating conditions. The modelled heat flux is compared to the measured heat flux in a CFR engine with a thermopile sensor. The shape of the heat flux trace, the maximum heat flux and the total heat loss are evaluated and different model calibration procedures are investigated. It is found that all models require calibration {{and need to be}} recalibrated if the fuel type and certain engine settings are changed. <b>A</b> <b>better</b> <b>model</b> <b>fit</b> can be obtained if different model coefficients are applied for the compression and the expansion phase...|$|E
30|$|Perceived {{ease of use}} (PEU) {{model was}} checked with CFA results and {{identified}} that the <b>model</b> is not <b>fitted</b> well. Thus, the modification indices were reviewed to have <b>a</b> <b>better</b> <b>fit</b> <b>model.</b> The modification indices show significant covariance, which can be merged (e 1 to e 2, e 5 to e 6 and e 1 to e 6). The modified model shows acceptable <b>model</b> <b>fit.</b> The values for GFI (0.952), AGFI (0.910), CFI (0.935), NFI (0.926) and TLI (0.902) are acceptable with the cut-off value. The value for RMSEA (0.089) is bit exceeds to threshold value suggested by Hu and Bentler (1999), however, {{it was in the}} acceptable level. RMR (0.018) indicates better values. The normalized Chi square (8.076, P value: 0.000) is bit exceeds than the threshold. Accordingly, giving attention to all fit indices, the modified model was considered for the final model design.|$|R
40|$|We {{have used}} fluvial (Solent River system) and marine {{terraces}} {{to reconstruct the}} uplift history of central southern England. In {{the case of the}} former, we make the assumption that fluvial incision has been a direct response to surface uplift, with its precise timing controlled by climatic forcing of fluvial activity, such that height of terrace gravel above modern river is a consequence of uplift since deposition. In the case of the marine sequence, we take the height of interglacial raised beaches above a calculated contemporaneous sea-level as a measure of uplift, the calculation involving an adjustment from modern sea-level using the deep oceanic oxygen isotope signal as an indication of global ice volume at the time of deposition. This exercise requires some degree of dating constraint, which is problematic for both environments. The Solent terraces have yielded little biostratigraphical evidence, whereas the south coast raised beaches have either been poorly exposed in recent years or their ages have been controversial because of disputes between biostratigraphy and geochronological data. We have supplemented the evidence available from these sources by using key aspects of the archaeological record as dating constraints, in particular the first appearances of Levallois technique (a marker for MIS 9 - 8) and of bout coupé handaxes (MIS 3). The first of these has been particularly useful in modelling of the Middle Pleistocene parts of the river terrace staircases of the Solent system. In undertaking this reappraisal, we have noted several inconsistencies and disagreements between past correlation schemes for the terraces of the Solent and its various tributaries. We find that versions involving shallower downstream gradients in the main Solent River {{are most likely to be}} correct and that revisions on this basis solve a number of problems in interpretation encountered previously. Our results show that most of this region has uplifted by 70 m since the late Early Pleistocene and by 150 m since the Middle Pliocene, there being a high degree of consistency between uplift histories inferred for river terraces and marine terraces. Uplift rates increase gradually westward, such that along the River Frome at the western end of the Hampshire Basin 80 m of uplift since the late Early Pleistocene is indicated. This variation is interpreted as a consequence of a regional-scale variation in crustal properties. About 80 m of uplift is also indicated on this timescale by raised beaches in the Portsdown area and adjacent terraces of the River Test and Solent in the vicinity of the Portsdown anticline to the north of Southampton. We interpret this as a consequence of 10 m of vertical slip in the past million years on the blind reverse fault beneath this anticline. This dataset thus provides the first clear indication of measurable Quaternary structural development in crustal basement in the onshore UK. The Solent has formed more than a single terrace per 100 ka Milankovitch cycle, leading us to attribute terraces to isotopic substages, potentially improving upon the resolution available from sequences in which terraces formed once per cycle. Athough the first appearence of Levallois technique was initially considered to date from the MIS 9 - 8 transition, based on evidence from the Thames, we found that there was <b>a</b> <b>better</b> <b>modelling</b> <b>fit</b> if this was taken as having occurred slightly earlier, in MIS 9 b, perhaps in association with the post-MIS 9 e or 9 c marine regression, which could have permitted immigration into a previously insular Britain of people versed in Levallois technology. ...|$|R
40|$|The {{effect of}} {{financial}} reports on stock market behavior {{is a central}} issue of research in accounting and finance. A number of studies investigate how financial information becomes impounded in security prices and affects investment decisions. Prior studies on the determinants of the bid-ask spread investigate the effect of market risk measures, and provide evidence that the bid-ask spread is a positive function of risk. Other studies report on an association between market risk measures and accounting risk measures. The present study extends this line of research by examining the effect of risk, proxied by accounting risk measures, on the bid-ask spread. The results of ordinary least squares (OLS) regressions provide evidence of a statistically significant association between certain accounting ratios and the bid-ask spread, and indicate that accounting risk measures account for more variability in the bid-ask spread than market risk measures. Most notably, {{the results indicate that}} a model which includes both accounting risk measures and market risk measures is <b>a</b> <b>better</b> <b>fitted</b> <b>model</b> that one which includes either accounting risk measures or market risk measures alone...|$|R
40|$|Purpose – The {{melamine}} milk scandal {{caused a}} crisis of confidence in food containing dairy products. The {{purpose of this paper}} is to explore the determinants of precautionary behaviour to avoid food containing dairy products among Taiwanese college students. Design/methodology/approach – Of the total respondents selected using a multistage cluster sampling plan, 1, 213 respondents completed the questionnaire. Findings – The survey results showed that subjective norms, attitude, perceived behavioural control, attention to news, and perceived credibility of information are significantly associated with the intention to take precautionary behaviour. Originality/value – The paper developed a modified theory of planned behaviour (TPB) that focused on attention and perceived credibility of milk scandal‐related information as additional determinants of precautionary behaviour to avoid food containing dairy products. The inclusion of attention and perceived credibility of information constructs enabled <b>a</b> <b>better</b> <b>model</b> <b>fit</b> than that of the TPB model...|$|E
30|$|We {{compared}} {{statistical models}} using Akaike’s Information Criterion (AIC; Burnham and Anderson 2002), {{so we did}} not compute P-values. We used an intercept-only model (including random effects) and the difference in Akaike’s Information Criterion (ΔAIC) values to evaluate how well the models approximated, or fit, the data (Burnham and Anderson 2002). Those with AIC values at least 10 units less than the intercept-only model were deemed good models, while those with ΔAIC less than 2 were considered the set of best-fit models (Burnham and Anderson 2002). For models with AAIC < 2, we used model averaging to estimate regression coefficients, following the methods of Burnham and Anderson (2002). Model averaging allows for <b>a</b> <b>better</b> <b>model</b> <b>fit</b> by determining the weighted contribution of each variable, based on their importance {{to each of the}} best-fit models. We used Z-statics (variable coefficient divided by the standard error) to compare the relative importance of explanatory variables, following model averaging (Neter et al. 1996).|$|E
40|$|A {{combined}} criterion {{involving the}} regression slopes of pretest-posttest achievement scores and achievement gain scores {{was used to}} classify similar types of classrooms. Mathematics achievement differences among 632 fifth graders were analysed in a longitudinal design and explained in a structural equation framework provided by LISREL, separately for four types of classrooms. The results replicated the findings of an earlier study (Schneider & Treiber, 1984) in that the local nature of achievement models could be demonstrated. That is, the structural components of the causal models could not be generalized across the four groups of classrooms. The inclusion of a second grouping criterion (i. e., achievement gainJ proved useful in that <b>a</b> <b>better</b> <b>model</b> <b>fit</b> was always obtained for classrooms with high achievement gains. As a global model test ignoring group and classroom membership did mask the differential validity of the achievement model in the various subgro. ups, the need for multilevel approaches was emphasized...|$|E
40|$|Abstract Background:Perceptions {{of aging}} {{have been found}} to {{independently}} contribute to various aspects of health and wellbeing in old age. Since valid and reliable perceptions of aging instruments are unavailable in Dutch, these associations have not yet been tested in the Netherlands. This study examined the reliability and construct validityof the Dutch-language version of the 7 -dimension Aging Perceptions Questionnaire (APQ). Furthermore, in order to decrease the response burden, while retaining the APQ’s original factor structure, a short version of the APQ (APQ-S) was developed {{as an alternative to the}} 5 -dimension Brief APQ (B-APQ). Methods:A Dutch translated version of the APQ was administered to a large sample of community-dwelling elders in the Netherlands,aged 70 to 99 (n= 1280), alongside measures of wellbeing and physical functioning. Results:Confirmatory factor analyses confirmed the multidimensionality of the APQ. APQ scales were found to havegood reliability and acceptable construct validity, yet several areas of localized strain were detected. These areas were addressed during item reduction, resulting in the 21 -item APQ-S with an acceptable reliability and validity and <b>a</b> <b>better</b> overall <b>model</b> <b>fit.</b> While several notable differences were found, APQ-S results were largely comparable to that of the 5 -dimension B-APQ. Conclusion: With its multidimensional nature and acceptable psychometric properties, the Dutch language version of the APQ may prove to be an invaluable instrument to assess the seven perceptions of aging dimensions among olderpopulations for geriatric research. However, use of a shortened version is advised, as these are less labor intensive and areas of localized strain are addressed. The choice between the APQ-S and the B-APQ should be based on theoretical and practical considerations concerning the dimensional structure most suitable for the study...|$|R
40|$|The {{role of the}} {{hierarchical}} syntactic structure has been controversial in sentence processing: while experience-based models of syntactic expectations or surprisal (Hale, 2001) generally rely on hierarchical sentence structure, memory-based models like the Dependency-Locality Theory (DLT; Gibson, 2000) tend to {{emphasize the importance of}} linear distance. Although DLT successfully predicts the difference between object and subject relative clauses in English (Gibson, 2000), it has problems accounting for a similar pattern in Korean (Kwon et al., 2006), where the linear distance between the verb and its object is the same in both constructions. One possible way to remedy this shortcoming of DLT is to replace linear distance by a structural distance measuring the number of syntactic nodes crossed (cf. O’Grady, 1997) when integrating the dependent(s) of a head. We tested to what degree structural distance could replace linear distance by evaluating their relative importance as predictors for reading times in the Dundee Corpus (Kennedy & Pynte, 2005). Both distances were calculated based on dependency relations obtained from parsing the corpus with the Stanford Parser (de Marneffe et al., 2006) : for each dependency relation the distance was determined as the number of words (LINEAR DISTANCE) between the head and its dependent and as the number of non-terminal nodes crossed (STRUCTURAL DISTANCE) when traversing the syntactic tree structure from the head to its dependent. First-pass reading times were modeled using linear mixed-effects regressions with subjects and word tokens as random effects. We first <b>fitted</b> a baseline <b>model</b> with the predictors word position, word length, unigram and bigram frequency and all two-way interactions that significantly improved the model in a log-likelihood ratio test. All predictors were centered and scaled to reduce collinearity. We then added linear and structural distance as a predictor to the baseline model: while structural distance yields <b>a</b> reliably <b>better</b> <b>model</b> <b>fit</b> (χ 2 (1, N= 189, 704) = 14. 53, p <. 001), linear distance does not significantly improve over the baseline model (...|$|R
40|$|AIM: To {{study the}} {{validity}} and liability of a Swedish translation of the Post Hospitalization Behavior Questionnaire (PHBQ) in children in Sweden. METHODS: The PHBQ was translated using a back-translation method. The subjects were 340 children, ages 2 - 13 y, admitted for elective surgery or diagnostic procedure with anaesthesia. The results were analysed using exploratory factor analysis with principal component analysis with Oblimin rotation. The fit to data was examined using confirmative factor analysis with a good measure of <b>fit</b> for the <b>model</b> (p> 0. 09 for all factors). RESULTS: Five factors emerged as being most consistent: general anxiety-withdrawal, eating disturbances, separation anxiety, regression-aggression and sleep anxiety. A panel of child psychologists confirmed the face validity of factors. Internal consistency (Chronbach's alpha) was adequate (0. 75 - 0. 87) for subscales and excellent for total score (0. 93). Children less than 5 y old had higher scores than older children (mean 0. 046 +/- 0. 018 vs - 0. 0089 +/- 0. 014, p< 0. 001). There were no gender differences. CONCLUSION: The results support a conclusion that <b>a</b> five-factor <b>model</b> <b>better</b> <b>fits</b> data from Swedish children than the original six-factor model...|$|R
