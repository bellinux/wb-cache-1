314|966|Public
25|$|In {{the early}} 1980s, the Analogic Corporation {{developed}} The APL Machine, {{which was an}} array processing computer designed to be programmed only in APL. There were actually three processing units, the user's workstation, an IBM PC, where programs were entered and edited, a Motorola 68000 processor that ran the APL interpreter, and the Analogic <b>array</b> <b>processor</b> that executed the primitives. At {{the time of its}} introduction, The APL Machine was likely the fastest APL system available. Although a technological success, The APL Machine was a marketing failure. The initial version supported a single process at a time. At the time the project was discontinued, the design had been completed to allow multiple users. As an aside, an unusual aspect of The APL Machine was that the library of workspaces was organized such that a single function or variable that was shared by many workspaces existed only once in the library. Several of the members of The APL Machine project had previously spent a number of years with Burroughs implementing APL\700.|$|E
50|$|SIMD engines: vector processor, <b>array</b> <b>processor,</b> {{digital signal}} processor, stream processor.|$|E
5000|$|... the world's first commercially {{available}} massively parallel computer, the Distributed <b>Array</b> <b>Processor</b> (DAP), that first ran as an attached processor to the ICL 2980.|$|E
40|$|Abstract:- <b>Array</b> <b>processors</b> are {{widespread}} in real–time systems. In {{the last ten}} years phase–locked loops (PLL) have widely been used in <b>array</b> <b>processors</b> as control devices correcting a clock skew. In this paper new type of floating phase–locked loops for <b>array</b> <b>processors</b> is designed. For the floating phase locked loops new stability conditions are obtained...|$|R
40|$|The {{rapid growth}} in device density {{achieved}} by VLSI technology {{over the past decade}} had the attention of researchers centered around the design of <b>array</b> <b>processors.</b> The systolic <b>arrays</b> had been designed {{for a wide variety of}} applications, and consequently formal strategies for mapping algorithms onto <b>processor</b> <b>arrays</b> wer...|$|R
50|$|The Warp {{machines}} were {{a series of}} increasingly general-purpose systolic <b>array</b> <b>processors,</b> created by Carnegie Mellon University (CMU), in conjunction with industrial partners G.E., Honeywell and Intel, and funded by the U.S. Defense Advanced Research Projects Agency (DARPA).|$|R
5000|$|A {{computer}} which exploits multiple data streams {{against a}} single stream to perform operations {{which may be}} naturally parallelized. For example, an <b>array</b> <b>processor</b> or graphics processing unit (GPU) ...|$|E
5000|$|... 1999: Eurotech {{started to}} co-operate with INFN (Italian Institute of Nuclear Physics) {{for the study}} and {{implementation}} of its third generation of <b>Array</b> <b>Processor</b> Experiment supercomputers, called APEmille. Eurotech's HPC business unit began with this cooperation.|$|E
50|$|DAP FORTRAN was an {{extension}} of the non IO parts of FORTRAN with constructs that supported parallel computing for theICL Distributed <b>Array</b> <b>Processor</b> (DAP). The DAP had a Single Instruction Multiple Data (SIMD) architecture with 64x64 single bit processors.|$|E
40|$|New {{direct and}} {{implicit}} algorithms for optical matrix-vector and systolic <b>array</b> <b>processors</b> are considered. Direct rather than indirect algorithms to solve linear systems and implicit rather than explicit solutions to solve second-order partial differential equations are discussed. In many cases, such approaches more properly utilize the advantageous features of optical systolic <b>array</b> <b>processors.</b> The matrix-decomposition operation (rather than {{solution of the}} simplified matrix-vector equation that results) is recognized as the computationally burdensome aspect of such problems that should be computed on an optical system. The Householder QR matrix-decomposition algorithm is considered as a specific example of a direct solution. Extensions to eigenvalue computation and formation of matrices of special structure are also noted...|$|R
40|$|Techniques for {{integrating}} microprocessors, <b>array</b> <b>processors,</b> and other intelligent devices in control systems are reviewed, {{with an emphasis}} on the (re) arrangement of components to form distributed or parallel processing systems. Consideration is given to the selection of the host microprocessor, increasing the power and/or memory capacity of the host, multitasking software for the host, <b>array</b> <b>processors</b> to reduce computation time, the allocation of real-time and non-real-time events to different computer subsystems, intelligent devices to share the computational burden for real-time events, and intelligent interfaces to increase communication speeds. The case of a helicopter vibration-suppression and stabilization controller is analyzed as an example, and significant improvements in computation and throughput rates are demonstrated...|$|R
40|$|Abstract-An {{algorithm}} {{is presented to}} merge two subfiles of size n/ 2 each, stored in {{the left and the}} right halves of a linearly connected <b>processor</b> <b>array,</b> in 3 n / 2 route steps and log n compare-exchange steps. This {{algorithm is}} extended to merge two horizontally adjacent subfiles of size m X n/ 2 each, stored in an m X n mesh-connected <b>processor</b> <b>array</b> in row-major order, in m + 2 n route steps and log mn compare-exchange steps. These algorithms are faster than their counterparts proposed so far. Next, an algorithm is presented to merge two vertically aligned subfiles, stored in a mesh-connected <b>processor</b> <b>array</b> in row-major order. Finally, a sorting scheme is proposed that requires 11 n route steps and 2 log 2 n compare-exchange steps to sort n 2 elements stored in an n X n mesh-connected <b>processor</b> <b>array.</b> The previous best sorting algorithm requires 14 n route steps for practical values of n, 4 < n < 512 (i. e., mesh-connected <b>processor</b> <b>arrays</b> containing 16 to 262 144 processors). The merge algorithms for the mesh-connected <b>processor</b> <b>array</b> use wrap around connections. These connections can be avoided at the expense of some extra hardware. Index Terms-Linearly connected <b>processor</b> <b>arrays,</b> mesh-connected <b>processor</b> <b>arrays,</b> odd-even merge algorithm, SIMD machines...|$|R
50|$|The Distributed <b>Array</b> <b>Processor</b> (DAP) {{produced}} byInternational Computers Limited (ICL) was the world's first commercialmassively parallel computer. The original paper study wascomplete in 1972 {{and building}} of the prototype began in 1974.The first machine was delivered toQueen Mary College in 1979.|$|E
50|$|The FPS AP-120B was a 38-bit, pipeline-oriented <b>array</b> <b>processor</b> {{manufactured}} by Floating Point Systems. It {{was designed to}} be attached to a host computer such as a DEC PDP-11 as a fast number-cruncher. Data transfer was accomplished using direct memory access.|$|E
50|$|APE ("ah-pei"), {{an acronym}} for <b>Array</b> <b>Processor</b> Experiment, was the {{collective}} name of several generations of massively parallel supercomputers since 1984, optimized for theoretical physics simulations. The APE machines were massively parallel 3D arrays of custom computing nodes with periodic boundary conditions.|$|E
40|$|A {{method for}} {{implementing}} an <b>array</b> signal <b>processor</b> for phased <b>array</b> radars. The <b>array</b> signal <b>processor</b> can receive planar array antenna inputs and can process it. It {{is based on}} the application of Adaptive Digital beam formers using FPGAs. Adaptive filter algorithm used here is Inverse Q-R Decomposition based Recursive Least Squares (IQRD-RLS) [1] algorithm. <b>Array</b> signal <b>processor</b> based on FPGAs is suitable in the areas of Phased Array Radar receiver, where speed, accuracy and numerical stability are of utmost important. Using IQRD-RLS algorithm, optimal weights are calculated in much less time compared to conventional QRD-RLS algorithm. A customized multiple FPGA board comprising three Kintex- 7 FPGAs is employed to implement <b>array</b> signal <b>processor.</b> The proposed architecture can form multiple beams from planar array antenna element...|$|R
40|$|Digital {{computers}} {{are becoming increasingly}} popular {{for a variety of}} purposes in nuclear medicine. They are particuiarly useful in the areas of nuclear imaging and gamma camera image processing, radionuclide inventory and patient record keeping. By far the most important use of the digital computer is in <b>array</b> <b>processors</b> which are commonly available with emission computed systems for fast reconstruction of images in transverse, coronal and sagittal views, particularly when the data to be handled is enormous and involves filtration and correction processes. The addition of <b>array</b> <b>processors</b> to computer systems has h ~ k d the clinicians in improving diagnostic nuclear medicine imaging capability. This paper reviews briefly the role of computers in the field of nuclear medicine imaging. 1...|$|R
40|$|Frequently used {{problems}} of linear algebra, {{such as the}} solution of linear systems, triangular decomposition and matrix multiplication, are computationally extensive. To increase the speed, those problems should be solved with systolic structures, where many processors are used concurrently to compute the result. Since two-dimensional <b>array</b> of <b>processors</b> is very consumptive, considering space and resources, {{it is better to}} use one-dimensional <b>array</b> of <b>processors.</b> This leads to the operation reallocation and causes unequal utilization of processors, but {{it is much easier to}} implernent since there is only one linear <b>array</b> of <b>processors.</b> ...|$|R
50|$|STARAN {{might be}} the first commercially {{available}} computer designed around an associative memory. The STARAN computer was designed and built by Goodyear Aerospace Corporation. It is a Content Addressable Parallel Processor (CAPP), a type of parallel processor which uses content addressable memory. STARAN is a single instruction, multiple data <b>array</b> <b>processor</b> with a 4x256 1-bit processing element (PE) computer. The STARAN machines became available in 1972.|$|E
50|$|The ZMS {{processors}} {{are based}} on a low-power multicore architecture including dual ARM cores for handling traditional CPU tasks plus a closely coupled, fully programmable SIMD <b>array</b> <b>processor</b> to do the heavy lifting for intensive media processing tasks such as; 2D graphics, 3D graphics, video decode/encode, image processing and floating point (32-bit IEEE). The processors integrate on-chip peripherals and interfaces suitable for a broad range of handheld and embedded devices.|$|E
50|$|The {{original}} goal of {{the company}} was to supply economical, but high-performance floating point coprocessors for minicomputers. In 1976, the AP-120B <b>array</b> <b>processor</b> was produced. This was soon followed by a unit for larger systems and IBM mainframes FPS AP-190. In 1981, the follow-on FPS-164 was produced, followed by its big brother, the 264 having the same architecture. This was 5 times faster using ECL instead of TTL chips.|$|E
40|$|ABSTRACT: Ultra high {{frame rate}} image {{processing}} {{was achieved by}} applying CNN-UM chips as focal plane <b>array</b> <b>processors.</b> By applying parallel optical input, and reading out binary decision from the chip only the computational overhead is negligible. This makes possible even 50, 000 fps image capturing and complex processing. Experiments were done and are described in the paper...|$|R
40|$|Decoding {{techniques}} and equipment used by MST radars are described and some recommendations for new systems are presented. Decoding {{can be done}} either by software in special-purpose (<b>array</b> <b>processors,</b> etc.) or general-purpose computers or in specially designed digital decoders. Both software and hardware decoders are discussed and the special case of decoding for bistatic radars is examined...|$|R
40|$|SEP {{has always}} been {{interested}} in problems that stretch our computational resources. Over time the high-end computer at SEP has gone from <b>array</b> <b>processors</b> (Newkirk, 1977) to the Convex (Claerbout, 1985) to the CM 5 (Biondi, 1991) to the Power Challenge to multi-processor Linux machines (Biondi et al., 1999), and in the last year, its first Linux Beowulf cluster...|$|R
50|$|It {{was based}} on Goodyear's earlier STARAN <b>array</b> <b>processor,</b> a 4x256 1-bit {{processing}} element (PE) computer.The MPP was a 128x128 2-dimensional array of 1-bit wide PEs. In actuality 132x128 PEs were configured with a 4x128 configuration added for fault tolerance to substitute for up to 4 rows (or columns) of processors {{in the presence of}} problems.The PEs operated in an SIMD (Single Instruction, Multiple Data) fashion -each processor performed the same operations simultaneously, on different dataelements, under the control of a microprogrammed control unit.|$|E
50|$|In October 1985, IBM {{introduced}} an optional vector facility for the IBM 3090; such a facility {{had not been}} previously available in the System/370 architecture, thus bringing integrated supercomputer capabilities to the mainframe line. IBM entered into partnerships with several universities to promote {{the use of the}} 3090 in scientific applications, and efforts were made to convert code traditionally run on Cray computers. Along with the vector unit, IBM introduced their Engineering and Scientific Subroutines Library and a facility to run programs written for the discontinued 3838 <b>array</b> <b>processor.</b>|$|E
50|$|Although the ILLIAC travails {{ended in}} uninspiring results, {{attempts}} {{to understand the}} reasons for the difficulties of the ILLIAC IV architecture pushed forward research in parallel computing. Illiac IV {{was a member of the}} class of parallel computers, referred to as SIMD (Single Instruction stream, Multiple Data stream), essentially an <b>array</b> <b>processor.</b> During the 1980s, with the falling processor cost predicted by Moore's Law, a number of companies created MIMD (Multiple Instruction, Multiple Data) to build even more parallel machines, with compilers that could make better use of the parallelism. The Thinking Machines CM-5 is an excellent examples of the MIMD concept.|$|E
40|$|A {{morphological}} operation using a large {{structuring element}} can be decomposed equivalently into {{a sequence of}} recursive operations, each using a smaller structural element. However, an optimal decomposition of arbitrarily shaped structural elements {{is yet to be}} found. In this paper, we have derived an optimal decomposition of a specific class of structuring elements - convex sets - for a specific type of machine - 4 -connected parallel <b>array</b> <b>processors.</b> The cost of morphological operation on 4 -connected parallel <b>array</b> <b>processors</b> is the total number of 4 -connected shifts required by the set of structuring elements. First, the original structuring element is decomposed into a set of prime factors, and their locations are determined while minimizing the cost function. Proofs are presented to show the optimality of the decomposition. Examples of optimal decomposition are given and compared to an existing decomposition reported by Xu. link_to_subscribed_fulltex...|$|R
40|$|As one of {{the point}} design teams for the PetaFlop {{supercomputer}} project sponsored by NSF, NASA, etc., we propose {{the study of the}} PIM (Processor-In-Memory) massive parallel architecture. To efficiently execute an application on the PIM <b>array</b> <b>processors,</b> a good data partitioning, which minimizes the interprocessor communication, is required. Default partitioning such as row-wise or columnwise may not produce a good data distribution and, thus, will prolong the total execution time of an application. In this paper, we propose efficient methods for finding the data placement for PIM <b>array</b> <b>processors</b> while minimizing the total communication time. The methods are currently being model where each processor has unlimited memory. The optimal data placement algorithm is proposed for such a model. Then, we present an algorithm and heuristics for finding the optimal data placement when each processor has limited memory. Experimental results showing the effectiveness of our approaches are also included. ...|$|R
5000|$|Floating Point Systems Inc. (FPS) was a Beaverton, Oregon vendor of {{attached}} <b>array</b> <b>processors</b> and minisupercomputers. The {{company was}} founded in 1970 by former Tektronix engineer Norm Winningstad, with partners Tom Prince, Frank Bouton and Robert Carter. Carter was a salesman for Data General Corp. who persuaded Bouton and Prince to leave Tektronix to start the new company. Winningstad was the fourth partner.|$|R
50|$|In computing, a vector {{processor}} or <b>array</b> <b>processor</b> {{is a central}} processing unit (CPU) that implements an instruction set containing instructions that operate on one-dimensional arrays of data called vectors, compared to scalar processors, whose instructions operate on single data items. Vector processors can greatly improve performance on certain workloads, notably numerical simulation and similar tasks. Vector machines appeared in the early 1970s and dominated supercomputer design through the 1970s into the 1990s, notably the various Cray platforms. The rapid fall in the price-to-performance ratio of conventional microprocessor designs led to the vector supercomputer's demise in the later 1990s.|$|E
50|$|A Modular and {{expandable}} {{system based}} on the VMEbus form factor could meet many customer needs. MaxVideo and the MaxBus were born. Marketing research determined the primary functions required and a road map {{for the next few}} years. The first seven MaxVideo boards were Digimax (digitizer and display), Framestore (triple 512^2 framestore with unprecedented density), VFIR (first real-time 3x3 image filter, SNAP (3x3 Systolic Neighborhood <b>Array</b> <b>Processor),</b> Featuremax (real-time statistics) SP (single point general purpose processor) and Protomax (MaxVideo prototyping board). 10 beta customers were lined up to receive the first 7 boards. MaxWare was the software and drivers written to control the new boards.|$|E
50|$|Unfortunately, due to {{the lack}} of a firm contract, IBM took only a couple of these systems and one year of Datacube's talented {{engineering}} efforts were effectively wasted. But Datacube had other projects going. It leveraged several key technologies with MaxVideo 20. An off-the-shelf disk storage system was integrated to be used for medical and image exploitation systems, but this system had unsolvable technical problems, so Siegel developed MD, based on an off-the-shelf external SCSI RAID box. A 12 bit digitizer, Digi-12 was developed by Erickson and was a key element in the Picker Digital Radiology system. Datacube designed an interface to a Sky <b>array</b> <b>processor</b> to obtain a GE military contract for a submarine sonar system.|$|E
40|$|A 4800 band {{synchronous}} {{communications link}} was established between the Perkin-Elmer (P-E) 3250 Atmospheric Modeling and Sensor Simulation (AMASS) {{system and the}} Cyber 205 located at the Goddard Space Flight Center. An extension study of off-the-shelf <b>array</b> <b>processors</b> offering standard interface to the Perkin-Elmer was conducted to determine which would meet computational requirements of the division. A Floating Point Systems AP- 120 B was borrowed from another Marshall Space Flight Center laboratory for evaluation. It was determined that available <b>array</b> <b>processors</b> did not offer significantly more capabilities than the borrowed unit, although {{at least three other}} vendors indicated that standard Perkin-Elmer interfaces would be marketed in the future. Therefore, the recommendation was made to continue to utilize the 120 B ad to keep monitoring the AP market. Hardware necessary to support requirements of the ASD as well as to enhance system performance was specified and procured. Filters were implemented on the Harris/McIDAS system including two-dimensional lowpass, gradient, Laplacian, and bicubic interpolation routines...|$|R
40|$|Special-purpose {{parallel}} systems, and {{in particular}} cellular SIMD (Single-Instruction Multiple-Data-Stream) and SPMD (Single-Program Multiple-Data-Stream) <b>array</b> <b>processors</b> are very interesting approaches for handling many computationally-intensive applications. These systems consist of an array of identical processing elements executing the same operations (at the instruction or at the program level, respectively) on different sets of data. The main obstacles to {{the widespread use of}} application-speciÞc <b>arrays</b> of <b>processors</b> are, of course, development time and price: the time required for the design of such systems is usually measured in months, if not years, while the cost of custom VLSI circuits makes such designs too expensive for most situations. A major goal of the Embryonics project, the research project which provides the framework for this thesis, is the development of such an <b>array</b> of <b>processors,</b> or cells, inspired by biological cellular processes, {{and in particular}} by the embryological processes of living beings. These processors, relatively simple binary decisio...|$|R
40|$|Simple {{instruction}} set <b>array</b> <b>processors</b> are groups of regularly connected processors with small {{instruction set}}s and local memories. The processors are augmented by built-in communication instructions. Because {{of the complexity}} of implementing these systems, a method of simulating simple instruction set <b>array</b> <b>processors</b> is developed for evaluating the performance of architectures and algorithms. This technique, called hybrid instruction-level/execution-driven simulation, uses a translator-profiler to extract timing information from a program written in a simple instruction set processor's (SISP) assembly language. The translator-profiler converts the assembly language program and the timing information into a high level language that can be compiled on the simulation host. The translator-profiler generated program is used to drive execution-driven simulations. The development of a translator-profiler for a hypothetical SISP is discussed at length. A technique for testing translator-profilers for errors by comparing simulation results to analytical predictions is also presented. The efficiency of hybrid simulation technique is also evaluated for simulations of QR decomposition and SVD algorithms implemented on arrays of SISP's...|$|R
