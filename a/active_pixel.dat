787|148|Public
5|$|By the mid-1980s, the {{flexible}} fiberoptic bronchoscope {{had become an}} indispensable instrument within the pulmonology and anesthesia communities. The digital revolution of the 21st century has brought newer technology to the art and science of tracheal intubation. Several manufacturers have developed video laryngoscopes which employ digital technology such as the CMOS <b>active</b> <b>pixel</b> sensor (CMOS APS) to generate {{a view of the}} glottis so that the trachea may be intubated.|$|E
25|$|It has {{a shallow}} P+ implant in N type {{diffusion}} layer over a P-type epitaxial substrate layer. It {{is used in}} CMOS <b>Active</b> <b>pixel</b> sensor.|$|E
25|$|The {{invention}} of X-ray image intensifiers in the 1950s allowed {{the image on}} the screen to be visible under normal lighting conditions, as well as providing the option of recording the images with a conventional camera. Subsequent improvements included the coupling of, at first, video cameras and, later, digital cameras using image sensors such as charge-coupled devices or <b>active</b> <b>pixel</b> sensors to permit recording of moving images and electronic storage of still images.|$|E
30|$|Activity {{areas are}} {{extracted}} {{to find the}} <b>active</b> <b>pixels.</b>|$|R
40|$|A Perceptually Attentive Super-Resolution (PASR) {{method is}} {{presented}} to significantly reduce the computational complexity of iterative super-resolution algorithms without loss of the desired perceptual quality. A perceptual model based on just noticeable distortion thresholds is utilized to select the <b>active</b> <b>pixels</b> {{that need to be}} processed by the SR algorithm. These selected <b>active</b> <b>pixels</b> are iterated upon until a certain visual quality is reached. Furthermore, the <b>active</b> <b>pixels</b> lying in the attended regions are processed at a higher accuracy by the SR method relative to pixels in other regions. Simulation results are presented to show the significant reduction in complexity and the preserved desired visual quality...|$|R
5000|$|... 525/59.94 SIF Format (NTSC) has a {{resolution}} of (360 or) 352 x 240 <b>active</b> <b>pixels</b> and a refresh rate of 29.97 frames per second.|$|R
2500|$|The [...] "digital revolution" [...] of the 21st {{century has}} brought newer {{technology}} to the art and science of tracheal intubation. Several manufacturers have developed video laryngoscopes which employ digital technology such as the complementary metal–oxide semiconductor <b>active</b> <b>pixel</b> sensor (CMOS APS) to generate {{a view of the}} glottis so that the trachea may be intubated. The Glidescope video laryngoscope is one example of such a device.|$|E
2500|$|The 20th century saw the {{transformation}} of the practices of tracheotomy, endoscopy and non-surgical tracheal intubation from rarely employed procedures to essential components of the practices of anesthesia, critical care medicine, emergency medicine, gastroenterology, pulmonology and surgery. The [...] "digital revolution" [...] of the 21st century has brought newer technology to the art and science of tracheal intubation. Several manufacturers have developed video laryngoscopes that use digital technology such as the CMOS <b>active</b> <b>pixel</b> sensor (CMOS APS) to generate a view of the glottis so that the trachea may be intubated. The Glidescope video laryngoscope is one example of such a device.|$|E
50|$|The term <b>active</b> <b>pixel</b> sensor {{was coined}} in 1985 by Tsutomu Nakamura {{who worked on}} the Charge Modulation Device <b>active</b> <b>pixel</b> sensor at Olympus, and more broadly defined by Eric Fossum in a 1993 paper.|$|E
5000|$|... 625/50 SIF format (PAL/SECAM) has a {{resolution}} of (360 or) 352 x 288 <b>active</b> <b>pixels</b> and a refresh rate of 25 frames per second.|$|R
30|$|In {{order to}} find the <b>active</b> <b>pixels,</b> that is, Activity Areas, the {{illumination}} variations at each pixel are accumulated over the entire video and their kurtosis is estimated from (2). Even if in practice the static pixels do not follow a strictly Gaussian distribution, their kurtosis is still significantly lower (by orders of magnitude) than that of <b>active</b> <b>pixels.</b> This is clearly obvious in the experimental results, where the regions of activity are indeed correctly localized, {{as well as in}} the simulations that follow.|$|R
40|$|Introduction The {{output signal}} of <b>active</b> <b>pixels</b> has a {{non-uniformity}} caused by technological {{variations of the}} electronic components composing the pixel. If no precautions are taken, this non-uniformity (fixed pattern noise or FPN) {{is seen as a}} "snow-like" shade over the image. We describe a method to improve the reading of <b>active</b> <b>pixels,</b> so that this FPN is cancelled, with as final result a better cosmetic quality of the image. Several solutions to this problem have been proposed in literature. We described a technique based upon shifting the threshold voltage of the source follower transistor in the pixel [1] and a correction technique with a dedicated co-processor [2]. The solution proposed here is a correlated double sampling technique, which is a widespread technique to tackle this problem for integrating pixels [3, 4, 5]. For this purpose, it must be possible to bring the <b>active</b> <b>pixels</b> in a reference state that corresponds to a known amount of collected...|$|R
50|$|The term <b>active</b> <b>pixel</b> sensor is {{also used}} to refer to the {{individual}} pixel sensor itself, as opposed to the image sensor; in that case the image sensor is sometimes called an <b>active</b> <b>pixel</b> sensor imager, or active-pixel image sensor.|$|E
5000|$|<b>Active</b> <b>pixel</b> startracker - Startrackers {{are vital}} to ensure {{satellites}} remain in the desired orbit, this startracker {{is based on an}} <b>active</b> <b>pixel</b> design and boasts good radiation resilience, small size and low power consumption. This module was built by Jena-Optronik Germany ...|$|E
5000|$|... 1992-1995 - JPL team invented CMOS <b>active</b> <b>pixel</b> sensor {{technology}} ...|$|E
50|$|The {{computer}} industry has defined square-pixel SIF to be 320 x 240 (QVGA) or 384 x 288 <b>active</b> <b>pixels</b> with a refresh rate of whatever {{the computer is}} capable of supporting.|$|R
50|$|These timings are {{the same}} in the higher {{frequency}} mode, but all pixel counts are correspondingly multiplied by 9/8thsthus, 720 <b>active</b> <b>pixels,</b> 900 total per line, and a 54 pixel back porch.|$|R
40|$|Using data {{taken during}} WFC 3 's Thermal Vacuum 2 (TV 2) testing campaign, we have {{characterized}} the non-linearity of the IR- 1 detector. Cubic polynomials {{were used to}} fit the signal and produce correction coefficients to remove the non-linearity effects. We have also created a mask that identifies pixels with non-nominal behavior. This population of pixels represents 4. 1 % {{of the total number}} of <b>active</b> <b>pixels</b> in the IR channel, and should be ignored in subsequent data analyses. A minimum of 5. 2 % of the <b>active</b> <b>pixels</b> fail to meet the CEI Spec for a saturation level above 70, 000 e-...|$|R
5000|$|... 1995 - Photobit {{established}} to commercialize CMOS <b>active</b> <b>pixel</b> sensor technology ...|$|E
5000|$|... 3 CCDs or CMOS <b>active</b> <b>pixel</b> sensors are used, one {{for each}} of the primary colors ...|$|E
5000|$|... #Caption: Glidescope video laryngoscope, {{incorporating}} a CMOS <b>active</b> <b>pixel</b> sensor (CMOS APS) {{video camera and}} a high resolution LCD monitor ...|$|E
3000|$|In practice, {{illumination}} {{variations of}} only one pixel over time do not provide enough samples to detect changes effectively, so the illumination variations of all <b>active</b> <b>pixels</b> in each frame are used. If an Activity Area contains [...]...|$|R
3000|$|Some {{studies suggest}} {{approximation}} methods to avoid implementation of hardware dividers. Such methods like that implemented in [29] replace the <b>active</b> <b>pixels</b> by the smallest rectangle containing this region and then replace the usual division by simple shifting (division by 2): [...]...|$|R
50|$|SMPTE 344M {{defines a}} 480p59.94 {{standard}} with twice the data rate of BT.601, using 704 × 480 <b>active</b> <b>pixels</b> with 16 x 480 horizontal blanking pixels. ITU-R Rec. 601 is the specification for component digital interlaced video (480i) {{commonly used in}} standard definition television production.|$|R
50|$|The {{two main}} types of sensors are {{charge-coupled}} devices (CCD), {{in which the}} photocharge is shifted to a central charge-to-voltage converter, and CMOS or <b>active</b> <b>pixel</b> sensors.|$|E
50|$|Pinned {{photodiode}} {{is not a}} PIN photodiode, it has p+/n/p {{regions in}} it.It has a shallow P+ implant in N type diffusion layer over a P-type epitaxial substrate layer. It is used in CMOS <b>Active</b> <b>pixel</b> sensor.|$|E
5000|$|... #Caption: Glidescope video laryngoscope, showing 60-degree angulated blade. The CMOS <b>active</b> <b>pixel</b> sensor (CMOS APS) {{video camera}} and light source are located {{at the point of}} {{angulation}} of the blade. An anesthesia machine is visible on the high resolution LCD monitor.|$|E
40|$|This thesis {{presents}} the rate distortion analysis of conditional motion estimation, {{a process in}} which motion computation is restricted to only <b>active</b> <b>pixels</b> in the video. We model <b>active</b> <b>pixels</b> as independent and identically distributed Gaussian process and inactive pixels as Gaussian-Markov process and derive the rate distortion function based on conditional motion estimation. Rate-Distortion curves for the conditional motion estimation scheme are also presented. In addition this thesis also {{presents the}} hardware implementation of a block based motion estimation algorithm. Block matching algorithms are difficult to implement on FPGA chip due to its complexity. We implement 2 D-Logarithmic search algorithm to estimate the motion vectors for the image. The matching criterion used in the algorithm is Sum of Absolute Differences (SAD). VHDL code for the motion estimation algorithm is verified using ISim and is implemented using Xilinx ISE Design tool. Synthesis results for the algorithm are also presented...|$|R
40|$|The {{increased}} {{presence of}} digital multimedia in numerous applications, such as security, surveillance, the semantic web, has rendered the automated characterization of video content necessary. The localization of different activities/events in video {{content is of}} particular interest, however it is quite challenging to achieve in a principled manner and with no prior knowledge or training. This work presents an original, principled {{solution to the problem}} of detecting changes of activity in video, based on sequential change detection techniques. Initially, a binary mask of the <b>active</b> <b>pixels,</b> the Activity Area, is extracted in a pre-processing step by estimating the kurtosis values of inter-frame illumination variations. Sequential change detection is then applied to the illumination changes of the <b>active</b> <b>pixels</b> over time, leading to the separation of the video sequence into segments corresponding to different activities, which can be further processed for classification and recognition. Experiments with various indoors and outdoors videos demonstrate the system’s good performance...|$|R
5000|$|... 625-line {{analogue}} video contains 575 {{active video}} lines (this includes two half lines). When the half lines are rounded up to whole lines {{for ease of}} digital representation, this gives 576 lines, {{which is also the}} nearest mod(16) value to 575. To maintain the same picture aspect ratio, the number of <b>active</b> <b>pixels</b> could be increased to 703.2, which can be rounded up to 704.|$|R
5000|$|The pointer [...] "hotspot" [...] is the <b>active</b> <b>pixel</b> of the pointer, used {{to target}} a click or drag. The hotspot is {{normally}} along the pointer edges or in its center, {{though it may}} reside at any location in the pointer.|$|E
50|$|In January 2012 Sony {{developed}} the back-side illuminated sensor further with Stacked CMOS, where the supporting circuitry is moved below the <b>active</b> <b>pixel</b> section, giving another 30% improvement to light capturing capability. This was commercialized by Sony in August 2012 as Exmor RS with resolutions of 13 and 8 effective megapixels.|$|E
50|$|Early analog sensors for {{visible light}} were video camera tubes. Currently, used types are {{semiconductor}} charge-coupled devices (CCD) or <b>active</b> <b>pixel</b> sensors in complementary metal-oxide-semiconductor (CMOS) or N-type metal-oxide-semiconductor (NMOS, Live MOS) technologies. Analog sensors for invisible radiation tend to involve vacuum tubes of various kinds. Digital sensors include flat panel detectors.|$|E
50|$|The {{frames are}} doubled (from a 25 frame source) on {{broadcast}} (to avoid flicker) for display devices that lack {{any kind of}} frame doubling ability. Widescreen 16:9 material has only the width scaled down to fit 720 pixels instead of an unscaled 1024 width. SMPTE 344M defines a 576p50 standard with twice the data rate of BT.601, using 704 × 576 <b>active</b> <b>pixels</b> with 16 x 576 horizontal blanking pixels.|$|R
5000|$|... 525-line {{analogue}} video contains 485 {{active video}} lines (this include two half lines, though typically only 483 picture lines are present due to Closed Captions data {{taking up the}} first [...] "active picture" [...] line on each field). The nearest mod(16) value is 480. To maintain the same picture aspect ratio, the number of <b>active</b> <b>pixels</b> could be decreased to 706.2, which can be rounded down to 704 for mod(16).|$|R
40|$|In {{this paper}} we suggest the Local <b>Active</b> <b>Pixels</b> Pattern, LAPP[1], which in-turn {{can reduce the}} {{computational}} resources compared to counterpart Local Binary Pattern, LBP. The approach is apt for mobile]based vision applications. The approach has been made use tofusion based face recognition [3, 4], 3 -D feature based face recognition[5]and age classification. The YALE, 3 -D Texas Face Dataset, IRIS visible and infrared data set {{has been used in}} the experimentation. 1...|$|R
