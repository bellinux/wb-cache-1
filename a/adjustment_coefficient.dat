145|195|Public
5000|$|The {{index is}} the {{arithmetic}} {{average of the}} change of prices between a time [...] and a base time 0, which {{is the end of}} the preceding quarter. The formula is:where [...] is the price of the component stock [...] at time , [...] is the price of the component stock [...] at the end of previous quarter, and [...] is the <b>adjustment</b> <b>coefficient.</b>|$|E
40|$|Frequency {{dependent}} I/Q {{imbalance in}} real I/Q filter pairs compensation may be performed using a simple compensation module, {{placed in the}} receiver/transmitter chain, with a gain <b>adjustment</b> <b>coefficient</b> and a delay <b>adjustment</b> <b>coefficient.</b> The gain <b>adjustment</b> <b>coefficient</b> may be determined by amplitude measurements conducted at a selected frequency {{near the center of}} the band-pass region of the filters. The delay <b>adjustment</b> <b>coefficient</b> may be determined by phase measurements conducted at a selected frequency near the edge of the band-pass region of the filters. Statistical analysis may be used to determine types of real filters that are better suited for the compensation method and to select the test frequencies that should be used...|$|E
30|$|Generally speaking, {{adjustment}} coefficients {{are regarded}} as the safety indices of the surplus processes, they are the positive zero-roots of the <b>adjustment</b> <b>coefficient</b> functions. In classical unidimensional Lundberg-type risk models, most of which assumed that the surplus processes are Lévy processes, the <b>adjustment</b> <b>coefficient</b> functions are obtained via martingale techniques: the cumulate generating functions (c.g.f.’s) of the net loss processes. However, in our risk models, the whole surplus processes are not Lévy processes anymore. According to Nyrhinen [18] and Müller and Pflug [19], there also exist <b>adjustment</b> <b>coefficient</b> functions for the unidimensional non-Lévy contexts using another approach: let c_n(t) be the c.g.f. of the aggregate net loss process (aggregate claims minus aggregate premia incomes) at time n, the <b>adjustment</b> <b>coefficient</b> function is given by c(t)=_n→∞ 1 /nc_n(t). In this subsection, we derive the joint c.g.f., which is denoted by c_n(t,s), of the aggregate net losses process based on model BPMA(1). Analogously to Cossétte et al. [15], the <b>adjustment</b> <b>coefficient</b> function c(t,s) is given by c(t,s)=_n→∞ 1 /nc_n(t,s).|$|E
30|$|In this paper, {{we propose}} {{a class of}} bidimensional discrete-time risk models whose bivariate claim counts obey the BPMA(1) and BPAR(1) processes, we derive their <b>adjustment</b> <b>coefficients</b> {{functions}} and the asymptotic distributions for the bivariate compound claim processes in finite time, we obtain the upper bounds for three types of ruin probabilities by large deviations theory, and we present examples to compute {{the three types of}} the <b>adjustment</b> <b>coefficients</b> for their corresponding ruin probabilities as well as the marginal VaR values.|$|R
40|$|One {{measure of}} market {{efficiency}} is {{the speed with}} which prices adjust to new information. The author develops a simple approach to estimating these price <b>adjustment</b> <b>coefficients</b> by using the information in return processes. This approach is used to estimate t he price <b>adjustment</b> <b>coefficients</b> for firms listed on the NYSE and the A MEX as well as for over-the-counter stocks. The author finds evidence of a lagged adjustment to new information in shorter return intervals for firms in all market value classes and some support for the propositi on that prices adjust much more slowly and with more noise for smaller firms. Copyright 1993 by American Finance Association. ...|$|R
30|$|The rest of {{this paper}} is {{organized}} as follows. Section  2 presents the model and problem. Section  3 gives the analysis process and the equations satisfying minimal <b>adjustment</b> <b>coefficients.</b> Section  4 gives comparison numerical examples and our conclusions.|$|R
40|$|A nonparametric Bayesian {{approach}} to the estimation of the <b>adjustment</b> <b>coefficient</b> for {{the distribution of the}} maximum of a random walk is performed. Approximations of the posterior distribution of the <b>adjustment</b> <b>coefficient</b> are studied. The consistency and asymptotic normality of its posterior law are also proved under mild conditions. Finally, an application to real data is provided...|$|E
40|$|We {{consider}} a periodic risk model {{with the possibility}} of investing into a risky asset, given by a geometrical Brownian motion. The aim is to maximize the <b>adjustment</b> <b>coefficient</b> of the risk process. It is shown that the optimal investment strategy only depends on the averaged data of the model and is constant over time. Thus maximizing the <b>adjustment</b> <b>coefficient</b> is a very weak optimization criterion. ...|$|E
3000|$|... where α is the <b>adjustment</b> <b>coefficient</b> used {{to match}} the sum of {{adjusted}} tree survival probabilities ([...] [...]...|$|E
40|$|Twelve {{kinds of}} special semipositive {{matrices}} and their basic characters are presented. Employing these matrices {{and the previous}} results in Zeng (2008), we research the conditions for the balances between final output values and values-added, and between input multipliers and output multipliers in an economy. A necessary and sufficient condition that (i) there exists a unique vector of output <b>adjustment</b> <b>coefficients</b> such that (a) all sectoral final output values equal their respective sectoral values-added in the new output system, or (b) all sectoral input multipliers redefined by the new output system equal their respective sectoral output multipliers; or (ii) there exists a unique vector of price <b>adjustment</b> <b>coefficients</b> such that (a) all sectoral values-added equal their respective sectoral final output values in the new price system, or (b) all sectoral output multipliers redefined by the new price system equal their respective sectoral input multipliers; is the irreducibility of the matrix of intermediate output (or input) coefficients. A necessary and sufficient condition that (i) there is no vector of output <b>adjustment</b> <b>coefficients</b> which enables all sectoral final output values (or input multipliers) to equal their respective sectoral values-added (or output multipliers), or (ii) there is no vector of price <b>adjustment</b> <b>coefficients</b> which enables all sectoral values-added (or output multipliers) to equal their respective sectoral final output values (or input multipliers); is that the matrix of intermediate output (or input) coefficients {{has at least one}} non-final (or non-initial) class. These class relations and their equivalent conditions are summarized. The elaborate examples verify the main conclusions thoroughly. Economic balance Input-output analysis Output adjustment model Price adjustment model Nonnegative matrix...|$|R
3000|$|... 2 on the system, and are {{otherwise}} called the speed of adjustment parameters. The VECM approach {{can be used to}} test Granger causality among the vectors of variables, by testing the statistical significance of the <b>adjustment</b> <b>coefficients</b> and the coefficients of the lagged explanatory variables.|$|R
40|$|In {{this paper}} we examine several {{approaches}} to detecting {{changes in the}} <b>adjustment</b> <b>coefficients</b> in cointegrated VARs. We adopt recursive and rolling techniques as mis-specification tests {{for the detection of}} non-constancy and the estimation of the breakpoints. We find that inspection of the recursive eigenvalues is not useful to detect a break in the <b>adjustment</b> <b>coefficients,</b> whilst recursive estimation of the coefficients can only indicate non-constancy, but not the exact breakpoint. Rolling estimation is found to perform better in detecting non-constancy in the parameters and their true value after the breakpoint. However, it only detects a region where the break is likely to occur. To overcome the drawbacks of these techniques, we use an OLS-based sequential test. To assess its performance, we derive its critical values for different sample sizes. Monte Carlo evidence shows that the test has reasonably good power even in moderately sized samples and that it {{can be used as a}} graphical device, as it shows a kink at the breakpoint. As a benchmar...|$|R
40|$|Abstract: In {{this paper}} {{we deal with}} the {{numerical}} computation of the optimal form of reinsurance from the ceding company point of view, when the cedent seeks to maximize the <b>adjustment</b> <b>coefficient</b> of the retained risk and the reinsurance loading is an increasing function of the variance. We compare the optimal treaty with the best stop loss policy. The optimal arrangement can provide a significant improvement in the <b>adjustment</b> <b>coefficient</b> when compared to the best stop loss treaty. Further, it is substantially more robust with respect to choice of retention level than stop-loss treaties. Keywords: <b>adjustment</b> <b>coefficient,</b> expected utility of wealth, optimal reinsurance, stop loss, standard deviation premium principle, variance premium principle. 1 This research has been supported by Fundação para a Ciência e a Tecnologia- FCT (FEDER/POCI 2010). 1...|$|E
40|$|Abstract. Following [18], {{we study}} the <b>adjustment</b> <b>coefficient</b> of ruin theory {{in a context}} of {{temporal}} dependency. We provide a consistent estimator of this coefficient, and perform some simulations. <b>Adjustment</b> <b>coefficient</b> w for risk processes may describe the behavior of ruin probability. Several results for sums of i. i. d. claims exist: in [12], H. U. Gerber gave an exact formula for finite time ruin probabilities involving the <b>adjustment</b> <b>coefficient</b> w, [19] provide a consistent estimator of w, V. Mammisch [15] gave a necessary and sufficient condition for the existence of w. In dependent contexts, let us cite H. U. Gerber [13] for auto-regressive processes, [2] for an extension to ARMA processes and [3, 4] {{for the study of the}} adjustment coefficients in Markovian environments. The main objective of the parper is to provide a non parametric estimation of the adjustement coefficient introduced in [18] in dependent contexts. We give a general dependent context (weak temporal dependency in the sense of [7]) for which our estimator is consistent. The paper is organized as follows: • Section 1 contains the definitions and elementary properties of weakdependent processes as well as <b>adjustment</b> <b>coefficient.</b> To make short, wi, the independent coefficient, will be the <b>adjustment</b> <b>coefficient</b> if the process is i. i. d. while wd will be the <b>adjustment</b> <b>coefficient</b> of a dependent sequence. • In Section 2, we prove that wd may be seen as a limit (for r → ∞) of independent coefficients wi r. We also provide some general examples for which the <b>adjustment</b> <b>coefficient</b> wd may be defined. • Section 3 is devoted to the estimation of coefficients wi and wd and contains the main results: we construct consistent estimators (see Theorems 3. 3, 3. 5 and 3. 10). Note that in [2], an estimation of wd is given for ARMA processes which is based on the estimation of the ARMA parameters. Our procedure is completely non parametric. • In Section 4 we provide some simulations. 1. Setting We consider (Yn) n∈N a sequence of random variables and Ru the event {Yn> u for some n ≥ 1 }. Yn is interpreted as the value of the claim surplu...|$|E
40|$|This paper {{develops}} a system instrumental variable method {{to estimate the}} speed of <b>adjustment</b> <b>coefficient</b> in the long-run equilibrium of structural error correction models for a class of linear rational expectations models. This method is applied to an exchange rate model with sticky prices, in which the speed of <b>adjustment</b> <b>coefficient</b> governs the half-life of the real exchange rate. Compared to single equation methods, the system method gives smaller half-life estimates with sharper standard errors. Copyright 2007 The Ohio State University. ...|$|E
30|$|For {{rates at}} higher {{maturities}} the two speeds of <b>adjustment</b> <b>coefficients</b> are {{not significantly different}} from each other. However, short maturities provide a better measure as loans are typically not collateralized and this allows isolating the balance sheet channel (Mishkin 1995). In other words, the pass-through does not depend on market price variations that influence the value of collateral. This reinforces the evidence of the results on 3 -month rates.|$|R
40|$|Mechanical {{properties}} of SFRC and its determination methods are examined. Results {{of the extensive}} experimental research as well as crack width and deflection calculation methods of steel fibre and combined reinforced concrete beams are analysed and presented in the work. Also, the <b>adjustment</b> <b>coefficients</b> kP and kpc, fRm, 1 and its variation coefficient Vx estimation methods, a new plastic hinge calculation and fR, 1 modification methods are presented in the dissertation...|$|R
40|$|This paper {{considers}} an expectations augmented {{version of}} the Engle and Granger (1987) error correction model and shows that standard inference about the <b>adjustment</b> <b>coefficients</b> can be severely biased. This has implications for long–run causality and impulse–response analysis in particular. However, a sometimes simple remedy exists which only requires some additional regressions. The results are illustrated using U. S., German and Swiss data. policy analysis; forecasting; rational expectations; error correction...|$|R
30|$|The number γ {{here is the}} {{so-called}} <b>adjustment</b> <b>coefficient</b> or the Lundberg exponent. It follows that _u→∞-ψ (u)/u=γ from (2.3) and (2.4), showing asymptotic behavior of ψ(u).|$|E
40|$|Error {{correction}} {{models are}} widely used to estimate dynamic cointegrated systems. In most applications error correction models are reduced form models. As a result, non-structural speed of adjustment coefficients are estimated in these applications. A single equation instrumental variable method {{can be used to}} estimate a structural speed of <b>adjustment</b> <b>coefficient.</b> This paper develops a system instrumental variable method to estimate the structural speed of <b>adjustment</b> <b>coefficient</b> in an error correction model. This method utilizes Hansen and Sargent's (1982) instrumental variable estimator for linear rational expectations models, and is applied to an exchange rate model with sticky prices. ...|$|E
30|$|Open {{image in}} new window = <b>adjustment</b> <b>coefficient</b> for the static p-y curves; Ps = {{governing}} ultimate soil resistance; k = initial subgrade reaction constant; Z = depth; and Pu = ultimate soil resistance.|$|E
3000|$|... max statistics. The {{estimated}} {{values of}} the above two statistics are compared with the Johansen and Juselius critical value {{to determine the number}} of cointegrating vectors that exist among the variables. This procedure allows for the testing of restricted forms of the cointegrating vectors. Restrictions can be imposed on the co-integrating vectors or on <b>adjustment</b> <b>coefficients,</b> and we can accordingly conclude whether restrictions are binding or not by using the statistic proposed by Johansen.|$|R
30|$|This paper {{considers}} an expectations augmented {{version of}} the Engle and Granger (1987) error correction model and shows that standard inference about the <b>adjustment</b> <b>coefficients</b> can be severely biased. This bias has implications for long-run causality and impulse-response analysis in particular. However, a sometimes simple remedy exists which only requires some additional regressions. The results are illustrated with popular macroeconomic relationships like the Fisher relation and uncovered interest parity hypothesis using U.S., German and Swiss data.|$|R
30|$|However, {{from the}} {{theoretical}} models, nearest measured value is Walfisch–Ikegami model, {{with a mean}} square error of 8.34 dB. Note that this model {{could also be used}} in the prediction of the spread in the analyzed location. Ibrahim–Parsons and Okumura et al.’s models, which showed the worst results, should undergo their <b>adjustment</b> <b>coefficients.</b> Possibly the analyzed urban environment for obtaining these models does not present many similarities with that found in the studied region in this study.|$|R
40|$|We {{establish}} an Edgeworth expansion for an estimator of the <b>adjustment</b> <b>coefficient</b> R, {{directly related to}} the geometric-type estimator for general exponential tail coefficients, proposed in [Brito, M., Freitas, A. C. M., 2003. Limiting behaviour of a geometric-type estimator for tail indices. Insurance Math. Econom. 33, 211 - 226]. Using the first term of the expansion, we construct improved confidence bounds for R. The accuracy of the approximation is illustrated using an example from insurance (cf. [Schultze, J., Steinebach, J., 1996. On least squares estimates of an exponential tail coefficient. Statist. Dec. 14, 353 - 372]). <b>Adjustment</b> <b>coefficient</b> Edgeworth expansions Parameter estimation Sparre Andersen model Tail index...|$|E
30|$|Thirdly, the fuzzy-analytic {{hierarchy}} {{process is}} used to calculate the subjective weights of network attributes, and α as an <b>adjustment</b> <b>coefficient</b> to integrate the objective weights and subjective weights of network attributes. Afterwards, the combined weight of network attributes is obtained.|$|E
3000|$|The joint m.g.f. of S_ 1 n+S_ 2 n-nπ_ 1 -nπ_ 2 is c_n(t,t), and the {{expression}} for <b>adjustment</b> <b>coefficient</b> function is c(t,t), then, by the univariate large deviations theory proposed by Glynn and Whitt [20], {{we get the}} proof of the result. □ [...]...|$|E
40|$|We {{consider}} estimation and {{hypothesis testing}} on the coefficients of the co-integrating {{relations and the}} <b>adjustment</b> <b>coefficients</b> in vector autoregressions driven by shocks which display both conditional and unconditional heteroskedasticity of a quite general and unknown form. We show that the conventional results in Johansen (1996) for the maximum likelihood estimators and associated likelihood ratio tests derived under homoskedasticity do not in general hold under heteroskedasticity. As a result, standard confidence intervals and hypothesis tests on these coefficients are potentially unreliable. Solutions based on Wald tests (using a "sandwich" estimator of the variance matrix) and {{on the use of}} the wild bootstrap are discussed. These do not require the practitioner to specify a parametric model for volatility. We establish the conditions under which these methods are asymptotically valid. A Monte Carlo simulation study demonstrates that significant improvements in finite sample size can be obtained by the bootstrap over the corresponding asymptotic tests in both heteroskedastic and homoskedastic environments. An application to the term structure of interest rates in the US illustrates the difference between standard and bootstrap inferences regarding hypotheses on the co-integrating vectors and <b>adjustment</b> <b>coefficients...</b>|$|R
40|$|The {{hypothesis}} of the adjustment {{costs associated with}} factor adjustments under intraindustry trade are lower than those under inter-industry trade is initially supported by a specific-factor model analysis theoretically. Yet there is no comprehensive empirical evidence to support that. This paper therefore, tested the hypothesis that factor adjustment under intra-industry trade specialisation predominantly occurs within industries rather than between industries using a dynamic factor demand system. The test {{was carried out in}} three steps. First, the optimal solutions of factor demand and output supply were derived for the dynamic adjustment costs model when the function of production is assigned in a quadratic form. Secondly, using data obtained from the OECD’s international sectoral database in the quasi-fixed input demand equations, <b>adjustment</b> <b>coefficients</b> were estimated at the subdivision level of ISIC manufacturing industries. This derivation was employed to Canada, Germany and the United States due to the availability of data. Thirdly, specifying two effects—a trade specialisation effect and a structural change effect—in the empirical model to explain the determinants of labour and capital <b>adjustment</b> <b>coefficients.</b> The results reveal strongly that if an industry has a high degree of intra-industr...|$|R
3000|$|The general form of {{the error}} {{correction}} model we use is ΔX_t=ΠX_t- 1 +∑_i= 1 ^k- 1 Γ_iΔX_t-i+ΦD_t+ε_t [...]. The lag length is selected according to the AIC. To check for cointegration, we test for the rank of the Pi matrix (which {{is equivalent to the}} number of cointegration relations). Using these restrictions, the system is estimated via maximum likelihood. The long-run coefficients are derived from the eigenvectors of the Pi matrix. The <b>adjustment</b> <b>coefficients</b> are calculated by using Π[*]=[*]αβ′ (Johansen 1995, 93).|$|R
40|$|We obtain {{upper and}} lower bounds for the tail of the deficit at ruin in the renewal risk model, which are (i) {{applicable}} generally; and (ii) based on reliability classifications. We also derive two-side bounds, in the general case where a function satisfies a defective renewal equation, and we apply them to the renewal model, using the function [Lambda]u introduced by [Psarrakos, G., Politis, K., 2007. A generalisation of the Lundberg condition in the Sparre Andersen model and some applications (submitted for publication) ]. Finally, we construct an upper bound for the integrated function and an asymptotic result when the <b>adjustment</b> <b>coefficient</b> exists. Probability of ruin Deficit at ruin Renewal equation Failure rate DFR IFR <b>Adjustment</b> <b>coefficient</b> Lundberg condition Stop-loss premium...|$|E
40|$|In {{this paper}} a {{quantitative}} {{analysis of the}} ruin probability in finite time of discrete risk process with proportional reinsurance and investment of finance surplus is focused on. It is assumed that the total loss on a unit interval has a light-tailed distribution [...] exponential distribution and a heavy-tailed distribution [...] Pareto distribution. The ruin probability for finite-horizon 5 and 10 was determined from recurrence equations. Moreover for exponential distribution the upper bound of ruin probability by Lundberg <b>adjustment</b> <b>coefficient</b> is given. For Pareto distribution the <b>adjustment</b> <b>coefficient</b> does not exist, hence an asymptotic approximation of the ruin probability if an initial capital tends to infinity is given. Obtained numerical results are given as tables and they are illustrated as graphs...|$|E
40|$|The paper {{focuses on}} a {{quantitative}} analysis of the probability of ruin in a finite time for a discrete risk process with proportional reinsurance and investment of the financial surplus. It is assumed that the total loss on a unit interval has either a light-tailed distribution - exponential distribution or a heavytailed distribution - Pareto distribution. The ruin probabilities for the finite-horizons 5 and 10 were determined from recurrence equations. Moreover, the upper bound of the ruin probability is given for the exponential distribution based on the Lundberg <b>adjustment</b> <b>coefficient.</b> This <b>adjustment</b> <b>coefficient</b> does not exist for the Pareto distribution, hence an asymptotic approximation is given for the ruin probability when the initial capital tends to infinity. The numerical results obtained are illustrated by tables and figures. (original abstract...|$|E
40|$|In {{this paper}} we compare rum {{functions}} for two risk processes with respect o sto-chastic ordering, stop-loss ordering and ordering of <b>adjustment</b> <b>coefficients.</b> The risk processes are as follows, m the Markov-modulated envtronment and the asso-ciated averaged compound Po~s~on model. In {{the latter case}} the arrival rate ts obtm-ned by averagmg over ttme the arnval rate m the Markov modulated model and the dtstnbutton of the claim size is obtained by averaging the ones over consecu-tive claim s i ze...|$|R
30|$|With {{regard to}} the trade {{openness}} indicators, the results are less conclusive. Nominal and real trade openness are not significantly related to productivity at the 5 % significance level. If we look at exports and imports without gold and transit trade, we find a significant positive long-run relation to productivity. However, {{the significance of the}} <b>adjustment</b> <b>coefficients</b> indicate that exports respectively imports adjust after a deviation from the long-run relationship. In this system, productivity is weakly exogenous. In addition to these openness indicators, we test the relationship between the real effective exchange rate and labor productivity and find a significant positive long-run relation. Therefore, a higher real exchange rate is accompanied with higher productivity. At first sight, a positive relation is not in line with theoretical considerations because an overvalued currency should dampen exports and therefore economic growth. However, Rodrik (2008) finds empirical evidence that this reasoning is only true for developing countries. He finds no negative relation for advanced economies. Moreover, the <b>adjustment</b> <b>coefficients</b> indicate that the real effective exchange rate adjusts after a deviation from the long-run relationship, productivity does not. Hence, an appreciation of the real effective exchange rate may be attributed to an increase in labor productivity.|$|R
40|$|We {{investigate}} analytically and via Monte Carlo simulations {{the effects}} of the inclusion of irrelevant variables in the statistical model, on the cointegration analysis of Johansen (1988, 1991). We show that overspecifying the statistical model does not affect inference about the cointegrating rank, as Johansen (1996, p. 42) suggests. Estimators of the cointegrating vectors and <b>adjustment</b> <b>coefficients</b> remain consistent, but efficiency is affected for the cointegrating vectors. Simulations show that overspecifying the statistical model can considerably reduce the power of tests of cointegrating rank. Keywords; cointegration, misspecification, irrelevant variables, asymptotics, monte carlo...|$|R
