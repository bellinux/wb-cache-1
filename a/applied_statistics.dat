1357|1069|Public
25|$|The zeta {{function}} {{occurs in}} <b>applied</b> <b>statistics</b> (see Zipf's law and Zipf–Mandelbrot law).|$|E
25|$|Further {{information}} regarding the methodology was published in The Annals of <b>Applied</b> <b>Statistics.</b>|$|E
25|$|Best, D. and Fisher, N. (1979). Efficient {{simulation}} of the von Mises distribution. <b>Applied</b> <b>Statistics,</b> 28, 152–157.|$|E
5000|$|<b>Applying</b> <b>Statistics</b> in the Courtroom: A New Approach for Attorneys and Expert Witnesses, Chapman Hall, London, 2001.|$|R
50|$|Barkan {{is noted}} for {{incorporating}} advanced statistical analysis to test hypotheses; {{one of his}} most popular teaching techniques is to incorporates ExplorIT software with large demographic data sets to provide students an interactive means of <b>applying</b> <b>statistics</b> tol sociology.|$|R
2500|$|In <b>applying</b> <b>statistics</b> to a problem, it {{is common}} {{practice}} {{to start with a}} population or process to be studied. Populations can be diverse topics such as [...] "all persons living in a country" [...] or [...] "every atom composing a crystal".|$|R
25|$|Hogg, Robert V. and Ledolter, J. (1992). <b>Applied</b> <b>Statistics</b> for Engineers and Physical Scientists. Macmillan, New York.|$|E
25|$|Candidates for CAS and SOA {{membership}} {{must pass}} standardized tests in introductory economics and corporate finance. Candidates for SOA membership must pass an additional standardized test in <b>applied</b> <b>statistics.</b> Economics has two components: macroeconomics and microeconomics. <b>Applied</b> <b>statistics</b> has two components: regression and time series. Instead of passing exams, candidates may earn credit by passing an approved college {{class with a}} B- or better grade or by completing an approved correspondence class.|$|E
25|$|In <b>applied</b> <b>statistics,</b> total {{least squares}} {{is a type}} of errors-in-variables regression, a least squares data {{modeling}} technique in which observational errors on both dependent and independent variables are taken into account. It is a generalization of Deming regression and also of orthogonal regression, and can be applied to both linear and non-linear models.|$|E
30|$|We <b>applied</b> {{descriptive}} <b>statistics</b> {{to present}} the data.|$|R
50|$|Genichi Taguchi (Taguchi Gen'ichi) (January 1, 1924 - June 2, 2012) was an {{engineer}} and statistician. From the 1950s onwards, Taguchi developed a methodology for <b>applying</b> <b>statistics</b> {{to improve the quality}} of manufactured goods. Taguchi methods have been controversial among some conventional Western statisticians, but others have accepted many of the concepts introduced by him as valid extensions to the body of knowledge.|$|R
5000|$|Step 3 - <b>Apply</b> order <b>statistics</b> and {{smoothing}} filters {{to obtain}} the MAX and MIN filter output ...|$|R
25|$|In 1890 Pearson married Maria Sharpe. The {{couple had}} three children: Sigrid Loetitia Pearson, Helga Sharpe Pearson, and Egon Pearson, who became an eminent {{statistician}} himself and succeeded {{his father as}} head of the <b>Applied</b> <b>Statistics</b> Department at University College. Maria died in 1928 and in 1929 Karl married Margaret Victoria Child, a co-worker at the Biometric Laboratory. He and his family lived at 7 Well Road in Hampstead, now marked with a blue plaque.|$|E
25|$|When Galton died, he {{left the}} residue of his estate to the University of London for a Chair in Eugenics. Pearson was the first holder of this chair — the Galton Chair of Eugenics, later the Galton Chair of Genetics—in {{accordance}} with Galton's wishes. He formed the Department of <b>Applied</b> <b>Statistics</b> (with financial support from the Drapers' Company), into which he incorporated the Biometric and Galton laboratories. He remained with the department {{until his retirement in}} 1933, and continued to work until his death in 1936.|$|E
25|$|Pearson's {{work was}} all-embracing {{in the wide}} {{application}} and development of mathematical statistics, and encompassed the fields of biology, epidemiology, anthropometry, medicine, psychology and social history. In 1901, with Weldon and Galton, he founded the journal Biometrika whose object was the development of statistical theory. He edited this journal until his death. Among those who assisted Pearson in his research {{were a number of}} female mathematicians who included Beatrice Mabel Cave-Browne-Cave and Frances Cave-Browne-Cave. He also founded the journal Annals of Eugenics (now Annals of Human Genetics) in 1925. He published the Drapers' Company Research Memoirs largely to provide a record of the output of the Department of <b>Applied</b> <b>Statistics</b> not published elsewhere.|$|E
5000|$|After {{he retired}} from Bell Labs in 1958, Dodge became a {{professor}} of <b>applied</b> mathematical <b>statistics</b> at Rutgers.|$|R
25|$|Actuarial science <b>applies</b> probability, <b>statistics,</b> and {{economic}} theory to assess risk in insurance, finance and other industries and professions.|$|R
50|$|In {{time series}} analysis, as <b>applied</b> in <b>statistics,</b> the {{cross-correlation}} between two time series is the normalized cross-covariance function.|$|R
25|$|The MBA degree {{originated}} in the United States in the early 20th century when the country industrialized and companies sought scientific approaches to management. The core courses in an MBA program cover various areas of business such as accounting, <b>applied</b> <b>statistics,</b> business communication, business ethics, business law, finance, managerial economics, management, marketing and operations in a manner most relevant to management analysis and strategy. Most programs also include elective courses and concentrations for further study in a particular area. Most challenging and prestigious MBA concentrations include accounting and finance. MBA programs typically require completing nearly {{twice the number of}} credits typically required for degrees that cover some of the same material such as the Master of Economics, Master of Finance, Master of Accountancy, Master of Science in Marketing and Master of Science in Management.|$|E
25|$|In {{mathematical}} statistics, the Kullback–Leibler divergence (also called relative entropy) is {{a measure}} of how one probability distribution diverges from a second, expected probability distribution. Applications include characterizing the relative (Shannon) entropy in information systems, randomness in continuous time-series, and information gain when comparing statistical models of inference. In contrast to variation of information, it is a distribution-wise asymmetric measure and thus does not qualify as a statistical metric of spread. In the simple case, a Kullback–Leibler divergence of 0 indicates that we can expect similar, if not the same, behavior of two different distributions, while a Kullback–Leibler divergence of 1 indicates that the two distributions behave in such a different manner that the expectation given the first distribution approaches zero. In simplified terms, it {{is a measure}} of surprise, with diverse applications such as <b>applied</b> <b>statistics,</b> fluid mechanics, neuroscience and machine learning.|$|E
500|$|In 2004 Josephson criticized an {{experiment}} by the Committee for Skeptical Inquiry to test claims by Russian schoolgirl Natasha Demkina {{that she could}} see inside people's bodies using a special kind of vision. The experiment involved her being asked to match six people to their confirmed medical conditions (plus one with none); to pass the test she had to make five correct matches, but made only four. Josephson argued that this was statistically significant, and that the experiment had set her up to fail. One of the researchers, Richard Wiseman, {{professor of psychology at the}} University of Hertfordshire, responded that Josephson had no record of publishing on parapsychology. Keith Rennolis, professor of <b>applied</b> <b>statistics</b> at the University of Greenwich, supported Josephson's position, asserting that the experiment was [...] "woefully inadequate" [...] to determine any effect.|$|E
40|$|<b>Applying</b> <b>Statistics</b> in Behavioural Research {{is written}} for {{undergraduate}} {{students in the}} behavioural sciences, such as Psychology, Pedagogy, Sociology and Ethology. The topics range from basic techniques, like correlation and t-tests, to moderately advanced analyses, like multiple regression and MANOV A. The focus is on practical application and reporting, {{as well as on}} the correct interpretation of what is being reported. For example, why is interaction so important? What does it mean when the null hypothesis is retained? And why do we need effect sizes? A characteristic feature of <b>Applying</b> <b>Statistics</b> in Behavioural Research is that it uses the same 'basic report' structure over and over in order to introduce the reader to new analyses. This enables students to study the subject matter very efficiently, as one needs less time to discover the structure. Another characteristic of the book is its systematic attention to reading and interpreting graphs in connection with the statistics. Many statistics books use graphical explanations, but ignore the fact that some students are simply not visually oriented. For these students, graphical explanations make things harder, not easier. Here, understanding the visualizations is addressed in separate chapters...|$|R
50|$|The School offers {{facilities}} for intensive training {{and research in}} the basic areas of Mathematics (including <b>Applied</b> Mathematics), <b>Statistics</b> and Operations Research (OR).|$|R
40|$|A {{friendly}} and accessible approach to <b>applying</b> <b>statistics</b> {{in the real}} worldWith an emphasis on critical thinking, The Art of Data Analysis: How to Answer Almost Any Question Using Basic Statistics presents fun and unique examples, guides readers through the entire {{data collection and analysis}} process, and introduces basic statistical concepts along the way. Leaving proofs and complicated mathematics behind, the author portrays the more engaging side of statistics and emphasizes its role as a problem-solving tool.   In addition, light-hearted case studie...|$|R
2500|$|... "Algorithm AS 86: The von Mises Distribution Function", Mardia, <b>Applied</b> <b>Statistics,</b> 24, 1975 (pp.268–272).|$|E
2500|$|Formed Department of <b>Applied</b> <b>Statistics</b> {{incorporating}} the Biometric Laboratory and Galton Laboratory, University College London ...|$|E
2500|$|The {{standards}} for Monte Carlo experiments in statistics were set by Sawilowsky. In <b>applied</b> <b>statistics,</b> Monte Carlo methods are generally used for three purposes: ...|$|E
50|$|They are <b>applied</b> in multivariate <b>statistics.</b>|$|R
40|$|The International Standards Organisation (ISO) will shortly be {{publishing}} the areal surface texture documents under the ISO number ISO/TS 25178. There are many innovative concepts introduced within {{this series of}} documents, amongst them is a distinction between two classes of surface texture parameters namely “Field” and “Feature” parameters. Field parameters <b>apply</b> <b>statistics</b> to the continuous surface (cloud of points) from each portion of the scale-limited surface and include parameters such as: Sq, the root mean square of the surface height; Sz, the peak-to-valley of the surface height; Ssk, the skewness of the surface; Sdq, the root mean square of the surface gradient, etc. Feature parameters <b>apply</b> <b>statistics</b> from a sub-set of pre-defined topographic features. Feature parameters are defined using a toolbox of pattern recognition techniques {{that can be used}} to characterise specified features on a scale-limited surface. The feature characterisation process is in five stages: 1. Selection of the type of texture feature 2. Segmentation 3. Determining significant features 4. Selection of feature attributes 5. Quantification of feature attribute statistics The paper sets out to explain what feature parameters are, the rational behind them and the distinction between them and field parameters. A case study will be used to illustrate the ideas and usage of feature parameters...|$|R
50|$|Bera, Anil K. and Anselin, L. (1998). 'Spatial Dependence in Linear Regression Models with an Introduction to Spatial Econometrics'. The Handbook of <b>Applied</b> Economic <b>Statistics,</b> pp. 237-289.|$|R
2500|$|The use of {{this number}} in <b>applied</b> <b>statistics</b> {{can be traced to}} the {{influence}} of Ronald Fisher's classic textbook, Statistical Methods for Research Workers, first published in 1925: ...|$|E
2500|$|He {{focuses on}} quality control and <b>applied</b> <b>statistics.</b> [...] He has also {{authored}} {{over a dozen}} scholarly books and 110 scientific articles. [...] He holds U.S. patents for eight mechanical designs.|$|E
2500|$|Shore, H. (1982). Simple Approximations for the Inverse Cumulative Function, the Density Function and the Loss Integral of the Normal Distribution. Journal of the Royal Statistical Society. Series C (<b>Applied</b> <b>Statistics),</b> 31(2), 108-114[...]|$|E
50|$|William Osgood Aydelotte (September 1, 1910 - January 17, 1996) was an American {{historian}} {{focused on}} the British Parliament, a pioneer in <b>applying</b> the <b>statistics</b> to historical research.|$|R
2500|$|Statistics is {{a branch}} of {{mathematics}} dealing with the collection, analysis, interpretation, presentation, and organization of data. In <b>applying</b> <b>statistics</b> to, e.g., a scientific, industrial, or social problem, it is conventional {{to begin with a}} statistical population or a statistical model process to be studied. Populations can be diverse topics such as [...] "all people living in a country" [...] or [...] "every atom composing a crystal." [...] Statistics deals with all aspects of data including the planning of data collection in terms of the design of surveys and experiments.|$|R
40|$|Pattern {{theory is}} a {{distinctive}} {{approach to the}} analysis of all forms of real-world signals. At its core is the design of a large variety of probabilistic models whose samples reproduce {{the look and feel of}} the real signals, their patterns, and their variability. Bayesian statistical inference then allows you to apply these models in the analysis of new signals. This book treats the mathematical tools, the models themselves, and the computational algorithms for <b>applying</b> <b>statistics</b> to analyze six representative classes of signals of increasing complexity. The book covers patterns in text, soun...|$|R
