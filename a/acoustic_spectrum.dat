156|346|Public
5000|$|Alveolar versus palatal. The {{hard palate}} is {{horizontal}} {{for up to}} 1 cm behind the teeth, before suddenly opening upward in a feature known as the alveolar ridge. By moving the tongue a few millimeters before or behind the alveolar ridge, therefore, {{it is possible to}} dramatically change the <b>acoustic</b> <b>spectrum,</b> resulting in the distinction between [...] "sip" [...] and [...] "ship".|$|E
50|$|He studied ethnomusicology, vocal extensions, Asian music chant, {{compared}} musicology, {{the problem}} of ethnic vocality, psychoanalysis, the relationship between spoken language and the psyche, {{the limits of the}} spoken language. He was able to reach 7,000 Hz, and to perform diplophony, triplophony, and also quadrophony. Daniel Charles has described him as the person who decimated monody by the demultiplication of the <b>acoustic</b> <b>spectrum.</b> His vocal abilities were explored and documented.|$|E
5000|$|The quantal theory {{suggests}} that the phonological inventory of a language is defined primarily by the acoustic characteristics of each segment, with boundaries specified by the acoustic-articulatory mapping. The implication is that phonological segments must {{have some type of}} acoustic invariance. [...] Blumstein and Stevens demonstrated what appeared tobe an invariant relationship between the <b>acoustic</b> <b>spectrum</b> and theperceived sound: by adding energy to the burst spectrum of [...] "pa" [...] at aparticular frequency, it is possible to turn it into [...] "ta" [...] or [...] "ka"respectively, depending on the frequency. Presence of the extraenergy causes perception of the lingual consonant; its absence causesperception of the labial.|$|E
40|$|The {{investigation}} of <b>acoustic</b> <b>spectra</b> in ion conductive glasses wiht different composition can reflect the basic {{features of the}} relaxation and transport processes of the mobile ions. It {{was found that the}} temeperature responses of all <b>acoustic</b> <b>spectra</b> are very similar and the relaxation peaks associated with ion transport depend on the galsss composition. Experimental and theoretical aspects of acoustic attenuation measurements in ion conductive glasses of the system Cul-CuBr-Cu 2 O-P 2 O 5 are reviewed. Theoretical studies of <b>acoustic</b> <b>spectra</b> due to the ionic hopping motion and relaxation processes connected with the mobility of Cu+ conductive ions are compared with experimental results and some attempts to fit the <b>acoustic</b> attenuation <b>spectra</b> are accomplished...|$|R
50|$|The BP scale {{divides the}} tritave into 13 steps, either equal {{tempered}} (the most popular form), or in a justly tuned version. Compared with octave-repeating scales, the BP scale's intervals are more consonant with {{certain types of}} <b>acoustic</b> <b>spectra.</b>|$|R
40|$|Optical {{absorption}} {{is closely}} associated with many physiological important parameters, such as the concentration and oxygen saturation of hemoglobin, {{and it can be}} used to quantify the concentrations of nonfluorescent molecules. We propose a method to use <b>acoustic</b> <b>spectra</b> of photoacoustic signals to quantify the absolute optical absorption. This method is self-calibrating and thus insensitive to variations in the optical fluence. Factors such as system bandwidth and acoustic attenuation can affect the quantification but can be canceled by dividing the <b>acoustic</b> <b>spectra</b> measured at two optical wavelengths. Using optical-resolution photoacoustic microscopy, we quantified the absolute optical absorption of black ink samples with various concentrations. We also quantified both the concentration and oxygen saturation of hemoglobin in a live mouse in absolute units...|$|R
5000|$|Let Y=f(X), where X is any {{particular}} articulatory parameter (tongue tip position, for example), and Y is {{any particular}} perceptual parameter (perceived {{frequency of the}} peak in the <b>acoustic</b> <b>spectrum,</b> for example). Like any nonlinear relation, f(X) has regions of low slope (|df/dX| small) and regions of high slope (|df/dX| large). Values of Y drawn from a high-slope region are unstable, {{in the sense that}} a small change in X causes a large change in Y; values of Y drawn from a low-slope region are conversely stable, in that they are little perturbed by large changes in X. Stevens proposed in 1968 that the stability of low-slope regions makes them more likely to be chosen as discrete linguistic units (phonemes) by the languages of the world, and that the distinction between any pair of phonemes tends similarly to occur across an unstable high-slope boundary region. Examples include ...|$|E
40|$|Let C be {{a crystal}} and ϕ be a {{periodic}} realization {{of it in}} R^n, also let L be the lattice group of ϕ(C) which preserves the covering space nature of crystal lattices. In this article, firstly, we define the concept of <b>acoustic</b> <b>spectrum</b> of the crystal lattice C and then provide the algebraic formalism {{of the question of}} finding the frequencies of the torus R^n/L, when the set of <b>acoustic</b> <b>spectrum</b> is known. An answer for crystals with uniform atomic force constants is given...|$|E
40|$|Abstract. We {{recently}} presented {{evidence of}} {{a strong correlation between}} the energy in the high-frequency part of the <b>acoustic</b> <b>spectrum</b> of the Sun and the solar X-ray flux (Karoff & Kjeldsen 2008). The discovery indicates that flares drive global oscillations in the Sun {{in the same way that}} the entire Earth is set ringing for several weeks after a major earthquake, such as the 2004 December Sumatra-Andaman one. If this indication turns out to be true we might be able to use the relation between flares and the energy in the high-frequency part of the <b>acoustic</b> <b>spectrum</b> to detect e. g. flares on the far side of the Sun and flares on other solar-like stars. But, the discovery also opens many new questions such as why is it only the high-frequency part of the <b>acoustic</b> <b>spectrum</b> that is correlated with the X-ray flux? And, are there energy enough in solar flares do drive global oscillations? 1...|$|E
40|$|An {{acoustic}} attenuation spectroscopy {{as a powerful}} technique is used to study the relaxation processes in phosphate glasses containing Cu+ conductive ions of the system CuI-CuBr-Cu 2 O-P 2 O 5 with respect to ion transport mechanisms. The <b>acoustic</b> attenuation <b>spectra</b> exhibit several distinctive peaks, corresponding to transport mechanisms originating from {{the different kinds of}} sites responsible for ionic hopping. The ex-perimental results of <b>acoustic</b> <b>spectra</b> are then analysed in connection with the frequency response, the ac-tivation energy at spectra peaks and the peak intensities using theoretical models and suitable mathemati-cal procedure for the simulations to fit the experimental data. © 2004 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim 1 Introduction It is known that the investigation of <b>acoustic</b> <b>spectra</b> of ionic glasses (glassy electro-lytes) can reflect the basic features of the relaxation and transport mechanisms of the mobile ions. Acoustical measurements made over a wide range of frequencies and temperatures can characterize dif-ferent relaxation processes according to corresponding transport mechanisms due to a strong acousto-ionic interaction [1 – 3]. In glassy electrolytes, the mobile ions encounter different kinds of sites so tha...|$|R
40|$|We have {{compared}} the <b>acoustic</b> <b>spectra</b> of adaxial surfaces of green leaves and observed higher signal intensities from adaxial surface. The intensities of signals at 545 nm and 675 nm in purple pigmented leaf {{were found to}} decrease with increase in acoustic frequency from 20 Hz to 50 Hz. However the signal ratio at 545 nm to 675 nm was found to increase with increase in frequency, indicating the depth profile of the purple pigment...|$|R
40|$|Despite {{the long}} history, {{so far there}} is no general {{theoretical}} framework for calculating the <b>acoustic</b> emission <b>spectrum</b> accompanying any plastic deformation. We set up a discrete wave equation with plastic strain rate as a source term and include the Rayleigh-dissipation function to represent dissipation accompanying acoustic emission. We devise a method of bridging the widely separated time scales of plastic deformation and elastic degrees of freedom. The efficacy of the framework is illustrated by considering three distinct cases of plastic deformation. The first one is the acoustic emission during a typical continuous yield exhibiting a smooth stress-strain curve. We first construct an appropriate set of evolution equations for two types of dislocation densities and then show that {{the shape of the}} model stress-strain curve and accompanying <b>acoustic</b> emission <b>spectrum</b> match very well with experimental results. The second and the third are the more complex cases of the Portevin-Le Chatelier bands and the Lüders band. These two cases are dealt with {{in the context of the}} Ananthakrishna model since the model predicts the three types of the Portevin-Le Chatelier bands and also Lüders-like bands. Our results show that for the type-C bands where the serration amplitude is large, the <b>acoustic</b> emission <b>spectrum</b> consists of well-separated bursts of acoustic emission. At higher strain rates of hopping type-B bands, the burst-type <b>acoustic</b> emission <b>spectrum</b> tends to overlap, forming a nearly continuous background with some sharp acoustic emission bursts. The latter can be identified with the nucleation of new bands. The <b>acoustic</b> emission <b>spectrum</b> associated with the continuously propagating type-A band is continuous. These predictions are consistent with experimental results. The <b>acoustic</b> emission <b>spectrum</b> of the Lüders-like band matches with recent experiments as well. Comment: 12 pages, 6 figure...|$|R
40|$|In {{the present}} study, the tool wear has been {{monitored}} using the cutting sound <b>acoustic</b> <b>spectrum</b> and the linear predictive cepstrum coefficient (LPCC) of the milling sound signal would be extracted {{to be used}} as the <b>acoustic</b> <b>spectrum</b> characteristic parameters. The relationship between each order component of LPCC and the flank wear of the tools was analysed. The experimental results show that there are clear characteristic components in the milling sound signal related to the tool wear. It has been found that the characteristic components associated with tool wear are mainly concentrated in the sixth-, seventh- and eighth-order components of LPCC...|$|E
40|$|We {{recently}} presented {{evidence of}} {{a strong correlation between}} the energy in the high-frequency part of the <b>acoustic</b> <b>spectrum</b> of the Sun and the solar X-ray flux Karoff & Kjeldsen (2008). The discovery indicates that flares drive global oscillations in the Sun {{in the same way that}} the entire Earth is set ringing for several weeks after a major earthquake, such as the 2004 December Sumatra-Andaman one. If this indication turns out to be true we might be able to use the relation between flares and the energy in the high-frequency part of the <b>acoustic</b> <b>spectrum</b> to detect e. g. flares on the far side of the Sun and flares on other solar-like stars. But, the discovery also opens many new questions such as why is it only the high-frequency part of the <b>acoustic</b> <b>spectrum</b> that is correlated with the X-ray flux? And, are there energy enough in solar flares do drive global oscillations?Comment: 6 pages, submitted to the proceedings for the GONG 2008 /SOHO XXI meeting on Solar-stellar dynamos as revealed by helio- and asteroseismology, August 2008, Boulder, Colorad...|$|E
40|$|AbstractBoiler tube leakage is {{the major}} reason of {{affecting}} the safe operation of the unit now, there are 3 methods of the “four tube” leakage detection: Traditional method, filtering method and <b>acoustic</b> <b>spectrum</b> analysis, <b>acoustic</b> <b>spectrum</b> analysis is the common method, but this method have low sensitivity and the sensor damage easily. Therewith, designed the special acoustic catheter with acoustic resonance cavity type, proved by experiments, the acoustic catheter with acoustic resonance cavity type can enhance leakage sound, can accurately extract leakage signals, has high sensitivity, and can avoid the effect of sensor by fire and hot-gas when the furnace is in positive pressure situation, reduce the installation and maintenance costs of the boiler tube leakage monitor system...|$|E
40|$|A phased {{microphone}} array {{was used in}} the NASA Langley Low-Turbulence Pressure Tunnel to obtain acoustic data radiating from high-lift wing configurations. The data included noise localization plots and <b>acoustic</b> <b>spectra.</b> The tests were performed at Reynolds numbers based on the cruise-wing chord, ranging from 3. 6 x 10 (exp 6) to 19. 2 x 10 (exp 6). The effects of Reynolds number were small and monotonic for Reynolds numbers above 7. 2 x 10 (exp 6) ...|$|R
40|$|We have {{analyzed}} the local <b>acoustic</b> <b>spectra</b> of small regions over the solar surface at different locations from disk center to limb via {{the technique of}} ring diagrams. It is found that the frequency shifts between velocity and intensity {{is a function of}} location on the disk and is higher near the disk center than those near the limb. Comment: 3 pages, Latex (requires Basi. sty), poster paper presented in the annual meeting of ASI (2003...|$|R
5|$|Tornadoes emit widely on the <b>acoustics</b> <b>spectrum</b> and {{the sounds}} are caused by {{multiple}} mechanisms. Various sounds of tornadoes have been reported, mostly related to familiar sounds for the witness and generally some variation of a whooshing roar. Popularly reported sounds include a freight train, rushing rapids or waterfall, a nearby jet engine, or combinations of these. Many tornadoes are not audible from much distance; the nature of and the propagation distance of the audible sound depends on atmospheric conditions and topography.|$|R
40|$|Digital {{electronic}} control system developed for use in effecting accurate, real-time, closed-loop control of large acoustic test facility. Installation of system incorporates state-of-the-art technology to optimize shaping of <b>acoustic</b> <b>spectrum</b> and controlling operation of equipment in large reverberant chamber to degree not possible with open-loop manual control...|$|E
40|$|The paper {{analyzes}} the theoretical {{approaches to the}} study of the <b>acoustic</b> <b>spectrum</b> and the speed of sound absorption in the frequency range up to 10  GHz in liquid systems. For example ethoxylated derivatives of normal decyl alcohol EDDn, belonging to nonionic surfactants showed that at room temperature and low degrees of ethoxylation n acoustic spectra can be described in terms of the relaxation theory. It is shown that within the experimental error of the <b>acoustic</b> <b>spectrum</b> of EDDn, in the studied range of frequencies and temperature, are composed of two prime areas of acoustic dispersion. The results of calculations of relaxation and thermodynamic parameters of fast and ultrafast processes of restructuring EDDn can be used in the development of combined technologies of enhanced oil recovery using surfactant solutions and various physical fields and factors...|$|E
40|$|Solar flares {{are large}} explosions on the Sun's surface {{caused by a}} sudden release of {{magnetic}} energy. They are known to cause local short-lived oscillations travelling away from the explosion like water rings. Here we show that the energy in the solar <b>acoustic</b> <b>spectrum</b> is correlated with flares. This means that the flares drive global oscillations in the Sun {{in the same way}} that the entire Earth is set ringing for several weeks after a major earthquake like the December 2004 Sumatra-Andaman Earthquake. The correlation between flares and energy in the <b>acoustic</b> <b>spectrum</b> of disk-integrated sunlight is stronger for high-frequency waves than for ordinary p-modes which are excited by the turbulence in the near surface convection zone immediately beneath the photosphere. Comment: 6 pages, 5 figures. Accepted for publication in ApJ...|$|E
40|$|In {{this paper}} we {{describe}} a model {{developed for the}} analysis of <b>acoustic</b> <b>spectra.</b> Unlike decompositions techniques that can result in difficult to interpret results this model explicitly models spectra as distributions and extracts sets of additive and semantically useful components that facilitate a variety of applications ranging from source separation, denoising, music transcription and sound recognition. This model is probabilistic in nature and is easily extended to produce sparse codes, and discover transform invariant components which can be optimized for particular applications. ...|$|R
50|$|Tornadoes emit widely on the <b>acoustics</b> <b>spectrum</b> and {{the sounds}} are caused by {{multiple}} mechanisms. Various sounds of tornadoes have been reported, mostly related to familiar sounds for the witness and generally some variation of a whooshing roar. Popularly reported sounds include a freight train, rushing rapids or waterfall, a nearby jet engine, or combinations of these. Many tornadoes are not audible from much distance; the nature and propagation distance of the audible sound depends on atmospheric conditions and topography.|$|R
40|$|In this work, the {{long-term}} spectral contours {{of a large}} dataset of popular commercial recordings were analyzed. The aim was to analyze overall trends, as well as yearly and genre-speci c ones. A novel method for averaging spectral distributions is proposed, which yields results that are prone to comparison. With it, {{we found out that}} there is a consistent leaning towards a target equalization curve that stems from practices in the music industry, but also to some extent mimics natural, <b>acoustic</b> <b>spectra</b> of ensembles...|$|R
40|$|ABSTRACT: Audio {{processors}} like Audacity {{provide a}} ‘‘hear-and-see’ ’ learning tool for basic acoustics, combining sound and image. Activities designed as laboratory experiments with PC (even at home!) have been already successfully implemented, for example, about {{the dependence of}} timbre and <b>acoustic</b> <b>spectrum,</b> of pitch and frequency, and of loudness an...|$|E
40|$|Music {{provides}} us with a complex, rapidly changing <b>acoustic</b> <b>spectrum,</b> often derived from the superposition of sounds from many different sources. Our auditory system has the task of analyzing this spectrum so as to reconstruct the originating sound events. This {{is analogous to the}} task performed by our visual syste...|$|E
40|$|The {{inner ear}} {{has been shown}} to {{characterize}} an acoustic stimuli by transducing fluid motion in the inner ear to mechanical bending of stereocilia on the inner hair cells (IHCs). The excitation motion/energy transferred to an IHC is dependent on the frequency spectrum of the acoustic stimuli, and the spatial location of the IHC {{along the length of the}} basilar membrane (BM). Subsequently, the afferent auditory nerve fiber (ANF) bundle samples the encoded waveform in the IHCs by synapsing with them. In this work we focus on sampling of information by afferent ANFs from the IHCs, and show computationally that sampling at specific time instants is sufficient for decoding of time-varying <b>acoustic</b> <b>spectrum</b> embedded in the acoustic stimuli. The approach is based on sampling the signal at its zero-crossings and higher-order derivative zero-crossings. We show results of the approach on time-varying <b>acoustic</b> <b>spectrum</b> estimation from cricket call signal recording. The framework gives a time-domain and non-spatial processing perspective to auditory signal processing. The approach works on the full band signal, and is devoid of modeling any bandpass filtering mimicking the BM action. Instead, we motivate the approach from the perspective of event-triggered sampling by afferent ANFs on the stimuli encoded in the IHCs. Though the approach gives <b>acoustic</b> <b>spectrum</b> estimation but it is shallow on its complete understanding for plausible bio-mechanical replication with current mammalian auditory mechanics insights...|$|E
40|$|The {{long-term}} {{goal of the}} NASA/U. S. helicopter industry program designated 'Rotonet' is the achievement of a helicopter noise signature-prediction capability {{on the basis of}} helicopter geometry and operating condition data. A prediction-validation data base is being compiled through flight testing of an MDHC 500 E helicopter; the data base will encompass <b>acoustic</b> <b>spectra,</b> noise-level time histories, and effective perceived noise levels incorporating actual meteorological conditions and helicopter dynamics. An evaluation is made of the Rotonet system as currently defined, with a view to prospective developments...|$|R
40|$|A new {{approach}} {{to the problem of}} reduced description for Boltzmann-type systems is developed. It involves a direct solution of two main problems: thermodynamici ty and dynamic invariance of reduced description. A universal construction is introduced, which gives a thermodynamic parameterization of an almost arbitrary approximation. Newton-type procedures of successive approximations are developed which correct dynamic noninvariance. The method is applied to obtain corrections to the local Maxwell manifold uSlng parametrics expansions instead of Taylor series into powers of Knudsen number. In particular, the high frequency <b>acoustic</b> <b>spectra</b> is obtained. 1...|$|R
40|$|Acoustic phase (ensemble) {{averaged}} {{measurements were}} {{performed in a}} cold, axisymmetric, Mach number 0. 6 jet of air. These measurements show that the noise directly radiated by the coherent structure in the jet flow field {{was responsible for the}} directivity of the acoustic field. Comparison of phase averaged <b>acoustic</b> <b>spectra</b> with phase averaged radial velocity fluctuations within the jet illustrate the direct link between the two and show that different regions of the jet are responsible for producing the noise measured at various locations in the acoustic field...|$|R
40|$|International audienceIn many {{technical}} applications, like supersonic jets, noise with {{a characteristic}} spectrum including certain dominant frequencies (e. g. jet-screech) is prevalent, and {{the elimination of}} sharp peaks in the <b>acoustic</b> <b>spectrum</b> is the aim of active or passive flow/noise control efforts. A mathematical framework for the optimization of control strategies is introduced that uses a cost objective in frequency-space coupled to constraints in form of partial differential equations in the time domain. An iterative optimization scheme based on direct and adjoint equations arises, which has been validated on two examples, the one-dimensional Burgers equation and the two-dimensional compressible Navier-Stokes equations. In both cases, the iterative scheme has proven effective and efficient in targeting and removing specified frequency bands in the <b>acoustic</b> <b>spectrum.</b> It is expected that this technique will find use in acoustic and other applications where the elimination or suppression of distinct frequency components is desirable. © 2011...|$|E
40|$|We analyze {{more than}} 5000 days of Sun-as-a-star radial {{velocity}} GOLF and intensity VIRGO observations to measure the visibilities of the l= 0, 1, 2, and 3 modes and the m-amplitude ratios of the l= 2 and 3 modes in the solar <b>acoustic</b> <b>spectrum.</b> We provide observational values that we compare to theoretical predictions. Comment: SOHO 24 / GONG 2010 conference, {{to be published in}} JPC...|$|E
40|$|Results of an {{experimental}} investigation at the Ames 40 - by 80 -Foot Wind Tunnel of fan rotor alone discrete tone noise is presented. The investigation examines rotor interaction with fan inlet turbulence. The importance of turbulence length scale {{is shown by}} comparing the fan radiated <b>acoustic</b> <b>spectrum</b> with and without modified turbulence length scales. A small-scale low pressure ratio fan {{was used for the}} experiment...|$|E
40|$|This paper {{examines}} {{three different}} behavioral modalities of {{production in the}} human vocal tract: read speech, spontaneous speech and singing. We observe and quantify differences in planning and execution of these three behaviors. We use audio-synchronized real-time magnetic resonance imaging technology [1] to record speech and song data from 4 formally trained, professional sopranos. To ana-lyze the data, we propose fully automatic measures of average articulator speed, posture and <b>acoustic</b> <b>spectra</b> to analyze the data. Finally, we provide evidence that these different behavioral modalities involve speech planning mechanisms in different ways...|$|R
30|$|The three {{evaluation}} {{methods for}} treating longitudinal irregularity recordings, all of them examined for the same section of tram rail, show contrasting results: the most rigorous method, which leads to gain the <b>Acoustic</b> Roughness <b>Spectrum</b> to compare with some reference levels provided by standards, is not very useful since the tram rails have always significantly accentuated longitudinal irregularities. <b>Acoustic</b> roughness <b>spectrum</b> calculated for a tram rail is always over the standard limit spectrum. Therefore, new limits should be established ad hoc for the tram rails, which are subject to operating conditions that are much more critical than the railway rails ones.|$|R
40|$|Abstract- <b>Acoustic</b> {{resonance}} <b>spectra</b> {{were obtained}} experimentally for steel spheres and cylinders with hemispherical endcaps by acoustic backscattering (for cylinders: with both axial and oblique incidence). They were interpreted theoretically by surface wave propagation with phase matching over a closed path. The character of an elastic object immersed in {{water can be}} extracted form its acoustic scattering signal analytically /l / and experimentally / 2 - 4 /. In the present study, the echo amplitudes and <b>acoustic</b> resonance <b>spectra</b> for steel spheres and cylinders with hemispherical endcaps were obtained by numerical (gated Fourier) processing o £ experimental data fro...|$|R
