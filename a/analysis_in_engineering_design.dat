5|10000|Public
50|$|The {{probabilistic}} approach is considered {{as the most}} rigorous approach to uncertainty <b>analysis</b> <b>in</b> <b>engineering</b> <b>design</b> due to its consistency with the theory of decision analysis. Its cornerstone is the calculation of probability density functions for sampling statistics. This can be performed rigorously for random variables that are obtainable as transformations of Gaussian variables, leading to exact confidence intervals.|$|E
40|$|The {{computational}} cost {{associated with}} the use of high-fidelity Computational Fluid Dynamics (CFD) models poses a serious impediment to the successful application of formal sensitivity <b>analysis</b> <b>in</b> <b>engineering</b> <b>design.</b> Even though advances in computing hardware and parallel processing have reduced costs by orders of magnitude over the last few decades, the fidelity with which engineers desire to model engineering systems has also increased considerably. Evaluation of such high-fidelity models may take significant computational time for complex geometries. In many engineering design problems, thousands of function evaluations may be required to undertake a sensitivity analysis. As a result, CFD models are ofte...|$|E
40|$|AbstractThe {{computational}} cost {{associated with}} the use of high-fidelity computational fluid dynamics (CFD) models poses a serious impediment to the successful application of formal sensitivity <b>analysis</b> <b>in</b> <b>engineering</b> <b>design.</b> Even though advances in computing hardware and parallel processing have reduced costs by orders of magnitude over the last few decades, the fidelity with which engineers desire to model engineering systems has also increased considerably. Evaluation of such high-fidelity models may take significant computational time for complex geometries. In many engineering design problems, thousands of function evaluations may be required to undertake a sensitivity analysis. As a result, CFD models are often impractical to use for design sensitivity analyses. In contrast, surrogate models are compact and cheap to evaluate (order of seconds or less) and can therefore be easily used for such tasks. This paper discusses and demonstrates the application of several common surrogate modelling techniques to a CFD model of flocculant adsorption in an industrial thickener. Results from conducting sensitivity analyses on the surrogates are also presented...|$|E
40|$|The {{theory of}} system and design {{methodology}} as {{the sphere of}} concepts being objective mode {{can be applied to}} a more precise description, analysis and improvement of the methods of the real architectural design process. Lull's art as the primary idea of morphological analysis, has been acknowledged as to an element corresponding with the specificity of architectural design. From the architect's point of view it is worth studying the rules and peculiarities of morphological <b>analysis</b> methodology. <b>In</b> <b>engineering</b> <b>design</b> thus {{it may be possible to}} apply the methodology in architectural design...|$|R
40|$|Simulation {{models have}} {{importantly}} expanded the <b>analysis</b> capabilities <b>in</b> <b>engineering</b> <b>designs.</b> With larg-er computing power, more variables can be modeled to estimate their effect in ever-larger number of per-formance measures. Statistical experimental designs, however, are still somewhat {{focused on the}} variation of less than about a dozen variables. In this work, an effort to identify strategies to deal with tens of va-riables is undertaken. The aim {{is to be able}} to generate designs capable to estimate full-quadratic models. Several strategies are contrasted: (i) generate designs with random numbers, (ii) use designs already in the literature, and (iii) generate designs under a clustering strategy. The first strategy is an easy way to gen-erate a design. The second strategy does focus on statistical properties, but the designs become somewhat inconvenient to generate when increasing the number of variables. The third strategy is currently being investigated as a possibility to provide a balance between (i) and (ii). ...|$|R
40|$|In {{order to}} {{describe}} possible applications of modal interval <b>analysis</b> <b>in</b> early <b>engineering</b> <b>design,</b> let us start by briefly explaining what is interval computation {{and what is}} modal interval analysis. Direct and indirect measurements: uncertainty is ubiquitous. In practice, how do we obtain the numerical values of different physical quantities? For some quantities, we can obtain these values directly, either by performing a measurement or by eliciting the value from an expert. Measurements are never absolutely accurate; as a result, the result ˜x of the measurement is somewhat different from the actual (unknown) value x of the desired physical quantity: ˜x ̸ = x. In other words, from measurements, we can only determine the value x with uncertainty: the approximation error ∆x def = ˜x − x is, in general, different from 0. Expert estimates are usually even less accurate than measurements, so the values ˜x obtained from the experts also always contain uncertainty...|$|R
40|$|Shape {{optimization}} involving {{finite element}} <b>analysis</b> <b>in</b> <b>engineering</b> <b>design</b> is frequently hindered by the prohibitive cost of function evaluations. Reduced-order models based on proper orthogonal decomposition (POD) constitute an economical alternative. However the truncation of the POD basis implies {{an error in}} the calculation of the global values used as objectives and constraints which in turn affects the optimization results. In our former contribution (Xiao and Breitkopf, 2013), we have introduced a constrained POD projector allowing for exact linear constraint verification for a reduced order model. Nevertheless, this approach was limited a to relatively low numbers constraints. Therefore, in the present paper, we propose an approach for {{a high number of}} constraints. The main idea is to extend the snapshot POD by introducing a new constrained projector in order to reduce both the physical field and the constraint space. This allows us to search for the Pareto set of best compromises between the projection and the constraint verification errors thereby enabling fine-tuning of the reduced model for a particular purpose. We illustrate the proposed approach with the reduced order model of the flow around an airfoil parameterized with shape variables. SCOPUS: ar. jSCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|E
40|$|The {{flexibility}} coefficient is popularly used {{to implement the}} macroevaluation of shape, safety, and economy for arch dam. However, the description of {{flexibility coefficient}} has not drawn a widely consensus all the time. Based on {{a large number of}} relative instance data, the relationship between influencing factor and flexibility coefficient is analyzed by means of partial least-squares regression. The partial least-squares regression equation of flexibility coefficient in certain height range between 30 [*]m and 70 [*]m is established. Regressive precision and equation stability are further investigated. The analytical model of statistical flexibility coefficient is provided. The flexibility coefficient criterion is determined preliminarily to evaluate the shape of low- and medium-sized arch dam. A case study is finally presented to illustrate the potential engineering application. According to the analysis result of partial least-squares regression, it is shown that there is strong relationship between flexibility coefficient and average thickness of dam, thickness-height ratio of crown cantilever, arc height ratio, and dam height, but the effect of rise-span ratio is little relatively. The considered factors in the proposed model are more comprehensive, and the applied scope is clearer than that of the traditional calculation methods. It is more suitable for the analogy <b>analysis</b> <b>in</b> <b>engineering</b> <b>design</b> and the safety evaluation for arch dam...|$|E
40|$|Abstract. Cast-steel joints {{characterized}} {{in strong}} adaptability are widely applied in various long span spatial structures. At present, {{there is no}} national design specification available on cast-steel joints. Therefore, {{it is quite a}} necessity to conduct full-scale test or model test on cast-steel joints suffering complicated forces. This Paper has, taking Nantong Sports Exhibition Center as an example, conducted the experimental study of some important joints, and compared with elastic-plastic nonlinear finite element analysis result. According to the result, the fracture morphology of joints, stress distribution and bearing capacity of joints obtained from the elastic-plastic nonlinear finite element analysis are consistent with those of measured result, proving that the <b>analysis</b> theory applied <b>in</b> <b>engineering</b> <b>design</b> is basically suitable for the actual working condition of cast-steel joints and the joints are sufficiently safe...|$|R
40|$|The {{simulation}} of advanced high-strength steel sheet (AHSS) stamping processes {{by means of}} dedicated computer-aided engineering (CAE) software {{requires the use of}} appropriate material models, the use of complex FEM models, and the use of advanced methods for solving nonlinear problems of their <b>analysis.</b> <b>In</b> practice, the <b>engineering</b> <b>design</b> of automotive body parts often leads to the formulation of problems, the solution of which requires ample computer resources and is very time-consuming. The paper describes a methodology to simulate stamping on the example of a car body part, with special attention being paid to the numerical efficiency of the FEM model and methods of solving it. The simulations of stamping of a sample stamped part—the automotive body part—in DynaForm and AutoForm programs are compared, focusing on the numerical effectiveness and consistency of the simulation results with the reality...|$|R
40|$|The {{development}} of reliability-based design methods requires {{the use of}} general-purpose engineering analysis tools that predict the uncertainty in a response due to uncertainties in the model formulation and input parameters. Barriers that have prevented the full acceptance of probabilistic <b>analysis</b> methods <b>in</b> the <b>engineering</b> <b>design</b> community include availability of tools, ease of use, robust and accurate probabilistic analysis methods, and the ability to perform probabilistic analyses for large-scale problems. The goal of the reported work has been to develop a software tool that fully addresses these three aspects (availability, robustness and efficiency) to enable the designer to efficiently and accurately account for uncertainties as they might affect structural reliability and risk assessment. The paper discusses the NESSUS probabilistic engineering analysis software with specific sections on the reliability modeling and <b>analysis</b> process <b>in</b> NESSUS, the robust and accurate solution strategies incorporated in the available probabilistic analysis methods, and several application examples to demonstrate the applicability of probabilistic analysis to large-scale engineering problems...|$|R
40|$|The {{application}} of reliability <b>analysis</b> <b>in</b> civil <b>engineering</b> {{is still an}} emerging technology, more so <b>in</b> geotechnical <b>engineering</b> {{and even more so}} in application to river dikes. However, much experience remains to be gained, recently, especially in European countries (the Netherlands, Germany, United Kingdom 8 ̆ 5) {{as well as in the}} United States of America. This paper focuses, only, on the general framework of reliability <b>analysis</b> <b>in</b> geotechnical <b>engineering</b> <b>design</b> and an example for river dike reliability analysis is illustrated. Reliability analysis is related to some other terminology such as: risk assessment, probabilistic design 8 ̆ 5 etc but they all deal with analyzing the relevant uncertain parameters. Theoretically, the limit state function is defined as: Z = R-S; where: Z is the limit state function; R: strength; S: load. Both R and S combine many uncertainties, for instance, the inherent and epistemic uncertainty. The determination of the probability of function Z< 0 with random variables (uncertainty) is the goal of reliability <b>analysis.</b> <b>In</b> the light of reliability analysis, a river dike ring is examined as a series system with many dike sections which have similar characters (geometry, geotechnical condition, protection area 8 ̆ 5 etc). Considering each dike reach, there are several failure mechanisms such as instability, under seepage, erosion 8 ̆ 5 etc, so all of them contribute to the dike breach probability with different levels. Practically, an example for a Red river dike section analysis is shown with some reliability methods (FOSM, level 3, fault tree 8 ̆ 5 etc) and the joint probability function for dike segments is formulated. Water ManagementCivil Engineering and Geoscience...|$|R
40|$|ABSTRACT Integration of Failure Modes and Effects <b>Analysis</b> (FMEA) <b>in</b> the <b>Engineering</b> <b>Design</b> Process Hua-wei Wen Failure modes {{and effects}} {{analysis}} (FMEA) {{is one of}} the most practical design tools implemented in the product design to analyze the potential failures and to improve the design. The practice of FMEA is diversified and different approaches are proposed by different organizations and researchers from one application to another. Yet, the question is how to systematically utilize the features of FMEA along with the design process. This thesis aims to integrate different types of FMEA in the design process, which is considered as the mapping between customer requirements, product functions, and design components. These three design elements are the foundation of the integration model proposed in this thesis. The objective of this thesis is to develop an integration approach of FMEA in the design process. Particularly, an integration framework is developed to integrate FMEA and design process. Then, a step-by-step FMEA-facilitated design process is proposed to apply FMEA along with the design process. In the end, a detailed case study of a smartphone model is conducted to demonstrate and verify the proposed methodology. The expectedly benefits of the proposed methodology are the consistency of failure analysis information, and the utilization of the failure analysis information from one stage to the later stages of the design process. ...|$|R
50|$|The first {{assumption}} is often {{but not always}} valid and should be tested {{on a case by}} case basis. The second {{assumption is}} often valid if the extreme events are observed under similar climate conditions. For example, if the extreme events on record all come from late summer thunder storms (as is the case in the southwest U.S.), or from snow pack melting (as is the case in north-central U.S.), then this assumption should be valid. If, however, there are some extreme events taken from thunder storms, others from snow pack melting, and others from hurricanes, then this assumption is most likely not valid. The third assumption is only a problem when trying to forecast a low, but maximum flow event (for example, an event smaller than a 2-year flood). Since this is not typically a goal <b>in</b> extreme <b>analysis,</b> or <b>in</b> civil <b>engineering</b> <b>design,</b> then the situation rarely presents itself. The final assumption about stationarity is difficult to test from data for a single site because of the large uncertainties in even the longest flood records (see next section). More broadly, substantial evidence of climate change strongly suggests that the probability distribution is also changing and that managing flood risks in the future will become even more difficult. The simplest implication of this is that not all of the historical data are, or can be, considered valid as input into the extreme event analysis.|$|R
40|$|Machineries, vehicles, {{ships and}} airliners have {{numerous}} components that inevitably have stress concentrations. These concentrations are mainly due to abrupt geometrical alteration caused by manufacturing processes and design. The magnitude of a stress concentration {{depends on the}} geometry, loading and interaction between two distinct geometrical features. Geometrical discontinuities occur in numerous forms; mostly as external surface notch or subsurface defects e. g., circular or elliptical porosities or inclusions. These surface and subsurface defects have long been identified as detrimental factors which reduce the fatigue life of components. To avoid catastrophic failures related to stress concentrations, detailed <b>analysis</b> of them <b>in</b> <b>engineering</b> <b>design</b> is required. This thesis focuses on the interaction of stress concentrations between a surface notch and a subsurface porosity. The motivation behind this thesis work has been the unavailability of related studies despite of its significance. The thesis work uses a stress averaging method of the tangential stress component to determine the maximum interacting stress concentration factors of semi-circular notch-hole and equivalent elliptical notch-hole configurations in a semi-infinite plate. The study of the maximum stress concentration factor of the notch-hole configurations uses global and local stress averaging techniques that strongly depend {{on the extent of}} notch-hole gap distances. Three cases with relative notch-hole radii ratios of 20 : 1, 10 : 1, and 1 : 1 are investigated to determine the interacting stresses concentration factors with subsequent gap increments. In addition, the developed method is further utilized to analyse the interacting stress concentration factors of an equivalent elliptical notch and a hole that represents surface roughness with a subsurface porosity. The results of this work are compared with analytical solutions for two interacting holes and finite element simulations carried out using Abaqus simulation software. Based on the results, the stress averaging methods can be used to analyse the interacting stress concentration factors of notch-hole configurations with a specified range of gaps. The limitations of estimations using stress averaging approach are observed when the notch-hole gap is substantially reduced. The differences between the results obtained using stress averaging and the corresponding benchmarks of two holes solutions as well as finite element simulations are discussed. The study also discusses the limitations of using the stress averaging method in determining the interacting stress concentrations between semi-circular notch-hole and equivalent elliptical notch-hole configurations. In this study, porosity is represented by a circular hole. As the thesis is a single case of study in terms of relative notch-hole orientation, there is a variety of further study possibilities that could incorporate different notch-hole arrangements, loading conditions and varying material properties, which are suggested as possible future works...|$|R
5000|$|... #Subtitle level 3: Traction {{coefficient}} <b>in</b> <b>engineering</b> <b>design</b> ...|$|R
5000|$|Booker, Peter Jeffrey. Principles and {{precedents}} <b>in</b> <b>Engineering</b> <b>Design.</b> Institute of <b>Engineering</b> Designers, 1962.|$|R
50|$|For {{leadership}} <b>in</b> <b>engineering</b> <b>design</b> {{and construction}} of SpaceShipOne, Voyager, and other successful experimental aircraft.|$|R
50|$|For his {{distinguished}} and pioneering contributions <b>in</b> <b>engineering</b> <b>design</b> {{and development}} of advanced military and commercial aircraft.|$|R
5000|$|NANA WorleyParsons, {{based in}} Anchorage, Alaska, specializes <b>in</b> <b>engineering,</b> <b>design</b> and project {{management}} in the petroleum sector.|$|R
40|$|Soft {{computing}} embraces methodologies for {{the development}} of intelligent systems that have been successfully applied to a large number of real world problems. This collection of keynote papers, presented at the 7 th On-line World Conference on Soft Computing <b>in</b> <b>Engineering</b> <b>Design</b> and Manufacturing, provides a comprehensive overview of recent advances in fuzzy, neural and evolutionary computing techniques and applications <b>in</b> <b>engineering</b> <b>design</b> and manufacturing. " [...] back cover...|$|R
40|$|Methods for {{incorporating}} imprecision <b>in</b> <b>engineering</b> <b>design</b> decision-making are briefly {{reviewed and}} compared. A tutorial is presented on the Method of Imprecision (MoI), a formal method, {{based on the}} mathematics of fuzzy sets, for representing and manipulating imprecision <b>in</b> <b>engineering</b> <b>design.</b> The results of a design cost estimation example, utilizing a new informal cost specification, are presented. The MoI can provide formal information upon which to base decisions during preliminary <b>engineering</b> <b>design</b> and can facilitate set-based concurrent design. Introduction One {{of the most critical}} problems <b>in</b> <b>engineering</b> <b>design</b> is making early decisions on a sound basis. However, the early stages of design are also the most uncertain, and obtaining precise information upon which to base decisions is usually impossible. The primary reason for this difficulty is that imprecision {{is an integral part of}} the <b>engineering</b> <b>design</b> process. Not imprecision in thought or logic, but rather the intrinsic [...] ...|$|R
50|$|Early {{work was}} mainly within {{the domains of}} {{architecture}} and industrial <b>design,</b> but research <b>in</b> <b>engineering</b> <b>design</b> developed strongly <b>in</b> the 1980s; for example, through ICED - the series of International Conferences on <b>Engineering</b> <b>Design,</b> now run by The Design Society. These developments were especially strong in Germany and Japan. In the USA there were also some important developments in design theory and methodology, including the publications of the Design Methods Group and the series of conferences of the Environmental Design Research Association. The National Science Foundation initiative on design theory and methods led to substantial growth <b>in</b> <b>engineering</b> <b>design</b> research <b>in</b> the late-1980s. A particularly significant development was {{the emergence of the}} first journals of design research. DRS initiated Design Studies in 1979, Design Issues appeared in 1984, and Research <b>in</b> <b>Engineering</b> <b>Design</b> <b>in</b> 1989.|$|R
5000|$|J. Edward Colgate, Professor, Mechanical Engineering, Breed Senior Professor in Design, and Director, Master of Science <b>in</b> <b>Engineering</b> <b>Design</b> Innovation program ...|$|R
40|$|This paper {{describes}} {{an approach to}} a more systematic and goal directed way of handling knowledge <b>in</b> educational <b>Engineering</b> <b>Design</b> projects. Knowledge is the main resource to be generated, acquired, and exchanged in project teaching and learning. <b>In</b> <b>Engineering</b> <b>Design</b> knowledge management is, like generally in modern conceptions of management and organisation, of increasing importanc...|$|R
40|$|Through the TIDEE (Transferable Integrated <b>Design</b> <b>Engineering</b> Education) project, {{assessment}} tools and performance criteria {{have been developed}} to quantify student achievement <b>in</b> the <b>engineering</b> <b>design</b> process, teamwork skills, and design communication skills. A sevenpoint scale describes performance levels spanning from entering engineering students to professional design engineers. Mid-program {{assessment tools}} were used to assess student achievement of <b>engineering</b> <b>design</b> capabilities during introductory classes <b>in</b> <b>engineering</b> <b>design.</b> Assessment results describe the level of a typical entering student's knowledge and performance <b>in</b> <b>engineering</b> <b>design.</b> These results also indicate that students can reach <b>engineering</b> <b>design</b> achievement targets set for the mid-point of an engineering degree program when the preparatory learning environment is a well-structured outcomes-based design curriculum. During the past few years engineering faculty have created many new introductory and intermedi [...] ...|$|R
5000|$|Product {{standardization}} is {{a technique}} <b>in</b> <b>engineering</b> <b>design</b> that aim {{to reduce the number}} of different parts within a product. The benefits are: ...|$|R
40|$|Negotiations {{are common}} <b>in</b> <b>engineering</b> <b>design,</b> {{especially}} on large projects, and are typically conducted informally. Often, negotiation {{is used to}} handle the imprecision or uncertainty that {{is inherent in the}} design process. Performance targets, initially specified as hard numerical constraints, are adjusted throughout the design process in negotiations between engineers and managers. Crucial unmeasured or unmeasurable aspects of performances, such as aesthetic concerns, are commonly negotiated. Negotiations settle conflicts between engineering groups over values of shared design variables and distribution of limited design resources. In this thesis, a formal description of negotiation <b>in</b> <b>engineering</b> <b>design</b> is presented. This formal model builds on earlier work at Caltech in the modelling of imprecision <b>in</b> <b>engineering</b> <b>design.</b> Negotiation is modelled mathematically as the aggregation of preferences. A complete characterization of the aggregation problem and of the aggregation operators [...] ...|$|R
40|$|Abstract: In {{order to}} improve the {{conditions}} for utilization of Shape Memory Alloys (SMAs) <b>in</b> <b>engineering</b> <b>design,</b> the <b>engineering</b> <b>design</b> process and the shape memory effect have been studied {{from the viewpoint of}} the engineering design-er. Further, the maturity of the SMA technology has been evaluated according to a common evaluation technique denoted the technology readiness assessment. The results obtained in this paper confirm that SMAs introduce unacceptable un-certainties <b>in</b> the <b>engineering</b> <b>design</b> process. It is shown that the SMA technology is still not sufficiently mature to be utilized <b>in</b> <b>engineering</b> <b>design.</b> Based on the requirement that the SMA technology must be upgraded to a level satisfying the conditions set by the technology readiness assessment, this paper presents fundamental objectives for future research involving a closer collaboration between researchers from the fields of material technology and <b>engineering</b> <b>design.</b> 1...|$|R
5000|$|Orsborn, Seth, Peter Boatwright and Jonathan Cagan (2008) “Identifying Product Shape Relationships Using Principal Component Analysis” Research <b>in</b> <b>Engineering</b> <b>Design,</b> 18, 4 (Jan), 163-180. Abstract ...|$|R
40|$|The {{purpose of}} this study is to {{consider}} how to use an electronic learning (e-learning) system <b>in</b> <b>engineering</b> <b>design.</b> An e-learning trial <b>in</b> an <b>engineering</b> <b>design</b> course was introduced as an online self-study module in order to support learning outside of the classroom at the Kanazawa Institute of Technology. This paper contains a description of the e-learning system and the related student activities an...|$|R
5000|$|Bachelor of <b>Engineering</b> <b>in</b> Electronic <b>Design</b> <b>Engineering</b> (Herning) ...|$|R
50|$|Shortcuts <b>in</b> <b>{{engineering}}</b> <b>design</b> {{can lead}} to engineering disasters. Engineering is the science and technology used {{to meet the needs}} and demands of society. These demands include buildings, aircraft, vessels, and computer software. In order to meet society’s demands, the creation of newer technology and infrastructure must be met efficiently and cost-effectively. To accomplish this, managers and engineers have to have a mutual approach to the specified demand at hand. This {{can lead to}} shortcuts <b>in</b> <b>engineering</b> <b>design</b> to reduce costs of construction and fabrication. Occasionally, these shortcuts can lead to unexpected design failures.|$|R
50|$|The {{algorithms}} {{used to calculate}} the distribution of light energy between surfaces of a scene are closely related to heat transfer simulations performed using finite-element methods <b>in</b> <b>engineering</b> <b>design.</b>|$|R
40|$|Knowledge Management Systems (KMS) {{have been}} {{developed}} <b>in</b> <b>Engineering</b> <b>Design</b> activities <b>in</b> order to improve the productivity of these activities. Nevertheless it is still very difficult to identify the impact of such Systems on the <b>Engineering</b> <b>Design</b> Performance. <b>In</b> this paper {{our goal is to}} present why valuing Knowledge Management Impact on <b>Engineering</b> <b>Design</b> is today a challenge. In a first part we aim at presenting how and why Knowledge Management has been introduced <b>in</b> <b>Engineering</b> <b>Design</b> Activities. By {{a review of the literature}} from a span of disciplines we will next focus on the different ways to value the impact of Knowledge Management Systems on firm activities. At least we will propose a method to monitor the impact of Knowledge Management Systems on <b>Engineering</b> <b>Design</b> Activities...|$|R
50|$|TTC {{opened in}} June 1977, and {{is located in}} Ann Arbor, Michigan. TTC employs 728 people in four states. The company is engaged <b>in</b> <b>engineering</b> <b>design</b> and {{research}} and development.|$|R
