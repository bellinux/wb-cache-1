2431|1432|Public
25|$|A general {{upper bound}} for the <b>approximation</b> <b>error</b> in the central limit theorem is given by the Berry–Esseen theorem, {{improvements}} of the approximation are given by the Edgeworth expansions.|$|E
25|$|An {{important}} part of the analysis of any numerical integration method is to study the behavior of the <b>approximation</b> <b>error</b> {{as a function of the}} number of integrand evaluations.|$|E
25|$|An {{algorithm}} {{has been}} proposed for identifying a representative subset of summary statistics, by iteratively assessing whether an additional statistic introduces a meaningful modification of the posterior. One of the challenges here is that a large ABC <b>approximation</b> <b>error</b> may heavily influence the conclusions about the usefulness of a statistic at any stage of the procedure. Another method decomposes into two main steps. First, a reference approximation of the posterior is constructed by minimizing the entropy. Sets of candidate summaries are then evaluated by comparing the ABC-approximated posteriors with the reference posterior.|$|E
40|$|This paper <b>approximation</b> <b>errors</b> are {{introduced}} in a Luca (1978) -type model to reflect model uncertainty. The purpose is twofold. First, the rational investor {{is allowed to}} take model uncertainty into account when asset prices are determined. Second, the statistical degeneracy, common to most structural models, is broken and maximum likehood inference made possible. The model is estimated using U. S. stock data. The equilibrium price is seriously affected by the existence of <b>approximation</b> <b>errors</b> and the descriptive and normative properties are greatly improved. This suggest that investors do {{not and should not}} ignore <b>approximation</b> <b>errors.</b> <b>Approximation</b> errors; rationality; structural estimation; risk premium; asset pricing...|$|R
50|$|<b>Approximation</b> <b>errors</b> {{due to the}} {{selection}} of numerical integration algorithm.|$|R
40|$|Abstract. In {{this paper}} we Studied the {{polynomial}} coefficients and <b>approximation</b> <b>errors</b> for {{functions of the}} form f(z) = ∑ ∞ k= 1 qk(z) [γ(z) ] k− 1 belong to L s (B), the class of all functions holomorphic on Caratheödory domain B. The lower (p, q) -order and generalized lower (p, q) -type with respect to proximate order have been characterized in terms of these polynomial coefficients and <b>approximation</b> <b>errors...</b>|$|R
500|$|It is {{not known}} {{precisely}} how the exact value for the magic number was determined. [...] Chris Lomont developed a function to minimize <b>approximation</b> <b>error</b> by choosing the magic number R over a range. He first computed the optimal constant for the linear approximation step as 0x5F37642F, close to 0x5F3759DF, but this new constant gave slightly less accuracy after one iteration of Newton's method. Lomont then searched for a constant optimal even after one and two Newton iterations and found 0x5F375A86, which is more accurate than the original at every iteration stage. He concluded by asking whether the exact value of the original constant was chosen through derivation or trial and error. [...] Lomont {{pointed out that the}} magic number for 64 bit IEEE754 size type double is 0x5FE6EC85E7DE30DA, but it was later shown by Matthew Robertson to be exactly 0x5FE6EB50C7B537A9.|$|E
2500|$|... {{which is}} the <b>approximation</b> <b>error</b> when {{approximating}} f with its Taylor polynomial. Using the little-o notation the statement in Taylor's theorem reads as ...|$|E
2500|$|Theoretically, the {{interpolation}} formula {{can be implemented}} as a low pass filter, whose impulse response is sinc(t/T) and whose input is [...] which is a Dirac comb function modulated by the signal samples. Practical digital-to-analog converters (DAC) implement an approximation like the zero-order hold. In that case, oversampling can reduce the <b>approximation</b> <b>error.</b>|$|E
40|$|AbstractThe {{discussion}} {{is devoted to}} the adaptive H∞ control method based on RBF neural networks for uncertain nonlinear systems in this paper. The controller consists of an equivalent controller and an H∞ controller. The RBF neural networks are used to approximate the nonlinear functions and the <b>approximation</b> <b>errors</b> of the neural networks are used in the adaptive law to improve the performance of the systems. The H∞ controller is designed for attenuating the influence of external disturbance and neural network <b>approximation</b> <b>errors.</b> The controller can not only guarantee stability of the nonlinear systems, but also attenuate the effect of the external disturbance and neural networks <b>approximation</b> <b>errors</b> to reach performance indexes. Finally, an example validates the effectiveness of this method...|$|R
40|$|In {{this paper}} some further {{work is done}} {{following}} the idea introduced by Parloo et all [2] where they proposed that the scaling factor should be estimated by repeated testing introducing mass changes in different points on the structure. In this paper the approximate formula for determination of the scaling factor based on the frequency shift when introducing mass changes on the structure is derived directly from the governing equation of motion. Further the error sources are studied and a new formula introducing less <b>approximation</b> <b>errors</b> on the scaling factor is proposed. Using this new formula scaling factors can be estimated from relative large frequency shifts without introducing any <b>approximation</b> <b>errors.</b> Further it is explained how testing should be performed in order to significantly reduce <b>approximation</b> <b>errors</b> due to mode shape changes and random errors due to uncertainty on the mode shape values. It turns out that if the mass changes are well distributed over the structure, then both random <b>errors</b> and the <b>approximation</b> <b>errors</b> will be minimized. Notation Mass matrix M Stiffness matrix K Un-scaled mode shape φ Scaled mode shape ψ Natural frequency ω Standard deviation σ Number of DOF’s N 1...|$|R
3000|$|This Greens {{function}} (17) is {{no longer}} harmonic and harmonic FMM cannot be used. One obvious option {{is to use the}} more general Cartesian FMM of Appendix A. 1 (Dehnen [2002]). The computational costs of this approach grow faster with expansion order p, such that small <b>approximation</b> <b>errors</b> (requiring high p) become significantly more expensive. However, small <b>approximation</b> <b>errors</b> are hardly required in situations where gravitational softening is employed. Alternatively, if softening is restricted to a finite region, i.e. if [...]...|$|R
2500|$|Multiplication with a {{rectangular}} {{window in the}} time domain corresponds to convolution with a [...] function in the frequency domain, resulting in spurious ringing artifacts for short/localized temporal windows. With the continuous-time Fourier Transform, [...] and this convolution is with a delta function in Fourier space, resulting in the true Fourier transform of the signal [...] The window function may be some other apodizing filter, such as a Gaussian. The choice of windowing function will affect the <b>approximation</b> <b>error</b> relative to the true Fourier transform.|$|E
2500|$|In calculus, Taylor's theorem {{gives an}} {{approximation}} of a k-times differentiable function around a given point by a k-th order Taylor polynomial. For analytic functions the Taylor polynomials {{at a given}} point are finite order truncations of its Taylor series, which completely determines the function in some neighborhood of the point. The exact content of [...] "Taylor's theorem" [...] is not universally agreed upon. Indeed, there are several versions of it applicable in different situations, {{and some of them}} contain explicit estimates on the <b>approximation</b> <b>error</b> of the function by its Taylor polynomial.|$|E
2500|$|Taylor's theorem is of {{asymptotic}} nature: it only {{tells us}} that the error Rk in an approximation by a k-th order Taylor polynomial Pk tends to zero faster than any nonzero k-th degree polynomial as x→a. It does not tell us how large the error is in any concrete neighborhood of the center of expansion, but for this purpose there are explicit formulae for the remainder term (given below) which are valid under some additional regularity assumptions on f. These enhanced versions of Taylor's theorem typically lead to uniform estimates for the <b>approximation</b> <b>error</b> in a small neighborhood of the center of expansion, but the estimates do not necessarily hold for neighborhoods which are too large, even if the function f is analytic. In that situation one may have to select several Taylor polynomials with different centers of expansion to have reliable Taylor-approximations of the original function (see animation on the right.) ...|$|E
40|$|Rational {{expectations}} models make stringent assumptions on the agent’s {{knowledge about}} the true model. This paper introduces a model in which the rational agent realizes that using a given model involves <b>approximation</b> <b>errors,</b> and adjusts behavior accordingly. If the researcher accounts for this empirical rationality on part of the agent, the resulting empirical model assigns likelihood to the data actually observed, unlike in the unmodified rational expectations case. A Lucas (1978) -type asset pricing model which incorporates empirical rationality is constructed and estimated using U. S. stock data. The equilibrium asset pricing function is seriously affected by the existence of <b>approximation</b> <b>errors</b> and the descriptive properties and normative implications of the model are significantly improved. This suggests that investors do not — and should not — ignore <b>approximation</b> <b>errors.</b> Keywords: pricing. Structural estimation, rationality, model uncertainty, asse...|$|R
30|$|Using {{the above}} lemmas and {{following}} the same lines as the proof of Theorem  4.1 in [35], we obtain the main result concerning the <b>approximation</b> <b>errors.</b>|$|R
50|$|The {{effect of}} <b>approximation</b> <b>errors</b> {{can be reduced}} by using a more {{accurate}} numerical integration algorithm than rectangular integration (e.g., trapezoidal integration) in the DDA integrators.|$|R
2500|$|All of the FFT {{algorithms}} {{discussed above}} compute the DFT exactly (i.e. neglecting floating-point errors). A few [...] "FFT" [...] algorithms have been proposed, however, that compute the DFT approximately, with an error {{that can be}} made arbitrarily small at the expense of increased computations. Such algorithms trade the <b>approximation</b> <b>error</b> for increased speed or other properties. For example, an approximate FFT algorithm by Edelman et al. (1999) achieves lower communication requirements for parallel computing {{with the help of a}} fast multipole method. A wavelet-based approximate FFT by Guo and Burrus (1996) takes sparse inputs/outputs (time/frequency localization) into account more efficiently than is possible with an exact FFT. Another algorithm for approximate computation of a subset of the DFT outputs is due to Shentov et al. (1995). The Edelman algorithm works equally well for sparse and non-sparse data, since it is based on the compressibility (rank deficiency) of the Fourier matrix itself rather than the compressibility (sparsity) of the data. Conversely, if the data are sparse—that is, if only K out of N Fourier coefficients are nonzero—then the complexity can be reduced to O(Klog(N)log(N/K)), and this has been demonstrated to lead to practical speedups compared to an ordinary FFT for N/K>32 in a large-N example (N=222) using a probabilistic approximate algorithm (which estimates the largest K coefficients to several decimal places).|$|E
5000|$|The <b>approximation</b> <b>error</b> in {{some data}} is the {{discrepancy}} between an exact value and some approximation to it. An <b>approximation</b> <b>error</b> can occur because ...|$|E
5000|$|... #Subtitle level 2: <b>Approximation</b> <b>error</b> {{bounds of}} quasi-Monte Carlo ...|$|E
40|$|We {{propose a}} novel {{methodology}} {{for evaluating the}} accuracy of numeri-cal solutions to dynamic economic models. Speci 8 ̆ 5 cally, we construct a lower bound {{on the size of}} <b>approximation</b> <b>errors.</b> A small lower bound on errors is a necessary condition for accuracy: If a lower error bound is unacceptably large, then the actual <b>approximation</b> <b>errors</b> are even larger, and hence, we reject the hypothesis that a numerical solution is accurate. Our accuracy analysis is logically equivalent to hypothesis testing in statistics. As an il-lustration of our methodology, we assess <b>approximation</b> <b>errors</b> in the 8 ̆ 5 rst-and second-order perturbation solutions for two stylized models: a neoclas-sical growth model and a new Keynesian model. The errors are small for the former model but unacceptably large for the latter model under some empirically relevant parameterizations. JEL classification: C 61, C 63, C 68, E 31, E 52 Key Words: approximation errors; best case scenario, error bounds, Euler equation residuals; accuracy; numerical solution; algorithm; new Key-nesian mode...|$|R
40|$|This paper studies asset returns {{adopting}} {{an alternative}} strategy to assess a model s goodness of fit. Based on spectral analysis, this approach considers a model as an approximation {{to the process}} generating the observed data, and characterizes the dimensions for which the model provides a good approximation and those for which it does not. Our aim is to offer new evidence regarding the size {{and the location of}} <b>approximation</b> <b>errors</b> of a set of stochastic growth models considered to be decisive steps in the progress of the asset pricing research program. Our specific objective is to reevaluate the results of Jermann s (1998) model extending the calculations to the spectral domain. Spectral results are relatively satisfactory: the benchmark model needs very few contributions of <b>approximation</b> <b>errors</b> to account for the empirical equity premium. Second, the location of the <b>approximation</b> <b>errors,</b> when they are substantial, seems to be essentially concentrated at high frequencies. ...|$|R
3000|$|..., where u is the {{predicted}} displacement over the domain Ω. The error estimator is denoted by η. We follow {{the theory of}} constitutive relation error (CRE) proposed by P. Ladevèze [22]. This kind of a posteriori error has been developed for a large set of constitutive equations [9, 23 - 26]. Although constitutive relation error (CRE) can handle all <b>approximation</b> <b>errors</b> due to time discretization, FE approximation, and eventually a separated representation of the displacements [27], we restrict our attention to <b>approximation</b> <b>errors</b> due to the additional assumptions incorporated in the numerical model by the hyper-reduced formulation. Here, the CRE η requires the construction of stresses fulfilling FE equilibrium equations.|$|R
5000|$|The <b>approximation</b> <b>error</b> {{is the sum}} of the {{remaining}} coefficients ...|$|E
5000|$|... {{when given}} {{the amount of}} basis M, {{minimize}} <b>approximation</b> <b>error</b> in mean-square sense ...|$|E
5000|$|Theorem (Optimality of Karhunen-Loève Basis). Let [...] be acovariance operator. For all , the <b>approximation</b> <b>error</b> ...|$|E
40|$|This paper {{suggests}} {{a method for}} determining rigorous upper bounds on <b>approximation</b> <b>errors</b> of numerical solutions to infinite horizon dynamic programming models. Bounds are provided for approximations of the value function and the policy function {{as well as the}} derivatives of the value function. The bounds apply to more general problems than existing bounding methods do. For instance, since strict concavity is not required, linear models and piecewise linear approximations can be dealt with. Despite the generality, the bounds perform well in comparison with existing methods even when applied to approximations of a standard (strictly concave) growth model. KEYWORDS: Numerical <b>approximation</b> <b>errors,</b> Bellman contractions, Error bound...|$|R
40|$|AbstractThe crude {{global search}} {{that is used}} in {{parameter}} space investigation provides approximations to the set of efficient points. Estimates of <b>approximation</b> <b>errors</b> are established and numerical examples confirm these estimates. The investigated examples {{can be used as}} tests for various numerical methods...|$|R
50|$|For smooth functions, the <b>approximation</b> <b>errors</b> made at {{each step}} are {{proportional}} to the square h2 of the width h of the input intervals. For this reason, affine arithmetic will often yield much tighter bounds than standard interval arithmetic (whose errors are proportional to h).|$|R
5000|$|The <b>approximation</b> <b>error</b> {{by using}} the {{simplified}} linear formula will increase as the angle increases. For example, a ...|$|E
5000|$|The Local/Neighborhood Approximation of Fuzzy Memberships is a {{procedure}} {{to minimize the}} Local/Neighborhood <b>Approximation</b> <b>Error</b> (LAE/NAE) defined as the following: ...|$|E
5000|$|... {{which is}} the <b>approximation</b> <b>error</b> when {{approximating}} f with its Taylor polynomial. Using the little-o notation the statement in Taylors theorem reads as ...|$|E
40|$|Abstract: In {{this paper}} we present some results on {{theoretical}} and numerical investigation of combined finite element/finite superelement <b>approximations.</b> <b>Error</b> estimates for one variant {{of this method}} for Laplace equation are presented. Some numerical results for velosity skin-layer problem are presented. Note: Publication language:russia...|$|R
40|$|AbstractQuasi-interpolation of radial basis {{functions}} on finite grids is a {{very useful}} strategy in approximation theory and its applications. A notable strongpoint of the strategy is to obtain directly the approximants without the need to solve any linear system of equations. For radial basis functions with Gaussian kernel, {{there have been more}} studies on the interpolation and quasi-interpolation on infinite grids. This paper investigates the approximation by quasi-interpolation operators with Gaussian kernel on the compact interval. The <b>approximation</b> <b>errors</b> for two classes of function with compact support sets are estimated. Furthermore, the <b>approximation</b> <b>errors</b> of derivatives of the approximants to the corresponding derivatives of the approximated functions are estimated. Finally, the numerical experiments are presented to confirm the accuracy of the approximations...|$|R
40|$|While {{the first}} part of the paper dealt with the problem of approximatinga {{prescribed}} frequency response by nonrecursive linear-phase and nonlinear-phase filters, in this part the three other central design problems for such filters in the frequency domain are studied in regard to the existence of solutions and the convergence of the <b>approximation</b> <b>errors.</b> These are the problems of approximatinga magnitude response and the problems of simultaneously approximatinga magnitude and phase response and a magnitude and group delay response respectively. The last two problems of simultaneous approximation first are formulated in a proper mathematical way. The <b>approximation</b> <b>errors</b> are measured again by an arbitrary L p - resp. l p -norm, 1 p 1; and constraints on the filter coefficients are permitted...|$|R
