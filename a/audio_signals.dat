2319|3382|Public
5|$|In the air, {{there were}} also two {{competing}} designs, originating from groups of different backgrounds and needs. The Army Signal Corps, representing military aviators, preferred a solution based on a stream of audio navigation signals, constantly fed into the pilots' ears via a headset. Civilian pilots on the other hand, who were mostly airmail pilots flying cross-country to deliver the mail, felt the <b>audio</b> <b>signals</b> would be annoying and difficult to use over long flights, and preferred a visual solution, with an indicator in the instrument panel.|$|E
25|$|Capture {{errors are}} {{anomalies}} {{created by the}} method used to capture <b>audio</b> <b>signals,</b> such as noise generated through the over-amplification of a signal {{at the point of}} recording.|$|E
25|$|This use is also {{extended}} into {{digital signal processing}} and digital image processing, which utilize digital versions of Fourier analysis (and wavelet analysis) to transmit, compress, restore, and otherwise process digital <b>audio</b> <b>signals,</b> still images, and video signals.|$|E
40|$|An input <b>audio</b> <b>signal</b> {{having an}} input {{temporal}} envelope is converted into an output <b>audio</b> <b>signal</b> having an output temporal envelope. The input temporal envelope of the input <b>audio</b> <b>signal</b> is characterized. The input <b>audio</b> <b>signal</b> is processed {{to generate a}} processed <b>audio</b> <b>signal,</b> wherein the processing de-correlates the input <b>audio</b> <b>signal.</b> The processed <b>audio</b> <b>signal</b> is adjusted based on the characterized input temporal envelope to generate the output <b>audio</b> <b>signal,</b> wherein the output temporal envelope substantially matches the input temporal envelope...|$|R
40|$|WO 200280415 A UPAB: 20021129 NOVELTY - The method {{involves}} estimating (13) an <b>audio</b> <b>signal</b> {{specific characteristic}} of the <b>audio</b> <b>signal</b> indicating {{a measure of the}} energy of the inserted information, pre-processing (12) the signal based on the estimated characteristic to influence the energy and obtain a pre-processed <b>audio</b> <b>signal</b> and extracting (16) the information from the pre-processed <b>audio</b> <b>signal.</b> DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following: an arrangement for detecting information inserted into an <b>audio</b> <b>signal,</b> an arrangement for inserting information into an <b>audio</b> <b>signal</b> and a method of inserting information into an <b>audio</b> <b>signal.</b> USE - For determining information with energy inserted into <b>audio</b> <b>signal.</b> ADVANTAGE - Enables secure determination of information inserted into an <b>audio</b> <b>signal</b> without reducing the data rate of the inserted information significantly...|$|R
40|$|A {{device for}} {{processing}} an <b>audio</b> <b>signal,</b> wherein the device comprises a detection unit adapted for detecting a widening {{state of the}} <b>audio</b> <b>signal,</b> and a widening modification unit adapted for modifying a widening characteristic of the <b>audio</b> <b>signal</b> depending on the detected widening state of the <b>audio</b> <b>signal...</b>|$|R
25|$|Other common uses are for dual-element or stereo {{microphones}} (two balanced <b>audio</b> <b>signals</b> with {{a common}} ground) and stereo intercom headset (3 pins for the stereo headphone signal - left, right, and ground, and 2 pins for the unbalanced microphone signal).|$|E
25|$|Amateur radio {{operators}} use various {{modes of}} transmission to communicate. The two most common modes for voice transmissions are frequency modulation (FM) and single sideband (SSB). FM offers high quality <b>audio</b> <b>signals,</b> while SSB is better at long distance communication when bandwidth is restricted.|$|E
25|$|Amateur Radio {{operators}} used various equipment {{designs to}} get on the air using RTTY in the 1950s and 1960s. Amateurs used their existing receivers for RTTY operation but needed to add a terminal unit, sometimes called a demodulator, to convert the received <b>audio</b> <b>signals</b> to DC signals for the teleprinter.|$|E
40|$|An {{apparatus}} {{for enhancing}} an <b>audio</b> <b>signal</b> comprises a signal processor for processing the <b>audio</b> <b>signal</b> {{in order to}} reduce or eliminate transient and tonal portions of the processed signal and a decorrelator for generating a first decorrelated signal and a second decorrelated signal from the processed signal. The apparatus further comprises a combiner for weightedly combining the first and the second decorrelated <b>signal</b> and the <b>audio</b> <b>signal</b> or a signal derived from the <b>audio</b> <b>signal</b> by coherence enhancement using time variant weighting factors and to obtain a two-channel <b>audio</b> <b>signal.</b> The apparatus further comprises a controller for controlling the time variant weighting factors by analyzing the <b>audio</b> <b>signal</b> so that different portions of the <b>audio</b> <b>signal</b> are multiplied by different weighting factors and the two-channel <b>audio</b> <b>signal</b> has a time variant degree of decorrelation...|$|R
40|$|An {{audio encoder}} for {{encoding}} an <b>audio</b> <b>signal,</b> comprises: a first encoding processor (600) for encoding a first <b>audio</b> <b>signal</b> portion in a frequency domain, wherein the first encoding processor (600) comprises: a time frequency converter (602) for converting the first <b>audio</b> <b>signal</b> portion into a frequency domain representation having spectral lines up {{to a maximum}} frequency of the first <b>audio</b> <b>signal</b> portion; an analyzer (604) for analyzing the frequency domain representation up to the maximum frequency to determine first spectral portions to be encoded with a first spectral resolution and second spectral regions to be encoded with a second spectral resolution, the second spectral resolution being lower than the first spectral resolution; a spectral encoder (606) for encoding the first spectral portions with the first spectral resolution and for encoding the second spectral portions with the second spectral resolution; a second encoding processor (610) for encoding a second different <b>audio</b> <b>signal</b> portion in the time domain; a controller (620) configured for analyzing the <b>audio</b> <b>signal</b> and for determining, which portion of the <b>audio</b> <b>signal</b> is the first <b>audio</b> <b>signal</b> portion encoded in the frequency domain and which portion of the <b>audio</b> <b>signal</b> is the second <b>audio</b> <b>signal</b> portion encoded in the time domain; and an encoded signal former (630) for forming an encoded <b>audio</b> <b>signal</b> comprising a first encoded signal portion for the first <b>audio</b> <b>signal</b> portion and a second encoded signal portion for the second <b>audio</b> <b>signal</b> portion...|$|R
40|$|DE 10129239 C UPAB: 20021204 NOVELTY - The water-marking method embeds a water-mark in an <b>audio</b> <b>signal</b> by {{providing}} a spectral representation of the <b>audio</b> <b>signal</b> and a spectral representation of the water-mark signal, the latter processed in dependence on the psychoacoustic masking threshold of the <b>audio</b> <b>signal,</b> to allow the water-mark signal to be combined with the <b>audio</b> <b>signal</b> without being audibly perceived. DETAILED DESCRIPTION - An INDEPENDENT CLAIM for a device for embedding a water-mark <b>signal</b> in an <b>audio</b> <b>signal</b> is also included. USE - The method is used for embedding a water-mark <b>signal</b> in an <b>audio</b> <b>signal.</b> ADVANTAGE - The method allows the water-mark signal to be embedded in the <b>audio</b> <b>signal</b> without being audibly perceived...|$|R
25|$|Headphones {{originated}} from the telephone receiver earpiece, {{and were the}} only way to listen to electrical <b>audio</b> <b>signals</b> before amplifiers were developed. The first truly successful set was developed in 1910 by Nathaniel Baldwin, who made them by hand in his kitchen and sold them to the United States Navy.|$|E
25|$|Later, when {{telephony}} {{began to}} replace telegraphy, {{it was found}} that the currents in the earth induced by power systems, electrical railways, other telephone and telegraph circuits, and natural sources including lightning caused unacceptable interference to the <b>audio</b> <b>signals,</b> and the two-wire or 'metallic circuit' system was reintroduced around 1883.|$|E
25|$|WMA can encode <b>audio</b> <b>signals</b> sampled {{at up to}} 48kHz with up to two {{discrete}} channels (stereo). WMA 9 introduced variable {{bit rate}} (VBR) and average bit rate (ABR) coding techniques into the MS encoder although both were technically supported by the original format. WMA 9.1 also added support for low-delay audio, which reduces latency for encoding and decoding.|$|E
40|$|An Audio decoder for {{decoding}} a multi-audio-object <b>signal</b> {{having an}} <b>audio</b> <b>signal</b> {{of a first}} type and an <b>audio</b> <b>signal</b> of a second type encoded therein is described, the multi-audio-object signal consisting of a downmix signal (56) and side information (58), the side information comprising level information (60) of the <b>audio</b> <b>signal</b> of the first type and the <b>audio</b> <b>signal</b> of the second type in a first predetermined time/frequency resolution (42), and a residual signal (62) specifying residual level values in a second predetermined time/frequency resolution, the audio decoder comprising means (52) for computing prediction coefficients (64) based on the level information (60);; and means (54) for up-mixing the downmix signal (56) based on the prediction coefficients (64) and the residual signal (62) to obtain a first up-mix <b>audio</b> <b>signal</b> approximating the <b>audio</b> <b>signal</b> of the first type and/or a second up-mix <b>audio</b> <b>signal</b> approximating the <b>audio</b> <b>signal</b> of the second type...|$|R
40|$|WO 2009100876 A 1 UPAB: 20090902 NOVELTY - The device has a {{fingerprint}} calculator (304) computing {{a fingerprint}} per block of an <b>audio</b> <b>signal</b> (114) according to block allocation information (302) {{to obtain a}} sequence of test-audio signal-fingerprints (306). A fingerprint extractor (308) extracts a sequence of reference-audio signal-fingerprints from reference <b>audio</b> <b>signal</b> fingerprint information of multi-channel expansion data (132). A fingerprint correlator (312) correlates the two sequences to obtain a correlation result. A compensator (316) controls a time offset between the expansion data and the <b>audio</b> <b>signal</b> based on the result. DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following: (1) a method for synchronizing multi-channel expansion data with an <b>audio</b> <b>signal</b> (2) a device for processing an <b>audio</b> <b>signal</b> (3) a method for processing an <b>audio</b> <b>signal</b> (4) a computer program with a program core for executing a method for processing an <b>audio</b> <b>signal.</b> USE - Device for synchronizing multi-channel expansion data with an <b>audio</b> <b>signal</b> e. g. mono-downmix, stereo-downmix and monophonic <b>audio</b> <b>signal,</b> according to MPEG- 4 standard. ADVANTAGE - The compensator controls the time offset between the multi-channel expansion data and the <b>audio</b> <b>signal</b> based on the correlation result, thus reducing or eliminating the time offset between the multi-channel expansion data and the <b>audio</b> <b>signal,</b> and hence achieving an accurate synchronization by the block-based printing technology in an efficient and reliable manner, while obtaining a multi-channel reconstruction with high quality. The fingerprints represent a better and efficient characteristic for the <b>audio</b> <b>signal...</b>|$|R
40|$|Abstract. This paper {{presents}} {{a system of}} <b>audio</b> <b>signal</b> processing based on FPGA,the system uses audio codec chip LM 4550 to A/D transform and D/A transform the input analog <b>audio</b> <b>signal</b> and output digital <b>audio</b> <b>signal.</b> Using FPGA as the high speed signal processor to realize volume adjustment and audio effect control,so it can output different style music. Meantime, the system designs a FFT computing module and control system of VGA display interface,to compute the digital <b>audio</b> <b>signal</b> which is A/D transformed,and real-time display the frequency spectrum of <b>audio</b> <b>signal</b> on VGA...|$|R
25|$|Originally, {{the only}} use for tubes in radio {{circuits}} was for rectification, not amplification. In 1906, Robert von Lieben filed {{for a patent}} for a cathode ray tube which included magnetic deflection. This {{could be used for}} amplifying <b>audio</b> <b>signals</b> and was intended for use in telephony equipment. He would later help refine the triode vacuum tube.|$|E
25|$|The soundtrack to Sin and Punishment was {{composed}} by Toshiya Yamanaka who was {{employed as a}} subcontractor before joining Treasure later in his career. All the music {{was composed}} using a Roland SC-88 Pro. One of the programmers was able to program in pulse-code modulation (PCM) support, a technology which can play digital <b>audio</b> <b>signals</b> converted from uncompressed analog audio, allowing for higher quality music.|$|E
25|$|Wireless {{speakers}} {{are very}} similar to traditional (wired) loudspeakers, but they receive <b>audio</b> <b>signals</b> using radio frequency (RF) waves rather than over audio cables. There is normally an amplifier integrated in the speaker's cabinet because the RF waves alone are not enough to drive the speaker. This integration of amplifier and loudspeaker is known as an active loudspeaker. Manufacturers of these loudspeakers design them to be as lightweight as possible while producing the maximum amount of audio output efficiency.|$|E
40|$|For a {{bandwidth}} {{extension of}} an <b>audio</b> <b>signal,</b> in a <b>signal</b> spreader the <b>audio</b> <b>signal</b> is temporally spread by a spread factor greater than 1. The temporally spread <b>audio</b> <b>signal</b> is then supplied to a demicator to decimate the temporally spread version by a decimation factor matched {{to the spread}} factor. The band generated by this decimation operation is extracted and distorted, and finally combined with the <b>audio</b> <b>signal</b> to obtain a bandwidth extended <b>audio</b> <b>signal.</b> A phase vocoder in the filterbank implementation or transformation implementation {{may be used for}} signal spreading...|$|R
50|$|<b>Audio</b> <b>signal</b> flow is {{the path}} an <b>audio</b> <b>signal</b> takes from source to output. The concept of <b>audio</b> <b>signal</b> flow {{is closely related}} to the concept of audio gain staging; each {{component}} in the signal flow {{can be thought of as}} a gain stage.|$|R
40|$|The <b>audio</b> <b>signal</b> coding method {{involves}} {{transforming the}} <b>audio</b> <b>signal</b> into a frequency range, {{in order to}} provide a number of spectral values. A prediction method is used to provide spectral residual values, with subsequent detection of the noise regions for the residual values and noise substitution. The information for the noise regions and the noise substitutions is inserted in the side information of the coded <b>audio</b> <b>signal,</b> e. g. via a bit stream multiplexer (208), with corresponding extraction of this information at the <b>audio</b> <b>signal</b> reception point. USE - For coded <b>audio</b> <b>signal</b> transmission. ADVANTAGE - Enhances coding efficiency...|$|R
25|$|In the {{professional}} audio sector, headphones {{are used in}} live situations by disc jockeys with a DJ mixer, and sound engineers for monitoring signal sources. In radio studios, DJs use a pair of headphones when talking to the microphone while the speakers are turned off to eliminate acoustic feedback while monitoring their own voice. In studio recordings, musicians and singers use headphones to play or sing along to a backing track or band. In military applications, <b>audio</b> <b>signals</b> of many varieties are monitored using headphones.|$|E
25|$|Temporal {{aliasing}} is a {{major concern}} in the sampling of video and <b>audio</b> <b>signals.</b> Music, for instance, may contain high-frequency components that are inaudible to humans. If a piece of music is sampled at 32000 samples per second (Hz), any frequency components above 16000 Hz (the Nyquist frequency for this sampling rate) will cause aliasing when the music is reproduced by a digital to analog converter (DAC). To prevent this, an anti-aliasing filter is used to remove components above the Nyquist frequency prior to sampling.|$|E
25|$|Like {{the video}} camera, most {{sampling}} schemes are periodic; that is, {{they have a}} characteristic sampling frequency in time or in space. Digital cameras provide {{a certain number of}} samples (pixels) per degree or per radian, or samples per mm in the focal plane of the camera. <b>Audio</b> <b>signals</b> are sampled (digitized) with an analog-to-digital converter, which produces a constant number of samples per second. Some of the most dramatic and subtle examples of aliasing occur when the signal being sampled also has periodic content.|$|E
40|$|Rapid {{increase}} in data transmission over internet results in emphasis on information security. Audio steganography {{is used for}} secure transmission of secret data with <b>audio</b> <b>signal</b> as the carrier. In the proposed method, cover audio file is transformed from space domain to wavelet domain using lifting scheme, leading to secure data hiding. Text message is encrypted using dynamic encryption algorithm. Cipher text is then hidden in wavelet coefficients of cover <b>audio</b> <b>signal.</b> Signal to Noise Ratio (SNR) and Squared Pearson Correlation Coefficient (SPCC) values are computed to judge {{the quality of the}} stego <b>audio</b> <b>signal.</b> Results show that stego <b>audio</b> <b>signal</b> is perceptually indistinguishable from the cover <b>audio</b> <b>signal.</b> Stego <b>audio</b> <b>signal</b> is robust even in presence of external noise. Proposed method provides secure and least error data extraction. ...|$|R
40|$|An {{apparatus}} for manipulating an <b>audio</b> <b>signal</b> comprising {{a transient}} event comprises a transient signal replacer configured {{to replace a}} transient signal portion, comprising the transient event of the <b>audio</b> <b>signal,</b> with a replacement signal portion adapted to signal energy characteristics {{of one or more}} non-transient signal portions of the <b>audio</b> <b>signal,</b> or to signal energy characteristics of the transient signal portion, to obtain a transient-reduced <b>audio</b> <b>signal.</b> The apparatus also comprises a signal processor configured to process the transient-reduced <b>audio</b> <b>signal</b> to obtain a processed version of the transient-reduced audio signal.; The apparatus also comprises a transient-signal-re-inserter configured to combine the processed version of the transient-reduced <b>audio</b> <b>signal</b> with a transient signal representing, in an original or processed form, a transient content of the transient signal portion...|$|R
3000|$|The first {{condition}} {{prevents the}} singularities in the <b>audio</b> <b>signal</b> that extremely deteriorate the audio quality. The second condition {{requires that the}} <b>audio</b> <b>signal</b> remains in the same length as the original signal within a given time span. The threshold [...] T [...] determines {{the quality of the}} <b>audio</b> <b>signal.</b> The larger the threshold, the worse the <b>audio</b> <b>signal</b> quality would be. Usually the threshold can be selected based on the specific quality requirement and application scenario.|$|R
25|$|Signal {{processing}} {{deals with}} the analysis and manipulation of signals. Signals can be either analog, {{in which case the}} signal varies continuously according to the information, or digital, in which case the signal varies according to a series of discrete values representing the information. For analog signals, signal processing may involve the amplification and filtering of <b>audio</b> <b>signals</b> for audio equipment or the modulation and demodulation of signals for telecommunications. For digital signals, signal processing may involve the compression, error detection and error correction of digitally sampled signals.|$|E
25|$|Three-pin XLR {{connectors}} {{are by far}} {{the most}} common style, and are an industry standard for balanced <b>audio</b> <b>signals.</b> The great majority of professional microphones use the XLR connector. In previous years, they were used for loudspeaker connections, for instance by Trace Elliot in its bass enclosures. The XLR could accept 14AWG (1.6mm) wire with a current-carrying capacity of 15 amps, suitable for most loudspeakers, but they have been superseded by the Speakon connector for professional loudspeakers. The Speakon connector accepts larger wire and carries more current, and it provides a better shield for the contacts, which may carry dangerous voltages when connected to an amplifier.|$|E
25|$|Windows Media Audio (WMA) is {{the most}} common codec of the four WMA codecs. Colloquial usage of the term WMA, {{especially}} in marketing materials and device specifications, usually refers to this codec only. The first version of the codec released in 1999 is regarded as WMA 1. In the same year, the bit stream syntax, or compression algorithm, was altered in minor ways and became WMA 2. Since then, newer versions of the codec have been released, but the decoding process remained the same, ensuring compatibility between codec versions. WMA is a lossy audio codec based on the study of psychoacoustics. <b>Audio</b> <b>signals</b> that are deemed to be imperceptible to the human ear are encoded with reduced resolution during the compression process.|$|E
40|$|An {{apparatus}} {{for processing}} an <b>audio</b> <b>signal</b> to focus an acoustic signal by {{an arrangement of}} a plurality of loudspeakers comprises a frequency analyzer, a signal processor and a signal output interface. The acoustic signal {{is based on the}} <b>audio</b> <b>signal.</b> The frequency analyzer is configured to determine a fundamental frequency in a frequency spectrum of the <b>audio</b> <b>signal</b> depending on a geometry parameter of the arrangement of the plurality of loudspeakers. The signal processor is configured to adapt an overtone of the fundamental frequency to obtain the processed <b>audio</b> <b>signal</b> and the signal output interface is configured to output the processed <b>audio</b> <b>signal</b> to the plurality of loudspeakers...|$|R
40|$|US 2006075884 A UPAB: 20060510 NOVELTY - The device has a {{provider}} providing a time/spectral representation of an <b>audio</b> <b>signal.</b> A scaler scales the time/spectral representation using curves of equal volume reflecting a human volume perception {{in order to}} obtain a perception-related time/spectral representation. A key determinater (308) determines a melody of the <b>audio</b> <b>signal</b> {{on the basis of the}} perception-related time/spectral representation. DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following: (A) a method for extracting a melody underlying an <b>audio</b> <b>signal</b> (B) a computer program having a program code to perform melody extraction method. USE - Used for extracting a melody of an <b>audio</b> <b>signal,</b> used for the generation of ring tones for mobile telephones from any <b>audio</b> <b>signal,</b> like e. g. singing, humming, whistling or the like. ADVANTAGE - The key determinater determines the melody of the <b>audio</b> <b>signal</b> on the basis of the perception-related time/spectral representation, thus efficiently generating ring tones e. g. polyphonic ring tone, from the <b>audio</b> <b>signal</b> at a reduced cost in a simple manner...|$|R
40|$|An {{audio encoder}} for {{encoding}} an <b>audio</b> <b>signal</b> includes an impulse extractor (10) for extracting an impulse-like portion from the <b>audio</b> <b>signal.</b> This impulse-like portion is encoded and forwarded to an output interface (22). Furthermore, the audio encoder includes a signal encoder (16) which encodes a residual signal {{derived from the}} original <b>audio</b> <b>signal</b> so that the impulse-like portion is reduced or eliminated in the residual <b>audio</b> <b>signal.</b> The output interface (22) forwards both, the encoded signals, i. e., the encoded impulse signal (12) and the encoded residual signal (20) for transmission or storage. On the decoder-side, both signal portions are separately decoded and then combined to obtain a decoded <b>audio</b> <b>signal...</b>|$|R
