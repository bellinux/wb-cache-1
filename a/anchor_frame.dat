19|87|Public
50|$|P-frames {{have one}} motion vector per macroblock, {{relative}} to the previous <b>anchor</b> <b>frame.</b> B-frames, however, can use two motion vectors; one from the previous <b>anchor</b> <b>frame,</b> and one from the future <b>anchor</b> <b>frame.</b>|$|E
50|$|The {{difference}} between a P-frame and its <b>anchor</b> <b>frame</b> is calculated using motion vectors on each macroblock of the frame (see below). Such motion vector data will be embedded in the P-frame {{for use by the}} decoder.|$|E
50|$|Finally, {{the whole}} page {{composition}} is built up by mapping all the images into the coordinate system of an “anchor” image, which is normally the one nearest the page center. The transformations to the <b>anchor</b> <b>frame</b> are calculated by concatenating the pair-wise transformations which found earlier. The raw document mosaic {{is shown in}} Figure 6.|$|E
40|$|Figure 1 : High-quality facial {{performance}} capture for two actors. The resulting meshes {{are in full}} vertex correspondence. We {{present a}} new technique for passive and markerless facial performance capture based on <b>anchor</b> <b>frames.</b> Our method starts with high resolution per-frame geometry acquisition using state-of-theart stereo reconstruction, and proceeds to establish a single triangle mesh that is propagated through the entire performance. Leveraging the fact that facial performances often contain repetitive subsequences, we identify <b>anchor</b> <b>frames</b> as those which contain similar facial expressions to a manually chosen reference expression. <b>Anchor</b> <b>frames</b> are automatically computed over one or even multiple performances. We introduce a robust image-space tracking method that computes pixel matches directly from the reference <b>frame</b> to all <b>anchor</b> <b>frames,</b> and thereby to the remaining frames in the sequence via sequential matching. This allows us to propagate one reconstructed frame to an entire sequence in parallel, in contrast to previous sequential methods. Our anchored reconstruction approach also limits tracker drift and robustly handles occlusions and motion blur. The parallel tracking and mesh propagation offer low computation times. Our technique will even automatically match <b>anchor</b> <b>frames</b> across different sequences captured on different occasions, propagating a single mesh to all performances...|$|R
50|$|The GOP {{structure}} {{is often referred}} by two numbers, for example, M=3, N=12. The first number tells the distance between two <b>anchor</b> <b>frames</b> (I or P). The second one tells the distance between two full images (I-frames): it is the GOP size. For the example M=3, N=12, the GOP {{structure is}} IBBPBBPBBPBBI. Instead of the M parameter the maximal count of B-frames between two consecutive <b>anchor</b> <b>frames</b> can be used.|$|R
50|$|B-frame {{stands for}} bidirectional-frame. They {{may also be}} known as backwards-predicted frames or B-pictures. B-frames are quite similar to P-frames, except they can make {{predictions}} using both the previous and future <b>frames</b> (i.e. two <b>anchor</b> <b>frames).</b>|$|R
50|$|It is {{therefore}} {{necessary for the}} player to first decode the next I- or P- <b>anchor</b> <b>frame</b> sequentially after the B-frame, before the B-frame can be decoded and displayed. This means decoding B-frames requires larger data buffers and causes an increased delay on both decoding and during encoding. This also necessitates the decoding time stamps (DTS) feature in the container/system stream (see above). As such, B-frames have long been subject of much controversy, they are often avoided in videos, and are sometimes not fully supported by hardware decoders.|$|E
5000|$|The encoder {{compares the}} current frame with {{adjacent}} {{parts of the}} video from the <b>anchor</b> <b>frame</b> (previous I- or P- frame) in a diamond pattern, up to a (encoder-specific) predefined radius limit from {{the area of the}} current macroblock. If a match is found, only the direction and distance (i.e. the [...] of the motion) from the previous video area to the current macroblock need to be encoded into the inter-frame (P- or B- frame). The reverse of this process, performed by the decoder to reconstruct the picture, is called motion compensation.|$|E
50|$|No other {{frames are}} {{predicted}} from a B-frame. Because of this, {{a very low}} bitrate B-frame can be inserted, where needed, to help control the bitrate. If this was done with a P-frame, future P-frames would be predicted from it and would lower {{the quality of the}} entire sequence. However, similarly, the future P-frame must still encode all the changes between it and the previous I- or P- <b>anchor</b> <b>frame.</b> B-frames can also be beneficial in videos where the background behind an object is being revealed over several frames, or in fading transitions, such as scene changes.|$|E
50|$|For example, in a {{sequence}} with pattern IBBBBPBBBBPBBBBI, the GOP size is equal to 15 (length between two I frames) and distance between two <b>anchor</b> <b>frames</b> (M value) is 5 (length between I and P frames or length between two consecutive P Frames).|$|R
40|$|Advances in sensor {{technology}} and computing capabilities and modalities are revolutionizing close-range image {{collection and analysis}} for geospatial applications. These advances create {{the need for new}} ways of handling and processing video datasets at quasi real time rates. In this paper we present an innovative two step orientation technique for ground level motion imagery using a 3 dimensional virtual model as control information. In the first step few select <b>anchor</b> <b>frames</b> are orientated precisely via an image orientation-through-queries approach. In the second step, intermediate frames are orientated relatively to these <b>anchor</b> <b>frames</b> through an innovative analysis of building façade variations in them. Combined, these two steps comprise a complete approach to motion imagery orientation using a VR as control information. 1...|$|R
40|$|Abstract—This paper proposes an {{algorithm}} to fix {{the tone}} inconsistency in captured video especially by mobile devices such as smartphone and black box cameras. We propose a method to stabilize the inconsistent tone of video frames in which tone is adjusted for each frame with adjustment map using several key <b>anchor</b> <b>frames...</b>|$|R
40|$|Abstract. This paper aims {{to reveal}} the {{mechanical}} effects of metal holder and bolt (anchor) in <b>anchor</b> <b>frame</b> combination structure, then shows existing problems of <b>anchor</b> <b>frame</b> combination supporting structure being used in present coal mine, and gives corresponding solution {{on the basis of}} modern mechanics theory. By specify examples and on the basis of having administered the pull test of bolt (anchor), the article has calculated and analyzed the stress distribution rule of metal holder in <b>anchor</b> <b>frame</b> combination supporting structure according to the statically indeterminate principle in solid mechanics. In contrast to single metal holder structure, the consequence comes to be that the bearing capacity was significantly increased. However, the actual stress values of bolt (anchor) in field measurement shows that the bearing capacity of bolt (anchor) has hot been given full work. So the essay not only reveals the good bearing capacity of <b>anchor</b> <b>frame</b> combination structure but also points out that there is plenty of scope for optimization in <b>anchor</b> <b>frame</b> combination structure, and its research results have a certain reference for supporting theory and technology research in deep level and high ground pressure soft rock roadway...|$|E
40|$|A {{negative}} stiffness {{device and}} method for seismic protection of a structure is described. In one embodiment, the device has an <b>anchor</b> <b>frame</b> and a movement frame laterally translatable {{relative to the}} <b>anchor</b> <b>frame.</b> The <b>anchor</b> <b>frame</b> and movement frame have respective extension portions. A linkage is pivotably connected to the extension portion of the <b>anchor</b> <b>frame.</b> A compressed spring has a first end {{is attached to the}} extension portion of the movement frame and a second end attached to the linkage. The compressed spring has a spring force. In a rest state, the compressed spring does not apply a lateral force to the movement frame. In an engaged state, the compressed spring is configured to apply a lateral force to displace the movement frame in a lateral direction of a seismic load. The spring force is amplified by the linkage when the movement frame is laterally displaced to an amplification point...|$|E
40|$|In {{this paper}} we {{determine}} the number of bits to be used for the encoding of the <b>anchor</b> <b>frame</b> in low bit rate video coding in order {{to improve the quality of}} the next frame to be encoded and, subsequently, the quality of the next frames to be encoded. We use a progressive method for the transmission of the <b>anchor</b> <b>frame</b> and we develop two methods for determining the optimal number of bits to be allocated to the first frame in real tim...|$|E
30|$|In video {{compression}} technologies, such as MEPG and H. 264 [4], encoded pictures (or frames) {{are arranged in}} groups of pictures (GOPs). An encoded video stream consists of successive GOPs. A GOP can contain the following frame types: I-frame, P-frame, and B-frame. The order of intraframes and interframes is specified in a GOP. An I-frame is a reference picture which is intracoded corresponding to a fixed image and it is independent of other pictures. A P-frame is predictive-coded frame which contains motion-compensated difference information from the preceding I- or P-frame. A B-frame is bidirectionally predictive-coded frame which contains different information from the preceding and following I- or P-frame within a GOP. I-frame and P-frame are {{often referred to as}} <b>anchor</b> <b>frames.</b> A GOP always begins with an I-frame. Afterwards, several P-frames follow. The B-frames are inserted between two consecutive <b>anchor</b> <b>frames.</b>|$|R
25|$|The {{steel anchors}} holding the statues to the {{pedestals}} {{were also in}} poor shape. Some of the bitumen flaked off, exposing the bare steel to corrosion and permitting corrosion to occur under the coating. Many of the tie rods were close to structural collapse, and one had completely failed. The steel <b>anchor</b> <b>frames</b> were removed, and brass framing installed.|$|R
40|$|Abstract We {{describe}} an approach for extracting three-dimensional articulated motion from unrestricted monocular video sequences. We combine feature extractionmethods based on active contours with interactive adjustment. An articulated model is interactively aligned withthe image in selected <b>anchor</b> <b>frames.</b> Active contour points are anchored to model segments in these frames. Occludedpoints are detected using object geometry {{and do not}} participate in edge tracking. Model joints are automaticallyadjusted in other frames to align with active contour points. The combination of interactive and automatic adjustmentallows extraction of arbitrarily complex movements. ...|$|R
40|$|A novel {{approach}} to image mosaicking from MPEG video {{is presented in}} this paper. The motion vectors in both P- and B-frames are used for global motion estimation. The bi-directional information in B-frames provides multiple routes to warp a frame to its previous <b>anchor</b> <b>frame.</b> A Least Median of Squares based algorithm is adopted for robust motion estimation. In {{the case of a}} large proportion of outliers, we detect possible algorithm failure and perform re-estimation along a different route. Based on the motion parameters between consecutive frames, the static back-ground panorama and dynamic foreground panorama are constructed from warped images over a whole video sequence. 1...|$|E
40|$|Multiview video coding (MVC) {{plays an}} {{important}} role in three-dimensional video applications. Joint Video Team developed a joint multiview video model (JMVM) with multi-reference frame technology. Motion and disparity estimation are employed in multi-reference frame technology to provide better rate distortion performance. However, the process of searching blocks with variable sizes for motion and disparity estimation in multi-reference frames significantly increases the computational complexity. After analyzing the statistical features of multi-reference frames in MVC, this paper proposes a fast multi-reference frame selection algorithm based on a dynamic threshold technology correlated with the types of frames. All views of prediction structure in JMVM are categorized into three types, that is, the basic view without inter-view reference relation, the first layer views that only refer <b>anchor</b> <b>frame</b> from upper view, the second layer views that need to refer the basic view and the first layer views. Furthermore, all frames in MVC prediction structure are divided into three categories, the <b>anchor</b> <b>frame</b> without any reference, non-anchor frame in the base view and the first layer view, and the non-anchor frame in other views. Dynamic threshold technique is given to terminate the process of searching multi-reference frames early. The proposed algorithm also reduces the useless candidate reference frames by filtering out those reference frames that are less likely to contain the best matched results and achieves significant speed-up. Experimental results show that the proposed algorithm can achieve 50. 13 % ~ 72. 19 % reduction of encoding time in comparison with JMVM 7. 0, while the proposed algorithm hardly influences the rate distortion performance of MVC. </p...|$|E
40|$|Abstract—Multiview video coding (MVC) {{plays an}} {{important}} role in three-dimensional video applications. Joint Video Team developed a joint multiview video model (JMVM) with multi-reference frame technology. Motion and disparity estimation are employed in multi-reference frame technology to provide better rate distortion performance. However, the process of searching blocks with variable sizes for motion and disparity estimation in multi-reference frames significantly increases the computational complexity. After analyzing the statistical features of multi-reference frames in MVC, this paper proposes a fast multi-reference frame selection algorithm based on a dynamic threshold technology correlated with the types of frames. All views of prediction structure in JMVM are categorized into three types, that is, the basic view without inter-view reference relation, the first layer views that only refer <b>anchor</b> <b>frame</b> from upper view, the second layer views that need to refer the basic view and the first layer views. Furthermore, all frames in MVC prediction structure are divided into three categories, the <b>anchor</b> <b>frame</b> without any reference, non-anchor frame in the base view and the first layer view, and the non-anchor frame in other views. Dynamic threshold technique is given to terminate the process of searching multi-reference frames early. The proposed algorithm also reduces the useless candidate reference frames by filtering out those reference frames that are less likely to contain the best matched results and achieves significant speed-up. Experimental results show that the proposed algorithm can achieve 50. 13 % ~ 72. 19 % reduction of encoding time in comparison with JMVM 7. 0, while the proposed algorithm hardly influences the rate distortion performance of MVC. Index Terms—multiview video; video coding; multi-reference frame; fast algorithm; dynamic threshold I...|$|E
40|$|A New simple {{approach}} to detect, classify shot boundaries and store shot boundary frames in Video sequence using human skin region detection based approach is proposed. Human skin region detection {{is the process}} of detecting skin region in sequence of frames. Skin region detection is mainly used for the identification of the human face detection. This approach is very much suitable for finding shots in TV News so that we can classify anchor and non <b>anchor</b> <b>frames</b> to save the overall time which is required to watch overall news...|$|R
40|$|We {{describe}} an approach for extracting threedimensional articulated motion from unrestricted monocular video sequences. We combine feature extraction methods based on active contours with interactive adjustment. An articulated model is interactively {{aligned with the}} image in selected <b>anchor</b> <b>frames.</b> Active contour points are anchored to model segments in these frames. Occluded points are detected using object geometry and {{do not participate in}} edge tracking. Model joints are automatically adjusted in other frames to align with active contour points. The combination of interactive and automatic adjustment allows extraction of arbitrarily complex movements. ...|$|R
50|$|Characteristics of {{traditional}} timber framing in {{the parts of}} the U.S. formerly known as New Netherland are H-framing also known as dropped-tie framing in the U.S. and the similar <b>anchor</b> beam <b>framing</b> as found in the New World Dutch barn.|$|R
40|$|Methods are {{presented}} {{for increasing the}} coverage and accuracy of image mosaics constructed from multiple, uncalibrated, weak-perspective views of the human retina. Extending our previous algorithm for registering pairs of image using a non-invertible, 12 -parameter, quadratic image transformation model and a hierarchical, robust estimation technique, two important innovations {{are presented}}. (1) The first is a linear, non-iterative method for jointly estimating the transformations of all images onto the mosaic. This employs constraints derived from pairwise matching between the non-mosaic image frames. It allows the transformations to be estimated for images that do not overlap the mosaic <b>anchor</b> <b>frame,</b> and results in mutually consistent transformations for all images. This means the mosaics can cover a much broader area of the retinal surface, even though the transformation model is not closed under composition. This capability is particularly valuable for mosaicing the retinal peripher [...] ...|$|E
40|$|Abstract—In video coding, an intra (I-) {{frame is}} used as an <b>anchor</b> <b>frame</b> for {{referencing}} the subsequence frames, as well as error propagation prevention, indexing, etc. To get better rate-distortion performance, a frame should have the following quality to be an ideal I-frame: the best similarity with the frames {{in a group of}} picture (GOP), so that when it {{is used as}} a reference frame for a frame in the GOP we need the least bits to achieve the desired image quality, minimize the temporal fluctuation of quality, and also maintain a more consistent bit count per frame. In this paper we use a most common frame of a scene (McFIS) in a video sequence with dynamic background modelling and then encode it to replace the conventional I-frame. The extensive experimental results confirm the superiority of our proposed scheme in comparison with the existing state-of-art methods by significant image quality improvement and computational time reduction. Index Terms—Intra frame, motion estimation, video coding, H. 264, multiple reference frame, MRFs, scene change detection, adaptive GOP, uncovered background, repetitive motion, and motion compensation...|$|E
40|$|An {{algorithm}} {{for constructing}} image mosaics from multiple, uncalibrated, weak-perspective {{views of the}} human retina is presented and analyzed. It builds on a previously described algorithm for registering pairs of retinal images using a non-invertible, 12 -parameter, quadratic image transformation model and a hierarchical, robust estimation technique. The major innovation presented here is a linear, feature-based, non-iterative method for jointly estimating consistent transformations of all images onto the mosaic image". Constraints for this estimation are derived from pairwise registration both directly with the anchor image and indirectly between pairs of non-anchor images. An incremental, graph-based technique constructs the set of registered image pairs used in the joint solution. The joint estimation technique allows images that do not overlap the <b>anchor</b> <b>frame</b> to be successfully mosaiced, a particularly valuable capability for mosaicing images of the retinal periphery. Experimental analysis of the algorithm on data sets from 16 eyes shows the average overall median transformation error in nal mosaic construction to be 0. 76 pixels. Overall, the technique is simpler, more accurate, and oers broader coverage than currently published methods...|$|E
40|$|Abstract Confirmatory bias, {{defined as}} the {{tendency}} to misinterpret new pieces of evidence as confirming previously held hypotheses, can lead to implacable, even incorrect decision making. It {{is one of the}} biases, along with <b>anchoring,</b> <b>framing,</b> and other judgment heuristic errors, that may lead to non-optimal behavior. This paper tests for the existence of confirmatory bias behavior in a uniquely economic setting (tax policy) and in a context relatively lacking in ambiguity. It also tests whether the confirmatory bias phenomenon can be prevalent enough to affect aggregate outcomes, a characteristic important in economic models in particular. The results indicate not only that confirmatory bias exists, but that the confirmatory bias effect may be stronger for evidence relating to losses than for comparable evidence relating to gains...|$|R
40|$|Anchor {{shots are}} {{important}} elements in news video, and locating them accurately and thoroughly {{is crucial to}} parse news video. The paper presents a novel approach, using neural networks, to detect anchor clips. Firstly, a background model is constructed through neural networks learning. Then, the trained neural networks classify frames in news video into two classes, i. e. <b>anchor</b> <b>frames</b> and non-anchor frames. At last, based on repeatability and dispersing of anchor shots on the temporal axis, false declarations in the outputs of neural networks are filtered out by clustering. The evaluation experiments, on nine days of news videos, demonstrate the approach is a fast, effective one, with the recall 98. 2 % and the accuracy 100 % [...] 1...|$|R
40|$|Abstract—Video has {{difficulty}} to maintain consistent intensity and color tone from frame to frame. Particularly, it happens when imaging device such as black box camera {{has to deal}} with fast changing illumination environment. However, conventional automatic white balance algorithms cannot handle this good enough to maintain tone consistency, which is observed in most commercial black box products. In this paper, a novel tone stabilization is proposed to enhance the performance of further applied algorithms like detecting and matching visual features across video frames. The proposed technique utilizes multiple <b>anchor</b> <b>frames</b> as references to smooth tone fluctuation between them. Experimental result shows the improvement of tone consistency as well as feature detection and matching accuracy on car black box videos with varying tone over time. I...|$|R
40|$|AbstractÐAn {{algorithm}} {{for constructing}} image mosaics from multiple, uncalibrated, weak-perspective {{views of the}} human retina is presented and analyzed. It builds on a previously described algorithm for registering pairs of retinal images using a noninvertible, 12 -parameter, quadratic image transformation model and a hierarchical, robust estimation technique. The major innovation presented here is a linear, feature-based, noniterative method for jointly estimating consistent transformations of all images onto the mosaic ªanchor image. º Constraints for this estimation are derived from pairwise registration both directly with the anchor image and indirectly between pairs of nonanchor images. An incremental, graph-based technique constructs the set of registered image pairs used in the joint solution. The joint estimation technique allows images that do not overlap the <b>anchor</b> <b>frame</b> to be successfully mosaiced, a particularly valuable capability for mosaicing images of the retinal periphery. Experimental analysis of the algorithm on data sets from 16 eyes shows the average overall median transformation error in final mosaic construction to be 0. 76 pixels. Overall, the technique is simpler, more accurate, and offers broader coverage than previously published methods. Index TermsÐRobust estimation, image mosaic, image montage, transformation estimation, retinal imaging, joint estimation. ...|$|E
40|$|The {{conventional}} Intra (I-) {{frame is}} used for error propagation prevention, backward/forward play, random access, indexing, etc. This frame is also used as an <b>anchor</b> <b>frame</b> for referencing the subsequence frames. To get better rate-distortion performance a frame should have the following quality to be an ideal I-frame: the best similarity with the frames in a GOP, so that (i) when it {{is used as a}} reference frame for a frame in the GOP we need less bits to achieve the desired image quality; (ii) if any frame is missing at the decoding end we can retrieve the missing frame from it. In this paper we will generate a most common frame of a scene (McFIS) in a video sequence using dynamic background modelling and then encode it to replace the conventional I-frame. By using McFIS as an I-frame, we not only gain the above mentioned two benefits but also ensure adaptive GOP for better rate-distortion performance compared to the existing coding schemes. The experimental results confirm the superiority of our proposed scheme in comparison with the existing state-of-art methods by significant image quality and computation time. Index Terms—Video coding, uncovered background, light change, repetitive motion, H. 264, motion estimation, multiple sprites, sprite, MRF, and multiple reference frames. 1...|$|E
40|$|Action {{recognition}} {{is an important}} problem in multimedia understanding. This paper addresses this problem by building an expressive compositional action model. We model one action instance in the video with an ensemble of spatio-temporal compositions: a number of discrete temporal anchor frames, {{each of which is}} further decomposed to a layout of deformable parts. In this way, our model can identify a Spatio-Temporal And-Or Graph (STAOG) to represent the latent structure of actions e. g. triple jumping, swinging and high jumping. The STAOG model comprises four layers: (i) a batch of leaf-nodes in bottom for detecting various action parts within video patches; (ii) the or-nodes over bottom, i. e. switch variables to activate their children leaf-nodes for structural variability; (iii) the and-nodes within an <b>anchor</b> <b>frame</b> for verifying spatial composition; and (iv) the root-node at top for aggregating scores over temporal anchor frames. Moreover, the contextual interactions are defined between leaf-nodes in both spatial and temporal domains. For model training, we develop a novel weakly supervised learning algorithm which iteratively determines the structural configuration (e. g. the production of leaf-nodes associated with the or-nodes) along with the optimization of multi-layer parameters. By fully exploiting spatio-temporal compositions and interactions, our approach handles well large intra-class action variance (e. g. different views, individual appearances, spatio-temporal structures). The experimental results on the challenging databases demonstrate superior performance of our approach over other competing methods. Comment: This manuscript has 10 pages with 7 figures, and a preliminary version was published in ACM MM' 1...|$|E
40|$|This paper {{describes}} {{the analysis of}} a novel isotropic suspension designed {{for use in a}} Micro Electro Mechani-cal System (MEMS) z-axis angular gyroscope. The sus-pension, consisting of six concentric interconnected rings rigidly attached to an <b>anchored</b> <b>frame,</b> supports a res-onating proof mass whose line of oscillation precesses in the presence of rotation induced Coriolis force. The pa-per demonstrates that the studied suspension is robust to quadrature errors and minimizes structural energy losses. Using a strain energy method, a closed form so-lution for the effective stiffness is developed, which is confirmed using finite element modeling. A parametric analysis is used to verify the necessity of thick structural layers in the fabrication of the suspension in order to separate desirable and undesirable modes of vibration...|$|R
40|$|UnrestrictedIn this research, {{we focus}} on two {{techniques}} related to the management of large video collection: video copy detection and automatic video classification. After the introductory chapter and a brief review in Chapter 2, our main research results are presented in Chapters 3 and 4.; In Chapter 3, a fast duplicate video detection system based on the camera transitional behavior and the suffix array data structure is proposed. The proposed system matches video clips according to their temporal structures, which are represented {{by a set of}} frames corresponding to unique events, called <b>anchor</b> <b>frames.</b> Noticing the natural association between the camera operation and the resulting video, we use the camera transitional behavior to indicate the unique events. Specifically, shot boundaries and the begin and end points of camera panning and tilting movements are detected as <b>anchor</b> <b>frames.</b> The length between adjacent <b>anchor</b> <b>frames</b> is computed to form a one-dimensional sequence, called the gap sequence, which serves as the signature of the video. An efficient gap sequence matching algorithm based on the suffix array data structure is adopted to match two given video signatures, which can achieve linear-time processing. A candidate pruning stage is also proposed to reduce the computation as much as possible. Specifically, video clips that are very unlikely to be duplicates of the input query video are eliminated in this stage before the signature matching is performed. Experimental results show that the proposed framework is not only efficient (in terms of computational speed) but also effective (in terms of high accuracy) in identifying duplicate video pairs.; In Chapter 4, two novel features that take the shooting process into consideration are first proposed for video genre classification, which are the number of camera used in a short time interval, and distance of the camera to the shooting subject. Preliminary experiment results show that the proposed features capture additional genre-related information. Some conclusion about the genre can be inferred from the proposed features to a certain degree. Then the properties of amateur and professional video clips are observed and analyzed. Although a large amount of work has been proposed by considering cinematic principles, most extracted features are low-level features without much semantic information. In the proposed scheme, features are designed to take the camera operation and the nature of amateur video clips into account. These features address various differences in video quality and editing effects. They are tested on video clips collected from an Internet video sharing website, with several classifiers. Experimental results on this test video data set demonstrate that the camera usage can be inferred from the proposed features and, thus, reliable separation of professional and amateur video contents can be achieved.; Concluding remarks and future extensions are given in Chapter 5...|$|R
40|$|This {{research}} work is partially {{funded by the}} Strategic Educational Pathways Scholarship Scheme (STEPS-Malta). This scholarship is partly financed by the European Union - European Social Fund (ESF 1. 25). Transmission of multi-view video encoded bit-streams over error-prone channels demands robust error concealment techniques. This paper studies the performance of solutions that exploit the neighbourhood spatial, temporal and inter-view information for this scope. Furthermore, different boundary distortion measurements, motion compensation refinement and temporal error concealment of <b>Anchor</b> <b>frames</b> were exploited to improve the results obtained by the basic error concealment techniques. Results show that a gain in performance is obtained {{with the implementation of}} each independent concealment technique. Furthermore, Peak Signal-to-Noise Ratio (PSNR) gains of about 4 dB relative to the standard were achieved when adopting a hybrid error concealment approach. peer-reviewe...|$|R
