18|82|Public
50|$|The third {{method of}} error {{handling}} {{is provided by}} the variant form , which specifies that no exception should be thrown; instead, a null pointer is returned to signal an <b>allocation</b> <b>error.</b>|$|E
5000|$|In 1964 Burroughs {{had also}} {{completed}} the D830 which was another {{variation of the}} D825 designed specifically for real-time applications, such as airline reservations. Burroughs designated it the B8300 after Trans World Airlines (TWA) ordered one in September 1965. A system with three instruction processors was installed at TWA's reservations center in Rockleigh, New Jersey in 1968. The system, which was called George, with an application programmed in JOVIAL, was intended to support some 4000 terminals, but the system experienced repeated crashes due to a filing system disk <b>allocation</b> <b>error</b> when operating under a large load. A fourth processor was added but did nothing to resolve the problem. The problem was resolved in late 1970 and the system became stable. Unfortunately the decision to cancel the project was being made {{at the very time}} that the problem was resolved. TWA canceled the project and acquired one IBM System/360 Model 75, two IBM System/360 model 65s, and IBM's PARS software for its reservations system. TWA sued Burroughs for non-fulfillment of the contract, but Burroughs counter-sued, stating that the basic system did work and that the problems were in TWA's applications software. The two companies reached an out-of-court settlement.|$|E
40|$|International audienceValidation {{of parental}} {{allocation}} using PAPA software (Duchesne P, Godbout MH, Bernatchez L. 2002. PAPA (package {{for the analysis}} of parental allocation) : a computer program for simulated and real parental allocation. Mol Ecol Notes. 2 : 191 – 193.) was investigated under the assumption that only a small proportion of potential breeders contributed to the offspring sample. Inbreeding levels proved to have a large impact on <b>allocation</b> <b>error</b> rate. Consequently, simulations from artificial, unrelated parents may strongly underestimate <b>allocation</b> <b>error,</b> and so, whenever possible, simulations based on the actual parental genotypes should be run. An unexpected and interesting finding was that ambiguity (the highest likelihood is shared by several parental pairs) rates below 10 % stood very close to exact <b>allocation</b> <b>error</b> rates (true proportions of wrong allocations). Hence, the ambiguity rate statistic may be viewed as a ready-made indicator of the resolution power of a specific parental allocation run and, if not exceeding 10 %, used as an estimate of <b>allocation</b> <b>error</b> rate. It was found that the PAPA simulator, even with few contributing breeders, can be trusted to output reasonably accurate estimates of <b>allocation</b> <b>error</b> as long as those estimates do not exceed 15 %. Indeed, most discrepancies between exact and estimated error then stood below 3 %. Reproductive success variance had little impact on error estimate discrepancies within the same range. Finally, a (focal set) method was described to correct the estimated family sizes computed directly from parental allocations. Essentially, this method makes use of the detailed structure of the allocation probabilities associated with each parental pair with at least 1 allocated offspring. The allocation probabilities are expressed in matrix form, and the subsequent calculations are run based on standard matrix algebra. On average, this method provided better estimates of family sizes for each investigated combination of parameter values. As the size of offspring samples increased, the corrections improved until a plateau was finally reached. Typically, samples comprising 250, 500, and 1000 offspring would bring corrections in the order of 10 – 20 %, 20 – 30 %, and 30 – 40 %, respectively...|$|E
3000|$|... {{we propose}} O-IDM which {{allows us to}} {{maximize}} budget utilization for all applications while minimizing budget <b>allocation</b> <b>errors</b> due to under- and over-provisioning problems; [...]...|$|R
3000|$|... aIntegration of {{adaptive}} power <b>allocation</b> and <b>error</b> concealment {{in addition to}} prioritization of video information will be considered in a future study.|$|R
40|$|ATSC datacasting {{provides}} {{many opportunities}} for terrestrial DTV broadcasters. This paper discusses key issues in this exciting area. Topics include: • A taxonomy of data broadcasting in terms of target audience and application characteristics • An overview of the emerging ATSC Data Broadcast Standard • Challenges in implementing end-to-end data broadcast solutions for enterprise-to-enterprise applications One key challenge is managing the end-to-end flow of data, with suitable architectural support for content providers, broadcasters, and users. Other challenges include bandwidth <b>allocations,</b> <b>error</b> correction, compression, and security...|$|R
40|$|This is a {{discussion}} note towards extending our previous {{work to the}} case of single-pass (online) optimization. Comments/rewrites please! 1 The background: multiple-pass optimization In [1] we showed that the minimum error for an entire video sequence, within a given bit budget, is achieved when the frames composing the sequence are compressed, using a best-first algorithm, up to a common threshold value of marginal error, where the threshold is chosen such that the bit budget is just exhausted. The common marginal error value that satisfies this condition is not known in advance; it is determined via an iterative process. We start from a guess at the marginal error threshold, compress the sequence up to that level, and calculate the total bit allocation this implies. In the next pass we adjust the threshold via negative feedback from the proportional bit <b>allocation</b> <b>error,</b> (B − B̂) /B), where B denotes the desired budget and B ̂ denotes the bit re-quirement of compressing the sequence to the given threshold, and recompress the sequence. Iteration proceeds until the proportional bit <b>allocation</b> <b>error</b> fall...|$|E
40|$|In this paper, we {{introduce}} a new facerecognitionapproach robust to <b>allocation</b> <b>error</b> of face features. We show that combining a “standard method” for facerecognition and a new approach based on a “cloud of points” for representing a face image, we obtain a system that not only gives good performance when faces are perfectly detected, {{but also in the}} presence of detection errors. Extensive experiments carried out on the ORL and YALE databases of faces prove the advantages of the proposed approach when compared with other well-known techniques...|$|E
40|$|Validity of CA-Markov in {{land use}} and cover change {{simulation}} was investigated at the Langat Basin, Selangor, Malaysia. CA-Markov validation was performed using validation metrics, allocation disagreement, quantity disagreement, and figure of merit in a three-dimensional space. The figure of merit, quantity error, and <b>allocation</b> <b>error</b> for total landscape simulation using the 1990 - 1997 calibration data were 5. 62 %, 3. 53 %, and 6. 13 %, respectively. CA-Markov showed a poor performance for {{land use and}} cover change simulation due to uncertainties in the source data, the model, and future land use and cover change processes in the study area.   ...|$|E
50|$|Because {{the virus}} {{appended}} {{itself to a}} file, while hiding the increase in file length, the system could cross-link files and diagnostics on the disks would report <b>allocation</b> <b>errors.</b> This would damage programs and data alike. The description of the problems found while trying correct the 'stupid-looking errors' would cause most computer professionals to erase the system and start over. A few days later the problems would arise again. Diagnostic disks and writable installation disks used to fix the computer would commonly be infected with the virus and this would aid in the spread.|$|R
40|$|Abstract: Poor {{households}} {{in rural areas}} {{of the developing world}} commonly lack access to (formal or informal) credit or insurance. These financing constraints naturally spill over into other behaviours and (asset, factor and product) markets as households rationally exploit other market and non-market resource allocation mechanisms to resolve, at least partly, their financing problems. These displaced distortions of financing constraints commonly manifest themselves in allocative inefficiency that may lead researchers and policymakers to mistakenly conclude that poor households routinely make serious <b>allocation</b> <b>errors</b> and to direct policy interventions towards the symptoms manifest in other markets rather than towards the root financial markets failures cause...|$|R
40|$|A novel {{saturated}} proportional-derivative control incorporated with null-space-based {{optimal control}} reallocation is proposed for spacecraft attitude stabilization {{in the presence}} of disturbance and input saturation. More specifically, a saturated proportional-derivative based baseline nonlinear controller is firstly developed to guarantee the globally asymptotic stability under input constraints and external disturbance. This is achieved with inexpensive online computations by dynamically adjusting a single parameter to ensure the desired performance. Then, a novel null-space-based optimal control reallocation method is employed to map the specified virtual control command to the redundant actuators. The optimal control solution is obtained by penalizing the control <b>allocation</b> <b>errors</b> at a lower power/energy cost using quadratic programming algorithm. The benefits of the proposed control method are analytically authenticated and also validated via simulation study...|$|R
40|$|This paper {{analyses}} accounting accruals {{that may}} relate to earnings quality and its information content. The characteristics specifying earning quality are discussed according to research surveys of earnings quality. These are compared with the characteristics of accounting income specified by the concept of ‘released from risks’ in ASBJ (2006). In this context, the conversion process of subjective goodwill, which {{is related to the}} allocation problem in accounting income and its relation to earnings quality, is focussed upon. The allocation problem is examined by clarifying the conversion process of subjective goodwill, and by highlighting the portion of the <b>allocation</b> <b>error</b> that reflects managerial discretion...|$|E
40|$|A special data {{compression}} approach using a quadtree-based method is proposed for allocating very large demand points to their nearest facilities while eliminating aggregation error. This allocation procedure {{is shown to}} be extremely effective when solving very large facility location problems in the Euclidian space. Our method basically aggregates demand points where it eliminates aggregation-based <b>allocation</b> <b>error,</b> and disaggregates them if necessary. The method is assessed first on the allocation problems and then embedded into the search for solving a class of discrete facility location problems namely the p-median and the vertex p-centre problems. We use randomly generated and TSP datasets for testing our method. The results of the experiments show that the quadtree-based approach is very effective in reducing the computing time for this class of location problems...|$|E
40|$|Our {{premise is}} that since there already exists a large, mature body of {{literature}} on real-time scheduling in general-purpose operating systems, {{it is time to}} spend more effort deciding which of these algorithms should be used and when, and less effort on generating new algorithms. In this paper we focus on proportional share schedulers. We introduce the notion of pessimism [...] -the proportion of overreservation required for an application to meet real-time deadlines when scheduled by proportional share schedulers that have bounded <b>allocation</b> <b>error.</b> We study the implications of pessimism and its effect on the selection of scheduling algorithm and scheduling quantum size, and also the interaction of quantum size and context switch overhead. Finally, we examine the implications of these tradeoffs for the design of applications and schedulers. 1...|$|E
30|$|The DAD {{method is}} based on the {{frequency}} domain <b>error</b> <b>allocation,</b> the implementation steps and enabling knowledge of which is introduced.|$|R
30|$|Both process-based LCA and EEIOA are {{associated}} with various types of assumptions and uncertainties on their own, including parameter and input data uncertainty (e.g., <b>allocation</b> <b>errors,</b> price homogeneity, linearity, aggregation uncertainty, geographical variation, temporal discrepancies), model uncertainty (e.g., impact categories, characterization factors), and scenario uncertainty (e.g., different choices of scope, cut-off criteria) (Peters 2006; Wiedmann 2009; Rowley et al. 2009; Lenzen 2000; Heijungs and Lenzen 2014; Ercan and Tatari 2015; Williams et al. 2009). Specific to the hLCA model developed in this study, two major stochastic uncertainties are investigated further: (1) the unit conversion conducted during {{the creation of the}} C^u matrix because of price uncertainty (see Sect.  2.4); and (2) the uncertainty associated with adding the EEIO data in the upstream cut-off matrix (Wiedmann et al. 2011; Wolfram et al. 2016; Teh et al. 2017).|$|R
40|$|Individuals {{who believe}} {{intelligence}} is malleable (a growth mindset) {{are better able}} to bounce back from failures than those who believe intelligence is immutable. Event-related potential (ERP) studies among adults suggest this resilience is related to increased attention <b>allocation</b> to <b>errors.</b> Whether this mechanism is present among young children remains unknown, however. We therefore evaluated error-monitoring ERPs among 123 school-aged children while they completed a child-friendly go/no-go task. As expected, higher attention <b>allocation</b> to <b>errors</b> (indexed by larger error positivity, Pe) predicted higher post-error accuracy. Moreover, replicating adult work, growth mindset was related to greater attention to mistakes (larger Pe) and higher post-error accuracy. Exploratory moderation analyses revealed that growth mindset increased post-error accuracy for children who did not attend to their errors. Together, these results demonstrate the combined role of growth mindset and neural mechanisms of attention allocation in bouncing back after failure among young children...|$|R
40|$|Evidence is accumulating that error {{monitoring}} is impaired {{in individuals}} with ADHD. The study aims {{to investigate the}} contribution of brain laterality and effort allocation/state regulation to impaired error monitoring in adults with ADHD symptoms. Based on the scores on the Conners’ Adult ADHD Rating Scales, a group with high and one with low ADHD were formed. The groups performed a lateralized lexical decision task with short and long ISI tapping effort <b>allocation.</b> <b>Error</b> monitoring is measured by post-error adjustments. Results showed that after errors subjects with low ADHD slowed down and improved their response accuracy only for the right visual field stimuli during long ISI. These adjustments were absent in subjects with high ADHD. Results suggest that impaired error monitoring in ADHD is related with affected left hemisphere when extra effort allocation is needed...|$|E
40|$|In this work, we devise an {{efficient}} method for the land-use optimization problem based on Laguerre Voronoi diagram. Previous Voronoi diagram-based methods are {{more efficient and}} more suitable for interactive design than discrete optimization-based method, but, in many cases, their outputs do not satisfy area constraints. To cope with the problem, we propose a force-directed graph drawing algorithm, which automatically allocates generating points of Voronoi diagram to appropriate positions. Then, we construct a Laguerre Voronoi diagram based on these generating points, use linear programs to adjust each cell, and reconstruct the diagram based on the adjustment. We adopt the proposed method to the practical case study of Chiang Mai University’s allocated land for a mixed-use complex. For this case study, compared to other Voronoi diagram-based method, we decrease the land <b>allocation</b> <b>error</b> by 62. 557  ...|$|E
40|$|We {{consider}} {{schemes for}} enacting task share changes—a process called reweighting—on real-time multiprocessor platforms. Our particular focus is reweighting schemes that are deployed in {{environments in which}} tasks may frequently request significant share changes. Prior work has shown that fair scheduling algorithms are capable of reweighting tasks with minimal <b>allocation</b> <b>error</b> and that partitioning-based scheduling algorithms can reweight tasks with better average-case performance, but greater error. However, preemption and migration overheads can be high in fair schemes. In this paper, we consider {{the question of whether}} global scheduling techniques can improve the accuracy of reweighting relative to partitioning-based schemes and provide improved average-case performance relative to fair scheduled systems. Our conclusion is that, for soft real-time systems, global scheduling techniques provide a good mix of accuracy and average-case performance. ...|$|E
40|$|CONTENTS THIS IS SDS THIS IS A TEACHING DOCUMENT WHAT SDS DOES EXPERIMENTAL SYSTEMS AND DATA FLOW Dealing with Data Flow Management Integrated Systems - Ideal If They Could Be Universal Interpreted and Compiled Languages The SDS Approach WHY SDS? Data Transfer / Memory Allocation / Data Structure MEMORY ALLOCATION IN COMPILED LANGUAGES - C Automatic Allocation Run-Time Allocation Common Memory <b>Allocation</b> <b>Errors</b> in C A Note About Memory Allocation in FORTRAN Lost Information and Overwrites in Compiled Languages MEMORY ALLOCATION IN INTERPRETED LANGUAGES Demonstration of a Crude Search Mechanism SDS' MEMORY ALLOCATION TECHNIQUES/SYSTEMS DATA TRANSFER BETWEEN PROCESSORS - LIFE BEFORE SDS Data Structures Varying Data Structure Storages in Compiled Languages Dealing with Data Transfer - External Data Representation THE SDS APPROACH TO DATA TRANSFER TRANSFER WITHIN A SYSTEM ALLOCATION WITHIN PROCESS AND SHARED MEMORY Sharing Data Originating in Process Memory Shared Memory How Share...|$|R
40|$|The paper {{discusses}} {{the sensitivity of}} the height assignment of optically thin cirrus clouds to satellite calibration errors. Thin cirrus are often used as tracers for the derivation of high-level wind vectors. The height assignment is based on bi-spectral techniques, which in the case of Meteosat use both the IR (10. 5 - 12. 5 µm) and WV (5. 7 - 7. 1 µm) channels. Height <b>allocation</b> <b>errors</b> for typical errors in calibration are of the order of 500 m. It is shown that a high bias in the calibration, implying a lower height assignment, leads to better wind quality. This {{can be explained by the}} fact that wind shear through optically thin cirrus can be substantial over the typical cloud geometric thickness of a few kilometers. Thus cloud tracking of optically thin cirrus rather represents the displacement of volume and thus does not correspond to winds at cloud top...|$|R
50|$|Electronic billing automates {{review for}} {{compliance}} <b>errors,</b> <b>allocation</b> to cost centers, and routing for approval. Independent {{research suggests that}} it reduces costs by decreasing manual labor and paper costs.|$|R
40|$|We {{consider}} {{schemes for}} enacting task share changes—a process called reweighting—on real-time multiprocessor platforms. Our particular focus is reweighting schemes that are deployed in {{environments in which}} tasks may frequently request significant share changes. Prior work has shown that fair scheduling algorithms are capable of reweighting tasks with minimal <b>allocation</b> <b>error.</b> However, in such schemes preemption and migration overheads can be high. In this paper, we consider {{the question of whether}} the lower migration costs of partitioning-based schemes can provide improved average-case performance relative to fair-scheduled systems. Our conclusion is that partitioning-based schemes are capable of providing significantly lower overall error (including “error ” due to preemption and migration costs) than fair schemes in the average case. However, partitioning-based schemes are incapable of providing strong fairness and real-time guarantees. ...|$|E
40|$|Abstract—Streaming high-fidelity audio over {{wireless}} Internet protocol (IP) networks is {{a challenging}} task because the networks present not only packet losses, but also residual bit errors. These losses and errors have severe {{adverse effect on}} the compressed audio bitstream. To solve this problem, this paper introduces error resilience in conjunction with error protection for scalable audio streaming over wireless networks. Specifically, error resilience is achieved by performing bitstream data partitioning and reversible variable length coding in the audio coder. Error protection is provided by layered product channel code to simultaneously handle packet losses and residual bit errors. Both the row and column codes of the product code provide unequal error protection for different layers of the audio bitstream by considering {{the characteristics of the}} scalable audio. Rate-distortion optimization is performed to determine the best source-channel coding tradeoff that minimizes the average expected end-to-end distortion. Simulation results demonstrate the effectiveness of our proposed approach. Index Terms—Bit <b>allocation,</b> <b>error</b> resilience, error robustness, rate-distortion optimization, scalable audio streaming, unequal error protection, wireless IP networks. I...|$|E
40|$|Abstract—In dual frame motion {{compensation}} (DFMC), one short-term reference frame (STR) and one long-term reference frame (LTR) are utilized for {{motion compensation}}. The performance of DFMC is {{heavily influenced by}} the jump updating parameter and bit allocation for the reference frames. In this paper, firstly the rate-distortion performance analysis of motion compensated prediction in DFMC is presented. Based on this analysis, an adaptive jump updating DFMC (JU-DFMC) with optimal LTR selection and bit allocation is proposed. Subsequently, an error resilient JU-DFMC is further presented based on the error propagation analysis of the proposed adaptive JU-DFMC. The experimental {{results show that the}} proposed adaptive JU-DFMC achieves better performance over the existing JU-DFMC schemes and the normal DFMC scheme in which the temporally most recently decoded two frames are used as the references. The performance of the adaptive JU-DFMC is significantly improved for video transmission over noisy channels when the specified error resilience functionality is introduced. Index Terms—Video coding, motion compensation, dual frame motion compensation, bit <b>allocation,</b> <b>error</b> propagation, error resilience. I...|$|E
40|$|This paper {{focuses on}} {{the problem of how to}} provide home network users a way to access the TINA {{services}} using a CORBA-enabled Residential Gateway. It proposes a standardised service architecture for the Next Generation Network. Additionally intelligent control and management schemes at the RGW are addressed. Issues such as billing, bandwidth <b>allocation</b> and <b>error</b> correction are highlighted in this paper...|$|R
30|$|In general, {{we believe}} that the {{literature}} on video streaming is still in a need for comprehensive solutions of the topic, whereby modulation, channel coding, source rate control, ARQ retransmissions, prioritization of video information (and related unequal <b>error</b> protection), power <b>allocation,</b> and <b>error</b> concealment are all performed jointly and adaptively with the objective of maximizing the likelihood of uninterrupted video playback subject to varying channel conditions and frame sizes.|$|R
5000|$|It is {{possible}} to express MAE as the sum of two components: Quantity Disagreement and Allocation Disagreement. Quantity Disagreement is the absolute value of the Mean <b>Error.</b> <b>Allocation</b> Disagreement is MAE minus Quantity Disagreement. The Mean Error is given by: ...|$|R
40|$|Abstract — For modern high {{performance}} systems, aggressive technology and voltage scaling has drastically increased their susceptibility to soft errors. At the grand scale of cloud computing, {{it is clear}} that soft error induced failures will occur far more frequently, but it is unclear as to how to effectively apply current error detection and fault tolerance techniques in scale. In this paper, we focus on energy-aware fault tolerant scheduling in public, multi-user cloud systems, and explore the three-way tradeoff between reliability (in terms of soft error resiliency), performance and energy. Through a systematically optimized resource <b>allocation,</b> <b>error</b> detection approach selection, virtual machine placement, spatial/temporal redundancy augmentation and task scheduling process, the cloud service provider can achieve high error coverage and fault tolerance confidence while minimizing global energy costs under user deadline constraints. Our scheduling algorithm includes a static scheduling phase that operates on task graph based workload inputs prior to execution, and a light-weight dynamic scheduler that migrates tasks during execution in case of excessive re-executions. All schedules are evaluated on a runtime simulation engine that (1) mimics the performance fluctuations in cloud systems, and (2) supports the injection of arbitrary fault patterns. Compared to current virtual machine or task replication techniques, we are able to reduce overall application failure rates by over 50 % with approximately 76 % total energy overhead. I...|$|E
40|$|Nonlinear Dynamic Inversion (NDI) is a {{promising}} method for Fault Tolerant Flight Control. The NDI algorithm cancels out the aircraft dynamics {{based on a}} dynamic aircraft model such that the closed loop system behaves linearly. The aircraft model is estimated online, which allows it to accommodate changes in the aircraft configurations and failures. It is important that an accurate dynamic aircraft model is provided in order to minimise the parasitic dynamics of imperfect dynamic inversion. Sliding Mode Control (SMC) feedback is applied to increase the robustness of the NDI algorithm {{especially in the case}} of a failure. SMC is well known for its strong robustness properties and controls the system using brute force. 1 st order SMC is a discontinuous control algorithm and the chattering behaviour is highly undesired in practical applications. Therefore 2 nd order SMC is applied on the critical rate control loop. This algorithm is less sensitive to noise and the control signals are continuous. It is shown that SMC can accommodate large uncertainties originating from control <b>allocation</b> <b>error.</b> Constraining the control solution minimises the parasitic dynamics and reduces the load on the feedback controllers. The Control Allocation problem is written as a low complexity linear program. For load balancing purposes the control solution is shaped with the Pseudo-Inverse. Control and SimulationAerospace Engineerin...|$|E
40|$|Public {{use of the}} Internet {{increases}} as wideband connections become pervasive and applications suitable for media distribution grow popular. Group collaboration applications have attracted interest during recent years. Wireless connectivity and business applications also furthers a need for reliable communication protocols. Multicast is a driving force for new applications involving one-to-many as well as many-to-many user scenarios like lecturing, discussions, and collaborative work. In some applications guaranteed delivery of every packet is not crucial, while in other this is a requirement. Error handling in reliable protocols can present a substantial challenge already in a homogeneous environment. Including a plethora of end-user terminal types with widely varying resources it becomes even more challenging. Protocols and applications must therefore {{be able to handle}} receiver and network link heterogeneity. The thesis addresses some of the challenges facing the applications in this field, related to multicast and unicast alike. Although the obstacles each of them must overcome may differ, there are similarities with regards to possible solutions with respect to error handling or resource <b>allocation.</b> <b>Error</b> handling protocols are proactive or reactive. Proactive protocols transmit redundant information along with the original information, enabling the receivers to repair lost packets without feedback to the sender. Reactive protocols rely either on positive or negative feedback from the receivers in order to establish reliability. According to a definition of semantic reliability the reliability concept can be interpreted in terms of application semantics. It is proposed to view reliable multicast as a special case of semantically reliable multicast and to implement a dynamically configurable transport layer with an error-handling rule set that can be configured from the application or even from the sender in- session. It is also proposed {{to make use of the}} application's knowledge of specific semantics to improve on the recovery of lost packets, congestion handling, or resource allocation. The thesis also presents a bandwidth-sharing scheme for video in group collaboration using application semantics in the form of user hints. The presence of such events is made available to all senders via message passing between session members. As information relating to a user's interest in another user is conveyed, the sender may increase its use of resources on the expense of other senders. A scheme is proposed and a prototype implementation and experimental results are presented. Godkänd; 2003; 20060918 (ysko) </p...|$|E
40|$|Abstract—Ultra-wideband (UWB) {{transmission}} is an emerging wireless technology for future short-range {{indoor and outdoor}} multimedia applications. To coordinate the access to the wireless medium among the competing devices, the IEEE 802. 15. 3 medium access control (MAC) is proposed for short-range high-speed wireless personal area networks (WPANs) in the IEEE 802. 15. 3 a task group. In the MAC, three acknowledgment (ACK) mechanisms are adopted during channel time <b>allocation</b> for <b>error</b> control over the error-prone wireless channel: No-ACK, Immediate-ACK (Imm-ACK), and Delayed-ACK (Dly-ACK). Frames received with errors can be retransmitted in the Imm-ACK and Dly-ACK mechanisms. However, how to optimally use these ACK mechanisms during channel time allocation is still an open issue. In this paper, we investigate how to configure the ACK mechanism parameters {{in order to achieve}} optimal throughput performance. We first formulate the throughput optimization problem for a contention-free channel time <b>allocation</b> under <b>error</b> channel condition. We then apply the three ACK mechanisms in the contention access period, to optimize the channel throughput. Simulation results demonstrate the effectiveness of our investigation. Index Terms—Bit-error rate (BER), error channel, IEEE 802. 15. 3, medium access control (MAC), ultra-wideband (UWB) ...|$|R
40|$|This paper {{addresses}} {{the problem of}} joint encoder optimization and channel coding for realtime video transmission over wireless channels. An efficient solution is proposed to optimally select macroblock modes and quantizers as well as channel coding rates. The proposed optimization algorithm fully considers error resilience, forward error correction and error concealment. Experimental results demonstrate {{the effectiveness of the}} proposed approach. Index Terms — Error concealment, error control, error resilience, multimedia streaming, quality of service (QoS), resource <b>allocation,</b> unequal <b>error</b> protection (UEP). 1...|$|R
40|$|Abstract—In this letter, we {{consider}} multiple-input single-output (MISO) systems with two-way training based transmis-sion. We {{focus on the}} long-term system performance and study the optimal power allocation between reverse training, forward training and data transmission. We derive closed-form solutions for the optimal power allocation using high signal-to-noise ratio (SNR) approximations, and show that they achieve near optimal performance in terms of symbol error rate (SER) for different modulation schemes {{over a wide range}} of SNR values. Index Terms—Two-way training, channel estimation, power <b>allocation,</b> symbol <b>error</b> rate. I...|$|R
