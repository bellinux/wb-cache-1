15|128|Public
5000|$|... the {{preservation}} of confidentiality (ensuring that information is accessible only to those authorized to have <b>access),</b> <b>integrity</b> (safeguarding the accuracy and completeness of information and processing methods) and availability (ensuring that authorized users have access to information and associated assets when required).|$|E
50|$|Another {{advantage}} of the functional model {{is that it is}} a database with features such as data independence, concurrent multiuser <b>access,</b> <b>integrity,</b> scalability, security, audit trail, backup/recovery, and data integration.Data independence is of particularly high value for analytics. Data need no longer reside in spreadsheets. Instead the functional database acts as a central information resource. The spreadsheet acts as a user interface to the database, so the same data can be shared by multiple spreadsheets and multiple users. Updates submitted by multiple users are available to all users subject to security rules. Accordingly, there is always a single consistent shared version of the data.|$|E
40|$|We {{will study}} {{security}} from multiple perspectives. We will consider {{a variety of}} security policies, authentication before <b>access,</b> <b>integrity</b> of information, and confidentiality of information. The course {{will focus on the}} models, the tools, and the techniques for enforcement of security policies, with some emphasis on the use of cryptography. An...|$|E
40|$|International audienceThis paper {{presents}} {{the design of}} a P 2 P data persistent platform. Durable <b>access</b> and <b>integrity</b> of the data are ensured despite massive attacks. This platform, named DataCube, exploits the properties of cluster-based peer-to-peer substrates to implement a compound of full replication and rateless erasure codes. DataCube guarantees durable <b>access</b> and <b>integrity</b> of data despite adversarial attacks. In particular, the recovery of damaged data is achieved through the retrieval of coded blocks whose integrity is checked on the fly...|$|R
50|$|Each {{user can}} create a job (that is, a string of TPT commands) {{that allows them to}} perform operations, such as {{heterogeneous}} data <b>access,</b> data <b>integrity</b> checks, data merging, and data loads in batch or interactive.|$|R
40|$|Management {{of content}} within a Digital Library system should {{address the issues}} of <b>access</b> control, <b>integrity</b> and {{recovery}} among other things, for both structured and semi-structured data. Most vendors either address the above issues in a custom fashion or do not address them at all. Our approach {{is to provide a}} Relational Database Management System (RDBMS) solution to the above issues. We take full advantage of the RDBMS capabilities of <b>access</b> control, <b>integrity</b> and recovery for structured data and extend the RDBMS to support the same for semi-structured data through a technology called DataLinks [7]. DataLinks extends Database technology to data residing outside of the database. Administrative tasks become simpler in a Digital Library System using the DataLinks technology. This paper describes how DataLinks feature within an RDBMS would benefit a Digital Library System in managing its content...|$|R
40|$|This {{report is}} a summary {{assessment}} of Sri Lanka’s data dissemination practices against the IMF’s Special Data Dissemination Standard (SDDS), complemented by an in-depth {{assessment of the}} elements of data quality that underlie the national accounts, prices, government finance, monetary, and balance-of-payments statistics. Sri Lanka has made good progress in meeting most of the SDDS specifications on coverage, periodicity, and timeliness of data categories. Shortcomings exist in the <b>access,</b> <b>integrity,</b> and quality dimensions compared with the SDDS. All agencies demonstrate professionalism and are generally transparent in their practices and policies...|$|E
40|$|Abstract: The paper {{deals with}} the {{security}} of interoperable heterogeneous database environments. It contains a general discussion of the issues involved {{as well as a}} description of our experiences gained during {{the development and implementation of}} the security module of IRO-DB- an European ESPRIT III funded project with the goal to develop interoperable access between relational and object-oriented databases. Key words: database federation, security, heterogeneity, authorization, access control Security in homogeneous database systems has been an issue for several years now. Various techniques have been proposed addressing the general security requirements confidentiality (protecting information from unauthorized <b>access),</b> <b>integrity</b> (protectin...|$|E
40|$|Abstract—We can {{distinguish}} three basic properties of information security, {{which should be}} implemented in nearly all IT systems: confidentiality, integrity and availability. Confidentiality means to protect the information against unauthorized <b>access.</b> <b>Integrity</b> is mentioned as a warranty of authenticity of information; it is also connected with protection against unauthorized interference. Availability means that users {{have access to the}} database, but their access needs should be met. The databases security strategy is not only concerning the cryptography. User access control, backup strategy, recovery rules, security audits and using only safe connection methods are also important. All the elements mentioned above are necessary, but nowadays they aren’t sufficient...|$|E
40|$|This paper {{considers}} {{questions related}} to the integrity and accessibility of new electronic information resources. It begins with a review of recent developments in networked information resources and the tools to identify, navigate, and use such resources. An overview is then given of the issues involved in <b>access</b> and <b>integrity</b> questions. Links between <b>access</b> and <b>integrity</b> are stressed. For example, ensuring the integrity of a body of information is meaningless {{if there is no}} access to the body of information. The changing legal framework that governs the use of electronic information as contract law rather than simple sale within the context of copyright law becomes the dominant model for acquiring access to electronic information. Effects of this shift on libraries and the interlibrary loan system are examined. Other issues considered are those of the relationships between privacy and acces...|$|R
5000|$|The {{inability}} to provide efficient solutions to security {{problems such as}} authentication, <b>access</b> control, <b>integrity</b> and confidentiality, since they {{were not part of}} the initial design. As stated in [...] “experience has shown {{that it is difficult to}} add security to a protocol suite unless it is built into the architecture from the beginning”.|$|R
30|$|The {{uppermost}} layer supports logical data {{structures such as}} relations, tuples, and views. Typical {{tasks of}} this layer include query processing and optimization, <b>access</b> control, and <b>integrity</b> enforcement.|$|R
40|$|In this paper, {{we propose}} a {{lightweight}} mechanism to isolate {{one or more}} Android userland instances from a trustworthy and secure entity. This entity controls and manages the Android instances and provides an interface for remote administration {{and management of the}} device and its software. Our approach includes several security extensions for secure network <b>access,</b> <b>integrity</b> protection of data on storage devices, and secure access to the touchscreen. Our implementation requires only minimal modification to the software stack of a typical Android-based smartphone, which allows easy porting to other devices when compared to other virtualization techniques. Practical tests show the feasibility of our approach regarding runtime overhead and battery lifetime impact...|$|E
40|$|Part 4 : Software SecurityInternational audienceIn this paper, {{we propose}} a {{lightweight}} mechanism to isolate {{one or more}} Android userland instances from a trustworthy and secure entity. This entity controls and manages the Android instances and provides an interface for remote administration {{and management of the}} device and its software. Our approach includes several security extensions for secure network <b>access,</b> <b>integrity</b> protection of data on storage devices, and secure access to the touchscreen. Our implementation requires only minimal modification to the software stack of a typical Android-based smartphone, which allows easy porting to other devices when compared to other virtualization techniques. Practical tests show the feasibility of our approach regarding runtime overhead and battery lifetime impact...|$|E
40|$|Early {{systems for}} {{networked}} intrusion detection (or, more generally, intrusion or misuse management) required either a centralized architecture or a centralized decision-making point, {{even when the}} data gathering was distributed. More recently, researchers have developed far more decentralized intrusion detection systems {{using a variety of}} techniques. Such systems often rely upon data sharing between sites which do not have a common administrator and therefore cooperation will be required in order to detect and respond to security incidents. It has therefore become important to address cooperation and data sharing in a formal manner. In this paper, we discuss the detection of distributed attacks across cooperating enterprises. We begin by defining relationships between cooperative hosts, then use the take-grant model to identify both when a host could identify a widespread attack and when that host is at increased risk due to data sharing. We further refine our definition of potential identification using <b>access,</b> <b>integrity,</b> and cooperation policies which limit sharing. Finally, we include a brief description of both a simple Prolog model encorporating data sharing policies and a prototype cooperative intrusion detection system...|$|E
40|$|Research Interests My {{research}} is primarily focused on developing rigorous formal techniques for solving security problems. I am particularly interested in: • formal methods for computer and network security: security protocols, privacy, anonymity, zeroknowledge, information flow control, <b>access</b> control, <b>integrity</b> protection • programming-languages techniques: rigorous semantics, type systems, verification, automatic testing, formal metatheory, formally certified tools • design and verification of security-critical systems: microkernel components, electronic voting systems, crypto devices, security-preserving compilers, mobile devices, etc...|$|R
50|$|From a purist perspective, SELinux {{provides}} {{a hybrid of}} concepts and capabilities drawn from mandatory <b>access</b> controls, mandatory <b>integrity</b> controls, role-based <b>access</b> control (RBAC), and type enforcement architecture. Third-party tools enable one to build a variety of security policies.|$|R
40|$|Awareness and {{implementation}} of appropriate quality assurance procedures at each stage {{in the process of}} digital preservation is vital for achieving the goals of long-term <b>access</b> and <b>integrity</b> of electronic information, and maximising the return on the high levels of investment being made in digital preservation. This paper outlines the four stages of quality assurance within the digitisation process suggested in the UK by the JISC QA Focus, and identifies issues to be considered at each stage...|$|R
40|$|Presentation at the NorthEast Regional Computing Program (NERCOMP) : Science Librarians in an e-Science World. October 9, 2009. Advances in {{computational}} capacity, the accelerating rate {{at which}} digital research data are accumulating, and the associated opportunities for new ways of doing data-driven research have brought increased attention to issues of data <b>access,</b> <b>integrity,</b> and preservation. Funders, government agencies and libraries, are attempting to define roles and responsibilities {{with respect to the}} curation of research data. I’ll discuss Cornell University Library’s efforts to: explore and define its own role in this area, partner with other units on the Cornell campus to support data stewardship, and develop an experimental “data staging repository” – a platform meant to promote the sharing of research data sets while research is in progress, and to promote the publication of completed data sets to long-term repositories. Some of this material is based upon work supported by the National Science Foundation under Grant No. III- 0712989. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation...|$|E
40|$|High Modernist {{residential}} {{architecture of}} the mid-twentieth century embodied an austere beauty of simplicity and purity of form. Applying strict design theory to material and structure, architects connected man, architecture and nature {{in a way that}} enabled a surreal experience, pushing a residential structure beyond a dwelling to a spiritual place. Over time, some of the most famous and iconic pieces of this architecture have shifted ownership and are no longer used as residences. A new demand for public access and visitation has transformed them into museums and public spaces, turning each into a piece of art in its own right. The function has now shifted in part into the public sphere. As ownership shifts, places originally designed as private retreats for their occupants are now under pressure to open to the public for view and exploration. Highly appreciated as works of art, they draw crowds eager to experience the unique and sensational lifestyle they provided. While this transformation gives a second life to buildings that otherwise might be threatened by destruction or unsympathetic ownership, it also presents problems. Issues of practicality (public <b>access),</b> <b>integrity</b> (durability of physical fabric), and theory (conceptual continuity) raise questions about the most appropriate future for Modernist residential architecture...|$|E
40|$|Developments in {{information}} and communication technologies are transforming the nature and scale of data-intensive research. The ease with which digital data can be stored, disseminated, and accessed by secondary users via information technologies encourages institutions to embrace the sharing of research data to increase its impact and visibility. The research community of Galicia needs to establish a policy that ensures that data and research derived from publicly-funded research is available and accessible for public use. Seeking to provide a framework for developing good practice to all research communities from Galicia (universities, research institutions, libraries, researchers, and research foundations), we prepare some principles, taking into account the need for sensitivity to issues related to <b>access,</b> <b>integrity,</b> transparency, professional responsibility, interoperability, and protection of intellectual property. In this work we move on several fronts: our acceptance of the principles of access and sharing of research data established by the Organization for Economic Cooperation and Development (OECD); the commitment to long-term preservation through the use and implementation of the Standard Reference Model for an Open Archival Information System (OAIS); we insist on a good data management policy according with the data lifecycle, while defining roles and responsibilities of the different stakeholders in the process...|$|E
5000|$|Security Architecture : The Security Architecture {{establishes}} {{a framework for}} integrating safeguards into all layers of the FDIC's Enterprise Architecture. The security architecture uses a risk management and information assurance strategy that provides <b>access</b> control, confidentiality, <b>integrity,</b> and non-repudiation for the Corporation's information and systems.|$|R
40|$|Since times immemorial, {{security}} {{of data to}} maintain its confidentiality, proper <b>access</b> control, <b>integrity</b> and availability {{has been a major}} issue in data communication. As soon as a sensitive message was etched on a clay tablet or written on the royal walls, then it must have been foremost in the sender’s mind that the information should not get intercepted and read by a rival. Codes, hence, form an important part of our history, starting from the paintings of Da Vinci and Michelangelo to the ancient Roman steganographic practices the necessity of data hiding was obvious...|$|R
50|$|ISO 55000:2014 can {{be applied}} to all types of assets and by all types and sizes of organization. It is {{intended}} to be used for managing physical assets in particular, {{but it can also be}} applied to other asset types. By itself it does not cover many of the requirements for IT and Software Asset Management, such as licensing, and the additional controls which are needed in general for software (e.g. for <b>access</b> and <b>integrity),</b> and for complex control situations such as SaaS and BYOD. These additional requirements are being incorporated in edition 3 of ISO/IEC 19770-1 which is based on ISO 55000:2014. Publication is not likely until 2017.|$|R
40|$|Security and {{integrity}} are frequently competing characteristics in an information system. Sectirity implies that a user can only access a specific {{subset of the}} information in the system, namely that information which the user has permission to <b>access.</b> <b>Integrity</b> implies that the information is 2 ̆ 2 correct 2 ̆ 2, i. e., that it satisfies the constraints, rules and conditions contained in the information system. A problem arises when a user who is unable to access certain information because of security restrictions, is left with an 2 ̆ 2 incorrect 2 ̆ 2 or inconsistent view of the information system. In this paper we define an information organizational structure and policy which permits security {{and integrity}} to co-exist. Our approach, called the xKB approach, specifies an area of the information system for those objects which meet the integrity requirements for a particular user but not the integrity constraints of the information system as a whole. Earlier versions and components of our approach are described in [Steinke, 1991]. Section 2 provides an example of the problem of providing security and maintaining integrity. Section 3 reviews past approaches to the problem and section 4 describes the xKB approach to solving the conflict between security and integrity. Section 5 provides a summary. Comments on the implementation of the xKB approach are found in section 6...|$|E
40|$|The Best Practices for Biomedical Big Data {{project is}} a two year {{collaboration}} between Harvard Medical School and University of Massachusetts Medical School, funded by the NIH Big Data to Knowledge (BD 2 K) Initiative for Resource Development. The Best Practices for Biomedical Research Data Management Massive Open Online Course (MOOC) provides training to librarians, biomedical researchers, undergraduate and graduate biomedical students, and other interested individuals on recommended practices facilitating the discoverability, <b>access,</b> <b>integrity,</b> reuse value, privacy, security, and long term preservation of biomedical research data. This poster highlights {{lessons learned from the}} first year of this project. Built upon the New England Collaborative Data Management Curriculum, the development team sought to use existing curricular materials to create a fully online course. The course is designed with an open course platform, WordPress Learning Management System (WPLMS), in order to facilitate broad access. Each of the MOOC’s nine modules is dedicated to a specific component of data management best practices and includes video lectures, presentation slides, research teaching cases, readings, activities, and interactive quizzes. The project team overcame multiple challenges related to creating an open online course: curriculum, audience and software. Working towards overcoming these, the Best Practices for Biomedical Research Data Management MOOC development team has moved slowly and deliberately, created additional content, and added content experts to provide guidance. These lessons learned will assist course development beyond this project, adding to best practices for creating massive open online courseware. Lessons learned include: teaching method influences the curriculum and content should not be developed in isolation from the teaching method; content is dependent on audience and supplementary content can be used to bridge audience gaps; and implementing new or unfamiliar technologies is challenging so allow more time in the timeline for project team to work with open source platform...|$|E
40|$|Defence date: 13 December 2011 Examining Board: Examining Board: Prof. Francesco Francioni, European University Institute (Supervisor) Prof. Ruth Rubio Marin, European University Institute Prof. Kerstin Odendahl, University of Kiel, Germany Prof. Ana Vrdoljak, University of Western AustraliaDisputes {{over the}} {{restitution}} and return of cultural materials have steadily increased in recent years. While several restitution claims pertaining to Nazi-confiscated art have been resolved, other cases {{relating to the}} appropriation of cultural materials during war, foreign or colonial occupation, theft, or {{as a consequence of}} illicit trafficking have proliferated. Despite these challenges and recent developments in international law, international treaty law and current State practice in resolving restitution disputes primarily focus on arguments associated with State interests and property rights, and thus do little to accommodate the interests of the various stakeholders involved in restitution disputes. Moreover, because of major legal obstacles claimants face in restitution cases (namely the non-retroactivity of international treaty law, the protection of the bona fide purchaser and provisions on the lapse of time), a purely legal approach is not a viable option in many restitution disputes. Therefore, this dissertation introduces an approach that aims at taking into account the interests of the various stakeholders in the resolution of these disputes. In a second step, complementary and alternative mechanisms in the resolution of restitution disputes are examined in order to accommodate these different interests. The utilization of this interest-oriented approach will allow restitution disputes to be resolved in a more sustainable and cooperative manner; moreover, ethical and historical considerations can also be more adequately addressed than in a purely legal approach. It will be demonstrated that within the scope of the ‘common interest’ in the protection of cultural heritage, other issues can be identified as being of common concern, including: physical and cultural preservation, <b>access,</b> <b>integrity,</b> and cooperation. Since these aspects form part of the ‘common interest’, they are valid not only for the protection of cultural heritage in war and peace, but must also be taken into account in the resolution of restitution disputes. Consequently, these common interests form new general principles in international cultural heritage law...|$|E
40|$|International audienceIn {{this paper}} we {{evaluate}} {{the performance of}} DataCube a P 2 P persistent data storage platform. This platform exploits the properties of cluster-based peer-to-peer structured overlays together with a hybrid redundancy schema (a compound of light replication and rateless erasure coding) to guarantee durable <b>access</b> and <b>integrity</b> of data despite adversarial attacks. The triptych "availability - storage overhead - bandwidth usage" is evaluated, and results show that despite massive attacks and high churn, DataCube performs remarkably well. We evaluate {{the performance of the}} rateless erasure codes implemented in DataCube. Our exploration shows how parameters selection impacts codes performance mainly in terms of decoding time, and collect strategies...|$|R
40|$|In this article, {{we propose}} a {{distributed}} security architecture for incorporation into object-oriented distributed computing systems, and in particular, into OMG 2 ̆ 7 s CORBA architecture. The primary {{objective of the}} security architecture is to make CORBA resilient to malicious attacks. The core of the architecture {{is the notion of}} secure ORB nodes, which are ORB nodes enhanced with ldquopluggablerdquo security system objects interacting through generic security service APIs. Security system objects coupled with protocols facilitate among them the creation and management of clients, objects, and security information, as well as the provision of security services, such as client/object authentication, <b>access</b> control, <b>integrity,</b> and confidentiality protections...|$|R
40|$|Abstract We {{report on}} {{a case study in}} {{applying}} formal methods to model and validate an architecture for administrating digital signatures. We use a process-oriented modeling language to model a signature system implemented on top of a secure operating system. Afterwards, we use the Spin model checker to validate <b>access</b> control and <b>integrity</b> properties. We describe here our modeling approach and the benefits gained from our analysis...|$|R
40|$|This paper {{presents}} {{the design of}} DataCube, a P 2 P data persistent platform. This platform exploits the properties of cluster-based peer-to-peer structured overlays altogether with a hybrid redundancy schema (a compound of light replication and rateless erasure coding) to guarantee durable <b>access</b> and <b>integrity</b> of data despite adversarial attacks. In particular, the recovery of damaged data is achieved through the retrieval of the minimum number of coded blocks: coded blocks are selectively retrieved and their integrity is checked on the y. An analysis validates DataCube principles design. Specically, the triptych "availability - storage overhead - bandwidth usage" is evaluated, and results show that despite massive attacks and high churn, DataCube performs remarkably well...|$|R
50|$|Check Point {{acquired}} the Integrity software {{as part of}} its acquisition of endpoint security start-up Zone Labs in 2004. The Integrity software, released in early 2002, was derived from the ZoneAlarm security technology and added central policy management and network <b>access</b> control functions. <b>Integrity</b> was integrated with network gateways (the Cisco VPN 3000 series) to ensure that a PC met security requirements before it was granted access to the network.|$|R
40|$|A {{majority}} of the Nuclear Power Facilities owners {{are faced with the}} issue of monitoring and repairing damaged carbon steel crossunder piping of the wet steam piping off of the turbine. Owners have adopted aggressive erosion/corrosion programs, which require the owner to perform 100 % inspection of the system. (5) The goal is to <b>access</b> the <b>integrity</b> of the piping. Upon completion of a visual and UT inspection of questionable damage, evaluation and repairs take place. Once a minimum wall thickness violation is identified, repair work begins in attempt to maintain minimum wall thickness. Often these areas of min wall violation are random through out the piping system. This random damage is sometimes known as Tiger Striping. In most cases Tiger stripping becomes a proble...|$|R
40|$|Many {{publications}} {{have dealt}} with various types of security requirements in cloud computing but not all types have been explored in sufficient depth. It is also hard to understand which types of requirements have been under-researched and which are most investigated. This paper's goal {{is to provide a}} comprehensive and structured overview of cloud computing security requirements and solutions. We carried out a systematic review and identified security requirements from previous publications that we classified in nine sub-areas: Access Control, Attack/Harm Detection, Non-repudiation, Integrity, Security Auditing, Physical Protection, Privacy, Recovery, and Prosecution. We found that (i) the least researched sub-areas are non-repudiation, physical protection, recovery and prosecution, and that (ii) <b>access</b> control, <b>integrity</b> and auditability are the most researched sub-areas...|$|R
40|$|Abstract—Data {{security}} and virtualization security issues are two key bottlenecks restricting {{the application of}} cloud computing promoting and applications, especially for the Cloud-based media computing system. In this paper, states {{of the art of}} the techniques on cloud computing data security issues, such as data encryption, <b>access</b> control, <b>integrity</b> authentication and other issues is surveyed, on this basis, the key technical issues of the cloud computing data security should concern about and focus on are indicated, and some corresponding countermeasures and suggestions are presented. For the virtualization security problem introduced by private cloud computing, the security risks induced by virtualization are analyzed and classified, and then based on the divide-conquer idea, for each kind of security risk, some corresponding solutions are presented...|$|R
30|$|Alkaline {{phosphatase}} is a membrane bound enzyme {{found at}} bile pole of hepatocytes and {{also found in}} pinocytic vesicle and Golgi complex. It is present on all cell membranes where active transport occurs, and hydrolase and transphosphorylase in function. It is often employed to <b>access</b> the <b>integrity</b> of plasma membrane (Akanji et al. 1993), since it is localized predominantly in the microvilli of the bile canaliculi, located in the plasma membrane. Elevation of this enzyme found in pathological condition such as liver impairment, kidney dysfunction and bone disease (Kopp and Hetesa 2000; Yang and Chen 2003). Since ALP is a membrane-bound enzyme, therefore exposure to heavy metal causes disruption of tissue membrane and change in their properties could alter the ALP activity.|$|R
