13|10000|Public
40|$|Results are {{presented}} from a 2 D {{model of the}} troposphere and stratosphere which allows the derivation of a budget for CO, {{as well as the}} <b>assessment</b> <b>of</b> <b>contributions</b> from different sources in maintaining observed CO concentrations. Attention is given to the results of a time-dependent calculation which evaluates the impact of present-day biomass burning on CO, OH, and CH 4, as well as the time constants for the system to respond to changes in the biomass source...|$|E
40|$|This article explores {{implications}} of the transition to {{an environment in which}} users have become secondary gatekeepers of the content published on media websites. This expanded user role, facilitated by technology and enabled by digital news editors, includes <b>assessment</b> <b>of</b> <b>contributions</b> by other users; communication of the perceived value or quality of user- and journalist-produced content; and selective re-dissemination of that content. The result is a two-step gatekeeping process, in which initial editorial decisions to make an item part the news product are followed by user decisions to upgrade or downgrade the visibility of that item for a secondary audience. Preliminary empirical evidence indicates these user gatekeeping capabilities are now pervasive on US newspaper sites...|$|E
40|$|During development, thalamocortical axons form arbors {{primarily}} in layer 4 of the neocortex. This lamina-specific branch formation was studied in cultures of rat thalamic explants grown next to chemically fixed cortical slices. After {{a week in}} vitro, thalamic axons formed branches specifically in the target layer of fixed cortical slices, regardless of {{the orientation of the}} ingrowth. This in vitro system permits a direct <b>assessment</b> <b>of</b> <b>contributions</b> of membrane-associated molecules to thalamic axon branch formation. To this end, the present study uses three enzymatic perturbations: chondroitinase, phosphatidylinositol phospholipase C, or the polysialic acid (PSA) -specific endoneuraminidase (endo N). With endo N pretreatment of cortex, the number of branch points was increased significantly, whereas branch tip length was decreased. In addition, the localization of branch points to the target layer was weakened considerably. Thes...|$|E
40|$|The article {{describes}} the method for the calculation of background concentration of pollutants in marine water and bottom sediments, developed by the authors. Comparative analysis of seasonal changes in mean and background concentrations lays {{the basis for the}} <b>assessment</b> <b>of</b> <b>contribution</b> <b>of</b> water cycle and in-basin processes to marine environment pollution at the license area “Lagansky”. </p...|$|R
5000|$|... ”The Industrial Court <b>of</b> Botswana: An <b>Assessment</b> <b>of</b> its <b>contribution</b> to Labour Relations” ...|$|R
40|$|The {{title of}} this {{research}} is Â“The <b>assessment</b> <b>of</b> Property Sector <b>Contribution</b> Return which is Go Public in Stock Exchange IndonesiaÂ”. Return is the result of return (profit) that you want to achive an investor. So, the <b>assessment</b> <b>of</b> <b>contribution</b> return by investor before investing their money is truly needed. The purpose of this research was to know the determining of the signal of buying and selling to the property sector contribution using technical analysis with indicator, and doing assessment toward property contribution. Analysis tool used in this research were technical analysis with Stochastic Oscillator Technical, relative strength index, and William...|$|R
40|$|This chapter {{was written}} in 1995 - 1996. The {{derivation}} of “convolution response functions”, their application to the carbon cycle, and the attribution of concentrations I still stand by. It also represents a methodology for attribution that is different in some respects from those presented at the Expert Meeting on <b>Assessment</b> <b>of</b> <b>Contributions</b> to Climate Change in Bracknell in September 2002. However, portions of this chapter also discuss applications to Global Warming Potentials and the calculation of marginal climate damages that I no longer support. For {{a number of reasons}} I no longer believe the new type of response function derived in this chapter is the right tool for those jobs. An updated version of this chapter focused on the attribution methodology, and comparing it to alternative methods (such as those presented in Bracknell) by recasting them within the theoretical framework of response functions, is in preparation...|$|E
40|$|Abstract. Monthly, {{seasonal}} {{and annual}} data of all India rainfall, minimum and maximum temperatures, representing Indian weather and climate, and geomagnetic index aa, as proxy for solar variability, have been utilized. About hundred years ’ data of these parameters {{were divided into}} six groups {{on the basis of}} intensity/amount of all India summer monsoon rainfall. Using the method of superposed analysis, simultaneous variations in rainfall, minimum and maximum temperatures, and geomagnetic indices were obtained in different months, season (i. e. monsoon) and years after dividing the whole period into six groups of very low to very high rainfall years. We present evidence that, (i) decreasing (increasing) solar activity during Indian summer monsoon months appears to influence the temperature in the season, (ii) Indian summer monsoon rainfall is higher (lower) during the periods of decreasing (increasing) solar activity in monsoon months, and (iii) Indian summer monsoon period is cooler during the years of higher summer monsoon rainfall. We found evidence that Indian (Tropical) weather and climate is affected by solar variability. It is proposed that in order to improve the predictive capability of Indian weather and climate, the <b>assessment</b> <b>of</b> <b>contributions,</b> and careful monitoring of solar variability may be useful...|$|E
40|$|Ferromagnetic {{resonance}} (FMR) spectroscopy {{has become}} an increasingly useful tool for studying the magnetic properties of natural samples. Magnetite (Fe 3 O 4) is the only magnetic mineral that has been well characterized using FMR. This limits the wider use of FMR in rock magnetism and paleomagnetism. In this study, we applied FMR analysis {{to a range of}} magnetic minerals, including greigite (Fe 3 S 4), monoclinic pyrrhotite (Fe 7 S 8), magnetically non-interacting titanomagnetite (Fe 3 -xTixO 4), and synthetic magnetite chains to constrain interpretation of FMR analysis of natural samples and to explore applications of FMR spectroscopy. We measured the FMR signatures {{of a wide range of}} well-characterized samples at the X- and Q-bands. FMR spectra were also simulated numerically to compare with experimental results. The effects of magnetic anisotropy, mineralogy, domain state, and magnetostatic interactions on the FMR spectra are discussed for all studied minerals. Our experimental and theoretical analyses of magnetically non-interacting tuff samples and magnetically interacting chains enable quantitative <b>assessment</b> <b>of</b> <b>contributions</b> of magnetostatic interactions and magnetic anisotropy to the FMR spectra. Our results also indicate that intact magnetosomes are a unique system with distinct FMR signatures. While FMR analysis is useful for characterizing magnetic properties of natural samples, care is needed when making interpretations because of overlaps in a range of FMR signatures of different magnetic minerals with different magnetic properties. Our analyses will help to constrain such interpretations in rock magnetic studie...|$|E
50|$|Gore, M.S.; Vitthal Ramji Shinde, An <b>Assessment</b> <b>of</b> his <b>Contribution</b> (book in English language), (1989), Tata Institute of Social Sciences, Bombay, India.|$|R
40|$|Henri Fayol, (1841 - 1925) {{along with}} F. W. Taylor, {{is one of}} the founders of 2 ̆ 7 {{classical}} management 2 ̆ 7. Fayol 2 ̆ 7 s work was the first significant attempt to develop principles of top-level management and one of the first attempts to analyse the different activities that constitute management. Fayol viewed management as a process of administration consisting of five activities: planning/forecasting, organizing, co-ordinating, commanding and controlling. These two volumes place Fayol 2 ̆ 7 s ideas in their historical context and provide access to his key writings. The set includes <b>assessments</b> <b>of</b> his work by his contemporaries, as well as current thinking about his ideas on management. In two volumes. (Accessed from Publisher) Part I: Henri Fayol: Life and Times. Part II: French Society at Time of Fayol. Part III: State of Administration at Time of Fayol. Part IV: Major Work in English. Part V: Parts from Major Work in English. Part VI: Other Works Translated in English. Part VII: <b>Assessment</b> <b>of</b> <b>Contribution</b> (1937 - 1969). Part VIII: <b>Assessment</b> <b>of</b> <b>Contribution</b> (1970 - 1999). Part IX: Fayolism and Related Subjects. Part X: Rejection of Fayol 2 ̆ 7 s Management Ideas. ISBN: 0415248205 ISBN: 0415248183 (v. 1) ISBN: 0415248191 (v. 2...|$|R
40|$|This paper {{examines}} {{the relation between}} audit committee characteristics, internal audit function characteristics and internal auditors 2 ̆ 7 <b>assessment</b> <b>of</b> their <b>contribution</b> to financial statement audits. Using survey data from chief internal auditors of 76 Malaysian publicly-listed firms, we provide evidence of {{a positive relationship between}} internal auditors 2 ̆ 7 <b>assessment</b> <b>of</b> their <b>contribution</b> to financial statement audits and three audit committee characteristics: the proportion of independent audit committee members, their knowledge and experience of accounting and auditing, and the extent of audit committee review of internal audit programmes, budget and coordination proposals. Further, a positive relationship is found between internal auditors 2 ̆ 7 evaluation <b>of</b> their <b>contribution</b> to the financial statement audit and internal audit function characteristics including size, prior experience of staff in auditing, time availability and the closeness of the function 2 ̆ 7 s relationship with the external auditor. The results indicate that more effective audit committees and well-resourced internal audit units tend to be positively associated with the internal auditors 2 ̆ 7 <b>assessment</b> <b>of</b> their <b>contribution</b> to the external audit. <br /...|$|R
40|$|The cytokines IL- 1 α and IL- 1 β exert {{powerful}} pro-inflammatory actions {{throughout the}} body, mediated {{primarily by the}} intracellular signaling capacity of the interleukin- 1 receptor (IL- 1 R 1). Although Il 1 r 1 knockout mice have been informative {{with respect to a}} requirement for IL- 1 R 1 signaling in inflammatory events, the constitutive nature of gene elimination has limited their utility in the assessment of temporal and spatial patterns of cytokine action. To pursue such questions, we have generated C 57 Bl/ 6 J mice containing a floxed Il 1 r 1 gene (Il 1 r 1 loxP/loxP), with loxP sites positioned to flank exons 3 and 4 and thereby the ability to spatially and temporally eliminate Il 1 r 1 expression and signaling. We found that Il 1 r 1 loxP/loxP mice breed normally and exhibit no gross physical or behavioral phenotypes. Moreover, Il 1 r 1 loxP/loxP mice exhibit normal IL- 1 R 1 receptor expression in brain and spleen, as well as normal IL- 1 R 1 -dependent increases in serum IL- 6 following IL- 1 α injections. Breeding of Il 1 r 1 loxP/loxP mice to animals expressing a cytomegalovirus (CMV) -driven Cre recombinase afforded efficient excision at the Il 1 r 1 locus. The Il 1 r 1 loxP/loxP line should be a valuable tool for the <b>assessment</b> <b>of</b> <b>contributions</b> made by IL- 1 R 1 signaling in diverse cell types across development...|$|E
40|$|<b>Assessment</b> <b>of</b> <b>contributions</b> from shallow {{lithosphere}} to teleseismic {{wave front}} distortion {{is a prerequisite}} for high-resolution regional teleseismic tomography. Several methods have been proposed in the past for the correction of these effects, e. g. application of station correction terms. We propose an approach that is independent of the subsequent inversion and uses the available a priori knowledge of the crustal structure to calculate crustal traveltime effects of teleseismic wave fronts. Our approach involves the construction of a 3 -D crustal model based on controlled source seismology data and calculation of the associated traveltime anomalies for incoming teleseismic wave fronts. The model for central Fennoscandia shows a maximum crustal thickness of 64 km and includes a high-velocity lower crust as derived for parts of the study area by previous authors. Traveltimes calculated using finite differences for teleseismic waves travelling through this crustal model are compared with those from the standard reference model IASP 91 and the residuals are used to correct observed teleseismic arrival times at the SVEKALAPKO array. To test the performance of this approach, in a second part of the study a synthetic traveltime data set is obtained by tracing wave fronts through a mantle structure with known velocity anomalies and the 3 -D crustal model. This data set is inverted with and without correction for crustal effects. The 3 -D crustal effects alone with a homogeneous mantle are also inverted and the results show that the crustal effects propagate down to 450 km. The comparison of the inversion results demonstrates the need to apply appropriate 3 -D crustal corrections in high-resolution regional tomography for upper-mantle structure beneath the Baltic Shiel...|$|E
40|$|AbstractThis {{study was}} {{designed}} to evaluate the costs between 2005 and 2013 of the national bluetongue virus (BTV) surveillance and vaccination programmes before, during and after the BTV serotype 8 (BTV- 8) outbreak in Austria commencing in 2008. In addition to an assessment of the temporal development of costs, a spatial cost analysis was performed. Within the context of this study, the term ‘costs’ refers to actual financial expenditure and imputed monetary costs for contributions in-kind. Costs were financed directly by the private–public sectors, by the European Commission (EC), and (in-kind) by responsible national institutions and individuals (e. g. blood sampling by veterinarians). The total net cost of the BTV- 8 surveillance and vaccination programmes arising from the outbreak amounted to € 22. 8 million (0. 86 % of the national agricultural Gross Value Added), of which 32 % was allocated to surveillance and 68 % to the vaccination programme. Of the total programme costs, the EC supplied € 4. 9 million, while the remaining costs (€ 18 million) were directly financed from national resources. Of the latter, € 14. 5 million was classed as public costs, including € 2 million contributions in-kind, and € 3. 4 million as private costs. The assessment of the costs revealed heterogeneous temporal and spatial distributions. The methodology of this analysis might assist decision makers in calculating costs for other surveillance and intervention programmes. The <b>assessment</b> <b>of</b> <b>contributions</b> in-kind is of importance to public authorities as it increases visibility of the available resources and shows how they have been employed. This study also demonstrates the importance of tracking changing costs per payer over time...|$|E
5000|$|Thomas Kunkel, {{writing a}} brief {{biography}} of Belt, also provided an intuitive <b>assessment</b> <b>of</b> the aesthetic <b>contributions</b> <b>of</b> the revival fortepiano: ...|$|R
40|$|Abstract. This paper {{describes}} a Voronoi analysis method to analyze a soccer game. It {{is important for}} us to know the quantitative <b>assessment</b> <b>of</b> <b>contribution</b> done by a player or a team in the game as an individual or collective behavior. The mean numbers of vertices are reported to be 5 – 6, which is a little less than those of a perfect random system. Voronoi polygons areas can be used in evaluating the dominance of a team over the other. By introducing an excess Voronoi area, we can draw some fruitful results to appraise a player or a team rather quantitatively...|$|R
3000|$|... 12 However, Haltiwanger et al. (2013) and Huber et al. (2012) also {{document}} that young firms exhibit an increased exit hazard. Accordingly, an overall <b>assessment</b> <b>of</b> the <b>contribution</b> <b>of</b> young firms to overall job creation would require census data that also contain information on market entry and exit.|$|R
40|$|The present-day <b>assessment</b> <b>of</b> <b>contributions</b> to {{sea level}} rise from glaciers and ice sheets depends {{to a large}} degree on new {{technologies}} that allow efficient and precise detection of change in otherwise inaccessible polar regions. The creation of an overall research strategy, however, was set in early collaborative efforts nearly 30 years ago to assess and project the contributions of glaciers and ice sheets to sea level rise. Many of the research objectives recommended by those early collaborations were followed by highly successful research programs and led to significant accomplishments. Other objectives are still being pursued, with significant intermediate results, but have yet to mature into fully operational tools; among them is the fully deterministic numerical ice sheet model. Recognized as a crucial tool in 1983 by the first formal working group to be convened to quantitatively evaluate glaciers and ice sheet contributions to sea level in a CO 2 -warmed future environment, the deterministic numerical model of glacier and ice sheet behavior has been the ultimate prognostic tool sought by the glaciological research community ever since. Progress toward this goal has been thwarted, however, by lack of knowledge of certain physical processes, especially those associated with interactions of ice with the bedrock it rests on, and interactions of ice with the ocean and calving of icebergs. Over the last decade, when mass loss rates from Greenland and Antarctica started to accelerate, some means of projecting glacier and ice sheet changes became increasingly necessary, and alternatives to deterministic numerical models were sought. The result was a variety of extrapolation schemes that offer partial constraints on future glacier and ice sheet losses, but also contain significant uncertainties and rely on assumptions that are not always clearly expressed. This review examines the history of assessments of glacier and ice sheet contributions to sea level rise, and considers how questions asked 30 years ago shaped the nature of the research agenda being carried out today...|$|E
40|$|Quantifying and {{comparing}} the scientific output of researchers has become critical for governments, funding agencies and universities. Comparison by reputation and direct <b>assessment</b> <b>of</b> <b>contributions</b> {{to the field}} is no longer possible, {{as the number of}} scientists increases and traditional definitions about scientific fields become blurred. The h-index is often used for comparing scientists, but has several well-documented shortcomings. In this paper, we introduce a new index for measuring {{and comparing}} the publication records of scientists: the pagerank-index (symbolised as π). The index uses a version of pagerank algorithm and the citation networks of papers in its computation, and is fundamentally different from the existing variants of h-index because it considers not only the number of citations but also the actual impact of each citation. We adapt two approaches to demonstrate the utility of the new index. Firstly, we use a simulation model of a community of authors, whereby we create various 'groups' of authors which are different from each other in inherent publication habits, to show that the pagerank-index is fairer than the existing indices in three distinct scenarios: (i) when authors try to 'massage' their index by publishing papers in low-quality outlets primarily to self-cite other papers (ii) when authors collaborate in large groups in order to obtain more authorships (iii) when authors {{spend most of their time}} in producing genuine but low quality publications that would massage their index. Secondly, we undertake two real world case studies: (i) the evolving author community of quantum game theory, as defined by Google Scholar (ii) a snapshot of the high energy physics (HEP) theory research community in arXiv. In both case studies, we find that the list of top authors vary very significantly when h-index and pagerank-index are used for comparison. We show that in both cases, authors who have collaborated in large groups and/or published less impactful papers tend to be comparatively favoured by the h-index, whereas the pagerank-index highlights authors who have made a relatively small number of definitive contributions, or written papers which served to highlight the link between diverse disciplines, or typically worked in smaller groups. Thus, we argue that the pagerank-index is an inherently fairer and more nuanced metric to quantify the publication records of scientists compared to existing measures...|$|E
40|$|Methodology used {{to measure}} in vitro gas {{production}} is reviewed to determine impacts of sources of variation on resultant gas production profiles (GPP). Current methods include measurement of gas production at constant pressure (e. g., use of gas tight syringes), {{a system that is}} inexpensive, but may be less sensitive than others thereby affecting its suitability in some situations. Automated systems that measure gas production at constant volume allow pressure to accumulate in the bottle, which is recorded at different times to produce a GPP, and may result in sufficiently high pressure that solubility of evolved gases in the medium is affected, thereby resulting in a recorded volume of gas that is lower than that predicted from stoichiometric calculations. Several other methods measure gas production at constant pressure and volume with either pressure transducers or sensors, and these may be manual, semi-automated or fully automated in operation. In these systems, gas is released as pressure increases, and vented gas is recorded. Agitating the medium does not consistently produce more gas with automated systems, and little or no effect of agitation was observed with manual systems. The apparatus affects GPP, but mathematical manipulation may enable effects of apparatus to be removed. The amount of substrate affects the volume of gas produced, but not rate of gas production, provided there is sufficient buffering capacity in the medium. Systems that use a very small amount of substrate are prone to experimental error in sample weighing. Effect of sample preparation on GPP {{has been found to be}} important, but further research is required to determine the optimum preparation that mimics animal chewing. Inoculum is the single largest source of variation in measuring GPP, as rumen fluid is variable and sampling schedules, diets fed to donor animals and ratios of rumen fluid/medium must be selected such that microbial activity is sufficiently high that it does not affect rate and extent of fermentation. Species of donor animal may also cause differences in GPP. End point measures can be mathematically manipulated to account for species differences, but rates of fermentation are not related. Other sources of inocula that have been used include caecal fluid (primarily for investigating hindgut fermentation in monogastrics), effluent from simulated rumen fermentation (e. g., `Rusitec¿, which was as variable as rumen fluid), faeces, and frozen or freeze-dried rumen fluid (which were both less active than fresh rumen fluid). Use of mixtures of cell-free enzymes, or pure cultures of bacteria, may be a way of increasing GPP reproducibility, while reducing reliance on surgically modified animals. However, more research is required to develop these inocula. A number of media have been developed which buffer the incubation and provide relevant micro-nutrients to the microorganisms. To date, little research has been completed on relationships between the composition of the medium and measured GPP. However, comparing GPP from media either rich in N or N-free, allows <b>assessment</b> <b>of</b> <b>contributions</b> of N containing compounds in the sample...|$|E
40|$|This article gives {{guidance}} for the handling and examination {{of various types}} of lung tissue specimens to provide: (1) accurate diagnosis and <b>assessment</b> <b>of</b> severity of disease; (2) sufficient information for the accurate staging of tumours; and (3) an <b>assessment</b> <b>of</b> the <b>contribution</b> <b>of</b> various occupational disorders {{to the cause of}} death. J Clin Pathol(J Clin Pathol 2000; 53 : 507 – 512...|$|R
40|$|Group {{projects}} based learning {{arrangements are}} common in higher education. Different practices are followed for <b>assessment</b> <b>of</b> individual <b>contributions</b> in group projects. Moreover, several such practices incorporate diverse arrangements for including peer and self assessments along with teacher assessments. An ongoing research by the authors aims at: (a) conducting a benchmarking study on such group project assessment frameworks and (b) thereby recommending rational arrangements for <b>assessment</b> <b>of</b> individual <b>contributions</b> in engineering higher education group projects. The research methods include knowledge-mining from literature reviews and lessons from case-studies in engineering higher education. The discussions in this paper include: (a) a basic overview <b>of</b> some <b>assessment</b> strategies; (b) a key summary from specific case-studies; and (c) a set of recommendations for rational <b>assessment</b> <b>of</b> group projects in engineering higher education...|$|R
40|$|The {{findings}} of the thesis allowed assessing plausible futures of agriculture in Flevoland around 2050 with insights in effective {{adaptation to climate change}} at different levels. Besides empirical findings, this thesis contributed methodologically to the portfolio of climate change impact and adaptation assessment. Overall, this thesis performed a prospective (using scenarios), multi-scale (taking into account crop, farm and regional level), integrated (notably multi-objective) and participatory assessment. The following features have been elaborated in this thesis to better assess the context of farm level impact and adaptation: analysis of long term farm structural change, <b>assessment</b> <b>of</b> farmers’ multiple objectives, <b>assessment</b> <b>of</b> <b>contribution</b> <b>of</b> crop and farm level adaptation measures to improvement of farm performance on important objectives, and an analysis on institutional feasibility of implementation of adaptation measures. <br/...|$|R
40|$|Arguably, {{sustainability}} is {{the most}} complex challenge humanity has faced to date. Not only are the impacts of our behavior resulting {{in more and more}} sever repercussions, but we are also realizing that the causes of unsustainability are deeply embedded in the design of many of the systems we rely on. This means, of course, also, that solutions to the problem cannot be one-off ideas, but that strategic and systematic transformation of many of our systems is needed. Because of the necessity of the re-design of our economic and other man-made systems, {{it has been suggested that}} sustainability science should be considered a “science of design” (Miller 2011). Perhaps it can be considered one of the most “wicked” cases of design, as it needs to aim both for significant impact and a participatory approach to solve the challenge.   One framework that approaches the sustainability challenge from a design angle is the Framework for Strategic Sustainable Development (FSSD). Specifically, it is based on the idea of strategically and step-wise designing sustainability out of the systems we currently rely on. The FSSD is a trans-disciplinary framework built on insights from systems thinking and has been continuously developed for the last two decades. Its core is built on backcasting from principles of re-design for sustainability, which allows for wide-spread agreement on what sustainability means and allows for creativity within these constraints, so that each group or organization can create their own path towards sustainability within these constraints. The FSSD has been used in organizations all over the world to create real transformation towards sustainability.   A particular recent development focus has been the social dimension of sustainability. Following the idea of sustainability as a design science, the development was based on a design research methodology (e. g Blessing and Chakrabarti 2009), which included a suggested new ‘prototype’ for the approach to social sustainability within the FSSD. Based on a systems approach to the social system, five new principles of social sustainability have been proposed (Missimer 2013, Missimer et al. 2013 a, 2013 b). This paper aims to contribute to the evaluation stage of the prototype and presents preliminary results of an evaluation based on field-work with the new social sustainability principles. Overall, a clearer definition of social sustainability is not just for theoretical purposes, but because without a clear theoretical concept, it is hard to strategically work towards social sustainability in practice. The data for evaluation comes from workshops that were run with sustainability professionals (also called practitioners) who use the FSSD in their work. In three workshops, the authors, as well as groups of sustainability professionals, used the new social sustainability principles to assess projects on their contribution to social sustainability. The workshops were followed by reflections by and interviews with the professionals assessing the usability of the new principles.   Preliminary results indicate that it is indeed possible to use the newly proposed social sustainability principles in the manner intended and that the approach yields results that are valuable to the professional and the potential clients of these professionals. Integration with existing tools commonly used by the practitioners was possible, although further refinement of the designed tool prototypes will be needed.   Practitioners reflected that the earlier approach to social sustainability lacked in clarity and the ability to structure other tools and concepts in the field. They reported that most practitioners designed their own way of working with social sustainability, which lead to confusion and undermined a common approach. They appreciated the more thorough and scientific approach to the social aspects presented in the new approach, which allowed for a common language and a more thorough <b>assessment</b> <b>of</b> <b>contributions</b> to un-sustainability. The practitioners also reported new insights regarding the use and connection to other tools and concepts in the field of social sustainability.   However, challenges were expressed as regards the somewhat more difficult nature of the science behind the new approach and how this impacted the ease of working with the framework for practitioners. The paper ends with some reflections by the authors. In further research this preliminary evaluation will be expanded and built upon to facilitate continuous improvement and applicability of the FSSD...|$|E
40|$|Dr. David Sackett, {{formerly}} of McMaster University and now at Oxford University in England, {{is considered one}} of the pioneers of the evidence-based medicine movement. This article looks at his colleagues' <b>assessment</b> <b>of</b> Sackett's <b>contributions</b> to medicine and at Sackett's own views on his lengthy career...|$|R
40|$|The {{dispersive}} {{approach to}} QCD is briefly overviewed and {{its application to}} the <b>assessment</b> <b>of</b> hadronic <b>contributions</b> to electroweak observables is discussed. Comment: Talk given at 12 th International Conference on Quark Confinement and the Hadron Spectrum, 29 August - 3 September 2016, Thessaloniki, Greece; 10 pages, 3 figure...|$|R
30|$|Map {{decomposition}} {{of the full}} BYM model enables visualisation of {{the full range of}} posterior estimated relative risks and residuals. This approach allows high and low areas of relative risk to be identified as well as an <b>assessment</b> <b>of</b> the <b>contribution</b> made by the covariates, unstructured and spatially structured random effects.|$|R
40|$|Over the years, {{the style}} of the {{progress}} reports on quantitative methods has varied from an <b>assessment</b> <b>of</b> recent <b>contributions</b> in scholarly journals to a detailed explication of a particular quantitative method. Examples of the latter are the reports by Wrigley during the 1980 s, wherein he introduced many human geographers to quanti...|$|R
40|$|An <b>assessment</b> <b>of</b> the <b>contributions</b> <b>of</b> Christoph Graupner's 1, 418 extant church cantatas is {{enhanced}} by a study of his fifty-five surviving Christmas cantatas, written for the feasts of Christmas, St. Stephen's, St. John's, and the Sunday after Christmas. Graupner's training in Kirchberg, Reichenbach and at the Thomas School in Leipzig is recounted {{as well as his}} subsequent tenures in Hamburg and Darmstadt...|$|R
40|$|Evaluation of the East Midlands {{regional}} tourism programme. A {{quantitative and}} qualitative <b>assessment</b> <b>of</b> the <b>contribution</b> <b>of</b> the programme between 2004 and 2010, including recommendations {{as to how the}} visitor economy can more fully contribute to the aims and objectives of the Regional Economic Strategy. Reviews the Strategic Added Value (SAV) of the programme and benchmarks estimated net impact against other regions...|$|R
30|$|Wide {{adoption}} of structured reporting is {{of critical importance}} for providing referring physicians and ultimately patients with the best quality <b>of</b> service, for <b>assessment</b> <b>of</b> radiology’s <b>contribution</b> and fair recognition of radiology in value-based medicine and for providing researchers with the best quality data {{in the context of}} big data exploitation of available clinical data.|$|R
30|$|One of the {{objectives}} of this experience was to perform a qualitative <b>assessment</b> <b>of</b> the students’ work on the wiki by assessing their wiki contributions. In previous experiments, the teacher did not consider the qualitative <b>assessment</b> <b>of</b> wiki <b>contributions</b> since this would take too long. From a theoretical point of view, it can be considered {{that the amount of}} time required to assess a wiki contribution i T[*]=[*]t_page. Thus, the time required to assess a number n <b>of</b> wiki <b>contributions</b> is T[*]=[*]n* t_page.|$|R
40|$|We {{report the}} results of studies in which {{partially}} purified centrosomes, nuclei, and DNA were injected into frog's eggs, which are naturally arrested in metaphase or interphase. These results have led to an independent <b>assessment</b> <b>of</b> the <b>contributions</b> <b>of</b> the centrosome and the chromatin {{to the formation of}} the mitotic spindle and suggest a simple explanation for the transition from interphase to metaphase microtubule arrays...|$|R
500|$|Biographer Stephen Murray-Smith is {{more generous}} in his <b>assessment</b> <b>of</b> Selfe's <b>contribution</b> to {{education}} debates {{around the turn}} of the twentieth century: [...] "Selfe went beyond the concept of helping the working man to achieve a share of the good things hitherto reserved for others, towards the concept of leading him to create good things for himself." ...|$|R
30|$|Peer- and Self-Assessment of wiki contributions: This stage {{started with}} a seminar to teach {{students}} how to peer-assess wiki contributions using AMW. Following this, students made 412 qualitative <b>assessments</b> <b>of</b> wiki <b>contributions.</b> This process provided students with critical feedback about their work. Students were also {{able to respond to}} an assessment if they disagreed with the mark received.|$|R
