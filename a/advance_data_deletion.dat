0|3866|Public
5000|$|... "A {{technical}} {{analysis of the}} <b>data</b> <b>deletion</b> malware used in this attack revealed links to other malware that the FBI knows North Korea previously developed. For example, there were similarities in specific lines of code, encryption algorithms, <b>data</b> <b>deletion</b> methods, and compromised networks.|$|R
40|$|Approaches to data {{protection}} have traditionally focused on physical security and/or cryptographic security, but the automatic <b>deletion</b> of <b>data</b> {{as a form}} of protection has not been widely employed. However, a vast amount of data is stored that has only a limited useful life and presents a risk to privacy and security after that time period. Approaches to <b>data</b> <b>deletion</b> can be broadly classified as physical destruction, data overwrite and cryptographic <b>deletion.</b> Cryptographic <b>data</b> <b>deletion</b> does not require any physical destruction and can be done quickly without any need to alter the data that is stored. Previous approaches to cryptographic <b>data</b> <b>deletion</b> have focused on bulk sanitization of storage devices. In this paper we introduce the notion of “forgetful ” storage that employs cryptographic <b>data</b> <b>deletion</b> using a time-based approach to key management. By periodically erasing old keys and creating new keys, old data becomes automatically and instantly inaccessible, or virtually deleted. This <b>data</b> <b>deletion</b> can be accomplished without depending on any actions {{on the part of the}} user, application software or operating system. A refresh policy can be utilized to cause information that is accessed to be re-encrypted using a newer key, thereby extending the time before it will expire...|$|R
40|$|This paper {{analyses}} how DNA {{sampling and}} genetic data retention {{can affect the}} fundamental rights of the individual. In particular, the author tries {{to focus on the}} <b>data</b> <b>deletion</b> in the discipline of the DNA database. In fact, the Italian legal discipline of the acquittal interacts with the regulation of <b>data</b> <b>deletion,</b> with the consequence that individual fundamental rights (i. e. the presumption of innocence, the principle of criminal responsibility based on illicit facts and not on personal qualities and the principle of equality) can be jeopardized by the retention of the genetic profiles in the DNA database...|$|R
40|$|With global {{personal}} information flows increasing, {{efforts have been}} made to develop principles to standardize data protection regulations. However, no set of principles has yet achieved universal adoption. This note proposes a principle mandating that personal data be securely destroyed when it is no longer necessary for the purpose for which it was collected. Including a <b>data</b> <b>deletion</b> principle in future data protection standards will increase respect for individual autonomy and decrease the risk of abuse of personal <b>data.</b> Though <b>data</b> <b>deletion</b> is already practiced by many data controllers, including it in legal data protection mandates will further the goal of establishing an effective global data protection regime...|$|R
30|$|The {{problem of}} rare pattern mining can be {{extended}} to handle various <b>advanced</b> <b>data</b> types. The basic rare pattern mining techniques, however, directly cannot address the variations demanded by these <b>advanced</b> <b>data</b> types. Modifications of existing techniques {{need to be developed}} for effectively handling the <b>advanced</b> <b>data</b> types.|$|R
50|$|Note: {{a factory}} reset may only hide {{data from the}} {{operating}} system so it appears it no longer exists. This {{is not the same}} effect as <b>data</b> <b>deletion,</b> and may not therefore be wholly suitable in situations where the device changes ownership.|$|R
30|$|Our {{main focus}} for future {{work is to}} study the effect of updates on <b>data</b> (<b>deletions</b> and insertions) in the {{fragments}}: it must be studied in detail how fragments can be reconfigured and probably migrated to other server without incurring too much transfer cost.|$|R
5000|$|Malware infections causing {{incidents}} such as unauthorized access, leakage or {{disclosure of}} personal or proprietary <b>data,</b> <b>deletion</b> of or {{damage to the}} data or programs, interruption or denial of authorized access to the database, attacks on other systems and the unanticipated failure of database services; ...|$|R
40|$|This diploma thesis {{deals with}} the {{analysis}} of <b>advanced</b> <b>data</b> warehouse concepts where three <b>advanced</b> <b>data</b> warehouse concepts are analysed and their selection is justified. The first selected <b>advanced</b> <b>data</b> warehouse concept is a method of capturing data changes from sources system Change Data Capture (CDC). The second concept is the historization of captured data into historical data collection. The third concept is the application of analytical functions directly within data warehouse technology. A new testing environment has been created to analyse these concepts where the main database system Netezza available in IBM PureData System for Analytics, powered by Netezza technology (PDA), is utilised. This testing environment allowed all selected <b>advanced</b> <b>data</b> warehouse concepts to be reviewed. An impact of the application of these <b>advanced</b> <b>data</b> warehouse concepts has been analysed based on results from the testing environment and practical insights, particularly regarding potential advances. In the testing environment it was verified that all analysed <b>advanced</b> <b>data</b> warehouse concepts are applicable in a data warehouse. In the first <b>advanced</b> <b>data</b> warehouse concept was chosen LiveAudit mapping as appropriate for further data processing, when with this mapping {{it is possible to}} unambiguously determine the state of data in a source system at any point in the past. The second <b>advanced</b> <b>data</b> warehouse concept established that data acquired from LiveAudit mapping is possible to effectively process into historical data collection. Based on these findings, there was proposed generic solution of processing data from source systems. In the third <b>advanced</b> <b>data</b> warehouse concept was also proved, {{that it is possible to}} work in native analytic environment RGui and move the computation itself into data, which is located in the data warehouse, without the necessity of migration of these data. Further, it is possible to develop and use a new analytic function written in C++ language directly into the technology of the data warehouse...|$|R
5000|$|... #Subtitle level 2: <b>Advanced</b> <b>data</b> {{validation}} {{and reconciliation}} ...|$|R
5000|$|ADN Telecom Ltd. (formerly <b>Advanced</b> <b>Data</b> Network Systems Ltd) ...|$|R
5000|$|Choose {{appropriate}} <b>advanced</b> <b>data</b> {{structures and}} algorithms. (AB only) ...|$|R
50|$|Btrieve is a {{database}} developed by Pervasive Software. The architecture of Btrieve {{has been designed}} with record management in mind. This means that Btrieve only deals with the underlying record creation, data retrieval, record updating and <b>data</b> <b>deletion</b> primitives. Together with the MicroKernel Database Engine it uses ISAM, Indexed Sequential Access Method, as its underlying storage mechanism.|$|R
50|$|PFIF 1.3, {{released}} in March 2011, addressed {{the privacy of}} personal information by adding a field to specify an expiry date on each person record and setting out requirements for <b>data</b> <b>deletion.</b> PFIF 1.3 also {{moved away from the}} US-specific assumption of a first and last name by adding one field for a person's full name.|$|R
25|$|Remote Data Service 1.5, which {{superseded}} the <b>Advanced</b> <b>Data</b> Connector.|$|R
5000|$|ADN Telecom Ltd. Formally named <b>Advanced</b> <b>Data</b> Network System Ltd.|$|R
5000|$|Passive {{electronically}} scanned array radars with <b>advanced</b> <b>data</b> {{processing methods}} ...|$|R
5000|$|Remote Data Service 1.5, which {{superseded}} the <b>Advanced</b> <b>Data</b> Connector.|$|R
5000|$|<b>Advanced</b> <b>Data</b> Analysis Techniques (Not to get {{confused}} with data analytics) ...|$|R
5000|$|... #Caption: The {{workflow}} of an <b>advanced</b> <b>data</b> validation {{and reconciliation}} process.|$|R
5000|$|... 2006 - TIMSS 2008 <b>Advanced</b> <b>Data</b> Entry Manager Seminar, Hamburg, Germany; ...|$|R
40|$|The {{purpose of}} this {{document}} {{is to establish a}} policy on records retention and disposition, for records in both electronic and hardcopy formats. This policy will contain instructions on: electronic document management, a policy on data retention and <b>data</b> <b>deletion,</b> and a process for instituting a litigation hold. These policies and procedures are necessary to comply with all applicable Federal and Stat...|$|R
5000|$|STANAG 4575 (Edition 4, 2 December 2014): NATO <b>Advanced</b> <b>Data</b> Storage Interface (NADSI) ...|$|R
5000|$|The <b>Advanced</b> <b>Data</b> Acquisition Model (ADAM): A {{process model}} for digital {{forensic}} practice (Adams, 2012) ...|$|R
5000|$|... {{availability}} of <b>advanced</b> <b>data</b> structures: arrays, queues (single or double), stacks, bit maps, sets, AVL trees.|$|R
5000|$|IASO Backup : <b>Advanced</b> <b>data</b> {{reduction}} technology. Data de-duplication mechanism. High {{level of}} scalability and cost effectiveness.|$|R
5000|$|MedChem Studio, a {{multi-purpose}} cheminformatics {{software tool}} used for <b>advanced</b> <b>data</b> mining and de novo molecule design.|$|R
40|$|International audienceDAQ {{and data}} {{processing}} {{is a basic}} part of all automated production systems and diagnostic systems, watching over quality of production, energy distribution, transport control, and various other areas. Demands on the speed, accuracy, and reliability increase in general. These demands are possible to achieve by not only using superior (but also more expensive) hardware but also by applying <b>advanced</b> <b>data</b> acquisition and intelligent data processing. It deals e. g. optimal data fusion {{of a number of}} sensors, new stochastic methods for accuracy increasing, new algorithms for acceleration of data processing, etc. These are the grounds for publishing this book. <b>Advanced</b> <b>Data</b> Acquisition and Intelligent Data Processing offers 10 up-to-date examples of different applications of <b>advanced</b> <b>data</b> acquisition and intelligent data processing used in monitoring, measuring and diagnostics systems. The book arose based on the most interesting papers from this area published at IDAACS 2013 conference. However, the indivudual chapters include not only designed solutions in wider context but also relevant theoretical parts and achieved results. Technical topics discussed in this book include: • <b>advanced</b> methods of <b>data</b> acquisition in application that are not routine;• measured data fusion using up-to-date <b>advanced</b> <b>data</b> processing;• nonlinear dynamical systems identification;• multidimensional image processing. <b>Advanced</b> <b>Data</b> Acquisition and Intelligent Data Processing is ideal for personnel of firms dealing with advanced instrumentation, energy consumption monitoring, environment monitoring, non-descructive diagnostics robotics, etc., as well as academic staff and postgraduate students in electrical, control, and computer engineering...|$|R
5000|$|<b>Advanced</b> <b>data</b> {{processing}} {{can be done}} {{using the}} Python Programmable filter with VTK, NumPy, SciPy and other Python modules.|$|R
5000|$|... for Virtual Environments - Provides <b>advanced</b> <b>data</b> {{protection}} and flexible recovery options for VMware vSphere ESX and ESXi servers.|$|R
30|$|Development of <b>advanced</b> <b>data</b> {{analytic}} {{models for}} event-driven data and {{machine learning algorithms}} can be incorporated in the existing methodologies.|$|R
50|$|On 22 March 2012, Pacnet {{opened its}} fourth <b>advanced</b> <b>data</b> centre in the Tseung Kwan O Industrial Estate, Hong Kong.|$|R
50|$|The main {{areas of}} his {{research}} are: extragalactic astronomy, cosmology, formation and evolution of galaxies, quasars, <b>advanced</b> <b>data</b> analysis methods.|$|R
50|$|Stoner is {{currently}} the CEO of Entelligent, a provider of Smart Climate indices, predictive equity portfolio analytics, and <b>advanced</b> <b>data.</b>|$|R
5000|$|Most recently, Thomas Stoner, Jr. {{launched}} Entelligent, {{a provider}} of Smart Climate indices, predictive equity portfolio analytics, and <b>advanced</b> <b>data</b> ...|$|R
40|$|The NASA Marshall Space Flight Center is {{currently}} developing an <b>Advanced</b> <b>Data</b> System {{in an effort}} to address the requirements of ground data systems for future missions. The <b>Advanced</b> <b>Data</b> System will be required to provide real-time telemetry acquisition and display capabilities, as well as commanding and off-line mission planning functions. This paper discusses the requirements of the ground data systems in support of the AXAF mission, and presents the conceptual design of those systems...|$|R
