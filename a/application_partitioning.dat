65|460|Public
50|$|For some {{application}}s, RAC {{may require}} careful <b>application</b> <b>partitioning</b> to enhance performance. An application that scales linearly on an SMP machine may scale linearly under RAC. However, if the application cannot scale linearly on SMP, {{it will not}} scale when ported to RAC. In short, the application scalability is based on how well the application scales in a single instance.|$|E
50|$|The most {{immediate}} {{challenge in the}} realm of parallel processing does not lie as much in the type of hardware architecture used, but in how easy it will be to program the system in question in a real-world environment with acceptable performance. Machines like Imagine use a straightforward single-threaded model with automated dependencies, memory allocation and DMA scheduling. This in itself {{is a result of the}} research at MIT and Stanford in finding an optimal layering of tasks between programmer, tools and hardware. Programmers beat tools in mapping algorithms to parallel hardware, and tools beat programmers in figuring out smartest memory allocation schemes, etc. Of particular concern are MIMD designs such as Cell, for which the programmer needs to deal with <b>application</b> <b>partitioning</b> across multiple cores and deal with process synchronization and load balancing. Efficient multi-core programming tools are severely lacking today.|$|E
40|$|<b>Application</b> <b>partitioning</b> is {{the task}} of {{breaking}} up the functionality of an application into distinct entities that can operate independently, usually in a distributed setting. Many distributed applications are created by partitioning their centralized versions. Traditional <b>application</b> <b>partitioning</b> entails re-coding the application functionality to use a middleware mechanism for communication between the different entities. This process is tedious and error-prone. Automating the partitioning process while preserving correctness and ensuring good performance of partitioned applications can greatly facilitate development of a large class of distributed applications. We review the main advantages and challenges of automatic <b>application</b> <b>partitioning</b> and present the J-Orchestra system. JOrchestra is an automatic partitioning system for Java programs. J-Orchestra takes as input Java applications in bytecode format and transforms them into distributed applications, running on distinct Java Virtual Machines...|$|E
40|$|Networks-on-chip (NoCs) are key {{components}} in many-core chip designs. Dynamic power-awareness {{is a new}} challenge present in NoCs that must be efficiently handled by the routing functionality as it introduces irregularities in the commonly used 2 -D meshes. In this paper, we propose a logic-based routing algorithm, iFDOR, oriented towards dynamic powering down one region within every <b>application</b> <b>partition</b> on the chip through dynamic rerouting, with low implementation costs. Results show that we can successfully shut- down an arbitrary rectangular region within an <b>application</b> <b>partition</b> without significant impact on network performance...|$|R
30|$|Possible uses of Intel SGX were {{discussed}} by Hoekstra et al. [8]. They present examples of applications that {{make use of}} the Intel SGX capabilities, as well as an application architecture considering an <b>application</b> <b>partition</b> between parts that demand security and should be executed within enclaves, and parts that do not require security, which can be run out of enclaves.|$|R
40|$|Cloud {{computing}} {{is one of}} {{the emerging}} technology which is finding its usage everywhere. Mobile cloud is one step ahead of Cloud computing. In this paper, we will give a brief an overview of Mobile cloud computing and will discuss some of the <b>application</b> <b>partition</b> schemes for offloading in mobile cloud. The paper also discusses what kind of applications are suitable for offloading and also indicates towards future research directions for offloading...|$|R
30|$|Our {{research}} bridges the {{two areas}} of application and database partitioning but differs from previous {{work in that}} it uses a new BIP formulation that considers both areas. Our focus is not on providing all of the many features provided by every previous project either on <b>application</b> <b>partitioning</b> or database partitioning. Instead, we have focused on providing a new interface between the two using our combined BIP. We describe the differences in more detail by first describing some related work in <b>application</b> <b>partitioning</b> and then database partitioning.|$|E
40|$|Abstract. Applications {{based on}} a service-oriented {{architecture}} are getting popular {{in the domain of}} business to customer electronic commerce and in automating information exchange between business processes. In this paper, we are investigating a service-oriented architecture for hosting of the services in wireless environments. The proposed architecture uses <b>application</b> <b>partitioning</b> techniques to offload the execution of service application to a backend node. Hosting of services on wireless devices is challenging, but we have shown that by using the <b>application</b> <b>partitioning</b> techniques proposed in this paper, it is possible to deliver services from such devices that are often characterized by very limited resources and attain good system performance. The paper also discusses a set of design guidelines for partitioning of web service applications to be deployed in wireless environment...|$|E
30|$|All {{the tasks}} of a DFG are thus modeled identically, and the only {{real-time}} constraint is on the total execution time. At each scheduler invocation, this total execution time corresponds to the longest path in the mapped task graph. It then depends both on the <b>application</b> <b>partitioning</b> and on the chosen order of execution on processors.|$|E
40|$|The {{conventional}} {{approach to}} scaling Software Defined Networking (SDN) controllers {{today is to}} partition switches based on network topology, with each partition being controlled by a single physical controller, running all SDN <b>applications.</b> However, topological <b>partitioning</b> {{is limited by the}} fact that (i) performance of latency-sensitive (e. g., monitoring) SDN applications associated with a given partition may be impacted by co-located compute-intensive (e. g., route computation) applications; (ii) simultaneously achieving low convergence time and response times might be challenging; and (iii) communication between instances of an <b>application</b> across <b>partitions</b> may increase latencies. To tackle these issues, in this paper, we explore functional slicing, a complementary approach to scaling, where multiple SDN applications belonging to the same topological partition may be placed in physically distinct servers. We present Hydra, a framework for distributed SDN controllers based on functional slicing. Hydra chooses partitions based on convergence time as the primary metric, but places <b>application</b> instances across <b>partitions</b> in a manner that keeps response times low while considering communication between <b>applications</b> of a <b>partition,</b> and instances of an <b>application</b> across <b>partitions.</b> Evaluations using the Floodlight controller show the importance and effectiveness of Hydra in simultaneously keeping convergence times on failures small, while sustaining higher throughput per partition and ensuring responsiveness to latency-sensitive applications. Comment: 8 page...|$|R
5000|$|NetVault Bare Metal Recovery {{enabling}} {{users to}} restore a computer from its [...] "bare metal" [...] state—including the necessary operating system, network settings, system settings, <b>applications,</b> disk <b>partitions</b> and data.|$|R
30|$|Researchers have {{proposed}} various partitioning {{techniques such as}} range, hash, list, schema level, and graph partitioning to improve scalability. But there is no partitioning technique present, which forms the partitions based on data access patterns of web <b>applications.</b> <b>Partitioning</b> plays {{a very important role}} to optimize the performance and scalability of Online Transaction Processing (OLTP). ElasTras [13] provides a great way to statically partition the data by providing a very high degree of load balancing and generates less number of distributed transactions. But as in OLTP millions of transactions are expected, so there may be a scope for improvement. The design of the systems [8 – 11] described above {{is based on the assumption}} that, an <b>application</b> accesses the <b>partition</b> statically. The <b>applications</b> for which there are dynamic changes in the data access pattern, making use of a static partitioning approach would result in distributed transactions.|$|R
30|$|Fourth, {{since the}} {{trade-offs}} on function placement {{depend on the}} placement of data and vice-versa, we need a model that can reason simultaneously about both application-tier function execution and query plan execution. Thus {{the model for the}} data-tier should be compatible for integration with an approach to <b>application</b> <b>partitioning</b> such as the one described in Section  3.|$|E
40|$|One {{important}} {{optimization technique}} {{for coping with}} resource constrained mobile hosts is <b>application</b> <b>partitioning,</b> the dynamic, resource-depedent distribution of application functionality across the available network nodes. This paper proposes a very pragmatic approach to this concept based on a specific end-user data model, the mobile frame model, which {{is an extension of}} the conventional frame model...|$|E
40|$|Wireless {{networking}} {{technology is}} evolving but is facing problems of limited network bandwidth, high error rates, poor security, etc. New designs in mobile applications {{are needed to}} overcome these problems in mobile computing. Dynamic <b>application</b> <b>partitioning</b> is a potentially useful technique for developing new mobile applications. This thesis presents a case study of an object-oriented mobile e-mail browser, M-Mail, built using the Mentat system, with the mail folders modeled as Mentat objects. This application can be partitioned dynamically according to the wireless network conditions by placing the distributed objects at a mobile client or a proxy server. The thesis further describes a dynamic <b>application</b> <b>partitioning</b> scheme which determines when and how the application should be partitioned. The scheme mainly looks at the following factors: network bandwidth, error rate, latency as well as the size of the mobile objects and the costs of object method invocations. This scheme is im [...] ...|$|E
40|$|The {{proliferation}} of cloud computing {{resources in the}} recent years offers a way for mobile devices with limited resources to achieve computationally intensive tasks in real-time. The mobile-cloud computing paradigm, which involves collaboration between mobile and cloud resources, is expected to become increasingly popular in mobile <b>application</b> development. Dynamic <b>partitioning</b> of ap-plications between mobile and cloud platforms based on resource availability is crucial in achiev-ing the best performance for any computationally intensive mobile application. In this paper, we propose a dynamic performance optimization framework for mobile-cloud computing utilizing mo-bile agent-based <b>application</b> <b>partitions.</b> The proposed framework imposes minimal infrastructural requirements on the cloud servers, therefore exhibiting widespread applicability, as opposed to pre-vious approaches with stricter requirements. Experiments with two real-world mobile applications serve as an initial feasibility study of the proposed framework and demonstrate the superiority of the proposed approach over monolithic execution of resource-intensive applications on mobile devices...|$|R
40|$|The energy {{consumption}} for Mobile Embedded Systems is a limiting factor because of today's battery capacities. The memory subsystem consumes {{a large chunk}} of the energy, necessitating its efficient utilization. Energy efficient scratchpads are thus becoming common, though unlike caches they require to be explicitly utilized. In this paper, an algorithm integrated into a compiler is presented which analyzes the <b>application,</b> <b>partitions</b> an array variable whenever its beneficial, appropriately modifies the application and selects the best set of variables and program parts to be placed onto the scratchpad. Results show an energy improvement between 5. 7 % and 17. 6 % for a variety of applications against a previously known algorithm...|$|R
40|$|Heterogeneous {{computing}} {{opens up}} new {{challenges and opportunities}} in fields such as parallel processing, design of algorithms for <b>applications,</b> <b>partitioning</b> and mapping of parallel tasks, interconnection network tech-nology and the design of heterogeneous programming environments. Lots of load balancing algorithms have been proposed and experimented with in the past years for homogeneous parallel and distributed systems. We present a priority-based decay usage load balancing algorithm for a heterogeneous computing environment. The algorithm determines the task precedence graph of the parallel jobs dynamically at run-time and assigns appropriate priorities to the processes to resolve the dependencies. The heuristic algorithm has been tested on some heterogeneous program models. 1...|$|R
40|$|This paper {{proposes a}} {{solution}} to improve the security of SRAM FPGAs through bitstream encryption. This proposition is distinct from other works because it uses the latest capabilities of SRAM FPGAs like partial and dynamic reconfiguration. It doesn’t need any external battery to store the secret key. It opens {{a new way of}} <b>application</b> <b>partitioning</b> according to the security policy. 1...|$|E
40|$|Part 5 : Big-Data and Cloud ComputingInternational audienceWith the {{functionality}} {{of mobile}} applications ever increasing, designers are often confronted {{with either the}} resource limitations of the devices or of the network. As pointed out by recent work, <b>application</b> <b>partitioning</b> between mobile devices and clouds, {{can be used to}} solve some of these issues, improving performance and/or battery life. In this paper, we argue that the static decisions made in existing work cannot leverage the full potential of <b>application</b> <b>partitioning.</b> Thus, to allow for variations in the execution environment, we have developed a system that dynamically adapts the application partition decisions. The system works by continuously profiling an applications performance and dynamically updating its distributed deployment to accommodate changes in the network bandwidth, devices CPU utilization, and data loads. Using several real applications, we show that our approach provides performance gains as high as 75 % over traditional approaches and achieves lower power consumption by a factor close to 45 %...|$|E
30|$|Application Partitioning: Coign [19] is {{an example}} of classic <b>application</b> <b>partitioning</b> {{research}} which provides partitioning of Microsoft COM components. Other work focuses specifically on partitioning of web/mobile applications such as Swift [20], Hilda [21], and AlfredO [22]. However that work is focused on partitioning the application-tier in order to off-load computation from the server-side to a client. That work does not handle partitioning of the data-tier.|$|E
50|$|As is {{the case}} with most KDE <b>applications,</b> KDE <b>Partition</b> Manager is written in the C++ {{programming}} language and uses the Qt GUI toolkit. Released under the GNU General Public License, KDE Partition Manager is free software.|$|R
5000|$|Peer-to-peer, a {{computing}} or networking distributed <b>application</b> {{architecture that}} <b>partitions</b> tasks or workloads among peers ...|$|R
40|$|Abstract — The energy {{consumption}} for Mobile Embedded Systems is a limiting factor because of today’s battery capacities. The memory subsystem consumes {{a large chunk}} of the energy, necessitating its efficient utilization. Energy efficient scratchpads are thus becoming common, though unlike caches they require to be explicitly utilized. In this paper, an algorithm integrated into a compiler is presented which analyzes the <b>application,</b> <b>partitions</b> an array variable whenever its beneficial, appropriately modifies the application and selects the best set of variables and program parts to be placed onto the scratchpad. Results show an energy improvement between 5. 7 % and 17. 6 % for a variety of applications against a previously known algorithm. I...|$|R
40|$|This paper {{shows how}} {{iterative}} hardware/software partitioning in heterogeneous DSP/FPGA based embedded {{systems can be}} utilized to achieve real-time deadlines of modern 3 GPP wireless equalization workloads. By utilizing a well defined set of <b>application</b> <b>partitioning</b> criteria in tandem with SOC simulation tools, {{we are able to}} show a greater than six fold improvement in application performance and ultimately meet, and even exceed real-time data processing deadlines...|$|E
40|$|The dynamic {{nature and}} {{heterogeneity}} of modern execution environments such as mobile, ubiquitous, and grid computing, present major {{challenges for the}} development and efficient execution of the applications targeted for these environments. In particular, applications tailored to run in a specific environment will show different and most likely sub-optimal behaviour when executed on a different and/or dynamic environment. Consequently, there has been growing interests {{in the area of}} application adaptation which aims to enable applications to cope with the varying execution environments. Adaptive <b>application</b> <b>partitioning,</b> a specific form of non-functional adaptation involving distribution of mobile objects across multiple host machines, is of particular interest to this thesis due to the diversity of its uses. In this approach, certain runtime information (known as context) is used to allow an object-oriented application to adaptively (re) adjust the placement of its objects during its execution, for purposes such as improving application performance and reliability as well as balancing resource utilisation across machines. Promoting the adoption of such adaptation requires a process that requires minimal human involvement in both the execution and the development of the relevant application. These challenges establish the main goals and contributions of this work, which include: 1) Proposing an effective <b>application</b> <b>partitioning</b> solution via the adoption of a decentralised adaptation strategy known as local adaptation. 2) Enabling adaptive <b>application</b> <b>partitioning</b> which does not require human intervention, through automatic collection of required information/context. 3) Proposing a solution for transparently injecting the required adaptation functionality into regular object-oriented applications allowing significant reduction of the associated development cost/effort. The proposed solutions have been implemented in a Java-based adaptation framework called MobJeX. This implementation, which was used as a test bed for the empirical experiments undertaken in this study, can be used to facilitate future research relevant to this particular study...|$|E
40|$|A major {{challenge}} facing ubiquitous computing R&D is {{the difficulty of}} writing software for complex, distributed applications. Automatic <b>application</b> <b>partitioning</b> can help development teams rapidly prototype distributed ubiquitous computing systems. The software-engineering goal of removing obstacles to human creativity is a primary challenge in several areas of computing research. In particular, ubiquitous computing is one area in which researchers have clearly identified the need for software-engineering support. 1, 2 Proponents of ubicomp envision {{a future in which}} computers are inexpensive and plentiful and seamlessly interoperate. Unfortunately, although hard...|$|E
40|$|In {{pervasive}} computing, {{software applications}} vanish into the user’s environment spreading their functionality to computers integrated into everyday devices. With the current state-of-the-art software tools, these characteristics put a great burden on programmers {{who have to}} enable the <b>applications</b> to dynamically <b>partition</b> across multiple devices, and to adapt such partitioning to frequent context changes such as network failures. This paper explores service partitioning techniques for development of pervasive computing applications. We propose a resilient actor model to structurally add service partitioning property to the pervasive <b>applications.</b> The service <b>partitioning</b> realised using resilient actor model happens at runtime, is user guided and the resulting <b>partitioned</b> <b>application</b> is retractable, and resilient to network failures...|$|R
40|$|Offloading is {{one major}} type of collaborations betweenmobile device and cloud to achieve less {{execution}} time andless energy consumption. Offloading decisions for mobile cloudcollaboration involve many decision factors. One of importantdecision factors is the network unavailability {{that has not}} beenwell studied. This paper presents an offloading decision modelthat takes network unavailability into consideration. Networkwith some unavailability can be modeled as an alternatingrenewal process. Then, application execution time and energyconsumption in both ideal network and network with someunavailability are analyzed. Based on the presented theoreticalmodel, an <b>application</b> <b>partition</b> algorithm and a decision moduleare presented to produce an offloading decision that is resistantto network unavailability. Simulation results demonstrate goodperformance of proposed scheme, where partition algorithm isanalyzed in different application and cloud scenarios...|$|R
50|$|QtParted is a Qt {{front-end}} to GNU Parted and {{the official}} KDE <b>Partition</b> Editor <b>application</b> besides KDE <b>Partition</b> Manager.|$|R
40|$|One of {{the main}} {{challenges}} facing ubiquitous computing research and development is the difficulty of writing software for complex, heterogeneous distributed applications. In this paper, we evaluate automatic <b>application</b> <b>partitioning</b> as an approach to rapid prototyping of ubiquitous computing systems. Our approach allows developers to largely ignore distribution issues when developing their applications, by providing tools for generating distribution code automatically, under user guidance. We claim that automatic partitioning is promising for a large class of ubiquitous computing applications and discuss an example ubicomp application re-engineered using our approach...|$|E
40|$|With the {{emergence}} of high quality and rich multimedia content, the end user demands of content processing and delivery are increasing rapidly. In view of increasing user demands and quality of service (QoS), cloud computing offers {{a huge amount of}} online processing and storage resources which can be exploited on demand. Moreover, the current high speed 4 G mobile network i. e. Long Term Evolution (LTE) enables leveraging of the cloud resources. Mobile Cloud Computing (MCC) is an emerging paradigm comprising three heterogeneous domains of mobile computing, cloud computing, and wireless networks. MCC aims to enhance computational capabilities of resource-constrained mobile devices towards rich user experience. Decreasing cloud cost and latency is attracting the research community to exploit the cloud computing resource to offload and process multimedia content in the cloud. High bandwidth and low latency of LTE makes it a suitable candidate for delivering of rich multi-media cloud content back to the user. The convergence of cloud and LTE give rise to an end-to-end communication framework which opens up the possibility for new applications and services. In addition to cloud and network, end user and application constitute the other enti-ties of the end-to-end communication framework. End user quality of service and particular application profile dictate about resource allocation in the cloud and the wireless network. This research formulates different building blocks of the end-to-end communications and in-troduces a new paradigm to exploit the network and cloud resources for the end user. In this way, we employ a multi-objective optimization strategy to propose and simulate an end-to-end communication framework which promises to optimize the behavior of MCC based end-to-end communication to deliver appropriate quality of service (QoS) with utilization of min-imum cloud and network resources. Then we apply <b>application</b> <b>partitioning</b> and offloading schemes to offload certain parts of an application to the cloud to improve energy efficiency and response time. As deliverables of this research, behavior of different entities (cloud, LTE based mobile network, user and application context) have been modeled. In addition, a com-prehensive <b>application</b> <b>partitioning</b> and offloading framework has been proposed in order to minimize the cloud and network resources to achieve user required QoS. Keywords: Long Term Evolution (LTE), Cloud computing, <b>Application</b> <b>partitioning</b> and offloading, Image Retrieval...|$|E
30|$|Internet {{data traffic}} is {{increasing}} exponentially, especially {{the portion of}} traffic going through mobile networks. That is why mobile data computation offloading has become an important issue in cellular networks. As a result, various cloud offloading systems were proposed in the literature. MAUI (Mobile Assistance Using Infrastructure) [1] and ThinkAir [6] describe hardware components and propose to offload data in order to optimize energy consumption of mobile devices. However, they ignore other aspects of offloading. CloneCloud [7] proposes to improve <b>application</b> <b>partitioning</b> between the device and the cloud {{with the purpose of}} reducing energy consumption or execution time.|$|E
40|$|Graph {{partitioning}} is {{an important}} tool for dividing work amongst processors of a parallel machine, but it is unsuitable for some important <b>applications.</b> Specifically, graph <b>partitioning</b> requires the work per processor to be a simple sum of vertex weights. For many applications, this assumption is not true — the work (or memory) is a complex function of the partition. In this paper we describe a general framework for addressing such partitioning problems and investigate its utility on two <b>applications</b> — <b>partitioning</b> so that overlapped subdomains are balanced and partitioning to minimize the sum of computation plus communication time. ...|$|R
40|$|In time-critical {{systems such}} as in avionics, for safety and timing guarantees, {{applications}} are isolated from each other. Resources are partitioned {{in time and space}} creating a <b>partition</b> per <b>application.</b> Such isolation allows fault containment and independent development, testing and verification of <b>applications.</b> Current <b>partitioned</b> systems do not allow dynamically adding applications. Applications are statically loaded in their respective partitions. However dynamic loading can be useful or even necessary for scenarios such as on-board software updates, dynamic reconfiguration or re-loading applications in case of a fault. In this paper we propose a software architecture to dynamically create and manage partitions and a method for compostable dynamic loading which ensures that loading applications do not affect the running applications and vice versa. Furthermore the loading time is also predictable i. e. the loading time can be bounded a priori. We achieve this by splitting the loading process into parts, wherein only a small part which reserves minimum required resources is executed in the system partition and the other parts are executed in the allocated <b>application</b> <b>partition</b> which ensures isolation from other applications. We implement the software architecture for a SoC prototype on an FPGA board and demonstrate its composability and predictability properties...|$|R
40|$|This thesis {{presents}} a novel design paradigm, called Virtual Runtime <b>Application</b> <b>Partitions</b> (VRAP), to judiciously utilize the on-chip resources. As the dark silicon era approaches, where the power considerations will allow {{only a fraction}} chip to be powered on, judicious resource management will become a key consideration in future designs. Most of the works on resource management treat only the physical components (i. e. computation, communication, and memory blocks) as resources and manipulate the component to application mapping to optimize various parameters (e. g. energy efficiency). To further enhance the optimization potential, {{in addition to the}} physical resources we propose to manipulate abstract resources (i. e. voltage/frequency operating point, the fault-tolerance strength, the degree of parallelism, and the configuration architecture). The proposed framework (i. e. VRAP) encapsulates methods, algorithms, and hardware blocks to provide each application with the abstract resources tailored to its needs. To test the efficacy of this concept, we have developed three distinct self adaptive environments: (i) Private Operating Environment (POE), (ii) Private Reliability Environment (PRE), and (iii) Private Configuration Environment (PCE) that collectively ensure that each application meets its deadlines using minimal platform resources. In this work several novel architectural enhancements, algorithms and policies are presented to realize the virtual runtime <b>application</b> <b>partitions</b> efficiently. Considering the future design trends, we have chosen Coarse Grained Reconfigurable Architectures (CGRAs) and Network on Chips (NoCs) to test the feasibility of our approach. Specifically, we have chosen Dynamically Reconfigurable Resource Array (DRRA) and McNoC as the representative CGRA and NoC platforms. The proposed techniques are compared and evaluated using a variety of quantitative experiments. Synthesis and simulation results demonstrate VRAP significantly enhances the energy and power efficiency compared to state of the art...|$|R
