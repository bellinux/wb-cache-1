14|77|Public
50|$|The 386 {{processor}} {{also uses}} 32 bit {{values for the}} <b>address</b> <b>offset.</b>|$|E
50|$|In simple layouts, {{programs}} {{begin their}} execution at the beginning, which {{is common in}} scripting languages, simple binary executable formats, and boot loaders. In other cases, the entry point is at some other fixed point, which is some memory address than can be an absolute address or relative <b>address</b> (<b>offset).</b>|$|E
5000|$|Recent Trusted Platform Module {{specifications}} define special TPM-Read {{cycles and}} TPM-Write cycles {{that are based}} on the I/O Read and the I/O Write cycles. These cycles use a START field with the formerly-reserved value of 0101 and place a 16-bit memory <b>address</b> <b>offset</b> in the address field. These cycles are used when using a TPM's locality facility.|$|E
40|$|In this paper, {{we present}} MemShuffle, an {{end-to-end}} mem-ory protection scheme that resists several attacks on cur-rent memory systems. Our protection scheme provides se-curity against both side channel attacks on caches, {{as well as}} physical on-bus memory snooping, to keep memory secrets within the process that owns them. Our approach utilizes micro-architecture changes in the CPU’s Memory Manage-ment Unit (MMU) to create a secret per-page memory map-ping from virtual <b>address</b> <b>offsets</b> to physical <b>address</b> <b>offsets.</b> This approach minimizes programmer effort, while incurring an average overhead of only 2. 5 %. 1...|$|R
50|$|For {{implementations}} {{of programming}} languages that {{are using a}} compiler, identifiers are often only compile time entities. That is, at runtime the compiled program contains references to memory <b>addresses</b> and <b>offsets</b> rather than the textual identifier tokens (these memory <b>addresses,</b> or <b>offsets,</b> having been assigned by the compiler to each identifier).|$|R
50|$|The link {{fields of}} a {{doubly linked list}} node are often called next and {{previous}} or forward and backward. The references stored in the link fields are usually implemented as pointers, but (as in any linked data structure) {{they may also be}} <b>address</b> <b>offsets</b> or indices into an array where the nodes live.|$|R
50|$|Instructions were of 1, 2 or 3 syllables. Most {{arithmetic}} {{took place}} {{at the top of the}} Nest and used zero-address, 1-syllable instructions, although address arithmetic and index updating were handled separately in the Q store. Q Store handling, and some memory reference instructions, used 2 syllables. Memory reference instructions with a 16-bit <b>address</b> <b>offset,</b> most jump instructions, and 16-bit literal load instructions, all used 3 syllables.|$|E
5000|$|This {{value is}} also the largest {{positive}} signed <b>address</b> <b>offset</b> for 64-bit CPUs utilizing sign-extended memory addressing (such as the AMD x86-64 architecture, which calls this [...] "canonical form" [...] extended addressing). Being an odd value, its appearance may reflect an erroneous (misaligned) memory address. Such a value may {{also be used as}} a sentinel value to initialize newly allocated memory for debugging purposes.|$|E
5000|$|Address, four hex digits, {{representing}} the 16-bit beginning memory <b>address</b> <b>offset</b> of the data. The physical {{address of the}} data is computed by adding this offset to a previously established base address, thus allowing memory addressing beyond the 64 kilobyte limit of 16-bit addresses. The base address, which defaults to zero, can be changed by various types of records. Base addresses and address offsets are always expressed as big endian values.|$|E
50|$|AddressSanitizer {{does not}} prevent any uninitialized memory reads, and only {{prevents}} some use-after-return bugs. It is also not capable of preventing all arbitrary memory corruption bugs. Arbitrary write bugs due to integer underflow/overflows (when the integer with undefined behavior {{is used to calculate}} memory <b>address</b> <b>offsets).</b> Adjacent buffers in structs and classes are not protected from overflow, in part to prevent breaking backwards compatibility.|$|R
5000|$|BRA - Branch Always - Jump to <b>address</b> where <b>offset</b> {{has been}} added to the program counter.|$|R
5000|$|... +----+------------------------------+ |jump| offset | jump {{relative}} +----+------------------------------+ [...] (Effective PC address = next instruction <b>address</b> + <b>offset,</b> offset may be negative) ...|$|R
50|$|Each segment {{begins at}} a {{multiple}} of 16 bytes, called a paragraph, {{from the beginning of}} the linear (flat) address space. That is, at 16 byte intervals. Since all segments are 64 KB long, this explains how overlap can occur between segments and why any location in the linear memory address space can be accessed with many segment:offset pairs. The actual location of the beginning of a segment in the linear address space can be calculated with segment×16. A segment value of 0Ch (12) would give a linear address at C0h (192) in the linear address space. The <b>address</b> <b>offset</b> can then be added to this number. 0Ch:0Fh (12:15) would be C0h+0Fh=CFh (192+15=207), CFh (207) being the linear address. Such address translations are carried out by the segmentation unit of the CPU. The last segment, FFFFh (65535), begins at linear address FFFF0h (1048560), 16 bytes before the end of the 20 bit address space, and thus, can access, with an offset of up to 65,536 bytes, up to 65,520 (65536−16) bytes past the end of the 20 bit 8088 address space. On the 8088, these address accesses were wrapped around to the beginning of the address space such that 65535:16 would access address 0 and 65533:1000 would access address 952 of the linear address space. Programmers using this feature led to the Gate A20 compatibility issues in later CPU generations, where the linear address space was expanded past 20 bits.|$|E
40|$|Automatic {{optimization}} of <b>address</b> <b>offset</b> {{assignment for}} DSP applications, which reduces {{the number of}} address arithmetic instructions to meet the tight memory size restrictions and performance requirements, {{received a lot of}} attention in recent years. However, most of current research focuses at the basic block level and does not distinguish different program structures, especially loops. Moreover, the effectiveness of modify register (MR) is not fully exploited since it is used only in the post optimization step. In this paper, a novel <b>address</b> <b>offset</b> assignment approach is proposed at the procedural level. The MR is effectively used in the address assignment for loop structures. By taking advantage of MR, variables accessed in sequence within a loop are assigned to memory words of equal distances. Both static and dynamic addressing instruction counts are greatly reduced. For DSPSTONE benchmarks and on average, 9. 9 %, 17. 1 % and 21. 8 % improvements are achieved over <b>address</b> <b>offset</b> assignment [4] together with MR optimization when there is 1, 2 and 4 address registers respectively. ...|$|E
40|$|Reducing address {{arithmetic}} operations by optimization of <b>address</b> <b>offset</b> assignment greatly {{improves the}} performance of digital signal processor (DSP) applications. However, minimizing address operations alone may not directly reduce code size and schedule length for DSPs with multiple functional units. Little research work has been conducted on loop optimization with <b>address</b> <b>offset</b> assignment problem for architectures with multiple functional units. In this paper, we combine loop scheduling, array interleaving, and address assignment to minimize the schedule length {{and the number of}} address operations for loops on DSP architectures with multiple functional units. Array interleaving is applied to optimize address assignment for arrays in loop scheduling process. An algorithm, Address Operation Reduction Rotation Scheduling (AORRS), is proposed. The algorithm minimizes both schedule length and the number of address operations. with to list scheduling, AORRS shows an average reduction of 38. 4 % in schedule length and an average reduction of 31. 7 % in the number of address operations. Compared with rotation scheduling, AORRS shows an average reduction of 15. 9 % in schedule length and 33. 6 % in the number of address operations. Department of Computin...|$|E
40|$|A surface micromachined {{pressure}} sensor array {{has been designed}} and fabricated. The sensors are based upon deformable, silicon nitride diaphragms with polysilicon piezoresistors. Absolute pressure is detected by virtue of reference pressure cavities underneath the diaphragms. For this type of sensor, design tradeoffs must be made among allowable diaphragm deflection, diaphragm size, and desirable pressure ranges. Several fabrication issues were observed and <b>addressed.</b> <b>Offset</b> voltage, sensitivity, and nonlinearity of 100 µm diameter sensors were measured. 1...|$|R
40|$|Communication {{components}} (address, instruction, {{and data}} buses and associated hardware like I/O pins, pads, and buffers) are contributing increasingly to the area/cost and power consumption of microprocessor systems. To decrease costs due to address buses, we propose to use narrow widths for underutilized buses (hardware-only compression) to transmit information in multiple cycles. We analyze performance and power consumption overheads of hardware-only compression and investigate {{the use of}} “address concatenation ” to mitigate performance loss and <b>address</b> <b>offsets</b> and XORs to reduce power consumption overheads. ...|$|R
5000|$|... +------+-----+-----+-----+----------------+ | load | reg | base|index| offset | +------+-----+-----+-----+----------------+ [...] (Effective <b>address</b> = <b>offset</b> + {{contents}} of specified base register + {{contents of}} specified index register) ...|$|R
40|$|Conference Name:International Workshop on Anti-counterfeiting, Security, and Identification. Conference Address: Xiamen, PEOPLES R CHINA. Time:APR 16 - 18, 2007. The {{main goal}} {{of this paper is}} to {{evaluate}} the anti-interference performance of a Bluetooth piconet in a multi-Bluetooth piconets environment. An overview of the frequency hop selection mechanism is presented and the basic design based on 79 -hop is described. We study correlation characteristics of the hopping sequences in typical scenarios and the simulation results show that the interference caused by the neighboring Bluetooth piconet is sensitive both to the <b>address</b> <b>offset</b> and the frequency offset between the victim and the inbreaker...|$|E
40|$|The {{proposed}} WIDAR correlator for the EVLA aims to use {{the method}} of `recirculation' to greatly increase the spectral resolution capabilities of the correlator at narrow bandwidths. This method involves buffering low sample rate data, and then bursting it at high data rates through the correlator with different relative station delays [...] -or buffer address offsets [...] -to effectively provide many more correlator lags for the hardware available. This memo investigates the basic recirculation architecture {{within the context of}} the proposed design, develops a buffer <b>address</b> <b>offset</b> algorithm, and discusses some fundamental limitations of the technique in terms of SNR degradation and integration time. Introduction In [1], the basic architecture of the proposed WIDAR correlator for the EVLA was presented. In that document so-called recirculation is used to provide very high spectral resolution when correlating narrow bandwidths. This capability was included in the design by request of NRAO at [...] ...|$|E
40|$|Reducing address {{arithmetic}} instructions by optimization of <b>address</b> <b>offset</b> assignment greatly {{improves the}} performance of DSP applications. However, minimizing address operations alone may not directly reduce code size and schedule length for multiple functional units DSPs. In this paper, we exploit address assignment and scheduling for application with loops on multiple functional units DSPs. Array transformation is used in our approach to leverage the indirect addressing modes provided {{by most of the}} DSP architectures. An algorithm, Address Instruction Reduction Loop Scheduling (AIRLS), is proposed. The algorithm utilizes the techniques of rotation scheduling, address assignment and array transformation to minimize both address instructions and schedule length. Compared to the list scheduling, AIRLS shows an average reduction of 35. 4 % in schedule length and an average reduction of 38. 3 % in address instructions. Compared to the rotation scheduling, AIRLS shows an average reduction of 19. 2 % in schedule length and 39. 5 % in the number of address instructions...|$|E
5000|$|The x86 {{architecture}} is a variable instruction length, primarily [...] "CISC" [...] design {{with emphasis on}} backward compatibility. The instruction set is not typical CISC, however, but basically an extended version of the simple eight-bit 8008 and 8080 architectures. Byte-addressing is enabled and words are stored in memory with little-endian byte order. Memory access to unaligned addresses is allowed for all valid word sizes. The largest native size for integer arithmetic and memory <b>addresses</b> (or <b>offsets)</b> is 16, 32 or 64 bits depending on architecture generation (newer processors include direct support for smaller integers as well). Multiple scalar values can be handled simultaneously via the SIMD unit present in later generations, as described below. Immediate <b>addressing</b> <b>offsets</b> and immediate data may be expressed as 8-bit quantities for the frequently occurring cases or contexts where a -128..127 range is enough. Typical instructions are therefore 2 or 3 bytes in length (although some are much longer, and some are single-byte).|$|R
50|$|A {{machine code}} {{instruction}} set may have all instructions {{of the same}} length, or it may have variable-length instructions. How the patterns are organized varies strongly with the particular architecture and often also {{with the type of}} instruction. Most instructions have one or more opcode fields which specifies the basic instruction type (such as arithmetic, logical, jump, etc.) and the actual operation (such as add or compare) and other fields that may give the type of the operand(s), the addressing mode(s), the <b>addressing</b> <b>offset(s)</b> or index, or the actual value itself (such constant operands contained in an instruction are called immediates).|$|R
5000|$|The CP1600's {{instruction}} set closely followed the PDP-11's, {{but was not}} entirely compatible. The instruction opcode was only 10 bits, with the remaining 6 marked [...] "Reserved for future expansion". It appears that the extra 6 bits were intended {{to be used with}} co-processors, asserting the PCIT line which stalled the CPU until released. Instructions might be one to three words long depending on the addressing format being used. Unlike similar CPUs, the CP1600 did not support memory-memory indirect <b>addressing</b> (<b>offsets),</b> and looping was implemented in a different way which allowed it to run much faster.|$|R
40|$|Abstract. Oblivious RAM (ORAM) is a {{cryptographic}} primitive {{that allows}} a trusted CPU to securely access untrusted memory, such that the access patterns reveal nothing about sensitive data. ORAM {{is known to have}} broad applications in secure processor design and secure multi-party computation for big data. Un-fortunately, due to a logarithmic lower bound by Goldreich and Ostrovsky (Jour-nal of the ACM, ’ 96), ORAM is bound to incur a moderate cost in practice. In particular, with the latest developments in ORAM constructions, we are quickly approaching this limit, and the room for performance improvement is small. In this paper, we consider new models of computation in which the cost of obliv-iousness can be fundamentally reduced in comparison with the standard ORAM model. We propose the Oblivious Network RAM model of computation, where a CPU communicates with multiple memory banks, such that the adversary ob-serves only which bank the CPU is communicating with, but not the <b>address</b> <b>offset</b> within each memory bank. In other words, obliviousness within each bank comes for free—either because the architecture prevents a malicious party fro...|$|E
40|$|Oblivious RAM (ORAM) is a {{cryptographic}} primitive {{that allows}} a trusted CPU to securely access untrusted memory, such that the access patterns reveal nothing about sensitive data. ORAM {{is known to have}} broad applications in secure processor design and secure multi-party computation for big data. Unfortunately, due to a well-known logarithmic lower bound by Goldreich and Ostrovsky (Journal of the ACM, ’ 96), ORAM is bound to incur a moderate cost in practice. In particular, with the latest developments in ORAM constructions, we are quickly approaching this limit, and the room for performance improvement is small. In this paper, we consider new models of computation in which the cost of obliviousness can be fundamentally reduced in comparison with the standard ORAM model. We propose the Oblivious Network RAM model of computation, where a CPU communicates with multiple memory banks, such that the adversary observes only which bank the CPU is communicating with, but not the <b>address</b> <b>offset</b> within each memory bank. In other words, obliviousness within each bank comes for free—either because the architecture prevents a malicious party from ob-serving the address accessed within a bank, or because another solution is employed to obfuscate memory accesses within each bank—and hence we only need to obfuscate the communication patterns between the CPU and the memory banks. We present several new constructions for obliviously simulating general or parallel programs in the Network RAM model. We describe applications of the Network RAM model in secure processor design and in distributed storage applications with a network adversary. ...|$|E
5000|$|This is {{sometimes}} referred to as 'base plus displacement' +------+-----+-----+----------------+ | load | reg | base| offset | reg := RAM+ offset +------+-----+-----+----------------+ [...] (Effective <b>address</b> = <b>offset</b> + contents of specified base register) ...|$|R
5000|$|Convert {{the target}} <b>address</b> to an <b>offset</b> and bit {{number in the}} bitmap.|$|R
50|$|The 80386 and its successors fully {{support the}} 16-bit {{segments}} of the 80286 but also segments for 32-bit <b>address</b> <b>offsets</b> (using the new 32-bit width of the main registers). If the base address of all 32-bit segments is set to 0, and segment registers are not used explicitly, the segmentation can be forgotten and the processor appears as having a simple linear 32-bit address space. Operating systems like Windows or OS/2 provide the possibility to run 16-bit (segmented) {{programs as well as}} 32-bit programs. The former possibility exists for backward compatibility and the latter is usually meant to be used for new software development.|$|R
5000|$|Multiple (local) literal pools are {{typically}} {{used only for}} computer architectures that lack branch instructions for long jumps, or {{have a set of}} instructions optimized for shorter jumps. Examples of such architectures include ARM architecture and the IBM System/360 and later architectures, which had a number of instructions which took 12-bit <b>address</b> <b>offsets.</b> In this case, the compiler would create a literal table on every 4K page; any branches whose target was less than 4K bytes away could be taken immediately; longer branches required an address lookup via the literal table. The entries in the literal pool are placed into the object relocation table during assembly, and are then resolved at link edit time.|$|R
50|$|In the Intel 80386 and later, {{protected}} mode retains the segmentation mechanism of 80286 {{protected mode}}, but a paging unit {{has been added}} as a second layer of address translation between the segmentation unit and the physical bus. Also, importantly, <b>address</b> <b>offsets</b> are 32-bit (instead of 16-bit), and the segment base in each segment descriptor is also 32-bit (instead of 24-bit). The general operation of the segmentation unit is otherwise unchanged. The paging unit may be enabled or disabled; if disabled, operation {{is the same as}} on the 80286. If the paging unit is enabled, addresses in a segment are now virtual addresses, rather than physical addresses as they were on the 80286. That is, the segment starting <b>address,</b> the <b>offset,</b> and the final 32-bit address the segmentation unit derived by adding the two are all virtual (or logical) addresses when the paging unit is enabled. When the segmentation unit generates and validates these 32-bit virtual addresses, the enabled paging unit finally translates these virtual addresses into physical addresses. The physical addresses are 32-bit on the 386, but can be larger on newer processors which support Physical Address Extension.|$|R
5000|$|To include time-continuous content such as {{audio and}} video media into the Web, it is {{necessary}} to be able to point hyperlinks into such content to <b>address</b> temporal <b>offsets.</b> Further information can be found at Annodex Time Intervals in URI Queries and Fragments ...|$|R
5000|$|... a new <b>offset</b> <b>addressing</b> mode; some {{addresses}} {{which were}} {{relative to the}} access bank are now interpreted relative to the FSR2 register ...|$|R
40|$|This article {{explores the}} {{practice}} of governments imposing domestic content based requirements known as “offsets” on suppliers {{in order to secure}} public procurement contracts. Known to cause distortions in international trade, offsets are forbidden under the WTO’s GPA and in the procurement chapters of several RTAs, although these restrictions have severe limitations with full offset prohibitions only accepted by a handful of developed countries. Given the sensitivity of procurement policy and the need to stimulate local economies, Asian countries in particular show an unwillingness to <b>address</b> <b>offsets</b> in their international agreements. While other WTO agreements restrain the use of local content rules, these regimes are ill-suited to control the harmful effects of offsets in a procurement context because of their focus on traditional commercial markets. The article suggests that an enlargement of offset prohibitions would be advisable given the expected expansion of global procurement markets commensurate with economic development...|$|R
5000|$|Internal {{memory of}} 8000 8-bit words memory {{is divided into}} 32-word pages. Instruction memory could be {{accessed}} using an instruction pointer. Data could be <b>addressed</b> using page:word <b>offset.</b>|$|R
30|$|Translation of the {{physical}} <b>address</b> to an <b>offset</b> inside the dump. This depends on the storage format and requires the meta information for memory segment mapping inside the dump.|$|R
