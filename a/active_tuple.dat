2|2|Public
40|$|This report {{sets out}} {{the results of}} an {{investigation}} into the distributed implementation of tuple spaces, hence Linda. There are numerous such schemes for implementing distributed tuple spaces, and a selection of these implementations are examined. It is observed that all the implementations {{have a great deal of}} similarities. These similarities form the basis for a generalised tuple space implementation, where specific implementations are formed by the appropriate selection of options for various choice points. 1 Introduction 1. 1 Linda Linda[Gel 85, CG 89] is a coordination language providing communication via tuple space, which is a global associative memory consisting of a bag (or multi-set) of tuples. Tuples are of two sorts: passive (tuple elements are data only) and <b>active</b> (<b>tuple</b> elements are functions). When the functions of an <b>active</b> <b>tuple</b> have completed, a passive tuple replaces it. The following operations operate on tuple space: out(t) takes a (passive) tuple, t, (containing [...] ...|$|E
40|$|Several {{attempts}} have been made to produce a (generally adopted) semantics for the generative communication coordination language Linda. However, none has been universally recognised as definitive. Therefore, there are various possible interpretations regarding the semantics of Linda operations. This report presents a survey of a variety of those attempts to produce a semantics for Linda. Also, an attempt is made to identify the areas of confusion which arise, and the possibilities which selecting different choices provide. 1 Introduction 1. 1 Linda Informally, Linda [Gel 85, CG 89] is a coordination language which provides communication via tuple space, which is a global associative memory consisting of a bag (or multi-set) of tuples. Tuples are of two sorts: passive (tuple elements are data only) and <b>active</b> (<b>tuple</b> elements are processes). When the processes of an <b>active</b> <b>tuple</b> have completed, a passive tuple replaces it. The following operations operate on tuple space: out(t) takes a [...] ...|$|E
40|$|In {{databases}} {{with time}} interval attributes, query processing techniques {{that are based}} on sort-merge or sort-aggregate deteriorate. This happens because for intervals no total order exists and either the start or end point is used for the sorting. Doing so leads to inefficient solutions with lots of unproductive comparisons that do not produce an output tuple. Even if just one tuple with a long interval is present in the data, the number of unproductive comparisons of sort-merge and sort-aggregate gets quadratic. In this paper we propose disjoint interval partitioning (DIP), a technique to efficiently perform sort-based operators on interval data. DIP divides an input relation into the minimum number of partitions, such that all tuples in a partition are non-overlapping. The absence of overlapping tuples guarantees efficient sort-merge computations without backtracking. With DIP the number of unproductive comparisons is linear in the number of partitions. In contrast to current solutions with inefficient random accesses to the <b>active</b> <b>tuples,</b> DIP fetches the tuples in a partition sequentially. We illustrate the generality and efficiency of DIP by describing and evaluating three basic database operators over interval data: join, anti-join and aggregation...|$|R
40|$|Given a dataset P and a {{preference}} function f, a top-k query retrieves the k tuples in P {{with the highest}} scores according to f. Even though the problem is well-studied in conventional databases, the existing methods are inapplicable to highly dynamic environments involving numerous long-running queries. This paper studies continuous monitoring of top-k queries over a fixed-size window W {{of the most recent}} data. The window size can be expressed either {{in terms of the number}} of <b>active</b> <b>tuples</b> or time units. We propose a general methodology for top-k monitoring that restricts processing to the sub-domains of the workspace that influence the result of some query. To cope with high stream rates and provide fast answers in an on-line fashion, the data in W reside in main memory. The valid records are indexed by a grid structure, which also maintains book-keeping information. We present two processing techniques: the first one computes the new answer of a query whenever some of the current top-k points expire; the second one partially pre-computes the future changes in the result, achieving better running time at the expense of slightly higher space requirements. We analyze the performance of both algorithms and evaluate their efficiency through extensive experiments. Finally, we extend the proposed framework to other query types and a different data stream model. Copyright 2006 ACM...|$|R

