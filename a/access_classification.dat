15|56|Public
5000|$|With an {{automated}} Global Classification solution, companies can collect, store, and <b>access</b> <b>classification</b> data in one centralized located at both {{a global level}} using the World Customs Organization (WCO) 6-digit Harmonized Schedule Numbers and with multiple country specific views tailored to the country of interest. As a result, thecentrally controlled classification database reduces errors, increases internal and external communication, strengthens compliance, and improves the timeliness of the information shared with external trading partners. Using {{an automated}} solution, companies can: ...|$|E
50|$|Robin Boast (born 2 March 1956) is the Professor of Information Science and Culture at the University of Amsterdam, Department of Media Studies. Until {{the end of}} 2012 he was the Deputy Director and Curator for World Archaeology at the Museum of Archaeology and Anthropology at the University of Cambridge (MAA). He teaches on Cultural Information Science, Neo-colonial {{information}} governance, and {{the history}} and sociology of digitally and collecting. He has been a Visiting Professor at the European University Institute in Florence Italy, a Scientific Advisor for several EU projects, and was the Director of the Virtual Teaching Collection Project. Dr. Boast has worked in museums in the US and Britain for over 30 years, specializing in museum <b>access,</b> <b>classification</b> and documentation, especially around diverse knowledge communities. Through a program of historical, theoretical and practical inquiry, his research explores forms of informed, collaborative and critical access to museum spaces and collections. Dr. Boast is currently working with many indigenous communities {{around the world that}} seek to enable and re-centre the many dimensions of local knowledge expertise within the academy - research informed by the critiques of the Sociology of Scientific Knowledge, Post-colonial studies, Indigenous Studies and collaborative developments in e-Science. Dr. Boast has worked for several years on an international research project which subjects the museum and the academy to the ethnographic gaze of indigenous partners to de-centre the ownership and control of research of indigenous patrimony. His most recent work has been with source community museums and heritage organizations with Dr. Ramesh Srinivasan and Mr. James Enote, primarily at the A:shiwi A:wan Museum & Heritage Center in Zuni, New Mexico (USA).|$|E
40|$|The Minnesota Department of Natural Resources (MN DNR) {{would like}} to be {{proactive}} in the development of Wildlife Management Area (WMA) Access Plans to assist with any potential disagreement that may result in different views of access to WMAs as well as to plan future access needs. A WMA <b>access</b> <b>classification</b> system was developed to help describe access on WMAs. A GIS model was developed to provide a means to develop a WMA <b>access</b> <b>classification</b> system through a path distance function. Path distance analysis is a very effective way to model distances a user could travel from parking areas on a WMA to any portion of a WMA that is not restricted by barriers. Several statistics were calculated across walking distance zones to describe the percent slope. Many recreation managers describe the degree of difficulty for traversing a path or area with classifications of percent slope. As with many types of GIS analyses, the accuracy of the data used is very important {{to the quality of the}} resulting analysis. Future data collection and acquisition for the use of maps and the WMA <b>access</b> <b>classification</b> system should be considered for providing a clear picture of access on WMAs...|$|E
50|$|Inmates have <b>access</b> to <b>classification</b> {{and mental}} health counselors at MCC, in {{addition}} {{to a wide range of}} paid and volunteer staff.|$|R
50|$|Classification - APC {{provides}} Australian {{athletes with}} a disability with <b>access</b> to <b>classification</b> by a trained classifier {{at all levels of}} their development.|$|R
3000|$|Separating traffic into flows {{requires}} a flow classifier. For WMNs providing last mile <b>access,</b> this <b>classification</b> can {{be based on}} source or destination mesh routers. Thus, a flow f [...]...|$|R
40|$|The {{development}} {{and diversity of}} information resources used in e-learning training generate problems of <b>access,</b> <b>classification</b> and management. In this article, we present {{the results of a}} research study about knowledge engineering focussed on the use of an organizational memory on the basis of ontologies (hierarchies of concepts hierarchies) (Chaput & al., 2004). This work allows the capitalization and th...|$|E
40|$|This paper deals about pricing {{services}} on the Internet. In the media, as audience increases advertising benefits, firms often tariff under their cost. However, Internet has a specificity: when firms offer complementary services, complementarity can benefit to competitors. The {{purpose of this}} paper is to analyze the effects of competition and vertical integration on pricing strategies and particularly on free <b>access.</b> <b>Classification</b> JEL : D 4, L 1...|$|E
40|$|This article {{considers}} {{the current state}} in Australia of education for cataloguing and classification (considered broadly and encompassing descriptive cataloguing, subject <b>access,</b> <b>classification,</b> metadata, knowledge organisation, bibliographic control, and other related areas for all formats of library resources). Data comes from, subject and course descriptions located in the handbook entries and web sites of Australian programs in library and information studies, and from an informal survey of practising cataloguers and library educators. Conclusions are drawn about the range of subjects taught, their focus, and their levels...|$|E
50|$|Current ad hoc AILA {{committees}} {{include the}} Budget and Finance Committee, By-Laws and Constitution Committee, Children's Literature Award Committee, Communications and Publications Committee, Development and Fundraising Committee, Distinguished Service Award Committee, Nominating Committee, Programming Committee, Subject <b>Access</b> and <b>Classification</b> Committee, and the Scholarship Review Board.|$|R
40|$|Abstract. This paper first briefly {{introduces}} the basic {{overview of the}} broadband <b>access</b> and the <b>classification.</b> Second this paper focuses on broadband access network technology application of optical fiber, finally puts forward {{the development of the}} optical fiber broadband access network might cover APON, BPON and EPON phase, from broadband pointto-point Ethernet fibre optic system and GEPON start and even finally GPON phase transition to the initial assumption...|$|R
40|$|The goal of {{this paper}} is to show the {{interest}} of combining various text analysis techniques (shallow parsing, semantic analysis, etc.) and some information <b>access</b> techniques (indexing, <b>classification,</b> clustering, mapping)) to developp an information analysis system to be used and customized by non-specialists of documentary languages. The paper shows how these techniques can be integrated to for a process chain including : XML reformating, information extraction, clustering, mapping...|$|R
40|$|The high {{performance}} delivered by modern computer system keeps scaling with an increasingnumber of processors connected using distributed network on-chip. As a result, memory accesslatency, largely dominated by remote data cache access and inter-processor communication, {{is becoming a}} critical performance bottleneck. To release this problem, {{it is necessary to}} localize data access as much as possible while keep efficient on-chip cache memory utilization. Achieving this however, is application dependent and needs a keen insight into the memory access characteristics of the applications. This thesis demonstrates how using fairly simple thus inexpensive compiler analysis memory accesses can be classified into private data access and shared data access. In addition, we introduce a third classification named probably private access and demonstrate the impact of this category compared to traditional private and shared memory classification. The memory <b>access</b> <b>classification</b> information from the compiler analysis is then provided to the runtime system through a modified memory allocator and page table to facilitate a hybrid private-shared caching technique. The hybrid cache mechanism is aware of different data <b>access</b> <b>classification</b> and adopts appropriate placement and search policies accordingly to improve performance. Our analysis demonstrates that many applications have a significant amount of both private and shared data and that compiler analysis can identify the private data effectively for many applications. Experimentsresults show that the implemented hybrid caching scheme achieves 4. 03 % performance improvement over state of the art NUCA-base caching...|$|E
40|$|Abstract There is no {{standardized}} {{definition of}} difficult polyps. However, polyps become difficult and challenging to remove endoscopically {{when they are}} large in size, flat in nature, situated in a high-risk location and when access to them is very awkward. Recently, an SMSA (Size, Morphol-ogy, Site, <b>Access)</b> <b>classification</b> has been proposed that helps to qualify the degree of difficulty by scoring on the above parameters. This article reviews the features that make polyps difficult to remove and provides some practical tips in managing these difficult polyps. We believe that ‘difficult polyp ’ is a relative term and each endoscopist should define their own level of difficulty and what {{they would be able}} to handle safely. However, in expert trained hands, most difficult polyps can be safely removed by an endoscopic approach...|$|E
40|$|Input/output {{performance}} on current parallel file systems {{is sensitive to}} a good match of application access pattern to file system capabilities. Automatic input/output <b>access</b> <b>classification</b> can determine application access patterns at execution time, guiding adaptive file system policies. In this paper we examine a new method for access pattern classification that uses hidden Markov models, trained on access patterns from previous executions, to create a probabilistic model of input/output accesses. We compare this approach to a neural network classification framework, presenting performance results from parallel and sequential benchmarks and applications. 1 Introduction Input/output is a critical bottleneck for many important scientific applications. One reason is that performance of extant parallel file systems is particularly sensitive to file access patterns. Often the application programmer must match application input/output requirements to {{the capabilities of the}} file system [...] . ...|$|E
40|$|Traditionally, maximizing input/output {{performance}} has required tailoring application input /output patterns to the idiosyncrasies of specific input/output systems. In this paper, {{we show that}} one can achieve high application input/output performance via a low overhead input /output system that automatically recognizes file access patterns and adaptively modifies system policies to match application input/output needs. This approach reduces the application developer's input/output optimization effort by isolating input/output optimization decisions within a retargetable file system infrastructure. To validate these claims, we have built a lightweight file system policy testbed that uses a trained learning mechanism to recognize access patterns. The file system then uses these <b>access</b> pattern <b>classifications</b> to select appropriate caching strategies, dynamically adapting file system policies to changing input/output demands throughout application execution. Our experimental data show dram [...] ...|$|R
40|$|Prior {{work has}} shown that goal {{crossing}} {{may be a more}} accessible interaction technique than conventional pointing-and-clicking for motor-impaired users. Although goal crossing with pen-based input devices has been studied, pen-based designs have limited applicability on the desktop because the pen can “fly in, ” cross, and “fly out, ” whereas a persistent mouse cursor cannot. We therefore explore possible designs for accessible mouse-based goal crossing widgets that avoid triggering unwanted goals by using secondary goals, gestures, and corners and edges. We identify four design principles for accessible desktop goal crossing widgets: ease of use for motor-impaired users, safety from false selections, efficiency, and scalability. Keywords: Crossing-based interfaces, input, human performance, mouse cursor, desktop accessibility, motor impairments, computer <b>access.</b> ACM <b>Classification</b> Keywords H 5. 2. [Information interfaces and presentation]: User interfaces – input devices and strategies. Copyright is held by the author/owner(s) ...|$|R
40|$|Abstract—Data {{rates on}} Internet links keep {{increasing}} with {{the deployment of}} optical technology. Packets coming into high-speed networks need to be classified quickly. Different packet classification schemes have been developed but they require a number of memory <b>accesses</b> as <b>classification</b> is complex and memory is slow. We follow the approach of providing support with fast memory, as cache, in computer systems, to support packet classification schemes. Here, we propose a scheme based on memory cache to support packet classification. The scheme not only makes use of faster and smaller memories but also reduces the number of memory accesses to perform packet classification. It can make {{the performance of the}} adopted classification scheme independent of the number of connection flows. We present various packet-classification caching schemes for performing classification and provide the cache hit ratio results for various traffic models generated with Classbench...|$|R
40|$|In recent work, we {{described}} a data prefetch mechanism for pointer-intensive and numeric computations, and presented some aggregate measurements on {{a suite of}} benchmarks to quantify its performance potential [MH 95]. The basis for this device is a simple classification of memory access patterns in programs that we introduced earlier [HM 94]. In this paper we {{take a close look}} at two codes from our suite, an English parser called Link-Gram, and the circuit simulation program spice 2 g 6, and present a detailed analysis of them in the context of our model. Focusing on just two programs allows us to display a wider range of data, and discuss relevant code fragments extracted from their source distributions. Results from this study provide a deeper understanding of our memory <b>access</b> <b>classification</b> scheme, and suggest additional optimizations for future data prefetch mechanisms. Keywords: CPU architecture, data cache, memory access pattern classification, instruction profiling, memory latency t [...] ...|$|E
40|$|The study {{responds}} to the new paradigms of knowledge organization in the 21 st century, trying to assess whether the current Czech terminology is still corresponding to it. We analyze and review Czech equivalents to the terms: knowledge organization, subject <b>access,</b> <b>classification,</b> subject headings, and indexing language (subject, systematic). The respective terms {{were introduced to the}} Czech terminology primarily due to Blahoslav Kovář during the 1970 s. Early in 2000 s they have been incorporated into the Czech terminology database of library and information science (TDKIV). Our analysis is based on the study of the theoretical literature focused at conceptual and terminological principles of the field. The methodology is based on modeling; we provide a comparison of Kovář's process model with our own proposal of an updated model of knowledge organization, adapted to the changed paradigm. Kovář's model sees knowledge organization as a sub-process of input and output processing phase within the framework of linear communication in the information system. The proposed updated model presents an extended concept of knowledge organization as a process carried on during several stages of the information lifecycle, in the information system and beyond, within the context of non-linear network environment...|$|E
40|$|PURPOSE: The {{use of a}} 2. 0 -mm {{locking plate}} system was {{evaluated}} in mandibular surgery. PATIENTS AND METHODS: 53 patients (42 male, 11 female) {{with a total of}} 56 mandibular fractures were treated with a 2. 0 -mm mini-locking-plate system and retrospectively examined. Gender, age, cause of fracture, surgical <b>access,</b> <b>classification</b> of fractures, osteosynthesis, postsurgical findings and complications were evaluated. RESULTS: Assault in male patients (mean age 31) was the most common aetiological factor. Fractures in women (mean age 43 years) mostly occurred due to falls. Mandibular angle fractures were the most common and this anatomical site also presented the highest complication rate. Only 6 % of patients had minor occlusal disturbance postoperatively, and minor complications (infections and dehiscence) occurred in 14 %of patients in this study. Major complications only occurred in one patient included in the study (1. 9 %). Risk factors for the development of complications in this series were a history of alcohol or tobacco use, mandibular angle fractures, associated facial fractures, presurgical occlusal disturbance and concomitant dental infections. Surgical access to the fracture and the interval from injury to surgery was not associated with the development of complications. CONCLUSIONS: The use of a 2. 0 -mm locking plate system with its advantages of improved handling characteristics, increased stability, shorter surgical time and the preservation of bony perfusion is a viable alternative to conventional miniplates in the management of mandibular fractures...|$|E
40|$|This paper {{describes}} {{the development of}} EyeDraw, a software system that enables children with severe motor impairments to draw pictures by just moving their eyes. EyeDraw will help these children to have creative and developmental experiences currently missing from their lives. The project demonstrates how task analysis integrated at various levels of detail, including that of the unit task {{as well as that}} of visual-perceptual and oculomotor processing, can improve eye tracking for real-time input. The project introduces refined techniques for controlling a computer with the eyes. The paper discusses the motivation for the project, previous research on eye-control of computers, how EyeDraw works, and the results of user observation studies that are currently in progress. Author Keywords Children, eye tracking, input devices, interaction techniques, universal <b>access.</b> ACM <b>Classification</b> Keywords H. 5. 2. User Interfaces: Input devices and strategies, interaction styles...|$|R
40|$|Abstract. We have {{developed}} an internet browser that functions {{in conjunction with a}} brain-computer interface, enabling world wide web <b>access</b> through real-time <b>classification</b> of the P 300 event related potential. Standard page navigation tools, hyperlink selection and page scrolling are available through user selection of symbols presented on a separate screen. The system was tested in healthy subjects, although future work will consist of testing the system with patients with severe paralysis (Locked-in Syndrome) to further evaluate the usefulness of the system for those lacking voluntary movement or control...|$|R
40|$|This {{review was}} {{completed}} {{at the request}} of the California Attorney General (AG) and the Youth Authority (YA). Issues to be examined were cited in federal and state court lawsuits filed by the Prison Law Office (PLO). My charge was to answer a set of specific questions, and to make recommendations for improvements as needed. The areas covered in this report are the following: ward <b>classification,</b> <b>access</b> to lawyers and ward's rights; use of force and ward safety; restricted programs, including special management programs and temporary detention; and access to religious services...|$|R
40|$|This report {{covers a}} {{feasibility}} {{study for the}} introduction of Network Access Control (NAC) at Vanderlande Industries. The focus of this report is on a network based access control architecture with as main research questions: What is the best architecture for a NAC solution in this environment? To answer this question, the different stages of network based NAC and their possible techniques are discussed. In chronological order these stages are: detection, registration and authentication, policy enforcement, preadmission control, <b>access</b> <b>classification</b> and post admission scanning. In the chapters about these stages, practical issues to implement them at the company will be unfolded. Also, a number of sections contain practical verifications of the findings. What elements and services {{should be part of}} this architecture? Elements and services that {{should be part of the}} architecture are placed in different environments the NAC solution can place clients into. In these environments, services as authentication, remediation (e. g. update repositories) and health check systems (e. g. vulnerability scanners and intrusion detection systems) need to be deployed. What organizational processes should be in place for an introduction of this technique? The architecture unfolded in this report is mainly based on the self-service aspect of the future users. Because of this, only IT management and helpdesk support processes should be in place. Next to this, the current processes on adding extra network equipment, asset management and the hardening of clients should be reviewed. Is network based NAC feasible technology for this situation? Some specific elements from a client-based approach are needed to make the solution complete. In general, the network based approach fits the company situation...|$|E
40|$|The Department of Fisheries and Wildlife is {{responsible}} for the administration of the Wildlife Conservation Act 1950 (as amended). Through the Act the Western Australian Wildlife Authority (WAWA) and the Department are responsible for the conservation of the State's wildlife. The Department services the Wildlife Authority, which is an advisory body under the Wildlife Conservation Act. Because the majority of the State's wildlife (plants and animals) cannot persist outside their natural environment, the main conservation technique has been the setting aside of a system of nature reserves. 	 In Western Australia, a nature reserve is a reserve set aside, under the Land Act 1933 (as amended) for the conservation of indigenous flora or fauna or both. Nature reserves include areas set aside solely for either or both purposes as well as those set aside for a variety of other additional purposes. There are 1131 nature reserves in Western Australia, encompassing nearly 10 million ha (June 1984). This plan is part of the "Western Australian Nature Reserve Management Plan" series, in which provision is made for each number in the series to be published as a "Draft", then as a "Revised Draft" for Wildlife Authority and Ministerial approval, and finally in its approved form. The main reason for producing draft management plans is to provide for full consultation with the public {{and at the same time}} encourage public comment. In this plan two sets of management prescriptions are used. The first gives a nature reserve a particular status, either as a "Key Site" or "Wildlife Refuge", and the second determines the <b>access</b> <b>classification</b> of the area...|$|E
40|$|The ISO 15489 {{standard}} {{focuses on}} the principles of records management and establishes the basic requirements that allows organizations to establish a framework of best practices that improves in a systematic and effective manner the creation and keeping of its records, supporting in this way the organizational policy and objectives. The publication of this standard and other complementary standards responds, on the one hand, to the evolution of the approaches of both the American records management and the Australian recordkeeping, and on the other hand, to the need to integrate records management with the process approach and the quality management standards. In order to develop a records management programme, it is necessary to establish policy and responsibilities in accordance with the needs of the organization. This standard proposes a specific methodology to design and implement a records management system, to define the technical processes, to develop the main instruments (classification system, disposition authorities, and security and <b>access</b> <b>classification</b> scheme) and to establish evaluation, measurement and learning tools for continuous improvement of the system. It also highlights the importance of metadata for the management of electronic documents and points out the requirements that they should meet. As a compendium of best practices for records management that has been adopted in many countries, the ISO 15489 standard involves new challenges and at a time opens new outlooks for information professionals. One of the issues that still needs to be resolved is the development of indicators to measure the performance of records management system and to demonstrate the value that it brings to the business processes of the organization...|$|E
40|$|The {{overarching}} {{question for}} the NSDL evaluation should be, "How does this online network of learning environments and resources support education?" Implied within that question are crucial ones about the NSDL as a defined technology, such as "How are people using it? How well do the mechanisms of acquisition, <b>classification,</b> <b>access,</b> and retrieval work? What {{is the quality of}} the resources?" as well as questions about the construction process, such as "How are the collections and tools changing? How well does the distributed development process work?"unpublishedis peer reviewe...|$|R
40|$|The {{shift towards}} {{parallel}} processor architectures has made programming, performance prediction and code generation increasingly challenging. Abstract representations of program code (i. e. classifications) {{have been introduced}} to address this challenge. An example is `algorithmic species', a memory <b>access</b> pattern <b>classification</b> of loop nests. It provides an architecture-agnostic structured view of program code, allowing programmers and compilers to take for example parallelisation decisions or perform memory hierarchy optimisations. The existing algorithmic species theory {{is based on the}} polyhedral model and is limited to static affine loop nests. In this work, we first present a revised theory of algorithmic species that overcomes this limitation. The theory consists of a 5 -tuple characterisation of individual array references and their corresponding merging operation. Second, we present an extension of this theory named SPECIES+, providing a more detailed 6 -tuple characterisation. With this, we are able to retain relevant access pattern information not captured by the original algorithmic species, such as column-major versus row-major matrix accesses. We implement both new theories into a tool, enabling automatic classification of program code...|$|R
40|$|The {{inception}} of the World Wide Web {{marked the beginning of}} a new age, an age where information is easily distributed and accessible to everyone. Years after it was conceived, the net is still growing at a higher rate than ever. It is becoming ever more apparent that the World Wide Web’s current software infrastructure will need to evolve if it is to remain a reliable and dependable resource. In this paper we will be looking into the facets that make web content accessible and reliable. We will also be proposing a structure that makes use of technologies such as the Semantic Web and Agent Technology to help resolve data <b>access</b> and <b>classification</b> issues. The approach that we are proposing will involve the creation and distribution of data tags, policies and reasoners. We will also show how these items can be used by entities such as software agents or users to specify access control, classify the resources in terms of relevance and to decide on how trustworthy the information being used is. peer-reviewe...|$|R
40|$|My {{research}} interests are in human-computer interaction. In particular, I {{am interested in}} important problems {{at the intersection of}} human-computer interaction and machine learning. My dissertation focuses on how to design effective end-user interaction with machine learning. In this research, I target real-world problems that can benefit from end-user driven machine learning. Concrete examples include image <b>classification,</b> <b>access</b> control in online social networks, and alarm triage in large-scale computer networks. Throughout my work, I identify challenges and opportunities for improving the interactive machine learning process and design new and balanced solutions. I also distill guiding principles applicable in a broader context, providing a foundation for future end-user interactive machine learning systems...|$|R
40|$|Abstract. This paper {{presents}} a technique and its computer implementation to facilitate "navigation " in the International Patent Classification system. The resulting system assists users having no specialised training m information retneval in iden-tifying relevant classification categones and keywords {{they can use}} in Boolean quenes on a target patent database. Applied to any subclass of the patent classification, the system builds a browsing environment that provides a relevance ranking of <b>access</b> paths to <b>classification</b> codes; this complements the often inadequate text labels currently associated with patent codes. l. l I The user mterface bottleneck The last twenty years have witnessed the develop-ment of large patent information systems, such a...|$|R
40|$|This package {{provides}} <b>access</b> to the <b>classification</b> of {{the following}} families of Lie algebras: • non-solvable Lie algebras over finite fields up to dimension 6; • nilpotent Lie algebras of dimension up to 9 over GF(2), of dimension up to 7 over GF(3) or GF(5); • simple Lie algebras of dimensions between 7 and 9 over GF(2); • the classification of solvable Lie algebras of dimension at most 4; • the classification of nilpotent Lie algebras of dimensions at most 6. Copyright c ○ 2006 – 2007 Willem de Graaf and Csaba Schneider Acknowledgements We are grateful to Andrea Caranti, Marco Costantini, Bettina Eick, Helmut Strade, Michael Vaughan-Lee...|$|R
40|$|The aim of {{the thesis}} was to derive complex {{information}} of the current vegetation cover in the alpine treeline ecotone in Praděd Reserve by using remote sensing. Particularly thesis focuses on an area and expansion of dwarf pine (Pinus mugo Turra) at site above the alpine treeline ecotone around the peak Praděd. Two types of aerial photograph from 2000 and 2012 and satellite images from Landsat 7 (yaer 2000) and Landsat 8 (year 2013) were used for mapping vegetation. Supervised and unsupervised <b>classification</b> <b>accesses</b> and also "per-pixel" and objected classification methods were used in image processing. All the classifications confirmed expansion of dwarf pine stands in the alpine treeline vegetation. Most precise method was based on supervised objected classification...|$|R
40|$|Thesis (M. A.) [...] Humboldt State University, Social Science: Environment and Community, 2011 Access {{to healthy}} foods is {{increasingly}} impaired by socio-economic and environmental influences. Providing a region with an adequate {{supply of food}} and access are basic tenets of a sustainable foodshed. This thesis highlights food access in Humboldt County, California by identifying and mapping local food production and food retail location resources utilizing a geospatial lens. Using Geographic Information Systems (GIS) technology I assessed local food access and production patterns overlayed with socioeconomic data to identify regions of Humboldt County having adequate or inadequate access to fresh and healthy food. Multiple GIS methods including participatory mapping, proximity and distance measures were employed to analyze food access throughout the county. Spatial analysis of food resources allows for determination of adequate or inadequate food <b>access</b> and <b>classification</b> of potential food insecure areas in Humboldt County. This research will benefit the community by highlighting vulnerable neighborhoods without access to quality fresh and healthy food resources. The project will also provide the new Humboldt County Food Policy Council with necessary data to work on strengthening food access for food insecure neighborhoods. Keywords: food access, food security, food insecurity, foodshed, Geographic Information Systems (GIS), Participatory GIS (PPGIS), Humboldt County...|$|R
40|$|Big Data concern large-volume, growing {{data sets}} that {{are complex and}} have {{multiple}} autonomous sources. Earlier technologies {{were not able to}} handle storage and processing of huge data thus Big Data concept comes into existence. This is a tedious job for users unstructured data. So, there should be some mechanism which classify unstructured data into organized form which helps user to easily <b>access</b> required data. <b>Classification</b> techniques over big transactional database provide required data to the users from large datasets more simple way. There are two main classification techniques, supervised and unsupervised. In this paper we focused on to study of different supervised classification techniques. Further this paper shows a advantages and limitations. Comment: 7 pages, 3 figures, 2 tables in IJAFRC, Vol. 1, Issue 11, November 2014, ISSN: 2348 - 485...|$|R
