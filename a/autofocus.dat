1364|184|Public
5|$|The lens {{features}} a hypersonic zoom motor for its <b>autofocus,</b> {{which is considered}} to be a fast and quiet design. In addition, manual override is allowed in the single-shot <b>autofocus</b> mode. The lens, which focuses internally, has one of the lowest maximum magnification measurements in its class (which includes the Canon 10–18mm and 10–22mm, Sigma 10–20mm f/3.5 and Sigma 10–20mm f/4–5.6 EX DC HSM, Tamron 10–24mm f/3.5–4.5 DI II, Nikon 10–24mm f/3.5–4.5G ED AF-S DX, and Tokina 11–16mm f/2.8 AT-X Pro DX lenses). The lens' <b>autofocus</b> feature is not functional with Pentax ist* series and K100D DSLR cameras that do not support hypersonic zoom mechanics. The lens is capable of focusing from infinity to minimum focusing distance and back in under a second: so micro focusing is rapid. However, because of the narrow focus range (0.13x) the lens is not suitable for macro photography.|$|E
5|$|The SIII has an 8-megapixel camera {{similar to}} that of the Galaxy SII. It can take 3264×2448-pixel {{resolution}} photos and record videos in 1920×1080-pixel (1080p) resolution. Samsung improved the camera's software over that of its predecessor to include zero shutter lag, and Burst Mode and Best Shot, which work together to quickly take numerous photos before the best-judged frame is selected. The phone can also take pictures while recording videos. The rear-facing camera is complemented by a 1.9-megapixel front-facing camera that can record 720p videos. The phone has LED flash and <b>autofocus.</b>|$|E
25|$|On {{almost all}} DSLRs that offer live preview via the primary sensor, the phase {{detection}} <b>autofocus</b> {{system does not}} work in the live preview mode, and the DSLR switches to a slower contrast system commonly found in point & shoot cameras. While even phase detection <b>autofocus</b> requires contrast in the scene, strict contrast detection <b>autofocus</b> is limited {{in its ability to}} find focus quickly, though it is somewhat more accurate.|$|E
40|$|The <b>autofocusing</b> {{is one of}} {{the most}} {{important}} features of imaging devices. This feature directly affects the quality of the image taken by the imaging device. Currently, many studies are being performed to improve the feature of <b>autofocusing.</b> In this study, we propose a method for passive <b>autofocusing</b> of the color cameras. This method suggested is called as the Passive <b>Autofocusing</b> Based-Brightness and Contrast (PA Based-BC). According to this method, <b>autofocusing</b> is performed by identifying the brightness of the R, G and B color components of the RGB image and by focusing of the camera on the brightest color component. To this end, in this study, many experiments have been conducted. The analyses of these experiments show that the contrast-based focusing made depending on the brightness gives much better results. The use of this method upgrades the focusing accuracy of the color camera up to 95 %...|$|R
40|$|Image focus {{analysis}} {{is an important}} technique for passive <b>autofocusing</b> and three-dimensional shape measurement. Electronic noise in digital images introduces errors in this technique. It is therefore important to derive robust focus measures that minimize error. In our earlier research, we have developed a method for noise sensitivity analysis of focus measures. In this paper we derive explicit expressions for the root-mean square (RMS) error in <b>autofocusing</b> based on image focus analysis. This is motivated by the <b>Autofocusing</b> Uncertainty Measure (AUM) defined earlier by us as a metric for comparing the noise sensitivity of different focus measures in <b>autofocusing</b> and 3 D shape-from-focus. The RMS error we derive is shown to be proportional to {{the square of the}} AUM. The expression for RMS error derived by us has the same advantage as AUM in that it can be computed in only one trial of <b>autofocusing.</b> We validate our theory on RMS error and AUM through experiments. It is shown that the the [...] ...|$|R
40|$|International audienceFast and {{reliable}} <b>autofocusing</b> methods {{are essential for}} performing automatic nano-objects positioning tasks using a scanning electron microscope (SEM). So far in the literature, various <b>autofocusing</b> algorithms have been proposed utilizing a sharpness measure to compute the best focus. Most of them are based on iterative search approaches; applying the sharpness function over the total range of focus to find an image in-focus. In this paper, a new, fast and direct method of <b>autofocusing</b> has been presented {{based on the idea}} of traditional visual servoing to control the focus step using an adaptive gain. The visual control law is validated using a normalized variance sharpness function. The obtained experimental results demonstrate the performance of the proposed <b>autofocusing</b> method in terms of accuracy, speed and robustness...|$|R
25|$|Some {{distance}} scales have markings {{for only}} a few distances; for example, the 35mm lens above shows only 3ft and 5ft on its upper scale. Using other distances for DOF limits requires visual interpolation between marked distances. Since the distance scale is nonlinear, accurate interpolation can be difficult. In most cases, English and metric distance markings are not coincident, so using both scales to note focused distances can sometimes lessen the need for interpolation. Many <b>autofocus</b> lenses have smaller distance and DOF scales and fewer markings than do comparable manual-focus lenses, so that determining focus and f-number from the scales on an <b>autofocus</b> lens may be more difficult than with a comparable manual-focus lens. In most cases, determining these settings using the lens DOF scales on an <b>autofocus</b> lens requires that the lens or camera body be set to manual focus.-number from user-determined near and far points in much the same manner as using DOF scales on manual-focus lenses (Canon Inc. 2000, 61–62). The feature has not been included on models introduced after April 2004.|$|E
25|$|Sony has {{modified}} the DSLR formula {{in favor of}} single-lens translucent (SLT) cameras, which are still technically DSLRs, but feature a fixed mirror that allows most light through to the sensor while reflecting some light to the <b>autofocus</b> sensor. Sony's SLTs feature full-time phase detection <b>autofocus</b> during video recording as well as continuous shooting of up to 12 frame/s. The α series, whether traditional SLRs or SLTs, offers in-body sensor-shift image stabilization and retains the Minolta AF lens mount. , the lineup included the Alpha 68, the semipro Alpha 77 II, and the professional full-frame Alpha 99 II. The translucent (transmissive) fixed mirror allows 70 percent of the light to pass through onto the imaging sensor, meaning a 1/3rd stop loss light, {{but the rest of}} this light is continuously reflected onto the camera's phase detection AF sensor for fast <b>autofocus</b> for both the viewfinder and live view on the rear screen, even during video and continuous shooting. The reduced number of moving parts also makes for faster shooting speeds for its class. This arrangement means that the SLT cameras use an electronic viewfinder as opposed to an optical viewfinder, which some consider a disadvantage, but does have the advantage of a live preview of the shot with current settings, anything displayed on the rear screen is displayed on the viewfinder, and handles bright situations well.|$|E
25|$|Compared {{with the}} newer concept of mirrorless interchangeable-lens cameras, this mirror/prism {{system is the}} {{characteristic}} difference providing direct, accurate optical preview with separate <b>autofocus</b> and exposure metering sensors. Essential parts of all digital cameras are some electronics like amplifier, analog to digital converter, image processor and other (micro-)processors for processing the digital image, performing data storage and/or driving an electronic display.|$|E
40|$|Different <b>autofocusing</b> methods {{exist for}} many cameras today. While not {{ignoring}} commercially available methods requiring specialized hardware, this paper focuses mainly on pixel based <b>autofocusing</b> algorithms {{as applied to}} CCD camera systems. Different measures of image sharpness are compared. For each of these, different algorithms for searching the best lens setting are assessed in terms of performance {{as well as their}} applicability to various situations. In addition, several other factors potentially affecting camera focusing are also discussed. Based on the information obtained, this research attempts to formulate a robust <b>autofocusing</b> algorithm...|$|R
40|$|Abstract — Fast and {{reliable}} <b>autofocusing</b> methods are essen-tial for performing automatic nano-objects positioning tasks using a {{scanning electron microscope}} (SEM). So far in the literature, various <b>autofocusing</b> algorithms have been proposed utilizing a sharpness measure to compute the best focus. Most of them are based on iterative search approaches; applying the sharpness function over the total range of focus to find an image in-focus. In this paper, a new, fast and direct method of <b>autofocusing</b> has been presented {{based on the idea}} of traditional visual servoing to control the focus step using an adaptive gain. The visual control law is validated using a normalized variance sharpness function. The obtained experimental results demonstrate the performance of the proposed <b>autofocusing</b> method in terms of accuracy, speed and robustness. I...|$|R
40|$|In {{order to}} realize the <b>autofocusing</b> in aerial camera, an <b>autofocusing</b> system is {{established}} and its characteristics such as working principle and optical-mechanical structure and focus evaluation function are investigated. The reason for defocusing in aviation camera is analyzed and several <b>autofocusing</b> methods along with appropriate focus evaluation functions are introduced based on the image processing techniques. The proposed <b>autofocusing</b> system is designed and implemented using two CMOS detectors. The experiment {{results showed that the}} proposed method met the aviation camera focusing accuracy requirement, and a maximum focusing error of {{less than half of the}} focus depth is achieved. The system designed in this paper can find the optical imaging focal plane in real-time; as such, this novel design has great potential in practical engineering, especially aerospace applications...|$|R
25|$|Video {{functionality}} {{has continued}} to improve since {{the introduction of the}} HDSLR, including higher video resolution (such as 1080p24) and video bitrate, improved automatic control (<b>autofocus)</b> and manual exposure control, and support for formats compatible with high-definition television broadcast, Blu-ray disc mastering or Digital Cinema Initiatives (DCI). The Canon EOS 5D Mark II (with the release of firmware version 2.0.3/2.0.4.) and Panasonic Lumix GH1 were the first HDSLRs to offer broadcast compliant 1080p24 video, and since then the list of models with comparable functionality has grown considerably.|$|E
25|$|Linear {{polarizing}} filters {{were the}} first types {{to be used in}} photography and can still be used for non-reflex and older SLR cameras. However, cameras with through-the-lens metering and autofocusing systems – that is, all modern SLR and DSLR – rely on optical elements that pass linearly polarized light. If light entering the camera is already linearly polarized, it can upset the exposure or <b>autofocus</b> systems. Circular polarizing filters cut out linearly polarized light and so can be used to darken skies or remove reflections, but the circular polarized light it passes does not impair through-the-lens systems.|$|E
25|$|Android devices {{incorporate}} many optional hardware components, including still {{or video}} cameras, GPS, orientation sensors, dedicated gaming controls, accelerometers, gyroscopes, barometers, magnetometers, proximity sensors, pressure sensors, thermometers, and touchscreens. Some hardware components are not required, but became standard in certain classes of devices, such as smartphones, and additional requirements apply {{if they are}} present. Some other hardware was initially required, but those requirements have been relaxed or eliminated altogether. For example, as Android was developed initially as a phone OS, hardware such as microphones were required, while over time the phone function became optional. Android used to require an <b>autofocus</b> camera, which was relaxed to a fixed-focus camera if present at all, since the camera was dropped as a requirement entirely when Android started to be used on set-top boxes.|$|E
40|$|<b>Autofocusing</b> is {{a routine}} {{technique}} in redressing focus drift {{that occurs in}} time-lapse microscopic image acquisition. To date, most automatic microscopes are designed on the distance detection scheme to fulfill the <b>autofocusing</b> operation, which may suffer from the low contrast of the reflected signal due to the refractive index mismatch at the water/glass interface. To achieve high <b>autofocusing</b> speed with minimal motion artifacts, we developed a compact multi-band fluorescent microscope with an electrically tunable lens (ETL) device for <b>autofocusing.</b> A modified searching algorithm based on equidistant scanning and curve fitting is proposed, which no longer requires a single-peak focus curve and then efficiently restrains the impact of external disturbance. This technique enables us to achieve an <b>autofocusing</b> time of down to 170 ms and the reproductivity of over 97 %. The imaging head of the microscope has dimensions of 12 cm x 12 cm x 6 cm. This portable instrument can easily fit inside standard incubators for real-time imaging of living specimens. (C) 2015 Optical Society of Americ...|$|R
40|$|Abstract—A {{method is}} {{described}} for selecting the optimal focus measure {{with respect to}} gray-level noise from a given set of focus measures in passive <b>autofocusing</b> and depth-from-focus applications. The method is based on two new metrics that have been defined for estimating the noise-sensitivity of different focus measures. The first metric—the <b>Autofocusing</b> Uncertainty Measure (AUM) —is useful in understanding the relation between gray-level noise and the resulting error in lens position for <b>autofocusing.</b> The second metric— <b>Autofocusing</b> Root-Mean-Square Error (ARMS error) —is an improved metric closely related to AUM. AUM and ARMS error metrics {{are based on a}} theoretical noise sensitivity analysis of focus measures, and they are related by a monotonic expression. The theoretical results are validated by actual and simulation experiments. For a given camera, the optimally accurate focus measure may change from one object to the other depending on their focused images. Therefore, selecting the optimal focus measure from a given set involves computing all focus measures in the set. Index Terms—Focus measure, focusing, <b>autofocusing,</b> depth-from-focus, focus analysis...|$|R
5000|$|... 3.2 MP (up to 2048x1536), with <b>autofocusing</b> and QVGA@15fps Video Recording ...|$|R
25|$|For a long time, DSLRs offered {{faster and}} more {{responsive}} performance, with less shutter lag, faster <b>autofocus</b> systems, and higher frame rates. Around 2016-17, specific mirrorless camera models started offering competitive or superior specifications in these aspects. The downside of these cameras being {{that they do not}} have an optical viewfinder, making it difficult to focus on moving subjects or in situations where a fast burst mode would be beneficial. Other digital cameras were once significantly slower in image capture (time measured from pressing the shutter release to the writing of the digital image to the storage medium) than DSLR cameras, but this situation is changing with the introduction of faster capture memory cards and faster in-camera processing chips. Still, compact digital cameras are not suited for action, wildlife, sports and other photography requiring a high burst rate (frames per second).|$|E
500|$|The iPhone 6's {{rear-facing}} camera now has {{the ability}} to shoot 1080p video at either 30 or 60 frames per second and slow-motion video at either 120 or 240 frames per second. The camera also includes phase detection <b>autofocus.</b> It can also record [...] The iPhone 6 Plus camera is nearly identical, but also includes optical image stabilization. The front-facing camera was also updated with a new sensor and f/2.2 aperture, along with support for burst and HDR modes.|$|E
500|$|The Sigma 8–16mm lens is an enthusiast-level, ultra {{wide-angle}} rectilinear {{zoom lens}} made by Sigma Corporation specifically {{for use with}} APS-C small format digital SLRs. It is the first ultrawide rectilinear (non-fisheye lens) zoom lens with a minimum focal length of 8mm, designed specifically for APS-C size image sensors. The lens was introduced at the February 2010 Photo Marketing Association International Convention and Trade Show. At its release it was the widest viewing angle focal length available commercially for APS-C cameras. It is part of Sigma's DC (Digital Camera) line of lenses, meaning {{it was designed to}} have an image circle tailored to work with APS-C format cameras. [...] The lens has a constant length regardless of optical zoom and focus with inner lens tube elements responding to these parameters. The camera has hypersonic zoom <b>autofocus.</b>|$|E
5000|$|Center cross-type {{focus point}} {{supports}} <b>autofocusing</b> with lenses {{with a maximum}} aperture of f/8; ...|$|R
5000|$|Central cross-type focus points support <b>autofocusing</b> with lenses with {{a maximum}} {{aperture}} of f/5.6; ...|$|R
40|$|A {{method is}} {{described}} for selecting the optimal focus measure {{with respect to}} grey-level noise from a given set of focus measures in passive <b>autofocusing</b> and depth-from-focus applications. The method is based on two new metrics that have been defined for estimating the noise-sensitivity of different focus measures. The first metric [...] the <b>Autofocusing</b> Uncertainty Measure (AUM) [...] is useful in understanding the relation between grey-level noise and the resulting error in lens position for <b>autofocusing.</b> The second metric [...] <b>Autofocusing</b> Root-Mean-Square Error (ARMS error) [...] is an improved metric closely related to AUM. AUM and ARMS error metrics {{are based on a}} theoretical noise sensitivity analysis of focus measures, and they are related by a monotonic expression. The theoretical results are validated by actual and simulation experiments. For a given camera, the optimally accurate focus measure may change from one object to the other depending on their focused images. Therefore s [...] ...|$|R
500|$|Art {{director}} Aaron Garbut {{said that}} the addition of first-person inspired the enhanced version's graphical upgrade. Remodelled cars feature interior effects including functional speedometers, fuel gauges and dashboard handbrake lights. The team added new particle and lighting effects, [...] "like fireflies {{at night in the}} countryside, or ambient light pollution over Los Santos at night", according to Garbut. Red Dead Redemption inspired the team to add more vegetation to [...] "break up the hard edges [...] straight lines" [...] of the open world. The original version's vegetation was replaced with more detailed equivalents in the enhanced version. An upgraded weather system lets tree branches and leaves blow realistically in the wind. The team hand placed weeds along fences and walls, and placed grass over many of the open world's terrains. They then layered flowers, plants, stones, leaves and litter over the grass. An upgraded screen space ambient occlusion (SSAO) system renders dynamic shadows that may cast through weather effects including volumetric fog, and particle effects including light reflections in water bodies or neon reflections in cars at night. The ambient light pollution over nighttime Los Santos may dissipate in poor weather. A dynamic depth of field system sharpens and softens images to emulate camera <b>autofocus,</b> and improved shaders produce new colours in skin and terrain textures.|$|E
2500|$|DSLRs {{typically}} use <b>autofocus</b> {{based on}} phase detection. This method allows the optimal lens {{position to be}} calculated, rather than [...] "found", as {{would be the case}} with <b>autofocus</b> based on contrast maximisation. Phase-detection <b>autofocus</b> is typically faster than other passive techniques. As the phase sensor requires the same light going to the image sensor, it was previously only possible with an SLR design. [...] However, with the introduction of focal-plane phase detect autofocusing in mirrorless interchangeable lens cameras by Sony, Fuji, Olympus and Panasonic, cameras can now employ both phase detect and contrast detect AF points.|$|E
2500|$|In 2012, Canon {{introduced}} hybrid <b>autofocus</b> {{technology to}} the DSLR in the EOS 650D/Rebel T4i, and introduced a more sophisticated version, which it calls [...] "Dual Pixel CMOS AF", with the EOS 70D. The technology allows certain pixels to act as both contrast-detection and phase-detection pixels, thereby greatly improving <b>autofocus</b> speed in live view (although it remains slower than pure phase detection). While several mirrorless cameras, plus Sony's fixed-mirror SLTs, have similar hybrid AF systems, Canon is the only manufacturer that offers such a technology in DSLRs.|$|E
40|$|In {{recent studies}} the {{possibility}} of extending <b>autofocusing</b> techniques to fully polarimetric ISAR systems has been proposed. One of the first techniques for ISAR image <b>autofocusing</b> still in use is the Hot Spot processing. In this paper, the Hot Spot technique is extended and applied to fully polarimetric ISAR data. A performance analysis is then provided and compared to single polarisation Hot Spot by using real data...|$|R
40|$|We {{investigate}} controllable spatial modulation of circular <b>autofocusing</b> Airy beams, under {{action of}} different dynamic linear potentials, both theoretically and numerically. We introduce a novel treatment method {{in which the}} circular Airy beam is represented as a superposition of narrow azimuthally-modulated one-dimensional Airy beams that can be analytically treated. The dynamic linear potentials are appropriately designed, so that the <b>autofocusing</b> effect can either be weakened or even eliminated when the linear potential exerts a "pulling" effect on the beam, or if the linear potential exerts a "pushing" effect, the <b>autofocusing</b> effect can be greatly strengthened. Numerical simulations agree with the theoretical results very well. Comment: 10 pages, 6 figures. accepted by Optics Expres...|$|R
40|$|Abstract — In MEMS {{microassembly}} areas, {{different methods}} of automatic focusing {{are presented in}} the literature. All these methods have a common point. Thus, the current <b>autofocusing</b> methods for microscopes need to perform a scanning on all the vertical axis of the microscope {{in order to find}} the peak corresponding to the focus (sharpen image). Those methods are time consuming. Therefore, this paper presents an original method of <b>autofocusing</b> based on a velocity control approach which is developed and validated on real experiments. I. OVERVIEW Reliable <b>autofocusing</b> methods are indispensable in the microassembly of hybrid micro-electromechanical systems (MEMS) and for general uses of optical microscopes [6], [8]. Ensuring an optimal focus is essential in industrial vision systems. A good focus ensures sharpen image and thu...|$|R
2500|$|Using the red-eye {{reduction}} capabilities {{built into}} many modern cameras. These precede the main flash {{with a series}} of short, low-power flashes, or a continuous piercing bright light triggering the pupil to contract. (This {{should not be confused with}} the <b>autofocus</b> assist beam, which uses a series of flashes for focus instead.) ...|$|E
2500|$|In the 1980s and 1990s {{membership}} again declined dramatically, a trend {{attributable to}} a number of factors including camera automation, for example <b>autofocus</b> and programmed exposure reducing the need for user instruction; the advent of consumer video; and changing social habits. [...] Since 2000 membership has increased again to about 150 today, {{due in large part to}} the club's emphasis on digital photography.|$|E
2500|$|In late-April 2016, BlackBerry {{began to}} release an upgrade to Android 6.0 [...] "Marshmallow"; along with {{features}} {{added to the}} core Android platform (which includes a new permissions system, and systems to reduce background activity when the device is not being physically handled to conserve battery power), it adds S/MIME, Slack, Skype, and Pinterest support to BlackBerry Hub, slide input on the physical keyboard, faster <b>autofocus,</b> and 24fps and 120fps video recording modes.|$|E
40|$|In this paper, we {{introduce}} a robust method for wideband DOA estimation {{which does not}} require any preliminary DOA estimation or calibration of the array during the whole estimating process with the performance similar to the <b>autofocusing</b> approach. Our method {{is based on the}} <b>autofocusing</b> approach and uses the ESPRIT algorithm during the narrowband processing stage. Meanwhile, we suggest the method of selecting the best focusing frequency which minimizes the mean square erro...|$|R
40|$|The {{method of}} {{acoustic}} <b>autofocusing</b> {{is a technique}} to estimate the wave field that originates from a virtual source inside of a medium, with little knowledge of the medium parameters, and with no receivers (nor sources) located inside of the medium. Herein we present the first <b>autofocusing</b> algorithm modified for elastic media. Our algorithm {{is based on the}} elastic version of the receiver-side wave field extrapolation step performed in certain wave-equation migration algorithms. The elastic <b>autofocusing</b> algorithm has similar requirements to the acoustic case, namely reflection data measure at an acquisition surface (e. g., the Earth's surface), as well as estimates of the direct arrivals from the subsurface virtual source to the acquisition surface. We use two numerical experiments in varying-density, constant velocity, lossless elastic media to examine the accuracy of the method...|$|R
40|$|The authors {{propose a}} novel SAR (synthetic {{aperture}} radar) image <b>autofocusing</b> technique based on higher order statistics (HOS) analysis. The SAR imaging {{system has been}} modelled as a bandlimited complex linear time invariant (LTI) filter, so the <b>autofocusing</b> problem {{is equivalent to the}} problem of reconstructing the phase of a bandlimited complex LTI system. The complex transfer function of the imaging system is recovered from the estimated bispectrum of the received data by means of an ad-hoc algorith...|$|R
