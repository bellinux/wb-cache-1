110|23|Public
40|$|This paper {{discusses}} FEM-based {{simulations of}} soft bodies {{in terms of}} speed and robustness. To be physically plausible, three fundamental laws must be respected: rotational invariance, Newton's law and Euler's law. We show that precomputed strain-displacement matrices generate nonphysical torques {{which can lead to}} visual <b>arti-facts.</b> We then derive the fastest FEM-based method meeting our criteria of plausibility and robustness and discuss their limitations...|$|E
40|$|International audienceThis paper {{proposes a}} new {{simulation}} framework for generat-ing realistic 3 D ultrasound synthetic images {{that can serve}} for validating strain quantification algorithms. Our approach ex-tends previous work and combines a real ultrasound sequence with synthetic biomechanical and ultrasound models. It pro-vides images that fairly represent all typical ultrasound <b>arti-facts.</b> Ground truth motion fields are unbiased to any track-ing algorithm and model both healthy and pathological con-ditions...|$|E
40|$|WedescribeXIRC, a {{tool and}} {{architecture}} that enables to define queries over a uniform representation of all <b>arti-facts</b> of a software project. These queries {{can be used}} for general cross-artifact information retrieval or for more special applications like checking implementation restric-tions or conformance to style guides. XIRC is also a good basis to implement a broad range of tools for refactor-ing, generators, aspect-oriented programming and many other domains on top of it. 1...|$|E
40|$|No {{matter the}} {{development}} process or methodology, a soft-ware product must ultimately be released to a user in a readily consumable form. Different software products, from desktop applications to web services, may require different release processes, but each process must produce an <b>arti-fact</b> which meets an expected level of quality, and is rela-tively bug-free. We describe current research to model and quantify existing release processes, and an effort to prescribe improvements to those processes...|$|R
40|$|June 2007 plicit {{attempts}} to design efficient, effective work practices. In a typical scenario, managers assemble {{a team to}} design or redesign a work process. The team produces a variety of artifacts, such as diagrams, checklists, forms, and procedures, {{some of which may}} be subsequently embedded into a software <b>arti-fact.</b> Sometimes they get the results they want, but often they do not. In this paper, we argue that the frequent disconnect between goals and results arises, at least in part, because people design artifacts when they want patterns of action. We paraphrase the classi...|$|R
40|$|Collaborative {{software}} development is nowadays incon-ceivable without optimistic version control systems (VCSs). Without such systems the parallel modification of one <b>arti-fact</b> by multiple users is impracticable. VCSs proved suc-cessful in the versioning of code, {{but they are}} only condi-tionally appropriate to the management of model versions. Conflicts which may occur when two different versions of one model are merged are detected in an unsatisfactory manner and consequently, automatic conflict resolution is hardly offered. In this work, a generic framework allowing precise conflict detection and intelligent conflict resolution for models is proposed. 1...|$|R
40|$|Abstract. Vital and {{spontaneous}} motion causes major artifacts in MRI. In this paper a method is presented which reduces subpixel motion <b>arti-facts</b> via computational post processing on a complete MR scan without additional data. On the compressed sparse MRI representation, trans-lational subpixel motion is estimated iteratively from a fully sampled, but motion corrupted k-space, and motion free images are reconstructed by linear interpolation. Motion adjusted {{results are presented}} for the Shepp-Logan phantom and brainweb data. ...|$|E
40|$|In {{this paper}} we present {{provenance}} issues {{that arise in}} building Platform-as-a-Service (PaaS) model of cloud computing. The issues are related to designing, build-ing, and deploying of the platform itself, and those re-lated to building and deploying applications on the plat-form. These include, tracking of commands for success-ful software installations, tracking of inter-service de-pendencies, tracking of configuration parameters for dif-ferent services, and tracking of application related <b>arti-facts.</b> We identify the provenance information {{to address these issues}} and propose mechanisms to track it. ...|$|E
40|$|The {{development}} {{of computer technology}} has created artifacts that have more complex and intelligent func-tions. Such artifacts need more sophisticated interfaces than primitive artifacts. In this paper, we discuss which characteristics are appropriate for interfaces with <b>arti-facts</b> and propose a concept of active affordance. We describe an autonomous mobile chair that we built as a test bed for active affordance. We also describe a exper-iment that we performed with a real robot that show the validity of our proposed method...|$|E
40|$|Identifying {{variants}} using high-throughput sequen-cing data {{is currently}} a challenge because true biological variants can be indistinguishable from technical artifacts. One source of technical <b>arti-fact</b> results from incorrectly aligning experimen-tally observed sequences to their true genomic origin (‘mismapping’) and inferring differences in mismapped sequences to be true variants. We de-veloped BlackOPs, an open-source tool that simu-lates experimental RNA-seq and DNA whole exome sequences derived from the reference genome, aligns these sequences by custom parameters, detects variants and outputs a blacklist of positions and alleles caused by mismapping. Blacklist...|$|R
40|$|Artifacts {{may occur}} during {{ultrasound}} imaging {{and it is}} important to recognize what you are seeing as an <b>arti-fact.</b> One of the more common artifacts is mirror image. This is a reverberation artifact caused by sound bounc-ing between multiple structures that are strong specular reflectors. Mirror images can occur during B-mode, color Doppler or pulsed-wave Doppler analysis. There are two major types of reverberation artifact: (1) the mir-ror is produced when the echoes are reflected between two specular reflectors multiple times (see Panel A); (2) a multipath artifact may incorrectly display the depth © 2006 SAGE Publications 10. 1177 / 1358863 x 0607223...|$|R
40|$|Abstract. Traditional {{workflow}} and activity-centric coordination offers limited {{process support}} to human collaborators when unanticipated situations predominate. Under such circumstances, informal processes focus on provisioning relevant resources for achieving collaboration goals. Resources include interaction mechanisms such as shared <b>arti-fact,</b> social networks, and publish/subscribe information dissemination as complex situations typically demand the close collaboration among mul-tiple human process participants. Currently, however, {{there exists a}} gap between (i) selecting and configuring suitable interaction mechanisms (collaboration level) and (ii) deploying the respective collaboration plat-forms (IT level). In this paper, we present an approach and techniques for transforming collaboration structures into automatically deployable informal processes. We demonstrate how our tools support the specifi-cation of desirable collaboration capabilities subsequently deployed to multiple MediaWiki instances...|$|R
40|$|We {{present a}} theory to {{generate}} pseudo-primary shot gathers from multiple and primary reections by performing a surface-consistent cross-correlation. The estimated pseudo-primaries exhibit the same kinematics {{as the original}} dataset with few transformation <b>arti-facts.</b> We demonstrate that pseudo-primaries can accurately esti-mate missing traces {{as long as the}} gaps are within the acquisition spread. Pseudo-primaries can also help to extrapolate the data out-side the acquisition spread. The image obtained by migrating the pseudo-primary gathers shows that multiple migration can provide valuable information under complex geology...|$|E
40|$|Abstract. Software Product Lines (SPL) {{are widely}} used to manage {{variability}} in the automotive industry. In a rapidly changing industrial environment, model transformations are necessary to aid in automating the evolution of SPLs. However, existing transformation technologies are not well-suited to handling industrial-grade variability in software <b>arti-facts.</b> We present a case study where we “lift ” a previously developed migration transformation so that it becomes applicable to realistic in-dustrial product lines. Our experience indicates that it is both feasible and scalable to lift transformations for industrial SPLs. ...|$|E
40|$|Developing a {{database}} engine is both challenging and re-warding. Database engines are very complex software <b>arti-facts</b> {{that have to}} scale to large data sizes and large hardware configurations, and developing such systems usually means choosing between different trade-offs at various points of de-velopment. This papers gives a survey over two different database en-gines, the disk-based SPARQL-processing engine RDF- 3 X, and the relational main-memory engine HyPer. It discusses the design choices that were made during development, and highlights optimization techniques that are important for both systems. 1...|$|E
40|$|Abstract. Although the {{importance}} of UML Sequence Diagrams is well recog-nized by the object-oriented community, they remain a very difficult UML <b>arti-fact</b> to develop. In this paper we present a multi-level methodology to develop UML Sequence Diagrams. Our methodology is significant in three aspects. First, it provides a multilevel procedure to facilitate ease of the development process. Second, it makes use of certain patterns to ensure the validity of SQDs. Third, it uses consistency checks with corresponding use-case and class dia-grams. Throughout {{the steps of the}} method we present rules and patterns dem-onstrating correct and incorrect diagramming of common situations through examples. The {{purpose of this study is}} to serve as a reference guide for novice sequence diagram modelers. This methodology is particularly useful for novice practitioners who face challenges in learning the process of SQD development. ...|$|R
40|$|Besides perfect {{reconstruction}} and linear phase, regularity is a de-sirable essential property of filter banks for image coding {{as it is}} associated with the smoothness of the related wavelet basis. This paper shows how to constrain quaternionic factorizations of eight-band linear phase paraunitary filter banks to have the first regularity structurally imposed. The result is not very general but some facts make it notable. Firstly, these systems are a direct extension of the standard eight-point discrete cosine transform (DCT) and this facili-tates practical applications. Secondly, the first regularity eliminates the DC leakage which cause visually annoying checkerboard <b>arti-fact.</b> Finally, our solution offers clear advantages over the known ones as the regularity conditions are formulated directly in terms of quaternionic lattice coefficients. Namely, both regularity and loss-lessness can be easily preserved regardless of coefficient quantiza-tion unavoidable in finite-precision implementations. 1...|$|R
40|$|Abstract. Though the {{importance}} of UML Sequence Diagrams is well recog-nized by the object-oriented community, they remain a very difficult UML <b>arti-fact</b> to develop. In this paper we present a multi-level methodology to develop UML Sequence Diagrams. Our methodology is significant in three aspects. First, it provides a multilevel procedure to facilitate ease of the development process. Second, it makes use of certain patterns to ensure the validity of SQDs. Third, it uses consistency checks with corresponding use-case and class dia-grams. Throughout {{the steps of the}} method we present rules and patterns dem-onstrating correct and incorrect diagramming of common situations through ex-amples. The {{purpose of this study is}} to serve as a reference guide for novice sequence diagram modelers. This methodology is particularly useful for novice practitioners in this field who face challenges in learning the process of SQD development. 1...|$|R
40|$|Abstract. We {{present the}} {{prototype}} tool CADS * for the computer-aided {{development of an}} important class of self- * systems, namely sys-tems whose components can be modelled as Markov chains. Given a Markov chain representation of the IT components to be included into a self- * system, CADS * automates or aids (a) {{the development of the}} <b>arti-facts</b> necessary to build the self- * system; and (b) their integration into a fully-operational self- * solution. This is achieved through a combination of formal software development techniques including model transforma-tion, model-driven code generation and dynamic software reconfiguration. ...|$|E
40|$|ICER- 3 D is a progressive, wavelet-based {{compressor}} for hyperspectral images. ICER- 3 D {{is derived}} from the ICER image compressor. ICER- 3 D can provide loss-less and lossy compression, and incorporates an error-containment scheme to limit the effects of data loss during transmission. The three-dimensional wavelet decom-position structure used by ICER- 3 D exploits correlations in all three dimensions of hyperspectral data sets, while facilitating elimination of spectral ringing <b>arti-facts.</b> Correlation is further exploited by a context modeler that effectively exploits spectral dependencies in the wavelet-transformed hyperspectral data. Performance results illustrating the benefits of these features are presented. I...|$|E
40|$|This paper {{proposes a}} systems {{engineering}} process utiliz-ing the conceptual artifacts of the Model Driven Architec-ture (MDA) describing platform independent views of models to capture operational requirements, to derive es-sential tasks, and to combine these tasks into scenarios and vignettes with attributed metrics. This model-independent mission description is {{then used to}} identify supporting si-mulation services that implement the identified military means and capabilities to perform the tasks in the given context. Once the services are identified, the necessary si-mulation middleware to federate the services is identified and the interfaces are configured using the technical <b>arti-facts</b> of the MDA describing platform specific views o...|$|E
40|$|Abstract—Safety {{requirements}} {{are a very}} important <b>arti-fact</b> {{in the development of}} safety critical embedded systems. They are usually identified during safety analyses and are used by experts as a basis for the correct selection and implementation of safety mechanisms. Various safety analysis research groups have worked on formal modeling of safety requirements with the goal of determining if a system can meet these requirements. In this abstract, we propose the application of formal models of safety requirements throughout all development phases of a model-driven development process. The safety requirements identified during safety analysis can be used to automatically generate appropriate mechanisms in the code generation phase and to verify the suitability of this mechanisms in the verification phase. By establishing safety requirements as a formal basis of all process phases, a consistent development process can be achieved. Keywords-model-driven development; safety analysis; em-bedded systems; safety critical embedded systems I...|$|R
40|$|Abstract Safety {{requirements}} {{are an important}} <b>arti-fact</b> {{in the development of}} safety critical systems. They are used by experts as a basis for appropriate selec-tion and implementation of fault detection mechanisms. Various research groups have worked on their formal modeling with the goal of determining if a system can meet these requirements. In this paper, we propose the application of for-mal models of safety requirements throughout all con-structive development phases of a model-driven devel-opment process to automatically generate appropriate fault detection mechanisms. The main contribution of this paper is a rigorous formal specification of safety requirements that allows the automatic propagation, transformation and refinement of safety requirements and the derivation of appropriate fault detection mech-anisms. This is an important step to guarantee consis-tency and completeness in the critical transition from requirements engineering to software design, where a lot of errors can be introduced into a system by using conventional, non-formal techniques...|$|R
40|$|International audienceIn this article, {{we propose}} a {{theoretical}} account of software appropriation {{as a basis}} for considering how to design software for appropriation. The analysis we develop is based on a holistic perspective including <b>arti-fact</b> mediation (how software acts as a mediator of users' activities and how users develop instruments), ecologies of artifacts (taking into consideration that users use multiple artifacts), collective and work practice aspects, and technical and software engineering aspects (different forms of and approaches to software adaptation by users). It leads to an understanding that software appropriation is related to how users consider software as a mediator of their activity and turn it into an instrument for themselves based on the functional values they attribute to it. Building on this analysis, We outline a general perspective on designing for appropriation as empowering users to continue software design in use, review some principles and means, and introduce research questions for future work...|$|R
40|$|The {{number of}} video formats is {{increasing}} rapidly. As a consequence, {{the conversion of}} video signals from one for-mat into another is of growing importance. The motion por-trayal of up-converted sequences significantly improves us-ing motion compensated interpolation techniques, but <b>arti-facts</b> are generally visible at the boundary of moving objects where either covering or uncovering of picture parts occurs. In this paper, a robust method to locate covered and uncov-ered areas, find the correct motion vector, and interpolate new pictures, is presented. Moreover, the paper provides an overview and an evaluation {{of some of the}} more relevant proposals for picture rate up-conversion. 1...|$|E
40|$|Robust {{autonomy}} on {{the part}} of software agents re-quires, at least in part, the ability to deal intelligently with novel and unexpected situations. According to global workspace theory, dealing with such situations is one of the primary functions of consciousness in humans. Below we briefly describe two software agents that implement this psychological theory, and discuss their resulting potential for robust autonomy. Autonomous Agents Artificial intelligence pursues the twin goals of understand-ing human intelligence and of producing intelligent <b>arti-facts.</b> Designing, implementing and experimenting with autonomous agents (Franklin & Graesser 1997) furthers both these goals in a synergistic way. In particular, design...|$|E
40|$|ABSTRACT: The {{outstanding}} {{importance of}} the Early Bronze Age “Skydisk of Nebra ” gave reason to investigate Central European copper occurrences {{in order to find}} out which occurrence might have been the source for its copper. Lead isotope ratios (by MC-ICP-MS) and trace element con-tents (Ag, As, Sb, Co, Ni, Bi, by energy-dispersive XRF) of German and Polish Kupferschiefer are presented and compared with data from the “Skydisk ” and other artifacts found at Nebra. Trace ele-ment ratios and lead isotope data show clear differences between Kupferschiefer ore and Nebra <b>arti-facts.</b> As a consequence, the investigated Kupferschiefer occurrences can be excluded as a copper source for the Nebra finds...|$|E
40|$|This paper {{explores the}} {{proximate}} {{cause of the}} Iron Age. Why did nations of the Eastern Mediterranean switch from bronze to ferrous metals between 1200 and 1000 BC, while Egypt did not commonly use ferrous metals for utilitarian purposes until 600 BC? To answer that question, {{it is first necessary}} to define why 1200 to 1000 BC in the Near East is considered the transition from Bronze Age to Iron Age. Paradoxically, it is not the smelting of iron that distinguishes the Bronze Age from the Iron Age. At least one Mesopotamian smelted iron <b>arti-fact</b> (distinguished from meteoric iron by its lack of nickel) dates from 5000 BC. Increasing numbers of smelted iron objects appear in Mesopotamia, Anatolia, and Egypt between 3000 and 2000 BC, including a circa 2800 BC iron sword from Tell Asmar. But iron in the Early Bronze Age was rare and expensive. At {{the end of the third}} millennium, iron appears to have been five times as expensive as gold. The weapons and tools made of iron are ceremo-nial in nature, and the other uses of iron are ornamental. ...|$|R
40|$|Respiratory {{motion is}} well known to cause {{artifacts}} in magnetic resonance spectroscopy (MRS). In MRS of the breast, the dom-inant artifact is not due to motion of the breast itself, but rather it is produced by B 0 field distortions associated with respiratory motion of tissues {{in the chest and}} abdomen. This susceptibility artifact has been reported to occur in the brain, but it is more apparent in the breast due to the anatomic proximity of the lungs. In the breast, these B 0 distortions cause shot-to-shot frequency shifts, which vary an average of 24 Hz during a typical 1 H MRS scan at 4 T. This variation can be corrected retrospec-tively by frequency shifting individual spectra prior to averaging. If not corrected, these shifts reduce spectral resolution and increase peak fitting errors. This work demonstrates the <b>arti-fact,</b> describes a method for correcting it, and evaluates its impact on quantitative spectroscopy. When the artifact is not corrected, quantification errors increase by an average of 28 %, which dramatically impacts the ability to measure metabolite resonances at low signal-to-noise ratios. Magn Reson Me...|$|R
40|$|Prior {{research}} suggests that perceived performance of a product or a service is directly linked to postpurchase satisfaction. We argue that this causal relationship might be a measurement <b>arti-fact</b> and/or insufficient modeling of the satisfaction process rather than an accurate assessment of how consumers form satisfaction judgments. To test our hypotheses, a 2 × 2 × 2 (Performance × Expectations × Needs) factorial design was used with 2 types of perceived performance measures (value-laden and objective). The findings demonstrate that the observed direct link from perceived performance to overall satisfaction di-minishes when more objective perceived performance indicators replace the commonly used value-laden measures. Furthermore, desire-congruency was found to contribute independently to satisfaction over and above a disconfirmation-of-expectations standard. In fact, desire-con-gruency {{was found to be}} a better predictor of satisfaction than disconfirmation-of-expectations. Finally, our results suggest that the direct performance–satisfaction link becomes insignificant when the modeling of the satisfaction process is improved. Taken together, these findings sup-port the view that the frequently observed high correlations between perceived performance and satisfaction might be a reflection of the type of measures used and/or insufficient capturing o...|$|R
40|$|Abstract: While {{performing}} a certain task software developers use multiple tools, read different artifacts and change others. As software developers are often inter-rupted during a task, {{they end up}} simultaneously using a vast set of tools and <b>arti-facts.</b> They need to switch between those artifacts many times until a task is com-pleted. In sum {{a lot of time}} gets wasted due to locating, reopening or selecting the right artifact needed next. To address this problem we introduce Switch!, a context aware artifact recommendation and switching tool for software developers. Switch! recommends artifacts that are likely needed in the current situation, based on task semantics, interaction history and community profile. ...|$|E
40|$|Abstract Model-driven {{development}} of user interfaces {{has become increasingly}} powerful in recent years. Unfortunately, model-driven approaches have the inherent limitation that they cannot handle the informal nature {{of some of the}} artifacts used in truly multidisciplinary user interface development such as storyboards, sketches, scenarios and personas. In this chapter, we present an approach and tool support for multidisciplinary user interface development bridging informal and formal <b>arti-facts</b> in the design and development process. Key features of the approach are the usage of annotated storyboards, which can be connected to other models through an underlying meta-model, and cross-toolkit design support based on an abstract user interface model...|$|E
40|$|Abstract. This paper {{presents}} a novel no-reference blocking artifacts metric us-ing selective gradient and plainness (BAM_SGP) measures for DCT-coded images. A boundary selection criterion is introduced {{to distinguish the}} blocking artifacts boundaries from the true-edge boundaries, which ensures that the most potential artifacts boundaries {{are involved in the}} measurement. Next, the <b>arti-facts</b> are evaluated by the gradient and plainness measures indicating different aspects of blocking artifacts characteristics. Then these two measures are fused into a metric of blocking artifacts. Compared with some existing metrics, ex-periments on the LIVE database and our own test set show that the proposed metric can keep better consistent with Mean Opinion Score (MOS) ...|$|E
40|$|The {{discrepancy}} of 120 {{orders of}} magnitude between the observed energy density of the vacuum and that predicted from manipulations of quantum assumptions has been considered as the “worst prediction in physics”. By employing abbreviated quantum “natural units ” the predicted density is 2. 9 × 10120 greater than the ~ 10 − 9 J/m 3 estimated by current measurements. However a comparable order of magnitude discrepancy for energy, 6 × 10120, emerges when the total calcu-lated force within the universe is distributed across its width. The energy density within the va-cuum should be ~ 10111 J/m 3. Because {{the emergence of the}} total force value required the square of the cut off frequency for Zero Point Fluctuations, the discrepancy could be considered as an <b>arti-fact</b> of temporal sampling, that is, the implicit temporal increments from which the estimates were derived. The identity of the predicted vacuum energy density from counting modes and energy density from quantum theory and that obtained from Newtonian Force applied across the un-iverse could be a considered example of ∑n = n, which is one condition for a holographic state...|$|R
40|$|Aim: Intervertebral spacers for {{anterior}} spine fusion {{are made}} of different materials, which can affect the post-fusion MRI scans. Suscep- tibility artifacts specially for implants made of titanium alloys can decrease the image quality. This study focused {{on the influence of}} deter-mined implant parameters like shape and implant volume in MRI artifacting independent from se-lected MRI-sequences. Methods: In this study the post-implantation MRI scans of determined cuboids and cylinders were evaluated. All in-terbody test implants were made of titanium alloys. MRI scans were carried out by using T 1 TSE sequences. The total artifact volume (TAV) of all examined implants were calculated for sta-tistical t-test correlation and implant volume (IV) /TAV-relation. Results: Considering all ex-amined test implants with an increasing implant size the TAV became significant larger (p< 0, 001) with simultaneous reduction of the respective IV/TAV-relation. According to an intergroup TAV- correlation for cylinders and cuboids with an equivalent implant volume the cylindric test im-plants demonstrated a significant smaller <b>arti-fact</b> range (p< 0, 05). Conclusions: Based on these results the MRI artifacts of larger test im-plants were more limited to the to the implant’s direct surroundings. In this connection for im- plants with identical material volumes a cylin- dric shape demonstrated more advantages con- sidering MRI artifacting than cubic forms...|$|R
40|$|Abstract. A {{bidirectional}} transformation {{consists of}} pairs of transfor-mations —a forward transformation get produces a target {{view from a}} source, while a putback transformation put puts back modifications on the view to the source — satisfying sensible roundtrip properties. Ex-isting bidirectional approaches are get-based in that one writes (an <b>arti-fact</b> resembling) a forward transformation and a corresponding backward transformation can be automatically derived. However, the unavoidable ambiguity that stems from the underspecification of put often leads to unpredictable bidirectional behavior, {{making it hard to}} solve nontriv-ial practical synchronization problems with existing bidirectional trans-formation approaches. Theoretically, this ambiguity problem could be solved by writing put directly and deriving get, but di↵erently from pro-gramming with get it is easy to write invalid put functions. An open challenge is how to check whether the definition of a putback transfor-mation is valid, while guaranteeing that the corresponding unique get exists. In this paper, we propose, as far as we are aware, the first safe language for supporting putback-based bidirectional programming. The key to our approach is a simple but powerful language for describing primitive putback transformations. We show that validity of putback transformations in this language is decidable and can be automatically checked. A particularly elegant and strong aspect of our design is that we can simply reuse and apply standard results for treeless functions and tree transducers in the specification of our checking algorithms. ...|$|R
