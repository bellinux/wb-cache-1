655|4133|Public
25|$|Zhang, J. and Honavar, V. (2003). Learning Decision Tree Classifiers from <b>Attribute</b> <b>Value</b> Taxonomies and Partially Specified Data. In: Proceedings of the International Conference on Machine Learning (ICML-03).|$|E
25|$|The World Wide Web Consortium's Internationalization {{working group}} {{recommends}} {{the use of}} the language tag zh-Hans as a language <b>attribute</b> <b>value</b> and Content-Language value to specify web-page content in simplified Chinese characters.|$|E
25|$|Kang, D-K., Silvescu, A., Zhang, J. and Honavar, V. Generation of <b>Attribute</b> <b>Value</b> Taxonomies from Data for Accurate and Compact Classifier Construction. IEEE International Conference on Data Mining, IEEE Press. pp.130–137, 2004.|$|E
5000|$|Handling {{training}} data with missing <b>attribute</b> <b>values</b> - C4.5 allows <b>attribute</b> <b>values</b> to be marked as ? for missing. Missing <b>attribute</b> <b>values</b> {{are simply not}} used in gain and entropy calculations.|$|R
2500|$|Two special {{data sets}} with missing <b>attribute</b> <b>values</b> were {{extensively}} studied: {{in the first}} case, all missing <b>attribute</b> <b>values</b> were lost (Stefanowski and Tsoukias, 2001), in the second case, all missing <b>attribute</b> <b>values</b> were [...] "do not care" [...] conditions (Kryszkiewicz, 1999).|$|R
40|$|Abstract. An {{action is}} defined as {{controlling}} or changing some of <b>attribute</b> <b>values</b> in an information system to achieve desired result. An action reduct is the minimal set of <b>attribute</b> <b>values</b> distinguishing a favorable object from other objects. We use action reducts to formulate necessary actions. The action suggested by an action reduct induces changes of decision <b>attribute</b> <b>values</b> by changing the condition <b>attribute</b> <b>values</b> to the distinct patterns in action reducts...|$|R
25|$|For {{search engine}} {{optimization}} purposes, some companies offer to sell high PageRank links to webmasters. As links from higher-PR pages {{are believed to}} be more valuable, they tend to be more expensive. It can be an effective and viable marketing strategy to buy link advertisements on content pages of quality and relevant sites to drive traffic and increase a webmaster's link popularity. However, Google has publicly warned webmasters that if they are or were discovered to be selling links for the purpose of conferring PageRank and reputation, their links will be devalued (ignored in the calculation of other pages' PageRanks). The practice of buying and selling links is intensely debated across the Webmaster community. Google advises webmasters to use the nofollow HTML <b>attribute</b> <b>value</b> on sponsored links. According to Matt Cutts, Google is concerned about webmasters who try to game the system, and thereby reduce the quality and relevance of Google search results.|$|E
500|$|... "Consciousness creates reality." [...] First {{proposed}} by John von Neumann, this interpretation grants special status to conscious minds as {{the location of}} wave function collapse, in which the myriad possibilities of a quantum system are narrowed to one observed state. Unlike the Copenhagen interpretation, in which the observer selects which attribute will be seen to have a definite value but does not determine the value itself, von Neumann contended that the actual <b>attribute</b> <b>value</b> is determined in a collapse that occurs at the interface {{of the brain and}} the mind.|$|E
2500|$|In attribute-concept values {{interpretation}} of a missing <b>attribute</b> <b>value,</b> the missing <b>attribute</b> <b>value</b> may be replaced by any value of the attribute domain restricted to the concept to which the object with a missing <b>attribute</b> <b>value</b> belongs (Grzymala-Busse and Grzymala-Busse, 2007). [...] For example, if for a patient {{the value of an}} attribute Temperature is missing, this patient is sick with flu, and all remaining patients sick with flu have values high or very-high for [...] Temperature when using the {{interpretation of}} the missing <b>attribute</b> <b>value</b> as the [...] attribute-concept value, we will replace the missing <b>attribute</b> <b>value</b> with [...] high and very-high. [...] Additionally, the characteristic relation, (see, e.g., Grzymala-Busse and Grzymala-Busse, 2007) enables to process data sets with all three kind of missing attribute values at the same time: lost, [...] "do not care" [...] conditions, and attribute-concept values.|$|E
30|$|The {{experiment}} is conducted under static network <b>attribute</b> <b>values</b> and dynamic network <b>attribute</b> <b>values.</b> The simulation code {{was written in}} Matlab.|$|R
50|$|Since the <b>{{attribute}}</b> <b>values</b> of one object {{may depend}} on the <b>attribute</b> <b>values</b> of related objects, the attribute generation process assigns values collectively.|$|R
40|$|Considering the {{different}} size of quantitative <b>attribute</b> <b>values</b> and categorical <b>attribute</b> <b>values</b> in databases, we present two quantitative association rules mining methods with privacy-preserving respectively, one bases on Boolean association rules, which {{is suitable for}} the smaller size of quantitative <b>attribute</b> <b>values</b> and categorical <b>attribute</b> <b>values</b> in databases; the other one bases on partially transforming measures, which is suitable for the larger ones. To each approach, the privacy and accuracy are analyzed, and the correctness and feasibility are proven by experiments. 1...|$|R
2500|$|Some {{work has}} also {{examined}} outliers for nominal (or categorical) data. In {{the context of}} a set of examples (or instances) in a data set, instance hardness measures the probability that an instance will be misclassified ( [...] where [...] is the assigned class label and [...] represent the input <b>attribute</b> <b>value</b> for an instance in the training set [...] ). Ideally, instance hardness would be calculated by summing over the set of all possible hypotheses : ...|$|E
2500|$|Rough {{set theory}} {{is useful for}} rule {{induction}} from incomplete data sets. Using this approach we can distinguish between three types of missing attribute values: lost values (the values that were recorded but currently are unavailable), attribute-concept values (these missing attribute values may be replaced by any <b>attribute</b> <b>value</b> limited to the same concept), and [...] "do not care" [...] conditions [...] (the original values were irrelevant). [...] A [...] concept (class) {{is a set of}} all objects classified (or diagnosed) the same way.|$|E
5000|$|In attribute-concept values {{interpretation}} of a missing <b>attribute</b> <b>value,</b> the missing <b>attribute</b> <b>value</b> may be replaced by any value of the attribute domain restricted to the concept to which the object with a missing <b>attribute</b> <b>value</b> belongs (Grzymala-Busse and Grzymala-Busse, 2007). For example, if for a patient {{the value of an}} attribute Temperature is missing, this patient is sick with flu, and all remaining patients sick with flu have values high or very-high for Temperature when using the {{interpretation of}} the missing <b>attribute</b> <b>value</b> as the attribute-concept value, we will replace the missing <b>attribute</b> <b>value</b> with high and very-high. Additionally, the characteristic relation, (see, e.g., Grzymala-Busse and Grzymala-Busse, 2007) enables to process data sets with all three kind of missing attribute values at the same time: lost, [...] "do not care" [...] conditions, and attribute-concept values.|$|E
40|$|In this paper, a new {{approach}} to working with missing <b>attribute</b> <b>values</b> in inductive learning algorithms is introduced. Three fundamental issues are studied: the splitting criterion, the allocation of <b>values</b> to missing <b>attribute</b> <b>values,</b> and the prediction of new observations. The formal definition for the splitting criterion is given. This definition takes into account the missing <b>attribute</b> <b>values</b> and generalizes the classical definition. In relation to the second objective, multiple values are assigned to missing <b>attribute</b> <b>values</b> using a decision theory approach. Each of these multiple values will have an associated confidence and error parameter. The error parameter measures how near or how far the value is from the original <b>value</b> of the <b>attribute.</b> After applying a splitting criterion, a decision tree is obtained (from training sets with or without missing <b>attribute</b> <b>values).</b> This decision tree can be used to predict the class of an observation (with or without missing <b>attribute</b> <b>values).</b> Hence, there are four perspectives. The three perspectives with missing <b>attribute</b> <b>values</b> are studied and experimental results are presented...|$|R
40|$|Weight {{aggregation}} is the {{key process}} to solve a multiple-attribute group decision-making (MAGDM) problem. This paper is trying to propose a possible approach to objectivize subjective information and to aggregate information from <b>attribute</b> <b>values</b> themselves and decision-makers’ judgment. An MAGDM problem without information about decision-makers’ and attributes’ weight is considered. In order to define decision-makers’ subjective preference, their utility function is introduced. The <b>attributes</b> <b>value</b> matrix is converted into a subjective <b>attributes</b> <b>value</b> matrix based on their subjective judgment on <b>attribute</b> <b>values.</b> By utilizing the entropy weighting technique, decision-maker’s subjective weight on attributes and objective weight on attributes are determined individually based on the subjective <b>attributes</b> <b>value</b> matrix and <b>attributes</b> <b>value</b> matrix. Based {{on the principle of}} minimum cross-entropy, all decision-makers’ subjective weights are integrated into a single weight vector that is closest to all decision-makers’ judgment without any extra information added. Then, by applying the principle of minimum cross-entropy again, a weight aggregation method is proposed to combine the subjective and objective weight of attributes. Finally, an MAGDM example of project choosing is presented to illustrate the procedure of the proposed method...|$|R
40|$|In a {{previous}} paper {{three types of}} missing <b>attribute</b> values: lost <b>values,</b> attribute-concept values and “do not care ” conditions were compared using six data sets. Since previous experimental results were affected by large variances due to con-ducting experiments on different versions of a given data set, we conducted new experiments, using {{the same pattern of}} missing <b>attribute</b> <b>values</b> for all three types of missing <b>attribute</b> <b>values</b> and for both certain and possible rules. Additionally, in our new experiments, the process of incremental replacing specified <b>values</b> by missing <b>attribute</b> <b>values</b> was terminated when entire rows of the data sets were full of missing <b>attribute</b> <b>values.</b> Finally, we created new, incomplete data sets by replacing the specified values starting from 5 % of all <b>attribute</b> <b>values,</b> instead of 10 % as in the previous experiments, with an increment of 5 % instead of the previous increment of 10 %. As a result, it is becoming more clear that the best approach to missing <b>attribute</b> <b>values</b> is based on lost values, with small difference between certain and possible rules, and that the worst approach is based on “do not care ” conditions, certain rules. With our improved experimental setup it is also more clear that for a given data set the type of the missing <b>attribute</b> <b>values</b> should be selected individually. ...|$|R
50|$|This {{particular}} notation {{is called}} <b>attribute</b> <b>value</b> matrix (AVM).|$|E
5000|$|<b>Attribute</b> <b>value</b> delimiters {{are set to}} {{quotation}} marks (double quotes) ...|$|E
5000|$|An {{alternative}} alt <b>attribute</b> <b>value</b> {{would be}} [...] "The Danish flag".|$|E
40|$|Entity <b>attribute</b> <b>values,</b> such as “lord of {{the rings}} ” for movie. title or “infant ” for shoe. gender, are atomic {{components}} of entity ex-pressions. Discovering alternative surface forms of <b>attribute</b> <b>values</b> is important for improving entity recognition and retrieval. In this work, we propose a novel compact clustering framework to jointly identify synonyms {{for a set of}} <b>attribute</b> <b>values.</b> The framework can integrate signals frommultiple information sources into a similarity function between <b>attribute</b> <b>values.</b> And the weights of these signals are optimized in an unsupervised manner. Extensive experiments across multiple domains demonstrate the effectiveness of our clus-tering framework for mining entity attribute synonyms. 1...|$|R
50|$|In {{addition}} to basic identity <b>attribute</b> <b>values</b> like strings and numbers, the data entity {{referred to by}} an r-card can have complex <b>attribute</b> <b>values</b> consisting of aggregates of basic attribute types as well as UDI links to other entities.|$|R
40|$|The chief {{hindrance}} to {{the widespread}} adoption of attribute-grammar-based systems {{has been that}} they are profligate consumers of storage. This paper concerns new storage management techniques that {{reduce the amount of}} storage used by reducing the number of <b>attribute</b> <b>values</b> retained at any stage of attribute evaluation; it presents one algorithm for evaluating an n-attribute tree that never retains more than O(√(n)) <b>attribute</b> <b>values,</b> and it presents a second algorithm that never retains more than O(n) <b>attribute</b> <b>values...</b>|$|R
5000|$|Compare — test if a named entry {{contains}} a given <b>attribute</b> <b>value</b> ...|$|E
5000|$|... «derive» UML2: The client (e.g., <b>attribute</b> <b>value,</b> link) may be {{computed}} from the supplier(s) ...|$|E
5000|$|... a valid fact, whose {{collection}} pauses whilst {{the missing}} dimensional <b>attribute</b> <b>value</b> itself is collected.|$|E
40|$|Abstract: Traditionally, {{similarity}} between two objects is calculated {{by using only}} their <b>attribute</b> <b>values,</b> such as number of coincided attributes, Euclid distance, etc. A new concept of similarity dealing with a uniqueness measure is proposed in this paper by which the {{similarity between}} two objects is not only considered using their <b>attribute</b> <b>values,</b> but also a subset of objects as an important parameter. Here, the subset of objects may be regarded as knowledge of human. In this concept of similarity, if <b>attribute</b> <b>values</b> of two objects are rare in the subset, and their <b>attribute</b> <b>values</b> are the same, then their degree of similarity is high. On the other hand, if the <b>attribute</b> <b>values</b> of two objects are not rare in the subset, and their <b>attribute</b> <b>values</b> are the same, then their degree of similarity is low. Consequently, the degree of similarity between two objects will be changed depending on the subset of objects. Moreover, we discuss mathematical properties {{of the concept of}} similarity dealing with uniqueness measure. Finally, we discuss differences between the concept of similarity based on uniqueness measure and traditional similarity using some examples...|$|R
40|$|We {{present a}} theory of {{decision}} by sampling (DbS) in which, in contrast with traditional models, there are no underlying psychoeconomic scales. Instead, we assume that an <b>attribute’s</b> subjective <b>value</b> is constructed {{from a series of}} binary, ordinal comparisons to a sample of <b>attribute</b> <b>values</b> drawn from memory and is its rank within the sample. We assume that the sample reflects both the immediate distribution of <b>attribute</b> <b>values</b> from the current decision’s context and also the background, real-world distribution of <b>attribute</b> <b>values.</b> DbS accounts for concave utility functions; losses looming larger than gains; hyperbolic temporal discounting; and the overestimation of small probabilities and the underestimation of large probabilities. ...|$|R
50|$|C4.5 improved: {{discrete}} {{and continuous}} <b>attributes,</b> missing <b>attribute</b> <b>values,</b> <b>attributes</b> with differing costs, pruning trees (replacing irrelevant branches with leaf nodes).|$|R
50|$|The syntax for {{an object}} with an <b>attribute</b> <b>value</b> OPL {{sentence}} shall be: Attribute of Object is value.|$|E
5000|$|There is a 2005 draft microformats {{specification}} {{with the}} same functionality. The Robot Exclusion Profile looks for the <b>attribute</b> <b>value</b> '''' in HTML tags: ...|$|E
50|$|The Compare {{operation}} takes a DN, {{an attribute}} name and an <b>attribute</b> <b>value,</b> and checks if the named entry contains that attribute with that value.|$|E
5000|$|Generate <b>attribute</b> <b>values</b> {{based on}} user-supplied prior probabilities.|$|R
40|$|Abstract: Fuzzy Realational Databases (FRDB) allow atribute {{values to}} be fuzzy sets. In the {{application}} {{developed by the}} author, <b>attribute</b> <b>values</b> can be intervals, triangular fuzzy numbers and linguistic labels. In this paper we present the algorithms for calculating these values when they appear in queries and <b>attribute</b> <b>values...</b>|$|R
3000|$|As {{pointed out}} by Zaki and Ogihara, the problem of finding a common itemset among the tuples is NP-complete, since it {{can be reduced to}} the problem of clique {{discovery}} in a bipartite graph [18]. Similarly, the problem of finding a common set of <b>attribute</b> <b>values</b> among a set of tuples can be reduced to a bipartite clique problem as follows. Assume we have a graph G = (U, V, E), where G is a bipartite graph consisting of parts U and V, and edges E. A set of tuples can be projected to U and a set of <b>attribute</b> <b>values</b> to V, and the existence of a tuple containing a set of <b>attribute</b> <b>values</b> to an edge in E. A clique in a bipartite graph is equivalent of a set of <b>attribute</b> <b>values</b> that is common in a set of tuples. Then, the problem of finding a common <b>attribute</b> <b>values</b> is reduced to the problem of finding a clique in a bipartite graph G. This problem is known to be NP-complete and, for instance, finding the largest clique requires computation O(|U||V|).|$|R
