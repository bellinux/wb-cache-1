11|10000|Public
40|$|A {{decoding}} device for a coding structure, consisting of parallel, interspaced marker bodies of basically equal width, which include fixed spacings {{so that at}} least a first and a second spacing difference are unambiguously assigned to encoded information, comprises <b>an</b> <b>image</b> <b>processing</b> <b>device</b> for the generation of spacing signals, two subtractors, which are connected downstream of the image processing device, and a table storage device, which can be controlled by the output signals of the subtractors...|$|E
40|$|The {{description}} {{refers to}} an illumination device for objects which are filmed by a camera whose image signal is presented to <b>an</b> <b>image</b> <b>processing</b> <b>device</b> and which {{has at least one}} CCD image sensor, comprising a light source which controls a control unit by means of pulses. The invention is characterized {{by the fact that the}} light source has a light emitting diode array whose diodes receive at least one pulse of variable width selectively from the control unit during each image period...|$|E
40|$|The {{invention}} {{relates to}} <b>an</b> <b>image</b> <b>processing</b> <b>device</b> (1) for finding corresponding {{first and second}} regions in two image data sets of an object. In a first image data set a source line and in a second image data set a corresponding target line are determined depending on reference regions detectable in both image data sets. A first region in the first image data set is projected onto the source line, thereby dividing the source line into two source sub-lines and defining a source ratio as {{the ratio of the}} length of one of the source sub-lines to the length of the entire source line. A second region in the second image data set is then determined such that a projection of the second region onto the target line leads to a corresponding target ratio which is similar to the source ratio...|$|E
40|$|NOVELTY - The digital <b>image</b> <b>processing</b> method {{provides}} <b>a</b> secondary <b>image</b> from <b>an</b> original <b>image</b> via <b>a</b> {{digital signal}} processor for wavelet separation, with a color transformation used for matching the digital color and brightness levels to the color and brightness sensitivity of the human eye and/or <b>an</b> <b>image</b> reduction for reduction of the image coefficients. DETAILED DESCRIPTION - <b>A</b> digital <b>image</b> <b>processing</b> <b>device</b> is independently claimed. USE - For <b>processing</b> <b>images</b> for image databank. ADVANTAGE - The processing method allows 100, 000 images or more to be stored in <b>an</b> <b>image</b> databank. DESCRIPTION OF DRAWING(S) - The drawing shows a schematic representation of the wavelet separation of the original image...|$|R
40|$|The {{evaluation}} of holographic interferograms has been reviewed to perform quasi-real time and more accurate measurements of temperature fields within CVD reactors. In this way <b>a</b> powerful <b>image</b> <b>processing</b> <b>device</b> has been annexed to our optical arrangement to perform suitable and fast data acquisition. The {{evaluation of}} holographic interferograms is achieved using Fast Fourier Transform algorithm. Temperature fields have been measured within a large cold wall CVD reactor for different cylindrical substrate diameters {{and also for}} a conic substrate. We present some useful empirical correlations between Nusselt and Rayleigh numbers. Our aim in {{this paper is to}} give some useful experimental data which could be used to improve the validity of mathematical models developed for CVD process...|$|R
40|$|The {{computational}} {{and communication}} {{requirements of a}} wide range of <b>image</b> <b>processing</b> algorithms were analysed and used to specify the design of <b>a</b> general purpose <b>image</b> <b>processing</b> <b>device.</b> The algorithms considered are restricted to image-in and image or feature-out type algorithms. These algorithms are catagorised by the deamands that they would place on a hardware architecture. We conclude that the major consideration is the o-chip input/output limitation which needs to be able to exploit redundancy in both the data and processor instructions. This paper summarises: the main conclusions of this work, an architecture which we have designed in an attempt to meet the identied constraints and how it diers from previous attempts. ...|$|R
40|$|US 2013235970 A <b>An</b> <b>image</b> <b>processing</b> <b>device</b> of a {{computer}} tomography system includes an interface and a calibration data determiner. The interface is implemented to receive a first set of X-ray recordings of an object to be examined from first discrete recording angles and to receive {{a second set of}} X-ray recordings of the object to be examined from second discrete recording angles. The calibration data determiner is implemented to determine calibration data for the computer tomography system {{on the basis of the}} first set. The first set is further recorded during a first rotation run wherein the computer tomography system and the object to be examined rotate relative to each other, wherein the second set is recorded during at least a further rotation run after the first rotation run. On the basis of the calibration data and the first and second sets {{a computer}} tomography recording is reconstructable...|$|E
40|$|The {{description}} {{refers to}} a coding structure affixed to an object for the coding of information affecting the object, said information being detectable and decodable by means of <b>an</b> <b>image</b> <b>processing</b> <b>device.</b> A known coding structure designated as a barcode is restricted to applications in which the coding structure can be printed with high precision. The coding structure according to the invention permits reliable information decoding, in particular {{in the area of}} identification of light alloy vehicle rims on which a barcode cannot be affixed, said coding structure comprising at least three parallel marking bodies running along the surface of the object and each having the same width, the quotient of a first distance {{between the first and second}} marking bodies in relation to a second distance between the third marking body and the first or second marking body having a value dependent on the coded information...|$|E
40|$|In this paper, a {{new method}} for an {{improved}} image password lock system by tracing position information of the pupil is described. The present technology relates to an efficient auto-detecting function, and in particular, to an image password lock system, which {{can provide the}} benefits of a novel password input mode without any contact. In this system, a PC camera device detects a movable target object to read a dynamic eye image data. Moreover, the dynamic eye image data has a predetermined shooting range set to be a whole-region image, and the whole-region image has a central region and a plurality of specific password regions. A target eye image is displayed by a display device, and then processed by <b>an</b> <b>image</b> <b>processing</b> <b>device,</b> thereby calculating a center coordinate point of the target eye image in the dynamic image data, compiling a password constituted by a movement position of the target object image, displaying the password, and validating the password. Therefore, {{the benefits of a}} novel password input mode without any contact, an efficient anti-theft function, are provided...|$|E
40|$|A lot of {{advancement}} {{in the technology}} day by day so here an algorithm is designed in such a fashion where the accurate detection of the objects from the randomized data respectively. Therefore here initially for {{the collection of the}} randomized data <b>a</b> <b>image</b> <b>processing</b> capturing <b>device</b> is place in a wide range for the entire image has to be captured and then followed by some of the processing it is stored in the database. Then after the object detection phenomena plays a crucial and critical role for the accurate detection of the objects respectively. Therefore a Zhang’s based algorithm is used for the pattern generation and recognition where the working is done on the randomized data. The system or the methodology is designed in such a fashion that that mainly the data has to be retrieved from the capturing device in to the system and then pre processing is done and then followed by the pattern recognition where the accurate object has to be detected based on the regional basis oriented scenario.  </p...|$|R
40|$|We {{present a}} {{modified}} stereo algorithm based on dynamic programming techniques, which outputs a dense disparity map, and its actual implementation on <b>a</b> linear SIMD <b>image</b> <b>processing</b> <b>device</b> with 256 PE, the IMAP-VISION. Our results show the high suitability of this algorithm and the parallel hardware for real-time 3 D-vision based robot control. Running on the SIMD device, the algorithm guarantees a processing time {{of less than}} 100 ms hard for a Region Of Interest of 128 by 128 pixel and a respectively large depth range of 64 disparity levels. The algorithm can be adjusted with ease and fast at the update rate of the input for even higher output rates, when considering lower depth resolution or less ROI width...|$|R
50|$|Development and {{fabrication}} of micro- and nano-electro mechanical systems (MEMS/NEMS). New devices being researched include NEMS-based metamaterials, miniature signal <b>processing</b> <b>devices,</b> biomedical, diagnostic and <b>image</b> <b>processing</b> <b>devices,</b> tiny wireless components (filters, mixers, antennas), miniature opto-electromechanical devices (optical relays, optical multiplexers, deformable optics), miniature biosensors and environmental sensors, and micro- and nano-fluidics devices.|$|R
40|$|This type {{of machine}} has a testing device for {{performing}} a quality {{control on the}} knitwear, said device having swivelling extendable arms on which the knitwear is stretched, whereby a gusset stretcher is provided between the extendable arms. The knitwear has only a short dwell time on the stretch-out device. The knitwear is checked for defects in a fully automatic and reliable process by a machine of simple design. The gusset stretcher of the machine contains an illumination source and a camera in the range outside the gusset stretcher, {{the lens of the}} camera being trained on the illuminated parts of the gusset stretcher, whereby the camera is connected to <b>an</b> <b>image</b> <b>processing</b> <b>device.</b> The knitwear is checked for defects by the machine. Very short machine cycles can be maintained, whereby a constant quality can be achieved during checking. The machine and the process performed by it permits the reliable detection of ladders, cobwebbing, holes and similar. The test method is based on the consideration that a hole in the stocking fabric is more transparent when looked through than the fabric itself...|$|E
40|$|DE 102009049387 A 1 UPAB: 20110509 NOVELTY - The device (1000) has a micro-lens field (10) {{with two}} micro-lenses (10 a, 10 b), and {{an image sensor}} with image {{detector}} matrices (30) including image detectors. The micro-lenses correlate with the matrices to form optical channels. Centers of the matrices are laterally shifted to varying extents in relation to area centroids of micro-lens apertures (13 a, 13 b) of the associated channels, so that the channels have different, partially overlapping capturing regions. An overlapping region of the capturing regions is imaged on the matrices with respect to an image detector grid of the matrices. DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following: (1) <b>an</b> <b>image</b> <b>processing</b> <b>device</b> comprising an image sensor {{with a set of}} image detectors (2) a method for optical imaging. USE - Optical imaging device i. e. miniaturized camera system, for a portable device e. g. mobile phone, personal digital assistant (PDA) and laptop. ADVANTAGE - The device achieves a high imaging quality with a lower installation height. The device can be manufactured in a simple and cost-effective manner...|$|E
40|$|A {{method of}} {{environment}} description based on stereovision sensors will be presented. The 3 D environment {{is composed of}} industrial objects depicted as cuboids. The objects can be stationary or moving, and a distinction should be made between these two classes. The system is structured in a distributed fashion. One sensor is composed {{of a pair of}} video cameras and <b>an</b> <b>image</b> <b>processing</b> <b>device,</b> which is able to perform real-time stereo processing. The output of one stereo sensor is a list of cuboids, describing the part of the environment that it sees. All the sensors must report the cuboids in the same coordinate system. The cuboids are communicated using a symbolic representation and a standard network communication protocol. Each sensor output is sent to a fusion computer, which assembles the complete description of the environment. The result of the fusion process is in two formats: a concise format which can be used by a remote control algorithm, and a standard 3 D description format which can be used by remote visualization standard programs. Both these formats are communicated through standard networking protocols. As possible employment of the system we can enumerate: warehouse activity planning, surveillance of harbors, parking lots, etc...|$|E
40|$|This paper {{describes}} {{several issues}} of parallelizing <b>an</b> <b>image</b> <b>processing</b> application. The parallelization is performed both automatically and user controlled at the application code level. The sequential <b>image</b> <b>processing</b> library is not modi ed. A solution for parallelizing <b>an</b> <b>image</b> <b>processing</b> library is also proposed...|$|R
30|$|The fourth paper designs a {{three-dimensional}} stereoscopic display system for operating microscopes in biomedical applications. The system {{consists of a}} stereoscopic camera part, <b>image</b> <b>processing</b> <b>device</b> for stereoscopic video recording, and the stereoscopic display. To reduce eyestrain and viewer fatigue, the authors apply a preexisting stereomicroscope structure and a polarized-light stereoscopic display method that does not reduce {{the quality of the}} stereoimages.|$|R
40|$|In {{applications}} of real-time <b>image</b> <b>processing,</b> <b>images</b> must be processed pace-keepingly with external processes. This leads to high data rates which require special real-time <b>image</b> <b>processing</b> <b>devices.</b> Such devices consist of configurable pipelines of dedicated electronic processing units, programmable processors, and data buffers. So far, these complex devices {{must have been}} programmed manually at a device-near level: The <b>image</b> <b>processing</b> algorithm must be decomposed into processing steps, the processing steps must be scheduled, the requested functions must be assigned to the given physical resources, and numerous operational parameters must be set. This manual "flow control planning" has several drawbacks: It is time-consuming and error-prone, {{it can be done}} only be experts who have detailed knowledge on the target device, and the resulting programs and restricted to only one specific target configuration and are thus badly re-usable. In order to overcome the drawbacks of a manual plan ning, an automatic flow control planner has been designed and implemented. Using this flow control planner, <b>image</b> <b>processing</b> algorithms can be specified in a device-independent, functional way by means of data flow graphs. These specifications are then automatically transformed into a control program for a desired target device. A graphical documentation of the planning results is created automatically as well. The programming environment is not restricted to one specific target device, but it can be applied to any real-time <b>image</b> <b>processing</b> <b>device</b> which has <b>a</b> configurable pipeline architecture. In order to verify that an automatic flow control planning can be successfully applied to real-time <b>image</b> <b>processing</b> applications, <b>a</b> case study has been performed. For a set of industrial applications which have been programmed manually in the past, the automatic planning and the manual planning are compared concerning the quality of the results and the time spent. It is shown that the results of the automatic planning are comparable to those of a manual planning by human experts, but they are created in much less time. Therefore, the automatic flow control planning offers a visible improvement of efficiency for the programming of real-time <b>image</b> <b>processing</b> <b>devices...</b>|$|R
40|$|DE 102007063041 A 1 UPAB: 20090710 NOVELTY - The {{arrangement}} has laser light-irradiation devices (E 1, E 2) including lasers (1 a, 1 b) {{and expanding}} optical systems (5 a, 5 b) for expanding laser beams (LS 1, LS 2). The expanded beams are irradiated from opposite sides {{on a common}} target volume (ZV), in which an object (O) is arranged. A charge coupled device (CCD) camera (2) optically detects laser sectional lines produced in the target volume by the radiated laser beams. <b>An</b> <b>image</b> <b>processing</b> <b>device</b> (3) identifies and separates the laser sectional lines {{from each other in}} a recorded image and assigns the lines to the respective lasers. DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a laser light section method for determining an elevation profile of an object. USE - Laser light section arrangement for determining an elevation profile of an object, for determining volume of the object, and for determining a filling level and a filling weight of bulk goods i. e. powder, in a container i. e. blister container (all claimed). Can also be used for measuring surface defects on copper plates, surface defects on concrete plates, welding seams at a robotic arm, thickness of metal bands, filling volume in Blistern, engine blocks in the passage, bodies, rotatable parts such as gear shafts or drive shafts and recognizing missing rivets, soldering level on printed circuit boards, warpages of food package, width and groove depth of motor-car tires, distortions of hot cast parts. ADVANTAGE - The object is subjected to a three-dimensional volume measurement to measure volume and elevation profile of the object in an easy, rapid and reliable manner without any inaccurate and/or incomplete volume and/or profile measurements. The laser beams are reflected by reflectors and/or mirrors such that the laser beams run one above the other perpendicular to a reference level and parallel to each other in an accurate manner, thus achieving a very compact design for the laser light section arrangement...|$|E
40|$|Altera’s and Terasic’s FPGA based (Hardware) Image Analyzer-synthesizer (HIMANSY) is presented. The present tool {{has been}} used for both {{analysis}} and synthesis of images using the rotation angles based discrete orthogonal transforms. HIMANSY is equipped with video camera, DE 2 /DE 3 Development Kit and LCD display. The core of the tool is based on the embedded NIOS II processor. The prototyping of novel <b>image</b> <b>processing</b> <b>devices</b> is possible using HIMANSY...|$|R
40|$|Using modern TV-endoscope equipment, we have experimented <b>image</b> <b>processing</b> {{in several}} ways. This time, we {{designed}} new <b>image</b> <b>processing</b> unit called &#x 201 c;Color Subtracted Enhancement <b>image</b> <b>processing</b> unit&#x 201 d;. This unit&#x 3000;was made {{by combining the}} RGB-Subtraction&#x 3000;image <b>processing</b> <b>device</b> with the color enhancement <b>image</b> <b>processing</b> <b>device.</b> The&#x 3000;RGB-subtraction device is an analogue unit that&#x 3000;enables us to remove the visible red, green and blue peaks from the image. We can subtract the images R-G, R-B, G-R, B-R, B-G simply by changing the switches. The color enhancement device (developed by Olympus optical corporation inc.) is a digital processing unit that lets us reinforce any of these colors. This unit let us enhance any of RGB colors on the image which is processed by RGB-subtraction device. |$|R
40|$|This paper {{addresses}} <b>an</b> <b>image</b> <b>processing</b> based {{technique for}} reading one-dimensional bar codes; {{such as the}} EAN- 13 bar code which is used worldwide for marking retail goods. The proposed technique uses a digital camera to acquire <b>an</b> <b>image</b> of the bar code, it then uses <b>an</b> <b>image</b> <b>processing</b> algorithm to locate and subsequently decode the information stored in the bar code label...|$|R
50|$|AugHit:Build <b>an</b> <b>Image</b> <b>Processing</b> robot {{which can}} play the Brick Break game.|$|R
5000|$|Fiji (Fiji Is Just ImageJ), <b>an</b> <b>image</b> <b>processing</b> package {{based on}} ImageJ ...|$|R
50|$|Aug-Hit: Build <b>an</b> <b>image</b> <b>processing</b> robot {{which can}} play the Break Bricks game.|$|R
50|$|Shadow and {{highlight}} enhancement {{refers to}} <b>an</b> <b>image</b> <b>processing</b> technique to correct exposure.|$|R
40|$|An {{extension}} of second-order differential edge detection methods to color images was previously proposed. This work shows how, by casting the problem into a subpixel resolution oriented framework, an efficient algorithm for edge detection and contour traversal can be devised for both graylevel and color images. The results from an implementation {{on a standard}} PC show that the computational cost is largely dominated by convolution-type operations, whose impact can be substantially reduced by using specialized <b>image</b> <b>processing</b> <b>devices...</b>|$|R
50|$|CxProcess is the {{trademark}} of <b>an</b> <b>image</b> <b>processing</b> technology used in Minolta and Konica Minolta digital cameras.|$|R
50|$|Altruicity, <b>an</b> <b>image</b> <b>processing</b> and {{augmented}} reality app, is currently shortlisted and competing in NYC Big Apps 3.0 contest.|$|R
40|$|This paper {{addresses}} <b>an</b> <b>image</b> <b>processing</b> based {{technique for}} reading EAN- 13 barcodes. This type of barcode is used worldwide for marking retail goods. The proposed technique uses {{a digital camera}} to acquire <b>an</b> <b>image</b> of the barcode, it then uses <b>an</b> <b>image</b> <b>processing</b> algorithm to locate and subsequently decode the barcode. Such an approach will enable electronic devices with cameras such as mobile phones and Personal Digital Assistants (PDAs) {{to act as a}} barcode reader...|$|R
40|$|Si {{interposer}} {{technology has}} the potential to enable highbandwidth and low-power <b>image</b> <b>processing</b> <b>devices</b> of the future, because a very high density system with an ultra-fine pitch (≤ 5 um) wiring can be fabricated. However, the ultrafine pitch wiring may adversely affect the electrical performance of devices. This paper discusses the signal propagation properties of ultra-fine coplanar interconnects on Si interposers. A design chart of the interconnects, obtained from the viewpoint of maximum line length versus target operating frequency, is presented. © 2009 IEEE...|$|R
30|$|The <b>image</b> <b>processing</b> and {{classification}} <b>device</b> allows {{to release}} the main processor from making one-type operations.|$|R
40|$|This paper {{describes}} how <b>an</b> <b>image</b> <b>processing</b> operator can be parallelized using and SIMD linear processor array architecture. Among {{various types of}} linear processor arrays IMAP-Vision was used. This architecture comes {{with a high level}} programming language called 1 DC which produces execution times comparable with using the IMAP assembly language instead. 1 DC is actually C enhanced with some data-parallel features. A solution for parallelizing <b>an</b> <b>image</b> <b>processing</b> library is also proposed. ...|$|R
50|$|Edge {{enhancement}} is <b>an</b> <b>image</b> <b>processing</b> filter {{that enhances}} the edge contrast of <b>an</b> <b>image</b> or video {{in an attempt}} to improve its acutance (apparent sharpness).|$|R
40|$|The paper {{presents}} an approach of using algorithmic skeletons for adding data parallelism to <b>an</b> <b>image</b> <b>processing</b> library. The method {{is used for}} parallelizing <b>image</b> <b>processing</b> applications composed of low-level <b>image</b> operators on <b>a</b> distributed memory system. In this way, a user who wants to parallelize <b>an</b> <b>image</b> <b>processing</b> application {{is not involved in}} the design and the implementation of parallel algorithms, but his only task is how to select for each low-level operator the appropriate skeleton to obtain the parallel version of the application. Example of the multibaseline stereo vision <b>image</b> <b>processing</b> aplication is given for reference...|$|R
50|$|In 1994, Johnson {{adapted the}} Eckhorn model to <b>an</b> <b>image</b> <b>processing</b> {{algorithm}}, calling this algorithm a pulse-coupled neural network. Over the past decade, PCNNs {{have been used}} in <b>a</b> variety of <b>image</b> <b>processing</b> applications, including: <b>image</b> segmentation, feature generation, face extraction, motion detection, region growing, and noise reduction.|$|R
