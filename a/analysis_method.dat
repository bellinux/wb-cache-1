10000|10000|Public
5|$|In 1988, at {{the request}} of {{investigator}} Joe Nickell, University of Kentucky professor of English Jean G. Pival studied the vocabulary, syntax, and other stylistic characteristics of the letter and concluded that it more closely resembled Lincoln's style of writing than Hay's. A computer <b>analysis</b> <b>method</b> used in a 2017 study by researchers at Aston University's Centre for Forensic Linguistics identified Hay as the letter's author nearly 90% of the time.|$|E
5|$|Experimental {{evidence}} supporting the Watson and Crick model {{was published in}} a series of five articles in the same issue of Nature. Of these, Franklin and Gosling's paper was the first publication of their own X-ray diffraction data and original <b>analysis</b> <b>method</b> that partly supported the Watson and Crick model; this issue also contained an article on DNA structure by Maurice Wilkins and two of his colleagues, whose analysis and in vivo B-DNA X-ray patterns also supported the presence in vivo of the double-helical DNA configurations as proposed by Crick and Watson for their double-helix molecular model of DNA in the prior two pages of Nature. In 1962, after Franklin's death, Watson, Crick, and Wilkins jointly received the Nobel Prize in Physiology or Medicine. Nobel Prizes are awarded only to living recipients. A debate continues about who should receive credit for the discovery.|$|E
25|$|Laser {{excitation}} with multispectral return {{analysis is}} a promising chemical and possibly biological <b>analysis</b> <b>method.</b>|$|E
3000|$|Material <b>Analysis</b> <b>Methods</b> (e.g. {{elemental}} <b>analysis</b> <b>methods,</b> qualitative <b>analysis</b> <b>methods,</b> spectroscopic methods) [...]...|$|R
30|$|In {{this paper}} we have {{presented}} {{the work of}} compilation, classification, structuring, characterization, and unification of automated <b>analysis</b> <b>methods</b> for enterprise models. We collected these <b>analysis</b> <b>methods</b> in one catalog, which aims to offer a guide for supporting enterprise analysts in analyses processes through the description of 78 <b>analysis</b> <b>methods</b> sorted in 2 dimensions (quantitative and functional) and 16 analysis types.|$|R
40|$|This paper {{addresses}} {{current work}} to develop probabilistic structural <b>analysis</b> <b>methods</b> for integration with a specially developed probabilistic finite element code. The {{goal is to}} establish distribution functions for the structural responses of stochastic structures under uncertain loadings. Several probabilistic <b>analysis</b> <b>methods</b> are proposed covering efficient structural probabilistic <b>analysis</b> <b>methods,</b> correlated random variables, and response of linear system under stationary random loading...|$|R
25|$|In 2013, a {{complete}} work about the regulations {{of the use}} of the Buckwalter transliteration for Tunisian was issued by Ines Zribi and her team from the University of Sfax. In fact, a morphological <b>analysis</b> <b>method</b> and a conventional orthography for Tunisian Arabic using this method were posted by 2014.|$|E
25|$|A strong-motion {{seismograph}} at El Centro {{recorded the}} earthquake {{and provided the}} first {{example of such a}} recording made very close to a fault rupture in a major earthquake. This gave a detailed record of the different types of shaking associated with the earthquake. It is often used in design of earthquake-proof structures today, particularly for the time history <b>analysis</b> <b>method.</b>|$|E
25|$|The moment {{distribution}} method is a structural <b>analysis</b> <b>method</b> for statically indeterminate beams and frames developed by Hardy Cross. It was published in 1930 in an ASCE journal. The method only accounts for flexural effects and ignores axial and shear effects. From the 1930s until computers began to be widely used {{in the design and}} analysis of structures, the {{moment distribution}} method was the most widely practiced method.|$|E
40|$|The {{structural}} <b>analysis</b> <b>methods</b> {{research has}} several goals. One {{goal is to}} develop <b>analysis</b> <b>methods</b> that are general. This goal of generality leads naturally to finite-element methods, but the research will also include other structural <b>analysis</b> <b>methods.</b> Another goal is that the methods be amenable to error analysis; that is, given a physical problem and a mathematical model of that problem, an analyst {{would like to know}} the probable error in predicting a given response quantity. The ultimate objective is to specify the error tolerances and to use automated logic to adjust the mathematical model or solution strategy to obtain that accuracy. A third goal is to develop structural <b>analysis</b> <b>methods</b> that can exploit parallel processing computers. The structural <b>analysis</b> <b>methods</b> research will focus initially on three types of problems: local/global nonlinear stress analysis, nonlinear transient dynamics, and tire modeling...|$|R
30|$|The {{literature}} review allowed {{us not only}} to identify <b>analysis</b> <b>methods,</b> but to understand the diversity of enterprise analyses. This diversity helped us to classify <b>analysis</b> <b>methods</b> in a more specialized category than the analysis dimension.|$|R
40|$|KAERI's {{contributions}} to the project entitled Development of <b>Analysis</b> <b>Methods</b> for Seismically Isolated Nuclear Structures under IAEA CRP of the intercomparison of <b>analysis</b> <b>methods</b> for predicting the behaviour of seismically isolated nuclear structures during 1996 - 1999 in effort to develop the numerical <b>analysis</b> <b>methods</b> and to compare the analysis results with the benchmark test results of seismic isolation bearings and isolated nuclear structures provided by participating countries are briefly described. Certain progress in the analysis procedures for isolation bearings and isolated nuclear structures has been made throughout the IAEA CRPs and the <b>analysis</b> <b>methods</b> developed can be improved for future nuclear facility applications. 1...|$|R
25|$|A {{problem the}} energy <b>analysis</b> <b>method</b> cannot resolve is that {{different}} energy forms (heat, electricity, chemical energy etc.) have different quality and value even in natural sciences, {{as a consequence}} of the two main laws of thermodynamics. A thermodynamic measure of the quality of energy is exergy. According to the first law of thermodynamics, all energy inputs should be accounted with equal weight, whereas by the second law diverse energy forms should be accounted by different values.|$|E
25|$|Duplex {{sequencing}} is {{a library}} preparation and <b>analysis</b> <b>method</b> for next-generation sequencing (NGS) platforms that employs random tagging of double stranded DNA to detect mutations with higher accuracy and lower error rate. This method uses degenerate molecular tags {{in addition to}} sequencing adapters to recognize reads originating from each strand of DNA. The generated sequencing reads then will be analyzed using two methods: single strand consensus sequences (SSCSs) and Duplex consensus sequences (DCSs) assembly. Duplex sequencing theoretically can detect mutations with frequencies as low as 5 x 10−8 {{that is more than}} 10,000 fold higher in accuracy compared to the conventional next-generation sequencing methods.|$|E
25|$|There are two typical {{protocols}} of SMD: one {{in which}} pulling velocity is held constant, and {{one in which}} applied force is constant. Typically, part of the studied system (e.g., an atom in a protein) is restrained by a harmonic potential. Forces are then applied to specific atoms at either a constant velocity or a constant force. Umbrella sampling is used to move the system along the desired reaction coordinate by varying, for example, the forces, distances, and angles manipulated in the simulation. Through umbrella sampling, all of the system's configurations—both high-energy and low-energy—are adequately sampled. Then, each configuration's change in free energy can be calculated as the potential of mean force. A popular method of computing PMF is through the weighted histogram <b>analysis</b> <b>method</b> (WHAM), which analyzes a series of umbrella sampling simulations.|$|E
30|$|The rest of {{the paper}} is {{structured}} as follows. The next section summarizes concepts regarding enterprise analysis. In the third section, we present the systematic literature review made regarding enterprise analysis. In the fourth section we (1) classify and characterize the <b>analysis</b> <b>methods</b> taken from the literature review, (2) collect them in one catalog of <b>analysis</b> <b>methods</b> for enterprise architecture models based on the ArchiMate modeling language, and (3) illustrate some <b>analysis</b> <b>methods</b> using the experimental enterprise scenario. Then, in the fifth section we present our tool {{in which we have}} implemented the <b>analysis</b> <b>methods</b> of the proposed catalog. Finally, the last section concludes the paper.|$|R
40|$|Biomedical {{research}} is increasingly using formal modeling and <b>analysis</b> <b>methods</b> {{to improve the}} understanding of complex systems. Verification methods for Stochastic Hybrid Systems (SHSs) are burdened with the curse of dimensionality; however, probabilistic <b>analysis</b> <b>methods</b> such as Monte Carlo (MC) method...|$|R
30|$|Unscalability and {{centralization}} Most data <b>analysis</b> <b>methods</b> are not {{for large-scale}} and complex dataset. The traditional data <b>analysis</b> <b>methods</b> cannot be scaled up because their design {{does not take into}} account large or complex datasets. The design of traditional data <b>analysis</b> <b>methods</b> typically assumed they will be performed in a single machine, with all the data in memory for the data analysis process. For this reason, the performance of traditional data analytics will be limited in solving the volume problem of big data.|$|R
25|$|Alan Fersht {{pioneered the}} phi value <b>analysis</b> <b>method</b> by first {{applying}} {{it to the}} small bacterial protein barnase. In conjunction with molecular dynamics simulations, the analysis illustrated that, at least for this protein, the transition state between folding and unfolding is the same in both reaction directions and more closely resembled the native state. Phi values were found to vary considerably with {{the location of the}} mutation, with some regions of the protein yielding values near 0 and others yielding values near 1. The distribution of phi values over the protein agrees well with the simulated unfolding transition state in all but one helix, later identified as folding semi-independently and forming native-like contacts with the remainder of the protein only after the complete transition state has been reached. Such variations in the folding rate within a protein present another challenge in interpreting phi values, since the transition state structure cannot be determined experimentally. Folding and unfolding simulations, though computationally expensive, can provide valuable structural information that complements phi value results.|$|E
2500|$|Probability binning is a non-gating <b>analysis</b> <b>method</b> {{in which}} flow cytometry data is split into {{quantiles}} on a univariate basis.|$|E
2500|$|... (2009) Workers used {{high quality}} masks - {{on time and}} correctly. So, in most cases {{pollution}} of inhaled air (under a mask) is below the threshold sensitivity of the <b>analysis</b> <b>method</b> used.|$|E
40|$|Abstract. A {{classification}} of <b>analysis</b> <b>methods</b> for CSCL systems is presented which uses as one dimension the distinction into summary analysis and structural analysis and as another distinction {{different types of}} raw data: either user actions or state descriptions. The Cool Modes environment for collaborative modeling enables us to explore the whole spectrum of <b>analysis</b> <b>methods.</b> Action logging {{is based on the}} MatchMaker communication server underlying Cool Modes. Example instances for several <b>analysis</b> <b>methods</b> have been implemented in the Cool Modes framework. ...|$|R
40|$|This study covers recent {{developments}} in automatic text processing, including syntactic, semantic, and statistical language <b>analysis</b> <b>methods.</b> The emphasis is on applications {{in the areas of}} machine translation, information retrieval, and question answering. Recent on-line text processing methods, using man-machine interaction are covered in some detail, as are certain simple, syntactic <b>analysis</b> <b>methods</b> incorporated into a number of experimental information retrieval systems. An evaluation is made of the syntactic <b>analysis</b> <b>methods,</b> and their importance in a retrieval environmentt is discussed...|$|R
50|$|Support {{for various}} time series <b>analysis</b> <b>methods.</b>|$|R
2500|$|... (shown {{here for}} , , [...] ) is unimodal, {{resembling}} a skewed Hénon map. [...] Knowing that the Rössler attractor {{can be used}} to create a pseudo 1-d map, it then follows to use similar analysis methods. [...] The bifurcation diagram is specifically a useful <b>analysis</b> <b>method.</b>|$|E
2500|$|... (2008) PAPR protect workers securely. In all cases, the {{concentration}} of harmful substances (under a mask) was less than the threshold sensitivity of the <b>analysis</b> <b>method</b> used. The authors noted that the tests of high efficiency respirators require workplaces with high polluted air, and these places are hard to find.|$|E
2500|$|Keywords-in-Context: It is a data <b>analysis</b> <b>method</b> {{that reveals}} how {{respondents}} use words in context by comparing words that appear {{before and after}} [...] "key words. KWIC is a helpful analysis to utilize when there are specific words that are {{of interest to the}} researcher or when the data appear to be less rich in information.|$|E
5000|$|Metabolomics Laboratory: <b>analysis</b> <b>methods</b> in {{biomedical}} research ...|$|R
40|$|After a short {{review of}} image <b>analysis</b> <b>methods</b> that use {{deformable}} structures, this paper reveals that fast and accurate matching {{can be achieved}} by employing a variable-flexibility elastic model for image <b>analysis.</b> <b>Methods</b> discussed are illustrated by application examples, with particular emphasis on analysis of wheat grain X-ray images. 1...|$|R
40|$|The bachelor’s thesis {{deals with}} the {{evaluation}} of a financial situation of a chosen cooperative {{with the help of}} selected financial <b>analysis</b> <b>methods.</b> The thesis specifies the selected financial <b>analysis</b> <b>methods</b> which are then applied to the chosen venture and also includes measures for improved financial health of the enterprise...|$|R
2500|$|Further {{methodology}} using MSP-amplified DNA {{analyzes the}} products using melting curve analysis (Mc-MSP). [...] This method amplifies bisulfite-converted DNA with both methylated-specific and unmethylated-specific primers, and determines the quantitative {{ratio of the}} two products by comparing the differential peaks generated in a melting curve analysis. A high-resolution melting <b>analysis</b> <b>method</b> that uses both quantitative PCR and melting analysis has been introduced, in particular, for sensitive detection of low-level methylation ...|$|E
2500|$|The slope {{deflection}} {{method is}} a structural <b>analysis</b> <b>method</b> for beams and frames introduced in 1914 by George A. Maney. The slope deflection method was widely used {{for more than}} a decade until the moment distribution method was developed. In the book, [...] "The Theory and Practice of Modern Framed Structures", written by J.B Johnson, C.W. Bryan and F.E. Turneaure, it is stated that this method was first developed,"by Professor Otto Mohr in Germany, and later developed independently by Professor G.A. Maney". According to this book, professor Otto Mohr introduced this method for the first time in his book,"Evaluation of Trusses with Rigid Node Connections" [...] or [...] "Die Berechnung der Fachwerke mit Starren Knotenverbindungen".|$|E
5000|$|Software {{architecture}} <b>analysis</b> <b>method,</b> {{precursor to}} architecture tradeoff <b>analysis</b> <b>method</b> ...|$|E
5000|$|Developing {{a robust}} {{technical}} basis in multidimensional multiphysics <b>analysis</b> <b>methods</b> ...|$|R
5000|$|In summary, a chronological {{overview}} of citation <b>analysis</b> <b>methods</b> includes: ...|$|R
5000|$|... cluster <b>analysis</b> <b>methods</b> {{including}} k-means, and Latent Dirichlet Allocation (LDA) ...|$|R
