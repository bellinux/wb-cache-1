0|4811|Public
30|$|The {{notion of}} <b>attribute</b> <b>value</b> power is distributive, {{meaning that the}} sum of the power of all <b>attribute</b> <b>values</b> is equal to 1. In other words, the power of an <b>attribute</b> <b>value</b> should be {{measured}} against that of other <b>attribute</b> <b>values</b> rather than as a standalone measure. We provide in “Case studies” section some examples of computation of <b>attribute</b> <b>value</b> power.|$|R
5000|$|Handling {{training}} data with missing <b>attribute</b> <b>values</b> - C4.5 allows <b>attribute</b> <b>values</b> to be marked as ? for missing. Missing <b>attribute</b> <b>values</b> {{are simply not}} used in gain and entropy calculations.|$|R
2500|$|Two special {{data sets}} with missing <b>attribute</b> <b>values</b> were {{extensively}} studied: {{in the first}} case, all missing <b>attribute</b> <b>values</b> were lost (Stefanowski and Tsoukias, 2001), in the second case, all missing <b>attribute</b> <b>values</b> were [...] "do not care" [...] conditions (Kryszkiewicz, 1999).|$|R
30|$|The {{notion of}} {{critical}} pair expresses {{a notion of}} power: if an <b>attribute</b> <b>value</b> {{is the only one}} associated with a critical pair for a given decision, then only this <b>attribute</b> <b>value</b> can trigger that decision. Conversely, if there is no critical pair associated with an <b>attribute</b> <b>value</b> for a decision, then this <b>attribute</b> <b>value</b> will never be responsible for triggering that decision. We therefore introduce the notion of <b>attribute</b> <b>value</b> power, following the intuition behind Banzhaf Power Index, which measures the number of times a coalition of voters is responsible for swinging a vote across all possible configurations.|$|R
40|$|Abstract. An {{action is}} defined as {{controlling}} or changing some of <b>attribute</b> <b>values</b> in an information system to achieve desired result. An action reduct is the minimal set of <b>attribute</b> <b>values</b> distinguishing a favorable object from other objects. We use action reducts to formulate necessary actions. The action suggested by an action reduct induces changes of decision <b>attribute</b> <b>values</b> by changing the condition <b>attribute</b> <b>values</b> to the distinct patterns in action reducts...|$|R
30|$|The {{experiment}} is conducted under static network <b>attribute</b> <b>values</b> and dynamic network <b>attribute</b> <b>values.</b> The simulation code {{was written in}} Matlab.|$|R
50|$|Since the <b>{{attribute}}</b> <b>values</b> of one object {{may depend}} on the <b>attribute</b> <b>values</b> of related objects, the attribute generation process assigns values collectively.|$|R
40|$|Considering the {{different}} size of quantitative <b>attribute</b> <b>values</b> and categorical <b>attribute</b> <b>values</b> in databases, we present two quantitative association rules mining methods with privacy-preserving respectively, one bases on Boolean association rules, which {{is suitable for}} the smaller size of quantitative <b>attribute</b> <b>values</b> and categorical <b>attribute</b> <b>values</b> in databases; the other one bases on partially transforming measures, which is suitable for the larger ones. To each approach, the privacy and accuracy are analyzed, and the correctness and feasibility are proven by experiments. 1...|$|R
2500|$|In attribute-concept values {{interpretation}} of a missing <b>attribute</b> <b>value,</b> the missing <b>attribute</b> <b>value</b> may be replaced by any <b>value</b> of the <b>attribute</b> domain restricted to the concept to which the object with a missing <b>attribute</b> <b>value</b> belongs (Grzymala-Busse and Grzymala-Busse, 2007). [...] For example, if for a patient the <b>value</b> of an <b>attribute</b> Temperature is missing, this patient is sick with flu, and all remaining patients sick with flu have values high or very-high for [...] Temperature when using the {{interpretation of}} the missing <b>attribute</b> <b>value</b> as the [...] attribute-concept value, we will replace the missing <b>attribute</b> <b>value</b> with [...] high and very-high. [...] Additionally, the characteristic relation, (see, e.g., Grzymala-Busse and Grzymala-Busse, 2007) enables to process data sets with all three kind of missing <b>attribute</b> <b>values</b> at the same time: lost, [...] "do not care" [...] conditions, and attribute-concept values.|$|R
30|$|The local spatial {{autocorrelation}} analysis {{compensates for}} {{the limitation of}} the Moran’s I value not describing the pattern of spatial correlation of regional elements as a whole. This paper uses the Moran scatter plot to further examine the local spatial characteristics of the minority population density in China. The Moran scatter plot is divided into four quadrants: HH (high <b>attribute</b> <b>values</b> of a certain region and its surrounding regions), LH (low <b>attribute</b> <b>value</b> of a certain region and high <b>attribute</b> <b>values</b> of the surrounding regions), LL (low <b>attribute</b> <b>values</b> of a certain region and its surrounding regions), and HL (high <b>attribute</b> <b>value</b> of a certain region and low <b>attribute</b> <b>values</b> of the surrounding regions). Among them, quadrants HH and LL are spatially positively correlated, indicating strong homogeneity while quadrants LH and HL are negatively correlated, indicating strong heterogeneity.|$|R
5000|$|In attribute-concept values {{interpretation}} of a missing <b>attribute</b> <b>value,</b> the missing <b>attribute</b> <b>value</b> may be replaced by any <b>value</b> of the <b>attribute</b> domain restricted to the concept to which the object with a missing <b>attribute</b> <b>value</b> belongs (Grzymala-Busse and Grzymala-Busse, 2007). For example, if for a patient the <b>value</b> of an <b>attribute</b> Temperature is missing, this patient is sick with flu, and all remaining patients sick with flu have values high or very-high for Temperature when using the {{interpretation of}} the missing <b>attribute</b> <b>value</b> as the attribute-concept value, we will replace the missing <b>attribute</b> <b>value</b> with high and very-high. Additionally, the characteristic relation, (see, e.g., Grzymala-Busse and Grzymala-Busse, 2007) enables to process data sets with all three kind of missing <b>attribute</b> <b>values</b> at the same time: lost, [...] "do not care" [...] conditions, and attribute-concept values.|$|R
30|$|We {{introduce}} {{the notion of}} <b>attribute</b> <b>value</b> power {{to determine how much}} an <b>attribute</b> <b>value</b> is capable of triggering a specific decision (“Attribute power” section).|$|R
40|$|In this paper, a new {{approach}} to working with missing <b>attribute</b> <b>values</b> in inductive learning algorithms is introduced. Three fundamental issues are studied: the splitting criterion, the allocation of <b>values</b> to missing <b>attribute</b> <b>values,</b> and the prediction of new observations. The formal definition for the splitting criterion is given. This definition takes into account the missing <b>attribute</b> <b>values</b> and generalizes the classical definition. In relation to the second objective, multiple values are assigned to missing <b>attribute</b> <b>values</b> using a decision theory approach. Each of these multiple values will have an associated confidence and error parameter. The error parameter measures how near or how far the value is from the original <b>value</b> of the <b>attribute.</b> After applying a splitting criterion, a decision tree is obtained (from training sets with or without missing <b>attribute</b> <b>values).</b> This decision tree can be used to predict the class of an observation (with or without missing <b>attribute</b> <b>values).</b> Hence, there are four perspectives. The three perspectives with missing <b>attribute</b> <b>values</b> are studied and experimental results are presented...|$|R
30|$|From n objects {{calculate}} a point whose <b>attribute</b> <b>value</b> is {{an average}} of n-objects <b>attributes</b> <b>values.</b> Therefore, the first initial centroid is the average on n-objects.|$|R
30|$|Find {{the weakest}} <b>attribute</b> <b>value</b> (min) of each {{alternative}} and then choose the alternative {{with the best}} (max) weakest <b>attribute</b> <b>value.</b> The logic is that a chain is as strong as its weakest link. This method is applicable only when <b>attribute</b> <b>values</b> are comparable with one another, either measured in the same unit or transformed to a common scale.|$|R
40|$|AbstractIn {{this paper}} we propose a method of extracting rules in Incomplete Information System based on an {{irregular}} decision table. Need not to make estimation of missing <b>attribute</b> <b>value,</b> we get the rule set contains no missing <b>attribute</b> <b>value.</b> The experiment justify, the accuracy of obtained rule set is almost same with the highest accuracy among those of the estimating missing <b>attribute</b> <b>value</b> methods...|$|R
30|$|In this section, we will {{evaluate}} and make statistics {{of the network}} selection with the above six algorithms in context of the dynamically changing network <b>attribute</b> <b>values.</b> As shown in Table  18 in Section 4.1, each network <b>attribute</b> <b>value</b> will dynamically change between the lowest value and the highest value with the rank in the bracket. In addition, the number of <b>attribute</b> <b>value</b> changes in the experiment is 1000 times.|$|R
40|$|Weight {{aggregation}} is the {{key process}} to solve a multiple-attribute group decision-making (MAGDM) problem. This paper is trying to propose a possible approach to objectivize subjective information and to aggregate information from <b>attribute</b> <b>values</b> themselves and decision-makers’ judgment. An MAGDM problem without information about decision-makers’ and attributes’ weight is considered. In order to define decision-makers’ subjective preference, their utility function is introduced. The <b>attributes</b> <b>value</b> matrix is converted into a subjective <b>attributes</b> <b>value</b> matrix based on their subjective judgment on <b>attribute</b> <b>values.</b> By utilizing the entropy weighting technique, decision-maker’s subjective weight on attributes and objective weight on attributes are determined individually based on the subjective <b>attributes</b> <b>value</b> matrix and <b>attributes</b> <b>value</b> matrix. Based {{on the principle of}} minimum cross-entropy, all decision-makers’ subjective weights are integrated into a single weight vector that is closest to all decision-makers’ judgment without any extra information added. Then, by applying the principle of minimum cross-entropy again, a weight aggregation method is proposed to combine the subjective and objective weight of attributes. Finally, an MAGDM example of project choosing is presented to illustrate the procedure of the proposed method...|$|R
40|$|We {{propose a}} novel {{extraction}} approach that exploits content redundancy {{on the web}} to extract structured data from template-based web sites. We start by populating a seed database with records extracted from a few initial sites. We then identify values within the pages of each new site that match <b>attribute</b> <b>values</b> contained in the seed set of records. To match <b>attribute</b> <b>values</b> with diverse representations across sites, we define a new similarity metric that leverages the templatized structure of attribute content. Specifically, our metric discovers the matching pattern between <b>attribute</b> <b>values</b> from two sites, and uses this to ignore extraneous portions of <b>attribute</b> <b>values</b> when computing similarity scores. Further, to filter out noisy <b>attribute</b> <b>value</b> matches, we exploit the fact that <b>attribute</b> <b>values</b> occur at fixed positions within template-based sites. We develop an efficient Apriori-style algorithm to systematically enumerate attribute position configurations with sufficient matching values across pages. Finally, we conduct an extensive experimental study with real-life web data to demonstrate the effectiveness of our extraction approach. 1...|$|R
40|$|The {{effectiveness}} {{of using the}} semantic attributes of verbs {{has been shown in}} various kinds of natural processing systems, such as machine translation systems. The addition of an <b>attribute</b> <b>value</b> is, however, time-consuming and must be performed by hand by an expert on the <b>attribute</b> <b>value.</b> In this paper, two methods for efficiently adding verbal semantic attributes to a Japanese-to-English valency transfer dictionary in a machine translation system are proposed and evaluated. One method involves a professional analyst mentally writing down decision-tree-like rules from process images when adding an <b>attribute</b> <b>value</b> to each dictionary entry. The other method involves automatically extracting a decision tree for adding <b>attribute</b> <b>values</b> from dictionary entries with semantic <b>attribute</b> <b>values</b> within a transfer dictionary using the decision tree learning program C 5. 0. We examine the key factors contributing towards the identification of an <b>attribute</b> <b>value</b> in the entries of the transfer dictionary. The proposed method is also applicable for adding semantic attributes effectively for dictionary entries of a bilingual dictionary within a machine translation system. ...|$|R
40|$|In a {{previous}} paper {{three types of}} missing <b>attribute</b> values: lost <b>values,</b> attribute-concept values and “do not care ” conditions were compared using six data sets. Since previous experimental results were affected by large variances due to con-ducting experiments on different versions of a given data set, we conducted new experiments, using {{the same pattern of}} missing <b>attribute</b> <b>values</b> for all three types of missing <b>attribute</b> <b>values</b> and for both certain and possible rules. Additionally, in our new experiments, the process of incremental replacing specified <b>values</b> by missing <b>attribute</b> <b>values</b> was terminated when entire rows of the data sets were full of missing <b>attribute</b> <b>values.</b> Finally, we created new, incomplete data sets by replacing the specified values starting from 5 % of all <b>attribute</b> <b>values,</b> instead of 10 % as in the previous experiments, with an increment of 5 % instead of the previous increment of 10 %. As a result, it is becoming more clear that the best approach to missing <b>attribute</b> <b>values</b> is based on lost values, with small difference between certain and possible rules, and that the worst approach is based on “do not care ” conditions, certain rules. With our improved experimental setup it is also more clear that for a given data set the type of the missing <b>attribute</b> <b>values</b> should be selected individually. ...|$|R
5000|$|URI <b>attribute</b> <b>value</b> [...] - [...] In {{versions}} {{prior to}} Opera 9, all URI <b>attribute</b> <b>values</b> are resolved to full URI. Hence the value from [...] and [...] {{could be wrong}} if relative URIs are used.|$|R
40|$|Entity <b>attribute</b> <b>values,</b> such as “lord of {{the rings}} ” for movie. title or “infant ” for shoe. gender, are atomic {{components}} of entity ex-pressions. Discovering alternative surface forms of <b>attribute</b> <b>values</b> is important for improving entity recognition and retrieval. In this work, we propose a novel compact clustering framework to jointly identify synonyms {{for a set of}} <b>attribute</b> <b>values.</b> The framework can integrate signals frommultiple information sources into a similarity function between <b>attribute</b> <b>values.</b> And the weights of these signals are optimized in an unsupervised manner. Extensive experiments across multiple domains demonstrate the effectiveness of our clus-tering framework for mining entity attribute synonyms. 1...|$|R
50|$|In {{addition}} to basic identity <b>attribute</b> <b>values</b> like strings and numbers, the data entity {{referred to by}} an r-card can have complex <b>attribute</b> <b>values</b> consisting of aggregates of basic attribute types as well as UDI links to other entities.|$|R
40|$|The chief {{hindrance}} to {{the widespread}} adoption of attribute-grammar-based systems {{has been that}} they are profligate consumers of storage. This paper concerns new storage management techniques that {{reduce the amount of}} storage used by reducing the number of <b>attribute</b> <b>values</b> retained at any stage of attribute evaluation; it presents one algorithm for evaluating an n-attribute tree that never retains more than O(√(n)) <b>attribute</b> <b>values,</b> and it presents a second algorithm that never retains more than O(n) <b>attribute</b> <b>values...</b>|$|R
40|$|We propose Oblivious Attribute Certificates (OACerts), an {{attribute}} certificate scheme {{in which a}} certificate holder can select which attributes to use {{and how to use}} them. In particular, a user can use <b>attribute</b> <b>values</b> stored in an OACert obliviously, i. e., the user obtains a service if and only if the <b>attribute</b> <b>values</b> satisfy the policy of the service provider, yet the service provider learns nothing about these <b>attribute</b> <b>values.</b> This way, the service provider’s access control policy is enforced in an oblivious fashion. To enable the oblivious access control using OACerts, we propose a new cryptographic primitive called Oblivious Commitment-Based Envelope (OCBE). In an OCBE scheme, Bob has an <b>attribute</b> <b>value</b> committed to Alice and Alice runs a protocol with Bob to send an envelope (encrypted message) to Bob such that: (1) Bob can open the envelope if and only if his committed <b>attribute</b> <b>value</b> satisfies a predicate chosen by Alice, (2) Alice learns nothing about Bob’s <b>attribute</b> <b>value.</b> We develop provably secure and efficient OCBE protocols for the Pedersen commitment scheme and predicates such as =, ≥, ≤,>, <, ̸ = as well as logical combinations of them...|$|R
40|$|Abstract: Traditionally, {{similarity}} between two objects is calculated {{by using only}} their <b>attribute</b> <b>values,</b> such as number of coincided attributes, Euclid distance, etc. A new concept of similarity dealing with a uniqueness measure is proposed in this paper by which the {{similarity between}} two objects is not only considered using their <b>attribute</b> <b>values,</b> but also a subset of objects as an important parameter. Here, the subset of objects may be regarded as knowledge of human. In this concept of similarity, if <b>attribute</b> <b>values</b> of two objects are rare in the subset, and their <b>attribute</b> <b>values</b> are the same, then their degree of similarity is high. On the other hand, if the <b>attribute</b> <b>values</b> of two objects are not rare in the subset, and their <b>attribute</b> <b>values</b> are the same, then their degree of similarity is low. Consequently, the degree of similarity between two objects will be changed depending on the subset of objects. Moreover, we discuss mathematical properties {{of the concept of}} similarity dealing with uniqueness measure. Finally, we discuss differences between the concept of similarity based on uniqueness measure and traditional similarity using some examples...|$|R
40|$|Finding all closed {{frequent}} itemsets {{is a key}} step {{of association}} rule mining since the non-redundant association rule can be inferred from all the closed frequent itemsets. In this paper we present a new method for finding closed frequent itemsets based on <b>attribute</b> <b>value</b> lattice. In the new method, we argue that vertical data representation and <b>attribute</b> <b>value</b> lattice can find all closed frequent itemsets efficiently, thus greatly improve the efficiency of association rule mining algorithm. We discuss how these techniques and methods are applied to find closed frequent itemsets. In our method, the data are represented vertically; each frequent <b>attribute</b> <b>value</b> is associated with its granule, which is represented as a hybrid bitmap. Based on the partial order defined between the <b>attribute</b> <b>values</b> among the databases, an <b>attribute</b> <b>value</b> lattice is constructed, which is much smaller compared with the original databases. Instead of searching all {{the items in the}} databases, which is adopted by almost all the association rule algorithms to find frequent itemsets, our method only searches the attribute-value lattice. A bottom-up breadth-first approach is employed to search the <b>attribute</b> <b>value</b> lattice to find the closed frequent itemsets...|$|R
40|$|The {{possibility}} that an unauthorised agent {{is able to}} infer a user’s hidden information (an <b>attribute’s</b> <b>value)</b> is known as attribute inference risk. It {{is one of the}} privacy issues for Facebook users in recent times. An existing technique [1] provides privacy by suppressing users’ <b>attribute</b> <b>values</b> from their profiles. However, suppression of an <b>attribute</b> <b>value</b> sometimes is not enough to secure a user’s confidential information. In this paper, we experimentally demonstrate that (after taking necessary steps on <b>attribute</b> <b>values)</b> a user’s sensitive information can still be inferred through his/her friendship information. We evaluated our approach experimentally on two datasets. We propose 3 LP, a new three layers protection technique, to provide privacy protection to users of on-line social networks. No Full Tex...|$|R
40|$|The MINERVA {{project is}} a {{distributed}} search engine prototype based on a Peer-to-Peer architecture. The MINERVA provides a functionality to search for documents from the selected top-k peers who have the most possibility to contain documents corresponding to the user specified query. In some cases, users may want to know information about the document such as bibliographic information or user recommendation {{in order to justify}} the value of the document before they really reach the document. In this thesis, we study about extending the MINERVA system to support the bibliographic information search or recommendation search in the shape of <b>attribute</b> <b>value</b> based search. In our design, we specify each bibliographic information entry or recommendation entry as an <b>attribute</b> <b>value</b> of the document. We propose three designs to modify the system’s global directory to support <b>attribute</b> <b>value</b> based search. We also implement the other extension parts of the application such as document database as well as new GUI to support new features. In our extended MINERVA system, users are allowed to search for documents from the bibliographic information, recommendation, or any <b>attribute</b> <b>values.</b> Users are allowed to retrieve <b>attribute</b> <b>values</b> corresponding to the specific document, and also allowed to insert and distribute the bibliographic information, recommendations or any <b>attribute</b> <b>value</b> to documents...|$|R
40|$|We {{present a}} theory of {{decision}} by sampling (DbS) in which, in contrast with traditional models, there are no underlying psychoeconomic scales. Instead, we assume that an <b>attribute’s</b> subjective <b>value</b> is constructed {{from a series of}} binary, ordinal comparisons to a sample of <b>attribute</b> <b>values</b> drawn from memory and is its rank within the sample. We assume that the sample reflects both the immediate distribution of <b>attribute</b> <b>values</b> from the current decision’s context and also the background, real-world distribution of <b>attribute</b> <b>values.</b> DbS accounts for concave utility functions; losses looming larger than gains; hyperbolic temporal discounting; and the overestimation of small probabilities and the underestimation of large probabilities. ...|$|R
50|$|C4.5 improved: {{discrete}} {{and continuous}} <b>attributes,</b> missing <b>attribute</b> <b>values,</b> <b>attributes</b> with differing costs, pruning trees (replacing irrelevant branches with leaf nodes).|$|R
5000|$|Generate <b>attribute</b> <b>values</b> {{based on}} user-supplied prior probabilities.|$|R
40|$|Abstract: Fuzzy Realational Databases (FRDB) allow atribute {{values to}} be fuzzy sets. In the {{application}} {{developed by the}} author, <b>attribute</b> <b>values</b> can be intervals, triangular fuzzy numbers and linguistic labels. In this paper we present the algorithms for calculating these values when they appear in queries and <b>attribute</b> <b>values...</b>|$|R
40|$|Part 2 : Security and Privacy in Social Applications and Cyber Attacks DefenseInternational audienceThe {{possibility}} that an unauthorised agent {{is able to}} infer a user’s hidden information (an <b>attribute’s</b> <b>value)</b> is known as attribute inference risk. It {{is one of the}} privacy issues for Facebook users in recent times. An existing technique [1] provides privacy by suppressing users’ <b>attribute</b> <b>values</b> from their profiles. However, suppression of an <b>attribute</b> <b>value</b> sometimes is not enough to secure a user’s confidential information. In this paper, we experimentally demonstrate that (after taking necessary steps on <b>attribute</b> <b>values)</b> a user’s sensitive information can still be inferred through his/her friendship information. We evaluated our approach experimentally on two datasets. We propose 3 LP, a new three layers protection technique, to provide privacy protection to users of on-line social networks...|$|R
40|$|We {{consider}} cost-sensitive <b>attribute</b> <b>value</b> acquisition {{in classification}} problems, where missing <b>attribute</b> <b>values</b> in test instances can be acquired at some cost. We examine {{this problem in}} the context of the support vector machine, employing a generic, iterative framework that aims to minimize both acquisition and misclassification costs. Under this framework, we propose an <b>attribute</b> <b>value</b> acquisition algorithm that is driven by the expected cost savings of acquisitions, and for this we propose a method for estimating the misclassification costs of a test instance before and after acquiring one or more missing <b>attribute</b> <b>values.</b> In contrast to previous solutions, we show that our proposed solutions generalize to support vector machines that use arbitrary kernels. We conclude with a set of experiments that show the effectiveness of our proposed algorithm. ...|$|R
