115|2350|Public
5000|$|The [...] "too-puddly" [...] song is {{actually}} an antiphonal duet. That means that one bird out of the pair sings the first note, then the other bird in the pair sings the second note. To bystanders, this does not sound like it comes from two different birds. It has distinct sexual duet roles after a greeting ceremony and the partner's notes do differ. The birds do not sing simultaneously, but are synchronized in their duets. The time between when one bird stops singing to when the other bird in the pair picks the song up is called the <b>auditory</b> <b>response</b> time for the duet. The approximate <b>auditory</b> <b>response</b> time for this bird is 178 ms.|$|E
50|$|Typically, {{testing is}} first done to {{determine}} the quality of hearing. This can be done as early as {{in the first two}} weeks with a BAER test (Brain Stem <b>Auditory</b> <b>Response</b> Test). At age 5-6, CT or CAT scans of the middle ear can be done to elucidate its development and clarify which patients are appropriate candidates for surgery to improve hearing. For younger individuals, this is done under sedation.|$|E
5000|$|Generally, the barbets in the duet will bow ceremoniously to {{each other}} while singing. In {{addition}} to bowing, certain African barbet species, like Lybius vieilloti and Lybius torquatus, will incorporate a snarl into their duet. The snarl might actually be how the duets are initiated in this species. When duetting, each bird {{will pick up the}} song from where the other bird left off. The time interval between when one bird ends the duet and when the other bird begins the song again is called the [...] "auditory response time". Basically, the <b>auditory</b> <b>response</b> time is the minimum time required for the barbet to hear the notes and respond to them.|$|E
40|$|AbstractWe {{examined}} {{the frame of}} reference of <b>auditory</b> <b>responses</b> in the inferior colliculus in monkeys fixating visual stimuli at different locations. Eye position modulated the level of <b>auditory</b> <b>responses</b> in 33 % of the neurons we encountered, {{but it did not}} appear to shift their spatial tuning. The effect of eye position on <b>auditory</b> <b>responses</b> was substantial—comparable in magnitude to that of sound location. The eye position signal appeared to interact with the <b>auditory</b> <b>responses</b> in at least a partly multiplicative fashion. We conclude that the representation of sound location in primate IC is distributed and that the frame of reference is intermediate between head- and eye-centered coordinates. The information contained in these neurons appears to be sufficient for later neural stages to calculate the positions of sounds with respect to the eyes...|$|R
40|$|We {{report a}} low cost mobile EEG system for characterizing {{cortical}} <b>auditory</b> <b>responses.</b> The system is built using commercial off-the-shelf components and each unit {{costs less than}} $ 200. It measures seven EEG channels plus one audio channel (envelope only), and communicates the data to external devices via Bluetooth. A novel implementation was pursued {{in order to support}} local signal compression using compressed sensing. At the same time, it provides a low cost solution that is useful for recording cortical <b>auditory</b> <b>responses</b> and extracting clinically relevant features of the waveform. This system has been designed with the eventual goal of long term monitoring of the brain activity of schizophrenic patients outside a clinical setting, in order to better understand auditory hallucinations and manage their ongoing treatment. In this preliminary study we obtained simultaneous audio and cortical recordings of evoked <b>auditory</b> <b>responses</b> from normal healthy subjects wearing the EEG for several hours in duration. We report evoked <b>auditory</b> <b>responses</b> for 2 Hz and 40 Hz click trains. We also report alpha wave responses, demonstrating stable and high quality recordings over a five hour period...|$|R
50|$|Katz, L.C., and Gurney, M.E. (1981). <b>Auditory</b> <b>responses</b> in {{the zebra}} finch’s motor system for song. Brain Res. 221, 192-97.|$|R
5000|$|After hatching, {{the male}} kill rate rises to one kill every 1.5 days. Pair {{behavior}} while raising chicks is very variable, some males are very attentive to their young, while others leave virtually all brooding to the female. After 40 days of age, the young {{is capable of}} feeding itself, though is often still fed. The first feathers through the white down emerge when the crowned eagle chick is 40 days old, with the feathers ultimately covering the down in 76 days. After 76 days, the main feather development is in the tail or the wings. Wing flapping begins at 45 to 50 days, increasing after around 75 days. The young fledge at 90 to 115 days, with an average 110.6 days and any period of time less than 100 days is considered unusually soon. On average, male chicks {{tend to be more}} active wing-flappers and usually will first fly around 10 days earlier than female chicks. After fledging, females are attentive 95% of the day and brood 50-75% of the day, the amount decreasing slightly with each day. The female does much of the prey capture and a majority of the nest defense after the young fledge. After fledging, the young remain in the neighborhood of the parent's nest and are fed every 3 to 5 days by either parent for their first 270-350 days of life. The rate of food-delivery varies from several times a day to every 3 days on average during the post-fledging period. The fledged juvenile will solicit adults (apparently even unrelated adults) for food but does not actually take the prey unless this occurs around the nest site. The first recorded kill for a young crowned occurred 61 days after fledging, although this is considered exceptionally early by the standards of this species. Flights increase incrementally through the post-fledging period, although the young do not engage in rising flights until they are fully independent. Independence appears to be triggered by the increased indifference of parents to bringing food. Due to the loud vocal interplay between the parents and the fledging eagle, the adults seem to take it as a sign that their offspring has sought independence if they return to the nesting area and hear no begging <b>auditory</b> <b>response.</b> The young eagle usually remains in the care of its parents for a total of up to 11 months after it fledges, longer than is known in almost any other raptor. The advantage of this prolonged stretch to independence is that it may make for a stronger young eagle when compared to other accipitrids which have almost no post-fledging dependency period. In 34 possible cases, 18 resulted in eggs being laid. Fledging success is approximately 83% and almost all young that leave the nest also reach independence. [...] It is estimated that most crowned eagles will reach breeding maturity at around five years old, as is typical for other large eagle species.|$|E
30|$|Slow {{auditory}} {{reaction time}} {{is associated with}} a decrease in correct <b>auditory</b> <b>response</b> and <b>auditory</b> <b>response</b> inhibition, and an increase in unintended <b>auditory</b> <b>response.</b>|$|E
40|$|Many {{authors have}} used the Auditory Evoked Potential (AEP) {{recordings}} to evaluate {{the performance of their}} ICA algorithms and have demonstrated that this procedure can remove the typical EEG artifact in these recordings (i. e. blinking, muscle noise, line noise, etc.). However, there is little work in the literature about the optimal parameters, for each of those algorithms, for the estimation of the AEP components to reliably recover both the <b>auditory</b> <b>response</b> and the specific artifacts generated for the normal function of a Cochlear Implant (CI), used for the rehabilitation of deaf people. In this work we determine the optimal parameters of three ICA algorithms, each based on different independence criteria, and assess the resulting estimations of both the <b>auditory</b> <b>response</b> and CI artifact. We show that the algorithm utilizing temporal structure, such as TDSEP-ICA, is better in estimating the components of the <b>auditory</b> <b>response,</b> in recordings contaminated by CI artifacts, than higher order statistics based algorithms...|$|E
5000|$|Schmidt, M. and Konishi, M. (1998) Gating of <b>auditory</b> <b>responses</b> in {{the vocal}} control system of awake songbirds. Nature Neurosci. 1:513-518.|$|R
50|$|Bone-conduction <b>auditory</b> {{brainstem}} <b>response</b> or BCABR {{is a type}} of <b>auditory</b> evoked <b>response</b> that records {{neural response}} from EEG with stimulus transmitted through bone conduction.|$|R
40|$|It is {{well known}} that visual {{information}} can affect auditory perception, as in the famous “McGurk effect,” but little is known concerning the processes involved. To address this issue, we used the best-developed animal model to study language-related processes in the brain: songbirds. European starlings were exposed to audiovisual compared to auditory-only playback of conspecific songs, while electrophysiological recordings were made in their primary auditory area (Field L). The results show that the audiovisual condition modulated the <b>auditory</b> <b>responses.</b> Enhancement and suppression were both observed, depending on the stimulus familiarity. Seeing a familiar bird led to suppressed <b>auditory</b> <b>responses</b> while seeing an unfamiliar bird led to response enhancement, suggesting that unisensory perception may be enough if the stimulus is familiar while redundancy may be required for unfamiliar items. This is to our knowledge the first evidence that multisensory integration may occur in a low-level, putatively unisensory area of a non-mammalian vertebrate brain, and also that familiarity of the stimuli may influence modulation of <b>auditory</b> <b>responses</b> by vision...|$|R
40|$|Speech {{production}} {{is one of}} the most complex motor skills, and involves close interaction between the perceptual and the motor system. Recently, prediction via forward models has been at the forefront of speech neuroscience research. For example, neuroimaging evidence has demonstrated that activation of the auditory cortex is suppressed to self-produced speech relative to listening without speaking. This finding has been explained via a forward model that predicts the auditory consequences of our own speech actions. An accurate prediction cancels out (part of) the auditory cortical activation. The present study was designed to test two critical predictions from these frameworks: First, whether the cortical <b>auditory</b> <b>response</b> during speech production varies as a function of the acoustic distance between feedback and prediction, and second, whether this in turn is predictive of the amount of adaptation in people’s speech production. MEG was recorded while subjects performed an online speech imitation task. Each subject heard and imitated Dutch vowels, varying in their distance from the original vowel in both F 1 and F 2. The results did not show clear evidence that the amount of suppression scaled with the distance between participants’ speech and the speech target. However, we found that subjects’ <b>auditory</b> <b>response</b> did correlate with imitation performance. This result supports the view that an enhanced <b>auditory</b> <b>response</b> may act as an error signal, driving subsequent speech adaptation. This suggests that individual differences in SIS could act as a marker for subsequent adaptation...|$|E
40|$|We {{investigated}} the feasibility {{and cost of}} screening all neonates for hearing loss using the <b>auditory</b> <b>response</b> cradle (ARC). At least three full time staff are needed to screen 95 % of the 3000 infants delivered each year including those in intensive care. Estimated costs per case detected are between pounds 3000 and pounds 6000 but true costs may be higher...|$|E
40|$|Echolocation {{calls and}} neurophysiological {{correlations}} with <b>auditory</b> <b>response</b> {{properties in the}} inferior colliculus of Pipistrellus abramus (Microchiroptera: Vespertilionidae). Zoological Studies 46 (4) : xxx-xxx. The present study examines the echolocation calls and auditory responses of single neurons in the inferior colliculus (IC) of Pipistrellus abramus (Microchiroptera: Vespertilionidae). The data showed {{that there was a}} neurophysiological correlation of the <b>auditory</b> <b>response</b> properties with echolocation calls in IC neurons. The echolocation calls of P. abramus were broad-band swept from 86. 6 to 43. 2 kHz. The ending frequencies of the 1 st harmonics which centered around 40 (average, 43. 2; range, 37. 0 - 47. 0) kHz, were relatively more stable than the initial high frequencies. The average peak frequency was 52. 1 (range, 43. 3 - 57. 6) kHz of which the majority (81 %, 154 of 190 calls) ranged from 50. 1 to 60 kHz. We recorded the responses of 75 single IC neurons to pure tones. Most IC neurons had the best frequency (BF) at between 3...|$|E
40|$|To {{investigate}} {{the value of}} the <b>auditory</b> brainstem <b>response</b> as a reliable test for the neurologic prognosis of infants with neonatal indirect hyperbilirubinemia, <b>auditory</b> brainstem <b>response</b> studies were performed in 22 infants. The patients were followed up until 12 months of age. Two patients demonstrated pathologic <b>auditory</b> brainstem <b>response</b> consistent with <b>auditory</b> neuropathy but had no neurologic finding except a lack of speech at 12 months of age. Two other patients had neurologic sequelae, one showing severe dyskinetic cerebral palsy, the other mild hypotonia and motor retardation, but their <b>auditory</b> brainstem <b>response</b> results were nor-mal. These results suggested that <b>auditory</b> brainstem <b>response</b> examination might not provide reliable information for the neu-rologic prognosis. Neurologic disturbances resulting from biliru-bin neurotoxicity can be seen in patients with a normal <b>auditory</b> brainstem <b>response,</b> but patients with an abnormal <b>auditory</b> brain-stem <b>response</b> may not have any neurologic dysfunction apart from speech retardation. (J Child NeuroL 2001; 16 : 772 - 775). Neonatal indirect hyperbilirubinemia is still an important medical problem because of the risk of neurotoxicity. 1, 2 The diagnosis of neurologic dysfunction related to kernicterus is still based on the clinical findings. 1, 3, 1 Various degrees of hearing impairment with or without other neurologic sequelae can be seen in infants with postkernicteric encephalopathy. 11 The <b>auditory</b> brainstem <b>response</b> is a noninvasive and reliable method for evaluating the electrophysiologic functions of the sub-cortical auditory structures. 8 - 1 O Although {{the value of the}} <b>auditory</b> brainstem <b>response</b> in early diagnosis of auditory neuropathy in cases with neonatal indirect hyperbilirubinemia has been reported during the last 20 years, its predictive value to assess the neuro-logic prognosis is not yet clear. 1, 6, 8 - 11 1 This study was performed to {{investigate the}} prognostic value of the <b>auditory</b> brainstem <b>response</b> in the otherwise healthy term newborn with indirect hyperbilirubinemia The relationship between <b>auditory</b> brainstem <b>response</b> results and neurologic outcome was assessed...|$|R
25|$|Diagnosis is {{possible}} after a test battery, that must necessarily include the following: the <b>auditory</b> brainstem <b>response</b> and otoacoustic emissions. <b>Auditory</b> brainstem <b>response</b> {{should be tested}} with both polarities (helps in identifying cochlear microphonics).|$|R
40|$|The barn owl's central {{auditory}} system {{creates a}} map of auditory space in the external nucleus of the inferior colliculus (ICX). Although the crucial role visual experience plays in the formation and maintenance of this auditory space map is well established, the mechanism by which vision influences ICX responses remains unclear. Surprisingly, previous experiments have found that {{in the absence of}} extensive pharmacological manipulation, visual stimuli do not drive neural responses in the ICX. Here we investigated the influence of dynamic visual stimuli on <b>auditory</b> <b>responses</b> in the ICX. We show that a salient visual stimulus, when coincident with an auditory stimulus, can modulate <b>auditory</b> <b>responses</b> in the ICX even though the same visual stimulus may elicit no neural responses when presented alone. For each ICX neuron, the most effective auditory and visual stimuli were located in the same region of space. In addition, the magnitude of the visual modulation of <b>auditory</b> <b>responses</b> was dependent on the context of the stimulus presentation with novel visual stimuli eliciting consistently larger response modulations than frequently presented visual stimuli. Thus the visual modulation of ICX responses is dependent on the characteristics of the visual stimulus {{as well as on the}} spatial and temporal correspondence of the auditory and visual stimuli. These results demonstrate moment-to-moment visual enhancements of auditory responsiveness that, in the short-term, increase <b>auditory</b> <b>responses</b> to salient bimodal stimuli and in the long-term could serve to instruct the adaptive auditory plasticity necessary to maintain accurate auditory orienting behavior...|$|R
40|$|The {{sedative}} {{effects of}} i. m. administration {{of a low}} dose of romifidine were evaluated in 13 healthy adult Beagles. Physiological saline solution (0. 2 ml), 0. 1 % romifidine (10, 20, or 40 micro g/kg) or 10 % xylazine (1 mg/kg) was given i. m. in a crossover study design. Heart rate, respiratory rate, rectal temperature, haemoglobin saturation and scores for sedation, muscle relaxation, posture, <b>auditory</b> <b>response</b> and positioning response were recorded before and at regular intervals for up to 240 min after drug administration. Scores for sedation, muscle relaxation, posture, <b>auditory</b> <b>response</b> and positioning response increased in a dose-dependent manner after romifidine administration. Sedation induced by the highest dose of romifidine (40 micro g/kg) was comparable to that induced by xylazine (1 mg/kg). Heart rate, respiratory rate, and rectal temperature decreased in a dose-dependent manner after romifidine administration, but haemoglobin saturation did not change. It is concluded that romifidine (10, 20 or 40 micro g/kg, i. m.) is an effective sedative in dogs, but causes a decrease in heart rate, respiratory rate and rectal temperature. ...|$|E
40|$|The Linco-Bennett <b>auditory</b> <b>response</b> cradle is a {{microprocessor}} controlled device for screening the hearing of neonates. A total of 396 neonates {{admitted to a}} special care unit were tested on the cradle and later followed up in a comprehensive test programme {{between the ages of}} 3 months and 8 months. Altogether 374 (94 %) were available for follow up. The use of the cradle resulted in the detection of six neonates with appreciable deafness. One neonate who passed the cradle test has severe bilateral hearing impairment. The false alarm rate for neonates failing two tests on the cradle but having normal hearing at follow up was 4. 3 %. The <b>auditory</b> <b>response</b> cradle was designed for use in mass screening programmes but testing the hearing of all newborns would require many staff. It is argued that this is unrealistic when resources are scarce, but that neonates in high risk groups should have their hearing screened at birth by an objective test such as this. The cradle has considerable potential but its method of use and the 'decision making' programme could be improved...|$|E
40|$|A {{technique}} {{utilizing the}} frequency following response (FFR) (obtained by auditory stimulation, whereby the stimulus frequency and duration are mirror-imaged in the resulting brainwaves) as a clinical tool for hearing disorders in humans {{of all ages}} is presented. Various medical studies are discussed to support the clinical value of the technique. The discovery and origin of the FFR and another significant brainstem <b>auditory</b> <b>response</b> involved in studying the eighth nerve is also discussed...|$|E
40|$|OBJECTIVES:We {{evaluated}} the central auditory pathways in workers with noise-induced tinnitus with normal hearing thresholds, compared the <b>auditory</b> brainstem <b>response</b> results in groups {{with and without}} tinnitus and correlated the tinnitus location to the <b>auditory</b> brainstem <b>response</b> findings in individuals {{with a history of}} occupational noise exposure. METHOD:Sixty individuals participated in the study and the following procedures were performed: anamnesis, immittance measures, pure-tone air conduction thresholds at all frequencies between 0. 25 - 8 kHz and <b>auditory</b> brainstem <b>response.</b> RESULTS:The mean <b>auditory</b> brainstem <b>response</b> latencies were lower in the Control group than in the Tinnitus group, but {{no significant differences between the}} groups were observed. Qualitative analysis showed more alterations in the lower brainstem in the Tinnitus group. The strongest relationship between tinnitus location and <b>auditory</b> brainstem <b>response</b> alterations was detected in individuals with bilateral tinnitus and bilateral <b>auditory</b> brainstem <b>response</b> alterations compared with patients with unilateral alterations. CONCLUSION:Our findings suggest the occurrence of a possible dysfunction in the central auditory nervous system (brainstem) in individuals with noise-induced tinnitus and a normal hearing threshold...|$|R
40|$|International audienceIt is {{well known}} that visual {{information}} can affect auditory perception, as in the famous "McGurk effect," but little is known concerning the processes involved. To address this issue, we used the best-developed animal model to study language-related processes in the brain: songbirds. European starlings were exposed to audiovisual compared to auditory-only playback of conspecific songs, while electrophysiological recordings were made in their primary auditory area (Field L). The results show that the audiovisual condition modulated the <b>auditory</b> <b>responses.</b> Enhancement and suppression were both observed, depending on the stimulus familiarity. Seeing a familiar bird led to suppressed <b>auditory</b> <b>responses</b> while seeing an unfamiliar bird led to response enhancement, suggesting that unisensory perception may be enough if the stimulus is familiar while redundancy may be required for unfamiliar items. This is to our knowledge the first evidence that multisensory integration may occur in a low-level, putatively unisensory area of a non-mammalian vertebrate brain, and also that familiarity of the stimuli may influence modulation of <b>auditory</b> <b>responses</b> by vision...|$|R
40|$|The song nucleus high vocal center (HVC) sends neural signals for song {{production}} and receives auditory input. By using electroencephalography (EEG) to objectively identify wake/sleep state, {{we show that}} HVC <b>auditory</b> <b>responses</b> change with physiological states. Comparison of EEG and HVC records revealed that HVC <b>response</b> to <b>auditory</b> stimuli is greatest during slow-wave sleep. During slow-wave sleep, HVC neurons responded preferentially to the bird's own song. Strikingly, both spontaneous and forced waking during sleep caused HVC <b>auditory</b> <b>responses</b> to cease within milliseconds of an EEG-measured state change. State-dependent phenomena in downstream nuclei, such as robustus archistriatalis, {{are likely to be}} derivatives of those in HVC...|$|R
40|$|OBJETIVO: verificar a concordância entre os resultados da triagem auditiva por meio de observação de respostas comportamentais e de emissões otoacústicas evocadas transientes. MÉTODO: foi realizado estudo clínico duplo-cego com 139 crianças de um a 180 dias de vida, atendidas no serviço de Triagem Auditiva Neonatal do Hospital Universitário de Santa Maria. Diferentes examinadores verificaram a presença do reflexo cócleo-palpebral e de emissões otoacústicas evocadas transientes. RESULTADOS: das 139 crianças avaliadas, 123 apresentaram reflexo cócleo-palpebral e emissões otoacústicas; 10 apresentaram somente reflexo cócleo-palpebral; três apresentaram somente emissões otoacústicas; três não apresentaram respostas em ambos os testes. Dezesseis crianças deveriam ser retestadas. Nove não compareceram. Das sete crianças retestadas, duas passaram em ambos os testes e cinco mantiveram falha e foram encaminhadas para avaliação de Potencial Evocado Auditivo de Tronco Encefálico. Uma delas não compareceu. Duas crianças tiveram emissões otoacústicas presentes e reflexo cócleo-palpebral ausente. Na avaliação de Potencial Evocado Auditivo de Tronco Encefálico uma delas manifestou audição normal e outra perda auditiva profunda. Uma criança que não evidenciou emissões otoacústicas, mas manifestou reflexo cócleo-palpebral, teve Potencial Evocado Auditivo de Tronco Encefálico compatível com perda auditiva moderada {{bilateral}}. A criança que falhou em ambos os testes apresentou perda auditiva severa bilateral na avaliação de Potencial Evocado Auditivo de Tronco Encefálico. CONCLUSÃO: a presença de emissões otoacústicas concomitante com ausência de reflexo cócleo-palpebral pode ser sinal de neuropatia auditiva. A análise de emissões otoacústicas e a avaliação do reflexo cócleo-palpebral são procedimentos complementares. A aparente discordância entre alguns resultados pode apontar diferentes tipos de comprometimento auditivo. PURPOSE: {{to check}} the agreement among the obtained results in hearing screening through the observation of behavioral responses and the transient evoked otoacoustic emissions. METHOD: a double-blind study was carried out with 139 infants attended in Neonatal Hearing Screening service of Santa Maria University Hospital. Different examiners evaluated the presence of eye blink reflex and transient evoked otoacoustic emissions. RESULTS: among the 139 evaluated infants, 123 showed eye blink reflex and otoacoustic emissions; 10 showed only otoacoustic emissions; and 3 failed in both tests. Sixteen infants should be re-evaluated. Nine did not come back to repeat the tests. Seven children were re-evaluated, two passed in both tests; five maintained the failed status and they were referred to evaluation on <b>Auditory</b> <b>Response</b> Audiometry. Two children showed otoacoustic emissions, but did not have eye blink reflex. In the evaluation of <b>Auditory</b> <b>Response</b> Audiometry, one manifested normal hearing and the other showed acute hearing loss. One child who did not evidence otoacoustic emissions, but manifested eye blink reflex, had compatible <b>Auditory</b> <b>Response</b> Audiometry with moderate hearing loss in both ears. The infant who failed in both test showed severe bilateral hearing loss {{in the evaluation of}} <b>Auditory</b> <b>Response</b> Audiometry. CONCLUSION: even though the otoacoustic emissions are present, the absence of eye blink reflex should be considered a reason to evaluate the <b>Auditory</b> <b>Response</b> Audiometry, and this can be sign of auditory neuropathy. Considering that the analysis of otoacoustic emissions and the evaluation of eye blink reflex are complement procedures. The apparent disagreement among some results can show different types of hearing disorder...|$|E
40|$|The human <b>auditory</b> <b>response</b> to {{pulses of}} {{radiofrequency}} (RF) energy, commonly called RF hearing, {{is a well}} established phenomenon. RF induced sounds {{can be characterized as}} low intensity sounds because, in general, a quiet environment is required for the <b>auditory</b> <b>response.</b> The sound is similar to other common sounds such as a click, buzz, hiss, knock, or chirp. Effective radiofrequencies range from 2. 4 to 10 000 MHz, but an individual’s ability to hear RF induced sounds is dependent upon high frequency acoustic hearing in the kHz range above about 5 kHz. The site of conversion of RF energy to acoustic energy is within or peripheral to the cochlea, and once the cochlea is stimulated, the detection of RF induced sounds in humans and RF induced auditory responses in animals is similar to acoustic sound detection. The fundamental frequency of RF induced sounds is independent of the frequency of the radiowaves but dependent upon head dimensions. The <b>auditory</b> <b>response</b> {{has been shown to be}} dependent upon the energy in a single pulse and not on average power density. The weight of evidence of the results of human, animal, and modeling studies supports the thermoelastic expansion theory as the explanation for the RF hearing phenomenon. RF induced sounds involve the perception via bone conduction of thermally generated sound transients, that is, audible sounds are produced by rapid thermal expansion resulting from a calculated temperature rise of only 5 106 8 C in tissue at the threshold level due to absorption of the energy in the RF pulse. The hearing of RF induced sounds at exposure levels many orders of magnitude greater than the hearing threshold is considered to be a biological effect without an accompanying health effect. This conclusion is supported by a comparison of pressure induced in the body by RF pulses to pressure associated with hazardous acoustic energy and clinical ultrasound procedures. Bioelectromagnetics Supplement 6 :S 162 –S 173, 2003. 2003 Wiley-Liss, Inc. Key words: RF hearing; microwave; thermoelastic; auditory respons...|$|E
40|$|Noninvasive brain imaging technique •Great temporal resolu;on and no distor;on MEG Usage Ex. :  Transient <b>Auditory</b> <b>Response</b> •Evoked response about  100  ms aGer a beep •Evoked (phase locked)   response seen by {{averaging}} field over trials •Induced (not phase locked)   responses cannot be seen this way MoCvaCon and Focus •Develop techniques to discern neural ac;vity from MEG data •Iden;fy induced neural ac;vity through dipoles •Verify dipole,  localize dipole,  clean signal Data •Previously collected  70  trials of response to different s;muli (noise,  sentences,  amplitude modulated noise)   in two subject...|$|E
40|$|Publisher’s {{permission}} requested and denied. Extracranial <b>auditory</b> <b>responses</b> {{have been}} recorded from the parietal and temporal region in man and in cats. <b>Auditory</b> nerve <b>responses</b> have also been recorded from the external auditory meatus of man. In all cases summation of the responses by a digital computer was necessary for their detection. Restricted Access: This resource is not available from the Digital Repository for copyright reasons. This is a citation and abstract only record...|$|R
40|$|SUMMARY Nineteen {{infants with}} posthaemorrhagic {{ventricular}} dilatation had <b>auditory</b> brain stem <b>responses</b> measured {{during the period}} of maximal ventricular dilatation. These showed various patterns ranging from normal, through various abnormalities, to complete absence of <b>responses.</b> When serial <b>auditory</b> brain stem <b>responses</b> were studied in parallel with the evolution of posthaemorrhagic ventricular dilatation it was seen that the abnormalities of <b>auditory</b> brain stem <b>response</b> usually resolved irrespective of the persistence or progression of ventricular dilatation. No correlation was found between cerebrospinal fluid pressure and prolonged interpeak intervals on the <b>auditory</b> brain stem <b>response.</b> In three patients with posthaemorrhagic ventricular dilatation improvement in the <b>auditory</b> brain stem <b>response</b> occurred when cerebrospinal fluid was withdrawn. Intermittent withdrawal of cerebrospinal fluid (by ventricular tap or lumbar puncture) in two of these infants was followed by improvement in the <b>auditory</b> brain stem <b>response</b> after a period of 24 hours (but not sooner). In one infant born at full term improvement in the <b>auditory</b> brain stem <b>response</b> was noted one week after shunting. Disturbances in <b>auditory</b> brainstem <b>responses</b> have been reported in disorders associated with ventricu...|$|R
40|$|Objective : The {{purpose of}} this study was to {{investigate}} whether <b>auditory</b> steady-state <b>responses</b> would reveal characteristics indicative of acoustic neuroma in patients. Methods : Subjects were 42 unilateral acoustic neuroma patients with an average age of 55. 0 (± 13. 6) years. 　The control group consisted of 19 idiopathic sensorineural hearing loss patients with an average age of 42. 3 years (± 18. 8 years). Carrier frequencies used to obtain <b>auditory</b> steady-state <b>response</b> were 500, 1, 000, 2, 000 and 4, 000 Hz, respectively. The measured <b>auditory</b> steady-state <b>responses</b> thresholds were compared with hearing levels of the pure tone audiogram. Results : The <b>auditory</b> steady-state <b>response</b> threshold was somewhat greater (6 to 12 dB) than the pure-tone threshold that has been reported. Even higher thresholds were found in the acoustic neuroma group. In fact, when the subtracted values obtained by <b>auditory</b> steady-state <b>responses</b> threshold minus pure tone audiogram threshold of each frequency in each case were compared between the two groups, the acoustic neuroma group showed significantly greater values in all frequency regions. On the other hand, no differences were found in the values between the control and intact ear side. Conclusion : The presence of acoustic neuroma may lower the <b>auditory</b> steady-state <b>responses</b> threshold. This might reflect that the tumor could jitter in creating a <b>auditory</b> steady-state <b>responses...</b>|$|R
40|$|BACKGROUND: There is {{overlap between}} {{schizophrenia}} and bipolar disorder regarding genetic risk {{as well as}} neuropsychological and structural brain deficits. Finding common and distinct event-response potential (ERP) responses and connectivity patterns may offer potential biomarkers to distinguish the disorders. OBJECTIVE: To examine the neuronal <b>auditory</b> <b>response</b> elicited by a roving mismatch negativity (MMN) paradigm using magnetoencephalography (MEG). PARTICIPANTS: 15 Adolescents with schizophrenia (ASZ), 16 adolescents with bipolar disorder with psychosis (ABP), and 14 typically developing individuals (TD) METHODS: The data were analysed using time-series techniques and dynamic causal modelling (DCM). OUTCOME MEASURES: MEG difference wave (deviant - standard) at primary auditory (90 ms), MMN (180 ms) and long latency (300 ms). RESULTS: The amplitude of difference wave showed specific patterns at all latencies. Most notably, it was significantly reduced ABP compared to both controls and ASZ at early latencies. In contrast, the amplitude was significantly reduced in ASZ compared to both controls and ABP. The DCM analysis showed differential connectivity patterns in all three groups. Most notably, inter-hemispheric connections were strongly dominated by the right side in ASZ only. CONCLUSIONS: Dissociable patterns of the primary <b>auditory</b> <b>response</b> and MMN response indicate possible developmentally sensitive, but separate biomarkers for schizophrenia and bipolar disorder...|$|E
40|$|Background: Cortical neurons {{implement}} a high frequency-specific modulation of subcortical nuclei {{that includes the}} cochlear nucleus. Anatomical studies show that corticofugal fibers terminating in the auditory thalamus and midbrain are mostly ipsilateral. Differently, corticofugal fibers terminating in the cochlear nucleus are bilateral, which fits {{to the needs of}} binaural hearing that improves hearing quality. This leads to our hypothesis that corticofugal modulation of initial neural processing of sound information from the contralateral and ipsilateral ears could be equivalent or coordinated at the first sound processing level. Methodology/Principal Findings: With the focal electrical stimulation of the auditory cortex and single unit recording, this study examined corticofugal modulation of the ipsilateral cochlear nucleus. The same methods and procedures as described in our previous study of corticofugal modulation of contralateral cochlear nucleus were employed simply for comparison. We found that focal electrical stimulation of cortical neurons induced substantial changes in the response magnitude, response latency and receptive field of ipsilateral cochlear nucleus neurons. Cortical stimulation facilitated <b>auditory</b> <b>response</b> and shortened the response latency of physiologically matched neurons whereas it inhibited <b>auditory</b> <b>response</b> and lengthened the response latency of unmatched neurons. Finally, cortical stimulation shifted the best frequencies of cochlear neurons towards those of stimulated cortical neurons...|$|E
40|$|Background There is {{overlap between}} {{schizophrenia}} and bipolar disorder regarding genetic risk {{as well as}} neuropsychological and structural brain deficits. Finding common and distinct event-response potential (ERP) responses and connectivity patterns may offer potential biomarkers to distinguish the disorders. Objective To examine the neuronal <b>auditory</b> <b>response</b> elicited by a roving mismatch negativity (MMN) paradigm using magnetoencephalography (MEG) Participants 15 Adolescents with schizophrenia (ASZ), 16 adolescents with bipolar disorder with psychosis (ABP), and 14 typically developing individuals (TD). Methods The data were analysed using time-series techniques and dynamic causal modelling (DCM). Outcome measures MEG difference wave (deviant – standard) at primary auditory (~ 90 ms), MMN (~ 180 ms) and long latency (~ 300 ms). Results The amplitude of difference wave showed specific patterns at all latencies. Most notably, it was significantly reduced ABP compared to both controls and ASZ at early latencies. In contrast, the amplitude was significantly reduced in ASZ compared to both controls and ABP. The DCM analysis showed differential connectivity patterns in all three groups. Most notably, inter-hemispheric connections were strongly dominated by the right side in ASZ only. Conclusions Dissociable patterns of the primary <b>auditory</b> <b>response</b> andMMNresponse indicate possible developmentally sensitive, but separate biomarkers for schizophrenia and bipolar disorder. </p...|$|E
50|$|Visual {{auditory}} distance constancy - Researchers {{explored the}} relationship between visual and <b>auditory</b> <b>responses</b> and how they influence distance constancy. A study found that at a certain distance, when a sound is sensed, the eye is stimulated slightly before the ear is.|$|R
40|$|Sensory {{systems may}} adapt to {{behavioral}} requirements through state-dependent changes. In the forebrain song-system nucleus HVc of zebra finches, state-dependent <b>auditory</b> <b>responses</b> {{have been described}} in multiunit recordings. Here we report on behavioral state-dependent changes in the activity of distinct HVc neuronal classes. HVc projection neurons were identified by electrically stimulating HVc's target nuclei, the robust nucleus of the archistriatum and Area X, in anesthetized zebra finches. Projection neurons and two classes of putative interneurons could be distinguished {{on the basis of}} extracellular spike waveforms, with the first two factors of a principal components analysis accounting for 81 % of the variance in spike morphometric values. Spike width was the best single variable for distinguishing among the neuronal classes. Putative interneurons had much higher firing rates spontaneously and in response to song than did projection neurons, which had extremely low spontaneous rates and phasic responses to song. Recordings from HVc in behaving animals were dominated by the two classes of putative interneurons. Both classes showed strong, selective, and temporally similar <b>auditory</b> <b>responses</b> during sleep, but only one class of interneurons reliably maintained <b>auditory</b> <b>responses</b> on waking. These responses were weaker and less selective than those seen during sleep. The observation that HVc auditory responsiveness in awake zebra finches is restricted to some classes of neurons may help explain prior multiunit results that suggested nearly complete suppression of HVc <b>auditory</b> <b>responses</b> in awake birds. We propose that the heterogeneous effects of behavioral state on distinct subpopulations of HVc neurons allow HVc to participate in multiple roles during song production, conspecific song recognition, and possibly memory consolidation during sleep...|$|R
40|$|Using {{functional}} {{magnetic resonance}} imaging, {{we found that}} cortical visual motion area MT�/V 5 responded to auditory motion in two rare subjects who had been blind since early childhood and whose vision was partially recovered in adulthood. Visually normal control subjects did not show similar <b>auditory</b> <b>responses.</b> These <b>auditory</b> <b>responses</b> in MT � were specific to motion compared with other complex auditory stimuli including frequency sweeps and speech. Thus, MT � developed motion-specific responses to nonvisual input, suggesting that cross-modal plasticity can {{be influenced by the}} normal functional specialization of a cortical region. Regarding sight recovery after early blindness, our results further demonstrate that cross-modal responses coexist with regained visual responses within the visual cortex. Key words: multisensory; plasticity; blindness; motion; human; MT; V...|$|R
