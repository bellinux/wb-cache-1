47|31|Public
5|$|The Asus Xonar HDAV1.3 {{became the}} first HDMI sound card that {{implemented}} the Protected <b>Audio</b> <b>Path</b> and could both bitstream and decode lossless audio (Dolby TrueHD and DTS-HD MA), although bitstreaming is only available if using the ArcSoft TotalMedia Theatre software. It has an HDMI 1.3 input/output, and Asus says that it can work with most video cards on the market.|$|E
25|$|Signed {{drivers are}} {{required}} for usage of PUMA, PAP (Protected <b>Audio</b> <b>Path),</b> and PVP-OPM subsystems.|$|E
500|$|Even with an HDMI output, a {{computer}} {{may not be}} able to produce signals that implement HDCP, Microsoft's Protected Video Path, or Microsoft's Protected <b>Audio</b> <b>Path.</b> Several early graphic cards were labelled as [...] "HDCP-enabled" [...] but did not have the hardware needed for HDCP; this included some graphic cards based on the ATI X1600 chipset and certain models of the NVIDIA Geforce 7900 series. The first computer monitors that could process HDCP were released in 2005; by February 2006 a dozen different models had been released. The Protected Video Path was enabled in graphic cards that had HDCP capability, since it was required for output of Blu-ray Disc video. In comparison, the Protected <b>Audio</b> <b>Path</b> was required only if a lossless audio bitstream (such as Dolby TrueHD or DTS-HD MA) was output. Uncompressed LPCM audio, however, does not require a Protected <b>Audio</b> <b>Path,</b> and software programs such as PowerDVD and WinDVD can decode Dolby TrueHD and DTS-HD MA and output it as LPCM. A limitation is that if the computer does not implement a Protected <b>Audio</b> <b>Path,</b> the audio must be downsampled to 16-bit 48kHz but can still output at up to 8channels. No graphic cards were released in 2008 that implemented the Protected <b>Audio</b> <b>Path.</b>|$|E
50|$|Remote control {{consoles}} use {{audio level}} compression in transmit and receive <b>audio</b> <b>paths.</b>|$|R
2500|$|Soundcard {{to radio}} {{interfaces}} typically use isolation transformers {{on both the}} send and receive <b>audio</b> <b>paths</b> ...|$|R
5000|$|Play {{segments}} {{on different}} <b>audio</b> <b>paths,</b> so that effects or spatialization {{can be applied}} individually to each sound.|$|R
500|$|In September 2009, AMD {{announced}} the ATI Radeon HD 5000 series video cards, which have HDMI 1.3 output (deep color, xvYCC wide gamut capability and {{high bit rate}} audio), 8-channel LPCM over HDMI, and an integrated HD audio controller with a Protected <b>Audio</b> <b>Path</b> that allows bitstream output over HDMI for AAC, Dolby AC-3, Dolby TrueHD and DTS Master Audio formats. The ATI Radeon HD 5870 released in September 2009 is the first video card that allows bitstream output over HDMI for Dolby TrueHD and DTS-HD Master Audio. [...] The AMD Radeon HD 6000 Series implements HDMI 1.4a. The AMD Radeon HD 7000 Series implements HDMI 1.4b.|$|E
50|$|The <b>audio</b> <b>path</b> is disconnected, and {{the billing}} system {{registers}} a call stop record.|$|E
50|$|Electronic {{switching}} systems rendered black boxes obsolete, as no <b>audio</b> <b>path</b> was established until {{the call was}} answered. The infinity transmitter, an eavesdropping device which in its original design relied on an <b>audio</b> <b>path</b> to the target line remaining open before a call was answered or after it was hung up by the recipient, was similarly affected by the demise of mechanical switching.|$|E
50|$|A {{telephone}} hybrid is {{the component}} {{at the ends}} of a subscriber line of the public switched telephone network (PSTN) that converts between two-wire and four-wire forms of bidirectional <b>audio</b> <b>paths.</b> When used in broadcast facilities to enable the airing of telephone callers, the broadcast-quality telephone hybrid is known as a broadcast telephone hybrid or telephone balance unit.|$|R
50|$|Unlike the {{original}} Minimoog, the Voyager's modulation busses {{can be set}} to affect almost any parameter of the sound, not just the filters. Although the synthesizer features MIDI control and advanced patch storage, all <b>audio</b> <b>paths</b> in the Voyager are analog. The three oscillators are designed for high tuning stability, as {{the original}} Minimoog oscillators tended to slightly shift out of tune while playing.|$|R
50|$|CDF {{is a major}} user on the State of California, Department of General Services, Public Safety Microwave Network (PSMN). The {{network is}} used for the state's Green Phone {{telephone}} network, a telephone system used for communications between public safety agencies. The system primarily serves state agencies. Intercoms between ECCs use <b>audio</b> <b>paths</b> supported by microwave radio. These intercoms usually appear as circuits on communications consoles in dispatching centers.|$|R
5000|$|Even with an HDMI output, a {{computer}} {{may not be}} able to produce signals that implement HDCP, Microsoft's Protected Video Path, or Microsoft's Protected <b>Audio</b> <b>Path.</b> Several early graphic cards were labelled as [...] "HDCP-enabled" [...] but did not have the hardware needed for HDCP; this included some graphic cards based on the ATI X1600 chipset and certain models of the NVIDIA Geforce 7900 series. The first computer monitors that could process HDCP were released in 2005; by February 2006 a dozen different models had been released. The Protected Video Path was enabled in graphic cards that had HDCP capability, since it was required for output of Blu-ray Disc video. In comparison, the Protected <b>Audio</b> <b>Path</b> was required only if a lossless audio bitstream (such as Dolby TrueHD or DTS-HD MA) was output. Uncompressed LPCM audio, however, does not require a Protected <b>Audio</b> <b>Path,</b> and software programs such as PowerDVD and WinDVD can decode Dolby TrueHD and DTS-HD MA and output it as LPCM. A limitation is that if the computer does not implement a Protected <b>Audio</b> <b>Path,</b> the audio must be downsampled to 16-bit 48 kHz but can still output at up to 8 channels. No graphic cards were released in 2008 that implemented the Protected <b>Audio</b> <b>Path.</b>|$|E
5000|$|Signed {{drivers are}} {{required}} for usage of PUMA, PAP (Protected <b>Audio</b> <b>Path),</b> and PVP-OPM subsystems.|$|E
50|$|The <b>audio</b> <b>path</b> is connected, {{parties can}} talk, and the billing system {{registers}} a call start record.|$|E
50|$|Base {{stations}} can be local controlled or remote controlled. Local {{controlled base}} stations are operated by front panel {{controls on the}} base station cabinet. Remote control base stations can be operated over tone- or DC-remote circuits. The dispatch point console and remote base station are connected by leased private line telephone circuits, (sometimes called RTO circuits), a DS-1, or radio links. The consoles multiplex transmit commands onto remote control circuits. Some system configurations require duplex, or four wire, <b>audio</b> <b>paths</b> from the base station to the console. Others require only a two-wire or half duplex link.|$|R
50|$|Protected <b>Audio</b> Video <b>Path</b> (PAVP) {{protects the}} data path within a {{computer}} during video playback (e.g., Blu-ray discs). It {{is supported by}} newer chipsets (e.g. Intel G45) and operating systems (since Windows Vista).|$|R
50|$|Beginning with Sandy Bridge, the {{graphics}} processors include {{a form of}} digital copy protection and digital rights management (DRM) called Intel Insider, which allows decryption of protected media within the processor. Previously there was a similar technology called Protected <b>Audio</b> Video <b>Path</b> (PAVP).|$|R
50|$|Some systems where {{transmitter}} steering {{is employed}} may also require a separate <b>audio</b> <b>path</b> for transmit and receive, (four-wire circuits).|$|E
50|$|The final {{component}} in the <b>audio</b> <b>path</b> is a VCA. It can be driven by the envelope generator or a CV/Gate pulse.|$|E
50|$|The Prophet '08 is {{an eight}} voice analog synthesizer. Each voice is {{identical}} in architecture. The <b>audio</b> <b>path</b> is all analog, {{while there is}} some digital control of parameters.|$|E
50|$|The {{technique}} minimizes electronic crosstalk and electromagnetic interference, both {{noise emission}} and noise acceptance, and can achieve a constant or known characteristic impedance, allowing impedance matching techniques {{important in a}} high-speed signal transmission line or high quality balanced line and balanced circuit <b>audio</b> signal <b>path.</b>|$|R
50|$|Around {{the same}} time that MP3 audio coding was being developed, ISDN (Integrated Services Digital Network) was also being launched. ISDN was {{designed}} to deliver simultaneous digital transmission of voice, video, data, and other network services over the traditional circuits of the telephone network. Church was able to combine MP3 audio coding with ISDN technology to create a high-quality digital audio dialup service for broadcasters.The result was the Telos Zephyr, a point-to-point audio codec which made it possible for radio and television stations, networks, and recording studios to link studio quality <b>audio</b> <b>paths</b> over long distance digital telephone lines. The Zephyr revolutionized remote broadcasting, and in some ways, programming, by enabling the use of spontaneous interviews for morning drive shows and newscasts.|$|R
40|$|Visualization is an {{intuitive}} way {{to observe and}} analyse the phenomena related to the propagation of sound. It is evident that human hearing is highly capable of discriminating different aspects from an acoustic signal. The ability to discriminate is not necessarily enough to identify causality, that is answering the question: what aspect in the <b>audio</b> signal <b>path,</b> being a device or a room, contributes t...|$|R
50|$|Some {{systems may}} not {{cut through the}} <b>audio</b> <b>path</b> {{until there is a}} {{positive}} indication that the called party answered the call—there may not be an audio connection until the answer signal is sent.|$|E
5000|$|Eli Crews, {{writing in}} Electronic Musician in 2008, wrote that [...] "Eric Barbour of Metasonix has a {{colorful}} approach to design, employing an all-tube <b>audio</b> <b>path</b> {{in his quest}} for unusual and sonically extreme products." ...|$|E
5000|$|The dbx Type-II [...] "disc" [...] {{setting on}} {{consumer}} dbx decoders adds an additional 1-3 dB of low-frequency roll-off {{in both the}} <b>audio</b> <b>path</b> and control path. This protects the system from audible mistracking due to record warps and low-frequency rumble.|$|E
50|$|If the inaudible radio {{frequency}} (RF) transmitter signal is inadvertently coupled into the receiver's <b>audio</b> signal <b>path,</b> it can trigger the AGC or squelch circuit {{to reduce the}} gain. Then, after a delay time set by the circuit's time constant, the circuit increases the gain again until the amplitude of the radio signal triggers another gain reduction. This repetitive cycle is heard as motorboating.|$|R
50|$|Support for WDM audio enables digital mixing, routing and {{processing}} of simultaneous audio streams and kernel streaming with high quality sample rate conversion on Windows 98. WDM Audio allows for software emulation of legacy hardware to support MS-DOS games, DirectSound support and MIDI wavetable synthesis. The Windows 95 11-device limitation for MIDI devices is eliminated. A Microsoft GS Wavetable Synthesizer licensed from Roland shipped with Windows 98 for WDM audio drivers. Windows 98 supports digital playback of audio CDs, and the Second Edition improves WDM audio support by adding DirectSound hardware mixing and DirectSound 3D hardware abstraction, DirectMusic kernel support, KMixer sample-rate conversion (SRC) for capture streams and multichannel audio support. All audio is sampled by the Kernel Mixer to a fixed sampling rate which {{may result in}} some audio getting upsampled or downsampled and having a high latency, except when using Kernel Streaming or third-party <b>audio</b> <b>paths</b> like ASIO which allow unmixed audio streams and lower latency. Windows 98 also includes a WDM streaming class driver (Stream.sys) to address real time multimedia data stream processing requirements and a WDM kernel-mode video transport for enhanced video playback and capture.|$|R
50|$|Multitrack DAWs support {{operations}} on multiple tracks at once. Like a mixing console, each track typically has controls {{that allow the}} user to adjust the overall volume, equalization and stereo balance (pan) of the sound on each track. In a traditional recording studio additional rackmount processing gear is physically plugged into the <b>audio</b> signal <b>path</b> to add reverb, compression, etc. However, a DAW can also route in software or use software plugins (or VSTs) to process the sound on a track.|$|R
5000|$|The final {{component}} in the <b>audio</b> <b>path</b> is a VCA. It is a single-transistor design, based on a selected 2SC945 which is an NPN silicon device (equivalenced by 2N2222A according to the Towers' International Transistor Selector book, update 5 ( [...] , 90100)).|$|E
50|$|The {{simplest}} tone {{remote system}} uses a two-wire audio circuit {{to operate a}} simplex base station. If simultaneous transmit and receive is required, a four-wire or full duplex <b>audio</b> <b>path</b> to the base station is required. Systems using diversity combining (voting) require four-wire circuits.|$|E
50|$|The Asus Xonar HDAV1.3 {{became the}} first HDMI sound card that {{implemented}} the Protected <b>Audio</b> <b>Path</b> and could both bitstream and decode lossless audio (Dolby TrueHD and DTS-HD MA), although bitstreaming is only available if using the ArcSoft TotalMedia Theatre software. It has an HDMI 1.3 input/output, and Asus says that it can work with most video cards on the market.|$|E
30|$|Nowadays, the {{flexibility}} provided by hands-free communication devices has revolutionized the way humans communicate. Nonetheless, when one deals with hands-free systems {{there are several}} issues to face and problems to solve. The most relevant one is the echo presence, due to the acoustic coupling between microphones and loudspeakers located in the same room. Thus, an acoustic echo canceler is needed and several algorithmic solutions have been proposed in the literature {{in the last two}} decades [1]. More recently, the academic and technology market interest has been attracted by the chance to employ spatial audio techniques to enhance the sound realism in teleconferencing systems. Thus, many solutions have been proposed for multiparty conferencing where more microphones and loudspeakers are involved in each room. As a consequence of this, suitable multichannel AEC algorithms have been developed to deal with the echo problem in presence of multiple <b>audio</b> <b>paths,</b> where the task to be solved is tougher than in the single-channel case study, as rigorously illustrated in [2]. Indeed, the “non-uniqueness problem” occurs in the multichannel scenario, due to the high correlation degree between recorded signals: a very popular involved technique involves the addition of a decorrelation module to allow multichannel adaptive filtering working properly [2 – 5].|$|R
5000|$|China's largest taxi {{operator}} will commence {{trials of}} a HDVSL based [...] "in cab" [...] television service which plays location specific content and advertisements. As an example, when the taxi {{is about to}} approach a famous landmark - a video related to that landmark plays on a 9" [...] screen in the taxi. The HDVSL terminal also provides an <b>audio</b> return <b>path</b> to enable the taxi passenger to access a translation service which can help instruct the taxi driver. A large pilot project was tested during the Canton fair in 2008 with excellent results.|$|R
50|$|The BBC {{has begun}} using audio {{contribution}} over IP in Scotland {{as part of}} the Pacific Quay development in Glasgow. A similar system is being installed in the Regions of England and will be installed in Wales and Northern Ireland. The audio packets are sent using UDP over the BBC’s Layer-3 network. To reduce the chance that the audio is corrupted, quality of service (QoS) is set to ensure that the packets are given priority over other network traffic. The platforms used are the WorldNet Oslo for multiple channel contribution and distribution with the WorldCast Horizon deployed in stereo drop-off locations. The aptX algorithm is used with 24 bit depth and 48 kHz sampling. This is a higher specification than normal CDs, and is used to avoid concatenation effects. There have been problems found in the past when NICAM and MPEG <b>audio</b> <b>paths</b> have been used in sequence in the broadcast chain. The audio heard in the presentation studio has been acceptable, but listeners at home using DAB have complained about artifacts. To avoid this, aptX is used at high bit rates. This is a differential PCM system that does not use psychoacoustic processing. It is able to resynchronise after momentary loss of the IP path without noticeable clicking, and is licensed to most codec manufactures.|$|R
