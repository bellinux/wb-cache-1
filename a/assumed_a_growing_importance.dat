15|10000|Public
50|$|Military Road <b>assumed</b> <b>a</b> <b>growing</b> <b>importance</b> in the {{regional}} transportation system in the 1930s and 1940s. In August 1931, Arlington County and the U.S. Army agreed to end a dispute over who should continue to maintain the road, with the county taking responsibility for the road itself and the military assuming authority over connections and on/off ramps to nearby military facitilies like Fort Myer and Arlington National Cemetery. One of the first traffic lights on Military Road was installed at the street's intersection with Wilson Boulevard in August 1934. In 1937, the federal government offered to sell Military Road to Arlington County for $1, but the county turned down the offer. The usefulness of the southern leg of Military Road from the 14th Street Bridge to Arlington Boulevard declined in the late 1930s. Although it once served as a major feeder street to traffic crossing the 14th Street Bridge, Military Road was severed from this road network in 1939. In 1941, much of Military Road {{in the vicinity of}} the 14th Street Bridge was obliterated by construction of The Pentagon.|$|E
50|$|The BEF {{was forced}} to retreat and, {{at the end of}} May, Pope was {{evacuated}} from Dunkirk. He returned to the War Office, where he was appointed Director of Armoured Fighting Vehicles in June 1940. While in this post he {{played a key role in}} initiating production of the A22 tank (afterwards known as the Churchill tank). The Western Desert Campaign now <b>assumed</b> <b>a</b> <b>growing</b> <b>importance</b> in strategic thinking, and by the summer of 1941 a major offensive in the desert against the Germans named Operation Crusader was being planned. It was to be fought by the Eighth Army, commanded by Lieutenant General Sir Alan Cunningham, comprising XIII Corps, an infantry corps, and XXX Corps, a predominantly armoured corps. In August 1941 Pope was appointed General Officer Commanding (GOC) of XXX Corps. He flew to Egypt in September and assembled a staff, but on 5 October, en route to Lieutenant General Cunningham's first Eighth Army conference on the forthcoming battle, his Hudson aircraft ran into trouble on taking off from Heliopolis, crashed in the Mocattam Hills, and all on board were killed. He was succeeded as GOC XXX Corps by Lieutenant General Willoughby Norrie, who had been one of his fellow students at the Staff College in the mid-1920s.|$|E
40|$|Refugees have <b>assumed</b> <b>a</b> <b>growing</b> <b>importance</b> in the world's latest {{historical}} developments. They illustrate {{by themselves}} interactions between nations and underline {{the problems of}} territoriality and the integration of exiled populations. These questions were {{at the core of}} J. Bonnemaison's thoughts. He was questioning the logic behind the world which will be left to future generations. (Résumé d'auteur...|$|E
40|$|The {{role of the}} {{psychology}} and sociology of information is discussed in the five main interdisciplinary areas of library and information science: information services management, information systems engineering, information retrieval, information structure and dynamics, and information science theory. In recent years, after the impact of technological change has been progressively accommodated, psychological and sociological perspectives are <b>assuming</b> <b>a</b> <b>growing</b> <b>importance</b> in our discipline...|$|R
50|$|The core {{theme of}} ACR 2009 is innovation. The report states {{that in the}} context of competitiveness, Armenia has moved toward a new {{development}} stage, where the role of the competitiveness drivers is changed. The role of performance of macroeconomic indicators, institutions and basic infrastructure is more significant for countries in the first stage of development. Currently, economic efficiency and innovation capacities <b>assume</b> <b>a</b> <b>growing</b> <b>importance</b> for Armenia. Hence, innovation is critical {{to the creation of a}} knowledge-based economy which in turn is vital to a country like Armenia that is landlocked, has scarce natural resources and faces high transportation costs.|$|R
40|$|Uncertainty {{analysis}} for model simulations is <b>assuming</b> <b>a</b> <b>growing</b> <b>importance</b> {{in the field}} of water quality management. The importance of this concern is provided by recent public awareness over health risks from improper disposal of toxic wastes {{as well as by the}} continuing emphasis on risk assessment. The first step in the chain of the risk assessment is the quantification of the error in predicting water quality. For each mathematical modelling application, different uncertainties are involved. The uncertainty-sources can be classified into different categories (model-input uncertainty, model-structure uncertainty, model-parameter uncertainty and measurement errors). These different types of uncertainty sources determine collectively the total uncertainty in the model results. In this paper, the relative contributions of uncertainties associated with each source were studied. This provides information as to where available resources should be focused...|$|R
30|$|The SP data {{applications}} {{related to}} stated choices {{in a specific}} hypothetical context have <b>assumed</b> <b>a</b> <b>growing</b> <b>importance</b> {{in the last few}} decades. Some authors have proposed methodologies for using this kind of data, and models derived from them [28, 31]. However, many authors assert that a direct application of these models in order to forecast the choices made by the users is not very appropriated [11, 19]; as a consequence, some authors have proposed joint calibration models using RP and SP data (see, for example, [7]).|$|E
40|$|Particularly since World War II {{physical}} {{medicine and}} rehabilitation have <b>assumed</b> <b>a</b> <b>growing</b> <b>importance.</b> The {{efforts of the}} Canadian Association of Physical Medicine and Rehabilitation, following a survey of Canadian universities, to increase the theoretical and practical teaching of physiatrics are emphasized. It is considered important that the teaching of {{physical medicine and rehabilitation}} should be carried out concurrently with other medical and surgical teaching programs. Paramedical and auxiliary rehabilitation personnel should participate in the teaching program. The number of hours devoted to physiatrics should be increased, and the medical student should be permitted to choose physical medicine and rehabilitation as a part of his internship program...|$|E
40|$|The {{diseases}} of parathyroid glands have <b>assumed</b> <b>a</b> <b>growing</b> <b>importance</b> for innovations in diagnosis and surgery which have enabled {{a more precise}} identification and therapy. Use of Sesta-MIBI scintigraphy allows a correct localization of the adenoma; the introduction of intraoperative monitoring of intact parathyroid hormone made possible unilateral neck exploration with a mini-incision above the adenoma. The emergence of videotechnology has led the innovation of endoscopic parathyroidectomy, realized {{for the first time}} in 1996 and subsequently performed without the use of CO 2. Currently, the SPECT scintigraphy allows a three-dimensional vision of the adenoma and is the more precise localization study, allowing to use mini-invasive access. Prerequisite for the use of minimally invasive techniques is the determination of intraoperative PTH, possible with various techniques. Our experience is based on 135 patients undergoing parathyroidectomy in the last 8 years with 5 cases of persistent hyperparathyroidism submitted to reoperation, an average hospital stay of 2 days and only 6 complications (1 bleeding and 5 temporary hypoparathyroidisms). The use of new technologies in parathyroid surgery can achieve optimal results, a better cosmetic result and quicker postoperative recovery, with a low incidence of recurrence and complications...|$|E
40|$|Diplomacy did {{not exist}} in the sense of an {{abstract}} institution until the end of 18 century. But as concret activity and as particular type of political knowledge, diplomacy <b>assumes</b> <b>a</b> <b>growing</b> <b>importance</b> in the modern age. What was central to relations among states was not a sphere of formalized actions (“diplomacy”) but a “role,” or an “office: that of ambassador. This contribution try to sketch out the features, the activities and the political learning of modern ambassadors, both in the leaterature about the ambassador’s institutio, and in the political practice of Early Modern Italy. Instead of writing about diplomacy as a specific sector of statecraft, early modern authors focused on the ambassador’s moral profile and duties. Until the late seventeenth century, writings about ambassadorship were primarily works on political ethics and education in a “role. ...|$|R
40|$|Research on 4 G/ 5 G {{cellular}} networks is progressively {{shifting to}} paradigms that involve virtualization and cloud computing. Within this context, prototyping <b>assumes</b> <b>a</b> <b>growing</b> <b>importance</b> as <b>a</b> performance evaluation method, besides large-scale simulations, as it {{allows one to}} evaluate the computational requirements of the system. Both approaches share {{the need for a}} structured and statistically sound experiment management, with the goal of reducing errors in both planning and measurement collection. In this paper, we describe how we solve the problem with OpenAirInterface (OAI), an open-source system for prototyping 4 / 5 G cellular networks. We show how to integrate a sound, validated software, namely ns 2 -measure, with OAI, so as to enable harvesting samples of arbitrary metrics in a structured way, and we describe scripts that allow structured experiment management, such as launching a parametric simulation campaign and harvesting its results in a plot-ready format. We complete the paper by demonstrating some advantages brought about by our modifications...|$|R
40|$|Contract {{furniture}} {{design is}} oriented to develop customized {{products for the}} creation of a finished commodity for hospitality, offices, retails, restaurants, stores. It is <b>assuming</b> <b>a</b> <b>growing</b> <b>importance</b> all over the Europe and represents a preferred channel for promoting Made in Italy offer. Numerous competences with different skill, abilities and background are necessary to fulfill market requirements. Stakeholders are arranged into complex inter and intra temporary networks where sometimes- conflicting interests and purposes need to converge into a single and integrated design solution. Contract furniture combines product design with interior and architectural design requests to provide coherent furniture by assembling custom high-quality items from different firms. As a consequence, the design process is complex and collaboration is imperative to achieve the expected goals. This paper explores contract furniture design and defines a technological platform to support team working. The proposed methodology is applied to an industrial case study in the hospitality and retail sectors. Method application brings to define the system platform architecture and its main software modules...|$|R
40|$|Since its {{introduction}} to hepatobiliary surgery, three-dimensional (3 D) imaging has <b>assumed</b> <b>a</b> <b>growing</b> <b>importance</b> for the visualization of abdominal diseases. The main clinical applications include preoperative simulation for oncologic liver resection, and living-donor liver transplantation. The advantages of 3 D imaging are the exact visualization of vessels {{in areas with}} complex and variable vascular anatomy, determining possible resection margins, and predicting operative risks. Although hepatectomy is increasingly carried out, it {{is still one of}} the most difficult operative procedures because of the anatomical complexity and hepatic vascular variability. Moreover, patients with hilar cholangiocarcinoma often have obstructive jaundice, and the impaired hepatic function restricts the volume of liver resection. In addition, a positive resection margin should be avoided in order to achieve a potential cure of the disease. Thus, exact preoperative information on the detailed topography and precise liver resection volume should be obtained for curative and harmless hepatectomy. Concerning hilar cholangiocarcinoma, a successful management requires the following three steps: accurate preoperative estimation of both the tumor extent and anatomical variations, appropriate planning and simulation of the operative procedures, and implementing the planned procedures securely...|$|E
40|$|In recent years, the radial-axial ring {{rolling process}} has <b>assumed</b> <b>a</b> <b>growing</b> <b>importance</b> in bulk {{deformation}} processes {{due to its}} low costs and high efficiency. Based on literature studies, and applying innovative concepts about feeding speed ranges, the paper details {{an efficient way to}} define feasible process parameters, both for FE simulations and real processes. Using a discretized representation of the ring by subdividing it into slices, the mathematical model estimates the geometry evolution of each slice during the whole ring rolling process, su-perseding previous averaged calculations and opening the way to a more detailed estimation of diameters, contact arc lengths, strains, stresses and forces. Based on the ring’s estimated dimensions, the mathematical frame, suitable for cold, warm and hot processes, allows to derive the three strain components of the strain tensor, while filling the incompleteness of the literature where only the equivalent plastic strain was considered, and to estimate process forces, founded on the calculation of the flow stress of the material. The proposed analytical models have been applied {{to a wide range of}} rings with different ex-pansion profiles and dimensions ratio, and the relevant predictions have been compared with the results of FE simulations, showing a good reliability of the proposed approach...|$|E
40|$|China has {{constituted}} {{the most significant}} source of the incremental growth in global oil demand over the last decade, adding around 5 million b/d between 2000 and 2012. This {{is expected to continue}} well into the future: the International Energy Agency (IEA) estimates that China will account for more than 40 per cent of the increase in oil demand to 2035. A big part of that growth story has related to diesel, which has <b>assumed</b> <b>a</b> <b>growing</b> <b>importance</b> in the energy production and consumption of the world’s fastest growing emerging market economies. Fuelled by trade and investment, China’s growth has strongly supported diesel demand over the last decade. The dominant position of diesel in commercial freight traffic, be it by truck or rail, has made it the fastest-growing demand component. In China, the government mandate requiring all trucks to be fuelled by diesel by 2010 simply accelerated the already rising momentum of diesel demand growth. Further, diesel demand received an extra boost from power problems that led to greater use of diesel as a back-up fuel. In 2004, 2008, and 2010, power shortages during the winter months together with periods of government power rationing (to achieve environmental targets) contributed to buoyant diesel demand. The heavy industrial and mining sectors –such as coal, ship building, steel, and cement – that rely heavily on diesel, boomed throughout the 2000 s. It is thus hardly a surprise that diesel was the backbone of Chinese oil demand growth, to the extent that Chinese oil demand growth was synonymous with diesel demand growth...|$|E
40|$|The PMI are <b>assuming</b> <b>a</b> <b>growing</b> <b>importance</b> as {{promoters}} {{of the economic}} industry, in particular {{in some of the}} most dynamic local productive systems in Europe. In spite of this, the majority of the PMI are affected by the lack of funds available to invest in research and development, a field traditionally considered to be the main source of innovation. This apparent contradiction has induced many studious to investigate the sources from which the PMI obtain their inputs of knowledge. Such investigation, which has tended to use patents as proxy of the public research activity, has shown that PMI are particuarly sensitive to the disclosures which derive from public and university research. In this essay, the matter is analysed by using, in place of the number of patents, a bibliometric indicator of the output of public research with regard to 99 Italian provinces during the nineties. The results highlight a strong geographical correlation between the teritorial concentration of the PMI and public research that, at the same time, such correlation is influenced by the size of the enterprize...|$|R
40|$|Peroxyformic acid {{has been}} {{recently}} <b>assuming</b> <b>a</b> <b>growing</b> <b>importance</b> {{due to the}} versatile oxidizing properties in several applications in the chemical industry. However, quite surprisingly, a lack of data exists about the kinetics of formation of this compound, an even more singular event considering that the acid, when used, is generally produced in situ via the reaction between formic acid and hydrogen peroxide. This paper is a contribution to fill this gap. A series of batch experiments were carried out to measure the conversion rate in the peroxyformic acid formation reaction in the temperature range 30 - 60 degrees C. The results from experiments were successfully interpreted through a kinetic mechanism consisting of the reversible formation of the peroxyformic acid and its irreversible decomposition to CO(2) and H(2) O, both catalyzed by hydrogen ions. With the considered kinetic mechanism, a pre-exponential factor of 13065. 1 L(6) mol(- 2) s(- 1) and an activation energy of 43524. 2 J mol(- 1) were calculated. This last value and enthalpy and entropy of reaction derived from the kinetic data are in quite good accordance with the limited literature data available on this subject...|$|R
40|$|The {{search for}} a reliable, low-cost, general-application {{modeling}} tool has been <b>assuming</b> <b>a</b> <b>growing</b> <b>importance</b> among integrated optics theoreticians. For example, finite-difference (FD) based algorithms {{have given rise to}} commercial photonic CAD software programs that are less expensive, from both financial and computational points of view, than finite-elements (FEM) based ones. On the other hand, the former show some computational drawbacks that do not permit to consider them as of truly general application, while the latter provide extremely reliable modeling tools. Recently, a few numerical techniques (alternative to both FD and FEM methods) have been proposed, mainly in view of an improvement in flexibility and a reduction in computational cost. In particular, methods based on the Galerkin approach and Krylov reduction have proven particularly effective for the solution of the Helmholtz equation in a very wide class of integrated optical structures. Moreover, these methods are very promising {{from the point of view}} of reliability and are computationally non-expensive. Here, we present the implementation of one of such numerical techniques, the so-called Arnoldi-Galerkin method, together with that of a home-made FEM software program. A comparison with the results from other algorithms is shown as well...|$|R
40|$|Rebecca Harris, Claire Noble, Victoria Lowers Institute of Psychology, Health and Society, University of Liverpool, Liverpool, UK Abstract: Neoliberal {{emphasis}} on “responsibility” has colonized {{many aspects of}} public life, including how health care is provided. Clinical risk assessment of patients based {{on a range of}} data concerned with lifestyle, behavior, and health status has <b>assumed</b> <b>a</b> <b>growing</b> <b>importance</b> in many health systems. It is a mechanism whereby responsibility for self (preventive) care can be shifted to patients, provided that risk assessment data is communicated to patients in a way which is engaging and motivates change. This study aimed to look at whether the form in which tailored risk information was presented in a clinical setting (for example, using photographs, online data, diagrams etc.), was associated with differences in patients’ responses and preferences to the material presented. We undertook a systematic review using electronic searching of nine databases, along with handsearching specialist journals and backward and forward citation searching. We identified eleven studies (eight with a randomized controlled trial design). Seven studies involved the use of computerized health risk assessments in primary care. Beneficial effects were relatively modest, even in studies merely aiming to enhance patient–clinician communication or to modify patients’ risk perceptions. In our paper, we discuss the apparent importance of the accompanying discourse between patient and clinician, which appears to be necessary in order to impart meaning to information on “risk,” irrespective of whether the material is personalized, or even presented in a vivid way. Thus, while expanding computer technologies might be able to generate a highly personalized account of patients’ risk in a time efficient way, the need for face-to-face interactions to impart meaning to the data means that these new technologies cannot fully address the resource issues attendant with this type of approach. Keywords: risk, patient communication, personalisation, information, behavior change, health educatio...|$|E
40|$|The {{real estate}} sector in India has <b>assumed</b> <b>a</b> <b>growing</b> <b>importance</b> with the {{liberalization}} of the economy. The consequent increase in business opportunities and migration {{of the labor force}} has, in turn increased the demand for commercial and housing space. However, lack of funds, poor transparency level, complex and hazy regulations and policies, and lack of financial infrastructure impede the growth of the Indian real estate industry. Moreover, it seems that Indian real estate companies were exposed to the risk of recession, as real estate market exhibits cyclic behavior. Therefore, real estate companies have to form rational strategies to sustain during the recession period. Given the changes in the business environment, restructuring business models seems more appropriate as a strategy for the Indian real estate companies. In this sense, Real Estate Investment Trust (REIT) seems a promising model for managing the real estate business in India. However, there is yet no REIT legislation in India, nevertheless, it is in the final stage of planning and soon would be launched in Indian market. This work seeks to address this gap by analyzing whether REIT would be successful in India and identifying the motivating factors for the real estate companies to adopt this model, and recognizing the key issues influencing the successful implementation of REIT. Using the data collected from the interviews of real estate managers, findings were quite encouraging and REIT seems a prospective business model. Moreover, six direct and three indirect motivating factors were identified. Knowledge of the property management team, reputation of the sponsor, relationship and network, and governance were the major sources of competitive advantage and facilitate the successful implementation of the REIT. Conclusion and implications are drawn and discussed to close the work. Key Words Indian real estate industry; real estate companies; real estate cycles; rational strategies; real estate investment trust (REIT); motivating factors; competitive advantage...|$|E
30|$|Over {{the last}} 15 years Low-Density Parity-Check (LDPC) codes have <b>assumed</b> <b>a</b> <b>growing</b> <b>importance</b> in the channel coding arena, namely {{because they have}} error {{correction}} capability to achieve efficient coding close to the Shannon limit. These codes were invented by Robert Gallager (MIT) in the early sixties [1] and have never been fully exploited due to overwhelming computational requirements by that time. LDPCs are linear block codes (N,K) and can be described by sparse binary parity-check H matrices with dimensions (N - K) × N. They can also be elegantly represented by a Tanner graph [2] defined by edges connecting two distinct types of nodes usually denoted as Bit Nodes (BN), with a BN for {{each one of the}} N variables of H, and Check Nodes (CN), also called restriction or test nodes, with a CN for each one of the (N - K) parity-check equations given by H. Naturally, the fact that their patent has expired, has shifted the attention of the scientific community and industry away from Turbo codes [3] towards the study of LDPC codes [4], which quickly have shown to be able of guaranteeing similar or even superior coding performance. Mainly for these reasons and also because advances in microelectronics allowed the development of hardware solutions for real-time decoding, LDPC codes have been adopted by modern communication standards [5 – 7]. Important examples of these standards are: the Digital Video Broadcasting-Satellite 2 (DVB-S 2) for satellite communications [8]; the WiMAX IEEE 802.16 e for wireless communication systems in Metropolitan area networks (MAN) [9]; the WiFi 802.11 n standard for wired home networking technologies; and the 10 Gb Ethernet IEEE 802.3 an. Also, the introduction of LDPC codes in 4 G systems has recently been proposed, as opposed to Turbo codes adopted in 3 G. Some of these applications impose challenges that typically have to be addressed by using dedicated solutions that require System-On-Chip (SoC) hardware providing at the same time good performance, low power consumption and small die areas. Naturally, special emphasis has been given to solutions addressing the DVB-S 2 standard for satellite communications [8], which represents the most challenging application that actually incorporates the use of LDPC codes.|$|E
40|$|GPR {{involves}} {{the transmission of}} high-frequency electromagnetic radio pulses into the ground, and {{the measure of the}} time elapsed between transmission and reception by a surface radar antenna, after reflection in a buried discontinuity. In a enormous wide range of applications, it <b>assumes</b> <b>a</b> <b>growing</b> <b>importance</b> in road assessment, because enables precise and continuous pavement layer thickness evaluation at high-speed velocities and simultaneously, through analysis of variation of dielectric constant of the inspected materials, detection of zones related with striping or segregation of hot mix asphalt, as well of contrasts in moisture of granular materials. Through the lifetime of a pavement GPR can assure fundamental information: in the aim of quality control or assurance of new pavements; monitoring during service time; or as inspection method to define rehabilitation strategies. Assume interest in network management, pavement design, monitoring and forensic disputes. The work carried out by the authors, confirms the potentialities of this method, and emphasizes integration of GPR data with video images and geographical positioning by GPS, as with other road pavement data, and deals with data acquisition and processing; as well statistical synthesis and interpretation; integration of GPR with data from other methods; and data report. The applied GPR method requires horn air launched antennas, and compares amplitude reflection in pavement surface with the amplitude reflection in a metallic plate to calculate dielectric values of the first layers. As an example of GPR inspection, it is presented 32 km of a left lane highway in both ways, inspected along three different lines (left and right wheels and centre line), in about 4 hours of field work, during daylight period and without traffic impact...|$|R
40|$|Background: Human Papilloma virus (HPV) {{infection}} {{is the main}} cause of cervical cancer and cervical intraepithelial neoplasia (CIN) worldwide. Consequently, {{it would be useful to}} evaluate HPV testing to screen for cervical cancer. Recently several molecular biological tests able to detect different HPV types and to classified them into high and low-risk groups have been developed. In this study we examined HPV prevalence and genotype distribution in a group of 346 patients, some women undergoing cytological screening for prevention, others with abnormal cytological and/ or clinics. Methods: HPV detection and genotyping were done using a polymerase chain reaction based assay with the use the HPV Typing kit (Nuclear Laser Medicine). The tests can detect and differentiate 14 types of human papilloma virus, classified them into low, medium and high risk. Results. During the period 2005 - 2008, a total of 346 samples were analysed. The results of this study show that in this series, HPV infection were detected in 43. 35 % with a prevalence of 83. 3 % in patients of 16 - 20 years. Over the years there weren’t an increase of the infection. Among patients with condylomas, the genotype most frequently detected were HPV 6 (79 %) followed by HPV 11 (25. 5 %) while among the eso-endocervical swabs were HPV 16 (34. 5 %) and HPV 6 (26. 1 %). Conclusions: Our work shows how is high the incidence of HPV infection in people especially young, thus the importance of HPV molecular test for diagnosing the presence of high risk HPV oncogenes. This epidemiological study can better understand the incidence of HPV in local and identification of the virus strain that maintains the infection, in order to <b>assume</b> <b>a</b> <b>growing</b> <b>importance</b> in prevention programs...|$|R
40|$|The aim of {{this note}} is to {{highlight}} the importance of statistical-economic forecasting models for the deployment of innovative services through modern communication tools. We will analyse some communication tools and, in particular, the following: the communication trough the mass media, the interpersonal communication and the communication "through word of mouth". After having analysed the means of communication, we will measure the influence that consumers will experience in their purchasing decisions {{through the use of}} economic-statistical models In the current landscape, in the companies, the importance of innovation strategies <b>assumes</b> <b>a</b> <b>growing</b> <b>importance,</b> so the ability to model the cost-effectiveness is essential. Among all the suitable models, the model of F. Bass (1969) is efficient for measuring the effectiveness of the communication tools used for the promotion of innovative products. The model is widely used by companies for their quantitative analysis of the sales deriving from the innovative products put on the market and it has proven to effectively support the commercial management of the companies in planning and programming of sales. The Bass model is a considerable tool for measuring the diffusion process of innovation of a product among the potential customers. Another important contribution is offered by the model of information dissemination developed by Rogers (1983) that is based on the Gaussian distribution, where the curve is the frequency of consumers buying a product over time. If can be detected the cumulative number of buyers, the result is a S form pattern (sigmoid). Rogers argues that the curve of purchase is normally distributed because of a learning effect due to the interpersonal interaction existing in the social system. The number of buyers increases as soon as the process of interpersonal influence acts on those who are not buyers and this leads Rogers to identify the diffusion process essentially with a communicative nature...|$|R
40|$|The {{concept of}} resilience, {{developed}} mainly within physics, natural sciences and technological disciplines, has progressively spread within social sciences, and has recently become important {{to interpret the}} dynamics of regional systems and urban areas. If resilience is defined in physics as {{the ability of a}} system to recover shape and balance after turbulences, in the regional and urban fields that term is understood as a system's ability to respond to change. The idea of resilience in economy and geography has <b>assumed</b> <b>a</b> <b>growing</b> <b>importance,</b> especially since the global financial and economic crisis of 2008, which produced significant effects on regional and local economies, which have differently responded to the shock. The difficulties related to the economic crisis have been particularly relevant for small cities since they seem to play an increasingly secondary role, if compared to the processes of concentration of creative vitality and technological activities, which seem to reward larger cities, more open and more able to adapt to change. This paper focuses on small cities, with particular attention to the need for them to promote local policies and practices, in order to define new models of intervention aimed at building or strengthening the urban resilience. The theoretical discussion and the case study presented in this work highlight the importance of two attitudes of the city, which may affect its resilience: on the one hand, the promotion of the distinctive characteristics of regional and local context (smart specialization); on the other hand, the ability to respond to changes at different scales and to develop new development trajectories (dynamic capabilities). The application of the concept of resilience to small cities also involves the role of local actors and development strategies to capture new ideas and innovations from the outside and to respond locally and with self-determination to external stimuli. These responses include not only the economic, but also the cultural sphere, the relationship between citizens and city, social inclusion and territorial sustainability. These aspects represent fundamental values especially for the smaller systems,systems, which cannot rely on the creative skills and attractive assets of metropolitan areas...|$|E
40|$|The {{evolution}} of Italian capitalism during the 20 th century {{has been characterized}} {{by the presence of}} different forms of enterprise which have typified different phases of the country’s economic growth process. Considering a set of dimensions such as size, performance, legal forms, types of ownership and governance, Colli and Vasta (2010) identified seven different forms of enterprise: 1) big business; 2) state-owned enterprises; 3) foreign-controlled companies; 4) medium-sized firms; 5) small firms operating in local production system; 6) municipalized firms, which provide services within an administrative county or a homogeneous geographical areas; 7) co-operative firms which – originally proposed as an alternative to capitalist corporation and characterized by a peculiar governance structure – has <b>assumed</b> <b>a</b> <b>growing</b> <b>importance</b> in the Italian economy in the last three decades. Some of these forms of enterprise are strictly specific to the Italian case: small firms, co-operatives and municipalized companies correspond, in their diffusion, form and structure, to the particular set of social and institutional conditions which characterized 20 th century Italy. Conversely, for other forms, such as big business and foreign-controlled firms, the Italian case is not particularly {{different from that of the}} other industrialized nations, at least in term of specialization and market concentration. However, Italian big business remained sharply different from its American and European counterparts as regards the degree of internationalization, the ownership and organizational structures, and the governance practices. A pervasive presence of business groups is a common trait to all the forms of enterprise we have identified in Italian capitalism. However, we argue that business groups are not a static component of the Italian industrial landscape. The rationale for their existence constantly changes over time according to the technological and institutional changes. Thus, this paper, by enlarging the focus of a previous article (Colli and Vasta, forthcoming) to various forms of enterprises, analyze, on one hand, the dynamics of business group formation and, on another hand, the different logics which emerge within all different forms of enterprise. Moreover, it provides a “new” taxonomy of groups’ typologies and discusses the reasons at the origin of the choice of the group as a governance mechanism alternative to the multidivisional form and, more generally, to the Anglo-Saxon capitalism model. Finally, we argue that the business group as a governance system looks particularly flexible, adapting itself to different ownership and market conditions. In absence of obstacles of legal or fiscal nature, this flexibility is probably the main reason for its resilience. The persistence of business groups in the Italian economy confirms that this peculiar form of business organization is neither limited to the less developed countries, nor simply a "second-best" substitute of the multidivisional form diffused in the liberal market economies...|$|E
40|$|The primary {{function}} of a cement clinker cooler must always be the adequate cooling of the clinker product; however {{from the point of}} view of fuel economy, such coolers are also designed to utilise the sensible heat of the clinker to preheat the secondary air necessary for combustion. In modern, large capacity plant, the efficiency of heat recuperation has <b>assumed</b> <b>a</b> <b>growing</b> <b>importance</b> because of two related economic factors. The first is cutting fuel costs via the well understood benefits of heat recuperation; the second factor is the gradual improvement in fuel economy of cement kilns in general. As kilns become more finely tuned, the air required for combustion is reduced in direct proportion to the fuel usage, i. e. less air is available to cool a unit quantity of clinker. Hence, in order to avoid the situation where more air is supplied to the cooler than is required for complete combustion of the fuel, more efficient heat recuperation is needed. The Fuels and Energy Research Group at the University of Surrey (FERGUS), first became aware of these kiln/cooler problems in the late 1960 's, during the course of their pioneer work on the aerodynamics of rotary cement kilns. Consequently during the last decade, FERGUS has actively investigated the limitations of grate cooler systems, in general. In the initial stages of the research, a perspex water model was constructed at the University, based on some of the largest kilns in the world, those at. Northfleet Works of Blue Circle Industries. These coolers were experiencing "air sliding" of the clinker bed, causing red hot clinker to be dumped onto the rubber belt conveyors. Using suitable flow tracing media under controlled, scaled flow conditions, the aerodynamics of the Fuller grate cooler were studied, thus revealing that the air flow balance through the chambers at the hotter end of the cooler was more significant in its effect on the clinker bed than the balance at the colder end. A solution to this problem could then be achieved by using a three step grate. Water modelling, although giving quick visual solutions to aerodynamics problems, is only qualitative. In order to quantify results, various models of rotary kiln cooler systems have been constructed, in particular a 1 / 24 th scale model of the No. 2 kiln of Rugby Cement's South Ferriby Works. This kiln had for some time suffered from excessive wear rates in the burning zone refractory lining, an expensive problem in terms of down-time and rebricking. Air model pitot static measurements indicated that the air jet (representing the fuel/primary air stream) was exhibiting a peculiar "corkscrewing" effect, which could possibly be the cause of impingement on the refractory lining, leading to premature failure of the refractory coating. Correct kiln firing practice is to promote recirculation of combustion products; these gases, being cooler than the flame, protect the brickwork from overheating. It was already understood that the primary cause of flame impingement was a lack of recirculation due to insufficient burner momentum flux, the solution being a costly change in the firing system. However, the air model results were later verified by full scale plant trials and a solution was proposed to eliminate the "corkscrewing" effect by means of a wedge- shaped bluff body welded along the jet axis. This study has quantified the macro aerodynamic effects of grate cooler systems, through the media of air and water modelling. Considerable information has also been obtained on the dynamic behaviour and heat transfer mechanisms of a particular polysize bed of clinker particles. From this information, putative predictions can be made regarding the general behaviour of clinker in beds. Recommendations have been made for further studies in this area. (Abstract shortened by ProQuest.) ...|$|E
5000|$|... "The Middle East, {{for many}} years a source of fascination and concern to ...specialists, has now <b>assumed</b> <b>a</b> greater and <b>growing</b> <b>importance</b> for Americans in all walks of life." [...] Annual Report 1974, Foreword [...] Furthermore, MEI started a program called [...] "Dialogue" [...] in 1974 in {{cooperation}} with the Arabist Travel Program. It sent small teams of scholars and students to seven Arab countries. The program was repeated in 1978, funded by the United States Information Agency and the State Department.|$|R
40|$|Abstract—Digital Video Broadcasting for Handheld {{terminals}} (DVB-H) is <b>assuming</b> <b>an</b> ever <b>growing</b> <b>importance</b> {{for digital}} video transmission over wireless terminals. In such a context, Time Slicing has been implemented {{to achieve a}} better power saving and manage handover. Specifically, a generic user transmits bursts of data, interspaced by time periods in which no data are transmitted. In this paper, to improve time sliced multiservice transmission effectiveness, the Variable Burst Time (VBT) algorithm is presented and discussed. It dynamically varies the whole set of stream Burst Durations according to input stream data, available channel bandwidth, receiving buffer size and eventually stream priority. Burst Durations are derived by the minimization of a Total Loss Function (TLF) representing the amount of losses of the whole service set. Numerical results show the VBT effectiveness if compared with the time sliced transmission recommended in the DVB guidelines, for different numbers, types and quality degrees of VBR streams, receiving buffer sizes and stream priorities. This suggests that VBT could be efficiently exploited for transmission of VBR streams in DVB-H systems...|$|R
40|$|In {{several areas}} of Civil Engineering real {{challenges}} arising for the design, construction {{and maintenance of}} new structures and for the retrofitting of existing ones concern the correct selection of materials, along with their complete and reliable characterization, and the diagnostic identification of possible damages. In particular, the task of determining the deformability of Civil Engineering materials is <b>assuming</b> <b>a</b> <b>growing</b> <b>importance,</b> both in design processes and in diagnosis, monitoring and strengthening procedures. Indeed, owing to recent design and verification codes, careful quality control and accurate design and verification in serviceability conditions are required {{to the number of}} structures and infrastructures which are currently under construction in Europe: to this end, investigating the deformability of materials turns out to be crucial. Similarly, the evaluation of deformability is a primary requirement in case of restoration works, in order to guarantee the maximum compatibility between the damaged members and the restored parts, and hence to ensure the durability of repairs. Moreover, the analysis of the deformability properties of materials is essential in order to assess not only the damage level in RC structures, but also the conservation conditions of the ancient and wide European architectural and monumental heritage, which is currently subject to high risks of deterioration. In particular, the investigation on the decrease in the elastic properties generally provides significant diagnostic information for damage detection and quantification: it is well-known, indeed, that the local elastic modulus of materials can be correlated with their integrity and consequently with their damage level when subjected to static or dynamic loading and environmental effects. Therefore, a prompt observation of significant variations in the values of the elastic modulus in time or point-by-point in a structure could be associated to the presence of damage phenomena in progress and makes it possible to take appropriate safety measures. Unfortunately, determining the elastic modulus in existing structures is a complex task, especially when dealing with large structures, such as bridges, viaducts, etc. Indeed, on account of the unavoidable variability in experimental measurements and most of all due to local material inhomogeneities, the elastic modulus should be suitably modeled as a random variable, to be examined in a probabilistic context, and consequently a considerable number of experimental data should be required for a satisfactory material characterization. It stands to reason that a systematic use of standard methods which involve drilling a high number of cores to be subjected to laboratory tests would be very expensive and, in most cases, unfeasible. For this reason, in the last decades, some authors have proposed sophisticated correlations with other properties that could be more easily determined and many others have developed experimental techniques in the attempt of obtaining rapid and cost-effective NDE methodologies. Some of these techniques are based on the measurement of ultrasonic waves propagation velocity and reveal to be particularly fast and easy-to-perform, but, on the other hand, their accuracy deeply depends on the ability of the operator and on testing conditions in general. Conversely, other mechanical techniques make it possible to achieve a substantially higher accuracy, but their use is restricted to specific applications or has the drawback of requiring a longer time and causing a little damage to the structural member under investigation. Based on the foregoing considerations, the present study deals with the problem of experimentally determining the elastic modulus in existing concrete structures and appropriately processing the experimental data through statistical tools. A novel mechanical method, denoted as Impulse Method, has been proposed for the on-site estimation of the elastic modulus: it proves to be accurate, repeatable and sufficiently fast and easy-to-perform to make it possible to collect a suitable number of data in a very short time. Subsequently, the problems related to the evaluation and the practical use of such experimental data are addressed through a statistical approach based on Hypothesis Testing Theory: in particular, a sequential hypothesis testing procedure has been developed, which is optimal with respect to the error probabilities and the required number of experimental measurements. Finally, an extensive experimental campaign has been conducted at the Non-Destructive Testing Laboratory of the Politecnico di Torino, with the aim of assessing the effectiveness and the possible drawbacks of the proposed method: the results achieved proved to be fairly accurate and reliable, so that the Impulse Method reveals to have interesting possibilities of application in the field of diagnosis and monitoring, especially when used in conjunction with the proposed hypothesis testing procedure. These encouraging findings suggest to continue the research in view of the integration with other experimental techniques, with the final aim of minimizing the total number of tests to be performed for a complete material characterization. The present thesis is structured as follows: at first, the main methods currently used for the experimental determination of the elastic modulus of concrete, {{as well as some of}} the most recent methods proposed in the literature as potentially valuable techniques, will be presented and discussed, in the attempt to provide a comprehensive and critical view of the state-of-the-art in this field (Chapter 1); then, a specific technique denoted as Impulse Method is described, with regards to its physical foundations (Chapter 2); subsequently, the sequential hypothesis testing procedure to be used to process the experimental data is presented (Chapter 3); finally, the results of the experimental campaign implementing the Impulse Method and the proposed hypothesis testing procedure are reported and discussed (Chapter 4...|$|R
40|$|In recent years, the {{development}} of policies aiming at promoting {{the use of public}} transport <b>assumed</b> <b>a</b> continuously <b>growing</b> <b>importance.</b> Under this perspective, ensuring that passengers perceive high service Quality is of paramount importance. Thus, in order to ensure high service Quality levels, Transport Authorities should be able to measure quality perceived by customers via customer oriented, clear and easy to apply approaches. In addition, {{they should be able to}} assess the effects of organizational settings and maintenance management policies on service availability. On the other hand, in order to be competitive, companies delivering transportation systems should be able to assess the effects of reliability objectives on the system Lifecycle cost since the conceptual design phase. In such a context, this research work aims at giving a methodological contribution, based on a solid stochastic and statistical framework, for managing Quality, Availability and Lifecycle Cost of Transportation Systems. A methodology to evaluate transport service quality, relying on a set of innovative indexes based on the generic customer’s waiting time, is defined. It allows to “on-line” monitor Quality of high frequency bus services by means of commonly available data, avoiding expensive data collection activities. In fact, a specific strategy is formulated to obtain the waiting time distribution for a generic customer on the basis of commonly available data/information. The adequacy of the above strategy and of the main working hypotheses is checked by means of real data concerning the route 181 operated by A. N. M. The proposed approach enables to quantify the effects of service frequency and service regularity on the customers’ waiting time. Moreover, besides allowing to assess the current service quality level, it allows to forecast how changes of the service frequency and/or regularity can affect quality perceived by customers. Moreover, a simple approach to assess the effects of the inherent repair time distribution, number of spare vehicles and number of maintenance crews on the operational availability of a fleet of vehicles is defined. The considered approach allows to easily handle complex Non - Markovian stochastic processes, and, in accordance with results found in Queueing theory, reveals that fleet operational availability may be significantly influenced by the inherent repair time distribution in both transient and steady phase. In addition, it is shown that the proposed approach leads to operational availability evaluations that are more accurate than those usually performed in the industrial practice and that it may overcome some issues arising when Monte Carlo Simulation is used. At last, a lifecycle cost – reliability model based on a three-parameters Hyperbolic failure intensity is presented. Numerical procedures to obtain Maximum Likelihood and Minimum Chi-square estimates of the Hyperbolic model parameters are outlined. By means of reliability data concerning the first two years of operation of the Copenhagen Metro vehicles, it is shown that the Hyperbolic model may be adequate to explain the failure rate behavior of complex repairable systems. Then, relationships between reliability and the main cost components depending on reliability are developed. In this respect, the innovative concept of inertia pertaining to the reliability improvement process is used to model costs to be born, during the testing phase and the early stages of operation, to reach the planned reliability target...|$|R
40|$|Information {{technology}} [...] computers, communication {{networks and}} the like [...] has <b>assumed</b> <b>a</b> role of <b>growing</b> <b>importance</b> in {{both private and public}} sector organizations during the 19802 ̆ 7 s. This technology is no longer the private preserve of small groups of computer specialists; rather, the office automation and end user computing movements are placing information technology into the hands of workers at all levels, and in all areas. The emergence of the business microcomputer has {{played a central role in}} this trend.;The rapid growth of microcomputers in the workplace, however, has not been without problems. In some offices, even where having a microcomputer is viewed as a status symbol, the systems themselves are highly used.;Because information technology, and in particular the microcomputer, has come to play such an important role in modern organizations, it is crucial that we develop a better understanding of the various factors that affect managers 2 ̆ 7 decisions whether to adopt this technology. The purpose of this research is to develop and test a model of the relationships between a variety of external variables, and the managers 2 ̆ 7 usage of computers.;Fishbein 2 ̆ 7 s 2 ̆ 7 theory of reasoned action, 2 ̆ 7 a widely accepted model of human behaviour, lies at the core of this study. Fishbein 2 ̆ 7 s model posits that one 2 ̆ 7 s intention to act a certain way (e. g., begin to use a microcomputer) is derived from two general classes of factors: attitudes, and subjective norms. Furthermore, intention leads to action (barring the presence of external variables, e. g., unavailability of a microcomputer).;Data was collected from a cross-sectional survey of 519 managers, drawn from managers of 54 corporations in Ontario. The results provided support for 11 of the 16 propositions in the model. Using LISREL as the data analysis technique, it was found that positive attitudes towards computer usage, and subjective norms that supported usage led to higher levels of usage. In turn, attitudes were affected by computer anxiety, computer skills, the quality of the system and management support. Subjective norms were affected by management support, and usage by upper level managers and peer managers in the organization...|$|R
5000|$|Schekkerman had {{witnessed}} <b>a</b> <b>growing</b> <b>importance</b> of Enterprise Architecture. He explained: ...|$|R
50|$|Medical tourism {{based on}} the clean air and idyllic {{settings}} by the Baltic Sea has <b>a</b> <b>growing</b> <b>importance</b> to the regional tourism industry.|$|R
50|$|In recent years, Shirur {{has been}} an {{imperative}} educational and commercial hub for Parner, Shrigonda and Shirur Talukas. Shirur is gaining <b>a</b> <b>growing</b> <b>importance</b> on Pune-Ahmednagar road for industrialization and trade.|$|R
3000|$|... and SO 2. The other {{finding is}} that FIRE and {{services}} <b>assume</b> <b>a</b> <b>growing</b> portion of CO and VOC emissions.|$|R
