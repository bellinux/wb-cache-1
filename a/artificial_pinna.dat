3|5|Public
50|$|Binaural hearing {{learning}} is a bionic method. The sensor is a robot dummy head with 2 sensor microphones along with the <b>artificial</b> <b>pinna</b> (reflector). The robot head has 2 rotation axes and can rotate horizontally and vertically. The reflector causes the spectrum change into a certain pattern for incoming white noise sound wave and this pattern {{is used for the}} cue of the vertical localization. The cue for horizontal localization is ITD. The system makes use of a learning process using neural networks by rotating the head with a settled white noise sound source and analyzing the spectrum. Experiments show that the system can identify the direction of the source well in a certain range of angle of arrival. It cannot identify the sound coming outside the range due to the collapsed spectrum pattern of the reflector. Binaural hearing use only 2 microphones and is capable of concentrating on one source among multiple sources of noises.|$|E
40|$|An {{important}} aspect of all robotic systems is sensing {{and there are many}} sensing modalities used including vision, tactile, olfactory and acoustics to name a few. This paper presents a robotic system for sensing in acoustics, specifically in elevation localization. The model presented is a two-stage model incorporating spectral analysis using <b>artificial</b> <b>pinna</b> and an artificial neural network for classification and elevation estimation. The spectral classifier uses notch filters to analyze changes in attenuation of certain frequencies with elevation. This paper shows how using the spectral output of a signal generated by an <b>artificial</b> <b>pinna</b> can be classified by a feed-forward backpropagation neural network to estimate the elevation of a sound-source...|$|E
40|$|Abstract. Principal {{component}} analysis (PCA) {{was used to}} reduce dimension and simplify the analysis of HRTF amplitude spectra of dummy head installed with different <b>artificial</b> <b>pinna</b> model. In addition to no-pinna case, 4 kinds of structural model of pinna were discussed. Directional mean of the corresponding frequency bands and the basic functions of spectral shape of HRTF were given to illustrate the effect of different pinna details act on HRTF. It proves, besides the no-pinna case, No. 2 pinna structure (with connected cymba conchae and cavitas conchae), No. 4 pinna structure(with thickened antitragus) affect the HRTF most obviously in the horizontal plane. However, the effect of helix alone on HRTF is rather little. As a whole, different pinna structural detail has different effect on HRTF amplitude spectrum...|$|E
40|$|In this paper, we {{evaluate}} adaptive sound localization algorithms for robotic heads. To {{this end}} {{we built a}} 3 degree-of-freedom head with two microphones encased in <b>artificial</b> <b>pinnae</b> (outer ears). The geometry {{of the head and}} pinnae induce temporal differences in the sound recorded at each microphone. These differences change with the frequency of the sound, location of the sound, and orientation of the robot in a complex manner. To learn the relationship between these auditory differences and the location of a sound source, we applied machine learning methods to a database of different audio source locations and robot head orientations. Our approach achieves a mean error of 2. 5 degrees for azimuth and 11 degrees for elevation for estimating the position of an audio source. The impressive results highlight the benefits of a two-stage regression model {{to make use of the}} properties of the <b>artificial</b> <b>pinnae</b> for elevation estimation. In this work, the algorithms were trained using ground truth data provided by a motion capture system. We are currently generalizing the approach so that the training signal is provided online based on a real-time face detection and speech detection system...|$|R
5000|$|While the {{relationship}} between human perception of sound and various attributes of the sound field is not yet well understood, DSP algorithms for sound localization are able to employ several mechanisms found in neural systems, including the interaural time difference (ITD, the difference in arrival time of a sound between two locations), the interaural intensity difference (IID, the difference in intensity of a sound between two locations), <b>artificial</b> <b>pinnae,</b> the precedence effect, and head-related transfer functions (HRTF) [...]When localizing 3D sound in spatial domain, one could {{take into account that}} the incoming sound signal could be reflected, defracted and scattered by the upper torso of the human which consists of shoulders, head and pinnae.Localization also depends on the direction of the sound source.|$|R
40|$|This paper {{describes}} {{the importance of}} the sense of hearing for immersive telepresence systems, and a fundamental approach to designing and implementing a binaural sensor system. This approach relies on knowledge of how the human auditory localisation mechanisms work to locate sounds in space, in order that a synthetic system can be derived. The most important of these mechanisms are explained. The Strathclyde auditory system is then described including ideas drawn from the literature to define a binaural approach. This novel system consists of a set of <b>artificial</b> <b>pinnae</b> and microphones mounted on a binocular stereo sensor platform capable of pan, tilt and roll which is slaved to a head tracking system. A set of preliminary experiments is described which test the performance of the system in practice, as a basis for further development...|$|R
40|$|Abstract. An {{improved}} {{sound source}} localization (SSL) method {{has been developed}} {{that is based on}} the generalized cross-correlation (GCC) method weighted by the phase transform (PHAT) for use with humanoid robots equipped with two microphones inside <b>artificial</b> <b>pinnae.</b> The conventional SSL method based on the GCC-PHAT method has two main problems when used on a humanoid robot platform: 1) diffraction of sound waves with multipath interference caused by the shape of the robot head and 2) front-back ambiguity. The diffraction problem was overcome by incorporating a new time delay factor into the GCC-PHAT method under the assumption of a spherical robot head. The ambiguity problem was overcome by utilizing the amplification effect of the pinnae for localization over the entire azimuth. Experiments conducted using a humanoid robot showed that localization errors were reduced by 9. 9 Â° on average with the improved method and that the success rate for front-back disambiguation was 32. 2 % better on average over the entire azimuth than with a conventional HRTF-based method...|$|R
50|$|According to the duplex theory, ITDs have {{a greater}} {{contribution}} to the localisation of low frequency sounds (below 1 kHz), while ILDs {{are used in the}} localisation of high frequency sound. These approaches can be applied to selective reconstructions of spatialized signals, where spectrotemporal components believed to be dominated by the desired sound source are identified and isolated through the Short-time Fourier transform (STFT). Modern systems typically compute the STFT of the incoming signal from two or more microphones, and estimate the ITD or each spectrotemporal component by comparing the phases of the STFTs. An advantage to this approach is that it may be generalized to more than two microphones, which can improve accuracy in 3 dimensions and remove the front-back localization ambiguity that occurs with only two ears or microphones. Another advantage is that the ITD is relatively strong and easy to obtain without biomimetic instruments such as dummy heads and <b>artificial</b> <b>pinnae,</b> though these may still beused to enhance amplitude disparities.HRTF phase response is mostly linear and listeners are insensitive to the details of the interaural phase spectrum as long as the interaural time delay (ITD) of the combined low-frequency part of the waveform is maintained.|$|R

