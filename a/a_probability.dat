10000|10000|Public
5|$|The {{commander}} {{took the}} aircraft into a spiral dive {{to the right}} because, with <b>a</b> <b>probability</b> bordering on certainty, he had lost spatial orientation.|$|E
5|$|In mathematics, {{constructions of}} {{mathematical}} objects are needed, {{which is also}} the case for stochastic processes, to prove that they exist mathematically. There are two main approaches for constructing a stochastic process. One approach involves considering a measurable space of functions, defining a suitable measurable mapping from <b>a</b> <b>probability</b> space to this measurable space of functions, and then deriving the corresponding finite-dimensional distributions.|$|E
5|$|To assess {{prospective}} {{wind power}} sites <b>a</b> <b>probability</b> distribution function is often {{fit to the}} observed wind speed data. Different locations will have different wind speed distributions. The Weibull model closely mirrors the actual distribution of hourly/ten-minute wind speeds at many locations. The Weibull factor is often close to 2 and therefore a Rayleigh distribution {{can be used as}} a less accurate, but simpler model.|$|E
50|$|At a HIC of 1000, {{there is}} <b>an</b> 18% <b>probability</b> of <b>a</b> severe head injury, <b>a</b> 55% <b>probability</b> of <b>a</b> serious injury and <b>a</b> 90% <b>probability</b> of <b>a</b> {{moderate}} head {{injury to the}} average adult.|$|R
30|$|The <b>a</b> priori <b>probability</b> is {{calculated}} from the last <b>a</b> posteriori <b>probability</b> using <b>a</b> probabilistic process (state transition) model f(⋅).|$|R
3000|$|... (w) is <b>a</b> priori <b>probability</b> {{related to}} the class w. Unfortunately, <b>a</b> priori <b>probability</b> is {{impossible}} to estimate using the available experimental data. Because of this, we assume that <b>a</b> priori <b>probability</b> related to each separate class is of the same value and equal to [...]...|$|R
5|$|Data {{from the}} ZDR was {{passed to the}} All-Target Processor (ATP), which ran initial {{processing}} on as many as 625 objects in a cloud. As many as 50 of these could be picked out for further processing in the Discrimination and Control Computer (DCC), which ran more tests on those tracks and assigned each one <b>a</b> <b>probability</b> of being the warhead or decoy. The DCC was able to run 100 different tests. For exoatmospheric signals the tests included measure of radar return pulse-to-pulse to look for tumbling objects, as well as variations in signals strength due to changes in frequency. Within the atmosphere, the primary method was examining the velocities of the objects to determine their mass.|$|E
5|$|Day 2 outlooks, issued {{twice daily}} at 0600Z and 1730Z, refer to {{predicted}} risks of convective weather {{for the following}} day (1200Z to 1200Z of the next calendar day; for example, a Day 2 outlook issued on April 12, 2100 would be valid from 1200Z on April 13, 2100 through 1200Z on April 14, 2100) and include only a categorical outline, textual description, and <b>a</b> <b>probability</b> graph for severe convective storms generally. Day 2 moderate risks are fairly uncommon, and a Day 2 high risk has only been issued twice (for April 7, 2006 and for April 14, 2012).|$|E
5|$|Donecle uses a {{swarm of}} drones {{equipped}} with laser sensors and micro-cameras. The algorithms for automatic detection of defects, trained on existing images database with a machine learning software, are able to identify various elements: texture irregularities, pitot probes, rivets, openings, text, defects, corrosion, oil stains. A damage report is sent on the operator's touch pad with each area of interest and the proposed classification with <b>a</b> <b>probability</b> percentage. After reviewing the images, the verdict is pronounced by a qualified inspector.|$|E
5000|$|Program D: [...] "there is <b>a</b> 1/3 <b>probability</b> {{that nobody}} will die, and <b>a</b> 2/3 <b>probability</b> that 600 people will die" ...|$|R
50|$|The term wet bias {{refers to}} the {{phenomenon}} whereby some weather forecasters (usually deliberately) report <b>a</b> higher <b>probability</b> of precipitation (in particular, of rain) than the probability they believe (and the probability borne out by empirical evidence), {{in order to increase}} the usefulness and actionability of their forecast. The Weather Channel has been empirically shown, and has also admitted, to having a wet bias in the case of low probability of precipitation (for instance, <b>a</b> 5% <b>probability</b> may be reported as <b>a</b> 20% <b>probability)</b> but not at high probabilities of precipitation (so <b>a</b> 60% <b>probability</b> will be reported as <b>a</b> 60% <b>probability).</b> Some local TV stations have been shown as having significantly greater wet bias, often reporting <b>a</b> 100% <b>probability</b> of precipitation in cases where it rains only 70% of the time.|$|R
2500|$|... may be {{considered}} to represent <b>a</b> discrete <b>probability</b> mass function of , with <b>an</b> associated <b>probability</b> mass function constructed from the transformed variable, ...|$|R
5|$|The {{inner product}} between two state vectors {{is a complex}} number known as <b>a</b> <b>probability</b> amplitude. During an ideal {{measurement}} of a quantum mechanical system, {{the probability that a}} system collapses from a given initial state to a particular eigenstate is given by the square of the absolute value of the probability amplitudes between the initial and final states. The possible results of a measurement are the eigenvalues of the operator—which explains the choice of self-adjoint operators, for all the eigenvalues must be real. The probability distribution of an observable in a given state can be found by computing the spectral decomposition of the corresponding operator.|$|E
5|$|Across {{languages}} and letters, the average {{probability of a}} letter being chosen {{as one of the}} six preferred letters was 0.30 for name letters and 0.20 for other letters. The strongest effects were observed in the Norwegian and Finnish studies. In the Hungarian, Portuguese, and Italian studies the effect was present but not to a significant degree. The effect was also found when only looking at letters in family names, as well as only first name letters. The name-letter effect emerged as very significant in all languages when only initials were considered. There was <b>a</b> <b>probability</b> of 0.46 that initial letters were chosen amongst the top-six letters. Further analysis revealed that the overall name-letter effect is not simply due to initials: when excluding initials a name-letter effect was still found across all languages.|$|E
25|$|In quantum mechanics, <b>a</b> <b>probability</b> {{amplitude}} is {{a complex}} number used in describing the behaviour of systems. The modulus squared of this quantity represents <b>a</b> <b>probability</b> or probability density.|$|E
3000|$|The <b>a</b> posteriori <b>probability</b> is {{calculated}} from the <b>a</b> priori <b>probability</b> using <b>a</b> probabilistic measurement model h(⋅) and the current measurement z [...]...|$|R
50|$|Observe {{also that}} a {{necessity}} measure {{can be seen}} as <b>a</b> lower <b>probability</b> and <b>a</b> possibility measure {{can be seen as}} <b>an</b> upper <b>probability.</b>|$|R
5000|$|Program B: [...] "there is <b>a</b> 1/3 <b>probability</b> that 600 {{people will}} be saved, and <b>a</b> 2/3 <b>probability</b> that no {{people will be}} saved" ...|$|R
25|$|In {{probability}} theory, <b>a</b> <b>probability</b> {{space or}} <b>a</b> <b>probability</b> triple is a mathematical construct that models a real-world process (or “experiment”) consisting {{of states that}} occur randomly. <b>A</b> <b>probability</b> space is constructed with a specific kind of situation or experiment in mind. One proposes that each time a situation of that kind arises, the set of possible outcomes is the same and the probabilities are also the same.|$|E
25|$|Any {{probability}} distribution defines <b>a</b> <b>probability</b> measure.|$|E
25|$|In {{probabilistic}} language, f is <b>a</b> <b>probability</b> density function.|$|E
2500|$|Given data [...] and {{parameter}} , {{a simple}} Bayesian analysis starts with <b>a</b> prior <b>probability</b> (prior) [...] and likelihood [...] to compute <b>a</b> posterior <b>probability</b> [...]|$|R
40|$|AbstractMarkov kernels {{are used}} to express <b>a</b> given fuzzy <b>probability</b> in quite <b>a</b> {{different}} way, as E. P. Klement had done. It {{is more difficult to}} establish <b>a</b> transition <b>probability</b> than <b>a</b> Markoff kernel P-everywhere defined to express <b>a</b> given fuzzy <b>probability.</b> <b>A</b> special concept of “compactness” is introduced to solve the above problem...|$|R
2500|$|<b>As</b> <b>probability</b> {{theory is}} used in quite diverse applications, {{terminology}} is not uniform and sometimes confusing. The following terms are used for non-cumulative probability distribution functions: ...|$|R
25|$|In {{probability}} theory, {{a standard}} probability space, also called LebesgueRokhlin probability space or just Lebesgue space (the latter term is ambiguous) is <b>a</b> <b>probability</b> space satisfying certain assumptions introduced by Vladimir Rokhlin in 1940. Informally, it is <b>a</b> <b>probability</b> space consisting of an interval and/or a finite or countable number of atoms.|$|E
25|$|Whereas {{ordinary}} mechanics only {{considers the}} behaviour {{of a single}} state, statistical mechanics introduces the statistical ensemble, which is a large collection of virtual, independent copies of the system in various states. The statistical ensemble is <b>a</b> <b>probability</b> distribution over all possible states of the system. In classical statistical mechanics, the ensemble is <b>a</b> <b>probability</b> distribution over phase points (as opposed to a single phase point in ordinary mechanics), usually represented as a distribution in a phase space with canonical coordinates. In quantum statistical mechanics, the ensemble is <b>a</b> <b>probability</b> distribution over pure states, and can be compactly summarized as a density matrix.|$|E
25|$|<b>A</b> <b>probability</b> {{model for}} {{estimating}} probability of an earthquake during a specified interval.|$|E
5000|$|Although [...] and [...] {{can be any}} {{space of}} functions, many {{learning}} algorithms are probabilistic models where [...] {{takes the form of}} <b>a</b> conditional <b>probability</b> model , or [...] takes the form of <b>a</b> joint <b>probability</b> model [...] For example, naive Bayes and linear discriminant analysis are joint probability models, whereas logistic regression is <b>a</b> conditional <b>probability</b> model.|$|R
5000|$|... #Caption: Doomsday Clock graph, 1947-2017. The lower {{points on}} the graph {{represent}} <b>a</b> higher <b>probability</b> of technologically or environmentally-induced catastrophe, and the higher points represent <b>a</b> lower <b>probability.</b>|$|R
5000|$|In Bayesian statistics, {{the problem}} arises at that of {{deciding}} on <b>a</b> prior <b>probability</b> {{for the outcome}} in question (or when considering multiple outcomes, <b>a</b> prior <b>probability</b> distribution).|$|R
25|$|Each node of the Chance {{player has}} <b>a</b> <b>probability</b> {{distribution}} over its outgoing edges.|$|E
25|$|The {{probability}} {{that any one}} of the events {1,6}, {3}, or {2,4} will occur is 5/6. This is the same as saying that the probability of event {1,2,3,4,6} is 5/6. This event encompasses the possibility of any number except five being rolled. The mutually exclusive event {5} has <b>a</b> <b>probability</b> of 1/6, and the event {1,2,3,4,5,6} has <b>a</b> <b>probability</b> of 1, that is, absolute certainty.|$|E
25|$|When {{there is}} <b>a</b> <b>probability</b> that the {{temperature}} may fall below 5°C within 24 hours of placing the concrete.|$|E
5000|$|T-score between −1.0 and −2.5 at the femoral neck or {{spine and}} <b>a</b> 10-year <b>probability</b> of hip {{fracture}} ≥3% or <b>a</b> 10-year <b>probability</b> of major osteoporotic fracture ≥20% ...|$|R
2500|$|The equal <b>a</b> priori <b>probability</b> {{postulate}} therefore {{provides a}} {{motivation for the}} microcanonical ensemble described below. There are various arguments in favour of the equal <b>a</b> priori <b>probability</b> postulate: ...|$|R
30|$|The {{results in}} Tables  1 and 2 {{lead to the}} {{following}} observations: When the null hypothesis is true, we have <b>a</b> larger <b>probability</b> to accept the null hypothesis. When the alternative hypothesis is true we also have <b>a</b> larger <b>probability</b> to reject the null hypothesis. Therefore, using the test method obtained by us, we have <b>a</b> larger <b>probability</b> to make <b>a</b> correct judgment.|$|R
