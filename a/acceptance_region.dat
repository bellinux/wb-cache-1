110|74|Public
5000|$|In {{statistical}} hypothesis testing, the critical {{values of a}} statistical test are {{the boundaries of the}} <b>acceptance</b> <b>region</b> of the test. The <b>acceptance</b> <b>region</b> is the set of values of the test statistic for which the null hypothesis is not rejected. Depending on the shape of the <b>acceptance</b> <b>region,</b> there can be one or more than one critical value.|$|E
50|$|It {{is worth}} noting that the {{confidence}} interval for a parameter {{is not the same as}} the <b>acceptance</b> <b>region</b> of a test for this parameter, as is sometimes thought. The confidence interval is part of the parameter space, whereas the <b>acceptance</b> <b>region</b> is part of the sample space. For the same reason, the confidence level is not the same as the complementary probability of the level of significance.|$|E
5000|$|... #Caption: View in {{performance}} space with performance <b>acceptance</b> <b>region</b> A {{and distribution of}} performance (red) under statistical and operation variations from which WCD can be calculated. Note: Often the statistical variables itself are not correlated but the performances do so (acc. to the stretch and rotation of the ellipsoids). Also often the specifications are set by just upper or lower limits - so being straight lines. If we would plot the statistical variable space, the spec-limits would typically become nonlinear shapes. WCD makes use of both ways of looking to the yield problem.|$|E
3000|$|... 4 {{are known}} as the sample L-skewness and L-kurtosis, respectively. The sample-size-dependent 95  % <b>acceptance</b> <b>regions</b> of the sample linear moment ratios (t [...]...|$|R
40|$|The {{problem of}} the robust {{definition}} of the <b>acceptance</b> <b>regions</b> in conditionmonitoring of the vibrations of rotatingmachinery {{is related to the}} more wide field of the analysis of bivariate data. Traditional parametric techniques and innovative nonparametric methods based on the statistical concept of the data depth are presented and critically examined in the paper. The performances with respect to the robustness in the estimation of the <b>acceptance</b> <b>regions</b> are analysed by means of experimental cases of real rotatingmachinery of a power plant...|$|R
30|$|L-moments-based goodness-of-fit (GOF) {{tests were}} {{conducted}} for selection of appropriate distributions for standardized flows of individual TDPs at different stations. The L-moments-based GOF tests {{were based on the}} 95  % <b>acceptance</b> <b>regions</b> of the sample linear moment ratios defined as follows.|$|R
5000|$|If {{a sample}} of size [...] is taken from a {{population}} having a normal distribution, {{then there is a}} result (see distribution of the sample variance) which allows a test to be made of whether the variance of the population has a pre-determined value. For example, a manufacturing process might have been in stable condition for a long period, allowing a value for the variance to be determined essentially without error. Suppose that a variant of the process is being tested, giving rise to a small sample of [...] product items whose variation is to be tested. The test statistic [...] in this instance could be set to be the sum of squares about the sample mean, divided by the nominal value for the variance (i.e. the value to be tested as holding). Then [...] has a chi-squared distribution with [...] degrees of freedom. For example, if the sample size is 21, the <b>acceptance</b> <b>region</b> for [...] with a significance level of 5% is between 9.59 and 34.17.|$|E
50|$|The second {{advantage}} is an expanded launch <b>acceptance</b> <b>region</b> (LAR). The LAR defines {{the region that}} the aircraft must be within to launch the weapon and hit the target. Non-GPS based precision guided weapons using seekers to guide to the target have significant restrictions on the launch envelope due to the seeker field of view. Some of these systems (such as the Paveway I, II, and III) must be launched so that the target remains in the seeker field of view throughout the weapon trajectory (or for lock-on-after-launch engagements, the weapon must be launched so that the target is {{in the field of}} view during the terminal flight). This requires the aircraft to fly generally straight at the target when launching the weapon. This restriction is eased in some other systems (such as the GBU-15 and the AGM-130) through the ability of a Weapon System Operator (WSO) in the aircraft to manually steer the weapon to the target. Using a WSO requires a data link between the weapon and the controlling aircraft and requires the controlling aircraft to remain in the area (and possibly vulnerable to defensive fire) as long as the weapon is under manual control. Since GPS-based flight control systems know the weapon's current location and the target location, these weapons can autonomously adjust the trajectory to hit the target. This allows the launch aircraft to release the weapon at very large off-axis angles including releasing weapons to attack targets behind the aircraft.|$|E
40|$|In {{this paper}} we {{introduce}} a fuzzy chart for variables {{which is used}} in situations when uncertainty and randomness are combined. It is showed that the Shewhart chart’s control limits must be adjusted in these situations. However, this chart {{is based on a}} fuzzy <b>acceptance</b> <b>region</b> and this method arises when a decision should be made by referring to the grade of a sample statistic belonging to the fuzzy <b>acceptance</b> <b>region.</b> Peer reviewe...|$|E
40|$|In multivariate {{statistical}} analysis. orthogonally invariant sets of real positive definite pxp matrices {{occur as}} <b>acceptance</b> <b>regions</b> for tests of invariant hypotheses concerning the covariance matrix [of a multivariate normal distribution. Equivalently. orthogonally invariant <b>acceptance</b> <b>regions</b> {{can be expressed}} in terms of the eigenvalues I, (S) [...] . lp(S) of a random Wishart matrix S- Wp(n. [) with n degrees of freedom and expectation nL The probabi Iities of such regions depend on [only through A, ([) [...] . Ap([). the eigenvalues of L this paper. the behavior of these probabi Ii ties is studied when some Ai increase while others decrease. Our results will be {{expressed in terms of}} the tnejorizetion ordering applied to the vector J. l = = () l,([) [...] .) lp([)). where) lp([) = log Ap([L and have implications for the unbiaseoness and monotonicity of the power functions of orthogonally invariant tests...|$|R
40|$|Based on the {{univariate}} t-statistic from an invariant {{representation of}} multivariate data, we propose a new quantile-quantile (Q-Q) plot to detect nonmultinormality in high-dimensional data analysis. <b>Acceptance</b> <b>regions</b> for the Q-Q plot {{are provided by}} the theory of quantile processes. Using the <b>acceptance</b> <b>regions,</b> we perform a Monte Carlo study {{on the power of}} the Q-Q plot. It turns out that the new Q-Q plot is convenient and effective for routine use. It could be recommended for use together with other graphical methods and numerical methods for testing multinormality. Key Words and Phrases: graphical methods, invariant statistics, quantile-quantile plot, test of multinormality. Mathematical Subject Classification 1991 : 6209, 62 H 10, 62 H 15 1 Introduction and Summary The quantile-quantile (Q-Q) plot is one of the convenient and effective graphical methods for testing a distributional assumption in data analysis. Many authors have This work is supported by National Institute on Drug [...] ...|$|R
40|$|Abstract: At {{several places}} in the {{literature}} {{there are indications that}} many tests are optimal in the sense of Hodges-Lehmann efficiency. It is argued here that shrinkage of the <b>acceptance</b> <b>regions</b> of the tests to the null set in a coarse way is already enough to ensure optimality. This type of argument can be used to show optimality of e. g. Kolmogorov-Smirnov tests, Cram&-von Mises tests, and likelihood ratio tests and many other tests in exponential families...|$|R
30|$|Because the {{statistic}} {{is in the}} <b>acceptance</b> <b>region</b> and {{we accept}} the null hypothesis at confidence level 95 %. This emphasizes that the SM average for MOPSO is statistically higher than NSGA-II.|$|E
40|$|Most {{experiments}} that search for direct interactions of WIMP dark matter with a target can distinguish the dominant electronrecoil background from the nuclear recoil signal, {{based on some}} discrimination parameter. An <b>acceptance</b> <b>region</b> is defined inthe parameter space spanned by the recoil energy and this discrimination parameter. In {{the absence of a}} clear signal in thisregion, a limit is calculated on the dark matter scattering cross section. Here, an algorithm is presented that allows to define the <b>acceptance</b> <b>region</b> a priori such that the experiment has the best sensitivity. This is achieved through optimized acceptance regions for each WIMP model and WIMP mass that is to be probed. Using recent data from the CRESST-II experiment as anexample, it is shown that resulting limits can be substantially stronger than those from a conventional <b>acceptance</b> <b>region.</b> In an experiment with a segmented target, the algorithm developed here can yield different acceptance regions for the individual subdetectors. Hence, it is shown how to combine the data consistently within the usual Maximum Gap or Optimum Interval framework. Comment: 4 pages, 3 figure...|$|E
40|$|The Kruskal-Wallis test is a {{non-parametric}} {{test for the}} equality of K population medians. The test statistic involved {{is a measure of}} the overall closeness of the K average ranks in the individual samples to the average rank in the combined sample. The resulting <b>acceptance</b> <b>region</b> of the test however may not be the smallest region with the required acceptance probability under the null hypothesis. Presently an alternative <b>acceptance</b> <b>region</b> is constructed such that it has the smallest size, apart from having the required acceptance probability. Compared to the Kruskal-Wallis test, the alternative test is found to have larger average power computed from the powers along the evenly chosen directions of deviation of the medians. </p...|$|E
40|$|Royston {{proposed}} a normal probability plot to detect nonnormality of univariate data. The normal probability plot was provided with normalized <b>acceptance</b> <b>regions</b> to enhance its interpretability. By using {{the theory of}} spherical distributions {{and the idea of}} principal component analysis, we propose an approach to extending Royston's normal plot to detecting nonmultivariate normality in analyzing high-dimensional data. The performance of the proposed multivariate normal plot is demonstrated by Monte Carlo studies and illustrated by two real datasets. © 2009 American Statistical Association. link_to_subscribed_fulltex...|$|R
50|$|A P-P plot {{can be used}} as a {{graphical}} {{adjunct to}} a tests of the fit of probability distributions, with additional lines being included on the plot to indicate either specific <b>acceptance</b> <b>regions</b> or the range of expected departure from the 1:1 line. An improved version of the P-P plot, called the SP or S-P plot, is available, which makes use of a variance-stabilizing transformation to create a plot on which the variations about the 1:1 line should be the same at all locations.|$|R
40|$|AbstractWe {{show that}} if ϕ is an {{increasing}} convex function of the eigenvalues of a symmetric matrix argument, then Y→ϕ((YY′) 12) is a convex function. This has the consequence for the {{multivariate analysis of variance}} that statistical tests for μ= 0 which are defined by increasing convex functions of the square roots of the eigenvalues of (ZZ′) − 1 YY′ have <b>acceptance</b> <b>regions</b> which are convex in Y for fixed Z. Tests of this form have some good properties, including unbiasedness and power functions which are increasing in the noncentrality parameters...|$|R
30|$|Because the {{statistic}} {{is in the}} <b>acceptance</b> <b>region</b> and {{we accept}} the null hypothesis at confidence level 95 %. This emphasizes that the NPS average for MOPSO is statistically higher than NSGA-II. In other words, the number of non-dominated solutions of MOPSO method is more.|$|E
40|$|International audienceStatistical {{researchers}} have shown increasing interest in generating truncated multivariate normal distributions. In this paper, we only {{assume that the}} <b>acceptance</b> <b>region</b> is convex and we focus on rejection sampling. We propose a new algorithm that outperforms crude rejection method for the simulation of truncated multivariate Gaussian random variables. The proposed algorithm {{is based on a}} generalization of Von Neumann’s rejection technique which requires the determination of the mode of the truncated multivariate density function. We provide a theoretical upper bound for the ratio of the target probability density function over the proposal probability density function. The simulation results show that the method is especially efficient when the probability of the multivariate normal distribution of being inside the <b>acceptance</b> <b>region</b> is low...|$|E
30|$|Here, in our {{identity}} attack detection problem, {{we use the}} distance in the signal space and make the decision {{in comparison with the}} calculated threshold. Then, the <b>acceptance</b> <b>region</b> Ω and the detection rate are based on the specified T. If the attack is present, then our proposed null hypothesis will be rejected.|$|E
40|$|At {{several places}} in the {{literature}} {{there are indications that}} many tests are optimal in the sense of Hodges-Lehmann efficiency. It is argued here that shrinkage of the <b>acceptance</b> <b>regions</b> of the tests to the null set in a coarse way is already enough to ensure optimality. This type of argument can be used to show optimality of e. g. Kolmogorov-Smirnov tests, Cramer-von Mises tests, and likelihood ratio tests and many other tests in exponential families. AMS 1980 Subject Classifications: Primary 62 G 20; Secondary 62 F 05, 60 F 10 Hodges-Lehmann efficiency large deviations Kullback-Leibler information number exponential family goodness-of-fit tests...|$|R
40|$|In {{this note}} we {{investigate}} {{the impact of}} the recent insertion of Color Octet Model processes in PYTHIA version 6. 324, through a tuning of different PYTHIA parameters, including the low-p_T behaviour. The Non-relativistic QCD parameters have been chosen {{according to the most recent}} theoretical calculations and fits to CDF data. This analysis has been mainly focused on J/ψ and Υ prompt production, with a comparison of the Monte Carlo predictions with available data from CDF at Run I and Run II energies. A prediction at the LHC energy, within different <b>acceptance</b> <b>regions</b> (CMS-Atlas and LHCb ones), is also given...|$|R
40|$|This paper proposes {{the tests}} which {{essentially}} (except for the scale parameter of the Cauchy distribution) have the <b>acceptance</b> <b>regions</b> derived form inverting the shortest interval {{estimates for the}} parameters based on Lagrange 2 ̆ 7 s method. As the examples {{we deal with the}} problems of hypothesis testing for the parameters of the Cauchy distribution, the location parameter of the exponetial distribution and the location parameter of the Logistic distriburion. We show that these tests are unbiased. In case of Exponential distribution we propose the uniformly most powerful unbiased one-sided test for certain one-sided hypothses. Includes bibliographical reference...|$|R
40|$|This {{research}} have purpose, 1) to know development acceptance for service parking area retribution in Jambi {{city and the}} contribution for retribution in region, PAD and <b>acceptance</b> <b>region</b> in Jambi city, 2) to know effectiveness degree acceptance for service Parking area retribution ini Jambi City about acceptance resources for 2006 until 2011 period, 3) to know factors which is influence acceptance for service parking area retribution in Jambi city. Research method which is used for this research that is Analysis from primary data is got through dissemination quetiosn list and live interview with Skilled worker parking area in Jambi city. For secondary data is time series during calculation era. Result of research to show that: 1) on the average during 2006 until 2011 period, the total of <b>acceptance</b> <b>region</b> in Jambi City has growing about 11, 88...|$|E
40|$|AbstractIt {{is shown}} that the quark–antiquark {{coalescence}} mechanism for pion production allows to explain the small pseudorapidity width of the balance function observed for central collisions of heavy ions, provided effects of the finite <b>acceptance</b> <b>region</b> and of the transverse flow are taken into account. In contrast, the standard hadronic cluster model is not compatible with this data...|$|E
40|$|We use recent network {{calculus}} {{results to}} study some properties of lossless multiplexing {{as it may}} be used in guaranteed service networks. We call network calculus a set of results that apply min-plus algebra to packet networks. We provide a simple proof that shaping a traffic stream to conform to a burstiness constraint preserves the original constraints satisfied by the traffic stream We show how all rate-based packet schedulers can be modeled with a simple rate latency service curve. Then we define a general form of deterministic effective bandwidth and equivalent capacity. We find that call acceptance regions based on deterministic criteria (loss or delay) are convex, in contrast to statistical cases where it is the complement of the region which is convex. We thus find that, in general, the limit of the call <b>acceptance</b> <b>region</b> based on statistical multiplexing when the loss probability target tends to 0 may be strictly larger than the call <b>acceptance</b> <b>region</b> based on lossless mult [...] ...|$|E
40|$|In Bayesian {{statement}} of hypotheses testing, instead of unconditional problem of minimization of average risk {{caused by the}} errors {{of the first and}} the second types, there is offered to solve the conditional optimization problem when restrictions are imposed on the errors of one type and, under such conditions, the errors of the second type are minimized. Depending on the type of restrictions, there are considered different conditional optimization problems. Properties of hypotheses <b>acceptance</b> <b>regions</b> for the stated problems are investigated and, finally, comparison of the properties of unconditional and conditional methods is realized. The results of the computed example confirm the validities of the theoretical judgments...|$|R
40|$|Testing genetic markers for Hardy-Weinberg {{equilibrium}} is {{an important}} issue in genetic association studies. The HardyWeinberg package o ers the classical tests for equilibrium, functions for power computation and for the simulation of marker data under equilibrium and disequilibrium. Functions for testing equilibrium in the presence of missing data by using multiple imputation are provided. The package also supplies various graphical tools such as ternary plots with <b>acceptance</b> <b>regions,</b> log-ratio plots and Q-Q plots for exploring the equilibrium status of a large set of diallelic markers. Classical tests for equilibrium and graphical representations for diallelic marker data are reviewed. Several data sets illustrate the use of the package. Postprint (published version...|$|R
40|$|A {{class of}} {{confidence}} sets with constant coverage probability for {{the mean of}} a p-variate normal distribution is proposed through a pseudo-empirical-Bayes construction. When the dimension is greater than 2, by combining analytical results with some exact numerical calculations the proposed sets are proved to have a uniformly smaller volume than the usual confidence region. Sufficient conditions for the connectedness of the proposed confidence sets are also derived. In addition, our confidence sets {{could be used to}} construct tests for point null hypotheses. The resultant tests have convex <b>acceptance</b> <b>regions</b> and hence are admissible by Birnbaum. Tabular results of the comparison between the proposed region and other confidence sets are also given...|$|R
40|$|The call {{admission}} {{problem for}} a wireless packet switched network supporting homogeneous applications - such as a cellular voice network - is an old one and has been extensively investigated in the past. The focus of the present article is to investigate the call admission region for a TDMA (wireless) system supporting heterogeneous real-time variable bit rate (VBR) applications with distinct quality of service (QoS) requirements and traffic characteristics. The QoS is {{defined in terms of}} a maximum tolerable packet delay and dropping probability; packets may be dropped due to delay violations or channel induced errors. The call <b>acceptance</b> <b>region</b> is investigated in this article under the assumption that each user's per frame resource (slot) requests are communicated to the scheduler (resource allocation authority). The call <b>acceptance</b> <b>region</b> is shaped by the QoS that can be delivered by the up-link scheduling policy. In the beginning of this article, some mechanisms employed to inform [...] ...|$|E
40|$|Integer {{ambiguity}} {{resolution is}} an indispensable procedure for all high precision GNSS applications. The correctness {{of the estimated}} integer ambiguities {{is the key to}} achieving highly reliable positioning, but the solution cannot be validated with classical hypothesis testing methods. The integer aperture estimation theory unifies all existing ambiguity validation tests and provides a new prospective to review existing methods, which enables us to have a better understanding on the ambiguity validation problem. This contribution analyses two simple but efficient ambiguity validation test methods, ratio test and difference test, from three aspects: <b>acceptance</b> <b>region,</b> probability basis and numerical results. The major contribution of this paper can be summarized as: (1) The ratio test <b>acceptance</b> <b>region</b> is overlap of ellipsoids while the difference test <b>acceptance</b> <b>region</b> is overlap of half-spaces. (2) The probability basis of these two popular tests is firstly analyzed. The difference test is an approximation to optimal integer aperture, while the ratio test follows an exponential relationship in probability. (3) The limitations of the two tests are firstly identified. The two tests may under-evaluate the failure risk if the model is not strong enough or the float ambiguities fall in particular region. (4) Extensive numerical results are used to compare the performance of these two tests. The simulation results show the ratio test outperforms the difference test in some models while difference test performs better in other models. Particularly in the medium baseline kinematic model, the difference tests outperforms the ratio test, the superiority is independent on frequency number, observation noise, satellite geometry, while it depends on success rate and failure rate tolerance. Smaller failure rate leads to larger performance discrepancy...|$|E
3000|$|For a {{specific}} significance level α (defined as {{the probability of}} rejecting the hypothesis if it is true), there is a corresponding <b>acceptance</b> <b>region</b> Ω such that we declare the null hypothesis to be valid if an observed value of the test statistic Tobs ∈ Ω and reject the null hypothesis if Tobs Ɇ Ω. In other words, we declare that an attack is present if Tobs ∈ Ω [...]...|$|E
40|$|Karl Pearson's seminal {{article on}} the {{criterion}} is reviewed, formalized in modern notation and its method is extended beyond the normal distributions using the Mahalanobis distance as a vehicle. The extension yields a simple method, firmly rooted in history, for computing exact p-values and <b>acceptance</b> <b>regions</b> for hypotheses under a large class of probability distributions and of arbitrary dimension. As a by-product it is for example shown that the so-called method of acceptance intervals by percentiles is a univariate special case of Pearson's method. The article's content is discussed in context of other sources, in particular Pearson's The Grammar of Science, yielding a holistic approach to verification/falisfication of hypotheses through empirical observation...|$|R
30|$|Different {{experiments}} {{have been performed}} for detecting fluctuating radar targets (Gaussian targets with unknown correlation coefficient and Swerling I target with unknown Doppler shift) in AWGN, and in correlated Gaussian clutter plus AWGN. Also, the detection of non-fluctuating targets in spiky K-distributed clutter has been studied. In all the cases, the capability of learning machines (particularly, MLPs) trained to minimize the Cross-Entropy error, to approximate the optimum detector in the NP sense, has been demonstrated. To obtain a good approximation, the number of hidden neurons must be high enough. This number {{is related to the}} minimum number of hyperplanes necessary to enclose the <b>acceptance</b> <b>regions</b> of the detection problem, but this theoretical study is beyond the objective of this article.|$|R
40|$|High-dimensional {{data with}} a small sample size, such as {{microarray}} data and image data, are commonly encountered in some practical problems for which many variables have to be measured {{but it is too}} costly or time consuming to repeat the measurements for many times. Analysis of this kind of data poses a great challenge for statisticians. In this paper, we develop a new graphical method for testing spherical symmetry that is especially suitable for high-dimensional data with small sample size. The new graphical method associated with the local <b>acceptance</b> <b>regions</b> can provide a quick visual perception on the assumption of spherical symmetry. The performance of the new graphical method is demonstrated by a Monte Carlo study and illustrated by a real data set...|$|R
