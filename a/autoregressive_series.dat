14|293|Public
40|$|AbstractIt {{is shown}} that the {{positivity}} of the angle between the past and future of a multivariate stationary process is sufficient {{for the existence of}} a mean-convergent <b>autoregressive</b> <b>series</b> representation of its linear predictor. A large class of multivariate processes whose past and future are at positive angle is characterized, thus providing a matricial extension of the Helson-Szegö theorem...|$|E
40|$|The {{problem of}} change point in autoregressive process is studied in this article. We propose a Bayesian {{information}} criterion-iterated cumulative sums of squares algorithm {{to detect the}} variance changes in an <b>autoregressive</b> <b>series</b> with unknown order. Simulation results and two examples are presented, where it is shown to have good performances when the sample size is relatively small. ...|$|E
40|$|It {{is shown}} that the {{positivity}} of the angle between the past and future of a multivariate stationary process is sufficient {{for the existence of}} a mean-convergent <b>autoregressive</b> <b>series</b> representation of its linear predictor. A large class of multivariate processes whose past and future are at positive angle is characterized, thus providing a matricial extension of the Helson-Szegö theorem. q-variate stationary processes prediction theory Helson-Szego theorem Fourier series linear predictor...|$|E
40|$|A {{weighted}} rank-based (GR) {{estimate for}} estimating the parameter vector of an <b>autoregressive</b> time <b>series</b> is considered. When the weights are constant, the estimate {{is equivalent to}} using Jaeckel's estimate with Wilcoxon scores. Asymptotic linearity properties are derived for the GR-estimate. Based on these properties, the GR-estimate is shown to be asymptotically normal at rate n 1 / 2. Asymptotic normality <b>Autoregressive</b> time <b>series</b> GR-estimate R-estimate Robust...|$|R
40|$|Forecasting for {{nonlinear}} {{time series}} {{is an important}} topic in time series analysis. Existing numerical algorithms for multi-step-ahead forecasting ignore accuracy checking, alternative Monte Carlo methods are also computationally very demanding and their accuracy is difficult to control too. In this paper a numerical forecasting procedure for nonlinear <b>autoregressive</b> time <b>series</b> models is proposed. The forecasting procedure {{can be used to}} obtain approximate m-step-ahead predictive probability density functions, predictive distribution functions, predictive mean and variance, etc. for a range of nonlinear <b>autoregressive</b> time <b>series</b> models. Examples in the paper show that the forecasting procedure works very well both in terms of the accuracy of the results and in the ability to deal with different nonlinear <b>autoregressive</b> time <b>series</b> models. Copyright © 2005 John Wiley & Sons, Ltd. ...|$|R
40|$|Abstract: We {{investigate}} the stability, {{in terms of}} V-uniform ergodicity or tran-sience, of cyclic threshold <b>autoregressive</b> time <b>series</b> models. These models cycle through {{one of a number}} of collections of subregions of the state space when the process is large. Our results can be applied in cases where the model has multiple cycles and/or affine thresholds. The bounds on the parameter space are sharper than those in previous results, and are easily verified. We extend these results to <b>autoregressive</b> nonlinear time <b>series</b> that can be approximated well by a threshold model (threshold-like). Key words and phrases: ergodicity; Markov chain; nonlinear autoregressive time series; nonlinear time series; threshold <b>autoregressive</b> time <b>series...</b>|$|R
40|$|Here we derive the {{asymptotic}} distribution of an arbitrary vector of residual cross-correlations {{resulting from the}} fitting of finite autoregressions to two uncorrelated infinite order vector <b>autoregressive</b> <b>series.</b> Its {{asymptotic distribution}} is the same multivariate normal as {{the one of the}} corresponding vector of cross-correlations between the two innovation series. The application of that result for testing the uncorrelatedness of two series is also discussed. Finite autoregression Residual cross-correlations Asymptotic distribution Tests for non-correlation Portmanteau statistics...|$|E
40|$|A {{spurious}} regression {{occurs when}} a pair of independent series, but with strong temporal properties, are found apparently to be related according to standard inference in an OLS regression. Although this is well known to occur with pairs of independent unit root processes, this paper finds evidence that similar results are found with positively autocorrelated <b>autoregressive</b> <b>series</b> on long moving averages. This occurs regardless of the sample size and for various distributions of the error terms...|$|E
40|$|The {{periodic}} correlation exists {{throughout the}} whole process in a analysis of variance (ANOVA) type model where the error terms consist of a periodic autoregressive time series. This paper studies the asymptotic property of least-squares estimators and linear testable hypotheses with a modified F-test {{in the analysis of}} variance akin to periodic <b>autoregressive</b> <b>series.</b> The techniques are applied in making inference on the quarterly streamflow in Asotin, WA. Periodically correlated time series Periodic autocovariances Periodic autoregressive moving-average models Least squares estimation Analysis of variance...|$|E
25|$|An {{example of}} a non-Markovian process with a Markovian {{representation}} is an <b>autoregressive</b> time <b>series</b> of order greater than one.|$|R
40|$|The {{asymptotic}} eigenvalue {{behavior of}} unbounded Hermitian Toeplitz matrices is derived {{and used to}} evaluate the asymptotic eigenvalue distribution of the covariance matrix of possibly nonstationary <b>autoregressive</b> time <b>series.</b> As an application, the results are used to generalize the evaluation of the ratedistortion function of possibly nonstationary <b>autoregressive</b> Gaussian time <b>series</b> with a mean-squared-error fidelity criterion...|$|R
40|$|We {{show that}} Dickey & Fuller's [Distribution of the {{estimator}} for <b>autoregressive</b> time <b>series</b> with a unit root. J. Amer. Statist. Assoc. 74, 427 - 431; Likelihood ratio statistics for <b>autoregressive</b> time <b>series</b> with a unit root. Econometrica 49, 1057 - 1072] normalized estimator and F-statistics for the unit root null hypothesis will spuriously reject {{the null hypothesis}} {{if there is a}} break in the innovation variance relatively early in the sample. Unit root Innovation break Normalized estimator Dickey-Fuller F-statistics...|$|R
40|$|A {{discrete}} time {{model for}} asset price changes is considered. The volatility process underlying these changes is modeled as a first-order Gaussian <b>autoregressive</b> <b>series.</b> Inversion of the marginal characteristic {{function of the}} return process simplifies {{the assessment of the}} tail behaviour of the probability density function of returns. The Generalized Method of Moments (GMM) is used to calibrate the model and implement an overidentification test. Daily Euro/USD, Pound/USD, AUD/USD, and Yen/USD exchange rates over the period January 1999 to October 2006 are used to illustrate the methods. 6 page(s...|$|E
40|$|AbstractIn {{this paper}} we propose a new {{approach}} for estimating the unknown parameter in the stochastic linear regressive model with stationary ergodic sequence of covariates. Under mild conditions on the joint distribution of the covariate and the error, the estimator constructed is shown to be strongly consistent in two important special cases: (1) The sequence of (variate, covariate) is independent identically distributed (i. i. d.), and (2) the sequence of variates is a stationary <b>autoregressive</b> <b>series.</b> The asymptotical normality is also discussed under more assumptions on the distribution of the covariate...|$|E
40|$|The mixture {{transition}} distribution (MTD) {{model was}} introduced by Raftery (1985) as a parsimonious model for high-order Markov chains. It is flexible, can {{a wide range of}} patterns, can be physically motivated, data well, and appears to be a discrete-valued analogue for the class of <b>autoregressive</b> <b>series</b> models. However, estimation has presented difficulties because the space is highly nonconvex, being defined by a large number of nonlinear constraints. we propose an computational algorithm for maximum likelihood is on a way of reducing the of also stnlcttlred verSl 011 S of Away apli>liE!d to a sequence...|$|E
40|$|Though actuaries have {{developed}} {{several types of}} stochastic investment models for inflation, stock market returns, and interest rates, there are two commonly used in practice: <b>autoregressive</b> time <b>series</b> models with normally distributed errors, and autoregressive conditional heteroscedasticity (ARCH) models. ARCH models are particularly suited when there is heteroscedasticity in inflation and interest rate series. In such cases nonnormal residuals {{are found in the}} empirical data. This paper examines whether Australian univariate inflation and interest rate data are consistent with <b>autoregressive</b> time <b>series</b> and ARCH model assumptions...|$|R
40|$|Self-exciting {{threshold}} <b>autoregressive</b> time <b>series</b> {{models have}} been used extensively, and the conditional mean obtained from these models {{can be used to}} predict the future value of a random variable. In this paper we consider quantile forecasts of a time series based on the quantile self-exciting threshold <b>autoregressive</b> time <b>series</b> models proposed by Cai and Stander (2008) and present a new forecasting method for them. Simulation studies and application to real time series show that the method works very well. Copyright 2010, Oxford University Press. ...|$|R
40|$|This paper {{introduces}} {{a new class}} of estimates for estimating the parameters of a vector <b>autoregressive</b> time <b>series.</b> The estimates minimize a sum of weighted pairwise Euclidean distances and extend the univariate GR-estimates of Terpstra et al. (Statist. Probab. Lett. 51 (2001) 165; Statist. Inference Stochastic Process. 4 (2001) 155) to the multivariate model. Asymptotic linearity properties are derived for the so called MGR-estimate. Based on these properties, the MGR-estimate is shown to be asymptotically normal at rate n 1 / 2. Asymptotic normality GR-Estimates MGR-Estimates Robust Vector <b>autoregressive</b> time <b>series...</b>|$|R
40|$|In {{this paper}} we propose a new {{approach}} for estimating the unknown parameter in the stochastic linear regressive model with stationary ergodic sequence of covariates. Under mild conditions on the joint distribution of the covariate and the error, the estimator constructed is shown to be strongly consistent in two important special cases: (1) The sequence of (variate, covariate) is independent identically distributed (i. i. d.), and (2) the sequence of variates is a stationary <b>autoregressive</b> <b>series.</b> The asymptotical normality is also discussed under more assumptions on the distribution of the covariate. Asymptotic normality autoregressive model consistent estimator robustness stochastic regressive model...|$|E
40|$|We propose Significance-Offset Convolutional Neural Network, a deep {{convolutional}} {{network architecture}} for regression of multivariate asynchronous time series. The model {{is inspired by}} standard autoregressive (AR) models and gating mechanisms used in recurrent neural networks. It involves an AR-like weighting system, where the final predictor is obtained as a weighted sum of adjusted regressors, while the weights are data-dependent functions learnt through a convolutional network. The architecture was designed for applications on asynchronous time series and is evaluated on such datasets: a hedge fund proprietary dataset of over 2 million quotes for a credit derivative index, an artificially generated noisy <b>autoregressive</b> <b>series</b> and household electricity consumption dataset. The proposed architecture achieves promising results as compared to convolutional and recurrent neural networks. The code for the numerical experiments and the architecture implementation is shared online to make the research reproducible. Comment: Under review by the 31 st Conference on Neural Information Processing Systems (NIPS 2017...|$|E
40|$|A {{spurious}} regression {{occurs when}} a pair of independent series, but with strong temporal properties, are found apparently to be related according to standard inference in an OLS regression. Although this is well known to occur with pairs of independent unit root processes, this paper finds evidence that similar results are found with positively autocorrelated <b>autoregressive</b> <b>series</b> on long moving averages. This occurs regardless of the sample size and for various distributions of the error terms. Keywords: Autoregressions, Spurious Regressions, Inference JEL Classification: C 22 1. Introduction Suppose that X t, Y t are a pair of time series independent {{of each other and}} that the regression X t =a+bY t +u t (1. 1) is run using a standard least squares program which will also provide a t-statistic for the estimate of b. A "spurious relationship" can be said to have been found if the modulus of this t-statistic is greater than 1. 96. If X t, Y t are a pair of independent white noise [...] ...|$|E
40|$|Problems of robust {{statistical}} forecasting are considered for <b>autoregressive</b> time <b>series</b> observed under distortions generated by interval censoring. Three types of robust forecasting statistics are developed; meansquare risk is evaluated for the developed forecasting statistics. Numerical results are given...|$|R
40|$|<b>Autoregressive</b> time <b>series</b> {{observed}} under right censoring are considered. Sta- tistical estimators of autoregression model {{parameters are}} constructed {{by using the}} method of moments for special auxiliary time series. Consistency of con- structed estimators are proved under some additional general conditions...|$|R
40|$|We {{propose the}} quasi-maximum {{likelihood}} method {{to estimate the}} parameters of an RCA(1) process, i. e. a random coefficient <b>autoregressive</b> time <b>series</b> of order 1. The strong consistency and the asymptotic normality of the estimators are derived under optimal conditions. Copyright 2006 Blackwell Publishing Ltd. ...|$|R
40|$|The Electroencephalogram (EEG) {{is widely}} used in {{clinical}} and psychological situations, but it is often seriously obscured by ocular artefacts (OAs) resulting from movements in the ocular system (eyeball, eyelids etc). 'The work described in this thesis {{is concerned with the}} problems of OAs in the human EEG, their removal both off-line and on-line, and the design and development of an on-line OA removal system, together with a critical review of the literature on the subject. The work of Jervis and his co-workers was extended to further study OAs, to obtain improved measures of the effectiveness of OA removal, and to find the most effective model for removing OA on-line. A number of criteria were devised to compare the performance of several models, including a more reliable pictorial method. It was found unnecessary to use the vertical and horizontal EOGs for both eyes (ie. four EOGs) in a removal model, as previously reported. This was shown to be due to strong correlation between the EOGs. It was shown that the assumption of uncorrelated error terms, implicit in present removal models, is invalid. To remedy this, the error terms were modelled as an <b>autoregressive</b> <b>series.</b> New on-line removal algorithms based on numerically stable factorization algorithms were developed. Compared to the present on-line methods the algorithms are superior, requiring no subjective manual adjustments, or the co-operation of subjects which cannot always be guarranteed. The algorithms were shown to give similar results to their off-line equivalents. A simpler algorithm based on the present on-line method is also proposed as an alternative, but may lead to a reduced performance. An important part of this research lay in the application of the results to the design and development of a new automatic OA removal system utilizing the algorithms described above. Department of Neurological Sciences, Freedom Fields Hospital, Plymout...|$|E
40|$|A paper {{presented}} at ICSV 13 - Thirteenth International Congress on Sound and Vibration, held in Vienna, Austria, July 2 - 6, 2006 In this paper a novel approach is proposed for vibration based fault detection studies by the tracking of pole movements in the complex z domain. Vibration signals obtained from the ball bearings from a High Vacuum (HV) and Low Vacuum (LV) ends of a dry vacuum pump run in normal and fault conditions are modeled as time variant AR (<b>Autoregressive)</b> <b>series.</b> The positions of the poles which are {{the roots of the}} AR coefficient polynomial vary for every frame of vibration data. It is a known fact that as defects such as spalls and cracks start to appear on the ball bearings, the amplitude of the vibrations of characteristic defect frequencies increase. Faults can be predicted by movement of poles in the complex plane as the pole positions are expected to move closer to the unit circle as the severity of the defect increases. The area of the region swept by the migratory poles loci and their distances from the unit circle can be useful fault indicators. From the position of the poles inside the unit circle, classification and quantification of the main spectral peak of defect frequencies can be easily performed, leading to the possibility of having frame to frame monitoring of spectral parameters of interest. The AR pole positions also allow an easier quantitative estimation of the spectral parameters. The pole representation facilitates the easier understanding of the spectral characteristics of the process because of the one-to-one correspondence between the poles and the AR spectral peaks. This method has interesting potential applications in condition monitoring and diagnostic applications. The description of the movement of the poles is shown to be particularly important for the study of harmonic components of the signal. This analysis has been validated with actual data obtained from the pump and initial results obtained are very promising...|$|E
40|$|Within {{the last}} years several methods for the {{analysis}} of nonlinear <b>autoregressive</b> time <b>series</b> have been proposed. As in linear autoregressive models main problems are model identification, estimation and prediction. A boosting method is proposed that performs model identification and estimation simultaneously within the framework of nonlinear <b>autoregressive</b> time <b>series.</b> The method allows to select influential terms from a large numbers of potential lags and exogenous variables. The influence of the selected terms is modelled by an expansion in basis function allowing for a flexible additive form of the predictor. The approach is very competitive in particular in high dimensional settings where alternative fitting methods fail. This is demonstrated by means of simulations and two applications to real world data. ...|$|R
40|$|Hidden Markov {{models are}} {{extensions}} of Markov models where each observation {{is the result}} of a stochastic process in one of several unobserved states. Though favored by many scientists because of its unique and applicable mathematical structure, its independence assumption between the consecutive observations hampered further application. Autoregressive hidden Markov model is a combination of <b>autoregressive</b> time <b>series</b> and hidden Markov chains. Observations are generated by a few <b>autoregressive</b> time <b>series</b> while the switches between each <b>autoregressive</b> time <b>series</b> are controlled by a hidden Markov chain. In this thesis, we present the basic concepts, theory and associated approaches and algorithms for hidden Markov models, time <b>series</b> and <b>autoregressive</b> hidden Markov models. We have also built a bivariate autoregressive hidden Markov model on the temperature data from the Pacific Ocean to understand the mechanism of El Nino. The parameters and the state path of the model are estimated through the Segmental K-mean algorithm and the state estimations of the autoregressive hidden Markov model have been compared with the estimations from a conventional hidden Markov model. Overall, the results confirm the strength of the autoregressive hidden Markov models in the El Nino study and the research sets an example of ARHMM's application in the meteorology...|$|R
40|$|This {{paper is}} {{concerned}} with forecasting univariate seasonal time series data using periodic autoregressive models. We show how one should account for unit roots and deterministic terms when generating out-of-sample forecasts. We illustrate the models for various quarterly UK consumption <b>series.</b> Forecasting;periodic <b>autoregressive</b> time <b>series</b> models...|$|R
40|$|When {{considering}} {{the stability of}} a nonlinear time series, verifying aperiodicity, irreducibility and smoothness of the transitions for the corresponding Markov chain is often the first step. Here, we provide reasonably general conditions applicable to nonlinear <b>autoregressive</b> time <b>series,</b> including many with nonadditive errors. [psi]-Irreducibility Aperiodicity T-chain Feller chain...|$|R
40|$|Abstract: We {{determine}} the limiting behavior of near–integrated first–order random coefficient <b>autoregressive</b> RCA(1) time <b>series.</b> It is {{shown that the}} asymptotics of the finite dimensional distributions crucially depends on how the critical value 1 is approached, which determines whether the process is near–stationary, has a unit–root or is mildly explosive. In a second part, we derive the limit distribution of the serial correlation coefficient in the near–stationary and the mildly explosive setting under very general conditions on the parameters. The results obtained are in accordance with those available for first–order <b>autoregressive</b> time <b>series</b> and can hence serve as addition to existing literature in the area...|$|R
40|$|AbstractIt {{is shown}} that the {{likelihood}} ratio of an <b>autoregressive</b> time <b>series</b> of finite order with a regression trend is asymptotically normal. This result is used to derive {{the power of a}} test for positive correlation of the residuals under local autoregressive alternatives. The test is based on the Durbin-Watson statistics...|$|R
40|$|This note {{establishes}} the asymptotic normality of the median {{of the absolute}} residuals and the median of the absolute differences of pairwise residuals in the first order explosive <b>autoregressive</b> time <b>series.</b> These estimators are useful for obtaining some scale invariant estimators of the autoregressive parameter. (C) 2017 Elsevier B. V. All rights reserved...|$|R
40|$|Tests for shift {{detection}} in locally-stationary <b>autoregressive</b> time <b>series</b> {{are constructed}} which resist contamination by {{a substantial amount}} of outliers. Tests based on a comparison of local medians standardized by a highly robust estimate of the variability show reliable performance in a broad variety of situations if the thresholds are adjusted for possible autocorrelations...|$|R
40|$|Many {{economics}} and finance time series are non-Gaussian. In this paper, we propose a Bayesian approach to non-Gaussian <b>autoregressive</b> time <b>series</b> models via quantile functions. This approach is parametric, so we also compare the proposed parametric approach with a semi-parametric approach. Simulation studies and applications to real time series {{show that this}} method works very well. ...|$|R
40|$|The 3 -dimensional {{conformation}} {{of proteins}} {{is an active}} research area that has received much attention. Much of the statistical modelling of these conformations has been investigated with bivariate circular models (see for example Singh et al. (2002), Mardia et al. (2003)). In this poster we consider three first order <b>autoregressive</b> time <b>series</b> models for univariate directiona...|$|R
