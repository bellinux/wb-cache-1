2|1439|Public
5000|$|Business {{interruption}} costs reach $325 {{billion in}} addition to the $400 billion required for property repair costs, meaning that an ARkStorm could cost a total of $725 billion, nearly 3 times the amount of damage predicted by the California ShakeOut authors for a severe Southern California earthquake, an event with roughly the same <b>annual</b> <b>occurrence</b> <b>probability.</b>|$|E
40|$|The new French dam safety {{regulation}} classifies each dam in 4 classes depending on its height and {{the volume of}} water it stores. The first two classes require each owner to establish a safety report for an authority review. A main objective of this report is to demonstrate that all hazardous scenarios have been taken into account by the dam owner in assessing the risk level and also that sufficient safety measures have been specified to reach a global risk as low as reasonably possible. First, considering all existing data and characteristics of the dam, the owner has {{to carry out a}} risk analysis to identify all failure modes that may occur on dam structure and hydraulic equipment. Every potential accident is then characterised in terms of severity of consequences and <b>annual</b> <b>occurrence</b> <b>probability.</b> The severity level is assessed quantitatively or qualitatively, using a combination of maps representing the effects of the flood waves and the Population At Risks. The probability is assessed using a semi-quantitative method analyzing all scenarios and safety measures involved in prevention and protection: the bow-tie approach. This cross analysis implements an iterative approach to highlight complementary measures and recommendations and therefore enhance global safety level...|$|E
40|$|The {{purpose of}} this {{dissertation}} is to provide the means for contingency planners for regional earthquake risk mitigation to systematically determine how much to spend on mitigation versus post-event reconstruction and to prioritize alternative mitigation and reconstruction options. This dissertation is organized into three chapters. The focus of chapter one {{is the development of}} a method to estimate earthquake hazard for use in regional loss estimation. The method includes formulation of a linear program that selects a small subset of earthquake scenarios from a library of such events and estimates hazard-consistent <b>annual</b> <b>occurrence</b> <b>probabilities</b> so that their combined effect on the region of interest approximates that described by r-year return period for all possible events. The method is reproducible, computationally tractable, and results in earthquake scenarios, which are easily understood. We apply it to the identification of earthquake scenarios for Tehran, Iran. The second chapter develops an optimization model to help highly seismically active developing countries decide: (1) How much should be spent on pre-earthquak...|$|R
40|$|The {{residents}} of Mexico City face serious problems of air pollution. Identifying the most representative scenarios for the transport and dispersion of air pollutants requires {{the knowledge of}} the main wind circulation patterns. In this paper, a simple method to recognize and characterize the wind circulation patterns in a given region is proposed and applied to the Mexico City winds (2001 – 2006). This method uses a lattice wind approach to model the local wind events at the meso-β scale, and hierarchical cluster analysis to recognize their agglomerations in their phase space. Data of the meteorological network of Mexico City was used as input for the lattice wind model. The Ward’s clustering algorithm with Euclidean distance was applied to organize the model wind events in seasonal clusters for each year of the period. Comparison of the hourly population trends of these clusters permitted the recognition and detailed description of seven circulation patterns. These patterns resemble the qualitative descriptions of the Mexico City wind circulation modes reported by other authors. Our method, however, permitted also their quantitative characterization in terms of the wind attributes of velocity, divergence and vorticity, and an estimation of their seasonal and <b>annual</b> <b>occurrence</b> <b>probabilities,</b> which never before were quantified...|$|R
40|$|At Rothera Research Station (67. 3 °S, 68. 1 °W), Antarctica, 296 h {{of day and}} {{nighttime}} Fe-Boltzmann temperature lidar {{data were}} accumulated in 2003. During this time, sporadic iron layers (FeS) were observed with an <b>annual</b> average <b>occurrence</b> <b>probability</b> of 14 %. The peak altitude of the FeS layers was highest during the summer, with a fitted value of 103 km while during the winter the layer decreased in height to 90 km with an annual average of 97 km. The atmospheric temperature perturbations and potential energy density profiles computed from the same lidar data exhibited increased temperature but constant-with-height potential energy density when sporadic Fe layer occurred. Once sporadic Fe layers disappeared, the potential energy density decreased with height, indicating an energy loss due to atmospheric gravity wave breaking. These results suggest a link between FeS and atmospheric dynamics...|$|R
40|$|The {{aim of this}} {{investigation}} was an assessment of the application effectiveness of three alternatives for rainwater harvesting systems for individual households, in central Great Poland climatic conditions. During the study the amount of storm water, which can be collected from the 3 different size roof areas (80, 135, 185 m 2) was assessed, in relation to the needs of a four-person family, for the region of the Tarnowo Podgórne. The receivable amount of rainwater was analysed at a rate of 10, 25, 50 % of total <b>annual</b> precipitation <b>occurrence</b> <b>probability,</b> including the lower values, appeared in the period of 1960 - 2008. For the financial efficiency evaluation of investment, an indicator of the average annual cost per unit (Ws) and the net present value (NPV) were used. The results show that for the Great Poland region with the average annual sum of precipitation of 550 mm, only the roof surfaces of 185 m 2 and bigger allow obtaining the profits from collected rainwater and reimbursement for building rainwater harvesting installations within 30 years of its operation...|$|R
40|$|The {{purpose of}} this {{dissertation}} is to provide the means for contingency planners for regional earthquake risk mitigation to systematically determine how much to spend on mitigation versus post-event reconstruction and to prioritize alternative mitigation and reconstruction options. This dissertation is organized into three chapters. The focus of chapter one {{is the development of}} a method to estimate earthquake hazard for use in regional loss estimation. The method includes formulation of a linear program that selects a small subset of earthquake scenarios from a library of such events and estimates hazard-consistent <b>annual</b> <b>occurrence</b> <b>probabilities</b> so that their combined effect on the region of interest approximates that described by r-year return period for all possible events. The method is reproducible, computationally tractable, and results in earthquake scenarios, which are easily understood. We apply it to the identification of earthquake scenarios for Tehran, Iran. The second chapter develops an optimization model to help highly seismically active developing countries decide: (1) How much should be spent on pre-earthquake mitigation versus waiting until after an event and paying for reconstruction or simply not rebuilding damaged buildings?; (2) Which buildings should be mitigated and how?; and (3) Which buildings should be reconstructed and how? It extends previously developed optimization models to consider the particular issues that arise in such countries. First, the model allows for the possibility that some damaged buildings will not be reconstructed immediately and keeps track of any lost building inventory. Second, it allows the set of possible mitigation alternatives to be both the upgrade of a particular structural type or a change in the structural type. Third, the model relaxes the assumption that all buildings should be reconstructed to their pre-earthquake condition. Finally, it includes as one objective minimizing the chance of an extremely high death toll in any one earthquake as well as minimizing the average annual death toll across earthquakes. This chapter incorporates the results from the first chapter into a case study analysis for Tehran, Iran The focus of the third chapter is the introduction of equity into this type of analysis. NSF CMS- 0555738 NSF CMS- 040857...|$|R
40|$|<b>Occurrence</b> <b>probabilities</b> of open, shadowed {{and blocked}} {{propagation}} states are analyzed for Ottawa and Bells Corners, Canada, and Lillestrøm, Norway. Hemispherical photographs with pixels sorted into these three states {{are used to}} determine average path state <b>occurrence</b> <b>probabilities</b> {{as a function of}} azimuth and zenith angle. Two-dimensional state <b>occurrence</b> <b>probability</b> maps are compared with models depending on zenith angle only. These results are used to estimate the path-state <b>occurrence</b> <b>probabilities</b> for a low-earth-orbit system using the single highest satellite. Azimuthal asymmetry appears to increase in importance with both building height and the regularity of building location (e. g., on a grid) ...|$|R
3000|$|The <b>occurrence</b> <b>probability</b> of CFP is {{determined}} by the number of nodes and the CW size. There are two conditions in CFP. First, if a node successfully transmits its data packets, the CFP <b>occurrence</b> <b>probability</b> is 1 /CW because only one node may obtain a Backoff value of 0 (condition (1)). Second, if multiple nodes transmit data packets simultaneously, the average CFP <b>occurrence</b> <b>probability</b> is 1 - (1 - 1 /CW) [...]...|$|R
30|$|<b>Occurrence</b> <b>probability</b> of {{scenario}} s.|$|R
30|$|From {{the above}} {{analysis}} on the <b>occurrence</b> <b>probability</b> of CFP, the <b>occurrence</b> <b>probability</b> of CFP is very low when using the DCW method. This also implies that in situations where the number of nodes propagates, the impact of CFP may be neglected.|$|R
40|$|The three short {{baselines}} radio interferometer {{system at}} Awara campus in Fukui University of Technology {{has been used}} for study of Jovian decameter radiation (DAM) for 9 years since 2001. DAM is concerned with Jovian auroral phenomena and its <b>occurrence</b> <b>probability</b> reflects the activity of Jovian magnetosphere. Since the discovery, it has been well known that the <b>occurrence</b> <b>probability</b> of DAM shows a long-term time variation with nearly 12 -year periodicities in the past 50 years, however, the observation results at Awara campus from 2003 have showed the observed <b>occurrence</b> <b>probability</b> has been remained below the probability expected based on traditional observation results. We have paid attention to change in the <b>occurrence</b> <b>probability</b> and report the observation result in 2009...|$|R
40|$|Abstract niet beschikbaarIn {{this report}} the <b>occurrence</b> <b>probability</b> of 700 plant species has been {{described}} in relation to soil moisture, pH, nutrient availability, and salt. <b>Occurrence</b> <b>probability</b> is expressed with simple regression statistics in terms of semi- quantitative Ellenberg indication values. Analysis {{is based on a}} very large national data base of vegetation recordings. For each ecoregion of the Netherlands the <b>occurrence</b> <b>probability</b> of the plant species has been analysed separately. Results, regional differences and possible applications in the field of scenario studies and standard setting are discussed...|$|R
40|$|In {{our earlier}} papers [7, 6, 5] we {{introduced}} the formalism of probabilistic languages for modeling the stochastic qualitative behavior of discrete event systems (DESs). We presented {{a framework for}} their supervisory control in [11], where control is exercised by dynamically disabling certain controllable events thereby nulling the <b>occurrence</b> <b>probabilities</b> of disabled events, and increasing the <b>occurrence</b> <b>probabilities</b> of enabled events proportionately. The control objective is to design a supervisor such that the controlled system never executes any illegal traces (their <b>occurrence</b> <b>probability</b> is zero), and legal traces occur with minimum prespecified <b>occurrence</b> <b>probabilities.</b> In other words, the probabilistic language of the controlled system lies within a prespecified range, where the upper bound is a "non-probabilistic language" representing a legality constraint. In [11] we provided a condition {{for the existence of}} a supervisor, and also presented an algorithm to test this conditi [...] ...|$|R
40|$|We {{present a}} study of {{statistical}} relationships between the G condition, F 1 -layer and NmF 2 negative disturbance <b>occurrence</b> <b>probabilities</b> and geomagnetic and solar activity indices Kp and F 10. 7, season, and geomagnetic latitude, busing experimental data acquired by the Ionospheric Digital Database of the National Geophysical Data Center, Boulder, Colorado from 1957 to 1990. It is shown that the dependence of the G condition <b>occurrence</b> <b>probability,</b> yG, on Kp is mainly determined by processes that control the behaviour of the F 2 layer with Kp changes. We found that the relationship for log yG versus Kp {{is very close to}} the linear one. The G condition <b>occurrence</b> <b>probability</b> decreases from 0. 55 % to 0. 17 % as the value of&nbsp; F 10. 7 increases from low to middle values, reaches its minimum at the middle solar activity level of F 10. 7 = 144 – 170, increasing from the minimum value of 0. 17 % to 0. 49 % when the F 10. 7 index increases from the middle solar activity level to F 10. 7 = 248 – 274. Interhemispheric asymmetry is found for the G condition <b>occurrence</b> <b>probability</b> in the ionosphere, with a stronger enhancement seen in the magnetic latitude range close to the northern magnetic pole and a deep minimum of the G condition <b>occurrence</b> <b>probability</b> in the low magnetic latitude range from – 30 ° to 30 °. The measured magnetic latitude variation of the F 1 -layer <b>occurrence</b> <b>probability</b> is also asymmetrical relative to the geomagnetic equator. Our results provide additional evidence the F 1 -layer {{is more likely to be}} formed in summer than in winter. The Northern Hemisphere peak F 1 -layer <b>occurrence</b> <b>probability</b> is found to exceed that in the Southern Hemisphere. The G condition <b>occurrence</b> <b>probability</b> has maximum values of 0. 91 and 0. 75 % in summer, and minimum values of 0. 01 and 0. 05 % in winter for the Northern and Southern Hemisphere, respectively. Key words. Ionosphere; ion chemistry and composition; ionosphere-atmosphere interactions; ionospheric disturbance...|$|R
40|$|International audienceWe {{present a}} study of {{statistical}} relationships between the G condition, F 1 -layer and Nm F 2 negative disturbance <b>occurrence</b> <b>probabilities</b> and geomagnetic and solar activity indices Kp and F 10. 7, season, and geomagnetic latitude, busing experimental data acquired by the Ionospheric Digital Database of the National Geophysical Data Center, Boulder, Colorado from 1957 to 1990. It is shown that the dependence of the G condition <b>occurrence</b> <b>probability,</b> y G, on Kp is mainly determined by processes that control the behaviour of the F 2 layer with Kp changes. We found that the relationship for log y G versus Kp {{is very close to}} the linear one. The G condition <b>occurrence</b> <b>probability</b> decreases from 0. 55 % to 0. 17 % as the value of F 10. 7 increases from low to middle values, reaches its minimum at the middle solar activity level of F 10. 7 = 144 ? 170, increasing from the minimum value of 0. 17 % to 0. 49 % when the F 10. 7 index increases from the middle solar activity level to F 10. 7 = 248 ? 274. Interhemispheric asymmetry is found for the G condition <b>occurrence</b> <b>probability</b> in the ionosphere, with a stronger enhancement seen in the magnetic latitude range close to the northern magnetic pole and a deep minimum of the G condition <b>occurrence</b> <b>probability</b> in the low magnetic latitude range from ? 30 ° to 30 °. The measured magnetic latitude variation of the F 1 -layer <b>occurrence</b> <b>probability</b> is also asymmetrical relative to the geomagnetic equator. Our results provide additional evidence the F 1 -layer {{is more likely to be}} formed in summer than in winter. The Northern Hemisphere peak F 1 -layer <b>occurrence</b> <b>probability</b> is found to exceed that in the Southern Hemisphere. The G condition <b>occurrence</b> <b>probability</b> has maximum values of 0. 91 and 0. 75 % in summer, and minimum values of 0. 01 and 0. 05 % in winter for the Northern and Southern Hemisphere, respectively...|$|R
40|$|The {{purpose of}} this paper is to propose the method of {{reliability}} evaluation for structural systems using the higher-order moment standardization technique. In the reliability evaluation of structural systems, it is necessary to calculate the joint <b>occurrence</b> <b>probability</b> of multiple failure events that the system has. This paper formulates the joint <b>occurrence</b> <b>probability</b> of multiple failure events using the moments alone in a form that includes the non-Gaussian property of probability distribution. A method of reliability evaluation for structural systems is proposed by using the joint <b>occurrence</b> <b>probability.</b> Failure probabilities of several types of frame structure are calculated through the proposed method. The solutions by the proposed method agree with those by Monte Carlo simulation with sufficient precision...|$|R
30|$|The three {{relationships}} of {{the dependence of}} ESF occurrence on the PRE were discussed above. The first one {{is that there is}} a threshold PRE for the generation of ESF (Abdu et al. 1983; Basu et al. 1996; Fejer et al. 1999; Anderson et al. 2004; Smith et al. (2016)). In this scenario, ESF will either occur for a PRE of larger than the threshold or not occur for a PRE of smaller than the threshold. In contrast, the <b>occurrence</b> <b>probability</b> of ESF in other two relationships means that the <b>occurrence</b> <b>probability</b> of ESF depends on the PRE: linear increase of the ESF <b>occurrence</b> <b>probability</b> with the PRE (Su et al. 2008; Kil et al. 2009) or a continuous probability distribution as a function of the PRE (Huang and Hairston 2015). Occurrence of ESF is assured only for the PRE values where the <b>occurrence</b> <b>probability</b> is 100 %, and non-occurrence of ESF is assured only for the PRE values where the <b>occurrence</b> <b>probability</b> is zero. For all other PRE values, ESF may occur or not occur, although the <b>probability</b> for <b>occurrence</b> can be different.|$|R
30|$|The ACP scheme needs a {{training}} phase {{in order to}} assign the <b>occurrence</b> <b>probability</b> to each node. If the <b>occurrence</b> <b>probabilities</b> are not accurate, the compressed provenance size will deviate from the optimum size {{that can be achieved}} by arithmetic coding. Furthermore, the ACP scheme requires transmitting two real numbers to define the coding interval, which expands the provenance size.|$|R
40|$|To ensure {{performance}} of large-diameter bored piles, integrity tests are often conducted after pile construction. It is often impractical to inspect 100 % of piles {{due to high}} costs and possible delays. Accordingly, the presence of defects may not be fully detected as {{only a limited number}} of piles can be inspected. The defect sizes may also be insufficiently predicted based on limited tests. This paper proposes a procedure to predict the <b>occurrence</b> <b>probability</b> of defect and the defect size for piles at a site based on coring examinations supplemented with engineers' experiences. This procedure is formalized in the Bayesian framework. To update and estimate the <b>occurrence</b> <b>probability</b> and size of pile defects, the concepts of <b>occurrence</b> <b>probability</b> of defect and encounter probability are presented. Then, a method to evaluate the encounter probability is formulated. The <b>occurrence</b> <b>probability</b> of defect is updated based on results from on-site coring. After measurements on encountered defects are taken, the defect size distribution is updated using the proposed procedure. Results from numerical examples indicate that the <b>occurrence</b> <b>probability</b> of defect can be estimated using the proposed procedure in a more rational way. The inspection results from on-site coring have a significant influence on the estimated <b>occurrence</b> <b>probability</b> of defect. The uncertainty in defect size is substantially reduced after being updated with the information on defect sizes from on-site coring. Analysis results can assist the specification of pile inspection program to assure given level of quality assurance. (C) 2006 Elsevier Ltd. All rights reserved...|$|R
40|$|The project Hydropedological Map of the Republic of Croatia was {{implemented}} using the ESRI program package. It includes the Basic Hydropedological Map with the attribute database of hydropedological mapping units, pedological and hydropedological profi les and hydrological and hydropedological parameters. The cartographic attribute database of the Basic Hydropedological Map comprises hydropedological units – types of moistening by surface water and/or ground water. The soil water retention capacity of particular hydropedological units varies from 248 to 635 mm/m, water infiltration into soil ranges from 0. 01 to 7. 32 m/day, hydraulic conductivity for 1 m soil depth is from 0. 01 to 6. 84 m/day, and from 0. 01 to 15. 6 m/day for 2 m depth. Annual effective precipitation of 25 % <b>occurrence</b> <b>probability</b> varies from 551 to 2294 mm, {{and that of}} 75 % <b>occurrence</b> <b>probability</b> is between 272 and 1180 mm. Maximum one-day runoff coefficient in the conditions of different soil texture and different vegetative cover ranges from 0. 24 to 0. 94 (25 % probability) and from 0. 02 to 0. 89 (75 % probability). Water deficit in soils of different texture (25 % <b>occurrence</b> <b>probability)</b> varies annually from 0. 0 to 513 mm/m, and deficit of 75 % <b>occurrence</b> <b>probability</b> varies from 30 to 857 mm/m. Water surplus in soils of different texture (25 % <b>occurrence</b> <b>probability)</b> varies annually from 57 do 1686 mm/m, and surplus of 75 % <b>occurrence</b> <b>probability</b> ranges from 0. 0 to 606 mm/m. The Applied Hydropedological Map of the Republic of Croatia comprises priority amelioration units for agricultural land reclamation and management...|$|R
3000|$|Higher {{overconfidence}} {{leads to}} lower estimated risk <b>occurrence</b> <b>probability</b> through {{the mediation of}} risk awareness.|$|R
40|$|FIGURE 7. <b>Occurrence</b> <b>probability</b> for Otomops harrisoni sp. nov. (A) and O. martiensseni s. s. (B) in Africa and the Arabian Peninsula. Ecological niche {{models were}} {{generated}} {{based on current}} altitude and bioclimatic variables, and known occurrence records (indicated by the orange circles) for each species. Shading depicts the various grades of <b>occurrence</b> <b>probability</b> (based on habitat suitability), ranging from low (0) to high (1. 00) suitability...|$|R
40|$|We {{present a}} study of {{statistical}} relationships between the G condition, F 1 -layer and Nm F 2 negative disturbance <b>occurrence</b> <b>probabilities</b> and geomagnetic and solar activity indices Kp and F 10. 7, season, and geomagnetic latitude, busing experimental data acquired by the Ionospheric Digital Database of the National Geophysical Data Center, Boulder, Colorado from 1957 to 1990. It is shown that the dependence of the G condition <b>occurrence</b> <b>probability,</b> y G, on Kp is mainly determined by processes that control the behaviour of the F 2 layer with Kp changes. We found that the relationship for log y G versus Kp {{is very close to}} the linear one. The G condition <b>occurrence</b> <b>probability</b> decreases from 0. 55...|$|R
40|$|For {{obtaining a}} zero defect level, a high fault {{coverage}} {{with respect to}} the stuck-at fault model is often not sufficient as there are many defects that show a more complex behavior. In this paper, a method is presented for computing the <b>occurrence</b> <b>probabilities</b> of certain defects and the realistic fault coverage for test sets. The method is highly efficient as a pre-processing step is used for partitioning the layout and extracting the defects ranked in the order of their <b>occurrence</b> <b>probabilities.</b> The method was applied to a public domain library where defects causing a complex faulty behavior are possible. The <b>occurrence</b> <b>probability</b> of these faults was computed, and the defect coverage for different test sets was determined. ...|$|R
30|$|In Hypothesis H 2, {{we propose}} that {{estimated}} risk impact {{should have a}} significantly stronger influence on anticipated project success than estimated risk <b>occurrence</b> <b>probability.</b> Contrary to what was predicted, only the influence of estimated risk <b>occurrence</b> <b>probability</b> {{was found to be}} significant (γ = − 0.362, p <  0.001), while estimated risk impact did not have significant influence (γ =  0.026, p =  0.880). Furthermore, the path coefficient of estimated risk impact to anticipated project success is slightly positive, which therefore does not indicate that higher estimated risk impact would reduce anticipated project success. Using linear regression analysis, we test if estimated risk impact accounts for a significant R 2 of anticipated project success, which was not the case (R 2  =  0.006, F(1202) =  1.30, p =  0.256). When adding estimated risk <b>occurrence</b> <b>probability</b> to the regression model, R 2 increased significantly (R_change^ 2  =  0.107, F(1201) =  24.17, p <  0.001). Accordingly, H 2 has to be rejected, as the results show that estimated risk impact has no significant effect on anticipated project success, while the effect of estimated risk <b>occurrence</b> <b>probability</b> on anticipated project success is significant.|$|R
40|$|We {{report on}} the polar {{mesosphere}} summer echoes (PMSE) <b>occurrence</b> <b>probability</b> over SANAE (South African National Antarctic Expedition) IV, for the first time. A matching coincidence method is described and implemented for PMSE extraction from SuperDARN (Super Dual Auroral Radar Network) HF radar. Several SuperDARN-PMSE characteristics are studied during the summer period from years 2005 - 2007. The seasonal and interannual SuperDARN-PMSE variations {{in relation to the}} mesospheric neutral winds are studied and presented in this paper. The <b>occurrence</b> <b>probability</b> of SuperDARN-PMSE on the day-to-day scale show, predominantly, diurnal variation, with a broader peak between 12 - 14 LT and distinct minimum of 22 LT. The SuperDARN-PMSE <b>occurrence</b> <b>probability</b> rate is high in the summer solstice. Seasonal variations show a connection between the SuperDARN-PMSE <b>occurrence</b> <b>probability</b> rate and mesospheric temperature from SABER (Sounding of the Atmosphere using Broadband Emission Radiometry). The seasonal trend for both meridional and zonal winds is very stable year-to-year. Analysis of the neutral wind variations indicates the importance of pole-to-pole circulations in SuperDARN-PMSE generation...|$|R
40|$|Diagnostics of {{enterprise}} bankruptcy <b>occurrence</b> <b>probability</b> {{is defined as}} an important tool ensuring the viability of an organization under conditions of unpredictable dynamic environment. The paper aims to define the basic features of diagnostics of bankruptcy <b>occurrence</b> <b>probability</b> models and their classification. The article grounds the objective increasing of crisis probability in modern enterprises where such increasing leads {{to the need to}} improve the efficiency of anti-crisis enterprise activities. The system of anti-crisis management is based on the subsystem of diagnostics of bankruptcy <b>occurrence</b> <b>probability.</b> Such a subsystem is the main one for further measures to prevent and overcome the crisis. The classification of existing models {{of enterprise}} bankruptcy <b>occurrence</b> <b>probability</b> has been suggested. The classification is based on methodical and methodological principles of models. The following main groups of models are determined: the models using financial ratios, aggregates and scores, the models of discriminated analysis, the methods of strategic analysis, informal models, artificial intelligence systems and the combination of the models. The classification made it possible to identify the analytical capabilities of each of the groups of models suggested...|$|R
30|$|In practice, {{since the}} source pattern {{generating}} the observed anomalies is unknown, an elementary source of unitary strength is ideally used {{to scan the}} volume beneath the surveyed area, called the tomospace, and search where the sources are most probably located. From the analytical point of view, this ideal process corresponds to calculating the <b>occurrence</b> <b>probability</b> function in a grid of points in the tomospace. A positive value of this function will give the <b>occurrence</b> <b>probability</b> of an increase of resistivity {{with respect to a}} reference resistivity value, whereas a negative value will give the <b>occurrence</b> <b>probability</b> of a decrease of resistivity. By scanning the tomospace, a full 3 D image reconstruction of the anomaly sources distribution can at last be obtained in a probabilistic sense.|$|R
40|$|Abstract. Extracting motifs from {{a set of}} DNA {{sequences}} {{is important}} in computational biology. <b>Occurrence</b> <b>probability</b> is a common used statistics to evaluate the statistical significance of a motif. A main problem is how to calculate the <b>occurrence</b> <b>probability</b> of the motif on the random model of DNA sequence efficiently and accurately. In this paper, {{we are interested in}} a particular motif model which is useful in transcription process. This motif, which is called structured motif, is composed two motif words on single nucleotide alphabet and with fixed spacers between them. We present an efficient algorithm to calculate the exact <b>occurrence</b> <b>probability</b> of a structured motif on a given sequence. It is the first non-trivial algorithm to calculate the exact p-value for such kind of motifs...|$|R
40|$|Classiying user’s {{question}} {{into several}} topics helps respondents {{answering the question}} in a cQA service. The word weighting method must estimate the appropriate weight of a word to improve the category (or topic) classification. In this paper, we propose a novel effective word weighting method based on a language model for automatic category classification in the cQA service. We first calculate the <b>occurrence</b> <b>probability</b> of a word in each category by using a language model and then the final weight of each word is estimated by ratio of the <b>occurrence</b> <b>probability</b> of the word on a category to the <b>occurrence</b> <b>probability</b> of the word on the other categories. As a result, the proposed method significantly improves the performance of th...|$|R
40|$|We {{consider}} {{the problems of}} robust stability and control for a class of networked control systems with long-time delays. Firstly, a nonlinear discrete time model with mode-dependent time delays is proposed by converting the uncertainty of time delay into the uncertainty of parameter matrices. We consider a probabilistic case where the system is switched among different subsystems, and the probability of each subsystem being active is defined as its <b>occurrence</b> <b>probability.</b> For a switched system with a known subsystem <b>occurrence</b> <b>probabilities,</b> we give a stochastic stability criterion in terms of linear matrix inequalities (LMIs). Then, we extend the results to a more practical case where the subsystem <b>occurrence</b> <b>probabilities</b> are uncertain. Finally, a simulation example is presented to show {{the efficacy of the}} proposed method...|$|R
40|$|Personalization and {{recommendation}} systems require formalized {{model for}} user preference. This paper presents the formal model of preference including positive preference and negative preference. For rare events, we apply the <b>probability</b> of random <b>occurrence</b> {{in order to}} reduce noise effects caused by data sparseness. Pareto distribution is adopted for the random <b>occurrence</b> <b>probability.</b> We also present the method for combining information of joint feature variables in different sizes by dynamic weighting using random <b>occurrence</b> <b>probability...</b>|$|R
40|$|Hutchinson defined species' {{realized}} niche as the set {{of environmental}} conditions in which populations can persist {{in the presence of}} competitors. In terms of demography, the realized niche corresponds to the environments where the intrinsic growth rate (r) of populations is positive. Observed species occurrences should reflect the realized niche when additional processes like dispersal and local extinction lags do not have overwhelming effects. Despite the foundational nature of these ideas, quantitative assessments of the relationship between range-wide demographic performance and <b>occurrence</b> <b>probability</b> have not been made. This assessment is needed both to improve our conceptual understanding of species' niches and ranges and to develop reliable mechanistic models of species geographic distributions that incorporate demography and species interactions. The objective {{of this study is to}} analyse how demographic parameters (intrinsic growth rate r and carrying capacity K) and population density (N) relate to <b>occurrence</b> <b>probability</b> (P-occ). We hypothesized that these relationships vary with species' competitive ability. Demographic parameters, density, and <b>occurrence</b> <b>probability</b> were estimated for 108 tree species from four temperate forest inventory surveys (Quebec, western USA, France and Switzerland). We used published information of shade tolerance as indicators of light competition strategy, assuming that high tolerance denotes high competitive capacity in stable forest environments. Interestingly, relationships between demographic parameters and <b>occurrence</b> <b>probability</b> did not vary substantially across degrees of shade tolerance and regions. Although they were influenced by the uncertainty in the estimation of the demographic parameters, we found that r was generally negatively correlated with P-occ, while N, and for most regions K, was generally positively correlated with P-occ. Thus, in temperate forest trees the regions of highest <b>occurrence</b> <b>probability</b> are those with high densities but slow intrinsic population growth rates. The uncertain relationships between demography and <b>occurrence</b> <b>probability</b> suggests caution when linking species distribution and demographic models. 12 page(s...|$|R
40|$|In recent years, {{global climate}} change has altered {{precipitation}} patterns, causing uneven spatial and temporal distribution of precipitation that gradually induces precipitation polarization phenomena. Taiwan {{is located in the}} subtropical climate zone, with distinct wet and dry seasons, which makes the polarization phenomenon more obvious; this has also led to a large difference between river flows during the wet and dry seasons, which is significantly influenced by precipitation, resulting in hydrological drought. Therefore, to effectively address the growing issue of water shortages, it is necessary to explore and assess the drought characteristics of river systems. In this study, the drought characteristics of northern Taiwan were studied using the streamflow drought index (SDI) and Markov chains. Analysis results showed that the year 2002 was a turning point for drought severity in both the Lanyang River and Yilan River basins; the severity of rain events in the Lanyang River basin increased after 2002, and the severity of drought events in the Yilan River basin exhibited a gradual upward trend. In the study of drought severity, analysis results from periods of three months (November to January) and six months (November to April) have shown significant drought characteristics. In addition, analysis of drought <b>occurrence</b> <b>probabilities</b> using the method of Markov chains has shown that the <b>occurrence</b> <b>probabilities</b> of drought events are higher in the Lanyang River basin than in the Yilan River basin; particularly for extreme events, the <b>occurrence</b> <b>probability</b> of an extreme drought event is 20. 6 % during the dry season (November to April) in the Lanyang River basin, and 3. 4 % in the Yilan River basin. This study shows that for analysis of drought/wet <b>occurrence</b> <b>probabilities,</b> the results obtained for the drought frequency and <b>occurrence</b> <b>probability</b> using short-term data with the method of Markov chains can be used to predict the long-term <b>occurrence</b> <b>probability</b> of drought/wet events...|$|R
40|$|We {{consider}} a testing procedure for the <b>occurrence</b> <b>probability</b> of rare {{events such as}} a severe adverse drug reaction observed {{after the release of}} a drug to market. <b>Occurrence</b> <b>probabilities</b> in two periods or populations Ω_ 0 and Ω_ 1 are compared. Under the condition that k events were observed among n patients for one population Ω_ 0, we test whether the <b>occurrence</b> <b>probability</b> for the second period or population Ω_ 1 is the same as that in Ω_ 0. We derive the null distribution and the non-null distribution of the test statistic both in exact and approximate forms, and make numerical assessment of the accuracy of the approximation. Further, the power function is also derived {{and the power of the}} test will be evaluated using the power function...|$|R
