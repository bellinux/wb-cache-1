326|353|Public
50|$|<b>Analytical</b> <b>error</b> {{is around}} 2−3 °C for {{individual}} specimens, but this drops to 0.5−1.0 °C when a sample is analysed - {{not enough to}} explain the discrepancy. Other factors mean that any pristine sample can be considered to have an associated error of up to 3 °C. Changes in salinity, kinetic and diagenesis, can also confound analysis: the latter two are each estimated to reduce estimated temperatures by 1−2 °C, and are difficult to quantify.|$|E
50|$|There are {{two types}} of {{conductivity}} detectors, direct and membrane.Direct conductivity provides an all-encompassing approach of measuring CO2. This detection method uses no carrier gas, is good at the parts per billion (ppb) ranges, but has a very limited analytical range.Membrane conductivity relies upon the filtering of the CO2 prior to measuring it with a conductivity cell. Both methods analyze sample conductivity before and after oxidization, attributing this differential measurement to the TOC of the sample. During the sample oxidization phase, CO2 (directly related to the TOC in the sample) and other gases are formed. The dissolved CO2 forms a weak acid, thereby changing the conductivity of the original sample proportionately to the TOC in the sample. Conductivity analyses assume that only CO2 is present within the solution. As long as this holds true, then the TOC calculation by this differential measurement is valid. However, depending on the chemical species present in the sample and their individual products of oxidation, they may present either a positive or a negative interference to the actual TOC value, resulting in <b>analytical</b> <b>error.</b> Some of the interfering chemical species include Cl−, HCO3−, SO32−, SO2−, ClO2−, and H+. Small changes in pH and temperature fluctuations also contribute to inaccuracy.Membrane conductivity analyzers have improved upon the direct conductivity approach by incorporating the use of hydrophobic gas permeation membranes to allow a more “selective” passage of the dissolved CO2 gas and nothing else. This provides a more precise and accurate measurement of the organics that were converted to CO2.|$|E
40|$|Background: Total <b>analytical</b> <b>error</b> {{has been}} a useful metric both to assess {{laboratory}} assay quality and to set goals. It is often estimated by combining imprecision (SD) and average bias in the equation: total <b>analytical</b> <b>error</b> bias 1. 65 imprecision. This indirect estima-tion model (referred to as the simple combination model) leads to different estimates of total <b>analytical</b> <b>error</b> {{than that of a}} direct estimation method (referred to as the distribution-of-differences method) or of simulation. Methods: A review of the literature was undertaken to reconcile the different estimation approaches. Results: The simple combination model can underesti-mate total <b>analytical</b> <b>error</b> by neglecting random inter-ference bias and by not properly treating other error sources such as linear drift and outliers. A simulatio...|$|E
40|$|When {{compared}} with results {{obtained by the}} authors in a department of medicine, the values obtained by three hospital laboratories for sodium, potassium, and chloride in normal and pathological sera were found to contain gross errors. In particular, the values obtained on sera from healthy subjects had a wide range when {{compared with}} the results obtained by the authors. The maximum acceptable <b>analytical</b> <b>errors</b> are suggested...|$|R
40|$|An Overview of Proficiency Testing Sources of Pre-analytical Variations Five Q-Framework for Implementing Total Quality Management in Laboratory Delta Check in Clinical Laboratory Indicators of Quality Improvement in Surgical Pathology Types of <b>Analytical</b> <b>Errors</b> Method Validation for Quantitative Tests: CAP Recommendations Levey Jenning Chart and a Guide to Use Westgard Rules Quality Control of Vitek- 2 System Establishing Quality Control Values for Haematology Parameters[URL]...|$|R
40|$|In the {{laboratory}} of medical genetics NCSH «OKHMATDYT» {{to identify the}} reliability of laboratory results and control the number and frequency of errors, carry out internal quality control. In order to evaluate the results of measurements of samples and eliminate harmful <b>analytical</b> <b>errors</b> developed and introduced software {{that allows you to}} build a calibration curve and process the results of biochemical research activity of lysosomal enzymes...|$|R
40|$|The National Kidney Disease Education Program group {{demonstrated}} that MDRD equation {{is sensitive to}} creatinine measurement error, particularly at higher glomerular filtration rates. Thus, MDRD-based eGFR above 60 mL/min/ 1. 73 m 2 should not be reported numerically. However, {{little is known about}} the impact of <b>analytical</b> <b>error</b> on CKD-EPI-based estimates. This study aimed at assessing the impact of analytical characteristics (bias and imprecision) of 12 enzymatic and 4 compensated Jaffe previously characterized creatinine assays on MDRD and CKD-EPI eGFR. In a simulation study, the impact of <b>analytical</b> <b>error</b> was assessed on a hospital population of 24 084 patients. Ability using each assay to correctly classify patients according to chronic kidney disease (CKD) stages was evaluated. For eGFR between 60 and 90 mL/min/ 1. 73 m 2, both equations were sensitive to <b>analytical</b> <b>error.</b> Compensated Jaffe assays displayed high bias in this range and led to poorer sensitivity/specificity for classification according to CKD stages than enzymatic assays. As compared to MDRD equation, CKD-EPI equation decreases impact of <b>analytical</b> <b>error</b> in creatinine measurement above 90 mL/min/ 1. 73 m 2. Compensated Jaffe creatinine assays lead to important errors in eGFR and should be avoided. Accurate enzymatic assays allow estimation of eGFR until 90 mL/min/ 1. 73 m 2 with MDRD and 120 mL/min/ 1. 73 m 2 with CKD-EPI equation. Peer reviewe...|$|E
30|$|The TOC, TN, and δ 13 C of {{the samples}} were {{measured}} by an elemental analyzer (Flash EA 1112) coupled to a ConFlo III and a Thermo Finnigan DeltaPlus Advantage isotope ratio mass spectrometer at the Center for Advanced Marine Core Research, Kochi University. Sulfanilamide {{was used as a}} standard for the TOC and TN measurements, and its <b>analytical</b> <b>error</b> (σ) was within 0.03  wt% for both TOC and TN. L-Alanine (δ 13 C[*]=[*] 19.6 ‰[*]±[*] 0.2) was used as a standard for the δ 13 C measurement, and its <b>analytical</b> <b>error</b> (σ) is 0.89 ‰.|$|E
30|$|After the {{development}} of the <b>analytical</b> <b>error</b> model, the bit-width reduced FPUs, and the neural network were designed using MATLAB and VHDL. Finally, the analytical (MATLAB) results with the experimental (VHDL) results were compared.|$|E
40|$|The {{ability to}} {{discriminate}} real trends related to geological and geochemical causes {{from those that}} result from spurious factors such as sampling and <b>analytical</b> <b>errors</b> {{is of paramount importance}} in the suI:cess of geochemical data interpretation. Since the estimate of reproducibility (precision) allows us to quantify the amount of variation due to sampling and laboratory analysis it {{is an integral part of}} the evaluetion o...|$|R
30|$|Major {{and trace}} element {{analyses}} were performed using a Perkin-Elmer Optima 3300 DVICP-Atomic Emission Spectrometer at the Chengdu University of Technology (CDUT, Chengdu). Multielemental high-purity solution standards {{were used for the}} calibration. An internal standard was used to correct the matrix differences. The <b>analytical</b> <b>errors</b> for Ca, Mg, Fe, Mn, Sr, and Na were ≤ 0.5  %, 0.8  %, 1.1  %, 1.1  %, 1.4  %, and 0.9  %, respectively.|$|R
40|$|The last 50 {{years have}} seen {{substantial}} changes in the landscape of laboratory medicine: its role in modern medicine is in evolution {{and the quality of}} laboratory services is changing. The need to control and improve quality in clinical laboratories has grown {{hand in hand with the}} growth in technological developments leading to an impressive reduction of <b>analytical</b> <b>errors</b> over time. An essential cause of this impressive improvement has been the introduction and monitoring of quality indicators (QIs) such as the analytical performance specifications (in particular bias and imprecision) based on well-established goals. The evolving landscape of quality and errors in clinical laboratories moved first from <b>analytical</b> <b>errors</b> to all errors performed within the laboratory walls, subsequently to errors in laboratory medicine (including errors in test requesting and result interpretation), and finally, to a focus on errors more frequently associated with adverse events (laboratory-associated errors). After decades in which clinical laboratories have focused on monitoring and improving internal indicators of analytical quality, efficiency and productivity, it is time to shift toward indicators of total quality, clinical effectiveness and patient outcomes...|$|R
40|$|This paper {{reports on}} updates {{to the system}} used for {{quantitative}} analyses of major, trace, and rare earth elements in silicate rocks by X-ray fluorescence spectrometry (RIX 3000) at the National Institute of Polar Research. We added Sc and Th {{to the list of}} measured elements, and the overlap coefficient of Th is used for the measurement of Nb. The geochemical standard samples SY- 3 (Canada) and JCh- 1 (Japan) {{have been added to the}} existing set of standard samples to improve the precision of analyses of SiO_ 2 and rare earth elements. Furthermore, we established a new method of evaluating the <b>analytical</b> <b>error,</b> making it possible to use analytical data for geochemical evaluation while considering the precision of the data. We also found that the <b>analytical</b> <b>error</b> may increase as a consequence of using a different lot number of the flux used in preparing the fused glass beads. It is therefore necessary to assess the background of the flux as well as the target elements, in terms of whether they are within the <b>analytical</b> <b>error,</b> before using a new flux...|$|E
30|$|In this paper, the <b>analytical</b> <b>error</b> {{model was}} {{developed}} using the maximum relative representation error (MRRE) and average relative representation error (ARRE) {{to obtain the}} maximum and average output errors for the bit-width reduced FPUs.|$|E
30|$|The {{design and}} {{performance}} of a practical rate 1 DDM precoding scheme is studied in this section. A sub-optimum receiver is developed by studying the statistical properties of the estimated channel coefficients, and the corresponding <b>analytical</b> <b>error</b> performance is derived.|$|E
40|$|Spatial {{distribution}} of soil mineral nitrogen content (Nmin) is a scale variant process. Precision farming assumes {{knowledge about the}} spatial {{distribution of}} mineral soil nitrogen content. Moreover sampling in management zones {{is based on the}} assumption of spatial dependence between sampling points. In the present study, variabilit structure of Nmin and the source of variability were investigated. Within an agricultural landscape, Nmin was investigated across a field in a nested design over four consecutive years. Temporally unstable structure of individual nests require a sampling with several nets in the field. In the investigated field, 35 - 49 % of the total variability derived from small-scale variability observed at spatial distances of less than 5 m and from sampling and <b>analytical</b> <b>errors.</b> Differences between 10 and 29 kg N ha- 1 for the soil depth increment 0 - 60 cm can be expected. Uncertainty due to <b>analytical</b> <b>errors</b> were in order of 5 - 10 kg N ha- 1 for a 0 - 60 cm layer. JRC. H. 6 -Spatial data infrastructure...|$|R
40|$|Some time ago, Buswell and Boruff 7 {{reported}} in THIS JOURNAL {{the volume and}} weight of gas that are recovered during the quantitative anaerobic digestion of the various constituents found in sewage. These data indi-cate that the weight of gas produced always exceeds the weight of organic matter digested. (For a few exceptions, see references 7, 8 and 21.) In earlier experimental plant studies, Buswell and Pearson 9 had obtained 1. 25 pounds of gas per pound of volatile matter digested, {{but they had no}} definite proof at that time that their sampling and <b>analytical</b> <b>errors</b> were sufficiently low to justify their conclusions. To check these data and to determine possible sampling and <b>analytical</b> <b>errors,</b> they set up a 28 -liter laboratory digester. All additions made to and withdrawals from this tank were carefully sampled and analyzed. The first attempt was some-what of a failure as the tank contents became sour, 10 but the second time normal digestion was established. In summary the unpublished data show satisfactory balances, with a gas production, when corrected for dis...|$|R
30|$|Past {{studies have}} used 2 D {{radiographic}} photos {{to analyze the}} condylar position; however, difficulties arose due to overlapping images of both condyles and {{the position of the}} image changing with the position of the patient. However, since the introduction of CT, condyles could be observed without overlap, and the position of the patient had become irrelevant. As a result, <b>analytical</b> <b>errors</b> have reduced over time and more accurate analyses have become possible.|$|R
30|$|This paper {{implements}} a field programmable gate array- (FPGA-) based face detector using a {{neural network}} (NN) and the bit-width reduced floating-point arithmetic unit (FPU). The <b>analytical</b> <b>error</b> model, using the maximum relative representation error (MRRE) {{and the average}} relative representation error (ARRE), is developed to obtain the maximum and average output errors for the bit-width reduced FPUs. After {{the development of the}} <b>analytical</b> <b>error</b> model, the bit-width reduced FPUs and an NN are designed using MATLAB and VHDL. Finally, the analytical (MATLAB) results, along with the experimental (VHDL) results, are compared. The analytical results and the experimental results show conformity of shape. We demonstrate that incremented reductions in the number of bits used can produce significant cost reductions including area, speed, and power.|$|E
40|$|The {{increasing}} {{popularity of}} stable isotope analysis (SIA) as an ecological research tool and {{the ease of}} automated analysis have created a knowledge gap between ecologists using SIA and the operators of isotope ratio mass spectrometry (IRMS) equipment. This has led to deterioration {{in the understanding of}} IRMS methodology and its proper dissemination in the ecological literature. Of 330 ecological research papers surveyed, 63 (19 %) failed to report any form of <b>analytical</b> <b>error</b> associated with IRMS. Of the 267 papers that reported <b>analytical</b> <b>error,</b> there was considerable variation both in the terminology and approach used to quantify and describe error. Internal laboratory standards were often used to determine the <b>analytical</b> <b>error</b> associated with IRMS, so chosen because they are homogenous and have isotopic signatures that do not vary over time. We argue that true ecological samples collected in the field are complex bulk mixtures and often fail to adhere to these two criteria. Hence the <b>analytical</b> <b>error</b> associated with samples is potentially greater than that of standards. A set of standard data run over time with a precision typically reported in the ecological literature (1 standard deviation: 1 SD= 0. 26 驠was simulated to determine the likelihood of spurious treatment effects depending on timing of analysis. There was a 90 % likelihood of detecting {{a significant difference in the}} stable nitrogen ratio of a single sample (homogenized bovine liver) run in two time periods when n> 30. Minor protocol adjustments, including the submission of blind replicates by researchers, random assignment of sample repeats within a run by analytical labs, and reporting 1 SD of a single sample analyzed both within and between runs, will only serve to strengthen the interpretation of true ecological processes by both researchers and reviewers. No Full Tex...|$|E
40|$|Analytical errors {{caused by}} {{suboptimal}} {{performance of the}} chosen platform {{for a number of}} metabolites and instrumental drift are a major issue in large-scale metabolomics studies. Especially for MS-based methods, which are gaining common ground within metabolomics, it is difficult to control the analytical data quality without the availability of suitable labeled internal standards and calibration standards even within one laboratory. In this paper, we suggest a workflow for significant reduction of the <b>analytical</b> <b>error</b> using pooled calibration samples and multiple internal standard strategy. Between and within batch calibration techniques are applied and the <b>analytical</b> <b>error</b> is reduced significantly (increase of 25 % of peaks with RSD lower than 20 %) and does not hamper or interfere with statistical analysis of the final data. © 2009 American Chemical Society...|$|E
50|$|Silver {{enhancer}} {{solution is}} also used to increase the reflective properties of samples. Gold nanoparticles have catalytic properties which cause them to reduce silver ions to silver metal. The silver metal deposits on the analytes and causes signals to be amplified. Silver metal is more easily detectable by cameras, scanners, or other drives than is the analyte alone. Still, this enhancement procedure requires many additional reaction and washing steps which could lead to <b>analytical</b> <b>errors.</b>|$|R
40|$|A {{systematic}} approach to selectivity in chemical analysis is presented and discussed. The conven-tional de¢nition of this property is completed by considering its relationships with <b>analytical</b> <b>errors,</b> other <b>analytical</b> properties, chemical measurement processes and sample composition. The {{different types of}} interferences {{as well as the}} parameters used for a mathematical description of selectivity and the strategies to increase it are also systemati-cally described. The manipulation of selectivity for circumventing legal regulations is mentioned as representative of the importance of this fea...|$|R
40|$|Background In {{a famous}} article, Simpson {{described}} a hypothetical data example {{that led to}} apparently paradoxical results. Methods We make the causal structure of Simpson’s example explicit. Results We show how the paradox disappears when the statistical analysis is appropriately guided by subject-matter knowledge. We also review previous explanations of Simpson’s paradox that attributed it to two distinct phenomena: confounding and non-collapsibility. Conclusion <b>Analytical</b> <b>errors</b> may occur when the problem is stripped of its causal context and analyzed merely in statistical terms...|$|R
40|$|Therapeutic drug {{monitoring}} {{is an important}} aspect of clinical chemistry for which no objective analytical goals yet exist. Based on fundamental pharmacokinetic theory, and the current consensus strategy for analytical goal-setting for precision based upon biological variation, a theoretical model allows derivation of the goal that: analytical CV 1 / [(2 T/t- 1) /(2 T/t + 1) ] x 100 %, where T is the time interval between doses, and t is the average elimination half-life. Using published data on half-lives, I have derived goals for analysis for (e. g.) digoxin, lithium, some antiepileptic drugs, and theophylline. The goal for accuracy proposed is that methods should have no bias and should generate true values. Goals for precision should therefore be viewed as goals for total <b>analytical</b> <b>error.</b> AdditIonal Keyphrases: <b>analytical</b> <b>error</b> precision and accura...|$|E
40|$|We studied sample evaporationanditseffect on analyti-cal error. Several factors {{influencing}} evaporative loss {{have been identified}} and measured: environmental, in-strumental, and operational factors, and the chemical and physical properties of the sample and its container. Such losses from several different types of sample cups have been measured, either chemically or gray-imetrically, and compared with those calculated by using a model that allows evaporative loss from a cup of known geometry to be predicted under various envi-ronmental conditions. We discuss some steps that may be taken to minimize evaporative loss and give an ex-ample to demonstrate that <b>analytical</b> <b>error</b> from this source can be decreased to a routine 1 - 2 % or less by selecting a particular cup design. Addftlonal Keyphrases: microliter samples #{ 149 } <b>analytical</b> <b>error</b> #{ 149 }sample-cup geometry #{ 149 }predicting and prevent-ing evaporative loss #{ 149 }centrifugal analyzer #{ 149 }pediatric chemistry Various newly developed instruments offer real and potential advantages for automated clinical anal-yses. Because increased sensitivity is typically a fea-ture of these instruments, many factors that hereto-fore made relatively insignificant contributions to the total <b>analytical</b> <b>error</b> should now be examined and evaluated. One such factor is evaporative loss of volatile com-ponents or liquid 1 from a sample {{after it has been}} poured into its sample cup. This factor can contrib...|$|E
40|$|Quantum {{computers}} (QCs) must implement quantum error correcting codes (QECCs) {{to protect}} their logical qubits from errors, and modeling the effectiveness of QECCs on QCs is an important problem for evaluating the QC architecture. The previously developed Monte Carlo (MC) error models may take days or weeks of execution to produce an accurate result due to their random sampling approach. We present an alternative <b>analytical</b> <b>error</b> model that generates, {{over the course of}} executing the quantum program, a probability tree of the QC's error states. By calculating the fidelity of the quantum program directly, this error model has the potential for enormous speedups over the MC model when applied to small yet useful problem sizes. We observe a speedup on the order of 1, 000 X when accuracy is required, and we evaluate the scaling properties of this new <b>analytical</b> <b>error</b> model...|$|E
40|$|This paper {{provides}} the verification of {{coefficients for the}} calculation of particle density, bulk density, and total porosity based on the texture of soils proposed by Brogowski (1990). The verified and supplemented coefficients for the calculation of particle density, bulk density, and total porosity permit obtaining credible results {{within the range of}} <b>analytical</b> <b>errors.</b> The proposed calculations of density and total porosity of soils can be used for the general description of soils. They cannot, however, replace exact scientific research on the physical state of soils...|$|R
5000|$|The Antitrust Paradox {{has shaped}} {{antitrust}} law in several ways, prominently by focusing the discipline on efficiency and articulating its goal as [...] "consumer welfare." [...] Many lawyers and economists, however, {{have pointed out}} that Bork was wrong in his analysis of the legislative intent of the Sherman Act and have criticized him for incorrect economic assumptions and <b>analytical</b> <b>errors.</b> One of the key criticism focuses on Bork's use of the term [...] "consumer welfare," [...] which became the stated goal of American antitrust law.|$|R
30|$|For LA-ICP-MS, {{constant}} and homogeneous ablation and aerosol transport is essentially required to obtain high precision on elemental concentrations. Although the 266  nm laser {{is known to}} reduce fractionation compared with an infrared laser (1064  nm wavelength), the fractionation still remained considerable compared with shorter-wavelength laser systems (Gonzalez et al. 2002, Jochum et al. 2007). Relatively large <b>analytical</b> <b>errors</b> (more than 20  %) reported from a UV 266  nm laser could be attributed mainly to elemental fractionation during laser ablation and to contamination or loss of elements during glass preparation (Norman et al. 1998).|$|R
3000|$|... [...]) can be {{used for}} <b>analytical</b> <b>error</b> {{performance}}. Note that in [13], the authors used the Rayleigh PDF (single candidate) for obtaining the error performance of multiple candidate cases. However, we suggest using our PDF (multiple candidates) to obtain the theoretical error performance and also the statistical channel capacity for the multiple candidate system.|$|E
40|$|We {{present a}} new class of self-adaptive higher-order finite element methods (hp-FEM) which are free of <b>analytical</b> <b>error</b> {{estimates}} and thus work equally well for virtually all PDE problems ranging from simple linear elliptic equations to complex time-dependent nonlinear multiphysics coupled problems. The methodology was used to solve various types of problems. In this paper we use a nonlinear combustion problem for illustration...|$|E
40|$|Background: Patients and {{physicians}} expect accurate whole blood glucose monitoring even when patients are anemic, are undergoing peritoneal dialysis, or have slightly elevated ascorbate levels. The {{objective of this}} study was to estimate <b>analytical</b> <b>error</b> in two consumer and two hospital glucose meters contributed by variations in hematocrit, maltose, ascorbate, and imprecision. Method: The influence of hematocrit (20 – 60 %), maltose, and ascorbate were tested alone and in combination with each glucose meter and with a reference plasma glucose method at three concentrations of glucose. Precision was determined by consecutive analysis (n = 20) at three levels of glucose. Multivariate regression analysis was used to estimate the bias associated with the interferences, alone and in combination. Total <b>analytical</b> <b>error</b> was estimated as | % bias | + 1. 96 (% imprecision). Results: Three meters demonstrated hematocrit bias that was dependent upon glucose concentration. Maltose had profound concentration-dependent positive bias on the consumer meters, and the extent of maltose bia...|$|E
40|$|Polymer {{materials}} {{are very difficult}} to decompose for the purpose of chemical analysis. Nondestructive analysis without pretreatment provides a suitable solution that will overcome this obstacle. In this study, CRM candidate samples that contained toxic elements such as As, Cd, Cr and Zn in a polypropylene (PP) were analyzed using instrumental neutron activation analysis (INAA). The analytical results were obtained from ten samples selected by random sampling at two different concentration levels (low and high). Particular attention was paid to reducing <b>analytical</b> <b>errors</b> and evaluating the associated uncertainty...|$|R
50|$|In a 1978 {{paper and}} later in The Mismeasure of Man (1981), Stephen J. Gould {{asserted}} that Morton had, perhaps because of an unconscious bias, selectively reported data, manipulated sample compositions, made <b>analytical</b> <b>errors,</b> and mismeasured skulls {{in order to support}} his prejudicial views on intelligence differences between different populations. Gould's book became widely read and Morton came to be considered one of the main cases of the effects of unconscious bias in data collection, and as one of the main figures in the early history of scientific racism.|$|R
40|$|Previous {{studies from}} this {{laboratory}} on protein turnover in 3 H-labelled L-cell cultures have shown recovery of total 3 H {{at the end}} of a 3 -day experiment to be always significantly in excess of the 3 H recovered at the beginning of the experiment. In this study we have critically reviewed a number of possible sources for this error in measuring radioactivity in cell proteins. 3 H-labelled proteins, when dissolved in 0. 3 M-NaOH and counted for radioactivity in a liquid-scintillation spectrometer, showed losses of 30 - 40 % of the radioactivity; neither external or internal standardization compensated for this loss. Hydrolysis of these proteins with either Pronase or concentrated HCl significantly increased the measured radioactivity. In addition, approx. 5 - 10 % of the cell protein is left on the plastic culture dish when cells are recovered in phosphate-buffered saline. To aggravate this latter loss further, this surface-adherent protein, after pulse labelling, contains proteins of high radioactivity that turn over rapidly and make a major contribution to the accumulating radioactivity in the medium. These combined errors can account for up to 60 % of the total radioactivity in the cell culture. Similar <b>analytical</b> <b>errors</b> have been found in studies of other cell cultures. The effect of these <b>analytical</b> <b>errors</b> on estimates of protein turnover in cell cultures is discussed...|$|R
