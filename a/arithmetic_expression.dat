94|271|Public
2500|$|Typing any <b>arithmetic</b> <b>expression,</b> {{followed}} by [...] "=" [...] {{results in the}} result of the calculation being displayed.|$|E
5000|$|A simple {{example of}} {{evaluating}} an <b>arithmetic</b> <b>expression</b> follows: ...|$|E
5000|$|For an <b>arithmetic</b> <b>expression</b> , the {{abstract}} syntax tree looks like this: ...|$|E
40|$|ABSTRACT. It {{is shown}} that <b>arithmetic</b> <b>expressions</b> with n> 1 {{variables}} and constants; operations of addition, multiplication, and division; and any depth of parenthesis nesting can be evaluated in time 4 log 2 n + 10 (n- 1) /p using p> 1 processors which can independently perform arithmetic operations in unit time. This bound is within a constant factor {{of the best}} possible. A sharper result is given for expressions without the division operation, {{and the question of}} numerical stability is discussed. KEY WORDS AND PHRASES: <b>arithmetic</b> <b>expressions,</b> compilation of <b>arithmetic</b> <b>expressions,</b> compu-tational complexity, general <b>arithmetic</b> <b>expressions,</b> numerical stability, parallel computatioR...|$|R
40|$|Abstract. <b>Arithmetic</b> <b>expressions</b> for {{switching}} functions are introduced through {{the replacement of}} Boolean operations with arithmetic equivalents. In this setting, they {{can be regarded as}} the integer counterpart of Reed-Muller expressions {{for switching}} functions. However, <b>arithmetic</b> <b>expressions</b> can be interpreted as series expansions in the space of complex valued functions on finite dyadic groups in terms of a particular set of basic functions. In this case, <b>arithmetic</b> <b>expressions</b> can be derived from the Walsh series expansions, which are the Fourier expansions on finite dyadic groups. In this paper, we extend the <b>arithmetic</b> <b>expressions</b> to non-Abelian groups by the example of quaternion groups. Similar to the case of finite dyadic groups, the <b>arithmetic</b> <b>expressions</b> on quaternion groups are derived from the Fourier expansions. Attempts are done to get the related transform matrices with a structure {{similar to that of the}} Haar transform matrices, which ensures efficiency of computation of arithmetic coefficients...|$|R
5000|$|... <b>arithmetic</b> <b>expressions</b> for {{computing}} derived {{measures and}} aggregates ...|$|R
5000|$|The {{following}} <b>arithmetic</b> <b>expression</b> {{shows an}} example of operators and operands: ...|$|E
5000|$|Typing any <b>arithmetic</b> <b>expression,</b> {{followed}} by [...] "=" [...] {{results in the}} result of the calculation being displayed.|$|E
5000|$|... #Caption: Abstract {{syntax tree}} of the <b>arithmetic</b> <b>expression</b> [...] "a^2+4*b" [...] wrt. the example grammar (top) and its Chomsky normal form (bottom) ...|$|E
40|$|This paper {{presents}} a new, compact, canonical representation for <b>arithmetic</b> <b>expressions,</b> called Taylor Expansion Diagram. It {{can be used}} to facilitate the verification of RTL specifications and hardware implementations of arithmetic designs, and specifically the equivalence checking of complex algebraic and <b>arithmetic</b> <b>expressions</b> that arise in symbolic verification...|$|R
40|$|The {{problem of}} parsing and {{compiling}} <b>arithmetic</b> <b>expressions</b> in parallel computational environments is considered. It is {{seen that the}} concept of Operator Precedence can be generalized to allow encodings of one or more <b>arithmetic</b> <b>expressions</b> to be transformed directly into encodings of their corresponding derivation trees. The algorithm which performs this transformation is compact, efficient (linear in both time and space), and highly concurrent. Further, it can be extended to compile <b>arithmetic</b> <b>expressions</b> directly into object code (in the form of quadruples). The extention preserves the compactness, efficiency (1 inearity) and highly concurrent nature of the original a 1 gorithm...|$|R
50|$|Context-free {{languages}} {{have many}} applications in programming languages, in particular, most <b>arithmetic</b> <b>expressions</b> are generated by context-free grammars.|$|R
50|$|In 1947 Curry also {{described}} {{one of the}} first high-level programming languages and provided the first description of a procedure to convert a general <b>arithmetic</b> <b>expression</b> into a code for one-address computer.|$|E
5000|$|In {{one case}} of a {{three-way}} conditional provided by the programming language, Fortran's now-deprecated three-way arithmetic IF statement considers the sign of an <b>arithmetic</b> <b>expression</b> and offers three labels to jump to according to {{the sign of the}} result: ...|$|E
50|$|An {{optimising}} compiler may analyse {{the form}} of an <b>arithmetic</b> <b>expression,</b> to identify and remove repetition or make other potential improvements. Consider a*sin(x) + b*sin(x)Some languages, such as Algol, allow assignments within an <b>arithmetic</b> <b>expression,</b> so the programmer could have written something like a*(t:=sin(x)) + b*tbut aside from the exertion required to do so, the resulting statement's form is messy and will no longer be easily compared to the mathematical expression being coded for. Mistakes would be easily made. Instead, the compiler could represent the entire expression's form (typically using a tree structure), analyse and modify that structure, and then emit the code for the improved form. There would be an obvious extension to blocks of successive assignment statements. This does not involve a second pass through the source text, as such.|$|E
40|$|Abstract: It {{has been}} {{recently}} shown in [1], that elementary mathematical functions (as trigonometric, logarithmic, square root, gaussian, sigmoid, etc.) are compactly {{represented by the}} <b>Arithmetic</b> transform <b>expressions</b> and related Binary Moment Diagrams (BMDs). The complexity of the representations is estimated through the number of non-zero coefficients in <b>arithmetic</b> <b>expressions</b> {{and the number of}} nodes in BMDs. In this paper, we show that further optimization can be achieved when the method in [1] is combined with Fixed-polarity <b>Arithmetic</b> <b>expressions</b> (FPRAs). In addition, besides complexity measures used in [1], we also compared the number of bits and 1 -bits required to represent arithmetic transform coefficients in zero polarity and optimal polarity <b>arithmetic</b> <b>expressions.</b> This is a complexity measure relevant for the alternative implementations of elementary functions suggested in [1]. Experimental results confirm that exploiting of FPARs may provide for considerable reduction in terms of the complexity measures considered...|$|R
5000|$|C V Ramamoorthy and M J Gonzalez. Subexpression Ordering in the Execution of <b>Arithmetic</b> <b>Expressions.</b> Commun. ACM (...) , 14(7):479-485, 1971.|$|R
50|$|Manipulators: Manipulators modify {{data that}} has already been {{imported}} or generated. They range from simple <b>arithmetic</b> <b>expressions</b> to complex scripts.|$|R
50|$|A natural {{example of}} a problem in co-RP {{currently}} not known to be in P is Polynomial Identity Testing, the problem of deciding whether a given multivariate <b>arithmetic</b> <b>expression</b> over the integers is the zero-polynomial. For instance, x·x − y·y − (x + y)·(x − y) is the zero-polynomial whilex·x + y·y is not.|$|E
5000|$|... = / \ a * / \ / \ + + / \ / \ / \ d 3 + * / \ / \ b c f gTo {{continue}} with the algorithm, we need only to examine the <b>arithmetic</b> <b>expression</b> , i.e. we only {{have to look at}} the right subtree of the assignment '=': ...|$|E
5000|$|If {{you want}} to use any of these {{characters}} as a literal in a regex, you need to escape them with a backslash. For example, to match the <b>arithmetic</b> <b>expression</b> [...] "(1+1)*3=6" [...] with a regex, then the correct regex is [...] "\(1\+1\)\*3=6". Otherwise, the parenthesis, plus-sign, and asterisk will have a special meaning.|$|E
40|$|Numerical {{analysis}} has no satisfactory method {{for the more}} realistic optimization models. However, with constraint programming one can compute a cover for the solution set to arbitrarily close approximation. Because the use of constraint propagation for composite <b>arithmetic</b> <b>expressions</b> is computationally expensive, consistency is computed with interval arithmetic. In this paper we present theorems that support, selective initialization, a simple modification of constraint propagation that allows composite <b>arithmetic</b> <b>expressions</b> to be handled efficiently...|$|R
30|$|The {{application}} is successful in allowing for meaningful {{interaction with the}} Triplet Structure Model {{without the use of}} text and <b>arithmetic</b> <b>expressions.</b>|$|R
50|$|In an {{advanced}} {{version of the}} Sethi-Ullman algorithm, the <b>arithmetic</b> <b>expressions</b> are first transformed, exploiting the algebraic properties of the operators used.|$|R
50|$|To {{evaluate}} {{an expression}} given as a binary tree (this problem {{also known as}} binary expression tree), consider that:An <b>arithmetic</b> <b>expression</b> is a tree where the leaves have values from some domain and each internal vertex has two children and a label from {+, x, %}. And further assume that these binary operations can be performed in constant time.|$|E
5000|$|As {{it can be}} {{observed}} from the definition, application of distributive law to an <b>arithmetic</b> <b>expression</b> reduces the number of operations in it. In the previous example {{the total number of}} operations reduced from three (two multiplications and an addition in [...] ) to two (one multiplication and one addition in [...] ). Generalization of distributive law leads to a large family of fast algorithms. This includes the FFT and Viterbi algorithm.|$|E
5000|$|Given any valid primary <b>arithmetic</b> <b>expression,</b> insert {{into one}} or more {{locations}} any number of Latin letters bearing optional numerical subscripts; {{the result is a}} pa formula. Letters so employed in mathematics and logic are called variables. A pa variable indicates a location where one can write the primitive value [...] or its complement [...] Multiple instances of the same variable denote multiple locations of the same primitive value.|$|E
50|$|Forms of {{mathematical}} <b>expressions</b> include <b>arithmetic</b> <b>expressions,</b> polynomials, algebraic expressions, closed-form expressions, and analytical expressions. The table below illustrates the elements these forms may contain.|$|R
50|$|Donald Knuth {{considers}} {{him to have}} independently co-discovered {{the idea}} of hashing with linear probing. He also created {{one of the first}} algorithms for compiling <b>arithmetic</b> <b>expressions.</b>|$|R
50|$|Thus the {{relation}} of logical equivalence partitions all primary <b>arithmetic</b> <b>expressions</b> into two equivalence classes: those that simplify to the Cross, and those that simplify to the void.|$|R
5000|$|In both A1 and A2, the {{expression}} {{to the right}} of '=' has fewer symbols than {{the expression}} to the left of '='. This suggests that every primary <b>arithmetic</b> <b>expression</b> can, by repeated application of A1 and A2, be simplified to one of two states: the marked or the unmarked state. This is indeed the case, and the result is the expression's [...] "simplification". The two fundamental metatheorems of the primary arithmetic state that: ...|$|E
5000|$|BEGIN INT i := 10; %% Variable with initial value. REF INT ri := i; %% Pointer {{initialized}} {{to point}} to i. INT j := 11; j :- REF INT =: ri; %% Type conversion and assignment %% ri now points to j. i =: (ri :- VAL REF INT); [...] %% Assignment and type conversion %% ri points to j so j is changed. IF j > 10 %% Conditional statement with result THEN %% used inside an <b>arithmetic</b> <b>expression.</b> 1 ELSE 2 FI + j =: j; END ...|$|E
5000|$|The {{first version}} of FORTRAN (1957) and its {{successor}} FORTRAN II (1958) had no logical values or operations; even the conditional [...] statement took an <b>arithmetic</b> <b>expression</b> and branched {{to one of three}} locations according to its sign; see arithmetic IF. FORTRAN IV (1962), however, followed the ALGOL 60 example by providing a Boolean data type (...) , truth literals ( [...] and [...] ), Boolean-valued numeric comparison operators ( [...] , , etc.), and logical operators ( [...] , , [...] ). In [...] statements, a specific control character (...) was provided for the parsing or formatting of logical values.|$|E
40|$|Contents Grammars 3. 1 Poxsing: {{reconstruction}} of a derivation tree 3. 2 A more machine-oriented view of parsing Parser construction in ML 4. 2 Constructing parsing functions in ML 4. 3 Poxsing functions follow the derivation tree Scanners 5. 3 Distinguishing names from keywords 5. 4 Scanning real numerals 5. 5 Reading text files with ML Parsers with attributes 6. 2 Building representations of input 7 A larger example: <b>arithmetic</b> <b>expressions</b> 7. 1 A grammar for <b>arithmetic</b> <b>expressions</b> 7. 2 The parser constructed from the grammar 7. 3 A scanner for <b>arithmetic</b> <b>expressions</b> Some background 8. 1 History and notation 30 2 Often the input {{to a program}} is given as a text, but internally in the program it is better represented more abstractly: by an ML datatype, for instance. The program must read the input text, check that it is well-formed, and convert it to the internal form. This is particularly challenging when the input is in free form...|$|R
50|$|Spreadsheets {{that have}} a formula {{language}} based upon logical <b>expressions,</b> rather than <b>arithmetic</b> <b>expressions</b> are known as logical spreadsheets. Such spreadsheets {{can be used to}} reason deductively about their cell values.|$|R
50|$|Here, {{a program}} is {{converted}} into a complex state diagram in which states and arcs may include <b>arithmetic</b> <b>expressions,</b> and those expressions may use external inputs and outputs as well as variables.|$|R
