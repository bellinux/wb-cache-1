0|10000|Public
50|$|Imparja {{initially}} carried programming {{from all}} three major Australian commercial television networks, but following <b>aggregation</b> <b>of</b> <b>market</b> area with QSTV, it affiliated with the Nine Network and Network Ten. Imparja Television also screened some ABC Television and SBS Television indigenous programs, all in addition to original programs commissioned by the station.|$|R
40|$|It {{has been}} well-recognized that markets can {{aggregate}} less-than-perfect information across market participants. With two differently designed securities, this work examines {{the impact of}} security design on the information <b>aggregation</b> ability <b>of</b> <b>markets</b> in laboratory experiments. Results show that markets with one security aggregate information significantly better than markets with the other security, implying that information <b>aggregation</b> ability <b>of</b> <b>markets</b> {{is affected by the}} security design. Behavior of individual participants is then investigated to understand the observed market behavior. JEL Classification: C 92; C 91; D 8...|$|R
50|$|During the 1960s, 1970s and 1980s, the telethon {{was also}} re-broadcast through {{regional}} Victoria via local channels, with Prime Television being the sole regional broadcaster from 1992 with the <b>aggregation</b> <b>of</b> regional <b>markets.</b>|$|R
40|$|We {{consider}} the design <b>of</b> prediction <b>market</b> mechanisms known as automated market makers. We {{show that we}} can design these mechanisms via the mold of exponential family distributions, a popular and well-studied probability distribution template used in statistics. We give a full development of this relationship and explore a range of benefits. We draw connections between the information <b>aggregation</b> <b>of</b> <b>market</b> prices and the belief <b>aggregation</b> <b>of</b> learning agents that rely on exponential family distributions. We develop a very natural analysis <b>of</b> the <b>market</b> behavior {{as well as the}} price equilibrium under the assumption that the traders exhibit risk aversion according to exponential utility. We also consider similar aspects under alternative models, such as when traders are budget constrained...|$|R
5000|$|... 1994 - <b>Aggregation</b> <b>of</b> Tasmanian {{television}} <b>market</b> occurs - Southern Cross broadcasts statewide, {{competing with}} TasTV ...|$|R
50|$|In 1991, GLV/BCV {{changed its}} Melbourne-based news relay to Ten Eyewitness News from ATV-10, in the lead-up to the <b>aggregation</b> <b>of</b> {{regional}} <b>markets</b> which would see GLV/BCV align with the Ten Network for program material.|$|R
50|$|In 2001, Bridge Telerate {{was sold}} to MoneyLine Network {{as part of the}} Bridge Information Systems {{bankruptcy}} proceedings for just $10 million. As part of the deal, MoneyLine reached an agreement with Reuters for the collection and <b>aggregation</b> <b>of</b> <b>market</b> data and other services for a three to four year transition period. It also reached an agreement with SAVVIS Communications Corporation for network services, so that it could continue to offer Telerate services. The business was renamed MoneyLine Telerate. However, the relationship with Reuters was troublesome and would lead to a major dispute with Reuters in 2003 when Reuters threatened to cut Telerate's data feeds, which was only narrowly avoided.|$|R
40|$|Spectators at mega-sport {{events are}} an <b>aggregation</b> <b>of</b> <b>market</b> {{segments}} with distinct consumer behaviours. Relatively few economic impact studies have distinguished spectator market segments or the event tourists crowding out other visitors, resulting in inaccurate results. Despite {{a plethora of}} prior studies, there remains {{a need for a}} refined and agile model to predict a sporting event’s economic impact. The {{purpose of this study is}} to describe the ex ante model, ACE: Assessing Consumers of Events, developed to estimate spending impacts by spectators. ACE is then applied to the 2009 U. S. Women’s Open Golf Championship to illustrate its data requirements and results. U. S. Open spectators are projected to spend $ 7. 5 million in the host economy and induce a slight crowding out effect. Future applications of the ACE model are discussed...|$|R
40|$|This diploma thesis "Methods <b>of</b> risk <b>aggregation</b> on {{financial}} markets" introduces {{all kinds of}} risk that are present on the financial markets. In the first part there are explained the ways and methods of measurement of these risks. Next there are shown the methods <b>of</b> <b>aggregation</b> <b>of</b> credit, <b>market</b> and operational risks. One of these methods are copula functions which are constructed in practical part of this thesis...|$|R
40|$|As {{shown in}} the recent BCBS papers market and credit risks could {{reinforce}} each other in certain circumstances, meaning {{the sum of the}} parts might be less than an estimate of risk that takes into account the interactions between the two. Market risk factors have an ambiguous impact on the firms' repayment conditions because depreciation of domestic currency for instance favors exporters and harms importers. Within the task <b>of</b> a ‘top-down’ <b>aggregation</b> <b>of</b> <b>market</b> and credit risks this contribution presents a general framework to economic capital measurement and active portfolio management splitting exogenous risk factor influence throw different channels. The approach implies an exploiting of banks information about the clients' trade and cash flows related to global economic activity. The way to single out exposures to counterparties belonging to the same pattern of behavioural reactions to the market factors are considered as the bedrock of Factor endogenous behaviour aggregation (FEBA) approach. ...|$|R
40|$|In {{this paper}} {{we present a}} general {{framework}} for time-aware decision support systems. The framework uses the state-of-the-art tOWL language for the representation of temporal knowledge and enables temporal reasoning over the information that is represented in a knowledge base. Our approach uses state-of-the-art Semantic Web technology for handling temporal data. Through such an approach, the designer of a system can focus on the application intelligence rather than enforcing/checking data related restrictions manually. Also, there is an increased support for reuse of temporal reasoning tools across applications. We illustrate the applicability of our framework by building a market recommendations aggregation system. This system automatically collects market recommendations from online sources and, based on the past performance of the analysts that issued a recommendation, generates an aggregated recommendation {{in the form of}} a buy, hold, or sell advice. We illustrate the flexibility of our proposed system by implementing multiple methods for the <b>aggregation</b> <b>of</b> <b>market</b> recommendations...|$|R
40|$|Strategic {{business}} decision making involves the analysis <b>of</b> <b>market</b> forecasts. Today, {{the identification and}} <b>aggregation</b> <b>of</b> relevant <b>market</b> statements is done by human experts, often by analyzing documents from the World Wide Web. We present an efficient information extraction chain to automate this complex natural language processing task and show results for the identification part. Based on time and money extraction, we identify sentences that represent statements on revenue using support vector classification. We provide a corpus with German online news articles, {{in which more than}} 2, 000 such sentences are annotated by domain experts from the industry. On the test data, our statement identification algorithm achieves an overall precision and recall of 0. 86 and 0. 87 respectively. ...|$|R
40|$|Intel {{completed}} {{a study of}} several generations of products to learn how product forecasts and plans are managed, how demand risks manifest themselves, and how business processes contend with, and sometimes contribute to, demand risk. The study identified one critical area prone to breakdown: the <b>aggregation</b> <b>of</b> <b>market</b> insight from customers. Information collected from customers and then rolled up through sales, marketing, and business planning teams is often biased, and {{it can lead to}} inaccurate forecasts, as evidenced by historical results. A research effort launched in 2005 sought to introduce new methodologies that might help crack the bias in demand signals. We worked with our academic partners to develop a new application, a form <b>of</b> prediction <b>market,</b> integrated with Intel’s regular short-term forecasting processes. The process enables product and market experts to dynamically negotiate product forecasts in an environment offering anonymity and performance-based incentives. To the extent these conditions curb bias and motivate improved performance, the system should alleviate demand miscalls that have resulted in inventory surpluses or shortages in the past. Results of early experiments suggest that market-developed forecasts are meeting or beating traditional forecasts in terms of increased accuracy and decreased volatility, while responding well to demand shifts. In addition, the new process is training Intel’s experts to improve their use and interpretation of information...|$|R
40|$|As a {{consequence}} <b>of</b> <b>aggregation</b> over <b>markets,</b> the observed quantity {{may be less}} than the quantity demanded and less than the quantity supplied. To deal with such situations, a new technique is proposed for estimating demand and supply curves {{and the extent of}} shortage and slack. The technique is applied to the consumption goods <b>markets</b> <b>of</b> Czechoslovakia, the Germa...|$|R
50|$|In {{preparation}} for <b>aggregation</b> <b>of</b> the Victorian <b>market</b> - (excluding Mildura) - in early 1992, a studio facility and playout centre {{was constructed in}} the Ballarat suburb of Mitchell Park. At that time this facility was the playout centre for the Western Victoria, Central Victoria, and Gippsland regions. Playout for the Albury and Shepparton regions was maintained at Prime's Albury studios. The Ballarat centre was {{and continues to be}} operated under the AMV licence.|$|R
40|$|We {{investigate}} {{the effect of}} model specification on the <b>aggregation</b> <b>of</b> (correlated) <b>market</b> and credit risk. We focus on the functional form linking systematic credit risk drivers to default probabilities. Examples include the normal based probit link function for typical structural models, or the exponential (Poisson) link function for typical reduced form models. We first show analytically how model specification impacts 'diversification benefits' for aggregated market and credit risk. The specification effect can lead to Value-at-Risk (VaR) reductions {{in the range of}} 3 percent to 47 percent, particularly at high confidence level VaRs. We also illustrate the effects using a fully calibrated empirical model for US data. The empirical effects corroborate our analytic results...|$|R
40|$|The paper {{presents}} a detailed comparative review of price/cost elasticity estimates {{published in a}} number of studies on multi-mode freight transport demands. It attempts to determine which factors could explain the wide diversity <b>of</b> estimates: data <b>aggregation,</b> diversity <b>of</b> <b>markets,</b> and methodology. It also presents new estimates for rail, road, and waterway modes, derived from a multimodal freight network model of the Rhine area market. Direct and cross-elasticities are estimated for 11 groups of commodities and per distance category. The results are critically assessed by comparison with the reviewed studies. The paper concludes with a few recommendations about meaningful uses of existing estimates and the need for additional experiments with different methodologies applied on a common data basis...|$|R
40|$|The study {{explores the}} {{information}} <b>aggregation</b> properties <b>of</b> experimental <b>markets.</b> A fully-revealing rational expectations equilibrium {{exists in the}} competitive model of each <b>of</b> the <b>markets</b> studied. For markets with a single compound security in which traders have identical preferences, the rational expectations equilibrium mod el works well. However, if traders are allowed to have different preferences in the single security case, the observed information aggregation is minimal and rational expectations are not attained. If the single security is transformed to {{a complete set of}} Arrow-Debreu, state-contingent claims, the rational expectations model works well even when preferences differ. Copyright 1988 by The Econometric Society. ...|$|R
40|$|Recent {{years have}} seen {{extensive}} investigation <b>of</b> the information <b>aggregation</b> properties <b>of</b> <b>markets.</b> However, relatively {{little is known about}} conditions under which a market will aggregate the private information of rational risk averse traders who optimize their portfolios over time; in particular, what features <b>of</b> a <b>market</b> encourage traders to ultimately reveal their private information through trades? We consider a market model involving finitely many informed risk-averse traders interacting with a market maker. Our main result identifies a basic asymptotic smoothness condition on prices in the market that ensures information is aggregated as long as portfolios remain bounded; further, under this assumption, the allocation achieved is ex post Pareto efficient. Asymptotic smoothness is fairly mild: it requires that, eventually, infinitesimal purchases or sales should see the same per unit price. Notably, we demonstrate that, under some mild conditions, algorithmic markets based on cost function (or, equivalently, markets based on market scoring rules) aggregate the information of traders. ...|$|R
40|$|This paper {{researches}} {{the microstructure}} {{of the price}} process after the IPO, to gain insight into the information <b>aggregation</b> process <b>of</b> secondary <b>market</b> trading. We investigate a sample of 2, 040 US IPOs between 1993 and 2000 and find that it takes approximately one week for all IPO-related information to {{be reflected in the}} market price. Using a novel methodology to gauge event-time volatility, we attribute this fast information aggregation to the bookbuilding process and to the extraordinary liquidity in the IPO aftermarket. market microstructure; initial public offerings; IPOs; information aggregation; volatility; secondary market trading. ...|$|R
40|$|As a {{consequence}} <b>of</b> <b>aggregation</b> over <b>markets,</b> the observed quantity may b e {{less than the}} quantity demanded and less than the quantity supplied. To deal with such situations, a new technique is proposed for estim ating demand and supply curves {{and the extent of}} shortage and slack. The technique is applied to the consumption goods <b>markets</b> <b>of</b> Czechosl avakia, East Germany, Hungary, Poland, and Yugoslavia. It is found th at shortage, even corrected for a discouraged consumer effect, is sel dom as great as slack. Copyright 1988 by The Review of Economic Studies Limited. ...|$|R
40|$|WP 17 / 13; An {{essential}} part of any firm's corporate strategy is {{the choice of the}} business portfolio through which to compete. When the portfolio's decision involves more than one business, firms are said to implement a diversification strategy, which is put into action through the firms concomitant entry in different market segments. It implies that the nature <b>of</b> the <b>market</b> segmentation affects the firms' differentiation degree. The aim of this paper consists in exploring a method for determining the market segmentation that is most informative to understand firms' diversification strategies, or in other words the market segmentation that most clearly reveals about firms' main diversification drivers. Given that each business can be described according to a set of business characteristics and by using different levels of detail, in the perspective of understanding firm diversification strategies, it is fundamental to determine the directions in the space of business characteristics along which it is “mostly convenient” to claim the business diversity and which is the “best” level <b>of</b> <b>aggregation</b> at which assess the businesses boundaries. This paper proposes an experimental method to do it. In particular, it empirically discerns which of two particular criteria – functional versus technological – mostly enrich our understanding of the diversification strategies adopted by Italian plastic processing machinery suppliers, finding out the most instructive level <b>of</b> <b>aggregation</b> <b>of</b> the <b>market</b> segmentation – namely the best segment dimension – to investigate the firms diversification strategie...|$|R
40|$|During {{the past}} five years the Oesterreichische Nationalbank (OeNB), {{together}} with the Austrian Financial Market Authority (FMA) and university experts, has developed and implemented several modern tools for the purposes of off-site banking analysis and supervision. One of these tools is the Value-at-Risk (VaR) model, which allows for the standardized quantification of every single bank’s economic capital. Within this portfolio model framework, a total VaR is calculated as an <b>aggregation</b> <b>of</b> credit, <b>market</b> and operational VaR, assuming perfect correlation between the risk categories. The methodology for measuring the credit risk of a bank’s portfolio is currently based on the standard CreditRisk+ model, an actuarial model for aggregating risks in a credit portfolio with a single risk factor. In 2005 the OeNB and the Vienna University of Technology launched a research project with the aim of developing an extended version of the credit risk model that is able to account better for portfolio diversification effects. As the background risk factors in the standard CreditRisk model have to be orthogonal, resemblance to real-world industrial sectors or other macroeconomic factors, which often appear to be strongly correlated, is not possible. This paper gives an overview of our approach to modeling correlations among systematic risk factors. Other extensions of the model, like the ability to calculate a single obligor’s risk contribution and the incorporation of stochastic loss given default, are touched upon. Financial Stability...|$|R
40|$|This report {{provides}} {{a detailed description}} of the methodology used to construct ERS’s Quarterly Food-at-Home Price Database (Q-FAHPD). As the name suggest, these data provide quarterly observations on the mean price of 52 food categories for specific U. S. markets. We provide a description of the Nielsen Homescan data that was used to create this database, the methodology used to classify foods into food groups, how we determined the appropriate the level <b>of</b> <b>aggregation</b> (sub-regional <b>markets)</b> and our calculation of average prices for each food group. This report also contains an overview and summary of the resulting data. Nielsen Homescan, food prices, diet quality, market prices, Demand and Price Analysis, Food Consumption/Nutrition/Food Safety, Health Economics and Policy,...|$|R
40|$|Recent {{years have}} seen {{extensive}} investigation <b>of</b> the information <b>aggregation</b> properties <b>of</b> prediction <b>markets.</b> However, relatively {{little is known about}} conditions under which a market will aggregate the private information of rational risk averse traders who optimize their portfolios over time. We consider a market model involving finitely many informed risk-averse traders interacting with a market maker. Our main result identifies a basic smoothness condition on the price in the market that ensures information will be aggregated. We give conditions under which cost function market makers (or, equivalently, market makers based on market scoring rules) satisfy the smoothness requirement. We further show that regardless of the level of risk aversion of the traders, the final allocation and prices together constitute a competitive equilibrium; thus, in particular, the final portfolios of the traders are ex post Pareto efficient. 1...|$|R
40|$|International audienceThis paper {{focuses on}} {{causality}} in demand. A methodology where causality is imposed and tested within an empirical co-integrated demand model, not pre-specified, is suggested. The methodology allows different causality of different products {{within the same}} demand system. The methodology is applied to fish demand. On the German market for farmed trout and substitutes, {{it is found that}} supply sources, i. e. aquaculture and fishery, are not the only determinant of causality. Storing, tightness <b>of</b> management and <b>aggregation</b> level <b>of</b> integrated <b>markets</b> might also be important. The methodological implication is that more explicit focus on causality in demand analyses provides improved information. The results suggest that frozen trout forms part of a large European whitefish <b>market,</b> where prices <b>of</b> fresh trout are formed on a relatively separate market. Redfish is a substitute on both markets. The policy implication is that increased production of trout causes a downward pressure on fresh trout prices, but frozen trout prices remain relatively unaffected...|$|R
40|$|This paper {{focuses on}} {{causality}} in demand. A methodology where causality is imposed and tested within an empirical co-integrated demand model, not pre-specified, is suggested. The methodology allows different causality of different products {{within the same}} demand system. The methodology is applied to fish demand. On the German market for farmed trout and substitutes, {{it is found that}} supply sources, i. e. aquaculture and fishery, are not the only determinant of causality. Storing, tightness <b>of</b> management and <b>aggregation</b> level <b>of</b> integrated <b>markets</b> might also be important. The methodological implication is that more explicit focus on causality in demand analyses provides improved information. The results suggest that frozen trout forms part of a large European whitefish <b>market,</b> where prices <b>of</b> fresh trout are formed on a relatively separate market. Redfish is a substitute on both markets. The policy implication is that increased production of trout causes a downward pressure on fresh trout prices, but frozen trout prices remain relatively unaffected...|$|R
40|$|We analyze {{an economy}} where {{production}} {{is subject to}} moral hazard. The degree of the incentive #agency# costs introduced {{by the presence of}} moral hazard naturally depends on the information structure in the economy# it is cheaper to induce correct incentives in a society which posesses better ex post information. The degree of ex post information depends on the number of projects and entrepreneurs in the economy# the more projects# the better the information. This implies that at the early stages of development# the range of projects and the amount of information are limited and agency costs are high. Since the information created by a project is an externality on others# the decentralized economy is constrained ine#cient# in particular# it does not #experiment# enough. The analysis of the role of information also opens the waytoaninves# tigation of the development of #nancial institutions. We contrast the infor# mation <b>aggregation</b> role <b>of</b> stock <b>markets</b> and information pro [...] ...|$|R
40|$|This {{article focuses}} on {{causality}} in demand. A methodology where causality is imposed and tested within an empirical co-integrated demand model, not prespecified, is suggested. The methodology allows different causality of different products within the same demand system. The methodology is applied to fish demand. On the German market for farmed trout and substitutes, {{it is found that}} supply sources, i. e. aquaculture and fishery, are not the only determinant of causality. Storing, tightness <b>of</b> management and <b>aggregation</b> level <b>of</b> integrated <b>markets</b> might also be important. The methodological implication is that more explicit focus on causality in demand analyses provides improved information. The results suggest that frozen trout forms part of a large European whitefish <b>market,</b> where prices <b>of</b> fresh trout are formed on a relatively separate market. Redfish is a substitute on both markets. The policy implication is that increased production of trout causes a downward pressure on fresh trout prices, but frozen trout prices remain relatively unaffected. ...|$|R
40|$|The paper {{discusses}} {{the construction of}} a new Consumer Price Index (CPI) for New Zealand, 1885 - 1913, based upon <b>aggregation</b> <b>of</b> data from the four largest provincial districts: Auckland, Canterbury, Otago and Wellington. Using these new provincial data, we explore the degree <b>of</b> <b>market</b> integration within the New Zealand dairy and meat sectors, and consider whether anecdotal evidence on South-North price convergence is supported statistically...|$|R
40|$|Experience {{during the}} {{financial}} crisis illustrates that the integrated measurement and management of different forms of risk remains a challenge for industry practitioners, researchers and financial supervisors alike. In the context of related literature, this article summarizes new research on the interaction <b>of</b> <b>market</b> and credit risk and implications for risk management that is presented in this special issue. The research covered highlights in particular the errors that can occur in the <b>aggregation</b> <b>of</b> {{the two types of}} risk and the strong relationships between them that suggest caution in the use of pragmatic distinctions between them. The article also touches on some research-based lessons for supervisory policies and suggests some directions for future research. Risk management <b>Aggregation</b> <b>of</b> risks Financial regulation Banking...|$|R
40|$|Various studies <b>of</b> asset <b>markets</b> {{have shown}} that traders are capable of {{learning}} and transmitting information through prices in many situations. In this paper we replace human traders with intelligent software agents in a series <b>of</b> simulated <b>markets.</b> Using these simple learning agents, {{we are able to}} replicate several features of the experiments with human subjects, regarding (1) dissemination of information from informed to uninformed traders, and (2) <b>aggregation</b> <b>of</b> information spread over different traders...|$|R
40|$|A {{number of}} {{analytical}} techniques have potential applications in marketing management. A questionnaire survey <b>of</b> <b>marketing</b> managers reveals {{that although the}} level of awareness of such techniques is high the usage made of many of them is low. Optimising techniques are generally less widely used than those concerned with <b>aggregation</b> <b>of</b> judgements. Associations in the usage of techniques appear and although limited differences between types of industry are apparent in this respect, organizational differences appear to be less significant. ...|$|R
5000|$|The day the London Stock Exchange's rules {{changed on}} 27 October 1986 was dubbed the [...] "Big Bang" [...] {{because of the}} {{increase}} in market activity expected from an <b>aggregation</b> <b>of</b> measures designed to alter the structure <b>of</b> the financial <b>market.</b>|$|R
40|$|This {{project is}} a {{documentary}} film and script with an accompanying critical essay. The creative work under review is Family First – A Federal Crusade, made by the author for broadcast by ABC TV, Australia, on 1 May, 2005. The critical essay evaluates {{the process of creating}} this and other documentary films using the ‘guerrilla doc’ method. The first section seeks to define documentary through a review of it as a field of practice with its own literature. It charts the history of documentary practice, arguing that changes in technology and the marketplace have seen present-day documentary production determined, not only by technologies of production and distribution, but also by significant market forces, such as <b>aggregation</b> <b>of</b> television <b>markets</b> and fragmentation <b>of</b> audiences. Both had a profound implication for the aesthetic and practice of documentary filmmaking. The second section contextualises documentary as a field of practice by examining the current practice of four contemporary, observational ‘guerrilla’ documentarians: David Bradbury, Leonard Retel Helmrich, Olivia Roussett, and Faramarz K-Rahber. It examines in detail their equipment, techniques and, relationship with investors and broadcasters, and it illustrates how the ‘guerrilla doc’ form has allowed them greater flexibility, intimacy, and overall artistic control over their work. The third section is a critical reflection on the creation of my documentary, Family First – A Federal Crusade in the context <b>of</b> <b>markets,</b> technology, and aesthetics. This documentary was produced in classic ‘guerrilla’ mode, without a broadcaster presale or external investment until shooting was completed. It was compiled for transmission when ABC TV was attracted to the unique ‘insider’s view’ of the potent mix of politics and religion during the 2004 Australian federal election. This third section draws upon the insights of section one and two to critically evaluate the personal experiences of the author during the production and post-production of the creative project. The essay’s conclusion is that the intimacy achieved by the filmmaker with the participants would not have been as effective if the project had been attempted using a traditional crew setup. The essay concludes with reflections about the possibilities and limitations of the ‘guerrilla doc’ method and the future of ‘guerrilla docs’ in a global, but increasingly fragmented digital media market...|$|R
40|$|One proxy {{of price}} {{rationing}} of credit is an <b>aggregation</b> <b>of</b> information on interest rates, while loan officer survey data measures quantity rationing of credit, meaning some borrowers are denied loans. The latter Granger causes real GDP but the former does not. The loan officer survey {{is a better}} leading indicator <b>of</b> credit <b>market</b> conditions that affect real activity...|$|R
