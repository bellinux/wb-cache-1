30|16|Public
50|$|A major use {{of noise}} {{weighting}} {{is in the}} measurement of residual noise in audio equipment, usually present as hiss or hum in quiet moments of programme material. The purpose of weighting here is to emphasise {{the parts of the}} <b>audible</b> <b>spectrum</b> that ears perceive most readily, and attenuate the parts that contribute less to perception of loudness, {{in order to get a}} measured figure that correlates well with subjective effect.|$|E
50|$|Dazzler is a mutant {{with the}} ability to transduce sonic {{vibrations}} which leave her body into various types of light. This ability seems to operate over a great range of frequencies, including the <b>audible</b> <b>spectrum,</b> and a great variation of sound pressure levels regardless of the complexity, dissonance, or randomness of the sound. Sounds as different as a car crash and a symphonic passage both produce convertible incoming acoustic vibrations.|$|E
5000|$|A major use {{of noise}} {{weighting}} {{is in the}} measurement of residual noise in audio equipment, usually present as hiss or hum in quiet moments of programme material. The purpose of weighting here is to emphasise {{the parts of the}} <b>audible</b> <b>spectrum</b> that our ears perceive most readily, and attenuate the parts that contribute less to our perception of loudness, {{in order to get a}} measured figure that correlates well with subjective effect.|$|E
50|$|In comparison, the CD system {{offers a}} {{frequency}} response of 0 Hz-20 kHz ±0.5 dB, with a superior dynamic range {{over the entire}} <b>audible</b> frequency <b>spectrum.</b>|$|R
50|$|Acapella Audio Arts is a German {{manufacturer}} of loudspeakers, {{and one of}} the oldest hi-fi manufactures in Germany. Acapella Audio was founded by Alfred Rudolph and Herman Winters in 1978 in Duisburg, Germany. Acapella is famous for its heavy horn-loaded speakers that are able to reproduce the whole <b>audible</b> sound <b>spectrum.</b> Other signature characteristic for the products of the company is the widely utilized plasma tweeter technology.|$|R
5000|$|A moving {{aircraft}} {{including the}} jet engine or propeller causes compression and rarefaction of the air, producing motion of air molecules. This movement propagates {{through the air}} as pressure waves. If these pressure waves are strong enough and within the <b>audible</b> frequency <b>spectrum,</b> a sensation of hearing is produced. Different aircraft types have different noise levels and frequencies. The noise originates from three main sources: ...|$|R
50|$|This is {{a common}} {{artifact}} in sets that use a cathode ray tube. While all CRT-based television systems produce such a noise, the higher number of lines per second in later standards produces frequencies (PAL's 15,625 Hz and NTSC's 15,734 Hz) {{that are at the}} upper end of the <b>audible</b> <b>spectrum,</b> which not all people are able to hear. Modern sets using plasma, LCD or OLED display technology are completely free of this effect as they are composed of a million or more individually controllable elements, rather than using a single magnetically deflected beam, so there is no requirement to generate the scanning signal.|$|E
5000|$|In the US, {{there are}} [...] "pay-to-play" [...] "Battle of the Bands" [...] {{contests}} where bands pay {{to perform on}} stage. Billboard Magazine's Oct. 21, 2006, article [...] "Pay to Get Played" [...] described how a [...] "third-party booking agency in New Jersey" [...] called <b>Audible</b> <b>Spectrum</b> Records was [...] "charging bands up to $350 per show, promising services and opportunities that were never delivered". [...] "Battle of the Bands" [...] are becoming increasingly common in both the U.S.A. and Europe, particularly the U.K. Typically, each band that enters the [...] "battle" [...] will pay a fee, returnable only if a minimum number of tickets is sold for {{the first round of}} the contest. Progress in the contest is dependent on [...] "votes". A prize is usually given to the winner.|$|E
50|$|High {{fidelity}} {{made great}} advances during the 1970s, as turntables became very precise instruments with belt or direct drive, jewel-balanced tonearms, some with electronically controlled linear tracking and magnetic cartridges. Some cartridges had frequency response above 30 kHz {{for use with}} CD-4 quadraphonic 4 channel sound. A high fidelity component system which cost under $1,000 could {{do a very good}} job of reproducing very accurate frequency response across the human <b>audible</b> <b>spectrum</b> from 20 Hz to 20,000 Hz with a $200 turntable which would typically have less than 0.05% wow and flutter and very low rumble (low frequency noise). A well-maintained record would have very little surface noise, though it was difficult to keep records completely free from scratches, which produced popping noises. Another characteristic failure mode was groove lock, causing a section of music to repeat, separated by a popping noise. This was so common that a saying was coined: you sound like a broken record, referring to someone who is being annoyingly repetitious.|$|E
50|$|A {{mid-range}} {{driver is}} {{called upon to}} handle the most {{significant part of the}} <b>audible</b> sound <b>spectrum,</b> the region where the most fundamentals emitted by musical instruments and, most importantly, the human voice, lie. This region contains most sounds which are the most familiar to the human ear, and where discrepancies from faithful reproduction are most easily observed. It is therefore paramount that a mid-range driver of good quality be capable of low-distortion reproduction.|$|R
40|$|Abstract—A novel speech {{enhancement}} technique is presented {{based on the}} definition of the psychoacoustically derived quantity of <b>audible</b> noise <b>spectrum</b> and its subsequent suppression using optimal nonlinear filtering of the short-time spectral amplitude (STSA) envelope. The filter operates with sparse spectral es-timates obtained from the STSA, and, when these parameters are accurately known, significant intelligibility gains, up to 40 %, result in the processed speech signal. These parameters can be also estimated from noisy data, resulting into smaller but significant intelligibility gains. I...|$|R
40|$|In {{this work}} we {{consider}} adaptive bit allocation for percep-tual coding of narrowband audio signals at low rates (down to 8 kb/s). Two different strategies {{are used to}} shape the <b>audible</b> noise <b>spectrum.</b> In one approach, the quantiza-tion noise spectrum is shaped in parallel with the masking threshold curve. This way the noise is equally audible in different frequency bands. The other approach generates a flat noise spectrum above the masking threshold. The noise power is not equally distributed over the frequency range, hence it is audible to various extents at different frequencies. ...|$|R
5000|$|With all {{of these}} improvements, the best units could record and play the full <b>audible</b> <b>spectrum</b> from 20 Hz to over 20 kHz (although this was {{commonly}} quoted at -10, -20 or even -30 dB, not at full output level), with wow and flutter less than 0.05% and very low noise. A high-quality recording on cassette could rival {{the sound of an}} average commercial CD, though the quality of pre-recorded cassettes has been regarded by the general public as lower than could be achieved in a quality home recording. There was a call for better sound quality in 1981, surprisingly by the head of Tower Records, Russ Solomon. At a meeting of the National Association of Recording Merchandisers (NARM) Retail Advisory Committee in Carlsbad, California, Solomon played two recordings of a Santana track; one he had recorded himself and the pre-recorded cassette release from Columbia Records. He used this technique to demonstrate what he called [...] "the tunnel effect" [...] in the audio range of pre-recorded cassettes and commented to the reporter Sam Sutherland, who wrote a news article printed in Billboard magazine: ...|$|E
40|$|We are {{all used}} {{to the concept of}} a subwoofer, used to extend the low {{frequency}} response of a loudspeaker system for added realism. A SuperTweeter ™ in effect does the same thing, but {{at the other end of}} the <b>audible</b> <b>spectrum,</b> extending the frequency range of the loudspeaker several octaves above the accepted limit o...|$|E
30|$|Numerical {{results show}} that after CLD placement, the {{radiated}} structural noise was effectively reduced across the entire <b>audible</b> <b>spectrum,</b> with the decrease in SPL ranging 3.9 – 4.3  dB(A) at different field points. Moreover, the SPL decrease underneath the bridge was greater than that above the bridge. The vibratory velocity of the longitudinal girder web and bottom flange decreased by 10.5 and 6.1  dB, respectively, showing excellent effectiveness.|$|E
40|$|The {{audible noise}} {{produced}} by three-phase, squirrel-cage induction motors, {{is caused by}} the space harmonics of the flux-density distribution in the air gap of the machine. When the motor is supplied by a frequency inverter in order to control the speed, time harmonics in both current and voltage are present, yielding new components in the <b>audible</b> noise <b>spectrum.</b> In the paper; a number of motor-inverter combinations are compared for medium-sized induction motors (90 kW). As a reference case, the motors are supplied with a generator, delivering a variable frequency without harmonics. Theoretical explanations for the increase of the audible noise level and the additional frequency components are given. status: publishe...|$|R
50|$|Many {{high quality}} {{domestic}} speakers have a sensitivity between ~84 dB and ~94 dB, but professional speakers {{can have a}} sensitivity between ~90 dB and ~100 dB. An '84 dB' source would require a 400-watt amplifier to produce the same acoustical power (perceived loudness) as a '90 dB' source being driven by a 100-watt amplifier, or a '100 dB' source being driven by a 10 watt amplifier. A good measure of the 'power' of a system is therefore a plot of maximum loudness before clipping of the amplifier and loudspeaker combined, in dB SPL, at the listening position intended, over the <b>audible</b> frequency <b>spectrum.</b> The human ear is less sensitive to low frequencies, as indicated by Equal-loudness contours, so a well-designed system should be capable of generating relatively higher sound levels below 100 Hz before clipping.|$|R
40|$|A {{detailed}} study {{was performed to}} simultaneously measure the mechanical and acoustic properties of crispy cellular solid foods. Different critical aspects are discussed {{in order to assess}} optimal test conditions. These are primarily data sampling rate, microphone positioning, frequency spectrum of interest, sound/noise ratio and selection of measuring probe. A data sampling rate of more than 50 kHz was shown to be sufficient to register fracture event and acoustic event, and the frequencies audible by human ear (at least 40 kHz needed). The optimum positioning of the microphone with respect to the test piece should be a compromise between a distance that the microphone registers a good sound over the whole human <b>audible</b> frequency <b>spectrum</b> and a good sound/noise ratio. It is shown that test method selection has to depend on whether the goal is determining material fracture behavior or correlation of data to consumer perception. The best method from a fracture mechanics point of view {{does not have to be}} the best choice for a combined fracture and acoustic measurement. © 2007. Blackwell Publishing...|$|R
40|$|This report {{details the}} design and {{construction}} of a 100 W Solid State guitar amplifier. The preamplifier is composed primarily of three user interchangeable electronic modules that together combine the preamp's signal processing characteristics. A template for module design is presented to ease design of additional preamplifier modules. The three-stage power amplifier's output circuit operates in biased Class B, with parameters selected to minimize crossover distortion and give remarkably low THD across the <b>audible</b> <b>spectrum...</b>|$|E
30|$|The {{advantage}} of this measurement technique over the sine analysis (Section 2.2) is that it displays more information in a single figure by drawing the magnitude responses {{as a function of}} the (fundamental) frequency on the full audio frequency range. For analyzing the magnitude of high-order distortion components, however, the sine analysis is usually better since it displays the entire <b>audible</b> <b>spectrum</b> in one figure, while the logsweep analysis can successfully be used to track only the low-order distortion components, due to clarity reasons and the aforementioned SNR issue. Another drawback of the logsweep analysis technique is that long excitation signals can take a long time to analyze due to the relatively slow computation of long convolutions.|$|E
40|$|Noise {{emitted by}} heating, {{ventilation}} {{and air conditioning}} (HVAC) systems {{is one of the}} main causes of disturbance inside buildings. High frequency noise can be reduced using passive devices, but noise components at frequencies below 400 - 500 Hz are hardly reduced in such way. Active noise control (ANC) has its maximum efficiency at low frequency and then it is the ideal complement to passive techniques for achieving acoustic comfort over the whole <b>audible</b> <b>spectrum.</b> In this paper the maximum performance of an experimental active noise control system is investigated. A real scale model of an air conditioning system was built and the ANC system was applied to it. The performance of the ANC system has been tested in a realistic case (HVAC system terminating into a room) and by placing an anechoic termination at the end of the duct...|$|E
40|$|Even {{in these}} days where data {{networks}} has increased much in terms of speed, bandwidth and penetration, {{the need for a}} low power, low bandwidth, ubiquitous networks is more pronounced than ever before. As the devices get smaller, their power supply is also limited, in according to the definition of 'dust', 'skin' and 'clay' in the ubiquitous computing paradigm. The possibility of these devices to be present in real world depends a lot on the key capability they must possess, which is to be network enabled, ubiquitously. This paper looks at the possibility of using the ever present signal 'sound' as a ubiquitous medium of communication. We are currently experimenting on various possibilities and protocols that can make use of sound for text transmission between two electronic devices and this paper looks at some attempts in this direction. The initial phase of the experiment was conducted using a very large spectrum and encoding the entire ASCII text over <b>audible</b> sound <b>spectrum.</b> This gave a very large spectrum spread requirement which a very narrow frequency gap. The experimental results showed good improvement when the frequency gap was increased...|$|R
40|$|Safe {{operation}} of kinetic pumps, as liquid movers, can {{be threatened by}} cavitation phenomenon in, amongst others. Cavitation is the Achilles 2 ̆ 7 heel of kinetic pumps. It can cause deterioration of the hydraulic performance, damage of the pump by pitting and material erosion, and structure vibration and noise. Cavitation can appear within {{the entire range of}} operating conditions, therefore it must by all means be prevented. To prevent cavitation in a pump we have to know the beginning and development of the cavitation in the pump. For this purpose, the emitted noise in the audible range can be used, amongst other possibilities. Experiments have shown that there is a discrete frequency tone within the <b>audible</b> noise <b>spectra,</b> which is in strong correlation with development of the cavitation process in the pump. Therefore, the discrete frequency tone can be separated from the noise spectra of a cavitating pump and used to detect the incipient of cavitation and its development as well as to prevent the onset of the cavitation process in the pump, by means of initiating an alarm, shutdown, or control signal via an electrical control system...|$|R
5000|$|Although {{a number}} of {{short-lived}} [...] "hybrid" [...] studio and consumer technologies appeared in this period (e.g. Digital Audio Tape or DAT, which recorded digital signal samples onto standard magnetic tape), Sony assured the preeminence of its new digital recording system by introducing, together with Philips, the most advanced consumer audio format to date — the digital compact disc (CD). The Compact disc rapidly replaced both the 12" [...] album and the 7" [...] single as the new standard consumer format, and ushered {{in a new era}} of high-fidelity consumer audio — CDs were small, portable and durable, and they could reproduce the entire <b>audible</b> sound <b>spectrum,</b> with unrestricted dynamic range, perfect clarity and no distortion. Because CDs were encoded and read optically, using a laser beam, there was no physical contact between the disc and the playback mechanism, so a well-cared-for CD could be played over and over, with absolutely no degradation or loss of fidelity. CDs also represented a considerable advance in both the physical size of the medium, and its storage capacity — LPs could only practically hold about 50 minutes of audio, because they were physically limited {{by the size of the}} disc itself and the density of the grooves that could be cut into it — the longer the recording, the closer together the grooves and thus the lower the overall fidelity; CDs, on the other hand they were less than half the overall size of the old 12" [...] LP format, but offered about double the duration of the average LP, with up to 80 minutes of audio.|$|R
40|$|This work {{deals with}} {{the design of a}} 10 -zones {{equalizer}} with optimized frequency characteristics with a spectrum audio analyzer. In this work the problem of processing audio signals using equalization for filtering the interference frequencies, correction of frequency cover signal boost or suppression of the required zones of the <b>audible</b> <b>spectrum</b> are also analyzed. The influence of subjective perception of sound intensity of the audio signals reproduction and its use in working with equalizer is discussed too. The work describes the principles and usage of the audio-analyzer as a tool for the optimization of the audio equalization setting when ensuring the appropriate listening conditions of music reproduction, spoken word, sounds, etc. It also focuses on the signal source for testing audio-chains, their generation and measurement using the audio analyzer. The equalizer equipment, audio-analyzer generator of reference signals equipment and power supply are designed as a single unit...|$|E
40|$|In audio processing, {{equalization}} is {{the process}} of changing the frequency envelope of a sound. In passing through any channel, frequency spreading occurs. In this project I have build 9 band graphic equalizer. The graphic equalizer has become very popular in recent years. It is called graphic because, as the front-panel sliders or knob are adjusted; their positions give an approximate display of the resultant frequency response. This device divide the <b>audible</b> <b>spectrum</b> into nine frequency bands, and allow adjustments to each band via its own boost/cut control gain from 1. 17 to 6. A growing number of audio enthusiasts are using equalizers to adjust their stereo system's frequency response, whether to compensate for room acoustics, for PA system or for creative recording purposes. Instead of broad adjustments of treble, bass, and maybe the midrange (sometimes called presence), we now have independent control over the low bass, mid-bass, high bass, low midrange, and so forth...|$|E
40|$|Disclosed is {{a method}} for modifying the {{frequency}} response of a wood panel within an acoustical structure such as a studio or concert hall. The modification is imparted by exciting the wood paneling with acoustic energy. Frequency response is the measure of a system 2 ̆ 7 s spectrum response at the output to a signal of varying frequency (but constant amplitude) at its input. The acoustic energy includes at least one excitation frequency, which is preferably in the <b>audible</b> <b>spectrum</b> (20 to 20, 000 Hz). The use of acoustic energy from the remote source provides non-contact excitation of the wood paneling. In one embodiment, the acoustic energy {{is at least one}} sound wave which comprises at least one resonant frequency of the wood paneling, at least one acoustic mode of the wood paneling, at least one discrete broadband frequency, a composite frequency (including multiple broadband frequencies, white noise and pink noise) or any combination thereof...|$|E
5000|$|The {{earliest}} practical recording technologies {{were entirely}} mechanical devices. These recorders typically used a large conical horn {{to collect and}} focus the physical air pressure of the sound waves produced by the human voice or musical instruments. A sensitive membrane or diaphragm, located {{at the apex of}} the cone, was connected to an articulated scriber or stylus, and as the changing air pressure moved the diaphragm back and forth, the stylus scratched or incised an analogue of the sound waves onto a moving recording medium, such as a roll of coated paper, or a cylinder or disc coated with a soft material such as wax or a soft metal. These early recordings were necessarily of low fidelity and volume, and captured only a narrow segment of the <b>audible</b> sound <b>spectrum</b> — typically only from around 250 Hz up to about 2,500 Hz — so musicians and engineers were forced to adapt to these sonic limitations. Bands of the period often favored louder instruments such as trumpet, cornet and trombone, lower-register brass instruments (such as the tuba and the euphonium) replaced the string bass, and blocks of wood stood in for bass drums; performers also had to arrange themselves strategically around the horn to balance the sound, and to play as loudly as possible. The reproduction of domestic phonographs was similarly limited in both frequency-range and volume — this period gave rise to the expression [...] "put a sock in it", which commemorates the common practice of placing a sock in the horn of the phonograph to muffle the sound for quieter listening. By the end of the acoustic era, the disc had become the standard medium for sound recording, and its dominance in the domestic audio market lasted {{until the end of the}} 20th century.|$|R
40|$|Increasing quality {{demands of}} {{combustion}} engines require, amongst others, improvements of the engine’s acoustics and all (sub) components mounted to the latter. A significant impact to the <b>audible</b> tonal noise <b>spectrum</b> {{results from the}} vibratory motions of fast-rotating turbocharger rotor systems in multiple hydrodynamic bearings such as floating bearing rings. Particularly, the study of self-excited non-linear vibrations of the rotor-bearing systems is crucial for the understanding, prevention or reduction of the noise and, consequently, for a sustainable engine acoustics development. This work presents an efficient modeling approach for the investigation, optimization, and design improvement of complex turbocharger rotors in hydrodynamic journal bearings, including floating bearing rings with circular and non-circular bearing geometries. The capability of tonal non-synchronous vibration prevention using non-circular bearing shapes is demonstrated with dynamic run-up simulations of the presented model. These findings {{and the performance of}} our model are compared and validated with results of a classical Laval/Jeffcott rotor-bearing model and a specific turbocharger model found in the literature. It is shown that the presented simulation method yields fast and accurate results and furthermore, that non-circular bearing shapes are an effective measure to reduce or even prevent self-excited tonal noise...|$|R
40|$|Presented at the 16 th International Conference on Auditory Display (ICAD 2010) on June 9 - 15, 2010 in Washington, DC. Capturing a {{scene for}} later or {{contemporaneous}} display needs {{to capture the}} complex interactions between the source(s) in the scene and the environment. High order spherical Ambisonics and plane-wave analysis are powerful mathematical tools for such scene analysis. The spherical microphone array (and its embodiment in the Audio Camera) is {{a useful tool for}} capture and analysis of scenes. Further information about the environment is available from the visual scene. We present the audio-visual panoramic camera as a tool that greatly simplifies the task of processing audio visual information by providing one common framework for both modalities. Via the Audio Camera [1], we show that microphone arrays {{can be viewed as a}} central projection camera that can effectively image the <b>audible</b> acoustic frequency <b>spectrum.</b> We demonstrate a new device, the audio visual Panoramic camera that is composed of a 64 channel spherical microphone array combined with a 5 element video camera array. The combined sensor is capable of real-time audio visual panoramic image generation using state of the art NVidia Graphics cards. It also provides an order- 7 ambisonic description of the scene...|$|R
40|$|Abstract — Communication {{relies on}} good understanding. Humans {{relate to each}} other through visual, audible and tactile communication. It is {{imperative}} that the audible communication message reaches the receiver in good conditions, in order to keep a healthy, smooth and understandable speech. There are some disturbances in human speech and communication when hearing damage is present. Nowadays, hearing loss is a frequent injury, caused by noise pollution, daily stress or noisy workplaces. Yet, it can be treated by several ways. This project consists in developing a tool that captures the emitter's voice <b>audible</b> <b>spectrum,</b> filters the noise and other frequencies, and compensates the message, enabling the listener/receiver understanding. The purpose of this research is not aimed to substitute nor compete with hearing aids in the market, which are well-developed, certified and prescribed by Otorhinolaryngology clinicians. The focus {{of this study is to}} identify the issues of human hearing loss and to develop an algorithm for hearing compensation by using filtering techniques in a simulated environment applied to a hearing model...|$|E
40|$|Cavitation in a kinetic pump reduces {{delivery}} head {{and efficiency of}} the pump. It also causes mechanical damage and an increase of vibrations and noise. Therefore, {{it is important to}} detect inception and development of a cavitation phenomenon in the pump. This article deals with signals of vibration and noise, which will be used for detection and monitoring of the cavitation in kinetic pumps, and also to prevent the effect of the cavitation in the pump and pumping system. When the cavitation is increasing, the flowing conditions are changing, which leads to an increase of vibrations of the pump and emitted noise in the surroundings. Because vibrations and noise are transferred from the pump through its casing, the signal is non-uniformly distorted due to transfer losses and structure of the casing surfaces. Noise and vibrations are increasing steadily, but in some specific frequency ranges the signal is more pronounced than {{in other parts of the}} spectrum. Experimental results have shown that vibration and noise in the <b>audible</b> <b>spectrum</b> can be successfully used for cavitation detection and its prevention...|$|E
40|$|Abstract—Complete genomic {{sequences}} from biological {{species can}} be graphically {{represented by a}} “genomic sig-nature”. This representation provides information about the oligonucleotide frequencies considering different size of k-mers. Moreover, genomic sequences can also be represented by an audio signal, obtained by translating each oligonucleotide or protein into a certain range of audio frequencies. Although audio representation strategies provide an interesting result, they only use part of the genomic sequence. To date no method exists which contemplates the complete genome sequence. This work proposes a new method for audio representation of genomes by composing a polyphonic signal using a set of complete genomic sequences. This method is described here by first extracting the genomic signature for each sequence. Then, to obtain the audio signal, two-dimensional genomic signatures are transformed into a one-dimensional sequence by normalizing each value into an <b>audible</b> <b>spectrum.</b> Finally each signal, depending {{on the number of}} sequences, is played on a different channel to generate a polyphonic track. The experimental results and the audio analysis suggest that the described method, preserves the main patterns and genome structure from the original sequence. I...|$|E
40|$|The Southern Ocean {{is one of}} {{the most}} diverse soundscapes of earth. The {{dynamics}} of the cryosphere i. e. sea ice, glaciers and icebergs create unique acoustic conditions. During polar winter the snow covered sea ice shields the ocean from atmospheric influences, suppresses the creation of waves and resembles an almost perfect acoustic absorber, thus creating one of the quietest environments of all oceans. On the other hand, large table icebergs calved from the enormous ice sheet of the Antarctic continent are the largest moving objects on earth and can accumulate kinetic energy in the terajoule range when driven by circumpolar currents. This energy is eventually released when these giants collide with the continental or ice shelves - events that create some of the loudest sounds in the sea which can be detected thousands of kilometers away. However, these are singular events which occur only few times per year. Typically the acoustic environment is dominated by the vocalizations of marine mammals. Most remarkable, the chorus of blue whales represents the spectral peak of the acoustic <b>spectrum,</b> <b>audible</b> almost during every single minute of the year despite the remaining population of blue whales in the Southern Ocean is just 2300 animals – compared to about 350. 000 in the pre whaling area 100 years ago. The second largest source of acoustic energy are Antarctic Minke whales - the main target of today’s scientific whaling. The relation between these animals and a sound of formerly unknown origin was just recently identified in 2013. Long term acoustic monitoring of this ecosystem thus can yield easy indicators for the population development of these animals. In 2005 we set up the autonomous PALAOA observatory on the Eckström ice shelf, an acoustic array deployed through bore holes into the ocean under a 100 m thick ice sheet. In 2009 we started to add long term deep water acoustic recorders to most of the oceanographic moorings that are deployed throughout the Weddell Sea, creating a basin wide acoustic array with 20 nodes at the moment. An international project will extend this to a circum- Antarctic installation during the next years, aiming to infer the complete spatio-temporal distribution of the Antarctic great whales. While the long term recorders are typically recovered every three years and their data are analyzed offline, the PALAOA data is streamed live via satellite to the lab and the public internet. This allows to direct field parties immediately to the seaside when interesting acoustic events are detected. Additional sensors provide related information that helps to interpret the acoustics. An AIS receiver monitors all ship traffic in the area to analyze human impacts. A CTD probe delivers oceanographic data. Meteorology and webcams make local weather and ice conditions accessible. Relating the acoustics to the medium and large scale ice situation is possible through high resolution ASAR images, provided by several satellites. All this data is collected in a database at the Alfred Wegener Institute and published in the PANGAEA data center. Live audio stream and historical data are available via www. awi. de/palaoa...|$|R
40|$|Communication {{relies on}} good understanding. Humans {{relate to each}} other through visual, audible and tactile communication. It is {{imperative}} that the audible communication message reaches the receiver in good conditions, in order to keep a healthy, smooth and understandable speech. There are some disturbances in human speech and communication when hearing damage is present. Nowadays, hearing loss is a frequent injury, caused by noise pollution, daily stress or noisy workplaces. Yet, it can be treated by several ways. This project consists in developing a tool that captures the emitter's voice <b>audible</b> <b>spectrum,</b> filters the noise and other frequencies, and compensates the message, enabling the listener/receiver understanding. The purpose of this research is not aimed to substitute nor compete with hearing aids in the market, which are well-developed, certified and prescribed by Otorhinolaryngology clinicians. The focus {{of this study is to}} identify the issues of human hearing loss and to develop an algorithm for hearing compensation by using filtering techniques in a simulated environment applied to a hearing model...|$|E
40|$|The aim for {{the thesis}} project is to design a concert venue for the City of Saint Albans, Vermont. The venue will serve as an {{entertainment}} hotspot, an educational tool, a set of rehearsal spaces, and performance halls with recording capabilities. The {{goal is to create}} a welcoming entertainment and educational environment, open to use by all, to show that music is more than entertainment, but also a hobby, an educational medium, a skill-set, and a tool. The driving theme behind the project is the concept of 2 ̆ 2 movement. 2 ̆ 2 Its first representation is in music. Sound itself is movement; it is pressure; it is the air moving around you, translated to the <b>audible</b> <b>spectrum</b> by your ears and brain. It is impossible to perform music without moving in some way. Second, water will be moving through the building (as in all buildings), but in this special case through an in-pipe microhydropower system. Lastly, the idea of a landmark, contemporary concert hall in Saint Albans constitutes progress and forward movement in the City’s development...|$|E
