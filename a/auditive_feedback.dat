9|1|Public
40|$|Abstract. In {{this paper}} the {{architecture}} and functionality of a person-alized body motion sensitive training {{system based on}} <b>auditive</b> <b>feedback</b> is discussed. The system supports recognition of body motion using body worn sensors and gives the user feedback {{about his or her}} current status in adaptively selecting audio files accompanying the speed and path of exercise...|$|E
40|$|In {{the therapy}} {{of the hearing}} {{impaired}} {{one of the central}} problems is the handling of the lack of proper <b>auditive</b> <b>feedback</b> which impedes the development of intelligible speech. Our Phonological Awareness Teaching System, the ”Speech-Master ” package, seeks to apply speech recognition technology to speech therapy [7, 8]. It provides a visual phonetic feedback for replacing the insufficient <b>auditive</b> <b>feedback</b> of the hearing impaired. We designed and implemented computer-aided training software that uses an effective phoneme recognizer and provides a realtime visual feedback in the form of flickering letters on calling pictures. The brightness of the letters is proportional to the speech recognizers output. The effectiveness of the therapy relies heavily on accurate phoneme recognition. Phoneme recognition is a special pattern recognition problem [1, 2, 11] where the continuously varying speech signal has to be mapped to a symbol of a phoneme. Because of the environmental conditions, simple recognition algorithms may have a weak classification performance, so various techniques such a...|$|E
40|$|The {{increase}} of the dorsal flexion of the ankle and {{the control of the}} inversion of the foot have been evaluated in a clinical study conducted in a group of adult chronic patients affected from hemiplegia. The patients were provided with visual and <b>auditive</b> <b>feedback</b> of the electrical activity of the muscles peronaeus longus and extensor communis. Data obtained demonstrate that by EMG feedback the expected increase in the dorsal flexion of the ankle and the control of the inversion of the foot together with an improvement in walking and stair climbing has been obtained...|$|E
40|$|Abstract — Feedback stimuli are {{fundamental}} components in Brain-Computer Interfaces. It {{is known that}} the presentation of feedback stimuli elicits certain brain potentials that can be measured and classified. As stimuli can be given through different sensory modalities, {{it is important to}} understand the effects of different types of feedback on brain responses and their impact on classification. This paper presents a protocol used to obtain brain potentials elicited by visual, <b>auditive</b> or vibrotactile <b>feedback</b> stimuli. Experiments were carried out with five different subjects for each modality. Four different single-trial classification strategies were compared, according to the information used to train the classifier, achieving a classification rate of approximately 80 % for each modality. I...|$|R
40|$|Presented at the 17 th International Conference on Auditory Display (ICAD 2011), 20 - 23 June, 2011 in Budapest, Hungary. Upper limb amputees {{have to rely}} {{extensively}} on visual feedback in order to monitor and manipulate successfully their prosthetic device. This situation leads to high consciousness burden, which generates fatigue and frustration. Therefore, {{in order to enhance}} motor-sensory performance and awareness, sonification of the prosthetic hand's spatio-temporal and force information was implemented in a real setting. The main purpose is to explore the difficulties people face when using a prosthetic hand and how the usage of auditory information affects their performance. Preliminary results showed that the temporal performance and the grasping performance was improved, also that the mental effort was reduced, when using <b>auditive</b> <b>feedback...</b>|$|E
40|$|AbstractIn {{swimming}} sport, {{the proper}} perception of moving water masses {{is a key}} factor. This paper presents an embedded system for the acquisition of values of pressure on swimmers hands and their transformation into sound. The sound, obtained using sonification, is used as an auditive representation of hand-water interactions while swimming in water. The sound obtained is used as an <b>auditive</b> <b>feedback</b> for the swimmer and as an augmented communication channel between the swimming trainer and the athlete. The developed system is self-contained, battery powered and able to work continuously for over eight hours, thus, representing a viable solution for daily usage in swimmers training. Preliminary results from in-pool experiments with both novel and experienced swimmers demonstrate the high acceptability of this technology and its promising future evolution and usage possibilities...|$|E
40|$|BACKGROUND AND AIM: Several {{studies have}} shown that {{feedback}} in upper-leg prostheses is possible, but slow or difficult to interpret. In this study, electrotactile and auditive error-based feedback, only giving feedback when an undesired event occurs, were tested for its use in upper-leg prosthesis when provided during a perturbation. TECHNIQUE: A total of nine healthy subjects walked on a prosthetic simulator which was disturbed {{at the end of the}} swing phase. They received either no feedback, electrotactile feedback, or <b>auditive</b> <b>feedback</b> at the time of the perturbation. DISCUSSION: The reaction time of the subjects only improved by 40 ms when using auditory feedback, compared to the no-feedback condition. No changes in reaction time were found in the electrotactile feedback condition. Considering perturbation detection was not taken into account in this study, this improvement is not enough for practical applications in upper-leg prosthesis. CLINICAL RELEVANCE: Many transfemoral amputees are insecure about their prosthesis, are afraid of falling, or actually fall. Providing feedback specifically during a perturbation may prevent them from falling, or at least give them a chance to react...|$|E
40|$|While {{learning}} new motor skills, we often rely on feedback from a trainer. <b>Auditive</b> <b>feedback</b> and demonstrations are used most frequently, {{but in many}} domains they are inappropriate or impractical. We introduce tactile instructions {{as an alternative to}} assist in correcting wrong posture during physical activities, and present a set of full-body vibrotactile patterns. An initial study informed the design of our tactile patterns, and determined appropriate locations for feedback on the body. A second experiment showed that users perceived and correctly classified our tactile instruction patterns in a relaxed setting and during a cognitively and physically demanding task. In a final experiment, snowboarders on the slope compared their perception of tactile instructions with audio instructions under real-world conditions. Tactile instructions achieved overall high recognition accuracy similar to audio instructions. Moreover, participants responded quicker to instructions delivered over the tactile channel than to instructions presented over the audio channel. Our findings suggest that these full-body tactile feedback patterns can replace audio instructions during physical activities. Author Keywords Vibrotactile feedback, real-time instructions, physical activities...|$|E
40|$|I {{would like}} to take the {{opportunity}} to thank the test persons involved in the project, for their comments and evaluations of the prototype. Their findings are invaluable for prospective work and further investigation in this matter. I am specially grateful to my supervisor Kirsten Rassmus-Gröhn for all help and com-mitment in the project. Miguel Molina, September 2010 i ii This master’s dissertation describes a study that relates to persons with visual impairments, and wayfinding using a smartphone with touchscreen. The study consists of the development of a prototype and an evaluation of its usability while interacting with haptic and <b>auditive</b> <b>feedback.</b> The prototype was developed for the Android platform. It provides a way of scanning for points of interest while pointing at them with a mobile phone and then choosing to be guided to them. The evaluation was executed by six users, five participants with visual impairments and one sighted, in an open area. The evaluation showed that users found the application usable. The scanning approach was perceived more valuable than the guiding because of gps inaccuracy and the lack of routing built into the application...|$|E
40|$|This paper {{describes}} work {{in progress}} on automatic generation of "impact sounds" based on physical modelling. These sounds {{can be used as}} non-speech audio presentation of objects and as interaction-mechanisms to non visual interfaces. In this paper especially we present the complete physical model for impact sounds "spherical objects hitting flat plates or beams. " The results of analysing of some examples of recorded (digitised) "impact sounds" and their comparisons with some theoretical aspects are discussed in this paper. These results are supposed to be used as input for the next phases of our audio framework project. The objective of this research project (joint project University of Zurich and Swiss Federal Institute of Technology) is to develop a concept, methods and a prototype for an audio framework. This audio framework shall describe sounds on a highly abstract semantic level. Every sound is to be described as the result of one or several interactions between one or several objects at a certain place and in a certain environment. Keywords: non speech sound generation, visual impairment, auditory interfaces, physical modelling, <b>auditive</b> <b>feedback,</b> human computer interaction, software ergonomics, usability engineering, material properties...|$|E

