171|70|Public
25|$|By the 1950s {{the success}} of digital {{electronic}} computers had spelled the end for most <b>analog</b> <b>computing</b> machines, but hybrid analog computers, controlled by digital electronics, remained in substantial use into the 1950s and 1960s, and later in some specialized applications.|$|E
25|$|The {{first modern}} analog {{computer}} was a tide-predicting machine, invented by Sir William Thomson, later Lord Kelvin, in 1872. It used {{a system of}} pulleys and wires to automatically calculate predicted tide levels for a set period at a particular location and was of great utility to navigation in shallow waters. His device was the foundation for further developments in <b>analog</b> <b>computing.</b>|$|E
25|$|The {{advent of}} digital {{computing}} made simple analog computers obsolete {{as early as}} the 1950s and 1960s, although analog computers remained in use in some specific applications, like the flight computer in aircraft, and for teaching control systems in universities. More complex applications, such as synthetic aperture radar, remained the domain of <b>analog</b> <b>computing</b> well into the 1980s, since digital computers were insufficient for the task.|$|E
40|$|A density search {{clustering}} {{technique is}} presented for a univariate population through the component {{separation of the}} corresponding mixture probability density function. This is done through the formulation of a special linear programming problem {{for the purpose of}} mixture analysis, which can be readily solved on an <b>analog</b> <b>compute...</b>|$|R
40|$|The graph {{of atomic}} orbitals (GAO) {{is a novel}} type of {{molecular}} graph, recently proposed {{by one of the}} authors. Various molecular structure-descriptors computed for GAO are compared with their <b>analogs</b> <b>computed</b> for ordinary molecular graphs. The quality of these structure-descriptors was tested for correlation with the normal boiling points of alkanes and cycloalkanes. In all the studied cases, the results based on GAO are similar to, and usually slightly better than, those obtained by means of ordinary molecular graps...|$|R
40|$|Automated formula {{manipulation}} {{is central}} to object-oriented continuous-system modeling. Such techniques are needed to a) solve the causality assignment problem in modeling any kind of energy transducer, b) generate the equations that result from the couplings between different objects, c) automatically reduce higher index models, and d) take care of algebraic loops that often result from subsystem couplings, and that also occur from the reduction of higher index models. A new tool, Dymola, imple-ments all of these formula manipulation techniques, {{and can be used}} to generate state-space models in a variety of different simulation languages (ACSL, DESIRE, DSblock, Simnon, and SIMULINK). Simulation Languages The first generation of digital continuous-system simulation languages were designed to resemble <b>analog</b> <b>compute...</b>|$|R
25|$|The art of {{mechanical}} <b>analog</b> <b>computing</b> reached its zenith with the differential analyzer, built by H. L. Hazen and Vannevar Bush at MIT starting in 1927, which {{built on the}} mechanical integrators of James Thomson and the torque amplifiers invented by H. W. Nieman. A dozen of these devices were built before their obsolescence became obvious; the most powerful was constructed at the University of Pennsylvania's Moore School of Electrical Engineering, where the ENIAC was built.|$|E
25|$|However, the {{difference}} between these systems is what makes <b>analog</b> <b>computing</b> useful. If one considers a simple mass–spring system, constructing the physical system would require making or modifying the springs and masses. This would be followed by attaching them to each other and an appropriate anchor, collecting test equipment with the appropriate input range, and finally, taking measurements. In more complicated cases, such as suspensions for racing cars, experimental construction, modification, and testing is both complicated and expensive.|$|E
25|$|With the {{development}} of very-large-scale integration (VLSI) technology, Yannis Tsividis' group at Columbia University has been revisiting analog/hybrid computers design in standard CMOS process. Two VLSI chips have been developed, an 80th-order analog computer (250nm) by Glenn Cowan in 2005 and an 4th-order hybrid computer (65nm) developed by Ning Guo in 2015, both targeting at energy-efficient ODE/PDE applications. Glenn's chip contains 16 macros, {{in which there are}} 25 <b>analog</b> <b>computing</b> blocks, namely integrators, multipliers, fanouts, few nonlinear blocks. Ning's chip contains one macro block, in which there are 26 computing blocks including integrators, multipliers, fanouts, ADCs, SRAMs and DACs. Arbitrary nonlinear function generation is made possible by the ADC+SRAM+DAC chain, where the SRAM block stores the nonlinear function data. The experiments from the related publications revealed that VLSI analog/hybrid computers demonstrated about 1–2 orders magnitude of advantage in both solution time and energy while achieving accuracy within 5%, which points to the promise of using analog/hybrid computing techniques in the area of energy-efficient approximate computing.|$|E
25|$|Other {{uses for}} {{semiconductor}} diodes include the sensing of temperature, and <b>computing</b> <b>analog</b> logarithms (see Operational amplifier applications#Logarithmic output).|$|R
50|$|In 2002, Stanford Ovshinsky {{described}} an <b>analog</b> neural <b>computing</b> medium in which phase change material {{has the ability}} to cumulatively respond to multiple input signals. An electrical alteration of the resistance of the phase change material is used to control the weighting of the input signals.|$|R
40|$|The modern analog {{technique}} typically uses {{a distance}} metric {{to determine the}} dissimilarity between fossil and modern biological assemblages. Despite this quantitative approach, interpretation of distance metrics is usually qualitative and rules for selection of analogs tend to be ad hoc. We present a statistical tool, the receiver operating characteristic (ROC) curve, which provides a framework for identifying analogs from distance metrics. If modern assemblages are placed into groups (e. g., biomes), this method can (1) evaluate the ability of different distance metrics to distinguish among groups, (2) objectively identify thresholds of the distance metric for determining <b>analogs,</b> and (3) <b>compute</b> a likelihood ratio and a Bayesian probability that a modern group is an analog for an unknown (fossil) assemblage. Applied {{to a set of}} 1689 modern pollen assemblages from eastern North America classified into eight biomes, ROC analysis confirmed that the squared-chord distance (SCD) outperforms most other distance metrics. The optimal threshold increased when more dissimilar biomes were compared. The probability of an analog vs no-analog result (a likelihood ratio) increased sharply when SCD decreased below the optimal threshold, indicating a nonlinear relationship between SCD and the probability of analog. Probabilities of <b>analog</b> <b>computed</b> for a postglacial pollen record at Tannersville Bog (Pennsylvania, USA) identified transitions between biomes and periods of no analog...|$|R
25|$|An {{important}} {{advance in}} <b>analog</b> <b>computing</b> was {{the development of}} the first fire-control systems for long range ship gunlaying. When gunnery ranges increased dramatically in the late 19th century it was no longer a simple matter of calculating the proper aim point, given the flight times of the shells. Various spotters on board the ship would relay distance measures and observations to a central plotting station. There the fire direction teams fed in the location, speed and direction of the ship and its target, as well as various adjustments for Coriolis effect, weather effects on the air, and other adjustments; the computer would then output a firing solution, which would be fed to the turrets for laying. In 1912, British engineer Arthur Pollen developed the first electrically powered mechanical analogue computer (called at the time the Argo Clock). It was used by the Imperial Russian Navy in World War I. The alternative Dreyer Table fire control system was fitted to British capital ships by mid-1916.|$|E
500|$|Author Brett Alan Weiss {{wrote that}} Skeet Shoot was [...] "a shoddily programmed, {{graphically}} primitive game" [...] {{and said that}} the poor controls and difficulty levels rendered the game [...] "virtually worthless". A writer for Atari HQ called it a mediocre game. Lee Peppas of <b>ANALOG</b> <b>Computing</b> remarked that [...] "Atari & Activision have nothing to fear from the graphics on this first release." [...] TV Gamer opined {{it was one of the}} worst games for the system, saying that it was boring and criticizing the fact that it was difficult to hit the skeet.|$|E
2500|$|In the 1970s every {{big company}} and {{administration}} concerned with problems in dynamics {{had a big}} <b>analog</b> <b>computing</b> center, for example: ...|$|E
40|$|Our continuous-space {{model of}} {{computation}} {{was developed for}} the analysis of <b>analog</b> optical <b>computing</b> architectures and algorithms. We show a lower bound on the computational power of this model by Type- 2 machine simulation. We view each Type- 2 computation as a sequence of repeated instantiations of a single halting Turing machine. We also illustrate, by example, a problem solvable with our model that is not Type- 2 computable...|$|R
40|$|Adiabatic quantum <b>computing</b> is an <b>analog</b> quantum <b>computing</b> scheme {{with various}} {{applications}} in solving optimization problems. In the parity picture of quantum optimization, {{the problem is}} encoded in local fields that act on qubits which are connected via local 4 -body terms. We present an implementation of a parity annealer with Transmon qubits with a specifically tailored Ising interaction from Josephson ring modulators. Comment: 22 pages, 6 figure...|$|R
50|$|André Maréchal, an OSA Honorary Member and Fellow {{and former}} {{director}} general of the French Institut d’Optique. Maréchal received the OSA’s highest honor, in 1986, for his work in the areas of coherence, diffraction, geometric optics, image formation and image processing, and for his contributions to the international optics community. His pioneering work influenced the development of computer programs that optimized lens designs and advanced the automatic optimization of optical systems. He strongly contributed to the promotion of Fourier optics and <b>analog</b> optical <b>computing.</b>|$|R
2500|$|<b>Analog</b> <b>{{computing}}</b> {{devices are}} fast, digital computing devices are more versatile and accurate, {{so the idea}} is to combine the two processes for the best efficiency. An example of such hybrid elementary device is the hybrid multiplier where one input is an analog signal, the other input is a digital signal [...] and the output is analog. It acts as an analog potentiometer upgradable digitally. [...] This kind of hybrid technique is mainly used for fast dedicated real time computation when computing time is very critical as signal processing for radars and generally for controllers in embedded systems.|$|E
2500|$|Compute!'s Gazette in 1986 called Temple of Apshai Trilogy for the Commodore 64 [...] "a classic {{series of}} {{computer}} games made even better", stating that improved graphics and game play made it worthwhile {{even for those}} who had played them before. Amiga World criticized the Amiga version of Trilogys repetitiveness, stating that [...] "unless you are very easily amused you will probably lose interest fairly soon". Bill Kunkel, Arnie Katz and Joyce Worley for <b>Analog</b> <b>Computing,</b> on the other hand, listed Trilogy {{as one of the best}} Atari ST games of 1986, lauded the improved graphics and interface, while asserting that [...] "the actual content is timeless". In Dragon #114's [...] "The Role of Computers" [...] column in 1986, reviewers Hartley and Pattie Lesser also stated that the game was [...] "well-worth your interest." [...] Info gave the Amiga version four-plus stars out of five, stating that the trilogy [...] "has been admirably Amiga-tized". The magazine approved of the graphics, sound, and user interface and concluded that the game would be [...] "more likely to appeal to novices than Ultima". In 1991 and 1993 Computer Gaming Worlds Scorpia stated that the graphics [...] "caused a sensation when it first appeared", but also criticized a lack of polish in the programming and slow speed due to the use of BASIC, issues which were improved upon in the Atari 8-bit version.|$|E
5000|$|... #Article: Fast <b>Analog</b> <b>Computing</b> with Emergent Transient States ...|$|E
40|$|We {{present and}} {{demonstrate}} {{a method for}} blind separation and bearing estimation of broadband traveling waves, impinging on a sensor array with dimensions smaller than the shortest wavelength in the sources. By sensing spatial and temporal gradients of the received signal, the problem of separating mixtures of time-delayed sources reduces to that of separating instantaneous mixtures of the gradient components of the sources using conventional tools of independent component analysis. Experimental results demonstrate real-world separation of speech in outdoors and indoors environments, using a planar array of four microphones within a 5 mm radius and <b>analog</b> circuits <b>computing</b> spatial and temporal derivatives. 1...|$|R
40|$|I review {{some work}} on models of quantum computing, optical {{implementations}} of these models, {{as well as}} the associated computational power. In particular, we discuss the circuit model and cluster state implementations using quantum optics with various encodings such as dual rail encoding, Gottesman-Kitaev-Preskill encoding, and coherent state encoding. Then we discuss intermediate models of optical computing such as boson sampling and its variants. Finally, we review some recent work in optical implementations of adiabatic quantum <b>computing</b> and <b>analog</b> optical <b>computing.</b> We also provide {{a brief description of the}} relevant aspects from complexity theory needed to understand the results surveyed...|$|R
40|$|Abstract—Approximate {{computing}} is {{a promising}} design paradigm for better performance and power efficiency. In this paper, we propose a power efficient framework for <b>analog</b> approximate <b>computing</b> with the emerging metal-oxide resistive switching random-access memory (RRAM) devices. A programmable RRAM-based approximate computing unit (RRAM-ACU) is introduced first to accelerate approximated computation, and an approximate computing framework with scalability is then proposed {{on top of}} the RRAM-ACU. In order to program the RRAM-ACU efficiently, we also present a detailed configuration flow, which includes a customized approxima-tor training scheme, an approximator-parameter-to-RRAM-state mapping algorithm, and an RRAM state tuning scheme. Finally, the proposed RRAM-based computing framework is modeled at system level. A predictive compact model is developed to esti-mate the configuration overhead of RRAM-ACU and help explore the application scenarios of RRAM-based <b>analog</b> approximate <b>computing.</b> The simulation results on a set of diverse bench-marks demonstrate that, compared with a x 86 - 64 CPU at 2 GHz, the RRAM-ACU is able to achieve 4. 06 – 196. 41 × speedup and power efficiency of 24. 59 – 567. 98 GFLOPS/W with quality loss of 8. 72 % on average. And the implementation of hierarchical model and X application demonstrates that the proposed RRAM-based approximate computing framework can achieve> 12. 8 × power efficiency than its pure digital implementation counter-parts (CPU, graphics processing unit, and field- programmable gate arrays). Index Terms—Approximate computing, neural network, power efficiency, resistive random-access memory (RRAM). I...|$|R
5000|$|Incoming! (Atari 8-bit, 1986) by Conrad Tatge in <b>ANALOG</b> <b>Computing</b> magazine.|$|E
5000|$|... #Caption: [...] <b>Analog</b> <b>computing</b> {{machine at}} the Lewis Flight Propulsion Laboratory circa 1949.|$|E
50|$|<b>ANALOG</b> <b>Computing</b> (an {{acronym for}} Atari Newsletter And Lots Of Games) was an American {{computer}} magazine {{devoted to the}} Atari 8-bit home computer line, published from 1981 until 1989. ANALOG {{had a reputation for}} publishing fast and smooth machine language games, whereas most listings in the other Atari magazines of the time were written in Atari BASIC. Such games were accompanied by the assembly language source code. Originally the title as printed on the cover was A.N.A.L.O.G. 400/800 Magazine, but by the eighth issue it changed to <b>A.N.A.L.O.G.</b> <b>Computing.</b> Though the dots remained in the logo, it was simply referred to as ANALOG or <b>ANALOG</b> <b>Computing</b> inside the magazine.|$|E
30|$|Since {{the cells}} {{cooperate}} {{in order to}} solve a given computational task, CNNs have provided in recent years an ideal framework for programmable <b>analog</b> array <b>computing,</b> where the instructions are represented by the templates. This {{is in fact the}} basic idea underlying the CNN Universal Machine [1], where the architecture combines analog array operations with logic operations (therefore named as analogic computing). A global programming unit was included in the architecture, along with the integration of an array of sensors. Moreover, local memories were added to each computing cell [1]. The physical implementations of the CNN Universal Machine with integrated sensor array proved the physical feasibility of the architecture [11, 12].|$|R
40|$|International audienceThis paper {{presents}} an <b>analog</b> decoder <b>computing</b> cell less sensitive to {{bipolar junction transistor}} (BJT) parasitic elements. Unlike customary cells, the proposed cell does not invert the output probabilities ranking, hence limiting the wrong decoding outcome. This is achieved with a slight complexity increase as only two diodes {{are added to the}} basic computing cell. It is also shown that the proposed cell can improve the decoding performance even for large biasing current, opening the way to improve the decoding convergence of an analog BiCMOS decoder. Simulation results are shown for a 0. 25 -µm BiCMOS process from NXP with minimal size transistors...|$|R
5000|$|According to Sarah Bergbreiter in {{her paper}} [...] "Moving from Practice to Theory: Automatic Control after World War II," [...] fire {{control for the}} downing of enemy {{aircraft}} by anti-aircraft guns was the priority. The <b>analog</b> electro-mechanical <b>computing</b> machines plotted the differential firing data while servos created by H.L. Hazen adapted the data to the guns for precise firing control and accuracy. Other improvements of a similar type by Bell Labs increased firing stability so that output from the differential engines could be fully used to compensate for stochastic behaviors of enemy aircraft and large guns. A new age of intelligent warfare had begun.|$|R
50|$|<b>Analog</b> <b>Computing</b> in the Soviet Union, by D. Abramovitch, IEEE Control Systems Magazine, pp. 52-62, June 2005.|$|E
50|$|In {{its early}} years, <b>ANALOG</b> <b>Computing</b> also sold {{commercial}} games via mail order {{under the name}} ANALOG Software.|$|E
50|$|VG&CE {{began as}} a spinoff of <b>ANALOG</b> <b>Computing,</b> a {{magazine}} published by LFP devoted to Atari 8-bit computers.|$|E
25|$|In 2009, {{a simple}} {{electronic}} circuit consisting of an LC network and a memristor {{was used to}} model experiments on adaptive behavior of unicellular organisms. It was shown that subjected to a train of periodic pulses, the circuit learns and anticipates the next pulse similar to the behavior of slime molds Physarum polycephalum where the viscosity of channels in the cytoplasm responds to periodic environment changes. Applications of such circuits may include, e.g., pattern recognition. The DARPA SyNAPSE project funded HP Labs, {{in collaboration with the}} Boston University Neuromorphics Lab, has been developing neuromorphic architectures which may be based on memristive systems. In 2010, Versace and Chandler described the MoNETA (Modular Neural Exploring Traveling Agent) model. MoNETA is the first large-scale neural network model to implement whole-brain circuits to power a virtual and robotic agent using memristive hardware. Application of the memristor crossbar structure in the construction of an <b>analog</b> soft <b>computing</b> system was demonstrated by Merrikh-Bayat and Shouraki. In 2011 they showed how memristor crossbars can be combined with fuzzy logic to create an <b>analog</b> memristive neuro-fuzzy <b>computing</b> system with fuzzy input and output terminals. Learning is based on the creation of fuzzy relations inspired from Hebbian learning rule.|$|R
40|$|Abstract- Indeed, the {{development}} of mixed signal (Analog+digital) based System-on-Chip (SoC) for dedicated application is an ubiquitous field. Moreover, {{in the field of}} VLSI design the Smart Fusion technology is emerged, which introduces the configurable analog cores along with customizable digital cores. Employing SmartFusion device from Microsemi USA, the A 2 F 200 M 3 F, the mixed signal based System-on-Chip is designed for monitoring of environmental parameters of polyhouse, where crops are cultivated in precisely controlled environment. Deploying dynamically reconfigurable resources of A 2 F 200 M 3 F, such as <b>Analog</b> <b>Compute</b> Engine (ACE), Signal Conditioning Block (SCB) etc, the Signal Conditioning stages for respective signals are designed. The analog front end (AFE), of the device provides ultra high input impedance, which helps to read the analog signals, very precisely. Moreover, on deployment of on-chip ADC and configuration of the same to 10 bit realizes the enhancement in the resolution. The device comprises ARM CortexM 3 as a processing core, which ensure the 32 bit processing capacity. This results into increase in the processing speed with low power consumption. An IDE Libero SoC is used for design and customizing of hardware of System-on-Chip, whereas the firmware is co-designed by employing SoftConsole vendored by microsemi. To measure environmental parameters of polyhouse, the sensors such as SY-HS- 220 (Humidity), LM 35 (Temperature) and BPW 34 (Light intensity) are deployed. The system is calibrated and standardized to respective engineering unit. The results of implementation exhibit the high preciseness and reliability of the system. Keyword- SmartFusion, System-on-Chip, Mixed signal based VLSI design, reconfigurability, agricultural parameters. ...|$|R
40|$|In {{this work}} we {{introduce}} a new method for computing Form Factors in Radiosity. We demostrate how our method improves on existing projective techniques such as the hemicube. We use the Nusselt <b>analog</b> to directly <b>compute</b> form factors by projecting the scene onto the unit circle. We compare our method with other form factor computation methods. The results show an improvement in the quality/speed ratio using our technique...|$|R
