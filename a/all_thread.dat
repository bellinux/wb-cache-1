22|678|Public
5000|$|We {{were able}} to draw from the books and films to create a story that ties into the story that people know while still being really new. So {{we have a lot}} of new {{characters}} and locations, but they <b>all</b> <b>thread</b> into the War of the Ring, and all the Lord of the Rings stuff that people know. You're meeting characters that you're familiar with as well as brand new characters and some characters from the books that you might know of that weren't in the films, so we really get the best of all possible worlds. We're in Middle-earth, which is the best fantasy world, drawing from all the sources and creating something really new that players are going to be excited about.|$|E
30|$|The first scheme (see Fig.  2 a) makes <b>all</b> <b>thread</b> blocks two-dimensional. In each block, all threads are indexed {{along one}} dimension. Section 4.1 details how {{the number of}} thread in one block may affect the performance. For fFFT, a thread block b(x, y) is {{responsible}} for processing the xth segment’s data of the yth channel with x∈[0, d) and y∈[0, m). For iFFT, <b>all</b> <b>thread</b> blocks are also two-dimensional, but a thread block should be referenced as b(x, y×z) {{to deal with the}} xth segment’s data of the yth channel under a scale factor z∈ [0, s) (see 2 (b)).|$|E
40|$|For {{software}} executing several threads in parallel, {{testing is}} unreliable, as it cannot cover <b>all</b> <b>thread</b> schedules. Model checking, however, can cover all possible thread interleavings. Software model checkers can directly verify an implementation, but typically cannot handle network input/output operations, which most programs require. This shortcoming {{can be addressed}} by a special model checker designed for multiple processes, or by different kinds of extensions and preprocessors for existing model checkers. This paper surveys currently existing approaches and tools...|$|E
5000|$|Another problem {{comes from}} {{releasing}} a lock. <b>All</b> <b>threads</b> are spinning on one variable, {{so when the}} lock is released there are Ө(p) invalidations (as well as Ө(p) acquisitions). This is because <b>all</b> <b>threads</b> must reload their block into the cache and perform a test to determine their admittance to the critical section.|$|R
5000|$|... reduction: a safe way {{of joining}} work from <b>all</b> <b>threads</b> after construct.|$|R
50|$|<b>All</b> <b>threaded</b> or {{press-fit}} jewelry {{must have}} internal tapping (no screw threads on posts).|$|R
40|$|Abstract. Sequentialization {{has been}} shown to be an {{effective}} symbolic verification technique for concurrent C programs using POSIX threads. Lazy-CSeq, a tool that applies a lazy sequentialization scheme, has won the Concurrency division of the last two editions of the Competition on Software Verification. The tool encodes <b>all</b> <b>thread</b> schedules up to a given bound into a single non-deterministic sequential C program and then invokes a C model checker. This paper presents a novel optimized imple-mentation of lazy sequentialization, which integrates symbolic pruning of redundant schedules into the encoding. Experimental evaluation shows that our tool outperforms Lazy-CSeq significantly on many benchmarks...|$|E
40|$|Cache sharing on a {{multicore}} processor is usually competitive. In multi-threaded code, however, different threads may access {{the same data}} and have a cooperative effect in cache. This retport describes a new metric called shared footprint and a new locality theory to measure and analyze parallel data sharing in cache. Shared footprint is machine indepen-dent, i. e. data sharing in all cache sizes, not just one cache size and compositional, i. e. data sharing in <b>all</b> <b>thread</b> sets, not just one set. The report gives a single-pass, parallel algorithm for measurement and evaluates the new metric using 14 PARSEC and SPEC OMP benchmarks, including a use in improving the performance of multi-threaded code...|$|E
40|$|AbstractMultithreaded {{software}} {{systems are}} prone to errors due {{to the difficulty of}} reasoning about multiple interleaved threads operating on shared data. Static checkers that analyze a program's behavior over all execution paths and <b>all</b> <b>thread</b> interleavings are a powerful approach to identifying bugs in such systems. In this paper, we present Calvin, a scalable and expressive static checker for multithreaded programs based on automatic theorem proving. To handle realistic programs, Calvin performs modular checking of each procedure called by a thread using specifications of other procedures and other threads. Our experience applying Calvin to several real-world programs indicates that Calvin has a moderate annotation overhead and can catch common defects in multithreaded programs, such as synchronization errors and violations of data invariants...|$|E
5000|$|Global memory:Accessible by <b>all</b> <b>threads</b> {{as well as}} host (CPU). High latency (400-800 cycles) ...|$|R
5000|$|... 3) <b>All</b> <b>threads</b> {{should have}} a clear {{statement}} on its initiative and its benefits.|$|R
30|$|Once {{the matrix}} μ ^k+ 1 is updated for <b>all</b> <b>threads,</b> pSM {{goes to the}} next iteration, k=k+ 1.|$|R
40|$|A {{large body}} of data-flow {{analyses}} exists for analyzing and optimizing sequential code. Unfortunately, much of it cannot be directly applied on parallel code, for reasons of correctness. This paper presents a technique to automatically, aggressively, yet safely apply sequentially-sound data-flow transformations, without change, on shared-memory programs. The technique is founded {{on the notion of}} program references being “siloed ” on certain control-flow paths. Intuitively, siloed references are free of interference from other threads within the confines of such paths. Data-flow transformations can, in general, be unblocked on siloed references. The solution has been implemented in a widely used compiler. Results on benchmarks from SPLASH- 2 show that performance improvements of up to 41 % are possible, with an average improvement of 6 % across all the tested programs over <b>all</b> <b>thread</b> counts...|$|E
40|$|This paper {{explores the}} {{practicality}} of conducting program analysis for multithreaded software using constraint solving. By precisely defining the underlying memory consistency rules {{in addition to}} the intra-thread program semantics, our approach o#ers a unique advantage for program verification [...] - it provides an accurate and exhaustive coverage of <b>all</b> <b>thread</b> interleavings for any given memory model. We demonstrate how this can be achieved by formalizing sequential consistency for a source language that supports control branches and a monitor-style mutual exclusion mechanism. We then discuss how to formulate programmer expectations as constraints and propose three concrete applications of this approach: execution validation, race detection, and atomicity analysis. Finally, we describe the implementation of a formal analysis tool using constraint logic programming, with promising initial results for reasoning about small but non-trivial concurrent programs...|$|E
40|$|Abstract. Designing multithreaded {{software}} {{systems is}} prone to errors due {{to the difficulty of}} reasoning about multiple interleaved threads of control operating on shared data. Static checking, with the potential to analyze the program's behavior over all execution paths and for <b>all</b> <b>thread</b> interleavings, is a powerful debugging tool. We have built a scalable and expressive static checker called Calvin for multithreaded programs. To handle realistic programs, Calvin performs modular checking of each procedure called by a thread using specifications of other procedures and other threads. The checker leverages off existing sequential program verification techniques based on automatic theorem proving. To evaluate the checker, we have applied it to several real-world programs. Our experience indicates that Calvin has a moderate annotation overhead and can catch defects in multithreaded programs, including synchronization errors and violation of data invariants...|$|E
5000|$|... '''''' - If a {{field is}} {{declared}} , {{it is ensured that}} <b>all</b> <b>threads</b> see a consistent {{value for the}} variable.|$|R
5000|$|... int threadLocal; // This is a thread-local {{variable}}.shared int global; // This is {{a global}} variable shared with <b>all</b> <b>threads.</b>|$|R
30|$|There {{is no need}} {{to argue}} about the {{correctness}} of Algorithm (2). Note that b is fixed for <b>all</b> <b>threads.</b> Thus, this value is computed by a single thread and stored in the shared memory in order to be accessible for <b>all</b> <b>threads.</b> Moreover, this value is computed in the previous step, just before checking the stopping criteria. z̅_LR represents an upper bound of the solution value of S 2 FVPP, see Problem (1).|$|R
40|$|Title: GIMPLE Model Checker Author: Ondrej Krč-Jediný Department: Department of Distributed and Dependable Systems Supervisor: RNDr. Ondřej Šerý Ph. D. Supervisor's e-mail address: Ondrej. Sery@mff. cuni. cz The goal of {{the thesis}} is a {{prototype}} implementation of explicit-state model checker of C - an advanced tool for finding errors in programs. This tool ex- plores all possible paths of program execution as well as <b>all</b> <b>thread</b> interleavings. It is based on GIMPLE - output of front-end of GCC compiler, which is the input language for GMC. The thesis {{is based on the}} previous work 'Memory represen- tation for GIMPLE Model Checker', that implements work with memory for this tool. Since it is based on GIMPLE, it makes it possible to verify systems directly in C. In addition, it is easily extensible to other languages supported by GCC. Keywords: model checking, GIMPLE, GCC, C...|$|E
40|$|Multithreaded {{programs}} are notoriously prone to unintended interference between concurrent threads. To address this problem, {{we argue that}} yield annotations in the source code should document <b>all</b> <b>thread</b> interference, and we present a type system for verifying the absence of undocumented interference in Java programs. Under this type system, welltyped programs behave as if context switches occur only at yield annotations. Thus, well-typed programs can be understood using intuitive sequential reasoning, except where yield annotations remind the programmer to account for thread interference. Experimental results show that yield annotations describe thread interference more precisely than prior techniques based on method-level atomicity specifications. In particular, yield annotations {{reduce the number of}} interference points one must reason about by an order of magnitude. The type system is also more precise than prior methods targeting race freedom, and yield annotations highlight all known concurrency defects in our benchmarks...|$|E
40|$|We {{present a}} “memory-model-sensitive” {{approach}} to validating correctness properties for multithreaded programs. Our key insight {{is that by}} specifying both the inter-thread memory consistency model and the intra-thread program semantics as constraints, a program verification task {{can be reduced to}} an equivalent constraint solving problem, thus allowing an exhaustive examination of <b>all</b> <b>thread</b> interleavings precisely allowed by a given memory model. To demonstrate, this paper formalizes race conditions according to the new Java memory model, for a simplified but non-trivial source language. We then describe the implementation of a memory-model-sensitive race detector using constraint logic programming (CLP). In comparison with conventional program analysis, our approach does not offer the same kind of performance and scalability due to the complexity involved in exact formal reasoning. However, we show that a formal semantics can serve more than documentation purposes — it can be applied as a sound basis for rigorous property checking, upon which more scalable methods can be derived...|$|E
40|$|Multi-threaded {{programs}} employ {{barriers to}} temporally synchronize across <b>threads.</b> <b>All</b> <b>threads</b> must reach the barrier before any thread may advance past the barrier. A barrier {{is a form}} of global synchronization; the efficiency with which the barrier is processed extends the program’s critical path. Large delays between the time the last thread reaches a barrier and when <b>all</b> <b>threads</b> receive notification that the barrier has been released can add significantly to program execution time. In this paper, we show how nanophotonic devices can be configured to provide low latency, low power hardware barriers. The mechanism uses the presence of light in a waveguide to indicate that <b>all</b> <b>threads</b> have arrived at the barrier. DWDM (dense wave division multiplexing) allows multiple barriers to be processed in parallel with only a single physical waveguide. ...|$|R
30|$|In the Operating Systems realm, {{the running}} {{time of a}} process is {{distinguished}} to real, user and sys, where the first denotes the actual clock time, the second equals the total time spent at user space for <b>all</b> <b>threads</b> and the last equals the time spent at kernel for <b>all</b> <b>threads.</b> So far, we have used the real time; in this experiment we prefer to demonstrate the user {{time in order to}} better isolate the snapshot behavior.|$|R
5000|$|In this example, <b>all</b> <b>threads</b> {{execute the}} same [...] "main" [...] function, Thread.In real applications, {{different}} threads often have different [...] "main" [...] functions.|$|R
40|$|Pipelining is {{commonly}} used in multi-threaded code. In pipeline programs, the computation is divided into stages that perform different types of computations. Unlike in a data parallel program, threads in a pipeline program have different behavior. Because of the asymmetry, the performance varies significantly depending on how threads are grouped {{to use the same}} shared cache. It is time consuming to find the best grouping through exhaustively testing. As the number of threads increases, testing is not scalable. This short paper presents model-assisted search. It profiles a program to find all-thread data sharing in training executions and predicts the cache performance for <b>all</b> <b>thread</b> groupings. From the prediction, inferior groupings are removed from consideration, leaving a smaller set of choices for test. The pruning uses a concept called the miss-count poset (partially ordered set). For an 8 -thread pipeline program running on a hyper-threaded quad-core processor, we show that the best grouping is 70 % faster than the worst and the proposed technique reduced the cost of testing by 64 %. 1...|$|E
40|$|The {{increasing}} {{level of}} automation in critical infrastructures requires development of effective ways for finding faults in safety critical software components. Synchronization in concurrent components is especially prone to errors and, due to difficulty of exploring <b>all</b> <b>thread</b> interleavings, {{it is difficult to}} find synchronization faults. In this paper we present an experimental study demonstrating the effectiveness of model checking techniques in finding synchronization faults in safety critical software when they are combined with a design for verification approach. We based our experiments on an automated air traffic control software component called the Tactical Separation Assisted Flight Environment (TSAFE). We first reengineered TSAFE using the concurrency controller design pattern. The concurrency controller design pattern enables a modular verification strategy by decoupling the behaviors of the concurrency controllers from the behaviors of the threads that use them using interfaces specified as finite state machines. The behavior of a concurrency controller is verified with respect to arbitrary numbers of threads using the infinite state model checking techniques implemented in the Action Language Verifier (ALV). The threads which use the controller classes are checked for interface violations using the finite state model checking technique...|$|E
40|$|Concurrent code is {{becoming}} increasingly important {{with the advent of}} multi-cores, but testing concurrent code is challenging. Researchers are developing new testing tech-niques and test suites for concurrent code, but evaluating these techniques and test suites often uses a small number of real or manually seeded bugs. Mutation testing allows creating a large number of buggy programs to evaluate test suites. However, performing mu-tation testing is expensive even for sequential code, and the cost is higher for concurrent code where each test has to be executed for many (possibly <b>all)</b> <b>thread</b> schedules. The most widely used technique to speed up mutation testing is selective mutation, which reduces the number of mutants by applying only a subset of mutation operators such that test suites that kill all mutants generated by this subset also kill (almost) all mutants generated by all mutation operators. To date, selective mutation has been used only for sequen-tial mutation operators. This paper explores selective mutation for concurrent mu-tation operators. Our results identify several sets of con-current mutation operators that can effectively reduce the number of mutants, show that operator-based selection is slightly better than random mutant selection, and show that sequential and concurrent mutation operators are indepen-dent, demonstrating the importance of studying concurrent mutation operators...|$|E
5000|$|... 8, 32 or 256 {{priority}} scheduling multi-thread scheduling; Using the round-robin policy {{ensures that}} <b>all</b> <b>threads</b> {{having the same}} priority level will be scheduled equally; ...|$|R
50|$|A Combining Tree Barrier is a {{hierarchical}} way of implementing barrier {{to resolve the}} scalibility by avoiding the case that <b>all</b> <b>threads</b> spinning on a same location.|$|R
5000|$|Storage is not {{necessarily}} a problem as <b>all</b> <b>threads</b> spin on one variable, unlike array-based queueing locks (ABQL) who have threads spin on individual elements of an array.|$|R
40|$|With advancements {{in process}} technologies, {{manufacturers}} {{are able to}} pack many processor cores on a single chip. Consequently, there is a paradigm shift from single processor to single chip multiprocessors (CMP). As mobile industry is moving towards CMPs, the challenge of working in a low power/energy budget while still delivering good performance, has taken the precedence. Therefore, energy and power optimization has become a primary design constraint along with performance in CMP design space. CMPs get performance benefit from running multithreaded programs which utilizes Thread Level Parallelism (TLP). But these parallel programs have inherent load imbalance between threads due to synchronization which degrades performance as well as energy consumption. The solution is to develop energy efficient algorithms which can detect and reduce this imbalance to maximize performance while still giving energy savings. Dynamic thread criticality prediction is an approach to detect the load imbalance by identifying the critical threads which cause performance/energy degradation due to synchronization. Cores running critical threads can then be run on high power states using Dynamic Voltage Frequency Scaling, thus balancing the execution times of <b>all</b> <b>thread.</b> But {{in order to create}} an accurate balance and utilize DVFS efficiently, one also needs to know the impact of voltage/frequency scaling on thread's performance gain and power usage. Thread frequency scalability prediction can give a good estimate of the performance improvements that DVFS can provide to each thread. We present an active load balancing algorithm which uses thread criticality and frequency scalability prediction to get the maximum possible performance benefit in an energy efficient manner. Results show that balancing the load in an accurate way can give energy savings as high as 10 % with minimal performance loss as compared to running all cores at high frequency...|$|E
40|$|Hyperthreaded (HT) and {{simultaneous}} multithreaded (SMT) processors are {{now available}} in commodity workstations and servers. This technology is designed to increase throughput by executing multiple concurrent threads on a single physical processor. These multiple threads share the processor’s functional units and on-chip memory hierarchy {{in an attempt to}} make better use of idle resources. Most OpenMP applications and runtime libraries have been written assuming an Symmetric Multiprocessor (SMP), not an SMT, model. Threads executing on the same physical SMT processor have interactions on data locality and resource sharing that do not occur on traditional SMPs. This work focuses on tuning the behavior of an OpenMP runtime library to improve the performance of applications executing on SMPs with SMT processors. First we implement and evaluate three techniques that have been asserted as important on HT processors: the use of pause instructions in spin loops, incorporation of per-thread stack offsets in slave threads, and lock padding. After implementing these techniques in the Omni OpenMP runtime library, we discover that both pause instructiosn and lock padding show noticible improvements, while stack offsets show negligible gains. We then propose three adaptive loop schedulers: a region-based scheduler, a loop-based scheduler and hardware counter based scheduler. These novel schedulers determine effective hierarchical schedules for individual parallel regions or loops to exploit the unique nature of SMPs with HT processors. We compare the performance of our three proposed schedulers against several standard schedulers using the SPEC and NAS OpenMP benchmark suites. We show that schedule selection must be done at the granularity of loops not regions, and that our loop-based adaptive schedulers outperform all other approaches on average, increasing speedup on average by over 25 % when <b>all</b> <b>thread</b> contexts are used. I...|$|E
40|$|Roller screws (RS) {{featuring}} {{very high}} operational parameters {{are the most}} promising transformers of rotational motion into translational motion. The original gear design {{with a number of}} peculiarities and precision accuracy in manufacturing its essential details, first of <b>all,</b> <b>thread</b> ones allow us to have high operating parameters of RS. Errors of manufacturing special thread of such details greatly affect the load carrying capacity, precision, reliability, and endurance of RS. That is why the challenge is highly accurate metrological control of errors, which have the greatest influence on specified parameters, and processing of measurement results. Major errors include deviations of real pitch of thread from nominal ones and deviations of real thread profiles from nominal ones. The aim {{of this paper is to}} determine abovementioned errors, which were measured by high-precision computerized devices, namely: MITUTOYO CV- 2000 contour measurement instrument; Form Talysurf PGI 420 contour measurement instrument. Both have a measurement range of 100 mm and resolution of 0. 2 μm. As far as a rental cost of the contour measurement instrument was rather high and a software of this device did not allow us to obtain all required information on the thread profile errors of interest, a thread profile was measured using a contour measuring device on the sampling length. Measurement results were copied to the USB flash drive, and then conversion of obtained results and calculation of all errors of interest were carried out on ECM by means of specially designed software. For example, when using a contour measurement instrument MITUTOYO CV- 2000, to make measurement of RS screw on the sampling length of 100 mm along one path, the longitudinal and transverse coordinates of 57411 points of thread profile were obtained. Specially developed mathematical support was used as the basis for software. Programs written in Delphi language have been sent to the Federal Institute for Industrial Property of the RF for registration. Calculation results represent information on the left and right side of each turn of measured detail and final parameters for all measured turns. Developed software may be applied to process results of control of RS thread details as well as high-precision screws and nuts with metrical, inch and trapezium thread...|$|E
50|$|The {{book is a}} {{philosophical}} thriller/comedy/murder-mystery/ghost story set first in London and then in Wales. A mystical element is diffused through an increasingly complex plot, as <b>all</b> <b>threads</b> converge in the final chapters.|$|R
5000|$|One {{disadvantage}} is {{that there}} is a higher uncontended latency due to the extra instructions required to read and test the value that <b>all</b> <b>threads</b> are spinning on before a lock is released.|$|R
5000|$|Finally a Barrier can be used; {{a barrier}} is entered using a single instruction, and when <b>all</b> <b>threads</b> {{that want to}} {{synchronise}} have reached the barrier they are all released within a single thread-cycle.|$|R
