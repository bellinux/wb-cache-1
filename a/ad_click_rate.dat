1|286|Public
40|$|The contextual {{recommender}} task is {{the problem}} of making useful offers, e. g., placing ads or related links on a web page, based on the context information, e. g., contents of the page and information about the user visiting, and information on the available alternatives, i. e., the advertisements or relevant links. In the case of ads for example, the goal is to select ads that result in high click rates, where the (<b>ad)</b> <b>click</b> <b>rate</b> is some unknown function of the attributes of the context and ad. We describe the task and make connections to related problems including recommender and multi-armed bandit problems...|$|E
40|$|Suppose {{we have a}} large {{dictionary}} of strings. Each entry {{starts with}} a figure of merit (popularity). We wish to find the kbest matches for a substring, s, in a dictinoary, dict. That is, grep s dict | sort –n | head –k, but {{we would like to}} do this in sublinear time. Example applications: (1) web queries with popularities, (2) products with prices and (3) <b>ads</b> with <b>click</b> through <b>rates.</b> This paper proposes a novel index, k-best suffix arrays, based on ideas borrowed from suffix arrays and kdtrees. A standard suffix array sorts the suffixes by a single order (lexicographic...|$|R
40|$|Online {{advertising}} is a huge, rapidly growing advertising market in today's world. One {{common form of}} online {{advertising is}} using image ads. A decision is made (often in real time) every time a user sees an ad, and the advertiser is eager {{to determine the best}} ad to display. Consequently, many algorithms have been developed that calculate the optimal ad to show to the current user at the present time. Typically, these algorithms focus on variations of the ad, optimizing among different properties such as background color, image size, or set of images. However, there is a more fundamental layer. Our study looks at new qualities of ads that can be determined before an ad is shown (rather than online optimization) and defines which ads {{are most likely to be}} successful. We present a set of novel algorithms that utilize deep-learning image processing, machine learning, and graph theory to investigate online advertising and to construct prediction models which can foresee an image ad's success. We evaluated our algorithms on a dataset with over 260, 000 ad images, as well as a smaller dataset specifically related to the automotive industry, and we succeeded in constructing regression models for <b>ad</b> image <b>click</b> <b>rate</b> prediction. The obtained results emphasize the great potential of using deep-learning algorithms to effectively and efficiently analyze image ads and to create better and more innovative online ads. Moreover, the algorithms presented in this paper can help predict ad success and can be applied to analyze other large-scale image corpora...|$|R
50|$|Search engines use {{algorithms}} {{to determine}} the position of <b>ads</b> according to <b>click</b> through <b>rates.</b> <b>Ads</b> with poor <b>click</b> through <b>rates</b> can be pushed {{down to the bottom}} of the first page of search results or onto subsequent pages. Even though advertisers are only paying for click throughs, the algorithms assigning ad positions based on ad popularity provide incentives for optimizing keyword selection and other cost control measures. Without cost control measures, it is possible for ad buyers to spend twenty five to fifty percent of their ad budget ineffectively.|$|R
50|$|Google Analytics allows website {{owners to}} track {{where and how}} people use their website, for example by {{examining}} <b>click</b> <b>rates</b> for all the links on a page. Google advertisements can be placed on third-party websites in a two-part program. Google's AdWords allows advertisers to display their advertisements in the Google content network, through a cost-per-click scheme. The sister service, Google AdSense, allows website owners to display these advertisements on their website and earn money every time <b>ads</b> are <b>clicked.</b>|$|R
40|$|Computational Advertising is the {{currently}} emerging multidimensional statistical modeling sub-discipline in digital advertising industry. Web pages visited per user {{every day is}} considerably increasing, resulting in an enormous access to display advertisements (ads). The {{rate at which the}} <b>ad</b> is <b>clicked</b> by users is termed as the <b>Click</b> Through <b>Rate</b> (CTR) of an advertisement. This metric facilitates the measurement of the effectiveness of an advertisement. The placement of ads in appropriate location leads to the rise in the CTR value that influences the growth of customer access to advertisement resulting in increased profit rate for the ad exchange, publishers and advertisers. Thus it is imperative to predict the CTR metric in order to formulate an efficient ad placement strategy. This paper proposes a predictive model that generates the <b>click</b> through <b>rate</b> based on different dimensions of ad placement for display advertisements using statistical machine learning regression techniques such as multivariate linear regression (LR), poisson regression (PR) and support vector regression(SVR). The experiment result reports that SVR based click model outperforms in predicting CTR through hyperparameter optimization. Keywords <b>ad</b> campaign metrics, <b>click</b> through <b>rate,</b> displa...|$|R
5000|$|... 22. Impressions {{that are}} not visible are {{included}} in <b>click</b> through <b>rate,</b> making <b>click</b> <b>rate</b> misleading.|$|R
40|$|We {{study the}} impact of social {{influence}} {{on the performance of}} ads on social networks. Using data for several ads on Facebook for two different firms, we measure {{the impact of}} past connections on the <b>click</b> <b>rate</b> and endorsement rate of ads. We find that increase in the connections does not lead to an increase in the click performance and may even decrease the click performance. We also find that increase in connections can increase the endorsement rate of ads provided that <b>ads</b> have been <b>clicked.</b> However, when the number of connections is very large the connection performance may also reduce. Our results inform advertisers on how the social influence impacts the performance of their ads and how should they advertise on social platforms such as Facebook. Our results also provide insight into consumer behavior in social networks. Specifically we show that consumers {{are less likely to be}} influenced by social connections to <b>click</b> <b>ads.</b> However, if they do <b>click</b> <b>ads</b> they are more likely to endorse ads if more of their connections do...|$|R
40|$|This study {{concerns}} {{the use of}} a multiple stimulus discrimination procedure for producing data on the generalization of conditioned suppression. Four rats were maintained on a variable interval schedule of milk reinforcement in the presence of five stimuli varying in auditory <b>click</b> <b>rate.</b> When response rates were stable, electric shock was regularly paired with the termination of one of the click stimuli. For two rats the shock was paired with the slowest <b>click</b> <b>rate,</b> and for two rats shock was paired with the fastest <b>click</b> <b>rate.</b> The VI schedule remained in effect. Plots of the relative rates of response to each of the five stimuli yielded concave gradients for both animals suppressed at the slowest <b>click</b> <b>rate,</b> and flat gradients with a sharp drop at the warning stimulus for both animals suppressed at the fastest <b>click</b> <b>rate.</b> When the warning stimuli were reversed for both pairs of subjects, both gradient forms were reproduced. The present procedure was contrasted with procedures used by other investigators...|$|R
30|$|User metrics {{including}} page views, <b>click</b> <b>rates</b> etc.|$|R
40|$|Treballs Finals de Grau d'Enginyeria Informàtica, Facultat de Matemàtiques, Universitat de Barcelona, Any: 2017, Director: Jordi Vitrià i MarcaThis {{project is}} based on a {{challenge}} provided by the website called Kaggle, which involves the creation of an automatic learning system that makes possible a prediction of clicks on online advertising. Assuming this challenge, a program that is able to predict <b>ad</b> <b>clicks</b> has been created, but by using new technologies like Docker, which makes possible a virtualization of a customized Linux environment ideal for programming Tensorflow, a library that enables an automatic, fast and flexible learning. The program’s main algorithm makes an automatic learning using a linear regression model that feeds from the database provided by Kaggle, which is destined for this challenge. This database is composed of a 10 day history of <b>ad</b> <b>clicks</b> and no clicks...|$|R
40|$|The {{capacity}} of auditory cortex on Heschl's gyrus (HG) to encode repetitive transients was studied in human patients undergoing surgical evaluation for medically intractable epilepsy. Multicontact depth electrodes were chronically implanted in gray matter of HG. Bilaterally presented stimuli were click trains varying in rate from 4 to 200 Hz. Averaged evoked potentials (AEPs) and event-related band power (ERBP), computed from responses {{at each of}} 14 recording sites, identified two auditory fields. A core field, which occupies posteromedial HG, was characterized by a robust polyphasic AEP on which could be superimposed a frequency following response (FFR). The FFR was prominent at <b>click</b> <b>rates</b> below ∼ 50 Hz, decreased rapidly as <b>click</b> <b>rate</b> was increased, but could reliably be detected at <b>click</b> <b>rates</b> as high as 200 Hz. These data are strikingly similar to those obtained by others in the monkey under essentially the same stimulus conditions, indicating that mechanisms underlying temporal processing in the auditory core may be highly conserved across primate species. ERBP, which reflects increases or decreases of both phase-locked and non–phase-locked power within given frequency bands, showed stimulus-related increases in gamma band frequencies as high as 250 Hz. The AEPs recorded in a belt field anterolateral to the core were typically of low amplitude, showing little or no evidence of short-latency waves or an FFR, even at the lowest <b>click</b> <b>rates</b> used. The non–phase-locked component of the response extracted from the ERBP showed a robust, long-latency response occurring here {{in response to the}} highest <b>click</b> <b>rates</b> in the series...|$|R
40|$|We {{consider}} {{the problem of}} estimating occurrence rates of rare events for extremely sparse data, using pre-existing hierarchies to perform inference at multiple resolutions. In particular, {{we focus on the}} problem of estimating <b>click</b> <b>rates</b> for (webpage, advertisement) pairs (called impressions) where both the pages and the ads are classified into hierarchies that capture broad contextual information at different levels of granularity. Typically the <b>click</b> <b>rates</b> are low and the coverage of the hierarchies is sparse. To overcome these difficulties we devise a sampling method whereby we analyze a specially chosen sample of pages in the training set, and then estimate <b>click</b> <b>rates</b> using a two-stage model. The first stage imputes the number of (webpage, ad) pairs at all resolutions of the hierarchy to adjust for the sampling bias. The second stage estimates <b>click</b> <b>rates</b> at all resolutions after incorporating correlations among sibling nodes through a tree-structured Markov model. Both models are scalable and suited to large scale data mining applications. On a real-world dataset consisting of 1 / 2 billion impressions, we demonstrate that even with 95 % negative (non-clicked) events in the training set, our method can effectively discriminate extremely rare events in terms of their click propensity...|$|R
50|$|Prioritizing clicks {{refers to}} display <b>click</b> <b>ads,</b> {{although}} advantageous by being ‘simple, fast and inexpensive’ rates for display ads in 2016 is only 0.10 {{percent in the}} United States. This means one in a thousand <b>click</b> <b>ads</b> are relevant therefore having little effect. This displays that marketing companies should not just use <b>click</b> <b>ads</b> {{to evaluate the effectiveness}} of display advertisements (Whiteside, 2016).|$|R
40|$|A {{key feature}} of online markets for {{advertising}} (e. g., sponsored links) is that <b>clicking</b> <b>rates</b> {{depend on the}} searchers' expectations that the platform selects relevant advertisers. This article studies auction design by a platform that maximizes profits in the long run, where <b>clicking</b> <b>rates</b> are mechanism dependent. In line with {{the practice of the}} major search engines, the revenue-maximizing mechanism is a scoring auction that combines the willingness to pay and the relevance to searchers of advertisers. By trading off rent extraction and clicking volume, this mechanism works as a cross-subsidization device between searchers and advertisers...|$|R
30|$|Rates Criterion is {{the score}} based on users’ click {{behaviour}} and votes. Higher <b>click</b> <b>rates</b> or positive votes mean that an item {{has a high}} score. It also refers to an item’s popularity.|$|R
50|$|A trick banner is {{a banner}} ad where the ad copy imitates some screen element users {{commonly}} encounter, {{such as an}} operating system message or popular application message, to induce <b>ad</b> <b>clicks.</b> Trick banners typically do not mention the advertiser in the initial ad, and thus they are a form of bait-and-switch. Trick banners commonly attract a higher-than-average click-through rate, but tricked users may resent the advertiser for deceiving them.|$|R
5000|$|Google claims their users click (organic) {{search results}} {{more often than}} ads, {{essentially}} rebutting the research cited above. A 2012 Google study found that 81% of ad impressions and 66% of <b>ad</b> <b>clicks</b> happen {{when there is no}} associated organic search result on the first page. Research has shown that searchers may have a bias against ads, unless the ads are relevant to the searcher's need or intent ...|$|R
40|$|Click {{prediction}} {{is one of}} the fundamental problems in sponsored search. Most of existing studies took ad-vantage of machine learning approaches to predict <b>ad</b> <b>click</b> for each event of ad view independently. However, as observed in the real-world sponsored search system, user’s behaviors on ads yield high dependency on how the user behaved along with the past time, especially in terms of what queries she submitted, what <b>ads</b> she <b>clicked</b> or ignored, and how long she spent on the land-ing pages of <b>clicked</b> <b>ads,</b> etc. Inspired by these observa-tions, we introduce a novel framework based on Recur-rent Neural Networks (RNN). Compared to traditional methods, this framework directly models the depen-dency on user’s sequential behaviors into the click pre-diction process through the recurrent structure in RNN. Large scale evaluations on the click-through logs from a commercial search engine demonstrate that our ap-proach can significantly improve the click prediction ac-curacy, compared to sequence-independent approaches...|$|R
40|$|Perception of the {{temporal}} structure of acoustic signals contributes critically to vocal signaling. In the aquatic clawed frog Xenopus laevis, calls differ primarily in {{the temporal}} parameter of <b>click</b> <b>rate,</b> which conveys sexual identity and reproductive state. We show here that an ensemble of auditory neurons in the laminar nucleus of the torus semicircularis (TS) of X. laevis specializes in encoding vocalization <b>click</b> <b>rates.</b> We recorded single TS units while pure tones, natural calls, and synthetic clicks were presented directly to the tympanum via a vibration-stimulation probe. Synthesized <b>click</b> <b>rates</b> ranged from 4 to 50 Hz, {{the rate at which}} the clicks begin to overlap. Frequency selectivity and temporal processing were characterized using response-intensity curves, temporal-discharge patterns, and autocorrelations of reduplicated responses to click trains. Characteristic frequencies ranged from 140 to 3, 250 Hz, with minimum thresholds of − 90 dB re 1 mm/s at 500 Hz and − 76 dB at 1, 100 Hz near the dominant frequency of female clicks. Unlike units in the auditory nerve and dorsal medullary nucleus, most toral units respond selectively to the behaviorally relevant temporal feature of the <b>rate</b> of <b>clicks</b> in calls. The majority of neurons (85 %) were selective for <b>click</b> <b>rates,</b> and this selectivity remained unchanged over sound levels 10 to 20 dB above threshold. Selective neurons give phasic, tonic, or adapting responses to tone bursts and click trains. Some algorithms that could compute temporally selective receptive fields are described...|$|R
5000|$|Almost half of American Internet users {{check or}} send email {{on a typical}} day, with emails {{delivered}} between 1 am and 5 am local time outperforming those sent at other times in open and <b>click</b> <b>rates.</b>|$|R
50|$|Using the {{real-estate}} on electronic documents and bills for marketing and promotional offers, {{results in a}} higher <b>click</b> <b>rate</b> and ROI than traditional email marketing has offered. Email content can be customized to include relevant, targeted and personalized marketing offers.|$|R
50|$|The {{series has}} {{received}} overwhelming critical acclaim since its release {{particularly for the}} suspenseful plot, buzz-generating episodes, performances by the casts, and direction. It {{is also one of}} the highest rated TVB series of the year, and is the most watched TVB drama of the year. The <b>click</b> <b>rate</b> of this drama has hit 2 billion online in Mainland China, breaking the record of Triumph in the Skies 2 and becoming the highest <b>click</b> <b>rate</b> TVB drama in Mainland China. The series has won Singapore's Media Favourite Series in StarHub TVB Awards 2014, Most Favourite Series in TVB Star Awards Malaysia 2014 and Best Drama in Hong Kong's TVB 48th Anniversary Awards 2014.|$|R
40|$|This paper {{addresses}} {{estimating the}} number of the users of a specific application behind IP addresses (IPs). This prob-lem is central to combating abusive traffic, such as DDoS attacks, <b>ad</b> <b>click</b> fraud and email spam. We share our expe-rience building a general framework at Google for estimating {{the number of}} users behind IPs, called hereinafter the sizes of the IPs. The primary goal of this framework is combating abusive traffic without violating the user privacy. The esti-mation techniques produce statistically sound estimates of sizes relying solely on passively mining aggregated applica-tion log data, without probing machines or deploying active content like Java applets. This paper also explores using the estimated sizes to detect and filter abusive traffic. The pro-posed framework was used to build and deploy an <b>ad</b> <b>click</b> fraud filter at Google. The first 50 M clicks tagged by the fil-ter had a significant recall of all tagged clicks, and their false positive rate was below 1. 4 %. For the sake of comparison, we simulated a näıve IP-based filter that does not consider the sizes of the IPs. To reach a comparable recall, the näıve filter’s false positive rate was 37 % due to aggressive tagging...|$|R
40|$|Evaluation {{of search}} engine result {{relevance}} {{has traditionally been}} an expensive process done by human judges. Researchers have sought cheap automated proxies for such judgments. This paper examines the relationship between relative <b>click</b> <b>rates</b> (of two engines) and relative human judgments of result sets returned by those engines. Previous work has indicated that human judgments are more consistent if provided in a relative form. We additionally observe that clicks are a function {{not only of the}} clicked result, but also of its competing neighborhood. These observations force an experimental design where we collect relative judgments of sets of results, rather than judgments on individual results. We conduct a large empirical study using forty judges, thousands of live users and hundreds of queries. Our results comparing Yahoo with another search engine in October 2003 show that in aggregate, higher <b>click</b> <b>rate</b> is indicative of higher relevance but the strength of the association is only moderate 40 %. Qualitative analysis suggests the association is not stronger because users click for reasons other than relevance such as curiosity and confusion. However, there are classes of queries (such as navigational queries) for which <b>click</b> <b>rates</b> are good indicators of relevance...|$|R
40|$|In this {{research}} we {{examine how the}} number of organic clicks change when search ads are present and when search ad campaigns are turned off. We then develop a statistical model to estimate the fraction of total clicks that {{can be attributed to}} search advertising. A meta-analysis of several hundred of these studies reveals that over 89 % of the <b>ads</b> <b>clicks</b> are incremental, {{in the sense that the}} visits to the advertiser’s site would not have occurred without the ad campaigns. ...|$|R
30|$|Firstly, click {{reflects}} {{the degree of}} user attention on an event. On the other hand, <b>click</b> <b>rate</b> can measure how many roles are participating in the event. The role of an event by click is a light degree, only showing the instinct of roles.|$|R
5000|$|Although Smart Post loses {{in terms}} of <b>click</b> <b>rates</b> by a narrow margin to Flash Post, whose {{editor-in-chief}} has just resigned, Fong is indifferent to this but summarises journalists attitude with Kevin Kellys message on the Whole Earth Catalog: [...] "Stay hungry. Stay Foolish." ...|$|R
5000|$|They use text {{content on}} their {{websites}} that encourages visitors to click on advertisements. Note that Google prohibits webmasters from using phrases like [...] "Click on my AdSense ads" [...] to increase <b>click</b> <b>rates.</b> The phrases accepted are [...] "Sponsored Links" [...] and [...] "Advertisements".|$|R
40|$|Platform {{companies}} such as Alibaba. com increasingly rely on search advertising as a revenue source. This study examines (1) the direct effect of new and existing buyers and sellers on platform advertising revenue, (2) their indirect effect through two intermediary performance variables (buyer's <b>click</b> <b>rate</b> and seller's <b>click</b> price), and (3) how the effects differ between launch and mature stages of the search advertising service. Unique data collected from a leading transactional business-to-business electronic platform suggest that new buyers click on more search advertisements than existing buyers, especially after the firm's buyers and sellers have learned and adapted to the service (mature stage). New sellers tend to outbid existing sellers in the mature stage, but {{the opposite is true}} when the service is newly introduced (launch stage). Because existing sellers can more effectively send quality signals in the launch stage, attracting existing, rather than new, sellers has a greater effect on <b>click</b> <b>rate</b> in the launch stage; however, the opposite is true in the mature stage. Attracting new buyers also has a greater effect on <b>click</b> <b>rate</b> and price, especially in the mature stage. Finally, using cost data from the platform, this article examines the economic returns of attracting new and existing buyers and sellers with respect to advertising revenue. Full Tex...|$|R
40|$|Toothed whales echolocating in {{the wild}} {{generate}} clicks with low repetition rates to locate prey but then produce rapid sequences of clicks, called buzzes, when attempting to capture prey. However, {{little is known about}} the factors that determine <b>clicking</b> <b>rates</b> or how prey type and behaviour influence echolocation-based foraging. Here we study Blainville's beaked whales foraging in deep water using a multi-sensor DTAG that records both outgoing echolocation clicks and echoes returning from mesopelagic prey. We demonstrate that the <b>clicking</b> <b>rate</b> at the beginning of buzzes is related to the distance between whale and prey, supporting the presumption that whales focus on a specific prey target during the buzz. One whale showed a bimodal relationship between target range and <b>clicking</b> <b>rate</b> producing abnormally slow buzz clicks while attempting to capture large echoic targets, probably schooling prey, with echo duration indicating a school diameter of up to 4. 3  m. These targets were only found when the whale performed tight circling manoeuvres spending up to five times longer in water volumes with large targets than with small targets. The result indicates that toothed whales {{in the wild}} can adjust their echolocation behaviour and movement for capture of different prey on the basis of structural echo information...|$|R
40|$|Sponsored {{search is}} at the center of a multibil-lion dollar market {{established}} by search tech-nology. Accurate <b>ad</b> <b>click</b> prediction is a key component for this market to function since the pricing mechanism heavily relies on the estimation of click probabilities. Lexical fea-tures derived from the text of both the query and ads play a significant role, complementing features based on historical click information. The purpose of this paper is to explore the use of word embedding techniques to generate ef-fective text features that can capture not only lexical similarity between query and ads but also the latent user intents. We identify several potential weaknesses of the plain application of conventional word embedding methodolo-gies for <b>ad</b> <b>click</b> prediction. These observa-tions motivated us to propose a set of novel joint word embedding methods by leveraging implicit click feedback. We verify the effec-tiveness of these new word embedding models by adding features derived from the new mod-els to the click prediction system of a com-mercial search engine. Our evaluation results clearly demonstrate the effectiveness of the proposed methods. To the best of our knowl-edge this work is the first successful applica-tion of word embedding techniques for the task of click prediction in sponsored search. ...|$|R
50|$|Moths {{have further}} evolved {{the ability to}} {{discriminate}} {{between high and low}} echolocation <b>click</b> <b>rates,</b> which indicates whether the bat has just detected their presence or is actively pursuing them. This allows them {{to decide whether or not}} defensive ultrasonic clicks are worth the time and energy expenditure.|$|R
5000|$|Engagement. Bills and {{statements}} receive {{more attention than}} {{any other form of}} communication including television advertisements. As a result, marketing included in these types of emails and documents has a higher <b>click</b> <b>rate</b> and conversion rate. The average customer invests between one and three minutes for statement review.|$|R
40|$|Many {{real life}} {{datasets}} have skewed distributions of events when {{the probability of}} observing few events far exceeds the others. In this paper, we observed that in skewed datasets {{the state of the}} art collaborative filtering methods perform worse than a simple probabilistic model. Our test bench includes a real <b>ad</b> <b>click</b> stream dataset which is naturally skewed. The same conclusion is obtained even from the popular movie rating dataset when we pose a binary prediction problem of whether a user will give maximum rating to a movie or not...|$|R
40|$|Abstract: In {{this paper}} {{addresses}} estimating {{the number of}} the users of a specific application behind IP address (IPs). This problem is central to combating abusive traffic, such as DDoS attacks, <b>ad</b> <b>click</b> fraud and email spam, scams, phishing, and malware distribution. Here we proposed an efficient method to classify the IP addresses that are associated with a large number of user requests. The idea is to classify the network traffic based on the IP addresses by first clustering the data using K-mean clustering and then applying horizontal partition based id 3 decision tree. 1...|$|R
