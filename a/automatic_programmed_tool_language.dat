0|8128|Public
5000|$|These {{developments}} {{were done}} in collaboration with his employee Frank L. Stulen, who Parsons hired when he {{was head of the}} Rotary Wing Branch of the Propeller Lab at Wright-Patterson Air Force Base, in April 1946. Together, they were the first to use computer methods to solve machining problems, in particular, the accurate interpolation of the curves describing helicopter rotor blades. In 1946, [...] "computer" [...] still meant a punched-card operated calculation machine. In 1948, Parsons' company, [...] "Parsons Corporation" [...] of Traverse City, Michigan, was awarded a contract to make the innovative and challenging tapered wings for military aircraft; they won the contract because they developed the computer support to do the difficult three-dimensional interpolation for the complex shapes, as well as the 800 steps long production cycle for the wing manufacturing. IBM was one of the subcontractors, as was MIT, which took care of the servomechanisms. The latter lab boosted the developments of CNC machining in the following decades, by developing reliable servo control in 1952 and the APT (<b>Automatic</b> <b>Programmed</b> <b>Tool)</b> <b>programming</b> <b>language</b> for CNC machines. It was only after the servos were also steered by computers that real [...] "numerical control" [...] was realised. The initial developments of Parsons and Stulen were only about the calculations, and not the control: the results of the calculations were given to human operators that turned the wheels on the machine tool to generate the desired tool paths.|$|R
50|$|SADT {{has been}} {{developed}} and field-tested {{during the period of}} 1969 to 1973 by Douglas T. Ross and SofTech, Inc.. The methodology was used in the MIT <b>Automatic</b> <b>Programming</b> <b>Tool</b> (APT) project. It received extensive use starting in 1973 by the US Air Force Integrated Computer Aided Manufacturing program.|$|R
40|$|In 1982 FORTRAN {{will have}} {{existed in the}} {{environment}} of computers, computing and computation for 25 years, {{making it one of}} the most successful of programming languages even if it is not the actual oldest still surviving language. The honor of being the Oldest still belongs to APT (<b>Automatic</b> <b>Programmed</b> <b>Tool.)</b> This report is the script of talk given at several institutions during the Spring of 1982 and serves as a Skeleton on which a broader history is to be developed...|$|R
40|$|Abstract: Post-processing {{technology}} {{is the key to}} CNC <b>automatic</b> <b>programming</b> technology and an important module of the CAD / CAM system. Post-processing technology converts the NC program that is produced by the CNC <b>automatic</b> <b>programming</b> <b>tool</b> into the file that can be identified by CNC system. Moreover, the generated tool path files must match with the CNC system. Post-processing techniques and UG software are briefly introduced. Using them, a post-processor for FANUC CNC systems is created. The program that generated by the special processor is contrasted with the general processor. The results illustrate that using the dedicated post-processor in engineering applications can improve programming efficiency and processing reliability...|$|R
50|$|Tools for {{reasoning}} about programs fall on {{a spectrum}} from fully <b>automatic</b> <b>program</b> analysis <b>tools,</b> {{which do not}} require any user input, to interactive tools where the humanis intimately involved in the proof process. Many such tools have been developed; the following list includes a few representatives in each category.|$|R
40|$|The {{cluster of}} {{workstations}} (COW) {{is becoming an}} important platform for parallel processing applications. COWs offer the benefits of cost and accessibility over other platforms. In order to develop applications which exploit parallelism on a COW, a <b>programming</b> <b>tool,</b> <b>programming</b> <b>language,</b> distributed shared memory, or a parallelising compiler should be used. Each of these approaches is discussed within, and <b>tools</b> and <b>languages</b> {{become the focus of}} this report. Additionally, an approach based on <b>programming</b> <b>tools</b> and distributed shared memory, supported by distributed operating systems is proposed. <b>Tools</b> and <b>Languages</b> for Developing Parallel Applications for Clusters of Workstations Page ii 1 Introduction............................................................... 1 2 The Development of Parallel Applications for Clusters of Workstations............... 1 2. 1 Parallel <b>Programming</b> <b>Tools...........</b> [...] ...|$|R
50|$|<b>Automatic</b> <b>Program</b> Analyses. These <b>tools</b> {{typically}} {{look for}} restricted classes of bugs (e.g., memory safety errors) or attempt {{to prove their}} absence, but fall short of proving full correctness.|$|R
40|$|Abstract. Infer 1 {{is a new}} <b>automatic</b> <b>program</b> {{verification}} <b>tool</b> {{aimed at}} proving memory safety of C programs. It attempts to build a compositional proof of the program at hand by composing proofs of its constituent modules (functions/procedures). Bugs are extracted from failures of proof attempts. We describe the main features of Infer {{and some of the}} main ideas behind it. ...|$|R
5000|$|Plug-ins {{system for}} {{independent}} 5-th generation <b>programming</b> <b>language</b> <b>tools</b> {{to work on}} [...] "properties, methods, events and actions" ...|$|R
40|$|The YAFL {{programming}} language is an original modern coding language. In this article, {{the design and}} implementation of YAFL are discussed, along with several attached <b>programming</b> <b>tools.</b> The <b>language</b> and its underlying principles are discussed first. Furthermore, some information about the experience gained {{with the use of}} YAFL are provided. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|R
25|$|Since 2006, {{a series}} of {{organized}} hackathons has occurred, the Hac series, aimed at improving the <b>programming</b> <b>language</b> <b>tools</b> and libraries.|$|R
40|$|Computer-Aided Design/Computer-Aided Manufacturing (CAD/CAM), {{a highly}} {{interactive}} software, has been implemented on minicomputers at the NASA Langley Research Center. CAD/CAM software integrates many formerly fragmented programs and procedures into one cohesive system; {{it also includes}} finite element modeling and analysis, and has been interfaced via a computer network to a relational data base management system and offline plotting devices on mainframe computers. The CAD/CAM software system requires interactive graphics terminals operating at a minimum of 4800 bits/sec transfer rate to a computer. The system is portable and introduces 'interactive graphics', which permits the creation and modification of models interactively. The CAD/CAM system has already produced designs for a large area space platform, a national transonic facility fan blade, and a laminar flow control wind tunnel model. Besides the design/drafting element analysis capability, CAD/CAM provides options to produce an <b>automatic</b> <b>program</b> <b>tooling</b> code to drive a numerically controlled (N/C) machine. Reductions in time for design, engineering, drawing, finite element modeling, and N/C machining will benefit productivity through reduced costs, fewer errors, and {{a wider range of}} configuration...|$|R
40|$|Image {{segmentation}} plays {{a critical}} role in many image analysis applications. However, it is ill-defined in nature and {{remains one of the most}} intractable problems in image processing. In this thesis, we propose a genetic programming based algorithm for image segmentation (GPIS). Typically, genetic programming is a Darwinian-evolution inspired program discovery method and in the past it has been successfully used as an <b>automatic</b> <b>programming</b> <b>tool.</b> We make use of this property of GP to evolve efficient and accurate image segmentation programs from a pool of basic image analysis operators. In addition, we provide no a priori information about that nature of the images to the GP. The algorithm was tested on two separate medical image databases and results show the proposed GP's ability to adapt and produce short and accurate segmentation algorithms, irrespective of the database in use. We compared our results with a popular GA based image segmentation/classification system, GENIE Pro. We found that our proposed algorithm produced accurate image segmentations performed consistently on both databases and could possibly be extended to other image databases as a general-purpose image segmentation tool...|$|R
40|$|Communication lifting is {{a program}} {{transformation}} {{that can be applied}} to a synchronous process network to restructure the network. This restructuring in theory improves sequen-tial and parallel performance. The transformation has been formally specied and proved correct and it has been implemented as an <b>automatic</b> <b>program</b> transformation <b>tool.</b> This tool has been applied to a small set of programs consisting of synchronous process net-works. Measurements indicate performance gains in practice both with sequential and parallel evaluation. Communication lifting is a worthwhile optimisation to be included in a compiler for a lazy functional language. ...|$|R
40|$|In {{order to}} assist the {{performance}} evaluation of complex stochastic models, <b>automatic</b> <b>program</b> <b>tools</b> were developed since a long time. Stochastic Petri Nets (SPN) are applied as an e#ective model description language supported by several analytical and simulation tools. The analytical description and the numerical analysis of non-Markovian stochastic Petri Net models gained attention recently. There are di#erent theoretical approaches and numerical methods considered in recent works, such as the Markov renewal theory and the supplementary variable approach, but {{to find the most}} e#ective way of the analysis of such models is still an open research problem. The supplementary variable approach was successfully applied to the transient and steady state analysis of Markov Regenerative Stochastic Petri Nets (MSRPN) when the preemption policy associated with the Petri Net (PN) transitions was preemptive repeat di#erent (prd), but it was not applicable with other preemption mechanisms. In this paper we extend the applicability of the supplementary variable approach to a class of MRSPNs in which preemptive resume (prs) policy can also be assigned to the transitions of the PN. Key words: Markov Regenerative Stochastic Petri Nets, Preemption Policies, Supplementary Variable Approach...|$|R
40|$|The {{objective}} of <b>automatic</b> <b>programming</b> {{is to improve}} the overall environment for describing the program. This improved environment is realized by a reduction in the amount of detail that the programmer needs to know and is exposed to. Furthermore, this improved environment is achieved by a specification language that is more natural to the user's problem domain and to the user's way of thinking and looking at the problem. The goal of this research is to apply the concepts of <b>automatic</b> <b>programming</b> (AP) to modeling discrete event simulation system. Specific emphasis is on the design and development of simulation tools to assist the modeler define or construct a model of the system and to then automatically write the corresponding simulation code in the target simulation language, GPSS/PC. A related goal is to evaluate the feasibility of various languages for constructing <b>automatic</b> <b>programming</b> simulation <b>tools...</b>|$|R
40|$|<b>Automatic</b> <b>program</b> {{verification}} <b>tools</b> have to {{cope with}} program-ming language and machine semantics, undecidability, and mathe-matical induction, and so are all complex and imperfect. The ins and outs of <b>automatic</b> <b>program</b> verification will be discussed in light of the theory and practice of abstract interpretation [18, 19, 22]. Programming language semantics If Edsger W. Dijkstra could claim in his 1972 Turing lecture [29, p. 863] that “When FORTRAN has been called an infantile disorder, full PL/ 1, with its growth characteristics of a dangerous tumor, {{could turn out to be}} a fatal disease. ”, PL/ 1 and its 1000 pages formal operational semantics defined in VDL [7] now appears as a marvel of simplicity compared to present-day programming languages [57] and their informal definitions [1]. The formal specification of the semantics of programming lan...|$|R
30|$|A strong {{cluster of}} {{references}} emerged around <b>tools,</b> <b>programming</b> <b>languages</b> and methods for understanding data. These works represent {{a cross section}} of non-domain specific methods that researchers from a variety of disciplines are utilizing to process data to information to understanding.|$|R
50|$|A once common, but now outdated, {{application}} {{of this type of}} cam was <b>automatic</b> machine <b>tool</b> <b>programming</b> cams. Each <b>tool</b> movement or operation was controlled directly by one or more cams. Instructions for producing programming cams and cam generation data for the most common makes of machine were included in engineering references well into the modern CNC era.|$|R
5000|$|Douglas Taylor [...] "Doug" [...] Ross (21 December 1929 - 31 January 2007) was an American {{computer}} scientist pioneer, and Chairman of SofTech, Inc. [...] He is most famous for originating the term CAD for computer-aided design, {{and is considered}} to be the father of Automatically <b>Programmed</b> <b>Tools</b> (APT) a <b>language</b> to drive numerically controlled manufacturing.|$|R
40|$|This {{workshop}} {{was dedicated}} to research towards better support for unanticipated software evolution (USE) in development <b>tools,</b> <b>programming</b> <b>languages,</b> component models and related runtime infrastructures. The report gives {{an overview of the}} submitted papers and summarizes the essence of discussions during plenary sessions and in working groups...|$|R
2500|$|Their actual {{minority}} report {{quote from}} 1970: [...] " [...] More than ever {{it will be}} required from an adequate <b>programming</b> <b>tool</b> that it assists, by structure, the programmer in the most difficult aspects of his job, viz. in the reliable creation of sophisticated programs. In this respect we fail {{to see how the}} language proposed here [...] is a significant step forward: on the contrary, we feel that its implicit view of the programmer's task is very much the same as, say, ten years ago. This forces upon us the conclusion that, regarded as a <b>programming</b> <b>tool,</b> the <b>language</b> must be regarded as obsolete. [...] " [...] Signed by: Dijkstra, Duncan, Hoare, Randell, Seegmueller, Turski, Woodger. With Jan V. Garwick on Dec. 23, 1968.|$|R
40|$|Abstract—We {{consider}} {{the problem of}} establishing cryptographic guarantees—in particular, computational indistinguishability—for Java or Java-like programs that use cryptography. For this purpose, we propose a general framework that enables existing <b>program</b> analysis <b>tools</b> that can check (standard) non-interference properties of Java programs to establish cryptographic security guarantees, even if the tools a priori cannot deal with cryptography. The approach that we take is new and combines techniques from program analysis and simulation-based security. Our framework is stated and proved for a Java-like language that comprises a rich fragment of Java. The general idea of our approach should, however, be applicable also to other practical programming languages. As a proof of concept, we use an <b>automatic</b> <b>program</b> analysis <b>tool</b> for checking non-interference properties of Java <b>programs,</b> namely the <b>tool</b> Joana, {{in order to establish}} computational indistinguishability for a Java program that involves clients sending encrypted messages over a network, controlled by an active adversary, to a server. I...|$|R
40|$|International audienceWe {{present an}} {{application}} of relational algebra to coalition formation. This leads to speciﬁcations, which can be executed {{with the help of}} the RelView tool after a simple translation into the <b>tool's</b> <b>programming</b> <b>language.</b> As an example we consider a simpliﬁcation of the situation in Poland after the 2001 elections...|$|R
40|$|This {{document}} {{describes the}} main features of Object Oriented Programming (OOP). The C++ <b>programming</b> <b>language</b> <b>tools</b> that help implement these concepts of OOP are illustrated with several examples. Some rules for designing classes have been described: An attempt {{has been made to}} emphasise the importance of OOP in scientific code development...|$|R
50|$|Microsoft Azure is the company's cloud {{computing}} platform that hosts virtual machines, websites and more. It provides both platform {{as a service}} (PaaS) and infrastructure as a service (IaaS) services and supports many different <b>programming</b> <b>languages,</b> <b>tools</b> and frameworks, including both Microsoft-specific and third-party software and systems. It was launched in 2010.|$|R
40|$|By {{paying more}} {{attention}} to semantics-based <b>tool</b> generation, <b>programming</b> <b>language</b> semantics can significantly increase its impact. Ultimately, this may lead to "Language Design Assistants" incorporating substantial amounts of semantic knowledge. 1991 ACM Computing Classification System: D. 2. 2, D. 3. 1, D. 3. 4, F. 3. 2 Keywords and Phrases: semantics of <b>programming</b> <b>languages,</b> <b>tool</b> generation, <b>language</b> development system, language design assistant, domain-specific language, compiler toolkit, software renovation tool Note: Submitted to ACM SIGPLAN Notices. This research {{was supported in part by}} the Telematica Instituut under the Domain-Specific Languages project. 1 The Role of Programming Language Semantics Programming language semantics has lost touch with large groups of potential users [39]. Among the reasons for this unfortunate state of a#airs, one stands out. Semantic results are rarely incorporated in practical systems that would help language designers to implement and test a [...] ...|$|R
40|$|Work {{contains}} {{review of}} declarative domain-specific language for data mining, using of which doesn?t demand knowledge of <b>tool</b> <b>programming</b> <b>languages</b> {{for development of}} data processing scenarios and that really reduces labor inputs in analytical reports development. Proposed language is implemented at ICSU World Data Center for Geoinformatics and Sustainable Development hosted by NTUU ?KPI?...|$|R
40|$|This report {{documents}} the Bachelor’s End Project of Jon Mediero Iturrioz for the Bachelor in Informatics Engineering of the UPV/EHU. The project was made {{under the supervision}} of Francisca Lucio Carrasco. The project belongs to the domain of formal methods. In the project a methodology to prove the correctness of concurrent programs called Local Rely-Guarantee reasoning is analyzed. Afterwards, the methodology is implemented over Dagny <b>automatic</b> <b>program</b> verification <b>tool,</b> which was introduced to me in the Formal Methods for Software Developments optional course of the fourth year of the bachelor. In addition to Local Rely-Guarantee reasoning, in the report Hoare logic, Separation logic and Variables as Resource logic are explained, {{in order to have a}} good foundation to understand the new methodology. Finally, the Dafny implementation is explained, and some examples are presented...|$|R
40|$|MatLab is an {{essential}} tool in high-productivity development of applications that involve much scientific computation. Problems can be presented in a familiar mathematical formalism and the simple yet extensive visualization capabilities support rapid algorithm and model prototyping. Nonetheless, {{for the sake of}} efficiency and homogeneity with other parts of the code, it is often necessary to convert MatLab code into C or C++, which is a tedious and errorprone task if performed manually. The author presents a tool named MatForce that automatically converts MatLab scripts into C++ code, producing human-readable, extensible C++ sources that can subsequently be fitted {{to the needs of the}} encapsulating application. KEYWORDS <b>programming</b> <b>tools</b> and <b>languages,</b> developing computation-intensive algorithms, source-to-source compilation, automatic type inference...|$|R
40|$|Parsing {{programming}} languages is {{an essential}} component of the front end of most <b>program</b> comprehension <b>tools.</b> <b>Languages</b> such as C++ can be difficult to parse and so it can prove useful to re-use existing front ends such as those from the GNU compiler collection, gcc. We have modified gcc to provide syntactic tags in XML format around the source code which can greatly enhance our comprehension of the program structure. Further, by using XML transformation stylesheets, the XML outputted by our modified gcc can be translated into a more readable format. Our tool, gccXfront leverages the power and portability of the gcc suite, since any C, C++, Objective C or Java program can be processed using gcc. Our tool can thus act as a bridge between gcc and other <b>program</b> comprehension <b>tools</b> that accept XML formatted input. ...|$|R
40|$|We {{present an}} {{application}} of relational algebra to coalition formation. This leads to speciﬁcations, which can be executed {{with the help of}} the RelView tool after a simple translation into the <b>tool's</b> <b>programming</b> <b>language.</b> As an example we consider a simpliﬁcation of the situation in Poland after the 2001 elections. RelView; relational algebra; coalition formation; feasible government; dominance; stable government...|$|R
40|$|A partial {{evaluator}} is an <b>automatic</b> <b>program</b> transformation <b>tool.</b> Given as input {{a general}} program {{and part of}} its input, it can produce a specialized version. If the partial evaluator is self-applicable, program generators can be made. The goal is efficiency : the specialized program often runs {{an order of magnitude}} faster than the general one. We consider partial evaluation of the pragmatic oriented imperative C programming language. New problems studied includes partially static data structures, non-local static side-effects under dynamic control, and a restricted use of pointers. We define a Core C language, derive a two-level Core C language with explicit binding times, and formulate well-annotatedness conditions. Function specialization and code generation is described in terms of the two-level Core C language. An implementation of the C partial evaluator has been made. Some experimental results are given. 1 Introduction Partial evaluation is now a well-established tool for aut [...] ...|$|R
40|$|The {{purpose of}} this paper is to {{describe}} a comprehensive approach to representing and machining complex surface shapes in an APT programming system. The APT (Automatically <b>Programmed</b> <b>Tools)</b> user <b>language</b> was extended to permit the definition of a hierarchy of curves and surfaces. Much of the logic has been implemented using matrix canonical forms which are closed under the full family of projective transformations, permitting family of parts storage and retrieval and part compensation. The area of numerical control machining was addressed, but the solutions for tool positioning were only partially successful due to the complexity of the algorithmic problem. This paper first outlines some of the mathematical methods adopted and then illustrates how these have been implemented with an APT part programming exampl...|$|R
5000|$|Microsoft Azure (formerly Windows Azure) [...] is a cloud {{computing}} service created by Microsoft for building, testing, deploying, and managing applications and services through a global network of Microsoft-managed data centers. It provides software {{as a service}} (SAAS), platform as a service and infrastructure as a service and supports many different <b>programming</b> <b>languages,</b> <b>tools</b> and frameworks, including both Microsoft-specific and third-party software and systems.|$|R
40|$|In {{this paper}} we generalize {{the notion of}} non-interference making it {{parametric}} relatively to what an attacker can analyze about the input/output information flow. The idea is to consider attackers as data-flow analyzers, whose task is to reveal properties of confidential resources by analyzing public ones. This means that no unauthorized flow of information is possible from confidential to public data, relatively {{to the degree of}} precision of an attacker. We prove that this notion can be fully specified in standard abstract interpretation framework, making the degree of security of a program a property of its semantics. This provides a comprehensive account of non-interference features for language-based security. We introduce systematic methods for extracting attackers from programs, providing domain-theoretic characterizations of the most precise attackers which cannot violate the security of a given program. These methods allow us both to compare attackers and program secrecy by interpretations, and to design <b>automatic</b> <b>program</b> certification <b>tools</b> for language-based security by abstract interpretation...|$|R
