7|49|Public
40|$|Abstract- We {{describe}} a pre-processing technique for mining a telecommunication <b>alarm</b> <b>log</b> for frequent temporal patterns. The method consists in extracting relevant subsets {{from the initial}} log {{with the aim of}} discovering frequent patterns more accurately. In a first step, the alarm types presenting the same temporal behaviour are clustered with a self organizing map. Then, log areas which are rich in alarms of each cluster are regrouped in subsets which are subsequently exhaustively searched for frequent patterns. We demonstrate the efficiency of our preprocessing method through experiments on an actual <b>alarm</b> <b>log</b> from an ATM network. Keywords: Self-organizing map, chronicle recognition, telecommunications network supervision. ...|$|E
40|$|The {{introduction}} of {{distributed control systems}} and {{the high level of}} interconnectivity of modern process plants has caused alarm flooding {{to become one of the}} main problems in alarm management of process plants. A reduction of alarm flood periods contributes to a decrease in plant incidents. In this work, a combination of <b>alarm</b> <b>log,</b> process data and connectivity analysis is used to isolate consequence alarms originating from the same process abnormality and to provide a causal alarm suggestion. The effectiveness of the method is illustrated on an industrial case study of an ethylene plant, a typical example of a large-scale industrial system...|$|E
40|$|This paper {{presents}} a novel methodology {{to detect a}} set of more suitable attributes that may potentially contribute to emerging faults of a wind turbine. The set of attributes were selected from one-year historical data for analysis. The methodology uses the k-means clustering method to process outlier data and verifies the clustering results by comparing quartiles of boxplots, and applies the auto-associative neural networks to implement the residual approach that transforms the data to be approximately normally distributed. Hotelling T 2 multivariate quality control charts are constructed for monitoring the turbine’s performance and relative contribution of each attribute is calculated for the data points out of upper limits to determine the set of potential attributes. A case using the historical data and the <b>alarm</b> <b>log</b> is given and illustrates that our methodology {{has the advantage of}} detecting a set of susceptible attributes at the same time compared with only one independent attribute is monitored...|$|E
40|$|Equipment shelter alarm {{management}} is usually performed from central offices from which field units react to alarms {{and to which}} they return after the alarm source has been fixed. This is time consuming and travel times are often long. The goal of this thesis is to present an efficient alarm handling solution that reduces costs and repair times. The thesis also presents theory about digital cartography, routing and mobile positioning. An alarm pilot was planned and built. The pilot combines a GIS system, an equipment shelter database, mobile positioning, routing and <b>alarm</b> <b>logging.</b> <b>Alarms</b> are received from external systems. Costs and repair times are reduced significantly when travel times are shorter. This requires the mobile positioning of the nearest field units to the alarm source. Efficient <b>alarm</b> <b>logging</b> and reporting facilitates service planning and increases customer satisfaction...|$|R
40|$|The APT {{attack on}} the Internet is {{becoming}} more serious, and most of intrusion detection systems can only generate alarms to some steps of APT attack and cannot identify {{the pattern of the}} APT attack. To detect APT attack, many researchers established attack models and then correlated IDS logs with the attack models. However, the accuracy of detection deeply relied on the integrity of models. In this paper, we propose a new method to construct APT attack scenarios by mining IDS security logs. These APT attack scenarios can be further used for the APT detection. First, we classify all the attack events by purpose of phase of the intrusion kill chain. Then we add the attack event dimension to fuzzy clustering, correlate IDS <b>alarm</b> <b>logs</b> with fuzzy clustering, and generate the attack sequence set. Next, we delete the bug attack sequences to clean the set. Finally, we use the nonaftereffect property of probability transfer matrix to construct attack scenarios by mining the attack sequence set. Experiments show that the proposed method can construct the APT attack scenarios by mining IDS <b>alarm</b> <b>logs,</b> and the constructed scenarios match the actual situation {{so that they can be}} used for APT attack detection...|$|R
40|$|A {{computer}} system for control and monitoring of aquaculture plants {{has been developed}} by the Norwegian company NODEC. The system {{is based on a}} local area network which interfaces a {{computer system}} to the primary instruments located at various sites in the plant. Special software modules have been developed to handle different tasks such as data gathering, automatic control, <b>alarming,</b> <b>logging,</b> trend analysis and reporting. Special effort has been made to develop a user-friendly high level man-machine interface. A software library is available for monitoring and control of water quality, water distribution, heating systems, biomass and feeding systems...|$|R
40|$|As the {{software}} industry grows larger by the minute, {{the need for}} automated solutions within bug report management is on the rise. Although some {{research has been conducted}} in the area of bug handling, new, faster or more precise approaches are yet to be developed. A bug report typically contains a free text observations field where the issue can be described by a human. Research regarding processing of this type of field is extensive, however, bug reports are often accompanied with system log files which have been given less attention so far. In the 4 G LTE telecommunications network, the available system log files are many and several are likely to aid the routing of bug reports. In this thesis, one system log file was chosen to be evaluated; the <b>alarm</b> <b>log.</b> The alarm logs are time series count data containing alarms raised by the system. The <b>alarm</b> <b>log</b> data have been pre-processed with data mining techniques. The Apriori algorithm has been used to mine for specific alarms and alarming objects which indicates that the bug report should be solved by a particular developer group. We extend the Apriori algorithm to a temporal setting by using a customised time dependent confidence measure. To further mine for interesting sequences of events in the logs, the sequence mining approach SPADE has been used. The extracted class-associated sequences from both pre-processing approaches are transformed into binary features possible to use as predictors in any prediction model. The results have been evaluated by predicting the correct developer group with two different methods; logistic regression and DO-probit. Logistic regression was regularised with the elastic net penalty to avoid computational issues as well as handling the sparse covariate set. DO-probit was used with a horseshoe prior; it is well suited for the sparse covariate regression problem as it is customised to obtain signals in sparse, noisy data. The results indicate that a data mining approach for processing alarm logs is promising. The results show that the rules obtained with the Apriori mining process are suitable for mining the alarm logs as most binary representations of the rules used as covariates in logistic regression are kept in the equations for the expected classes with strongly positive coefficients. Although, the overall improvement in accuracy from using the alarms logs in addition to the learned topics from free text fields is modest, the alarm logs are concluded to be a good complement to the free text information as some Apriori covariates appears to be better suited to predict some classes than some topics...|$|E
40|$|The massive {{amount of}} alarm data {{generated}} from intrusion detection systems is cumbersome for network system administrators to analyze. Often, important details are overlooked {{and it is difficult}} to get an overall picture of what is occurring in the network by manually traversing textual alarm logs. We have designed a novel visualization to address this problem by showing alarm activity within a network. Alarm data is presented in an overview where system administrators can get a general sense of network activity and easily detect anomalies. They then have the option of zooming and drilling down for details. The information is presented with local network IP (Internet Protocol) addresses plotted over multiple yaxes to represent the location of alarms. Time on the x-axis is used to show the pattern of the alarms and variations in color encode the severity and amount of alarms. Based on our system administrator requirements study, this graphical layout addresses what system administrators need to see, is faster and easier than analyzing text logs, and uses visualization techniques to effectively scale and display the data. With this design, we have built a tool that effectively uses operational <b>alarm</b> <b>log</b> data generated on the Georgia Tech campus network. The motivation and background of our design is presented along with examples that illustrate its usefulness...|$|E
40|$|International audienceIn {{this paper}} {{we focus on}} serial episodes, that are {{sequences}} of event types extracted from single or multiple input sequences, and that reflect a qualitative relation is-followed-by between the event types. Episodes have natural applications into several domains, including for instance the analysis of business time series, medical data, geophysical data and also <b>alarm</b> <b>log</b> analysis for network monitoring (especially in telecommunications). However, in many applications episodes clearly show some limitations, {{due to the fact}} that the information provided by the is-followed-by relation is not always enough to properly characterize the phenomena at hand. This, in particular, pulls our research toward the refinement of episodes to incorporate quantitative temporal information, able to describe the time intervals observed for the is-followed-by relation. We proposed a refinement of episodes called quantitative episodes, that provides quantitative temporal information in a readable, tree-based graphically representable form. These quantitative episodes describe the main groups of homogeneous behaviors within the occurrences of each episode, according to the elapsed times between the consecutive event types of the episode. Moreover, they are not provided in an isolated way, but in trees giving a global view of how the occurrences of the corresponding episode differentiate in homogeneous groups along the elements of the pattern. From a computational point of view, the main interest of the quantitative episodes is that they can be mined in a sound and complete way without increasing the cost of extractions significantly when compared to extractions of episodes alone. This is achieved through an extraction algorithm that tightly integrates episode extraction with a computationally reasonable analysis of temporal quantitative information...|$|E
40|$|This paper {{presents}} {{the way we}} take benefit of new technological improvements for teaching statistics. The underlying courses are given in « data mining » and in « statistics consulting » at a master level: Master ISIFAR 1 at Paris X University. Nowadays, due particulary to new technologies, the data sources have deeply changed. Every compagny owns its datawarehouse to store current and strategic data. Every plant owns its Distributed Control System (DCS), where the information management system is used for long term data storage, data and <b>alarm</b> <b>logging.</b> Large data bases, available through internet or privat...|$|R
40|$|Thesis (MTech (Electrical Engineering)) [...] Peninsula Technikon, Cape Town, 1996 The Southern Nylon Spinning plant, at South African Nylon Spinners in Bellville - Cape Town - South Africa, {{is one of}} {{the oldest}} on the site and a need arose to upgrade the {{existing}} method used in speed monitoring in this particular plant. This system was unable to produce alarms on speed limits being exceeded (i. e. on under-speed or over-speed). There was no <b>alarm</b> <b>logging</b> or historical trending. Manual records on speed were either incomplete or non-existent. Thus the purpose of this study was to investigate the existing speed monitoring system and implement a suitable computerised method of speed monitoring...|$|R
40|$|The EU FP 7 Reliawind {{project has}} the aim to {{identify}} and understand critical failures and their mechanisms through quantitative studies of detailed wind farm data. A common wind turbine taxonomy and a universal database structure for storing downtime events from multiple manufacturer's turbines have been defined. Systematic and consistent processes {{have been developed to}} deal with historical data from wind farm Owners and Operators. Data including 10 -minute SCADA, service records/work orders and <b>alarm</b> <b>logs</b> have been analysed to determine downtime events within the common taxonomy. The downtime events have been analysed to determine the distribution of failure rates and downtimes between the sub-assemblies. To date 31, 500 downtime events have already been added to the common database structure and the database is still expanding...|$|R
40|$|As {{the trend}} of {{successful}} network attacks continue to rise, better forms of intrusion, detection and prevention are needed. This thesis addresses network traffic visualization techniques that aid administrators in recognizing attacks. A view of port statistics and Intrusion Detection System (IDS) alerts has been developed. Each help to address issues with analyzing large datasets involving networks. Due {{to the amount of}} traffic as well as the range of possible port numbers and IP addresses, scaling techniques are necessary. A port-based overview of network activity produces an improved representation for detecting and responding to malicious activity. We have found that presenting an overview using stacked histograms of aggregate port activity, combined with the ability to drill-down for finer details allows small, yet important details to be noticed and investigated without being obscured by large, usual traffic. Another problem administrators face is the cumbersome amount of alarm data generated from IDS sensors. As a result, important details are often overlooked, {{and it is difficult to}} get an overall picture of what is occurring in the network by manually traversing textual alarm logs. We have designed a novel visualization to address this problem by showing alarm activity within a network. Alarm data is presented in an overview from which system administrators can get a general sense of network activity and easily detect anomalies. They additionally have the option of then zooming and drilling down for details. Based on our system administrator requirements study, this graphical layout addresses what system administrators need to see, is faster and easier than analyzing text logs, and uses visualization techniques to effectively scale and display the data. With this design, we have built a tool that effectively uses operational <b>alarm</b> <b>log</b> data generated on the Georgia Tech campus network. For both of these systems, we describe the input data, the system design, and examples. Finally, we summarize potential future work. Ph. D. Committee Chair: Copeland, John; Committee Member: Hamblen, James; Committee Member: Ji, Chuanyi; Committee Member: Owen, Henry; Committee Member: Stasko, Joh...|$|E
40|$|Despite {{advances}} in intrusion detection and analysis systems (IDS), real-time monitoring of network security status remains a prominent problem. Current methods rely on serendipitous discovery of network anomalies through IDS alarms or exhaustive backtracking through off-line data repositories consisting of network flows and <b>alarm</b> <b>logs.</b> Our work seeks {{to enhance the}} alarm capabilities of IDS systems with simultaneous display of pertinent network data and IDS alerts facilitated by an ambient display. Ambient displays rely on the enormous bandwidth of the visual cortex to convey vast amounts of information in visual form. Here, we present a framework for network security visualization based on the display of configurable per-host qualities (e. g. data packets transferred) with an interface to current IDS systems (e. g. MINDS, Snort) {{with the goal of}} providing a flexible system to complement conventional network security analysis methods...|$|R
50|$|A {{full size}} {{computer}} system was installed to automatically switch heaters {{on or off}} as required to rebalance the phase loading and to remove {{the threat of a}} 120 KV line outage. Detroit Edison permitted McLouth a maximum phase imbalance of 43 MW. The computer shut off heaters if a limit was reached and provided printouts of hourly demands, <b>alarms,</b> engineering <b>logs,</b> as well as maintenance logs.|$|R
50|$|The term ICE {{is widely}} used in {{cyberpunk}} fiction.White ICE trips an <b>alarm,</b> or simply <b>logs</b> an intrusion.Gray ICE fights defensively.Black ICE will follow the intruder back to their computer, and completely destroy it, possibly harming the intruder.|$|R
40|$|Modern 3 rd {{generation}} synchrotron light sources aim for 100 % availability. No {{single beam}} interruption is acceptable and every beam disturbance should be investigated: {{what caused the}} interruption? Can it be avoided in the future? If it cannot be avoided, how can the recovery be accelerated? An automated event recording system has been implemented at the Swiss Light Source (SLS) {{in order to simplify}} beam distortion investigations with respect to a well-defined metrics. The system identifies beam disturbances and records automatically the type and duration of the event. Relevant information of the event, like control system archive data or shift summaries, is linked to the event and presented in Web pages. Tools for the automated evaluation of <b>alarm</b> <b>logs</b> are provided that generate summaries of a beam distortion. On the basis of this information each event will be assigned to a failure cause. The means to filter the events are provided. We will describe the concept and the implementation of the system at the SLS and our experiences with it. Finally, the SLS operation event logging system will be compared with failure analysis at other light sources...|$|R
40|$|Abstract: Most {{commercial}} {{intrusion detection}} systems (IDSs) presently available are signature-based network IDSs. Organisations using these IDSs are still experiencing difficulties in detecting intrusive activity on their networks since novel new attacks are consistently being encountered, and analysts can miss legitimate alarms when reviewing large <b>alarm</b> <b>logs</b> that contain {{a high number}} of false positives. There has been research investigating the use of data mining techniques to effectively detect malicious activity in an enterprise network. The results of many of these projects have demonstrated that these techniques can be effective when trained/calibrated using labelled datasets. Labelled datasets identify and characterize normal and malicious traffic for use in training/calibrating the detection sensor. However, the creation of labelled datasets is resource intensive. It requires a significant effort by security analysts to create a data set that characterises the traffic in a specific enterprise network environment. This research simulates and analyses malicious activity on an enterprise network to explore the detection of malicious activity with data mining techniques using unlabelled datasets. Semi-discrete decomposition (SDD) is used as a clustering and outlier analysis technique to characterize network traffic as either normal or anomalous. 1...|$|R
40|$|The four LHC {{experiments}} at CERN {{have decided}} to use a commercial SCADA (Supervisory Control And Data Acquisition) product for the supervision of their DCS (Detector Control System). The selected SCADA, which is therefore used for the CMS DCS, is PVSS II from the company ETM. This SCADA has its own database, which is suitable for storing conventional controls data such as voltages, temperatures and pressures. In addition, calibration data and FE (Front-End) electronics configuration need to be stored. The amount of these data is too large to be stored in the SCADA database [1]. Therefore an external database {{will be used for}} managing such data. However, this database should be completely integrated into the SCADA framework, it should be accessible from the SCADA and the SCADA features, e. g. <b>alarming,</b> <b>logging</b> should be benefited from. For prototyping, Oracle 8 i was selected as the external database manager. The development of the control system for calibration constants and FE electronics configuration has been done in close collaboration with the CMS tracker group and JCOP (Joint COntrols Project) (1). (1) The four LHC experiments and the CERN IT/CO group has merged their efforts to build the experiments controls systems and set up the JCOP at the end of December, 1997 for this purpose. Comment: 3 pages, 4 figures, Icaleps' 01 conference PSN WEDT 00...|$|R
40|$|The new {{cryogenics}} {{controls for}} LHC (UNICOS) are implemented {{in an open}} architecture based on SCADA and PLC industrial components, with Ethernet as Fieldnetwork. Its development was outsourced to industry and since mid- 2001 several applications have been produced and delivered for refrigerators in the accelerator and experiment domains. This has allowed to validate detailed performance requirements in terms of communication and distributed architecture. The second phase of this project will involve its integration with the LHC accelerator controls, both at the information exchange level (<b>alarms,</b> data <b>logging)</b> and at the device configuration level. This phase {{takes advantage of the}} integrated design a...|$|R
40|$|Learning {{from our}} {{experience}} with the Experimental Physics and Industrial Control System (EPICS) alarm handler (ALH) {{as well as a}} functionally similar approach based on script-generated operator screens, we developed the Best Ever Alarm System Toolkit (BEAST). It is based on Java and Eclipse on the Control System Studio (CSS) platform, using a relational database (RDB) to store the configuration and to log actions. It employs the Java Message Service (JMS) for communication between the modular pieces of the toolkit, which include an Alarm Server to maintain the current alarm state, an arbitrary number of Alarm Client user interfaces (GUI), and tools to annunciate <b>alarms</b> or <b>log</b> <b>alarm</b> related actions. Web reports allow us to monitor the alarm system performance and spot deficiencies in the alarm configuration. The Alarm Client GUI not only gives the end users various ways to view alarms in tree and table format, but also makes it easy to access guidance information, related operator displays and other CSS tools. It also allows the alarm configuration to be modified online from the GUI. Coupled with a good "alarm philosophy " on how to provide useful alarms, we can finally improve the configuration to achieve an effective alarm system...|$|R
50|$|Security Electric Fences are {{electric}} fences constructed using {{specialised equipment}} and built for perimeter security {{as opposed to}} animal management. Security electric fences consist of wires that carry pulses of electric current to provide a non-lethal shock to deter potential intruders. Tampering with the fence also results in an <b>alarm</b> that is <b>logged</b> by the security electric fence energiser, and can also trigger a siren, strobe, and/or notifications to a control room or directly to the owner via email or phone.|$|R
40|$|Oil and gas {{industries}} need {{secure and}} cost-effective alarm systems to meet safety requirements {{and to avoid}} problems that lead to plant shutdowns, production losses, accidents and associated lawsuit costs. Although most current distributed control systems (DCS) collect and archive <b>alarm</b> event <b>logs,</b> the extensive quantity and complexity of such data make identification of the problem a very labour-intensive and time-consuming task. This paper proposes a data mining approach {{that is designed to}} support alarm rationalization by discovering correlated sets of alarm tags. The proposed approach was initially evaluated using simulation data from a Vinyl Acetate model. Experimental results show that our novel approach, using an event segmentation and data filtering strategy based on a cross-effect test is significant because of its practicality. It has the potential to perform meaningful and efficient extraction of alarm patterns from a sequence of alarm events...|$|R
40|$|This paper {{describes}} the "R'eseau Fut'e (Smart Net) " project whose {{aim is to}} introduce DAI and Multi-Agent techniques in network management and supervision, {{in order to help}} the processing of the large volume of alarms and various event notifications received by network management platforms. Actually, many of these alarms prove to have a user-depending utility and have to be filtered. We have chosen a Chronicle model in order to incorporate temporal reasoning in our experimental platform. Thus some of the tasks (<b>alarm</b> filtering, <b>log</b> recording, fault detection [...] .) can be automated via a chronicle recognition system, letting the supervision operator focus on more important tasks. Although it is possible to have a model-based approach, we will assume {{that we do not have}} a complete knowledge of the network, and that the model can evolve quickly...|$|R
40|$|Preventative {{maintenance}} {{is a key}} consideration for equipment manufacturers. In industries such as mining, oil & gas and rail, the site operators prioritise minimising disruption caused by downtime which leads to significant losses in terms of revenue and damage to reputation. Ensuring equipment is healthy is therefore a major concern for all stakeholders to ensure continued reliable operation of a site. Current methods of delivering such diagnostics typically form part of a SCADA suite which takes a site-wide approach to displaying information. While correct use of these suites has shown to bring benefits to both customer and supplier, {{it can be argued}} that they are not suitable for customers with small scale implementations, especially given their expensive nature and difficulty to configure. SCADA systems are also prone to being ineffective when troubleshooting low-level equipment related problems, especially in scenarios where automated equipment is deployed in remote sites for extended periods. In such cases, service engineers report scenarios where <b>alarm</b> <b>logs</b> were too full to effectively analyse and draw meaningful conclusions from. The aim of this project is to design and develop a solution that delivers enhanced product support through diagnostics and preventative maintenance. A graphical interface will be developed for engineers that displays technical information about equipment, aiding the troubleshooting process and reducing time spent on-site. A report-based graphical interface will cater for non-technical customers, providing an intuitive display of how healthy the system is. The report will also provide advice to aid with decision making when equipment is not being used optimally or is approaching the end of its life. Equipment manufacturers can take advantage of the solution to improve relationships with existing customers, appeal to new customers and generate a new revenue stream through enhanced support programmes. The solution is designed to recognise that continued site operation is of paramount importance for a customer. Production environments impose stringent safety restrictions which restricts invasive access to equipment when it is operating. A non-invasive wireless access mechanism is therefore a key requirement to ensure that downtime is minimised...|$|R
40|$|Current network {{security}} tools generally lack sufficient context for maintaining a well informed and proactive defense posture. Vulnerabilities are usually assessed in isolation, without considering how {{they contribute to}} overall attack risk. Similarly, intrusion <b>alarms</b> are <b>logged</b> as isolated events, with limited correlation capabilities. Security professionals are overwhelmed by constant threats, complexity of security data, and network growth. Our approach to network defense applies attack graphs for advanced vulnerability analysis and intrusion detection. Attack graphs map paths of vulnerability, showing how attackers can incrementally penetrate a network. We can then identify critical vulnerabilities and provide strategies for protection of critical network assets. Because of operational constraints, vulnerability paths may often remain. The residual attack graph then guides optimal intrusion detection and attack response. This includes optimal placement of intrusion detection sensors, correlating intrusion alarms, accounting for missed detections, prioritizing alarms, and predicting next possible attack steps. 1...|$|R
50|$|The human-machine {{interface}} (HMI) is the operator {{window of the}} supervisory system. It presents plant information to the operating personnel graphically {{in the form of}} mimic diagrams, which are a schematic representation of the plant being controlled, and <b>alarm</b> and event <b>logging</b> pages. The HMI is linked to the SCADA supervisory computer to provide live data to drive the mimic diagrams, alarm displays and trending graphs. In many installations the HMI is the graphical user interface for the operator, collects all data from external devices, creates reports, performs alarming, sends notifications, etc.|$|R
40|$|A {{number of}} recent data mining {{techniques}} have been targeted especially {{for the analysis of}} sequential data. Traditional examples of sequential data involve telecommunication <b>alarms,</b> Www <b>log</b> files, user action registration for Hci studies, or any other series of events consisting of an event type and a time of occurrence. Text can also be seen as sequential data, in many respects similar to the data collected by sensors, or other observation systems. Traditionally, texts have been analysed using various information retrieval related methods, such as full-text analysis, and natural language processing. However, only few examples of data mining in text, particularly in full text, are available. In this paper we show that general data mining methods are applicable to text analysis tasks under certain conditions. Moreover, we present a general framework for text mining. The framework follows the general Kdd process, thus containing steps from preprocessing to the utilization of the results [...] ...|$|R
40|$|Modern {{experiments}} in high energy physics {{conducted in the}} Large Hadron Collider in CERN are incredibly complex. Measurements in these experiments require many different and advanced systems, integrated in complicated machines called detectors. ATLAS is a general purpose detector at the LHC. Such an elaborate machine requires a sophisticated control system to allow users to control and monitor its performance. This system, called the ATLAS Detector Control System (DCS), regularly logs information regarding the various subsystems, such as system information coming from DCS servers and software tools. It also notifies users about any malfunctions in the detectors software or hardware using <b>alarms.</b> Accessing <b>log</b> information and <b>alarms</b> efficiently may help detect problem more easily, increase {{our understanding of the}} various systems and even help predict and prevent future problems. DCS Data miner (DDM) is an application created using a tool called Splunk, in order to make data mining of <b>log</b> and <b>alarm</b> information easy and efficient...|$|R
50|$|Security {{electric}} fences {{consist of}} wires that carry pulses of electric current {{to provide a}} non-lethal shock to deter potential intruders. Tampering with the fence also results in an <b>alarm</b> that is <b>logged</b> by the security electric fence energiser, and can also trigger a siren, strobe, and/or notifications to a control room or directly to the owner via email or phone. In practical terms, security electric fences are a type of sensor array {{that acts as a}} (or part of a) physical barrier, a psychological deterrent to potential intruders, and as part of a security alarm system.|$|R
40|$|Complex {{industrial}} {{processes such as}} nuclear power plants, chemical plants and petroleum refineries are usually equipped with alarm systems capable of monitoring thousands of process variables and generating {{tens of thousands of}} alarms which are used as mechanisms for alerting operators to take actions to alleviate or prevent an abnormal situation. Overalarming and a lack of configuration management practices have often led to the degradation of these alarm systems, resulting in operational problems such as the Three-Mile Island accident. In order to aid alarm rationalization, this paper proposed an approach that incorporates a context-based segmentation approach with a data mining technique to find a set of correlated alarms from historical <b>alarm</b> event <b>logs.</b> Before the set of extracted results from this automated technique are used they can be evaluated by a process engineer with process understanding. The proposed approach is evaluated initially using simulation data from a Vinyl Acetate model. The approach is cost effective as any manual alarm analysis of the event logs for identifying primary and consequential alarms could be very time and labour intensive...|$|R
40|$|The UNICOS {{industrial}} controls framework, initially {{designed for}} LHC cryogenics controls {{on top of}} the PVSS-II SCADA system, is being successfully deployed for several other projects based on different architectures. This includes a variety of front-end systems (multiple PLC and VME solutions), communication methods and device models. In addition to the reuse of components and tools allowing fast development for the hardware commissioning phase and ensuring coherence between front-end and supervision process variables, this choice guarantees common HMI standards and will thus facilitate their use by the operation team. These projects benefit of the already developed integration with LHC accelerator central facilities (<b>alarms</b> and data <b>logging)</b> ...|$|R
40|$|Abstract. The ALMA Common Software (ACS) is an {{application}} framework {{designed to provide}} a common and homogeneous software architecture and infrastructure, spanning the end to end needs of an Astronomical observatory, from the Telescope Control system to high-level data flow management. ACS offers, at the lower level, several basic services needed for object-oriented distributed computing like transparent remote object invocation, object deployment and location, dis-tributed error, <b>alarm</b> handling, <b>logging</b> and events. On top of this it provides {{an application}} architecture based on the Component/Container paradigm that fosters sharing and reusing of software components. Although developed for the ALMA project, ACS is now used by several other projects worldwide, among which the Italian Sardinia Radio Telescope (SRT). Besides, there is an active community that shares ideas, concepts and actual software components. Major drivers for this diffusion were the choice of adopting the LGPL public license and the adoption of CORBA, a free but reliable and widely used middleware software. In this paper we present an overview of the main features of ACS, emphasizing in particular the role of INAF-OAT in this project. Key words. CORBA, common software, middleware, object-oriente...|$|R
40|$|In this {{implementation}} of Defense securitysystems. When {{a person or}} motor vehicle enters amonitored area, PIR motion detectors are commonly {{used in conjunction with}} different parts of the war field. Whensomeone enters secured places, immediately it will sendan indication to the control room section through wirelesscommunication and is indicated to the control roomthrough alarm [1]. The concerned people can understandthat an eventuality has happened in the host section. At thesame time web camera connected to the microcontrollerkeeps on capturing what is going on there at the host place and saves it into the computer. When the security peoplein supervisory room, get an indication to the host sectionby <b>alarm,</b> they <b>log</b> into the host section computer throughwireless LAN, and view all information of the war fieldsection images by PC and can operate the weapons if theentered people were opponent person. Sectors based on PIR detectors, ultrasonic sensors and also communicate to theControl room through wireless communication by meansof encrypted data and then from the control room theycan able to monitor what’s happening in the war field and supervise from the control room itself when signal is senton detection of human by pir sensors a...|$|R
40|$|The new ELETTRA {{alarm system}} {{is a set of}} {{programs}} used to <b>log</b> <b>alarm</b> events, report them to control room operators and feed them to analysis programs. The design of the new alarm system is based on an object oriented distributed architecture with an extend client/server communication model; moreover it has the added constraint of supporting the old RPC based alarm delivery system. The new system, written almost entirely in C++, shows that the object oriented paradigm is a natural choice for building event driven programs and {{that it is possible to}} encapsulate RPC based servers into C++ classes. The Motif graphical user interface is also written in C++ and is based on the well known concept of component b...|$|R
40|$|The {{functional}} requirements for {{that part of}} the Technical Area (TA) - 55 Operations Center Upgrade Project that involves the human-system interface (HSI) are described in this document. The upgrade project seeks to replace completely the center`s existing computerized data acquisition and display system, which consists of the field multiplexer units, Data General computer systems, and associated peripherals and software. The upgrade project has two parts-the Facility Data Acquisition Interface System (FDAIS) and the HSI. The HSI comprises software and hardware to provide a high-level graphical operator interface to the data acquisition system, as well as data archiving, <b>alarm</b> annunciation, and <b>logging.</b> The new system will be built with modern, commercially available components; it will improve reliability and maintainability, and it can be expanded for future needs...|$|R
