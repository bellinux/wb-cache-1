107|476|Public
5000|$|... #Caption: Areas of {{localization}} on lateral {{surface of}} hemisphere. Motor area in red. Area of general sensations in blue. <b>Auditory</b> <b>area</b> in green. Visual area in yellow.|$|E
50|$|Studies {{suggest that}} {{individuals}} {{are capable of}} automatically detecting a difference or anomaly in a melody such as an out of tune pitch which does not fit with their previous music experience. This automatic processing occurs in the secondary auditory cortex. Brattico, Tervaniemi, Naatanen, and Peretz (2006) performed one such study {{to determine if the}} detection of tones that do not fit an individual's expectations can occur automatically. They recorded event-related potentials (ERPs) in nonmusicians as they were presented unfamiliar melodies with either an out of tune pitch or an out of key pitch while participants were either distracted from the sounds or attending to the melody. Both conditions revealed an early frontal negativity independent of where attention was directed. This negativity originated in the auditory cortex, more precisely in the supratemporal lobe (which corresponds with the secondary auditory cortex) with greater activity from the right hemisphere. The negativity response was larger for pitch that was out of tune than that which was out of key. Ratings of musical incongruity were higher for out of tune pitch melodies than for out of key pitch. In the focused attention condition, out of key and out of tune pitches produced late parietal positivity. The findings of Brattico et al. (2006) suggest that there is automatic and rapid processing of melodic properties in the secondary auditory cortex. The findings that pitch incongruities were detected automatically, even in processing unfamiliar melodies, suggests that there is an automatic comparison of incoming information with long term knowledge of musical scale properties, such as culturally influenced rules of musical properties (common chord progressions, scale patterns, etc.) and individual expectations of how the melody should proceed. The <b>auditory</b> <b>area</b> processes the sound of the music. The <b>auditory</b> <b>area</b> is located in the temporal lobe. The temporal lobe deals with the recognition and perception of auditory stimuli, memory, and speech (Kinser, 2012).|$|E
50|$|Speech mapping (also {{known as}} output-based measures) {{involves}} testing with a speech or speech-like signal. The hearing aid is adjusted {{so that the}} speech is amplified to the approximate middle of the patient's residual <b>auditory</b> <b>area</b> (the amplitude range between the patient's hearing threshold and upper limit of comfort) while observing a real-time spectrum display of the speech in the patient's ear canal. Many multi-channel hearing aids allow each frequency channel to be adjusted separately. The aim {{is to find a}} good compromise between intelligibility and loudness discomfort. This approach to hearing aid testing is implemented in most current real ear systems {{and there has been a}} significant increase in audiologists selecting to verify using the output method. Using a real speech signal to test a hearing aid has the advantage that features that may need to be disabled in other test approaches can be left active, and the effects of these features in normal use are included in the test.|$|E
50|$|In <b>auditory</b> <b>areas,</b> {{the primary}} map is tonotopic. Sounds are parsed {{according}} to frequency (i.e., high pitch vs. low pitch) by subcortical <b>auditory</b> <b>areas,</b> and this parsing is {{reflected by the}} primary auditory zone of the cortex. As with the visual system, {{there are a number}} of tonotopic cortical maps, each devoted to analyzing sound in a particular way.|$|R
40|$|Evidence {{from human}} and {{non-human}} primate studies supports a dual-pathway model of audition, with partially segregated cortical networks for sound recognition and sound localisation, {{referred to as}} the What and Where processing streams. In normal subjects, these two networks overlap partially on the supra-temporal plane, suggesting that some early-stage <b>auditory</b> <b>areas</b> are involved in processing of either auditory feature alone or of both. Using high-resolution 7 -T fMRI we have investigated the influence of positional information on sound object representations by comparing activation patterns to environmental sounds lateralised to the right or left ear. While unilaterally presented sounds induced bilateral activation, small clusters in specific non-primary <b>auditory</b> <b>areas</b> were significantly more activated by contra-laterally presented stimuli. Comparison of these data with histologically identified non-primary <b>auditory</b> <b>areas</b> suggests that the coding of sound objects within early-stage <b>auditory</b> <b>areas</b> lateral and posterior to primary auditory cortex AI is modulated by the position of the sound, while that within anterior areas is not...|$|R
40|$|The human primary {{auditory}} cortex (AI) {{is surrounded}} by several other <b>auditory</b> <b>areas,</b> which can be identified by cyto-, myelo- and chemoarchitectonic criteria. We report here on the pattern of calcium-binding protein immunoreactivity within these areas. The supratemporal regions of four normal human brains (eight hemispheres) were processed histologically, and serial sections were stained for parvalbumin, calretinin or calbindin. Each calcium-binding protein yielded a specific pattern of labelling, which differed between <b>auditory</b> <b>areas.</b> In AI, defined as area TC [see C. von Economo and L. Horn (1930) Z. Ges. Neurol. Psychiatr., 130, 678 - 757], parvalbumin labelling was dark in layer IV; several parvalbumin-positive multipolar neurons were distributed in layers III and IV. Calbindin yielded dark labelling in layers I-III and V; it revealed numerous multipolar and pyramidal neurons in layers II and III. Calretinin labelling was lighter than that of parvalbumin or calbindin in AI; calretinin-positive bipolar and bitufted neurons were present in supragranular layers. In non-primary <b>auditory</b> <b>areas,</b> the intensity of labelling tended to become progressively lighter while moving away from AI, with qualitative differences between the cytoarchitectonically defined areas. In analogy to non-human primates, our results suggest differences in intrinsic organization between <b>auditory</b> <b>areas</b> that are compatible with parallel and hierarchical processing of auditory information...|$|R
50|$|Thalamocortical axons project {{primarily}} from the Medial geniculate Body (MGB) via sublenticular region of the internal capsule and terminate in an organized topographic manner in the transverse temporal gyri of Heschl. MGBm radiations terminate in specific locations while TC fibers from the MGBv terminate in nonspecific clusters of cells and form collateral connections to neighboring cells. Research done by staining the brains of macaque monkeys reveals projections from the ventral nucleus mainly terminating in layers IV and IIIB, with some nonspecific clusters of PIR cells terminating in layers I, II, IIIA, and VI. Fibers from the dorsal nuclei were found to project more directly to the primary <b>auditory</b> <b>area,</b> with most axons terminating in layer IIIB. The magnocellular nucleus projected {{a small amount of}} PIR cells with axons mainly terminating in layer 1, though large regions of the middle cortical layers were innervated through collaterally connected CIR neurons. Past research suggests that the thalamocortical-auditory pathway may be the only neural correlate that can explain a direct translation of frequency information to the cortex via specific pathways.|$|E
50|$|Freezing of gait (FOG) {{is a major}} {{contributor}} of gait disturbances in Parkinson’s disease. There is impairment in controlling cadence that regulates stride to stride variations in gait timing and maintaining stable walking rhythm. It {{is a result of}} various factors with combination of Hypokinesia and sequence effect, severity and variability of sequence effect, severity of festination which depends on background level Hypokinesia, response to Hypokinesia to medications and the ability to focus on gait and visual cues, extrinsic environmental or attentional demands. There is a strong relation of Freezing of gait and turning. This involves reduced mediolateral deviation, a forward COM shift and decrease step width in freezers just before FOG episodes. These hamper fluent weight shifts required while turning. Cortical ChangesThe FOG is an outcome of dynamic process of hypo and hyper activation of cortical areas such as SMA and subcortical areas like striatum, mesencephalic locomotor region and pedunculopontine nucleus. Freezing of gait during turning and walking can be due to impaired cortical regulation of motor execution and reduced ability of mesencephalic structures to flexibly compensate for that alterations. Interhemispheric connection between bilateral parietal operculum, somatosensory cortex and primary <b>auditory</b> <b>area</b> are reduced in PD people with freezing of gait. Reorganization occurs in functional connections within the locomotor network to compensate loss of connectivity between STN and SMA and loss of lower order automatic control of gait by Basal Ganglia.|$|E
50|$|In a 2014 {{study by}} Thaler and colleagues, the {{researchers}} first made {{recordings of the}} clicks and their very faint echoes using tiny microphones placed in the ears of the blind echolocators as they stood outside and tried to identify different objects such as a car, a flag pole, and a tree. The researchers then played the recorded sounds back to the echolocators while their brain activity was being measured using functional magnetic resonance imaging. Remarkably, when the echolocation recordings were played back to the blind experts, {{not only did they}} perceive the objects based on the echoes, but they also showed activity in those areas of their brain that normally process visual information in sighted people, primarily primary visual cortex or V1. This result is surprising, as visual areas, as their names suggest, are only active during visual tasks. Most interestingly, the brain areas that process auditory information were no more activated by sound recordings of outdoor scenes containing echoes than they were by sound recordings of outdoor scenes with the echoes removed. Importantly, when the same experiment was carried out with sighted people who did not echolocate, these individuals could not perceive the objects and there was no echo-related activity anywhere in the brain. This suggests that the cortex of blind echolocators is plastic and reorganizes such that primary visual cortex, rather than any <b>auditory</b> <b>area,</b> becomes involved in the computation of echolocation tasks.|$|E
40|$|The {{generality}} {{of findings}} implicating secondary <b>auditory</b> <b>areas</b> in <b>auditory</b> imagery was tested {{by using a}} timbre imagery task with fMRI. Another aim was to test whether activity in supplementary motor area (SMA) seen in prior studies might have been related to subvocalization. Participants with moderate musical background were scanned while making similarity judgments about the timbre of heard or imagined musical instrument sounds. The critical control condition was a visual imagery task. The pattern of judgments in perceived and imagined conditions was similar, suggesting that perception and imagery access similar cognitive representations of timbre. As expected, judgments of heard timbres, relative to the visual imagery control, activated primary and secondary <b>auditory</b> <b>areas</b> with some right-sided asymmetry. Timbre imagery also activated secondary <b>auditory</b> <b>areas</b> relative to the visual imagery control, although less strongly, in accord with previous data. Significant overlap was observed in these regions between perceptual and imagery conditions. Because the visual control task resulted in deactivation of <b>auditory</b> <b>areas</b> relative to a silent baseline, we interpret the timbre imagery effect as a reversal of that deactivation. Despite {{the lack of an}} obvious subvocalization component to timbre imagery, some activity in SMA was observed, suggesting that SMA may have a more general role in imagery beyond any motor component...|$|R
40|$|AbstractFunctional and {{structural}} brain alterations {{in the absence}} of the auditory input have been described, but the observed structural brain changes in the deaf are not uniform. Some of the previous researchers focused only on the <b>auditory</b> <b>areas,</b> while others investigated the whole brain or other selected regions of interest. Majority of studies revealed decreased white matter (WM) volume or altered WM microstructure and preserved grey matter (GM) structure of the <b>auditory</b> <b>areas</b> in the deaf. However, preserved WM and increased or decreased GM volume of the <b>auditory</b> <b>areas</b> in the deaf have also been reported. Several structural alterations in the deaf were found also outside the <b>auditory</b> <b>areas,</b> but these regions differ between the studies. The observed differences between the studies could be due to the use of different single-analysis techniques, or the diverse population sample and its size, or possibly due to the usage of hearing aids by some participating deaf subjects. To overcome the aforementioned limitations four different image-processing techniques were used to investigate changes in the brain morphology of prelingually deaf adults who have never used hearing aids. GM and WM volume of the Heschl's gyrus (HG) were measured using manual volumetry, while whole brain GM volume, thickness and surface area were assessed by voxel-based morphometry (VBM) and surface-based analysis. The microstructural properties of the WM were evaluated by diffusion tensor imaging (DTI). The data were compared between 14 congenitally deaf adults and 14 sex- and age-matched normal hearing controls. Manual volumetry revealed preserved GM volume of the bilateral HG and significantly decreased WM volume of the left HG in the deaf. VBM showed increased cerebellar GM volume in the deaf, while no statistically significant differences were observed in the GM thickness or surface area between the groups. The results of the DTI analysis showed WM microstructural alterations between the groups in the bilateral <b>auditory</b> <b>areas,</b> including the superior temporal gyrus, the HG, the planum temporale and the planum polare, which were more extensive in the right hemisphere. Fractional anisotropy (FA) was significantly reduced in the right and axial diffusivity (AD) in the left <b>auditory</b> <b>areas</b> in the deaf. FA and AD were significantly reduced also in several other brain <b>areas</b> outside the <b>auditory</b> cortex in the deaf. The use of four different methods used in our study, although showing changes that are not directly related, provides additional information and supports the conclusion that in prelingually deaf subjects structural alterations are present both in the <b>auditory</b> <b>areas</b> and elsewhere. Our results support the findings of those studies showing that early deafness results in decreased WM volume and microstructural WM alterations in the <b>auditory</b> <b>areas.</b> As we observed WM microstructural alteration also in several other areas and increased GM volume in the cerebellum in the deaf, we can conclude that early deafness results in widespread structural brain changes. These probably reflect atrophy or degradation as well as compensatory cross-modal reorganisation {{in the absence of}} the auditory input and the use of the sign language...|$|R
50|$|Programs are {{broadcast}} in 10 languages to 8,000,000 Japanese and 50,000 foreigners. The <b>auditory</b> <b>areas</b> are Fukuoka/ Saga/ Kumamoto/ Oita/ Nagasaki 76.1 MHz, and Fukuoka nishi 82.5 MHz, {{a part of}} Yamaguchi/ Kitakyushu 82.7 MHz.|$|R
40|$|Retrograde tracers were {{injected}} {{in various}} parts of the neocortex of the porpoise (Phocoena phocoena). Labelled thalamic neurons were plotted in three-dimensional reconstructions. The lateral geniculate nucleus projects to the visually excitable part of the lateral gyrus. Ventral parts of the medial geniculate nucleus project to the <b>auditory</b> <b>area</b> of the suprasylvian gyrus, while dorsal medial geniculate projects to the 'secondary' <b>auditory</b> <b>area</b> of the ectosylvian gyrus and to the temporal operculum. The ventrobasal and ventropostero-inferior complex projects to cortex anterior to the suprasylvian <b>auditory</b> <b>area,</b> corresponding to somatosensory function. The main projection of the inferior pulvinar is to the suprasylvian gyrus, that of the medial pulvinar to the ectosylvian gyrus, and of the lateral pulvinar to the border of the lateral and suprasylvian gyri. The lateral and posterior complexes project to perisylvian cortex. Throughout the thalamus there is a rough topographic organisation. Lateral to medial through the thalamus represents progression from medial to lateral over the cortex from lateral gyrus to perisylvian cortex. Anterior in cortex is represented by anteroventral in thalamus, and posterior in cortex by posterodorsal in thalamus...|$|E
40|$|WOS: 000262258700003 International audienceDirect {{social contact}} and social {{interaction}} affect speech development in human infants and are required {{in order to}} maintain perceptual abilities; however the processes involved are still poorly known. In the present study, we tested the hypothesis that social segregation during development would prevent the proper development of a central <b>auditory</b> <b>area,</b> using a "classical" animal model of vocal development, a songbird. Based on our knowledge of European starling, we raised young female starlings with peers and only adult male tutors. This ensured that female would show neither social bond with nor vocal copying from males. Electrophysiological recordings performed when these females were adult revealed perceptual abnormalities: they presented a larger <b>auditory</b> <b>area,</b> a lower proportion of specialized neurons and a larger proportion of generalist sites than wild-caught females, whereas these characteristics were similar to those observed in socially deprived (physically separated) females. These results confirmed and added to earlier results for males, suggesting that the degree of perceptual deficiency reflects the degree of social separation. To our knowledge, this report constitutes the first evidence that social segregation can, as much as physical separation, alter the development of a central <b>auditory</b> <b>area...</b>|$|E
40|$|WOS: 000221750200018 International audienceAlthough {{evidence}} exists for a lateralization of song production, {{few studies have}} focused on the perceptual aspect of lateralization in songbirds. In the present study, the authors recorded neuronal responses to a variety of species-specific and artificial, nonspecific stimuli in both hemispheres of awake and anesthetized male starlings (Sturnus vulgaris). Recordings were made in the primary <b>auditory</b> <b>area</b> of the songbird brain, the Field L complex. The right hemisphere exhibited significantly more responsive units than the left hemisphere in awake birds, and this difference was significantly reduced in anesthetized birds. Furthermore, clear hemispheric specialization toward categories of behaviorally relevant stimuli and precise parameters of these stimuli were found, The main <b>auditory</b> <b>area</b> of the starling's brain thus appears to show some degree of lateralization...|$|E
40|$|In {{contrast}} to vision, where retinotopic mapping alone can define areal borders, primary <b>auditory</b> <b>areas</b> such as A 1 are best delineated by combining in vivo tonotopic mapping with postmortem cyto- or myeloarchitectonics {{from the same}} individual. We combined highresolution (800 �m) quantitative T 1 mapping with phase-encoded tonotopic methods to map primary <b>auditory</b> <b>areas</b> (A 1 and R) within the “auditory core ” of human volunteers. We first quantitatively characterize the highly myelinated auditory core in terms of shape, area, cortical depth profile, and position, with our data showing considerable correspondence to postmortem myeloarchitectonic studies, both in cross-participant averages and in individuals. The core region contains two “mirror-image ” tonotopic maps oriented along the same axis as observed in macaque and owl monkey. We suggest that these two maps within the core are the human analogs of primate <b>auditory</b> <b>areas</b> A 1 and R. The core occupies a much smaller portion of tonotopically organized cortex on the superior temporal plane and gyrus than is generally supposed. The multimodal approach to defining the auditory core will facilitate investigations of structure–function relationships, comparative neuroanatomical studies, and promises new biomarkers for diagnosis and clinical studies...|$|R
25|$|Positron {{emission}} tomography (PET) and functional {{magnetic resonance imaging}} (fMRI) show that musical hallucinations activate a wide variety of areas in the brain including the following: <b>auditory</b> <b>areas,</b> motor cortex, visual areas, basal ganglia, brainstem, pons, tegmentum, cerebellum, hippocampi, amygdala, and peripheral auditory system.|$|R
40|$|While {{advances}} in {{magnetic resonance imaging}} (MRI) throughout the last decades have enabled the detailed anatomical and functional inspection {{of the human brain}} non-invasively, to date there is no consensus regarding the precise subdivision and topography of the areas forming the human auditory cortex. Here, we propose a topography of the human <b>auditory</b> <b>areas</b> based on insights on the anatomical and functional properties of human <b>auditory</b> <b>areas</b> as revealed by studies of cyto- and myelo-architecture and fMRI investigations at ultra-high magnetic field (7 Tesla). Importantly, we illustrate that - whereas a group-based approach to analyze functional (tonotopic) maps is appropriate to highlight the main tonotopic axis - the examination of tonotopic maps at single subject level is required to detail the topography of primary and non-primary areas that may be more variable across subjects. Furthermore, we show that considering multiple maps indicative of anatomical (i. e. myelination) as well as of functional properties (e. g. broadness of frequency tuning) is helpful in identifying <b>auditory</b> cortical <b>areas</b> in individual human brains. We propose and discuss a topography of areas that is consistent with old and recent anatomical post mortem characterizations of the human auditory cortex and that may serve as a working model for neuroscience studies of auditory functions...|$|R
40|$|International audienceDirect {{social contact}} and social {{interaction}} affect both speech development in human infants and song learning in songbirds, and are required {{in order to}} maintain perceptual abilities. However, the processes involved are still poorly known. In the present study, we tested the hypothesis that social withdrawal would prevent the proper development of a central <b>auditory</b> <b>area,</b> using an established animal model of vocal development, a songbird. Based on our knowledge of European starlings' vocal behaviour and development, we raised young female starlings with peers and adult male tutors only. This ensured that these females would show neither social bond with nor vocal copying from males. Electrophysiological recordings performed when these females were adult revealed perceptual abnormalities: they presented a larger <b>auditory</b> <b>area,</b> a lower proportion of specialized neurons and a larger proportion of generalist sites than wild-caught females, whereas these characteristics were similar to those observed in socially deprived (physically isolated) females. These results confirmed, and added to, earlier results for males, suggesting that the degree of perceptual deficiency reflects the degree of social withdrawal. To our knowledge, this report constitutes the first evidence that the lack of social interactions can, as much as physical separation, alter the development of a central <b>auditory</b> <b>area...</b>|$|E
40|$|The {{understanding}} of the functions of a certain portion of the cortex ultimately is dependent on {{a knowledge of the}} connections or interrelationships of that particular cortex. Consequently, the visual cortex and the <b>auditory</b> <b>area</b> are better understood because of the works of Poliak (1932), Talbot (1942), Talbot, Woolsey and Thompson (1946), and of Walker (1937 a, 1937 b), of Ades and Felder (1942, 1945), Ades (1943), Woolsey and Walzl (1942), Walzl and Woolsey (1943), Tunturi (1944, 1945), Rose (1949), and Rose and Woolsey (1949) ...|$|E
40|$|The {{localization}} of {{the primary}} auditory cortex in man was studied by direct recordings in 150 different sites in the superior transverse gyrus, especially in Heschl's gyms and the planum temporale. The distribution {{of the primary}} evoked responses (N 13 /P 17 /N 26) was studied in 15 epileptic patients who were candidates for surgical treatment. Precise topography of recording sites was determined stereotactically. Our results provide evidence for considering only a restricted portion of Heschl's gyrus (its posteromedial part) as the primary <b>auditory</b> <b>area...</b>|$|E
2500|$|Studies {{utilizing}} positron {{emission tomography}} (PET) have found during tasks that invoke disfluent speech, people who stutter show hypoactivity in cortical areas associated with language processing, such as Broca's area, but hyperactivity in areas associated with motor function. [...] One such study that evaluated the stutter period {{found that there was}} over activation in the cerebrum and cerebellum, and relative deactivation of the left hemisphere <b>auditory</b> <b>areas</b> and frontal temporal regions.|$|R
40|$|Currently it is {{discussed}} whether the same cortical areas are activated during {{the imagination of}} as during the actual presentation of specific stimuli. Some argue that mostly the secondary but not the primary sensory areas are active during imagination. Using {{functional magnetic resonance imaging}} we explored whether auditory verbal imagery of syllables has sufficient power to evoke haemodynamic responses in the auditory cortex. To overcome the detrimental effects of scanner noise, one group of subjects was trained to vividly imagine hearing a syllable while a flashlight was presented. A control group did not receive this training. We found that only the trained group revealed haemodynamic responses in the auditory cortex during auditory imagination while the control group showed no activation within the auditory cortex. Peak activations during auditory verbal imagery are located bilaterally within the superior temporal gyrus region {{in the vicinity of the}} planum temporale. While these secondary <b>auditory</b> <b>areas</b> are active during auditory verbal imagery, there was no activation in Heschl's gyrus. We hypothesize that auditory verbal imagery is associated with haemodynamic responses in secondary auditory and not primary <b>auditory</b> <b>areas...</b>|$|R
40|$|Everyday, {{humans and}} animals {{navigate}} complex acoustic environments, where multiple sound sources overlap. Somehow, they effortlessly perform an acoustic scene analysis and extract relevant signals from background noise. Constant updating of the behavioral relevance of ambient sounds requires the representation and integration of incoming acoustical information with internal representations such as behavioral goals, expectations and memories of previous sound-meaning associations. Rapid plasticity of auditory representations may contribute to our ability to attend and focus on relevant sounds. In order to better understand how auditory representations are transformed in the brain to incorporate behavioral contextual information, we explored task-dependent plasticity in neural responses recorded at four levels of the auditory cortical processing hierarchy of ferrets: the primary auditory cortex (A 1), two higher-order <b>auditory</b> <b>areas</b> (dorsal PEG and ventral-anterior PEG) and dorso-lateral frontal cortex. In one study we explored the laminar profile of rapid-task related plasticity in A 1 and found that plasticity occurred at all depths, but was greatest in supragranular layers. This result suggests that rapid task-related plasticity in A 1 derives primarily from intracortical modulation of neural selectivity. In two other studies we explored task-dependent plasticity in two higher-order areas of the ferret auditory cortex that may correspond to belt (secondary) and parabelt (tertiary) <b>auditory</b> <b>areas.</b> We found that representations of behaviorally-relevant sounds are progressively enhanced during performance of auditory tasks. These selective enhancement effects became progressively larger as you ascend the auditory cortical hierarchy. We also observed neuronal responses to non-auditory, task-related information (reward timing, expectations) in the parabelt area that were very similar to responses previously described in frontal cortex. These results suggests that auditory representations in the brain are transformed from the more veridical spectrotemporal information encoded in earlier auditory stages to a more abstract representation encoding sound behavioral meaning in higher-order <b>auditory</b> <b>areas</b> and dorso-lateral frontal cortex...|$|R
40|$|International audienceCategorization is {{essential}} to all cognitive processes, but identifying the neural substrates underlying categorization processes is a real challenge. Among animals that {{have been shown to}} be able of categorization, songbirds are particularly interesting because they provide researchers with clear examples of categories of acoustic signals allowing different levels of recognition, and they possess a system of specialized brain structures found only in birds that learn to sing: the song system. In this study, we demonstrate that the activity of a songbird's non-primary, associative <b>auditory</b> <b>area</b> can indicate or represent classes of sounds corresponding to behaviourally-defined recognition processes. This <b>auditory</b> <b>area</b> has been compared to the superficial layers of auditory cortex or to secondary mammalian auditory regions such as the lateral belt in primates or Wernicke's area in humans. By showing differential representation of sounds with distinct biological significance (as observed in the field), as seen in higher-order fields of the auditory cortex of mammals, including humans, our study actually reinforce the parallel between these structures, and contribute to widen the impact of studies on songbirds. Moreover, given the many parallels that exist between birdsong and speech, we believe our results may contribute to a better understanding of the neural bases of speech...|$|E
40|$|WOS: 000234184700008 International audienceRecent {{literature}} on the Field L of songbirds, showing that some neurons present a clear selectivity towards complex sounds, especially conspecific songs, is reviewed. Furthermore, studies on European starlings have revealed a complex functional organization in this central <b>auditory</b> <b>area,</b> with subareas exhibiting different response features. Interestingly, both the functional organization and the neuronal specialization can be drastically affected by early deprivation, clearly showing {{the existence of a}} developmental plasticity. Some recovery seems to remain possible at later stages, and social factors may be involved...|$|E
40|$|The NCM, {{a region}} of the higher <b>auditory</b> <b>area</b> in avian telencephalon, is a site of gene {{expression}} when stimulated with conspecific songs. We used cardiac response to characterize the process related to song perception in Bengalese finches. Song playback evoked an increased heart rate, but repeated exposure to one song resulted in habituation. Habituation did not occur, however, when exposed to series of unique songs in females, but not in males. Lesioning NCM in females completely abolished this sex specific cardiac response. This is the first demonstration that the NCM is involved in auditory memory at behavioral level...|$|E
40|$|H(2) (15) O-PET {{was used}} to {{investigate}} changes in regional cerebral blood flow in response to auditory stimulation in patients in the vegetative state. Five patients in a vegetative state of hypoxic origin were compared with 18 age-matched controls. In addition, the cerebral metabolism of these patients and 53 age-matched controls was studied using [(18) F]fluorodeoxyglucose. In control subjects, auditory click stimuli activated bilateral <b>auditory</b> cortices [Brodmann <b>areas</b> (BA) 41 and 42] and the contralateral auditory association cortices (BA 22). In the patients, although resting metabolism was decreased to 61 % of normal values, bilateral <b>auditory</b> <b>areas</b> 41 and 42 showed activation {{as seen in the}} controls, but the temporoparietal junction cortex (BA 22) failed to be activated. Moreover, the auditory association cortex was functionally disconnected from the posterior parietal association area (BA 40), the anterior cingulate cortex (BA 24) and the hippocampus, as revealed by psychophysiological interaction analysis. Thus, despite altered resting metabolism, the auditory primary cortices were still activated during external stimulation, whereas hierarchically higher-order multi- modal association areas were not. Such a cascade of functional disconnections along the auditory cortical pathways, from the primary <b>auditory</b> <b>areas</b> to multimodal and limbic areas, suggests that the residual cortical processing observed in the vegetative state cannot lead to the integrative processes that are thought to be necessary for the attainment of the normal level of awareness. Peer reviewe...|$|R
40|$|This thesis {{focuses on}} audiotactile integration, brain areas {{activated}} by vibrotactile stimulation, transfer of vibrotactile information to motor output, and reactivity {{of the human}} primary motor and somatosensory cortices in action observation. Human experience {{of the outside world}} results from integration of information obtained simultaneously via multiple senses. Accumulating evidence, from studies in both primates and humans, suggests that integration between different sensory modalities also occurs at early stages of cortical processing, in areas classically considered as purely unisensory. In Study I we studied integration between auditory and somatosensory systems. We showed, in a loudness-matching task, that subjects chose lower intensities for the probe than for the reference tone, when auditory and vibrotactile stimuli were presented simultaneously. In Studies II and III we explored brain areas involved in processing vibrotactile and tactile information, respectively. We showed that, besides primary and secondary somatosensory <b>areas,</b> <b>auditory</b> <b>areas</b> are also activated. In Study II we characterized the time course of brain activations and showed convergence of vibrotactile information to <b>auditory</b> <b>areas.</b> On the other hand, in Study III we identified, with good spatial accuracy, common neural substrates that process auditory and tactile information in <b>auditory</b> belt <b>areas.</b> In Study IV we assessed whether frequency information transfers from touch to vocal utterance in normal-hearing female adults. We demonstrated that such information transfer occurs clearly between 150 – 400  Hz. Based on findings in Studies II and III, we hypothesized that this transfer may involve at least primary and secondary somatosensory and <b>auditory</b> <b>areas.</b> Our social skills rely on the capability to understand others. In the human brain, the mirror-neuron system matches observation and execution of actions. This system comprises at least the inferior frontal gyrus, premotor areas, primary motor cortex, and the inferior parietal lobule. In Study V we investigated similarities in sensorimotor oscillatory activity between own, observed, and heard actions. We demonstrated that the primary motor cortex is activated before own and observed actions and stabilizes similarly. We also showed that rhythmic activity in the primary somatosensory cortex recovers later during own actions, which may be related to proprioceptive input and contribute to maintaining the sense of agency. reviewe...|$|R
40|$|According to the {{asymmetric}} sampling in time hypothesis, {{the left}} auditory cortex processes stimuli using a short temporal integration window (~ 25 – 50 ms), whereas the right auditory cortex processes stimuli using a long temporal integration window (~ 200 ms). We examined N 1 and T-complex {{responses to the}} second tone of tone-pairs presented with inter-stimulus intervals (ISIs) of 50 and 200 ms. Twenty-seven undergraduate students were presented with stimuli binaurally whilst the EEG was recorded. N 1 and Ta responses were symmetric between hemispheres, with responses elicited by the second tone of the 50 ms ISI tone-pairs. Tb responses to the second tones were significantly attenuated over the right hemisphere {{when compared to the}} left hemisphere for the 50 ms ISI tone-pairs, but returned to similar amplitudes in the 200 ms condition. Our results suggest that temporal integration windows of the left and right primary <b>auditory</b> <b>areas</b> are symmetric whereas those of the left and right secondary <b>auditory</b> <b>areas</b> are asymmetric. These findings are consistent with the asymmetric sampling in time hypothesis and provide justification for further investigation of the involvement of temporal integration in higher order auditory processes...|$|R
40|$|The {{standard}} general {{linear model}} (GLM) for rapid event-related fMRI design protocols typically ignores reduction in hemodynamic responses in successive stimuli in a train due to incomplete {{recovery from the}} preceding stimuli. To capture this adaptation effect, we incorporate a region-specific adaptation model into GLM. The model quantifies the rate of adaptation across brain regions, which is of interest in neuroscience. Empirical evaluation of the proposed model demonstrates its potential to improve detection sensitivity. In the fMRI experiments using visual and auditory stimuli, we observed that the adaptation effect is significantly stronger in the visual area than in the <b>auditory</b> <b>area,</b> suggesting that we must account for this effect to avoid bias in fMRI detection. ...|$|E
40|$|The {{present study}} {{examined}} cerebral representations of Japanese {{long and short}} vowel categories with near-infrared spectroscopy (NIRS) by measuring the hemodynamic changes. Results showed that NIRScould capture phoneme-speci¢c information. The {{left side of the}} <b>auditory</b> <b>area</b> showed large hemodynamic changes only for contrasting stimuli between which the phonemic boundary was estimated, but not for stimuli di¡ering by an equal duration but belonging to the same phoneme category. Left dominance in phoneme processing was also con¢rmed for the across-category stimuli. These ¢ndings indicate that the Japanese vowel contrast based only on duration di¡erences is dealt with in the same language-dominant hemisphere as other spectrally varying phonemic categories, and that the cortical activities related to its processing can be detected with NIRS. NeuroReport 13 : 581 ^ 58...|$|E
40|$|The {{present study}} was {{undertaken}} to trace the thalamic projections to the second and fourth somesthetic areas in the anterior ectosylvian gyrus of the cat using the technique of retrograde axonal transport of horseradish peroxidase. The projections of the posterolateral and posteromedial ventral nuclei (VPL, VPM) to the second somesthetic area (SⅡ) are organized somatotopically. The posterior portion of SⅡ (hindlimb area) receives fibers largely from the dorsolateral part of VPL, the middle portion of SⅡ (forelimb area) from the ventromedial part of VPL, and the anterior portion of SⅡ(face area) from VPM. These topical projections are more loosely organized and less densely arranged than those to the first somesthetic area (SI). The SⅡ receives a few fibers from the medial geniculate nucleus, particularly its magnocellular and dorsal principal parts, and from the suprageniculate nucleus. The posterior part of SⅡ near the secondary <b>auditory</b> <b>area</b> receives many fibers from the medial geniculate and suprageniculate nuclei, {{and only a few}} fibers from the lateral central and paracentral nuclei. The fourth somesthetic area (SIV), located in the dorsal bank of the anterior ectosylvian sulcus, receives fibers mainly from the dorsal principal and magnocellular parts of the medial geniculate nucleus, and from the suprageniculate nucleus. The SIV receives a few fibers from VPL and VPM in a somatotopical manner. The posterior portion of SIV receives fibers mainly from the dorsolateral part of VPL, the middle portion of SIV from the ventromedial part of VPL, and the anterior portion from VPM. In addition, SIV receives a few fibers from the lateral central, paracentral, ventral lateral and ventral medial nuclei. The SIV, together with the most posterior part of SⅡ, forms an <b>auditory</b> <b>area,</b> receiving many fibers from the medial geniculate and suprageniculate nuclei...|$|E
40|$|Environmental {{sounds are}} highly complex stimuli whose {{recognition}} {{depends on the}} inter-action of top-down and bottom-up processes in the brain. Their semantic representations were shown to yield repetition suppression effects, i. e. a decrease in activity during expo-sure to a sound that is perceived as belonging to the same source as a preceding sound. Making use of the high spatial resolution of 7 T fMRI we have investigated the representa-tions of sound objects within early-stage <b>auditory</b> <b>areas</b> on the supratemporal plane. The primary auditory cortex was identified by means of tonotopic mapping and the non-primary areas by comparison with previous histological studies. Repeated presentations of different exemplars of the same sound source, {{as compared to the}} presentation of different sound sources, yielded significant repetition suppression effects within a subset of early-stage areas. This effect was found within the right hemisphere in primary areas A 1 and R as well as two non-primary areas on the antero-medial part of the planum temporale, and within the left hemisphere in A 1 and a non-primary area on the medial part of Heschl’s gyrus. Thus, several, but not all early-stage <b>auditory</b> <b>areas</b> encode the meaning of environmental sounds...|$|R
40|$|We studied {{possible}} brain {{changes with}} functional MRI (fMRI) and fluorodeoxyglucose {{positron emission tomography}} (FDG-PET) in a patient with a rare, high-intensity "objective tinnitus" (high-level SOAEs) in the left ear of 10 years duration, with no associated hearing loss. This is the first case of objective cochlear tinnitus to be investigated with functional neuroimaging. The objective cochlear tinnitus was measured by Spontaneous Otoacoustic Emissions (SOAE) equipment (frequency 9689  Hz, intensity 57  dB SPL) and is clearly audible to anyone standing near the patient. Functional modifications in primary <b>auditory</b> <b>areas</b> and other brain regions were evaluated using 3 T and 7 T fMRI and FDG-PET. In the fMRI evaluations, a saturation of the auditory cortex at the tinnitus frequency was observed, but the global cortical tonotopic organization remained intact {{when compared to the}} results of fMRI of healthy subjects. The FDG-PET showed no evidence of an increase or decrease of activity in the auditory cortices or in the limbic system as compared to normal subjects. In this patient with high-intensity objective cochlear tinnitus, fMRI and FDG-PET showed no significant brain reorganization in <b>auditory</b> <b>areas</b> and/or in the limbic system, as reported in the literature in patients with chronic subjective tinnitus...|$|R
40|$|The human {{auditory}} cortex {{comprises the}} supratemporal plane and {{large parts of}} the temporal and parietal convexities. We have investigated the relevant intrahemispheric cortico-cortical connections using in vivo DSI tractography combined with landmark-based registration, automatic cortical parcellation and whole-brain structural connection matrices in 20 right-handed male subjects. On the supratemporal plane, the pattern of connectivity was related to the architectonically defined early-stage <b>auditory</b> <b>areas.</b> It revealed a three-tier architecture characterized by a cascade of connections from the primary auditory cortex to six adjacent non-primary areas and from there to the superior temporal gyrus. Graph theory-driven analysis confirmed the cascade-like connectivity pattern and demonstrated a strong degree of segregation and hierarchy within early-stage <b>auditory</b> <b>areas.</b> Putative higher-order areas on the temporal and parietal convexities had more widely spread local connectivity and long-range connections with the prefrontal cortex; analysis of optimal community structure revealed five distinct modules in each hemisphere. The pattern of temporo-parieto-frontal connectivity was partially asymmetrical. In conclusion, the human early-stage auditory cortical connectivity, as revealed by in vivo DSI tractography, has strong similarities with that of non-human primates. The modular architecture and hemispheric asymmetry in higher-order regions is compatible with segregated processing streams and lateralization of cognitive functions...|$|R
