0|5147|Public
50|$|A {{number of}} <b>query</b> <b>users</b> (S) is chosen, {{each of which}} execute the full set of 17 queries in a {{different}} order. In the background there is an update stream that runs a series of insert/delete operations (one pair for each <b>query</b> <b>user).</b> The choice {{of the number of}} users is at the discretion of the test sponsor.|$|R
30|$|We {{introduce}} {{an active}} learning method called Border for selecting pairs {{of objects and}} <b>query</b> <b>users</b> for constraint types. The general idea is examining objects lying around borders of clusters since {{they are the most}} uncertain ones and choosing a block of β pairs of objects to <b>query</b> <b>users</b> until the <b>query</b> budget δ is reached. Here, β and δ are predefined constants.|$|R
5000|$|... audit all <b>users</b> <b>queries,</b> so <b>users</b> using system {{incorrectly}} can {{be investigated}} ...|$|R
40|$|In this work, {{we study}} {{the task of}} {{personalized}} tag recommendation in social tagging systems. To reach out to tags beyond the existing vocabularies of the query resource and of the <b>query</b> <b>user,</b> we examine recommendation methods {{that are based on}} personomy translation, and propose a probabilistic framework for incorporating translations by similar users (neighbors). We propose to use distributional divergence to measure the similarity between users in the context of personomy translation, and examine two variations of such similarity measures. We evaluate the proposed framework on a benchmark dataset collected from BibSonomy, and compare with personomy translation methods based on the <b>query</b> <b>user</b> solely and collaborative filtering. Our experimental results show that our neighbor based translation methods outperform these baseline methods significantly. Moreover, we show that the translations borrowed from neighbors indeed help ranking relevant tags higher than that based solely on the <b>query</b> <b>user...</b>|$|R
3000|$|... [...]) {{were stored}} for each genuine user. (3) In the {{verification}} step, {{the features of}} the <b>query</b> <b>user</b> were quantized and coded according to the quantization information ([...] [...]...|$|R
40|$|In this paper, we {{consider}} a scenario where a <b>user</b> <b>queries</b> a <b>user</b> profile database, maintained by a {{social networking service}} provider, to find out some users whose profiles {{are similar to the}} profile specified by the <b>querying</b> <b>user.</b> A typical example of this application is online dating. Most recently, an online data site, Ashley Madison, was hacked, which results in disclosure {{of a large number of}} dating user profiles. This serious data breach has urged researchers to explore practical privacy protection for user profiles in online dating. In this paper, we give a privacy-preserving solution for user profile matching in social networks by using multiple servers. Our solution is built on homomorphic encryption and allows a user to find out some matching users with the help of the multiple servers without revealing to anyone privacy of the query and the <b>queried</b> <b>user</b> profiles. Our solution achieves user profile privacy and <b>user</b> <b>query</b> privacy as long as at least one of the multiple servers is honest. Our implementation and experiments demonstrate that our solution is practical...|$|R
50|$|OpenGL ES 1.1 added {{features}} such as mandatory support for multitexture, better multitexture support (including combiners and dot product texture operations), automatic mipmap generation, vertex buffer objects, state <b>queries,</b> <b>user</b> clip planes, and greater control over point rendering.|$|R
30|$|Visual {{interactive}} <b>query</b> allows <b>users</b> {{to learn}} more specific air quality values, performing a series of selection operations through the interactive graphical interface to <b>query.</b> <b>Users</b> intuitively transmit the query without complex query statements. The data shorted in the server can be directly read and written into KML format recognized by Google Earth [20 – 22]. The template changes according to different needs, and the air quality data is displayed in Google Earth with various forms.|$|R
40|$|Abstract—This paper {{presents}} a novel framework for dynamic circle recommendation for a <b>query</b> <b>user</b> {{at a given}} time point from historical communication logs. We identify the fundamental factors that govern interactions and aim to automatically form friend circles for scenarios, such as, who should I share the photo with in the early morning? Whose post should be listed on top of my Facebook Wall feed at night? We develop a temporal probabilistic model that not only captures temporal tendencies between the <b>query</b> <b>user</b> and each friend candidate but also blends frequency and recency into circle formation. Experimental results on Enron dataset and Call Detail Records prove the effectiveness of dynamic circle formation with proposed temporal probabilistic model...|$|R
50|$|The InterMine web {{application}} allows creation of custom bioinformatics queries, includes template queries (web forms to run 'canned' <b>queries).</b> <b>Users</b> can upload and operate on lists of data. It {{is possible to}} configure/create widgets to analyse lists with graphs and enrichment statistics.|$|R
40|$|A {{temporal}} aggregation query is {{an important}} but costly operation for applications that maintain timeevolving data (data warehouses, temporal databases, etc.). Due to the large volume of such data, performance improvements for temporal aggregation queries are critical. In this paper we examine techniques to compute temporal aggregates that include key-range predicates (range temporal aggregates). In particular we concentrate on SUM, COUNT and AVG aggregates. This problem is novel; to handle arbitrary key ranges, previous methods would need to keep a separate index for every possible key range. We propose an approach based on a new index structure called the Multiversion SB-Tree, which incorporates features from both the SB-Tree and the Multiversion B-Tree, to handle arbitrary key-range temporal SUM, COUNT and <b>AVG</b> <b>queries.</b> We analyze the performance of our approach and present experimental results that show its efficiency. ...|$|R
30|$|To reduce human effort, several methods {{incorporate}} {{active learning}} into the feedback process, e.g., [17, 18, 32, 43]. At each iteration, the algorithm automatically chooses pairs {{of objects and}} <b>queries</b> <b>users</b> for their feedback in terms of must-link and cannot-link constraints instead of leaving the whole clustering results for users to examine. Though these techniques are proven to be very useful in real-world tasks such as document clustering [17], they suffer from very high runtime since they have to repeatedly perform clustering and explore all O(n^ 2) pairs of objects to generate <b>queries</b> to <b>users</b> each time.|$|R
40|$|An {{important}} {{obstacle to}} accurate data analytics is dirty {{data in the}} form of missing, duplicate, incorrect, or inconsistent values. In the SampleClean project, we have developed a new suite of techniques to esti-mate the results of queries when only a sample of data can be cleaned. Some forms of data corruption, such as duplication, can affect sampling probabilities, and thus, new techniques have to be designed to ensure correctness of the approximate query results. We first describe our initial project on computing statistically bounded estimates of sum, count, and <b>avg</b> <b>queries</b> from samples of cleaned data. We sub-sequently explored how the same techniques could apply to other problems in database research, namely, materialized view maintenance. To avoid expensive incremental maintenance, we maintain only a sam-ple of rows in a view, and then leverage SampleClean to approximate aggregate query results. Finally, we describe our work on a gradient-descent algorithm that extends the key ideas to the increasingly common Machine Learning-based analytics. ...|$|R
40|$|With the {{exponential}} growth {{of information on}} the Internet, current information integration systems have become more and more unsuitable for this “Internet age ” due to the great diversity among sources. This paper presents a constraintbased <b>query</b> <b>user</b> interface model, which {{can be applied to the}} construction of dynamically generated adaptive user interfaces for meta-search engines...|$|R
40|$|Social {{networks}} are a vital mechanism to disseminate information {{to friends and}} colleagues. In this work, we investigate an important problem-the personalized influential topic search, or PIT-Search in a social network: Given a keyword query q issued by a user u in a social network, a PIT-Search {{is to find the}} top-k q-related topics that are most influential for the <b>query</b> <b>user</b> u. The influence of a topic to a <b>query</b> <b>user</b> depends on the social connection between the <b>query</b> <b>user</b> and the social users containing the topic in the social network. To measure the topics&# 039; influence at the similar granularity scale, we need to extract the social summarization of the social network regarding topics. To make effective topic-aware social summarization, we propose two random-walk based approaches: random clustering and an L-length random walk. Based on the proposed approaches, we can find a small set of representative users with assigned influential scores to simulate the influence of the large number of topic users in the social network with regards to the topic. The selected representative users are denoted as the social summarization of topic-aware influence spread over the social network. And then, we verify the usefulness of the social summarization by applying it to the problem of personalized influential topic search. Finally, we evaluate the performance of our algorithms using real-world datasets, and show the approach is efficient and effective in practice...|$|R
5000|$|More: Named Queries (pm.newNamedQuery), FetchPlan, Sequence, Delete by <b>Query,</b> {{multiple}} <b>User</b> Objects on PM ...|$|R
50|$|According to {{the lead}} professor, 3DESS can also {{describe}} objects using feature vectors, such as volume, surface area, etc. The system processes queries by comparing their feature vectors or skeletal graphs with data {{stored in the}} database. When the system retrieves models {{in response to the}} <b>query,</b> <b>users</b> can pick whichever object looks more similar to what they want and leave feedback.|$|R
40|$|Abstract—In this work, {{we study}} {{the task of}} {{personalized}} tag recommendation in social tagging systems. To include candidate tags beyond the existing vocabularies of the query resource and of the <b>query</b> <b>user,</b> we examine recommendation methods {{that are based on}} personomy translation, and propose a probabilistic framework for adopting translations from similar users (neigh-bors). We propose to use distributional divergence to measure the similarity between users in the context of personomy translation, and examine two variations of such divergence (similarity) measures. We evaluate the proposed framework on a benchmark dataset collected from BibSonomy, and compare with two groups of baseline methods: (i) personomy translation methods based solely on the query user; and (ii) collaborative filtering. The experimental results show that our neighbor based translation methods outperform these baseline methods significantly. More-over, we show that adopting translations from neighbors indeed helps including more relevant tags than that based solely on the <b>query</b> <b>user.</b> I...|$|R
40|$|Abstract. The use of {{preferences}} in query answering, both in traditional data-bases and in ontology-based data access, has recently received much attention, {{due to its}} many real-world applications. In this paper, we tackle the problem of top-k query answering in Datalog+/ – ontologies subject to the <b>querying</b> <b>user’s</b> preferences {{and a collection of}} (subjective) reports of other users. Here, each report consists of scores for a list of features, its author’s preferences among the features, as well as other information. Theses pieces of information of every report are then combined, along with the <b>querying</b> <b>user’s</b> preferences and his/her trust into each report, to rank the query results. We present two alternative such rankings, along with algorithms for top-k (atomic) query answering under these rankings. We also show that, under suitable assumptions, these algorithms run in polynomial time in the data complexity. We finally present more general reports, which are associated with sets of atoms rather than single atoms. ...|$|R
40|$|Radiologists {{frequently}} {{search the}} Web to find {{information they need}} to improve their practice, and knowing the types of information they seek could be useful for evaluating Web resources. Our goal was to develop an automated method to categorize unstructured <b>user</b> <b>queries</b> using a controlled terminology and to infer the type of information users seek. We obtained the query logs from two commonly used Web resources for radiology. We created a computer algorithm to associate RadLex-controlled vocabulary terms with the <b>user</b> <b>queries.</b> Using the RadLex hierarchy, we determined the high-level category associated with each RadLex term to infer the type of information users were seeking. To test the hypothesis that the term category assignments to <b>user</b> <b>queries</b> are non-random, we compared the distributions of the term categories in RadLex with those in <b>user</b> <b>queries</b> using the chi square test. Of the 29, 669 unique search terms found in <b>user</b> <b>queries,</b> 15, 445 (52 %) could be mapped to one or more RadLex terms by our algorithm. Each query contained an average of one to two RadLex terms, and the dominant categories of RadLex terms in <b>user</b> <b>queries</b> were diseases and anatomy. While the same types of RadLex terms were predominant in both RadLex itself and <b>user</b> <b>queries,</b> the distribution of types of terms in <b>user</b> <b>queries</b> and RadLex were significantly different (p[*]<[*] 0. 0001). We conclude that RadLex can enable processing and categorization of <b>user</b> <b>queries</b> of Web resources and enable understanding the types of information users seek from radiology knowledge resources on the Web...|$|R
5000|$|... <b>queries</b> the <b>user's</b> AkelPad configuration, i.e. which plugins are in use, {{available}} and their versions ...|$|R
5000|$|... (1) More personalization. Community detection/discovery often {{uses the}} same global {{criterion}} to decide whether a subgraph qualifies as a community. In other words, the criterion is fixed and predetermined. But in reality, communities for different vertices may have very different characteristics. Moreover, community search allows the <b>query</b> <b>users</b> to specify more personalized query conditions. In addition, the personalized query conditions enable the communities to be interpreted easily.|$|R
5000|$|Zero-input {{interfaces}} get inputs from a set {{of sensors}} instead of <b>querying</b> the <b>user</b> with input dialogs.|$|R
40|$|Abstract. PageRank, {{the popular}} link-analysis {{algorithm}} for ranking web pages, assigns a <b>query</b> and <b>user</b> independent estimate of “importance ” to web pages. <b>Query</b> and <b>user</b> sensitive extensions of PageRank, which use a basis set of biased PageRank vectors, {{have been proposed}} in order to personalize the ranking function in a tractable way. We analaytically compare three recent approaches to personalizing PageRank and discuss the tradeoffs of each one. ...|$|R
40|$|Because of the {{increasing}} number of electronic data, designing efficient tools to retrieve and exploit documents is a major challenge. Current search engines suffer from two main drawbacks: there is limited interaction with the list of retrieved documents and no explanation for their adequacy to the <b>query.</b> <b>Users</b> may thus be confused by the selection and have no idea how to adapt their query so that the results match their expectations. |$|R
40|$|In {{order to}} explain model behaviors, traces are stored during execution. These may beaccessed {{directly}} using a trace query language, which provides different views into the trace. A {{connection to a}} general explanation generator developed in a companion thesis hasalso been established through these <b>queries.</b> <b>Users</b> may ask questions about {{the behavior of a}} conceptual model. Some of the information included in the explanation is fetchedfrom execution traces...|$|R
40|$|Abstract—This paper proposes LARS*, a location-aware {{recommender}} system that uses location-based ratings to produce recommen-dations. Traditional {{recommender system}}s {{do not consider}} spatial properties of users nor items; LARS*, on the other hand, supports a taxonomy of three novel classes of location-based ratings, namely, spatial ratings for non-spatial items, non-spatial ratings for spatial items, and spatial ratings for spatial items. LARS * exploits user rating locations through user partitioning, a technique that influences recommendations with ratings spatially close to <b>querying</b> <b>users</b> {{in a manner that}} maximizes system scalability while not sacrificing recommendation quality. LARS * exploits item locations using travel penalty, a technique that favors recommendation candidates closer in travel distance to <b>querying</b> <b>users</b> in a way that avoids exhaustive access to all spatial items. LARS * can apply these techniques separately, or together, {{depending on the type of}} location-based rating available. Experimental evidence using large-scale real-world data from both the Foursquare location-based social network and the MovieLens movie recommendation system reveals that LARS * is efficient, scalable, and capable of producing recommendations twice as accurate compared to existing recommendation approaches...|$|R
40|$|The use of {{preferences}} in query answering, both in traditional databases and in ontology-based data access, has recently received much attention, {{due to its}} many real-world applications. In this paper, we tackle the problem of top-k query answering in Datalog+/- ontologies subject to the <b>querying</b> <b>user's</b> preferences {{and a collection of}} (subjective) reports of other users. Here, each report consists of scores for a list of features, its author's preferences among the features, as well as other information. Theses pieces of information of every report are then combined, along with the <b>querying</b> <b>user's</b> preferences and his/her trust into each report, to rank the query results. We present two alternative such rankings, along with algorithms for top-k (atomic) query answering under these rankings. We also show that, under suitable assumptions, these algorithms run in polynomial time in the data complexity. We finally present more general reports, which are associated with sets of atoms rather than single atoms. Comment: arXiv admin note: text overlap with arXiv: 1106. 3767 by other author...|$|R
40|$|Query {{formulation}} in {{the context}} of large conceptual schemata is known to be a hard problem. When formulating ad-hoc <b>queries</b> <b>users</b> may become overwhelmed by the vast amount of information that is stored in the information system; leading to a feeling of lost in conceptual space. In this article we develop a strategy to cope with this problem. This strategy is based on ideas from the information retrieval world. In particular the query by navigation mechanism and the stratified hypermedia architecture. The stratified hypermedia architecture is used to describe the information contained in the information system on multiple levels of abstraction. When using our approach to the formulation of <b>queries,</b> a <b>user</b> will first formulate a number of simple queries corresponding to linear paths through the information structure. The formulation of the linear paths {{is the result of the}} explorative phase of <b>query</b> formulation. Once <b>users</b> have specified a number of these linear paths, they ma [...] ...|$|R
5000|$|... for {{developing}} login modules. Your module invokes callbacks to <b>query</b> the <b>user,</b> checks their response and generates a Subject.|$|R
5000|$|... 7. How to {{calculate}} ishta lagna, nashta jataka details, prashna lagna and answering <b>queries</b> of <b>users</b> on lost articles.|$|R
30|$|The {{idea of the}} {{approach}} is to recommend personalized MDX <b>queries</b> to the <b>user.</b> The <b>queries</b> are adapted to user’s preferences and objectives of analysis. Preferences of the user are detected implicitly using collaborative filtering technique by comparing the current <b>user</b> <b>query</b> with previous queries triggered by former users and recorded in a log file. The comparison between the current <b>user</b> <b>query</b> and previous queries is performed using the spatio-semantic similarity measure.|$|R
40|$|Web is a {{very large}} {{evolving}} network 25 % new links and 8 % new pages per week [NCO 04] 15 % of pages weekly updated [FMNW 03] Evolution and associated temporal features like recency and frequency of change ignored in Web search For many <b>queries</b> <b>user’s</b> interest has a temporal dimension “new orleans hurricane ” (∼ most recent information) “www conference ” (∼ upcoming conference) “tour de france ” (∼ this year’s event...|$|R
40|$|Abstract—In this {{demonstration}} paper, {{we present a}} novel framework for searching objects (e. g., images, videos, etc.) cap-tured by the users in a mobile social community. Our framework, is founded on an in-situ data storage model, where captured objects remain local on their owners smartphones and searches then take place over a novel lookup structure we compute dynamically. Initially, a <b>query</b> <b>user</b> invokes a search to find an object of interest. Our structure concurrently optimizes several conflicting objectives (i. e., it minimizes energy consumption, minimizes search delay and maximizes query recall), using a Multi-Objective Optimization approach and calculates a diverse set of high quality non-dominated Query Routing Trees (QRTs), in a single run. The optimal set is then forwarded to the <b>query</b> <b>user</b> (decision maker) to select a particular QRT to be searched based on instant requirements and preferences. To demonstrate the capabilities of SmartP 2 P during the conference, we will utilize our cloud of smartphone devices, i. e. the SmartLab testbed composed of 40 + Android smartphones and tablets, as well as mobility and social patterns derived by Microsofts Geolife project, DBLP and Pics n Trails. We will allow the attendees to use a real SmartLab Android device to query our local Smartphone Network using {{any of the four}} algorithmic choices provided by the SmartP 2 P framework. The query device will then be provided with the optimal QRTs and the attendees will be able to visually decide the optimal QRT to be searched. A P 2 P search on the Smartphone Network will follow making available to the <b>query</b> <b>user</b> the desired objects of interest, in an optimal manner. The conference attendees will be able to appreciate how social content can be efficiently shared with other attendees within close proximity without revealing their personal content to a centralized authority. I...|$|R
50|$|A {{database}} {{containing the}} data entered and <b>queried</b> by <b>users.</b> Each User Database {{is associated with}} a version of a Schema.|$|R
40|$|Instuitionistic {{fuzzy logic}} is widely {{accepted}} method to analyse the imprecise and vague data. There are number of database management systems (DBMS) {{are available to}} facilitate the users to store and organize {{the data for the}} future purpose. DBMS lacks to understand the <b>user</b> <b>queries</b> in distributed environment. Sql is a popular querying language to fetch data depend upon the <b>user</b> <b>queries.</b> The structure of the sql query is designed for precise <b>queries</b> from the <b>user</b> but it will return error for vague queries. As the business extends from one part of the world to the other language should be a barrier for the non- English speakers. The research is to find the solution for the problems exist in the sql to translate the <b>user</b> <b>queries.</b> The proposed model will answer all kind of <b>user</b> <b>queries</b> and tries solve the vagueness problem using fuzzy logic...|$|R
