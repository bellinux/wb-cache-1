20|54|Public
5000|$|Cloud based digital <b>artifact</b> <b>management</b> (cloud {{library for}} documents, video, code, etc.) ...|$|E
50|$|Robust {{management}} of artifacts, including RWave identification, interpolation and exclusion requires {{a high degree}} of care and precision. This can be very time consuming in large studies with data recorded over long durations. Software packages are able to assist users with a variety of robust and tested <b>artifact</b> <b>management</b> tools. These software programs also include some automated capability but it is important that a human review any automated <b>artifact</b> <b>management</b> and edit accordingly.|$|E
50|$|Rational Quality Manager is a collaborative, web-based {{tool that}} offers test planning, test construction, and test <b>artifact</b> <b>management</b> {{functions}} throughout the software development lifecycle.|$|E
40|$|In {{this paper}} an {{automatic}} ocular <b>artifacts</b> <b>management</b> procedure for EEG analysis on-line is proposed, {{composed of a}} detection algorithm followed by a correction {{which is based on}} canonical correlation analysis (CCA). The accuracy of the whole method is tested on simulated signals and its capability of recovering the original signals is shown to be comparable with non-automatic ‘gold standard’ procedure (independent component analysis - ICA). The method is implemented to be suitable for fast EEG processing to improve on-line signal interpretation. An example on real data is also provided...|$|R
50|$|The Project Initiation Documentation (PID) - one of {{the most}} {{significant}} <b>artifacts</b> in project <b>management,</b> which provides the foundation for the business project.|$|R
40|$|The {{search for}} an {{acceptable}} colorectal cancer screening examination {{has led to the}} development of virtual colonoscopy, which includes both computed tomographic (CT) colonography and magnetic resonance (MR) colonography. As indicated by the much larger number of published studies on CT colonography than on MR colonography, multidetector CT appears to be more suitable for colorectal screening than does MR colonography, in part reflecting the ease and speed of performing CT, as well as the increased spatial resolution, decreased cost, and wider availability of CT colonography. The main advantage of MR colonography over CT colonography is that it does not use ionizing radiation, which has important implications for colorectal cancer screening. The use of dark-lumen MR colonography to screen patients for colorectal cancer as well as other abdominopelvic disease could make it more attractive than CT. With the integration of 3. 0 -T MR colonography, fecal tagging, and parallel imaging into research and clinical settings, new MR colonography protocols must be optimized. Future MR colonography research should address issues such as image characteristics, presence of <b>artifacts,</b> <b>management</b> of specific absorption rate, and hardware-related modifications...|$|R
50|$|Buildr {{is based}} on Ruby's build system Rake, and uses Ruby as a {{scripting}} language. It uses several project automation idioms from Maven like automated <b>artifact</b> <b>management</b> (Buildr is out-of-box compatible with Maven's repositories). As opposed to the more imperative style of build systems like Ant, Buildr takes a more declarative approach in describing the project automation logic (similarly to Maven).|$|E
40|$|We {{present an}} {{approach}} to integrate a visual authorization policy management system based on RBAC and XACM in the ADAMS (ADvanced <b>Artifact</b> <b>Management</b> System) Process Support System. ADAMS is a Web-based system that integrates project management features such as resource allocation and process control and <b>artifact</b> <b>management</b> features, such as coordination of cooperative workers and artifact versioning, as well as context-awareness. We propose a hierarchy of visual languages aiming to support project managers and security administrators in modeling RBAC based access policies in ADAMS. The visual sentences are translated into XACML and stored into a Policy Repository. In this way the Policy Management System is able to process XACML requests and compare them against the defined access policies...|$|E
40|$|The main {{drawback}} {{of existing}} software <b>artifact</b> <b>management</b> systems {{is the lack}} of automatic or semi-automatic traceability link generation and maintenance. We have improved an <b>artifact</b> <b>management</b> system with a traceability recovery tool based on Latent Semantic Indexing (LSI), an information retrieval technique. We have assessed LSI to identify strengths and limitations of using information retrieval techniques for traceability recovery and devised the need for an incremental approach. The method and the tool have been evaluated during the development of seventeen software projects involving about 150 students. We observed that although tools based on information retrieval provide a useful support for the identification of traceability links during software development, they are still far to support a complete semi-automatic recovery of all links. The results of our experience have also shown that such tools can help to identify quality problem...|$|E
40|$|Abstract—Traceability {{links between}} {{requirements}} and source code are often created after development. This re-duces {{the possibilities for}} developers to use these traceability links during the development process. Additionally, existing approaches applied after development do not consider <b>artifacts</b> from project <b>management,</b> which are used for planning and organizing a project. These artifacts {{can serve as a}} mediator between requirements and source code. In contrast to these existing approaches, we present an approach that creates traceability links between requirements and source code as the development progresses by incorporating <b>artifacts</b> from project <b>management.</b> In this paper, we make two key contributions. First, a Traceability Information Model integrating require-ments, source code and <b>artifacts</b> from project <b>management.</b> Second, an approach for the (semi-) automatic creation of traceability links between artifacts from the Traceability In-formation Model achieving traceability between requirements and source code during the development process. We identified a catalog of information needs of developers from literature regarding requirements, source code that realizes these re-quirements, and work done by co-workers implementing these requirements. The presented approach satisfies the information needs of the developers during the development process, while keeping the traceability links up-to-date. Keywords-traceability; requirements; source code; software development; information needs. I...|$|R
40|$|In this contribution, {{we report}} on a diploma thesis project which {{combined}} two major aims: (1) to try out UML as a specification language for a specific software process model, and (2) to study the general aptness of UML for the software process modelling task. Due to the limited space we can only sketch our work and results here, for a longer {{version of this article}} cf. [BH 03], for the diploma thesis [Be 01]. The EOS 1 model, developed by the second author [He 97, He 03], was taken as subject of our experiment, since there was no prior elaborated formalisation (which might have bi-ased the modelling), it has special features (systematics, orthogonality, transparent struc-ture) supporting such a formalisation, and because there is a good mixture of static and (non-linear, sufficiently complex) dynamic process features. The skeleton for all EOS process elements is the building block hierarchy consisting of systems, components (in-cluding subcomponents of arbitrary depth) and modules. Building blocks are the central anchor for development cycles, activities, <b>artifacts,</b> <b>management</b> and quality assurance ac-tions; they determine the repository structure and project documentation. The recursive, scalable structure of this hierarchy induces a similar structure of software processes. De...|$|R
40|$|Software {{systems are}} {{specified}} with formal artifacts such as requirements or architecture models. However, informal project artifacts such as bug reports, tasks or discussion threads also include relevant {{information about the}} respective software systems and their development. It is beneficial to externalize such information in formalized representations, e. g. to increase the automation of development activities. In this paper we describe a model that integrates formal system models and informal artifacts of software development projects. We show how this integration eases the manual transition of information from project <b>management</b> <b>artifacts</b> to system models, and discuss how this transition can be automated. To facilitate this transition we propose an approach for the automated identification of informal <b>management</b> <b>artifacts,</b> which contain information about functional requirements and other system specifications such as classes...|$|R
40|$|Our goal in {{this chapter}} is to propose a model for {{analyzing}} physical artifacts, and to illustrate how this model can help prevent what we call 'artifact myopia'. We suggest that identifying three simultaneous dimensions of artifacts can significantly enhance the understanding of artifacts, avoid a limited and narrow view of artifacts, and facilitate effective <b>artifact</b> <b>management.</b> The three dimensions are instrumentality, aesthetics, and symbolism, and potential myopia involves overlooking one or more dimension or overlooking certain aspects {{of any of the}} dimensions, because of oversight of relevant artifact constituents. Artifact myopia – page...|$|E
40|$|The goal of {{this thesis}} is to improve Usability and {{functionality}} of a tool for <b>artifact</b> <b>management,</b> which applies taxonomic paths for categorizing artifacts. The main issues of using the taxonomic paths are used for categorization and should improve the precision when retrieving documents. The results show the improvements in functionality and usability of the artifact manager. This thesis explains about Usability, re-engineering, and necessary infrastructure to improve {{the performance of the}} artifact manager tool. At the end of the thesis necessary modifications has been done to improve usability and functionality of artifact manage...|$|E
40|$|Prior {{research}} in software environments focused on three important problems [...] -tool integration, <b>artifact</b> <b>management,</b> and process guidance. The context for that research, {{and hence the}} orientation of the resulting environments, was a traditional model of development in which an application is developed completely from scratch by a single organization. A notable characteristic of component-based development is its emphasis on integrating independently developed components produced by multiple organizations. Thus, while component-based development can benefit from the capabilities of previous generations of environments, its special nature induces requirements for new capabilities not found in previous environments. This pape...|$|E
40|$|Standards for {{critical}} avionics software development, such as DO 178 B, place {{a strong emphasis}} on process issues: ensuring traceability between different development artifacts and proper configuration <b>management</b> of these <b>artifacts.</b> Certification <b>Management</b> (CM) systems formalize many of the relationships between different artifacts and hold the promise of both streamlining the <b>management</b> of the <b>artifacts</b> and ensuring that relationships between the artifacts are formally justified. However, to be useful in an industrial context, the definition and scope of CM systems must be better understood, and several open issues must be addressed. This paper describes issues and potential uses of CM systems in industrial practice. 1...|$|R
30|$|Finally, future {{research}} should build on the identified and further validated reasons for process deviance when theorizing about the deviance proneness of business processes and exploring the relationship between deviance proneness and process deviance. We believe that deviance proneness is an important, yet under-researched concept, as it takes an ex ante and managerial view on process deviance. These resulting insights should also be leveraged for design-oriented research. Potentially worthwhile design artifacts are deviance-aware process valuation, prioritization, and improvement methods as well as and decision support systems for deviance-aware process portfolio management. Regarding context-aware BPM, a potential design <b>artifact</b> is <b>management</b> practices {{for dealing with the}} identified reasons for process deviance in routine and nonroutine processes.|$|R
40|$|Abstract. Model-based {{software}} engineering (MBSE) projects require and generate numerous artifacts. While MBSE methodology and design tools have reached certain maturity level, {{the issue of}} <b>artifact</b> persistence and <b>management</b> has been somewhat left in the background. We present design {{and implementation of the}} repository that supports storing and managing of artifacts such as metamodels, models, constraints, meta-data, specifications, transformation rules, code, templates, configuration or documentation, and their metadata. ...|$|R
30|$|Cooperation According to Gorton et al. (1997 a), {{the vast}} {{majority}} of the tools used in a collocated development context are designed to support only single-user activity, thus making the exchange of information between users more difficult. This problem is particularly frequent in the CM process in which the project metadata must be shared in a controlled manner. In this SMS, 69 cooperative tools have been identified, which makes cooperation the most prominent feature in SPM tools for GSD. The tools in this category are mainly <b>artifact</b> <b>management</b> or versioning system tools that provide a shared and distributed workspace by using either a centralized or a peer-to-peer (P 2 P) architecture.|$|E
40|$|A process {{modeling}} {{language that is}} easy to learn and use while grounded in rigorous semantics to facilitate execu-tion and simulation {{has always been a}} big challenge for re-searchers. In this paper, we describe Little-JIL, a visual pro-cess modeling language and its runtime-infrastructure, Juli-ette, that is capable of driving a process with the help of participating human or computing agents. We then introduce JSim, a discrete-event simulation environment with flexible <b>artifact</b> <b>management</b> and intricate resource management ca-pability built on top of the Little-JIL and Juliette framework. The factored architecture and rich modeling mechanism for both the process description as well as the resource specifica-tion has allowed us to simulate some dynamic and complex real-life systems in details. 1...|$|E
30|$|As {{shown in}} Fig.  6, tools {{focusing}} on a specific process (mono-activity tool) are dominant in comparison with tools focusing on several processes (multi-activity tool). For example, tools like Travis (Geisser et al. 2007), DPMTool (Garrido et al. 2012) and Microsoft Office Communicator (Niinimaki et al. 2010) focus on a particular process while other tools focus on several activities (see Table  12 in Appendix 2). Another example of a single activity tool is Atlassian JIRA (Prikladnicki et al. 2012; Lanubile et al. 2010) which {{is considered to be}} an issue tracker without any other relevant features, thus focusing only on the PA process. IBM Rational Team Concert (Scharff et al. 2010; Treude and Storey 2012; Wang et al. 2012), meanwhile, has PP, <b>artifact</b> <b>management</b> and messaging features. In this case, it is focused on PP, CM and IM processes.|$|E
40|$|This master’s thesis {{describes}} {{life cycle}} phases {{management of the}} project Implementation of the project culture in the MoroSystems company {{from the perspective of}} a project manager. The thesis comprehensively describes the project from its inception, through planning, implementation up to handover of the outcomes to the customer, completion and evaluation. The thesis contains attachments which document meetings with the customer and project <b>management</b> <b>artifacts</b> created at different stages of the project...|$|R
40|$|IT enabled {{teaching}} and learning systems {{have been widely used}} in higher education institutions. This paper describes how the e-learning environment, such as myCourses, can support teaching higher-order thinking. The theme of this study is the design of organizational structures of {{teaching and}} learning artifacts for higher-order thinking. The paper proposes a model of thinking inquiry-based structure of {{teaching and learning}} <b>artifact</b> for e-learning <b>management</b> systems. It presents a design case study of implementation of this model. 1...|$|R
40|$|A risk {{inventory}} {{provides an}} integrated view on risk <b>management</b> <b>artifacts,</b> e. g., risks, risk controls, and performance indicators. In this paper, we show how adapting the enterprise architecture management processes (EAM) {{may provide a}} foundation for an integrated IT risk inventory. Based on a design research approach, we develop a systematic approach for integrating the disciplines of risk management and enterprise architecture management. We demonstrate the utility of our approach by evaluating an identity management solution in a large bank...|$|R
40|$|Abstract. We propose an {{approach}} to <b>artifact</b> <b>management</b> in software engineering that uses an artifact matrix to structure the artifact space of a project along stakeholder viewpoints and realization levels. This matrix structure provides a basis on top of which relationships between artifacts can be defined, such as consistency constraints, tracebility links and model transformations. The management of all project artifacts and their relationships supports collaboration across different roles in the development process as well as change management and agile practices. Our approach is highly configurable to facilitate adaptation to different development methods and processes. It provides a basis to develop and/or to integrate generic tools that can flexibly support such different methods. In particular, it can be leveraged to improve the transition from requirements analysis to architecture design. ...|$|E
40|$|AbstractIn recent years, {{importance}} on software security technologies {{has been recognized}} and various types of technologies have been developed. On the other hand, in spite of recognition of necessity of providing cases that deal with full life cycle for secure software development, only few are reported. This paper describes a case-based management system (CBMS) that consists of an <b>artifact</b> <b>management</b> system and a knowledge-based management system (KBMS) to manage cases for secure software development. The former manages the artifacts created in secure software life cycle. The latter manages software security knowledge. The case-based management system also manages association between artifacts and software security knowledge and supports both visualization among software security knowledge and between artifacts and software security knowledge. We conducted an experiment to evaluate the system. We describe the effectiveness and future work of the system...|$|E
40|$|Concurrent {{versioning}} of {{source code}} {{is a common}} and well-established practice to manage concurrency and consistency within source code repository. With the growing complexity of nowadays software systems, the need for high level representations of the system to develop becomes inevitable. These software models evolve together with the software system, thus requiring versioning management. Moreover, software models are often the result of cooperative work by different software engineers, that need to update them even concurrently. Unfortunately, the available concurrent versioning tools, do not provide an adequate support {{for this type of}} software artifacts. We propose a solution to manage versioning and concurrency for software models (in particular, UML models), that consists of a fine-grained concurrent modeling approach. The approach has been implemented and integrated in an <b>artifact</b> <b>management</b> system, thus also enabling reuse of model elements across the entire project...|$|E
40|$|Our {{understanding}} of off-nominal behavior - failure modes and fault propagation - in complex systems is often based purely on engineering intuition; specific cases are assessed {{in an ad}} hoc fashion as a (fallible) fault management engineer sees fit. This work {{is an attempt to}} provide a more rigorous approach to this understanding and assessment by automating the creation of a fault <b>management</b> <b>artifact,</b> the Failure Modes and Effects Analysis (FMEA) through querying a representation of the system in a SysML model. This work builds off the previous development of an off-nominal behavior model for the upcoming Soil Moisture Active-Passive (SMAP) mission at the Jet Propulsion Laboratory. We further developed the previous system model to more fully incorporate the ideas of State Analysis, and it was restructured in an organizational hierarchy that models the system as layers of control systems while also incorporating the concept of "design authority". We present software that was developed to traverse the elements and relationships in this model to automatically construct an FMEA spreadsheet. We further discuss extending this model to automatically generate other typical fault <b>management</b> <b>artifacts,</b> such as Fault Trees, to efficiently portray system behavior, and depend less on the intuition of fault management engineers to ensure complete examination of off-nominal behavior...|$|R
40|$|Software {{design is}} a complex process that {{requires}} signi cant human involvement, collaboration, and coordinated use of tools and artifacts. Software design methods describe software design in general terms but neglect many details {{that are important to}} executing speci c design processes. A process program that de nes a design process clearly and precisely should be an important aid to supporting and reasoning about the process. The demands placed on a process programming language in de ning a software design process are great, including the need for exible control ow, error handling, resource management, agent coordination, and <b>artifact</b> consistency <b>management.</b> This paper describes the use of JIL, a process programming language, in the de nition of a process supporting Booch object-oriented design. The paper illustrates the need for precision and clarity in de ning software processes, and it indicates how various of the features of JIL are e ective in meeting these needs. ...|$|R
40|$|Nowadays, {{responding}} to requirements change in software industry {{is essential for}} survival in the competitive market to achieve business objectives. However, it is clearly evident that changing requirements have many problems which causes software failure. This was a great motivation to analyse literature for identifying current challenges of Requirements Change Management (RCM); which in return can improve our ability to make better decisions and resolve changing requirements problems. Major challenges of RCM have been elucidated as reusability, change anticipation, change activity measurement, connectivity with software <b>artifacts</b> and change <b>management</b> automation. Identifying RCM challenges will help to draw a road map for researchers and practioners to find optimal solutions...|$|R
40|$|We {{present the}} GENESIS {{platform}} (GEneralised eNvironment for procEsS management in cooperatIve Software engineering), {{the outcome of}} a research project aiming at designing and developing a noninvasive and open-source system to support software engineering processes in a highly distributed environment. The system supports the cooperation and coordination in software processes as its process modeling language enables the decomposition of complex processes into subprocesses that can be distributed and executed at different organizational sites. In GENESIS, workflow management technologies have been integrated with <b>artifact</b> <b>management</b> and communication services to meet the necessary requirements of managing the cooperation among distributed teams. Its strengths are a powerful activity management, covering all the main aspects of the life cycle of an activity; an efficient and flexible project monitoring, collecting productivity and quality metrics to show on-demand snapshots of the whole process and of its parts at different levels of detail, and a careful consideration of the process evolution questions, allowing to adequately manage the most common exceptions happening during process execution in a simple and flexible way...|$|E
40|$|Prior {{research}} in software environments focused on three important problems — tool integration, <b>artifact</b> <b>management,</b> and process guidance. The context for that research, {{and hence the}} orientation of the resulting environments, was a traditional model of development in which an application is developed completely from scratch by a single organization. A notable characteristic of component-based development is its emphasis on integrating independently developed components produced by multiple organizations. Thus, while component-based development can benefit from the capabilities of previous generations of environments, its special nature induces requirements for new capabilities not found in previous environments. This paper is concerned with the design of component-based development environments, or CBDEs. We identify seven important requirements for CBDEs and discuss their rationale, and we describe a prototype environment called WREN that we are building to implement these requirements and to further evaluate and study the role of environment technology in component-based development. Important capabilities of the environment include the ability to locate potential components of interest from component distribution sites, to evaluate the identified components for suitability to an application, to incorporate selected components into application design models, and to physically integrate selected components into the application...|$|E
40|$|Abstract—Agent {{modularisation}} is a {{main issue}} in agent and multi-agent system programming. Existing solutions typically propose {{some kinds of}} constructs – such as capabilities – to group and encapsulate in well-defined modules inside the agent different kinds of agent features, that depend on the architecture or model adopted—examples are goals, beliefs, intentions, skills. In this paper we introduce a further perspective, which can be considered complimentary to existing approaches, which accounts for externalizing some of such functionalities into the computational environment where agents are (logically) situated. In this perspective, agent modules are realised as suitably designed artifacts that agents can dynamically exploit as external tools to enhance their action repertoire and – more generally – their capability to execute tasks. Then, to let agent (and agent programmers) exploit such capabilities abstracting from the low-level mechanics of <b>artifact</b> <b>management</b> and use, we exploit the dual notion of internalization, which consists in dynamically consulting and automatically embedding high-level usage protocols described in artifact manuals as agent plans. The idea is discussed providing some practical examples of use, based on CArtAgO as technology for programming artifacts and Jason agent platform to program the agents. I...|$|E
40|$|The web’s {{historical}} periodization as Web 1. 0 (“read-only”) and Web 2. 0 (“read/write”) eras {{continues to}} hold sway even as the umbrella term “social media” has become the preferred way to talk about today’s ecosystem of connective media. Yet, we have much to gain by not exclusively positing social media platforms as a 21 st-century phenomenon. Through case studies of two commercially sponsored web projects from the mid- 1990 s—Massachusetts Institute of Technology Media Lab’s Day in the Life of Cyberspace and Rick Smolan’s 24 Hours in Cyberspace—this article examines how notions of social and publics were imagined and designed into the web {{at the start of}} the dot-com boom. In lieu of a discourse of versions, I draw on Lucy Suchman’s trope of configuration as an analytic tool for rethinking web historiography. By tracing how cultural imaginaries of the Internet as a public space are conjoined with technological <b>artifacts</b> (content <b>management</b> systems, templates, session tracking, and e-commerce platforms) and reconfigured over time, the discourses of “read-only publishing” and the “social media revolution” can be reframed not as exclusively oppositional logics, but rather, as mutually informing the design and development of today’s social, commercial, web...|$|R
40|$|Management {{of project}} planning, monitoring, scheduling, {{estimation}} and risk management are critical issues faced by a project manager during development {{life cycle of}} software. In RUP, project management is considered as core discipline whose activities are carried in all phases during development of software products. On other side service monitoring is considered as best practice of SOA which leads to availability, auditing, debugging and tracing process. In this paper, authors define a strategy to incorporate the service monitoring of SOA into RUP to improve the <b>artifacts</b> of project <b>management</b> activities. Moreover, the authors define the rules to implement the features of service monitoring, which help the project manager to carry on activities in well define manner. Proposed frame work is implemented on RB (Resuming Bank) application and obtained improved results on PM (Project Management) work...|$|R
40|$|Digital image {{acquisition}} using CR technology is po-tentially a cost-effective {{way to go}} filmless using the already installed x-ray systems and the same techni-cal background from the technologists' point of view. It eliminates dark room and has tremendous effect on workflow in the department. In those imaging centers where direct digital mam-mography installation is not justified, CR can be a shortcut to achieve a digital {{image acquisition}}, which is an inevitable prerequisite to filmless radiology. At the same time, superior modern technology will change image quality {{in a way that}} may also affect the radiologist's performance and the clinician's satis-faction. Although the overall improvement of breast imaging will be affected by availability of PACS and image management equipment and network, it will make benefit from CAD technology, {{which is one of the}} promising fields of actual decision-making support in medical imaging. Telemammography and consulta-tions are made easy by digital images produced by CR mammography. The experience of 220 consecutive mammography studies using CR technology will be presented in terms of pathologic findings, comparison of image quality in patients undergoing repeat or follow-up mammograms, superiority in detection of dense pa-renchyma and skin or soft tissue components, diffi-culties of microcalcification detection and <b>artifacts,</b> department <b>management</b> issues regarding archive, reproducibility, digital magnification and cost-effectiveness considering parallel CR installation for studies other than mammography and problems aris-ing from technical support by the vendor...|$|R
