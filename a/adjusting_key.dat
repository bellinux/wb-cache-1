16|186|Public
5000|$|To {{light the}} stove, {{the fuel tank}} must first be {{pre-heated}} and pressurized by lighting {{a small amount of}} fuel poured into the primer pan or spirit cup (a small well) on top of the tank {{at the base of the}} vaporizer (the vertical stem connecting the fuel tank to the burner). Alternatively, the primer pan can be filled directly from the fuel tank by opening the control valve and warming the fuel tank by holding it in one’s hands. This will increase the pressure in the fuel tank and force a small amount of fuel to trickle out of the burner jet and into the primer pan. [...] The control valve must then be closed before lighting the priming fuel so as to allow pressure to build up in the tank when the exterior fuel begins to heat the tank and the fuel within. The tank can also be pressurized by an optional pump that may be attached to the filler cap, but this is generally not necessary except in extreme cold. Fuel from the tank is fed by a cotton wick inside the tank to the base of the vaporizer. The heat and pressure created by the priming flame vaporizes the fuel inside the vaporizer. When the priming flame is nearly burnt out, the control valve is opened by turning the <b>adjusting</b> <b>key.</b> This allows the vaporized fuel to flow under pressure through the burner jet (a small opening at the base of the burner), where it mixes with oxygen and burns with a blue flame. Adjusting the flow of the vaporized fuel that is forced through the burner jet controls the flame size and heat output. The control valve (a spindle) is threaded in the vaporizer's housing, and as it is opened (by turning the <b>adjusting</b> <b>key)</b> it opens like a faucet (counter-clockwise to open and clockwise to close) and the vaporized fuel flows through the burner jet. Closing the spindle closes the fuel supply. A small plate on the top of the burner (a flame spreader) spreads the flame outwards. The heat generated in the burner and vaporizer maintains the internal pressure in the fuel tank.|$|E
5000|$|Made {{of solid}} brass, the Svea 123 weighs about 500 grams (19 ounces), {{measures}} 100 mm x 130 mm (3.9” x 5.1”) and will burn {{for over an}} hour on full tank (about 4 ounces) of fuel. Later models (designated the “Svea 123R” and also sold as the Optimus “Climber”) were made with a built-in cleaning needle to keep the burner jet from clogging by pushing soot or other impurities outward; early Sievert models without the self-cleaning needle came with a small wire pricker that is used to clean the burner jet manually by pushing the soot inwards. These older models are distinguishable by their downwardly-angled spindle and control valve, to which the <b>adjusting</b> <b>key</b> is attached. The spindle on a Svea 123R with the self-cleaning needle is at a right angle to the stem. Other differences between older and newer models include the vaporizer on older models, which is smooth, while newer models of both the Svea 123 and the 123R are finned and have a stronger joint configuration at the base. The pressure-relief valve in the filler cap has also been redesigned several times to improve both reliability as well as re-seating of the valve after it has opened. [...] The pentagonal hole in the pressure relief valve is designed as a vent, not a key socket. The valve disassembles easily with a pliers. A brass windscreen attaches directly to the stove, and has built-in pot supports that fold inward for storage. The aluminum lid comes with a detachable handle and can also be used as a small cook-pot.|$|E
40|$|In this paper, a novel unified channel model {{framework}} is proposed for cooperative multiple-input multiple-output (MIMO) wireless channels. The proposed model {{framework is}} generic and adaptable to multiple cooperative MIMO scenarios by simply <b>adjusting</b> <b>key</b> model parameters. Based {{on the proposed}} model framework and using a typical cooperative MIMO communication environment as an example...|$|E
30|$|Despite these {{positive}} observational studies, {{the evidence}} for a harmful effect of blood storage remains uncertain. This is because few of these reports <b>adjusted</b> for <b>key</b> confounding factors, including leukodepletion, volume of RBC transfused, the year of transfusion, and ABO type, and very few analyzed RBC age as a continuous variable[60]. None <b>adjusted</b> for all <b>key</b> confounders.|$|R
5000|$|Because {{it may not}} {{be obvious}} to many users what each of the {{measurements}} really mean, a simulation tool allows a user to <b>adjust</b> <b>key</b> parameters, visualizing how surfaces which are obviously different to the human eye are differentiated by the measurements. For example, [...] fails to distinguish between two surfaces where one is composed of peaks on an otherwise smooth surface and the other is composed of troughs of the same amplitude. Such tools can be found in app format.|$|R
40|$|Helophorus dracomontanus sp. n. is {{described}} from the Tibetan Plateau near Kangding, Sichuan, China. It {{is a member}} of the subgenus Helophorus s. str. but the anterolateral part of the pronotum resembles subgenus Gephelophorus Sharp, 1915. The short metallic-black maxillary palpi with almost symmetrical apical segments are suggestive of subgenus Kyphohelophorus Kuwert, 1886, but the elytral flanks are narrower than the epipleurs, excluding the species from that subgenus. An <b>adjusted</b> <b>key</b> to Helophorus s. str. is given to identify the new species, as well as H. jaechi Angus, 1995 and H. kozlovi Zaitsev, 1908...|$|R
40|$|Abstract — This paper {{addresses}} {{the control of}} a planar, biped robot with one degree of underactuation. Previous work has designed controllers that induce provably, exponentially stable, periodic walking motions at fixed, pre-determined walking rates. These controllers operate in continuous time during the single support phase of the robot. The present paper shows how to design an event-based PI controller that provides an additional control feature: the ability to regulate the average walking rate to a continuum of values. The PI controller is active only in the (instantaneous) double support phase and achieves regulation by <b>adjusting</b> <b>key</b> parameters of the within-stride controller. I...|$|E
40|$|This paper {{addresses}} {{the control of}} a planar, biped robot with one degree of underactuation. Previous work has designed controllers that induce provably, exponentially stable, periodic walking motions at fixed, pre-determined walking rates. These controllers operate in continuous-time during the single support phase of the robot. The present paper shows how to design an event-based PI controller that provides an additional control feature: the ability to regulate the average walking rate to a continuum of values. The PI-controller is active only in the (instantaneous) double support phase and achieves regulation by <b>adjusting</b> <b>key</b> parameters of the in-stride controller...|$|E
40|$|Abstract—In this paper, a novel unified channel model {{framework}} is proposed for cooperative multiple-input multiple-output (MIMO) wireless channels. The proposed model {{framework is}} generic and adaptable to multiple cooperative MIMO scenarios by simply <b>adjusting</b> <b>key</b> model parameters. Based {{on the proposed}} model framework and using a typical cooperative MIMO communication environment as an example, we derive a novel geometry-based stochastic model (GBSM) applicable to multiple wireless propagation scenarios. The proposed GBSM is the first cooperative MIMO channel model that {{has the ability to}} investigate the impact of the local scattering density (LSD) on channel characteristics. From the derived GBSM, the corresponding multi-link spatial correlation functions are derived and numerically analyzed in detail. Index Terms—Cooperative MIMO channels, geometry-based stochastic model, spatial correlation, non-isotropic scattering...|$|E
30|$|ANS SON algorithm: This {{sub-function}} {{realizes the}} actual SON algorithm, which {{is able to}} automatically <b>adjust</b> <b>key</b> parameters, referred herein to as control parameters, which influence the ANS behavior. The adjustment follows dynamic changes in traffic, radio signal level, and radio interference situations. The sub-function is comprised of the Trigger block, which determines whether any adjustment of the control parameters is beneficial in the current time interval, and the control parameter adjustment block, which performs the actual adjustment. The control parameters adopted {{in this study are}} further discussed in Section 3.3, whereas the ANS SON algorithm is described in detail in Section 4.|$|R
40|$|I {{examined}} {{the effect of}} the conspecific mobbing call of the Red-backed Shrike (Lanius collurio) on nest defence against arial predator (kestrel). I used a playback experiment {{in the presence of a}} dummy of kestrel (Falco tinnunculus) in two variants either with nature look or with <b>adjusted</b> <b>key</b> features (pigeon beak, claws and eyes), and pigeon (Columba palumbus) as a control. Shrikes were attracted by the mobbing call and arrived to their nests faster. Only the modified kestrel was attacked more likely in the presence of the playback, that suggests possible function of the mobbing call as a cue for social learning of predator recognition...|$|R
6000|$|... "By all means." [...] Mr. Bucket skilfully {{and softly}} takes that precaution, stooping {{on his knee}} for a moment from mere force of habit so to <b>adjust</b> the <b>key</b> in the lock as that no one shall peep in from the outerside.|$|R
40|$|Abstract: This paper {{discusses}} {{a method}} for automatically generating summary slides from a text, studying the automatic generation of presentation slides from a technical paper and also examines the challenging task of continuously creating presentation slides from academic papers. The created slides {{can be used as}} a draft to help moderators setup their systematic slides in a quick manner. This paper introduces a novel system called PPSGen to help moderators create such slides. The system uses the backslide procedure to determine the Noteworthiness Score of the sentences in an educational paper and then uses the whole number Integer Linear Programming (ILP) system to create well-organized slides by selecting and <b>adjusting</b> <b>key</b> expressions and sentences. Evaluation results, based on a test game plan of 200 arrangements of papers and slides assembled on the web, display that our proposed PPSGen structure can create slides with better quality. A customer study also exhibits that PPSGen has obvious advantage over baseline methods...|$|E
40|$|This thesis will {{describe}} two functional Magnetic Resonance Imaging (fMRI) experiments and one Voxel-Based Morphometry (VBM) study, each investigating how {{the human brain}} identifies objects and their associated properties. In particular, we used three different categories of objects – living (animals), nonliving (tools and nontools) and faces (famous and non-famous) – to examine the type of knowledge attribute in question: one perceptual (movement) and two semantic attributes (typical object location and biographic knowledge). We know from neuropsychological literature that the most anterior portions of the temporal cortices critically support human conceptual knowledge. Unfortunately, the Anterior Temporal Lobe (ATL) is a challenging region for fMRI due to susceptibility artifacts, especially at high fields. For these reasons we established an optimized fMRI protocol (described in the second Chapter) by <b>adjusting</b> <b>key</b> acquisition parameters like phase-encoding gradient polarity, slice thickness, echo time, and slice angle. The protocol gave reliable Blood-Oxygen-Level Dependence (BOLD) signal sensitivity in the ATL...|$|E
40|$|This study {{concerns}} the modeling of non-linear {{operation of a}} silicon waveguide on an insulator of simox type with grating coupler in a dynamic regime, the simulation parameters are determined {{in accordance with the}} experiment, with the aim of achieving fast threshold optoelectronic switches. The optical non-linearities in the silicon are related to the change of the refractive index, and are used to obtain fast switching on the transmitted beam due to the propagation of the fundamental mode in the guide. The performances of these components are highly dependent of its rising time and its sensitivity. We will maximize the latter two. The model of non-linear operation of fast threshold optoelectronic switches are made in the dynamic regime based on the variations of the refractive index caused by both of the creation of free carriers and by the thermal effects due to the recombination of the carriers. This model allows, starting from the time variation of different diffracted intensities, to determine the operating range of the waveguide by <b>adjusting</b> <b>key</b> parameters such as: incident power density, the angular offset relative to the resonance...|$|E
50|$|The ink {{fountain}} holds {{a pool of}} ink and controls the amount of ink that enters the inking system. The {{most common type of}} fountain consists of a metal blade that is held in place near the fountain roller. The gap between the blade and the {{ink fountain}} roller can be controlled by <b>adjusting</b> screw <b>keys</b> to vary the amount of ink on the fountain roller. The printer <b>adjusts</b> the <b>keys</b> in or out as the ink fountain roller turns to obtain the desired quantity of ink. In simple presses, the printer must turn these screws by hand. In modern presses, the adjusting screws are moved by servomotors which are controlled by the printer at a press console. Thus the printer can make ink adjustments electronically. If the printer needs to increase or decrease ink in an area of the plate (print), he need only <b>adjust</b> the needed <b>keys</b> to allow more or less ink flow through the blade. The ink flow can also be controlled by the rotation velocity of the ink fountain roller.|$|R
40|$|This paper {{presents}} {{evidence that}} bank managers <b>adjust</b> <b>key</b> strategic variables following a risk and/or valuation {{signal from the}} stock market. Banks receive a risk signal when they exhibit substantially higher (semi-) volatility compared to the best performing bank(s) with similar characteristics, and a valuation signal when they are undervalued relative to the average bank with similar characteristics. We document, using a partial adjustment model, that bank managers adjust the long-term target value of key strategic variables and the speed of adjustment towards those targets following a risk and/or negative valuation signal. We interpret this as evidence of stock market influencing. We show that our results {{are unlikely to be}} driven by indirect influencing by regulators, subordinated debtholders, retail or wholesale depositors. Finally, we show that the likelihood that banks receive a risk and/or valuation signal increases with opaqueness, managerial discretion and specialization...|$|R
50|$|Torsion bar {{suspensions}} {{are used}} on combat vehicles and tanks like the T-72, Leopard 1, Leopard 2, M26 Pershing, M18 Hellcat, and the M1 Abrams (many tanks from World War II used this suspension), and on modern trucks and SUVs from Ford, Chrysler, GM, Mitsubishi, Mazda, Nissan, Isuzu and Toyota. Manufacturers change the torsion bar or <b>key</b> to <b>adjust</b> the ride height, usually {{to compensate for}} engine weight. While the ride height may be adjusted by turning the adjuster bolts on the stock torsion key, rotating the stock key too far can bend the adjusting bolt and place the shock piston outside its standard travel. Over-rotating the torsion bars can also cause the suspension to hit the bump-stop prematurely, causing a harsh ride. Aftermarket forged-metal torsion key kits use relocked <b>adjuster</b> <b>keys</b> to prevent over-rotation, and shock brackets to keep the piston travel in the stock range.|$|R
40|$|International audienceThe {{intermittent}} {{nature of}} renewable energy sources is a key challenge to their integration into the electricity grid. The aim {{of this paper is}} to introduce an advanced concept of Power-to-Gas (PtG) plant, which is designed to bring a closed-loop solution able to absorb electricity surplus and to restore it later, via the transient storage of energy carriers. After a brief conceptual overview of the studied unit and its individual components, the paper introduces the key results of the steady state model used to assess process flowsheets as well as operating conditions of the industrial scale unit. These results indicate that during the storage phase, a 200 MW power supply to the electrolysis process leads to a corresponding 155 MW of Synthetic Natural Gas (SNG) produced in a thermally integrated methanation process with an efficiency of 83. 1 %. By producing and storing enough amount of SNG and oxygen, an Oxy-combustion power plant can be subsequently used to recover up to 480 MW electric power as well as to produce CO 2 rich gas with an overall efficiency of 51. 8 %. Lastly, a thorough sensitivity analysis was conducted to show that the Electrolysis-Methanation-Oxy-combustion (EMO) unit performance can be further improved by <b>adjusting</b> <b>key</b> design parameters accordingly...|$|E
40|$|Pigeons {{were tested}} in a {{computer-controlled}} two-key chamber. A standard (nonchanging) schedule of reinforcement was in force on one key, and an adjusting schedule on the other. The schedules were available concurrently after each reinforcement, but after the first peck on either key (the choice peck), the schedule on the other key was made inoperative. The parameter of the adjusting schedule was decreased when the standard schedule was chosen and increased when the adjusting schedule was chosen. The standard schedule was changed only between sessions. Fixed intervals and fixed ratios were used as standard schedules, and intervals and ratios were used as adjusting schedules. When standard and adjusting schedules were of the same type, median parameters on the <b>adjusting</b> <b>key</b> equalled those of the standard schedules, at four values of each standard schedule. For four of five birds, and for the group median, similar curves could be plotted through the indifference points obtained from a standard ratio with an adjusting interval, and from a standard interval with an adjusting ratio. These points showed consistent individual differences, but they could be predicted by assuming that the median time from the choice peck to reinforcement {{should be the same}} on both keys. This is equivalent to treating the schedule as a concurrent chain and assuming that Herrnstein's quantitative law of effect applies...|$|E
40|$|Understanding {{interactions}} of genotype, environment, and management {{under field conditions}} is vital for selecting new cultivars and farming systems. Image analysis is considered a robust technique in high-throughput phenotyping with non-destructive sampling. However, analysis of digital field-derived images remains challenging because {{of the variety of}} light intensities, growth environments, and developmental stages. The plant canopy coverage (PCC) ratio is an important index of crop growth and development. Here, we present a tool, EasyPCC, for effective and accurate evaluation of the ground coverage ratio from a large number of images under variable field conditions. The core algorithm of EasyPCC is based on a pixel-based segmentation method using a decision-tree-based segmentation model (DTSM). EasyPCC was developed under the MATLAB® and R languages; thus, it could be implemented in high-performance computing to handle large numbers of images following just a single model training process. This study used an experimental set of images from a paddy field to demonstrate EasyPCC, and to show the accuracy improvement possible by <b>adjusting</b> <b>key</b> points (e. g., outlier deletion and model retraining). The accuracy (R 2 = 0. 99) of the calculated coverage ratio was validated against a corresponding benchmark dataset. The EasyPCC source code is released under GPL license with benchmark datasets of several different crop types for algorithm development and for evaluating ground coverage ratios...|$|E
30|$|Schofield ([2008]) {{sets out}} a mixed effects {{structural}} equations (MESE) model, which we employ {{here for the}} problem of <b>adjusting</b> our <b>key</b> regression (1) when we replace θ with a fallible test score. 3 The latent cognitive variable is a random effect and the IRT and linear model parameters are all fixed effects, {{so this is a}} “mixed effects” model.|$|R
40|$|Self-organization to {{ferromagnetic}} {{phase transition}} in cellular automata of spins governed by stochastic majority rule and when topology between spins is changed, is investigated numerically. Three types of edge rewiring are considered. The algorithm of Watts and Strogatz is applied at each time step {{to establish a}} network evolving stochastically (the first network). The preference functions are defined to amplify the role of strongly connected vertices (the second network). Demand to preserve graph connectivity provides the third way of edge rewiring. Each of these processes yields the different network: small-world, scattered nodes with one strongly connected component, and scale-free network when rewiring is properly adjusted. The stochastic majority rule applied to these networks can lead or not to ferromagnetic transition. Classical mean-field transition in case {{of the first and}} third network is observed. Scale-free ferromagnetic transition can be observed when rewiring is properly <b>adjusted.</b> <b>Key</b> words: stochastic majority rule, phase transition, small-world network, scale-free network...|$|R
40|$|Abstract—A novel type of {{ultra-wide band}} (UWB) crossed {{semi-ring}} monopole antenna with band notched characteristics is presented. The proposed antenna {{consists of a}} wideband crossed semi-ring monopole and four L-shaped slots, producing band-notched characteristic. Effects of the various parameters for antenna performances are discussed. The central frequency and bandwidth of the notched band can be controlled easily by <b>adjusting</b> three <b>key</b> design parameters. A prototype is constructed and measured finally...|$|R
40|$|Dual {{apprenticeship}} training is increasingly {{seen as an}} important educational track that provides youth with the skills necessary for a smooth transition into the labour market. However, providing skills at the workplace rather than at (vocational) school comes at a cost for firms that hire such apprentices. Nonetheless, as apprentices {{become part of a}} firm’s workforce, they also generate a benefit from working productively. This paper provides a theoretical framework and the latest empirical evidence about a firm’s costs and benefits that are associated with offering dual {{apprenticeship training}}. While many aspects of such training are determined by external factors such as government policies, training regulations, and labour market institutions, firms can still influence many other aspects. The available empirical evidence suggests that there is no single optimal model of dual apprenticeship training. However, given the differences in the institutional setting across countries, <b>adjusting</b> <b>key</b> framework conditions can allow training firms to generate a sufficiently high return on their training investments. The main parameters affecting the cost–benefit ratio are apprentice wages, amount of training provided at the workplace, apprenticeship duration, {{and the manner in which}} firms integrate apprentices into the production process (to perform both skilled and unskilled tasks). An important prerequisite to successful apprenticeships, however, is also an adequate supply of suitable apprentices, which in turn (among other factors) depends on the training quality at the workplace, certification of the acquired skills, and future wages and career opportunities from obtaining a vocational qualification...|$|E
40|$|The Direct Numerical Simulation (DNS) {{approach}} {{to solving the}} fundamental transport equations down to the smallest scales of motion is favorable should the requirement be a truly predictive solution of fluid dynamic problems, but the simulation run times are unacceptable for most practical industrial applications. Despite the steadily increasing computational capabilities, Reynolds Averaged Navier-Stokes (RANS) based frameworks remain the most commercially viable option for high volume sectors, like automotive. The sub models within RANS simplify the description of key physical phenomena and include several numerical constants. These so-called “tuning constants” introduce multivariable dependencies that are almost impossible to untangle with local sensitivity studies. This paper addresses the prevailing difficulties in setting up an adequate diesel spray simulation which arise from the mentioned multi-variable interactions of these “tuning constants”, by applying a statistical approach named Design of Experiments (DoE). Often combined with an optimizer, DoE is commonly used to find an optimum set of engine parameters for set criteria at reduced experimental effort. In this case, the methodology was applied to determine an optimal set of “tuning constants” for the simulations which best matched experimental data at five conditions taken from the Engine Combustion Network (ECN) database. Multi-variable DoE were run for each condition. Stochastic response models (SPM’s) highlighted crucial simulation sensitivities of the turbulent dissipation constant C 2 and liquid/gas-phase momentum transfer at injection pressure swings. Further, {{a comparison of the}} breakup models which produced matching simulations exhibited patterns which correspond with physical processes. Lastly, it was shown that while a single set of the constants can give reasonable results in the space explored, there is merit in <b>adjusting</b> <b>key</b> constants to suit the operating condition in the search for accuracy...|$|E
40|$|This thesis will {{describe}} two functional Magnetic Resonance Imaging (fMRI) experiments and one Voxel-Based Morphometry (VBM) study, each investigating how {{the human brain}} identifies objects and their associated properties. In particular, we used three different categories of objects – living (animals), nonliving (tools and nontools) and faces (famous and non-famous) – to examine the type of knowledge attribute in question: one perceptual (movement) and two semantic attributes (typical object location and biographic knowledge). We know from neuropsychological literature that the most anterior portions of the temporal cortices critically support human conceptual knowledge. Unfortunately, the Anterior Temporal Lobe (ATL) is a challenging region for fMRI due to susceptibility artifacts, especially at high fields. For these reasons we established an optimized fMRI protocol (described in the second Chapter) by <b>adjusting</b> <b>key</b> acquisition parameters like phase-encoding gradient polarity, slice thickness, echo time, and slice angle. The protocol gave reliable Blood-Oxygen-Level Dependence (BOLD) signal sensitivity in the ATL. Clinical data describe patients with specific semantic impairments {{at the level of}} category (living, nonliving) as well as disproportionate deficits for a modality or type of knowledge (e. g., visual/perceptual knowledge or manipulation knowledge). Functional neuroimaging studies on semantic organization with normal subjects found an “action network” specific for tools rather than living items. In the first experiment (Chapter 3) we devised an fMRI paradigm to investigate the processing of movement (action) and place (encyclopedic) features, and their influence on category-specific activations. Within the “movement network” statistical analyses did not show any significant interaction between categories. These findings suggest that the visuomotor “action network” is not specific for tools because it is also activated when the action related knowledge is elicited for other categories, such as animals. The second and the third experiment (Chapter 4) focus on the processing of faces. Neuropsychological literature attributes semantic and lexical retrieval deficits in patients to ATL lesions. In Part I of Chapter 4, we report data from a VBM study on patients with known lesions in the temporal lobe. Unfortunately, as far as we know, data on patients and functional neuroimaging in healthy individuals has not clarified the differential role of this area in the two mental operations because semantic and lexical processes usually occur simultaneously and automatically. In Part II, we devised an event-related fMRI activation paradigm that allowed us to study the identification (i. e., association of semantic biographical information) of celebrities, with and without the ability to retrieve the proper name. While semantic retrieval reliably activated the ATL, only more posterior areas in the left temporal and temporal-parietal junction were significantly modulated by covert lexical retrieval. These results support findings from patients with ATL lesions and suggest that their anomia is due to semantic rather than lexical retrieval impairment...|$|E
40|$|While {{there are}} many methods to measure the {{competitiveness}} of an economy, most of these concepts {{ignore the fact that}} competitiveness can change because of market processes like wage negotiation but also because of political decision-making. Governments that compete with others for factors of production face the incentive to <b>adjust</b> <b>key</b> policy variables to improve their competitive position. Disentangling market-induced and politics-induced changes in competitiveness is not easy, but strongly warranted given current discussions that some EMU Member States should improve their competitive position within the euro area by adjusting policy variables. Increasing country competitiveness {{is one of the key}} objectives currently discussed by policy makers in the context of creating an economic union in the euro area, to complement monetary union. We propose a new competitiveness index that captures the dimensions in which politics can influence competitiveness beyond factor price adjustments. Our index shows that the individual components of institutional competitiveness have developed heterogeneously among EMU Member States. To explain these divergent developments, the uneven integration within the EU Single Market may play a role...|$|R
40|$|Growth in {{the world}} economy appears to be {{continuing}} at a brisk rate. Recent forecasts suggest that output should expand by about 3 % this year compared with 3. IX in 1987. The outlook therefore appears to be more favourable than when we last reported; a reflection of the limited impact to date of the October stock market crash. Some {{progress has been made in}} <b>adjusting</b> the <b>key</b> trade imbalances but progress remains slow...|$|R
40|$|The {{impact of}} {{environmental}} change on animal populations is {{strongly influenced by}} the ability of individuals to plastically <b>adjust</b> <b>key</b> life-history events. There is therefore considerable interest in establishing the degree of plasticity in traits and how selection acts on plasticity in natural populations. Breeding time is a key life-history trait that affects fitness and recent {{studies have found that}} females vary significantly in their breeding time–environment relationships, with selection often favouring individuals exhibiting stronger plastic responses. In contrast, here, we show that although breeding time in the common guillemot, Uria aalge, is highly plastic at the population level in response to a large-scale environmental cue (the North Atlantic Oscillation, NAO), there is very little between-individual variation—most individuals respond to this climate cue very similarly. We demonstrate strong stabilizing selection against individuals who deviate from the average population-level response to NAO. This species differs significantly from those previously studied in being a colonial breeder, in which reproductive synchrony has a substantial impact on fitness; we suggest that counter selection imposed by a need for synchrony could limit individuals in their response and potential for directional selection to act. This demonstrates the importance of considering the relative costs and benefits of highly plastic responses in assessing the likely response of a population to the environmental change. ...|$|R
40|$|There is {{increasing}} {{recognition that the}} hydrology of the Greenland Ice Sheet {{plays an important role}} in the dynamics and therefore mass balance of the ice sheet. Understanding the hydrology of the ice sheet and being able to predict its future behaviour is therefore a key aspect of glaciological research. To date, the ice sheet’s hydrology has tended to be inferred from the analysis of surface velocity measurements, or modelled in a theoretical, idealised way. This study focuses on the development of a high spatial (100 m) and temporal (1 hour) resolution, physically based, time-dependent hydrological model which is applied to the ~ 2, 300 km 2 Paakitsoq region, West Greenland, and is driven, calibrated, and evaluated using measured data. The model consists of three components. First, net runoff is calculated across the ice sheet from a distributed, surface energy- balance melt model coupled to a subsurface model, which calculates changes in temperature, density and water content in the snow, firn and upper-ice layers, and hence refreezing. The model is calibrated by <b>adjusting</b> <b>key</b> parameter values to minimize the error between modelled output and surface height and albedo measurements from the three Greenland Climate Network (GC-Net) stations, JAR 1, JAR 2 and Swiss Camp. Model performance is evaluated in two ways by comparing: i) modelled snow and ice distribution with that derived from Landsat- 7 ETM+ satellite imagery using Normalised Difference Snow Index (NDSI) classification and supervised image thresholding; and ii) modelled albedo with that retrieved from the Moderate- resolution Imaging Spectroradiometer (MODIS) sensor MOD 10 A 1 product. Second, a surface routing / lake filling model takes the time-series of calculated net runoff over the ice sheet and calculates flow paths and water velocities over the snow / ice covered surface, routing the water into ‘open’ moulins or into topographic depressions which can fill to form supraglacial lakes. This model component is calibrated against field measurements of a filling lake in the study area made during June 2011. Supraglacial lakes are able to drain by a simulated hydrofracture mechanism if they reach a critical volume. Once water is at the ice / bed interface, discharge and hydraulic head within subglacial drainage pathways are modelled using the third model component. This consists of an adaptation of a component (EXTRAN) of the U. S. Environmental Protection Agency Storm Water Management Model (SWMM), modified to allow for enlargement and closure of ice-walled conduits. The model is used to identify how the subglacial hydrological system evolves in space and time in response to varying surface water inputs due to melt and lake drainage events, driven ultimately by climate data. A key output from the model is the spatially and temporally varying water pressures which are of interest in helping to explain patterns of surface velocity and uplift found by others, and will ultimately be of interest for driving ice dynamics models. Natural Environment Research Council Doctoral Training Gran...|$|E
40|$|Abstract—A new {{modeling}} method for DC-DC converter based on Cadence platform and Verilog-A is proposed in this paper. It provides a continuous-time model for system design, {{in which the}} transistor-level power stage, the compensation network and the error amplifier could be put together in, therefore provides accurate prediction of system loop transfer function frequency response. In addition, the properly <b>adjusted</b> transistor-level <b>key</b> building blocks in the proposed continuous-time model can be directly used in the later all transistor-level system, {{which leads to a}} seamless design flow within the Cadence design platform...|$|R
40|$|Due to the {{character}} of the original source materials and the nature of batch digitization, quality control issues may be present in this document. Please report any quality issues you encounter to digital@library. tamu. edu, referencing the URI of the item. Includes bibliographical references (leaves 43 - 44). In the traditional study of queueing theory, a typical ics. assumption is that the server is not subject to failures. This assumption, however, is not realistic for modeling many queueing systems in practice. Since the late 1950 's, there has been research into finding exact or approximate methods that <b>adjust</b> <b>key</b> performance measures of a system to reflect server failures. Many of the methods that have been developed suffer either from a high degree of computational complexity or from tight restrictions on possible system structures feasible for the particular method. In this thesis, an approximation method is formulated which allows for a general system structure (i. e. the distributions for arrival, service, failure, and repair times are arbitrary), and yet maintains computational simplicity and efficiency. This method will be obtained through the implementation of a stationary delayed renewal process and simple modifications of common approximation formulas for a G/G/m queue. Through experimentation, approximated values are compared to exact values, and system structures that tend to induce error are identified...|$|R
40|$|The {{problem of}} {{identifying}} and repairing data errors {{has been an}} area of persistent focus in data management research. However, while tra-ditional data cleaning techniques can be effective at identifying sev-eral data discrepancies, they disregard {{the fact that many}} errors are systematic, inherent to the process that produces the data, and thus will keep occurring unless the root cause is identified and corrected. In this demonstration, we will present a large-scale diagnostic framework called DATAXRAY. Like a medical X-ray that aids the diagnosis of medical conditions by revealing problems underneath the surface, DATAXRAY reveals hidden connections and common properties among data errors. Thus, in contrast to traditional clean-ing methods, which treat the symptoms, our system investigates the underlying conditions that cause the errors. The core of DATAXRAY combines an intuitive and principled cost model derived by Bayesian analysis, and an efficient, highly-parallelizable diagnostic algorithm that discovers common proper-ties among erroneous data elements in a top-down fashion. Our system has a simple interface that allows users to load different datasets, to interactively <b>adjust</b> <b>key</b> diagnostic parameters, to ex-plore the derived diagnoses, and to compare with solutions produced by alternative algorithms. Through this demonstration, participants will understand (1) the characteristics of good diagnoses, (2) how and why errors occur in real-world datasets, and (3) the distinctions with other related problems and approaches. 1...|$|R
60|$|Leaving Mrs Gamp {{in the act}} {{of repeating}} all she had been told, and of {{producing}} in support of her memory and trustworthiness, many commendations selected from among the most remarkable opinions of the celebrated Mrs Harris, he descended to the little room prepared for him, and pulling off his coat and his boots, put them outside the door before he locked it. In locking it, he was careful so to <b>adjust</b> the <b>key</b> as to baffle any curious person who might try to peep in through the key-hole; and when he had taken these precautions, he sat down to his supper.|$|R
30|$|The {{prevalence}} of vitamin D deficiency was 74  % (95  % CI: 65 – 88). The median (IQR) duration of ICU stay was significantly longer in ‘vitamin D deficient’ children (7  days; 2 – 12) {{than in those}} with ‘no vitamin D deficiency’ (3  days; 2 – 5; p =  0.006). On multivariable analysis, the association between length of ICU stay and vitamin D deficiency remained significant, even after <b>adjusting</b> for <b>key</b> baseline variables, diagnosis, illness severity (PIM- 2), PELOD, and need for fluid boluses, ventilation, inotropes and mortality [adjusted mean difference (95  % CI): 3.5  days (0.50 – 6.53); p =  0.024].|$|R
