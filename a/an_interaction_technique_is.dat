6|10000|Public
5000|$|From the user's perspective, <b>an</b> <b>interaction</b> <b>technique</b> <b>is</b> a way {{to perform}} a single {{computing}} task and can be informally expressed with user instructions or usage scenarios. For example, [...] "to delete a file, right-click on the file you want to delete, then click on the delete item".|$|E
50|$|From {{the user}} {{interface}} designer's perspective, <b>an</b> <b>interaction</b> <b>technique</b> <b>is</b> a well-defined {{solution to a}} specific user interface design problem. Interaction techniques as conceptual ideas can be refined, extended, modified and combined. For example, contextual menus are {{a solution to the}} problem of rapidly selecting commands. Pie menus are a radial variant of contextual menus. Marking menus combine pie menus with gesture recognition.|$|E
40|$|Session: Multimodal interfacesInternational audienceA large {{variety of}} gestural {{interaction}} techniques based on accelerometers is now available. In this article, we propose a new taxonomic space as a systematic structure {{for supporting the}} comparative analysis of these techniques {{as well as for}} designing new ones. <b>An</b> <b>interaction</b> <b>technique</b> <b>is</b> plotted as a point in a space where the vertical axis denotes the semantic coverage of the techniques, and the horizontal axis expresses the physical actions users are engaged in, i. e. the lexicon. In addition, syntactic modifiers are used to express the interpretation process of input tokens into semantics, as well as pragmatic modifiers to make explicit the level of indirection between users' actions and system responses. To demonstrate the coverage of the taxonomy, we have classified 25 interaction techniques based on accelerometers. The analysis of the design space per se reveals directions for future research...|$|E
40|$|Knowledge-based {{authentication}} (e. g. passwords) {{has long}} been associated with a vulnerability to shoulder surfing; being stolen by attackers overlooking the interaction. In order to combat such threats, steps {{can be taken to}} either alter the form of the challenge made to the user, or make use of <b>an</b> <b>interaction</b> <b>technique</b> that <b>is</b> resistant to information leakage. We consider the latter, and empirically evaluate th...|$|R
40|$|We present <b>an</b> <b>interaction</b> <b>technique</b> {{which could}} <b>be</b> used {{to ease the}} {{well-known}} problem of browsing large interface surfaces [...] -in particular web pages [...] -on small screen devices. A prototype implementation is introduced and discussed, turning some of the traditional notions of direct manipulation inside-out...|$|R
40|$|In {{this paper}} a mixed Eulerian-Lagrangian {{approach}} for the modelling metal extrusion processes is presented. The approach involves {{the solution of}} non-Newtonian fluid flow equations in an Eulerian context, using a free-surface algorithm to track the behaviour of the workpiece and its extrusion. The solid mechanics equations associated with the tools are solved in Lagangrian context. Thermal interactions between the workpiece are modelled and <b>a</b> fluid-structure <b>interaction</b> <b>technique</b> <b>is</b> employed to model {{the effect of the}} fluid traction load imposed by the workpiece on the tools. Two extrusion test cases are investigated and the results obtained show the potential of the model with regard to representing the physics of the process and the simulation time...|$|R
40|$|A large {{variety of}} gestural {{interaction}} techniques based on accelerometers is now available. In this article, we propose a new taxonomic space as a systematic structure for support-ing the comparative {{analysis of these}} techniques {{as well as for}} designing new ones. <b>An</b> <b>interaction</b> <b>technique</b> <b>is</b> plotted as a point in a space where the vertical axis denotes the se-mantic coverage of the techniques, and the horizontal axis expresses the physical actions users are engaged in, i. e. the lexicon. In addition, syntactic modifiers are used to express the interpretation process of input tokens into semantics, as well as pragmatic modifiers to make explicit the level of in-direction between users â€™ actions and system responses. To demonstrate the coverage of the taxonomy, we have classi-fied 25 interaction techniques based on accelerometers. The analysis of the design space per se reveals directions for fu-ture research. Author Keywords Handheld devices and mobile computing, Input and interac...|$|E
40|$|This article {{mentions}} some of {{the technical}} background for this area, surveys the range of input devices currently in use and emerging, and considers future trends in input. Background A designer looks at the interaction tasks necessary for a particular application [3]. Interaction tasks are low-level primitive inputs required from the user, such as entering a text string or choosing a command. For each such task, the designer chooses an appropriate interaction device and interaction technique. <b>An</b> <b>interaction</b> <b>technique</b> <b>is</b> a way of using a physical device to perform an interaction task. There may be several different ways of using the same device to perform the same task. For example, one could use a mouse to select a command by using a pop-up menu, a fixed menu (or palette), multiple clicking, circling the desired command, or even writing {{the name of the}} command with the mouse. - 2 - User performance with many types of manual input depends on the speed with w...|$|E
40|$|In this {{position}} {{paper we discuss}} the usage of various interaction technologies with focus on the presentations of 3 D visualizations involving a presenter and an audience. While <b>an</b> <b>interaction</b> <b>technique</b> <b>is</b> commonly evaluated from a user perspective, we want to shift the focus from a sole analysis of the naturalness and the ease-of-use for the user, to focus on how expressive and understandable the interaction technique is when witnessed by the audience. The interaction process itself can {{be considered to be}} a communication channel and a more expressive interaction technique might {{make it easier for the}} audience to comprehend the presentation. Thus, while some natural interaction techniques for interactive visualization are easy to perform by the presenter, they may be less beneficial when interacting with the visualization in front of (and for) an audience. Our observations indicate that the suitability of an interaction technique as a communication channel is highly dependent on the setting in which the interaction takes place. Therefore, we analyze different presentation scenarios in an exemplary fashion and discuss how beneficial and comprehensive the involved techniques are for the audience. We argue that interaction techniques complement the visualization in an interactive presentation scenario as they also serve as an important communication channel, and should therefore also be observed from an audience perspective rather than exclusively a user perspective...|$|E
40|$|In {{this paper}} we will present <b>an</b> <b>interaction</b> <b>technique</b> that may <b>be</b> {{used to teach}} simple {{geometric}} shapes to visually impaired peo-ple. The idea {{is to use a}} VTPlayer mouse- a device with two braille displays- and by using directional cues on the braille display of the mouse, we guide the user to describe a path with his hand. Then, we think the user will be able to learn a shape, and recognize it later on...|$|R
40|$|Abstract. Touch screen mobile {{devices are}} highly {{flexible}} and customizable, allowing designers to create inclusive user interfaces that are accessible {{to a broader}} user population. However, the knowledge to provide this new generation of user interfaces {{is yet to be}} uncovered. Our goal is to thoroughly study mobile touch interfaces, thus providing the tools for informed design. We present an evaluation performed with 15 tetraplegic and 18 able-bodied people that allowed us to identify their main similarities and differences within <b>a</b> set of <b>interaction</b> <b>techniques</b> (Tapping, Crossing, and Directional Gesturing) and parameterizations. Results show that despite the expected error rate disparity, there are clear resemblances, thus enabling the development of inclusive touch interfaces. Tapping, <b>a</b> traditional <b>interaction</b> <b>technique,</b> <b>was</b> among the most effective for both target populations, along with Crossing. The main difference concerns Directional Gesturing that in spite of its unconstrained nature shows to be inaccurate for motor impaired users...|$|R
40|$|This study {{focuses on}} {{quantifying}} {{the change in}} phase speed of waves transmitting through periodically undulated plates under pass band <b>interaction.</b> <b>A</b> perturbation <b>technique</b> <b>is</b> {{used to analyze the}} transmission of horizontally polarized guided waves in elastic plates with sinusoidal periodicity at their outerfaces. Phase speed of transmitting modes is presented as a function of various parameters, including outerface wavenumber, undulation amplitude, degree of undulations symmetry about the periodically undulated plate midplane, plate average thickness, arid frequency of propagation...|$|R
40|$|Lung {{radiotherapy}} {{is greatly}} benefitted when the tumor motion caused by breathing can be modeled. The {{aim of this}} paper is to present the importance of using anisotropic and subject-specific tissue elasticity for simulating the airflow inside the lungs. A computational-fluid-dynamics (CFD) based approach is presented to simulate airflow inside a subject-specific deformable lung for modeling lung tumor motion and the motion of the surrounding tissues during radiotherapy. <b>A</b> flow-structure <b>interaction</b> <b>technique</b> <b>is</b> employed that simultaneously models airflow and lung deformation. The lung is modeled as a poroelastic medium with subject-specific anisotropic poroelastic properties on a geometry, which was reconstructed from four-dimensional computed tomography (4 DCT) scan datasets of humans with lung cancer. The results include the 3 D anisotropic lung deformation for known airflow pattern inside the lungs. The effects of anisotropy are also presented on both the spatiotemporal volumetric lung displacement and the regional lung hysteresis...|$|R
40|$|<b>A</b> local inviscid-viscous <b>interaction</b> <b>technique</b> <b>was</b> {{developed}} {{for the analysis of}} low speed airfoil leading edge transitional separation bubbles. In this analysis an inverse boundary layer finite difference analysis is solved iteratively with a Cauchy integral representation of the inviscid flow which is assumed to be a linear perturbation to a known global viscous airfoil analysis. Favorable comparisons with data indicate the overall validity of the present localized interaction approach. In addition numerical tests were performed to test the sensitivity of the computed results to the mesh size, limits on the Cauchy integral, and the location of the transition region...|$|R
40|$|License, which permits {{unrestricted}} use, distribution, {{and reproduction}} in any medium, provided the original work is properly cited. Lung radiotherapy is greatly benefitted when the tumor motion caused by breathing can be modeled. The {{aim of this}} paper is to present the importance of using anisotropic and subject-specific tissue elasticity for simulating the airflow inside the lungs. A computational-fluid-dynamics (CFD) based approach is presented to simulate airflow inside a subject-specific deformable lung for modeling lung tumor motion and the motion of the surrounding tissues during radiotherapy. <b>A</b> flow-structure <b>interaction</b> <b>technique</b> <b>is</b> employed that simultaneously models airflow and lung deformation. The lung is modeled as a poroelastic medium with subject-specific anisotropic poroelastic properties on a geometry, which was reconstructed from four-dimensional computed tomography (4 DCT) scan datasets of humans with lung cancer. The results include the 3 D anisotropic lung deformation for known airflow pattern inside the lungs. The effects of anisotropy are also presented on both the spatiotemporal volumetric lung displacement and the regional lung hysteresis. 1...|$|R
40|$|There is {{a growing}} need for {{visualizing}} heterogeneous social networks as new data sets become available. However, the existing visualization tools do not address the challenge of reading topological information introduced by heterogeneous node and link types. To resolve this issue, we introduce glyphs to node-link diagrams to conveniently represent the multivariate nature of heterogeneous node and link types. This provides the opportunity to visually reorganize topological information of the heterogeneous social networks without losing connectivity information. Moreover, <b>a</b> set of <b>interaction</b> <b>techniques</b> <b>are</b> provided to the analyst to give total control over the reorganization process. Finally, a case study is presented to using InfoVis 2008 data set to show the exploration process...|$|R
40|$|The {{inferred}} mode protocol uses contextual {{reasoning and}} local mediators {{to eliminate the}} need to access specic modes to perform draw, select, move and delete operations in a sketch interface. This thesis describe an observational experiment to understand the learn- ability, user preference and frequency of use of mode inferencing in a sketch appli- cation. Novel methodology is presented to study both quantitative and long term qualitative facets of mode inferencing. The experiment demonstrated that participants instructed in the in- terface features enjoyed fluid transitions between modes. <b>As</b> well, <b>interaction</b> <b>techniques</b> <b>were</b> not self-revealing: Participants who were not instructed in <b>interaction</b> <b>techniques</b> took longer to learn about inferred mode features and were more negative about the <b>interaction</b> <b>techniques.</b> Over multiple sketching sessions, as users develop expertise with the system, they combine inferred mode <b>techniques</b> to speed <b>interaction,</b> and frequently make use of scratch space on the display to retrain themselves and to tune their behaviors. Lastly, post- task interviews outline impediments to discoverability and how performance is affected by negative perceptions around computational intelligence. The results of this work inform the design of sketch interface techniques that incorporate noncommand features...|$|R
5000|$|In {{fluorescence}} microscopy, colocalization {{refers to}} {{observation of the}} spatial overlap between two (or more) different fluorescent labels, each having a separate emission wavelength, {{to see if the}} different [...] "targets" [...] are located in the same area of the cell or very near to one another. The definition can be split into two different phenomena, co-occurrence, which refers to the presence of two (possibly unrelated) fluorophores in the same pixel, and correlation, a much more significant statistical relationship between the fluorophores indicative of <b>a</b> biological <b>interaction.</b> This <b>technique</b> <b>is</b> important to many cell biological and physiological studies during the demonstration of a relationship between pairs of bio-molecules.|$|R
40|$|Numerical {{solutions}} are presented for the laminar and turbulent boundary-layer equations for incompressible flows with separation and reattachment. The separation angularity is avoided {{by using an}} inverse technique in which the displacement thickness is prescribed and the pressure is deduced from the resulting solution. The turbulent results appear qualitatively correct despite {{the use of a}} two-layer eddy-viscosity model which is generally assumed appropriate only for mild-pressure-gradient flows. <b>A</b> new viscous-inviscid <b>interaction</b> <b>technique</b> <b>is</b> presented in which the inviscid flow is solved inversely by prescribing the pressure from the boundary-layer solution and deducing the new displacement thickness from the solution of a Cauchy integral. Calculations are presented using this <b>interaction</b> procedure for <b>a</b> laminar flow in which separation and reattachment occur on a solid surface...|$|R
40|$|This project {{deals with}} {{interaction}} across multiple devices in mobile computing envi-ronments, and will investigate {{the use of}} spatial information to support such <b>interactions.</b> Therefore <b>a</b> variety of application scenarios is considered, which involve spatially co-located devices, objects, or people. The general research aim is to understand how such interac-tions can be supported with spatial information, {{that is how the}} devices are positioned and oriented with respect to each other. The first task is a thorough research of existing literature to identify prior work on mobile interactions that involve the use of spatial information. Based on this survey, a classification of spatial concepts is developed. Afterwards the focus is shifted to actions, which are triggered under spatial conditions. To simplify the development of such appli-cations, a toolkit is designed and implemented. Finally, <b>a</b> new <b>interaction</b> <b>technique</b> <b>is</b> introduced, which is also based on spatial criteria. It involves small windows called gate-ways, which appear {{on the edge of the}} screen to represent a co-located device. By clicking on the gateway or dropping a file on it, the user is able to interact with the co-located device in an intuitive and easy way. The gateway <b>interaction</b> <b>technique</b> <b>was</b> evaluated in <b>a</b> user study. To ensure that the results are not limited by the capabilities of any particular sensor system, the Wizard of Oz approach was used to simulate the positioning system. Zusammenfassun...|$|R
40|$|Figure 1 : The {{inferred}} mode protocol. Panel a. shows smart circle select. When {{an object}} is circled, a mediator appears (top), but no mediator appears if the circle encloses nothing. Panel b. shows smart select click. Panel c. shows smart delete (top) and shading (bottom). Panel d. shows translation (top) vs smart drawing (bottom). The inferred mode protocol uses contextual reasoning and local mediators {{to eliminate the}} need to access specific modes to perform draw, select, move and delete operations in a sketch interface. In this paper, we describe an observational experiment to understand the learnability â€“ whether the features are discovered independently â€“ and the usability â€“ user preference and frequency of use â€“ of mode inferencing within a tablet-based sketch application. The experiment showed that those participants instructed in the interface features liked the fluid transitions between draw and lasso selection, but did not like click-select and delete inferencing. <b>As</b> well, <b>interaction</b> <b>techniques</b> <b>were</b> not self-revealing: Participants who were not instructed in <b>interaction</b> <b>techniques</b> took longer to learn about inferred mode features and were more negative about the <b>interaction</b> <b>techniques.</b> Together these results inform the future design of pen/tablet interfaces that seek {{to make use of}} computational intelligence in support of interaction. Author Keywords inferred mode, sketch interface, pen, tablet, stylu...|$|R
40|$|Abstract. <b>A</b> new <b>interaction</b> {{integral}} <b>technique</b> <b>is</b> derived for computation of mixed-mode {{stress intensity}} factors (SIFs) in nonhomogeneous materials with continuous or discontinuous properties. This method {{is based on}} a conservation integral that relies on two admissible mechanical states (actual and auxiliary fields). In the equivalent domain formulation, the integrand does not involve any derivatives of material properties. Moreover, the formulation is proved to be still valid when the integral domain contains material interfaces. Therefore, its applicable range is greatly enlarged. The method is combined with the extended finite element method (XFEM) to calculate the SIFs for different integral domains. Numerical results show that the interaction integral has excellent convergence for material nonhomogeneity and discontinuity...|$|R
40|$|Abstract. This paper {{presents}} <b>a</b> new <b>interaction</b> <b>technique,</b> which <b>is</b> {{based on}} arm posture recognition, for mobile computing devices to switch between dif-ferent visualization modes seamlessly. We implemented a pedestrian navigation system on Pocket PC, which {{is connected to}} a GPS receiver and an inertial ori-entation tracker. In the global coordinate system, userâ€™s position is tracked with GPS data, and in the local coordinate system userâ€™s arm posture is mapped into two application dependent states with inertial orientation tracker data. Hence, natural interaction and different levels of information is provided by processing orientation tracker data. As unnecessary computation and rendering increase power consumption in small devices, we introduced another state to our system, which saves battery according to the userâ€™s idle arm posture...|$|R
40|$|Mobile {{devices are}} being used to benefit a variety of {{personal}} and working environments. One potential working environment is newspaper distribution, where mental tiredness during night-time working hours can result in loss of efficiency and motivation. Reading the addresses manually from the address book whilst simultaneously keeping track of the subscriberâ€™s newspaper preferences and delivering them to the right door increases the cognitive load on the distributor and can lead to early exhaustion. Distributors could benefit from the automation of their manual home address book by having its electronic version on their mobile devices. However, merely automating the manual book keeping does not decrease the required visual attention during the work. Incorporating multimodality decreases the cognitive load on the distributors and makes the system more usable, allowing them to complete their job efficiently and accurately. A prototype system of the presented solution was developed and tested in a real working environment to prove its feasibility. <b>A</b> new <b>interaction</b> <b>technique</b> <b>was</b> introduced combining simple gesture recognition for accelerometer equipped mobile devices, as well as providing auditory and haptic feedback for the distributor. An intermediate comparative study between manual distribution and presented solution was made in order to measure the usefulness of the system in the context of time and efficiency. The feedbac...|$|R
40|$|Dendronized polyferrocenylsilanes were {{synthesized}} by a substitution {{reaction of}} reactive poly-(ferrocenylchloromethylsilane) with monodendrons with a focal hydroxy group. The resulting dendronized polymers were studied by 1 H NMR, {{differential scanning calorimetry}} (DSC), and polarized optical microscopy (POM). To facilitate the direct visualization of single polymer chains by atomic force microscopy (AFM), <b>an</b> <b>interaction</b> chromatography <b>technique</b> (IC) <b>was</b> used to fractionate the polydisperse polymers to separate the high molecular weight dendronized PFSs. AFM studies of the fractionated high molecular weight PFSs revealed a spherical cocoon for the single chains of the dendronized polymer as well as elongated single-chain structures. The cocoon of the dendronized PFS could be interesting as a unimolecular micelle with the transition-metal-rich core which is isolated by the dense outer layer of the dendrons. close 181...|$|R
40|$|Part 1 : Long and Short Papers (Continued) International audienceThis paper {{examines}} webcam-enabled {{head tracking}} for {{games in a}} home setting. <b>A</b> new head <b>interaction</b> <b>technique</b> <b>was</b> developed based upon prior laboratory-based research, {{with a focus on}} making it robust to the variable conditions of a home setting. Our <b>technique</b> <b>was</b> integrated into a test-bed game and 550 hours of gameplay data was collected from 2500 users, many of whom also provided formal feedback. The head tracking performed creditably and players reported that the experience was more immersive. Head tracking failed to enhance competitive playing performance, perhaps owing to familiarization effects. Nevertheless, the data revealed evidence of learning amongst users, suggesting that performance would improve with continued use. Key lessons that emerged in the home setting in contrast to the earlier laboratory study were a demonstrated need for clear guidance and feedback during system set-up, and greater caution regarding its deployment, having discovered a small population of users who became nauseous...|$|R
40|$|Abstract. This paper {{examines}} webcam-enabled {{head tracking}} for {{games in a}} home setting. <b>A</b> new head <b>interaction</b> <b>technique</b> <b>was</b> developed based upon prior laboratory-based research, {{with a focus on}} making it robust to the variable conditions of a home setting. Our <b>technique</b> <b>was</b> integrated into a test-bed game and 550 hours of gameplay data was collected from 2500 users, many of whom also provided formal feedback. The head tracking performed creditably and players reported that the experience was more immersive. Head tracking failed to enhance competitive playing performance, perhaps owing to familiarization effects. Nevertheless, the data revealed evidence of learning amongst users, suggesting that performance would improve with continued use. Key lessons that emerged in the home setting in contrast to the earlier laboratory study were a demonstrated need for clear guidance and feedback during system set-up, and greater caution regarding its deployment, having discovered a small population of users who became nauseous...|$|R
40|$|In {{this paper}} {{we present a}} novel {{framework}} for the integration of visual sensor networks and speech-based interfaces. Our proposal follows the standard reference architecture in fusion systems (JDL), and combines different techniques related to Artificial Intelligence, Natural Language Processing and User Modeling to provide <b>an</b> enhanced <b>interaction</b> with their users. Firstly, the framework integrates a Cooperative Surveillance Multi-Agent System (CS-MAS), which includes several types of autonomous agents working in a coalition to track and make inferences on {{the positions of the}} targets. Secondly, enhanced conversational agents facilitate human-computer interaction by means of speech <b>interaction.</b> Thirdly, <b>a</b> statistical methodology allows modeling the user conversational behavior, which is learned from an initial corpus and improved with the knowledge acquired from the successive <b>interactions.</b> <b>A</b> <b>technique</b> <b>is</b> proposed to facilitate the multimodal fusion of these information sources and consider the result for the decision of the next system action. </p...|$|R
40|$|School {{library and}} youth {{services}} professionals must develop and display {{a strong sense}} of cultural competence to effectively serve their patrons. Cultural competence is defined here as oneâ€™s ability to understand the needs of populations different from their own. This paper reports on the perceptions of school library and youth services students about how well their library and information sciences (LIS) coursework has prepared them to become culturally competent library practitioners. An electronic survey was used to collect data from matriculating LIS students. The survey contained a Likert scale measuring three areas of cultural competence: self-awareness, education, and <b>interaction.</b> <b>A</b> gap-analysis <b>technique</b> <b>was</b> employed to detect discrepancies between studentsâ€™ prior knowledge and actual learning relative to cultural competence. By focusing on the responses from students enrolled in school library and youth services concentrations, this study may help both school library and youth services educators and practitioners consider implementing more culturally sensitive curriculum and pedagogical reforms...|$|R
40|$|The {{objective}} {{of this study was}} to evaluate the potential usage, benefits, and limitations of using 3 D graphics in an interactive exploration of multi-dimensional dairy data. A software prototype was, therefore, designed, consisting of two modules: a histogram to view joint frequency distributions for two dimensions of the data set at a time; and a scatter plot to explore clouds of data points plotted along three dimensions. <b>A</b> number of <b>interaction</b> <b>techniques</b> <b>were</b> implemented including chart zooming and translation, brushing of chart objects to display details, rapid attribute selection per chart coordinate, and dynamic data filtering. Chart rotation was implemented in order to analyze the 3 D representations optimally. The feasibility of developing such prototypes was demonstrated in terms of data access, filtering, flexibility, and functionality under standard personal computer resources. However, performance tests with the 3 D scatter plot revealed that in order for smooth interactions to occur, data needed to be limited to a few thousand records. The two resulting modules were seen as potentially useful in the support of various on-farm decision-making activities including the monitoring of cow performance for the most recent milk test, and the benchmarking of herd performance, based on annual economics and milk recording dat...|$|R
40|$|Actas de: CAEPIA 2013, Congreso federado Agentes y Sistemas Multi-Agente: de la TeorÃ­a a la PrÃ¡ctica (ASMas). Madrid, 17 - 20 Septiembre 2013. In {{this paper}} {{we present a}} multi-agent {{architecture}} for the integration of visual sensor networks and speech-based interfaces. The proposed architecture combines different techniques related to Artificial Intelligence, Natural Language Processing and User Modeling to provide <b>an</b> enhanced <b>interaction</b> with their users. Firstly, the architecture integrates a Cooperative Surveillance Multi-Agent System (CS-MAS), which includes several types of autonomous agents working in a coalition to track and make inferences on {{the positions of the}} targets. Secondly, the proposed architecture incorporates enhanced conversational agents to facilitate human-computer interaction by means of speech <b>interaction.</b> Thirdly, <b>a</b> statistical methodology allows to model the user conversational behavior, which is learned from an initial corpus and posteriorly improved with the knowledge acquired from the successive <b>interactions.</b> <b>A</b> <b>technique</b> <b>is</b> proposed to facilitate the multimodal fusion of these information sources and consider the result for the decision of the next system action. This work {{was supported in part by}} Projects MINECO TEC 2012 - 37832 -C 02 - 01, CICYT TEC 2011 - 28626 -C 02 - 02, CAM CONTEXTS (S 2009 /TIC- 1485). Publicad...|$|R
40|$|In {{this paper}} we {{investigate}} <b>a</b> new <b>interaction</b> <b>technique</b> that enables users to capture You-Are-Here maps using their smartphone, and then manipulate the captured image {{in such a}} way that it can be used for navigation purposes. This technique utilises groups of similar You-Are-Here maps, which we call map constellations. Results from our field study, in which we tested a working prototype of our <b>interaction</b> <b>technique,</b> <b>are</b> presented. The results show an insight into users' views towards the <b>interaction,</b> and the <b>techniques</b> they employed to identically frame two You-Are-Here maps using a smartphone camera...|$|R
5000|$|From the computer's perspective, <b>an</b> <b>interaction</b> <b>technique</b> involves: ...|$|R
40|$|This study {{introduced}} <b>an</b> <b>interaction</b> <b>technique</b> {{that used}} tangible interaction for 3 D modeling. <b>A</b> hybrid <b>interaction</b> <b>technique</b> using <b>a</b> Kinect {{camera and a}} smartphone with a gyroscope was developed for the navigating objects in a 3 D modeling software. It was then tested on 20 participants categorized as amateurs who had basic 3 D/ CAD modeling experience and 20 participants categorized as the experts who had extensive experience working with the modeling software. This research study presents the need for existence of such <b>interaction</b> <b>technique,</b> gaps from the related previous studies, statistical findings from the current study and possible reasons for the results. The results concluded that the even though the hybrid <b>interaction</b> <b>technique</b> <b>was</b> efficient for both the participant categories and though there existed a statistical significance in efficiency for the amateur category, it did not provide a better user experience for the expert category and user experience for the amateur category was inconclusive. The study suggests that future studies and fine tuning {{of the current study}} could {{have a positive effect on}} the beginners in 3 D modeling without causing a major impact for the experts. ...|$|R
40|$|The {{research}} and development of <b>interaction</b> <b>techniques</b> <b>is</b> currently hindered by inadequate programming abstractions and the lack of an unifying framework, thus requiring low-level programming and a laborious cycle of compiling and testing code. This research project introduces a structural framework for the development of interaction objects to be used in a 2 D or 3 D environment. Interaction objects {{can be thought of as}} software "agents " that recognize and respond to interactive gestures. Each <b>interaction</b> object supports <b>an</b> <b>interaction</b> <b>technique,</b> and several <b>interaction</b> objects ran res 1 lOnd to a single interactive gesture in different ways. The design of the structural framework strives to satisfy four research objectives: separability, generality, flexibility, and usability. An initial implementation, described in detail in the appendix, shows promise for the viability of this design and helps identify areas fo...|$|R
40|$|Mixed-reality {{games have}} the {{potential}} to let users play in the world surrounding them. However, to exploit this new approaches to game content creation, content presentation <b>techniques</b> and <b>interaction</b> <b>techniques</b> <b>are</b> required. In this paper we explore the potential of computer-vision on mobile devices with a camera as <b>an</b> <b>interaction</b> modality. Based on a theoretical review of the available design space potential <b>interaction</b> <b>techniques</b> <b>are</b> discussed. Some of these were implemented in an experimental game to enable practical evaluation. We provide an overview of the game and present intial experiences with the vision-based <b>interaction</b> <b>techniques</b> employed...|$|R
