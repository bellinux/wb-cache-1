10000|5276|Public
25|$|<b>A</b> <b>multivariate</b> {{function}} is one which takes several inputs.|$|E
25|$|<b>A</b> <b>multivariate</b> {{version of}} Wallenius' {{distribution}} is used {{if there are}} more than two different colors.|$|E
25|$|The Wishart {{distribution}} is <b>a</b> <b>multivariate</b> generalization of the gamma distribution (samples are positive-definite matrices rather than positive real numbers).|$|E
40|$|Realized {{volatility}} of stock returns is often decomposed into two distinct components that {{are attributed to}} continuous price variation and jumps. This paper proposes <b>a</b> tobit <b>multivariate</b> factor model for the jumps coupled with <b>a</b> standard <b>multivariate</b> factor model for the continuous sample path to jointly forecast volatility in three Chinese Mainland stocks. Out of sample forecast analysis shows that separate multivariate factor models for the two volatility processes outperform <b>a</b> single <b>multivariate</b> factor model of realized volatility, and that <b>a</b> single <b>multivariate</b> factor model of realized volatility outperforms univariate models. ...|$|R
2500|$|K is the kernel {{function}} which is <b>a</b> symmetric <b>multivariate</b> density; ...|$|R
5000|$|... where [...] are {{independent}} m-dimensional vectors with <b>a</b> given <b>multivariate</b> distribution, ...|$|R
25|$|The {{information}} {{given by}} a correlation coefficient {{is not enough to}} define the dependence structure between random variables. The correlation coefficient completely defines the dependence structure only in very particular cases, for example when the distribution is <b>a</b> <b>multivariate</b> normal distribution. (See diagram above.) In the case of elliptical distributions it characterizes the (hyper-)ellipses of equal density; however, it does not completely characterize the dependence structure (for example, <b>a</b> <b>multivariate</b> t-distribution's degrees of freedom determine the level of tail dependence).|$|E
25|$|This {{adaptive}} {{encoding procedure}} {{is not confined}} to algorithms that sample from <b>a</b> <b>multivariate</b> normal distribution (like evolution strategies), but can in principle be applied to any iterative search method.|$|E
25|$|Fisher's {{distribution}} {{can simply}} {{be defined as}} the conditional distribution of two or more independent binomial variates dependent upon their sum. <b>A</b> <b>multivariate</b> version of the Fisher's distribution is used if there are more than two colors of balls.|$|E
5000|$|K is the kernel {{function}} which is <b>a</b> symmetric <b>multivariate</b> density; ...|$|R
5000|$|If , the {{probability}} density function (pdf) for <b>a</b> k-dimensional <b>multivariate</b> Laplace distribution becomes: ...|$|R
40|$|This paper {{concerns}} with the sensitivity {{analysis for the}} multivariate eigenvalue problem (MEP). The concept of <b>a</b> simple <b>multivariate</b> eigenvalue of <b>a</b> matrix is generalized to the MEP and the first-order perturbation expansions of <b>a</b> simple <b>multivariate</b> eigenvalue and the corresponding multivariate eigenvector are presented. The explicit expressions of condition numbers, perturbation upper bounds and backward errors for multivariate eigenpairs are derived...|$|R
25|$|Hilbert's tenth problem {{asked for}} an {{algorithm}} to determine whether <b>a</b> <b>multivariate</b> polynomial equation with integer coefficients has a solution in the integers. Partial progress was made by Julia Robinson, Martin Davis and Hilary Putnam. The algorithmic unsolvability {{of the problem was}} proved by Yuri Matiyasevich in 1970 (Davis 1973).|$|E
25|$|No {{good way}} of calculating the {{variance}} is known. The best known method is to approximate the multivariate Wallenius distribution by <b>a</b> <b>multivariate</b> Fisher's noncentral hypergeometric distribution with the same mean, and insert the mean as calculated above in the approximate formula for the variance of the latter distribution.|$|E
25|$|Maximum {{likelihood}} estimation can {{be performed}} when {{the distribution of the}} error terms is known to belong to a certain parametric family ƒθ of probability distributions. When fθ is a normal distribution with zero mean and variance θ, the resulting estimate is identical to the OLS estimate. GLS estimates are maximum likelihood estimates when ε follows <b>a</b> <b>multivariate</b> normal distribution with a known covariance matrix.|$|E
5000|$|In {{the multivariate}} case, the {{marginal}} distribution of [...] is <b>a</b> [...] <b>multivariate</b> t distribution: ...|$|R
5000|$|... {{then the}} {{distribution}} of x1 conditional on x2 = <b>a</b> is <b>multivariate</b> normal [...] where ...|$|R
3000|$|... {{distributions}} We now introduce <b>a</b> general <b>multivariate</b> skew-slash {{t distribution}} by incorporating location and scale parameters.|$|R
25|$|A {{probability}} distribution whose sample space is {{the set of}} real numbers is called univariate, while a distribution whose sample space is a vector space is called multivariate. A univariate distribution gives the probabilities of a single random variable taking on various alternative values; <b>a</b> <b>multivariate</b> distribution (a joint {{probability distribution}}) gives the probabilities of a random vector—a list {{of two or more}} random variables—taking on various combinations of values. Important and commonly encountered univariate probability distributions include the binomial distribution, the hypergeometric distribution, and the normal distribution. The multivariate normal distribution is a commonly encountered multivariate distribution.|$|E
25|$|In 1900, Hilbert posed {{a famous}} list of 23 {{problems}} for the next century. The first two of these were to resolve the continuum hypothesis and prove the consistency of elementary arithmetic, respectively; the tenth was to produce a method that could decide whether <b>a</b> <b>multivariate</b> polynomial equation over the integers has a solution. Subsequent work to resolve these problems shaped the direction of mathematical logic, as did the effort to resolve Hilbert's Entscheidungsproblem, posed in 1928. This problem asked for a procedure that would decide, given a formalized mathematical statement, whether the statement is true or false.|$|E
25|$|Copulas {{are useful}} in portfolio/risk {{management}} and help us analyse the effects of downside regimes by allowing the modelling of the marginals and dependence structure of <b>a</b> <b>multivariate</b> probability model separately. For example, consider the stock exchange as a market consisting {{of a large number}} of traders each operating with his/her own strategies to maximize profits. The individualistic behaviour of each trader can be described by modelling the marginals. However, as all traders operate on the same exchange, each trader's actions have an interaction effect with other traders'. This interaction effect can be described by modelling the dependence structure. Therefore, copulas allow us to analyse the interaction effects which are of particular interest during downside regimes as investors tend to herd their trading behaviour and decisions.|$|E
5000|$|The factor {{regression}} model, or hybrid factor model, is <b>a</b> special <b>multivariate</b> {{model with}} the following form.where, ...|$|R
40|$|Normal 0 false false false EN-US X-NONE X-NONE In this paper, it {{is shown}} that <b>a</b> complex <b>multivariate</b> random {{variable}}   is <b>a</b> complex <b>multivariate</b> normal random variable of dimensionality if {{and only if}} all nondegenerate complex linear combinations of   have a complex univariate normal distribution. The characteristic function of   has been derived, and simpler forms of some theorems have been given using this characterization theorem without assuming that the variance-covariance matrix of the vector   is Hermitian positive definite. Marginal distributions of   have been given. In addition, <b>a</b> complex <b>multivariate</b> t-distribution has been defined and the density derived. A characterization of the complex multivariate t-distribution is given. A few possible uses of this distribution have been suggested. </p...|$|R
40|$|The aim of {{this paper}} is to nd a {{modeling}} approach for spatially and temporally structured data. The spatial distribution is considered to form an irregular lattice with a specied denition of neighborhood. Additional to the spatial component, a temporal autoregressive parameter, and a time trend are modeled within <b>a</b> <b>multivariates</b> Markov process. This Markov process can be expressed on the basis of an innovation process, which allows for statistical inference on various parameters...|$|R
2500|$|If [...] is <b>a</b> <b>multivariate</b> normal {{distribution}} then [...] has <b>a</b> <b>multivariate</b> log-{{normal distribution}} with mean ...|$|E
2500|$|... is <b>a</b> <b>multivariate</b> {{polynomial}} equation {{over the}} rational numbers.|$|E
2500|$|The {{iteration}} {{starts with}} sampling [...] candidate solutions [...] from <b>a</b> <b>multivariate</b> normal distribution , i.e.|$|E
40|$|There arise two {{problems}} when {{the expectation of}} some function with respect to <b>a</b> nonuniform <b>multivariate</b> distribution has to be computed by (quasi-) Monte Carlo integration: the integrand can have singularities when {{the domain of the}} distribution is unbounded and it can be very expensive or even impossible to sample points from <b>a</b> general <b>multivariate</b> distribution. We show that importance sampling is a simple method to overcome both problems. (author's abstract) Series: Preprint Series / Department of Applied Statistics and Data Processin...|$|R
2500|$|For <b>a</b> one-sample <b>multivariate</b> test, the {{hypothesis}} is that the mean vector (...) is equal to a given vector (...) [...] The test statistic is Hotelling's t2: ...|$|R
2500|$|For <b>a</b> two-sample <b>multivariate</b> test, the {{hypothesis}} is that the mean vectors ( [...] , [...] ) of two samples are equal. The test statistic is Hotelling's two-sample t2: ...|$|R
2500|$|The {{result can}} be {{generalized}} to obtain <b>a</b> <b>multivariate</b> version of the inequality, as follows: ...|$|E
2500|$|Wishart distribution, for a {{symmetric}} non-negative definite matrix; conjugate to {{the inverse}} of the covariance matrix of <b>a</b> <b>multivariate</b> normal distribution; generalization of the gamma distribution ...|$|E
2500|$|The Gaussian copula is a {{distribution}} over the unit cube [...] It is constructed from <b>a</b> <b>multivariate</b> normal distribution over [...] {{by using the}} probability integral transform.|$|E
5000|$|For <b>a</b> one-sample <b>multivariate</b> test, the {{hypothesis}} is that the mean vector (...) is equal to a given vector (...) [...] The test statistic is Hotelling's t 2: ...|$|R
5000|$|For <b>a</b> two-sample <b>multivariate</b> test, the {{hypothesis}} is that the mean vectors ( [...] , [...] ) of two samples are equal. The test statistic is Hotelling's two-sample t 2: ...|$|R
50|$|The zij must be sampled from <b>a</b> {{truncated}} <b>multivariate</b> {{normal distribution}} {{to preserve their}} rank ordering. Hajivassiliou's Truncated Multivariate Normal Gibbs sampler {{can be used to}} sample efficiently.|$|R
