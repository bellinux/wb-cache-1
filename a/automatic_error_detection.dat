51|5699|Public
5|$|Parallel {{computing}} {{can also}} {{be applied to the}} design of fault-tolerant computer systems, particularly via lockstep systems performing the same operation in parallel. This provides redundancy in case one component should fail, and also allows <b>automatic</b> <b>error</b> <b>detection</b> and error correction if the results differ. These methods can be used to help prevent single event upsets caused by transient errors. Although additional measures may be required in embedded or specialized systems, this method can provide a cost effective approach to achieve n-modular redundancy in commercial off-the-shelf systems.|$|E
50|$|Dataspeed was the Bell System {{name for}} a family of high speed paper tape systems used with DataPhone modems. Type 1was 5-level, 1050 wpm. Type 2 was 5-8 level, 1050 wpm. Type 4 was 8 level with <b>automatic</b> <b>error</b> <b>detection</b> and correctionby retransmitting blocks of data {{received}} in error. Type 5 was 8 level 750 wpm using a modem that was very inexpensiveas a transmitter; hence the system was popular for data collection applications.|$|E
50|$|Parallel {{computing}} {{can also}} {{be applied to the}} design of fault-tolerant computer systems, particularly via lockstep systems performing the same operation in parallel. This provides redundancy in case one component should fail, and also allows <b>automatic</b> <b>error</b> <b>detection</b> and error correction if the results differ. These methods can be used to help prevent single event upsets caused by transient errors. Although additional measures may be required in embedded or specialized systems, this method can provide a cost effective approach to achieve n-modular redundancy in commercial off-the-shelf systems.|$|E
40|$|We aim to {{sufficiently}} define annotation for post-positional particle {{errors in}} L 2 Korean writing, so that future work on <b>automatic</b> particle <b>error</b> <b>detection</b> can make progress. To achieve this goal, we outline the linguistic properties of Korean particles in learner data. Given the agglutinative nature of Korean {{and the range}} of functions of particles, this annotation effort involves issues such as defining the tokens and target forms. ...|$|R
40|$|This paper {{describes}} a pronunciation <b>error</b> <b>detection</b> method for Repetitor, a pronunciation training computer program for second language learners of Dutch. A database of L 2 -speech was constructed and {{a selection of}} relevant pronunciation errors for Repetitor was made. Our <b>error</b> <b>detection</b> method {{is based on a}} weighted variant selection using forced alignment. Tested on the database, the results show that our method achieves satisfactory detection performance for most pronunciation errors yielding a precision of correct rejects of over 85 % for most errors, and scoring accuracies between 85 % and 100 %. Index Terms: CAPT, <b>automatic</b> pronunciation <b>error</b> <b>detection</b> 1...|$|R
40|$|Annotating a corpus with error {{information}} is a challenging task. This paper describes the design, evaluation and refinement of an an-notation scheme for Spanish article errors in learner data, so that future work on corpus an-notation and <b>automatic</b> article <b>error</b> <b>detection</b> can progress. To evaluate reliability, 300 noun phrases with definite, indefinite and zero arti-cle have been tagged by four annotators. We analysed {{different types of}} disagreement, pre-sented suggestions to increase reliability and applied the refined annotation scheme to cre-ate a gold-standard annotation. ...|$|R
40|$|A problem-adaptive {{solution}} {{procedure for}} improving the reliability of finite element solutions to geometrically nonlinear shell-type problem is presented. The strategy incorporates <b>automatic</b> <b>error</b> <b>detection</b> and control and includes an iterative procedure which utilizes the solution at the same load step on a more refined model. Representative nonlinear shell problem are solved...|$|E
40|$|We {{present a}} complex, open source tool for {{detailed}} machine translation error analysis providing the user with <b>automatic</b> <b>error</b> <b>detection</b> and classification, several monolingual alignment algorithms {{as well as}} with training and test corpus browsing. The tool {{is the result of a}} merge of <b>automatic</b> <b>error</b> <b>detection</b> and classification of Hjerson (Popović, 2011) and Addicter (Zeman et al., 2011) into the pipeline and web visualization of Addicter. It classifies errors into categories similar to those of Vilar et al. (2006), such as: morphological, reordering, missing words, extra words and lexical errors. The graphical user interface shows alignments in both training corpus and test data; the different classes of errors are colored. Also, the summary of errors can be displayed to provide an overall view of the MT system’s weaknesses. The tool was developed in Linux, but it was tested on Windows too...|$|E
40|$|In this paper, a {{software}} debugging mechanism for embedded systems is presented. The debugger is a dynamically loadable and linkable module {{of the operating}} system. The methodology {{presented in this paper}} provides <b>automatic</b> <b>error</b> <b>detection,</b> classification and location capabilities for a set of algorithmic errors. An example implementation of our approach is given for debugging an integer divide-by-zero error...|$|E
40|$|Abstract — Massively {{parallel}} “Processing-In-Memory” (PIM) architectures {{have been}} shown to yield increases in performance due to their “memory-centric ” nature. However, as PIM is still a developing technology, advanced issues such as <b>error</b> <b>detection</b> and failure recovery have not yet been addressed. We describe the application of concepts found in our multi-agent system, ADE, to PIM, incorporating its mechansims for <b>automatic</b> and intelligent <b>error</b> <b>detection,</b> failure recovery, and dynamic system reconfiguration in the PIM architecture, enhancing architecture robustness...|$|R
40|$|Abstract. This paper {{presents}} error patterns {{built on}} the basis of our comparative analysis of American English and Mexican Spanish phonemes and allophones which can be applied in designing the <b>error</b> <b>detection</b> module of a Computer Assisted Pronunciation Training (CAPT) System for teaching American English pronunciation to Mexican Spanish speakers. Error identification is important for an adequate choice of correcting techniques which improves English pronunciation acquisition and helps learners to develop less accented speech. Since <b>automatic</b> individual <b>error</b> <b>detection</b> remains a highly complex computational task, error patterns can enhance the system performance and improve its precision. To the best of our knowledge, error patterns in American English speech generated by Mexican Spanish speakers has not been defined in previous work which was done mainly for Castilian-originated standard Spanish...|$|R
40|$|With {{the rapid}} {{development}} of video surveillance and broadcast systems monitoring the video quality becomes {{an important aspect}} to assure better quality of service. <b>Error</b> <b>detection</b> is an important technique to measure the quality of videos transmitted over unreliable network. With the advent of HDTV previously subtle errors in videos are becoming more prominent. In this paper we want to propose a next generation cloud based video <b>error</b> <b>detection</b> system using video processing technology for making the detection process in real-time. At first, we introduce an <b>automatic</b> video <b>error</b> <b>detection</b> method and then propose a cloud computing platform. Finally we integrate <b>error</b> <b>detection</b> method with cloud computing platform named as Hawkeye to achieve a real time video <b>error</b> <b>detection</b> system which ensures contents integrity and minimizes testing time and efforts required to keep ahead of other conventional quality check system. Extensive experiments on prominent datasets and telecasted videos show that the proposed algorithm is very much efficient to detect errors for video broadcast and surveillance applications in terms of computation time and the detection of distorted frames...|$|R
40|$|In {{the case}} of {{large-scale}} surveys, such as a Census, data may contain errors or missing values. An <b>automatic</b> <b>error</b> <b>detection</b> and correction procedure is therefore needed. We propose here an approach to this problem based on Discrete Optimization. The treatment of each data record is converted into a mixed integer linear programming model and solved by means of state-of-the-art branch and cut procedures. Results on real-world Agricultural Census data show {{the effectiveness of the}} proposed procedure...|$|E
40|$|Background: Endothelial {{examination}} of organ culture stored corneas is usually done manually and on several mosaic zones. Some banks use an image analyser that takes account {{of only one}} zone. This method is restricted by image quality, and may be inaccurate if endothelial cell density (ECD) within the mosaic is not homogeneous. The authors have developed an analyser that has tools for <b>automatic</b> <b>error</b> <b>detection</b> and correction, and can measure ECD and perform morphometry on multiple zones of three images of the endothelial mosaic...|$|E
40|$|An {{important}} {{problem in}} real-time DSP (digital signal-processing) systems with highly integrated components is {{the capability of}} <b>automatic</b> <b>error</b> <b>detection</b> and correction. The use of residue number arithmetic allows error detection and correction because of its unweighted nature. A single-error-correction procedure is proposed {{which is based on}} the use of redundant residue number systems (RRNS) and the base extension operation. The proposed method uses a small decision table and works in parallel mode; therefore it is suitable for high-speed VLSI circuit realization. A parallel architecture which realizes the method is also introduce...|$|E
40|$|In this paper, {{we present}} an acoustic-phonetic {{approach}} to <b>automatic</b> pronunciation <b>error</b> <b>detection.</b> Classifiers using {{techniques such as}} Linear Discriminant Analysis and Decision Trees were developed for three sounds that are frequently pronounced incorrectly by L 2 -learners of Dutch: /�/, /� / and /�/. This paper will focus mainly on {{the problems with the}} latter phoneme. The acoustic properties of these pronunciation errors were examined so as to define a number of discriminative acoustic features to be used to train and test the classifiers. Experiments showed that the classifiers are able to discriminate correct sounds from incorrect sounds in both native and non-native speech, and therefore can be used to detect pronunciation errors in non-native speech. 1...|$|R
40|$|This paper expands our {{previous}} work on <b>automatic</b> pronunciation <b>error</b> <b>detection</b> that exploits knowledge from psychoacoustic auditory models. The new system has two additional important features, i. e., auditory and acoustic processing {{of the temporal}} cues of the speech signal, and classification feedback from a trained linear dynamic model. We also perform a pronunciation analysis by considering the task as a classification problem. Finally, we evaluate the proposed methods conducting a listening test on the same speech material and compare {{the judgment of the}} listeners and the methods. The automatic analysis based on spectro-temporal cues is shown to have the best agreement with the human evaluation, particularly with that of language teachers, and with previous plenary linguistic studies. Index Terms: L 2 pronunciation error, auditory model, linear dynamic model, distortion measure, phoneme...|$|R
40|$|We {{introduce}} a boosting algorithm {{to improve on}} existing methods for deformable image registration (DIR). The proposed DIRBoost algorithm is inspired by the theory on hypothesis boosting, {{well known in the}} field of machine learning. DIRBoost utilizes a method for <b>automatic</b> registration <b>error</b> <b>detection</b> to obtain estimates of local registration quality. All areas detected as erroneously registered are subjected to boosting, i. e. undergo iterative registrations by employing boosting masks on both the fixed and moving image. We validated the DIRBoost algorithm on three different DIR methods (ANTS gSyn, NiftyReg, and DROP) on three independent reference datasets of pulmonary image scan pairs. DIRBoost reduced registration errors significantly and consistently on all reference datasets for each DIR algorithm, yielding an improvement of the registration accuracy by 5 - 34 % depending on the dataset and the registration algorithm employed. © 2014 Elsevier B. V...|$|R
40|$|This paper gives a {{detailed}} information {{on the design of}} the speech corpus for the purpose of developing an ASR-based pronunciation tutoring system. In the first place, assumptions on the structure of the corpus are presented. Then collection of text material, recordings and procedure of annotation of the resulting speech corpus are described. In the end, preliminary results of the analysis of pronunciation errors are discussed. They provide information which is important for ASR training and testing on the one hand, and <b>automatic</b> <b>error</b> <b>detection</b> on the other hand. 1...|$|E
40|$|Abstract. The {{video capture}} and {{preprocessing}} {{is the basis}} of video process system. This paper analyzes the timing of video capture by Camera Link interface based on FPGA, and proposed an <b>automatic</b> <b>error</b> <b>detection</b> approach to avoid error accumulation during the video data capture. Furthermore, by adopting the optimized LUT and pipeline addition, an optimized method for RGB to YCbCr color space conversion (CSC) is presented specifically for the video format preprocessing. Experimental results demonstrate that the strategy we proposed is of high reliability, and it could obtain maximum operation frequency of 334 MHz, 3. 16 times faster than the direct method...|$|E
40|$|The {{shuttle system}} of {{interest}} in this paper is the shuttle's data processing system (DPS). The DPS is composed of the following: (1) general purpose computers (GPC); (2) a multifunction CRT display system (MCDS); (3) mass memory units (MMU); and (4) a multiplexer/demultiplexer (MDM) and related software. In order to ensure the correct functioning of shuttle systems, some level of <b>automatic</b> <b>error</b> <b>detection</b> has been incorporated into all shuttle systems. For the DPS, error detection equipment has been incorporated into all of its subsystems. The automated diagnostic system, (MCDS) diagnostic tool, that aids in a more efficient processing of the DPS is described...|$|E
40|$|Visual {{detection}} based {{sense and}} avoid problem {{is more and}} more important nowadays as UAVs are getting closer to entering remotely piloted or autonomously into the airspace. It is critical to gain as much information as possible from the silhouettes of the distant aircrafts. In our paper, we investigate the reachable accuracy of the orientation information of remote planes under different geometrical condition, by identifying their wing lines from their detected wingtips. Under the assumption that the remote airplane is on a straight course, the error of the spatial discretization (pixelization), and the <b>automatic</b> <b>detection</b> <b>error</b> is calculated...|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedAn <b>automatic,</b> language-independent syntax <b>error</b> <b>detection,</b> recovery, and correction system for LR(k) grammars is proposed. The requirement is {{made that the}} reverse of the grammar involved is also LR(k). The implications and justification for this requirement are discussed. Given that the grammar is both LR(k) and RL(k), forward and reverse parsers localize errors and define left and right error context providing a strong base from which error analysis may proceed. Possible deterministic and heuristic corrective actions to follow error analysis are presented. The definition and selection of keys from the set of terminal symbols for the grammar which enable the reverse parser to be engaged upon <b>error</b> <b>detection</b> are discussed. A model of the proposed system, implemented in an XPL compiler for a large ALGOL-like grammar, is described {{and the results of}} test programs are exampled and discussed. Possible extensions to the system are presented and areas requiring further analysis are defined. [URL] Commander, United States Nav...|$|R
40|$|AbstractFeature-based NC machining, which {{requires}} {{high quality of}} 3 D CAD model, is widely used in machining aircraft structural part. However, {{there has been little}} research on how to automatically detect the CAD model errors. As a result, the user has to manually check the errors with great effort before NC programming. This paper proposes an <b>automatic</b> CAD model <b>errors</b> <b>detection</b> approach for aircraft structural part. First, the base faces are identified based on the reference directions corresponding to machining coordinate systems. Then, the CAD models are partitioned into multiple local regions based on the base faces. Finally, the CAD model error types are evaluated based on the heuristic rules. A prototype system based on CATIA has been developed to verify the effectiveness of the proposed approach...|$|R
40|$|Abstract. We present FoREnSiC, an {{open source}} {{environment}} for <b>automatic</b> <b>error</b> <b>detection,</b> localization and correction in C programs. The framework implements different automated debugging methods in a unified way covering the whole design flow from ESL to RTL. Currently, a scalable simulation-based back-end, a back-end based on symbolic execution, and a formal back-end exploiting functional equivalences between a C {{program and a}} hardware design are available. FoREnSiC is designed as an extensible framework. Its infrastructure, including a powerful front-end and interfaces to logic problem solvers, can be reused for implementing new program analysis or debugging methods. In addition to the infrastructure, the back-ends, and a few experimental results, we present an illustrative application scenario that shows FoREnSiC in use. ...|$|E
40|$|Abstract—We build a {{distance}} education {{application of a}} Chinese handwriting education system that allows students to do practice at anytime and anywhere. As an intelligent tutor, the system can automatically check the handwriting errors, such as the stroke production errors, stroke sequence error and stroke relationship error. Then our system should provide useful feedback to the student. In this paper, attributed relational graph matching is used to locate the handwriting errors. The pruning strategy is applied to reduce the computational time. The experiment results show that our proposal can handle more handwriting error cases than existing methods with a higher accuracy. Index Terms—Chinese handwriting education, handwriting errors, <b>automatic</b> <b>error</b> <b>detection,</b> intelligent tutoring, attributed relational graph matching. I...|$|E
40|$|This paper {{discusses}} {{the value of}} using learner corpora to improve language teaching (CALL) software, and NLP tools, focussing on an error detection system to be included within a CALL software for French. We explain how errors are encoded in the corpora and present different types of analyses possible once the corpora have been annotated. We also describe error detection levels, the techniques used for <b>automatic</b> <b>error</b> <b>detection</b> and preliminary results. We then discuss the didactic perspective and the interface of the whole CALL software. Taking past participle agreement as an example, we also provide a concrete illustration of the interplay between learner corpora, NLP tools and didactic content. Finally, we identify key areas for further research...|$|E
40|$|Various {{facial image}} quality {{parameters}} like pose, illumination, noise, resolution, etc {{are known to}} be a predictor of face recognition performance. However, there still remain many other properties of facial images that are not captured by the existing quality parameters. In this paper, we propose a novel image quality parameter called the <b>Automatic</b> Eye <b>Detection</b> <b>Error</b> (AEDE) which measures the difference between manually located and automatically detected eye coordinates. Our experiment results carried out using FaceVACS recognition system and the MultiPIE dataset show that AEDE is indeed a predictor of face recognition performance...|$|R
40|$|Data {{acquisition}} (DAQ) {{and control}} systems for arrays of Cherenkov telescopes comprise hundreds of distributed software processes that implement the readout, control and monitoring of various hardware devices. A multitude of different error conditions (malfunctioning detectorhardware, crashing software, failures of network and computing equipment etc.) can occur {{and must be}} dealt with to ensure the speedy continuation of observations and an efficient use of dark time. Flexible, fast and configurable methods for <b>automatic</b> and centralized <b>error</b> <b>detection</b> and recovery are therefore highly desirable for the current generation of ground-based Cherenkovexperiments (H. E. S. S., MAGIC, VERITAS) and will be important for the Cherenkov Telescope Array (CTA), a more complex observatory with O(100) telescopes. This contribution describes a Java-based software demonstrator that was developed for the High Energy Stereoscopic System (H. E. S. S.) and uses the complex event processing engine Esper for <b>error</b> <b>detection</b> and recovery. The software demonstrator analyses streams of error messages in the time domain and aims to apply recovery procedures that reflect the knowledge of DAQ and detector experts...|$|R
40|$|This article {{presents}} {{a new approach}} for <b>automatic</b> Chinese spelling <b>error</b> <b>detection</b> and correction. Existing Chinese spelling checking systems have two problems: (1) low precision rate, and (2) lack of correction capability. The proposed Chinese spelling correction method is composed of two mechanisms (1) composite confusing character substitution, and (2) advanced word class bigram language model. The characters in the input sentence are first substituted by their corresponding composite confusing character sets one by one. A composite confusing set is the collection of similar characters to a Chinese character from multiple views of shape, pronunciation, meaning, and input keystroke sequence. The substitution step produces several sentence hypotheses for the input sentence. Then, an advanced word class bigram language model, such as inter-word character bigram (IWCB) or SA-class bigram {{can be used for}} scoring each sentence hypothesis. Finally, the best scored sentence hypothesis is c [...] ...|$|R
40|$|Abstract. The {{development}} {{and maintenance of}} domain-specific application ontol-ogies require knowledge input from domain experts who are usually without any formal ontology or AI background. When dealing with large-scale ontologies, for example of the kind with which we are currently familiar in the biomedical spheres, quality assurance becomes important in minimizing modelling mistakes and the ap-plication errors which they bring in their wake. In this paper we describe how the upper-level framework BFO (for: Basic Formal Ontology), developed by the Insti-tute for Formal Ontology and Medical Information Science, {{is being used to}} provide <b>automatic</b> <b>error</b> <b>detection</b> and run-time modelling support to the development of LinKBase®, a large-scale medical domain ontology developed by Language and Computing NV to serve a range of natural language processing applications...|$|E
40|$|This paper {{proposes a}} pointer alias {{analysis}} for <b>automatic</b> <b>error</b> <b>detection.</b> State-of-the-art pointer alias analyses are either too slow or too imprecise for finding errors in real-life programs. We propose a hybrid pointer analysis that tracks actively manipulated pointers held in local variables and parameters accurately with path and context sensitivity and handles pointers stored in recursive data structures less precisely but efficiently. We make the unsound assumption that pointers passed into a procedure, in parameters, global variables, and locations reached by applying simple access paths to parameters and global variables, are all distinct {{from each other}} and from any other locations. This assumption matches the semantics of many functions, reduces spurious aliases and speeds up the analysis. We present a program representation [...] ...|$|E
40|$|The {{development}} {{and maintenance of}} domain-specific application ontologies require knowledge input from domain experts who are usually without any formal ontology or AI background. When dealing with large-scale ontologies, for example of the kind with which we are currently familiar in the biomedical spheres, quality assurance becomes important in minimizing modelling mistakes and the application errors which they bring in their wake. In this paper we describe how the upper-level framework BFO (for: Basic Formal Ontology), developed by the Institute for Formal Ontology and Medical Information Science, {{is being used to}} provide <b>automatic</b> <b>error</b> <b>detection</b> and run-time modelling support to the development of LinKBase, a large-scale medical domain ontology developed by Language and Computing NV to serve a range of natural language processing applications...|$|E
40|$|An {{automatic}} detection algorithm of P-wave arrival {{time for a}} microearthquake is described. A function based on normalized fourth-order cumulant, kurtosis, is used to detect both provisional P-wave arrival time {{and the end of}} microseismic signal. The contrast function has the maximum value near the P-wave arrival time. After detection of the provisional P-wave arrival time, maximum likelihood analysis is applied to evaluate residuals between microseismic signal and its AR model, which is made based on the provisional P-wave arrival time. 100 of microseismic events are used to examine the performance of this <b>automatic</b> <b>detection.</b> <b>Errors</b> of the <b>automatic</b> <b>detection</b> are within 3 ms in the 97 events. 3 ms is as long as a quarter of a period of P-wave because dominant frequency of P-wave is 80 Hz...|$|R
5000|$|... "End to End Error Code Correction" [...] (e2eECC) - all {{memory storage}} and {{internal}} transfers may {{be protected by}} error correction encoding having a Hamming Distance of 4, that distance providing <b>automatic</b> single bit-flip <b>error</b> correction and double bit-flip <b>error</b> <b>detection.</b>|$|R
40|$|As edit, analyze, measure or {{transform}} attribute grammars by hand is {{an exhaustive}} task, {{it would be}} great if it could be automatized, specially for those who work in Language Engineering. However, currently there are no editors oriented to grammar development that cover all our needs. In this paper we describe the architecture and the development stages of AGile, a structured editor, analyzer, metric calculator and transformer for attribute grammars. It is intended, with this tool, to fill the existing gap. An AnTLR based attribute grammar syntax was used to define the input for this system. As soon as the user types the grammar, the input is parsed and kept in an intermediate structure in memory which holds the important information about the input grammar. This intermediate structure can be used to calculate all the metrics or to transform the input grammar. This system can be a valorous tool for those who need to improve the performance or functionalities of their language processor, speeding up the difficult task of defining and managing a language. Features like highlighting, <b>automatic</b> indentation, on-the-fly <b>error</b> <b>detection,</b> etc., also adds efficiency...|$|R
