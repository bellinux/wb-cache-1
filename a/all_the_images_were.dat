69|10000|Public
60|$|Observing that <b>all</b> <b>the</b> <b>images</b> <b>were</b> {{more or less}} defaced, Babbalanja {{sought the}} reason.|$|E
50|$|The {{choice of}} images {{used by the}} ESP game makes a {{difference}} in the player’s experience. The game would be less entertaining if <b>all</b> <b>the</b> <b>images</b> <b>were</b> chosen from a single site and were all extremely similar.|$|E
5000|$|... "For many years, it {{was thought}} that the village nostalgically portrayed in these {{photographs}} was a fictional creation. However, recent research revealed that <b>all</b> <b>the</b> <b>images</b> <b>were</b> taken at Hinton Waldrist, in Berkshire (now in Oxfordshire) and its surroundings." ...|$|E
5000|$|... "If {{you look}} at my book, <b>all</b> <b>the</b> <b>images</b> <b>are</b> with people's hands to their faces...this was {{actually}} a direct reference to Ader's image." ...|$|R
3000|$|These test {{are carried}} out on an image {{database}} that contains 2000 images taken from BOWS- 2 database [11]. <b>All</b> <b>the</b> <b>images</b> <b>are</b> natively in lossless format and gray-scaled. <b>Image</b> dimensions <b>are</b> [...]...|$|R
3000|$|... {{were set}} as 128 and 16 bins. <b>All</b> <b>the</b> <b>images</b> <b>are</b> {{converted}} to grey scale. For removing {{the effect of}} global intensity and contrast, each texture <b>image</b> <b>was</b> normalized to have an average intensity 128 and a standard deviation 20 [1].|$|R
50|$|The {{crew had}} photographed 30 {{geographic}} areas in 2,400 photographs. None of the cassettes {{were found to}} be faulty and <b>all</b> <b>the</b> <b>images</b> <b>were</b> of good quality. The results, it was said, would aid experts in the fields of agriculture, cartography, mineralogy, and hydrology.|$|E
30|$|These {{behavioral}} data clearly {{show that}} the cartoon images were overall easier to respond to, even when <b>all</b> <b>the</b> <b>images</b> <b>were</b> presented at 500 ms.|$|E
30|$|<b>All</b> <b>the</b> <b>images</b> <b>were</b> reconstructed using maximum-likelihood {{expectation}} maximization (MLEM) with 50 iterations {{with and}} without resolution recovery function, based on the recommendation {{in our previous study}} [5]. The voxel size was set to 0.5 [*]×[*] 0.5 [*]×[*] 0.5  mm. Neither attenuation nor scatter correction was performed. Reconstructed transaxial images were transferred to a workstation for further processing and data analysis.|$|E
60|$|Most {{interesting}} {{is it to}} consider the effect, when the feelings are wrought above the natural pitch by the belief of something mysterious, while <b>all</b> <b>the</b> <b>images</b> <b>are</b> purely natural. Then it is, that religion and poetry strike deepest.|$|R
30|$|The {{format of}} the data is RAW {{including}} amplitude and phase information. In the following experiments, only amplitude information <b>is</b> used. <b>All</b> <b>the</b> <b>images</b> <b>are</b> cropped by extracting 64 × 64 patches {{from the center of}} <b>the</b> <b>image</b> but without any other preprocessing.|$|R
50|$|<b>The</b> {{following}} three <b>images</b> illustrate how RDS {{can be used}} on an FM radio station; the latter two were taken when the radio was tuned to Nottingham radio station Trent FM. <b>All</b> <b>the</b> <b>images</b> <b>are</b> of <b>the</b> display on the Sony XDR-S1 DAB/FM/MW/LW portable radio.|$|R
30|$|After <b>all</b> <b>the</b> <b>images</b> <b>were</b> {{processed}} with AM-FM, {{they were}} divided in regions of 100 × 100 pixels avoiding the optic disc. Feature vectors were calculated using the moments in each region: mean, standard deviation, skewness, and kurtosis. Finally, the information per image is the input for the PLS algorithm were the algorithm is trained to classify normal images vs abnormal images.|$|E
40|$|This {{lithograph}} shows Jupiter's four largest moons {{in their}} correct scales, {{in order of}} increasing distance away from Jupiter (from bottom: Io, Europa, Ganymede, and Callisto). <b>All</b> <b>the</b> <b>images</b> <b>were</b> taken by the Galileo spacecraft, except for the globe of Callisto, which {{was taken by the}} Voyager spacecraft. The accompanying text describes the images, provides some historical facts and statistical data, and lists some important dates in Jovian exploration. Educational levels: Undergraduate lower division, Middle school, High school...|$|E
30|$|We {{constructed}} a tongue image data set of 300 imagesc {{to evaluate the}} proposed method. Manual segmentation results were used as the ground truth. <b>All</b> <b>the</b> <b>images</b> <b>were</b> acquired by our tongue image acquisition device. The image size was 768 [*]×[*] 576. Since the images were captured in a semi-enclosed environment under stable lighting conditions, {{it was not necessary}} to use any pre-processing method for illumination normalization. All the experiments were executed on a PC with T 2250 @ 1.73 GHz CPU and 2 G memory.|$|E
6000|$|... "Most {{interesting}} {{is it to}} consider the effect, when the feelings are wrought above the natural pitch by the belief of something mysterious, while <b>all</b> <b>the</b> <b>images</b> <b>are</b> purely natural: then it is that religion and poetry strike deepest."--'Biog. Lit.' vol. i. p. 204.|$|R
30|$|Most {{settings}} {{of the experiments}} in this part are similar with the ones in ‘Part A’ section. We use the luminance channel of <b>all</b> <b>the</b> <b>images</b> to extract sensor pattern noises of test images and reference SPN of each camera device. <b>All</b> <b>the</b> <b>image</b> blocks <b>are</b> of three sizes (i.e., 128 [*]×[*] 128, 256 [*]×[*] 256, and 512 [*]×[*] 512  pixels) and are <b>all</b> cropped from <b>the</b> center of full-size images. In this image database, exactly blue sky <b>images</b> <b>are</b> not available. <b>All</b> <b>the</b> <b>images</b> <b>are</b> ordinary scene pictures in daily life. There <b>are</b> about 200 <b>images</b> of each camera device (Table  3).|$|R
50|$|<b>All</b> <b>the</b> <b>images</b> <b>are</b> {{fixed on}} a painted stepped base made of sandalwood. The base, covered {{completely}} with ivory sheet has the traditional south Indian design {{of flowers and}} is decorated with several knobs fixed at the bottom step. Also two pillars support the fence in the background on both sides.|$|R
40|$|Note: Alle Bilder weisen eine 'old no. ' auf. Sie waren Teil der 'offiziellen Sammlung', wurden jedoch aus dem Standort C- 30, resp. QC- 30 ausgegliedert, da es sich nicht um Indien-Bilder handelt.; Note translation: <b>All</b> <b>the</b> <b>images</b> <b>were</b> {{once part of}} the "Official series" of the Basel Mission {{and have}} the {{appropriate}} old reference numbers. They {{seem to have been}} taken out of the C- 30 (or perhaps in some cases the QC- 30) series because they are pictures of Ceylon, not India...|$|E
30|$|Additionally, <b>all</b> <b>the</b> <b>images</b> <b>were</b> geometrically {{corrected}} to remove, haze, scan {{lines and}} speckles; and referenced to the Mississippi ground based coordinate system and Datum. From there, Landsat ETM+ data of November 18, 1999 and November 27, 1999 were mosaicked. This {{was followed by}} a histogram equalization enhancement technique performed on all the images. Later, the counties (Hancock, Harrison, Jackson, George, Stone and Pearl River) Shape file was imported into ERDAS, and used as ERDAS Area of Interest Tool (AOI) file to subset the ETM+ image of the study area.|$|E
40|$|Part 1 : Decision Support Systems, Intelligent Systems and Artificial Intelligence ApplicationsInternational audienceFor {{the purpose}} of {{classification}} of fish species, a recognition system was preliminary designed using computer vision. In the first place, pictures were pre-processed by developed programs, dividing into rectangle pieces. Secondly, color and texture features are extracted for those selected texture rectangle fish skin images. Finally, <b>all</b> <b>the</b> <b>images</b> <b>were</b> classified by multi-class classifier named SVMs. The experiment showed that color and texture are the appropriate features for fish species classification. The multi-class classifier based on SVM will be developed for further work...|$|E
40|$|Everyday Dada is {{a series}} of 50 colour {{photographs}} arranged over 4 chapters. <b>All</b> <b>the</b> <b>images</b> <b>are</b> made using food in some way and the book functions as an artwork itself with no written text or explanation. The scale and the lack of writing means that <b>the</b> <b>images</b> function in a totally democratic way, communicating all they need to visually...|$|R
40|$|The Cover Picture: A {{rendering}} of a geometric {{model of the}} CM 200 Connection Machine installed at KTH. Images sampled from different projects at PDC have been texture mapped onto the surfaces not occupied by LEDs. <b>All</b> <b>the</b> <b>images</b> <b>are</b> results from production runs at the CM 200 at PDC. The rendering model was developed with the visualization software AVS by Joha...|$|R
5000|$|MIR JAWAHAR ALI has the {{possession}} of religious valuables including stick of Ja'far al-Sadiq, hand written of Imam e Jafar a.s, piece of wood belongs to Imam e Sadiq and one water drinking cup made up of wood. These valuavles are still in possesion with Nasir Jafri's family in Karachi. <b>All</b> <b>the</b> <b>images</b> <b>are</b> stored Wikimedia Commons with the tag of this username.|$|R
30|$|For {{structural}} analysis of polymeric hydrogel scaffold (PVP–CMC–CaCO 3) always lyophilized (swelled samples were freeze dried under – 81  °C for 72  h and then lyophilized for 24  h to produce porous scaffold) samples were used. The morphology of swelled biomineralized (CaCO 3) hydrogel {{in the presence}} of GS, US and PS was investigated using scanning electron microscopy (SEM: Phenom world Pro) which is operated in the high vacuum/secondary electron imaging mode at an accelerating voltage of 5 – 20  kV). <b>All</b> <b>the</b> <b>images</b> <b>were</b> taken at the magnification of 100 ×– 10 k× and always freeze drying samples were used for cross-sectional studies.|$|E
40|$|In the {{seasonal}} tropics, vegetation shows large reflectance variation because of phenology, which complicates land cover change monitoring. Ideally, multi-temporal images for change monitoring should {{be from the}} same season, but availability of cloud-free images is limited in wet season in comparison to dry season. Our aim was to investigate how land cover classification accuracy depends on the season in southern Burkina Faso by analyzing 14 Landsat 8 OLI images from April 2013 to April 2014. Because <b>all</b> <b>the</b> <b>images</b> <b>were</b> acquired within one year, we assumed {{that most of the}} observed variation between the images was due to phenology. <b>All</b> <b>the</b> <b>images</b> <b>were</b> cloud masked and atmospherically corrected. Field data was collected from 160 field plots located within a 10 km × 10 km study area between December 2013 and February 2014. The plots were classified to closed forest, open forest and cropland, and used as training and validation data. Random forest classifier was employed for classifications. According to the results, there is a tendency for higher classification accuracy towards the dry season. The highest classification accuracy was provided by an image from December, which corresponds to the dry season and minimum NDVI period. In contrast, an image from October, which corresponds to the wet season and maximum NDVI period provided the lowest accuracy. Furthermore, the multi-temporal classification based on dry and wet season images had higher accuracy than single image classifications, but the improvement was small because seasonal changes affect similarly to the different land cover classes...|$|E
30|$|The {{multiband}} and fluorescence {{images were}} acquired using a 8.3 Megapixels Chroma C 4 scientific camera from DTA Scientific Instruments s.r.l. Two series of multi-band images were acquired {{of the left}} and right parts of the artwork using six interferential filters (centered at 400, 450, 550, 600, 750 and 1, 050  nm, with bandpass ±  25  nm) in front of the CCD sensor. <b>All</b> <b>the</b> <b>images</b> <b>were</b> white-balanced using as a reference a Spectralon and then reunited to form single high resolution images of the whole painting. For the specific information sought in our work, we used the classical four bands (RGB + IR) for building RGB, False Colours and UV–Visible fluorescence images). The UV–Visible fluorescence image was obtained illuminating the painting with high pressure Hg lamps.|$|E
30|$|We {{compare the}} {{proposed}} network with BN 1, BN 2, FLBP, and NRLBPs on the AR database injected with Gaussian noise, uniform noise, {{and salt and}} pepper noise. For FLBP and NRLBPs, <b>all</b> <b>the</b> <b>images</b> <b>are</b> normalized to 100 [*]×[*] 80  pixels and divided into 20 patches of 20 [*]×[*] 20  pixels. For the NR-Network, BN 1, and BN 2, <b>the</b> <b>images</b> <b>are</b> normalized to 64 [*]×[*] 64  pixels.|$|R
40|$|Artist Statement I {{forget my}} keys and usually {{misplace}} my telephone but I {{know exactly where}} my camera is at any given moment. I capture moments for my artwork {{as well as my}} own personal benefit. Not <b>all</b> <b>the</b> <b>images</b> will <b>be</b> translated into paint or clay and not <b>all</b> <b>the</b> <b>images</b> <b>are</b> those filled with beauty. However, a bicycle leaning on the corner of a house in Key West and a two hundred dollar pair of shoes from when I was single {{are a few of the}} memories that evolved from snapshot to artwork. My photographs inspire my colorful paintings and patterned clay work. I use them as a way to document my personal journeys and evolution of my life...|$|R
40|$|We {{present a}} novel method for {{aligning}} images in an HDR (high-dynamic-range) image stack {{to produce a}} new exposure stack where <b>all</b> <b>the</b> <b>images</b> <b>are</b> aligned and appear {{as if they were}} taken simultaneously, even in the case of highly dynamic scenes. Our method produces plausible results even where <b>the</b> <b>image</b> used as a reference is either too dark or bright to allow for an accurate registration. 1...|$|R
30|$|Overlapping {{sections}} of the aerial photographs were carefully trimmed out in order to minimise image parallax, using image subsetting procedures within ERDAS. In order to optimise {{the contrast between the}} light and dark tones, contrast on each trimmed image was enhanced by spreading the digital number (DN) values on the full grey level scale range using a linear stretch. After separately mapping the woody cover on the respective aerial photographs from a given analysis year and study site, using image classification, the photographs were joined into thematic layer mosaics. <b>All</b> <b>the</b> <b>images</b> <b>were</b> carefully examined for presence of burn scars whose dark tone could have introduced error in mapping woody cover. Consequently the 1940 photographs of the Nhlowa site were excluded from the analysis due to extensive burn scars.|$|E
30|$|Images of {{four types}} of {{melanoma}} (acral lentiginous, lentigo maligna, nodular, superficial spreading) and {{four types of}} benign pigmented lesion (blue nevi, lentigo, melanocytic nevi, seborrheic keratoses) {{were used in the}} current study. Images of skin lesion were collected via Google image search by using the name of the lesion type (e.g. lentigo maligna) as the key words. The accuracy of the diagnosis of <b>all</b> <b>the</b> <b>images</b> <b>were</b> then validated by an expert dermatologist. This validation procedure excluded 11 images from the study, either because of the uncertainty of the diagnosis from visual inspection of the images alone or the existence of more than one type of melanoma lesion in the same image (e.g. lentigo maligna with a nodular component). The remaining 237 images (120 melanoma, 117 benign) were scaled to fit within a frame of 300 × 300 pixels and cropped to remove any body part information.|$|E
40|$|First-person stories can be {{analyzed}} by means of egocentric pictures acquired throughout the whole active day with wearable cameras. This manuscript presents an egocentric dataset with more than 45, 000 pictures from four people in different environments such as working or studying. <b>All</b> <b>the</b> <b>images</b> <b>were</b> manually labeled to identify three patterns of interest regarding people's lifestyle: socializing, eating and sedentary. Additionally, two different approaches are proposed to classify egocentric images {{into one of the}} 12 target categories defined to characterize these three patterns. The approaches are based on machine learning and deep learning techniques, including traditional classifiers and state-of-art convolutional neural networks. The experimental results obtained when applying these methods to the egocentric dataset demonstrated their adequacy for the problem at hand. Comment: Accepted at First International Workshop on Social Signal Processing and Beyond, 19 th International Conference on Image Analysis and Processing (ICIAP), September 201...|$|E
3000|$|... {{was set to}} {{the least}} {{possible}} value so that the resulting sub-images fitted into GPU memory. For example, if <b>the</b> <b>image</b> <b>was</b> small enough, <b>the</b> decomposition was not performed at <b>all,</b> <b>the</b> larger <b>the</b> <b>image</b> <b>was</b> <b>the</b> more parts it was decomposed into.|$|R
60|$|It {{should be}} observed, that <b>all</b> <b>the</b> imagery in the speeches {{of the men}} is taken from the East, and {{is no more than}} a mere {{representation}} of the forms of material nature. But when God speaks, the tone is exalted; and almost <b>all</b> <b>the</b> <b>images</b> <b>are</b> taken from Egypt, the crocodile, the war-horse, and so forth. Egypt was then the first monarchy that had a splendid court.|$|R
3000|$|<b>The</b> <b>images</b> {{supporting}} <b>the</b> {{conclusions of}} this article are available in <b>the</b> “Test <b>Images</b> of Computer Vision Group”, <b>All</b> of <b>the</b> <b>images</b> <b>are</b> Copyright free. [URL] [...]...|$|R
