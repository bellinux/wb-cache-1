9|13|Public
30|$|Plasma {{samples were}} assayed for {{diazoxide}} using a validated analytical method, {{according to the}} principles of good laboratory practice (GLP) [US Department of Health and Human Services 2010, Organisation for Economic Co-operation and Development (OECD) 2006). Tandem mass spectrometry was used for diazoxide detection. This analytical method was developed and validated at Pharma Medica Research Inc. All samples from a given subject were analyzed in a single <b>analytical</b> <b>batch.</b> The lower limit of quantitation (LLOQ) of this assay was 50.0 ng/mL and the precision and accuracy at this level during study sample analysis were 5.6 % and 100.2 % respectively. Any value below the LLOQ is reported as below the limit of quantitation (BLQ).|$|E
40|$|Internal {{quality control}} (IQC) {{is one of}} the most {{important}} elements contributing to quality assurance in the laboratory. In this study, the strategy for the implementation of an IQC program to monitor performance of the analytical procedures used in an antidoping control laboratory is presented. Different IQC parameters have been defined according to the aim of the method (qualitative or quantitative, screening or confirmation). They are based on the analysis of control and calibration samples in each <b>analytical</b> <b>batch</b> and on the use of an internal standard in chromatographic methods. IQC parameters for chromatographic and immunological methods and the acceptance criteria used to check the quality control data obtained are described and discussed. These IQC procedures have been applied during routine antidoping analyses of more than 5000 samples per year in a laboratory accredited by the International Olympic Committee (IOC) and meeting the requirements o...|$|E
40|$|Chiral 2 -hydroxypropanone {{derivatives}} 5 a-v, 8 a-d, and 10 a, b {{were formed}} by benzoylformate decarboxylase (BFD) catalyzed C-C bond formation. A donor aldehyde and acetaldehyde as an acceptor were carboligated in aqueous buffer solution with remarkable ease in high chemical yield and good to high optical purity. The substrate range of this thiamin diphosphate dependent enzyme was examined to employ this benzoin condensation type reaction in stereoselective synthesis. The observed {{dependence of the}} enantiomeric excess on the substitution pattern could be exploited to design substrates resulting in high selectivity Best substrates with regard to optical purity were meta-substituted benzaldehyde derivatives. To enable a general and convenient applicability of the BFD-catalyzed C-C bond formation, <b>analytical</b> <b>batch</b> experiments were scaled up to give (S) - 2 -hydroxy ketones in good to high yields on a preparative scale. Further, the solubility {{of some of the}} organic substrates in aqueous solution was increased by the use of cyclodextrin or buffer/DMSO mixtures...|$|E
40|$|Introduction Availability {{of large}} cohorts of samples with related {{metadata}} provides scientists with extensive material for studies. At the same time, recent development of modern high-throughput 'omics' technologies, including metabolomics, {{has resulted in}} the potential for analysis of large sample sizes. Representative subset selection becomes critical for selection of samples from bigger cohorts and their division into <b>analytical</b> <b>batches.</b> This especially holds true when relative quantification of compound levels is used. Objectives We present a multivariate strategy for representative sample selection and integration of results from multi-batch experiments in metabolomics. Methods Multivariate characterization was applied for design of experiment based sample selection and subsequent subdivision into four <b>analytical</b> <b>batches</b> which were analyzed on different days by metabolomics profiling using gas-chromatography time-of-flight mass spectrometry (GC-TOFMS). For each batch OPLS-DA (R) was used and its p(corr) vectors were averaged to obtain combined metabolic profile. Jackknifed standard errors were used to calculate confidence intervals for each metabolite in the average p(corr) profile. Results A combined, representative metabolic profile describing differences between systemic lupus erythematosus (SLE) patients and controls was obtained and used for elucidation of metabolic pathways that could be disturbed in SLE. Conclusion Design of experiment based representative sample selection ensured diversity and minimized bias that could be introduced at this step. Combined metabolic profile enabled unified analysis and interpretation. Open Access, link to the Creative Commons license: [URL]...|$|R
5000|$|... 2. Impuritiesa) Sources of Potential Impurities.b) Types of impurities.c) Test Procedure for {{determining}} impurities.D. CONTROL OF DRUG SUBSTANCES1. Specifications2. Analytical procedure (STP)3. Validation of <b>Analytical</b> procedure4. <b>Batch</b> Analysisa) Description of Batchesb) Certificate of Analysis5. Justification of Specification ...|$|R
40|$|Due to its {{unsurpassed}} {{sensitivity and}} selectivity, LC-HRMS {{is one of}} the major analytical techniques in metabolomics research. However, limited stability of experimental and instrument parameters may cause shifts and drifts of retention time and mass accuracy or the formation of different ion species, thus complicating conclusive interpretation of the raw data, especially when generated in different <b>analytical</b> <b>batches.</b> Here, a novel software tool for the semi-automated alignment of different measurement sequences is presented. The tool is implemented in the Java programming language, it features an intuitive user interface and its main goal is to facilitate the comparison of data obtained from different metabolomics experiments. Based on a feature list (i. e., processed LC-HRMS chromatograms with mass-to-charge ratio (m/z) values and retention times) that serves as a reference, the tool recognizes both m/z and retention time shifts of single or multiple analytical datafiles/batches of interest. MetMatch is also designed to account for differently formed ion species of detected metabolites. Corresponding ions and metabolites are matched and chromatographic peak areas, m/z values and retention times are combined into a single data matrix. The convenient user interface allows for easy manipulation of processing results and graphical illustration of the raw data as well as the automatically matched ions and metabolites. The software tool is exemplified with LC-HRMS data from untargeted metabolomics experiments investigating phenylalanine-derived metabolites in wheat and T- 2 toxin/HT- 2 toxin detoxification products in barley...|$|R
40|$|This report {{describes}} the validation of a cost effective method for quantifying phytic acid in grains, namely, rice and wheat, using UV/Vis spectroscopy. Background information describing phytic acid {{and its impact}} on human biological systems and hence the importance of its analysis is included in this report. The validation method involved a range of tests to determine accuracy, precision and reproducibility of the method. Multiple sample matrices were used including standards and spiked samples as described in the validation plan and criteria in Appendix 2. The method employed a commercially available assay kit from Megazyme® and was found to give accurate reliable data according to the performance characteristics attained. This method also has the potential for transfer to laboratories with limited resources, in particular developing countries. It is applicable to survey scale and small batch analysis owing to its relatively low start up and running costs, fast analysis time and ease of instrument set up for each <b>analytical</b> <b>batch</b> compared to established methods using ion chromatography...|$|E
40|$|AbstractThis article {{presents}} investigations to transfer an <b>analytical</b> <b>batch</b> electro-chromatography to a continuous annular electro-chromatography process. In order {{to study the}} electro-chromatographic effects of such a process a lab scale planar reference system was manufactured and tested. This planar device represents {{a fraction of the}} final annular geometry. An inorganic C 8 reversed-phase monolith was filled between two glass plates as stationary phase inside a 1 mm gap. The generation of Joule heating during the process was determined by using a contact-free thermal camera system. Additionally, the volume flow rate of the electrolyte was detected at the outlet geometry with a continuous imaging analysis system using the transmitted light method. Finally, a mixture of neutral test substances was used to evaluate the continuous separation and to compare the results of the planar plate with an analytical capillary. The obtained results indicate a uniform electro-osmotic flow as well as a successful separation of the test system and a good agreement between the efficiency of the planar gap and an analytical capillary electro-chromatographic device...|$|E
30|$|The samples pretreated with 100  mM {{ammonium}} {{acetate buffer solution}} were extracted using SPE cartridge. This extraction procedure gave higher PE and cleaner sample. Due to hydrophobic nature of LS, different polymeric cartridges like Oasis HLB, Bond Elut Plexa, Cleanert PEP-H, and Cleanert PEP- 3 were tried during method development. The high PE and consistent results were obtained in sample prepared using Cleanert PEP- 3 cartridges. Inconsistency in peak area response of LS and IS was observed during analysis of extracted samples. This {{could be due to}} low solubility of LS and IS in the mobile phase that was finalized during chromatographic optimization. Low solubility of LS and IS could be due to the high hydrophobic nature of these compound, which led to suppressed LS and IS peak area response in the extracted samples. Therefore, the reconstitution solution composition was further optimized and it was observed that reconstitution solution consisting acetonitrile 2  mM {{ammonium acetate}} (pH  3.6) buffer (60 : 40, v/v) was suitable for solubility of LS and IS and gave consistent IS peak area throughout the <b>analytical</b> <b>batch</b> of larger sample size.|$|E
40|$|Composites of {{actinide}} oxides dispersed in a Mo {{metal matrix}} {{is a recent}} inert matrix fuel (IMF) concept for the transmutation of Pu and the minor actinides (MA = Np, Am, Cm). These elements are present in spent nuclear fuel, and their long term radiotoxicity can be minimised if they are recovered from the fuel and irradiated in dedicated targets nuclear reactors. The synthesis of such highly radioactive fuels is not simple and given the high radiotoxicity of Am, the safety of operation of such a process must be examined for production of small scale <b>analytical</b> <b>batches.</b> Infiltration of Am nitrate infiltration into porous PuO 2 beads has potential safety bonuses. The beads are produced by sol-gel external gelation route. Tests have been made here with CeO 2, as a surrogate for PuO 2 and have been optimised for both bead production and pelletisation of a blend of calcined beads and Mo powder. Addition of carbon to the sol gel feed solution, and its subsequent pyrolysis provides a means to optimise the porosity of the oxide beads. It acts as a pore former. The highest quality product meeting typical fuel specifications required addition of 20 g/litre carbon in the sol-gel feed and calcination of the CeO 2 beads at 800 ˚C. Subsequent Mo cermet composites with 20 or 40 % by volume of ceramic reached densities in excess of 90 % of the theoretical value as is required for nuclear reactor applications. Finally, the step from CeO 2 surrogates to (Pu,Am) O 2 targets has been made. JRC. E. 4 -Nuclear fuel...|$|R
40|$|Metabolomics {{research}} {{often requires}} {{the use of}} multiple <b>analytical</b> platforms, <b>batches</b> of samples, and laboratories, any of which can introduce a component of unwanted variation. In addition, every experiment is subject to within-platform and other experimental variation, which often includes unwanted biological variation. Such variation must be removed in order to focus on the biological information of interest. We present a broadly applicable method for the removal of unwanted variation arising from various sources for the identification of differentially abundant metabolites and, hence, for the systematic integration of data on the same quantities from different sources. We illustrate the versatility and the performance of the approach in four applications, and we show that it has several advantages over the existing normalization methods. © 2012 American Chemical Society...|$|R
40|$|BGS 102, a {{guidance}} material for bioaccessible arsenic (As) and lead (Pb), was produced during {{validation of the}} in vitro Unified Bioaccessibility Method (UBM). This paper reports a compilation of reproducible bioaccessible guidance values for fifty-five additional elements in BGS 102, providing guidance for analysts to broaden the scope of UBM analyses for {{a wider range of}} elements based on data collected over an average of 60 separate <b>analytical</b> <b>batches</b> per element. Data are presented in categories for both gastric (STOM) and gastrointestinal (STOM + INT) extraction phases, where reproducibility, measured as relative standard deviation (RSD) was; ≤ 10 % RSD for 27 elements (Mg, Al, Si, P, Ca, Cr, Mn, Co, Ni, As, Rb, Sr, Y, Ba, La, Ce, Pr, Nd, Sm, Eu, Tb, Gd, Dy, Ho, Er, Tm, Yb); between 10 and 20 % RSD for 10 elements (Li, K, V, Fe, Cu, Zn, Cd, Lu, Pb, U); and ≥ 20 % RSD for 19 elements in the gastric phase (Be, B, S, Ti, Ga, Se, Zr, Nb, Mo, Ag, Sn, Sb, Cs, Hf, Ta, W, Tl, Bi, Th). Two elements (Mg, Rb) met the ≤ 10 % RSD criteria in the UBM gastrointestinal extraction phase due to the alkaline conditions of this phase precipitating out the majority of determinands. Certain elements, including Na, K, Zn and Se, were found to be a significant component of the extraction fluids with proportionally higher concentrations compared to the {{guidance material}}. Bioaccessible fractions (%BAF) were also calculated, but were found to be a less reproducible format for confirming the accuracy of measurements. The low concentration of some elements of interest in BGS 102, such as antimony (Sb), justifies the preparation of an alternative certified reference material (CRM). This paper presents an opportunity to broaden the scope of the UBM method to address food security issues (e. g. Fe and Zn micronutrient deficiencies) and contributions to dietary intake from extraneous dust or soil through evidence of the analytical possibilities and current limitations requiring further investigation...|$|R
40|$|Simulating {{the storage}} of aerobic soils under water, the {{chemical}} speciation of heavy metals and arsenic was studied over a long-term reduction period. Time-dynamic and redox-discrete measurements in reactors were used to study geochemical changes. Large kinetic differences in the net-complexation quantities of heavy metals with sulfides was observed, and elevated pore water concentrations remained for a prolonged period (> 1 year) specifically for As, B, Ba, Co, Mo, and Ni. Arsenic is associated to the iron phases as a co-precipitate or sorbed fraction to Fe-(hydr) oxides, and it is being released into solution {{as a consequence of}} the reduction of iron. The composition of dissolved organic matter (DOM) in reducing pore water was monitored, and relative contributions of fulvic, humic and hydrophylic compounds were measured via <b>analytical</b> <b>batch</b> procedures. Quantitative and qualitative shifts in organic compounds occur during reduction; DOM increased up to a factor 10, while fulvic acids become dominant over humic acids which disappear altogether as reduction progresses. Both the hydrophobic and hydrophilic fractions increase and may even become the dominant fraction. Reactive amorphous and crystalline iron phases, as well as dissolved FeII/FeIII speciation, were measured and used as input for the geochemical model to improve predictions for risk assessment to suboxic and anaerobic environments. The release of arsenic is related to readily reducible iron fractions that may be identified by 1 mM CaCl 2 extraction procedure. Including DOM concentration shifts and compositional changes during reduction significantly improved model simulations, enabling the prediction of peak concentrations and identification of soils with increased emission risk. Practical methods are suggested to facilitate the practice of environmentally acceptable soil storage under water. </p...|$|E
40|$|In 1999, an {{international}} standard ISO 17025 made {{the calculation of}} measurement uncertainty for all analytical test results mandatory. Little guidance was available. How to account for bias in measurement uncertainty was contentious. Many analytical chemistry sectors proposed different ways of including bias in the uncertainty estimate. Six different approaches were investigated: (i) Always correcting for bias; (ii) Correcting for bias when significant; (iii) Including the bias by quadrature with the combined measurement uncertainty; (iv) Including the bias by quadrature in the expanded measurement uncertainty; (v) Adding the bias to the expanded uncertainty to give an asymmetrical confidence interval; (vi) Adding the absolute bias to the expanded uncertainty. Each of these approaches was evaluated by Monte Carlo simulation. It was found that always correcting for bias and including {{the uncertainty of the}} correction had the best outcome. If this was not possible then correcting for significant bias performed better than most other approaches. However, clarification needed to be made on what constituted the bias of a test result. Was bias to be determined within a batch run, between a batch run or between laboratories? This question was answered by looking at interlaboratory proficiency data which showed that run bias was indeed the bias of an analytical test result and therefore a correction when necessary should be made on that basis. This run bias needed to be determined across the concentration range of the analysis. Performing a regression analysis of the trueness of the <b>analytical</b> <b>batch</b> run solved this problem. The uncertainty of this regression approach was determined and applied to experimental test data. A comparison of the different approaches was then determined and it was concluded that the uncertainty based on the run bias approach gave the most realistic estimate of the uncertainty of measurement...|$|E
40|$|Children {{who develop}} type 1 {{diabetes}} early in life show low levels of carnitine and amino acids at birth: does this finding {{shed light on the}} etiopathogenesis of the disease? G la Marca 1, 2, S Malvagia 1, S Toni 3, B Piccini 3, V Di Ciommo 4 and GF Bottazzo 5 BACKGROUND: Children and adolescents with overt {{type 1 diabetes}} (T 1 D) have been found to show an altered carnitine profile. This pattern has not previously been analyzed in neonates before onset of the disease. MATERIALS AND METHODS: Fifty children who developed T 1 D during the first 6 years of life, born and living in the Tuscany and Umbria Regions of Italy, were identified and 200 controls were recruited into the study. All newborns were subjected to extended neonatal screening by mass spectrometry at 48 – 72 h of life. Four controls for each of the 50 index cases were taken randomly and blinded in the same <b>analytical</b> <b>batch.</b> The panel used for neonatal screening consists of 13 amino acids, free carnitine, 33 acyl-carnitines and 21 ratios. All Guthrie cards are analyzed within 2 days of collection. RESULTS: Total and free carnitine were found to be significantly lower in neonates who later developed T 1 D compared with controls. Moreover, the concentrations of the acyl-carnitines – acetyl-L-carnitine (C 2), proprionylcarnitine (C 3), 3 -hydroxy-isovalerylcarnitine (C 5 OH), miristoylcarnitine (C 4), palmitoylcarnitine (C 16) and stearoylcarnitine (C 18) – were also significantly low in the cases vs controls. Furthermore, total amino-acid concentrations, expressed as the algebraic sum of all amino acids tested, showed a trend toward lower levels in cases vs controls. CONCLUSIONS: We found that carnitine and amino-acid deficit may be evident before the clinical appearance of T 1 D, possibly from birth. The evaluation of these metabolites in the neonatal period of children human leukocyte antigen genetically at ‘risk ’ to develop T 1 D, could represent an additional tool for the prediction of T 1 D and could also offer the possibility to design new strategies for the primary prevention of the disease from birth...|$|E
40|$|To better {{understand}} the molecular mechanisms underpinning physiological variation in human populations, metabolic phenotyping approaches are increasingly being applied to studies involving hundreds and thousands of biofluid samples. Hyphenated ultra-performance liquid chromatography-mass spectrometry (UPLC-MS) has become a fundamental tool for this purpose. However, the seemingly inevitable need to analyze large studies in multiple <b>analytical</b> <b>batches</b> for UPLC-MS analysis poses a challenge to data quality which has been recognized in the field. Herein, we describe in detail a fit-for-purpose UPLC-MS platform, method set, and sample analysis workflow, capable of sustained analysis on an industrial scale and allowing batch-free operation for large studies. Using complementary reversed-phase chromatography (RPC) and hydrophilic interaction liquid chromatography (HILIC) together with high resolution orthogonal acceleration time-of-flight mass spectrometry (oaTOF-MS), exceptional measurement precision is exemplified with independent epidemiological sample sets of approximately 650 and 1000 participant samples. Evaluation of molecular reference targets in repeated injections of pooled quality control (QC) samples distributed throughout each experiment demonstrates a mean retention time relative standard deviation (RSD) of < 0. 3 % across all assays in both studies and a mean peak area RSD of < 15 % in the raw data. To more globally assess {{the quality of the}} profiling data, untargeted feature extraction was performed followed by data filtration according to feature intensity response to QC sample dilution. Analysis of the remaining features within the repeated QC sample measurements demonstrated median peak area RSD values of < 20 % for the RPC assays and < 25 % for the HILIC assays. These values represent the quality of the raw data, as no normalization or feature-specific intensity correction was applied. While the data in each experiment was acquired in a single continuous batch, instances of minor time-dependent intensity drift were observed, highlighting the utility of data correction techniques despite reducing the dependency on them for generating high quality data. These results demonstrate that the platform and methodology presented herein is fit-for-use in large scale metabolic phenotyping studies, challenging the assertion that such screening is inherently limited by batch effects. Details of the pipeline used to generate high quality raw data and mitigate the need for batch correction are provided...|$|R
30|$|Present study {{explores the}} {{potentiality}} of locally available cellulose, hemicellulose and lignin-rich agricultural by-product sugarcane bagasse (SB) {{for the removal}} of erythrosin B (EB) and methylene blue (MB) from aqueous waste. The SB has been characterized by Fourier transform infrared and scanning electron microscopy <b>analytical</b> techniques. <b>Batch</b> experiments have been carried out to determine the influence of parameters like initial dye concentration, pH of the medium, contact time between the adsorbate and adsorbent, weight of adsorbent and system temperature on the removal of EB and MB. Optimum conditions for adsorption are found to be pH 9, temperature 308  K and an equilibration time of 1  h. Under these conditions equilibrium isotherms have been analysed by Langmuir and Freundlich isotherm equations. Based on the Langmuir adsorption isotherm model, the predicted maximum monolayer adsorption capacities of SB for EB and MB are found to be 500  mg g– 1 (at 328  K) and 1, 000  mg g– 1 (at 308  K), respectively. The separation factor reveals the favourable nature of the isotherm for the studied dyes—SB system. The thermodynamic study indicates that the adsorptions of dyes are spontaneous and endothermic process. High temperatures favour EB adsorption whereas optimum temperature for MB adsorption is 318  K.|$|R
40|$|Metabolomics, the {{measurement}} of {{a broad range of}} small molecules in a sample, is maturing as a field in analytical chemistry and becoming a standard research tool in biological sciences for helping to generate a wider understanding of the complex biological mechanisms behind, for example, development of disease and effects of diet on health. Metabolomics analysis is generally divided into either targeted or untargeted metabolomics. The former ‘targets’ a specific set of molecules, often quantitatively, while the latter aims to detect as many metabolites as possible in the sample. Both of these approaches have their advantages and disadvantages, and combining both into one single analytical method could allow the specificity, sensitivity, and quantitation of targeted metabolomics to be combined with the broad coverage and potential to find unknown compounds that are the key advantages of untargeted metabolomics. In this thesis, a novel gas chromatography triple quadrupole metabolomics (GC-MS) method that exploits fast data acquisition to simultaneously acquire both targeted quantitative data using multiple reaction and selected ion monitoring, and untargeted qualitative data using full spectrum scanning. The method was developed for human blood plasma and applied to two studies. The first was a crossover intervention study comparing metabolic effects of consumption of herring with chicken and pork in 15 adults. The second was a prospective cohort of 600 older Swedish women for discovering predictive biomarkers of development of type 2 diabetes (T 2 D) and for exploration of the associations between potential dietary and nutrient biomarkers and glucose tolerance status and development of T 2 D in the same cohort. The evaluated method parameters (linearity, limit of detection and quantification, precision, accuracy, number of spectral features) supports the approach of combining targeted quantitative and untargeted qualitative data acquisition as a way to improve GC-MS metabolomics. The method was successfully applied to the analysis of 1200 samples from 600 subjects, measured over 24 separate <b>analytical</b> <b>batches</b> with an average within batch metabolite variation of 10 %, based on control sample metabolites detected using multiple reaction monitoring. In the intervention study, the new metabolomics method detected 190 identified metabolites, of which 18 were altered when subjects ate herring instead of chicken and pork. These changes were mainly around the tricarboxylic acid and urea cycles, with an apparent differential effect related to arginine metabolism. This finding was supported by finding that circulating nitric oxide was higher in male subjects after the herring diet compared to the chicken and pork diets. In the cohort study, we established that the best predictive markers of T 2 D detected using metabolomics improved on or had similar prediction to established predictors of T 2 D. Using a combination of both the targeted and untargeted data, we were also able to detect 10 dietary and nutrient biomarkers, many of which were strongly associated with glucose tolerance status and development of T 2 D in this cohort. This {{is one of the first}} studies using multiple dietary and nutrient biomarkers that suggests a clear role of diet in prevention of T 2 D. This supports the current dietary guidelines for eating whole grains and fish for preventing T 2 D. In conclusion, the metabolomics method developed as part of this thesis detects a wide array of known biomarkers in blood plasma while still providing global untargeted information and having the possibility of expansion by addition of targeted molecules of interest. The method proved to be robust during the analysis of a moderately sized sample set, supporting its further use in observational cohorts. Results from the application of this metabolomics method further support the potential of metabolomics to add value to biological research by highlighting diverse outcome- metabolite relationships that may otherwise be overlooked...|$|R
40|$|A {{biomimetic}} sensor {{is proposed}} as a promising new analytical method for determination of captopril in different classes of samples. The sensor was prepared by modifying a carbon paste electrode with iron (II) phthalocyanine bis(pyridine) [FePe(dipy) ] complex. Amperometric measurements in a <b>batch</b> <b>analytical</b> mode were first {{carried out in}} order to optimize the sensor response. An applied potential lower than 0. 2 V vs Ag vertical bar AgCl in 0. 1 mol L(- 1) of TRIS buffer at pH 8. 0 provided the best response, with a linear range of 2. 5 x 10 (- 5) to 1. 7 x 10 (- 4) mol L(- 1). A detailed investigation of the selectivity of the sensor, employing seventeen other drugs, was also performed. Recovery {{studies were carried out}} using biological and environment samples in order to evaluate the sensor`s potential for use with these sample classes. Finally, the performance of the biomimetic sensor was optimized in a flow injection (FIA) system using a wall jet electrochemical cell. Under optimized flow conditions, a broad linear response range, from 5. 0 x 10 (- 4) to 2. 5 x 10 (- 2) mol L(- 1), was obtained for captopril, with a sensitivity of 210 +/- 1 mu A L mol(- 1) ...|$|R
40|$|Abstract. As data {{warehousing}} technology gains a ubiquitous presence in business today, companies {{are becoming increasingly}} reliant upon {{the information contained in}} their data warehouses to inform their operational decisions. This information, known as business intelligence (BI), traditionally has taken the form of nightly or monthly reports and <b>batched</b> <b>analytical</b> queries that are run at specific times of day. However, as the time needed for data to migrate into data warehouses has decreased, and as the amount of data stored has increased, business intelligence has come to include metrics, streaming analysis, and reports with expected delivery times that are measured in hours, minutes, or seconds. The challenge is that {{in order to meet the}} necessary response times for these operational business intelligence queries, a given warehouse must be able to support at any given time multiple types of queries, possibly with different sets of performance objectives for each type. In this paper, we discuss why these dynamic mixed workloads make workload management for operational business intelligence (BI) databases so challenging, review current and proposed attempts to address these challenges, and describe our own approach. We have carried out an extensive set of experiments, and report on a few of our results. ...|$|R
40|$|Thesis (Ph. D.) -University of KwaZulu-Natal, Durban, 2008. Wireless {{communication}} systems have demonstrated tremendous {{growth over the}} last decade, and this growth continues unabated worldwide. The networks have evolved from analogue based first generation systems to third generation systems and further. We are envisaging a Next Generation Network (NGN) that should deliver anything anywhere anytime, with full quality of service (QoS) guarantees. Delivering anything anywhere anytime is a challenge that is a focus for many researchers. Careful teletraffic design is required for this ambitious project to be realized. This research goes through the protocol choices, design factors, performance measures and the teletraffic analysis, necessary to make the project feasible. The first significant contribution of this thesis {{is the development of}} a Call Admission Control (CAC) model as a means of achieving QoS in the NGN’s. The proposed CAC model uses an expanded set of admission control parameters. The existing CAC schemes focus on one major QoS parameter for CAC; the Code Division Multiple Access (CDMA) based models focus on the signal to interference ratio (SIR) while the Asynchronous Transfer Mode (ATM) based models focus on delay. A key element of NGN’s is inter-working of many protocols and hence the need for a diverse set of admission control parameters. The developed CAC algorithm uses an expanded set of admission control parameters (SIR, delay, etc). The admission parameters can be generalized as broadly as the design engineer might require for a particular traffic class without rendering the analysis intractable. The second significant contribution of this thesis is the presentation of a complete teletraffic analytical model for an NGN. The NGN network features the following issues; firstly, NGN call admission control algorithm, with expanded admission control parameters; secondly, multiple traffic types, with their diverse demands; thirdly, the NGN protocol issues such as CDMA’s soft capacity and finally, scheduling on both the wired and wireless links. A full teletraffic analysis with all analytical challenges is presented. The analysis shows that an NGN teletraffic model with more traffic parameters performs better than a model with less traffic parameters. The third contribution of the thesis is the extension of the model to traffic arrivals that are not purely Markovian. This work presents a complete teletraffic <b>analytical</b> model with <b>Batch</b> Markovian Arrival (BMAP) traffic statistics unlike the conventional Markovian types. The Markovian traffic models are deployed for analytical simplicity at the expense of realistic traffic types. With CAC, the BMAP processes become non-homogeneous. The analysis of homogeneous BMAP process is extended to non-homogeneous processes for the teletraffic model in this thesis. This is done while incorporating all the features of the NGN network. A feasible analytical model for an NGN must combine factors from all the areas of the protocol stack. Most models only consider the physical layer issues such as SIR or the network layer issues such as packet delay. They either address call level issues or packet level issues on the network. The fourth contribution has been to incorporate the issues of the transport layer into the admission control algorithm. A complete teletraffic analysis of our network with the effects of the transport layer protocol, the Transmission Control Protocol (TCP), is performed. This is done over a wireless channel. The wireless link and the protocol are mathematically modeled, there-after, the protocols effect on network performance is thoroughly presented...|$|R

