0|10000|Public
30|$|We {{have been}} {{conducting}} research on different pastoral systems in the Chad Basin for the last 20 years (Moritz 2008; Moritz et al. 2013 a; Moritz et al. 2010; Scholte et al. 2006), <b>and</b> <b>our</b> <b>discussion</b> <b>here</b> draws from <b>our</b> involvement in pastoral development in the far north region in different capacities. Two of the authors worked for the Waza Logone Project in the 1990 s (PS, SK), two others are currently members of Centre d'Appui à la Recherche et au Pastoralisme (CARPA) (SK, AM), one studied the process of delimiting the transhumance corridor as an intern at CARPA (BLC), and two others have studied different pastoral systems in the Far North Province, including pastoral development (MM, AD).|$|R
40|$|Which smooth compact 4 -manifolds admit an Einstein metric with non-negative Einstein constant? A {{complete}} {{answer is}} provided in the special case of 4 -manifolds that also happen to admit either a complex structure or a symplectic structure. A Riemannian manifold (M, g) {{is said to be}} Einstein if it has constant Ricci curvature, {{in the sense that the}} function v ↦ → r(v, v) on the unit tangent bundle {v ∈ T M | ‖v‖g = 1 } is constant, where r denotes the Ricci tensor of g. This is of course equivalent to demanding that g satisfy the Einstein equation r = λg for some real number λ. A fundamental open problem in global Riemannian geometry is to determine precisely which smooth compact n-manifolds admit Einstein metrics. For further background on this problem, see [4]. When n = 4, the problem is deeply intertwined with geometric and topological phenomena unique to this dimension; <b>and</b> <b>our</b> <b>discussion</b> <b>here</b> will therefore solely focus on this idiosyncratic case. But this article will focus on even narrower versions of the problem. Let us thus first consider the special class of smooth 4 -manifolds that arise from compact complex surfaces by forgetting the complex structure. Which of these admit Einstein metrics? If we are willing to also constrain the Einstein constant λ to be non-negative, the following complete answer can now be given...|$|R
40|$|Dedicated to Akira Fujiki, on the {{occasion}} of his 60 th birthday. A Riemannian manifold (M, g) is said to be Einstein if it has constant Ricci curvature, {{in the sense that the}} function v ↦ → r(v, v) on the unit tangent bundle {v ∈ T M | ‖v‖g = 1 } is constant, where r denotes the Ricci tensor of g. This is of course equivalent to demanding that g satisfy the Einstein equation r = λg for some real number λ. A fundamental open problem in global Riemannian geometry is to determine precisely which smooth compact n-manifolds admit Einstein metrics. For further background on this problem, see [4]. The n = 4 case is deeply intertwined with many geometric and topological phenomena that are unique to dimension four, <b>and</b> <b>our</b> <b>discussion</b> <b>here</b> will be entirely limited to this rather idiosyncratic case. But the results I will derive here in fact concern much narrower versions of the problem. For example, consider the special class of smooth 4 -manifolds that arise from compact complex surfaces by forgetting their complex structures. Which of these admit Einstein metrics? If we are willing to also constrain the Einstein constant λ to be non-negative, a complete answer can now be given, as described below. One key ingredient is the following recent result [7]: Theorem 1 (Chen-LeBrun-Weber) Let (M 4, J) be any compact complex surface with c 1 > 0. Then there is a λ> 0 Einstein metric on M which is conformally equivalent to a Kähler metric on (M, J) ...|$|R
40|$|This paper {{describes}} a proposed high resolution soft X-ray and Extreme Ultraviolet (EUV) spectroscopy mission {{to carry out}} a survey of Stellar and Galactic Environments (SAGE). The payload is based on novel diffraction grating technology which has already been proven in a sub-orbital space mission and which is ready to fly on a satellite platform with minimal development. Much of the technical detail of the instrumentation has been reported elsewhere <b>and</b> we concentrate <b>our</b> <b>discussion</b> <b>here</b> on the scientific goals of a SAGE base-line mission, demonstrating the scientific importance of high resolution spectroscopy in the Extreme Ultraviolet for the study of stars and the local interstellar medium...|$|R
40|$|We used cold target recoil ion {{momentum}} spectroscopy (COLTRIMS) {{to investigate}} the decay of Ne 2 after K-shell photoionization. The breakup into Ne 1 +/Ne 2 + shows interatomic Coulombic decay (ICD) occurring after a preceding atomic Auger decay. The molecular frame angular distributions of the photoelectron and the ICD electron show distinct, asymmetric features, which imply localization of the K-vacancy created {{at one of the}} two atomic sites of the Ne 2 and an emission of the ICD electron from a localized site. The experimental results are supported by calculations in the frozen core Hartree–Fock approach. (Some figures in this article are in colour only in the electronic version) Are inner-shell holes in homonuclear diatomic molecules localized at one of the atoms or delocalized over the two equivalent sites? This highly controversial question has been discussed in the literature for more than 35 years now (see, e. g. [1 – 11] <b>and</b> <b>our</b> <b>discussion</b> below). <b>Here</b> we report on an experiment answering that question for the Ne 2 van der Waal...|$|R
40|$|Team Fortress 2 (hereafter TF 2) was {{released}} by Valve as part of The Orange Box compilation in October 2007 for PC, Xbox 360 and later, Playstation 3. Arguably the third release of this multiplayer, team-based FPS following the Quake (id Software 1996) modification Team Fortress (1996) and Valve&# 039;s own Half-Life Naive 1998) mod Team Fortress Classic (1999). As such, many of the series&# 039; defining gameplay elements were already in place, including the character classes and team-oriented play dynamic (PlanetFortress n. d.). During its lengthy nine-year development, the designers of TF 2 were {{able to focus on}} refining these core mechanics whilst experimenting with suitable visual styles in an attempt to serve two, self-identified aims- in terms of branding, to differentiate TF 2 from other multiplayer FPS games (Wicklund 2007) and, in terms of gameplay, to focus the players&# 039; attention towards achieving the goals of the game during the intensity of play (Diaz 2007). It is the latter which concerns us here. The scope of this chapter is to focus on the visual information presented on-screen to the player during play. This is not to suggest the overall aesthetic appeal of TF 2 is one based solely on a reading of the screen, rather it is how TF 2 makes explicit use of the affordance of the screen that forms the basis of <b>and</b> delimits <b>our</b> <b>discussion</b> <b>here...</b>|$|R
40|$|The factor Xa {{inhibitor}} apixaban {{is one of}} {{the novel}} anticoagulants to emerge as alternatives to long-standing standards of care that include low-molecular-weight heparin and warfarin. The development of apixaban reflects a strategy to optimize the clinical pharmacology profile, dosing posology, trial designs, and statistical analyses across multiple indications, and to seek alignment with global health authorities. The primary objective of dose selection was to maintain balance between efficacy and bleeding risk. Twice-daily dosing of apixaban, rather than once daily, was chosen to lower peak concentrations and reduce fluctuations between peak <b>and</b> trough levels. <b>Our</b> <b>discussion</b> <b>here</b> focuses on the use of apixaban for stroke prevention in nonvalvular atrial fibrillation (NVAF). Supporting this indication, a pair of registrational trials was conducted that enrolled the full spectrum of patients who, by guidelines, were eligible for anticoagulation. In the AVERROES study of patients who were unsuitable for warfarin therapy, apixaban was superior to aspirin in reducing the risk of stroke or systemic embolism (SSE), without a significant increase inmajor bleeding (MB). In theARISTOTLE (Apixaban forReduction InSTroke andOtherThromboemboLic Events inAtrial Fibrillation) study, apixabanwas superior towarfarin on the rates of SSE,MB, and all-causemortality. Overall, these studies have demonstrated a substantially favorable benefit–risk profile for apixaban over warfari...|$|R
30|$|SFL, in general, and {{systemic}} typology, in particular, have developed in interaction with many {{different approaches to}} language study. We limit <b>our</b> <b>discussion</b> <b>here</b> to connections with a few other functional approaches that interact with and/or influence typology research in systemic linguistics.|$|R
30|$|Other {{types of}} time {{consistency}} for stochastic processes {{may be defined}} in analogy to what is done in Section “Other types of time consistency” for the case of random variables. For brevity, we limit <b>our</b> <b>discussion</b> <b>here</b> to the update rules derived from dynamic LM-measures.|$|R
50|$|Given a ring R, the {{polynomial}} ring Rx is {{the set of}} all polynomials in x {{that have}} coefficients chosen from R. In the special case that R is also a field, then the polynomial ring Rx is a principal ideal domain and, more importantly to <b>our</b> <b>discussion</b> <b>here,</b> a Euclidean domain.|$|R
30|$|In {{the years}} since Laney’s paper was published, {{numerous}} people have proposed additions to this list and many refer to four or five V’s, adding in Value or Veracity [7]. However, we are skeptical that these additions add to an overall understanding of big data, so we focus <b>our</b> <b>discussion</b> <b>here</b> to the original three.|$|R
30|$|Robust {{representations}} {{have been}} studied for general dynamic LM-measures, not only for dynamic monetary utility measures. However, {{in this paper we}} only use robust representations for dynamic monetary utility measures for random variables, and that is why <b>our</b> <b>discussion</b> <b>here</b> is limited to this case. Consequently, we take X=L^p for a fixed p∈ 0, 1,∞.|$|R
6000|$|... "Your father's note {{suggests}} to me," [...] replied Nugent, [...] "that he {{is a little}} hurt at the short notice I gave him of <b>our</b> <b>discussion</b> <b>here.</b> I thought--if you and Madame Pratolungo went on first--that you might make our peace with the rector, and assure him that we meant no disrespect, before Oscar and I appeared. Don't you think yourself you {{would make it easier}} for us, if you did that?" ...|$|R
40|$|Three-dimensional {{integration}} is an emerging fabrication technology that vertically stacks multiple integrated chips. The benefits include {{an increase in}} device density; much greater flexibility in routing signals, power, and clock; the ability to integrate disparate technologies; {{and the potential for}} new 3 D circuit and microarchitecture organizations. This article provides a technical introduction to the technology and its impact on processor design. Although <b>our</b> <b>discussions</b> <b>here</b> primarily focus on highperformance processor design, most of the observations and conclusions apply to other microprocessor market segments...|$|R
40|$|This book {{describes}} and {{illustrates the}} application of several asymptotic methods that have proved useful in the authors' research in electromagnetics and antennas. We first define asymptotic approximations and expansions and explain these concepts in detail. We then develop certain prerequisites from complex analysis such as power series, multivalued functions (including the concepts of branch points and branch cuts), and the all-important gamma function. Of particular importance {{is the idea of}} analytic continuation (of functions of a single complex variable); <b>our</b> <b>discussions</b> <b>here</b> include so...|$|R
40|$|We {{describe}} updated {{calculations of}} Q Q̅ production in pp and π^- p interactions. We compare these results to {{total cross section}} data and discuss how the baseline cross sections extrapolate to heavy ion collider energies. We touch upon the differences between leading and next-to-leading order heavy quark production. Finally, we discuss the implications of our calculations for quarkonium production. <b>Our</b> <b>discussion</b> <b>here</b> focuses on bottom quarks. Comment: 10 pages, uses special included style file, 4 eps figures, for proceedings of the Budapest' 02 Workshop on Quark and Hadron Dynamic...|$|R
30|$|Additionally, we can {{decouple}} scheduling decisions {{among different}} users based on many-user assumptions <b>and</b> <b>our</b> <b>discussion</b> in Section 1 [10, 11, 15].|$|R
30|$|The rest of {{this paper}} is {{organized}} as follows. In Section 2, we present our proposed refrigerator image classification approach. Section 3 contains experimental results <b>and</b> <b>our</b> <b>discussions.</b> In Section 4, we present the conclusion.|$|R
30|$|Typically, F 0 {{along with}} its delta and delta-delta {{derivatives}} form three streamsa of a context-dependent[34, 35]multi-space probability distribution (MSD)[36]left-to-right without skip transitions HSMM[58, 37] (which for obvious reasons, we shorten to simply ‘HMM’ in this paper). This model structure generates acoustic trajectories of a unit (e.g., phoneme) by emitting observations from hidden states. The output distribution {{of the state is}} a context-dependent multi-space Gaussian distribution [36], and these are clustered into groups of related contexts using a decision tree {{in order to reduce the}} number of free parameters and allow the modeling of unseen contexts. For notational simplicity, we limit <b>our</b> <b>discussion</b> <b>here</b> to an HMM with just one stream. Generalizing this to the multi-stream case is straightforward.|$|R
30|$|It {{should be}} noted, however, that <b>our</b> <b>discussion</b> <b>here</b> applies to {{recurrent}} excitation and inhibition. Tuned excitation and inhibition, when {{measured in terms}} of the total excitatory and inhibitory conductances in intracellular recordings, are the total excitatory and inhibitory input that a neuron observes. It is therefore possible that the tuning of the feedforward input is dominant in the tuning. Likewise, feedforward inhibition, mediated by disynaptic inhibition, can have the same tuning as the feedforward excitatory input, as the former is mediating it. The mechanisms discussed here, however, apply to recurrent excitation and inhibition, since they are a consequence of the dynamics of a network of synaptically connected neurons and, in particular, recruitment of feedback inhibition within the network.|$|R
40|$|We derive some asymptotics {{for a new}} {{approach}} to curve estimation proposed by Mr'{a}zek et al. cite{MWB 06 } which combines localization and regularization. This methodology has been considered as the basis of a unified framework covering various different smoothing methods in the analogous two-dimensional problem of image denoising. As a first step for understanding this approach theoretically, we restrict <b>our</b> <b>discussion</b> <b>here</b> to the least-squares distance where we have explicit formulas for the function estimates and where we can derive a rather complete asymptotic theory from known results for the Priestley-Chao curve estimate. In this paper, we consider only the case where the bias dominates the mean-square error. Other situations are dealt with in subsequent papers...|$|R
40|$|Abstract. In this paper, we {{consider}} the effect of dispersal on the permanence of single and interacting populations modelled by systems of integro differential equations. Different from former studies, <b>our</b> <b>discussion</b> <b>here</b> includes the important situation when species live in a weak patchy environment; i. e., species in some isolated patches will become extinct without the contribution from other patches. For the single population model considered in this paper, we show that the same species can persist for some dispersal rates and the species will vanish in some isolated patches. Based on the results for a single population model, we derive sufficient conditions for the permanence of two interacting competitive and predator-prey dispersing systems. 1...|$|R
30|$|Findings on {{the impact}} of PPPs on {{education}} quality indicates that the implementation of PPPs in Tanzania higher education has {{had an impact on the}} quality of education provided by the private sub sector. Scholars agree at some point that the quality dimension of education is better seen when the education system is viewed as a complex manufacturing industry with inputs, process and outputs (Scheerens 2011). Based on this conception of education, input and the quality of the process are what determine the quality of outputs or graduates. As we could not get data about the output indicator of quality because of our research design, <b>our</b> <b>discussion</b> <b>here</b> focuses on inputs (number and qualifications of academic staff) and partly on the process indicator (teaching and learning).|$|R
30|$|In this section, we {{investigate}} the convergence {{properties of the}} SO-DCTS algorithm in undirected networks when there is both deterministic and random (Gaussian) delay between network nodes during local time information exchange. In [19], we motivate why the Gaussian assumption is appropriate to model the undeterministic timing differences between nodes exchanging either MAC layer or physical layer timing information. We do not reiterate those arguments here but rather present convergence results for the SO-DCTS algorithm when such timing differences exist. We have separately examined {{the performance of the}} SO-DCTS algorithm considering alternate delay distributions, for example, exponential delay distribution [20]. Results show similar performance bounds as those presented in this paper for the Gaussian assumption. For this reason, we constrain <b>our</b> <b>discussion</b> <b>here</b> to the more common Gaussian delay model.|$|R
30|$|In {{existing}} research, {{there is}} also attention given {{to the use of}} film and video documentaries as sources of data (e.g. Chattoo & Das, 2014; Warmington, van Gorp & Grosvenor, 2011), however, <b>our</b> <b>discussion</b> <b>here</b> focuses on using media to capture information and communicate resulting narratives for research purposes. In our work, we promote a perspective on emergent storytelling that develops from data collection and analysis, allowing the research to drive the narrative, and situating it in the context from where data was collected. We rely on theories and practices of research and storytelling that leverage the affordances of participant observation and interview for the construction of narratives (Bailey & Tilley, 2002; de Carteret, 2008; de Jager, Fogarty & Tewson, 2017; Gallagher, 2011; Hancox, 2017; LeBaron, Jarzabkowski, Pratt & Fetzer, 2017; Lewis, 2011; Meadows, 2003).|$|R
40|$|We report {{surprising}} surface-induced torsional {{alignment of}} polydimethylsiloxane (PDMS) chains {{in contact with}} the muscovite (001) mica surface with and without confinement. The alignment was measured by polarized confocal Raman spectroscopy over diffraction-limit circular spots with ∼ 0. 3 μm diameter. <b>Our</b> <b>discussion</b> <b>here</b> focuses on the intense symmetric methyl-group vibration centered at 2907 cm- 1, whose Raman scattering intensity is found to depend on whether incident light is polarized in the x or y direction of the surface, the x direction being parallel to one of the mica optical axes. Furthermore, the Raman peak broadens significantly relative to that of bulk PDMS while remaining Lorentzian in shape, implying slower but homogeneous vibrational dephasing. However, the preferred orientation differs, apparently stochastically, from spot to spot on the surface. Possible origins of this heterogeneous surface-induced structure are discussed. close 6...|$|R
40|$|On the Mars Exploration Rovers, Mossbauer {{spectroscopy}} {{has recently}} been called upon {{to assist in the}} task of mineral identification, a job for which it is rarely used in terrestrial studies. For example, Mossbauer data were used to support the presence of olivine in Martian soil at Gusev and jarosite in the outcrop at Meridiani. The strength (and uniqueness) of these interpretations lies in the assumption that peak positions can be determined with high degrees of both accuracy and precision. We summarize here what we believe to be the major sources of error associated with peak positions in remotely-acquired spectra, and speculate on their magnitudes. <b>Our</b> <b>discussion</b> <b>here</b> is largely qualitative because necessary background information on MER calibration sources, geometries, etc., have not yet been released to the PDS; we anticipate that a more quantitative discussion can be presented by March 2005...|$|R
60|$|They {{were true}} Celts, swift to {{laughter}} and quick with tears; they {{inspired me to}} bolder flights. They met me on every plane of my intellectual interests, <b>and</b> <b>our</b> <b>discussions</b> of Herbert Spencer, Henry George, and William Dean Howells often lasted deep into the night. In all matters concerning the American Drama we were in accord.|$|R
40|$|Iatrogenic factors {{refer to}} anyinadequate medical {{treatment}} or diagnostic proceduresconducted inadvertently by practitioners who precipitate adverse injuries or symptoms. The unavoidable {{consequences of these}} factors should be corrected promptly, as they may result in erroneous treatment or new injury either on the tooth or the periodontium or both. Periodontal disease has a multifactorial etiology, which results from the interaction of local and systemic factors, intrinsically or extrinsically. Therefore, in most cases of periodontal disease, aninterdisciplinary approach is needed, such as restorative treatment of interproximal cavities that may induced food impacted. In contrary, a periodontal therapy could also act as an iatrogenic factor {{in the case of}} dentinal hypersensitivity or gingival recessionthat frequently creates an adverse effect in esthetic. <b>Our</b> <b>discussion</b> <b>here</b> is presented so that dentists could treat carefully and give {{a lot of attention to}} potential danger of other consequences of iatrogenic factors...|$|R
30|$|The {{paper is}} {{organized}} as follows: conceptual framework and hypotheses; {{data collection and}} experimental design; estimation methods; results; <b>and</b> finally <b>our</b> <b>discussion</b> <b>and</b> conclusions.|$|R
30|$|The {{reason why}} the offset between the {{position}} of the bead in the two channels does not fall below the expected sum of the FRE and the particles’ localization precision for all of the points is quite complex to address. We will focus <b>our</b> <b>discussion</b> <b>here</b> {{to the fact that the}} relative drift in between the imaging channels may play a role by increasing the residual offset. Additional file 1 : Figure S 3 displays the x-y drift of a fiducial marker in an actual dual color measurement: the fiducial drift follows a slightly different path when measured in each channel, and the relative drift, that should be constant, fluctuates approximately 10 nm (as shown in lower inset in Additional file 1 : Figure S 3). It was demonstrated that this relative drift can corrected using an active stabilization of the imaging path, but only in a proof-of-principle single molecule experiment (Pertsinidis et al. 2010).|$|R
40|$|Despite the {{diversity}} of microbes associated with decayed hearts of living trees (71, 89), the degradation of the cell wall components is still ascribable to Hymenomycetes. <b>Our</b> <b>discussion</b> <b>here</b> is limited to them, although we by no means want to discount their probable interactions with other microbes that might play key roles in the decay process (89). Of the several thousand wood decaying fungi, only a small number-a few hundred-can cause decay {{in the hearts of}} living trees (95). The term heartrot is used to include the overall process that culminates in degradation of the wood in the hearts of living trees; decay per se may be only a part of the total process. The interior, primarily nonliving portion of a tree is referred to here as the heart. The term heartwood has been avoided. A great deal is known about the mechanisms by which fungi degrade the principal components of wood. Recent advances have been stimulated primarily by a desire to exploit cellulases an...|$|R
40|$|Error {{measures}} {{can be used}} to numerically assess the differences between two images. Much work has been done on binary error measures, but little on objective metrics for grey-scale images. In <b>our</b> <b>discussion</b> <b>here</b> we introduce a new grey-scale measure, Δ g, aiming to improve upon the most common grey-scale error measure, the root-mean-square error. Our new measure is an extension of the authors' recently developed binary error measure, Δ b, not only in structure, but also having both a theoretical and intuitive basis. We consider the similarities between Δ b and Δ g when tested in practice on binary images, and present results comparing Δ g to the root-mean-squared error and the Sobolev norm for various binary and grey-scale images. There are no previous examples where the last of these measures, the Sobolev norm, has been implemented for this purpose. 1 Introduction There are three main methods for comparing images: human perception, which is a subjective me [...] ...|$|R
40|$|We extend Madland's {{parameterization}} of {{the energy}} release in fission to obtain the dependence of the fission Q value for major and minor actinides on the incident neutron energies in the range 0 {le} E{sub n} {le} 20 MeV. Our parameterization {{is based on the}} actinide evaluations recommended for the ENDF/B-VII. 1 release. This paper describes the calculation of energydependent fission Q values based on the calculation of the prompt energy release in fission by Madland. This calculation was adopted for use in the LLNL ENDL database and then generalized to obtain the prompt fission energy release for all actinides. Here the calculation is further generalized to the total energy release in fission. There are several stages in a fission event, depending on the time scale. Neutrons and gammas may be emitted {{at any time during the}} fission event. While <b>our</b> <b>discussion</b> <b>here</b> is focussed on compound nucleus creation by an incident neutron, similar parameterizations could be obtained for incident gammas or spontaneous fission...|$|R
40|$|A {{boundary}} element method (BEM) {{combined with}} a linear slip boundary condition is proposed to calculate SH wave scattering from fractures. The linear slip boundary condition was proposed by Schoenberg (1980) to model elastic wave propagation through an imperfectly bonded interface, where the traction cross the interface is continuous and displacement is discontinuous. Here, we demonstrate how to simulate SH wave scattering from fractures by applying the BEM and this linear slip boundary. Comparisons between results obtained using our model with those obtained using a computationally expensive finite difference method (FDM) (Coates and Schoenberg, 1995; Kruger et al., 2005) are performed to show the validity <b>and</b> accuracy of <b>our</b> approach. An example of SH wave scattering from three curved, crossing fractures is also given. Although <b>our</b> <b>discussion</b> <b>here</b> {{is focused on the}} linear slip boundary condition, our approach can easily be adopted to various slip boundary conditions that specify the displacement discontinuity and traction relations depending on different physical models of fractures. Eni-MIT Energy Initiative Founding Member Progra...|$|R
40|$|As per <b>our</b> <b>discussion</b> {{yesterday}} <b>here</b> is {{the results}} of the review by the technical staff at the Center for Nuclear Waste Regulatory Analyses (CNWRA). They were asked only to comment on issues within the U. S. Nuclear Regulatory Commission's regulatory framework. They commented on your issues 3 - 5 and 7 in the comments you provided to the Department of Energy. I would be happy to send you copies of any the NRC references cited in the CNWRA's response...|$|R
