2|96|Public
40|$|Buffer {{insertion}} is {{an increasingly}} critical optimization for achieving timing closure, {{and the number}} of buffers required increases significantly with technology migration. It is imperative for an automated buffer insertion algorithm to be able to efficiently optimize tens of thousands of nets. One must also be able to effectively navigate the existing layout, including handling large blockages, blockages with holes specifically for buffers, specially allocated buffer blocks, placement porosity, and routing congestion. The algorithm must also be flexible enough to know when to use and when not to use expensive layout resources. Although several previous works have <b>addressed</b> <b>buffer</b> insertion in the presence of blockages, this is the first to present a complete solution that can manage the physical layout environment...|$|E
40|$|Statement of the Problem Rapid {{population}} {{and economic growth}} combined with depleting groundwater reserves are resulting in ever increasing demands on surface water resources in Texas, as well as elsewhere. The climate {{of the state is}} characterized by extremes of floods and droughts. Reservoirs are necessary to control and utilize the highly variable streamflow. Due to a number of economic, environmental, institutional, and political considerations, construction of new reservoir projects is much more difficult now than in the past. Consequently, optimizing the beneficial use of existing reservoirs is becoming increasingly more important. Reservoir operation is based on the conflicting objectives of maximizing the amount of water available for conservation purposes and maximizing the amount of empty space available for storing future flood waters to reduce downstream damages. Common practice is to operate a reservoir for either flood control only, conservation only, or a combination of flood control and conservation with separate pools designated for each. The conservation and flood control pools, or vertical zones, in a multipurpose project are fixed by a designated top of conservation (bottom of flood control) pool elevation. Conservation pools may be shared by various purposes, such as water supply, hydroelectric power, and recreation, which involve both complementary and conflicting interactions. Public needs and objectives and numerous factors affecting reservoir operation change over time. An increasing necessity to use limited storage capacity as effectively as possible warrants periodic re-evaluations of operating policies. Reallocation of storage capacity between purposes represents a general strategy for optimizing the beneficial use of limited storage capacity in response to changing needs and conditions. A storage reallocation between flood control and conservation purposes typically involves a permanent or seasonal change in the designated top of conservation pool elevation. Reallocations between conservation purposes can be achieved by various modifications of operating policies. Although given relatively little consideration in the past, storage reallocations will likely be proposed more frequently as demands on limited resources increase. Scope of Study This report documents an investigation of: (1) the potential of storage capacity reallocation and other related modifications in operating policies as management strategies for optimizing the beneficial use of existing reservoirs in Texas and (2) modeling capabilities for formulating and evaluating such changes to operating policies. In general, storage reallocations can involve a variety of types of reservoir use. The present study focused primarily on flood control and water supply. Multiple purpose reservoir operations involving hydroelectric power were also investigated. Both permanent conversion of storage capacity between purposes and seasonal rule curve operations were <b>addressed.</b> <b>Buffer</b> pool operations were also considered. Multiple reservoir system operation was a major emphasis of the study. The literature was reviewed and several reservoir management agencies contacted to (1) identify experiences in studying and/or implementing storage reallocations and (2) evaluate the state-of-the-art of associated modeling and analysis capabilities. The feasibility of seasonal rule curve operation depends upon the seasonal characteristics of the various factors affecting reservoir operation. Precipitation, streamflow, reservoir evaporation, water demands, and reservoir storage content data for Texas were analyzed to identify seasonal characteristics. A 12 -reservoir system operated by the U. S. Army Corps of Engineers and Brazos River Authority provided a case study for evaluating the potential for storage reallocations and related operating strategies. This system, located in the Brazos River Basin, is considered representative of major reservoirs in Texas. The existing operating policies and possible modifications were investigated. The case study includes (1) flood control storage frequency and conservation drawdown frequency analyses {{based on the results of}} monthly hydrologic period-of-record simulations of reservoir system operations and (2) firm yield and reliability analyses. The generalized computer programs HEC- 3, HEC- 5, STATS, and MOSS-IV, and several utility software packages were used in the modeling study. Simulation of reservoir system operations was based on an 85 -year sequence of monthly hydrologic data. The case study provides a preliminary assessment of the viability of permanent storage conversions and/or adoption of seasonal rule curve operations as potential reservoir management strategies. The objective is to evaluate storage reallocation potentialities in general, not develop detailed reallocation plans. The case study is basically a reconnaissance-level hydrologic analysis of reservoir operations. The monthly period-of-record simulations provide a reasonably precise analysis of water supply considerations. However, the daily hydrologic data required for detailed analysis of flood control operations were not included in the study. Reallocation of reservoir storage capacity involves complex institutional, financial, economic, legal, political, and technical considerations not addressed in the case study. However, the hydrologic analyses provide a good starting point for determining what types of reallocation strategies and modeling approaches might be potentially effective and whether more detailed studies are worthwhile. Organization of the Report Chapter 2 is a general discussion of reservoir operation and institutional and technical aspects of storage reallocation and a review of reallocations which have been implemented or proposed throughout the nation. Chapter 3 addresses the seasonality of the hydrologic factors pertinent to seasonal rule curve operation in Texas. Chapter 4 reviews state-of-the-art modeling capabilities and describes the computer models adopted for use in the case study. The Brazos River Basin case study is presented in chapters 5 through 8. Study results are summarized, and conclusions are presented in chapter 9...|$|E
25|$|Performance of <b>Address</b> Translation <b>Buffers</b> {{has been}} enhanced.|$|R
5000|$|... 3270 {{displays}} and printers had a buffer containing one byte for every screen position. For example, a 3277 model 2 featured a screen size of 24 rows of 80 columns for a buffer size of 1920 bytes. Bytes were addressed {{from zero to}} the screen size minus one, in this example 1919. [...] "There is a fixed relationship between each ... buffer storage location and its position on the display screen." [...] Most orders started operation at the [...] "current" [...] <b>buffer</b> <b>address,</b> and executing an order or writing data would update this <b>address.</b> The <b>buffer</b> <b>address</b> could be set directly using the Set <b>Buffer</b> <b>Address</b> (SBA) order, often followed by Start Field. For a device with a 1920 character display a twelve bit address was sufficient. Later 3270s with larger screen sizes used fourteen or sixteen bits.|$|R
50|$|The 200-series IO {{instructions}} were a Peripheral Data Transfer (PDT) and a Peripheral Control and Branch (PCB) that explicitly implemented asynchronous IO. The PDT specified a device <b>address,</b> a <b>buffer</b> <b>address</b> and the transfer operation to be started, while the PCB specified a device address, {{and set the}} operating mode or tested {{the status of the}} device. Both used the format Op-code Address I/O unit address Variant.|$|R
40|$|The 90 degree {{rotation}} {{is important}} for the geometrical transformation of the video image. This paper describes a functional memory for the 90 degree rotation of video image. The functional memory consists of a memory cell array, data registers, data selectors, address decoders and a <b>address</b> <b>buffer.</b> Their components are designed by use of MOS FET. Especially, the memory cell is designed in a DRAM structure. The chip area of the memory cell is about two times compared to the one of a conventional DRAM cell...|$|R
5000|$|... : The <b>buffer</b> <b>address</b> is {{verified}} to be readable by {{the user}} mode caller.|$|R
5000|$|P1 is the <b>address</b> of the <b>buffer</b> {{into which}} the input {{characters}} are received ...|$|R
5000|$|Specialized {{instructions}} for modulo <b>addressing</b> in ring <b>buffers</b> and bit-reversed <b>addressing</b> mode for FFT cross-referencing ...|$|R
40|$|We usually measure cell {{delays in}} ATM {{switches}} by using time stamps. Alternatively, we here propose a delay estimation method by monitoring the <b>address</b> <b>buffers</b> {{of a shared}} buffer type ATM switch. We derive a relation between the address queue length distribution and cell delay distribution and verify this relation by simulation. For a multiple stage switch, we can estimate end-to-end delay characteristics by the successive convolutions of the delay distribution of each stage. We investigate cell delay distributions of multiplexed streams {{as well as a}} specific virtual connection (VC) stream. We derive the upper bound of cell delay distribution of each connection. Finally, we study the effect of burstiness on delay, and show that the burstiest traffic yields the worst delay performance under the given traffic parameters when the background traffic load is low. 1...|$|R
5000|$|... "CAS before RAS refresh" [...] (CBR) - In {{this mode}} the on-chip counter {{keeps track of}} the row to be {{refreshed}} and the external circuit merely initiates the refresh cycles. [...] This mode uses less power because the memory <b>address</b> bus <b>buffers</b> don't have to be powered up. It is used in most modern computers.|$|R
40|$|The NSC 800 is an 8 -bit CMOS {{microprocessor}} {{manufactured by}} National Semiconductor Corp., Santa Clara, California. The 8 -bit microprocessor chip with 40 -pad pin-terminals has eight <b>address</b> <b>buffers</b> (A 8 -A 15), eight data <b>address</b> [...] I/O <b>buffers</b> (AD(sub 0) -AD(sub 7)), six interrupt controls and sixteen timing controls with a chip clock generator and an 8 -bit dynamic RAM refresh circuit. The 22 internal registers {{have the capability}} of addressing 64 K bytes of memory and 256 I/O devices. The chip is fabricated on N-type (100) silicon using self-aligned polysilicon gates and local oxidation process technology. The chip interconnect consists of four levels: Aluminum, Polysi 2, Polysi 1, and P(+) and N(+) diffusions. The four levels, except for contact interface, are isolated by interlevel oxide. The chip is packaged in a 40 -pin dual-in-line (DIP), side brazed, hermetically sealed, ceramic package with a metal lid. The operating voltage for the device is 5 V. It is available in three operating temperature ranges: 0 to + 70 C, - 40 to + 85 C, and - 55 to + 125 C. Two devices were submitted for product evaluation by F. Stott, MTS, JPL Microprocessor Specialist. The devices were pencil-marked and photographed for identification...|$|R
40|$|This paper {{presents}} a technique for eliminating redundant cache-tag and cache-way accesses to reduce power consumption. The basic {{idea is to}} keep {{a small number of}} Most Recently Used (MRU) addresses in a Memory <b>Address</b> <b>Buffer</b> (MAB) and to omit redundant tag and way accesses when there is a MAB-hit. Since the approach keeps only tag and set-index values in the MAB, the energy and area overheads are relatively small even for a MAB with a large number of entries. Furthermore, the approach does not sacrifice the performance. In other words, neither the cycle time nor the number of executed cycles increases. The proposed technique has been applied to Fujitsu VLIW processor (FR-V) and its power saving has been estimated using NanoSim. Experiments for 32 kB 2 -way set associative caches show the power consumption of I-cache and D-cache can be reduced by 40 % and 50 %, respectively. ...|$|R
40|$|A {{taxonomy}} {{that uses}} 22 attributes to characterize Cprogram overflows {{was used to}} construct 291 small Cprogram test cases {{that can be used}} to diagnostically determine the basic capabilities of static and dynamic analysis buffer overflow detection tools. Attributes in the taxonomy include the buffer location (e. g. stack, heap, data region, BSS, shared memory) ; scope difference between buffer allocation and access ; index, pointer, and alias complexity when <b>addressing</b> <b>buffer</b> elements; complexity of the control flow and loop structure surrounding the overflow ; type of container the buffer is within (e. g. structure, union, array) ; whether the overflow is caused by a signed/unsigned type error ; the overflow magnitude and direction ; and whether the overflow is discrete or continuous. As an example, the 291 test cases were used to measure the detection, false alarm, and confusion rates of five static analysis tools. They reveal specific strengths and limitations of tools and suggest directions for improvements...|$|R
40|$|Abstract—The {{widespread}} {{availability of}} mobile wireless devices offers growing {{opportunities for the}} formation of temporary networks with only intermittent connectivity. These intermittently-connected networks (ICNs) typically lack stable end-to-end paths. In order to improve the delivery rates of the networks, new store-carry-and-forward protocols have been proposed which often use message replication as a forwarding mechanism. Message replication is effective at improving delivery, but given the limited resources of ICN nodes, such as buffer space, bandwidth and energy, as well as the highly dynamic nature of these networks, replication can easily overwhelm node resources. In this work we propose a novel node-based replication management algorithm which <b>addresses</b> <b>buffer</b> congestion by dynamically limiting the replication a node performs during each encounter. The insight for our algorithm comes from a stochastic model of message delivery in ICNs with constrained buffer space. We show through simulation that our algorithm is effective, nearly tripling delivery rates in some scenarios, and imposes no or little overhead. I...|$|R
40|$|The Human Factor {{has long}} been {{recognized}} as the weakest link in computer systems security, yet, nothing technically significant {{has been done to}} address this problem in an attack agnostic manner. In this paper, we introduce the mantra of “The User is the Enemy ” for security designers and developers alike as an underlying current towards addressing the weak human factor. We present different notions of the user and the system and argue from parallel tracks that user actions, both ignorant and non-compliant, are detrimental to the organization. We further show how the paradigm has been applied in a rather unconscious manner and contend that security mechanisms borne out of a conscious application will be more effective towards addressing this systemic problem. Our position is not meant to be a cynical attitude towards users; rather, it is meant to be the focal point of security design attitude, similar to the mantra “All user input is evil ” for <b>addressing</b> <b>buffer</b> overflow attacks...|$|R
40|$|Submitted {{on behalf}} of EDAA ([URL] audienceThis paper {{presents}} a technique for eliminating redundant cache-tag and cache-way accesses to reduce power consumption. The basic idea is to keep {{a small number of}} Most Recently Used (MRU) addresses in a Memory <b>Address</b> <b>Buffer</b> (MAB) and to omit redundant tag and way accesses when there is a MAB-hit. Since the approach keeps only tag and set-index values in the MAB, the energy and area overheads are relatively small even for a MAB with a large number of entries. Furthermore, the approach does not sacrifice the performance. In other words, neither the cycle time nor the number of executed cycles increases. The proposed technique has been applied to Fujitsu VLIW processor (FR-V) and its power saving has been estimated using NanoSim. Experiments for 32 kB 2 -way set associative caches show the power consumption of I-cache and D-cache can be reduced by 40 % and 50 %, respectively...|$|R
5000|$|I/O request packets (IRPs) are {{kernel mode}} {{structures}} {{that are used}} by Windows Driver Model (WDM) and Windows NT device drivers {{to communicate with each}} other and with the operating system. They are data structures that describe I/O requests, and can be equally well thought of as [...] "I/O request descriptors" [...] or similar. Rather than passing a large number of small arguments (such as <b>buffer</b> <b>address,</b> <b>buffer</b> size, I/O function type, etc.) to a driver, all of these parameters are passed via a single pointer to this persistent data structure. The IRP with all of its parameters can be put on a queue if the I/O request cannot be performed immediately. I/O completion is reported back to the I/O manager by passing its address to a routine for that purpose, IoCompleteRequest. The IRP may be repurposed as a special kernel APC object if such is required to report completion of the I/O to the requesting thread.|$|R
5000|$|The {{instrument}} used a waveform buffer, now a widespread practice, but independently conceived by Moore and Coupland. This was driven with high precision phase generator, of which only the high order bits <b>addressed</b> the <b>buffer.</b> A subtle logarithmic algorithm (log eighth root of two) was invented to apply audio level and ADSR amplitude modulation to the signal generated for each voice. This avoided {{the cost and}} heat dissipation of available commercial multiplier modules.|$|R
50|$|This {{programming}} paradigm maps well {{to vector}} processors: {{there is an}} assumption that each invocation of a kernel within a batch is independent, allowing for data parallel execution. However, atomic operations may sometimes be used for synchronisation between elements (for interdependent work), in some scenarios. Individual invocations are given indices (in 1 or more dimensions) from which arbitrary <b>addressing</b> of <b>buffer</b> data may be performed (including scatter gather operations), {{so long as the}} non-overlapping assumption is respected.|$|R
50|$|Peddle {{continued}} {{working for}} Motorola while looking for investors {{for his new}} microprocessor concept. In August 1974 Chuck Peddle left Motorola and joined a small semiconductor company in Pennsylvania, MOS Technology. He was followed by seven other Motorola engineers: Harry Bawcum, Ray Hirt, Terry Holdt, Mike James, Will Mathis, Bill Mensch and Rod Orgill. Peddle's group at MOS Technology developed two new microprocessors that were compatible with the Motorola peripheral chips like the 6820 PIA. Rod Orgill designed the MCS6501 processor that would plug into a MC6800 socket and Bill Mensch did the MCS6502 that had the clock generation circuit on chip. These microprocessors would not run 6800 programs {{because they had a}} different architecture and instruction set. The major goal was a microprocessor that would sell for under $25. This would be done by removing non-essential features to reduce the chip size. An 8-bit stack pointer was used instead of a 16-bit one. The second accumulator was omitted. The <b>address</b> <b>buffers</b> did not have a three-state mode for Direct Memory Access (DMA) data transfers. The goal was to get the chip size down to 153 mils x 168 mils (3.9 mm x 4.3 mm).|$|R
40|$|This work {{considers}} data memory {{alternatives for}} multiscalar processors that can support the aggressive control and data speculative execution of loads and stores. We discuss {{the key issues}} that {{must be dealt with}} for such a data memory design and partition the design space of alternatives on the basis of composition, i. e. whether the storage for speculative and architectural versions is separate or aggregate, and on the basis of organization, i. e. whether the storage for speculative and architectural versions is shared or private. Moreover, we attempt to address a broad spectrum of solutions by considering two schemes in terms of centralized and distributed designs: a known scheme, the <b>address</b> resolution <b>buffer</b> which provides distinct speculative and architectural storage; and a novel scheme, the time-sequence cache which merges the speculative and architectural storage. We have performed a preliminary experimental evaluation of designs from opposite ends of the spectrum of solutions. Our experimental evidence from a simulation of a multiscalar processor with a centralized <b>address</b> resolution <b>buffer</b> and a distributed time-sequence cache shows (i) that hit latency is an important performance factor (even for a latency tolerant processor like a multiscalar processor) and (ii) that distributed schemes may trade-off hit rate for hit latency to improve performance over centralized schemes...|$|R
40|$|In this paper, {{we focus}} on a class of buffer {{overflow}} vulnerabilities that occur due to the 2 ̆ 2 placement new 2 ̆ 72 ̆ 7 expression in C++. 2 ̆ 2 Placement new 2 ̆ 72 ̆ 7 facilitates placement of an object/array at a specific memory location. When appropriate bounds checking is not in place, object overflows may occur. Such overflows can lead to stack as well as heap/data/bss overflows, which can be exploited by attackers in order {{to carry out the}} entire range of attacks associated with buffer overflow. Unfortunately, buffer overflows due to 2 ̆ 2 placement new 2 ̆ 72 ̆ 7 have neither been studied in the literature nor been incorporated in any tool designed to detect and/or <b>address</b> <b>buffer</b> overflows. In this paper, we show how the 2 ̆ 2 placement new 2 ̆ 72 ̆ 7 expression in C++ can be used to carry out buffer overflow attacks - on the stack as well as heap/data/bss. We show that overflowing objects and arrays {{can also be used to}} carry out virtual table pointer subterfuge, as well as function and variable pointer subterfuge. Moreover, we show how 2 ̆ 2 placement new 2 ̆ 2 can be used to leak sensitive information, and how denial of service attacks can be carried out via memory leakage...|$|R
40|$|Time-shared {{interface}} speeds {{data processing}} in distributed computer network. Two-level high-speed scanning approach routes information to buffer, portion {{of which is}} reserved for series of "first-in, first-out" memory stacks. <b>Buffer</b> <b>address</b> structure and memory are protected from noise or failed components by error correcting code. System is applicable to any computer or processing language...|$|R
40|$|The {{proposed}} WIDAR correlator for the EVLA aims to use {{the method}} of `recirculation' to greatly increase the spectral resolution capabilities of the correlator at narrow bandwidths. This method involves buffering low sample rate data, and then bursting it at high data rates through the correlator with different relative station delays [...] -or <b>buffer</b> <b>address</b> offsets [...] -to effectively provide many more correlator lags for the hardware available. This memo investigates the basic recirculation architecture {{within the context of}} the proposed design, develops a <b>buffer</b> <b>address</b> offset algorithm, and discusses some fundamental limitations of the technique in terms of SNR degradation and integration time. Introduction In [1], the basic architecture of the proposed WIDAR correlator for the EVLA was presented. In that document so-called recirculation is used to provide very high spectral resolution when correlating narrow bandwidths. This capability was included in the design by request of NRAO at [...] ...|$|R
40|$|Abstract: Buffer {{overflow}} {{attacks are}} widely acknowledged by computer security professionals {{to be one}} of the greatest threats to the security of computer systems. We present an integrated softwarehardware approach to protect against buffer overflow attacks while minimizing performance degradation, software development time, and deployment costs. Our technique does not change the processor core, but instead adds a hardware module in the form of a Field Programmable Gate Array (FPGA) that sits between cache and memory and that is able to defend return <b>addresses</b> from <b>buffer</b> overflow attacks. Our solution exhibits neither the performance overhead of software solutions nor the CPU redesign costs of hardware solutions...|$|R
50|$|AddressSanitizer {{does not}} prevent any uninitialized memory reads, and only {{prevents}} some use-after-return bugs. It is also not capable of preventing all arbitrary memory corruption bugs. Arbitrary write bugs due to integer underflow/overflows (when the integer with undefined behavior {{is used to calculate}} memory <b>address</b> offsets). Adjacent <b>buffers</b> in structs and classes are not protected from overflow, in part to prevent breaking backwards compatibility.|$|R
40|$|Buffer {{overflow}} {{attack is}} the most common and arguably the most dangerous attack method used in Internet security breach incidents reported in the public literature. Various solutions have been developed to <b>address</b> the <b>buffer</b> overflow vulnerability problem in both research and commercial communities. Almost all the solutions that provide adequate protection against buffer overflow attacks are implemented as compiler extensions and hence require the source code of the programs being protected to be available {{so that they can be}} re-compiled. While this requirement is reasonable in many cases, there are scenarios in which it is not feasible, e. g., legacy applications that are purchased from an outside vendor. The work reported in this paper explore...|$|R
50|$|In MINIX 3, when a user expects data from, for example, {{the file}} system, it builds a {{descriptor}} telling who has access {{and at what}} addresses. It then passes an index to this descriptor to the file system, which may pass it to a driver. The file system or driver then asks the kernel to write via the descriptor, {{making it impossible for}} them to write to <b>addresses</b> outside the <b>buffer.</b>|$|R
40|$|The {{problem of}} {{database}} buffer management has extensively been studied {{for nearly three}} decades. In this paper, we explore the use of newly emerging data mining technology to tackle the traditional buffer management issue. In particular, we <b>address</b> the <b>buffer</b> size setting problem for distributed database systems. The main goal is to minimize physical I/O while achieving better buffer utilization at the same time. Different from the traditional buffer management strategies where limited knowledge of user access patterns is analyzed and used, our buffer allocation mechanism extracts knowledge from historical reference streams, and then determines the optimal buffer space based on the discovered knowledge. Simulation experiments show that the proposed method can achieve an optimal buffer allocation solution for distributed database systems...|$|R
5000|$|<b>Addressing</b> of <b>Buffer</b> should {{guarantee}} that the complete buffer is inside the given segment,i.e. ( [...] BX + size_of_buffer [...] ) <= 10000h.Otherwise the interrupt may fail with some BIOS or hardware versions.Example: Assume {{you want to read}} 16 sectors (= 2000h bytes) and your <b>buffer</b> startsat memory <b>address</b> 4FF00h. Utilizing memory segmentation, there are different ways to calculate the register values, e.g.: ES = segment = 4F00h BX = offset = 0F00h sum = memory address = 4FF00h would be a good choice because 0F00h + 2000h = 2F00h <= 10000h ES = segment = 4000h BX = offset = FF00h sum = memory address = 4FF00h would not be a good choice because FF00h + 2000h = 11F00h > 10000h ...|$|R
40|$|An FPGA {{design of}} 4 K UHDTV (Ultra-high {{definition}} TV) H. 264 video decoder is proposed in this paper. The decoder {{is a complete}} one starting from bit stream input to decoding and final displaying, {{all of which are}} implemented on FPGA. Decoder engine that saves 51 % DRAM bandwidth and dis-play frame <b>buffer</b> <b>addressing</b> scheme that increases DRAM efficiency by 45 % are proposed. The proposed work is ca-pable of decoding and displaying...|$|R
5000|$|The C {{programming}} language reifies the low-level detail of memory addresses.Many {{programming language}} designs encapsulate {{the details of}} memory allocation in the compiler and the run-time system. In {{the design of the}} C programming language, the memory address is reified and is available for direct manipulation by other language constructs. For example, the following code may be used when implementing a memory-mapped device driver. The buffer pointer is a proxy for the memory <b>address</b> 0xB800000. char* <b>buffer</b> = (char*) 0xB800000; buffer0 = 10; ...|$|R
40|$|Abstract-In this paper, a new ATM switch {{architecture}} is presented. Our proposed Mtdtinet switch is a self-routing multistage switch with partially shared internal buffers capable of achieving 100 % throughput under uniform traffic. Although it provides incoming ATM cells with multiple paths, the cell sequence is maintained throughout the switch fabric thus eliminating the out-of-order cell sequence problem. Cells contending {{for the same}} output <b>addresses</b> are <b>buffered</b> internally according to a partially shared queueing discipline. In a partially shared queueing scheme, buffers are partially shared to accommodate bursty traffic and to limit tbe performance degradation that may occur in a completely shared system where {{a small number of}} calls may hog the entire buffer space unfairly. Although the hardware complexity in terms of number of crosspoints {{is similar to that of}} input queueing switches, the Mtdtinet switch has throughpu...|$|R
30|$|We {{find that}} {{hardware}} instruction tracing simplifies the isolation enforcement as it records tracing data securely and efficiently. For example, Intel PT can be configured by the kernel driver {{to save the}} trace into a memory buffer which is inaccessible from the traced application. Thus the application is incapable of corrupting the trace. Additionally, the hardware facility <b>addresses</b> the memory <b>buffer</b> with physical memory address, which allows the trace to be written to the user-mode inaccessible memory buffer without a processor mode switching to the kernel mode.|$|R
5000|$|Classic Forth systems {{traditionally}} use neither {{operating system}} nor file system. Instead of storing code in files, source code {{is stored in}} disk blocks written to physical disk addresses. The word [...] is employed to translate the number of a 1K-sized block of disk space into the <b>address</b> of a <b>buffer</b> containing the data, which is managed automatically by the Forth system. Block use has become rare since the mid-1990s. In a hosted system those blocks too are allocated in a normal file in any case.|$|R
