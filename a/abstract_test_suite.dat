24|5271|Public
5000|$|MEF 25 [...] <b>Abstract</b> <b>Test</b> <b>Suite</b> for UNI Type 2 Part 3 Service OAM ...|$|E
5000|$|MEF 27 [...] <b>Abstract</b> <b>Test</b> <b>Suite</b> For UNI Type 2 Part 5: Enhanced UNI Attributes & Part 6: L2CP Handling ...|$|E
50|$|ISO 16845-1:2004 {{provides}} the methodology and <b>abstract</b> <b>test</b> <b>suite</b> necessary for checking the conformance of any CAN {{implementation of the}} CAN specified in ISO 11898-1.|$|E
40|$|Colloque avec actes et comité de lecture. internationale. International audienceIn this paper, {{we present}} an {{overview}} of "Modeling, Specifying and Testing IPv 6 Protocols" project. The aim of the project is to formalize IPv 6 protocols and to allow simulation and automatic generation of <b>test</b> <b>suites</b> for conformance and interoperability testing. Protocol behavior is specified with SDL and <b>test</b> <b>suites</b> are described with TTCN (Tree and Tabular Combined Notation). Our methodology for formalizing, verifying and generating <b>abstract</b> <b>test</b> <b>suites</b> is based on ObjectGeode from Telelogic. A selection of corresponding executable <b>test</b> <b>suites</b> are provided in C language and are ready to apply to an existing implementation. The set of protocols that have been specified includes "Internet Protocol version 6 ", "Neighbor Discovery for IPv 6 ", "Internet Control Message Protocol for IPv 6 ", "Multicast Listener Discovery for IPv 6 " and "RIPng for IPv 6 ". A brief overview of each protocol is given before the general approach used is presented. An example is given based on a small protocol MLD for which all steps have been applied and executable <b>test</b> <b>suite</b> have been coded in C language and executed in an active environment...|$|R
40|$|An {{important}} recent {{advance in}} the area of communications has been the development of standards for specifying <b>test</b> <b>suites</b> for Open System Interconnection (OSI) systems. In particular, the standardization and formalization of <b>test</b> <b>suites</b> has been achieved through the development of a formal specification language, Tree and Tabular Combined Notation (TTCN), and an associated data definition language, Abstract Syntax Notation One (ASN. 1). This development of formal language for specifying <b>test</b> <b>suites</b> has provided a new challenge for compiler developers. That is, the development of a compiler that can translate from the <b>abstract</b> descriptions for <b>test</b> <b>suites</b> to executable <b>testing</b> programs that can be executed {{on a wide variety of}} communication architectures. In response to these challenges, a compiler (TACK) has been developed by the author which translates from TTCN/ASN. 1 specifications to executable C++ <b>test</b> <b>suites.</b> Compared to other TTCN compilers, the TACK compiler makes two important contributions. The first contribution is that the TACK compiler supports both ASN. 1 and TTCN within the same framework. Due to the complexity of merging ASN. 1 with TTCN, the existing implementations of TTCN compilers have all simplified the ASN. 1 implementation. This restriction means that the other TTCN compilers cannot be used for upper-layer testing, whereas the TACK compiler can be used for both lower-layer and upper-layer testing. Secondly, the TACK compiler has been designed so that it can support compilation to a wide variety of testing environments. TTCN is a general-purpose test definition language and TTCN <b>test</b> <b>suites</b> are designed in an abstract way to carry out real tests on various test architectures. Thus, one can expect to generate executable test cases for different test architectures from the same <b>abstract</b> <b>test</b> <b>suites.</b> However, all existing TTCN compilers target the object code in a designated test environment in which a specific test architecture is required. Through <b>suites</b> and typical <b>test</b> architectures, a modularizing code-generator and associated run-time systems have been developed by the author for use with a wide variety of test architectures...|$|R
40|$|The International Standards Organization (ISO) {{has defined}} a {{protocol}} test language called TTCN (Tree and Tabular Combined Notation) to specify <b>abstract</b> <b>test</b> <b>suites</b> for Open Systems Interconnection (OSI) protocols. TTCN combines a tree notation for dynamic behaviour description with a tabular representation of various language constructs. TTCN allows tabular constraints to enforce values on the Abstract Service Primitive (ASP) or Protocol Data Unit (PDU) parameters. For application layer protocols, Abstract Syntax Notation One (ASN. 1) constraints are used. Dynamic behaviour description in TTCN {{is shown to}} address many important aspects of conformance testing such as modularity support in terms of test cases, steps and default behaviour tables and sophisticated timer management. TTCN has a machine processable form called TTCN-MP that defines all the TTCN syntax using BNF. Semantics of the tests specified in TTCN is operationally defined rendering TTCN almost a formal notation. © 1992...|$|R
5000|$|... #Caption: An {{example of}} a model-based testing {{workflow}} (offline test case generation). IXIT refers to implementation extra information and refers to information needed to convert an <b>abstract</b> <b>test</b> <b>suite</b> into an executable one. Typically, IXIT contains information on the test harness, data mappings and SUT configuration.|$|E
5000|$|A model {{describing}} a SUT is usually an abstract, partial {{presentation of the}} SUT's desired behavior.Test cases derived from such a model are functional tests {{on the same level}} of abstraction as the model.These test cases are collectively known as an abstract test suite.An <b>abstract</b> <b>test</b> <b>suite</b> cannot be directly executed against an SUT because the suite is on the wrong level of abstraction.An executable test suite needs to be derived from a corresponding abstract test suite.The executable test suite can communicate directly with the system under test.This is achieved by mapping the abstract test cases to concrete test cases suitable for execution. In some model-based testing environments, models contain enough information to generate executable test suites directly.In others, elements in the <b>abstract</b> <b>test</b> <b>suite</b> must be mapped to specific statements or method calls in the software to create a concrete test suite. This is called solving the [...] "mapping problem".In the case of online testing (see below), abstract test suites exist only conceptually but not as explicit artifacts.|$|E
50|$|Originally every APs was {{required}} to have a companion <b>Abstract</b> <b>test</b> <b>suite</b> (ATS) (e.g. ATS 303 for AP 203), providing Test Purposes, Verdict Criteria and Abstract Test Cases together with example STEP-Files. But because {{the development of an}} ATS was very expensive and inefficient this requirement was dropped and replaced by the requirements to have an informal validation report and recommended practises how to use it. Today the recommended practises are a primary source for those going to implement STEP.|$|E
40|$|The {{traditional}} GA {{theory is}} pillared on the Building Block Hypothesis (BBH) {{which states that}} Genetic Algorithms (GAs) work by discovering, emphasizing and recombining low order schemata in high-quality strings, in a strongly parallel manner. Historically, attempts to capture the topological fitness landscape features which exemplify this intuitively straight-forward process, have been mostly unsuccessful. Population-based recombinative methods had been <b>test</b> <b>suites,</b> by different variants of mutation-based algorithms. Departing from the BBH, {{in this paper we}} seek to exemplify the utility of crossover from a different point of view, emphasizing the creative potential of the crossover operator. We design a special class of <b>abstract</b> <b>test</b> <b>suites,</b> called Trident functions, which exploits the ability of modern GAs to mix good but significantly different solutions. This approach has been so far neglected as it is widely believed that disruption caused by mating individuals that are too dissimilar is harmful. We anticipate that hybridizing different designs induces a complex neighborhood structure unattainable by trajectory-based methods which can conceal novel solutions. Empirical results confirm that the proposed class of problems can be solved efficiently only by population-based panmictic recombinative methods, employing diversity maintaining mechanisms...|$|R
40|$|<b>Abstract.</b> Today, <b>test</b> <b>suites</b> {{of several}} ten {{thousand}} {{lines of code}} are specified using the Testing and Test Control Notation (TTCN- 3). Experience shows that the resulting <b>test</b> <b>suites</b> suffer from quality problems with respect to internal quality aspects like usability, maintainability, or reusability. Therefore, a quality assessment of TTCN- 3 <b>test</b> <b>suites</b> is desirable. A powerful approach to detect quality problems in source code is the identification of code smells. Code smells are patterns of inappropriate language usage that is error-prone or may lead to quality problems. This paper presents a quality assessment approach for TTCN- 3 <b>test</b> <b>suites</b> {{which is based on}} TTCN- 3 code smells: To this aim, various TTCN- 3 code smells have been identified and collected in a catalogue; the detection of instances of TTCN- 3 code smells in <b>test</b> <b>suites</b> has been automated by a tool. The applicability of this approach is demonstrated by providing results from the quality assessment of several standardised TTCN- 3 <b>test</b> <b>suites.</b> ...|$|R
40|$|<b>Abstract.</b> Running unit <b>tests</b> <b>suites</b> with {{contemporary}} {{tools such as}} JUNIT can show the presence of bugs, but not their locations. This is different from check-ing a program with a compiler, which always points the programmer to the most likely causes of the errors it detects. We {{argue that there is}} enough infor-mation in <b>test</b> <b>suites</b> and the programs under test to exclude many locations in the source as reasons for the failure of test cases, and further to rank the remain-ing locations according to derived evidence of their faultiness. We present a framework for the management of fault locators whose error diagnoses are based on data about a program and its test cases, especially as collected during test runs, and demonstrate that it is capable of performing reasonably well using a couple of simple fault locators in different evaluation scenarios...|$|R
50|$|In model-based testing, one {{distinguishes between}} {{abstract}} test suites, which are collections of abstract test cases {{derived from a}} high-level model of the system under test, and executable test suites, which are derived from abstract test suites by providing the concrete, lower-level details needed to execute this suite by a program. An <b>abstract</b> <b>test</b> <b>suite</b> cannot be directly used on the actual system under test (SUT) because abstract test cases remain at a high abstraction level and lack concrete details about the SUT and its environment. An executable test suite works on a sufficiently detailed level to correctly communicate with the SUT and a test harness is usually present to interface the executable test suite with the SUT.|$|E
40|$|World Res InstTesting {{to ensure}} service QoS {{is a key}} problem for Web Service {{adoption}} One of the key problems for software testing is designing the finite test suit tailored to test case generation efficiently This paper focuses on <b>Abstract</b> <b>Test</b> <b>Suite</b> and Executable Test Suite analysis of WSDL_based Web Service and proposes automated WSDL_based Web Service testing A XML_based test scripting language is discussed and Executable Test Suite {{can be derived from}} <b>Abstract</b> <b>Test</b> <b>Suite</b> automatically based on XML parser. Executable Test Suite consists of message Schema syntactic test group, Web Service interface test group, and interoperation test group A test process is used in WSDL_based Web Service testing The three key techniques adopted by the test process including the test case generation, test flow, and test data generation are analyzed...|$|E
40|$|The AGEDIS testing {{methodology}} {{is based on}} an iterative process with the following six key steps: 1. Build a behavioral model of the system under test (SUT). 2. Annotate the model with testing information: Describe coverage criteria, specific test purposes, and testing constraints. Describe the testing interface between the model and the SUT, including points of control and observation. 3. Generate, automatically, a test suite. 4. Review the model, test information, and test suite with developers and customers. 5. Execute the test suite automatically, and log the results. 6. Review the results and repeat steps 2 – 5 until the coverage and quality goals of the test are achieved. AGEDIS provides the following tools to assist with the implementation of this {{testing methodology}}: n n n n n Model Compiler – takes a model written in the AGEDIS Modeling Language (AML), and produces a standard intermediate format that the test suite generator can read. The modeling language includes both the behavioral model and the test generation directives. Test Suite Generator – reads the intermediate format and produces a test suite written in the <b>Abstract</b> <b>Test</b> <b>Suite</b> (ATS) format. Test Execution Engine – reads the <b>abstract</b> <b>test</b> <b>suite</b> and the test execution directives, runs the test suite against the application under test, and logs the test results. AML Profile – enables the Objecteering UML modeling tool to produce models in AML. <b>Abstract</b> <b>test</b> <b>suite</b> browser. The following tools are still under development: n n n An integrated platform to control and coordinate the entire AGEDIS tool set. A test log browser. Automated components for the analysis and feedback step of the methodology. The relationship between the tools and the data transfer formats is illustrated below...|$|E
40|$|In the B 2 B/B 2 C environment, many {{applications}} and documents requires {{to be tested}} for conformance and interoperability. However {{because there are a lot}} of standards, solutions, specific environments, and test needs, it is difficult to develop all testing tools (i. e., testbeds) to cope with these test diversity. The testbed should be developed more rapidly and easier. In addition, the implemented testbed should be accommodated for various testing specifics. Thus we have proposed the agile test framework (ATF), which consists of <b>test</b> <b>suite</b> design and its execution model. The <b>test</b> <b>suite</b> is designed with a double layer: <b>abstract</b> and executable <b>test</b> <b>suites.</b> The execution model is also invented considering as reusability and plug-and-play concepts. This approach makes test engineer rapidly generate <b>test</b> <b>suite</b> and rapidly implement testbed. It also enables the implemented testbed to test various applications and documents based on diverse standard specifications. In other words, ATF is a test framework that has high reusability, high extensibility and high efficiency for the test. In conclusion, ATF makes B 2 B/B 2 C systems interoperable rapidly Key words: Agile test framework (ATF), business-to-business (B 2 B) integration, conformance test, interoperability test, standard, test automation, and <b>test</b> <b>suite</b> generatio...|$|R
40|$|<b>Abstract.</b> Designing unit <b>test</b> <b>suites</b> for {{object-oriented}} {{systems is}} a painstaking, repetitive, and error-prone task, and significant {{research has been}} devoted to the automatic generation of <b>test</b> <b>suites.</b> One method for generating unit tests is to use formal class and method specifications as test oracles and automatically run them with developer-provided data values; for Java code with formal specifications written in the Java Modeling Language, this method is embodied in the JMLUnit tool and the JUnit testing framework on which it is based. While JMLUnit can provide reasonable test coverage when used by a skilled developer, it suffers from several shortcomings including excessive memory utilization during testing and the need to manually write significant amounts of code to generate non-primitive test data objects. In this paper we describe JML-UnitNG, a TestNG-based successor to JMLUnit that can automatically generate and execute millions of tests, using supplied test data of only primitive types, without consuming excessive amounts of memory. We also present a comparison of test coverage between JMLUnitNG and the original JMLUnit. ...|$|R
40|$|This paper {{presents}} a test process named CoFI (Conformance and Fault Injection), which has being defined {{as part of}} the doctorate program. CoFI integrates two existing test approaches: conformance test and fault injection technique. It was conceived for validating the space communication services being standardized by ESA. For the test case specification activity this process defines an approach for automatically generating test and fault cases. The main idea behind this process is to create a re-usable <b>abstract</b> <b>test</b> and fault <b>suite</b> that may help to improve the effectiveness of testing and allow the space communication services evaluation under faults. The CoFI is partially illustrated for the telecommand verification service stated in the ESA standard for the Telemetry and Telecommand Packet Utilization (PUS) services...|$|R
40|$|The paper {{presents}} a country profile for the cadastre of the Czech Republic {{based on the}} ISO 19152 : 2012 Land Administration Domain Model (LADM). The proposed profile consists of both legal and spatial components and re{{presents a}}n important driving force with which to develop a 3 D cadastre for the Czech Republic, which can guide the Strategy for the Development of the Infrastructure for Spatial Information in the Czech Republic to 2020. This government initiative emphasizes {{the creation of the}} National Set of Spatial Objects, which is defined as the source of guaranteed and reference 3 D geographic data at the highest possible level of detail covering the entire territory of the Czech Republic. This can also be a potential source of data for the 3 D cadastre. The <b>abstract</b> <b>test</b> <b>suite</b> stated in ISO 19152 : 2012 —Annex A (<b>Abstract</b> <b>Test</b> <b>Suite)</b> and the LADM conformance requirements were applied in order to explore the conformity of the Czech country profile with this international standard. To test their conformity, a mapping of elements between the LADM and the tested country profile was conducted. The profile is conformant with the LADM at Level 2 (medium level) and can be further modified, especially when legislation is updated with respect to 3 D real estate in the future...|$|E
30|$|For {{the design}} of the LADM country profile for Greece certain {{requirements}} were complied: when needed, new attributes were added so as to maintain the basic characteristics of the HC, while certain LADM classes were not used and code lists were implemented to adjust with national legislation. In order to differentiate the proposed model from other country profiles, the GR_ prefix was used. What is more, to show that the Greek model is conformant with the LADM according to the <b>Abstract</b> <b>test</b> <b>suite</b> (Annex A), it was implemented through providing the inheritance structure between LADM and the tested model, and not as a mapping as this would make the implementation more difficult.|$|E
40|$|The {{rationale}} for conducting {{any type of}} testing is ultimately to draw reasonable conclusions about the subject {{based on the results}} of the test or tests performed. Given a new piece of software, a software engineer may wish to determine the software 2 ̆ 7 s ability to handle inputs outside its specified domain, the software 2 ̆ 7 s performance on a given computing platform, or the software 2 ̆ 7 s ability to interact with other similar pieces of software. The testing performed by software engineers and analysis of the test results is the general area known as software testing;In this thesis, a newly proposed structured framework for test suite development is introduced to capture the interaction between the applications being tested, to investigate the use of an application 2 ̆ 7 s invalid input space for the generation of test cases, and to explore the notation that test suites can be expressed on two levels, abstractly and concretely via instantiation. In addition, the proposed structured framework is applied to the Minimum Interoperability Specification for Public Key Infrastructure (PKI) Components (MISPC) standard for the development of an <b>abstract</b> <b>test</b> <b>suite.</b> A part of the <b>abstract</b> <b>test</b> <b>suite</b> was instantiated, or implemented, and executed against a reference implementation of an MISPC specified Certificate Authority (CA) to explore the proposed structured frameworks capabilities. The result of this thesis demonstrate the limitation of structured test suite development frameworks that do not utilize an application 2 ̆ 7 s invalid input space for test case generation and the benefits of being able to express test suites at both abstract and concrete levels. In addition, the instantiated test suite revealed the MISPC CA reference implementation could not process a few valid MISPC messages and generated some invalid MISPC messages of its own...|$|E
40|$|<b>Abstract.</b> <b>Testing</b> is {{inherently}} incomplete; no <b>test</b> <b>suite</b> {{will ever be}} able to test all possible usage scenarios of a system. It is therefore vital to assess the implication of a system passing a <b>test</b> <b>suite.</b> The work discussed in this presentation quantifies that implication by means of two distinct, but related, measures: the risk quantifies the confidence in a system after it passes a <b>test</b> <b>suite,</b> i. e. the number of faults still expected to be present (weighted by their severity); the actual coverage quantifies the extent to which faults have been shown absent, i. e. the fraction of possible faults that has been covered. We apply a probabilistic approach, taking into account uncertainties in system behaviour. We provide evaluation algorithms that calculate the metrics for a given <b>test</b> <b>suite,</b> as well as optimisation algorithms that yield the best <b>test</b> <b>suite</b> for a given optimisation criterion. 1 Problem description Software becomes more and more complex, making thorough testing an indispensabl...|$|R
40|$|<b>Abstract.</b> Conformance <b>testing</b> is {{the problem}} of {{constructing}} a com-plete <b>test</b> <b>suite</b> of inputs based on a specification S such that any imple-mentation I (of size less than a given bound) that is not equivalent to S gives a different output on the <b>test</b> <b>suite</b> than S. Typically I and S are assumed to be some type of finite automata. In this paper we consider the problem of constructing <b>test</b> <b>suites</b> for boolean programs (or more pre-cisely modular visibly pushdown automata) that are guaranteed to catch all erroneous implementations that have at least R faults, and pass all correct implementations; if the incorrect implementation has fewer than R faults then the <b>test</b> <b>suite</b> may or may not detect it. We present a ran-domized algorithm for the construction of such <b>test</b> <b>suites,</b> and prove the near optimality of our <b>test</b> <b>suites</b> by proving lower bounds on the size of <b>test</b> <b>suites.</b> ...|$|R
40|$|The {{development}} of <b>test</b> <b>suites</b> using standardized <b>test</b> languages like TTCN- 3 and UTP starts with {{an analysis of}} the external interfaces towards the system under test (SUT). Large and complex SUTs often require a distributed test system architecture that have to consider the test objectives and the introduction of multiple parallel test system components. The decomposition of a test system needs to be discussed and decided {{at the very beginning of}} the test development process. This presentation introduces different approaches from industrial <b>test</b> <b>suite</b> development projects and provides experiences with <b>abstract</b> <b>test</b> system architecture issues (e. g. synchronization, logging and maintenance) ...|$|R
40|$|AP Issues Feedback Industrial Need ATS Review AIM Review Report Qualified AIM Develop Application Reference Model (ARM) Develop Application Interpreted Model (AIM) Develop AP Define Conformance Requirements AP Validation Management Reports AP Issues Feedback <b>Abstract</b> <b>Test</b> <b>Suite</b> & Validate Test Requirements Candidate AP Summary Sheet Purposes Validation Test Suite (AAM) Submit AP to Standards Body Report PICS {{proforma}} Conform clause NIIIP Reference Architecture: Concepts and Guidelines NIIIP Reference Architecture Page 24 Cycle 0 Figure 7 : STEP Data Objects STEP Data {{objects are}} supported by a potentially large number of AIM objects. In addition, STEP Data Objects interact with STEP Services. STEP Services represent the applications {{that the members of}} an industrial virtual enterprise use to develop and share product data. The figure shows applications and objects that have been identified in the AAM's and ARM's of AP 203 and AP 210. The [...] ...|$|E
40|$|This paper {{presents}} a testing methodology {{to check the}} conformity of implementations following the ITU-T. 120 Multimedia Conferencing protocol (ITU-T Recommendation T. 120 : data protocols for multimedia conferencing, 1996). The study {{takes into account the}} stateless and complex nature of the T. 120 protocols and provides a method of compatibility testing appropriate for complex protocol implementations. For this purpose a Reference Model for conformance testing of T. 120 systems is defined. A testing tool called Reference Tester/Implementation System has been implemented according to the Reference Model specifications and a test strategy for ensuring compatibility testing is defined. To illustrate the effectiveness of the system, test coverage of testing architectures defined in ISO/IEC 9646 - 2 (Information technology-open systems interconnection-conformance testing methodology and framework-Part 2 : <b>Abstract</b> <b>Test</b> <b>Suite</b> Specification, 1994) is shown and the relative conclusions are deducted. (C) 2001 Elsevier Science B. V. All rights reserved...|$|E
40|$|Abstract. Formal system {{modeling}} and rigorous validation techniques {{have become a}} corner stone in the development practice for safety critical systems. It is characteristic for model-based approaches {{that the relationship between}} the model and its implementation needs to be monitored and ultimately brought to conformance. To bridge the gap between model and implementation, the current paper proposes a new methodology called slope testing where we concretize an <b>abstract</b> <b>test</b> <b>suite</b> covering the model to obtain a corresponding concrete test suite on the implementation. In this way, our method is able to systematically expose the potential deficiencies in the mapping between model and code. Motivated by the avionic certification standard DO- 178 B, we introduce slope testing in a prototypical process which is based upon UML activity diagrams and ANSI-C as the respective {{modeling and}} implementation languages. Our implementation makes use of the test case generator FShell which automatically generates the required test suites for activity diagrams and source code. ...|$|E
40|$|<b>Abstract.</b> <b>Testing</b> tasks can {{be viewed}} (and organized!) as games against nature. We {{introduce}} and study reachability games. Such games are ubiquitous. A single industrial <b>test</b> <b>suite</b> may involve many instances of a reachability game. Hence the importance of optimal or near optimal strategies for reachability games. We find out when exactly optimal strategies exist for a given reachability game, and how to construct them. ...|$|R
40|$|<b>Abstract</b> — Redundant <b>test</b> {{cases in}} newly {{generated}} <b>test</b> <b>suites</b> often remain undetected until execution and waste scarce project resources. In model-based testing, the testing process starts {{early on in}} the developmental phases and enables early fault detection. The redundancy in the <b>test</b> <b>suites</b> generated from models can be detected earlier as well and removed prior to its execution. The article presents a novel model-based <b>test</b> <b>suite</b> optimization technique involving UML Activity Diagrams by formulating the <b>test</b> <b>suite</b> optimization problem as an Equality Knapsack Problem. The aim here is the development of a <b>test</b> <b>suite</b> optimization framework that could optimize the model-based <b>test</b> <b>suites</b> by removing the redundant test cases. An evolution-based algorithm is incorporated into the framework and is compared with the performances of two other algorithms. An empirical study is conducted with four synthetic and industrial scale Activity Diagram models and results are presented...|$|R
40|$|Abstract. This paper {{focuses on}} the {{terminal}} RRC connection establishment procedure, designs its message sequence chart(MSC), then write <b>abstract</b> <b>test</b> suits in TTCN- 3 core language on TTworkbench test platform, generate GFT figure and compare it with the protocol specification, and complete conformance testing of RRC connection establishment procedure. At present, this scheme has been effectively verified in the project of TD-LTE TTCN extended <b>test</b> <b>suite</b> instrument development...|$|R
40|$|The test {{generation}} method SaMsTaG (SDL and MSC based {{test case}} generation) has successfully {{been applied to}} the B-ISDN ATM Adaption Layer protocol SSCOP (Service Specific Connection Oriented Protocol). In parallel to our work the ATM Forum developed another test suite for SSCOP. Unlike the test suite generated automatically by the SaMsTaG tool, this one was specified manually. Both test suites have been compared, but the results were only of restricted value because the test suites base on different test architectures. In order to achieve more significant comparison results the SaMsTaG tool has been adapted to the test method chosen by the ATM Forum, i. e., the remote test method, and the test suite has been re-generated. In this paper we present a revised comparison of various aspect of the two test suites. Keywords SDL, MSC, TTCN, conformance testing, test case generation, <b>abstract</b> <b>test</b> <b>suite,</b> remote test method, B-ISDN SSCOP 1. Introduction SaMsTaG [3, 4, 12] is a method and a to [...] ...|$|E
40|$|Abstract The {{implementation}} of the INSPIRE directive requires to check the conformity {{of a large number}} of network services with the implementing rules of INSPIRE. The evaluation whether a service is fully conformant with INSPIRE is complex and requires the use of specialized testing tools that should report how verification has been made and should identify non-conformances. The use of the-se tools requires a high degree of technical knowledge. This fact makes very diffi-cult for non-technical stakeholders (end users, managers, domain experts, etc.) to participate effectively in conformance testing, hinders stakeholders understanding of the causes and consequences of non-conformant results and may cause in some stakeholders disinterest in conformance testing. This work explores the suitability of a behaviour-driven development (BDD) approach to the conformance testing of OGC Web services in the context of the INSPIRE directive. BDD emphasizes the participation of non-technical parties in the design of acceptance tests by means of automatable abstract tests expressed in a human readable format. Using this idea as base, this work describes a BDD based workflow to derive <b>abstract</b> <b>test</b> <b>suite...</b>|$|E
40|$|Abstract. In model based testing {{test cases}} {{are derived from}} a model (the specification) of the system we want to test. In general the model is more {{abstract}} than the implementation. This may result in test cases that are not executable, because their actions are too abstract; the implementation does not understand them. The standard approach is to rewrite the model by hand to the required level of detail and regenerate the test cases. This is error-prone and time consuming. In this paper we present an approach to automatically obtain test cases at the required level of detail by means of action refinement. Action refinement {{is a way to}} add information to the abstract model. It relates actions from the abstract model to concrete actions of the system under test. We apply this approach to a simple case of action refinement, so-called atomic linear input-inputs refinement. In order to reason about correctness between an abstract model and a concrete implementation we introduce a new implementation relation. We show that this relation is equivalent with the uioco implementation relation on the refined model. Furthermore we show under which conditions the refinement of a complete <b>abstract</b> <b>test</b> <b>suite</b> is again complete. ...|$|E
40|$|<b>Abstract.</b> <b>Testing</b> is a {{critical}} part of the software-engineering process. Coverage tools provide information about which components are exercised by a <b>test</b> <b>suite,</b> but they do not assist programmers with the important problem of how to increase coverage. We propose a tool to address that problem:Using the program’s control and flow dependences, the tool helps programmers determine where to focus their efforts, and how to force a chosen component to be exercised. ...|$|R
40|$|AbstractDeveloping <b>test</b> <b>suites</b> is {{a costly}} and {{error-prone}} process. Model-based test generation tools facilitate this process by automatically generating test cases from system models. The applicability of these tools, however, {{depends on the}} size of the target systems. Here, we propose an approach to generate test cases by combining data abstraction, enumerative test generation and constraint-solving. Given the concrete specification of a possibly infinite system, data abstraction allows to derive an abstract system, which is finite and thus suitable for the automatic generation of <b>abstract</b> <b>test</b> cases with enumerative tools. To execute <b>abstract</b> <b>test</b> cases, we have to instantiate them with concrete data. For data selection we make use of constraint-solving techniques...|$|R
40|$|<b>Abstract.</b> Model-based <b>testing</b> has {{mainly focused}} on models where {{currency}} is interpreted as interleaving (like the ioco theory for labeled transition systems), {{which may be}} too coarse when one wants concurrency to be preserved in the implementation. In order to test such concurrent systems, we choose to use Petri nets as specifications and define a concurrent conformance relation named coioco. We propose a test generation algorithm based on Petri net unfolding able to build a complete <b>test</b> <b>suite</b> w. r. t our co-ioco conformance relation. In addition we propose a coverage criterion based on a dedicated notion of complete prefixes that selects a manageable <b>test</b> <b>suite.</b> Model-based <b>Testing.</b> The aim of testing is to execute a software system, the implementation, {{on a set of}} input data selected so as to find discrepancies between actual behavior and intended behavior described by the specification. The testing process is usually decomposed into three phases: selection of relevant input data, called a <b>test</b> <b>suite,</b> among the possible inputs of the system; submission of this <b>test</b> <b>suite</b> to the implementation, its execution; and decision of the success or the failure of the <b>test</b> <b>suite</b> submission, know...|$|R
