701|1717|Public
5|$|In March 2013, Nvidia {{launched}} the GTX Titan, a consumer graphics card {{that uses the}} same GPU die as the K20X GPUs in Titan. Titan underwent acceptance testing in early 2013 but only completed 92% of the tests, short of the required 95%. The problem was discovered to be excess gold in the female edge connectors of the motherboards' PCIe slots causing cracks in the motherboards' solder. The cost of repair was borne by Cray and between 12 and 16 cabinets were repaired each week. Throughout the repairs users were given access to the available CPUs. On March 11, they gained access to 8,972 GPUs. ORNL announced on April 8 that the repairs were complete and <b>acceptance</b> <b>test</b> completion was announced on June 11, 2013.|$|E
25|$|Following {{the high}} speed flights, Waterton joined the Gloster Aircraft Company in September 1946 as a {{development}} test pilot. He became the company's Chief Test Pilot, primarily {{in charge of}} experimental flight testing their new designs, the Meteor family, the experimental Gloster E.1/44, and the delta-wing Gloster GA.5 which entered service as the Gloster Javelin. He also was involved in <b>acceptance</b> <b>test</b> flying on production aircraft.|$|E
25|$|The first 5-car set of R160As (8653-8657) was {{delivered}} on November 29, 2005, {{and the next}} remaining five cars (8658-8662) were delivered on December 6, 2005 to the New York City Transit Authority, forming a complete 10-car train for acceptance testing and evaluation. The R160As entered revenue service on the A on October 17, 2006 for their 30-day <b>acceptance</b> <b>test,</b> after several months of exhaustive non-revenue service tests.|$|E
40|$|Software <b>acceptance</b> <b>testing</b> is an {{industry}} best practice. Most development teams do it poorly. This is because teams often misunderstand what <b>acceptance</b> <b>testing</b> is and why it is important. Furthermore, these teams often {{do not have an}} extensible framework for automated <b>acceptance</b> <b>testing.</b> In this paper, we define <b>acceptance</b> <b>testing</b> and discuss why it is important, and we describe our custom automated <b>acceptance</b> <b>testing</b> framework...|$|R
50|$|In {{software}} testing the ISTQB defines <b>acceptance</b> as: formal <b>testing</b> {{with respect to}} user needs, requirements, and business processes conducted {{to determine whether a}} system satisfies the acceptance criteria and to enable the user, customers or other authorized entity {{to determine whether or not}} to accept the system. <b>Acceptance</b> <b>testing</b> is also known as user <b>acceptance</b> <b>testing</b> (UAT), end-user <b>testing,</b> operational <b>acceptance</b> <b>testing</b> (OAT) or field (<b>acceptance)</b> <b>testing.</b>|$|R
5000|$|<b>Acceptance</b> <b>testing</b> {{performed}} by the customer, often in their lab environment on their own hardware, is known as user <b>acceptance</b> <b>testing</b> (UAT). <b>Acceptance</b> <b>testing</b> may be performed {{as part of the}} hand-off process between any two phases of development.|$|R
25|$|The {{design of}} the trains was {{finalised}} in September 2004. Manufacture of two pre-production trains began in January 2005, the first scheduled {{to be completed by}} mid-2006. On 3 February 2006, Metronet announced that the first of the pre-production cars had been completed in preparation for static testing. From 21 July to 4 August 2006, a mock-up of the train was on show at Euston Square Gardens, near Euston Square tube station, for a customer <b>acceptance</b> <b>test</b> followed by public display.|$|E
25|$|In October 1982, a {{consortium}} of French engineering companies was selected by the MTA to build 225 subway cars, which {{became known as the}} R68s. The consortium was chosen over bids from the Budd Company and the Sumitomo Group. The first regular R68 train went into revenue service in Brighton Beach on June 20, 1986, after passing a successful 30-day test. Two hundred option-1 cars were later delivered for a total of 425 cars. The option for 200 additional R68s was given to Kawasaki and the car class became known as the R68A. The first R68A cars were delivered to New York City on April 12, 1988 and transferred to the MTA the following day. The first train of R68As began a 30-day <b>acceptance</b> <b>test</b> on May 18, 1988 on the IND Concourse Line.|$|E
25|$|Producing metric {{drawings}} and analyzing {{the materials used}} in the Derwent V went fairly quickly, but finding {{a substitute for the}} high-temperature, creep-resistant Nimonic 80 steel alloy was a more difficult challenge. Eventually an alloy that matched Nimonic 80's high-temperature properties was found in KhN 80T, but it was not creep-resistant. The first Derwent V copy, designated as the RD-500 (Reaktivnyy Dvigatel — jet engine) after the Factory No. 500 where the engine was first produced, was being tested on 31 December 1947, but problems cropped up quickly. Combustion was uneven and this cracked the combustion chambers. This may {{have had something to do}} with the modifications made by the Soviets to the fuel, speed and starter systems. But these problems were resolved by September 1948 when the engine passed its 100-hour State <b>acceptance</b> <b>test.</b>|$|E
40|$|Functionally {{generated}} <b>acceptance</b> <b>tests</b> {{are examined}} using structural coverage metrics. A method of comparing <b>acceptance</b> <b>tests</b> and operational usage was generated. <b>Acceptance</b> <b>tests</b> are prepresentative of operational usage {{except for the}} mix of statement types. Structural coverage metrics may provide insight into software faults...|$|R
40|$|Abstract. User <b>acceptance</b> <b>testing</b> {{is finally}} getting the {{attention}} and tool support it deserves. It is imperative that <b>acceptance</b> <b>tests</b> follow the best practices and embody the critical success factors that have been established over the years for automated unit testing. However, it is often challenging for <b>acceptance</b> <b>tests</b> to be repeatable, readable, and maintainable {{due to the nature}} of the tests and the tools currently available for automation. The key contributions this paper makes to the agile community are: first, it provides concrete examples of applying test automation patterns to user <b>acceptance</b> <b>testing,</b> and secondly it provides a description of various extensions to the WebTest <b>acceptance</b> <b>testing</b> framework that facilitate developing automated <b>acceptance</b> <b>tests</b> according to these established best practices...|$|R
5000|$|... system {{development}} lifecycle - including {{the topics of}} internal kickoff, requirements, design, development, unit/module & integration <b>testing,</b> factory <b>acceptance</b> <b>testing,</b> system shipping, installation, commissioning and site <b>acceptance</b> <b>testing</b> ...|$|R
25|$|The {{delivery}} of the first R68 was made on February 4, 1986, but it failed to pass a sharp curve on the South Brooklyn Railway trackage on 38th Street in Brooklyn, {{and as a result}} the curve had to be rebuilt and the radius eased somewhat, and the delivery took place on February 26, 1986. The 30-day <b>acceptance</b> <b>test</b> for the R68s began on the Brighton Line on April 13, 1986. The R68s' first entry to revenue service was on June 20, 1986, on the Brooklyn half of the divided D train with the first fleet consisting of cars 2500–2507. There were two contracts to supply the R68 fleet. The primary order consisted of cars 2500-2724 while the option order consisted of cars 2725-2924. The R68, therefore, became the first subway fleet to have an option order.|$|E
500|$|Replaced [...] "ramp" [...] {{cylinder}} heads with parallel pattern heads (valves {{parallel to the}} cylinder) scaled up from the Kestrel engine. 400-hour flight endurance tests carried out at RAE July 1937; <b>acceptance</b> <b>test</b> 22 September 1937. It was first widely delivered as the 1,030-horsepower (770kW) Merlin II in 1938, and production was quickly stepped up for Fairey Battle II.|$|E
2500|$|The first {{train of}} R160Bs (8713-8722) was {{delivered}} on July 22, 2005. The R160Bs entered revenue {{service on the}} [...] on August 17, 2006 for their 30-day <b>acceptance</b> <b>test,</b> after slightly over a year of successful non-revenue service tests.|$|E
30|$|Adjudicators {{generally}} {{come in two}} flavours, {{voters and}} <b>Acceptance</b> <b>Tests</b> (ATs). A brief description of voter characteristics and differences are presented in Section 5, {{in the context of}} the proposed taxonomy. We refer to Pullum ([2001]) for a more detailed description about the various types of adjudicators and their operations (pages 269 - 324). For example, specific adjudicators covered by Pullum ([2001]) are exact majority, consensus, formal consensus, formal majority, median, mean, weighted, and dynamic voters; <b>acceptance</b> <b>tests</b> can be based on satisfaction of requirements, accounting <b>tests,</b> computer run-time <b>acceptance</b> <b>tests</b> and reasonableness <b>acceptance</b> <b>tests.</b>|$|R
5000|$|ATDD {{is closely}} related to test-driven {{development}} (TDD). [...] It differs by the emphasis on developer-tester-business customer collaboration. ATDD encompasses <b>acceptance</b> <b>testing,</b> but highlights writing <b>acceptance</b> <b>tests</b> before developers begin coding.|$|R
50|$|Aircrew {{training}} include Class A (Experimental and <b>Acceptance</b> <b>Testing)</b> or {{the shorter}} Class B (<b>Acceptance</b> <b>Testing)</b> courses on either fixed or rotary-wing aircraft. A light aircraft test pilot course is also offered.|$|R
2500|$|The Wright {{brothers}} spent {{ten months}} following the fatal crash making engineering improvements to the airplane. By July 1909, Orville was ready to complete the <b>acceptance</b> <b>test</b> for the Signal Corps. On July 30, 1909, Foulois' first flight in an aeroplane was the evaluation test flight from Fort Myer to Alexandria, Virginia. Pilot Orville Wright and Navigator Foulois broke previous speed, altitude and cross-country duration records, flying at 42.5mph, 400 feet, and for [...] The Army purchased this Wright Model A Military Flyer, which became [...] "Signal Corps No. 1". The final condition of the contract was to train two pilots.|$|E
2500|$|RD-500 {{was a close}} copy of the Derwent with a {{single-stage}} centrifugal compressor, nine {{combustion chambers}} and a single-stage turbine. It matched the Derwent's thrust of 15.9kN (3,506lbf) and was only [...] heavier. The main problem with the engine in service was with its turbine blades, 30% of which failed inspection due to recrystallization after casting. The poor creep resistance of the KhN 80T alloy resulted in dangerous elongation of the turbine blades. Up to 40% of the early production RD-500s had to be individually adjusted before delivery and the service life of the engine never approached the 100 hours demonstrated in the <b>acceptance</b> <b>test.</b>|$|E
2500|$|As {{the space}} race continued, the {{civilian}} space agency, NASA started on October1, 1958 but the Army kept von Braun and the ABMA {{for another year}} and a half. [...] NASA's Project Mercury chose the [...] "Old Reliable" [...] Redstone, with its unmatched launch record, as America's first manned launch vehicle. [...] Nevertheless, the Army had to make improvements for manned missions. [...] The crew at the Interim Test Stand ran over 200 static firings to improve the Redstone propulsion system. [...] In addition, all eight Mercury-Redstone launch vehicles endured a full duration <b>acceptance</b> <b>test</b> at the interim stand. [...] On July 1, 1960, 4,670 people transferred from the ABMA to NASA forming the Marshall Space Flight Center (MSFC).|$|E
50|$|<b>Acceptance</b> <b>tests</b> {{are a part}} of {{an overall}} testing strategy. They are the {{customer}} tests that demonstrate the business intent of a system. Component <b>tests</b> are technical <b>acceptance</b> <b>tests</b> developed by an architect that specify the behavior of large modules. Unit tests are created by the developer to drive easy-to-maintain code. They are often derived from <b>acceptance</b> <b>tests</b> and unit tests. Cross-functional testing includes usability testing, exploratory testing, and property testing (scaling and security).|$|R
5000|$|In {{contract}} <b>acceptance</b> <b>testing,</b> {{a system}} is <b>tested</b> against <b>acceptance</b> criteria as documented in a contract, before the system is accepted. In regulation <b>acceptance</b> <b>testing,</b> {{a system is}} tested to ensure it meets governmental, legal and safety standards.|$|R
5000|$|This {{may include}} factory <b>acceptance</b> <b>testing</b> (FAT), i.e. the testing {{done by a}} vendor before the product or system is moved to its {{destination}} site, after which site <b>acceptance</b> <b>testing</b> (SAT) may be performed by the users at the site.|$|R
5000|$|If {{the test}} is successful, the product is copied to an <b>Acceptance</b> <b>test</b> environment. During the <b>Acceptance</b> <b>test,</b> the {{customer}} will test the product in this environment to verify whether it meets their expectations.|$|E
50|$|Capybara: <b>Acceptance</b> <b>test</b> {{framework}} for web applications.|$|E
5000|$|Cucumber, a behavior-driven {{development}} (BDD) <b>acceptance</b> <b>test</b> framework ...|$|E
40|$|<b>Acceptance</b> <b>Testing</b> will be {{performed}} by a medical physicist before the scanner is used to scan patients. The goal of the <b>acceptance</b> <b>testing</b> {{is to ensure that}} the scanner meets or exceeds the manufacturer’s specifications as is required by the CAR Standards for Magnetic Resonance Imaging. The references {{at the end of this}} section provide guidelines for the <b>acceptance</b> <b>tests.</b> However, actual tests may deviate from the guidelines due to the capabilities and limitations of the scanner and phantoms...|$|R
5000|$|In {{addition}} to <b>acceptance</b> <b>tests</b> for requirements, <b>acceptance</b> <b>tests</b> {{can be used}} on a project as a whole. For example, if this requirement was part of a library book checkout project, there could be <b>acceptance</b> <b>tests</b> for the whole project. These are often termed SMART objectives. An example test is [...] "When the new library system is in production, the users will be able to check books in and out three times as fast as they do today".|$|R
40|$|Abstract—During <b>acceptance</b> <b>testing</b> {{customers}} {{assess whether}} a system meets their expectations and often identify issues {{that should be}} improved. These findings have to be communicated to the developers – a task we observed to be error prone, especially in distributed teams. Here, it is normally not possible to have developer representatives from every site attend the test. Developers who were not present might misunderstand insufficiently documented findings. This hinders fixing the issues and endangers customer satisfaction. Integrated feedback systems promise to mitigate this problem. They allow to easily capture findings and their context. Correctly applied, this technique could improve feedback, while reducing customer effort. This paper collects our experiences from comparing <b>acceptance</b> <b>testing</b> with and without feedback systems in a distributed project. Our results indicate that this technique can improve <b>acceptance</b> <b>testing</b> – if certain requirements are met. We identify key requirements feedback systems should meet to support <b>acceptance</b> <b>testing.</b> Keywords-distributed software development; requirements engineering; <b>acceptance</b> <b>testing</b> I...|$|R
5000|$|Capybara, <b>Acceptance</b> <b>test</b> {{framework}} for Ruby web applications ...|$|E
5000|$|Note: Repaired Unit Acceptance Testing {{performance}} data {{is also used}} to evaluate [...] "in-family" [...] performance. While a UUT may meet all other <b>Acceptance</b> <b>Test</b> pass/fail criteria, results which deviate significantly from other repaired units or from the original Production Unit <b>Acceptance</b> <b>Test</b> data shall require rejection of the UUT.|$|E
5000|$|Mocha, {{a popular}} web <b>acceptance</b> <b>test</b> {{framework}} based on Javascript and Node.js ...|$|E
40|$|The {{same kind}} of {{standard}} and controls are established that are currently in use for the procurement of new analog, digital, and IBM/IBM compatible 3480 tape cartridges, and 1 in wide channel video magnetic tapes. The Magnetic Tape Certification Facility (MTCF) maintains a Qualified Products List (QPL) for the procurement of new magnetic media and uses the following specifications for the QPL and Acceptance Tests: (1) NASA TM- 79724 {{is used for the}} QPL and <b>Acceptance</b> <b>Testing</b> of new analog magnetic tapes; (2) NASA TM- 80599 is used for the QPL and <b>Acceptance</b> <b>Testing</b> of new digital magnetic tapes; (3) NASA TM- 100702 is used for the QPL and <b>Acceptance</b> <b>Testing</b> of new IBM/IBM compatible 3840 magnetic tape cartridges; and (4) NASA TM- 100712 is used for the QPL and <b>Acceptance</b> <b>Testing</b> of new 1 in wide channel video magnetic tapes. This document will be used for the QPL and <b>Acceptance</b> <b>Testing</b> of new Helical Scan 8 mm digital data tape cartridges...|$|R
40|$|Automated <b>acceptance</b> <b>testing</b> {{is a new}} and {{promising}} agile testing approach. Fit is the most established technical framework for specifying and executing <b>acceptance</b> <b>tests</b> which, ideally, lets the users express requirements {{in the form of}} <b>acceptance</b> <b>tests.</b> We performed an industrial case study to learn more on {{the costs and benefits of}} Fit tests. We learned that Fit tests may improve important parts of an agile development process but there is still a need for further research and improvements. 1...|$|R
5000|$|Closing project, {{supported}} by realization {{number of tests}} focused on complex verification of overall quality of created solution. It can include System Integration <b>Tests,</b> User <b>Acceptance</b> <b>Tests</b> and Operational <b>Acceptance</b> <b>Tests.</b> One of the products can be recommendation about production start of the system.|$|R
