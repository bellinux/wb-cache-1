26|10000|Public
40|$|Models {{provide the}} {{foundation}} to statistics and are generally viewed as approximations {{to the underlying}} true state of nature. Data are used to estimate parameters in these approximating models. Assuming there exists a true underlying model, the parameters in the models used for data analysis are actually functions of the parameters of an underlying true model. Therefore, in order to fully understand what a proposed model actually represents, {{it is useful to}} examine how the parameters in <b>an</b> <b>approximating</b> <b>model</b> relate to the parameters in the true model. That is, given a statistic, this paper seeks to determine what the statistic is actually estimating in terms of an underlying true model. Examples and illustrations of the meaning of parameters in <b>an</b> <b>approximating</b> <b>model</b> to a true underlying model are provided. This is accomplished by fitting <b>an</b> <b>approximating</b> <b>model</b> to an assumed true model, similar to the way <b>an</b> <b>approximating</b> <b>model</b> is fit to a data set. The ideas are also illustrated with latent variable models, in particular, using mixture models...|$|E
40|$|Abstract. In {{this paper}} we derive <b>an</b> <b>approximating</b> <b>model</b> for the kinetic {{reaction}} of the processes in yeast multiplication. The model comprising a Michaelis-Menten mechanism for yeast's feeding and other two elementary reactions for multiplication and degradation of the yeasts were qualitatively compared {{with a series of}} experimental results for yeast fermentation. The analysis given an estimate for the minimum number of experiments required to obtain good estimates for the parameters of the yeast fermentation process...|$|E
40|$|We {{investigate}} a stochastic {{model for the}} competition between two species. Based on percentiles of {{the maximum number of}} individuals in the ecosystem, we present <b>an</b> <b>approximating</b> <b>model</b> for which the extinction time {{can be thought of as}} a phase-type random variable. We determine formulae for the probabilities of extinction and the moments of the extinction time. We discuss the use of several quasi-stationary assumptions. We include a comparative study between existing asymptotic results, results obtained from a simulation of the process, and our solution. ...|$|E
2500|$|Coulomb friction, {{named after}} Charles-Augustin de Coulomb, is <b>an</b> <b>approximate</b> <b>model</b> used to {{calculate}} the force of dry friction. It is governed by the model: ...|$|R
25|$|Bohr {{extended}} {{the model of}} hydrogen to give <b>an</b> <b>approximate</b> <b>model</b> for heavier atoms. This gave a physical picture that reproduced many known atomic properties for the first time.|$|R
25|$|The Lennard-Jones {{potential}} {{is often used}} as <b>an</b> <b>approximate</b> <b>model</b> for the isotropic part of a total (repulsion plus attraction) van der Waals force {{as a function of}} distance.|$|R
40|$|This paper {{considers}} {{testing for}} normality for correlated data. The proposed test procedure employs the skewness-kurtosis test statistic, but studentized by standard error estimators {{that are consistent}} under serial dependence of the observations. The standard error estimators are sample versions of the asymptotic quantities that do not incorporate any downweighting, and, hence, no smoothing parameter is needed. Therefore, the main feature of our proposed test is its simplicity, {{because it does not}} require the selection of any user-chosen parameter such as a smoothing number or the order of <b>an</b> <b>approximating</b> <b>model.</b> Publicad...|$|E
40|$|A {{decision}} maker fears that data are {{generated by a}} statistical perturbation of <b>an</b> <b>approximating</b> <b>model</b> that is either a controlled diffusion or a controlled measure over continuous functions of time. A perturbation is constrained {{in terms of its}} relative entropy. Several different two-player zero-sum games that yield robust decision rules are related to one another, to the max–min expected utility theory of Gilboa and Schmeidler [Maxmin expected utility with non-unique prior, J. Math. Econ. 18 (1989) 141 – 153], and to the recursive risk-sensitivity criterion described in discrete time by Hansen and Sargent [Discounted linear exponentia...|$|E
40|$|This {{thesis is}} about the {{analysis}} of Hamiltonian dynamical systems through reduction. This reduction consists of two parts: a reduction {{of the number of}} degrees of freedom ('moving parts') of the system, and a reduction of the number of parameters it depends upon. Both reductions {{take the form of a}} coordinate transformation that brings the system in a simpler form. The final result is <b>an</b> (<b>approximating)</b> <b>model</b> system, with one degree of freedom and a small number of parameters. The advantage is that the dynamics of this system can be analyzed in detail. [...] . Zie: Summary...|$|E
50|$|Bohr {{extended}} {{the model of}} hydrogen to give <b>an</b> <b>approximate</b> <b>model</b> for heavier atoms. This gave a physical picture that reproduced many known atomic properties for the first time.|$|R
50|$|The Lennard-Jones {{potential}} {{is often used}} as <b>an</b> <b>approximate</b> <b>model</b> for the isotropic part of a total (repulsion plus attraction) van der Waals force {{as a function of}} distance.|$|R
30|$|Since (3) is only <b>an</b> <b>approximate</b> <b>model</b> {{of system}} (1), can a dynamic output {{feedback}} {{designed for the}} reduced-order subsystem stabilize the original full-order system? Next, we will address this problem.|$|R
40|$|This article studies random {{variables}} whose stop-loss rank falls between a cer'tain risk (assumed to be integer-valued and non-negative, {{but not necessarily}} of life-insurance type) and the compound Poisson approximation to this risk. They con-sist of a compound Poisson part to which some independent Bernoulli-type variables are added. Replacing each term in an individual model with such a random variable leads to <b>an</b> <b>approximating</b> <b>model</b> for the total claims on a portfolio of contracts that is computationally almost as attractive as the compound Poisson approximation used in the standard collective model. The resulting stop-loss premiums are {{much closer to the}} real values. 1...|$|E
40|$|We {{present a}} proof {{that in a}} fat-tree network with n {{processing}} nodes m n messages with randomly chosen, distinct sources and independently and randomly chosen destinations are delivered within O(lg m) delivery rounds with high probability. More succinctly, we establish that m messages are delivered in O(lg m+ ln 1 =) delivery rounds with probability 1 for any small > 0. Unlike previously applied proof methods, we use <b>an</b> <b>approximating</b> <b>model</b> for the collision behavior of the network amenable to concise yet simple theoretical analysis. We justify {{the accuracy of the}} approximation by means of behavioral simulations based on a gate-level implementation of a fat-tree network...|$|E
40|$|In the past, {{environmental}} phosphorus (P) parameters like soil P indices {{have been}} used to catogorize the potential risk of P losses from agricultural land. In order to assess the actual risk of P pollution of groundwater and surface waters, dynamic process oriented soil and water quality models have been frequently used. Recently, <b>an</b> <b>approximating</b> <b>model</b> for phosphorus, called SIMPLE, has been developed. This model approximates the output from a complex dynamic water quality model. The approximating model is called a metamodel. This simple P-model proves to be a powerful tool for quick assessment of the risk of P pollution from agricultural land to surface waters...|$|E
40|$|The use of {{polarization}} filters {{is demonstrated}} on lunar seismograms. Body-wave arrivals from artificial impacts {{are identified as}} surface reflections, which {{may be used for}} improving our knowledge of the lunar interior or to relocate surface events if <b>an</b> <b>approximate</b> location is known as well as <b>an</b> <b>approximate</b> <b>model...</b>|$|R
50|$|Adaptive fuzzy fitness {{granulation}} (AFFG) is {{a proposed}} solution to constructing <b>an</b> <b>approximate</b> <b>model</b> of the fitness function {{in place of}} traditional computationally expensive large-scale problem analysis like (L-SPA) in the Finite element method or iterative fitting of a Bayesian network structure.|$|R
40|$|A common {{approach}} when applying reinforcement learning to address control {{problems is that}} of first learning a policy based on <b>an</b> <b>approximated</b> <b>model</b> of the plant, whose behavior can be quickly and safely explored in simulation; and then implementing the obtained policy to control the actual plant. Here we follow this approach to learn to engage a transmission clutch, {{with the aim of}} obtaining a rapid and smooth engagement, with a small torque loss. Using <b>an</b> <b>approximated</b> <b>model</b> of <b>a</b> wet clutch, which simulates a portion of the whole engagement, we first learn an open loop control signal, which is then transferred on the actual wet clutch, and improved by further learning with a different reward function, based on the actual torque loss observed. info:eu-repo/semantics/publishe...|$|R
40|$|A {{decision}} maker fears that data are {{generated by a}} statistical perturbation of <b>an</b> <b>approximating</b> <b>model</b> that is either a controlled diffusion or a controlled measure over continuous functions of time. A perturbation is constrained {{in terms of its}} relative entropy. Several different two-player zero-sum games that yield robust decision rules and are related to one another, to the max-min expected utility theory of Gilboa and Schmeidler (1989), and to the recursive risk-sensitivity criterion described in discrete time by Hansen and Sargent (1995). To represent perturbed models, we use martingales on the probability space associated with the approximating model. Alternative sequential and non-sequential versions of robust control theory imply identical robust decision rules that are dynamically consistent in a useful sense...|$|E
40|$|International audienceWe present {{iterative}} {{methods for}} choosing the optimal regularization parameter for linear inverse problems with Total Variation regularization. This approach {{is based on}} the Morozov discrepancy principle or on a damped version of this principle and on <b>an</b> <b>approximating</b> <b>model</b> function for the data term. The theoretical convergence of the method of choice of the regularization parameter is demonstrated. The choice of the optimal parameter is refined with a Newton method. The efficiency of the method is illustrated on deconvolution and super-resolution experiments on different types of images. Results are provided for different levels of blur, noise and loss of spatial resolution. The damped Morozov discrepancy principle often outerperforms the approaches based on the classical Morozov principle and on the Unbiased Predictive Risk Estimator. Moreover, the proposed methods are fast schemes to select the best parameter for TV regularization...|$|E
40|$|In {{this paper}} {{we examine the}} time T to reach a {{critical}} number K 0 of infections during an outbreak in an epidemic model with infective and susceptible immigrants. The underlying process X, which was first introduced by Ridler-Rowe (1967), is related to recurrent diseases and {{it appears to be}} analytically intractable. We present <b>an</b> <b>approximating</b> <b>model</b> inspired from the use of extreme values, and we derive formulae for the Laplace-Stieltjes transform of T and its moments, which are evaluated by using an iterative procedure. Numerical examples are presented to illustrate the effects of the contact and removal rates on the expected values of T and the threshold K 0, when the initial time instant corresponds to an invasion time. We also study the exact reproduction number Rexact, 0 and the population transmission number Rp, which are random versions of the basic reproduction number R 0...|$|E
40|$|We {{model the}} {{formation}} of magnetospheric components of millisecond pulsar light curves, deriving <b>an</b> <b>approximate</b> <b>model</b> for the curved space, `swept-back' dipole field and following photon emission, propagation, and scattering. Magnetospheric pulse components are strongly affected by rapid rotation and Schwarzschild effects. Comment: submitted to Ap...|$|R
40|$|A general {{procedure}} is presented for constructing and analyzing approximations of dynamic programming models. The models considered are the monotone contraction operator models of Denardo (1967), which include Markov decision processes and stochastic {{games with a}} criterion of discounted present value over an infinite horizon plus many finite-stage dynamic programs. The approximations are typically achieved by replacing the original state and action spaces by subsets. Tight bounds are obtained for the distances between the optimal return function in the original model and (1) {{the extension of the}} optimal return function in the approximate mode! and (2) the return function associated with the extension of an optimal pohcy in the <b>approximate</b> <b>model.</b> Conditions are also given under which the sequence of bounds associated with <b>a</b> sequence of <b>approximating</b> <b>models</b> converges to zero. 1. Introductioni and summary. If the state and action spaces in a dynamic programming model are large (infinite, for example), it is often convenient to use <b>an</b> <b>approximate</b> <b>model</b> in order to apply a dynamic programming algorithm to obtain <b>an</b> <b>approximate</b> solution. <b>A</b> natural way to construct <b>an</b> <b>approximate</b> <b>model</b> is to let the new state and action spaces be subsets of the original state and action spaces; the...|$|R
40|$|We {{describe}} the physical hypotheses underlying the derivation of <b>an</b> <b>approximate</b> <b>model</b> of water waves. For unidirectional surface shallow water waves moving over an irrotational flow {{as well as}} over a non-zero vorticity flow, we derive the Camassa-Holm equation by an interplay of variational methods and small-parameter expansions. Comment: 14 page...|$|R
40|$|This paper {{considers}} {{testing for}} normality for time series data. In econometrics the typical testing procedure employs the Jarque-Bera test statistic {{which has an}} asymp-totic chi-square distribution when the considered series is uncorrelated. However, with time series data it often happens that the model is not correctly speci…ed (so, the residual series may exhibit serial correlation), and in other cases, the researcher might not be interested in modeling the serial correlation at all. In these cases the Jarque-Bera test is invalid {{because it does not}} take the serial correlation into account. In this paper we propose a simple nonparametric modi…cation of the Jarque-Bera test that is robust to the presence of serial correlation of a general form. Besides its simplic-ity, the remarkable feature of our test {{is that it does not}} require the selection of any user-chosen parameter such as a smoothing number or the order of <b>an</b> <b>approximating</b> <b>model...</b>|$|E
40|$|Abstract. The {{open pit}} mine block {{sequencing}} problem (OPBS) seeks a discrete-time production schedule that maximizes the {{net present value}} of the orebody extracted from an open-pit mine. This integer program (IP) discretizes the mine’s volume into blocks, imposes precedence con-straints between blocks, and limits resource consumption in each time period. We develop a “sliding time window heuristic ” to solve this IP ap-proximately. The heuristic recursively defines, solves and partially fixes <b>an</b> <b>approximating</b> <b>model</b> having: (i) fixed variables in early time periods, (ii) an exact submodel defined over a “window ” of middle time peri-ods, and (iii) a relaxed submodel in later time periods. The heuristic produces near-optimal solutions (typically within 2 % of optimality) for model instances that standard optimization software fails to solve. Fur-thermore, it produces these solutions quickly, even though our OPBS model enforces standard upper-bounding constraints on resource con-sumption along with less standard, but important, lower-bounding con-straints...|$|E
40|$|In a Markov {{decision}} problem with hidden state variables, a posterior distribution {{serves as a}} state variable and Bayes ’ law under <b>an</b> <b>approximating</b> <b>model</b> gives its law of motion. A decision maker expresses fear that his model is misspecified by surrounding it {{with a set of}} alternatives that are nearby as measured by their expected log likelihood ratios (entropies). Sets of martingales represent alternative models. A decision maker constructs a sequence of robust decision rules by pretending that a sequence of minimizing players chooses increments to a martingale and a distortion to the time t prior over the hidden state. A risk sensitivity operator induces robustness to perturbations of the approximating model conditioned on the hidden state. Another risk sensitivity operator induces robustness with respect to a prior distribution over the hidden state. We thereby extend the approach of Hansen and Sargent (1995) to problems that contain hidden states. The worst case martingale is overdetermined, expressing an intertemporal inconsistency of worst case beliefs about the hidden state, but not about observables. ...|$|E
40|$|We present <b>an</b> <b>approximate</b> <b>model</b> of Wheeler-Feynman electrodynamics {{for which}} {{uniqueness}} of solutions is proved. It is simple {{enough to be}} instructive but close enough to Wheeler-Feynman electrodynamics such that we can discuss its natural type of initial data, constants of motion and stable orbits with regard to Wheeler-Feynman electrodynamics. Comment: 16 page...|$|R
40|$|We {{consider}} an ideal ﬂuid with vorticity concentrated on a smooth curve and we study <b>an</b> <b>approximate</b> <b>model</b> for {{the evolution of}} a line vortex. We prove existence and uniqueness of solutions in suitable Sobolev spaces, together with some blow-up estimates, near the possible singularities. We also prove a continuation criterion involving the length of the line itself...|$|R
40|$|Simulations {{of space}} shuttle {{synthetic}} aperture radar antennas {{under the influence of}} space environmental conditions were carried out at L, C, and X-band. Mathematical difficulties in modeling large, non-planar array antennas are discussed, and <b>an</b> <b>approximate</b> <b>modeling</b> technique is presented. Results for several antenna error conditions are illustrated in far-field profile patterns, earth surface footprint contours, and summary graphs...|$|R
40|$|The {{interest}} is in a stochastic model for the competition of two species, which was first introduced by Reuter [18] and Iglehart [11], and then analyzed by Ridler-Rowe [19]. The model {{is related to the}} two-species autonomous competitive model (Zeeman [24]), where individuals compete either directly or indirectly for a limited food supply and, consequently, birth and death rates depend on the population size of {{one or both of the}} species. The aim is to complement the treatment of the model we started in [8, 9] by focusing here on probabilistic descriptors that are inherently linked to an individual: its residual lifetime and the number of direct descendants. We present <b>an</b> <b>approximating</b> <b>model</b> based on the maximum size distribution, and we discuss on various models defined in terms of the underlying killing and reproductive strategies. Numerical examples are presented to show the effects of the killing and reproductive strategies on the behavior of an individual, and how the impact of these strategies on the descriptors vanishes in highly competitive ecosystems...|$|E
40|$|In {{time series}} analysis, {{the family of}} {{generalized}} state-space models is extremely rich. However, their likelihood functions are intractable, except in certain special cases, and this limits the options in analyses. In practice, a study typically (1) uses some kind of approximation to the likelihood function, for instance, one obtained analytically or by making use of the particle filter or related methods, (2) adopts a standard Markov chain Monte Carlo approach to parameter estimation, or (3) sacrifices goodness-of-fit for numerical convenice by choosing <b>an</b> <b>approximating</b> <b>model</b> for which the likelihood can be computed. Each of these approaches has advantages and disadvantages, but since none of them yields a consistent estimate of the likelihood, model selection remains an outstanding problem for the general family. This paper addresses this problem by introducing a recursive estimator of the log-likelihood for the generalized state-space model, which is obtained as a kernel density estimator driven by the iterations of a Markov chain. The estimator is very simple to compute, and is shown to converge almost surely to the exact log-likelihood {{as the number of}} iterations of the Markov chain approaches infinity...|$|E
40|$|Cyber-{{physical}} systems (CPS) {{bridge the}} virtual cyber {{world with the}} real physical world. For representing a physical environment in cyber, CPS devices / nodes are as-signed to collect data in a region of interest. In practice, the nodes seldom fully cover the region due to the restriction of quantity and cost. Hence, the sampled data are usually inadequate to describe the holistic environment. Recent re-searches mainly focus on the interpolation methods to gen-erate <b>an</b> <b>approximating</b> <b>model</b> from the raw data. However, in this paper, we propose to study the spatio-temporal dis-tribution of CPS nodes {{in order to obtain}} the crucial data for optimal environment abstraction. There are two target problems. First, when the environment changes little over time, what is the optimal spatial distribution of stationary nodes based on historical data? Second, when the environ-ment is time-varying, what is the adaptive spatio-temporal distribution of mobile nodes? We show the NP hardness of the former problem and propose an approximation al-gorithm. For the latter problem, we develop a cooperative movement algorithm on nodes for achieving a curvature-weighted distribution pattern. A trace driven simulation based on real data of GreenOrbs project evaluates the per-formance of the proposed approaches. 1...|$|E
40|$|Séminaire des jeudis de la com' de l'équipe SCNThe {{existing}} {{near field}} sources localization techniques {{are based on}} <b>an</b> <b>approximated</b> <b>model</b> which brings error with it. In bistatic MIMO system, it takes a combined form due to the two arrays. This error is small but may be significant for a precision demanding application. Therefore, we can either use exact model based method to obtain the directional parameters or correct the directional parameters obtained from the <b>approximated</b> <b>model</b> based methods...|$|R
40|$|AbstractThis paper {{presents}} <b>an</b> <b>approximate</b> <b>model</b> for {{the simulation}} of pulsar aided navigation systems. High fidelity simulations {{of these systems}} are computationally intensive and impractical for simulating periods of a day or more. Simulation of yearlong missions is done by abstracting navigation errors as periodic Gaussian noise injections. This paper presents <b>an</b> intermediary <b>approximate</b> <b>model</b> to simulate position errors for periods of several weeks, useful for building more accurate Gaussian error models. This is done by abstracting photon detection and binning, {{replacing it with a}} simple deterministic process. The <b>approximate</b> <b>model</b> enables faster computation of error injection models, allowing the error model to be inexpensively updated throughout a simulation. Testing of the <b>approximate</b> <b>model</b> revealed <b>an</b> optimistic performance prediction for non-millisecond pulsars with more accurate predictions for pulsars in the millisecond spectrum. This performance gap was attributed to noise which is not present in the <b>approximate</b> <b>model</b> but can be predicted and added to improve accuracy...|$|R
40|$|We {{provide a}} novel view of {{learning}} <b>an</b> <b>approximate</b> <b>model</b> of <b>a</b> partially observable environment from data and present a simple {{implementation of the}} idea. The learned model abstracts away unnecessary details of the agent’s experience and focuses only on making certain predictions of interest. We illustrate our approach in small computational examples, demonstrating the data efficiency of the algorithm. 1...|$|R
