0|2878|Public
30|$|Fill {{the fine}} <b>aggregate</b> <b>sample</b> in a 1 -L steel {{cylinder}} and measure its <b>weight.</b> The fine <b>aggregate</b> <b>sample</b> should then be fully packed using a rubber hammer {{and the surface}} leveled.|$|R
3000|$|... 9 This {{could also}} be a {{consequence}} of not using the <b>sampling</b> <b>weights</b> to calculate the means. We do not use the MxFLS <b>sampling</b> <b>weights</b> because we did not consider them reliable. In many cases the <b>sampling</b> <b>weight</b> was missing and in some others the <b>sampling</b> <b>weight</b> was zero. <b>Sampling</b> <b>weights</b> are calculated as the inverse of the probability that a given respondent is included in the sample, hence zero <b>sampling</b> <b>weights</b> are not a sensible <b>weight.</b> Missing <b>sampling</b> <b>weights</b> are also a problem.|$|R
25|$|Methylene blue value {{reflects}} {{the amount of}} clay minerals in <b>aggregate</b> <b>samples.</b>|$|R
3000|$|... is {{the density}} of water, Wair is the <b>sample’s</b> <b>weight</b> in air, and Wwater is the <b>sample’s</b> <b>weight</b> in water.|$|R
40|$|This {{piece of}} {{research}} work {{aim is to}} assess the influences of silt/clay impurities present in fine aggregates on the concrete strength. Five <b>samples</b> of fine <b>aggregates</b> were taken from five different locations within Ado-Ekiti, Ekiti State Nigeria. The percentage of silt/clay in each sample was determined by sieve analysis test in the laboratory. The concrete cubes of mix 1 : 2 : 4 were prepared using water/cement ratio of 0. 65 from the five fine <b>aggregates</b> <b>samples.</b> The cubes were crushed at ages 7, 14, 21 and 28 days and the compressive strength determined. The same coarse aggregates, cement and water were used with these fine <b>aggregates</b> <b>samples</b> to prepare the concrete cubes. It was discovered that these fine <b>aggregates</b> <b>samples</b> {{do not have the}} same percentage of silt/clay content. Also, as the silt/clay content increases, the compressive strength of concrete decreases. The concrete produced from these fine <b>aggregates</b> <b>samples</b> {{do not have the same}} slump, the slump decreases as the percentage of silt/clay content increases...|$|R
30|$|Empirical studies often {{pass over}} the survey design and the <b>sampling</b> <b>weights.</b> There are however two ways of {{incorporating}} <b>sampling</b> <b>weights</b> when estimating the propensity score. The first one is to fit a weighted regression model and the second one is to include <b>sampling</b> <b>weights</b> as an additional covariate in the propensity score model. However, Austin (2016) shows that this does not significantly alter {{the performance of the}} matching estimator in terms of balancing covariates.|$|R
40|$|<b>Sampling</b> <b>weights</b> are a {{reflection}} of sampling design; they allow us to draw valid conclusions about population features from sample data. This paper explains the fundamentals of computing <b>sampling</b> <b>weights</b> for large-scale assessments in educational research. The relationship between the nature of complex samples and best practices in developing a set of weights to enable computation of unbiased population estimates is described. Effects of <b>sampling</b> <b>weights</b> on estimates are shown, as well as potential consequences of not using weights when analysing data from complex samples. Illustrative examples are provided {{in order to make}} it easy to understand the rationale behind the mathematical foundations. Keywords complex samples, large-scale assessments, non-response adjustments, <b>sampling</b> <b>weights</b> Copyrigh...|$|R
30|$|Brem et al. (Brem et al. 2001) {{found that}} 8 -gauge SVAB showed a 39 % {{increase}} in <b>sample</b> <b>weight</b> compared with 11 -gauge SVAB. We used estimated weights of tissue obtained with SVAB, which are 0.09 g with 11 -gauge and 0.19 g with 8 -gauge needle, {{to compare the}} obtained <b>sample</b> <b>weight</b> between two groups. Out result showed that obtained sample numbers in 8 G group were significantly lower but <b>sample</b> <b>weight</b> were significantly heavier than those of 11 G group.|$|R
40|$|When analysts {{estimate}} a multilevel model using survey data, {{they often}} use weighted procedures using multilevel <b>sampling</b> <b>weights</b> {{to correct the}} effect of unequal probabilities of selection. This study addresses the impacts of including <b>sampling</b> <b>weights</b> {{and the consequences of}} ignoring them by asses-sing the performance of four approaches: the multilevel pseudo–maximum likelihood (MPML), the probability-weighted iterative generalized least squares (PWIGLS), the naive (ignoring <b>sampling</b> <b>weights),</b> and the <b>sample</b> distribution methods for a linear random-intercept model under a two-stage clustering sampling design. When inclusion probabilities are correlated with the values of outcome variable conditioning on the model covariates, the sam-pling design becomes informative. The results show that whether a sampling design is informative and at which stage of the sampling design it is informa-tive have substantial impacts on the estimation. The results also show that the level of variation of <b>sampling</b> <b>weights</b> is correlated with the bias of estimates. A higher level of variation of <b>sampling</b> <b>weights</b> is associated with a higher level of bias when a sampling design is informative; however, under a nonin-formative design, the level of variation of <b>sampling</b> <b>weights</b> may not necessa-rily associate with biased results. Ignoring an informative sampling design at the first stage will result in biased estimates on the intercept and variance o...|$|R
30|$|The survey <b>sampling</b> <b>weights</b> {{are used}} in the analysis.|$|R
30|$|The {{sieve test}} {{required}} oven-dried sand samples; however, when the sand sample {{is mixed with}} cement paste as a mortar, the oven-dried sand sample absorbs the mixing water. Hence, {{it was necessary to}} determine the absorption rate to calculate the saturated but surface dry (SSD) condition of each sample. Furthermore, since smaller sizes of fine aggregates have higher specific surface areas, fine <b>aggregate</b> <b>samples</b> with the smaller mean size absorbed more water than the larger fine aggregates. This relates to the solid concentration of mortar and its need for a water-to-cement ratio. When this ratio is properly applied, it gives the mortar a higher yield stress and viscosity. The absorption ratio of each fine <b>aggregate</b> <b>sample</b> was evaluated based on ASTM C 128 (ASTM International 2015). Table  2 lists the fine aggregate samples’ absorption rates. The absorption ratio increased as the mean size of the fine <b>aggregate</b> <b>sample</b> decreased, as expected. Notably, for G 0.34, about 7.26 % of the highest absorption was observed.|$|R
5000|$|A {{horizontal}} portion, or plateau {{that indicates}} constant <b>sample</b> <b>weight</b> ...|$|R
40|$|From {{family of}} {{corrective}} boosting algorithms (i. e. AdaBoost, LogitBoost) to total corrective algorithms (i. e. LPBoost, TotalBoost, SoftBoost, ERLPBoost), we analysis these methods of <b>sample</b> <b>weight</b> updating. Corrective boosting algorithms update the <b>sample</b> <b>weight</b> {{according to the}} last hypothesis; comparatively, total corrective algorithms update the weight with the best one of all weak classifiers. However, all these algorithms just use the local information for updating the <b>sample</b> <b>weight</b> ignoring the global information. In light of this context, we show that updating the <b>sample</b> <b>weight</b> using global information of combined weak classifiers maybe accelerate the convergence speed of boosting algorithm. By simply adding the strong classifier to the linear constraints of LPBoost, a new algorithm was proposed. The experimental results show that our algorithm can achieve both better performance and less generalization error compared to some representative boosting algorithm...|$|R
30|$|The IAA amount (ng) per <b>sample</b> <b>weight</b> (g) was {{affected}} by the increase in <b>sample</b> <b>weight</b> during xylem formation [17]. Therefore, the IAA amount of the cambial-region tissues was shown as the IAA amount (ng) per cambium area (L × T cm 2) (ng/cm 2). LC/MS/MS analysis and LC/MS analysis were used for juvenile and mature tree samples, respectively.|$|R
30|$|Standard {{errors are}} {{clustered}} by survey strata. <b>Sample</b> <b>weights</b> {{are used as}} appropriate.|$|R
25|$|The {{bottom ash}} residue {{remaining}} after combustion {{has been shown}} to be a non-hazardous solid waste that can be safely put into landfills or recycled as construction <b>aggregate.</b> <b>Samples</b> are tested for ecotoxic metals.|$|R
5000|$|If the size, mean, and {{standard}} deviation of two overlapping samples are known for the samples {{as well as their}} intersection, then the standard deviation of the <b>aggregated</b> <b>sample</b> can still be calculated. In general, ...|$|R
40|$|Empirical Bayes and Bayes {{hierarchical}} {{models have}} been used extensively for small area estimation. However, the <b>sampling</b> <b>weights</b> that are required to reflect complex surveys are rarely considered in these models. In this paper, we develop a method to incorporate the <b>sampling</b> <b>weights</b> for binary data when estimating, for example, small area proportions or predicting small area counts. We consider empirical Bayes beta-binomial models, and normal hierarchical models. The latter may include spatial random effects, with computation carried out using the integrated nested Laplace approximation, which is fast. A simulation study is presented, to demonstrate {{the performance of the}} proposed approaches, and to compare results from models with and without the <b>sampling</b> <b>weights.</b> The results show that estimation mean squared error can be greatly reduced using the proposed models, when compared with more standard approaches. Bias reduction occurs through the incorporation of <b>sampling</b> <b>weights,</b> with variance reduction being achieved through hierarchical smoothing. We also analyze data taken from th...|$|R
40|$|The two {{fundamental}} approaches {{used to analyze}} survey data, design- and model-based, differ in how they incorporate complexities of the sampling design, such as stratification, clustering and/or unequal probabilities of selection, into the survey analysis. The design-based analysis uses the sampling design as the sole source of the variability, which necessitates the use of survey <b>sampling</b> <b>weights.</b> Model-based analysis includes a model which generated the data {{in addition to the}} sampling design, which makes the role of the <b>sampling</b> <b>weights</b> questionable. The goal of this dissertation is to investigate the use of <b>sampling</b> <b>weights</b> in model-based analysis, and to that end, the proposed work has three major components. The first component investigates two current proposals for incorporating <b>sampling</b> <b>weights</b> to robustly estimate mixed-effects models in the presence of model mis-specification and/or informative sampling (Korn and Graubard, 2003; Pfeffermann et al., 1998), comparing their advantages and disadvantages in various situations. The second component addresses the role of <b>sampling</b> <b>weights</b> when the survey design was not formulated according to particular statistical model of substantive interest, and will consider models other than mixed-effects models to see how the work generalizes across model-based techniques. This component will consider using estimating equation methods (Binder and Patak, 1994) as a bridge between model-based and design-base...|$|R
3000|$|... 5 The {{estimates}} are based throughout on equations with observations weighted by the CPS <b>sampling</b> <b>weights.</b>|$|R
30|$|The {{value of}} <b>sample</b> <b>weights</b> {{is equal to}} 0 or 1, and value 1 denotes that the {{corresponding}} sample can satisfy with the filtering condition. When the number of <b>sample</b> <b>weights</b> reaches to N or the maximum generation G, the evolutionary algorithm terminates. Finally, the estimation of node’s localization {{can be obtained by}} using the sampled nodes being selected optimally from the differential evolution algorithm.|$|R
30|$|Firstly, varying {{selection}} {{probabilities of}} programs and individuals make the use of <b>sampling</b> <b>weights</b> absolutely critical {{in order to achieve}} unbiased parameter estimates (e.g., correlation coefficients)l. But the graphs in all preceding figures in this paper display only the relationships observed in the sample. When making inferences about the population, we have to use <b>sampling</b> <b>weights.</b> As a matter of fact, the data points in the graphs may have different weights, or, in other words, they may contribute to the analysis with different magnitudes. This is true for both individual and aggregated data. Note, though, that we took the <b>sampling</b> <b>weights</b> into account for the computation of the correlation coefficients presented throughout the whole paper.|$|R
30|$|The {{selected}} personal, environmental, {{and behavioral}} measures were first {{entered into a}} logistic regression analysis to determine how well they could differentiate between individuals working in STEMM fields and non-STEMM fields overall. Collinearity diagnostics showed no issues among the predictor and control variables. All logistic regression models were conducted using the F 4 PNLWT <b>sampling</b> <b>weight</b> and the complex sampling design options (svy commands) within STATA 12. This <b>sampling</b> <b>weight</b> is for the fourth follow-up complete panel weight for respondents at all five NELS: 88 data collection points. Using these <b>sampling</b> <b>weights</b> makes {{the findings of this}} study generalizable to a nationally representative sample of eighth graders in the spring of 1988.|$|R
3000|$|... percentile. Also, all {{regressions}} are weighted by multiplication of <b>sampling</b> <b>weight</b> {{and number}} of total hours worked.|$|R
40|$|This {{paper is}} {{concerned}} with the identification of influential observations when we analyze survey data using a linear regression estimator involving survey weights. Based on conventional OLS diagnostic approaches, adapted statistics are proposed and justified to deal with the <b>sampling</b> <b>weights</b> in survey data. Using a sample from NHANES data, a comparison will be made between the diagnostics with and without <b>sampling</b> <b>weights</b> for some types of diagnostic statistics...|$|R
40|$|AbstractAlthough {{there have}} been many {{researches}} on cluster analysis considering feature (or variable) weights, little effort has been made regarding <b>sample</b> <b>weights</b> in clustering. In practice, not every sample in a data set has the same importance in cluster analysis. Therefore, it is interesting to obtain the proper <b>sample</b> <b>weights</b> for clustering a data set. In this paper, we consider a probability distribution over a data set to represent its <b>sample</b> <b>weights.</b> We then apply the maximum entropy principle to automatically compute these <b>sample</b> <b>weights</b> for clustering. Such method can generate the sample-weighted versions of most clustering algorithms, such as k-means, fuzzy c-means (FCM) and expectation & maximization (EM), etc. The proposed sample-weighted clustering algorithms will be robust for data sets with noise and outliers. Furthermore, we also analyze the convergence properties of the proposed algorithms. This study also uses some numerical data and real data sets for demonstration and comparison. Experimental results and comparisons actually demonstrate that the proposed sample-weighted clustering algorithms are effective and robust clustering methods...|$|R
40|$|Abstract. An {{algorithm}} for arbitrary polygonal aggregate {{generation is}} proposed based on secondary development of ANSYS in this paper. It is established {{on the basis}} of circular aggregate model, and the central angle is the control parameter to generate poristic polygon as the coarse aggregate of concrete. The concrete numerical samples with first gradation of aggregate and two gradation of aggregate are generated. The aggregate fraction of polygon sample is lower about 20 % than the original circular <b>aggregate</b> <b>sample</b> in the statistical sense. The results show that the proposed method can simulate gravel aggregate appropriately as long as the central angle and the aggregate percentage of original circular <b>aggregate</b> <b>sample</b> is reasonable controlled...|$|R
40|$|The {{purpose of}} this study is to {{investigate}} the mechanism of freezing and thawing deterioration in　concrete. Concrete　specimens　having　coarse　<b>aggregate</b>　<b>samples</b>　or steel bars were used for this purpose. 　　The main conclusions were as follows :　 1 ）The interval changes of　the　coarse <b>aggregate</b> <b>samples</b> increased with the increase of the diameter of the aggregates by freezing and thawing action. 2 ）The bond cracks between mortar and horizontal bars occured more easily as compared with the vertical bars by the freeze-thaw action. It was found that mortar had many air voids as compared with concrete of the same water-cement ratio, from the microscopic determination of air-void content in hardened concrete and mortar...|$|R
40|$|The Puget Sound Transportation Panel (PSTP) is {{a survey}} that {{contains}} sampling stages which lessen the sample's representativeness of the Puget Sound region. This paper presents {{an analysis of}} survey participation and a method for <b>sample</b> <b>weight</b> creation when systematic self-selection in survey participation can be detected and accounted for. The method uses probability of participation models for selected stages of the survey to first identify determinants of participation and then create <b>sample</b> <b>weights.</b> A variety of weight schemes are thus derived and used to correct for systematic self-selection in panel participation. The performance of these <b>sample</b> <b>weights</b> is tested using as a benchmark sample the Public Use Microdata Sample (PUMS) from the census of 1990 in the U. S. ...|$|R
3000|$|... [*]=[*]Δm/(S[*]⋅[*]τ), where Δm[*]− {{the loss}} of the <b>sample</b> <b>weight,</b> g; S[*]− the sample area, m 2; τ[*]− {{exposure}} time, h).|$|R
40|$|Abstract. This paper {{investigates the}} <b>sample</b> <b>weighting</b> effect on Genetic Parallel Programming (GPP) that evolves {{parallel}} programs {{to solve the}} training samples captured directly from a real-world system. The distribution of these samples can be extremely biased. Standard GPP assigns equal <b>weights</b> to all <b>samples.</b> It slows down evolution because crowded regions of samples dominate the fitness evaluation and cause premature convergence. This paper compares the performance of four <b>sample</b> <b>weighting</b> (SW) methods, namely, Equa...|$|R
30|$|The complex {{survey design}} and <b>sampling</b> <b>weights</b> have been {{accounted}} for in the estimations of the parameters in the regression analysis.|$|R
3000|$|..., at {{the country}} level. All {{regressions}} also include <b>sample</b> <b>weights</b> which ensure that the data are representative {{at the country}} level.|$|R
30|$|Once the {{sampling}} box {{and a certain}} number of initial samples are acquired, the proposed differential evolution algorithm will be executed, which uses the <b>sample</b> <b>weight</b> as objective function. Since the observation results from the normal nodes only involve anchor nodes, the <b>sample</b> <b>weight</b> is equal to 0 or 1. Next, the derived <b>sample</b> <b>weight</b> is equal to 1 and it can be remained in the next generation. Otherwise, the parents’ sample can only reserve in the next generation. After several generations being produced, plenty of samples can be satisfied with the filtering conditions, most of which is close to the actual position of the node. As can be seen from Fig.  1, compared with the initial samples, the samples of subsequent generation with differential evolution are closer to the actual location of the node.|$|R
40|$|Abstract: The Grade of Membership (GoM) {{model is}} a {{hierarchical}} mixed-membership model used to characterize underlying latent classes based on categorical data. When using GoM models to analyze survey data, the sampling design needs to be appropriately modeled. Linear mixed-effect models (LME’s) easily model the stratification and clustering in sampling designs. This paper introduces a modification of the GoM model to include a polytomous logistic mixed-effects regression prior, designed to take sampling design induced dependencies into account. In addition, there is a debate {{regarding the use of}} <b>sampling</b> <b>weights</b> in model based analyses. I developed a new type of weighting, weighting based on the estimated parameter, to incorporate the <b>sampling</b> <b>weights</b> in the updated GoM model. Finally, simulation studies demonstrate the effect of the <b>sampling</b> <b>weights</b> under different levels of informative sampling...|$|R
30|$|Mini-slump {{and channel}} flow of mortar showed {{decreased}} flowing distance and reaching time with smaller fine aggregate grains. The workability change {{according to the}} dimension of aggregates {{can be related to}} the relationship between viscosity and the mean size of the fine <b>aggregate</b> <b>sample.</b>|$|R
