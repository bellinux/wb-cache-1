948|2860|Public
5|$|The team used Unreal Engine 2.5 {{to build}} and test prototypes of the {{real-time}} strategy elements, allowing the designers and gameplay programmers to commence work while another team focused on creating a new game engine. Having completed the multiplayer stage battle portion of the game first, Double Fine found it easy to gradually introduce the player to its more advanced aspects during the single-player campaign. The game-world's large size and varied content necessitated a game engine with streaming capabilities, allowing the game to seamlessly load and unload content as needed — this was also something the team had no prior experience with. Double Fine developed several in-house tools to help streamline the content-creation process for the game's world: an <b>automated</b> <b>testing</b> bot, RoBert (so named {{after one of the}} test engineers), was created to put daily builds of the game through continuous and rigorous testing, automatically reporting any errors to developers, while the Multi-User-Editor allowed the game's artists to simultaneously work on the game-world without fear of overwriting each other's work. The team ran into content management issues late in the game's development as more of the game's assets neared completion. Within the span of a few months the combined asset size tripled, endangering the game's ability to fit on a DVD and causing performance problems throughout the company's development systems. With the help of the engineering team, they were eventually able to overcome the performance issues and re-optimize the content for space.|$|E
25|$|The {{core system}} {{packages}} receive <b>automated</b> <b>testing</b> via openQA. When <b>automated</b> <b>testing</b> is completed and the repo is in a consistent state, the repo is synced to the download mirrors and published as openSUSE Tumbleweed, which many developers and hackers from the openSUSE Project use {{as their primary}} operating system.|$|E
25|$|Chromium {{snapshots}} {{are built}} automatically {{several times a}} day by Buildbot Buildslaves and made available as binary code releases. Once a snapshot has been built, it is placed in a directory in the chromium-browser-snapshots root directory and it is automatically tested. If the snapshot passes the <b>automated</b> <b>testing,</b> it is placed in a directory in the chromium-browser-continuous root directory.|$|E
5000|$|... <b>automated</b> <b>test</b> {{framework}} - Selenium-based library includes <b>automated</b> <b>test</b> {{framework that}} can be adopted to create application tests set. Effi has built-in mechanism that automatically generates primitives for <b>automated</b> <b>test</b> library.|$|R
40|$|In the {{development}} of test methods for solid dosage forms, manual test procedures for assay and content uniformity often precede {{the development}} of <b>automated</b> <b>test</b> procedures. Since the mode of extraction for <b>automated</b> <b>test</b> methods is often slightly {{different from that of}} the manual test method, additional validation of an <b>automated</b> <b>test</b> method is usually required. In addition to compliance with validation guidelines, developers of <b>automated</b> <b>test</b> methods are often asked to demonstrate equivalence between the manual and <b>automated</b> <b>test</b> methods. There are problems associated with using the traditional zero-difference hypothesis tests (such as the Student’s t-test) for demonstrating equivalence. The use of the Westlake Interval and Schuirmann’s Two Onesided test as more rigorous methods of demonstrating equivalence is discussed...|$|R
40|$|In this master thesis the <b>automated</b> <b>tests</b> {{generation}} for XML WEB {{services by}} using WSDL files is presented. First section describes a research of algorithms {{and ways to}} generate <b>automated</b> <b>test</b> for XML WEB services. For <b>automated</b> <b>tests</b> generation plug-in for Visual Studio development tool is created. Plug-in takes web service specification analyses and shows WEB service structure in tree. Users by using analyzed data user can easily enter testing data by using developed tool and generate <b>automated</b> unit <b>tests.</b> Also system let user to enter response time and generate performance tests. Created plug-in requirements, functional and non-functional specification, architecture. In investigation section is described developed plug-in investigation. In this section were investigate the working efficiency of tool by doing mutation <b>testing</b> for generated <b>automated</b> <b>tests...</b>|$|R
25|$|Visual Studio Application Lifecycle Management (ALM) is a {{collection}} of integrated software development tools developed by Microsoft. These tools currently consist of the IDE (Visual Studio 2015 Community and greater editions), server (Team Foundation Server), and cloud services (Visual Studio Team Services). Visual Studio ALM supports team-based development and collaboration, Agile project management, DevOps, source control, packaging, continuous development, <b>automated</b> <b>testing,</b> release management, continuous delivery, and reporting tools for apps and services.|$|E
25|$|A {{number of}} {{security}} flaws affecting IE originated {{not in the}} browser itself, but ActiveX-based add-ons used by it. Because the add-ons have the same privilege as IE, the flaws can be as critical as browser flaws. This {{has led to the}} ActiveX-based architecture being criticized for being fault-prone. By 2005, some experts maintained that the dangers of ActiveX have been overstated and there were safeguards in place. In 2006, new techniques using <b>automated</b> <b>testing</b> found more than a hundred vulnerabilities in standard Microsoft ActiveX components. Security features introduced in Internet Explorer 7 mitigated some of these vulnerabilities.|$|E
25|$|Semantic {{networks}} {{were also used}} to devise originality scores that yielded significant correlations with socio-personal measures. Most recently, an NSF-funded team of researchers led by James C. Kaufman and Mark A. Runco combined expertise in creativity research, natural language processing, computational linguistics, and statistical data analysis to devise a scalable system for computerized <b>automated</b> <b>testing</b> (SparcIt Creativity Index Testing system). This system enabled automated scoring of DT tests that is reliable, objective, and scalable, thus addressing most of the issues of DT tests that had been found and reported. The resultant computer system was able to achieve a correlation of 0.73 to human graders.|$|E
40|$|Abstract- Although several {{approaches}} for <b>automated</b> <b>test</b> case generation {{have been proposed}} {{over the last few}} years, <b>automated</b> <b>test</b> case generation for object oriented application based on their behavior is still in an infant stage. This thesis proposed a new framework for <b>automated</b> <b>test</b> case generation from UML diagrams for object oriented applications based on the behavior. This thesis implements this framework with the development of a tool integrates all types of <b>automated</b> <b>test</b> case generation from four UML diagrams (Class Diagram, Sequence diagram and State-chart Diagram and Use case Diagram) in an object oriented application. Parsing the Petal files to generate the collaborative Test cases from these UML Diagrams using Pattern Discovery and Information Retrieval is discussed...|$|R
50|$|This {{technology}} reduces {{time and}} effort that testers spend on script maintenance and allows writing <b>automated</b> <b>tests</b> from unstable, lacking or partial specifications. It also enables testers to <b>automate</b> <b>tests</b> resilient to frequent application user interface changes, avoiding continuous reworking of the scripts.|$|R
5000|$|Delta Debugging a {{technique}} of <b>automating</b> <b>test</b> case simplification.|$|R
50|$|UIA {{can also}} be useful as a {{framework}} for programmatic access in <b>automated</b> <b>testing</b> scenarios. In addition to providing more refined solutions for accessibility, it is also specifically designed to provide robust functionality for <b>automated</b> <b>testing.</b>|$|E
5000|$|The {{core system}} {{packages}} receive <b>automated</b> <b>testing</b> via openQA. When <b>automated</b> <b>testing</b> is completed and the repo is in a consistent state, the repo is synced to the download mirrors and published as openSUSE Tumbleweed, which many developers and hackers from the openSUSE Project use {{as their primary}} operating system.|$|E
50|$|Test & MeasurementSemtech {{supplies}} {{products and}} technology to manufacturers of <b>automated</b> <b>testing</b> equipment. They offer pin electronic solutions consisting of driver/comparator/loads, PMUs, DACs, deskews, signal and clock distribution, power, and protection products. And they {{use a variety of}} process/design sources to offer products which support a wide range of <b>automated</b> <b>testing</b> equipment.|$|E
50|$|TestableEmailer: Enables you {{to write}} <b>automated</b> <b>tests</b> for {{emailing}} functionality.|$|R
40|$|Testing is {{the process}} to check the program with the aim to detect errors. Software testing is an {{expensive}} and challenging process, typically consuming at least 50 % of the total development cost and 35 % of total development time. The critical step of software <b>testing</b> is <b>automated</b> <b>test</b> data generation. <b>Automated</b> <b>test</b> data generation scheme generate optimum set of test data automatically {{on the basis of}} test data adequacy criteria. The goal of this contribution is to summarize the major techniques in recognizing the <b>automated</b> <b>test</b> data generation. The main objective {{of this paper is to}} look into the current research in the <b>automated</b> <b>test</b> data generation, various metaheuristics techniques (ACO, PSO, GA, SA etc.) and hybridization of these metaheuristics techniques (ACSGA, GAPSO etc.) all these topics have been discussed so far to mitigate the errors in the software...|$|R
40|$|This {{paper offers}} an {{alternative}} to the typical <b>automated</b> <b>test</b> scripting method of ‘record and playback now and enhance the automation environment later’. It explores a regression automation system design for testing Internet applications through the GUI, along with scripting techniques to enhance the scalability and flexibility of an <b>automated</b> <b>test</b> suite. This paper will present a basic structure for an <b>automated</b> <b>test</b> environment, and will expand on each of the items found in that structure. Web testing levels will be laid out, along with a basic approach to designing test scripts based on those web-testing levels...|$|R
5000|$|A {{software}} framework that provides <b>automated</b> <b>testing</b> of all proposed changes ...|$|E
5000|$|An <b>automated</b> <b>testing</b> harness {{to connect}} to all the leading testing tools ...|$|E
50|$|The ANSTI {{machine is}} used for <b>automated</b> <b>testing</b> of {{underwater}} breathing apparatus.|$|E
5000|$|Rakefile {{is used by}} Rake to <b>automate</b> <b>tests</b> and {{generate}} code.|$|R
2500|$|Delta Debugging a {{technique}} of <b>automating</b> <b>test</b> case simplification., Morgan Kaufmann, 2005.|$|R
50|$|Each module {{contains}} functionality {{for creating}} <b>automated</b> <b>tests</b> on that specified platform.|$|R
5000|$|Security Content Automation Protocol [...] - [...] <b>automated</b> <b>testing</b> for {{security}} compliance ...|$|E
5000|$|... #Subtitle level 3: Abstraction of {{application}} layers {{as applied to}} <b>automated</b> <b>testing</b> ...|$|E
5000|$|Travis CI based {{continuous}} integration {{for both}} build, install and <b>automated</b> <b>testing</b> ...|$|E
5000|$|Various {{changes to}} the <b>automated</b> <b>tests</b> {{provided}} by the MySQL community releases ...|$|R
5000|$|This API {{also allows}} <b>automated</b> <b>test</b> scripts to {{interact}} with the UI.|$|R
50|$|AscentialTest is an {{enterprise}} level Test Management System that encompasses Test Planning, Development, Data Management, Execution and Defect Tracking, developed by Zeenyx Software. Users build <b>automated</b> <b>test</b> steps by interacting with graphical {{representations of the}} application under <b>test.</b> Manual and <b>automated</b> <b>tests</b> are created by dragging and dropping reusable test steps in a visual test editor.|$|R
50|$|The group {{includes}} the <b>automated</b> <b>testing</b> system called LAVA (Linaro Automated Validation Architecture) that Linaro developed. LAVA is for <b>automated</b> <b>testing</b> {{of the open}} source components {{that are used in}} the major Linux-based software platforms. A lab running LAVA and a wide variety of ARM hardware is run for the use of Linaro and member company engineers.|$|E
5000|$|<b>Automated</b> <b>Testing</b> tool {{actions to}} {{automate}} tests {{as part of}} a build process ...|$|E
5000|$|<b>Automated</b> <b>testing</b> tools (examples: Test scripts) For {{executing}} tests {{after each}} daily build.|$|E
40|$|This {{technical}} report presents a study about software tools and approaches for testing web service compositions. Our goals consist on understanding the current scenario of Verification and Validation (V&V) activities (focusing on <b>automated</b> <b>tests)</b> in the SOA context. We also present a prototype we developed to illustrate {{different types of}} <b>automated</b> <b>test</b> case scripts for testing web service choreographies...|$|R
50|$|AAI also {{provides}} functional <b>automated</b> <b>test</b> equipment for satellite, electronic and other systems.|$|R
5000|$|... #Caption: The UltraFLEX, a {{state-of-the-art}} <b>automated</b> <b>test</b> equipment designed and manufactured by Teradyne.|$|R
