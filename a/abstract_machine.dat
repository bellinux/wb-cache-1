1252|1485|Public
25|$|GraphTalk is a {{proprietary}} implementation of Warren's <b>Abstract</b> <b>Machine,</b> with additional object-oriented properties.|$|E
25|$|For efficiency, Prolog code is {{typically}} compiled to <b>abstract</b> <b>machine</b> code, often {{influenced by the}} register-based Warren <b>Abstract</b> <b>Machine</b> (WAM) instruction set. Some implementations employ abstract interpretation to derive type and mode information of predicates at compile time, or compile to real machine code for high performance. Devising efficient implementation methods for Prolog code is a field of active research in the logic programming community, and various other execution methods are employed in some implementations. These include clause binarization and stack-based virtual machines.|$|E
25|$|P is the {{smallest}} time-complexity class on a deterministic machine which is robust in terms of machine model changes. (For example, a change from a single-tape Turing machine to a multi-tape machine {{can lead to a}} quadratic speedup, but any algorithm that runs in polynomial time under one model also does so on the other.) Any given <b>abstract</b> <b>machine</b> will have a complexity class corresponding to the problems which can be solved in polynomial time on that machine.|$|E
40|$|We study <b>abstract</b> <b>machines</b> as a {{perspective}} {{from which to}} better approach the development of complex systems. We believe that <b>abstract</b> <b>machines</b> provide a form of modularity that has been largely under-appreciated, and {{that has the potential}} to yield varied and substantial benets. An important notion in exploring the interaction of <b>abstract</b> <b>machines</b> is one of renement of one machine by another, which provides the ability for processes, threads, programs, or even single instructions from several <b>abstract</b> <b>machines</b> to share processors and data. ...|$|R
40|$|We {{present an}} extensive, {{annotated}} bibliography of the <b>abstract</b> <b>machines</b> designed {{for each of}} the main programming paradigms (imperative, object oriented, functional, logic and concurrent). We conclude that whilst a large number of efficient <b>abstract</b> <b>machines</b> have been designed for particular language implementations, relatively little work has been done to design <b>abstract</b> <b>machines</b> in a systematic fashion...|$|R
40|$|Living {{cells are}} {{extremely}} well-organized autonomous systems, consisting of discrete interacting components. Key to understanding and modelling their behavior is modelling their system organization, {{which can be}} described as a collection of distinct but interconnected <b>abstract</b> <b>machines.</b> Biologists have invented a number of notations attempting to describe, abstractly, these <b>abstract</b> <b>machines</b> and the processes that they implement. Systems biology aims to understand how these <b>abstract</b> <b>machines</b> work, separately and together...|$|R
25|$|A {{deterministic}} Turing {{machine is}} the most basic Turing machine, which uses a fixed set of rules to determine its future actions. A probabilistic Turing machine is a deterministic Turing machine with an extra supply of random bits. The ability to make probabilistic decisions often helps algorithms solve problems more efficiently. Algorithms that use random bits are called randomized algorithms. A non-deterministic Turing machine is a deterministic Turing machine with an added feature of non-determinism, which allows a Turing machine to have multiple possible future actions from a given state. One way to view non-determinism is that the Turing machine branches into many possible computational paths at each step, and if it solves the problem {{in any of these}} branches, it is said to have solved the problem. Clearly, this model is not meant to be a physically realizable model, it is just a theoretically interesting <b>abstract</b> <b>machine</b> that gives rise to particularly interesting complexity classes. For examples, see non-deterministic algorithm.|$|E
2500|$|Krivine machine - A <b>abstract</b> <b>machine</b> to {{interpret}} call-by-name in lambda-calculus ...|$|E
2500|$|Categorical <b>abstract</b> <b>machine</b> – A {{model of}} {{computation}} applicable to lambda calculus ...|$|E
40|$|Colloque avec actes et comité de lecture. The paper {{introduces}} a new {{use for the}} B method {{as a means of}} specifying telecommunication services with the help of <b>abstract</b> <b>machines</b> and, consequently, it defines a formal framework for studying the feature interaction problem. An interaction is defined as a violation of an invariant and is detected when combining two or more <b>abstract</b> <b>machines.</b> The current B method is extended to allow the composition of <b>abstract</b> <b>machines.</b> The B method is supported by sofware that helps the specifier of services and features. We have not only modelled services within the B technology, but we have also extended the possibilities of B through the composition of <b>abstract</b> <b>machines...</b>|$|R
5000|$|The {{diagrammatic}} component: {{the study}} of <b>abstract</b> <b>machines,</b> {{from the standpoint of}} semiotically unformed matters in relation to physically unformed matters. Making the diagram of the <b>abstract</b> <b>machines</b> that are in play in each case, either as potentialities or as effective emergences.|$|R
40|$|One {{method for}} {{producing}} verified implementations of programming languages is to formally derive them from <b>abstract</b> <b>machines.</b> Tail-recursive <b>abstract</b> <b>machines</b> provide e#cient support for iterative processes via the ordinary procedure call mechanism. This document {{argues that the}} use of tail-recursive <b>abstract</b> <b>machines</b> incurs only a small increase in theorem-proving burden when compared with what is required when using ordinary <b>abstract</b> <b>machines.</b> The position is supported by comparing correctness proofs performed using the BoyerMoore theorem prover. A by-product of this e#ort is a syntactic criterion based on tail contexts for identifying which procedure calls must be implemented as tail calls. The concept of tail contexts was used in the latest Scheme Report, the only language specification known to the author that defines the requirement that its implementations must be tail recursive. Keywords: tail recursion, tail call, SECD machine, CEK machine, verified implementati [...] ...|$|R
2500|$|A Turing {{machine is}} a {{mathematical}} model of computation that defines an <b>abstract</b> <b>machine</b> ...|$|E
2500|$|Donald Knuth (1968), The Art of Computer Programming, Second Edition 1973, Addison-Wesley, Reading, Massachusetts. Cf pages 462-463 {{where he}} defines [...] "a {{new kind of}} <b>abstract</b> <b>machine</b> or 'automaton' which deals with linked structures." ...|$|E
2500|$|Repeated {{applications}} of the Collatz function can be represented as an <b>abstract</b> <b>machine</b> that handles strings of bits. [...] The machine will perform the following three steps on any odd number until only one [...] "1" [...] remains: ...|$|E
40|$|We {{study the}} {{connections}} between different forms of operational semantics for functional programming languages and we present systematic methods of interderiving reduction semantics, <b>abstract</b> <b>machines</b> and higher-order evaluators. We first consider two methods based on program transformations: a syntactic correspondence relating reduction semantics and <b>abstract</b> <b>machines,</b> and a functional correspondence relating <b>abstract</b> <b>machines</b> and higher-order evaluators. We show that {{an extension of the}} syntactic correspondence provides a systematic and uniform derivation method connecting calculi of explicit substitutions and environment machines. In particular, we show that canonical environment-based <b>abstract</b> <b>machines</b> for evaluation in the lambda calculus, including the Krivine machine for call by name and the CEK machine for call by value, can be systematically derived from a calculus of explicit substitutions, given a reduction strategy such as normal order or applicative order. Furthermore, we show that the syntactic correspondence applies to language...|$|R
40|$|This {{document}} {{illustrates how}} functional implementations of for-mal semantics (structural operational semantics, reduction seman-tics, small-step and big-step <b>abstract</b> <b>machines,</b> natural semantics, and denotational semantics) {{can be transformed}} into each other. These transformations were foreshadowed by Reynolds in Def-initional Interpreters for Higher-Order Programming Languages for functional implementations of denotational semantics, natural semantics, and big-step <b>abstract</b> <b>machines</b> using closure conver-sion, CPS transformation, and defunctionalization. Over the last few years, the author and his students have further observed that machines are related using fusion by xed-point promotion and that functional implementations of reduction semantics and of small-step <b>abstract</b> <b>machines</b> are related using refocusing and transitio...|$|R
30|$|The B {{method is}} based on the notion of <b>abstract</b> <b>machines.</b> These <b>abstract</b> <b>machines</b> can be {{associated}} to imperative programing, which describes the operations in terms of sequences of elementary instructions executed to change the program state. Each machine declares its own variables and operations and variables can only be changed by the machine’s operations.|$|R
2500|$|A finite-state machine (FSM) or finite-state {{automaton}} (FSA, plural: automata), finite automaton, {{or simply a}} state machine, is a mathematical model of computation. [...] It is an <b>abstract</b> <b>machine</b> that can be in exactly one of {{a finite number of}} states at any given time. [...] The FSM can change from one state to another in response to some external inputs; the change from one state to another is called a transition. An FSM is defined by a list of its states, its initial state, and the conditions for each transition.|$|E
2500|$|For a good {{treatment}} of the counter machine see Minsky (1967) Chapter 11 [...] "Models similar to Digital Computers"—he calls the counter machine a [...] "program computer". A recent overview is found at van Emde Boas (1990). A recent {{treatment of}} the Minsky (1961)/Lambek (1961) model can be found Boolos-Burgess-Jeffrey (2002); they reincarnate Lambek's [...] "abacus model" [...] to demonstrate equivalence of Turing machines and partial recursive functions, and they provide a graduate-level introduction to both <b>abstract</b> <b>machine</b> models (counter- and Turing-) and the mathematics of recursion theory. Beginning with the first edition Boolos-Burgess (1970) this model appeared with virtually the same treatment.|$|E
2500|$|Note †: The {{unbounded}} μ operator {{will continue}} this attempt-to-match process ad infinitum {{or until a}} match occurs. Thus the [...] "y" [...] register must be unbounded -- it {{must be able to}} [...] "hold" [...] a number of arbitrary size. Unlike a [...] "real" [...] computer model, <b>abstract</b> <b>machine</b> models allow this. In the case of a bounded μ operator, a lower-bounded μ operator would start with the contents of y set to a number other than zero. An upper-bounded μ operator would require an additional register [...] "ub" [...] to contain the number that represents the upper bound plus an additional comparison operation; an algorithm could provide for both lower- and upper bounds.|$|E
5000|$|<b>Abstract</b> <b>machines</b> for logic {{programming}} languages. These {{are based on}} predicate calculus.|$|R
40|$|It is {{well-known}} that many environment-based <b>abstract</b> <b>machines</b> {{can be seen}} as strategies in lambda calculi with explicit substitutions (ES). Recently, graphical syntaxes and linear logic led to the linear substitution calculus (LSC), a new approach to ES that is halfway between big-step calculi and traditional calculi with ES. This paper studies the relationship between the LSC and environment-based <b>abstract</b> <b>machines.</b> While traditional calculi with ES simulate <b>abstract</b> <b>machines,</b> the LSC rather distills them: some transitions are simulated while others vanish, as they map to a notion of structural congruence. The distillation process unveils that <b>abstract</b> <b>machines</b> in fact implement weak linear head reduction, a notion of evaluation having {{a central role in the}} theory of linear logic. We show that such a pattern applies uniformly in call-by-name, call-by-value, and call-by-need, catching many machines in the literature. We start by distilling the KAM, the CEK, and the ZINC, and then provide simplified versions of the SECD, the lazy KAM, and Sestoft's machine. Along the way we also introduce some new machines with global environments. Moreover, we show that distillation preserves the time complexity of the executions, i. e. the LSC is a complexity-preserving abstraction of <b>abstract</b> <b>machines.</b> Comment: 63 page...|$|R
40|$|Recently {{the topic}} of <b>abstract</b> <b>machines</b> has got a new boost {{by the success of}} the Java Virtual Machine. For many years <b>abstract</b> <b>machines</b> have been {{designed}} for different sorts of languages including imperative, object-oriented, eager functional, lazy functional, constraint and logic languages, as well as hybrid languages. The goal of this workshop is to bring together researchers and developers working on different language paradigms...|$|R
2500|$|The name Prolog {{was chosen}} by Philippe Roussel as an {{abbreviation}} for [...] (French for programming in logic). [...] It was created around 1972 by Alain Colmerauer with Philippe Roussel, based on Robert Kowalski's procedural interpretation of Horn clauses. [...] It was motivated {{in part by the}} desire to reconcile the use of logic as a declarative knowledge representation language with the procedural representation of knowledge that was popular in North America in the late 1960s and early 1970s. [...] According to Robert Kowalski, the first Prolog system was developed in 1972 by Colmerauer and Phillipe Roussel. The first implementations of Prolog were interpreters. However, David H. D. Warren created the Warren <b>Abstract</b> <b>Machine,</b> an early and influential Prolog compiler which came to define the [...] "Edinburgh Prolog" [...] dialect which served {{as the basis for the}} syntax of most modern implementations.|$|E
2500|$|Beyond general {{algorithms}} {{and their}} implementation on an <b>abstract</b> <b>machine,</b> concrete source code level choices {{can make a}} significant difference. For example, on early C compilers, while(1) was slower than for( [...] ;;) for an unconditional loop, because while(1) evaluated 1 and then had a conditional jump which tested if it was true, while for ( [...] ;;) had an unconditional jump [...] Some optimizations (such as this one) can nowadays be performed by optimizing compilers. This depends on the source language, the target machine language, and the compiler, and can be both difficult to understand or predict and changes over time; this is a key place where understanding of compilers and machine code can improve performance. Loop-invariant code motion and return value optimization are examples of optimizations that {{reduce the need for}} auxiliary variables and can even result in faster performance by avoiding round-about optimizations.|$|E
50|$|The ALF {{system was}} {{designed}} to be an efficient implementation of the combination of resolution, narrowing, rewriting, and rejection. ALF programs are compiled into instructions of an <b>abstract</b> <b>machine.</b> The <b>abstract</b> <b>machine</b> is based on the Warren <b>Abstract</b> <b>Machine</b> (WAM) with several extensions to implement narrowing and rewriting. In the current ALF implementation programs of this <b>abstract</b> <b>machine</b> are executed by an emulator written in C.|$|E
40|$|We {{consider}} {{the problem of}} mechanically constructing <b>abstract</b> <b>machines</b> from operational semantics, producing intermediate-level specifications of evaluators guaranteed to be correct {{with respect to the}} operational semantics. We construct these machines by repeatedly applying correctness-preserving transformations to operational semantics until the resulting specifications have the form of <b>abstract</b> <b>machines.</b> Though not automatable in general, this approach to constructing machine implementations can be mechanized, providing machine-verified correctness proofs. As examples we present the transformation of machines that implement such evaluation strategies. We also present extensions to the call-by-value machine for a language containing constructs for recursion, conditionals, concrete data types, and built-in functions. In all cases, the correctness of the derived <b>abstract</b> <b>machines</b> follows from the (generally transparent) correctnes...|$|R
50|$|Examples of {{particular}} <b>abstract</b> <b>machines</b> which are deterministic include the deterministic Turing machine and deterministic finite automaton.|$|R
5000|$|<b>Abstract</b> <b>machines</b> for {{object-oriented}} programming languages. These are basically stack based machines to access data and method of program.|$|R
50|$|An <b>abstract</b> <b>machine</b> {{can also}} {{refer to a}} {{microprocessor}} design which {{has yet to be}} (or is not intended to be) implemented as hardware. An <b>abstract</b> <b>machine</b> implemented as a software simulation, or for which an interpreter exists, is called a virtual machine.|$|E
50|$|In 1983, David H. D. Warren {{designed}} an <b>abstract</b> <b>machine</b> for {{the execution}} of Prolog consisting of a memory architecture and an instruction set. This design {{became known as the}} Warren <b>Abstract</b> <b>Machine</b> (WAM) and has become the de facto standard target for Prolog compilers.|$|E
5000|$|Register machine—generic register-based <b>abstract</b> <b>machine</b> {{computational}} model ...|$|E
40|$|In {{this paper}} we {{describe}} the design rationale of GANIMAM, a web-based system which generates interactive animations of <b>abstract</b> <b>machines</b> from specifications. Common principles of <b>abstract</b> <b>machines</b> come into play at three levels: {{the design of the}} specification language, the choice of graphical annotations to visualize higher-level abstractions {{and the use of the}} system to explore and better understand known and detect new principles. 2000 Elsevier Science B. V. All rights reserved. Keywords: Abstract machines; Software visualization; Animation 1...|$|R
50|$|Automata {{theory is}} the study of <b>abstract</b> <b>machines</b> (or more appropriately, <b>abstract</b> 'mathematical' <b>machines</b> or systems) and the {{computational}} problems that can be solved using these <b>machines.</b> These <b>abstract</b> <b>machines</b> are called automata. Automata comes from the Greek word (Αυτόματα) which means that something is doing something by itself.Automata theory is also closely related to formal language theory, as the automata are often classified by the class of formal languages they are able to recognize. An automaton can be a finite representation of a formal language that may be an infinite set. Automata are used as theoretical models for computing machines, and are used for proofs about computability.|$|R
50|$|Every {{programming}} language requires <b>abstract</b> <b>machines</b> that {{bridge the gap}} between the high level language and the low level of a real machine.|$|R
