115|338|Public
25|$|The {{data from}} the {{different}} sensing technologies can be combined in intelligent ways to determine the traffic state accurately. A Data fusion based approach that utilizes the road side collected <b>acoustic,</b> <b>image</b> and sensor data {{has been shown to}} combine the advantages of the different individual methods.|$|E
5000|$|In the <b>acoustic</b> <b>image</b> and side-view {{diagram of}} the plastic-encapsulated IC to the right, {{ultrasound}} was pulsed through the black mold compound (plastic), and reflected from: ...|$|E
5000|$|Another way of categorizing bass {{equipment}} manufacturers is by {{which part of}} the market they are targeting. While Peavey and Yorkville products are aimed at the generalist mass market, some bass {{equipment manufacturers}}, such as <b>Acoustic</b> <b>Image</b> or Walter Woods make expensive [...] "boutique" [...] equipment that is aimed at a niche market within the professional musician market. <b>Acoustic</b> <b>Image</b> amplifiers and speaker cabinets tend {{to be used by}} professional acoustic folk and jazz musicians, and Walter Woods amplifiers are associated with professional acoustic jazz bass players.|$|E
40|$|<b>Acoustic</b> <b>images</b> {{of silicon}} carbide ceramic disks were {{obtained}} using a precision scanning contact pulse-echo technique. Phase and cross-correlation velocity and attenuation maps {{were used to}} form color images of microstructural variations. These <b>acoustic</b> <b>images</b> reveal microstructural variations not observable with X-radiography...|$|R
40|$|A {{system of}} {{transmission}} raster acoustic microscope with an ultrasound frequency of 450 MHz {{has been designed}} to investigate biological tissues and comparative analysis of their optical and <b>acoustic</b> <b>images.</b> The possibility of obtaining the contrast <b>acoustic</b> <b>images</b> of nonfixed, nonstained biological tissues and viscoelasticity measurements in microscale was demonstrated...|$|R
5000|$|U.S. Coast Guard Facility Indian River Underwater <b>Acoustic</b> <b>Imaging</b> and Shoreline Stabilization, Rehoboth, Delaware ...|$|R
50|$|The <b>acoustic</b> <b>image</b> of the plastic-encapsulated IC {{below was}} made using a 30 MHz {{transducer}} because this frequency {{provides a good}} compromise between penetration and image resolution.|$|E
50|$|The Libra <b>acoustic</b> <b>image</b> system {{provides}} acoustical control by incorporating passive acoustical panels that absorb sound. The {{exterior of the}} panels have works of art created or selected by California photographer Deborah O'Grady.|$|E
50|$|The {{data from}} the {{different}} sensing technologies can be combined in intelligent ways to determine the traffic state accurately. A Data fusion based approach that utilizes the road side collected <b>acoustic,</b> <b>image</b> and sensor data {{has been shown to}} combine the advantages of the different individual methods.|$|E
40|$|This paper proposes {{the use of}} {{a signal}} {{acquisition}} and processing system based on an 8 × 8 planar array of MEMS (Microelectromechanical Systems) microphones to obtain <b>acoustic</b> <b>images</b> of a fan matrix. A 3 × 3 matrix of PC fans has been implemented to perform the study. Some tests to obtain the <b>acoustic</b> <b>images</b> of the individual fans and of the whole matrix have been defined and have been carried out inside an anechoic chamber. The nonstationary signals received by each MEMS microphone and their corresponding spectra have been analyzed, as well as the corresponding <b>acoustic</b> <b>images.</b> The analysis of the acoustic signals spectra reveals the resonance frequency of the individual fans. The obtained results reveal the feasibility of the proposed system to obtained <b>acoustic</b> <b>images</b> of a fan matrix and of its individual fans, in this last case, in order to estimate the real position of the fan inside the matrix...|$|R
40|$|The fault {{diagnosis}} of gearboxes {{was developed for}} some decades. The current diagnosing techniques were mostly based on analyzing the vibration signal of shell especially close to the bearing seat of gearbox. In order to utilize the spatial distribution information of fault signal, the near field acoustic holography (NAH) is employed for the condition monitoring and {{fault diagnosis}} of the gearbox in this presentation. The distribution images of sound pressure {{on the surface of}} gearbox are reconstructed by NAH, and the feature extraction and pattern recognition can be made by image processing techniques. A gearbox is studied in a semi-anechoic chamber to verify the fault diagnosis technique based on NAH. The pitting and partial broken teeth of gears are artificially made respectively as fault statuses, and the differences of <b>acoustic</b> <b>images</b> among normal and fault working states under the idling condition are analyzed. It can be found that the <b>acoustic</b> <b>images</b> of gearbox in three different situations change regularly, and the main sound sources can be recognized from the <b>acoustic</b> <b>images</b> which also contain rich diagnosis information. After feature extraction of the <b>acoustic</b> <b>images,</b> the pattern reorganization technique is employed for diagnosis. The results indicate that this diagnosis procedure based on <b>acoustic</b> <b>images</b> is available and feasible for the gearbox fault diagnosis...|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedThe {{primary goal of}} this research is to test the effectiveness of various image processing techniques applied to <b>acoustic</b> <b>images</b> generated in MATLAB. The simulated <b>acoustic</b> <b>images</b> have the same characteristics as those generated by a computer model of a high resolution imaging sonar. Edge Detection and Segmentation are the two image processing techniques discussed in this study. The two methods tested are {{a modified version of the}} Kalman filtering and median filtering. [URL] United States Nav...|$|R
50|$|Finally, the plastic-encapsulated IC was {{flipped over}} and imaged {{from the back}} side. The return echoes were gated on the depth where the {{backside}} mold compound interfaces with {{the back side of}} the die paddle. The small black dots in the <b>acoustic</b> <b>image</b> above are small voids (trapped bubbles) in the mold compound.|$|E
50|$|Gating {{was then}} changed to include only {{depth of the}} die attach {{material}} that attaches the silicon die to the die paddle. The die, the die paddle, and other features {{above and below the}} die attach depth are ignored. In the resulting <b>acoustic</b> <b>image,</b> shown above slightly magnified, the red areas are voids (defects) in the die attach material.|$|E
5000|$|In {{compositional}} design, pied butcherbird vocalisations {{have been}} the source in the parameters of melody, harmony, rhythm, gesture, contour, dynamic envelope, formal structure, phrase length (and the balance of sound and silence), scales, repetition, <b>acoustic</b> <b>image,</b> programmatic intent, and poetic or psychic inspiration. Their flute-like phrases have been assigned to piano and bass, clarinet and bassoon, xylophone and violin. They have been embedded in a stuffed toy.|$|E
40|$|This paper {{describes}} a voting-based approach for the fast automatic recognition of man-made objects and related attitude estimation in underwater <b>acoustic</b> <b>images</b> generated by forward-looking sonars or acoustic cameras, In general, the continuous analysis of sequences of images {{is a very}} heavy task for human operators and {{this is due to}} the poor quality of <b>acoustic</b> <b>images,</b> Hence, algorithms able to recognize an object on the basis of a priori knowledge of the model and to estimate its attitude with reference to a global coordinate system are very useful to facilitate underwater operations like object manipulation or vehicle navigation, The proposed method is capable of recognizing objects and estimating their two-dimensional attitude by using information coming from boundary segments and their angular relations, It is based on a simple voting approach directly applied to the edge discontinuities of underwater <b>acoustic</b> <b>images,</b> whose quality is usually affected by some undesired effects such as object blurring, speckle noise, and geometrical distortions degrading the edge detection, The voting approach is robust, with respect to these effects, so that good results are obtained even with images of very poor quality, The sequences of simulated and real <b>acoustic</b> <b>images</b> are presented in order to test the validity of the proposed method in terms of average estimation error and computational load...|$|R
40|$|This paper {{proposes a}} {{scalable}} and multi-platform framework for signal acquisition and processing, {{which allows for}} the generation of <b>acoustic</b> <b>images</b> using planar arrays of MEMS (Micro-Electro-Mechanical Systems) microphones with low development and deployment costs. Acoustic characterization of MEMS sensors was performed, and the beam pattern of a module, based on an 8 × 8 planar array and of several clusters of modules, was obtained. A flexible framework, formed by an FPGA, an embedded processor, a computer desktop, and a graphic processing unit, was defined. The processing times of the algorithms used to obtain the <b>acoustic</b> <b>images,</b> including signal processing and wideband beamforming via FFT, were evaluated in each subsystem of the framework. Based on this analysis, three frameworks are proposed, defined by the specific subsystems used and the algorithms shared. Finally, a set of <b>acoustic</b> <b>images</b> obtained from sound reflected from a person are presented {{as a case study}} in the field of biometric identification. These results reveal the feasibility of the proposed system...|$|R
40|$|<b>Acoustic</b> <b>images</b> present {{views of}} {{underwater}} dynamics, even in high depths. With multi-beam echo sounders (SONARs), {{it is possible}} to capture series of 2 D high resolution <b>acoustic</b> <b>images.</b> 3 D reconstruction of the water column and subsequent estimation of fish abundance and fish species identification is highly desirable for planning sustainable fisheries. Main hurdles in analysing <b>acoustic</b> <b>images</b> are the presence of speckle noise and the vast amount of acoustic data. This paper presents a level set formulation for simultaneous fish reconstruction and noise suppression from raw <b>acoustic</b> <b>images.</b> Despite the presence of speckle noise blobs, actual fish intensity values can be distinguished by extremely high values, varying exponentially from the background. Edge detection generally gives excessive false edges that are not reliable. Our approach to reconstruction is based on level set evolution using Mumford-Shah segmentation functional that does not depend on edges in an image. We use the implicit function in conjunction with the image to robustly estimate a threshold for suppressing noise in the image by solving a second differential equation. We provide details of our estimation of suppressing threshold and show its convergence as the evolution proceeds. We also present a GPU based streaming computation of the method using NVIDIA’s CUDA framework to handle large volume data-sets. Our implementation is optimised for memory usage to handle large volumes...|$|R
50|$|One {{application}} of sensor fusion is GPS/INS, where Global Positioning System and {{inertial navigation system}} data is fused using various different methods, e.g. the extended Kalman filter. This is useful, for example, in determining the altitude of an aircraft using low-cost sensors. Another example is using the data fusion approach to determine the traffic state (low traffic, traffic jam, medium flow) using road side collected <b>acoustic,</b> <b>image</b> and sensor data.|$|E
5000|$|Still {{scanning}} {{the top of}} the sample, the gating of the return echoes was then changed to include only the plastic encapsulant (mold compound) above the die. The resulting <b>acoustic</b> <b>image</b> is shown above. It shows the structure of the particle-filled plastic mold compound, as well as the circular mold marks at the top surface of the component. The small white features are voids (trapped bubbles) in the mold compound. (These voids are also visible in the previous image as dark acoustic shadows.) ...|$|E
50|$|A {{pulse of}} {{ultrasound}} from the transducer might travel nanoseconds or microseconds {{to reach an}} internal interface and be reflected back to the transducer. If there are several internal interfaces at different depths, the echoes will arrive at the transducer at different times. Planar acoustic images do not often use all return echoes from all depths to make the visible <b>acoustic</b> <b>image.</b> Instead, a time window is created that accepts only those return echoes from the depth of interest. This process is known as “gating” the return echoes.|$|E
40|$|Abstract- This paper {{describes}} a voting-based approach for the fast automatic recognition of man-made objects and related pose estimation in underwater <b>acoustic</b> <b>images</b> generated by forward looking sonars or acoustic cameras. In general, the continuous analysis of sequences of images {{is a very}} heavy task for human operators and {{this is due to}} the poor quality of <b>acoustic</b> <b>images.</b> Hence, algorithms able to recognize an object on the basis of a-priori knowledge of the model and to estimate its attitude with reference to a global coordinate system, are very useful to facilitate underwater operations like object manipulation or vehicle navigation. The proposed method is capable to recognize objects and to estimate their two-dimensional pose by using information coming from boundary segments and their angular relations. It is based on a simple voting approach directly applied to the edge discontinuities of underwater <b>acoustic</b> <b>images,</b> whose quality is usually affected by some undesired effects such as object blurring, speckle noise, and geometrical distortions degrading the edge detection. The voting approach is robust with respect to these effects, so that good results are obtained even with images of very poor quality. The sequences of simulated and real <b>acoustic</b> <b>images</b> are presented in order to test the validity of the proposed method in terms of average estimation error and computational load. 1 I...|$|R
40|$|We {{present a}} {{hierarchical}} and robust algorithm {{addressing the problem}} of filtering and segmentation of three-dimensional <b>acoustic</b> <b>images.</b> This algorithm {{is based on the}} tensor voting approach - a unified computational framework for the inference of multiple salient structures. Unlike most previous approaches, no models' or prior information of the underwater environment, nor the intensity information of <b>acoustic</b> <b>images</b> is' considered in this' algorithm. Salient structures and outlier noisy points' are directly clustered in two steps according to both the density and the structural information of input data. Our experimental trials' show promising results', very robust despite the low computational complexity...|$|R
40|$|The {{weakest link}} in the {{inspection}} process is the subjective interpretation of data by inspectors. To overcome this troublesome fact computer based analysis systems have been developed. In the field of nondestructive evaluation (NDE) {{there is a large}} class of inspections that can benefit from computer analysis. X-ray images (both film and fluoroscopic) and <b>acoustic</b> <b>images</b> lend themselves to automatic analysis as do the one-dimensional signals associated with ultrasonic, eddy current and acoustic emission testing. Computer analysis can enhance and evaluate subtle details. Flaws can be located and measured, and acceptance decisions made by computer in a consistent and objective manner. This paper describes the interactive, computer-based analysis of real-time x-ray <b>images</b> and <b>acoustic</b> <b>images</b> of graphite/epoxy adhesively bonded structures...|$|R
5000|$|In 1984, Kessler’s group {{completed}} {{development of}} the C-SAM concept instrument [...] which operated in the reflection mode, {{as well as the}} through-transmission (only) mode of the SLAM. Using the same transducer to pulse ultrasound and receive the return echoes meant that the <b>acoustic</b> <b>image</b> could easily be constrained to a depth of interest. This design was the precursor of essentially all of the acoustic microscopes in use today, and was the development that made possible numerous later advances such as cross-sectional acoustic imaging, three-dimensional acoustic imaging, and others.|$|E
5000|$|However, Class D {{amplifiers}} (also called [...] "switching amplifiers" [...] or confusingly, [...] "digital amplifiers") {{are more}} efficient than conventional Class-AB amplifiers, and so are lighter in weight and smaller. The <b>Acoustic</b> <b>Image</b> Focus head, for example, produces 800 watts of power and weighs 2.2 kilograms (about 4 pounds). Class-D amplifiers use MOSFETs (Metal Oxide Semiconductor Field Effect Transistors) rather than 'ordinary' (bipolar) transistors, and generate a pulse-width modulated signal that is filtered before it reaches the speaker. In the 2010s, the availability of Class D amplifiers has enabled amp manufacturers to produce very lightweight and small, yet very powerful amp heads and small, lightweight combo amps.|$|E
50|$|The {{ultrasonic}} frequencies pulsed into samples by the transducers of acoustic microscopes {{range from}} a low of 10 MHz (rarely, 5 MHz) to a high of 400 MHz or more. Across this spectrum of frequencies there is a trade-off of penetration and resolution. Ultrasound at low frequencies such as 10 MHz penetrates deeper into materials than ultrasound at higher frequencies, but the spatial resolution of the <b>acoustic</b> <b>image</b> is less. On the other hand, ultrasound at very high frequencies do not penetrate deeply, but provide acoustic images having very high resolution. The frequency chosen to image a particular sample will depend on the geometry of the part and on the materials involved.|$|E
40|$|Acoustic imaging is {{an active}} {{research}} field that aims to study techniques for the formation and processing of images generated by raw signals acquired by an acoustic system [1]. Our purpose is to present a brief survey concerning the generation and processing of <b>acoustic</b> <b>images</b> for underwater applications [2, 3]...|$|R
40|$|Reviews the {{significance}} of acoustics in environmental design, noting that research on the office environment reveals that acoustics is a primary source of dissatisfaction. Problems of the hearing impaired are discussed, and design suggestions are offered. The significance of <b>acoustic</b> <b>images,</b> memories, and perceptions is also considered. Source type: Electronic(1...|$|R
40|$|Knowledge {{discovery}} {{from large}} <b>acoustic</b> <b>images</b> is a computationally intensive task. The data-mining {{step in the}} knowledge discovery process that involves unsupervised learning (clustering) consumes {{the bulk of the}} computation. We have developed a technique that allows us to partition the data, distribute it to different processors for training, and train a single system to join the results of the independent categorizers. We report preliminary results using this approach for knowledge discovery with large <b>acoustic</b> <b>images</b> having more than 10, 000 training instances. 1. Introduction Knowledge discovery is an iterative process consisting of several steps including selection, preprocessing, transformation, data mining, and interpretation and evaluation [8]. We have worked collaboratively with the scientists at the Naval Oceanographic Office (NAVOCEANO) at the Stennis Space Center to develop a knowledge discovery process for extracting provinces of similar visual texture from a da [...] ...|$|R
5000|$|This kind {{of sound}} {{localization}} technique provides us the real virtual stereo system. It utilizes [...] "smart" [...] manikins, such as KEMAR, to glean signals or use DSP methods {{to simulate the}} transmission process from sources to ears. After amplifying, recording and transmitting, the two channels of received signals will be reproduced through earphones or speakers. This localization approach uses electroacoustic methods to obtain the spatial information of the original sound field by transferring the listener's auditory apparatus to the original sound field. The most considerable advantages of {{it would be that}} its acoustic images are lively and natural. Also, it only needs two independent transmitted signal to reproduce the <b>acoustic</b> <b>image</b> of a 3D system.|$|E
5000|$|A {{small number}} of bass amps {{designed}} for the upright bass have both a 1/4" [...] input for a piezoelectric pickup and an XLR input for a condenser microphone mounted on the bass, with a simple mixer for combining the two signals, as described below. Some <b>Acoustic</b> <b>Image</b> amps have a dual input design. A rare feature on expensive amplifiers (e.g., the EBS TD660) is the provision of phantom power to supply electrical power over the patch cable to bass pickups, effects, a condenser mic (for an upright bass player) or other uses. A {{small number of}} 2010-era amps that have digital modelling features may have an input for a computer (e.g., USB), so that new digital effects and presets can be loaded onto the amp.|$|E
5000|$|... {{reports that}} Japanese {{speakers}} who cannot hear {{the difference between}} [...] and [...] may still learn to produce the difference, presumably through articulatory training in which they learn the correct places and manners of articulation required {{for the production of}} the two sounds. In this sense, they learn to produce [...] and [...] {{in much the same way}} a deaf person would. Although they have only a single <b>acoustic</b> <b>image</b> corresponding to a single phoneme intermediary between [...] and , they can determine they are producing the correct sound based on the tactile sensations of the speech articulators (i.e. tongue, alveolar ridge, etc.) coming into contact with each other without any auditory feedback or confirmation that they are indeed producing the sound correctly.|$|E
50|$|The <b>acoustic</b> <b>images</b> {{shown above}} are all planar images, {{so named because}} they make visible a {{horizontal}} plane within the sample. The acoustic data received in the return echo signals {{can also be used}} to make other types of images, including three-dimensional images, cross-sectional images, and thru-scan images. Some of these types are illustrated in the Photo Gallery.|$|R
40|$|Knowledge {{discovery}} {{from large}} <b>acoustic</b> <b>images</b> is a computationally intensive task. An approach that has proven successful for parallelizing supervised learning algorithms {{has been to}} partition data and distribute it to multiple processors, each running a learning algorithm. Then some sort of voting scheme or tree construction technique is used to combine results of the classifiers in order to predict the class of an instance. Systems built using such an approach {{have proven to be}} effective both in reducing computation time and in yielding better classification results. We have developed a technique for using this approach to parallelize unsupervised learning tasks. The process is more complicated for unsupervised learning, because one must determine a correspondence between classes learned by the different classifiers and determine how to combine the classes. We report preliminary results from using this approach for knowledge discovery with large <b>acoustic</b> <b>images</b> wher [...] ...|$|R
40|$|This paper {{describes}} a system {{designed and built}} at the Marine Physical Laboratory of the Scripps Institution of Oceanography to produce <b>acoustic</b> <b>images</b> of the seafloor on-line with a Sea Beammultibeam echo-sounder. This system uses a stand alone interface between the Sea Beam system and a grey-scale line-scan recorder. The interface is built around a Motorola 68000 microprocessor and has digitizing capabilities. It digitizes the detected echo signals {{from each of the}} 16 preformed beams inside the Sea Beam echo processor as well as the roll information given by the ship 2 ̆ 7 s vertical reference. Theacoustic data are then roll compensated and combined into a port and a starboard time series. These time series are eventually output in digital format to a line-scan recorder which produces the grey scaleacoustic image. Results are discussed for Sea Beam <b>acoustic</b> <b>images</b> of the seafloor and of the Deep Scattering layers...|$|R
