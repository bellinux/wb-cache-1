409|1440|Public
5000|$|Telephones: Basic models, {{models with}} Caller ID and <b>answering</b> <b>systems.</b>|$|E
50|$|Finding {{the right}} answer from {{multiple}} choices can be automated using multiple choice question <b>answering</b> <b>systems.</b>|$|E
5000|$|Within NLP, he has {{published}} papers on combinatory categorial grammar parsing as well as question <b>answering</b> <b>systems.</b> http://www.cs.usyd.edu.au/~james/pubs/ ...|$|E
50|$|TeLQAS (Telecommunication Literature Question <b>Answering</b> <b>System)</b> is an {{experimental}} question <b>answering</b> <b>system</b> developed for <b>answering</b> English {{questions in the}} telecommunications domain.|$|R
40|$|AbstractAgainst {{the lack}} of {{existing}} <b>answering</b> <b>system</b> in terms of intelligence and human-computer interaction, {{on the basis of}} the CBR, proposed a design of intelligent question <b>answering</b> <b>system,</b> and study the key technologies of this program, include the automatic segmentation, questions similarity calculation, improve search efficiency. Experiments show that the program can improve the accuracy and intelligence of <b>answering</b> <b>system,</b> has some practical value...|$|R
30|$|The {{proposed}} framework modules {{have been}} applied to case study on modeling of Question–Answer system for Udutu based e-learning system. (Shrief et al. 2010) developed their threat framework and applied their framework on AI specific question <b>answering</b> <b>system</b> which is different from our question <b>answering</b> <b>system.</b>|$|R
50|$|TimeML was {{conceptualized}} in 2002 {{during the}} TERQAS (Time and Event Recognition for Question <b>Answering</b> <b>Systems)</b> workshops, organized by Professor James Pustejovsky of Brandeis University. The TERQAS Workshops {{set out to}} address the problem of how to enhance natural language question <b>answering</b> <b>systems</b> to answer temporally-based questions about the events and entities in news articles. During these workshops, TimeML version 1.0 was defined, and the TimeBank corpus was created as an illustration.|$|E
50|$|Question {{answering}} heavily {{relies on}} reasoning. There {{are a number}} of question <b>answering</b> <b>systems</b> designed in Prolog, a logic programming language associated with artificial intelligence.|$|E
5000|$|In {{a broader}} definition, voice search include open-domain keyword query on any {{information}} on the Internet, for example in Google Voice Search, Cortana, Siri and Amazon Echo. Given that voice-based systems are interactive, such systems are also called open-domain question <b>answering</b> <b>systems.</b>|$|E
40|$|Abstract Question {{classification}} is play {{important role}} in the question <b>answering</b> <b>system.</b> The results of the question classification find out the quality of the question <b>answering</b> <b>system.</b> In this paper, a question classification algorithm based on SVM and feature, Support Vector Machine model is take to train a classifie...|$|R
40|$|Part 4 : Data Analysis and Information RetrievalInternational audienceIn this paper, {{we develop}} a Vietnamese Question <b>Answering</b> <b>system</b> to <b>answer</b> simple {{questions}} about provisions, processes, procedures, and sanctions in law on enterprises Vietnam. Research {{to build a}} Vietnamese Question <b>Answering</b> <b>system</b> is more difficult than English Question <b>Answering</b> <b>system</b> {{because of lack of}} Vietnamese processing resources and tools, or their results isn’t high. We have utilized available Vietnamese resources, tools and modified some tools (such as Lucene) and algorithms, which worked well in English, applies in Vietnamese. From that, we have proposed a similarity-based model to build a Vietnamese Question <b>Answering</b> <b>system</b> in Vietnam’s legal documents, namely vLawyer system. In experimental section, we achieved promising result, about 70 % precision in legal documents, it proved that our approach is reasonable in legal document domain...|$|R
40|$|In this paper, we {{investigate}} how an accurate question classifier {{contributes to a}} question <b>answering</b> <b>system.</b> We first present a Maximum Entropy (ME) based question classifier which makes use of head word features and their WordNet hypernyms. We show that our question classifier can achieve {{the state of the}} art performance in the standard UIUC question dataset. We then investigate quantitatively the contribution of this question classifier to a feature driven question <b>answering</b> <b>system.</b> With our accurate question classifier and some standard question answer features, our question <b>answering</b> <b>system</b> performs close to {{the state of the art}} using TREC corpus. ...|$|R
50|$|The core to Trip’s {{system is}} the {{identification}} and incorporation of new evidence. The people behind Trip are heavily involved in clinical question <b>answering</b> <b>systems</b> (e.g., NLH Q&A Service). Therefore, if resources are identified that are useful in the Q&A process {{they tend to be}} added to Trip.|$|E
5000|$|UMBEL {{is written}} in the Semantic Web {{languages}} of SKOS and OWL 2. It is a class structure used in Linked Data, along with OpenCyc, YAGO, and the DBpedia ontology. Besides data integration, UMBEL {{has been used to}} aid concept search, concept definitions, query ranking, ontology integration, and ontology consistency checking. It has also been used to build large ontologies [...] and for online question <b>answering</b> <b>systems.</b>|$|E
50|$|The more {{technology}} improves,everyday {{tasks that}} used to be performed by human employees can now be carried out by computer systems. Telephone <b>answering</b> <b>systems</b> replacing live receptionists is one example of such substitution. It is, however, important to understand that often these changes can lead to issues as well as benefits. Losing personal communication with clients, security issues, etc. may have a heavy impact in company value. Such aspects must be considered before, during and after all decisions and implementations for IT management to be successful.|$|E
5000|$|... {{telephone}} (either a manned {{bureau service}} or an automated <b>answering</b> <b>system)</b> ...|$|R
40|$|This paper {{describes}} a question <b>answering</b> <b>system</b> that automatically finds {{answers to questions}} in a large collection of documents. The prototype CNLP question <b>answering</b> <b>system</b> was developed {{for participation in the}} TREC- 9 question <b>answering</b> track. The <b>system</b> uses a two-stage retrieval approach to answer finding based on keyword and named entity matching. Results indicate that the <b>system</b> ranks correct <b>answers</b> high (mostly rank 1), provided that an answer to the question was found. Performance figures and further analyses are included. 1...|$|R
40|$|Question <b>answering</b> <b>system</b> (QAS) {{consists}} of three modules question processing, document processing and answer processing. Question processing is the main module of QAS. If it doesn’t work properly, it causes problem for the whole <b>system.</b> A further <b>answer</b> processing module is a spring up the topic in Question <b>Answering.</b> These <b>systems</b> are often required to rank and validate candidate answers. These modules are finding the exact answer of given query by the user. In this paper, we have discussed a new model for question <b>answering</b> <b>system</b> which is find exact answer and improved their module...|$|R
50|$|Woods built one of {{the first}} natural {{language}} question <b>answering</b> <b>systems</b> (LUNAR) to answer questions about the Apollo 11 moon rocks for the NASA Manned Spacecraft Center while he was at Bolt Beranek and Newman (BBN) in Cambridge, Massachusetts. At BBN, he was a Principal Scientist and manager of the Artificial Intelligence Department in the '70's and early '80's. He was the principal investigator for BBN's early work in natural language processing and knowledge representation and for its first project in continuous speech understanding. Subsequently, he was Chief Scientist for Applied Expert Systems and Principal Technologist for ON Technology, Cambridge start-ups. In 1991, he joined Sun Microsystems Laboratories as a Principal Scientist and Distinguished Engineer, and in 2007, he joined ITA Software as a Distinguished Software Engineer. ITA was acquired by Google in 2011, where he now works.|$|E
50|$|An auto {{receptionist}} {{is another}} option to handle callers, this solution is machine based versus a live virtual receptionist. Just like the automated <b>answering</b> <b>systems</b> large companies have, this system allows for businesses {{to set up}} auto answering for callers {{trying to reach the}} business. Users are allowed to have their own recordings and provide prompts with a number selection based on the department or individual a caller might be trying to reach, which the system then routes to a number based on the selection. This solution also offers a find me/follow me option, where all phone numbers associated with the account can be rang at once. Added features are that callers can be instructed to introduce themselves, and this gets played to the user when the call is connected, allowing the user to choose if they want to take the call or ignore it.|$|E
50|$|MultiNet {{is claimed}} {{to be one of}} the most {{comprehensive}} and thoroughly described knowledge representation systems. It specifies conceptual structures by means of about 140 predefined relations and functions, which are systematically characterized and underpinned by a formal axiomatic apparatus. Apart from their relational connections, the concepts are embedded in a multidimensional space of layered attributes and their values. Another characteristic of MultiNet discerning it from simple semantic networks is the possibility to encapsulate whole partial networks and represent the resulting conceptual capsule as a node of higher order, which itself can be an argument of relations and functions. MultiNet has been used in practical NLP applications such as natural language interfaces to the Internet or question <b>answering</b> <b>systems</b> over large semantically annotated corpora with millions of sentences. MultiNet is also a cornerstone of the commercially available search engine SEMPRIA Search, where it is used for the description of the computational lexicon and the background knowledge, for the syntactic-semantic analysis, for logical answer finding, as well as for the generation of natural language answers.|$|E
40|$|Question <b>Answering</b> <b>System</b> is {{a system}} that allows users to express their {{information}} needs in a more specific and natural, in the form of natural language question. Question <b>Answering</b> <b>System</b> does not return a list of documents that must be filtered by the user if the documents containing the appropriate answer but returns quoted text or even a phrase as an <b>answer.</b> The <b>system,</b> known as Question <b>Answering</b> (QA) <b>system</b> is to allow users to enter a query in natural language, the language used in everyday conversation, and get an answer in a nutshell, or even accompanied by a sentence sufficient to support the correctness of the response. This study aims to create a natural language processing applications for the domain of Christian songs. The process of making the application was preceded by the creation of grammar. which the formation of alternate language query sentences are realized in a production rule. The production rules for domain Question <b>Answering</b> <b>System</b> for Christian song begins with a symbol that is pengganti_query defined as kata_tanya bagian_ditanyakan and bagian_diketahui. This application is created using components-components of language processing, namely Scanner and Parser. Scanner duty lexical analysis, which identifies all scale build up a language in a source program. While on duty Parser and verify the sequence of tokens that are formed by the lexical analysis. Programming language to be used is Visual Basic 6. 0 programming language that assisted with Microsoft SQL server 2000 database handling. From the design and testing of question <b>answering</b> <b>system</b> for the domain of Christian songs, Question <b>Answering</b> <b>System</b> which is able to answer a single question with a success rate reached 83. 3 %...|$|R
40|$|In {{the field}} of Information Retrieval (IR), it may be {{difficult}} to answer a question posed by the user, because the search engine retrieves a ranked list of documents that may contain the answer inside the documents, but this needs extra effort from the user to search for the answer inside the documents, and there may be no answer. The alternative to IR search engine is a question <b>answering</b> <b>system,</b> which retrieves the answer to the question in the natural language text if found. A question <b>answering</b> <b>system</b> accepts the question in natural language, then applies a series of processes to extract the answer. In general a question <b>answering</b> <b>system</b> is composed of three main components: question classification module, information retrieval module and answer extraction module. We developed a question <b>answering</b> <b>system</b> applied to the Holy Quran written in Classical Arabic. Some characteristics of the Arabic language were used to enhance the answer extraction: one of these important characteristics is number in nouns: singular, dual and plural. A version of the question-answering system was built which uses noun number patterns to process the number in Arabic questions and candidate answers, which enhances the result set of answers by adding more words and meaning. A corpus of questions and its answers about the Holy Quran was used to test and compare baseline and enhanced versions of our Quran Qurstion <b>Answering</b> <b>system...</b>|$|R
40|$|Early {{question}} and <b>answering</b> (QA) <b>systems</b> focused on keyword search among documents for <b>answers.</b> However, such <b>systems</b> can only <b>answer</b> fact-based questions. It {{becomes clear that}} to answer more sophisticated questions, QA systems should rely on some domain knowledge. We propose a {{question and}} <b>answering</b> <b>system</b> that uses AnsProlog to represent and reason from the knowledge extracted by using Link Grammar and WordNet...|$|R
40|$|The paper studies Question <b>Answering</b> <b>Systems</b> {{that can}} be used in {{education}} as an engine to search for learning and/or other useful information. A wide set of different Question <b>Answering</b> <b>Systems,</b> such as START, Wolfram|Alpha, AllExperts, etc. is described and their main characteristics, benefits and drawbacks are given. The paper also presents four classifications of Question <b>Answering</b> <b>Systems</b> depending on: content, information source, language paradigm and information processing, as well as proposes recommendations for using Question <b>Answering</b> <b>Systems</b> in educatio...|$|E
40|$|Question <b>Answering</b> <b>Systems</b> (QAS) are {{receiving}} increasing attention from information systems researchers, {{particularly those in}} the information retrieval and natural language processing communities. Evaluation of an information system’s success and user satisfaction are important issues in information systems research, especially for emerging online service systems on the Internet. Although many QAS have been implemented, little {{work has been done}} on the development of an evaluation model for them. The {{purpose of this study is}} to develop an evaluation model for question <b>answering</b> <b>systems</b> from user’s perspective. We have established the theoretical foundation and conceptualization of the constructs for user satisfaction with question <b>answering</b> <b>systems.</b> We have developed a general instrument capable of reliably and accurately measuring user satisfaction in the context of question <b>answering</b> <b>systems.</b> The proposed evaluation model provides a framework for the design of question <b>answering</b> <b>systems</b> from the user’s perspective to enhance user satisfaction and acceptance of QAS...|$|E
40|$|Abstract—This paper {{describes}} a proposal of using ontological models {{as a basis}} of Query <b>Answering</b> <b>Systems</b> design. It is assumed that the models are presented {{in the form of}} relations described on some classes of items (ontological concepts) specified by taxonomic trees. There are analyzed the sufficient and necessary conditions for getting the replies to the queries as solution of relational equations based on the data provided by ontological databases. Simple examples illustrate basic concepts of practical realization of the Query <b>Answering</b> <b>Systems</b> based on domain ontologies. Index Terms—query <b>answering</b> <b>systems,</b> domain ontologies, relations, relational equations, D I...|$|E
40|$|The {{usage of}} {{computer}} {{applications in the}} construction industry has steadily increased over the years, as has the complexity of many applications. However, project managers, who are usually responsible for making decisions, are not necessarily familiar with these ever-increasingly complex applications. As a result, a question <b>answering</b> <b>system</b> is needed for efficiently managing construction projects. In this paper, we examine the various aspects involved in building a question <b>answering</b> <b>system.</b> In particular, we use ifcXML files as the knowledge representation system, which require no manual efforts to build the knowledge base. Moreover, we explore the mechanism to utilize information in the knowledge base for question understanding. A prototype question <b>answering</b> <b>system,</b> based on various technologies, has been built and successfully tested on several construction projects...|$|R
50|$|IBM's {{question}} <b>answering</b> <b>system,</b> Watson, {{defeated the}} two greatest Jeopardy champions, Brad Rutter and Ken Jennings, {{by a significant}} margin.|$|R
40|$|We {{present an}} {{approach}} to summarisation based {{on the use of}} a question <b>answering</b> <b>system</b> to select the most relevant sentences. We used AnswerFinder, a question <b>answering</b> <b>system</b> that is being developed at Macquarie University. The sentences returned by AnswerFinder are further re-ranked and collated to produce the final summary. This system will serve as a baseline upon which we intend to develop methods more specific to the task of question driven summarisation. 8 page(s...|$|R
40|$|Linguistic {{treatment}} of questions in Spanish for question classification in question answering systems]. We propose a procedure for the linguistic {{treatment of}} Spanish questions {{as a step}} prior to their classification in question <b>answering</b> <b>systems.</b> The main types of question <b>answering</b> <b>systems</b> and their basic architecture are described. We review the principal question classification taxonomies used to date and the different fields from {{which they have been}} derived. Finally, we present the stages of linguistic analysis that the text of questions in question <b>answering</b> <b>systems</b> should be subject to in order to facilitate the location of appropriate answers...|$|E
40|$|In today’s {{world of}} {{technological}} advancement, Question Answering {{has emerged as}} the key area for the researchers. In Question Answering user is provided with specific answers instead of large number of documents or passages. Question Answering has been carried out in many languages. This paper compares some already existing Question <b>Answering</b> <b>Systems</b> for Chinese and Japanese languages. Different Chinese and Japanese Question <b>Answering</b> <b>Systems</b> are compared {{on the basis of their}} performance in different workshops held for Question <b>Answering</b> <b>Systems.</b> We also discuss the best approach out of all and the reasons for which it is considered good and some methods for further improvement in those technique...|$|E
40|$|Growth in {{government}} investment, academic research, and commercial question answering (QA) systems is motivating {{a need for}} increased planning and coordination. The internationalization of QA research, {{and the need to}} move toward a common understanding of resources, tasks and evaluation methods provided motivate a need to facilitate more rapid and efficient progress. This paper characterizes a range of question <b>answering</b> <b>systems</b> and provides an initial roadmap for future research, including a list of existing resources and ones under development. This roadmap was initiated at the LREC 2002 Workshop on QA and we propose to update the roadmap during the workshop with moderated group brainstorming sessions. Characterizing Question <b>Answering</b> <b>Systems</b> Figure 1 characterizes a range of characteristics of question <b>answering</b> <b>systems.</b> The set of dimensions the distinguish various question <b>answering</b> <b>systems</b> which might range from systems for on-line help to access encyclopedic or technical manual information, to open web-based question answering, to very sophisticated QA in support of business o...|$|E
40|$|We {{propose a}} method for using the scoring values of {{passages}} to effectively retrieve documents in a Question <b>Answering</b> <b>system.</b> For this, we suggest evaluation function that considers proximity between each question terms in passage. And using this evaluation function, we extract a documents which involves scoring values in the highest collection, as a suitable document for question. The proposed method is very effective in document retrieval of Korean question <b>answering</b> <b>system.</b> Comment: 4 page...|$|R
40|$|VOCAULA, for Verification Of Candidate Answers Using Linguistic Analysis, is an <b>answer</b> {{verification}} <b>system</b> {{and methodology}} {{developed as a}} component for a larger Web-based question <b>answering</b> <b>system,</b> Aranea. Aranea uses the high recall avail-able by applying information retrieval techniques to the World Wide Web to increase domain coverage. This approach generates multiple candidate answers for any ques-tion; VOCAULA picks {{the best of these}} candidates by considering linguistic constraints present in the question and comparing these to supporting information for the candi-date answers. Although intended for a particular system, this component's modular design allows it to easily integrate into any question <b>answering</b> <b>system</b> which is based on high recall from large corpora. In evaluation against a set of TREC test questions, VOCAULA increased the number of correct answers by nearly ten percent over the base Aranea system. This is a modest gain, but it shows that answer verification should play a part in any question <b>answering</b> <b>system</b> using an information retrieva...|$|R
40|$|In Question <b>answering</b> (QA) <b>system</b> {{retrieves}} {{the precise}} information from large documents according to user query. This survey paper describe the different methods of natural language question <b>answering</b> <b>system</b> (NLQA) for general languages. QA System automatically retrieve correct {{responses to the}} question asked by the human in natural languages...|$|R
