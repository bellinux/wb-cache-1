9|12|Public
40|$|Automaticity, or instant {{recognition}} of combinations of letters as units of language, {{is essential for}} proficient reading in any language. The article explores automaticity amongst competent adult first-language readers of isiZulu, and the factors associated with it or its opposite - <b>active</b> <b>decoding.</b> Whilst the transparent spelling patterns of isiZulu aid learner readers, some of its orthographical features may militate against their gaining automaticity. These features are agglutination; a conjoined writing system; comparatively long, complex words; and {{a high rate of}} recurring strings of particular letters. This implies that optimal strategies for teaching reading in orthographically opaque languages such as English should not be assumed to apply to languages with dissimilar orthographies. Keywords: Orthography; Eye movement; Reading; isiZulu</p...|$|E
40|$|The {{presented}} work {{deals with}} the experimental identification of parts in a tree based decoder lexicon, that are more important for decoding efficiency compared to less important lexicon parts. Three different methods for constructing only the most important nodes {{in a set of}} tree lexicon copies are presented: building large trees; tree cutting; lexicon node removal. This leads to dramatic reduction of memory requirements while retaining the original recognition performance. In addition a reduction of the <b>active</b> <b>decoding</b> search space can be observed that leads to improved recognition speed. Although the presented methods can be generally applied to any HMM speech recognizer, experiments are performed in the hybrid MMI-connectionist/HMM system framework on the speaker independent 5 k WSJ database...|$|E
40|$|Reading {{to young}} {{children}} {{has a number of}} benefits, including supporting the acquisition of vocabulary and literacy skills. Digital reading games, including ones with new modes of interface such as the Kinect for Xbox, may provide similar benefits in part by allowing dynamic in-game activities. However, these activities may also be distracting and detract from learning. Children (ages 5 - 7 years, N = 39) were randomly assigned to either i) jointly read a story with an adult, ii) have the story read by a character in a Kinect game, or iii) have the story read by a character in a Kinect game plus in-game activities. Both Kinect-Activities and Book Reading groups had significant gains for High Frequency Words, <b>Active</b> <b>Decoding,</b> and Total Reading Score, but only Kinect-Activities group had significant gain for Sight words (p <. 05). Overall, these findings are encouraging {{for the next generation of}} digital literacy games...|$|E
40|$|The two {{dominant}} {{methods of}} reducing SRAM power {{have been to}} reduce operating range and to limit signal swings on the highcapacitance bit and I/O lines [1]. As a consequence, decode and write now consume a significant fraction of SRAM power. Dual-Vt CMOS circuit techniques implement reduced-swing decode and write [1]. Swings on high-capacitance predecode lines, bitlines and write bus, are limited to half Vdd. The half-Vdd supply is generated internally with high efficiency by chargerecycling between positive and negative half-swing signals. SRAM architecture and decoder organization are shown in Figure 1. The main limitation resulting from reducing signal swings is reduction in gate overdrive at the receiving transistor leading to delay penalty. This design overcomes this using positive and negative half-swing signals on high-capacitance predecode lines so <b>active</b> <b>decode</b> circuits see a full gate-overdrive...|$|R
40|$|Abstract: In this paper, a dual-resource {{constrained}} {{job shop}} scheduling problem was studied by designing a hybrid genetic algorithm based on Genetic Algorithm (GA) and Simulated Annealing (SA). GA {{is used to}} search for a group of better solutions to the problem of minimizing production cost and then SA is applied to searching them for the best one. The combination of GA and SA utilizes the advantages of the two algorithms and overcomes their disadvantages. The operation-based encoding and an <b>active</b> schedule <b>decoding</b> method were employed. This hybrid genetic algorithm reasonably assigns the resources of machines and workers to jobs and achieves optimum on some performance. The results of numerical simulations, which are compared with those of other well-known algorithms, show better performance of the proposed algorithm...|$|R
40|$|Abstract — We {{deal with}} the coding problem of the multiple-access adder channel, {{considering}} both {{the identification of the}} <b>active</b> users and <b>decoding</b> of their messages. We examine the bounds on the minimal length of codes solving these tasks. We examine codes solving both tasks simultaneously, and we give asymptotic upper and lower bounds on the length of the shortest possible code. Our new bounds are quite similar to the bounds known for the identification task only. The difference between the upper and lower bounds is a factor of two. I...|$|R
40|$|International audienceThe A site of {{the small}} ribosomal subunit participates in the {{fidelity}} of decoding by switching between two states, a resting 'off' state and an <b>active</b> <b>decoding</b> 'on' state. Eight crystal structures of RNA duplexes containing two minimal decoding A sites of the Homo sapiens mitochondrial wild-type, the A 1555 G mutant or bacteria have been solved. The resting 'off' state of the mitochondrial wild-type A site is surprisingly {{different from that of}} the bacterial A site. The mitochondrial A 1555 G mutant has two types of the 'off' states; one is similar to the mitochondrial wild-type 'off' state and the other is similar to the bacterial 'off' state. Our present results indicate that the dynamics of the A site in bacteria and mitochondria are different, a property probably related to the small number of tRNAs used for decoding in mitochondria. Based on these structures, we propose a hypothesis for the molecular mechanism of non-syndromic hearing loss due to the mitochondrial A 1555 G mutation...|$|E
40|$|There are {{claims that}} up to twenty per cent of our {{children}} are failing {{to learn to read}} at a level considered adequate in the wider community. The problem is compounded by the Great Debate which continues to rage globally between the adherents to the opposing reading models. The debaters seldom acknowledge the vast background of research into learning failure and strategy deficiencies. It is possible that cognitive strategies may well be the facilitating skill potentially capable of enhancing reading for life. There is an urgent need for thorough research to investigate a reading model that would supplement and complement the psycholinguistic approach by teaching <b>active</b> <b>decoding</b> as a step in the application of cognitive strategies. This research set out to develop and implement a cognitive-interactive program for facilitating reading for students with reading difficulties. The program (CIP) was implemented within the existing classrooms of the participating students. Thirteen schools co-operated, allowing data to be collected from nearly three hundred students. The impact of the program was statistically evaluated. The purpose of this thesis is to extend existing knowledge by the articulation of a novel approach designed to remedy reading failure...|$|E
40|$|Abstract — Some impulse radio UWB (IR-UWB) {{networks}} {{may allow}} concurrent transmissions without power control (for example MAC protocols {{that do not}} use power control, or co-exisiting, non-coordinated piconets). In such cases, it has been proposed to mitigate multi-user interference (MUI) at the physical layer, but existing proposals for interference mitigation do {{not account for the}} multipath nature of UWB channels. We address this problem and propose a receiver that employs a combination of statistical interference modeling and thresholding to mitigate MUI. We find that in a multipath environment the proposed receiver significantly outperforms existing receiver designs that either completely neglect the effect of MUI or only use a simple threshold to reject samples from interfering users. Further, in contrast to successive interference cancellation schemes, our receiver does not require <b>active</b> <b>decoding</b> of each interferer. Thus {{there is no need to}} synchronize the receiver with all the interfering users, which would be impractical in an IR-UWB system that is likely to be run in ad hoc mode. To model MUI we consider a hidden Markov model (HMM) and a Gaussian mixture model (GMM). We find that the HMM models interference better than the GMM. However, the resulting performance difference is not huge and comes at the cost of increased receiver complexity. I...|$|E
40|$|<b>Active</b> error <b>decoding</b> and {{correction}} of topological quantum codes - {{in particular the}} toric code - {{remains one of the}} most viable routes to large scale quantum information processing. In contrast, passive error correction relies on the natural physical dynamics of a system to protect encoded quantum information. However, the search is ongoing for a completely satisfactory passive scheme applicable to locally-interacting two-dimensional systems. Here, we investigate dynamical decoders that provide passive error correction by embedding the decoding process into local dynamics. We propose a specific discrete time cellular-automaton decoder in the fault tolerant setting and provide numerical evidence showing that the logical qubit has a survival time extended by several orders of magnitude over that of a bare unencoded qubit. We stress that (asynchronous) dynamical decoding gives rise to a Markovian dissipative process. We hence equate cellular-automaton decoding to a fully dissipative topological quantum memory, which removes errors continuously. In this sense, uncontrolled and unwanted local noise can be corrected for by a controlled local dissipative process. We analyze the required resources, commenting on additional polylogarithmic factors beyond those incurred by an ideal constant resource dynamical decoder. Comment: 8 pages, 3 figures, replaced with published versio...|$|R
40|$|We discuss memory models {{which are}} based on tensor decompositions using latent {{representations}} of entities and events. We show how episodic memory and semantic memory can be realized and discuss how new memory traces can be generated from sensory input: Existing memories are the basis for perception and new memories are generated via perception. We relate our mathematical approach to the hippocampal memory indexing theory. We describe the first detailed mathematical models for the complete processing pipeline from sensory input and its semantic decoding, i. e., perception, to the formation of episodic and semantic memories and their declarative semantic decodings. Our main hypothesis is that perception includes an <b>active</b> semantic <b>decoding</b> process, which relies on latent representations of entities and predicates, and that episodic and semantic memories depend on the same decoding process. We contribute to the debate between the leading memory consolidation theories, i. e., the standard consolidation theory (SCT) and the multiple trace theory (MTT). The latter is closely related to the complementary learning systems (CLS) framework. In particular, we show explicitly how episodic memory can teach the neocortex to form a semantic memory, which is a core issue in MTT and CLS. Comment: Presented at MLINI- 2016 workshop, 2016 (arXiv: 1701. 01437) Report-no: MLINI/ 2016 / 0...|$|R
30|$|Usually, several radio {{frequency}} identification (RFID) tags operate within a coverage area of an RFID reader. For the efficient scheduling of tag transmissions, framed slotted Aloha (FSA) or binary tree protocols are used on the medium access control layer. Our focus is on passive ultra high-frequency (UHF) RFID systems and FSA as defined in the EPCglobal standard [1]. If multiple tags respond simultaneously, a collision at the air interface occurs. The standard collision detection mechanism regards this as a destructive event and discards the information. Thus, only slots in which one tag is <b>active</b> can be <b>decoded</b> successfully [2]. This determines the maximal throughput per slot for an FSA system. The maximum throughput value of 0.368 is achieved when the inventory frame size F {{is equal to the}} tag population size N.|$|R
40|$|The {{temporally}} encoded {{information obtained}} by vibrissal touch could be decoded “passively,” involving only input-driven elements, or “actively,” utilizing intrinsically driven oscillators. A previous study {{suggested that the}} trigeminal somatosensory system of rats does not obey the bottom-up order of activation predicted by passive decoding. Thus, we have tested whether this system obeys the predictions of <b>active</b> <b>decoding.</b> We have studied cortical single units in the somatosensory cortices of anesthetized rats and guinea pigs and found that {{about a quarter of}} them exhibit clear spontaneous oscillations, many of them around whisking frequencies (≈ 10 Hz). The frequencies of these oscillations could be controlled locally by glutamate. These oscillations could be forced to track the frequency of induced rhythmic whisker movements at a stable, frequency-dependent, phase difference. During these stimulations, the response intensities of multiunits at the thalamic recipient layers of the cortex decreased, and their latencies increased, with increasing input frequency. These observations are consistent with thalamocortical loops implementing phase-locked loops, circuits that are most efficient in decoding temporally encoded information like that obtained by active vibrissal touch. According to this model, and consistent with our results, populations of thalamic “relay” neurons function as phase “comparators” that compare cortical timing expectations with the actual input timing and represent the difference by their population output rate...|$|E
40|$|Communication is an {{important}} aspect of human life, allowing us to powerfully coordinate our behaviour with that of others. Boiled down to its mere essentials, communication entails transferring a mental content from one brain to another. Spoken language obviously plays {{an important}} role in communication between human individuals. Manual gestures however often aid the semantic interpretation of the spoken message, and gestures may have played a central role in the earlier evolution of communication. Here we used the social game of charades to investigate the neural basis of gestural communication by having participants produce and interpret meaningful gestures while their brain activity was measured using functional magnetic resonance imaging. While participants decoded observed gestures, the putative mirror neuron system (pMNS: premotor, parietal and posterior mid-temporal cortex), associated with motor simulation, and the temporo-parietal junction (TPJ), associated with mentalizing and agency attribution, were significantly recruited. Of these areas only the pMNS was recruited during the production of gestures. This suggests that gestural communication relies on a combination of simulation and, during decoding, mentalizing/agency attribution brain areas. Comparing the decoding of gestures with a condition in which participants viewed the same gestures with an instruction not to interpret the gestures showed that although parts of the pMNS responded more strongly during <b>active</b> <b>decoding,</b> most of the pMNS and the TPJ did not show such significant task effects. This suggests that the mere observation of gestures recruits most of the syste...|$|E
40|$|Abstract—Quality {{of object}} {{detection}} and network lifetime hold critical importance to many sensor network {{applications such as}} military surveillance. Unfortunately, improving one of these aspects comes {{at the expense of}} the other. In this paper, based on the probabilistic sensing model, we propose a novel framework for object detection in sensor networks, called DeCODe (on-Demand framework for Collaborative Object Detection), which provides a desired object detection performance (characterized in terms of detection probability and false detection probability), while attempting to prolong the network lifetime. The design of DeCODe is motivated by a counterintuitive observation that simple collaboration among active sensors indeed degrades the object detection performance. By contrast, each <b>active</b> sensor in <b>DeCODe</b> can trigger its neighboring inactive sensors to participate in the detection process in an on-demand fashion, so as to achieve the same low false detection probability while increasing the probability of detection. The effectiveness of the proposed DeCODe framework is supported by theoretical analysis and simulation-based validation. I...|$|R
40|$|Traffic of the {{integral}} yeast membrane protein chitin synthase III (Chs 3 p) from the trans-Golgi network (TGN) {{to the cell}} surface and {{to and from the}} early endosomes (EE) requires <b>active</b> protein sorting <b>decoded</b> by a number of protein coats. Here we define overlapping signals on Chs 3 p responsible for sorting in both exocytic and intracellular pathways by the coats exomer and AP- 1, respectively. Residues 19 DEESLL 24, near the N-terminal cytoplasmically-exposed domain, comprise both an exocytic di-acidic signal and an intracellular di-leucine signal. Additionally we show that the AP- 3 complex is required for the intracellular retention of Chs 3 p. Finally, residues R 374 and W 391, comprise another signal responsible for an exomer-independent alternative pathway that conveys Chs 3 p to the cell surface. These results establish a role for active protein sorting at the trans-Golgi en route to the plasma membrane (PM) and suggest a possible mechanism to regulate protein trafficking...|$|R
30|$|The context-dependent GMM {{system with}} the {{standard}} setting (1740 k parameters) achieved higher performance than the proposed DTAM systems. However, {{the difference in the}} performance between the GMM and DTAM systems became small when the numbers of parameters were similar. The proposed context-dependent DTAMs are highly compact compared to GMMs. Unlike the state-tying mechanism in the GMM setup, contexts in DTAMs are untied only after significant acoustic splitting has taken place, generally at depths 4 and lower. This results in effective data-sharing across various context classes. The difference in the number of parameters between monophone and triphone DTAM systems shows that nearly one-third of the triphone system questions are context questions. It {{should also be noted that}} for DTAMs the computational complexity of likelihood computation is only logarithmic. Therefore, as long as the number of <b>active</b> nodes during <b>decoding</b> is kept comparable to the GMM system, DTAMs prove to be much faster compared to GMMs. A similar observation was made in [4] where the number of vector operations required for DTAMs was only 1 / 16 of that of GMMs for similar accuracy.|$|R
40|$|Abstract Background The {{development}} of large-scale technologies for quantitative transcriptomics has enabled comprehensive {{analysis of the}} gene expression profiles in complete genomes. RNA-Seq allows the measurement of gene expression levels in a manner far more precise and global than previous methods. Studies using this technology are altering our view about the extent {{and complexity of the}} eukaryotic transcriptomes. In this respect, multiple efforts have been done to determine and analyse the gene expression patterns of human cell types in different conditions, either in normal or pathological states. However, until recently, little has been reported about the evolutionary marks present in human protein-coding genes, particularly from the combined perspective of gene expression and protein evolution. Results We present a combined analysis of human protein-coding gene expression profiling and time-scale ancestry mapping, that places the genes in taxonomy clades and reveals eight evolutionary major steps (“hallmarks”), that include clusters of functionally coherent proteins. The human expressed genes are analysed using a RNA-Seq dataset of 116 samples from 32 tissues. The evolutionary analysis of the human proteins is performed combining the information from: (i) a database of orthologous proteins (OMA), (ii) the taxonomy mapping of genes to lineage clades (from NCBI Taxonomy) and (iii) the evolution time-scale mapping provided by TimeTree (Timescale of Life). The human protein-coding genes are also placed in a relational context based in the construction of a robust gene coexpression network, that reveals tighter links between age-related protein-coding genes and finds functionally coherent gene modules. Conclusions Understanding the relational landscape of the human protein-coding genes is essential for interpreting the functional elements and modules of our <b>active</b> genome. Moreover, <b>decoding</b> the evolutionary history of the human genes can provide very valuable information to reveal or uncover their origin and function...|$|R
50|$|The Encoding/decoding {{model of}} {{communication}} was first developed by cultural studies scholar Stuart Hall in 1973. Titled 'Encoding and Decoding in the Television Discourse', Hall's essay offers a theoretical approach of how media messages are produced, disseminated, and interpreted. As an important {{member of the}} Birmingham School of Cultural Studies, Hall had {{a major influence on}} media studies. His model claims that television and other media audiences are presented with messages that are decoded, or interpreted in different ways depending on an individual's cultural background, economic standing, and personal experiences. In contrast to other media theories that disempower audiences, Hall proposed that audience members can play an <b>active</b> role in <b>decoding</b> messages as they rely on their own social contexts, and might be capable of changing messages themselves through collective action. In simpler terms, encoding/decoding is the translation of a message that is easily understood. When you decode a message, you extract the meaning of that message in ways that make sense to you. Decoding has both verbal and non-verbal forms of communication: Decoding behavior without using words means observing body language and its associated emotions. For example, some body language signs for when someone is upset, angry, or stressed would be a use of excessive hand/arm movements, red in the face, crying, and even sometimes silence. Sometimes when someone is trying to get a message across to someone, the message can be interpreted differently from person to person. Decoding is all about the understanding of what someone already knows, based on the information given throughout the message being received. Whether there is a large audience or exchanging a message to one person, decoding is the process of obtaining, absorbing, understanding, and sometimes using the information that was given throughout a verbal or non-verbal message.|$|R
40|$|Under the {{framework}} of dual-route theory of speech comprehension, two neurological routes are simultaneously <b>active</b> during speech <b>decoding,</b> the dorsal stream and the ventral stream. The dorsal stream is argued to be a sound processor whereas the ventral stream is a meaning processor, hence in cognitive terms, they are called the sound component and the meaning component respectively. Hypotheses concerning the processing speed and response accuracy of these two cognitive components were tested on compound words in Modern Mandarin Chinese. Four experiments were run contrasting, the sound-based task and the meaning-based task, corresponding {{to each of the}} two cognitive components. In Experiment 1 and 2, the Task effect was tested on one set of words in which the word-level and word-initial-syllable frequencies were controlled. In Experiment 3 and 4, the Task effect was tested on a different set of words in which semantic transparency was controlled. Multiple regression analyses integrating the data collected in Experiment 1 - 4 were conducted to test which language theory was preferred, the probability-based theory, the rule-based theory or the integrative theory. The probability-based theory suggests that speech comprehension of compound words relies only on the probability distribution of linguistic units. The rule-based theory suggests that speech comprehension of compound words relies only on phrase-structural rules. The integrative theory suggests that speech comprehension of compound words relies on both the probabilities of linguistic units and phrase-structural rules. It was suggested that the integrative theory explains the data best, but further data testing is needed to confirm this hypothesis. The {{results of the present study}} provide evidence for functional trade-off of the sound and meaning components, garden path effects during parsing opaque words and the possibility of the role of a mirror system in human speech comprehension...|$|R

