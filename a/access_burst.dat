2|47|Public
50|$|There {{are several}} other burst formats, though. Bursts that require higher {{processing}} gain for signal acquisition have longer midambles. The random <b>access</b> <b>burst</b> (RACH) has an extended guard period {{to allow it}} to be transmitted with incomplete timing acquisition. Burst formats are described in GSM 05.02 Section 5.2.|$|E
5000|$|Random Access Channel (RACH) {{is used by}} the MS on the [...] "uplink" [...] {{to request}} for {{allocation}} of an SDCCH. This request from the MS on the uplink could either be as a page response (MS being paged by the BSS in response to an incoming call) or due to user trying to access the network to establish a call. Availability of SDCCH at the BTS will not have any impact on the Random Access Success.In the transceiver, the timeslot handler in charge of the RACH channel listens for <b>access</b> <b>burst</b> from mobiles (on the time-slot that transmits BCCH). These bursts contain a check sequence (8 bits) that is used to determine if the message is valid.|$|E
50|$|The RACH is the uplink {{counterpart}} to the AGCH. The RACH is a shared channel {{on which the}} mobile stations transmit random <b>access</b> <b>bursts</b> to request channel assignments from the BTS.|$|R
50|$|Data is <b>accessed</b> in <b>bursts</b> {{of either}} 16 or 32 {{transfers}} (256 or 512 bits, 32 or 64 bytes, 8 or 16 cycles DDR). Bursts must begin on 64-bit boundaries.|$|R
40|$|Abstract—Network {{applications}} {{often require}} large data stor-age resources, fast queries, and frequent updates. Hash tables support these operations with low costs, yet they cannot provide worst-case guarantees because of hash collisions. Also, the widely used, low-cost Dynamic Random Access Memory (DRAM) cannot suitably accommodate hash tables because DRAMs provide full bandwidth only if <b>accessed</b> in <b>bursts,</b> whereas hash tables require random access. In this paper, we propose a hash co-processor to support hash tables on DRAMs. The co-processor provides a load-balancing method {{to reduce the}} impact of hash collisions on the worst-case behavior by moving multiple keys within the hash table in constant time. This leads to a balanced distribution of keys in the hash table despite the collisions. Furthermore, the co-processor guarantees the full DRAM bandwidth is always utilized by defining all fundamental hash table operations, namely insert, query, and delete, in terms of <b>burst</b> <b>accesses.</b> In the worst case, the query, delete, and insert operations take one, two, and three <b>burst</b> <b>accesses,</b> respectively. The proposed architecture reduces hash overflows by 35 % compared to a naı̈ve hash table and for each key uses 6. 42 bits of on-chip memory. I...|$|R
25|$|A {{data phase}} with all four C/BE# lines {{deasserted}} is explicitly permitted by the PCI standard, {{and must have}} no effect on the target other than to advance the address in the <b>burst</b> <b>access</b> in progress.|$|R
5000|$|PCI also {{supports}} <b>burst</b> <b>access</b> to I/O and configuration space, but only linear mode is supported. (This is rarely used, {{and may be}} buggy in some devices; they may not support it, but not properly force single-word access either.) ...|$|R
5000|$|Compute {{elements}} {{may have}} different cache structures, cache coherency protocols, and memory access may be uniform or non-uniform memory access (NUMA). Differences {{can also be found}} in the ability to read arbitrary data lengths as some processors/units can only perform byte-, word-, or <b>burst</b> <b>accesses.</b>|$|R
50|$|HD Tach is a {{software}} program for Microsoft Windows (2000 or XP) that tests and graphs the sequential read, random <b>access</b> and interface <b>burst</b> speeds of attached storage devices (hard drive, flash drive, removable drive etc.). Drive technologies such as SCSI, IDE/ATA, IEEE 1394, USB, SATA and RAID are supported.|$|R
2500|$|<b>Bursts</b> always <b>access</b> an aligned {{block of}} BL {{consecutive}} words beginning on {{a multiple of}} BL. So, for example, a four-word <b>burst</b> <b>access</b> to any column address from four to seven will return words four to seven. The ordering, however, depends on the requested address, and the configured burst type option: sequential or interleaved. Typically, a memory controller will require one or the other. When the burst length is one or two, the burst type does not matter. For a burst length of one, the requested word is the only word <b>accessed.</b> For a <b>burst</b> length of two, the requested word is accessed first, and the other word in the aligned block is accessed second. [...] This is the following word if an even address was specified, and the previous word if an odd address was specified.|$|R
2500|$|Combining : Write {{transactions}} to consecutive addresses may {{be combined}} into a longer burst write, {{as long as the}} order of the <b>accesses</b> in the <b>burst</b> {{is the same as the}} order of the original writes. [...] It is permissible to insert extra data phases with all byte enables turned off if the writes are almost consecutive.|$|R
40|$|We propose an {{experimental}} demonstration of visible light communication (VLC) based on interleave {{division multiple access}} (IDMA), which offers low peak-to-average power ratio, low complexity, and high robustness against multiple <b>access</b> interference and <b>burst</b> error. Bidirectional IDMA-VLC transmission is experimentally demonstrated. The experiment results indicate that IDMA offers better bit error rate performance compared with orthogonal frequency-division multiplexing access...|$|R
5000|$|Combining : Write {{transactions}} to consecutive addresses may {{be combined}} into a longer burst write, {{as long as the}} order of the <b>accesses</b> in the <b>burst</b> {{is the same as the}} order of the original writes. It is permissible to insert extra data phases with all byte enables turned off if the writes are almost consecutive.|$|R
50|$|DMA {{transfers}} {{can either}} occur one byte {{at a time}} or all at once in burst mode. If they occur a byte at a time, this can allow the CPU to access memory on alternate bus cycles - this is called cycle stealing since the CPU and either the DMA controller or the bus master contend for memory <b>access.</b> In <b>burst</b> mode DMA, the CPU can be put on hold while the DMA transfer occurs and a full block of possibly {{hundreds or thousands of}} bytes can be moved. When memory cycles are much faster than processor cycles, an interleaved DMA cycle is possible, where the DMA controller uses memory while the CPU cannot.|$|R
40|$|Power {{consumption}} is the limiting {{factor for the}} functionality of future wearable devices. Since interactive applications like wireless information <b>access</b> generate <b>bursts</b> of activities, {{it is important to}} match the performance of the wearable device accordingly. This paper describes a system with a microprocessor whose speed can be varied (frequency scaling) as well as its input voltage. Voltage scaling is important for reducing power consumption to very low values when operating at low speeds. Measurements show that the energy per instruction at minimal speed (59 MHz) is 1 / 5 of the energy required at full speed (251 MHz). The frequency and voltage can be scaled dynamically from user space in only 140 ¡ s. This allows power-aware applications to quickly adjust the performance level of the processor whenever the workload changes. ...|$|R
40|$|Background Point-of-care (POC) {{diagnostics}} provide quick {{results for}} patients {{in remote areas}} with limited access to laboratory equipment. Concurrently in-vitro diagnostic device market is a valued at $ 24 billion dollar and its expected to be valued at over $ 70 billion by 2020 • These diagnostics require access to intracellular components, such as DNA, which can be <b>accessed</b> by <b>bursting</b> open the cell, a process called cell lysis. Microfluidic technology allows for an entire laboratory procedure to miniaturized onto a small, portable platform, allowing for a quicker diagnostics and results.   Andrew Chavarin, Leovi Espitia, Saffi Khan, Marisa Lopez, Frederique Norpetlian, Abdullaah Tarif Advisor: Professor William C. Tang Mentor: Dr. Brad Sargent, Omnica Corporation, Irvine, CA School of Engineering Department of: Biomedical Engineering, Chemical and Material Science & Mechanical and Aerospace Engineering, University of California-Irvine, C...|$|R
30|$|Row {{precharge}} and row {{opening delay}} for DDR 3 SDRAM are memory and clock frequency dependent. For a 64 -bit 7 - 7 - 7 memory, the delay {{because of a}} row opening and precharging is three times {{higher than that of}} a column access. One feature of the <b>burst</b> <b>accesses</b> is that the subsequent column access time for consecutive locations is hidden and the only case where this access time is influencing the data retrieval delay is for the first column from the burst.|$|R
40|$|Image {{processing}} applications often demand powerful {{calculations and}} real-time performance with low {{power and energy}} consumption. Programmable hardware provides inherent parallelism and flexibility making it a good implementation choice for this application domain. In this work we introduce a new modeling technique combining Cyclo-Static Dataflow (CSDF) base model semantics and Homogeneous Parameterized Dataflow (HPDF) meta-modeling framework, which exposes more levels of parallelism than previous models {{and can be used}} to reduce buffer sizes. We model two different applications and show how we can achieve efficient scheduling and memory organization, which is crucial for this application domain, since large amounts of data are processed, and storing intermediate results usually requires the use of off-chip resources, causing slower data access and higher power consumption. We also designed a reusable wishbone compliant memory controller module {{that can be used to}} access the Xilinx Multimedia Board’s memory chips using single <b>accesses</b> or <b>burst</b> mode...|$|R
40|$|Restricted <b>Access.</b> Gamma-ray <b>bursts</b> (GRBs) {{are thought}} to arise when an {{extremely}} relativistic outflow of particles from a massive explosion (the nature of which is still unclear) interacts with material surrounding {{the site of the}} explosion. Observations of the evolving changes in emission at many wavelengths allow us to investigate the origin of the photons, and so potentially determine the nature of the explosion. Here we report the results of gamma-ray, optical, infrared, submillimetre, millimetre and radio observations of the burst GRB 990123 and its afterglow. Our interpretation of the data indicates that the initial and afterglow emissions are associated with three distinct regions in the fireball. The peak flux of the afterglow, one day after the burst, has a lower frequency than observed for other bursts; this explains the short-lived radio emission. We suggest that the differences between bursts reflect variations in the magnetic-field strength in the afterglow-emitting regions...|$|R
5000|$|File {{contiguity}} is, in {{most practical}} applications, [...] "invisible" [...] at operating-system or user levels, {{since all the}} files in a sequence are always available to applications in the same way, regardless of their physical location on the storage device (due to operating systems hiding the filesystem internals to higher-level services). Indeed, file contiguity {{may be related to}} I/O performance when the sequence is to be read or written in the shortest time possible.In some contexts (like optical disk burning - also cfr. below), data in a file sequence must be accessed in the same order as the file sequence itself; in other contexts, a [...] "random" [...] access to the sequence may be required. In both cases, most professional filesystems provide faster access strategies to contiguous files than non-contiguous ones. Data pre-allocation is crucial for write <b>access,</b> whereas <b>burst</b> read speeds are achievable only for contiguous data.|$|R
40|$|Open <b>Access.</b> Gamma ray <b>bursts</b> (GRBs) {{have been}} {{proposed}} as one possible class of sources of the ultrahigh energy cosmic ray (UHECR) events observed up to energies gtrsim 10 ^{ 20 } eV. The synchrotron radiation of the highest energy protons accelerated within the GRB source should produce gamma rays up to TeV energies. Here we briefly discuss the implications on the energetics of the GRB {{from the point of}} view of the detectability of the prompt TeV gamma-rays of proton-synchrotron origin in GRBs in the up-coming ICECUBE muon detector in the south pole...|$|R
40|$|It {{is pointed}} out that the NASA 30 / 20 GHz program will place in {{geosynchronous}} orbit a technically advanced communication satellite which can process time-division multiple <b>access</b> (TDMA) information <b>bursts</b> with a data throughput in excess of 4 GBPS. To guarantee acceptable data quality during periods of signal attenuation {{it will be necessary to}} provide a significant forward error correction (FEC) capability. Convolutional decoding (utilizing the maximum-likelihood techniques) was identified as the most attractive FEC strategy. Design trade-offs regarding a maximum-likelihood convolutional decoder (MCD) in a single-chip CMOS implementation are discussed...|$|R
40|$|Networks (WLANs) {{have become}} {{extremely}} popular. The IEEE 802. 11 protocol is the dominating standard for WLANs employing the Distributed Coordination Function (DCF) as its essential {{medium access control}} (MAC) mechanism. This paper presents a simple and accurate analysis using Markov chain modelling to compute IEEE 802. 11 DCF performance, {{in the absence of}} hidden stations and transmission errors. This mathematical analysis calculates in addition to the throughput efficiency, the average packet delay and the packet drop probability for both basic access and RTS/CTS medium access schemes. The derived analysis, which takes into account packet retry limits, is validated by comparison with OPNET simulation results. The mathematical model is used to study the effectiveness of the RTS/CTS scheme at high data rates and the performance improvements of transmitting a burst of packets after winning the contention for medium <b>access.</b> Packet <b>bursting</b> considerably increases both throughput and packet delay performance but lowers the short-term fairness on medium access. I...|$|R
40|$|ABSTRACT Power {{consumption}} is the limiting {{factor for the}} functionality of future wearable devices. Since interactive applications like wireless information <b>access</b> generate <b>bursts</b> of activities, {{it is important to}} match the performance of the wearable device accordingly. This paper describes a system with a microprocessor whose speed can be varied (frequency scaling) as well as its supply voltage. Voltage scaling is important for reducing power consumption to very low values when operating at low speeds. Measurements show that the energy per instruction at minimal speed is 1 / 5 of the energy required at full speed. The frequency and voltage can be scaled dynamically from user space in only 140 _s. This allows power-aware applications to quickly adjust the performance level of the processor whenever the workload changes. Experiments with an H. 263 video benchmark show that the power-aware decoder outperforms a static fixed-frequency policy as well as a dynamic interval-based scheduler...|$|R
40|$|Computer Studies Image {{processing}} applications often demand powerful {{calculations and}} real-time performance with low {{power and energy}} consumption. Programmable hardware provides inherent parallelism and flexibility making it a good implementation choice for this application domain. In this work we introduce a new modeling technique combining Cyclo-Static Dataflow (CSDF) base model semantics and Homogeneous Parameterized Dataflow (HPDF) meta-modeling framework, which exposes more levels of parallelism than previous models {{and can be used}} to reduce buffer sizes. We model two different applications and show how we can achieve efficient scheduling and memory organization, which is crucial for this application domain, since large amounts of data are processed, and storing intermediate results usually requires the use of off-chip resources, causing slower data access and higher power consumption. We also designed a reusable wishbone compliant memory controller module {{that can be used to}} access the Xilinx Multimedia Board’s memory chips using single <b>accesses</b> or <b>burst</b> mode...|$|R
40|$|With an {{increasing}} need for lower latency and higher operating frequencies, memory interface IP {{is becoming more}} complex {{and needs to be}} tailored based on a number of factors such as latency, burst length, interface width, and operating frequency. The Xilinx ® Memory Interface Generator (MIG) tool enables the creation of a large variety of memory interfaces for devices such as the Virtex®- 6 FPGA. However, in the Virtex- 6 FPGA, QDR II SRAM {{is not one of the}} options available by default. Instead, the focus has been on the QDR II+ technology using four-word <b>burst</b> <b>access</b> mode. This application note presents a Verilog reference design that has been simulated, synthesized, and verified on hardware using Virtex- 6 FPGAs and QDR II SRAM two-word burst devices...|$|R
40|$|Abstract—In modern {{digital systems}} large {{capacity}} and {{data transfer rate}} is required. Synchronous DRAM (SDRAM) became the memory of choice due to its speed, <b>burst</b> <b>access</b> and pipeline features. A Controller is required to provide proper commands for SDRAM initialization, read/write accesses and memory refresh. In semiconductor memories there are chances of errors. To ensure reliable data storage, an error correction and detection scheme is required. This paper describes the architecture design and characterization of SDRAM Controller IP core with built in Error Correcting Codes (ECC) module which is vendor neutral. The design is described using Verilog HDL, simulated using ModelSim and prototyped in Altera ® platform FPGA. Resource utilization and power analysis was done using Altera ® Quartus II. Hardware test results are obtained from Signal Tap Logic Analyzer...|$|R
40|$|Abstract: Double Data Rate Synchronous DRAM (DDR SDRAM) {{has become}} a {{mainstream}} memory of choice in design due to its speed, <b>burst</b> <b>access</b> and pipeline features. The DDR SDRAM is an enhancement to the conventional SDRAM running at bus speed over 75 MHz. The DDR SDRAM (referred to as DDR) doubles the bandwidth of the memory by transferring data twice per cycle on both the rising and falling edges of the clock signal. The designed DDR Controller supports data width of 64 bits, Burst Length of 4 and CAS (Column Address Strobe) latency of 2. DDR Controller provides a synchronous command interface to the DDR SDRAM Memory along with several control signals. In this paper, the implementation {{has been done in}} Verilog HDL by using Xilinx ISE 9. 2 i and Modelsim 6. 4 b...|$|R
50|$|In 1990s, {{asynchronous}} SRAM used to {{be employed}} for fast access time. Asynchronous SRAM was used as main memory for small cache-less embedded processors used in everything from industrial electronics and measurement systems to hard disks and networking equipment, among many other applications. Nowadays, synchronous SRAM (e.g. DDR SRAM) is rather employed similarly like Synchronous DRAMDDR SDRAM memory is rather used than asynchronous DRAM (dynamic random-access memory). Synchronous memory interface is much faster as access time can be significantly reduced by employing pipeline architecture. Furthermore, as DRAM is much cheaper than SRAM, SRAM is often replaced by DRAM, {{especially in the case}} when large volume of data is required. SRAM memory is however much faster for random (not block / <b>burst)</b> <b>access.</b> Therefore, SRAM memory is mainly used for CPU cache, small on-chip memory, FIFOs or other small buffers.|$|R
30|$|At the moment, the DDR 3 {{memories}} are preferred for such implementations {{thanks to their}} fast memory access, high bandwidth, relatively large storage capability, and affordable price. The major bottlenecks of external SDRAM memory in a H. 264 decoder are numerous accesses to implement the motion compensation (MC) and accesses to multiple memory rows to reach columns of pixels. This last bottleneck, known as cross-row memory access, {{is a problem for}} both access time and power utilization. The row precharge and row opening delay for DDR 3 SRDAM are memory and clock frequency dependent. For a 64 -bit 7 - 7 - 7 memory it takes about three times more time to read a data from an unopened row than from an already opened one [6]. This, together with the DDR 3 optimized <b>burst</b> <b>access</b> are the facts that drove us to look into a more efficient memory access for MC.|$|R
30|$|The higher {{resolutions and}} new {{functionality}} of video applications increase their throughput and processing requirements. In contrast, {{the energy and}} heat limitations of mobile devices demand low-power video cores. We propose a memory and communication centric design methodology to reach an energy-efficient dedicated implementation. First, memory optimizations are combined with algorithmic tuning. Then, a partitioning exploration introduces parallelism using a cyclo-static dataflow model that also expresses implementation-specific aspects of communication channels. Towards hardware, these channels are implemented as a restricted set of communication primitives. They enable an automated RTL development strategy for rigorous functional verification. The FPGA/ASIC design of an MPEG- 4 Simple Profile video codec demonstrates the methodology. The video pipeline exploits the inherent functional parallelism of the codec and contains a tailored memory hierarchy with <b>burst</b> <b>accesses</b> to external memory. 4 CIF encoding at 30 fps, consumes 71 mW in a 180 nm, 1.62 V UMC technology.|$|R
40|$|The Chidi {{system is}} a PCI-bus media {{processor}} card which performs its processing tasks on a large fieldprogrammable gate array (Altera 10 K 100) {{in conjunction with a}} general purpose CPU (PowerPC 604 e). Special address-generation and buffering logic (also implemented on FPGAs) allows the reconfigurable processor to share a local bus with the CPU, turning <b>burst</b> <b>accesses</b> to memory into continuous streams and converting between the memory's 64 -bit words and the media data types. In this paper we present the design requirements for the Chidi system, describe the hardware architecture, and discuss the software model for its use in media processing. Keywords: video compression, field-programmable gate array, data-flow computing, digital signal processing 1. INTRODUCTION Now that field-programmable gate arrays (FPGAs) have reached gate densities at which they can perform useful computational tasks, particularly in certain mathematical and signal-processing domains, they are increasingly bein [...] ...|$|R
40|$|The higher {{resolutions and}} new {{functionality}} of video applications increase their throughput and processing requirements. In contrast, {{the energy and}} heat limitations of mobile devices demand low-power video cores. We propose a memory and communication centric design methodology to reach an energy-efficient dedicated implementation. First, memory optimizations are combined with algorithmic tuning. Then, a partitioning exploration introduces parallelism using a cyclo-static dataflow model that also expresses implementation-specific aspects of communication channels. Towards hardware, these channels are implemented as a restricted set of communication primitives. They enable an automated RTL development strategy for rigorous functional verification. The FPGA/ASIC design of an MPEG- 4 Simple Profile video codec demonstrates the methodology. The video pipeline exploits the inherent functional parallelism of the codec and contains a tailored memory hierarchy with <b>burst</b> <b>accesses</b> to external memory. 4 CIF encoding at 30 fps, consumes 71 mW in a 180 nm, 1. 62 V UMC technology. </p...|$|R
40|$|Abstract: Now days, DDR SDRAM (Double Data Rate Synchronous Dynamic Random Access Memory) {{has become}} the most popular class of memory used in {{computers}} due to its high speed, <b>burst</b> <b>access</b> and pipeline feature. For high speed applications like image/video processing, signal processing, networking etc. DDR SDRAM is widely used. The basic operations of DDR SDRAM controller are similar to that of SDR (Single Data Rate) SDRAM; however there is a difference in the circuit design; DDR simply use sophisticated circuit techniques to achieve high speed. To perform more operations per clock cycle DDR SDRAM uses double data rate architecture. DDR SDRAM (also known as DDR) transfers data on both the rising and falling edge of the clock. The DDR controller is designed with objective of proper commands for SDRAM initialization, read/write accesses, regular refresh operation, proper active and precharge command etc. DDR SDRAM controller is implemented using Verilog HDL and simulation and synthesis is done by using Modelsim and Xilinx ISE accordingly...|$|R
40|$|SAN-level caching {{can manage}} caching within a global view so that global hot {{data can be}} {{identified}} and cached. However, two problems may be encountered in the existing SAN-level caching methods: first, too many migrations from disks to cache resulting from cache thrashing; second, too few cache hits resulting from insufficient caching. This paper proposes a SAN-level caching method employing chunk-aging to control the migrations of chunks of data from disks to cache, which takes the temporal distribution of chunk accesses into account and solves the two problems above. Then by employing two LRU lists to manage the cache replacement, this method separates and manages two types of hot data chunks, one of which have <b>burst</b> <b>accesses</b> and the other have long-term frequent accesses, thus preventing them from interfering {{with each other in}} cache. The simulation results demonstrate that our method can achieve a high hit ratio while maintaining a relatively low migration rate. 1...|$|R
50|$|The 4000 I/O {{design is}} based around having {{a number of}} Input/Output Processors known as IOPs, each of which {{interfaces}} between the store {{and a set of}} I/O controllers. The IOPs are controlled by the Nucleus function in the CPU, but once an I/O event is triggered, they operate autonomously without interaction with the CPU until the I/O completes. The Normal Interface IOPs can each support up to 255 or 256 simultaneous I/O operations, each on a separate Way. The I/O controllers on each IOP would each occupy one or more Ways, depending on how many simultaneous I/O operations they need to handle. The IOP polices each Way's access to main store, allowing only access to successive memory locations defined for the I/O operation that Way is currently performing. The earlier IOPs performed 8-bit and 16-bit wide store <b>accesses,</b> with a <b>burst</b> mode for doing up to 8 transfers together for higher throughput I/O controllers. The later IOPs added 32-bit wide store accesses.|$|R
