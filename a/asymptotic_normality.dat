3438|74|Public
25|$|<b>Asymptotic</b> <b>normality,</b> that is, {{convergence}} to {{the normal}} distribution after appropriate shift and rescaling, is a phenomenon much more general than the classical framework treated above, namely, sums of independent random variables (or vectors). New frameworks are revealed from time to time; no single unifying framework is available for now.|$|E
2500|$|The {{assumption}} [...] {{cannot be}} omitted, since the <b>asymptotic</b> <b>normality</b> fails for [...] where [...] are another stationary sequence.|$|E
2500|$|This maximum log {{likelihood}} {{can be shown}} to be the same for more general least squares, even for non-linear least squares. [...] This is often used in determining likelihood-based approximate confidence intervals and confidence regions, which are generally more accurate than those using the <b>asymptotic</b> <b>normality</b> discussed above.|$|E
40|$|We {{study the}} nonparametric estimators of the infinitesimal {{coefficients}} of the second-order jump-diffusion models. Under the mild conditions, we obtain the weak consistency and the <b>asymptotic</b> <b>normalities</b> of the estimators. Comment: This paper has been withdrawn {{since there are}} many mistakes in the proo...|$|R
40|$|Motivated by {{normalizing}} DNA microarray {{data and}} by predicting the interest rates, we explore nonparametric estimation of additive models with highly correlated covariates. We introduce two novel approaches for estimating the additive components, integration estimation and pooled backfitting estimation. The former {{is designed for}} highly correlated covariates, and the latter is useful for nonhighly correlated covariates. <b>Asymptotic</b> <b>normalities</b> of the proposed estimators are established. Simulations are conducted to demonstrate finite sample behaviors of the proposed estimators, and real data examples are given to illustrate {{the value of the}} methodology. 1. Introduction. Th...|$|R
40|$|Local <b>asymptotic</b> mixed <b>normality</b> (LAMN) of a {{class of}} {{transformed}} Gaussian models for discretely observed random fields is proved. The original Gaussian random field {{is assumed to be}} the product of a deterministic process and a process with independent increments. The transformed process is observed only on discrete lattice points in the unit cube and fixed domain asymptotics is investigated. This model is useful for modeling random fields with non-Gaussian marginal distributions. Brownian sheet Discrete observation Fixed domain asymptotics Local <b>asymptotic</b> mixed <b>normality</b> Multiparameter process Ornstein-Uhlenbeck sheet Random field Transformed Gaussian model...|$|R
2500|$|In a {{wide range}} of situations, maximum {{likelihood}} parameter estimates exhibit <b>asymptotic</b> <b>normality</b> – that is, they are equal to the true parameters plus a random error that is approximately normal (given sufficient data), and the error's variance decays as 1/n. For this property to hold, it is necessary that the estimator does not suffer from the following issues: ...|$|E
50|$|Barndorff-Nielson & Cox {{provide a}} direct {{definition}} of <b>asymptotic</b> <b>normality.</b>|$|E
50|$|In statistics, local <b>asymptotic</b> <b>normality</b> is a {{property}} of {{a sequence of}} statistical models, which allows this sequence to be asymptotically approximated by a normal location model, after a rescaling of the parameter. An important example when the local <b>asymptotic</b> <b>normality</b> holds is {{in the case of}} iid sampling from a regular parametric model.|$|E
40|$|This {{paper is}} {{concerned}} with the estimation of a varying-coefficient partially linear regression model that is frequently used in statistical modeling. We first construct estimators of the parametric components and the error variance by a wavelet procedure and establish their <b>asymptotic</b> <b>normalities</b> under weaker conditions than those assumed in the previous literature. Then we propose appropriate estimators for the functions characterizing the nonlinear part of the model and derive their convergence rates. Furthermore, we present consistent estimators for the asymptotic (co) variances of the parametric components and error variance estimators as well. These results {{can be used to make}} asymptotically valid statistical inference. Department of Applied Mathematic...|$|R
40|$|This paper {{develops}} a partially linear regression-based {{test for the}} weak unbiased forward pre-mium (WUFP) hypothesis. Assuming both long memory and conditional heteroscedasticity in the error process of the regression model, <b>asymptotic</b> <b>normalities</b> of both estimators for the parametric and nonparametric parts of the regression function are obtained, and the WUFP hypothesis is tested {{by means of a}} χ 2 -statistics. Using daily spot exchange rates and one-, three- and six-months forward rates for Euro, British pound, Japanese yen and Canadian dollar (rates are US dollars per unit of foreign currency), the WUFP hypothesis is investigated under both a simple linear and a partially linear regression model. Results obtained are compared and discussed...|$|R
40|$|Master of ScienceDepartment of StatisticsWeixing SongThere {{has been}} a {{continuing}} interest among statisticians in the problem of regression models wherein the independent variables are measured with error and there is considerable literature on the subject. In the following report, we discuss the errors-in-variables regression model: yi = β 0 + β 1 xi + β 2 zi + ϵi,Xi = xi + ui,Zi = zi + vi with i. i. d. errors (ϵi, ui, vi), for i = 1, 2, [...] ., n and find the least square estimators for the parameters of interest. Both weak and strong consistency for the least square estimators βˆ 0, βˆ 1, and βˆ 2 of the unknown parameters β 0, β 1, and β 2 are obtained. Moreover, under regularity conditions, the <b>asymptotic</b> <b>normalities</b> of the estimators are reported...|$|R
5000|$|For {{a general}} {{distribution}} F with a continuous non-zero density at F −1(p), a similar <b>asymptotic</b> <b>normality</b> applies: ...|$|E
50|$|Local <b>asymptotic</b> <b>normality</b> is a {{generalization}} of the Central Limit Theorem. It is a property of {{a sequence of}} statistical models, which allows this sequence to be asymptotically approximated by a normal location model, after a rescaling of the parameter. An important example when the local <b>asymptotic</b> <b>normality</b> holds is {{in the case of}} iid sampling from a regular parametric model; this is just the Central Limit Theorem.|$|E
5000|$|The {{assumption}} [...] {{cannot be}} omitted, since the <b>asymptotic</b> <b>normality</b> fails for [...] where [...] are another stationary sequence.|$|E
40|$|In econometric {{analysis}} of panel data, one always doesn't have {{enough information to}} assure the existence/absence of time effects, {{which can lead to}} wrong conclusions in statistical inference such as moment estimation and hypothesis testing. In this paper, estimation of second and fourth order moments of the individual effects and the errors are studied for linear panel data models without information on the existence/absence of time effects. With differences of the residuals over the individual index, the orthogonality-based moment estimators of the random individual effects and the errors are respectively obtained without affecting each other. These moment estimators are robust on the potential existence of time effects. Their <b>asymptotic</b> <b>normalities</b> are obtained under some moment conditions. Monte Carlo simulations are carried out for illustration. Estimation of moments Individual effects Linear panel data models Time effects...|$|R
40|$|Kimura and Yoshida treated a {{model in}} which the finite {{variation}} part of a two-dimensional semimartingale is expressed by time-integration of latent processes. They proposed a correlation estimator between the latent processes and proved its consistency and <b>asymptotic</b> mixed <b>normality.</b> In this paper, we discuss the confidence interval of the correlation estimator to detect the correlation. ...|$|R
40|$|The {{adaptive}} varying-coefficient partially {{linear regression}} (AVCPLR) model is proposed {{by combining the}} nonparametric regression model and varying-coefficient regression model with different smoothing variables. It {{can be seen as}} a generalization of the varying-coefficient partially linear regression model, and it is also an example of a generalized structured model as defined by Mammen and Neilsen [Mammen, E., Nielsen, J. P., 2003. Generalised structured models. Biometrika 90, 551 - 566]. Based on the local linear technique and the marginal integrated method, the initial estimators of these unknown functions are obtained, each of which has big variance. To decrease the variances of these initial estimators, the one-step backfitting technique proposed by Linton [Linton, O. B., 1997. Efficient estimation of additive nonparametric regression models. Biometrika 82, 93 - 100] is used to obtain the efficient estimators of all unknown functions for the AVCPLR model, and their <b>asymptotic</b> <b>normalities</b> are studied. Two simulated examples are given to illustrate the AVCPLR model and the proposed estimation methodology. ...|$|R
50|$|In more {{complicated}} cases, {{it is impossible}} to construct exact pivots. However, having approximate pivots improves convergence to <b>asymptotic</b> <b>normality.</b>|$|E
50|$|On a {{conjecture}} in {{geometric probability}} regarding <b>asymptotic</b> <b>normality</b> of a random simplex, Annals of Probability, 10, 247 - 251, (1982).|$|E
50|$|Thus, the {{definition}} of the local <b>asymptotic</b> <b>normality</b> is satisfied, and we have confirmed that the parametric model with iid observations and twice continuously differentiable likelihood has the LAN property.|$|E
40|$|In this thesis, {{for several}} {{important}} high-dimensional problems where the dimension is large {{in comparison with}} the sample size, new methodologies are investigated with new limiting results and meaningful applications. In the first problem, I generalise two simple but effective procedures, the determinant-based and trace-based criteria, to general populations for high-dimensional classification. Their asymptotic misclassification probabilities are derived using the theory of large dimensional random matrices. One of main results is that the misclassification probability cannot vanish even if the sample size become very large for some situations. The performance of these two criteria are explored for various structures of mean vector and covariance. In the second problem, I study the question of testing independence between two large sets of variates. The main application here is to infer gene regulatory networks from gene expression data for normal and diseased populations, respectively. The networks are constructed by testing independence between pairs of genes and the test statistic is constructed from trace of a suitable large random matrix. Compared to traditional statistical methods, this new method successfully identifies important connections of genes in normal and diseased samples, respectively. In the third problem, I develop new statistical theory for probabilistic principal component analysis models in high dimensions. An accurate estimator of the noise variance is proposed. By using random-matrix theory, the <b>asymptotic</b> <b>normalities</b> of this estimator are established for Gaussian and non-Gaussian cases, respectively. In addition, based on this new estimator of noise variance, I develop several important applications including constructing new criterion of determining the number of principal components and deriving new asymptotics for the related goodness-of-fit statistic. In the last problem, I propose new tests to detect the existence of heteroscedasticity in high-dimensional linear regression. Using the theory of random Haar orthogonal matrices, the <b>asymptotic</b> <b>normalities</b> of statistics are obtained under the null and the assumption that the degree of freedom of model tends to infinity. These new tests are dimension-proof, which guarantees a wide applicability of them to different combinations of sample size and dimension. Extensive Monte-Carlo experiments and real data analyses demonstrate the superiority of our proposed tests over traditional methods in terms of size and power. published_or_final_versionStatistics and Actuarial ScienceDoctoralDoctor of Philosoph...|$|R
40|$|In Quantum Non Demolition measurements, the {{sequence}} of observations is distributed as a mixture of multinomial random variables. Parameters of the dynamics are naturally encoded into this family of distributions. We show the local <b>asymptotic</b> mixed <b>normality</b> of the underlying statistical model and {{the consistency of the}} maximum likelihood estimator. Furthermore, we prove the asymptotic optimality of this estimator as it saturates the usual Cramér Rao bound...|$|R
40|$|AbstractIt {{is shown}} here that Bahadur's [Ann. Math. Statist. (1966) 37, 577 – 580] almost sure (a. s.) {{asymptotic}} {{representation of a}} sample quantile for independent and identically distributed random variables holds under certain regularity conditions for a general class of stationary multivariate autoregressive processes. This yields the <b>asymptotic</b> (multi-) <b>normality</b> of the standardized forms of quantiles in autoregressive processes. Other useful applications will be considered in a subsequent paper...|$|R
5000|$|Lancastershows the {{connections}} among the binomial, normal, and chi-squared distributions, as follows. De Moivre and Laplace established that a binomial distribution could {{be approximated by}} a normal distribution. Specifically they showed the <b>asymptotic</b> <b>normality</b> of the random variable ...|$|E
5000|$|Within {{the local}} <b>asymptotic</b> <b>normality</b> framework, {{it is assumed}} that the value of the “true parameter” in the model varies {{slightly}} with n, such that the n-th model corresponds to [...] This approach lets us study the regularity of estimators.|$|E
5000|$|<b>Asymptotic</b> <b>normality</b> is {{a useful}} property, as {{it allows us to}} {{construct}} confidence bands for the estimator, and conduct different tests. Before we can make a statement about the asymptotic distribution of the GMM estimator, we need to define two auxiliary matrices: ...|$|E
40|$|AbstractLocal <b>asymptotic</b> mixed <b>normality</b> (LAMN) of a {{class of}} {{transformed}} Gaussian models for discretely observed random fields is proved. The original Gaussian random field {{is assumed to be}} the product of a deterministic process and a process with independent increments. The transformed process is observed only on discrete lattice points in the unit cube and fixed domain asymptotics is investigated. This model is useful for modeling random fields with non-Gaussian marginal distributions...|$|R
40|$|We {{study the}} {{asymptotic}} behaviour of the cross-variation of two-dimensional processes having {{the form of}} a Young integral with respect to a fractional Brownian motion of index H 1 / 2. When H is smaller than or equal to 3 / 4, we show <b>asymptotic</b> mixed <b>normality.</b> When H is strictly bigger than 3 / 4, we obtain a limit that is expressed in terms of the difference of two independent Rosenblatt processes. Comment: 15 page...|$|R
40|$|AbstractPrincipal {{component}} analysis (PCA) {{is one of}} the key techniques in functional data analysis. One important feature of functional PCA is that there is a need for smoothing or regularizing of the estimated principal component curves. Silverman’s method for smoothed functional principal {{component analysis}} is an important approach in a situation where the sample curves are fully observed due to its theoretical and practical advantages. However, lack of knowledge about the theoretical properties of this method makes it difficult to generalize it to the situation where the sample curves are only observed at discrete time points. In this paper, we first establish the existence of the solutions of the successive optimization problems in this method. We then provide upper bounds for the bias parts of the estimation errors for both eigenvalues and eigenfunctions. We also prove functional central limit theorems for the variation parts of the estimation errors. As a corollary, we give the convergence rates of the estimations for eigenvalues and eigenfunctions, where these rates depend on both the sample size and the smoothing parameters. Under some conditions on the convergence rates of the smoothing parameters, we can prove the <b>asymptotic</b> <b>normalities</b> of the estimations...|$|R
50|$|This maximum log {{likelihood}} {{can be shown}} to be the same for more general least squares, even for non-linear least squares. This is often used in determining likelihood-based approximate confidence intervals and confidence regions, which are generally more accurate than those using the <b>asymptotic</b> <b>normality</b> discussed above.|$|E
50|$|<b>Asymptotic</b> <b>normality,</b> that is, {{convergence}} to {{the normal}} distribution after appropriate shift and rescaling, is a phenomenon much more general than the classical framework treated above, namely, sums of independent random variables (or vectors). New frameworks are revealed from time to time; no single unifying framework is available for now.|$|E
50|$|These {{confidence}} interval estimates {{assume that the}} data {{from all of the}} tasks combine to be approximately normal (see <b>asymptotic</b> <b>normality).</b> Typically, there would need to be 20 - 30 tasks for this to be reasonable, and each of the estimates E for the individual tasks would have to be unbiased.|$|E
40|$|In this paper, {{we study}} the {{estimation}} of the unbalanced panel data partially linear models with a one-way error components structure. A weighted semiparametric least squares estimator (WSLSE) is developed using polynomial spline approximation and least squares. We show that the WSLSE is asymptotically more efficient than the corresponding unweighted estimator for both parametric and nonparametric components of the model. This is a significant improvement over previous results in the literature which showed that the simply weighting technique can only improve {{the estimation of}} the parametric component. The <b>asymptotic</b> <b>normalities</b> of the proposed WSLSE are also established. Another focus {{of this paper is}} to provide a variable selection procedure to select significant covariates in the parametric part, based on a combination of the nonconcave penalization and the weighted semiparametric least squares. The proposed procedure simultaneously selects significant covariates and estimates unknown parameters. With a proper choice of regularization parameters and penalty function, the resulted estimator is shown to possess an oracle property. Simulation studies and an example of application on a set of hormone data are used to demonstrate this proposed procedure. 17 page(s...|$|R
40|$|This paper {{concerns}} {{linear regression}} with interval censored data. M-estimators for the regression coefficients are derived. <b>Asymptotic</b> consistency and <b>normality</b> of the M-estimators are obtained via an exponential inequality for U-statistics. Asymptotically efficient estimators are provided under mild conditions. 1. Introduction. Conside...|$|R
40|$|We study {{statistical}} models for one-dimensional diffusions which are recurrent null. A first parameter in the drift {{is the principal}} one, and determines regular varying rates of convergence for the score and the information process. A finite number of other parameters, of secondary importance, introduces additional flexibility for the modelization of the drift, and does not perturb the null recurrent behaviour. Under time-continuous observation we obtain local <b>asymptotic</b> mixed <b>normality</b> (LAMN), state a local asymptotic minimax bound, and specify asymptotically optimal estimators...|$|R
