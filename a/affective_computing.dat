654|21|Public
25|$|<b>Affective</b> <b>computing</b> devices, {{typically}} with {{image or}} voice recognition capabilities, {{have been proposed}} to help autistic individuals improve their social communication skills. These devices are still under development. Robots have also been proposed as educational aids for autistic children.|$|E
25|$|The College of Computer Studies Center for Empathic Human-Computer Interactions {{specializes in}} <b>affective</b> <b>computing,</b> {{a study that}} seeks to create {{machines}} capable of reacting to human emotions. The center is funded by the Philippine Department of Science and Technology. Emotion recognition (including laughter recognition), behavior prediction {{and the influence of}} music to emotion are among the center's research, many of which are in collaboration with Osaka University. The center, also in collaboration with Osaka, is the first one that constructed an empathic computing space in the Philippines.|$|E
25|$|Research {{is mainly}} {{funded by the}} De La Salle University Science Foundation. Since 2000, DLSU has been the CHED Zonal Research Center for 10 cities in {{southern}} Metro Manila. As such, it evaluates research proposals for recommendation for CHED funding, monitors CHED-funded research papers, among others. DLSU {{research has focused on}} <b>affective</b> <b>computing</b> and renewable energy. Application of its research has resulted in the electrification of remote areas in the country through the use of micro hydro generators, and the creation of the first two solar cars of the Philippines, SINAG and SIKAT.|$|E
50|$|Borrowing {{theatrical}} terminology, each interaction session {{between the}} synthetic characters in RRL {{is called a}} scene. A scene description specifies the content, timing, and emotional features employed within a scene. A specific module called the <b>affective</b> reasoner <b>computes</b> the emotional primitives involved in the scene, including the type {{and the intensity of}} the emotions, as well as their causes. The affective reasoner uses emotion dimensions such as intensity and assertiveness.|$|R
40|$|Abstract. Facial {{expressions}} are {{an important}} aspect in <b>affective</b> social <b>computing.</b> They express internal states of robots during social interactions. In this paper we present the use of Scherer’s psychological theory to express facial emotions. This theory {{has the advantage of}} linking cognitive and emotional processes. We have implemented a part of this theory on a robot: iCat. We present results by comparing several representations of the same emotions. ...|$|R
40|$|Our {{states of}} mind keep on {{changing}} all the time. How do we determine a mapping between our {{states of mind}} and music stimulus? In this report, we discuss, from a bird’s eye view, the meanings and effects of music which are impressed upon us. We review related literature in musical meanings and computational model, and finally we discuss the impression while listening to the fourth movement of the Pastoral. We point out challenges and suggest plausible computational approches to the <b>affective</b> music <b>computing...</b>|$|R
2500|$|<b>Affective</b> <b>computing</b> is {{the study}} and {{development}} of systems that can recognize, interpret, process, and simulate human affects. It is an interdisciplinary field spanning computer sciences, psychology, and cognitive science. While {{the origins of the}} field may be traced {{as far back as the}} early philosophical inquiries into emotion, the more modern branch of computer science originated with Rosalind Picard's 1995 paper on [...] "affective computing". A motivation for the research is the ability to simulate empathy, where the machine would be able to interpret human emotions and adapts its behavior to give an appropriate response to those emotions.|$|E
50|$|The <b>Affective</b> <b>Computing</b> Engine of Turing OS enables robots to {{have the}} same ability to {{demonstrate}} affection as humans. The Turing OS develops a mature <b>affective</b> <b>computing</b> engine for robots, which assists robots in understanding and expressing human emotions. The <b>affective</b> <b>computing</b> engine of the Turing OS has two components: human emotion recognition and human-like emotion expression.|$|E
50|$|Text {{has been}} used to detect {{emotions}} in the related area of <b>affective</b> <b>computing.</b> Text based approaches to <b>affective</b> <b>computing</b> have been used on multiple corpora such as students evaluations, children stories and news stories.|$|E
40|$|Abstract — This work {{reports a}} {{electrocardiograph}} and skin conductivity hardware architecture, based on E-textile electrodes, {{attached to a}} wheelchair for <b>affective</b> and physiological <b>computing.</b> Appropriate conditioning circuits and a microcontroller platform that performs acquisition, primary processing, and communication using Bluetooth were designed and implemented. To increase the accuracy and repeatability of the skin conductivity measuring channel, force measurement sensors were attached to the system certifying measuring contact force on the electrode level. Advanced processing including R-wave peak detector, adaptive filtering and autonomic nervous system analysis based on wavelets transform was designed and implemented on a server. A central design of affective recognition and biofeedback system is described...|$|R
40|$|This work {{reports a}} {{electrocardiograph}} and skin conductivity hardware architecture, based on E-textile electrodes, {{attached to a}} wheelchair for <b>affective</b> and physiological <b>computing.</b> Appropriate conditioning circuits and a microcontroller platform that performs acquisition, primary processing, and communication using Bluetooth were designed and implemented. To increase the accuracy and repeatability of the skin conductivity measuring channel, force measurement sensors were attached to the system certifying measuring contact force on the electrode level. Advanced processing including Rwave peak detector, adaptive filtering and autonomic nervous system analysis based on wavelets transform was designed and implemented on a server. A central design of affective recognition and biofeedback system is described. Fundação para a Ciência e a Tecnologia (FCT...|$|R
40|$|The {{effect of}} driver's {{physiological}} and psychological characteristics on traffic safety is represented mainly as driver's propensity. Previous researches focus mostly on psychology test {{and its influence}} on traffic safety from relative static and macroscopic perspective. However, {{in the field of}} vehicle active safety, there are few studies on driver's <b>affective</b> measurement and <b>computing</b> from microcosmic and dynamic perspective, and previous researchers did not consider the influence of environment. The emphasis is about situation factors which directly influence driver's affection in all environment factors under two-lane condition. Various experiments are designed to collect driver's microdynamic information, and characteristics of driver's propensity toward different environments are extracted using genetic simulated annealing algorithm. Results show that the method can provide a basis to establish dynamic recognition model of driver's propensity further which is adapted to multilane environment...|$|R
5000|$|Picard is a {{researcher}} {{in the field}} of <b>affective</b> <b>computing</b> and the {{founder and director of the}} <b>Affective</b> <b>Computing</b> Research Group at the MIT Media Lab. The <b>Affective</b> <b>Computing</b> Research Group develops tools, techniques, and devices for sensing, interpreting, and processing emotion signals that drive state-of-the-art systems that respond intelligently to human emotional states. [...] Applications of their research include improved tutoring systems and assistive technology for use in addressing the verbal communications difficulties experienced by individuals with autism.|$|E
50|$|In {{e-learning}} applications, <b>affective</b> <b>computing</b> {{can be used}} {{to adjust}} the presentation style of a computerized tutor when a learner is bored, interested, frustrated, or pleased. Psychological health services, i.e. counseling, benefit from <b>affective</b> <b>computing</b> applications when determining a client's emotional state.|$|E
50|$|It {{has been}} {{computationally}} modelled in an <b>affective</b> <b>computing</b> model.|$|E
40|$|Abstract—In this paper, we {{reflect on}} two observations. The {{first one is}} that sharing {{artifacts}} such as photographs is a powerful and emotionally-rich form of social interaction. The second one is that we all associate emotions to the places that we visit. For these reasons, we are interested to explore new tools for capturing the ambience of neighborhoods and cities. We are also interested to develop ways for people to share these ambiences both on-line and in augmented physical places. We introduce our ideas in this domain and illustrate them with two ongoing projects: AmbiGrabber and Boxes and Lenses. With these systems, {{our goal is to}} create a basic set of technologies {{that will allow us to}} build and experiment with social applications in urban environments. Index Terms—Memories, emotions, <b>affective</b> awareness, mobile <b>computing,</b> ubiquitous computing, digital photography, public displays, augmented communities. I...|$|R
40|$|Creative CommonsAttribution License, which permits {{unrestricted}} use, distribution, {{and reproduction}} in any medium, provided the original work is properly cited. The effect of driver’s physiological and psychological characteristics on traffic safety is represented mainly as driver’s propensity. Previous researches focus mostly on psychology test {{and its influence}} on traffic safety from relative static and macroscopic perspective. However, {{in the field of}} vehicle active safety, there are few studies on driver’s <b>affective</b> measurement and <b>computing</b> frommicrocosmic and dynamic perspective, and previous researchers did not consider the influence of environment. The emphasis is about situation factors which directly influence driver’s affection in all environment factors under two-lane condition. Various experiments are designed to collect driver’s microdynamic information, and characteristics of driver’s propensity toward different environments are extracted using genetic simulated annealing algorithm. Results show that the method can provide a basis to establish dynamic recognition model of driver’s propensity further which is adapted to multilane environment. 1...|$|R
40|$|This paper {{gives an}} {{overview}} of the REsponsive FLExible Collaborating ambienT (REFLECT) project, concerning the developing of new concepts and means for pervasive-adaptive systems. Reflective approach combines different know-how in <b>affective</b> and physiological <b>computing,</b> software engineering, physics and pragmatic expertise into a unique endeavour to design and develop user-centric systems that control the specific environment and react relative to users' emotional, cognitive and physical situation. The central philosophy is to mimic the natural process of adaptation by implementing a biocybernetic loop that senses, diagnoses and analyses the user situation in a concrete settings and react accordingly. In a pervasive manner, the approach effectively brings system adaptation into real-life applications, making them sensitive and reactive to human inner states and behaviours. To show how these concepts have been put into practice, the document describes in detail how the s eat adaptation system of the "REFLECTive Comfort Loop" has been developed for in an automotive environment...|$|R
5000|$|While {{working in}} the field of <b>affective</b> <b>computing,</b> Picard {{published}} <b>Affective</b> <b>Computing.</b> MIT's press release for Picard's textbook states, [...] "According to Rosalind Picard, if we want computers to be genuinely intelligent and to interact naturally with us, we must give computers the ability to recognize, understand, even to have and express emotions".|$|E
5000|$|... e-learning, serious games, {{software}} engineering, crisis management, <b>affective</b> <b>computing,</b> cybersecurity, e-Health, personalisation.|$|E
5000|$|<b>Affective</b> <b>Computing</b> -"How new {{technologies}} {{can help people}} better communicate, understand, and respond to affective information." ...|$|E
40|$|The {{inferred}} cost of {{work-related stress}} call for early prevention strategies. In this, {{we see a}} new opportunity for <b>affective</b> and pervasive <b>computing</b> by detecting early warning signs. This paper goes one step toward this goal. A collective of 33 subjects underwent a laboratory stress intervention, while a set of physiological signals was collected. In this paper, we investigate whether affective information related to stress {{can be found in}} the posture channel during office work. Following more recent work in this field, we directly associate features that are derived from the pressure distribution on a chair with affective states. We found that nervous subjects reveal higher variance of movements under stress. Furthermore, we show that a person-independent discrimination of stress from cognitive load is feasible when using pressure data only. A supervised variant of a self-organizing map, which is able to adapt to different patterns of stress responses, reaches an overall accuracy of 73. 75 % with unknown subjects...|$|R
40|$|The circumplex {{structure}} {{derived from}} similarity ratings of affect words {{is assumed to}} be a conceptual representation of affect anchored in semantic knowledge. Recently, it been suggested that this structure is not based on semantic knowledge at all, but may instead reflect a type of episodic knowledge: The degree to which emotions covary in everyday life. In two experience-sampling studies, we compared the semantic and the episodic hypotheses by comparing participants’ similarity ratings to the observed covariations in their own <b>affective</b> experience <b>computed</b> from their momentary reports. In Study 2, participants also provided estimates {{of the degree to which}} their emotions covaried. Evidence from both studies indicate that similarity judgements are related both to semantic and episodic information, indicating that a pure episodic account of similarity ratings, and the mental representation of affect that they reflect, is untenable. Much of the psychological knowledge that we have generated is based on what people tell us in response to the questions we ask. No where is this more true than in research on emotion. We ask participants to judge the similarity of emotion words, the emotional content contained in facial expressions, pictures, or movies, or their own feeling states. Based on what participants can tell us, we infer something about the nature of emotion knowledge, emotional experience, or both, depending on what we think the questions assess. This last inferential step is often where the process of knowledge accumulation breaks down, because researchers do not always agree about which information participants rely upon when making judgements of emotion. The purpose of this paper is to Correspondenc e should be addressed to Lisa Feldman Barrett at the Department of Psychology...|$|R
40|$|Motivated {{by recent}} {{advances}} {{in the area of}} Compo-sitional Distributional Semantic Models (CDSMs), we propose a compositional approach for estimating continuous affective ratings for adjective-noun (AN) and noun-noun (NN) pairs. The ratings are computed for the three basic dimensions of continuous affective spaces, namely, valence, arousal and dominance. We propose that similarly to the semantic modification that underlies CDSMs, affective modification may occur within the framework of affec-tive spaces, especially when the constituent words of the linguistic structures under investigation form modifier-head pairs (e. g., AN and NN). The affective content of the entire structure is determined from the interaction between the respective constituents, i. e., the affect conveyed by the head is altered by the modifier. In addition, we investigate the fusion of the proposed model with the semantic-affective model proposed in (Malandrakis et al., 2013) applied both at word-and phrase-level. The automatically <b>computed</b> <b>affective</b> ratings were evaluated against human ratings in terms of correlation. The most accurate estimates are achieved via fusion and absolute performance improvement up to 5 % and 4 % is reported for NN and AN, respectively...|$|R
50|$|<b>Affective</b> <b>computing</b> is {{also being}} applied to the {{development}} of communicative technologies for use by people with autism.|$|E
50|$|Mainstream <b>affective</b> <b>computing,</b> as it {{has been}} {{characterized}} above, is critically discussed, e.g., within the field of human-computer interaction.|$|E
5000|$|Novel {{methods to}} support and enhance social interaction, {{including}} innovative ideas like social orthotics, <b>affective</b> <b>computing,</b> and experience capture.|$|E
40|$|In {{this paper}} we {{introduce}} ALMA – A Layered Model of Affect. It integrates three major affective characteristics: emotions, moods and personality that cover short, medium, {{and long term}} affect. The use of this model consists of two phases: In the preparation phase appraisal rules and personality profiles for characters must be specified {{with the help of}} AffectML – our XML based affect modeling language. In the runtime phase, the specified appraisal rules are used to compute real-time emotions and moods as results of a subjective appraisal of relevant input. The <b>computed</b> <b>affective</b> characteristics are represented in AffectML and can be processed by sub-sequent modules that control the cognitive processes and physical behavior of embodied conversational characters. ALMA is part of the VirtualHuman project which develops interactive virtual characters that serve as dialog partners with human-like conversational skills. ALMA provides our virtual humans with a personality profile and with real-time emotions and moods. These are used by the multimodal behavior generation module to enrich the lifelike and believable qualities...|$|R
40|$|REFLECT project {{aimed at}} {{developing}} new concepts and means for pervasive-adaptive systems. The "reflective approach" puts together different know-hows in <b>affective</b> and physiological <b>computing,</b> software engineering, physics and pragmatic expertise into a unique endeavour {{to design and}} develop user-centric systems that control the specific environment and react relative to users' emotional, cognitive and physical situation. REFLECT's core philosophy is to mimic the natural process of adaptation by implementing a biocybernetic loop that senses, diagnoses and analyses the user situation in a concrete settings and reacts accordingly. To show how these concepts have been put into practice, the document describes in detail how the seat adaptation system of the "Comfort Loop" has been developed in an automotive environment. After giving {{a brief overview of}} the project as a whole, the paper deals with the definition of sitting comfort and discomfort, then it presents the idea of the seat adaptation system, whose implementation in a real environment is extensively reported together with the description and discussion of the experimental phase. In the last section comments from the final review process are reported, and new lines of research deploying REFLECT findings are outlined...|$|R
40|$|<b>Affective</b> and human-centered <b>computing</b> have {{attracted}} {{an abundance of}} attention during the past years, mainly due to the abundance of environments and applications able to exploit and adapt to multimodal input from the users. The combination of facial expressions with prosody information allows us to capture the users' emotional state in an unintrusive manner, relying on the best performing modality in cases where one modality suffers from noise or bad sensing conditions. In this paper, we describe a multi-cue, dynamic approach to detect emotion in naturalistic video sequences, where input is taken from nearly real world situations, contrary to controlled recording conditions of audiovisual material. Recognition is performed via a recurrent neural network, whose short term memory and approximation capabilities cater for modeling dynamic events in facial and prosodic expressivity. This approach also differs from existing work in that it models user expressivity using a dimensional representation, instead of detecting discrete 'universal emotions', which are scarce in everyday human-machine interaction. The algorithm is deployed on an audiovisual database which was recorded simulating human-human discourse and, therefore, contains less extreme expressivity and subtle variations {{of a number of}} emotion labels. Results show that in turns lasting more than a few frames, recognition rates rise to 98 %. © OpenInterface Association 2009...|$|R
50|$|Picard is {{credited}} with starting the branch of computer science known as <b>affective</b> <b>computing</b> {{with the publication of}} <b>Affective</b> <b>Computing.</b> This book described the importance of emotion in intelligence, the vital role human emotion communication has to relationships between people, and the possible effects of emotion recognition by robots and wearable computers. Her work in this field has led to an expansion into autism research and developing devices that could help humans recognize nuances in human emotions.|$|E
5000|$|Rosalind Picard - {{professor}} of media {{arts and sciences}} at MIT, director of the <b>Affective</b> <b>Computing</b> Research Group at the MIT Media Lab ...|$|E
50|$|To summarize, Picard and her adherents {{pursue a}} cognitivist {{measuring}} approach to users' affect, while the interactional perspective endorses a pragmatist approach that views (emotional) experience as inherently referring to social interaction. While the Picardian approach, thus, focuses on human-machine relations, interactional <b>affective</b> <b>computing</b> focuses primarily on computer-mediated interpersonal communication. And while the Picardian approach {{is concerned with}} the measurement and modeling of physiological variables, interactional <b>affective</b> <b>computing</b> is concerned with emotions as complex subjective interpretations of affect, arguing that emotions, not affect, are at stake {{from the point of view}} of technology users.|$|E
40|$|Abstract. <b>Affective</b> and human-centered <b>computing</b> have {{attracted}} {{a lot of}} attention during the past years, mainly due to the abundance of devices and environments able to exploit multimodal input from the part of the users and adapt their functionality to their preferences or individual habits. In the quest to receive feedback from the users in an unobtrusive manner, the combination of facial and hand gestures with prosody information allows us to infer the users’ emotional state, relying on the best performing modality in cases where one modality suffers from noise or bad sensing conditions. In this paper, we describe a multi-cue, dynamic approach to detect emotion in naturalistic video sequences. Contrary to strictly controlled recording conditions of audiovisual material, the proposed approach focuses on sequences taken from nearly real world situations. Recognition is performed via a ‘Simple Recurrent Network’ which lends itself well to modeling dynamic events in both user’s facial expressions and speech. Moreover this approach differs from existing work in that it models user expressivity using a dimensional representation of activation and valence, instead of detecting discrete ‘universal emotions’, which are scarce in everyday human-machine interaction. The algorithm is deployed on an audiovisual database which was recorded simulating human-human discourse and, therefore, contains less extreme expressivity and subtle variations of a number of emotion labels...|$|R
40|$|<b>Affective</b> and human-centered <b>computing</b> are {{two areas}} related to HCI which have {{attracted}} attention {{during the past}} years. One {{of the reasons that}} this may be attributed to, is the plethora of devices able to record and process multimodal input from the part of the users and adapt their functionality to their preferences or individual habits, thus enhancing usability and becoming attractive to users less accustomed with conventional interfaces. In the quest to receive feedback from the users in an unobtrusive manner, the visual and auditory modalities allow us to infer the users' emotional state, combining information both from facial expression recognition and speech prosody feature extraction. In this paper, we describe a multi-cue, dynamic approach in naturalistic video sequences. Contrary to strictly controlled recording conditions of audiovisual material, the current research focuses on sequences taken from nearly real world situations. Recognition is performed via a 'Simple Recurrent Network' which lends itself well to modeling dynamic events in both user's facial expressions and speech. Moreover this approach differs from existing work in that it models user expressivity using a dimensional representation of activation and valence, instead of detecting the usual 'universal emotions' which are scarce in everyday human-machine interaction. The algorithm is deployed on an audiovisual database which was recorded simulating human-human discourse and, therefore, contains less extreme expressivity and subtle variations of a number of emotion labels. Copyright 2006 ACM...|$|R
40|$|Advances in {{computational}} psychometrics {{and mathematical}} {{methods have been}} gaining {{a significant role in}} both medicine and psychology over these past years. The mainstream in psychometrics is moving towards ever greater use of computational and mathematical modeling techniques. Such techniques are critical in the emerging fields of <b>affective</b> and wearable <b>computing,</b> where new biomedical instruments available both in the laboratory and in the field are allowing for deeper understanding of human psychology. These experimental methods offer new opportunities but also new challenges in data interpretation and analysis. This special issue has two foci, namely, to feature works that (a) advance scientific knowledge in the area of computational psychometrics and (b) explore deep investigated methods, techniques, and instruments for the assessment of cognitive, emotional, and medical (e. g., diagnostic) as well as mental health {{at the cutting edge of}} current technology. There have recently been an increasing number of research initiatives that utilize computational technologies in order to support patients in maintaining or regaining a healthy mental state. Computational psychometrics and related tools have been exploited for assessing, measuring, and defining new methods for an effective and focused psychological intervention. It is of utmost importance to provide people with higher quality of life and also to shift a part of monitoring tasks from therapists and caregivers to unobtrusive technological systems. Efforts have started with Internet-based self-help therapies, but recently systems make an increasing use of computational psychometrics, including ambient intelligence, pervasive computing, smart phones, and sensor systems. Their common goal is to provide effective solutions for maintaining and improving mental health and related assessment...|$|R
