3|10000|Public
40|$|As {{electronic}} business transactions over the Internet become more popular, users and markets pose new requirements on both electronic commerce {{services and the}} applications implementing them. These requirements include support for multiuser business protocols, cooperation among users, and real-time (multimedia) interaction. The development {{of this kind of}} electronic commerce applications is a complex, costly, and time-consuming activity. Electronic commerce middlewares are an approach to support the development of these applications by providing a set of commerce-oriented functionalities that can be integrated into an application. Nonetheless, these platforms provide little support or guidance during the conceptual design of the application. This paper presents Jecom, a new approach to the development of distributed, cooperative electronic commerce applications. Jecom defines an <b>application</b> <b>reference</b> <b>model,</b> based on roles and state transition diagrams; furthermore, the model is dire [...] ...|$|E
40|$|AP Issues Feedback Industrial Need ATS Review AIM Review Report Qualified AIM Develop <b>Application</b> <b>Reference</b> <b>Model</b> (ARM) Develop Application Interpreted Model (AIM) Develop AP Define Conformance Requirements AP Validation Management Reports AP Issues Feedback Abstract Test Suite & Validate Test Requirements Candidate AP Summary Sheet Purposes Validation Test Suite (AAM) Submit AP to Standards Body Report PICS {{proforma}} Conform clause NIIIP Reference Architecture: Concepts and Guidelines NIIIP Reference Architecture Page 24 Cycle 0 Figure 7 : STEP Data Objects STEP Data {{objects are}} supported by a potentially large number of AIM objects. In addition, STEP Data Objects interact with STEP Services. STEP Services represent the applications {{that the members of}} an industrial virtual enterprise use to develop and share product data. The figure shows applications and objects that have been identified in the AAM's and ARM's of AP 203 and AP 210. The [...] ...|$|E
40|$|Due to Taiwan join WTO and quotas cancellation, textile goods faced global competition. With {{the short}} {{life cycle of}} the textile market and demand {{uncertainty}} in market, it leads to increasing pressure on the textile industry. Brand vendors start to search partners and hope to solve these problems through information sharing and collaboration. After sixty-year’s development, textile industry in Taiwan had established a complete supply chain system. Beside, the ROC Government promoted electronic industry in 1999, which assisted textile industry to build the collaborative design platform {{that contributed to the}} textile manufacturers and own brand vendors link each other. Through the concept of the collaborative design, enterprise masters the markets and share information with suppliers immediately to achieve time to market. This study introduced collaborative application deep in Taiwan textile industry. Through literature review on collaboration design, information technology and strategy to build collaborative design <b>application</b> <b>reference</b> <b>model.</b> By the case study, we observe collaboration applied most deeply in apparel industry. Enterprise size has a significant effect in information technology application. Spinning, Dyeing and Apparel industry relate to the selection of materials, pigments and clothing production, so their strategies are early involvement. Finally, we suggested that the textile industry in Taiwan should control the market information, and enhance own knowledge/skills to achieve minimum produce cost with the maximum product value. The study indicated that central manufacturers could maintain competitive in the global market only through collaborative design which integrated the central manufacturers, suppliers, and customers together...|$|E
30|$|Each of the {{standards}} mentioned in Section 2.1 relies on its own <b>model.</b> Metadata <b>reference</b> <b>models</b> are also available in several domains [15, 16, 25]. Adopting the model for one of {{the standards}} leads to a specialization in its <b>application</b> domain. <b>Reference</b> <b>models,</b> on the other hand, are not focused on the repository, having a much broader scope within the organizational workflow.|$|R
5000|$|The <b>Application</b> <b>Reference</b> <b>Models</b> (ARM) is the {{mediator}} between the AAM and the AIM/MIM. Originally its purpose {{was only to}} document high level application objects and the basic relations between them. IDEF1X diagrams documented the AP of early APs in an informal way. The ARM objects, their attributes and relations are mapped to the AIM {{so that it is}} possible to implement an AP. As APs got more and more complex formal methods were needed to document the ARM and so EXPRESS which was originally only developed for the AIM was also used for the ARM. Over time these ARM models got very detailed till to the point that some implementations preferred to use the ARM instead of the formally required AIM/MIM. Today a few APs have ARM based exchange formats standardized outside of ISO TC184/SC4: ...|$|R
40|$|<b>Reference</b> <b>models,</b> {{sometimes}} called with other different words, prepare a general model from a specific {{view of the}} related environment. <b>Reference</b> <b>models</b> are considered as a basic foundation to create: 1) a common language among specialists 2) a reference for the entities such as processes 3) relationships among entities 4) tools and decision making procedures for the real world. In this report, it 2 ̆ 7 s tried the definitions of <b>reference</b> <b>model</b> in the selected papers have been reviewed. It 2 ̆ 7 s noticeable that in many papers the term of framework is used instead of <b>reference</b> <b>model.</b> Also, <b>applications</b> of <b>reference</b> <b>models</b> are reviewed and finally future studies are suggested...|$|R
40|$|In work it is {{considered}} a method of synthesis of the adaptive law of control with <b>application</b> of obvious <b>reference</b> <b>model</b> on a class of flying machines which carry out functions of high-rise aeroplatforms for telecommunication systems. Thus synthesis thus to minimise energy for control. ??????????? ???????????????? ????? ???????????? ??????? ???????????? ?? ?????????????? ?????? ?????????? ???????????????? ????????? ???? ??????? ??????, ??????? ????????? ??????? ???????????? ??? ???????????????????? ?????? (???) ? ?????????????? ????????? ?????? ? ??????? ????????...|$|R
30|$|The three-parameter model {{represents}} {{an example of}} <b>application</b> of the <b>reference</b> <b>model</b> and shows the possibility of further simplification. Indeed, the user can also perform a calculation by setting four to nine variables in Equation 3 (reference model): {{the reliability of the}} estimation increases with the number of customized parameters.|$|R
40|$|Present {{literature}} and expert discussions clearly {{show that the}} term <b>reference</b> <b>model</b> in simulation is not commonly used. Based on work done in the working group "simulation in production and logistics" within ASIM, this paper shows some quite different approaches, to illustrate the wideness of the research field. One approach of the research field, the Fraunhofer <b>Reference</b> <b>Model</b> for simulation, is then explained in more detail, {{and focused on the}} <b>reference</b> <b>model</b> "manufacturing systems". An example illlustrates the <b>application</b> of the <b>reference</b> <b>model...</b>|$|R
40|$|We outline a {{multiple}} dimensional <b>reference</b> <b>model</b> architecture and a methodology for representing and developing intelligent systems. The <b>reference</b> <b>model</b> architecture features multiple dimensions enabling modeling the multiple aspects of complex systems. The canonical form {{within this framework}} facilitates an open and scalable system architecture. The well-defined structures facilitate efficient knowledge engineering processes. We describe a submarine automation model performing real-time control to illustrate the <b>application</b> of this <b>reference</b> <b>model</b> architecture. Keywords: automation, functional decomposition, hierarchical systems, intelligent control, methodology, multiple dimensional architecture, object oriented, task analysis...|$|R
40|$|This work {{presents}} an <b>application</b> of a <b>reference</b> <b>model</b> for product development: a {{ground support equipment}} for an environmental monitoring imager. MUX-EGSE is a product designed on demand to INPE (Brasilian National Institute of Spatial Researches). It is an equipment of electronic tests of a camera which will equip the CBERS 3 & 4 satellite. This <b>reference</b> <b>model</b> was adapted to manage {{the development of this}} product, which is quite diferent from the products commercialized in other lines of the researched company. Pages: 31 - 3...|$|R
40|$|Abstract — <b>Reference</b> <b>models</b> are an {{important}} aid for business process modeling and design. Their aim is to capture domain knowledge and assist {{in the design of}} enterprise specific business processes. The <b>application</b> of <b>reference</b> <b>models</b> for process design requires guidance in reusing these models, as well as flexibility in adapting them to specific enterprises. A popular modeling language for specifying <b>reference</b> <b>models</b> is Event-driven Process Chains (EPC), which has been extended for expressing configurable <b>reference</b> <b>models</b> (C-EPC). These models provide explicit reuse guidance, but allow a limited level of flexibility following a reuse by configuration approach. To increase the level of adaptability of <b>reference</b> <b>models,</b> we propose in this paper to utilize the Application-based Domain Modeling (ADOM) approach for the purpose of specifying and applying <b>reference</b> <b>models</b> using EPC. ADOM supports the enforcement of <b>reference</b> <b>model</b> constraints while allowing a high level of flexibility, adaptability, and variability in the business processes of particular enterprises. The paper presents the syntax and semantics of the proposed approach, called ADOM-EPC, and its specialization and configuration capabilities. ADOM-EPC is evaluated by comparing it to C-EPC, a leading approach for <b>reference</b> <b>modeling</b> and reuse, in terms of expressiveness and comprehensibility. While the expressiveness of ADOM-EPC, namely, its set of specified reuse operations, exceeds that of C-EPC, the understandability of the two types of <b>reference</b> <b>models</b> is similar...|$|R
40|$|Abstract. There are {{increasing}} numbers of systems and research projects involving software agents and mobile agents. However, there is no <b>reference</b> <b>model</b> or conceptual framework to compare the result-ing systems. In this paper, we propose a <b>reference</b> <b>model</b> to identify, classify and evaluate mobile agent systems having a significant set of non-trivial architectural issues and technical and functional features {{in order to support}} agent-based <b>applications.</b> Our proposed <b>reference</b> <b>model</b> describes a generic and global architecture and identifies a set of technical and functional features. The items analyzed include the following: execution, management of agent types, management of identifiers, persistence, navigation, communication, interaction with external resources, and security. We apply this <b>reference</b> <b>model</b> to ana-lyze, compare, and discuss some well-known mobile agent systems: Telescript, Aglets, ffMain, D’Agents...|$|R
40|$|An <b>application</b> of <b>Model</b> <b>Reference</b> Adaptive Control (MRAC) to the {{position}} and force control of flexible manipulators and robots is presented. A single-link flexible manipulator is analyzed. The problem {{was to develop a}} mathematical model of a flexible robot that is accurate. The objective is to show that the adaptive control works better than 'conventional' systems and is suitable for flexible structure control...|$|R
40|$|The <b>application</b> of <b>model</b> <b>referenced</b> {{adaptive}} control theory to an optical tracking telescope is discussed. The {{capability of the}} adaptive technique to compensate for mount irregularities such as inertial variations and bearing friction is demonstrated via field test results on a large tracking telescope. Results are presented which show a 6 to 1 improvement in tracking accuracy for a worst-case satellite trajectory...|$|R
40|$|This <b>Reference</b> <b>Model</b> for Service Oriented Architecture is an {{abstract}} {{framework for understanding}} significant entities and relationships between them within a serviceoriented environment, and {{for the development of}} consistent standards or specifications supporting that environment. It is based on unifying concepts of SOA and may be used by architects developing specific service oriented architectures or in training and explaining SOA. A <b>reference</b> <b>model</b> is not directly tied to any standards, technologies or other concrete implementation details. It does seek to provide a common semantics that can be used unambiguously across and between different implementations. The relationship between the <b>Reference</b> <b>Model</b> and particular architectures, technologies and other aspects of SOA is illustrated in Figure 1. While service-orientation may be a popular concept found in a broad variety of <b>applications,</b> this <b>reference</b> <b>model</b> focuses on the field of software architecture. The concepts and relationships described may apply to other &quot;service &quot; environments; however, this specification makes no attempt to completely account for use outside of the software domain. Status: This document is updated periodically on no particular schedule. Send comments to the editor(s). Committee members should send comments on this specification to the soarm@lists. oasis-open. org list. Others should visit the SOA-RM TC home page a...|$|R
40|$|The Semantics Difficulty Model (SDM) is a {{model that}} {{measures}} the difficult of introducing semantics technology into a company. SDM manages three descriptions of stages, which we will refer to as ?snapshots?: a company semantic snapshot, data snapshot and semantic application snapshot. Understanding a priory the complexity of introducing semantics into a company {{is important because it}} allows the organization to take early decisions, thus saving time and money, mitigating risks and improving innovation, time to market and productivity. SDM works by measuring the distance between each initial snapshot and its <b>reference</b> <b>models</b> (the company semantic snapshots <b>reference</b> <b>model,</b> data snapshots <b>reference</b> <b>model,</b> and the semantic <b>application</b> snapshots <b>reference</b> <b>model)</b> with Euclidian distances. The difficulty level will be "not at all difficult" when the distance is small, and becomes "extremely difficult" when the the distance is large. SDM has been tested experimentally with 2000 simulated companies with arrangements and several initial stages. The output is measured by five linguistic values: "not at all difficult, slightly difficult, averagely difficult, very difficult and extremely difficult". As the preliminary results of our SDM simulation model indicate, transforming a search application into integrated data from different sources with semantics is a "slightly difficult", in contrast with data and opinion extraction applications for which it is "very difficult"...|$|R
40|$|The {{objective}} {{of this paper is}} to demonstrate the feasibility of a Nonlinear Generalized Predictive Control algorithm by showing real-time adaptive control on a plant with relatively fast time-constants. Generalized Predictive Control has classically been used in process control where linear control laws were formulated for plants with relatively slow time-constants. The plant of interest for this paper is a magnetic levitation device that is nonlinear and open-loop unstable. In this <b>application,</b> the <b>reference</b> <b>model</b> of the plant is a neural network that has an embedded nominal linear model in the network weights. The control based on the linear model provides initial stability at the beginning of network training. In using a neural network the control laws are nonlinear and online adaptation of the model is possible to capture unmodeled or time-varying dynamics. Newton-Raphson is the minimization algorithm. Newton-Raphson requires the calculation of the Hessian, but even with this computational expense the low iteration rate make this a viable algorithm for real-time control...|$|R
40|$|In {{order to}} remain competitive, a company must {{organize}} {{the development of}} its new products around an effective and manageable product introduction process (PIP). Frequently, the product introduction process is an ad-hoc collection of separate procedures that follow one after another with responsibility being passed on until a product is eventually produced and introduced into the market. This situation is usually worse in the vital early stages of development before the product has been physically defined. This paper describes the development, industrial testing and validation of a <b>Reference</b> <b>Model,</b> which covers the stages from {{the development of a}} product strategy through to the formal approval of a new product for its detailed design and manufacture. It can be used for the effective management of the fuzzy front end of the new product introduction process. The paper concludes with a discussion of the <b>application</b> of the <b>reference</b> <b>model</b> to a case study company...|$|R
40|$|Abstract—We are {{interested}} in re-engineering families of legacy applications towards using Domain-Specific Languages (DSLs). DSL design is hard because next to language engineering skills it requires a deep and complete understanding of the domain. Is it worth to invest in harvesting domain knowledge from the source code of legacy applications? Reverse engineering domain knowledge from source code is sometimes considered very hard or even impossible. Is it also difficult for “modern legacy systems”? More specifically, {{we would like to}} know if there are opportunities to harvest domain knowledge from high-level object-oriented code. To explore this question, we compare manually recovered domain models of two open-source <b>applications</b> to a <b>reference</b> <b>model</b> extracted from domain literature. The recovered models are accurate: they cover a significan...|$|R
40|$|The first, and {{probably}} the major challenge of Enio, the new Information Technology Director of the university, was, in his own definition, {{the lack of information}} systems (IS) for his institution, mainly in administrative and human resources areas. In his understanding, there was a main IS in operation, supporting the academic area, but just for undergraduate courses and, moreover, what was expected was integration between distinct IS databases: "We had loose coupled systems and still remains such systems throughout the institution". Would be better to develop a new IS or purchase a ready one? Choosing to develop it, what would be the cost and effort? Once opting for the acquisition, how to find the most suitable supplier and IS product for the university? The discussion of these issues offers opportunity for increasing planning and diagnostic skills on the <b>application</b> of <b>reference</b> <b>models</b> for software selection and acquisition, through the description of steps undertaken by managers and directors in a context of major decisions. This theme has potential to promote relevant discussions on subjects such as "IS Management" and "Enterprise Applications" in Business Administration undergraduate and post-graduation courses, and Software Engineering subjects in Computer Science undergraduate courses...|$|R
40|$|Abstract: Several {{factors may}} force {{enterprises}} {{to modify their}} business processes: they are threatened by competition; they need to develop new process solutions to fulfil customer needs; they have to react to organizational change; and more. In order to efficiently change business processes, <b>reference</b> <b>models</b> as sources of to-be business processes that are to bring about economic improvements can be used. While {{in the past the}} <b>application</b> of <b>reference</b> process <b>models</b> would merely provide a new process model without addressing the necessary efforts of changing the technical solutions beneath it, the concept of service-oriented architecture (SOA) may significantly reduce these efforts by aligning services to business activities. The presumed ease of readily deployable business processes will then strongly promote the increased use of <b>reference</b> process <b>models</b> in business process optimization. In order to gain more insights into the potential of using reference processes in an SOA environment we carried out an analysis of a business process improvement scenario. We classified the modification operations of implementing reference processes in the scenario and propose an evaluation method for the implementation effort based on a cost model. ...|$|R
40|$|In Germany {{currently}} {{the development of}} a marine data infrastructure takes place with the aim of merging information concerning the fields coastal engineering, hydrography and surveying, protection of the marine environment, maritime conservation, regional planning and coastal research. This undertaking is embedded in a series of regulations and developments on many administrative levels from which specifications and courses of action derive. To set up a conceptual framework for the marine data infrastructure (MDI-DE) scientists at the Professorship for Geodesy and Geoinformatics at Rostock University are building a <b>reference</b> <b>model,</b> evaluating meta-information systems and developing models to support common workflows in marine <b>applications.</b> The <b>reference</b> <b>model</b> for the marine spatial data infrastructure of Germany (MDI-DE) is the guideline for all developments inside this infrastructure. Because the undertaking is embedded in a series of regulations and developments this paper illustrates an approach on modelling a scenario for the Marine Strategy Framework Directive (MSFD) using the Unified Modelling Language (UML). Evaluating how other countries built their marine spatial infrastructures is of main importance, to learn where obstacles are and errors are likely to occur. To {{be able to look at}} other initiatives from a neutral point of view it is necessary to construct a framework for evaluation of marine spatial data infrastructures. Spatial data infrastructure assessment approaches were used as bases and were expanded to meet the requirements of the marine domain. As an international case-study this paper will look at Canada's Marine Geospatial Data Infrastructure (MGDI), COINAtlantic and GeoPortal...|$|R
40|$|Reliability {{of power}} system {{depends on the}} up to date {{knowledge}} of the system state for operation and control. Shifting from large conventional production units to small and/or renewable DG connected in the distribution network means more control and monitoring system require for the Distributed System operator caused by active generation and reactive power consumption by DG. Therefore {{it is interesting to}} explore concepts in fast and scalable topology processors for monitoring and controlling applications such as state estimation, OPF and static and dynamic stability assessment in electrical distribution network the need is evident to validate with meshed network to analyze the overall performance of the proposed methodology Topology Inference of Electrical Distribution Networks". The topology inference processor is require minimal prior knowledge of electrical network structure by taking a series of time-stamped process measurements from each bays of each substation in the network and distinguished between connected and unconnected bays. This master thesis project has implemented an IEEE reference electric power distribution network in Simulink platform, integrating the reference electrical network with the Java-based multi agent topology inference application as well as having investigated. This project has included work in the real time simulation of a standard IEEE reference distribution network, OPC server interfacing between <b>reference</b> <b>model</b> and the topology inference application, testing and analysis of the <b>application.</b> The <b>reference</b> <b>model</b> is selected to provide a sucient case to analyses and validate the methodology...|$|R
40|$|Several {{synergistic}} trends, subsumed {{under the}} phrase "Internet of things (IoT) " massively drive the increasing importance of networking applications. In the past, the exponential {{growth of the}} Internet was mainly due to semantically agnostic transport protocols. In the future {{it is to be}} expected that, because of the increasing autonomy of technical systems, it becomes necessary to better understand the nature of the semantics of these interaction networks to create appropriate networking applications. Appropriate means that the architecture of these applications allows to minimize the effort to adapt these applications to the permanently changing interaction networks. The proposed interaction oriented architecture is based on a <b>reference</b> <b>model</b> of interaction semantics. It provides guiding principles on how to design networking <b>applications.</b> The <b>reference</b> <b>model</b> of interaction semantics provides: a unifying description of the things in the physical, the information and the human world; an interaction model that is of direct runtime relevance; an understanding for how hierarchical structured components can cooperate loosely coupled; a concept to determine how much semantics has to be common to enable components of different semantic domains to cooperate loosely coupled; and a data type <b>model.</b> The software <b>reference</b> architecture provides: a definition of software layers; means to express vertical interactions, that is interactions which demarcate a software layer; means to express horizontal interactions, that is, between processes in the same software layer; a definition of a component and how to distinguish it from other entities like systems or objects; and a model how to separate reusable from non-reusable parts of an application's functionality...|$|R
40|$|The Internet of Things is a {{hot topic}} for {{development}} and research right now. More and more devices get connected to Internet by the day, but sometimesthe security of Internet of Things is neglected. Xavitech is a manufacturer ofmicropump that is interested in entering {{the world of the}} Internet of Things. This thesis work was done in collaboration with Xavitech and aimed to look athow an Internet of Things implementation for micropump could be designedin a secure manner. The goal was to design a concept application that could beused to calibrate micropumps remotely over the Internet, with primary focuson the security of the in-flight data of the application. When designing thisconcept <b>application,</b> an existing <b>reference</b> <b>model</b> was used as a basis. Acomparison of different protocols suitability for this application was alsoconducted and the most suitable protocol was implemented. The conceptapplication proposed in this thesis {{is an example of how}} a secure Internet ofThings implementation for micropumps can be designed...|$|R
40|$|International audienceRadiation {{protection}} and shielding studies are {{often based on}} the extensive use of 3 D Monte-Carlo neutron and photon transport simulations. ITER organization hence recommends the use of MCNP- 5 code (version 1. 60), {{in association with the}} FENDL- 2. 1 neutron cross section data library, specifically dedicated to fusion <b>applications.</b> The MCNP <b>reference</b> <b>model</b> of the ITER tokamak, the ‘C-lite’, is being continuously developed and improved. This article proposes to develop an alternative model, equivalent to the 'C-lite', but for the Monte-Carlo code TRIPOLI- 4 ®. A benchmark study is defined to test this new model. Since {{one of the most critical}} areas for ITER neutronics analysis concerns the assessment of radiation levels and Shutdown Dose Rates (SDDR) behind the Equatorial Port Plugs (EPP), the benchmark is conducted to compare the neutron flux through the EPP. This problem is quite challenging with regard to the complex geometry and considering the important neutron flux attenuation ranging from 1014 down to 108 n•cm- 2 •s- 1. Such code-to-code comparison provides independent validation of the Monte-Carlo simulations, improving the confidence in neutronic results...|$|R
40|$|Thanks to {{improvement}} in simulation, high resolution scanning facilities and multidimensional medical imaging, {{the size of}} geometrical dataset is rapidly increasing, and huge datasets are commonly available. For this reason, Level-of-Detail (LOD) techniques have been proposed for triangle-based models of terrains and of the boundary of 3 D manifold objects {{in a variety of}} applications. The basic operation that an LOD model needs to support is selective refinement. Selective refinement consists of extracting an adaptive mesh-based representation that satisfies some application-dependent requirements. The extracted representation may have a resolution which is uniform or varies {{in different parts of the}} shape or of the field domain. In this thesis we address the problem of designing LOD data structures for supporting selective refinement. The emphasis of this work is designing and developing compact LOD data structures tailored to specific <b>applications.</b> Our <b>reference</b> LOD <b>model</b> is the Multi-Tessellation, a dimension-independent model based on a collection of modifications organized according to a dependency relation, which guides the extraction of meshes a...|$|R
40|$|This thesis {{proposes a}} <b>reference</b> <b>model</b> and its {{computational}} core {{to support the}} creation of software applications within educational environments, which address Differences In Learning (DiffInL) and are applicable to both learners and instructors. This work differs from others in that {{the strength of this}} model resides on the re-usable character of the reasoning mechanism enabled by the computational environment. The starting point is the definition of agreed learning goals that the learner needs to achieve. In turn, the <b>reference</b> <b>model</b> generates personalised, best-practice teaching and learning materials, suitable for achieving the individual’s learning goals. This <b>reference</b> <b>model</b> consists of MODEL and MANAGEMENT components. The MODEL components store the domain needed to create learners and instructional models, which are required for the creation of Learning Spaces (LeS). The MANAGEMENT compo- nent also manages the semantics stored in various model components in order to carry out the configuration of an LeS. The architecture of software applications generated from the <b>reference</b> <b>model</b> is illustrated and contains: Netbeans IDE 8. 0. 2, JavaServer Faces framework and OWL-API library. We tested this to generate teaching practices for Learning Difficulties (LDif) student. In order to prove the feasibility of creating a software <b>application</b> from the <b>reference</b> <b>model,</b> an example of a particular scenario in a specific educational setting for LDif Students has been shown. This proposed model has successfully proved its ability {{to address the needs of}} LDif Students through a corresponding novel and re-usable reasoning mechanism implemented in Web Ontology Language (OWL) and Semantic Web Rule Language (SWRL) computational environments. The <b>reference</b> <b>model</b> has shown its ability to integrate with different disciplines such as psychology, sociology and human-computer interactions. The main contribution to research is the creation of a novel <b>reference</b> computational <b>model</b> which addresses the needs of people with DiffInL. The strength of this model resides on the re-usable character of the reasoning mechanism enabled by the computational environment. The whole framework allows a unified implementation which takes into account classes, constraints, matching, and inference mechanisms for the complete configuration of an LeS. The suggested approach also differs from previous work in that it is personalised, and the applied reasoning rules are dynamic. Therefore this model can be constantly “tuned” according to the questions we may ask in such environments. Overall, the proposed <b>reference</b> <b>model</b> in this research offers a promising and feasible solution that can support current educational systems and benefit both learners and instructors. It also demonstrates the applicability of the latest technologies and would allow for future technologies to be incorporated, in order to enhance the model...|$|R
40|$|Subject headings: supply chain, {{tracking}} and tracing, reference-data modelling The thesis des­­cribes the deve­lop­ment {{and application of}} a general information-system blue­print for {{tracking and}} tracing: a reference-data model. The problem statement reads: How can we im­prove tracking and tracing (with the help of modern ICT means) {{in such a way}} that food safety is guaranteed to a larger extent than happens at this moment (2003) ? The objective of the research is twofold: (1) establishing the tracking-and-tracing functionality within an object system, i. e., establishing the supply chain, and (2) represen­ting the functionality by data models so as to facilitate the develop­ment of information systems suitable for tracking and tracing. To obtain the research objective, the follo­wing five ques­tions are addre­s­s­ed: (1) which elements characterise tracking and tracing, in relation to (i) an enter­prise in the chain, (ii) its objective, and (iii) its admini­stra­­tion? (2) which functionality and per­formance with regard to tracking and tracing is derived from the enter­prise in the chain? (3) which data models are fit for an adequate representation of the functionality? (4) which reference-data model can be successfully construc­ted? (5) what is the eva­lu­a­tion of the <b>application</b> of the <b>reference</b> <b>model...</b>|$|R
40|$|International audienceThe {{digitalization}} {{of manufacturing}} fuels {{the application of}} sophisticated virtual product models, which {{are referred to as}} digital twins, throughout all stages of product realization. Particularly, more realistic virtual models of manufactured products are essential {{to bridge the gap between}} design and manufacturing and to mirror the real and virtual worlds. In this paper, we propose a comprehensive <b>reference</b> <b>model</b> based on the concept of Skin Model Shapes, which serves as a digital twin of the physical product in design and manufacturing. In this regard, model conceptualization, representation, and implementation as well as applications along the product life-cycle are addressed. In today's highly competitive markets, the ambitions for shortening the time to market and for increasing the product development performance fuel the application of sophisticated virtual product models, which are frequently referred to as digital twins. Enabled by the digitalization of manufacturing, cyber-physical production systems, model-based system engineering, and a growing endeavour for data gathering and processing, these models are increasingly enriched with production and operation data. Moreover, they allow the efficient prediction of the effects of product and process development as well as operating and servicing decisions on the product behaviour without the need for costly and time-expensive physical mock-ups [1 - 3]. Particularly in design, such realistic product models are essential to allow the early and efficient assessment of the consequences of design decisions on the quality and function of mechanical products. However, current approaches to the implementation of digital twins lack of a conceptual basis, which hinders the applicability of the digital twin vision to various activities in design and production engineering. Motivated by this need, this paper proposes a comprehensive <b>reference</b> <b>model,</b> which serves as a digital twin of the physical product in design and production engineering. In this regard, important model properties, such as scalability, interoperability, expansibility, and fidelity, as well as different operations on this <b>reference</b> <b>model</b> along the product life-cycle, such as composition, decomposition, conversion, and evaluation are addressed. Moreover, the <b>application</b> of this <b>reference</b> <b>model</b> to geometrical variations management is highlighted. The paper is structured as follows. In the next section, the vision of the digital twin and its evolution is reviewed. After that, a comprehensive <b>reference</b> <b>model</b> for the digital twin is introduced, which is then applied to geometrical variations management. Finally, a conclusion and an outlook are given...|$|R
40|$|AbstractHeat {{exchangers}} are {{an essential}} component of any energy production system. Obtaining a detailed characterization of them is a must for the design and operation of an energy plant. This article presents a characterization process of a finned tube heat exchanger with an unusual configuration. Throughout the article, the proceedings to study the influence of two unusual features that make unsuitable the use of <b>reference</b> <b>models</b> for heat exchangers are explained. One is the inclination of the tubes in the direction transverse to the flow velocity, which causes variable spacing between finned tubes. The other feature that prevents the <b>application</b> of the <b>reference</b> <b>models</b> is the importance of bypass flow, not negligible due to the small distance between walls compared with the width of the flow path near to the walls. A computational fluid dynamics (CFD) steady-state analysis has been completed in order to study this problem. The results show that although the inclination of the tubes does not affect considerably the overall performance of the exchanger, the influence of bypass flow close to the wall causes a significant reduction in pressure drop and a substantially lower heat transfer capacity than calculated with analytical models. This study was conducted within the Seventh Framework Programmes FP 7, for the HYSOL project. HYSOL plant has been proposed as an alternative to deliver dispatchable and firm energy regardless the climate conditions throughout the whole year while it uses 100 % renewable energy sources for electricity production through is innovative hybrid system...|$|R
40|$|Conventional {{authentication}} systems {{especially in}} a ubiquitous environment do not consider interoperability among different organizations. Therefore, carrying multiple security cards is inevitable for incompatible authentications. In this {{paper we propose a}} flexible, scalable, interoperable and usable authentication system using a ZigBee-enabled tiny portable device. It is specialized for the ubiquitous computing environments. In our authentication system, public key infrastructure (PKI) is used for interoperability and scalability. The noble security mechanism using PKI is also proposed. By applying Single Sign-On concept into our authentication system, possible frequent authentic operations in ubiquitous environment can be reduced. Instead of using the conventional security card, we developed a new lowpower tiny terminal which has ability of encryption-related computation. Therefore, authentication operations over many different services are possible with our tiny terminal. We presented three <b>reference</b> <b>application</b> <b>models</b> that use our authentication system in order to show that our proposed system does not sacrifice usability for security...|$|R
40|$|This paper {{presents}} {{a new approach}} to robust adaptive control, using fractional order systems as parallel feedforward in the adaptation loop. The problem is that adaptive control systems may diverge when confronted with finite sensor and actuator dynamics, or with parasitic disturbances. One of the classical robust adaptive control solutions to these problems makes use of parallel feedforward and simplified adaptive controllers based on the concept of positive realness. The proposed control scheme is based on the Almost Strictly Positive Realness (ASPR) property of the plant. We show that this condition implies also robust stability in the case of fractional order controllers. An <b>application</b> to <b>Model</b> <b>Reference</b> Adaptive Control (MRAC) with a fractional order adaptation rule is provided with an implementable algorithm. A simulation example of a SISO robust adaptive control system illustrates the advantages of the proposed method in the presence of disturbances and noise...|$|R
40|$|Abstract—The central idea in <b>reference</b> <b>modeling</b> is the reutilization of the {{business}} knowledge contained in a <b>reference</b> <b>model.</b> The user’s task in reference model-based construction is the adaptation of the <b>reference</b> <b>model.</b> The derivation of specific <b>models</b> from <b>reference</b> <b>models</b> corresponds {{with the creation of}} <b>reference</b> <b>model</b> variants. Research on the design of such variant constructions generally assumes an unchangeable stock of <b>reference</b> <b>models.</b> The potential inherent in the management of these variant constructions, which reflect the changes in designed <b>reference</b> <b>models</b> through time and in doing so, their evolutionary development, has not yet been tapped into. The article at hand analyzes this problem and presents a concept for the version management of <b>reference</b> <b>models</b> as a solution. The task to be mastered with the proposed approach will be concretized using data structures and a system architecture and then prototypically implemented. Index Terms—Information <b>model,</b> information <b>modeling,</b> <b>reference</b> <b>model,</b> <b>reference</b> <b>modeling,</b> version, versio...|$|R
40|$|This paper {{introduces}} a new REA enterprise information <b>reference</b> <b>model</b> that integrates the transaction <b>reference</b> <b>model</b> of Mc- Carthy and the conversion <b>reference</b> <b>model</b> of Hruby {{into a single}} model that accounts for both inter-enterprise and intra-enterprise processes. This new <b>reference</b> <b>model</b> should {{make it easier to}} represent services in REA models by allowing an explicit duality between transfer and trans- formation events, where McCarthy’s and Hruby’s <b>reference</b> <b>models</b> can only represent duality between one kind of events. First, {{the state of the art}} in REA <b>reference</b> <b>models</b> is addressed by presenting and compa- ring McCarthy’s and Hruby’s models. Second, the new, integrated REA <b>reference</b> <b>model</b> is presented...|$|R
