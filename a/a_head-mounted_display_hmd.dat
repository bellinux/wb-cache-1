98|1409|Public
50|$|As <b>a</b> <b>head-mounted</b> <b>display</b> (<b>HMD)</b> {{designer}} at the University of Southern California Institute for Creative Technologies, Palmer Luckey {{earned a}} reputation for having the largest personal collection of HMDs in the world, and was a longtime moderator in Meant to be Seen (MTBS)'s discussion forums.|$|E
50|$|<b>A</b> <b>head-mounted</b> <b>display</b> (<b>HMD)</b> is {{a display}} device paired to the {{forehead}} {{such as a}} harness or helmet. HMDs place images of both the physical world and virtual objects over the user's field of view. Modern HMDs often employ sensors for {{six degrees of freedom}} monitoring that allow the system to align virtual information to the physical world and adjust accordingly with the user's head movements. HMDs can provide VR users mobile and collaborative experiences. Specific providers, such as uSens and Gestigon, are even including gesture controls for full virtual immersion.|$|E
50|$|For {{displaying}} {{information gathered}} {{from a range}} of sensors across the aircraft, the cockpit features a wide-angle holographic head-up display (HUD) system, two head-down flat-panel colour multi-function displays (MFDs) as well as a central collimated display. These displays have been strategically placed to minimise pilot distraction from the external environment. Some displays feature a touch interface for ease of Human-computer interaction (HCI). <b>A</b> <b>head-mounted</b> <b>display</b> (<b>HMD)</b> remains to be integrated {{to take full advantage of}} its MICA missiles. The cockpit is fully compatible with night vision goggles (NVG).|$|E
50|$|The Z800 3DVisor is <b>a</b> <b>head-mounted</b> <b>display</b> {{manufactured}} by eMagin since 2005.|$|R
50|$|Systems which merely {{display a}} virtual reality {{directly}} to the user (e.g. using <b>a</b> <b>head-mounted</b> <b>display)</b> do not qualify. They are endocentric environments.|$|R
25|$|An {{apparatus}} that uses <b>a</b> <b>head-mounted</b> <b>display</b> and <b>a</b> touch that confuses {{the sense of}} proprioception (and which can also create the sensation of additional limbs).|$|R
50|$|Arguably {{the most}} {{important}} facet in making a virtual environment seem real is an appeal to sight. A virtual reality headset, incorporating <b>a</b> <b>head-mounted</b> <b>display</b> (<b>HMD)</b> is {{placed in front of}} the eyes of a patient like a pair of sunglasses, enabling for complete visual attention. A virtual environment is then displayed. A system of motion sensors tracks movement of the patient's head. If the patient tilts, or turns his head to view another part of the room, the environment adjusts accordingly. This allows for a more realistic experience by limiting restrictions of the head.|$|E
5000|$|Augmented reality-based testing (ARBT) is a {{test method}} that {{combines}} augmented reality and software testing to enhance testing by inserting an additional dimension into the testers field of view. For example, a tester wearing <b>a</b> <b>head-mounted</b> <b>display</b> (<b>HMD)</b> or Augmented reality contact lenses [...] that places images of both the physical world and registered virtual graphical objects over the user's {{view of the world}} can detect virtual labels on areas of a system to clarify test operating instructions for a tester who is performing tests on a complex system.|$|E
50|$|In 2002 Eric Joris and Kurt Vanhoutte (University of Antwerp) {{wanted to}} create a medium ‘like a prosthesis’ based upon Joris' work with the {{paraplegic}} actor. Eric Joris sought to combine 360° Omni Directional Video (ODV) with <b>a</b> <b>Head-mounted</b> <b>display</b> (<b>HMD)</b> and a tracking system instead of using computer graphics or ‘virtual reality’ tools (as in Computer Caves). EDM/University of Hasselt developed not only the camera but the whole system and software around. Their collaboration resulted in immersive performance like Crash,U, EUX and Terra Nova. Their system proved to be ahead of its time and led to many new applications. Ever since Omni Directional Video (360°) grew popular and the University of Hasselt made a first spin-off, centering on a 16head camerasystem for sports events.|$|E
5000|$|... #Caption: An {{astronaut}} {{on board}} the International Space Station is wearing <b>a</b> <b>head-mounted</b> <b>display</b> for performing <b>a</b> space neuroscience experiment aimed at evaluating changes in perceived depth and distance.|$|R
30|$|The <b>head-mounted</b> <b>display</b> {{gives the}} user an {{immersive}} {{experience with a}} relatively small amount of space. <b>A</b> <b>head-mounted</b> <b>display</b> is <b>a</b> small display that places the screen {{directly in front of}} the eyes. The <b>head-mounted</b> <b>display</b> creates <b>an</b> environment where the surroundings are blocked out and the display covers the user’s field of view.|$|R
50|$|TDVisor is <b>a</b> <b>head-mounted</b> <b>display</b> for {{stereoscopic}} 3D video viewing. In 2007, it {{was supported}} in a Northrop Grumman system called RainStorm., and many other training, remote controlled operations, surveillance, unmanned vehicles, educational and immersive video gaming applications.|$|R
40|$|We {{present a}} first study where we combine two {{asymetric}} virtual reality systems for telecollaboration purposes: a CAVE system and <b>a</b> <b>head-mounted</b> <b>display</b> (<b>HMD),</b> using a server-client type architecture. Experiments on a puzzle game in limited time, alone and in collaboration, show that combining asymetric systems reduces cognitive load. Moreover, {{the participants reported}} preferring working in collaboration and showed to be more efficient in collaboration. These results provide insights in combining several low cost HMDs with a unique expensive CAVE...|$|E
40|$|In {{this study}} {{the effects of}} virtual reality {{exposure}} therapy (VRET) were investigated in patients with panic disorder and agoraphobia. The level of presence in VRET was compared between using either <b>a</b> <b>head-mounted</b> <b>display</b> (<b>HMD)</b> or a computer automatic virtual environment (CAVE). Results indicate that there was no relationship between the level of experienced presence and treatment outcome. Analyses indicate that VRET in general was more effective than no treatment. No differences in effectiveness were found between VRET using an HMD or CAVE...|$|E
40|$|This work {{addresses}} {{the creation of}} a development framework where application developers can create, in a natural way, immersive physical activities where users experience a 3 D first-person perception of full body control. The proposed frame-work is based on commercial motion sensors and <b>a</b> <b>Head-Mounted</b> <b>Display</b> (<b>HMD),</b> and a uses Unity 3 D as a unifying environment where user pose, virtual scene and immersive visualization functions are coordinated. Our proposal is exemplified by the development of a toy application showing its practical us...|$|E
40|$|A novel {{approach}} was {{proposed to improve}} situational awareness using <b>a</b> <b>head-mounted</b> <b>display</b> when working together with an industrial robot arm. With the introduction of affordable intrinsically safe industrial robot arms, research into human-robot interaction has increased. When robot arms and humans are working together, {{it is not only}} essential that the robot arm is aware of humans, but also that the human knows what the robot arm is doing and intending to do. Situational awareness is value representation for the comprehension of a situation used to infer what is going on and what is going to happen. The situational awareness of a human was improved by showing extra virtual information using augmented reality. The virtual information was shown using a virtual model of the robot arm on <b>a</b> <b>head-mounted</b> <b>display.</b> Two categories of information to improve situational awareness were found by analysing the human-robot interaction in orange repacking: state and intention information. From each category, one information type with a high potential to improve situational was implemented and explored. Two within-subject experiments were conducted in which the test subjects were asked to wear <b>a</b> <b>head-mounted</b> <b>display</b> and work in a designed robot working cell. During the first experiment the test subject were presented with visual cues {{about the state of the}} robot arm and during the second experiment with visual cues about the intended goal of the robot arm. In each experiment the test subjects were evaluated on the reaction time to the visual cues. Each experiment was done twice, once with the presence of virtual information and once without, but both while wearing the <b>head-mounted</b> <b>display.</b> Compared to the case without virtual information, the results showed a decrease in reaction times to state and intention information when presented with the virtual information. This decrease in reaction time was a measure for an increased situational awareness of the human and showed that situational awareness could be improved by using <b>a</b> <b>head-mounted</b> <b>display</b> to show extra, not observable, information about the robot arm. This work contributes to help humans work more efficiently together with industrial robot arms by using <b>a</b> <b>head-mounted</b> <b>display</b> to present information in a more natural manor. BMDBioMechanical EngineeringMechanical, Maritime and Materials Engineerin...|$|R
50|$|Augmented or Mixed reality game {{graphics}} use {{images that}} partial overlay {{the image of}} reality seen through partial transparent glasses or captured with a camera and seen with <b>a</b> <b>head-mounted</b> <b>display</b> or other displays such as smartphone or tablet displays.|$|R
5000|$|Hypothetical {{virtual reality}} as {{immersive}} as consensus reality. Most {{likely to be}} produced using a brain-computer interface.An intermediate stage may be produced by [...] "Virtual Space" [...] using <b>a</b> <b>head-mounted</b> <b>display</b> with head tracking and computer control of the image presented to the helmet.|$|R
40|$|Modern {{technologies}} are developing {{so fast that}} it is impossible to follow them all. Here is an example of a new breakthrough in Google’s creativity. It is a wearable computer with <b>a</b> <b>head-mounted</b> <b>display</b> (<b>HMD)</b> that is being developed by Google in the Project Glass research and development project, with the mission of producing a mass-market ubiquitous computer. Google Glass displays information in a smartphone-like hands-free format that can interact with the Internet via natural language voice commands. When you are citing the document, use the following link [URL]...|$|E
40|$|Correctly {{calibrating}} <b>a</b> <b>head-mounted</b> <b>display</b> (<b>HMD)</b> {{is critical}} {{for the kinds of}} virtual reality applications used by visual neuroscientists. ► We propose a method that produces these calibrations accurately and quickly. ► Unlike methods proposed by others, ours requires no error-prone human judgements. ► Our method permits the collection of large numbers of samples for the calibration data. We show how number of samples affects calibration accuracy. ► Can be used for the more popular non-see-through HMDs, which, traditionally, have been neglected. Existing calibration techniques work only with optical-see-through HMDs...|$|E
40|$|Point of {{view has}} its {{foundations}} in film. It usually depicts a scene {{through the eyes}} of a character. Body-worn video-recording technologies now mean that a wearer can shoot film from a first-person perspective of another subject or object in his or her immediate field of view (FOV). The term sousveillance has been defined by Steve Mann to denote a recording done from a portable device such as <b>a</b> <b>head-mounted</b> <b>display</b> (<b>HMD)</b> unit in which the wearer is a participant in the activity. Some people call it inverse surveillance because it is the opposite of a camera that is wall mounted and fixed...|$|E
40|$|Virtual Reality (VR) {{is usually}} {{described}} by the media as a particular collection of technological hardware: a computer capable of 3 D real-time animation, <b>a</b> <b>head-mounted</b> <b>display,</b> data gloves equipped {{with one or more}} position trackers. However, this focus on technology is disappointing for communication researchers and VR designers...|$|R
50|$|The Virtualizer enables {{motion by}} the {{principle}} of low friction. The body is fixed in a rotatable ring that can be moved vertically. In combination with <b>a</b> <b>head-mounted</b> <b>display</b> it allows to move, run, jump or crouch in virtual worlds. The current prototype does not need any special kind of shoes.|$|R
40|$|<b>Head-mounted</b> <b>displays</b> provide {{relatively}} hands-free interaction {{that could}} improve mobile computing access for users with motor impairments. To investigate this largely unexplored area, we present two user studies. The first, smaller study evaluated {{the accessibility of}} Google Glass, <b>a</b> <b>head-mounted</b> <b>display,</b> with 6 participants. Findings revealed potential benefits of <b>a</b> <b>head-mounted</b> <b>display</b> yet demonstrated the need for alternative means of controlling Glass— 3 of the 6 participants could not use it at all. We then conducted a second study with 12 participants to evaluate a potential alternative input mechanism that could allow for accessible control of <b>a</b> <b>head-mounted</b> display: switch-based wearable touchpads that can be affixed to the body or wheelchair. The study assessed input performance with three sizes of touchpad, investigated personalization patterns when {{participants were asked to}} place the touchpads on their body or wheelchair, and elicited subjective responses. All 12 participants were able to use the touchpads to control the display, and patterns of touchpad placement point to the value of personalization in providing support for each user’s motor abilities. Author Keywords Motor impairments; wearables; mobile accessibility...|$|R
40|$|One of {{the classic}} {{problems}} with immersive environments is data entry; with <b>a</b> <b>head-mounted</b> <b>display</b> (<b>HMD)</b> the user can no longer see the keyboard. Although for many applications data entry is not a requirement, for some it is essential: communicating in collaborative environments, entering a filename to which work can be saved, or accessing system controls. Combining data gloves and a graphically represented keyboard with a predictive spelling paradigm, we describe an effective text entry technique for immersive environments; we explore the key issues when using such a technique, and report the results of preliminary usability testing...|$|E
40|$|Abstract. In {{this paper}} {{we present a}} new {{multimodal}} locomotion user interface that enables users to travel through 3 D environments displayed in geospatial information systems (GISs), e. g., Google Earth or Microsoft Virtual Earth. When using the proposed interface the geospatial data can be explored immersively using stereoscopic visualization on <b>a</b> <b>head-mounted</b> <b>display</b> (<b>HMD).</b> When using certain tracking approaches the entire body can be tracked {{in order to support}} natural traveling by real walking. Moreover, intuitive devices are provided for both-handed interaction such as gestures to complete the navigation process. We introduce the setup as well as associated interaction concepts. ...|$|E
40|$|Able-bodied {{participants}} {{are able to}} move forward in a Virtual Environment (VE) by imagining movements of their feet. This is achieved by exploiting a Brain-Computer Interface (BCI) which transforms thought-modulated EEG signals into an output signal that controls events within the VE. The experiments were carried out in an immersive projection environment, {{commonly referred to as}} a &quot;Cave” in which participants were able to move through a virtual street by foot imagery alone. Experiments of BCI feedback on a normal monitor, VE experiments with <b>a</b> <b>head-mounted</b> <b>display</b> (<b>HMD)</b> and in the Cave-VE are compared. Keywords — Virtual environment (VE), Brain-Computer Interface (BCI), walking, thought...|$|E
50|$|<b>A</b> <b>head-mounted</b> <b>display</b> (or helmet-mounted display, for {{aviation}} applications), both abbreviated HMD, is {{a display}} device, worn {{on the head}} {{or as part of}} a helmet, that has a small display optic in front of one (monocular HMD) or each eye (binocular HMD). A HMD has many uses including in gaming, aviation, engineering, and medicine.|$|R
40|$|Human vision {{underlies}} natural constraints. Field of view, perceived wavelength, angular resolution, or perspective {{are just}} a few. Combining <b>a</b> <b>head-mounted</b> <b>display</b> with <b>a</b> camera can overcome some of these limitations and constraints. We investigate the field of view, which is created by presenting a third person view to the wearer of the <b>head-mounted</b> <b>display.</b> We propose <b>an</b> automatic camera posi-tioning that may provide a better overview to the user compared to a manual positioning. ...|$|R
40|$|We have {{constructed}} a wearable outdoor computer system which presents sounds and images placed at particular locations {{by means of}} headphones and <b>a</b> <b>head-mounted</b> <b>display.</b> The apparent location of a sound source can be fixed relative to the earth, independent of the listener’s position or orientation. For easy duplication, the system is built exclusively from off-the-shelf hardware and publicly available software. ...|$|R
40|$|Proceedings of the 9 th International Conference on Auditory Display (ICAD), Boston, MA, July 7 - 9, 2003. This paper {{presents}} a system developed at NASA Langley Research Center to render aircraft flyovers {{in a virtual}} reality environment. The present system uses monaural recordings of actual aircraft flyover noise and presents these binaurally using head tracking information. The three-dimensional audio is simultaneously rendered with a visual presentation using <b>a</b> <b>head-mounted</b> <b>display</b> (<b>HMD).</b> The final system will use flyover noise synthesized using data from various analytical and empirical modeling systems. This will permit presentation of flyover noise from candidate low-noise flight operations to subjects for psychoacoustical evaluation...|$|E
40|$|This paper {{contests}} that Mixed Reality (MR) {{offers a}} potential solution in achieving transferability between Human Computer Interaction (HCI) and Human Robot Interaction (HRI). Virtual characters (possibly of a robotic genre) can offer highly expressive interfaces {{that are as}} convincing as a human, are comparably cheap and can be easily adapted and personalized. We introduce {{the notion of a}} mixed reality agent, i. e. an agent consisting of a physical robotic body and a virtual avatar displayed upon it. We realized an augmented reality interface with <b>a</b> <b>Head-Mounted</b> <b>Display</b> (<b>HMD)</b> in order to interact with such systems and conducted a pilot study to demonstrate the usefulness of mixed reality agents in human-robot collaborative tasks. Categories and Subject Descriptor...|$|E
40|$|We {{present a}} summary of the {{development}} of a new virtual reality setup for behavioural experiments in the area of spatial cognition. Most previous virtual reality setups can either not provide accurate body motion cues when participants are moving in a virtual environment, or participants are hindered by cables while walking in virtual environments with <b>a</b> <b>head-mounted</b> <b>display</b> (<b>HMD).</b> Our new setup solves these issues by providing a large, fully trackable walking space, in which a participant with a HMD can walk freely, without being tethered by cables. Two experiments on spatial memory are described, which tested this setup. The results suggest that environmental spaces traversed during wayfinding are memorised in a view-dependent way, i. e., in the local orientation they were experienced, and not with respect to a global reference direction...|$|E
50|$|<b>A</b> {{virtual reality}} <b>head-mounted</b> <b>display</b> (VR HMD) mount is a mount for {{attaching}} <b>a</b> VR <b>head-mounted</b> <b>display.</b> It {{is distinct from}} a virtual reality head mounted display, like the Oculus Rift, HTC Vive, Sony Morpheus, Carl Zeiss VR One, as a VR HMD mount does not contain any electronics or screen itself, but rather allows users to insert a smartphone or other device in it {{and place it on}} the head.|$|R
50|$|There is also <b>an</b> optical <b>head-mounted</b> <b>display</b> (OHMD), {{which is}} a {{wearable}} display that can reflect projected images and allows a user to see through it.|$|R
5000|$|... 3D’s early {{beginnings}} can {{be traced}} back to 1962 when Morton Heilig invented the Sensorama simulator. It provided 3D video feedback, as well motion, audio, and haptic feedbacks to produce a virtual environment. The next stage of development was Dr. Ivan Sutherland's completion of his pioneering work in 1968. He created <b>a</b> <b>head-mounted</b> <b>display</b> that produced <b>a</b> 3D, virtual environment by presenting a left and right still image of that environment.|$|R
