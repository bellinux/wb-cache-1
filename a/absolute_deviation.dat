1516|842|Public
25|$|When {{the median}} {{is used as}} a {{location}} parameter in descriptive statistics, there are several choices for a measure of variability: the range, the interquartile range, the mean <b>absolute</b> <b>deviation,</b> and the median <b>absolute</b> <b>deviation.</b>|$|E
25|$|There {{are several}} types of indices used for the {{analysis}} of nominal data. Several are standard statistics that are used elsewhere - range, standard deviation, variance, mean deviation, coefficient of variation, median <b>absolute</b> <b>deviation,</b> interquartile range and quartile deviation.|$|E
25|$|A useful {{property}} of the standard deviation is that, unlike the variance, it is expressed in the same units as the data. There are also other measures of deviation from the norm, including average <b>absolute</b> <b>deviation,</b> which provide different mathematical properties from standard deviation.|$|E
50|$|Though {{the idea}} of least <b>absolute</b> <b>deviations</b> {{regression}} is just as straightforward as that of least squares regression, the least <b>absolute</b> <b>deviations</b> line is not as simple to compute efficiently. Unlike least squares regression, least <b>absolute</b> <b>deviations</b> regression {{does not have an}} analytical solving method. Therefore, an iterative approach is required. The following is an enumeration of some least <b>absolute</b> <b>deviations</b> solving methods.|$|R
50|$|Alternate {{optimization}} criteria {{have been}} used as well, such as standard <b>absolute</b> <b>deviations</b> and mean <b>absolute</b> <b>deviations.</b>|$|R
40|$|Least <b>absolute</b> <b>deviations</b> {{regression}} resists outliers in {{the response}} variable but is relatively sensitive to outlying observations in the explanatory variables. In this paper {{a simple solution}} is proposed to overcome this problem. This is achieved by minimizing the absolute values of vertical and horizontal deviations in turn. Two algorithms are proposed: one for the simple {{and one for the}} multiple regression case. The methods presented have been tested on a variety of data and have proven to be quite effective. least <b>absolute</b> <b>deviations</b> regression inverse least <b>absolute</b> <b>deviations</b> regression robust regression outliers leverage points...|$|R
25|$|While the {{standard}} deviation does measure how far typical values tend {{to be from the}} mean, other measures are available. An example is the mean <b>absolute</b> <b>deviation,</b> which might be considered a more direct measure of average distance, compared to the root mean square distance inherent in {{the standard}} deviation.|$|E
25|$|The {{combination}} of different observations taken under different conditions. The method {{came to be}} known as the method of least <b>absolute</b> <b>deviation.</b> It was notably performed by Roger Joseph Boscovich in his work on the shape of the earth in 1757 and by Pierre-Simon Laplace for the same problem in 1799.|$|E
25|$|Least <b>absolute</b> <b>deviation</b> (LAD) {{regression}} is {{a robust}} estimation technique {{in that it}} is less sensitive to the presence of outliers than OLS (but is less efficient than OLS when no outliers are present). It is equivalent to maximum likelihood estimation under a Laplace distribution model for ε.|$|E
5000|$|... #Subtitle level 2: Contrasting {{least squares}} with least <b>absolute</b> <b>deviations</b> ...|$|R
50|$|There exist other unique {{properties}} of the least <b>absolute</b> <b>deviations</b> line. In {{the case of a}} set of (x,y) data, the least <b>absolute</b> <b>deviations</b> line will always pass through {{at least two of the}} data points, unless there are multiple solutions. If multiple solutions exist, then the region of valid least <b>absolute</b> <b>deviations</b> solutions will be bounded by at least two lines, each of which passes through at least two data points. More generally, if there are k regressors (including the constant), then at least one optimal regression surface will pass through k of the data points.|$|R
40|$|We prove, under mild conditions, {{a result}} about {{the speed of}} {{convergence}} of a class of estimators found by optimization of certain random criterion functions. We apply the result to the estimator of Least <b>Absolute</b> <b>Deviations</b> (LAD) in a Linear Model without second-order moment assumptions. Empirical processes stable random variable Vapnik [...] Cervonenkis classes least <b>absolute</b> <b>deviations...</b>|$|R
25|$|The {{development}} of a criterion that can be evaluated to determine when the solution with the minimum error has been achieved. Laplace tried to specify a mathematical form of the probability density for the errors and define a method of estimation that minimizes the error of estimation. For this purpose, Laplace used a symmetric two-sided exponential distribution we now call Laplace distribution to model the error distribution, and used the sum of <b>absolute</b> <b>deviation</b> as error of estimation. He felt these to be the simplest assumptions he could make, and {{he had hoped to}} obtain the arithmetic mean as the best estimate. Instead, his estimator was the posterior median.|$|E
2500|$|The {{standard}} deviation and the expected <b>absolute</b> <b>deviation</b> can both {{be used as}} an indicator of the [...] "spread" [...] of a distribution. [...] The {{standard deviation}} is more amenable to algebraic manipulation than the expected <b>absolute</b> <b>deviation,</b> and, together with variance and its generalization covariance, is used frequently in theoretical statistics; however the expected <b>absolute</b> <b>deviation</b> tends to be more robust as it is less sensitive to outliers arising from measurement anomalies or an unduly heavy-tailed distribution.|$|E
2500|$|The mean <b>absolute</b> <b>deviation</b> {{around the}} mean for the beta {{distribution}} with shape parameters α and β is: ...|$|E
5000|$|Least <b>absolute</b> <b>deviations,</b> {{which is}} more robust in the {{presence}} of outliers, leading to quantile regression ...|$|R
5000|$|... where [...] are the medians and median <b>absolute</b> <b>deviations</b> in the {{positive}} and negative controls, respectively.|$|R
40|$|Abbreviations: (ARD) <b>absolute</b> {{relative}} <b>deviation,</b> (BG) blood glucose, (CG-EGA) continuous glucose error grid analysis, (CGM) continuous glucose monitoring, (CLSI) Clinical and Laboratory Standards Institute, (EGA) error grid analysis, (MARD) mean <b>absolute</b> relative <b>deviation,</b> (PARD) precision <b>absolute</b> relative <b>deviation,</b> (SD) standard deviatio...|$|R
2500|$|At {{the limit}} α → ∞, β → ∞, {{the ratio of}} the mean <b>absolute</b> <b>deviation</b> to the {{standard}} deviation (for the beta distribution) becomes equal to {{the ratio of the}} same measures for the normal distribution: [...] [...] For α = β = 1 this ratio equals , so that from α = β = 1 to α, β → ∞ the ratio decreases by 8.5%. [...] For α = β = 0 the standard deviation is exactly equal to the mean <b>absolute</b> <b>deviation</b> around the mean. Therefore, this ratio decreases by 15% from [...] α = β = 0 to [...] α = β = 1, and by 25% from α = β = 0 to α, β → ∞ [...] However, for skewed beta distributions such that α → 0 or β → 0, the ratio of the standard deviation to the mean <b>absolute</b> <b>deviation</b> approaches infinity (although each of them, individually, approaches zero) because the mean <b>absolute</b> <b>deviation</b> approaches zero faster than the standard deviation.|$|E
2500|$|... one {{can express}} the mean <b>absolute</b> <b>deviation</b> around the mean {{in terms of}} the mean μ and the sample size ν as follows: ...|$|E
2500|$|Unlike {{expected}} [...] <b>absolute</b> <b>deviation,</b> {{the variance}} of a variable has units that are {{the square of the}} units of the variable itself. [...] For example, a variable measured in meters will have a variance measured in meters squared. [...] For this reason, describing data sets via their standard deviation or root mean square deviation is often preferred over using the variance. [...] In the dice example the standard deviation is √2.9≈1.7, slightly larger than the expected <b>absolute</b> <b>deviation</b> of1.5.|$|E
40|$|AbstractA general fuzzy {{linear model}} for fuzzy {{regression}} analysis was first formulated. Based on both this general model and a fuzzy difference ranking method [1, 2], approaches for fuzzy least squares regression and fuzzy least <b>absolute</b> value <b>deviations</b> regression were proposed. The former approach resulted in a nonlinear programming problem while the latter resulted linear. Numerical examples were solved by using the <b>absolute</b> <b>deviations</b> approach to illustrate the problems of conflicting trends and ways to at least partially overcome these problems. Furthermore, these examples showed that the <b>absolute</b> <b>deviations</b> formulation forms an effective computational tool...|$|R
40|$|LAD computes least <b>absolute</b> <b>deviations</b> {{regression}}, {{also known}} as L 1 regression or Laplace regression. This type of regression is optimal when the disturbances have the Laplace distribution and is better than least squares (L 2) regression for many other leptokurtic (fat-tailed) distributions such as Cauchy or Student’s t. Usage: To estimate by least <b>absolute</b> <b>deviations</b> in TSP, use the LAD command just like the OLSQ command. For example...|$|R
50|$|In {{regression}} analysis, {{the least}} <b>absolute</b> <b>deviations</b> estimate arises as the maximum likelihood estimate if the errors have a Laplace distribution.|$|R
2500|$|The {{standard}} deviation of a random variable, statistical population, data set, or probability distribution is the square root of its variance. [...] It is algebraically simpler, though in practice less robust, than the average <b>absolute</b> <b>deviation.</b>|$|E
2500|$|The {{first and}} third inequalities come from Jensen's {{inequality}} applied to the absolute-value function and the square function, which are each [...] convex. [...] The second inequality {{comes from the fact}} that a median minimizes the <b>absolute</b> <b>deviation</b> function ...|$|E
2500|$|The {{coefficient}} of dispersion (CD) {{is defined as}} the ratio of the average <b>absolute</b> <b>deviation</b> from the median to the median of the data. It is a statistical measure used by the states of Iowa, New York and South Dakota in estimating dues taxes. In symbols ...|$|E
40|$|There is some renewed {{interest}} among agricultural economists {{and others in}} the old technique of using minimized <b>absolute</b> <b>deviations</b> in computing lines of best fit. H. B. Jones and J. C. Thompson, in a recent article in Agricultural Economics Research, discussed philosophical and practical questions raised when fitted lines using squared and unsquared deviations are compared. However, economic literature (including the Jones-Thompson paper) as well as elementary statistics and econometric literature seems to contain no concise description of the straight-forward and simple procedure for calculating straight lines of best fit which minimize the sum of <b>absolute</b> <b>deviations</b> from the empirical observations to the fitted line. In some work at the University of Minnesota, we find that lines fitted by minimizing the sum of <b>absolute</b> <b>deviations</b> can be useful in certain circumstances...|$|R
5000|$|For a {{univariate}} {{data set}} X1, X2, ..., Xn, the MAD {{is defined as}} the median of the <b>absolute</b> <b>deviations</b> from the data's median: ...|$|R
5000|$|Least <b>{{absolute}}</b> <b>deviations</b> (LAD), {{also known}} as least absolute errors (LAE), least absolute value (LAV), least absolute residual (LAR), sum of <b>absolute</b> <b>deviations,</b> or the L1 norm condition, is a statistical optimality criterion and the statistical optimization technique that relies on it. Similar to the popular least squares technique, it attempts to find a function which closely approximates a set of data. In the simple case {{of a set of}} (x,y) data, the approximation function is a simple [...] "trend line" [...] in two-dimensional Cartesian coordinates. The method minimizes the sum of absolute errors (SAE) (the sum of the absolute values of the vertical [...] "residuals" [...] between points generated by the function and corresponding points in the data). The least <b>absolute</b> <b>deviations</b> estimate also arises as the maximum likelihood estimate if the errors have a Laplace distribution.|$|R
2500|$|... where tj is {{the mean}} <b>absolute</b> <b>deviation</b> of the jth sample, var (...) is the {{variance}} and zα {{is the value}} from the normal distribution for the chosen value of α: for α = 0.05, zα = 1.96. The following formulae {{are used in the}} derivation of these confidence intervals ...|$|E
2500|$|First, a data set's {{average is}} determined. Next the <b>absolute</b> <b>deviation</b> between each data {{point and the}} average are determined. Thirdly, a {{rejection}} region is determined using the formula: where [...] is the critical value from the Student t distribution, n is the sample size, and s is the sample standard deviation.|$|E
2500|$|The mean <b>absolute</b> <b>deviation</b> {{around the}} mean {{is a more}} robust {{estimator}} of statistical dispersion than the standard deviation for beta distributions with tails and inflection points at {{each side of the}} mode, Beta(α, β) distributions with α,β > 2, as it depends on the linear (absolute) deviations rather than the square deviations from the mean. [...] Therefore, the effect of very large deviations from the mean are not as overly weighted.|$|E
50|$|The {{following}} is a table contrasting some properties of the method of least <b>absolute</b> <b>deviations</b> {{with those of the}} method of least squares (for non-singular problems).|$|R
50|$|Peters {{became a}} {{name in the}} {{literature}} on the theory of errors for his 1856 note on the estimation of precision using <b>absolute</b> <b>deviations</b> from the mean.|$|R
50|$|Closely related is {{the subject}} of least <b>absolute</b> <b>deviations,</b> a method of {{regression}} that is more robust to outliers than is least squares, in which the sum of the absolute value of the observed errors is used in place of the squared error. The connection is that the mean is the single estimate of a distribution that minimizes expected squared error while the median minimizes expected absolute error. Least <b>absolute</b> <b>deviations</b> shares the ability to be relatively insensitive to large deviations in outlying observations, although even better methods of robust regression are available.|$|R
