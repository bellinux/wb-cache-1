397|350|Public
25|$|Crystal {{structures}} of nanometer sized crystalline samples {{can be determined}} via structure factor <b>amplitude</b> <b>information</b> from single-crystal electron diffraction data or structure factor amplitude and phase angle information from Fourier transforms of HRTEM images of crystallites. They are stored in crystal structure databases specializing in nanocrystals and can be identified by comparing zone axis subsets in lattice-fringe fingerprint plots with entries in a lattice-fringe fingerprinting database.|$|E
25|$|In {{the case}} of {{electron}} diffraction patterns, structure factor amplitudes can be used, in a later step, to further discern among a selection of candidate structures (so-called 'structure factor fingerprinting'). Structure factor amplitudes from electron diffraction data are far less reliable than their counterparts from X-ray single-crystal and powder diffraction data. Existing precession electron diffraction techniques greatly {{improve the quality of}} structure factor amplitudes, increase their number and, thus, make structure factor <b>amplitude</b> <b>information</b> much more useful for the fingerprinting process.|$|E
50|$|However {{many new}} {{communications}} systems from WiMAX to LTE do use <b>amplitude</b> <b>information.</b> The amplifier cannot be run into compression, because the <b>amplitude</b> <b>information</b> becomes distorted. These amplifiers can only achieve their peak efficiency on {{the peaks of}} the amplitude. The remainder of the time power is being dissipated unnecessarily.|$|E
40|$|A {{wealth of}} new data in charmed {{particle}} physics allows {{the testing of}} flavor symmetry and the extraction of key <b>amplitudes.</b> <b>Information</b> on relative strong phases is obtained. Comment: 6 pages, 5 figures, {{to be published in}} Proceedings of the Charm 2007 Workshop, Ithaca, NY, August 5 - 8, 2007, eConf #C 07080...|$|R
40|$|New {{data on the}} decays of the charmed {{particles}} D 0, D +, and Ds to {{pairs of}} light pseudoscalar mesons P allow the testing of flavor symmetry and the extraction of key <b>amplitudes.</b> <b>Information</b> on relative strong phases is obtained. One sees evidence for the expected interference between Cabibbofavored and doubly-Cabibbo-suppressed decays in the differing patterns of D 0 → KS,Lπ 0 and D + → KS,Lπ + decays. ...|$|R
40|$|New {{data on the}} decays of the charmed {{particles}} D^ 0, D^+, and D_s to {{pairs of}} light pseudoscalar mesons P allow the testing of flavor symmetry and the extraction of key <b>amplitudes.</b> <b>Information</b> on relative strong phases is obtained. One sees evidence for the expected interference between Cabibbo-favored and doubly-Cabibbo-suppressed decays in the differing patterns of D^ 0 → K_S,Lπ^ 0 and D^+ → K_S,Lπ^+ decays. Comment: 12 pages, 5 figures, to be submitted to Phys. Rev. ...|$|R
50|$|In {{the case}} of Daugman's algorithms, a Gabor wavelet {{transform}} is used. The result {{is a set of}} complex numbers that carry local amplitude and phase information about the iris pattern. In Daugman's algorithms, most <b>amplitude</b> <b>information</b> is discarded, and the 2048 bits representing an iris pattern consist of phase information (complex sign bits of the Gabor wavelet projections). Discarding the <b>amplitude</b> <b>information</b> ensures that the template remains largely unaffected by changes in illumination or camera gain, and contributes to the long-term usability of the biometric template.|$|E
50|$|The vocoder uses {{a filter}} bank to {{determine}} the <b>amplitude</b> <b>information</b> of the subbands of a modulator signal (such as a voice) and uses them to control the amplitude of the subbands of a carrier signal (such as the output of a guitar or synthesizer), thus imposing the dynamic characteristics of the modulator on the carrier.|$|E
50|$|The {{need for}} greater {{efficiency}} arises particularly as modulation schemes become {{more complicated and}} their peak to average power ratio increases. Older modulation schemes based on phase or frequency modulation with no <b>amplitude</b> <b>information</b> carried on the signal can use amplifiers that are driven into compression and offer high levels of efficiency. As of 2014 mobile communications basestations consumed ~1% of global electricity.|$|E
3000|$|... {{which is}} capable of giving time-frequency {{localized}} both instantaneous <b>amplitude</b> and phase <b>information.</b>|$|R
50|$|Applications {{of complex}} random {{variables}} {{are found in}} digital signal processing, quadrature <b>amplitude</b> modulation and <b>information</b> theory.|$|R
3000|$|... data. In this application, the {{physical}} unit for the geomagnetic field spectra is nanotesla (nT). Thus, F_k contains <b>amplitude</b> and phase <b>information</b> {{of the differences}} ΔB [...]...|$|R
50|$|Crystal {{structures}} of nanometer sized crystalline samples {{can be determined}} via structure factor <b>amplitude</b> <b>information</b> from single-crystal electron diffraction data or structure factor amplitude and phase angle information from Fourier transforms of HRTEM images of crystallites. They are stored in crystal structure databases specializing in nanocrystals and can be identified by comparing zone axis subsets in lattice-fringe fingerprint plots with entries in a lattice-fringe fingerprinting database.|$|E
50|$|The output can be {{recorded}} with an audio recorder as with FD detectors, or with more recent units, the signal can {{be recorded}} directly {{to an internal}} digital memory such as a compact flash card. The whole waveform is recorded with the full call range being preserved, rather than 1/10 of the waveform as in a FD detector. Since both frequency and <b>amplitude</b> <b>information</b> are preserved in the recorded call, more data is available for species analysis.|$|E
50|$|In {{the case}} of {{electron}} diffraction patterns, structure factor amplitudes can be used, in a later step, to further discern among a selection of candidate structures (so-called 'structure factor fingerprinting'). Structure factor amplitudes from electron diffraction data are far less reliable than their counterparts from X-ray single-crystal and powder diffraction data. Existing precession electron diffraction techniques greatly {{improve the quality of}} structure factor amplitudes, increase their number and, thus, make structure factor <b>amplitude</b> <b>information</b> much more useful for the fingerprinting process.|$|E
40|$|Abstract: The {{conversion}} of {{time domain data}} via the fast Fourier (FFT) and Hilbert-Huang (HHT) transforms is compared. The FFT treats <b>amplitude</b> vs. time <b>information</b> globally as it transforms the data to an amplitude vs. frequency description. The HHT is not constrained by the assumptions of stationarity and linearity, required for the FFT, and generates both <b>amplitude</b> and frequency <b>information</b> {{as a function of}} time. The behavior and flexibility of these two transforms are examined for a number of different time domain signal types. Keywords: fast Fourier transform, Hilbert-Huang transform, data analysis...|$|R
30|$|At present, {{the radar}} based feature {{extraction}} for the BM target recognition mainly {{includes the following}} techniques: (1) Electromagnetic scattering feature extraction, i.e. radar signal <b>amplitude,</b> phase <b>information,</b> and polarization features; (2) Motion feature extraction, i.e. the spinning and precession frequency extraction based on the time-frequency analysis [5, 6]; (3) Target geometrical structure extraction based on the high resolution range profile (HRRP), ISAR image or three dimensional imaging [7 – 9].|$|R
40|$|We {{experimentally}} {{demonstrate the}} concept of continuous variable quantum erasing. The amplitude quadrature of the signal state is labeled to another state via a quantum nondemolition interaction, leading to a large uncertainty in {{the determination of the}} phase quadrature due to the inextricable complementarity of the two observables. We show that by erasing the <b>amplitude</b> quadrature <b>information</b> we are able to recover the phase quadrature information of the signal state...|$|R
50|$|Spherical {{cells and}} {{pyramidal}} cells then project to the torus semicircularis (TS), a structure with many laminae, or layers. The TS {{is located in}} the mesencephalon. Phase and <b>amplitude</b> <b>information</b> are integrated here to determine whether the stimulus frequency is greater or less than the EOD frequency. Sign-selective neurons in the deeper layers of the TS are selective to whether the frequency difference is positive or negative; any given sign-selective cell will fire in one case but not for the other.|$|E
5000|$|The core of {{both the}} SAR and the phased array {{techniques}} is that the distances that radar waves travel to and back from each scene element consist of some integer number of wavelengths plus some fraction of a [...] "final" [...] wavelength. Those fractions cause differences between the phases of the re-radiation received at various SAR or array positions. Coherent detection is needed to capture the signal phase information {{in addition to the}} signal <b>amplitude</b> <b>information.</b> That type of detection requires finding the differences between the phases of the received signals and the simultaneous phase of a well-preserved sample of the transmitted illumination.|$|E
5000|$|In {{a typical}} {{reconstruction}} {{the first step}} is to generate random phases and combine them with the <b>amplitude</b> <b>information</b> from the reciprocal space pattern. Then a Fourier transform is applied back and forth to move between real space and reciprocal space with the modulus squared of the diffracted wave field set equal to the measured diffraction intensities in each cycle. By applying various constraints in real and reciprocal space the pattern evolves into an image after enough iterations of the HIO process. To ensure reproducibility the process is typically repeated with new sets of random phases with each run having typically hundreds to thousands of cycles.|$|E
40|$|Intensity {{modulation}} sensors {{are classified}} {{by the way}} in which the reference and signal channels are separated: in space, wavelength, or time domains. To implement the time-domain referencing, different types of fiber-optic loops have been used. A pulse of short duration sent into the loop results in a series of pulses of different <b>amplitudes.</b> The <b>information</b> about the measured parameter is retrieved from the relative amplitudes of pulses in the same train...|$|R
40|$|Heterodyne receivers, which down-convert radio {{frequency}} (RF) signals to intermediate frequency (IF) signals - preserving the <b>amplitude</b> and phase <b>information</b> {{of the incoming}} radiation, are generally the detector of choice for high resolution spectroscopic studies in astrophysics and planetary remote sensing...|$|R
40|$|Employing {{scanning}} transmission {{electron microscope}} as interferometer, relative phases of diffraction maximums can be determined by analysis of dark field images. Synthetic aperture technique and Fourier-transform computer processing of <b>amplitude</b> and phase <b>information</b> provide high resolution images at approximately one angstrom...|$|R
50|$|Combining {{the series}} of {{observations}} requires significant computational resources, usually using Fourier transform techniques. The high digital computing speed now available allows such processing {{to be done in}} near-real time on board a SAR aircraft. (There is necessarily a minimum time delay until all parts of the signal have been received.) The result is a map of radar reflectivity, including both amplitude and phase. The <b>amplitude</b> <b>information,</b> when shown in a map-like display, gives information about ground cover {{in much the same way}} that a black-and-white photo does. Variations in processing may also be done in either vehicle-borne stations or ground stations for various purposes, so as to accentuate certain image features for detailed target-area analysis.|$|E
50|$|Unmodulated {{continuous}} wave radar cannot measure distance, and the beam is usually broad with side-lobes that {{extend to the}} side and behind the radar antenna. Signal amplitude provides the only way to determine which object corresponds with which speed measurement when {{there is more than one}} moving object near the receiver, but <b>amplitude</b> <b>information</b> is not useful without range measurement to evaluate target size. Moving objects include birds flying near objects in front of the antenna. Reflections from small objects directly in front of the receiver can be overwhelmed by reflections entering antenna side-lobes from large object located to the side, above, or behind the radar, such as trees with wind blowing through the leaves, tall grass, sea surface, freight trains, busses, trucks, and aircraft.|$|E
50|$|In the gymnotiform fish, Eigenmannia {{illustrated}} here, {{the primary}} sensory neurons in the electroreceptor system are simple feature detectors, and {{they include the}} ampullary receptors, probability coders (P units), and phase coders (T units). P units and T units are meant to acquire information about the amplitude and phase of the stimulus, respectively, with very little processing. The P and T units differ in tuning and in threshold for evoking a single spike {{in response to a}} sinusoidal stimulus. P units have high threshold and are broadly tuned; T units have low thresholds and narrow tuning. The separate processing of information continues passed the primary sensory neurons into the electrosensory lateral-line lobe (ELL) where spherical cells relay phase or time information to higher centers and pyramidal cells code for <b>amplitude</b> <b>information.</b> As a result, we also consider the class of spherical and pyramidal cells located in the ELL to be feature detectors. More specifically, pyramidal cells are considered feature detectors that respond to the amplitude of the stimulus. One class of pyramidal cell, E-cells, respond to increases; a second, I-cells, respond to decreases in stimulus amplitude whereas all peripheral receptors are E-units.|$|E
40|$|In this paper, {{algorithms}} for {{the work}} of eddy current flaw detectors based on microcontrollers are considered that allow to increase the speed of their operation in tens, hundreds of times. The algorithms of the work of eddy current flaw detectors based on frequency synthesizers are considered. It makes it possible to significantly increase the speed of such flaw detectors without reducing the accuracy of determining the changes in phase shifts and <b>amplitudes</b> of <b>information</b> signals...|$|R
40|$|Motivation: Baseline removal, as {{the first}} {{preprocessing}} step of SELDI data, critically influences subsequent analysis steps. Current baseline removal algorithms of SELDI data, {{which are based on}} mathematical morphology, result in biased signal estimates. Due to the parameterization of current algorithms for baseline removal, noise and spectral signal distributions bias the removal results, which may lead to seemingly interesting but ultimately irreproducible results in downstream analysis. Results: We proposed a Heuristic Based Baseline Removal (HbBr) algorithm to model the baseline. HbBr first identifies the potential peak regions by utilizing first derivatives and <b>amplitudes</b> <b>information</b> as a fast heuristic, then down-weights peak regions before modeling the baseline with a nonparametric smooth curve. It outperformed mathematical morphology-based algorithms implemented in the PROcess package of Bioconductor, as judged by a series of benchmark experimental data sets and simulated data sets. We also found that HbBr is computationally more efficient than PROcess. Furthermore, we demonstrated that the HbBr algorithm, although designed for SELDI, yields a good baseline correction of MALDI data without adjusting any parameters. Availability: The algorithm is implemented in R and will be included as an open source module in the Bioconductor project...|$|R
40|$|International audienceIn {{this paper}} a new {{approach}} for blurred image restoration is presented. Our algorithm is based on human vision which zooms {{back and forth in}} the image in order to identify global structures or details. Deconvolution parameters are estimated by an edge detection and correspond to the ones of a chosen edge detection model. The segmentation is obtained by merging multiscale information provided by multiscale edge detection. The edge detection is achieved by using a derivative approach following a generalization of Canny-Deriche ﬁltering. This multiscale analysis performs an efﬁcient edge detection in noisy blurred images. The merging leads to the best local representation of edge information across scales. The algorithm deals with a mixed (coarse-to-ﬁne/ﬁne-to-coarse) approach and searches for candidate edge points through the scales. Edge characteristics are estimated by the merging algorithm for the chosen model. Scale, direction and <b>amplitude</b> <b>informations</b> allow a local deconvolution of the original image. The noise problem is not considered in this work since it does not disturb the process. Results show that this method allows non-uniformly blurred image restoration. An implementation of the whole algorithm in an intelligent camera (DSP) has been performed...|$|R
50|$|Time-frequency {{analysis}} {{has been proposed}} as an analysis method {{that is capable of}} overcoming many of the challenges associated with sliding windows. Unlike sliding window analysis, time frequency analysis allows the researcher to investigate both frequency and <b>amplitude</b> <b>information</b> simultaneously. The wavelet transform has been used to conduct DFC analysis that has validated the existence of DFC by showing its significant changes in time. This same method has recently been used to investigate some of the dynamic characteristics of accepted networks. For example, time frequency {{analysis has}} shown that the anticorrelation between the default mode network and the task-positive network is not constant in time but rather is a temporary state.Independent component analysis {{has become one of the}} most common methods of network generation in steady state functional connectivity. ICA divides fMRI signal into several spatial components that have similar temporal patterns. More recently, ICA has been used to divide fMRI data into different temporal components. This has been termed temporal ICA and it has been used to plot network behavior that accounts for 25% of variability in the correlation of anatomical nodes in fMRI.|$|E
5000|$|Ray [...] "Skip" [...] Johnson, Jr., now a {{professor}} at Queens College, published a triarchic model of P300 amplitude in 1986. [...] Although he does not explicitly refer to P3b in this paper, most of his discussions refer to P3b. He offered three things that affected the amplitude - subjective probability, stimulus meaning, and information transmission. He summarized his view in the following formula: P300 amplitude = fx (1/P + M), where P is subjective probability, M is stimulus meaning, and T is information transmitted. [...] He describes subjective probability as objective probability with the added element of human judgment of how relevant a stimulus is to the task, and notes that P300 amplitude {{is directly related to}} the amount of uncertainty that is reduced by a stimulus. However, it has also been found that P300 amplitude can change in the absence of changes in probability. Stimulus meaning therefore refers to variables that account for the processing of a stimulus that are not related to probability. (Recall that Chapman and Bragdon found that only the stimulus that had meaning in their experiment elicited the late positivity.) Stimulus meaning encompasses three independent variables that can be manipulated - task complexity (how difficult a task is, or how many tasks must be performed at once), stimulus complexity (perceptual demand, or how many relevant features of the stimulus must be processed - a face being more complex than a dot), and stimulus value (the significance, or for example the monetary value: the greater the value the larger the P300 <b>amplitude).</b> <b>Information</b> transmission is the proportion of stimulus information received by a person relative to how much information the stimulus originally contained. [...] There are external and internal manipulations of information transmission. When much information is lost for external reasons, for example because the stimulus is harder to discriminate or perceive, P300 amplitude is lower. Internal manipulations are variations in how much attention subjects are required or allowed to give to the stimulus. P3b requires attention, and increasing the difficulty of maintaining attention will correspondingly decrease P3b amplitude. To summarize, Johnson describes that probability on many levels, the relevance of the stimulus to the task, and the amount information a stimulus transmits are all variables that will determine P3b amplitude.|$|E
3000|$|... [...]. Conversely, the {{complete}} knowledge of <b>amplitude</b> <b>information</b> determines the phase information. From an abstract point of view, phase information and <b>amplitude</b> <b>information</b> each individually contain the full information of the signal. In the auditory pathway both phase and <b>amplitude</b> <b>information</b> is being processed. It is commonly assumed that phase information dominates {{in the low}} frequency range and <b>amplitude</b> <b>information</b> in the regions that process high frequencies. The equations tell us that phase processing and amplitude processing are equally significant.|$|E
40|$|Programming as {{mathematical}} narrative Actually, it is {{half the}} art of storytelling to keep a story free from explanation as one reproduces it. [ [...] . ] The most extraordinary things, marvelous things, are related with the greatest accuracy, but the psychological connection of the events is not forced on the reader. It is left up to him to interpret things the way he understands them, and thus the narrative achieves <b>amplitude</b> that <b>information</b> lacks. Walter Benjamin (The storyteller, in Illuminations, p. 86...|$|R
40|$|We {{present a}} {{real-time}} system which allows musicians {{to interact with}} synthetic virtual characters as they perform. Using Max/MSP to parameterize keyboard and vocal input, meaningful features (pitch, <b>amplitude,</b> chord <b>information,</b> and vocal timbre) are extracted from live performance in real-time. These extracted musical features are then mapped to character behaviour {{in such a way}} that the musician 's performance elicits a response from the virtual character. The system uses the ANIMUS framework to generate believable character expressions. Experimental results are presented for simple characters...|$|R
40|$|We report {{measurements}} of quantum oscillations {{detected in the}} putative nematic phase of Sr 3 Ru 2 O 7. Improvements in sample purity enabled the resolution of small amplitude de Haas-van Alphen (dHvA) oscillations between two first order metamagnetic transitions delimiting the phase. Two distinct frequencies were observed, whose amplitudes follow the normal Lifshitz-Kosevich profile. Variations of the dHvA frequencies are {{explained in terms of}} a chemical potential shift produced by reaching a peak in the density of states, and an anomalous field dependence of the oscillatory <b>amplitude</b> provides <b>information</b> on domains...|$|R
