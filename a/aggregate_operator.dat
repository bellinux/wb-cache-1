12|89|Public
40|$|Thesis (M. S.) [...] University of Missouri-Columbia, 1993 Includes bibliographical {{references}} (leaves 99 - 102) Dissertations, Academic [...] University of Missouri [...] Columbia [...] Industrial engineeringCarpal {{tunnel syndrome}} (CTS) {{is a common}} type of neuropathy in which the median nerve is compressed within the carpal tunnel at the wrist. The incidence of carpal tunnel syndrome {{in the work place}} is called occupational carpal tunnel syndrome (OCTS). OCTS is a multifactorial cumulative trauma disorder. This disorder is linked to occupational factors, clinical factors, and personal factors. Our objective is in quantifying factors and predicting the incidence of OCTS. Statistical procedures, back propagation method of neural network, and fuzzy <b>aggregate</b> <b>operator</b> have been adapted to quantify factors and predict the incidence of OCTS...|$|E
40|$|A {{spatial object}} changes its states over time. However, {{existing}} {{spatial and temporal}} database systems cannot fully manage time-varying data with both spatial and non-spatial attributes. To overcome this limitation, we present a framework for spatio-temporal databases that can manage all time-varying historical information and integrate spatial and temporal relationship operators into the select statement in SQL 3. For the purpose of our framework, we define three referencing macros and a history <b>aggregate</b> <b>operator</b> and classify the existing spatial and temporal relationship operators into three groups: exclusively spatial relationship operators, exclusively temporal relationship operators, and spatio-temporal common relationship operators. Finally, we believe the integration of spatial and temporal relationship operators into SQL 3 will provide a useful framework for the history management of time-varying spatial objects in a uniform manner...|$|E
40|$|Abstract—Relational data {{classification}} {{is the problem}} of predicting a class label of a target entity given information about features of the entity, of the related entities, or neighbors, and of the links. This paper compares two fundamental approaches to relational classification: aggregating the features of entities related to a target instance, or aggregating the probabilistic predictions based on the features of each entity related to the target instance. Our experiments compare different relational classifiers on sports, financial, and movie data. We examine {{the strengths and weaknesses of}} both score and feature aggregation, both conceptually and empirically. The performance of a single <b>aggregate</b> <b>operator</b> (e. g., average) can vary widely across datasets, for both feature and score aggregation. Aggregate features can be adapted to a dataset by learning with a set of aggregate features. Used adaptively, aggregate features outperformed learning wit...|$|E
40|$|We {{show how}} to add {{aggregation}} to a constraint database query language. One {{example of the}} use of aggregation in such a database is computing the area of a region in a geographic database. We show how aggregation can be added to the algebra and tuple calculus, and discuss the problems that arise from the interaction of <b>aggregate</b> <b>operators</b> and constraints. 1. 2 Introduction The idea of of combining relational databases with constraint formalisms is introduced in [KKR 90] (see also [KG 94] [Revesz 90]). The key idea is the generalization of the notion of a tuple to a conjunction of constraints. One important aspect of relational databases that is missing in these papers is a discussion of how <b>aggregate</b> <b>operators</b> interact with constraints. In a standard relational database, typical <b>aggregate</b> <b>operators</b> are: sum, average, max and count. In a constraint database, besides these operations, we also want to compute functions such length, area and volume. Other possible <b>aggregate</b> <b>operators</b> include [...] ...|$|R
30|$|This <b>aggregating</b> <b>operator</b> {{provides}} IFVs and {{is currently}} the most popular in the solution of MCDM problems in the intuitionistic fuzzy setting.|$|R
40|$|We study adding <b>aggregate</b> <b>operators,</b> such as {{summing up}} {{elements}} of a column of a relation, to logics with counting mechanisms. The primary motivation comes from database applications, where <b>aggregate</b> <b>operators</b> are present in all real life query languages. Unlike other features of query languages, aggregates are not adequately captured by the existing logical formalisms. Consequently, all previous approaches to analyzing the expressive power of aggregation were only capable of producing partial results, depending on the allowed class of aggregate and arithmetic operations. We consider a powerful counting logic, and extend it with the set of all <b>aggregate</b> <b>operators.</b> We show that the resulting logic satis es analogs of Hanf's and Gaifman's theorems, meaning that it can only express local properties. We consider a database query language that expresses all the standard aggregates found in commercial query languages, and show {{how it can be}} translated into the aggregate logic, thereby pro [...] ...|$|R
40|$|Abstract. We {{provide a}} {{methodology}} which integrates dynamic feature generation from relational databases with statistical feature selection and modeling. Unlike the standard breadth- or depth-first {{search of a}} refinement graph, {{the order in which}} we generate features and test them for inclusion in the model is dynamically determined based on which features are found to be predictive. This best-first search often reduces the number of computationally expensive feature evaluations. Multiple feature streams are created based on the syntactic structure of the feature expressions; for example, based on the type of <b>aggregate</b> <b>operator</b> used to generate the feature. At each iteration, the next feature to be evaluated is taken from the stream which has been producing better features. Experiments show that dynamic feature generation and selection produces more accurate models per feature generated than its static alternative. ...|$|E
40|$|The {{data cube}} is an <b>aggregate</b> <b>operator</b> {{which has been}} shown to be very {{powerful}} for On Line Analytical Processing (OLAP) in the context of data warehousing. It is, however, very expensive to compute, access, and maintain. In this paper we de ne the &quot; as a storage abstraction of the cube and realize it using packed R-trees for most e-cient cube queries. We then reduce the problem of creation and maintenance of the cube to sorting and bulk incremental merge-packing of cubetrees. This merge-pack has been implemented to use separate storage for writing the updated cubetrees, therefore allowing cube queries to continue even during maintenance. Finally, wecharacterize the size of the delta increment for achieving good bulk update schedules for the cube. The paper includes experiments with various data sets measuring query and bulk update performance. ...|$|E
40|$|Stream {{processing}} {{is gaining}} importance as more data becomes {{available in the}} form of continuous streams and companies com-pete to promptly extract insights from them. In such applications, sliding-window aggregation is a central operator, and incremental aggregation helps avoid the performance penalty of re-aggregating from scratch for each window change. This paper presents Reactive Aggregator (RA), a new framework for incremental sliding-window aggregation. RA is general in that it does not require aggregation functions to be invertible or commuta-tive, and it does not require windows to be FIFO. We implemented RA as a drop-in replacement for the <b>Aggregate</b> <b>operator</b> of a com-mercial streaming engine. Given m updates on a window of size n, RA has an algorithmic complexity of Opm ` m logpn{mqq, rivaling the best prior algorithms for any m. Furthermore, RA’s implementa-tion minimizes overheads from allocation and pointer traversals by using a single flat array. 1...|$|E
40|$|AbstractThe aggregative closure problem, a {{transitive}} closure problem with aggregations on transitive paths, is formally defined by database terms. Its definition in our paper holds {{only on the}} subset conditions of path algebra, thereby it is more general than other definitions in previous works. For {{the completion of the}} definition, we suggest conditions for the existence of the fixpoint and classified the conditions as the properties of the <b>aggregate</b> <b>operators</b> and the problem domain. So we can verify the existence of the fixpoint by the suggested conditions. The naive algorithm is proposed as a computational semantics for the aggregative closure problem. This study also proves that for an aggregative closure problem the semi-naive algorithm is computationally equivalent to the naive algorithm when the <b>aggregate</b> product <b>operator</b> is distributive over <b>aggregate</b> sum <b>operator...</b>|$|R
40|$|Data stream {{management}} systems {{may be subject}} to higher input rates than their resources can handle. When overloaded, the system must shed load in order to maintain low-latency query results. In this paper, we describe a load shedding technique for queries consisting of one or more <b>aggregate</b> <b>operators</b> with sliding windows. We introduce a new type of drop operator, called a “Window Drop”. This operator is aware of the window properties (i. e., window size and window slide) of its downstream <b>aggregate</b> <b>operators</b> in the query plan. Accordingly, it logically divides the input stream into windows and probabilistically decides which windows to drop. This decision is further encoded into tuples by marking the ones that are disallowed from starting new windows. Unlike earlier approaches, our approach preserves integrity of windows throughout a query plan, and always delivers subsets of original query answers with minimal degradation in result quality. 1...|$|R
40|$|We {{investigate}} {{the problem of}} rewriting queries with <b>aggregate</b> <b>operators</b> using views {{that may or may}} not contain <b>aggregate</b> <b>operators.</b> A rewriting of a query is a second query that uses view predicates such that evaluating first the views and then the rewriting yields the same result as evaluating the original query. In this sense, the original query and the rewriting are equivalent modulo the view definitions. The queries and views we consider correspond to unnested SQL queries, possibly with union, that employ the operators min, max, count, and sum. Our approach is based on syntactic characterizations of the equivalence of aggregate queries. One contribution of this paper are characterizations of the equivalence of disjunctive aggregate queries, which generalize our previous results for the conjunctive case. For each operator ff, we introduce several types of queries using views as candidates for rewritings. We unfold such a candidate by replacing each occurrence of a view predicate [...] ...|$|R
40|$|Accurate summary data is of {{paramount}} concern in data warehouse systems; however, {{there have been}} few attempts to completely characterize the ability to summarize measures. The sum operator is the typical <b>aggregate</b> <b>operator</b> for summarizing the large amount of data in these systems. We look to uncover and characterize potentially inaccurate summaries resulting from aggregating measures using the sum operator. We discuss the effect of classification hierarchies, and non-, semi-, and fully-additive measures on summary data, and develop a taxonomy of the additive nature of measures. Additionally, averaging and rounding rules can add complexity to seemingly simple aggregations. To deal with these problems, we describe the importance of storing metadata {{that can be used to}} restrict potentially inaccurate aggregate queries. These summary constraints could be integrated into data warehouses, just as integrity constraints and are integrated into OLTP systems. We conclude by suggesting methods for identifying and dealing with non- and semi- additive attributes...|$|E
40|$|Abstract. Ranking-aware queries {{have been}} gaining much {{attention}} recently in many {{applications such as}} search engines and data streams. They are, however, not only restricted to such applications but are also very useful in OLAP applications. In this paper, we introduce aggregation ranking queries in OLAP data cubes motivated by an online advertisement tracking data warehouse application. These queries aggregate information over a specified range and then return the ranked order of the aggregated values. They differ from range aggregate queries in that range aggregate queries are mainly concerned with an <b>aggregate</b> <b>operator</b> such as SUM and MIN/MAX over the selected ranges of all dimensions in the data cubes. Existing techniques for range aggregate queries {{are not able to}} process aggregation ranking queries efficiently. Hence, in this paper we propose new algorithms to handle this problem. The essence of the proposed algorithms is based on both ranking and cumulative information to progressively rank aggregation results. Furthermore we empirically evaluate our techniques and the experimental results show that the query cost is improved significantly. ...|$|E
40|$|Sliding Window is {{the most}} popular data model in {{processing}} data streams as it captures finite and relevant subset of an infinite stream. This paper studies different Mathematical operators used for querying and mining of datastreams. The focus of our study is on operators, operating on the whole data set. These are termed as blocking operators. We have classified these operators according to their method of evaluation. An operator is termed as <b>aggregate</b> <b>operator</b> if it produces the sub-set of values satisfying some given condition. The evaluation of these operators is more complex when the query is continuous and data are changing. We present here a formal definition of incremental computation onsliding windows. We have proposed a vector model and graph abstraction to represent the sliding window and algorithms to evaluate Mathematical operators on the sliding window. The model is robust and can be applied to visualize different mathematical operators on the sliding window. We have introduced a novel concept of checkpoints {{in order to make the}} computation incremental. We present an efficient algorithm to find maximum (or minimum) on the sliding windows using the checkpoint concept...|$|E
40|$|Equivalence of {{aggregate}} queries is {{investigated for}} the class of conjunctive queries with comparisons and the <b>aggregate</b> <b>operators</b> min, max, count, count-distinct, and sum. Essentially, this class contains all unnested SQL queries with the above <b>aggregate</b> <b>operators,</b> with a WHERE clause consisting of a conjunction of comparisons, and without a HAVING clause. The comparisons can be interpreted over either a dense order (e. g., over the rationals) or a discrete order (e. g., over the integers). Generally, however, different techniques and characterizations are needed {{in each of these}} two cases. For queries with either max or min, equivalence is characterized in terms of dominance mappings, which {{can be viewed as a}} generalization of containment mappings. For queries with the count-distinct operator, a sufficient condition for equivalence is given in terms of equivalence of conjunctive queries under set semantics. For some special cases, it is shown that this condition is also necessary. For [...] ...|$|R
40|$|We {{discuss the}} issues that arise when we add {{aggregation}} to a constraint database query language. One example {{of the use of}} aggregation in such a context is to compute the area of a region in a geographic database. We show how aggregation could be added to the query language, tuple calculus, and discuss the problems that arise from the interaction of <b>aggregate</b> <b>operators</b> and constraints. 1 Introduction [KKR 90] proposes the use of constraint query languages as a natural way of combining relational databases with constraint formalisms (see also [Kuper 90] [Revesz 90]). One important aspect of relational databases that is not discussed in that paper is the use of aggregation. Typical <b>aggregate</b> <b>operators</b> in relational databases are: Sum, Average, Count. In a spatial database, the simplest analogue is computing the area of an object. More complicated aggregate operations, such as averaging an attribute over a given region, could be useful. In this paper, we outline a method to add aggregatio [...] ...|$|R
40|$|We {{present a}} formal {{treatment}} of multisets (that arise when duplicates are not eliminated) and <b>aggregate</b> <b>operators</b> for deductive and relational databases. We define the semantics rigorously {{and extend the}} magic-sets technique to programs containing multisets and aggregates. The work presented here {{is an important step}} in demonstrating the applicability of the magic-sets technique for optimizing queries in commercial query languages such as SQL...|$|R
40|$|Abstract: Sliding Window is {{the most}} popular data model in {{processing}} data streams as it captures finite and relevant subset of an infinite stream. This paper studies different Mathematical operators used for querying and mining of data streams. The focus of our study is on operators, operating on the whole data set. These are termed as blocking operators. We have classified these operators according to their method of evaluation. An operator is termed as <b>aggregate</b> <b>operator</b> if it produces the sub-set of values satisfying some given condition. The evaluation of these operators is more complex when the query is continuous and data are changing. We present here a formal definition of incremental computation on sliding windows. We have proposed a vector model and graph abstraction to represent the sliding window and algorithms to evaluate Mathematical operators on the sliding window. The model is robust and can be applied to visualize different mathematical operators on the sliding window. We have introduced a novel concept of checkpoints {{in order to make the}} computation incremental. We present an efficient algorithm to find maximum (or minimum) on the sliding windows using the checkpoint concept. Key words: Algorithm, incremental, sliding window...|$|E
40|$|Ranking-aware queries {{have been}} gaining much {{attention}} recently in many {{applications such as}} search engines and data streams. They are, however, not only restricted to such applications but are also very useful in OLAP applications. In this paper, we introduce aggregation ranking queries in OLAP data cubes motivated by an online advertisement tracking data warehouse application. These queries aggregate information over a specified range and then return the ranked order of the aggregated values. For instance, an advertiser {{might be interested in}} the top-k publishers over the last three months in terms of sales obtained through the online advertisements placed on the publishers. They differ from range aggregate queries in that range aggregate queries are mainly concerned with an <b>aggregate</b> <b>operator</b> such # $ % as %' & () % * + and over the selected ranges of all dimensions in the data cubes. Existing techniques for range aggregate queries are not able to process aggregation ranking queries efficiently. Hence, in this paper we propose new algorithms to handle this problem. The essence of the proposed algorithms is based on both ranking and cumulative information to progressively rank aggregation results. Furthermore we empirically evaluate our techniques and the experimental results show that the query cost is improved significantly. ...|$|E
40|$|Interactive data {{exploration}} platforms in Web, {{business and}} scientific domains {{are becoming increasingly}} popular. Typically, users without prior knowledge of data interact with these platforms in an exploratory manner hoping they might retrieve the results they are looking for. One way to explore large-volume data is by posing aggregate queries which group values of multiple rows by an <b>aggregate</b> <b>operator</b> to form a single value: an aggregated value. Though, when a query fails, i. e., returns undesired aggregated value, users will have to undertake a frustrating trial-and-error process to refine their queries, until a desired result is attained. This data exploration process, however, is growing rather difficult as the underlying data is typically of large-volume and high-dimensionality. While heuristic-based techniques are fairly successful in generating refined queries that meet specified requirements on the aggregated values, they are rather oblivious to the (dis) similarity between the input query and its corresponding refined version. Meanwhile, enforcing a similarity-aware query refinement is rather a non-trivial challenge, as it requires a careful examination of the query space while maintaining a low processing cost. To address this challenge, we propose an innovative scheme for efficient Similarity-Aware Refinement of Aggregation Queries called (EAGER) which aims to balance the tradeoff between satisfying the aggregate and similarity constraints imposed on the refined query to maximize its overall benefit to the user. To achieve that goal, EAGER implements efficient strategies to minimize the costs incurred in exploring the available search space by utilizing similarity-based and monotonic-based pruning techniques to bound the search space and quickly find a refined query that meets users’ expectations. Our extensive experiments show the scalability exhibited by EAGER under various workload settings, and the significant benefits it provides...|$|E
40|$|We {{investigate}} {{the problem of}} how to extend constraint query languages with <b>aggregate</b> <b>operators.</b> We deal with standard relational aggregation, and also with aggregates specific to spatial data, such as volume. We study several approaches, including the addition of a new class of approximate <b>aggregate</b> <b>operators</b> which allow an error tolerance in the computation. We show how techniques of [23, 25] based on VC-dimension can be used to give languages with approximation operators, but also show that these languages have a number of shortcomings. We then give a set of results showing that it is impossible to get constraint-based languages that admit de nable aggregation operators, both for exact operators and for approximate ones. These results are quite robust, in that they show that closure under aggregation is problematic even when the class of functions permitted in constraints is expanded. This motivates a different approach to the aggregation problem. We introduce a language FO + Poly+Sum, which permits standard discrete aggregation operators to be applied to the outputs of range-restricted constraint queries. We show that this language has a number of attractive closure and expressivity properties, and that it can compute volumes of linear-constraint databases...|$|R
40|$|A {{crucial part}} of {{relational}} query optimiza-tion is the reordering of query processing for more efficient query evaluation. The reordering may be explicit or implicit. Our major goal in {{this paper is to}} describe manipulation rules for queries that include outerjoins, and views or nested subqueries. By expressing queries and processing Strategies in terms of relational algebra, one can use the ordinary mechanisms of query optimization and view substitution with a minimum of disrupt ion. We also <b>aggregate</b> <b>operators,</b> universal sorting. 1...|$|R
40|$|Fuzzy subgroups and T-vague {{groups are}} {{interesting}} fuzzy algebraic structures {{that have been}} widely studied. While fuzzy subgroups fuzzify the concept of crisp subgroup, T-vague groups can be identified with quotient groups of a group by a normal fuzzy subgroup {{and there is a}} close relation between both structures and T-indistinguishability operators (fuzzy equivalence relations). In this paper the functions that aggregate fuzzy subgroups and T-vague groups will be studied. The functions <b>aggregating</b> T-indistinguishability <b>operators</b> have been characterized [9] and the main result of this paper is that the functions <b>aggregating</b> T-indistinguishability <b>operators</b> coincide with the ones that aggregate fuzzy subgroups and T-vague groups. In particular, quasi-arithmetic means and some OWA <b>operators</b> <b>aggregate</b> them if the t-norm is continuous Archimedean. Peer ReviewedPostprint (author's final draft...|$|R
40|$|Enabling {{enterprise}} {{beans to}} implement web service endpoints and utilize web services Providing a container-managed timer service Enhancing EJB QL {{with the addition}} of ORDER BY and <b>aggregate</b> <b>operators</b> Extending the message-driven bean component type to other messaging typesClient View 01 public class WarehouseBean 02 implements SessionBean{ 03 public void checkPrice ( [...] .) { 04 Context ctx = new InitialContext (); 05 PriceSearchService pss = ctx. lookup (06 “java:comp/env/service/PriceSearchService”) 07 PriceSearchProvider psp = pss. getPriceSearchProviderPort (); 08 float itemPrice = psp. getListingPrice ( [...] .); [...] . }...|$|R
5000|$|Strong {{soon began}} {{recording}} Operator's Atlantic debut {{as a solo}} album playing the lead/rhythm guitar, Bass, Piano, backing and lead vocals. He eventually put together a band to play live; rhythm consisting of guitarist Paul Phillips, Lead guitarist Rikki Lixx, bassist Wade Carpenter, and drummer Dorman Pantfoeder completed the lineup. Thus <b>aggregated,</b> <b>Operator's</b> Atlantic debut, Soulcrusher, was released {{in the summer of}} 2007. The album has since sold over 110,000 copies and peaked No. 14 on the heatseekers chart and has produced three singles: [...] "Soulcrusher", [...] "Nothing to Lose" [...] and [...] "Delicate".|$|R
40|$|Views {{stored in}} a data {{warehouse}} need to be kept current. As recomputing the views is very expensive, incremental maintenance algorithms are required. Over recent years, several incremental maintenance algorithms have been proposed. None of the proposed algorithms handle the case of general relational expressions involving <b>aggregate</b> and/or outerjoin <b>operators.</b> Moreover, {{in most of the}} maintenance algorithms proposed, changes are propagated as insertions and deletions. In this article, we develop a framework of change-tables and a refresh operator for incrementally maintaining general view expressions involving relational and <b>aggregate</b> <b>operators.</b> We show that the presented techniques outperform the previously proposed techniques by orders of magnitude. The developed framework easily extends to efficiently maintaining view expressions containing outerjoin operators. Moreover, the framework also yields an approach to allow propagation of certain kinds of deletions and updates directly in [...] ...|$|R
40|$|SQL {{is full of}} {{difficulties}} and traps for the unwary. You can avoid them if you understand relational theory, {{but only if you}} know how to put the theory into practice. In this insightful book, author C. J. Date explains relational theory in depth, and demonstrates through numerous examples and exercises how you can apply it directly to your use of SQL. This second edition includes new material on recursive queries, "missing information" without nulls, new update operators, and topics such as <b>aggregate</b> <b>operators,</b> grouping and ungrouping, and view updating. If you have a modest-to-advanced bac...|$|R
40|$|AbstractThe {{operator}} “min” {{is one of}} {{the most}} frequently used aggregation operators in fuzzy decision. However, this operator is the softest operator and no allowance is made for any compensation. The “product” and other operators, some of them may be compensatory, are seldom used because of the nonlinearity of the resulting problem. In this paper, an exponential, instead of linear membership function is proposed. The advantages of using exponential membership are two fold. First, the resulting problems can be transformed to linear ones when the “product” and several other nonlinear <b>aggregate</b> <b>operators</b> are used. Secondly, exponential representation is more realistic than the linear ones usually used for some practical applications...|$|R
40|$|In many data {{gathering}} applications, information {{arrives in the}} form of continuous streams rather than finite data sets. Efficient one-pass algorithms are required to cope with high input loads. Stream processing engines support continuous queries to process data in a real-time fashion and have evolved rapidly from centralized to distributed, parallel and elastic solutions. While a big effort has been put on leveraging the processing capacity of clusters of machines, less work has focused on leveraging the parallelism enabled by multi-core architectures by means of concurrent and lock-free data structures, to support the pipeline. This paper explores this aspect focusing on multiway aggregation, where large data volumes are received from multiple input streams. Multiway aggregation is crucial in contexts such as sensor networks, social media or clickstream analysis applications. We provide three enhanced <b>aggregate</b> <b>operators</b> that rely on two new concurrent data structures and their lock-free implementations, supporting both order-sensitive and order-insensitive aggregation functions. We provide an extensive study of the properties of the proposed <b>aggregate</b> <b>operators</b> and the new data structures. We also show an extensive experimental evaluation of the proposed methods, giving empirical evidence of their superiority. In this evaluation we run a variety of aggregation queries on two large datasets, one with data extracted from SoundCloud, a music social network, and one with data from a smart grid metering network. In all the experiments, the new data structures improved the aggregation performance significantly, up to one order of magnitude, in terms of both processing throughput and latency...|$|R
30|$|If {{we apply}} the {{proposed}} IFHIWA <b>operator</b> to <b>aggregate</b> the different IFNs as given in Example 2 {{then we get}} aggregated IFN are 〈 0.5137, 0.2196 〉 when γ = 1 and 〈 0.5060, 0.2231 〉 when γ = 2. On the other hand, if we apply proposed <b>aggregated</b> <b>operator</b> on modified IFNs then we get IFHIWA(α _ 1,β _ 2,β _ 3,α _ 4)=〈 0.3443, 0.2257 〉 for γ = 1 and 〈 0.3422, 0.2264 〉 for γ = 2. Thus, the change of membership function will affect {{on the degree of}} non-membership functions and is non-zero. Therefore, there is a proper interaction between the degree of membership and non-membership functions and hence the results are consistent and more practical than the existing operators results.|$|R
40|$|ABSTRACT: Two major {{abstract}} {{data manipulation}} models, the relational calculus and relational algebra, were proposed {{in relation to}} Rela-tional Model. However, these {{are known to be}} not powerful enough for dealing with advanced applications that require various complicated operations in various value sets. Also it is known that these are not suitable for describ-ing traditional data processing applications. In this paper two extensions of the alpha ex-pression, a pair of a relational calculus and a target list, are proposed. One is a exten-sion that enables us to use various <b>operators</b> (including <b>aggregate</b> <b>operators)</b> in various value set in defining the relational calculus and target list. The second extension is in-troduction of imaginary tuples that enables us easy description and effective implementation of traditional data processing applications. 1...|$|R
40|$|We address {{efficient}} {{processing of}} SPARQL queries over RDF datasets. The proposed techniques, {{incorporated into the}} gStore system, handle, in a uniform and scalable manner, SPARQL queries with wildcards and <b>aggregate</b> <b>operators</b> over dynamic RDF datasets. Our approach is graph based. We store RDF data as a large graph and also represent a SPARQL query as a query graph. Thus, the query answering problem is converted into a subgraph matching problem. To achieve efficient and scalable query processing, we develop an index, together with effective pruning rules and efficient search algorithms. We propose techniques that use this infrastructure to answer aggregation queries. We also propose an effective maintenance algorithm to handle online updates over RDF repositories. Extensive experiments confirm the efficiency and effectiveness of our solutions...|$|R
40|$|This article {{studies the}} {{aggregation}} of transitive fuzzy relations. We first find operators that preserve transitivity and then extend {{the results to}} <b>aggregating</b> <b>operators.</b> As special cases, means {{and some kind of}} suitable ordered weighted averaging (OWAs) are used to aggregate transitive fuzzy relations with respect to an Archimedean t-norm. Three families of transitive relations that allow us to modify the entries of a given relation R continuously towards the smallest and the greatest ones in our universe are given. Aggregation of nonfinite families of transitive relations also is studied and applied to calculate the degree of inclusion or similarity of fuzzy quantities (fuzzy subsets of an interval of the real line). © 2003 Wiley Periodicals, Inc. Postprint (published version...|$|R
40|$|We {{investigate}} {{the problem of}} rewriting queries with <b>aggregate</b> <b>operators</b> using views {{that may or may}} not contain <b>aggregate</b> <b>operators.</b> A rewriting of a query is a second query that uses view predicates such that evaluating first the views and then the rewriting yields the same result as evaluating the original query. In this sense, the original query and the rewriting are equivalent modulo the view definitions. The queries and views we consider correspond to unnested SQL queries, possibly with union, that employ the operators min, max, count, and sum. Our approach is based on syntactic characterizations of the equivalence of aggregate queries. One contribution of this paper are characterizations of the equivalence of disjunctive aggregate queries, which generalize our previous results for the conjunctive case. For each operator a, we introduce several types of queries using views as candidates for rewritings. We unfold such a candidate by replacing each occurrence of a view predicate with its definition, thus obtaining a regular aggregate query. The candidates have a different, usually more complex operator than a. We prove that unfolding the candidate, however, results in a regular aggregate query that is equivalent to the candidate modulo the view definitions. This property justifies considering these types of queries as natural candidates for rewritings. In this way, we reduce the problem of whether there exist rewritings of a particular type to a problem involving equivalence. We distinguish between partial rewritings that contain at least one view predicate and complete rewritings that contain only view predicates. In contrast to previous work on this topic, we not only give sufficient, but also necessary conditions for a rewriting to exist. More precisely, we show for each type of candidate that the existence of both, partial and complete rewritings is decidable, and we provide upper and lower complexity bounds...|$|R
30|$|The {{experiments}} {{were carried out}} on 10 GB versions of the TPC-H and TPC-DS benchmark databases. For TPC-H, we constructed the queries on lineitem, the largest table in the TPC-H schema (60 million rows). Each query had range predicates on four attributes, with the predicates covering the entire spectrum of selectivities. The reason we used synthetically created queries is because the native queries were either not rich in range predicates, or contained <b>aggregate</b> <b>operators</b> which we currently do not handle. On the other hand, for TPC-DS, we directly invoked three benchmark queries (queries Q 82, Q 87, and Q 96) which contained only range predicates, and could therefore be fully executed on a SPLIT encrypted version of the database. The listings of these queries are provided in [24].|$|R
