6|83|Public
40|$|In this article, we {{evaluate}} {{the impact of}} link layer retransmissions {{on the performance of}} TCP in the context of aeronautical communications. We present the architecture of aeronautical networks, which is manly driven by an important channel access delay, and the various retransmission strategies that can be implemented at both link and transport layers. We consider a worst case scenario to illustrate the benefits provided by the ARQ scheme at the link layer in terms of transmission delay. We {{evaluate the}} trade-off between allowing a fast data transmission and a low usage of satellite capacity by <b>adjusting</b> <b>link</b> layer parameters...|$|E
40|$|In {{this paper}} we survey {{a variant of}} the inverse {{shortest}} paths problem. Given is a network in which certain node-pairs require connections over specific predefined single paths. The aim is to find link weights such that the desired paths are uniquely induced by a shortest-path algorithm. Further we require that the link weights fit existing shortest-path based routing protocols. We give a motivation for this problem, discuss a number of its solvability aspects, and show how a feasible solution can be obtained from its linear relaxation. A network operator who wants to obtain a specific routing pattern by <b>adjusting</b> <b>link</b> weights, will find practical use of the solution to the considered problem. ...|$|E
40|$|Dynamic Transfer Mode (DTM) is a ring based MAN {{technology}} {{that provides a}} channel abstraction with a dynamically adjustable capacity. TCP is a reliable end to end transport protocol capable of adjusting its rate. The primary goal of this work is investigate the coupling of dynamically allocating bandwidth to TCP flows with the a#ect this has on the congestion control mechanism of TCP. In particular {{we wanted to find}} scenerios where this scheme does not work, where either all the link capacity is allocated to TCP or congestion collapse occurs and no capacity is allocated to TCP. We have created a simulation environment using ns- 2 to investigate TCP over networks which have a variable capacity link. We begin with a single TCP Tahoe flow over a fixed bandwidth link and progressively add more complexity to understand the behaviour of dynamically <b>adjusting</b> <b>link</b> capacity to TCP and vice versa. ...|$|E
5000|$|EDF has {{negotiated}} a guaranteed fixed price - a [...] "strike price"- for electricity from Hinkley Point C of £92.50/MWh (in 2012 prices), {{which will be}} <b>adjusted</b> (<b>linked</b> to inflation) during the construction period and over the subsequent 35 years tariff period. The strike price could fall to £89.50/MWh if a new plant at Sizewell is also approved.|$|R
50|$|Some {{authors have}} {{proposed}} that to make datacenter networks more energy proportional, the routing elements need greater power dynamic range. They proposed {{the use of the}} flattened butterfly topology instead of the common folded Clos network in use in datacenters (also known as the fat tree) to improve overall power efficiency, and to use adaptive <b>link</b> rates to <b>adjust</b> <b>link</b> power in relation to utilization. They also propose predicting future link utilization to scale data rates in anticipation.|$|R
40|$|An {{efficient}} {{combination of}} repetitive coded L-PPM with an ARQ protocol is presented which can estimate the channel state and <b>adjust</b> the <b>link</b> transmission rate. The protocol operation is modelled as a Markov chain and analysis results indicate the enhanced {{performance of the}} proposed scheme under adverse channel conditions...|$|R
40|$|Research Areas: Networking and CommunicationsResearch Topics: Network Management, NetworkingNetwork {{operators}} use {{traffic engineering}} {{to control the}} flow of traffic across their networks. Existing TE methods establish static topologies offline, either by setting link weights or by configuring paths a priori. These methods require manual configuration {{and may not be}} robust in the face of failures. Some methods also require knowledge about traffic demands and {{may not be able to}} handle traffic fluctuations. Even when changes in demand are expected, operators must manually tune network configurations to prepare for them. Because adjusting configurations is difficult to get right, we start from an extreme design point, asking instead whether it is possible to perform traffic engineering online without having to perform any a priori configuration. Our traffic engineering technique, SculpTE, adapts to changing traffic demands by automatically configuring link weights in a stable manner. SculpTE balances load across the network by continually <b>adjusting</b> <b>link</b> weights to expose lightly-loaded paths. We evaluate SculpTE using a simple analytical model and simulations on realistic ISP network topologies. Our results show that SculpTE achieves excellent load balancing, responsiveness, and stability compared to state-of-the-art TE schemes, without requiring network operators to perform any offline configuration...|$|E
40|$|Due to the {{character}} of the original source materials and the nature of batch digitization, quality control issues may be present in this document. Please report any quality issues you encounter to digital@library. tamu. edu, referencing the URI of the item. Includes bibliographical references (leaves 52 - 55). Issued also on microfiche from Lange Micrographics. Facing limited network resources such as bandwidth and processing capability, the Internet will have congestion from time to time. In this thesis, we propose a scheme to maximize the total utility offered by the network to the end user during congested times. We believe the only way to achieve our goal is to make the scheme application-aware, that is, to take advantage of {{the character}}istics of the application. To make our scheme scalable, it is designed to be class-based. Traffic from applications with similar characteristics is classified into the same class. We adopted the RED queue management mechanism to adaptively control the traffic belonging to the same class. To achieve the optimal utility, the traffic belonging to different classes should be controlled differently. By <b>adjusting</b> <b>link</b> bandwidth assignments of different classes, the scheme can achieve the goal and adapt to the changes of dynamical incoming traffic. We use the control heoretical approach to analyze our scheme...|$|E
40|$|Even if the Internet is {{commonly}} considered a formidable mean {{to reduce the}} impact of human activities on the environment, its energy consumption is rapidly becoming an issue due to the exponential traffic growth and {{the rapid expansion of}} communication infrastructures worldwide. One of the first options available to reduce energy consumption is that of limiting wastes. Actually, even if {{it has been shown that}} traffic load greatly varies over time and rarely saturates available capacity, the energy consumed by the network is almost constant as if it were fully loaded at all time. In this paper we propose an IP traffic engineering approach that allows to adapt the network energy consumption to different daily traffic scenarios switching on and off communication interfaces (links) and entire routers. We focus on routing domains of the Internet Service Providers where the popular OSPF (Open Shortest Path First) protocol is adopted and we consider the problem of switching off network elements (links and routers) and of <b>adjusting</b> <b>link</b> weights so as to minimize the energy consumption and the network congestion. We present two heuristics for this problem: the Greedy Algorithm for Energy Saving (GA-ES) and the Two-stage Algorithm for Energy Saving (TA-ES). The computational results for three real network topologies show that it is possible to switch off up to 80 % of the core nodes during low traffic periods (night hours), and up to 65 % during moderate traffic periods, while guaranteeing the same point-to-point service quality, and moderately increasing the network congestion...|$|E
40|$|Abstract—Data centre power {{consumption}} {{can be reduced}} by switching off servers during low load. However, excess switching is wasteful. This paper reviews online algorithms for optimizing this tradeoff, including the benefits of shifting load between geographically distant data centres. These algorithms can also <b>adjust</b> a <b>link’s</b> number of parallel lightpaths. I...|$|R
40|$|Abstract — In a {{multi-rate}} wireless network, a node can dynamically <b>adjust</b> its <b>link</b> {{transmission rate}} by switching between different modulation schemes. For the current IEEE 802. 11 a/b/g standards, this rate adjustment {{is limited to}} unicast traffic only while multicast and broadcast traffic is always transmitted at the lowest possible rate. In this paper, we consider a novel type of multi-rate mesh networks where a node can dynamically <b>adjust</b> its <b>link</b> layer multicast rates to its neighbours. In particular, we consider the problem of realising low latency network-wide broadcast {{in this type of}} multi-rate wireless meshes. We will first show that the multi-rate broadcast problem is significantly different from the single-rate case. We will then present an algorithm for achieving low latency broadcast in a multi-rate mesh which exploits both wireless broadcast advantage and the multi-rate nature of the network. I...|$|R
5000|$|... #Caption: A {{collection}} of various designs of temperature compensation equaliser. Some can be <b>adjusted</b> with plugable <b>links,</b> others require soldering. Adjustment {{is not very}} frequent.|$|R
40|$|In this demo, {{we present}} Ripcord, a modular {{platform}} for rapidly prototyping scale-out data center networks. Rip-cord enables researchers {{to build and}} evaluate new network features and topologies, using only commercially available hardware and open-source software. The Ripcord demo will show three examples of custom network functions, operating together, {{on top of a}} 160 -node cluster. The first is a routing engine that isolates classes of traffic. The second is a dy-namic network manager than <b>adjusts</b> <b>links</b> and switch power states to reduce energy. The third is a statistics aggrega-tor that supports network health monitoring and automatic alerts. The demo will be interactive, with a visualization of live parameters for each link and switch, such as bandwidth, drops, and power status, as well a control panel to modify the traffic load. We feel that an interactive demo {{is the best way to}} introduce the research community to Ripcord and get their feedback...|$|R
40|$|Abstract—Routing {{optimization}} {{is a key}} {{aspect to}} take into account when providing QoS in next generation networks (NGN), especially in access networks. The problem of weight setting with conventional link state routing protocols for routing optimization has been studied in order to <b>adjust</b> <b>link’s</b> utilization and it has been object of study by a few authors. Among different approaches, GAs have been devised {{as one of the most}} appealing methodologies to tackle this problem since it becomes NP-hard when applied to large networks. In particular, some authors have used hybrid GAs (memetic GAs) which incorporate local search procedures in order to optimize the GA results. This paper has proposed and implemented the integration of routing optimization using HGA with the ITU-T architecture for QoS resource control in Next Generation Networks (NGN). The implementation has been done over an IPv 6 Linux testbed with OPSPv 3 using the ITU-T proposed COPS-PR protocol for the policy delivery, in this case the weight setting delivery. Keywords- QoS; PBNM; ITU-T; NGN; traffic engineering; routing optimization; OSPF; IPv 6; hybrid genetic algorithm; local searc...|$|R
40|$|In {{this paper}} {{we present a}} novel {{experimental}} platform for network management able to dynamically optimize the energy consumption of backbone IP networks operating with OSPF. The idea is to efficiently <b>adjust</b> <b>link</b> weights to put to sleep idle devices. The framework relies on multiple precomputed sets of link weights that are applied to the considered network domain according to real time measurements on the link utilization. The management module exploits the Simple Network Management Protocol (SNMP) to collect the load measurements and modify the link weights. The pre-computed link weights are calculated by running a state-of-the-art algorithm for off-line energy-aware traffic engineering based on predicted traffic matrices. The modules of the platforms have been implemented for Linux based environments and tested using emulated networks of virtual machines. Experimental results showed {{a significant reduction in}} terms of network resources required to route traffic demands, demonstrating how, in average, 20 % of nodes and 40 % of links, can be put to sleep without compromising network performance and stability...|$|R
40|$|Originally {{developed}} to connect processors and memories in multicomputers, prior research {{and design of}} interconnection networks have focused largely on performance. As these networks get deployed {{in a wide range}} of new applications, where power is becoming a key design constraint, we need to seriously consider power efficiency in designing interconnection networks. As the demand for network bandwidth increases, communication links, already a significant consumer of power now, will take up an ever larger portion of total system power budget. In this paper, we motivate the use of dynamic voltage scaling (DVS) for links, where the frequency and voltage of <b>links</b> are dynamically <b>adjusted</b> to minimize power consumption. We propose a history-based DVS policy that judiciously <b>adjusts</b> <b>link</b> frequencies and voltages based on past utilization. Our approach realizes up to 6. 3 X power savings (4. 6 X on average). This is accompanied by a moderate impact on performance (15. 2 % increase in average latency before network saturation and 2. 5 % reduction in throughput.) To the best of our knowledge, this is the first study that targets dynamic power optimization of interconnection networks...|$|R
40|$|Methods for {{efficient}} mining {{of frequent}} patterns {{have been studied}} extensively by many researchers. However, the previously proposed methods still encounter some performance bottlenecks when mining databases with different data characteristics, such as dense vs. sparse, long vs. short patterns, memory-based vs. disk-based, etc. In this study, we propose a simple and novel hyperlinked data structure, H-Struct, and a new mining algorithm, H-mine, which takes advantage of this data structure and dynamically <b>adjusts</b> <b>links</b> in the mining process. A distinct feature of this method {{is that it has}} very limited and precisely predictable space overhead and runs really fast in memory-based setting. Moreover, it can be scaled up to very large databases by database partitioning, and when the data set becomes dense, (conditional) FP-trees can be constructed dynamically as part of the mining process. Our study shows that H-mine has high performance in various kinds of data, outperforms the previously developed algorithms in different settings, and is highly scalable in mining large databases. This study also proposes a new data mining methodology, space-preserving mining, which may have strong impact in the future development of efficient and scalable data mining methods. © 2001 IEEE...|$|R
40|$|In this paper, {{we address}} the rate control {{problem in a}} {{multihop}} random access wireless network, {{with the objective of}} achieving proportional fairness amongst the end-to-end sessions. The problem is considered in the framework of nonlinear optimization. Compared to its counterpart in a wired network where link capacities are assumed to be fixed, rate control in a multi-hop random access network is much more complex and requires joint optimization at both the transport layer and the link layer. This {{is due to the fact}} that the attainable throughput on each link in the network is ‘elastic’ and is typically a non-convex and non-separable function of the transmission attempt rates. Two cross-layer algorithms, a dual based algorithm and a primal based algorithm, are proposed in this paper to solve the rate control problem in a multi-hop random access network. Both algorithms can be implemented in a distributed manner, and work at the <b>link</b> layer to <b>adjust</b> <b>link</b> attempt probabilities and at the transport layer to adjust session rates. We prove rigorously that the two proposed algorithms converge to the globally optimal solutions. Simulation results are provided to support our conclusions...|$|R
50|$|The dynamic linker can be {{influenced}} into modifying its behavior during either the program's execution or the program's linking.A typical modification of this behavior {{is the use}} of the LIBPATH environment variable.This variable <b>adjusts</b> the runtime <b>linking</b> process by searching for shared libraries at alternate locations and by forcibly loading and linking libraries that would otherwise not be, respectively.|$|R
40|$|Abstract — The {{problem of}} {{providing}} end-to-end delay guarantees for deterministic-delay services in multi-service packet networks is addressed {{through a combination}} of dynamic resource reservation and routing. Our model is based on using rate-controlled earliest-deadline-first (RC-EDF) for providing hard bounds on end-to-end delays. With RC-EDF a certain delay bound has to be allocated for a connection at each node in the selected path. The most commonly used resource reservation policy is uniform allocation which is based on dividing the end-to-end delay bound equally among the nodes in the selected path. This simple allocation policy could lead to non-uniform resource loading and subsequently lead to high blocking rates. Moreover, the most commonly used routing method is shortest-path first routing which is known to lead to network hotspots. We propose a set of dynamic non-uniform resource reservation policies and dynamic routing methods. One of the routing methods is the well-known widest-shortest path method and the other is a dynamic routing method that adaptively <b>adjusts</b> <b>link</b> costs and uses a similar algorithm to shortestpath routing (e. g. Dijkstra’s algorithm). We show that for both uniform and non-uniform traffic loading of some example network topologies that the combination of the proposed resource reservation policies and dynamic routing can lead to significant reduction in the connection blocking ratio in all loading conditions except for excessively high loads [...] Index Terms — Call admission control, deterministic delay bounds, quality of service routing, rate-controlled earliestdeadlin...|$|R
5|$|By {{gathering}} clues and {{manipulating the}} environment, the player solves thematically linked puzzles. For example, the book leading to Voltaic is accessed by aligning beams of light across a canyon; the Age itself contains similar energy-based puzzles. Edanna's plant-filled puzzles require {{manipulation of the}} Age's ecosystem. Puzzles often involve observing interactions between elements of the environment, then <b>adjusting</b> the <b>links</b> between them. The player can also pick up and view journals or pages written by game characters which reveal back-story and give hints to solving puzzles. Cursor Mode allows the player to select items from a personal inventory {{at the bottom of}} the screen.|$|R
40|$|We {{discuss a}} {{methodology}} to dynamically generate links among digital objects {{by means of}} an unsupervised learning mechanism which analyzes user link traversal patterns. We performed an experiment with a test bed of 150 complex data objects, referred to as buckets. Each bucket manages its own content, provides methods to interact with users and individually maintains a set of links to other buckets. We demonstrate that buckets were capable of dynamically <b>adjusting</b> their <b>links</b> to other buckets according to user link selections, thereby generating a meaningful network of bucket relations. Our results indicate such adaptive networks of linked buckets approximate the collective link preferences of a community of userComment: pages: 1...|$|R
40|$|Traffic Engineering in both MPLS and OSPF {{networks}} {{has come}} under close scrutiny from the research com-munity {{over the past few}} years. We propose a novel approach to tackle the traffic engineering problem in OSPF networks. Our approach is based on top of a recent method that proposes to shift the traffic engineering capabilities of the IP core to the edge routers where traffic is split unevenly through k connections to achieve near optimal load balance. We show how dynamic Huffman trees can efficiently be used to guide IP traffic into the core by <b>adjusting</b> the <b>link</b> weights in a dynamic fashion. Our results are yet to be published. 1...|$|R
30|$|The {{accuracy}} of our proposed predictor is presented here by two means: slot(s) state and idle time slot(s) prediction. The training and {{validation of the}} proposed MLP are carried out for both slot(s) state and idle time slot(s). Generally speaking, the training refers to the phase of NN in which the nonlinear mapping between the inputs and the desired outputs is done by <b>adjusting</b> the <b>link</b> weights. The weights are adaptively adjusted by minimizing the mean square error between the desired and the actual MLP output. The validation refers to confirm the {{accuracy of}} the trained NN by giving the unseen data, where unseen data are the data for which the NN is not trained.|$|R
40|$|This paper {{presents}} {{a framework for}} the evaluation of the performance of proactive and reactive routing protocols in MANET. In mobile ad-hoc networks, local link connectivity information is more important for route discovery and maintenance. Periodic Hello messaging is a widely-used scheme to provide local link connectivity information. According to the local network load density, ASR can help to improve the network performance by <b>adjusting</b> the <b>link</b> distance in the route. Collaborative reinforcement learning (CRL) is a self- organizing technique for building a MANET routing protocol, called SAMPLE. To improve the performance MANET of Routing Protocols “checkpoint” method is propose. General Terms Mobile ad-hoc networks, route discovery and maintenance, and routing protocols et...|$|R
5000|$|Roller {{chain is}} ordinarily hooked up using a master link (also {{known as a}} {{connecting}} link), which typically has one pin held by a horseshoe clip rather than friction fit, allowing it to be inserted or removed with simple tools. Chain with a removable link or pin {{is also known as}} cottered chain, which allows the length of the chain to be <b>adjusted.</b> Half <b>links</b> (also known as offsets) are available and are used to increase the length of the chain by a single roller. Riveted roller chain has the master link (also known as a connecting link) [...] "riveted" [...] or mashed on the ends. These pins are made to be durable and are not removable.|$|R
50|$|First, a toolchain must be {{compiled}} {{consisting of}} the tools used to compile LFS, like GCC, glibc, binutils and other necessary utilities. Then, the root directory must be changed, (using chroot), to the toolchain's partition to start building the final system. One of the first packages to compile is glibc; after that, the toolchain's linker must be <b>adjusted</b> to <b>link</b> against the newly built glibc, so that all other packages that will make up the finished system can be linked against it as well. During the chroot phase, bash's hashing feature is turned off and the temporary toolchain's bin directory moved {{to the end of}} PATH. This way the newly compiled programs come first in PATH and the new system builds on its own new components.|$|R
40|$|Federal {{estate tax}} returns are {{a rich source}} of {{information}} on the assets and liabilities associated with decedents, as well as data on beneficiaries of estates. When linked with income tax data for the decedents and their beneficiaries, the resulting data base provides a unique opportunity to study a variety of important economic issues relating to the transfer of wealth and the accumulation of capital. However, in creating such a complex, linked data base, it is inevitable that, for a variety of reasons, a number of records would be missing. In this paper, we detail steps taken to weight the <b>linked</b> files. We <b>adjust</b> the <b>linked</b> record weights in two stages. First, an adjustment factor is created to balance to the original population totals, essentially treatin...|$|R
5000|$|An {{example of}} how this could happen {{manifested}} itself in the 2007 Lesotho general election. In this case the two leading parties, the Lesotho Congress for Democracy (LCD) and the All Basotho Convention (ABC) used decoy lists, respectively named the National Independent Party and the Lesotho Workers' Party to avoid the compensatory mechanisms of MMP. As a result, the LCD and its decoy {{were able to take}} 69.1% of the seats with only 51.8% of the vote. ABC leader Tom Thabane called the vote [...] "free, but not fair." [...] In the 2012 election, the voting system was <b>adjusted</b> to <b>link</b> the local and list seats to limit the decoy lists' effectiveness, resulting in an almost perfectly proportionate election result for the competing parties.|$|R
40|$|In 1990, a {{case-control study}} was {{conducted}} in Italy to investigate the possible association between HCV infection and hepatocellular carcinoma (HCC). Serum samples from 65 subjects with newly diagnosed hepatocellular carcinoma and 99 hospital control subjects were tested for the presence of anti-HCV by second-generation ELISA test; positive sera were assayed by RIBA anti-HCV second-generation test. In addition, samples were tested for hepatitis B surface antigen (HBsAg), antibodies to the hepatitis B core antigen (anti-HBc), and antibodies to HBsAg (anti-HBs). The presence of HCV and/or HBsAg serologic markers was significantly associated with hepatocellular carcinoma risk: the relative risk (RR) of HCC was 21. 3 (95 % CI= 8. 8 - 51. 5) for anti-HCV positivity in the absence of HBsAg; the relative risk of HCC was 13. 3 (95 % CI= 5. 5 - 32. 2) for the presence of HBsAg in the absence of anti-HCV. A higher risk (77. 0) was observed when both markers were present. These findings indicate that HCV and HBsAg are independent risk factors for HCC. The results of multivariate analysis showed that the <b>adjusted</b> RR <b>linking</b> anti-HCV and HCC was 26. 9 (95 % CI= 9. 9 - 72. 5), the <b>adjusted</b> RR <b>linking</b> HBsAg and HCC was 11. 4 (95 % CI= 3. 1 - 41. 4), whereas no association (RR 1. 5; 95 % CI= 0. 6 - 3. 6) was found to link HCC with anti-HBc and/or anti-HBs positivity. Through the computation of population attributable risk we estimate that 25 % of HCC cases occurring in Italy could be attributed to anti-HCV positivity alone and 20 % to HBsAg carrier state alone. These data provide evidence that HCV infection {{plays a major role in}} the development of HCC in Italy...|$|R
40|$|Network DEA models assess {{production}} systems that contain {{a set of}} network-structured subsystems. Each subsystem has input and output measures from and to the external network and has intermediate measures that link to other subsystems. Most published studies demonstrate how to employ DEA models to establish network DEA models. Neither static nor dynamic network DEA models <b>adjust</b> the <b>links.</b> This paper applies the virtual gap measurement (VGM) model to construct a mixed integer program to solve dynamic network DEA problems. The mixed integer program sets the total numbers of “as-input” and “as-output” equal to {{the total number of}} links in the objective function. To obtain the best-practice efficiency, each DMU determines a set of weights for inputs, outputs, and links. The links are played either “as-input” or “as-output. ” Input and as-input measures reduce slack, whereas output and as-output measures increase slacks to attain their target on the production frontier...|$|R
40|$|Given a {{sequence}} of n nonnegative integers how can we find the graphs which achieve the minimal deviation from that sequence? This extends the classical problem regarding what sequences are "graphic", that is, can be the degrees of a simple graph, to issues regarding arbitrary sequences. In this context, we investigate properties of the "minimal graphs". We shall demonstrate how {{a variation on the}} Havel-Hakimi algorithm can supply the value of the minimal possible deviation, and how consideration of the Ruch-Gutman condition and the Ferrer diagram can yield the complete set of graphs achieving this minimum. An application of this analysis is to a population of individuals represented by vertices, interactions between pairs by edges and in which each individual has a preferred range for their number of links to other individuals. Individuals <b>adjust</b> their <b>links</b> according to their preferred range and the graph evolves towards some set of graphs which achieve the minimal possible deviation. This Markov chain is defined but detailed analysis is omitted...|$|R
40|$|In a multirate {{wireless}} network, a node can dynamically <b>adjust</b> its <b>link</b> {{transmission rate}} by switching between different modulation schemes. In the current IEEE 802. 11 a/b/g standards, this rate adjustment is defined for unicast traffic only. In this paper, we consider a wireless mesh network (WMN), where a node can dynamically adjust its link-layer multicast rates to its neighbors, {{and address the}} problem of realizing low-latency network-wide broadcast in such a mesh. We first show that the multirate broadcast problem is significantly different from the single-rate case. We will then present an algorithm for achieving low-latency broadcast in a multirate mesh which exploits both the wireless multicast advantage and the multirate nature of the network. Simulations based on current IEEE 802. 11 parameters show that multirate multicast can reduce broadcast latency by 3 - 5 times compared with using the lowest rate alone. In addition, we show the significance of the product of transmission rate and transmission coverage area in designing multirate WMNs for broadcast...|$|R
40|$|This {{dissertation}} {{focuses on}} the topic of relational data clustering, which is the task of organizing objects into logical groups, or clusters, taking into account the relational links between objects. As a research area, relational clustering has received {{a great deal of attention}} recently, because of the large variety of social media applications and other modern relational data sources that have become popular, such as weblogs, protein interac-tion networks, social networks, and citation graphs. The contributions of this dissertation are in three areas: probabilistic clustering algorithms, iterative clustering algorithms, and multi- relational clustering algorithms. The probabilistic clustering algorithms are presented as a general framework and allow for the highest level of expression in developing models for relational clustering. Specifically, I show that one particular part of the clustering model— the relation existence distribution— can be modified in a variety of ways. I give two example instantiations of the framework: one that uses objects’ distance from their cluster mean to <b>adjust</b> <b>link</b> prob-abilities, and another that measures the correlation of paired covariate values to determine link probabilities. I demonstrate the properties of each model on both artificial data and two social networks. The results show the potential of the relational probability function in developing useful clustering models. The iterative algorithm presented in this dissertation, BMOD, trades off model ex-pressiveness for speed and can be applied to much larger data sets, scaling up to several thousand objects. I present empirical results showing that BMOD performs similarly to two related probabilistic models, while also being much faster. The model is applied to a variety of relational data sets including a protein interaction network, a citation graph, and a social network. The results for the BMOD algorithm led to a multi- relational approach: M- BMOD, which generalizes the clustering model for multiple relation types. The M- BMOD algo-rithm is shown to perform poorly when low- quality data is present, so an approach for relation selection, or the process of identifying the most relevant relational information out of a larger set of different relation types, is presented. I show that the approach effectively identifies relations that mutually agree on an optimal clustering while also filtering out any relations that will mislead the algorithm...|$|R
40|$|We {{will present}} a {{real-time}} simulation environment for IP-traffic over cellular links, which is suitable for analyzing the interactive behavior of higher layer transport protocols when used on bandwidth-constrained and error-prone wireless channels. It {{is based on a}} so-called split-simulation approach in order to satisfy the real-time constraint: All time-consuming simulations of the complete transmission and reception procedure at the air interface, which usually have to be done at bit level, are performed offline. The resulting packet loss statistics are then used to parameterize a suitable set of stochastic loss generators, which are of fairly low complexity and can be easily integrated into a network-level simulator. The latter operates in real-time and contains models for the various protocol entities at the data link layer of the cellular system. Furthermore, a central control unit allows to dynamically <b>adjust</b> the <b>link</b> conditions for each user during the simulation run. An additional feature is the possibility to inject live IP-traffic from external sources into the virtual simulation environment. The applicability of our approach will be shown for the example of a GSM-GPRS system...|$|R
40|$|International audienceIn this paper, {{we propose}} a novel cross-layer {{framework}} for jointly controlling and coding for multiple video streams in wireless multihop networks. At first, we develop a cross-layer flow control algorithm which {{works at the}} medium access control (MAC) layer to <b>adjust</b> each <b>link's</b> persistence probability and at the transport layer to adjust flow rates. This proposal is designed in distributed manner that is amenable to on-line implementation for wireless networks. And then, a rate-distortion optimized joint source-channel coding (JSCC) approach for error-resilient scalable encoded video is presented, in which the video is encoded into multiple independent streams and each stream is assigned forward error correction (FEC) codes to avoid error propagation. Furthermore, we integrate the JSCC with the specific flow control algorithm, which optimally applies the appropriate channel coding rate given the constraints imposed by the transmission rate obtained from the proposed flow control algorithm and the prevailing channel condition. Simulation results demonstrate the merits {{and the need for}} joint QoS control in order to provide an efficient solution for video streaming over wireless multihop networks...|$|R
