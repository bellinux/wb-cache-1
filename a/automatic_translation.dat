670|353|Public
25|$|By 2009, the {{majority}} of spam sent around the World was in the English language; spammers began using <b>automatic</b> <b>translation</b> services to send spam in other languages.|$|E
25|$|The first {{formally}} verified microkernel, seL4, used Haskell as a prototyping {{language for}} the OS developer. At the same time, the Haskell code defined an executable specification {{with which to}} reason, for <b>automatic</b> <b>translation</b> by the theorem-proving tool. The Haskell code thus served as an intermediate prototype before final C refinement.|$|E
5000|$|... {{based on}} <b>automatic</b> <b>translation</b> from :eo:Tibor Sekelj with vikitradukilo / Apertium ...|$|E
5000|$|Version 4.0 {{released}} June 16, 2011 introduced unicode support, a rewritten e-commerce module, Google Maps and YouTube objects, polls, <b>automatic</b> <b>translations...</b>|$|R
5000|$|... (Substantial {{parts of}} this article were taken from {{selected}} sentences from <b>automatic</b> <b>translations</b> from the Romanian Wiki, and from the Avram reference.) ...|$|R
40|$|We {{consider}} {{the problem of}} identifying <b>automatic</b> <b>translations</b> from manual translations of the same sentence. Using two different similarity metrics (BLEU and Levenshtein edit distance), {{we found out that}} <b>automatic</b> <b>translations</b> are closer to each other than they are to manual translations. We also use phylogenetic trees to provide a visual representation of the distances between pairs of individual sentences in a set of translations. The differences in lexical distance are statistically significant, both for Chinese to English and for Arabic to English translations. 1...|$|R
5000|$|Chat - an IM module which {{integrates}} <b>automatic</b> <b>translation</b> of exchanged messages ...|$|E
5000|$|<b>Automatic</b> <b>translation</b> from Dutch to English often {{translates}} [...] "dubbeltje" [...] as [...] "dime".|$|E
5000|$|AMORES CARREDANO, Jose Javier. <b>Automatic</b> <b>translation</b> systemsline. Available in: http://quark.prbb.org/19/019046.htm of view: 29 May 2011 ...|$|E
40|$|This {{bachelor}} {{thesis is}} focused on a Evaluation of SMT translation systems (Google Translate, Bing) from French to Czech: collocations related to "Waste management". At first, the work describes {{a brief history of}} machine translation. Then the work describes the basic principles of machine translation like the rule-based machine transla-tion, the statistical machine translation, the hybrid machine translation and the by com-puter aided translation. The online translators GT and MB are introduced as well. These translators are completed by specific studies of correctness their evaluations. The <b>automatic</b> <b>translations</b> of these tranlators are evaluated on the based of outlined typology of resulting mistakes. These <b>automatic</b> <b>translations</b> are the most important ob-ject of this bachelor thesis...|$|R
40|$|We {{investigate}} {{the effect of}} four different competitive machine translation systems on post-editor productivity and behaviour. The study involves four volunteers post-editing <b>automatic</b> <b>translations</b> of news sto-ries from English to German. We see sig-nificant difference in productivity due to the systems (about 20 %), and even bigger variance between post-editors. ...|$|R
40|$|Given the {{significant}} improvements in Machine Translation (MT) quality and the increasing demand for <b>translations,</b> post-editing of <b>automatic</b> <b>translations</b> is becoming a popular practice in the translation industry. It {{has been shown to}} allow for larger volumes of translations to be produced, saving time and costs. In addition, the post-editing of <b>automatic</b> <b>translations</b> can help understand problems in such translations and this can be used as feedback for researchers and developers to improve MT systems. Finally, post-editing {{can be used as a}} way of evaluating the quality of translations in terms of how much effort these translations require in order to be fixed. We describe a standalone tool that has two main purposes: facilitate the post-editing of translations from any MT system so that they reach publishable quality and collect sentence-level information from the post-editing process, e. g. : post-editing time and detailed keystroke statistics...|$|R
5000|$|Source {{to source}} compilation: <b>automatic</b> <b>translation</b> of a {{computer}} program from one programming language to another ...|$|E
50|$|US President Barack Obama drew {{criticism}} after a 2009 White House {{white paper}} proposed incentives for <b>automatic</b> <b>translation.</b>|$|E
5000|$|To produce sample {{application}} for <b>automatic</b> <b>translation</b> {{of news and}} web pages and make that application freely accessible.|$|E
50|$|Because machine {{translation}} {{is based on}} statistical algorithms rather than human translators, the <b>automatic</b> <b>translations</b> it produces are not always entirely accurate. Microsoft Translator has introduced various feedback features, such as the Collaborative Translations Framework, into its products to allow users to suggest alternative translations. These alternative translations are then integrated into the Microsoft Translator algorithms to improve future translations.|$|R
40|$|International audienceIn this paper, {{we present}} a freely {{available}} corpus of <b>automatic</b> <b>translations</b> accompanied with post-edited versions, annotated with labelsidentifying {{the different kinds of}} errors made by the MT system. These data have been extracted from translation students exercises thathave been corrected by a senior professor. This corpus can be useful for training quality estimation tools and for analyzing the types oferrors made MT system...|$|R
5000|$|... 64:ff9b::/96 â€” The [...] "Well-Known" [...] Prefix. Addresses {{with this}} prefix {{are used for}} <b>automatic</b> IPv4/IPv6 <b>translation.</b>|$|R
5000|$|The History section comes {{substantially}} from selected {{sentences in}} the Czech Wikipedia article, and used an <b>automatic</b> <b>translation</b> tool.|$|E
5000|$|The Microsoft Translator API is a {{cloud-based}} <b>automatic</b> <b>translation</b> service {{that can be}} used to build applications, websites, and tools requiring multi-language support.|$|E
50|$|In 2003, {{the company}} {{invested}} in expanding the ZyIMAGE product suite with advanced text analytics, text mining, data visualization, computational linguistics, and <b>automatic</b> <b>translation.</b>|$|E
5000|$|<b>Automatic</b> DOCTYPE <b>translations</b> -from {{template}} DTD {{to result}} DTD- for (optional) validation of both template and result code.|$|R
40|$|AbstractThis paper {{addresses}} the <b>automatic</b> <b>translations</b> of verbal answers to yes-no questions from partial pro-drop languages (Brazilian Portuguese and Russian) into a non-pro-drop language (English). The outputs provided by standard statistical machine translations are mostly grammatically inaccurate or semantic-pragmatically inadequate. This paper proposes a question under discussion based annotation {{to improve the}} statistical correspondence. The results show {{the accuracy of the}} outputs was significantly increased as regards fidelity, adequacy and grammaticality...|$|R
40|$|Complex {{networks}} have been increasingly used in text analysis, including {{in connection with}} natural language processing tools, as important text features appear to be captured by the topology and dynamics of the networks. Following previous works that apply complex networks concepts to text quality measurement, summary evaluation, and author characterization, we now focus on machine translation (MT). In this paper we assess the possible representation of texts as complex networks to evaluate cross-linguistic issues inherent in manual and machine translation. We show that different quality translations generated by NIT tools can be distinguished from their manual counterparts by means of metrics such as in-(ID) and out-degrees (OD), clustering coefficient (CC), and shortest paths (SP). For instance, we demonstrate that the average OD in networks of <b>automatic</b> <b>translations</b> consistently exceeds the values obtained for manual ones, and that the CC values of source texts are not preserved for manual translations, but are for good <b>automatic</b> <b>translations.</b> This probably reflects the text rearrangements humans perform during manual translation. We envisage that such findings could lead to better NIT tools and automatic evaluation metrics...|$|R
50|$|By 2009, the {{majority}} of spam sent around the World was in the English language; spammers began using <b>automatic</b> <b>translation</b> services to send spam in other languages.|$|E
50|$|The {{paper has}} a digital version {{available}} in Spanish and Galician, however the Galician version is an <b>automatic</b> <b>translation,</b> the original articles are written exclusively in Spanish.|$|E
5000|$|MILU : Online {{game with}} a {{character}} progression based on mutual aid. It also uses an <b>automatic</b> <b>translation</b> system that enables South Korean and Japanese users to play together.|$|E
40|$|<b>Automatic</b> <b>translations</b> of WordNet {{have been}} tried to many {{different}} target lan-guages. JAWS is such a translation for French nouns using bilingual dictionaries and a syntactic language model. We im-prove its precision and coverage, complete it with translations of other parts of speech and enhance its evaluation method. The result is named WoNeF. We produce three final translations balanced between pre-cision (up to 93 %) and coverage (up to 109 447 (literal, synset) pairs). ...|$|R
40|$|In this paper, {{we present}} a freely {{available}} corpus of <b>automatic</b> <b>translations</b> accompanied with post-edited versions, annotated with labels identifying {{the different kinds of}} errors made by the MT system. These data have been extracted from translation students exercises that have been corrected by a senior professor. This corpus can be useful for training quality estimation tools and for analyzing the types of errors made MT system. Keywords:Translation Error Corpus, Post-Edition, Error Analysis 1...|$|R
40|$|It is {{anticipated}} that the UML, perhaps with domain-specific extensions, will increasingly be used to model and analyse agent-based systems. Current commercial tools for UML, however, contain a number of gaps that limit this growth potential. As an example, {{there is little or}} no support for <b>automatic</b> <b>translations</b> between UML notations. We present one such translation [...] - from sequence diagrams to statecharts [...] - and discuss how such an algorithm could be used in agent modeling...|$|R
5000|$|Several machine {{translation}} (MT) systems for <b>automatic</b> <b>translation</b> {{in the government}} domain; developed language pairs include: English (EN-GB) into Afrikaans (AF-ZA), IsiZulu (ZU-ZA), Sepedi (NSO-ZA), Xitsonga (TS-ZA) and Setswana (TN-ZA).|$|E
50|$|In 2009 {{simplifies}} the subtitles system. The programme upload reports to YouTube {{to be available}} the <b>automatic</b> <b>translation</b> to many languages. The quality improve and a HD 720 version is available too.|$|E
5000|$|Other named folders include {{ones for}} {{automatic}} consultation within the program: /tm/ for existing translation pairs in [...]tmx format, /tm/auto/ for <b>automatic</b> <b>translation</b> of 100% matches, /glossary/ for glossaries, /dictionary/ for StarDict (and [...]tbx) dictionaries.|$|E
50|$|J. VaissiÃ¨re studied {{computing}} and <b>automatic</b> language <b>translation</b> {{under the}} supervision of Bernard Vauquois, at Centre dâ€™Etudes et de Traduction Automatique, University of Grenoble.|$|R
50|$|One of {{the main}} {{features}} of QQ International is the optional and <b>automatic</b> machine <b>translation</b> of all chats. Its last update was in 2014.|$|R
40|$|In this paper, {{we present}} our Named Entity Recognition (NER) system for German â€“ NERU (Named Entity Rules), which heavily relies on {{handcrafted}} rules {{as well as}} information gained from a cascade of existing external NER tools. The system combines large gazetteer lists, information obtained by comparison of different <b>automatic</b> <b>translations</b> and POS taggers. With NERU, we were able to achieve a score of 73. 26 % on the development set provided by the GermEval 2014 Named Entity Recognition Shared Task for German...|$|R
