45|34|Public
50|$|<b>A</b> <b>concordancer</b> is a {{computer}} program that automatically constructs a concordance. The output of <b>a</b> <b>concordancer</b> may serve as input to a translation memory system for computer-assisted translation, or as an early step in machine translation.|$|E
5000|$|Bitext aligners: {{tools that}} align a source text and its {{translation}} which {{can then be}} analyzed using a full-text search tool or <b>a</b> <b>concordancer</b> ...|$|E
50|$|It was Tim Johns (1991), however, {{who raised}} {{the profile of}} the use of {{concordancers}} in the language classroom with his concept of Data-driven learning (DDL). DDL encourages learners to work out their own rules about the meaning of words and their usage by using <b>a</b> <b>concordancer</b> to locate examples in a corpus of authentic texts. It is also possible for the teacher to use <b>a</b> <b>concordancer</b> to find examples of authentic usage to demonstrate a point of grammar or typical collocations, and to generate exercises based on the examples found. Various types of concordancers and where they can be obtained are described by Lamy & Klarskov Mortensen (2011).|$|E
40|$|Diachronic Corpus of Early Written Latvian Texts (16 - 18 th c.). > 1 mill. running words (work is on-going). The {{main data}} are ecclesiastical texts, secular texts (laws, fiction) and some first bilingual (Latvian-German) dictionaries. <b>A</b> KWIC-based <b>concordancer,</b> {{as well as}} inverse vocabulary, {{frequency}} lists and word lists are provided. Some source facsimiles are available...|$|R
40|$|AntConc is a freeware, multi-platform, {{multi-purpose}} corpus analysis toolkit, {{designed specifically}} {{for use in the}} classroom. It hosts a comprehensive set of tools including <b>a</b> powerful <b>concordancer,</b> word and keyword frequency generators, tools for cluster and lexical bundle analysis, and a word distribution plot. In this paper, I will describe each of these tools, and explain their value to learners. Then, I will discuss the current limitations of the software, before explaining how I hope it will be improved in future releases...|$|R
40|$|This paper {{presents}} {{a tool for}} extracting multi-word expressions from corpora in Modern Greek, which is used together with <b>a</b> parallel <b>concordancer</b> to augment the lexicon of a rule-based machinetranslation system. The tool {{is part of a}} larger extraction system that relies, in turn, on a multilingual parser developed over the past decade in our laboratory. The paper reviews the various NLP modules and resources which enable the retrieval of Greek multi-word expressions and their translations: the Greek parser, its lexical database, the extraction and concordancing system. ...|$|R
50|$|Robb (2003) {{shows how}} it is {{possible}} to use Google as <b>a</b> <b>concordancer,</b> but he also points out a number of drawbacks, for instance there is no control over the educational level, nationality, or other characteristics of the creators of the texts that are found, and the presentation of the examples is not as easy to read as the output of a dedicated concordancer that places the key words (i.e. the search terms) in context.|$|E
40|$|The idea of {{language}} learners using <b>a</b> <b>concordancer,</b> to autonomously investigate vocabulary and structure in a target language was suggested over 30 years ago. Since then, some research has explored this idea further, {{but the potential}} benefit of concordancers {{in the hands of}} learners is still largely unexplored – especially with regards to structure. This study investigates what learners are able to accomplish when asked to investigate an English corpus with <b>a</b> <b>concordancer</b> in order to correct grammar errors in an essay. The study was conducted after only 30 minutes of training on <b>a</b> <b>concordancer.</b> Participants reactions to the software and to analyzing the target language autonomously are also shared. While participants’ reactions were mixed with regards to using a concordacer for error correction, all participants expressed an interest in using <b>a</b> <b>concordancer</b> during their writing process – something which was {{beyond the scope of this}} study – but which suggests a potential value for learner exposure to concordancers for autonomous language investigation...|$|E
40|$|This {{pilot study}} {{set out to}} {{determine}} whether a parallel corpus and <b>a</b> <b>concordancer</b> would be appropriate tools to supplement a teaching programme of German at the beginners' level in an unsupervised environment. In this instance, a beginner student of German was asked to find satisfactory answers to unknown vocabulary and formulate appropriate grammar rules for himself using the parallel corpus and concordancer as the only tools. It is shown that these tools can be of great benefit for beginners. AIMS AND OBJECTIVES I describe a pilot study involving a beginner student of German who undertook a supplementary unsupervised programme of learning German using <b>a</b> <b>concordancer</b> and a parallel corpus. I investigate how a beginner student of German fares using <b>a</b> <b>concordancer,</b> Multiconcord (see King & Wools, 1996; St. John & Chattle, 1998), and a parallel German/English corpus, INTERSECT (Salkie, 1995) consisting of the original German source texts and their English translations. The aim {{of this study was to}} determine how this student copes using the parallel corpus and what conclusions he comes to when comparing the two languages, and in particular, when investigating lexical items. As students at the beginner an...|$|E
40|$|This paper {{introduces}} {{a method for}} computational analysis of move structures in abstracts of research articles. In our approach, sentences in a given abstract are analyzed and labeled with a specific move in light of various rhetorical functions. The method involves automatically gathering {{a large number of}} abstracts from the Web and building a language model of abstract moves. We also present <b>a</b> prototype <b>concordancer,</b> CARE, which exploits the move-tagged abstracts for digital learning. This system provides a promising approach to Web-based computer-assisted academic writing...|$|R
40|$|In this paper, we {{describe}} TANGO as <b>a</b> collocational <b>concordancer</b> for looking up collocations. The system {{was designed to}} answer user’s query of bilingual collocational usage for nouns, verbs and adjectives. We first obtained collocations from the large monolingual British National Corpus (BNC). Subsequently, we identified collocation instances and translation counterparts in the bilingual corpus such as Sinorama Parallel Corpus (SPC) by exploiting the word-alignment technique. The main goal of the concordancer is to provide the user with a reference tools for correct collocation use so as to assist second language learners to acquire the most eminent characteristic of native-like writing. ...|$|R
40|$|This paper makes a {{case for}} the {{inclusion}} of modules on revising specialised English texts in advanced language courses at university. In particular, it recounts an experiment with students from the International Relations stream of a second level degree in Foreign Languages in Italy. The students were given non-edited and edited versions of the same text, and encouraged to reflect on the reasons why the revisions were made, using printed dictionaries, reference corpora and printouts from <b>a</b> parallel <b>concordancer.</b> They were also given extracts from works on clear writing such as Cutts (2007), Williams (2007) and the European Commission’s booklet How to Write Clearly. The results were positive in that students found the exercises motivating, and remembered the principles of clear writing months after the experiment had concluded...|$|R
40|$|CLaRK is an XML-based {{software}} system for corpora development. It incorporates several technologies: XML technology; Un i code; Regular Cascaded Grammars; Constraints over XML Documents. The basic {{components of the}} system are: a tagger, <b>a</b> <b>concordancer,</b> an extractor, a grammar processor, a constraint engine. ...|$|E
40|$|Close {{reading is}} {{considered}} {{important in the}} criticism of English literature; however, in analyzing novels researchers should make a precise memo to record how and where certain words {{are used in the}} work. If we could use both corpus made up from electronic texts on the internet and <b>a</b> <b>concordancer,</b> it would make the above efforts much easier. In this essay Thomas Hardy's Tess of the d'Urbervilles was examined by using three tools of WordSmith, a concordance software, in comparison with George Eliot's Middlemarch and Sommerset Maugham's Of Human Bondage. WordSmith is a set of programs, which has three main tools called Wordlist, Keywords, and Concord. Wordlist as a tool makes {{a list of all the}} words in a text, set out in frequency order. With Keywords, the key words can be observed by comparing its wordlist with that of other reference text(s). Concord, <b>a</b> <b>concordancer,</b> can be used to plot any keyword or phrase in context to check what sort of wording it accompanies. With these tools we could get a lot of linguistic information about the text, which leads us deeper understanding of the novel. Especially, Concord gives useful information on wording about keywords of a novel. How to select keywords is up to each researcher; however, concordance lines can help us to gain a clear view about a theme. In this way <b>a</b> <b>concordancer</b> is a useful tool for literary criticism...|$|E
40|$|Current version: 1. 7 (released 22 March 2016) EEBOCorp Concordancer is <b>a</b> <b>concordancer</b> {{to query}} EEBOCorp 1. 0, a 525 million word corpus {{covering}} the period 1474 - 1700. EEBOCorp 1. 0 is a selective offline conversion of EEBO (eebo. chadwyck. com). This installation will only install the concordancer software. The corpus is {{available as a}} download on [URL] publishe...|$|E
40|$|The paper {{presents}} the SVEZ-IJS corpus, a large parallel annotated English-Slovene corpus containing translated legal {{texts of the}} European Union, the ACQUIS Communautaire. The corpus contains approx. 2 x 5 million words and was compiled from the translation memory obtained from the Translation Unit of the Slovene Government Office for European Affairs. The corpus is encoded in XML, according to the Text Encoding Initiative Guidelines TEI P 4, where each translation memory unit contains useful metadata and the two aligned segments (sentences). Both the Slovene and English text is linguistically annotated at the word-level, by context disambiguated lemmas and morphosyntactic descriptions, which follow the MULTEXT guidelines. The complete corpus is freely available for research, either via <b>an</b> on-line <b>concordancer,</b> or for downloading from the corpus home page a...|$|R
40|$|With {{more and}} more text being {{available}} in electronic form, it is becoming relatively easy to obtain digital texts together with their translations. The paper presents the processing steps necessary to compile such texts into parallel corpora, an extremely useful language resource. Parallel corpora {{can be used as}} a translation aid for second-language learners, for translators and lexicographers, or as a datasource for various language technology tools. We present our work in this direction, which is characterised by the use of open standards for text annotation, the use of publicly available third-party tools and wide availability of the produced resources. Explained is the corpus annotation chain involving normalisation, tokenisation, segmentation, alignment, word-class syntactic tagging, and lemmatisation. Two exploitation results over our annotated corpora are also presented, namely <b>a</b> Web <b>concordancer</b> and the extraction of bi-lingual lexica...|$|R
40|$|This paper {{presents}} <b>an</b> {{introduction to}} <b>concordancers,</b> {{and to the}} concordanc-ing of Chinese e-texts in particular. Demonstrations are given of searches us-ing spaced and non-spaced source e-texts, with the concordance results pre-sented in Keyword-in-Context (KWIC) display format. There are illustrations to accompany discussions of full-text concordances, and of concordances tar-geting specific words or phrases. The writer suggests how concordancers might be used in language-teaching and in conducting research on various lin-guistic phenomena of the Chinese language. An appendix compares several concordancing programs capable of handling Chinese e-texts...|$|R
40|$|Ontology {{design is}} a {{difficult}} task {{for which there is}} no agreed upon methodology. Texts of the domain can provide the words and terms of the domain, and support the abstraction of concepts and relationships which constitute the skeleton of the ontology. An environment to help the ontology designer has been built. Its main components are a term extractor, <b>a</b> <b>concordancer</b> and an ontology editor specially designed for multilingual treatment...|$|E
40|$|The study {{investigates the}} {{relative}} effectiveness of inductive and deductive approaches to learning collocations by using <b>a</b> <b>concordancer.</b> The relationship between cognitive approaches {{and levels of}} collocation difficulty is also examined. 81 second-year students from a senior high school in Taiwan participated in the study. The {{results showed that the}} inductive group improved significantly better than the deductive group in the performance of collocation learning and easy collocations seem to be more suitable in the concordancer learning setting. 1...|$|E
40|$|The {{study was}} {{designed}} to examine the effect of concordancing and scaffolding in developing learners’ knowledge of lexical collocations. Four tests were administered on two groups of Vietnamese learners of English to assess their ability in three aspects: (1) to identify (mis) collocations, (2) to provide answers with suggested options, and (3) to provide their own correction. Regarding the students’ ability to identify (mis) collocations and to provide answers with suggested options, the study revealed that concordancing significantly improved their score while scaffolding had no considerable impact. Concerning the students’ ability to provide their own correction, both concordancing and scaffolding were found to {{have a significant effect on}} the students’ performance. The study therefore discusses the importance of introducing <b>a</b> <b>concordancer</b> to promote learners’ independence in learning collocations. Scaffolding is also argued to be equally important especially when <b>a</b> <b>concordancer</b> is first introduced to students. Concordancing should be considered as a long-term task for learners in their development of collocation knowledge while scaffolding is temporary in its nature. Both concordancing and scaffolding can therefore be regarded as co-supporters in helping learners eventually take charge of learning collocations by themselves. ...|$|E
40|$|Very {{few studies}} have {{investigated}} the use of data-driven learning (DDL) in the beginner-level EFL classroom, and few or no studies have compared the use of paper-based, computer-based and combined approaches. This paper reports {{on the results of}} a three-year comparative case study of computer-based, paperbased, and combined computer- and paper-based DDL using a parallel corpus for beginner-level university students. Students followed guided tasks on a worksheet to inductively understand target grammar patterns, had an explicit confirmation or correction of their hypotheses, and did follow up practice. The DDL exercises were done on <b>a</b> bilingual <b>concordancer</b> using newspaper corpus. It was demonstrated that each DDL approach can be effective for improving grammar basics such as understanding and producing noun phrases. Pre- and post-tests showed students made significant gains using all three approaches, and there {{does not appear to be}} any significant difference in effectiveness among the three approaches. Literature Revie...|$|R
40|$|Journal articleIllustrates that ParaConc, <b>a</b> {{parallel}} <b>concordancer</b> {{designed by}} Barlow (1995) has proved {{useful in the}} analysis of parallel texts, i. e. source texts (ST) and their target texts (TT), which are English original texts and their Xhosa translated versions respectively in this context. Uses the ?hot word? function in ParaConc to verify the use of simplification strategies by translators during the translation process. Reports that both stylistic and lexical simplification strategies are noticeable in the English- Xhosa parallel texts under study, but that the focal point here is lexical simplification. Indicates that lexical simplification strategies investigated are: using a superordinate or more general word, using a general word with extended meaning and using more familiar or common synonyms. Gives the reader an idea about how some general words are used to translate technical language. Displays that ?hot words? in ParaConc in most instances do indeed include translations of the search word, if the texts are aligned properly...|$|R
40|$|In this paper, we {{introduce}} the FastKwic (Key Word In Context using FASTR), <b>a</b> new <b>concordancer</b> for French and English {{that does not}} require users to learn any particular request language. Built on FASTR, it shows them not only occurrences of the searched term but also of several morphological, morpho-syntactic and syntactic variants (for example, image enhancement, enhancement of image, enhancement of fingerprint image, image texture enhancement). Fastkwic is freely available. It consists of two UTF- 8 compliant Perl modules that depend on several external tools and resources: FASTR, TreeTagger, Flemm (for French). Licenses of theses tools and resources permitting, the FastKwic package is nevertheless self-sufficient. FastKwic first modules is for terminological resource compilation. Its input {{is a list of}} terms- as required by FASTR. FastKwic second module is for processing concordances. It relies on FASTR again for indexing the input corpus with terms and their variants. Its output is a concordancer: for each term and its variants, the context of occurrence is provided. 1...|$|R
40|$|This {{research}} {{identifies the}} high frequencies of quantifiers in argumentative writing, {{which is a}} popular mode in English proficiency tests, bykeyword analyses and reveals their roles as rhetorical devices in argumentation by focusing on particular collocation in actual contexts. The results of small-scale discourse analyses show that different quantifiers carry different hidden messages under the surface, balancing degree of agreement or commitment. This study advocates a classroom activity of quantifiers by <b>a</b> <b>concordancer,</b> suggesting the importance of contextualization, and argues for different-level persuasive texts from TOEFL model essays and American LOCNESS, not only for test preparationbut also for familiarity with argumentation through reading...|$|E
40|$|This paper 1 {{reports on}} a {{multi-media}} web-based CALL program designed to teach Arabic to foreign learners. It discusses several important theoretical and practical issues related to language pedagogy, such as the variety of Arabic to teach, the problem of the, types of text, and the representation of Arabic. It also discusses the issue of incorporating <b>a</b> <b>concordancer</b> and corpus into a teaching environment. An important and unique feature {{of the program is}} that it is designed and implemented by linguists with many years of experience in teaching linguistics and Arabic as a foreign language, and takes into account the latest methodological and pedagogical advances in the field rather than merely transferring existing materials into the electronic format. 1...|$|E
40|$|TerminoWeb is {{a web-based}} {{platform}} designed {{to find and}} explore specialized domain knowledge on the Web. An important aspect of this exploration is the discovery of domain-specific collocations on the Web and their presentation in <b>a</b> <b>concordancer</b> to provide contextual information. Such information is valuable to a translator or a language learner presented with a source text containing a specific terminology to be understood. The {{purpose of this article}} is to show a proof of concept that TerminoWeb, as an integrated platform, allows the user to extract terms from the source text and then automatically build a related specialized corpus from the Web in which collocations will be discovered to help the user understand the unknown specialized terms...|$|E
40|$|This paper {{describes}} {{a database of}} translation memory, TotalRecall, developed to encourage authentic and idiomatic use in second language writing. TotalRecall is <b>a</b> bilingual <b>concordancer</b> that support search query in English or Chinese for relevant sentences and translations. Although initially intended for learners of English as Foreign Language (EFL) in Taiwan, it is a gold mine of texts in English or Mandarin Chinese. TotalRecall is particularly useful for those who write in or translate into a foreign language. We exploited and structured existing high-quality translations from bilingual corpora from a Taiwan-based Sinorama Magazine and Official Records of Hong Kong Legislative Council to build a bilingual concordance. Novel approaches were taken to provide high-precision bilingual alignment on the subsentential and lexical levels. A browser-based user interface was developed for ease of access over the Internet. Users can search for word, phrase or expression in English or Mandarin. The Web-based user interface facilitates the recording of the user actions to provide data for further research. ...|$|R
40|$|The aim of {{this article}} is to {{illustrate}} that ParaConc, <b>a</b> parallel <b>concordancer</b> designed by Barlow (1995) has proved useful in the analysis of parallel texts, i. e. source texts (ST) and their target texts (TT), which are English original texts and their Xhosa translated versions respectively in this context. The ‘hot word’ function in ParaConc has been used to verify the use of simplification strategies by translators during the translation process. Both stylistic and lexical simplification strategies are noticeable in the English-Xhosa parallel texts under study, but the focal point here is lexical simplification. Lexical simplification strategies investigated are: using a superordinate or more general word, using a general word with extended meaning and using more familiar or common synonyms. The analysis gives the reader an idea about how some general words are used to translate technical language. It also displays that ‘hot words’ in ParaConc in most instances do indeed include translations of the search word, if the texts are aligned properly...|$|R
40|$|Abstract. Despite the {{exciting}} work accomplished {{over the past}} decade in the field of Statistical Machine Translation (SMT), we are still far from the point of being able to say that machine translation fully meets the needs of real-life users. In a previous study [6], we have shown how a SMT engine could benefit from terminological resources, especially when translating texts very different from those used to train the system. In the present paper, we discuss the opening of SMT to examples automatically extracted from a Translation Memory (TM). We report results on a fair-sized translation task using the database of <b>a</b> commercial bilingual <b>concordancer.</b> ...|$|R
40|$|The paper {{presents}} a gold-standard reference corpus of historical Slovene containing 1, 000 sampled pages from over 80 texts, which were, {{for the most}} part, written between 1750 – 1900. Each page of the transcription has an associated facsimile and {{the words in the}} texts have been manually annotated with their modern-day equivalent, lemma and part-of-speech. The paper presents the structure of the text collection, the sampling procedure, annotation process and encoding of the corpus. The corpus is meant to facilitate HLT research and enable corpus based diachronic studies for historical Slovene. The corpus is encoded according to the Text Encoding Initiative Guidelines (TEI P 5), is available via <b>a</b> <b>concordancer</b> and for download fro...|$|E
40|$|International audienceThis {{presentation}} {{describes a}} trilingual corpus of three endangered languages of the Kiranti group (Tibeto-Burman family) from Eastern Nepal. The languages, which are exclusively oral, share a rich mythology, {{and it is}} thus possible to build a corpus of the same native narrative material in the three languages. The segments of similar semantic content are tagged with a "similarity" label to identify correspondences among the three language versions of the story. An interface has been developed to allow these similarities to be viewed together, {{in order to allow}} make possible comparison of the different lexical and morphosyntactic features of each language. <b>A</b> <b>concordancer</b> makes it possible to see the various occurrences of words or glosses, and to further compare and contrast the languages...|$|E
40|$|This study {{analyses}} {{the blogs}} of thirty new {{students as they}} leave home and begin their university lives. Inspired {{by the work of}} social psychologist James Pennebaker, who uses his software LIWC (LinguisticInquiryandWordCount) to track changes in word use and map them onto psychological correlates, this thesis seeks partly to understand the social and psychological impact of the student transition, and partly to investigate the methodological implications of a word-count program such as LIWC. A closed-class keywords analysis is used to bolster and complement the LIWC findings, and the results are examined qualitatively with <b>a</b> <b>concordancer.</b> It is found that the students display a number of linguistic changes following the move to university, and even some beforehand; overall, they appear to become more self-aware, more socially involved and more tentative in their writing...|$|E
40|$|Notwithstanding machine translation’s {{impressive}} progress {{over the}} last decade, many translators remain convinced that the output of even the best MT systems {{is not sufficient to}} facilitate the production of publication-quality texts. To increase their productivity they turn instead to translator support tools. We examine the use of one such tool: TransSearch, <b>an</b> online bilingual <b>concordancer.</b> From the millions of requests stored in the system’s logs over a 6 -year period, we extracted and analyzed the most frequently submitted queries, in an effort to characterize the kinds of problems for which translators turn to this system for help. What we discover, somewhat surprisingly, is that our system seems particularly well-suited to help translate highly polysemous adverbials and prepositional phrases. ...|$|R
40|$|Parallel {{concordance}} software provides a gen ral purpose tool that permits {{a wide range}} of investigations of translated texts, from the analysis of bilingual terminology and phraseology to the study of alternative translations of a single text. This paper outlines the main features of <b>a</b> Windows <b>concordancer,</b> ParaConc, focussing on alignment of parallel (translated) texts, general search procedures, identification of translation equivalents, and the furnishing of basic frequency information. ParaConc accepts up to four parallel texts, which might be four different languages or an original text plus three different translations. A semi-automatic alignment utility is included in the program to prepare texts that are not already pre-aligned. Simple text searches for words or phrases can be performed and the resulting concordance lines can be sorted according to the alphabetical order of the words surrounding the searchword. More complex searches are also possible, including context searches, searches based on regular expressions, and word/part-of-speech searches (assuming that the corpus is tagged for POS). Corpus frequency and collocate frequency information can be obtained. The program includes features for highlighting potential translations, including an automatic component “Hot words, ” which uses frequency information to provide information about possible translations of the searchword...|$|R
40|$|Considerable {{research}} {{has now been}} undertaken into the development of different approaches to exploiting language corpora for pedagogic purposes {{in the context of}} ESP. The question of how language corpora might be utilized by students beyond the immediate language-teaching context is, however, one as yet seldom addressed in the literature. This study attempts to explore the relationship between student use of online corpus tools and academic and professional discourse practices {{in the context of a}} professional legal training course at The City University of Hong Kong. Students enrolled in this course were given instruction in how to consult <b>an</b> online <b>concordancer</b> as language support when completing their legal writing assignments. Drawing on narratives of student experience, and other informant data including detailed logs of searches and the outcomes of assessments of English language proficiency, the paper discusses the ways in which students make strategic use of the corpus tools provided to develop competence in writing for legal purposes. The paper concludes by appraising the potential of corpus-based methods as an affordance for studying the practice of Law, in particular as a means of enhancing the acquisition of professional expertise by novice lawyers. 16 page(s...|$|R
