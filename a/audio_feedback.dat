498|141|Public
5|$|For live shows, The White Stripes {{were known}} for Jack's {{employment}} of heavy distortion, {{as well as}} <b>audio</b> <b>feedback</b> and overdrive. The duo performed considerably more recklessly and unstructured live, never preparing set lists for their shows, believing that planning too closely would ruin the spontaneity of their performances.|$|E
5|$|Hyundai {{developed}} a warning noise for called the Virtual Engine Sound System (VESS). The system, which {{was introduced in}} September 2010 on its test fleet of BlueOn electric hatchbacks, provides synthetic <b>audio</b> <b>feedback</b> mimicking {{the sound of an}} idling internal combustion engine.|$|E
5|$|Robert Ashley used <b>audio</b> <b>feedback</b> in his avant-garde piece The Wolfman (1964) {{by setting}} up a howl between the {{microphone}} and loudspeaker and then singing into the microphone in way that modulated the feedback with his voice.|$|E
5000|$|Masami Akita - <b>feedback</b> <b>audio</b> mixer, metals, electronics, {{electric}} shaver ...|$|R
50|$|Technical {{advances}} can {{be expected}} to increase the scope of these devices considerably, for example by use of sensors and <b>audio</b> or tactile <b>feedback.</b>|$|R
40|$|This paper investigates {{and compares}} the {{effectiveness}} of haptic and audio modality for navigation in low visibility environment using a sensory augmentation device. A second generation head-mounted vibrotactile interface as a sensory augmentation prototype was developed to help users to navigate in such environments. In our experiment, a subject navigates along a wall relying on the haptic or <b>audio</b> <b>feedbacks</b> as navigation commands. Haptic/audio feedback is presented to the subjects according to the information measured from the walls {{to a set of}} 12 ultrasound sensors placed around a helmet and a classification algorithm by using multilayer perceptron neural network. Results showed the haptic modality leads to significantly lower route deviation in navigation compared to auditory feedback. Furthermore, the NASA TLX questionnaire showed that subjects reported lower cognitive workload with haptic modality although both modalities were able to navigate the users along the wall...|$|R
5|$|In his youth, Dugan {{was fascinated}} by the {{technical}} aspects of theatre. He worked as a lighting designer then transitioned to sound design in 1967. Dugan became interested in achieving the automatic adjustment of sound controls after a frustrating experience staging the musical Hair. His first automixer design was not fully practical but his second design was successful; it used a reference derived from a total of all of its microphone signals. Dugan devised a third improvement which helped prevent <b>audio</b> <b>feedback</b> in the presence of sound reinforcement loudspeakers. Dugan next produced an automixer design that could be inserted into an existing mixing console. This proved popular for broadcast and live sound applications. Each of Dugan's subsequent automixer models has been of the insertable type.|$|E
5|$|In both {{recording}} and in live musical sound reinforcement, {{the key to}} noise minimisation is headroom. Headroom can be used either to reduce distortion and <b>audio</b> <b>feedback</b> by keeping signal levels low, or to reduce interference, both from outside sources and from the Johnson-Nyquist noise produced in the equipment, by keeping signal levels high. Most proprietary noise reducing technologies also introduce low levels of distortion. Noise minimisation therefore becomes a compromise between interference and distortion, both in {{recording and}} in live music, and between interference and feedback in live amplification. The work of Bart Kosko and Sanya Mitaim has also demonstrated that stochastic resonance {{can be used as}} a technique in noise minimisation and signal improvement in non-linear dynamical systems, as the addition of noise to a signal can improve the signal-to-noise ratio.|$|E
5|$|The {{college is}} {{actively}} involved in the development and use of assistive technology to aid visually impaired people in their everyday lives. For example, working with a United States-based software engineer, RNC produced the T3 (Talking Tactile Tablet), a touch sensitive device for interpreting tactile images such as diagrams, charts and maps. The device is connected to a computer and run with a programme CD, and has a tactile surface which produces touchable icons that provide <b>audio</b> <b>feedback</b> when they are pressed. The device was originally developed for educational purposes but can be adapted for other uses. In 2005 Hereford Museum and Art Gallery became the first in the United Kingdom to invest in the technology. The T3 was later marketed internationally {{with the help of the}} UK Trade & Investment's passport initiative– a scheme which gives new exporters the training, planning and support they need to succeed in overseas markets.|$|E
5000|$|In <b>audio</b> amplifiers, {{negative}} <b>feedback</b> reduces distortion, minimises {{the effect}} of manufacturing variations in component parameters, and compensates for changes in characteristics due to temperature change.|$|R
40|$|Feedback in Online Course for Non-Native English-Speaking Students is an {{investigation}} of the effectiveness of <b>audio</b> and text <b>feedback</b> provided in English in an online course for non-native English-speaking students. The study presents results showing how <b>audio</b> and text <b>feedback</b> can impact on non-native English-speaking students' higher-order learning as they participate in an asynchronous online course. It also discusses the results of how students perceive both types of the feedback provided. In addition, the study examines how the impact and perceptions differ when the instructor giving th...|$|R
40|$|In {{real-time}} Internet based teleoperation systems, {{the operator}} controls the robot and receives feedback through the Internet. Supermedia refers to robotic control commands, video, <b>audio,</b> haptic <b>feedback,</b> and other sensory {{information in the}} control system. Traditional transport services {{may not be able}} to meet the timely transmission requirements and dynamic priority changes of supermedia streams. This paper aims to design an e#cient transport service for teleoperation applications...|$|R
25|$|Wen-Ying Tsai (October 13, 1928 – January 2, 2013) was an American pioneer cybernetic {{sculptor}} and kinetic artist {{best known}} for creating sculptures using electric motors, stainless steel rods, stroboscopic light, and <b>audio</b> <b>feedback</b> control. As {{one of the first}} Chinese-born artists to achieve international recognition in the 1960s, Tsai was an inspiration to generations of Chinese artists around the world.|$|E
25|$|Since their {{introduction}} in the mid-1980s, in-ear monitors {{have grown}} {{to be the most}} popular monitoring choice for large touring acts. The reduction or elimination of loudspeakers other than instrument amplifiers on stage has allowed for cleaner and less problematic mixing situations for both the front of house and monitor engineers. <b>Audio</b> <b>feedback</b> is greatly reduced and there is less sound reflecting off the back wall of the stage out into the audience, which affects the clarity of the mix the front of house engineer is attempting to create.|$|E
25|$|The British {{and blues}} musicians {{of the early}} 1960s {{inspired}} a number of American blues rock fusion performers, including the Doors, Canned Heat, the early Jefferson Airplane, Janis Joplin, Johnny Winter, The J. Geils Band, Ry Cooder, and the Allman Brothers Band. One blues rock performer, Jimi Hendrix, was a rarity in his field at the time: {{a black man who}} played psychedelic rock. Hendrix was a skilled guitarist, and a pioneer in the innovative use of distortion and <b>audio</b> <b>feedback</b> in his music. Through these artists and others, blues music influenced the development of rock music.|$|E
50|$|Digital filters may be {{used for}} both <b>audio</b> systems and <b>feedback</b> control systems, but since the {{objectives}} are different, generally the phase characteristics of the filters will be significantly different for the two applications.|$|R
40|$|Abstract — The paper {{presents}} a robot cell for multimodal standing-up motion augmentation. The robot cell {{is aimed at}} augmenting the standing-up capabilities of impaired or paraplegic subjects. The setup incorporates the rehabilitation robot device, functional electrical stimulation system, measurement instrumentation and cognitive feedback system. For controlling the standing-up process a novel approach was developed integrating the voluntary activity of {{a person in the}} control scheme of the rehabilitation robot. The simulation results demonstrate the possibility of “patient-driven ” robotassisted standing-up training. Moreover, to extend the system capabilities, the <b>audio</b> cognitive <b>feedback</b> is aimed to guide the subject throughout rising. For the feedback generation a granular synthesis method is utilized displaying highdimensional, dynamic data. The principle of operation and example sonification in standing-up are presented. In this manner, by integrating the cognitive feedback and “patientdriven” actuation systems, an effective motion augmentation system is proposed in which the motion coordination is under the voluntary control of the user. Index Terms — Rehabilitation robotics, standing-up, voluntary control, <b>audio</b> cognitive <b>feedback,</b> granular synthesis...|$|R
40|$|This is {{a conference}} paperThe JISC-funded ‘Sounds Good’ project at Leeds Metropolitan University (www. soundsgood. org. uk) is {{exploring}} {{the use of}} digital <b>audio</b> for <b>feedback</b> on students’ work. A central issue is whether the use of MP 3 files {{makes it possible to}} provide students with richer feedback and save staff time. The latest results will be presented to the conference as a work in progress, with a view to refining the paper and planning future research...|$|R
25|$|Rock Band 4 {{now has the}} use of Freestyle Guitar Solos, an {{optional}} feature. If this feature is disabled, guitar solos in songs are presented {{as they were in}} previous Rock Band games with more of the same note-matching aspects in beat with the original song's solo; the player scores as they normally do as during regular song sections, with an added scoring bonus based on the percentage of the solo notes hit correctly. When this feature is enabled, instead of the predefined solo, the game shows suggestions for the solo style to emulate at that time, such as single notes or longer licks, chords, or tremolos, using different patterns to highlight the guitar player's on-screen track. The track markings also indicate which set of fret keys on the instrument control to use, which determine the pitch of the notes. Players cannot fail these freestyle sections, but they are scored on how well they hit the suggested style during the segment, and they can retain their scoring multiplier by performing the proper playing style on each section of the solo. The game includes tutorials to help explain these mechanics to players. Further, the <b>audio</b> <b>feedback</b> from these solos has been refined as to make whatever the player performs stay consistent and in-tune with the other active and backing instruments.|$|E
500|$|As well as distortion, rock musicians {{have used}} <b>audio</b> <b>feedback,</b> which is {{normally}} undesirable. The use of feedback was pioneered by musicians such as John Lennon of The Beatles, Jeff Beck of The Yardbirds, Pete Townshend of The Who, and Jimi Hendrix. Hendrix {{was able to}} control feedback {{and turn it into}} a musical quality, and his use of noise has been described as [...] "sculpted - liquid and fire expertly shaped in mid-air as if by a glass blower." [...] Other techniques used by Hendrix include distortion, wah, fuzz, dissonance, and loud volume.|$|E
500|$|In a mixed review, AllMusic {{reviewer}} Jason Birchmeier criticized Experimental Jet Set for its stripped-down sound, {{saying that}} the album only contains [...] "odd lyrics and unique guitar nuance." [...] Similarly, Evelyn McDonnell of Entertainment Weekly noted that the songs [...] "never quite emerge from the sketch stage" [...] and that newcomers may {{find it difficult to}} appreciate. In contrast, Alternative Press highlighted the album's anti-commercial aesthetic, claiming that [...] "It doesn't get much cooler than this". The Advocate criticized the album and the band for not taking risks, concluding: [...] "Sonic Youth is stuck repeating the same experience. And this time around, the songs don't stick." [...] Mike Rubin, writing for Spin, described Experimental Jet Set as a [...] "low-key, mellow affair", but highlighted the guitar playing and the <b>audio</b> <b>feedback</b> on some songs.|$|E
40|$|One {{hallmark}} {{difficulty of}} children with Autism Spectrum Disorder (ASD) centers on communication and speech. Research into computer visualizations of voice {{has been shown to}} influence conversational patterns and allow users to reflect upon their speech. In this paper we present the Spoken Impact Project (SIP) examines the effect of <b>audio</b> and visual <b>feedback</b> on vocalizations in low-functioning children with ASD by providing them with additional means of understanding and exploring their voice. This researdh spans over 12 months, including the creation of multiple software packages and detailed analysis of more than 20 hours of experimental video. SIP demonstrates the potential of computer generated <b>audio</b> and visual <b>feedback</b> to shape vocalizations {{of children with}} ASD. Author Keyword...|$|R
40|$|International audienceThanks to {{the help}} of the French National Agency for Research (ANR), manufacturers, {{researchers}} on spoken interactive systems and researchers in French language didactics have developed a software in order to help young French learners (students aged 6 to 7) to produce written texts. Our presentation, resulting from the conclusions of an investigation conducted among six French classes in Spring 2014, will start from this statement: by emphasizing the links between graphemes and phonemes (Saussure, 1916), vocal synthesis may enhance some phonological acquisitions and help the learner better understand the properties of the written language. Indeed, mastering phonems' and graphems' code is necessary, but not enough to enter in the written world (Maisonneuve, 2002). So it may be relevant for young learners to keep a bond between what is about to be written and oral aspects. Consequently, collecting and analysing data that can produce evidence of the impact of this software's <b>audio</b> <b>feedbacks</b> represents an interesting step towards the understanding of how primary school students build writing skills. We will show how we proceeded to get as much evidence as possible of the development of those skills among the students we observed...|$|R
40|$|Haptic {{feedback}} {{plays an}} important role to further enhance the level of realism of virtual environments where visual and <b>audio</b> <b>feedbacks</b> are only provided. However, realistic haptic rendering depends on its coupling to the underlying physics engine that governs the behavior of virtual objects. This paper presents methods to streamline the generation of haptic feedback with physics engine based on Sensable’s OpenHaptics and nVidia’s PhysX. Minimal development effort is required to couple these two components. To render the forces due the interactions between virtual objects, the Error-based method and the Contact Plane Collision Response method are proposed to utilize virtual material stiffness and object collision geometry provided by PhysX. The latter method yields more jitter-free output by restricting the haptic interface {{on one side of the}} contact plane. While PhysX does not release force information, an Indirect Force Estimation technique is proposed to simulate static or dynamic pulling force by introducing a spring between the haptic interface and the object being pulled. By using Hooke’s Law, the pulling force can be estimated indirectly from the elongation of the spring. The use of these methods provides the desired force feedback without significant changes to the developer’s codebase...|$|R
500|$|The UK {{edition of}} Are You Experienced opened with [...] "Foxy Lady", a track that, with the {{exception}} of a few overdubs, was recorded in one session at CBS. Hendrix wrote the song about Heather Taylor, a highly desirable London socialite who later married the Who's Roger Daltrey. It begins with the fade-in of an F note that Hendrix is bending-up to F while applying generous finger vibrato. Using his guitar's control knob, he slowly increases volume until an <b>audio</b> <b>feedback</b> loop develops and he slides into the song's dominant Fm7 chord. Hendrix used a combination of natural amplifier overdrive and fuzz box effects units to create the song's razor-sharp guitar tone. Its blues–inspired solo—his fourth since arriving in England—used pentatonic scales while showcasing his innovative approach to melody; by exploiting the increased sustain created by overdriving his amplifiers, he moved seamlessly between the middle and high registers with a fluid, singing tone. While author Peter Doggett compared its slow beat to Memphis soul, David Stubbs described the track as a prototype for heavy metal bands such as Black Sabbath.|$|E
500|$|To {{adjust to}} {{potential}} <b>audio</b> <b>feedback</b> and leakage and obtain a usable take, Chavarria tried having Badu sit in an overstuffed chair six feet behind the mixing console and use alternate microphones {{such as a}} Neumann M 269 or AEA R44 ribbon microphone with Sony MDR-V900 headphones into a Furman headphone mixer. However, Badu felt she could not perceive all of her voice's frequencies with the headphones and often discarded them to move towards the studio monitors. He also considered situating her in an equilateral triangle with the two speakers, one {{of which would be}} placed out of phase in order to have the leakage cancel itself. However, according to him, the mic has to be stationary, while Badu [...] "likes to hold the mic like an MC. She is at home as a live performer." [...] He said of working around audio spills and adapting to Badu's methods, [...] "We worked to make her vocals fit into the track, phase-wise ... What did work was to keep the monitors fairly low and turn the microphone out of phase, and we would move her around the room until she found a spot where the leakage was reasonable and where she felt comfortable and could hear herself. But just as often she would just sit in that chair behind the board in the A Room." ...|$|E
2500|$|A {{feedback}} suppressor detects unwanted <b>audio</b> <b>feedback</b> and suppresses it, typically by automatically inserting a notch filter into the signal {{path of the}} system, which prevents feedback [...] "howls" [...] from occurring. <b>Audio</b> <b>feedback</b> can create unwanted loud, screaming noises which are disruptive to the performance, and which can damage performers' and audience members' ears and speakers. <b>Audio</b> <b>feedback</b> from microphones occurs when a microphone [...] "hears" [...] the sound it is picking up through the monitor speakers or the main speakers. While microphone <b>audio</b> <b>feedback</b> is almost universally regarded as a negative phenomenon, in hard rock and heavy metal music, electric guitarists purposely create guitar feedback to create unique, sustained sounds with their guitar and guitar amplifier. This type of feedback is sought out by guitarists, so the sound engineer does not try to prevent it.|$|E
40|$|This paper {{discusses}} {{the use of}} ABKD, a multimodal mobile learning game that aims to help Filipino {{children and young adults}} remember and increase their Chinese Hanzi and Japanese Kanji vocabularies by engaging them in a collaborative game-like group activity and challenging their creativity and imagination through drawing, taking pictures, and <b>audio</b> recording. <b>Feedback</b> from language learners after playing the game reveals that ABKD has the potential to make learning and remembering Hanzi characters easier, more fun, and more interesting...|$|R
40|$|This paper {{describes}} {{current work}} on the design and development of haptic interfaces for use with digital sound editing software. Current systems rely on computer keyboards, mice, and sometimes passive knobs for user input and graphics and <b>audio</b> for <b>feedback.</b> The addition of haptic feedback will improve the user experience because of the additional mode of feedback received through touch. This work is focused on using a design methodology, including need finding, user observations, prototyping, and user testing to develop haptic sensations effective for manipulating sound...|$|R
40|$|One {{hallmark}} {{difficulty of}} children with Autism Spectrum Disorder (ASD) centers on communication and speech. Research into computer visualizations of voice {{has been shown to}} influence conversational patterns and allow users to reflect upon their speech. In this research, called the Spoken Impact Project (SIP), we explore the effects of <b>audio</b> and visual <b>feedback</b> on vocalization in low-functioning children with ASD. By presenting a child with a new interpretation of their vocalizations (though <b>audio</b> and visual <b>feedback),</b> we aim to provide them with additional means of understanding and exploring their own voice. The SIP research spans over 12 months, including the creation of multiple software packages and detailed analysis of more than 20 hours of experimental video. This thesis details the four major components of this research project; 1) theory for visuals as feedback; 2) Supporting Video Annotation; 3) Creation of a Coding Guideline for Working with pre-verbal children and computers, and; 4) exploring SIP in an Experimental Context. In this work, we demonstrate the potential of computer generated <b>audio</b> and visual <b>feedback</b> to shape vocalizations {{of children with}} ASD. ii ACKNOWLEDGEMENS It is because of the constant support, guidance and compassion of my advisor, Karrie Karahalios, that this research could even be conducted. I would like to thank all of m...|$|R
2500|$|The back {{reaction}} of the medium is an determinant of source motion. In many important cases, linear thinking (small cause = small effect) is fallacious. Unstable fluid motion or the sound generated by it can feedback to the source and control it, much like <b>audio</b> <b>feedback</b> squeal. The basic requirements for a feedback controlled system are: ...|$|E
2500|$|The loud squeals that {{sometimes}} occurs in audio systems, PA systems, and rock music {{are known as}} <b>audio</b> <b>feedback.</b> If a microphone {{is in front of}} a loudspeaker that it is connected to, sound that the microphone picks up comes out of the speaker, and is picked up by the microphone and re-amplified. [...] If the loop gain is sufficient, howling or squealing at the maximum power of the amplifier is possible.|$|E
2500|$|<b>Audio</b> <b>feedback</b> {{and the use}} of tape loops, sound {{synthesis}} and computer generated compositions reflected a cybernetic awareness of information, systems and cycles. Such techniques became widespread in the 1960s in the music industry. The visual effects of electronic feedback became a focus of artistic research in the late 1960s, when video equipment first reached the consumer market. Steina and Woody Vasulka, for example, used [...] "all manner and combination of audio and video signals to generate electronic feedback in their respective of corresponding media." ...|$|E
2500|$|... iOS 11.0.3 was {{released}} on October 11, 2017. It fixed an issue with the <b>audio</b> and haptic <b>feedback</b> on iPhone 7 and 7 Plus, and an issue on iPhone 6S where the touch input was unresponsive if the device's display had been serviced with non-genuine Apple parts.|$|R
50|$|Research in 3D {{interaction}} and 3D display {{began in the}} 1960s, pioneered by researchers like Ivan Sutherland, Fred Brooks, Bob Sproull, Andrew Ortony and Richard Feldman. But {{it was not until}} 1962 when Morton Heilig invented the Sensorama simulator. It provided 3D video feedback, as well motion, <b>audio,</b> and <b>feedbacks</b> to produce a virtual environment.The next stage of development was Dr. Ivan Sutherland’s completion of his pioneering work in 1968, the Sword of Damocles. He created a head-mounted display that produced 3D virtual environment by presenting a left and right still image of that environment.|$|R
40|$|The use {{of video}} {{feedback}} is popular, even usual, in fields involving social behaviour and interaction or physical performance. In other academic subject areas, {{the use of}} video as feedback is, as yet, uncommon. The work of others in this field covers group work, generic feedback, small numbers of students, samples and trials. We believe this {{may be one of}} the first studies on returning individual personalised feedback to a sizeable number of first year undergraduate students taking Computer Programming, or any other academic subject, for every assessment submitted on the unit. Student engagement with feedback is often lacking and in that case, a valuable learning opportunity is missed. Previous work using <b>audio</b> as <b>feedback</b> showed 80 % of students would prefer <b>audio</b> to written <b>feedback.</b> However, the separation of submitted programming code from audio comments still limits ease of reference to the work. The next natural step was to use video screen capture to augment the student experience by improving easy reference to work by simultaneously providing contextually relevant narrative and visually referring to elements of the work...|$|R
