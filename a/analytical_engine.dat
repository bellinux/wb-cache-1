236|41|Public
5|$|An {{offshoot}} of the work at MIT {{was the beginning of}} digital circuit design theory by one of Bush's graduate students, Claude Shannon. Working on the <b>analytical</b> <b>engine,</b> Shannon described the application of Boolean algebra to electronic circuits in his landmark master's thesis, A Symbolic Analysis of Relay and Switching Circuits. In 1935, Bush was approached by OP-20-G, which was searching for an electronic device to aid in codebreaking. Bush was paid a $10,000 fee to design the Rapid Analytical Machine (RAM). The project went over budget and was not delivered until 1938, when it was found to be unreliable in service. Nonetheless, it was an important step toward creating such a device.|$|E
25|$|During a nine-month {{period in}} 1842–43, Ada Lovelace {{translated}} the memoir of Italian mathematician Luigi Menabrea. The memoir covered the <b>Analytical</b> <b>Engine.</b> The translation contained Note G which completely detailed {{a method for}} calculating Bernoulli numbers using the <b>Analytical</b> <b>Engine.</b> This note is recognized by some historians as the world's first written computer program.|$|E
25|$|After {{the attempt}} at making the first {{difference}} engine fell through, Babbage worked {{to design a}} more complex machine called the <b>Analytical</b> <b>Engine.</b> He hired C. G. Jarvis, who had previously worked for Clement as a draughtsman. The <b>Analytical</b> <b>Engine</b> marks the transition from mechanised arithmetic to fully-fledged general purpose computation. It is largely on it that Babbage's standing as computer pioneer rests.|$|E
5000|$|The flying {{ships in}} the anime Last Exile are seen to have <b>analytical</b> <b>engines</b> inside of them. Although some have more {{advanced}} technology, the common ships use <b>analytical</b> <b>engines,</b> {{and even some of}} the advanced ships are seen to have clockwork mechanisms as well.|$|R
5000|$|Mechanical calculators, {{used before}} {{electronic}} computers were developed around World War II. Among {{the most complex}} were Babbage's difference and <b>analytical</b> <b>engines,</b> which were mechanical versions of computers.|$|R
5000|$|Most {{discussions of}} the history of {{computing}} start with Charles Babbage, and what we know about Charles Babbage's Difference and <b>Analytical</b> <b>engines</b> really starts with the scholarship of Allan Bromley. Tim Berguin ...|$|R
25|$|In 1837, Charles Babbage was {{inspired}} by Jacquard's loom to attempt to build the <b>Analytical</b> <b>Engine.</b>|$|E
25|$|In 1914, Leonardo Torres y Quevedo {{designed}} an electro-mechanical {{version of}} Charles Babbage's <b>Analytical</b> <b>Engine,</b> and included floating-point arithmetic.|$|E
25|$|During a nine-month {{period in}} 1842–43, Lovelace {{translated}} the Italian mathematician Luigi Menabrea's article on Babbage's newest proposed machine, the <b>Analytical</b> <b>Engine.</b> With the article, she appended {{a set of}} notes. Explaining the Analytical Engine's function was a difficult task, as even many other scientists did not really grasp the concept and the British establishment was uninterested in it. Lovelace's notes even had {{to explain how the}} <b>Analytical</b> <b>Engine</b> differed from the original Difference Engine. Her work was well received at the time; the scientist Michael Faraday described himself as a supporter of her writing.|$|E
5000|$|The {{cyberpunk}} novelists William Gibson and Bruce Sterling co-authored a steampunk {{novel of}} alternative history titled The Difference Engine in which Babbage's Difference and <b>Analytical</b> <b>Engines</b> became available to Victorian society. The novel explores the consequences {{and implications of}} the early introduction of computational technology.|$|R
5000|$|The first Advanced Chess {{event was}} held in June 1998 in León, Spain. It was played between Garry Kasparov, who was using Fritz 5, and Veselin Topalov, who was using ChessBase 7.0. The <b>analytical</b> <b>engines</b> used, such as Fritz, HIARCS and Junior, were {{integrated}} into these two programs, and could have been called at a click of the mouse. It was a 6-game match, and it was arranged in advance that the players would consult the built-in million games databases only for the 3rd and 4th game, and would only use <b>analytical</b> <b>engines</b> without consulting the databases for the remaining games. The time available to each player during the games was 60 minutes. The match ended in a 3-3 tie. After the match, Kasparov said: ...|$|R
40|$|Advances in {{econometrics}} {{and financial}} mathematics are still confined to use within {{the domains of}} stocks, bonds, shares, currency exchanges and derivatives markets. Extracting the principles (see paper by Datta & Granger) and simulating a data environment for its use, in business operations and security, may provide clues to future software systems that can use these <b>analytical</b> <b>engines</b> to improve forecasting and risk analytics. This is a proposal to create a simulation tool that can explore advanced tools and techniques from econometrics to use in operations management in business and security. MIT Forum for Supply Chain Innovation [URL]...|$|R
25|$|The Oracle CVE <b>Analytical</b> <b>Engine</b> uses {{a set of}} {{theoretical}} models, each of which evaluates {{some or all of}} the data. When a business analyst configures causal factors, he/she specifies criteria indicating which models should consider which causal factor.|$|E
25|$|In 1953, {{more than}} a century after her death, Ada Lovelace's notes on Babbage's <b>Analytical</b> <b>Engine</b> were republished. The engine has now been {{recognised}} as an early model for a computer and her notes as a description of a computer and software.|$|E
25|$|In 1840, Babbage {{was invited}} to give a seminar at the University of Turin about his <b>Analytical</b> <b>Engine.</b> Luigi Menabrea, a young Italian engineer, and the future Prime Minister of Italy wrote up Babbage's lecture in French, and this {{transcript}} was subsequently published in the Bibliothèque universelle de Genève in October 1842.|$|E
40|$|Abstract—Newton is a library-based CAD tool with an <b>analytical</b> {{synthesis}} <b>engine</b> {{which has}} been developed to support the direct synthesis of the physical design and an electromechanically equivalent model of RF-MEMS resonators based on process parameters and performance metrics. Newton provides accuracy comparable to finite element analysis while requiring {{a fraction of the}} computation and design time. A comparison of results from synthesis with Newton, design with FEA, and test results from fabricated devices is presented. I...|$|R
2500|$|During the 1980s, Allan G. Bromley, an {{associate}} professor at the University of Sydney, Australia, studied Babbage's original drawings for the Difference and <b>Analytical</b> <b>Engines</b> at the Science Museum library in London. [...] This work led the Science Museum to construct a working difference engine No. 2 from 1989 to 1991, under Doron Swade, the then Curator of Computing. This was to celebrate the 200th anniversary of Babbage's birth in 2001. In 2000, the printer which Babbage originally designed for the difference engine was also completed. The conversion of the original design drawings into drawings suitable for engineering manufacturers' use revealed some minor errors in Babbage's design (possibly introduced as a protection in case the plans were stolen), which had to be corrected. Once completed, both the engine and its printer worked flawlessly, and still do. The difference engine and printer were constructed to tolerances achievable with 19th-century technology, resolving a long-standing debate as to whether Babbage's design would actually have worked. (One of the reasons formerly advanced for the non-completion of Babbage's engines had been that engineering methods were insufficiently developed in the Victorian era.) ...|$|R
50|$|Lex Machina, Inc. is an IP {{litigation}} {{research company}} that develops legal analytics data and software. The company {{started as a}} project at Stanford University within the university's law school and computer science department before launching as a startup in Menlo Park, California. Lex Machina provides a SaaS product that is available for free to federal courts, academics and students, and select non-profits. It consults clients such as law firms or corporate general councils and provides risk advisory services through its IP <b>analytical</b> reference <b>engine.</b>|$|R
25|$|English {{mathematician}} Ada, Lady Lovelace, a pupil of Somerville, {{corresponded with}} Charles Babbage about applications for his <b>analytical</b> <b>engine.</b> In her notes (1842–3) appended to her translation of Luigi Menabrea's {{article on the}} engine, she foresaw wide applications for it as a general-purpose computer, including composing music. She has been credited as writing the first computer program, though this has been disputed.|$|E
25|$|Ada Lovelace's {{notes were}} {{labelled}} alphabetically from A to G. In note G, she describes an algorithm for the <b>Analytical</b> <b>Engine</b> to compute Bernoulli numbers. It {{is considered the}} first published algorithm ever specifically tailored for implementation on a computer, and Ada Lovelace has often been cited as the first computer programmer for this reason. The engine was never completed so her program was never tested.|$|E
25|$|In 1814, Georgiana Whitmore, a {{daughter}} of William Whitmore and sister of the budding politician, married computing pioneer Charles Babbage. Babbage lived at Dudmaston Hall for significant periods and even engineered the central heating system. Their son Henry Prevost Babbage's 1910 <b>Analytical</b> <b>Engine</b> Mill was on display at Dudmaston Hall until the 1980s, after which it {{was moved to the}} Science Museum in London.|$|E
40|$|A {{computer}} program titled GENENG is described. The program uses component performance maps {{to enable the}} user to do <b>analytical</b> steady-state <b>engine</b> cycle calculations. Through a scaling procedure, each of the component maps {{can be used to}} represent a family of maps (different design values of pressure ratios, efficiency, weight flow, etc.). Either convergent or convergent divergent nozzles may be used. Included is a complete FORTRAN IV listing of the program. Sample results and input explanations are shown for one-spool and two-spool turbojets and two-spool separate and mixed-flow turbofans operating at design and off-design conditions. The {{computer program}} is available from the authors. Includes bibliographical references (p. 150). A computer program titled GENENG is described. The program uses component performance maps to enable the user to do <b>analytical</b> steady-state <b>engine</b> cycle calculations. Through a scaling procedure, each of the component maps can be used to represent a family of maps (different design values of pressure ratios, efficiency, weight flow, etc.). Either convergent or convergent divergent nozzles may be used. Included is a complete FORTRAN IV listing of the program. Sample results and input explanations are shown for one-spool and two-spool turbojets and two-spool separate and mixed-flow turbofans operating at design and off-design conditions. The computer program is available from the authors. Mode of access: Internet...|$|R
40|$|Part 3 : What New Educational Management Information Systems Are Being Developed?International audienceLarge {{technological}} developments have {{occurred over the}} last three decades and their impacts are affecting the management of educational systems. With cloud computing, we now have an opportunity to reshape architectures. In this paper, we present a model-based redesign for next generation technologies, to act on educational management at a school level. This redesign model respects existing system architectures, increases and organizes school communication channels and includes an intelligence element. Key performance indicators were included in an intelligence element to allow peer benchmarking and provide a refresh referential. The new referential is included in the architecture core element and will allow schools to respond to the informational needs of next level <b>analytical</b> <b>engines.</b> This redesign model intends to create conditions to develop the holistic analyses of educational management. Based on Stafford Beer´s work, it is also in the intelligence element that the interaction with the school´s internal and external environments is developed. Stafford Beer´s Viable System Model (VSM) is a conceptual framework {{that can be used to}} diagnose and resctructure organizations. In this work, we used the VSM to remodel the informational architecture of school management in Portugal...|$|R
30|$|Differential {{evolution}} is an optimisation algorithm introduced by Storn and Price (1995). This optimisation method is an evolutionary algorithm based on population, mutation and recombination. Differential {{evolution is}} easy to implement and has only four parameters which need to be set. The parameters are: generations, NP, F and Cr. The generations parameter determines the number of generations; the NP parameter is the population size; the F parameter is the weighting factor; and the Cr parameter is the crossover probability (Storn 1996). In this research, the differential evolution is used as an <b>analytical</b> programming <b>engine.</b>|$|R
25|$|Ada Lovelace, who {{corresponded with}} Babbage during his {{development}} of the <b>Analytical</b> <b>Engine,</b> is credited with developing an algorithm that would enable the Engine to calculate a sequence of Bernoulli numbers. Despite documentary evidence in Lovelace's own handwriting, some scholars dispute {{to what extent the}} ideas were Lovelace's own. For this achievement, she is often described as the first computer programmer; though no programming language had yet been invented.|$|E
25|$|His {{youngest}} surviving son, Henry Prevost Babbage (1824–1918), went on {{to create}} six small demonstration pieces for Difference Engine No. 1 based on his father's designs, {{one of which was}} sent to Harvard University where it was later discovered by Howard H. Aiken, pioneer of the Harvard Mark I. Henry Prevost's 1910 <b>Analytical</b> <b>Engine</b> Mill, previously on display at Dudmaston Hall, is now on display at the Science Museum.|$|E
25|$|The {{notes are}} around three {{times longer than}} the article itself and include (in Section G), in {{complete}} detail, a method for calculating a sequence of Bernoulli numbers with the Engine, which could have run correctly had Babbage's <b>Analytical</b> <b>Engine</b> been built. (Only his Difference Engine has been built, completed in London in 2002.) Based on this work Lovelace is now widely considered the first computer programmer and her method is recognised as the world's first computer program.|$|E
40|$|The use of {{analytical}} redundancy {{to improve}} {{gas turbine engine}} control system reliability through sensor failure detection, isolation, and accommodation is surveyed. Both the theoretical and application papers that form the technology base of turbine <b>engine</b> <b>analytical</b> redundancy research are discussed. Also, several important application efforts are reviewed. An assessment of the state-of-the-art in analytical redundancy technology is given...|$|R
40|$|Aim of the talk:Control of EGR/TVA of a Diesel Engine - Process Model Identification for Controller Design Approach List of {{possible}} topics: Design of a control scheme for commercial (HD) diesel engines (boats, ships, farm tractors, [...] .). Diesel engine modelling. Control system strategy. Diesel <b>engine</b> <b>analytical</b> description. Estimation of engine submodels, maps. Submodel parameter calibration. Electronic Control Unit (ECU). Control scheme implementation...|$|R
40|$|Abstract. Biomarker {{measurements}} now support key decisions {{throughout the}} drug development process, from lead optimization to regulatory approvals. They {{are essential for}} documenting exposure-response relationships, specificity and potency toward the molecular target, untoward effects, and therapeutic applications. In a broader sense, biomarkers constitute the basis of clinical pathology and laboratory medicine. The utility of biomarkers is limited by their specificity and sensitivity toward the drug or disease process and by their overall variability. Understanding and controlling sources of variability is not only imperative for delivering high-quality assay results, but ultimately for controlling the size and expense of research studies. Variability in biomarker measurements is affected by: biological and environmental factors (e. g., gender, age, posture, diet and biorhythms), sample collection factors (e. g., preservatives, transport and storage conditions, and collection technique), and analytical factors (e. g., purity of reference material, pipetting precision, and antibody specificity). The quality standards for biomarker assays used in support of nonclinical safety studies fall under GLP (FDA) regulations, whereas, those assays used to support human diagnostics and healthcare are established by CLIA (CMS) regulations and accrediting {{organizations such as the}} College of American Pathologists. While most research applications of biomarkers are not regulated, biomarker laboratories in all settings are adopting similar laboratory practices in order to deliver high-quality data. Because of the escalation in demand for biomarker measurements, the highly-parallel (multi-plexed) assay platforms that have fueled the rise of genomics will likely evolve into the <b>analytical</b> <b>engines</b> that drive the biomarker laboratories of tomorrow...|$|R
25|$|The 19th century {{also saw}} the designs of Charles Babbage calculating machines, first with his {{difference}} engine, started in 1822, {{which was the first}} automatic calculator since it continuously used the results of the previous operation for the next one, and second with his <b>analytical</b> <b>engine,</b> which was the first programmable calculator, using Jacquard's cards to read program and data, that he started in 1834, and which gave the blueprint of the mainframe computers built {{in the middle of the}} 20th century.|$|E
25|$|The major {{innovation}} {{was that}} the <b>Analytical</b> <b>Engine</b> was to be programmed using punched cards: the Engine was intended to use loops of Jacquard's punched cards to control a mechanical calculator, which could use as input the results of preceding computations. The machine was also intended to employ several features subsequently used in modern computers, including sequential control, branching and looping. It {{would have been the}} first mechanical device to be, in principle, Turing-complete. The Engine was not a single physical machine, but rather a succession of designs that Babbage tinkered with until his death in 1871.|$|E
25|$|In {{this context}} {{function}} composition is complicated to express, because the chain rule {{is not simply}} applied to second and higher derivatives. This matter was known to Woodhouse by 1803, who took from Louis François Antoine Arbogast {{what is now called}} Faà di Bruno's formula. In essence it was known to Abraham De Moivre (1697). Herschel found the method impressive, Babbage knew of it, and it was later noted by Ada Lovelace as compatible with the <b>analytical</b> <b>engine.</b> In the period to 1820 Babbage worked intensively on functional equations in general, and resisted both conventional finite differences and Arbogast's approach (in which Δ and D were related by the simple additive case of the exponential map). But via Herschel he was influenced by Arbogast's ideas in the matter of iteration, i.e. composing a function with itself, possibly many times. Writing in a major paper on functional equations in the Philosophical Transactions (1815/6), Babbage said his starting point was work of Gaspard Monge.|$|E
40|$|The aim of {{this chapter}} is to study {{the history of the}} design and use of calculating {{machines}} to produce anduse numerical tables, from the time of Babbage’s plans for difference and <b>analytical</b> <b>engines</b> to the modern digitalcomputer, including in this analysis the role played by analog machines between the two. We will examine howthe place and role of numerical tables changed throughout the different stages of this mechanization. It is ourhypothesis that these processes of mechanization and, ultimately, automisation and digitalization, result in theprogressive internalization of aspects of the dynamical relation between humans and tables into the machine. This chapter considers several major stages in the devising of machines for the making and use of tables, fromdifference engines to computers. Following these stages, we investigate how increasing demands for calculatingpower go hand in hand with advances in the new technological possibilities offered by machines. The way by which machines were introduced and accepted for mathematical computations will also be examined. Eventhough this chapter is thus structured according to the changes in the machines, the focus will be on how thesechanges have affected numerical tables. By doing so, it will become clear how {{it is not only the}} machine whichshapes the history of the numerical table, but, also how the numerical table has impacted on the design anduse of calculating machinery. In fact, as we will argue, the history of calculating machinery is reciprocal to thehistory of the numerical table. With the development of modern computers, in which data and programs can bemanipulated in the same way, this reciprocity is expressed by an increasing interchangeability between tablesand algorithms...|$|R
40|$|This {{bachelor}} {{thesis is}} focused on the study of gas microturbine. The first part presents the main principle of cogeneration. Then there is described construction and properties of mi-croturbine technology and states major manufacturers and their products. There is also in-cluded comparison to gas <b>engines.</b> <b>Analytical</b> part makes familiar with microturbine performance in relation to operational conditions. It includes using mathematical software Maple for processing data supplied by the manufacturer. The last part compares the results of experimental measurement with cal-culated results...|$|R
40|$|As {{open access}} market {{principles}} {{are applied to}} power systems, significant changes are happening in their planning, operation and control. In the emerging marketplace, systems are operating under higher loading conditions as markets focus greater attention to operating costs than stability and security margins. Since operating stability is a basic requirement for any power system, there is need for newer tools to ensure stability and security margins being strictly enforced in the competitive marketplace. This dissertation investigates issues associated with incorporating voltage security into the unbundled operating environment of electricity markets. It includes addressing voltage security in the monitoring, operational and planning horizons of restructured power system. This dissertation presents a new decomposition procedure to estimate voltage security usage by transactions. The procedure follows physical law and uses an index that can be monitored knowing {{the state of the}} system. The expression derived is based on composite market coordination models that have both PoolCo and OpCo transactions, in a shared stressed transmission grid. Our procedure is able to equitably distinguish the impacts of individual transactions on voltage stability, at load buses, in a simple and fast manner. This dissertation formulates a new voltage stability constrained optimal power flow (VSCOPF) using a simple voltage security index. In modern planning, composite power system reliability analysis that encompasses both adequacy and security issues is being developed. We have illustrated the applicability of our VSCOPF into composite reliability analysis. This dissertation also delves into the various applications of voltage security index. Increasingly, FACT devices are being used in restructured markets to mitigate a variety of operational problems. Their control effects on voltage security would be demonstrated using our VSCOPF procedure. Further, this dissertation investigates the application of steady state voltage stability index to detect potential dynamic voltage collapse. Finally, this dissertation examines developments in representation, standardization, communication and exchange of power system data. Power system data is the key input to all <b>analytical</b> <b>engines</b> for system operation, monitoring and control. Data exchange and dissemination could impact voltage security evaluation and therefore needs to be critically examined...|$|R
