26|951|Public
5|$|The {{magneto-optical}} drive manufactured by Canon Inc. {{was used as}} the primary mass storage device. These drives were relatively new to the market, and the NeXT was the first computer to use them. They were cheaper than hard drives (blank media especially so: though each had a cost of $150 to Canon, Jobs's typically forthright negotiations saw Canon agree to a retail of only $50 apiece) but slower (with an <b>average</b> <b>seek</b> <b>time</b> of 96 ms). The design made it impossible to move files between computers without a network, since each NeXT Computer had only one MO drive and the disk could not be removed without shutting down the system. Storage options proved challenging for the first NeXT Computers. The magneto-optical media was relatively expensive and had performance and reliability problems despite being faster than a floppy drive. The drive was not sufficient to run as the primary medium running the NeXTSTEP operating system both in terms of speed and capacity.|$|E
2500|$|Seek time is {{a measure}} of how long it takes the head {{assembly}} to travel to the track of the disk that contains data. The first HDD had an <b>average</b> <b>seek</b> <b>time</b> of about 600ms;. [...] Some early PC drives used a stepper motor to move the heads, and as a result had seek times as slow as 80–120ms, but this was quickly improved by voice coil type actuation in the 1980s, reducing seek times to around 20ms. Seek time has continued to improve slowly over time. [...] The fastest server drives today have a seek time around 4 ms. The <b>average</b> <b>seek</b> <b>time</b> is strictly the time to do all possible seeks divided by the number of all possible seeks, but in practice is determined by statistical methods or simply approximated as the time of a seek over one-third of the number of tracks.|$|E
5000|$|... 4 {{milliseconds}} - typical <b>average</b> <b>seek</b> <b>time</b> for a 10,000 rpm {{hard disk}} ...|$|E
50|$|LOOK has {{slightly}} better <b>average</b> <b>seek</b> <b>times</b> than SCAN. C-LOOK {{has a slightly}} lower variance in <b>seek</b> <b>time</b> than LOOK since the worst case <b>seek</b> <b>time</b> is nearly cut in half.|$|R
50|$|The {{following}} {{is an example of}} how to calculate <b>average</b> disk <b>seek</b> <b>times</b> for both the SCAN and C-SCAN algorithms.|$|R
50|$|The ST-412 disk drive, {{among other}} improvements, added {{buffered}} seek capability to the interface. In this mode, the controller can send STEP pulses to the drive {{as fast as}} it can receive them, without having to wait for the mechanism to settle. An onboard microprocessor then moves the mechanism to the desired track as fast as possible. The ST-506 disk drive without buffered <b>seek,</b> <b>averages</b> 170 ms (similar to a floppy drive or modern optical drive) while the mechanically very similar ST412 disk drive with buffered <b>seek</b> <b>averages</b> 85 ms. By the late 1980s, ST-412 drives were capable of <b>average</b> <b>seek</b> <b>times</b> between 15 and 30 milliseconds.|$|R
50|$|A {{rotating}} drive's <b>average</b> <b>seek</b> <b>time</b> is {{the average}} of all possible seek times which technically {{is the time to}} do all possible seeks divided by the number of all possible seeks, but in practice it is determined by statistical methods or simply approximated as the time of a seek over one-third of the number of tracks. <b>Average</b> <b>seek</b> <b>time</b> ranges from under 4 ms for high-end server drives, to 15 ms for mobile drives, with the most common mobile drives at about 12 ms and the most common desktop drives typically being around 9 ms.|$|E
50|$|<b>Average</b> <b>seek</b> <b>time</b> {{ranges from}} under 4 ms for {{high-end}} server drives to 15 ms for mobile drives, {{with the most}} common mobile drives at about 12 ms and the most common desktop type typically being around 9 ms. The first HDD had an <b>average</b> <b>seek</b> <b>time</b> of about 600 ms; {{by the middle of}} 1970s, HDDs were available with seek times of about 25 ms. Some early PC drives used a stepper motor to move the heads, and as a result had seek times as slow as 80-120 ms, but this was quickly improved by voice coil type actuation in the 1980s, reducing seek times to around 20 ms. Seek time has continued to improve slowly over time.|$|E
50|$|The DBC/1012 used a 474 {{megabyte}} Winchester {{disk drive}} with an <b>average</b> <b>seek</b> <b>time</b> of 18 milliseconds. The disk drive {{was capable of}} transferring data at 1.9 MB/s although in practice the sustainable data rate was lower because the IO pattern tended towards random access and transfer lengths of 8 to 12 kilobytes.|$|E
5000|$|A {{tape drive}} {{provides}} sequential access storage, unlike a hard disk drive, which provides direct access storage. A disk drive can move to any {{position on the}} disk in a few milliseconds, but a tape drive must physically wind tape between reels to read any one particular piece of data. As a result, tape drives have very slow <b>average</b> <b>seek</b> <b>times</b> to data. However, tape drives can stream data very quickly off a tape when the required position has been reached. For example, [...] Linear Tape-Open (LTO) supported continuous data transfer rates of up to 140 MB/s, comparable to hard disk drives.|$|R
25|$|Large {{databases}} {{have historically}} been kept on disk drives. The time to read a record on a disk drive far exceeds {{the time needed to}} compare keys once the record is available. The time to read a record from a disk drive involves a <b>seek</b> <b>time</b> and a rotational delay. The <b>seek</b> <b>time</b> may be 0 to 20 or more milliseconds, and the rotational delay averages about half the rotation period. For a 7200 RPM drive, the rotation period is 8.33 milliseconds. For a drive such as the Seagate ST3500320NS, the track-to-track <b>seek</b> <b>time</b> is 0.8 milliseconds and the <b>average</b> reading <b>seek</b> <b>time</b> is 8.5 milliseconds. For simplicity, assume reading from disk takes about 10 milliseconds.|$|R
40|$|Asynchronous IO (AIO) {{allows a}} process to {{continue}} to do other work while an IO operation initiated earlier completes. AIO allows a large number of random IO operations to be issued at once, allowing the disk subsystem to order access to data on disk, reducing <b>average</b> <b>seek</b> <b>times</b> considerably, as well as allowing much better utilization of disks in a multi-disk RAID environments where reads can be done in parallel across disks. In this paper we address the issue of how to extend a database query execution engine to exploit asynchronous IO. To best exploit AIO, we propose a new iterator model called the Asynchronous Iterator Model, where a getnext() call on an operator can return a status LATER instead of blocking on an IO, permitting other actions to be initiated while an IO is pending. We show how to modify the implementation of Index Nested Loop (INL) join by issuing asynchronous requests to a batch of tuple ids. We have prototyped the asynchronous iterator model for INL joins on the PostgreSQL database system, and present performance results that clearly indicate the benefits to be had from exploiting AIO. ...|$|R
50|$|An HDD's Average Access Time is its <b>average</b> <b>seek</b> <b>time</b> which {{technically}} is {{the time}} to do all possible seeks divided by the number of all possible seeks, but in practice is determined by statistical methods or simply approximated as the time of a seek over one-third of the number of tracks.|$|E
5000|$|DSS180 {{removable}} disk storage subsystem provided up to 18 drives using disks physically compatible with IBM 2316 disks {{used in the}} 2314. The disks were formatted to provide 384 six-bit characters per sector and 27,648,000 characters per pack. The <b>average</b> <b>seek</b> <b>time</b> was 34 milliseconds (ms) and data transfer rate was 416,000 cps.|$|E
50|$|The first HDD had an <b>average</b> <b>seek</b> <b>time</b> {{of about}} 600 ms, {{and by the}} middle 1970s, HDDs were {{available}} with seek times of about 25 ms. Some early PC drives used a stepper motor to move the heads, {{and as a result}} had seek times as short as 80-120 ms, but this was quickly improved by voice coil type actuation in the 1980s, reducing seek times to around 20 ms. Seek time has continued to improve slowly over time.|$|E
40|$|File {{systems for}} flash devices {{have been in}} demand since this storage has become {{attractive}} for general purpose usage. The technology is now widespread. Flash based storage devices exist since the mid 80 ’s [15] and have long been known exclusively for their use in storing small data like PC BIOSes and the firmware of embedded devices. In these cases the flash chip’s content has been memory mapped almost always into a processors adress space and treated as a read-only area during normal usage. Nowadays flash is also used for dedicated read-write operation since the maximum capacity of this technology has seen a huge increase in size and thus opened it {{to be used in}} many different areas like USB drives, a larger read-writeable area for embedded devices and eventually solid state disks (SSDs). However, pure flash storage behaves very different in comparison to normal rotating- disk block devices. <b>Average</b> <b>seek</b> <b>times</b> are several magnitudes better than with common hard disks. There are also a number of drawbacks, for which two approaches to solve them exist: A translation layer to make the memory behave like a normal block device and special file systems. Those file systems and also the changes to traditional file systems for use with flash based solid state disks (SSDs) shall be discussed in this paper. 1...|$|R
40|$|A new {{signature}} file method, Multi-Frame Signature File (MFSF), is introduced by extending the bit-sliced {{signature file}} method. In MFSF, a signature file {{is divided into}} variable sized vertical frames with different on-bit densities to optimize the response time using a partial query evaluation methodology. In query evaluation the on-bits of the lower on-bit density frames are used first. As the number of query terms increases, the number of query signature on-bits in the lower on-bit density frames increases and the query stopping condition is reached in fewer evaluation steps. Therefore, in MFSF, the query evaluation time decreases for increasing numbers of query terms. Under the sequentiality assumption of disk blocks, in a PC environment with 30 ms <b>average</b> disk <b>seek</b> <b>time,</b> MFSF provides a projected worst-case response time of 3. 54 seconds for a database size of one million records in a uniform distribution multi-term query environment with 1 - 5 terms per query. Due to partial evaluation, this desired response time is guaranteed for queries with several terms. The comparison of MFSF with the inverted file approach shows that MFSF provides promising research opportunities. © 1997 Elsevier Science Ltd...|$|R
40|$|Cataloged from PDF {{version of}} article. A new {{signature}} file method, Multi-Frame Signature File (MFSF), is introduced by extending the bit-sliced signature file method. In MFSF a signature file {{is divided into}} variable sized vertical frames with different on-bit densities to optimize the response time using a partial query evaluation methodology. In query evaluation the on-bits of the lower on-bit density frames are used first. As the number of query terms increases, the number of query signature on-bits in the lower on-bit density frames increases and the query stopping condition is reached in fewer evaluation steps. Therefore, in MFSF, the query evaluation time decreases for increasing numbers of query terms. Under the sequentiality assumption of disk blocks, in a PC environment with 30 ms <b>average</b> disk <b>seek</b> <b>time,</b> MFSF provides a projected worst-case response time of 3. 54 seconds for a database size of one million records in a uniform distribution multi-term query environment with 1 - 5 terms per query. Due to partial evaluation, this desired response time is guaranteed for queries with several terms. The comparison of MFSF with the inverted file approach shows that MFSF provides promising research opportunities. (C) 1997 Elsevier Science Ltd...|$|R
50|$|The first {{generation}} Quantum Bigfoot drives were introduced around May 1996 and offered in capacities of 1.2 GB (1 platter, 2 heads) and 2.5 GB (2 platters, 4 heads), with suggested retail prices of $225 and $370 respectively. These drives offered only ATA-2 PIO Mode 4 and DMA mode 2 support (16.6 MBps) {{and had an}} <b>average</b> <b>seek</b> <b>time</b> of 15 ms. Actual transfer rate from the platters was much lower, measured at 813 KB/s by PC Magazine using Disk WinMark 96, slower than a same-capacity/similar-capacity Quantum Fireball (3.5") drive, which delivered 1170 KB/s.|$|E
5000|$|Many 1 in {{hard drives}} (often {{referred}} to by the trademarked name [...] "Microdrive") typically spin at 3600 RPM, so rotational latency is a consideration, as is spin-up from standby or idle. Seagate's 8 GB ST68022CF drive spins up fully within a few revolutions but current drawn can reach up to 350 milliamps and runs at 40-50 mA mean current. Its <b>average</b> <b>seek</b> <b>time</b> is 8 ms and can sustain 9 MByte/s read and write, and has an interface speed of 33 MByte/s. Hitachi's 4 GB Microdrive is 12 ms seek, sustained 6 MByte/s.|$|E
50|$|Short {{stroking}} is a {{term used}} in enterprise storage environments to describe an HDD that is purposely restricted in total capacity so that the actuator only has to move the heads across {{a smaller number of}} total tracks. This limits the maximum distance the heads can be from any point on the drive thereby reducing its <b>average</b> <b>seek</b> <b>time,</b> but also restricts the total capacity of the drive. This reduced seek time enables the HDD {{to increase the number of}} IOPS available from the drive. The cost and power per usable byte of storage rises as the maximum track range is reduced.|$|E
40|$|The {{analysis}} of PQRS and other bias models A new family of models for I/O access patterns, the PQRS family was recently introduced and studied by Wang et. al. In particular these authors studied experimentally <b>average</b> <b>seek</b> distances and cache hit rates for these models. In this paper we compute analytically <b>average</b> <b>seek</b> distances and cache hit rates for PQRS models. We introduce an efficient, parameter independent, caching algorithm for all PQRS models and analyze it’s hit ratio. The {{existence of such}} an algorithm shows that PQRS generated traces are too predictable {{to be used as}} benchmarks. We show how the models can be amended to eliminate predictability. We also introduce the, parameter dependent, optimal caching algorithm for PQRS models and compute it’s hit ratio. We show that models with time independent spatial distributions produce the lowest hit ratios. We compute the <b>average</b> <b>seek</b> distance and show that the models whose spatial distribution is time independent have the largest <b>average</b> <b>seek</b> distance. thus proving a fact which was previously noted experimentally. We also show that the output stream of read misses coming from a PQRS input stream after passing through a cache is also approximated by a PQRS model. The results also quantify and clarify the relations between the various entropies of the models and properties such as burstiness and cache hit ratio. Taken together the results present a comprehensive picture of the behavior of PQRS models. Our formulas for the <b>average</b> <b>seek</b> and for hit ratios make PQRS models much more useful in optimization applications. The predictability reducing mechanisms make them eligible for use in benchmarks. In addition we introduce a larger class of models which we call bias models. We extend many of our results to this larger class. We then provide evidence that this larger class is needed for more realistic modeling of real workloads...|$|R
40|$|An {{adaptive}} UNIX disk {{device driver}} is described. To reduce <b>seek</b> <b>times,</b> the driver copies frequentlyreferenced blocks from their original locations to reserved space {{near the center}} of the disk. Block reference frequencies need not be known in advance. Instead, they are estimated by monitoring the stream of arriving requests. Measurements show that the adaptive driver reduces <b>seek</b> <b>times</b> and response times substantially. 1 Introduction Disk performance can be a limiting factor in the performance of a computer system. The problem of slow secondary storage devices has come to be known as the I/O bottleneck. One of the major components of disk access <b>times</b> is <b>seek</b> <b>time,</b> the time required to move the drive's read/write heads to the required data. By reducing <b>seek</b> <b>time,</b> the performance of a disk can be improved. In a recent paper [Akyurek 93] we introduced an adaptive block rearrangement technique which reduces disk <b>seek</b> <b>times.</b> Under this technique, a small number of frequently refere [...] ...|$|R
40|$|I/O {{performance}} has been improved by proper scheduling of disk accesses {{since the time}} movable head disk came into existence. Disk scheduling {{is the process of}} carefully examining the pending requests to determine {{the most efficient way to}} service the pending requests. Scheduling algorithms generally concentrate on reducing <b>seek</b> <b>times</b> for a set of requests, because <b>seek</b> <b>times</b> tend to be an order of magnitude greater than latency times. Some important scheduling algorithms are First-Come-First-Served (FCFS), Shortest <b>Seek</b> <b>Time</b> First (SSTF), SCAN, Circular Scan (C-SCAN) and LOOK. This paper proposes a new disk scheduling algorithm called Major Half Served First (MHSF). Simulation results show that using MHSF the service is fast and <b>seek</b> <b>time</b> has been reduced drastically...|$|R
50|$|The 2311 {{mechanism}} is largely {{identical to the}} 1311, but recording improvements allow higher data density. The 2311 stores 7.25 megabytes on a single removable IBM 1316 disk pack (the same type used on the IBM 1311) consisting of six platters that rotate as a single unit. The 2311 has ten individual read/write (R/W) heads mounted on a common actuator which moves in and out hydraulically and is mechanically detented at the desired track before reading or writing occurred. Each recording surface has 200 tracks plus three optional tracks {{which could be used}} as alternatives in case faulty tracks were discovered. <b>Average</b> <b>seek</b> <b>time</b> was 85 ms. Data transfer rate was 156 kB/s.|$|E
50|$|The FACIT ECM 64, {{manufactured}} by Swedish company Facit AB, is {{a prototype of}} carousel memory. To avoid having a single, long magnetic tape, it instead has 64 small rolls of 9 meters each, with 1.6-cm wide tape on each roll, divided into 8 channels per roll. The tape speed is 5 m/s. To read a particular roll, the carousel rotates so the desired roll ends up at the bottom. A counterweight sits at the free end of the tape, and facilitates the roll in moving out and down into a mechanism with a read-and-write head. The tape is then rewound. The <b>average</b> <b>seek</b> <b>time</b> is 2 seconds and the storage space is 2560 kilobytes. The control system is operated by transistors. Both the carousel and individual spools are replicable.|$|E
5000|$|This {{resulted}} in a superfloppy disk that had all of the 3.5-inch floppy's convenience, but held much more data, with performance that was much improved over a standard floppy drive (though not directly competitive with hard disk drives). However, Zip disk housings were much thicker than those of floppy disks. The original Zip drive had a maximum data transfer rate of about 1 megabyte/second (comparable to 6× CD-R; although some connection methods were slower, down to approximately 50 kB/second for maximum-compatibility parallel [...] "nibble" [...] mode) and a seek time of 28 milliseconds on average, compared to a standard 1.44 MB floppy's typical 500 kbit/s (62.5 kB/s) transfer rate and several-hundred-millisecond <b>average</b> <b>seek</b> <b>time.</b> Typical desktop hard disk drives from mid-to-late 1990s revolved at 5400 rpm and had transfer rates from 3 MB/s to 10 MB/s or more, and average seek times from 20 ms to 14 ms or less.|$|E
50|$|With SSDs {{there are}} no moving parts, so a {{measurement}} of the <b>seek</b> <b>time</b> is only testing electronic circuits preparing a particular location on the memory in the storage device. Typical SSDs will have a <b>seek</b> <b>time</b> between 0.08 and 0.16 ms.|$|R
40|$|Since {{the time}} movable head disk came into existence, the I/O {{performance}} has been improved by proper scheduling of disk accesses. Disk scheduling involves a careful examination of pending requests {{to determine the}} most efficient way to service the requests. The two most common types of scheduling are seek optimization and rotational (or latency) optimization. Most of the scheduling algorithms concentrate on reducing <b>seek</b> <b>times</b> for a set of requests, because <b>seek</b> <b>times</b> tend to be an order of magnitude greater than latency times. Some of the most important scheduling algorithms are First-Come-First-Served (FCFS), Shortest <b>Seek</b> <b>Time</b> First (SSTF), SCAN, Circular Scan (C-SCAN) and LOOK. FCFS is the simplest form of disk scheduling algorithm. This algorithm is simple to implement, but it generally does not provide the fastest service. This paper describes an improvement in FCFS. A simulator program has been designed and tested the improved FCFS. After improvement in FCFS it has been found that the service is fast and <b>seek</b> <b>time</b> has been reduced drastically...|$|R
5000|$|<b>Seek</b> <b>time</b> - Time {{needed to}} move the head to a new {{position}} (specific track).|$|R
50|$|The {{magneto-optical}} drive manufactured by Canon Inc. {{was used as}} the primary mass storage device. These drives were relatively new to the market, and the NeXT was the first computer to use them. They were cheaper than hard drives (blank media especially so: though each had a cost of $150 to Canon, Jobs's typically forthright negotiations saw Canon agree to a retail of only $50 apiece) but slower (with an <b>average</b> <b>seek</b> <b>time</b> of 96 ms). The design made it impossible to move files between computers without a network, since each NeXT Computer had only one MO drive and the disk could not be removed without shutting down the system. Storage options proved challenging for the first NeXT Computers. The magneto-optical media was relatively expensive and had performance and reliability problems despite being faster than a floppy drive. The drive was not sufficient to run as the primary medium running the NeXTSTEP operating system both in terms of speed and capacity.|$|E
5000|$|On a DOS 3.x disk, tracks 0, 1, {{and most}} of track 2 were {{reserved}} to store the operating system. (It was possible, with a special utility, to reclaim most of this space for data if a disk {{did not need to}} be bootable.) A short ROM program on the disk controller had the ability to seek to track zero - which it did without regard for the read/write head's current position, resulting in the characteristic [...] "chattering" [...] sound of a Disk II boot, which was the read/write head hitting the rubber stop block at the end of the rail - and read and execute code from sector 0. The code contained in there would then pull in the rest of the operating system. DOS stored the disk's directory on track 17, smack in the middle of the 35-track disks, in order to reduce the <b>average</b> <b>seek</b> <b>time</b> to the frequently used directory track. The directory was fixed in size and could hold a maximum of 105 files. Subdirectories were not supported.|$|E
40|$|Management of disk {{scheduling}} is a {{very important}} aspect of operating system. Performance of the disk scheduling completely depends on how efficient is the scheduling algorithm to allocate services to the request in a better manner. Many algorithms (FIFO, SSTF, SCAN, C-SCAN, LOOK, etc.) are developed in the recent years in order to optimize the system disk I/O performance. By reducing the <b>average</b> <b>seek</b> <b>time</b> and transfer time, we can improve the performance of disk I/O operation. In our proposed algorithm, Optimize Disk Scheduling Algorithm (ODSA) is taking less <b>average</b> <b>seek</b> <b>time</b> and transfer time as compare to other disk scheduling algorithms (FIFO, SSTF, SCAN, C-SCAN, LOOK, etc.), which enhances the efficiency of the disk performance in a better manner. Comment: 8 pages, 26 figure...|$|E
50|$|Anti-starvation {{techniques}} {{can be applied}} to the shortest <b>seek</b> <b>time</b> first algorithm to guarantee an optimum response time.|$|R
5000|$|... 4× CD-ROM drive using no {{more than}} 40% of CPU to read, with < 250 ms <b>seek</b> <b>time</b> ...|$|R
40|$|Reducing access {{times to}} {{secondary}} I/O devices {{has long been}} the focus of many systems researchers. With traditional disk drives, access time is the composition of <b>seek</b> <b>time</b> and rotational latency, and so many techniques to order I/O requests or place data to minimize these factors have been developed. MEMS-based storage devices are seen by many as a replacement or an augmentation for modern disk drives, but algorithms for reducing access time for MEMS-based devices are still poorly understood. These devices, based on MicroElectroMechanical systems (MEMS), use thousands of active read/write heads working in parallel on a two-dimensional non-rotating magnetic substrate, eliminating rotational latency variable from the access time equation. This leaves <b>seek</b> <b>time</b> as the dominant variable. Therefore, new data layout techniques based on minimizing the unique <b>seek</b> <b>time</b> characteristics of a MEMS-based storage device must be developed. This paper examines the qualities of a MEMS-based storage device, and based on experimental simulation, develops an understanding of the <b>seek</b> <b>time</b> characteristics on such a device. These characteristics then allow us to identify equivalent regions in which to place data for improved access. ...|$|R
