29|1|Public
50|$|Soundproofing is {{any means}} of {{reducing}} the sound pressure {{with respect to a}} specified sound source and receptor. There are several basic approaches to reducing sound: increasing the distance between source and receiver, using noise barriers to reflect or absorb the energy of the sound waves, using damping structures such as sound baffles, or using active <b>antinoise</b> sound generators.|$|E
50|$|In telecommunication, {{de-emphasis}} is the {{complement of}} pre-emphasis, in the <b>antinoise</b> system called emphasis. De-emphasis {{is a system}} process designed to decrease, (within a band of frequencies), the magnitude of some (usually higher) frequencies {{with respect to the}} magnitude of other (usually lower) frequencies in order to improve the overall signal-to-noise ratio by minimizing the adverse effects of such phenomena as attenuation distortion or saturation of recording media in subsequent parts of the system.|$|E
40|$|The {{effects of}} {{aerodynamic}} actions acting on <b>antinoise</b> barriers produced in proximity to high-speed trains are considered. Because of certain accidents noticed {{on the german}} high-speed railway, {{the problem has been}} developed. A mathematical model has been carried out for specific typologies of barriers. The input applied to this model is represented by the Time History furnished by the technical supplemental and temporary prescriptions for the <b>antinoise</b> barriers design. A critical analysis of the results has been conducted...|$|E
40|$|A large {{class of}} {{acoustic}} noise sources has an underlying periodic process that generates a periodic noise component, and thus their acoustic noise can in general be modeled as {{the sum of}} a periodic signal and a randomly fluctuating signal (usually a broadband background noise). Active control of periodic noise (i. e., for a mixture of sinusoids) {{is more effective than}} that of random noise. For mixtures of sinusoids in a background broadband random noise, conventional FXLMS-based single filter method does not reach the maximum achievable Noise Attenuation Level (NALmax⁡). In this paper, an alternative approach is taken and the idea of a parallel active noise control (ANC) architecture for cancelling mixtures of periodic and random signals is presented. The proposed ANC system separates the noise into periodic and random components and generates corresponding <b>antinoises</b> via separate noise cancelling filters, and tends to reach NALmax⁡ consistently. The derivation of NALmax⁡ is presented. Both the separation and noise cancellation are based on adaptive filtering. Experimental results verify the analytical development by showing superior performance of the proposed method, over the single-filter approach, for several cases of sinusoids in white noise...|$|R
40|$|Multiscale {{distance}} coherence vector algorithm for content-based image retrieval (CBIR) {{is proposed}} {{due to the}} same descriptor with different shapes and the shortcomings of <b>antinoise</b> performance of the distance coherence vector algorithm. By this algorithm, the image contour curve is evolved by Gaussian function first, and then the distance coherence vector is, respectively, extracted from the contour of the original image and evolved images. Multiscale distance coherence vector was obtained by reasonable weight distribution of the distance coherence vectors of evolved images contour. This algorithm not only is invariable to translation, rotation, and scaling transformation but also has good performance of <b>antinoise.</b> The experiment results show us that the algorithm has a higher recall rate and precision rate for the retrieval of images polluted by noise...|$|E
40|$|This paper {{presents}} a new audio signal enhancement method based on reflection signal detection in the reverberant environment. This technique enhances the audio {{signal from the}} target sound source in time domain. The advantages of this technique are enhancing the target sound source by a simple algorithm and reducing the background noise effectively. The effects of distances between the speaker and microphone and the coefficient of correlation are discussed in this paper. The coefficient of correlation is rising from 0. 17 to 0. 63 as {{the distance between the}} speaker and microphone is varying from 30 to 90 [*]cm. Also, some <b>antinoise</b> experiments are carried out in this study and the results show that the audio enhancement algorithm provides a good <b>antinoise</b> performance in different background noise levels...|$|E
40|$|In {{this thesis}} is {{elaborated}} a complex documentation {{for a new}} sports and relaxation complex. Project accentuates on dispositional and architectural design with emphasis on technical solution. Valuation of static, <b>antinoise</b> protection, energy saving and safety of construction using {{is part of the}} project. Heft of the thesis is designed by AutoCAD software application...|$|E
40|$|In this study, a novel {{algorithm}} is proposed to solve poor performance problems of Tent Chaos-based Phase Modulation (CBPM) signal for range-Doppler imaging which take it into complex multi-segment system by increasing its segments. Simulation results show the effectiveness of <b>antinoise</b> performances of the proposed improving algorithm in a noise environment and {{it will have a}} good prospect in the high-resolution imaging radar...|$|E
40|$|Image {{segmentation}} {{plays an}} important role in medical image processing. Fuzzy c-means (FCM) clustering is one of the popular clustering algorithms for medical image segmentation. However, FCM has the problems of depending on initial clustering centers, falling into local optimal solution easily, and sensitivity to noise disturbance. To solve these problems, this paper proposes a hybrid artificial fish swarm algorithm (HAFSA). The proposed algorithm combines artificial fish swarm algorithm (AFSA) with FCM whose advantages of global optimization searching and parallel computing ability of AFSA are utilized to find a superior result. Meanwhile, Metropolis criterion and noise reduction mechanism are introduced to AFSA for enhancing the convergence rate and <b>antinoise</b> ability. The artificial grid graph and Magnetic Resonance Imaging (MRI) are used in the experiments, and the experimental results show that the proposed algorithm has stronger <b>antinoise</b> ability and higher precision. A number of evaluation indicators also demonstrate that the effect of HAFSA is more excellent than FCM and suppressed FCM (SFCM) ...|$|E
40|$|This Bachelor Thesis {{studies the}} Noise Pollution Issue in the {{surrounding}} of a Bull Farm. In Theoretical Part there are explained the basic noise concepts, its circumscription, sources, effects on Human health and basic prevention and <b>antinoise</b> protective agents. There is a brief introduction of the examined Farm and Livestock as well. In Practical Part there are indicated measurement procedures, their subsequent evaluation and assessment according to relevant standards and regulations...|$|E
40|$|Sampling and {{reconstruction}} techniques are {{of special interest}} and importance in ghost imaging. Up to now, the transverse correlation scale of measurement matrices are usually constant. This paper explores a new possibility of constructing highly efficient measurement matrices with multi-correlation scales. Comparisons between the simulational and experimental {{results show that the}} multi-correlation-scale measurement matrices are highly efficient and accurate in sampling and image reconstruction and have a better <b>antinoise</b> ability than the existing constant-correlation-scale measurement matrices. (C) 2014 Optical Society of Americ...|$|E
40|$|This paper {{introduces}} the fractal theory {{into the study}} of flame stability, and presents a method of image segmentation based on fractal feature. Application of this methods successfully segment flame targets from the background, the he adaptability of this means is extensive and <b>antinoise</b> performance is strong. At the same time, some experiments show besides some conventional image characteristic parameters, fractal dimension is also one kind of image feature, which can reflect the combustion state, and be used to diagnose the flame stability. link_to_subscribed_fulltex...|$|E
30|$|The {{problems}} of acoustic noise have received much attention {{during the past}} several decades. Traditionally, acoustic noise control uses passive techniques such as enclosures, barriers, and silencers to attenuate the undesired noise [1, 2]. These passive techniques are highly valued for their high attenuation over a broad range of frequency. However, they are relatively large in volume, expensive at cost, and ineffective at low frequencies. It has been shown that the active noise control (ANC) system [3 – 14] can efficiently achieve a good performance for attenuating low-frequency noise as compared to passive methods. Based on the principle of superposition, ANC system can cancel the primary (undesired) noise by generating an <b>antinoise</b> of equal amplitude and opposite phase.|$|E
40|$|Estimation of {{spatially}} varying permeability {{within the}} two-phase porous media flow {{plays an important}} role in reservoir simulation. Usually, one needs to estimate a large number of permeability values from a limited number of observations, so the computational cost is very high even for a single field-model. This paper applies a nonlinear multigrid method to estimate the permeability field within the two-phase porous media flow. Numerical examples are provided to illustrate the feasibility and effectiveness of the proposed estimation method. In comparison with other existing methods, the most outstanding advantage of this method is the computational efficiency, computational accuracy, and <b>antinoise</b> ability. The proposed method has a potential applicability to a variety of parameter estimation problems...|$|E
40|$|A local active {{noise control}} method that uses {{stochastic}} numerical acoustical modeling is introduced. The frequency domain acoustical simulations are performed by a sequence solutions to Helmholtz equations approximated by FEM. The proposed ANC method maps microphone measurements linearly to the output signals of <b>antinoise</b> actuators. The matrix defining the linear mapping is optimized for each frequency to minimize expected value of the noise. The paper concentrates on defining the quadratic least-squares optimization problem for the minimization of the sound pressure field in the silet region. The formulation leads to a robust and accurate noise control in stochastic domains that has a stochastic noise source. The method is demonstrated numerically by an experiment in a car cabin, and significant noise reduction is demonstrated at lower frequencies...|$|E
40|$|Optical {{computed}} tomography technique {{has been widely}} used in pathological diagnosis and clinical medicine. For most of optical {{computed tomography}} algorithms, the relaxation factor plays {{a very important role}} in the quality of the reconstruction image. In this paper, the optimal relaxation factors of the ART, MART, and SART algorithms for bimodal asymmetrical and three-peak asymmetrical tested images are analyzed and discussed. Furthermore, the reconstructions with Gaussian noise are also considered to evaluate the <b>antinoise</b> ability of the above three algorithms. The numerical simulation results show that the reconstruction errors and the optimal relaxation factors are greatly influenced by the Gaussian noise. This research will provide a good theoretical foundation and reference value for pathological diagnosis, especially for ophthalmic, dental, breast, cardiovascular, and gastrointestinal diseases...|$|E
40|$|Pupil phase {{diversity}} (PPD) wavefront sensor is a {{new kind}} of phase-visualization methods, and the output signal of PPD represents the input pupil phase and shows a 1 - 1 mapping between the position of the wavefront error in the pupil and its position in the output signal. High-precisely wavefront measuring can be obtained under no noise by using appropriate phase restoration algorithm while performance of PPD under noise is unknown. We analyzed <b>antinoise</b> performance of PPD based on genetic algorithm (GA) through measuring the distorted wavefront under different noise level. Simulation results show that wavefront measuring is almost not affected by the existence of noise, which indicates that PPD based on GA can be used in applications with noise...|$|E
40|$|To {{avoid the}} false results of {{deterministic}} identification methods induced by uncertainties, a fuzzy nearness-based method is {{proposed for the}} damage identification of bridge. An improved index based on ratios of modal shape components is used as identification measurements. The knowledge base for damage identification is established through corresponding relationship between fuzzified measurements and damage severities. The damage condition of test samples can be assessed based on approaching principle through fuzzy nearness with rules in knowledge base. A numerical analysis on a multigirder bridge considering uncertainty is presented to demonstrate {{the effectiveness of the}} proposed method. The results indicate that the fuzzy nearness-based method can achieve an accurate identification with success rate up to 93. 75 %. <b>Antinoise</b> analysis and the ability for dealing with incomplete information reveal its robustness...|$|E
30|$|As can be {{seen from}} Fig.  3, the use of this method for image segmentation, the {{performance}} of <b>antinoise</b> in different scenes is different. The results of Fig.  3 show that this method is effective for street segmentation with less construction vehicles and scenery. For example, the details of the building (upper left in Fig.  3) can be well recognized. However, for the trees in the street and indoor scenes, there is poor segmentation (top and bottom right in Fig.  3). The main {{reason for this is that}} the light in the trees and the indoor environment is dark, and the boundary is not as good as the street under the strong light. At the same time, because the shape of the building and vehicle is large, the contour boundary is clear, especially the building, and there are special signs between the boundaries.|$|E
40|$|Based on the Biot model, we {{performed}} the inversion of reservoir parameters with improved niche ant colony algorithms (INACA). In order {{to overcome the}} premature problem of inverse process, the improved niche ant colony algorithms are constructed by combining the fitness-sharing principle {{which is one of}} the niche methods with the ant colony algorithm. The numerical results indicate that the relative error of single parameter inversion can be maintained at less than 0. 4 percent; particulary, the relative error of porosity is less than 0. 02 percent. However, the inversion effect of two-parameter inversion was found to be slightly weak, but the relative error can still be maintained at less than 7. 5 percent. Moreover, the <b>antinoise</b> property of the method was also verified. The results of numerical simulation demonstrate that the method is an effective convergent optimization method...|$|E
40|$|Image {{segmentation}} {{plays an}} important role in medical image processing. Fuzzy c-means (FCM) is one of the popular clustering algorithms for medical image segmentation. But FCM is highly vulnerable to noise due to not considering the spatial information in image segmentation. This paper introduces medium mathematics system which is employed to process fuzzy information for image segmentation. It establishes the medium similarity measure based on the measure of medium truth degree (MMTD) and uses the correlation of the pixel and its neighbors to define the medium membership function. An improved FCM medical image segmentation algorithm based on MMTD which takes some spatial features into account is proposed in this paper. The experimental results show that the proposed algorithm is more <b>antinoise</b> than the standard FCM, with more certainty and less fuzziness. This will lead to its practicable and effective applications in medical image segmentation...|$|E
40|$|This paper {{proposed}} a fault line voting selection method based on atomic sparse decomposition (ASD) and extreme learning machine (ELM). Firstly, it adopted ASD algorithm to decompose zero sequence current of every feeder line at first two cycles and selected {{the first four}} atoms to construct main component atom library, fundamental atom library, and transient characteristic atom libraries 1 and 2, respectively. And it used information entropy theory to calculate the atom libraries; the measure values of information entropy are got. It constructed four ELM networks to train and test atom sample and then obtained every network accuracy. At last, it combined the ELM network output and confidence degree to vote and then compared the vote number to achieve fault line selection (FLS). Simulation experiment illustrated that the method accuracy is 100 %, it is not affected by fault distance and transition resistance, and it has strong ability of <b>antinoise</b> interference...|$|E
40|$|This paper {{concerns}} {{the problems of}} huge data and off-grid effect of cross-track direction in downward-looking linear array (DLLA) 3 D SAR imaging. Since the 3 D imaging needs {{a great deal of}} memory space, we consider the methods of downsampling to reduce the data quantity. In the azimuth direction, we proposed a method based on the multiple measurement vectors (MMV) model, which can enhance computational efficiency and elevate the performance of <b>antinoise,</b> to recover the signal. Further, in cross-track direction, since the resolution is restricted by the length of array, as well as platform size, the influence of off-grid effect is more serious than azimuth direction. Continuous compressive sensing (CCS), which can solve the off-grid effect of the classical compressive sensing (CS), is presented to obtain the precise imaging result under the noise scenarios. Finally, we validate our method by extension numerical experiments...|$|E
40|$|Active {{noise control}} {{is based on}} the {{destructive}} interference between the primary noise and generated noise from the secondary source. An <b>antinoise</b> of equal amplitude and opposite phase is generated and combined with the primary noise. In this paper, performance of the neural networks is evaluated in active cancellation of sound noise. For this reason, feedforward and recurrent neural networks are designed and trained. After training, performance of the feedforwrad and recurrent networks in noise attenuation are compared. We use Elman network as a recurrent neural network. For simulations, noise signals from a SPIB database are used. In order to compare the networks appropriately, equal number of layers and neurons are considered for the networks. Moreover, training and test samples are similar. Simulation results show that feedforward and recurrent neural networks present good performance in noise cancellation. As it is seen, the ability of recurrent neural network in noise attenuation is better than feedforward network...|$|E
40|$|Text {{classification}} {{has always}} been an interesting issue in the research area of natural language processing (NLP). While entering the era of big data, a good text classifier is critical to achieving NLP for scientific big data analytics. With the ever-increasing size of text data, it has posed important challenges in developing effective algorithm for text classification. Given the success of deep neural network (DNN) in analyzing big data, this article proposes a novel text classifier using DNN, in an effort to improve the computational performance of addressing big text data with hybrid outliers. Specifically, through the use of denoising autoencoder (DAE) and restricted Boltzmann machine (RBM), our proposed method, named denoising deep neural network (DDNN), is able to achieve significant improvement with better performance of <b>antinoise</b> and feature extraction, compared to the traditional text classification algorithms. The simulations on benchmark datasets verify the effectiveness and robustness of our proposed text classifier...|$|E
40|$|Sound {{absorption}} {{and optical}} transparency {{are among the}} most useful properties of noise barriers. While the latter is required to reduce visual impact and for aesthetical reasons, the former is required whenever conditions of multiple reflections and presence of close, high receivers occur. The technical feasibility of a transparent, sound-absorbing panel for outdoor <b>antinoise</b> devices is investigated in this paper. An analysis of acoustical performance of multiple perforated plates is performed employing an existing theory for microperforated absorbers under normal incidence and diffused sound field. An optimization of the geometrical parameters is carried out {{on the basis of the}} European classification criteria of noise barriers for roadways. An optimized three-layer configuration can achieve sound-absorption properties similar to nontransparent products with only a limited loss of visual transparency and appropriate mechanical strength. Experimental data obtained with an impedance tube on small test samples made of transparent polycarbonate and in a reverberation room on full-scale prototypes are reported, showing a rather good agreement with the theoretical predictions. The optical performance of a multilayered configuration is evaluated also...|$|E
40|$|With the {{development}} of national information processes, specific image information from secret departments or individuals is often required to be confidentially transmitted. Numerous image encryption methods exist, especially since the initial value sensitivity and other characteristics of chaos theory and chaos theory-based encryption have become increasingly important in recent years. At present, DNA coding constitutes a new research direction of image encryption that uses the four base pairs of DNA code and image pixel values to establish a special correspondence, {{in order to achieve}} pixel diffusion. There are eight DNA encoding rules, and current methods of selecting the DNA encoding rules are largely fixed. Thus, the security of encoded data is not high. In this paper, we use the Lorenz chaotic system, Chen’s hyperchaotic system, and the DNA encoding combination and present a new image encryption algorithm that can dynamically select eight types of DNA encoding rules and eight types of DNA addition and subtraction rules, with significant improvements in security. Through simulation experiments and histograms, correlations, and NPCR analyses, we have determined that the algorithm possesses numerous desirable features, including good encryption effects and antishear and <b>antinoise</b> performances...|$|E
40|$|New {{medical imaging}} technology, such as Computed Tomography and Magnetic Resonance Imaging (MRI), {{has been widely}} used {{in all aspects of}} medical diagnosis. The purpose of these imaging {{techniques}} is to obtain various qualitative and quantitative data of the patient comprehensively and accurately, and provide correct digital information for diagnosis, treatment planning and evaluation after surgery. MR has a good imaging diagnostic advantage for brain diseases. However, as the requirements of the brain image definition and quantitative analysis are always increasing, it is necessary to have better segmentation of MR brain images. The FCM (Fuzzy C-means) algorithm is widely applied in image segmentation, but it has some shortcomings, such as long computation time and poor anti-noise capability. In this paper, firstly, the Ant Colony algorithm is used to determine the cluster centers and the number of FCM algorithm so as to improve its running speed. Then an improved Markov random field model is used to improve the algorithm, so that its <b>antinoise</b> ability can be improved. Experimental results show that the algorithm put forward in this paper has obvious advantages in image segmentation speed and segmentation effect...|$|E
40|$|Xiaoqi He, 1 Zizhao Zheng, 1, 2 Chao Hu 1 1 Ningbo Institute of Technology, Zhejiang University, Ningbo, People&# 39;s Republic of China; 2 Taiyuan University of Science and Technology, Taiyuan, People&# 39;s Republic of China Abstract: The {{development}} of the capsule endoscope has made possible {{the examination of the}} whole gastrointestinal tract without much pain. However, there are still some important problems to be solved, among which, one important problem is the localization of the capsule. Currently, magnetic positioning technology is a suitable method for capsule localization, and this depends on a reliable system and algorithm. In this paper, based on the magnetic dipole model as well as magnetic sensor array, we propose nonlinear optimization algorithms using a random complex algorithm, applied to the optimization calculation for the nonlinear function of the dipole, to determine the three-dimensional position parameters and two-dimensional direction parameters. The stability and the <b>antinoise</b> ability of the algorithm is compared with the Levenberg–Marquart algorithm. The simulation and experiment results show that in terms of the error level of the initial guess of magnet location, the random complex algorithm is more accurate, more stable, and has a higher “denoise” capacity, with a larger range for initial guess values. Keywords: wireless capsule endoscope, magnet, optimization ...|$|E
40|$|The {{phenomenon}} {{of climate change}} has had widespread impacts on the climatic and ecological setup of the globe ranging from rapid melting of polar ice caps to startling changes in weather patterns around the planet. From a hydrological standpoint, climate change has had a pronounced impacts on precipitation patterns which has posed a mammoth challenge for the water dependent infrastructures such as domestic water supply systems, storm water drainage systems and the hydropower industries across the globe. This project aims to add and to strengthen the findings of previous works {{carried out in the}} fields of flood frequency analysis and hydrological regimes in a future climatic setup in central Norway. Discerning the future flood patterns in select catchments of central Norway can provide valuable information and insight for decision makers and planners to evaluate and if necessary, modify the existing design of key protective infrastructures such dams, culverts and storm water drainage systems. Furthermore, the findings of the project could help hydropower planners in designing modifications to the existing reservoir operation and power production schemes to cope with the changes imparted to the natural hydrological regime by climate change. Also, the project aims to work towards discerning possible changes to flow regimes in the region which can validate and also strengthen the findings of earlier works. The project aims at understanding the changes imparted to the natural hydrological regimes in select catchments of central Norway such as Hagabru, Krinsvatn and Svartjonbekken. The chosen catchments represent variability in size, hypsography and distance from the coast and these parameters greatly influence the hydrological regime features of these catchments such as precipitation pattern, snow melt features, seasonality and also influence flow response characteristics. Upon investigation of the retrieved historical observed discharge time series for these catchments, it was evident that climate change impacts on the annual natural flow regime were already observable. Further, the process of hydrological model calibration for these catchments provided an insight into the complexities in model calibration for the purpose of flood frequency analysis as the project findings showed that a hydrological model calibrated to obtain a general good fit for water balance underperformed when employed for the purpose of flood frequency analysis and vice-versa. The process of climate data downscaling was particularly challenging and initial analysis revealed that the GCM simulated temperature time series exhibited a high degree of correspondence with the observed temperature time series. But, the GCM simulated precipitation data had a poor correspondence with the observed data which necessitated implementation of a downscaling technique. A new method of precipitation downscaling was devised termed <b>Antinoise</b> Downscaling which helped correct systematic biases within the GCM simulated precipitation data series. Finally, the calibrated hydrological models for the various catchments were employed to simulate flow regimes in a future time period (2051 - 2099) to get an insight into the possible ramifications to the natural flow regimes in the catchments with the downscaled GCM precipitation and temperature data series as input. The results of the investigation revealed that the stream flow pattern would be strongly influenced with exponential reduction in spring flood peak magnitudes. A more evenly distributed flow volumes were observed and also, significant reduction in the amount of available snow cover was observed. A new methodology was implemented for the purpose of analysis of the changes imparted to the flow regimes termed Flow Regime Modification Indices. Flood frequency analysis was carried out over the historical observation period and also over the future simulation period. The results obtained suggested that the flood magnitudes of respective return periods would be reduced in the future simulation period in all the modeled catchments on an annual basis and also as spring floods...|$|E

