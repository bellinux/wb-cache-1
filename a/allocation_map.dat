34|104|Public
25|$|Storage space {{allocated}} to a database {{is divided into}} sequentially numbered pages, each 8KB in size. A page is the basic unit of I/O for SQL Server operations. A page is marked with a 96-byte header which stores metadata about the page including the page number, page type, free space on the page and the ID of the object that owns it. Page type defines the data contained in the page: data stored in the database, index, <b>allocation</b> <b>map</b> which holds information about how pages are {{allocated to}} tables and indexes, change map which holds information about the changes made to other pages since last backup or logging, or contain large data types such as image or text. While page is the basic unit of an I/O operation, space is actually managed {{in terms of an}} extent which consists of 8 pages. A database object can either span all 8 pages in an extent ("uniform extent") or share an extent with up to 7 more objects ("mixed extent"). A row in a database table cannot span more than one page, so is limited to 8KB in size. However, if the data exceeds 8KB and the row contains varchar or varbinary data, the data in those columns are moved to a new page (or possibly a sequence of pages, called an allocation unit) and replaced with a pointer to the data.|$|E
5000|$|When a {{non-resident}} attribute is so fragmented, {{that its}} effective <b>allocation</b> <b>map</b> cannot fit entirely within one MFT record, NTFS stores the attribute in multiple records. The first one {{among them is}} called the base record, while the others are called extension records. NTFS creates a special attribute $ATTRIBUTE_LIST to store information mapping {{different parts of the}} long attribute to the MFT records, which means the <b>allocation</b> <b>map</b> may be split into multiple records. The $ATTRIBUTE_LIST itself can also be non-resident, but its own <b>allocation</b> <b>map</b> must fit within one MFT record.|$|E
5000|$|The {{format of}} the <b>allocation</b> <b>map</b> for {{non-resident}} attributes depends on its capability of supporting sparse data storage. In the current implementation of NTFS, once a non-resident data stream has been marked and converted as sparse, it cannot be changed back to non-sparse data, so it cannot become resident again, unless this data is fully truncated, discarding the sparse <b>allocation</b> <b>map</b> completely.|$|E
40|$|Abstract—In {{the paper}} authors present new concept of {{realization}} of algorithms with regular graphs of information dependencies, {{in form of}} systolic arrays realized in multi-context programmable devices. Processor matrix efficiency depends on both <b>allocation</b> and schedule <b>mapping.</b> Authors use evolution algorithms and constraint programming to determine <b>allocation</b> <b>mapping</b> and optimize runtime of set algorithm. Authors compared the runtime of Cholesky’s algorithm for banded matrices in which the new concept has been used with ones obtained by use of linear and non-linear <b>allocation</b> <b>mapping</b> for processor matrix. I...|$|R
40|$|A spatial {{curdling}} index (C) {{is presented}} for studying income concentration in two-dimensional fields originated by a cascade process, resembling resource <b>allocation</b> <b>maps.</b> Computational simulations of spatial distributions {{show that the}} relation between C and measures of income inequality such as the Gini coefficient (G) forms a concave area. Acknowledgment of this fact brings additional information for formulating geopolitical strategies for income inequality reduction, and for comparison purposes {{in a set of}} countries or across time within a country. With the aim of showing the importance of index C, a prototype of the empirical application is shown based on the Peruvian and Swedish income <b>maps.</b> Resource <b>allocation</b> <b>maps,</b> cascade processes, Gini coefficient...|$|R
30|$|An {{efficient}} protocol which realizes subcarrier-wise {{rate adaptation}} over wireless channels has not previously been proposed, {{due to the}} large overhead caused by the frequent transmission of the feedback information, which is not small. In this paper, we propose a novel rate-adaptive MAC protocol for OFDM-based wireless communication systems. The proposed method provides {{an efficient way to}} implement subcarrier-wise rate adaptation by designing a protocol which has a relatively small feedback overhead associated with the subcarrier state information. The proposed protocol plugs one OFDM symbol into a CTS packet. By utilizing the OFDM symbol and synchronously maintaining the bit <b>allocation</b> <b>maps</b> at both the sender and receiver, it can adaptively change the data rate allocated to each subcarrier. To synchronize the bit <b>allocation</b> <b>maps</b> at both the sender and receiver over an error-prone wireless channel, a detailed error recovery procedure is also proposed.|$|R
50|$|The BAM (Block <b>Allocation</b> <b>Map)</b> {{starts at}} 1/2 (track 1, sector 2) and {{continues}} to 1/33.|$|E
5000|$|Some {{attributes}} (such as {{the preferred}} filename, the basic file attributes) cannot be made non-resident. For non-resident attributes, their <b>allocation</b> <b>map</b> must fit within MFT records.|$|E
5000|$|XFS {{provides}} a 64-bit sparse address space for each file, which allows both for very large file sizes, and for [...] "holes" [...] within files {{in which no}} disk space is allocated. As the file system uses an extent map for each file, the file <b>allocation</b> <b>map</b> size is kept small. Where {{the size of the}} <b>allocation</b> <b>map</b> is too large for it to be stored within the inode, the map is moved into a B+ tree which allows for rapid access to data anywhere in the 64-bit address space provided for the file.|$|E
40|$|A {{theory of}} <b>allocation</b> <b>maps</b> has been {{developed}} by J. F. Feinstein and M. J. Heath {{in order to prove}} a theorem, using Zorn's lemma, concerning the compact plane sets known as Swiss cheese sets. These sets are important since, as domains, they provide a good source of examples in the theory of uniform algebras and rational approximation. In this paper we take a more direct approach when proving their theorem by using transfinite induction and cardinality. An explicit reference to a theory of <b>allocation</b> <b>maps</b> is no longer required. Instead we find that the repeated application of a single operation developed from the final step of the proof by Feinstein and Heath is enough. Comment: 10 pages, 1 figure, Accepted for publication by the Proceedings of the American Mathematical Society, volume 138, year 2010, number 12, pages 4423 - 443...|$|R
40|$|In this paper, {{a static}} <b>allocation</b> (<b>mapping)</b> {{algorithm}} is described which handles periodic, hard real-time controller tasks. Our hybrid approach combines {{the advantages of}} constructive, and non-guided-search methods to overcome the problems of purely constructive, or purely non-guided-search techniques. The new method is motivated by the configuration of a parallel real-time operating system to manage very complex control applications. The goal of the configuration is to reduce OS overhead as much as possible. It is achieved by allocating the controller tasks to the processor network in advance. Following this approach the advantages of special purpose processors (no overhead) and OS driven computers (good utilisation) are combined. Keywords. Parallel Real-Time Operating System, Preconfiguration, <b>Allocation</b> (<b>Mapping).</b> 1 INTRODUCTION Today's complex mechatronic real-time systems, like cars, contain many tens of processors to manage system control, and the number is still increasing. [...] ...|$|R
40|$|In this paper, {{we address}} the control design problem of {{positioning}} of over-actuated marine vehicles with control allocation. The proposed design {{is based on}} a combined position and velocity loops in a multi-variable anti-windup implementation together with a control <b>allocation</b> <b>mapping.</b> The vehicle modelling is considered with appropriate simplifications related to low-speed manoeuvring hydrodynamics and vehicle symmetry. The control design is considered together with a control <b>allocation</b> <b>mapping.</b> We derive analytical tuning rules based on requirements of closed-loop stability and performance. The anti- windup implementation of the controller is obtained by mapping the actuator-force constraint set into a constraint set for the generalized forces. This approach ensures that actuation capacity is not violated by constraining the generalized control forces; thus, the control allocation is simplified since it can be formulated as an unconstrained problem. The mapping can also be modified on-line based on actuator availability to provide actuator-failure accommodation. We provide a proof of the closed-loop stability and illustrate the performance using simulation scenarios for an open-frame underwater vehicle...|$|R
5000|$|In {{computer}} file systems, a block <b>allocation</b> <b>map</b> is a data structure used to track disk blocks {{that are considered}} [...] "in use". Blocks may also {{be referred to as}} allocation units or clusters.|$|E
50|$|The extent {{allocation}} tree {{acts as an}} <b>allocation</b> <b>map</b> for {{the file}} system. Unlike other trees, items in this tree do not have object ids and represent regions of space: their left-hand and right-hand key values are the starting offsets and lengths of the regions they represent.|$|E
5000|$|Typically, {{the first}} {{megabyte}} of each physical volume contains a mostly ASCII-encoded structure {{referred to as}} an [...] "LVM header" [...] or [...] "LVM head". Originally, the LVM head used to be written {{in the first and}} last megabyte of each PV for redundancy (in case of a partial hardware failure); however, this was later changed to only the first megabyte. Each PV's header is a complete copy of the entire volume group's layout, including the UUIDs of all other PVs and of LVs, and <b>allocation</b> <b>map</b> of PEs to LEs. This simplifies data recovery if a PV is lost.|$|E
3000|$|... {{has been}} optimally {{allocated}} across the parameter set. Because our power <b>allocation</b> algorithm <b>maps</b> the average power parameter [...]...|$|R
40|$|This article {{presents}} and evaluates the Slack Method, a new constructive heuristic for the <b>allocation</b> (<b>mapping)</b> of periodic hard real-time tasks to multiprocessor or distributed systems. The Slack Method {{is based on}} task deadlines, in contrast with other constructive heuristics, such as List Processing. The presented evaluation shows that the Slack Method is superior to list-processing-based approaches with regard to both finding more feasible solutions as well as finding solutions with better objective function values...|$|R
50|$|HFS Plus is an {{improved}} version of HFS, supporting much larger files (block addresses are 32-bit length instead of 16-bit) and using Unicode (instead of Mac OS Roman {{or any of}} several other character sets) for naming items. Like HFS, HFS Plus uses B-trees to store most volume metadata, but unlike most other file systems, HFS Plus supports hard links to directories. HFS Plus permits filenames up to 255 characters in length, and n-forked files similar to NTFS, though until 2005 almost no system software took advantage of forks other than the data fork and resource fork. HFS Plus also uses a full 32-bit <b>allocation</b> <b>mapping</b> table rather than HFS's 16 bits, significantly improving space utilization with large disks.|$|R
50|$|The <b>allocation</b> <b>map</b> {{is stored}} in a form of data runs with {{compressed}} encoding. Each data run represents a contiguous group of clusters that store the attribute value. For files on a multi-GB volume, each entry can be encoded as 5 to 7 bytes, which means a 1 KB MFT record can store about 100 such data runs. However, as the $ATTRIBUTE_LIST also has a size limit, it is dangerous {{to have more than}} 1 million fragments of a single file on an NTFS volume, which also implies that it is in general {{not a good idea to}} use NTFS compression on a file larger than 10 GB.|$|E
5000|$|CP/M used a block <b>allocation</b> <b>map</b> in its {{directory}}. Each {{directory entry}} could list 8 or 16 blocks (depending on disk format) that were allocated to a file. If a file used more blocks, additional directory entries would be needed. Thus, a single file could have multiple directory entries. A benefit {{of this method}} is the possibility to use sparse files by declaring a large file size but only allocating blocks that are actually used. [...] A detriment of this method is the disk may have free space (unallocated blocks) but data cannot be appended to a file because all directory entries are used.|$|E
5000|$|To {{optimize}} the storage {{and reduce the}} I/O overhead for the very common case of attributes with very small associated value, NTFS prefers to place the value within the attribute itself (if {{the size of the}} attribute does not then exceed the maximum size of an MFT record), instead of using the MFT record space to list clusters containing the data; in that case, the attribute will not store the data directly but will just store an <b>allocation</b> <b>map</b> (in the form of data runs) pointing to the actual data stored elsewhere on the volume. When the value can be accessed directly from within the attribute, it is called [...] "resident data" [...] (by computer forensics workers). The amount of data that fits is highly dependent on the file's characteristics, but 700 to 800 bytes is common in single-stream files with non-lengthy filenames and no ACLs.|$|E
3000|$|Let P(h) {{represent}} the optimal power <b>allocation</b> strategy which <b>maps</b> the channel realization h to a power level in [...]...|$|R
40|$|AbstractCensus 2011 marked {{erstwhile}} Andhra Pradesh as {{the second}} largest and fifth most populous state of India housing 7 % of its total population. In 2014, it was divided into the two states of Telangana and Andhra Pradesh {{on the basis of}} disparities in resource <b>allocation.</b> <b>Mapping</b> regional disparities can aid in effective policy-making at the preliminary stage of planning itself. This paper aims to study the regional disparities in human development in the case of erstwhile Andhra Pradesh through the tool of graduated colour mapping. Indicators mapped were drawn from the Andhra Pradesh Human Development Report of 2007. The studies reveal that while there is a clear case of polarized growth in the case of Hyderabad and its immediate surroundings, we also find similar trends in the Vizianagaram district, {{as well as in the}} Rayalseema region...|$|R
40|$|This article {{presents}} and evaluates the Slack Method, a new constructive heuristic for the <b>allocation</b> (<b>mapping)</b> of periodic hard realtime tasks to multiprocessor or distributed systems. The Slack Method {{is based on}} task deadlines, in contrast with other constructive heuristics, such as List Processing. The presented evaluation shows that the Slack Method is superior to list-processing-based approaches with regard to both finding more feasible solutions as well as finding solutions with better objective function values. In a comparative survey we evaluate the Slack Method against several alternative allocation techniques. This includes comparisons with optimal algorithms, non-guided search heuristics (e. g. Simulated Annealing), and other constructive heuristics. The main practical result of the comparison is {{that a combination of}} non-guided search and constructive approaches is shown to perform better than either of them alone, especially when using the Slack Method. 1 Introduction Man [...] ...|$|R
50|$|Storage space {{allocated}} to a database {{is divided into}} sequentially numbered pages, each 8 KB in size. A page is the basic unit of I/O for SQL Server operations. A page is marked with a 96-byte header which stores metadata about the page including the page number, page type, free space on the page and the ID of the object that owns it. Page type defines the data contained in the page: data stored in the database, index, <b>allocation</b> <b>map</b> which holds information about how pages are {{allocated to}} tables and indexes, change map which holds information about the changes made to other pages since last backup or logging, or contain large data types such as image or text. While page is the basic unit of an I/O operation, space is actually managed {{in terms of an}} extent which consists of 8 pages. A database object can either span all 8 pages in an extent ("uniform extent") or share an extent with up to 7 more objects ("mixed extent"). A row in a database table cannot span more than one page, so is limited to 8 KB in size. However, if the data exceeds 8 KB and the row contains varchar or varbinary data, the data in those columns are moved to a new page (or possibly a sequence of pages, called an allocation unit) and replaced with a pointer to the data.|$|E
40|$|Abstract — Based on the {{end-to-end}} delay {{experienced by}} the user, this paper derives a spreading factor <b>allocation</b> <b>map</b> for thefourUMTStrafficclassesandforfouruserprofileswiththe help of a computer testbed emulating the UTRAN. Using this <b>allocation</b> <b>map,</b> {{the performance of the}} UTRAN is measured in terms of cell throughput and blocking rate in different scenarios...|$|E
40|$|We {{consider}} a device-To-device scenario in a fragmented spectrum band. Multiple devices transmit complex symbols {{with a single}} antenna on distributed, but disjoint OFDM resources. The devices select sufficient frequency resources to enable channel estimation, if the receiver has complete knowledge of the resource map. However, in this scenario the actual <b>allocation</b> <b>map</b> is unknown to the receiver. Therefore, a receiver observing the superposition of all transmitted signals is faced with two problems, channel estimation and identification of the correct resources <b>allocation</b> <b>map.</b> In our previous work [1], we identified the channel and the <b>allocation</b> <b>map</b> of the corresponding users by applying an objective function based on the â 1 -norm. In this work, we show that successful recovery is possible under different practical ITU channel models...|$|E
40|$|Heterogeneous {{computing}} systems {{composed of}} interconnected machines with varied computational capabilities often operate in environments where {{there may be}} sudden machine failures, higher than expected load, or inaccuracies in estimation of system parameters. Makespan (defined as the completion time for an entire set of tasks) is often the performance feature that is optimized in such systems. It {{is important that the}} makespan of a resource <b>allocation</b> (<b>mapping)</b> be robust against errors in task computation time estimates. The problem of optimally mapping tasks onto machines of a heterogeneous computing environment has been shown, in general, to be NP-complete. Therefore, heuristic techniques to find near optimal solutions to this mapping problem are required. The goal of this research is to find a static mapping of tasks so that the robustness of the desired system feature, makespan, is maximized against the errors in task execution time estimates. Seven heuristics to derive near-optimal solutions and an upper bound to this problem are presented and evaluated...|$|R
40|$|In this paper, {{we address}} the control design problem of {{positioning}} of over-actuated underwater vehicles. The proposed design {{is based on}} a control architecture with combined position and velocity loops and a control tuning method based on the decoupled models. We derive analytical tuning rules based on requirements of closed-loop stability, positioning performance, and the vehicle velocity dynamic characteristics. The vehicle modelling is considered from force to motion with appropriate simplifications related to low-speed manoeuvring hydrodynamics and vehicle symmetry. The control design is considered together with a control <b>allocation</b> <b>mapping.</b> This approach makes the control tuning independent of the characteristics of the force actuators and provides the basis for control reconfiguration in the presence of actuator failure. We propose an anti-wind-up implementation of the controller, which ensures that the constraints related to actuation capacity are not violated. This approach simplifies the control allocation problem since the actuator constraints are mapped into generalised force constraints...|$|R
40|$|We {{develop a}} genetic-based {{approach}} for system-level architecture synthesis for scheduling, <b>allocation,</b> and <b>mapping.</b> Traditional design practices lead to over allocating resources for embedded SoC and, hence, high manufacture cost. The approach determines the scheduling, <b>allocation,</b> and <b>mapping</b> {{for the system}} at every step to find the near optimal solution. Unlike other genetic approach for parallel processing in the literature, a new chromosome encoding is designed to avoid generating invalid system architecture and, hence, {{reduce the number of}} generations to obtain near optimal solutions. In addition, a dynamic allocation probability is designed to reduce cost and run-time overhead. We evaluate our approach with extensive simulations and compare our performance with other approaches in the literature. The results show that our approach increases schedulability up to 80 % and reduces the cost up to 60 % for the tested workload, comparing to earlier approaches. Furthermore, its run-time overhead is still acceptable for complex system design. ...|$|R
40|$|We aim {{to use a}} multi-spatial and {{temporal}} approach to trace people’s livelihoods from a village to a regional level. For this, we accumulated various spatial data and considered the seasonal and inter-annual changes. The principal data was from satellite images, aerial photographs and a crop <b>allocation</b> <b>map</b> determined by field investigation. Our concept of a multi-spatial {{and temporal}} approach was used to integrate the various kinds of data...|$|E
40|$|A laser beam, as {{a source}} of energy, has been lately widely used in {{additive}} technologies for the manufacture of parts for the power engineering industry. One of the promising methods of additive manufacturing based on laser overlay welding of metal wires is the so-called Laser Engineering Net Shape. This work studies the structure and mechanical properties of the sample manufactured using a direct laser alloying unit designed for 07 X 18 H 10 T stainless steel grade alloying. The <b>allocation</b> <b>map</b> of chemical elements has been examined in this work...|$|E
30|$|The H. 264 {{standard}} {{introduces a}} new design concept that enables it to generate self-contained packets without requiring large header fields. To do so, the encoder separates the higher-layer metainformation relevant {{to more than}} one slice from the media stream or video slices. The higher layer information is then delivered to the decoder using a reliable communications mechanism (inband or out of band) before transmitting the stream of video slices. This way it is possible to reduce the header information in each video packet to a codeword that identifies the set of parameters required for decoding the packet. The combination of higher-level parameters is called the parameter set concept (PSC) and usually includes information such as picture size, optional coding modes employed, and MB <b>allocation</b> <b>map.</b>|$|E
50|$|Significant {{achievements}} {{were also}} {{made in the}} reform of the economic system. The new financial system with tax decentralization at its core, and the new tax system with value-added tax as its main component, were set up. Policy finance and commercial finance were gradually separated. A macro regulating system emerged, and the market started to play a more major role in resource <b>allocation.</b> Also <b>mapped</b> out were {{the beginnings of a}} dominant public sector.|$|R
40|$|A co-synthesis {{system is}} presented, which partitions, schedules, and voltage scales {{multi-rate}} system specifications onto heterogeneous architectures containing dynamic voltage scalable processing elements (DVS-PEs). To achieve {{high degree of}} energy reduction, we formulate a generalised DVS problem, taken into account the power variations among the executing tasks. An efficient heuristic is presented, that identifies optimised supply voltages by not only "simply" exploiting slack time, as in previous research, but under the additional consideration of the PE power profiles. Thereby, this algorithm minimises the energy dissipation of heterogeneous architectures, including power managed PEs, effectively. Further, we address the DVS optimisation at different steps of the system synthesis, including <b>allocation,</b> <b>mapping,</b> and scheduling, by integrating the proposed heuristic into the design flow. We demonstrate how genetic list scheduling and mapping algorithms are adapted to the DVS problem to produce simultaneously high quality solutions in terms of energy dissipation and timing behaviour. We investigate and analyse the possible energy reductions at all steps of the co-synthesis, including the power variation effects. Extensive experiments and comparisons with recently proposed DVS techniques, which are included as sub-cases in our generalised DVS approach, indicate that the presented work has advantages in terms of solution quality...|$|R
40|$|Abstract — Mobile WiMAX systems {{based on}} the IEEE 802. 16 e {{standard}} require all downlink <b>allocations</b> to be <b>mapped</b> to a rectangular region in the two dimensional subcarrier-time map. Many published resource allocation schemes ignore this requirement. It {{is possible that the}} <b>allocations</b> when <b>mapped</b> to rectangular regions may exceed the capacity of the downlink frame, and the QoS of some flows may be violated. The rectangle mapping problem is a variation of the bin or strip packing problem, which is known to be NP-complete. In a previous paper, an algorithm called OCSA (One Column Striping with nonincreasing Area first mapping) for rectangular mapping was introduced. In this paper, we propose an enhanced version of the algorithm. Similar to OCSA, the enhanced algorithm is also simple and fast to implement; however, eOCSA considers the allocation of an additional resource to ensure the QoS. eOCSA also avoids an enumeration process and so lowers the complexity to O(n 2) ...|$|R
