15|248|Public
2500|$|Literally, hoo is a {{particle}} {{used to make}} an actualizing verb from the following noun, as would [...] "to" [...] before a noun in English. Here, it creates a verb from the noun pono, which is defined as: [...] "...goodness, uprightness, morality, moral qualities, correct or proper procedure, excellence, well-being, prosperity, welfare, benefit, true condition or nature, duty; moral, fitting, proper, righteous, right, upright, just, virtuous, fair, beneficial, successful, in perfect order, <b>accurate,</b> <b>correct,</b> eased, relieved; should, ought, must, necessary." ...|$|E
5000|$|... nvs. Goodness, uprightness, morality, moral qualities, {{correct or}} proper procedure, excellence, well-being, prosperity, welfare, benefit, behalf, equity, sake, true {{condition}} or nature, duty; moral, fitting, proper, righteous, right, upright, just, virtuous, fair, beneficial, successful, in perfect order, <b>accurate,</b> <b>correct,</b> eased, relieved; should, ought, must, necessary.|$|E
5000|$|Literally, hoo is a {{particle}} {{used to make}} an actualizing verb from the following noun, as would [...] "to" [...] before a noun in English. Here, it creates a verb from the noun pono, which is defined as: [...] "...goodness, uprightness, morality, moral qualities, correct or proper procedure, excellence, well-being, prosperity, welfare, benefit, true condition or nature, duty; moral, fitting, proper, righteous, right, upright, just, virtuous, fair, beneficial, successful, in perfect order, <b>accurate,</b> <b>correct,</b> eased, relieved; should, ought, must, necessary." ...|$|E
50|$|Clear {{seeing is}} the product of <b>accurate</b> sensing and <b>correct</b> perceiving.|$|R
50|$|The 3rd {{printing}} of the Wesleyan edition of Tales of Nevèrÿon {{is currently the}} most <b>accurate</b> and <b>corrects</b> some errors from previous editions that might actually have confused some particularly careful readers of Delany's series.|$|R
5000|$|<b>Accurate</b> - Precise, <b>correct</b> and unambiguous, stating {{what the}} term {{is and is not}} ...|$|R
5000|$|The Voice of America called Oatis [...] "the first American martyr {{to press}} freedom behind the Iron Curtain." [...] The United States Department of State denounced the Czechoslovak verdict as a ludicrous travesty and the U.S. press said Oatis was {{condemned}} {{for no more}} than doing his job as a reporter. The case's Orwellian overtones were highlighted by the prosecution's assertion at the show trial that Oatis, a careful reporter, was [...] "particularly dangerous because of his discretion and insistence on obtaining only <b>accurate,</b> <b>correct,</b> verified information." [...] Oatis contracted tuberculosis during his imprisonment and sought treatment shortly after his release.|$|E
40|$|There is {{no doubt}} at all that {{pronunciation}} {{represents one of the}} most important and inevitable parts in the process of English language teaching, particularly in the case of teaching English to Romanian students. In time, all over the world many linguists have proposed different notions regarding the degrees of accuracy necessary in teaching pronunciation. Thus, in teaching the pronunciation of a language there should always be taken into account the learners’ objectives, in other words the class objectives. In this way, if the main objectives are to learn English and to use it in every day situations they should learn an <b>accurate,</b> <b>correct</b> and authentic pronunciation; if there is used mainly written communication, though, there is no obligation to strive for perfect pronunciation, although we do not encourage this option either...|$|E
40|$|The article {{analyzes}} {{the relevance of}} the research topics, defines goals and objectives, subject and object of research. On the basis of the literature analysis, the following eduction was made: not all the test methods in road and agricultural vehicles (tractors) contribute to the effective implementation of the requirements of normative documents including international, inter-laboratory comparative tests. The approach in laboratory testing to the synthesis adaptive system of metrological assurance the use of fuzzy logic is proposed. These labs conduct testing of automotive and tractor equipment. The decision is under risk. The scheme of metrological assurance system covers all parties to ensure the necessary accuracy of measurements and tests; the necessary normative-technical documentation is provided; availability of measuring instruments and test equipment, standards and reference measures; availability of qualified personnel; the assurance that test results are <b>accurate</b> (<b>correct</b> and precision); provides effective decisions based on objective information...|$|E
5000|$|However, {{this system}} also {{requires}} the missile {{to have a}} fixed roll-axis orientation. If the missile spins at all, the timing based on the speed of rotation of the mirror is no longer <b>accurate.</b> <b>Correcting</b> for this spin would normally require some sort of sensor to tell which way is [...] "down" [...] and then adding controls to correct it. Instead, small control surfaces were placed {{at the rear of}} the missile with spinning disks on their outer surface; these are known as rollerons. Airflow over the disk spins them to a high speed. If the missile starts to roll, the gyroscopic force of the disk drives the control surface into the airflow, cancelling the motion. Thus the Sidewinder team replaced a potentially complex control system with a simple mechanical solution.|$|R
30|$|This {{research}} {{provides a}} pathway towards <b>accurate</b> and <b>correct</b> diagnosis of frozen shoulder. The {{objective of this}} research is to develop reliable method for frozen shoulder. First milestone is to collect questionnaire from work related and chronic disease patients. Then on the basis of questionnaire and physical examination reports, we develop model which detect frozen shoulder category.|$|R
40|$|To {{select a}} secure investment, it needs an <b>accurate</b> and <b>correct</b> {{analysis}} {{supported by a}} qualified and integrated data and information. This kind of analysis technique can reduce or minimize damage risks to the investor who invested funds in several or individual security investment. There are many techniques {{can be used by}} investors, either simple or complicate methods...|$|R
40|$|We {{are working}} on the {{development}} of an availability risk assessment method for telecommunication services, called Raster. From previous research we know that Raster can produce assessments with reasonable effort, but we have not yet shown that its results are reliable (repeatable) and <b>accurate</b> (<b>correct).</b> In this experiment we tested reliability, as without reliability it is difficult to test and improve accuracy. By reliability of a method we mean that its results are not dependent on chance or unknown circumstances. The results of a method may vary due to many factors. The goal of our experiment was to test the variation due to factors inherent in the Raster method itself. We identified and analysed sources of variation, and explain our mitigations. From the results we were able to identify three sources of variation. Two of these could be attributed to the experiment setup, but is due to ambiguity in the Raster method. We conclude with proposals for improvement of Raster...|$|E
40|$|We {{examined}} associative priming {{of words}} (e. g., TOAD) and pseudohomophones {{of those words}} (e. g., TODE) in lexical decision. In addition to word frequency effects, reliable base-word frequency effects were observed for pseudohomophones: Those based on high-frequency words elicited faster and more <b>accurate</b> <b>correct</b> rejections. Associative priming had disparate effects on high- and low-frequency items. Whereas priming improved performance to high-frequency pseudohomophones, it impaired performance to low-frequency pseudohomophones. The results suggested a resonance process, wherein phonologic identity and semantic priming combine to undermine the veridical perception of infrequent items. We tested this hypothesis in another experiment by administering a surprise recognition memory test after lexical decision. When asked to identify words that were spelled correctly during lexical decision, the participants often misremembered pseudohomophones as correctly spelled items. Patterns of false memory, however, were jointly affected by base-word frequencies and their original responses during lexical decision. Taken together, the {{results are consistent with}} resonance accounts of word recognition, wherein bottom-up and top-down information sources coalesce into correct, and sometimes illusory, perception. The results are also consistent with a recent lexical decision model, REM-LD, that emphasizes memory retrieval and top-down matching processes in lexical decision...|$|E
40|$|Quantum {{mechanical}} calculations {{on three}} of the collinear H+H 2 reactions involving D-substitutions are presented and compared {{with each other and}} with previous calculations on the H+H 2 reaction itself. The energy at which the reaction probability becomes appreciable is well predicted by the vibrationally adiabatic model. The reaction probabilities at low energies (``tunneling'') are larger than predicted by tunneling through one-dimensional barriers for motion along the reaction coordinate. The deviations of the exact rates from transition state theory with unit transmission coefficient and with transmission coefficients corrected for tunneling and nonclassical reflection are examined. Transition state theory including tunneling is usually very <b>accurate</b> (<b>correct</b> within 20 % for rate constants); but the errors are much larger at temperatures below 300 °K. Although the main use of the present results is for testing approximate models of reaction, not for comparison with laboratory experiments, it is interesting to note that the isotope effects are in rough agreement with the (noncollinear) experimental ones. The results are used to examine the general validity of treatments of the dynamics which separate effects due to the different modes of motion...|$|E
40|$|The authors {{discovered}} that the recombinant UGT 1 A 6 enzyme preparation used in this work also contained UGT 1 A 9. Accordingly, experiments involving UGT 1 A 6 were repeated with HEK 293 cell lysate expressing only this enzyme. Data reported for all other isoforms are <b>accurate.</b> The <b>corrected</b> version of the paper, which is in departure from print, follows...|$|R
40|$|Corrector {{surfaces}} {{have been}} used to model the differences between the geoid and the mean sea level derived orthometric heights, which are not coincident due to varying factors. In this case corrector surfaces are derived for 25 points co-located with GPS ellipsoidal heights, orthometric heights and geoid derived gravimetric heights, which lie throughout Johor, the southern State of Peninsular Malaysia. In order to model and minimise the differences a similarity transformation is utilised for fitting the gravimetric co-geoid undulations with GPS/Levelling data. Before the transformation the comparison between GPS and levelling is a standard deviation of ± 0. 151 m and a mean of 0. 699 m. When tested the internal relative accuracy suggests a standard deviation of ± 0. 072 m and a mean of 0. 003 m, which indicates the bias between the two datum’s has been eliminated. With the valid transformation it is now possible for the GIS field user to apply <b>accurate</b> <b>corrected</b> geoid heights to GPS derived ellipsoidal heights in a rapid feature driven field mode...|$|R
40|$|The Liley {{technique}} {{used to obtain}} an indirect measure of amniotic fluid bilirubin is compared with a direct spectrophotometric bilirubin method which corrects for interference from pigments and turbidity. The relationship established enables results from the spectrophotometric method {{to be used in}} conjunction with the clinical interpretation chart originally described by Liley. Management of pregnancies complicated by Rhesus sensitisation often relies to some extent on the determination of amniotic fluid bilirubin which is presented as an optical density difference on a chart described by Liley (1961). This method has found wide acceptance by clinicians as the results are easily interpreted in terms of the optical density difference at 450 nm and the period of gestation. The present work was carried out in an attempt to retain the advantages of the Liley presentation while using the quantitative and less subjective method of Fleming and Woolf (1965) to determine the bilirubin [...] turbidity, an <b>accurate</b> <b>corrected</b> bilirubin measure-ment in mg/l 00 ml can be obtained in the presence of interfering substances...|$|R
40|$|M. B. A. The {{purpose of}} this audit was to {{investigate}} factors related to the communication structure at Western Platinum Mine. These factors had been investigated regarding their validity regarding all levels ofcommunication. The factors included the following: I. Top-Down Communication 2. Bottom-Up Communication 3. Lateral Communication 4. Objectives ofCommunication 5. Informal Communication 6. Meetings 7. Feedback 8. Written Communication 9. External Communication 10. General Attitudes towards Western Platinum Mine The researcher relied on both quantitative and qualitative research techniques. During the audit, analysis were carried out by means ofthe following data collection methods: • Individual focus interviews with top management, • Focus group discussions with junior level staff, and • Self completion questionnaires were completed by supervisors and middle management When comparing the conclusions with the research hypotheses a high correlation was evident between the original hypotheses and the information generated by the research. It was established that communication, at the lower levels, needs attention. Messages are totally distorted and employees rely on the " [...] . grapevine [...] . " Top Management's perception that communication is sound, was {{proved to be a}} fallacy. The research thus proved that the hypotheses in fact was in general <b>accurate,</b> <b>correct</b> and evident. As a result of the research a proper communication strategy was developed for Western Platinum Mine which could satisfy all the objectives [...] ...|$|E
40|$|Reading an {{electronic}} patient record (EPR) {{is a very}} challenging task because of the medical jargons, which are almost impossible to understand for the layman. This becomes a highly relevant challenge because of the more extensive {{use of the internet}} to get medical information. Also the Norwegian laws state that the patient has the right to read his or her own EPR. A master thesis executed in 2006, and a specialization project in 2007 addressed this subject and developed a prototype for adapting EPRs to a patient presentation. This thesis continues this work and aims to extend the system with more functionality and improve the translation of the EPRs. The main issues discussed in the thesis are how disambiguating between Norwegian words and medical terms, provide summaries of EPRs, and supply the patient with external information about his or her health condition. In addition the refined user interface from the specialization project was implemented. The conclusion of this thesis is that the Support Vector Machine classifier with character bigrams provides good and accurate disambiguation between Norwegian words and medical terms. The external information functionality provides correct and quality assured information from the patient hand book. There are still some issues, and possible improvements on providing only precise and relevant articles. Summarizing of EPRs is achieved through named entity extraction of ICD codes, and then presenting the codes together with their corresponding descriptions. This implementation seems to be <b>accurate,</b> <b>correct,</b> and precise. </p...|$|E
40|$|Spell-checking is {{the process}} of {{detecting}} and correcting incorrectly spelled words in a text paragraph. Spell checking system first detects the incorrect words and then provide the best possible solution of corrected words. Spell checking system is a combination of handcrafted rules of the language for which spell checking system is to be created and a dictionary which contain the accurate spellings of various words. Better rules and large dictionary of words is help to improve the rate of error detection otherwise all the errors cannot be detected. After detecting the wrong or misspelled words,the various spell correcting techniques are used to provide the best <b>accurate</b> <b>correct</b> words or alternate words which higher the rate of correction of the wrong words. There are many systems available for detecting and correcting text. The system is made to check the spellings and to correct them using various techniques for Punjabi-Hindi text. We used hybrid approach to implement the Spelling checking and Correcting System. This hybrid approach is a combination of “Dictionary look up approach”, “Rule based approach”, “N-Gram Approach”, “Edit Distance approach” and use linguistic features of the Punjabi-Hindi language. This System gives the result accuracy as 91 % according to the research work for Punjabi-Hindi words. It gives nearby result up to 91 % of words tested in the input data. It gives results for rest of 9 % but not the best possible correct word was displayed {{on the top of the}} correct word list from the database...|$|E
40|$|RefactorIT is a {{trademark}} of Aqris Software AS. • All other products mentioned are registered trademarks {{of their respective}} owners. • Aqris Software AS endeavors {{to ensure that the}} information contained in this manual is <b>accurate</b> and <b>correct.</b> Although Aqris Software AS does not accept liability for errors and/or omissions, we do appreciate constructive criticism as to how this document/product can be improved. Please send any corrections and/or suggestions to us a...|$|R
50|$|Chiefly a text {{medium in}} the beginning, the World Wide Web {{gave rise to}} any number of {{personal}} quotation collections that continue to flourish, even though {{very few of them}} seem to facilitate <b>accurate</b> information or <b>correct</b> citation.|$|R
50|$|The game {{provides}} an explorable three-dimensional world which is displayed through a Top-down perspective. The in-game world represents, {{according to the}} publisher Kalypso Media, an almost <b>accurate</b> and historical <b>correct</b> reproduction of the American city Atlantic City of this period.|$|R
40|$|Background : Death {{certification}} {{is a vital}} {{source of}} information used in mortality statistics worldwide to assess {{the health of the}} general population. This study focuses on the consistency of information between the death reports and the clinical records (files) of deceased patients in two hospitals: the King Khalid University Hospital (KKUH) and King Fahad National Guard hospital (KFNGH) in Saudi Arabia. Methods: A random sample of the records of 157 deceased patients′ registered in 2002 in the two hospitals was retrospectively reviewed independently to determine the underlying cause of death and compare them with death reports. It was also to check the accuracy of the translation from English in to Arabic. Results: It was found that the underlying cause of death was misdiagnosed in 80. 3 % of the death reports. When the two hospitals were compared, no significant difference was observed (p> 0. 05). In addition, 81. 8 % of the <b>accurate</b> (<b>correct)</b> death reports in both hospitals were of patients who had died of a malignant disease. However, the translation of the underlying cause of death in KFNGH was correct in 86. 1 % of the death reports, while in KKUH it was only 25 %, which is highly statistically significant (p< 0. 0001). Conclusion: With the limitation of studying {{only a small number of}} cases, these results indicate a discrepancy between the file and death reports in relation to the cause of death. Also, the translation of the cause of death was inconsistent in the two hospitals. Hence, there is a real need to adopt suitable measures to improve the quality of death certification...|$|E
40|$|Various {{governmental}} organizations need <b>accurate,</b> <b>correct</b> {{and up to}} date {{information for}} optimization of resource and service management. In this issue, geospatial information is very important. Geospatial information as essential part of Geospatial Information System (GIS) has important role in performance of civil projects, urban service management. Using conventional surveying methods for producing geospatial data {{require a lot of}} cost and time. Thus, utilization of modern methods in production and updating of this kind of data is necessary. Photogrammetry and Remote Sensing are methods that produce geospatial data in extensive area with acceptable accuracy. In various countries of the world, many researches have been carried out and many algorithms have been introduced in order to decrease human operation in automatic feature extraction of satellite images. Building is one of the features that take the maximum of time and cost of feature extraction due to its abundance in urban area. As a result, on access to a model or algorithm of automatic or semi-automatic extraction of this feature not only minimizes human role in producing large scale maps but also has a dramatic effect on time and cost of the project. The aim of this paper is automatic extraction of boundary of this feature from high resolution aerial images in a way that its output is a vector map that needs the least editing in GIS. the main goal of this research is to introduce a method based on active contour model that the initialization stage of algorithm can be carried out automatically and active contour be ultimately optimized in building extraction. A new model is also suggested for automatic detection and extraction of boundary of buildings. New model of active contour can detect and extract boundary of building very accurately compared to classical model of active contour model and avoid detection of the boundary of features that ar...|$|E
40|$|Math {{expressions}} are {{an essential}} part of scientific documents. Handwritten math expressions recognition can benefit human-computer interaction especially in the education domain and is a critical part of document recognition and analysis. Parsing the spatial arrangement of symbols is {{an essential part}} of math expression recognition. A variety of parsing techniques have been developed during the past three decades, and fall into two groups. The first group is graph-based parsing. It selects a path or sub-graph which obeys some rule to form a possible interpretation for the given expression. The second group is grammar driven parsing. Grammars and related parameters are defined manually for different tasks. The time complexity of these two groups parsing is high, and they often impose some strict constraints to reduce the computation. The aim of this thesis is working towards building a straightforward and effective parser with as few constraints as possible. First, we propose using a line of sight graph for representing the layout of strokes and symbols in math expressions. It achieves higher F-score than other graph representations and reduces search space for parsing. Second, we modify the shape context feature with Parzen window density estimation. This feature set works well for symbol segmentation, symbol classification and symbol layout analysis. We get a higher symbol segmentation F-score than other systems on CROHME 2014 dataset. Finally, we develop a Maximum Spanning Tree (MST) based parser using Edmonds 2 ̆ 7 algorithm, which extracts an MST from the directed line of sight graph in two passes: first symbols are segmented, and then symbols and spatial relationship are labeled. The time complexity of our MST-based parsing is lower than the time complexity of CYK parsing with context-free grammars. Also, our MST-based parsing obtains higher structure rate and expression rate than CYK parsing when symbol segmentation is <b>accurate.</b> <b>Correct</b> structure means we get the structure of the symbol layout tree correct, even though the label of the edge in the symbol layout tree might be wrong. The performance of our math expression recognition system with MST-based parsing is competitive on CROHME 2012 and 2014 datasets. For future work, how to incorporate symbol classifier result and correct segmentation error in MST-based parsing needs more research...|$|E
40|$|Innovative {{analytically}} based {{method to}} calculate corrected fuel consumption of parallel and series hybrid electric vehicles (HEVs) at balanced energy {{content of the}} electric storage devices is proposed and validated in the paper. The proposed analytical method is generally applicable and features highly <b>accurate</b> <b>corrected</b> fuel consumption results. It enables calculation of the corrected fuel consumption out of a single fuel consumption test run in a single analytic post-processing step. An additional fuel consumption test run might be needed to obtain highly accurate results if ratio of the energy content deviation of the electric storage devices to the energy used for vehicle propulsion over the test cycle is high. Proposed method enables consideration of non-linear energy flow changes and non-linear HEV component efficiency changes caused by the energy management strategy or by the component characteristics. The method therefore features highly accurate results out of the minimum number of fuel consumption test runs and thus optimizes workload for development or optimization of HEVs. The input data of the method are characteristic energy flows and efficiencies that are derived from the energy flows on selected energy paths of HEVs. Hybrid vehicle Electric storage devices Fuel consumption correction Analytical method...|$|R
50|$|As historians {{continue}} to examine events during the German occupation and Vichy rule, several long-standing disputes have emerged. In {{the case of}} the Plateau Vivarais-Lignon and Le Chambon-sur-Lignon these include whether the interpretations based on Trocmé's writings are sufficiently <b>accurate</b> or <b>correct</b> but partial. The issues are addressed in Robert Paxton's Vichy France: Old Guard and New Order (1972). Caroline Moorehead's Village of Secrets (2014) examine's both the events in the Plateau Vivarais-Lignon and Le Chambon-sur-Lignon, and offers a review of conflicting interpretations.|$|R
40|$|This article {{presents}} {{the advantages of}} edge detection methods using filtering operations followed by application of differential operators eye an image. When using methods based on differential operators when applying intensity variations can be detected by differentiation, but if noisy signals differentiation is dangerous due {{to the effect of}} amplifying the high frequencies. To eliminate this disadvantage must be designed optimal edge detectors (Canny) which satisfy the following criteria: <b>accurate</b> detection, <b>correct</b> location and a single response to a single edg...|$|R
40|$|Starting {{from the}} analisys of some {{exemplary}} texts related to some concurrent means, {{from which the}} interpretation of Brazilian educational statistics were produced {{in the beginning of}} the 1940 ’s, we sought to explicitly express that the understanding of the quantitative information is not an objective consequence of the existence of <b>accurate</b> and <b>correct</b> data. It is rather the object of the symbolical dispute among the professionals involved in the production, analisys and divulgation of the referred information aiming to impose a legitimate interpretation of these data...|$|R
50|$|After {{returning}} to West Germany, Richebächer became a media commentator on economics. In 1957 {{he returned to}} London to become a commentator on British economic policy. In 1964, he {{was appointed to the}} position of post of chief economist and managing director of Dresdner Bank, in Frankfurt. Richebächer provided economic advice to the clients of his employer. However, he was sometimes critical of the economic policy of the government of Helmut Schmidt. His supervisor, Jürgen Ponto, continued to support Richebächer's activities in researching and providing what he deemed to be <b>accurate</b> and <b>correct</b> economic commentary.|$|R
40|$|The paper {{presents}} ANALYST, a {{tool that}} automates impact analysis by exploiting a framework that implements dependency based software representation models. The preliminary experimental results show that it supports the improvement of software representation models {{to be used in}} software comprehension. Moreover, the tool allows the maintainer to perform more <b>accurate</b> and <b>correct</b> changes, decreasing the software degradation effect. Finally, it is shown that the tool {{can be used as a}} general platform for experimenting with different impact analysis approaches, and for assessing and comparing their effectiveness with the use of suitable metric...|$|R
40|$|Very high {{dynamical}} range coronagraphs targeting direct exo-planet detection (10 ^ 9 - 10 ^ 10 contrast) {{at small}} angular separation (few lambda/D units) usually require an input wavefront quality {{on the order}} of ten thousandths of wavelength RMS. We propose a novel method based on a pre-optics setup that behaves partly as a low-efficiency coronagraph, and partly as a high-sensitivity wavefront aberration compensator (phase and amplitude). The combination of the two effects results in a highly <b>accurate</b> <b>corrected</b> wavefront. First, an (intensity-) unbalanced nulling interferometer (UNI) performs a rejection of part of the wavefront electric field. Then the recombined output wavefront has its input aberrations magnified. Because of the unbalanced recombination scheme, aberrations can be free of phase singular points (zeros) and can therefore be compensated by a downstream phase and amplitude correction (PAC) adaptive optics system, using two deformable mirrors. In the image plane, the central star's peak intensity and the noise level of its speckled halo are reduced by the UNI-PAC combination: the output-corrected wavefront aberrations can be interpreted as an improved compensation of the initial (eventually already corrected) incident wavefront aberrations. The important conclusion is that not all the elements in the optical setup using UNI-PAC need to reach the lambda/ 10000 rms surface error quality. Comment: Accepted for publication in A&...|$|R
40|$|Context. Very high {{dynamical}} range coronagraphs targeting direct exo-planet detection (10 9 ∼ 10 10 contrast) {{at small}} angular separation (few λ/D units) usually require an input wavefront quality {{on the order}} of ten thousandths of wavelength RMS. Aims. We propose a novel method based on a pre-optics setup that behaves partly as a low-efficiency coronagraph, and partly as a highsensitivity wavefront aberration compensator (phase and amplitude). The combination of the two effects results in a highly <b>accurate</b> <b>corrected</b> wavefront. Methods. First, an (intensity-) unbalanced nulling interferometer (UNI) performs a rejection of part of the wavefront electric field. Then the recombined output wavefront has its input aberrations magnified. Because of the unbalanced recombination scheme, aberrations can be free of phase singular points (zeros) and can therefore be compensated by a downstream phase and amplitude correction (PAC) adaptive optics system, using two deformable mirrors. Results. In the image plane, the central star’s peak intensity and the noise level of its speckled halo are reduced by the UNI-PAC combination: the output-corrected wavefront aberrations can be interpreted as an improved compensation of the initial (eventually already corrected) incident wavefront aberrations. Conclusions. The important conclusion is that not all the elements in the optical setup using UNI-PAC need to reach theλ/ 10000 rms surface error quality. Key words. Instrumentation: interferometers – Instrumentation: adaptive optics – Techniques: interferometric – (Stars:) planetary systems 1...|$|R
40|$|Five {{methods were}} {{compared}} {{to determine the best}} technique for accurate identification of coagulase-negative staphylococci (CoNS) (n= 142 strains). MALDI-TOF MS showed the best results for rapid and <b>accurate</b> CoNS differentiation (<b>correct</b> identity in 99. 3 %). An alternative to this approach could be Vitek 2 combined with partial tuf gene sequencing...|$|R
