34|0|Public
5000|$|<b>Autocoder</b> on Disk, similar to, but not {{compatible}} with, <b>Autocoder</b> on Tape, {{required at}} least one 1311 disk drive.|$|E
50|$|The most {{well known}} <b>Autocoder</b> {{is that of}} the IBM 1401, {{undoubtedly}} {{due in part to the}} general success of that series of machines. <b>Autocoder</b> was the primary language of this computer, and its macro capabilities supported use of the Input/Output Control System which eased the programming burden. Another assembler, Symbolic Programming System (SPS), was the assembler offered when the IBM 1401 originally was announced as a punched-card-only computer. SPS had mnemonics (often different) but a different input format. It lacked Autocoder's features and was generally used only on machines that lacked tape drives (punched-card only). A copy of the source programs for SPS-1, SPS-2 and <b>Autocoder</b> was donated to the Charles Babbage Institute, University of Minnesota, by Gary Mokotoff, author of SPS and coauthor of <b>Autocoder.</b>|$|E
50|$|For the 7070 {{these are}} done using 7070 <b>Autocoder</b> {{declarative}} statements and Macro instructions.|$|E
5000|$|<b>Autocoder</b> on Tape, a more {{advanced}} assembler, required at least 4000-character memory and four tape drives.|$|E
50|$|Programming {{languages}} for the 1400 series included Symbolic Programming System (SPS, {{an assembly}} language), <b>Autocoder</b> (assembly language), COBOL, FORTRAN, Report Program Generator (RPG), and FARGO.|$|E
50|$|<b>Autocoder</b> was {{the name}} given to certain {{assemblers}} {{for a number of}} IBM computers of the 1950s and 1960s.The first Autocoders appear to have been the earliest assemblers to provide a macro facility.|$|E
5000|$|Besides the 702 and 705, there {{eventually}} {{also were}} Autocoders for the IBM 7010, IBM 7030 (Stretch), IBM 7070, IBM 7080, and the IBM 1400 series. [...] Other manufacturers sometimes built competing products, such as NCR's [...] "National's Electronic <b>Autocoder</b> Technique" [...] (NEAT).|$|E
5000|$|IBM {{historically}} placed {{emphasis on}} backward compatibility, and FARGO and 1400 <b>Autocoder</b> {{continued to be}} used in some IBM System/360 shops by running in [...] "Emulation" [...] mode. COBOL, FORTRAN and RPG languages did not require emulation because System/360 versions were provided.|$|E
50|$|Mokotoff {{joined the}} IBM Applied Programming Department in 1959, working on {{developing}} systems {{software for the}} yet-to-be-announced IBM 1401. He {{is the author of}} SPS-1, SPS-2 IBM 1401 Symbolic Programming System, coauthor of 1401 <b>Autocoder</b> and participated in the 1401 Fortran II compiler project.|$|E
5000|$|At {{that time}} the primary storage media was Â½" [...] {{magnetic}} tape read and written on drives the size of refrigerators. There were no named files, a concept still in the future. <b>Autocoder</b> did implement a new feature: the byte mark, a single character which served to delimit a block of memory of any size, or a tape file.|$|E
50|$|Today {{the term}} is {{used to refer to}} the family of early {{languages}} descended from the Manchester Mark 1 <b>autocoder</b> systems, which were generally similar. In the 1960s, the term autocoders was used more generically as to refer to any high-level programming language using a compiler. Examples of languages referred to as autocodes are COBOL and Fortran.|$|E
5000|$|The first Autocoders were {{released}} in 1955 for the IBM 702 and in 1956 for the almost compatible IBM 705. They {{were designed by}} Roy Goldfinger who earlier had worked on New York University's (NYU) NYAP assembler. [...] These machines were variable word length commercial machines, as were many of the computers for which an <b>Autocoder</b> was released.|$|E
5000|$|Like all 1401 programs, <b>Autocoder</b> was {{stored in}} binary form on punched cards. When the cards were {{inserted}} into the card reader, pressing the Run button on the computer (a floor-standing unit; the card reader/punch was a peripheral, and there was neither keyboard or monitor) {{the contents of the}} first 80-character card were read into memory locations 0-79, and the instruction at address 0 was executed, thus beginning the bootstrap loader. <b>Autocoder</b> took human-intelligible symbols (such as a period to indicate [...] "stop") and transformed them into the instructions the machine recognized. It supported conditional branching, named subroutines, counting iterations, and what IBM called its Advanced Programming Feature, an optional feature involving three separate bytes between location 80 and 90. (Since memory locations 0-79 were reserved for the card reader, 100-179 for the card punch, which punched a card with the data in these locations when the [...] "punch" [...] command was issued, and 200-279 for the (single) printer, locations 80-99 were orphans and available for other purposes that only needed a few bytes.) ...|$|E
50|$|The {{alternative}} languages {{generally available}} at the time were Assembler, COBOL or FORTRAN. COBOL was a natural language-like business oriented language and FORTRAN was a language that facilitated mathematical applications. Other languages of the era included ALGOL and <b>Autocoder</b> and a few years later PL/I. Assembler and COBOL were more common in mainframe business operations (System/360 models 30 and above) and RPG more commonly used by customers who were in transition from tabulating equipment (System/360 model 20).|$|E
5000|$|The {{idea behind}} FARGO was to {{facilitate}} ease of transition for IBM 407 Accounting Machine technicians {{to the new}} IBM 1400 series of computers. The 1400 series had two [...] assemblers; Symbolic Programming System (SPS) and <b>Autocoder</b> (a more advanced assembler which required more memory than SPS). These represented a significant paradigm shift and learning curve for the technicians who were accustomed to wiring a control panel to direct input, output, control and counter operations (add, subtract). Multiplication and division operations were possible but their practicality was limited.|$|E
5000|$|The term <b>autocoder</b> {{needs to}} be {{distinguished}} from autocode, a term of the same era which {{was used in the}} UK for languages of a higher level. Both terms derive from the phrase automatic coding, which referred generally to programs which eased the burden of producing the numeric machine language codes of programs. [...] ("Autocoding" [...] is seen occasionally, and can refer to any kind of programming system.) In some circles [...] "autocoder" [...] could be used in a rather generic way to refer to what is now called a macro-assembler.|$|E
5000|$|The IBM 1410, {{a member}} of the IBM 1400 series, was a {{variable}} wordlength decimal computer that was announced by IBM on September 12, 1960 and marketed as a midrange [...] "Business Computer". It was withdrawn on March 30, 1970. The 1410 was similar in design to the very popular IBM 1401, but it had one major difference. Addresses were five characters long and allowed a maximum memory of 80,000 characters, much larger than the 16,000 characters permitted by the 1401's three character addresses. However, the 1410 could also be run in what was termed 1401 compatibility mode. On the 1410, this was accomplished in wired hardware - the machine literally turned into a 1401 with the flip of a switch. In addition, with care, it was possible to write source code in the <b>Autocoder</b> assembler language that could be used on either system, as nearly all 1401 instructions had exact 1410 equivalents, and had the same mnemonics.|$|E
40|$|Abstract Background Autocoding (or {{automatic}} concept indexing) {{occurs when}} a software program extracts terms contained within text and maps them to a standard list of concepts contained in a nomenclature. The purpose of autocoding {{is to provide a}} way of organizing large documents by the concepts represented in the text. Because textual data accumulates rapidly in biomedical institutions, the computational methods used to autocode text must be very fast. The {{purpose of this paper is}} to describe the doublet method, a new algorithm for very fast autocoding. Methods An <b>autocoder</b> was written that transforms plain-text into intercalated word doublets (e. g. "The ciliary body produces aqueous humor" becomes "The ciliary, ciliary body, body produces, produces aqueous, aqueous humor"). Each doublet is checked against an index of doublets extracted from a standard nomenclature. Matching doublets are assigned a numeric code specific for each doublet found in the nomenclature. Text doublets that do not match the index of doublets extracted from the nomenclature are not part of valid nomenclature terms. Runs of matching doublets from text are concatenated and matched against nomenclature terms (also represented as runs of doublets). Results The doublet <b>autocoder</b> was compared for speed and performance against a previously published phrase <b>autocoder.</b> Both autocoders are Perl scripts, and both autocoders used an identical text (a 170 + Megabyte collection of abstracts collected through a PubMed search) and the same nomenclature (neocl. xml, containing over 102, 271 unique names of neoplasms). In side-by-side comparison on the same computer, the doublet method <b>autocoder</b> was 8. 4 times faster than the phrase <b>autocoder</b> (211 seconds versus 1, 776 seconds). The doublet method codes 0. 8 Megabytes of text per second on a desktop computer with a 1. 6 GHz processor. In addition, the doublet <b>autocoder</b> successfully matched terms that were missed by the phrase <b>autocoder,</b> while the phrase <b>autocoder</b> found no terms that were missed by the doublet <b>autocoder.</b> Conclusions The doublet method of autocoding is a novel algorithm for rapid text autocoding. The method will work with any nomenclature and will parse any ascii plain-text. An implementation of the algorithm in Perl is provided with this article. The algorithm, the Perl implementation, the neoplasm nomenclature, and Perl itself, are all open source materials. </p...|$|E
40|$|Origin Image Seeker is {{a program}} for the IBM- 7074. It is written in Fortran, {{although}} the program uses an <b>Autocoder</b> subroutine. This program determines trial structures from Patterson projections and Harker sections provided that the projection contains either a real or projected atom at the origin or that the section contains a real atom at the origin...|$|E
40|$|Abstract. This article {{describes}} the potential application of a credible autocoding framework for control systems towards a nonlinear car con-troller example. The framework generates code, along with guarantees of high level functional properties about the code that can be indepen-dently verified. These high-level functional properties not only serves as a certificate of good system behvaior but {{also can be used}} to guarantee the absence of runtime errors. In one of our previous works, we have constructed a prototype <b>autocoder</b> with proofs that demonstrates this framework in a fully automatic fashion for linear and quasi-nonlinear controllers. With the nonlinear car example, we propose to further ex-tend the prototypeâs dataflow annotation language environment with with several new annotation symbols to enable the expression of gen-eral predicates and dynamical systems. We demonstrate manually how the new extensions to the prototype <b>autocoder</b> work on the car controller using the output language Matlab. Finally, we discuss the requirements and scalability issues of the automatic analysis and verification of the documented output code...|$|E
40|$|Abstract Background Concept {{indexing}} is {{a popular}} method for characterizing medical text, {{and is one of}} the most important early steps in many data mining efforts. Concept indexing differs from simple word or phrase indexing because concepts are typically represented by a nomenclature code that binds a medical concept to all equivalent representations. A concept search on the term renal cell carcinoma would be expected to find occurrences of hypernephroma, and renal carcinoma (concept equivalents). The purpose of this study is to provide freely available resources to compare speed and performance among different autocoders. These tools consist of: 1) a public domain <b>autocoder</b> written in Perl (a free and open source programming language that installs on any operating system); 2) a nomenclature database derived from the unencumbered subset of the publicly available Unified Medical Language System; 3) a large corpus of autocoded output derived from a publicly available medical text. Methods A simple lexical <b>autocoder</b> was written that parses plain-text into a listing of all 1, 2, 3, and 4 -word strings contained in text, assigning a nomenclature code for text strings that match terms in the nomenclature. The nomenclature used is the unencumbered subset of the 2003 Unified Medical Language System (UMLS). The unencumbered subset of UMLS was reduced to exclude homonymous one-word terms and proper names, resulting in a term/code data dictionary containing about a half million medical terms. The Online Mendelian Inheritance in Man (OMIM), a 92 + Megabyte publicly available medical opus, was used as sample medical text for the <b>autocoder.</b> Results The autocoding Perl script is remarkably short, consisting of just 38 command lines. The 92 + Megabyte OMIM file was completely autocoded in 869 seconds on a 2. 4 GHz processor (less than 10 seconds per Megabyte of text). The autocoded output file (9, 540, 442 bytes) contains 367, 963 coded terms from OMIM and is distributed with this manuscript. Conclusions A public domain Perl script is provided that can parse through plain-text files of any length, matching concepts against an external nomenclature. The script and associated files can be used freely to compare the speed and performance of autocoding software. </p...|$|E
40|$|Medical coding {{has become}} an {{important}} new industry that has originated {{from the field of}} medical informatics. Automatic coding of specimens has emerged as a way of relieving hospitals from the cost of paying professional coders and for achieving uniform coding for all specimens. Unfortunately, automatic coding, like manual coding, has numerous pitfalls. Further, the coding algorithms employed by manufacturers of automatic coders are typically proprietary. We have developed a method for automatic coding of pathology reports. Using this public domain <b>autocoder,</b> we have previously demonstrated that automatic SNOMED coding was superior to manual coding in several measurable categories, including the overall number of codes generated and the number of distinct code entities provided. In this report, we describe an algorithm that executes this strategy in the M-Technology environment...|$|E
40|$|This {{case study}} details the set-up and {{implementation}} of the PathNet <b>autocoder</b> (Cerner Corporation) in a busy anatomic pathology laboratory. After initial start-up, procedures were developed to improve the system's performance. Four classes of software coding errors were identified, and an index was developed to measure the number of cases between errors (CBE). Through modifications in the program, the CBE increased sharply {{by the end of the}} six-month study period. During the last three months of the study, the efficiency of case retrieval was tested by comparing manual and electronic methods on the same reference cases. This demonstrated significant time saving and removed the variability of manual coding. The technique employed in this study may assist other institutions seeking to implement such a coding system within their respective environments...|$|E
40|$|Data {{transfer}} and messaging {{is an important}} part of a spacecraft. Creating a standard protocol for messaging that can be used for a variety of applications is an extremely beneficial project at the Jet Propulsion Laboratory (JPL). The Asynchronous Messaging Service (AMS) is a protocol outlining how subsystems initialize and conduct communication between each other. There are currently two implementations of AMS in the works. At JPL, my task is to get a working implementation of AMS onto vxWorks as a proof of concept. An <b>Autocoder,</b> a program used to convert visually created state chart diagrams to C++, has also been created to accomplish a part of the implementation. I was assigned to make the program portable on any Unix type environment. Lastly, I was to develop a program to demonstrate messaging between two FireWire cards running vxworks...|$|E
40|$|This paper {{presents}} a hierarchical architecture for integrated guidance and control that achieves risk and cost reduction for NASA's 2 d generation {{reusable launch vehicle}} (RLV). Guidance, attitude control, and control allocation subsystems that heretofore operated independently will now work cooperatively under the coordination of a top-level autocommander. In addition to delivering improved performance from a flight mechanics perspective, the autocommander is intended to provide an autonomous supervisory control capability for traditional mission management under nominal conditions, G&C reconfiguration in response to effector saturation, and abort mode decision-making upon vehicle malfunction. This high-level functionality is to be implemented {{through the development of}} a relational database that is populated with the broad range of vehicle and mission specific data and translated into a discrete event system model for analysis, simulation, and onboard implementation. A Stateflow <b>Autocoder</b> software tool that translates the database into the Stateflow component of a Matlab/Simulink simulation is also presented...|$|E
40|$|International audienceThe {{efficiency}} of modern optimization methods, coupled with increasing computational resources, {{has led to}} the possibility of real-time optimization algorithms acting in safety critical roles. There is a considerable body of mathematical proofs on on-line optimization programs which can be leveraged to assist in the development and verification of their implementation. In this paper, we demonstrate how theoretical proofs of real-time optimization algorithms can be used to describe functional properties {{at the level of the}} code, thereby making it accessible for the formal methods community. The running example used in this paper is a generic semi-definite programming (SDP) solver. Semi-definite programs can encode a wide variety of optimization problems and can be solved in polynomial time at a given accuracy. We describe a top-to-down approach that transforms a high-level analysis of the algorithm into useful code annotations. We formulate some general remarks about how such a task can be incorporated into a convex programming <b>autocoder.</b> We then take a first step towards the automatic verification of the optimization program by identifying key issues to be adressed in future work...|$|E
40|$|In this paper, {{we present}} a domain {{specific}} process to assist the verification of observer-based fault detection software. Observer-based fault detection systems, like control systems, yield invariant properties of quadratic types. These quadratic invariants express both safety properties of the software such as the boundedness of the states and correctness properties such as the absence of false alarms from the fault detector. We seek to leverage these quadratic invariants, in an automated fashion, for the formal verification of the fault detection software. The approach, {{referred to as the}} credible autocoding framework [1], can be characterized as autocoding with proofs. The process starts with the fault detector model, along with its safety and correctness properties, all expressed formally in a synchronous modeling environment such as Simulink. The model is then transformed by a prototype credible <b>autocoder</b> into both code and analyzable annotations for the code. We demonstrate the credible autocoding process on a running example of an output observer fault detector for a 3 -degrees-of-freedom (3 DOF) helicopter control system...|$|E
40|$|This article {{describes}} a fully automated, credible autocoding chain for control systems. The framework generates code, along with guarantees of high level functional properties {{which can be}} independently verified. It relies on domain specific knowledge and fomal methods of analysis to address a context of heightened safety requirements for critical embedded systems and ever-increasing costs of verification and validation. The platform strives to bridge the semantic gap between domain expert and code verification expert. First, a graphical dataflow language is extended with annotation symbols enabling the control engineer to express high level properties of its control law {{within the framework of}} a familiar language. An existing <b>autocoder</b> is enhanced to both generate the code implementing the initial design, but also to carry high level properties down to annotations {{at the level of the}} code. Finally, using customized code analysis tools, certificates are generated which guarantee the correctness of the annotations with respect to the code, and can be verified using existing static analysis tools. Only a subset of properties and controllers are handled at this point...|$|E
40|$|The {{efficiency}} of modern optimization methods, coupled with increasing computational resources, {{has led to}} the possibility of real-time optimization algorithms acting in safety critical roles. There is a considerable body of mathematical proofs on on-line optimization programs which can be leveraged to assist in the development and verification of their implementation. In this paper, we demonstrate how theoretical proofs of real-time optimization algorithms can be used to describe functional properties {{at the level of the}} code, thereby making it accessible for the formal methods community. The running example used in this paper is a generic semi-definite programming (SDP) solver. Semi-definite programs can encode a wide variety of optimization problems and can be solved in polynomial time at a given accuracy. We describe a top-to-down approach that transforms a high-level analysis of the algorithm into useful code annotations. We formulate some general remarks about how such a task can be incorporated into a convex programming <b>autocoder.</b> We then take a first step towards the automatic verification of the optimization program by identifying key issues to be adressed in future work...|$|E
40|$|A {{computer}} program translates Unified Modeling Language (UML) representations of state charts into source code in the C, C++, and Python computing languages. (State charts signifies graphical descriptions {{of states and}} state transitions of a spacecraft or other complex system.) The UML representations constituting the input to this program are generated by using a UML-compliant graphical design program to draw the state charts. The generated source code {{is consistent with the}} "quantum programming" approach, which is so named because it involves discrete states and state transitions that have features in common with states and state transitions in quantum mechanics. Quantum programming enables efficient implementation of state charts, suitable for real-time embedded flight software. In addition to source code, the <b>autocoder</b> program generates a graphical-user-interface (GUI) program that, in turn, generates a display of state transitions in response to events triggered by the user. The GUI program is wrapped around, and can be used to exercise the state-chart behavior of, the generated source code. Once the expected state-chart behavior is confirmed, the generated source code can be augmented with a software interface {{to the rest of the}} software with which the source code is required to interact...|$|E
40|$|Abstract. This article {{describes}} a fully automated, credible autocod-ing chain for control systems. The framework generates code, along with guarantees of high level functional properties {{which can be}} independently verified. It relies on domain specific knowledge and fomal analysis to ad-dress a context of heightened safety requirements for critical embedded systems and ever-increasing costs of verification and validation. The plat-form strives to bridge the semantic gap between domain expert and code verification expert. First, a graphical dataflow language is extended with annotation symbols enabling the control engineer to express high level properties of its control law {{within the framework of}} a familiar language. An existing <b>autocoder</b> is enhanced to both generate the code implement-ing the initial design, but also to carry high level properties down to an-notations {{at the level of the}} code. Finally, using customized code analysis tools, certificates are generated which guarantee the correctness of the annotations with respect to the code, and can be verified using existing static analysis tools. While only a subset of properties and controllers are handled at this point, the approach appears readily extendable to a broader array of both...|$|E
40|$|This paper {{describes}} {{the implementation of}} an interface connecting the two tools : the JPL SCA (Statechart <b>Autocoder)</b> and TuLiP (Temporal Logic Planning Toolbox) to enable the automatic synthesis of low level implementation code directly from formal specifications. With system dynamics, bounds on uncertainty and formal specifications as inputs, TuLiP synthesizes Mealy machines that are correct-by-construction. An interface is built that automatically translates these Mealy machines into UML statecharts. The SCA accepts the UML statecharts (as XML files) to synthesize flight-certified implementation code. The functionality of the interface is demonstrated through three example systems of varying complexity a) a simple thermostat b) a simple speed controller for an autonomous vehicle and c) a more complex speed controller for an autonomous vehicle with a map-element. In the thermostat controller, there is a specification regarding the desired temperature range {{that has to be}} met despite disturbance from the environment. Similarly, in the speed-controllers there are specifications about safe driving speeds depending on sensor health (sensors fail unpredictably) and the map-location. The significance of these demonstrations is the potential circumventing of some of the manual design of statecharts for flight software/controllers. As a result, we expect that less testing and validation will be necessary. In applications where the products of synthesis are used alongside manually designed components, extensive testing or new certificates of correctness of the composition may still be required...|$|E

