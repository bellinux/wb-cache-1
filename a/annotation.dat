10000|10000|Public
5|$|Data {{relating}} to transcriptomics, such as complementary DNA, with optional <b>annotation.</b>|$|E
5|$|Metagenomic {{analysis}} pipelines use {{two approaches}} in the <b>annotation</b> of coding {{regions in the}} assembled contigs. The first approach is to identify genes based upon homology with genes that are already publicly available in sequence databases, usually by simple BLAST searches. This type of approach is implemented in the program MEGAN4.|$|E
5|$|Bioinformatics is a {{field of}} study that {{includes}} the creation and advancement of databases, and computational and statistical techniques, {{that can be used}} in studies of the human brain, particularly in the areas of gene and protein expression. Bioinformatics and studies in genomics, and functional genomics, generated the need for DNA <b>annotation,</b> a transcriptome technology, identifying genes, and their and location and function. GeneCards is a major database.|$|E
50|$|There {{are three}} options users can add: {{highlight}} <b>annotations,</b> text <b>annotations</b> and ink <b>annotations.</b>|$|R
5000|$|RTF {{specification}} supports <b>annotations</b> (comments in documents) since version 1.0. RTF 1.7 specification defined {{some new}} features for annotations: date stamp (there was previously only [...] "time stamp") and parents of <b>annotations.</b> When a RTF document with <b>annotations</b> is opened in an application {{that does not}} support RTF <b>annotations,</b> they are not displayed at all. Similarly, when a document with <b>annotations</b> is saved as RTF in an application that does not support RTF <b>annotations,</b> <b>annotations</b> are not preserved in the RTF file. Some implementations may hide <b>annotations</b> by default or require some user action to display them - e.g. in Abiword since version 2.8 or in IBM Lotus Symphony (up to version 1.3).|$|R
40|$|In the {{development}} of <b>annotations</b> for a spoken database, an important issue is whether the <b>annotations</b> can be generated automatically with sufficient precision, or whether expensive manual <b>annotations</b> are needed. In this paper, the case of prosodic <b>annotations</b> is discussed, which was investigated on the CGN database (Spoken Dutch Corpus). The main conclusions of this work are as follows. First, {{it was found that}} the available amount of manual prosodic <b>annotations</b> is sufficient for {{the development}} of our (baseline, decision tree based) prosodic models. In other words, more manual <b>annotations</b> do not improve the models. Second, the developed prosodic models for prominence are insufficiently accurate to produce automatic prominence <b>annotations</b> that are as good as the manual ones. But on the other hand the consistency between manual and automatic break <b>annotations</b> is as high as the inter-transcriber consistency for breaks. So given the current amount of manual break <b>annotations,</b> <b>annotations</b> for the remainder of the CGN database can be generated automatically with the same quality as the manual <b>annotations.</b> 1...|$|R
5|$|Functional {{genomics}} using RNAi is {{a particularly}} attractive technique for genomic mapping and <b>annotation</b> in plants because many plants are polyploid, which presents substantial challenges for more traditional genetic engineering methods. For example, RNAi has been successfully used for functional genomics studies in bread wheat (which is hexaploid) {{as well as more}} common plant model systems Arabidopsis and maize.|$|E
5|$|The EMBL Nucleotide Sequence Database (also {{known as}} EMBL-Bank) is {{the section of}} the ENA which {{contains}} high-level genome assembly details, as well as assembled sequences and their functional <b>annotation.</b> EMBL-Bank is contributed to by direct submission from genome consortia and smaller research groups {{as well as by the}} retrieval of sequence data associated with patent applications.|$|E
5|$|Windows 10 {{introduces}} a new default web browser, Microsoft Edge. It features a new standards-compliant rendering engine forked from Trident, <b>annotation</b> tools, and offers integration with other Microsoft platforms present within Windows 10. Internet Explorer 11 is maintained on Windows 10 for compatibility purposes, but is deprecated {{in favor of}} Edge and {{will no longer be}} actively developed.|$|E
40|$|Preliminary results {{obtained}} by comparing personal <b>annotations</b> on paper with shared <b>annotations</b> made on-line show {{that only a}} small fraction of personal <b>annotations</b> are used in initiating and responding to related on-line discussions. The personal <b>annotations</b> that are shared tended to correspond to explicit marginalia; much effort is still put into rendering both the content and anchors of these <b>annotations</b> intelligible to others...|$|R
40|$|This paper {{presents}} <b>annotations</b> {{needed for}} handwritten archives document retrieval by content. We propose two complementary ways of producing those <b>annotations</b> : automatically by using optical document recognition and collectively by using Internet and a manual input by users. A platform for managing those <b>annotations</b> {{is presented as}} well as examples of automatic <b>annotations</b> on civil status registers, military forms (tested on 60, 000 pages) and naturalization decrees, using a generic document recognition method. Examples of collective <b>annotations</b> built on automatic <b>annotations</b> are also given...|$|R
40|$|Abstract. We {{present an}} {{approach}} to tag image automatically via visual topic detecting and initial <b>annotations</b> expanding. Visual topics are detected from corel 5 k dataset by probabilistic latent semantic analysis (PLSA) model. For an image {{which is to be}} tagged, PLSA is used to find visual topic of this image, and then construct initial <b>annotations</b> set. After initial <b>annotations</b> are generated, we use a weighted voting scheme and Flickr API to expand initial <b>annotations.</b> After the above two process, we combine initial <b>annotations</b> and expanded <b>annotations</b> together to construct final <b>annotations.</b> From experimental results, the conclusions can be draw that our PLSA based image tagging approach works effectively. 1...|$|R
25|$|For SNP <b>annotation</b> many {{genetic and}} genomic {{information}} are used. Based on different feature {{used by the}} <b>annotation</b> tool, the SNP <b>annotation</b> can be classified into this category.|$|E
25|$|Automatic <b>annotation</b> tools try {{to perform}} these steps in silico, {{as opposed to}} manual <b>annotation</b> (a.k.a. curation) which {{involves}} human expertise and potential experimental verification. Ideally, these approaches co-exist and complement {{each other in the}} same <b>annotation</b> pipeline (also see below).|$|E
25|$|Traditionally, {{the basic}} level of <b>annotation</b> is using BLAST for finding similarities, and then annotating genomes based on homologues. More recently, {{additional}} information {{is added to}} the <b>annotation</b> platform. The additional information allows manual annotators to deconvolute discrepancies between genes that are given the same <b>annotation.</b> Some databases use genome context information, similarity scores, experimental data, and integrations of other resources to provide genome annotations through their Subsystems approach. Other databases (e.g. Ensembl) rely on both curated data sources as well as a range of software tools in their automated genome <b>annotation</b> pipeline. Structural <b>annotation</b> consists of the identification of genomic elements, primarily ORFs and their localisation, or gene structure. Functional <b>annotation</b> consists of attaching biological information to genomic elements.|$|E
30|$|In {{addition}} to the common JUnit <b>annotations,</b> the ReTest framework has a set of 4 <b>annotations</b> for the test methods and 4 <b>annotations</b> for the method parameters.|$|R
40|$|The annex is the {{presentation}} file {{used for the}} talk. Invited talk, Hankuk University of Foreign Studies, Yong-in, South KoreaThe Unitex/GramLab system provides tools for inserting and modifying <b>annotations</b> in written text. We describe current practices for the following tasks: inserting <b>annotations,</b> copying information into <b>annotations,</b> controlling where we place <b>annotations,</b> and deleting <b>annotations.</b> In particular, we provide practical information {{on the use of}} several types of variables...|$|R
40|$|Search for {{multimedia}} is {{hampered by}} both the lack of quality <b>annotations</b> and a quantity of <b>annotations.</b> In recent {{years there has been}} a growth in multimedia search services that emphasis interactivity between the user and the interface. Some of these systems present an as yet untapped resource for providing <b>annotations</b> for video. In this paper, we investigate the use of a new innovative grouping interface for video search to provide additional <b>annotations</b> for video collections. The <b>annotations</b> provided are an inherent part of the search interface, thus providing less overhead for the user in providing <b>annotations.</b> In addition we believe that the users are more likely to provide high quality <b>annotations</b> as the <b>annotations</b> are used to aid the users search. Specifically we investigate the <b>annotations</b> provided as part of two evaluations of our system; the results of these evaluations also demonstrate the utility and benefit of a grouping interface for video search [8]. The results of the analysis presented in this paper demonstrate the benefit of this implicit approach for providing additional high quality <b>annotations</b> for video collections...|$|R
25|$|There {{are also}} web <b>annotation</b> systems that support <b>annotation</b> in pdf and other {{documents}} formats, e.g., A.nnotate, crocodoc, WebNotes.|$|E
25|$|For mobile <b>annotation,</b> iAnnotate PDF (from Branchfire) and GoodReader (from Aji) allow <b>annotation</b> of PDFs {{as well as}} {{exporting}} {{summaries of}} the annotations.|$|E
25|$|<b>Annotation</b> unification: Different {{data source}} often offer {{annotations}} with heterogeneous naming system. <b>Annotation</b> unification of GeneDecks {{is based on}} the similarity in GeneCards gene-content space detection algorithms.|$|E
40|$|Abstract Background <b>Annotations</b> that {{describe}} {{the function of}} sequences are enormously important to researchers during laboratory investigations and when making computational inferences. However, {{there has been little}} investigation into the data quality of sequence function <b>annotations.</b> Here we have developed a new method of estimating the error rate of curated sequence <b>annotations,</b> and applied this to the Gene Ontology (GO) sequence database (GOSeqLite). This method involved artificially adding errors to sequence <b>annotations</b> at known rates, and used regression to model the impact on the precision of <b>annotations</b> based on BLAST matched sequences. Results We estimated the error rate of curated GO sequence <b>annotations</b> in the GOSeqLite database (March 2006) at between 28 % and 30 %. <b>Annotations</b> made without use of sequence similarity based methods (non-ISS) had an estimated error rate of between 13 % and 18 %. <b>Annotations</b> made with the use of sequence similarity methodology (ISS) had an estimated error rate of 49 %. Conclusion While the overall error rate is reasonably low, it would be prudent to treat all ISS <b>annotations</b> with caution. Electronic annotators that use ISS <b>annotations</b> as the basis of predictions are likely to have higher false prediction rates, and for this reason designers of these systems should consider avoiding ISS <b>annotations</b> where possible. Electronic annotators that use ISS <b>annotations</b> to make predictions should be viewed sceptically. We recommend that curators thoroughly review ISS <b>annotations</b> before accepting them as valid. Overall, users of curated sequence <b>annotations</b> from the GO database should feel assured that they are using a comparatively high quality source of information. </p...|$|R
40|$|The {{vision of}} the Semantic Web was coined by Tim Berners-Lee almost two decades ago. The idea {{describes}} {{an extension of the}} existing Web in which “information is given well-deﬁned meaning, better enabling computers and people to work in cooperation” [Berners-Lee et al., 2001]. Semantic <b>annotations</b> in HTML pages are one realization of this vision which was adopted by large numbers of web sites in the last years. Semantic <b>annotations</b> are integrated into the code of HTML pages using one of the three markup languages Microformats, RDFa, or Microdata. Major consumers of semantic <b>annotations</b> are the search engine companies Bing, Google, Yahoo!, and Yandex. They use semantic <b>annotations</b> from crawled web pages to enrich the presentation of search results and to complement their knowledge bases. However, outside the large search engine companies, {{little is known about the}} deployment of semantic annotations: How many web sites deploy semantic <b>annotations?</b> What are the topics covered by semantic <b>annotations?</b> How detailed are the <b>annotations?</b> Do web sites use semantic <b>annotations</b> correctly? Are semantic <b>annotations</b> useful for others than the search engine companies? And how can semantic <b>annotations</b> be gathered from the Web in that case? The thesis answers these questions by proﬁling the web-wide deployment of semantic <b>annotations.</b> The topic is approached in three consecutive steps: In the ﬁrst step, two approaches for extracting semantic <b>annotations</b> from the Web are discussed. The thesis evaluates ﬁrst the technique of focused crawling for harvesting semantic <b>annotations.</b> Afterward, a framework to extract semantic <b>annotations</b> from existing web crawl corpora is described. The two extraction approaches are then compared for the purpose of analyzing the deployment of semantic <b>annotations</b> in the Web. In the second step, the thesis analyzes the overall and markup language-speciﬁc adoption of semantic <b>annotations.</b> This empirical investigation is based on the largest web corpus that is available to the public. Further, the topics covered by deployed semantic <b>annotations</b> and their evolution over time are analyzed. Subsequent studies examine common errors within semantic <b>annotations.</b> In addition, the thesis analyzes the data overlap of the entities that are described by semantic <b>annotations</b> from the same and across different web sites. The third step narrows the focus of the analysis towards use case-speciﬁc issues. Based on the requirements of a marketplace, a news aggregator, and a travel portal the thesis empirically examines the utility of semantic <b>annotations</b> for these use cases. Additional experiments analyze the capability of product-related semantic <b>annotations</b> to be integrated into an existing product categorization schema. Especially, the potential of exploiting the diverse category information given by the web sites providing semantic <b>annotations</b> is evaluated...|$|R
5000|$|Interlinear <b>annotations</b> that attach <b>annotations</b> {{directly}} into a text ...|$|R
25|$|A {{large number}} of variant <b>annotation</b> tools are {{available}} for variant <b>annotation</b> {{but in some cases}} the prediction by the tools does not agree since the way the rules have been defined differ slightly between each application. It is frankly impossible to perform a perfect comparison of the tools. Not all the tools have same input and output and function. Here is a table of major <b>annotation</b> tools and it's functional area.|$|E
25|$|Each {{consortium}} member is {{heavily involved in}} protein database maintenance and <b>annotation.</b> Until recently, EBI and SIB together produced the Swiss-Prot and TrEMBL databases, while PIR produced the Protein Sequence Database (PIR-PSD). These databases coexisted with differing protein sequence coverage and <b>annotation</b> priorities.|$|E
25|$|<b>Annotation</b> combinatory: Using GeneDecks, {{one can get}} a set {{of similar}} genes for a {{particular}} gene with a selected combinatorial <b>annotation.</b> The summary table result in ranking the different level of similarity between the identified genes and the probe gene.|$|E
50|$|Summary <b>annotations</b> {{are further}} {{classified}} into informative and indicative <b>annotations.</b>|$|R
5000|$|... {{security}} with <b>annotations.</b> ztemplates provides {{support for}} security by <b>annotations.</b>|$|R
40|$|Background <b>Annotations</b> that {{describe}} {{the function of}} sequences are enormously important to researchers during laboratory investigations and when making computational inferences. However, {{there has been little}} investigation into the data quality of sequence function <b>annotations.</b> Here we have developed a new method of estimating the error rate of curated sequence <b>annotations,</b> and applied this to the Gene Ontology (GO) sequence database (GOSeqLite). This method involved artificially adding errors to sequence <b>annotations</b> at known rates, and used regression to model the impact on the precision of <b>annotations</b> based on BLAST matched sequences. Results We estimated the error rate of curated GO sequence <b>annotations</b> in the GOSeqLite database (March 2006) at between 28 % and 30 %. <b>Annotations</b> made without use of sequence similarity based methods (non-ISS) had an estimated error rate of between 13 % and 18 %. <b>Annotations</b> made with the use of sequence similarity methodology (ISS) had an estimated error rate of 49 %. Conclusion While the overall error rate is reasonably low, it would be prudent to treat all ISS <b>annotations</b> with caution. Electronic annotators that use ISS <b>annotations</b> as the basis of predictions are likely to have higher false prediction rates, and for this reason designers of these systems should consider avoiding ISS <b>annotations</b> where possible. Electronic annotators that use ISS <b>annotations</b> to make predictions should be viewed sceptically. We recommend that curators thoroughly review ISS <b>annotations</b> before accepting them as valid. Overall, users of curated sequence <b>annotations</b> from the GO database should feel assured that they are using a comparatively high quality source of information. Craig E. Jones, Alfred L. Brown and Ute Bauman...|$|R
25|$|Label {{high-resolution}} images using {{a web-based}} image <b>annotation</b> application.|$|E
25|$|SNP <b>annotation</b> {{to predict}} the {{functional}} effect of each variation.|$|E
25|$|UniProtKB/TrEMBL {{contains}} high-quality computationally analyzed records, {{which are}} enriched with automatic <b>annotation.</b> It {{was introduced in}} response to increased dataflow resulting from genome projects, as the time- and labour-consuming manual <b>annotation</b> process of UniProtKB/Swiss-Prot could not be broadened to include all available protein sequences. The translations of annotated coding sequences in the EMBL-Bank/GenBank/DDBJ nucleotide sequence database are automatically processed and entered in UniProtKB/TrEMBL.|$|E
5000|$|<b>Annotations</b> {{applied to}} other <b>annotations</b> (also known as [...] "Meta Annotations"): ...|$|R
5000|$|A {{variety of}} tools provide {{functionality}} based on JML <b>annotations.</b> The Iowa State JML tools provide an assertion checking compiler [...] which converts JML <b>annotations</b> into runtime assertions, a documentation generator [...] which produces Javadoc documentation augmented with extra information from JML <b>annotations,</b> and a unit test generator [...] which generates JUnit test code from JML <b>annotations.</b>|$|R
40|$|The {{focus of}} this paper is on the design, implementation, and {{validation}} of asynchronous multimedia <b>annotations</b> designed for Web-based collaboration in educational and research settings. The two key questions we explore in this paper are: How useful are such <b>annotations</b> and what purpose do <b>annotations</b> serve? What is the ease of use of our specific implementation of <b>annotations?</b> The context of our project has been in the area of multimedia information usage and collaboration in the biological sciences. We have developed asynchronous <b>annotations</b> for HTML and image data. Our <b>annotations</b> can be executed via any browser and require no downloads. They are stored in a central database allowing search and asynchronous access by all registered users. An easy to use user interface allows users to add, view and search <b>annotations.</b> We also performed a usability study that showed that our implementation of text <b>annotations</b> to validate our implementation. 1...|$|R
