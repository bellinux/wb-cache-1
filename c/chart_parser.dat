117|17|Public
50|$|A common {{approach}} {{is to use a}} variant of the Viterbi algorithm. The Earley parser is a type of <b>chart</b> <b>parser</b> mainly used for parsing in computational linguistics, named for its inventor. Another chart parsing algorithm is the Cocke-Younger-Kasami (CYK) algorithm.|$|E
50|$|In {{computer}} science, a {{left corner}} parser {{is a type}} of <b>chart</b> <b>parser</b> used for parsing context-free grammars. It combines the top-down and bottom-up approaches of parsing. The name derives from the use of the left corner of the grammar's production rules.|$|E
50|$|In {{computer}} science, a <b>chart</b> <b>parser</b> {{is a type}} of parser {{suitable for}} ambiguous grammars (including grammars of natural languages). It uses the dynamic programming approachâ€”partial hypothesized results are stored in a structure called a chart and can be re-used. This eliminates backtracking and prevents a combinatorial explosion.|$|E
50|$|<b>Chart</b> <b>parsers</b> are {{distinguished}} between top-down and bottom-up, {{as well as}} active and passive.|$|R
40|$|This paper {{discusses}} {{the relationship between}} memoized top-down recognizers and <b>chart</b> <b>parsers.</b> It presents a version of memoization suitable for continuation-passing style programs. When applied to a simple formalization of a top-down recognizer it yields a terminating parser. Comment: uuencoded, compressed postscript fil...|$|R
50|$|<b>Chart</b> <b>parsers</b> {{can also}} be used for parsing {{computer}} languages. Earley parsers in particular have been used in compiler compilers where their ability to parse using arbitrary Context-free grammars eases the task of writing the grammar for a particular language. However their lower efficiency has led to people avoiding them for most compiler work.|$|R
50|$|In {{computer}} science, the Earley parser is an algorithm for parsing strings {{that belong}} to a given context-free language, though (depending on the variant) it may suffer problems with certain nullable grammars. The algorithm, named after its inventor, Jay Earley, is a <b>chart</b> <b>parser</b> that uses dynamic programming; it is mainly used for parsing in computational linguistics. It was first introduced in his dissertation in 1968 (and later appeared in abbreviated, more legible form in a journal).|$|E
50|$|The {{deterministic}} {{behavior is}} desired and expected in compiling programming languages. In natural language processing, {{it was thought}} {{for a long time}} that deterministic parsing is impossible due to ambiguity inherent in natural languages (many sentences have more than one plausible parse). Thus, non-deterministic approaches such as the <b>chart</b> <b>parser</b> had to be applied. However, Mitch Marcus proposed in 1978 the Parsifal parser that was able to deal with ambiguities while still keeping the deterministic behavior.|$|E
40|$|Abstract: Packed forest <b>chart</b> <b>parser,</b> {{like the}} {{traditional}} chart parsing algorithm, uses charts to store {{all the information}} produced while parsing to avoid redundant works. Its advantage over the traditional <b>chart</b> <b>parser</b> was the packed forest representation. The algorithm not only shares the non-terminal categories as what {{was done in the}} shared parse forest, but also shares the leftmost common elements. The number of active edges in packed forest <b>chart</b> <b>parser</b> was decreased, so memory requirement was reduced and parsing was speeded up. The effectiveness of our approach has been evaluated on Chinese parsing. Results show that packed forest <b>chart</b> <b>parser</b> significantly outperforms packed <b>chart</b> <b>parser,</b> with the former 10 times faster than the latter. Key words: Parsing algorithm, packed forest <b>chart</b> <b>parser,</b> active edg...|$|E
40|$|We {{present an}} {{efficient}} procedure for cost-based abduction, {{which is based}} on the idea of using <b>chart</b> <b>parsers</b> as proof procedures. We discuss in detail three features of our algorithm [...] goal-driven bottom-up derivation, tabulation of the partial results, and agenda control mechanism [...] and report the results of the preliminary experiments, which show how these features improve the computational efficiency of cost-based abduction...|$|R
40|$|This paper compares two parsing strategies: {{bidirectional}} bottom-up parsing with top-down predictions (BBP) {{and standard}} chart parsing. We demonstrate that BBP {{is superior to}} classical <b>chart</b> <b>parsers</b> from a linguistic and computational points of view. The efficiency of BBP results from two factors: first, top-down predictions bring about an algorithmic improvement, and, second, the memory model, the data structures and the programming techniques incorporate notable computational improvements...|$|R
40|$|Parsing schemata give a {{high-level}} formal description of parsers. These can be used, among others, {{as an intermediate}} level of abstraction for deriving the formal correctness of a parser. A parser is correct if it duly implements a parsing schema that {{is known to be}} correct. We discuss how the correctness of a parsing schema can be proven and how parsing schemata relate to some well-known classes of <b>parsers,</b> viz. <b>chart</b> <b>parsers</b> and LR-type parsers...|$|R
40|$|Packed forest <b>chart</b> <b>parser,</b> {{like the}} {{traditional}} chart parsing algorithm, uses charts to store {{all the information}} produced while parsing to avoid redundant works. Its advantage over the traditional <b>chart</b> <b>parser</b> was the packed forest representation. The algorithm not only shares the non-terminal categories as what {{was done in the}} shared parse forest, but also shares the leftmost common elements. The number of active edges in packed forest <b>chart</b> <b>parser</b> was decreased, so memory requirement was reduced and parsing was speeded up. The effectiveness of our approach has been evaluated on Chinese parsing. Results show that packed forest <b>chart</b> <b>parser</b> significantly outperforms packed <b>chart</b> <b>parser,</b> with the former 10 times faster than the latter...|$|E
40|$|Head-Corner (HC) parsing {{has come}} up in {{computational}} linguistics a few years ago, motivated by linguistic arguments. This idea is a heuristic, rather than a fail-safe principle, hence it is relevant indeed to consider the worst-case behaviour of the HC parser. We define a novel predictive head-corner <b>chart</b> <b>parser</b> of cubic time complexity. We start with a left-corner (LC) <b>chart</b> <b>parser,</b> which is easier to understand. Subsequently, the LC <b>chart</b> <b>parser</b> is generalized to an HC <b>chart</b> <b>parser.</b> It is briefly sketched how the parser can be enhanced with feature structures...|$|E
40|$|In this paper, {{we present}} a novel {{approach}} to integrate speech recognition and rulebased machine translation by lattice parsing. The presented approach is hybrid in two senses. First, it combines structural and statistical methods for language modeling task. Second, it employs a <b>chart</b> <b>parser</b> which utilizes manually created syntax rules in addition to scores obtained after statistical processing during speech recognition. The employed <b>chart</b> <b>parser</b> is a unification-based active <b>chart</b> <b>parser.</b> It can parse word graphs by using a mixed strategy instead of being bottom-up or top-down only. The results are reported based on word error rate on the NIST HUB- 1 word-lattices. The presented approach is implemented and compared with other syntactic language modeling techniques. ...|$|E
40|$|Parsing schemata {{provide a}} {{high-level}} formal description of parsers. These can be used, among others, {{as an intermediate}} level of abstraction for deriving the formal correctness of a parser. A parser is correct if it duely implements a parsing schema that {{is known to be}} correct. In this paper it is discussed how the correctness of a parsing schema can be proven and how parsing schemata relate to some well-known classes of <b>parsers,</b> viz. <b>chart</b> <b>parsers</b> and LR-type parsers. ...|$|R
40|$|Shieber (1987) {{describes}} a technique for {{limiting the number}} of active edges introduced into a chart by top-down prediction in <b>chart</b> <b>parsers</b> for PATR grammars, without affecting the correctness or completeness of the parser. That technique, termed restriction, is extendable to other parsing algorithms. It can be employed to increase parsing efficiency and to induce termination for some classes of grammars that would not otherwise terminate. Here, we describe one class of grammars for which restriction, as described by Shieber, induces non-termination. We do not suggest that the concept of restriction is fatally flawed, however. On the contrary, relatively minor modifications to the implementation of restriction can make it a more flexible tool for fine-tuning PATR grammars...|$|R
40|$|Abstract: Three {{statistical}} parsing models, {{which are}} incremental augmentations {{to the conventional}} PCFG, are presented in this paper. In this sequence of models, wider structural context is taken to condition the derivations. We have applied the models {{to the task of}} Chinese parsing. Results on the Penn Chinese Treebank and another treebank of shorter sentences are both reported. The results show that the Labeled Precision and Recall are raised steadily in this approach. For the MT 97 treebank, precision/recall are raised from 85. 58 %/ 85. 66 % to 90. 72 %/ 90. 92 %. For the Penn Chinese Treebank, the rise is from 75. 71 %/ 70. 27 % to 77. 16 %/ 77. 69 %. We also present our efficient parsing algorithm that saves over 70 % of active edges in comparison with traditional <b>Chart</b> <b>parsers.</b> ...|$|R
40|$|Head-Corner (HC) parsing {{has come}} up in {{computational}} linguistics a few years ago, motivated by linguistic arguments. This idea is a heuristic, rather than a fail-safe principle, hence it is relevant indeed to consider the worst-case behaviour of the HC parser. We define a novel predictive head-corner <b>chart</b> <b>parser</b> of cubic time complexity. We start with a left-corner (LC) <b>chart</b> <b>parser,</b> which is easier to understand. Subsequently, the LC <b>chart</b> <b>parser</b> is generalized to an HC <b>chart</b> <b>parser.</b> It is briefly sketched how the parser can be enhanced with feature structures. 1. Introduction "Our Latin teachers were apparently right", Martin Kay (1989) remarks. "You should start [parsing] with the main verb. This {{will tell you what}} kinds of subjects and objects to look for and what cases they will be in. When you come to look for these, you should also start by trying to find the main word, because this will tell you most about what else to look for". Head-driven or head-corner parsing has been [...] ...|$|E
40|$|This paper {{describes}} syntactic {{repair and}} spelling correction of ill-formed sentences within a context-free grammar using non-static filtering, of ill-formed sentences which violate subjectverb agreement or premodifier-noun agreement. The system described here provides recovery of local trees, {{reconstruction of the}} sentence, and spelling correction of detected typographical errors. It also produces {{a report on the}} repair that has been carried out. The system includes generalised problem-solving strategies for detecting and correcting several types of syntactic and typographical errors, and also includes heuristics. The paper focuses on a system for the integration of lexical and syntactic recovery of ill-formed sentences at the local tree and the final goal (sentence) level. The system is based on a <b>chart</b> <b>parser</b> and employs a mixed top-down/bottom-up strategy together with left-to-right and rightto-left parsing. The implementation is composed of two chart parsers: a well-formed sentence <b>chart</b> <b>parser</b> (WFSCP) and an ill-formed sentence <b>chart</b> <b>parser</b> (IFSCP), and a spelling correction algorithm based on dictionary lookup...|$|E
40|$|The {{objective}} {{of this research was}} to extract simple noun phrases from natural language texts using two different grammars: stochastic context-free grammar (SCFG) and non-statistical context free grammar (CFG). Precision and recall were calculated to determine how many precise and correct noun phrases were extracted using these two grammars. Several text files containing sentences from English natural language specifications were analyzed manually to obtain the test-set of simple noun-phrases. To obtain precision and recall, this test-set of manually extracted noun phrases was compared with the extracted-sets of noun phrases obtained using the both grammars SCFG and CFG. A probabilistic <b>chart</b> <b>parser</b> was developed by modifying a deterministic parallel <b>chart</b> <b>parser.</b> Extraction of simple noun-phrases with the SCFG was accomplished using this probabilistic <b>chart</b> <b>parser,</b> a dictionary containing word probabilities along with the meaning, context-free grammar rules associated with rule probabilities and finally an algorithm to extract most likely parses of a sentence. The probabilistic parsing algorithm and the algorithm to determine figures of merit were implemented using C+...|$|E
40|$|This paper {{describes}} {{the extension of}} the system DyALog to compile tabular parsers from Feature Tree Adjoining Grammars. The compilation process uses intermediary 2 -stack automata to encode various parsing strategies and a dynamic programming interpretation to break automata derivations into tabulable fragments. 1. Introduction This paper {{describes the}} extension of the system DyALog in order to produce tabular parsers for Tree Adjoining Grammars [TAGs] and focuses on some practical aspects encountered during the process. By tabulation, we mean that traces of (sub) computations, called items, are tabulated in order to provide computation sharing and loop detection (as done in <b>Chart</b> <b>Parsers).</b> The system DyALog 1 handles logic programs and grammars (DCG). It has two main components, namely an abstract machine that implements a generic fix-point algorithm with subsumption checking on objects, and a bootstrapped compiler. The compilation process first compiles a grammar into a Push-Down [...] ...|$|R
40|$|This paper {{presents}} the LTAG Workbench, {{a set of}} graphical tools and parsers freely available for LTAG. The system can be view as a modern alternative to the XTAG system. We present first {{the outlines of the}} workbench including different graphical editors and two <b>chart</b> <b>parsers.</b> The encoding of resources and results is based on an XML application called TagML. We present then future works dedicated to speed efficiency: Optimization based on sharing techniques and preprocessing of features. The whole system has been developed in Java which allows a strong portability and interesting reusability properties. Submission Type: short talk with tool demonstration Contact: Patrice Lopez Phone: (++ 49) (0) 681 - 302 - 5256 Fax: (++ 49) (0) 681 - 302 - 5341 Under consideration for other conferences (specify) ? None LTAG Workbench: A General Framework for LTAG (with Tool demonstration) Abstract This paper {{presents the}} LTAG Workbench, a set of graphical tools and parsers freely available for L [...] ...|$|R
40|$|Parsing schemata {{provide a}} {{high-level}} formal description of parsers. These can be used, among others, {{as an intermediate}} level of abstraction for deriving the formal correctness of a parser. A parser is correct if it duely implements a parsing schema that {{is known to be}} correct. In this paper it is discussed how the correctness of a parsing schema can be proven and how parsing schemata relate to some well-known classes of <b>parsers,</b> viz. <b>chart</b> <b>parsers</b> and LR-type parsers. 1 Introduction Parsing schemata were introduced in [Sik 93] as a framework for high-level description of parsing algorithms, both parallel and sequential. A parsing schema abstracts from implementation details of an algorithm like data structures and control structures. A prime application of this framework is the analysis of relations between different parsing algorithms by studying formal relations between their underlying parsing schemata. For a concise introduction, see [Sik 94]. Here we concentrate on correctness, a [...] ...|$|R
40|$|This paper {{describes}} a technique for parsing dependency grammars using a bottom-up <b>chart</b> <b>parser</b> originally designed for phrase-structure grammars, using typed feature structures {{as the only}} data structure. Each lexical item is represented as a tree where nodes indicate lexical elements (the anchor, its dependents and governor) and edges (branches) indicate dependency relations between these elements. Nodes may carry additional features, including one for node saturation. Trees combine into derived trees provided that node and edge features unify. The ALE system is used to implement an active <b>chart</b> <b>parser</b> where a chart edge represents a tree, and two adjacent edges are combined into a more saturated tree. status: publishe...|$|E
40|$|This paper {{discusses}} the robustness of four efficient syntactic error-correcting parsing algorithms {{that are based}} on chart parsing with a context-free grammar. In this context, by robust we mean able to correct detectable syntactic errors. We implemented four versions of a bottom-up error-correcting chart parser: a basic bottom-up <b>chart</b> <b>parser,</b> and chart parsers employing selectivity, top-down filtering, and a combination of selectivity and a top-down filtering. The combined selectivity and top-down filtering parser was the most efficient. However, this parser failed to correctly repair more sentences than the other parsers, failing on 18 out of 119 ill-formed sentences, compared to no failures for the basic bottom-up <b>chart</b> <b>parser.</b> This paper examines trade-offs between parsing efficiency and robustness at the syntactic level...|$|E
40|$|This paper {{presents}} {{empirical studies}} and closely corresponding theoretical {{models of the}} performance of a <b>chart</b> <b>parser</b> exhaustively parsing the Penn Treebank with the Treebank's own CFG grammar. We show how performance is dramatically affected by rule representation and tree transformations, but little by top-down vs. bottom-up strategies...|$|E
40|$|An {{environment}} {{built around}} WEDNESDAY 2, a <b>chart</b> based <b>parser</b> is introduced. The environment is in particular oriented towards exploring dynamic aspects of parsing. It includses {{a number of}} specialized tools that consent an easy, graphics-based interaction with the parser. It is shown in particular how {{a combination of the}} characteristics of the parser (based on the lexicon and on dynamic unification) and of the environment allow a nonspecialized user to explore heuristics that may alter the basics control of the system. In this way, for instance, a psycholinguist may explore ideas on human parsing strategies, or a "language engineer" may find useful heuristics for parsing within a particular application...|$|R
40|$|This paper {{describes}} an efficient and robust {{implementation of a}} bi-directional, head-driven parser for constraint-based grammars. This parser is developed for the OVIS system: a Dutch spoken dialogue system in which information about public transport {{can be obtained by}} telephone. After a review of the motivation for head-driven parsing strategies, and head-corner parsing in particular, a non-deterministic version of the head-corner parser is presented. A memoization technique is applied to obtain a fast parser. A goal-weakening technique is introduced which greatly improves average case efficiency, both in terms of speed and space requirements. I argue in favor of such a memoization strategy with goal-weakening in comparison with ordinary chart-parsers because such a strategy can be applied selectively and therefore enormously reduces the space requirements of the parser, while no practical loss in time-efficiency is observed. On the contrary, experiments are described in which head-corner and left-corner parsers implemented with selective memoization and goal weakening outperform `standard' <b>chart</b> <b>parsers.</b> The experiments include the grammar of the OVIS system and the Alvey NL Tools grammar. Head-corner parsing is a mix of bottom-up and top-down processing. Certain approaches towards robust parsing require purely bottom-up processing. Therefore, it seems that head-corner parsing is unsuitable for such robust parsing techniques. However, it is shown how underspecification (which arises very naturally in a logic programming environment) can be used in the head-corner parser to allow such robust parsing techniques. A particular robust parsing model is described which is implemented in OVIS. Comment: 31 pages, uses cl. st...|$|R
40|$|In {{this paper}} we present {{preliminary}} results of investigating {{the structure of}} the Penn Treebank and how these results can be used in probabilistic parsing of English. Penn Treebank is a corpus of 4. 9 million part-of-speech tagged words and 2. 9 million words of skeletally parsed data developed by the University of Pennsylvania (see 8). By matching skeletal parse files with POS-tagged files we extract rules used to produce parses and count the number of occurrences of each rule. Consequently, we acquire a stochastic context-free grammar (SCFG), or a CFG with a probability attached to each rule. The grammar we acquired is used in a simple <b>chart</b> probabilistic <b>parser.</b> This parser is capable of parsing a few short sentences. However, the grammar is still too large to be used in a real-time parser, and intelligent reduction of the number of rules is needed. We propose to develop a methodology for processing the acquired grammar and discuss techniques we have considered. Our approach [...] ...|$|R
40|$|This paper {{proposes a}} {{sequential}} coupling of a Hidden Markov Model (HMM) recognizer for offline handwritten English sentences with a probabilistic bottom-up <b>chart</b> <b>parser</b> using Stochastic Context-Free Grammars (SCFG) extracted from a text corpus. Based on extensive experiments, {{we conclude that}} syntax analysis helps to improve recognition rates significantly...|$|E
40|$|This paper {{describes}} a Prolog-based typed feature structure grammar formalism and a <b>chart</b> <b>parser</b> for it. The system provides some facilities for tracing {{the application of}} the grammar, including a graphical interface to the chart. It is intended to be tool for implementation of contraint-based grammars, useful for both research and teaching purposes...|$|E
40|$|We {{present a}} novel method for {{improving}} parsing performance, using a stochastic islanddriven <b>chart</b> <b>parser</b> {{preceded by a}} chunking process for identifying initial islands. Two different stochastic models {{have been developed for}} the island-driven parsing. Some experiments with nominal chunking using broad-coverage grammars derived from the Penn Treebank have been performed with remarkable results. ...|$|E
40|$|We {{propose a}} system for {{analyzing}} texts written in languages which don't make use of punctuation, with syntactic tagging in mind. The core system is a simple <b>chart</b> <b>parser,</b> but {{to cope with the}} complexity and ambiguity problems, we use simplied finite-state automata, which guide the analysis. An application to Ancient Egyptian texts is introduced...|$|E
40|$|Abstract. We {{present a}} {{formalization}} of lexicalized Recursive Transition Networks {{which we call}} Automaton-Based Generative Dependency Grammar (gdg). We show how to extract a gdg from a syntactically annotated corpus, present a <b>chart</b> <b>parser</b> for gdg, and discuss different probabilistic models which are directly implemented in the finite automata and do not affect the parser. ...|$|E
40|$|International audienceParsing with categorial grammars {{often leads}} to {{problems}} such as proliferating lexical ambiguity, spurious parses and overgeneration. This paper presents a parser for French developed on an unification based categorial grammar (FG) which avoids these problems. This parser is a bottom-up <b>chart</b> <b>parser</b> augmented with a heuristic eliminating spurious parses. The unicity and completeness of parsing are proved...|$|E
