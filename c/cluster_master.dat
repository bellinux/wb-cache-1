4|57|Public
50|$|In 1957, the United Kingdom Warning and Monitoring Organisation (UKWMO) was {{established}} under Home Office control. It was intended that the UKWMO would provide both civil and military {{authorities in the}} UK with essential information during a nuclear attack, with the ROC providing primary data on the position and magnitude of atomic weapons detonated during any such attack. This data would {{be used by the}} UKWMO, in conjunction with weather information provided by the Meteorological Office, to produce a forecast of radioactive fallout. Fallout would be monitored as and where it occurred, with its actual location and strength mapped using data obtained from instrumentation at ROC posts. Such information when combined with ROCMet, (data concerning actual wind speed and direction obtained from <b>cluster</b> <b>Master</b> Posts equipped with wind anemometers and other basic meteorological instruments), would permit the dissemination of accurate forecasts predicting the distribution and strength of nuclear fallout.|$|E
30|$|Kafka has the {{following}} properties: it stores temporary data {{in its own}} file system, and each Consumer schedules its own task. Saving data in the storage nodes enables Kafka to recover the data without data loss when an error occurs. Although memory-based structures are typically faster than disk-based structures, the speed of data access in Kafka is {{comparable to that of}} memory-based structures because of efficient disk usage [20]. The second property indicates that a Kafka node need not wait for a job schedule from the <b>cluster</b> <b>master.</b> Therefore, bottleneck problems caused by scheduling can be avoided and the communication between nodes can be decreased, reducing the network load. Because of these properties, Kafka can be a suitable framework in a real-time environment, and it was validated in [21].|$|E
40|$|The City of St. Catharines, {{located on}} the {{southern}} shore of Lake Ontario, is Niagara Region's only major urban node. Like many small/medium-sized cities in Canada and abroad, the city experienced a rapid decline of large-scale manufacturing in the 1990 s. In a renewed attempt to recover from this economic depression, and spurred by Provincial policy, the City implemented the Downtown Creative <b>Cluster</b> <b>Master</b> Plan (DCCMP) in 2008. In this thesis I conduct a discourse analysis of the DCCMP. My analysis indicates that DCCMP is shaped by neoliberal economic development paradigms. As such {{it is designed to}} restructure the downtown into a creative cluster by attracting developers/investors and appealing to the interests, tastes, and desires of middle-class consumers and creatives. I illustrate that this competitive city approach to urban planning has a questionable track record, and has been shown to result in retail and residential gentrification and displacement...|$|E
30|$|Hadoop Cluster: The <b>cluster</b> {{contains}} a <b>master</b> node and two datanodes.|$|R
40|$|Energy {{efficient}} utilization is {{an important}} criteria and factor that affects the design of wireless sensor networks (WSNs). In this literature, we propose an energy distance aware clustering protocol with Dual Cluster Heads using Niching Particle Swarm Optimization (DCH-NPSO). The protocol selects two cluster heads in each <b>cluster,</b> the <b>Master</b> <b>Cluster</b> Head (MCH) and the Slave Cluster Head (SCH), and the selection needs to consider the network state information carefully and deliberately. Simulation {{results show that the}} protocol we proposed can balance the energy dissipation and extend the network lifetime effectively...|$|R
3000|$|In a Hadoop <b>cluster,</b> a <b>master</b> node {{controls}} a {{group of}} slave nodes by assigning tasks to the slave nodes based on their availability. In this section, we characterize the Hadoop framework based benchmarks performance and power on ATOM and Xeon-based systems: [...]...|$|R
40|$|Large-scale {{wireless}} sensor and actuator networks(LWSANs) are {{networks that}} consist of many sensor and/or actuator devices (i. e. > 1, 000 devices). These sensor and/or actuator devices (also called nodes) communicate wirelessly to deliver their sensor readings {{to one or}} more gateway devices in the network or to receive information {{from other parts of the}} networks to carry out actuation tasks or receive configuration information. This invention describes the organization of wireless communication for large-scale monitoring and actuation applications. Typically, these networks must be designed to use efficiently available bandwidth in the wireless communication channel and to be able to deal with high node densities. Envisioned deployments of such networks consist of several square kilometers of terrestrial surface with nodes every few square meters. This enormous deployment area, the high sensor density and the (potential) large data volume that must be transported (potentially near real-time) make an interesting challenge. This invention describes methodology to organize communication in LWSANs. Topics like spatial time slot and frequency allocation and medium access control protocols are discussed. The present invention relates to a communication method for high density wireless networks. The present invention also relates to a terminal for use in a high density wireless network. The present invention further relates to a <b>cluster</b> <b>master</b> device for use in a high density wireless network. The present invention also relates to a central node for use in a high density wireless network. Furthermore, the present invention relates to a system for use in a high density wireless network...|$|E
40|$|Abstract – Wireless Sensor Network is {{the network}} of {{power-limited}} sensing devices called sensors deployed in a region to sense various types of physical information from the environment when these sensors sense and transmit data to other sensors present in the network; considerable amount of energy is dissipated. In this paper, an effort {{has been done to}} propose F-MCHEL, a homogeneous energy protocol. In LEACH protocol the clusters are formed randomly on the basis of threshold values; whereas, in the proposed protocol a fuzzy logic approach is used to elect the cluster-head based on two descriptors- energy and proximity distance. Out of these elected <b>cluster</b> heads one <b>Master</b> <b>cluster</b> head has been elected. The cluster head which has the maximum residual energy is elected as <b>Master</b> <b>cluster</b> head. In conventional Leach approach all the Cluster heads are used to sends the aggregated information to the base station, however in the proposed protocol only <b>Master</b> <b>cluster</b> head sends the aggregated information to the base station. Simulation results on MATLAB shows that the proposed protocol provides higher energy efficiency, better stability period and lower instability period as compared to LEACH protocol in spite of overhead of election of <b>Master</b> <b>cluster</b> head. Results obtained shows that an appropriate Master cluster-head election can drastically reduce the energy consumption and enhance the lifetime of the network...|$|R
50|$|Awards he has {{received}} include the Defense Superior Service Medal, the Legion of Merit with oak leaf cluster, the Meritorious Service Medal with oak leaf cluster, the Joint Service Commendation Medal, the Air Force Commendation Medal with oak leaf <b>cluster,</b> the <b>Master</b> Astronaut Badge, and the Master Missile Badge.|$|R
40|$|One of {{the main}} reasons for protein {{clustering}} is prediction of structure, function and evolution. Many of current tools have disadvantage of high computational complexity due to all-to-all sequence alignment. If any tool works faster, it does not reach accuracy as other tools. Further disadvantage is processing on higher rate of similarity but homologous proteins can be similar with less identity. The process of clustering often ends when reach the condition which does not reflect sufficient quality of <b>clusters.</b> <b>Master's</b> thesis describes the design and implementation of new tool for clustering of protein sequences. New tool should not be computationally demanding but it should preserve required accuracy and produce better clusters. The thesis also describes testing of designed tool, evaluation of results and possibilities of its further development...|$|R
50|$|General Kimmons' awards {{include the}} Distinguished Service Medal with Oak Leaf Cluster, Defense Superior Service Medal with three Oak Leaf Clusters, Legion of Merit with two Oak Leaf <b>Cluster,</b> Bronze Star, <b>Master</b> Parachutist Badge, Joint Chiefs of Staff Identification Badge, and Army Staff Identification Badge.|$|R
30|$|The {{examination}} {{is conducted}} on 12 node Hadoop <b>clusters</b> with two <b>master</b> nodes (Namenode and Job tracker) and 10 slave nodes. Each node has an Intel Core (TM) i 7 - 4770 CPU@ 3.4  GHz having 8  GB RAM. The cluster works on Ubuntu 14.04, Java 1.8. 0 and Hadoop 2.7. 4.|$|R
30|$|The routing for {{wireless}} {{sensor network}} [2] (WSN) based on bionics heuristic algorithm {{has become one of}} the hot WSN research topics. Currently, ant colony algorithm [3], EEABR [4], MACS [5], and EPACOR [6] are utilized to find the best path from source to sink for {{wireless sensor network}}. In addition, ant colony optimization (ACO) [7], EAQR [8], QDV [9] not only solves the WSN network congestion, but also improves QOS and network security. Since the clustering algorithm has a good performance on the WSN routing, Salehpour et al. [10] proposed an efficient routing algorithm for large-scale WSN. This algorithm takes advantage of two routing levels. In the first level (intracluster), cluster members send data directly to their cluster head and the cluster head is selected by LEACH [11]. In the second level (inter-cluster), the cluster head uses ACO algorithm to find a route to the base station. ACDCHA [12] (Ant Colony-based Double Cluster-Heads Algorithm) is proposed by Su et al. through introducing the idea of ant colony algorithm. A <b>master</b> <b>cluster</b> head and a vice cluster head are selected in each cluster according to the pheromone concentration. The tasks such as data collection, fusion, transition, and so forth, are allocated, respectively, to these two kinds of cluster head. Simulation results show that this algorithm can get a better balance of the energy dissipation and prolong the network lifetime than the traditional clustering algorithm. The benefit of this algorithm is that the <b>master</b> <b>cluster</b> head only sends the data to the vice cluster head within the cluster, then the vice cluster head sends the data to base station, thus saving the energy of the <b>master</b> <b>cluster</b> head. However, when the <b>master</b> <b>cluster</b> head and vice cluster head are selected, only the residual energy of the node is considered; the node's location information is not taken into account, so the distance between vice-cluster head and base station maybe greater than the distance between the base station and the master cluster-head, resulting in more energy consumption for vice cluster head.|$|R
30|$|In the experiments, the Hadoop <b>cluster</b> {{contains}} one <b>master</b> node and 40 slave nodes, {{and each}} node contains an Intel Core i 3 3.1  GHz CPU, 8  GB memory, and 500  GB storage and runs Redhat Linux 6.1. In the slave nodes, each node is configured with two Map task slots and two Reduce task slots.|$|R
40|$|Specifications for {{the fuel}} {{assemblies}} Experimental Gas Cooled Reactor (EGCR) Core-I were developed {{for use in}} procuring the first core loading. A fuel assembly for the EGCR consists of a cluster of seven cylindrical fuel elements spaced and supported within a graphite sleeve. Each fuel element consists of a stainless-steel tube containing a column of hollow UO/sub 2 / pellets and having a spacer brazed at the midsection to control the spacing between fuel elements in a <b>cluster.</b> A <b>master</b> specification for the fuel assembly, a supplementary specification {{for each of the}} components, and a specification on record keeping daring manufacture are included. (auth...|$|R
50|$|A task in DrQueue is {{composed}} of multiple jobs all of which require a script which is distributed to the slave nodes of the <b>cluster</b> by the <b>master.</b> The master acts as a central server, where all tasks are stored. The slave software is run on each node in the cluster and it reports its status back to the master periodically.|$|R
30|$|We have {{implemented}} the newly introduced system architecture on commercial phones using Python for S 60 [13, 14] to evaluate its performance. The application is installed on both master and slave phones. When the web browsing session starts, a Bluetooth connection is established between them, {{in order to}} form the cooperation <b>cluster.</b> The <b>master</b> sends a request for the header of the specified web page to the web server, and the page request phase starts. After receiving this request, the web server replies to the phone by sending all {{the information about the}} requested page. Now the page download phase starts. We can divide this phase into two subphases: Web Page Processing Phase and Components Downloading Phase.|$|R
40|$|AbstractThis paper {{presents}} Fuzzy and Ant Colony Optimization (ACO) based MAC/Routing cross-layer protocol (FAMACRO) for Wireless Sensor Networks that encompases cluster head selection, clustering and inter-cluster routing protocols. FAMACRO uses {{fuzzy logic}} with residual energy, number of neighboring nodes {{and quality of}} communication link as input variables for cluster head selection. To avoid “hot spots”, FAMACRO uses an unequal clustering mechanism with <b>clusters</b> closer to <b>master</b> station having smaller sizes than those far from it. Finally, ACO techinque is used for reliable and energy-efficient inter-cluster routing from <b>cluster</b> heads to <b>master</b> station. The inter-cluster routing protocol decides relay node considering its residual energy, distance from current cluster head, distance from master station and packet reception rate. A comparative analysis of FAMACRO with Distributed Energy Efficient Hierarchical Clustering, Unequal Hybrid Energy Efficient Distributed Clustering, Energy Efficient Unequal Clustering and Improved Fuzzy Unequal Clustering protocol shows that FAMACRO is 82 % more energy-efficient, has 5 % to 30 % more network lifetime and sends 91 % more packets compared to Improved Fuzzy Unequal Clustering protocol...|$|R
30|$|Compared with APTEEN, ADCAPTEEN reduces energy dissipation, {{improves}} node survival rate, {{and extends}} network life cycle. The proposed algorithm has good scalability, {{and it is}} suitable for large-scale network. Because ADCAPTEEN optimizes the cluster head election method compared with APTEEN. And one <b>master</b> <b>cluster</b> head (MCH) and one vice cluster head (VCH) will be selected in each cluster. The double cluster heads (DCH) can co-work on data collection, fusion, transition, etc. MCH has no direct communication with sink node, and VCH performs most of energy consumption.|$|R
40|$|This paper {{proposes a}} new design of an {{efficient}} cluster head in wireless sensor head {{which is based}} on nested cluster head (sub cluster head). In Wireless Networks;cluster head is the key technology where nodes transmit the information to the base station. The energy consumption in a wireless network can be reduced by allowing only some nodes to communicate with the base station. One way to support efficient communication between sensors is to organize the network into several groups, called clusters, with each cluster electing one node as the head of cluster. To support scalability, nodes are often grouped into disjoint and mostly non-overlapping clusters. In nested cluster head approach instead of sensor nodes sends the data to cluster heads directly, each node sends data to sub <b>cluster</b> head and <b>master</b> node (<b>master</b> <b>cluster</b> head) sends the data to the base station. A cluster head can send and receive the message to their respective sub-cluster head and vice versa. This approach is used to save power consumption of cluster head. This paper deals about the frame work for energy conservation of a Wireless sensor network. The frame work is developed {{such a way that the}} nodes are to be clustered, electing the cluster head, performing intra cluster transmission and from the cluster head the information is transmitted to the base station...|$|R
40|$|Masteroppgave i informasjons- og kommunikasjonsteknologi 2008 – Universitetet i Agder, GrimstadIn today’s java community, modern {{enterprise}} application products have more constraints and requirements then ever. High availability, application scalability and also good performance are required, which means an application {{is needed to}} be deployed on multiple JVMs, in other words, {{it has to be}} clustered or distributed. It is essential for the application to scale out well, has better performance and less complexity during development of <b>clustering.</b> This <b>master</b> thesis focuses on clustering with Terracotta which is a JVM level clustering technique. First I start analyzing the complexity when an application comes into scale-out, and also analyzing the shortcomings of the common approaches to clustering an application. Then I do a deep dive to the Terracotta and demonstrate how to utilize Terracotta to conquer these problems with emphasis on providing scalability and high performance using natural java programming. Finally, various scenarios are made as benchmark tests. The final result has shown that Terracotta as redundancy solution is strong recommended to be implemented for high availability and high scalabilit...|$|R
40|$|In today’s java community, modern {{enterprise}} application products have more constraints and requirements then ever. High availability, application scalability and also good performance are required, which means an application {{is needed to}} be deployed on multiple JVMs, in other words, {{it has to be}} clustered or distributed. It is essential for the application to scale out well, has better performance and less complexity during development of <b>clustering.</b> This <b>master</b> thesis focuses on clustering with Terracotta which is a JVM level clustering technique. First I start analyzing the complexity when an application comes into scale-out, and also analyzing the shortcomings of the common approaches to clustering an application. Then I do a deep dive to the Terracotta and demonstrate how to utilize Terracotta to conquer these problems with emphasis on providing scalability and high performance using natural java programming. Finally, various scenarios are made as benchmark tests. The final result has shown that Terracotta as redundancy solution is strong recommended to be implemented for high availability and high scalabilit...|$|R
30|$|The Thor {{cluster is}} {{implemented}} using a master/slave topology {{with a single}} master and multiple slave processes, which provide a parallel job execution environment for programs coded in ECL. Each slave provides localized data storage and processing power within the distributed file system <b>cluster.</b> The Thor <b>master</b> monitors and coordinates the processing activities of the slave nodes and communicate status information. ECL programs are compiled into optimized C++ source code, which is subsequently linked into executable machine code distributed to the slave processes of a Thor cluster. The distribution of the code {{is done by the}} Thor master process. Figure 2 shows a representation of a physical Thor processing cluster.|$|R
40|$|Abstract. One of {{the biggest}} {{challenges}} encountered at PAN' 11 External Plagiarism Detection was the need for different clusterization methods for different types of plagiarism within the corpus. The existence of sparse sections of highly obfuscated, low obfuscated and translated plagiarism sections alongside with verbatim plagiarism parts, made single pass clusterization inefficient as it produced negative effects in one of the above cases. At PAN' 11 we used a single pass fixed length clusterization algorithm with a fixed value defining the maximum distance for cluster formation. The main issue with the fixed cauterization value is that large numbers (1600 - 1800) perform best for high obfuscation, medium (900) for translated and low (40) for verbatim sections. We decided to develop the system that will be able to either dynamically adjust the clusterization distance {{depending on the type of}} detected sections or try out multi-pass clusterization with different distance value with the exclusion of already detected clusters and heuristic post processing. For each detected cluster in several clusterization runs we measured Diagonal Density Distribution (DDD) and Mean Average Diagonal Fingerprint Distance (MADFD). These two values reflect the relative distribution of detected equal fingerprints within the cluster diagonal and allows to effectively tell which type of plagiarism is actually there. One more important role that these values play is the negation of cluster merging if the resulting DDD is less than any of the two clusters merged. This was particularly effective preventing accidental fingerprints merging the resulting clusters. Additionally we discovered that the total number of parameters that affect the system performance is already large and decided to apply the genetic algorithm in order to tackle the best possible meta values instead of picking them by hand. In PAN' 12 prototype application we employed a dot plot visualization with both detected <b>clusters</b> and <b>master</b> <b>clusters</b> overlay that allowed us to efficiently control the training process and to measure the overall progress for each separate document pair. ...|$|R
40|$|As {{the need}} for more {{reporting}} and assessment of information increase exponentially, computer-based applications consume resources at an alarmingly rapid rate. Therefore, traditional techniques for managing resource allocation, topology and systems need urgent revision. In this paper, we present an intelligent architecture that introduces a new strategy for managing resource discovery, allocation and dynamic reconfiguration at run-time. Our building methodology involves the employment of new types of clustered systems based on large application groupings, each having a <b>master</b> <b>cluster</b> controller. Each controlling engine consists of self-healing intelligent entities that can compensate for a variety of software or hardware problems. We also present evaluation results of extensive experiments in a production environment, which demonstrate the advantages of our approach...|$|R
40|$|Most of {{the local}} {{seismicity}} in the Ruhr Basin can be separated into characteristic clusters of similar, mining induced earthquakes. Each cluster can be represented by a strong master event. Therefore, {{it is possible to}} associate weak events to the corresponding <b>clusters</b> by <b>master</b> event comparison. The seismic signal matching is performed by a nonlinear correlation termed DWM for the entire seismogram length. DWM permits stretchings and shortenings between the two signals and overcomes the ambiguities in phase correlation by a consistent matching path. The automatic cluster association searches for the best DWM-correlation between the actual event and all master events of the appropriate epicenter region. Knowing the P- and S-onsets of the master event, they can be transposed to the actual event by the correlation path with one sample accuracy. The method has been applied to all BUG small array recordings 1987 – 1990 of local events from the Hamm-region to investigate spatial and temporal clustering. Within the clusters, a high percentage of weak events could be located relative to its master event. The temporal clustering resolved seismic activities that typically last a few months per cluster, but single aftershocks occur in the following years...|$|R
30|$|Figure  8 depicts {{that now}} that the network {{bottleneck}} is removed, our deployment scheme achieves to execute the configuration phase in practically constant time, regardless {{of the number of}} deployed VMs. This behavior drastically changes the relationships between the times of the deployment phases, making the resource allocation phase dominant of the entire deployment, whereas, again, the booting time is constant and the configuration phase presents marginal increase with the number of deployed VMs. Moreover, note that the absolute times remain extremely low: AURA achieved to deploy a Hadoop <b>cluster</b> of 1 <b>Master</b> and 8 Slaves in less that 200 s, a time that can be further decreased if AURA operates on an enterprise cluster with a faster storage medium that accelerates resource allocation.|$|R
40|$|Master thesis {{deals with}} {{dividing}} destricts of the Czech Republic in to clusters acording to demographic indicators {{during the year}} 2011. After the theoretical introduction with exploratory data analyiss, factor analysis and cluster analysis is described practical implementation of agglomerative hierarchical clustering. Within the frame cluster analysis we compare results calculated by four methods of clustering, which are the single linkage method, the complete linkage method, the average linkage method and Ward's method. At the conclusion we select the method which divides destricts of the Czech Republic in to the <b>clusters</b> the best. <b>Master</b> thesis includes a prezentations of discovere results {{with the help of}} dendrograms and cartograms. The analysis were carried out {{with the help of the}} statistical program STATISTICA...|$|R
40|$|Heterogeneous cluster-based {{wireless}} sensor networks (WSN) attracted increasing attention recently. Obviously, the clustering {{makes the}} entire networks hierarchical; thus, several kinds of keys are required for hierarchical network topology. However, most existing key management schemes for it place more emphasis on pairwise key management schemes or key predistribution schemes and neglect the property of hierarchy. In this paper, we propose a complete hierarchical key management scheme which only utilizes symmetric cryptographic algorithms and low cost operations for heterogeneous cluster-based WSN. Our scheme considers four kinds of keys, which are an individual key, a <b>cluster</b> key, a <b>master</b> key, and pairwise keys, for each sensor node. Finally, the analysis and experiments demonstrate that the proposed scheme is secure and efficient; thus, it is suitable for heterogeneous cluster-based WSN...|$|R
40|$|TTP/A is the {{fieldbus}} protocol of the Time Triggered Architecture (TTA). It provides periodic {{transmission of}} real-time data {{and allows for}} on-line configuration, diagnostics, and maintenance by use of an interface file system. It is well integrated with the TTP/C protocol and is {{designed to meet the}} requirements of a low-cost sensor/actuator bus. TTP/A is a master-slave protocol where the master establishes a common time base within a TTP/A <b>cluster.</b> Since the <b>master</b> establishes the time base prior to the communication of slaves, the protocol can be implemented with imprecise on-chip RC oscillators for the slaves. Using a standard UART-based serial interface as physical layer, the slave TTP/A protocol can be implemented in very low cost Commercial Off-The-Shelf (COTS) hardware...|$|R
40|$|Piwi proteins, a {{subclass}} of Argonaute-family proteins, carry ∼ 24 – 30 -nt Piwi-interacting RNAs (piRNAs) that mediate gonadal {{defense against}} transposable elements (TEs). We analyzed the Drosophila ovary somatic sheet (OSS) cell line {{and found that}} it expresses miRNAs, endogenous small interfering RNAs (endo-siRNAs), and piRNAs in abundance. In contrast to intact gonads, which contain mixtures of germline and somatic cell types that express different Piwi-class proteins, OSS cells are a homogenous somatic cell population that expresses only PIWI and primary piRNAs. Detailed examination of its TE-derived piRNAs and endo-siRNAs revealed aspects of TE defense that do not rely upon ping-pong amplification. In particular, we provide evidence that a subset of piRNA <b>master</b> <b>clusters,</b> including flamenco, are specifically expressed in OSS and ovarian follicle cells. These data indicate that the restriction of certain TEs in somatic gonadal cells is largely mediated by a primary piRNA pathway...|$|R
40|$|As a large-scale, {{high-density}} multi-hop network becomes desirable in many applications, {{there exists}} a greater demand for scalable mobile ad hoc network (MANET) architecture. Due to the increased route length between two end nodes in a multi-hop MANET, the challenge is in the limited scalability despite the improved spatial diversity in a large network area. Common to most of existing approaches for a scalable MANET is the link cluster architecture (LCA), where mobile nodes are logically partitioned into groups, called clusters. <b>Clustering</b> algorithms select <b>master</b> nodes and maintain the cluster structure dynamically as nodes move. Routing protocols utilize the underlying cluster structure to maintain routing and location information in an efficient manner. This paper discusses the various issues in scalable clustered network architectures for MANETs. This includes a classification of link-clustered architectures, an overview of clustering algorithms focusing on master selection, and a survey of cluster-based routing protocols...|$|R
40|$|Due to {{the problem}} of balance for energy {{consumption}} in underwater wireless sensor networks (UWSNs), a cluster-based routing protocol for UWSNs based on an improved K-means algorithm was proposed. This algorithm was used for clustering in underwater sensor networks to avoid unbalanced clustering which could happen in LEACH protocol. Considering the depth of nodes and their densities around, the initial centers of clusters can be selected by the maximum distance method. The <b>master</b> <b>cluster</b> heads and the aided cluster heads can be chosen with the consideration of the residual energy of nodes, the distance between nodes and the cluster center and the distance between nodes and the base station. It can share the energy consumption reasonably. The network simulation results show that the proposed algorithm can effectively balance the energy consumption, prolong the network lifetime, and increase the amount of data transmission compared with LEACH and LEACH-L protocols...|$|R
40|$|Suppose {{data for}} a survey with {{multi-stage}} design {{is to be}} collected in two periods of time. This paper assesses {{the relative merits of}} keeping the same clusters in the sample vs. sampling new clusters, under different statistical (correlation between clusters and over time) and logistical (costs of survey) scenarios. The design effect of re-using the same <b>clusters</b> from the <b>master</b> sample over time is of the form 1 A n − /ρπ where ρ is intertemporal correlation of the cluster totals, n is the number of clusters, π is the proportion of clusters retained from the previous round, and 0 A> is a fixed constant. As long as the efficiency gains appear to be minor, the value of the designs that reuse the clusters comes from the logistical (cost of the survey) considerations. Empirical demonstration that uses Demographic and Health Survey (DHS) data fo...|$|R
40|$|Thesis (MSc (Space Physics)) [...] North-West University, Potchefstroom Campus, 2012. The {{majority}} of galaxy clusters contain a massive galaxy in {{the centre of}} the clusters that are far more luminous and massive than the other galaxies in the cluster. These galaxies are called the brightest galaxy clusters (BCGs) and the formation and evolution of these BCGs are intimately related to the formation of the host clusters. In this project, the star formation histories (SFHs) of 51 galaxies (49 BCGs and two ellipticals) were determined by using high signal–to–noise ratio, long–slit spectra. The spectra of the galaxies were fitted against the software package ULySS which is a stellar population synthesis code. Two stellar population models, the Pegase. HR (P. HR) and the Vazdekis/MILES were used to determine the SFHs of the galaxies, more specifically determine whether a single stellar population (SSP) or composite stellar population (CSP) provided the most probable representation of the SFHs. Additional parameters, such as the velocity dispersions of the galaxies, the redshifts, the error spectra and the wavelength range were defined to extend these models. The observed spectra were then respectively fitted against a SSP and CSP. A series of 500 Monte–Carlo simulations were then preformed to asses the relevance of the solutions and aided in the selection of the most probable SFHs of the BCGs. The c 2 maps were then drawn to assist in the understanding {{of the structure of the}} parameter space. The SFHs of the galaxies were given in the form of stellar components characterised by the derived ages and metallicities ([Fe/H]). The derived parameters were then compared against those derived with the LICK Indices to determine whether these approaches produced consistent results. Lastly, the derived parameters were tested against the internal galaxy properties (the velocity dispersions and absolute K–band magnitudes) and the properties of the host cluster environment (the X–ray temperatures, luminosities, offsets and the presence of cooling flows (CFs)) to determine whether any correlations could be derived to shed light on the formation and evolution of the BCGs. The results indicate that the P. HR model gave the most probable representation of the SFHs of the sample. Although 55 % of the sample could be represented by a single star formation epoch, the remaining 45 % had a more complex SFH. The ages, derived by the P. HR and LICK Indices showed significant consistency when compared but the [Fe/H] did not because the current P. HR model does not include a enhancements. 14 galaxies contained CFs. No correlations could be found between the internal properties (velocity dispersion and the absolute K–band magnitudes) and the ages/[Fe/H] but it was found that clusters containing CFs were located at higher luminosities than those without CFs. No correlations could be found between the ages/[Fe/H] and the X–ray temperatures. The intermediate aged galaxies with CFs were located closer to the centre than the old aged galaxies with CFs. These results indicated that at least some of the galaxies in the sample had a more complex SFH than first assumed and the presence of the CFs could account for some, but not all of the star formation activities in the <b>clusters.</b> <b>Master...</b>|$|R
40|$|A visual {{cryptography}} based watermarking scheme {{incorporating the}} concepts of singular value decomposition (SVD) and the homogeneity analysis of the cover image is proposed here. Firstly, feature vectors are created from the singular values of the homogeneous blocks and thereby classified using the k-medoid <b>clustering</b> technique. A <b>master</b> share is then constructed based on the clustering result and thereafter, combined with the secret binary image (watermark) ownership share is build up. This ownership share is registered with the certificate authority in case to resolve any dispute regarding rightful ownership of the image in future. A two-out-of-two visual cryptography scheme is {{being used in the}} proposed methodology and robustness validated by applying comprehensive set of attacks. The peak signal to noise ratio (PSNR) and normalized cross correlation (NCC) metric values are used for evaluation of the scheme. Higher values of these metrics establish the appropriateness of the proposed methodology as compared to the other state of art schemes for copyright protection...|$|R
