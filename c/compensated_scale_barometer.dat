0|62|Public
3000|$|... {{is a good}} {{approximate}} of {{the ratio}} between {{the energy of the}} reference filter and that of the decimated one. Thus, this effect of decimation is <b>compensated</b> by <b>scaling</b> [...]...|$|R
40|$|We {{extend the}} ideas of (Barbour 1990) and use Stein's method to obtain a bound on the {{distance}} between a scaled time-changed random walk and a time-changed Brownian Motion. We then apply this result to bound the distance between a time-changed <b>compensated</b> <b>scaled</b> Poisson process and a time-changed Brownian Motion. This allows us to bound the distance between a process whose dynamics resemble those of the Moran model with mutation and a process whose dynamics resemble those of the Wright-Fisher diffusion with mutation upon noting that the former may be expressed as a difference of two time-changed Poisson processes and the diffusive part of the latter may be expressed as a time-changed Brownian Motion. The method is applicable to a much wider class of examples satisfying the Stroock-Varadhan theory of diffusion approximation...|$|R
50|$|Balayan {{falls under}} the first type of climate: Dry season from November to April and Wet season from May to October. Balayan’s Atmospheric Temperature is 28.5 inches - 29.8 inches (English Mercurial <b>Barometer</b> <b>Scale).</b> The average annual {{temperature}} in Balayan is 27.2 C. The Average Annual Rainfall is 73.39 in.|$|R
5000|$|If {{we allow}} [...] to <b>scale</b> and <b>compensate</b> for the <b>scaling</b> in the {{constant}} factor, we potentially can have simpler recurrences of the form: ...|$|R
40|$|When {{trying to}} model {{molecular}} processes, one often comes against {{the problem of}} how to <b>compensate</b> between <b>scales.</b> On one hand, there is the fact that observable phenomena occur at the macroscopic scale, and so often times we average out the interactions to get a general equation for our appropriate scale. On the other hand, the microscopic interactions can and d...|$|R
40|$|We {{study the}} {{automatic}} localization and identification of African clawed frogs (Xenopus laevis sp.) in digital images {{taken in a}} laboratory environment. We propose a novel and stable frog body localization and skin pattern window extraction algorithm. We show that it <b>compensates</b> <b>scale</b> and rotation changes very well. Moreover, {{it is able to}} localize and extract highly overlapping regions (pattern windows) even in the cases of intense affine transformations, blurring, Gaussian noise, and intensity transformations. The frog skin pattern (i. e. texture) provides a unique feature for the identification of individual frogs. We investigate the suitability of five different feature descriptors (Gabor filters, area granulometry, HoG, 1 dense SIFT, 2 and raw pixel values) to represent frog skin patterns. We compare the robustness of the features based on their identification performance using a nearest neighbor classifier. Our experiments show that among five features that we tested, the best performing feature against rotation, scale, and blurring modifications was the raw pixel feature, whereas the SIFT feature was the best performing one against affine and intensity modifications...|$|R
5000|$|In a metal the {{resistivity}} at {{low temperatures}} {{is dominated by}} electron-electron scattering in combination with umklapp scattering. For a Fermi liquid, the resistivity from this mechanism varies as , which is often taken as an experimental check for Fermi liquid behaviour (in addition to the linear temperature-dependence of the specific heat), although it only arises {{in combination with the}} lattice. In certain cases, umklapp scattering is not required. For example, the resistivity of <b>compensated</b> semimetals <b>scales</b> as [...] because of mutual scattering of electron and hole. This is known as the Baber mechanism.|$|R
50|$|Generalized Procrustes {{analysis}} {{estimates the}} scaling factor applied to respondent scale usage, thus it generates a weighting factor {{that is used}} to <b>compensate</b> for individual <b>scale</b> usage differences. Unlike measures such as a principal component analysis, since GPA uses individual level data, a measure of variance is utilized in the analysis.|$|R
5000|$|CU Amiga {{called the}} game [...] "original, good to look at, {{excellent}} {{to play and}} varied throughout." [...] CU Amiga wrote that the game's overhead perspective [...] "plays {{a lot better than}} it looks", and complimented the dinosaur animations. CU Amiga particularly praised the game's first-person mode for [...] "some amazing 3D graphics" [...] but also wrote that the [...] "smoothly-scrolling backgrounds aren't as detailed as they could have been considering they are on the 1200, but the dinosaur graphics more than <b>compensate.</b> The <b>scaling</b> as they come towards you is pixel-perfect with no nasty blockiness to spoil the atmosphere." ...|$|R
40|$|While {{algorithmic}} {{autonomous agent}} control architectures demonstrate high efficiency, they suffer from network structure rigidity that {{shows in the}} liability to crucial errors. On the other hand, the redundancy inherent i n most connectionist architectures allows for continuous s elf-organization that <b>compensates</b> for limited <b>scale</b> local neuron failures. In this article, we a re investigating the relation between algorithmicity an...|$|R
40|$|Abstract. Recently, a {{reconstruction}} algorithm for {{region of interest}} (ROI) imaging in C-arm CT was published, named Approximated Trun-cation Robust Algorithm for Computed Tomography (ATRACT). Even in presence of severe data truncation, {{it is able to}} reconstruct images without the use of any explicit extrapolation or prior knowledge. Howe-ver, this method suffers from a scaling artifact in the reconstruction. In this paper, we have investigated a calibration applied in the projecti-on domain to <b>compensate</b> this <b>scaling</b> problem. The proposed correction method is evaluated by using six clinical datasets in presence of different artificial truncation. The results show that a relative root mean squa-re error (rRMSE) of up to 0. 9 % is achieved by the corrected ATRACT method. ...|$|R
40|$|The article {{presents}} {{the state of}} the art and perspectives of the Finnish builders’ carpentry Industry and the role of the small firms. It is identified that firms producing prefabricated components to BtoC markets do not supply their products to BtoB markets and vice versa. Domestic markets of single dwelling house construction have been growing during the recent years. There is a large demand potential opening up by the replacment of concrete by wood in the frame construction for multi storey dwelling buildings. The competitive structure of the industry as one determinant of business performance is evaluated with respect to suppliers (supply chain), entrants (entry barriers), buyers, rivals and substitutes. Despite of high cost, differentiation is used by firms in the industry as the major competitive strategy. Lack of knowledge and skills in strategic management, low innovativeness and low marketing competencies are common. Exports do not show any positive impact on business performance. Human capital rather than technology is a strategic but scarce resource. Subcontracting is common but partnerships in production and procurement are rare. There is large variation in the degree of process integration. Differentiation strategy, i. e. broadening competitive scope, implies flexible manufacturing systems with sufficient manufacturing capacity and a sufficient number of product variants. Small firms encounter restrictions with respect to the endowment of human and financial capital. At the end the {{article presents}} some factors of success for small firms in the Finnish builders’ carpentry industry. Differentiation strategy hardly does provide a competitive advantage for small firms without extended networking. Business networking can allow small firms to <b>compensate</b> <b>scale</b> disadvantages when focusing into narrow demand segments. The preconditions for small firms to enter a BtoB partnership with a construction company are process automation and exploitation of IT-technologies, integrated information management and the implementation of an open construction system. ...|$|R
40|$|For {{each type}} of number, {{structures}} that differ by arbitrary scaling factors and are isomorphic to one another are described. The scaling of number values in one structure, relative to the values in another structure, must be <b>compensated</b> for by <b>scaling</b> of the basic operations and relations (if any) in the structure. The scaling must be such that one structure satisfies the relevant number type axioms {{if and only if}} the other structure does. Comment: 23 pages, 1 figur...|$|R
40|$|The Sustainability Indicators are {{parameters}} {{that characterize}} past events, evidence situational {{portraits of the}} present and assist in projecting future scenarios in relation to sustainability. These instruments allow periodic checks {{of the process of}} sustainable development at various <b>scales.</b> The <b>Barometer</b> of Sustainability fits this proposal, because, treating men and nature equally, it assesses the degree of sustainability and has been used from local to national scope. Within this perspective, the basic aim of this research was to analyze the quality dimension of water resources in the development of this instrument, taking as an example the city of Ribeirão Preto, SP, Brazil. The adopted methodology had as its main foundation the Seven Stages Cycle for implementing the Barometer of Sustainability. The Barometer of Sustainability as an assessment tool has proved to be useful in contributing to the understanding of natural phenomena, being relevant to the analysis of water resources at the local level. This tool is a component part of an environmental management process and cannot be considered alone. The Barometer of Sustainability showed that Ribeirão Preto is at a reasonable level in relation to the water resources which were analyzed and considered in the research. The index of the theme Water, originated from the assessment tool, showed the highest value among the other topics discussed in the Ecological Subsystem for the city, being in health and environmental compliance...|$|R
40|$|Many {{electronic}} watermarks {{for still}} images and video content {{are sensitive to}} geometric distortions. For example, simple rotation, scaling, and/or translation (RST) of an image can prevent blind detection of a public watermark. In this paper, we propose a watermarking algorithm that is robust to RST distortions. The watermark is embedded into a one-dimensional (1 -D) signal obtained by taking the Fourier transform of the image, resampling the Fourier magnitudes into log-polar coordinates, and then summing a function of those magnitudes along the log-radius axis. Rotation of the image results in a cyclical shift of the extracted signal. Scaling of the image results in amplification of the extracted signal. And translation of the image {{has no effect on}} the extracted signal. We can therefore compensate for rotation with a simple search, and <b>compensate</b> for <b>scaling</b> by using the correlation coefficient as the detection measure. Fals...|$|R
40|$|We study {{holographic}} momentum relaxation in {{the limit}} {{of a large number of}} spacetime dimensions D. For an axion model we find that momentum conservation is restored as D becomes large. To <b>compensate</b> we <b>scale</b> the strength of the sources with D so that momentum is relaxed even at infinite D. We analytically obtain the quasi-normal modes which control electric and heat transport, and give their frequencies in a 1 /D expansion. We also obtain the AC thermal conductivity as an expansion in 1 /D, which at leading order takes Drude form. To order 1 /D our analytical result provides a reasonable approximation to the AC conductivity even at D= 4, establishing large D as a practical method in this context. As a further application, we discuss the signature of the transition from coherent to incoherent behaviour known to exist in the system for finite D. Comment: 19 pages, 2 figure...|$|R
40|$|When first introduced, the cross-ratio (CR) based remote eye {{tracking}} method offered many attractive features for natural human gaze-based interaction, such as simple camera setup, no user calibration, and invariance to head motion. However, due to many simplification assumptions, current CR-based methods are still sensitive to head movements. In this paper, we revisit the CR-based method and introduce two new extensions {{to improve the}} robustness of the method to head motion. The first method dynamically <b>compensates</b> for <b>scale</b> changes in the corneal reflection pattern, and the second method estimates true coplanar eye features so that the cross-ratio can be applied. We present real-time implementations of both systems, and compare the performance of these new methods using simulations and user experiments. Our results show a significant improvement in robustness to head motion and, for the user experiments in particular, an average reduction of up to 40 % in gaze estimation error was observe...|$|R
40|$|A {{fundamental}} problem posed {{to the visual}} system is the estimation of depth from the twodimensional image sensed at the retina. In mammals, under certain viewing and environmental conditions, the physical mapping between retinal and cortical cells appears to <b>compensate</b> for <b>scaling</b> and foreshortening effects (at the retina) by reconstructing the relative spatial layout of environmental points {{on the surface of}} the striate cortex. Johnston (1986) proposed that relative distances along visual meridia are preserved in a mapping of the striate cortex onto a conic environmental surface, with apex in line with the point of fixation and base in the same plane as the lens of the eye. Johnston (1986) went onto suggest how the geometric properties of this conic model could be used in computation of depth, surface slant and self-motion. Through simulating Johnston’s inverse conic transformation on images and image sequences, this paper demonstrates how the model may be used in estimation of depth, surface-slant and self-motion. Results have implications for visual psychology, computer vision and robotic control. ...|$|R
40|$|While {{computed}} tomography (CT) has since long {{been used for}} medical applications and material inspection, its application field has recently been broadened to include dimensional metrology in industry. However, the accuracy and repeatability of CT-based measurements remain yet largely uncertain. Not only are the measurements influenced {{by a number of}} factors and parameters like e. g. voltage, current, magnification, object thickness, … but also the calibration method is of major concern (both for scale errors as well as for offset errors). This paper investigates the influence of the power settings (voltage and current) on the accuracy and repeatability of dimensional measurements. Experiments show that after rescaling the pixel size (to <b>compensate</b> for <b>scale</b> errors), the accuracy still remains dependent on the energy used. After correction of the edge threshold value (offset error), measurement results become less dependent on the voltage and current used and are more repeatable. Beam hardening effects cause the material thickness of the measurand to be another important parameter. Using spheres of different sizes, the dependence of the edge offset error on the sphere diameter is investigated. status: publishe...|$|R
40|$|A {{dimensional}} {{analysis of the}} problem of vessels transiting level continuous ice is presented. Resistance is divided into components and each is analyzed to identify dimensionless terms relevant to the individual component. These expressions provide a framework for scaling ship-ice model test results. A workable subset of scaling requirements for a three-component division of the problem is derived from the general case. Some experimental results are presented demonstrating the utility of the method. It is shown that {{it may be possible to}} <b>compensate</b> for poor <b>scaling</b> in ice properties by scaling each component based on its own law of similitude. Peer reviewed: NoNRC publication: Ye...|$|R
40|$|Abstract — Existing Nonlinear {{dimensionality}} reduction (NLDR) algorithms {{make the}} assumption that distances between observations are uniformly scaled. Unfortunately, with many interesting systems, this assumption does not hold. We present a new technique called Temporal NLDR (TNLDR), which is specifically designed for analyzing the high-dimensional observations obtained from random-walks with dynamical systems that have external controls. It uses the additional information implicit in ordered sequences of observations to <b>compensate</b> for non-uniform <b>scaling</b> in observation space. We demonstrate that TNLDR computes more accurate estimates of intrinsic state than regular NLDR, and we show that accurate estimates of state {{can be used to}} train accurate models of dynamical systems. I...|$|R
40|$|SMR (Small Modular Reactor) is {{an acronym}} {{for a group of}} nuclear power plant designs {{receiving}} an increasing deal of attention from the industry and policy makers. A large number of SMRs need to be built in the same site and across the word to <b>compensate</b> diseconomies of <b>scale</b> and be cost competitive with large reactors and other base-load technologies. A major barrier is the licensing process, historically developed for large reactors, preventing the simply deployment of several identical units in different countries. This paper, discussing Ramana, Hopkins and Glaser [1], enlarges the view to all the SMR-related implications on the licensing process, presenting their legislative implications and market effects...|$|R
40|$|This paper {{presents}} an interesting observation that epipolar geometry and log–polar transform can be naturally combined by setting {{the center of}} the log–polar transform into the epipoles. This choice preserves the linearity of the epipolar lines. Moreover, the setting is especially advantageous, when camera moves towards the optical axis of the camera as the log–polar transform <b>compensates</b> the large <b>scale</b> changes in the scene. This practically implies that conventional matching techniques can be used with wide baseline images. We discuss the approach with both calibrated and uncalibrated cameras and show some dense wide baseline reconstruction examples where the epipoles are close to the image centers. 1...|$|R
5000|$|Merchant fleets usually {{refers to}} Chartist captains, who {{are given a}} charter {{allowing}} them to ply a given warp route or sector, usually in slow going ships that usually lack a navigator. Instead, these trading vessels make use of short [...] "hops" [...] through the warp based upon cognitor algorithms and some degree of risky guess work in every given hop. These trips between systems can take anywhere from months to years, even centuries. As such, these chartist vessels tend to be gargantuan in <b>scale,</b> <b>compensating</b> with sheer capacity and often decent armaments for their lack of speed and attendant escort vessels by being too large and requiring the application of overwhelming amounts of firepower to raid effectively.|$|R
40|$|Registering {{consecutive}} {{images from}} an airborne sensor into a mosaic {{is an essential}} tool for image analysts. Strictly local methods tend to accumulate errors, resulting in distortion. We propose here to use a reference image (such as a high resolution map image) to overcome this limitation. In our approach, we register a frame in an image sequence to the map using both frame-to-frame registration and frameto-map registration iteratively. In frame-to-frame registration, a frame is registered to its previous frame. With its previous frame been registered to the map in the previous iteration, we can derive an estimated transformation from the frame to the map. In frame-to-map registration, we warp the frame to the map by this transformation to <b>compensate</b> for <b>scale</b> and rotation difference and then perform an area based matching using Mutual Information to find correspondences between this warped frame and the map. From these correspondences, we derive a transformation that further registers the warped frame to the map. With this two-step registration, the errors between each consecutive frames are not accumulated. We present results on real image sequences from a hot air balloon. 1...|$|R
40|$|Magnetometer, {{misalignment}} {{error and}} distortion field {{can reduce the}} accuracy of gradiometers. So, {{it is important to}} calibrate and <b>compensate</b> gradiometers error. <b>Scale</b> factor, bias, nonorthogonality, misalignment and distortion field should be considered. A gradiometer is connected by an aluminium frame, which contains two fluxgate magnetometers. A nonmagnetic rotation equipment is used to change gradiometer attitude, and the compensation parameters are estimated. Experiment results show that, after calibration and compensation, error of each axis is reduced from 888. 4 nT, 1292. 6 nT and 168. 9 nT to 15. 3 nT, 22. 1 nT and 9. 9 nT, respectively. It shows that the proposed method can calibrate gradiometer and compensate distortion field. After calibration and compensation, the object remote sensing performance is improved...|$|R
40|$|Abstract—Many {{electronic}} watermarks {{for still}} images and video content {{are sensitive to}} geometric distortions. For example, simple rotation, scaling, and/or translation (RST) of an image can prevent blind detection of a public watermark. In this paper, we propose a watermarking algorithm that is robust to RST distortions. The watermark is embedded into a one-dimensional (1 -D) signal obtained by taking the Fourier transform of the image, resampling the Fourier magnitudes into log-polar coordinates, and then summing a function of those magnitudes along the log-radius axis. Rotation of the image results in a cyclical shift of the extracted signal. Scaling of the image results in amplification of the extracted signal. And translation of the image {{has no effect on}} the extracted signal. We can therefore compensate for rotation with a simple search, and <b>compensate</b> for <b>scaling</b> by using the correlation coefficient as the detection measure. False positive results on a database of 10 000 images are reported. Robustness results on a database of 2000 images are described. It is shown that the watermark is robust to rotation, scale, and translation. In addition, we describe tests examining the watermarks resistance to cropping and JPEG compression. Index Terms—Fourier–Mellin, rotation, RST, scale, translation, watermarking...|$|R
40|$|Abstract. Linear transformations (shear or scale transformations) {{of either}} {{horizontal}} or vertical disparity {{give rise to}} the percept of slant or inclination. It has been proposed that the percept of slant induced by vertical size disparity, known as Ogle's induced-size effect, and the analogous induced-shear effect, <b>compensate</b> for <b>scale</b> and shear distortions arising from aniseikonia, eccentric viewing, and cyclodisparity. We hypothesised that these linear transformations of vertical disparity are processed more slowly than equivalent transformations of horizontal disparity (horizontal shear and size disparity). We studied the temporal properties of the stereoscopic slant and inclination percepts that arose when subjects viewed stereograms with various combinations of horizontal and vertical size or shear disparities. We found {{no evidence to support}} our hypothesis. There were no clear differences in the build-up of percepts of slant or inclination induced by step changes in horizontal size or shear disparity and those induced by step changes in vertical size or shear disparity. Perceived slant and inclination decreased in a similar manner with increasing temporal frequency for modulations of transformations of both horizontal and vertical disparity. Considerable individual differences were found and several subjects experienced slant reversal, particularly with oscillating stimuli. An interesting finding was that perceived slant induced b...|$|R
40|$|Directional gap {{probability}} or gap fraction is a {{basic parameter}} in the optical remote sensing modeling. Although some approaches have been proposed to estimate this gap probability from remotely sensed measurements, few efforts {{have been made to}} investigate the scaling effects of this parameter. This paper analyzes the scaling effect through aggregating the high-resolution directional gap probability (pixel size of 20 meters) estimated from leaf area index (LAI) images of VALERI database by means of Beer's law and introduces an extension of clumping index, (C) over cap, to <b>compensate</b> the <b>scaling</b> bias. The results show that the scaling effect depends on both the surface heterogeneity and the nonlinearity degree of the retrieved function. Analytical expressions for the scaling bias of gap probability and (C) over cap are established in function of the variance of LAI and the mean value of LAI in a coarse pixel. With the VALERI dataset, the study in this paper shows that relative scaling bias of gap probability increases with decreasing spatial resolution for most of land cover types. Large relative biases are found for most of crops sites and a mixed forest site due to their relative large variance of LAI, while very small biases occur over grassland and shrubs sites. As for (C) over cap, it varies slowly in the pure forest, grassland and shrubs sites, while more significantly in crops and mixed forest...|$|R
40|$|The {{purpose of}} this study was to {{investigate}} how the CNS adjusts motor patterns for variants of a complex axial movement-the situp. Adjustments were induced by changing the support surface contact and mass distribution of the body. Healthy adults performed straight-legged sit-ups, 3 s in duration, with support added to or removed from the lumbar trunk, or with mass added to the head or to the legs. Each of these interventions either increased or decreased the difficulty of the task. The study addressed the extent to which changes in sit-up difficulty are <b>compensated</b> by <b>scaling</b> of muscle activity, kinematics, and dynamics versus the extent to which they are compensated by changing discretely the motor pattern. The analysis of muscle activity, kinematics, and dynamics focused on the first 30 - 40 % of the sit-up-the trunk flexion phase-since this is the most critical part of the movement. Our results demonstrate that, in some respects, sit-up kinematics and dynamics scaled with difficulty, but in other respects, they did not. Muscle activity also scaled, in many respects, but in more difficult sit-ups, abdominal flexor activity decreased instead of increased. Non-scaling changes in these parameters suggest that complex movements, such as the sit-up, may require discrete changes in motor pattern in order to deal with large loads, which challenge the available leverage. (C) 2005 Elsevier Ltd. All rights reserved...|$|R
40|$|While {{algorithmic}} {{autonomous agent}} control architectures demonstrate high efficiency, they suffer from network structure rigidity that {{shows in the}} liability to crucial errors. On the other hand, the redundancy inherent in most connectionist architectures allows for continuous self-organization that <b>compensates</b> for limited <b>scale</b> local neuron failures. In this article, we are investigating the relation between algorithmicity and plasticity and attempt a compromise by extending a basic algorithmic cell model. At first, we introduce motivation : the cell becomes a system of multiple independent drives capable of recognizing and consuming different kinds of messages and in competition with one another {{for the use of}} the cell resources. Messages may be consumable or catalytic and have identification templates that excite the corresponding cell drives. Those templates are expressed as continuous numeric variables, thus as eigenfrequencies. Unlike usual connectionist models, there are no co [...] ...|$|R
30|$|Although {{the above}} {{location}} estimation procedure can <b>compensate</b> the large <b>scale</b> location error, the unstable wireless link {{caused by the}} NLOS condition may still disturb the geographic routing procedure. Moreover, {{it is difficult for}} the mobile device to detect the NLOS link accurately, since the LOS and NLOS conditions of the mobile device are continuously changing. To solve the NLOS link problems, we propose a dynamic link detection approach for the NLOS environments. In the geographic routing, each mobile device periodically performs the RNG or GG planarization by using the beacon messages received from its neighbor devices. Based on the information of the received beacon messages, the proposed approach constructs the two RNG topologies: One is an RNG topology based on the location through the proposed location estimation, and the other is an RNG topology based on the ranging distances with the neighbor devices.|$|R
3000|$|..., the {{relative}} location and scale of part i {{with respect to}} part j [27]. Note that the distances dx and dy for part i and j are defined {{with respect to a}} root level factor r, scaled by s which is derived from the pyramid layer at which the deformation takes place. We allow each part to have its own spatial resolution. r compensates for the resolution difference between i and j that occurs when parts have a different spatial resolution. In practice, we only allow two different resolutions. This allows us to quickly find candidate detections for some parts at a coarse level, on which a localization of fine-grained pose and motion cues at double the resolution can be detected for other parts. s on the other hand <b>compensates</b> for the <b>scale</b> difference between i and j, that occurs because we scaled responses w_i·ϕ_i(I,l_i) [...] by ϑ [...]...|$|R
40|$|Molecular {{epidemiologic}} {{studies of}} infectious diseases rely on pathogen genotype comparisons, which usually yield patterns comprising sets of DNA fragments (DNA fingerprints). We use a highly developed genotyping system, IS 6110 -based {{restriction fragment length polymorphism}} analysis of Mycobacterium tuberculosis, to develop a computational method that automates comparison of large numbers of fingerprints. Because error in fragment length measurements is proportional to fragment length and is positively correlated for fragments within a lane, an align-and-count method that <b>compensates</b> for relative <b>scaling</b> of lanes reliably counts matching fragments between lanes. Results of a two-step method we developed to cluster identical fingerprints agree closely with 5 years of computer-assisted visual matching among 1, 335 M. tuberculosis fingerprints. Fully documented and validated methods of automated comparison and clustering will greatly expand the scope of molecular epidemiology. The combination of conventional epidemiologic investigations with molecular techniques for genotyping pathogens has elucidated th...|$|R
40|$|Preliminary {{comparisons}} between global ozone burdens {{derived from the}} backscattered ultraviolet (BUV) experiment on Nimbus 4 and those inferred from an analysis of ground-based network data seem to indicate {{significant differences in the}} inter-annual variability of ozone. Some of the observed differences may be due to improper weighting of the ground-based network data, slowly changing planetary wave structure over the fixed station, of small inter-annual changes in meridional transport parameters. There is also some evidence which indicates that the polar stratosphere at high latitudes may represent an important ozone storage resevoir which tends to <b>compensate</b> for large <b>scale</b> changes observed in the regions outside of the polar stratosphere. Possible consequences of this are that the global trends derived from ground based ozone measurements may not be valid and furthermore that the current satellite techniques by themselves may be sufficient. An ozone monitoring system which includes observations from satellites, ground-based stations, balloons and rockets may be necessary...|$|R
40|$|Poverty {{measures}} {{in developing countries}} often ignore the distribution of resources within families and the gains from joint consumption. In this paper, we extend the collective model of household consumption to recover mother's, father's and children's shares together with economies of scale, using the observation of adult-specific goods and an extended version of the Rothbarth method. The application on data from C 4 te d'Ivoire shows that children command a reasonable fraction of household resources, though not enough to avoid a very large extent of child poverty compared to what is found in traditional measures based on per capita expenditure. We find no significant evidence of discrimination against girls, and educated mothers have more command over household resources. Baseline results on children's shares are robust to using alternative identifying assumptions, which consolidates a general approach grounded on a flexible version of the Rothbarth method. Individual measures of poverty show that parents are highly <b>compensated</b> by the <b>scale</b> economies due to joint consumption...|$|R
