17|120|Public
5000|$|... pragmatic {{competence}} (every day, functional literacy, i.e. {{writing a}} <b>check,</b> <b>reading</b> the newspaper, filling out a job application, etc.) ...|$|E
5000|$|The 2501 uses a {{photoelectric}} sensor {{to read the}} data punched in the card. Cards are read serially (column by column) and the reader uses a simplified [...] "straight through" [...] card path. [...] "Each column is read twice and the two readings are compared to <b>check</b> <b>reading</b> accuracy." ...|$|E
5000|$|The medieval Muslim world {{also used}} {{a method of}} {{reproducing}} reliable copies of a book in large quantities known as <b>check</b> <b>reading,</b> {{in contrast to the}} traditional method of a single scribe producing only a single copy of a single manuscript. In the <b>check</b> <b>reading</b> method, only [...] "authors could authorize copies, and this was done in public sessions in which the copyist read the copy aloud {{in the presence of the}} author, who then certified it as accurate." [...] With this check-reading system, [...] "an author might produce a dozen or more copies from a single reading," [...] and with two or more readings, [...] "more than one hundred copies of a single book could easily be produced." [...] By using as writing material the relatively cheap paper instead of parchment or papyrus the Muslims, in the words of Pedersen [...] "accomplished a feat of crucial significance not only to the history of the Islamic book, but also to the whole world of books".|$|E
50|$|<b>Check</b> and <b>reading</b> rooms.|$|R
5000|$|Using [...] "pro-words" [...] {{based on}} the English {{language}} such as Acknowledge, All after, All before, All stations, Confirm, Correct, Correction, In figures, In letters, Over, Out, Radio <b>check,</b> <b>Read</b> back, Received, Repeat, Say again, Spell, Standby, Station calling, This is, Wait, Word after, Word before, Wrong (local language is used for some of these, when talking to local stations) ...|$|R
5000|$|Progress: {{allows users}} to <b>check</b> their <b>reading</b> {{progress}} in a chapter and in a book ...|$|R
40|$|Graduation date: 1985 Figures in {{original}} document {{are black and}} white photocopies. Best scan available. This {{study was designed to}} compare two types process overview displays for a distributed process control system. The two types of formats included in the study were an alphanumeric type (letter) and an analog type (bar). The study required the subjects to perform <b>check</b> <b>reading</b> and search tasks. Thirty-six subjects were tested on both types of display. The results indicated that the analog display was superior to the alphanumeric display. The results reported are based on speed (response time) and accuracy (percent correct) ...|$|E
40|$|A new {{courtesy}} amount recognition module of CENPARMI’s <b>Check</b> <b>Reading</b> System (CRS) {{is proposed}} in this paper. The module consists of 3 main segments: pre-processing, segmentation and recognition, and post-processing. A new feedbackbased segmentation algorithm is adopted for the segmentation task. Besides one individual numeral recognizer for numerals from ‘ 0 ’ to ‘ 9 ’, one convolutional neural network(CNN) recognizer for “ 00 ” and “ 000 ” numeral strings is also integrated into our module for the recognition task. The experimental {{results on the}} Quebec Bell Check database show that the recognition rate of the courtesy amount has improved from 41. 2 % to 74. 3 %. 1...|$|E
40|$|Multi-class {{classification}} {{problems can}} be efficiently solved by partitioning the original problem into sub-problems involving only two classes: for each pair of classes, a (potentially small) neural network is trained using only the data of these two classes. We show how to combine the outputs of the two-class neural networks {{in order to obtain}} posterior probabilities for the class decisions. The resulting probabilistic pairwise classifier is part of a handwriting recognition system which is currently applied to <b>check</b> <b>reading.</b> We present results on real world data bases and show that, from a practical point of view, these results compare favorably to other neural network approaches. ...|$|E
50|$|The {{programme}} {{began as}} a segment in the long-running programme World of Sport, a sports magazine programme that aired on the ITV network from 2 January 1965 to 28 September 1985. At around 4:40pm, at around the time final whistles began to be blown at football matches across Britain, World of Sport would air 'Results Service', taking reports from major football matches before a full classified <b>check</b> <b>read</b> by Bob Colston.|$|R
5000|$|... where XXXXX is a Branch Number, and YYY is an Institution Number. The dash {{between the}} branch {{number and the}} {{institution}} number {{is an integral part}} of the transit number. This format is only valid for paper-type transactions such as checks. For Electronic Fund Transactions (EFT) the current format is a leading zero, the institution number, then the branch number all with no dashes. For example if a <b>check</b> <b>reads</b> XXXXX-YYY, the corresponding EFT code would be 0YYYXXXXX.|$|R
5000|$|While the Bull punch {{was used}} with the UNIVAC Solid State 80 for 80 column cards the UNIVAC Solid State 90 used the Univac {{manufactured}} [...] "Tower Punch" [...] for 90 column cards. The Tower Punch operating at 150 cards per minute used mechanical pin sensing in the pre punch read and the post punch read stations giving {{the ability to read}} a card, punch additional information into the card, and <b>check</b> <b>read</b> the results in the post punch station.|$|R
40|$|Page {{segmentation}} {{and image}} content classification {{is an important}} step for automatic document image processing including mixed-type document image compression, form and <b>check</b> <b>reading,</b> and mail sorting. The authors first propose an enhanced background thinning based page segmentation approach. They then present a hierarchical approach for the classification of the segmented sub-images into one of two categories: text and picture. The approach combines a cross-correlation method, the Kolmogorov complexity measure (A. N. Kolmogorov, 1965), and a neural network classifier in order to achieve both efficiency and high accuracy. Our approach has been tested on a number of mixed-type document images with good resultsDepartment of Electronic and Information EngineeringRefereed conference pape...|$|E
40|$|We {{propose a}} new machine {{learning}} paradigm called Graph Transformer Networks that extends {{the applicability of}} gradient-based learning algorithms to systems composed of modules that take graphs as inputs and produce graphs as output. Training is performed by computing gradients of a global objective function with respect to all the parameters in the system using a kind of back-propagation procedure. A complete <b>check</b> <b>reading</b> system based on these concept is described. The system uses convolutional neural network character recognizers, combined with global training techniques to provides record accuracy on business and personal checks. It is presently deployed commercially and reads million of checks a month. 1 Introduction The most common technique for building document processing systems is to partition the task into manageable subtasks, such as field detection, word segmentation, or character recognition, and to build a separate module for each one. Typically, each module is trained [...] ...|$|E
40|$|We {{propose a}} new machine {{learning}} paradigm called Multilayer Graph Transformer Network that extends {{the applicability of}} gradient-based learning algorithms to systems composed of modules that take graphs as input and produce graphs as output. A complete <b>check</b> <b>reading</b> system based on this concept is described. The system combines convolutional neural network character recognizers with graph-based stochastic models trained cooperatively at the document level. It is deployed commercially and reads million of business and personal checks per month with record accuracy. 1. INTRODUCTION The most common technique for building document processing systems is to partition the task into manageable subtasks, such as field detection, word segmentation, or character recognition, and to build a separate module for each one. Typically, each module is trained, or manually optimized, outside of its context. After the complete system is assembled, {{a subset of the}} parameters of the modules is manually ad [...] ...|$|E
30|$|Mobile {{devices have}} {{fulfilled}} the true aim of Internet by offering full connectivity anytime anywhere. The trend of going wireless {{goes beyond the}} walls of homes, university buildings, or hotels and reaches the open spaces of nature or the mobile spaces of trains and buses. The freedom of movements is used to speak everywhere without the need to log in a local wireless network, and to extend it to other Internet services such as Web surfing, email <b>checking,</b> <b>reading</b> news, listen to online radios, or even watching video streaming and television.|$|R
40|$|Human Machine {{interface}} {{are constantly}} gaining improvements because of increasing development ofcomputer tools. Handwritten Character Recognition do have various significant applications like formscanning, verification, validation, or <b>checks</b> <b>reading.</b> Because {{of the importance}} of these applicationspassionate research in the field of Off-Line handwritten character recognition is going on. The challenge inrecognising the handwritings lies in the nature ofhumans, having unique styles in terms of font, contours,etc. This paper presents a novice approach to identify the offline characters; we call it as characterdividerapproach which can be used after pre-processing stage. We devise an innovative approach for featureextraction known as vector contour. We also discussthe pros and cons including limitations, of ourapproach...|$|R
40|$|This study {{reports the}} {{analyses}} of the rhizospheric microbiome of the terrestrial mangrove fern Acrostichum aureum Linn. from the Indian Sunderbans. Samples were collected using standard protocols and 16 S rRNA gene V 3 –V 4 region amplicon sequencing was performed to identify the microbial communities prevalent in the rhizosphere. A total of 1, 931, 252 quality <b>checked</b> <b>reads</b> were assembled into 204, 818 contigs and were analysed using QIIME to reveal the abundance of Proteobacteria, Acidobacteria and Planctomycetes. The data {{is available at the}} NCBI - Sequence Read Archive with accession number: SRX 2660456. This is the first report of the rhizospheric microbiome belonging to a fern species...|$|R
40|$|Abstract. As the {{accuracy}} of conventional classifiers, based only on a static partitioning of feature space, appears to be approaching a limit, {{it may be useful}} to consider alternative approaches. Interactive classification is often more accurate then algorithmic classification, and requires less time than the unaided human. It is more suitable for the recognition of natural patterns in a narrow domain like trees, weeds or faces than for symbolic patterns like letters and phonemes. On the other hand, symbolic patterns lend themselves better to using context and style to recognize entire fields instead of individual patterns. Algorithmic learning and adaptation is facilitated by accurate statistics gleaned from large samples in the case of symbolic patterns, and by skilled human judgment in the case of natural patterns. Recent technological advances like pocket computers, camera phones and wireless networks will have greater influence on mobile, distributed, interactive recognition of natural patterns than on conventional high-volume applications like mail sorting, <b>check</b> <b>reading</b> or forms processing. 1...|$|E
40|$|This {{contribution}} {{takes the}} example of a <b>check</b> <b>reading</b> system to discuss the modeling and estimation issues associated with large scale pattern recognition systems. 1. Problem Decomposition and Model Composition Consider a system that takes the image of a check and returns the check amount. This system locates the numerical amount, recognizes digits or other symbols, and parses the check amount. Accuracy should remain high despite countless variations in check layout, writing style or amount grammar. From an engineering perspective, one must design components for locating the amount, segmenting characters, recognizing digits, and parsing the amount text. Yet {{it is very difficult to}} locate the amount without identifying that it is composed of characters that mostly resemble digits and form a meaningful check amount (not a date or a routing number). Purely sequential approaches do not work. Components must interact, form hypotheses and backtrack erroneous decisions. The orchestration is difficult to design and costly to maintain...|$|E
40|$|Page {{segmentation}} {{and image}} content classification {{play an important}} role in automatic image processing with applications to mixed-type document image compression, form and <b>check</b> <b>reading,</b> and automatic mail sorting. In this paper, we first present an enhanced background thinning based approach for fast page segmentation. After the analysis of three different methods individually, a hierarchical approach for document content classification is proposed, which classifies a sub-image into one of two categories: text and halftone. Our approach combines a neural network model, cross-correlation metric, and Kolmogorov complexity measure in a hierarchical structure. Considering the necessity of a recognition system, we also propose using a three-layer feedforward neural network to classify text regions into Chinese and English scripts. The classification accuracy on a number of document images reaches 100 % and 97. 1 % for halftone region and text region, respectively. Meanwhile, the system can achieve a correct rate of 92. 3 % and 95. 0 % for Chinese and alphabetic script determination, respectively. Department of Electronic and Information Engineerin...|$|E
50|$|Medium {{errors are}} most {{commonly}} detected by <b>checking</b> the <b>read</b> data against a checksum - itself being most commonly also stored {{on the same}} device. The mismatch of data to its supposed checksum {{is assumed to be}} caused by the data being corrupted.|$|R
50|$|Existence {{checking}} or existence detection is {{an important}} aspect of many computer programs. An existence <b>check</b> before <b>reading</b> a file can catch and/or prevent a fatal error, for instance. For that reason, most programming language libraries contain a means of checking whether a file exists.|$|R
50|$|Because the Torah scrolls are {{generally}} large, the central {{feature of the}} bimah in a synagogue is a table {{large enough to hold}} an open Torah along with a tikkun or Chumash (reference books used to <b>check</b> the <b>reading).</b> In some synagogues, this table may resemble a large lectern.|$|R
40|$|The {{problem of}} {{automatic}} recognition of scanned handwritten documents {{is of great}} significance in numerous scientific, business, industrial, and personal applications that require the reading and processing of human written texts. The ultimate goal is that computers approach, or even surpass, the text recognition performance of humans. Despite the enormous amount of research activities that already {{have been carried out}} to study this problem, it is considered very difficult and still not satisfactorily solved. Today’s commercial systems work in areas where strict task specific knowledge and constraints are available, for example address and <b>check</b> <b>reading.</b> On the other hand, the more challenging task of recognizing unconstrained handwriting has also many potential applications such as office automation, digital libraries, and personal digital assisting devices. In the current dissertation this problem of unconstrained recognition is addressed. The dissertation proposes novel methods to improve the performance of today’s handwriting recognition technology. In one important part of the work novel methods are developed to generate synthetic handwriting by computer, which enable handwriting recognizers to be better trained with the help of synthetically expanded sets of trainin...|$|E
40|$|Abstract — Using {{computer}} simulated tests, {{this study}} examined direction-of-motion stereotypes and response times for different configurations of lever controls and circular displays. Quantitative measures of the strength and reversibility of stereotypes were {{used to analyze the}} effects of pointer position, direction of turn instruction, and control plane on movement compatibility. The results showed that strong and significantly reversible stereotypes were obtained for horizontal and vertical levers, at the 12 and 9 o’clock pointer positions, respectively. Response times were generally longer when there were no clear movement stereotypes. In the analysis of contributions of component principles to overall stereotypes, the results were explained in terms of a number of common control operating principles. Based on the experimental findings, recommendations for <b>check</b> <b>reading</b> or resetting purposes are that the pointer should be placed at 12 and 9 o’clock positions for the horizontal and vertical levers, respectively. Both the levers and the display should be positioned in the frontal plane. Due to weak response preferences and low reversibility, vertical and horizontal levers were found not suitable for use with other control/display configurations tested here. This study provided useful design guidance for improving the design of control panels used in person-machine interfaces. Index Terms — movement compatibility; circular display, lever control; stereotype, reversibility I...|$|E
40|$|Paper checks play an {{important}} role in our modern commercial society. However, Reading paper checks and typing into computers manually is a time-consuming and labor-intensive task. Therefore, accurate and efficient <b>Check</b> <b>Reading</b> Systems (CRS) are in high demand by banks. In this thesis, a CENPARMI CRS is introduced. Its courtesy amount recognition module is then presented in depth. The module makes use of a new feedback-based segmentation algorithm. The original segmentation algorithm can segment the inputted numeral string only once. The new algorithm can adjust the parameters of the segmentation algorithm according to the feedback information from the digit recognizer and can re-segment the inputted numeral string multiple times if necessary. Two rejection strategies in the new segmentation algorithm are also presented. The first strategy is used for rejecting unreasonable segmentations, which can be accepted by the individual digit recognizer. The second strategy is used to avoid accepting a digit string as one digit. Moreover, three algorithms in pre-processing and post-processing modules are proposed: a new border noise removal algorithm, an extra punctuations removal algorithm, and an implicit decimal points detection algorithm. Finally, a Convolutional Neural Network (CNN) recognizer is integrated into the CRS to recognize " 00 " and " 000 " directly in order to avoid segmenting " 00 " and " 000 ". The experiment, based on the Bell Quebec check database, has shown that the courtesy amount recognition rate of the CRS has improved from 41. 2 % to 74. 3 %. The CRS can produce preliminary courtesy amount recognition results, which can be used for validation with the legal amounts to suppress the substitution rate...|$|E
50|$|In {{computational}} complexity theory, a probabilistically checkable proof (PCP) {{is a type}} {{of proof}} that can be checked by a randomized algorithm using a bounded amount of randomness and reading a bounded number of bits of the proof. The algorithm is then required to accept correct proofs and reject incorrect proofs with very high probability. A standard proof (or certificate), as used in the verifier-based definition of the complexity class NP, also satisfies these requirements, since the <b>checking</b> procedure deterministically <b>reads</b> the whole proof, always accepts correct proofs and rejects incorrect proofs. However, what makes them interesting is the existence of probabilistically checkable proofs that can be <b>checked</b> by <b>reading</b> only a few bits of the proof using randomness in an essential way.|$|R
5000|$|This {{model is}} used for {{children}} who are reading up to about NC level 1A/2C. In this model the book introduction, strategy <b>check,</b> independent <b>reading,</b> return to text and response to text all take place generally within one session. This is aided {{by the fact that the}} books suitable for children reading at this stage are very short. (Baker, Bickler and Bodman) ...|$|R
40|$|This study {{examines}} {{the ability of}} children to detect the reading mistakes of their peers. Peer-assisted learning strategies (PALS) is an effective, cooperative learning method of reading instruction for children (Fuchs & Fuchs, 1994). PALS {{has been shown to}} be effective for improving the reading fluency and comprehension of not only students with learning disabilities and low achievement levels but also of students with average achievement levels. Researchers have examined the extent of children's ability to identify the reading mistakes of their peers and those made deliberately by experimenters to standardize PALS in Japan. This study revealed the following three results: 1) students of all grades find mistakes without a classification of errors more correctly than with classification, 2) students of all grades except the fourth graders showed an increase in the number of letters that they could read aloud correctly per minute in each session, and 3) fifth graders and sixth graders showed an improvement in their rates of correctly <b>checking</b> <b>reading</b> mistakes in each subsequent session...|$|R
40|$|Convolutional Neural Networks (CNNs) {{have shown}} to be {{powerful}} classification tools in tasks that range from <b>check</b> <b>reading</b> to medical diagnosis, reaching close to human perception, {{and in some cases}} surpassing it. However, the problems to solve are becoming larger and more complex, which translates to larger CNNs, leading to longer training times that not even the adoption of Graphics Processing Units (GPUs) could keep up to. This problem is partially solved by using more processing units and distributed training methods that are offered by several frameworks dedicated to neural network training. However, these techniques do not take full advantage of the possible parallelization offered by CNNs and the cooperative use of heterogeneous devices with different processing capabilities, clock speeds, memory size, among others. This paper presents a new method for the parallel training of CNNs that can be considered as a particular instantiation of model parallelism, where only the convolutional layer is distributed. In fact, the convolutions processed during training (forward and backward propagation included) represent from 60 - 90 % of global processing time. The paper analyzes the influence of network size, bandwidth, batch size, number of devices, including their processing capabilities, and other parameters. Results show that this technique is capable of diminishing the training time without affecting the classification performance for both CPUs and GPUs. For the CIFAR- 10 dataset, using a CNN with two convolutional layers, and 500 and 1500 kernels, respectively, best speedups achieve 3. 28 × using four CPUs and 2. 45 × with three GPUs. Modern imaging datasets, larger and more complex than CIFAR- 10 will certainly require more than 60 - 90 % of processing time calculating convolutions, and speedups will tend to increase accordingly...|$|E
40|$|This {{contribution}} {{takes the}} example of a <b>check</b> <b>reading</b> system to discuss the modeling and estimation issues associated with large scale pattern recognition systems. 1. Problem Decomposition and Model Composition Consider a system that takes the image of a check and returns the check amount. This system locates the numerical amount, recognizes digits or other symbols, and parses the check amount. Accuracy should remain high despite countless variations in check layout, writing style or amount grammar. From an engineering perspective, one must design components for locating the amount, segmenting characters, recognizing digits, and parsing the amount text. Yet {{it is very difficult to}} locate the amount without identifying that it is composed of characters that mostly resemble digits and form a meaningful check amount (not a date or a routing number). Purely sequential approaches do not work. Components must interact, form hypotheses and backtrack erroneous decisions. The orchestration is difficult to design and costly to maintain. From a statistical perspective, one seeks to estimate and compare the posterior probabilities P (Y |X) where variable X represents a check image and variable Y represents a check amount. Let us define a suitable parametric model pθ(y|x), gather data pairs (xi, yi), and maximize the likelihood � i log pθ(yi|xi). Such a direct approach leads to problems of unpractical sizes. It is therefore common to manually annotate some pairs (xi, yi) with detailled information such as isolated character images T, character codes C, or sequences S of character codes. One can then model P (C|T) and P (Y |S) and obtain components such as a character recognizer or an amount parser. The statistical perspective suggests a principled way to orchestrate the interaction of these components: let the global model pθ(y|x) be expressed as a composition of submodels such as pθ(c|t) and pθ(y|s). The submodels are first fit using the detailled data. The resulting parameters are used as a bias when fitting the global model pθ(y|x) using the initial data pairs (yi|xi). This bias can be viewed as a capacity control tool for structural risk minimizatio...|$|E
40|$|Background: The {{advent of}} massively {{parallel}} sequencing technologies (Next Generation Sequencing, NGS) profoundly modified {{the landscape of}} human genetics. In particular, Whole Exome Sequencing (WES) is the NGS branch {{that focuses on the}} exonic regions of the eukaryotic genomes; exomes are ideal to help us understanding high-penetrance allelic variation and its relationship to phenotype. A complete WES analysis involves several steps which need to be suitably designed and arranged into an efficient pipeline. Managing a NGS analysis pipeline and its huge amount of produced data requires non trivial IT skills and computational power. Results: Our web resource WEP (Whole-Exome sequencing Pipeline web tool) performs a complete WES pipeline and provides easy access through interface to intermediate and final results. The WEP pipeline is composed of several steps: 1) verification of input integrity and quality <b>checks,</b> <b>read</b> trimming and filtering; 2) gapped alignment; 3) BAM conversion, sorting and indexing; 4) duplicates removal; 5) alignment optimization around insertion/deletion (indel) positions; 6) recalibration of quality scores; 7) single nucleotide and deletion/insertion polymorphism (SNP and DIP...|$|R
5000|$|Dale {{runs his}} own {{extermination}} business, Dale's Dead-Bug, although he generally {{does not pay}} taxes on his income and has filled out an income tax form only once. It is hinted {{that he is not}} professionally trained in extermination and that his business is not a legally operating firm in the United States, as his company <b>checks</b> <b>read</b> [...] "Dales Dead Bug - A Liberian Registered Company". He drives a white Dodge Caravan nicknamed [...] "the Bug-ebago" [...] (a portmanteau of [...] "bug" [...] and Winnebago) with a large plastic queen ant sculpture perched on the roof. The ant, which can be rotated to appear dead (legs up) or alive (legs down), was a group project of Dale and friends/neighbors Hank Hill, Bill Dauterive and Boomhauer to help them over the emotional turmoil they shared over the death of actor Hervé Villechaize. Later on, Dale ends up buying a Hyundai claimed to be owned by Deion Sanders former Dallas cowboy from another former cowboy and super bowl champion, [...] "Big Willie Lane".|$|R
60|$|Her replies {{had been}} prompt and frank. At this sudden query she seemed <b>checked.</b> Lane <b>read</b> in Bessy Bell then {{more of the}} truth of her than he had yet divined. Falsehood was {{naturally}} abhorrent to her. To lie to her parents or teachers savored of fun, and {{was part of the}} game. She did not want to lie to Lane, but in her code she could not betray another girl, especially to that girl's brother.|$|R
50|$|Relational {{databases}} mainly use row-based data storage, but column-based {{storage is}} more useful for many business applications. Column database has faster access which columns can read throughout the range process of a query. Any of the columns {{are known to}} serve as an index. Row-based application desires to progress an only record at one time and normally need to access a complete record or two. Column database has better compression as the data storage permits highly effective compression since the majority of the columns cover only few distinct values compared to number of rows. Furthermore, in a column store, data is already vertically divided. This results that operations on different columns can certainly be processed in parallel. If the multiple needs to be search or aggregated, each of these operations can be assigned to a different processor core. Overall, row based database in a row needs to <b>check</b> <b>read</b> though the obligation is to access data from a few columns. Therefore, these requests on a large amount of data {{take a lot of time}} whereas in column database tables, this information is kept physically next to each other, knowingly increasing the speed of certain data queries.|$|R
