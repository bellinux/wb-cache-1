478|195|Public
25|$|Typically, {{computer}} programs {{are stored in}} non-volatile memory until requested {{either directly or indirectly}} to be executed by the computer user. Upon such a request, the program is loaded into random-access memory, by a computer program called an operating system, where it can be accessed directly by the <b>central</b> <b>processor.</b> The <b>central</b> <b>processor</b> then executes ("runs") the program, instruction by instruction, until termination. A program in execution is called a process. Termination is either by normal self-termination or by error– software or hardware error.|$|E
25|$|This {{approach}} (called MPQS, Multiple Polynomial Quadratic Sieve) is {{ideally suited}} for parallelization, since each processor {{involved in the}} factorization can be given n, the factor base {{and a collection of}} polynomials, and it will have no need to communicate with the <b>central</b> <b>processor</b> until it is finished with its polynomials.|$|E
25|$|When the sonar park sensors {{feature is}} used, the processor(s) {{calculate}} steering angle data which are {{displayed on the}} navigation/camera touchscreen along with obstacle information. The Intelligent Parking Assist System expands on this capability and is accessible when the vehicle is shifted to reverse (which automatically activates the backup camera). When in reverse, the backup camera screen features parking buttons {{which can be used}} to activate automated parking procedures. When the Intelligent Parking Assist System is activated, the <b>central</b> <b>processor</b> calculates the optimum parallel or reverse park steering angles and then interfaces with the Electric Power Steering systems of the vehicle to guide the car into the parking spot.|$|E
50|$|IBM, that {{provides}} RISC servers and AIX on <b>central</b> <b>processors.</b>|$|R
50|$|Both <b>central</b> <b>processors</b> {{have access}} to {{channels}} (as many as 24), and main memory (up to 32 megabytes).|$|R
50|$|Bigger {{systems were}} {{sometimes}} built with a <b>central</b> <b>processor(s)</b> and some number of I/O processors, {{a kind of}} asymmetric multiprocessing.|$|R
500|$|The SSEM's 32-bit {{word length}} was {{increased}} to 40 bits. Each word could hold either one 40-bit number or two 20-bit program instructions. The main store initially {{consisted of two}} double-density Williams tubes, each holding two arrays of 32 x 40-bit words– known as pages– backed up by a magnetic drum capable of storing an additional 32 pages. [...] The capacity was increased in the Final Specification version to eight pages of main store on four Williams tubes and 128 magnetic drum pages of backing store. The [...] diameter drum, initially known as a magnetic wheel, contained a series of parallel magnetic tracks around its surface, {{each with its own}} read/write head. Each track held 2,560bits, corresponding to twopages (2×32×40bits). One revolution of the drum took 30milliseconds, during which time both pages could be transferred to the CRT main memory, although the actual data transfer time depended on the latency, the time it took for a page to arrive under the read/write head. Writing pages to the drum took about twice as long as reading. The drum's rotational speed was synchronised to the main <b>central</b> <b>processor</b> clock, which allowed for additional drums to be added. Data was recorded onto the drum using a phase modulation technique still known today as Manchester coding.|$|E
2500|$|There {{are several}} {{theories}} {{used to explain}} the Stroop effect and {{are commonly known as}} ‘race models’. This is based on the underlying notion that both relevant and irrelevant information are processed in parallel, [...] but [...] "race" [...] to enter the single <b>central</b> <b>processor</b> during response selection. [...] They are: ...|$|E
2500|$|A {{channel program}} is a {{sequence}} of channel command words (CCWs) which are executed by the I/O channel subsystem in the IBM System/360 and subsequent architectures. [...] A channel program consists {{of one or more}} channel command words. [...] The operating system signals the I/O channel subsystem to begin executing the channel program with a SSCH (start sub-channel) instruction. [...] The <b>central</b> <b>processor</b> is then free to proceed with non-I/O instructions until interrupted. [...] When the channel operations are complete, the channel interrupts the <b>central</b> <b>processor</b> with an I/O interruption. [...] In earlier models of the IBM mainframe line, the channel unit was an identifiable component, one for each channel. In modern mainframes, the channels are implemented using an independent RISC processor, the channel processor, one for all channels. IBM System/370 Extended Architecture and its successors replaced the earlier SIO (start I/O) and SIOF (start I/O fast release) assembler instructions (System/360 and early System/370) with the SSCH (start sub-channel) instruction (late System/370 and successors).|$|E
50|$|In 2014, United Instrument Manufacturing Corporation also {{confirmed}} {{that it was}} developing Russian <b>central</b> <b>processors</b> Baikal for advanced computing equipment together {{with a group of}} companies “Т-Platform” and Rosnano. A representative of the company announced that UIMC would produce telecommunication and computing hardware with those processors24.|$|R
50|$|Barrel {{processors}} {{have also}} been used as large-scale <b>central</b> <b>processors.</b> The Tera MTA (1988) was a large-scale barrel processor design with 128 threads per core. The MTA architecture has seen continued development in successive products, such as the YarcData uRiKA, introduced in 2012 and targeted at data-mining applications.|$|R
40|$|Printer uses Kerr cell {{as light}} shutter for {{controlling}} the print on photosensitive paper. Applied to output data transfer, the {{information transfer rate}} of graphic computer printers could be increased to speeds approaching the data transfer rate of computer <b>central</b> <b>processors</b> / 5000 to 10, 000 lines per minute/...|$|R
50|$|In all the CDC 6000 series computers, the <b>central</b> <b>processor</b> {{communicates}} with around seven simultaneously active programs (jobs), which {{reside in}} central memory. Instructions from {{these programs are}} read into the <b>central</b> <b>processor</b> registers and are executed by the <b>central</b> <b>processor</b> at scheduled intervals. The results are then returned to central memory.|$|E
5000|$|The <b>central</b> <b>processor</b> (CPU) {{and central}} memory (CM) {{operated}} in units of 60-bit words. In CDC lingo, the term [...] "byte" [...] referred to 12-bit entities (which {{coincided with the}} word size used by the peripheral processors). Characters were six bits, operation codes were six bits, and central memory addresses were 18 bits. <b>Central</b> <b>processor</b> instructions were either 15 bits or 30 bits.The 18-bit addressing inherent to the Cyber 170 series imposed a limit of 262,144 (256K) words of main memory, which was semiconductor memory in this series. The <b>central</b> <b>processor</b> had no I/O instructions, relying upon the peripheral processor (PP) units to do I/O.|$|E
50|$|The CDC 6700 {{computer}} {{combined the}} best {{features of the}} other three computers. Like the CDC 6500, it had two central processors. One was a CDC 6400/CDC 6500 <b>central</b> <b>processor</b> with the unified arithmetic section; the other was the more efficient CDC 6600 <b>central</b> <b>processor.</b> The combination made the CDC 6700 the fastest and the most powerful of the four CDC 6000 series.|$|E
40|$|This summer I {{worked in}} the Level 1 <b>Central</b> Trigger <b>Processor</b> group. I had two projects. First I created a web-based {{monitoring}} tool, the Mioct Presenter to monitor the muon detector side of the <b>Central</b> Trigger <b>Processor</b> (CTP). The second project was updating an existing application, the BunchGrouper application...|$|R
5000|$|The IBM System z10 servers {{supported}} more memory {{than previous}} generation systems and can {{have up to}} 64 <b>central</b> <b>processors</b> (CPs) per frame. The full speed z10 processor's uniprocessor performance was up to 62% faster {{than that of the}} z9 server, according to IBM's z10 announcement, and included these other features: ...|$|R
40|$|The ATLAS Level- 1 <b>Central</b> Trigger <b>Processor</b> {{combines}} {{information from}} the calori-meters and the muon detectors and takes a decision to accept an event based {{on a list of}} selection criteria (trigger items). Busy signals from the detectors and generated dead time by the <b>Central</b> Trigger <b>Processor</b> prevents the buﬀers to become full. The visualisation of this data is useful to check the functionality of the system. My project during the CERN summer student programme was to develop an application, which produces plots of relevant <b>Central</b> Trigger <b>Processor</b> data and presents the results in an appropriate format for experts and users...|$|R
5000|$|A microprogrammed 16-bit <b>central</b> <b>processor</b> with {{floating}} point hardware, error detection and system integrity checking features.|$|E
5000|$|System {{performance}} - monitors {{loads of}} <b>central</b> <b>processor</b> unit (CPU), {{random access memory}} (RAM), local or remote computers.|$|E
50|$|However, {{since the}} Cray {{machines}} {{did not have}} peripheral processors, the main <b>central</b> <b>processor</b> executed the operating system code.|$|E
50|$|The positronic brain, which Asimov {{named his}} robots <b>central</b> <b>processors,</b> is what powers Data from Star Trek: The Next Generation, {{as well as}} other Soong type androids. Positronic brains have been {{referenced}} {{in a number of other}} television shows including Doctor Who, Once Upon a Time... Space, Perry Rhodan, The Number of the Beast, and others.|$|R
2500|$|Additionally, the 6809 {{processor}} {{was used}} in the mid-1980s through the early 2000s in Motorola SMARTNET and SMARTZONE Trunked Central Controllers (so dubbed the [...] "6809 Controller"). These controllers are used as the <b>central</b> <b>processors</b> in many of Motorola's trunked two-way radio communications systems. It was widely accepted as a reliable platform and bulletproof controller, solidifying the processor's further use.|$|R
5000|$|Linux runs on standard, {{general purpose}} {{mainframe}} CPs (<b>Central</b> <b>Processors)</b> {{as well as}} IFLs (Integrated Facility for Linux). IFLs are mainframe processors dedicated to running Linux, either natively or under a hypervisor (z/VM or KVM on z). Microcode restricts IFLs from running [...] "traditional" [...] workloads, such as z/OS, but they are physically identical to other z System processors. IFLs are typically less expensive to acquire from IBM than CPs.|$|R
5000|$|The <b>Central</b> <b>Processor</b> (CP) {{and main}} {{memory of the}} 6400, 6500, and 6600 {{machines}} had a 60-bit word length. The <b>Central</b> <b>Processor</b> had eight general purpose 60-bit registers X0 through X7, eight 18-bit address registers A0 through A7, and eight 18-bit [...] "increment" [...] registers B0 through B7. B0 was held at zero permanently by the hardware. Many programmers found it useful to set B1 to 1, and similarly treat it as inviolate.|$|E
5000|$|COMPASS CP is the {{assembly}} language for the CP (<b>Central</b> <b>Processor),</b> the processor running user programs. See CDC 6600 CP architecture.|$|E
50|$|The {{language}} has two variants: Plex-C {{used for the}} AXE <b>Central</b> <b>Processor</b> (CP) and Plex-M used for Extension Module Regional Processors (EMRP).|$|E
40|$|<b>Central</b> Controlling <b>Processor</b> {{is applied}} in many {{scientific}} {{fields such as}} computer network, centralized mutual exclusion algorithm, centralized control IPC, Berkeley algorithm, etc. <b>Central</b> Controlling <b>Processor</b> in distributed systems {{is a very important}} problem, and this problem must be solved by suitable algorithms. The main goal of <b>Central</b> Controlling <b>Processor</b> is synchronizing the process at optimal using of the resources. In this paper we call the <b>Central</b> Controlling <b>Processor</b> as a leader many different algorithms have been presented for leader election. The most important leader election algorithms are the Bully and Ring algorithms. Ring election algorithm is one of the classic method which is used to virtual ring and determine the process with highest number as the coordinator, {{and one of the most}} important leader election algorithm is the Bully algorithm. In this paper we will describe novel approaches with fault tolerant method to improve the Bully and Ring algorithms. Our simulation shows that our algorithm is more efficient rather than the Ring algorithm in number of message passing. By doing this, performance and behavior will be improved and message passing will be reduced. 1...|$|R
5000|$|A Westlock {{system is}} divided {{into a number of}} components, called the <b>Central</b> Interlocking <b>Processor</b> (CIP), Trackside Interface (TIF) and Technicians Workstation (TW).|$|R
40|$|Accelerated Processing Units (APUs) are <b>central</b> <b>processors</b> {{that feature}} {{integrated}} GPU cores. In this study, {{we show that}} this architecture is well-suited to the domain of graph analytics. Our evaluation shows that a current-generation integrated GPU can out-perform an externally-connected discrete GPU by up to 50 % for the breadth-first search and PageRank algorithms. Furthermore, by operating on data with different characteristics in unison, the CPU and integrated GPU can halve the running time of PageRank on a scale-free dataset. 1...|$|R
50|$|A GEC 4080M {{was also}} used as the <b>central</b> <b>processor</b> for the radar system of the ill-fated Nimrod AEW.3 {{airborne}} early warning aircraft.|$|E
50|$|Nearly {{all of the}} {{operating}} system ran on the PPs; thus leaving the full power of the <b>Central</b> <b>Processor</b> available for user programs.|$|E
5000|$|IBM {{described}} MVPG as [...] "moves {{a single}} page and the <b>central</b> <b>processor</b> cannot execute any other instructions until the page move is completed." ...|$|E
40|$|Printed: November 20, 2002 This {{document}} is {{intended as a}} reference manual for use in working with the <b>Central</b> Alarm <b>Processor</b> and its user program interface. It contains a short introduction into the <b>Central</b> Alarm <b>Processor,</b> describes what alarms are {{and how they can}} be filtered. The main contents of the {{document is}} the exact description of the user program interface to the <b>Central</b> Alarm <b>Processor.</b> All constants, data types and functions of the interface are explained in detail in a formalized and language-independent manner. This manual {{can be found in the}} VMS Online Help Service, too. Correction of errors and upgrades in the CAP Online Help will be made as soon as possible, so that Online Help is always up to date. Note, that this may lead to differences between Online Help and this manual...|$|R
50|$|BroadLight's {{products}} include GPON <b>Central</b> office <b>processors,</b> integrated GPON Customer-premises {{equipment and}} Ethernet Gateway processors which are utilized in Fiber {{to the home}} (FTTx), and Ethernet CPEs.|$|R
40|$|The {{advanced}} avionics breadboard (AAB) executive {{evolved from}} {{an effort to}} design and develop an avionics system. This executive is unique in that it supervises a triple redundant avionics computer system. Three IBM System 4 Pi/CP computers, operating synchronously and executing identical software, comprise the <b>central</b> <b>processors</b> which route data to and from a data bus via an input/output controller. The executive's basic function is to provide application programs with an efficient software structure within which to perform specific avionics application tasks. Although implemented in a triplex data management system, the AAB executive contains the flexibility to be adapted to other systems with minimal change...|$|R
