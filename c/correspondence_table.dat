22|40|Public
50|$|The Atthakatha <b>Correspondence</b> <b>Table,</b> in {{collaboration}} with Sodo Mori and T. Endo, Pali Text Society, London, 1995 Mori, Sodo, Y. Karunadasa & Toshiichi Endo (1994). Pali Atthakatha <b>Correspondence</b> <b>Table.</b> Oxford: Pali Text Society.|$|E
50|$|Hiragana and Katakana to Polivanov cyrillization <b>correspondence</b> <b>table,</b> for single/modified kana.|$|E
5000|$|Mori, Sodo, Y Karunadasa & Toshiichi Endo (1994). Pali Atthakatha <b>Correspondence</b> <b>Table.</b> Oxford: Pali Text Society.|$|E
40|$|The {{analysis}} of FDZ BA data is hampered by changing industry classifications. This report describes two methods {{to deal with}} this and provides ready-to-use working tools. The first method is the usage of directional <b>correspondence</b> <b>tables.</b> We create several <b>correspondence</b> <b>tables</b> for the classifications used in our data. The mapping is based on the mode. The quality for each mapping is indicated by the share of correct matches for each value of the base classification. The <b>correspondence</b> <b>tables</b> are supplements to this report. Due to the limitations of <b>correspondence</b> <b>tables</b> we also generate two completed variables for each establishment in our data: w 73 (3 -digit) and w 93 (3 -digit). We first extrapolate valid values whenever possible. Then we use <b>correspondence</b> <b>tables</b> to replace further missing values based on available classifications. A large share of the missing values can be replaced. The generated variables are available for our users upon request. " (Author's abstract, IAB-Doku) ((en)) Additional Information Correspondence tablesIAB-Betriebs-Historik-Panel, Wirtschaftszweige, Klassifikation, Datenaufbereitung...|$|R
5000|$|<b>Tables</b> of <b>correspondences</b> are {{not limited}} to magical spellcasting. Gnostic books in the Nag Hammadi Library contain lists of aeons and archons (good and evil beings), {{correlating}} them to virtues and vices. The First Book of Enoch lists fallen angels and their spheres of influence. Medieval grimoires also included lists of <b>correspondences.</b> <b>Tables</b> of <b>correspondences</b> are also found in Chinese traditional and Indian Ayurvedic healthcare manuals.|$|R
5000|$|Work on {{the project}} started in 1929. To prove the superiority of his ideas, Yourkevitch {{believed}} {{he had to work}} until late at night. [...] "He created his work in primitive, refugee-style surroundings, where the drawing board was the most sacred object. On the walls, on the floor and on the desks there were volumes of <b>correspondence,</b> <b>tables,</b> diagrams…" [...] remembered one of Yourkevitchs friends.|$|R
5000|$|Note: Psalms are {{numbered}} {{according to the}} Greek Septuagint. For the Hebrew Masoretic numbering that is more familiar in the West, usually add '1'. (See the main Psalms article for an exact <b>correspondence</b> <b>table.)</b> ...|$|E
5000|$|In the Sexagenary {{cycle and}} Chinese astrology, duchen 土辰 [...] "The Year of the Earth Dragon" [...] is a {{recurring}} combination of Dragon (zodiac) with the Five Elements/Phases, see Chinese calendar <b>correspondence</b> <b>table</b> and Tibetan calendar.|$|E
50|$|The Chinese {{calendar}} <b>correspondence</b> <b>table</b> {{shows the}} stem/branch year names, correspondences to the Western (Gregorian) calendar, {{and other related}} information for the current, 79th Sexagenary cycle of the Chinese calendar (or the 78th cycle if an epoch of 2637 BC is accepted).|$|E
5000|$|B. R. Haydon's <b>Correspondence</b> and <b>Table</b> Talk, with {{a memoir}} by his son, FW Haydon (2 vols., 1876) ...|$|R
40|$|This paper tests a new {{approach}} by linking merchandise trade to general business registers (sectoral high-tech trade). It highlights that the data shown using the "traditional" approach to calculate the trade value of the high-tech industries via <b>correspondence</b> <b>tables</b> represents relatively well the exports to third countries (Extratrade) but not so well the exports to other EU Member States (Intratrade). The analysis also showed that the "traditional" approach gives a better estimation of the values exported by high-tech industries than of the values imported by them. Therefore, calculating the trade value of high-tech industries via <b>correspondence</b> <b>tables</b> can lead to an overestimation of their trade, especially {{with respect to their}} imports. In addition, the paper shows the methodological issues encounter when linking (high-tech) foreign trade data with business registers, it presents some first analytical results of the "high-tech trade by enterprise characteristics" especially with respect to the share of high-tech goods traded by the high-tech industries, and it gives an outlook for further research. JRC. G. 9 -Econometrics and applied statistic...|$|R
40|$|Research in {{economics}} using documentary archives provides clearer interpretations about {{the ideas and}} their development throughout time, {{in the context of}} the writing process in relation to the interlocutors and antagonists, and the nature of the problems addressed. This document presents examples of works with tough drafts, <b>correspondence,</b> <b>tables</b> of contents, notes, and related material of four economists of the "Cambridge Group": Piero Sraffa, Richard Kahn, Joan Robinson, and John Maynard Keynes. In each case the findings and importance of the research done in the files are described...|$|R
50|$|Only single consonants are {{considered}} here. In {{the middle of}} words, clusters of two consonants were allowed in Proto-Altaic as reconstructed by Starostin et al. (2003); the <b>correspondence</b> <b>table</b> of these clusters spans almost 7 pages in their book (83-89), and most clusters are only found in {{one or a few}} of the reconstructed roots.|$|E
5000|$|Woese {{turned his}} {{attention}} to the genetic code while setting up his lab at General Electric's Knolls Laboratory in the fall of 1960. Interest among physicists and molecular biologists had begun to coalesce around deciphering the correspondence between the twenty amino acids and the four letter alphabet of nucleic acid bases in the decade following James D. Watson, Francis Crick, and Rosalind Franklin's discovery of the structure of DNA in 1953. Woese published a series of papers on the topic. In one, he deduced a <b>correspondence</b> <b>table</b> between what was then known as [...] "soluble RNA" [...] and DNA based upon their respective base pair ratios. He then re-evaluated experimental data associated with the hypothesis that viruses used one base, rather than a triplet, to encode each amino acid, and suggested 18 codons, correctly predicting one for proline. Other work established the mechanistic basis of protein translation, but in Woese's view, largely overlooked the genetic code's evolutionary origins as an afterthought.|$|E
40|$|The <b>correspondence</b> <b>table</b> {{is one of}} the {{important}} tools in categorizing existing records into different perspective. It helps to understand the pattern of various economic activities from single source of data. Nevertheless, most of the existing correspondence tables have been focusing more on the latest classification and neglect the correspondence for the older version. Since some analysis would require longer series of data, therefore it is necessary to create a <b>correspondence</b> <b>table</b> for the earlier version of classification. This paper devoted to create a <b>correspondence</b> <b>table</b> between SITC Revision 2 and ISIC Revision 3 using a proxy method. The proxy is done using the SITC Rev. 2 – SITC Rev. 3 <b>correspondence</b> <b>table</b> and the SITC Rev. 3 – ISIC Rev. 3 <b>correspondence</b> <b>table.</b> This method has capable to directly find an industrial match for more than 98 percent of commodities under SITC Rev. 3. For remaining commodities which industrial category cannot be matched directly, the identification was done automatically based on the closest code. ...|$|E
5000|$|WA 61. Inhaltsverzeichnis zur Abteilung ‘Schriften’ Bd. 1-60 nebst Verweisen auf die Abteilungen ‘Deutsche Bibel’, ‘Briefwechsel’, ‘Tischreden’ (i.e. List of {{contents}} for the section Writings, vol. 1-60, with {{amendments to the}} sections German Bible, <b>Correspondence</b> & <b>Table</b> talk) ...|$|R
40|$|The Physical Model (PM) is an {{internal}} multi-Volume document for the IAEA’s Department of Safeguards describing the nuclear fuel cycle. This report describes work {{carried out by}} the JRC with the IAEA to prototype the integration of the PM with The Big Table (TBT), a document search tool developed by the JRC and in use at the IAEA. The core of TBT is an integrated collection of reference documents including regulatory documents, technical handbooks and trade nomenclatures. The documents are stored in a database. They are searchable by text in a structured way (i. e. on database fields) and also by <b>correspondence</b> <b>tables</b> that relate items by their meaning. To integrate the Physical Model into TBT, the IAEA/SG/SGIM has first turned the PM into a tabular format. JRC has then proposed and implemented a way of coding the PM in TBT tables to better reflect the PM structure. Eleven PM Volumes have been integrated in a TBT-PM database for use by the IAEA. The PM Volumes are linked by <b>correspondence</b> <b>tables</b> to other documents in the TBT collection. By coding the Physical Model into a TBT database format, the original intended uses of the PM are still supported. TBT can ease the consultation of the PM for evaluating States’ nuclear activities by IAEA’s analysts. TBT can be an aid for IAEA’s inspectors preparing for routine and ad hoc inspections, design information verification visits and complementary access operations. Further the PM integrated into TBT {{can be used as a}} tool for training inspectors on steps of the nuclear fuel cycle. Finally implementing the Physical Model multi-level structure into a database-coded format opens the possibility of linking the PM to other taxonomies and collections of open sources relevant for safeguards analyses. JRC. E. 8 -Nuclear securit...|$|R
5000|$|He {{was interviewed}} by ABC Radio NSW and 2CS Radio three times, the Sydney Morning Herald, The Financial Review and by National Channel 7 News five times {{promoting}} local and national health issues between 2007 and 2013 and his <b>correspondence</b> was <b>tabled</b> in the NSW Parliament in May 2008 ...|$|R
40|$|This {{classification}} {{list for}} price data was processed by EISfOM {{in order to}} provide a structured classification systematic to obtain comparable data and enable the exchange of data between national and Eurostat databases. A <b>correspondence</b> <b>table</b> for every national database should be defined, to link national codecs to those of Eurostat. As Eurostat uses a highly aggregated level of crop details (due to the lack of availability of data), member states should be free to use as many disaggregations as needed for their individual purposes, as case in the present list of ZMP in Germany. As long as a <b>correspondence</b> <b>table</b> is defined and data are recorded in a consistent structure, there should not be no problem to exchange data with Eurostat...|$|E
30|$|In {{order to}} {{generate}} the physical satellite to the MRIO system, the around 380 categories of primary raw material extraction data are aggregated into the 33 extraction sectors of EXIOBASE (see Additional file 4 : <b>Correspondence</b> <b>table</b> between raw materials and EXIOBASE sectors). All MFA data are fed into the MRIO system in the unit of 1000  t.|$|E
40|$|This {{classification}} {{list for}} {{land use and}} livestock data was processed by the EISfOM project {{in order to provide}} a structured classification systematic to obtain comparable data and enable the exchange of data between national and Eurostat databases. A <b>correspondence</b> <b>table</b> - similiar to this - for every nation database should be defined, to link national codecs to those of Eurostat. The Cropitem/Livestock classification is used for land use/livestock data according to EU regulation 2092 / 91. The FFS codecs is used for Farm Structure Survey (conventional data) in the different countries...|$|E
40|$|We {{present a}} new version of Babelomics, a {{complete}} suite of web tools for the functional profiling of genome scale experiments, with new and improved methods as well as more types of functional definitions. Babelomics includes different flavours of conventional functional enrichment methods as well as more advanced gene set analysis methods that makes it a unique tool among the similar resources available. In addition to the well-known functional definitions (GO, KEGG), Babelomics includes new ones such as Biocarta pathways or text mining-derived functional terms. Regulatory modules implemented include transcriptional control (Transfac, CisRed) and other levels of regulation such as miRNA-mediated interference. Moreover, Babelomics allows for sub-selection of terms in order to test more focused hypothesis. Also gene annotation <b>correspondence</b> <b>tables</b> can be imported, which allows testing with user-defined functional modules. Finally, a tool for the ‘de novo’ functional annotation of sequences has been included in the system. This allows using yet unannotated organisms in the program. Babelomics has been extensively re-engineered and now it includes the use of web services and Web 2. 0 technology features, a new user interface with persistent sessions and a new extended database of gene identifiers. Babelomics is available at [URL]...|$|R
40|$|Over {{the last}} few years, a growing concern {{developed}} around the trade of equipment designed for nuclear use and nuclear-related dual-use items that may be diverted to non-peaceful uses. Trade data sources and tools presented hereafter can enhance understanding of nuclear related trade from different perspectives. One perspective is nuclear safeguards. Since 2007, the Joint Research Centre has been supporting the IAEA in finding and evaluating collections of open source data on trade. We identified, and documented in a catalogue of trade data, sources stemming from declarations made by importers and exporters to customs authorities. Customs data are collected nationally, processed and published in transactional or aggregated formats by decision of individual States. Bringing these data together results in a large collection that creates a global geographical view on trade, covers all commodities, and reports trade in quantitative form over several years. The data are retrieved by Harmonised System (HS) codes, the taxonomy of goods designed and maintained by the World Customs Organization. HS codes introduce approximations {{in the description of}} the trade making the data of no immediate use to safeguards. Their use requires first mapping items of interest to safeguards verifications to HS codes. To this goal, <b>correspondence</b> <b>tables</b> have been developed by trade analysts and experts of the Harmonised System. To make these tables easy-to-use, we have designed and developed a software tool named The Big Table (TBT) which supports: (a) searching a collection of reference documents relevant to nuclear trade (legal documents and handbooks); (b) selecting items of interest to specific safeguards verifications; (c) mapping items to HS codes by means of <b>correspondence</b> <b>tables.</b> These steps are preliminary to data retrieval from sources on trade described above. These data sources and TBT are currently in use at IAEA¿s Trade and Technology Analysis Unit, for safeguards purposes. Other perspective uses of trade data pertain to the area of export controls. Potential uses include the estimation of trade flows of controlled items to inform the design of export control policies, as well as verifications on compliance with export controls regulations. In this paper we present firstly a collection of data sources on global trade. The paper will then tackle in some detail the first perspective, i. e. the use of trade data to support safeguards with a focus on the TBT software tool for nuclear trade analysis. Other perspectives on the use of trade data will then be briefly outlined. JRC. E. 9 -Nuclear security (Ispra...|$|R
40|$|International audienceFrom {{the outset}} of Mesopotamian archaeology, the archaeologists have {{constantly}} been excavating school tablets from the major sites of the Near East; these tablets were found incorporated in walls, in filling material, in pavements or abandoned in buildings which housed a scribal school. The majority of the tablets date from the Old Babylonian period, i. e. {{the beginning of the}} second millennium B. C. Today these tablets are spread all over the world, kept in the reserve collections of several important archaeology museums of the Near-East, of Europe and of the United States. Ten to twenty percent of these tablets are mathematical tablets. Some of the school mathematical texts have drawn the attention of the historians of science, in particular the numerical tables (multiplication tables, tables of reciprocals, tables of squares, etc.); but others remained in the dark. The latter were the metrological tablets, i. e. tablets containing enumerations of measures of various types (capacities, weights, surfaces, lengths) either in the form of simple lists, or in the form of <b>correspondence</b> <b>tables.</b> Why have these metrological texts been studied so little? What do they tell us about our comprehension of cuneiform mathematics? These are the questions this article intends to answer...|$|R
40|$|The goal of {{the present}} study is to create a {{methodology}} for measuring or estimating public ICT R&D expenditures in the EU and allow subsequently their monitoring. For this purpose, we estimate ICT share in existing disaggregated GBAORD data from the period 2004 - 2010 using an assumption that the share of ICT expenditures in GBAORD is similar to the share of ICT R&D employment. Labour Force Survey (LFS) is employed to calculate ICT R&D employment. In order to link GBAORD and LFS, we define a NABS-NACE <b>correspondence</b> <b>table.</b> Our estimation shows that the total EU ICT GBAORD accounts for € 5. 4 bn (2010) and that, so far, the EU is lagging behind its Digital Agenda target. JRC. J. 3 -Information Societ...|$|E
40|$|We {{construct}} triangulated {{categories of}} mixed motives over a noetherian scheme of finite dimension, extending Voevodsky's definition of motives over a field. We prove that motives with rational coefficients satisfy the formalism {{of the six}} operations of Grothendieck. This includes the analog of the absolute purity theorem and the stability of constructibility under the six operations known for l-adic sheaves. Finally, we associate to any mixed Weil cohomology a system of categories of coefficients and well behaved realization functors. This is the final version, to be submitted. Many changes and complements have been added in version 3 compare to version 2, notably an index of terminology and an index of notations. See also the new introduction for an updated account. A <b>correspondence</b> <b>table</b> between version 2 and version 3 is available: see the file table. pdf...|$|E
3000|$|... +[*] 12  V, −[*] 12  V and +[*] 3.3  V are {{supplied}} {{from the}} power supply unit (PSU), and it consumes about 16.7  W. The XEP uses three high-voltage units, −[*] 1020  V for the photomultiplier (PMT), −[*] 320  V for the five solid-state silicon detectors (SSDs) and −[*] 360  V for the two avalanche photodiodes (APDs). Voltages are slowly changed over the time of 60  s {{to step up and}} to step down the high-voltage power supply under the FPGA control. With reference to a temperature near a point of the APDs, the high voltage is automatically adjusted according to a <b>correspondence</b> <b>table</b> of temperatures and high voltages memorized in the FPGA register. The CPU board is located behind the digital circuit board. The CPU receives data from the FPGA and sends it to the system data recorder that records all telemetry data generated in the satellite.|$|E
40|$|Implicit in {{the idea}} of {{measurement}} is the concept of objectivity. When we measure the temperature using a thermometer, we assume that the measurement we obtain is not dependent on the conditions of measurement, such as which thermometer we use. Any functioning thermometer should give us the same reading of, for example, 75 degrees Fahrenheit. If one thermometer measured 40 degrees, another 250 and a third 150, then the lack of objectivity would invalidate the very idea of accurately measuring temperature. It is this general objectivity that distinguishes physical science measurement from behavioral science measurement. General objectivity requires a construct theory embodied in a specification equation that is capable of estimating indicant calibrations. When these theory-based calibrations are employed in the Rasch model, observations (i. e., raw scores) can be converted into measures without relying on individual or group data on indicants (e. g., items) or objects of measurement (e. g., persons). The benefits of these methods include: (1) the construct theory is exposed to falsification, (2) it is possible to build <b>correspondence</b> <b>tables</b> between observations and measures with recourse only to theory, (3) a generalized linking solution is available for placing observations of all kinds on a common scale, (4) a reproducible unit of measurement ca...|$|R
40|$|Dual-use {{items are}} goods and {{technologies}} that have both civil and military uses. In the European Union their export is controlled and governed by an EC regulation since the year 2000. Its implementation, {{in terms of}} legislation, export authorisations and customs controls, remains the responsibility {{of each of the}} 27 Member States. For reasons linked to the non-proliferation of weapons of mass destruction, competition in trade and free market rules, it is ‘desirable to achieve a uniform and consistent application of controls throughout the EU in order to promote EU and international security and to provide a level playing field for EU exporters’ – as stated in the regulation. How far is the goal? Hard to say since no official data about the trade of dual-use items are shared among Member States, nor with the European Commission, Directorate General Trade, in charge of the dual-use regulation. This report presents sources of generic, statistical trade data and a methodology to create an approximate picture of extra-EU trade flows of dual-use items. The data stem from goods’ declarations made by exporters to customs authorities as part of the normal export process for any commodity. The data are collected at national level, aggregated by categories of goods, and made public in web data services on trade. The data are referred to a commodity classification system, the Combined Nomenclature (CN), in use for customs controls in the EU. However the CN is only indirectly related to dual-use items. <b>Correspondence</b> <b>tables</b> exist that map dual-use items to CN descriptors, but they introduce approximations in the description of the items traded. For this reason the CN trade data provide, in the general case, upper bounds to the real trade volume of dual-use items. Notwithstanding this limitation, the CN trade data may prove useful for a number of issues and assessments needed for export controls. One example is presented in this report. It concerns the estimation of extra-EU trade flows for dual-use chemicals under consideration for inclusion in a Union General Export Authorisation (EU GEA). EU GEAs define a framework valid in all EU Members States whereby the export of selected categories of dual-use items to specific destination countries with a low-risk of diversion is automatically authorised. An analysis of the volume of exports based on CN trade data allows estimating the impact expected for EU exporters by including given dual-use chemicals in an EU GEA. To facilitate the estimation of extra-EU trade flows, it is proposed to develop a dedicated Information Technology tool merging lists of export-controlled items with <b>correspondence</b> <b>tables</b> of CN items’ descriptors and export data. Such a tool can become a design and evaluation instrument to assess the economic impact of alternative policy options to regulate the European dual-use trade. JRC. E. 8 -Nuclear securit...|$|R
40|$|The Rio Grande Compact Commission {{was formed}} {{as a result of}} the interstate compact signed by the states of Colorado, New Mexico and Texas in 1938 and {{approved}} by Congress. The Texas commission’s goal is to implement the compact by assuring the equitable apportioning of waters from the Rio Grande Basin. The collection contains <b>correspondence,</b> reports, <b>tables,</b> maps, and photographs that reflect the activities of the Texas office of the Rio Grande Compact Commission. Past Commissioners include Frank B. Clayton, Julian P. Harrison, J. E. Quaid, Louis A. Scott, and Joe Hanson. Commissioner as of June, 2012 is Patrick Gordo...|$|R
40|$|This verbal autopsy guide aims {{to assist}} staff who conduct verbal autopsies in {{applying}} the International statistical {{classification of diseases}} and related health problems, 10 th revision (ICD- 10) rules to the diagnoses resulting from such an autopsy. The aim is to assist staff who: record diagnoses on the standard certificate of death (certifiers), code the diagnoses (coders) and select {{the cause of death}} (coders). This guide provides an overview of certification, coding and causeof-death assignment so that people working on only one aspect of the verbal autopsy procedure will be able to understand all the steps involved. The use of this guide will ensure consistency in verbal autopsy-based mortality statistics, and their comparability with other sources of cause-ofdeath data that are coded to ICD- 10. It incorporates questions and exercises aimed at acquainting users with ICD- 10 in order to help them avoid frequent pitfalls. The verbal autopsy guide, contained in sections 3. 2 – 3. 8, should be used in conjunction with the three volumes of ICD- 10. The cause-of-death list for verbal autopsy with corresponding ICD- 10 codes (the <b>correspondence</b> <b>table),</b> in section 3. 9 provides a list of verbal autopsy cause-of-death categories that are mapped to broad three- and four-character ICD- 10 categories; the <b>correspondence</b> <b>table</b> simplifies the process of using ICD- 10 for coding. It contains codes, some criteria that ensure categories are used correctly and hints to help users avoid common mistakes. When sufficient information is available to describe the cause of death in more detail than provided for by this table, the coder should refer to the full ICD- 10. A separate field instruction manual must be individually compiled by those who plan to set up a verbal autopsy project. Its content will depend largely on the local setting, and for any particular project should describe: • the process of verbal autopsy; • the organization and workflow of the project; • the collection of data; • the use of separate interview questionnaires; • instructions on interpreting data obtained from verbal autopsy interviews; • the responsibilities and roles of all staff involved; • quality assurance procedures; and • local circumstances, such as who the contact people are, relevant telephone numbers, and whether computers are available...|$|E
40|$|In this poster {{we intend}} to show {{students}} {{how to use the}} instrumentality of ANACOR and HOMALS procedures for nominal or categorical data analysis, in particular analysis of narratives episodes or interviews content. A <b>correspondence</b> <b>table</b> is any two-way table whose cells contain some measurement of correspondence between the rows and the columns of the table ” (SPSS, 1990, p. B- 31). ANACOR also known as correspondence analysis serves to analyze either two-way contingency [or correspondence] tables or data that can be expressed as a two-way table, such as brand preference or sociometric. Homogeneity analysis {{can be thought of as}} principal components analysis of nominal data. HOMALS is a multiple correspondence analysis, that is a nonlinear association procedure of homogeneity analysis, suitable for data reduction. It also can be considered as an optimal scaling method by alternative least squares and serves to analyze multiway contingency table data. These are procedures suitable to analyze multiple nominal variables in a multiway contingence table. With this multivariate analysis the relationships among variables are represented in a few dimensions, for example two or three...|$|E
40|$|We formalize the Call Arity {{analysis}} [Bre 15 a], as {{implemented in}} GHC, and prove both functional correctness and, more interestingly, safety (i. e. the transformation does not increase allocation). A highlevel {{overview of the}} work {{can be found in}} [Bre 15 b]. We use syntax and the denotational semantics from an earlier work [Bre 13], where we formalized Launchbury’s natural semantics for lazy evaluation [Lau 93]. The functional correctness of Call Arity is proved with regard to that deno-tational semantics. The operational properties are shown with regard to a small-step semantics akin to Sestoft’s mark 1 machine [Ses 97], which we prove to be equivalent to Launchbury’s semantics. We use Christian Urban’s Nominal 2 package [UK 12] to define our terms and make use of Brian Huffman’s HOLCF package for the domain-theoretical aspects of the development [Huf 12]. Artifact <b>correspondence</b> <b>table</b> The following table connects the definitions and theorems from [Bre 15 b] with their cor-responding Isabelle concept in this development. Concept corresponds to in theory Syntax nominal-datatype expr Terms in [Bre 13] Stack type-synonym stack SestoftCon...|$|E
40|$|Global trade {{data are}} {{collected}} worldwide and made available by national statistical services {{as well as}} dedicated data providers. JRC has carried out a support task to IAEA to identify main trade data sources and explore uses for safeguards. In this context a software tool has been developed in support to nuclear trade analysis. The tool, called The Big Table (TBT), allows IAEA¿s analysts to search control lists, identify items of interest to trade-related case studies, and link these to technical documentation and descriptors needed to retrieve global trade data. A distinguishing trait of TBT is that it enables searching in an ¿inter-related way¿ a collection of reference documents for export controls on nuclear and nuclear-related items. Reference documents include: regulatory documents, technical handbooks and the Harmonized System, the taxonomy of goods by the World Customs Organization used by traders to declare exports and imports to customs. By inter-related search it is meant that semantically related items listed in different documents of TBT¿s collection are put in correspondence by ad hoc <b>correspondence</b> <b>tables.</b> In this way, any document in the collection can be taken as starting point for a search, and retrieve complementary perspectives on items given other relevant documents. TBT can serve a variety of tasks and communities underpinning export controls, including the rating of items by licensing authorities and commodity identification for customs controls. JRC. E. 9 -Nuclear security (Ispra...|$|R
30|$|Regarding the SBP, the {{literature}} reports conflicting results {{about the effect}} of glucocorticoid treatment on systolic blood pressure; some studies observed an increase in SBP in rats (Scheuer and Bechtold 2002) and humans (Whitworth et al. 1989) whereas other did not (Marquet et al. 1999). In the present study, pharmacological treatment with the administration of 60  mg per day of prednisone during 7  days did not increase systolic blood pressure (SBP). This result is in accordance with a study by Marquet et al. (1999) who investigated the effect of dexamethasone (a synthetic glucocorticoid with a higher activity than prednisone) at low (1  mg/day) and high doses (3  mg/day) during 4  days on the cardiovascular system. As in our study, steroid administration did not change SBP whatever the dosage. Conversely, a significant increase in SBP was observed (Brotman et al. 2006) following higher doses of dexamethasone (6  mg/day for 5  days). According to <b>correspondence</b> <b>tables</b> for glucocorticoids (Meikle and Tyler 1977), 60  mg/day of prednisone would correspond to 9  mg/day of dexamethasone. Therefore, our dosage of prednisone should have produced stronger effects than the dexamethasone treatment administered in both of the above cited studies (Brotman et al. 2006; Marquet et al. 1999). In addition, differences in the methods used to measure blood pressure might account for this discrepancy. Indeed, BP results were the average of three punctual measurements in the two previous articles (Brotman et al. 2006; Marquet et al. 1999) whereas more accurate results are expected from the continuous, 10  min BP recording used in the present study.|$|R
40|$|Abstract. There {{are many}} {{problems}} requiring a semantic {{account of a}} database schema. At its best, such an account consists of mapping formulas between the schema and a formal conceptual model or ontology (CM) of the domain. This paper describes the underlying principles, algorithms, and a prototype of a tool which infers such semantic mappings when given simple <b>correspondences</b> from <b>table</b> columns in a relational schema and datatype properties of classes in an ontology. Although the algorithm presented is necessarily heuristic, we offer formal results stating that the answers returned are “correct ” for relational schemas designed according to standard Entity-Relationship techniques. We also report on experience in using the tool with public domain schemas and ontologies. ...|$|R
