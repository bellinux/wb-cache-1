51|582|Public
40|$|We {{developed}} a fast and efficient method to derive and apply a natural <b>colour</b> <b>mapping</b> for night-time imagery from multi-band sensors. The <b>colour</b> <b>mapping</b> {{is derived from}} the combination of a multi-band image and a corresponding natural colour reference image. The mapping optimizes the match between the multi-band image and the reference image, and yields a nightvision image with a colour distribution {{similar to that of the}} reference image. The actual mapping procedure is extremely simple and fast, and once it has been derived the <b>colour</b> <b>mapping</b> can be deployed in realtime to other multi-band images. Displaying night-time imagery in natural colours may help human observers to process this type of imagery faster and better, thereby improving situational awareness and reducing reaction times...|$|E
40|$|International audienceThe {{objective}} of <b>colour</b> <b>mapping</b> or colour transfer methods is to recolour a given image or video by deriving a mapping between that image and another image {{serving as a}} reference. These methods have received considerable attention in recent years, both in academic literature and industrial applications. Methods for recolouring images have often appeared under the labels of colour correction, colour transfer or colour balancing, to name a few, but their goal is always the same: mapping the colours of one image to another. In this paper, we present a comprehensive overview of these methods and offer a classification of current solutions depending not only on their algorithmic formulation but also their range of applications. We also provide a new dataset and a novel evaluation technique called ‘evaluation by <b>colour</b> <b>mapping</b> roundtrip’. We discuss the relative merit of each class of techniques through examples and show how <b>colour</b> <b>mapping</b> solutions can have been applied to a diverse range of problems...|$|E
40|$|The {{variation}} in the seed coat colour of adzuki beans among varieties, harvest years and growing locations, using a two-dimensional <b>colour</b> <b>mapping</b> technique was investigated. It {{was found that the}} differences of the seed coat colour among varieties contributed to the variation of chroma (C*) values, while the differences of the seed coat colour among harvest years were associated with lightness (L*) values. The L* values for the seed coat colour increased when the temperature during the maturing period of adzuki beans was low, and decreased when the temperature was high. The difference in the seed coat colour among the samples from different growing locations was much larger in the L* values than the C* values for samples of the same variety. The seed coat colours of adzuki beans harvested in Hokkaido and China had significantly different C* values, and were easily discriminated by the <b>colour</b> <b>mapping</b> method. This study showed that the two-dimensional <b>colour</b> <b>mapping</b> was useful for evaluating the seed coat colour of adzuki beans, which varies among samples of different varieties, harvest years and growing locations...|$|E
40|$|Many <b>colour</b> <b>maps</b> {{provided}} by vendors have highly uneven perceptual contrast over their range. It {{is not uncommon}} for <b>colour</b> <b>maps</b> to have perceptual flat spots that can hide a feature as large as one tenth of the total data range. <b>Colour</b> <b>maps</b> may also have perceptual discontinuities that induce the appearance of false features. Previous work in the design of perceptually uniform <b>colour</b> <b>maps</b> has mostly failed to recognise that CIELAB space is only designed to be perceptually uniform at very low spatial frequencies. The most important factor in designing a <b>colour</b> <b>map</b> is to ensure that the magnitude of the incremental change in perceptual lightness of the colours is uniform. The specific requirements for linear, diverging, rainbow and cyclic <b>colour</b> <b>maps</b> are developed in detail. To support this work two test images for evaluating <b>colour</b> <b>maps</b> are presented. The use of <b>colour</b> <b>maps</b> in combination with relief shading is considered and the conditions under which colour can enhance or disrupt relief shading are identified. Finally, a set of new basis colours for the construction of ternary images are presented. Unlike the RGB primaries these basis colours produce images whereby the salience of structures are consistent irrespective of the assignment of basis colours to data channels. Comment: 42 pages, 25 figure...|$|R
2500|$|Two volumes {{planned for}} occupations of Germany and Turkey {{cancelled}} after Foreign Office objections. Research continued in 1930s, interest revived 1942. Rhineland volume commissioned and completed 1943. Published 1944, marked Confidential, [...] printed. Republished IWM-HMSO, green dj, <b>colour</b> <b>maps,</b> 1987, IWM-NMP pbk. <b>Colour</b> <b>maps,</b> 2009.|$|R
5000|$|... #Caption: A 2D {{resolved}} Nuclear Magnetic Resonance Cryoporometry <b>colour</b> <b>map</b> of pore sizes in 4 tubes. A standard NMR imaging protocol {{is added}} to a standard NMR cryoporometry protocol, so as to spatially resolve the mesoscale median pore-size on the macroscale, as a 2D <b>colour</b> <b>map.</b>|$|R
40|$|Human scene {{recognition}} {{performance was}} tested {{with images of}} night-time outdoor scenes. The scenes were registered both with a dual band (visual and near infrared) image intensified low-light CCD camera (DII) and with a thermal middle wavelength band (3  5 mm) infrared (IR) camera. Fused imagery was produced through a grayscale pyramid image merging scheme, in combination with two different colour mappings. Observer performance was tested {{for each of the}} (individual and fused) image modalities. The results show that DII imagery contributes most to global scene recognition (situational awareness), whereas IR imagery serves best for the detection and recognition of targets like humans and vehicles. Grayscale fused imagery yields appreciable performance levels in most conditions. With an appropriate <b>colour</b> <b>mapping,</b> colour fused imagery yields the best overall scene recognition performance. However, an inappropriate <b>colour</b> <b>mapping</b> significantly decreases observer performance compared to grayscale image fusion. The deployment of a DII system in addition to a 3 - 5 mu IR system through image fusion can increase the performance of human observers when the <b>colour</b> <b>mapping</b> relates {{to the nature of the}} visual task and the conditions (scene content) at hand...|$|E
40|$|We {{present a}} {{hardware}} design based around scan-line algorithms. The design can perform <b>colour</b> <b>mapping,</b> environment mapping and produce shading effects {{which include a}} specular term. We describe the algorithms which are implemented, and the approximations we have made to achieve near real-time performance. 1. ...|$|E
40|$|Abstract- We {{present a}} fast and {{efficient}} method to derive and apply natural colours to nighttime imagery from multiband sensors. The <b>colour</b> <b>mapping</b> {{is derived from}} the combination of a multiband image and a corresponding daytime colour reference. The mapping optimizes the match between the multiband image and the reference, and yields a nightvision image with colours similar to the daytime image. The mapping procedure is simple and fast. Once it has been derived the <b>colour</b> <b>mapping</b> can be deployed in realtime. Different colour schemes can be used tailored to the environment and the application. The expectation is that by displaying nighttime imagery in natural colours human observers will be able to interpret the imagery better and faster, thereby improving situational awareness and reducing detection times...|$|E
5000|$|Two volumes {{planned for}} occupations of Germany and Turkey {{cancelled}} after Foreign Office objections. Research continued in 1930s, interest revived 1942. Rhineland volume commissioned and completed 1943. Published 1944, marked Confidential, 100 copies printed. Republished IWM-HMSO, green dj, <b>colour</b> <b>maps,</b> 1987, IWM-NMP pbk. <b>colour</b> <b>maps,</b> 2009.|$|R
5000|$|Large (A4) format with {{fold-out}} character {{sheet and}} <b>colour</b> <b>map</b> ...|$|R
5000|$|The atlas {{contains}} 36 <b>colour</b> <b>maps,</b> {{divided into}} three sections: ...|$|R
40|$|This article proposes an {{original}} method for grading the colours between different images or shots. The {{first stage of}} the method {{is to find a}} one-to-one <b>colour</b> <b>mapping</b> that transfers the palette of an example target picture to the original picture. This is performed using {{an original}} and parameter free algorithm that is able to transform any N-dimensional probability density function into another one. The proposed algorithm is iterative, non-linear and has a low computational cost. Applying the <b>colour</b> <b>mapping</b> on the original picture allows reproducing the same ‘feel ’ as the target picture, but can also increase the graininess of the original picture, especially if the colour dynamic of the two pictures is very different. The second stage of the method is to reduce this grain artefact through an efficient post-processing algorithm that intends to preserve the gradient field of the original picture...|$|E
40|$|A common task in image editing is {{to change}} the colours of a picture to match the desired colour grade of another picture. Finding the correct <b>colour</b> <b>mapping</b> is tricky because it {{involves}} numerous interrelated operations, like balancing the colours, mixing the colour channels or adjusting the contrast. Recently, a number of automated tools have been proposed to find an adequate one-to-one <b>colour</b> <b>mapping.</b> The focus in this paper is on finding the best linear colour transformation. Linear transformations have been proposed in the literature but independently. The aim of this paper is thus to establish a common mathematical background to all these methods. Also, this paper proposes a novel transformation, which is derived from the Monge-Kantorovicth theory of mass transportation. The proposed solution is optimal {{in the sense that it}} minimises the amount of changes in the picture colours. It favourably compares theoretically and experimentally with other techniques for various images and under various colour spaces. ...|$|E
40|$|Objectives:Currently colour flow Duplex {{examination}} of the iliac arteries is at best 84 – 92 % sensitive. In an attempt to find a technique to improve on this sensitivity we have studied the effect of Klean Prep, an iso-osmotic bowel preparation, on the Duplex image and Doppler signal obtained when scanning iliac arteries. Methods:Twenty iliac segments in 10 arteriopaths were scanned by a blinded observer, after either starving for 12 h or having Klean Prep bowel preparation. Grey scale image, <b>colour</b> <b>mapping</b> and Doppler signal to noise ratios were scored on a linear analogue system. Each patient was subsequently rescanned after the other method of preparation and was once again scored by a blinded observer. The two sets of scores were then compared. Results:We found significant improvements in the linear analogue scoring of grey scale images, <b>colour</b> <b>mapping</b> and Doppler signal to noise ratios, when using Klean Prep as opposed to starving the patient prescan. Conclusions:Preparing patients with Klean Prep before iliac Duplex examination improves the visualisation of these arteries...|$|E
30|$|Neuquant[4]: A {{one-dimensional}} self-organising Kohonen {{neural network}} {{is applied to}} generate the <b>colour</b> <b>map.</b>|$|R
50|$|If the ILBM file {{contains}} a CAMG chunk in which bit 7 is set (i.e. 0x80 in hexadecimal). The file expects {{to make use}} of the EHB (Extra Half-Brite) mode of the Amiga chipset. The <b>colour</b> <b>map</b> will have no more than 32 entries, but the image will have 6 bitplanes. The most significant bitplane should be regarded as a flag, when unset, use the lower 5 bits as an index into the <b>colour</b> <b>map</b> as usual. When the flag is set; use the lower 5 bits as an index into the <b>colour</b> <b>map,</b> but the actual colour to be used should be half as bright, which can be achieved by shifted the RGB components of the colour one bit to the right. Alternatively, create a <b>colour</b> <b>map</b> with 64 entries, and copy the lower 32 entries into the upper half, converting them to half brightness; then use all 6 bitplanes as a colour index.|$|R
5000|$|An image {{containing}} no <b>colour</b> <b>map</b> {{and only}} 8 bitplanes {{may be a}} greyscale image: ...|$|R
40|$|Human perceptual {{performance}} was tested {{with images of}} nighttime outdoor scenes. The scenes were registered both with a dual band (visual and near infrared) image intensified low-light CCD camera (DII) and with a thermal middle wavelength band (3 - 5 μm) infrared (IR) camera. Fused imagery was produced through a pyramid image merging scheme, in combination with different colour mappings. For all (individual and fused) image modalities, small patches of the scenes, displaying a range of different objects and materials, were briefly presented to human observers. The sensitivity of human observers was tested for different recognition tasks. The results show that greyscale image fusion yields improved performance levels for most perceptual tasks investigated here. When an appropriate <b>colour</b> <b>mapping</b> scheme is applied, the addition of colour to greyscale fused imagery significantly increases observer sensitivity for a given condition and a certain task. However, inappropriate use of colour significantly decreases observer performance compared to straightforward greyscale image fusion. This suggests that <b>colour</b> <b>mapping</b> should adapt to the visual task and the conditions (scene content) at han...|$|E
40|$|A pixel based <b>colour</b> <b>mapping</b> {{algorithm}} is presented {{that produces a}} fused false colour rendering of two gray level images representing different sensor modalities. The result-ing fused false colour images have a higher information content than each of the original images and retain sensor-specific image information. The unique component of each image modality is enhanced in the resulting fused colour image representation. First, the common component of the two original input images is determined. Second, the common component is subtracted from the original images to obtain the unique component of each image. Third, the unique component of each image modality is subtracted from {{the image of the}} other modality. This step serves to enhance the representation of sensor specific details in the final fused result. Finally, a fused colour image is produced by displaying the images resulting from the last step through respec-tively the red and green channels of a colour display. The method is applied to fuse thermal and visual images. The results show that the <b>colour</b> <b>mapping</b> enhances the visibility of certain details and preserves the specificity of the sensor information. The fused images also have a fairly natural appearance. The fusion scheme involves only operations on corresponding pixels. The resolution of a fused image is therefore directly related to the resolution of the input images. Before fusing, the contrast of the images can be enhanced and their noise can be reduced by standard image processing techniques. The <b>colour</b> <b>mapping</b> {{algorithm is}} computational simple. This implies that the investi-gated approaches can eventually be applied in real time and that the hardware needed is not too complicated or too voluminous (an important consideration when it has to fit in an aeroplane for instance) ...|$|E
40|$|Climate {{is often}} {{defined in terms}} of {{discrete}} classes. Here I use bivariate <b>colour</b> <b>mapping</b> to show that the global distribution of K¨oppen-Geiger climate classes can largely be reproduced by combining the simple means of two key states of the climate system 5 (i. e., air temperature and relative humidity). This allows for a classification that is not only continuous in space, but can be applied at and transferred between timescales ranging from minutes to decades...|$|E
5000|$|The creek in our backyard: a {{practical}} guide for habitat restoration, Second edition revised and expanded June 2013.  Save Our Waterways Now Inc, 2013 59 pages, <b>colour</b> illustrations, <b>colour</b> <b>map,</b> <b>colour</b> portraits ...|$|R
25|$|Addenda and {{corrigenda}} {{sheet with}} Italy 1915–1919. Republished IWM-BP b/w maps 1991, IWM-NMP pbk. <b>Colour</b> <b>maps</b> 2009.|$|R
25|$|Republished Imperial War Museum-Battery Press, b/w maps, 1992, Imperial War Museum-Naval and Military Press, pbk, <b>colour</b> <b>maps,</b> 2009.|$|R
40|$|This paper {{describes}} seagrass {{and ocean}} <b>colour</b> <b>mapping</b> off Peninsular Malaysia. The seagrass were extracted form visible bands of Landsat TM using the depth invariant {{index of the}} seabottom type. The ocean colour which is much referred to micro-plankton concentration is derived by regressing samples form known site collected at time of satellite overpass. Both these information were then input into GIS database which were also being established to assist the Marine Fisheries Management and Development Center in managing and monitoring coastal areas...|$|E
30|$|The first {{pertains}} to the viewing modality and its graphical user interface, where and how visual control elements are placed, manipulated, and how the aspect of an image mode are ‘switched’ from one data view to another. These barriers can be categorised as graphical user interface barriers. The second set of barriers to efficient use and understanding relate to what the image set is communicating, in any particular imaging mode. These can relate to issues of scale, what the <b>colour</b> <b>mapping</b> presents or tangibility issues associated with sample position or shape.|$|E
40|$|International audienceComputer-generated {{visualizations}} of geoscientific data, such {{as those}} from climate models are in high demand {{for a wide variety}} of usages; these include, among others, scientific publications, reports and graphical aides for the general public's improved understanding of complex developments. The paper will focus on the effects of colours in two-dimensional displays. Practical examples are given from which it becomes clear that considerable confusion or even damage can arise from an uninformed use of <b>colour</b> <b>mapping</b> and if results become, e. g., published in an unchecked manner by the media...|$|E
5000|$|A2 vinyl <b>colour</b> <b>map</b> of Allansia, {{from the}} {{original}} material from Jonathan Green, Steve Jackson and Ian Livingstone.|$|R
5000|$|Republished Imperial War Museum-Battery Press, b/w maps, 1992, Imperial War Museum-Naval and Military Press, pbk, <b>colour</b> <b>maps,</b> 2009.|$|R
25|$|Addenda and Corrigenda {{sheet with}} Italy 1915–1919. Republished IWM-BP b/w maps 1992 Map Case 1994, IWM-NMP <b>colour</b> <b>maps</b> 2009.|$|R
40|$|This work {{presents}} a visualization methodology for the correct comprehension {{and interpretation of}} ERT data by archaeologists. The authors developed a methodology based not only in <b>colour</b> <b>mapping</b> and slicing techniques but also on contouring and interaction procedures, obtaining {{an alternative to the}} traditional 2 D pseudosection data visualization workflows. The implementation was carried out with the Visualization Toolkit from Kitware Inc. and is illustrated using two data samples: the first one was obtained on a hillfort in Boticas (Portugal) and the second one was acquired on an urban archaeological intervention in Braga (Portugal). info:eu-repo/semantics/publishedVersio...|$|E
40|$|This paper {{discusses}} {{three distinct}} techniques for animation of procedural textures and describes the assisting software tool. Animation is attained {{by moving the}} rendered point before texture evaluation, changing the definition of texture space or changing the texture <b>colour</b> <b>mapping.</b> Examples are given for textures that base on noise and turbulence functions in order to simulate natural phenomena. Some phases of texture animation process can be automated by using the code generator supported by a library of animation effects. Aspects of practical implementation are discussed and Renderman compliant code is presented...|$|E
40|$|The paper {{outlines}} {{the nature of}} the geographical information system that was developed for the BBC Domesday optical disc project. The successful exploitation of optical disc storage for geographical analysis and mappings dependent on the development of appropriate data structures that allow fastest possible data retrieval for geographical areas of interest. The authors describe how they achieved this objective such that a low powered BBC micro-computer is able to offer interactive <b>colour</b> <b>mapping</b> of over 20, 000 variables for 33 different sets of geographical areas at ten different levels of resolution...|$|E
25|$|No Map Case, map folder {{on inside}} back cover. Republished IWM-BP b/w maps 1993, IWM-NMP pbk. <b>Colour</b> <b>maps</b> 2009.|$|R
5000|$|Addenda and Corrigenda {{sheet with}} Italy 1915-1919. Republished IWM-BP b/w maps 1992 Map Case 1994, IWM-NMP <b>colour</b> <b>maps</b> 2009.|$|R
5000|$|No Map Case, map folder {{on inside}} back cover. Republished IWM-BP b/w maps 1993, IWM-NMP pbk. <b>colour</b> <b>maps</b> 2009.|$|R
