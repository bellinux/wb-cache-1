0|810|Public
40|$|Exploitation of {{architectural}} support for Prolog-like languages takes {{one of two}} main paths: compiler-based or interpreter-based. The former scheme enforces the transformation from a logic program {{to a set of}} instructions tailored for Prolog to accommodate the instruction-driven von Neumann processor, while the latter implements a complicated inference procedure as a microinterpreter to realize the relation-driven paradigm of logic programming. In this paper, we present a new sequential control model developed {{in the design of the}} LI-Engine. The control unit of LI-Engine is designed by fully exploiting the simplicity of the relation-driven paradigm. The proposed algorithm adopts the post-choice method and involves only four basic cache operations, ten assignments and four iterators controlled by simple Boolean tests. We believe that this research offers another possible direction for developing <b>high</b> performance logic <b>inference</b> <b>machines.</b> 1 Introduction In the last ten years, many archi [...] ...|$|R
40|$|R. Freivalds and C. H. Smith [FS 92] {{proved that}} {{probabilistic}} limited memory inductive <b>inference</b> <b>machines</b> can learn some classes of total recursive functions with a probability I which cannot be learned by deterministic limited memory inductive <b>inference</b> <b>machines.</b> We introduce quantum limited memory inductive <b>inference</b> <b>machines</b> as quantum finite automata used as inductive <b>inference</b> <b>machines.</b> Our main result below shows that quantum limited memory inductive <b>inference</b> <b>machines</b> can learn classes of total recursive functions not learnable by any deterministic and even by probabilistic limited memory inductive <b>inference</b> <b>machines...</b>|$|R
40|$|AbstractFreivalds and Smith [R. Freivalds, C. H. Smith Memory limited {{inductive}} <b>inference</b> <b>machines,</b> Springer Lecture Notes in Computer Science 621 (1992) 19 – 29] {{proved that}} probabilistic limited memory inductive <b>inference</b> <b>machines</b> can learn with probability  1 certain classes of total recursive functions, which cannot be learned by deterministic limited memory inductive <b>inference</b> <b>machines.</b> We introduce quantum limited memory inductive <b>inference</b> <b>machines</b> as quantum finite automata acting as inductive <b>inference</b> <b>machines.</b> These machines, we show, can learn classes of total recursive functions not learnable by any deterministic, nor even by probabilistic, limited memory inductive <b>inference</b> <b>machines...</b>|$|R
40|$|AbstractThe {{notion of}} an {{inductive}} <b>inference</b> <b>machine</b> aggregating a team of <b>inference</b> <b>machines</b> models the problem of making use of several explanations for a single phenomenon. This article investigates {{the amount of information}} necessary for a successful aggregation of the theories given by a team of <b>inference</b> <b>machines.</b> Variations of using different kinds of identification and aggregation are investigated...|$|R
50|$|In the mid-1980s, Integrated <b>Inference</b> <b>Machines</b> (IIM) built prototypes of Lisp {{machines}} named Inferstar.|$|R
40|$|Abstract—Based on the {{research}} of the intelligent cataract ultrasonic emulsification instrument, mainly discusses the principle of design and inference algorithm of the <b>inference</b> <b>machine</b> of intelligent ultrasonic emulsification instrument. Designing the cataract expert knowledge base {{by the use of}} relational database, the <b>inference</b> <b>machine</b> can simulate the real doctor thinking features effectively; at the same time, according to the patient's cataract symptoms, it can make intelligent judgment to select the ultrasonic energy level for the emulsifying needle, and effectively control the release of energy. The inference strategy is the combined of deductive reasoning, certainty and forward inference, so as to improve the efficiency of <b>inference</b> <b>machine.</b> Through the verification tests, the system obtains better inference results...|$|R
40|$|Ph. D. ThesisInductive {{inference}} is {{a process}} of hypothesizing a general rule from examples. As a successful inference criterion for inductive inference of formal languages and models of logic programming, we have mainly used Gold 2 ̆ 7 s identification in the limit. An <b>inference</b> <b>machine</b> M is said to infer a concept L in the limit, if the sequence of guesses from M which is successively fed a sequence of examples of L converges to a correct expression of L, that is, all guesses from M become a unique expression in a finite time and that the expression is a correct one. A class, or a hypothesis space, is said to be inferable in the limit, if there is an <b>inference</b> <b>machine</b> M which infers every concept in the class. In the present thesis, we mainly investigate three criteria related to the identification in the limit. As we will see, they are necessary for practical applications of machine learning or machine discovery. The first criterion requires an <b>inference</b> <b>machine</b> to produce a unique guess. That is, we apply so-called finite identification to concept learning. As stated above, ordinary inductive inference is an infinite process. Thus we can not decide in general whether a sequence of guesses from an <b>inference</b> <b>machine</b> has converged or not at a certain time. To the contrary, in the criterion of finite identification, if an <b>inference</b> <b>machine</b> produces a guess, then it is a conclusive answer. The second criterion requires an <b>inference</b> <b>machine</b> to refute a hypothesis space in question, if a target concept is not in the hypothesis space. In the ordinary inductive inference, the behavior of an <b>inference</b> <b>machine</b> is not specified, when we feed examples of a target concept not belonging to the hypothesis space. That is, we implicitly assume that every target concept belongs to the hypothesis space. As far as data or facts are presented according to a concept that is unknown but guaranteed to be in the hypothesis space, the machine will eventually identify the hypothesis. However this assumption is not appropriate, if we want an <b>inference</b> <b>machine</b> to infer or to discover an unknown rule which explains examples or data obtained from scientific experiments. Thus we propose a successful inference criterion where, if there is no concept in the hypothesis space which coincides with a target concept, then an <b>inference</b> <b>machine</b> explicitly tells us this and stops in a finite time. The third criterion requires an <b>inference</b> <b>machine</b> to infer a minimal concept within the hypothesis space concerned. In actual applications of inductive inference, there are many cases where we want an <b>inference</b> <b>machine</b> to infer an approximate concept within the hypothesis space, even when there is no concept which exactly coincides with the target concept. Here we take a minimal concept as an approximate concept within the hypothesis space, and discuss inferability of a minimal concept of the target concept which may not belong to the hypothesis space. That is, we force an <b>inference</b> <b>machine</b> to converge to an expression of a minimal concept of the target concept, if there is a minimal concept of the target concept within the hypothesis space. In the present thesis, we discuss inferability of recursive concepts under the above three criteria, and show some necessary and sufficient conditions for inferability and some comparisons between inferable classes. Furthermore as practical and concrete hypothesis spaces, we take the classes definable by so-called lengt h-bounded elementary formal systems (EFS 2 ̆ 7 s, for short) and discuss their inferability in the above three criteria. In 1990, Shinohara showed that the classes definable by length-bounded EFS 2 ̆ 7 s with at most n axioms are inferable in the limit from positive data for any n 2 : 1. In the present thesis, we show that the above classes are also refutably inferable from complete data, i. e. positive and negative data, as well as minimally inferable from positive data. This means that there are rich hypothesis spaces that are refutably inferable from complete data or minimally inferable from positive data...|$|R
40|$|Abstract. In {{ordinary}} learning paradigm, {{a target}} concept, whose examples are fed to an <b>inference</b> <b>machine,</b> {{is assumed to}} belong to a hypothesis space which is given in advance. However this assumption is not appropriate, if we want an <b>inference</b> <b>machine</b> to infer or to discover an unknown rule which explains examples or data obtained from scientific experiments. In their previous paper, Mukouchi and Arikawa discussed both refut ability and inferability of a hypothesis space from examples. In this paper, we take a minimal concept as an approximate concept within a hypothesis space, and discuss inferability of a minimal concept of the target concept which may not belong to the hypothesis space. That is, we force an <b>inference</b> <b>machine</b> to converge to a minimal concept of the target concept, if there are minimal concepts of the target concept within the hypothesis space. We also show that there are some rich hypothesis spaces that are minimally inferable from positive data. 1...|$|R
40|$|Abstract. The paper {{introduces}} {{a method of}} transition from TIL into Prolog system and vice versa, in order to utilize Prolog <b>inference</b> <b>machine</b> in the deductive system of TIL. We specify {{a subset of the}} set of TIL constructions the elements of which can be encoded in Prolog language, and introduce the method of translation from TIL into Prolog. Since Prolog is less expressive than TIL, we have to build up a TIL functional overlay that makes it possible to realize the reverse transition from Prolog into TIL in a near to equivalent way. Key words: TIL, T IL-Script language, <b>inference</b> <b>machine,</b> Prolog...|$|R
40|$|Inductive <b>inference</b> <b>machines</b> are {{algorithmic}} devices which {{attempt to}} synthesize (in the limit) programs for a function while they examine {{more and more}} of the graph of the function. There are many possible criteria of success. We study the inference of nearly minimal size programs. Our principal results imply that nearly minimal size programs can be inferred (in the limit) without loss of inferring power provided we are willing to tolerate a finite, but not uniformly, bounded, number of anomalies in the synthesized programs. On the other hand, there is a severe reduction of inferring power in inferring nearly minimal size programs if the maximum number of anomalies allowed is any uniform constant. We obtain a general characterization for the classes of recursive functions which can be synthesized by inferring nearly minimal size programs with anomalies. We also obtain similar results for Popperian inductive <b>inference</b> <b>machines.</b> The exact tradeoffs between mind change bounds on inductive <b>inference</b> <b>machines</b> and anomalies in synthesized programs are obtained. The techniques of recursive function theory including the recursion theorem are employed...|$|R
40|$|Ground {{investigations}} {{often use}} trial pits and borehole cores on construction sites {{to determine the}} strata likely to be encountered at various depths. The data obtained from trial pits can be coded into a form {{that can be used}} as sample observations for input to a grammatical <b>inference</b> <b>machine.</b> A grammatical <b>inference</b> <b>machine</b> is a black box, which when presented with a sample of observations of some unknown source language, produces a grammar which is compatible with the sample. This article presents a heuristic model for a grammatical <b>inference</b> <b>machine,</b> which takes as data sentences and non-sentences identified as such, and is capable of inferring grammars in the class of context-free grammars expressed in Chomsky Normal Form. An algorithm and its corresponding software implementation have been developed based on this model. The software takes, as input, coded representations of ground investigation data, and produces as output a grammar which describes and classifies the geotechnical data observed in the area, and also promises the possibility of being able to predict the likely configuration of strata across the site...|$|R
40|$|All {{processes}} in a software implemented <b>inference</b> <b>machine</b> are called fuzzy processes. These processes are fuzzification, fuzzy inference and defuzzification, executed in that order. The implementation itself {{is called a}} fuzzy <b>inference</b> <b>machine</b> or a fuzzy logic system. This thesis describes such a system in a parallel implementation with a specific approach, where complex operations are broken down into multiple simpler ones. We used the CUDA architecture, which allows us the usage of general purpose parallel computing on modern GPU’s. At the end we tested this implementation, {{in comparison with the}} sequential implementation on the CPU, by comparing the precision of the computational results and the needed times of operation algorithms...|$|R
30|$|Step 4 - 2 Otherwise, {{the score}} shall be calculated. In this paper, {{the design of}} the QoE score is {{accomplished}} by employing intelligent <b>inference</b> <b>machine</b> method to avoid the constraint by linear method, and directly reasoning {{on the basis of the}} parameter indexes.|$|R
40|$|AbstractDegrees of inferability {{have been}} {{introduced}} to measure the learning power of inductive <b>inference</b> <b>machines</b> which have access to an oracle. The classical concept of degrees of unsolvability measures the computing power of oracles. In this paper we determine the relationship between both notions...|$|R
50|$|Particle {{filters and}} Feynman-Kac {{particle}} methodologies find application in signal and image processing, Bayesian <b>inference,</b> <b>machine</b> learning, risk analysis and rare event sampling, engineering and robotics, artificial intelligence, bioinformatics, phylogenetics, computational science, Economics and mathematical finance, molecular chemistry, computational physics, pharmacokinetic and other fields.|$|R
40|$|In {{this paper}} we {{describe}} fuzzy rules {{used in the}} developed prototype of a “fuzzy music interpretation system ” [4]. The core of this system consists of two essential units, the rule base and the <b>inference</b> <b>machine.</b> The rule base contains general IF–THEN interpretation rules, formulated by an experienced pianist. The <b>inference</b> <b>machine</b> contains both conventional and advanced fuzzy information processing strategies. Once the system is fed with the information—the notes and special signs such as “ppp ” and “legato”, coded {{in accordance with the}} MIDI format—contained in the score of Beethoven’s “Für Elise”, it generates an interpretation of this piece of music and renders it {{in the form of a}} MIDI file. Certain refinement parameters allow us to modify the character of the interpretation. 1...|$|R
40|$|We examine uniform {{procedures}} {{for improving the}} scientific competence of inductive <b>inference</b> <b>machines.</b> Formally, such procedures are construed as recursive operators. Several senses of improvement are considered, including (a) enlarging the class of functions on which success is certain, and (b) transforming probable success into certain success...|$|R
40|$|We outline an {{abstract}} <b>inference</b> <b>machine</b> for producing discourse models in natural language understanding. This machine has tableaux as its central data structure and can operate in model generation and theorem proving modes. Search spaces {{are controlled by}} keeping track of NP saliences and equipping proof rules with costs...|$|R
50|$|Five running Parallel <b>Inference</b> <b>Machines</b> (PIM) were {{eventually}} produced: PIM/m, PIM/p, PIM/i, PIM/k, PIM/c. The project also produced applications {{to run on}} these systems, such as the parallel database management system Kappa, the legal reasoning system HELIC-II, and the automated theorem prover MGTP, as well as applications to bioinformatics.|$|R
40|$|The {{aggregation}} {{problem is}} to design an inferential agent that makes intelligent use of the theories offered {{by a team of}} inductive <b>inference</b> <b>machines</b> working in a common environment. The present paper formulates several versions of the aggregation problem and investigates them from a recursion theoretic point of view...|$|R
40|$|Enhanced Vision Systems (EVS) are {{currently}} developed {{with the goal}} to alleviate restrictions in airspace and airport capacity in low-visibility conditions. EVS relies on weather penetrating forward-looking sensors that augment the naturally existing visual cues in the environment and provide a real-time image of prominent topographical objects that may be identified by the pilot. In this paper an automatic analysis of millimetre wave radar images for Enhanced Vision Systems is presented. The core {{part of the system}} is a fuzzy rule based <b>inference</b> <b>machine</b> which controls the data analysis based on the uncertainty in the actual knowledge in combination with a-priori knowledge. Compared with standard TV or IR images the quality of MMW images is rather poor and data is highly corrupted with noise and clutter. Therefore, one main task of the <b>inference</b> <b>machine</b> is to handle uncertainties as well as ambiguities and inconsistencies to draw the right conclusions. The output of different sensor data analysis processes are fused and evaluated within a fuzzy/possibilistic clustering algorithm whose results serve as input to the <b>inference</b> <b>machine.</b> The only a-priori knowledge used in the presented approach is the same pilots already know from airport charts which are available of almost every airport. The performance of the approach is demonstrated with real data acquired during extensive flight tests to several airports in Northern Germany...|$|R
50|$|Knowledge {{retrieval}} (KR) {{seeks to}} return {{information in a}} structured form, consistent with human cognitive processes as opposed to simple lists of data items. It draws {{on a range of}} fields including epistemology (theory of knowledge), cognitive psychology, cognitive neuroscience, logic and <b>inference,</b> <b>machine</b> learning and knowledge discovery, linguistics, and information technology.|$|R
40|$|Abstract. Presents a {{fuzzy logic}} {{inference}} algorithm {{based on the}} feature of concentration difference {{to solve the problem}} of odor source spatial positioning to mobile robot. The algorithm simulates the dynamic stimulation’s behavior of merit, let the robot to make decisions on the direction of travel by sensing the rate of change of concentration in different positions, and finally achieve the function of autonomous positioning to odor source. Let the robot's actual environment as the premise, design a fuzzy <b>inference</b> <b>machine,</b> and determine the fuzzy <b>inference</b> <b>machine’s</b> input variables, output variables, language value of input and output and corresponding fuzzy inference rules. Simulation results show that the proposed fuzzy logic algorithm has a strong applicability on bionic odor source spatial positioning to mobile robot; it can make the robot search to the odor source faster and more accurate...|$|R
40|$|Contents 1 Introduction 5 1. 1 Scope of course..................................... 5 1. 2 Computers as <b>inference</b> <b>machines...........................</b> 6 1. 3 References........................................ 6 1. 4 Acknowledgement.................................... 6 2 Simulation 7 2. 1 Introduction....................................... 7 2. 2 Issues in simulation................................... 7 2. 3 Buffon's Needle..................................... 7 2. 4 Raw ingredients..................................... 10 2. 5 Simulating from {{specified}} distributions........................ 10 2. 5. 1 Inversion....................... ...|$|R
40|$|In {{this article}} we {{formally}} specify and implement a diagnostic agent based on extended logic programming. Motivated by the application of decentralised diagnosis of distributed systems we develop an architecture for such agents that consists of a deliberative layer with a knowledge base, an <b>inference</b> <b>machine</b> and a reactive layer for communication and control. Throughout the layers we employ logic and logic programming to solve these tasks: the knowledge base uses extended logic programming to specify the agent's behaviour and its knowledge about the system to be diagnosed. The <b>inference</b> <b>machine,</b> which provides algorithms to compute diagnoses, {{as well as the}} reactive layer, that realises a meta interpreter for the agent behaviour, are implemented in PVMProlog, wich enhances standard Prolog with message passing facilities. Keywords: Model-based Diagnosis, Multi Agent Systems, Distributed Logic Programming 1 Introduction Real-world diagnosis problems are usually complex, large, and dis [...] ...|$|R
40|$|A model-based optical {{processor}} is introduced for the acquisition and tracking of a satellite {{in close proximity}} to an imaging sensor of a space robot. The type of satellite is known in advance, and a model of the satellite (which exists from its design) is used in this task. The model base is used to generate multiple smart filters of the various parts of the satellite, which are used in a symbolic multi-filter optical correlator. The output from the correlator is then treated as a symbolic description of the object, which is operated upon by an optical inference processor to determine the position and orientation of the satellite and to track it as a function of time. The knowledge and model base also serves to generate the rules used by the <b>inference</b> <b>machine.</b> The <b>inference</b> <b>machine</b> allows for feedback to optical correlators or feature extractors to locate the individual parts of the satellite and their orientations...|$|R
40|$|Autonomic Computing allows {{systems like}} {{wireless}} sensor networks (WSN) to self-manage computing resources in order to extend their autonomy as much as possible. In addition, contextualization tasks can fuse two or more different sensor data into a more meaningful information. Since these tasks usually run in a single centralized context server (e. g., sink node), the massive volume of data generated by the wireless sensors {{can lead to a}} huge information overload in such server. Here we propose DAIM, a distributed autonomic <b>inference</b> <b>machine</b> distributed which allows the sensor nodes to do self-management and contextualization tasks based on fuzzy logic. We have evaluated DAIM in a real sensor network taking into account other <b>inference</b> <b>machines.</b> Experimental results illustrate that DAIM is an energy-efficient contextualization method for WSN, reducing 48. 8 % of the number of messages sent to the context servers while saving 19. 5 % of the total amount of energy spent in the network...|$|R
40|$|Degrees of inferability {{have been}} {{introduced}} to measure the learning power of inductive <b>inference</b> <b>machines</b> which have access to an oracle. The classical concept of degrees of unsolvability measures the computing power of oracles. In this paper we determine the relationship between both notions. 1 Introduction We consider learning of classes of recursive functions {{within the framework of}} inductive inference [21]. A recent theme is the study of inductive <b>inference</b> <b>machines</b> with oracles ([8, 10, 11, 17, 24] and tangentially [12]; cf. [10] for a comprehensive introduction and a collection of all previous results.) The basic question is how the information content of the oracle (technically: its Turing degree) relates with its learning power (technically: its inference degree [...] -depending on the underlying inference criterion). In this paper a definitive answer is obtained for the case of recursively enumerable oracles and the case when only finitely many queries to the oracle are allo [...] ...|$|R
40|$|Bayesian {{reasoning}} {{has been}} applied formally to statistical <b>inference,</b> <b>machine</b> learning and analyzing scientific method. Here I apply it informally to more common forms of inference, namely natural language arguments. I analyze a variety of traditional fallacies, deductive, inductive and causal, and find more merit in them than is generally acknowledged. Bayesian principles {{provide a framework for}} understanding ordinary arguments which is well worth developing...|$|R
50|$|Variational Bayesian methods, {{a family}} of {{techniques}} for approximating intractable integrals arising in Bayesian <b>inference</b> and <b>machine</b> learning.|$|R
40|$|Introduction Computational vision can {{perceived}} of as {{the process}} of using an <b>inference</b> <b>machine</b> to infer information on {{a higher level of}} abstraction from the information given in terms of images. Images are typically represented as a list of numbers. The higher level of abstraction is defined in terms of an output space. Examples of output spaces are the set of all possible depth maps, a list of physical objects which are to be recognised, a list of possible actions for a robot, or any other set of possible results of a visual process. Common for all these different types of output is that they have an interpretation in 3 D space. We can interpret the output of the <b>inference</b> <b>machine</b> in the same domain as the input. Thereby, the inference loop is closed, which is necessary to construct a <b>machine</b> performing <b>inference.</b> In computer vision, we measure in 3 D space and infer knowledge of structures in 3 D space. We need a machine which can infer from the input space into the output sp...|$|R
40|$|AbstractThis paper {{intends to}} give a {{theoretical}} foundation of machine discovery from facts. We {{point out that the}} essence of a computational logic of scientific discovery or a logic of machine discovery is the refutability of the entire spaces of hypotheses. We discuss this issue in the framework of inductive inference of length-bounded elementary formal systems (EFSs), which are a kind of logic programs over strings of characters and correspond to context-sensitive grammars in Chomsky hierarchy. First we present some characterization theorems on inductive <b>inference</b> <b>machines</b> that can refute hypothesis spaces. Then we show differences between our inductive inference and some other related inferences such as in the criteria of reliable identification, finite identification and identification in the limit. Finally we show that for any n, the class, i. e. hypothesis space, of length-bounded EFSs with at most n axioms is inferable in our sense, that is, the class is refutable by a consistently working inductive <b>inference</b> <b>machine.</b> This means that sufficiently large hypothesis spaces are identifiable and refutable...|$|R
40|$|AbstractA {{class of}} computable {{functions}} ismaximaliff {{it can be}} incrementally learned by some inductive <b>inference</b> <b>machine</b> (IIM), but no infinitely larger class of computable functions can be so learned. Rolf Wiehagen posed the question whether there exist such maximal classes. This question and many interesting variants are answered herein in the negative. Viewed positively, each IIM can be infinitely improved upon! Also discussed are the problems of algorithmically finding the improvements proved to exist...|$|R
40|$|This article {{presents}} {{a mechanism to}} infer mood states, aiming to provide virtual learning environments (VLEs) with a tool able to recognize the student’s motivation. The inference model has as its parameters personality traits, motivational factors obtained through behavioral standards and the affective subjectivity identified in texts made available in the communication functionalities of the VLE. In the <b>inference</b> <b>machine,</b> such variables are treated under probability reasoning, more precisely by Bayesian networks...|$|R
40|$|Abstract. In {{this article}} we {{describe}} a layered architecture for a diagnosis agent based on REVISE, a non-monotonic reasoning system that revises contradictory extended logic programs. We discuss the agent's <b>inference</b> <b>machine</b> consisting of REVISE and a strategy component. We sketch the REVISE algorithm and evaluate it {{in the domain of}} digital circuits. We show how to specify the agent's behaviour with an extended logic program and define a meta-interpreter for the agent's top-layer for communication and control. ...|$|R
40|$|During {{the last}} years we {{collected}} data of abdominal septic shock patients from clinics all over Germany. The mortality of septic shock is about 50 %. Septic shock is related to immune system reactions and unusual measurements. Septic shock patients are intensely medicated during their stay at the intensive care unit. To help physicians recognizing the critical states of their patients as early as possible, we built a rule based alarm system based on a neuro-fuzzy <b>inference</b> <b>machine.</b> Analysing the patient data [...] ...|$|R
