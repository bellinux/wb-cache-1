2746|4448|Public
25|$|Numerical {{analysis}} {{takes advantage}} {{of many of the}} properties of orthogonal matrices for numerical linear algebra, and they arise naturally. For example, it is often desirable to compute an orthonormal basis for a space, or an orthogonal change of bases; both take the form of orthogonal matrices. Having determinant ±1 and all eigenvalues of magnitude 1 is of great benefit for numeric stability. One implication is that the <b>condition</b> <b>number</b> is 1 (which is the minimum), so errors are not magnified when multiplying with an orthogonal matrix. Many algorithms use orthogonal matrices like Householder reflections and Givens rotations for this reason. It is also helpful that, not only is an orthogonal matrix invertible, but its inverse is available essentially free, by exchanging indices.|$|E
2500|$|... where [...] These {{iterations}} are stable {{provided the}} <b>condition</b> <b>number</b> of [...] {{is less than}} three.|$|E
2500|$|... on (nearly) convex-quadratic {{functions}} {{with low}} or moderate <b>condition</b> <b>number</b> of the Hessian matrix, where BFGS or NEWUOA are typically ten times faster; ...|$|E
40|$|Abstract We present componentwise <b>condition</b> <b>numbers</b> for the {{problems}} of Moore-Penrose generalized matrix inversion and linear least squares. Also, the <b>condition</b> <b>numbers</b> for these <b>condition</b> <b>numbers</b> are given. Key words <b>Condition</b> <b>numbers,</b> componentwise analysis, generalized matrix inverses, linear least squares. AMS(2000) subject classifications 15 A 12, 65 F 20, 65 F 35...|$|R
40|$|In this paper, we {{consider}} the mixed and componentwise <b>condition</b> <b>numbers</b> for a linear function of {{the solution to the}} linear least squares problem with equality constrains (LSE). We derive the explicit expressions of the mixed and componentwise <b>condition</b> <b>numbers</b> through the dual techniques. The sharp upper bounds for the derived mixed and componentwise <b>condition</b> <b>numbers</b> are obtained, which can be estimated efficiently by means of the classical Hager-Higham algorithm for estimating matrix one-norm during using the generalized QR factorization method for solving LSE. The numerical examples show that the derived <b>condition</b> <b>numbers</b> can give sharp perturbation bounds, on the other hand normwise <b>condition</b> <b>numbers</b> can severely overestimate the relative errors because normwise <b>condition</b> <b>numbers</b> ignore the data sparsity and scaling...|$|R
40|$|In this paper, we {{consider}} the mixed and componentwise <b>condition</b> <b>numbers</b> for a linear function of {{the solution to the}} total least squares (TLS) problem. We derive the explicit expressions of the mixed and componentwise <b>condition</b> <b>numbers</b> through the dual techniques. The sharp upper bounds for the derived mixed and componentwise <b>condition</b> <b>numbers</b> are obtained. For the structured TLS problem, {{we consider}} the structured perturbation analysis and obtain the corresponding expressions of the mixed and componentwise <b>condition</b> <b>numbers.</b> We prove that the structured ones are smaller than their corresponding unstructured ones based on the derived expressions. Moreover, we point out that the new derived expressions can recover the previous results on the condition analysis for the TLS problem. The numerical examples show that the derived <b>condition</b> <b>numbers</b> can give sharp perturbation bounds, on the other hand normwise <b>condition</b> <b>numbers</b> can severely overestimate the relative errors because normwise <b>condition</b> <b>numbers</b> ignore the data sparsity and scaling. Meanwhile, from the observations of numerical examples, it is more suitable to adopt structured <b>condition</b> <b>numbers</b> to measure the conditioning for the structured TLS problem. Comment: arXiv admin note: text overlap with arXiv: 1612. 03645, arXiv: 1612. 0665...|$|R
2500|$|... and is zero elsewhere. This {{demonstrates}} {{the effect of}} the Tikhonov parameter on the <b>condition</b> <b>number</b> of the regularized problem. For the generalized case a similar representation can be derived using a generalized singular value decomposition.|$|E
2500|$|Backward error analysis, {{the theory}} of which was {{developed}} and popularized by James H. Wilkinson, {{can be used to}} establish that an algorithm implementing a numerical function is numerically stable. The basic approach is to show that although the calculated result, due to roundoff errors, will not be exactly correct, it is the exact solution to a nearby problem with slightly perturbed input data. If the perturbation required is small, on the order of the uncertainty in the input data, then the results are in some sense as accurate as the data [...] "deserves". The algorithm is then defined as backward stable. Stability {{is a measure of the}} sensitivity to rounding errors of a given numerical procedure; [...] by contrast, the <b>condition</b> <b>number</b> of a function for a given problem indicates the inherent sensitivity of the function to small perturbations in its input and is independent of the implementation used to solve the problem.|$|E
60|$|Meantime the skipper, half walking, half running, went {{on his way}} to Overcourt, {{arriving}} at Stagg’s Gardens in a breathless <b>condition.</b> <b>Number</b> five was fast asleep when he reached it and began a violent thumping upon the door.|$|E
40|$|For {{standard}} eigenvalue problems, a closed-form {{expression for}} the <b>condition</b> <b>numbers</b> of a multiple eigenvalue is known. In particular, they are uniformly 1 in the Hermitian case, and generally take different {{values in the}} non-Hermitian case. We consider the generalized eigenvalue problem and identify the <b>condition</b> <b>numbers</b> of a multiple eigenvalue. Our main result is that a multiple eigenvalue generally has multiple <b>condition</b> <b>numbers,</b> even in the Hermitian definite case. The <b>condition</b> <b>numbers</b> are characterized {{in terms of the}} singular values of the outer product of the corresponding left and right eigenvectors...|$|R
40|$|AbstractEstimates on {{spectral}} <b>condition</b> <b>numbers</b> for scattered-data interpolation matrices {{associated with}} a certain class of conditionally positive definite radial functions of order 0, including the Gaussians, are provided. In addition, ℓp-condition number estimates, with 1 ≤ p ≤ ∞ are discussed. The estimates on the spectral <b>condition</b> <b>numbers</b> lead to necessary and sufficient conditions for such <b>condition</b> <b>numbers</b> to be independent {{of the number of}} data sites...|$|R
40|$|AbstractWe derive exact and computable {{formulas}} for the <b>condition</b> <b>numbers</b> {{characterizing the}} forward instability in Lanczos bidiagonalization with complete reorthogonalization. One series of <b>condition</b> <b>numbers</b> {{is responsible for}} stability of Krylov spaces, the second for stability of orthonormal bases in the Krylov spaces and the third for stability of the bidiagonal form. The behaviors of these <b>condition</b> <b>numbers</b> are illustrated numerically on several examples...|$|R
6000|$|... "Condition number one, then," [...] he observed, [...] "is now agreed upon. We {{proceed to}} <b>condition</b> <b>number</b> two. Mrs. Delaporte, Captain Bannister, and Mr. Cheape," [...] {{he went on}} earnestly, [...] "I have been guilty of an indiscretion the proof of which is in your hands. Having decided to make London my home for a time, I desire {{once and for all}} to {{extinguish}} all possibility of this affair ever cropping up again in any shape or form." ...|$|E
50|$|Condition numbers {{can also}} be defined for {{nonlinear}} functions, and can be computed using calculus. The <b>condition</b> <b>number</b> varies with the point; in some cases one can use the maximum (or supremum) <b>condition</b> <b>number</b> over {{the domain of the}} function or domain of the question as an overall <b>condition</b> <b>number,</b> while in other cases the <b>condition</b> <b>number</b> at a particular point is of more interest.|$|E
50|$|The <b>condition</b> <b>number</b> {{with respect}} to L2 arises so often in {{numerical}} linear algebra that it is given a name, the <b>condition</b> <b>number</b> of a matrix.|$|E
40|$|<b>Condition</b> <b>numbers</b> play an {{important}} role in numerical analysis. Classical <b>condition</b> <b>numbers</b> are normwise: they measure both input perturbations and output errors with norms. To take into account the relative scaling of data components or a possible sparseness, componentwise <b>condition</b> <b>numbers</b> have been increasingly considered. In this paper, we give explicit expressions for the mixed and componentwise <b>condition</b> <b>numbers</b> for the weighted Moore-Penrose inverse of a matrix A, as well as for the solution and residue of a weighted linear least squares problem ‖W 1 2 (Ax−b) ‖ 2 = minv∈R n ‖W 1 2 (Av−b) ‖ 2, where the matrix A with full column rank. ...|$|R
40|$|AbstractThis paper {{considers}} the <b>condition</b> <b>numbers</b> of a nondefective multiple eigenvalue of a nonsymmetric matrix pencil. Based on the directional derivatives of a nondefective multiple eigenvalue of a nonsymmetric matrix pencil analytically dependent on several parameters, different <b>condition</b> <b>numbers</b> of a nondefective multiple eigenvalue are introduced. The computable expressions and bounds of introduced <b>condition</b> <b>numbers</b> are derived. Moreover, some {{results on the}} perturbation of a nondefective multiple eigenvalue of a nonsymmetric matrix pencil are given...|$|R
40|$|For any bounded linear {{operator}} A in a Banach space, two generalized <b>condition</b> <b>numbers</b> N. A / and O. A/ are defined in this paper. These <b>condition</b> <b>numbers</b> may {{be applied to}} the perturbation analysis for the solution of ill-posed differential equations and bounded {{linear operator}} equations in infinite dimensional Banach spaces. Different expressions for the two generalized <b>condition</b> <b>numbers</b> are discussed in this paper and applied to the perturbation analysis of the operator equation...|$|R
50|$|The <b>condition</b> <b>number</b> {{computed}} {{with this}} norm is generally {{larger than the}} <b>condition</b> <b>number</b> computed with square-summable sequences, {{but it can be}} evaluated more easily (and this is often the only practicably computable <b>condition</b> <b>number,</b> when the problem to solve involves a non-linear algebra, for example when approximating irrational and transcendental functions or numbers with numerical methods).|$|E
5000|$|In the {{expression}} for the relative error bound, the fraction (&Sigma;|xi|/|&Sigma;xi|) is the <b>condition</b> <b>number</b> of the summation problem. Essentially, the <b>condition</b> <b>number</b> represents the intrinsic {{sensitivity of the}} summation problem to errors, regardless of how it is computed. [...] The relative error bound of every (backwards stable) summation method by a fixed algorithm in fixed precision (i.e. not those that use arbitrary-precision arithmetic, nor algorithms whose memory and time requirements change based on the data), is proportional to this <b>condition</b> <b>number.</b> [...] An ill-conditioned summation problem {{is one in which}} this ratio is large, and in this case even pairwise summation can have a large relative error. For example, if the summands xi are uncorrelated random numbers with zero mean, the sum is a random walk and the <b>condition</b> <b>number</b> will grow proportional to [...] On the other hand, for random inputs with nonzero mean the <b>condition</b> <b>number</b> asymptotes to a finite constant as [...] If the inputs are all non-negative, then the <b>condition</b> <b>number</b> is 1.|$|E
5000|$|<b>Condition</b> <b>number</b> test: The {{standard}} measure of ill-conditioning in a matrix is the condition index. It will {{indicate that the}} inversion of the matrix is numerically unstable with finite-precision numbers (standard computer floats and doubles). This indicates the potential sensitivity of the computed inverse to small changes in the original matrix. The <b>Condition</b> <b>Number</b> is computed by finding the square root of (the maximum eigenvalue divided by the minimum eigenvalue). If the <b>Condition</b> <b>Number</b> is above 30, the regression may have significant multicollinearity; multicollinearity exists if, in addition, {{two or more of}} the variables related to the high <b>condition</b> <b>number</b> have high proportions of variance explained. One advantage of this method is that it also shows which variables are causing the problem.|$|E
40|$|Abstract. In this paper, {{we present}} a theory for {{bounding}} the minimum eigenvalues, maximum eigenvalues, and <b>condition</b> <b>numbers</b> of stiffness matrices arising from the p-version of finite element analysis. Bounds are derived for the eigenvalues and the <b>condition</b> <b>numbers,</b> which are valid for stiffness matrices based {{on a set of}} general basis functions {{that can be used in}} the p-version. For a set of hierarchical basis functions satisfying the usual local support condition that has been popularly used in the p-version, explicit bounds are derived for the minimum eigenvalues, maximum eigenvalues, and <b>condition</b> <b>numbers</b> of stiffness matrices. We prove that the <b>condition</b> <b>numbers</b> of the stiffness matrices grow like p 4 (d− 1),wheredisthenumberofdimensions. Ourresults disprove a conjecture of Olsen and Douglas in which the authors assert that “regardless of the choice of basis, the <b>condition</b> <b>numbers</b> grow like p 4 d or faster”. Numerical results are also presented which verify that our theoretical bounds are correct. 1...|$|R
40|$|We {{investigate}} the structured normwise and componentwise <b>condition</b> <b>numbers</b> for solving linear systems with Sylvester structure. Numerical examples {{show that the}} Sylvester structured <b>condition</b> <b>numbers</b> can be {{much smaller than the}} unstructured <b>condition</b> <b>numbers.</b> Here and hereafter, we denote ‖ · ‖ the spectral norm ‖ · ‖ 2 and ‖ · ‖ ∞ the infinity norm of its arguments. If A is a matrix, we write |A | = (|Aij|), where Aij is the (i, j) th entry of A. Le...|$|R
40|$|AbstractSimple {{formulae}} {{are derived}} for certain relative <b>condition</b> <b>numbers.</b> Tridiagonal matrices may be represented as products of bidiagonals {{in various ways}} depending on properties such as symmetry and positive definiteness. The <b>condition</b> <b>numbers</b> give the amplification factor for relative changes in a nonzero eigenvalue caused by relative changes in an entry of a bidiagonal factor. The formulae show that in many, but not all cases these <b>condition</b> <b>numbers</b> are of modest size. Several examples illustrate the results and raise new questions...|$|R
5000|$|The <b>condition</b> <b>number</b> of ƒ {{at a point}} x (specifically, its {{relative}} <b>condition</b> <b>number)</b> is then defined to be the maximum ratio of the fractional change in ƒ(x) to any fractional change in x, in the limit where the change δx in x becomes infinitesimally small: ...|$|E
50|$|If the <b>condition</b> <b>number</b> is not {{too much}} larger than one (but it can still be a {{multiple}} of one), the matrix is well conditioned which means its inverse can be computed with good accuracy. If the <b>condition</b> <b>number</b> is very large, then the matrix {{is said to be}} ill-conditioned. Practically, such a matrix is almost singular, and the computation of its inverse, or solution of a linear system of equations is prone to large numerical errors. A matrix that is not invertible has <b>condition</b> <b>number</b> equal to infinity.|$|E
50|$|There are two {{benefits}} of this method. First, {{the elimination of the}} interior unknowns on the subdomains, that is the solution of the Dirichlet problems, can be done in parallel. Second, passing to the Schur complement reduces <b>condition</b> <b>number</b> and thus tends to decrease the number of iterations. For second-order problems, such as the Laplace equation or linear elasticity, the matrix of the system has <b>condition</b> <b>number</b> of the order 1/h2, where h is the characteristic element size. The Schur complement, however, has <b>condition</b> <b>number</b> only of the order 1/h.|$|E
40|$|In this paper, we {{investigate}} the normwise, mixed, and componentwise <b>condition</b> <b>numbers</b> and their upper bounds for the Moore–Penrose inverse of the Kronecker product and more general matrix function compositions involving Kronecker products. We also present the <b>condition</b> <b>numbers</b> and their upper bounds {{for the associated}} Kronecker product linear least squares solution with full column rank. In practice, the derived upper bounds for the mixed and componentwise <b>condition</b> <b>numbers</b> for Kronecker product linear least squares solution can be efficiently estimated using the Hager–Higham Algorithm. Copyright © 201...|$|R
40|$|In this {{research}} we investigate <b>condition</b> <b>numbers</b> obtained from least squares estimation for a car-trailer system to characterize estimation performance. In this case, we can select better parameter estimation methods or well-posed measured data sets for the car-trailer system using <b>condition</b> <b>numbers.</b> We calculate <b>condition</b> <b>numbers</b> from several different linear model-based least squares methods which use four linear regression models and three least squares methods to estimate trailer parameters. We also consider three different observed data sets in ideal and non-ideal sensor scenarios for simulation tests...|$|R
30|$|Using wavelet {{discretization}} with {{a standard}} wavelet diagonal preconditioning for singularly perturbed two-point boundary value problems, one can observe that <b>condition</b> <b>numbers</b> of arising stiffness matrices are growing with decreasing parameter ϵ when a nonsymmetric part starts to dominate. We propose here a simple diagonal preconditioning which significantly improves <b>condition</b> <b>numbers</b> of the stiffness matrices with a dominating nonsymmetric part and compare it {{with a standard}} wavelet preconditioning. Further, we prove that the <b>condition</b> <b>numbers</b> of diagonally preconditioned stiffness matrices are bounded independent of the matrix size. Numerical examples are given.|$|R
5000|$|The <b>condition</b> <b>number</b> of a {{differentiable}} function f {{at a point}} x is [...] see Condition number: One variable for details. Note that if a function has a zero at a point, its <b>condition</b> <b>number</b> at the point is infinite, as infinitesimal changes in the input can change the output from zero to non-zero, yielding a ratio with zero in the denominator, hence an infinite relative change. The <b>condition</b> <b>number</b> of the mostly used functions are as follows; these {{can be used to}} compute significant figures for all elementary functions: ...|$|E
50|$|For example, the <b>condition</b> <b>number</b> {{associated}} with the linear equationAx = b gives a bound on how inaccurate the solution x will be after approximation. Note that this is before the effects of round-off error are taken into account; conditioning is a property of the matrix, not the algorithm or floating point accuracy of the computer used to solve the corresponding system. In particular, one should think of the <b>condition</b> <b>number</b> as being (very roughly) {{the rate at which}} the solution, x, will change with respect to a change in b. Thus, if the <b>condition</b> <b>number</b> is large, even a small error in b may cause a large error in x. On the other hand, if the <b>condition</b> <b>number</b> is small then the error in x will not be much bigger than the error in b.|$|E
50|$|A {{problem with}} a low <b>condition</b> <b>number</b> {{is said to be}} well-conditioned, while a {{problem with a}} high <b>condition</b> <b>number</b> is said to be ill-conditioned. The <b>condition</b> <b>number</b> is a {{property}} of the problem. Paired with the problem are any number of algorithms {{that can be used to}} solve the problem, that is, to calculate the solution. Some algorithms have a property called backward stability. In general, a backward stable algorithm can be expected to accurately solve well-conditioned problems. Numerical analysis textbooks give formulas for the condition numbers of problems and identify known backward stable algorithms.|$|E
40|$|In this paper, we {{consider}} the perturbation analysis for the periodic generalized coupled Sylvester (PGCS) equation. The normwise backward error for this equation is first obtained. Then, we present its normwise and componentwise perturbation bounds, from which the normwise and effective <b>condition</b> <b>numbers</b> are derived. Moreover, the mixed and componentwise <b>condition</b> <b>numbers</b> for the PGCS equation are also given. To estimate these <b>condition</b> <b>numbers</b> with high reliability, the probabilistic spectral norm estimator and the statistical condition estimation method are applied. The obtained results are illustrated by numerical examples. Comment: 15 pages, 1 figur...|$|R
40|$|Provisional {{estimates}} of incidence of acute <b>conditions,</b> <b>number</b> of persons reporting {{one or more}} chronic <b>conditions,</b> <b>number</b> of persons injured, hospital discharges, disability days, and number of persons with corrective lenses. Based on data collected in household interviews during the period July 1965 - June 1966. [Mary Lou Bauer]. 529868...|$|R
40|$|Provisional {{estimates}} of incidence of acute <b>conditions,</b> <b>number</b> of persons reporting {{one or more}} chronic <b>conditions,</b> <b>number</b> of persons injured, hospital discharges, disability days, costs of prescribed medicine, and distribution of nonprescribed medicines by place obtained. Based on data collected in household interviews during the period July 1964 -June 1965. [Charles S. Wilder]...|$|R
