43|20|Public
50|$|The <b>cycle</b> <b>stealing</b> mode is used {{in systems}} in which the CPU should not be {{disabled}} {{for the length of}} time needed for burst transfer modes. In the <b>cycle</b> <b>stealing</b> mode, the DMA controller obtains access to the system bus the same way as in burst mode, using BR (Bus Request) and BG (Bus Grant) signals, which are the two signals controlling the interface between the CPU and the DMA controller. However, in <b>cycle</b> <b>stealing</b> mode, after one byte of data transfer, the control of the system bus is deasserted to the CPU via BG. It is then continually requested again via BR, transferring one byte of data per request, until the entire block of data has been transferred. By continually obtaining and releasing the control of the system bus, the DMA controller essentially interleaves instruction and data transfers. The CPU processes an instruction, then the DMA controller transfers one data value, and so on. On the one hand, the data block is not transferred as quickly in <b>cycle</b> <b>stealing</b> mode as in burst mode, {{but on the other hand}} the CPU is not idled for as long as in burst mode. <b>Cycle</b> <b>stealing</b> mode is useful for controllers that monitor data in real time.|$|E
50|$|Unexpected <b>cycle</b> <b>stealing</b> by the {{rendezvous}} radar during descent nearly caused the Apollo 11 landing to be aborted, but {{the design of}} the Apollo Guidance Computer allowed the landing to continue by dropping low-priority tasks.|$|E
50|$|<b>Cycle</b> <b>stealing</b> is {{difficult}} to achieve in modern systems due to many factors such as pipelining, where pre-fetch and concurrent elements are constantly accessing memory, leaving few predictable idle times to sneak in memory access. DMA is the only formal and predictable method for external devices to access RAM.|$|E
5000|$|Valid Data Address (VDA) and Valid Program Address (VPA) outputs for dual cache and <b>cycle</b> <b>steal</b> DMA implementation.|$|R
25|$|The {{cause was}} a rapid, {{steady stream of}} {{spurious}} <b>cycle</b> <b>steals</b> from the rendezvous radar (tracking the orbiting Command Module), intentionally left on standby during the descent in case it was needed for an abort.|$|R
50|$|PGNCS {{generated}} unanticipated warnings during Apollo 11's lunar descent, {{with the}} AGC showing a 1201 alarm ("Executive overflow - no vacant areas") and a 1202 alarm ("Executive overflow - no core sets").The cause was a rapid, {{steady stream of}} spurious <b>cycle</b> <b>steals</b> from the rendezvous radar, intentionally left on standby during the descent in case it was needed for an abort.|$|R
5000|$|... "Transfer I/O" [...] (XIO, X'D0') {{performs}} a data transfer operation on a device. XIO starts a transfer and specifies {{the number of}} bytes to be read or written. Data transfer can optionally be performed by <b>cycle</b> <b>stealing</b> (IBM documentation calls this time-sharing), that is taking processor cycles from the user program as necessary to perform the operation.|$|E
5000|$|<b>Cycle</b> <b>stealing</b> {{has been}} the cause of major {{performance}} degradation on machine such as the Sinclair QL, where, for economy reasons, the video RAM was not dual access. Consequently, the M68008 CPU was denied access to the memory bus when the ZX8301 [...] "master controller" [...] was accessing memory, and the machine performed poorly when compared with machines using similar processors at similar speeds.|$|E
50|$|DMA {{transfers}} {{can either}} occur one byte {{at a time}} or all at once in burst mode. If they occur a byte at a time, this can allow the CPU to access memory on alternate bus cycles - this is called <b>cycle</b> <b>stealing</b> since the CPU and either the DMA controller or the bus master contend for memory access. In burst mode DMA, the CPU can be put on hold while the DMA transfer occurs and a full block of possibly {{hundreds or thousands of}} bytes can be moved. When memory cycles are much faster than processor cycles, an interleaved DMA cycle is possible, where the DMA controller uses memory while the CPU cannot.|$|E
50|$|For a Type III Communications Scanner <b>cycle</b> <b>steal</b> {{processing}} {{of a single}} character was fairly inexpensive - a single storage cycle was required. This would give a theoretical limit of a million cps (eighty 9.6 kbit/s half-duplex lines). In practice the limit was probably lower as some processing would be required for end of frame. Also if the frame contents were moved about in storage this would require 3.5 storage cycles per byte.|$|R
40|$|This paper {{presents}} a multithreaded system used to schedule parallel applications on heterogeneous multiuser parallel architectures. The approach {{is based on}} idle <b>cycles</b> <b>stealing,</b> and on adaptive parallelism to dynamically adjust the parallelism degree {{with respect to the}} system load. The basic mecanisms used are thread migration and machine global load estimation. 1 The ESPACE project The ESPACE project (Execution Support for Parallel Applications in high-performance Computing Environments) aims to provide a full environment for highly parallel application programming. One goal of the ESPACE project is to design an efficient low level parallel environment with a computation model based on lightweight processes (threads). Using threads for supporting high computing parallel applications is a recent approach [1] which allows efficient management of a great number of activities inside applications. PM 2 (Parallel Multithreaded Machine) [2] is a preemptive multithreaded run-time syste [...] ...|$|R
50|$|Type 2 and Type 3 Channel Adapters were {{designed}} for NCP use only. Only one device address was recognized. Data transfer was via <b>cycle</b> <b>steal</b> which made the overhead low if large buffers were used. The hardware accepted seven channel commands of which four were completely processed by the adapter. This left a read and two write commands for the software to process. These adapters could be connected {{to any of the}} three System/370 channel types but a block multiplexor channel was preferred. The Type 3 Adapter could be simultaneously operational (but not in mid-command) on two different channels which might be connected to different hosts. An Amdahl 4705 could have Type 2 channel adapters as well as Type 4 channel adapters (up to a total of four channel adapters). Amdahl's 4705 Type 2 channel adapter also simulated a Type 3 channel adapter.|$|R
50|$|In computing, {{traditionally}} <b>cycle</b> <b>stealing</b> is {{a method}} of accessing computer memory (RAM) or bus without interfering with the CPU. It is similar to Direct memory access (DMA) for allowing I/O controllers to read or write RAM without CPU intervention. Clever exploitation of specific CPU or bus timings can permit the CPU to run at full speed without any delay if external devices access memory not actively participating in the CPU's current activity and complete the operations before any possible CPU conflict. Such systems are nearly dual-port RAM without the expense of high speed RAM. Most systems halt the CPU during the steal, essentially making it a form of DMA by another name.|$|E
50|$|The QL was {{designed}} to be more powerful than the IBM Personal Computer, and comparable to Apple's Macintosh. The QL was the first mass-market personal computer based on the Motorola 68000-series processor family. Rushed into production, the QL beat the Apple Macintosh by a month, the Atari ST by a year and the Commodore Amiga by a year and 2 months. While clock speeds were comparable, the 8-bit databus and <b>cycle</b> <b>stealing</b> of the ZX8301 gate array limited the QL's performance. However, at the time of launch, on January 12, 1984, the QL was far from being ready for production, there being no complete working prototype in existence. Although Sinclair started taking orders immediately, promising delivery within 28 days, first customer deliveries only started, slowly, in April. This provoked much criticism of the company and the attention of the Advertising Standards Authority.|$|E
40|$|This work {{describes}} a programming model and performance model for <b>cycle</b> <b>stealing</b> on the Internet. <b>Cycle</b> <b>stealing</b> {{is the use}} of otherwise idle computers to perform work, and promises high performance computing at relatively low cost. The Internet, being the largest pool of potentially idle computers, is an obvious target for <b>cycle</b> <b>stealing.</b> However, computers connected to the Internet are often protected by firewalls, preventing point-to-point communication between them. The fluctuating avail-ability of computers for <b>cycle</b> <b>stealing</b> as they move in and out of an idle state, combined with the restricted communication of the Internet environment, means that programming models and abstractions suitable for programming supercom-puters and clusters are not ideal. Therefore, I have created a programming model for <b>cycle</b> <b>stealing</b> which reflects the types of parallel applications that are suitable for execution using idle computers connected to the Internet. The model is de-signed for use by non-expert parallel programmers, and I will show how it simpli-fies the development of <b>cycle</b> <b>stealing</b> applications, enabling rapid application de-velopment, and straightforward porting of existing sequential applications. This simple to use programming model, combined with the low cost of <b>cycle</b> <b>stealing,</b> improves the accessibility of high performance computing to non-traditional us-ers of supercomputers and clusters. Deployment on the Internet, and the need to navigate through firewalls, suggests a web based framework using common web protocols, web servers and web browsers. Part of this work investigates the feasibility of web based approaches to <b>cycle</b> <b>stealing,</b> from the setup of a <b>cycle</b> <b>stealing</b> system, application development and deployment, and connection of potentially idle computers. I designed and implemented a <b>cycle</b> <b>stealing</b> framework, deployable on the web, to meet expec-tations of performance, reliability, ease of use and safety. Existing <b>cycle</b> <b>stealing</b> frameworks emphasise the need for applications to be de-composed into a set of jobs that execute for a long period, that is, a job should have a computation time sufficient to justify its communication cost. However, there are no tools available for users to determine what an appropriate computa-tion time might be, given a job's data communication requirements. To date, de-ciding the granularity of jobs has been a matter of intuition. Therefore, a user may experience uncertainty as to the benefit of <b>cycle</b> <b>stealing</b> for their particular application, especially if the applications will have relatively short-lived jobs. Based on performance analysis of my framework, I have developed an analytical model and simulator, which can be used to predict, and help to optimise, the per-formance of user applications, and show the feasibility of executing a particular application using the <b>cycle</b> <b>stealing</b> framework...|$|E
2500|$|The {{problem was}} not a {{programming}} error in the AGC, nor was it pilot error. It was a peripheral hardware design bug that was already known and documented by Apollo 5 engineers. However, because the problem had only occurred once during testing, they concluded that it was safer to fly with the existing hardware that they had already tested, than to fly with a newer but largely untested radar system. In the actual hardware, {{the position of the}} rendezvous radar was encoded with synchros excited by a different source of 800Hz AC than the one used by the computer as a timing reference. The two 800Hz sources were frequency locked but not phase locked, and the small random phase variations made it appear as though the antenna was rapidly [...] "dithering" [...] in position, even though it was completely stationary. These phantom movements generated the rapid series of <b>cycle</b> <b>steals.</b>|$|R
2500|$|During {{this part}} of the approach, the {{processor}} would normally be almost 85% loaded. The extra 6,400 <b>cycle</b> <b>steals</b> per second added the equivalent of 13% load, leaving just enough time for all scheduled tasks to run to completion. Five minutes into the descent, Buzz Aldrin gave the computer the command 1668 which instructed it to calculate and display DELTAH (the difference between altitude sensed by the radar and the computed altitude). This added an additional 10% to the processor workload, causing executive overflow and a 1202 alarm. After being given the [...] "GO" [...] from Houston, Aldrin entered 1668 again and another 1202 alarm occurred. When reporting the second alarm, Aldrin added the comment [...] "It appears to come up when we have a 1668 up". The AGC software had been designed with priority scheduling, and automatically recovered, deleting lower priority tasks including the 1668 display task, to complete its critical guidance and control tasks. Guidance controller Steve Bales and his support team that included Jack Garman issued several [...] "GO" [...] calls and the landing was successful. For his role, Bales received the US Presidential Medal of Freedom on behalf of the entire control center team and the three Apollo astronauts.|$|R
40|$|Process {{variation}} reduces a pipeline’s maximum attainable frequency {{by creating}} unbalance in the stage delays. As a result, the pipeline ends up cycling with a period {{close to that}} of the slowest pipeline stage. ReCycle was proposed in ISCA 2007 as a framework for comprehensively applying <b>cycle</b> time <b>stealing</b> to balance the stage delays under process variation, thereby allowing the pipeline to cycle with a period close to the average latency of the stages. This paper duplicates the evaluation of ReCycle with more realistic pipeline and critical path models than in the original paper. Most notably, we do not assign one cycle to the feedback path of each pipeline loop. As a result, our pipeline contains five singlecycle loops. This is significant because these loops are not amenable to <b>cycle</b> time <b>stealing.</b> In this updated environment, ReCycle is able to regain on average only 40 % of the performance lost to process variation. In contrast, in the original paper, ReCycle regained 64 %. Moreover, we find that further adding Donor stages does not significantly increase performance. Consequently, we propose to extend the Donor algorithm by applying Forward Body Biasing (FBB) to single-cycle loops when they become critical. With ReCycle, Donor stages, and FBB, we regain on average 90 % of the performance lost to variation — still short of the roughly 110 % regained by ReCycle and Donor stages alone in the original ReCycle paper. 1...|$|R
40|$|We {{analyze the}} mean {{response}} {{time for the}} donor and beneficiary processors. Our analysis is approximate, but can be made as accurate as desired, and is validated via simulation. Results of the analysis illuminate several interesting principles {{with respect to the}} general benefits of <b>cycle</b> <b>stealing</b> and the design of <b>cycle</b> <b>stealing</b> policies...|$|E
40|$|Studies {{have shown}} that for a {{significant}} fraction of the time desktop PCs and workstations are underutilized. To exploit these idle resources, various Desktop/Workstation Grid systems have been developed. The ultimate goal of such systems is to maximize efficiency of resource usage while maintaining low obtrusiveness to machine owners. To this end, we created a new finegrain <b>cycle</b> <b>stealing</b> approach and conducted a performance comparison study against the traditional coarsegrain <b>cycle</b> <b>stealing.</b> We developed a prototype of finegrain <b>cycle</b> <b>stealing,</b> the Linger-Longer system, on a Linux cluster. The experiments on a cluster of desktop Linux PCs with benchmark applications show that, overall, fine-grain <b>cycle</b> <b>stealing</b> can improve efficiency of idle cycle usage by increasing the guest job throughput by 50 % to 70 %, while limiting obtrusiveness {{with no more than}} 3 % of host job slowdown. Index Terms – Desktop grid, meta-computing, cluster computing, process migration, networks of workstations...|$|E
40|$|We {{consider}} {{the problem of}} task assignment in a distributed server system, where short jobs are separated from long jobs, but short jobs may be run in the long job partition if it is idle (<b>cycle</b> <b>stealing).</b> Jobs {{are assumed to be}} nonpreemptible, where short and long jobs have generallydistributed service requirements, and arrivals are Poisson. We consider two variants of this problem: a central queue model and an immediate dispatch model. This paper presents the first analysis of <b>cycle</b> <b>stealing</b> under the central-queue model. (<b>Cycle</b> <b>stealing</b> under the immediate dispatch model is analyzed in [9]). The analysis uses a technique which we refer to as busy period transitions. Results show that <b>cycle</b> <b>stealing</b> can reduce mean response time for short jobs by orders of magnitude, while long jobs are only slightly penalized. Furthermore using a central queue yields significant performance improvement over immediate dispatch, both {{from the perspective of the}} benefit to short jobs and the penalty to long jobs...|$|E
40|$|Since {{the onset}} of pipelined processors, {{balancing}} the delay of the microarchitectural pipeline stages such that each microarchitectural pipeline stage has an equal delay has been a primary design objective, as it maximizes instruction throughput. Unfortunately, this causes significant energy inefficiency in processors, as each microarchitectural pipeline stage gets {{the same amount of}} time to complete, irrespective of its size or complexity. For poweroptimized processors, the inefficiency manifests itself as a significant imbalance in power consumption of different microarchitectural pipestages. In this paper, rather than balancing processor pipelines for delay, we propose the concept of power balanced pipelines – i. e., processor pipelines in which different delays are assigned to different microarchitectural pipestages to reduce the power disparity between the stages while guaranteeing the same processor frequency/performance. A specific implementation of the concept uses <b>cycle</b> time <b>stealing</b> [19] to deliberately redistribute cycle time from low-power pipeline stages to power-hungry stages, relaxing their timing constraints and allowing them to operate at reduced voltages or use smaller, less leaky cells. We present several static and dynamic techniques for power balancing and demonstrate that balancing pipeline power rather than delay can result in 46 % processor power reduction with no loss in processor throughput for a full FabScalar processor over a power-optimized baseline. Benefits are comparable over a Fabscalar baseline where static <b>cycle</b> time <b>stealing</b> is used to optimize achieved frequency. Power savings increase at lower operating frequencies. To the best of our knowledge, this is the first such work on microarchitecturelevel power reduction that guarantees the same performance. ...|$|R
50|$|Conceptually {{peripheral}} equipment {{is attached to}} a S/360 through control units, which in turn are attached through channels. However, the architecture does not require that control units be physically distinct, and in practice they are sometimes integrated with the devices that they control. Similarly, the architecture does not require the channels to be physically distinct from the processor, and the smaller S/360 models (through 360/50) have integrated channels that <b>steal</b> <b>cycles</b> from the processor.|$|R
40|$|Process {{variation}} affects processor pipelines {{by making}} some stages slower and others faster, therefore exacerbating pipeline unbalance. This reduces the frequency attainable by the pipeline. To improve performance, this paper proposes ReCycle, an architectural framework that comprehensively applies <b>cycle</b> time <b>stealing</b> to the pipeline — transferring the time slack of the faster stages to the slow ones by skewing clock arrival times to latching elements after fabrication. As a result, the pipeline can be clocked with a period {{close to the}} average stage delay rather than the longest one. In addition, ReCycle’s frequency gains are enhanced with Donor stages, which are empty stages added to “donate ” slack to the slow stages. Finally, ReCycle can also convert slack into power reductions. For a 17 FO 4 pipeline, ReCycle increases the frequency by 12 % and the application performance by 9 % on average. Combining Re-Cycle and donor stages delivers improvements of 36 % in frequency and 15 % in performance on average, completely reclaiming the performance losses due to variation...|$|R
40|$|Ordinary desktop {{computers}} continue to obtain ever more resources – in-creased processing power, memory, network speed and bandwidth – yet these resources {{spend much of}} their time underutilised. <b>Cycle</b> <b>stealing</b> frameworks harness these resources so they can be used for high-performance computing. Traditionally <b>cycle</b> <b>stealing</b> systems have used client-server based architectures which place significant limits on their ability to scale and the range of applica-tions they can support. By applying a fully decentralised network model to <b>cycle</b> <b>stealing</b> the limits of centralised models can be overcome. Using decentralised networks in this manner presents some difficulties which have not been encountered in their previous uses. Generally decentralised ap-plications do not require any significant fault tolerance guarantees. High-performance computing on the other hand requires very stringent guarantees to ensure correct results are obtained. Unfortunately mechanisms developed for traditional high-performance computing cannot be simply translated because of their reliance on a reliable storage mechanism. In the highly dynamic world of P 2 P computing this reliable storage is not available. As part of this research a fault tolerance system has been created which provides considerable reliability without the need for a persistent storage. As well as increased scalability, fully decentralised networks offer the ability for volunteers to communicate directly. This ability provides the possibility of supporting applications whose tasks require direct, message passing style communication. Previous <b>cycle</b> <b>stealing</b> systems have only supported embarrassingly parallel applications and applications with limited forms of communication so a new programming model has been developed which can support this style of communication within a <b>cycle</b> <b>stealing</b> context. In this thesis I present a fully decentralised <b>cycle</b> <b>stealing</b> framework. The framework addresses the problems of providing a reliable fault tolerance sys-tem and supporting direct communication between parallel tasks. The thesis includes a programming model for developing <b>cycle</b> <b>stealing</b> applications with direct inter-process communication and methods for optimising object locality on decentralised networks...|$|E
40|$|Abstract We {{consider}} {{the problem of}} task assignment in a dis-tributed server system, where short jobs are separated from long jobs, but short jobs may be run in the long job parti-tion if it is idle (<b>cycle</b> <b>stealing).</b> Jobs {{are assumed to be}} nonpreemptible, where short and long jobs have generally-distributed service requirements, and arrivals are Poisson. We consider two variants of this problem: a centralqueue model and an immediate dispatch model. This paper presents the first analysis of <b>cycle</b> <b>stealing</b> under thecentral-queue model. (<b>Cycle</b> <b>stealing</b> under the immediate dispatch model is analyzed in [9]). The analysis usesa technique which we refer to as busy period transitions. Results show that <b>cycle</b> <b>stealing</b> can reduce mean responsetime for short jobs by orders of magnitude, while long jobs are only slightly penalized. Furthermore using a centralqueue yields significant performance improvement over immediate dispatch, both {{from the perspective of the}} benefit toshort jobs and the penalty to long jobs. 1 Introduction Distributed server model In recent years, distributed servers have become increas-ingly common because they allow for increased computin...|$|E
40|$|Abstract—This paper {{presents}} the design, implementation, and performance {{evaluation of a}} suite of resource policing mechanisms that allow guest processes to efficiently and unobtrusively exploit otherwise idle workstation resources. Unlike traditional policies that harvest cycles only from unused machines, we employ fine-grained <b>cycle</b> <b>stealing</b> to exploit resources even from machines that have active users. We developed a suite of kernel extensions that enable these policies to operate without significantly impacting host processes: 1) a new starvation-level CPU priority for guest jobs, 2) a new page replacement policy that imposes hard bounds on physical memory usage by guest processes, and 3) a new I/O scheduling mechanism called rate windows that throttle guest processes ’ usage of I/O and network bandwidth. We evaluate both the individual impacts of each mechanism, and their utility for our fine-grain <b>cycle</b> <b>stealing.</b> Index Terms—Grid computing, cluster computing, networks of workstations, parallel computing, resource scheduling, <b>cycle</b> <b>stealing.</b> æ...|$|E
40|$|The University of Huddersfield has a {{large number}} of {{computers}} laboratories on campus that are used to capacity during timetabled session but out of these sessions the machine can be unused for long periods of time. Whilst these machines have power management software installed to reduce the universities electricity bill. The idle machines could be used to perform complex calculations and simulations to benefit the research community through <b>cycles</b> <b>stealing</b> techniques and High Throughput Computing (HTC) middlewares. In order to provide a suitable HTC service an investigation was undertaken into what middlewares are available and how they compared against each other. This study also looked at what is green IT and how the chosen HTC middleware has been adapted to conform. The investigation also involved looking into publication from other universities to see how it is used. A survey was conducted into how useful a Condor HTC grid could fit in with other universities High Performance Computing (HPC) clusters and how beneficial Condor is. The survey also looked at how Condor is funded and how it is administered. Overall the results show that Condor is an extremely useful and low cost HTC solution. Condor has been deployed within Canalside East within the University of Huddersfield as a test bed with plans to expand the Condor pool across campus. To help Condor fit within the green IT policy the compute nodes were configured to allow the machines to go into a low power state when required. To be able to prevent the possibility of having a large job queue with very few nodes online a number of scripts were created that would collect the information required to remotely wake machines up using Wake on LAN (WoL). The scripts will wake machine when a number of jobs are idle and there are machine available that are offline. In order to make Condor able to run programs that have been developed for Windows and Linux a dual Condor client system has be implemented. This has been achieved by using the standard Windows client and a virtualized Linux client with Condor on called Pools of Virtual Boxes (PoVB). These clients run as a Windows service that can be remotely switched on and off when required remotely within the same script that can wake machines when required...|$|R
5000|$|The {{cycle-stealing}} {{concept of}} the 1130permits the CPU program to start an operation on an I/O device and then continue the mainline program while the I/O device is performing its operation. Each I/O device that operates in this manner takes (<b>steals)</b> a <b>cycle</b> from the CPU when it is needed.The CPU is [...] "tied up" [...] only one cycle while a data character is being transferred. The frequency at which devices <b>steal</b> <b>cycles</b> depends {{on the type of}} device.Since the CPU is much faster than any I/O device on the system, the CPU may be performing another function, such as arithmetic, at the same time an I/O operation is being performed. In fact, several I/O operations may be overlapped {{with each other and with}} other CPU functions.|$|R
40|$|Abstract—The {{functional}} consolidation {{induced by}} the cost-reduction trends in embedded systems can force tasks of different criticality (e. g. ABS Brakes with DVD) to share a processor and interfere with each other. These systems are known as mixed-criticality systems. While traditional temporal isolation tech-niques prevent all inter-task interference, they waste utilization because they need to reserve for the absolute worst-case execution time (WCET) for all tasks. In many mixed-criticality systems the WCET is not only rare, but at times difficult to calculate, such as the time to localize all possible objects in an obstacle avoidance algorithm. In this situation it is more appropriate to allow the execution time to grow by <b>stealing</b> <b>cycles</b> from lower-criticality tasks. Even more crucial {{is the fact that}} temporal isolation techniques can stop a high-criticality task (that was overrunning its nomimal WCET) to allow a low-criticality task to run, makin...|$|R
40|$|The idea of {{stealing}} cycles has been hyped for some years, boasting unlimited potential by tapping the computational power {{of millions of}} under utilized PCs connected to the Internet. Despite a few spectacular success stories (e. g. SETI@HOME), cycle-stealing is today not a widely used technology. We believe two principal impediments need to be overcome. The first is ease of development and use. Most of the problems faced in developing <b>cycle</b> <b>stealing</b> applications are not specific to those applications, so generic <b>cycle</b> <b>stealing</b> frameworks such as our G 2 framework can {{play a vital role}} in this regard. The second is uncertainty. Potential developers don't know whether if they went to the effort of developing a parallel application for a <b>cycle</b> <b>stealing</b> environment, it would pay off, i. e. whether they would get a reasonable speedup. To minimize this risk, we propose the development and use of detailed performance models...|$|E
40|$|In a {{world where}} {{electronic}} databases are used to store ever-increasing quantities of data it is becoming harder to mine useful information from them. Therefore {{there is a need}} for a highly scalable parallel architecture capable of handling the ever-increasing complexity of data mining problems. A <b>cycle</b> <b>stealing</b> network is one possible scalable solution to this problem. A <b>cycle</b> <b>stealing</b> network allows users to donate their idle cycles to form a virtual supercomputer by connecting multiple machines via a network. This research aims to establish whether <b>cycle</b> <b>stealing</b> networks, specifically the G 2 system developed at the Queensland University of Technology, are viable for large scale data mining problems. The computationally intensive sequence mining, feature selection and functional dependency mining problems are deliberately chosen to test the usefulness and scalability of G 2. Tests have shown that G 2 is highly scalable where the ratio of computation to communication is approximately known. However for combinatorial problems where computation times are difficult or impossible to predict, and communication costs can be unpredictable, G 2 often provides little or no speedup. This research demonstrates that existing sequence mining and functional dependency mining techniques are not suited to a client-server style <b>cycle</b> <b>stealing</b> network like G 2. However the feature selection is well suited to G 2, and a new sequence mining algorithm offers comparable performance to other existing, non-cycle stealing, parallel sequence mining algorithms. Furthermore new functional dependency mining algorithms offer substantial benefit over existing serial algorithms...|$|E
40|$|Abstract The {{problem of}} task {{assignment}} in a distributed server system is considered, where short jobs areseparated from long jobs, but short jobs may be {{run in the}} long job partition if it is idle (<b>cycle</b> <b>stealing).</b> Jobs {{are assumed to be}} non-preemptible. New techniques are presented for analyzing thisproblem, both in the case of immediate dispatch of jobs to hosts {{and in the case of}} a central queue. The analysis is approximate, but can be made as close to exact as desired. Analysis is validated viasimulation. Results of the analysis show that <b>cycle</b> <b>stealing</b> can reduce mean response time for short jobs by orders of magnitude, while long jobs are only slightly penalized...|$|E
40|$|This paper {{describes}} a new scheduler, called BERT, that runs {{a mix of}} best eort and real-time tasks. BERT extends the fair sharing scheduling discipline to allow one task to dynamically <b>steal</b> <b>cycles</b> from another, thereby lessening the system's dependency on making accurate reservations. BERT also supports a notion of task priority by allowing important real-time tasks to steal to meet deadlines and important best eort tasks to be immune from stealing. This paper develops the BERT algorithm from its theoretical roots in the generalized processor sharing uid model, to a practical implementation as an extension to the WF 2 Q algorithm. It also discusses our experiences using BERT to schedule a mix of tasks on a multimedia workstation. Categories and Subject Descriptors: []: General Terms: Additional Key Words and Phrases: 1. INTRODUCTION One of the challenges of multimedia workstations is that they must support workloads with diver...|$|R
40|$|We {{describe}} a new algorithm, called BERT, {{that can be}} used to schedule both best e#ort and realtime tasks on a multimedia workstation. BERT exploits two innovations. First, it is based on the virtual clock algorithm originally developed to schedule bandwidth on packet switches. Because this algorithm maintains a relationship between virtual time and real time, our algorithm allows us to simultaneously factor realtime deadlines into the scheduling decision, and to allocate some fraction of the processor to best e#ort tasks. Second, BERT includes a mechanism that allows one task to <b>steal</b> <b>cycles</b> from another. This mechanism is valuable for two reasons: it allows us to distinguish among tasks based on their importance, and it results in a robust algorithm that is not overly sensitive to the task having made a perfect reservation. 1 Introduction One of challenges of multimedia workstations is that they must support workloads with diverse CPU requirements, ranging from compute-inte [...] ...|$|R
40|$|Two {{forms of}} variation, namely, Spatial or Process Variation, and Temporal Variation or Aging, are {{becoming}} severe limiters of performance scaling {{provided by the}} Moore's law in the sub- 45 nm regime. Process variation affects processor pipelines by making some stages slower and others faster, therefore exacerbating pipeline unbalance. This reduces the frequency attainable by the pipeline. To improve performance, we propose ReCycle, an architectural framework that comprehensively applies <b>cycle</b> time <b>stealing</b> to the pipeline - transferring the time slack of the faster stages to the slow ones by skewing clock arrival times to latching elements after fabrication. As a result, the pipeline can be clocked with a period close to the average stage delay rather than the longest one. In addition, ReCycle's frequency gains are enhanced with Donor stages, which are empty stages added to "donate" slack to the slow stages, and Forward Body Biasing (FBB). For a 17 FO 4 pipeline at 45 nm, ReCycle combined with Donor stages and FBB improves performance by 9 %, on average, reclaiming 90 % of the performance losses due to variation. In addition to spatial variation, processors progressively age during their useful lifetime due to normal workload activity. Such aging results in gradually slower circuits. Anticipating this fact, designers add timing guardbands to processors, so that they last {{for a number of}} years. As a result, aging has important design and cost implications. To address this problem, we show how to hide the effects of aging and slow it down. Our framework is called Facelift. It hides aging through aging-driven application scheduling. It slows down aging by applying voltage changes at key times - it uses a non-linear optimization algorithm to carefully balance the impact on the aging rate and on the critical path delays. Moreover, it can gainfully configure the chip for a short lifetime. We can take a multicore with a 7 -year lifetime and, by hiding and slowing down aging, enable it to cycle, on average, at a 14 - 15 % higher frequency. Alternatively, we can design a multicore for a 5 to 7 -month lifetime and use it for 7 years...|$|R
