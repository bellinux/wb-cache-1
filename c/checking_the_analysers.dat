0|10000|Public
40|$|It is {{the year}} 2025. FutureCorp, the private sector defence {{contractor}} to whom the US government has outsourced its management of nuclear weapons, has just had its missile control software hijacked by terrorists. It {{is only a matter}} of hours before Armageddon. The CEO of FutureCorp, Dr F. Methods, is incredulous: “This is impossible”, he told one of our reporters. “We used program analysis to formally prove that the software was secure!”. “Ah, Dr Methods,” responded open-source developer Mr B. Door, “But did you <b>check</b> <b>the</b> <b>analyser?...</b>|$|R
50|$|The Russian Deputy Prosecutor {{declared}} in 2002 that a comprehensive {{testing of the}} samples showed no traces of any explosives, and that sacks from Ryazan contained only sugar. However Yuri Tkachenko, the police explosives expert who defused the Ryazan bomb, insisted that it was real. Tkachenko said that the explosives, including a timer, a power source, and a detonator were genuine military equipment and obviously prepared by a professional. He also said that <b>the</b> gas <b>analyser</b> that tested <b>the</b> vapours coming from the sacks unmistakably indicated the presence of RDX. Tkachenko {{said that it was}} out of the question that <b>the</b> <b>analyser</b> could have malfunctioned, as <b>the</b> gas <b>analyser</b> was of world-class quality, cost $20,000, and was maintained by a specialist who worked according to a strict schedule, <b>checking</b> <b>the</b> <b>analyser</b> after each use and making frequent prophylactic checks. Tkachenko pointed out that meticulous care in the handling of <b>the</b> gas <b>analyser</b> was a necessity because the lives of the bomb squad experts depended on the reliability of their equipment. The police officers who answered the original call and discovered the bomb also insisted that it was obvious from its appearance that the substance in the bomb was not sugar.|$|R
40|$|This paper {{describes}} {{the components of}} a robust and wide-coverage morphological <b>analyser</b> for Basque. <b>The</b> <b>analyser</b> {{is based on the}} two-level formalism and has been designed in an incremental way with three main modules: <b>the</b> standard <b>analyser,</b> <b>the</b> <b>analyser</b> of linguistic variants, and <b>the</b> <b>analyser</b> without lexicon which can recognize word-forms without having their lemmas in the lexicon. Using lexical transducers for our analyser we have improved both the performance of the different components of the system and the description itself. <b>The</b> <b>analyser</b> is a basic tool for current and future work on automatic processing of Basque and its first two applications are a commercial spelling corrector and a general purpose lemmatizer/tagger...|$|R
40|$|We {{carried out}} a study to {{evaluate}} the quality of results obtained by 14 nontechnical medical office personnel using desktop <b>analysers.</b> <b>The</b> instruments evaluated were <b>the</b> Reflotron <b>analyser,</b> <b>the</b> Seralyzer, <b>the</b> Vision <b>analyser</b> and <b>the</b> DT 60 <b>analyser.</b> For precision studies low and high concentrations of control materials were used. For correlation studies the results obtained by the office personnel were compared with those obtained by a trained technologist. The coefficient of variation for the office personnel ranged from 3. 0 % to 8. 1 % with <b>the</b> Reflotron <b>analyser,</b> from 6. 3 % to 26. 5 % with the Seralyzer, from 1. 0 % to 4. 1 % with <b>the</b> Vision <b>analyser</b> and from 1. 4 % to 16. 7 % with <b>the</b> DT 60 <b>analyser.</b> <b>The</b> correlation coefficient ranged from 0. 970 to 0. 997 with <b>the</b> Reflotron <b>analyser,</b> from 0. 779 to 0. 997 with the Seralyzer, from 0. 975 to 0. 998 with <b>the</b> Vision <b>analyser</b> and from 0. 963 to 0. 995 with <b>the</b> DT 60 <b>analyser.</b> <b>The</b> proportion of results obtained by the office personnel that differed by more than 10 % from those obtained by the technologist was 7 % with <b>the</b> Reflotron <b>analyser,</b> 42 % with the Seralyzer, 2 % with <b>the</b> Vision <b>analyser</b> and 21 % with <b>the</b> DT 60 <b>analyser.</b> <b>The</b> instruments whose operation involves the least number of steps gave the most reliable results {{in the hands of}} medical office personnel...|$|R
25|$|After 2 or 3 months, Kay and Fran {{were moved}} to work on <b>the</b> {{differential}} <b>analyser</b> in <b>the</b> basement of the Moore School, {{the largest and most}} sophisticated analogue mechanical calculator of the time, of which there were only 3 in the United States and 5 or 6 in the world (all of the others were in Great Britain). <b>The</b> <b>analyser</b> had been lent to the University of Pennsylvania {{for the duration of the}} war. Using <b>the</b> <b>analyser</b> (invented by Vannevar Bush of MIT a decade prior and made more precise with improvements by the Moore School staff), a single trajectory computation—about 40 hours of work on a mechanical desk calculator—could be performed in about 50 minutes. Kay was further promoted to supervising calculations on <b>the</b> <b>analyser.</b> <b>The</b> <b>analyser</b> room staff worked six days a week, with their only official holidays as Christmas and the Fourth of July.|$|R
40|$|This work {{describes}} {{the design of}} a phosphate analyser that utilises a microfluidic lab-on-a-chip. <b>The</b> <b>analyser</b> contains all <b>the</b> required chemical storage, pumping and electronic components to carry out a complete phosphate assay. The system is self-calibrating and self-cleaning, thus capable of long-term operation. This was proven by a bench top calibration of <b>the</b> <b>analyser</b> using standard solutions and also by comparing <b>the</b> <b>analyser</b> 2 ̆ 7 s performance to a commercially available phosphate monitor installed at a waste water treatment plant. The output of <b>the</b> microfluidic lab-on-a-chip <b>analyser</b> was shown to have sensitivity and linear range equivalent to the commercially available monitor and also the ability to operate {{over an extended period of}} time...|$|R
40|$|A flow {{injection}} analyser {{has been}} constructed to allow an operatorfree determination {{of up to}} 40 samples. Besides the usual F!A apparatus, <b>the</b> <b>analyser</b> includes a home-made sample introduction device made with three electromechanical three-way valves and an auto-sampler from Technicon which has been adapted {{to be commanded by}} an external digital signal. <b>The</b> <b>analyser</b> is controlled by a single board SDK- 8085 microcomputer. The necessary interface to couple <b>the</b> <b>analyser</b> components to <b>the</b> microcomputer is also described. <b>The</b> <b>analyser</b> was evaluated for a Cr(VI) -FIA determination showing a very good performance with a relative standard deviation for 15 signalsfrom the injection of 100 bl of a 1. 0 mg. m 1 - 1 standard Cr(VI) solution being equal to 0 " 5 %. Since its introduction {{in the middle of the}} 1970 s, flow injection analysis has encouraged a do-it-yourself approach [1]. Most of the advances achieved by th...|$|R
50|$|With the {{development}} of <b>the</b> biochip, <b>analysers</b> were created to handle the biochip in a high throughput routine laboratory. <b>The</b> <b>analyser</b> range expanded from the evidence, to include the evidence evolution, evidence investigator and evidence multistat.|$|R
40|$|A Sucrose <b>Analyser,</b> {{developed}} by <b>the</b> Sugar Research Institute in Australia, was {{made available for}} evaluation in the South African sugar industry. <b>The</b> <b>analyser</b> was installed in line on evaporator syrup, at a raw sugar factory. After an original in situ calibration with sucrose solutions of known concentrations it performed satisfactorily and repeated calibrations showed no evidence of drift or bias. Tests were carried out for six weeks during which the sucrose values were logged by the factory data capturing system. <b>The</b> Sucrose <b>Analyser</b> was then set up for laboratory applications at the Sugar Milling Research Institute (SMRI). Both continuous and batch operations were evaluated using juices, syrups and molasses with the appropriate calibrations. Again <b>the</b> <b>analyser</b> performed well. <b>The</b> paper describes how <b>the</b> <b>analyser</b> was calibrated and comments on the results obtained...|$|R
40|$|White et al [...] Assesgment, of <b>the</b> Chemetrics <b>analyser</b> In conclusion, <b>the</b> kits {{have been}} used as a means to {{evaluate}} the performance of this analyser. In doing so, it is important to realise that the total variance of the system has as components the errors due to the kits as well as <b>the</b> Chemetrics <b>analyser.</b> <b>The</b> total system variance was well within the chosen criteria of acceptability. Therefore the performance of <b>the</b> <b>analyser</b> itself must have been acceptable...|$|R
40|$|The paper {{presents}} {{some models}} for optimizing {{the production rate}} of an automatic multitest blood analyser. A blood analysis may require one or more tests. The performance of <b>the</b> <b>analyser</b> depends on <b>the</b> test compositions of the analyses and the design of <b>the</b> <b>analyser</b> itself. <b>The</b> design can be changed. The optimal design can be determined by solving a set partitioning problem, given {{a representative sample of}} blood analyses...|$|R
5000|$|The Michel-Levy Chart {{arises when}} polarised white light is {{passed through a}} {{birefringent}} sample. If the sample is of uniform thickness, then only one specific wavelength will meet the above condition described above, and be perpendicular to the direction of <b>the</b> <b>analyser.</b> This means that instead of polychromatic light being viewed at <b>the</b> <b>analyser,</b> one specific wavelength will have been removed. This information {{can be used in}} a number of ways: ...|$|R
40|$|A {{commercial}} {{electron spin}} analyser, based on spin-polarised low-energy electron diffraction (SPLEED) from W(100), has been characterised with incident polarised electron beams from a standard GaAs polarised electron source. The {{dependence of the}} Sherman function on the scattering energy and elapse time after CO-flash of the tungsten crystal of <b>the</b> <b>analyser</b> have been measured. The influence of the stray magnetic field {{on the performance of}} <b>the</b> <b>analyser</b> has been investigated. <b>The</b> spin <b>analyser</b> has been applied in monitoring the reorientation transition of the easy magnetisation direction of Fe films on W(110) upon the exposure of CO adsorbent on the surface. © 2007, Elsevier Ltd...|$|R
40|$|Copper {{flotation}} profit can {{be estimated}} online utilising the assay of <b>the</b> on-stream <b>analysers.</b> High and low limits of the profit can be calculated, and the range between limits {{can be used for}} an evaluation of the return on investment, which has to be done during the implementation of a new control system or <b>analyser.</b> <b>The</b> range depends on the target values for concentrate and tailings, and on the accuracy of <b>the</b> controls and <b>analyser.</b> <b>The</b> separate pay-back values from any improvement in the controls or <b>the</b> <b>analyser</b> accuracy are estimated. The economic effect is analysed and demonstrated on data collected from two flotation plants. Peer reviewe...|$|R
40|$|An XRF {{analyser}} {{suitable for}} measuring up to 15 liters of slurry {{has been tested}} in the laboratory. A range of slurries consisting of approximately 40 wt % solids and low concentrations of tantalum were obtained and measured. The accuracy of <b>the</b> <b>analyser</b> has been determined to be ± 2 ppm (1 sigma). Improvements are planned that will significantly increase the speed and accuracy of <b>the</b> <b>analyser</b> and facilitate its adaptation to online / byline monitoring of mineral process streams...|$|R
50|$|<b>The</b> <b>analysers,</b> by <b>the</b> {{association}} of robotics and spectrophotometry, allowed these last decades a better reproducibility {{of the results}} of proportionings, in particular in medical biochemistry and hematology.|$|R
50|$|This {{is related}} to the {{sampling}} rate of <b>the</b> <b>analyser</b> and <b>the</b> FFT rate. It is also important for the realtime spectrum analyzer to give good level accuracy.|$|R
50|$|Light {{traveling}} in the backward direction becomes polarized at 45° by <b>the</b> <b>analyser.</b> <b>The</b> Faraday rotator will again rotate the polarization by 45°. This means the light is polarized horizontally (the rotation is sensitive to direction of propagation). Since the polarizer is vertically aligned, the light will be extinguished.|$|R
5000|$|This then {{leads to}} a phase {{difference}} between the light passing in the two vibration directions of [...]For example, if the optical path difference is , then the phase difference will be , and so the polarisation will be perpendicular to the original, resulting {{in all of the}} light passing through <b>the</b> <b>analyser</b> for crossed polars. If the optical path difference is , then the phase difference will be , and so the polarisation will be parallel to the original. This means that no light will be able to pass though <b>the</b> <b>analyser</b> which it is now perpendicular to.|$|R
40|$|The aim of {{the present}} article is to give an {{overview}} of the current state of syntactic analysis of Estonian and describe problems that were encountered in the generation of syntactic rules for <b>the</b> syntactic <b>analyser</b> of Estonian. So far only the rules based on linguistics have been used. This article is focused on the statistical methods in syntactic analysis and it describes the experiments of using corpus-based patterns in syntactical disambiguation. 1 Introduction The aim of <b>the</b> <b>analyser</b> is to give syntactic description to the text which is previously analysed and disambiguated morphologically. <b>The</b> <b>analyser</b> marks each word with a syntactic tag. The tags denote subjects, objects, main verbs, adverbials, etc. The framework that <b>the</b> syntactic <b>analyser</b> is based on is Constraint Grammar [1], [2] which is described in following section. Section 3 gives an overview of current state of Estonian Constraint Grammar, section 4 discusses the efforts to use statistical methods for syntactic a [...] ...|$|R
40|$|Analyst, were evaluatedfor their {{adequacy}} {{for use in}} laboratories {{attached to}} Saudi ’polyclinics’. All <b>the</b> <b>analysers</b> showed comparable within-batch imprecision. The Analyst {{was found to be}} the most useful because it was simple and practical and because its throughput time was faster than <b>the</b> other two <b>analysers.</b> <b>The</b> EPOS 5060 would be more suitablefor screening large numbers of samplesfor single parameters; and the ERIS 6170 essentially suits normal routine chemical laboratory work...|$|R
40|$|Nutrients such as Phosphate, Ammonia, Nitrite and Nitrate {{are central}} in many {{environmental}} processes within the marine environment, including several microbial, {{plant and animal}} metabolic processes. <b>The</b> Phosphate <b>Analyser</b> was developed {{as part of the}} COMMON SENSE FP 7 project (614155). <b>The</b> <b>analyser</b> is based on a combination of microfluidic analytical systems, colorimetric reagent chemistry, low-cost LED-based optical detection, low cost pumps and wireless communications...|$|R
40|$|The {{purpose of}} the {{investigation}} was to derive the optimal configuration of <b>the</b> spectrum <b>analyser</b> when used for the exposure assessment around base stations, together with the associated uncertainty and the underlying rationale for the chosen settings. A base-band simulation model for both <b>the</b> spectrum <b>analyser</b> and <b>the</b> Universal Mobile Telecommunications System (UMTS) communication signals has been developed to investigate the behaviour of <b>the</b> spectrum <b>analyser</b> when used for exposure assessment. Simulations and theoretical derivations enable to determine the theoretical bounds on the achievable accuracy for the measurement of a mobile communications signal and to examine {{the impact on the}} measurement result of one individual setting of <b>the</b> spectrum <b>analyser.</b> <b>The</b> simulation and theoretical models have been validated with measurements on a realistic UMTS test-signal...|$|R
50|$|Light {{traveling}} in the forward direction becomes polarized vertically by the input polarizer. The Faraday rotator will rotate the polarization by 45°. <b>The</b> <b>analyser</b> then enables <b>the</b> light to be transmitted through the isolator.|$|R
40|$|This paper {{addresses}} the experimental bootstrapping {{of the development}} of broad-coverage finite-state morphological analysers for Xhosa, Swati and (Southern) Ndebele by using an existing prototype of a morphological analyser for Zulu. These languages are both morphologically complex and resource-scarce. The research question is whether bootstrapping is feasible across the language boundaries between these closely related varieties. The objective is an assessment of the recognition rates yielded by <b>the</b> Zulu morphological <b>analyser</b> for <b>the</b> three related languages. The strategy is to use bootstrapping techniques that consist of the following steps: applying <b>the</b> <b>analyser</b> to corpus data from all languages, identifying (types of) failures, and implementing the respective changes in <b>the</b> <b>analyser.</b> <b>The</b> results show that the high degree of shared typological properties and formal similarities among the Nguni varieties warrants a modular bootstrapping approach. Word forms in these languages that were recognized by <b>the</b> Zulu <b>analyser</b> were mostly adequately analysed. Therefore, the focus lies on providing the necessary adaptations based on an analysis of the failure output for each language. As a result, <b>the</b> development of <b>analysers</b> for Xhosa, Swati and Ndebele is considerably faster than the creation of the Zulu prototype. The paper concludes with comments on the feasibility of the experiment, and the results of the evaluation. ...|$|R
5000|$|The {{analysis}} {{can be done}} on samples which the operator brings to <b>the</b> <b>analyser</b> or <b>the</b> <b>analyser</b> can {{be connected to the}} source of the samples and the sampling be done automatically. The source of samples for automatic sampling is commonly some kind of process such as a chemical process. Analysers which are connected to a process, and conduct automatic sampling, can be called online (or on-line) analysers or sometimes inline (or in-line) analysers. For inline analysis, a sensor can be placed in a process vessel or stream of flowing material to conduct the analysis. Another method of online analysis is allowing a sample stream to flow from the process equipment into an <b>analyser,</b> sometimes conditioning <b>the</b> sample stream in between such as reducing pressure or changing the sample temperature. Such sampling is typically for fluids (either liquids or gases). If the sample stream is not substantially modified by <b>the</b> <b>analyser,</b> it can be returned to the process. Otherwise, the sample stream is not returned; for example, if any reagents have been added for the analysis.|$|R
50|$|<b>The</b> <b>Analyser</b> test takes {{approximately}} 5-8 minutes, excluding patient set up. There {{are multiple}} steps which {{need to be}} done before commencement of the test to ensure reliable results are attained. The test type and eye are firstly selected and the patient's details are entered, including their refractive error. <b>The</b> <b>Analyser</b> will provide a lens strength and type (either spherical and/or cylindrical), if required for the test. In these instances, wire-rimmed trial lenses are generally used, with the cylindrical lens placed closest to the patient so the axis is easily read. The clinician can alter the fixation targets as per necessary (see Fixation Targets for advice).|$|R
5000|$|<b>The</b> <b>Analyser</b> {{projects}} {{a series of}} white light stimuli of varying intensities (brightness), throughout a uniformly illuminated bowl. The patient uses a handheld button that they press to indicate {{when they see a}} light. This assesses the retina's ability to detect a stimulus at specific points within the visual field. This is called retinal sensitivity and is recorded in 'decibels' (dB). [...] <b>The</b> <b>Analyser</b> currently utilises <b>the</b> Swedish Interactive Thresholding Algorithm (SITA); a formula which allows the fastest and most accurate visual field assessment to date. Results are then compared against an age-matched database which highlights unusual and suspicious vision loss, potentially caused by pathology.|$|R
5000|$|... where [...] is {{the average}} width of the two slits, and [...] is the {{incidence}} angle of the incoming photoelectrons.Though the resolution improves with increasing , technical problems related {{to the size of}} <b>the</b> <b>analyser</b> put a limit on the actual value of [...]Although a low pass energy [...] improves the resolution, the electron transmission probability is reduced at low pass energy, and the signal-to-noise ratio deteriorates, accordingly.The electrostatic lenses in front of <b>the</b> <b>analyser</b> have two main purposes: they collect and focus the incoming photoelectrons into the entrance slit of the analyzer, and they decelerate the electrons to the kinetic energy , in order to increase the resolution.|$|R
40|$|Three autoanalysers, the EPOS 5060, ERIS 6170 and the Analyst, were {{evaluated}} for their adequacy {{for use in}} laboratories attached to Saudi ‘polyclinics’. All <b>the</b> <b>analysers</b> showed comparable within-batch imprecision. The Analyst {{was found to be}} the most useful because it was simple and practical and because its throughput time was faster than <b>the</b> other two <b>analysers.</b> <b>The</b> EPOS 5060 would be more suitable for screening large numbers of samples for single parameters; and the ERIS 6170 essentially suits normal routine chemical laboratory work...|$|R
40|$|Providing {{guidelines}} for testing expected inaccuracy and imprecision {{is still a}} matter under debate. The Expert Panel of the French Society of Clinical Chemistry has developed a protocol, {{which was based on}} a comparative multi-centre evaluation of four instruments: the Ciba-Corning 278, the Instrumentation Laboratory 1306, the Nova SP 5 and the ABL 330. The purpose was to evaluate the analytical performance and efficiency of <b>the</b> <b>analysers.</b> Another aim was to design a valid approach for evaluating any new system. As buffered aqueous solutions and fluorocarbon emulsions give only partial information, tonometered blood was used at different levels of gas mixture, even though it is both difficult and time-consuming. Comparisons have been established on patients' blood samples with <b>the</b> <b>analysers</b> currently used in the evaluation sites. The tests showed that <b>the</b> four <b>analysers</b> have <b>the</b> same degree of precision, and interinstrument comparisons demonstrated a very high degree of reliability...|$|R
5000|$|The {{pressure}} {{of a sample}} stream can be lowered by a pressure reducing valve, particularly since many analysers are not designed to withstand high pressure. Such pressure reducing or similar valves {{may be used to}} control the flow rate to <b>the</b> online <b>analyser.</b> If <b>the</b> process pressure is insufficient to allow a sample stream to flow by itself to <b>the</b> <b>analyser,</b> a small pump may be used to move it there. The temperature of a hot sample may be lowered by use of an online sample cooler. The sampling and analysis can be done at the command of an operator, periodically (for example, every 15 minutes), or continuously - providing an analysis result vs. time graph on a chart recorder, computer, or other device. For periodic sampling, valves (or other devices) can be switched open to allow a fluid sample stream to flow to <b>the</b> <b>analyser</b> and shut when not sampling.|$|R
40|$|The {{development}} of {{natural language processing}} (NLP) components is resource-intensive and therefore justifies exploring ways of reducing development time and effort when building NLP components. This paper addresses the experimental fast-tracking of the {{development of}} finite-state morphological analysers for Xhosa, Swati and (Southern) Ndebele by using an existing prototype of a morphological <b>analyser</b> for Zulu. <b>The</b> research question is whether fast-tracking is feasible across the language boundaries between these closely related varieties. The objective is a thorough assessment of the recognition rates yielded by <b>the</b> Zulu morphological <b>analyser</b> for <b>the</b> three related languages. The strategy is to use fast-tracking techniques that consist of several cycles of the following steps: applying <b>the</b> <b>analyser</b> to corpus data from all languages, identifying (types of) failures, and implementing the respective changes in <b>the</b> <b>analyser.</b> <b>The</b> tests show that the high degree of shared typological properties and formal similarities among the Nguni varieties warrants a modular fast-tracking approach. Those word forms in these languages that were recognized by <b>the</b> Zulu <b>analyser</b> were mostly adequately interpreted. Therefore, the focus lies on providing the necessary adaptations based on an analysis of the failure output for each language. As a result, <b>the</b> development of <b>analysers</b> for Xhosa, Swati and Ndebele is considerably faster than the creation of the Zulu prototype. The paper concludes with comments on the feasibility of the experiment, and the results of the evaluation. 1...|$|R
50|$|Figure 2 shows a Faraday rotator with {{an input}} polarizer, and an output analyser. For a {{polarization}} dependent isolator, the angle between the polarizer and <b>the</b> <b>analyser,</b> , {{is set to}} 45°. The Faraday rotator is chosen to give a 45° rotation.|$|R
40|$|From the {{requirements}} of the Ionosonde digitisation project, undertaken by Rhodes University Antarctic Research Group, it was decided to use the Fast Fourier Transform to compute the spectrum analysis. Several FFT algorithms are reviewed and properties discussed, and the Ccoley Tukey algorithm chosen for utilization. The hardware implementation of this algorithm, and the microprogram control of the whole system are discussed in detail, and such design aspects that required computer simulation are also treated in detail. The final testing of <b>the</b> <b>analyser</b> is shown, and includes a test using data from an ionosonde sounding. The conclusions contain details of extensions to <b>the</b> <b>analysers</b> present operation, required by plans to place the whole Chirpsounder under microprocessor contro...|$|R
40|$|The paper {{presents}} {{a case study}} in the development of software modularisation tools. The tools are produced by using a system for developing code analysers that uses a database to store both a no-loss fine-grained intermediate representation and the analyses' results. <b>The</b> <b>analysers</b> are automatically generated from a high-level specification of the desired analyses expressed in a domain-oriented language. We use a program intermediate representation, called F(p), as the user-visible data base conceptual model. Analysers are specified in a declarative language, called F(p) – ell, which allows the specification of an analysis {{in the form of a}} traversal of an algebraic expression, with accesses to, and stores of, the database information the algebraic expression indexes. A foreign language interface allows <b>the</b> <b>analysers</b> to be embedded into C programs. This is useful, for example, to implement the user interface of an analyser or to facilitate interoperation of <b>the</b> generated <b>analysers</b> with pre-existing tools...|$|R
