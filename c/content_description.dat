388|517|Public
25|$|The PlayStation Portable {{version of}} the game was {{announced}} on February 1, 2005, alongside the PlayStation 2, Xbox and Windows versions. Originally scheduled for release with the other versions in Fall 2005, and then re-scheduled for March 2006, the game was ultimately released in September 2006. There was no indication the PSP version would be a different game until July 11, 2006, when Electronics Boutique and GameStop changed their listing from simply The Godfather to The Godfather: Mob Wars, {{although there was no}} change in the game's <b>content</b> <b>description</b> on either website. The following day, EA confirmed the PSP version would indeed be called Mob Wars and would not be the same game as the PlayStation 2, Xbox and Windows versions.|$|E
5000|$|MPEG-7 (2002): Multimedia <b>content</b> <b>description</b> interface. (ISO/IEC 15938) ...|$|E
50|$|MPEG-7 is a {{multimedia}} <b>content</b> <b>description</b> standard. It was standardized in ISO/IEC 15938 (Multimedia <b>content</b> <b>description</b> interface). This description will {{be associated with}} the content itself, to allow fast and efficient searching for material that is of interest to the user. MPEG-7 is formally called Multimedia <b>Content</b> <b>Description</b> Interface. Thus, it is not a standard which deals with the actual encoding of moving pictures and audio, like MPEG-1, MPEG-2 and MPEG-4. It uses XML to store metadata, and can be attached to timecode in order to tag particular events, or synchronise lyrics to a song, for example.|$|E
50|$|The <b>content</b> <b>descriptions</b> were revised in 2005 {{to enable}} easier {{application}} {{to a wide}} range of digital content, not just websites.|$|R
40|$|In this paper, {{we propose}} novel ranking methods of {{effectively}} finding <b>content</b> <b>descriptions</b> {{of classical music}} compositions. In addition to rather naive methods using technical term frequency and latent Dirichlet allocation(LDA), we proposed a novel classification of web pages about classical music and used {{the characteristics of the}} classification for our method of search by labeled LDA(L-LDA). The experimental results showed our method performed well at finding <b>content</b> <b>descriptions</b> of classical music compositions. Categories and Subject Descriptor...|$|R
40|$|We {{propose a}} generic {{solution}} for user adaptation of synchronized multimedia presentations. We consider adaptation as a transformation problem: the user specifies a predicate that {{applied to a}} generic multimedia presentation yields a customized view of the presentation. We specify a means of expressing <b>content</b> <b>descriptions</b> and alternate <b>content</b> in generic multimedia presentations. User adaptation is based on content predicates that a player uses to select alternate content or elements that match <b>content</b> <b>descriptions.</b> Several examples show flexibility and expressing power of the proposed approach...|$|R
5000|$|In 1994, several top gaming {{publishers}} {{formed the}} Entertainment Software Association (ESA) as the trade {{association of the}} video game industry. Shortly after its creation, the ESA established the Entertainment Software Rating Board (ESRB) to independently assign individual games content ratings and descriptors according {{to a variety of}} factors. Identification of sexuality falls under the sexual <b>content</b> <b>description</b> which is allowed for games rated Teen to Adults Only [...]|$|E
50|$|In 1996, Thinking Pictures {{partnered with}} Universal Music Group {{to develop a}} digital <b>content</b> <b>description</b> language. This was {{integrated}} into the Universal Media Player interface, also developed by Thinking Pictures and licensed to UMG, and distributed on over 1 billion music compact discs between 1998 and 2005. This was a major innovation in digital rights management, providing a way for artists to include electronic press kits (EPKs) or other information on CDs. Thinking Pictures continued to develop the UMP as a platform-independent device which could make DRM more widely available within the music industry.|$|E
5000|$|Content: The {{content section}} of each DID {{describes}} {{the requirements of}} subject(s), topic(s), or element(s) for the data item. This may be a string of defined data elements for entry into a Government database (e.g., DI-MGMT-81861 Integrated Program Management Report shows the terms and meanings for parts of the XML format file), or a listing of paragraph titles or topics for inclusion (e.g., DI-IPSC-80690 System/Subsystem Specification). For a specific contract, the content of a deliverable shall contain information that fulfills the requirements identified in the CDRL and {{the description of the}} DID. Documents should have section numbers and titles matching to the subsections of the DID <b>content</b> <b>description</b> for easier application and use.|$|E
40|$|In this paper, {{we present}} the self-describing schemes for {{interoperable}} image/video <b>content</b> <b>descriptions,</b> {{which are being}} developed {{as part of our}} proposal to the MPEG- 7 standard. MPEG- 7 aims to standardize <b>content</b> <b>descriptions</b> for multimedia data. The objective of this standard is to facilitate content-focused applications like multimedia searching, filtering, browsing, and summarization. To ensure maximum interoperability and flexibility, our descriptions are defined using the eXtensible Markup Language (XML), developed by the World Wide Web Consortium. We demonstrate the feasibility and efficiency of our self-describing schemes in our MPEG- 7 testbed. First, we show how our scheme can accommodate image and video descriptions that are generated by a wide variety of systems. Then, we present two systems being developed that are enabled and enhanced by the proposed approach for multimedia <b>content</b> <b>descriptions.</b> The first system is an intelligent search engine with an associated expressiv [...] ...|$|R
40|$|Computer Networks, 31 (11 – 16) : 1273 – 1290, May 17, 1999. International audienceWe {{propose a}} generic {{solution}} for user adaptation of synchronized multimedia presentations. We consider adaptation as a transformation problem: the user specifies a predicate that {{applied to a}} generic multimedia presentation yields a customized view of the presentation. We specify a means of expressing <b>content</b> <b>descriptions</b> and alternate <b>content</b> in generic multimedia presentations. User adaptation is based on content predicates that a player uses to select alternate content or elements that match <b>content</b> <b>descriptions.</b> Several examples show flexibility and expressing power of the proposed approach...|$|R
40|$|In this paper, {{we present}} {{results from the}} {{experimental}} evaluation for the TRECVID 2011 MED 11 (Multimedia Event Detection) task {{as a part of}} Team SRI-Sarnoff’s AURORA system being developed under the IARPA ALADDIN Program. Our approach employs two classes of <b>content</b> <b>descriptions</b> for describing videos depicting diverse events: (1) Low level features and their aggregates, and (2) Semantic concepts that capture scenes, objects and atomic actions that are local in space-time. In this presentation we summarize our system design and the <b>content</b> <b>descriptions</b> used. We also present four MED 11 experiments that we submitted, discuss the results and lessons learned. ...|$|R
50|$|The PlayStation Portable {{version of}} the game was {{announced}} on February 1, 2005, alongside the PlayStation 2, Xbox and Windows versions. Originally scheduled for release with the other versions in Fall 2005, and then re-scheduled for March 2006, the game was ultimately released in September 2006. There was no indication the PSP version would be a different game until July 11, 2006, when Electronics Boutique and GameStop changed their listing from simply The Godfather to The Godfather: Mob Wars, {{although there was no}} change in the game's <b>content</b> <b>description</b> on either website. The following day, EA confirmed the PSP version would indeed be called Mob Wars and would not be the same game as the PlayStation 2, Xbox and Windows versions.|$|E
5000|$|ICRA {{created a}} <b>content</b> <b>description</b> system which allowed webmasters and digital content creators to self-label their content in {{categories}} such as nudity, sex, language (profanity etc.), violence, other potentially undesired material and online interactivity such as social networking and chat. There are context variables such as art, medicine and news - for example, a piece of content or site {{can be described as}} having depictions of nudes, but they are in an artistic context. A key point is that ICRA does not rate internet content, nor do they make value judgements about sites [...] - [...] the content providers self-label, and then parents and other concerned adults make a value judgement as to what is or is not appropriate content.|$|E
5000|$|Giant Steps: GiantSteps is a STREP project {{coordinated by}} JCP-Consult SAS in France in {{collaboration}} with the MTG and partially funded by the European Commission (FP7-ICT-2013-10 Grant agreement nr 610591). The GiantSteps project aims to create the [...] "seven-league boots" [...] for music production in the next decade and beyond. The GiantSteps project unites leading music research institutions, industrial R&D companies, and music practitioners, to combine techniques and technologies in new ways, including state of the art interface design techniques with MIR methods new in the areas of real time interaction and creativity. The consortium's industry partners will guarantee the alignment of these cutting edge technologies with market requirements. In terms of S&T contributions, the MTG provides the project with expertise coming from different research areas within the research group, including music <b>content</b> <b>description,</b> music interaction using advanced interfaces and development of user experience evaluation frameworks.|$|E
50|$|The {{audio-visual}} descriptors are {{in charge}} of the <b>contents</b> <b>description.</b> These descriptors have a good knowledge of the objects and events found in a video, image or audio and they allow the quick and efficient searches of the audio-visual content.|$|R
40|$|Multimedia Database Systems (MMDS) support rich data types, such as text, images, video, and sound. Queries in MMDSs may {{refer to}} the content of the stored {{multimedia}} objects. This is called content-based querying. However, manual entry of <b>content</b> <b>descriptions</b> is very difficult and subjective. A better approac...|$|R
40|$|Australian {{curriculum}} classroom approaches: history includes 12 {{units of}} work {{developed from the}} Australian Curriculum for years 7 to 10. The units seek to develop students' historical understanding and literacy, integrating the <b>content</b> <b>descriptions</b> of the two curriculum strands of historical knowledge and understanding and historical skills...|$|R
5000|$|Horizons is {{billed as}} a season of five expansions, {{starting}} with planetary landings and then followed with a more comprehensive looting and crafting system released in May 2016, ship launched fighters and passenger missions released in October 2016, as well as support for multiple players working cooperatively on the same ship planned for a future expansion within {{the first half of}} 2017 ahead of Playstation 4 release and with a 5th expansion to follow after that. The 2nd, 3rd and 4th expansions were announced originally for Spring, Summer and Fall 2016 respectively. But the 5th expansion had no reference to [...] "Winter", it was not time scheduled and had no <b>content</b> <b>description,</b> only stating a cryptic [...] "soon" [...] reference. [...] The ability to walk around and the types of worlds players can land on is expected to be expanded during upcoming seasons, with landing on planets with atmospheres or earthlike worlds not being part of the Horizons season, but due at a later stage.|$|E
40|$|The {{explosive}} growth of applications involving digital audio-visual material {{is driving the}} need for more rich <b>content</b> <b>description.</b> In this paper, we present a design process for audio-visual <b>content</b> <b>description.</b> The process involves constructing a conceptual model in which entities, attributes and relationships important for <b>content</b> <b>description</b> are identi ed and modeled. The procedure provides special handling of di erent types of spatio-temporal relationships important for audio-visual content modeling. In this paper, we describe the audiovisual <b>content</b> <b>description</b> conceptual modeling methodology {{in the context of the}} evolution of MPEG- 7 description schemes...|$|E
40|$|World-wide large {{repositories}} {{of learning}} material are created with the dual goals of global access for the learner and of re-use of material by the teacher. <b>Content</b> <b>description</b> standards have been defined which {{make it possible}} to locate appropriate material. This paper looks into complementing these standards by extending the possibilities of describing the actual content of the learning material and by extending the use of these descriptions beyond the normal search-and-retrieve tasks. A framework for the multi-modal description of learning material is suggested. The framework aims at providing multiple <b>content</b> <b>description</b> mechanisms and suggests the design of an information system to perform this <b>content</b> <b>description.</b> The <b>content</b> <b>description</b> mechanisms are text-based, that is keywords, freeform text, FSCL description, and audio-based. The system design addresses issues like ownership, public and private access rights for description and the subsequent retrieval...|$|E
40|$|Abstract: We {{present a}} new {{architecture}} for information transformation that leads practical information refinery to a abstract level {{in order to}} support concepts-based information finding for the Grid. The overall goal of the architecture is to provide abstract <b>content</b> <b>descriptions</b> of network resource to achIRve precise information finding. ...|$|R
40|$|Australian Curriculum Classroom Approaches: Mathematics {{includes}} 16 {{units of}} work {{developed from the}} Australian Curriculum for years 7 to 10. The units provide students with essential mathematical skills and knowledge, and incorporate the <b>content</b> <b>descriptions</b> of all three curriculum strands of Number and Algebra, Measurement and Geometry, and Statistics and Probability...|$|R
40|$|We {{present a}} {{framework}} for media inter-pretation that leverages low-level information extraction {{to a higher level}} of abstraction in order to support semantics-based information retrieval for the Semantic Web. The overall goal of the framework is to provide high-level <b>content</b> <b>descriptions</b> of documents for maxi-mizing precision and recall of semantics-based information retrieval. 1...|$|R
40|$|<b>Content</b> <b>Description</b> is a {{major issue}} in {{multimedia}} and animation systems and is necessary for content creation, delivery, and even retrieval. This paper proposes a <b>content</b> <b>description</b> language, specifically designed for face animation systems. Face Modeling Language (FML) is an XML-based Structured <b>Content</b> <b>Description.</b> It allows definition of face actions from complicated stories to simple moves, and also face models and behaviours. FML is used as input script in ShowFace animation system. The paper describes FML hierarchical structure, dynamic behaviour and event handling, relation to face animation components, and also other multimedia languages and standards like SMIL and MPEG- 4...|$|E
40|$|Audio <b>content</b> <b>description</b> {{is one of}} the key {{components}} to multimedia search, classification and source identification. This project examines precision of audio <b>content</b> <b>description</b> based on spectral information only on one hand, and spectral and temporal on the other. Multilayer neural network with varied parameters is used to classify musical instruments based on obtained descriptors...|$|E
40|$|The {{semantic}} Web and {{the multimedia}} <b>content</b> <b>description</b> interface (MPEG- 7) {{are the two}} most widely known approaches toward machine-processable and semantic-based <b>content</b> <b>description.</b> The concepts and technologies behind the approaches are essential for the next step in multimedia development - that is, providing multimedia metadata on the Web. Unfortunately, as this article discusses, many practical obstacles block their widespread use...|$|E
50|$|The {{database}} {{provides information}} on about 85 000 German cinema and television films (as of June 2015) from 1895 to the present. About 8 000 films are presented in detail with <b>content</b> <b>descriptions,</b> stills and/or posters. In addition, filmportal.de catalogues about 190 000 names of filmmakers, 5 000 of these entries feature a biography.|$|R
40|$|We {{introduce}} a new paradigm in digital audio effects {{that is based on}} more symbolic manipulations of elements of a sound, rather than using linear signal processing alone. By utilising <b>content</b> <b>descriptions</b> such as those enabled by MPEG- 7, a system may apply context-sensitive effects that are more aware {{of the structure of the}} sound than current systems...|$|R
40|$|Index de les obres ressenyades: Cornelius O’BOYLE, Thirteenth-and Fourteenth-Century Copies of the «Ars Medicine». A Checklist and <b>Contents</b> <b>Descriptions</b> of the Manuscripts. Jon ARRIZABALAGA, The «Articella» in the Early Press c. 1476 - 1534. PAPERS of the Articella Project Meeting. Fernando SALMÓN, Medical Classroom Practice. Petrus Hispanus’ Questions on Isagoge, Tegni, Regimen Acutorum and Prognostica (c. 1245 - 50) ...|$|R
40|$|Information Retrieval Systems {{which are}} used to {{retrieve}} multimedia documents perform a set of assertions of queries based on previous knowledge and retrieve related documents following the perspective of similar content description of such documents. The term multimedia documents is referred to those text formated files containing images and video. In order to identify which documents are more similar to others {{it is necessary to}} focus on the content of the documents and provide a representation model which provides a set of features to distinguish the similarities and differences among a given collection of documents. There are two main content representation formats, holistic <b>content</b> <b>description</b> and symbolic <b>content</b> <b>description.</b> Holistic <b>content</b> <b>description</b> is based on similarity measures and it matches the content based, for example, using nearestneighbor algorithms [MRS 08]. On the other hand symbolic <b>content</b> <b>description</b> are based on multimedia elements (images, video, caption and text) which are represented by symbolic content descriptions. In this project work symbolic content descriptions will be used. The creation of symbolic conten...|$|E
30|$|Vretos et al. [76] {{presented}} {{a way of}} using the audio-visual description profile (AVDP) of the MPEG- 7 standard for 3 D video <b>content</b> <b>description.</b> The description of key-frames is contemplated in the AVDP profile through the MediaSourceDecompositionDS (i.e. MediaSourceDecompositionDS {{is used in the}} AVDP context to decompose an audiovisual segment into the constituent audio and video channels). Thus this <b>content</b> <b>description</b> scheme, allows that 3 D key-frames can be used for fast browsing and condensed representation of query results of 3 D video search tasks. Other application of key-frames to <b>content</b> <b>description</b> was proposed by Sano et al. [77]. Here, the authors proposed and discussed how the AVDP profile of the MPEG- 7 can be applied to multiview 3 D video content [56].|$|E
40|$|The {{development}} of a semantic web of text, images, structured information, and continuous media information including video and audio, depends {{on being able to}} annotate content with semantic meaning and then use that <b>content</b> <b>description</b> directly in applications. ANNODEX is a recently announced initiative to allow continuous media files to be integrated directly with their own <b>content</b> <b>description,</b> into one unified source. In this short paper we take a state of the art video indexing, browsing and retrieval system, FÍSCHLÁR-NEWS, whose architecture and design is based on a separation of content from <b>content</b> <b>description,</b> and we re-engineer it using ANNODEX. In doing this we demonstrate the improvements this new approach makes over our system and the increased opportunities it offers in terms of functionality. ...|$|E
40|$|In this paper, we {{describe}} {{a system which}} enables the filtering, recording and delivery of digital video broadcasts over satellite, by matching incoming <b>content</b> <b>descriptions</b> to pre-defined sets of personal user preferences which have been defined using MPEG- 7. The system enables the automatic analysis, selection and flexible, customized delivery of relevant content extracted from potentially hundreds of concurrent video channels...|$|R
40|$|With {{the growing}} number of bibliographic {{databases}} accessible online the user has to choose between the various sources, but <b>content</b> <b>descriptions</b> of the databases are often missing. In this paper we present an approach to describe bibliographic databases by content. It is based on classification profiles for each database. These profiles can be gained automatically with a limited number of queries with characteristic terms for each class of a classification. A method to gain characteristic terms is presented and the approach is tested on different databases. 1 Introduction The number of online databases is continously growing and the user has access to a lot of information sources via the internet. He has to choose between the various sources to select appropriate databases. It is therefore necessary to have <b>content</b> <b>descriptions</b> of the existing databases. Up to now there are few approaches to describe bibliographic databases by content. Moreover most of them aim at comparing a given [...] ...|$|R
40|$|The {{emerging}} ISO/IEC MPEG- 7 and MPEG- 21 multimedia standards use XML Schema {{for digital}} <b>content</b> <b>descriptions</b> and digital item declarations. They have posed an interesting challenge to XML query language design. The paper shows certain critical query specification issues for MPEG- 7 and MPEG- 21 XML documents and illustrates a logic method {{to handle the}} limitations in current text-oriented XML query languages for retrieving multimedia content and digital items...|$|R
