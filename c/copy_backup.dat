5|231|Public
5000|$|... "True disk-based backup staging"—which copies the [...] "Improved disk-to-disk-to-tape" [...] and [...] "Create {{synthetic}} full backups" [...] {{capabilities of}} Retrospect Windows 7 with different terminology. This uses a <b>Copy</b> <b>Backup</b> Script for later transfer to tape or portable media for safe offsite storage of disk backups that were created for fast onsite restores. <b>Copy</b> <b>Backup</b> {{can also be}} used for transfers of individual point-in-time backups between destination Media Sets. One can also use a Copy Media Set Script to copy multiple backups of the same Source(s) from one Media Set to another.|$|E
50|$|Logging and {{recovery}} {{also play a}} role in protecting data from media failure. ESE supports on-line backup where one or more databases are copied, along with log files in a manner that does not affect database operations. Databases can continue to be queried and updated while the backup is being made. The backup is referred to as a ‘fuzzy backup’ because the recovery process must be run as part of backup restoration to restore a consistent set of databases. Both streaming and shadow <b>copy</b> <b>backup</b> are supported.|$|E
50|$|A {{number of}} Microsoft Windows {{components}} have been updated {{to make use}} of Shadow <b>Copy.</b> <b>Backup</b> and Restore in Windows Vista, Windows Server 2008, Windows 7 and Windows Server 2008 R2 use shadow copies of files in both file-based and sector-by-sector backup. VSS is also used by the System Protection component which creates and maintains periodic copies of system and user data on the same local volume (similar to the Shadow Copies for Shared Folders feature in Windows Server) but allows it to be locally accessed by System Restore.|$|E
50|$|Shadow <b>copy</b> <b>backups</b> are a {{new high}} speed <b>backup</b> method. Shadow <b>copy</b> <b>backups</b> are {{dramatically}} faster because the copy is virtually made after {{a brief period of}} quiescing an application. As subsequent updates are made to the data, the virtual copy is materialized. In some cases, hardware support for shadow <b>copy</b> <b>backups</b> means that actually saving the virtual copies is unnecessary. Shadow <b>copy</b> <b>backups</b> are always full backups.|$|R
5000|$|Stacking feature {{which allows}} to have several <b>backup</b> <b>copies</b> - each <b>backup</b> <b>copy</b> for a {{particular}} point of time, to allow {{to get back to}} any of them whenever required.|$|R
5000|$|Argentum Backup is {{a backup}} {{software}} program for Microsoft Windows, produced by Argentum. Argentum <b>Backup</b> <b>copies</b> files into Zip compressed folders, {{as well as}} provides native file <b>copying.</b> <b>Backup</b> <b>copies</b> can be created both manually and automatically on the schedule. The product features a number of backup task templates to back up common file locations on computers with Microsoft Windows. Argentum Backup has won PC Magazine Editors' Choice award [...] and PC World Best Buy award.|$|R
5000|$|At {{the same}} time the User's Guide for Retrospect Windows was {{expanded}} from around 300 pages to nearly 700 pages. Some of the extra pages describe the extra Add-On features available only for Retrospect Windows 8, but a lot of them describe the use of features in much more fine-grained detail than in the Retrospect Macintosh 10 User's Guide. Contributing to the need for this detail is the fact that Retrospect Windows 8 and following editions have kept—probably to avoid confusing the administrator as Retrospect Macintosh 8 had—the same non-Macintosh-style UI (which some have found confusing, and which this article doesn't attempt to outline) and former terminology that Retrospect Windows 7 had. In GUI, for instance, Retrospect Windows has kept Immediate operations; it has also kept the Activity Monitor, which automatically displays on the Executing tab when an operation is in progress and can otherwise be displayed by clicking a button on the Retrospect toolbar, as a rough equivalent of the Activities category panel introduced in Retrospect Macintosh 8. Activity Monitor's different tabs, which perform the same function as Retrospect Macintosh 8 and following editions' Activities category panel Scope Bar and detail pane buttons, are described in multiple places in the Retrospect Windows User's Guide. In terminology, for instance, what Retrospect Macintosh 8 and following editions call a Media Set is still called a Backup Set in Retrospect Windows. Moreover, what is called a Copy Media Set operation in Retrospect Macintosh 8 and following is still called a Transfer Snapshots operation in Retrospect Windows; what is called a <b>Copy</b> <b>Backup</b> operation in Retrospect Macintosh 8 and following is still called a Transfer Backup Sets operation in Retrospect Windows. In Retrospect Windows, what is called a Copy operation in Retrospect Macintosh 8 and following is still called a Duplicate operation. What is called an [...] "activity thread" [...] in Retrospect Macintosh 8's [...] "powerful new engine" [...] is called an [...] "execution unit" [...] in Retrospect Windows. What Retrospect Macintosh 8 and following editions call a No Media Action backup and a Start New Media backup are still called a Normal backup and a New Media backup, respectively, in Retrospect Windows. No doubt because Selectors may specify the types of files and folders that are to be excluded from the operation, Retrospect Macintosh 8 and following editions have renamed Selectors as Rules. As noted in the appropriate section above, what is still called a Subvolume in Retrospect Windows has been renamed a Favorite Folder in Retrospect Macintosh 8.|$|E
40|$|As the {{computer}} system has developed much in this highly information-oriented society, database security has become a very important problem and its backup strategies {{need to be made}} more efficiently and safety. The image copy method has been used as the most simple and dependable recovery mechanism for media failure. However, this method spends high overhead costs for massive data transmission and much processing time in the normal operation of the database. To cover such weak points, incremental and full backup methods are adopted before updated trucks reach a predetermined level. Moreover, when the number of full backup files exceeded a predetermined level, we stop incremental and full backups and switch it to the image copy. This paper applies cumulative damage model to backup of files in a database system, by putting damage shock by update, failure shock by database failure and damage by dumped files, and considers the tradeoff among overhead costs of image copy and incremental, full backup methods, and discusses analytically an optimal policy for the image <b>copy</b> <b>backup</b> interval. Finally, numerical examples are given in the case of Poisson process and exponential distributions. </p...|$|E
30|$|MapReduce is {{a popular}} {{programming}} model for data-intensive tasks and has been widely used in many fields [9 – 14]. Hadoop is an opensource implementation of MapReduce, and a Hadoop cluster {{can be made up}} of thousands of commodity computers. The Hadoop cluster runs on top of the Hadoop distributed file system (HDFS). In the HDFS, data are partitioned into many small chunks and each chunk has multiple <b>backup</b> <b>copies.</b> The multiple <b>backup</b> <b>copy</b> mechanism of HDFS makes the running MapReduce tasks fault-tolerant.|$|R
5000|$|... 321 Studios was {{a private}} company that marketed and sold {{software}} and instructions for copying DVDs. DVD Copy Plus consisted of an electronic guide explaining how to create <b>backup</b> <b>copies</b> of DVDs, two pieces of free, publicly available software, and a CD burning application. This software allowed users to copy portions of DVDs onto CDs {{regardless of whether they}} were encoded using Content Scramble System ("CSS"). DVD X <b>Copy</b> created <b>backup</b> <b>copies</b> of DVDs onto a user's computer that could then be burned to a DVD. DVD X Copy used a CSS key to access the data if a DVD was encoded with CDD.|$|R
5000|$|... @MAX SyncUp {{allows users}} to create <b>backup</b> <b>copies</b> of files and recover data from <b>backup</b> <b>copies,</b> {{including}} recovering old versions of files that have changed and files that have been destroyed. It also {{allows users to}} synchronize files between two separate locations in both directions, and to schedule backups and synchronizations.|$|R
40|$|Abstract—Fault-tolerant {{scheduling}} plays {{a significant}} role in improving system reliability of clusters. Although extensive fault-tolerant scheduling algorithms have been proposed for real-time tasks in parallel and distributed systems, quality of service (QoS) requirements of tasks have not been taken into account. This paper presents a fault-tolerant scheduling algorithm called QAFT that can tolerate one node’s permanent failures at one time instant for real-time tasks with QoS needs on heterogeneous clusters. In order to improve system flexibility, reliability, schedulability, and resource utilization, QAFT strives to either advance the start time of primary copies and delay the start time of <b>backup</b> <b>copies</b> in order to help <b>backup</b> <b>copies</b> adopt the passive execution scheme, or to decrease the simultaneous execution time of the primary and <b>backup</b> <b>copies</b> of a task as much as possible to improve resource utilization. QAFT is capable of adaptively adjusting the QoS levels of tasks and the execution schemes of <b>backup</b> <b>copies</b> to attain high system flexibility. Furthermore, we employ the overlapping technology of <b>backup</b> <b>copies.</b> The latest start time of <b>backup</b> <b>copies</b> and their constraints are analyzed and discussed. We conduct extensive experiments to compare our QAFT with two existing schemes—NOQAFT and DYFARS. Experimental results show that QAFT significantly improves the scheduling quality of NOQAFT and DYFARS. Index Terms—Heterogeneous clusters, real-time, scheduling, fault tolerance, quality of service (QoS), heuristic. Ç...|$|R
5000|$|DVDFab, World's top-ranking DVD/Blu-ray backup tools, {{including}} DVD Copy and Blu-ray Copy, dedicating {{to providing}} the leading service to <b>copy</b> and <b>backup</b> any DVD/Blu-ray disc/ISO/folder without losing quality at a flash speed.|$|R
40|$|We {{describe}} {{a technique to}} make application programs fault tolerant. This techADnique {{is based on the}} concept of checkpointing from an active program to one ormore passive <b>backup</b> <b>copies</b> which serve as an abstraction of stable memory. Ifthe primary copy fails, one of the <b>backup</b> <b>copies</b> takes over and resumes processADing service requests. After each failure a new <b>backup</b> <b>copy</b> is created in order torestore the replication degree of the service. All mechanisms necessary to achieveand maintain fault tolerance can be added automatically to the code of a nonADfaulttolerant server, thus making fault tolerance completely transparent for the applicaADtion programmer...|$|R
50|$|Loading of {{third-party}} (homebrew) applications/games, not <b>backup</b> <b>copies</b> {{of retail}} games.|$|R
5000|$|M:Rokovnik (M:Organiser) - {{creating}} a <b>backup</b> <b>copy</b> of contacts and the calendar ...|$|R
5000|$|Kakegae no nai Mono (かけがえのないもの, Something with no <b>Backup</b> <b>Copy)</b> (January 21, 1999) ...|$|R
2500|$|The 1993 {{copyright}} law contained {{a list of}} allowed free uses of copyrighted works, similar to may other countries' laws. Free uses only related to limitations on the patrimonial rights of an author on a work; his moral rights remained untouched. Any free use was subject to the condition {{that it did not}} impede an author's legitimate rights and did not harm the normal exploitation of a work. The free uses contained provisions on reproductions made purely for personal uses and on archival <b>copies</b> (<b>backups),</b> as well as quotation rights, and provisions on news reporting (including a provision allowing the reproduction of previously published news reports in other newspapers or broadcasts.) ...|$|R
40|$|Abstract. In {{the paper}} {{we present a}} concept of making backups in the cloud. We discuss the current {{practice}} of making <b>backup</b> <b>copies</b> of data enabling backups to be stored in a separate location and analyze the possibility of making backups in the cloud. We mainly focus on the economic and performance aspects of using cloud computing for making <b>backup</b> <b>copies</b> of data...|$|R
40|$|Fault {{tolerance}} is {{an essential}} requirement for real-time systems, due to the potentially catastrophic consequences of faults. In this paper, we investigate an efficient off-line scheduling algorithm in which real-time tasks with precedence constraints can tolerate one processor's permanent failure in a heterogeneous system with fully connected network. The tasks {{are assumed to be}} non-preemptable, and each task has two copies that are scheduled on different processors and mutually excluded in time. In the literature in recent years, the quality of a schedule has been previously improved by allowing a <b>backup</b> <b>copy</b> to overlap with other <b>backup</b> <b>copies</b> on the same processor. However, this approach assumes that tasks are independent of one other. To meet the needs of real-time systems where tasks have precedence constraints, a new overlapping scheme is proposed. We show that, given two tasks, the necessary conditions for their <b>backup</b> <b>copies</b> to safely overlap in time with each other are, (1) their corresponding primary copies are scheduled on two different processors, (2) they are independent tasks, and (3) the execution of their <b>backup</b> <b>copies</b> implies the failures of the processors on which their primary copies are scheduled. For tasks with precedence constraints, the new overlapping scheme allows the <b>backup</b> <b>copy</b> of a task to overlap with its successors’ primar...|$|R
5000|$|Shadow <b>Copy</b> based block-level <b>backup</b> which {{supports}} optical media, network shares and Windows Recovery Environment.|$|R
50|$|Because {{the backup}} is already halfway {{done and the}} index already <b>copied,</b> the <b>backup</b> will be written with the article data present, but with the index {{reference}} missing. As {{a result of the}} inconsistency, this file is considered corrupted.|$|R
5000|$|VIDEO_TS.BUP file: the <b>backup</b> <b>copy</b> of the VIDEO_TS.IFO file. It {{is part of}} Video Manager (VMG).|$|R
40|$|As {{real-time}} fault-tolerant scheduling {{is one of}} {{the main}} research areas in real-time fault-tolerant techniques, this paper proposes an efficient scheduling algorithm for BKCL(EBKCL). EBKCL can schedule the tasks with the fault-tolerant requirements(FTR) together with tasks without FTR. It is assumed in BKCL that there are no overlaps between the <b>backup</b> <b>copies,</b> however, the <b>backup</b> <b>copies</b> are allowed to be overlapped in EBKCL. The simulation experiment shows that the performance of EBKCL is better than that of BKCL. In order to enhance the performance of the BKCL, a dynamic scheduling algorithm is proposed, the performance simulation and analysis of DSA are also given in this paper. KEY WORDS Fault-tolerant, real-time task, efficient scheduling, performance analysis, heuristics, distributed systems...|$|R
5000|$|In computing, [...] ".bak" [...] is a {{filename}} extension {{commonly used to}} signify a <b>backup</b> <b>copy</b> of a file.|$|R
5000|$|Makes {{explicit}} {{allowance for}} time shifting, format shifting and <b>backup</b> <b>copies</b> {{as long as}} no digital locks are involved.|$|R
5000|$|Hacking {{other systems}} {{to install and}} run <b>backup</b> <b>copies</b> of itself, or {{creating}} other allied superintelligent agents without kill switches.|$|R
50|$|A {{number of}} Microsoft Windows {{components}} have been updated {{to make use}} of Shadow <b>Copy.</b> The <b>Backup</b> and Restore Center in Windows Vista and later performs block-based backups when doing full system backups. The file backup feature also uses shadow copy but stores files inside ZIP files.|$|R
50|$|How {{persistent}} is the model, how protected is {{it against}} loss or damage? This also includes previous {{versions of the}} model, if these are relevant. E.g. for a model on disk, the physical quality will be higher {{if there is a}} <b>backup</b> <b>copy,</b> or even higher if this backup is on another disk whose failure is independent of the originals. Similarly, for models on paper, the amount and security of <b>backup</b> <b>copies</b> will be essential.|$|R
40|$|Many time-critical {{applications}} require predictable performance. Tasks {{corresponding to}} these applications have deadlines {{to be met}} {{despite the presence of}} faults. Failures can happen either due to processor faults or due to task errors. To tolerate both processor and task failures, the copies of every task have to be mutually excluded in space and also in time in the schedule. We assume that each task has two versions, namely, primary <b>copy</b> and <b>backup</b> <b>copy.</b> We believe that the position of the <b>backup</b> <b>copy</b> in the task queue with respect to the position of the primary copy (distance) is a crucial parameter which affects the performance of any fault-tolerant dynamic scheduling algorithm. To study the effect of distance parameter, we make fault-tolerant extensions to the well-known myopic scheduling algorithm [3] which is a dynamic scheduling algorithm capable of handling resource constraints among tasks. We have conducted an extensive simulation to study the effect of distance parameter on the schedulability of fault-tolerant myopic scheduling algorithm...|$|R
50|$|Restoring the <b>backup</b> <b>copy</b> {{of these}} data may reset the volume's {{password}} {{to what it was}} when the backup was taken.|$|R
40|$|Data {{corruption}} {{is one of}} the key problems that is on top of the radar screen of most CIOs. Continuous Data Protection (CDP) technologies help enterprises deal with data corruption by maintaining multiple versions of data and facilitating recovery by allowing an administrator restore to an earlier clean version of data. The aim of the recovery process after data {{corruption is}} to quickly traverse through the <b>backup</b> <b>copies</b> (old versions), and retrieve a clean copy of data. Currently, data recovery is an ad-hoc, time consuming and frustrating process with sequential brute force approaches, where recovery time is proportional to the number of <b>backup</b> <b>copies</b> examined and the time to check a <b>backup</b> <b>copy</b> for data corruption. In this paper, we present the design and implementation of SWEEPER architecture and <b>backup</b> <b>copy</b> selection algorithms that specifically tackle the problem of quickly and systematically identifying a good recovery point. We monitor various system events and generate checkpoint records that help in quickly identifying a clean <b>backup</b> <b>copy.</b> The SWEEPER methodology dynamically determines the selection algorithm based on user specified recovery time and recovery point objectives, and thus, allows system administrators to perform trade-offs between recovery time and data currentness. We have implemented our solution as part of a popular Storage Resource Manager product and evaluated SWEEPER under many diverse settings. Our study clearly establishes the effectiveness of SWEEPER as a robust strategy to significantly reduce recovery time. ...|$|R
50|$|For the Apple III version {{which came}} on a single {{diskette}} with a <b>backup</b> <b>copy</b> and instruction manual, the MSRP was US$295.|$|R
5000|$|Common {{desktop system}} {{recovery}} tools {{and procedures for}} failed desktop units, typically using <b>backup</b> <b>copies</b> of a boot image created with utilities ...|$|R
50|$|A fuzzy backup is a {{secondary}} (or <b>backup)</b> <b>copy</b> of data file(s) or directories {{that were in}} one state when the backup started, but in a different state {{by the time the}} backup completed. This may result in the <b>backup</b> <b>copy</b> being unusable because of the data inconsistencies. Although the backup process might have seemed successful, the resultant copies of the files or directories could be useless because a restore would yield inconsistent and unusable data.|$|R
40|$|Remote <b>backup</b> <b>copies</b> of {{databases}} {{are often}} maintained to ensure availability of data {{even in the}} presence of exten-sive failures, for which local replication mechanisms may be inadequate. We present two versions of an epoch algo-rithm for maintaining a consistent remote <b>backup</b> <b>copy</b> of a database. The algorithms ensure scalability, which makes them suitable for very large databases. The correctness and the performance of the algorithms are discussed, and an additional application for distributed group commit is given. 1...|$|R
