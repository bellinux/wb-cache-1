19|10000|Public
5000|$|The lens {{is focused}} {{manually}} and directly, without intermediate servo controls. However the lens zoom and focus can be operated with remote controls with a television studio configuration {{operated by a}} <b>camera</b> <b>control</b> <b>unit</b> (CCU).|$|E
5000|$|... 1946 RCA's TK-10 studio camera used a 3" [...] IO - Image Orthicon Tube with a 4 lens turret. The RCA TK-30 (1946) {{was widely}} {{used as a}} Field Camera. A TK-30 is simply a TK-10 with a {{portable}} <b>camera</b> <b>control</b> <b>unit.</b>|$|E
5000|$|... 1954 RCA's TK-11 studio camera used a 3" [...] IO - Image Orthicon Tube with a 4 lens turret. The RCA TK-31 (1954) {{was widely}} {{used as a}} Field Camera. A TK-31 is simply a TK-11 with a {{portable}} <b>camera</b> <b>control</b> <b>unit.</b> There is some commonality between the TK-11/TK-31 and the earlier TK-10/TK-30.|$|E
5000|$|The {{technical}} director's station, with waveform monitors, vectorscopes and the <b>camera</b> <b>control</b> <b>units</b> (CCU) or {{remote control}} panels for the CCUs.|$|R
5000|$|Multicore cables {{are used}} with {{professional}} video cameras. In television studios, 26-pin cables {{are used to}} connect [...] "cameras" [...] to <b>camera</b> <b>control</b> <b>units</b> (CCU). Triaxial cables are used primarily in outside broadcasting however both are capable of delivering an HD-SDI feed and 30 - 40 Watts of power for the Cameras.|$|R
5000|$|The fourth part is {{the video}} control area where the {{professional}} video <b>cameras</b> are <b>controlled</b> using <b>camera</b> <b>control</b> <b>units</b> (CCU) by one or two operators, {{to make sure that}} the iris is at the correct exposure and that all the cameras look the same. These operators can shade, balance, and focus the cameras from this position inside the truck. This area is controlled by an operator called a V1 and depending on the size of the show and/or the broadcast company may have a V2.|$|R
5000|$|The <b>camera</b> <b>control</b> <b>unit</b> (CCU) is {{typically}} {{part of a}} live television broadcast [...] "chain". It is responsible for powering the professional video camera, handling signals sent over the camera cable (multicore cable, triax or fiber) {{to and from the}} camera, and can be used to control various camera parameters such as iris remotely.|$|E
50|$|CM2 was a 'Topical News & Drama', two-camera vehicle {{equipped}} with Philips LDK-14 cameras connected to LDK-5 CCUs (<b>Camera</b> <b>Control</b> <b>Unit)</b> {{and based on}} a Dennis TK chassis. In 1982, Boys from the Blackstuff, an English Regions Drama production, was shot on CM2 in Liverpool. The director, Philip Saville, was breaking lots of conventions (not least shooting wide-angles and close-ups at the same time) and presented Ramon Bailey (Sound Supervisor) and his sound crew with lots of challenges.|$|E
5000|$|The Link-NEC 100 was the {{companion}} camera to the Type 130 and designed {{in conjunction with}} NEC. It had a triax interface unit and could be used stand alone, via a radio link or with a CCU via triax cable. it shared a common architecture with the 130 by using the same 18mm tubes and both where fully automatic for set-up and used the same CCU (<b>Camera</b> <b>Control</b> <b>Unit),</b> OCP (operational Control Unit) and MSU (Master Setup Unit) ...|$|E
5000|$|In a {{production}} control room (PCR), the technical director (TD) has overall responsibility for {{the operation of the}} production. The technical director ensures that all equipment in the PCR operates correctly. They also match the quality and the output of all the cameras on the studio floor through the <b>camera</b> <b>control</b> <b>units</b> (CCU) (Vision Engineering). The TD supervises the other crew members in the PCR. The technical director also coordinates the working of the whole crew, and handles technical problem before, during, or after the shooting of a project.|$|R
50|$|The cameras, which weighed {{hundreds}} of pounds on their own, were only {{one component of}} the TK-40/41 system. There were also backend devices placed in the <b>control</b> rooms (<b>camera</b> <b>control</b> <b>units</b> and colorplexers) to generate both full NTSC outputs routed to the program switchers as well as signals for the cameras for both video and intercom communication among crew members (the cameras integrated an audio system so that camera operators could talk to others via headsets). This combined chain was {{required in order to}} produce images. The TK-41's camera head weighed 300 lb and had to be carried by at least two people when setting up for remote broadcasts.|$|R
50|$|APIX is {{a serial}} high speed Gigabit Multichannel link to {{interconnect}} displays, <b>cameras</b> and <b>control</b> <b>units</b> over one single cable targeting automotive applications.APIX2 transmits {{up to two}} independent HR real time video channels plus bidirectional protected data communication like Ethernet, SPI, I2C including 8 channels for audio.|$|R
5000|$|The 2001 {{was both}} heavy and large. The {{pull-out}} handles at each corner needed four people to safely move the camera with the lens in place. It also required a separate remote <b>camera</b> <b>control</b> <b>unit</b> and the cable connecting the two was over 2 inches thick. The standard servo-controlled studio zoom lens had a 5 to 50° horizontal angle of view, {{with a minimum}} focus distance of either 36 inches (J type) or 18 inches (K type) ...|$|E
50|$|Most {{television}} studio and professional video cameras have dedicated generator-locking ports on the camera. If {{the camera is}} tethered with a triaxial cable or optical fibre cable, the analog generator-locking signal is used to lock the <b>camera</b> <b>control</b> <b>unit,</b> which in turn locks the camera head by means of information carried within a data channel transmitted along the cable. If the camera is an ENG-type camera, one without a triax/fibre connection or without a dockable head, the generator-locking signal is carried through a separate cable from the video.|$|E
50|$|While shooting, the {{director}} and assistant director create a line cut by instructing the technical director (or vision mixer in UK terminology) to switch between the feeds from the individual cameras. In the case of sitcoms with studio audiences, this line cut is typically displayed to them on studio monitors. The line cut might be refined later in editing, as often the output from all cameras is recorded, both separately and as a combined reference display called the q&shy; split. The camera currently being recorded to the line cut is indicated by a tally light controlled by a <b>camera</b> <b>control</b> <b>unit</b> (CCU) on the camera as a reference both for the actors and the camera operators.|$|E
40|$|Camera system {{provides}} accurate photographic recording during acceleration of centrifuge and permits immediate observation of dynamic changes in retinal circulation by a closed-circuit television loop. System consists of main <b>camera,</b> remote <b>control</b> <b>unit,</b> and strobe power supply unit, {{and is used}} for fluorescein studies and dynamometry sequences...|$|R
50|$|For {{television}} productions {{with more}} than one camera in a multiple-camera setup, the tally lights are generally illuminated automatically by a vision mixer trigger that is fed to a tally breakout board and then to a special video router designed for tally signals. The video switcher keeps track of which video sources are selected by the technical director and output to the main program bus. A switch automatically closes the appropriate electrical contacts to create a circuit, this lights the tallys located in the <b>camera</b> <b>control</b> <b>units</b> (CCU). If more than one camera is on-air simultaneously (as {{in the case of a}} dissolve), during the duration of the transition the tally lights of both cameras will remain lit until transition completion.|$|R
50|$|The FTTO switch {{provides}} {{a connection between}} optical uplinks and electrical downlinks. Typically, the switch has up to five twisted pair ports supporting Power over Ethernet (IEEE 802.3af, 15.4W per Port) and Power over Ethernet Plus (IEEE 802.3at, 30W per Port). Modern FTTO Switches offer speeds of 1 Gbit/s per user port (Gigabit Ethernet). Link aggregation may also be supported. Thus, PCs, laptops, IP Phones, wireless access points, <b>cameras,</b> access <b>control</b> <b>units,</b> building automation devices (including lights control, electricity meters, cooling and HVAC units), and other devices with network interfaces may {{be connected to the}} backbone network with Gigabit speeds.|$|R
5000|$|Block {{cameras are}} so called because the camera head {{is a small}} block, often smaller than the lens itself. Some block cameras are {{completely}} self-contained, while others only contain the sensor block and its pre-amps, thus requiring connection to a separate <b>camera</b> <b>control</b> <b>unit</b> in order to operate. All {{the functions of the}} camera can be controlled from a distance, and often there is a facility for controlling the lens focus and zoom as well. These cameras are mounted on pan and tilt heads, and may be placed in a stationary position, such as atop a pole or tower, in a corner of a broadcast booth, or behind a basketball hoop. They can also be placed on robotic dollies, at the end of camera booms and cranes, or [...] "flown" [...] in a cable supported harness, as shown in the illustration.|$|E
50|$|Most {{television}} studio cameras {{stand on the}} floor, usually with pneumatic or hydraulic mechanisms called pedestals to adjust the height, and are usually on wheels. Any video camera when used along with other video cameras in a multiple-camera setup is controlled by a device known as CCU (<b>camera</b> <b>control</b> <b>unit),</b> {{to which they are}} connected via a Triax, Fibre Optic or the almost obsolete multicore cable. The CCU along with genlock and other equipment is installed in the production control room (PCR) often known as the Gallery of the {{television studio}}. When used outside a formal television studio in outside broadcasting (OB), they are often on tripods {{that may or may not}} have wheels (depending on the model of the tripod). Initial models used analog technology, but are now obsolete, supplanted by digital models. Studio cameras are light and small enough to be taken off the pedestal and the lens changed to a smaller size to be used on a Multiple-camera setup's shoulder. Cameras can be mounted on a tripod, a dolly or a crane, thus making the cameras much more versatile than previous generations of studio cameras. These cameras have a tally light, a small signal-lamp used that indicates, for the benefit of those being filmed as well as the camera operator, that the camera is 'live' - i.e. its signal is being used for the 'main program' at that moment.|$|E
5000|$|The Link 125 {{camera was}} {{purchased}} in quantity by the BBC and deployed {{to most of}} the studios at Television Centre, Pebble Mill in Birmingham and Belfast as well as several other BBC studios. It was also the camera of choice at Limehouse Television. As well as ITV company Television South (TVS) used the model in its Maidstone studios, which were still in use by those studios when they were sold off as an independent studio facility following the loss of TVS's franchise at the end of 1992.The 125 was a well thought out and well-built studio and OB camera developed from the Link 120 portable camera system. It also contained a comprehensive communications system and used a <b>camera</b> <b>control</b> <b>unit</b> (CCU) based around the 110's but updated with auto black, white, iris and centering functions.The BBC preferred to use a mid range Schneider-Kreuznach lens as it gave good zoom angles. Some believed it produced one of the best images for a pickup tube camera, others believed it could never match the quality of the EMI 2001. Many BBC users felt that the image was soft and not easy to focus, it also produced an unusual image effect that formed the shape of a 'teardrop'The Link 125 was the most successful of all of Links cameras and the last studio to use them was BBC Pebble Mill which decommissioned the last four in 1994 from the news studio having upgraded to Sony BVP-375's and Ikegami HL-55's a few years before. These cameras have become collectable vintage items.|$|E
40|$|In {{order to}} grab {{and place the}} sealing rings of battery lid quickly and accurately, an {{automatic}} assembling system for sealing rings based on machine vision is developed in this paper. The whole system is composed of the light sources, <b>cameras,</b> industrial <b>control</b> <b>units,</b> and a 4 -degree-of-freedom industrial robot. Specifically, the sealing rings are recognized and located automatically with the machine vision module. Then industrial robot is controlled for grabbing the sealing rings dynamically under the joint work of multiple <b>control</b> <b>units</b> and visual feedback. Furthermore, the coordinates of the fast-moving battery lid are tracked by the machine vision module. Finally the sealing rings are placed on the sealing ports of battery lid accurately and automatically. Experimental results demonstrate that the proposed system can grab the sealing rings and place them on the sealing port of the fast-moving battery lid successfully. More importantly, the proposed system can improve {{the efficiency of the}} battery production line obviously...|$|R
40|$|We {{present a}} {{framework}} for real-time tracking of objects. Our system consists of multiple <b>cameras</b> and a <b>control</b> <b>unit</b> that communicate through a network. Each camera has a generalpurpose processor and a reconfigurable hardware unit embedded in it. Therefore, some computation can be performed {{at the point of}} data collection. We argue that collocating the computation with the data at vision sensors can improve performance, communication overhead and network scalability. We exploit the parameterization and tuning of the vision algorithms and present a sample tracking application implemented on our framework. We further argue that the proposed architecture can be used to implement many other real-time vision applications through hardware reconfiguration...|$|R
40|$|AbstractIn {{the field}} of Biomedical Optics {{measurement}} of tissue optical properties, like absorption, scattering, and reduced scattering coefficient, has gained importance for therapeutic and diagnostic applications. Accuracy in determining the optical properties is of vital importance to quantitatively determine chromophores in tissue. There are different techniques used to quantify tissue chromophores. Reflectance spectroscopy {{is one of the}} most common methods to rapidly and accurately characterize the blood amount and oxygen saturation in the microcirculation. With a hyper spectral imaging (HSI) device it is possible to capture images with spectral information that depends both on tissue absorption and scattering. To analyze this data software that accounts for both absorption and scattering event needs to be developed. In this thesis work an HSI algorithm, capable of assessing tissue oxygenation while accounting for both tissue absorption and scattering, is developed. The complete imaging system comprises: a light source, a liquid crystal tunable filter (LCTF), a camera lens, a CCD <b>camera,</b> <b>control</b> <b>units</b> and power supply for light source and filter, and a computer. This work also presents a Graphic processing Unit (GPU) implementation of the developed HSI algorithm, which is found computationally demanding. It is found that the GPU implementation outperforms the Matlab “lsqnonneg” function by the order of 5 - 7 X. At the end, the HSI system and the developed algorithm is evaluated in two experiments. In the first experiment the concentration of chromophores is assessed while occluding the finger tip. In the second experiment the skin is provoked by UV light while checking for Erythema development by analyzing the oxyhemoglobin image at different point of time. In this experiment the melanin concentration change is also checked at different point of time from exposure. It is found that the result matches the theory in the time dependent change of oxyhemoglobin and deoxyhemoglobin. However, the result of melanin does not correspond to the theoretically expected result...|$|R
5000|$|The {{earliest}} {{video cameras}} were mechanical flying-spot scanners {{which were in}} use in the 1920s and 1930s {{during the period of}} mechanical television. Improvements in video camera tubes in the 1930s ushered in the era of electronic television. Earlier, cameras were very large devices, almost always in two sections. The camera section held the lens and tube pre-amplifiers and other necessary electronics, and was connected to a large diameter multicore cable to the remainder of the camera electronics, usually mounted in a separate room in the studio, or a remote truck. The camera head could not generate a video picture signal on its own. The video signal was output to the studio for switching and transmission. By the fifties, electronic miniaturization had progressed to the point where some monochrome cameras could operate stand alone and even be handheld. But the studio configuration remained, with the large cable bundle transmitting the signals back to the <b>camera</b> <b>control</b> <b>unit</b> (CCU). The CCU in turn was used to align and operate the camera's functions, such as exposure, system timing, video and black levels.The first color cameras (1950s in the US, early 1960s in Europe), notably the RCA TK-40/41 series, were much more complex with their three (and in some models four) pickup tubes, and their size and weight drastically increased. Handheld color cameras did not come into general use until the early 1970s - the first generation of cameras were split into a camera head unit (the body of the camera, containing the lens and pickup tubes, and held on the shoulder or a body brace in front of the operator) connected via a cable bundle to a backpack CCU. The Ikegami HL-33, the RCA TK45 and the Thomson Microcam were portable two piece color cameras introduced in the early 1970s. For field work a separate VTR was still required to record the camera's video output. Typically this was either a portable 1" [...] reel to reel VTR, or a portable 3/4" [...] U-matic VCR. Typically, the two camera units would be carried by the camera operator, while a tape operator would carry the portable recorder. With the introduction of the RCA TK76 in 1976, camera operators were finally able to carry on their shoulders a one piece camera containing all the electronics to output a broadcast quality composite video signal. A separate videotape recording unit was still required.|$|E
30|$|It is a fully {{integrated}} system complete with laser <b>camera,</b> <b>control</b> <b>unit,</b> and software.|$|E
30|$|IR 1, IR 2, UVI and LIR are cameras with large-format {{detector}} arrays, {{and have}} much common {{features in the}} image data format. They are operated sequentially as a unit in many cases as described in Section 5. For these reasons, a dedicated <b>camera</b> <b>control</b> <b>unit</b> called the Digital Electronics unit (DE) was developed to conduct sequential exposures using these cameras and to process the image data from these cameras before storing them in the data recorder.|$|E
40|$|Visual {{perception}} {{is thought to}} provide us with the illusion of a stable visual world that is seamless in time and space while it is continuously explored with saccades. The oculomotor system ensures retinal image stabilization during head, object, and surround motion. Prior to manipulation, objects are fixated with topdown driven look-ahead saccades, and similarly, the locomotion path is visually inspected about two steps ahead. In human-human interaction tasks gaze is not only crucial for motor intention recognition but it is also essential in detecting the direction of social attention. A new prototype of a <b>camera</b> motion <b>control</b> <b>unit</b> was developed that provides a sufficiently short latency and a light-weight setup for both a wearable gazecontrolled and a humanoid stereo camera system. The camera system will serve as a binocular eye plant for a humanoid active vision system. The long-term aim is to integrate eye tracking capabilities into the vision system that will equip the humanoid with the ability to infer the target of gaze of a human in human-machine cooperation scenarios. The eye tracking technology has been improved by extending it into the direction of a calibration-free operation. The antropomorphic <b>camera</b> motion <b>control</b> system was integrated into the humanoid JOHNNIE. Thereby, a new experimental tool was created that will help to evaluate the relevance of gaze and look-ahead fixations in the interaction of humans with humanoids in social contexts or during (humanoid) locomotion. ∗This work was supported in part within the DFG excellence initiativ...|$|R
40|$|The Low Vision Enhancement System (LVES) is a video headset {{that offers}} {{people with low}} vision a view of their {{surroundings}} equivalent to the image on a five-foot television screen four feet from the viewer. It will not make the blind see but for many people with low vision, it eases everyday activities such as reading, watching TV and shopping. LVES was developed over almost a decade of cooperation between Stennis Space Center, the Wilmer Eye Institute of the Johns Hopkins Medical Institutions, the Department of Veteran Affairs, and Visionics Corporation. With the aid of Stennis scientists, Wilmer researchers used NASA technology for computer processing of satellite images and head-mounted vision enhancement systems originally intended for the space station. The unit consists of a head-mounted video display, three video <b>cameras,</b> and a <b>control</b> <b>unit</b> for the <b>cameras.</b> The cameras feed images to the video display in the headset...|$|R
40|$|A {{performance}} {{test of a}} night image intensification system {{for use as a}} visual aid by the crewmen in Gemini is reported. The equipment package consisted of (1) image intensification camera; (2) <b>camera</b> <b>control</b> unit; (3) viewing monitor; (4) recording monitor and photographic recorder; and (5) monitor electronics and equipment <b>control</b> <b>unit.</b> Representative photographs are predominantly of lights and clouds. Photographs of three different sections of coastline reveal a contrast between the images of land and ocean. These images range in quality from good to poor...|$|R
40|$|In {{order to}} obtain an {{objective}} and permanent record of motility of human spermatozoa, a spermatozoon was followed under a microscope and its movement was traced on paper. Instruments for recording spermatozoal movement consisted of a phase-contrast microscope, a camera head, a <b>camera</b> <b>control</b> <b>unit,</b> an X-Y tracker, a TV monitor and an X-Y recorder. These are assembled as illustrated in Fig's. 1 and 2. The X-Y tracker, {{one of the most}} important instruments in this system, was devised for use in aeronautics or architecture, such as to monitor the orbit of a rocket, to measure the sway of skyscrapers to predict when it might crumble down during an earthquake and to measure the sway of a big bridge to determine whether it would hold during a storm. In the spermatozoal trackogram the spermatozoon progressed in a roughly straight line in a sine curve, and at times in a rectangular wave (Fig. 2 to 5). The speed of spermatozoa movement in the X and Y directions can be immediately and automatically calculated if a computer is connected to this system. The system will be useful for recording the movement of a single free cell...|$|E
40|$|We {{present a}} {{synchronous}} navigation module for CT colonography (CTC) reading. The {{need for such}} a system arises because most CTC protocols require a patient to be scanned in both supine and prone positions to increase sensitivity in detecting colonic polyps. However, existing clinical practices are limited to reading one scan at a time. Such limitation {{is due to the}} fact that building a reference system between scans for the highly flexible colon is a nontrivial task. The conventional centerline approach, generating only the longitudinal distance along the colon, falls short in providing the necessary orientation information to synchronize the virtual navigation cameras in both scanned positions. In this paper we describe a synchronous navigation system by using the teniae coli as anatomical references. Teniae coli are three parallel bands of longitudinal smooth muscle on the surface of the colon. They are morphologically distinguishable and form a piecewise triple helix structure from the appendix to the sigmoid colon. Because of these characteristics, they are ideal references to synchronize virtual cameras in both scanned positions. Our new navigation system consists of two side-by-side virtual colonoscopic view panels (for the supine and prone data sets respectively) and one single <b>camera</b> <b>control</b> <b>unit</b> (which controls both the supine and prone virtual cameras). The capability to examine the same colonic region simultaneously in both scanned images can raise an observer’s confidence in polyp identification and potentially improve the performance of CT colonography...|$|E
40|$|Voltage {{response}} {{of an active}} CID pixel is analyzed in detail theoretically. The linearity of the photo-response is assessed in destructive and non-destructive read-out modes of operation. The theoretical findings are illustrated by experimental data obtained from a test chip fabricated in 0. 18 [micron] process. The test chip contained over 2400 active CID pixel structures with different geometries. The analysis is shown {{to be in good}} agreement with the experimental results. The charge injection device, CID 25, is presented. CID 25 is a color video sensor compliant with the NTSC TV standard. It has 484 by 710 displayable pixels and is capable of producing 30 frames-per-second color video. CID 25 is equipped with the active pixel technology combined with parallel row processing to achieve high conversion gain and low noise bandwidth. The on-chip correlated double sampling circuitry seres to reduce the low frequency noise components. CID 25 is operated by the camera system, ColoRAD, consisting of two parts, the head assembly and the <b>camera</b> <b>control</b> <b>unit.</b> These two parts are separated by a cable that can be up to 150 meter long. The CID 25 imager and the head portion of the camera are radiation hardened. They can produce color video with insignificant signal-to-noise ratio degradation out to at least 4 Mrad of total dose of ⁶⁰Co [gamma]- radiation. Detailed results of ColoRAD system testing before, during, and after irradiation are presented and discussed. In summary ColoRAD is the first radiation hardened color video system, based on a semiconductor photo-detector that has an adequate sensitivity for operation in room lighting environment...|$|E
50|$|Four {{computers}} were used. Two {{were used for}} frame reductions, one for telescope pointing control and one for <b>camera</b> <b>control.</b> The <b>camera</b> <b>control</b> software had scripting capability and could control all the other computers.|$|R
40|$|Virtual <b>camera</b> <b>control</b> is a {{key factor}} in game {{experience}} be-cause the camera dictates how players see the game world. As the complexity and unpredictability of games increases, automatic <b>camera</b> <b>control</b> becomes a fundamental require-ment. In this paper, we present a game technology demon-strator that showcases automatic <b>camera</b> <b>control</b> capable of creating dissimilar experiences within a 3 D prey/predator game. An adaptation algorithm informed by predictors of subjective experiences adjusts the behavior of the camera to influence the experience of the player throughout the game. 1. ADAPTIVE <b>CAMERA</b> <b>CONTROL</b> <b>Camera</b> <b>control</b> is an important component of player expe-rience [4]: the camera viewpoint defines the amount of in-formation shown to the player and thus has a direct impact on the perceived challenge [5] as well as other aspects of the experience, such as player frustration [6]. While most research on automatic <b>camera</b> <b>control</b> tech-niques has centered around the efficient placement of the camera, determination of the viewpoint and the ease of use (e. g. [3]), {{a number of studies have}} investigated the connec-tions between <b>camera</b> <b>control</b> and player experience. Burelli and Yannakakis [2] studied automatic <b>camera</b> <b>control</b> in re-lation to playing and gaze behavior, building computational models of camera view preferences based on the players’ behavior. Yannakakis et al. [6] investigated a larger vari-ety of experiences focusing on the relation between camera and several affective states, such as frustration and excite-ment. Computational models mapping the player’s physi-ological state and the game’s camera profile to subjective self-reports of experience were built facilitating an objec-tive estimator of the player’s affective state in relation to camera behavior. Similar models — substituting physiolog-ical information with gameplay data — were used to imple-ment a demonstrator of affective <b>camera</b> <b>control</b> 1 in whic...|$|R
50|$|Since {{the camera}} {{operator}} {{is often not}} {{able to use the}} <b>camera's</b> <b>controls</b> directly or look through the camera's viewfinder, a jib is often used in conjunction with a remote <b>camera</b> <b>control</b> for focus and zoom and with a portable video monitor.|$|R
