53|13|Public
50|$|The {{main issue}} about certain {{applications}} of <b>color</b> <b>normalization</b> {{is that the}} end result looks unnatural or too distant from the original colors. In cases {{where there is a}} subtle variation between important aspects, this can be problematic. More specifically, the side effect can be that pixels become divergent and not reflect the actual color value of the image.A way of combating this issue is to use <b>color</b> <b>normalization</b> in combination with thresholding to correctly and consistently segment a colored image.|$|E
50|$|Comprehensive <b>color</b> <b>normalization,</b> {{just like}} the {{histogram}} equalization method previously mentioned, produces results that may look less natural due to {{the reduction in the}} number of color values.|$|E
50|$|<b>Color</b> <b>normalization</b> is a {{topic in}} {{computer}} vision concerned with artificial color vision and object recognition. In general, the distribution of color values in an image depends on the illumination, which may vary depending on lighting conditions, cameras, and other factors. Colour normalisation allows for object recognition techniques based on colour to compensate for these variations.|$|E
40|$|This work {{presents}} {{an evaluation of}} three color constancy techniques applied to a landmark detection system designed for a walking robot, which has to operate in unknown and unstructured outdoor environments. The first technique is the well-known image conversion to a chromaticity space, and the second technique is based on successive lighting intensity and illuminant <b>color</b> <b>normalizations.</b> Based on a differential model of color constancy, we propose the third technique, based on color ratios, which unifies the processes of color constancy and landmark detection. The approach used to detect potential landmarks, which is common to all evaluated systems, is based on visual saliency concepts using multiscale color opponent features to identify salient regions in the images. These regions are selected as landmark candidates, and they are further characterized by their features for identification and recognition. ...|$|R
40|$|European Workshop on Advanced Mobile Robots (EUROBOT), 2001, Lund (Suecia) This work {{presents}} {{an evaluation of}} three color constancy techniques applied to a landmark detection system designed for a walking robot, which has to operate in unknown and unstructured outdoor environments. The first technique is the well-known image conversion to a chromaticity space, and the second technique is based on successive lighting intensity and illuminant <b>color</b> <b>normalizations.</b> Based on a differential model of color constancy, we propose the third technique, based on color ratios, which unifies the processes of color constancy and landmark detection. The approach used to detect potential landmarks, which is common to all evaluated systems, is based on visual saliency concepts using multiscale color opponent features to identify salient regions in the images. These regions are selected as landmark candidates, and they are further characterized by their features for identification and recognition. This work {{was supported by the}} project 'Navegación autónoma de robots guiados por objetivos visuales' (070 - 720). Peer Reviewe...|$|R
40|$|The author {{discusses}} five infants, aged {{eight to}} 11 months, with carotenemia secondary to excessive consumption of carotene-containing foods. These infants had white sclerae {{in spite of}} yellow discoloration of the skin. Simple elimination of these foods led to clearing of the yellow skin <b>color</b> and <b>normalization</b> of serum carotene levels. All infants had normal vitamin A levels, white cell count, serum glucose, lipids, liver- and thyroid-function tests. The benign nature of this condition is emphasized...|$|R
50|$|As {{mentioned}} above, grey world <b>color</b> <b>normalization</b> is invariant to illuminated color variations α, β and γ, {{however it}} has one important problem: it {{does not account for}} all variations of illumination intensity and it is not dynamic; when new objects appear in the scene it fails. To solve this problem there are several variants of the grey world algorithm.Additionally there is an iterative variation of the grey world normalization, however it was not found to perform significantly better.|$|E
50|$|There is a {{vast array}} of {{different}} transformations and algorithms for achieving <b>color</b> <b>normalization</b> and a limited list is presented here. The performance of an algorithm is dependent on the task and one algorithm which performs better than another in one task might perform worse in another (no free lunch theorem). Additionally, the choice of the algorithm depends on the preferences of the user for the end-result, e.g. they may want a more natural-looking color image.|$|E
5000|$|The {{comprehensive}} <b>color</b> <b>normalization</b> {{is shown}} to increase localization and object classification results in combination with color indexing. It is an iterative algorithm which works in two stages. The first stage {{is to use the}} red, green and blue color space with the intensity normalized, to normalize each pixel. The second stage is to normalize each color channel separately, so that the sum of the color components is equal to one third of the number of pixels. The iterations continue until convergence, meaning no additional changes. Formally: ...|$|E
40|$|This paper {{proposes a}} novel {{approach}} to color texture characterization and classification. Rather than developing new textural features, we propose to derive a family of new, reduced dimensionality color spaces (that we call), that allow a good classification performance {{by the use of}} classical energy-distribution features, defined in a scalar spectral domain. The dimensionality reduction approach {{can be traced back to}} <b>color</b> constancy <b>normalization</b> and the reduced ordering principle and exhibits a strong perceptual background. We develop an adaption procedure for the selection of the proper color space within the new family. The overall classification performance is very promising and the proposed methodology surmounts the current color texture characterization by energetic features extracted from the luminance spectrum only. 1. Introduction The ever increasing range of computer vision applications continuously fed the need for faster and more accurate image analysis [...] ...|$|R
30|$|We may note at {{this point}} that all the above {{mentioned}} illumination normalization techniques are used on gray-scale images. However, in recent times, most face images that are acquired and are available for face recognition task are color images. Studies have shown that illumination effect due to changes in light direction can be addressed in the color domain when the source color is known and constant over a scene [34, 35]. According to Zickler et al. [34], red, green, and blue (rgb) color space transformations remove the effect of illumination direction without explicit specular/diffuse separation. This claim is also supported by the work of Finlayson et al. [35], where it is highlighted that the image dependencies due to lighting geometry can be removed by normalizing the magnitude of the rgb pixel triplets. Therefore, inspired by these studies, the proposition of illumination normalization steps that take advantage of <b>color</b> domain <b>normalization</b> to improve the performance of edge-based face recognition systems is desired.|$|R
40|$|Images or videos may be imaged under {{different}} illuminants than models in an image or video proxy database. Changing illumination color in particular may confound recognition algorithms based on color histograms or video segmentation routines based on these. Here {{we show that}} a very simple method of discounting illumination changes is adequate for both image retrieval and video segmentation tasks. We develop a feature vector of only 36 values that can also be em used for both these objectives {{as well as for}} retrieval of video proxy images from a database. The new image metric is based on a color-channel-normalization step, followed by reduction of dimensionality by going to a chromaticity space. Treating chromaticity histograms as images, we perform an effective low-pass filtering of the histogram by first reducing its resolution via a wavelet-based compression and then by a DCT transformation followed by zonal coding. We show that the color constancy step [...] <b>color</b> band <b>normalization</b> [...] can [...] ...|$|R
50|$|<b>Color</b> <b>normalization</b> {{has been}} used for object {{recognition}} on color images in the field of robotics, bioinformatics and general artificial intelligence, when it is important to remove all intensity values from the image while preserving color values. One example is in case of a scene shot by a surveillance camera over the day, where it is important to remove shadows or lighting changes on same color pixels and recognize the people that passed. Another example is automated screening tools used for the detection of diabetic retinopathy as well as molecular diagnosis of cancer states, where it is important to include color information during classification.|$|E
40|$|In {{order to}} improve object {{recognition}} results, usually several image preprocessings are performed. If color images are used, a <b>color</b> <b>normalization</b> is normally applied. Algorithms for <b>color</b> <b>normalization</b> will be compared to a colorimetric approach found in the literature. Recovering colorimetric values instead of a simple RGB camera output leads to more reliable color images. To this kind of processed object image a basic object recognition approach using different histogram distances is applied. It will be shown {{that there is an}} effect on the results of object recognition rates if we use color calibrated images instead of <b>color</b> <b>normalization</b> methods...|$|E
30|$|There exist several color systems, for {{different}} purposes: RGB (for displaying process), XYZ (for color standardization), rgb, xyz (for <b>color</b> <b>normalization</b> and representation), CieL*u*v*, CieL*a*b* (for perceptual uniformity), HSV (intuitive description) [2, 32].|$|E
40|$|Microarray-based {{analysis}} of {{single nucleotide polymorphisms}} (SNPs) has many applications in large-scale genetic studies. To minimize the influence of experimental variation, microarray data usually need to be processed in different aspects including background subtraction, normalization and low-signal filtering before genotype determination. Although many algorithms are sophisticated for these purposes, biases are still present. In the present paper, new algorithms for SNP microarray data analysis and the software, AccuTyping, developed based on these algorithms are described. The algorithms {{take advantage of a}} large number of SNPs included in each assay, and the fact that the top and bottom 20 % of SNPs can be safely treated as homozygous after sorting based on their ratios between the signal intensities. These SNPs are then used as controls for <b>color</b> channel <b>normalization</b> and background subtraction. Genotype calls are made based on the logarithms of signal intensity ratios using two cutoff values, which were determined after training the program with a dataset of ∼ 160 [*] 000 genotypes and validated by non-microarray methods. AccuTyping was used to determine > 300 [*] 000 genotypes of DNA and sperm samples. The accuracy was shown to be > 99 %. AccuTyping can be downloaded from...|$|R
40|$|The authors {{present an}} early laparoscopic {{treatment}} in a newborn with biliary atresia. They describe the technical {{details of the}} Kasai laparoscopic procedure. A 10 -day-old girl, weight 2. 4 kg, was admitted {{with a history of}} jaundice and fecal acholia since birth, with elevated total bilirubin and abnormal hepatic test. Abdominal ultrasound showed a small gallbladder with hyperechogenicity in porta hepatis and absence of biliary principal duct. Other metabolic and hematological tests were normal. The procedure was performed at 20 -day-old by laparoscopy. The cholangiography confirmed the biliary atresia and Kasai&#x 2032;s procedure was continued by laparoscopy and transumbilical extracorporeal Roux-Y approach. The duration of the procedure was 220 min, with good tolerance of pneumoperitoneum due to the laparoscopy. Feedings of breast milk began on the third day postoperative, presenting normal <b>colored</b> stools, with <b>normalization</b> of the hepatic test. A 20 months follow-up was without complications...|$|R
40|$|Abstract — This paper {{presents}} a new <b>color</b> space <b>normalization</b> (CSN) technique for enhancing the discriminating power of color space {{along with the}} principal component analysis (PCA) for the face recognition process. The common RGB technique is not suitable for the characterizing of the skin color due {{to the presence of}} luminance factor. In the YCbCr color space, the luminance information is contained in Y component, and the chrominance information is in Cb and Cr. Therefore, the luminance information can be easily de-embedded. Different color spaces have different discriminating power, in this paper, eye can be perfectly detected by using YcbCr color space and the mouth regions can be perfectly detected by using the YIQ color space. Then PCA is used to express the large 1 -D vector of pixels constructed from 2 -D facial image into the compact principal components of the feature space. Each face image may be represented as a weighted sum (feature vector) of the eigenfaces, which are stored in a 1 D array. PCA allows us to compute a linear transformation that maps data from a high dimensional space to a lower dimensional space. It covers standard deviation, covariance, eigenvectors and eigenvalues. Face recognition is obtained by PCA without much loss of information. Experiments using different databases by varying the facial expressions (open/closed eyes, smiling/not smiling) show that the proposed method by combining color space discrimination and PCA can improve face recognition to a great extend...|$|R
40|$|Color is a {{powerful}} descriptor that often simplifies object extraction and identification, and many computer vision systems use color to aid object recognition. However, image colors strongly depend on lighting geometry (direction and intensity of light source) and illuminant color (spectral power distribution). Either small variation in the intensity or the change of scene illumination can dramatically make object color changed. To overcome the lighting dependency problem, a color constancy or normalization algorithm {{should be used for}} pre-processing. This paper presents a novel approach to performing <b>color</b> <b>normalization.</b> A nonlinear mapping function is estimated using a neural network. Once the mapping function is found accurately, an image under unknown illumination may be transformed to the image under the predetermined illumination, which will be useful for color image processing. Three groups of experiments were conducted. In our experiments, images are processed by various neural networks and the performance is boosted by using a committee machine, and then the mapping errors is estimated and the results are compared with those of other algorithms. The experimental results demonstrate that the performance of the proposed method is superior to that of other <b>color</b> <b>normalization</b> algorithms. Index Terms [...] <b>Color</b> <b>normalization,</b> color constancy, neural networks, committee machine, genetic algorith...|$|E
40|$|Context: <b>Color</b> <b>normalization</b> {{techniques}} for histology {{have not been}} empirically tested for their utility for computational pathology pipelines. Aims: We compared two contemporary {{techniques for}} achieving a common intermediate goal - epithelial-stromal classification. Settings and Design: Expert-annotated regions of epithelium and stroma were treated as ground truth for comparing classifiers on original and color-normalized images. Materials and Methods: Epithelial and stromal regions were annotated on thirty diverse-appearing H and E stained prostate cancer tissue microarray cores. Corresponding sets of thirty images each were generated using the two <b>color</b> <b>normalization</b> techniques. Color metrics were compared for original and color-normalized images. Separate epithelial-stromal classifiers were trained and compared on test images. Main analyses were conducted using a multiresolution segmentation (MRS) approach; comparative analyses using two other classification approaches (convolutional neural network [CNN], Wndchrm) were also performed. Statistical Analysis: For the main MRS method, which relied on classification of super-pixels, the number of variables used was reduced using backward elimination without compromising accuracy, and test - area under the curves (AUCs) were compared for original and normalized images. For CNN and Wndchrm, pixel classification test-AUCs were compared. Results: Khan method reduced color saturation while Vahadane reduced hue variance. Super-pixel-level test-AUC for MRS was 0. 010 - 0. 025 (95 % confidence interval limits ± 0. 004) higher for the two normalized image sets compared to the original in the 10 - 80 variable range. Improvement in pixel classification accuracy was also observed for CNN and Wndchrm for color-normalized images. Conclusions: <b>Color</b> <b>normalization</b> can give a small incremental benefit when a super-pixel-based classification method is used with features that perform implicit <b>color</b> <b>normalization</b> while the gain is higher for patch-based classification methods for classifying epithelium versus stroma...|$|E
40|$|Digital fundus {{images are}} getting more {{interest}} while developing automated screening systems for diabetic retinopathy. And owing to the acquisition process, these images are very often of poor quality that hinders further analysis. Up to date studies still struggle {{with the issue of}} preprocessing the fundus images, mainly {{due to the lack of}} literature reviews and comparative studies. Furthermore, available methods are not being evaluated on large benchmark publicly-available datasets. The paper discusses three major preprocessing methodologies described in literature (Mask Generation, Illumination Equalization, and <b>Color</b> <b>Normalization),</b> and their effect on detecting Retinal Anatomy. In each methodology, a comparative performance measure based on proposed appropriate metrics is accomplished among available methods, using two publicly-available fundus datasets. In addition, the paper proposed the comprehensive normalization method which recorded acceptable results when applied for <b>color</b> <b>normalization...</b>|$|E
40|$|This paper {{presents}} {{the concept of}} <b>color</b> space <b>normalization</b> (CSN) and two CSN techniques, i. e., the within-color-component normalization technique (CSN-I) and the across-color-component normalization technique (CSN-II), for enhancing the discriminating power of color spaces for face recognition. Different color spaces usually display different discriminating power, and our experiments {{on a large scale}} face recognition grand challenge (FRGC) problem reveal that the RGB and XYZ color spaces are weaker than the I 1 I 2 I 3, YUV, YIQ, and LSLM color spaces for face recognition. We therefore apply our CSN techniques to normalize the weak color spaces, such as the RGB and the XYZ color spaces, the three hybrid color spaces XGB, YRB and ZRG, and 10 randomly generated color spaces. Experiments using the most challenging FRGC version 2 Experiment 4 with 12, 776 training images, 16, 028 controlled target images, and 8, 014 uncontrolled query images, show that the proposed CSN techniques can significantly and consistently improve the discriminating power of the weak color spaces. Specifically, the normalized RGB, XYZ, XGB, and ZRG color spaces are more effective than or as effective as the I 1 I 2 I 3, YUV, YIQ and LSLM color spaces for face recognition. The additional experiments using the AR database validate the generalization of the proposed CSN techniques. We finally explain why the CSN techniques can improve the recognition performance of color spaces from the color component correlation point of view. Department of Computin...|$|R
40|$|This thesis {{addresses}} {{the problem of}} image-based logotype detection and recognition. A new algorithm for logotype detection in images of cars is proposed. In the first stage, the algorithm localizes all maximally-stable extremal regions as candidates of logotype parts. In the next stage, the regions are combined to create logotype candidates, which are encoded by histograms of gradients. A random forest classifier is then used to verify the candidate regions as being logotypes or not and simultaneously classify them into the type of the logotype. In addition, improvements to basic algorithm are proposed. The improvements {{include the use of}} alternative <b>color</b> spaces, geometric <b>normalization</b> and use of the car license plate location to form the logotype position prior. An annotated dataset with photographs of vehicles of twenty different makes was prepared for evaluation of the algorithm. The algorithm was able to correctly localize and recognize over 70 % of car logotypes at a very low false positive rate. Despite the fact that we focus on car logotype detection, the algorithm can be easily extended to detection of arbitrary logotypes or objects that do not violate assumptions we impose on the logotype appearance...|$|R
40|$|Abstract Background Accurate {{characterization}} of complex plant phenotypes {{is critical to}} assigning biological functions to genes through forward or reverse genetics. It can also be vital in determining {{the effect of a}} treatment, genotype, or environmental condition on plant growth or susceptibility to insects or pathogens. Although techniques for characterizing complex phenotypes have been developed, most are not cost effective or are too imprecise or subjective to reliably differentiate subtler differences in complex traits like growth, color change, or disease resistance. Results We designed an inexpensive imaging protocol that facilitates automatic quantification of two-dimensional visual phenotypes using computer vision and image processing algorithms applied to standard digital images. The protocol allows for non-destructive imaging of plants in the laboratory and field and can be used in suboptimal imaging conditions due to automated <b>color</b> and scale <b>normalization.</b> We designed the web-based tool PhenoPhyte for processing images adhering to this protocol and demonstrate its ability to measure a variety of two-dimensional traits (such as growth, leaf area, and herbivory) using images from several species (Arabidopsis thaliana and Brassica rapa). We then provide a more complicated example for measuring disease resistance of Zea mays to Southern Leaf Blight. Conclusions PhenoPhyte is a new cost-effective web-application for semi-automated quantification of two-dimensional traits from digital imagery using an easy imaging protocol. This tool’s usefulness is demonstrated for a variety of traits in multiple species. We show that digital phenotyping can reduce human subjectivity in trait quantification, thereby increasing accuracy and improving precision, which are crucial for differentiating and quantifying subtle phenotypic variation and understanding gene function and/or treatment effects. </p...|$|R
40|$|Introduction: Sinusitis {{is one of}} {{the most}} common chronic illnesses. Computed {{tomography}} is the most common imaging method in sinusitis detection. Objectives: The main purpose of this study is to determine the diagnostic usage of NIR imaging in maxillary sinusitis. It is also determined which feature set produces the most efficient classification results. In addition, it is investigated whether the <b>color</b> <b>normalization</b> of the NIR images affects on the results. Results: Histogram mean, texture inertia, and texture entropy are the most efficient features in data discrimination. The best sensitivity in maxillary sinusitis detection is 76 % produced by using asymmetry indicator values of histogram mean feature extracted from the original images. In addition, the discrimination functionality of the selected feature set is degraded by <b>color</b> <b>normalization.</b> Methods: After the NIR images are prepared, their regions of interest (ROI) are selected manually. Then several features are extracted from the images. The values are used to measure a feature-based asymmetry indicator according to the left and right maxillary sinuses in each image. Also, the images of test class (test set) can be classified by having the range of the asymmetry indicator for control and sever images (train set). The classification correctness metrics are calculated to evaluate the diagnostic role of NIR images in sinusitis disease. Conclusion: It is possible to detect sinusitis using NIR imaging with the sensitivity of 76 %. The most effective feature for maxillary sinusitis detection is histogram mean feature. <b>Color</b> <b>normalization</b> is not recommended to be applied on the images...|$|E
40|$|We {{propose a}} novel {{approach}} to retrieve similar images from image databases that works {{in the presence of}} significant illumination variations. The most common method to compensate for illumination changes is to perform <b>color</b> <b>normalization.</b> The existing approaches to <b>color</b> <b>normalization</b> tend to destroy image content in that they map distinct color values to identical color values in the transformed color space. From the mathematical point of view, the normalization transformation is not reversible. In this paper we propose to use a reversible illumination normalization transformation. Thus, we are able to compensate for illumination changes without any reduction of content information. Since natural illumination changes affect different parts of images in different amounts, we apply our transformation locally to sub-images. Basic idea is to divide an image into sub-images, normalize each one separately, and then project it to an n-dimensional reduced space using principal component analysis. This process yields a normalized texture representation as a set of n-vectors. Finding similar images is now reduced to computing distances between sets of n-vectors. Results were compared with a leading image retrieval system...|$|E
30|$|More specifically, {{we first}} apply a <b>color</b> <b>normalization</b> method [28] {{to reduce the}} {{illumination}} variations across frames. Pedestrian detector [9] is then applied at every frame. To reduce false alarms from the detector, given camera pose information read from the sensors, we further remove false alarms of detections using a prior on human heights. The probability of linking newly detected response to the existing trajectory is defined according to the appearance affinity, position affinity, and size affinity [23]. We only track the target we tagged at the first frame here.|$|E
40|$|The {{concept of}} "Isolated Horizon" has been {{recently}} {{used to provide}} a full Hamiltonian treatment of black holes. It has been applied successfully to the cases of non-rotating, non-distorted black holes in Einstein Vacuum, Einstein-Maxwell and Einstein-Maxwell-Dilaton Theories. In this note, it is investigated {{the extent to which}} the framework can be generalized to the case of non-Abelian gauge theories where `hairy black holes' are known to exist. It is found that this extension is indeed possible, despite the fact that in general, there is no `canonical normalization' yielding a preferred Horizon Mass. In particular the zeroth and first laws are established for all <b>normalizations.</b> <b>Colored</b> static spherically symmetric black hole solutions to the Einstein-Yang-Mills equations are considered from this perspective. A canonical formula for the Horizon Mass of such black holes is found. This analysis is used to obtain nontrivial relations between the masses of the colored black holes and the regular solitonic solutions in Einstein-Yang-Mills theory. A general testing bed for the instability of hairy black holes in general non-linear theories is suggested. As an example, the embedded Abelian magnetic solutions are considered. It is shown that, within this framework, the total energy is also positive and thus, the solutions are potentially unstable. Finally, it is discussed which elements would be needed to place the Isolated Horizons framework for Einstein-Yang-Mills theory in the same footing as the previously analyzed cases. Motivated by these considerations and using the fact that the Isolated Horizons framework seems to be the appropriate language to state uniqueness and completeness conjectures for the EYM equations [...] in terms of the horizon charges [...] , two such conjectures are put forward. Comment: 24 pages, 3 figures, Revtex fil...|$|R
40|$|Abstract. This article {{introduces}} a generalization of the discrete optimal transport, with ap-plications to color image manipulations. This new formulation includes a relaxation {{of the mass}} conservation constraint and a regularization term. These two features are crucial for image pro-cessing tasks, which necessitate {{to take into account}} families of multimodal histograms, with large mass variation across modes. The corresponding relaxed and regularized transportation problem is the solution of a convex optimization problem. Depending on the regularization used, this mini-mization can be solved using standard linear programming methods or first order proximal splitting schemes. The resulting transportation plan {{can be used as a}} color transfer map, which is robust to mass variation across images color palettes. Furthermore, the regularization of the transport plan helps to remove colorization artifacts due to noise amplification. We also extend this framework to the computation of barycenters of distributions. The barycenter is the solution of an optimization problem, which is separately convex with respect to the barycenter and the transportation plans, but not jointly convex. A block coordinate descent scheme converges to a stationary point of the energy. We show that the resulting algorithm can be used for <b>color</b> <b>normalization</b> across several images. The relaxed and regularized barycenter defines a common color palette for those images. Applying color transfer toward this average palette performs a <b>color</b> <b>normalization</b> of the input images. 1. Introduction. ...|$|E
40|$|This paper {{presents}} an effective <b>color</b> <b>normalization</b> method for thin blood film images of peripheral blood specimens. Thin blood film images {{can easily be}} separated to foreground (cell) and background (plasma) parts. The color of the plasma region is used to estimate and reduce the differences arising from different illumination conditions. A second stage nor- malization based on the database-gray world algorithm trans- forms {{the color of the}} foreground objects to match a reference color character. The quantitative experiments demonstrate the effectiveness of the method and its advantages against two other general purpose color correction methods: simple gray world and Retinex...|$|E
40|$|Important {{to the use}} of multitemporal Landsat MSS {{data for}} earth {{resources}} monitoring, such as agricultural inventories, is the ability to minimize the effects of varying atmospheric and satellite viewing conditions, while extracting physically meaningful features from the data. In general, the approaches to the preprocessing problem have been derived from either physical or statistical models. This paper compares three proposed algorithms; XSTAR haze correction, <b>Color</b> <b>Normalization,</b> and Multiple Acquisition Mean Level Adjustment. These techniques represent physical, statistical, and hybrid physical-statistical models, respectively. The comparisons are made in the context of three feature extraction techniques; the Tasseled Cap, the Cate Color Cube. and Normalized Difference...|$|E
40|$|For a large {{collection}} of satellite images,because {{of the differences}} in season,light,atmospheric conditions and so on,adjacent satellite images may have different color and there will be obviously "seam-line" in mosaic satellite image. In this paper,a method of satellite image <b>color</b> <b>normalization</b> was proposed,it was implemented to correct the color of image automatically based on better color low resolution satellite imagery which covered the mapping area. We selected a large collection and long time interval GF- 1 satellite images as experiment data,results show that the mosaic image have a good visual effect,the color transition of two images smoothly,statistical indicators of overlap area obviously improved,all of those verified the validity and reliability of the algorithm...|$|E
40|$|Abstract During {{endoscopic}} operations {{the surgeon}} works without direct visual contact {{to the operation}} area. The image of the operation situs is displayed on a monitor. Currently, only hardware based image enhancement methods are used (e. g., white balance) and often only once {{at the beginning of}} an operation. In this contribution we describe a system for real-time endoscopic image enhancement: a typical video-endoscopic system was extended by a computer and a second monitor. Thus the enhanced and the original image can be displayed at the same time. The implemented image enhancement methods (temporal filtering, undis-tortion and <b>color</b> <b>normalization)</b> were evaluated by 14 surgeons and the results showed that the enhanced images were preferred. The system was already used during a real operation. ...|$|E
40|$|We {{present a}} fast object {{recognition}} system coding shape by viewpoint invariant geometric relations and appearance information. In our advanced industrial work-cell, {{the system can}} observe the work space of the robot by three pairs of Kinect and stereo cameras allowing for reliable and complete object information. From these sensors, we derive global viewpoint invariant shape features and robust color features making use of <b>color</b> <b>normalization</b> techniques. We show that in such a set-up, our system can achieve high performance already with a very low number of training samples, which is crucial for user acceptance and {{that the use of}} multiple views is crucial for performance. This indicates that our approach can be used in controlled but realistic industrial contexts that require—besides high reliability—fast processing and an intuitive and easy use at the end-user side. European UnionDanish Council for Strategic Researc...|$|E
40|$|Retinal exudates {{are among}} the {{preliminary}} signs of diabetic retinopathy, {{a major cause of}} vision loss in diabetic patients. Correct and efficient screening of exudates is very expensive in professional time and may cause human error. Nowadays, the digital retinal image is frequently used to follow-up and diagnoses eye diseases. Therefore, the retinal image is crucial and essential for experts to detect exudates. Unfortunately, it is a normal situation that retinal images in Thailand are poor quality images. In this paper, we present a series of experiments on feature selection and exudates classification using the support vector machine classifiers. The retinal images are segmented following key preprocessing steps, i. e., <b>color</b> <b>normalization,</b> contrast enhancement, noise removal and color space selection. On data sets of poor quality images, sensitivity, specificity and accuracy is 94. 46 %, 89. 52 % and 92. 14 %, respectively...|$|E
40|$|Dermoscopic skin {{images are}} often {{obtained}} with different imaging devices, under varying acquisition conditions. In this work, instead {{of attempting to}} perform intensity and <b>color</b> <b>normalization,</b> we propose to leverage computational color constancy techniques to build an artificial data augmentation technique suitable {{for this kind of}} images. Specifically, we apply the shades of gray color constancy technique to color-normalize the entire training set of images, while retaining the estimated illuminants. We then draw one sample from the distribution of training set illuminants and apply it on the normalized image. We employ this technique for training two deep convolutional neural networks for the tasks of skin lesion segmentation and skin lesion classification, {{in the context of the}} ISIC 2017 challenge and without using any external dermatologic image set. Our results on the validation set are promising, and will be supplemented with extended results on the hidden test set when available...|$|E
