3|806|Public
50|$|Presently {{there are}} English and Spanish {{versions}} of CAP with French and Portuguese versions planned in the future. Each {{segment of the}} course contains <b>close</b> <b>captioning</b> to facilitate learning styles and clarity of the material presented.|$|E
50|$|Ebony and Ivory (voiced by Liza Del Mundo and Lori Alan): An interracial lesbian couple, {{even more}} hyper-PC than Kirsten and Dana. They named their baby Echinacea (spelled as Echanasia in <b>close</b> <b>captioning),</b> {{and refuse to}} learn what gender she/he is so that she/he can {{discover}} that for her/himself.|$|E
30|$|Although the {{concepts}} of inclusion and accessibility have been used within the disability community in connection with people with disabilities, these practices also benefit people without disabilities. For example, the accessibility shift {{to the use of}} curb-cuts in the United States on pedestrian sidewalks at intersections not only benefits people using wheelchairs, but also elderly people with balance problems and mothers pushing strollers. Similarly, the inclusion shift in the United States to provide <b>close</b> <b>captioning</b> on television not only benefits Deaf people but those who are learning English as a second language or those who would rather watch sports without narration. Within the context of disaster risk reduction, the constructs of accessibility and inclusion can be beneficial in similar ways. Evacuation procedures for people with mobility impairments, for example, will benefit both people who use wheelchairs and people who cannot walk long distances. Inclusive procedures, for example, such as considering the diverse dietary needs of people in a shelter, will benefit people with diabetes as well as people following religious dietary laws.|$|E
2500|$|This new <b>closed</b> <b>captioning</b> {{workflow}} {{known as}} e-Captioning involves making a proxy video from the non-linear system to import into a third-party non-linear <b>closed</b> <b>captioning</b> software. Once the <b>closed</b> <b>captioning</b> software project is completed, it must export a <b>closed</b> <b>caption</b> file {{compatible with the}} non-linear editing system. In the case of Final Cut Pro 7, three different file formats can be accepted: a [...]SCC file (Scenarist <b>Closed</b> <b>Caption</b> file) for Standard Definition video, a QuickTime 608 <b>closed</b> <b>caption</b> track (a special 608 coded track in the [...]mov file wrapper) for standard-definition video, and finally a QuickTime 708 <b>closed</b> <b>caption</b> track (a special 708 coded track in the [...]mov file wrapper) for high-definition video output.|$|R
25|$|In 2010, Vegas Pro, the {{professional}} non-linear editor, was updated to support importing, editing, and delivering CEA-608 <b>closed</b> <b>captions.</b> Vegas Pro 10, released on October 11, 2010, added several enhancements to the <b>closed</b> <b>captioning</b> support. TV-like CEA-608 <b>closed</b> <b>captioning</b> {{can now be}} displayed as an overlay when played back in the Preview and Trimmer windows, {{making it easy to}} check placement, edits, and timing of CC information. CEA708 style <b>Closed</b> <b>Captioning</b> is automatically created when the CEA-608 data is created. Line 21 <b>closed</b> <b>captioning</b> is now supported, as well as HD-SDI <b>closed</b> <b>captioning</b> capture and print from AJA and Blackmagic Design cards. Line 21 support provides a workflow for existing legacy media. Other improvements include increased support for multiple <b>closed</b> <b>captioning</b> file types, as well as the ability to export <b>closed</b> <b>caption</b> data for DVD Architect, YouTube, RealPlayer, QuickTime, and Windows Media Player.|$|R
5000|$|<b>Closed</b> <b>captioning</b> support {{provides}} <b>closed</b> <b>captioning</b> for {{the deaf}} and hard of hearing ...|$|R
2500|$|Reid Kimball, a game {{designer}} who is hearing impaired, {{is attempting to}} educate game developers about <b>closed</b> <b>captioning</b> for games. Reid started the [...] group to <b>closed</b> <b>caption</b> games {{and serve as a}} research and development team to aid the industry. Kimball designed the Dynamic <b>Closed</b> <b>Captioning</b> system, writes articles and speaks at developer conferences. Games's first <b>closed</b> <b>captioning</b> project called Doom3 was nominated for an award as [...] for IGDA's Choice Awards 2006 show.|$|R
5000|$|ISMA <b>Closed</b> <b>Captioning</b> - specifying how {{to carry}} <b>closed</b> <b>caption</b> (line 21) data {{as a third}} stream over an IP network ...|$|R
50|$|<b>Closed</b> <b>Captioning</b> and Video Description {{should be}} {{provided}} as this is already a requirement that video-on-demand services must be offered with <b>closed</b> <b>captions.</b>|$|R
5000|$|He wrote {{three books}} about <b>closed</b> <b>captioning,</b> most notably The <b>Closed</b> <b>Captioning</b> Handbook, {{published}} [...] by Focal Press, then an imprint of Elsevier.|$|R
50|$|Reid Kimball, a game {{designer}} who is hearing impaired, {{is attempting to}} educate game developers about <b>closed</b> <b>captioning</b> for games. Reid started the Games group to <b>closed</b> <b>caption</b> games {{and serve as a}} research and development team to aid the industry. Kimball designed the Dynamic <b>Closed</b> <b>Captioning</b> system, writes articles and speaks at developer conferences. GamesCC's first <b>closed</b> <b>captioning</b> project called Doom3CC was nominated for an award as Best Doom3 Mod of the Year for IGDA's Choice Awards 2006 show.|$|R
50|$|<b>Closed</b> <b>captioning</b> {{was first}} {{demonstrated}} at the First National Conference on Television for the Hearing Impaired in Nashville, Tennessee in1971. A second demonstration of <b>closed</b> <b>captioning</b> {{was held at}} Gallaudet College (now Gallaudet University) on February 15, 1972, where ABC and the National Bureau of Standards demonstrated <b>closed</b> <b>captions</b> embedded within a normal broadcast of The Mod Squad.|$|R
40|$|Time lagging {{problem is}} needed to be solved when using <b>closed</b> <b>caption</b> {{as a source of}} {{features}} in video indexing. One of solution is aligning <b>closed</b> <b>caption</b> to transcripts then take the time code from transcripts as new references for <b>closed</b> <b>caption.</b> This paper describes a work using limited resources to generate decent alignment results. 1...|$|R
50|$|Poynter’s {{main focus}} is {{to fight for}} a higher {{quantity}} and quality of <b>Closed</b> <b>Captioning</b> on YouTube videos. According to Poynter, YouTube’s automatically-generated <b>Closed</b> <b>Captions</b> are often inaccurate, do not make sense {{in the context of the}} video, and/or contain profanity or inappropriate words. Because of this, Poynter encourages YouTube creators to manually enter their own <b>Closed</b> <b>Captions.</b>|$|R
25|$|Windows Media Video {{can support}} <b>closed</b> <b>captions</b> for both {{video on demand}} {{streaming}} or live streaming scenarios. Typically Windows Media captions support the SAMI file format but can also carry embedded <b>closed</b> <b>caption</b> data.|$|R
2500|$|Other {{non-linear}} editing systems indirectly support <b>closed</b> <b>captioning</b> only in Standard Definition line-21. Video files on the editing timeline must be composited with a line-21 VBI graphic layer {{known in the}} industry as a [...] "blackmovie" [...] with <b>closed</b> <b>caption</b> data. [...] Alternately, video editors working with the DV25 and DV50 firewire workflows must encode their DV [...]avi or [...]mov file with VAUX data which includes CEA-608 <b>closed</b> <b>caption</b> data.|$|R
5000|$|Prior to {{the advent}} of e-Captioning, <b>closed</b> <b>captioning</b> was added to a video using a linear deck-to-deck process, which {{required}} {{the use of a}} physical master video tape, two tape decks (play and record), and a hardware <b>closed</b> <b>captioning</b> encoder. [...] Since this equipment is very expensive, it was not practical for most video production facilities to own it on site. Instead, video editors had to first output a video to tape, then mail the tape to a special <b>closed</b> <b>captioning</b> facility. In the process, a second video tape with <b>closed</b> <b>captions</b> would be created, incurring generation loss. [...] Finally, the tape would need to be mailed to its final destination. If the video later required edits or changes, then the producer would have to ship another master tape to the <b>closed</b> <b>captioning</b> facility, repeating the process and possibly incurring additional fees.|$|R
50|$|VITAC {{has been}} {{continuously}} providing <b>closed</b> <b>captioning</b> services since 1986. In 2000, VITAC {{was sold to}} Word Wave, Inc. In 2006, Word Wave, Inc. was acquired by Merrill Corporation. In August 2012, VITAC acquired <b>Closed</b> <b>Captioning</b> Services.|$|R
30|$|The <b>closed</b> <b>caption</b> {{extraction}} modules {{are used}} to convert the <b>closed</b> <b>caption</b> input streams into a sequence of words in BP. The synchronization module is used to synchronize the <b>closed</b> <b>caption</b> input and the LIBRAS window output. As mentioned earlier, it extracts the reference clock from the input and uses it to generate the timestamps for the signs presentation. The machine translation and encoding modules will be detailed in the next subsections.|$|R
5000|$|... e-Captioning is a {{workflow}} {{for adding}} <b>closed</b> <b>captioning</b> data to video tapes and files. This process uses software to encode the <b>closed</b> <b>captioning</b> data into a video, {{instead of the}} dedicated <b>closed</b> <b>caption</b> hardware encoders that were previously required. Originally, e-Captioning could be done only for web based new media formats such as Windows Media, Real Video, QuickTime, and Flash. However, e-Captioning is now available to TV Broadcast facilities for tapeless workflows.|$|R
2500|$|... 1971. A second {{demonstration}} of <b>closed</b> <b>captioning</b> {{was held at}} Gallaudet College (now Gallaudet University) on February 15, 1972, where ABC and the National Bureau of Standards demonstrated <b>closed</b> <b>captions</b> embedded within a normal broadcast of The Mod Squad.|$|R
50|$|<b>Closed</b> <b>captioning</b> on television.|$|R
50|$|XDS {{uses the}} same line in the {{vertical}} blanking interval as <b>closed</b> <b>captioning</b> (NTSC line 21), and shares the available second video field bandwidth with the <b>closed</b> <b>captioning</b> channels CC3 and CC4, and with the text channels TXT3 and TXT4.|$|R
30|$|Synchronization between <b>closed</b> <b>caption</b> input in BP and the LIBRAS window {{output is}} {{performed}} {{by using the}} axis-based synchronization model [5]. This model defines synchronization points that are inserted in the stream using timestamps based on a global timer. In this case, the global timer is the reference clock of the <b>closed</b> <b>caption</b> input stream. This clock is extracted from <b>closed</b> <b>caption</b> and is used to generate the presentation timestamps for the signs in the LIBRAS window.|$|R
50|$|In 1989, WMAQ-TV {{became the}} first station in the Chicago {{metropolitan}} area to adopt its real-time <b>closed</b> <b>captioning</b> for the hearing impaired {{in all of its}} newscasts; five years later in 1994, the <b>closed</b> <b>captioning</b> service was later added to the station's morning newscast.|$|R
5|$|The HDMI {{standard}} {{was not designed}} to pass <b>closed</b> <b>caption</b> data (for example, subtitles) to the television for decoding. As such, any <b>closed</b> <b>caption</b> stream must be decoded and included as an image in the video stream(s) prior to transmission over an HDMI cable to be viewed on the DTV. This limits the caption style (even for digital captions) to only that decoded at the source prior to HDMI transmission. This also prevents <b>closed</b> <b>captions</b> when transmission over HDMI is required for upconversion. For example, a DVD player that sends an upscaled 720p/1080i format via HDMI to an HDTV has no way to pass <b>Closed</b> <b>Captioning</b> data so that the HDTV can decode it, {{as there is no}} line 21 VBI in that format.|$|R
2500|$|In mid-2009, Apple {{released}} Final Cut Pro version 7 {{and began}} support for inserting <b>closed</b> <b>caption</b> data into SD and HD tape masters via firewire and compatible video capture cards. [...] Up until this time, {{it was not}} possible for video editors to insert caption data with both CEA-608 and CEA-708 to their tape masters. The typical workflow included first printing the SD or HD video to a tape and sending it to a professional <b>closed</b> <b>caption</b> service company that had a stand-alone <b>closed</b> <b>caption</b> hardware encoder.|$|R
50|$|There {{have also}} been a few local {{stations}} that have broadcast programming in American Sign Language, accompanied by English <b>closed</b> <b>captioning.</b> Prior {{to the development of}} <b>closed</b> <b>captioning,</b> it was not uncommon for some public television programs to incorporate ASL translations by an on-screen interpreter. An interpreter may still be utilized for the deaf and hard-of-hearing community for on-air emergency broadcasts (such as severe weather alerts given by local governments) as well as televised press conferences by local and state government officials accompanied by <b>closed</b> <b>captioning.</b>|$|R
5000|$|In mid-2009, Apple {{released}} Final Cut Pro version 7 {{and began}} support for inserting <b>closed</b> <b>caption</b> data into SD and HD tape masters via firewire and compatible video capture cards. [...] Up until this time, {{it was not}} possible for video editors to insert caption data with both CEA-608 and CEA-708 to their tape masters. The typical workflow included first printing the SD or HD video to a tape and sending it to a professional <b>closed</b> <b>caption</b> service company that had a stand-alone <b>closed</b> <b>caption</b> hardware encoder.|$|R
30|$|The <b>closed</b> <b>caption</b> {{extraction}} module {{was developed}} based on definitions of ABNT NBR 15606 - 1 [1]. This module receives an MPEG- 2 TS streaming and extracts BP sentences and synchronization information (i.e., timestamps) from <b>closed</b> <b>captions</b> packets. These timestamps are inserted into DSM-CC stream events.|$|R
50|$|The show {{currently}} {{runs for}} reruns in 2007 and airs every Weekend mornings on ANT1 {{and has also}} Greek subtitles or <b>closed</b> <b>captioning</b> for the hearing umpaired, unlike most English programs, {{it is one of}} the few Greek speaking shows that offers <b>closed</b> <b>captioning</b> probably different.|$|R
5000|$|... #Subtitle level 3: <b>Closed</b> <b>captioning</b> {{and related}} {{technologies}} ...|$|R
5000|$|... #Subtitle level 3: Technical {{development}} of <b>closed</b> <b>captioning</b> ...|$|R
40|$|We {{describe}} {{an approach to}} Machine Translation of transcribed speech, as found in <b>closed</b> <b>captions.</b> We discuss how the colloquial nature and input format peculiarities of <b>closed</b> <b>captions</b> are dealt with in a pre-processing pipeline that prepares the input for effective processing by a core MT system. In particular, we describe components for proper name recognition and input segmentation. We evaluate the contribution of such modules to the system performance. The described methods have been implemented on an MT system for translating English <b>closed</b> <b>captions</b> to Spanish and Portuguese...|$|R
2500|$|Special {{effort has}} been made to build {{accessibility}} features into digital projection systems (see digital cinema). Through SMPTE, standards now exist that dictate how open and <b>closed</b> <b>captions,</b> as well as hearing-impaired and visually impaired narrative audio, are packaged {{with the rest of the}} digital movie. This eliminates the proprietary caption distributions required for film, and the associated royalties. SMPTE has also standardized the communication of <b>closed</b> <b>caption</b> content between the digital cinema server and 3rd-party <b>closed</b> <b>caption</b> systems (the CSP/RPL protocol). As a result, new, competitive <b>closed</b> <b>caption</b> systems for digital cinema are now emerging that will work with any standards-compliant digital cinema server. These newer <b>closed</b> <b>caption</b> devices include cupholder-mounted electronic displays and wireless glasses which display caption text in front of the wearer's eyes. [...] Bridge devices are also available to enable the use of Rear Window systems. As of mid-2010, the remaining challenge to the wide introduction of accessibility in digital cinema is the industry-wide transition to SMPTE DCP, the standardized packaging method for very high quality, secure distribution of digital movies.|$|R
50|$|A SAMI file {{provides}} <b>closed</b> <b>caption</b> {{support for}} multimedia formats. Generally, a multimedia file (such as a video or a sound file) {{is played by}} a media player such as Windows Media Player. Media players that support <b>closed</b> <b>captioning</b> and SAMI format may display {{the contents of the}} included SAMI file.|$|R
