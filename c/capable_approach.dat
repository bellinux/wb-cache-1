15|811|Public
30|$|Fishburn (1970) {{is a clear}} {{evidence}} that a new proof can open up a new research direction. It is also reasonable {{to believe that a}} more <b>capable</b> <b>approach</b> can prove more general results; see e.g. Eliaz (2004) and Yu (2015).|$|E
40|$|In this {{abstract}} {{we propose}} an integrated {{strategy for the}} geophysical exploration of Mars that we believe represents the fastest, most cost-effective, and technically <b>capable</b> <b>approach</b> to identifying the state and distribution of subsurface water. Additional information is contained in the original extended abstract...|$|E
40|$|Today's {{vehicles}} are more innovative and connected {{than ever and}} will continue to be so as innovation in the automotive industry keeps moving forward. With this connectivity, remote vehicle hacking becomes a greater threat as it has been proven as a <b>capable</b> <b>approach</b> of altering the functions of a vehicle in motion. This threat creates a heightened concern in the software security development of vehicles. This study will attempt to introduce an additional platform, to the already used in-house penetration testing, for detecting software security vulnerabilities through a hackathon in collaboration with the HoliSec project conducted by the Viktoria Institute. Through a qualitative design science approach and completion of two regulative cycle iterations, artifacts and templates for setting up a hackathon for software security vulnerability detection in the automotive domain were designed, constructed and evaluated...|$|E
40|$|Services and {{applications}} in pervasive environments must adapt to changes {{occurring in the}} surrounding environment and {{meet the needs of}} mobile users according to the users' changing situations. Existing context-aware architectures and middleware are faced with two problems. First, is their weakness in expressing complex inter-context relationships, stemming from use of less <b>capable</b> <b>approaches</b> to modeling contextual knowledge. Secondly, context dissemination methods used by these systems result in network flooding, unrestricted access to private context information, and the inability of consumers to limit or personalize received context. This thesis provides an ontology-based context-level negotiation protocol along with a context-aware system architecture. The protocol permits context consumers to personalize their received context information through negotiations with context providers. The thesis illustrates the use of this negotiation protocol through the design and implementation of a context-aware system architecture capable of acquiring, modeling, reasoning and disseminating context information through ontologies...|$|R
40|$|The {{analytic}} {{signal is}} one of the most <b>capable</b> <b>approaches</b> in one-dimensional signal processing. Two-dimensional signal theory suffers from the absence of an isotropic extension of the analytic signal. Accepting the fact that there is no odd filter with isotropic energy in higher dimensions, one tried to circumvent this drawback using the onedimensional quadrature filters with respect to several preference directions. Disadvantages of these methods are an increased complexity, the loss of linearity and a lot of different heuristic approaches. In this paper we present a filter that is isotropic and odd, which means that the whole theory of local phase and amplitude can directly be applied to images. Additionally, a third local property is obtained which is the local orientation. The advantages of our approach are demonstrated by a stable orientation detection algorithm and an adaption of the phase congruency method which yields a superior edge detector with very low complexity...|$|R
40|$|<b>Capable</b> <b>approaches</b> {{to assess}} the likely future of lands on various spatial scales, from global to local are required. The aim of {{integration}} was formulated 10 {{years ago in the}} LUCC Science Plan. An effort was made to structure 30 land use and land cover change models many out of them originating from Asia according to their spatial and temporal range as a first attempt to structure individual models or case studies. A simple scale time matrix proposed 9 classes from long range and long term to short range and short term. Models within the same classes are considered for comparative studies and thereby provide more information than for the purpose they were written for. However, when coming to the more detailed level, even “near ” models from time scale evaluation are far away from to be integrated. They are separated and LUCC community should develop simple modelling standards to make case studies comparable {{to each other in the}} future...|$|R
40|$|Abstract—Predicting {{turn and}} stop {{maneuvers}} of potentially errant drivers {{is a basic}} requirement for advanced driver assistance systems for urban intersections. Previous work has shown that an early estimate of the driver’s intent can be inferred by evaluating the vehicle’s speed during the intersection approach. In {{the presence of a}} preceding vehicle, however, the velocity profile might be dictated by car-following behavior rather than by the need to slow down before doing a left or right turn. To infer the driver’s intent under such circumstances, a simple, real-time <b>capable</b> <b>approach</b> using a parametric model to represent both car-following and turning behavior is proposed. The performance of two alternative parameterizations based on observations at an individual intersection and a generic curvature-based model is evaluated in combination with two different Bayes net classification algorithms. In addition, the driver model is shown to be capable of predicting the future trajectory of the vehicle...|$|E
40|$|In this paper, {{we present}} a Gaussian mixture model based {{approach}} to capture the spatial characteristics of any target signal in a sensor network, and further propose a temporallyadaptive variant of the approach for dynamic multiple target tracking under changing environments, {{with the presence of}} both significant background event noises and a large portion of outlying sensor readings. The target position is estimated by adopting the mean-shift optimization to discriminate the target signals from the background noises. Our mixture model based algorithm is capable of fusing multivariate real-valued sensor measurements and its probability nature shows fault tolerance and robustness in noisy sensing environments. This consideration is practical as in real world applications, sensor readings are multi-modal and may contain errors. The simulation study validates our design and the results indicate that our mixture model based algorithm is an effective and <b>capable</b> <b>approach</b> for the two most typical target signal models under consideration. Desirable quantitative target tracking results are also achieved through extensive evaluations under challenging background conditions...|$|E
40|$|Dense 3 D data as {{delivered}} by stereo vision systems, modern laser scanners or timeof-flight cameras such as PMD {{is a key}} element for 3 D scene understanding. Real-time high-level vision systems require a compact and explicit representation of that data which allows for efficient attention control, object detection, and reasoning. Because man-made environments are dominated by planar horizontal and vertical surfaces we approximate the three dimensional scenery by using sets of thin planar rectangles called Stixels. This medium level representation serves as input for further processing steps and applications. Using this novel representation those are not required to process the large amounts of raw 3 D data individually. This reconstruction is addressed by means of a unified probabilistic approach. Dynamic programming allows to incorporate real-world constraints such as perspective ordering and delivers an optimal segmentation with respect to freespace and obstacle information. We present results for both stereo vision data and laser data. The real-time <b>capable</b> <b>approach</b> {{can also be used to}} fuse the information of multiple data sources. ...|$|E
40|$|A generically {{applicable}} hybrid multiuser detector (MUD) {{concept is}} proposed by appropriately activating different MUDs in consecutive turbo iterations {{based on the}} mutual information (MI) gain. It is demonstrated that the proposed hybrid MUD is <b>capable</b> of <b>approaching</b> the optimal Bayesian MUD's performance despite its reduced complexity, which is at a modestly increased complexity in comparison {{with that of the}} suboptimum soft interference cancellation (SoIC) MU...|$|R
50|$|When Mercedes {{canceled}} its racing {{program after}} the Le Mans disaster, the hybrid project was shelved. Company design chief Rudolf Uhlenhaut, architect {{of both the}} 300 SLR racer and the hybrids, appropriated one of the leftover mules as his personal driver. <b>Capable</b> of <b>approaching</b> 290 km/h (180 mph), the Uhlenhaut Coupé was {{far and away the}} fastest road car in the world in its day.|$|R
5000|$|Later in the novel, Ortega {{is quoted}} as saying: [...] "The latest {{development}} is the mass-conversion ship, such as the Mayflower, {{and it may be}} the final development [...] - [...] a mass-conversion ship is theoretically <b>capable</b> of <b>approaching</b> the speed of light."The scientific advance that permits this efficient conversion of mass to energy is called the [...] "Kilgore equations" [...] (likely a reference to Kilgore Trout).|$|R
40|$|This paper {{presents}} an analytic network process (ANP) experiment for demolition plan evaluation. An experimental {{case study on}} the Warren Farm Bridge demolition project is used to demonstrate the effectiveness of an ANP model to support finding the most appropriate demolition plan. Alternative plans used in the experiment include plans that utilise deliberate collapse, progressive demolition, and deconstruction. The ANP model adopted the same assessment criteria, which were previously used in an analytic hierarchy process (AHP) model for the same evaluation purpose for the case project, {{in order to further}} make a comparison between AHP and ANP models with different evaluation results. Further to the conclusion that ANP is a viable and <b>capable</b> <b>approach</b> to demolition plan evaluation, the experiment provides a notably different result, which matches the demolition plan actually used, on the most appropriate solution for the case project in comparison with the AHP model. This study indicates that further practice oriented research is necessary through case studies and model improvement to further validate ANP's capability to support reliable decision making with regard to its inherent advantage in measuring interrelationships and interactions among evaluation criteria in a multicriteria decision-making (MCDM) model. Department of Building and Real Estat...|$|E
40|$|Since the mid- 1990 's, {{the stated}} {{strategy}} of the Mars Exploration Program has been to Follow the Water. Although this strategy has been widely publicized, its degree of influence [...] and the logic behind its current implementation (as reflected in mission planning, platform and instrument selection, and allocation of spacecraft resources) remains unclear. In response to this concern, we propose an integrated strategy for the post- 2009 exploration of Mars that identifies the scientific objectives, rationale, sequence of missions, and specific investigations, that we believe provides the maximum possible science return by pursuing the most direct, cost-effective, and technically <b>capable</b> <b>approach</b> to following the water. This strategy {{is based on the}} orbital identification, high-resolution surface investigation, and ultimate sampling of the highest priority targets: near-surface liquid water and massive ground ice (potentially associated with the discharge of the outlflow channels or the relic of a former ocean). The analysis of such samples, in conjunction with the data acquired by the necessary precursor investigations (to identify the locations and characterize the environments of the optimum sampling sites), is expected to address a majority of the goals and high priority science objectives identified by MEPAG...|$|E
40|$|The {{major goal}} of a pre-sales phase is to provide {{customers}} with a compelling offer that exactly fits their needs. For its creation not only sales but also requirements engineering activities take place. The latter are needed to translate the customers’ needs to features, to efforts, and eventually to costs. Although this sounds like business as usual, compared to conventional requirements engineering, there are substantial differences: the pre-sales phase entails challenges (e. g., a limited duration, a steadily moving target or the supplier’s pre-investment) having {{a tremendous impact on}} all of these activities. With their conventional approach requirements engineering professionals are doomed to fail. However, an appropriate requirements engineering approach for the pre-sales phase remains to be defined. To address this issue the principal idea is to investigate typical customer engagement types and to conduct a risk analysis revealing the details of the pre-sales phase’s challenges. The results deliver the basis informing the design of a new and <b>capable</b> <b>approach.</b> This article contributes the resulting concept and tools for successful pre-sales requirements engineering. They provide the risk responses and exit criteria to the pre-sales phase’s challenges. The proposed approach even turns analysts into “boxers” when tackling {{one of the most difficult}} pre-sales problems: the moving target...|$|E
40|$|Abstract — A generically {{applicable}} hybrid MultiUser Detector (MUD) {{concept is}} proposed by appropriately activating different MUDs in consecutive turbo iterations {{based on the}} Mutual Information (MI) gain. It is demonstrated that the proposed hybrid MUD is <b>capable</b> of <b>approaching</b> the optimal Bayesian MUD’s performance despite its reduced complexity, which is at a modestly increased complexity in comparison {{to that of the}} suboptimum Soft Interference Cancellation (SoIC) MUD. I...|$|R
50|$|Based on the Mercedes-Benz 300 SLR sport racer of 1955, Uhlenhaut {{created a}} road legal SLR/SL hybrid. <b>Capable</b> of <b>approaching</b> 290 km/h (180 mph), the 300 SLR Uhlenhaut Coupé easily earned the {{reputation}} of being the era's fastest road car. A story circulates that running late for a meeting Uhlenhaut roared up the autobahn from Munich to Stuttgart in just over an hour, a 137 mile/220 km journey that today takes two-and-a-half.|$|R
40|$|Abstract—A generically {{applicable}} hybrid multiuser detector (MUD) {{concept is}} proposed by appropriately activating different MUDs in consecutive turbo iterations {{based on the}} mutual information (MI) gain. It is demonstrated that the proposed hybrid MUD is <b>capable</b> of <b>approaching</b> the optimal Bayesian MUD’s performance despite its reduced complexity, which is at a modestly increased complexity in comparison {{with that of the}} suboptimum soft interference cancellation (SoIC) MUD. Index Terms—EXIT charts, interleave-division multiple-access (IDMA), iterative detector. I...|$|R
40|$|AbstractBackgroundAs the {{population}} ages, {{it is increasingly}} important to test new models of care that improve life quality and decrease health costs. This paper presents the rationale and design for a randomized clinical trial of a novel interdisciplinary program to reduce disability among low income older adults based on a previous pilot trial of the same design showing strong effect. MethodsThe CAPABLE (Community Aging in Place, Advancing Better Living for Elders) trial is a randomized controlled trial in which low income older adults with self-care disability are {{assigned to one of}} two groups: an interdisciplinary team of a nurse, occupational therapist, and handyman to address both personal and environmental risk factors for disability based on participants' functional goals, or an attention control of sedentary activities of choice. Both groups receive up to 10 home visits over 4 months. OutcomesThe primary outcome is decreased disability in self-care (ADL). Secondary outcomes are sustained decrease in self care disability as well as improvement in instrumental ADLS, strength, balance, walking speed, and health care utilization. Careful cost tracking and analysis using intervention data and claims data will enable direct measurement of the cost impact of the <b>CAPABLE</b> <b>approach.</b> CAPABLE has the potential to leverage current health care spending in Medicaid waivers, Accountable Care Organizations and other capitated systems to save the health care system costs as well as improving low income older adults' ability to age at home with improved life quality...|$|E
40|$|Este trabalho prop??e a modelagem Sem??ntica para a constru????o de uma ontologia para o dom??nio da Educa????o a Dist??ncia. Busca na Sem??ntica uma abordagem para representar a descri????o e conceitua????o do dom??nio EAD, partindo do pressuposto de que ?? necess??rio modelar os relacionamentos entre conceitos com base em uma abordagem capaz de ampliar a rede de rela????es. Fundamenta-se na Sem??ntica Lexical (CRUSE, 1986, 2000) e na Sem??ntica de Frames (FILLMORE, 1982), baseando-se nas rela????es paradigm??ticas e sintagm??ticas (SAEED, 2003; CALZOLARI et. al, 2010), levando em conta as rela????es de hipon??mia, sinon??mia e meron??mia, para estabelecer a taxonomia (hierarquia de classes) e pap??is tem??ticos e frames para outros tipos de rela????es. Tomando como corpus manuais de uso do ambiente Moodle, este estudo prop??e a constru????o de uma ontologia com vistas a contribuir com a melhoria dos Ambientes Virtuais de Aprendizagem. O resultado desta investiga????o aponta para a Sem??ntica de Frames como uma poss??vel abordagem para descrever o significado em ontologias. This work proposes the Semantics Modelling for the {{construction}} of an ontology for the Remote Education dominion. It quests in Semantics an approach to represent the description and conceptualization of the EAD dominion, having as a starting point {{that it is necessary to}} model relationships among concepts with base in a <b>capable</b> <b>approach</b> of extending the relations network. Based on Lexical Semantics (CRUSE, 1986, 2000) and on the Frames? Semantics (FILLMORE, 1982), based on the Paradigmatic and Sintagmatic relations (SAEED, 2003; CALZOLARI et. al, 2010), considering relations of hiponomy, synomny, meromny, to establish taxonomy (class hierarchy) and thematic roles and frames for other kind of relations. Takins as corpus Moodle environment usage manuals, this study porposes {{the construction}} of and onthology having in sight a contribution on improving Learning Virtual Environments. The result of this investigaton points towards Frame Semantics as a possible approach on describing meanings in onthology...|$|E
40|$|Problem Statement The {{idea of an}} ‘Internet of Everything’ {{has been}} {{floating}} around for a while, but beyond mere buzzword this concept carries with it immense, and unfortunately as of yet untapped potential. The idea of complete interconnectivity most typically conjures images of home automation; smart appliances capable of self-regulation, self-setting thermostats, etc., but with this connectivity comes with it not only the capacity to remotely monitor an existing system but to control it as well (be it with a smart phone, online application, what have you). There exists ‘smart technologies’ which incorporate user’s smart phones in the operation and monitoring of home appliances, but rarely has this extended beyond novelty. The technology has failed to take off with the general public, be it due to the design not being given serious consideration (again, capitalization on mere novelty), limited functionality, or in perhaps the more obnoxious of scenarios unnecessary ‘bundling’. Without addressing the issue, the technology, and the potential it brings with it, will descend further {{into the realm of}} novelty and make serious consideration just that more difficult. Rationale There is a niche available to produce a system which can be easily incorporated into a future design which takes into consideration this interconnectivity; a highly flexible, highly portable system would ideally, help this technology, and the ideas which inspired it, finally take off in the capacity we feel it <b>capable.</b> <b>Approach</b> The approach taken by the team will be to construct an embeddable system which can detect parameters vital to the operation of a given appliance/component of the home as well as communicate remotely with the end user those parameters and adjust conditions accordingly. Anticipated Results and Conclusions The anticipated results of our project is a system capable of receiving and interpreting a set of signals relevant to a given system, respond to the signals according to a program set by the manufacturer, and deliver those metrics to the end user while allowing for remote control. To better illustrate the concept, our intention is to design an iPhone app which allows for the control of a circuit constructed for demonstration purposes, and can receive updates/warnings should the circuit behave in a way unintended for the system. [URL]...|$|E
40|$|Decoding (Ir-BICM-ID) aided {{scheme is}} proposed. The {{irregularity}} of the scheme pervades the three basic components of BICM-ID, namely the encoder, the unity-rate precoder and the bit-to-symbol mapper. As a result, adaptive BICM-ID schemes constituted by irregular components are created, which are <b>capable</b> of <b>approaching</b> {{the capacity of}} coded modulation. This is achieved by creating a narrow EXtrinsic Information Transfer (EXIT) chart, using a novel EXIT curve matching algorithm. The proposed Ir-BICM-ID scheme employs Irregular Convolutiona...|$|R
30|$|Gauger et al. {{described}} a minimally invasive <b>approach</b> <b>capable</b> of exposing the posterior body, neck, and glenoid. They evaluated {{the results in}} seven patients, reporting mean DASH Score of 8.1. In that series, muscle strength and motion returned to equivalency to the uninjured arm.|$|R
40|$|In this contribution, we derive the Discrete-input Continuous-output Memoryless Channel (DCMC) {{capacity}} of the non-regenerative Multiple-Input Multiple-Output (MIMO) relay channel, when the source-to-destination link is inferior and hence considered absent. We design near-capacity Forward Error Correction (FEC) codes for approaching this capacity limit. It is shown that our design is <b>capable</b> of <b>approaching</b> the DCMC capacity within 0. 4 dB, when communicating over uncorrelated Raleigh fading channels, where the source node, relay node and destination node are equipped with two antennas each...|$|R
40|$|The {{search for}} {{subsurface}} water {{has become a}} primary focus of Mars exploration. Its abundance and distribution (both as ground ice and groundwater) {{have important implications for}} understanding the geologic, hydrologic, and climatic evolution of the planet; the potential origin and continued survival of life; and the accessibility of a critical in situ resource for sustaining future human explorers. For these reasons, a principal goal of the Mars science, astrobiology, and the HEDS programs is to determine the 3 -D distribution and state of subsurface H 2 O, at a resolution sufficient to permit reaching any desired volatile target by drilling. The three targets most often discussed are: groundwater, massive deposits of near-surface ground ice (associated with the ponded discharge of the outflow channels or the relic of a former ocean), and ice-saturated frozen ground. Based on the present best estimates of mean annual surface temperature, crustal thermal conductivity, geothermal heat flow, and groundwater freezing temperature, the mean thickness of frozen ground on Mars is expected to vary from approx. = 2. 5 - 5 km at the equator to approx. = 6. 5 - 13 km at the poles. However, natural variations in both crustal heat flow and thermal conductivity are likely to result in significant local departures from these predicted values. The recent discovery of "young" fluvial-like features, emanating from the slopes of local scarps, raises the possibility that liquid water may also exist episodically at shallow (approx. = 100 - 500 m) depth; however, the true nature and absolute age of these features remains highly uncertain. Although the belief that Mars is water-rich is supported by a wide variety geologic evidence, our ignorance about the heterogeneous nature and thermal evolution of the planet's crust effectively precludes geomorphic or theoretical attempts to quantitatively assess the current geographic and subsurface vertical distribution of ground ice and groundwater. For this reason, any exploration activity (such as drilling) whose success is contingent on the presence of subsurface water, must be preceded by a comprehensive high-resolution geophysical survey capable of assessing whether local reservoirs of water and ice actually exist. Terrestrial experience has demonstrated that the accurate identification of such targets is likely to require the application of multiple geophysical techniques. In this abstract we propose an integrated strategy for the geophysical exploration of Mars that we believe represents the fastest, most cost-effect, and technically <b>capable</b> <b>approach</b> to identifying the state and distribution of subsurface water. Additional information is contained in the original extended abstract...|$|E
40|$|Advanced Driver Assistance Systems (ADAS) already {{make a major}} {{contribution}} to driving safety. To further increase this contribution, it is, however, vital that future intelligent vehicles perceive, predict, and assess their environment more comprehensively. In this context, the present dissertation approaches the questions i) how to represent the driving environment adequately within an environment model, ii) how to obtain such a representation, and iii) how {{to predict the future}} traffic scene evolution for proper criticality assessment. Bayesian inference provides the common theoretical framework of all designed methods. Based on the shortcomings of existing environment representations, a novel parametric representation of general driving environments is first introduced in this work. It consists of a combination of dynamic object maps for moving objects and so-called Parametric Free Space (PFS) maps for static environment structures. PFS maps model the environment by a closed curve around the vehicle, which encloses relevant drivable free space. The representation compactly describes all essential information contained in common occupancy grid maps, suppresses irrelevant details, and consistently separates between static and dynamic environment objects. A novel method for grid mapping in dynamic road environments provides the basis to realize this representation. Therein, dynamic cell hypothesis are detected, clustered, and subsequently tracked and classified with an adaptive Bayesian multiple model filter for jump Markov nonlinear systems – the so-called Interacting Multiple Model Unscented Kalman Probabilistic Data Association Filter (IMM-UK-PDAF). The intermediate result is a dynamic object map and an optimized grid of the static driving environment. From the optimized grid, relevant free space is then extracted by methods of image analysis, and robustly converted to a PFS map in a final B-Spline contour tracking step. Evaluations and experiments, which were performed with an experimental vehicle equipped with radars and a stereo camera in real driving environments, confirm the advantages of the real-time <b>capable</b> <b>approach.</b> The so-obtained representation additionally forms the basis of a novel method for long-term trajectory prediction and criticality assessment. Therein, a three-layered Bayesian network is used to infer current driving maneuvers of traffic participants initially. A trash maneuver class allows the detection of irrational driving behavior and the seamless application from highly-structured to non-structured environments. Subsequently, maneuver-based prediction models in form of stochastic processes are presented and employed to predict the vehicle configurations under consideration of uncertainties in the maneuver executions. Finally, the criticality time metric Time-To-Critical-Collision-Probability (TTCCP) is introduced as a generalization of the time metric Time-To-Collision (TTC) for arbitrary, uncertain, multi-object driving environments and longer prediction horizons. The TTCCP considers all uncertain, maneuver-based predictions and is estimated via Monte Carlo simulations. Simulations confirm its potential to suppress false warnings, to generate timely true warnings, and to generate warnings in critical almost-collision situations effectively. All methods are part of the driver assistance system PRORETA 3, which has been co-developed {{in the context of this}} thesis. It constitutes a novel, integrated approach to collision avoidance and vehicle automation and thereby makes a valuable contribution to realize the Vision Zero – the vision of a future without traffic deaths...|$|E
40|$|Thesis (Ph. D. (Ethics)) [...] North-West University, Potchefstroom Campus, 2006 Due to {{the fact}} that Scripture is the {{authoritative}} Word of God (Belgic Confession. Article 5), the infallible written Word of God. is and stays the basis for Christian ethics. Scripture is not just another single source for Christian ethics among other sources, but it is the decisive source among all other sources. The question then arises - how is it possible in the ever-changing life situation of the modem day context of society? In an ever increasing secularized society places the Christian life and also the Christian ethics under more pressure. The acceptance of the authority of Scripture is therefore indispensable for Christian ethics. Scripture does however not present a text as an absolute answer for every possible or similar ethical problem. The deep-seated principles of Scripture must be exposed. From these principles norms should be derived that is applicable to the modem problem. The problem statement that follows from this culminates as the following: Can a thematic analysis of the Biblical dogma present a fundamental working foundation for Christian ethics in modem day society and serve as a corrective for the problematic approaches of a biblicistic as well as an over critical view of Scripture for the basis of ethics? The central theoretical argument of the study is the following: A thematic analysis of the Biblical dogma can indeed present a fundamental, working foundation for Christian ethics in modem day society and can serve as a corrective for the problematic approaches of a biblicistic as well as an over critical view of Scripture for the basis of ethics. In the second chapter the definitions of what could be defined as Christian ethical perspectives and principles is examined. In other words, the purpose of the chapter is to examine and to give a broad overview of the understanding of ethics, morality, morals etc. The qualified deontological approach is chosen due {{to the fact}} that normative approach with its focus on Scripture as authoritative therein plays a big role. The third chapter focuses on which view of Scripture and use of Scripture is normally applied in Reformed ethics in the use or interpretation of Scripture. Special attention is given to the authority of Scripture, view of Scripture and an attempt is made to convey the hermeneutical points of departure (axioms) in order to derive an intra-biblical use of Scripture. The chapter comes to the conclusion that even though the Christian ethicist does have in theory at his disposal a biblical-founded hermeneutical model it does not safeguard him against a faulty use or interpretation of Scripture in practice in the fourth chapter the present-day Scriptural principles that serves as basis and cadre for the interpretation of Scripture in light of the answering of Christian ethical questions is examined. In light of the present-day situation seems that although there is a sound hermeneutical axiom that serves as filters in the interpretation of Scripture in the reformed ethics, in practice either a biblicistic or a Criticism of Scripture approach to Scripture is chosen. The approaches of the fundamentalistic/biblicistic and Criticism of Scripture is examined and m e s to the conclusion that both, in their own way, does bring the authority and the message of Scripture in disrepute. In the event of the fundamentalistic and biblicistic approach the divine inspiration character of Scripture is overemphasized and all Scriptural Utterances is treated on the same level to such an instance that everything is sanctioned. In the event of the Criticism of Scripture the human fallible character is again overemphasized to the extent that the normative authority of Scripture for Christian ethics is not taken into account. The chapter comes to the conclusion mat a "third way” must be examined to circumvent the many pitfalls of either a fundamentalistic/biblicistic of Criticism of Scripture in the interpretation of Scripture in light of a modem day ethical problem. In the fifth chapter an adjudication and evaluation of the quality of the use or Interpretation of Scripture in light of capital punishment within the biblical view of a right to life is given as a representative of modem day ethical problems. In light of the principles given in Chapter 3 and 4 it is shown that Scripture is most often misused despite fair hermeneutical principles Only to reflect the ethicist own preconceived ideas. The last chapter indicates an approach that might possibly serve as an alternative/valid use or interpretation of Scripture in reformed ethics other than a typical biblicistic/fundamentalistic or Criticism of Scripture approach. The chapter draws to the conclusion that the contextual-paradigmatic approach is at this time the only <b>capable</b> <b>approach</b> of acknowledging the proper interpretation of Scripture to shed some light on the ethical problems of modem day society, without stepping into the boundaries of either a biblicistic/fundamentalistic of Criticism of Scripture interpretation of Scripture. The contextual-paradigmatic approach succeeds in preventing the ethicist to misinterpret Biblical texts that seems to be of importance to the debate of capital punishment and to make a scientific contribution lo important debates in South Africa today, especially those related to the interpretation of the Bible and its use in the development of South Africa. In this way an attempt is made to contribute towards and to provide guidelines for a healthy and responsible society and for the functioning of Christians within the current South African state. The message of the Bible must thus be established in a responsible and valid way, and communicated effectively to society. Doctora...|$|E
40|$|STBC) schemes are designed. Recursive unity-rate {{codes and}} IRregular Convolutional Codes (IRCCs) are {{employed}} for assisting the conventional non-recursive STBC schemes in achieving decoding convergence to an infinitesimally low {{bit error ratio}} at near-capacity signal-to-noise ratios. IRregular Convolutional Codes (IRCCs) are used as the outer codes for achieving a near-capacity performance. It was shown that the resultant iteratively decoded STBC schemes are <b>capable</b> of <b>approaching</b> the corresponding channel capacity within 0. 4 dB, when communicating over uncorrelated, flat Rayleigh fading channels. I...|$|R
40|$|Label-free NAPPA technology, in {{combination}} with protein nanobiocrystallography and its possible future development using anodic porous alumina along with a cell-free expression system [...] . appear to form a single <b>approach</b> <b>capable</b> of effectively solving the numerous problems still present in medical diagnosis and therapy...|$|R
5000|$|Second-generation sequencing, often {{referred}} to as Next-generation sequencing (NGS), has dominated the DNA sequencing space since its development. It has dramatically reduced the cost of DNA sequencing by enabling a massively-paralleled <b>approach</b> <b>capable</b> of producing large numbers of reads at exceptionally high coverages throughout the genome.|$|R
40|$|Iteratively decoded near-capacity Space-Time Block Coding (STBC) schemes are designed. Recursive unity-rate {{codes and}} IRregular Convolutional Codes (IRCCs) are {{employed}} for assisting the conventional non-recursive STBC schemes in achieving decoding convergence to an infinitesimally low {{bit error ratio}} at near-capacity signal-to-noise ratios. IRregular Convolutional Codes (IRCCs) are used as the outer codes for achieving a near-capacity performance. It was shown that the resultant iteratively decoded STBC schemes are <b>capable</b> of <b>approaching</b> the corresponding channel capacity within 0. 4 dB, when communicating over uncorrelated, flat Rayleigh fading channels...|$|R
40|$|In this contribution, Near-capacity Non-coherent Cooperative Network-coding aided Multi-user (NNCNM) {{systems are}} {{designed}} {{with the aid of}} Extrinsic Information Transfer (EXIT) charts for the sake of approaching the Differential Discrete-input Continuous-output Memoryless Channel (D-DCMC) -based capacity. The proposed subframe- based network coding solution allows the system to significantly mitigate the effects of large-scale fading on each frame. Hence, NNCNM systems operating in large-scale fading environments are <b>capable</b> of <b>approaching</b> the D-DCMC capacity of the less hostile single link channel incurring the small-scale fading, but no shadow fading...|$|R
25|$|Second-generation sequencing, often {{referred}} to as Next-generation sequencing (NGS), has dominated the DNA sequencing space since its development. It has dramatically reduced the cost of DNA sequencing by enabling a massively-paralleled <b>approach</b> <b>capable</b> of producing large numbers of reads at exceptionally high coverages throughout the genome.|$|R
40|$|Aim of {{this book}} {{is to focus on}} the {{properties}} of defects in semiconductors of the fourth group under a physico-chemical <b>approach,</b> <b>capable</b> to demonstrate whether the full acknowledgement of their chemical nature could account for several problems encountered in practice or would suggest further experimental or theoretical accomplishments...|$|R
40|$|Imports scatterplot 3 d Description Dynamic Transcriptome Analysis (DTA) {{can monitor}} the {{cellular}} response to perturbations with higher sensitivity and temporal resolution than standard transcriptomics. The package implements the underlying kinetic modeling <b>approach</b> <b>capable</b> of the precise determination of synthesis- and decay rates from individual microarray or RNAseq measurements...|$|R
40|$|A novel reduced-complexity near-optimal {{detection}} {{algorithm is}} proposed for enhancing the recent coherently-detected Space-Time Shift Keying (STSK) scheme employing arbitrary constellations, such as L-point Phase-Shift Keying (PSK) and Quadrature Amplitude Modulation (QAM). The proposed detector relies on a modified Matched Filter (MF) concept. More specifically, we exploit both the constellation diagram of the modulation scheme employed {{as well as the}} Inter-Element-Interference (IEI) -free STSK architecture. It is revealed that the proposed detector is <b>capable</b> of <b>approaching</b> the optimal Maximum Likelihood (ML) detector's performance, while avoiding the exhaustive ML search...|$|R
