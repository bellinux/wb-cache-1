30|896|Public
40|$|Abstract. In KDD procedure, {{to fill in}} {{missing data}} {{typically}} requires a very large investment of time and energy- often 80 % to 90 % of a data analysis project is spent in making the data reliable enough so that {{the results can be}} trustful. In this paper, we propose a SVM regression based algorithm for filling in missing data, i. e. set the decision attribute (output attribute) as the <b>condition</b> <b>attribute</b> (input attribute) and the <b>condition</b> <b>attribute</b> as the decision attribute, then use SVM regression to predict the <b>condition</b> <b>attribute</b> values. SARS data set experimental results show that SVM regression method has the highest precision. The method with which the value of the example that has the minimum distance to the example with missing value will be taken to fill in the missing values takes the second place, and the mean and median methods have lower precision. ...|$|E
40|$|Recently, National Bureau of Statistics of China has {{released}} macro-economic climate index of China from 2009 - 02 to 2010 - 05. Based on these indices, we establish an information system. In this information system, monitoring signal {{is taken as}} a decision attribute and coincident index, leading index, lagging index are taken as condition attributes. We use rough-set theory to investigate the importance of each <b>condition</b> <b>attribute</b> with respective to decision attribute {{and the strength of}} each <b>condition</b> <b>attribute</b> supporting decision attribute. Results of this investigation will be helpful for Chinese government to make active macro-economic policy and to maintain the steady and relatively fast development of Chinese economy...|$|E
3000|$|<b>Condition</b> <b>attribute</b> set C = {a 1, a 2, a 3, a 4, a 5, a 6 }, and {{decision}} set P = {d 1, d 2 }. QoE co-evaluation based on fuzzy clustering heuristic algorithm {{is described as}} follows, [...]...|$|E
40|$|In this paper, {{the rough}} set theory is used {{to deal with the}} {{relations}} between patient’s temperature, oxygen saturation, blood pressure and decision ADM-DECS in care of postoperative patients, we select 28 postoperative patients as a sample, take ADM-DECS as a decision attribute and take patient’s temperature, oxygen saturation, blood pressure as <b>condition</b> <b>attributes.</b> We are based on rough-set theory to research importance of <b>condition</b> <b>attributes</b> with respective to decision attribute and strength of <b>condition</b> <b>attributes</b> supporting decision attribute. Results of this research will be helpful for nurses to raise quality of care...|$|R
5000|$|Eleventh Chapter: The <b>Conditions,</b> <b>Attributes,</b> and Customs of the Morīd ...|$|R
40|$|Abstract. Environment {{settlements}} always occur while tunnel constructs in cities, {{which may}} cause ground collapse and building damage. It is engineering significant {{to analyze the}} key factors in the tunnel construction for an acceptable environment settlements value. The Rough Sets and the settlements induced by the tunnel construction were reviewed, and 22 engineering samples were investigated on the 9 <b>condition</b> <b>attributes</b> to 1 decision attribute. The significant degrees of the 9 <b>condition</b> <b>attributes</b> are normalized, {{and the importance of}} the <b>condition</b> <b>attributes</b> is obtained based on the normalized value. The results offer a method to extract the key factors on environment settlements in tunnel construction based on Rough Sets...|$|R
40|$|This paper {{analyses}} the behaviour of inductive algorithms in {{the field}} of spontaneous intracerebral extravasation (haematoma). For haematoma <b>condition</b> <b>attribute</b> diagnostics, the use of inductive algorithm, CART 2, has been suggested. During investigations in practical data in haematoma field the algorithm has shown good results 9 ̆ 6 up to 96...|$|E
40|$|Abstract. In this paper, {{we propose}} a new rough set {{classifier}} induced from partially uncertain decision system. The proposed classifier aims at simplifying the uncertain decision system and generating more significant belief decision rules for classification process. The uncertainty is reperesented by the belief functions and exists {{only in the}} decision attribute and not in <b>condition</b> <b>attribute</b> values...|$|E
40|$|Attribute {{reduction}} {{is the strongest}} and most characteristic result in rough set theory to distinguish itself to other theories. In the framework of rough set, an approach of discernibility matrix and function is the theoretical foundation of finding reducts. In this paper, sample pair selection with rough set is proposed in order to compress the discernibility function of a decision table so that only minimal elements in the discernibility matrix are employed to find reducts. First relative discernibility relation of <b>condition</b> <b>attribute</b> is defined, indispensable and dispensable condition attributes are characterized by their relative discernibility relations and key sample pair set is defined for every <b>condition</b> <b>attribute.</b> With the key sample pair sets, all the sample pair selections can be found. Algorithms of computing one sample pair selection and finding reducts are also developed; comparisons with other methods of finding reducts are performed with several experiments which imply sample pair selection is effective as preprocessing step to find reducts. Department of Computin...|$|E
40|$|Rough {{classifiers}} combine {{features of}} machine learning classification models with probabilistic methods of data structure description. The paper presents a procedure for rough classifier construction which is invariant {{with regard to}} the sequence of <b>condition</b> <b>attributes</b> as well as objects in the learning set. The probabilistic structure of the datasets is estimated from the learning samples using the approach based on the frequency estimators of unknown probabilities. <b>Condition</b> <b>attributes</b> can be of any mixed type from unordered qualitative ones to continuous quantitative ones. The relationships between the <b>condition</b> <b>attributes</b> and the decisions are expressed in terms of {{a relatively small number of}} if condition then decision rules. The resulting decision algorithm is minimizing the misclassification cost of new objects, which is a more flexible and general criterion than the error rate minimization. The strength of each rule is characterized by the estimate of its probability and by th [...] ...|$|R
40|$|This paper {{explores the}} effect of the results from the {{continuous}} valued discretisation (CVD) of <b>condition</b> <b>attributes</b> in an analysis using the variable precision rough sets model (VPRSβ). With the utilisation of an ordered criteria for the identification of an associated β-reduct, a ‘leave n out’ approach is undertaken in the subsequent analysis. A small example problem is considered for which three alternative methods of CVD are used to intervalise the continuous <b>condition</b> <b>attributes.</b> For each CVD approach used 1500 decision tables are constructed and VPRSβ analysis undertaken...|$|R
40|$|Peer-reviewedThe use of {{languages}} based on positive or negative expressiveness is very common for the deployment of security policies (i. e., deployment of permissions and prohibitions on firewalls through single-handed positive or negative <b>condition</b> <b>attributes).</b> Although these languages may allow us to specify any policy, the single use of positive or negative statements alone leads to complex configurations when excluding some specific cases of general rules that should always apply. In this paper we survey such a management and study existing solutions, such as ordering of rules and segmentation of <b>condition</b> <b>attributes,</b> in order to settle this lack of expressiveness...|$|R
40|$|Abstract. An {{action is}} defined as {{controlling}} or changing some of attribute values in an information system to achieve desired result. An action reduct is the minimal set of attribute values distinguishing a favorable object from other objects. We use action reducts to formulate necessary actions. The action suggested by an action reduct induces changes of decision attribute values by changing the <b>condition</b> <b>attribute</b> values to the distinct patterns in action reducts...|$|E
30|$|The third case is to {{describe}} the One-to-Many mapping relationship between Server elements in the customized model and Apache, JOnAS, MySQL elements in Cloud resource runtime models. The “helper” tag is used {{to describe}} the One-to-Many mapping relationship, so the value of its type attribute is “multi”. The <b>condition</b> <b>attribute</b> in the “helper” tag {{is to describe}} the mapping precondition. For instance, if the value of the imageId attribute of the Server element is “ 1 ”, the Server element is mapped to the JOnAS element.|$|E
30|$|In this step, the RSS is {{introduced}} {{to reduce the}} redundant bits. In this regard, the obtained population is assumed as an information system consisting of bats’ solutions where each bat is represented {{by a set of}} condition attributes and one decision attribute. For the bat i,x_ij the <b>condition</b> <b>attribute</b> illustrates the selected item j, and the decision attribute demonstrates the feasibility of this bat. The term feasibility means that the candidate bat satisfies the knapsack capacity. When the candidate bat is feasible, the decision attribute takes one value; otherwise it takes 0 value. After that, all solutions are formulating as augmented matrix consisting of the condition and decision attributes [x_i 1,x_i 2,...,x_in|{D}]_i= 1 ^PS, where D denotes decision attribute that takes 1 or 0 value. Therefore, D splits the population into two classes: members that picked value of one in D and members that picked value of zero in D. Let U be the set of objects (solutions) and X⊆ U that contains the one values of D and B={x_ 1,x_ 2,...,x_n} is the set of <b>condition</b> <b>attribute</b> in an IS. Then according to Definition  4, the redundant items are eliminated where BX,B̅XBN_B (X) and NEG_B (X) of X are obtained based on the process of attribute reduction.|$|E
5000|$|Let us {{say that}} we wish to find the minimal set of {{consistent}} rules (logical implications) that characterize our sample system. For a set of <b>condition</b> <b>attributes</b> [...] and a decision attribute , these rules should have the form , or, spelled out, ...|$|R
40|$|Attribute {{reduction}} {{is very important}} in rough set-based data analysis (RSDA) because {{it can be used to}} simplify the induced decision rules without reducing the classification accuracy. The notion of reduct plays a key role in rough set-based attribute reduction. In rough set theory, a reduct is generally defined as a minimal subset of attributes that can classify the same domain of objects as unambiguously as the original set of attributes. Nevertheless, from a relational perspective, RSDA relies on a kind of dependency principle. That is, the relationship between the class labels of a pair of objects depends on component-wise comparison of their <b>condition</b> <b>attributes.</b> The larger the number of <b>condition</b> <b>attributes</b> compared, the greater the probability that the dependency will hold. Thus, elimination of <b>condition</b> <b>attributes</b> may cause more object pairs to violate the dependency principle. Based on this observation, a reduct can be defined alternatively as a minimal subset of attributes that does not increase the number of objects violating the dependency principle. While the alternative definition coincides with the original one in ordinary RSDA, it is more easily generalized to cases of fuzzy RSDA and relational data analysis. Rough sets Decision analysis Fuzzy sets Attribute reduction Relational information system...|$|R
25|$|The ouvrage {{has been}} {{maintained}} {{as a museum}} since 1975. It remains in a good state of preservation, a <b>condition</b> <b>attributed</b> to the unusual attention given to drainage of groundwater while the site was open to the sky for construction, something not possible in tunneled positions.|$|R
30|$|Query: The “query” tag {{is used to}} {{describe}} the mapping relationship between attributes of elements. There are usually four attributes in the “query” tag. The key and value attributes in the “query” tag are similar with the ones in “mapper” tag. But the element, which the attribute belongs to, is defined by the node and condition attributes; the node attribute describes the type of the target element and the <b>condition</b> <b>attribute</b> describes the constraint that the target element should follow. The “query” tag is usually used in the descriptions of many-to-one mapping relationships between elements.|$|E
40|$|Decision tree {{is widely}} used in machine learning. In the process of {{constructing}} a tree, appropriate attributes have to be selected as nodes of the tree based on some criteria. There are several approaches to selection of attributes. In this paper, we present {{a new approach to}} selection of attributes for construction of decision tree based on rough set theory. The basic idea is, if the size of the implicit region corresponding to one <b>condition</b> <b>attribute</b> is the smallest, then this attribute will be chosen as the node for branching. The presente...|$|E
40|$|AbstractThe {{development}} of wind power is so rapid that wind power plants are built aimlessly. It will help standardize the {{development of}} wind power and promote the healthy development of China's wind power industry to evaluate the feasibility of wind power projects scientifically. In this paper, Rough Set theory is {{used to evaluate the}} feasibility of wind power. Namely reduce the condition attributes firstly in the case of keeping the ability of grouping the index properties, then evaluate the evaluation object using the importance of <b>condition</b> <b>attribute</b> to object division as index attribute weights. Finally, the method is verified with an example...|$|E
30|$|In this section, {{a simple}} example {{is given to}} show how the {{proposed}} algorithm can be used to cluster the attributes. Table  3 shows the scores of eight students. There are eight <b>condition</b> <b>attributes</b> A = PR, CA, DM, C++, JAVA, DB, DS, AL, respectively stands for the eight subjects: Probability, Calculus, Discrete Mathematics, C++, JAVA, Database, Data Structure and Algorithms. The values of the <b>condition</b> <b>attributes</b> are { A, B, C, D}, which stand for the grade levels of a subject. There is one decision attribute ST, which stands for Study  for  Master  Degree and has two possible classes Yes, No. In this example, the number of clusters is set at 2 (i.e. k = 2). For the set of data, the proposed algorithm proceeds as follows.|$|R
2500|$|Kahneman and Frederick propose three <b>conditions</b> for <b>attribute</b> substitution: ...|$|R
40|$|Abstract: A multi-valued {{information}} system (MIS) is a generalization {{of the idea}} of a single valued {{information system}} (SIS). In a multi-valued information system, attribute functions are allowed to map elements to sets of attribute values. In this paper, we initiated a new approach for data reduction in Generalized Multi–Valued Decision Information System (GMDIS). In the beginning we converted the Single-Valued Decision Information System (SDIS) by collecting the attributes to a GMDIS. Two general relations are defined on <b>condition</b> <b>attributes</b> and decision attribute. We constructed new classes using the general relations which are used for data reduction. The measure of decision dependency on the <b>condition</b> <b>attributes</b> is studied in our approach. To evaluate the performance of the approach, an application of, rheumatic fever datasets has been chosen and the reduct approach have been applied to see their ability and accuracy...|$|R
40|$|In {{the data}} base of {{information}} system, usually {{there are some}} attributes which are unimportant to the decision attribute, and some records that disturb the decision making. In this paper, reducing the condition attributes based on the matter-element theory and rough set method, calculating the importance to the decision attribute for each <b>condition</b> <b>attribute</b> after reduction, and data mining the relevant rules based on the reduced attributes, extension relevant function is used to depict quality of data gather in data mining. Finally, how to tap new customers and how to recommend an appropriate brand to new customers, Research result indicates that extension data mining can provide effective decide support for the Decision-making of enterprise. </p...|$|E
40|$|The {{process of}} {{determining}} missing values in {{information system is}} an important issue for decision making especially when the missing values are in the decision attribute. The main goal for this paper is to introduce algorithm for finding missing values of decision attribute. Our approach is depending on distance function between existing values. These values can be calculated by distance function between the conditions attributes values for the complete information system and incomplete information system. This method can deal with the repeated small distance by eliminating a <b>condition</b> <b>attribute</b> which has the smallest effect on the complete information system. This algorithm will be discussed in detail with an example of a case study...|$|E
40|$|Abstract—Nowadays, it {{is certain}} that {{we have to deal with}} massive data and {{abstract}} implicit regularity from massive data. In this paper, the reduction algorithm based on Rough Sets is proposed as a practical data mining technology and the procedure of telecommunication decision is analyzed. In the paper, the procedure of telecommunication based on data mining of Rough Sets is discussed. The factor set is established including <b>condition</b> <b>attribute</b> and decision attribute. The attribute reduction algorithm based on Rough Sets is used to eliminate the redundant risk factor and its value of decision table. It can be generalized to some useful rules and we can make proper decision from the rules to improve precision and explanatory ability in practice. Keywords-rough sets; data mining; discernibility matrix I...|$|E
40|$|This {{study was}} an {{assessment}} of how children's achievement attributions were influenced by their age, attentional focus, gender, and success or failure experience. Older and younger elementary school children performed a memory task under either self-focusing or task-focusing instructions. After performance, half {{of the children in}} each condition were given success feedback and the other half failure feedback. Attributions for performance were then obtained. In the success condition, children judged effort {{to be the most important}} cause of their performance, whereas children in the failure <b>condition</b> <b>attributed</b> their performance mostly to the difficulty of the task and their inability to remember the story. Older children in the self-focus <b>condition</b> <b>attributed</b> success more to internal causes than did older children in the task-focus <b>condition.</b> Younger children <b>attributed</b> both success and failure more to luck than did older children. Few sex differences in attributions were obtained. Achievement attributions have significant consequences for subsequent achievement motivation and behavior; attributing success to one's ability and failure to lack of effort promotes positive achievement motivation and behavior, whereas at...|$|R
30|$|Using {{a reduced}} algorithm, the rules {{can be found}} through {{determining}} the decision attributes value, based on the <b>condition</b> <b>attributes</b> values. Therefore, the rules are showed in an “IF condition(s) THEN decision(s)” format. The concept of the decision table is {{used in this study}} to create rules from fuzzy relationships, which generate rules for better reaching results.|$|R
3000|$|An {{information}} {{system can be}} expressed by a four-parameters group[10]: S = {U R V f}. U is a finite and non-empty set of objects called the universe, and R = C ∪ D is a finite set of attributes, where C denotes the <b>condition</b> <b>attributes</b> and D denotes the decision attributes. V =∪ v [...]...|$|R
40|$|AbstractA {{generalization}} {{of the original}} definition of rough sets and variable precision rough sets is introduced. This generalization {{is based on the}} concept of absolute and relative rough membership. Similarly to variable precision rough set model, the generalization called parameterized rough set model, is aimed at modeling data relationships expressed in terms of frequency distribution rather than in terms of a full inclusion relation used in the classical definition of rough sets. However, differently from the variable precision rough set model, one or more parameters modeling {{the degree to which the}} <b>condition</b> <b>attribute</b> values confirm the decision attribute value, are considered. The properties of this extended model are investigated and compared to the classical rough set model and to the variable precision rough set model...|$|E
40|$|Abstract — In {{the data}} base of {{information}} system, usually {{there are some}} attributes which are unimportant to the decision attribute, and some records that disturb the decision making. In this paper, reducing the condition attributes based on the matter-element theory and rough set method, calculating the importance to the decision attribute for each <b>condition</b> <b>attribute</b> after reduction, and data mining the relevant rules based on the reduced attributes, extension relevant function is used to depict quality of data gather in data mining. Finally, how to tap new customers and how to recommend an appropriate brand to new customers, Research result indicates that extension data mining can provide effective decide support for the Decision-making of enterprise. Index Term — rough set, extension data mining, attributes reduction, matter-element I...|$|E
40|$|AbstractThis study {{uses the}} {{variable}} precision rough set (VPRS) model {{as a tool}} to support group decision-making (GDM) in credit risk management. We consider the case that the classification in decision tables consisting of risk exposure (RE) may be partially erroneous, and use a variable precision factor βk to adjust the classification error. In this paper, we firstly combine VPRS and AHP to obtain the weight of <b>condition</b> <b>attribute</b> sets decided by each decision-maker (DM). Then, the integrated risk exposure (IRE) of attributes is obtained based on the three VPRS-based models. Subsequently, a new procedure of obtaining βk-stable intervals for DMk is investigated. To verify the effectiveness of these proposed methods, an illustrative example is presented. The experimental results suggest that the VPRS-based IRE have advantages in recognizing important attributes...|$|E
50|$|The {{population}} {{attributed to}} the sculpture various miraculous <b>conditions,</b> <b>attributing</b> to it the power to attract rain if the tecomates were wet or healing powers to the water that accumulated in them. The people gave offerings to the sculpture and asked for sufficient rains and good harvests. In addition, the monument was a tourist attraction of the population.|$|R
40|$|Abstract. The use of {{languages}} based on positive or negative expres-siveness is very common for the deployment of security policies (i. e., deployment of permissions and prohibitions on firewalls through single-handed positive or negative <b>condition</b> <b>attributes).</b> Although these lan-guages may allow us to specify any policy, the single use of positive or negative statements alone leads to complex configurations when ex-cluding some specific cases of general rules that should always apply. In this paper we survey such a management and study existing solutions, such as ordering of rules and segmentation of <b>condition</b> <b>attributes,</b> in order to settle this lack of expressiveness. We then point out to the ne-cessity of full expressiveness for combining both negative and positive conditions on firewall languages {{in order to improve}} this management of exceptions on access control policies. This strategy offers us a more efficient deployment of policies, even using fewer rules. ...|$|R
50|$|Inattention (attributed to 307 operators), {{inexperience}} (attributed to 296 operators), {{and inappropriate}} speed for the operating <b>conditions</b> (<b>attributed</b> to 246 operators) {{were the most}} frequently cited causes {{that contributed to the}} PWC accidents. One or more of these three causes were associated with 70 percent of the 814 accidents. A fourth cause, improper lookout (153), was associated with about one-fifth of the accidents.|$|R
