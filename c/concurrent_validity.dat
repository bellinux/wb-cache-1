2699|402|Public
50|$|<b>Concurrent</b> <b>validity</b> and {{predictive}} validity are {{two types}} of criterion-related validity. The difference between <b>concurrent</b> <b>validity</b> and predictive validity rests solely on the time at which the two measures are administered. <b>Concurrent</b> <b>validity</b> applies to validation studies in which the two measures are administered at approximately the same time. For example, an employment test may be administered to a group of workers and then the test scores can be correlated with the ratings of the workers' supervisors taken on the same day or in the same week. The resulting correlation would be a <b>concurrent</b> <b>validity</b> coefficient. This type of evidence might be used to support the use of the employment test for future selection of employees.|$|E
50|$|The Strong Interest Inventory {{is high in}} both {{predictive}} and <b>concurrent</b> <b>validity.</b>|$|E
5000|$|... <b>concurrent</b> <b>validity</b> may {{be defined}} by various {{correlates}} or markers, and perhaps also treatment response; ...|$|E
40|$|This paper {{reports on}} the {{criterion}} validity of the Occupational Therapy Adult Perceptual Screening Test (OT-APST) including <b>concurrent</b> criterion <b>validity</b> and its sensitivity and specificity. The performance of 208 people following stroke on the OT-APST and a reference tool (either the Loewenstein Occupational Therapy Cognitive Assessment (LOTCA) or the LOTCA - Geriatric version (LOTCA-G)) was compared. The OT-APST subscale scores and performance outcome (intact or impaired) on related subscales of the reference tool was analyzed to evaluate the <b>concurrent</b> criterion <b>validity</b> of the OT-APST and its sensitivity and specificity at selected cut-off scores. Significant correlations were found between participants 2 ̆ 7 performance (intact or impaired) on the reference tool and scores on the OT-APST. The sensitivity and specificity of the OT-APST were analyzed at selected cut-off scores to explore the validity of decisions based on OT-APST performance {{when compared with the}} reference tool. This study shows that the OT-APST is a tool with demonstrated <b>concurrent</b> criterion <b>validity</b> for the assessment of visual perception...|$|R
40|$|Purpose: The {{purpose of}} the current study was to develop and {{validate}} a sport-specific mindfulness measure, the Athlete Mindfulness Questionnaire (AMQ), through 5 related studies using 4 separate samples of Chinese athletes. The AMQ is a 3 -factor measure designed to assess mindfulness that reflects present-moment attention, awareness, and acceptance in a sport context. Methods: In Study 1, an initial pool of items was generated based on previous literature, existing mindfulness scales, as well as interviews with and feedback from the athletes, coaches, and mindfulness experts. Initial support for the 3 -factor structure of the AMQ was established via exploratory factor analysis in Study 2, and cross-validated through confirmatory factor analysis in Studies 3 and 4. In Study 5, a modified 3 -factor AMQ with direct-worded acceptance items was examined in a fourth independent sample. Results: Convergent and <b>concurrent</b> <b>validities</b> of the acceptance subscale failed to be established in Studies 3 and 4 which {{may be due to the}} inattention and confusion of the athletes whilst interpreting the reverse-worded items. A modified 16 -item AMQ in Study 5 displayed satisfactory model fit and acceptable internal consistencies. Most importantly, convergent and <b>concurrent</b> <b>validities</b> of the 16 -item AMQ were supported. The 3 subscales showed significant positive associations with mindfulness, flow, well-being, and positive affect and significant negative associations with experiential avoidance, burnout, and negative affect. Conclusion: The AMQ is a psychometrically sound measure of mindfulness in a sport context. The importance of using direct-worded acceptance items is discussed...|$|R
40|$|A three‐item {{sense of}} {{coherence}} (SOC) scale was developed, incorporating {{the definitions of}} the three subordinate concepts of SOC for use in population surveys. A cross‐sectional internet survey was conducted {{in the latter part}} of July 2006. Cronbach's α was 0. 84. The correlation coefficient of SOC‐ 13 and the newly devised University of Tokyo Health Sociology version of the SOC Scale (SOC‐ 3 ‐UTHS) was 0. 51. As regards correlation with a health index, SOC‐ 3 ‐UTHS had a significant association, although this association was somewhat weaker than that of SOC‐ 13. Therefore, certain levels of convergent and <b>concurrent</b> <b>validities</b> of SOC‐ 3 ‐UTHS have been indicated...|$|R
50|$|<b>Concurrent</b> <b>validity</b> {{may be used}} as a {{practical}} substitute for predictive validity. In the example above, predictive validity would be the best choice for validating an employment test, because using the employment test on existing employees may not be a strong analog for using the tests for selection. Reduced motivation and restriction of range are just two possible biasing effects for <b>concurrent</b> <b>validity</b> studies.|$|E
50|$|<b>Concurrent</b> <b>validity</b> {{is a type}} of {{evidence}} that can be gathered to defend the use of a test for predicting other outcomes. It is a parameter used in sociology, psychology, and other psychometric or behavioral sciences. <b>Concurrent</b> <b>validity</b> is demonstrated when a test correlates well with a measure that has previously been validated. The two measures may be for the same construct, but more often used for different, but presumably related, constructs.|$|E
50|$|The Severe Impairment Battery: <b>Concurrent</b> <b>Validity</b> and the Assessment of Longitudinal Change in Alzheimer's Disease; Alzheimer Disease and Associated Disorders, Volume 11, Supplement 2, 1997.|$|E
40|$|The psychometric {{properties}} of all instruments specifically intended to measure alexithymia, are reviewed in this chapter. These reviews, not only set out clear descriptions of {{the pros and cons}} of each measure, but also demonstrate that most alexithymia measures have only low to moderate <b>concurrent</b> <b>validities,</b> indicating that alexithymia is, in its measurement, ill-defined. The starting point of our scale-analyses is the original description of the alexithymia construct as provided by Nemiah and Sifneos (1970 a), and Sifneos (1973). Since alexithymia is a multi-faceted construct, factorial validity is also evaluated. Moreover, alexithymia scales are both research and diagnostic instruments. Diagnostic differentiation (discriminant validity) demands that subscales also intercorrelate lowly or only moderately...|$|R
30|$|The FSS was {{administered}} to 72 MS patients, without co morbid fatigue and 75 matched paired controls with respect to gender and age. Both groups responded to the FSS, SF- 36 v 2, BDI-II and a demographic questionnaire on two time points separated by a 1 -week interval. Exploratory and confirmatory factor analysis was performed to test construct <b>validity,</b> <b>concurrent</b> and divergent <b>validity,</b> internal and test-retest reliability were also examined.|$|R
5000|$|Evidence for construct, <b>concurrent</b> and discriminatory <b>validity</b> of the STQ-105 and STQ-150 was {{demonstrated}} through significant correlations {{with the following}} measures: ...|$|R
5000|$|Zelinski, E. M., Gilewski, M. J., & Anthony-Bergstone, C. R. (1990). Memory Functioning Questionnaire: <b>Concurrent</b> <b>validity</b> with memory {{performance}} and self-reported memory failures. Psychology and Aging, 5, 388-399.|$|E
5000|$|Although {{psychologists and}} {{educators}} {{were aware of}} several facets of validity before World War II, their methods for establishing validity were commonly restricted to correlations of test scores with some known criterion. Under the direction of Lee Cronbach, the 1954 Technical Recommendations for Psychological Tests and Diagnostic Techniques attempted to clarify and broaden the scope of validity by dividing it into four parts: (a) <b>concurrent</b> <b>validity,</b> (b) predictive validity, (c) content validity, and (d) construct validity. Cronbach and Meehl’s subsequent publication grouped predictive and <b>concurrent</b> <b>validity</b> into a [...] "criterion-orientation", which eventually became criterion validity.|$|E
50|$|St. Louis, K., Reichel, I., Yaruss, J.S., & Lubker, B.B. (2009). Construct and <b>concurrent</b> <b>validity</b> of a {{prototype}} questionnaire to survey public attitudes toward stuttering. Journal of Fluency Disorders, 34, 11-28.|$|E
30|$|The {{comparison}} of <b>concurrent</b> <b>validities</b> {{based on the}} first year participants’ O-NET scores found {{no significant differences between}} the correlations with the experimental test scores derived from the multiple choice tests although there was a higher correlation for the 3 -option test than the 4 -option test, despite the O-NET examination itself being composed of 4 -option multiple choice items, with the 5 -option test producing the lowest correlation. There were no significant differences in the Cronbach alpha reliability coefficients of the three tests and those for the structure sections and also overall were very closely aligned, with the coefficients for the reading sections somewhat lower as well as being more widely spread due to the lower number of items on which the calculation of the coefficients was based.|$|R
40|$|This study {{explored}} <b>concurrent</b> and incremental <b>validity</b> {{of three}} trait emotional intelligence measures: the Schutte Emotional Intelligence Scale, Multidimensional Emotional Intelligence Assessment, and Trait Emotional Intelligence Questionnaire. A total of 307 participants were drawn predominantly from community and student populations. <b>Concurrent</b> criterion <b>validity</b> {{of the measures}} varied depending on whether emotional intelligence (EI) was assessed as a lower, middle or higher level construct, with validity coefficients being larger for the former. In all cases, the Trait Emotional Intelligence Questionnaire was the superior predictor of multiple psychological criteria. At the higher level of assessment, incremental validity beyond (a) age, gender and the Big Five, and (b) the remaining two EI measures, was also superior...|$|R
40|$|Children with Asperger’s {{syndrome}} {{are often}} reported {{by their parents}} as having difficulties communicating affection. This study aimed to develop a valid measure of affectionate behaviour {{that could be used}} to investigate and quantify these anecdotal reports and then be used in further intervention research. Using parent and expert focus groups, three measures (Affection for Others Questionnaire, Affection for You Questionnaire and General Affection Questionnaire) were developed with reference to the existing affection literature. The measures were completed by 131 parents of children with a clinician-confirmed diagnosis of Asperger’s syndrome. Psychometric assessment of the measures revealed clear factor structures with high internal consistencies and significant <b>concurrent</b> <b>validities.</b> The findings suggest many children with Asperger’s syndrome have difficulties with affectionate behaviour that significantly impact their daily functioning and relationships with others, signalling future research needs to develop interventions in this area. Limitations of the research are also discussed...|$|R
50|$|Predictive {{validity}} shares similarities with <b>concurrent</b> <b>validity</b> in {{that both}} are generally measured as correlations between a test and some criterion measure. In {{a study of}} <b>concurrent</b> <b>validity</b> the test is administered {{at the same time}} as the criterion is collected. This is a common method of developing validity evidence for employment tests: A test is administered to incumbent employees, then a rating of those employees' job performance is, or has already been, obtained independently of the test (often, as noted above, in the form of a supervisor rating). Note the possibility for restriction of range both in test scores and performance scores: The incumbent employees are likely to be a more homogeneous and higher performing group than the applicant pool at large.|$|E
50|$|If {{the test}} data and {{criterion}} data are {{collected at the}} same time, this {{is referred to as}} <b>concurrent</b> <b>validity</b> evidence. If the test data are collected first in order to predict criterion data collected at a later point in time, then this is referred to as predictive validity evidence.|$|E
50|$|ASRS {{has been}} adapted to other {{languages}} including Spanish and Chinese. Conducted research {{proved that the}} scale is a valid and useful tool for the screening of adult ADHD. The ASRS was externally validated on approximately 60 adult patients, and showed high internal consistency and high <b>concurrent</b> <b>validity</b> with the physician-administered ADHD rating system.|$|E
3000|$|This study {{aimed to}} develop and test the Japanese version of the Gambling Related Cognitions Scale (GRCS-J) to {{investigate}} its reliability and validity for assessing gambling cognitions in a Japanese sample. Five hundred and thirty-six participants (351 male, 185 female; Mean age[*]=[*] 29.75  years) from a community sample living in Japan {{were included in the}} analyses. The results of a confirmatory factor analysis confirmed that a five-factor model was appropriate for the data (goodness of fit index[*]=[*]. 87, comparative fit index[*]=[*]. 90, root mean square error of approximation[*]=[*]. 07). The Cronbach’s alpha coefficient was [...]. 94 for the total scale and ranged from [...]. 74 to [...]. 85 for the subscales. The <b>concurrent</b> <b>validities</b> for the GRCS-J were also good. Further, the results of a t-test revealed significant gender differences in the GRCS-J subscale scores and the total score. These results indicated that the GRCS-J was a valid and reliable measure for assessing gambling cognitions in a non-clinical Japanese sample.|$|R
40|$|AbstractThis study {{aimed to}} examine the {{reliability}} and validity of the California Bullying Victimization Scale (CBVS) (Felix et al., 2011) in a sample of Turkish middle school students. A total of 313 students (47. 9 % male, 52. 1 % female) participated in this study. For the reliability the Cronbach's alpha coefficient and test-retest reliability coefficient; for the <b>validity</b> <b>concurrent</b> and predictive <b>validity</b> were calculated. Results indicated the internal consistency of. 72 and. 83 for victimization items; two-week test-retest reliability of. 82. The total scores of CBVS were also positively correlated with a bullying measure and negatively correlated with life satisfaction and hope...|$|R
40|$|Background Spanish {{is one of}} {{the five}} most spoken {{languages}} in the world. There is currently no published Spanish version of the Örebro Musculoskeletal Pain Questionnaire (OMPQ). The aim of the present study is to describe the process of translating the OMPQ into Spanish and to perform an analysis of reliability, internal structure, internal consistency and <b>concurrent</b> criterion-related <b>validity.</b> Methods Design: Translation and psychometric testing. Procedure: Two independent translators translated the OMPQ into Spanish. From both translations a consensus version was achieved. A backward translation was made to verify and resolve any semantic or conceptual problems. A total of 104 patients (67 men/ 37 women) {{with a mean age of}} 53. 48 (± 11. 63), suffering from chronic musculoskeletal disorders, twice completed a Spanish version of the OMPQ. Statistical analysis was performed to evaluate the reliability, the internal structure, internal consistency and <b>concurrent</b> criterion-related <b>validity</b> with reference to the gold standard questionnaire SF- 12 v 2. Results All variables except “Coping” showed a rate above 0. 85 on reliability. The internal structure calculation through exploratory factor analysis indicated that 75. 2...|$|R
50|$|Early adopters {{include the}} University of Cambridge Local Examinations Syndicate, (which {{operates}} under {{the brand name}} Cambridge Assessment) which conducted its first major test of e-marking in November 2000. Cambridge Assessment has conducted extensive research into e-marking and e-assessment. The syndicate has published a series of papers, including research specific to e-marking such as: Examining the impact of moving to on-screen marking on <b>concurrent</b> <b>validity.</b>|$|E
50|$|First {{published}} in October 2013, the SIPPI {{was developed by}} Rhys Lewis, Ph.D. and published by Sokanu Interactive. An early version of scales for Holland Codes and Basic interests used items published by the open source Interest Item Pool project. Computer adaptive versions of the personality and interest scales are currently under development. Validation studies are currently being conducted to establish <b>concurrent</b> <b>validity</b> with other popular assessments and job behaviors.|$|E
50|$|<b>Concurrent</b> <b>validity</b> {{refers to}} {{the degree to which}} the {{operationalization}} correlates with other measures of the same construct that are measured at the same time. When the measure is compared to another measure of the same type, they will be related (or correlated). Returning to the selection test example, this would mean that the tests are administered to current employees and then correlated with their scores on performance reviews.|$|E
40|$|Background: There is {{widespread}} interest in measuring organizational readiness to implement evidence-based practices in clinical care. However, {{there are a}} number of challenges to validating organizational measures, including inferential bias arising from the halo effect and method bias- two threats to validity that, while welldocumented by organizational scholars, are often ignored in health services research. We describe a protocol to comprehensively assess the psychometric properties of a previously developed survey, the Organizational Readiness to Change Assessment. Objectives: Our objective is to conduct a comprehensive assessment of the psychometric properties of the Organizational Readiness to Change Assessment incorporating methods specifically to address threats from halo effect and method bias. Methods and Design: We will conduct three sets of analyses using longitudinal, secondary data from four partner projects, each testing interventions to improve the implementation of an evidence-based clinical practice. Partner projects field the Organizational Readiness to Change Assessment at baseline (n = 208 respondents; 53 facilities), and prospectively assesses the degree to which the evidence-based practice is implemented. We will conduct predictive and <b>concurrent</b> <b>validities</b> using hierarchical linear modeling and multivariate regression, respectively. Fo...|$|R
40|$|AbstractThe {{aim of this}} {{research}} is to develop the Analytic Geometry Perception and Attitudes Scale and to examine its validity and reliability analyses. The sample of study consists of 236 university students from Sakarya University. In this study construct and <b>concurrent</b> <b>validities,</b> internal consistency, test-retest reliabilities and item analysis of the scale were examined. As a result of factor analysis for construct validity three factors have emerged which named “attitude toward analytic geometry”, “self efficacy of analytic geometry” and “requirement for achievement”, consist of 26 items and account for the 44. 4 % of the total variance. The internal consistency reliability coefficients were. 79 for attitude toward analytic geometry,. 81 for self efficacy of analytic geometry and. 77 for requirement for achievement. Findings also demonstrated that item-total correlations ranged from. 35 to. 75. Test-retest reliability coefficient was found. 85 for scale. According to these findings the Analytic Geometry Perception and Attitudes Scale can be named as a valid and reliable instrument {{that could be used in}} the field of education...|$|R
50|$|This eight-level {{scale was}} found to possess test-retest and interrater {{reliability}} as well as <b>concurrent</b> and predictive <b>validity.</b> It is widely used clinically and is often paired with the Glasgow Coma Scale in health care facilities.|$|R
50|$|Another {{criticism}} {{is that the}} Versant tests do not measure communicative abilities {{because there are no}} interaction exchanges between live participants. Versant, in Downey et al. (2008) claim that the psycholinguistic competencies that are assessed in their tests underlie a larger spoken language performance. This claim is supported by the <b>concurrent</b> <b>validity</b> data that Versant test scores correlate highly with other well-known oral proficiency interview tests such as ACTFL OPIs or ILR OPIs.|$|E
50|$|<b>Concurrent</b> <b>validity</b> {{differs from}} {{convergent}} validity {{in that it}} focuses {{on the power of}} the focal test to predict outcomes on another test or some outcome variable. Convergent validity refers to the observation of strong correlations between two tests that are assumed to measure the same construct. It is the interpretation of the focal test as a predictor that differentiates this type of evidence from convergent validity, though both methods rely on simple correlations in the statistical analysis.|$|E
50|$|An {{example of}} <b>concurrent</b> <b>validity</b> is a {{comparison}} of the scores of the CLEP College Algebra exam with course grades in college algebra to determine the degree to which scores on the CLEP are related to performance in a college algebra class. An example of predictive validity is {{a comparison of}} scores on the SAT with first semester grade point average (GPA) in college; this assesses the degree to which SAT scores are predictive of college performance.|$|E
3000|$|... (145)[*]=[*] 6.007, p[*]<[*] 0.001), {{revealed}} sufficient construct, <b>concurrent</b> and divergent <b>validity</b> evidence. The {{factor analysis}} demonstrated a unidimensional structure Cronbach alpha (0.953) and ICC (0.889) was high, {{indicating that the}} responses of our sample were internally consistent and stable across time.|$|R
30|$|Although many {{publications}} have sufficiently {{demonstrated that}} both virtual reality and box models are efficient for training laparoscopic skills, {{and that they}} have face, content and construct <b>validity,</b> their <b>concurrent</b> and predictive <b>validity</b> remains largely unknown and demands further studies.|$|R
40|$|Based {{on the web}} survey，new Egogram {{has been}} developed. From a {{preliminary}} survey of college students (N= 117) and two web surveys (N= 564, 1072) ，reliability (internal consistency，temporal stability) and <b>concurrent</b> test <b>validity</b> were confirmed. The new Egogram is composed of Controlling Parent (CP) Nurturing Parent (NP), Adult (A), Natural Child (NC), Adapted Child (AC), Demonstrative Child (DC), Deviation Scale, Question Scale. The new Egogram is characterized that conventional C is divided to NC, AC, and DC...|$|R
