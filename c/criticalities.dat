651|10000|Public
2500|$|By 23 March 2011, neutron {{radiation}} had been observed outside the reactors 13 {{times at the}} Fukushima I site. While this could indicate ongoing fission, a recriticality event was not believed to account for these readings. Based on those readings and TEPCO reports of high levels of chlorine-38, Dr. Ferenc Dalnoki-Veress speculated that transient <b>criticalities</b> may have occurred. However, Edwin Lyman at the Union of Concerned Scientists was skeptical, believing the reports of chlorine-38 to be in error. TEPCO's chlorine-38 report was later retracted. Noting that limited, uncontrolled chain reactions might occur at Fukushima I, {{a spokesman for the}} International Atomic Energy Agency (IAEA) [...] "emphasized that the nuclear reactors won’t explode." ...|$|E
5000|$|K-11 (1965; November-class submarine; two {{refueling}} <b>criticalities)</b> ...|$|E
5000|$|Alternate Schemes: Models, <b>Criticalities</b> and Opportunities panel (organized in {{collaboration}} with CKBG and RUIAP) @EMEM 2017 Free University of Bozen-Bolzano ...|$|E
40|$|International audienceCurrent {{adaptive}} mixed <b>criticality</b> scheduling policies {{assume a}} high <b>criticality</b> mode {{in which all}} low <b>criticality</b> tasks are descheduled to ensure that high <b>criticality</b> tasks can meet timing constraints derived from certification approved methods. In this paper we present a new scheduling policy, Adaptive Mixed <b>Criticality</b> - Weakly Hard, which provides a guaranteed minimum quality of service for low <b>criticality</b> tasks {{in the event of}} a <b>criticality</b> mode change. We derive response time based schedulability tests for this model. Empirical evaluations are then used to assess the relative performance against previously published policies and their schedulability tests...|$|R
40|$|This {{compilation}} of notes {{is presented as}} a source reference for the <b>criticality</b> safety course. At the completion of this training course, the attendee will: be able to define terms commonly used in nuclear <b>criticality</b> safety; be able to appreciate the fundamentals of nuclear <b>criticality</b> safety; be able to identify factors which affect nuclear <b>criticality</b> safety; be able to identify examples of <b>criticality</b> controls as used as Los Alamos; be able to identify examples of circumstances present during <b>criticality</b> accidents; have participated in conducting two critical experiments; be asked to complete a critique of the nuclear <b>criticality</b> safety training course...|$|R
40|$|Hands-on {{experimental}} {{training in}} the physical behavior of multiplying systems is one of ten key areas of training required for practitioners to become qualified in the discipline of <b>criticality</b> safety as identified in DOE-STD- 1135 - 99, ''Guidance for Nuclear <b>Criticality</b> Safety Engineer Training and Qualification''. This document is a <b>criticality</b> safety evaluation of the training activities (or operations) associated with HS- 3200, ''Laboratory Class for <b>Criticality</b> Safety''. These activities utilize the Training Assembly for <b>Criticality</b> Safety (TACS). The original intent of HS- 3200 was to provide LLNL fissile material handlers with a practical hands-on experience {{as a supplement to}} the academic training they receive biennially in HS- 3100, ''Fundamentals of <b>Criticality</b> Safety'', as required by ANSI/ANS- 8. 20 - 1991, ''Nuclear <b>Criticality</b> Safety Training''. HS- 3200 is to be enhanced to also address the training needs of nuclear <b>criticality</b> safety professionals {{under the auspices of the}} NNSA Nuclear <b>Criticality</b> Safety Program...|$|R
50|$|We can use {{the same}} idea of {{enumerating}} peak, pits and pass <b>criticalities</b> in a very complex archipelago of island features, at any size scale, or any range of size scales, including noise at any size scale.|$|E
5000|$|By 23 March 2011, neutron {{radiation}} had been observed outside the reactors 13 {{times at the}} Fukushima I site. While this could indicate ongoing fission, a recriticality event was not believed to account for these readings. Based on those readings and TEPCO reports of high levels of chlorine-38, Dr. Ferenc Dalnoki-Veress speculated that transient <b>criticalities</b> may have occurred. However, Edwin Lyman at the Union of Concerned Scientists was skeptical, believing the reports of chlorine-38 to be in error. TEPCO's chlorine-38 report was later retracted. Noting that limited, uncontrolled chain reactions might occur at Fukushima I, {{a spokesman for the}} International Atomic Energy Agency (IAEA) [...] "emphasized that the nuclear reactors won’t explode." ...|$|E
5000|$|There was {{speculation}} {{although not}} confirmed within criticality accident experts, that Fukushima 3 suffered a criticality accident. Based on incomplete {{information about the}} 2011 Fukushima I nuclear accidents, Dr. Ferenc Dalnoki-Veress speculates that transient <b>criticalities</b> may have occurred there. Noting that limited, uncontrolled chain reactions might occur at Fukushima I, {{a spokesman for the}} International Atomic Energy Agency (IAEA) “emphasized that the nuclear reactors won’t explode.” By March 23, 2011, neutron beams had already been observed 13 times at the crippled Fukushima nuclear power plant. While a criticality accident was not believed to account for these beams, the beams could indicate nuclear fission is occurring. On April 15, TEPCO reported that nuclear fuel had melted and fallen to the lower containment sections of three of the Fukushima I reactors, including reactor three. The melted material was not expected to breach one of the lower containers, which could cause a massive radioactivity release. Instead, the melted fuel is thought to have dispersed uniformly across the lower portions of the containers of reactors No. 1, No. 2 and No. 3, making the resumption of the fission process, known as a [...] "recriticality", most unlikely.|$|E
40|$|Many Mixed <b>Criticality</b> {{scheduling}} algorithms {{have been}} developed with an assumption that lower <b>criticality</b> level tasks may be abandoned to guarantee the schedulability of higher <b>criticality</b> tasks when the <b>criticality</b> level of the system changes. But it is valuable to explore means by which all of the tasks remain schedulable throughout <b>criticality</b> level changes. This thesis introduces a semi-partitioned model which allows all of the tasks to remain schedulable if only a bounded number of cores increase their <b>criticality</b> levels. In such a model, some lower <b>criticality</b> tasks are allowed to migrate instead of being abandoned. Different possible semi-partitioned approaches are proposed and analysed in this thesis. It is concluded from the experiments results that the semi-partitioned algorithm provides improved schedulability and performance of multi-core mixed <b>criticality</b> systems while enables all tasks to keep executing {{in the majority of}} scenarios...|$|R
40|$|As nuclear {{industry}} continues marching from an expert-base support to more procedure-base support, {{it is important}} to revisit the total risk concept to <b>criticality</b> safety. A key objective of <b>criticality</b> safety is to minimize total <b>criticality</b> accident risk. The {{purpose of this paper is}} to assess key constituents of total risk concept pertaining to <b>criticality</b> safety from an operations support perspective and to suggest a risk-informed means of utilizing <b>criticality</b> safety resources for minimizing total risk. A PRA methodology was used to assist this assessment. The <b>criticality</b> accident history was assessed to provide a framework for our evaluation. In supporting operations, the work of <b>criticality</b> safety engineers ranges from knowing the scope and configurations of a proposed operation, performing <b>criticality</b> hazards assessment to derive effective controls, assisting in training operators, response to floor questions, surveillance to ensure implementation of <b>criticality</b> controls, and response to <b>criticality</b> mishaps. In a compliance environment, the resource of <b>criticality</b> safety engineers is increasingly being directed towards tedious documentation effort to meet some regulatory requirements to the effect of weakening the floor support for <b>criticality</b> safety. By applying a fault tree model to identify the major contributors of <b>criticality</b> accidents, a total risk picture is obtained to address relative merits of various actions. Overall, human failure is the key culprit in causing <b>criticality</b> accidents. Factors such as failure to follow procedures, lacks of training, lack of expert support at the floor level etc. are main contributors. Other causes may include lack of effective <b>criticality</b> controls such as inadequate <b>criticality</b> safety evaluation. Not all of the causes are equally important in contributing to <b>criticality</b> mishaps. Applying the limited resources to strengthen the weak links would reduce risk more than continuing emphasis on the strong links of <b>criticality</b> safety support. For example, some compliance failures such as lack of detailed documentation may not be as relevant as the lack of floor support in answering operator's questions during operations. Misuse of resources in reducing lesser causes rather than on major causes of <b>criticality</b> accidents is not risk free without severe consequences. A regulatory mandate without due consideration of total risk may have its opposite effect of increasing the total risk of an accident. A lesson is to be learned here. For regulatory standard/guide development, use of ANS/ANSI standard process, which provides the pedigree of consensus participation, is recommended...|$|R
40|$|Mixed <b>criticality</b> systems contain {{components}} {{of at least}} two <b>criticality</b> levels which execute on a common hardware platform in order to more efficiently utilise re- sources. Due to multiple worst-case execution time estimates, current adaptive mixed <b>criticality</b> scheduling policies assume the notion of a low <b>criticality</b> mode where by a taskset executes under a set of more realistic temporal assumptions and a high <b>criticality</b> mode, in which all low <b>criticality</b> tasks in the taskset are descheduled, to ensure that high <b>criticality</b> tasks can meet more conservative timing constraints derived from certification approved methods. This issue is known as the service abrupt problem and comprises the topic of this work. The principles of real-time schedulability analysis are first reviewed, providing relevant background and theory on which mixed <b>criticality</b> systems analysis is based. The current state-of-the-art of mixed <b>criticality</b> systems scheduling policies on uni-processor systems are then discussed along with the major challenges facing the adoption of such approaches in practice. To address the service abrupt issue this work presents a new policy, Adaptive Mixed <b>Criticality</b> - Weakly Hard which provides a guaranteed minimum quality of service for low <b>criticality</b> tasks {{in the event of a}} <b>criticality</b> mode change. Two offline response time based schedulability tests are derived for this model and dominance relationship proved. Empirical evaluations are then used to assess the relative performance against previously published policies and their schedulability tests, where the new policy is shown to offer a scalable performance trade-off between existing fixed priority preemptive and adaptive mixed <b>criticality</b> policies. The work concludes with possible directions for future research...|$|R
40|$|A {{real-time}} implementation for allocating slack to aperiodic {{processes in}} MetaH [4] is nearing completion. The slack scheduling algorithm used {{is based on}} the slack stealer originally proposed in [2] with practical extensions to allow for support of process <b>criticalities,</b> multiple process streams (of different <b>criticalities)</b> competing for pooled slack and inclusion of run-time overheads in the slack functions. Areas in need of future work are also identified...|$|E
40|$|A WBAN Network {{is one of}} {{the most}} {{critical}} real time networks defined with certain restrictions and constraints. The <b>criticalities</b> of this network are because of the environmental contraints, device restrictions and architectural constraints. These <b>criticalities</b> also raise various issues related to network life, reliability and security. In this paper, an exploration to the WBAN layered model is done. Each layer of this model is here defined along with associated issues relative to different network aspects...|$|E
30|$|The {{different}} project’s {{components are}} detailed {{in the following}} sections, in order to highlight {{the way in which}} the project tackles the emerged <b>criticalities.</b>|$|E
40|$|The ''Range of Neutronic Parameters for Repository <b>Criticality</b> Analyses'' {{technical}} report contains {{a summary of}} the benchmark <b>criticality</b> analyses (including the laboratory critical experiment [LCEs] and the commercial reactor criticals [CRCs]) used to support the validation of the <b>criticality</b> evaluation methods. This report also documents the development of the Critical Limits (CLs) for the repository <b>criticality</b> analyses...|$|R
40|$|The need to {{prioritize}} maintenance activities and investments based on asset <b>criticality</b> and associated risk is seen increasingly {{as important in}} industry. However, proper use of <b>criticality</b> in developing maintenance strategies and plans is still at a nascent stage in most organisations. A review of industrial practices showed that <b>criticality</b> is considered as {{more or less a}} static quantity that is not updated with sufficient frequency as the operating environment changes. This paper examines an electricity distribution network operator (DNO) to show the need to model the changing nature of <b>criticality</b> and ensure an optimal maintenance strategy and plan, aligned to business needs. A Dynamic <b>Criticality</b> Based Maintenance (DCBM) methodology is proposed to identify factors affecting and influencing changes to <b>criticality,</b> monitor and update asset <b>criticality</b> and exploit the dynamic <b>criticality</b> to optimise maintenance decisions. Asset <b>criticality</b> was calculated using network performance, safety, environmental integrity, maintenance cost among other factors as the consequence categories for asset failure. The <b>criticality</b> for each asset (such as transformer circuit breakers, busbars etc.) is calculated as a weighted sum of the impact of supply loss on each of the consequence categories. Variations in some factors such as electricity demand influences changes in asset <b>criticality</b> with time and therefore <b>criticality</b> is modelled as a dynamic process, which is a function of time in addition to other factors. The performance measure used for the maintenance plan is based on the utility network reliability (quality of service) which is measured in terms of Customer Interruptions (CI) and Customer Minutes Lost (CML). The performance targets (for CIs & CMLs) and standard service levels for DNOs are given in the UK's Office of Gas and Electricity Markets (OFGEM). The results showed evidence of changing asset <b>criticality</b> in the network. The benefit of reviewing maintenance plans based on changing <b>criticality</b> was also highlighted...|$|R
40|$|During the 1996 audit, a {{corrective}} action program {{was developed and}} implemented to enhance the <b>Criticality</b> Safety Program at Lawrence Livermore National Laboratory. The <b>Criticality</b> Safety Program at LLNL has been rebuilt to combine a strong core <b>criticality</b> safety program with direct field support to floor operations. Field staff are integrated into the supported facility and program efforts. This method of operation effects {{all aspects of the}} <b>criticality</b> safety program including, as examples, development of <b>criticality</b> safety controls and training...|$|R
40|$|The antiferromagnetic Heisenberg two-leg ladder in the {{presence}} of frustration and an external magnetic field is a system that is characterized by two sorts of quantum <b>criticalities,</b> not only one. One criticality is the consequence of intrinsic frustration, and the other one {{is a result of the}} external magnetic field. So the behaviour of each of them in {{the presence}} of the other deserves to be studied. Using the Jordan-Wigner transformation in dimensions higher than one and bond-mean-field theory we examine the interplay between the field-induced and frustration-induced quantum <b>criticalities</b> in this system. The present work could constitute a prototype for those systems showing multiple, perhaps sometimes competing, quantum <b>criticalities.</b> We calculate several physical quantities like the magnetization and spin susceptibility as functions of field and temperature. Comment: 9 pages, 8 figures, submitted to the Canadian Journal of Physic...|$|E
40|$|This {{study is}} part of a project which aims to study {{innovative}} RFID-based management systems, to optimise logistics in a blood transfusion centre (BTC). In 2009, an analysis of transfusion processes (AS IS 2009) and <b>criticalities</b> was carried out and a RFID-based process reengineering was performed (TO BE 2009). After several technical and management changes in BTC, a further process analysis was carried out and a new model (AS IS 2013) was implemented. The aim of the study is to evaluate efficiency and safety levels of BTC at present, and to compare the models using a coherent methodological approach. A failure modes, effects and <b>criticalities</b> analysis (FMECA) was carried out, in order to highlight <b>criticalities</b> related to patient safety and ad hoc key performance indicators (KPI) were designed and calculated for the two as is models. This paper describes a significant step prior to the design of UHF RFID systems...|$|E
40|$|International audienceIn {{this paper}} {{we present a}} {{probabilistic}} response time analysis for mixed criticality real-time systems running on a single processor according to a fixed priority pre-emptive scheduling policy. The analysis extends the existing {{state of the art}} probabilistic analysis to the case of mixed <b>criticalities,</b> taking into account both the level of assurance at which each task needs to be certified, as well as the possible <b>criticalities</b> at which the system may execute. The proposed analysis is formally presented as well as explained with the aid of an illustrative example...|$|E
40|$|A {{program was}} {{developed}} and implemented at LLNL to provide more detailed, documented <b>Criticality</b> Safety Evaluations of operations in an R&D facility. The new <b>Criticality</b> Safety evaluations were consistent with regulatory requirements of the then new DOE Order 5480. 24, Nuclear <b>Criticality</b> Safety. The evaluations provide a <b>criticality</b> safety basis for each operation in the facility {{in support of the}} facility Safety Analysis Report. This implementation program provided a transition from one method of conducting and documenting <b>Criticality</b> Safety Evaluations to a new method consistent with new regulatory requirements. The program also allowed continued safe operation of the facility while the new implementation level <b>Criticality</b> Safety Evaluations were developed...|$|R
40|$|Current {{adaptive}} mixed <b>criticality</b> scheduling policies as-sume a high <b>criticality</b> mode {{in which}} all low <b>criticality</b> tasks are descheduled to ensure that high <b>criticality</b> tasks can meet timing constraints derived from certification ap-proved methods. In this paper we present a new scheduling policy, Adaptive Mixed Criticality- Weakly Hard, which provides a guaranteed minimum quality of service for low <b>criticality</b> tasks {{in the event of}} a <b>criticality</b> mode change. We derive response time based schedulability tests for this model. Empirical evaluations are then used to assess the rel-ative performance against previously published policies and their schedulability tests. Categories and Subject Descriptors C. 3 [Special-Purpose and Application-Based]: Real-time and embedded system...|$|R
40|$|This paper proposes new net <b>criticality</b> metrics and {{one pass}} design flow {{methodology}} for timing-driven physical design. The proposed net <b>criticality</b> metrics employ net parameters and bounds on net delays derived by the Minimax algorithm. The <b>criticality</b> metrics were mapped to weights in the Cadence Silicon Ensemble DSM Automatic Layout System and produced in one-pass layouts with the clock cycle approximately 27 % faster in average than without <b>criticality</b> evaluation. <b>Criticality</b> metrics {{are independent of}} layout tools producing actual placement and routing. <b>Criticality</b> calculation could be integrated with any layout system that allows weights for individual nets on the placement and routing steps. 1...|$|R
40|$|Enterprise Resource Planning {{has been}} mainly {{implemented}} in private industries {{and there are}} few inquiries of implementation in public healthcare, particularly in Europe. Hence, this paper aims to enrich the debate concerning public healthcare by investigating {{one of the first}} applications in Italy. The research aims at highlighting the benefits brought by the implementation as well as the <b>criticalities</b> encountered. We found that benefits can be classified into four theoretical categories: patients satisfaction, stakeholders satisfaction, operations efficiency, and strategic and performance management. Whereas <b>criticalities</b> such as complexity of the project, process reengineering and staffs involvement can impede the implementation. The novelty and value of the paper lie in a new classification of benefits and <b>criticalities</b> concerning Enterprise Resource Planning implementation in public healthcare. The classification is particularly useful for practitioners and managers who want to implement structured Enterprise Resource Planning in complex organizations such as large public hospitals. We concluded with the limitations of this research and the new avenues of research opened...|$|E
40|$|Combustible dust explosions {{are among}} the most serious <b>criticalities</b> {{affecting}} a broad number of industries around the world. According to a Chemical Safety and Hazard Investigation Board report, more than 50 accidents have occurred only in the U. S. between 2008 and 2012; this datum shows that such a problem requires a relevant attention from both researchers and authorities. The aim of this review is to provide an overview of the currently available techniques able to estimate the severity of a combustible dust explosion. Moreover, the main <b>criticalities</b> arising from these methodologies are discussed, also providing some suggestions for future works...|$|E
40|$|MAAT {{project is}} a large airship project {{presented}} to the last European 7 Framework Program Transport including Aeronautics 2011 deadline. MAAT {{project is a}}n airship based cruiser-feeder transport system. This paper analyzes the <b>criticalities</b> {{of the project and}} the way to upfront these problems which have different natures and possible solutions. Most important <b>criticalities</b> are analyzed both on a methodological point of view and on a direct point of view. Enhanced design methodologies are analyzed in depth to analyze problems, upgrade the project design status continuously and to examine different design options and solutions. An innovative design method has been defined to avoid that problems can produce show stoppers and minimize time delays during project definition...|$|E
40|$|Abstract — The {{impact of}} process {{variations}} increases as tech-nology scales to nanometer region. Under large process vari-ations, {{the path and}} arc/node <b>criticality</b> [18] provide effective metrics in guiding circuit optimization. To facilitate the <b>criticality</b> computation considering the correlation, we define the critical region for the path and arc/node in a timing graph, and propose an efficient method to compute the <b>criticality</b> for paths and arcs/nodes simultaneously by a single breadth-first graph traversal during the backward propagation. Instead of choosing a set of paths for analysis prematurely, we develop a new property of the path <b>criticality</b> to prune those paths with low <b>criticality</b> at very earlier stages, so that our path <b>criticality</b> computation method has linear complexity with respect of the timing edges in a timing graph. To improve the computation accuracy, cutset and path <b>criticality</b> properties are exploited to calibrate the computation results. The experimental results on ISCAS benchmark circuits show that our <b>criticality</b> computation method can achieve high accuracy with fast speed. I...|$|R
40|$|AbstractThis paper {{brings a}} {{discussion}} on the current state-of-the-art in <b>criticality</b> assessment in an international context. It analyzes the status of resource <b>criticality</b> concepts and their calculation methods. The current practice often exhibits a common two-axis assessment framework but the way the two axes are further operationalized shows heterogeneous approaches. Apart from the two-axis as key element of <b>criticality</b> assessment, {{the scope of the}} materials, the role of substitution, the delineation of the supply chain and data, and indicator selection are addressed as key elements. The abovementioned <b>criticality</b> assessment practice is approached in function of the upcoming international debate on <b>criticality.</b> The paper tackles the role of <b>criticality</b> assessment {{in the context of the}} sustainability assessment toolbox and it proposes a clear distinction between <b>criticality</b> assessment and resilience to <b>criticality.</b> The insights offered in the paper may feed the international discussion in the identification of elements that may be harmonized and elements that may be better left open in function of the particular application...|$|R
40|$|The {{regulations}} (governing disposal <b>criticality</b> {{require that}} <b>criticality</b> not be possible, except under certain very unlikely sequences of events, {{and that the}} risk of <b>criticality</b> (probability times consequences) not violate repository performance Guidelines. This paper describes the analysis and results of a probabilistic evaluation of the likelihood that the events/conditions required for a <b>criticality</b> event internal to the waste package (WP) during the postclosure phase of the repository will occur. This analysis supports a determination of licensability as it is affected by <b>criticality</b> control...|$|R
40|$|The works {{focuses on}} the issue of risk in supply chains of {{aeronautical}} industries and aims to develop and set up a toolkit to measure suppliers’ <b>criticalities</b> as well as related impacts on the programmes involving them. Starting from the qualitative procedures generally adopted to estimate risk in supply chain and stated that so-acquired results are approximate and subjective, the work consisted in setting up a fine analysis of <b>criticalities</b> for fifteen operational areas of the supplier (manufacturing, technology, human resources, tooling, finance, market, investments, and so on), which provided a list of major risks per area. Specific indicators have been set up to monitor weak signals that anticipate <b>criticalities</b> and measure risks accordingly. Moreover, specific indicators have been defined able to track risk’s impact on a specific aeronautical programme. Single weights have been assigned to risk’s indicator, single risks and impacts as well as supplier’s areas in order to take in account their contribute to define the position of the supplier into the risk vs. impact map, The work has been carried out at the Alenia Aeronautica Purchase Department where the risk analysis tool has been applied to a group of suppliers involved in the main aeronautical programmes. Results have been shared with the program managers and contingency actions discussed. ...|$|E
40|$|The integration- {{meant as}} real and virtual {{organization}} among various museums- is opening new perspectives to the Italian cultural panorama. The new experiences of network which inevitably pass through <b>criticalities</b> – in the change process, {{in the definition}} of roles and objectives to be shared among th...|$|E
40|$|Purpose – This study {{sets out}} to {{introduce}} an innovative performance measurement system (PMS) for business process outsourcing in facility management (FM) industry and analyse, comprehend and explain the main <b>criticalities</b> in the relationship among the actors involved in an outsourcing non core services contract, which {{is typical of the}} FM business sector. The aim of the tool is to improve performances and enhance their integration towards a partnership. Design/methodology/approach – A case study research has been carried out on a medical service authority and on its FM service provider in order to investigate, understand and explain the main <b>criticalities</b> in their relationships. Starting from a literature analysis on empirical applications of PMS, an adaptation of a balanced scorecard (BSC) has been realized to exceed the <b>criticalities</b> of the case study and to propose a PMS for facility management. Findings – As highlighted in the case study, the need for an improved actors’ partnership has been fulfilled through an innovative approach, i. e. a performance measurement system which shares some indicators among FM service provider and customer. Research limitations/implications – The limitation of this research {{lies in the fact that}} PMS has been designed from a single case study. Despite this fact, the PMS can be easily adapted for wide applications inside the FM business sector. Practical implications – The PMS allows a better integration and coordination of the actors involved in an outsourcing services contract. It could be implemented in FM software tools. Originality/value – The proposed performance measurement system is an innovative integration between the balanced scorecard and service balanced scorecard (SBC) for the facility management service industry. Furthermore, it shares some indicators which solve the main <b>criticalities</b> in the relationships among the actors involved in an outsourcing services contract and enhance partnershi...|$|E
40|$|I h a t e bate Date <b>Criticality</b> Safety Department Manager The {{purpose of}} this {{document}} is to address {{the potential for a}} <b>criticality</b> in the Subsurface Disposal Area because of the proposed in situ grouting process. A <b>criticality</b> safety study was performed to address issues relating to postulated <b>criticality</b> scenarios in the Subsurface Disposal Area for Operable Unit 7 - 13 / 14 i...|$|R
40|$|We review <b>criticality</b> {{theory as}} a prelude to {{consideration}} of <b>criticality</b> of the Grad-Shafranov equation. Novel <b>criticality</b> conditions of ODEs and PDEs are derived, easily evaluated. The possibility that transport barriers are associated with characteristics of the equilibrium equation is explored. We conjecture that equilibrium <b>criticality</b> permits the appearance of new solution branches: the high confinement branch has high poloidal flux gradient in a diamagnetic region of the plasma. Similarly, <b>criticality</b> may lead to loss of solution, which could be related to MHD instability and/or island formationComment: 6 pages, 2 figure...|$|R
5000|$|Failure mode <b>criticality</b> {{assessment}} may be qualitative or quantitative. For qualitative assessment, a mishap probability code {{or number}} is assigned and entered on the matrix. For example, MIL - STD - 882 uses five probability levels:The failure mode may then be charted on a <b>criticality</b> matrix using severity code as one axis and probability level code as the other.For quantitative assessment, modal <b>criticality</b> number [...] is {{calculated for each}} failure mode of each item, and item <b>criticality</b> number [...] is calculated for each item. The <b>criticality</b> numbers are computed using the following values: ...|$|R
