11|33|Public
5000|$|Consumer protection:Product testing; labelling; <b>conformity</b> <b>checks</b> with {{marketing}} standards (e.g. fruit and vegetables) ...|$|E
50|$|<b>Conformity</b> <b>checks</b> and {{integrity}} checks need not covered in all business needs, it’s strictly under the database architecture's discretion.|$|E
40|$|The Water Framework Directive 2000 / 60 /EC (WFD) sets {{an overall}} {{framework}} for water management in Europe. The main instrument for its implementation is the river basin management plan (RBMP) {{and the accompanying}} programme of measures. As we are almost {{in the end of}} the WFD implementation cycle (in 2015), the paper presents the progress regarding the RBMPs developed by each EU 27 member state (MS). A review of the <b>conformity</b> <b>checks</b> regarding the obligation {{and the quality of the}} RBMPs is provided for all EU 27 MS. Special focus is given to Greece attempting a comparative analysis of its RBMPs. Although they comply with the context requirements set by the WFD, there have been problems occurring as consequences intense disputes. Special focus is given in the economic assessment. Different methodologies used and the lack of data are the main problems identified. © 2014 Balaban Desalination Publications. All rights reserved...|$|E
40|$|Abstract. Checking {{whether the}} agreed service quality {{attributes}} are fulfilled or maintained during the service life-cycle {{is a very}} important task for SLA (Service Level Agreement) enforcement. In this paper, we leverage conformance checking techniques developed for computational services to automate the <b>conformity</b> <b>checking</b> of transport & logistics services. Our solution extends the WS-Agreement metamodel to support the definition of frame and specific SLAs. With this extension, we define a new validation operation for the <b>conformity</b> <b>check</b> of transport & logistics SLAs based on CSPs solvers. The key contribution of our work is that, as far as we know, it is the first definition of an automated <b>conformity</b> <b>check</b> solution for long term agreements in the transport & logistics domain. Nonetheless, other domains in which similar SLAs are defined can also benefit from our solution. ...|$|R
40|$|International audienceThe {{field of}} {{construction}} engineering {{is governed by}} an important volume of legal texts. Each of these texts provide a set of requirements by means of sentences written in natural language. These texts support <b>conformity</b> <b>checking</b> process of objects in construction engineering. Automate or at-least semi-automate this <b>conformity</b> <b>checking</b> process is the target of our project. This automation imposes {{to be able to}} make legal requirements processable. Thus, we envisage to rephrase natural language sentences into a set of atomic requirements (i. e a triple:). Further, we must identify between the facts found in a given sentence, the exist relations (e. g sentence = f act 1 AND f act 2 or IF f act 1 THEN f act 2, etc.), expressible using logical operators. For facts extraction, we have used Open Information Extraction-systems. Since they face a drop of precision mainly due to multi-word expressions, provide a method to handle them before OIE itself. Moreover, we also tackle the problem of enumeration items to improve OIEperformance. Using OIE for legal sentences semantics handling, handling of multi-word expressions and contextual phrases and finally computation of relations between facts constitute the originality of this work. Such decomposition is the prerequisite to our target: automatic <b>conformity</b> <b>checking...</b>|$|R
40|$|International audienceThis paper {{presents}} an ontological method {{aimed at the}} capitalization of expert knowledge {{in the context of}} semi-automatic checking model of the conformity of construction projects against a set of construction norms. The efficiency of our ontology-based reasoning model relies on two keystones. First, {{it is based on the}} matching of construction projects represented by RDF graphs to technical conformity queries formalized as SPARQL queries. Second, our reasoning model integrates the meta-knowledge on <b>conformity</b> <b>checking</b> process. Our approach of capitalizing such knowledge is based on the development of semantic annotations of conformity queries and organizing them into a query base. This helps to formalize the expert knowledge in form of expert rules scheduling the matching operations of the checking process. Semantic annotations of conformity queries also help to generate a structured conformity report, which interprets the results of reasoning in terms of <b>conformity</b> <b>checking</b> in construction...|$|R
40|$|ABSTRACT: Ten simple {{sequence}} repeat (SSR) loci {{were used}} to study polymorphism in 54 almond genotypes. All genotypes {{used in this study}} originated from almond-growing areas in Tunisia with different climatic conditions ranging from the sub-humid to the arid and are preserved in the national collection at Sidi Bouzid. Using ten SSR, 130 alleles and 250 genotypes were revealed. In order to develop an identification key for each accession, the data were analysed separately for each microsatellite marker. The most polymorphic mic-rosatellite (CPDCT 042) was used as a first marker. Two microsatellite loci (CPDCT 042 and CPDCT 025) were sufficient to discriminate among all accessions studied. Neighbour-joining clustering and principal coordinate analysis were performed to arrange the genotypes ac-cording to their genetic relationships and origin. The results are discussed in the context of almond collection management, <b>conformity</b> <b>checks,</b> identification of homonyms, and screen-ing of the local almond germplasm. Furthermore, this microsatellite-based key is a first step toward a marker-assisted identification almond database...|$|E
40|$|Specific {{microsatellites}} (SSRs) markers {{were used}} to characterize a set of 32 Tunisian pomegranate (Punica granatum L.) cultivars. Using 13 SSR primers, a total of 40 alleles and 46 genotypes have been identified. As a result, data proved that {{a high level of}} polymorphism characterizes the Tunisian pomegranate germplasm at the DNA level. The derived Neighbour-joining (NJ) dendrogram constructed using DAS genetic distances exhibited a genetic diversity structured independently from the geographical origin of cultivars and their denomination. This result suggested that a common genetic basis may characterize Tunisian pomegranate cultivars despite their phenotypic divergences. Furthermore, based on the multilocus genotypes a cultivar’s identification key has been established and permitted to unambiguously differentiate between varieties. The obtained results are discussed in term of establishment and management of a national collection of pomegranate varieties, <b>conformity</b> <b>checks,</b> identification of homonyms and synonyms, and screening of the local resources. Furthermore, this microsatellite-based key is a first step towards a marker-assisted identification pomegranate database. Peer reviewe...|$|E
40|$|Due to an {{increasing}} number of regulatory restric- tions and a rising product complexity, compliance and safety management have become key issues for enterprises today. Besides the requirements to build safe products, documentation of safety compliance and in-use restrictions have to be archived and published by law. Some research projects have already tackled the problem of visually identifying hazards zones within virtual environments. Other approaches deal with the formal analysis of safety issues in expert systems for <b>conformity</b> <b>checks.</b> What is still missing is the bridge between visual representation and documentation. The virtual reality (VR) approaches do not support storage and processing of identified hazards, furthermore 3 D models have to be prepared and converted to VR formats, which does not allow “online” analysis. Expert systems only cover an abstract, textual definition of hazard zones, which separates the safety domain from design. This paper describes a framework for “product safety information” to identify, track and document hazards and protective measures throughout the product life cycle. The underlying data model supports integration of geometric references into the safety information, similar to the use of product manufacturing information like GD&T...|$|E
40|$|We {{address the}} problem of {{describing}} and analyzing not only functional but also performance properties of software architectures in a formal framework. We thus develop an architectural description language with a precise syntax and semantics and we illustrate the various kinds of analysis that can be conducted on its descriptions, such as architectural compatibility and <b>conformity</b> <b>checking,</b> functional verification, and performance evaluation. The proposed architectural description language is based on stochastically timed process algebras by virtue of their compositionality, which makes them suited to work with at the architectural level...|$|R
40|$|Conformity Study for Austria Directive 2004 / 38 /EC on {{the right}} of {{citizens}} of the Union and their family members to move and reside freely within the territory of the Member StatesThis National Conformity Study has been prepared by Milieu Ltd. in consortium with the Europa Institute, Edinburgh University under Contract No JLS/ 2007 /C 4 / 004 - 30 -CE- 0159638 / 00 - 31. The actual <b>conformity</b> <b>checking</b> was carried out in Austria by Werner Schroeder and was concluded on 1 August. The study {{does not take into account}} any subsequent changes in EU law and national legislation and/or administrative practice. The views expressed herein are those of the consultants alone and do not necessarily represen...|$|R
40|$|This {{contribution}} {{presents a}} Bayesian {{approach to the}} issue of linking of the results from key comparison measurements. A mathematical treatment based on Bayesian statistics for the analysis of the results from two comparisons with some joint participants is described. This robust statistical analysis provides expressions and standard uncertainties for the key comparison reference value (KCRV) and the degree of equivalence (DOE) as well as a <b>conformity</b> <b>check</b> without any assumption on a priority of one of the comparisons. In addition to the derivation of the mathematical formulae to be used for this type of "distributed linking", we also present one synthetic and one real linking example and discuss possible applications of this new linking procedure...|$|R
40|$|The {{foreseen}} Phase 2 pixel upgrades at the LHC {{have very}} challenging {{requirements for the}} design of hybrid pixel readout chips. A versatile pixel simulation platform is as an essential development tool for the design, verification and optimization of both the system architecture and the pixel chip building blocks (Intellectual Properties, IPs). This work is focused on the implemented simulation and verification environment named VEPIX 53, built using the SystemVerilog language and the Universal Verification Methodology (UVM) class library in the framework of the RD 53 Collaboration. The environment supports pixel chips at different levels of description: its reusable components feature the generation of different classes of parameterized input hits to the pixel matrix, monitoring of pixel chip inputs and outputs, <b>conformity</b> <b>checks</b> between predicted and actual outputs and collection of statistics on system performance. The environment has been tested performing a study of shared architectures of the trigger latency buffering section of pixel chips. A fully shared architecture and a distributed one have been described at behavioral level and simulated; the resulting memory occupancy statistics and hit loss rates have subsequently been compared. Comment: 15 pages, 10 figures (11 figure files), submitted to Journal of Instrumentatio...|$|E
40|$|DLR {{has set up}} {{a number}} of {{projects}} to increase flight safety and economics of aviation. Within these activities one field of interest is the development and validation of systems for pilot assistance in order to increase the situation awareness of the aircrew. The basic idea behind these sys-tems is the principal of an ''electronic co-pilot''. All flight phases ("gate-to-gate") are taken into account, but as far as approaches, landing and taxiing are the most critical tasks in the field of civil aviation, special emphasis is given to these operations. Especially under adverse weather conditions the situation awareness of pilots is decreased in these critical flight phases due to the reduced visual range. Therefore, an Enhanced and Synthetic Vision System (ESVS) is inte-grated into the assistance system. Data acquired by weather penetrating sensors are combined with digital terrain data and status information by application of data fusion tech-niques. The resulting description of the situation is given to the pilot via head-up or head-down displays. One promising sensor for Enhanced Vision application is the 35 GHz MMW radar ''HiVision' ' of EADS. This paper is focused on the automatic analysis of HiVi-sion radar images with regard to the requirements for ap-proach, landing, and taxiing. This includes the integrity monitoring of navigation data by <b>conformity</b> <b>checks</b> of da-tabase information with radar data, the detection of obsta-cles on the runway (or/and on taxiways) and the acquisition of navigation information by extracting runway structures from radar images...|$|E
40|$|Energy {{management}} and carbon accounting schemes {{are increasingly being}} adopted as a corporate response to climate change. These schemes often demand the setting of ambitious targets for the reduction of corporate greenhouse gas emissions. There is however only limited empirical insight in the companies’ target setting process and the auditing practice of certifying agencies that evaluate ambition levels of greenhouse gas reduction targets. We studied the target setting process of firms participating in the CO 2 Performance Ladder. The CO 2 Performance Ladder is a new certifiable scheme for energy {{management and}} carbon accounting that {{is used as a}} tool for green public procurement in the Netherlands. This study aimed at answering the question ‘to what extent does the current target setting process in the CO 2 Performance Ladder lead to ambitious CO 2 emission reduction goals?’. The research methods were interviews with relevant stakeholders (auditors, companies and consultants), document reviews of the certification scheme, and an analysis of corporate target levels for the reduction of CO 2 emissions. The research findings showed that several certification requirements for target setting for the reduction of CO 2 emissions were interpreted differently by the various actors and that the <b>conformity</b> <b>checks</b> by the auditors did not include a full assessment of all certification requirements. The research results also indicated that corporate CO 2 emission reduction targets were not very ambitious. The analysis of the target setting process revealed that there was a semi-structured bottom-up auditing practice for evaluating the corporate CO 2 emission reduction targets, but the final assessment whether target levels were sufficiently ambitious were rather loose. The main conclusion is that the current target setting process in the CO 2 Performance Ladder did not necessarily lead to establishing the most ambitious goals for CO 2 emission reduction. This process and the tools to assess the ambition level of the CO 2 emission reduction targets need further improvement {{in order to maintain the}} CO 2 Performance Ladder as a valid tool for green public procurement...|$|E
40|$|International audienceExperts in {{construction}} engineering are overwhelmed by regulatory texts. It {{is a heavy}} task to go through these texts and get an unambiguous list of requirements they contain. Moreover, {{with regard to the}} number of texts and the diversity of their writers, we cannot neglect the possibility of getting inconsistencies. Finally, these requirements are to be put close to digital representation of buildings to detect potential non-conformities. This paper examines these problems and envisions solutions to help experts. We thus envisage to automate detection and extraction of business rules in regulatory texts. Next, we propose to formalise identified requirements as SPARQL queries. These queries will serve for <b>conformity</b> <b>checking</b> on OWL-representation of buildings. Moreover, we plan to leverage these queries to detect inconsistencies in regulatory texts...|$|R
40|$|The {{installation}} of a multifunctional railway portal (or TCCS - Train <b>Conformity</b> <b>Check</b> system) can contribute to improve {{the safety of a}} railway infrastructure. The TCCS can detect the conformity of the trains traveling along the tracks, and can transfer the status information to a main traffic control center. This paper proposes a methodological approach based on Analytic Hierarchy Process (AHP) to evaluate the optimal locations to install a TCCS on a railway section. The eligibility and ranking of the potential sites have been defined with respect to constraints related to the rail line track layout and geometry, the TCCS technological features, and the required safety distance allowing the train to stop. The proposed approach has been applied to a real case study on the Italian railway...|$|R
40|$|International audienceIn {{machining}} workshops, workpieces {{are produced}} according to dimensions known as manufacturing dimensions. For the same workpiece {{and the same}} manufacturing plan, several sets of manufacturing dimensions can be used but none satisfy simultaneously the two main missions workshops need to fulfil: (a) Ensuring conformity of products to their design dimension tolerances (also called blueprint tolerances) and (b) steering machines in order to compensate for tool wear. The set of manufacturing dimensions obtained from the design dimensions using the minimal chain of dimensions method is optimal for a <b>conformity</b> <b>check</b> of workpieces but is practically unusable for steering machines because {{of the complexity of}} its relationships toward the tool correctors and tools dimensions. The pilot dimensions method consists in, on the one hand, identifying and representing these tool correctors and these tool/program dimensions on the production drawings (besides the manufacturing dimensions) and, on other the other hand, determining their correction values through a mathematical set of relations after having measured the manufacturing dimensions on a workpiece. Doing so will strongly reduce adjustment time, reduce the number of workpieces used for adjustments and greatly enhance the quality of workpiece batches...|$|R
40|$|MODIStsp is a "R" package {{devoted to}} automatizing the {{creation}} of time series of rasters derived from MODIS Land Products data. MODIStsp allows to perform several preprocessing steps (e. g., download, mosaicking, reprojection and resize) on MODIS data available within a given time period. Users {{have the ability to}} select which specific layers of the original MODIS HDF files they want to process. They also can select which additional Quality Indicators should be extracted from the aggregated MODIS Quality Assurance layers and, in the case of Surface Reflectance products, which Spectral Indexes should be computed from the original reflectance bands. For each output layer, outputs are saved as single-band raster files corresponding to each available acquisition date. Virtual files allowing access to the entire time series as a single file can be also created. All processing parameters can be easily selected with a user-friendly GUI, although non-interactive execution exploiting a previously created Options File is possible. Stand-alone execution outside an "R" environment is also possible, allowing to use scheduled execution of MODIStsp to automatically update time series related to a MODIS product and extent whenever a new image is available. MODIStsp v 1. 2. 1 Release Notes v 1. 2. 1 was released on 20 / 04 / 2016 Major Changes 	 	Modified format of "R" output time series from rts objects to RasterStack objects with temporal information added in the "z" attribute via setZ() 	 	 	Major changes/improvements in MODIStsp_extract function: 	 		Use of plain rasterstack with "z" attribute instead than rasterstackts 		Use of gdal_rasterize (gdalUtils) instead of rasterize (rgdal) to improve speed. Temporary shapes and rasters necessay are saved in "R" temporary folder and removed automatically 		Fixed bugs on functionality for point/lines shapefiles, according to what specified by the "small" and "small_method" parameters 		Added functionality for retrieving data for small polygons 		Added out_format selection - xts or plain data. frame 		Added possibility to use a shp filename as input directly 		Added <b>conformity</b> <b>checks</b> on inputs 		Added functionality to run without specifying start and end dates 		Added id_field parameter for choosing which column of the input SP object should be used for "naming" the columns of the output 	 	 	 	Removed possibility to use "complex" resampling methods when reprojecting (e. g., bilinear, cubic, etc.) to avoid incorrect resampling on categorical variables and "contamination" of good pixels' data. 	 Minor Changes 	Changed the input method for starting and ending dates selection in the GUI. Now a text field is used 	Added functionaluty for writing data ignore value on ENVI files 	Removed automatic deletion of XML files created by writeRaster to keep metadata information 	Changed names of products in the GUI for products with both TERRA and AQUA dataset to M*D 09 A 1, M*D 13 Q 1, etc [...] . 	Modified code syntax to satisfy R code styling guidelines 	Modified roxygen parameters so that only required functions are imported from imported packages 	Updated and corrected the list of dependencies 	Updated required "R" version to 3. 2, and minimum versions for dependent packages to current versions. 	Added Welcome message 	Updated links to LPDAAC product description pages 	Changed all "print" and "cat" calls to show messages/warnings to "message" or "warning" to allow easy disabling MODIStsp verbose messages 	Using "R" tempfile/tempdir to save vrt files Bug Fixes 	Corrected a bug that threw an error in case incorrect bounding box specifie...|$|E
40|$|Mestrado em Engenharia Alimentar - Instituto Superior de AgronomiaIn this study, {{the data}} of {{foodstuffs}} samples collected at retail and subjected to analytical determinations, {{in the period of}} 2008 to 2010, under the National Sampling Plan (NSP) by ASAE –The Portuguese Authority for Safety Food and Economic, were analyzed. The main objective {{of the study was to}} evaluate the microbiological data in the NSP report and to identify the source of the non <b>conformities,</b> <b>checking</b> the development of the foodstuff groups with higher susceptibility to contamination by microbiological hazards. During the mentioned period 5541 samples were collected among various groups of foodstuffs and the data from 1966 samples submitted to microbiological analysis were studied. The total non conformities of NSP increased from 3. 4 % to 6. 9 % and in 2010 around a third were of microbiological origin. The microbiological non conformities were detected in 3. 8 % (2008), 3. 6 % (2009) and 5. 4 % (2010) of the samples analyzed and mainly observed in meat and meat products, milk and milk-based products. The largest number of non conformities samples in the group of meat and meat products was due to the presence of Salmonella, whereas in the group of milk and milk-based products this was due to the presence of L. monocytogene...|$|R
40|$|International audienceThis paper {{presents}} {{an approach that}} aims to suggest to Construction experts a formal representation of given requirements. When available as formal expressions, requirements are suitable for automatic compliance checking. The goal of <b>conformity</b> <b>checking</b> is {{to answer the question}} " which components of a building project are non-compliant to a set of construction rules? ". When we consider both the size and the complexity of corpora of construction requirements, a computer-aided compliance checking process would be beneficial for experts. Such checking process requires a formal representation of building projects and construction rules. Nowadays, there are various tools for the formal designing of building products obeying to the Industry Foundation Classes (IFC) standard (e. g. Revit Building of Autodesk, ArchiCAD by Graphisoft, and ACTIVe 3 d by ARCHIMEN GROUP). On the other hand, {{to the best of our}} knowledge, there isn't any tool which allows business experts to convert automatically and in a formal language, construction rules written in natural language. We propose an approach which intends to convert automatically natural language requirements into formal expressions. This approach relies on the IfcOWL ontology and represents formal rules as SPARQL queries using the RAINS language as an interim result. RAINS is a controlled natural language (CNL), whose sentences can be transformed automatically into SPARQL queries, and as a CNL it hides the complexity of formal languages...|$|R
40|$|Purpose. Experimental {{definition}} of {{values of the}} dynamic parameters characterizing traffic safety of the rail autobus in tangent and curved track sections and switches, and <b>conformity</b> <b>check</b> to their demands of normative documents. Methodology. Test methods are based on comparison of experimentally determined dynamic qualities of the autobus with their admitted values. As the parameters defining traffic safety, the numerical value of which is resulted further, are used the following ones: the derailment stability coefficient; vertical dynamics coefficients {{in the first and}} second steps of spring suspension; the frame forces; smoothness of movement. Determination of the derailment stability coefficient is performed by a known technique. Vertical dynamics coefficients in the each step of spring suspension are defined as the relation of dynamic vertical bending flexures to magnitudes of their static values corresponding to the set occupancy of the autobus. Findings. Coefficient values of the vertical dynamics of train carriages in the first and second steps of spring suspension, as well as the value of frame forces and parameters of movement smoothness did not exceed the admissible standard values, and was higher than the minimum admissible value. Originality. Values of the parameters characterizing dynamic qualities of new type of the rail autobus are obtained, and possibility of its operation on the main ways of the railways of Ukraine is shown. Practical value. Admissible speeds of the rail autobus traffic on various railway track sections are defined...|$|R
40|$|Since the EURO V {{standards}} for heavy-duty engines, the European emissions legislation requires {{to verify the}} conformity of heavy-duty engines with the applicable emissions certification standards: these provisions are identified as “In Service Conformity” (ISC). It was considered impractical and expensive to adopt an ISC scheme for heavy-duty vehicles requiring the removal of engines from vehicles to test pollutant emissions against legislative limits. Therefore, it was proposed to develop a protocol for in-service <b>conformity</b> <b>checking</b> of heavy-duty vehicles based {{on the use of}} Portable Emission Measurement Systems (PEMS). As a result, ISC testing based on PEMS was introduced in the EURO V and the EURO VI standards. The corresponding administrative and technical provisions were formulated in the European Regulations 582 / 2011 and 64 / 2012. The above route was followed for non-road engines as well: preliminary research activities studied and confirmed the possibility to apply the methods developed for heavy-duty engines with minor modifications. The basis for the introduction of ISC provisions based on the PEMS approach into the European NRMM type-approval legislation has been established in several texts. The NRMM PEMS Pilot Program was launched to facilitate the introduction into the European NRMM emissions legislation of use of PEMS as a tool for ISC. This had to be achieved by improving the technical procedures (e. g. available from the heavy-duty scheme) and increasing the awareness of the different stakeholders about PEMS as a new regulatory tool. JRC. F. 8 -Sustainable Transpor...|$|R
40|$|In {{order to}} improve quality, any {{activity}} performed in garment production enterprises, must adhere to the following principles: the technical documentation must be observed first, and also all resources necessary for the proper functioning of the production process; <b>conformity</b> <b>check</b> {{must be carried out}} to fulfill production goals in advance; the technical specifications and documentation must be implemented and for proper execution there must exist a control method, consisting in discovering defects and correct them. In the garment industry, the situation is more difficult because of the large number of features present in its complex products, and the problems that may arise must be estimated. Thus, for different activities in quality assurance, experiments have been carried out which show that even the measurement results can be affected by human error. The training of inspectors is important inspection requires a high level of judgment in specific cases, which can be acquired only by experience. In many inspection situations, judgment is essential. Therefore, garment manufacturers must boost inspections, {{in order to keep the}} technological process under control. This paper focuses on meeting certain objectives in establishing certain control structures for compliance of processes, by presenting a few criteria. After analyzing quality problems along the process flow, both in terms of the manufacturing process and product quality, we propose customized solutions by product type, to prevent and solve quality issues. This analysis of the control plan for the conformity of the technological processes will improve the production of garment manufacturers, from a technical as well as economical standpoint...|$|R
40|$|In-use testing with Portable Emissions Measurement Systems (PEMS) has {{received}} attention by {{policy makers and}} industry as an effective and cost-efficient means to verify emissions {{of a wide range}} of vehicles. We provide an overview of the state-of-the-art PEMS in-use emissions testing in the current and future European emissions legislation for light-duty and heavy-duty vehicles as well as non-road mobile machinery. For obtaining type approval in European Union (EU), light-duty vehicles have to comply with Euro 6 emission standards from January 2014 onward. In parallel, a new test procedure will complement standard emissions testing in the laboratory to control gaseous and particulate emissions over a wide range of real-world driving conditions. Two candidate procedures are developed at present, i. e., random cycle testing and on-road emissions testing with PEMS. Currently, key challenges are the definition of test conditions and design of a suitable method for data evaluation. For heavy-duty vehicles, in-use testing with PEMS is already enforced in the European Union since 2009. The revision of European requirements will be completed in 2014 and shifts the focus from engine <b>conformity</b> <b>checking</b> towards the assessment of emissions under real-world driving conditions. The feasibility of PEMS for measuring particle mass is currently investigated by an industry-run pilot program. Moreover, the application of PEMS to Stage IV and V engines of non-road mobile machinery is currently under discussion. We conclude that in-use testing with PEMS will play an important role in the future European vehicle emissions legislation. The application of PEMS can effectively control vehicle emissions, may accelerate the adoption of novel emission abatement technologies and thereby contribute to air quality improvements throughout Europe. JRC. F. 8 -Sustainable Transpor...|$|R
50|$|It is {{important}} to note the scope and intent of conformity assessment. The purpose of conformity assessment is to ensure that Ada processors achieve a high degree of conformity with the Ada standard (Ada95 as corrected by TC1). Characteristics such as performance and suitability for a particular application are not specified by the standard, and thus are outside the scope of Ada conformity assessment. Moreover, the ACATS is a set of test programs intended to check broadly for correct implementation; {{it is not possible to}} exhaustively test for conformity. Thus, <b>conformity</b> is <b>checked</b> only to the extent of these tests; processors that are certified as conforming may fail to conform to the standard in ways peculiar to each, under particular circumstances.|$|R
40|$|The European {{emissions}} legislation requires to <b>check</b> the <b>conformity</b> of heavy-duty engines {{with the}} applicable emissions certification standards during the normal life of those engines: {{these are the}} “In Service Conformity” (ISC) requirements. It was considered impractical and expensive to adopt an in-service <b>conformity</b> (ISC) <b>checking</b> scheme for heavy-duty vehicles, which require removal of engines from vehicles to test pollutant emissions against legislative limits. Therefore, it has been proposed to develop a protocol for in-service <b>conformity</b> <b>checking</b> of heavy-duty vehicles based {{on the use of}} Portable Emission Measurement Systems (PEMS). The European Commission through DG ENTR in co-operation with DG JRC launched in January 2004 a co-operative research programme to study the feasibility of PEMS in view of their application in Europe for In-Service Conformity of heavy-duty engines. The technical and experimental activities were started in August 2004 to study the feasibility of PEMS systems and to study their potential application for on-road measurements on heavy-duty vehicles. The main objectives of the above project had been defined as follows: -To assess and validate the application and performance of portable instrumentation relative to each other, and in comparison with alternative options for ISC testing; -To define a test protocol for the use of portable instrumentation within the ISC of heavy-duty vehicles; -To assess on-road data evaluation methods such as the US ‘Not To Exceed’ (NTE) approach and possibly to develop a simplified ones; -To address the need of the European industry, authorities and test houses to go through a learning process with on-vehicle emissions testing. The main objective of the present document is to report on: a. The evaluation of the test protocol, i. e. to judge whether the mandatory data and its quality were appropriate for the final evaluation (S b. The analysis conducted to evaluate the potential of the different data evaluation (Pass/Fail) methods for ISC and in particular their ability to use on-road PEMS emissions data. The candidate methods were categorized into two families: -The "control-area / data reduction methods" (Chapter 4) that use only a part of the data, depending whether the operation points considered are part of a control area and belong to a sequence of consecutive points within this control area. The US-NTE (Not To Exceed) method - already established as an official tool in the United States - falls into this category but variations of the methods could be envisaged (with another control area for instance). -The "averaging window methods" (Chapter 4. 3) that use all the operation data. The main objective of task b. was to answer the following question: “Once the data has been collected correctly, what is the most appropriate method to analyze the test data measured with PEMS and to judge whether the engine is in conformity with the applicable emissions limits?”JRC. F. 9 -Sustainable Transport (Ispra...|$|R
40|$|Abstract. Reuse of high {{confidence}} subsystems {{depends on}} their appropriate modelling and documentation. This paper discusses the different aspects {{that have to be}} considered when modelling a system and its subsystems. We propose a concrete artefact model for integrated reuse from requirements to technical architecture, which satisfies documentation demands with respect to functionality and the context assumed by the subsystem. Based on the artefact model, we describe the steps for <b>conformity</b> and compatibility <b>checking</b> at the development stage of subsystem integration and/or reuse. ...|$|R
40|$|The {{problem of}} {{designing}} a component that {{combined with a}} known part of a system, conforms to a given overall specifica-tion arises in several applications ranging from logic synthesis {{to the design of}} discrete controllers. We cast the problem as solving abstract equations over languages. Language equations can be defined with respect to several language composition op-erators such as synchronous composition,, and parallel com-position,; <b>conformity</b> can be <b>checked</b> by language contain-ment. In this paper we address parallel language equations. Parallel composition arises in the context of modeling delay-insensitive processes and their environments. The parallel com-position operator models an exchange protocol by which an in-put is followed by an output after a finite exchange of internal signals. It abstracts a system with two components with a singl...|$|R
40|$|International audienceIn {{high-speed}} machining {{it is of}} key importance to avoid any collision between the machine tool and the machining setup. If the machining setup has not been assembled correctly by the operator and does not conform to the 3 D CAD model sent to the machining unit, such collisions may occur. This paper presents a new chain-processing-based computer vision system to automatically avoid collision between tool and machining setup components by checking that the actual machining setup is in conformity with the desired 3 D CAD model used to generate the tool trajectory. This computer vision system utilizes a single camera to automatically <b>check</b> <b>conformity</b> {{before the start of}} the machining operation. The proposed solution was tested in different kinds of machining setups, and each step of the proposed chain was evaluated. The results show the robustness of the solution for different kinds of machining setups...|$|R
40|$|Validating {{complex systems}} is {{nowadays}} achieved by simulation of cooperating components. As complex systems {{have to support}} multidisciplinarity and multiformalism it induces these components may be different. Moreover cooperation between them means a data exchange. Exchanged data among various components may have different format and then a match is necessary. The latter is called interoperability, an essential notion. HLA OMT aim {{is to provide a}} template to document the exchanged data and their characteristics and so to promote interoperability. However verification of the document consistence becomes laborious if a huge number of data is exchanged. We propose a way to check a part of the consistence of OMT by using Coloured Petri Nets. We consider the parts consist of data compliance, completeness and structural <b>conformity</b> and we <b>check</b> only the first two ones. To do it, firstly OMT is transformed into a Coloured Petri Net and secondly verification may be achieved by its structure analysis...|$|R
40|$|Quality {{assurance}} {{policies for}} long-term care in France are founded on a law passed in 2002, but the organisation {{of the system is}} still underway. It is principally based on a legal framework that sets out requirements for quality monitoring and quality improvement. Quality assessment is related to outcomes, indicators and guidelines. It pertains to formal care and is related to administrative authorisation and financial conditions. In the public sector, the aim is to develop continuous quality assurance in a system differentiated by internal and external quality assessment. In the private sector, the aim is mainly to <b>check</b> <b>conformity</b> with quality standards, as internal and external quality assurance may be replaced by a certification procedure. A central agency is in charge of enhancing quality through the production of new guidelines but quality supervision {{is the role of the}} funding institution and qualitative results are not publicly available. To date, not many organisations or units have conducted the entire quality assurance process, as the quality of long-term care is ensured by an institutional system that is in the final stages of being structured...|$|R
40|$|From {{the basic}} data and tlie {{previous}} results of priorpapers, {{we have made}} evaluations of the energy released and studied itsvariation. Its pulsative form is confirmed, which suggests several superposedperiods, perhaps of simple multiples of tlie undecenal of solar activity. For steps of a whole unity of m, the total approximated energy is computed. EN and Et may be compared, it being possible to replace one by the other,indifferently, from m = 5 up to m = 7. 5. The compared variation of logEN with N demostrates they are not proportional. The tectonic flux is evaluated {{and we have the}} graphs for 5 and 15 year lapses, from 1901 to I 960, as well as another graph which correspondsto the representative average of these 60 years. A reduction of the mapof seismic activity attained through log (2 E) li 2 -. 60 x 2. 5 is attached, whichrefers the annual flux for every 1000 sq km. This map is analyzed and thecomparative results with the zones of the first seismotectonic sketch publishedby Rey Pastor (1927) are considered. The <b>conformity</b> is <b>checked</b> andthe differences are shown. With Benioff's curve, expressed by 10 u (erg) V 2, we show the accumulationand release of the total elastic strain, S 60 (S E) xh and (S JB) 1 / 2 for everyyear of the instrumental period (1901 - 1960). The cumulative interval (halfa Century) coincides with the return period of the destructive earthquakes,which was estimated through other considerations. We have made a comparative sketch between seismic activity andthe admitted drawing of the Alpine Geosyncline on the Western Mediterreaneanand we suggest a possible rough-draft of the Oval regression at itsWestern end. The alignments of the intermediate shocks, in the AlboranSea and the Betican region, indicate active faults which might associated,perhaps, in a half-close as another oval connected to the Guadalquivir Faultand Southwards...|$|R
40|$|The Governance Committee {{ensures that}} CIP’s {{governance}} {{policies and procedures}} are effective, transparent, and {{in keeping with the}} mission of the Institute. Specifically, the Governance Committee will: a. undertake an annual review of the performance of the Board in terms of its adherence to its governance policies and procedures b. review new policies and procedures of Board, such as the Strategic Plan, to <b>check</b> <b>conformity</b> with existing governance policies and procedures c. address issues of governance that may be referred to the Committee throughout the year, and recommend appropriate actions to the Board of Directors d. identify any gaps in the Governance Policy and procedures of the Institute and propose new policies and procedures, as needed, including in the first instance, setting a process for dealing with violations of conflicts of interest or Code of Conduct arising from a Board member or staff of CIP. e. enforce, investigate, and make recommendations to Council as necessary on issues related to the Code of Conduct and Conflict of Interest policies that apply to members of the Board, committees and the subcommittees and staff. 2. Usual Complement – 3 The Chair of the Board of Directors as Chair, plus two Directors of the Board. The Committee can, at its discretion, call upon additional advisors to contribute expertise. 3. Terms of Office Chair: 3 year term of office Members: 1 year, renewable for one additional ter...|$|R
40|$|The use of {{stereotactic}} body {{radiation therapy}} (SBRT) for lung treatments is very popu-lar in radiotherapy clinics. This {{is because of}} its better results {{compared to the other}} treatments. The development of flattening filter free (FFF) beams has given a new per-spective to this treatment. In this thesis, the commissioning of SBRT FFF beam for cen-tral lung treatment was aimed. Two spherical volumes of diameter 3 cm (PTV 3) and 6 cm (PTV 6) representing the planning target volumes were created within the central lung area in Alderson phantom. The dose plan for the treatment was done for 6 MV FFF photon beam using stereotactic radiotherapy (SRT) volume modulated arc therapy (VMAT) and dose fractions of 4 Gy, 7. 5 Gy, 11 Gy and 18 Gy. Dose distribution calculations were performed in Eclipse treatment planning system (Varian Medical Systems, Palo Alto, CA). Radiation Ther-apy Oncology Group (RTOG) protocol was utilized to obtain the required dose confor-mity within the target. Dose plan verification was done by ionization chamber matrix detector (in two different setups: combined with the cubic solid water phantom and mounted in the gantry) and radiochromic film inserted within the cubic solid water phantom. Irradiation was done with Varian TrueBeam STx linear accelerator (Varian Medical Systems, Palo Alto, CA). Results of dose <b>conformity</b> were <b>checked</b> using dose-volume histograms (DVH) and were in accordance with the RTOG protocol. Moreover, measured and calculated dose distribution data were compared using gamma analysis with the acceptance criteria of 3 %, 3 mm. According to the suggested criteria (less than 5 %) of technical reports se-ries (TRS) 398, the general average values of the disagreement between measured and calculated data obtained from the ion chamber matrix detector for PTV 6 were within the required limits, 4. 2 % for both of the detector setups. However, {{this was not the case}} for PTV 3 because the general average values were 6. 2 % and 6. 5 % for each of the de-tector setups. Main reasons for these unacceptable results were mostly due to the small field sizes and poor resolution of the matrix detector. Film measurements showed very satisfactory results regarding the shape of the measured dose profile compared to the calculated one. The only problem with film results was the unacceptable absolute dose difference between these two dose profiles, approximately 10 %, which most likely was due to inaccuracies from film calibration or post processing. Based on those results, it was concluded that the commissioning of the 6 MV FFF pho-ton beam for SBRT lung treatment was partly successful. Before its clinical application, further studies are needed related to the mentioned dosimetric uncertainties...|$|R
40|$|PosterUnderground karst is {{an object}} that can be studied using 3 D approaches, and new {{technological}} breakthroughs now allow revisiting subterranean karst. Lasergrammetry in particular allows fast dense point clouds acquisition. Their protocol allows to shape analyses without any contact and to reduce the time spent within the cave. When studying underground topographic matters, pipe sections are usually considered as spindly skeletons. Stations are sampled one after another, in polar geometry (distance, direction, angle). Gallery sections allow to recognize large changes in conduit dimensions. Lasergrammetry, based on Lidars uses, help to acquire very numerous point measurements during minimal time. The point cloudis then meshed to obtain a TIN model. This oneis significantly helpful to inform about neighbouring information and topology. This is of prior importance {{to the rest of}} the analyses, in particular to identify morphology breaks or segmentation operations. The model <b>conformity</b> must be <b>checked.</b> Once these treatments are achieved, it is possible to analyse the numerical clone. These analyzes wereapplied to different objects: drains, walls, speleothems [...] . It was shown that the use of 3 D analysis on a numerical clone may be fruitful. It allows breakthroughs compared to classical approaches. First of all, it allows investigation of all the objects. Indeed, height, darkness, limited residence time, conservation constraints and limited moves within high patrimonial value objects are limiting factors to an in situ analysis. This completeness when investigating underground karst allows to notably statistically validate results that, used to be limited and reduced to preselected objects. The aim here was to explore the potential of 3 D modelling of underground environments, keeping in mind the ever geomorphologic issues that drive our research...|$|R
