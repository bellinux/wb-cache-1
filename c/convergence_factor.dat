164|293|Public
40|$|Abstract. We {{consider}} multigrid {{methods for}} symmetric positive definite linear systems. We present a new algebraic convergence analysis of two-grid schemes with inexact {{solution of the}} coarse grid system. This analysis allows us to bound the <b>convergence</b> <b>factor</b> of such perturbed two-grid schemes, assuming only a certain bound on the <b>convergence</b> <b>factor</b> for the unperturbed scheme (with exact solution of the coarse grid system). Applied to multigrid methods with the standard W-cycle, this analysis shows that if the <b>convergence</b> <b>factor</b> of the (unperturbed) two-grid method is uniformly bounded by σ< 1 / 2, then the <b>convergence</b> <b>factor</b> of the multigrid method is uniformly bounded by σ/(1 −σ). The analysis is purely algebraic and requires only that pre- and postsmoothing are applied in a symmetric way. It covers both geometric and algebraic multigrid methods, and the coarse grid matrix may be of any type (not necessarily Galerkin) ...|$|E
40|$|A {{complete}} {{characterization of}} the <b>convergence</b> <b>factor</b> can be very useful when analyzing the asymptotic convergence of an iterative method. We will here establish a formula for the <b>convergence</b> <b>factor</b> of the method called residual inverse iteration, which is a method for nonlinear eigenvalue problems and a generalization of the well known inverse iteration. The formula for the <b>convergence</b> <b>factor</b> is explicit and only involves quantities associated with the eigenvalue the iteration converges to, in particular the eigenvalue and eigenvector. Besides deriving the explicit formula we also use the formula to characterize the convergence of the method. In particular, we derive a formula for the first order expansion when the shift {{is close to the}} eigenvalue. The residual inverse iteration allows some freedom in the choice of a vector r_k. In the analysis we characterize the convergence for different choices of r_k. We use the explicit formula for the first order expansion to show that the <b>convergence</b> <b>factor</b> approaches zero when the shift approaches the eigenvalue for an arbitrary choice of r_k. Moreover, we show that using an approximation of the left eigenvector as r_k as proposed in the literature, is natural since it results in accurate eigenvalue estimates; but it is not necessarily optimal in terms of the first order expansion of the <b>convergence</b> <b>factor</b> when the shift is close to the eigenvalue. The <b>convergence</b> <b>factor</b> also allows us to completely characterize the behavior of the method for double eigenvalues. For non-semisimple double eigenvalues {{it turns out that the}} <b>convergence</b> <b>factor</b> is one, implying slow or no convergence at all. For the case of a semisimple eigenvalue, the method behaves in a similar as for a simple eigenvalue, except that when converging, the iterates converge to the subspace of eigenvectors, not necessarily to a particular eigenvector. nrpages: 19 status: publishe...|$|E
40|$|A {{complete}} {{characterization of}} the <b>convergence</b> <b>factor</b> can be very useful when analyzing the asymptotic convergence of an iterative method. We will here establish a formula for the <b>convergence</b> <b>factor</b> of the method called residual inverse iteration, which is a method for nonlinear eigenvalue problems and a generalization of the well known inverse iteration. The formula for the <b>convergence</b> <b>factor</b> is explicit and only involves quantities associated with the eigenvalue the iteration converges to, in particular the eigenvalue and eigenvector. Besides deriving the explicit formula we also use the formula to characterize the convergence of the method. In particular, we derive a formula for the first order expansion when the shift {{is close to the}} eigenvalue. The residual inverse iteration allows some freedom in the choice of a vector rk. In the analysis we characterize the convergence for different choices of rk. We use the explicit formula for the first order expansion to show that the <b>convergence</b> <b>factor</b> approaches zero when the shift approaches the eigenvalue for an arbitrary choic...|$|E
40|$|Local Fourier {{analysis}} (LFA) is {{a useful}} tool in predicting the <b>convergence</b> <b>factors</b> of geometric multigrid methods (GMG). As is well known, on rectangular domains with periodic boundary conditions this analysis gives the exact <b>convergence</b> <b>factors</b> of such methods. In this work, using the Fourier method, we extend these results by proving that such analysis yields the exact <b>convergence</b> <b>factors</b> for a wider class of problems...|$|R
50|$|Charles Napoleon Moore (1882-1967) was an American {{mathematician}} at Bowling Green State University {{who worked}} on <b>convergence</b> <b>factors.</b>|$|R
50|$|The {{summation}} by <b>convergence</b> <b>factors</b> of Laplace-Stieltjes integrals {{outside their}} half plane of convergence, Mathematische Zeitschrift 67 (1957) 10-31.|$|R
40|$|This paper {{addresses}} the optimal scaling of the ADMM method for distributed quadratic programming. Scaled ADMM iterations are first derived for generic equalityconstrained quadratic problems and then {{applied to a}} class of distributed quadratic problems. In this setting, the scaling corresponds to the step-size and the edge-weights of the underlying communication graph. We optimize the <b>convergence</b> <b>factor</b> of the algorithm {{with respect to the}} step-size and graph edge-weights. Explicit analytical expressions for the optimal <b>convergence</b> <b>factor</b> and the optimal step-size are derived. Numerical simulations illustrate our results. QC 20140912 </p...|$|E
40|$|Abstract. We study {{convergence}} in weighted convolution algebras L 1 (ω) on R +, {{with the}} weights chosen {{such that the}} corresponding weighted space M(ω) of measures is also a Banach algebra and is the dual space of a natural related space of continuous functions. We determine <b>convergence</b> <b>factor</b> η for which weak ∗-convergence of {λn} to λ in M(ω) implies norm convergence of λn ∗ f to λ ∗ f in L 1 (ωη). We find necessary and sufficent conditions which depend on ω and f and also find necessary and sufficent conditions for η to be a <b>convergence</b> <b>factor</b> for all L 1 (ω) and all f in L 1 (ω). We also give some applications {{to the structure of}} weighted convolution algebras. As a preliminary result we observe that η is a <b>convergence</b> <b>factor</b> for ω and f if and only if convolution by f is a compact operator from M(ω) (or L 1 (ω)) to L 1 (ωη). ...|$|E
40|$|In this paper, we {{consider}} solutions of Toeplitz systems Anu = b where the Toeplitz matrices An are generated by nonnegative functions with zeros. Since the matrices An are ill-conditioned, the <b>convergence</b> <b>factor</b> of classical iterative methods, {{such as the}} damped Jacobi method, will approach 1 as the size n of the matrices becomes large. Here we propose to solve the systems by the multigrid method. The cost per iteration for the method is of O(n log n) operations. For a class of Toeplitz matrices which includes weakly diagonally dominant Toeplitz matrices, we show that the <b>convergence</b> <b>factor</b> of the two-grid method is uniformly bounded below 1 independent of n and the full multigrid method has <b>convergence</b> <b>factor</b> depends only {{on the number of}} levels. Numerical results are given to illustrate the rate of convergence. Key Words: Multigrid Method, Toeplitz Matrices. 1 Introduction In this paper we discuss the solutions of ill-conditioned symmetric Toeplitz systems A n u = b by the multig [...] ...|$|E
40|$|AbstractThis paper {{deals with}} predictor-corrector {{iteration}} of Runge—Kutta—Nyström (RKN) methods for integrating initial-value problems for special second-order ordinary differential equations. We consider RKN correctors based on both {{direct and indirect}} collocation techniques. The paper focuses on the <b>convergence</b> <b>factors</b> and stability regions of the iterated RKN correctors. It {{turns out that the}} methods based on direct collocation RKN correctors possess smaller <b>convergence</b> <b>factors</b> than those based on indirect collocation RKN correctors. Both families of methods have sufficiently large stability boundaries for nonstiff problems...|$|R
40|$|AbstractConcerning the {{approximation}} of periodic functions {{by means of}} singular convolution integrals having positive trigonometric kernels, an equivalence theorem of P. P. Korovkin on <b>convergence</b> <b>factors,</b> i. e., on the Fourier coefficients of the kernel, is of great importance. A simple inversion formula between <b>convergence</b> <b>factors</b> and trigonometric moments of a general kernel immediately delivers an extension of this theorem to a class of singular integrals with not necessarily positive kernels {{as well as a}} simplified proof of the original result. The new theorem is applied to three representative examples of oscillating kernels...|$|R
40|$|Fairly {{early in}} the {{development}} of the theory of summability of divergent series, the concept of <b>convergence</b> <b>factors</b> was recognized as of fundamental importance in the subject. One of the pioneers in this field was C. N. Moore, the author of the book under review [...] Moore classifies <b>convergence</b> <b>factors</b> into two types. In type I he places the factors which have only the property that they preserve convergence for a convergent series or produce convergence for a summable series. In type II he places the factors which not only maintain or produce convergence but have the additional property tha...|$|R
40|$|New {{comparison}} theorems {{are presented}} comparing the asymptotic <b>convergence</b> <b>factor</b> of iterative methods for {{the solution of}} consistent (as well as inconsistent) singular systems of linear equations. The asymptotic <b>convergence</b> <b>factor</b> of the iteration matrix T is the quantity γ(T) =max{|λ|,λ ∈ σ(T),λ � = 1 }, where σ(T) is the spectrum of T. In the new theorems, no restrictions are imposed on the projections associated with the two iteration matrices being compared. The splittings of the well-known example of Kaufman [SIAM J. Sci. Statist. Comput., 4 (1983), pp. 525 – 552] satisfythe hypotheses of the new theorems...|$|E
40|$|In {{this paper}} we study the {{solution}} of large sparse augmented linear systems. The generalized modified extrapolated SOR (GMESOR) method is considered. We find sufficient conditions for GMESOR to converge and determine its optimal iteration parameters and the corresponding minimum value of its <b>convergence</b> <b>factor.</b> Under {{the assumption that the}} eigenvalues of a key matrix are real it is shown that optimum GMESOR becomes equivalent to optimum GSOR [1], [2] whose <b>convergence</b> <b>factor</b> equals to the one of the Conjugate Gradient (CG) method. For comparison, we develop a similar analysis for the Generalized Modified Preconditioned Simultaneous Displacemen...|$|E
40|$|AbstractIn this paper, multigrid methods with {{residual}} scaling {{techniques for}} symmetric positive definite linear systems are considered. The idea of perturbed two-grid methods proposed in [7] {{is used to}} estimate the <b>convergence</b> <b>factor</b> of multigrid methods with residual scaled by positive constant scaling factors. We will show that if the convergence factors of the two-grid methods are uniformly bounded by σ (σ< 0. 5), then the convergence factors of the W-cycle multigrid methods are uniformly bounded by σ/(1 −σ), whether the residuals are scaled at some or all levels. This result extends Notay’s Theorem 3. 1 in [7] to more general cases. The result also confirms the viewpoint that the W-cycle multigrid method will converge sufficiently well {{as long as the}} <b>convergence</b> <b>factor</b> of the two-grid method is small enough. In the case where the <b>convergence</b> <b>factor</b> of the two-grid method is not small enough, by appropriate choice of the cycle index γ, we can guarantee that the <b>convergence</b> <b>factor</b> of the multigrid methods with residual scaling techniques still has a uniform bound less than σ/(1 −σ). Numerical experiments are provided to show that the performance of multigrid methods can be improved by scaling the residual with a constant factor. The convergence rates of the two-grid methods and the multigrid methods show that the W-cycle multigrid methods perform better if the convergence rate of the two-grid method becomes smaller. These numerical experiments support the proposed theoretical results in this paper...|$|E
40|$|A general local Fourier {{analysis}} for overlapping block smoothers on triangular grids is presented. This analysis is {{explained in a}} general form for its application to problems with different discretizations. This tool is demonstrated for two different problems: a stabilized linear finite element discretization of Stokes equations and an edge-based discretization of the curl-curl operator by lowest-order Nédélec finite element method. In this latter, special Fourier modes {{have to be considered}} in order to perform the analysis. Numerical results comparing two- and three-grid <b>convergence</b> <b>factors</b> predicted by the local Fourier analysis to real asymptotic <b>convergence</b> <b>factors</b> are presented to confirm the predictions of the analysis and show their usefulness...|$|R
50|$|We can {{notice that}} even third order method is a {{variation}} of Newton's method. We see the Newton's steps are multiplied by some factors. These factors are called the <b>convergence</b> <b>factors</b> of the variations, which are useful for analyzing the rate of convergence. See Gander(1978).|$|R
40|$|AbstractThe nonnull {{distribution}} of some statistics, used for testing Σ 1 = Σ 2 are obtained as mixtures of incomplete beta functions {{as well as}} mixtures of incomplete gamma functions. The introduction of the <b>convergence</b> <b>factors</b> and certain recurrence relations are useful in the computation {{of the power of}} the tests as well as computation of exact percentage points for tests of significance...|$|R
40|$|Abstract—Two new {{improved}} recursive least-squares adap-tive-filtering algorithms, {{one with}} a variable forgetting factor {{and the other with}} a variable <b>convergence</b> <b>factor</b> are proposed. Optimal forgetting and convergence factors are obtained by mini-mizing the mean square of the noise-free a posteriori error signal. The determination of the optimal forgetting and convergence fac-tors requires information about the noise-free a priori error which is obtained by solving a known minimization problem. Simulation results in system-identification and channel-equaliza-tion applications are presented which demonstrate that improved steady-state misalignment, tracking capability, and readaptation can be achieved relative to those in some state-of-the-art com-peting algorithms. Index Terms—Adaptive filters, adaptive-filtering algorithms, recursive least-squares algorithms, forgetting factor, <b>convergence</b> <b>factor.</b> I...|$|E
3000|$|... 2, {{which is}} the <b>convergence</b> <b>factor</b> for the noise, may be enlarged. Then, the noise {{suppression}} generated by the CS iteration will be weak. However, comparing the variation trends of the several factors following N, C [...]...|$|E
40|$|AbstractIterative {{methods for}} the {{solution}} of consistent singular systems of linear equations are governed by the <b>convergence</b> <b>factor</b> of the iteration matrix T, i. e., by the quantity γ(T) =max{|λ|,λ∈σ(T),λ≠ 1 }, where σ(T) is the spectrum of T. Theorems are presented comparing the <b>convergence</b> <b>factor</b> of two iterative methods. The comparison {{is based on the}} relationship between the matrices of the splittings. A cone other than the usual nonnegative hyperoctant is used to define the order used in this comparison. Although this cone is based on the (unknown) projection onto the null-space of a matrix, the characterization provided in the paper allows, in specific instances, the cone to be readily computable...|$|E
40|$|Algebraic multigrid (AMG) {{is one of}} {{the most}} {{efficient}} and scalable parallel algorithms for solving sparse linear systems on unstructured grids. However, for large 3 D problems, the coarse grids that are normally used in AMG often lead to growing complexity in terms of memory use and execution time per AMG V-cycle. Sparser coarse grids, such as those obtained by the parallel modified independent set (PMIS) coarsening algorithm, remedy this complexity growth but lead to nonscalable AMG <b>convergence</b> <b>factors</b> when traditional distance-one interpolation methods are used. In this paper, we study the scalability of AMG methods that combine PMIS coarse grids with long-distance interpolation methods. AMG performance and scalability are compared for previously introduced interpolation methods as well as new variants of them for a variety of relevant test problems on parallel computers. It is shown that the increased interpolation accuracy largely restores the scalability of AMG <b>convergence</b> <b>factors</b> for PMIS-coarsened grids, and in combination with complexity reducing methods, such as interpolation truncation, one obtains a class of parallel AMG methods that enjoy excellent scalability properties on large parallel computers...|$|R
40|$|AbstractInterval {{operators}} of a function strip obtained by splitting the given Lipschitz matrix A = B − C are discussed. Using these operators we can construct {{a sequence of}} intervals which converges to a limit interval, if the set of solutions of a given function strip is not empty. Under certain conditions the limit interval is a fixed interval of the corresponding interval operator. The different fixed intervals and <b>convergence</b> <b>factors</b> for some splittings are determined...|$|R
40|$|In {{this paper}} we present {{efficient}} multigrid methods for systems of partial differential equations that {{are governed by}} a dominating grad-div operator. In particular, we show that distributive smoothing methods give multigrid <b>convergence</b> <b>factors</b> that are independent of problem parameters and of the mesh sizes in space and time. The applications range from model problems to secondary consolidation Biot’s model. We focus on the smoothing issue, and mainly solve academic problems on Cartesian staggered grids. Copyright c...|$|R
40|$|This paper {{presents}} optimal {{scaling of}} the alternating directions method of multipliers (ADMM) algorithm {{for a class}} of distributed quadratic programming problems. The scaling corresponds to the ADMM step-size and relaxation parameter, {{as well as the}} edge-weights of the underlying communication graph. We optimize these parameters to yield the smallest <b>convergence</b> <b>factor</b> of the algorithm. Explicit expressions are derived for the step-size and relaxation parameter, {{as well as for the}} corresponding <b>convergence</b> <b>factor.</b> Numerical simulations justify our results and highlight the benefits of optimally scaling the ADMM algorithm. Comment: Submitted to the IEEE Transactions on Signal Processing. Prior work was presented at the 52 nd IEEE Conference on Decision and Control, 201...|$|E
40|$|In {{the recent}} years, {{advancement}} in telecommunication technologies {{and the increasing}} demand of data rate has motivated the optimized use of frequency spectrum. One technique for the efficient usage of frequency is Smart Antenna system. In this work, the proposed novel least mean square algorithm (No-LMS) build and studied the results as comparative work with results of two another algorithms called Standard LMS algorithm(S-LMS), and normalized LMS algorithm (N-LMS). The computer simulation work results based No-LMS algorithm have better performance refer to obtain the optimum <b>convergence</b> <b>factor</b> (CF) and shows that robustness smart system, good tracking capability, and high adaptation accuracy than the other algorithms. The smart antenna system {{that is based on}} LMS-algorithms for all types (S-LMS),(N-LMS),and(No-LMS) show that this system is affected by the <b>convergence</b> <b>factor,</b> the computer simulation results shows the minimum mean square error (MSE = 0. 007) is obtained for the value of <b>convergence</b> <b>factor</b> equal to (0. 2). The test of the three algorithms for different values of signal to noise ratio (SNR) show that the(No-LMS) algorithm gives the minimum MSE values compared with the two those obtain from other algorithms...|$|E
40|$|International audienceThis {{paper is}} {{the second part of}} a study dealing with the {{application}} of a global-in-time Schwarz method to a one dimensional diffusion problem defined on two non-overlapping subdomains. In the first part, we considered that the diffusion coefficients were constant and possibly discontinuous. In the present study, we address the problem for spatially variable coefficients with a discontinuity at the interface between subdomains. For this particular case, we derive a new approach to determine analytically the <b>convergence</b> <b>factor</b> of the associated algorithm. The theoretical results are illustrated by numerical experiments with Dirichlet-Neumann and Robin-Robin interface conditions. In the Robin-Robin case, thanks to the <b>convergence</b> <b>factor</b> found at the analytical level, we can optimize the convergence speed of the Schwarz algorithm...|$|E
40|$|The nonnull {{distribution}} of some statistics, used for testing [Sigma] 1 = [Sigma] 2 are obtained as mixtures of incomplete beta functions {{as well as}} mixtures of incomplete gamma functions. The introduction of the <b>convergence</b> <b>factors</b> and certain recurrence relations are useful in the computation {{of the power of}} the tests as well as computation of exact percentage points for tests of significance. Nonnull distributions hypergeometric functions of matrix argument zonal polynomial mixtures of beta functions and gamma functions...|$|R
40|$|Standard Gibbs {{sampling}} {{applied to}} a multivariate normal distribution with a specified precision matrix is equivalent in fundamental ways to the Gauss-Seidel iterative solution of linear equations in the precision matrix. Specifically, the iteration operators, {{the conditions under which}} convergence occurs, and geometric <b>convergence</b> <b>factors</b> (and rates) are identical. These results hold for arbitrary matrix splittings from classical iterative methods in numerical linear algebra giving easy access to mature results in that field, including existing convergence results for antithetic-variable Gibbs sampling, REGS sampling, and generalizations. Hence, efficient deterministic stationary relaxation schemes lead to efficient generalizations of Gibbs sampling. The technique of polynomial acceleration that significantly improves the convergence rate of an iterative solver derived from a symmetric matrix splitting may be {{applied to a}}ccelerate the equivalent generalized Gibbs sampler. Identicality of error polynomials guarantees convergence of the inhomogeneous Markov chain, while equality of <b>convergence</b> <b>factors</b> ensures that the optimal solver leads to the optimal sampler. Numerical examples are presented, including a Chebyshev accelerated SSOR Gibbs sampler applied to a stylized demonstration of low-level Bayesian image reconstruction in a large 3 -dimensional linear inverse problem. Comment: 33 pages, 4 figure...|$|R
40|$|A single grid {{local mode}} {{analysis}} {{is used to}} predict the smoothing properties of numerical schemes for solving the Navier-Stokes equations with factorization based on Stone's Strongly Implicit Method. Four difference approximations for the convection terms are considered, namely, hybrid, central, second-order upwind, and third-order upwind. Smoothing factors from the analysis are compared with practical <b>convergence</b> <b>factors</b> in a multigrid method for flow over a backward facing step and {{it is found that}} the local mode analysis correctly predicts the effects of Reynolds number and higher-order schemes...|$|R
40|$|We {{study the}} extent of {{macroeconomic}} convergence/divergence among euro area countries. Our analysis focuses on four variables (unemployment, inflation, relative prices and the current account), and seeks to uncover {{the role played by}} monetary union as a <b>convergence</b> <b>factor</b> by using non-euro developed economies and the pre-EMU period as control samples...|$|E
40|$|Abstract: We discuss {{extended}} one-step {{methods of}} order three for the numerical solution of delay-differential equations. A convergence theorem and the numerical studies regarding the <b>convergence</b> <b>factor</b> {{of these methods}} are given. Also, we investigate the stability properties of these methods. The results of the theoretical studies are illustrated by numerical examples...|$|E
40|$|A quantum-electrodynamical {{description}} of the self-energy in which the interaction is propagated with the velocity of light instead of instantaneously {{gives rise to a}} modification of the photon propagator identical with the <b>convergence</b> <b>factor.</b> The self-energy is discussed in relation to the static polarization induced in the vacuum due to the presence of an electron itself...|$|E
40|$|Abstract. We {{present a}} new {{formulation}} of multigrid, the so-called tensor-product multigrid method, {{which can be}} used to solve Lyapunov equations. These matrix equations are of considerable importance in control theory and model reduction. Since they are formulated on a tensor product space, they are of possibly very large dimension and one needs an efficient solver like multigrid with optimal chosen components. We show that this can be done by computing the <b>convergence</b> <b>factors</b> with Local Fourier Analysis adapted for this tensor-product multigrid method...|$|R
40|$|In {{this paper}} we study {{the use of}} long {{distance}} interpolation methods with the low complexity coarsening algorithm PMIS. AMG performance and scalability is compared for classical as well as long distance interpolation methods on parallel computers. It is shown that the increased interpolation accuracy largely restores the scalability of AMG <b>convergence</b> <b>factors</b> for PMIS-coarsened grids, and in combination with complexity reducing methods, such as interpolation truncation, one obtains a class of parallel AMG methods that enjoy excellent scalability properties on large parallel computers...|$|R
40|$|New sum rules {{from current}} algebra valid in {{the limit of}} large {{negative}} fourmomentum squared of the current are obtained; some of these depend upon commutators of space-components of the current densities. They contain <b>convergence</b> <b>factors</b> which make their validity plausible on most models of high-energy behavior, with the Regge-pole model being one of them. With one exception, their utility con-sists of placing constraints upon models of hadrons designed to saturate the current algebra scheme. (Submitted to Phys. Rev.) Work supported in p‘art by the U. S. Atomic Energy Commission and the Nationa...|$|R
