17|2221|Public
5000|$|In telecommunication, a <b>coded</b> <b>set</b> {{is a set}} of {{elements}} onto which another set {{of elements}} has been mapped according to a code.|$|E
50|$|Other <b>coded</b> <b>set</b> of {{laws have}} existed {{before the first}} Constitutions were {{developed}} having some similar purpose and functions, like the United Kingdom's 1215 Magna Carta or the Virginia Bill of Rights of 1776.|$|E
5000|$|... #Caption: Color-coding hot- and cold-water faucets (taps) {{is common}} in many {{cultures}} but, as this example shows, the coding may be rendered meaningless because of context. The two faucets (taps) probably were sold as a <b>coded</b> <b>set,</b> but the code is unusable (and ignored), {{as there is a}} single water supply.|$|E
30|$|Figure  5 {{compares the}} BERs between system {{adopting}} OZCZ <b>code</b> <b>set</b> and system adopting ZCC <b>code</b> <b>set.</b> The results are calculated for time delays within ZCZ length Z[*]=[*] 3. For ZCC <b>code</b> <b>set,</b> only in-phase cross-correlation is zero. For OZCZ <b>code</b> <b>set,</b> {{all of the}} cross-correlations within the ZCZ are zeros. Therefore, the system adopting OZCZ <b>code</b> <b>set</b> performs better than that adopting ZCC <b>code</b> <b>set,</b> which verifies the theoretical analysis of the performance, presented in Section 4.|$|R
3000|$|... 2) in dB. Considering {{conditions}} (12) and (13) of an orthogonal <b>code</b> <b>set,</b> it {{is clear}} that the smaller the values of ASPs and CPs of a nearly orthogonal <b>code</b> <b>set</b> are, the closer the <b>code</b> <b>set</b> is to an orthogonal <b>code</b> <b>set.</b>|$|R
5000|$|Despite its name, Code 128 {{does not}} have 128 {{distinct}} symbols, so it cannot represent 128 code points directly. To represent all 128 ASCII values, it shifts among three <b>code</b> <b>sets</b> (A, B, C). Together, <b>code</b> <b>sets</b> A and B cover all 128 ASCII characters. <b>Code</b> <b>set</b> C is used to efficiently encode digit strings. The initial subset is selected by using the appropriate start symbol. Within each <b>code</b> <b>set,</b> some of the 103 data code points are reserved for shifting {{to one of the}} other two <b>code</b> <b>sets.</b> The shifts are done using code points 98 and 99 in <b>code</b> <b>sets</b> A and B, 100 in <b>code</b> <b>sets</b> A and C and 101 in <b>code</b> <b>sets</b> B and C to switch between them): ...|$|R
50|$|From the 1980s {{most of the}} S cars {{was placed}} into the Z type {{carriage}} sets, and from the mid-1990s were also added as additional cars in the N type sets. Today the 5 BS cars in V/Line service are placed in a single carriage set coded SZ7 (formerly SN7), along with a single BCZ carriage. The BS V/Line cars are in a Z <b>coded</b> <b>set</b> because the BCZ car is a classed as a Z.|$|E
5000|$|... “Judith Hall’s {{translations}} {{of the ancient}} poet known as J II read as richly researched and imaginatively restored for a contemporary audience. The only catch is that J II never existed [...] [...] [...] For her latest book, Three Trios, Hall concocted the alter ego of J II, a Jewish female poet {{who lived in the}} sixth century B.C.E. who wrote the Apocryphal book of Judith as well as a mysterious, <b>coded</b> <b>set</b> of pagan poems associated with the cult of Dionysius. These ‘translations’ emit the same earthiness and sensuality of the best ancient erotic poetry but are framed in Hall’s contemporary language - not stale, but sexy[...] [...] [...] The book is such a complete forgery that it includes a scholarly introduction to J II and footnotes throughout. All of Hall’s efforts add up to a powerful, imaginative experiment in poetry.” American Poet, The Journal of the Academy of American Poets ...|$|E
40|$|In {{this paper}} I conduct a Foucauldian {{discourse}} {{analysis of a}} political speech given by Brendon Nelson in 2006 when the Australian Minister for Defence in the Howard Coalition Government. The speech connects conceptualisations of terror, globalization, education and literacy {{as part of a}} whole of government security strategy. The analysis examines this speech {{as an example of a}} liberal way of governing the conduct of diverse and unpredictable populations. My analysis suggests that the apparatus of government has been strategically used in order to biopolitically contain the rise of complex social forces and protect a set of homogenous cultural values. The purposes of education and uses of literacy are seen as instruments for the inscription of a <b>coded</b> <b>set</b> of values understood to be synonymous with civil society...|$|E
30|$|It is {{impossible}} to design an orthogonal <b>code</b> <b>set</b> that perfectly satisfies both (12) and (13). Hence, an alternative is to design a <b>code</b> <b>set</b> that satisfies the conditions as closely as possible. In this paper, we call such a <b>code</b> <b>set</b> a nearly orthogonal <b>code</b> <b>set.</b>|$|R
30|$|It is {{proved that}} the new <b>code</b> <b>set</b> is still an OZCZ <b>code</b> <b>set.</b>|$|R
5000|$|<b>Code</b> <b>Set</b> Manager: [...] Helps {{drive the}} {{organization}} of user defined reference data and <b>Code</b> <b>Sets</b> across an enterprise.|$|R
40|$|Automatic {{verbatim}} coding {{technology is}} essential in many contexts in which, either because of {{the sheer size of}} the dataset we need to code, or because of demanding time constraints, or because of cost-effectiveness issues, manual coding is not a viable option. However, in some of these contexts the accuracy standards imposed by the customer may be too high for today’s automated verbatim coding technology; this means that human coders may need to devote some time to inspecting (and correcting where appropriate) the most problematic autocoded verbatims, with the goal of increasing the accuracy of the <b>coded</b> <b>set.</b> We discuss a software tool for optimising the human coders ’ work, i. e. a tool that minimises the amount of human inspection required to reduce the overall error down to a desired level, or that (equivalently) maximises the reduction in the overall error achieved for an available amount of human inspection work...|$|E
40|$|The use of {{discussion}} forums {{as a means}} of promoting collaboration and interaction between distance education students is increasing {{as a result of the}} growing popularity of online learning. The transcripts of these discussion forums have provided researchers an opportunity to analyse the interactions between participants and investigate evidence of cognitive and metacognitive activity. This paper outlines some of the methodologies adopted by researchers who have attempted to measure evidence of cognitive processes and critical thinking among discussion forum participants. It also investigates the use of computers in the content analysis process and describes the use of automated tools to analyse discussion forum transcripts. The paper then introduces a computerised tool, which has been designed with the aim of allowing different content analysis methodologies to be compared. The paper describes how the tool was used to analyse the discussion forum transcripts from a first year undergraduate degree course and discusses how the results obtained using the tool compared to a manually <b>coded</b> <b>set</b> of results...|$|E
40|$|If we know more, we {{can achieve}} more. " This adage also applies to {{communication}} networks, where {{more information about the}} network state translates into higher sumrates. In this paper, we formalize this increase of sum-rate with increased knowledge of the network state. The knowledge of network state is measured {{in terms of the number}} of hops, h, of information available to each transmitter and is labeled as h-local view. To understand how much capacity is lost due to limited information, we propose to use the metric of normalized sum-capacity, which is the h-local view sum-capacity divided by global-view sum capacity. For the cases of one and two-local view, we characterize the normalized sum-capacity for many classes of deterministic and Gaussian interference networks. In many cases, a scheduling scheme called maximal independent graph scheduling is shown to achieve normalized sum-capacity. We also show that its generalization for 1 -local view, labeled <b>coded</b> <b>set</b> scheduling, achieves normalized sum-capacity in some cases where its uncoded counterpart fails to do so. Comment: Submitted to Special Issue of the IEEE Transactions on Information Theory on Interference Networks, Apr 201...|$|E
5000|$|Although <b>code</b> <b>set</b> C uses one {{code symbol}} to {{represent}} two digits, {{it does not}} always produce a more compact <b>code</b> than <b>code</b> <b>sets</b> A or B. Using <b>code</b> <b>set</b> C saves one symbol per two digits, but costs a mode-shift symbol to enter and exit the set. Thus, it only worth using if there are enough consecutive digits. For example, encoding the string [...] "X00Y" [...] with <b>code</b> <b>set</b> A or B requires 7 code symbols (...) , while using <b>code</b> <b>set</b> C for the [...] "00" [...] {{would result in a}} code 8 symbols long (...) [...]|$|R
40|$|In this paper, a new large {{spreading}} <b>code</b> <b>set</b> with {{a uniform}} low cross-correlation is proposed. The proposed <b>code</b> <b>set</b> {{is capable of}} (1) {{increasing the number of}} assigned user (capacity) in a multicarrier code division multiple access (MC-CDMA) system and (2) reducing the peak-to-average power ratio (PAPR) of an orthogonal frequency division multiplexing (OFDM) system. In this paper, we derive a new <b>code</b> <b>set</b> and present an example to demonstrate performance improvements of OFDM and MC-CDMA systems. Our proposed <b>code</b> <b>set</b> with <b>code</b> length of N has K= 2 N+ 1 number of codes for supporting up to (2 N+ 1) users and exhibits lower cross correlation properties compared to the existing spreading <b>code</b> <b>sets.</b> Our results with subcarrier N= 16 confirm that the proposed <b>code</b> <b>set</b> outperforms the current pseudo-orthogonal carrier interferometry (POCI) <b>code</b> <b>set</b> with gain of 5 dB at bit-error-rate (BER) level of 10 - 4 in the additive white Gaussian noise (AWGN) channel and gain of more than 3. 6 dB in a multipath fading channel...|$|R
3000|$|... is the {{criterion}} value of criteria j and <b>code</b> <b>set</b> i, cv_j is the mean value of criteria j over all different <b>code</b> <b>sets,</b> and R [...]...|$|R
40|$|This note is {{intended}} as a supplement and clarification to the proof of Theorem 3. 3 of [1]; namely, it is consistent that b = ℵ 1 yet for every ultrafilter U on ω there is a ≤ ∗ chain {fξ: ξ ∈ ω 2 } such that {fξ/U: ξ ∈ ω 2 } is cofinal in ω/U. The general outline of the the proof remains the same. In other words, a ground model is taken which satisfies 2 ℵ 0 = ℵ 1 and {{in which there is}} a ♦ω 2 sequence {Dξ: ξ ∈ ω 2 } such that for every X ⊆ ω 2 there is a stationary set of ordinals, µ, such that cof(µ) = ω 1 and such that X ∩ µ = Dµ. Actually, a coding will be used to associate with subsets of ω 2, names for subsets on ω in certain partial orders. The details of this coding will be ignored except to state that c(Dη) will denote the <b>coded</b> <b>set</b> and that if Pω 2 = lim{Pξ: ξ ∈ ω 2 } is the finite support iteration of ccc partial orders of size no greater than ω 1 and 1 ⊩P...|$|E
40|$|Normal {{fibroblasts}} {{in medium}} containing 0. 02 mM CaCl 2 arrested growth within 24 hr, whereas Duchenne muscular dystrophy fibroblasts {{continued to grow}} for 5 days, albeit at 40 % of their rate in standard medium (1. 8 mM CaCl 2). Moreover, Duchenne cells in calcium-deficient medium showed an enhanced rate of protein synthesis (60 % over the rate in standard medium), whereas normal cells were unaffected. Previously we described a general assay for detection of mutant cells by using herpes simplex virus I replication as a probe of cellular function. By altering the growth medium, one can elicit changes in viral DNA replication that depend upon cellular differences. Duchenne fibroblasts in calcium-deficient low-serum (0. 5 %) medium supported viral replication at a rate 7 - to 10 -fold greater than did normal cells infected under the same conditions. Using this viral assay, we have successfully identified all 10 samples of a blind <b>coded</b> <b>set</b> of Duchenne muscular dystrophy, normal, and heterozygote cells. In addition, differences of a lower magnitude were found between these cell strains as measured by cellular growth or protein synthesis. Therefore, a cell's ability to grow and support viral replication in calcium-deficient medium {{can be used to}} readily distinguish Duchenne muscular dystrophy fibroblasts from normal ones. These results suggest that the viral assay {{could be used as a}} prenatal diagnostic test. A defect related to calcium metabolism may be fundamental to this disease...|$|E
40|$|Abstract {{copyright}} UK Data Service {{and data}} collection copyright owner. The Northern Ireland Household Sample of Anonymised Records (SAR) is a 1 % sample of households and all individuals in those households. It is a hierarchical file allowing linkages between individuals. The SARs were drawn from the fully <b>coded</b> <b>set</b> of Census records returned by households and institutions. They therefore omit wholly imputed households and also households that were missed by the Census. The NI Household SAR contains 81 variables, {{similar to those in}} the Individual file. However, the structure of the file allows a large number of other variables to be derived. The sampling strategy used is similar to that used in GB, however, while in GB only 10 % of cases were fully coded, in Northern Ireland all cases were fully coded. Consequently the NI file was not drawn from a pre-existing 10 % sample. New variables have been created for the hierarchical household file since summary information about a household can be computed from data about the individuals in that household. Further information, including guides and other documentation, may be found on the Cathie Marsh Centre for Survey Research Samples of Anonymised Records (SARS) website. Main Topics : Variables included in the 1991 NI Household SAR include (for entire or household/individual members) : age, sex, marital status, employment status, religion, occupation, industry, social class, accommodation, bath/shower and indoor toilet facilities, tenure, economic position and social class of family head; number of pensioners/students/sick persons/persons with long-term illness/economically active and inactive/retired/employed and unemployed/under 16 -year-olds/dependants in the household...|$|E
50|$|The Current Procedural Terminology (CPT) <b>code</b> <b>set</b> is {{a medical}} <b>code</b> <b>set</b> {{maintained}} by the American Medical Association through the CPT Editorial Panel. The CPT <b>code</b> <b>set</b> (copyright protected by the AMA) describes medical, surgical, and diagnostic services and is designed to communicate uniform information about medical services and procedures among physicians, coders, patients, accreditation organizations, and payers for administrative, financial, and analytical purposes.|$|R
30|$|The {{correlation}} {{properties of}} multiple access codes dominate {{the performance of}} OCDMA systems. In this paper, a construction method of the OZCZ <b>code</b> <b>set</b> is proposed. The correlation properties have been proved and discussed. The performance of the VLC-QS-CDMA system adopting the proposed OZCZ <b>code</b> <b>set</b> has been analyzed taking into account effects of the intensity, shot, and thermal noise. The BER performance of this system is comparing with that adopting ZCC <b>code</b> <b>sets.</b> The numerical results of performance analysis show that the new <b>code</b> <b>set</b> can eliminate intensity noise completely and improve the system performance when path delay is considered.|$|R
40|$|Abstract — A new {{complete}} complementary <b>code</b> <b>set</b> {{with zero}} correlation window (ZCW) is constructed {{and it can}} be seen as a natural extension of conventional complete complementary code without ZCW. The construction method of this <b>code</b> <b>set</b> is motivated by that of Loose Synchronous (LS) code used in LAS-CDMA system. The main property of the new complementary <b>code</b> <b>set</b> of order 4 is that it can provide twice the number of code as the conventional LS code under the condition of same ZCW. The construction method of the new <b>code</b> <b>set</b> and the proof of the properties are shown in this paper...|$|R
40|$|An {{antigen capture}} {{immunoassay}} to detect West Nile (WN) virus antigen in infected mosquitoes and avian tissues has been developed. With this assay purified WN virus was detected at {{a concentration of}} 32 pg/ 0. 1 ml, and antigen in infected suckling mouse brain and laboratory-infected mosquito pools could be detected when the WN virus titer was 10 (2. 1) to 10 (3. 7) PFU/ 0. 1 ml. In a blindly <b>coded</b> <b>set</b> of field-collected mosquito pools (n = 100), this assay detected WN virus antigen in 12 of 18 (66. 7 %) TaqMan-positive pools, whereas traditional reverse transcriptase PCR detected 10 of 18 (55. 5 %) positive pools. A sample set of 73 organ homogenates from naturally infected American crows was also examined by WN virus antigen capture immunoassay and TaqMan {{for the presence of}} WN virus. The antigen capture assay detected antigen in 30 of 34 (88. 2 %) TaqMan-positive tissues. Based upon a TaqMan-generated standard curve of infectious WN virus, the limit of detection in the antigen capture assay for avian tissue homogenates was approximately 10 (3) PFU/ 0. 1 ml. The recommended WN virus antigen capture protocol, which includes a capture assay followed by a confirmatory inhibition assay used to retest presumptive positive samples, could distinguish between the closely related WN and St. Louis encephalitis viruses in virus-infected mosquito pools and avian tissues. Therefore, this immunoassay demonstrates adequate sensitivity and specificity for surveillance of WN virus activity in mosquito vectors and avian hosts, and, in addition, it is easy to perform and relatively inexpensive compared with the TaqMan assay...|$|E
30|$|Perception, therefore, {{reveals itself}} as an {{implicit}} preption {{of the body to}} respond and act, and a type of understanding springs from it whose nature is in fact eminently pragmatic and does not in itself determine any “semantic” representation of the object. Rather than being, for example, identified and recognised on the grounds of its form, meaning or function, in a word its belonging to an already classified, <b>coded</b> <b>set,</b> the said object would therefore be perceived and recognised simply as something that can be grasped by the hand. “F 5 and AIP neurons only respond to certain features of objects (their shape, size, inclination, etc.), and this selectivity is significant in that these features are interpreted as just as many systems of visual affordances and potential motor acts. Whereas the neurons populating the lower cerebral cortex areas code profiles, colours and wefts of objects, processing the information selected in images that, once memorised, would enable them to be recognised in their visual features. But is this enough to resolve the anatomical distinction between the ventral and dorsal routes in the functional opposition between vision-for-perception and vision-for-action? We do not think so – unless perception is reduced to an iconic representation of objects, the portrayal of a thing, independent from any where or how, and action reduced to an intention that discriminates between how and perhaps where, but {{has nothing to do with}} what. Unless, that is, the perceptive process is relegated to a mere identification of figures (ideas, in the literal sense of the word), corrected of any motor meaningfulness and raised to the rank of single possible vehicles of meaning, and the sense of the action broken up into a simple succession of movements in themselves devoid of any objective correlative” (Rizzolatti and Sinigaglia 2006, p. 49 - 50).|$|E
40|$|Abstract {{copyright}} UK Data Service {{and data}} collection copyright owner. The 1991 Household Sample of Anonymised Records for Great Britain (SARs) is a 1 % sample of households and all individuals in those households in Great Britain. It is a hierarchical file allowing linkages between individuals. The geographical base of the 1991 Household SAR is the Registrar General's Standard Regions (the South East is split into Inner and Outer London and {{the remainder of the}} South East). The SARs were drawn from the fully <b>coded</b> <b>set</b> of Census records returned by households and institutions. They therefore omit wholly imputed households and also households that were missed by the Census. The 1991 Household SAR contains 67 variables, similar to those in the Individual file (held under SN 7210). However, the structure of the file allows a large number of other variables to be derived. Many new variables have been created for the hierarchical household file since summary information about a household can be computed from data about the individuals in that household. Both 1991 SARs, Household and Individual, were selected from the 10 % sample of the 1991 Census. The 1991 Household SAR was selected first. Households were ordered geographically by county and enumeration district in England and Wales, by region and output area in Scotland. They were then grouped into ten households at a time and one household was selected at random from each group. The sampled records were then scrambled to prevent geographical tracing within a SAR area. The 1991 Household SAR approximates to a simple stratified random sample of households, although counts of individuals in the household file are subject to the effects of clustering. Further information, including guides and other documentation, may be found on the Cathie Marsh Centre for Survey Research Samples of Anonymised Records website. Main Topics : Variables included in the 1991 Household SAR are(for entire or household/individual members) : age, sex, marital status, employment status, occupation, industry, social class, accommodation, bath/shower and indoor toilet facilities, tenure, economic position and social class of family head; number of pensioners/students/sick persons/persons with long-term illness/economically active and inactive/retired/employed and unemployed/under 16 -year-olds/dependants in the household. <br...|$|E
5000|$|EUC-TW is a variable-width {{encoding}} {{that supports}} US-ASCII and 16 planes of CNS 11643, {{each of which}} is 94x94. It is a rarely used encoding for traditional Chinese characters as used in Taiwan. Big5 is much more common. A character in US-ASCII (G0, <b>code</b> <b>set</b> 0) is encoded as a single byte in GL( [...] 0x21-0x7E) and a character in CNS 11643 plane 1 (<b>code</b> <b>set</b> 1) is encoded as two bytes in GR (0xA1-0xFE). A character in plane 1 through 16 of CNS 11643 (<b>code</b> <b>set</b> 2) is encoded as four bytes with the first byte always being 0x8E(Single Shift 2) and the second byte indicating the plane (the plane number is obtained by subtracting 0xA0 from the second byte). The third and fourth bytes are in GR (0xA1-0xFE). Note that the plane 1 of CNS 11643 is encoded twice as <b>code</b> <b>set</b> 1 and a part of <b>code</b> <b>set</b> 2. UTF-8 is becoming more common than EUC-TW, as with most code pages.|$|R
40|$|A {{letter report}} {{issued by the}} General Accounting Office with an {{abstract}} that begins "Consistently classifying, defining, and distinguishing among the range of medical services provided today [...] from diagnoses to treatments [...] is critical for reimbursing providers and analyzing health care utilization, outcomes, and cost. Codes serve this role by assigning each distinct service a unique identifier. Health care providers, such as hospitals and physicians, report medical conditions and the health-related services they have provided to patients on medical records. In August 2000, the Department of Health and Human Services (HHS) adopted two standard <b>code</b> <b>sets</b> for reporting medical procedures: (1) the International Classification of Diseases, 9 th Revision, Clinical Modification, Volume 3 (ICD- 9 -CM Vol. 3); and (2) the Current Procedural Terminology (CPT). Despite HIPAA's goals for administrative simplification, many representatives {{of the health care}} industry have expressed concern that the individual limitations of these <b>code</b> <b>sets</b> result in inefficiencies in record keeping and data reporting. GAO found that, given the 18 -month time frame allotted to HHS under HIPAA for adopting standard <b>code</b> <b>sets,</b> ICD- 9 -CM Vol. 3 and CPT were practical options for HIPAA standard <b>code</b> <b>sets</b> despite some limitations. Both <b>code</b> <b>sets</b> meet almost all of the criteria for standard <b>code</b> <b>sets</b> recommended by HHS's HIPAA implementation teams. For example, they improve the efficiency and {{meet the needs of the}} health care industry, have low additional costs and administrative burdens associated with their implementation, and are consistent with other HIPAA standards. In addition, each of these <b>codes</b> <b>sets</b> meets a criterion for procedural <b>code</b> <b>sets</b> recommended by the National Committee on Vital and Health Statistics. ...|$|R
3000|$|By {{using the}} design method {{described}} in Section 3.1. 3, we have designed a nearly orthogonal polyphase <b>code</b> <b>set</b> with length L= 128 and P= 4 phases for N= 3 radars: specifically, we have obtained the 3 × 128 <b>code</b> <b>set</b> matrix S=[s [...]...|$|R
40|$|Abstract {{copyright}} UK Data Service {{and data}} collection copyright owner. The 1991 Individual Sample of Anonymised Records for Great Britain (SARs) represents a 2 % sample of individuals enumerated in households and communal establishments in the 1991 Census. It consists of almost 1. 2 million individual records. The SARs were drawn from the fully <b>coded</b> <b>set</b> of census records returned by households and institutions. They therefore omit wholly imputed households and also households that were missed by the Census. In total, 278 geographical areas are identified on the Individual SAR and include all large local authority districts {{with a population of}} at least 120, 000 in the 1989 mid-year estimates. Smaller local authorities have been grouped together to form areas with populations over 120, 000. The Individual SAR was selected from the 10 % sample of the 1991 Census from the remaining households after the removal of the Household SAR. This ensured that there were no overlapping cases in the two samples. Individuals in the remaining households were stratified into groups of nine, and two individuals were selected from each group at random. Individuals in communal establishments were stratified into groups of five, and one individual was selected at random from each group. The records were then scrambled to prevent the geographical tracing within a SAR area. In the Individual file there are two potential sources of clustering which arise in the sampling process. First, individuals are clustered into households in the selection of the 1 % sample and second, the removal of the household SAR from the 1 % sample implies a further clustering into households. Nonetheless, the Individual SAR approximates to a simple random sample. Further information, including guides and other documentation, may be found on the Cathie Marsh Centre for Survey Research Samples of Anonymised Records website. Main Topics : Variables included in the 1991 Individual SAR are: age, sex, marital status, employment status, occupation, industry, social class, accommodation, bath/shower and indoor toilet facilities, tenure, economic position and social class of family head; and some limited information on other members of household, e. g. number of persons with long-term illness, number of pensioners and number of earners. <br...|$|E
40|$|Establishing space {{communication}} between ground facilities and other satellites is a painstaking task that requires many precise calculations dealing with relay time, atmospheric conditions, and satellite positions, {{to name a}} few. The Space Communications Emulation Facility (SCEF) team here at NASA is developing a facility that will approximately emulate the conditions in space that impact {{space communication}}. The emulation facility is comprised of a 32 node distributed cluster of computers; each node representing a satellite or ground station. The objective of the satellites is to observe the topography of the Earth (water, vegetation, land, and ice) and relay this information {{back to the ground}} stations. Software originally designed by the University of Kansas, labeled the Emulation Manager, controls the interaction of the satellites and ground stations, as well as handling the recording of data. The Emulation Manager is installed on a Linux Operating System, employing both Java and C++ programming codes. The emulation scenarios are written in extensible Markup Language, XML. XML documents are designed to store, carry, and exchange data. With XML documents data can be exchanged between incompatible systems, which makes it ideal for this project because Linux, MAC and Windows Operating Systems are all used. Unfortunately, XML documents cannot display data like HTML documents. Therefore, the SCEF team uses XML Schema Definition (XSD) or just schema to describe the structure of an XML document. Schemas are very important because they have the capability to validate the correctness of data, define restrictions on data, define data formats, and convert data between different data types, among other things. At this time, in order for the Emulation Manager to open and run an XML emulation scenario file, the user must first establish a link between the schema file and the directory under which the XML scenario files are saved. This procedure takes place on the command line on the Linux Operating System. Once this link has been established the Emulation manager validates all the XML files in that directory against the schema file, before the actual scenario is run. Using some very sophisticated commercial software called the Satellite Tool Kit (STK) installed on the Linux box, the Emulation Manager is able to display the data and graphics generated by the execution of a XML emulation scenario file. The Emulation Manager software is written in JAVA programming code. Since the SCEF project is in the developmental stage, the source code for this type of software is being modified to better fit the requirements of the SCEF project. Some parameters for the emulation are hard <b>coded,</b> <b>set</b> at fixed values. Members of the SCEF team are altering the code to allow the user to choose the values of these hard coded parameters by inserting a toolbar onto the preexisting GUI...|$|E
5000|$|For example, {{given the}} string [...] "098x1234567y23", savings on barcode length using <b>code</b> <b>set</b> C are {{achieved}} {{only if it}} is applied to middle part of the string. For the beginning and ending part of the string, switching to <b>code</b> <b>set</b> C is not effective. As there are an odd number of digits {{in the middle of the}} string, the odd one must be use a different <b>code,</b> <b>set,</b> but it makes no difference whether this is the first or last; 16 symbols are required in either case: , or [...]|$|R
5000|$|For {{the purpose}} of {{computing}} the check symbol, the shift and code-switch symbols are treated the same as any other symbol in the bar code. The checksum is computed over the symbol values, without regard for which <b>code</b> <b>set</b> is active at the time. For instance the <b>code</b> <b>set</b> C value [...] "33" [...] and the <b>code</b> <b>set</b> B value [...] "A" [...] are both {{considered to be a}} Code 128 value of 33, and the check digit is computed based on the value of 33 times the symbol's position within the barcode.|$|R
50|$|In late 2013, the Expense <b>Code</b> <b>set</b> was {{reworked}} and ratified.|$|R
5000|$|In late 2013, the Activity <b>Code</b> <b>set</b> was updated and ratified.|$|R
