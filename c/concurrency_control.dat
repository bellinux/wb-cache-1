2088|85|Public
25|$|Seamless, low {{overhead}} {{integration with}} any <b>concurrency</b> <b>control</b> mechanism, with neither changing any transaction's operation scheduling or blocking it, nor adding any new operation.|$|E
25|$|Heterogeneity: Global {{serializability}} {{is achieved}} across multiple transactional objects (e.g., database management systems) with different (any) <b>concurrency</b> <b>control</b> mechanisms, without {{interfering with the}} mechanisms' operations.|$|E
25|$|In <b>concurrency</b> <b>control</b> of databases, {{transaction}} processing (transaction management), and other transactional distributed applications, Global serializability (or Modular serializability) is a property {{of a global}} schedule of transactions. A global schedule is the unified schedule of all the individual database (and other transactional object) schedules in a multidatabase environment (e.g., federated database). Complying with global serializability means that the global schedule is serializable, has the serializability property, while each component database (module) has a serializable schedule as well. In other words, a collection of serializable components provides overall system serializability, which is usually incorrect. A need in correctness across databases in multidatabase systems makes global serializability a major goal for global <b>concurrency</b> <b>control</b> (or modular <b>concurrency</b> <b>control).</b> With the proliferation of the Internet, Cloud computing, Grid computing, and small, portable, powerful computing devices (e.g., smartphones), as well as increase in systems management sophistication, the need for atomic distributed transactions and thus effective global serializability techniques, to ensure correctness in and among distributed transactional applications, seems to increase.|$|E
40|$|In {{this paper}} {{a model for}} instruction-level {{distributed}} computing is described. This model allows the implementation of scalable chip multiprocessors. It is based on microthreading and operates within a single context. It is a direct replacement for the out-of-order issue of instructions but is based on explicit <b>concurrency</b> <b>controls.</b> As such it would not yield speedup unless existing sequential code were recompiled using the <b>concurrency</b> <b>controls.</b> An analysis of the model, in particular the communication and synchronisation, shows that the model can be implemented in a distributed manner in which instruction-level data is held in distributed register files, one per processor. This implementation is scalable {{as the number of}} ports in each register file is constant. Only the switching network between processors would have less than ideal scaling properties. 1...|$|R
40|$|This {{discussion}} paper explores {{the problems of}} operating systems support when implementing <b>concurrency</b> <b>controls</b> {{at the level of}} the instruction set in processors designed for multi- and many-core chips. It introduces the SVP model and its implementation in DRISC processors to a level of detail required to understand these problems. The major contribution of the paper is in analysing the issues faced in porting operating system functionality onto such processors. The paper covers the issues of job scheduling, dynamic resource management, memory protection and security. It provides examples in µTC (a language based on the SVP model) of how resource management and security issues are managed. It concludes that the implementation of <b>concurrency</b> <b>controls</b> in a processors instruction set is very disruptive. However, the author sees no alternatives if mainstream computing is ever to be served effectively by multi- and many core processors...|$|R
40|$|Snapshot {{isolation}} {{is a popular}} transactional isolation level in database systems. Several replication techniques based on snapshot isolation have recently been proposed. These proposals, however, do not fully leverage the local <b>concurrency</b> <b>controls</b> that provide snapshot isolation. Furthermore, guaranteeing snapshot isolation in lazy replicated systems may result in transaction inversions, which happen when transactions see stale data. Strong snapshot isolation, which is provided in centralized database servers, avoids transaction inversions but is expensive to provide in a lazy replicated system. In this paper, we show how snapshot isolation can be maintained in lazy replicated systems while taking {{full advantage of the}} local <b>concurrency</b> <b>controls.</b> We propose strong session snapshot isolation, a correctness criterion that prevents transaction inversions. We show how strong session snapshot isolation can be implemented efficiently in alazy replicated database system. Through performance studies, we quantify the cost of implementing our techniques in lazy replicated systems. 1...|$|R
25|$|The {{commitment}} ordering solution comprises effective {{integration of}} autonomous database management systems with possibly different <b>concurrency</b> <b>control</b> mechanisms. This while {{local and global}} transactions execute in parallel without restricting any read or write operation in either local or global transactions, and without compromising the systems' autonomy.|$|E
25|$|In a federated {{database}} {{system or}} any other more loosely defined multidatabase system, which are typically distributed in a communication network, transactions span multiple (and possibly distributed) databases. Enforcing global serializability in such system, where different databases may use different types of <b>concurrency</b> <b>control,</b> is problematic. Even if every local schedule of a single database is serializable, the global schedule of a whole system is not necessarily serializable. The massive communication exchanges of conflict information needed between databases to reach conflict serializability globally would lead to unacceptable performance, primarily due to computer and communication latency. Achieving global serializability effectively over different types of <b>concurrency</b> <b>control</b> has been open for several years. Commitment ordering (or Commit ordering; CO), a serializability technique publicly introduced in 1991 by Yoav Raz from Digital Equipment Corporation (DEC), provides an effective general solution for global (conflict) serializability across any collection of database systems and other transactional objects, with possibly different <b>concurrency</b> <b>control</b> mechanisms. CO does not need the distribution of conflict information, but rather utilizes the already needed (unmodified) atomic commitment protocol messages without any further communication between databases. It also allows optimistic (non-blocking) implementations. CO generalizes Strong strict two phase locking (SS2PL), which {{in conjunction with the}} Two-phase commit (2PC) protocol is the de facto standard for achieving global serializability across (SS2PL based) database systems. As a result, CO compliant database systems (with any, different <b>concurrency</b> <b>control</b> types) can transparently join existing SS2PL based solutions for global serializability. The same applies also to all other multiple (transactional) object systems that use atomic transactions and need global serializability for correctness (see examples above; nowadays such need is not smaller than with database systems, the origin of atomic transactions).|$|E
25|$|Find an {{efficient}} (high-performance and fault tolerant) method to enforce Global serializability (global conflict serializability) in a heterogeneous distributed environment of multiple autonomous database systems. The database systems may employ different <b>concurrency</b> <b>control</b> methods. No limitation should {{be imposed on}} the operations of either local transactions (confined to a single database system) or global transactions (span two or more database systems).|$|E
40|$|Communicated by This {{discussion}} paper explores {{the problems of}} operating systems support when implementing <b>concurrency</b> <b>controls</b> {{at the level of}} the instruction set in processors designed for multi- and manycore chips. It introduces the SVP model and its implementation in DRISC processors to a level of detail required to understand these problems. The major contribution of the paper is in analysing the issues faced in porting operating system functionality onto such processors. The paper covers the issues of job scheduling, dynamic resource management, memory protection and security. It provides examples in µTC (a language based on the SVP model) of how resource management and security issues are managed. It concludes that the implementation of <b>concurrency</b> <b>controls</b> in a processor’s instruction set is very disruptive. However, the author sees no alternatives if mainstream computing is ever to be served effectively by multi- and many core processors...|$|R
30|$|Operational {{transformation}} {{is the most}} optimistic method for <b>concurrency</b> and consistency <b>control</b> in muti-user groupware systems.|$|R
5000|$|This {{is a form}} of dataflow. This {{model can}} be applied to an {{existing}} instruction set architecture incrementally by providing just five new instructions to implement <b>concurrency</b> <b>controls.</b> A set of microthreads is a static partition of a basic block into concurrently executing fragments, which execute on a single processor and share a microcontext. An iterator over a set provides a dynamic and parametric family of microthreads. Iterators capture loop concurrency and can be scheduled to different processors. An iterator over a set is created dynamically and is called a family of microthreads. This is the mechanism that allows the model to generate concurrency, which can be run on multiple processors or functional units.|$|R
25|$|SQL Server also {{provides}} the optimistic <b>concurrency</b> <b>control</b> mechanism, {{which is similar}} to the multiversion <b>concurrency</b> <b>control</b> used in other databases. The mechanism allows a new version of a row to be created whenever the row is updated, as opposed to overwriting the row, i.e., a row is additionally identified by the ID of the transaction that created the version of the row. Both the old as well as the new versions of the row are stored and maintained, though the old versions are moved out of the database into a system database identified as Tempdb. When a row {{is in the process of}} being updated, any other requests are not blocked (unlike locking) but are executed on the older version of the row. If the other request is an update statement, it will result in two different versions of the rows—both of them will be stored by the database, identified by their respective transaction IDs.|$|E
25|$|Commitment ordering, {{publicly}} {{introduced in}} May 1991 (see below), provides an efficient elegant general solution, from both practical and theoretical points of view, {{to the global}} serializability problem across database systems with possibly different <b>concurrency</b> <b>control</b> mechanisms. It provides conflict serializability with no negative effect on availability, and with no worse performance than the de facto standard for global serializability, CO's special case Strong strict two-phase locking (SS2PL). It requires knowledge about neither local nor global transactions.|$|E
25|$|Also {{the above}} quoted article proposes a relaxed global {{serializability}} solution, while referencing the CO work. The CO solution for global serializability both bridges between different <b>concurrency</b> <b>control</b> protocols with no substantial concurrency reduction (and typically minor, if at all), and maintains {{the autonomy of}} local DBMSs. Evidently also here CO has been misunderstood. This misunderstanding continues to 2010 in a textbook {{by some of the}} same authors, where the same relaxed global serializability technique, Two level serializability, is emphasized and described in detail, and CO is not mentioned at all.|$|E
40|$|IntroductionMotivation Where does {{concurrency}} appear? Why is concurrency considered hard? Timeliness ApproachConcepts in <b>Concurrency</b> TerminologyConceptsConcurrency <b>Control</b> CorrectnessTechniquesThe State of the Art Limitations of libraries Explicit techniques Higher-level techniques The {{limits of}} explicit control Concluding remarksHigh-Level Language Constructs Common high-level constructsUsing and evaluating language constructs Implications of concurrency Interpreted languagesHistorical Context and Evolution of Languages Evolution of machinesEvolution of programming languagesLimits to automat...|$|R
40|$|Energy {{minimization}} {{of parallel}} applications considering thermal distributions among the processor cores is an emerging challenge for {{current and future}} generations of many-core computing systems. This paper proposes an adaptive energy minimization approach that hierarchically applies dynamic voltage frequency scaling (DVFS), thread-to-core affinity and dynamic <b>concurrency</b> <b>controls</b> (DCT) to address this challenge. The aim is to minimize the energy consumption and achieve balanced thermal distributions among cores, thereby improving the lifetime reliability of the system, while meeting a specified power budget requirement. Fundamental to this approach is an iterative learning-based control algorithm that adapts the VFS and core allocations dynamically based on the CPU workloads and thermal distributions of the processor cores, guided by the CPU performance counters at regular intervals. The adaptation is facilitated through modified OpenMP library-based power budget annotations. The proposed approach is extensively validated on an Intel Xeon E 5 - 2630 platform with up to 12 CPUs running NAS parallel benchmark applications...|$|R
40|$|Safe {{programming}} languages {{encourage the}} development of dynamically extensible systems, such as extensible Web servers and mobile agent platforms. Although protection is of utmost importance in these settings, current solutions do not adequately address fault containment. This paper advocates an approach to protection where transactions act as protection domains. This enables direct sharing of objects while protecting against unauthorized accesses and failures of authorized components. The main questions about this approach are what transaction models translate best into protection mechanisms suited for extensible language-based systems {{and what is the}} impact of transaction-based protection on performance. A programmable isolation engine has been integrated with the runtime of a safe programming language in order to allow quick experimentation with a variety of isolation models and to answer both questions. This paper reports on the techniques for flexible finegrained locking and undo devised to meet the functional and performance requirements of transaction-based protection. Performance analysis of a prototype implementation shows that (i) sophisticated <b>concurrency</b> <b>controls</b> do not translate into higher overheads, and (ii) the ability to memoize locking operations is crucial to performance...|$|R
25|$|Most {{existing}} OT control algorithms for <b>concurrency</b> <b>control</b> {{adopt the}} theory of causality/concurrency as the theoretical basis: causally related operations must be executed in their causal order; concurrent operations must be transformed before their execution. However, it was well known that concurrency condition alone cannot capture all OT transformation conditions. In a recent work, {{the theory of}} operation context has been proposed to explicitly represent {{the notion of a}} document state, which can be used to formally express OT transformation conditions for supporting the design and verification of OT control algorithms.|$|E
25|$|Classes of {{schedules}} {{defined by}} relaxed global serializability properties either contain the global serializability class, or are incomparable with it. What differentiates techniques for relaxed global conflict serializability (RGCSR) properties {{from those of}} relaxed conflict serializability (RCSR) properties that are not RGCSR is typically the different way global cycles (span two or more databases) in the global conflict graph are handled. No distinction between global and local cycles exists for RCSR properties that are not RGCSR. RCSR contains RGCSR. Typically RGCSR techniques eliminate local cycles, i.e., provide local serializability (which can be achieved effectively by regular, known <b>concurrency</b> <b>control</b> methods), however, obviously they do not eliminate all global cycles (which would achieve global serializability).|$|E
25|$|SQL Server allows {{multiple}} {{clients to}} use the same database concurrently. As such, it needs to control concurrent access to shared data, to ensure data integrity—when multiple clients update the same data, or clients attempt to read data that {{is in the process of}} being changed by another client. SQL Server provides two modes of concurrency control: pessimistic concurrency and optimistic concurrency. When pessimistic <b>concurrency</b> <b>control</b> is being used, SQL Server controls concurrent access by using locks. Locks can be either shared or exclusive. Exclusive lock grants the user exclusive access to the data—no other user can access the data as long as the lock is held. Shared locks are used when some data is being read—multiple users can read from data locked with a shared lock, but not acquire an exclusive lock. The latter would have to wait for all shared locks to be released.|$|E
40|$|Database sharing {{refers to}} a general {{architecture}} for distributed transaction and da-tabase processing. The nodes of a database sharing system are locally coupled via a high-speed interconnect and share the common database at the disk level ("shared disk"). We discuss system functions requiring new and coordinated solutions for da-tabase sharing. In particular, the most relevant alternatives for <b>concurrency</b> and co-herency <b>control</b> are classified and surveyed. We consider the techniques used in ex-isting database sharing systems as well as algorithms proposed in the literature. Fur-thermore, we summarize previous performance studies on database sharing. Related <b>concurrency</b> and coherency <b>control</b> schemes for workstation/server database sys-tems, network file systems, and distributed shared memory systems are also dis...|$|R
40|$|MANY TECHNIQUES for synthesizing digital {{hardware}} from C-like languages {{have been}} proposed, but none {{have emerged as}} successful as Verilog or VHDL for register-transfer-level design. This paper looks at two of the fundamental challenges: <b>concurrency</b> and timing <b>control.</b> Comment: Submitted on behalf of EDAA ([URL]...|$|R
40|$|We {{describe}} an environment {{within which the}} programmer has access to and <b>control</b> over <b>concurrency.</b> This <b>control</b> can be manifested by requiring a program to reproduce a previously manifested interleaving of instructions in concurrent threads, or by exploring the space of possible interleavings. Scientifically valid experimentation with concurrent software requires such control to make the experiments reproducible. Formal methods for showing properties of programs can also make use of this capability to force the program to exhibit its behavior under a range of interleaving scenarios. ...|$|R
25|$|While local (to a {{database}} system) relaxed serializability methods compromise serializability for performance gain (and are utilized {{only when the}} application can tolerate possible resulting inaccuracies, or its integrity is unharmed), it is unclear that various proposed relaxed global serializability methods which compromise global serializability, provide any performance gain over commitment ordering which guarantees global serializability. Typically, the declared intention of such methods has not been performance gain over effective global serializability methods (which apparently have been unknown to the inventors), but rather correctness criteria alternatives {{due to lack of}} a known effective global serializability method. Oddly, some of them were introduced years after CO had been introduced, and some even quote CO without realizing that it provides an effective global serializability solution, and thus without providing any performance comparison with CO to justify them as alternatives to global serializability for some applications (e.g., Two-level serializability). Two-level serializability is even presented as a major global <b>concurrency</b> <b>control</b> method in a 2010 edition of a text-book on databases (authored by two of the original authors of Two-level serializability, where one of them, Avi Silberschatz, is also an author of the original Strong recoverability articles). This book neither mentions CO nor references it, and strangely, apparently does not consider CO a valid Global serializability solution.|$|E
2500|$|... {{maintains}} each database's autonomy, {{and does}} not need any <b>concurrency</b> <b>control</b> information distribution (e.g., local precedence relations, locks, timestamps, or tickets).|$|E
2500|$|... allows heterogeneity: Global {{serializability}} {{is achieved}} across multiple transactional objects with different (any) <b>concurrency</b> <b>control</b> mechanisms, without {{interfering with the}} mechanisms' operations.|$|E
40|$|In {{this paper}} a general model for instruction-level {{distributed}} computing is described. This model provides an explicit description of instruction-level concurrency {{and allows for}} scalable implementations of various types of wide-issue multiprocessors. The model is based on microthreading, a hardware-supported multithreading paradigm that schedules small fragments of code dynamically. This model is a replacement for out-of-order issue, currently used in superscalar processors, in order to expose higher levels of concurrent instruction issue. The model describes parametric concurrency, based on loops, and produces scheduleindependent binary code. Moreover, this model can be implemented in a fully scalable manner and it is shown here that the instruction issue logic, the distributed register-files and communication structures all scale linearly with issue width. Out-of-order issue has the distinct advantage of backward compatibility in binary code execution as the concurrency is implicit but the scalability disadvantages will eventually outweigh this; in the out-of-orderissue model there is a square-law scaling {{in the size of}} issue logic with issue width and a cube law scaling of the global register-file with issue width. Microthreading does not yield concurrency unless existing code is recompiled using the <b>concurrency</b> <b>controls</b> introduced by this model. However, backward compatibility is still possible and some speedup on legacy code may be achieved by binary-code translation...|$|R
50|$|In addition, {{she studied}} virtual node layers {{regarding}} Mobile Ad Hoc Networks or MANETs. In the 1990s, she patented methods to protect databases against hackers trying to deduce confidential attributes. Her research has included distributed databases, simulations, <b>concurrency</b> and recovery <b>controls,</b> database design issues, performance modeling, and other issues.|$|R
40|$|Distributed {{transaction}} processing {{systems can be}} unnecessarily complex when crosscutting concerns, e. g. logging, <b>concurrency</b> <b>controls,</b> transaction management, and access controls, are scattered throughout the {{transaction processing}} logic or tangled into otherwise cohesive modules. Aspect orientation {{has the potential of}} reducing this kind of complexity with better modularization and encapsulation of crosscutting concerns, but currently aspect-oriented programming languages and frameworks only allow weaving of advice, i. e., the logic for crosscutting concerns, into contexts derived from traditional executable structures, such as method calls, constructors, and exceptions. This paper lays a foundation for weaving advice into distributed transactions by considering them to be target contexts and identifying interesting points in time, i. e., events, into which advice may be woven. To establish this foundation, we survey common approaches to transaction management, distribution, and execution; concurrency controls; and rollback. We then capture these ideas in a conceptual model, called Unified Model for Distributed Transactions (UMDT), and show that this model accurately describes all the common approaches. In the end, this model defines interesting point in time relative to transactions in general and what a transaction may know at those points in time, i. e., its context. A brief discussion of advice weaving and the potential for reducing complexity with transaction-specific aspects is provided, but the details of the actual weaving are left for another paper...|$|R
2500|$|... "Not all <b>concurrency</b> <b>control</b> {{algorithms}} use locks... Three {{other techniques}} are timestamp ordering, serialization graph testing, and commit ordering. Timestamp ordering assigns each transaction a timestamp and ensures that conflicting operations execute in timestamp order. Serialization graph testing tracks conflicts and {{ensures that the}} serialization graph is acyclic. Commit ordering ensures that conflicting operations {{are consistent with the}} relative order in which their transactions commit, which can enable interoperability of systems using different <b>concurrency</b> <b>control</b> mechanisms." ...|$|E
2500|$|Commitment {{ordering}} (or Commit ordering; CO) is {{the only}} high-performance, fault tolerant, conflict serializability providing solution that has been proposed as a fully distributed (no central computing component or data-structure are needed), general mechanism that can be combined seamlessly with any local (to a database) <b>concurrency</b> <b>control</b> mechanism (see technical summary). Since the CO property of a schedule is {{a necessary condition for}} global serializability of autonomous databases (in the context of <b>concurrency</b> <b>control),</b> it provides the only general solution for autonomous databases (i.e., if autonomous databases do not comply with CO, then global serializability may be violated). Seemingly by sheer luck, the CO solution possesses many attractive properties: ...|$|E
2500|$|... {{does not}} {{interfere}} with any transaction's operation, particularly neither block, restrict nor delay any data-access operation (read or write) for either local or global transactions (and thus does not cause any extra aborts); thus allows seamless integration with any <b>concurrency</b> <b>control</b> mechanism.|$|E
25|$|Concurrent {{constraint}} {{logic programming}} combines concurrent logic programming and constraint logic programming, using constraints to <b>control</b> <b>concurrency.</b> A clause can contain a guard, {{which is a}} set of constraints that may block the applicability of the clause. When the guards of several clauses are satisfied, concurrent constraint logic programming makes a committed choice to the use of only one.|$|R
40|$|In this paper, we {{introduce}} object{oriented {{programs as}} sets of communicat-ing objects. We investigate possibilities for their concurrent execution, {{starting with a}} review of existing concurrent, object{oriented systems. Most of these systems introduce new programming{language features, forcing a programmer to <b>control</b> <b>concurrency</b> by hand. In contrast, we prefer automatic paralleliza-tion of programs. For this purpose, we introduce a concurrent, object{based execution model. 2...|$|R
40|$|Fuzzy Petri nets are {{powerful}} specifications as they cover <b>concurrency</b> and <b>control</b> of impreciseness {{of any real}} time application domain. Researchers use this tool for interpreting the results obtained in data mining. Data mining helps marketing professionals improve their understanding of customer behavior. In turn, this better understanding allows them to target marketing campaigns more accurately and to align campaigns more closely with the needs, wants and attitudes of customers and prospects. In this paper, fuzzy Petri nets and classification mining techniques have been implemented using a real marketing data obtained from Portuguese marketing campaign related to bank deposit subscription The {{aim of this study}} is to predict whether a client will subscribe a term deposit...|$|R
