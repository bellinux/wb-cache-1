126|93|Public
5|$|The {{camera on}} the , also known as an iSight camera, can take 8-megapixel photos (3,264 by 2,448pixels) and record 1080p videos at up to 30frames per second with {{upgraded}} quality (30% better clarity, 26% better white balance, <b>color</b> <b>accuracy)</b> due to an additional lens, IR filter, a wider f/2.4 aperture, and Image signal processor (built-in A5).|$|E
25|$|The results, {{in terms}} of <b>color</b> <b>accuracy</b> (metamerism index), were {{state of the art}} {{at the time of their}} invention.|$|E
25|$|On {{the other}} hand, {{the method of}} color {{separation}} by silicon penetration depth gives more cross-contamination between color layers, meaning more issues with <b>color</b> <b>accuracy,</b> especially in the red channel.|$|E
3000|$|... 2. Reference-based {{assessment}} of quality Measurement of <b>color</b> rendering <b>accuracy</b> by {{analysis of the}} extracted reference targets (cf. Section 4.1).|$|R
40|$|Two {{methods for}} {{colorimetric}} characterization of color scanner are proposed {{based on the}} measures of perceptual color difference error. The first method is used to minimize the total color differences between the actual and predicted color samples. The second one, which is a generalization of the existing cubic-root preprocessing technique, derives the mapping between the p'th root of scanner responses and Commission Internationale de l’Eclairage L*a*b (CIELAB) values. The experiment {{results indicate that the}} <b>color</b> <b>accuracies</b> of the proposed methods, especially the second one, are better than those of the traditional CIE XYZ (CIEXYZ) - space-based characterization methods. Institute of Textiles and ClothingAuthor name used in this publication: John H. Xi...|$|R
40|$|For {{improving}} <b>color</b> reproduction <b>accuracy</b> {{of mobile}} displays, we recently developed a generic model for device-specific display characterization model that also {{accounts for the}} influence of illuminance from ambient light. In the present article, this MDCIM model (Mobile Display Characterization and Illumination Model) is applied to a Samsung Galaxy S 4 display, representing OLED displays. The performance of the model was tested by determining the values of all model parameters using publicly available technical data only. We organized visual tests under various ambient illuminance levels from 600 to 3000 lux. Seven observers compared the color of displayed images with the color of physical samples. With the MDCIM method, {{the quality of the}} color match was shown to improve considerably as compared to using only device-independent encoding color space. On a five-point scale to quantify <b>color</b> reproduction <b>accuracy,</b> the MDCIM resulted in more than 1 unit improvement at 1000 lux illuminance. At lower and higher illuminance, the improvement was even larger. <b>Color</b> reproduction <b>accuracy</b> was found to be at least reasonable, according to the subjective assessment of visual observers, for more than 75 % of the samples when using the MDCIM method, but only 20 % or less when using the common device-independent encoding color space...|$|R
25|$|Proper {{reproduction}} of colors, especially in professional environments, requires color management {{of all the}} devices involved in the production process, many of them using RGB. Color management results in several transparent conversions between device-independent and device-dependent color spaces (RGB and others, as CMYK for color printing) during a typical production cycle, {{in order to ensure}} color consistency throughout the process. Along with the creative processing, such interventions on digital images can damage the <b>color</b> <b>accuracy</b> and image detail, especially where the gamut is reduced. Professional digital devices and software tools allow for 48 bpp (bits per pixel) images to be manipulated (16 bits per channel), to minimize any such damage.|$|E
500|$|The G2 was {{considered}} by critics to be well-built, but {{was criticized for}} replacing the glass-based construction of the Optimus G with a plainer, plastic-based design, drawing comparisons to recent Samsung products. Ars Technica further criticized the Verizon Wireless version for having a cheaper appearance than the international versions, with a plainer rear cover, modified buttons, and a different speaker layout. The G2's rear buttons were met with equally mixed reception, with most reviewers believing that users {{would be able to}} adjust themselves to operate them. Accordingly, the ability to wake the phone by tapping on the screen {{was considered}} a more convenient method. The G2 was praised for its high-end hardware, with Engadget describing the device as a [...] "beast" [...] with specifications that [...] "seem familiar to anyone who's read a flagship Android phone review in the last 12 months", recognizing that it had become harder for manufacturers to differentiate their flagship products beyond displays and processors. The G2's display was praised for its high resolution and <b>color</b> <b>accuracy,</b> along with LG's efforts to reduce the screen bezel size. The G2 was also praised for having unexpectedly longer battery life than any of its competitors (along with Motorola's Droid Razr Maxx). After lasting about 20 hours of [...] "standard" [...] use in its testing, the G2's battery was considered by Engadget to be [...] "a sign that we're finally crossing into a world of sensible smartphone batteries." ...|$|E
2500|$|The main camera {{remained}} relatively unchanged, using an [...] "UltraPixel" [...] image sensor (OmniVision OV4688) composed of pixels that are 2.0µm in size. The UltraPixel sensor was updated to provide better <b>color</b> <b>accuracy</b> in lit photographs, and the device now includes a dual-tone flash. The main camera {{is accompanied by}} a second, 2-megapixel depth of field sensor (OmniVision OV2722) located directly above the main camera {{as a part of the}} device's [...] "Duo Camera" [...] system. The sensor analyzes the distance and position of elements within a photo, and generates a depth map, which is embedded within each photo.|$|E
25|$|Digital cameras sensors {{may have}} {{internal}} filters that block UV to improve <b>color</b> rendition <b>accuracy.</b> Sometimes these internal filters can be removed, {{or they may}} be absent, and an external visible-light filter prepares the camera for near-UV photography. A few cameras are designed for use in the UV.|$|R
30|$|Color {{calibration}} {{hardware and}} software was used to optimize the monitor's <b>color</b> profile for <b>accuracy</b> and optimal contrast given the room's lighting environment.|$|R
50|$|Several {{industrial}} and commercial markets have great need for characterized and accurate color vision {{as well as}} tests to quantify <b>color</b> vision <b>accuracy.</b> Among these are divisions like healthcare systems, design companies and photography and motion picture industries. In order to generate color accurate products, employee vision accuracy is crucial as well.|$|R
5000|$|Independent {{tests can}} be used to {{demonstrate}} that the [...] "APO" [...] designation is used rather loosely by some photographic lens manufacturers to describe the <b>color</b> <b>accuracy</b> of their lenses, as comparable lenses have shown superior <b>color</b> <b>accuracy</b> even though they did not carry the [...] "APO" [...] designation.|$|E
5000|$|The 1600 x 900 display was {{indicated}} to be [...] "spacious enough" [...] with acceptable <b>color</b> <b>accuracy.</b> However, the brightness level {{was indicated}} to be low, at 210.8 cd/m2.|$|E
50|$|Some {{monitors}} {{are designed}} exclusively for gamers, featuring higher refresh rates and improved response {{times at the}} expense of a lower resolution. E-sports, or competitive gamers, often favor higher framerates {{at the expense of}} reduced <b>color</b> <b>accuracy,</b> preferring TN panels over IPS panels.|$|E
40|$|An {{enhanced}} character registration {{method is}} proposed {{in this paper}} to assist the auto coloring for 2 D animation characters. After skeletons are extracted, the skeleton of the character in a target frame is relocated based on a stable branch in a reference frame. Subsequently the characters among a sequence are automatically matched and registered. Occlusion are then detected and located in certain components segmented from the character. Two different approaches are applied to color regions in components without and with occlusion respectively. The approach has been tested for coloring a practical animation sequence and achieved high <b>coloring</b> <b>accuracy,</b> showing its applicability in commercial animation production. Copyright © 2008 Jie Qiu et al. This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. 1...|$|R
40|$|For many people, {{the correct}} {{perception}} of the colors of objects {{is an important part}} of life, and today it is being threatened by misinformed policy-making and associated business decisions. Some conservationists and lamp manufacturers have concluded that the accurate color rendering provided by ordinary incandescent lamps is an unaffordable luxury that good citizens should forgo as we employ more energy-efficient alternatives. Though this is not as extreme as suggesting that we should live in cold darkness, it is in the same general direction of deprivation. Yet research has shown that color rendering is important to people and highefficiency lamps can now also provide high color rendering, so there is no longer any need to have lighting that distorts color appearance. This article focuses on the tradeoff between <b>color</b> rendering <b>accuracy</b> and lamp efficiency to show that high <b>color</b> rendering <b>accuracy</b> is appropriate and, contrary to a common misconception, does not intrinsically require greater electrical energy consumption. Peer reviewed: YesNRC publication: Ye...|$|R
30|$|For the AWB algorithms, a {{modified}} version of the edge-based method is used in this paper. Although the edge-based method is simple, the <b>color</b> constancy <b>accuracy</b> of the method is reasonable [30], and the average edge difference in the scene is assumed to be achromatic. To prevent color failure when more than one uniform object existed in an image, a predefined achromatic region is used in this paper.|$|R
50|$|Delta-E: <b>Color</b> <b>accuracy</b> is {{measured}} in delta-E; the lower the delta-E, the more accurate the color representation. A delta-E of below 1 is imperceptible to the human eye. Delta-Es of 2 to 4 are considered good and require a sensitive eye to spot the difference.|$|E
50|$|Among {{many other}} applications, Imatest {{has been used}} to adjust images with {{different}} amounts of sharpening to a standard amount of sharpening, and to compare resolution in of those adjusted images. Imatest also tests <b>color</b> <b>accuracy,</b> tone-scale linearity, image distortion, light falloff, and printing gamut.|$|E
5000|$|<b>Color</b> <b>accuracy</b> is an {{important}} but ambiguous image quality factor. Many viewers prefer enhanced color saturation; the most accurate color isn't necessarily the most pleasing. Nevertheless {{it is important to}} measure a camera's color response: its color shifts, saturation, and the effectiveness of its white balance algorithms.|$|E
5000|$|Several {{sources of}} error (and therefore, {{inherent}} accuracy shortcomings) {{are directly related}} to the observer. Although CIE demonstrates several sets of data regarding the optimal, standard observer, each individual observer differs slightly from the baseline. Factors like visual acuity, color blindness and visual system defects (cataracts, surgeries, LASIK, tinted optics, poor cone responsivity, etc.) are all directly tied to observer <b>color</b> perception <b>accuracy.</b> The accuracy of an observers test answers are represented in Test Results ...|$|R
40|$|Abstract — Before any of {{the eleven}} {{possible}} quinones of azulene were known, predictions were made about their proper— ties {{on the basis of}} Hickel, MINDO/ 3, PPP and ab initio SCF (STO— 3 G) calculations (3). Four unsubstituted quinones of azulene have now been prepared, and the experimental results obtained so far provide information regarding their stability, reduction potentials, cycloadditions with cyclopentadiene, periselectivity of dimerization, and <b>color.</b> The <b>accuracy</b> of the predictions in some instances has been remarkable...|$|R
40|$|Quality {{by design}} is a {{comprehensive}} program that begins with understanding user needs and continues through (but does not end with) monitoring customer acceptance. Management tools and processes such as ISO 9000 standards and the Food and Drug Administration Quality System Regulations exist to guide medical device manufacturers in quality practices. The goal is to deliver products acceptable for their intended use. Quality control begins with defining attributes ranging from <b>color</b> to <b>accuracy</b> and precision. Failure mode and effects analysis and risk analysis consider both probability and severity o...|$|R
5000|$|The {{combination}} {{of very high}} resolution with the option of 14-bit per channel recording and a very sharp anti-aliasing filter (which Nikon claims is a unique design) provides extremely high image quality, with superior dynamic range and <b>color</b> <b>accuracy</b> {{compared with that of}} other 35mm-format digital cameras.|$|E
5000|$|The iPad Pro's 9.7-inch version set {{a record}} among all {{currently}} released tablets tested in <b>color</b> <b>accuracy,</b> screen reflectance, peak brightness, contrast rating in high ambient light, and smallest color variation. However, the iPad Pro 12.9-inch version tested to having better contrast ratio in the dark.|$|E
50|$|Engadget {{gave the}} Fire HDX an 85 out of 100, {{saying that it}} may be the most {{compelling}} case for Amazon's tablet ecosystem. While advanced users may be turned off by the limited app selection, the display's gorgeous <b>color</b> <b>accuracy</b> may make the tablet a good buy for everyone else, especially Amazon Prime members.|$|E
40|$|Abstract In {{digital cameras}} a color {{processing}} pipeline is implemented {{to convert the}} RAW image acquired by the camera sensor into a faithful representation of the origi-nal scene. There are two main modules in this pipeline: the former is the illuminant estimation and correction module, the latter is the color matrix transformation. In this work we design extended color correction pipelines which ex-ploit the crosstalks between their modules {{to lead to a}} higher <b>color</b> rendition <b>accuracy.</b> The effectiveness of the proposed pipelines is shown on a publicly available dataset of RAW images...|$|R
40|$|We {{address the}} problem of {{automatic}} color categorization of the objects in surveillance videos. This problem is challenging for realistic situations due to the large intra-class variations of the same color and the large portions of noisy areas including the backgrounds and the parts of the objects that do not contribute to color assignments. We develop an integrated color categorization system with algorithms that address these challenges. With the algorithms proposed in this paper, we can improve the average <b>color</b> categorization <b>accuracy</b> by 18 % from our previous work [7]...|$|R
40|$|This paper {{presents}} a new evaluation method of the <b>color</b> estimation <b>accuracy</b> {{for a set}} of multispectral color sensors. In this method, the probability density distribution of the spectral reflectance is assumed, and then it yields the possible range of estimation error in the color space at a specified confidence level. It is shown that the error range in the color space is expressed as the ellipses, when the probability density of the spectral reflectance is given by a multi-dimensional Gaussian function. Some examples of the evaluations of multispectral imaging systems are shown for different numbers of bands, and the results are compared with MacAdam ellipse...|$|R
50|$|The {{camera on}} the iPhone 4S, also known as an iSight camera, can take 8-megapixel photos (3,264 by 2,448 pixels) and record 1080p videos at up to 30 frames per second with {{upgraded}} quality (30% better clarity, 26% better white balance, <b>color</b> <b>accuracy)</b> due to an additional lens, IR filter, a wider f/2.4 aperture, and Image signal processor (built-in A5).|$|E
50|$|Most {{applications}} running under WINE {{have not}} been fully tested for <b>color</b> <b>accuracy.</b> While 8-bpp programs can have some color resolution difficulties due to depth conversion errors, colors in higher-depth applications should be accurate, as long as those programs perform their gamut conversions {{based on the same}} monitor profile as that used for loading the LUT. The corresponding LUT adjustments do need to be loaded though.|$|E
50|$|In {{the design}} sphere, {{there are several}} common yet largely {{important}} uses for <b>color</b> <b>accuracy</b> that lean heavily on the designers ability to accurately sense color. Careers such as graphic design, photography, graphics and color development are common fields that rely heavily on employees with accurate color vision. Additionally, paint engineering also relies heavily on color science employees with a demonstrated acuity in color vision. Examples of relevant companies includes Pantone and Sherwin-Williams.|$|E
40|$|Abstract. Scanner is the {{indispensable}} image acquisition {{equipment in the}} prepress system, high quality ICC profile is significant to reflect the color expression of scanner, and the character of ICC profile is influenced in a great extent by the color input target. The subject {{is to set up}} the ICC profile by scanning and data processing Kodak IT 8. 7 / 2, Goldencolor GCT 3. 0 and GretagMacbeth ColorChecker SG, get the influence of each color input target to the scanner color characteristic through the <b>accuracy</b> analysis and <b>color</b> gamut comparison. Research shows that three kinds of color target has its own advantage, Kodak IT 8. 7 / 2 has big <b>color</b> gamut, high <b>accuracy,</b> and better reappearance ability, meets the needs of the everyday users; GretagMacbeth ColorChecker SG is good to the reappearance of high saturate manuscript, and its precision is high, applying to recreate natural landscape; Glodencolor GCT 3. 0 is of high precision and larger color gamut, but its expression ability is not good enough in the section of high saturation red and magenta, it can produce high quality scanner ICC profile also. Consequently, it should be taken into consideration of the manuscript, <b>color</b> gamut, <b>accuracy</b> and cost-effective factors comprehensively when choosing scanner color target, eventually you get a satisfactory scanning result...|$|R
30|$|The {{proposed}} method {{predicts the}} perceived sharpness. The image-quality space of imaging devices is multi-dimensional. Sharpness is one low-level quality attribute. Other low-level attributes, including noise and <b>color</b> reproduction <b>accuracy,</b> are fairly simple to implement {{in the proposed}} framework. Both can be measured using the same procedure, which locates the appropriate regions for measurement in the reference image using block data. Higher-level attributes, including naturalness and clarity, set higher requirements for the method. We can expect that new components need to be added in the framework. The higher-level attributes relate strongly to image content and semantics. The framework will require advanced computational methods for content understanding before higher-level attributes or overall image quality can be calculated.|$|R
50|$|Photographic film {{responds}} to ultraviolet radiation but the glass lenses of cameras usually block radiation shorter than 350 nm. Slightly yellow UV-blocking filters {{are often used}} for outdoor photography to prevent unwanted bluing and overexposure by UV rays. For photography in the near UV, special filters may be used. Photography with wavelengths shorter than 350 nm requires special quartz lenses which do not absorb the radiation.Digital cameras sensors may have internal filters that block UV to improve <b>color</b> rendition <b>accuracy.</b> Sometimes these internal filters can be removed, {{or they may be}} absent, and an external visible-light filter prepares the camera for near-UV photography. A few cameras are designed for use in the UV.|$|R
