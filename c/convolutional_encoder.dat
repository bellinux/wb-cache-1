234|32|Public
5000|$|... #Caption: Img.1. Rate 1/3 non-recursive, non-systematic <b>convolutional</b> <b>encoder</b> with {{constraint}} length 3 ...|$|E
50|$|A <b>convolutional</b> <b>encoder</b> is {{a finite}} state machine. An encoder with n binary cells will have 2n states.|$|E
5000|$|... #Caption: Img.2. Rate 1/2 8-state {{recursive}} systematic <b>convolutional</b> <b>encoder.</b> Used as constituent code in 3GPP 25.212 Turbo Code.|$|E
30|$|The {{use of a}} {{recursive}} <b>convolutional</b> inner <b>encoder</b> always yields an interleaver gain.|$|R
3000|$|The type of FEC encoder {{adopted at}} the OFDM {{transmitter}} {{has to be}} taken into consideration when the proposed sub-sampling method is defined. The type of FEC encoder used affects the parity pattern predictability that is employed in this approach. Moreover, the FEC type also affects the IFFT input symbol structures that can be used. The recursive systematic <b>convolutional</b> (RSC) <b>encoder,</b> described in [17] will be used, since recursive encoders are more effective in correcting errors at the destination. The encoder used is described by the feed forward and feedback polynomials: 1 +D+D [...]...|$|R
30|$|In {{the article}} {{entitled}} ‘Evaluation of H. 264 /AVC over IEEE 802.11 p Vehicular Networks’ by Ismael Rozas-Ramallal, Tiago M. Fernández-Caramés, Adriana Dapena, and José A. García-Naya, the authors present an FPGA-based testbed developed for evaluating H. 264 /AVC video transmission over vehicular networks. The testbed covers {{some of the}} most common situations in vehicle-to-vehicle and roadside-to-vehicle communications, and it is highly flexible, allowing for the performance evaluation of different vehicular standard configurations. In order to improve the received video quality performance, the authors propose to substitute the <b>convolutional</b> channel <b>encoder</b> used in IEEE 802.11 p for a low-density parity-check code encoder.|$|R
5000|$|A <b>convolutional</b> <b>encoder</b> {{is called}} so because it {{performs}} a convolution of the input stream with the encoder's impulse responses: ...|$|E
50|$|So we {{generally}} find {{the output of}} the system <b>convolutional</b> <b>encoder,</b> which is the convolution of the input bit, against the states of the convolution encoder, registers.|$|E
50|$|A <b>convolutional</b> <b>encoder</b> is a {{discrete}} linear time-invariant system. Every output of an encoder {{can be described}} by its own transfer function, which {{is closely related to}} the generator polynomial. An impulse response is connected with a transfer function through Z-transform.|$|E
5000|$|Serial {{concatenated}} convolutional codes {{were first}} analyzed {{with a view}} toward turbo decoding in [...] "Serial Concatenation of Interleaved Codes: Performance Analysis, Design, and Iterative Decoding" [...] by S. Benedetto, D. Divsalar, G. Montorsi and F. Pollara. This analysis yielded a set of observations for designing high performance, turbo decodable serial concatenated codes that resembled turbo codes. One of these observations was that [...] "the use of a recursive <b>convolutional</b> inner <b>encoder</b> always yields an interleaver gain." [...] This {{is in contrast to}} the use of block codes or non-recursive convolutional codes, which do not provide comparable interleaver gain.|$|R
40|$|Deep {{learning}} {{has been successfully}} applied to image super resolution (SR). In this paper, we propose a deep joint super resolution (DJSR) model to exploit both external and self similarities for SR. A Stacked Denoising <b>Convolutional</b> Auto <b>Encoder</b> (SDCAE) is first pre-trained on external examples with proper data augmentations. It is then fine-tuned with multi-scale self examples from each input, where the reliability of self examples is explicitly taken into account. We also enhance the model performance by sub-model training and selection. The DJSR model is extensively evaluated and compared with state-of-the-arts, and show noticeable performance improvements both quantitatively and perceptually {{on a wide range}} of images...|$|R
40|$|The paper {{presents}} this year's CUNI submissions to the WAT 2017 Translation Task {{focusing on}} the Japanese-English translation, namely Scientific papers subtask, Patents subtask and Newswire subtask. We compare two neural network architectures, the standard sequence-to-sequence with attention (Seq 2 Seq) (Bahdanau et al., 2014) and an architecture using <b>convolutional</b> sentence <b>encoder</b> (FBConv 2 Seq) described by Gehring et al. (2017), both implemented in the NMT framework Neural Monkey that we currently participate in developing. We also compare various types of preprocessing of the source Japanese sentences {{and their impact on}} the overall results. Furthermore, we include the results of our experiments with out-of-domain data obtained by combining the corpora provided for each subtask...|$|R
50|$|Other forward channels, {{selected}} by their Walsh code, carry {{data from the}} network to the mobiles. Data consists of network signaling and user traffic. Generally, {{data to be transmitted}} is divided into frames of bits. A frame of bits is passed through a <b>convolutional</b> <b>encoder,</b> adding forward error correction redundancy, generating a frame of symbols. These symbols are then spread with the Walsh and PN sequences and transmitted.|$|E
50|$|The {{space probe}} {{included}} a redundant system transceivers, one {{attached to the}} high-gain antenna, the other to an omni-antenna and medium-gain antenna. Each transceiver was 8 watts and transmitted data across the S-band using 2110 MHz for the uplink from Earth and 2292 MHz for the downlink to Earth with the Deep Space Network tracking the signal. Prior to transmitting data, the probe used a <b>convolutional</b> <b>encoder</b> to allow correction of errors in the received data on Earth.|$|E
50|$|The term {{block code}} may also refer to any error-correcting code that acts on {{a block of}} k bits of input data to produce n bits of output data (n,k). Consequently, the block coder is a memoryless device. Under this {{definition}} codes such as turbo codes, terminated convolutional codes and other iteratively decodable codes (turbo-like codes) would also be considered block codes. A non-terminated <b>convolutional</b> <b>encoder</b> would {{be an example of}} a non-block (unframed) code, which has memory and is instead classified as a tree code.|$|E
40|$|We {{propose a}} new encoder-decoder {{approach}} to learn distributed sentence representations that are applicable to multiple purposes. The model is learned {{by using a}} convolutional neural network as an encoder to map an input sentence into a continuous vector, and using a long short-term memory recurrent neural network as a decoder. Several tasks are considered, including sentence reconstruction and future sentence prediction. Further, a hierarchical encoder-decoder model is proposed to encode a sentence to predict multiple future sentences. By training our models on a large collection of novels, we obtain a highly generic <b>convolutional</b> sentence <b>encoder</b> that performs well in practice. Experimental results on several benchmark datasets, and across {{a broad range of}} applications, demonstrate the superiority of the proposed model over competing methods. Comment: Accepted by EMNLP 201...|$|R
40|$|We propose an {{iterative}} decoding method, {{which we}} call turbo-CS, for the reception of concatenated source-channel encoded sparse signals transmitted over an AWGN channel. The turbo-CS encoder applies 1 -bit compressed sensing as a source encoder concatenated serially with a <b>convolutional</b> channel <b>encoder.</b> At the turbo-CS decoder, an iterative joint source-channel decoding method is proposed for signal reconstruction. We analyze, for the first time, the convergence of turbo-CS decoder by determining an EXIT chart of the constituent decoders. We modify the soft-outputs of the decoder to improve the signal reconstruction performance of turbo-CS decoder. For a fixed signal reconstruction performance RSNR of 10 dB, we achieve more than 5 dB of improvement in the channel SNR after 6 iterations of the turbo-CS. Alternatively, for a fixed SNR of - 1 dB, we achieve a 10 dB improvement in RSNR...|$|R
40|$|This paper instroduces an {{unsupervised}} {{framework to}} extract semantically rich features for video representation. Inspired by how the human visual system groups objects based on motion cues, we propose a deep {{convolutional neural network}} that disentangles motion, foreground and background information. The proposed architecture consists of a 3 D <b>convolutional</b> feature <b>encoder</b> for blocks of 16 frames, which is trained for reconstruction tasks over the first and last frames of the sequence. The model is trained with a fraction of videos from the UCF- 101 dataset taking as ground truth the bounding boxes around the activity regions. Qualitative results indicate that the network can successfully update the foreground appearance based on pure-motion features. The benefits of these learned features are shown in a discriminative classification task when compared with a random initialization of the network weights, providing a gain of accuracy above the 10...|$|R
5000|$|In an RA code, an {{information}} block of length [...] is repeated [...] times, scrambled by an interleaver of size , and then encoded by a rate 1 accumulator. The accumulator {{can be viewed}} as a truncated rate 1 recursive <b>convolutional</b> <b>encoder</b> with transfer function , but Divsalar et al. prefer to think of it as a block code whose input block [...] and output block [...] are related by the formula [...] and [...] for [...] The encoding time for RA codes is linear and their rate is [...] They are nonsystematic.|$|E
50|$|The {{space probe}} {{included}} a redundant system of transceivers, one {{attached to the}} narrow-beam, high-gain antenna, the other to an omni-antenna and medium-gain antenna. The parabolic dish for the high-gain antenna was 2.74 m in diameter and made from an aluminum honeycomb sandwich material. The spacecraft was spun about an axis that was parallel to the axis of this antenna {{so that it could}} remain oriented toward the Earth. Each transceiver was 8 W and transmitted data across the S-band using 2110 MHz for the uplink from Earth and 2292 MHz for the downlink to Earth with the Deep Space Network tracking the signal. Data to be transmitted was passed through a <b>convolutional</b> <b>encoder</b> so that most communication errors could be corrected by the receiving equipment on Earth. The data transmission rate at launch was 256 bit/s, with the rate degrading by about &minus;1.27 millibit/s for each day during the mission.|$|E
3000|$|... [*]=[*]k/n[*]=[*] 1 / 3, {{constraint}} length K[*]=[*] 3, <b>convolutional</b> <b>encoder</b> with generator polynomials g [...]...|$|E
40|$|Supervised {{approaches}} classify {{input data}} using {{a set of}} representative samples for each class, known as training samples. The collection of such samples are expensive and time-demanding. Hence, unsupervised feature learning, which has a quick access to arbitrary amount of unlabeled data, is conceptually of high interest. In this paper, we propose a novel network architecture, fully Conv-Deconv network with residual learning, for unsupervised spectral-spatial feature learning of hyperspectral images, which is able to be trained in an end-to-end manner. Specifically, our network {{is based on the}} so-called encoder-decoder paradigm, i. e., the input 3 D hyperspectral patch is first transformed into a typically lower-dimensional space via a <b>convolutional</b> sub-network (<b>encoder),</b> and then expanded to reproduce the initial data by a deconvolutional sub-network (decoder). Experimental results on the Pavia University hyperspectral data set demonstrate competitive performance obtained by the proposed methodology compared to other studied approaches...|$|R
40|$|We {{introduce}} {{a framework for}} treating multirate filter banks for signal and image processing applications, as well as communication applications, in a unified way. We show how methods from group and ring theory {{can be applied to}} derive structural properties of filter banks. 1 Introduction Multirate filter banks are often used in signal and image processing applications to realize a multiresolution decomposition of the input signal. Suitably generalized, these filter banks are also used in communication applications, namely for error correction. Here a <b>convolutional</b> code <b>encoder</b> can be interpreted as a multirate filter bank. We {{introduce a}} framework which deals with all these applications in a unified way. We view the coe#cients of the input signal as ring elements. This allows us to deal with the finite rings used in communication applications and with real or complex numbers, as used in signal or image processing applications. The input signals are indexed by group elements, so tha [...] ...|$|R
40|$|Many blind channel equalization/identification algorithms, e. g. [1, 8, 11, 14] {{are derived}} {{assuming}} the transmitted information sequence to be white. In practical communication systems, redundancy {{is added to}} the source sequence in order to detect and correct symbol errors in the receiver. It is not obvious how channel encoding will affect the assumption of whiteness. The autocorrelation function of some commonly used channel codes is analyzed in order to study the validity of assumptions used in blind equalization. The codes are presented in terms of a Markov model, for which the autocorrelation is analytically expressed. The various encoded sequences are used in the prediction-error filtering based blind equalizer of [1] and the performance is empirically compared to the case of unencoded data. A blind equalization example using a practical GSM speech encoder combined with a <b>convolutional</b> channel <b>encoder</b> is also given 1 1 This work was supported by the Academy of Finland. Some results of this paper were presented in [10]...|$|R
40|$|In {{this paper}} we discuss the {{correlation}} properties of the output of a binary <b>convolutional</b> <b>encoder.</b> We consider both random statistically independent inputs and first-order Markov inputs. It is shown that for random inputs, the ensemble average of {{the product of the}} outputs of a <b>convolutional</b> <b>encoder</b> taken two at a time is always either 0 or 1, and that for almost all good codes the ensemble average is always 0...|$|E
3000|$|... [*]=[*]k/n {{constraint}} length K <b>convolutional</b> <b>encoder</b> is used {{to produce}} a sequence c of coded bits of length N [...]...|$|E
3000|$|..., and {{the coding}} {{structure}} shown by ‘code structure’ in (8) {{that represents the}} trellis structure of the outer <b>convolutional</b> <b>encoder</b> [10].|$|E
40|$|In {{this final}} project, {{analysis}} {{will be done}} on the performance of convolutional codes on the system Parallel Interference Cancellation Multiuser Detection CDMA using QPSK modulation. <b>Convolutional</b> code <b>encoder</b> is used at the transmitter side with a rate 1 / 3 and the decoder at the receiver side using the Viterbi algorithm. The results of the BER curve of the function of SNR Performance with convolutional code in the PIC system is better than 7 dB without convolutional code for 10 - 3 BER value. For the PIC MUD system stage 3 5 dB better than the stage 2 and 3 dB compared to stage 1. The use of convolutional code with rate 1 / 3 better 4 dB than the rate of ½. Application of the active users 12 is better than 16 users because more and more users then the value of the required SNR increases. Key words: Convolution Code, PIC, BER, QPS...|$|R
40|$|Abstract We {{introduce}} {{a framework for}} treating multirate filter banks for signal and image processing applications, as well as communication applications, in a unified way. We show how methods from group and ring theory {{can be applied to}} derive structural properties of filter banks. $ 1 Introduction Multirate filter banks are often used in signal and image processing applications to realize a multiresolution decomposition of the input signal. Suitably generalized, these filter banks are also used in communication applications, namely for error correction. Here a <b>convolutional</b> code <b>encoder</b> can be interpreted as a multirate filter bank. We {{introduce a}} framework which deals with all these applications in a unified way. We view the coefficients of the input signal as ring elements. This allows us to deal with the finite rings used in communication applications and with real or complex numbers, as used in signal or image processing applications. The input signals are indexed by group elements, so that we can treat one dimensional or higher dimensional signals alike...|$|R
40|$|Error {{control is}} the major insistence in today’s {{wireless}} communication systems. In this era parallel concatenated convolutional codes known as turbo codes plays a crucial role. These codes have been chosen as error control approach for various wireless applications such as UMTS (Universal Mobile Telecommunication System),DVB (Digital Video Broadcasting) etc. In this paper an area efficient turbo encoder (2, 1, 3) is proposed to suffice the elevated demand of miniaturization in future wireless communication. The proposed design is simulated using matlab and synthesized on Xilinx Virtex- 2 p (xc 2 vp 30 -ff 896 - 5) FPGA. During simulation the proposed design is compared with the matlab model of RSC encoder. The performance of proposed Turbo encoder will be compared for FPGAs in terms of number of slices, number of slice Flip-flops {{and the number of}} registers. The Synthesis results show a 7 % improvement in the utilized no. of slices and slice flip-flop. So an area efficient, cost effective Parallel Concatenated <b>Convolutional</b> Code <b>Encoder</b> has been proposed in this pape...|$|R
40|$|In this paper, we are {{implementing}} the <b>Convolutional</b> <b>encoder</b> and viterbi decoder with code rate 2 / 3 using verilog. The main {{issue of this}} paper is to implement the RTL level model of <b>Convolutional</b> <b>encoder</b> and viterbi decoder, with the testing results of behavior model. We tried to achieve a low silicon cost. The viterbi algorithm, used for Convolutional codes extensively employed decoding algorithm for Convolutional codes. This paper is realized using verilog HDL. It is simulated and synthesized using Modelsim Alter...|$|E
40|$|The {{performance}} of a coding system consisting of a <b>convolutional</b> <b>encoder</b> and a Viterbi decoder is analytically found by the well-known transfer function bounding technique. For the partial-unit-memory byte-oriented <b>convolutional</b> <b>encoder</b> with m sub 0 binary memory cells and (k sub 0 m sub 0) inputs, a state diagram of 2 (K) (sub 0) was for the transfer function bound. A reduced state diagram of (2 (m sub 0) + 1) is used for easy evaluation of transfer function bounds for partial-unit-memory codes...|$|E
30|$|In [7], a Euclidean algorithm-based {{method is}} {{proposed}} {{to identify a}} 1 / 2 -rate <b>convolutional</b> <b>encoder</b> in noiseless cases. However, it is not suitable for noisy channels. In [8], another approach is presented to identify a 1 /n-rate <b>convolutional</b> <b>encoder</b> in noisy cases based on the Expectation Maximization algorithm. The authors of [9, 10] develop methods for blind recovery of <b>convolutional</b> <b>encoder</b> in turbo code configuration. In [6, 11], a dual code method for blind identification of k/n-rate convolutional codes is proposed for cognitive radio receivers. An iterative decoding-technique-based reconstruction of block code is introduced by the authors of [12] and was applied to low-density parity-check (LDPC) codes. An algebraic approach for the reconstruction of linear and convolutional codes is presented in [13]. In [14], an algorithm for blind recognition of error-correcting codes is presented by utilizing the rank properties of the received stream.|$|E
40|$|This paper {{gives the}} results of a {{simulation}} study on the performance of JPEG image transmission over AWGN and Rayleigh fading channels using typical and proposed asymmetric turbo codes for error control coding. The baseline JPEG algorithm is used to compress a QCIF () "Suzie" image. The recursive systematic <b>convolutional</b> (RSC) <b>encoder</b> with generator polynomials, that is, (13 / 11) in decimal, and 3 G interleaver are used for the typical WCDMA and CDMA 2000 turbo codes. The proposed asymmetric turbo code uses generator polynomials, that is, (13 / 11; 13 / 9) in decimal, and a code-matched interleaver. The effect of interleaver in the proposed asymmetric turbo code is studied using weight distribution and simulation. The simulation results and performance bound for proposed asymmetric turbo code for the frame length, code rate with Log-MAP decoder over AWGN channel are compared with the typical system. From the simulation results, it is observed that the image transmission using proposed asymmetric turbo code performs better than that with the typical system. </p...|$|R
40|$|We {{introduce}} the variational graph auto-encoder (VGAE), {{a framework for}} unsupervised learning on graph-structured data based on the variational auto-encoder (VAE). This model makes use of latent variables and is capable of learning interpretable latent representations for undirected graphs. We demonstrate this model using a graph <b>convolutional</b> network (GCN) <b>encoder</b> and a simple inner product decoder. Our model achieves competitive results on a link prediction task in citation networks. In contrast to most existing models for unsupervised learning on graph-structured data and link prediction, our model can naturally incorporate node features, which significantly improves predictive performance {{on a number of}} benchmark datasets. Comment: Bayesian Deep Learning Workshop (NIPS 2016...|$|R
40|$|International audienceMost {{existing}} {{methods for}} action recognition mainly rely on manually engineered features which, despite their good performances, are highly problem dependent. We propose {{in this paper}} a fully automated model, which learns to classify human actions without using any prior knowledge. A <b>convolutional</b> sparse auto- <b>encoder</b> learns to extract sparse shift-invariant representations of the 2 D local patterns present in each video frame. The evolution of these mid-level features is learned by a Recurrent Neural Network trained to classify each sequence. Experimental results on the KTH dataset show that the proposed approach outperforms existing models which rely on learned-features, and gives comparable results with the best related works...|$|R
