10|369|Public
5000|$|Himmelwright was an {{environmentalist}} before his time whose belief in sustainable building practices is strongly stated in his preface to A Model Fire-Proof Farm House. He wrote:"A new epoch in home building is at hand. The wasteful, shortsighted and ephemeral {{methods of the}} past have become intolerable, and on account of our depleted timber supply, will soon be impossible.The conservation of the world's natural resources is attracting universal attention, and will undoubtedly receive {{a large portion of}} the best thought and consideration of the present generation. The conservation of individual resources and energy will follow as a natural consequence, and that is the keynote of this volume."The reckless destruction of our forests by the early settlers, supplemented by the wasteful practices of the large lumber companies, and finally, the enormous destruction by forest fires, have brought about greatly changed conditions. Our timber supply has been depleted to such an extent that according to statistics prepared by the United States Government, we take from our forests each year, not <b>counting</b> <b>loss</b> and waste, three and one half times their yearly growth; in other words, we use forty cubic feet per acre for each twelve cubic feet grown. We use two hundred and sixty cubic feet per capita, while Germany uses thirty-seven and France thirty-five. The large per capita consumption in the United States is attributable partly to our great fire losses, but principally to the ephemeral and flimsy character of our buildings. If the present rate of demand and supply is not changed, our timber resources will be entirely exhausted in a few years. Such a result would have far reaching consequences, and would be a national calamity. This can be averted, (1) by substituting incombustible and more durable materials for wood, and (2) by employing proper safeguards and appliances, thus preventing a large part of the annual fire loss."Twenty to fifty years ago when timber was abundant and the best only was selected for building purposes, much more durable houses were built than at present. Large sized and heavy pieces were used for the framing and the beams. These were frequently hewn by hand, so as to utilize the heart which is the best and most durable part of the timber."The cost of lumber is now from two to five times as great as formerly, and the quality is generally much inferior. Wood or [...] "frame" [...] buildings, as now constructed, are serviceable only for periods of from twenty to fifty years. After this comparatively short term, they become unsafe for human habitation and can be utilized only for a few years more for storage, after which, if not demolished, they decay, become dangerous, and finally fall to pieces. By frequent painting, prompt repairs, renewals of roofs, sills, etc., the period of serviceability may sometimes be extended twenty to thirty years longer , but this presumes a practical knowledge of building construction, the exercise of intelligent watchfulness and judgment, and a willingness to expend money for repairs before such repairs are actually necessary— a combination seldom found in present day owners."The home builders of the past generally took cognizance of their own immediate necessities and requirements only, and planned and built their homes accordingly. Such a course was the direct result of the fact that the serviceability of the buildings was limited to a period of one or two generations. In the design of a building which is to endure for an indefinite period, other features and a broader policy must influence the design. Instead of planning for his own family or his immediate successors, the designer of an enduring home must plan it so as to fulfill the requirements of an average family. Planned in this way, such a building will always be suitable for a majority of its future occupants and will have the maximum value."Himmelwright concluded the introduction, adding these comments linking family values to engineering and sustainable building practices:"A home built of durable and incombustible materials...conserves the resources and energies of the original owner and all his descendants. Its deterioration is inappreciable for from ten to twenty generations, during which time it retains its full original value, plus the added value due to the subsequent development and improvement of the section in which it is located. Consequently, it is a valuable inheritance to each succeeding generation. Furthermore, such a home is cumulative in its tendency and effect, in so far as its contents are concerned. Being durable, and fire-proof, it becomes a permanent receptacle for all the objects of intrinsic and sentimental value, accumulated by the original owner and his descendants; each generation adding its quota to the family treasures, until the home becomes a veritable storehouse of ever increasing value, not only financially, but educationally, and artistically. True, there may be periodical divisions and distributions of some of the contents, but this involves no sacrifice of actual value, and articles removed in this way often find their way back to such a home after the lapse of time. But by far the most important feature of a home of this character is the security and permanent immunity it affords against destruction by fire."An enduring and fire-proof home, therefore, conserves the energy and resources of the successive owners, assures permanent safety, comfort and satisfaction, and unlike a frame building, it retains indefinitely its full value as an asset and inheritance." ...|$|E
40|$|Statistical {{variance}} of x-ray intensity affected by <b>counting</b> <b>loss</b> of detection systems has been experimentally evaluated by a repeated Chipman’s foil method for a laboratory powder x-ray diffractometer and a high-resolution synchrotron powder diffractometer. The effects of <b>counting</b> <b>loss</b> were modeled by an intermediately extended dead-time model. It {{has been found}} that the statistical variance is satisfactorily reproduced applying the parameters evaluated by least-squares analyses on the data measured by a single-shot Chipman’s method. It means that the statistical errors attached to the observed intensity data can appropriately be predicted from the results of a rapid calibration measurement...|$|E
40|$|A {{counting}} system {{capable of}} processing input pulses {{at an average}} rate in excess of 3 x lO/sup 5 / counts per second with less than 10 % <b>counting</b> <b>loss</b> because of instrumental dead time is described. The system is capable of detecting thermal neutrons {{in the presence of}} a high gamma background. It consists of a fission counter, a preamplifier, linear amplifier, and integral discriminator. Components of the system are described in detail, and circuit diagrams and layout information are given. Factors governing the design are discussed; testing procedures and the performance are outlined. (auth...|$|E
5000|$|Qualified {{financial}} institutions may <b>count</b> <b>losses</b> on FNMA and FHLMC preferred stock against ordinary income, rather than capital gain income.|$|R
30|$|A {{similar study}} to ours was {{performed}} by Guy et al. [13], but they used 131 I while in our case, it is 177 Lu. They found large differences between the deadtime correction factor {{which was based on}} the analysis of the primary photon <b>count</b> <b>losses</b> and that based on the <b>count</b> <b>losses</b> in the full spectrum. The full-spectrum correction factor would be underestimated by up to 20 % when compared to the DT correction based only on PP.|$|R
40|$|Constructional {{details are}} given of a {{complete}} Geiger‐Müller counting system consisting of a stabilized high voltage supply, Neher‐Harper coupling circuit and vacuum‐tube scale‐of‐eight feeding a Cenco counter stage. The system is entirely a. c. operated. Its resolution time of 6. 5 × 10 − 6 second allows it to follow the G‐M circuit without <b>counting</b> <b>losses.</b> The <b>counting</b> <b>losses</b> in the Cenco counter stage are negligible for random input rates to the system up to 20, 000 – 30, 000 counts a minute...|$|R
40|$|Procedures for {{correcting}} the beam-beam effects in luminosity measurement at CLIC at 3 TeV CM energy are described and tested using Monte Carlo simulations: - Correction of the angular <b>counting</b> <b>loss</b> {{due to the}} combined Beamstrahlung and initial-state radiation (ISR) effects, based on the reconstructed velocity of the collision frame of the Bhabha scattering. - Deconvolution of the luminosity spectrum distortion due to the ISR emission. - Correction of the counting bias due to the finite calorimeter energy resolution. All procedures were tested by simulation. Bhabha events were generated using BHLUMI, and used in Guinea-PIG to simulate the outgoing momenta of Bhabha particles in the bunch collisions at CLIC. Residual uncertainties after correction are listed in {{a table in the}} conclusions. The beam-beam related systematic counting uncertainty in the luminosity peak can be reduced to the order of permille...|$|E
40|$|Procedures for {{correcting}} the beam-beam effects in luminosity measurements at CLIC at 3 TeV center-of-mass energy are described and tested using Monte Carlo simulations. The angular <b>counting</b> <b>loss</b> {{due to the}} combined Beamstrahlung and initial-state radiation effects is corrected based on the reconstructed velocity of the collision frame of the Bhabha scattering. The distortion of the luminosity spectrum due to the initial-state radiation is corrected by deconvolution. At the end, the counting bias due to the finite calorimeter energy resolution is numerically corrected. To test the procedures, BHLUMI Bhabha event generator, and Guinea-Pig beam-beam simulation were used to generate the outgoing momenta of Bhabha particles in the bunch collisions at CLIC. The systematic effects of the beam-beam interaction on the luminosity measurement are corrected with precision of 1. 4 permille in the upper 5 % of the energy, and 2. 7 permille in the range between 80 and 90 % of the nominal center-of-mass energy. Comment: 16 pages, 6 figures, version accepted for publication in Journal of Instrumentation. arXiv admin note: text overlap with arXiv: 1211. 686...|$|E
40|$|Citation: Li, Y., Liu, D., López-Paz, C., Olson, B. J. S. C., & Umen, J. G. (2016). A {{new class}} of cyclin {{dependent}} kinase in chlamydomonas is required for coupling cell size to cell division. eLife, 5 (MARCH 2016). doi: 10. 7554 /eLife. 10767 Proliferating cells actively control their size by mechanisms that are poorly understood. The unicellular green alga Chlamydomonas reinhardtii divides by multiple fission, wherein a ‘counting’ mechanism couples mother cell-size to cell division number allowing production of uniform-sized daughters. We identified a sizer protein, CDKG 1, that acts through the retinoblastoma (RB) tumor suppressor pathway as a D-cyclin-dependent RB kinase to regulate mitotic <b>counting.</b> <b>Loss</b> of CDKG 1 leads to fewer mitotic divisions and large daughters, while mis-expression of CDKG 1 causes supernumerous mitotic divisions and small daughters. The concentration of nuclear-localized CDKG 1 in pre-mitotic cells is set by mother cell size, and its progressive dilution and degradation with each round of cell division may provide a link between mother cell-size and mitotic division number. Cell-size-dependent accumulation of limiting cell cycle regulators such as CDKG 1 is a potentially general mechanism for size control. © Li et al...|$|E
40|$|Nuclear {{counting}} {{is affected}} by pulse pileup and system dead time which induce rate-related <b>count</b> <b>loss</b> and alter the statistical properties of the counting process. Fundamental equations are presented to predict deviations from Poisson statistics due to non-random <b>count</b> <b>loss</b> in nuclear counters and spectrometers. Throughput and dispersion of counts are studied for systems with pileup, extending and non-extending dead time, before and also after compensation for <b>count</b> <b>loss.</b> Equations are provided for random fractions of the output events, applicable to spectrometry applications. Methods for loss compensation are discussed, incl. inversion of the throughput equation, live-time counting and loss-free counting. Secondary effects in live-time counting are addressed: residual interference from pileup in systems with imposed dead times and errors due to varying count rate when measuring short-lived radionuclides. JRC. D. 4 -Standards for Nuclear Safety, Security and Safeguard...|$|R
30|$|System {{performance}} {{measurements of}} the dPET utilized NEMA NU 2 - 2012 procedures [29] for spatial resolution, sensitivity, scatter fraction, <b>count</b> <b>loss,</b> NECR, and image quality.|$|R
30|$|In our opinion, {{the issue}} of DT {{correction}} requires further investigation using large number of dataset from patients with different body shapes and sizes to fully understand the interdependence between primary photons <b>count</b> <b>losses</b> and patient’s body shape, scatter, and primary photon count rates.|$|R
40|$|Bangladesh is a {{small country}} of South—East Asia. It is a low-lying coastal area {{surrounded}} by India on three sides and Bay of Bengal in one side. It {{is one of the}} densely populated countries in the world. Natural disaster is a common phenomenon in this country. Most of the people live in villages and depend on agriculture for the livelihood. Agriculture is responsible for 32 % of the total GDP (An overview or the current economic growth in Bangladesh at www. GlobalPolicyNetwork. org). But there is no specific management level in agricultural sector as it is still running with old style fashion. Motivation as an incentive of inspiring employees in all sectors appears strongly in private sector enterprises and slightly in govt. sector organizations and Non Govt. Organizations (NG 0 s). Government sector organizations are <b>counting</b> <b>loss</b> year after year due to inappropriate training, shortage of skilled workers, poor salary, weak administration, poor ethical standard, corruption and overall lacking of motivation. Skilled and honest workers are being motivated in private sector organizations. Government organizations were never been designed according to any predetermined criteria. They were established and their goals were set by executive orders considering other factors like social, economic and technological environment. Here motivatio...|$|E
40|$|Time-Correlated Single Photon Counting (TCSPC) {{has been}} long {{recognized}} as the most sensitive method for fluorescence lifetime measurements, but often requiring “long” data acquisition times. This drawback {{is related to the}} limited counting capability of the TCSPC technique, due to pile-up and <b>counting</b> <b>loss</b> effects. In recent years, multi-module TCSPC systems have been introduced to overcome this issue. Splitting the light into several detectors connected to independent TCSPC modules proportionally increases the counting capability. Of course, multi-module operation also increases the system cost and can cause space and power supply problems. In this paper, we propose an alternative approach based on a new detector and processing electronics designed to reduce the overall system dead time, thus enabling efficient photon collection at high excitation rate. We present a fast active quenching circuit for single-photon avalanche diodes which features a minimum dead time of 12. 4 ns. We also introduce a new Time-to-Amplitude Converter (TAC) able to attain extra-short dead time thanks to the combination of a scalable array of monolithically integrated TACs and a sequential router. The fast TAC (F-TAC) makes it possible to operate the system towards the upper limit of detector count rate capability (∼ 80 Mcps) with reduced pile-up losses, addressing one of the historic criticisms of TCSPC. Preliminary measurements on the F-TAC are presented and discussed...|$|E
40|$|Dead-time {{losses are}} well {{recognized}} and studied drawbacks in counting and spectroscopic systems. In this work the abilities on dead-time correction of a real-time digital pulse processing (DPP) system for high-rate high-resolution radiation measurements are presented. The DPP system, through a fast and slow {{analysis of the}} output waveform from radiation detectors, is able to perform multi-parameter analysis (arrival time, pulse width, pulse height, pulse shape, etc.) at high input counting rates (ICRs), allowing accurate <b>counting</b> <b>loss</b> corrections even for variable or transient radiations. The fast analysis is used to obtain both the ICR and energy spectra with high throughput, while the slow analysis is used to obtain high-resolution energy spectra. A complete characterization of the counting capabilities, through both theoretical and experimental approaches, was performed. The dead-time modeling, the throughput curves, the experimental time-interval distributions (TIDs) and the counting uncertainty of the recorded events of both the fast and the slow channels, measured with a planar CdTe (cadmium telluride) detector, will be presented. The throughput formula {{of a series of}} two types of dead-times is also derived. The results of dead-time corrections, performed through different methods, will be reported and discussed, pointing out the error on ICR estimation and the simplicity of the procedure. Accurate ICR estimations (nonlinearity < 0. 5 %) were performed by using the time widths and the TIDs (using 10 - 14;ns time bin width) of the detected pulses up to 2. 2 - 14;Mcps. The digital system allows, after a simple parameter setting, different and sophisticated procedures for dead-time correction, traditionally implemented in complex/dedicated systems and time-consuming set-ups...|$|E
6000|$|And though naught falleth to us here [...] But gains {{the world}} <b>counts</b> <b>loss,</b> [...] Though all we hope of wisdom clear [...] When climbed to seems but dross, [...] Yet all, though ne'er Christ's faith they wear, [...] At least may share his cross.|$|R
30|$|Count rate {{accuracy}} {{was estimated}} by extrapolating the true rate for low-activity concentrations (where <b>count</b> <b>losses</b> and randoms can be effectively neglected) back to higher activity levels and {{comparing it to}} the measured and corrected trues rate. Data was reconstructed using the FORE algorithm and FBP.|$|R
30|$|Additionally, if imaged {{activities}} are very high, the <b>count</b> <b>losses</b> caused by camera dead time must be corrected for. In our phantom experiments the activities were relatively low, so no dead time corrections were necessary. Nevertheless, this topic {{has been extensively}} investigated by us in a separate study and will be reported shortly.|$|R
40|$|A {{meteorological}} balloon-borne cloud sensor {{called the}} cloud particle sensor (CPS) has been developed. The CPS {{is equipped with}} a diode laser at [*]∼[*]  790  nm and two photodetectors, with a polarization plate {{in front of one of}} the detectors, to count the number of particles per second and to obtain the cloud-phase information (i. e. liquid, ice, or mixed). The lower detection limit for particle size was evaluated in laboratory experiments as [*]∼[*]  2  µm diameter for water droplets. For the current model the output voltage often saturates for water droplets with diameter equal to or greater than [*]∼[*]  80  µm. The upper limit of the directly measured particle number concentration is [*]∼[*]  2  cm − 3 (2 [*]×[*] 10 3  L − 1), which is determined by the volume of the detection area of the instrument. In a cloud layer with a number concentration higher than this value, particle signal overlap and multiple scattering of light occur within the detection area, resulting in a <b>counting</b> <b>loss,</b> though a partial correction may be possible using the particle signal width data. The CPS is currently interfaced with either a Meisei RS- 06 G radiosonde or a Meisei RS- 11 G radiosonde that measures vertical profiles of temperature, relative humidity, height, pressure, and horizontal winds. Twenty-five test flights have been made between 2012 and 2015 at midlatitude and tropical sites. In this paper, results from four flights are discussed in detail. A simultaneous flight of two CPSs with different instrumental configurations confirmed the robustness of the technique. At a midlatitude site, a profile containing, from low to high altitude, water clouds, mixed-phase clouds, and ice clouds was successfully obtained. In the tropics, vertically thick cloud layers in the middle to upper troposphere and vertically thin cirrus layers in the upper troposphere were successfully detected in two separate flights. The data quality is much better at night, dusk, and dawn than during the daytime because strong sunlight affects the measurements of scattered light...|$|E
40|$|<b>Count</b> <b>loss</b> {{through a}} cascade of pile-up and dead time is studied. Time {{interval}} density distribution functions and throughput factors are presented for counters with a series arrangement of pile-up with extending or non-extending dead time. A counter is considered where an artifcial dead time is imposed on every counted event, {{in order to control}} the length and type of dead time. For such system, it is relatively easy to determine an average <b>count</b> <b>loss</b> correction factor via a live-time clock gated by the imposed dead time signal ('live-time mode'), or otherwise to apply a correction factor based on the inversion of the throughput function ('real-time mode'). However, these techniques do not account for additional loss through pulse pile-up. In this work, counting errors associated with neglecting cascade effects are calculated for measurements in live-time and real-time mode. JRC. D. 4 -Isotope measurement...|$|R
30|$|Despite the {{modifications}} {{from the}} 2007 to the 2012 standard, {{the results for}} the system sensitivity, the count rates, NECR, scatter fraction, corrections for <b>count</b> <b>losses</b> and random measurements as well as the count rate error are in accordance with published values for the mCT system [6] following the NEMA NU 2 - 2007 standard.|$|R
40|$|An {{overview}} {{is presented}} on recent {{progress in the}} field of nuclear counting statistics; theoretical expressions are shown to predict deviations from Poisson statistics due to non-random <b>count</b> <b>loss</b> in the spectrometer set-up. Frequently encountered misconceptions in the literature and in daily practice are uncovered: the unconditional belief in the general validity of Poisson statistics, the neglect of the dependency of counting statistics on the considered fraction of the pulse spectrum, the mix-up between pulse pile-up and extending dead time, the unawareness of the influence of pile-up rejection on the counting statistics in fixed live-time measurements and also with ‘loss-free counting’. Insight is provided into the statistical properties of spectra taken with ‘loss-free counting’ and ‘zero dead time’ counting, as well as the ‘variance spectrum’ provided with the latter. Uncertainty formulas are also presented for more conventional nuclear spectrometry measurements, with different types of <b>count</b> <b>loss.</b> JRC. D. 4 -Isotope measurement...|$|R
2500|$|Ottoman {{casualties}} were higher, totaling 325,000. Not <b>counting</b> <b>losses</b> due to disease (disease deaths were more numerous than battle deaths {{by a factor}} of two for the Ottomans in the war overall, and this proportion was even higher in Mesopotamia),Erickson 2001, p. 240 Ottoman irrecoverable battle casualties totaled 55,858 (13,069 KIA, 22,385 WIA, 20,404 POW). They were divided up as follows: ...|$|R
40|$|Characterization of the count-rate {{performance}} of scintillation cameras should {{include not only}} the specification of <b>count</b> <b>losses.</b> At high <b>count</b> rates, {{there is also an}} image distortion due to the mispositioning of pile-up events. In this paper a simple and clinically relevant procedure to quantify this distortion is presented. The images of a square uniform technetium- 99 m phantom at high and low count rates are used. The fraction of the total counts being correctly positioned is determined as the peripheral count density divided by the total average count density. This ratio, corrected for the camera non-uniformity at low count rates, is called the 'positioning ability'. According to the National Electrical Manufacturers' Association (NEMA), the 'system count rate performance with scatter' should be reported as the measured count rate giving 20 % <b>count</b> <b>losses.</b> In this paper it is suggested that this measure be complemented by a measure of the fraction correct positioned events at this count rate. This fraction, the 'high count rate positioning ability', can be easily and accurately measured using our method. The method has been tested on two different scintillation cameras. For one of them the high count rate positioning ability was determined as 91 % at a measured count rate of 30, 000 s- 1 with 20 % <b>count</b> <b>losses.</b> For the other camera, the corresponding figures were 88 % at 59, 000 s- 1 and close to 100 % at 38, 000 s- 1, before and after the installation of a new pile-up rejection circuit, respectively...|$|R
40|$|Thirty-six Angus-Hereford steers {{were fed}} four diets of {{different}} potassium concentration for 2 -week periods such that each steer received each diet for a 2 -week period. The relationship between 40 K <b>count</b> <b>loss</b> {{and weight loss}} during a 24 -hr. shrink period was evaluated by regression analysis. At {{the end of each}} of the four feeding periods the steers,were weighed and 40 K counted unshrunk and again after 24 -hr. shrink. The mean weight loss during shrink was similar for all treatments (overall mean of 22. 8 kg), however the mean 40 K <b>count</b> <b>loss</b> was larger for the high potassium diets than for low potassium diets although the rank of these means did not correspond to the potassium content of the diets. The overall loss in 40 K count during shrink was 708. 3 (S. D. = 449. 2) counts per minute. The regression coefficients of <b>count</b> <b>loss</b> on weight loss during shrink were not significantly different among treatments. The pooled regression coefficient was 22. 5 ± 5. 4 cpm per kilogram. When 40 K count was regressed on weight, all regression coefficients were significantly (P 3 ̆c. 01) greater than zero, however regression coefficients for the various treatments were not significantly different from each other, although there was a tendency for coefficients to be higher for high potassium diets and on unshrunk measurements. Pooled unshrunk and shrunk regression coefficients of 40 K count on weight were 14. 75 ± 1. 92 and 12. 41 ± 1. 76 cpm per kilogram, respectively...|$|R
5000|$|... and <b>count</b> the <b>losses</b> worth / To see {{across the}} darkness/ The green hills of Earth...|$|R
30|$|Since <b>count</b> <b>losses</b> due to DT {{depend on}} the scatter {{characteristics}} of a particular patient (related to his/her body size), {{it is reasonable to}} expect that the DTCF should be analyzed as a function of observed count rates in the full spectrum as these will be the least affected {{by the size of the}} patient. This approach is being used in our method as described above.|$|R
30|$|INJ). The trues {{rates of}} the {{myocardial}} transit phase show the expected increases with higher activity used and are unaffected by <b>count</b> <b>losses</b> {{as indicated by the}} live-time fraction. It should be noted that as in clinical studies, the amount of activity in the field of view for perfusion phantom simulations changes rapidly over time, and therefor, of primary interest to our work is the peak activity during the input phase.|$|R
50|$|Most people develop {{side effects}}. Common side effects include low {{white blood cell}} <b>counts,</b> <b>loss</b> of appetite, vomiting, hair loss, and {{bleeding}} from the bladder. Other severe side effects include an increased future risk of cancer, infertility, allergic reactions, and pulmonary fibrosis. Cyclophosphamide is in the alkylating agent and nitrogen mustard family of medications. It is believed to work by interfering with the duplication of DNA {{and the creation of}} RNA.|$|R
60|$|Q. Indeed {{this is a}} full place, can {{you give}} me one more?--A. Yes; 'What things were gain to me, those I <b>counted</b> <b>loss</b> for Christ. Yea, doubtless, and I count all things but loss for the {{excellency}} of the knowledge of Christ Jesus my Lord: for whom I have suffered the loss of all things, and do count them but dung, that I may win Christ,' &c. (Phil 3:7,8).|$|R
50|$|Mastitis - a {{persistent}} and potentially fatal mammary gland infection, leading to high somatic cell <b>counts</b> and <b>loss</b> of production.|$|R
30|$|Measurements of scatter fraction, <b>count</b> <b>losses,</b> and NECR were {{performed}} using the NEMA PET scatter phantom. A plastic tubing (3.2  mm inner diameter) filled with ~[*] 1100  MBq 18 F over {{a length of}} 70  cm was measured over 16 -h until the activity decayed to a low level with true events losses of <[*] 1 %. Data were binned into sinograms and {{used to calculate the}} scatter fraction and count rates.|$|R
30|$|The paralyzable model showed to be {{appropriate}} for the investigated range of counts, which were five to six times higher than those observed in the patient post-therapy imaging. Our {{results suggest that the}} deadtime corrections should be based on <b>count</b> <b>losses</b> in the scatter-corrected photopeak window and not on the deadtime determined from the full spectrum. Finally, a general procedure that can be followed to correct patient images for deadtime is presented.|$|R
40|$|Issues {{associated}} with making quantitative {{measurements of the}} arsenic implant dose in silicon by SIMS are described. These {{include the use of}} a certified reference material for calibration, the choice of silicon matrix reference species, the matrix normalization method, and minimization of detector <b>count</b> <b>losses.</b> A round-robin study is being conducted by ISO TC 201 /SC 6 to determine the best analytical procedures and the level of interlaboratory agreement for this type of measurement...|$|R
30|$|In is {{important}} to realize that even when high activities are administered in therapy procedures, the DT <b>count</b> <b>losses</b> are typically observed only in the first scan, done shortly after the injection. Based on our experience with therapy patients, the DT correction is typically less or much less than 10 %. Since dosimetry calculations are based on the time-integrated activity, the change in total organ/tumor dose due to the DT correction is expected to be relatively small.|$|R
25|$|Only {{competitive}} matches are <b>counted.</b> Wins, <b>losses</b> {{and draws}} are results {{at the final}} whistle; the results of penalty shootouts are not counted.|$|R
