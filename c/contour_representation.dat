96|167|Public
5000|$|Most 18th {{and early}} 19th century {{national}} surveys did not record relief {{across the entire}} area of coverage, calculating only spot elevations at survey points. The United States Geological Survey (USGS) topographical survey maps included <b>contour</b> <b>representation</b> of relief, and so maps that show relief, especially with exact representation of elevation, {{came to be called}} topographic maps (or [...] "topo" [...] maps) in the United States, and the usage has spread internationally.|$|E
40|$|We {{review the}} status of the " of the Renormalization Group {{encountered}} when one tries to de ne rigorously the Renormalization Group transformation as a map between Hamiltonians. We explain their origin and clarify their status by relating them to the Gri ths ' singularities appearing in disordered systems � moreover, we suggest {{that the best way to}} avoid those pathologies is to use the <b>contour</b> <b>representation</b> rather than the spin representation for lattice spin models at low temperatures. Finally, we outline how to implement the Renormalization Group in the <b>contour</b> <b>representation.</b> ...|$|E
40|$|Abstract- A novel <b>contour</b> <b>representation</b> {{algorithm}} for binary {{images is}} proposed in this paper. It {{is an extension}} of the conventional chain code. The precise, efficient and simple algorithm exploits the features of the conventional chain code when advantageous. More robust to noise, the algorithm also uses very low bit-rate. The corresponding reconstruction algorithm is completely reversible to give the lossless reconstruction of the contour. Experimental results on various binary images add to the improved efficiency claim of the proposed <b>contour</b> <b>representation</b> algorithm in terms of visual fidelity and bit-rate. I...|$|E
5000|$|A Ghosh, N Petkov: Robustness {{of shape}} {{descriptors}} to incomplete <b>contour</b> <b>representations.</b> IEEE transactions on pattern analysis and machine intelligence 27 (11), 2005: 1793 -1804 ...|$|R
40|$|We {{propose the}} Hermite <b>representation</b> for {{deformable}} <b>contour</b> finding. This <b>representation</b> compares favorably {{in terms of}} versatility and controlability with other local <b>contour</b> <b>representations</b> {{that have been used}} previously for this purpose. The Hermite representation allows a compact representation of curved shapes, without the smoothing out of corners. It is also well suited for both interactive and tracking applications...|$|R
40|$|With {{inspiration}} from psychophysical researches {{of the human}} visual system we propose a novel method for performance evaluation of contour based shape recognition algorithms. We use complete <b>contour</b> <b>representations</b> of objects as a training set. Incomplete <b>contour</b> <b>representations</b> of the same objects are used as a test set and the recognition performance of two shape based methods is investigated. The amount of incompleteness in test cases is quantified using the percentage of contour pixels retained. The performances of the methods are reported using the recognition rate {{as a function of}} the degree of incompleteness. We consider three types of incomplete <b>contour</b> <b>representations,</b> viz. segment-wise deletion, occlusion and random pixel depletion. The methods compared in this framework use shape context and distance multiset as local shape descriptors. Qualitatively, both methods mimic human visual perception in the sense that they perform best in the case of random depletion and worst in the case of occluded contours. Quantitatively, the distance multiset method performs better than the shape context method in this test framework. ...|$|R
40|$|In {{this letter}} a {{screening}} current or <b>contour</b> <b>representation</b> is given of certain quantum superalgebras. The Gomez-Sierra construction of quantum groups in conformal field theory is generalized to cover superalgebras and illustrated using recent results on screening currents in affine current superalgebra. Comment: 9 pages, LaTe...|$|E
30|$|Depending on the <b>contour</b> <b>representation,</b> the {{resulting}} Fourier coefficients will behave differently under the geometric transformations scaling, rotation, and start point shift. When the contour points are transformed {{by any of}} these operations, the Fourier coefficients change according to simple rules, {{which can be used}} to define invariant descriptors.|$|E
40|$|In 1975 Parsons {{developed}} his dictionary of musical themes {{based on a}} simple <b>contour</b> <b>representation.</b> The motivation was that people with little training in music {{would be able to}} identify pieces of music. We decided to test whether people of various levels of musical skill could indeed make use of a text representation to describe a simple melody query. The results indicate that the task is beyond those who are unmusical, and that a scale numeric representation is easier than a contour one for those of moderate musical skill. Further, a common error when using the scale representation still yields a more accurate <b>contour</b> <b>representation</b> than if a user is asked to enter a contour query. We observed an average query length of about seven symbols for the retrieval task. ...|$|E
50|$|This {{is evident}} from the <b>contour</b> {{integral}} <b>representation</b> below.|$|R
40|$|Present image {{processing}} algorithms {{are unable to}} extract a neat and closed contour of an object of interest from a natural image. Advanced contour detection algorithms extract the contour of an object of interest from a natural scene with {{a side effect of}} depletion of the contour. Hence in order to perform well in a real world scenario, object recognition algorithms should be robust to contour incompleteness. With inspiration from psychophysical studies of the human cognitive abilities we propose a novel method to evaluate the performance of object recognition algorithms in terms of their robustness to incomplete <b>contour</b> <b>representations.</b> Complete <b>contour</b> <b>representations</b> of objects are used as a reference (training) set. Incomplete <b>contour</b> <b>representations</b> of the same objects are used as a test set. The performance of an algorithm is evaluated using the recognition rate {{as a function of the}} percentage of contour retained. The test framework is illustrated by using two contour based shape recognition algorithms which use a shape context and a distance multiset as shape descriptors. Three types of contour incompleteness, viz. segment-wise contour deletion, occlusion and random pixel depletion, are considered. In our experiments we use images from the COIL and MPEG- 7 datasets. Both algorithms qualitatively perform similar to the human visual system in the sense that recognition performance monotonously increases with the degree of completeness and that they perform best in the case of random depletion and worst in the case of occluded contours. The distance multiset shape descriptor outperforms the shape context in this test especially for high levels of incompleteness. ...|$|R
40|$|Inspired by psychophysical {{studies of}} the human {{cognitive}} abilities we propose a novel aspect and a method for performance evaluation of contour based shape recognition algorithms regarding their robustness to incompleteness of contours. We use complete <b>contour</b> <b>representations</b> of objects as a reference (training) set. Incomplete <b>contour</b> <b>representations</b> of the same objects are used as a test set. The performance of an algorithm is reported using the recognition rate {{as a function of}} the percentage of contour retained. We call this evaluation procedure the ICR test. We consider three types of contour incompleteness, viz. segment-wise contour deletion, occlusion and random pixel depletion. We illustrate the test procedure using two shape recognition algorithms. These algorithms use a shape context and a distance multiset as local shape descriptors. Both algorithms qualitatively mimic human visual perception in the sense that the recognition performance monotonously increases with the degree of completeness and that they perform best in the case of random depletion and worst in the case of occluded contours. The distance multiset method performs better than the shape context method in this evaluation framework. ...|$|R
30|$|First of all, we give two {{generalized}} Leibniz {{rules for}} fractional derivatives. Theorem  1 is a slightly modified theorem obtained in 1970 by Osler [26]. Theorem  2 was given, some years ago, by Tremblay et al. [33] {{with the help}} of the properties of Pochhammer’s <b>contour</b> <b>representation</b> for fractional derivatives.|$|E
40|$|Contour {{representations}} of binary images of handwritten words afford considerable reduction in storage requirements while providing lossless representation. On the other hand, the one-dimensional nature of contours presents interesting challenges for processing images for handwritten word recognition. Our experiments indicate that significant gains {{are to be}} realized in both speed and recognition accuracy by using a <b>contour</b> <b>representation</b> in handwriting applications...|$|E
40|$|Dirac's <b>contour</b> <b>representation</b> is {{extended}} to parabose and parafermi systems {{by use of}} deformed algebra techniques. In this analytic representation {{the action of the}} paraparticle annihilation operator is equivalent to a deformed differentiation which encodes the statistics of the paraparticle. In the parafermi case, the derivative's ket-domain is degree $p$ polynomials. Comment: 15 pages, LaTex file, no macros, no figure...|$|E
40|$|International audienceIn {{the field}} of digital geometry, {{numerous}} advances have been recently made to efficiently represent a simple polygonal shape; from dominant points of a curvature-based representation, a binary shape is efficiently represented even in presence of noise. In this article, we exploit recent results of such digital <b>contour</b> <b>representations</b> and propose an image vectorization algorithm allowing a geometric quality control. All the results {{presented in this paper}} can also be reproduced online...|$|R
40|$|This paper aims {{to address}} the ability of {{self-organizing}} neural network models to manage video and image processing in real-time. The Growing Neural Gas networks (GNG) with its attributes of growth, flexibility, rapid adaptation, and excellent quality representation of the input space makes it a suitable model for real time applications. A number of applications are presented that includes: image compression, hand and medical image <b>contours</b> <b>representation,</b> surveillance systems, hand gesture recognition systems or 3 D data reconstruction...|$|R
50|$|Veraldi {{employs a}} {{distinctive}} style of two-dimensional, monochromatic line art. Her works {{focus on the}} outlines of her subjects and typically use solid pigment rather than shading or colour to draw contrast. She occasionally makes use of bold colors as accents in a portrait. Although rooted in the realistic portrayal of visual objects, her broad, somewhat minimalist, strokes eliminate nuanced features, resulting in a cartoonish but <b>contoured</b> <b>representation.</b> Her drawings of celebs are lighthearted and uniquely identifiable.|$|R
40|$|Eigenstates of the parabose and parafermi {{creation}} {{operators are}} constructed. In the Dirac <b>contour</b> <b>representation,</b> the parabose eigenstates {{correspond to the}} dual vectors of the parabose coherent states. In order $p= 2 $, conserved-charge parabose creation operator eigenstates are also constructed. The contour forms of the associated resolutions of unity are obtained. Comment: 14 pages, LaTex file, no macros, no figure...|$|E
40|$|Time series {{representations}} {{are common}} in MIR applications such as query-by-humming, where a sung query might be represented {{by a series of}} `notes' for database retrieval. While such a transcription into (pitch, duration) pairs is convenient and musically intuitive, {{there is no evidence that}} it is an optimal representation. The present work explores three time series representations for sung queries: a sequence of notes, a `smooth' pitch contour, and a novel sequence of pitch histograms. Dynamic alignment procedures are described for the three representations. Multiple continuity constraints are explored and a modified dynamic alignment procedure is described for the histogram representation. We measure the performance of the three representations using a collection of naturally sung queries applied to a target database of varying size. The results show that the note representation lends itself to rapid retrieval whereas the <b>contour</b> <b>representation</b> lends itself to robust performance. The histogram representation yields performance nearly as robust as the <b>contour</b> <b>representation,</b> but with computational complexity similar to the note representation...|$|E
30|$|This {{paper is}} {{organised}} as follows: In Section 2 we give an overview over different Fourier descriptors {{described in the}} literature for closed contours of unbroken shapes. In Section 3 we describe our new method for a <b>contour</b> <b>representation</b> of broken shapes and define different methods to obtain invariant Fourier descriptors from this representation. Sections 4 and 5 contain {{the results of a}} comparative evaluation of the different Fourier descriptors and the conclusions drawn therefrom.|$|E
40|$|AbstractContour {{interpolation}} mechanisms allow {{perception of}} bounded objects despite incomplete edge information. Here, we introduce a paradigm that maps interpolated contours as they unfold over time. Observers localize dots relative to perceived boundaries of illusory, partly occluded, or control stimuli. Variations {{in performance with}} dot position and processing time reveal the location and precision of emerging <b>contour</b> <b>representations.</b> Illusory and occluded contours yielded more proficient dot localization than control stimuli containing only spatial cues, suggesting performance based on low-level <b>representations.</b> Further, illusory <b>contours</b> exhibited a distinct developmental time course, emerging over the first 120 ms of processing. These experiments establish {{the effectiveness of the}} dot localization paradigm for examining interpolated edge <b>representations,</b> <b>contour</b> microgenesis, and the underlying processing mechanisms...|$|R
40|$|Abstract—With {{inspiration}} from psychophysical researches {{of the human}} visual system, we propose a novel aspect and a method for performance evaluation of contour-based shape recognition algorithms regarding their robustness to incompleteness of contours. We use complete <b>contour</b> <b>representations</b> of objects as a reference (training) set. Incomplete <b>contour</b> <b>representations</b> of the same objects are used as a test set. The performance of an algorithm is reported using the recognition rate {{as a function of}} the percentage of contour retained. We call this evaluation procedure the ICR test. We consider three types of contour incompleteness, viz. segment-wise contour deletion, occlusion, and random pixel depletion. As an illustration, the robustness of two shape recognition algorithms to contour incompleteness is evaluated. These algorithms use a shape context and a distance multiset as local shape descriptors. Qualitatively, both algorithms mimic human visual perception in the sense that recognition performance monotonously increases with the degree of completeness and that they perform best in the case of random depletion and worst in the case of occluded contours. The distance multiset method performs better than the shape context method in this test framework...|$|R
40|$|A {{recently}} proposed {{visual aid}} {{for patients with}} a restricted visual field (tunnel vision) combines a see-through head-mounted display and a simultaneous minified contour view of the wide-field image of the environment. Such a widening of the effective visual field is helpful for tasks, such as visual search, mobility, and orientation. The sufficiency of image contours for performing everyday visual tasks is of major importance for this application, {{as well as for}} other applications, and for basic understanding of human vision. This research aims is to examine and compare the use of different types of automatically created <b>contours,</b> and <b>contour</b> <b>representations,</b> for practical everyday visual operations using commonly observed images. The visual operations include visual searching for items, such as cutlery, housewares, etc. Considering different recognition levels, identification of an object is distinguished from mere detection (when the object is not necessarily identified). Some nonconventional visualbased <b>contour</b> <b>representations</b> were developed for this purpose. Experiments were performed with normal-vision subjects by superposing contours of the wide field of the scene over a narrow field (see-through) background. From the results, it appears that about 85 % success is obtained for searched object identification when the best contour versions are employed. Pilot experiments with video simulations are reported {{at the end of the}} paper. © 201...|$|R
40|$|A quad-tree-based {{hierarchical}} <b>contour</b> <b>representation</b> and coding {{method is}} studied. This method {{is based on}} multiscale line segments—beamlets. Simulations are reported {{to evaluate the effectiveness}} of such an approach. This is a proof-of-concept study. The reported compression ratios are not the “best”. However, the idea of tree-based coding is novel; and this idea has good potential to realize a progressive contour coding, which is important in applications such as content-based video transmission. 1...|$|E
40|$|Abstract—Contour {{representations}} of binary images of handwritten words afford considerable reduction in storage requirements while providing lossless representation. On the other hand, the one-dimensional nature of contours presents interesting challenges for processing images for handwritten word recognition. Our experiments indicate that significant gains {{are to be}} realized in both speed and recognition accuracy by using a <b>contour</b> <b>representation</b> in handwriting applications. Index Terms—Image processing, chain code, handwriting recognition, preprocessing, segmentation, feature extraction. æ...|$|E
40|$|A new way {{for obtaining}} the bound-states for {{arbitrary}} non zero l-states of the rotating Morse potential is presented. We show that by {{making use of}} the inverse <b>contour</b> <b>representation,</b> {{which is based on}} a knowledge of the integral representation of Euler's beta function, the radial wave-function as well as their energy eigenvalues are deduced. The results obtained are compared with the findings in the literature and it is found that are good agreement with those deduced by others methods. Comment: 10 page...|$|E
40|$|Psychophysical {{researches}} on {{the human}} visual system {{have shown that the}} points of high curvature on the contour of an object {{play an important role in}} the recognition process. Inspired by these studies we propose: (i) a novel algorithm to select points of high curvature on the contour of an object which can be used to construct a recognizable polygonal approximation, (ii) a test which evaluates the effect of deletion of contour segments containing such points on the performance of contour based object recognition algorithms. We use complete <b>contour</b> <b>representations</b> of objects as a reference (training) set. Incomplete <b>contour</b> <b>representations</b> of the same objects are used as a test set. The performance of an algorithm is reported using the recognition rate as a function of the percentage of contour retained. We consider two types of contour incompleteness obtained by deletion of contour segments of high or low curvature. We illustrate the test procedure using two shape recognition algorithms that deploy a shape context and a distance multiset as local shape descriptors. Both algorithms qualitatively mimic human visual perception in that the deletion of segments of high curvature has a stronger performance degradation effect than the deletion of other parts of the contour. This effect is more pronounced in the performance of the shape context method. ...|$|R
40|$|In this paper, {{we propose}} to study {{different}} smoothness measures of planar contours or surfaces. We first define a smoothness measure as a functional that follows {{three types of}} invariance : invariance to changes of contour parameterization, invariance to contour rotations and translations and invariance to the contour sizes. We then introduce different smoothness measures that can be classified into local or global functionals but also that can be of geometric or algebraic nature. We finally discuss their implementation by observing {{the advantages and disadvantages}} of explicit and implicit <b>contour</b> <b>representations.</b> ...|$|R
40|$|Some {{meaningful}} prosodic patterns can be usefully represented with pitch contours, however developing {{such descriptions}} is a labor-intensive process. To {{assist in the}} discovery of <b>contour</b> <b>representations,</b> visualization tools may be helpful. Edlund et al. [1] proposed the superimposition of hundreds of pitch curves from a corpus to reveal the general patterns. In this paper we refine and extend this method, and illustrate its utility in {{the discovery of a}} prosodic cue for back-channels in Chinese. Index Terms: prosodic cue, tune, turn-taking, back-channel, Chinese, bitmap cluster, overlay, superimpos...|$|R
40|$|In {{this work}} we propose a new {{statistic}} deformable model {{that we call}} discriminant snake for 3 D reconstruction in volumetric images. Our discriminant snake generalises the classical snake attracted by edge points, it deforms due to a generalised <b>contour</b> <b>representation.</b> The snake selects and classifies image features by a parametric classifier and each snaxel deforms to minimise the dissimilarity between the learned and found image features inside the feature space. We apply our statistic snake to segment anatomical organs {{and the results are}} very encouraging...|$|E
40|$|This article {{describes}} a novel algorithmic development extending the contour advective semi-Lagrangian model to include nonconservative effects. The Lagrangian <b>contour</b> <b>representation</b> of finescale tracer fields, such as potential vorticity, allows for conservative, nondiffusive treatment of sharp gradients allowing very high numerical Reynolds numbers. It {{has been widely}} employed in accurate geostrophic turbulence and tracer advection simulations. In the present, diabatic version of the model the constraint of conservative dynamics is overcome by including a parallel Eulerian field that absorbs the nonconservative (diabatic) tendencies. The diabatic buildup in this Eulerian field is limited through regular, controlled transfers of this field to the <b>contour</b> <b>representation.</b> This transfer is done with a fast newly developed contouring algorithm. This model has been implemented for several idealized geometries. In this paper a single-layer doubly periodic geometry is used {{to demonstrate the validity}} of the model. The present model converges faster than the analogous semi-Lagrangian models at increased resolutions. At the same nominal spatial resolution the new model is 40 times faster than the analogous semi-Lagrangian model. Results of an orographically forced idealized storm track show nontrivial dependency of storm-track statistics on resolution and on the numerical model employed. If this result is more generally applicable, this may have important consequences for future high-resolution climate modeling...|$|E
30|$|When {{implementing}} an algorithm for computing the <b>contour</b> <b>representation</b> (x(t),y(t),d(t)), {{two questions}} occur: how the convex hull should be sampled {{and how the}} distances d(t) can be efficiently computed. The vertices of the convex hull polygon can be obtained e.g. with Graham’s scan algorithm[17]. These vertices are obvious sampling points, but their distance can be arbitrary, so that the edges need to be sampled. As the image sampling distance is one pixel, it is natural to compute the edge length l and to add ⌊l[*]-[*] 1 ⌋ equidistant sampling points on each edge.|$|E
40|$|We {{propose the}} Hermite <b>representation</b> for {{deformable}} <b>contour</b> finding. This <b>representation</b> compares favorably {{in terms of}} versatility and controlability with other local <b>contour</b> <b>representations</b> {{that have been used}} previously for this purpose. The Hermite representation allows a compact representation of curved shapes, without the smoothing out of corners. It is also well suited for both interactive and tracking applications. The Hermite representation is used to formulate the contour finding problem as an optimization problem using a maximum a posteriori energy criterion. Optimization is performed by dynamic programming. Our approach to contour tracking decouples the effects of transformation and deformation, using a template matching strategy to robustly account for the transformation effect. We demonstrate these ideas on a variety of images from different domains. 1 Introduction Image segmentation by boundary finding is one of the central problems in computer vision. This is because [...] ...|$|R
40|$|In recent years, {{the field}} of active-contour based image {{segmentation}} have seen the emergence of two competing approaches. The first and oldest approach represents active contours in an explicit (or parametric) manner corresponding to the Lagrangian formulation. The second approach represent active contours in an implicit manner corresponding to the Eulerian framework. After comparing these two approaches, we describe several new topological and physical constraints applied on parametric active contours in order to combine the advantages of these two <b>contour</b> <b>representations.</b> We introduce three key algorithms for independently controlling active contour parameterization, shape and topology. We compare our result to the level-set method and show similar results with a significant speed-up...|$|R
40|$|In contour-based shape {{representation}} different schemas exist [1], like order numbering, geometric moments [2], Fourier-based coefficients [3] or autoregressive (AR) models [4]. In [3] {{an interesting}} comparison is described between AR-methods and Fourier-based methods for <b>contour</b> feature <b>representation...</b>|$|R
