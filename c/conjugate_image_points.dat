7|3682|Public
30|$|The {{proportionality}} of the x-parallax disparity {{and ground}} height {{can also be}} validated by area-based stereo matching algorithm described in the previous section. The x-parallax disparity between the <b>conjugate</b> <b>image</b> <b>points</b> from resampled epipolar image pair and the ground heights of the corresponding ground points, which can be calculated by the newly generated RPCs, are investigated the proportionality between them. The difference between the fitted lines {{is used as a}} performance metric for these criteria.|$|E
40|$|The {{dimensional}} {{quantitative analysis}} of human motion requires {{the reproduction of}} three dimensional coordinates from multiple camera images. In current photogrammetric systems the ability to identify and track individual camera image points imposes limitations on the accuracy and complexity of human motion analysis. Current photogrammetric systems are limited {{by the number of}} cameras, three dimensional segments, markers per segment, and the complexity of movement possible due to the increased difficulty and time required to reproduce three dimensional coordinates. The automated reconstruction and tracking of three dimensional coordinates may overcome these limitations by removing the necessity to track and identify two dimensional camera coordinates. The aims of the present research were firstly, to identify limitations and practical problems {{associated with the use of}} conjugate imagery in the reproduction of three dimensional coordinates, and secondly, to identify and implement techniques involving conjugate imagery for the automated reproduction of three dimensional coordinates. The methods and procedures developed in the current research provides the basis for future research into automated three dimensional tracking. Four criterion measures, i) Conjugate Point Error, ii) Lab Point Standard Error, iii) Lab Point Error, and iv) Lab Point Paired Error, were established for determining the validity of <b>conjugate</b> <b>image</b> <b>points.</b> Based on the criterion measures an algorithm was developed which accurately reproduced three dimensional coordinates and <b>conjugate</b> <b>image</b> <b>points</b> for a 55 point marker system viewed in four cameras (digitisation error 3 ̆c 0. 2...|$|E
40|$|Epipolar {{resampling}} aims {{to eliminate}} the vertical parallax of stereo images. Due to the dynamic nature of the exterior orientation parameters of linear pushbroom satellite imagery and the complexity of reconstructing the epipolar geometry using rigorous sensor models, so far, no epipolar resampling approach has been proposed based on these models. In this paper {{for the first time}} it is shown that the orientation of the instantaneous baseline (IB) of <b>conjugate</b> <b>image</b> <b>points</b> (CIPs) in the linear pushbroom satellite imagery can be modeled with high precision in terms of the rows- and the columns-number of CIPs. Taking advantage of this feature, a novel approach is then presented for epipolar resampling of cross-track linear pushbroom satellite imagery. The proposed method is based on the rigorous sensor model. As the instantaneous position of sensors remains fixed, the digital elevation model of the area of interest is not required in the resampling process. Experimental results obtained from two pairs of SPOT and one pair of RapidEye stereo imagery with different terrain conditions shows that the proposed epipolar resampling approach benefits from a superior accuracy, as the remained vertical parallaxes of all CIPs in the normalized images are close to zero...|$|E
50|$|The {{transformation}} between {{object space}} and image space is completely {{defined by the}} cardinal points of the system, and these points {{can be used to}} map any point on the object to its <b>conjugate</b> <b>image</b> <b>point.</b>|$|R
5000|$|... #Caption: The optical {{setup and}} light path of {{critical}} illumination showing the <b>conjugate</b> <b>image</b> planes {{of the various}} optical components.|$|R
50|$|Microscopes using Köhler {{illumination}} must be routinely {{checked for}} correct alignment. The realignment procedure tests whether the correct optical components are in focus {{at the two}} sets of <b>conjugate</b> <b>image</b> planes; the light source image planes and the specimen image planes.|$|R
40|$|High-resolution Cassini stereo {{images of}} Saturn’s moon Phoebe {{have been used}} to derive a {{regional}} digital terrain model (DTM) and an orthoimage mosaic of the surface. For DTM-control a network of 130 points measured in 14 images (70 – 390 m/pixel resolution) was established which was simultaneously used to determine the orientation of the spin-axis. The J 2000 spin-axis was found at Dec 78. 0170. 11 and RA 356. 6170. 31, substantially different from the former Voyager solution. The control points yield a mean figure radius of 107. 2 km with RMS residuals of 6. 2 km demonstrating the irregular shape of this body. The DTM was computed from densely spaced <b>conjugate</b> <b>image</b> <b>points</b> determined by methods of digital image correlation. It has a horizontal resolution of 1 – 2 km and vertical accuracies in the range 50 – 100 m. It is limited in coverage, but higher in resolution than the previously derived global shape model of Phoebe [Porco et al., 2005. Cassini imaging science: initial results on Phoebe and Iapetus. Science 307, 1237 – 1242] and allows us to study the morphology of the surface in more detail. There is evidence for unconsolidated material from a steep and smooth slope at the rim of a 100 km impact feature. There are several conically shaped craters on Phoebe, which may hint at highly porous and low compaction material on the surface...|$|E
40|$|With the {{popularity}} of geospatial applications, database updating is getting important due to the environmental changes over time. Imagery provides a lower cost and efficient way to update the database. Three dimensional objects can be measured by space intersection using <b>conjugate</b> <b>image</b> <b>points</b> and orientation parameters of cameras. However, precise orientation parameters of light amateur cameras are not always available due to their costliness and heaviness of precision GPS and IMU. To automatize data updating, the correspondence of object vector data and image may be built to improve the accuracy of direct georeferencing. This study contains four major parts, (1) back-projection of object vector data, (2) {{extraction of image feature}} lines, (3) object-image feature line matching, and (4) line-based orientation modeling. In order to construct the correspondence of features between an image and a building model, the building vector features were back-projected onto the image using the initial camera orientation from GPS and IMU. Image line features were extracted from the imagery. Afterwards, the matching procedure was done by assessing the similarity between the extracted image features and the back-projected ones. Then, the fourth part utilized line features in orientation modeling. The line-based orientation modeling was performed by the integration of line parametric equations into collinearity condition equations. The experiment data included images with 0. 06 m resolution acquired by Canon EOS Mark 5 D II camera on a Microdrones MD 4 - 1000 UAV. Experimental results indicate that 2. 1 pixel accuracy may be reached, which is equivalent to 0. 12 m in the object space...|$|E
40|$|Interferometric {{synthetic}} aperture radar (InSAR) is a promising recent technique for the generation of digital elevation models and/or the measurement of ground surface deformations. In InSAR data processing, {{the first step is}} the image co-registration, achieved by using a set of tie points which are the <b>conjugate</b> <b>image</b> <b>points</b> on the master and slave images. Tie points are selected with the aim of finding the conjugate point automatically on the slave image for any given point on the master image, by the process known as image matching. To achieve reliable matching, a set of points within a window is used instead of a single point. The size of the window will affect the reliability of matching. Hitherto there have been no effective methods for the determination of optimum window size for this purpose. In practice, this parameter is determined by experience. In this paper, a pair of SAR images is used to test the effect of window size on the reliability of co-registration. An optimum window size is {{selected on the basis of}} the experimental results. The determination of optimum window size for tie point matching is then examined theoretically, leading to a proposal for an automated method based on the auto-correlation of the SAR images, which reflects the similarity between image pixels. The auto-correlation function is decomposed into waves of various frequencies by a wavelet transform. By a combined analysis of the variations of wave amplitudes with frequency, the optimum window size for tie point matching can be determined. A procedure based on the use of Daubechies wavelet db 1 is proposed in detail. An optimum window size could be determined in this way for any pair of SAR images. Department of Land Surveying and Geo-Informatic...|$|E
50|$|Unlike rays in mathematics, optical rays {{extend to}} {{infinity}} in both directions. Rays are real {{when they are}} in the part of the optical system to which they apply, and are virtual elsewhere. For example, object rays are real on the object side of the optical system. In stigmatic imaging an object ray intersecting any specific point in object space must be <b>conjugate</b> to an <b>image</b> ray intersecting the <b>conjugate</b> <b>point</b> in <b>image</b> space. A consequence is that every point on an object ray is conjugate to some <b>point</b> on the <b>conjugate</b> <b>image</b> ray.|$|R
40|$|Phase <b>conjugate</b> <b>images</b> are {{produced}} by resonant degenerate four-wave mixing from rotationally excited OH molecules in a premixed, laminar methane/air flame. By comparing signal intensities in the images produced using transitions from different rotational levels, the temperature map of a planar section of the flame is derived...|$|R
40|$|Melbourne (Australia) test {{sites were}} {{evaluated}} using the modified IRS- 1 C/ 1 D stereo photogrammetric software Saphire and PCI Geomatica Orthoengine (version 9) software. Both the stereo pairs were processed using {{the four corners}} and one center pixel planimetric coordinates for each individual <b>image</b> as control <b>points.</b> The linearly interpolated satellite state vectors {{were used in the}} space resection module of the modified Saphire software to compute the updated attitude angles based on the control point coordinates, separately for each <b>image.</b> <b>Conjugate</b> <b>points</b> were automatically identified using interest <b>points</b> based hierarchical <b>image</b> matching. Using the space intersection module, (planimetric coordinates and) heights were computed at each conjugate point. These were interpolated to generate a uniform DEM grid of required spacing. For Montmirail, the DEM generated was compared with the two reference DEMs provided in Lambert II projection with NTF datum in Clarke 1866 ellipsoid, which are accurate to about 1 m. For Melbourne, the DEM could not be generated using the PCI Geomatica possibly due to large cloud patches. It is observed that without using any control points, the modified Saphire software could achieve an accuracy of 20 m at 89 % (10 m at 75 % and 5 m at 58 %) of the DEM points in the case of Montmirail. The results could be improved if manual interaction for interactively increasing the density of conjugate points and identifying break-lines are introduced in Saphire. Availability of a near-nadir image would also help reduce the occlusions that occur in high slope areas. 1...|$|R
40|$|Three sets of radar {{images have}} been {{acquired}} under different viewing conditions by the Magellan synthetic aperture radar: (1) left-looking with varied incidence angles (cycle 1); (2) right-looking with nearly constant incidence angles (cycle 2); and (3) left-looking with varied incidence angles, {{most of which}} were smaller than those in (1) except for those acquired on passes across Maxwell Montes with incidence angles larger than those in (1) (cycle 3). Image displacements in the radar images that are caused by the relief of landforms provide several methods of estimating this relief: (1) monoscopic measurements of foreshortening of landforms that are symmetrical in the plane of the look-direction of the radar (includes radial symmetry); (2) stereoscopic measurements of parallax in same-side image pairs (cycles 1 - 2 and 3); and (3) measurements of parallax in opposite-side image pairs (cycles 1 - 2 and/or 2 - 3). Success in methods 2 and 3 (especially 3) depends on identifying <b>conjugate</b> <b>image</b> <b>points</b> in the two images. Here, we report our preliminary results for five impact craters, seven small volcanic edifices, and two lava flows. The three methods mentioned above lead to the interesting result that Venusian impact craters have depth-diameter ratios like those on Mars rather than those on Earth, but some appear partly filled. Our results for de Lalande and Melba also suggest filling, but there may be other causes for their relatively small depth-diameter ratios. A host of small volcanic edifices have relief that can be crudely estimated using the above methods. Relief/diameter ratios for our cratered cones are about the same as those of Icelandic lava shields; some Venusian cones resemble the Martian shields of Mareotis-Tempe and Ceraunius Fossae, but the Venusian relief diameter ratios are larger. The smallest cratered dome is similar in size and profile to a Martian dome north of Uranius Patera; the smallest cratered cone resembles one in Chryse Planitia. Lava flows on Venus that are thick enough to measure are rare, but we have applied methods 1 and 3 to the huge flow of Ovda Regio and flows of an unusual volcano, Mahuea Tholus...|$|E
30|$|This paper {{describes}} a digital holographic microscope using Zernike’s phase contrast observation method [4] using a hard X-ray Gabor hologram, which is recorded in a computer. In Gabor holograms, {{the most important}} aspect is to reduce the effect of <b>conjugate</b> <b>images.</b> Good quality high-resolution images were obtained after some numerical processing.|$|R
5000|$|Border extension: Extend {{the input}} image {{sufficiently}} by adding extra points outside the original image which {{are set to}} the image value at the closest <b>image</b> <b>point.</b> The loops over the <b>image</b> <b>points</b> described above visit only the original <b>image</b> <b>points.</b>|$|R
30|$|The {{second step}} is to {{generate}} piecewise epipolar curve <b>image</b> <b>points</b> from original stereo images. As with the previously reported methods, this step {{is based on the}} fact that the hyperbola-like epipolar curve for a reference <b>image</b> <b>point</b> exists between two control points that correspond to the minimum and maximum ground height of the reference <b>image</b> <b>point.</b>|$|R
40|$|Abstract: Edge {{detection}} can {{be performed}} by filtering an image in a selected number of directions. We discuss a set of complex directional edge filters ranging from a basic four-directional one-pixel-per-direction filter to a tri-directional optimal filter. A method of generating n-directional optimal filters is given. Relationship between the directional filters and <b>conjugate</b> <b>images</b> used to create n-dimensional histograms is discussed...|$|R
40|$|In {{reconstruction}} of in-line recorded holograms, zero-order and <b>conjugate</b> <b>images</b> {{appear on the}} same physical location as the object image. Here we propose a method, new to our knowledge, to separate the object image from the others by using two quadrature phase-shifted holograms. The method uses the Hartley transform and a phase retrieval type of algorithm on the difference hologram...|$|R
50|$|A common {{example of}} feature vectors appears when each <b>image</b> <b>point</b> {{is to be}} {{classified}} as belonging to a specific class. Assuming that each <b>image</b> <b>point</b> has a corresponding feature vector based on a suitable set of features, meaning that each class is well separated in the corresponding feature space, the classification of each <b>image</b> <b>point</b> can be done using standard classification method.|$|R
50|$|Object planes {{perpendicular}} to the optical axis are <b>conjugate</b> to <b>image</b> planes {{perpendicular to}} the axis.|$|R
50|$|The primary {{limitation}} of critical illumination is {{the formation of}} an image of the light source in the specimen image plane. Köhler illumination addresses this by ensuring the image of the light source is perfectly defocused in the sample plane and its <b>conjugate</b> <b>image</b> planes. In a ray diagram of the illumination light path this {{can be seen as the}} image-forming rays passing parallel through the sample.|$|R
5000|$|Zero padding: Extend {{the input}} image {{sufficiently}} by adding extra points outside the original image which {{are set to}} zero. The loops over the <b>image</b> <b>points</b> described above visit only the original <b>image</b> <b>points.</b>|$|R
40|$|WO 2011009775 A 1 UPAB: 20110209 NOVELTY - The device has {{an image}} {{provider}} providing an image (36) of a blood smear (32). A classifier classifies entire <b>image</b> <b>points</b> in the <b>image</b> into <b>image</b> <b>points</b> showing blood cells and other <b>image</b> <b>points</b> not showing blood cells. A selector selects {{a region of}} the blood smear as a valid region based on a local frequency of <b>image</b> <b>point</b> clusters of a minimum threshold value of the former <b>image</b> <b>points</b> and a local average parameter of the <b>image</b> <b>point</b> clusters for laterally distributed regions of the blood smear. The threshold value is achieved for {{a quantity of the}} former <b>image</b> <b>points.</b> DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following: (1) a method for localizing a valid region of a blood smear (2) a computer program comprising instructions for performing a method for localizing a valid region of a blood smear. USE - Device for localizing a valid region of a blood smear on an object carrier for diagnosis of disease. Uses include {{but are not limited to}} skin cancer, breast cancer, blood count, malaria and sexually transferred disease. ADVANTAGE - The device easily, automatically and objectively localizes the valid region of the blood smear on the object carrier...|$|R
40|$|International audienceWe {{consider}} the three discrete representations in the Falbel-Koseleff-Rouillier census where the peripheral subgroups have cyclic holonomy. We show {{that two of}} these representations have <b>conjugate</b> <b>images,</b> even though they represent different 3 -manifold groups. This illustrates {{the fact that a}} discrete representation π_ 1 (M) → PU(2, 1) with cyclic unipotent boundary holonomy is not in general the holonomy of a spherical CR uniformization of M...|$|R
5000|$|... #Caption: An {{illustration}} of some 3D points and their corresponding <b>image</b> <b>points</b> {{as described by}} the pinhole camera model. As the 3D points are moving in space, the corresponding <b>image</b> <b>points</b> are also moving. The motion field consists of the motion vectors in the <b>image</b> for all <b>points</b> in the <b>image.</b>|$|R
5000|$|... for {{corresponding}} <b>image</b> <b>points</b> {{represented in}} normalized image coordinates [...] The problem which the algorithm solves {{is to determine}} [...] {{for a set of}} matching <b>image</b> <b>points.</b> In practice, the image coordinates of the <b>image</b> <b>points</b> are affected by noise and the solution may also be over-determined which means that it may not be possible to find [...] which satisfies the above constraint exactly for all points. This issue is addressed in the second step of the algorithm.|$|R
40|$|WO 2004021280 A UPAB: 20040418 NOVELTY - The method involves, {{for each}} {{of a number of}} <b>image</b> <b>points</b> (x 1 /y 1, x 2 /y 2) {{combining}} <b>image</b> <b>point</b> information from at least two channels (202, 204, 206) of the image and determining one or more texture characteristics from the combined image information. The step of combining the image information is repeated until combined image information is available for all combinations of different channels of the image. USE - For extracting texture characteristics from a multi-channel image containing a number of <b>image</b> <b>points.</b> ADVANTAGE - The improved method takes into account the information of an <b>image</b> <b>point</b> contained in each channel of the image...|$|R
40|$|The <b>image</b> <b>points</b> in two <b>images</b> satisfy epipolar constraint. However, not all sets {{of points}} {{satisfying}} epipolar constraint correspond to any real geometry because there can exist no cameras and scene points projecting to given <b>image</b> <b>points</b> such that all <b>image</b> <b>points</b> have positive depth. Using the cheirality theory due to Hartley and previous work on oriented projective geometry, we give necessary and sufficient conditions for an <b>image</b> <b>point</b> set {{to correspond to}} any real geometry. For images from conventional cameras, this condition is simple and given in terms of epipolar lines and epipoles. Surprisingly, this is not sufficient for central panoramic cameras. Apart from giving the insight to epipolar geometry, among the applications are reducing the search space and ruling out impossible matches in stereo, and ruling out impossible solutions for a fundamental matrix computed from seven points. 1. Introduction It is a well-known fact that corresponding <b>image</b> <b>points</b> in two <b>images</b> of a 3 [...] ...|$|R
50|$|Starting with a 2D <b>image,</b> <b>image</b> <b>points</b> are {{extracted}} which {{correspond to}} corners in an image. The projection rays from the <b>image</b> <b>points</b> are reconstructed from the 2D points {{so that the}} 3D points, which must be incident with the reconstructed rays, can be determined.|$|R
40|$|We {{present a}} conceptually simple {{algorithm}} for dense <b>image</b> <b>point</b> matching between two colour images. The algorithm {{is based on}} the assumption that the topology only changes slightly between the two images. Following this assumption we use an iterative fuzzy inference process to find the likeliest <b>image</b> <b>point</b> matches. Advantages of this algorithm are that it is fundamentally parallel, it does not need any exact geometric information about the cameras and it can also give <b>image</b> <b>point</b> matches within homogeneous areas of the two images. ...|$|R
5000|$|... #Caption: [...] Figure 1: In {{this phase}} shift image of cells in culture, the height {{and color of}} an <b>image</b> <b>point</b> {{correspond}} to the measured phase shift. The phase shift induced by an object in an <b>image</b> <b>point</b> depends only on the object's thickness and the relative refractive index of the object in the <b>image</b> <b>point.</b> The volume of an object can therefore be determined from a phase shift image when the difference in refractive index between the object and the surrounding media is known.|$|R
50|$|The {{pseudo code}} given above {{suggests}} that a neighborhood operation is implemented {{in terms of an}} outer loop over all <b>image</b> <b>points.</b> However, since the results are independent, the <b>image</b> <b>points</b> can be visited in arbitrary order, or can even be processed in parallel. Furthermore, in the case of linear shift-invariant operations, the computation of f at each point implies a summation of products between the image data and the filter coefficients. The implementation of this neighborhood operation can then be made by having the summation loop outside the loop over all <b>image</b> <b>points.</b>|$|R
3000|$|... = 53 μm in {{the object}} plane was obtained, {{so that the}} {{wavefront}} of the <b>conjugate</b> <b>image</b> in the image plane {{can be regarded as}} a wavefront caused from a point source. Samples of polystyrene sphere beads with 8 -μm diameter and dried HeLa cells are used as phase objects; in the used hologram, the aperture diameter magnitude can be considered to produce a wavefront originating from a point source. The numerical value of (1 +Φ(0, 0))/(2 λZ [...]...|$|R
40|$|We {{consider}} the discrete representations of 3 -manifold groups into PU(2, 1) {{that appear in}} the Falbel-Koseleff-Rouillier census, such that the peripheral subgroups have cyclic unipotent holonomy. We show that two of these representations have <b>conjugate</b> <b>images,</b> even though they represent different 3 -manifold groups. This illustrates {{the fact that a}} discrete representation π_ 1 (M) → PU(2, 1) with cyclic unipotent boundary holonomy is not in general the holonomy of a spherical CR uniformization of M...|$|R
50|$|In a telescope, {{the subject}} focal plane is at {{infinity}} and the <b>conjugate</b> <b>image</b> plane, {{at which the}} image sensor is placed, {{is said to be}} an infinite conjugate. In microscopy and macro photography, the subject is close to the lens, so the plane at which the image sensor is placed {{is said to be a}} finite conjugate. Within a system with relay lenses or eyepieces, there may be planes that are conjugate to the aperture.|$|R
5000|$|... #Caption: The {{object and}} {{corresponding}} <b>image</b> <b>points</b> can be interchanged ...|$|R
