10|27|Public
50|$|The North Carolina Forest Service {{has moved}} its {{regional}} aviation firefighting operations to Raleigh Exec. The facility {{serves as an}} operational base for five fixed-wing aircraft and two helicopters used to fight forest fires. It {{also serves as a}} <b>centralized</b> <b>maintenance</b> location for a total of 25 Forest Service aircraft.|$|E
50|$|Difficulties {{with the}} {{introduction}} of VLOM have called into question a number of inherent assumptions in the concept relating to the user community, the supporting environment and technology choice. Of particular importance is the assumption that introducing and supporting VLOM is an easier task for government than running a <b>centralized</b> <b>maintenance</b> service.|$|E
50|$|In {{addition}} to the routine position reports, F-GZCP's <b>Centralized</b> <b>Maintenance</b> System sent a series of messages via ACARS in the minutes immediately prior to its disappearance. These messages, sent to prepare maintenance workers on the ground prior to arrival, were transmitted between 02:10 UTC and 02:15 UTC, and consisted of five failure reports and nineteen warnings. Until the black box flight recorders were recovered two years later, these messages represented the only recorded data available to the investigators. They offered a tantalizing but incomplete picture {{of what had happened}} to Flight 447.|$|E
50|$|The {{project was}} started by Kristian Høgsberg with two goals: to provide PDF {{rendering}} functionality as a shared library for <b>centralizing</b> <b>maintenance</b> effort, and {{to go beyond the}} goals of Xpdf, and integrate with functionality provided by modern operating systems.|$|R
5000|$|Caltrain <b>Centralized</b> Equipment <b>Maintenance</b> and Operations Facility ...|$|R
5000|$|... #Article: Caltrain <b>Centralized</b> Equipment <b>Maintenance</b> and Operations Facility ...|$|R
50|$|VLOM, meaning Village Level Operation and Maintenance, {{is a term}} {{first used}} during the UNDP and World Bank Rural Water Supply Hand Pumps Project. This project lasted from 1981 to 1991, and studied the {{availability}} and maintenance of hand pump systems. 40 kinds of hand pumps were analyzed in laboratories, {{and the performance of}} 2700 hand pumps was analyzed in the field. The study established that <b>centralized</b> <b>maintenance</b> structure was a cause of many problems in hand pump programs, and that maintenance at the village level is best.|$|E
40|$|Providing a {{continuous}} service {{is the main}} requirement for many application types deployed in Wireless Sensor Networks (WSNs). In this paper, we study two maintenance strategies using {{a small number of}} mobile maintainer robots to restore the WSN coverage and connectivity upon a sensor failure: the <b>Centralized</b> <b>Maintenance</b> Strategy (CMS) and the <b>Centralized</b> <b>Maintenance</b> Strategy with Anticipation (CMSA). The CMS and CMSA are based on the Centralized Manager Algorithm [1] used to detect, report sensor failures and coordinate the movement of robots. In CMSA, the predictive version of CMS, a selected robot is chosen as a manager to anticipate the sensor failures and schedule the available maintainer robots to repair them before they happen. To predict the lifetime of a sensor node, we propose an energy state model that represents the behavior of a sensor node based on Markov Chain. We use this model, validated by simulations, to predict the energy consumption by a sensor node and consequently the lifetime of a wireless sensor node. The simulation results show that the CMSA ensures a null dysfunction network time and a message overhead lower than the classical centralized manager strategy...|$|E
40|$|To {{support our}} {{research}} on using intelligent agents in team training, {{we have developed}} a distributed multiplayer game in Java that executes in real time. We based our development on the game Space Fortress, which has been widely used by cognitive psychologists for studying training protocols. Typical experiments involve in excess of 100 trials of the game under different training conditions. We incorporated features allowing flexible definition of experiment conditions (e. g., which players play which roles), mixed teams of human and intelligent software agents, synchronization of multiple player teams across a network, coordination of a formal experiment encompassing several different experimental conditions with many teams simultaneously playing the game, and the <b>centralized</b> <b>maintenance</b> of fine grained data on individual and team game activity. In this paper we describe the design of this game to achieve these features and real time performance in the Java environment...|$|E
2500|$|The <b>Centralized</b> Equipment <b>Maintenance</b> and Operations Facility {{is a new}} train {{maintenance}} {{yard and}} facility north of San Jose Diridon station in San Jose. The [...] maintenance station began construction in 2004 and opened on September 29, 2007. It consolidates much of Caltrain's maintenance and operations into one location.|$|R
50|$|The Caltrain <b>Centralized</b> Equipment <b>Maintenance</b> and Operations Facility (CEMOF) is a train {{maintenance}} {{yard and}} facility located {{to the north}} of San Jose Diridon station in San Jose. The $140 million maintenance station began construction in 2004 and opened on September 29, 2007. The facility consolidates much of Caltrain's maintenance and operations into one location.|$|R
50|$|The {{facility}} includes five residential units, a gym and aquatics center, {{a sheltered}} workshop, <b>centralized</b> dietary services, <b>maintenance</b> and transportation services, laundry, canteen, sewing room, all-faith chapel, guest house and camping facilities at nearby Lake Mexia.|$|R
40|$|Timely vaccinations {{decrease}} a child’s risk {{of contracting}} vaccine-preventable disease and prevent disease outbreaks. Childhood immunization schedules {{may represent the}} only clinical guideline {{for which there is}} official national consensus. So an immunization clinical decision support system (CDSS) is a natural application. However, immunization schedules are complex and change frequently. Maintaining multiple CDSS’s is expensive and error prone. Therefore, a practical strategy would be an immunization CDSS as a centralized web service that can be easily accessed by various electronic medical record (EMR) systems. This allows <b>centralized</b> <b>maintenance</b> of immunization guidelines. We have developed a web service, based on Miller’s tabular model with modifications, which implements routine childhood immunization guidelines. This immunization web service is currently operating in the Regenstrief Institute intranet and system evaluations are ongoing. We will make this web service available on the Internet. In this paper, we describe this web service -based immunization decision support tool...|$|E
40|$|Implementation {{of quality}} {{maintenance}} programs {{is essential to}} enhancing sustainable continuous operations of United States funded Materials Protection, Control and Accountability (MPC and A) equipment/systems upgrades at various Russian nuclear facilities. An effective maintenance program is expected to provide assurances to both parties for achieving maximum continuous systems operations with minimum down time. To be effective, the program developed must focus on minimum down time for any part of a system. Minimum down time is realized through {{the implementation of a}} quality maintenance program that includes preventative maintenance, necessary diagnostic tools, properly trained technical staff, and an in-house inventory of required spare parts for repairing the impacted component of the system. A <b>centralized</b> <b>maintenance</b> management program is logistically essential for the success of this effort because of the large volume of MPC and A equipment/systems installed at those sites. This paper will discuss current programs and conditions at the Russian Research Center-Kurchatov Institute, the All-Russian Scientific Institute for Technical Physics and the All-Russian Research Institute of Experimental Physics and will address those steps necessary to implement an upgraded program at those sites...|$|E
40|$|Image {{processing}} is {{an important}} quantitative technique for neuroscience researchers, but difficult for those who lack experience in the field. In this paper we present a web-based platform that allows an expert to create a brain image processing pipeline, enabling execution of that pipeline even by those biomedical researchers with limited image processing knowledge. These tools are implemented as a plugin for Midas, an open-source toolkit for creating web based scientific data storage and processing platforms. Using this plugin, an image processing expert can construct a pipeline, create a web-based UI, manage jobs, and visualize intermediate results. Pipelines are executed on a grid computing platform using BatchMake and HTCondor. This represents a new capability for biomedical researchers and offers an innovative platform for scientific collaboration. Current tools work well, but can be inaccessible for those lacking image processing expertise. Using this plugin, researchers in collaboration with image processing experts can create workflows with reasonable default settings and streamlined user interfaces, and data can be processed easily from a lab environment {{without the need for}} a powerful desktop computer. This platform allows simplified troubleshooting, <b>centralized</b> <b>maintenance,</b> and easy data sharing with collaborators. These capabilities enable reproducible science by sharing datasets and processing pipelines between collaborators. In this paper, we present a description of this innovative Midas plugin, along with results obtained from building and executing several ITK based image processing workflows for diffusion weighted MRI (DW MRI) of rodent brain images, as well as recommendations for building automated image processing pipelines. Although the particular image processing pipelines developed were focused on rodent brain MRI, the presented plugin can be used to support any executable or script-based pipeline...|$|E
50|$|As {{the rail}} network {{at that time}} was laid out {{in the shape of a}} star focused on Lomé, its assets were able to be used very economically, with vehicle <b>maintenance</b> <b>centralized</b> at Lomé in a main workshop.|$|R
50|$|Call Agents all of above {{features}} for all sites under the central controller. A central gateway controller includes both <b>centralized</b> configuration and <b>maintenance</b> of call control functionality. When new functionality {{needs to be}} added, only the controller needs to be updated.|$|R
40|$|International audiencePurpose - In this paper, we are {{concerned}} with a <b>maintenance</b> workshop <b>centralizing</b> all corrective <b>maintenance</b> activities. Our goal is to propose a methodology for designing this Central Maintenance Workshop, enabling us to evaluate performance in terms of cost and sojourn time for a given budget...|$|R
40|$|Change from a {{regulated}} to deregulated structure means that, the <b>centralized</b> <b>maintenance</b> {{system is}} not valid any more. In the surveyed published literature, {{there is not a}} single model which incorporates all maintenance cost components to analyze the effect of different maintenance strategies for generator companies (GENCOs). The work enclosed in this thesis demonstrates that there is a considerable requirement for accurately modelling cost components of the maintenance model, to be used in maintenance scheduling for deregulated power system, in order to attain a superior schedule with major financial and operational impact. This research investigates and models most cost factors that affect the maintenance activities of the deregulated GENCOs, and demonstrates the utilization of the developed cost models in maintenance scheduling. It also presents the data gathering process for the developed maintenance cost model. A generator maintenance scheduling model that considers direct and indirect maintenance costs, opportunity costs (i. e. loss of customer goodwill), effective maintenance strategies, failures, and interruptions is developed. A Genetic Algorithm (GA) based approach is employed to achieve maintenance schedules to various generators maintenance scenarios. An Analytical Hierarchy Process (AHP) approach is proposed for modelling customer goodwill. The maintenance model was redeveloped under the Reliability Centred Maintenance (RCM) strategy to analyze the effect of a maintenance strategy on maintenance costs. Case studies are presented to demonstrate the utilisation of the developed models. The investigation shows that the market prices, opportunity costs and maintenance strategy have an effect on the final maintenance schedule. The research demonstrates that the cost components are critical factors to achieve an effective maintenance schedule, and they must be considered and carefully modelled in order to reflect more realistic situation for maintenance scheduling of generator units in deregulation environment. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|E
40|$|Abstract. According to {{the current}} actual {{situation}} of informatization in Commercial Vehicle Company of DF Motor Co., Ltd., there exists such a problem as the incomplete parts data of S-BOM, which fails to provide complete parts data {{of the department of}} procurement and sales. In order to solve the problem, this paper designs and develops the parts of DF Motor Co., Ltd. Data Management System. The system uses Delphi 7. 0 as the development tools and Oracle 9 i as the back-end database，which implements the function of <b>centralized</b> management, <b>maintenance</b> and query of S-BOM parts data by means of parts state management, structured data management, parts data query and other function modules. The system meets Commercial Vehicle Company's requirements of centralized procurement by addressing some of the key issues in the original parts management...|$|R
50|$|PIM systems {{generally}} need {{to support}} multiple geographic locations, multi-lingual data, and maintenance and modification of product information within a centralized catalog. Information kept by a business can be scattered throughout departments and held by employees or systems, instead of being available centrally; data may be saved in various formats, or only be available in hard copy form. Information may be needed for detailed product descriptions with prices, or calculating freight costs. PIM represents a solution for <b>centralized,</b> media-independent data <b>maintenance,</b> as well as efficient data collection, management, refinement and output.|$|R
30|$|NGS strikingly {{contributed to}} expand the number of genomes {{currently}} completely sequenced (Fig.  1), {{as well as to}} the establishment of novel ambitious efforts, for instance, those focused on multi-genome sequencing [24, 25, 73] or those aiming to define global metagenomes from different environmental samples to define reference collections [74, 75]. These technologies are also exploited for the production of alternative, related collections, namely from transcriptomics, epigenomics, and metagenomics projects. The unexpected amount of raw data the new technologies are providing requires also dedicated storage for <b>centralized</b> data <b>maintenance,</b> currently solved by the SRA system [76]. Worthy to note is the size reached by the SRA archive in a short time span when compared to the entire nucleotide collection currently available (Fig.  1). NGS data size represents a big challenge for bioinformatics. Indeed, main computational tasks are today focused on the optimization and adaptation of typical methodologies in bioinformatics to the magnitude of NGS collections.|$|R
40|$|Java-enabled {{wireless}} {{devices are}} preferred {{for various reasons}} such as enhanced user experience and the support for dynamically downloading applications on demand. The dynamic download capability supports extensibility of the mobile client features and <b>centralizes</b> application <b>maintenance</b> at the server. Also, it enables service providers to customize features for the clients. In this work, we extend this client-server collaboration further by offloading some of the computations (i. e., method execution and dynamic compilation) normally performed by the mobile client to the resourcerich server in order to conserve energy consumed by the client in a wireless Java environment. In the proposed framework, the object serialization feature of Java is used to allow offloading of both method execution and bytecode-to-native code compilation to the server when executing a Java application. Our framework takes into account communication, computation and compilation energies to dynamically decide where to compile and execute a method (locally or remotely) and how to execute it (using interpretation or just-in-time compilation with different levels of optimizations). ...|$|R
25|$|Only {{five of the}} ten ships, the Junior N. Van Noy, Madison Jordan Manchester, Glenn Gerald Griswold, Thomas F. Farrel and Robert M. Emery made it to Europe in {{time for}} {{significant}} work. The remaining ships were not operational until 1945. Some of the modifications {{turned out not to}} be as useful as anticipated. The distinctive forty ton capacity bow horn in particular was seldom used. Navy salvage units had been operational earlier for heavy lift and the most valuable function of the ships may have been to <b>centralize</b> support, heavy <b>maintenance</b> and facilities for Army Engineers conducting repairs.|$|R
5000|$|Many {{of these}} {{problems}} were intended to be solved with the PowerShare server, which acted as an always-on, always responsive [...] "super-peer". The basic AOCE protocol would notice these machines when attempting delivery, and send to them first, thereby eliminating the delays and <b>centralizing</b> storage and <b>maintenance.</b> Sadly the server was not ready {{in time for the}} release, and did not ship for another year. When it did it was likewise slow and resource hungry, largely a side effect of various features of the Mac OS that made it unsuitable for server applications - a role for which it was never designed in the first place.|$|R
40|$|With {{the rapid}} growth of the Internet into global {{communication}} and commercial infrastructure, the need for Quality of Services (QoS) in the Internet becomes more and more important. With a Bandwidth Broker (BB) support in each administrative domain, Differentiated Services (Diffserv) is seen as a key technology for achieving QoS guarantees in a scalable, efcient, and deployable manner in the Internet. This paper presents the design and and implementation of a new Bandwidth Broker (BB) model to achieve QoS across a Diffserv domain. Our BB uses <b>centralized</b> network state <b>maintenance</b> and pipe-based intra-domain resource management schemes. The proposed model signicantly reduces admission control time and minimizes scalability problems present in prior research while optimizing network resource utilization. The experimental results verify the achievements of our model. ...|$|R
40|$|Abstract—Java-enabled {{wireless}} {{devices are}} preferred for various reasons. For example, users can dynamically download Java applications on demand. The dynamic download capability supports extensibility of the mobile client features and <b>centralizes</b> application <b>maintenance</b> at the server. Also, it enables service providers to customize features for the clients. In this work, we extend this clientserver collaboration further by offloading {{some of the}} computations (i. e., method execution and dynamic compilation) normally performed by the mobile client to the resource-rich server in order to conserve energy consumed by the client in a wireless Java environment. In the proposed framework, the object serialization feature of Java is used to allow offloading of both method execution and bytecode-to-native code compilation to the server when executing a Java application. Our framework takes into account communication, computation, and compilation energies to decide where to compile and execute a method (locally or remotely), and how to execute it (using interpretation or just-in-time compilation with different levels of optimizations). As both computation and communication energies vary based on external conditions (such as the wireless channel state and user supplied inputs), our decision must be done dynamically when a method is invoked. Our experiments, using a set of Java applications executed on a simulation framework, reveal that the proposed techniques are very effective in conserving {{the energy of the}} mobile client. Index Terms—Client/server, Java, runtime environment. ...|$|R
40|$|International audienceIn this paper, we are {{concerned}} with a <b>maintenance</b> workshop <b>centralizing</b> all corrective <b>maintenance</b> activities. Our goal is to propose a methodology for designing this Central Maintenance Workshop, enabling us to evaluate performance in terms of cost and sojourn time for a given budget. We propose a modelling framework based on queuing networks. The aim is to maximize operational availability of the production workshop, by reducing the sojourn time of failed equipment in the maintenance workshop. The proposed methodology leads to a maintenance decision support tool enabling to give {{the structure of the}} maintenance workshop, performing at a higher level, but at a reasonable configuration cost. Simulation results illustrate the influence of different parameters, such as the number of stations and the level of spare parts in the maintenance workshop, on the sojourn time of the equipment...|$|R
40|$|Cost reduction, {{simplified}} management, {{security and}} quality of service are fundamental targets when designing network services. Large organizations, which require great flexibility, often implement distributed services leading to {{the high cost of}} managing multiple servers. Transferring services from a distributed to a centralized model can reduce costs considerably. However, this choice could limit the freedom of peripheral administrators to manage their own services. We believe that the best solution is {{to strike a balance between}} the centralized and the distributed model: i. e., a hybrid management system, partly centralized, partly distributed. The idea is to <b>centralize</b> system configuration, <b>maintenance</b> and monitoring while distributing administrative tasks, typical of peripheral organization units, via web-based interfaces. We call this approach 2 ̆ 7 Centralized Management with Delegated Administration 2 ̆ 7. In this report we describe INSM (Integrated Network Services Manager), a system for managing e-mail and DNS services, based on the CMDA model...|$|R
40|$|One of CogniTech’s {{customers}} collects and verifies back-ground data {{on various}} appli-cants {{to determine their}} suitability to perform specified tasks as a contractor or an employee for other organizations (clients). The background data include education, professional certification, employment history, criminal allega-tions, and citizenship. The business processes of collecting and verifying these data are time- and resource-inten-sive and require the <b>centralized</b> storage and <b>maintenance</b> of the resulting records. To increase the efficiency, responsive-ness, and quality of its verification ser-vices, the customer wanted to reengineer its business processes {{through the use of}} software packages {{for each of the three}} distinct but interdependent services: • Collection of background data. • Verification and auditing to authenti-cate the data. • Generation of reports and other forms of data access based upon the verified data. The profile of each applicant deter-mines the data collected, verified, and reported during the process. Therefore, each applicant requires a customized user interface, which is determined dy-namically, based on the clients request-ing the collection and verification ser-vices. CogniTech developed an Internet solution to support the collection of the background data...|$|R
40|$|Problem {{statement}} for distributed and dynamic mobility management draft-chan-distributed-mobility-ps- 00 Mobility solutions deployed with centralized mobility anchoring in existing hierarchical mobile networks {{are more prone}} to the following problems or limitations compared with distributed and dynamic mobility management: (1) Routing via a centralized anchor is often longer, so that those mobility protocol deployments that lack optimization extensions results in non-optimal routes, affecting performance; whereas routing optimization may {{be an integral part of}} a distributed design. (2) As mobile network becomes more flattened centralized mobility management can become more non-optimal, especially as the content servers in a content delivery network (CDN) are moving closer to the access network; in contrast, distributed mobility management can support both hierarchical network and more flattened network as it also supports CDN networks. (3) <b>Centralized</b> route <b>maintenance</b> and context maintenance for a large number of mobile hosts is more difficult to scale. (4) Scalability may worsen when lacking mechanism to distinguish whether there are real need for mobility support; dynamic mobility management, i. e., to selectively provide mobility support, is needed and may be better implemented with distributed mobility management. (5) Deployment is complicated with numerous variants and extensions of mobile IP; these variants and extensions may be better integrated in a distributed and dynamic design which can selectively adapt to the needs. (6) Excessive signaling overhead should be avoided when end nodes are able to communicate end-to-end; capability to selectively turn off signaling that are not needed by the end hosts will reduce the handover delay. (7) Centralized approach is generally more vulnerable to a single point of failure and attack often requiring duplication and backups, whereas a distributed approach intrinsically mitigates the problem to a local network so that the needed protection can be simpler...|$|R
40|$|Abstract—One {{of the key}} {{mechanisms}} underlying {{a wireless}} sensor network (WSN) is to monitor the network itself. Many existing approaches perform <b>centralized</b> analysis and <b>maintenance</b> based on {{a large amount of}} status reports collected from the WSN, while others use add-on protocols/modules that not only require extra management cost but also interrupt the normal operations of targeted WSN applications. Unlike existing work, we propose LoMoM, a new approach of Local Monitoring and Maintenance for a WSN, which combines monitoring operations for the WSN with the operations of a mobile event monitoring, {{in a manner that is}} both energy- and latency-efficient. LoMoM includes a two-part monitoring architecture: a WSN and a 3 G network. Our main interest is in the WSN-part, where we address two important issues: monitoring probable anomalies/faults of the nodes, and the link failures. To achieve the event monitoring efficiently, LoMoM conducts a prompt local maintenance when such a fault occurs. Fault and event detection status reports are observed by a remote monitoring center using the 3 G network. Comprehensive evaluations via both simulations and real-world experiments are conducted to validate the effectiveness of LoMoM. Keywords-Wireless sensor networks; network monitoring; monitoring architecture; local maintenance; event monitoring I...|$|R
40|$|After almost 20 {{years of}} declining cocoa production, Ghana {{has been able}} {{in the last decade}} to {{increase}} the share of export prices going to producers, more than doubling production. Contrary to Washington Consensus prescriptions, these accomplishments were achieved through reforms but without liberalization of domestic and export marketing. The Cocoa Coast: The Board-Managed Cocoa Sector in Ghana seeks to understand the success of a sector that was not liberalized. The authors identify three major reasons for Ghana’s success in cocoa production. First, cocoa producers receive an increasing share of export prices, because of factors including a stakeholder-advised process for determining producer prices that also pays explicit attention to discouraging smuggling of cocoa to neighboring countries and the popular perception that cocoa performance is tied to the country’s general economic performance. Second, the Ghana Cocoa Board (COCOBOD) has a policy of retaining a portion of producer revenues to promote the adoption of yield-enhancing measures. Third, <b>centralized</b> marketing and <b>maintenance</b> of the high export quality for which Ghana is known enables the country to offer stable prices to producers and opportunities for local businesses to participate in the sector and retain some power in the global value chain. Book summary; SynopsisPRGSSP; CRP 2; IFPRI 1; C Improving markets and tradeDSGD; PIMCGIAR Research Programs on Policies, Institutions, and Markets (PIM...|$|R
40|$|Modem {{organizations}} {{struggle with}} controlling computer platform maintenance expenses. This maintenance effort is {{further complicated by}} the existence of multiple, heterogeneous platform environments. A diverse composition of Computer maintenance engineers is responsible for diagnosing and carrying out tasks required to assure quality platform performance. Client/server notification systems are an effective tool designed to manage these computer resources, and yet {{one of the least}} mature within the computer platform maintenance domains. The system requirements for a new expert system generalized inference engine were developed based upon research and analysis of expert system generalized inference methods to date, in addition to related efforts accomplished in the Client/server notification system arena. These computer notification systems have done little to address the issues related to the increased complexities in monitoring and managing the maintenance of multiple computer platforms, each with their own unique environments and applications. The systems requirements for a generalized inference engine that utilize binding, matching and unification to categorize alarms written in Prolog have been developed and validated. When the inferencing method was applied to the notification interface, it generalized the heterogeneous data. The rules were applied to an instance of a frame through unification. The inference engine then identified the correct node reporting the error, and applied the appropriate resolution. The requirements also detailed an explanation. The system requirements for the new expert system generalized inference engine provide for effective centralized processing of multiple computer alarms generated by diverse systems. The systems requirements have been tested via test case execution to verify the logical processing of the new generalized inference engine. The results indicate that the growing discipline of Computer maintenance engineering will benefit from the system requirements for the generalized inference engine that provides for effective centralized processing of computer alarms generated by diverse computer platforms. The implication is that organizations will be able to achieve cost-effective <b>centralized</b> heterogeneous platform <b>maintenance</b> with fewer Computer maintenance engineers, each with a lesser degree of expertise required on multiple platforms...|$|R
40|$|Due to {{automation}} and robotization {{of material}} handling systems (MHS) in the transportation industry, maintaining equipment and systems becomes more important, {{and needs to}} be integrated in the company’s business strategy (Tsang, 2002). Implementing and investing in the right maintenance approach to keep these systems in optimum state is therefore essential for the performance of a company and more important, for the customer’s satisfaction. When a company has to deal with an increase in failures and decreasing performance, it needs to anticipate to change this negative trend. In literature, most of these problems are analysed by using electronic data and condition-based monitoring (Bouvard, Artus, Bérenguer, & Cocquempot, 2011). Analysing the condition of equipment requires data monitoring which is not always possible. Besides, these analyses are often based on a single system which conditions do not apply on systems with different specifications. TNT Express (initiator of this research) is dealing with this problem within the Benelux. They are dealing with decreasing on-time delivery (OTD) performance and increasing costs of smaller sorting-sites without technicians. Having high OTD performance is an essential element of TNT’s business strategy, and is a competitive advantage in their industry. Their time-critical processes combined with the interrelated network structure of their sites makes it hard to develop a single strategy or solution that positively affects the performance of all sites. The differences in size, work methods, level of technology, different size of freight and fluctuating demands makes it a dynamic and complex environment with a lot of variables that influence the performance of on-time delivery. That makes it hard to identify the causes and effects of these failures over time. Besides, TNT doesn’t have the useful data to base their maintenance on. Therefore, finding the bottlenecks and the right variables that influence this performance most is essential for decreasing the costs of TNT. Therefore, the objective of this research is: “Identify the constraints of TNT’s Material Handling Systems in a dynamic environment, to be able to apply the right maintenance strategy that preserves TNT’s delivery performance at lower cost. ” Before a start could be made on finding the bottlenecks of the sorting sites, TNT’s maintenance structure, operational structure, financial structure and operational structure needed to be defined. TNT’s sorting operation, where freight is unloaded, sorted, measures and loaded, runs around 19 hours a day, 6 days a week all year long. That limits the time for maintenance and check-ups to 6 hours a day. Still, a fast response is needed when the sorter does fail during operation, to prevent the process getting delayed which generates extra costs. TNT’s maintenance of those sites turned out to be depending on mostly corrective maintenance, and less on preventive and predictive maintenance. Mechanics are traveling from site to site to solve current incidents that cause delays, and less for preventive maintenance and check-ups. Original equipment manufacturers (OEMs) are also responsible for some maintenance activities, although these are mostly time-based and less used for trouble shooting. When specifying TNT’s on-time delivery performance, the performance of the sorting sites {{turned out to be the}} most important factor of the OTD. This sorting site performance is measured by the capacity of freight it theoretically can handle, and the amount of freight it is transporting in reality. This site performance is also influenced by several variables, where the Material Handling Systems availability turned out to be the largest influential variable. The failing devices and equipment are the cause that IV operators on the floor have to sort manually, which takes a lot more time. Besides, these delays are generating extra costs, only how much and which costs is not quite clear. TNT’s limited registration of essential elements like downtime, maintenance costs and OEM activities made it difficult to link these elements, and to find possible bottlenecks. So, to be able to link the MHS- downtime with the related costs on a daily basis, three Critical-to-Quality factors (CTQs) are analysed:  Breakdown costs  Maintenance costs  MHS availability Because the financial impact of a breakdown was not yet specified, the most important factors are determined by interviewing business improvement experts. Some costs turned out to be different for the import or export process during a working day. For TNT, the next financial factors turned out to be important: 1. Missed Check-Weight-Cube (CWC) revenue 2. Hiring extra vans and trucks 3. Personnel costs (overtime) 4. Financial consequences of lower service level (loss of customers) From these factors, the missed CWC revenue turned out to be largest costs factor in the import process, where hiring extra trucks and vans turned out to be the largest costs factor of the export process. These two factors are further specified and calculated, to link them to specific breakdowns. Depending on the volume in different locations, the missed CWC revenue is variating between € 000,- and € 000,- for a single shift per day. These costs are calculated by determining the number of packages that are affected by a breakdown and do not get a second weighing check on a next location, multiplied by the average revenue missed per parcel. These calculations showed that without a working sorter or CWC on a single location comes with large financial consequences. These specific insights in CWC revenue loss show the need for fewer failures to improve the financial performance of TNT by changing the maintenance activities. The extra costs of hiring extra vans to transport all freight towards the customers in the export process turned out to be € 000,- for a single shift (1 day). These costs are in the same order as the CWC revenue losses, and from financial perspective just as bad. The cost analysis regarding this data showed how disperse the information is within TNT, and that it is hard to develop a strategy without this kind of crucial information. Maintenance costs are referred as costs that are made to solve the incidents and include, service contracts, mechanics salaries etc. However, costs that are made for decreasing the number of incidents are more important. Think of hiring extra employees, changing service contracts, training current employees. Quantifying these costs is only possible when the bottlenecks of the breakdowns have been derived. V The lacking quality of the data regarding downtime and availability of the MHS made it impossible to use mathematical solutions to find the bottlenecks, so “Soft Operations Research” methods have been used to find the causes of the failures (Heyer, 2004; Masys, 2015). Using Pareto charts and Ishikawa diagrams on the incident file controlled by TNT’s mechanics, the data in this file is structured and enriched to find failures with recurring root causes that are a structural problem. First, three devices that have the most impact on the MHS availability are determined. These are the Sorter, Roller track/belts and Check- Weigh-Cube (CWC) and are responsible for 130 of the 210 incidents for the first 5 months in 2017, which represents more than 60 % of all incidents of the MHS. The registered incident data of these three devices is enriched by going a step further in the cause, structuring all data, and visualising them in an Ishikawa diagram. By doing so, it became clear that a high number of incidents (35 %) have an operation cause, which means that they are caused by human error. These incidents are not specifically location bounded, and solving the most frequent occurring incidents will prevent a lot of future incidents. The three selected root causes that are responsible for most incidents are: 1. Lack of system knowledge Operators, especially Team Leaders (TL) and Leading Hands (LH), have too little knowledge of the process, the effects of failures and simple technical solutions. There skills haven’t been developed with the increasing mechanisation. Not knowing the impact of failures, and how simple incidents can be prevented leads to unnecessary failures. 2. Sensor related incidents A large part of those operational incidents are sensor related. Because these incidents are still frequently occurring, they need to be handled separately. These incidents can be solved quite easy most of the times, and a support system to help operators to solve them is very helpful. 3. Lack of working according instructions A large part of the incidents are caused by wrong choices of operators, by putting wrong parcels on the sorter, putting them on the sorter at the wrong place or working not according the given instructions. The lack of knowing the consequences results in an uninterested work attitude which results in a performance decrease of the sorting site. For these three root causes, several improvements have been developed. For the first root cause, a training program is recommended which start with a well-communicated plan to create the urge for change. The current attitude of personnel is asking for a plan that provides support from the whole organisation. TNT needs to know the value of knowledge amongst their employees, and this needs support from top management. Combining this with low-technical training sessions and useful supporting tools will increase the employees’ knowledge, and also creates ownership with the employees. To do so, TNT needs to review its distribution between part-time employees from employment agencies, and employees contracted by TNT. Increasing system knowledge amongst employees is only effective if that knowledge stays within the company. Rewarding well performing VI employees with a contract by TNT will have positive effect on the knowledge on the work floor and not only prevents, but also decreases the amount of downtime. For sensor related incidents, a supporting manual has been developed that functions as a simple flow chart that guides TL through the process of solving these failures. Following these steps in the included manual gives simple but clear instructions how to act and what to do. Before using this supporting manual, the TL need sufficient training before they can execute the process. Although this solution is more focussed on corrective maintenance, this manual helps to solve simple incidents that mechanics do not have to solve by themselves. Not only are these incidents solved much quicker, due to direct handling of the TL, but the mechanics do not have to drive towards the location of the incident. That also gives the mechanics more time to do preventive maintenance tasks, and therefore further decrease the number of incidents of the MHS. This manual strengthens the need for more direct or autonomous maintenance within the sorting sites of TNT (Chen, 2013). Currently, these sites are too depended on the knowledge of external maintenance providers to repair the failures which is not desirable. To improve that employees work more according instructions, better supervision is advised and recommendations are made to reward well-performing operators. Rewarding operators also means that they will be more responsible for their colleagues and have to make sure that they understand the instructions. They become responsible for preventing wrong parcels being put on the sorter, and have to correct their employees if they ignore the instructions because a lot of incidents are caused by wrong packages being put on the sorter. However, TNT should also improve the visibility and clarity of these instructions by using dummy parcels to indicate the allowed parcels sizes. Improving this product flow on the sorter will improve the sorters performance and lowers the number of incidents. The effect of these improvement could only be expressed by a decrease on the number of incidents, and not on downtime due to lacking data registration. If, as a starting point, already half of these structural incidents is solved by these improvements, the total amount of these 210 incidents over 2017 would already decrease with 13 %. Due to the unknown length of the breakdowns, they cannot be compared to financial results although these results definitely improve. All these improvements are based on autonomous maintenance which is focussed on letting operators do more maintenance and technical tasks. Finally, all these improvements will help retaining TNT’s on-time delivery and decrease their breakdown costs. This process of finding these bottlenecks led to an even more valuable advice for gathering data. This research showed that TNT needs to improve their data collection system, and document important factors with a computerized maintenance management system (CMMS) like time registration, downtime during operations, and weight of breakdown. This data also needs to be accessible for OEM’s, so they also have insight in the failures, and can help improve the MHS performance. With this data, TNT can measure the downtime and better monitor its MHS availability to see which devices or incidents need further improvement. The importance of such data collection system is once emphasized by the fact that it was hard to determine the bottlenecks, especially with multiple locations at the sorting locations of TNT. VII The goal was to identify the constraints in a dynamic environment that has a lot of influential factors that make it hard to determine the effects of these variables. Using multiple techniques based on the number of incidents and the failure history, the first bottlenecks could be derived that needed improvement. Together with a costs analysis on the most important financial factors, solutions and recommendations are developed that will retain TNT’s on-time delivery at lower costs. However, the recommendations for a more <b>centralized</b> data-based <b>maintenance</b> system could even be more valuable in the future. Management of Technolog...|$|R

