31|47|Public
40|$|Labels {{have been}} shown to play an {{important}} role in inductive generalization; however, the mechanism by which labels contribute to generalization early in development remains unclear. We investigated two factors that may influence the inductive potential of labels: semantic similarity and <b>co-occurrence</b> <b>probability.</b> Results suggested that adults and 6 -year-olds rely on semantic similarity of labels and that their generalizations are not affected by <b>co-occurrence</b> <b>probability.</b> Specifically, generalization patterns were qualitatively similar for co-occurring semantically similar labels (e. g., bunny-rabbit) and non-co-occurring semantically similar labels (e. g., rock-stone) in 6 -year-olds and adults. Unlike 6 -year-olds and adults, 4 -year-olds were likely to generalize co-occurring labels but not non-co-occurring labels. Possible mechanisms by which <b>co-occurrence</b> <b>probability</b> may influence label generalization in young children are discussed...|$|E
40|$|The paper {{presents}} the framework and results of team Florida International University- University of Miami (FIU-UM) {{for the task}} of semantic indexing of TRECVID 2010. In this task, we submitted four runs of results: • F A FIU-UM- 1 1 : KF+RERANK- apply subspace learning and classification using key framebased low-level features (KF) and <b>co-occurrence</b> <b>probability</b> re-ranking method (RERANK). • F A FIU-UM- 2 2 : LF+KF+SF+RERANK- apply subspace learning and classification using late fusion (LF), i. e., key frame-based low-level features (KF) and shot based low-level features (SF) separately. Then <b>co-occurrence</b> <b>probability</b> re-ranking method (RERANK) is used for both keyframe based model and shot based model. Finally, a fusion method combines ranking scores from each model and generates the final ranked shots. • F A FIU-UM- 3 3 : EF+KF+SF+RERANK- apply subspace learning and classification using early fusion (EF), i. e., combined features from the selected key frame-based low-level features (KF) and shot based low-level features (SF). Then <b>co-occurrence</b> <b>probability</b> re-ranking method (RERANK) is used...|$|E
40|$|One of {{the core}} tasks in social network {{analysis}} is to predict the formation of links (i. e. various types of relation-ships) over time. Previous research has generally repre-sented the social network {{in the form of}} a graph and has leveraged topological and semantic measures of similar-ity between two nodes to evaluate the probability of link formation. Here we introduce a novel local probabilistic graphical model method that can scale to large graphs to estimate the joint <b>co-occurrence</b> <b>probability</b> of two nodes. Such a probability measure captures information that is not captured by either topological measures or measures of se-mantic similarity, which are the dominant measures used for link prediction. We demonstrate the effectiveness of the <b>co-occurrence</b> <b>probability</b> feature by using it both in isola-tion and in combination with other topological and seman-tic features for predicting co-authorship collaborations on three real datasets. ...|$|E
40|$|This paper investigates a {{framework}} that actively selects informative document pairs for obtaining user feedback for semi-supervised document clustering. A gain-directed document pair selection method that measures how much we can learn by revealing judgments of selected document pairs is designed. We use the estimation of term <b>co-occurrence</b> <b>probabilities</b> as a clue for finding informative document pairs. Term <b>co-occurrence</b> <b>probabilities</b> are considered in the semi-supervised document clustering process to capture term-to-term dependence relationships. In the semi-supervised document clustering, each cluster is represented by a language model. We have conducted extensive experiments on several real-world corpora. The results demonstrate that our proposed framework is effective. Department of Industrial and Systems Engineerin...|$|R
40|$|Abstract- Image texture {{interpretation}} {{is an important}} aspect of the computer-assisted discrimination of SAR sea ice imagery. <b>Co-occurrence</b> <b>probabilities</b> are the most common approach to solve this problem. However, other texture feature extraction methods exist that have not been fully studied for their ability to interpret SAR sea ice imagery. Gabor filters and Markov random fields (MRF) are two such methods considered here. Classification and significance level testing shows that <b>co-occurrence</b> <b>probabilities</b> classify the data with the highest classification rate, with Gabor filters a close second. MRF results significantly lag Gabor and co-occurrence results. However, the MRF features are uncorrelated with respect to co-occurrence and Gabor features. The fused co-occurrence/MRF feature set achieves higher performance. I...|$|R
30|$|The texture {{feature of}} SAR image {{can be derived}} by using the GCM method. However, it is very {{difficult}} to apply it to interpret the images straightly due to the amount of the data in GCM. To generate the texture features based on the <b>co-occurrence</b> <b>probabilities,</b> the statistics are applied to the probabilities. Generally, these statistics identify some structural aspects of the arrangement of probabilities stored within a matrix, which in turn reflects some qualitative characteristics of the local image texture.|$|R
40|$|This paper {{described}} an algorithm for automatic construction of English-Chinese translation lexicon from sentence aligned parallel spoken language corpus. We {{get the first}} part of the translation lexicon by using the electronic dictionary to filter the corpus. Secondly, state and calculate the <b>co-occurrence</b> <b>probability</b> of the word pairs to produce “The Table of Chinese...|$|E
40|$|A design-based {{method to}} fuse Gabor filter and grey level <b>co-occurrence</b> <b>probability</b> (GLCP) {{features}} for im-proved texture recognition is presented. Feature space separability and unsupervised image segmentation {{are used for}} testing. The fused features are robust with re-spect to the curse of dimensionality and additive noise. Feature reduction methods are typically detrimental to the segmentation performance. Overall, the fused fea-tures are a definite improvement over non-fused features and are advocated in texture analysis applications. ...|$|E
40|$|Distributional {{measures}} of lexical similarity and kernel methods for classification are well-known tools in Natural Language Processing. We bring these two methods together by introducing distributional kernels that compare <b>co-occurrence</b> <b>probability</b> distributions. We demonstrate {{the effectiveness of}} these kernels by presenting state-of-the-art results on datasets for three semantic classification: compound noun interpretation, identification of semantic relations between nominals and semantic classification of verbs. Finally, we consider explanations for the impressive performance of distributional kernels and sketch some promising generalisations. ...|$|E
30|$|Some other {{features}} {{can be derived}} from a vector whose components are the <b>co-occurrence</b> <b>probabilities</b> for pixels with a determined sum of the grey levels. All possible sum values are taken into account. The probabilities forming a vector are sorted in increasing order of corresponding sum values. These features are: sum average, sum variance, and sum entropy [36]. Taking the absolute differences of grey levels, instead of their sums, leads to the features already known from GLDM - based method.|$|R
40|$|The {{discrimination}} {{ability of}} texture features derived from Gaussian Markov random fields (GMRFs) and grey level <b>co-occurrence</b> <b>probabilities</b> (GLCPs) are compared and contrasted. More specifically, {{the role of}} window size in feature consistency and separability {{as well as the}} role of multiple textures within a win-dow are investigated. GLCPs are demonstrated to have improved discrimination ability relative to MRFs with decreasing window size, an important concept when performing image segmentation. On the other hand, GLCPs are more sensitive to texture boundary confu-sion than GMRFs. ...|$|R
40|$|This paper {{describes}} {{a method of}} generating effective language models for voice query recognition and a new dialogue strategy for a voice activated QA system. By using multiple domain language models, better recognition accuracy is obtained for query utterances. In the proposed interactive dialogue strategy using multimodal user interface, users are requested to indicate correct keywords and incorrect keywords are automatically replaced by most probable keywords in the n-best list based on word <b>co-occurrence</b> <b>probabilities.</b> A preliminary QA system using voice input and graphical user interface has been implemented using the SAIQA open-domain QA system...|$|R
30|$|In [23], {{the authors}} used the {{potential}} of the spectral/textural approach to improve the classification accuracy of intra-urban land cover types; Claussi [24] studied the effect of gray quantization on the ability of <b>co-occurrence</b> <b>probability</b> statistics; Kiema [25] examined the gray-level co-occurrence based texture image fused to thematic mapper (TM) imagery to expand the object feature base to include both spectral and spatial features; while Bau and Healey [26] used a bank of rotation scale invariant Gabor feature vectors to represent the spectral/spatial properties of a region.|$|E
40|$|This paper explores a design-based {{method to}} fuse Gabor filter {{features}} and <b>co-occurrence</b> <b>probability</b> features for improved texture recognition. The fused feature set utilizes both the Gabor filter’s capability of accurately capturing lower frequency texture {{information and the}} co-occurrence probability’s capability in texture information relevant to higher frequency components. Fisher linear discriminant analysis indicates that the fused features have much higher feature space separation than the pure features. Image texture segmentation results are presented that also demonstrate the improvement using the fused feature sets. ...|$|E
40|$|Abstract-A {{critical}} shortcoming {{of determining}} <b>co-occurrence</b> <b>probability</b> texture features using Haralick's popular grey level co-occurrence matrix (GLCM) is the excessive computational burden. Here, a more robust algorithm (the grey level co-occurrence integrated algorithm or GLCIA) to perform this task is presented. The GLCIA {{is created by}} integrating the preferred aspects of two algorithms: the grey level co-occurrence hybrid structure (GLCHS) and the grey level co-occurrence hybrid histogram (GLCHH). The GLCHS utilizes a dedicated 2 -d data structure to quickly generate the probabilities and apply statistics to generate the features. The GLCHH uses a more efficient 1 -d data structure to perform the same tasks. Since the GLCHH is faster than the GLCHS yet the GLCHH {{is not able to}} calculate features using all available statistics, the integration of these two methods generates a superior algorithm (the GLCIA). The computational gains vary as a function of window size, quantization level, and statistics selected. The GLCIA computational time relative to that of the standard GLCM method ranges from 0. 04 % to 16 %. The GLCIA is a highly recommended technique for anyone wishing to calculate <b>co-occurrence</b> <b>probability</b> texture features, especially from large-scale digital imagery. Index Terms-Texture features, data structures, co-occurrence probabilities, remote sensing imagery, computational efficiency...|$|E
40|$|This study {{starts from}} the hypothesis, first {{advanced}} by McDonald and Shillcock (2001), {{that the word}} frequency effect for a large part reflects local syntactic co-occurrence. It is shown that indeed the word frequency effect {{in the sense of}} pure repeated exposure accounts for only a small proportion of the variance in lexical decision, and that local syntactic and morpholog-ical <b>co-occurrence</b> <b>probabilities</b> are what makes word frequency a powerful predictor for lexical decision latencies. A comparison of two computational models, the cascaded dual route model (Coltheart, Rastle, Perry, Langdon...|$|R
40|$|Abstract Given {{a set of}} keyphrases, we analyze how Web queries {{with these}} phrases can be formed that, taken altogether, return a {{specified}} number of hits. The use case of this problem is a plagiarism detection system that searches the Web for potentially plagiarized passages in a given suspicious document. For the query formulation problem we develop a heuristic search strategy based on <b>co-occurrence</b> <b>probabilities.</b> Compared to the maximal termset strategy [3], which {{can be considered as}} the most sensible non-heuristic baseline, our expected sav-ings are on average 50 % when queries for 9 or 10 phrases are to be constructed. ...|$|R
40|$|An exponential-time exact {{algorithm}} is {{provided for the}} task of clustering n items of data into k clusters. Instead of seeking one partition, posterior probabilities are computed for summary statistics: the number of clusters, and pairwise co-occurrence. The method is based on subset convolution, and yields the posterior distribution {{for the number of}} clusters in O(n * 3 ^n) operations, or O(n^ 3 * 2 ^n) using fast subset convolution. Pairwise <b>co-occurrence</b> <b>probabilities</b> are then obtained in O(n^ 3 * 2 ^n) operations. This is considerably faster than exhaustive enumeration of all partitions. Comment: 6 figure...|$|R
30|$|Semi-automatic image {{segmentation}} methods {{have addressed the}} problem of cross-boundary scribbles [29 – 31]. Although Subr et al. [29] and Bai et al. [30] can reduce artifacts caused by cross-boundary scribbles, they focus on the foreground object segmentation and are hard to apply in 2 D-to- 3 D conversion. Oh et al. [31] used occurrence and <b>co-occurrence</b> <b>probability</b> (OCP) of color values at labeled pixels to estimate the confidence of user input. This method {{can be used for}} 2 D-to- 3 D conversion, but it may mistake expected scribbles for unwanted ones.|$|E
40|$|National audienceFolksonomies - {{collections}} of user-contributed tags, {{proved to be}} efficient in reducingthe inherent semantic gap when retrieving web contents. To get best use of folksonomies, tag clustering was proposed {{to address the problems}} implied by free-style user tagging, such as lexical variations, tag split, multilingualism, etc. In this paper, we propose a novel approach for identifying similar tags in folksonomies. It is {{based on the idea that}} in folksonomies, the most frequent tags can be used to identify groups of semantically related tags. For this purpose, frequent tags are identified and their co-occurrence statistics are used to create a probability distribution for each tag. After that, the frequent tags are clustered based on the distance between their <b>co-occurrence</b> <b>probability</b> distributions. Next, probability distributions for the less frequent tags are generated based on the co-occurrence with the clusters of most frequent tags. Finally, similar tags are identified by calculating the distance between the corresponding probability distributions. To that end, we propose an extension for Jensen-Shannon Divergence which is sensitive for the size of the sample from which the <b>co-occurrence</b> <b>probability</b> distributions are calculated. We evaluated our approach by applying it on folksonomies obtained from Flickr. Additionally, we compared our results to that which were produced by a traditional method for tag clustering. The adversary method identifies similar tags by calculating the cosine similarity between the co-occurrence vectors of the tags. The evaluation shows promising results and emphasizes the advantage of our approach...|$|E
40|$|Prior {{research}} suggests that preschoolers can generalize object properties based on category information conveyed by semantically-similar labels. However, previous research did not control for <b>co-occurrence</b> <b>probability</b> of labels in natural speech. The current studies re-assessed children 2 ̆ 7 s generalization with semantically-similar labels. Experiment 1 indicated that adults made category-based inferences regardless of co-occurrence probability; however, 4 -year-olds generalized with semantically-similar labels that co-occurred in child-directed speech (e. g., bunny-rabbit) but not with non-co-occurring labels (e. g., crocodile-alligator). Experiment 2 indicated that generalization with semantically-similar labels increased gradually between 4 - and 6 -years of age. These results are discussed in relation to theories of early learning...|$|E
40|$|Abstract — Most of {{the recent}} {{research}} on polarimetric SAR classification focused on pixel-based techniques using the covariance matrix representation. Since multiple channels are inherently provided in polarimetric data, conventional techniques for increasing the dimensionality of the observation, such as texture feature extraction, were ignored. In this paper, we have demonstrated the potential of texture classification through gray level <b>co-occurrence</b> <b>probabilities</b> (GLCP), and proposed an unsupervised scheme using the self-organizing map (SOM) neural network. The increase in separability of the feature space is shown via the Fisher criterion and also verified by increased classification performance. Compared to the Wishart classifier, promising classification results are obtained from the Flevoland data set. I...|$|R
40|$|Becoming {{a native}} {{listener}} is the necessary precursor {{to becoming a}} native speaker. Babies {{in the first year}} of life undertake a remarkable amount of work; by the time they begin to speak, they have perceptually mastered the phonological repertoire and phoneme <b>co-occurrence</b> <b>probabilities</b> of the native language, and they can locate familiar word-forms in novel continuous-speech contexts. The skills acquired at this early stage form a necessary part of adult listening. However, the same native listening skills also underlie problems in listening to a late-acquired non-native language, accounting for why in such a case listening (an innate ability) is sometimes paradoxically more difficult than, for instance, reading (a learned ability) ...|$|R
40|$|Estimating word <b>co-occurrence</b> <b>probabilities</b> is {{a problem}} {{underlying}} many applications in statistical natural language processing. Distance-weighted (or similarityweighted) averaging {{has been shown to}} be a promising approach to the analysis of novel co-occurrences. Many measures of distributional similarity have been proposed for use in the distance-weighted averaging framework; here, we empirically study their stability properties, finding that similarity-based estimation appears to make more efficient use of more reliable portions of the training data. We also investigate properties of the skew divergence, a weighted version of the Kullback-Leibler (KL) divergence; our results indicate that the skew divergence yields better results than the KL divergence even when the KL divergence is applied to more sophisticated probability estimates. ...|$|R
40|$|With the {{development}} of community based question answering (Q&A) services, a large scale of Q&A archives have been accumulated and are an important information and knowledge resource on the web. Question and answer matching has been attached much importance to {{for its ability to}} reuse knowledge stored in these systems: it can be useful in enhancing user experience with recurrent questions. In this paper, we try to improve the matching accuracy by overcoming the lexical gap between question and answer pairs. A Word Embedding based Correlation (WEC) model is proposed by integrating advantages of both the translation model and word embedding, given a random pair of words, WEC can score their <b>co-occurrence</b> <b>probability</b> in Q&A pairs and it can also leverage the continuity and smoothness of continuous space word representation to deal with new pairs of words that are rare in the training parallel text. An experimental study on Yahoo! Answers dataset and Baidu Zhidao dataset shows this new method's promising potential. Comment: 8 pages, 2 figure...|$|E
40|$|Prior {{research}} suggests young children understand that labels serve as category markers {{and that they}} can utilize this information to perform category-based induction with both identical and semantically-similar labels (Gelman & Markman, 1986). Recent {{research suggests}} that children’s ability to perform category-based induction is limited to a small subset of semantically-similar labels which co-occur in child-directed speech (Fisher, 2010; Fisher, Matlen, & Godwin, in press). However, most of the co-occurring labels used in prior research are not only semantically-similar but they also refer to baby-parent relationships (e. g., puppydog). Thus, children may be able to perform induction with these particular label-pairs, because they contain kinship information rather than because they co-occur. The present study aims to disentangle whether young children’s induction performance is driven by kinship information or <b>co-occurrence</b> <b>probability.</b> Results indicate that 4 -year-olds’ (but not 5 -year-olds, 7 -year-olds, or adults) induction performance was influenced by co-occurrence probability; kinship information was found to be insufficient to promote young children’s induction performance...|$|E
40|$|AbstractSignature file is a well-studied {{method in}} {{information}} retrieval for indexing large text databases. Because {{of the small}} index size in this method, {{it is a good}} candidate for environments where memory is scarce. This small index size, however, comes at the cost of high false positive error rate. In this paper we address the problem of high false positive error rate of signature files by introducing COCA filters, a new variation of Bloom filters which exploits the <b>co-occurrence</b> <b>probability</b> of words in documents to reduce the false positive error. We show experimentally that by using this technique in real document collections we can reduce the false positive error by up to 21 times, for the same index size. It is also shown that in some extreme cases this technique is even able to completely eliminate the false positive error. COCA filters can be considered as a good replacement for Bloom filters wherever the co-occurrence of any two members of the universe is identifiable...|$|E
40|$|This paper {{describes}} the National Research Council (NRC) Word Sense Disambiguation (WSD) system, {{as applied to}} the English Lexical Sample (ELS) task in Senseval- 3. The NRC system approaches WSD as a classical supervised machine learning problem, using familiar tools such as the Weka machine learning software and Brill's rule-based part-of-speech tagger. Head words are represented as feature vectors with several hundred features. Approximately half of the features are syntactic {{and the other half}} are semantic. The main novelty in the system is the method for generating the semantic features, based on word <b>co-occurrence</b> <b>probabilities.</b> The probabilities are estimated using the Waterloo MultiText System with a corpus of about one terabyte of unlabeled text, collected by a web crawler...|$|R
40|$|A given entity, {{representing}} a person, a location or an organization, may be mentioned in text in multiple, ambiguous ways. Understanding natural language requires identifying whether different mentions of a name, {{within and across}} documents, represent the same entity. We develop an unsupervised learning approach that is shown to resolve accurately several aspects of the name identity and tracing problem. At {{the heart of our}} approach is a generative model of how documents are generated and how names are “sprinkled ” into them; in particular, we model appearance similarity between names representing the same entity, contextual correlation among entities, and <b>co-occurrence</b> <b>probabilities</b> of entities within a document. We show how to estimate the model and do inference with it and how this resolves several aspects of the problem from the perspective of applications such as questions answering. ...|$|R
40|$|International audienceThe general goal {{of music}} signal {{decomposition}} is {{to represent the}} music structure into a note level to provide val- uable semantic features for further music analysis tasks. In this paper, we propose a new method to sparsely decompose the music signal onto a MIDI dictionary made of musical notes. Statistical music knowledge is further integrated into the whole sparse decomposition process. The proposed method is divided into a frame level sparse decomposition stage and a whole music level optimal note path searching. In the first stage note <b>co-occurrence</b> <b>probabilities</b> are embedded to generate a sparse multiple candidate graph while in the second stage note transition probabilities are incorporated into the optimal path searching. Experiments on real-world polyphonic music show that embedding music knowledge within the sparse decomposition achieves notable improvement in terms of note recognition precision and recall...|$|R
40|$|A design-based {{method to}} fuse Gabor filter and grey level <b>co-occurrence</b> <b>probability</b> (GLCP) {{features}} for improved texture recognition is presented. The fused feature set utilizes both the Gabor filter’s capability of accurately capturing lower and mid-frequency texture {{information and the}} GLCP’s capability in texture information relevant to higher frequency components. Evaluation methods include comparing feature space separability and comparing image segmentation classification rates. The fused feature sets are demonstrated to produce higher feature space separations, as well as higher segmentation accuracies relative to the individual feature sets. Fused feature sets also outperform individual feature sets for noisy images, across different noise magnitudes. The curse of dimensionality is demonstrated not to affect segmentation using the proposed the 48 -dimensional fused feature set. Gabor magnitude responses produce higher segmentation accuracies than linearly normalized Gabor magnitude responses. Feature reduction using principal component analysis is acceptable for maintaining the segmentation performance, but feature reduction using the feature contrast method dramatically reduced the segmentation accuracy. Overall, the designed fused feature set is advocated {{as a means for}} improving texture segmentation performance...|$|E
40|$|Much {{research}} {{has been devoted to}} the task of learning lexical classes from unannotated input text. Among the chief difficulties facing any approach to the unsupervised induction of lexical classes are that of token-level ambiguity and the classification of rare and unknown words. Following the work of previous authors, the initial stage of syntactic category induction is treated in the current approach as a clustering problem over a small number of highly frequent word types. An iterative procedure making use of Zipf’s law to generate the clustering schedule classifies less frequent words based on the monotonic Bernoulli entropy of expected <b>co-occurrence</b> <b>probability</b> with respect to the clusters output by the previous stage, employing a fuzzy cluster membership heuristic to approximate type-level ambiguity and reduce error propagation in a simulated melting procedure. In a second processing phase, cluster membership probabilities output by the final clustering stage are used in a procedure for the recovery of context-dependent token-level ambiguity resolution. The induced classifications are evaluated with a meta-modelling strategy intended t...|$|E
40|$|Prior {{research}} had documented that semantically-similar labels that co-occur in child-directed speech promote generalization in young children. The present study examined whether <b>co-occurrence</b> <b>probability</b> – {{in the absence}} of semantic similarity – can influence children’s inferences. Four- and five-year-old children were exposed to an auditory speech stream consisting of trisyllabic nonsense words (e. g. “golabu”) that were concatenated into a continuous speech stream. After listening to the stream, children were given a label extension task where the first two syllables of a nonsense word were assigned to a novel target object (e. g. “gola”); children were asked to choose which of the three test items should be referred to by the remaining syllable of this nonsense word (e. g., “bu”; Experimental condition) or by a syllable from a different nonsense word (e. g., “ti”; Control condition). Children’s generalization performance in this task was similar to results of previous research that used natural rather than artificial language stimuli. These results are consistent with the notion that that low-level, automatic processes can influence performance on high-level reasoning tasks...|$|E
40|$|Abstract—We tackle {{problems}} related to Web query formulation: given the set of keywords from a search session, 1) we find a maximum promising Web query, and, 2) we construct a family of promising Web queries covering all keywords. A query is promising if it fulfills user-defined constraints {{on the number of}} returned hits. We assume a real-world setting where the user is not given direct access to a search engine’s index, i. e., querying is possible only through an interface. The goal to be optimized is the overall number of submitted Web queries. For both problems we develop search strategies based on <b>co-occurrence</b> <b>probabilities.</b> The achieved performance gain is substantial: compared to the uninformed baselines without cooccurrence probabilities the expected savings are up to 50 % in the number of submitted queries, index accesses, and runtime...|$|R
30|$|A set of 13 {{attributes}} per image {{sample were}} computed from {{color and texture}} models using HSI statistics and gray level <b>co-occurrence</b> matrices (GLCMs) <b>probabilities.</b>|$|R
40|$|We {{propose a}} method for {{accurately}} localizing ground vehicles {{with the aid of}} satellite imagery. Our approach takes a ground image as input, and outputs the location from which it was taken on a georeferenced satellite image. We perform visual localization by estimating the <b>co-occurrence</b> <b>probabilities</b> between the ground and satellite images based on a ground-satellite feature dictionary. The method is able to estimate likelihoods over arbitrary locations without the need for a dense ground image database. We present a ranking-loss based algorithm that learns location-discriminative feature projection matrices that result in further improvements in accuracy. We evaluate our method on the Malaga and KITTI public datasets and demonstrate significant improvements over a baseline that performs exhaustive search. Comment: 9 pages, 8 figures. Full version is submitted to ICRA 2016. Short version is to appear at NIPS 2015 Workshop on Transfer and Multi-Task Learnin...|$|R
