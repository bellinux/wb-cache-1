39|10000|Public
2500|$|... Homebrew Cavendish experiment, showing <b>calculation</b> <b>of</b> <b>results</b> and {{precautions}} {{necessary to}} eliminate wind and electrostatic errors.|$|E
2500|$|Starting in 2011, {{critics of}} the studies filed Freedom of Information Act {{requests}} {{to get access to}} the authors' primary data, in order to learn what the trial’s results would have been under the original protocol. [...] In 2016 some of the data was released, which allowed <b>calculation</b> <b>of</b> <b>results</b> based on the original protocol and found that additional treatment led to no significant improvement in recovery rates over the control condition.|$|E
5000|$|... 42,274 {{people could}} not vote, because they worked abroad or were {{involved}} in military service or military exercises, and were not counted in the <b>calculation</b> <b>of</b> <b>results.</b>|$|E
5000|$|... #Subtitle level 2: Process <b>of</b> <b>calculation</b> <b>of</b> the <b>results</b> <b>of</b> the {{election}} ...|$|R
25|$|The fifty-move rule {{is ignored}} in the <b>calculation</b> <b>of</b> these <b>results</b> and lengths.|$|R
40|$|To {{solve the}} high cost and the {{excessive}} payment problem in calculation for Shortest Path of the traditional Ad-hoc VCG mechanism, a new route selection mechanism based on social-aware (named SA-VCG) and its related algorithm are developed. By bridge nodes detected by calculating the egobetweenness centrality in the Social Network Analysis, the network topology is divided into many subgroups effectively. the <b>calculation</b> <b>of</b> <b>result</b> <b>of</b> SP is reused in the same subgroup. The “irreplaceable subgroup ” and “irreplaceable bridge ” have also been put forward. The analytical and simulation {{results show that the}} algorithm can reduce the storage cost and increase the computational efficiency...|$|R
50|$|All the {{possible}} penalties {{are described in}} the rule books, published by the FEI and National Federations. <b>Calculation</b> <b>of</b> <b>results</b> is complex. There are software programs available to record the data and output results.|$|E
5000|$|Protocols for {{methods that}} produce {{numerical}} results generally include detailed formulae for <b>calculation</b> <b>of</b> <b>results.</b> Formula {{may also be}} included for preparation of reagents and other solutions required for the work. Methods of statistical analysis may be included to guide interpretation of the data.|$|E
50|$|Instrumentation {{can be used}} to read {{extremely}} small signals created by secondary reactions linked to the antibody - antigen binding. Instrumentation can control sampling, reagent use, reaction times, signal detection, <b>calculation</b> <b>of</b> <b>results,</b> and data management to yield a cost effective automated process for diagnosis of infectious disease.|$|E
40|$|Three {{statistical}} methods are described and illustrated with working examples. Using these methods {{it is possible}} to include all subjects involved in cross-sectional studies in <b>calculations</b> <b>of</b> <b>results,</b> even if the data are incomplete {{at the end of the}} investigation. The use of censored data is taken from survival analysis. It is shown that combination of the Kaplan-Meier estimate, the log-rank test and the proportional hazards model gives more satisfactory results in nutritional and growth studie...|$|R
40|$|This article {{provides}} a brief {{introduction of the}} bioengineering and biomechanical modelling approaches use to determine the force and moment, structural stability, and risk of injury. Model gives the conceptual construction which allows the formulation and testing. The analysis of complete body is done using link segment model. Throughout the article various modelling methods are presented and their applications are discussed. The computer program is developed for <b>calculation</b> <b>of</b> <b>result.</b> The program is user friendly in operation and change in the input can be made easily...|$|R
40|$|The goal of {{the paper}} is {{theoretical}} and methodological analysis {{in the evaluation of}} the level of innovative potential of regions. The novelty is the approach to the estimation of innovative potential of regions, which is based on the <b>calculation</b> <b>of</b> <b>resulting</b> index <b>of</b> innovative potential of the regions which is improved methodologically on the basis of four subindexes of the relevant components compared with the existing potential. Key words: human capital, knowledge economy, economy index, knowledge index, innovative potential, regions of Ukraine, regional ranking...|$|R
5000|$|PATENTEM {{system allows}} {{to conduct the}} process of voting in three {{different}} ways: open, closed, and secret. Every type can be customized {{to address the needs}} of each meeting through [...] "Settings" [...] section. Such customizaation may include setting up of vote weight, formula for <b>calculation</b> <b>of</b> <b>results</b> etc. Participants of the meeting are given an option to vote using either buttons on delegates' workstations or touchscreens.|$|E
50|$|Starting in 2011, {{critics of}} the studies filed Freedom of Information Act {{requests}} {{to get access to}} the authors' primary data, in order to learn what the trial’s results would have been under the original protocol. In 2016 some of the data was released, which allowed <b>calculation</b> <b>of</b> <b>results</b> based on the original protocol and found that additional treatment led to no significant improvement in recovery rates over the control condition.|$|E
50|$|In {{the natural}} {{sciences}} a protocol is a predefined written procedural method {{in the design and}} implementation of experiments. Protocols are written whenever it is desirable to standardize a laboratory method to ensure successful replication of results by others in the same laboratory or by other laboratories. Detailed protocols also facilitate the assessment of results through peer review. In addition to detailed procedures and lists of required equipment and instruments, protocols often include information on safety precautions, the <b>calculation</b> <b>of</b> <b>results</b> and reporting standards, including statistical analysis and rules for predefining and documenting excluded data to avoid bias. Protocols are employed {{in a wide range of}} experimental fields, from social science to quantum mechanics. Written protocols are also employed in manufacturing to ensure consistent quality.|$|E
40|$|AbstractIn {{order to}} study {{consistency}} <b>of</b> <b>calculation</b> <b>results</b> <b>of</b> typical vehicle collision models {{based on the}} law of momentum conservation, the difference of coordinate systems of two typical models is analyzed. Consistency of two typical models is studied by using empirical formulas based on vehicle collision tests. From the above study, a vehicle collision accident is analyzed by using two typical models. Results show that <b>calculation</b> <b>results</b> <b>of</b> two typical models are identical under reasonable selection of coefficients in these models, thus two typical models are consistent. Study results provide the basis for consistent analysis of similar models...|$|R
40|$|Abstract: Comparison <b>of</b> <b>calculation</b> <b>results</b> <b>of</b> {{transport}} {{properties of}} the solid fuels combustion products was made with known experimental data. Calculation was made {{by means of the}} modified program TETRAN developed in G. M. Krzhizhanovsky Power Engineering Institute. The calculation was spent with chemical reactions and phase transformations occurring during combustion. Also ionization of products of solid fuels combustion products at high temperatures was taken into account. In the capacity of fuels various Russian coals and some other solid fuels were considered. As a <b>result</b> <b>of</b> density, viscosity and heat conductivity <b>calculation</b> <b>of</b> a gas phase of solid fuels combustion products the data has been obtained in a range of temperatures 500 - 20000. This comparison has shown good convergence <b>of</b> <b>calculation</b> <b>results</b> with experiment. 1...|$|R
40|$|The article {{introduces}} {{social network}} user sentiment evaluation with proposed technique based on fuzzy sets. The advantage of proposed technique consists in {{ability to take}} into account user's influence as well as the fact that a user could be an author <b>of</b> several messages. <b>Results</b> presented in this paper can be used in mechanical engineering to analyze reviews on products as well as in robotics for developing user communication interface. The paper contains experimental data and shows the steps <b>of</b> sentiment value <b>calculation</b> <b>of</b> <b>resulting</b> messages on a certain topic. Application of proposed technique is demonstrated on experimental data from Twitter social network...|$|R
5000|$|But though Hutcheson usually {{describes}} the moral faculty as acting instinctively and immediately, he does not, like Butler, conflate the moral faculty with the moral standard. The test or criterion of right action is with Hutcheson, as with Shaftesbury, its tendency {{to promote the}} general welfare of mankind. He thus anticipates the utilitarianism of Bentham—and not only in principle, {{but even in the}} use of the phrase [...] "the greatest happiness for the greatest number" [...] (Inquiry concerning Moral Good and Evil, sect. 3). Hutcheson does not seem to have seen an inconsistency between this external criterion with his fundamental ethical principle. Intuition has no possible connection with an empirical <b>calculation</b> <b>of</b> <b>results,</b> and Hutcheson in adopting such a criterion practically denies his fundamental assumption. Connected with Hutcheson's virtual adoption of the utilitarian standard is a kind of moral algebra, proposed for the purpose of [...] "computing the morality of actions." [...] This calculus occurs in the Inquiry concerning Moral Good and Evil, sect. 3.|$|E
40|$|Direct {{leukocyte}} migration inhibition assays {{using the}} capillary tube technique {{can be used}} to demonstrate cell-mediated immunity in vitro. Unfortunately, the cumbersome nature of this technique makes it time consuming and difficult to perform. Similar results have been obtained using the direct agarose microdroplet leukocyte migration inhibition assay. In this paper, modifications of the agarose technique are outlined which insure standardization of droplets and ease of performance of the assay. Additionally a technique is described to reduce the time required for <b>calculation</b> <b>of</b> <b>results...</b>|$|E
40|$|The {{enzyme-linked}} immunosorbent assay (ELISA) is {{used extensively}} in immunologic research for obtaining quantitative estimates of immunoglobulin concentration in cell culture supernates. Through incorporation of a microcomputer for data acquisition, storage and rapid <b>calculation</b> <b>of</b> <b>results,</b> a substantial reduction in total assay time may be realized. Described here are a set of menu-driven programs written in Basic for the IBM-PC which provide advantages over existing software in simplicity, versatility and accuracy. Hardware requirements are minimal. These programs should encourage greater flexibility {{in terms of the}} size and complexity of experimental designs...|$|E
40|$|This paper {{proposes a}} {{modeling}} framework {{on how to}} specify security preferences and importance of software services, and compute a quantifiable value. Our approach advocates for an automatic <b>calculation</b> <b>of</b> the <b>results</b> <b>of</b> compliances between user's security preferences and the provider's capabilities in terms of security properties...|$|R
30|$|However, {{the papers}} {{mentioned}} above are mainly about {{the comparison between}} single ESSs and HESSs, and the evaluation is based on subjective judgment instead <b>of</b> the quantitative <b>calculation</b> <b>of</b> optimization <b>results.</b> Also, the impact on safety and the environment is not included.|$|R
40|$|AbstractIn {{the paper}} the Analysis of the Interaction of Drilled Shafts with soft and middle {{strength}} Rock Masses is con-sidered. The Analysis {{is based on}} <b>results</b> <b>of</b> three dimensional numerical modeling {{of the behavior of}} drilled shafts under normal compression loads. Factor dependences (regression equations) for <b>calculations</b> <b>of</b> values of shafts bearing capacity and settlements were developed. As varying factors in factor dependences the length and diameter of shafts, the deformability of concrete and rocks and rock quality designation parameter (RQD) were taken. <b>Results</b> <b>of</b> <b>calculations</b> with <b>results</b> <b>of</b> in situ loading tests were compared...|$|R
40|$|Here, {{we used a}} fully automated, computer-directed centrifU-gal {{analyzer}} (which permitted simultaneous turbidimetry and <b>calculation</b> <b>of</b> <b>results)</b> and purifed thrombin, fibrinogen, {{and various}} inhibitors to study clot formation. The l and Vmfor these reactionswere useful in detecting and partlycharacter-izing anticoagulants. We also explored the generation and inactivation of thrombin, using the two-stage prothrombin time and antithrombin activity tests. The amount of thrombin instantaneously generated and inactivated was monitored under artificially created pathological conditions. The pseu-do-first-order rate constant for thrombin generation and inac-tivation and the instantaneous concentration of enzymatically active and inactive thrombin {{were used in the}} characteriza-tion of these conditions. We believe this approach is suitable for routine clinical use...|$|E
40|$|Abstract. A microneutralization {{test that}} {{measures}} anti-dengue antibodies was developed. Serum dilutions, neu-tralization reactions, and virus growth were performed in 96 -well plates. After incubation, an enzyme-linked immu-nosorbent assay that used mouse anti-dengue antibodies and an enzyme-conjugated anti-mouse antibody {{was used to}} measure cell-associated viral antigens. The resulting optical density readings were processed and graphed automati-cally by a spreadsheet program. This procedure provided results that are essentially the same as those from the plaque-reduction neutralization test for serum samples from primary dengue virus infections, but results correlated poorly with results from samples from people with secondary infections. The test offers the advantages of ease of perfor-mance, ease in the <b>calculation</b> <b>of</b> <b>results,</b> lower cost, and increased speed...|$|E
40|$|Results of {{analysis}} of your seven samples collected 18 through 21 January, 1984 are attached. All {{analyses were performed}} using standard water analysis methodologies. Radon- 222 was determined on samples originally submitted for routine chemical analysis. These samples were delivered in partially-filled polyethylene bottles. Radon determinations were performed 4 February, 1984, by outgassing followed by scintillation counting. <b>Calculation</b> <b>of</b> <b>results</b> includes factors to correct for decay of radon subsequent to sampling. However, as time between collection and analysis increases, the reliability of data for low-level samples decreases. Also, because mathematical corrections cannot account for loss of radon, through container walls and into sample headspace, {{it is clear that}} radon data reported should be regarded with extreme caution...|$|E
30|$|This method {{involves}} a wet combustion {{of organic matter}} {{with a mixture of}} potassium dichromate and sulphuric acid at about 125  °C. To compensate for incomplete destruction, an empirical factor 1.3 (correction factor) is applied in <b>calculation</b> <b>of</b> the <b>result</b> (Walkley and Black 1934).|$|R
40|$|The method <b>of</b> <b>calculation</b> and <b>results</b> <b>of</b> {{computer}} dynamics {{modeling of}} solid ingot skin in a crystallizer {{are presented in}} the paper. The paper shows influence of ingot drawing rate on dynamics of solid ingot skin growth in the continuous casting machine at steel grades used at Republic Unitary Enterprise «Belarussian Metallurgical Works» (BMZ). </p...|$|R
40|$|Abstract. A {{remarkable}} {{series of}} breakthroughs in numerical relativity modeling of black hole binary mergers has {{occurred over the}} past few years. This paper provides a general overview of these exciting developments, focusing on recent progress in merger simulations and <b>calculations</b> <b>of</b> the <b>resulting</b> gravitational waveforms...|$|R
40|$|An {{overview}} of quasi-static electromagnetic dosimetry is presented. After an introductive description of quantities and standards {{and a quick}} look at experimental and analytical approaches, attention is focused on numerical dosimetry. The process that leads to the <b>calculation</b> <b>of</b> <b>results</b> is analyzed in its basic steps, including the representation of the human body by means of a realistic voxel phantom. The most popular numerical methods are then described. An analysis of different methods in the same framework emphasizes common features and differences. This can help in choosing a more suitable method to solve a particular problem. An example of an application is finally reported. numerical electromagnetic dosimetry quasi-static conditions voxel phantoms finite difference SPFD current vector potential method impedance network method 1...|$|E
40|$|This paper {{presents}} a concept for {{the identification of}} stable reference points used in horizontal control networks, {{which is based on}} the lengths of apparent displacement vectors and their mean errors. These vectors and their mean errors are obtained during the process of calculating displacements with free adjustment conditions. It will be shown that the influence of the apparent displacement vectors has a significant effect on the <b>calculation</b> <b>of</b> <b>results.</b> The identification of stable points, using the proposed method, {{is an integral part of}} the adjustment process and allows for the interrogation the influence of individual point inclusion or deletion from the reference database, on the values of displacements of controlled points. A detailed process of stable reference points identification is presented using the example of a linear-angular network for a barrage...|$|E
40|$|We have {{evaluated}} {{results for}} albumin obtained by a standard procedure for cellulose acetate electro-phoresis of proteins in serum. The Ponceau S-stained. albumin and globulins were eluted and the albumin {{was calculated by}} the generally accepted formula [(albumin-bound dye absorbance/absorbance of total protein-bound dye) X total serum protein concn] and by the formula (absorbance of albumin-bound dye in test/absorbance of albumin-bound dye in a refer-ence serum) X concn of albumin in reference serum. The ratio of values by {{the first and second}} methods ranged from 0. 93 to 1. 30, the first giving the higher results in cases of discrepancy. These findings confirm the limitations in accurately calculat-ing any serum-protein fraction by the first method. The second method appears to be the more accurate. Additional Keyphrases: serum albumin. dye-binding by proteins. <b>calculation</b> <b>of</b> <b>results</b> of electrophore...|$|E
40|$|The paper {{presents}} {{investigations of}} optical-microwave frequency conversion processes for InP-PIN photodiode. The planar InGaAsP/InGaAs/InP heterostructure PIN photodiode operating at 1. 3 µm {{has been used}} in an optoelectronic mixer configuration. The nonlinear model of the PIN photodiode responsivity has been assumed. The mathematical analysis of frequency conversion process and <b>results</b> <b>of</b> simulation are presented. The obtained <b>results</b> <b>of</b> <b>calculation</b> and <b>results</b> <b>of</b> measurements are compared and discussed...|$|R
40|$|The {{combustion}} {{of solid}} low-grade fuel in LTV-boiler furnaces is a pressing research questions currently. The {{aim of this}} work is to study the influence of flue gas entering the process fully-the boiler furnace. The <b>result</b> <b>of</b> the <b>calculation</b> <b>of</b> the <b>resulting</b> distribution <b>of</b> temperatures and oxygen concentrations along {{the height of the}} furnace. The analysis <b>of</b> the obtained <b>results...</b>|$|R
40|$|The {{problem of}} {{development}} of models and methods {{for carrying out}} the assessment of socio-economic projects is examined. The approach to informational simulation of project status {{on the basis of}} the determined, statistical and linguistic description of separate indexes is offered. A hierarchical procedure <b>of</b> <b>calculation</b> <b>of</b> project’s <b>resulting</b> figure is developed...|$|R
