21|44|Public
40|$|Interior-point {{methods have}} not only shown their {{efficiency}} for linear and some nonlinear programming problems, but also for cutting plane methods and large scale optimization. The analytic center cutting plane method uses the analytic center of the current polyhedral approximation of the feasible region to add a new cutting plane. In this thesis, analytic center cutting plane and path-following interior-point methodologies are used to solve the following problems: (1) convex feasibility problems defined by a deep <b>cut</b> <b>separation</b> oracle; (2) convex optimization problems involving a nonlinear objective and a constraint set defined implicitly by a separation oracle; (3) variational inequalities involving a nonlinear operator and a convex set explicitly defined; (4) variational inequalities involving an affine operator and a constraint set defined implicitly by a deep <b>cut</b> <b>separation</b> oracle; and (5) variational inequalities involving a nonlinear operator and a constraint set defined implicitly by a deep <b>cut</b> <b>separation</b> oracle. Here, the oracle is a routine that takes as input a test point. If the point belongs to the feasible region, it answers "yes", otherwise it answers "no" and returns a cut separating the point from the feasible region. Complexity bounds are established for algorithms developed for Cases 1, 2 and 4. The algorithm developed for Case 3 will be proven to be convergent, whereas, in Case 5, the developed algorithm will be shown to find an approximate solution in finite time...|$|E
40|$|International audienceStabilization {{procedures}} for column generation {{can be viewed}} as cutting plane strategies in the dual. Exploiting the link between in-out separation strategies and dual price smoothing techniques for column generation, we derive a generic bound convergence property for algorithms using a smoothing feature. Such property adds to existing in-out asymptotic convergence results. Beyond theoretically convergence, we describe a proposal for effective finite convergence in practice and we develop a smoothing auto-regulating strategy that makes the need for parameter tuning obsolete. These contributions turn stabilization by smoothing into a general purpose practical scheme that can be used into a generic column generation procedure. We conclude the paper by showing that the approach can be combined with an ascent method, leading to improved performances. Such combination might inspire novel <b>cut</b> <b>separation</b> strategies...|$|E
40|$|Disjunctive {{cuts for}} Mixed-Integer Linear Programs (MIPs) were {{introduced}} by Egon Balas {{in the late}} 1970 s and have been successfully exploited in practice since the late 1990 s. In this paper we investigate the main ingredients of a disjunctive <b>cut</b> <b>separation</b> procedure, and analyze {{their impact on the}} quality of the root-node bound for a set of instances taken from MIPLIB library. We compare alternative normalization conditions, and try to better understand their role. In particular, we point out that constraints that become redundant (because of the disjunction used) can produce over-weak cuts, and analyze this property with respect to the normalization used. Finally, we introduce a new normalization condition and analyze its theoretical properties and computational behavior. Along the way, we make use of a number of small numerical examples to illustrate some basic (and often misinterpreted) disjunctive programming features...|$|E
3000|$|In this case, the {{possible}} time reserves at separating elements min{δ t_ 1 ([...] v_ 2), δ t_ 2 ([...] v_ 2)} - t_min {{are used to}} ensure the <b>cuts</b> <b>separation</b> when the actual time of their rolling along the route {{is different from the}} calculated one (here, t_min is the minimum permissible value of the interval between the cuts, at which the point can be switched).|$|R
50|$|<b>Cutting</b> is the <b>separation</b> of a {{physical}} object, into two or more portions, {{through the application of}} an acutely directed force.|$|R
40|$|Purpose. The {{application}} of automation systems of breaking up process on the gravity hump is the efficiency improvement of their operation, absolute provision of trains breaking up safety demands, {{as well as}} improvement of hump staff working conditions. One of the main tasks of the indicated systems is the assurance of <b>cuts</b> reliable <b>separation</b> at all elements of their rolling route to the classification track. This task is a sophisticated optimization problem and has not received a final decision. Therefore, the task of determining the cuts braking mode is quite relevant. The purpose {{of this research is}} to find the optimal braking mode of control cut of design group. Methodology. In order to achieve the purpose is offered to use the direct search methods in the work, namely the Box complex method. This method does not require smoothness of the objective function, takes into account its limitations and does not require calculation of the function derivatives, and uses only its value. Findings. Using the Box method was developed iterative procedure for determining the control cut optimal braking mode of design group. The procedure maximizes the smallest controlled time interval in the group. To evaluate the effectiveness of designed procedure the series of simulation experiments of determining the control cut braking mode of design group was performed. The results confirmed the efficiency of the developed optimization procedure. Originality. The author formalized the task of optimizing control cut braking mode of design group, taking into account the <b>cuts</b> <b>separation</b> of design group at all elements (switches, retarders) during cuts rolling to the classification track. The problem of determining the optimal control cut braking mode of design group was solved. The developed braking mode ensures <b>cuts</b> reliable <b>separation</b> of the group not only at the switches but at the retarders of brake position. Practical value. The developed procedure can be successfully used to determine the optimal braking modes of cuts in automation systems of trains breaking up on the gravity humps...|$|R
30|$|The {{problem of}} car speed control at humps was {{considered}} by Bessonenko et al. [9]. They proposed {{to set the}} cut exit speed from the first braking position, proceeding from the conditions of preserving the initial interval between the cuts at the hump top and ensuring their separation at the second brake position, and the braking mode at the second position—from the condition of <b>cut</b> <b>separation</b> at the switches. Some other researchers [10, 11] proposed {{to solve the problem}} of controlling the car rolling speed at the humps based on neural network training. The problem with this approach is that the methods based on the use of neural networks are heuristic and often lead to ambiguous solutions; as a result, the behavior of the trained neural network cannot always be clearly predicted. This increases the risk of their use in real-time systems related to traffic safety.|$|E
40|$|Assessment is an {{essential}} element for every student in learning processes. Learning management systems (LMSs) provide support for assessment. As we are computer science students assessment is required for programming languages. Automatic assessment of programming exercises has become an important method for grading students exercises and giving feedback for them. In addition to assignments that are graded by teachers, we also support assignments that can be automatically compiled and can check for errors. This is very helpful for students {{so that they can}} check and assess themselves before submitting. In this paper we report about service-oriented approach for automatic assessment of programming assignments specifically taking a single programming language c#. net. There is a clear <b>cut</b> <b>separation</b> between frontends and back-ends. Assessment can be easily interfaced with different existing learning management systems (as so called frontends). We also report about different generations of automatic assessment system, their problems...|$|E
40|$|We {{present a}} model of office work and {{workflow}} systems that we call workcase centric, based on the view that office work is a collaborative construction of a case artifact. This model allows for the uniform treatment of cases for which the organization has no predefined procedure, of exceptional cases where the standard procedure must be modified, and of standard cases. 1 Introduction Most of the existing workflow management systems target formal procedures automation only. Informal or unstructured procedures are, for the most part, treated as exceptions. As the name implies, exceptions are by definition things for which no support is provided, because they should be rare. As a result, the most challenging and demanding organizational work is not dealt with. In these systems, there is usually a clear <b>cut</b> <b>separation</b> between modeling and enactment, due perhaps {{to the influence of}} traditional systems analysis. This approach seems not to work well for workflow systems, because of the much [...] ...|$|E
40|$|We {{are given}} a set of n d-dimensional (possibly intersecting) isothetic hyperrectangles. The topic {{of this paper is}} the {{separation}} of these rectangles by means of a cutting isothetic hyperplane. Thereby we assume that a rectangle which is intersected by the cutting plane is cut into two non-overlapping hyperrectangles. We investigate the behavior of several kinds of balancing functions, as well as their linear combination and present optimal and practical algorithms for computing the corresponding balanced cuts. In addition, we give tight worst-case bounds for the quality of the balanced cuts. Our results include a generalization [1] and a simplification [3, 10] of recent results. Keywords: rectangles, balanced <b>cuts,</b> <b>separation,</b> binary space partition 1 Introduction Given a set of n d-dimensional (possibly intersecting) isothetic hyperrectangles, we consider the problem of separating these rectangles by means of a cutting isothetic hyperplane. If the cutting plane crosses a rectangle, [...] ...|$|R
40|$|Purpose. The {{purpose is}} the {{improvement}} of the method of choosing the retarding regimes of cut rolling within the particular group in order to increase the quality of interval speed control of cuts at the automated hump. Methodology. Simulation method was used for research the trains’ breaking up process at the hump. Findings. The <b>separation</b> conditions of <b>cuts</b> within the particular group and their relation between the retarding regimes of cut control based on a system approach were studied. Interval between cuts within the particular group at the switches and retarders were considered simultaneously. The features of interval controlling at the classification humps with different mutual alignment of the first switch and master retarder were stressed. Originality. The researches found out that during optimization of the retarding regimes of cuts within the particular group one should provide the best conditions of <b>cuts</b> <b>separation</b> at the switches and retarders. Practical value. The problem of choosing the retarding regimes of cuts within the particular group is optimized formally. This retarding regime allows maximizing the minimum value of interval between cuts within the group...|$|R
40|$|Separation of binary isotope {{mixtures}} in multistage installations {{consisting of}} separation elements with constant <b>cut</b> numbers and <b>separation</b> factors is considered. The analytical solution for component concentration distributions over a cascade with constant cut numbers is obtained. Major mass transfer regularities {{in such a}} kind of cascades are reviewed...|$|R
40|$|A branch-and-cut mixed integer {{programming}} system, called bc - opt, is described, incorporating {{most of the}} valid inequalities {{that have been used}} or suggested for such systems, namely lifted 0 - 1 knapsack inequalities, 0 - 1 gub knapsack and integer knapsack inequalities, flow-cover and continuous knapsack inequalities, path inequalities for fixed charge network flow structure and Gomory mixed integer cuts. The principal development is a set of interface routines allowing these cut routines to generate cuts for new subsets or aggregations of constraints. The system is built using the XPRESS Optimisation Subroutine Library (XOSL) which includes a cut manager that handles the tree and cut management, so that the user only essentially needs to develop the <b>cut</b> <b>separation</b> routines. Results for the MIPLIB 3. 0 library are presented - 37 of the instances are solved very easily, optimal or near optimal solution are produced for 18 other instances, and of the 4 remaining instances, 3 have 0, + 1, - 1 matrices for which bc - opt contains no special features...|$|E
40|$|The split cuts of Cook, Kannan and Schrijver are {{general-purpose}} valid inequalities for {{integer programming}} {{which include a}} variety of other well-known cuts as special cases. To detect violated split cuts, one has to solve the associated separation problem. The complexity of split <b>cut</b> <b>separation</b> was recently cited as an open problem by Cornuejols & Li [10]. In this paper we settle this question by proving strong NP-completeness of separation for split cuts. As a by-product we also show NP-completeness of separation for several other classes of inequalities, including the MIR-inequalities of Nemhauser and Wolsey and some new inequalities which we call balanced split cuts and binary split cuts. We also strengthen NP-completeness results of Caprara & Fischetti [5] (for { 0, 1 2 }-cuts) and Eisenbrand [12] (for Chvatal-Gomory cuts). To compensate for this bleak picture, we also give a positive result for the Symmetric Travelling Salesman Problem. We show how to separate in polynomial time over a class of split cuts which includes all comb inequalities with a fixed handle...|$|E
40|$|Ipomoea genus {{is widely}} {{distributed}} in the tropical and subtropical regions of the world. The exploration of genetic diversity is pre-requisite for genome organization in the wild species and the related domesticated ones. Inter-simple Sequence Repeat (ISSR) markers {{was used to assess}} the identification of 21 important Ipomoea species and determination of the genetic relationships among these species. Out of 20 ISSR primers tested, twelve primers produced 218 detectable fragments, of which 207 (94. 9 %) were polymorphic across the species. Each of the twelve primers produced fingerprint profile unique to each of the species studied, and thus could be solely used for their identification. Forty four unique bands specific to fifteen species were detected. These may be converted into species-specific probes for identification purposes. Genetic relationships among these species were evaluated by generating a similarity matrix based on the Dice coefficient and the Unweighted Pair Group Method with Arithmetic Average (UPGMA) dendogram. The results showed a clear <b>cut</b> <b>separation</b> of the 21 Ipomoea species and were in broad agreement with the morphology. Both molecular and morphological markers will be useful for preservation of the Ipomoea germplas...|$|E
50|$|Emek's style, {{known for}} its {{attention}} to detail and layers of meaning, infuses socio-political commentary into pop culture imagery. All of Emek's artwork is originally hand-drawn and then hand-silkscreened for each actual concert or event, usually in limited editions of around 300. In recent years Emeks’ file separations are digital, favoring the time saving method over the traditional hand- <b>cut</b> rubilith <b>separations</b> he would make to produce posters like The Black Crowes 2001 show at the Santa Barbara Bowl & Greek Theater. Over the last decade, Emek's work {{has been shown in}} galleries across the United States, in Berlin, London and Tokyo.|$|R
50|$|The {{puncture}} resistance {{will depend}} on the nature of puncture attempt, with the two most important features being point sharpness and force. A fine sharp point such as a hypodermic needle will require a high ability to absorb and distribute the force to avoid penetration, but the total forces applied are still limited. The EN388 glove standard use a more pencil-like object with a flat tip of 1mm diameter. The EN388 test is highly dependent on the materials ability to withstand high forces through high tenacity {{and to a lesser extent}} to avoid <b>cut</b> or <b>separation</b> of the material.|$|R
40|$|DE 10303741 A UPAB: 20040910 NOVELTY - A {{process for}} {{separating}} a longitudinal member, especially a polymer optical fibre, comprises cutting the member (2) using a separating tool (1) cutting edge, and then smoothing the separation surface. Separating and smoothing {{are carried out}} in a single step using the tool. A tool surface with abrasive granules (3) is used to smooth <b>cut.</b> The <b>separation</b> tool surface is smooth and is heated during separation. Heating is carried out using a radiation source (5), eg a light source. USE - The process is used to separate a longitudinal member, especially a polymer optical fibre. ADVANTAGE - The cut is smooth and minimizes optical losses...|$|R
40|$|Much {{progress}} has been made in recent years in solving certain classes of production planning problems using mixed integer programming. One of the major challenges is how to make this expertise available and easy to use to the non-specialist and to the practitioners. Here we describe a modeling approach and tool LS-LIB, and report on computational results. LS-LIB is a library of primitives to declare procedures/subroutines/global constraints in a high-level modeling language that we believe offers an interesting partial answer to this challenge. LS-LIB provides routines for problem reformulation, cut generation, and heuristics to find good feasible solutions quickly. The user must provide an initial formulation of his problem in the modeling language MOSEL. Then using his knowledge of the problem he must first classify each product or sku according to a simple three field scheme: [production type, capacity type, variant] proposed recently. Then it is a simple matter to use the global constraints of LS-LIB by adding a few lines to his initial MOSEL formulation to get a tightened formulation and/or call the appropriate <b>cut</b> <b>separation</b> routines. The heuristic procedures are called in a similar fashion. We illustrat...|$|E
40|$|How {{difficult}} is, in practice, {{to optimize}} exactly {{over the first}} Chvátal closure of a generic ILP? Which fraction of the integrality gap can be closed this way, e. g., for some hard problems in the MIPLIB library? Can the first-closure optimization be useful as a research (off-line) tool to guess the structure of some relevant classes of inequalities, when a specific combinatorial problem is addressed? In this paper we give answers to the above questions, based on an extensive computational analysis. Our approach is to model the rank- 1 Chvátal- Gomory separation problem, which {{is known to be}} NP-hard, through a MIP model, which is then solved through a general-purpose MIP solver. As far as we know, this approach was never implemented and evaluated computationally by previous authors, though it gives a very useful separation tool for general ILP problems. We report the optimal value over the first Chvátal closure for a set of ILP problems from MIPLIB 3. 0 and 2003. We also report, for the first time, the optimal solution of a very hard instance from MIPLIB 2003, namely nsrand-ipx, obtained by using our <b>cut</b> <b>separation</b> procedure to preprocess the original ILP model. Finally, we describe a new class of ATSP facets found with the help of our separation procedure...|$|E
40|$|This work {{deals with}} a class of {{problems}} under interval data uncertainty, namely interval robust-hard problems, composed of interval data min-max regret generalizations of classical NP-hard combinatorial problems modeled as 0 - 1 integer linear programming problems. These problems are more challenging than other interval data min-max regret problems, as solely computing the cost of any feasible solution requires solving an instance of an NP-hard problem. The state-of-the-art exact algorithms in the literature {{are based on the}} generation of a possibly exponential number of cuts. As each <b>cut</b> <b>separation</b> involves the resolution of an NP-hard classical optimization problem, the size of the instances that can be solved efficiently is relatively small. To smooth this issue, we present a modeling technique for interval robust-hard problems {{in the context of a}} heuristic framework. The heuristic obtains feasible solutions by exploring dual information of a linearly relaxed model associated with the classical optimization problem counterpart. Computational experiments for interval data min-max regret versions of the restricted shortest path problem and the set covering problem show that our heuristic is able to find optimal or near-optimal solutions and also improves the primal bounds obtained by a state-of-the-art exact algorithm and a 2 -approximation procedure for interval data min-max regret problems...|$|E
40|$|Abstract In random {{geometric}} graphs, vertices are randomly distributed on [0; 1] 2 and {{pairs of}} vertices are connected by edges whenever they are sufficiently close together. Layout problems seek a linear ordering of the vertices of a graph such {{that a certain}} measure is minimized. In this paper, we study several layout problems on random geometric graphs. The layout problems that we consider are: Bandwidth, Minimum Linear Arrangement, Minimum Cut, Minimum Sum <b>Cut,</b> Vertex <b>Separation</b> and Bisection. We first prove {{that some of these}} problem remain NP-complete even for geometric graphs. Afterwards, we compute lower bounds that hold with high probability on random geometric graphs. Finally, we characterize the probabilistic behavior of the lexicographic ordering for our layout problems on the class of random geometric graphs...|$|R
40|$|In random {{geometric}} graphs, vertices are randomly distributed on [0, 1]^ 2 and {{pairs of}} vertices are connected by edges whenever they are sufficiently close together. Layout problems seek a linear ordering of the vertices of a graph such {{that a certain}} measure is minimized. In this paper, we study several layout problems on random geometric graphs: Bandwidth, Minimum Linear Arrangement, Minimum Cut, Minimum Sum <b>Cut,</b> Vertex <b>Separation</b> and Bisection. We first prove {{that some of these}} problems remain -complete even for geometric graphs. Afterwards, we compute lower bounds that hold with high probability on random geometric graphs. Finally, we characterize the probabilistic behavior of the lexicographic ordering for our layout problems on the class of random geometric graphs. Postprint (published version...|$|R
40|$|The {{epidermis}} of superficial {{human skin}} samples {{could easily be}} separated from the dermis following incubation at + 4 °C for 1 h in a solution containing 250 – 500 µg/ml thermolysin, a proteolytic enzyme hitherto mostly used for protein analysis. Light and electron microscopy revealed that the dermo-epidermal separation occurred at the basement membrane between the sites of bullous pemphigoid antigen and laminin and that the hemidesmosomes were selectively disrupted. The cohesion and morphology of the separated epidermis as well as the immunologic parameters investigated were not altered by this procedure. The clear <b>cut</b> dermo-epidermal <b>separation</b> produced by thermolysin treatment differed from the separation obtained with trypsin, which predominantly occurred between basal and suprabasal cells by disruption of desmosomes...|$|R
40|$|Multivariate {{analysis}} {{techniques in}} the study of the male genitalia of Pyrgus bellieri (Oberthür 1910) and P. alveus (Hübner 1803) (Lepidoptera: Hesperiidae) : species discrimination and distribution in the Iberian Peninsula Abstract. We used statistical multivariate analyses to study two morphologically similar species: Pyrgus bellieri and P. alveus. Ten different variables were measured in the male genitalia, and the results tested with Principal Component Analysis which showed a clear <b>cut</b> <b>separation</b> between the two species later confi rmed by Discriminant Analysis. The discerning variables were the length of cuiller and the length of uncus that are inversely proportional in the two species. The classifi cation functions for each species have been worked out resulting in the possibility to identify any individual just using some parameters in the male genitalia. The presence of P. bellieri in the Iberian Peninsula is confi rmed and 18 literature citations of the species are rejected while 13 new ones are given. The resulting distribution in the Peninsula is restricted to 32 UTM squares (10 km) in the NE, all of them in Catalonia and in the Province of Huesca (Aragón). The study highlights the validity of statistical multivariate analysis techniques, using variables taken from the male genitalia, to discriminate species with identifi cation problems...|$|E
40|$|In this paper, {{a set of}} {{efficient}} hydrocyclones {{are designed}} for ultra-fines classification using Computational Fluid Dynamics (CFD) technique. The CFD model uses Volume of Fluid multiphase model coupled with Reynolds Stress turbulence model for two phase flow predictions. Lagrangian particle-tracking method is used to predict the particle classification. Conventional cylindrical-conical design and various novel cyclone designs having a combination of multiple and small cone angles, tapered vortex finder and different body shapes are considered in this study. Simulation results are presented in terms of mean flow field, pressure drop, flow split, air core diameter, and turbulent intensity levels and particle cut diameter. Predictions show that all the tested novel designs inherently have potential for finer <b>cut</b> <b>separation</b> and higher tangential velocity compared with the conventional design. Multiphase simulations are also carried out for multiple cone angles design and standard design for 15 wt% of solids. Simulations adopted the Algebraic Slip Mixture model modified with shear lift forces and slurry rheology corrected with fines fraction. Performance by multiphase simulation shows that multiple cone angles design and modified small cone angle design are the best among the tested designs suitable for high separation efficiency, smaller cut-point and minimum coarse particle misplacement due to resultant low turbulence intensity levels. Best designs are fabricated further and tested the performance. CFD predicted efficiency curves are found {{in close agreement with}} experiments...|$|E
40|$|In this paper, {{a set of}} {{potential}} hydrocyclone designs are explored for fines classification using Computational Fluid Dynamics (CFD) technique. The CFD model uses Volume of Fluid multiphase model coupled with Reynolds Stress turbulence model for two phase flow predictions. Lagrangian Particle Tracking and Algebraic Slip Mixture model (ASM) modified with shear lift forces and slurry rheology corrected with fines fraction are used to predict the particle classification. Conventional cylindrical-conical design and various novel cyclone designs having a combination of, multiple and small cone angles, tapered vortex finder and air core free designs are considered in this study. Simulation results are presented in terms of mean and turbulent flow field along with particle efficiency' curve. Predictions show that all the tested novel designs are inherently having the potential for finer <b>cut</b> <b>separation</b> and higher tangential velocity compared to the conventional design. Cyclone design with a small cone angle is further modified by placing various sizes of rods at the center axis of the cyclone. Multiphase simulations with modified ASM model are also carried out for the multiple cone angles design, standard design, and the modified small cone angle design with full length rod at 15 wt% of solids. Performance by multiphase simulations show that multiple cone angles design and modified small cone angle design with the full length rod are the best among the tested designs yielding high separation efficiency, smaller cut-point and minimum coarse particle misplacement due to resultant turbulence minimization...|$|E
500|$|Netham Lock in east Bristol is the {{upstream}} {{limit of}} the harbour. Beyond the lock is a junction: on one arm the navigable River Avon continues upstream to Bath, {{and on the other}} arm is the tidal River Avon. The first [...] of the floating harbour, downstream from Netham Lock to Totterdown Basin, is an artificial canal known as the Feeder Canal, while the tidal River Avon follows its original route. Downstream of Totterdown Basin, the floating harbour occupies the former natural course of the River Avon, whilst the tidal River Avon flows through an artificial channel known as the New <b>Cut.</b> This <b>separation</b> of the floating harbour and the tidal River Avon allows boats in the harbour to remain floating at low tide, reduces currents and silting and prevents flooding.|$|R
50|$|High {{frequency}} screens {{have become}} more standardized and widely adopted in materials classification processes. It allows efficient <b>cuts</b> and fine <b>separations,</b> which can provide high purity and precise sizing control of the product (for sizes of fine particles up to 0.074-1.5mm). Common industrial applications include dewatering of materials, processing of powder in coal, ores and minerals, wood pelleting, fractionated reclaimed asphalt pavement, food, pharmaceutical and chemical industry. Fineness of the products and system capacities varies over a huge range between different models, to satisfy individual application requirements.|$|R
40|$|In this paper, {{we study}} the approximability of several layout {{problems}} {{on a family}} of random geometric graphs. Vertices of random geometric graphs are randomly distributed on the unit square and are connected by edges whenever they are closer than some given parameter. The layout problems that we consider are: Bandwidth, Minimum Linear Arrangement, Minimum Cut Width, Minimum Sum <b>Cut,</b> Vertex <b>Separation</b> and Edge Bisection. We first prove {{that some of these}} problems remain NP-complete even for geometric graphs. Afterwards, we compute lower bounds that hold, almost surely, for random geometric graphs. Then, we present two heuristics that, almost surely, turn to be constant approximation algorithms for our layout problems on random geometric graphs. In fact, for the Bandwidth and Vertex Separation problems, these heuristics are asymptotically optimal. Finally, we use the theoretical results in order to empirically compare these and other well-known heuristics. # This research was partially [...] ...|$|R
40|$|In {{this thesis}} I focus on cutting planes for large Mixed Integer Programming (MIP) problems. More specifically, I focus on two {{independent}} cutting planes studies. The {{first of these}} deals with cutting planes for the Traveling Salesman Problem (TSP), and the second with cutting planes for general MIPs. In the first study I introduce {{a new class of}} cutting planes which I call the Generalized Domino Parity (GDP) inequalities. My main achievements with regard to these are: (1) I show that these are valid for the TSP and for the graphical TSP. (2) I show that they generalize most well-known TSP inequalities (including combs, domino-parity constraints, clique-trees, bipartitions, paths and stars). (3) I show that a sub-class of these (which contains all clique-tree inequalities w/ a fixed number of handles) can be separated in polynomial time, on planar graphs. My second study can be subdivided in two parts. In the first of these I study the Mixed Integer Knapsack Problem (MIKP) and develop a branch-and-bound based algorithm for solving it. The novelty of the approach is that it exploits the notion of "dominance" in order to effectively prune solutions in the branch-and-bound tree. In the second part, I develop a Mixed Integer Rounding (MIR) <b>cut</b> <b>separation</b> heuristic, and embed the MIKP solver in a column generation algorithm in order to assess the performance of said heuristic. The goal {{of this study is to}} understand why no other class of inequalities derived from single-row systems has been able to outperform the MIR. Computational results are presented. Ph. D. Committee Chair: Cook, William; Committee Member: Gu, Zonghao; Committee Member: Johnson, Ellis; Committee Member: Nemhauser, George; Committee Member: Thomas, Robi...|$|E
40|$|The present thesis {{introduces}} the lock scheduling problem and promising decompositions into sub problems. Several combinatorial optimization {{methods have been}} developed for the lock scheduling problem. Single and parallel chamber locks and lock operations in both an inland and mixed-traffic setting are considered, and a mathematical model precisely describing the problem is presented. Three interrelated sub problems can be discerned: ship placement, chamber assignment and lockage operation scheduling. These are closely related to the two dimensional bin packing problem, the assignment problem and the (parallel) machine scheduling problem respectively. After an in-depth analysis the ship placement sub problem is decomposed by exploiting its sequence constraints, and both an exact and a heuristic approach are developed and tested on a large and diverse test set. A decision support tool for lock masters is presented and evaluated during live-tests at mixed-traffic locks in a major port and on an important waterway. These tests reveal that the introduction of fast and high-quality optimization software in the lock master's tool suite can increase lock efficiency by enabling a faster reaction to last-minute changes, quickly producing good solutions during peak traffic and increasing the lock's planning horizon. The lock scheduling problem is solved through Combinatorial Benders' decomposition by combining the assignment and scheduling problems into a master problem and considering ship placement as a sub problem. Efficient <b>cut</b> <b>separation</b> methods are introduced and tested and the performance of an exact and of a heuristic solution method for the packing sub problem are evaluated. Experiments show that the decomposition method outperforms a monolithic branch-and-bound approach, and that the slow convergence of the master problem is currently the decomposition method's limiting factor. nrpages: 160 status: publishe...|$|E
40|$|Background: Low-grade fibromyxoid sarcoma (LGFMS) is an {{uncommon}} neoplasm with bland morphology and an indolent clinical course, although metastases may develop in approximately 5 - 10 % of the cases. The diagnosis of LGFMS {{can be difficult}} to render from fine needle aspiration cytology (FNAC) alone because of morphological overlap with other spindle cell and myxoid lesions. Objective: To determine cytological criteria for LGFMS by reviewing FNAC aspirates in eight cases and to compare the findings with those in subsequent histological sections. Methods: FNAC slides were reviewed from eight patients with subsequently excised tumours diagnosed as LGFMS. Of these patients, six also had core needle biopsies (CNB). Cytogenetic and/or molecular analysis was carried on all tumours. Results: The patients were six men and two women ranging in age from 26 to 78 years. Tumours arose in the deep soft tissues of the thigh (n = 5), shoulder girdle (n = 1) or upper arm (n = 1) and one in the subcutaneous tissue of the abdominal wall. Cytological features included clusters of bland spindle and round/polygonal cells embedded in a collagenous and myxoid matrix along with dissociated, uniform or slightly/moderately pleomorphic spindle cells, bare nuclei and fragments of collagen and myxoid tissue in varying proportions. Unequivocal sarcoma was diagnosed in two aspirates, but mitoses were absent in all cases. In three cases, the diagnosis was inconclusive with regard to benignity or malignancy, while three were erroneously diagnosed as benign spindle cell lesions. Although the diagnosis was suggested on three of six CNB, these presented similar diagnostic problems. Conclusions: There were no cytomorphological findings in FNAC to allow for a clear <b>cut</b> <b>separation</b> of LGFMS from other spindle cell or myxoid lesions, but high-grade sarcoma could be excluded. Surgical (incisional or excisional) biopsy or, alternatively, examination of RT-PCR for the FUS/CREB 3 L or FUS/CREB 3 L 1 fusion transcripts may be necessary to obtain a correct diagnosis...|$|E
50|$|Until 1999, the {{vertical}} separation between aircraft flying at high altitudes {{on the same}} airway was 2000 ft. Since then {{there has been a}} phased introduction around the world of reduced vertical separation minimum (RVSM). This <b>cuts</b> {{the vertical}} <b>separation</b> to 1000 ft between about 29000 ft and 41,000 feet (the exact limits vary slightly from place to place). Since most jet aircraft operate between these heights, this measure effectively doubles the available airway capacity. To use RVSM, aircraft must have certified altimeters, and autopilots must meet more accurate standards.|$|R
40|$|We show two simple {{algorithms}} that, {{with high}} probability, approximate within a constant several layout problems for geometric random graphs {{drawn from the}} Gn (r) model with r = c p log n=n for any constant c 6. The layout problems that we consider are: Bandwidth, Minimum Linear Arrangement, Minimum Cut, Minimum Sum <b>Cut,</b> Vertex <b>Separation</b> and Bisection. This research was partially supported by ESPRIT LTR Project no. 20244 [...] - ALCOM-IT, CICYT Project TIC 97 - 1475 -CE, and CIRIT project 1997 SGR- 00366. y Departament de Llenguatges i Sistemes Inform`atics. Universitat Polit`ecnica de Catalunya. Campus Nord C 6. c/ Jordi Girona 1 - 3. 08034 Barcelona (Spain). fdiaz,jpetit,mjsernag@lsi. upc. es z Department of Mathematical Sciences, University of Durham, South Road, Durham DH 1 3 LE, England. Mathew. Penrose@durham. ac. uk 1 Introduction Several well-known optimization problems on graphs can be formulated as Layout Problems. Their goal {{is to find a}} layout (linear ordering) of the nodes of an [...] ...|$|R
40|$|Josep D'iaz y Mathew D. Penrose z Jordi Petit y Mar'ia Serna y April 8, 1999 Abstract In random {{geometric}} graphs, vertices are randomly distributed on [0; 1] 2 and {{pairs of}} vertices are connected by edges whenever they are sufficiently close together. Layout problems seek a linear ordering of the vertices of a graph such {{that a certain}} measure is minimized. In this paper, we study several layout problems on random geometric graphs: Bandwidth, Minimum Linear Arrangement, Minimum Cut, Minimum Sum <b>Cut,</b> Vertex <b>Separation</b> and Bisection. We first prove {{that some of these}} problems remain NP-complete even for geometric graphs. Afterwards, we compute lower bounds that hold with high probability on random geometric graphs. Finally, we characterize the probabilistic behavior of the lexicographic ordering for our layout problems on the class of random geometric graphs. This research was partially supported by ESPRIT LTR Project no. 20244 [...] - ALCOM-IT, CICYT Project TIC 97 - 1475 -CE, [...] ...|$|R
