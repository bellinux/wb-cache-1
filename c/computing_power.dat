6605|1955|Public
5|$|The two {{projects}} {{also differ}} significantly in their <b>computing</b> <b>power</b> and host diversity. Averaging about 6,650 teraFLOPS from a host base of {{central processing units}} (CPUs), graphics processing units (GPUs), and PS3s, Folding@home has nearly 108 times more <b>computing</b> <b>power</b> than Rosetta@home.|$|E
5|$|The goal of {{computer}} forensics is {{to explain the}} current state of a digital artifact; such as a computer system, storage medium or electronic document. The discipline usually covers computers, embedded systems (digital devices with rudimentary <b>computing</b> <b>power</b> and onboard memory) and static memory (such as USB pen drives).|$|E
5|$|A {{common theme}} {{throughout}} Zobel's {{work is the}} issue of impedance matching. The obvious approach to filter design is to design directly for the attenuation characteristics desired. With modern <b>computing</b> <b>power,</b> a brute force approach is possible and easy, simply incrementally adjusting each component while recalculating in an iterative process until the desired response is achieved. However, Zobel developed a more indirect line of attack. He realized very early on that mismatched impedances inevitably meant reflections, and reflections meant a loss of signal. Improving the impedance match, conversely, would automatically improve a filter's pass-band response.|$|E
50|$|The method {{works in}} every semigroup {{and is often}} used to <b>compute</b> <b>powers</b> of matrices.|$|R
5000|$|The {{same idea}} allows fast {{computation}} of large exponents modulo a number. Especially in cryptography, {{it is useful}} to <b>compute</b> <b>powers</b> in a ring of integers modulo q. It {{can also be used to}} <b>compute</b> integer <b>powers</b> in a group, using the rule ...|$|R
40|$|<b>Compute</b> {{sample size}} <b>power</b> two{{correlation}}s r 1 r 2, power(numlist) options <b>Compute</b> <b>power</b> power twocorrelations r 1 r 2, n(numlist) options Compute effect size and experimental-group correlation power twocorrelations r 1, n(numlist) power(numlist) options where r 1 is the correlation {{in the control}} (reference) group, and r 2 is the correlation in the experimental (comparison) group. r 1 and r 2 may each be specified either as one number or as a list of values in parentheses (see [U] 11. 1. 8 numlist). 1 2 power twocorrelations — Power analysis for a two-sample correlations tes...|$|R
5|$|Instead of {{an eighth}} dual-GPU video card, the single-GPU GTX 275 {{is in the}} {{computer}} because, {{out of all the}} video cards in the Fastra II, the GTX 275 is the only one the Fastra II's BIOS can fully initialize. The total amount of GPUs is 13. The video cards together bring 12 teraflops of <b>computing</b> <b>power.</b> Four of the six GTX 295 video cards have 2 PCBs, while the other two have only 1 PCB.|$|E
5|$|Page and Brin {{used the}} former's basic HTML {{programming}} skills {{to set up}} a simple search page for users, as they did not have a web page developer to create anything visually elaborate. They also began using any computer part they could find to assemble the necessary <b>computing</b> <b>power</b> to handle searches by multiple users. As their search engine grew in popularity among Stanford users, it required additional servers to process the queries. In August 1996, the initial version of Google, still on the Stanford University website, was made available to Internet users.|$|E
5|$|Another {{difference}} is that machinima is created in real time, but other animation is pre-rendered. Real-time engines need to trade quality for speed and use simpler algorithms and models. In the 2001 animated film , every strand of hair on a character's head was independent; real-time needs would likely force them {{to be treated as}} a single unit. Kelland, Morris, and Lloyd argue that improvement in consumer-grade graphics technology will allow more realism; similarly, Paul Marino connects machinima to the increasing <b>computing</b> <b>power</b> predicted by Moore's law. For cut scenes in video games, issues other than visual fidelity arise. Pre-rendered scenes can require more digital storage space, weaken suspension of disbelief through contrast with real-time animation of normal gameplay, and limit interaction.|$|E
3000|$|The {{investigation}} of the <b>computed</b> <b>power</b> figures for the Multitasking operation mode (cf. Fig. 4) reveals a maximum power consumption reduction of 81.5 % in case of instruction memory. As for the Combined setup, an increase of the mems [...]...|$|R
40|$|How do {{massive stars}} explode? Progress toward {{the answer is}} driven by {{increases}} in <b>compute</b> <b>power.</b> Petascale supercomputers are enabling detailed 3 D simulations of core-collapse supernovae that are elucidating the role of fluid instabilities, turbulence, and magnetic field amplification in supernova engines...|$|R
50|$|Though the MCC {{provided}} {{command and}} control, {{it was not}} the only facility involved in supporting Mercury or Gemini flights. The Computing and Communications Center was located at the Goddard Space Flight Center in Greenbelt Maryland and provided <b>compute</b> <b>power</b> for missions.|$|R
5|$|At first clients sent hole-punched {{accounting}} records to a Reynolds processing center, which would print a complete accounting that is {{sent back to}} the client by mail. The development of modems and internet technology in the 1970s led to several advancements. Reynolds provided 3,600 specialized modems to dealerships between 1974 and 1978. The modems communicated with Reynolds' VIM-brand minicomputers at 80 Reynolds locations, which provided <b>computing</b> <b>power</b> and printed forms. This eliminated the need for clients to ship data to Reynolds in tapes and allowed daily access to online services. By the end of the 1970s, batch processing and computer processing centers were being phased out in response to personal computers kept at the dealership. In the years 1978 and 1982, Reynolds introduced VIM-brand computer systems that were kept at dealerships.|$|E
5|$|Due to the {{complexity}} of proteins' conformation or configuration space (the set of possible shapes a protein can take), and limits in <b>computing</b> <b>power,</b> all-atom molecular dynamics simulations have been severely limited in the timescales which they can study. While most proteins typically fold in the order of milliseconds, before 2010 simulations could only reach nanosecond to microsecond timescales. General-purpose supercomputers have been used to simulate protein folding, but such systems are intrinsically costly and typically shared among many research groups. Further, because the computations in kinetic models occur serially, strong scaling of traditional molecular simulations to these architectures is exceptionally difficult. Moreover, as protein folding is a stochastic process and can statistically vary over time, it is challenging computationally to use long simulations for comprehensive views of the folding process.|$|E
5|$|From March 2007 until November 2012, Folding@home took {{advantage}} of the <b>computing</b> <b>power</b> of PlayStation 3s. At the time of its inception, its main streaming Cell processor delivered a 20x speed increase over PCs for some calculations, processing power which could not be found on other systems such as the Xbox 360. The PS3's high speed and efficiency introduced other opportunities for worthwhile optimizations according to Amdahl's law, and significantly changed the tradeoff between computing efficiency and overall accuracy, allowing the use of more complex molecular models at little added computing cost. This allowed Folding@home to run biomedical calculations that would have been otherwise infeasible computationally.|$|E
40|$|<b>Compute</b> {{sample size}} <b>power</b> one{{correlation}} r 0 ra, power(numlist) options <b>Compute</b> <b>power</b> power onecorrelation r 0 ra, n(numlist) options Compute effect size and target correlation power onecorrelation r 0, n(numlist) power(numlist) options where r 0 is the null (hypothesized) correlation or {{the value of}} the correlation under the null hypothesis, and ra is the alternative (target) correlation or {{the value of the}} correlation under the alternative hypothesis. r 0 and ra may each be specified either as one number or as a list of values in parentheses (see [U] 11. 1. 8 numlist). 1 2 power onecorrelation — Power analysis for a one-sample correlation tes...|$|R
30|$|One of {{the most}} {{powerful}} theoretical approaches to studying nanocrystals is the self-consistent calculations {{on the basis of the}} Kohn and Sham theory. For performing such calculations, a number of software packages using distributed multiprocessor <b>computing</b> <b>powered</b> by MPI and CUDA has been developed.|$|R
5000|$|CloudShare Enterprise is {{designed}} for enterprise-grade applications such as development and testing, virtual training, presales demos, proof of concepts, technical evaluations, and other IT functions. More robust and offering greater <b>compute</b> <b>power</b> and storage, as well as unlimited machines and sharing, CloudShare Enterprise also includes: ...|$|R
5|$|In March 2002, Google cofounder Sergey Brin {{launched}} Google Compute as an add-on for the Google Toolbar. Although {{limited in}} function and scope, it increased participation in Folding@home from 10,000, {{up to about}} 30,000 active CPUs. The program ended in October 2005, {{in favor of the}} official Folding@home clients, and is no longer available for the Toolbar. Folding@home also gained participants from Genome@home, another distributed computing project from the Pande lab and a sister project to Folding@home. The goal of Genome@home was protein design and associated applications. Following its official conclusion in March 2004, users were asked to donate <b>computing</b> <b>power</b> to Folding@home instead.|$|E
5|$|Research programs, {{including}} field {{projects such}} as the VORTEX projects (Verification of the Origins of Rotation in Tornadoes Experiment), deployment of TOTO (the TOtable Tornado Observatory), Doppler On Wheels (DOW), {{and dozens of other}} programs, hope to solve many questions that still plague meteorologists. Universities, government agencies such as the National Severe Storms Laboratory, private-sector meteorologists, and the National Center for Atmospheric Research are some of the organizations very active in research; with various sources of funding, both private and public, a chief entity being the National Science Foundation. The pace of research is partly constrained by the number of observations that can be taken; gaps in information about the wind, pressure, and moisture content throughout the local atmosphere; and the <b>computing</b> <b>power</b> available for simulation.|$|E
5|$|The {{first known}} game {{incorporating}} graphics that updated in real time, rather than {{only when the}} player made a move, was a pool game programmed by William Brown and Ted Lewis specifically for {{a demonstration of the}} University of Michigan-developed MIDSAC computer at the University of Michigan in 1954. The game, developed over six months by the pair, featured a pool stick controlled by a joystick and a knob, and a full rack of 15 balls on a table seen in an overhead view. The computer calculated the movements of the balls as they collided and moved around the table, disappearing when they reached a pocket, and updated the graphics continuously, forty times a second, so as to show real-time motion. Like previous video games, the pool game was intended primarily to showcase the <b>computing</b> <b>power</b> of the MIDSAC computer.|$|E
40|$|The {{results of}} an {{investigation}} of the effects of far field boundary conditions on the solution of the three dimensional Euler equations governing the flow field of a high speed single rotation propeller are presented. The results show that the solutions obtained with the nonreflecting boundary conditions are in good agreement with experimental data. The specification of nonreflecting boundary conditions is effective in reducing the dependence of the solution on the location of the far field boundary. Details of the flow field within the blade passage and the tip vortex are presented. The dependence of the <b>computed</b> <b>power</b> coefficient on the blade passage and the tip vortex are presented. The dependence of the <b>computed</b> <b>power</b> coefficient on the blade setting angle is examined...|$|R
30|$|<b>Compute</b> the LP <b>power</b> {{spectrum}} for {{the same}} number of frequency points as used for <b>computing</b> the MVDR <b>power</b> spectrum.|$|R
40|$|Abstract. We {{exhibit a}} {{numerical}} method to compute three-point branched covers {{of the complex}} projective line. We develop algorithms for working explicitly with Fuchsian triangle groups and their finite index subgroups, and we use these algorithms to <b>compute</b> <b>power</b> series expansions of modular forms on these groups...|$|R
5|$|Drugs {{function}} by binding {{to specific}} locations on target molecules and causing some desired change, such as disabling a target or causing a conformational change. Ideally, a drug should act very specifically, and bind only to its target without interfering with other biological functions. However, {{it is difficult}} to precisely determine where and how tightly two molecules will bind. Due to limits in <b>computing</b> <b>power,</b> current in silico methods usually must trade speed for accuracy; e.g., use rapid protein docking methods instead of computationally costly free energy calculations. Folding@home's computing performance allows researchers to use both methods, and evaluate their efficiency and reliability. Computer-assisted drug design has the potential to expedite and lower the costs of drug discovery. In 2010, Folding@home used MSMs and free energy calculations to predict the native state of the villin protein to within 1.8 angstrom (Å) root mean square deviation (RMSD) from the crystalline structure experimentally determined through X-ray crystallography. This accuracy has implications to future protein structure prediction methods, including for intrinsically unstructured proteins. Scientists have used Folding@home to research drug resistance by studying vancomycin, an antibiotic drug of last resort, and beta-lactamase, a protein that can break down antibiotics like penicillin.|$|E
5|$|During the 1950s, various {{computer}} games {{were created in}} the context of academic computer and programming research and for demonstrations of <b>computing</b> <b>power,</b> especially after the introduction later in the decade of smaller and faster computers on which programs could be created and run in real time as opposed to being executed in batches. A few programs, however, while used to showcase the power of the computer they ran on were also intended as entertainment products; these were generally created by undergraduate and graduate students and university employees, such as at the Massachusetts Institute of Technology (MIT) where they were allowed on occasion to develop programs for the TX-0 experimental computer. These interactive graphical games were created by a community of programmers, many of them students and university employees affiliated with the Tech Model Railroad Club (TMRC) led by Alan Kotok, Peter Samson, and Bob Saunders. The games included Tic-Tac-Toe, which used a light pen to play a simple game of noughts and crosses against the computer, and Mouse in the Maze, which used a light pen to set up a maze of walls for a virtual mouse to traverse.|$|E
5|$|Life with PlayStation was a Folding@home {{application}} {{available for}} PlayStation 3 which connected to Stanford University’s Folding@home distributed computer network {{and allowed the}} user to donate their console's spare processing cycles to the project. Folding@home is supported by Stanford University and volunteers {{make a contribution to}} society by donating <b>computing</b> <b>power</b> to this project. Research made by the project may eventually contribute to the creation of vital cures. The Folding@home client was developed by Sony Computer Entertainment in collaboration with Stanford University. Life with PlayStation also consisted of a 3D virtual view of the Earth and contained current weather and news information of various cities and countries from around the world, as well as a World Heritage channel which offered information about historical sites, and the United Village channel which is a project designed to share information about communities and cultures worldwide. As of PlayStation 3 system software update version 4.30 on October 24, 2012, the Life With PlayStation project has ended.|$|E
40|$|Shortest path {{algorithms}} {{are required}} by several transportation applications; furthermore, the shortest path computation in these applications can account for {{a large percentage of}} the total execution time. Since these algorithms are very computationally intense, parallel processing can provide the <b>compute</b> <b>power</b> and memory required to solve large problems quickly...|$|R
50|$|The first Mac-compatible (clone) PC {{shipped in}} May 1995. Like Dell Computer, <b>Power</b> <b>Computing</b> {{followed}} a direct, build-to-order sales model. In one year, <b>Power</b> <b>Computing</b> shipped 100,000 units with revenues of $250 {{million in the}} first year. <b>Power</b> <b>Computing</b> was the first company to sell $1,000,000 of products on the internet.|$|R
40|$|<b>Compute</b> {{sample size}} <b>power</b> pairedmeans ma 1 ma 2, corrspec power(numlist) options <b>Compute</b> <b>power</b> power pairedmeans ma 1 ma 2, corrspec n(numlist) options Compute effect size and target mean {{difference}} power pairedmeans ma 1, corrspec n(numlist) power(numlist) options where corrspec {{is one of}} sddiff() corr() sd() corr() sd 1 () sd 2 () ma 1 is the alternative pretreatment mean or the pretreatment mean under the alternative hypothesis, and ma 2 is the alternative posttreatment mean or {{the value of the}} posttreatment mean under the alternative hypothesis. ma 1 and ma 2 may each be specified either as one number or as a list of values in parentheses (see [U] 11. 1. 8 numlist). 1 2 power pairedmeans — Power analysis for a two-sample paired-means tes...|$|R
5|$|Tennis for Two is {{considered}} under some definitions {{to be the}} first video game. Other candidates with stronger candidacies from a technological standpoint include the 1947 cathode-ray tube amusement device, the earliest known interactive electronic game, though it did not run on a computing device; the 1950 Bertie the Brain, the earliest known game to run on a computer, though it used light bulbs for a display; and OXO and a draughts game by Christopher Strachey in 1952, the earliest digital computer games to display visuals on an electronic screen. Tennis for Two, though it contained no technological developments to separate it from earlier games, has the distinction of being the earliest known computer game with visuals created purely for entertainment purposes. Prior games were created primarily for academic research purposes or to demonstrate the <b>computing</b> <b>power</b> of the underlying machine, {{with the exception of the}} non-computer based cathode-ray tube amusement device. This, therefore, makes Tennis for Two the first video game under some definitions from a philosophical viewpoint rather than a technical one and a distinctive moment in the early history of video games.|$|E
25|$|If {{neuroscience}} is the bottleneck on brain emulation {{rather than}} <b>computing</b> <b>power,</b> emulation advances {{may be more}} erratic and unpredictable based on when new scientific discoveries happen. Limited <b>computing</b> <b>power</b> would mean the first emulations would run slower and so {{would be easier to}} adapt to, and there would be more time for the technology to transition through society.|$|E
25|$|The {{next great}} advance in <b>computing</b> <b>power</b> {{came with the}} advent of the {{integrated}} circuit.|$|E
5000|$|AP Computer Science Principles is an {{introductory}} course to computer science, [...] "with {{a focus on}} how <b>computing</b> <b>powers</b> the world". It is designed as a parallel to AP Computer Science A, to emphasize computational thinking and fluency. It {{is meant to be}} the equivalent of a first-semester course in computer science.|$|R
40|$|We {{exhibit a}} {{numerical}} method to compute three-point branched covers {{of the complex}} projective line. We develop algorithms for working explicitly with Fuchsian triangle groups and their finite index subgroups, and we use these algorithms to <b>compute</b> <b>power</b> series expansions of modular forms on these groups. Comment: 58 pages, 24 figures; referee's comments incorporate...|$|R
40|$|Computation (IAMC) {{framework}} aims {{to make it}} easy {{to supply}} mathematical <b>computing</b> <b>powers</b> over the Internet/Web. The Mathematical Computation Protocol (MCP), the core part in the IAMC framework, enables developers to create interoperable clients and servers easily and independently. Presented are the specification of MCP, and the design and implementation of our Java based MCP protocol library (JMCP) ...|$|R
