1|348|Public
40|$|Practical {{applications}} of controlled-source electromagnetic modeling require solutions for multiple sources at several frequencies, thus {{leading to a}} dramatic increase of the computational cost. In this paper we present an approach using block Krylov subspace solvers that are iterative methods especially designed for problems with multiple right hand-sides. Their main advantage is the shared subspace for approximate solutions, hence, these methods are expected to converge in less iterations than the corresponding standard solver applied to each linear system. Block solvers also share the same preconditioner, which is constructed only once. Simultaneously <b>computed</b> <b>block</b> operations have better utilization of cache due to the less frequent access to the system matrix. In this paper we implement two different block solvers for sparse matrices resulting from the finitedifference and the finite-element discretizations, discuss the computational cost of the algorithms and study their dependence {{on the number of}} right-hand sides given at once. The effectiveness of the proposed methods is demonstrated on two electromagnetic survey scenarios, including a large marine model. As the results of the simulations show, when a powerful preconditioning is employed, block methods are faster than standard iterative techniques in terms of both iterations and time. Funding for this work was provided by the Repsol-BSC Research Center and the RISE Horizon 2020 European Project GEAGAM (644602). MareNostrum Supercomputer was used for the numerical tests. The authors express their thanks to Rene-Edouard Plessix, Mikhail Zaslavsky and one anonymous reviewer for their valuable comments that significantly helped to improve the paper. Peer ReviewedPostprint (author's final draft...|$|E
40|$|One of {{the unique}} {{features}} of the REPORT procedure is the <b>Compute</b> <b>Block.</b> This PROC step tool allows the use of most DATA step statements, logic, and functions, and {{through the use of}} the <b>compute</b> <b>block</b> you can modify existing columns, create new columns, write text, and more! This provides the SAS programmer a level of control and flexibility that is unavailable in virtually all other procedures. Along with this flexibility comes complexity and this complexity often thwarts us as we try to write increasingly interesting <b>compute</b> <b>blocks.</b> The complexity of the <b>compute</b> <b>block</b> includes a number of column identification and timing issues that can confound the PROC REPORT user. Of course to make matters even more interesting, there can be multiple <b>compute</b> <b>blocks</b> that can interact with each other and these can execute for different portions of the report table. This tutorial will discuss the essential elements of the <b>compute</b> <b>block,</b> its relationship to the processing phases, and how it interacts with temporary variables and other <b>compute</b> <b>blocks.</b> We will discuss timing issues and naming conventions through a series of examples...|$|R
40|$|One of {{the unique}} {{features}} of the REPORT procedure is the <b>Compute</b> <b>Block.</b> Unlike most other SAS procedures, PROC REPORT {{has the ability to}} modify values within a column, to insert lines of text into the report, to create columns, and to control the content of a column. Through <b>compute</b> <b>blocks</b> it is possible to use a number of SAS language elements, many of which can otherwise only be used in the DATA step. While powerful, the <b>compute</b> <b>block</b> can also be complex and potentially confusing. This tutorial introduces basic <b>compute</b> <b>block</b> concepts, statements, and usages. It discusses a few of the issues that tend to cause folks consternation when firs...|$|R
40|$|In the <b>compute</b> <b>block</b> of the PROC REPORT step {{variables}} {{can be both}} {{created and}} used. They {{may be on the}} incoming data table, they may be computed in the REPORT step, they can be statistical summaries, and they may even be artificially created by the REPORT process. In the DATA step each variable has a name and that variable’s name is used whenever we want to address a particular value on the Program Data Vector. In the REPORT step things are not so simple. The origins and use of a variable will determine how it is to be named in a <b>compute</b> <b>block.</b> If you {{do not know how to}} properly address a variable or report item in the <b>compute</b> <b>block,</b> the <b>compute</b> <b>block</b> will often fail. This paper will discuss the various variable types, how they are used, and how they are addressed in the <b>compute</b> <b>block.</b> Once introduced the rules are fairly easy, and a full understanding of the naming conventions and how they are applied- “use what name when”, will go a long way to allowing you to create more complex and successful <b>compute</b> <b>blocks</b> in PROC REPORT...|$|R
30|$|The first {{implementation}} strategy {{is about the}} allocation of the GPU computing resources. According to the GPU compute unified device architecture (CUDA) programming principles, the GPU CUDA programming model consists of three programming hierarchy levels, i.e., GPU compute grid, GPU <b>compute</b> <b>block,</b> and GPU <b>compute</b> thread. At the top level of the programming hierarchy, all the algorithm computations are executed within one GPU compute grid. Meanwhile, at the second level of the programming hierarchy, the program tasks are allocated into a set of GPU <b>compute</b> <b>blocks.</b> The computation in different GPU <b>compute</b> <b>blocks</b> can be executed in parallel. Besides, at the third level of the programming hierarchy, the computational workloads are assigned {{to a series of}} GPU compute threads. The programs in different GPU compute threads are executed simultaneously, while the program instructions within one GPU compute thread are executed sequentially.|$|R
40|$|The authors {{present a}} novel {{architecture}} for implementing general-purpose fuzzy chips which allows fully-parallel rule processing employing a reduced number of mixed-signal <b>computing</b> <b>blocks</b> and minimum-sized digital memories. The resulting fuzzy processor can interact directly with continuous sensors and actuators {{and the subsequent}} digital processing system...|$|R
5000|$|If {{a shorter}} process arrives during another process' execution, the {{currently}} running process is interrupted (known as preemption), dividing that process into two separate <b>computing</b> <b>blocks.</b> This creates excess overhead through additional context switching. The scheduler must also place each incoming process into a specific {{place in the}} queue, creating additional overhead.|$|R
40|$|El pdf del artículo es la versión post-print. The authors {{present a}} novel {{architecture}} for implementing general-purpose fuzzy chips which allows fully-parallel rule processing employing a reduced number of mixed-signal <b>computing</b> <b>blocks</b> and minimum-sized digital memories. The resulting fuzzy processor can interact directly with continuous sensors and actuators {{and the subsequent}} digital processing system. Peer Reviewe...|$|R
25|$|With the {{development}} of very-large-scale integration (VLSI) technology, Yannis Tsividis' group at Columbia University has been revisiting analog/hybrid computers design in standard CMOS process. Two VLSI chips have been developed, an 80th-order analog computer (250nm) by Glenn Cowan in 2005 and an 4th-order hybrid computer (65nm) developed by Ning Guo in 2015, both targeting at energy-efficient ODE/PDE applications. Glenn's chip contains 16 macros, {{in which there are}} 25 analog <b>computing</b> <b>blocks,</b> namely integrators, multipliers, fanouts, few nonlinear blocks. Ning's chip contains one macro block, in which there are 26 <b>computing</b> <b>blocks</b> including integrators, multipliers, fanouts, ADCs, SRAMs and DACs. Arbitrary nonlinear function generation is made possible by the ADC+SRAM+DAC chain, where the SRAM block stores the nonlinear function data. The experiments from the related publications revealed that VLSI analog/hybrid computers demonstrated about 1–2 orders magnitude of advantage in both solution time and energy while achieving accuracy within 5%, which points to the promise of using analog/hybrid computing techniques in the area of energy-efficient approximate computing.|$|R
30|$|The {{computing}} speed {{evaluation of}} the MV adaptive beamforming algorithm implementation comprised (a) the giga floating-point operations per second (GFLOPS), (b) the output image frame rate of the algorithm implementation, and (c) the computational speedup of the embedded GPU implementation over its ARM processor counterpart. The algorithm computing speed evaluation was conducted on Jetson TX 1 heterogeneous embedded development board. The evaluation test cases included various M and L combinations. While doing the evaluation tests, the value of M was first determined, which was chosen as 16, 32, 64, and 128, respectively. Then, the value of L was chosen from 1 to M/ 2. Therefore, there were 8 M and L combinations when M is 16, 16 M and L combinations when M is 32, 32 M and L combinations when M is 64, and 64 M and L combinations when M is 128. In the experiments, {{as the number of}} image pixels, 127 × 1000 pixels for one image, did not change during the tests, the number of the GPU <b>compute</b> <b>blocks</b> were not changed in the experiments. But the number of the GPU compute threads, a.k.a. GPU <b>compute</b> thread <b>block</b> size, was varying during the experiments. The algorithm computing speed of various GPU <b>compute</b> thread <b>block</b> size was tested so as to find the value of the GPU <b>compute</b> thread <b>block</b> size in the best practices. The GPU <b>compute</b> thread <b>block</b> size test cases covered the numbers from 32 to 1024 which were multiples of 32.|$|R
5000|$|HP Cloud Monitoring {{delivers}} fundamental <b>compute</b> and <b>block</b> storage metrics, providing visibility into resource utilization, application performance, {{and operational}} health.|$|R
40|$|Radio {{astronomy}} observatories {{with high}} throughput back end instruments require real-time data processing. While computing hardware continues to advance rapidly, development of real-time processing pipelines remains difficult and time-consuming, which can limit scientific productivity. Motivated by this, {{we have developed}} Bifrost: an open-source software framework for rapid pipeline development. Bifrost combines a high-level Python interface with highly efficient reconfigurable data transport and a library of <b>computing</b> <b>blocks</b> for CPU and GPU processing. The framework is generalizable, but initially it emphasizes the needs of high-throughput radio astronomy pipelines, {{such as the ability}} to process data buffers as if they were continuous streams, the capacity to partition processing into distinct data sequences (e. g., separate observations), and the ability to extract specific intervals from buffered data. <b>Computing</b> <b>blocks</b> in the library are designed for applications such as interferometry, pulsar dedispersion and timing, and transient search pipelines. We describe the design and implementation of the Bifrost framework and demonstrate its use as the backbone in the correlation and beamforming back end of the Long Wavelength Array station in the Sevilleta National Wildlife Refuge, NM. Comment: 25 pages, 13 figures, submitted to JAI. For the code, see [URL]...|$|R
40|$|Relay {{deployment}} in Orthogonal Frequency Division Multiple Access (OFDMA) based cellular networks {{helps in}} coverage extension and or capacity improvement. In OFDMA system, each user requires different number of subcarriers {{to meet its}} rate requirement. This resource requirement depends on the Signal to Interference Ratio (SIR) experienced by a user. Traditional methods to <b>compute</b> <b>blocking</b> probability cannot be used in relay based cellular OFDMA networks. In this paper, we present an approach to <b>compute</b> the <b>blocking</b> probability of such networks. We determine {{an expression of the}} probability distribution of the users resource requirement based on its experienced SIR and then classify the users into various classes depending upon their subcarrier requirement. We consider the system to be a multidimensional system with different classes and evaluate the blocking probability of system using the multi-dimensional Erlang loss formulas. Comment: 33 pages, 10 figure...|$|R
40|$|Recent {{years have}} seen the {{evolution}} of networks of tiny low power <b>computing</b> <b>blocks,</b> known as sensor networks. In one class of sensor networks a non-expert user, who {{has little or no}} experience with electronics or programming, is required to select, connect and/or configure one or more blocks such that the <b>blocks</b> <b>compute</b> a particular Boolean logic function of sensor values. We describe a series of experiments showing that non-expert users have much difficulty with a block based on Boolean logic truth tables, and that a logic block having a sentence-like structure with some configurable switches yields a better success rate. We also show that adding color to a truth table improves results over a traditional truth table. Author Keywords Sensor networks, Boolean logic, embedded computin...|$|R
40|$|Tyt. z nagłówka. Bibliogr. s. 473 - 474. The paper {{presents}} the results of investigations concerning the possibility of using programm able logic devices (FPGA) to build virtual multi-core processors dedicated specifically towards particular applications. The paper shows the designed architecture of a multi-core processor specialized to perform a particular task, and it discusses its computational efficiency depending on the number of cores used. An evaluation of the results is also discussed. Dostępny również w formie drukowanej. KEYWORDS: microprocessor, FPGA, parallel <b>computing,</b> <b>block</b> cipher...|$|R
40|$|Abstract The paper {{deals with}} the vector control systems of the {{induction}} motor supplied from the failed and non-failed tandem converter. There are described the research results regarding the reconfiguration aspects of the control strategy for {{the transition from a}} control structure to another. Simulation results are presented for both control system topologies. Implementation of the general <b>computing</b> <b>block</b> in the Configurable Logic Cells ® of the Triscend’s Configurable System on Chip ® is presented together with the results of the path delay analyses. I...|$|R
40|$|Golub and Meurant {{have shown}} {{how to use}} the {{symmetric}} block Lanczos algorithm to <b>compute</b> <b>block</b> Gauss quadrature rules for the approximation of certain matrix functions. We describe new block quadrature rules that can be computed by the symmetric or nonsymmetric block Lanczos algorithms and yield higher accuracy than standard block Gauss rules after the same number of steps of the symmetric or nonsymmetric block Lanczos algorithms. The new rules are block generalizations of the generalized averaged Gauss rules introduced by Spalevi´c. Applications to network analysis are presente...|$|R
30|$|The {{memory access}} {{strategy}} of GPU implementation {{has an important}} impact on the overall GPU computational speed. There are basically three types of memory modules inside the GPU, i.e., global memory, shared memory, and register files. The lifetime of the data in the three memory types is associated to the GPU computing resources respectively. The lifetime of the data in the global memory is associated to the GPU compute grid, the lifetime of the data in the shared memory is associated to the GPU <b>compute</b> <b>block,</b> and the lifetime of the data in the register files is associated to the GPU compute thread.|$|R
40|$|Quality of Service (QoS) {{optimisation}} of converged networks {{has become}} an absolute necessity for mobile communication businesses to deliver business differentiation in a saturated market. In this paper, we present a resource allocation scheme for 3 G wireless systems that optimises QoS control by exploiting multi-component nature of multimedia applications. We build a Markovian model of our Multi-Component Resource Allocation Scheme (MCRAS) and analyse its performance by computing steady-state probability distributions. We <b>compute</b> <b>blocking</b> probability – the key QoS parameter – for different system configurations using MCRAS and make comparisons with Complete Partitioning (CP) and Complete Sharing (CSH) resource allocation schemes...|$|R
40|$|In this work, a Euclidean {{distance}} calculator is presented. The circuit comprises {{of simple}} <b>computing</b> <b>blocks,</b> their basic element being the floating gate MOSFET (FGMOS), exploiting {{the merits of}} this device in designing circuits with low-voltage and rail-to-rail operation. Therefore the overall circuit has the characteristics of modularity, low-voltage and rail-to-rail operation under a single supply voltage, accuracy and simplicity. The circuitis des#it 8 with 2 MIETEC CMOS technology and {{is used in the}} simulation of a hand-written digit recognition system using the nearest neighbour classification method. The simulation results presented, demonstrate the functionality of the circuit...|$|R
40|$|A fast control wrapper for a micropipeline with {{two-phase}} {{control is}} presented. The wrapper is implemented in an Artisan 0. 13 µ commercial standard library {{that has not}} been augmented with any special cells for asynchronous design. The wrapper is approximately 25 % faster than a more traditional approach that uses a Muller C-element. Introduction: Micropipelines [1] use control logic wrapped around <b>compute</b> <b>blocks</b> to implement asynchronous systems. Micropipelines have been used to implement significant designs, including complex microprocessors [2]. Four-phase control [3] means that the control lines between micropipeline stages undergo a low-to-high-to-low transition for each data movement between stages; while two-phase control implies either a single low-to-high or high-lo...|$|R
40|$|Hierarchical {{temporal}} memory (HTM) {{tries to}} mimic the computing in cerebral-neocortex. It identifies spatial and temporal patterns in the input for making inferences. This may require large number of computationally expensive tasks like, dot-product evaluations. Nano-devices that can provide direct mapping for such primitives are of great interest. In this work we show that the <b>computing</b> <b>blocks</b> for HTM can be mapped using low-voltage, fast-switching, magneto-metallic spin-neurons combined with emerging resistive cross-bar network (RCN). Results show possibility of more than 200 x lower energy as compared to 45 nm CMOS ASIC designComment: this work was submitted to IEEE Transactions on Neural Networks and Learning Systems. It is under review no...|$|R
40|$|Graver {{test sets}} for linear {{two-stage}} stochastic integer programs are studied. It is shown that test sets can be decomposed into finitely many building blocks whose number {{is independent of}} the number of scenarios of the sochastic program. A finite algorithm to <b>compute</b> the building <b>blocks</b> directly, without prior knowledge of test set vectors, is presented. Once <b>computed,</b> building <b>blocks</b> can be employed to solve the stochastic program by a simple augmentation scheme, again without explicit knowledge of test set vectors. Preliminary computational experience is reported...|$|R
40|$|We study Graver {{test sets}} for linear {{two-stage}} stochastic integer programs {{and show that}} test sets can be decomposed into finitely many building blocks whose number is independent {{on the number of}} scenarios of the stochastic program. We present a finite algorithm to <b>compute</b> the building <b>blocks</b> directly, without prior knowledge of test set vectors. Once <b>computed,</b> building <b>blocks</b> can be employed to solve the stochastic program by a simple augmentation scheme, again without explicit knowledge of test set vectors. Finally, we report preliminary computational experience...|$|R
30|$|The {{effect of}} {{different}} inter-view prediction directions on the coding efficiency of mixed spatial-resolution stereoscopic video coding is discussed. At low bitrates, mixed spatial-resolution stereoscopic video coding provides superior coding efficiency, when using full spatial-resolution frames rather than low spatial-resolution frames {{in the base}} view. This implies that full spatial-resolution and low spatial-resolution frames should use different reference frame selection and reference frame ordering processes. A comparison of different decimation and interpolation methods showed that the high-performance methods {{reduce the amount of}} time needed for both processes through filtering fewer samples than the conventional methods. The high-performance methods for decimation and interpolation were therefore used when <b>computing</b> <b>block</b> matching statistics and in the comparisons reported in Section 5.|$|R
40|$|A {{two-phase}} control wrapper for a micropipeline is presented. The wrapper {{is implemented}} in an Artisan 0. 13 µ standard cell library {{that has not}} been augmented with any special cells for asynchronous design. The wrapper supports early evaluation allowing the output to be updated after a subset of the inputs have arrived, thus improving the throughput of the micropipeline. Introduction: Micropipelines [1] use control logic wrapped around <b>compute</b> <b>blocks</b> to implement asynchronous systems. Micropipelines have been used to implement significant designs, including complex microprocessors [2]. Four-phase control [3] means that the control lines between micropipeline stages undergo a low-to-high-to-low transition for each data movement between stages; while two-phase control implies either a single low-to-high or high-lo...|$|R
40|$|Abstract — Many DSP, {{image and}} video {{processing}} applications use Finite Impulse Response (FIR) filters as basic <b>computing</b> <b>blocks.</b> Our paper introduces an efficient dynamically reconfigurable FIR {{system that can}} adapt the number of filter coefficients, and their values, in real time. Here, dynamic reconfiguration is used to switch between different, pre-computed, fixed-point realizations of different digital filters. Our platform relies {{on the use of}} Distributed Arithmetic blocks, mapped to the specific LUTs of the underlying FPGA. Dynamic reconfiguration of the coefficients is limited to changing a small number of relevant LUT contents, while leaving the rest of the architecture intact. We investigate the dynamic system throughput {{as a function of the}} dynamic reconfiguration rate...|$|R
40|$|International audienceWe analyze {{transient}} and stationary {{behaviors of}} multidimensional Markov chains defined on large state spaces. In this paper, we apply stochastic comparisons on partially ordered state {{which could be}} very interesting for performance evaluation of computer networks. We propose an algorithm for bounding aggregations in order to derive upper and lower performance measure bounds on a reduced state space. We study different queueing networks with rejection in order to <b>compute</b> <b>blocking</b> probability and end to end mean delay bounds. Parametric aggregation schemes are studied in order to propose an attractive solution: given a performance measure threshold, we vary the parameter values to obtain a trade-off between the accuracy of bounds and the computation complexity...|$|R
40|$|Abstract—There exist many {{recurrent}} {{neural networks}} for solving optimization-related problems. In this paper, {{we present a}} method for deriving such networks from existing ones by changing connections be-tween <b>computing</b> <b>blocks.</b> Although the dynamic systems may become much different, some distinguished properties may be retained. One example is discussed to solve variational inequalities and related optimization problems with mixed linear and nonlinear constraints. A new network is obtained from two classical models by this means, and its performance is comparable to its predecessors. Thus, an alternative choice for circuits implementation is offered to accomplish such computing tasks. Index Terms—Asymptotic stability, global convergence, linear program-ming (LP), optimization, quadratic programming (QP), recurrent neural network (RNN), variational inequality. I...|$|R
40|$|AbstractA {{polynomial}} time algorithm is presented for the founding question of Galois theory: determining solvability by radicals of a monic irreducible polynomial over the integers. Also a {{polynomial time}} algorithm which expresses a root in radicals {{in terms of a}} straightline program is given. Polynomial time algorithms are demonstrated for <b>computing</b> <b>blocks</b> of imprimitivity of roots of the polynomial under the action of the Galois group, and for computing intersections of algebraic number fields. In all of the algorithms it is assumed that the number field is given by a primitive element which generates it over the rationals, that the polynomial in question is monic, and that its coefficients are in the integers...|$|R
40|$|AbstractWe analyze {{transient}} and stationary {{behaviors of}} multidimensional Markov chains defined on large state spaces. In this paper, we apply stochastic comparisons on partially ordered state {{which could be}} very interesting for performance evaluation of computer networks. We propose an algorithm for bounding aggregations in order to derive upper and lower performance measure bounds on a reduced state space. We study different queueing networks with rejection in order to <b>compute</b> <b>blocking</b> probability and end to end mean delay bounds. Parametric aggregation schemes are studied in order to propose an attractive solution: given a performance measure threshold, we vary the parameter values to obtain a trade-off between the accuracy of bounds and the computation complexity...|$|R
40|$|The {{process control}} system {{described}} in this paper, is a very flexible system equipped {{with a range of}} computer-aided configuration tools. These are tools for the configuration and reconfiguration of control loops, <b>computing</b> <b>blocks,</b> logic control modules, i/o connections or graphics, and presentation elements such as reports, trend curves, flowsheets, free graphical pictures etc., while the system is operational and in control. Documentation of system topology, system parametrization and the i/o configuration/connection etc., can be extracted from the system at any time. The system can also be configured for training and simulation applications as well as for process control. The paper describes the system hardware architecture, the distributed database and the configuration and operation tools...|$|R
3000|$|... [...]. To {{compute the}} birth rates in (7), {{we need to}} solve the {{handover}} rate Equations (11). To <b>compute</b> the <b>blocking</b> and dropping probabilities for connection requests from new and handover users of service s, the following iterative fixed-point algorithm[15] is used.|$|R
40|$|Relay {{deployment}} in orthogonal {{frequency division}} multiple access (OFDMA) based cellular networks helps in coverage extension and/or capacity improvement. To quantify capacity improvement, blocking probability of voice call is typically calculated using Erlang B formula. This calculation {{is based on the}} assumption that all users require same amount of resources to satisfy their rate requirement. However, in an OFDMA system, each user requires different number of subcarriers to meet its rate requirement. This resource requirement depends on the signal to interference ratio (SIR) experienced by a user. Therefore, the Erlang B formula can not be employed to <b>compute</b> <b>blocking</b> probability in an OFDMA network. In this paper, we determine an analytical expression to <b>compute</b> the <b>blocking</b> probability in a relay based cellular OFDMA network. We determine an expression of the probability distribution of the user's resource requirement based on its experienced SIR. Then, we classify the users into various classes depending upon their subcarrier requirement. We consider the system to be a multi-dimensional system with different classes and evaluate the blocking probability using the multi-dimensional Erlang loss formulas. This model is useful in the performance evaluation, design, planning of resources and call admission control in a relay based cellular OFDMA networks like long term evolution...|$|R
3000|$|The basic {{implementation}} of the ZMSSD function <b>block</b> <b>computes</b> {{the means of the}} pixel values in a window m [...]...|$|R
40|$|A new {{lower bound}} {{algorithm}} for real and mixed µ problems is presented. The basic {{idea of this}} algorithm {{is to use a}} related worst-case gain problem to <b>compute</b> the real <b>blocks</b> and, if the block structure is mixed, the standard power iteration to <b>compute</b> the complex <b>blocks.</b> Numerical tests indicate that the algorithm is fast and provides good lower bounds for both real and mixed µ problems of small to moderate size...|$|R
