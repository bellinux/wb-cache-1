9|157|Public
50|$|By the Principle of Duality in a {{projective}} plane, {{the dual}} of each {{point is a}} line, and the dual of a locus of points (a set of points satisfying some condition) is called an envelope of lines. Using Steiner's definition of a conic (this locus of points will now {{be referred to as}} a point conic) as the meet of <b>corresponding</b> <b>rays</b> of two related pencils, it is easy to dualize and obtain the corresponding envelope consisting of the joins of corresponding points of two related ranges (points on a line) on different bases (the lines the points are on). Such an envelope is called a line conic (or dual conic). In the real projective plane, a point conic has the property that every line meets it in two points (which may coincide, or may be complex) and any set of points with this property is a point conic. It follows dually that a line conic has two of its lines through every point and any envelope of lines with this property is a line conic. At every point of a point conic there is a unique tangent line, and dually, on every line of a line conic there is a unique point called a point of contact. An important theorem states that the tangent lines of a point conic form a line conic, and dually, the points of contact of a line conic form a point conic.|$|E
50|$|A {{parallel}} beam {{is described as}} a group of straight and parallel 'rays'.The rays cross through the transparent medium while potentially interacting with the contained acoustic field, and finally reach the focusing element.Note that the principle of a focusing element is directing (i.e. focusing) rays that are parallel - into a single point on the focal plane of the element. Thus, the population of rays crossing the focal plane of the focusing element can be divided into two groups: those that interacted with the acoustic field and those that didn't. The latter group is undisturbed by the acoustic field, so it remains parallel and forms a point in a well-defined position in the focal plane. The optical stop is positioned exactly at that point, so as to prevent all <b>corresponding</b> <b>rays</b> from further propagating through the system and to the camera.Thus we get rid of the portion of light that crossed the acoustic field without interaction.However, there are also rays that did interact with the acoustic field in the following manner:If a ray travels through a region of nonuniform density whose spatial gradient has a component orthogonal to the ray, that ray is deflected from its original orientation, as if it were passing through a prism. This ray is no longer parallel, so it doesn't intersect {{the focal point of the}} focusing element and is not blocked by the knife. In some circumstances the deflected ray escapes the knife-blade and reaches the camera to create a point-like image on the camera-sensor, with a position and intensity related to the inhomogeneity experienced by the ray. An image is formed in this way, exclusively by rays that interacted with the acoustic field, providing a mapping of the acoustic field.|$|E
40|$|A more {{rigorous}} algorithm is presented for correction of refraction effects in two-media stereo photogrammetry. The mid-point of the shortest line segment joining two aerial <b>corresponding</b> <b>rays</b> {{of a point}} on an underwater object {{is used as a}} photogrammetric intersection point which doesn't exist when the two rays are non-intersecting. As a result, the uncertainty of the intersection point is removed, the positional relationship between the intersection point and the true object point becomes definite, and the refraction correction formula from the intersection point to the true object point can be strictly derived. The bad effect on the refraction correction is firstly analyzed, which caused by that the two rays are non-intersecting. Then the positional relationship between the intersection point and the true object point is studied. After that, the formulas regarding water depth and geodetic coordinates of points on an underwater object are deduced, that is often known as correction of refraction effects. Finally, the algorithm is tested by two experiments using the data of WorldView- 2. The results show that the algorithm is suitable for any case in which whether or not the two aerial <b>corresponding</b> <b>rays</b> of an underwater object point are intersecting, and it can significantly improve the measurement accuracy of underwater object's elevation...|$|E
5000|$|... is {{the impact}} parameter. Each {{incoming}} light ray can be backtraced to a <b>corresponding</b> <b>ray</b> at infinity. The Impact parameter for the incoming light ray is {{the distance between the}} <b>corresponding</b> <b>ray</b> at infinity and a ray parallel to it that plunges directly into the black hole.|$|R
5000|$|Weber {{introduced}} ray class {{groups in}} 1897. Takagi proved {{the existence of}} the <b>corresponding</b> <b>ray</b> class fields in about 1920. Chevalley reformulated the definition of ray class groups in terms of ideals in 1933.|$|R
5000|$|In optics, {{the optical}} sine theorem {{states that the}} {{products}} of the index, height, and sine of the slope angle of a ray in object space and its <b>corresponding</b> <b>ray</b> in image space are equal. That is: ...|$|R
40|$|Central {{catadioptric}} {{cameras are}} cameras which combine lenses and mirrors {{to capture a}} very wide field of view with a central projection. In this paper we extend the classical epipolar geometry of perspective cameras to all central catadioptric cameras. Epipolar geometry is formulated as the geometry of <b>corresponding</b> <b>rays</b> in a three-dimensional space. Using the model of image formation of central catadioptric cameras, the constraint on corresponding image points is then derived. It is shown that the corresponding points lie on epipolar conics. In addition, {{the shape of the}} conics for all types of central catadioptric cameras is classified. Finally, the theory is verified by experiments with real central catadioptric cameras...|$|E
40|$|AbstractWe {{study the}} {{weighted}} Fermat–Torricelli problem for tetrahedra in R 3 and solve an “inverse” problem by introducing {{a method of}} differentiation. The solution of the inverse problem is the main result which states that: Given the Fermat–Torricelli point A 0 with the vertices lie on four prescribed rays, find the ratios between every pair of non-negative weights of two <b>corresponding</b> <b>rays</b> such that {{the sum of the}} four non-negative weights is a constant number. An application of the inverse weighted Fermat–Torricelli problem is the strong invariance principle of the weighted Fermat–Torricelli point which gives some classes of tetrahedra that could be named “evolutionary tetrahedra”...|$|E
40|$|This paper {{demonstrates}} that, for axial non-central optical systems, {{the equation}} of a 3 D line can be estimated using only four points extracted from a single image of the line. This result, which is {{a direct consequence of}} the lack of vantage point, follows from a classic result in enumerative geometry: there are exactly two lines in 3 -space which intersect four given lines in general position. We present a simple algorithm to reconstruct {{the equation of}} a 3 D line from four image points. This algorithm is based on computing the Singular Value Decomposition (SVD) of the matrix of Plücker coordinates of the four <b>corresponding</b> <b>rays.</b> We evaluate the conditions for which the reconstruction fails, such as when the four rays are nearly coplanar. Preliminary experimental results using a spherical catadioptric camera are presented. We conclude by discussing the limitations imposed by poor calibration and numerical errors on the proposed reconstruction algorithm. ...|$|E
40|$|We {{report the}} direct {{observation}} of lasing action from a dynamically localized mode in a microdisk resonator with rough boundary. In contrast to microlasers based on stable ray trajectories, {{the performance of}} our device is robust {{with respect to the}} boundary roughness and <b>corresponding</b> <b>ray</b> chaos, taking advantage of Anderson localization in angular momentum. The resonator design, although demonstrated here in GaAs-InAs microdisk laser, should be applicable to any lasers and sensors based on semiconductor or polymer materials...|$|R
50|$|A ray class {{field of}} K is the abelian {{extension}} of K associated to a ray class group by class field theory, and its Galois group is isomorphic to the <b>corresponding</b> <b>ray</b> class group. The proof of {{existence of a}} ray class field of a given ray class group is long and indirect and there is in general no known easy way to construct it (though explicit constructions are known in some special cases such as imaginary quadratic fields).|$|R
3000|$|... {{where the}} first {{summation}} corresponds to the clusters and the second <b>corresponds</b> to <b>rays</b> within the clusters. The complex attenuation factor for the [...]...|$|R
40|$|Abstract: Before {{corresponding}} {{points in}} images taken with two cameras {{can be used}} to recover distances to objects in a scene, one has to determine the position and orientation of one camera relative to the other. This is the classic photogrammetric problem of relative orientation, central to the interpretation of binocular stereo information. Iterative methods for determining relative orientation were developed long ago; without them we would not have most of the topographic maps we do today. Relative orientation is also of importance in the recovery of motion and shape from an image sequence when successive frames are widely separated in time. Workers in motion vision are rediscovering some of the methods of photogrammetry. Described here is a simple iterative scheme for recovering relative orientation that, unlike existing methods, does not require a good initial guess for the baseline and the rotation. The data required is a pair of bundles of <b>corresponding</b> <b>rays</b> from the two projection centers to points in the scene. It is well known that at least five pairs of rays are needed. Less appears to be known about the existence of multiple solutions and their interpretation. These issues are discussed here. The unambiguous determination of all of the parameters of relative orientation is not possible when the observed points lie on a critical surface. These surfaces and their degenerate forms are analysed as well...|$|E
40|$|Fast {{estimation}} of point-source parameters for earthquakes has progressed much {{in recent years}} due {{to the development of}} broadband seismic networks. The expansion of these networks now provides the opportunity to investigate second-order effects such as source finiteness for regional and local events on a routine basis. This potential motivates the development of methods to quickly generate synthetic seismograms for finite sources. This is possible when the fault dimension is small compared to the source-receiver distance and when the structure around the source region is relatively simple. To study the directivity for a finite source, we discretize the fault region into a set of elements represented as point sources. We then generate the generalized rays for the best-fitting point-source location and derive for each separate ray the response for neighboring point sources using power series expansions. The response for a finite fault is then a summation over rays and elements. If we sum over elements first, we obtain an effective far-field source-time function for each ray, which is sensitive to the direction of rupture. These far-field source-time functions are convolved with the <b>corresponding</b> <b>rays,</b> and the results are summed to form the total response. A simple application of the above method is demonstrated with the tangential motions observed from the 1991 Sierra Madre earthquake. For this event, we constrain the fault dimension to be about 3 km with rupture toward the west, which is compatible with other more detailed studies...|$|E
40|$|Before {{corresponding}} {{points in}} images taken with two cameras {{can be used}} to recover distances to objects in a scene, one has to determine the position and orientation of one camera relative to the other. This is the classic photogrammetric problem of relative orientation, central to the interpretation of binocular stereo information. Iterative methods for determining relative orientation were developed long ago; without them we would not have most of the topographic maps we do today. Relative orientation is also of importance in the recovery of motion and shape from an image sequence when successive frames are widely separated in time. Workers in motion vision are rediscovering some of the methods of photogrammetry. Described here is a simple iterative scheme for recovering relative orientation that, unlike existing methods, does not require a good initial guess for the baseline and the rotation. The data required is a pair of bundles of <b>corresponding</b> <b>rays</b> from the two projection centers to points in the scene. It is well known that at least five pairs of rays are needed. Less appears to be known about the existence of multiple solutions and their interpretation. These issues are discussed here. The unambiguous determination of all of the parameters of relative orientation is not possible when the observed points lie on a critical surface. These surfaces and their degenerate forms are analyzed as well. (See also "Relative Orientation Revisited,'' Journal of the Optical Society of America, A, October 1991, Vol. 8, pp. 1630 [...] 1638.) ...|$|E
40|$|We have {{investigated}} quasi-eigenmodes of a quadrupolar deformed microcavity by extensive numerical calculations. The spectral structure {{is found to}} be quite regular, which can be explained {{on the basis of the}} fact that the microcavity is an open system. The far-field emission directions of the modes show unexpected similarity irrespective of their distinct shapes in phase space. This universal directionality is ascribed to the influence from the geometry of the unstable manifolds in the <b>corresponding</b> <b>ray</b> dynamics. Comment: 10 pages 11 figure...|$|R
40|$|We {{propose to}} render {{geometry}} using an image based representation. Geometric information is encoded by a texture with depth and rendered by rasterizing the bounding box geometry. For each resulting fragment, a shader computes {{the intersection of}} the <b>corresponding</b> <b>ray</b> with the geometry using pre-computed information to accelerate the computation. Our method is almost always artifact free even when zoomed in or at grazing angles. We integrate our algorithm with reverse perspective projection to represent a larger class of shapes. The extra texture requirement is small and the rendering cost is output sensitive, so our representation can be used to model many parts of a 3 D scene...|$|R
40|$|Waves {{traveling}} through weakly random media {{are known to}} be strongly affected by their <b>corresponding</b> <b>ray</b> dynamics, in particular in forming linear freak waves. The ray intensity distribution, which, e. g., quantifies the probability of freak waves is unknown, however, and a theory of how it is approached in an appropriate semiclassical limit of wave mechanics is lacking. We show that this limit is not the usual limit of small wavelengths, but that of decoherence. Our theory, which can describe the intensity distribution for an arbitrary degree of coherence is relevant {{to a wide range of}} physical systems, as decoherence is omnipresent in real systems...|$|R
30|$|With the {{projection}} matrix P {{it is possible}} to backproject any 2 D point to a 3 D projection ray. If this is done on both cameras, the intersection of the <b>corresponding</b> projection <b>rays</b> will represent the reconstructed 3 D position.|$|R
5000|$|Given a {{quadratic}} map {{from the}} complex plane to itself and a repelling or parabolic periodic orbit [...] of , so that [...] (where subscripts are taken 1 + modulo [...] ), let [...] be {{the set of}} angles whose <b>corresponding</b> external <b>rays</b> land at [...]|$|R
3000|$|... (same point, same direction), but a whole {{collection}} of <b>rays</b> <b>corresponding</b> to the horizontal segment {{that connects the}} source line [...]...|$|R
40|$|I {{begin with}} the {{argument}} that continuous archival of personal experience requires certain criteria to be met. In particular, for continuous usage, {{it is essential that}} each ray of light entering the eye be collinear with a <b>corresponding</b> <b>ray</b> of light entering the device, in at least one mode of operation. This is called the EyeTap criterion, and devices meeting this criterion are called EyeTap devices. Secondly, I outline Mediated Reality as a necessary framework for continuous archival and retrieval of personal experience. Thirdly, I show some examples of personalized experience capture (i. e. visual art). Finally, I outline the social issues of such devices, in particular, the accidentally discovered inverse to surveillance that I call “sosuveillance”. It is argued that an equilibrium between surveillance and sousveillance is implicit in the archival of personal experiences...|$|R
40|$|Wave {{scattering}} in chaotic {{systems can}} be characterized by its spectrum of resonances, z_n=E_n-iΓ_n/ 2, where E_n {{is related to the}} energy and Γ_n is the decay rate or width of the resonance. If the <b>corresponding</b> <b>ray</b> dynamics is chaotic, a gap is believed to develop in the large-energy limit: almost all Γ_n become larger than some γ. However, rare cases with Γ<γ may be present and actually dominate scattering events. We consider the statistical properties of these super-sharp resonances. We find that their number does not follow the fractal Weyl law conjectured for the bulk of the spectrum. We also test, for a simple model, the universal predictions of random matrix theory for density of states inside the gap and the hereby derived probability distribution of gap size...|$|R
40|$|The hypermetric cone {{is defined}} as the cone of semimetrics {{satisfying}} the hypermetric inequalities. Every Delaunay polytope <b>corresponds</b> to a <b>ray</b> of this polyhedral cone. The Delaunay polytopes, which <b>correspond</b> to extreme <b>rays</b> are called extreme. We use this polyhedral cone and the closest vector problem to present a new technique that allow to find, from a given extreme Delaunay polytope, some new ones. Then, we show some examples of applications of this technique in low-dimensions. Comment: 7 page...|$|R
40|$|We {{show that}} {{relative}} earthquake location using double-difference methods requires an accurate {{knowledge of the}} velocity structure throughout the study region to prevent artifacts in the relative position of hypocenters. The velocity structure determines the ray paths between hypocenters and receivers. These ray paths, and the <b>corresponding</b> <b>ray</b> take-off angles at the hypocenters, determine the partial derivatives of travel time {{with respect to the}} hypocentral coordinates which form the inversion kernel that maps double-differences into hypocentral perturbations. Thus the large-scale velocity structure enters into the core of the double-difference technique. By employing a 1 D layered model with sharp interfaces to perform double-difference inversion of synthetic data generated using a simple, 1 D gradient model; we show that inappropriate choice of the velocity model, combined with unbalanced source-receiver distributions, can lead to significant distortion and bias in the relative hypocenter positions of closely spaced events...|$|R
40|$|Plenoptic {{cameras are}} gaining {{attention}} for their unique light gathering and post-capture processing capabilities. We describe a decoding, calibration and rectification pro-cedure for lenselet-based plenoptic cameras {{appropriate for a}} range of computer vision applications. We derive a novel physically based 4 D intrinsic matrix relating each recorded pixel to its <b>corresponding</b> <b>ray</b> in 3 D space. We further propose a radial distortion model and a practical objec-tive function based on ray reprojection. Our 15 -parameter camera model is of much lower dimensionality than cam-era array models, and more closely represents the physics of lenselet-based cameras. Results include calibration of a commercially available camera using three calibration grid sizes over five datasets. Typical RMS ray reprojection er-rors are 0. 0628, 0. 105 and 0. 363 mm for 3. 61, 7. 22 and 35. 1 mm calibration grids, respectively. Rectification ex-amples include calibration targets and real-world imagery. 1...|$|R
3000|$|... and the {{vertical}} direction with {{the vertical}} direction of the spherical image. Exploiting each projection matrix, we can associate to each final image pixel its <b>corresponding</b> viewing <b>ray,</b> and from this the pixel's corresponding coordinates in the original spherical image. These correspondences are used to perform a bilinear interpolation of the spherical image to recover each single finally rectified image (see Figure 4).|$|R
25|$|To canonically {{quantize}} Chern–Simons theory one {{defines a}} state on each 2-dimensional surface Σ in M. As in any quantum field theory, the states <b>correspond</b> to <b>rays</b> in a Hilbert space. There is no preferred notion {{of time in}} a Schwarz-type topological field theory and so one can require that Σ be a Cauchy surface, in fact, a state can be defined on any surface.|$|R
40|$|A {{model is}} {{proposed}} {{for the study of}} the statistical properties of the impedance (Z) and scattering (S) matrices of open electromagnetic cavities with several transmission lines or waveguides connected to the cavity. The model is based on assumed properties of the eigenfunctions for the closed cavity. Analysis of the model successfully reproduces features of the random matrix model believed to be universal, while at the same time incorporating features which are specific to individual systems. Universal statistical properties of the cavity impedance Z are obtained in terms of the radiation impedance. These universal properties are independent of system-specific details and shared by the members of the general class of systems whose <b>corresponding</b> <b>ray</b> trajectories are chaotic. In the single channel case, I obtained the normalized impedance and scatter-ing coefficients whose probability density functions (PDF) are predicted to be universal. In the multiple-channel case, I focused on correlations in the phases of the eigenvalues of the S-matrix, and derived a formula for the averaged reflection coefficients in terms of the port radiation impedance. Effects of time-reversa...|$|R
40|$|Ray casting may {{be applied}} to the terrain {{rendering}} from DTMs (Digital Terrain Models). In this paper we propose a ray casting method which exploits exact vertical ray coherence. This method not only achieves a good performance, but also allows any set of viewing parameters. To analyze vertical ray coherence property, we define the terms: a ray plane which is perpendicular to the sea-level plane and passes through the COP (center of projection); and the <b>corresponding</b> <b>ray</b> line which is the line of intersection of the ray plane and the projection plane. Vertical ray coherence can be stated as: if two rays pass through the same ray line, they pass over the identical set of points on the DTM base plane. After a ray is cast on the DTM, we can get a good starting point to cast another ray using this property. Our method tries to cover the projection plane with ray lines. Since ray lines are not parallel to each other, it is a difficult task to cover the entire plane. In fact all ray lines in [...] ...|$|R
40|$|Rays {{represent}} {{the direction of}} wave-front propagation. Therefore, rays point {{in the direction of}} the wave-front surface normal and can be calculated as the wave-front gradient. The “transverse ray aberration ” (TRA) is the distance, orthogonal to the optical axis, between a paraxial <b>ray</b> and its <b>corresponding</b> real <b>ray</b> (i. e., the transverse distance between ideal and real ray locations). The TRA can be calculated as a derivative of the wave front: TRA(y) =...|$|R
40|$|It is {{demonstrated}} that the ballistic quantum transport properties of an open quantum dot may be described by an ensemble of spatially correlated virtual classical particles moving within self-avoiding strings. The string paths <b>correspond</b> to <b>ray</b> trajectories. The strings exhibit the necessary properties of self-avoidance, interference and the non-local condition ∮mv · dr=nh. The formalism suggests that numerical simulation of quantum flows may be constructed ab initio by using the string representation...|$|R
50|$|Note {{that this}} {{argument}} could be shortened using {{the fact that}} two Busemann functions hγ and hδ differ by a constant if and only if the <b>corresponding</b> geodesic <b>rays</b> satisfy supt ≥ 0 d(γ(t),δ(t)) < ∞. Indeed, all the geodesics defined by the flow αt satisfy the latter condition, so differ by constants. Since along any of these geodesics h is linear with derivative 1, h must differ from these Busemann functions by constants.|$|R
50|$|His legacy lived on, however. Ryan Choi, {{a student}} of Physics in Hong Kong that <b>corresponded</b> with <b>Ray</b> Palmer via mail in the past, found {{a copy of his}} costume and {{shrinking}} device to become the current Atom. Around this same time, an unnamed teenager with powers similar to Palmer joins the Teen Titans under the name Molecule. After a brief tenure with the team, he is later killed during a confrontation with the Terror Titans.|$|R
40|$|The limacon-shaped {{semiconductor}} microcavity is a ray-chaotic cavity sustaining low-loss modes with mostly unidirectional emission patterns. Investigating these modes systematically, we {{show that}} the modes <b>correspond</b> to <b>ray</b> description collectively, rather than individually. In addition, we present experimental data on multimode lasing emission patterns that show high unidirectionality and closely agree with the ray description. The origin of this agreement is well explained by the collective correspondence mechanism. Comment: 4 pages, 4 figures, to appear in PR...|$|R
30|$|Ultrasonic {{velocity}} {{measurements were}} performed using the pulse reflection technique with buffer rod. To generate elastic waves, sinusoidal electric burst signals were produced by an arbitrary waveform generator (Tektronix AWG 2021, Beaverton, OR, USA) {{and applied to}} the LiNbO 3 piezoelectric transducer (10 ° Y-cut). The elastic waves of 8 MHz were transmitted through the buffer rod and the sample. The sample length was more than ten times longer than the wavelength of the elastic waves. Reflected elastic waves from {{the top and bottom}} surfaces of the sample were received by the transducer and then converted into an electric signal. The waveforms were recorded using a digital oscilloscope (Hewlett-Packard 54825 A, Palo Alto, CA, USA). These signals were sampled 4, 096 times for each run at a sample rate of 1.0 [*]×[*] 109 samples/s for a given P-T condition. We used the mean value of the recorded travel time for a given P-T condition and <b>corresponding</b> <b>ray</b> path to compute the average velocity. The maximum uncertainty in the measured V p values was ± 0.4 %. This procedure is described in more detail elsewhere (Kono et al. 2004).|$|R
