14|697|Public
2500|$|If {{the signal}} is {{inverted}} {{on its way}} round the control loop, the system {{is said to have}} negative feedback; otherwise, the feedback is said to be positive. Negative feedback is often deliberately introduced to increase the stability and accuracy of a system by correcting or reducing the influence of unwanted changes. [...] This scheme can fail if the input changes faster than the system can respond to it. [...] When this happens, the lag in arrival of the <b>correcting</b> <b>signal</b> can result in overcorrection, causing the output to oscillate or [...] "hunt". While often an unwanted consequence of system behaviour, this effect is used deliberately in electronic oscillators.|$|E
5000|$|Satellite {{navigation}} systems, {{such as the}} American Global Positioning System (GPS). LNAV and LNAV/VNAV approaches require Receiver autonomous integrity monitoring (RAIM) which detects {{problems with}} GPS satellites. LPV (Localiser Performance with Vertical guidance) and LP (without vertical guidance) do not require RAIM since they utilise SBAS <b>correcting</b> <b>signal</b> like Wide Area Augmentation System (WAAS) or European Geostationary Navigation Overlay Service (EGNOS).|$|E
5000|$|If {{the signal}} is {{inverted}} {{on its way}} round the control loop, the system {{is said to have}} negative feedback; otherwise, the feedback is said to be positive. Negative feedback is often deliberately introduced to increase the stability and accuracy of a system by correcting or reducing the influence of unwanted changes. This scheme can fail if the input changes faster than the system can respond to it. When this happens, the lag in arrival of the <b>correcting</b> <b>signal</b> can result in overcorrection, causing the output to oscillate or [...] "hunt". While often an unwanted consequence of system behaviour, this effect is used deliberately in electronic oscillators.|$|E
5000|$|... #Subtitle level 3: Insulating <b>correct</b> <b>signaling</b> {{proteins}} from inactivation ...|$|R
50|$|Scaffold {{proteins}} act in {{at least}} four ways: tethering signaling components, localizing these components to specific areas of the cell, regulating signal transduction by coordinating positive and negative feedback <b>signals,</b> and insulating <b>correct</b> <b>signaling</b> proteins from competing proteins.|$|R
5000|$|Maintenance of {{expressive}} control {{refers to}} the need to stay 'in character'. The performance has to make sure that s/he sends out the <b>correct</b> <b>signals</b> and quiets the occasional compulsion to convey misleading ones that might detract from the performance.|$|R
40|$|The {{invention}} relates on a sigma delta {{digital to analog}} converter, digitally sequenced by a clock, comprising a {{main line}} and a feedback line, the main line comprising: an input port, a linear filter G(z) and a multibit quantifier, a digital to analog converter, an output port, and the feedback line comprising a correcting memory table, able to process a <b>correcting</b> <b>signal,</b> and an adder able to subtract said <b>correcting</b> <b>signal</b> from an input signal, wherein the correcting memory table time cycle is k {{times greater than the}} clock time cycle...|$|E
40|$|An {{improved}} {{system and}} method for modulation, demodulation and signal processing for single sideband communications systems which provides correction for {{the adverse effects}} of rapid fading characteristics in a mobile environment. The system provides modulation through a modified Weaver modulator in which the audio input is processed to produce an output {{in the form of}} an upper sideband having a pilot tone in a spectral gap at approximately midband. The receiver includes a modified Weaver demodulator and a correction signal generating circuit which processes the received faded audio input and pilot tone to produce a <b>correcting</b> <b>signal.</b> The <b>correcting</b> <b>signal</b> is mixed with the received signal to regenerate unfaded versions of both the signal and pilot by removing random amplitude and phase modulations imposed on them by the fading...|$|E
40|$|Abstract: A {{trajectory}} {{tracking control}} for a wheeled mobile robot using fuzzy logic controller (FLC) {{is presented in}} this paper. The control algorithm based on the errors in postures of mobile robot which feed FLC, which generates correction signals for {{the left and right}} motor speeds. The control strategy is based on a feed forward velocity profile and the <b>correcting</b> <b>signal</b> in the velocity generated from the FLC according to the postures errors. Simulation and experimental results demonstrate the effectiveness of the proposed algorithm, which proved the good tracking results and showed the robustness of the algorithm against the uncertainties in the system model. Key-words:- velocity profile-trajectory tracking-postures control-fuzzy logic control-and low-level control system...|$|E
50|$|Some cards {{incorrectly}} have dual notches, {{and some}} motherboards incorrectly have fully open slots, allowing a card to be plugged {{into a slot}} that {{does not support the}} <b>correct</b> <b>signaling</b> voltage, which may damage card or motherboard. Some incorrectly designed older 3.3 V cards have the 1.5 V key.|$|R
40|$|The SABRINA-X {{receiver}} {{designed for}} bistatic operation with TerraSAR-X class satellites is described. The main performance {{parameters of the}} receiver shown its adequacy for near-range bistatic acquisitions using simple rectangular horn antennas. First results are presented showing the <b>correct</b> <b>signal</b> envelope and a first bistatic Ter-raSAR-X image acquired over Barcelona...|$|R
40|$|Two {{different}} carrier frequencies modulated by {{a reference}} frequency are transmitted to each receiver to be synchronized therewith. Each receiver responds to local phase {{differences between the}} two received <b>signals</b> to <b>correct</b> the phase of one of them so as to maintain the <b>corrected</b> <b>signal</b> as a reliable synchronization reference...|$|R
40|$|Transverse {{feedback}} {{systems for}} controlling the vertical coupled-bunch instabilities in the positron and electron main rings are installed at DAFNE. They {{started to be}} operative respectively from June and September 2000. For the horizontal plane, similar systems have been installed in summer 2001 with less kicker power. Design specifications and the basic system concepts are presented. Real time bunch-by-bunch offset correction is implemented using digital signal processors and dual-port RAM's. Fast analog to digital sampling is performed at the maximum bunch frequency (368 MHz). The system manages at full speed a continuous flow of 8 -bits data {{and it has the}} capability to invert the sign or put to zero the output for any combination of bunches. A conversion from digital to analog produces the output <b>correcting</b> <b>signal.</b> Comment: 3 pages, 5 figures, 2 tables, submitted at ICALEPCS 2001, psn# WEAP 04...|$|E
40|$|Abstract—This study investigates {{snowfall}} detectability and snowfall rate estimation with NASA’s CloudSat {{through the}} first evaluation of its newly released 2 C-SNOW-PROFILE products using the National Mosaic and Multisensor QPE System (NMQ) snowfall products. The primary {{focus is on the}} detection and estimation of surface snowfall. The results show that the CloudSat product has good detectability of light snow (snow water equivalent less than 1 mm/h) but degrades in moderate and heavy snow (heavier than 1 mm/h). The analysis suggests that the new 2 C-SNOW-PROFILE algorithm is insufficient in <b>correcting</b> <b>signal</b> losses due to attenuation. Its underestimation is well correlated to snowfall intensity. Issues of sensitivity and data sampling with ground radars, which may affect the interpretation of the results, are also discussed. This evaluation of the new 2 C-SNOW-PROFILE algorithm provides guidance for applications of the product and identifies particular error sources that can be addressed in future versions of the CloudSat snowfall algorithm. 1...|$|E
40|$|Driving {{simulators}} {{have become}} useful research tools {{for the institution}} and laboratories which are studying in different fields of vehicular and transport design to increase road safety. Although classical washout filters are broadly used because of their short processing time, simplicity and ease of adjust, they have some disadvantages such as generation of wrong sensation of motions, false cue motions, and also their tuning process which {{is focused on the}} worst case situations leading to a poor usage of the workspace. The aim {{of this study is to}} propose a new motion cueing algorithm that can accurately transform vehicle specific force into simulator platform motions at high fidelity within the simulator’s physical limitations. This method is proposed to compensate wrong cueing motion caused by saturation of tilt coordination rate limit using an adaptive <b>correcting</b> <b>signal</b> based on added fuzzy logic into translational channel to minimize the human sensation error and exploit the platform more efficiently...|$|E
50|$|Assistive {{technology}} {{is the creation of}} a new device that assists a person in completing a task that would otherwise be impossible. Some examples include new computer software programs like screen readers, and inventions such as assistive listening devices, including hearing aids, and traffic lights with a standard color code that enables colorblind individuals to understand the <b>correct</b> <b>signal.</b>|$|R
5000|$|... <b>correcting</b> market <b>signals</b> to the {{consumer}} by incorporating waste management costs into the product’s price; ...|$|R
50|$|To ensure more uniform color reproduction, {{receivers}} {{started to}} incorporate color correction circuits that converted the received signal — encoded for the colorimetric values listed above — into signals encoded for the phosphors actually used within the monitor. Since such color correction {{can not be}} performed accurately on the nonlinear gamma <b>corrected</b> <b>signals</b> transmitted, the adjustment can only be approximated, introducing both hue and luminance errors for highly saturated colors.|$|R
40|$|Hormones, like Insulin play a {{major part}} in the control of blood glucose level. The {{increase}} in insulin secretion accelerates cellular utilization of glucose, which in turn decreases the blood glucose level. The response of any system can be controlled either by changing the input or by changing the system parameters i. e the system transfer function. Neither of these two cases is feasible in biological system. In biological system, <b>correcting</b> <b>signal</b> may be applied for obtaining the desired performance of the system without disturbing the normal system input. This technique named as “Signal Correction Technique (SCT) ” is feasible for application in biological system for achieving desired response. The Signal Correction Technique (SCT) may be applicable to control the secretion of insulin for reducing the level of blood sugar. This paper deals with the control of blood sugar level by the application of additional high frequency signals at the pancreas. Here pancreas stimulation means the application of high frequency signal. This signal acts as a triggering input to activate a protein cell which is responsible to release insulin from pancreas...|$|E
40|$|A living {{system as}} a whole runs well, as various {{parametric}} values related in the system lie within specific ranges. Whenever there is some disorder, the parametric value(s) get deteriorated, so that the related system or subsystem does not offer proper response, as it should be for well functioning. As a measure to cure, medicinalor other sort of management may be administered externally to improve the deficiency. Medicinal management again functions by the application of equivalent signal at some point (node) of the living system. Curing by the application electrical/ mechanical/ chemical/ or else how is in process for remedy from various sorts of ailments. Again for any control system, the response of the system is simply the system transfer function multiplied by the system input, input being applicable at a single point or at a number of points. In biological system, to realize the appropriate performance of the systems, an additional signal named as “Correcting Signal” is requiredwithout disturbing the system parameters. The regulation regarding movement of eye pupil aperture of human being is exemplified in the present work. The light intensity of the ambience in addition to its normal value acts here as a <b>correcting</b> <b>signal</b> to regulate the aperture of pupil...|$|E
40|$|Abstract Background DNA microarrays {{provide an}} {{efficient}} method for measuring activity of genes in parallel and even covering all the known transcripts of an organism {{on a single}} array. This has to be balanced against that analyzing data emerging from microarrays involves several consecutive steps, {{and each of them}} is a potential source of errors. Errors tend to accumulate when moving from the lower level towards the higher level analyses because of the sequential nature. Eliminating such errors does not seem feasible without completely changing the technologies, but one should nevertheless try to meet the goal of being able to realistically assess degree of the uncertainties that are involved when drawing the final conclusions from such analyses. Results We present a Bayesian hierarchical model for finding differentially expressed genes between two experimental conditions, proposing an integrated statistical approach where <b>correcting</b> <b>signal</b> saturation, systematic array effects, dye effects, and finding differentially expressed genes, are all modeled jointly. The integration allows all these components, and also the associated errors, to be considered simultaneously. The inference is based on full posterior distribution of gene expression indices and on quantities derived from them rather than on point estimates. The model was applied and tested on two different datasets. Conclusions The method presents a way of integrating various steps of microarray analysis into a single joint analysis, and thereby enables extracting information on differential expression in a manner, which properly accounts for various sources of potential error in the process. </p...|$|E
5000|$|With {{the advent}} of {{digitally}} based displays, some modern spectrum analyzers use analog-to-digital converters to sample spectrum amplitude after the VBW filter. Since displays have a discrete number of points, the frequency span measured is also digitised. Detectors are used {{in an attempt to}} adequately map the <b>correct</b> <b>signal</b> power to the appropriate frequency point on the display. There are in general three types of detectors: sample, peak, and average ...|$|R
40|$|A {{near-field}} direct antenna modulation (NFDAM) transmitter at 2. 4 GHz {{is demonstrated}} on a microstrip setting. The transmitter {{is capable of}} transmitting information in a direction-dependent fashion by sending the <b>correct</b> <b>signal</b> constellation only in the desired direction while leaving the signal constellation points scrambled in undesired directions. This direction-dependent constellation scrambling nature of the NFDAM systems prevents undesired receivers to correctly demodulate the signal transmitted to a desired receiver at a specific direction...|$|R
3000|$|... {{represents}} the model complexity. Note that the MCS {{and the new}} LMCS methods are both under the Bayesian framework, which enables their integration with the statistical MDL technique. Compared with the DP-MCS technique that utilizes variational Bayes (VB) inference and could suffer from local convergence, the newly proposed MDL-MCS and MDL-LMCS methods offer improved <b>correct</b> <b>signal</b> classification rate and better signal reconstruction performance. This is also illustrated via computer simulations in Section 5.|$|R
40|$|High {{precision}} positioning {{and time}} transfer {{are required by}} {{a large number of}} scientific applications: seismic ground deformations, sea level monitoring or land survey applications require sub-centimeter precision in kinematic position; monitoring of stable atomic frequency standards requires an increasing sub –nanosecond precision. Differential GNSS is presently the best tool to reach such precisions, as it removes the majority of the errors affecting the GNSS signals. However, the associated need for dense GNSS observation networks is not fulfilled for many locations (e. g. Pacific, Africa). An alternative is to use Precise Point Positioning (PPP), but this technique requires <b>correcting</b> <b>signal</b> delays at the highest level of precision, including high order ionospheric effects. It is thus essential to accurately characterize the higher order ionospheric terms (I 2 +), i. e. I 2, I 3, I 4, geometric bending and differential STEC bending, which is the goal of this paper. For that, we used a network of well-distributed GPS stations, and the Bernese v 5. 0 software. We have focused our attention in the I 2 + terms, studying two approaches: A) Combining independent and simultaneous measurements of the same transmitter-receiver pair at three (or more) different frequencies, in order to remove the I 2 term: it is theoretically possible to cancel out both I 1 and I 2 similarly as it is done typically in precise dual-frequency GNSS measurements for I 1. It is shown that, as expected, due to the proximity of the corresponding frequencies in L-band, the high noise of the combinations makes this approach unpractical to either isolate or remove I 2. B) Modelling the I 2 + terms, in function of estimates of electron content, geomagnetic field and electron density values. Their characterization has been done in a realistic and full-control environment, by using the last version of the International Reference Ionosphere model (IRI 2012) and International Geomagnetic Reference Model in its 11 th version (IGRF 11). Two metrics have been considered to assess the importance of the different higher order ionospheric corrections and their approximations: a) At the signal level, or range level, directly provided by the corresponding slant delays. b) At the geodetic domain level, provided by the impact of such values in the different geodetic parameters estimated consistently (i. e. simultaneously) from a global GNSS network. JRC. G. 5 -Security technology assessmen...|$|E
40|$|The digital {{electronic}} market development {{is founded on}} the continuous reduction of the transistors size, to reduce area, power, cost and increase the computational performance of integrated circuits. This trend, known as technology scaling, is approaching the nanometer size. The lithographic process in the manufacturing stage is increasing its uncertainty with the scaling down of the transistors size, resulting in a larger parameter variation in future technology generations. Furthermore, the exponential relationship between the leakage current and the threshold voltage, is limiting the threshold and supply voltages scaling, increasing the power density and creating local thermal issues, such as hot spots, thermal runaway and thermal cycles. In addiction, {{the introduction of new}} materials and the smaller devices dimension are reducing transistors robustness, that combined with high temperature and frequently thermal cycles, are speeding up wear out processes. Those effects are no longer addressable only at the process level. Consequently the deep sub-micron devices will require solutions which will imply several design levels, as system and logic, and new approaches called Design For Manufacturability (DFM) and Design For Reliability. The purpose of the above approaches is to bring in the early design stages the awareness of the device reliability and manufacturability, in order to introduce logic and system able to cope with the yield and reliability loss. The ITRS roadmap suggests the following research steps to integrate the design for manufacturability and reliability in the standard CAD automated design flow: i) The implementation of new analysis algorithms able to predict the system thermal behavior with the impact to the power and speed performances. ii) High level wear out models able to predict the mean time to failure of the system (MTTF). iii) Statistical performance analysis able to predict the impact of the process variation, both random and systematic. The new analysis tools have to be developed beside new logic and system strategies to cope with the future challenges, as for instance: i) Thermal management strategy that increase the reliability and life time of the devices acting to some tunable parameter,such as supply voltage or body bias. ii) Error detection logic able to interact with compensation techniques as Adaptive Supply Voltage ASV, Adaptive Body Bias ABB and error recovering, in order to increase yield and reliability. iii) architectures that are fundamentally resistant to variability, including locally asynchronous designs, redundancy, and error <b>correcting</b> <b>signal</b> encodings (ECC). The literature already features works addressing the prediction of the MTTF, papers focusing on thermal management in the general purpose chip, and publications on statistical performance analysis. In my Phd research activity, I investigated the need for thermal management in future embedded low-power Network On Chip (NoC) devices. I developed a thermal analysis library, that has been integrated in a NoC cycle accurate simulator and in a FPGA based NoC simulator. The results have shown that an accurate layout distribution can avoid the onset of hot-spot in a NoC chip. Furthermore the application of thermal management can reduce temperature and number of thermal cycles, increasing the systemreliability. Therefore the thesis advocates the need to integrate a thermal analysis in the first design stages for embedded NoC design. Later on, I focused my research in the development of statistical process variation analysis tool that is able to address both random and systematic variations. The tool was used to analyze the impact of self-timed asynchronous logic stages in an embedded microprocessor. As results we confirmed the capability of self-timed logic to increase the manufacturability and reliability. Furthermore we used the tool to investigate the suitability of low-swing techniques in the NoC system communication under process variations. In this case We discovered the superior robustness to systematic process variation of low-swing links, which shows a good response to compensation technique as ASV and ABB. Hence low-swing is a good alternative to the standard CMOS communication for power, speed, reliability and manufacturability. In summary my work proves the advantage of integrating a statistical process variation analysis tool in the first stages of the design flow...|$|E
50|$|The TLS {{functions}} using {{airborne equipment}} {{that is currently}} widely used by the aviation industry. TLS uses the existing Mode 3/A/C/S transponder equipment to determine the aircraft's position. It then transmits the <b>correct</b> <b>signal</b> on the same frequencies used for the current ILS system. All the pilot is required to do is wait for clearance from ATC for the TLS approach and then tune an ILS receiver to the appropriate frequency. TLS uses equipment most airplanes already have.|$|R
40|$|This paper investigates an {{adaptive}} M-ary phaseshift keying (M-PSK) modulation scheme over Rayleigh flat fading channels. The data rate is adapted {{according to the}} channel state. At the receiver, the fading is estimated using pilot symbols. To cancel the channel impact, we <b>correct</b> the received <b>signal</b> by dividing it by the estimated value of the fading. So, we propose to adjust the modulation level by examining the statistics of the <b>corrected</b> <b>signal.</b> In contrast to the previous works on the adaptive M-PSK modulation techniques, our modulation switching protocol {{takes into account the}} channel estimation error variance. Moreover, we derive a new closed-form expression for the average bit error rate of the considered system...|$|R
40|$|Abstract — In {{this paper}} we propose a novel twodimensional {{clocking}} and timing scheme for systems which permit a reduction in the longest line length in each clocking zone. The proposed clocking schemes utilize logic propagation techniques which have been developed for systolic arrays. Placement of QCA cells is modified to ensure <b>correct</b> <b>signal</b> generation and timing. The significant reduction in the longest line length permits a fast timing and efficient pipelining to occur, while guaranteeing kink-free behavior in switching...|$|R
40|$|In “situ” tissue {{engineering}} is a promising approach in regenerative medicine, envisaging to potentiate the physiological tissue repair processes by recruiting the host’s own cellular progenitors at the lesion site {{by mean of}} a bioactive materials. This approach, heavily relies on the capability of scaffold to broadcast the <b>correct</b> <b>signals</b> to effectively and selectively recruit stem cells. Our aim is to realize innovative device able to recruit and select Mesenchymal Stem Cells both in three dimensional matrix and twoo- dimensional platforms...|$|R
40|$|This paper {{presents}} a near-field reflector switching technique that can generate independently controlled modulated signals for sufficiently different angles of radiation. This technique {{can be used}} either to transmit different data in different directions simultaneously, or to generate the <b>correct</b> <b>signal</b> constellation only in the desired direction and scrambled ones for other angles, creating a secure communication link. This approach is also conducive to power-efficient switching PAs, even for wideband non-constant envelope modulation schemes, enabling fast and power-efficient transmitter architectures...|$|R
40|$|This paper investigates a jury {{decision}} when hung juries and retrials are possible. When {{jurors in}} subsequent trials know that previous trials resulted in hung juries, informative voting cannot be an equilibrium regardless of voting rules unless {{the probability that}} each juror receives the <b>correct</b> <b>signal</b> when the defendant is guilty {{is identical to the}} one when he is innocent. Thus, while Coughlan (2000) claims that mistrials facilitate informative voting, our result shows that such an assertion holds only in limited circumstances. ...|$|R
40|$|Sparse {{modeling}} {{has been}} widely and successfully used in many applications such as computer vision, machine learning, and pattern recognition. Accompanied with those applications, significant research has studied the theoretical limits and algorithm design for convex relaxations in sparse modeling. However, theoretical analyses on non-negative versions of sparse modeling are limited in the literature either to a noiseless setting or a scenario with a specific statistical noise model such as Gaussian noise. This paper studies the performance of non-negative sparse modeling in a more general scenario where the observed signals have an unknown arbitrary distortion, especially focusing on non-negativity constrained and L 1 -penalized least squares, and gives an exact bound for which this problem can recover the <b>correct</b> <b>signal</b> elements. We pose two conditions to guarantee the <b>correct</b> <b>signal</b> recovery: minimum coefficient condition (MCC) and nonlinearity vs. subset coherence condition (NSCC). The former defines the minimum weight {{for each of the}} correct atoms present in the signal and the latter defines the tolerable deviation from the linear model relative to the positive subset coherence (PSC), a novel type of "coherence" metric. We provide rigorous performance guarantees based on these conditions and experimentally verify their precise predictive power in a hyperspectral data unmixing application. Comment: 12 pages, 8 figure...|$|R
25|$|Once the {{challenge}} is invoked, acknowledged, and agreed, the Third Umpire reviews the play. The Third Umpire then reports to the on-field umpire whether his analysis supports the original call, contradicts the call, or is inconclusive. The on-field umpire then makes the final decision: either re-signalling a call that is standing or revoking a call that is being reversed and then making the <b>corrected</b> <b>signal.</b> Only clearly incorrect decisions are reversed; if the Third Umpire's analysis is within established margins of error or is otherwise inconclusive, the on-field umpire's original call stands.|$|R
40|$|Atmospheric {{turbulence}} {{results in}} many effects causing fluctuation in the received optical power. Terrestrial laser beam communication is affected above all by scintillations. The paper deals with modeling {{the influence of}} scintillation on link performance, using the modified Rytov theory. The probability of <b>correct</b> <b>signal</b> detection in direct detection system in dependence on many parameters such as link distance, power link margin, refractive-index structure parameter, etc. is discussed and different approaches to the evaluation of scintillation effect are compared. The simulations are performed for a horizontal-path propagation of the Gaussian-beam wave...|$|R
40|$|Adaptive antenna arrays, {{also known}} as smart antennae, are {{becoming}} progressively {{a viable alternative to}} larger antenna structures in a wide number of different scenarios. However, in order {{to take full advantage of}} the arrays' interference rejection and SNR (Signal-to-Noise Ratio) improvement capabilities, that is, in order to perform a <b>correct</b> <b>signal</b> beamforming via complex weights' manipulation, the antenna structure needs a precise calibration procedure. In this paper, two algorithms, based on efficient MLE (Maximum Likelihood Estimation) and MEE (Maximum Entropy Estimation) are analyzed and simulated, in order to obtain their relative performance...|$|R
