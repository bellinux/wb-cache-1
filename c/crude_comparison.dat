18|63|Public
30|$|A <b>crude</b> <b>comparison</b> of {{patients}} with ICH treated or not with continuous osmotherapy was first performed. To consider the biases related to this observational study, an adjustment on potential confounders (age, glasgow coma scale, pupil reactivity, Marshall score, hypotension and hypoxemia) was performed by both a propensity analysis and a multivariate analysis.|$|E
30|$|Methods: A {{prospective}} {{audit of}} the first 30 adult critically ill patients receiving RCA with post dilution CVVHF. <b>Crude</b> <b>comparison</b> was made with a historical group of consecutive critically ill patients who received CRRT without heparin prior {{to the introduction of}} the RCA protocol. Patients were excluded from the RCA protocol and the comparison if they had, severe acute liver injury. Data is presented as median (range) with non parametric analysis and filter survival as a Kaplan Meier for the event ´filter clotting´ and censored for medical cessation or technical failure.|$|E
40|$|AbstractThe {{focus of}} this paper is on issues arising from the {{comparison}} of business survey indices (BSI’s). Any BSI may be contaminated by false reports or contagion effects so that a <b>crude</b> <b>comparison</b> of BSI’s across different groups is not appropriate. A method is therefore proposed for transforming different business survey indices into comparable indices using the generalized birth and death process. The method is carefully designed in order to filter out contagion effects by taking respondents’ interaction into consideration. The method also improves the comparability of the BSI’s by adjusting the information precision of different survey groups...|$|E
40|$|The {{comments}} which follow {{relating to}} the role of agriculture in Minnesota's economic development are organized into four sections. First a brief look is taken at historical changes in production agriculture in Minnesota. Second some <b>crude</b> <b>comparisons</b> are made of growth over time in agriculture and in other major economic sectors. Third a brief assessment is made of current employment and income in Minnesota's agriculture and related industries. Finally, a list is presented of several future issues which appear important for Minnesota's agriculture with particular reference to its natural resource base. Community/Rural/Urban Development,...|$|R
40|$|Abstract: This paper {{examines}} {{the impact of}} contracting out on the costs incurred by local authorities in providing refuse collection services. Using original survey data for the Republic of Ireland, three methods of estimating the impact of tendering are adopted. <b>Crude</b> <b>comparisons</b> of costs before and after tendering {{and the costs of}} local authorities versus private contractors indicate that tendering can yield savings of between 34 and 45 per cent. Using multivariate regression analysis to enable us to control for service characteristics confirms cost savings of around 45 per cent. The bulk of these cost savings are attributed to real efficiency gains as a result of contracting out. ...|$|R
30|$|Continuous {{data was}} {{described}} by means or medians and standard deviations or interquartile ranges and categorical data by frequencies and proportions. <b>Crude</b> <b>comparisons</b> on the outcome variables between the sporting and non-sporting participants were made using ANOVA. Adjusted associations between sports participation and the outcome variables were estimated by linear (or logistic) regression analyses. Assumptions were checked, and residuals showed an acceptable normal distribution, except for the Exercise Self-Efficacy scale. Therefore, the scale was dichotomized at the third tertile (score[*]≥[*] 37) and associations with sports participation were assessed by means of logistic regression analyses. Sensitivity analyses were run with and without outliers, i.e. those with standardised residual scores below −[*] 3 or higher than 3.|$|R
40|$|<b>Crude</b> <b>comparison</b> {{between four}} {{alternative}} proposals {{for the very}} definition of a wormhole is provided, all of which were intended to apply to the dynamical cases. An interesting dynamical solution, based upon large scale magnetic fields, is used for the comparisons. Such solution goes beyond the perfect fluid approximation due to an anisotropic pressure component, bringing to the fore some unsuspected features of those definitions. Certain notions as reversible traversability are claimed as a way to select among those definitions the best suited one to represent our intuition of what a wormhole solution is expected to be. Comment: 14 pages, 21 figure...|$|E
40|$|P>Benchmarking and {{comparisons}} between transplantation centers {{are becoming more}} common. A <b>crude</b> <b>comparison</b> indicated a 50 % difference in patient survival between centers in Sweden. A 'task group' was formed to refute or confirm and learn from this observation. Patient survival and graft survival of 5 933 patients transplanted at three different transplantation centers in Sweden (Stockholm, Goteborg, and Malmo) were followed up until February 2007. Patient survival and graft survival were compared between the centers with and without consideration being given to important covariates such as time period, type of donation (living or deceased donor), gender, and age. A refined cohort of 2 956 adult patients that had been transplanted {{for the first time}} between 1991 and 2007 was assessed in more detail using Cox regression analysis. The difference in patient and transplant outcome observed in the <b>crude</b> <b>comparison</b> diminished considerably after adjustment for differences in case mix and time period of transplantation, and was neither evident nor significant after 1999. Patient survival and graft survival have improved considerably during the time period since 1991. The adjusted hazards ratio for mortality was 0. 39 (95 % CI 0. 29 - 0. 53) for patients who were transplanted after 1999 when compared with those transplanted between 1991 and 1994. Crude {{comparisons between}} results from transplantation centers may be severely confounded not only by case mix but also by differences in the proportion of patients transplanted during different time periods. Patient outcome and graft outcome have improved considerably since 1991, and after 1999 center effects were no longer apparent in Sweden...|$|E
40|$|In {{randomized}} trials with follow-up, outcomes such as {{quality of life}} may be undefined for individuals who die before the follow-up is complete. In such settings, restricting analysis to those who survive can give rise to biased outcome comparisons. An alternative approach is to consider the “principal strata effect” or “survivor average causal effect” (SACE), defined as the effect of treatment on the outcome among the subpopulation that would have survived under either treatment arm. The authors describe a very simple technique {{that can be used}} to assess the SACE. They give both a sensitivity analysis technique and conditions under which a <b>crude</b> <b>comparison</b> provides a conservative estimate of the SACE. The method is illustrated using data from the ARDSnet (Acute Respiratory Distress Syndrome Network) clinical trial comparing low-volume ventilation and traditional ventilation methods for individuals with acute respiratory distress syndrome...|$|E
40|$|This {{paper was}} {{obtained}} through PEER (Publishing and the Ecology of European Research) [URL] paper examines {{the impact of}} contracting out on the costs incurred by local authorities in providing refuse collection services. Using original survey data for the Republic of Ireland, three methods of estimating the impact of tendering are adopted. <b>Crude</b> <b>comparisons</b> of costs before and after tendering {{and the costs of}} local authorities versus private contractors indicate that tendering can yield savings of between 34 and 45 per cent. Using multivariate regression analysis to enable us to control for service characteristics confirms cost savings of around 45 per cent. The bulk of these cost savings are attributed to real efficiency gains as a result of contracting out...|$|R
40|$|This paper assesses, by {{comparing}} recent published evidence with Dean's pioneering work, whether {{an increase in}} the milder forms of dental fluorosis may have occurred since Dean's time. To the extent that the <b>crude</b> <b>comparisons</b> of recent research with historic studies are valid, the data indicate a slight trend toward more fluorosis today than would be expected based upon findings in the late 1930 s and early 1940 s. This suggested increase in fluorosis is not as clear-cut nor as widely accepted as the recent decline in the prevalence of dental caries. Thus, further study of the prevalence of fluorosis and caries in relation to fluoride ingestion will be required to help validate the trend, and to allow dental researchers and decision makers to plan for the future...|$|R
50|$|The {{discovery}} in 1819 by Cardinal Angelo Mai {{was one of}} the first major recoveries of an ancient text from a palimpsest, and although Mai's techniques were <b>crude</b> by <b>comparison</b> with later scholars', his discovery of De Republica heralded a new era of rediscovery and inspired him and other scholars of his time to seek more palimpsests.|$|R
40|$|The {{baseline}} DARHT 2 {{external beam}} uses a pulsed solenoid final focus lens. The design of this lens {{was presented at}} TOS 2 and has been considered as the final focus lens {{in all of the}} Livermore beamlines for DARHT 2. In this note, we consider a new alternative DC final focus solenoid. A <b>crude</b> <b>comparison</b> between the parameters of these two designs is given in table 1. The small spot size required by the radiography and the small drift distance available between the last magnetic focusing element and the final focus solenoid imposed by the close proximity between the DARHT 2 building and the DARHT 1 axis, implies a short focal length solenoid. This in turn requires that the final focus solenoid mount inside the re-entrant cavity of the containment vessel in order to accommodate the 0. 9 meter conjugate: figure 1. The ID of this cavity is 13. 88 inches (35. 25 cm) ...|$|E
40|$|We {{discuss the}} origins, in meson theory, {{of a nuclear}} {{potential}} which will adequately describe the interactions of nucleons up to energies of approximately 150 Mev. Our Hamiltonian is obtained from a non-relativistic reduction of the relativistic pseudo-scalar theory. The coefficients of all terms in the Hamiltonian are treated as parameters whose values are determined from experiment. In computing the actual potential we follow precisely the philosophy of Breuckner and Watson and Gartenhaus. The resulting potential is an expansion in powers of the coupling constant and {{the ratio of the}} velocity of the nucleons to that of light. Only the second and fourth order terms in the coupling constant and the zeroth and first order term in (v/c) nucleon will be retained. All pieces of the potential are evaluated numerically with a smooth momentum space cutoff. We also consider a modified type of relativistic theory where pair terms are supressed. A <b>crude</b> <b>comparison</b> is made with experiment. It is found that the potential is in qualitative agreement with the experimental data on nucleon-nucleon scattering, the splitting of the levels in He 5, and the observed magnetic moment of the deuteron...|$|E
40|$|The first Herschel/HiFi data on pPNe {{and young}} PNe are being obtained, providing, {{for the first}} time, {{systematic}} observations of high-excitation molecular lines from these sources with high spectral resolution. The telescope and all telescopes sub-systems are performing as expected, and so the data are of very good quality. The high spectral resolution provided by the heterodyne detection technique allows the detection of spectra of high velocity resolution (always better than 1 km/s), in which the different dynamical components of the nebulae can be clearly separated and identified. This data allows, for the first time, systematically study of the warm molecular component in these objects, including in particular the study of thermal lines of water vapor, which of course cannot be done from the ground. In this poster we summarize the very first results on pPNe and PNe obtained with Herschel/HiFi. In particular we note the detection of intense emission from the bipolar fast flows in the C-rich pPNe CRL 618. A <b>crude</b> <b>comparison</b> with the existing models for the source, indicates that this emission comes {{from the base of}} the very fast shock-accelerated jets. Results on additional sources, like NGC 6302, the Red Rectangle, and others, are also discussed. status: publishe...|$|E
40|$|A {{mathematical}} model hasbeen developed to predict he electrolyte velocity field, bubble distribution, current dis-tribution: and mass-transfer rates in cells with vertical planar electrodes, {{one of which}} evolves gases. The {{mathematical model}} employed either the k-e or the k-l representation f turbulence. The predictions of the model were compared with experimental velocity measurements, carried out using a laser-Doppler velocimeter, on a laboratory cell; semi-quanti-tative agreement was obtained {{in the case of}} the k-l model when the bubble size was used as an adjustable parameter. <b>Crude</b> <b>comparisons</b> could be made between mass-transfer p edictions and measurements of others. As described in Part I of this two-part paper, electrolyte flow has an effect on the performance of the cells em-ployed in electrometallurgy. The effect is first on mass transfer (and thereby on limiting current and deposit morphology) and particle suspension. In the case of electrorefining cells, flow can be natural convection, driven b: ~ solute concentration gradients. Such natural convection can also occur in electrowinning cells, as wil...|$|R
40|$|It {{is often}} {{argued that there}} are {{significant}} differences in the costs of providing public and non-public services. However, these arguments have almost invariably been based on <b>crude</b> <b>comparisons</b> of bald expenditure figures of rather dubious validity. In this paper we describe and apply a conceptual framework which attempts to place such inter-sectoral comparisons on a more reliable basis. Our application is to day care services for elderly people provided by local authority social services departments, area health authorities and voluntary organizations, although the framework has much wider relevance. Our results provide clear evidence to refute the oft-made assumption that voluntary services are universally cheaper than their statutory counterparts. Standardizing costs for the dependency characteristics of users and the activities of day units, we find that voluntary-statutory cost differences are dependent upon the scale of operation. Small voluntary units certainly enjoy a cost advantage, but larger voluntary units are unlikely to be cheaper, and are probably more expensive, than local authority units of a similar scale...|$|R
40|$|Includes bibliographical {{references}} (pages [61]- 68) The {{differences in}} prey avoidance caused by illness (conditioned taste aversion = CTA) versus noxious taste {{may be important}} with respect to both the longevity and the generalization of the learned avoidance. The results of the first study that examined the separate and combined effects of illness and noxious taste of insect prey on a vertebrate predator are reported here. Sucrose Octaacetate, a bitter tasting, but non-toxic, substance was used to render prey noxious tasting, but not illness causing. Quinine Hydrochloride was injected into the prey to render them illness causing, but not noxious tasting. The prey used in the experiment were mealworms (Tenebrio sp.) and the predators were free-ranging breeding, male red-winged blackbirds (Agelaius phoeniceus). The <b>crude</b> <b>comparisons</b> of this study strongly suggest that {{both in terms of}} individual and inclusive fitness, no defense (control) and noxious taste only were not as effective a defense as were either CTA only or CTA + noxious. M. S. (Master of Science...|$|R
40|$|Background and Purpose—The {{effect of}} {{previous}} antiplatelet use on stroke severity is controversial. We {{assume that this}} controversy is attributable to its difference according to the stroke mechanism. Methods—Using a prospective stroke registry, patients who were hospitalized because of ischemic stroke and had relevant lesions on MRI were selected. Patients who were using anticoagulants or whose stroke subtype was categorized as stroke of other determined etiology or undetermined etiology were excluded. Baseline stroke severity was measured using the National Institutes of Health Stroke Scale scores at presentation and was compared between no previous antiplatelet users and previous antiplatelet users with stratification by stroke subtypes. Results—Among the 1622 patients, a total of 490 (30. 2 %) patients reported use of an antiplatelet within 1 week of stroke onset. The baseline National Institutes of Health Stroke Scale score showed {{no difference between the}} nonantiplatelet and antiplatelet groups by <b>crude</b> <b>comparison.</b> However, the interaction between previous antiplatelet use and stroke subtype was significant (P 0. 023) in a multivariable analysis; when the study subjects were stratified by stroke subtype, the difference in baseline National Institutes of Health Stroke Scale between the nonantiplatelet and platelet groups was significant in the large artery atherothrombosis group but not in those with cardioembolism and small-vessel occlusion before and after adjustments. Conclusions—Our study suggests that the reduction of initial stroke severity in the previous antiplatelet users may diffe...|$|E
40|$|Whether {{presence}} or history of extracolonic primary malignancy {{is a risk}} for colorectal neoplasia is not fully known. In this study, 26, 452 first-time colonoscopy cases were examined using a colonoscopy database. Among the analyzed subjects, 3, 026 (11 %) subjects had history or concomitance of extracolonic primary malignancy, while the remaining 23, 426 subjects did not. Colorectal neoplasia was observed in 39 % of all the subjects. A <b>crude</b> <b>comparison</b> showed that the prevalence of any type of colorectal neoplasia was higher in subjects with extracolonic malignancy than in those without (42 % vs. 39 %, p＝ 0. 0012). However, after adjusting for confounding factors, the odds ratios (ORs) of subjects with extracolonic malignancy for having colorectal neoplasia, advanced neoplasia, and cancer were all less than 1. 0, and all significantly {{different from those of}} subjects without extracolonic malignancy. Analysis according to the type of extracolonic malignancy revealed that gastric cancer cases had a significantly lower risk for colorectal advanced neoplasia (OR: 0. 81; 95 % CI: 0. 67 - 0. 99). Among major malignancies, only esophageal squamous cell cancer cases had increased risk for colorectal neoplasia (OR: 1. 66; 95 % CI: 1. 20 - 2. 29). Patients with {{presence or}} history of extracolonic malignancy did not carry a higher risk of occurrence of colorectal neoplasia...|$|E
40|$|Bac k g r o u n d: Rates of preterm birth {{have been}} rising {{over the past several}} decades. Factors {{contributing}} to this trend remain largely unclear, and exposure to environmental contaminants may play a role. Objective: We investigated the relationship between phthalate exposure and preterm birth. Met h o d s: Within a large Mexican birth cohort study, we compared third-trimester urinary phthalate metabolite concentrations in 30 women who delivered preterm (< 37 weeks of gestation) with those of 30 controls (≥ 37 weeks of gestation). Res u l t s: Concentrations of most of the metabolites were similar to those reported among U. S. females, although in the present study mono-n-butyl phthalate (MBP) concentrations were higher and monobenzyl phthalate (MBzP) concentrations lower. In a <b>crude</b> <b>comparison</b> before correcting for urinary dilution, geometric mean urinary concentrations were higher for the phthalate metabolites MBP, MBzP, mono(3 -carboxylpropyl) phthalate, and four metabolites of di(2 -ethylhexyl) phthalate among women who subsequently delivered preterm. These differences remained, but were somewhat lessened, after correction by specific gravity or creatinine. In multivariate logistic regression analysis adjusted for potential confounders, elevated odds of having phthalate metabolite concentrations above the median level were found. Co n c l u s i o n s: We found that phthalate exposure is prevalent among this group of pregnant women in Mexico and that some phthalates may be associated with preterm birth...|$|E
5000|$|The Rubberbandits {{developed}} a comedic style that is satirical, surrealist and <b>crude,</b> drawing <b>comparisons</b> to satirist Flann O'Brien. The track [...] "Up Da Ra", employs the literary device of the unreliable narrator to lambast the Irish phenomenon of armchair republicanism. Their work explores {{a number of}} themes that are of significance to Irish urban youth, including drug abuse, interaction with the Garda Síochána, and violence.|$|R
40|$|This paper gives a brief {{review of}} work on virtual and remote {{laboratories}} along with a critique of their strengths and weaknesses. This is used as a motivation for a proposed method for producing virtual laboratories which, while relatively <b>crude</b> in <b>comparison</b> with professional alternatives, are much cheaper and faster to produce and thus can be created using the skill set and time of normal academics. Some examples and the coding processes are demonstrated. ...|$|R
40|$|This paper engages recent {{debates over}} equity group {{representation}} among university professors. Since {{at least the}} time of John Porter’s publication of The Vertical Mosaic, the correlation between ethnicity, education, and employment success has been shown. The most troubling of Porter’s research findings was the persistence of a stratified Canadian workforce and society. Using data from the 1991, 1996, 2001, and 2006 Canadian censuses, three questions are engaged: 1) How well are different equity groups represented among university professors? 2) Is their representation improving over time? and 3) Does looking at the pool of earned doctorates matter {{in the analysis of}} equity group representation among university professors? The paper shows that when looking at <b>crude</b> <b>comparisons</b> of the proportion of equity groups in the general population to the proportion of equity groups in the professorate, visible minorities have moved from being overrepresented to underrepresented, Aboriginal peoples are consistently underrepresented by a small amount, and women are significantly underrepresented, although the gap is narrowing over time. When addi-tional analysis is done by looking at comparisons of the proportion of equity groups who work as university professors compared to the national average of all people working as university profes...|$|R
40|$|AbstractBiodiversity offsets are {{interventions}} that compensate for ecological losses caused by economic development, seeking ‘no net loss’ (NNL) of biodiversity overall. Calculating the ecological gains {{required to achieve}} NNL is non-trivial, with various methodologies available. To date, {{there has been no}} comparison among methodologies for a common case study. We use data on industrial impacts in Uzbekistan to provide such a comparison. We quantify losses from 40 years of gas extraction, using empirical data on vegetation impacts alongside estimates of disruption to mammals. In doing so, we implement a novel technique by estimating spatial ‘functional forms’ of disturbance to calculate biodiversity impacts. We then use a range of offset methodologies to calculate the gains required to achieve NNL. This allows a <b>crude</b> <b>comparison</b> of the potential biodiversity outcomes of “in kind” offsets (here, vegetation restoration) with “out of kind” offsets (protecting fauna from poaching). We demonstrate that different methods for calculating the required offset activities result in divergent outcomes for biodiversity (expressed in habitat condition x area, or ‘weighted area’), and different trajectories in biodiversity outcomes over time. An Australian method is currently being considered for adoption in Uzbekistan, but we show that it would require careful adjustments to achieve NNL there. These findings highlight that the method used to quantify losses and gains strongly influences the biodiversity outcomes of offsetting, implying that offsets generated using different methodologies are not transferable between jurisdictions. Further, conservation gains from out of kind offsets may outweigh those from strict in kind NNL interpretations...|$|E
40|$|We {{present a}} {{detailed}} {{investigation into the}} recent star formation histories of 5, 697 Luminous Red Galaxies (LRGs) based on the Hdelta (4101 A) and [OII] (3727 A) lines. LRGs are luminous (L> 3 L*), galaxies which have been selected to have photometric properties consistent with an old, passively evolving stellar population. For this study we utilise LRGs from the recently completed 2 dF-SDSS LRG and QSO survey (2 SLAQ). Equivalent widths of the Hdelta and [OII] lines are measured and used to define three spectral types, those with only strong Hdelta absorption (k+a), those with strong [OII] in emission (em) and those with both (em+a). All other LRGs are considered to have passive star formation histories. The vast majority of LRGs {{are found to be}} passive (~ 80 per cent), however significant numbers of k+a (2. 7 per cent), em+a (1. 2 per cent) and em LRGs (8. 6 per cent) are identified. An investigation into the redshift dependence of the fractions is also performed. A sample of SDSS MAIN galaxies with colours and luminosities consistent with the 2 SLAQ LRGs is selected to provide a low redshift comparison. While the em and em+a fractions are consistent with the low redshift SDSS sample, the fraction of k+a LRGs is found to increase significantly with redshift. This result is interpreted as an indication of an increasing amount of recent star formation activity in LRGs with redshift. By considering the expected life time of the k+a phase, the number of LRGs which will undergo a k+a phase can be estimated. A <b>crude</b> <b>comparison</b> of this estimate with the predictions from semi-analytic models of galaxy formation shows that the predicted level of k+a and em+a activity is not sufficient to reconcile the predicted mass growth for massive early-types in a hierarchical merging scenario. Comment: Accepted for publication in MNRAS, 13 pages, 10 figure...|$|E
40|$|Abstract Background Statins {{may reduce}} the risk of first and {{recurrent}} venous thromboembolism (VTE). No data are available on their potential benefit in patients treated with the oral anticoagulant rivaroxaban. Methods The EINSTEIN DVT/PE and EINSTEIN Extension studies compared rivaroxaban with standard of care (n= 8280) and placebo (n= 1188), respectively. The incidences of recurrent VTE and major bleeding per 100 patient-years for exposure (or not) to statins were calculated. A Cox proportional hazards model was constructed, stratified by index event and intended treatment duration, with statin use as a time-dependent variable, for each treatment group (rivaroxaban vs enoxaparin/vitamin K antagonist or placebo) and adjusted for relevant variables. Results In EINSTEIN DVT/PE, 1509 (18. 3 %) patients used statins during the at-risk period, and 6731 (81. 7 %) did not. Overall, 2. 6 recurrent VTEs occurred per 100 patient-years with statin use compared with 3. 8 per 100 patient-years without statins (adjusted hazard ratio [HR] 0. 76; 95 % confidence interval [CI] 0. 46 – 1. 25). HRs for recurrent VTE were similar for concomitant use of rivaroxaban-statin and enoxaparin/VKA-statin. Major bleeding events occurred in 3. 0 per 100 patient-years with statin use compared with 2. 3 per 100 patient-years without statins (adjusted HR 0. 77; 95 % CI 0. 46 – 1. 29). Due to adjustments in the Cox regression model, the direction of this HR is in contrast to the <b>crude</b> <b>comparison.</b> In EINSTEIN Extension, no recurrent VTEs occurred with statin use in the rivaroxaban group compared with 1. 6 per 100 patient-years without statins. In the placebo group, 12. 2 recurrent VTEs occurred per 100 patient-years with statin use compared with 13. 2 per 100 patient-years without (adjusted HR 0. 81; 95 % CI 0. 35 – 1. 86). Conclusions The effect of statins in this secondary analysis of the EINSTEIN VTE treatment program is consistent with other studies that suggest a reduced risk of recurrent VTE, but conclusive evidence of this benefit is lacking. Statins are simple to use, inexpensive, very safe and do not cause bleeding. Therefore, the potential effect on reducing recurrent VTE, which is in the range of that of acetylsalicylic acid, deserves evaluation in a large randomized trial. Trial registration number ClinicalTrials. gov: EINSTEIN PE, NCT 00439777; EINSTEIN DVT, NCT 00440193; EINSTEIN Extension, NCT 00439725...|$|E
50|$|From time immemorial, the Mizo {{have been}} using {{different}} musical instruments. Even though we cannot date the origin, the “Mizo of Kabaw Valley during late 10th to 13th century AD had developed their music as nearly as they have done today”. The traditional Mizo musical instruments are very simple and <b>crude</b> in <b>comparison</b> to other Indian musical instruments and very out-dated to Modern Musical instruments. They can broadly be divided into three: Beating or Striking instruments; Wind instruments and String instruments.|$|R
50|$|One gunnery {{advantage}} the Americans had was the radar-controlled Mark 37 Gun Fire Control System. The {{brains of}} the system was the Ford Mark I Fire Control Computer, which provided coordinated automatic firing solutions for her 5-inch guns merely by pointing the gun director at the target. <b>Crude</b> by <b>comparison,</b> the Japanese used optical range finders aided by splash color dye markers in each shell, color-coded to the firing ship. At this point, the Japanese were unable to find the range of their attacker.|$|R
40|$|Background There is {{conflicting}} information about whether nitrate treatment aggravates long-term prognosis, so the present retrospective {{study was designed}} {{to determine the effects of}} long-term nitrate therapy on major adverse events after acute myocardial infarction (AMI) in the coronary interventional era. Methods and Results Using the Japanese Acute Coronary Syndrome Study database, 1, 236 consecutive patients who were hospitalized within 48 h of onset of symptoms of AMI from January to December 2003 were evaluated. All-cause mortality, cardiac events and cardiovascular events were lower in patients treated with nitrates than in the untreated controls. However, these <b>crude</b> <b>comparisons</b> included several confounding factors on nitrate prescription. To minimize the effect of selection bias on outcomes, the technique of propensity score matching for clinical characteristics was used and distortion of effective nitrate treatment was excluded as much as possible. The results of propensity score matching showed that nitrate therapy had no impact on all-cause mortality, cardiac events and cardiovascular events at 30, 60 or 90 days, 6 months, 1 year, and 2 years follow-up. Conclusions Long-term nitrate therapy after AMI neither improves nor aggravates prognosis. Prospective randomized clinical trials are warranted to determine the effects of long-term nitrate therapy for secondary prevention of AMI. (Circ J 2007; 71 : 301 - 307) 出版者照会後に全文公...|$|R
40|$|The {{primary purpose}} of this project is to assess the {{environmental}} impacts associated with the wood pellet production. The study has extended to the entire life cycle of wood pellet, which includes the up- and down-stream processes. Therefore it leaves the Life Cycle Assessment (LCA) the best method to carry out such study. LCA is a popular tool for evaluating environmental impacts of products or services. In this study, the mainstream LCA methodology is adopted, which includes four steps starting from goal and scope definition, life cycle inventory analysis, to life cycle impact assessment, and interpretation. The {{results of the study}} will be used for the wood pellet producer to communicate with its customers and also facilitate a better environmental management. The entire life cycle of wood pellet can be divided into eight main processes. According to the results of inventory analysis, the Silviculture is the most fossil fueldependant process, while the Pellet Production is, however, the most energy-intense process. Regarding the emissions, the final Combustion process contributes most to the air emissions, but the Pellet Production has a remarkably high emission of hydrocarbons, which can be explained as incomplete combustion of a mass of biofuel. The resources use, on the other hand, is close related to the consumption of electricity, since the electricity production is included in the system. The process with bigger demand of electricity results in bigger amount of resources use. When it comes to the characterisation level, the inventory data have been aggregated and translated into real environmental impacts. There are at least six different environmental impacts are possible to be initiated from the wood pellets production. It is noted that the Silviculture and the final Combustion are the least environmental preferable processes, due to the relatively big environmental impacts potential in relation to these two processes. There are three valuation methods involved in the report to weigh the importance of the environmental impacts against from one to another. The results of the three valuation methods are somehow different, which is, however, only because the methods tend to weight the importance of the environmental impacts from different perspective, and there is no such best weighting method exits. At last, a sensitivity analysis is given to discuss the hot points in the report, which is about to test the uncertainties of the data. Plus a discussion part is made {{at the end of the}} report to discuss the account of carbon dioxide emission in bioenergy system, and a <b>crude</b> <b>comparison</b> of avoided green house gas emission of using different kind of wood energy...|$|E
40|$|Inorganic lead is a {{hazardous}} substance, exposure to {{which has been}} linked to various adverse health effects including haematological, neurological, renal and reproductive health problems. These adverse health effects can be correlated with blood lead levels (BLL) and are potentially significant for lead workers, such as production and maintenance personnel at lead smelters. Such workers usually need to wear particle-filtering respirators in order to reduce uptake of airborne lead, and follow strict hygiene protocols. However, there is a paucity of literature on the effectiveness of lead exposure reduction programs for lead smelter workers, especially those engaged as contractors for short periods. The aim {{of this study was to}} evaluate an intervention targeted at maintenance and refurbishment contractors engaged during a two-yearly plant shutdown of a primary lead smelter. This evaluation addressed a variety of factors that influence the uptake of lead and gathered information on a rarely-studied group of contractors so as to provide recommendations for improving future occupational health and safety (OHS) interventions in lead industries. Findings from the research may assist in refining conceptual models of OHS interventions addressing complex exposure scenarios. The intervention for the contractors entailed training and the mandatory use of a single brand of half-face disposable particle respirator. Contractors were instructed by the smelter management to undergo a pre-employment blood lead test and attend a health and safety induction, where they were informed of lead hazards and trained in the correct usage of disposable respirators. A post-induction questionnaire was used to elicit information on personal characteristics, smoking status, lead-based hobbies (hobbies that expose contractors to inorganic lead), prior respirator experience and perceptions of the use of disposable respirators. Fixed-position air sampling was conducted to determine the levels of airborne lead-bearing dust generated during maintenance activities and to assess differences between areas, including rest areas. Compliance with respirator usage requirements was assessed by routine observation, and site inspection checklists were used for the assessment of lead contamination. After the two-week shutdown period and prior to departure from the site, contractors underwent a second blood lead test. Other information was gathered prior to, during and after the intervention, through repeated observation and discussions with key stakeholders, and formed the basis of a stakeholder analysis. Full questionnaire and blood lead data were available for 62 male contractors, and of these 81 % were previous contractors to the smelter, 87 % had previous respirator experience, 78 % believed disposable respirators were equal in protection to non-disposable rubber respirators, 87 % were confident disposable respirators would keep blood lead down, and 35 % reported non-occupational exposure to lead. The arithmetic mean entry BLL was 5. 5 μg/dl (std dev= 3. 9) and the increase in BLL over the shutdown period was 14. 4 (9. 3). Smokers (n= 18) had a mean increase of 17. 4 μg/dl, compared to non-smokers (n= 44) with 13. 2 μg/dl, but this difference was not statistically significant. Similarly, potentially predictive factors such as age, job category, lead-based hobbies, respirator experience and confidence were not statistically significant. Crane operators and riggers (n= 8) had the greatest increase in BLL (19. 6), compared with welders (17. 1, n= 9) and general maintenance contractors (13. 0, n= 45). Although it was a non-smoking site, many contractors were observed to smoke. Observed compliance with respirator usage was generally good (estimated at 95 % via direct observation). However it appeared that compliance and airborne lead dust levels were variable between locations, indicating these may be task related. Hot work, e. g. welding in confined areas, was associated with lower respirator usage and sweat-related respirator deterioration. Air monitoring in an area ostensibly lead-free, i. e. the blast furnace crib room (rest area), demonstrated appreciable levels of airborne lead dust (GM = 55 μg/m³, n= 4). A stakeholder analysis of the intervention identified a lack of consultation between contractors and management prior to implementation. It was evident that smokers had difficulty complying with the strict non-smoking rules and that some contractors wore contaminated clothing in crib rooms, a source of lead exposure and a breach of policy. In addition, contractors were often unshaven, which significantly reduces the effectiveness of the mandated respirators. Finally, some contracting companies exhausted their supply of respirators, suggesting logistical problems and limited consultation. This study appears to be the first to report increases in blood lead for a cohort of shutdown maintenance contractors working in a lead smelter environment. It also demonstrates appreciable BLL increases in a relatively short space of time. The findings relating to airborne lead and to BLL differences between contracting companies indicate that lead uptake is associated with task and that the use of a half-face disposable respirator with moderate protection performance may not be suitable for all tasks. The lack of personal inhalational exposure data limits the interpretation of the effectiveness of the respiratory protection program based on BLL alone. The stakeholder analysis highlighted disparate management and contractor perspectives on consultation. Overall, however, the intervention was judged as successful by the lead smelting company on the basis of observed respirator compliance and by a <b>crude</b> <b>comparison</b> with BLL data observed in a previous shutdown period, two years earlier. It is recommended that task-specific personal air sampling be undertaken, especially for hot work, in order to determine whether the half-face respirator is adequate for all tasks. The induction training should more explicitly address routes of lead exposure and the importance of factors determining respirator effectiveness. A greater degree of consultation between contracting companies and smelter management should be undertaken in order to address logistics issues, work practices and hygiene, especially for smokers. This study has highlighted the complexity of exposure pathways, often mediated by worker behaviour in response to company directives, and relatedly, the value of stakeholder analysis as a means of identifying areas for improvement. The change in BLL serves as an index of actual success for future interventions. Thesis (M. Med. Sc.) [...] University of Adelaide, School of Population Health and Clinical Practice, 201...|$|E
40|$|The {{effective}} management {{of water resources}} in Alberta is crucial to sustainable agriculture, industrial development, and environmental management. The historical water allocation mechanism, administrative apportionment, has been viewed in recent years as ineffective and cumbersome. Accordingly, the revision of the Water Act in 1996, included an attempt to improve the efficiency of water allocation. By making the transfer of water rights possible, the revised Act provides many new options for water use and flexibility. The implications of transferable water rights in Alberta water policy must be carefully considered {{in order to determine the}} viability and suitability of such a system in the provincial context. This project examines some of the economic aspects of transferable water rights and the potential for effective water allocation by way of transfers in an Alberta setting. As a major part of this project, a hedonic price model, focusing on land values in southern Alberta, was constructed based on similar models, which have been used elsewhere to value water rights or agricultural products. The hedonic approach to market analysis uses the relationship between the price of land and the attributes of the land, such as water availability, soil quality and location, to explain differences in land prices. In this process, the hedonic model is used to estimate the implicit marginal price or value of each land attribute [...] in our case, the marginal value of irrigation water. This value will provide us with an indirect estimate of the value of water rights in the region studied. An advantage of the technique is that it estimates the value that farmers express for irrigation water in the market place for land. Such values, then, give us an indication of the anticipated prices, which might prevail for water rights in southern Alberta. The focus of the study was an area of southern Alberta encompassing the counties of Wheatland, Newell, Cypress, Forty Mile, Taber, Warner, Lethbridge and Vulcan and the irrigation districts of Western, Eastern, St. Mary's, Taber, Lethbridge Northern, and portions of Raymond. Information was collected on the physical and economic characteristics of 230 land parcels, which were sold in this region in 1993 and early 1994. A <b>crude</b> <b>comparison</b> of the value of irrigated agricultural land and non-irrigated agricultural land in the sample reveals that irrigated land was worth, on average, $ 325 more per acre than non-irrigated land. In the ensuing analysis, it was estimated that the value of a parcel of land was determined largely by the buildings on it, the number of acres in the parcel, the proximity of the parcel to a major city (in this case Calgary or Lethbridge), and by the availability of irrigation water. In the hedonic model, the coefficient values of the variables included represent the marginal impact of each of these characteristics on land prices holding all other things constant. For example, the value of water rights represents the average difference between land values of farms that have access to irrigation and farms that do not. This study estimated that every dollar of improvements to farm buildings translates to a one cent increase in the per acre price of the land parcel, where the addition of one extra acre of land to a land parcel lowers the price per acre by $ 5. 17 per acre. Land prices were seen to increase with the proximity of the parcel to large cities. Similarly, the results of the preferred model indicate that the implicit value of having access to irrigation water in southern Alberta is approximately $ 190 per acre, or, using the conventional estimate that irrigating one acre of land requires 1. 5 acre feet of water, this translates to $ 126 per acre foot of irrigation water. Accordingly, it is revealed that the existence of water rights adds approximately 35 % to the value of non-irrigated land. Since this value represents the implicit amount farmers are willing to pay for access to water, it could also be construed as an indirect measure of the value of water rights. From these results, it is reasonable to conclude that water rights do have a measurable impact on land values. Accordingly, proper incentives may be needed to ensure that water is used efficiently and not incorrectly treated as a relatively free or cheap good. One possible method of policy reform to achieve such a system would be the institution of a system of transferable water rights, permitting water to be traded, or effectively sold, at its market price or scarcity value. Further work was done to determine the potential effects of transferable water rights on the Eastern Irrigation District in southern Alberta. Farm budget information was used to gather information and create twelve representative farm types whose financial performance was analysed using linear programming with increasing water quantity constraints. The resulting productive water values were then used to imply potential reallocations of water among farm types and cropping systems. Analysis of the data gathered revealed that all representative farms faced downward sloping demand functions for water. The overall value of water for a 1 % reduction ranged from $ 8 to $ 250 per acre foot, with the lowest value belonging to largely pasture operations and the highest value attributed to specialty crop producers. This large range in water values for the region indicates that there is sufficient heterogeneity within the EID to accommodate a transferable rights system. Further analysis of the data reveals that the implementation of a transfer system would result in water being transferred to specialty crop producers and the acreage devoted to specialty crops would increase. Small irrigated pasture operations and cereal crop producers would be the first to give up their water allocations under a transfer system. The analysis indicates that there is considerable potential for economic gains from water trade within this district, the main constraint being the market limitations to expanded specialty crop production. Using these two major studies and other sources, this report concludes with a brief evaluation of the economic advantages, disadvantages and other issues involved in instituting a system of transferable water rights in Alberta. Experience elsewhere, primarily in Australia and the western United States, strongly suggests that transferable water rights, despite some drawbacks and problems of implementation, can be a very worthwhile water policy tool. Now that such tradable water rights are permissible under the revised Water Resources Act of 1996, it is recommended that a pilot project involving transferable water rights be instituted in a water short basin or sub-basin in southern Alberta once a water management plan for that basin is completed. Resource /Energy Economics and Policy,...|$|E
50|$|For an {{illustration}} of mechanical control: as the load on a steam engine increases and the engine starts to slow down, the regulator reacts by opening a valve that releases additional inputs of steam energy. This new input returns the engine to the desired number of revolutions per minute. This type of mechanical control is <b>crude</b> in <b>comparison</b> to the more sophisticated electronic control systems in everyday use. Consider the complex missile-guidance systems that measure the actual course according to predetermined mathematical calculations and make almost instantaneous corrections to direct the missile to its target.|$|R
40|$|BACKGROUND: Population samples show {{bacterial}} genomes can {{be divided}} into a core of ubiquitous genes and accessory genes that are present in a fraction of isolates. The ecological significance of this variation in gene content remains unclear. However, microbiologists agree that a bacterial species should be 'genomically coherent', even though there is no consensus on how this should be determined. RESULTS: We use a parsimonious model combining diversification in both the core and accessory genome, including mutation, homologous recombination (HR) and horizontal gene transfer (HGT) introducing new loci, to produce a population of interacting clusters of strains with varying genome content. New loci introduced by HGT may then be transferred on by HR. The model fits well to a systematic population sample of 616 pneumococcal genomes, capturing the major features of the population structure with parameter values that agree well with empirical estimates. CONCLUSIONS: The model does not include explicit selection on individual genes, suggesting that <b>crude</b> <b>comparisons</b> of gene content may be a poor predictor of ecological function. We identify a clearly divergent subpopulation of pneumococci that are inconsistent with the model and may be considered genomically incoherent {{with the rest of the}} population. These strains have a distinct disease tropism and may be rationally defined as a separate species. We also find deviations from the model that may be explained by recent population bottlenecks or spatial structure...|$|R
5000|$|We drove a Highlanderequipped with Toyota's {{standard}} stability control system. When {{running through}} a loose dirt course, it kept us {{pointed in the}} right direction. At the same time, it felt intrusive and somewhat herky-jerky as it did its magic to keep us in line.But then we drove a Highlander Hybrid, which has the new VDIM system, through the same slalom. The new system made the old one feel <b>crude</b> by <b>comparison.</b> The VDIM was virtually invisible in operation, making {{it seem as if}} the Highlander Hybrid was guided by the hand of God. John DiPietro, Edmunds.com ...|$|R
