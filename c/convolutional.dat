10000|0|Public
25|$|A <b>convolutional</b> {{neural network}} (CNN) is {{a class of}} deep, {{feed-forward}} networks, composed {{of one or more}} <b>convolutional</b> layers with fully connected layers (matching those in typical ANNs) on top. It uses tied weights and pooling layers. In particular, max-pooling is often structured via Fukushima's <b>convolutional</b> architecture. This architecture allows CNNs {{to take advantage of the}} 2D structure of input data.|$|E
25|$|As of 2011, {{the state}} of the art in deep and {{feedforward}} networks, particularly <b>convolutional</b> neural networks, alternated <b>convolutional</b> layers and max-pooling layers, topped by several fully or sparsely connected layers followed by a final classification layer. Learning is usually done without unsupervised pre-training.|$|E
25|$|DPCNs can be {{extended}} to form a <b>convolutional</b> network.|$|E
25|$|Kalray have {{demonstrated}} an MPPA and report efficiency gains over GPUs for <b>convolutional</b> neural nets.|$|E
25|$|Eyeriss, {{a design}} aimed {{explicitly}} at <b>convolutional</b> neural networks, using a scratchpad and on chip network architecture.|$|E
25|$|A {{classical}} type {{of error}} correction coding used with OFDM-based systems is <b>convolutional</b> coding, often concatenated with Reed-Solomon coding. Usually, additional interleaving (on {{top of the}} time and frequency interleaving mentioned above) in between the two layers of coding is implemented. The choice for Reed-Solomon coding as the outer error correction code is based on the observation that the Viterbi decoder used for inner <b>convolutional</b> decoding produces short error bursts when there is a high concentration of errors, and Reed-Solomon codes are inherently well-suited to correcting bursts of errors.|$|E
25|$|Google Tensor {{processing}} unit {{was presented as}} an accelerator for Google's TensorFlow framework, which is extensively used for <b>convolutional</b> neural networks. It focuses on a high volume of 8-bit precision arithmetic.|$|E
25|$|This {{killed off}} {{the market for a}} {{dedicated}} physics accelerator, and superseded Cell in video game consoles, and eventually led to their use in running <b>convolutional</b> neural networks such as AlexNet (which exhibited leading performance the ImageNet Large Scale Visual Recognition Challenge).|$|E
25|$|These {{can be used}} {{to output}} object {{bounding}} boxes {{in the form of a}} binary mask. They are also used for multi-scale regression to increase localization precision. DNN-based regression can learn features that capture geometric information, in addition to serving as a good classifier. They remove the requirement to explicitly model parts and their relations. This helps to broaden the variety of objects that can be learned. The model consists of multiple layers, each of which has a rectified linear unit as its activation function for non-linear transformation. Some layers are <b>convolutional,</b> while others are fully connected. Every <b>convolutional</b> layer has an additional max pooling. The network is trained to minimize L2 error for predicting the mask ranging over the entire training set containing bounding boxes represented as masks.|$|E
25|$|Deep {{learning}} often uses <b>convolutional</b> {{neural networks}} (CNNs), whose origins {{can be traced}} back to the Neocognitron introduced by Kunihiko Fukushima in 1980. In 1989, Yann LeCun and colleagues applied backpropagation to such an architecture. In the early 2000s, in an industrial application CNNs already processed an estimated 10% to 20% of all the checks written in the US.|$|E
25|$|Spontaneous {{innovative}} software appeared using vertex and pixel shaders {{for general}} purpose computation through rendering APIs, by storing non-graphical data in vertex buffers and texture maps (including implementations of <b>convolutional</b> neural networks for OCR), Vendors of graphics processing units subsequently saw {{the opportunity to}} expand their market and generalised their shader pipelines with specific support for GPGPU, mostly motivated by the demands of video game-physics but also targeting scientific computing.|$|E
25|$|Drawbacks of block {{interleaver}} : As it {{is clear}} from the figure, the columns are read sequentially, the receiver can interpret single row only after it receives complete message and not before that. Also, the receiver requires a considerable amount of memory in order to store the received symbols and has to store the complete message. Thus, these factors give rise to two drawbacks, one is the latency and other is the storage (fairly large amount of memory). These drawbacks can be avoided by using the <b>convolutional</b> interleaver described below.|$|E
25|$|Interleaving is used {{to convert}} <b>convolutional</b> codes from random error correctors to burst error correctors. The basic idea behind the use of {{interleaved}} codes is to jumble symbols at the receiver. This leads to randomization of bursts of received errors which are closely located and we can then apply the analysis for random channel. Thus, the main function performed by the interleaver at transmitter is to alter the input symbol sequence. At the receiver, the deinterleaver will alter the received sequence to get back the original unaltered sequence at the transmitter.|$|E
500|$|In {{the first}} decades of the 21st century, access to large amounts of data (known as [...] "big data"), faster {{computers}} and advanced machine learning techniques were successfully applied to many problems throughout the economy. By 2016, the market for AI related products, hardware and software reached more than 8 billion dollars and the New York Times reported that interest in AI had reached a [...] "frenzy". The applications of big data began to reach into other fields as well, such as training models in ecology and for various applications in economics. Advances in deep learning (particularly deep <b>convolutional</b> neural networks and recurrent neural networks) drove [...] progress and research in image and video processing, text analysis, and even speech recognition.|$|E
500|$|In 2004, Defeated Sanity {{signed with}} UK label Grindethic Records to release their {{full-length}} debut. The album was recorded at Soundforge Studios in Rhauderfehn, Germany. The band produced {{the record and}} Andreas Hilbert handled the engineering and mastering. Prelude to the Tragedy was released in November that same year. The album received mixed reviews. Diabolical Conquest said, [...] "Prelude to the Tragedy is a gleaming chrome harpoon of immaculate technical death metal, deftly interweaving cryptic riff-tangles with <b>convolutional</b> percussive violence to surprisingly comprehensible and utterly enjoyable results. Drumwork, relentless in its complexity, enhances both the progressive and barbaric elements of the tracks, nailing ambitious patterns to them with satisfying snare punch, lucid cymbals and expert fills." [...] Negative criticism of the album was mostly about the higher technical style of their music. Lords of Metal said, [...] "This is only interesting for the real die hard trash (not thrash!) lovers, and mathematicians, of course." [...] To promote the album, the band toured during 2005, appearing at Rotterdam Deathfest (an extreme metal festival in The Netherlands), along with bands such as Suffocation, Visceral Bleeding, and Vomit Remnants.|$|E
2500|$|The TMU encodes {{the high}} rate data stream with a <b>convolutional</b> code having {{constraint}} length of 7 with a symbol rate equal to twice the bit rate (k=7, r=1/2) ...|$|E
2500|$|Currently, {{the best}} {{algorithms}} for such tasks {{are based on}} <b>convolutional</b> neural networks. [...] An illustration of their capabilities is given by the ImageNet Large Scale Visual Recognition Challenge; this is a benchmark in object classification and detection, with millions of images and hundreds of object classes. [...] Performance of <b>convolutional</b> neural networks, on the ImageNet tests, is now close to that of humans. The best algorithms still struggle with objects that are small or thin, such as a small ant on a stem of a flower or a person holding a quill in their hand. They also have trouble with images that have been distorted with filters (an increasingly common phenomenon with modern digital cameras). By contrast, those kinds of images rarely trouble humans. [...] Humans, however, tend to have trouble with other issues. For example, they are not good at classifying objects into fine-grained classes, such as the particular breed of dog or species of bird, whereas <b>convolutional</b> neural networks handle this with ease.|$|E
2500|$|The new DAB+ {{standard}} has incorporated Reed-Solomon ECC as an [...] "inner layer" [...] of coding that {{is placed}} around the byte interleaved audio frame {{but inside the}} [...] "outer layer" [...] of <b>convolutional</b> coding used by the older DAB system, although on DAB+ the <b>convolutional</b> coding uses equal error protection (EEP) rather than UEP since each bit is equally important in DAB+. This combination of Reed-Solomon coding as the inner layer of coding, followed by an outer layer of <b>convolutional</b> coding – so-called [...] "concatenated coding" [...] – became a popular ECC scheme in the 1990s, and NASA adopted it for its deep-space missions. One slight difference between the concatenated coding used by the DAB+ system and that used on most other systems is that it uses a rectangular byte interleaver rather than Forney interleaving {{in order to provide}} a greater interleaver depth, which increases the distance over which error bursts will be spread out in the bit-stream, which in turn will allow the Reed-Solomon error decoder to correct a higher proportion of errors.|$|E
2500|$|Compound hierarchical-deep models compose deep {{networks}} with non-parametric Bayesian models. Features can {{be learned}} using deep architectures such as DBNs, DBMs, deep auto encoders, <b>convolutional</b> variants, ssRBMs, deep coding networks, DBNs with sparse feature learning, RNNs, conditional DBNs, de-noising auto encoders. This provides a better representation, allowing faster learning and more accurate classification with high-dimensional data. However, these architectures are poor at learning novel classes with few examples, because all network units are involved in representing the input (a [...] ) and must be adjusted together (high degree of freedom). Limiting the degree of freedom reduces the number of parameters to learn, facilitating learning of new classes from few examples. Hierarchical Bayesian (HB) models allow learning from few examples, for example for computer vision, statistics and cognitive science.|$|E
2500|$|The old {{version of}} DAB uses {{punctured}} <b>convolutional</b> coding for its ECC. The coding scheme uses {{unequal error protection}} (UEP), which means that parts of the audio bit-stream that {{are more susceptible to}} errors causing audible disturbances are provided with more protection (i.e. a lower code rate) and vice versa. However, the UEP scheme used on DAB results in there being a grey area in between the user experiencing good reception quality and no reception at all, as opposed to the situation with most other wireless digital communication systems that have a sharp [...] "digital cliff", where the signal rapidly becomes unusable if the signal strength drops below a certain threshold. When DAB listeners receive a signal in this intermediate strength area they experience a [...] "burbling" [...] sound which interrupts the playback of the audio.|$|E
50|$|The {{code rate}} of a <b>convolutional</b> code is {{commonly}} modified via symbol puncturing. For example, a <b>convolutional</b> code with a 'mother' code rate n/k=1/2 may be punctured {{to a higher}} rate of, for example, 7/8 simply by not transmitting a portion of code symbols. The performance of a punctured <b>convolutional</b> code generally scales well {{with the amount of}} parity transmitted. The ability to perform economical soft decision decoding on <b>convolutional</b> codes, as well as the block length and code rate flexibility of <b>convolutional</b> codes, makes them very popular for digital communications.|$|E
50|$|<b>Convolutional</b> {{codes are}} often {{described}} as continuous. However, {{it may also be}} said that <b>convolutional</b> codes have arbitrary block length, rather than being continuous, since most real-world <b>convolutional</b> encoding is performed on blocks of data. Convolutionally encoded block codes typically employ termination. The arbitrary block length of <b>convolutional</b> codes can also be contrasted to classic block codes, which generally have fixed block lengths that are determined by algebraic properties.|$|E
50|$|The example encoder is {{composed}} of a 16-state outer <b>convolutional</b> code and a 2-state inner <b>convolutional</b> code linked by an interleaver. The natural code rate of the configuration shown is 1/4, however, the inner and/or outer codes may be punctured to achieve higher code rates as needed. For example, an overall code rate of 1/2 may be achieved by puncturing the outer <b>convolutional</b> code to rate 3/4 and the inner <b>convolutional</b> code to rate 2/3.|$|E
5000|$|<b>Convolutional</b> {{codes are}} {{implemented}} as either systematic or non-systematic codes. Non-systematic <b>convolutional</b> codes can provide better performance under maximum-likelihood (Viterbi) decoding.|$|E
5000|$|<b>Convolutional</b> codes work on bit or symbol {{streams of}} {{arbitrary}} length. They {{are most often}} soft decoded with the Viterbi algorithm, though other algorithms are sometimes used. Viterbi decoding allows asymptotically optimal decoding efficiency with increasing constraint length of the <b>convolutional</b> code, but {{at the expense of}} exponentially increasing complexity. A <b>convolutional</b> code that is terminated is also a 'block code' in that it encodes a block of input data, but the block size of a <b>convolutional</b> code is generally arbitrary, while block codes have a fixed size dictated by their algebraic characteristics. Types of termination for <b>convolutional</b> codes include [...] "tail-biting" [...] and [...] "bit-flushing".|$|E
5000|$|<b>Convolutional</b> {{neural network}} - a <b>{{convolution}}al</b> neural net where the convolution is performed {{along the time}} axis of the data {{is very similar to}} a TDNN.|$|E
50|$|The channel {{encoding}} {{process in}} GPRS {{as well as}} EGPRS/EDGE consists of two steps: first, a cyclic code is used to add parity bits, which are {{also referred to as}} the Block Check Sequence, followed by coding with a possibly punctured <b>convolutional</b> code. In GPRS, the Coding Schemes CS-1 to CS-4 specify the number of parity bits generated by the cyclic code and the puncturing rate of the <b>convolutional</b> code. In GPRS Coding Schemes CS-1 through CS-3, the <b>convolutional</b> code is of rate 1/2, i.e. each input bit is converted into two coded bits. In Coding Schemes CS-2 and CS-3, the output of the <b>convolutional</b> code is punctured to achieve the desired code rate. In GPRS Coding Scheme CS-4, no <b>convolutional</b> coding is applied.|$|E
50|$|A <b>convolutional</b> {{neural network}} (CNN) is {{a class of}} deep, {{feed-forward}} networks, composed {{of one or more}} <b>convolutional</b> layers with fully connected layers (matching those in typical ANNs) on top. It uses tied weights and pooling layers. In particular, max-pooling is often structured via Fukushima's <b>convolutional</b> architecture. This architecture allows CNNs {{to take advantage of the}} 2D structure of input data.|$|E
50|$|<b>Convolutional</b> codes were {{introduced}} in 1955 by Peter Elias. It was thought that <b>convolutional</b> codes could be decoded with arbitrary quality {{at the expense of}} computation and delay. In 1967 Andrew Viterbi determined that <b>convolutional</b> codes could be maximum-likelihood decoded with reasonable complexity using time invariant trellis based decoders — the Viterbi algorithm. Other trellis-based decoder algorithms were later developed, including the BCJR decoding algorithm.|$|E
5000|$|Using the [...] "convolutional" [...] terminology, {{a classic}} <b>convolutional</b> code might be {{considered}} a Finite impulse response (FIR) filter, while a recursive <b>convolutional</b> code {{might be considered}} an Infinite impulse response (IIR) filter.|$|E
50|$|Simple Viterbi-decoded <b>convolutional</b> {{codes are}} now {{giving way to}} turbo codes, {{a new class of}} {{iterated}} short <b>convolutional</b> codes that closely approach the theoretical limits imposed by Shannon's theorem with much less decoding complexity than the Viterbi algorithm on the long <b>convolutional</b> codes that would be required for the same performance. Concatenation with an outer algebraic code (e.g., Reed-Solomon) addresses the issue of error floors inherent to turbo code designs.|$|E
5000|$|Free {{distance}} can {{be interpreted}} as the minimal length of an erroneous [...] "burst" [...] at the output of a <b>convolutional</b> decoder. The fact that errors appear as [...] "bursts" [...] should be accounted for when designing a concatenated code with an inner <b>convolutional</b> code. The popular solution for this problem is to interleave data before <b>convolutional</b> encoding, so that the outer block (usually Reed-Solomon) code can correct most of the errors.|$|E
50|$|In telecommunication, a <b>convolutional</b> code {{is a type}} of error-correcting {{code that}} generates parity symbols via the sliding {{application}} of a boolean polynomial function to a data stream. The sliding application represents the 'convolution' of the encoder over the data, which gives rise to the term 'convolutional coding.' The sliding nature of the <b>convolutional</b> codes facilitates trellis decoding using a time-invariant trellis. Time invariant trellis decoding allows <b>convolutional</b> codes to be maximum-likelihood soft-decision decoded with reasonable complexity.|$|E
50|$|Quantum <b>convolutional</b> {{stabilizer}} codes borrowheavily {{from the}} structure of their classical counterparts.Quantum <b>convolutional</b> codes are similar {{because some of the}} qubits feed backinto a repeated encoding unitary and give the code a memory structure likethat of a classical <b>convolutional</b> code. The quantum codes feature onlineencoding and decoding of qubits. This feature gives quantum convolutionalcodes both their low encoding and decoding complexity and their ability tocorrect a larger set of errors than a block code with similar parameters.|$|E
50|$|The {{first class}} of turbo code was the {{parallel}} concatenated <b>convolutional</b> code (PCCC). Since {{the introduction of}} the original parallel turbo codes in 1993, many other classes of turbo code have been discovered, including serial versions serial concatenated <b>convolutional</b> codes and repeat-accumulate codes. Iterative turbo decoding methods have also been applied to more conventional FEC systems, including Reed-Solomon corrected <b>convolutional</b> codes, although these systems are too complex for practical implementations of iterative decoders. Turbo equalization also flowed from the concept of turbo coding.|$|E
5000|$|Classical (algebraic) block {{codes and}} <b>convolutional</b> codes are {{frequently}} combined in concatenated coding schemes {{in which a}} short constraint-length Viterbi-decoded <b>convolutional</b> code {{does most of the}} work and a block code (usually Reed-Solomon) with larger symbol size and block length [...] "mops up" [...] any errors made by the <b>convolutional</b> decoder. Single pass decoding with this family of error correction codes can yield very low error rates, but for long range transmission conditions (like deep space) iterative decoding is recommended.|$|E
