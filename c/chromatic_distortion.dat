9|33|Public
25|$|In optics, {{chromatic}} aberration (abbreviated CA; also called <b>chromatic</b> <b>distortion</b> and spherochromatism) is an effect resulting from dispersion {{in which there}} is a failure of a lens to focus all colors to the same convergence point. It occurs because lenses have different refractive indices for different wavelengths of light. The refractive index of transparent materials decreases with increasing wavelength in degrees unique to each.|$|E
40|$|The use {{of color}} in QR codes brings extra data capacity, but also inflicts {{tremendous}} challenges on the decoding process due to <b>chromatic</b> <b>distortion,</b> cross-channel color interference and illumination variation. Particularly, we further discover {{a new type of}} <b>chromatic</b> <b>distortion</b> in high-density color QR codes, cross-module color interference, caused by the high density which also makes the geometric distortion correction more challenging. To address these problems, we propose two approaches, namely, LSVM-CMI and QDA-CMI, which jointly model these different types of <b>chromatic</b> <b>distortion.</b> Extended from SVM and QDA, respectively, both LSVM-CMI and QDA-CMI optimize over a particular objective function to learn a color classifier. Furthermore, a robust geometric transformation method is proposed to accurately correct the geometric distortion for high-density color QR codes. We put forth and implement a framework for high-capacity color QR codes equipped with our methods, called HiQ. To evaluate the performance of HiQ, we collect a challenging large-scale color QR code dataset, CUHK-CQRC, which consists of 5390 high-density color QR code samples. The comparison with the baseline method [2] on CUHK-CQRC shows that HiQ at least outperforms [2] by 188 % in decoding success rate and 60 % in bit error rate. Our implementation of HiQ in iOS and Android also demonstrates the effectiveness of our framework in real-world applications. Comment: 13 pages, 10 figures, submitted to IEEE Transaction on Image Processin...|$|E
40|$|Abstract: This paper {{presents}} {{an approach to}} correct <b>chromatic</b> <b>distortion</b> within an image (vignetting) and to compensate for color response differences among similar cameras which equip a team of robots, based on Evolutionary Algorithms. Our black-box approach does not make assumptions concerning the physical/geometrical roots of the distortion, and the efficient implementation is suitable for real time applications on resource constrained platforms. ...|$|E
50|$|Introducing colors into QR codes {{requires}} addressing additional issues. In particular, during QR code reading {{only the}} brightness information is taken into account, while HCC2D codes {{have to cope}} with <b>chromatic</b> <b>distortions</b> during the decoding phase. In order to ensure adaptation to <b>chromatic</b> <b>distortions</b> which arise in each scanned code, HCC2D codes make use of an additional field: the Color Palette Pattern. This is because color cells of a Color Palette Pattern are supposed to be distorted {{in the same way as}} color cells of the Encoding Region. Replicated color palettes are used for training machine learning classifiers.|$|R
40|$|Though a {{straight}} drift-quadrupole system {{can not be}} made an achromat, there exists an example of a bend-free drift-quadrupole system which can transport certain incoming beam ellipses without introducing first-order <b>chromatic</b> <b>distortions.</b> In this paper we show that such a possibility is not a rare special case, but a general property. For every drift-quadrupole system there exists an unique set of Twiss parameters, which will be transported through that system without first order <b>chromatic</b> <b>distortions.</b> Moreover, we prove {{that at the same time}} these Twiss parameters minimize the absolute values of the system chromaticities and also bring the second order effect of the betatron oscillations on the longitudinal dynamics to the minimal possible value. Comment: 3 pages, IPAC 1...|$|R
50|$|Symmetry was {{discovered}} in the 1850s to automatically correct the distortion, coma, and transverse <b>chromatic</b> <b>distortions.</b> There are also decentration aberrations arising from manufacturing errors. A real lens will not produce images of expected quality {{if it is not}} constructed to or cannot stay in specification.|$|R
40|$|It {{is shown}} that {{aspheric}} deformations {{of the first}} and fourth elements of the four element Ross objective can be introduced to permit one to obtain improved color corrections for astrometric purposes. The usual monochromatic aberrations are as well corrected as for the standard Ross lens. In addition, one can eliminate or reduce additional aberrations, such as secondary spectrum, chromatic spherical aberration, chromatic coma and <b>chromatic</b> <b>distortion.</b> The resulting objectives are suitable for use as intermediate and long focus astrometric objectives covering large angle fields...|$|E
40|$|Beams with helical phasefronts {{described}} by exp(iφ) carry an {{orbital angular momentum}} equivalent to ¯h per photon. Using diffractive optics this helical phase structure {{can be applied to}} every spectral component of the beam such that a spatially coherent white-light beam can carry orbital angular momentum without any <b>chromatic</b> <b>distortion.</b> This achromatic property can be hard to achieve in spin angular momentum where pure circular polarization is difficult to maintain across a finite spectral bandwidth. We illustrate the achromatic, helical phase structure of a white-light beam by observing the transfer of its orbital angular momentum to particles held in optical tweezers...|$|E
40|$|In {{this paper}} we study {{the effects of}} {{changing}} the operating laser wavelength on the projection lens aberrations of KrF and ArF scanners as measured by the Litel In-Situ Interferometer. Specifically, we quantify the change in 28 individual Zernike coefficients 1 as a function of wavelength as well as the total RMS. Effects on Zernikes exhibiting a field dependent behavior are described in detail. We convert the Z 4 terms to Z positions to estimate the displacement of the image plane, and we identify a new <b>chromatic</b> <b>distortion</b> term. Finally, we input the measured wavefronts into a lithographic simulator to estimate the full effects on image placement error...|$|E
50|$|The lens {{is renowned}} for having {{exceptional}} sharpness straight from its maximum aperture of f/2.8, {{with very little}} <b>chromatic</b> aberration, <b>distortion,</b> and vignetting.|$|R
50|$|Lens {{correction}} tools, such as <b>chromatic</b> aberration or <b>distortion</b> control.|$|R
3000|$|Blur as {{index of}} lack of sharpness. The {{corresponding}} measure is indicated as B in what follows. <b>Chromatic</b> zipper <b>distortion</b> (measure indicated as CD) Achromatic zipper distortion (measure indicated as AcD) [...]...|$|R
40|$|Atmosphere {{light value}} {{is a highly}} {{critical}} parameter in defogging algorithms {{that are based on}} an atmosphere scattering model. Any error in atmosphere light value will produce a direct impact on the accuracy of scattering computation and thus bring <b>chromatic</b> <b>distortion</b> to restored images. To address this problem, this paper propose a method that relies on clustering statistics to estimate atmosphere light value. It starts by selecting in the original image some potential atmosphere light source points, which are grouped into point clusters by means of clustering technique. From these clusters, a number of clusters containing candidate atmosphere light source points are selected, the points are then analyzed statistically, and the cluster containing the most candidate points is used for estimating atmosphere light value. The mean brightness vector of the candidate atmosphere light points in the chosen point cluster is taken as the estimate of atmosphere light value, while their geometric center in the image is accepted as the location of atmosphere light. Experimental results suggest that this statistics clustering method produces more accurate atmosphere brightness vectors and light source locations. This accuracy translates to, from a subjective perspective, more natural defogging effect {{on the one hand and}} to the improvement in various objective image quality indicators on the other hand...|$|E
40|$|A {{combined}} use of fluorescence {{and light}} microscopy {{is a powerful}} approach to further increase our understanding in biological systems of structure-function relations at cellular and sub-cellular levels. The power of fluorescence microscopy (FM) is to spectrally resolve and visualize individual proteins with endogenous or immuno- fluorescent labeling. Additionally, super-resolution microscopy techniques have beaten the diffraction limit and improved the achievable resolution in FM down to sub 20 nm. However, inherent to FM, {{it is only the}} labelled components that are visible and FM cannot provide the ultrastuctural information. On the other hand, electron microscopy (EM) has the power to visualize the ultrastructure with nanometer scale resolution. Therefore, correlative light and electron microscopy (CLEM), which brings the complementary information from FM and EM together, has gained deep interest in recent years. CLEM studies are typically carried out sequentially, by transferring the sample between two separate microscopes, which makes the process considerably cumbersome and therefore constrain widespread CLEM applications. A solution is proposed by integrated strategies, in which a light microscope is mostly integrated in an EM. We have also recently presented an integrated microscope design which enables high-resolution FM inside a Scanning EM (SEM) without compromises in the capabilities of both microscopes. This thesis aims to explore the potential of the integrated microscope for linking spectrally resolved and live-cell imaging capable FM with structural and high-resolution EM. The novel possibilities introduced by the integrated microscope are presented and discussed firstly for fixed and dehydrated samples, as typical samples in CLEM studies. Furthermore, CLEM of samples in hydrated conditions is realized, and a novel method, which enables on-demand SEM of living cells in liquid is demonstrated. Chapter II. introduces the method of Simultaneous Correlative Light and Electron Microscopy (SCLEM), which is a novel approach to CLEM brought up by the integrated microscope. The method is based on the new possibility to carry out both high-resolution light and electron microscopy simultaneously to the same region of a sample. The method makes it possible for fast and accurate acquisition of large CLEM datasets, and therefore for quantitative investigations of large sample areas. The correlation of high-NA fluorescence imaging with cellular ultrastructure is demonstrated for fluorescently labelled whole cells, as well as tissue sections stained both fluorescently and for EM. The optimized protocol for SCLEM, which aims to help other researchers to adapt their workflows to integrated CLEM, is presented in Chapter III. The complete sample preparation protocols for whole cells expressing endogenous fluorophores, for whole cells with immuno-labelling, and for resin embedded cells and tissues are presented together with the mounting procedure for the prepared samples in the integrated microscope. Also the imaging steps required to assure high accuracy registration between the FM and SEM images are explained and demonstrated comprehensively. Chapter IV. presents the enrichment of SCLEM with multi-color capabilities. Simultaneous dual-color FM and SEM is demonstrated by imaging cellular sections of Equine Arteritis Virus (EAV) infected cells, where EAV expresses GFP from its replicase gene and the nuclei/DNA of the infected cells are labelled with Hoechst. The chapter also shows that the method for FM-SEM image registration can also be used for <b>chromatic</b> <b>distortion</b> correction in between distinct FM color channels, which is crucial if the fluorescence information will be mapped onto high-resolution SEM images. The presented method is demonstrated by registering dual-color fluorescence images and a SEM images of paxillin and phospho-paxillin labelled cells into a single coordinate frame with a high precision. The rest of this thesis focuses on CLEM of samples in liquid, encapsulated in the integrated FM and SEM. Chapter V. investigates the achievable resolution in SEM imaging of liquid-immersed nanoparticle bio-labels in detail. Simulations with the Geant 4 -based Monte Carlo scheme are directly compared to the experimental results for nanoparticles located directly beneath SiN membranes of different thicknesses. The beam broadening, resulting from the interaction of the electron beam with the membrane, and the contrast forming mechanism was discussed and characterized. Also in liquid- SCLEM imaging of single epidermal growth factor (EGF) conjugated quantum dots docked at filopodia during cellular uptake is presented. Furthermore, the resolution and contrast for imaging nanoparticle bio-labels located not directly beneath the membrane but at different depths are investigated in Chapter VI. Some initial simulation and experimental results are presented which already shows that imaging single nanoparticle bio-labels is still feasible with reasonable resolution even under these conditions. The design and fabrication processes of the holder used for CLEM of liquid samples are presented in Chapter VII. The holder encapsulates liquid samples in the vacuum chamber of the integrated microscope and enables simultaneous correlative microscopy through the electron transparent and the light transparent windows it has. The detailed sample preparation process for correlative imaging of whole cells cultured directly on the electron transparent membranes, which brings new possibilities to study cells in their near native environment, is represented. Also the possibility of advancing the holder to a microfluidic reactor is discussed and proof-of concept experiments with consecutive filling and imaging in the reactor are demonstrated. Finally, Chapter VIII. presents the novel method of on-demand EM (ODEM), which merges the strengths of live-cell FM imaging with high resolution SEM. The cellular dynamics are monitored in liquid with live-cell FM, and SEM snapshots are captured at selected regions and time-points on-demand, based on the FM observations. ODEM is demonstrated by imaging the uptake and retrograde transport of EGF-conjugated quantum dots (QDots) in fibroblasts. ODEM is promising for opening up entirely novel perspectives for imaging biological dynamics by linking the live cell imaging capabilities of FM with high resolution structural EM imaging. Imaging Science & TechnologyApplied Science...|$|E
40|$|The first- and second-order optics for the Stanford Linear Collider (SLC) Arcs are {{designed}} to preserve the small transverse beam emittance while transporting electrons and positrons of * 0. 5 % energy spread from the linac to the Interaction Point. This paper describes the repetitive and special sections lattices, the orbit correction scheme to compensate field and alignment errors, {{and the results of}} the studies of the Arc optical properties. The effects on the beam of quantum emission, <b>chromatic</b> <b>distortions</b> and higher-order aberrations are discussed. Utilization of various computer programs for Arcs studies is described briefly. Relevance of this work to future linear colliders is pointed out...|$|R
50|$|The optics are {{exceptionally}} sharp {{across the}} frame from its maximum aperture of f/2.8. It {{has very little}} <b>distortion,</b> <b>chromatic</b> aberration, or vignetting.|$|R
40|$|Abstract— 2 D color {{barcodes}} {{have been}} introduced to obtain larger storage capabilities than traditional black and white barcodes. Unfortunately, the data density of color barcodes is substantially limited by the redundancy needed for correcting errors, which are due not only to geometric but also to <b>chromatic</b> <b>distortions</b> introduced by the printing and scanning process. The higher the expected error rate, the more redundancy is needed for avoiding failures in barcode reading, and thus, the lower the actual data density. Our work addresses this trade-off between reliability and data density in 2 D color barcodes and aims at identifying the most effective algorithms, in terms of byte error rate and computational overhead, for decoding 2 D color barcodes. In particular, we perform a thorough experimental study to identify the most suitable color classifiers for converting analog barcode cells to digital bit streams. I...|$|R
50|$|Compared to its {{predecessor}} (the Sony E 18-200mm F3.5-6.3 OSS), the lens discussed here is less sharp and suffers from greater <b>chromatic</b> aberration. However, <b>distortion</b> {{has been reduced}} in the new design.|$|R
5000|$|Modal {{dispersion}} {{should not}} be confused with <b>chromatic</b> dispersion, a <b>distortion</b> that results due to the differences in propagation velocity of different wavelengths of light. Modal dispersion occurs even with an ideal, monochromatic light source.|$|R
40|$|The {{matching}} {{function for}} the problem of stereo reconstruction or optical flow has been traditionally designed {{as a function of}} the distance between the features describing matched pixels. This approach works under assumption, that the appearance of pixels in two stereo cameras or in two consecutive video frames does not change dramatically. However, this might not be the case, if we try to match pixels over a large interval of time. In this paper we propose a method, which learns the matching function, that automatically finds the space of allowed changes in visual appearance, such as due to the motion blur, <b>chromatic</b> <b>distortions,</b> different colour calibration or seasonal changes. Furthermore, it automatically learns the importance of matching scores of contextual features at different relative locations and scales. Proposed classifier gives reliable estimations of pixel disparities already without any form of regularization. We evaluated our method on two standard problems - stereo matching on KITTI outdoor dataset, optical flow on Sintel data set, and on newly introduced TimeLapse change detection dataset. Our algorithm obtained very promising results comparable to the state-of-the-art. Comment: rejected from ACCV 2014 and probably from CVPR 201...|$|R
40|$|The paper {{describes}} a suitable algorithms pipeline able {{to enhance the}} picture quality of low cost imaging sensors, typically present in consumer devices (i. e. mobile phone, web-cams, PDA, etc) and accounts for compression artifacts, <b>chromatic</b> and geometric <b>distortions,</b> wrong exposure and poor sharpness...|$|R
30|$|For what {{concerns}} the chromatic zipper, the behavior is simpler. This artifact is more visible {{as the number}} of edge pixels in the image increases, {{and it seems to be}} immune to masking effects. For this reason we chose to discriminate between <b>chromatic</b> and achromatic <b>distortion.</b>|$|R
50|$|Chester Moore Hall (9 December 1703, Leigh, Essex, England - 17 March 1771, Sutton, Surrey) was a British {{lawyer and}} {{inventor}} who produced the first achromatic lenses in 1729 or 1733 (accounts differ).He used the achromatic lens {{to build the}} first refracting telescope free from <b>chromatic</b> aberration (colour <b>distortion).</b>|$|R
40|$|<b>Chromatic</b> {{aberration}} <b>distortions</b> such as wavelength-dependent blur {{are caused}} by imperfections in photographic lenses. These distortions are much more severe {{in the case of}} color and near-infrared joint acquisition, as a wider band of wavelengths is captured. In this paper, we consider a scenario where the color image is in focus, and the NIR image captured with the same lens and same focus settings is out-of-focus and blurred. To reduce <b>chromatic</b> aberration <b>distortions,</b> we propose an algorithm that estimates the blur kernel and deblurs the NIR image using the sharp color image as a guide in both steps. In the deblurring step, we retrieve the lost details of the NIR image by exploiting the sharp edges of the color image, as the gradients of color and NIR images are often correlated. However, differences of scene reflections and light in visible and NIR bands cause the gradients of color and NIR images to be different in some regions of the image. To handle this issue, our algorithm measures the similarities and differences between the gradients of the NIR and color channels. The similarity measures guide the deblurring algorithm to efficiently exploit the gradients of the color image in reconstructing high-frequency details of NIR, without discarding the inherent differences between these images. Simulation results verify the effectiveness of our algorithm, both in estimating the blur kernel and deblurring the NIR image, without producing ringing artifacts inherent to the results of most deblurring methods...|$|R
40|$|Background Angioscopy surpasses other {{diagnostic}} tools, such as angiography and intravascular ultrasound, {{in detecting}} arterial thrombus. This capability arises {{in part from}} the unique ability of angioscopy to assess true color during imaging. In practice, hardware-induced <b>chromatic</b> <b>distortions</b> and the subjectivity of human color perception substantially limit the theoretic potential of angioscopic color. We used a novel application of tristimulus colorimetry to quantify thrombus color to both aid in its detection and assess its composition. Methods and Results A series of human thrombus models were constructed in vitro. Spatial homogeneity was ensured by light and electron microscopy. Quantitative colorimetric angioscopic analysis demonstrated excellent measurement reproducibility (mean difference, 0. 07 % to 0. 17 %), unaffected by illuminating light intensity (coefficient of variation, 0. 21 % to 3. 67 %). Colorimetric parameters C 1 and C 2 were strongly correlated (r=. 99, P<. 0001) with thrombus erythrocyte concentration. Principal components analysis transformed these parameters into a single value, the thrombus erythrocyte index, with little (0. 06 %) loss of content. Measured and predicted concentrations were similar (mean difference, 0. 16 erythrocytes per 1 ng). Randomly ordered images were also subjected to visual analysis by three experienced angioscopists, with suboptimal levels of both intraobserver (mean = 0. 63) and interobserver (mean = 0. 48) agreement. In addition, visual ranking resulted in a Kendall rank coefficient of 0. 72 to 0. 76 versus a perfect 1. 00 from quantitative measurement. Conclusions Quantitative colorimetric angioscopic analysis provides a new, objective, and reproducible analytic tool for assessing angioscopic images of human thrombus. Even under ideal circumstances, experienced angioscopists do a poor job of assessing color (and therefore composition) of human thrombi. This technique can, for the first time, provide quantitative information of thrombus composition during routine diagnostic imaging...|$|R
50|$|These eyepieces {{work well}} with the very long focal length telescopes (in Huygens day they were used with single element long focal length non-achromatic refracting telescopes, {{including}} very long focal length aerial telescopes). This optical design is now considered obsolete since with today's shorter focal length telescopes the eyepiece suffers from short eye relief, high image <b>distortion,</b> <b>chromatic</b> aberration, and a very narrow apparent field of view. Since these eyepieces are cheap to make they can often be found on inexpensive telescopes and microscopes.|$|R
40|$|Abstract — The paper {{describes}} a suitable algorithms pipeline able {{to enhance the}} picture quality {{in terms of both}} measured and perceived quality. The overall pipeline is mainly devoted to improve image acquired by low cost imaging sensors, typically present in consumer devices (i. e. mobile phone, web-cams, PDA, etc). A series of ad-hoc heuristics and techniques have been applied, taking into account main compression artifacts, <b>chromatic</b> and geometric <b>distortions,</b> etc [...] Experimental results show effectiveness of the proposed pipeline. Index Terms — Adaptive sharpness, exposure correction, de-blocking, JPEG, white balancing...|$|R
40|$|Modern {{techniques}} for medical diagnosis and therapy make considerable use of endoscopes. Unfortunately, the wide-angle characteristic of endoscopes introduce severe aberrations such as <b>chromatic</b> aberration, geometric <b>distortion</b> or comb-structure to the images. The aberrations hinder or at worst prevent {{the application of}} fundamental image processing {{techniques for}} an appropriate image analysis. In this paper, we propose a uniform ray-tracing based image model for rigid as well as fiber-optic endoscopes. This model enables an objective assessment of algorithms that rely on the image formation using physically correct and thus valid ground truth data...|$|R
40|$|To {{achieve a}} {{realistic}} integration of virtual and real imagery in video see-through augmented reality, the rendered images {{should have a}} similar appearance and quality to those captured by the video camera. This paper describes a compositing method which models the artefacts produced by a small low-cost camera, and adds these effects to an ideal pinhole image produced by conventional rendering methods. We attempt to model and simulate {{each step of the}} imaging process, including <b>distortions,</b> <b>chromatic</b> aberrations, blur, bayer masking, noise and colour-space compression, all while requiring only an RGBA image and an estimate of camera velocity as inputs. © 2008 IEEE...|$|R
30|$|We here {{propose a}} no-reference metric to assess image quality {{in case of}} demosaicing {{artifact}} that combines measures of blurriness (intended as lack of sharpness), <b>chromatic</b> and achromatic <b>distortions</b> and fits the psycho-visual data. Several full-reference metrics exist {{for this kind of}} artifact [6], while the literature is poor in no-reference ones. Some no-reference sharpness metrics [7, 8] could be adopted, but they can not take into account typical chromatic and achromatic zipper effects. Liu et al. [9] have recently presented a no-reference method for CFA demosaicing based on double interpolation and have evaluated several demosaicing algorithms. However this metric has not been correlated with psycho-visual experiments.|$|R
40|$|Video see-through Augmented Reality adds {{computer}} graphics {{to the real}} world in real time by overlaying graphics onto a live video feed. To achieve a realistic integration of the virtual and real imagery, the rendered images should have a similar appearance and quality to those produced by the video camera. This paper describes a compositing method which models the artifacts produced by a small low-cost camera, and adds these effects to an ideal pinhole image produced by conventional rendering methods. We attempt to model and simulate each step of the imaging process, including <b>distortions,</b> <b>chromatic</b> aberrations, blur, Bayer masking, noise, sharpening, and color-space compression, all while requiring only an RGBA image and an estimate of camera velocity as inputs...|$|R
30|$|This {{paper is}} {{organized}} as follows. In Demosaicing section we briefly describe the demosaicing process, while in Psycho-visual setup section we describe {{how we have}} generated the dataset utilized during our tests and the psycho-visual experiments that we have conducted to rank the chosen algorithms. From {{the analysis of the}} experimental data (detailed in Data analysis section), we propose our novel no-reference metric, described in No-reference metric for Demosaicing section, based on measures of blurriness, <b>chromatic</b> and achromatic <b>distortions.</b> In Metric parameter estimation section we report details of the regression we have proposed to fit the subjective data and we compare our metric with a reference one [9]. All the psycho-visual data presented and the corresponding distorted images are available at [URL] Finally, in Section Methods we report details on the testing methodology adopted here.|$|R
40|$|Aspheres with no {{rotational}} symmetry offer new perspectives {{for the development}} of high power laser optics. Confronted with the dynamic range of the manufacturing process recently opened by scientists in ultra-precision engineering, interferometric form testing is having to meet the challenge posed by complex mirror shapes with high local slopes andlor stepheights exceeding the range of unambiguity which conventional interferometry can handle. For this reason, special interferometric techniques such as Two-Wavelength- Interferometry, Sub-Nyquist- and Sub-Aperture- approaches are to be combined, to overcome the above mentioned problems. But even if the refined experimental setup is capable of resolving the interferometric fringe pattern, the question as to how the data collected should be interpreted, is extremely time-consuming. The use of ray-tracing software in experimental setups with <b>chromatic</b> aberrations or <b>distortions</b> is, therefore inevitable, building a theoretical background to distinguish between system and manufacturing error...|$|R
50|$|The biggest {{advantage}} of catadioptric systems (panoramic mirror lenses) {{is that because}} one uses mirrors to bend the light rays instead of lenses (like fish eye), the image has almost no <b>chromatic</b> aberrations or <b>distortions.</b> The image, {{a reflection of the}} surface on the mirror, {{is in the form of}} a doughnut to which software is applied in order to create a flat panoramic picture. Such software is normally supplied by the company who produces the system. Because the complete panorama is imaged at once, dynamic scenes can be captured without problems. Panoramic video can be captured and has found applications in robotics and journalism. The mirror lens system uses only a partial section of the digital camera's sensor and therefore some pixels are not used. Recommendations are always to use a camera with a high pixel count in order to maximize the resolution of the final image.|$|R
30|$|The present work {{concerns}} {{the analysis of}} how demosaicing artifacts affect image quality and proposes a novel no-reference metric for their quantification. This metric that fits the psycho-visual data obtained by an experiment analyzes the perceived distortions produced by demosaicing algorithms. The demosaicing operation consists {{of a combination of}} color interpolation (CI) and anti-aliasing (AA) algorithms and converts a raw image acquired with a single sensor array, overlaid with a color filter array, into a full-color image. The most prominent artifact generated by demosaicing algorithms is called zipper. The zipper artifact is characterized by segments (zips) with an On–Off pattern. We perform psycho-visual experiments on a dataset of images that covers nine different degrees of distortions, obtained using three CI algorithms combined with two AA algorithms. We then propose our no-reference metric based on measures of blurriness, <b>chromatic</b> and achromatic <b>distortions</b> to fit the psycho-visual data. With this metric demosaicing algorithms could be evaluated and compared.|$|R
40|$|This work is {{focussed}} {{on different}} unwanted effects that damage a digitally acquired image. An image acquired using {{a digital camera}} can suffer {{from a series of}} defects. First, the noise is concerned. It occures due to discretisation. Next, there are the defects including vignetting, radial image <b>distortion,</b> <b>chromatic</b> aberration. In my thesis I also worked on backlight image compensation and panorama creation from an image sequence. For backlight images we need to increase the brightness in the dark parts of the image, so that the details became more visible. At panorama creation we are careful about brightness evenness in partial images, which is usually not conserved and consequently we try to find a suitable boundary-line to connect images and smooth it. The fundamental part of my work was writing the algorithms that are able to compensate these defects at least partly. For this aim I took use of the Matlab environment...|$|R
