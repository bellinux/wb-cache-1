23|11|Public
50|$|Alok R. Chaturvedi is a Professor of Information Systems and {{the founder}} and the Director of SEAS Laboratory at the Krannert School of Management, Purdue University. His {{research}} is focused on using artificial intelligence, <b>computational</b> <b>ecology,</b> and enterprise integration for wargaming enterprise situations. He received a Ph.D. (1989) and M.S (1985) in Management Information Systems from the University of Wisconsin-Milwaukee and a B.Sc (1980) in Mechanical Engineering from B.I.T Ranchi (India).|$|E
50|$|Cells {{in silico}} are placed into this <b>computational</b> <b>ecology</b> {{and allowed to}} {{compete with each other}} for resources. The {{distribution}} of resources is set in a temporal dependent manner. During each round, random mutations and perturbations are introduced to the biochemical pathways. At the end of each round, the cells with the lowest energy count are eliminated. This selects for cells that are able to maximize energy uptake by optimizing the expression of its pathways in a particular time period.|$|E
40|$|<b>Computational</b> <b>Ecology</b> and Software ISSN 2220 - 721 X URL: [URL] RSS: [URL] E-mail: ces@iaees. org Editor-in-Chief: WenJun Zhang Aims and Scope <b>COMPUTATIONAL</b> <b>ECOLOGY</b> AND SOFTWARE (ISSN 2220 - 721 X) {{is an open}} access, peer-reviewed {{online journal}} that {{considers}} scientific articles in all different areas of <b>computational</b> <b>ecology.</b> It is the transactions of the International Society of <b>Computational</b> <b>Ecology.</b> The journal {{is concerned with the}} ecological researches, constructions and applications of theories and methods of computational sciences including computational mathematics, computational statistics and computer science. It features the simulation, approximation, prediction, recognition, and classification of ecological issues. Intensive computation {{is one of the major}} stresses of the journal. The journal welcomes research articles, short communications, review articles, perspectives, and book reviews. The journal also supports the activities of the International Society of <b>Computational</b> <b>Ecology.</b> The topics to be covered by CES include, but are not limited to: •Computation intensive methods, numerical and optimization methods, differential and difference equation modeling and simulation, prediction, recognition, classification, statistical computation (Bayesian computing, randomization, bootstrapping, Monte Carlo techniques, stochastic process, etc.), agent-based modeling, individual-based modeling, artificial neural networks, knowledge based systems, machine learning, genetic algorithms, data exploration, network analysis and computation, databases, ecological modeling and computation using Geographical Information Systems, satellite imagery, and other computation intensive theories and methods. •Artificial ecosystems, artificial life, complexity of ecosystems and virtual reality. •The development, evaluation and validation of software and algorithms for <b>computational</b> <b>ecology.</b> The development and evaluation of apparatus, instruments and machines for ecological and environmental analysis, investigation and monitoring based on the software of <b>computational</b> <b>ecology.</b> •Methodological applications of <b>computational</b> <b>ecology</b> in the researches of ecology and environmental sciences. Authors can submit their works to the email box of this journal, ces@iaees. org. All manuscripts submitted to this journal must be previously unpublished and may not be considered for publication elsewhere at any time during review period of this journal. Authors are asked to read Author Guidelines before submitting manuscripts. In addition to free submissions from authors around the world, special issues are also accepted. The organizer of a special issue can collect submissions (yielded from a research project, a research group, etc.) on a specific research topic, or submissions of a scientific conference for publication of special issue...|$|E
5000|$|Carl Boettiger, Theory and <b>computational</b> {{modeling}} in <b>ecology</b> and evolution.|$|R
40|$|Carl A. Waldspurger. Priority Flow: A {{framework}} for abstract, adaptive resource management. MIT LCS Parallel Software Group, Internal Memo (unpublished), May 1990. 32 [13] Carl Hewitt. The challenge of open systems. Byte, 10 : 223 242, April 1985. [14] Bernardo A. Huberman and Tad Hogg. The behavior of <b>computational</b> <b>ecologies.</b> In B. A. Huberman editor, The Ecology of Computation, pages 77 115. North-Holland, Amsterdam, 1988. [15] Kenneth M. Kahn and Mark S. Miller. Language design and open systems. In Bernardo A. Huberman editor, The Ecology of Computation, pages 291 313. North-Holland, Amsterdam, 1988. [16] Kenneth M. Kahn and Vijay A. Saraswat. Money as a concurrent logic program. Technical report, Xerox PARC, 1989. [17] Jeffrey O. Kephart, Tad Hogg, and Bernardo A. Huberman. Dynamics of computational ecosystems. Physical Review A, 40 : 404 421, 1989. [18] Douglas B. Lenat. The role of heuristics in learning by discovery: Three case studies. In R. S. Michalski et. al., ed...|$|R
5000|$|Plant and Microbial Biology {{encompasses}} {{theoretical and}} applied research in <b>ecology,</b> <b>computational</b> biology, genomics, host-microbe interactions, physiology, and biochemistry. It offers a Ph.D. in Plant or Microbial Biology, and oversees two similarly named undergraduate major programs. PMB is chaired by Kris Niyogi.|$|R
40|$|The {{last ten}} years have been marked by {{important}} discoveries and scientific advances {{in our understanding of}} biodiversity. The emergence of new fields, such as bioinformatics, ecoinformatics, and <b>computational</b> <b>ecology</b> (Helly et al., 1995; Spengler, 2000; Green et al., 2005) has brought about an informationa...|$|E
40|$|A book, Computational Ecology: Artificial Neural Networks and Their Applications, {{published}} in 2010, was introduced and reviewed. This book provides readers with deep insights on algorithms, codes, and applications of artificial neural networks in ecology. A science discipline, <b>computational</b> <b>ecology,</b> is clearly defined and {{outlined in the}} book...|$|E
40|$|We {{present a}} variant of the Q-learning {{algorithm}} with automatic control of the exploration rate by a competition scheme. The theoretical approach is accompanied by systematic simulations of a chaos control task. Finally, we give interpretations of the algorithm in the context of <b>computational</b> <b>ecology</b> and neural networks. I...|$|E
50|$|The journal's {{focus is}} {{theoretical}} biology which includes mathematical representation, treatment, and modeling for simulations and quantitative descriptions. The journal's focus {{also includes the}} philosophy of biology which emphasizes looking at the methods developed to form biological theory. Topical coverage also includes biomathematics, <b>computational</b> biology, genetics, <b>ecology,</b> and morphology.|$|R
40|$|In {{recent years}} {{there has been}} a great deal of {{interest}} in "scientific workflows". These allow scientists to specify large computational experiments involving a range of different activities, such as data integration, modelling and analysis, and visualization, to name a few. Activities can be composed, often using a graphical programming environment, so that the output of one stage can be passed as input to the next, forming a pipeline of arbitrary complexity. Scientific workflows have been used to great effect in a number of different disciplines including <b>computational</b> chemistry, <b>ecology</b> and bioinformatics...|$|R
5000|$|Louis J. Gross (born January 6, 1952) is {{distinguished}} professor of ecology and evolutionary biology and mathematics at the University of Tennessee. [...] He is the founding director of the National Institute for Mathematical and Biological Synthesis and the Institute for Environmental Modeling. His research focuses on <b>computational</b> and mathematical <b>ecology,</b> with applications to plant physiological ecology, conservation biology, natural resource management, and landscape ecology.|$|R
40|$|<b>Computational</b> <b>ecology</b> {{is a field}} {{devoted to}} the {{quantitative}} description and analysis of ecological systems using empirical data, mathematical models (including statistical models), and computational technology. While the components of this field are not new, {{there is a new}} emphasis on the integrated treatment of the area. To a large degree, this emphasis is precipitated by the expansion of our local, national, and international computational infrastructure, coupled with the heightened social awareness of ecological and environmental issues and its effects on research funding. In an attempt to consolidate what is known about the state-of-practice in <b>computational</b> <b>ecology,</b> a workshop was held gathering together ecologists and computer scientists for the purpose of identifying those technology issues which impede the progress of ecological research. This workshop was held at the San Diego Supercomputer Center in September 1995. The results of the workshop are expressed in three areas: da [...] ...|$|E
40|$|We analyze {{evolutionary}} {{trends in}} artificial neural dynamics and network architectures specified by haploid genomes in the Polyworld <b>computational</b> <b>ecology.</b> We discover consistent trends in neural connection densities, synaptic weights and learning rates, entropy, mutual information, and an information-theoretic measure of complexity. In particular, we observe a consistent trend towards greater structural elaboration and adaptability, with a concomitant and statistically significant growth in neural complexity...|$|E
40|$|We {{investigate}} the matching of agents to resources in a <b>computational</b> <b>ecology</b> configured to present heterogeneous resource patches to evolving, neurally controlled agents. We repeatedly find a nearly optimal, ideal free distribution (IFD) of agents to resources. Deviations from IFD are {{shown to be}} consistent with models of human foraging behaviors, and possibly driven by spatial constraints and maximum foraging rates. The lack of any model parameters addressing agent foraging or clustering behaviors and the biological verisimilitude of our agent control systems differentiates these results from simpler models and suggests the possibility of exploring the underlying mechanisms by which optimal foraging emerges. Comment: 7 page...|$|E
40|$|Increasingly {{powerful}} {{computers are}} making possible distributed systems comprised of many adaptive and self-motivated computational agents. Such systems, when distinguished by system-level performance criteria, {{are known as}} "collectives. " Collectives and the Design of Complex Systems lays {{the foundation for a}} science of collectives and describes how to design them for optimal performance. An introductory survey chapter is followed by descriptions of information-processing problems that can only be solved by the joint actions of large communities of computers, each running its own complex, decentralized machine-learning algorithm. Subsequent chapters analyze the dynamics and structures of collectives, as well as address economic, model-free, and control-theory approaches to designing complex systems. The work assumes a modest understanding of basic statistics and calculus. Topics and Features: Introduces the burgeoning science of collectives and its practical applications in a single useful volume Combines approaches from known researchers in the physics, economics, game theory, biology, and artificial intelligence (A. I.) communities Analyzes the role of information transmission in collectives, such as in the minority game, specific game theory scenarios, and <b>computational</b> <b>ecologies</b> Presents a broad view of state-of-the-art techniques and developments in the field Describes the benefits and promise of collectives-based design of systems, and explores recent challenges faced by researchers Highlights the interdisciplinary value to studying and using collectives Provides a comprehensive subject index and chapter-ending bibliographies With an accessible style that integrates key theoretical principles with applications in real-world scenarios, this unique monograph surveys the latest research on the dynamics of collectives, their A. I. -related aspects, and critical design issues pertaining to them. Computer scientists, computer engineers, and practitioners, researchers, and graduate students with an interest in this new and growing field will find the book an authoritative introduction and resource...|$|R
40|$|This report {{documents}} {{the program and}} the outcomes of Dagstuhl Seminar 14132 "Interaction and Collective Movement Processing 2 ̆ 72 ̆ 7. This seminar brought together a group of 30 scientists with varied backgrounds, but with a shared interest in computations involved in the processing of moving entity data, like humans or animals. The seminar focused on characterizing and modelling interaction between moving entities, and featured four invited talks in four main research fields: <b>ecology,</b> <b>computational</b> geometry, GIScience, and collective motion. The remainder of the program consisted of short presentations, open problem sessions, break-out groups to work on open problems, and reporting sessions based on research done in the break-out groups...|$|R
30|$|In recent years, {{parallel}} {{developments in}} disparate disciplines {{have focused on}} {{what has come to}} be termed connectivity; a concept used in understanding and describing complex systems. Conceptualisations and operationalisations of connectivity have evolved largely within their disciplinary boundaries, yet similarities in this concept and its application among disciplines are evident. However, any implementation of the concept of connectivity carries with it both ontological and epistemological constraints, which leads us to ask if there is one type or set of approach(es) to connectivity that might be applied to all disciplines. In this review we explore four ontological and epistemological challenges in using connectivity to understand complex systems from the standpoint of widely different disciplines. These are: (i) defining the fundamental unit for the study of connectivity; (ii) separating structural connectivity from functional connectivity; (iii) understanding emergent behaviour; and (iv) measuring connectivity. We draw upon discipline-specific insights from <b>Computational</b> Neuroscience, <b>Ecology,</b> Geomorphology, Neuroscience, Social Network Science and Systems Biology to explore the use of connectivity among these disciplines. We evaluate how a connectivity-based approach has generated new understanding of structural-functional relationships that characterise complex systems and propose a ‘common toolbox’ underpinned by network-based approaches that can advance connectivity studies by overcoming existing constraints.|$|R
40|$|MSc(Eng),Faculty of Engineering and the Built Environment, University of the Witwatersrand, 2010 This {{dissertation}} presents {{two important}} results: a novel algorithm that approximately solves the optimal assignment problem {{as well as}} a novel method of projecting matrices into the doubly stochastic polytope while preserving the optimal assignment. The optimal assignment problem is a classical combinatorial optimisation problem that has fuelled extensive research in the last century. The problem is concerned with a matching or assignment of elements in one set to those in another set in an optimal manner. It finds typical application in logistical optimisation such as the matching of operators and machines but there are numerous other applications. In this document a process of iterative weighted normalization applied to the benefit matrix associated with the Assignment problem is considered. This process is derived from the application of the <b>Computational</b> <b>Ecology</b> Model to the assignment problem and referred to as the OACE (Optimal Assignment by <b>Computational</b> <b>Ecology)</b> algorithm. This simple process of iterative weighted normalisation converges towards a matrix that is easily converted to a permutation matrix corresponding to the optimal assignment or an assignment close to optimality. The document also considers a method of projecting a matrix into the doubly stochastic polytope while preserving the optimal assignment. Various methods of projecting square matrices into the doubly stochastic polytope exist but none that preserve the assignment. This novel result could prove instrumental in solving assignment problems and promises applications in other optimisation algorithms similar to those that Sinkhorn’s algorithm finds...|$|E
40|$|In ecology, the {{patterns}} usually refer {{to all kinds}} of nonrandom spatial and temporal structures of ecosystems driving by multiple ecological processes. Pattern recognition is an important step to reveal the complicated relationship between ecological patterns and processes. To review and present some advances about ecological modeling, patterns recognition, and computer simulation, an international workshop on Mathematical and Numerical Ecology with the theme "Pattern recognition and simulation in ecology" was held in in October 2014 in Guangzhou, China, and the International Society of <b>Computational</b> <b>Ecology</b> was the co-sponsor. Eight peer-reviewed papers those were originally presented at this workshop covering three themes: patterns in phylogeny, patterns in communities and ecosystems, and spatial pattern analysis are included in this special issue. ...|$|E
40|$|Abstract. We propose an IBM for clonal plant dynamics, {{focusing}} {{on the effects of}} the network structure of the plants on the reproductive strategy of ramets. After some numerical tests we propose a large population approximation as an advection-diffusion PDE for population densities. 1 The model Individual-based models are in constant development in <b>computational</b> <b>ecology.</b> These models aim to represent the dynamics of populations, they explicitly describe each individual as well as each mechanism acting on these individuals. Here we consider a model for a clonal plant: At time t it is represented as a set of nodes (ramets) that may be connected by links (rhizomes or stolons), see Figure 1. The state of the nodes is described by: νt = ∑Nt i= 1 δxi t, xit ∈ D def = [x (1) min, x(1) max] × [x(2) min, x(2) max...|$|E
50|$|The journal {{was founded}} as the {{official}} publication of the Society for Research on Biological Rhythms. It released its first issue in March 1986, under first editor-in-chief Ben Rusak, who served from 1986 to 1994. The original Associate Editors were Gene Block, Serge Daan, Jerry Feldman, Bruce Goldman, Mike Menaker, Bob Moore, and Terry Page. The first issue largely focused on zoology and physiology, {{but over the years}} the field of discussion has expanded to include neurobiology, cell and molecular biology, photobiology, <b>computational</b> biology, behavioral <b>ecology,</b> and translational medicine. Early experiments focused on Syrian and Siberian hamsters, ground squirrels, and bubble snails. Since those first publications, experimental subjects represented in the journal have grown to be more diverse, as well as the techniques used to research them. The techniques mentioned in the first few publications involved behavioral and physiological monitoring, circumscribed brain lesions, melatonin radioimmunoassays, electroretinography, and electrophysiological recordings. Early research topics included “splitting,” circannual rhythmicity, photoperiodic time measurement, and circadian pacemaker development, coupling, and output.|$|R
40|$|Over {{the last}} two decades, macroecology – the {{analysis}} of large-scale, multi-species ecological patterns and processes – has established itself as a major line of biological research. Analyses of statistical links between environmental variables and biotic responses have long and successfully been employed as a main approach, but new developments are due to be utilized. Scanning the horizon of macroecology, the European and Australian authors of this paper identified four challenges that will probably {{play a major role}} in the future. They support their claims by examples and bibliographic analyses. 1) Integrating the past into macroecological analyses, e. g. by using paleontological or phylogenetic information or by applying methods from historical biogeography, will sharpen our understanding of the underlying reasons for contemporary patterns. 2) Explicit consideration of the local processes that lead to the observed larger-scale patterns is necessary to understand the fine-grain variability found in nature, and will enable better prediction of future patterns (e. g. under environmental change conditions). 3) Macroecology is dependent on large-scale, high quality data from a broad spectrum of taxa and regions. More available data sources need to be tapped and new, small-grain large-extent data need to be collected. 4) Although macroecology already lead to mainstreaming cutting-edge statistical analysis techniques, they find that more sophisticated methods are needed to account for the biases inherent to sampling at large scale. Bayesian methods may be particularly suitable to address these challenges. To continue the vigorous development of the macroecological research agenda, it is time to address these challenges and to avoid becoming too complacent with current achievements. Authors: Jan Beck, Liliana Ballesteros-Mejia, Carsten M. Buchmann, Jürgen Dengler, Susanne A. Fritz, Bernd Gruber, Christian Hof, Florian Jansen, Sonja Knapp, Holger Kreft, Anne-Kathrin Schneider, Marten Winter and Carsten F. Dormann. J. Beck (jan. beck@unibas. ch) and L. Ballesteros-Mejia, Univ. of Basel, Dept of Environmental Sciences (Biogeography), CH- 4056 Basel, Switzerland. – C. M. Buchmann, Univ. of Potsdam, Dept of Plant Ecology and Nature Conservation, DE- 14469 Potsdam, Germany. – J. Dengler, Univ. of Hamburg, Biocentre Klein Flottbek and Botanical Garden, Biodiversity, Evolution and Ecology of Plants, DE- 22609 Hamburg, Germany. – S. A. Fritz and C. Hof, Univ. of Copenhagen, Center for Macroecology, Evolution and Climate, Dept of Biology, DK- 2100 Copenhagen, Denmark. Present address of SAF and CH: Biodiversity and Climate Research Centre (BiK-F) and Senckenberg Gesellschaft für Naturforschung, DE- 60325 Frankfurt, Germany. – B. Gruber, Univ. of Canberra, Faculty of Applied Science, Inst. for Applied Ecology, ACT 2601 Canberra, Australia. – F. Jansen, Ernst-Moritz-Arndt-Univ., Inst. of Botany and Landscape Ecology, DE- 17487 Greifswald, Germany. – S. Knapp and M. Winter, UFZ – Helmholtz Centre for Environmental Research, Dept of Community Ecology, DE- 06120 Halle (Saale), Germany. – H. Kreft, Univ. of Göttingen, Faculty of Forest Sciences and Forest Ecology, Biodiversity, Macroecology, and Conservation Biogeography group, DE- 37077 Göttingen, Germany. – A. -K. Schneider, Leibniz-Center for Agricultural Landscape Research (ZALF), DE- 15374 Müncheberg, Germany. Present address for A-KS: Univ. of Potsdam, Inst. for Earth- and Environmental Sciences, DE- 14476 Potsdam, Germany. – C. F. Dormann, UFZ – Helmholtz, Centre for Environmental Research, Dept of <b>Computational</b> Landscape <b>Ecology,</b> DE- 04318 Leipzig, Germany and Univ. of Freiburg, Biometry and Environmental System Analysis, DE- 79106 Freiburg, Germany...|$|R
40|$|<b>Computational</b> <b>ecology</b> is an {{emerging}} interdisciplinary discipline founded mainly on {{modeling and simulation}} methods for studying ecological systems. Among the existing modeling formalisms, the individual-based modeling is particularly well suited for capturing the complex temporal and spatial dynamics {{as well as the}} nonlinearities arising in ecosystems, communities or populations due to individual variability. In addition, being a bottom up approach, it is useful for providing new insights on the local mechanisms which are generating some observed global dynamics. Of course no conclusions about model results could be taken seriously if they are based on a single model execution and they are not analyzed carefully. Therefore, a sound methodology should always be used for underpinning the interpretation of model results. The sensitivity analysis is a methodology for quantitatively assessing the effect of input uncertainty in the simulation output which should be incorporated compulsorily to every work based on in silico experimental setup. In this paper we present R/Repast a GNU R package for running and analyzing Repast Simphony models accompanied by two worked examples on how to perform global sensitivity analysis and how to interpret the results...|$|E
40|$|The {{challenges}} {{posed by}} complex stochastic models used in <b>computational</b> <b>ecology,</b> biology and genetics have stimulated {{the development of}} approximate approaches to statistical inference. Here we focus on Synthetic Likelihood (SL), a procedure that reduces the observed and simulated data {{to a set of}} summary statistics, and quantifies the discrepancy between them through a synthetic likelihood function. SL requires little tuning, but it relies on the approximate normality of the summary statistics. We relax this assumption by proposing a novel, more flexible, density estimator: the Extended Empirical Saddlepoint approximation. In addition to proving the consistency of SL, under either the new or the Gaussian density estimator, we illustrate the method using two examples. One of these is a complex individual-based forest model for which SL offers one of the few practical possibilities for statistical inference. The examples show that the new density estimator is able to capture large departures from normality, while being scalable to high dimensions, and this in turn leads to more accurate parameter estimates, relative to the Gaussian alternative. The new density estimator is implemented by the esaddle R package, which {{can be found on the}} Comprehensive R Archive Network (CRAN) ...|$|E
40|$|A Bayesian {{approach}} to model comparison {{based on the}} integrated or marginal likelihood is considered, and applications to linear regression models and nonlinear ordinary differential equation (ODE) models are used as the setting in which to elucidate and further develop existing statistical methodology. The focus is on two methods of marginal likelihood estimation. First, a statistical failure of the widely employed Posterior Harmonic Mean estimator is highlighted. It is demonstrated {{that there is a}} systematic bias capable of significantly skewing Bayes factor estimates, which has not previously been highlighted in the literature. Second, a detailed study of the recently proposed Thermodynamic Integral estimator is presented, which characterises the error associated with its discrete form. An experimental study using analytically tractable linear regression models highlights substantial differences with recently published results regarding optimal discretisation. Finally, with the insights gained, it is demonstrated how Population MCMC and thermodynamic integration methods may be elegantly combined to estimate Bayes factors accurately enough to discriminate between nonlinear models based on systems of ODEs, which has important application in describing the behaviour of complex processes arising {{in a wide variety of}} research areas, such as Systems Biology, <b>Computational</b> <b>Ecology</b> and Chemical Engineering. (C) 2009 Elsevier B. V. All rights reserve...|$|E
40|$|Seabird {{populations are}} a {{valuable}} and accessible indicator of marine health: population {{changes have been}} linked with fish stock levels, climate change, and pollution. Understanding the development of particular colonies requires detailed data, but manual collection methods are labour intensive and error prone. Our work is concerned with development of computer vision algorithms to support autonomous visual monitoring of cliff-nesting nesting seabirds, and collection of behavioural data on a scale not feasible using manual methods. This work has been conducted at the University of Lincoln (UK), {{in collaboration with the}} Centre for <b>Computational</b> <b>Ecology</b> and Environmental Science (CEES) at Microsoft Research Cambridge. Our work has been ongoing for around 12 months, and focussed on robust image processing techniques capable of detecting and localising individual birds in image and video data. In our case, we are using data captured from a population of Common Guillemots (Uria aalge) resident on Skomer Island (UK) during the summer of 2010. This work represents a unique adaptation of computer vision technology, and we present a discussion of current and future technical challenges, processing techniques which we have developed, and some preliminary evaluation and results. In particular, we consider techniques based on feature based detection of birds and their body parts using gradient image features...|$|E
40|$|Spatially {{explicit}} landscape population {{models are}} widely {{used to analyze the}} dynamics of an ecological species over a realistic landscape. These models may be data intensive applications when they include the age and size structure of the species in conjunction with spatial informa-tion coming from a geographic information system (GIS). We report on parallelization of a spatially explicit land-scape model (PALFISH), in a component-based simula-tion framework, utilizing different parallel architectures. A multithreaded programming language (Pthread) is used to deliver high scalability on a symmetric multiprocessor (SMP), and a message-passing library is deployed for par-allel implementation on both an SMP and a commodity cluster. The PALFISH model delivers essentially identical results as a sequential version but with high scalability: yielding a speedup factor of 12 as the runtime is reduced from 35 hours (sequential ALFISH) to 2. 5 hours on a 14 -processor SMP. Hardware performance data were col-lected to better characterize the parallel execution of the model on the different architectures. This is the first docu-mentation of a high performance application in natural resource management that uses different parallel comput-ing libraries and platforms. Due to the diverse needs for computationally intensive multimodels in scientific applica-tions, our conclusions arising from a practical application which brings the software component paradigm to high-performance scientific computing, can provide guidance for appropriate parallelization approaches incorporating multiple temporal and spatial scales. Key words: Component-based parallel computing, inte-grated ecological simulation, spatially-explicit model, per-formance evaluation, <b>computational</b> <b>ecology...</b>|$|E
40|$|The system {{described}} herein {{represents the}} first example of a recommender system in digital ecosystems where agents negotiate services on behalf of small companies. The small companies compete not only with price or quality, but with a wider service-by-service composition by subcontracting with other companies. The final result of these offerings depends on negotiations at the scale of millions of small companies. This scale requires new platforms for supporting digital business ecosystems, as well as related services like open-id, trust management, monitors and recommenders. This {{is done in the}} Open Negotiation Environment (ONE), which is an open-source platform that allows agents, on behalf of small companies, to negotiate and use the ecosystem services, and enables the development of new agent technologies. The methods and tools of cyber engineering are necessary to build up Open Negotiation Environments that are stable, a basic condition for predictable business and reliable business environments. Aiming to build stable digital business ecosystems by means of improved collective intelligence, we introduce a model of negotiation style dynamics {{from the point of view}} of <b>computational</b> <b>ecology.</b> This model inspires an ecosystem monitor as well as a novel negotiation style recommender. The ecosystem monitor provides hints to the negotiation style recommender to achieve greater stability of an open negotiation environment in a digital business ecosystem. The greater stability provides the small companies with higher predictability, and therefore better business results. The negotiation style recommender is implemented with a simulated annealing algorithm at a constant temperature, and its impact is shown by applying it to a real case of an open negotiation environment populated by Italian companie...|$|E
40|$|<b>Computational</b> <b>ecology</b> is {{a recent}} field whose {{objective}} is to construct models of ecological systems (e. g., ecological communities and metapopulations) to gain understanding of the real systems. These models can be analysed with several computational tools to make predictions about the dynamics of the real systems. The biggest motivation of constructing these models is to simulate large-scale experiments that would be too costly or unethical to perform over a real ecosystem. There are several computational models suitable to model ecological systems such as Petri nets, process calculi and P systems. Process-calculus approaches are a promising direction because they are suited with different techniques such as process equivalence (i. e., bisimulation), model checking and simulation. In addition, some process calculi offer different extensions to model discrete time, continuous time, hybrid time, stochastic behaviour, non-deterministic behaviour or a combination of the above. Anna Philippou et al. have developed a process calculus, called PALPS, to model spatially-explicit ecological systems [1]. My work consisted on building on this work in two directions: (1) I developed a methodology for simulating and model-checking the models. (2) I applied the framework for the analysis of the varroa mite parasite that atacks honey bees, and for the Eleonora Falcon which is a species whose conservation in the Mediterranean region is of special interest. I strongly believe that this study complements existing ecological studies and offers important insights for dealing with these problems. It has already been discussed in the literature that process calculi offer several advantages over the ordinary-differential equations. I confirmed that PALPS bears the promise of producing a useful framework for reasoning about ecological systems. As an example, we showed {{that it is possible to}} reason about probabilistic temporal properties of PALPS processes; for instance, the probability of extinction of a species...|$|E
40|$|Knorr, W., Pytharoulis, I., Petropoulos, G., Gobron, N. (2011). Combined use {{of weather}} {{forecasting}} and satellite remote sensing information for fire risk, fire and fire impact monitoring. <b>Computational</b> <b>Ecology</b> & Software, 1 (2), 112 - 120. The restoration of fire-affected forest areas {{needs to be}} combined with their future protection from renewed catastrophic fires, {{such as those that}} occurred in Greece during the 2007 summer season. The present work demonstrates that the use of various sources of satellite data in conjunction with weather forecast information is capable of providing valuable information for the characterization of fire danger with the purpose of protecting the Greek national forest areas. This study shows that favourable meteorological conditions have contributed to the fire outbreak during the days of the unusually damaging fires in Peloponnese as well as Euboia (modern Greek: Evia) at the end of August 2007. During those days, Greece was located between an extended high pressure system in Central Europe and a low pressure system in the Middle East. Their combination resulted in strong north-northeasterly winds in the Aegean Sea. As a consequence, strong winds were also observed in the regions of Evia and Peloponnese, especially in mountainous areas. The analysis of satellite images showing smoke emitted from the fires corroborates the results from the weather forecasts. A further analysis using the Fraction of Absorbed Photosyntetically Active Radiation (FAPAR) as an indicator of active vegetation shows the extent of the destruction caused by the fire. The position of the burned areas coincides with that of the active fires detected in the earlier satellite image. Using the annual maximum FAPAR as an indicator of regional vegetation density, it was found that only regions with relatively high FAPAR were burned. Peer reviewe...|$|E
40|$|The {{last decade}} {{has seen a}} shift in {{emphasis}} from centralised to decentralised systems to meet the demanding coordination requirements of today's complex computer systems. In such systems, {{the aim is to}} achieve effective decentralised control through autonomous software agents that perform local decision-making based on incomplete and imperfect information. Specifically, when the various agents interact, the system behaves as a <b>computational</b> <b>ecology</b> with no single agent coordinating their actions. In this thesis, we focus on one specific type of <b>computational</b> <b>ecology,</b> the Continuous Double Auction (CDA), and investigate market-oriented approaches to decentralised control. In particular, the CDA is a fixed-duration auction mechanism where multiple buyers and sellers compete to buy and sell goods, respectively, in the market, and where transactions can occur at any time whenever an offer to buy and an offer to sell match. Now, in such a market mechanism, the decentralised control is achieved through the decentralised allocation of resources, which, in turn, is an emergent behaviour of buyers and sellers trading in the market. The CDA was chosen, among the plenitude of auction formats available, because it allows efficient resource allocation without the need of a centralised auctioneer. Against this background, we look at both the structure and the behaviour of the CDA in our attempt to build an efficient and robust mechanism for decentralised control. We seek to do this for both stable environments, in which the market demand and supply do not change and dynamic ones in which there are sporadic changes (known as market shocks). While the structure of the CDA defines the agents' interactions in the market, the behaviour of the CDA is determined by what emerges when the buyers and sellers compete to maximise their individual profits. In more detail, on the structural aspect, we first look at how the market protocol of the CDA can be modified to meet desirable properties for the system (such as high market efficiency, fairness of profit distribution among agents and market stability). Second, we use this modified protocol to efficiently solve a complex decentralised task allocation problem with limited-capacity suppliers that have start-up production costs and consumers with inelastic demand. Furthermore, we demonstrate that the structure of this CDA variant is very efficient (an average of 80 % and upto 90 %) by evaluating the mechanism with very simple agent behaviours. In so doing, we emphasise the effect of the structure, rather than the behaviour, on efficiency. In the behavioural aspect, we first developed a multi-layered framework for designing strategies that autonomous agents can use for trading in various types of market mechanisms. We then use this framework to design a novel Adaptive-Aggressiveness (AA) strategy for the CDA. Specifically, our bidding strategy has both a short and a long-term learning mechanism to adapt its behaviour to changing market conditions and it is designed to be robust in both static and dynamic environments. Furthermore, we also developed a novel framework that uses a two-population evolutionary game theoretic approach to analyse the strategic interactions of buyers and sellers in the CDA. Finally, we develop effective methodologies for evaluating strategies for the CDA in both homogeneous and heterogeneous populations, within static and dynamic environments. We then evaluate the AA bidding strategy against {{the state of the art}} using these methodologies. By so doing, we show that, within homogeneous populations, the AA strategy outperformed the benchmarks, in terms of market efficiency, by up to 3. 6 % in the static case and 2. 8 % in the dynamic case. Within heterogeneous populations, based on our evolutionary game theoretic framework, we identify that there is a probability above 85 % that the AA strategy will eventually be adopted by buyers and sellers in the market (for being more efficient) and, therefore, AA is also better than the benchmarks in heterogeneous populations as well. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|E
40|$|Website {{presentation}} {{is becoming a}} crucial issue {{as more and more}} services of all different kinds are offered by more and more content providers to a rapidly growing audience on the Internet. In the face of accelerated competition and intransparency it is highly important for a service provider to present himself with an appealing and professionally designed website. To attract the attention of as many Internet surfers as possible and to raise their curiosity and interest, service providers will have to do everything to enhance their website’s traffic and to transform casual visitors into habitual customers and partners. In order to attract more traffic, linkages directing the user from website to website is a crucial issue and building-up strategic linkage liaisons with other website owners on a B 2 B basis {{will be one of the}} future key elements of successful website presentation. Linkage liaisons between websites will give rise to emergent network structures (professional and non-professional) as well as to all sorts of minor and major linkage conflicts that arise among website owners (or their agents) in the course of incrementally engaging in building up new linkages and deleting old ones. Hence, linkage liaisons look like a particularly suitable scenario for designing, implementing, and testing models for real world applications and for scientific research purposes of comparing interactionism with social systems approaches in sociology. We assume that liaison models differ from more conventional DAI applications not only because they operate on a permanent basis (cf. <b>computational</b> <b>ecology)</b> and that they produce, reproduce and modify an ”emergent” social structure while resolving (or not resolving!) conflictive episodes. The presumed advantages of the proposed model, both from a software engineering and from a sociological perspective, should be seen in the way that a linkage networks would have to meet the demands of shifting from a highly efficient and cost saving routine mode into a resource consumptive conflict mode and back again into a new routine mode after the conflict has been settled. In other words: the system should be able to learn from conflicts and, in doing so, an agent society would operate like a self-organising mechanism or a selfsustaining general purpose infrastructure...|$|E
40|$|International audienceUnderstanding clonal {{strategies}} (i. e. {{the ability}} of plants to reproduce vegetatively) is particularly important to explain species persistence. A clonal individual may {{be considered as a}} network of interconnected ramets that colonizes space. Resources in this network can be shared and/or stored. We developed an individual-based model (IBM) to simulate the growth of an individual clonal plant. Typically a realistic IBM requires a large set of parameters to adequately represent the complexity of the clonal plant growth. Simulations in the literature are often limited to small subsets of the parameter space and are guided by the a priori knowledge and with heuristic aims of the researcher. The aim of this paper was to demonstrate the benefit of volunteer computing in <b>computational</b> <b>ecology</b> to systematically browse the parameter space and analyze the simulation results in order to draw rigorous conclusions. To be specific, we simulated clonal plant growth using nine growth rules related to the metabolic process, plant architecture, resource sharing and storage and nineteen input parameters. We chose 2 - 4 values per input parameter which corresponded to 20 millions of combinations tested through volunteer computing. We used three criteria to evaluate plant performance: plant total resource, ramet production and maximum length of one branch. The 1 % top-performing plants were sorted according to these criteria. Plant total resource and ramet production were correlated while considering the top-performing plants. The maximum length of one branch was independent from the other two performance traits. We detected two processes promoting {{at least one of the}} plant performance traits: (i) a relatively high metabolic gain (high photosynthetic activity and low production cost for new growth units), a low resource storage and long integration distance for resource sharing; (ii) short spacer lengths and the predominance of elongation of existing branches over branching. Interactive effects between parameter values were demonstrated for more than half of the input parameters. Best performance was reached for plants with slightly different combinations of values for these parameters (i. e. different strategies) rather than a single one (i. e. unique strategy). This modeling approach with volunteer computing enabled us to proceed to large-scale virtual experiments which provided a new quality of insight into ecological processes linked with clonal plant growth...|$|E

