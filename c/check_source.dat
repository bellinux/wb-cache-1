16|344|Public
25|$|Style {{guidelines}} often {{distinguish between}} {{upper and lower}} camel case, typically specifying which variety {{should be used for}} specific kinds of entities: variables, record fields, methods, procedures, types, etc. These rules are sometimes supported by static analysis tools that <b>check</b> <b>source</b> code for adherence.|$|E
50|$|The device had {{a leather}} carrier bag {{when used in}} the military. This bag had a probe compartment, {{as well as a}} small <b>check</b> <b>source.</b>|$|E
50|$|Style {{guidelines}} often {{distinguish between}} {{upper and lower}} camel case, typically specifying which variety {{should be used for}} specific kinds of entities: variables, record fields, methods, procedures, types, etc. These rules are sometimes supported by static analysis tools that <b>check</b> <b>source</b> code for adherence.|$|E
5000|$|Automated {{code review}} {{software}} <b>checks</b> <b>source</b> code against a predefined {{set of rules}} and produces reports.|$|R
5000|$|<b>Check</b> <b>sources</b> {{to make a}} {{long list}} of {{possible}} material topics: internal data, external review or media reporting etc.; ...|$|R
40|$|Issues in {{maintaining}} readiness of instruments for deployment and use in emergency response situation often {{differ from those}} {{in maintaining}} instruments for normal operations. Confunding circumstances include use of non-availability of <b>check</b> <b>sources,</b> ensuring instruments are always in calibration and operable, possible use of instruments in different climates, packaging of instrumentation for deployment, transport of instrumentation and <b>check</b> <b>sources,</b> and ensuring users are familiar with instruments. Methods and procedures for addressing these issues are presented. Instrumentation used for survey, in situ measurements, electronic dosimetry, and air conditioning are discussed...|$|R
5000|$|The CD V-700 {{also came}} with a [...] "check source", {{a bit of a}} {{radioactive}} isotope under a sticker {{on the side of the}} unit. The isotope varied with the maker; depleted or natural uranium was common, though the Instruction and Maintenance Manual for the Lionel model 6B indicates that a [...] "Radium D+E beta source" [...] with an approximate half-life of 22 years is present under the nameplate. This produced, at the time of installation on the machine, about 1-2 mR/hr adjacent to the source, a value which was clearly visible on the analog meter as well as audible via the headphones that accompanied the units. Measured with the probe's beta window uncovered and the probe directly in contact with the operational <b>check</b> <b>source,</b> this is about 100 times normal sea-level background levels of radiation, and similar to the near-field from a uranium oxide-glazed red Fiestaware saucer. The level drops back to background levels a few feet from the source. Since the half-life of the different operational <b>check</b> <b>source</b> materials used varied and since all CD V-700's were manufactured prior to 1964 and are now approaching a half-century old, the amount of radiation emitted from the source may be much lower than when the unit was originally issued. Therefore, accurate calibration via the source cannot be assured.|$|E
5000|$|TESSY is {{developed}} by Razorcat Development. The international sales partner is Hitex Development Tools.Tessy has 3 major tabs in it. They are: (1) Workspace tab (2)Test Interface Editor(TIE) and (3) Test Data Editor(TDE).(1)Workspace tab include [...]c or [...]cpp files (path configuration is done here). <b>Check</b> <b>Source</b> (checks for compilation), Analyzer (analyses file (.c or [...]cpp) and opens constituent {{of that particular}} file (Global variables and Functions)). (2) Test Interface Editor(TIE): Here we can decide the status of all the global variables.(3) Test Data Editor(TDE):Here we feed the conditions or values for the framework decided in TIE.|$|E
50|$|There {{are many}} {{approaches}} available in software testing. Reviews, walkthroughs, or inspections {{are referred to}} as static testing, whereas actually executing programmed code with a given set of test cases is referred to as dynamic testing. Static testing is often implicit, as proofreading, plus when programming tools/text editors <b>check</b> <b>source</b> code structure or compilers (pre-compilers) check syntax and data flow as static program analysis. Dynamic testing takes place when the program itself is run. Dynamic testing may begin before the program is 100% complete in order to test particular sections of code and are applied to discrete functions or modules. Typical techniques for this are either using stubs/drivers or execution from a debugger environment.|$|E
40|$|This paper {{presents}} {{an overview of}} the tools provided by KANTOO MT system for controlled <b>source</b> language <b>checking,</b> <b>source</b> text analysis, and terminology management. The steps in each process are described, and screen images are provided to illustrate the system architecture and example tool interfaces. ...|$|R
50|$|Polyspace is {{a static}} code {{analysis}} tool for large-scale analysis by abstract interpretation to detect, or prove the absence of, certain run-time errors in source code for the C, C++, and Ada programming languages. The tool also <b>checks</b> <b>source</b> code for adherence to appropriate code standards.|$|R
5000|$|... {{security}} label <b>checks</b> against <b>source</b> and destination clearances ...|$|R
40|$|Program Dependency Graphs and Constraint Solving can be {{combined}} to achieve {{a powerful tool for}} information flow control, allowing to <b>check</b> <b>source</b> code for security problems such as external manipulation of critical computations. The method generates path conditions for critical information flows, being conditions over the program variables necessary for flow. As all variables are existentially quantified, quantifier elimination and in particular the REDLOG system developed at Volker Weispfenning’s group, are used to solve path conditions for the input variables, thus generating witnesses for security leaks. ...|$|E
40|$|Static code {{analysis}} {{is the process}} of evaluating a system or component based on its form, structure, content, or documentation. From a software assurance perspective, static analysis addresses weaknesses in program code that might lead to vulnerabilities Such analysis may be manual, as in code inspections, or automated through the use of one or more tools Automated static code analyzers typically <b>check</b> <b>source</b> code but there is a smaller set of analyzers that check byte code and binary code, especially useful when source code in not available (e. g for COTS components) ...|$|E
40|$|Review {{actions and}} parked {{issues from the}} {{previous}} meeting The actions and the parked issues from the previous meeting were discussed with the Working Group. Comments from these discussions are noted in the tables {{at the end of}} these minutes. A significant amount of discussion ensued around the use of the Valid Bid Report (VBR) functionality for <b>check</b> <b>source</b> data. A WG member asked if the VBR could be used to identify the bids/offers that were used in the Pre‐dispatch of Record (PDoR) and, if so, when {{is the best time to}} request this data. The IESO responded with the following observations: The VBR functionality is unchanged with the implementation of the DACP. The VBR will not be altered to include an identifier that indicates the data that was used in the PDoR...|$|E
50|$|Today, the Journal employs {{approximately}} 100 second- and third-year law students—about 50 {{in their}} graduating year who serve in editorial positions and 50 in intermediate years who serve as staff. The staff collect and <b>check</b> <b>sources,</b> performing technical edits and checking for typographical errors. The upperclass students are tasked with administering the Journal‘s daily operations.|$|R
50|$|Automated code {{reviewing}} software lessens {{the task}} of reviewing large chunks of code on the developer by systematically <b>checking</b> <b>source</b> code for known vulnerabilities. A 2012 study by VDC Research reports that 17.6% of the embedded software engineers surveyed currently use automated tools for peer code review and 23.7% expect to use them within 2 years.|$|R
40|$|This thesis {{focuses on}} {{software}} source code plagiarism. In the theoretical part {{there is a}} description of usual plagiarism techniques. The main output in practical part is the program that <b>checks</b> <b>source</b> codes of Java programs, whether these codes are really developed by individual students independently. It detects two or more students with identical source codes by controlling names of methods and variables...|$|R
40|$|Traditional static {{checkers}} {{are limited}} to detecting simple anomalies since they have no information regarding {{the intent of the}} code. Program verifiers are too expensive for nearly all applications. This thesis investigates the possibilities of using specifications to do lightweight static checks to detect inconsistencies between specifications and implementations. A tool, LCLint, was developed to do static checks on C source code using LCL specifications. It is similar to traditional lint, except it uses information in specifications to do more powerful checks. Some typical problems detected by LCLint include violations of abstraction barriers and modifications of caller-visible state that are inconsistent with the specification. Experience using LCLint to check a specified program and to understand and maintain a program with no specifications illustrate some applications of LCLint and suggest future directions for using specifications to <b>check</b> <b>source</b> code...|$|E
40|$|One of the {{decontamination}} and decommissioning projects within DOD is demilitarization of {{an aging}} stockpile of munitions. A {{large portion of the}} stockpile contains depleted uranium (DU) as an armor piercing core and so these munitions must be assayed for the presence of uranium in other components. The assay method must be fast and preferably easy to implement. Presence of DU is indicated by its alpha decay. The alpha particles in turn produce ions in the ambient air. If a significant fraction of these ions can escape the quantity of propellant, the ions can be detected instead of the alpha particles. As a test of the feasibility of detecting alpha emissions from DU somewhere within a cartridge of propellant, the transmission of ions through layers of real propellant was measured. The propellant {{is in the form of}} graphite-coated cylindrical pellets. A 105 nun cartridge was modified for use as a pellet chamber. A <b>check</b> <b>source</b> served as an ion source. The ion detector consisted of a grid held at 300 V coupled to an ammeter. Results confirm that this is a promising technique for testing the propellant for the presence of DU quickly yet with sensitivity...|$|E
40|$|Abstract. A coinduction-based {{technique}} to generate an optimal monitor from a Linear Temporal Logic (LTL) formula {{is presented in}} this paper. Such a monitor receives a sequence of states (one at a time) from a running process, checks them against a requirements specification expressed as an LTL formula, and determines whether the formula has been violated or validated. It can also say whether the LTL formula is not monitorable any longer, i. e., that the formula can in the future neither be violated nor be validated. A Web interface for the presented algorithm adapted to extended regular expressions is available. 1 Introduction Linear Temporal Logic (LTL) [19] is a widely used logic for specifying propertiesof reactive and concurrent systems. The models of LTL are infinite execution traces, reflecting the behavior of such systems as ideally always being readyto respond to requests, operating system being typical example. LTL has been mainly used to specify properties of finite-state reactive and concurrent systems,so that the full correctness of the system can be verified automatically, using model checking or theorem proving. Model checking of programs has received anincreased attention from the formal methods community within {{the last couple of}} years, and several tools have emerged that directly model <b>check</b> <b>source</b> codewritten in Java or C [7, 26, 27]. Unfortunately, such formal verification techniques are not scalable to real-sized systems without exerting a substantial effort toabstract the system more or less manually to a model that can be analyzed...|$|E
5000|$|Science journalism {{concerns}} {{itself with}} gathering and evaluating {{various types of}} relevant evidence and rigorously <b>checking</b> <b>sources</b> and facts. As Boyce Rensberger, {{the director of the}} Massachusetts Institute of Technology (MIT) Knight Center for Science Journalism, put it “balanced coverage of science does not mean giving equal weight to both sides of an argument. It means apportioning weight according to the balance of evidence.” ...|$|R
50|$|The Borthwick Institute for Archives {{recommends}} that researchers looking at Yorkshire parishes between 1770 and 1812 should <b>check</b> both <b>sources.</b>|$|R
500|$|This article {{incorporates}} {{text from}} a scholarly publication published under the : [...] Please <b>check</b> the <b>source</b> for the exact licensing terms.|$|R
40|$|International Basic Safety Standards (International Atomic Energy Agency, IAEA) provide {{guidance}} levels for diagnostic procedures in nuclear medicine indicating the maximum usual activity for various diagnostic tests {{in terms of}} activities of injected radioactive formulations. An accuracy of &# 177; 10 &#x 0025; {{in the activities of}} administered radio-pharmaceuticals is being recommended, for expected outcome in diagnostic and therapeutic nuclear medicine procedures. It is recommended that the long-term stability of isotope calibrators used in nuclear medicine is to be checked periodically for their performance using a long-lived <b>check</b> <b>source,</b> such as Cs- 137, of suitable activity. In view of the un-availability of such a radioactive source, we tried to develop methods to maintain traceability of these instruments, for certifying measured activities for human use. Two re-entrant chambers [(HDR 1000 and Selectron Source Dosimetry System (SSDS) ] with I- 125 and Ir- 192 calibration factors in the Department of Radiotherapy were used to measure Iodine- 131 (I- 131) therapy capsules to establish traceability to Mark V isotope calibrator of the Department of Nuclear Medicine. Special nylon jigs were fabricated to keep I- 131 capsule holder in position. Measured activities in all the chambers showed good agreement. The accuracy of SSDS chamber in measuring Ir- 192 activities in the last 5 years was within 0. 5 &#x 0025;, validating its role as departmental standard for measuring activity. The above method is adopted because mean energies of I- 131 and Ir- 192 are comparable...|$|E
40|$|PURPOSE: To {{determine}} {{the safety of}} pulsed-dose-rate (PDR) brachytherapy by analyzing errors and technical failures during treatment. METHODS AND MATERIALS: More than 1, 300 patients underwent treatment with PDR brachytherapy, using five PDR remote afterloaders. Most patients were treated with consecutive pulse schemes, also outside regular office hours. Tumors were located in the breast, esophagus, prostate, bladder, gynecology, anus/rectum, orbit, head/neck, with a miscellaneous group of small numbers, such as the lip, nose, and bile duct. Errors and technical failures were analyzed for 1, 300 treatment sessions, for which nearly 20, 000 pulses were delivered. For each tumor localization, the number and type of occurring errors were determined, as were which localizations were more error prone than others. RESULTS: By routinely using the built-in dummy <b>check</b> <b>source,</b> only 0. 2 % of all pulses showed an error during the phase of the pulse when the active source was outside the afterloader. Localizations treated using flexible catheters had greater error frequencies than those treated with straight needles or rigid applicators. Disturbed pulse frequencies were {{in the range of}} 0. 6 % for the anus/rectum on a classic version 1 afterloader to 14. 9 % for orbital tumors using a version 2 afterloader. Exceeding the planned overall treatment time by > 10 % was observed in only 1 % of all treatments. Patients received their dose as originally planned in 98 % of all treatments. CONCLUSIONS: According to the experience in our institute with 1, 300 PDR treatments, we found that PDR is a safe brachytherapy treatment modality, both during and outside of office hour...|$|E
40|$|The {{ultrasonic}} power measurement, worldwide accepted, standard is the IEC 61161, presently in its 2 nd edition (2006), but under review. To fulfil its requirements, considering that a radiation force balance {{is to be}} used as {{ultrasonic power}} detector, a large amount of raw data (mass measurement) shall be collected as function of time to perform all necessary calculations and corrections. Uncertainty determination demands calculation effort of raw and processed data. Although it is possible to be undertaken in an old-fashion way, using spread sheets and manual data collection, automation software are often used in metrology to provide a virtually error free environment concerning data acquisition and repetitive calculations and corrections. Considering that, a fully automate ultrasonic power measurement system was developed and comprehensively tested. A 0, 1 mg of precision balance model CP 224 S (Sartorius, Germany) was used as measuring device and a calibrated continuous wave ultrasound <b>check</b> <b>source</b> (Precision Acoustics, UK) was the device under test. A 150 ml container filled with degassed water and containing an absorbing target at the bottom was placed on the balance pan. Besides the feature of automation software, a routine of power measurement simulation was implemented. It was idealized as a teaching tool of how ultrasonic power emission behaviour is with a radiation force balance equipped with an absorbing target. Automation software was considered as an effective tool for speeding up ultrasonic power measurement, while allowing accurate calculation and attractive graphical partial and final results. © Published under licence by IOP Publishing Ltd...|$|E
5000|$|... "In history, {{the term}} {{historical}} method {{was first introduced}} in a systematic way {{in the sixteenth century}} by Jean Bodin in his treatise of source criticism, Methodus ad facilem historiarium cognitionem (1566). Characteristically, Bodin's treatise intended to establish the ways by which reliable knowledge of the past could be established by <b>checking</b> <b>sources</b> against one another and by so assessing the reliability of the information conveyed by them, relating them to the interests involved." [...] (Lorenz, 2001, p. 6870).|$|R
30|$|The ASB {{analyzes}} the packet by <b>checking</b> the <b>source</b> IP and the destination IP, calculates the routing path and generates the corresponding flow entries.|$|R
50|$|The second-year law {{students}} participate as associate {{editors of the}} Law Review. Duties of the associate editors include <b>checking</b> <b>sources</b> cited in the articles pending publication to ensure the sources' compliance with the most recent edition of the Bluebook. The associate editors are also required to produce a legal comment of publishable quality. Once complete, the student-written comments are reviewed and graded by the Law Review comments editors. Subsequently, {{some of the comments}} are selected for publication in the journal.|$|R
40|$|New {{methods are}} {{required}} for a better interpretation of the response of ionisation chambers {{in order to improve}} further the determination of the absorbed doses in a mixed neutron-gamma BNCT field. Simulations might help to understand in particular the behaviour of the sensitivity factors of an ionisation chamber in the mixed field. The study presented here is a continuation of previous work with the final aim to obtain validated computer models of the Mg-Ar and TE-TE ionisation chambers. With these two chambers the so-called paired ionisation chamber technique is performed by which the neutron and gamma dose components can be separated and determined. By knowing exactly the neutron and gamma source in a simulation, the chamber response can be investigated. However, the validation of a simulated ionisation chamber set-up, starting directly with the mixed neutron/gamma fields is too complicated regarding the number of possibilities that could cause a discrepancy between measurements and simulations. Therefore, two simplified and well-known irradiation fields are considered first and will be discussed in this paper: an existing 60 Co calibration source and a 90 Sr <b>check</b> <b>source</b> which has been designed and constructed to perform ionisation chamber stability measurements. Both irradiation sources as well as the two ionisation chambers are modelled with MCNPX. This code has been used because it is capable of simulating neutrons among many other types of particles and rays. The model of the two ionisation chambers is investigated comparing the measured charge collection rate when the detectors are exposed in the 60 Co gamma-ray field and in the 90 Sr beta field with the calculated results. For the 60 Co experiments the calculations agree within 3 % with the measured values. For the 90 Sr source the simulated Mg-Ar charge is 8 % higher than the measurement and the simulated TE-TE charge is 6 % lower than the measured charge from the ionisation chamber. JRC. F. 4 -Safety of future nuclear reactor...|$|E
30|$|Here I {{provide a}} {{definition}} {{for all the}} variables used in the robustness <b>checks.</b> The <b>source</b> is EUROSTAT. The year is 2006 unless otherwise indicated.|$|R
50|$|Many cache {{poisoning}} {{attacks against}} DNS servers {{can be prevented}} by being less trusting of the information passed to them by other DNS servers, and ignoring any DNS records passed back which are not directly relevant to the query. For example, versions of BIND 9.5.0-P1 and above perform these <b>checks.</b> <b>Source</b> port randomization for DNS requests, combined {{with the use of}} cryptographically-secure random numbers for selecting both the source port and the 16-bit cryptographic nonce, can greatly reduce the probability of successful DNS race attacks.|$|R
50|$|Automated {{code review}} {{software}} <b>checks</b> <b>source</b> code for compliance with a predefined {{set of rules}} or best practices. The use of analytical methods to inspect and review source code to detect bugs has been a standard development practice. This process can be accomplished both manually and in an automated fashion. With automation, software tools provide assistance with the code review and inspection process. The review program or tool typically displays a list of warnings (violations of programming standards). A review program can also provide an automated or a programmer-assisted way to correct the issues found.|$|R
5000|$|Churnalism {{is a form}} {{of journalism}} in which press releases, stories {{provided}} by news agencies, and other forms of pre-packaged material, instead of reported news, are used to create articles in newspapers and other news media. Its purpose is to reduce cost by reducing original news-gathering and <b>checking</b> <b>sources,</b> to counter revenue lost with the rise of Internet news and decline in advertising; there was a particularly steep fall from late 2015. The term [...] "churnalism" [...] has been credited to BBC journalist Waseem Zakir, who coined the term in 2008.|$|R
30|$|The ASB {{analyzes}} the packet by <b>checking</b> the <b>source</b> IP {{and the information}} message of the selected Wi-Fi AP, calculates the routing path and generates the corresponding flow entries.|$|R
