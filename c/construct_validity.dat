9628|774|Public
25|$|Researchers have {{reported}} that the JP and the SN scales correlate with one another. One factor-analytic study based on (N=1291) college-aged students found six different factors instead of the four purported dimensions, thereby raising doubts as to the <b>construct</b> <b>validity</b> of the MBTI.|$|E
25|$|In {{order for}} an animal model {{to be useful}} in {{developing}} treatments, results from the animal model must translate into results in the patient with schizophrenia, {{this is called the}} validity of the model. Criteria for assessing the validity of animal models of schizophrenia include face validity, <b>construct</b> <b>validity,</b> and predictive validity.|$|E
25|$|The ability EI {{model has}} been criticized in the {{research}} for lacking face and predictive validity in the workplace. However, in terms of <b>construct</b> <b>validity,</b> ability EI tests have great advantage over self-report scales of EI because they compare individual maximal performance to standard performance scales and do not rely on individuals' endorsement of descriptive statements about themselves.|$|E
5000|$|There are {{six major}} {{considerations}} when examining a <b>construct's</b> <b>validity</b> through the MTMM matrix, which are as follows: ...|$|R
50|$|The 1999 Standards for Educational and Psychological Testing largely codified Messick’s model. They {{describe}} five {{types of}} validity-supporting evidence that incorporate each of Messick’s aspects, {{and make no}} mention of the classical models’ content, criterion, and <b>construct</b> <b>validities.</b>|$|R
5000|$|Construct {{validation}} checks what underlying construct is being measured. There are three variants of <b>construct</b> validity: convergent <b>validity</b> (how well the research relates to {{other measures of}} the same <b>construct),</b> discriminant <b>validity</b> (how poorly the research relates to measures of opposing <b>constructs),</b> and nomological <b>validity</b> (how well the research relates to other variables as required by theory).|$|R
25|$|Personnel {{selection}} {{procedures are}} usually validated, i.e., {{shown to be}} job relevant to personnel selection, using {{one or more of}} the following types of validity: content validity, <b>construct</b> <b>validity,</b> and/or criterion-related validity. I/O psychologists must adhere to professional standards in personnel selection efforts. SIOP (e.g., Principles for validation and use of personnel selection procedures) and APA together with the National Council on Measurement in Education (e.g., Standards for educational and psychological testing are sources of those standards. The Equal Employment Opportunity Commission's Uniform guidelines are also influential in guiding personnel selection decisions.|$|E
25|$|One {{study done}} by Simon Vermeier used neuroimaging to {{investigate}} serotonergic and dopaminergic neurotransmission in 9 dogs with Canine Compulsive Disorder (CCD) {{to measure the}} serotonin 2A receptor availability. When compared to the 15 non-compulsive dogs used as a control group, the dogs with CCD {{were found to have}} lower receptor availability as well as lower subcortical perfusion and hypothalamic availability. The results of this study provide evidence that there are imbalanced serotonergic and dopaminergic pathways in dogs. Similarities between other studies about human OCD provide <b>construct</b> <b>validity</b> for this study, which suggests that the research will be valid and useful in continuing to investigate brain activity and drug treatment in Obsessive Compulsive Disorder.|$|E
25|$|There are {{a number}} of {{different}} forms of validity. Criterion-related validity can be assessed by correlating a measure with a criterion measure theoretically expected to be related. When the criterion measure is collected {{at the same time as}} the measure being validated the goal is to establish concurrent validity; when the criterion is collected later the goal is to establish predictive validity. A measure has <b>construct</b> <b>validity</b> if it is related to measures of other constructs as required by theory. Content validity is a demonstration that the items of a test do an adequate job of covering the domain being measured. In a personnel selection example, test content is based on a defined statement or set of statements of knowledge, skill, ability, or other characteristics obtained from a job analysis.|$|E
40|$|No sponsorships or {{competing}} interests have been disclosed for this article. Objective. To assess the face, content, and <b>construct</b> <b>validities</b> of a low-cost sinus surgery task trainer in acquisition of skills for endoscopic sinus surgery. Study Design. Prospective validation study. Setting. Tertiary academic center...|$|R
30|$|The {{present study}} aimed at {{investigating}} the construct validly of Translation Competence Questionnaire {{in the context}} of Iran. Based on the findings, the researchers concluded that Translation Competence Questionnaire by Orozco and Albir has undoubtedly strong psychometric characteristics and good <b>constructs</b> <b>validity</b> {{in the context of}} Iran.|$|R
40|$|ABSTRACTObjectivesTo {{culturally}} adapt a Chinese {{version of}} the Hepatitis Quality of Life Questionnaire (HQLQ) and assess its suitability for use in Chinese-speaking hepatitis B virus (HBV patients in Singapore. StudyReliability was assessed using Cronbach's alpha coefficients and intra-class correlation coefficients. Item-to-scale correlation was assessed using Spearman's rank correlations (ρ) between scale scores and their constituent items. Convergent and divergent <b>construct</b> <b>validities</b> were tested in three and two a priori hypotheses, respectively, and the correlations were assessed using Spearman's rank correlation coefficients. ResultsWhen tested in 134 HBV patients, the test-retest reliability was supported with all scales showing acceptable correlation coefficients (i. e., α > 0. 7). Item-to-scale correlations were good with most items highly correlated with their hypothesized scales. Convergent and divergent <b>construct</b> <b>validities</b> were supported by the hypothesized correlations between the HQLQ and the EQ- 5 D domains. ConclusionsThe culturally adapted questionnaire has good validity and reliability for use in Singapore...|$|R
2500|$|Shlomo Sawilowsky, psychometrics, <b>construct</b> <b>validity</b> for the multitrait-multimethod matrix ...|$|E
2500|$|<b>Construct</b> <b>validity</b> is [...] "the {{degree to}} which a test {{measures}} what it claims, or purports, to be measuring." ...|$|E
2500|$|He {{collaborated with}} Samuel Messick at the Educational Testing Service, {{examining}} <b>construct</b> <b>validity.</b> Jackson also published several analyses on sex and intelligence that found males applying to medical schools {{had a small}} but nontrivial advantage in general intelligence factor [...] and in reasoning.|$|E
30|$|In {{order to}} analyse the {{strength}} of association among the variables, the <b>constructs</b> <b>validity</b> was tested using the Bartlett’s Test of Sphericity and the Kaiser-Mayer-Olkin (KMO) for the measure of sampling adequacy [61]. The result for Bartlett’s test of Sphericity and the KMO value was 0.000 and 0.688 respectively (see Table  4). The latter value is more than 0.5, which shows {{a high level of}} sampling adequacy.|$|R
5000|$|The {{advantages}} of FST {{are that it}} is low-costing and is a fast and reliable tool, easy to handle and has proven its reliability across laboratories, for testing potential antidepressants activities with a strong predictive validity. Besides, it allows rapid screening {{of large numbers of}} drugs. The major dis{{advantages of}} FST are that it has poor face and <b>construct</b> <b>validities.</b> The test is sensitive to acute treatment only, and its validity for non-monoamine antidepressants is uncertain ...|$|R
40|$|The psychometric {{properties}} of a Chinese version of the Mini-Mental Adjustment to Cancer scale (Mini-MAC) were examined among 115 Chinese cancer patients in Hong Kong. The five subscales from the original Mini-MAC (Anxious Preoccupation, Helpless-Hopeless, Fighting Spirit, Fatalism, Cognitive Avoidance) had acceptable internal reliabilities (Cronbach's α ranged from 0. 65 to 0. 88) and <b>construct</b> <b>validities</b> in our sample. Factor analysis suggested three factors: (1) Negative Emotion (α = 0. 91) contained items of the Anxious Preoccupation and the Helpless-Hopeless subscales of the original Mini-MAC, (2) Positive Attitude (α = 0. 77) combined the Fighting Spirit and the Fatalism subscales of the original version, and (3) Cognitive Avoidance (α = 0. 65) which was identical to the Cognitive Avoidance subscale of the original Mini-MAC. <b>Construct</b> <b>validities</b> of the novel factors were shown by their correlations with HADS Anxiety and Depression scores in the predicted directions. It was concluded that both the 5 -factor model from the original Mini-MAC and the 3 -factor model {{from the present study}} were valid in Hong Kong Chinese cancer patients. The results were discussed in terms of the meaning of the original Mini-MAC factors and cultural differences in coping functions between Chinese and UK cancer patients. Copyright © 2003 John Wiley & Sons, Ltd. link_to_subscribed_fulltex...|$|R
2500|$|There is some ongoing {{scientific}} doubt {{concerning the}} <b>construct</b> <b>validity</b> {{and reliability of}} psychiatric diagnostic categories and criteria {{even though they have}} been increasingly standardized to improve inter-rater agreement in controlled research. In the United States, there have been calls and endorsements for a congressional hearing to explore {{the nature and extent of}} harm potentially caused by this [...] "minimally investigated enterprise".|$|E
2500|$|The TMAS {{scale was}} {{frequently}} {{used in the}} past, however, its use has declined over the years due to problems with the validity of this self-report measure. [...] Participants use their own judgement when answering questions, which causes internal and <b>construct</b> <b>validity</b> issues, which makes the interpretation of results difficult. Another possible reason this scale has declined in its use over the years is that researchers seemed to only get results of anxiety from participants under threat conditions and not under non-threat conditions, which again questioned the scale's validity.|$|E
2500|$|As {{with any}} use of {{mathematical}} models, {{it is important}} to assess the fit of the data to the model. [...] If item misfit with any model is diagnosed as due to poor item quality, for example confusing distractors in a multiple-choice test, then the items may be removed from that test form and rewritten or replaced in future test forms. If, however, a large number of misfitting items occur with no apparent reason for the misfit, the <b>construct</b> <b>validity</b> of the test will need to be reconsidered and the test specifications may need to be rewritten. Thus, misfit provides invaluable diagnostic tools for test developers, allowing the hypotheses upon which test specifications are based to be empirically tested against data.|$|E
40|$|Developing valid {{measures}} of gang membership for self-report surveys is a challenging task in comparative cross-national research. In {{this article we}} use the Venezuelan case to assess {{the validity of the}} Eurogang indicators of gang membership. Based on focus groups with adolescents and the results from two sweeps of the International Self-Report Survey of Juvenile Delinquency we identify problems in the content and <b>construct</b> <b>validities</b> of the Eurogang items. We propose an alternative set of measures for cross-national studies of gang membership, focusing on a group’s reputation for violence (or broader criminal behaviour) ...|$|R
40|$|Objective: The study aims {{to examine}} the psychometric {{properties}} of the Holistic Well-Being Scale (HWS), a new instrument developed on the Eastern concepts of affliction, and equanimity in a new sample involving patients with cancer. Methods: A cross-sectional survey was conducted with 300 patients with cancer in Singapore. The patients completed the HWS, WHO- 5 Well-Being Index (WHO- 5), and Hospital Anxiety and Depressions Scale (HADS). Thirty-two patients participated in the 2 -week retest. Results: Mixed findings were obtained from the original seven-factor model in our sample: six factors had acceptable internal reliabilities (Cronbach’s α; range, 0. 657 – 0. 809), and <b>construct</b> <b>validities</b> were partially supported. Factor analysis suggested three factors: Blissful-self (α[*]=[*] 0. 874), Disturbed-self (α[*]=[*] 0. 885) and Embittered-others (α[*]=[*] 0. 709). The novel factors demonstrated good test-retest reliability (ICC; range, 0. 894 – 0. 930) and <b>construct</b> <b>validities,</b> which were shown by significant correlations with HADS and WHO- 5 in the predicted directions. Conclusions: The present study is the first step taken to validate a scale that is essential in the development of culturally appropriate psychosocial interventions to support and promote personal well-being of cancer patients. The findings suggest that the three-factor model may be more applicable to the Singapore context, but it does not necessarily invalidate the original HWS. The results were discussed in terms of the meaning of the original HWS factors and cultural differences in coping behaviors between Singapore and Hong Kong, though both are Asian countries. The HWS could be further tested in other Asian populations as achieving holistic well-being is a common goal for patients in many cultures...|$|R
40|$|Purpose: The aim of {{this study}} was to cross- {{culturally}} adapt the Patient Global Impression of Change Scale - (PGICS) for the Portuguese Language in a population of people with chronic musculoskeletal pain, and to investigate its <b>construct</b> convergent <b>validity.</b> Methods: The English version of the PGICS was translated into Portuguese (PGIC-VP) and back translated blindly and independently by a multidisciplinary team according to established guidelines. <b>Construct</b> convergent <b>validity</b> of the translated version of the PGIC-VP was then administered to 46 patients with non-traumatic chronic cervical pain. Association between the PGIC-VP scores and the numerical pain rating scale (NPRS) were investigated, using Pearson’s correlation coefficient. Results: Comprehensibility of PGIC-VP was good. The correlation between the PGIS-VP and the END showed desirable results, indicating a good <b>construct</b> convergent <b>validity,</b> with the r value of - 82 (p ≤ 0, 01.), suggesting that low levels of pain intensity are associated with a highest patient’ satisfaction and perception of treatment response. Conclusion. The Portuguese version of PGIC-VP was found to be a valid method of measurement for evaluating patients’ perceptions of their improvement and satisfaction with the treatment, when applied to patients with chronic musculoskeletal pain. It is simple and easy to use and now can be applied in clinical settings and future outcome research studies in Portugal...|$|R
2500|$|Addition {{of the new}} {{category}} to the DSM-system was recognized by the psychiatric press, and the New York Times. Several commentators have also offered their viewpoints. Chinen notes that the inclusion marks [...] "increasing professional acceptance of transpersonal issues", while Sovatsky sees the addition as an admittance of spiritually oriented narratives into mainstream clinical practice. Smart and Smart recognizes {{the addition of the}} category, and similar improvements in the fourth version, as a step forward for the cultural sensitivity of the DSM manual. Greyson, representing the field of Near-death studies, concludes that the diagnostic category of Religious or spiritual problem [...] "permits differentiation of near-death experiences and similar experiences from mental disorders". In a study from 2000 Milstein and colleagues reported that their findings provided empirical evidence for the <b>construct</b> <b>validity</b> of the new DSM-IV category religious or spiritual problem (V62.89).|$|E
50|$|<b>Construct</b> <b>validity</b> is {{essential}} to the perceived overall validity of the test. <b>Construct</b> <b>validity</b> is particularly important in the social sciences, psychology, psychometrics and language studies.|$|E
50|$|Evaluation of <b>construct</b> <b>validity</b> {{requires}} that the correlations of the measure be examined in regard to variables that {{are known to be}} related to the construct (purportedly measured by the instrument being evaluated or for which there are theoretical grounds for expecting it to be related). This is consistent with the multitrait-multimethod matrix (MTMM) of examining <b>construct</b> <b>validity</b> described in Campbell and Fiske's landmark paper (1959). There are other method to evaluate <b>construct</b> <b>validity</b> besides MTMM. It can be evaluated through different forms of factor analysis, structural equation modeling (SEM), and other statistical evaluations. It is important to note that a single study does not prove <b>construct</b> <b>validity.</b> Rather it is a continuous process of evaluation, reevaluation, refinement, and development. Correlations that fit the expected pattern contribute evidence of <b>construct</b> <b>validity.</b> <b>Construct</b> <b>validity</b> is a judgment based on the accumulation of correlations from numerous studies using the instrument being evaluated.|$|E
40|$|Abstract The aims of {{this study}} were to test the face, content, and <b>construct</b> <b>validities</b> of a virtual-reality haptic {{arthroscopy}} simulator and to validate four assessment hypothesis. The participants in our study were 94 arthros-copists attending an international conference on arthroscopy. The interviewed surgeons had been performing arthroscop-ies for a mean of 8. 71 years (r = 6. 94 years). We explained the operation, functionality, instructions for use, and the exercises provided by the simulator. They performed a trial exercise and then an exercise in which performance was recorded. After having using it, the arthroscopists answered a questionnaire. The simulator was classified {{as one of the best}} training methods (over phantoms), and obtained a mark of 7. 10 out of 10 as an evaluation tool. The simulator was considered more useful for inexperienced surgeons than fo...|$|R
30|$|Evaluation of the {{relevance}} of the items by a panel of 20 educational psychologists indicated that 27 of the 32 initial items were “essential” to evaluate university’s student engagement by {{at least half of the}} specialists (CVR[*]>[*] 0) (see Table  1). These items were then subjected to a confirmatory factor analysis for the assessment of <b>construct</b> related <b>validity.</b>|$|R
40|$|Measurement {{scholars}} have recently <b>constructed</b> <b>validity</b> arguments {{in support of}} a variety of educational assessments, including classroom observation instruments. In this article, we note that users must examine the robustness of validity arguments to variation in the implementation of these instruments. We illustrate how such an analysis might be used to assess a <b>validity</b> argument <b>constructed</b> for the Mathematical Quality of Instruction instrument, focusing in particular on the 20 effects of varying the rater pool, subject matter content, observation procedure, and district context. Variation in the subject matter content of lessons did not affect rater agreement with master scores, but the evaluation of other portions of the validity argument varied according to the composition of the rater pool, observation procedure, and district context. These results demonstrate the need for conducting such analyses, especially for classroom observation instruments that are subject to 25 multiple sources of variation...|$|R
5000|$|<b>Construct</b> <b>validity</b> is [...] "the {{degree to}} which a test {{measures}} what it claims, or purports, to be measuring." [...] In the classical model of test validity, <b>construct</b> <b>validity</b> is one of three main types of validity evidence, alongside content validity and criterion validity. Modern validity theory defines <b>construct</b> <b>validity</b> as the overarching concern of validity research, subsuming all other types of validity evidence.|$|E
5000|$|There are a lack {{of studies}} that support the <b>construct</b> <b>validity</b> of the CD-RISC. In order for a measure to {{demonstrate}} good <b>construct</b> <b>validity,</b> {{it needs to be}} based on a complex, detailed theoretical construct (i.e., nomological network). If the measure has good <b>construct</b> <b>validity,</b> then it should [...] "behave" [...] as a measure of this complex concept should behave. The CD-RISC has been associated as expected (i.e., either positively or negatively) with various constructs, such as family functioning and depressive symptoms. However, it needs to be tested in relation to a more complex theory to better establish <b>construct</b> <b>validity.</b>|$|E
50|$|<b>Construct</b> <b>validity</b> {{refers to}} the extent to which the {{independent}} and dependent variables in a study represent the abstract hypothetical variables of interest. In other words, it has to do with whether the manipulated and/or measured variables in a study accurately reflect the variables the researcher hoped to manipulate. <b>Construct</b> <b>validity</b> also reflects the quality of one’s operational definitions. If a researcher has done a good job of converting the abstract to the observable, <b>construct</b> <b>validity</b> is high.|$|E
40|$|Using four {{samples from}} the United States and China, we {{developed}} two theoretically based abridged job insecurity (JI) scales to address researcher concerns with {{the length of the}} original 57 -item scale. These two scales contained all the components of the scale originally developed and validated by Ashford et al., 1989. Our abridged scale has 37 items (18 items for job features, 16 items for total job, and 3 items for powerlessness). We further developed a bare-bones scale with only 25 items (10 items for job features, 12 items for total job, and 3 items for powerlessness). Results show that the content and <b>construct</b> <b>validities</b> of both the abridged and the bare-bones scales are highly similar to the original JI scale. Our results provide support for the use of either the abridged or the bare-bones JI scales. Copyright © 2007 John Wiley & Sons, Ltd...|$|R
40|$|The study {{investigated}} the relationship of reliability and validity. Three psychological tests were administered on 268 Nigerian secondary school students spread over forms one, three and five. The tests were administered twice within a period of 6 weeks to allow for computation of test-retest reliability. The Cronhach’s r, the Split-half r, the Spearman Brown r and the Kuder-Richardson (KR 20) r were also derived. Content and <b>Construct</b> <b>Validities</b> were established through Z-test, t-test, factor analysis and correlation coefficient. It was concluded that when {{it is said that}} valid tests are reliable, it is the internal consistency reliability that is being referred to rather than the rest-retest reliability. In essence, not all valid tests will necessarily furnish indices of reliability on all types of reliability coefficients. Apart from raising some issues for further study, the finding has important implications for psychological tests’ development and usage...|$|R
30|$|As {{with any}} {{research}} method, there are limitations related to our choice of research methods. These {{can be divided}} into threats to external, <b>construct,</b> and internal <b>validity.</b>|$|R
