10000|10000|Public
5|$|A <b>cluster</b> is a {{group of}} loosely coupled {{computers}} that work together closely, so that in some respects they can be regarded as a single computer. Clusters are composed of multiple standalone machines connected by a network. While machines in a <b>cluster</b> {{do not have to be}} symmetric, load balancing is more difficult if they are not. The most common type of <b>cluster</b> is the Beowulf <b>cluster,</b> which is a <b>cluster</b> implemented on multiple identical commercial off-the-shelf computers connected with a TCP/IP Ethernet local area network. Beowulf technology was originally developed by Thomas Sterling and Donald Becker. The vast majority of the TOP500 supercomputers are clusters.|$|E
5|$|Andromeda's {{most celebrated}} open <b>cluster</b> is NGC 752 (Caldwell 28) at an overall {{magnitude}} of 5.7. It is a loosely scattered <b>cluster</b> in the Milky Way that measures 49 arcminutes across and features approximately twelve bright stars, although more than 60 stars of approximately 9th magnitude become visible at low magnifications in a telescope. It {{is considered to}} be one of the more inconspicuous open clusters. The other open <b>cluster</b> in Andromeda is NGC 7686, which has a similar magnitude of 5.6 and is also a part of the Milky Way. It contains approximately 20 stars in a diameter of 15 arcminutes, making it a tighter <b>cluster</b> than NGC 752.|$|E
5|$|As {{a result}} of a tidal shock, streams of stars can be pulled away from the <b>cluster</b> halo, leaving only the core part of the <b>cluster.</b> These tidal {{interaction}} effects create tails of stars that can extend up to several degrees of arc away from the <b>cluster.</b> These tails typically both precede and follow the <b>cluster</b> along its orbit. The tails can accumulate significant portions of the original mass of the <b>cluster,</b> and can form clumplike features.|$|E
40|$|Abstract — <b>Clustering</b> {{is related}} to data mining for {{information}} retrieval. Relevant information is retrieved quickly while doing the <b>clustering</b> of documents. It organizes the documents into groups; each group contains the documents of similar type content. Different <b>clustering</b> algorithms are used for <b>clustering</b> the documents such as partitioned <b>clustering</b> (K-means <b>Clustering)</b> and Hierarchical <b>Clustering</b> (Agglomerative Hierarchical <b>Clustering</b> (AHC)). This paper presents analysis of Semantic Suffix Tree <b>Clustering</b> (SSTC) Algorithm and other <b>clustering</b> techniques (K-means, AHC, and Lingo). SSTC perform the <b>clustering</b> and make the <b>clusters</b> based on synonyms shared between the documents. SSTC is faster <b>clustering</b> algorithm for document <b>clustering</b> as it is incremental...|$|R
40|$|Abstract-Data <b>clustering</b> is {{a process}} of putting similar data into groups. A <b>clustering</b> {{algorithm}} partitions a data set into several groups such that the similarity within a group is larger than among groups. This paper reviews six types of <b>clustering</b> techniques- k-Means <b>Clustering,</b> Hierarchical <b>Clustering,</b> DBScan <b>clustering,</b> Density Based <b>Clustering,</b> Optics, EM Algorithm. These <b>clustering</b> techniques are implemented and analysed using a <b>clustering</b> tool WEKA. Performance of the 6 techniques are presented and compared. Index Terms-Data <b>clustering,</b> K-Means <b>Clustering...</b>|$|R
40|$|This chapter surveys common <b>clustering</b> {{algorithms}} {{widely used}} in the data mining community in light of chemometrics. It starts with taxonomy of <b>clustering</b> algorithms, and discusses two common <b>clustering</b> approaches – partitioning <b>clustering</b> and hierarchical <b>clustering</b> – in detail. Several variants of these <b>clustering</b> methods are presented and their strengths and weaknesses are addressed. This chapter continues to overview hybrid <b>clustering</b> approaches combining partitioning <b>clustering</b> and hierarchical <b>clustering,</b> and concludes with a quick overview on constrained <b>clustering...</b>|$|R
5|$|<b>Cluster</b> {{diffusion}} involves {{motion of}} atomic clusters {{ranging in size}} from dimers to islands containing hundreds of atoms. Motion of the <b>cluster</b> may occur via the displacement of individual atoms, sections of the <b>cluster,</b> or the entire <b>cluster</b> moving at once. All of these processes involve a change in the cluster’s center of mass.|$|E
5|$|Concerted {{mechanisms}} {{are those that}} involve movement of either sections of the <b>cluster</b> or the entire <b>cluster</b> all at once.|$|E
5|$|Evaporation-condensation {{involves}} atoms “evaporating” {{from the}} <b>cluster</b> onto a terrace accompanied by “condensation” of terrace adatoms onto the <b>cluster</b> {{leading to a}} change in the cluster’s center of mass. While figure 10 appears to indicate the same atom evaporating from and condensing on the <b>cluster,</b> it may in fact be a different atom condensing from the 2D gas.|$|E
30|$|<b>Clustering</b> is a {{well-known}} means of organizing networks in MANETs. Many <b>clustering</b> solutions, including identifier neighbor-based <b>clustering,</b> topology-based <b>clustering,</b> mobility-based <b>clustering,</b> energy-based <b>clustering,</b> and weight-based <b>clustering,</b> have been proposed [14 - 21]. However, these <b>clustering</b> solutions significantly differ from vehicular <b>clustering.</b> MANETs are primarily limited because of their energy [22] and processing power; hence, their <b>clustering</b> is optimized for low-resource usage. However, vehicles are not only rich in resources, {{but they are also}} highly mobile. Consequently, <b>clustering</b> algorithms for MANETs are not effective in VANETs, and new solutions must be developed.|$|R
40|$|Data mining is the {{mechanism}} of implementing patterns in large amount of data sets involving methods {{at the intersection of}} artificial intelligence, machine learning, statistics, and database systems. <b>Clustering</b> is the very big area in which grouping of same type of objects in data mining. <b>Clustering</b> has divided into different categories – partitioned <b>clustering</b> and hierarchical <b>clustering.</b> In this paper we study two types of <b>clustering</b> first is Kmeans which is part of partitioned <b>clustering.</b> Kmeans <b>clustering</b> generates a specific number of disjoint, flat (non-hierarchical) <b>clusters.</b> Second <b>clustering</b> is robust <b>clustering</b> which is part of hierarchical <b>clustering.</b> This <b>clustering</b> uses Jaccard coefficient instead of using the distance measures to find the similarity between the data or documents to classify the <b>clusters.</b> We show comparison between Kmeans <b>clustering</b> and robust <b>clustering</b> which is better for categorical data...|$|R
3000|$|Depending on the <b>clustering</b> rules, {{existing}} <b>clustering</b> algorithms can {{be roughly}} {{divided into three}} categories: hierarchical <b>clustering,</b> partition based <b>clustering,</b> and grid-based <b>clustering.</b> The [...]...|$|R
5|$|Finally {{the tidal}} radius, or Hill sphere, is the {{distance}} {{from the center of the}} globular <b>cluster</b> at which the external gravitation of the galaxy has more influence over the stars in the <b>cluster</b> than does the <b>cluster</b> itself. This is the distance at which the individual stars belonging to a <b>cluster</b> can be separated away by the galaxy. The tidal radius of M3 is about 40 arc minutes, or about 113 pc at the distance of 10.4 kpc.|$|E
5|$|IC 410, a faint nebula, is {{accompanied}} by the bright open <b>cluster</b> NGC 1893. The <b>cluster</b> is thin, with a diameter of 12 arcminutes and a population of approximately 20 stars. Its accompanying nebula has very low surface brightness, partially because of its diameter of 40 arcminutes. It appears in an amateur telescope with brighter areas {{in the north and}} south; the brighter southern patch shows a pattern of darker and lighter spots in a large instrument. NGC 1893, of magnitude 7.5, is classified as a Trumpler Class II 3 r n or II 2 m n <b>cluster,</b> meaning that it is not very large and is somewhat bright. The <b>cluster</b> possesses approximately 30 stars of magnitude 9–12. In an amateur instrument, IC 410 is only visible with an Oxygen-III filter. NGC 2281 is a small open <b>cluster</b> at a distance of 1,500 light-years. It contains 30 stars in a crescent shape. It has an overall magnitude of 5.4 and a fairly large diameter of 14.0 arcseconds, classified as a Trumpler Class I 3 m <b>cluster.</b> The brightest star in the <b>cluster</b> is magnitude 8; there are approximately 12 stars of magnitude 9–10 and 20 stars of magnitude 11–13.|$|E
5|$|It was {{formerly}} {{thought that the}} dust was {{left over from the}} formation of the <b>cluster,</b> but at the age of about 100 million years generally accepted for the <b>cluster,</b> almost all the dust originally present would have been dispersed by radiation pressure. Instead, it seems that the <b>cluster</b> is simply passing through a particularly dusty region of the interstellar medium.|$|E
40|$|<b>Clustering</b> {{is related}} to data mining for {{information}} retrieval. Relevant information is retrieved quickly while doing the <b>clustering</b> of documents. It organizes the documents into groups; each group contains the documents of similar type content. Document <b>clustering</b> is an unsupervised approach of data mining. Different <b>clustering</b> algorithms are used for <b>clustering</b> the documents such as partitioned <b>clustering</b> (K-means <b>Clustering)</b> and Hierarchical <b>Clustering</b> (Agglomerative Hierarchical <b>Clustering</b> (AHC)). This paper presents analysis of Suffix Tree <b>Clustering</b> (STC) Algorithm and other <b>clustering</b> techniques (K-means, AHC) that are being done in literature survey. The paper also focuses on traditional Vector Space Model (VSM) for similarity measures, which is used for <b>clustering</b> the documents. This paper also focuses on the comparison of different <b>clustering</b> algorithms. STC algorithm improves the searching performance as compare to other <b>clustering</b> algorithms as the papers studied in literature survey. The paper presents STC algorithm applied on the search result documents, which is stored in the dataset. This paper articulates the key requirements for web document <b>clustering</b> and <b>clusters</b> would be created on {{the full text of}} the web documents. STC perform the <b>clustering</b> and make the <b>clusters</b> based on phrases shared between the documents. STC is faster <b>clustering</b> algorithm for document <b>clustering...</b>|$|R
40|$|<b>Clustering</b> aims at {{grouping}} data objects into meaningful <b>clusters</b> using no (or only a {{small amount}} of) supervision. This thesis studies two major cluster-ing paradigms: density-based and semi-supervised <b>clustering.</b> Density-based <b>clustering</b> algorithms seek partitions with high-density areas of points (<b>clusters</b> that are not necessarily globular) separated by low-density areas that may con-tain noise objects. Semi-supervised <b>clustering</b> algorithms use a small amount of information about data to guide the <b>clustering</b> task. In the context of density-based <b>clustering,</b> we study (a) the validation of density-based <b>clustering</b> and (b) hierarchical density-based <b>clustering.</b> The validation of density-based <b>clustering,</b> i. e., the objective and quanti-tative assessment of <b>clustering</b> results, {{is one of the most}} challenging aspects of <b>clustering.</b> Numerous different relative validity criteria have been proposed for the validation of globular <b>clusters.</b> Not all data, however, are composed of globular <b>clusters.</b> We propose a relative density-based validation index, DBCV...|$|R
40|$|We {{study the}} {{distribution}} of X-ray selected <b>clusters</b> of galaxies with respect to superclusters determined by Abell <b>clusters</b> of galaxies and show that {{the distribution of}} X-ray <b>clusters</b> follows the supercluster-void network determined by Abell <b>clusters.</b> We find that in this network X-ray <b>clusters</b> are more strongly <b>clustered</b> than other <b>clusters.</b> Poor, non-Abell X-ray <b>clusters</b> follow the supercluster-void network as well: these <b>clusters</b> are embedded in superclusters determined by rich <b>clusters</b> and populate filaments between them. We present a new catalog of superclusters of Abell <b>clusters</b> out to a redshift of z_{lim}= 0. 13, a catalog of X-ray <b>clusters</b> located in superclusters determined by Abell <b>clusters,</b> {{and a list of}} additional superclusters of X-ray <b>clusters.</b> Comment: LaTex (sty files added), 16 pages, 3 ps figures, submitted to Astronomical Journal. Animations of the 3 D distribution of superclusters of Abell and X-ray <b>clusters</b> at [URL]...|$|R
5|$|M53 (NGC 5024) is a {{globular}} <b>cluster</b> {{which was}} discovered independently by Johann Elert Bode in 1775 and Charles Messier in February 1777; William Herschel {{was the first}} to resolve it into stars. The magnitude-7.7 <b>cluster</b> is 56,000 light-years from Earth. Only 1° away is NGC 5053, a globular <b>cluster</b> with a sparser nucleus of stars. Its total luminosity is the equivalent of about 16,000 suns, one of the lowest luminosities of any globular <b>cluster.</b> It was discovered by William Herschel in 1784. NGC 4147 is a somewhat dimmer globular <b>cluster,</b> with a much-smaller apparent size.|$|E
5|$|Naveen Andrews as Jonas Maliki, a sensate from a {{different}} <b>cluster</b> who wants to help the newly-born <b>cluster</b> of sensates.|$|E
5|$|One way of {{clustering}} {{a set of}} {{data points}} in a metric space into two clusters is to choose the clusters {{in such a way}} as to minimize the sum of the diameters of the clusters, where the diameter of any single <b>cluster</b> is the largest distance between any two of its points. This is preferable to minimizing the maximum <b>cluster</b> size, which may lead to very similar points being assigned to different clusters. If the target diameters of the two clusters are known, a clustering that achieves those targets may be found by solving a 2-satisfiability instance. The instance has one variable per point, indicating whether that point belongs to the first <b>cluster</b> or the second <b>cluster.</b> Whenever any two points are too far apart from each other for both to belong to the same <b>cluster,</b> a clause is added to the instance that prevents this assignment.|$|E
40|$|Abstract — Image {{segmentation}} places {{an important}} role in image processing. This segmentation process can be done using various techniques like <b>clustering,</b> thresholding, edge detection and region extraction. This paper gives introduction to image processing operations and <b>clustering</b> process. Then the overview and algorithmic process of each <b>clustering</b> technique such as K-Means <b>clustering,</b> Kernel K-Means <b>clustering,</b> Fuzzy C-Mean and Graph based <b>clustering</b> is discussed. Index Terms — Fuzzy C-Mean, Graph based <b>clustering,</b> Image segmentation, Kernel K-Means <b>clustering,</b> K-Means <b>clustering...</b>|$|R
40|$|Background: Simple <b>clustering</b> {{methods such as}} {{hierarchical}} <b>clustering</b> and k-means {{are widely}} used for gene expression data analysis; but {{they are unable to}} deal with noise and high dimensionality associated with the microarray gene expression data. Consensus <b>clustering</b> appears to improve the robustness and quality of <b>clustering</b> results. Incorporating prior knowledge in <b>clustering</b> process (semi-supervised <b>clustering)</b> has been shown to improve the consistency between the data partitioning and domain knowledge. Methods. We proposed semi-supervised consensus <b>clustering</b> (SSCC) to integrate the consensus <b>clustering</b> with semi-supervised <b>clustering</b> for analyzing gene expression data. We investigated the roles of consensus <b>clustering</b> and prior knowledge in improving the quality of <b>clustering.</b> SSCC was compared with one semi-supervised <b>clustering</b> algorithm, one consensus <b>clustering</b> algorithm, and k-means. Experiments on eight gene expression datasets were performed using h-fold cross-validation. Results: Using prior knowledge improved the <b>clustering</b> quality by reducing the impact of noise and high dimensionality in microarray data. Integration of consensus <b>clustering</b> with semi-supervised <b>clustering</b> improved performance as compared to using consensus <b>clustering</b> or semi-supervised <b>clustering</b> separately. Our SSCC method outperformed the others tested in this paper. Peer reviewed: YesNRC publication: Ye...|$|R
40|$|Abstract — <b>Clustering</b> {{is related}} to data mining for {{information}} retrieval. Relevant information is retrieved quickly while doing the <b>clustering</b> of documents. It organizes the documents into groups; each group contains the documents of similar type content. Document <b>clustering</b> is an unsupervised approach of data mining. Different <b>clustering</b> algorithms are used for <b>clustering</b> the documents such as partitioned <b>clustering</b> (K-means <b>Clustering)</b> and Hierarchical <b>Clustering</b> (Agglomerative Hierarchical <b>Clustering</b> (AHC)). This paper presents analysis of Suffix Tree <b>Clustering</b> (STC) Algorithm and other <b>clustering</b> techniques (K-means, AHC) that are being done in literature survey. The paper also focuses on traditional Vector Space Model (VSM) for similarity measures, which is used for <b>clustering</b> the documents. This paper also focuses on the comparison of different <b>clustering</b> algorithms. STC algorithm improves the searching performance as compare to other <b>clustering</b> algorithms as the papers studied in literature survey. The paper presents STC algorithm applied on the search result documents, which is stored in the dataset. This paper articulates the key requirements for web document <b>clustering</b> and <b>clusters</b> would be created on {{the full text of}} the web documents. STC perform the <b>clustering</b> and make the <b>clusters</b> based on phrases shared between the documents. STC is faster <b>clustering</b> algorithm fo...|$|R
5|$|Size-dependence: {{the rate}} of <b>cluster</b> {{diffusion}} has a strong dependence {{on the size of}} the <b>cluster,</b> with larger <b>cluster</b> size generally corresponding to slower diffusion. This is not, however, a universal trend and it has been shown in some systems that the diffusion rate takes on a periodic tendency wherein some larger clusters diffuse faster than those smaller than them.|$|E
5|$|The <b>cluster</b> has {{generated}} lava ranging in composition from andesite to dacite, {{with the main}} volcano being exclusively of dacitic composition. Systematic variations in temperature, crystal and biotite content have been recorded during {{the evolution of the}} <b>cluster.</b>|$|E
5|$|The {{results of}} N-body {{simulations}} {{have shown that}} the stars can follow unusual paths through the <b>cluster,</b> often forming loops and often falling more directly toward the core than would a single star orbiting a central mass. In addition, due to interactions with other stars that result in an increase in velocity, some of the stars gain sufficient energy to escape the <b>cluster.</b> Over long periods of time this will result in a dissipation of the <b>cluster,</b> a process termed evaporation. The typical time scale for the evaporation of a globular <b>cluster</b> is 1010 years. In 2010 it became possible to directly compute, star by star, N-body simulations of a globular <b>cluster</b> over the course of its lifetime.|$|E
40|$|U*C is a {{recently}} proposed <b>clustering</b> algorithm using Emergent Self-Organizing Maps (ESOM). U*C <b>clustering</b> {{is superior to}} standard <b>clustering</b> algorithms such as K-means and hierarchical <b>clustering.</b> This work illumintaes the advantages and limitations of U*C <b>clustering</b> compared to other <b>clustering</b> algorithms. Some insights into the principles of ESOM/U*-maps visualization and <b>clustering</b> techniques are also presented. ...|$|R
40|$|Abstract. Representative-based <b>clustering</b> {{algorithms}} {{are quite}} {{popular due to}} their relative high speed and because of their sound theoretical foundation. On the other hand, the <b>clusters</b> they can obtain are limited to convex shapes and <b>clustering</b> results are also highly sensitive to initializations. In this paper, a novel agglomerative <b>clustering</b> algorithm called MOSAIC is proposed which greedily merges neighboring <b>clusters</b> maximizing a given fitness function. MOSAIC uses Gabriel graphs to determine which <b>clusters</b> are neighboring and approximates non-convex shapes as the unions of small <b>clusters</b> that have been computed using a representative-based <b>clustering</b> algorithm. The experimental results show that this technique leads to <b>clusters</b> of higher quality compared to running a representative <b>clustering</b> algorithm standalone. Given a suitable fitness function, MOSAIC is able to detect arbitrary shape <b>clusters.</b> In addition, MOSAIC is capable of dealing with high dimensional data. Keywords: Post-processing, hybrid <b>clustering,</b> finding <b>clusters</b> of arbitrary shape, agglomerative <b>clustering,</b> using proximity graphs for <b>clustering.</b> ...|$|R
30|$|<b>Clustering</b> is {{considered}} as an unsupervised classification process [4]. A {{large number of}} <b>clustering</b> algorithms {{have been developed for}} different purposes [4 – 6]. <b>Clustering</b> techniques can be categorised into Partitioning <b>clustering,</b> Hierarchical <b>clustering,</b> Density-based methods, Grid-based methods and Model based <b>clustering</b> methods.|$|R
5|$|The use of M85S <b>cluster</b> bombs by the Georgians and RBK 250 <b>cluster</b> bombs by the Russians {{resulted}} in civilian casualties. Georgia {{was reported to}} have used <b>cluster</b> munitions twice to hit civilians fleeing via the main escape road and admitted using <b>cluster</b> bombs against Russian troops and near the Roki Tunnel. Russia denied using <b>cluster</b> bombs.|$|E
5|$|After {{they are}} formed, {{the stars in}} the {{globular}} <b>cluster</b> begin to interact gravitationally with each other. As a result, the velocity vectors of the stars are steadily modified, and the stars lose any history of their original velocity. The characteristic interval for this to occur is the relaxation time. This is related to the characteristic length of time a star needs to cross the <b>cluster</b> as well as the number of stellar masses in the system. The value of the relaxation time varies by <b>cluster,</b> but the mean value is on the order of 109 years.|$|E
5|$|Another massive {{globular}} <b>cluster,</b> named 037-B327 {{and discovered}} in 2006 as is heavily reddened by the Andromeda Galaxy's interstellar dust, {{was thought to}} be more massive than G1 and the largest <b>cluster</b> of the Local Group; however, other studies have shown it is actually similar in properties to G1.|$|E
40|$|<b>Clustering</b> is one {{basic and}} {{important}} data mining approach used independently {{as well as}} the pre-processing stage in many data mining applications. The <b>clustering</b> process basically divides the available dataset into smaller subsets called <b>clusters.</b> These <b>clusters</b> are generally substantially different from one other. In this present work, the <b>clustering</b> is performed on text documents. Text document <b>clustering</b> basically divide the available documents in sub groups based on <b>clustering</b> parameters. The document <b>clustering</b> includes number of basic phenomenon such as document organization, topic extraction and the information retrieval. In this, an improvement <b>clustering</b> approach is defined over the basic <b>clustering</b> approach. The basic <b>clustering</b> approaches that we have to improve in this work areK-Means <b>Clustering</b> and C-Means <b>Clustering.</b> The improvement is here done with the inclusion of PSO (Particle Swarm Optimization...|$|R
40|$|Abstract. <b>Clustering</b> analysis, as a {{practical}} data mining method, has wide-ranging applications in many fields. But because of different original data resources, <b>clustering</b> results of different data distribution patterns and applicable <b>clustering</b> evaluation methods are different from each other. Aiming at different data distribution patterns, only reasonable <b>clustering</b> evaluation methods can achieve a better recognition of different <b>clustering</b> results for realizing the application value of <b>clustering</b> technology. In this paper, the combination <b>clustering</b> evaluation model is constructed form three angles, through <b>clustering</b> experiment of different artificial simulated data distribution patterns, comparative analysis draw a conclusion that the combination <b>clustering</b> evaluation model constructed is reasonable, and according to applicable <b>clustering</b> and <b>clustering</b> evaluation methods based on different data distribution patterns, the optimization <b>clustering</b> process is constructed for improving the effectiveness and interpretability of different <b>clustering</b> results...|$|R
40|$|This paper {{presents}} the experiments and {{results of a}} <b>clustering</b> approach for <b>clustering</b> of the large Wikipedia dataset in the INEX 2007 Document Mining Challenge. The <b>clustering</b> approach employed makes use of an incremental <b>clustering</b> method and a pairwise <b>clustering</b> method. The approach enables us to perform the <b>clustering</b> task on a large dataset by first reducing the dimension of the dataset to an undefined number of <b>clusters</b> using the incremental method. The lower-dimension dataset is then <b>clustered</b> to a required number of <b>clusters</b> using the pairwise method. In this way, <b>clustering</b> of {{the large number of}} documents is performed successfully and the accuracy of the <b>clustering</b> solution is achieved...|$|R
