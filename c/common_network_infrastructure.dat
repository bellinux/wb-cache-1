15|10000|Public
50|$|At {{the time}} the National Science Foundation (NSF) {{believed}} in a settlement model based on usage, with payments or contributions based on how much data was sent or received, mirroring the public X.25 networks at that time. Such a settlement policy would allow research and education and commercial traffic to share a <b>common</b> <b>network</b> <b>infrastructure</b> without using NSF funds to support the commercial use. NSF in fact entered into {{an agreement with the}} non-profit Advanced Network and Services to allow commercial traffic through a for-profit subsidiary, ANS CO+RE (commercial plus research), subject to the conditions (i) that the NSFNET Backbone Service was not diminished; (ii) that ANS CO+RE recovered at least the average cost of the commercial traffic traversing the network; and (iii) that any excess revenues recovered above the cost of carrying the commercial traffic would be placed into an infrastructure pool to be distributed by an allocation committee broadly representative of the networking community to enhance and extend national and regional networking infrastructure and support.|$|E
50|$|Users may share access over a <b>common</b> <b>network</b> <b>infrastructure.</b> Since most users do not {{use their}} full {{connection}} capacity all of the time, this aggregation strategy (known as contended service) usually works well and users can burst to their full data rate at least for brief periods. However, peer-to-peer (P2P) file sharing and high-quality streaming video can require high data-rates for extended periods, which violates these assumptions and can cause a service to become oversubscribed, resulting in congestion and poor performance. The TCP protocol includes flow-control mechanisms that automatically throttle back on the bandwidth being used during periods of network congestion. This is fair {{in the sense that}} all users that experience congestion receive less bandwidth, but it can be frustrating for customers and a major problem for ISPs. In some cases the amount of bandwidth actually available may fall below the threshold required to support a particular service such as video conferencing or streaming live video-effectively making the service unavailable.|$|E
30|$|Especially for {{operators}} {{with both}} fixed and mobile network infrastructure, cost reduction in future deployment stages {{is of great}} importance. For reuse of <b>common</b> <b>network</b> <b>infrastructure</b> on transport and access layer (Fixed-Mobile Convergence (FMC)), WSDN and NFV are, as well, seen as the key enablers [54] allowing multi-operator network infrastructure and resource sharing in a cost-optimized way. The integration of joint core functionalities belongs to the next steps towards FMC.|$|E
40|$|Convergence of {{data and}} {{telephony}} networks {{is one of the}} current trends in telecommunications. It is supposed that all telephony traffic might be carried over a <b>common</b> data <b>network</b> <b>infrastructure</b> in the future. In accordance with this development, wide area IP telephony network has been deployed in the TEN- 155 CZ network (located in Czech Republic), connected to the European network for research and education TEN- 155...|$|R
40|$|Fault {{tolerant}} {{and distributed}} embedded systems are research {{areas that have}} the interest of such entities as NASA, the Department of Defense, and various other government agencies, corporations, and universities. Taking a system and designing it {{to work in the}} presence of faults is appealing to these entities as it inherently increases the reliability of the deployed system. There are a few different fault tolerant techniques that can be implemented in a system design to handle faults as they occur. One such technique is the reconfiguration of a portion of the system to a redundant resource. This is a difficult task to manage within a distributed embedded system because of the distributed, directly addressed data producer and consumer dependencies that exist in <b>common</b> <b>network</b> <b>infrastructures.</b> It is the goal of this thesis work to develop a novel message routing layer for the communication management of distributed embedded systems that reduces the complexity of this problem. The resulting product of this thesis provides a robust approach to the design, implementation, integration, and deployment of a distribute...|$|R
40|$|Abstract. Scientific {{innovation}} {{continues to}} increase requirements for the computing and networking infrastructures of the world. Collaborative partners, instrumentation, storage, and processing facilities are often geographically and topologically separated, {{as is the case}} with LHC virtual organizations. These separations challenge the technology used to interconnect available resources, often delivered by Research and Education (R&E) networking providers, and leads to complications in the overall process of end-to-end data management. Capacity and traffic management are key concerns of R&E network operators; a delicate balance is required to serve both long-lived, high capacity network flows, as well as more traditional enduser activities. The advent of dynamic circuit services, a technology that enables the creation of variable duration, guaranteed bandwidth networking channels, allows for the efficient use of <b>common</b> <b>network</b> <b>infrastructures.</b> These gains are seen particularly in locations where overall capacity is scarce compared to the (sustained peak) needs of user communities. Related efforts, including those of the LHCOPN [3] operations group and the emerging LHCONE [4] project, may take advantage of available resources by designating specific network activities as a “high priority”, allowing reservation of dedicated bandwidth or optimizing for deadline scheduling an...|$|R
30|$|The {{main idea}} of WNV is to enable {{differentiated}} services {{to run on}} <b>common</b> <b>network</b> <b>infrastructure</b> [3]. In WNV, the traditional role of mobile network provider is separated into two parts. One {{is referred to as}} infrastructure provider (InP), who owns and supervises the overall physical network infrastructure. The other is virtual operator (VO) whose concentration is paid on offering on-demand services to their customers by purchasing resources from InP.|$|E
40|$|The {{integration}} of different mobile transmission technologies into a heterogeneous mobile network {{of the next}} generation is only a question of time. Various transmission technologies have been developed with different goals in mind. Each technology has its strengths and weaknesses in certain areas because they have been designed for different usage scenarios. In next generation mobile networks, the devices will be equipped with several interfaces. Hence, the <b>common</b> <b>network</b> <b>infrastructure</b> will be able to distribute the users over various technologies like UMTS and WLAN, in order to guarantee specific Quality-of-Service (QoS) levels for the users or optimize their perceived quality. The contribution of this work is a proposal of a combined WLAN/UMTS network architecture which we implemented i...|$|E
40|$|Asynchronous Transfer Mode (ATM) is a {{new data}} {{communications}} technology that promises to integrate voice, video, and data traffic into a <b>common</b> <b>network</b> <b>infrastructure.</b> In order to fully utilize ATM`s ability to transfer real-time data at high rates, applications will start to access the ATM layer directly. As {{a result of this}} trend, security mechanisms at the ATM layer will be required. A number of research programs are currently in progress which seek to better understand the unique issues associated with ATM security. This paper describes some of these issues, and the approaches taken by various organizations in the design of ATM layer security mechanisms. Efforts within the ATM Forum to address the user communities need for ATM security are also described...|$|E
30|$|The key {{technologies}} of WNV include wireless network function virtualization and wireless resource virtualization. Wireless network function virtualization leads to various deployment solutions such as cloud radio access network(C-RAN) and F-RAN. The motivations for virtualizing a wireless network diverse from enabling the infrastructure sharing among several operators, offering {{a layer of}} abstraction to simplify network management and programmability of wireless networks as well as network slicing based on service, user, or application [6 – 8]. Virtualization of a wireless network can be applied at different layers and degrees. Virtualizing radio spectrum and physical layer of base stations allows sharing spectrum as well as <b>common</b> access <b>network</b> <b>infrastructure,</b> which includes opportunistic sensing to discover scenario-dependent optimal platform [9], deep sensing for spectrum resources [10, 11], and radio resources allocation in RAN. Another respect of virtualization resources is computing, storage, and networking resources deployed in RAN regarding the requirements of cloudified applications [6 – 8].|$|R
40|$|Scientific {{innovation}} {{continues to}} increase requirements for the computing and networking infrastructures of the world. Collaborative partners, instrumentation, storage, and processing facilities are often geographically and topologically separated, {{as is the case}} with LHC virtual organizations. These separations challenge the technology used to interconnect available resources, often delivered by Research and Education (R&E) networking providers, and leads to complications in the overall process of end-to-end data management. Capacity and traffic management are key concerns of R&E network operators; a delicate balance is required to serve both long-lived, high capacity network flows, as well as more traditional end-user activities. The advent of dynamic circuit services, a technology that enables the creation of variable duration, guaranteed bandwidth networking channels, allows for the efficient use of <b>common</b> <b>network</b> <b>infrastructures.</b> These gains are seen particularly in locations where overall capacity is scarce compared to the (sustained peak) needs of user communities. Related efforts, including those of the LHCOPN operations group and the emerging LHCONE project, may take advantage of available resources by designating specific network activities as a "high priority", allowing reservation of dedicated bandwidth or optimizing for deadline scheduling and predicable delivery patterns. This paper presents the DYNES instrument, an NSF funded cyberinfrastructure project designed to facilitate end-to-end dynamic circuit services. This combination of hardware and software innovation is being deployed across R&E networks in the United States at selected end-sites located on University Campuses. DYNES is peering with international efforts in other countries using similar solutions, and is increasing the reach of this emerging technology. This global data movement solution could be integrated into computing paradigms such as cloud and grid computing platforms, and through the use of APIs can be integrated into existing data movement software...|$|R
40|$|Traditional analog video {{surveillance}} systems technology has recently become inadequate {{to face the}} massive demand of security systems consisting of hundreds and sometimes thousands of cameras often deployed in hostile environments tens of miles {{far away from the}} control room. During the last few years, the rapid growth of the digital technology has produced sophisticated cameras which can directly record high-definition digital videos. The packetized video stream can be straightforwardly conveyed to the control room relaying on <b>common</b> IP <b>network</b> <b>infrastructures.</b> This solution results extremely flexi-ble as the <b>network</b> <b>infrastructure</b> can be built over a wide variety of heterogeneous network technologies from the traditional Ethernet-based Local Area Networks (LANs) to the recently proposed Wireless Mesh Networks (WMNs). However, the widespread adoption of IP-based solutions for video surveil-lance poses serious problems in terms of required bandwidth, processing power, network security and system dependability. In this paper, we first investigate the advantages of the IP-based video surveil-lance systems over the traditional analog ones. Then, we describe the technical challenges and the open research issues which still lack an ultimate solution which permits to completely abandon the traditional analog technology. Finally, we propose and verify, by means of a case study, a methodology to address the design of {{video surveillance}} systems in real deployment...|$|R
40|$|In {{this paper}} we present an {{application}} of the Fixed Mobile Convergence approach developed in the EU COMBO project for the seamless delivery of fixed and mobile services using a <b>common</b> <b>network</b> <b>infrastructure</b> and set of functions. In particular, we apply this approach within a convergent multilayer packet-optical aggregation network {{in order to provide}} QoS support to the transport of packet services regardless of the access technology. As a proof of concept of our approach, we developed a Fixed Mobile Convergence testbed that integrates the LTE-EPC LENA emulator and the multi-layer ADRENALINE testbed. We describe and experimentally validate how this integration is done on the data plane to provide the end-to-end transport of LTE mobile services through the packet-optical aggregation network...|$|E
30|$|Nowadays, the IEEE 802.11 [1] {{wireless}} {{local area}} networks (WLANs) {{have become the}} <b>common</b> <b>network</b> <b>infrastructure</b> for most organizations. In typical wireless environments, the bandwidth will be shared among wireless devices, while wireless access points or routers act as hubs connecting these devices together. In general, the bandwidth may not be equally shared among users in the same WLAN, because some users may utilize greedy applications that consume much larger bandwidth and consequently prevent other applications from connecting to the Internet. These applications include, for example, video streaming applications, download accelerators that create many sessions for each download, and the P 2 P applications such as BitTorrent. Moreover, traffic from wireless stations mounting denial-of-service (DoS) attacks or infected by a virus may overwhelm the network. This problem is particularly crucial for the wireless network environments since the bandwidth is very scarce. To alleviate this problem, per-station fairness shall be guaranteed. By fairness, we mean each wireless client {{should be able to}} evenly obtain the maximum bandwidth.|$|E
40|$|Recent {{research}} has demonstrated the benefits of active networks: customized network services can easily be built and modified, packet streams can be processed inside the network, etc. This paper addresses the question how the benefits of active networking can be exploited in a telecom environment, where {{a large number of}} customers must share a <b>common</b> <b>network</b> <b>infrastructure.</b> We introduce a framework that allows customers to deploy and manage their own active services in a provider domain. The key concept in this framework is the Virtual Active Network (VAN). A VAN is a generic service, offered by the provider to the customer. From the customer's point of view, a VAN represents an environment on which the customer can install, run and manage active network services, without further interaction with the provider. From the provider 's perspective, the VAN serves as the entity for partitioning the provider's resources and isolating customers from one another in virtual environments. We d [...] ...|$|E
40|$|We {{demonstrate}} {{the design and}} an early prototype of IrisNet (Internet-scale Resource-Intensive Sensor <b>Network</b> services), a <b>common,</b> scalable <b>networked</b> <b>infrastructure</b> for deploying wide area sensing services. IrisNet is a potentially global network of smart sensing nodes, with webcams or other monitoring devices, and organizing nodes that provide the means to query recent and historical sensor-based data. IrisNet exploits the fact that high-volume sensor feeds are typically attached to devices with significant computing power and storage, and running a standard operating system. It uses aggressive filtering, smart query routing, and semantic caching to dramatically reduce network bandwidth utilization and improve query response times, as we demonstrate. Our demo will present two services built on IrisNet, from two very di#erent application domains. The first one, a parking space finder, utilizes webcams that monitor parking spaces to answer queries such as the availability of parking spaces near a user's destination. The second one, a distributed infrastructure monitor, uses measurement tools installed in individual nodes of a large distributed infrastructure to answer queries such as average network bandwidth usage {{of a set of}} nodes...|$|R
40|$|Network slicing is a {{fundamental}} capability for future 5 G networks to properly support current and envisioned future application scenarios. Network slicing facilitates a cost-effective deployment and operation of multiple logical <b>networks</b> over a <b>common</b> physical <b>network</b> <b>infrastructure</b> such that each network is customized to best {{serve the needs of}} specific applications (e. g., mobile broadband, Internet of Things applications) and/or communications service providers (e. g., special purpose service providers for different sectors such as public safety, utilities, smart city, and automobiles). Slicing a RAN becomes particularly challenging due to the inherently shared nature of the radio channel and the potential influence that any transmitter may have on any receiver. In this respect, this article analyzes the RAN slicing problem in a multi-cell network in relation to the RRM functionalities that {{can be used as a}} support for splitting the radio resources among the RAN slices. Four different RAN slicing approaches are presented and compared from different perspectives, such as the granularity in the assignment of radio resources and the degrees of isolation and customization. Peer ReviewedPostprint (author's final draft...|$|R
40|$|The {{proliferation}} and affordability of webcams has created opportunities for exciting new classes of distributed services. A key stumbling block to mining these rich information sources {{is the lack}} of a <b>common,</b> scalable <b>networked</b> <b>infrastructure</b> for collecting, filtering, and combining the video feeds, extracting the useful information, and enabling distributed queries. This paper describes the design of such an infrastructure, called IRIS (for Internet-scale ResourceIntensive Sensor services). IRIS is a potentially global network of smart sensor nodes, with webcams or other sensors, and organizing nodes that provide the means to query recent and historical sensor-based data. IRIS exploits the fact that high-volume sensor feeds are typically attached to devices with significant computing power and storage, and running a standard operating system. Aggressive filtering, smart query routing, and semantic caching are used to dramatically reduce network bandwidth utilization and improve query response times, as demonstrated by experiments with an IRIS prototype. We consider a number of potential sensor-based services enabled by IRIS, including a service for finding the cheapest available parking space near a user's destination...|$|R
40|$|Active {{networking}} is {{an expanding}} field of research. It includes {{the ability to}} easily install and modify customized network services and to process packets within the network in a customized way. This paper addresses {{the question of how}} the benefits of active networking can be exploited in an environment, where a large number of customers must share a <b>common</b> <b>network</b> <b>infrastructure.</b> We introduce a management framework for active networks that allows customers to deploy and manage their own active services in a provider domain. The key concept in our framework is the Virtual Active Network (VAN). From the customers perspective, the VAN represents the environment in which the customer can install, run, and manage active services without interaction with the VAN provider. From the VAN provider's perspective the VAN represents the object of resource partitioning and customer isolation. Active networking combined with the VAN concept allows for new business models in the telecom industry. K [...] ...|$|E
40|$|Converged {{telecommunication}} networks, which simultaneously {{support a}} growing variety of services through a <b>common</b> <b>network</b> <b>infrastructure,</b> {{are aimed at}} significantly reducing network expenditures. This trend has encouraged {{the development of a}} unified network paradigm capable of supporting a wide variety of cost-effective recovery solutions, each of which may cope differently with fiber cuts and nodal equipment failures in order to satisfy service-dependent requirements. Expansion of the Origin-Destination (OD) Cycles approach is used to meet that challenge by offering ten different policies for survivability and their relative performance measures in terms of consumption of network resources and the resulting times of recovery. For practical purposes the scope of failure scenarios is limited to single and double-network failures only, even though the approach suggested is generic and can basically address even more complex events. Three test networks are extensively analyzed to demonstrate the paradigm developed and to present some useful observations about the relative positioning of the policies considered for survivability...|$|E
40|$|Abstract. Recent {{research}} has demonstrated the benefits of active networks: customized network services can easily be built and modified, packet streams can be processed inside the network, etc. This paper addresses the question how the benefits of active networking can be exploited in a telecom environment, where {{a large number of}} customers must share a <b>common</b> <b>network</b> <b>infrastructure.</b> We introduce a framework that allows customers to deploy and manage their own active services in a provider domain. The key concept in this framework is the Virtual Active Network (VAN). A VAN is a generic service, offered by the provider to the customer. From the customer’s point of view, a VAN represents an environment on which the customer can install, run and manage active network services, without further interaction with the provider. From the provider’s perspective, the VAN serves as the entity for partitioning the provider’s resources and isolating customers from one another in virtual environments. We describe how the VAN concept, VAN management, and customer service management is realized on ANET, an active networking testbed...|$|E
40|$|Service overlay {{networks}} and network virtualization enable multiple overlay/virtual networks {{to run over}} a <b>common</b> physical <b>network</b> <b>infrastructure.</b> They are widely used to overcome deficiencies of the Internet (e. g., resiliency, security and QoS guarantees). However, most overlay/virtual networks are used for routing/tunneling purposes, and not for providing scoped transport flows (involving all mechanisms such as error and flow control, resource allocation, etc.), which can allow better network resource allocation and utilization. Most importantly, the design of overlay/virtual networks is mostly single-layered, and lacks dynamic scope management, which is important for application and network management. In response to these limitations, we propose a multi-layer approach to Virtual Transport Network (VTN) design. This design is {{a key part of}} VTN-based network management, where network management is done via managing various VTNs over different scopes (i. e., ranges of operation). Our simulation and experimental results show that our multi-layer approach to VTN design can achieve better performance compared to the traditional single-layer design used for overlay/virtual networks. This work has been partly supported by National Science Foundation awards: CNS- 0963974 and CNS- 1346688...|$|R
30|$|The SEC 2 and VICTOR {{have some}} <b>common</b> features. The <b>network</b> <b>infrastructure</b> of SEC 2 {{as well as}} VICTOR is {{organized}} in two levels: a core domain and edge domains. An edge domain consists of physical hosts and switches. The core domain is made {{of a set of}} customized layer 2 switch called as Forwarding Element (FE) and Central Controller (CC). Central Controller (CC) controls the operation of FEs. FE performs two functions namely, (a) address lookup and mapping and (b) policy enforcement. The security service of SEC 2 is made available through tunnelling or FEs. FEs can implement firewalls, NAT and middleboxes. The remaining seven datacenters proposals have different aims but do not provide any security features as summarized in Table 1.|$|R
40|$|We have {{experienced}} amazing {{growth of the}} data-centric, wired Internet and the cellular voice networks in the last decade. In the new millennium, there is the remarkable trend of network evolution toward convergence of wireless networks and the Internet; this is in addition to convergence of voice and data into a <b>common</b> packet-based <b>network</b> <b>infrastructure.</b> Mobility {{is one of the}} unique characteristics of wireless networks, in comparison to the wired networks, and thus mobility management technologies for the wireless Internet have been a topic of significant research in recent years. In this thesis, we present technologies for fast handoff, load balancing and survivable hierarchical mobility management in the wireless Internet. Different from the cellular networks, mobile nodes have primary control of handoff or network access point selection in the wireless Internet. Therefore, it is essential to provide mobile nodes with information necessary for intelligent and efficient handoff control, for which the candidate access router protocol is a solution. We present a secure candidate access router protocol by which each access router can discover in a dynamic and distributed fashion its neighboring access routers who serve the areas overlapping the local cell and provid...|$|R
40|$|In recent decades, the {{networking}} {{community has}} been looking for strategies to converge over a single <b>common</b> <b>network</b> <b>infrastructure</b> carrying voice, video and data. The pervasive and ubiquitous packet-based IP network provides the most convenient platform for the desirable convergence, where resources can be managed in an efficient and dynamic manner. The gradual convergence into the IP infrastructure introduces multimedia-rich and interactive applications that are bandwidth-intensive and delay-bound, while more sophisticated data applications are deployed that place new demands onto IP networks. The IP-based network is evolving {{to satisfy the requirements}} of traffic differentiation and reliable service. Quality of Service (QoS) mechanisms are introduced to meet the traffic expectations and enhance the basic service model of the network in many subtle ways. This thesis provides a comprehensive examination of QoS mechanisms and protocols that have surfaced to optimize the utilization of network resources, to provide differentiated treatment of traffic and enforce the appropriate policies. The study proposes a balanced approach of bandwidth increase and integration of robust QoS techniques into existing IP network infrastructure to arrive at a convergent, multiservice and scalable telecommunications network. Findings from this thesis can be incorporated into the design and implementation of an integrated network within a large organization that will deliver accurate services and defined level of performances...|$|E
40|$|The fifth {{generation}} of mobile communications is anticipated {{to open up}} innovation opportunities for new industries such as vertical markets. However, these verticals originate myriad use cases with diverging requirements that future 5 G networks have to efficiently support. Network slicing may be a natural solution to simultaneously accommodate over a <b>common</b> <b>network</b> <b>infrastructure</b> {{the wide range of}} services that vertical-specific use cases will demand. In this article, we present the network slicing concept, with a particular focus on its application to 5 G systems. We start by summarizing the key aspects that enable the realization of so-called network slices. Then, we give a brief overview on the SDN architecture proposed by the ONF and show that it provides tools to support slicing. We argue that although such architecture paves the way for network slicing implementation, it lacks some essential capabilities that can be supplied by NFV. Hence, we analyze a proposal from the ETSI to incorporate the capabilities of SDN into the NFV architecture. Additionally, we present an example scenario that combines SDN and NFV technologies to address the realization of network slices. Finally, we summarize the open research issues with the purpose of motivating new advances in this field...|$|E
40|$|By 2020 {{there will}} be 50 billion {{connected}} devices over the Internet. With the fast-increasing data traffic demand in both fixed and mobile networks, network operators need to migrate networks towards next generation solutions. The network migration requires the enormous investment in equipment and infrastructure, while the revenues {{are not expected to}} grow significantly. Therefore, one of the main challenges for network operators is to find out a proper cost-effective optical network solution that can match future high capacity demand and flexibly support multiple network services on a <b>common</b> <b>network</b> <b>infrastructure.</b> The first part of the thesis addresses the Active Optical Network (AON) and its migration strategies towards Next Generation Optical Access (NGOA) solutions. Several migration strategies are proposed from the perspective of network topology, data plane and control plane. A general methodology for Techno-Economic analysis has been developed and applied to the Total Cost of Ownership (TCO) calculation of different NGOA solutions. The thesis provides a complete cost evaluation of AON migration paths, which can be used by network operators to assess the economic feasibility of network migration. A converged Optical Transport Network (OTN) that can serve both fixed and mobile network services is beneficial from the cost-saving perspective. However, the different types of services, require different network performance. The second part of the thesis focuses on the investigation of the converged OTN that can be flexibly and timely adjusted to satisfy varying service conditions. A programmable OTN featured with Wavelength Division Multiplexing (WDM) in the data plane and Software Defined Networking (SDN) in control plane has been proposed. To demonstrate the benefits of the converged OTN, the thesis also provides a multi-domain orchestration architecture for the multiple network services.   The resource orchestration, across three network domains: OTN, mobile network and cloud, enables agile service creation and optimized resource allocation among the multiple domains. QC 20170512 </p...|$|E
40|$|We {{study how}} to use quantum key {{distribution}} (QKD) in <b>common</b> optical <b>network</b> <b>infrastructures</b> and propose a method to overcome its distance limitations. QKD is the first technology offering information theoretic secret-key distribution that relies only on the fundamental principles of quantum physics. Point-to-point QKD devices have reached a mature industrial state; however, these devices are severely limited in distance, since signals at the quantum level (e. g. single photons) are highly affected by the losses in the communication channel and intermediate devices. To overcome this limitation, intermediate nodes (i. e. repeaters) are used. Both, quantum-regime and trusted, classical, repeaters have been proposed in the QKD literature, but only the latter can be implemented in practice. As a novelty, we propose here a new QKD network model based {{on the use of}} not fully trusted intermediate nodes, referred as weakly trusted repeaters. This approach forces the attacker to simultaneously break several paths to get access to the exchanged key, thus improving significantly the security of the network. We formalize the model using network codes and provide real scenarios that allow users to exchange secure keys over metropolitan optical networks using only passive components...|$|R
40|$|The {{proliferation}} and affordability of smart sensors such as webcams, microphones etc., has created opportunities for exciting new classes of distributed services. A key stumbling block to mining these rich information sources {{is the lack}} of a <b>common,</b> scalable <b>networked</b> <b>infrastructure</b> for collecting, filtering, and combining the video feeds, extracting the useful information, and enabling distributed queries. In this demo, we demonstrate the design and an early prototype of such an infrastructure, called IRIS (Internetscale Resource-Intensive Sensor services). IRIS is a potentially global network of smart sensor nodes, with webcams or other sensors, and organizing nodes that provide the means to query recent and historical sensor-based data. IRIS exploits the fact that high-volume sensor feeds are typically attached to devices with significant computing power and storage, and running a standard operating system. Aggressive filtering, smart query routing, and semantic caching are used to dramatically reduce network bandwidth utilization and improve query response times, as we will demonstrate. The service that we demonstrate here is that of a parking space finder. This service utilizes webcams that monitor parking spaces to answer queries such as the availability of parking spaces near a user’s destination...|$|R
5000|$|... 4. Mobile network {{operators}}:There {{are over}} 400 mobile network operators in the world; {{out of which}} some are CDMA, some GSM, whereas others use less <b>common</b> <b>network</b> standards like FOMA, and TD-SCDMA. Each network operator uses a different kind <b>network</b> <b>infrastructure</b> and this limits the flow of information.|$|R
40|$|As {{has been}} widely {{recognized}} for some time, the computing and telecommunications technologies are converging. This has meant different things at different times. In this review paper, we describe {{the current state of}} convergence, and speculate about what it may mean in coming years. In particular, we argue {{that as a result of}} the horizontal integration of all media (voice, audio, video, animation, data) in a <b>common</b> <b>network</b> and terminal <b>infrastructure,</b> telecommunications and networked-computing applications are no longer distinguishable. Considering that the old terminology is no longer meaningful, we attempt to codify networked applications in accordance with their functionality and immediacy. As application functionality is increasingly defined in software, with commensurate cost-effective programmable terminals and means for distribution of applications over the network itself, we argue that user-to-user applications will be greatly impacted, moving into the rapid-innovation regime [...] ...|$|R
40|$|We {{propose a}} network service {{framework}} where <b>common</b> <b>network</b> {{functions such as}} routing and multicast can be customized on a per-application basis. Network service customization is achieved through service plug-in modules that can be dynamically loaded by applications. In addition to their customization, services can also be composed to form complex aggregate services. Finally, our framework is deployed using an overlay <b>network</b> <b>infrastructure.</b> 1...|$|R
40|$|Network {{virtualization}} is {{a technology}} that enables multiple virtual instances to coexist on a <b>common</b> physical <b>network</b> <b>infrastructure.</b> This paradigm fostered new business models, allowing infrastructure providers to lease or share their physical resources. Each virtual network is isolated and can be customized to support {{a new class of}} customers and applications. To this end, infrastructure providers need to embed virtual <b>networks</b> on their <b>infrastructure.</b> The virtual <b>network</b> embedding is the (NP-hard) problem of matching constrained virtual networks onto a physical network. Heuristics to solve the embedding problem have exploited several policies under different settings. For example, centralized solutions have been devised for small enterprise physical networks, while distributed solutions have been proposed over larger federated wide-area networks. In this thesis we present a policy-based architecture for the virtual network embedding problem. By policy, we mean a variant aspect of any of the three (invariant) embedding mechanisms: physical resource discovery, virtual network mapping, and allocation on the physical infrastructure. Our architecture adapts to different scenarios by instantiating appropriate policies, and has bounds on embedding efficiency, and on convergence embedding time, over a single provider, or across multiple federated providers. The performance of representative novel and existing policy configurations are compared via extensive simulations, and over a prototype implementation. We also present an object model as a foundation for a protocol specification, and we release a testbed to enable users to test their own embedding policies, and to run applications within their virtual networks. The testbed uses a Linux system architecture to reserve virtual node and link capacities...|$|R
40|$|With {{the growth}} of the Internet and the {{corresponding}} agreement on a <b>common</b> <b>network</b> and transport <b>infrastructure</b> comes a new opportunity for innovative network services. Examples include the rapid evolution of the WorldWide Web (WWW), and the ensuing interest in mining knowledge from the large body of WWW databases and repositories. At the same time, the explosive growth in availability and use of the Internet is creating new challenges. In particular, the existing infrastructure must be extended if it is to continue to scale. This demands that we raise the level of common services and introduce new types of higher-level services. These common services, termed "middleware " services [pc 95], would sit above the traditional network protocols and provide means for extending commonly available services on the network to enclose higher layers of abstraction. Many of these middleware services are crucial for the design of scalable data mining and knowledge discovery systems. In this paper we [...] ...|$|R
40|$|Abstract—In {{this paper}} we explore how recent {{technologies}} can improve the security of optical networks. In particular, we study how to use quantum key distribution(QKD) in <b>common</b> optical <b>network</b> <b>infrastructures</b> and propose a method to overcome its distance limitations. QKD is the first technology offering information theoretic secretkey distribution that relies only on the fundamental principles of quantum physics. Point-to-point QKDdevices have reached a mature industrial state; however, these devices are severely limited in distance, since signals at the quantum level (e. g., single photons) are highly affected by the losses in the communication channel and intermediate devices. To overcome this limitation, intermediate nodes (i. e., repeaters) are used. Both quantum-regime and trusted, classical repeaters have been proposed in the QKD literature, but only the latter can be implemented in practice. As a novelty, we propose here a new QKD network model based {{on the use of}} not fully trusted intermediate nodes, referred to as weakly trusted repeaters. This approach forces the attacker to simultaneously break several paths to get access to the exchanged key, thus improving significantly the security of the network. We formalize the model using network codes and provide real scenarios that allow users to exchange secure keys over metropolitan optical networks using only passive components. Moreover, the theoretical framework allows one to extend these scenarios not only to accommodate more complex trust constraints, but also to consider robustness and resiliency constraints on the network...|$|R
40|$|In this paper, we {{conceive}} {{an advanced}} neutral host micro operator (NH-μO) network approach providing venues with services tailored to their specialized/specific requirements and/or local context related services that the mobile network operators (MNOs) are poorly-suited to providing it, {{as well as}} mobile broadband experience to the users from MNOs in a venue where only a single infrastructure is mandated under shared spectrum access framework. A radio access network slicing concept is conceived to support and optimize both the slice instance (SI) use cases independently and efficiently by running all network implementations in parallel, simultaneously on a <b>common</b> physical <b>network</b> <b>infrastructure.</b> We devise a common shared architecture for the NH-μO {{small cell base stations}} and dynamic spectrum assignment control unit, and their required functionalities supporting coexistence of different SIs as well as multiple MNOs in shared spectrum access communications. We devise both inter-SI and intra- SI dynamic spectrum allocation policies considering time-varying requirements of different SIs. The policies are capable of taking care of application level priority, -i. e., mixture of guaranteed quality of service and best-effort service users served by each SI while ensuring a healthy competition. Our proposed framework serves two-fold advantages, such as it gives the venue owner its own managed wireless networks tailored to its very specific requirements, and it also brings out cost savings and coverage extension for MNOs and efficiency of resources that arise from sharing wireless networks, and delivering the network capacity into high density venues...|$|R
