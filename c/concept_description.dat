216|720|Public
2500|$|The three {{properties}} might be, for example, [...] [...] Then what {{is stored}} at this concept node is the property count , indicating that 1 {{of the objects}} in the concept is male, 3 of the objects have wings, and 3 of the objects are nocturnal. [...] The <b>concept</b> <b>description</b> is the category-conditional probability (likelihood) of the properties at the node. [...] Thus, given that an object {{is a member of}} category (concept) , the likelihood that it is male is [...] [...] Likewise, the likelihood that the object has wings and [...] likelihood that the object is nocturnal [...] or both is [...] [...] The <b>concept</b> <b>description</b> can therefore simply be given as , which corresponds to the -conditional feature likelihood, i.e., [...]|$|E
2500|$|Conceptual {{clustering}} is {{a machine}} learning paradigm for unsupervised classification developed mainly during the 1980s. [...] It is distinguished from ordinary data clustering by generating a <b>concept</b> <b>description</b> for each generated class. [...] Most conceptual clustering methods {{are capable of}} generating hierarchical category structures; [...] see Categorization {{for more information on}} hierarchy. [...] Conceptual clustering is closely related to formal concept analysis, decision tree learning, and mixture model learning.|$|E
2500|$|Conceptual {{clustering}} {{is obviously}} {{closely related to}} data clustering; however, in conceptual clustering {{it is not only}} the inherent structure of the data that drives cluster formation, but also the Description language which is available to the learner. [...] Thus, a statistically strong grouping in the data may fail to be extracted by the learner if the prevailing <b>concept</b> <b>description</b> language is incapable of describing that particular regularity. [...] In most implementations, the description language has been limited to feature conjunction, although in COBWEB (see [...] "" [...] below), the feature language is probabilistic.|$|E
40|$|Many {{successful}} {{inductive learning}} systems use a propositional attribute-value language for {{the representation of}} training examples and induced <b>concept</b> <b>descriptions.</b> Recent developments are concerned with systems that induce <b>concept</b> <b>descriptions</b> in #rst-order logic. In the deductive hierarchical database #DHDB# formalism used in LINUS training examples are given as a relation {{in the form of}} ground facts. <b>Concept</b> <b>descriptions</b> have the form of typed nonrecursive rules. Having variables, compound terms and utility predicates#functions in <b>concept</b> <b>descriptions,</b> the DHDB form allows for more compact <b>descriptions</b> of <b>concepts</b> than an attribute-value language. It also allows for learning nonrecursive logical de#nitions of relations. The paper gives a short description of LINUS and presents the results of its successful application to several inductive learning tasks taken from machine learning literature. 1 Introduction The general framework for machine learning can be stated as B H ` ET wh [...] ...|$|R
40|$|Schmidt-SchaulL M. and G. Smolka, Attributive <b>concept</b> <b>descriptions</b> with complements, Artificial Intelligence 48 (1991) 1 - 26. We {{investigate}} {{the consequences of}} adding unions and complements to attributive <b>concept</b> <b>descriptions</b> employed in terminological knowledge representation languages. It is shown that deciding coherence and subsumption of such descriptions are PSPACE-complete problems that can be decided with linear space. I...|$|R
40|$|Abstract. The {{development}} and use of ontologies may require users with no training in formal logic to handle complex <b>concept</b> <b>descriptions.</b> To aid such users, we propose a new visualization framework called “model outlines”, where more emphasis is placed on the semantics of <b>concept</b> <b>descriptions</b> than on their syntax. We present a rigorous definition of our visual language, as well as detailed algorithms for translating between model outlines and the Description Logic ALCN. We have recently conducted a usability study comparing model outlines and Manchester OWL; here, we report on its results, which indicate the potential benefits of our visual language for understanding <b>concept</b> <b>descriptions...</b>|$|R
5000|$|Operational <b>Concept</b> <b>Description</b> (OCD) - The {{operational}} concept {{for the system}} ...|$|E
5000|$|Conceptual {{clustering}} developed mainly {{during the}} 1980s, as a machine paradigm for unsupervised learning. It is distinguished from ordinary data clustering by generating a <b>concept</b> <b>description</b> for each generated category.|$|E
5000|$|In the Common cold {{example the}} <b>concept</b> <b>description</b> is [...] "primitive", {{which means that}} {{necessary}} criteria are given that must be met for each instance, without being sufficient for classifying a disorder as an instance of Common Cold [...] In contrast, the example Viral upper respiratory tract infection depicts a fully described concept, which is represented in description logic as follows: ...|$|E
40|$|Abstract. In this paper, we {{investigate}} cumulated clauses {{on a set}} of attributes consisting of <b>concept</b> <b>descriptions</b> of the description logic FLE. This kind of expression is useful for describing the attribute logic of contexts where the attributes can be seen as FLE <b>concept</b> <b>descriptions.</b> We provide a deduction calculus for this type of expressions and prove its soundness and completeness. ...|$|R
40|$|The {{methodology}} used {{to develop}} conceptual designs of the engineered barrier system and waste packages for a geologic repository {{is based on an}} iterative systems engineering process. The process establishes a set of general mission requirements and then conducts detailed requirements analyses using functional analyses, system concept syntheses, and trade studies identifications to develop preliminary system <b>concept</b> <b>descriptions.</b> The feasible <b>concept</b> <b>descriptions</b> are ranked based on selection factors and criteria and a set of preferred <b>concept</b> <b>descriptions</b> is then selected for further development. For each of the selected <b>concept</b> <b>descriptions,</b> a specific set of requirements, including constraints, is written to provide design guidance for the next and more detailed phase of design. The process documents all relevant waste management system requirements so that the basis and source for the specific design requirements are traceable and clearly established. Successive iterations performed during design development help to insure that workable concepts are generated to satisfy the requirements. 4 refs., 2 figs...|$|R
5|$|Berry L. G. & Mason B. 1959, Mineralogy: <b>Concepts,</b> <b>Descriptions,</b> Determinations, W. H. Freeman and Company, San Francisco.|$|R
50|$|Conceptual {{clustering}} is {{a machine}} learning paradigm for unsupervised classification developed mainly during the 1980s. It is distinguished from ordinary data clustering by generating a <b>concept</b> <b>description</b> for each generated class. Most conceptual clustering methods {{are capable of}} generating hierarchical category structures; see Categorization {{for more information on}} hierarchy. Conceptual clustering is closely related to formal concept analysis, decision tree learning, and mixture model learning.|$|E
50|$|During rule discovery, axioms (formal {{description}} of concepts) are generated for the extracted concepts. This {{can be achieved}} for example by analyzing the syntactic structure of a natural language definition {{and the application of}} transformation rules on the resulting dependency tree. The result of this process is a list of axioms, which is afterwards comprehended to a <b>concept</b> <b>description.</b> This one has to be evaluated by an ontologist.|$|E
5000|$|... 'To See is To Change: A Parallax View of 40 Years of German Video Art' (a re-curation of the {{globally}} circulating Goethe-Institut collection, '40 Years of German Video Art', as a 2-day annotated screening {{cycle and}} symposium {{by a group}} of theorists, artists and enthusiasts: Nancy Adajania, Shaina Anand, Ranjit Hoskote, Ashok Sukumaran, Kabir Mohanty, Mriganka Madhukaillya, Kaushik Bhaumik, Devdutt Trivedi and Rana Dasgupta; Jnanapravaha & Chemould Prescott Road, Bombay, 14-15 November 2008). <b>CONCEPT,</b> <b>DESCRIPTION</b> & SCHEDULE ARCHIVAL VIDEO ...|$|E
40|$|This study {{evaluates the}} impact of <b>concept</b> <b>descriptions</b> on the {{behaviour}} and performance of concept formation processes (in which the data is either noisy or noise-free). Using a common architecture (ADECLU), different concept definitions are envisaged. These descriptions are of symbolic/numeric type, including statistical indices. The use of these indices introduces a “contrasting” between <b>concept</b> <b>descriptions</b> and reduces the effect of noise on predictive performance. SCOPUS: cp. kinfo:eu-repo/semantics/publishe...|$|R
50|$|Development and {{positioning}} of the BWL Health Management course: compilation of <b>concepts,</b> <b>description</b> of modules, acquiring education partners and lecturers.|$|R
40|$|With {{the recent}} {{developments}} in the C++ language, concepts are mostly discussed {{as a form of}} constrained polymorphism. Yet, concepts also allow for an alternative, implementation-independent view that comes from their origin in (algebraic) specification languages. In this paper, we return to this specification view on concepts and formalize C++ concepts as institutions, a well-established notion for precise specifications of software components. We argue that institutions form a suitable theoretical framework for software systems like libraries where the different parts establish relations that are captured by different logics, or no formal logic at all. Assuming the C++ <b>concept</b> <b>descriptions,</b> <b>concept</b> maps, and axioms as in the draft currently accepted by the C++ standardization committee, we show that <b>concept</b> <b>descriptions</b> and axioms form an institution (with equational logic) but also, and perhaps surprisingly, that <b>concept</b> <b>descriptions</b> and <b>concept</b> maps form an institution (with no formal logic) ...|$|R
5000|$|The COBWEB data {{structure}} is a hierarchy (tree) wherein each node represents a given concept. Each concept represents a set (actually, a multiset or bag) of objects, each object being {{represented as a}} binary-valued property list. The data associated with each tree node (i.e., concept) are the integer property counts for the objects in that concept. For example, (see figure), let a concept [...] contain the following four objects (repeated objects being permitted). The three properties might be, for example, [...] Then what is stored at this concept node is the property count , indicating that 1 of the objects in the concept is male, 3 of the objects have wings, and 3 of the objects are nocturnal. The <b>concept</b> <b>description</b> is the category-conditional probability (likelihood) of the properties at the node. Thus, given that an object {{is a member of}} category (concept) , the likelihood that it is male is [...] Likewise, the likelihood that the object has wings and likelihood that the object is nocturnal or both is [...] The <b>concept</b> <b>description</b> can therefore simply be given as , which corresponds to the -conditional feature likelihood, i.e., [...]|$|E
5000|$|Conceptual {{clustering}} {{is obviously}} {{closely related to}} data clustering; however, in conceptual clustering {{it is not only}} the inherent structure of the data that drives cluster formation, but also the Description language which is available to the learner. Thus, a statistically strong grouping in the data may fail to be extracted by the learner if the prevailing <b>concept</b> <b>description</b> language is incapable of describing that particular regularity. In most implementations, the description language has been limited to feature conjunction, although in COBWEB (see [...] "COBWEB" [...] below), the feature language is probabilistic.|$|E
40|$|In Description Logics the {{inference}} most specific concept (msc) constructs a <b>concept</b> <b>description</b> that generalizes an individual into a <b>concept</b> <b>description.</b> For the Description Logic EL the msc needs not exist [1], if computed {{with respect to}} general EL-TBoxes. However, {{it is still possible}} to find a <b>concept</b> <b>description</b> that is the msc up to a fixe...|$|E
40|$|For {{learning}} tasks {{with few}} examples, greater classi cation accuracy {{can be achieved}} by learning several <b>concept</b> <b>descriptions</b> for each class in the data and producing a classi cation that combines evidence from multiple descriptions. Stochastic (randomized) search can be used to generate many <b>concept</b> <b>descriptions</b> for each class. Here we use a tractable approximation to the optimal Bayesian method for combining evidence from multiple descriptions. Learning multiple descriptions is very useful when additional data is di cult to obtain. The primary result of this paper is that multiple <b>concept</b> <b>descriptions</b> are particularly helpful for improving accuracy in hypothesis spaces in which there are many equally good rules to learn. Another result is experimental evidence that learning multiple rule sets yields more accurate classi cations than learning multiple rules for concepts containing many disjuncts. ...|$|R
40|$|Concept {{approximation}} is an inference {{service for}} Description Logics that provides “translations” of <b>concept</b> <b>descriptions</b> from one DL {{to a less}} expressive DL. In [4] a method for optimizing the computation of ALC-ALE-approximations of ALC-concept descriptions was introduced. The idea is to characterize a certain class of <b>concept</b> <b>descriptions</b> for which conjuncts can be approximated independently. In this paper we provide relaxed conditions for this class of ALC-concept descriptions, extend this notion to number restrictions and report on a first implementation of this method for ALCN-ALEN-approximation...|$|R
40|$|Abstract. We {{introduce}} a description language for specifying partial ordering relations over <b>concept</b> <b>descriptions</b> in description logics, and {{show how the}} language {{can be used in}} combination with binary trees to efficiently search a database that corresponds to a finite set of <b>concept</b> <b>descriptions.</b> The language consists of a pair of ordering constructors that support a form of exogenous indexing in which search criteria is independent of data, and a form of endogenous indexing in which the data itself provides search criteria. Our language can be refined {{in the same way as}} a description logic in that greater expressiveness and consequent richer search capability is achieved by adding additional ordering constructors. ...|$|R
40|$|Many {{learning}} algorithms form concept descriptions {{composed of}} clauses, {{each of which}} covers some proportion of the positive training data and a small to zero proportion of the negative training data. This paper presents a method using likelihood ratios attached to clauses to classify test examples. One <b>concept</b> <b>description</b> is learned for each class. Each <b>concept</b> <b>description</b> competes to classify the test example using the likelihood ratios assigned to clauses of that <b>concept</b> <b>description.</b> By testing on several artificial and "real world" domains, we demonstrate that attaching weights and allowing concept descriptions to compete to classify examples reduces an algorithm's susceptibility to noise...|$|E
40|$|Knowledge of {{properties}} that are applicable {{to a given}} object is a necessary prerequisite to formulate intelligent question. <b>Concept</b> <b>description</b> vectors provide simplest representation of this knowledge, storing for each object information about the values of its properties. Experiments with automatic creation of <b>concept</b> <b>description</b> vectors from various sources, including ontologies, dictionaries, encyclopedias and unstructured text sources, are described. Information collected {{in this way is}} used to formulate questions that have high discriminating power in the twenty questions game...|$|E
40|$|When {{performing}} <b>concept</b> <b>description,</b> modelsneed to {{be evaluated}} both on accuracy and comprehensibility. A comprehensible <b>concept</b> <b>description</b> model should present themost important relationships in the data in an accurate andunderstandable way. Two natural representations for this aredecision trees and decision lists. In this study, the two decisionlist algorithms RIPPER and Chipper, and the decision treealgorithm C 4. 5, are evaluated for <b>concept</b> <b>description,</b> usingpublicly available datasets. The experiments show that C 4. 5 performs very well regarding accuracy and brevity, i. e. theability to classify instances with few tests, but also produceslarge models {{that are hard to}} survey and contain manyextremely specific rules, thus not being good conceptdescriptions. The decision list algorithms perform reasonablywell on accuracy, and are mostly able to produce small modelswith relatively good predictive performance. Regardingbrevity, Chipper is better than RIPPER, using on averagefewer conditions to classify an instance. RIPPER, on the otherhand, excels in relevance, i. e. the ability to capture a largenumber of instances with every rule...|$|E
40|$|Introduction In {{the earlier}} Working Notes, we {{described}} {{the process of}} building <b>concept</b> <b>descriptions</b> from components. Components (unlike frame-slot-value triples or frames 1) encapsulate a single statement about the world, and are the `basic units' from which <b>concept</b> <b>descriptions</b> are built. By including or omitting components, we can selectively represent different aspects of concepts, as required by the particular problem-solving task at hand (eg. explanation, diagnosis). They also provide the `units of retraction' for fixing buggy <b>concept</b> <b>descriptions</b> (Working Note 3). This Working Note extends these ideas to the STRIPS-like representation of actions, ie. actions considered as discrete events with preconditions, add, and delete lists [Fikes et al., 1981]. As with concepts in general, we have to decide what to model and what to ignore when describing actions. Our goal here is to similarly encapsulate each modellable feature of the dynamics of the world a...|$|R
40|$|This paper {{deals with}} the problem of {{learning}} characteristic <b>concept</b> <b>descriptions</b> from examples and describes a new generalization approach implemented in the system Cola- 2. The approach tries {{to take advantage of the}} information which can be induced from descriptions of unclassified objects using a conceptual clustering algorithm. Experimental results in various real-world domains strongly support the hypothesis that the new approach delivers more correct (and possibly more comprehesible) <b>concept</b> <b>descriptions</b> than exisiting methods, if the induced <b>concept</b> <b>descriptions</b> are also used to classify objects which belong to concepts which were not present in the training data set. This paper describes the generalization approach implemented in Cola and presents experimental results obtained with a relational and a propositional real world data set. 1 Introduction In: Proceedings of the Fourth International Workshop on Inductive Logic Programming (ILP- 94), S. Wrobel (ed.), Arbeitspapier der G [...] ...|$|R
40|$|This paper {{describes}} AQ-PM, {{a system}} for partial memory learning, which determines and memorizes representative concept examples, and then uses them with new training examples to induce new <b>concept</b> <b>descriptions.</b> Our approach uses "extreme" examples that lie at the boundaries of current <b>concept</b> <b>descriptions.</b> We evaluated the system by applying it to synthetic and real-world learning problems. In the experiments, the partial memory learner notably reduced memory requirements for storing examples at the slight expense of predictive accuracy. The system also performed well when tracking concept drift. Keywords: concept learning, rule induction, partial instance memory models 1 Introduction Partial memory learners are on-line learning systems that select and store {{a portion of the}} past training examples. They can use these examples in different ways. One approach is to use them together with new, incoming examples for generating new <b>concept</b> <b>descriptions.</b> Another is to use them together w [...] ...|$|R
40|$|Abstract—Representing web {{data into}} a machine {{understandable}} format is a curtail {{task for the}} next generation of the web. Most of solutions are relying on ontologies. However, there are many problems of using ontologies. This paper proposes an approach to represent dynamic web page contents retrieved from underlying database, into <b>Concept</b> <b>Description</b> Language (CDL) semantic format. This format does not depend on ontologies. However, CDL describes semantic structure of web content based on a set of predefined concepts and semantic relations. A prototype of the proposed approach is implemented to show visibility of the proposed approach. Semantic represenation, semantic database, <b>Concept</b> <b>Description</b> Languag...|$|E
40|$|The {{subsumption}} {{problem in}} Description Logics (DL) {{refers to the}} question of deciding if a <b>concept</b> <b>description</b> always denotes a subset of the set denoted by another <b>concept</b> <b>description.</b> This paper explores reductions of query containment and other problems to the subsumption problem in DL. It first selects a DL dialect that is expressive enough to cover familiar classes of integrity constraints and query expressions. Then, it describes how to modify the tableau decision procedure for the subsumption problem to account for the classes of integrity constraints considered. Finally, it introduces a fast decision procedure for the subsumption problem for the dialect adopted...|$|E
40|$|Abstract. <b>Concept</b> <b>description</b> is an {{important}} task of descriptive data mining: Basically, its aim is to identify and to summarize properties of a selected target population {{in the form of}} a set of patterns – in a concise and comprehensible way. In this paper we present an approach for <b>concept</b> <b>description</b> in the social bookmarking domain: We show how subgroup discovery can be utilized for identifying discriminative and characteristic local patterns in order to understand the behavior of (non-) spammers. A case study applying data from a real-world system for social bookmarking provides exemplary results and demonstrates the applicability and effectiveness of the presented approach. ...|$|E
40|$|For {{description}} logics with existential restrictions, {{the size}} of the least common subsumer (lcs) of <b>concept</b> <b>descriptions</b> may grow exponentially in {{the size of}} the <b>concept</b> <b>descriptions.</b> To reduce {{the size of the}} output descriptions and the run-time of the lcs algorithm we present an optimized algorithm for computing the lcs in ALE using lazy unfolding. A first evaluation of the performance of the naive algorithm in comparison to the performance of the algorithm using lazy unfolding indicates a performance gain for both concept sizes as well as run-times...|$|R
5000|$|EPERC {{contains}} Fast Facts and <b>Concepts,</b> <b>descriptions</b> {{of educational}} material by content area and educational format, [...] "starter kits" [...] for health educators planning palliative care educational projects, and other resources.|$|R
40|$|Unification {{considers}} concept patterns, i. e., <b>concept</b> <b>descriptions</b> with variables, {{and tries}} to make these descriptions equivalent by replacing the variables by appropriate <b>concept</b> <b>descriptions.</b> Baader and Küsters have shown that unification in FL reg, a description logic that allows for the concept constructors top concept, concept conjunction, and value restrictions {{as well as the}} role constructors union, composition, and transitive closure, is an ExpTime-complete problem and that solvable FL reg - unification problems always have least unifiers. In the present paper, we generalize these results to a DL which extends FL reg by the bottom concept. The proo...|$|R
