1|19|Public
50|$|The Grane Reservoir (Granestausee) {{supplies}} drinking water, acts as flood protection, water {{regulation and}} electricity generation. The {{hydro-electric power station}} has a power output of 180 kW. The waterworks for drinking water lies higher up on the northern slope. The water from the reservoir is pumped up into a <b>compensating</b> <b>storage</b> basin of 60,000 m³ capacity, from where it flows to the waterworks. The Grane Dam has an average annual discharge of 55 million m³.|$|E
30|$|As an example, {{take the}} cost of digital storage and {{bandwidth}} for the realization potential of YouTube. Let A 1 be {{the cost of}} data storage in 1998 at US$ 100 per gigabyte, which gradually decreased to A 5 in 2005 at US$ 1. The cost of upload/download bandwidth decreased similarly from B 1 in 1998 at US$ 1200 per gigabit to B 5 in 2005 at US$ 75 per gigabit. A 5 and B 5 together enabled point F—The possibility to create an online video sharing platform like YouTube. The {{important point is that}} it was actually not viable, yet, to provide such a service in 2005. The income of advertising—even at today’s income rates—would not have been enough to <b>compensate</b> <b>storage</b> and especially bandwidth costs. But since both costs were expected to further decline, it created an opportunity vacuum for those who foresaw the future development of viability in this technological context. It is also important to note that innovations outside this trajectory are doomed to fail. If, for instance, YouTube would have tried to build the same service 5  years earlier, it would have been outright impossible due to the high bandwidth and storage costs, even if it would have been technically feasible.|$|R
30|$|The two {{fields of}} MC and IoT {{have been widely}} popular as future {{infrastructures}} and have seen an independent evolution. However, MC and IoT are complementary technologies, and several mutual advantages deriving from their integration have been identified [3]. Therefore, a symbiosis has developed between mobile devices and MC {{and is expected to}} be combined for the future Internet. Generally, mobile devices can benefit from the virtually unlimited capabilities and resources of MC to <b>compensate</b> its <b>storage,</b> processing, and energy constraints. Specifically, MC can offer an effective solution to implement IoT service management. On the other hand, MC can benefit from the IoT system by extending its scope to deal with real-world things in a more distributed and dynamic manner [2]. Nowadays, the extension of MC over dynamic IoT environments has been referred as a next generation communication and computing paradigm [5].|$|R
40|$|The {{implementation}} of Bougous dam at 5 km upstream of Mexa dam permits to <b>compensate</b> the <b>storage</b> capacity {{and to reduce}} sediment yields in the later, however, these advantages must be associated {{to the fact that}} the presence of two large dams in the region poses in case of a dam break event a potential threat to human life and property. Indeed, in this study a numerical simulation of the dam break wave propagation resulting from the failure of the two dams was performed using the two-dimensional hydrodynamic model Telemac- 2 D, in order to estimate the impacts on constructions located in the downstream valley. The simulation results exported to GIS platform allowed the elaboration of cartographic materials depicting the hydraulic characteristics of the flood wave and its arrival times at key locations, which constitute very useful information for the authorities to avoid significant loss in case of the failure of Bougous and Mexa dams...|$|R
40|$|The {{increase}} in penetration of {{wind in the}} current energy mix is hindered by its high volatility and poor predictability. These shortcomings lead to energy loss and increased deployment of fast ramping generation. The use of energy <b>storage</b> <b>compensates</b> to some extent these negative effects; it plays a buffer role between demand and production. We revisit a model of real storage proposed by Bejan et al. [1]. We study the impact on performance of energy conversion efficiency and of wind prediction quality. Specifically, we provide theoretical bounds on the trade-off between energy loss and fast ramping generation, which we show to be tight for large capacity of the available storage. Moreover, we develop strategies that outperform the proposed fixed level policies when evaluated on real data from the UK grid...|$|R
40|$|Mestrado em Engenharia Alimentar - Qualidade e Segurança Alimentar - Instituto Superior de AgronomiaFrom the {{bioactive}} composition {{characterization of}} cv. Nantes carrot considering tissue type (peel, cortex and vascular tissues) and harvest season (winter vs. summer), {{it was concluded}} that both factors affect significantly this composition. Carrots from the summer harvest showed to have about four times higher total phenolic and carotenoid contents than the winter ones. The cortex is the most representative carrot tissue (71 - 82 %) and holds higher contents of total phenolics (49 - 69 %) and carotenoids (78 - 85 %) than the remaining tissues – peel and vascular tissues. Therefore, the cortex is the tissue that contributes the most toward carrots’ total antioxidant capacity (61 - 72 %), mainly of hydrophilic nature (> 90 %) which {{is directly related to the}} respective phenolic composition. In minimal processing, the peeling and decontamination unit operations lead to significant losses in carrots’ bioactive composition, accounting for decreases of 58 % for phenolics and of 52 % for carotenoids regarding the raw material. These losses were <b>compensated</b> during <b>storage</b> of minimally processed carrot packed in a microperforated film, namely due to induced phenolic synthesis, reaching by day 7 similar levels to those evaluated in the raw material, with maintenance of the carotenoid content, pH and soluble solids content...|$|R
40|$|Abstract—This paper {{examines}} {{the value of}} storage in secur-ing reliability of a system with uncertain supply and demand, and supply friction. The storage is frictionless as a supply source, but once used, it cannot be filled up instantaneously. The focus application is a power supply network in which the base supply and demand are assumed to match perfectly, while deviations from the base are modeled as random shocks with stochastic arrivals. Due to friction, the random surge shocks cannot be tracked by the main supply sources. Storage, when available, {{can be used to}} compensate, fully or partially, for the surge in demand or loss of supply. The problem of optimal utilization of storage with the objective of maximizing system reliability is formulated as minimization of the expected discounted cost of blackouts over an infinite horizon. It is shown that when the stage cost is linear {{in the size of the}} blackout, the optimal policy is myopic in the sense that all shocks are <b>compensated</b> by <b>storage</b> up to the available level of storage. However, when the stage cost is strictly convex, it may be optimal to curtail some of the demand and allow a small current blackout in the interest of maintaining a higher level of reserve to avoid a large blackout in the future. The value of storage capacity in improving system’s reliability, as well as the effects of the associated optimal policies under different stage costs on the probability distribution of blackouts are examined...|$|R
30|$|When a {{large size}} VM is {{migrated}} over WAN networks with low bandwidth causes a complex live migration. Current techniques do not efficiently {{deal with such}} migrations where servers are part of different networks. There are various challenges such as migrating network and storage connections, migrating storage content and persistent state kept at the source server side. To minimize the migration latency’s Bose et al. [94] proposed a technique which combines VM replication with VM scheduling. They use the de-duplication method for finding the VM replicas to <b>compensate</b> the additional <b>storage</b> requirement generated by {{the increasing number of}} replicas of different VM’s images. Develop a CloudSpider architecture based on efficient replication strategies using VM replication and scheduling. The replica placement strategies evaluated on CloudSim simulator with physical machines (Intel Core 2 Duo CPU 2.53 GHz, 2 GB RAM). The proposed architecture is capable to minimize migration latency’s associated with the live migration of VM images over WAN network.|$|R
40|$|Carbon fibre {{reinforced}} flame-retarded bioepoxy composites {{were prepared}} from commercially available sorbitol polyglycidyl ether (SPE) cured with cycloaliphatic amine hardener. Samples containing 1, 2, and 3 % phosphorus (P) were prepared using additive type flame retardants (FRs) resorcinol bis(diphenyl phosphate) (RDP), ammonium polyphosphate (APP), and their combinations. The fire {{performance of the}} composites was investigated by limiting oxygen index (LOI), UL- 94 tests, and mass loss calorimetry. The effect of FRs on the glass transition temperature, and storage modulus was evaluated by dynamic mechanical analysis (DMA), while the mechanical performance was investigated by tensile, bending, and interlaminar shear measurements, {{as well as by}} Charpy impact test. In formulations containing both FRs, the presence of RDP, acting mainly in gas phase, ensured balanced gas and solid-phase mechanism leading to best overall fire performance. APP advantageously <b>compensated</b> the plasticizing (<b>storage</b> modulus and glass transition temperature decreasing) effect of RDP in combined formulations; furthermore, it led to increased tensile strength and Charpy impact energy...|$|R
40|$|This paper {{examines}} {{the value of}} storage in securing reliability of a system with uncertain supply and demand, and supply friction. The storage is frictionless as a supply source, but it cannot be filled up instantaneously. The focus is on application to an energy network in which the nominal supply and demand are assumed to match perfectly, while deviations from the nominal values are modeled as random shocks with stochastic arrivals. Due to friction, the random shocks cannot be tracked by the main supply sources. Storage, when available, {{can be used to}} compensate, fully or partially, for the surge in demand or sudden drop in supply. The problem of optimal utilization of storage with the objective of maximizing system reliability is formulated as minimization of the expected discounted cost of blackouts over an infinite horizon. It is shown that when the stage cost is linear {{in the size of the}} blackout, the optimal policy is myopic in the sense that all shocks will be <b>compensated</b> by <b>storage</b> up to the available level of storage. However, when the stage cost is strictly convex, it may be optimal to curtail some of the demand and allow a small blackout in the interest of maintaining a higher level of reserve, which may help avoid a large blackout in the future. The value of storage capacity in improving reliability, as well as the effects of the associated optimal policies under different stage costs on the probability distribution of blackouts are examined. Author's final manuscript: September 29, 2011 National Science Foundation (U. S.) Siemens-MIT Allianc...|$|R
40|$|Renewable {{energy sources}} will play an {{increasingly}} {{central role in}} the power network of the future. The will to reduce the dependence on fossil sources as well as growing environmental awareness, both individually and governmentally, is forcing governments throughout the world to invest an enormous amount of capital in renewable energy sources. The European Union, through its Energy and Climate Policy, has fixed an ambitious target: to provide, 20 % of electricity from renewable sources by 2020. The additional volatility introduced by renewable energy source to the grid can be <b>compensated</b> by energy <b>storage</b> systems as well as by demand control measurements and by the reinforcement of the power grid. These solutions can improve the system reliability of the electric grid and the efficiency of the energy supply and give more flexibility to the system. This study analyzes the possibilities to use electric vehicles connected to the grid as energy storage system within a Virtual Power Plant structure. Through the formulation of an optimization problem the optimal number of electric vehicles has been evaluate...|$|R
40|$|A {{series of}} genetically related lines of common bean (Phaseolus vulgaris L.) {{integrate}} a progressive deficiency in major storage proteins, the 7 S globulin phaseolin and lectins. SARC 1 integrates a lectin-like protein, arcelin- 1 from a wild common bean accession. SMARC 1 N-PN 1 is deficient in major lectins, including erythroagglutinating phytohemagglutinin (PHA-E) but not α-amylase inhibitor, and incorporates also a deficiency in phaseolin. SMARC 1 -PN 1 is intermediate and shares the phaseolin deficiency. Sanilac is the parental background. To understand the genomic basis for variations in protein profiles previously determined by proteomics, the genotypes were submitted to short-fragment genome sequencing using an Illumina HiSeq 2000 / 2500 platform. Reads were aligned to reference sequences {{and subjected to}} de novo assembly. The results of the analyses identified polymorphisms responsible {{for the lack of}} specific storage proteins, as well as those associated with large differences in storage protein expression. SMARC 1 N-PN 1 lacks the lectin genes pha-E and lec 4 -B 17, and has the pseudogene pdlec 1 in place of the functional pha-L gene. While the α-phaseolin gene appears absent, an approximately 20 -fold decrease in β-phaseolin accumulation is associated with a single nucleotide polymorphism converting a G-box to an ACGT motif in the proximal promoter. Among residual lectins <b>compensating</b> for <b>storage</b> protein deficiency, mannose lectin FRIL and α-amylase inhibitor 1 genes are uniquely present in SMARC 1 N-PN 1. An approximately 50 -fold increase in α-amylase inhibitor like protein accumulation is associated with multiple polymorphisms introducing up to eight potential positive cis-regulatory elements in the proximal promoter specific to SMARC 1 N-PN 1. An approximately 7 -fold increase in accumulation of 11 S globulin legumin is not associated with variation in proximal promoter sequence, suggesting that the identity of individual proteins involved in proteome rebalancing might also be determined at the translational level...|$|R
40|$|P 2 P file {{downloading}} and streaming {{have already}} become very popular Internet applications. These systems dramatically reduce the server loading, {{and provide a}} platform for scalable content distribution, {{as long as there}} is interest for the content. P 2 P-based video-on-demand (P 2 P-VoD) is a new challenge for the P 2 P technology. Unlike streaming live content, P 2 P-VoD has less synchrony in the users sharing video content, therefore it is much more difficult to alleviate the server loading and at the same time maintaining the streaming performance. To <b>compensate,</b> a small <b>storage</b> is contributed by every peer, and new mechanisms for coordinating content replication, content discovery, and peer scheduling are carefully designed. In this paper, we describe and discuss the challenges and the architectural design issues of a large-scale P 2 P-VoD system based on the experiences of a real system deployed by PPLive. The system is also designed and instrumented with monitoring capability to measure both system and component specific performance metrics (for design improvements) as well as user satisfaction. After analyzing a large amount of collected data, we present a number of results on user behavior, various system performance metrics, including user satisfaction, and discuss what we observe based on the system design. The study of a real life system provides valuable insights for the future development of P 2 P-VoD technology...|$|R
40|$|Apple {{production}} systems {{are an important}} component in the Chinese agricultural sector with 1. 99 million ha plantation. The orchards in China could {{play an important role}} in the carbon (C) cycle of terrestrial ecosystems and contribute to C sequestration. The carbon sequestration capability in apple orchards was analyzed through identifying a set of potential assessment factors and their weighting factors determined by a field model study and literature. The dynamics of the net C sink in apple orchards in China was estimated based on the apple orchard inventory data from 1990 s and the capability analysis. The field study showed that the trees reached the peak of C sequestration capability when they were 18 years old, and then the capability began to decline with age. Carbon emission derived from management practices would not be <b>compensated</b> through C <b>storage</b> in apple trees before reaching the mature stage. The net C sink in apple orchards in China ranged from 14 to 32 Tg C, and C storage in biomass from 230 to 475 Tg C between 1990 and 2010. The estimated net C sequestration in Chinese apple orchards from 1990 to 2010 was equal to 4. 5 % of the total net C sink in the terrestrial ecosystems in China. Therefore, apple {{production systems}} can be potentially considered as C sinks excluding the energy associated with fruit production in addition to provide fruits...|$|R
40|$|This {{study was}} {{undertaken}} for the Israeli Government and includes an updated cost evaluation, configuration optimization, and mode of operation, for a 100 MWe solar power plant, {{the first of}} five similar plants to be erected at one location. Regarding the preferred technology, the central receiver concept, although potentially more efficient then trough since it fits into a combined cycle plant- is neither technologically mature enough nor proven for commercial application. The Fresnel concept is in a similar development stage. The trough technology, used for the SEGS plants, is the only mature and proven technology ready for application today. The current trough plants use the solar steam to directly drive the turbine at 371 oC, due to the thermal oil limitations. This paper analyzes the option of further superheating the steam to 540 oC- the optimal temperature for commercial steam turbine. Higher cycle efficiency improves the plant cost effectiveness, since a smaller solar field is required. Solar fraction reduction can be <b>compensated</b> by thermal <b>storage.</b> The power cost is evaluated {{as a function of}} the solar fraction, for several operational modes. High solar fraction would increase the power cost significantly. Since the solar plant power generation largely overlaps the hours of high demand, and consequently high power cost-the plant becomes marginally economical for Israel at its present power cost level. The expected increase in power cost would make thus plant even more economically attractive. With the environmental and location premium, the plant becomes economical at the current power tariff. Located away from water resources, an air-cooled condenser was chosen instead of a cooling tower. Wet cooling would add 7 % to annual power generation, however, for the specified location, would hardly compensate for the expenses of pumping and desalinating brackish water, as well as the disposal of the concentrates...|$|R
40|$|Sea-level {{change is}} one of the most {{important}} consequences of a warming climate, affecting many densely populated coastal communities. To improve coastal management and the planning of flood defences, information on the future development of sea-level rise is needed. However, sea-level rise is not uniform around the world. It is therefore not sufficient to know how much the global mean sea level will rise in the future. Instead, there is a pressing need for information on a regional scale. Making sea-level projections, both globally and locally, requires understanding of the processes that contribute to sea-level change. The research in this thesis focuses on modelling these processes, and in particular on their regional patterns in sea-level change. Firstly, sea level can rise or fall due to the addition or removal of water. Water may be added when glaciers or ice sheets shrink or due to groundwater pumping, which may be partly <b>compensated</b> by <b>storage</b> of water in newly constructed dams in rivers. Apart from the direct effect of addition or removal of water, a gravitational effect needs to be considered when large masses of water are displaced. This gravitational effect causes a very distinctive pattern in sea-level change, with a sea-level fall close to the water input source, and sea-level rise further away from the source. Apart from the gravitational effect, there is a reaction of the solid earth to changes in the redistribution of mass on the Earth’s surface. This is an effect that occurs immediately, the ‘elastic’ response, as well as on time scales of thousands of years, the ‘viscous’ response. The latter process, termed ‘Glacial Isostatic Adjustment’, results for instance in an uplift of up to a centimetre per year in parts of Scandinavia, as a result of ice melt after the Last Ice Age. Another cause of sea-level change are density variations, which occur when temperature or salinity changes. An increasing temperature causes expansion and thus sea-level rise, while increasing salinity causes densification and thus sea-level fall. Since these changes are not the same everywhere on earth, this causes a very irregular pattern of sea-level change. The research described in this thesis combines the knowledge on these processes to produce regional patterns of sea-level change. These patterns have been computed for the period 1961 - 2003, and compared to sea-level measurements over the same period in order to see whether we understand the regional patterns in sea-level change. The same approach is also used for future projections. These projections clearly show that regional variations are expected to be substantial. We find that 10 % of the ocean surface will experience a change that differs more than 25 % from the global mean. Our research also shows that each process may locally dominate sea-level change, and hence it is very important to include all these processes when considering regional variations...|$|R
40|$|Doctor of PhilosophyDepartment of Hospitality Management and DieteticsElizabeth B. BarrettRebecca A. GouldEquipment {{to store}} foods at proper {{temperatures}} {{is critical to}} serving safe and nutritious meals in schools yet {{little is known about}} the amount or the adequacy of refrigerated storage in school nutrition programs. The purposes of this study were to identify the types and capacity of refrigeration equipment used in schools, determine the perceived adequacy of refrigerated storage capacity to meet new meal pattern requirements, and examine differences in adequacy and capacity. A modified Delphi technique, site observations, pilot study, and electronic survey were used for data collection. School nutrition directors in the USDA/FNS Southwest Region (N= 2392) served as the population. Respondents provided an inventory of refrigeration equipment for one of the schools in their district and information about perceived adequacy of refrigerated storage, barriers to purchasing refrigeration equipment, resources used to develop specifications, and practices to compensate for inadequate refrigerated storage in their program. Data analysis included descriptive statistics, independent sample t-tests, regression, and ANOVA. Over a third of directors indicated that refrigerated equipment was inadequate to meet new meal pattern requirements. Directors with more experience rated adequacy higher than directors with less experience. Milk coolers (n= 212, 88. 3 %) and walk-in freezers (n= 180, 75. 0 %) were the types of refrigeration equipment found most often in schools. Walk-in freezers and refrigerators provided over 95 % of refrigerated storage space. The mean average cubic feet of refrigerated storage per school was 1423 ± 1152. School enrollment is a significant predictor of refrigerated storage capacity. Refrigerated storage is a concern for school nutrition directors who reported practices to <b>compensate</b> for inadequate <b>storage</b> including maintaining low inventory and decreasing the number of items purchased. School nutrition professionals may use the results of this study to implement practices to compensate for inadequate refrigerated storage. Results cannot be generalized due to the regional nature of the survey and low response rate and possible non-response bias...|$|R
40|$|With the {{explosion}} of consumer demand, media streaming will soon be the dominant type of Internet traffic. Since such applications are intrinsically delay-sensitive, the conventional network control policies and coding algorithms may not be appropriate tools for data dissemination over networks. The major issue with design and analysis of delay-sensitive applications {{is the notion of}} delay, which significantly varies across different applications and time scales. We present a framework for studying the problem of media streaming in an unreliable environment. The focus of this work is on end-user experience for such applications. First, we take an analytical approach to study fundamental rate-delay-reliability trade-offs in the context of media streaming for a single receiver system. We consider the probability of interruption in media playback (buffer underflow) as well as the number of initially buffered packets (initial waiting time) as the Quality of user Experience (QoE) metrics. We characterize the optimal trade-off between these metrics as a function of system parameters such as the packet arrival rate and the file size, for different channel models. For a memoryless channel, we model the receiver's queue dynamics as an M/D/ 1 queue. Then, we show that for arrival rates slightly larger than the play rate, the minimum initial buffering required to achieve certain level of interruption probability remains bounded as the file size grows. For the case where the arrival rate and the play rate match, the minimum initial buffer size should scale as the square root of the file size. We also study media streaming over channels with memory, modeled using Markovian arrival processes. We characterize the optimal trade-off curves for the infinite file size case, in such Markovian environments. Second, we generalize the results to the case of multiple servers or peers streaming to a single receiver. Random linear network coding allows us to simplify the packet selection strategies and alleviate issues such as duplicate packet reception. We show that the multi-server streaming problem over a memoryless channel can be transformed into a single-server streaming problem, for which we have characterized QoE trade-offs. Third, we study the design of media streaming applications in the presence of multiple heterogeneous wireless access methods with different access costs. Our objective is to analytically characterize the trade-off between usage cost and QoE metrics. We model each access network as a server that provides packets to the user according to a Poisson process with a certain rate and cost. User must make a decision on how many packets to buffer before playback, and which networks to access during the playback. We design, analyze and compare several control policies. In particular, we show that a simple Markov policy with a threshold structure performs the best. We formulate the problem of finding the optimal control policy as a Markov Decision Process (MDP) with a probabilistic constraint. We present the Hamilton-Jacobi-Bellman (HJB) equation for this problem by expanding the state space, and exploit it as a verification method for optimality of the proposed control policy. We use the tools and techniques developed for media streaming applications in the context of power supply networks. We study the value of storage in securing reliability of a system with uncertain supply and demand, and supply friction. We assume storage, when available, can be used to compensate, fully or partially, for the surge in demand or loss of supply. We formulate the problem of optimal utilization of storage with the objective of maximizing system reliability as minimization of the expected discounted cost of blackouts over an infinite horizon. We show that when the stage cost is linear {{in the size of the}} blackout, the optimal policy is myopic in the sense that all shocks are <b>compensated</b> by <b>storage</b> up to the available level of storage. However, when the stage cost is strictly convex, it may be optimal to curtail some of the demand and allow a small current blackout in the interest of maintaining a higher level of reserve to avoid a large blackout in the future. Finally, we examine the value of storage capacity in improving system's reliability, as well as the effects of the associated optimal policies under different stage costs on the probability distribution of blackouts. by Ali ParandehGheibi. Thesis (Ph. D.) [...] Massachusetts Institute of Technology, Dept. of Electrical Engineering and Computer Science, 2012. Cataloged from PDF version of thesis. Includes bibliographical references (p. 137 - 142) ...|$|R
40|$|M. Ing. Ice storage {{systems are}} used to store thermal {{energy in the form}} of ice {{build-up}} inside storage tanks. During off peak hours, the chiller is used to charge up the storage tank until it is full. During on peak hours, the storage is discharged to meet a certain fraction of the building cooling load. The control strategy employed determines {{the extent to which the}} <b>storage</b> <b>compensates</b> the chiller and visa versa. Given the way in which electricity rates are structured, ice storage systems become an effective energy management strategy. The objective of the study is to compare energy savings derived by using conventional control strategies versus optimal control. Conventional control strategies can be classified as chiller priority control, constant proportion control and storage priority control. In chiller priority control, the chiller meets the cooling load subject to a pre-set limit not being exceeded. Should the limit be exceeded, the remaining cooling load (at each time horizon) is compensated for by the storage. In constant proportion control, both the storage and chiller meets a constant proportion of the cooling load. Storage priority control attempts to discharge as much of the storage as possible, such that at the end of the planning horizon, the ice build up in the storage tank is just depleted. Optimal control employs dynamic programming to ensure that the integrated cost of energy, during the entire planning horizon, is minimal. A steady state ice storage plant model for analysing the performance of the control strategies is presented. The model computes the inlet and outlet temperatures into the various components of the air-conditioning plant, being the air-handling units, heat exchanger, ice storage tanks and chiller. The maximal possible discharge and charging rate at each time period (for the different control strategies) is determined using the model. Given the state of charge of the ice storage tank at each time period, it is then possible to calculate chiller power consumption. The power consumed by fans, fan coil units and pumps (in the air-conditioning plant) has not been calculated in the present analysis, however, the model can easily be extended to include such calculations. The ice storage plant model, enabled simulations of the different control strategies to be carried out over building cooling load profiles for summer and winter. Based on a 24 -hour planning horizon, optimal control is found to be optimal and the only consistently performing strategy for all seasons. For the 5000 kWh ice storage plant investigated, optimal control yielded 25 % energy savings in June and 12 % in January, amounting to a potential of R 11 000 per month. Chiller priority control was near optimal in January but consumed 25 % more energy than the base case (without storage) in June. Constant proportion control was optimal in January but poorer in June. Storage priority control is found to be optimal in June but the lowest performer in January. The drawback of optimal control and storage priority control, however, is that they require prediction of future cooling loads. The variance when using auto-regressive neural network to predict the load is expected to be in the region of 2 % and thus considered acceptable. Chiller priority control and constant proportion control are instantaneous and simple to implement hence their popularity...|$|R
40|$|This report {{deals with}} the {{possibilities}} to fit the Barbier-brook in the Controlled lnundation Area of Kruibeke, Bazel en Rupelmonde that was planned according the Sigmaplan. The so called CIA-KBR is situated upstream Antwerp. The CIA-KBR will be inundated when a certain flood on the river Schelde overflows the lowered river dike. The result is a decrease of {{the peak of the}} flood. A dike at the polder side will fulfill the defensive function during the period of inundation. This dike is called the "ringdike". The Barbier-brook cuts through the CIA-KBR. Within the CIA the Barbier-brook is diked in since the 13 th century. Further on in this text these dikes will be called Barbier-brook dikes. Nowadays, the area between these dikes forms the storage for the Barbier-brook. The study participates in the preparations for the CIA-KBR. Co-ordinated by the Institute of Nature Conservation in Brussels some studies for possibilities of nature development within the CIA-KBR are carried out. In this report the technical possibilities to fit the Barbier-brook in the CIA-KBR as weIl as the perspectives for nature developrnent are studied. The perspectives for nature development can be split in:. nature development influenced by the Barbier-brook. nature development influenced by the Barbier-brook and a controlled reduced tide, controlled reduced tide stands for: a tide controlled by culverts for the in- and outlet of water from the river Schelde with a reduced tide amplitude with an average of 0, 25 to 0, 5 m. This last perspective corresponds most to the historical natural situation of the area, which consists of freshwater marshes and mud plains. To be able to work out these aspects it is necessary to carry out also a study ofthe water quality and quantity of the Barbier-brook. No discharge data from the Barbier-brook are known at all. Based on the discharge data of the Kleine Molenbeek near Liezele, which has a similar catchment area except the size, the discharge frorn the Barbier-brook could be abstracted. To do so, the surface area of the Kleine Molenbeek is multiplied by a factor 1, 43. Frorn these discharge data follows a mean discharge of the Barbier-brook which varies seasonally between 3 and 5 m 3 /s. These data show also an increase in the annual maximum 24 h-discharges starting from approximately 1980. The quality of the water of the Barbier-brook off the CIA-KBR is very bad. The brook is heavily polluted with domestic, industrial and agricultural wastewater. Nearby the site where the brook discharges into the Schelde it is characterised as "biologically dead". The involved communities have made sewerage plans which will decrease the pollution of the Barbier-brook with dornestic wastewater with about 80 %. Concerning the houses which are not covered by the sewerage plans the following measures are given: 1) yet inc 1 ude into the sewerage plans, and 2) provide small-scale biological treatment. After completion of the sewerage plans and the extra measures the following reductions of the pollution by wastewater on the Barbier-brook could be reached:dornestic wastewater: 92 %; industrial wastewater: 90 %; agricultural wastewater: 31 %To make it technically possible to fit the Barbier-brook in the CIA-KBR it is necessary to <b>compensate</b> the <b>storage</b> of the Barbier-brook in order to prevent the brook to cause trouble at the houses of Bazel that stand close to the brookside. For this reason the following measures will be elaborated:The realisation of a storage along the ringdike which is connected with the CIA by means of a culvert. The surface needed for the storage is regulated by the maximum water level that is tolerated in the storage. From calculations follows that there is enough place to realise a storage that can guarantee a safety for a situation with a return period of 1 per 1000 years. No houses need to be removed. The realisation of a storage in the natural valley of the Barbier-brook situated upstream Bazel and the CIA. This storage needs to be fit in the protected landscape without large works. From calculations follows that the available storage volume is insufficient to guarantee a safety for a situation with a return period of 1 per 1000 years. Placing a pumping station at the ringdike with sufficient capacity to pump over a discharge of the Barbier-brook with a return period of 1 per 400 years which is 8, 7 m 3 /s. It is technically possible to reach this with a "screw-up-pumping station" as well as with a "screw-centrifugal-pumping station”Not until the quality of the water of the Barbier-brook improves strongly, nature development can be effectively worked out. In this study the following perspectives for nature development are elaborated in order to increase the value of nature {{in that part of the}} CIA that can be influenced by the Barbier-brook:. Concerning the area between the Barbier-brook dikes possible measures are worked out to improve the present potential values of nature. Thus rich zones along the Creek of Kruibeke can be expected and the higher grounds will be rich in flowering plants. When the dikes around the Barbier-brook are preserved the introduction of a controlled reduced tide is of no influence concerning nature development of the Barbier-brook [...] Concerning a part of the polder of Kruibeke space will be created for development of a more natural Barbier-brook. The agricultural activities on the other grounds will be preserved. Different measures will make this possible of which one is the removal of the Northern Barbier-brook dike. There will be aimed towards broad and rich developed zones along the brook with gradation in vegetation types. The introduction of a controlled reduced tide is not considered because of the present function of agriculture in the polder [...] Concerning the polders of Kruibeke and Bazel measures are worked out to provide a total free development of the Barbier-brook. The most effective measure to reach this is the removal of the Barbier-brook dikes except that part of the dikes between the new ringdike and the natural height in the polder of Bazel. There will be a striving towards a large scaled landscape dominated by reeds and rich developed wetlands. The introduction of a controlled reduced tide is of great influence of the nature development in this situation. It might even re sult in freshwater marshes and mud plains in the CIA-KBR...|$|R

