200|1410|Public
25|$|Inverse {{transform}} sampling {{is simple}} and efficient for small values of λ, and requires only one uniform random number u per sample. <b>Cumulative</b> <b>probabilities</b> are examined in turn until one exceeds u.|$|E
5000|$|... #Caption: A typical {{weighting}} function in Cumulative Prospect Theory. It transforms objective <b>cumulative</b> <b>probabilities</b> into subjective <b>cumulative</b> <b>probabilities.</b>|$|E
5000|$|Online {{calculator}} {{for critical}} values, <b>cumulative</b> <b>probabilities,</b> and critical noncentral parameters ...|$|E
40|$|The {{functional}} relationship between <b>cumulative</b> <b>probability</b> of maximum load factors and <b>cumulative</b> <b>probability</b> of equivalent load factor amplitudes was determined. This relationship {{was derived from}} statistical correlation between cycle ratio and amplitude of load factor suggested {{on the basis of}} processing of firefighting flight records of load factor. The <b>cumulative</b> <b>probability</b> of maximum load factors and ground-air-ground cycle maximum load factor calculated through the <b>cumulative</b> <b>probability</b> of equivalent load factor amplitudes obtained using the range-pair cycle counting method have good agreement with the results calculated using the peak counting method...|$|R
5000|$|... #Caption: Histogram {{derived from}} the adapted <b>cumulative</b> <b>probability</b> {{distribution}} ...|$|R
5000|$|... calculates a <b>cumulative</b> <b>probability</b> {{distribution}} of the given numbers.|$|R
5000|$|Cumulative risk (Get {{the overall}} picture) - {{processing}} <b>cumulative</b> <b>probabilities</b> instead of singe incident probabilities ...|$|E
50|$|Inverse {{transform}} sampling {{is simple}} and efficient for small values of λ, and requires only one uniform random number u per sample. <b>Cumulative</b> <b>probabilities</b> are examined in turn until one exceeds u.|$|E
5000|$|In Shannon coding, {{the symbols}} are {{arranged}} in order from most probable to least probable, and assigned codewords by taking the first [...] bits from the binary expansions of the <b>cumulative</b> <b>probabilities</b> [...] Here [...] denotes the ceiling function (which rounds [...] up to the next integer value).|$|E
3000|$|... where x [...] t [...] and x [...] t+ 1 are {{the upper}} and lower bounds of the t th time interval, respectively; ψ [...] t [...] is the <b>cumulative</b> <b>probability</b> of the t th time interval; F(·) and f(·) are the <b>cumulative</b> <b>probability</b> density {{function}} and the probability density function, respectively.|$|R
50|$|N(d) is <b>cumulative</b> <b>probability</b> {{distribution}} function for a standard normal distribution.|$|R
5000|$|... #Caption: Cumulative {{frequency}} distribution, adapted <b>cumulative</b> <b>probability</b> distribution, {{and confidence}} intervals ...|$|R
5000|$|CPT {{incorporates}} {{these observations}} in {{a modification of}} Expected Utility Theory by replacing final wealth with payoffs relative to the reference point, replacing the utility function with a value function that depends on relative payoff, and replacing <b>cumulative</b> <b>probabilities</b> with weighted cumulative probabilities.In the general case, {{this leads to the}} following formula for subjective utility of a risky outcome described by probability measure : ...|$|E
50|$|The main {{modification}} to Prospect Theory is that, as in rank-dependent expected utility theory, <b>cumulative</b> <b>probabilities</b> are transformed, {{rather than}} the probabilities itself. This leads to the aforementioned overweighting of extreme events which occur with small probability, rather than to an overweighting of all small probability events. The modification helps to avoid a violation of first order stochastic dominance and makes the generalization to arbitrary outcome distributions easier. CPT is therefore on theoretical grounds an improvement over Prospect Theory.|$|E
5000|$|The Clopper-Pearson {{interval}} is {{an early}} and very common method for calculating binomial confidence intervals. This is often called an 'exact' method, but that is because {{it is based on}} the <b>cumulative</b> <b>probabilities</b> of the binomial distribution (i.e., exactly the correct distribution rather than an approximation), but the intervals are not exact in the way that one might assume: the discontinuous nature of the binomial distribution precludes any interval with exact coverage for all population proportions. The Clopper-Pearson interval can be written as ...|$|E
40|$|Background: False-positive {{mammography}} {{results are}} common. Bi-ennial screening may decrease the <b>cumulative</b> <b>probability</b> of false-positive results across {{many years of}} repeated screening but could also delay cancer diagnosis. Objective: To compare the <b>cumulative</b> <b>probability</b> of false-positive results and the stage distribution of incident breast cancer after 10 years of annual or biennial screening mammography...|$|R
50|$|Regression method, using a {{transformation}} of the cumulative distribution function so that a linear relation is found between the <b>cumulative</b> <b>probability</b> and {{the values of the}} data, which may also need to be transformed, depending on the selected probability distribution. In this method the <b>cumulative</b> <b>probability</b> needs to be estimated by the plotting position.|$|R
5000|$|The {{histogram}} {{can also}} be derived from the fitted <b>cumulative</b> <b>probability</b> distribution: ...|$|R
50|$|High card points (HCP) {{are usually}} counted using the Milton Work scale of 4/3/2/1 points for each Ace/King/Queen/Jack respectively. The a priori probabilities {{that a given}} hand {{contains}} {{no more than a}} specified number of HCP is given in the table below. To find the likelihood of a certain point range, one simply subtracts the two relevant <b>cumulative</b> <b>probabilities.</b> So, the likelihood of being dealt a 12-19 HCP hand (ranges inclusive) is the probability of having at most 19 HCP minus the probability of having at most 11 HCP, or: 0.9855 − 0.6518 = 0.3337.|$|E
30|$|The median {{follow-up}} duration was 28.2  months (IQR 26.7). <b>Cumulative</b> <b>probabilities</b> of bowel resection were 0.2, 11.8 and 42.4  % at 1, 3 and 5  years respectively. The CD {{patients with}} bowel damage {{had a higher}} bowel resection rate than those without bowel damage (P <  0.001). The <b>cumulative</b> <b>probabilities</b> of corticosteroid-requirement were 3.0, 19.6 and 78.4  % of patients at 1, 3 and 5  years, respectively, and 2.1, 11.9 and 56.1  %, {{in terms of the}} <b>cumulative</b> <b>probabilities</b> of requiring anti-TNF agents. Patients with elevated CRP (> 1.6  mg/dL) were more likely to undergo bowel resection (P =  0.032).|$|E
3000|$|... {{are known}} as cut-points or {{threshold}} parameters. The inverse logits of these threshold parameters indicate the baseline <b>cumulative</b> <b>probabilities</b> for a response ending up in a certain category (or lower) when all predictors are set to zero. In our case, this implies baseline <b>cumulative</b> <b>probabilities</b> for the clips belonging to the no card reference condition shown in real time (see the “Results” section for an example using the estimated threshold coefficients). The sign of the regression coefficients for reference decisions and video speed indicates how the <b>cumulative</b> <b>probabilities</b> are influenced. For example, positive coefficients indicate {{that the value of}} these predictors is associated with a higher category rating (i.e. a more severe decision).|$|E
30|$|To {{investigate}} {{the relationship of}} <b>cumulative</b> <b>probability</b> distribution {{and its effect on}} measured NDT.|$|R
30|$|In {{order to}} {{investigate}} the effect of beacon frequency, {{we also need to}} look at the <b>cumulative</b> <b>probability</b> of a successful packet reception, in addition to calculating the probability of a successful packet reception for an individual packet at a given time ‘t’. Since we know the single packet reception probability using Equation 8 from the simulation, the <b>cumulative</b> <b>probability</b> can be calculated.|$|R
5000|$|... #Caption: The <b>cumulative</b> <b>probability</b> of {{finishing}} {{a game of}} Snakes and Ladders by turn N ...|$|R
30|$|The primary {{endpoint}} was the cumulative probability of bowel resection. Non-resectional surgery such as seton insertion, fistula repair, perianal surgery, or abscess drainage was excluded. The secondary endpoints were assessed {{between the groups}} as follows: <b>cumulative</b> <b>probabilities</b> of (1) steroid requirement, (2) anti-TNF agents requirement, and (3) disease-related hospitalization. Furthermore, the <b>cumulative</b> <b>probabilities</b> of the primary and secondary endpoints were compared in the patients with bowel damage and those without bowel damage.|$|E
40|$|For square {{contingency}} tables with ordered categories, Yamamoto et al. (2007) considered {{a measure to}} represent the degree of departure from extended marginal homogeneity. It attains the maximum value when one of two symmetric <b>cumulative</b> <b>probabilities</b> is zero. The present paper proposes an improved measure so {{that the degree of}} departure from extended marginal homogeneity can attain the maximum value even when the <b>cumulative</b> <b>probabilities</b> are not zeros. An example is given...|$|E
30|$|In a WSN, {{according}} to a node’s occurrence probability among all the used packet paths the ACP scheme assigns each node a global cumulative probability. Furthermore, the conditional probability is computed for each pair of connected nodes. Such conditional probabilities are used to generate the <b>cumulative</b> <b>probabilities</b> for the directed edges in the provenance graph. Given a packet path in a WSN, the ACP scheme uses the global cumulative probability of the data source as the first coding interval, and then uses the <b>cumulative</b> <b>probabilities</b> derived from the conditional probabilities for all connected node pairs to generate the provenance through arithmetic coding’s encoding algorithm. Under the ACP scheme, the provenance is represented by a subinterval of [0.0,  1.0). With the same global <b>cumulative</b> <b>probabilities</b> for nodes and the same conditional probabilities for node pairs, the provenance can be decoded at the BS through arithmetic coding’s decoding algorithm.|$|E
5000|$|... #Caption: <b>Cumulative</b> <b>probability</b> of {{a normal}} {{distribution}} with expected value 0 and standard deviation 1.|$|R
3000|$|... [...]. The <b>cumulative</b> <b>probability</b> density {{distribution}} {{represented by}} Eq. (16) {{is referred to}} as a fragility function.|$|R
5000|$|<b>Cumulative</b> <b>{{probability}}</b> {{refers to}} the probability of drawing a hand as good as or better than the specified one. For example, the probability of drawing three of a kind is approximately 2.11%, while the probability of drawing a hand at least as good as three of a kind is about 2.87%. The <b>cumulative</b> <b>probability</b> is determined by adding one hand's probability with the probabilities of all hands above it.|$|R
40|$|There {{exists a}} {{performance}} limitation in a pulsed Geiger-mode avalanche photodiode laser ranging system {{because of the}} echo intensity random fluctuation caused by turbulence effects. To suppress the influence of turbulence effects, we present a cumulative pulse detection technique {{with the ability to}} achieve improved <b>cumulative</b> <b>probabilities</b> and range accuracy. Based on the modulated Poisson model, the <b>cumulative</b> <b>probabilities,</b> range accuracy, and their influencing factors are investigated for a cumulative Q-switched laser pulse train. The results show that the improved <b>cumulative</b> <b>probabilities</b> and range accuracy can be obtained by utilizing cumulative pulse detection, with the condition that the echo intensity is 10, the echo pulse width is 10 ns, and the turbulence degree is 3, the target detection probability increases by 0. 4, the false alarm probability decreases by 0. 08, and the accuracy and precision increase by 46 cm and 27 cm, respectively...|$|E
30|$|Interpretation of ordinal {{response}} variables {{can be performed}} according to odds ratios. In this paper, the proportional odds model is used to interpret odds ratios for <b>cumulative</b> <b>probabilities.</b>|$|E
40|$|The {{purposes}} of this study were to tabulate the exact <b>cumulative</b> <b>probabilities</b> for a multinomial such that expected frequencies vary from 1 to not less than 5 in the case where the expected frequencies are equal and to study the accuracy of the conventional chi-square goodness-of-fit test. The tables of <b>cumulative</b> <b>probabilities</b> provide exact tests of goodness-of-fit in small samples. They also serve as criteria for approximations to the multinomial other than the conventional chi-square test or as criteria for the effectiveness of corrections for that test. (Author/FL...|$|E
40|$|A {{statistical}} {{process control}} chart called the <b>cumulative</b> <b>probability</b> control chart (CPC-chart) is proposed. The CPC-chart is motivated from two existing statistical control charts, the cumulative count control chart (CCC-chart) and the cumulative quantity control chart (CQC-chart). The CCC- and CQC-charts are effective in monitoring production processes when the defect rate is low and the traditional p- and c-charts do not perform well. In a CPC-chart, the <b>cumulative</b> <b>probability</b> of the geometric or exponential random variable is plotted against the sample number, and hence the actual <b>cumulative</b> <b>probability</b> is indicated on the charts, Apart from maintaining all the favorable features of the CCC- and CQC-charts, the CPC-chart is more flexible and it can resolve a technical plotting inconvenience of the CCC- and CQC-charts. link_to_subscribed_fulltex...|$|R
30|$|The all-RTT <b>cumulative</b> <b>probability</b> {{distributions}} for Wi-Fi, Wi-Fi Direct, and Bluetooth {{are shown}} in Figs.  4,  5, and  6, respectively.|$|R
2500|$|Let [...] and [...] be {{respectively}} the <b>cumulative</b> <b>probability</b> distribution function and the probability density {{function of the}} N(0,1) distribution.|$|R
