3|3|Public
40|$|Knowledge {{discovery}} in databases {{has become an}} increasingly important research topic {{with the advent of}} wide area network computing. One of the crucial problems we study in this paper is how to scale machine learning algorithms, that typically are designed to deal with main memory based datasets, to efficiently learn from large distributed databases. We have explored an approach called meta-learning that is related to the traditional approaches of data reduction commonly employed in distributed query processing systems. Here we seek efficient means to learn how to combine a number of base classifiers, which are learned from subsets of the data, so that we scale efficiently to larger learning problems, and boost the accuracy of the constituent classifiers if possible. In this paper we compare the arbiter tree strategy to a new but related approach called the <b>combiner</b> <b>tree</b> strategy...|$|E
40|$|Sentiment can {{be defined}} as a {{tendency}} to experience certain emotions in relation to a particular object or person. Sentiment may be expressed in writing, in which case determining that sentiment algorithmically is known as sentiment analysis. Sentiment analysis is often applied to Internet texts such as product reviews, websites, blogs, or tweets, where automatically determining published feeling towards a product, or service is very useful to marketers or opinion analysts. The main goal of sentiment analysis is to identify the polarity of natural language text. This thesis sets out to examine quantitatively the factors that have an effect on sentiment analysis. The factors that are commonly used in sentiment analysis are text features, sentiment lexica or resources, and the machine learning algorithms employed. The main aim of this thesis is to investigate systematically the interaction between sentiment analysis factors and machine learning algorithms in order to improve sentiment analysis performance as compared to the opinions of human assessors. A software system known as TJP was designed and developed to support this investigation. The research reported here has three main parts. Firstly, the role of data pre-processing was investigated with TJP using a combination of features together with publically available datasets. This considers the relationship and relative importance of superficial text features such as emoticons, n-grams, negations, hashtags, repeated letters, special characters, slang, and stopwords. The resulting statistical analysis suggests that a combination of all of these features achieves better accuracy with the dataset, and had a considerable effect on system performance. Secondly, the effect of human marked up training data was considered, since this is required by supervised machine learning algorithms. The results gained from TJP suggest that training data greatly augments sentiment analysis performance. However, the combination of training data and sentiment lexica seems to provide optimal performance. Nevertheless, one particular sentiment lexicon, AFINN, contributed better than others in the absence of training data, and therefore would be appropriate for unsupervised approaches to sentiment analysis. Finally, the performance of two sophisticated ensemble machine learning algorithms was investigated. Both the Arbiter Tree and <b>Combiner</b> <b>Tree</b> were chosen since neither of them has previously been used with sentiment analysis. The objective here was to demonstrate their applicability and effectiveness compared to that of the leading single machine learning algorithms, Na√Øve Bayes, and Support Vector Machines. The results showed that whilst either can be applied to sentiment analysis, the Arbiter Tree ensemble algorithm achieved better accuracy performance than either the <b>Combiner</b> <b>Tree</b> or any single machine learning algorithm...|$|E
40|$|A {{method for}} {{measuring}} {{a wide range}} of SET pulses is demonstrated. Use of dynamic logic, faster than ordinary CMOS, allows capture of short pulses. A weighted binning of SET lengths allows measurement of {{a wide range of}} pulse lengths with compact circuitry. A pulse-length-conservative pulse <b>combiner</b> <b>tree</b> routes SETs from combinational logic to the measurement circuit, allowing SET measurements in circuits that cannot easily be arranged in long chains. The method is applied to add-multiplex combinational logic, and to an array of NFET routing switches, at. 35 micron. Pulses are captured in a chain of Domino Logic AND gates. Propagation through the chain is frozen on the trailing edge by dropping low the second "enable" input to the AND gates. Capacitive loading is increased in the latter stages to create an approximately logarithmic weighted binning, so that a broad range of pulse lengths can be captured with a 10 stage capture chain. Simulations show pulses can be captured which are 1 / 5 th the length of those typically captured with leading edge triggered latch methods, and less than the length of those captured with a trailing edge latch method. After capture, the pulse pattern is transferred to an SEU protected shift register for readout. 64 instances of each of two types of logic are used as targets. One is a full adder with a 4 to 1 mux on its inputs. The other is a 4 x 4 NFET routing matrix. The outputs are passed through buffered XNOR comparators to identify pulses, which are merged in a buffered not-nand (OR) tree designed to avoid pulse absorption as much as possible. The output from each of the two test circuits are input into separate pulse measurement circuits. Test inputs were provided so that the circuit could be bench tested and calibrated. A third SET measurement circuit with no inputs was used to judge the contribution from direct hits on the measurement circuit. Heavy ions were used with an LET range from 12 to 176. At LET of 21 and below, the very small number of SETs were not significantly higher in the test over the control circuits. At higher LET the test circuit SETs are one or two orders of magnitude greater than for the control circuit. The NFET circuit produces more and slightly longer SETs as expected. But the differences do not appear to be significant enough to modify strategies now used to avoid capture of SETs in chips such as FPGAs. Complete data and graphs will be in the full paper / presentation. In the summary figure below left, NOCL is the reference circuit without any input, and number of stages triggered is plotted. Simulation at right shows the smallest pulse captured (stage 2) at about 300 ps. Our conclusion is that the method is promising, but that improvements in the merge network are desirable before applying in a deep submicron proces...|$|E
40|$|Much of the {{research}} in inductive learning concentrates on problems with relatively small amounts of data residing at one location. In this paper we explore the scalability of learning arbiter and <b>combiner</b> <b>trees</b> from partitioned data. Arbiter and <b>combiner</b> <b>trees</b> integrate classifiers trained in parallel from small disjoint subsets. Previous work demonstrated their efficacy in terms of accuracy, this paper discusses their performance in terms of speedup and scalability. The performance of serial learning algorithms is evaluated. The performance of the algorithms used to construct <b>combiner</b> and arbiter <b>trees</b> in parallel is then analyzed. Our empirical {{results indicate that the}} techniques can effectively scale up to large datasets with millions of records. Keywords: scalability, arbiter and <b>combiner</b> <b>trees,</b> meta-learning, parallel/distributed processing, inductive learning This work was partially funded by grants from NSF (IRI- 96 - 32225 & CDA- 96 - 25374), ARPA (F 3060296 - 1 - 0311), NYSSTF (4231 [...] ...|$|R
40|$|In {{this paper}} we study {{the issue of}} how to scale machine {{learning}} algorithms, that typically are designed to deal with main-memory based datasets, to efficiently learn models from large distributed databases. We have explored an approach called metalearning that is related to the traditional approaches of data reduction commonly employed in distributed database query processing systems. We explore the scalability of learning arbiter and <b>combiner</b> <b>trees</b> from partitioned data. Arbiter and <b>combiner</b> <b>trees</b> integrate classifiers trained in parallel from small disjoint subsets. Previous work demonstrated the efficacy of these meta-learning architectures in terms of accuracy of the computed meta-classifiers. Here we discuss the computational performance of constructing arbiter and <b>combiner</b> <b>trees</b> in terms of speedup and scalability as a function of database size and number of partitions. The performance of serial learning algorithms is evaluated. We then analyze the performance of the algorithm [...] ...|$|R
40|$|Abstract Background Genome context {{methods have}} been {{introduced}} {{in the last decade}} as automatic methods to predict functional relatedness between genes in a target genome using the patterns of existence and relative locations of the homologs of those genes in a set of reference genomes. Much work has been done in the application of these methods to different bioinformatics tasks, but few papers present a systematic study of the methods and their combination necessary for their optimal use. Results We present a thorough study of the four main families of genome context methods found in the literature: phylogenetic profile, gene fusion, gene cluster, and gene neighbor. We find that for most organisms the gene neighbor method outperforms the phylogenetic profile method by as much as 40 % in sensitivity, being competitive with the gene cluster method at low sensitivities. Gene fusion is generally the worst performing of the four methods. A thorough exploration of the parameter space for each method is performed and results across different target organisms are presented. We propose the use of normalization procedures as those used on microarray data for the genome context scores. We show that substantial gains can be achieved from the use of a simple normalization technique. In particular, the sensitivity of the phylogenetic profile method is improved by around 25 % after normalization, resulting, to our knowledge, on the best-performing phylogenetic profile system in the literature. Finally, we show results from combining the various genome context methods into a single score. When using a cross-validation procedure to train the combiners, with both original and normalized scores as input, a decision <b>tree</b> <b>combiner</b> results in gains of up to 20 % with respect to the gene neighbor method. Overall, this represents a gain of around 15 % over what can be considered {{the state of the art}} in this area: the four original genome context methods combined using a procedure like that used in the STRING database. Unfortunately, we find that these gains disappear when the combiner is trained only with organisms that are phylogenetically distant from the target organism. Conclusions Our experiments indicate that gene neighbor is the best individual genome context method and that gains from the combination of individual methods are very sensitive to the training data used to obtain the combiner's parameters. If adequate training data is not available, using the gene neighbor score by itself instead of a combined score might be the best choice. </p...|$|R

