3|32|Public
40|$|Do-calculus is {{concerned}} with estimating the interventional distribution of an action from the observed joint probability distribution of the variables in a given causal structure. All identifiable causal effects can be derived using the rules of do-calculus, but the rules themselves do not give any direct indication whether the effect in question is identifiable or not. Shpitser and Pearl (2006 b) constructed an algorithm for identifying joint interventional distributions in causal models, which contain unobserved variables and induce directed acyclic graphs. This algorithm {{can be seen as}} a repeated application of the rules of do-calculus and known properties of probabilities, and it ultimately either derives an expression for the <b>causal</b> <b>distribution,</b> or fails to identify the effect, in which case the effect is non-identifiable. In this paper, the R package causaleffect is presented, which provides an implementation of this algorithm. Functionality of causaleffect is also demonstrated through examples...|$|E
40|$|Investigating {{the role}} of causal order in quantum {{mechanics}} has recently revealed that the <b>causal</b> <b>distribution</b> of events may not be a-priori well-defined in quantum theory. While this has triggered a growing interest on the theoretical side, creating processes without a causal order is an experimental task. Here we report the first decisive demonstration of a process with an indefinite causal order. To do this, we quantify how incompatible our set-up is with a definite causal order by measuring a 'causal witness'. This mathematical object incorporates a series of measurements which are designed to yield a certain outcome only if the process under examination is not consistent with any well-defined causal order. In our experiment we perform a measurement in a superposition of causal orders - without destroying the coherence - to acquire information {{both inside and outside}} of a 'causally non-ordered process'. Using this information, we experimentally determine a causal witness, demonstrating by almost seven standard deviations that the experimentally implemented process does not have a definite causal order. Comment: 11 pages + a 9 -page Appendix; 5 figures + 5 in the Appendix. Corrected definitions of unitaries in Appendi...|$|E
40|$|The {{purpose of}} this study was to examine and compare the {{association}} between culture and causal attribution for Saami and Norwegian participants. Data was collected through cognitive mapping, a technique aimed towards the investigation of causal attribution. Cognitive mapping investigates the causal models people hold, and sheds light on content, factors, structure, causal categories and maps people construct when forming explanations for events and situations. The events constructed in this study were based on Physical-, Biological-, Social and Psychological-, Supernatural- and Composite domain knowledge. Testing the causal model involved the three steps: 1) free listing of causal entities, 2) construction of causal maps and 3) identification of important factors in the maps for a selection of events across domains. There were 38 respondents, constituting of Saami (N = 19) and Norwegian (N = 19) participants. They were presented with the exact same events but in random order. The following cases were investigated: most different individual factors across domains, most different key factors, factor distribution within and across domain, factors within and across causal categories, differences and similarities in causal maps. Differences found related to individual- and key factor difference, use of more unidirectional arrows for the Saami and bidirectional arrows for the Norwegian. There was no significant difference between the groups in the scope of <b>causal</b> <b>distribution</b> across and within domain, causal categories and causal maps. The results were interpreted in terms of the relationship between the groups and the individual position within that group, as well as mechanisms of thinking and reasoning...|$|E
40|$|Shows how {{value chain}} {{analysis}} {{can be used}} both to chart the growing disjuncture between global economic activity and global income <b>distribution.</b> <b>Causal</b> relationship between increasing inequality and the global integration of production and trade; Outline of the central elements of value chain analysis...|$|R
40|$|The Epstein–Glaser type T-subtraction {{introduced}} {{by one of}} the authors in a previous paper is extended to the Lorentz invariant framework. The advantage of using our subtraction instead of Epstein and Glaser’s standard W-subtraction method is especially important when working in Minkowski space, as then the counterterms necessary to keep Lorentz invariance are simplified. We show how T-renormalization of primitive diagrams in the Lorentz invariant framework directly relates to <b>causal</b> Riesz <b>distributions.</b> A covariant subtraction rule in momentum space is found, sharply improving upon the BPHZL method for massless theories...|$|R
40|$|Risikovurdering av underbalansert boring og boring med styrt trykk (”managed {{pressure}} drilling”)) In recent years, underbalanced drilling (UBD) {{and managed}} pressure drilling (MPD) {{have been developed}} as alternatives to the traditional overbalanced drilling technique. The new techniques have several advantages, but the blowout risk is yet not fully understood. The main objective of the current master thesis {{is to develop a}} blowout risk model for UBD and MPD that is compatible with the blowout frequency assessment model (BlowFAM) that has been developed by Scandpower. As part of this thesis, the candidate shall: 1. Give a detailed presentation of the technology and procedures that are used for UBD and MPD. The presentation shall be based on a detailed literature survey and contacts with drilling operators and their consultants. 2. Identify, describe and document hazardous events during the various steps of a UBD and an MPD operation. The hazard identification shall be carried out by using analytical tools and supplemented by interviews with relevant personnel and analyses of available field performance data. 3. Extract descriptions of relevant well control incidents from available data and identify and describe root causes and <b>causal</b> <b>distributions.</b> 4. Establish formulas for relations between the causes in para. 3 and formation characteristics. 5. Establish a generic blowout frequency model that is compatible with BlowFAM...|$|R
40|$|To the Memory of Laurent Schwartz The Epstein–Glaser type T-subtraction {{introduced}} {{by one of}} the authors in a previous paper is extended to the Lorentz invariant framework. The advantage of using our subtraction instead of Epstein and Glaser’s standard W-subtraction method is especially important when working in Minkowski space, as then the counterterms necessary to keep Lorentz invariance are simplified. We show how T-renormalization of primitive diagrams in the Lorentz invariant framework directly relates to <b>causal</b> Riesz <b>distributions.</b> A covariant subtraction rule in momentum space is found, sharply improving upon the BPHZL method for massless theories...|$|R
40|$|This paper reviews inverse {{selection}} probability weighting {{to estimate}} dynamic <b>causal</b> effects. A <b>distribution</b> theory based on sequential GMM estimation is proposed and {{the method is}} applied to a re-evaluation of {{some parts of the}} Swiss active labor market policy to obtain new results and discuss several issues about the implementation of the estimation procedure...|$|R
40|$|Abstract: We {{consider}} asymptotic {{problems in}} spectral analysis of stationary <b>causal</b> processes. Limiting <b>distributions</b> of periodograms and smoothed periodogram spectral density estimates are obtained and applications to spectral domain boot-strap are made. Instead of the commonly used strong mixing conditions, in our asymptotic spectral theory we impose conditions only involving (conditional) mo-ments, which are easily veriable {{for a variety}} of nonlinear time series. ...|$|R
40|$|Black {{foot disease}} of grapevine is a {{relatively}} new, and as yet poorly known disease affecting vines in various countries where grapevines are cultivated. The <b>causal</b> organisms, their <b>distribution,</b> associated symptoms, known epidemiology and possible management strategies are discussed. Specific attention is also given to the taxonomy of the fungi involved, and the detection methods being developed to facilitate rapid identification of these pathogens...|$|R
40|$|We {{consider}} asymptotic {{problems in}} spectral analysis of stationary <b>causal</b> processes. Limiting <b>distributions</b> of periodograms and smoothed periodogram spectral density estimates are obtained and applications to the spectral domain bootstrap are given. Instead of the commonly used strong mixing conditions, in our asymptotic spectral theory we impose conditions only involving (conditional) moments, which are easily verifiable {{for a variety}} of nonlinear time series. 1. Introduction. Th...|$|R
40|$|Pigeonpea (Cajanus cajan (L.) Millsp.) {{is one of}} t h e most {{important}} grain legume components of subsistence farming systems in t h e semi-arid tropics. Many fungi, viruses, nematodes, bacteria, and mycoplasma-like organisms attack pigeonpea, {{but only a few}} of these are important constraints to pigeonpea production. This bulletin provides information on the <b>causal</b> agents, <b>distribution,</b> economic importance, symptoms, epidemiology, and management of major diseases of pigeonpea. The text is supplemented with color photographs of disease symptoms and a diagnostic key is included to facilitate identification. Information is provided on control measures that include the use of resistant varieties, cultural practices, and chemicals. Supporting literature on the major diseases is listed...|$|R
40|$|The Epstein [...] Glaser type T-subtraction {{introduced}} {{by one of}} the authors in a previous paper is extended to the Lorentz invariant framework. The advantage of using our subtraction instead of Epstein and Glaser's standard W-subtraction method is especially important when working in Minkowski space, as then the counterterms necessary to keep Lorentz invariance are simplified. We show how T-renormalization of primitive diagrams in the Lorentz invariant framework directly relates to <b>causal</b> Riesz <b>distributions.</b> A covariant subtraction rule in momentum space is found, sharply improving upon the BPHZL method for massless theories. Comment: LaTeX, 15 pages, no figure. Version to be published in J. Math. Phys. (Section 7 on the Massive Case and some references have been withdrawn). To the Memory of Laurent Schwart...|$|R
40|$|We {{consider}} the gauge invariance {{of the standard}} Yang-Mills model {{in the framework of}} the causal approach of Epstein-Glaser and Scharf and we prove the following result: if the anomalies are absent in lower orders of the perturbation theory (more precisely for n ≤ 6) then they are absent in all orders of perturbation theory. The method used is based on a careful consideration of the <b>causal</b> splitting of <b>distributions</b> and is quite elementary. ...|$|R
40|$|LaTeX, 15 pages, no figure. Version to be {{published}} in J. Math. Phys. (Section 7 on the Massive Case and some references have been withdrawn). To the Memory of Laurent Schwartz. Report-no: CPT- 2002 /P. 4462 The Epstein [...] Glaser type T-subtraction introduced by one of the authors in a previous paper is extended to the Lorentz invariant framework. The advantage of using our subtraction instead of Epstein and Glaserś standard W-subtraction method is especially important when working in Minkowski space, as then the counterterms necessary to keep Lorentz invariance are simplified. We show how T-renormalization of primitive diagrams in the Lorentz invariant framework directly relates to <b>causal</b> Riesz <b>distributions.</b> A covariant subtraction rule in momentum space is found, sharply improving upon the BPHZL method for massless theories...|$|R
40|$|For {{the latest}} on {{sugarcane}} diseases, here is clear and structured help: per disease, information on the <b>causal</b> agent, geographical <b>distribution,</b> symptoms, transmission, diagnosis and control. A guide to sugarcane diseases Edited by P Rott, R A Bailey et al., CIRAD & ISSCT, 2000. 339 pp. ISBN 2 87 614 386 0 FRF 490 E 74. 70 CIRAD TA 283 / 04, avenue Agropolis 34398 Montpellier Cedex 5,France Fax: + 33 467 61 55 47 Email: librairie@cirad. frA guide to sugarcane disease...|$|R
40|$|Statistical {{complexity}} is {{a measure}} of complexity of discrete-time stationary stochastic processes, which has many applications. We investigate its more abstract properties as a non-linear function of the space of processes and show its close relation to the Knight’s prediction process. We prove lower semi-continuity, concavity, and a formula for the ergodic decomposition of statistical complexity. On the way, we show that the discrete version of the prediction process has a continuous Markov transition. We also prove that, given the past output of a partially deterministic hidden Markov model (HMM), the uncertainty of the internal state is constant over time and knowledge of the internal state gives no additional information on the future output. Using this fact, we show that the <b>causal</b> state <b>distribution</b> is the unique stationary representation on prediction space that may have finite entropy...|$|R
40|$|The space-time {{foliation}} Sigma {{compatible with}} the gravitational field g on a 4 -manifold M determines a fibration pi of M, pi : M -> N is a surjective submersion over the 1 -dimensional leaves space N. M is then written as a disjoint union of the leaves of Sigma, which are 3 -dimensional spacelike surfaces on M. The decomposition, TM=Sigma + T^ 0 M, also implies that we can define a lift of the curves on N to curves (non-spacelike) on M. The stable causality condition M coincides with Sigma being a <b>causal</b> space-time <b>distribution,</b> generated by an exact timelike 1 -form omega^ 0 = dt where t is some real function on M. In this case M is written as a disjoint union {{of a family of}} spacelike 3 -surfaces of constant t, which cover D^+(S) of a initial 3 -surface S of M. Comment: 6 pages, LaTe...|$|R
40|$|Abstract—We {{investigate}} approximating joint {{distributions of}} random processes with <b>causal</b> dependence tree <b>distributions.</b> Such distributions are particularly useful in providing parsimonious representation when there exists causal dynamics among pro-cesses. By extending the results by Chow and Liu on dependence tree approximations, {{we show that}} the best causal dependence tree approximation is the one which maximizes the sum of directed informations on its edges, where best is {{defined in terms of}} minimizing the KL-divergence between the original and the approximate distribution. Moreover, we describe a low-complexity algorithm to efficiently pick this approximate distribution. I...|$|R
40|$|Among {{domestic}} animals, pigs {{are particularly}} susceptible to mycobacterial infections caused es-pecially {{by members of}} the Mycobacterium tubercu-losis complex (MTC; Thoen et al., 2006), M. avium complex (MAC; Pavlik et al., 2003 b, 2005 a), and conditionally pathogenic mycobacteria (Morita et al., 1994 a,b; Thorel et al., 1997; Komijn et al., 1999; Offermann et al., 1999). The occurrence of tuber-culous/tuberculoid lesions in pigs brings consider-able economic losses (Berthelsen, 1974; Dey and Mycobacterial and Rhodococcus equi infections in pigs in the Czech Republic between the years 1996 and 2004 : the <b>causal</b> factors and <b>distribution</b> of infections in the tissue...|$|R
40|$|Remarkably, it {{has been}} shown that in principle, {{security}} proofs for quantum key-distribution (QKD) protocols can be independent of assumptions on the devices used and even of the fact that the adversary is limited by quantum theory. All that is required instead is the absence of any hidden information flow between the laboratories, a condition that can be enforced either by shielding or by space-time causality. All known schemes for such <b>Causal</b> Key <b>Distribution</b> (CKD) that offer noise-tolerance (and, hence, must use privacy amplification as a crucial step) require multiple devices carrying out measurements in parallel on each end of the protocol, where the number of devices grows with the desired level of security. We investigate the power of the adversary for more practical schemes, where both parties each use a single device carrying out measurements consecutively. We provide a novel construction of attacks that is strictly more powerful than the best known attacks and has the potential to decide the question whether such practical CKD schemes are possible in the negative...|$|R
40|$|The space-time {{foliation}} {{compatible with}} the gravitational eld g on a 4 -manifold M determines a bration of M, : M ! N is surjective submersion over the 1 -dimensional leaves space N. M is then written as a disjoint union of the leaves of, which are 3 -dimensional spacelike surfaces on M. The decomposition, TM = T 0 M, also implies that we can dene a lift of the curves on N to curves (non-spacelike) on M. The stable causality condition holds on M [2] means that is a <b>causal</b> space-time <b>distribution,</b> generated by an exact timelike 1 -form ! 0 = dt where t is some real function on M. In this case M is written as a disjoint union {{of a family of}} spacelike 3 -surfaces of constant t, which cover D + (S) of a initial 3 -surface S of M. A. M. S. Classication Code. Primary: 83 C 99, Secondary: 53 B 30 53 C 50 53 C 12 57 R 30 Keywords. space-time distribution, 4 -manifold Suceava, 5800 Romania E-mail: mtime@warpnet. ro Copyright c 1999 by Cameron University 23 1 Introduction Note: [...] ...|$|R
40|$|The {{relation}} between rate distortion function (RDF) and Bayesian filtering theory is discussed. The relation is established by imposing a causal or realizability constraint on the reconstruction conditional {{distribution of the}} RDF, leading {{to the definition of}} a causal RDF. Existence of the optimal reconstruction <b>distribution</b> of the <b>causal</b> RDF is shown using the topology of weak convergence of probability measures. The optimal non-stationary <b>causal</b> reproduction conditional <b>distribution</b> of the <b>causal</b> RDF is derived in closed form; it is given by a set of recursive equations which are computed backward in time. The realization of causal RDF is described via the source-channel matching approach, while an example is briefly discussed to illustrate the concepts. Comment: 5 pages, 3 figures, 1 table, 1 graph, submitted to Information Theory Workshop 201...|$|R
40|$|AbstractLet the {{operator}} 5 describe a linear causal system. Then, roughly, {{the system is}} dissipative if it satisfies the scattering condition I − SS∗ ⩾ 0 [relation (4. 2) ] or the immittance condition S + S∗ ⩾ 0 [relation (4. 1) ]. In either case, the resulting kernel is a real, tempered, and <b>causal</b> matrix <b>distribution.</b> More specifically, s belongs to D′L 2 ∩ D′+ ⊗ L in one case and w ϵ D′L∞ ∩ D′+ ⊗ L in the other. The passivity {{of the system is}} reflected in the respective positivity statements that 1 δ − s ∗ ≈sT (the kernel of 1 − SS∗) or w + w̃T (the kernel of S + S∗) are positive in the sense of Bochner. The Laplace transform of the kernel exists and dissipativity shows that either the scattering matrix S(p) is bounded-real or that the immittance matrix W(p) is positive-real. Conversely, every bounded-real or positive-real matrix is the scatterings or immittance matrix of a dissipative system. In the frequency domain, these conditions translate into the assertion that either 1 − S(ω) S(ω) T is a. e. nonnegative definite (equivalently, ∥S(ω) ∥ ⩽ 1 a. e.), or that Wω + W̄ωT defines a positive matrix valued measure. In the lossless case, we must have S(ω) be a. e. unitary. We saw that S(p), W(p) ϵ H+ and have S′ boundary values, component by component. The real and imaginary parts of these boundary values satisfy precise dispersion relations...|$|R
40|$|In Nepal, maize ranks {{second after}} rice both in area and {{production}}. In recent years, maize area and production {{has shown a}} steady increase, but productivity has been low (2. 46 t/ha). The major maize producing regions in Nepal are mid hill (72. 85 %), terai (17. 36 %) and high hill (9. 79 %) respectively. A literature review was carried out to explore major maize diseases and their management in Nepal. The omnipresent incidence of diseases at the pre harvest stage {{has been an important}} bottleneck in increasing production. Till now, a total of 78 (75 fungal and 3 bacterial) species are pathogenic to maize crop in Nepal. The major and economically important maize diseases reported are Gray leaf spot, Northern leaf blight, Southern leaf Blight, Banded leaf and sheath blight, Ear rot, Stalk rot, Head smut, Common rust, Downy mildew and Brown spot. Information on bacterial and virus diseases, nematodes and yield loss assessment is also given. Description of the major maize diseases, their <b>causal</b> organisms, <b>distribution,</b> time and intensity of disease incidence, symptoms, survival, spreads, environmental factors for disease development, yield losses and various disease management strategies corresponded to important maize diseases of Nepal are gathered and compiled thoroughly from the available publications. Concerted efforts of NARC commodity programs, divisions, ARS and RARS involving research on maize pathology and their important outcomes are mentioned. The use of disease management methods focused on host resistance has also been highlighted...|$|R
40|$|This study {{builds on}} prior work, which {{identified}} that students of age 11 years had sound intuitions for short-term randomness but had few tools for articulating patterns in longer-term randomness. This previous work did however identify {{the construction of}} new <b>causal</b> meanings for <b>distribution</b> when they interacted with a computer-based microworld. Through a design research methodology, we are building new microworlds that aspire to capture how students might use knowledge about the deterministic to explain probability distribution as an emergent phenomenon. In this paper, we report on some insights gained from early iterations and show how we have embodied these ideas into a new microworld, not yet tested with students. EMERGENT PHENOMENA In the service of making sense of the world, people appear to have an intrinsic desire to attribute meaning to what they observe, a search which leads, in turn, to organisation, the formation of patterns, the encoding of pictures, and simplification. Even complex dynamic systems are simplified into emergen...|$|R
40|$|The {{environmental}} {{quality of soil}} polluted by mercury and lead in typical polymetallic deposit areas of western Hunan province and its natural and human causes were studied. It was found that western Hunan province is a high regional geochemical abnormal region on mercury and lead. The concentrations of mercury and lead in soils in mercury deposit areas were 1315 and 3. 1 times {{higher than that of}} the average background of soils in China respectively, while those in soils in lead-zinc deposit areas were 14. 8 and 16. 1 times higher. Using geoaccumulation index developed by Muller, it was found that either mercury deposit area or lead-zinc deposit area in western Hunan province is polluted by the two elements, the majority soils in mercury deposit areas are seriously polluted by mercury with middle polluted or light polluted by lead, while the majority soils in lead-zinc deposit areas are middle polluted or middle-heavily polluted by lead and middle-heavily polluted by mercury. The sources of metal pollutants in soils in the deposit areas are natural and human <b>causal,</b> the spatial <b>distribution</b> of mercury and lead are dominated by original geochemical situation but seriously affected by human mining activities...|$|R
40|$|Over {{the last}} two decades {{residential}} exposure to extremely low frequency magnetic fields (ELF MF) has been associated with childhood leukaemia relatively consistently in epidemiological studies, though causality is still under investigation. We aimed to estimate the cases of childhood leukaemia that might be attributable to exposure to ELF MF in the European Union (EU 27), if the associations seen in epidemiological studies were <b>causal.</b> We estimated <b>distributions</b> of ELF MF exposure using studies identified in the existing literature. Individual distributions of exposure were integrated using a probabilistic mixture distribution approach. Exposure–response functions were estimated from the most recently published pooled analysis of epidemiological data. Probabilistic simulation was used to estimate population attributable fractions (AFP) and attributable cases of childhood leukaemia in the EU 27. By assigning the literature review-based exposure distribution to all EU 27 countries, we estimated the total annual number of cases of leukaemia attributable to ELF MF at between ~ 50 (95 % CIs: − 14, 132) and ~ 60 (95 % CIs: − 9, 610), depending on whether exposure–response was modelled categorically or continuously, respectively, for a non-threshold effect. This corresponds to between ~ 1. 5 % and ~ 2. 0 % of all incident cases of childhood leukaemia occurring annually in the EU 27. Considerable uncertainties are due to scarce data on exposure and the choice of exposure–response model, demonstrating the importance of further research into better understanding mechanisms of the potential association between ELF MF exposure and childhood leukaemia and the need for improved monitoring of residential exposures to ELF MF in Europe...|$|R
40|$|This work {{examines}} {{an information}} theoretic quantity known as directed information, which measures statistically causal influences between processes. It {{is shown to}} be a general quantity, applicable to arbitrary probability distributions. It is interpreted in terms of prediction, communication with feedback, source coding with feed forward, control over noisy channels, and other settings. It is also shown to be consistent with Granger's philosophical definition. The concepts of direct and indirect causation in a network of processes are formalized. Next, two applications of directed information are investigated. Neuroscience researchers have been attempting to identify causal relationships between neural spike trains in electrode recordings, but have been doing so with correlation measures and measures based on Granger causality. We discuss why these methods are not robust, and do not have statistical guarantees. We use a point process GLM model and MDL (as a model order selection tool) for consistent estimation of directed information between neural spike trains. We have successfully applied this methodology to a network of simulated neurons and electrode array recordings. This work then develops a procedure, similar to Chow and Liu's, for fi nding the "best" approximation (in terms of KL divergence) of a full, joint distribution over a set of random processes, using a <b>causal</b> dependence tree <b>distribution.</b> Chow and Liu's procedure had been shown to be equivalent to maximizing a sum of mutual informations, and the procedure presented here is shown to be equivalent to maximizing a sum of directed informations. An algorithm is presented for efficiently finding the optimal causal tree, similar to that in Chow and Liu's work...|$|R
40|$|Powerful {{individuals}} often {{influence the}} delivery of government services for their own purposes. Officials may prefer inherently to direct assistance to their own relatives and social contacts (nepotistic preferences). Alternatively, they may use government services strategically in exchange for favors (patronage) or to gain voter support (clientelism). Most existing literature examines these three phenomena separately, or does not distinguish the motivations for politicians’ influence on <b>distribution.</b> <b>Causal</b> identification {{has also been a}} problem in the empirical literature. In the first chapter of this thesis, I develop a theoretical model of interaction between three levels of actors: politicians, local patrons, and households. The model allows for politicians and patrons to influence government services for nepotistic, clientelistic, and patronage purposes. In chapters 2 - 4, I test the predictions of the model using two novel household survey datasets I collected along with my collaborators in rural Punjab, Pakistan. Chapter 2 tests the theoretical predictions for the interaction of politicians, patrons and voters. Chapters 3 and 4 provide quasi-experimental evidence on the causal effect of links with politicians on assistance. I find evidence that politicians exert dramatic influence on the targeting of government assistance in this setting. Consistent with the theoretical model, the most assistance goes to a small “inner circle” of their closest contacts. Politicians assist this “inner circle” based on their inherent preferences, regardless of electoral pressure. When politicians face electoral pressure, they also deliver assistance to a wider group, in particular members of the same clan. In contrast, local patrons do not appear to have significant independent influence over the targeting of the government assistance programs I study, but they do provide other types of assistance to households. Their behavior is more consistent with the idea that they are motivated by inherent preferences for assisting their contacts. The results have implications for the interpretation of empirical literature on nepotism, clientelism, and patronage. They can also inform the policies of donor agencies and civil society organizations who aim to engage or pressure governments to reduce corruption and improve public spending. This thesis is not currently available in OR...|$|R
40|$|Two {{mesoscale}} net sampling {{surveys were}} conducted in the south-west Atlantic between 34 ° and 55 °S. The first survey was in the austral spring of 1990 and used both an RMT 8 net which was trawled obliquely down to 200 or 300 m and caught mainly macrozooplankton and a Bongo net which was deployed at the surface and sampled mesozooplankton. The second survey was in the austral spring of 1991 and used a Bongo net which was deployed obliquely down to 50 m and sampled mesozooplankton. This thesis considers the species composition and abundance of these samples and {{represents one of the}} first insights into the mesoscale biogeography of zooplankton communities in the south-west Atlantic. 155 species from 9 taxonomic groups were considered including euphausiids, hyperiid amphipods, chaetognaths, salps, siphonophores, and nektonic/planktonic fish. Multivariate analyses were used to highlight species assemblage distribution patterns and determine strongly correlated environmental variables. In the 1990 RMT 8 samples, species assemblages showed a distribution pattern related to the location of water masses, which was reflected in a combination of water mass and latitude being the most strongly correlated environmental variables. In the 1990 Bongo samples, a combination of seasurface temperature and latitude were most strongly correlated environmental variables and different species assemblages showed a pattern of being located in exclusive temperature ranges. The two sample sets did exhibit some common distribution patterns especially in the warm, sub-tropical waters to the north and the Falkland Shelf to the south. However, there were fundamental differences in the mid-latitudes regions, possibly reflecting the reduced ability of larvae to counteract expatriating forces when compared with adults. Further comparisons made between the 1990 and 1991 Bongo sample sets highlighted some of the <b>causal</b> factors behind <b>distribution</b> patterns. For instance, the precise definition of the boundary between sub-tropical and sub-Antarctic assemblages by the 17. 3 °C isotherm despite the multitude of expatriating phenomena suggested that many organisms were at the edge of their physiological limits in this region. In polar waters, distribution patterns were consistent but temperatures variable suggesting that advection rather than temperature tolerance was more influential. Further data from Montu (1977) and the Discovery Investigations was examined to add a seasonal dimension to the above patterns as well as providing an insight into the importance of population ecology on community distribution. Studies were concentrated on euphausiid species from which it was apparent that size structure and species dominance changed considerably with season. Estimates of the productivity of these species showed that weight-specific rates were comparable with more sub-tropical regions despite biomass levels being proportionally low. The use of satellite thermal images for predicting faunal distribution patterns was assessed with respect to future biogeographic analysis of this region. Images were a good predictor at the sub-tropical boundary but a poor predictor in other regions highlighting the fact that in situ net sampling methods still appear to be the most effective and reliable investigative tools for biogeographic analysis...|$|R
40|$|This study {{presents}} a detailed investigation into size, density and community structure of temperate marine reef {{fish in the}} medium-sized Goukamma Marine Protected Area (Goukamma MPA) and adjacent fishing grounds on the south coast of South Africa. The oceanographic conditions, the spatial distribution of the benthic community and the prevailing fishing effort are also described. Life history traits and per-recruit (PR) models for the principle target species, roman (Crysoblephus laticeps) are compared between the protected and exploited area. From the study results, various strategies are proposed {{for the use of}} MPAs in the conservation and management of linefish species along South Africa’s south coast. The distribution and topography of reefs in the protected and exploited sections of the study area were found to be comparable. Atmospheric pressure ranged from 992 to 1, 032 mb, being significantly lower in summer. Wind speeds ranged from 0. 7 to 71. 3 km/h. Water temperatures ranged between 9. 0 and 22. 2 ºC and turbidity between 0. 3 and 45. 8 NTU. Water temperature and clarity were uniformly low in winter. In summer the water was generally warm, clear and stratified, with a thermocline at around 20 m, although intermittent upwelling events caused water temperature to decrease and clarity to deteriorate. Current speeds ranged between 0. 11 and 2. 59 km/h and were significantly higher in spring and autumn. Easterly currents prevailed in spring, summer and autumn and westerly and southerly currents in winter. Hake (Merluccius capensis), various resident reef fish and kob (Argyrosomus japonicus) were most frequently targeted by the local linefishery. A significant amount of illegal fishing was found to occur in the protected area. Fishing effort was found to be highest around the border of the MPA (2. 7 boats/km²) and lowest in the core of the MPA (0. 2 boats/km²). If law enforcement remains poor {{it may be necessary to}} adapt the management strategy to extend the reserve, thereby mitigating against illegal fishing and ensuring a core area of no exploitation. Various other alternatives were investigated and it was demonstrated that the amount of fish caught of legal size could be increased by about 23 % and post-release mortality of undersized fish reduced by 50 % through the introduction of a suit of restrictive measures. Randomly stratified underwater visual census (UVC) and controlled fishing were used to investigate the ichthyofauna and benthic community at protected and exploited sites in the study area. Resulting density and size data from 273 fishing sites and 177 point counts were analyzed using generalized linear models (GLMs). Fish communities were found to vary significantly, depending on the level of exploitation. Roman, the principle reef fish species targeted by the fishery had significantly higher densities within the protected parts of the study area (CPUE: 4. 3 fish/anglerhour; UVC: 2. 2 fish/point-count) as compared to the exploited part (CPUE: 3. 4 fish/anglerhour; UVC: 1. 8 fish/point-count), correlating strongly with the observed fishing effort. Also mean sizes were significantly higher in the protected area (299 mm from fishing survey and 233 mm from diving estimates) as compared to the exploited section (283 mm from fishing survey and 198 mm from diving estimates). Although other fish species also had significantly higher mean sizes at protected sites in most cases their densities were significantly lower. This suggests a top-down control of the fish community by the dominant predator (roman). The results of the UVC showed the diversity of the ichthyofauna to be significantly higher inside the protected area. Interestingly this did not apply to the results of the controlled fishing experiment where the diversity of fish in the catch was lower in the protected area - a result that may be explained by the selectivity of fishing for the most aggressive species – and a reminder of the limitations of controlled fishing experiments. Possibly the most important finding of the study revolved around the benthic community. These were significantly different at exploited and protected sites, with algae and crinoids more abundant at exploited sites. Crinoids are the principle food of roman and were low in abundance where roman abundances were high, suggesting that the dominant top predator reduced crinoids. Furthermore, it substantiates the correlation of roman abundance with fishing effort, since habitat preferences can be ruled out by the observed <b>causal</b> predator-prey <b>distribution</b> pattern. Low algae abundances at protected sites correlated with high strepie (Sarpa salpa) frequencies within the fish communities encountered there. Strepie, a shoaling and abundant benthic grazer, does not compete for food with roman, suggesting a high potential for coexistence of the two species. As expected, and found by other studies, life history traits of roman differed between protected and exploited sample-sites. With a significantly lower age-at-maturity and age-atsex- change, the exploited population showed a typical response to fishing effort. The sex ratio of this protogynous hermaphrodite was found to be sustained at healthy levels by phenotypic plasticity. However, one important additional factor was highlighted by the study; the average condition factor of the protected population was significantly lower (0. 0283 g/cm³) compared to the exploited population (0. 0295 g/cm³). This was probably due to the higher intra-specific competition for lower food abundance in the protected area. Interestingly the diving and fishing survey methods yielded similar mortality results for roman. Total mortality rate estimates derived from length frequency analysis from the diving and fishing survey were not different (0. 32 and 0. 29 y⁻¹, respectively) as were natural mortality rate estimates (0. 24 and 0. 19 y⁻¹, respectively). Natural mortality rate (M) estimates indicated by Pauly’s and Hoenig’s relationship were similar (0. 25 and 0. 23 y⁻¹, respectively). Detailed yield-per-recruit (Y/R) and spawner biomass-per-recruit (SB/R) analyses were presented for different levels of M, varying age-at-recruitment (tR) and fishing mortality (F). Current tR (7. 60 y) and F (0. 16 and 0. 25 y⁻¹, from the diving and fishing dataset, respectively) suggests an optimal exploitation of the population in the exploited part of the study area. However, a separate SB/R analysis of the male part of the population showed their vulnerability to over-exploitation, even at reduced age-at-sex-change from fishing. There therefore remains a high risk of recruitment failure for the roman population. Of course MPAs can be used to measure stock status directly if the influence of factors such as cachability, habitat and sampling method on CPUE assessments can be limited or reduced. The experimental design in this study allowed for contemporary CPUE comparisons across the border of the Goukamma MPA. Results were similar to those obtained by the SB/R analyses. CPUE extrapolations therefore, using small MPAs, can provide reliable and consistent estimates, and offer a practical alternative to conventional assessment strategies. This study has highlighted the importance of ensuring a well structured and comprehensive survey design when undertaking a comparison of protected and exploited marine areas. The results provide a comprehensive framework for future management of the Goukamma MPA and other protected areas along the temperate coastline of South Africa...|$|R

