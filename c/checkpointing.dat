1770|10000|Public
500|$|As a {{computer}} system grows in complexity, the {{mean time between failures}} usually decreases. Application <b>checkpointing</b> is a technique whereby the computer system takes a [...] "snapshot" [...] of the application—a record of all current resource allocations and variable states, akin to a core dump—; this information can be used to restore the program if the computer should fail. Application <b>checkpointing</b> means that the program has to restart from only its last checkpoint rather than the beginning. While <b>checkpointing</b> provides benefits in a variety of situations, it is especially useful in highly parallel systems with a large number of processors used in high performance computing.|$|E
500|$|Rain World {{punishing}} gameplay frustrated reviewers, {{who often}} descended into apathy. Considering the random enemy spawns, one-hit kills, infrequent game saves, frequent repetition, crushing rain, some inexplicable enemy movements, and sometimes clumsy controls, IGN wrote {{that any of}} the game's challenging elements taken alone would be [...] "tough but fair", but when considered together, [...] "the odds are stacked so high against the player that it risks toppling the entire structure of the game". Reviewers were bored by the repeated navigation of rooms with random enemies after each death, which tempered their strong urge to explore. Polygon reviewer was miserable following the loss of her multi-hour progression. She wrote about futility as a central tenet of Rain World, and felt that she was not given the proper tools to survive. Reviewers lamented, in particular, how Slugcat's jerky animations and imprecise throwing mechanics led to many unwarranted deaths. Multiple reviewers concluded that while some hardcore players might enjoy the tough gameplay, Rain World excluded a large audience with its design choices, as its choice of emergent enemy strategy would feel unfair to most players. Rock, Paper, Shotgun called the game's <b>checkpointing</b> among the worst in modern platformers, and its challenge, unlike the similarly punishing Dark Souls, without purpose. Rain World karmic gates, which require players to have a positive hibernate to death ratio, were arbitrary goals [...] "disrespectful" [...] of the player's time, according to GameSpot. Making players trudge through an area a dozen times, IGN argued, is [...] "antithetical" [...] in a game in which exploration itself is the reward. PC Gamer reviewer, with time, began to see Rain World cumbersome controls less as [...] "bad design" [...] than as [...] "thematically appropriate", given the game's intent to disempower the player.|$|E
2500|$|The slot-and-state syntax in MCell {{can also}} be used to model multimeric {{proteins}} or macromolecular complexes. When used in this way, a slot is a placeholder for a subunit or a molecular component of a complex, and the state of the slot will indicate whether a specific protein component is absent or present in the complex. A way to think about this is that MCell macromolecules can have several dimensions: A [...] "state dimension" [...] and one or more [...] "spatial dimensions". The [...] "state dimension" [...] is used to describe the multiple possible states making up a multi-state protein, while the spatial dimension(s) describe topological relationships between neighboring subunits or members of a macromolecular complex. One drawback of this method for representing protein complexes, compared to Meredys, is that MCell does not allow for the diffusion of complexes, and hence, of multi-state molecules. This can in some cases be circumvented by adjusting the diffusion constants of ligands that interact with the complex, by using <b>checkpointing</b> functions or by combining simulations at different levels.|$|E
40|$|<b>Checkpoint</b> and Recovery {{facility}} {{saves the}} process state to stable storage periodically so {{that after a}} failure, user program can be restored {{to the state of}} its most recent <b>checkpoint.</b> <b>Checkpoint</b> and Recovery facility is especially important for long-running processes, because it prevents the loss of intermediate results generated by long-running processes due to a failure. In this paper we present Kckpt, a <b>Checkpoint</b> and Recovery facility on UnixWare Kernel, and compares Kckpt with Libckpt, a user-level <b>checkpoint</b> library. Using Kckpt, UnixWare can provide totally user-transparent <b>checkpoint</b> as well as user-directed <b>checkpoint.</b> In totally user-transparent <b>checkpoint,</b> no modification on source code is needed to take a <b>checkpoint.</b> <b>Checkpoint</b> overheads of Kckpt are significantly reduced compared with the previously developed user-level <b>checkpoint</b> library. Keywords: <b>Checkpoint,</b> Recovery, Totally User-transparent <b>Checkpoint,</b> Forked <b>Checkpoint,</b> UnixWare 1 Introduction <b>Checkpoint</b> and Reco [...] ...|$|R
25|$|There {{are several}} <b>checkpoints</b> {{to ensure that}} damaged or {{incomplete}} DNA is not passed on to daughter cells. Three main <b>checkpoints</b> exist: the G1/S <b>checkpoint,</b> the G2/M <b>checkpoint</b> and the metaphase (mitotic) <b>checkpoint.</b>|$|R
2500|$|Immune <b>checkpoints</b> affect {{immune system}} functioning. Immune <b>checkpoints</b> can be stimulatory or inhibitory. Tumors can use these <b>checkpoints</b> to protect {{themselves}} from immune system attacks. <b>Checkpoint</b> therapy can block inhibitory <b>checkpoints,</b> restoring immune system function.|$|R
50|$|Some SSI systems allow <b>checkpointing</b> {{of running}} processes, {{allowing}} their current {{state to be}} saved and reloaded at a later date.Checkpointing {{can be seen as}} related to migration, as migrating a process from one node to another can be implemented by first <b>checkpointing</b> the process, then restarting it on another node. Alternatively <b>checkpointing</b> can be considered as migration to disk.|$|E
50|$|There are {{two main}} {{approaches}} for <b>checkpointing</b> in such systems: coordinated <b>checkpointing</b> and uncoordinated <b>checkpointing.</b> In the coordinated <b>checkpointing</b> approach, processes must ensure that their checkpoints are consistent. This is usually achieved by some kind of two-phase commit protocol algorithm. In uncoordinated <b>checkpointing,</b> each process checkpoints its own state independently. It must be stressed that simply forcing processes to checkpoint their state at fixed time intervals {{is not sufficient to}} ensure global consistency. The need for establishing a consistent state (i.e., no missing messages or duplicated messages) may force other processes to roll back to their checkpoints, which in turn may cause other processes to roll back to even earlier checkpoints, which in the most extreme case may mean that the only consistent state found is the initial state (the so-called domino effect).|$|E
50|$|Apache Flink {{includes}} a lightweight fault tolerance mechanism based on distributed checkpoints. A checkpoint is an automatic, asynchronous {{snapshot of the}} state of an application and the position in a source stream. In the case of a failure, a Flink program with <b>checkpointing</b> enabled will, upon recovery, resume processing from the last completed checkpoint, ensuring that Flink maintains exactly-once state semantics within an application. The <b>checkpointing</b> mechanism exposes hooks for application code to include external systems into the <b>checkpointing</b> mechanism as well (like opening and committing transactions with a database system).|$|E
50|$|The Helmstedt-Marienborn <b>checkpoint</b> was one {{of three}} <b>checkpoints</b> used by the Western Allies. Its western side (in the former British zone) was labeled <b>Checkpoint</b> Alpha after the first letter of the NATO phonetic alphabet. The Allied side of the <b>checkpoint</b> for entry into West Berlin was named <b>Checkpoint</b> Bravo, while <b>Checkpoint</b> Charlie was the Allied <b>checkpoint</b> for entry into (and exit from) East Berlin.|$|R
50|$|There {{are three}} <b>checkpoints</b> {{in the cell}} cycle: the G1/S <b>Checkpoint</b> or the Start <b>checkpoint</b> in yeast; the G2/M checkpoint; and the spindle <b>checkpoint.</b>|$|R
50|$|To ensure proper cell division, {{the cell}} cycle {{utilizes}} numerous <b>checkpoints</b> to monitor cell progression and halt the cycle when processes go awry. These <b>checkpoints</b> include four DNA damage <b>checkpoints,</b> one unreplicated DNA <b>checkpoint</b> {{at the end}} of G2, one spindle assembly <b>checkpoint</b> in mitosis, and a chromosome segregation <b>checkpoint</b> during mitosis.|$|R
5000|$|Control {{freezing}} {{groups of}} processes, their <b>checkpointing</b> and restarting ...|$|E
50|$|The {{principal}} hardware cost is a {{means of}} <b>checkpointing</b> the register file state and preventing pre-processed stores from modifying memory. This <b>checkpointing</b> can be accomplished using very little hardware since all results computed during runahead are discarded after the cache miss has been serviced, at which time normal execution resumes using the checkpointed register file state.|$|E
5000|$|As a {{computer}} system grows in complexity, the {{mean time between failures}} usually decreases. Application <b>checkpointing</b> is a technique whereby the computer system takes a [...] "snapshot" [...] of the application—a record of all current resource allocations and variable states, akin to a core dump—; this information can be used to restore the program if the computer should fail. Application <b>checkpointing</b> means that the program has to restart from only its last checkpoint rather than the beginning. While <b>checkpointing</b> provides benefits in a variety of situations, it is especially useful in highly parallel systems with a large number of processors used in high performance computing.|$|E
40|$|Consistent global <b>checkpoints</b> {{have many}} uses in {{distributed}} computations. A central question in applications that use consistent global <b>checkpoints</b> {{is to determine}} whether a consistent global <b>checkpoint</b> that includes a given set of local <b>checkpoints</b> can exist. Netzer and Xu [16] presented the necessary and sufficient conditions under which such a consistent global <b>checkpoint</b> can exist, but they did not explore what <b>checkpoints</b> could be constructed. In this paper we prove exactly which local <b>checkpoints</b> can be used for constructing such consistent global <b>checkpoints.</b> We illustrate the use of our results with a simple and elegant algorithm to enumerate all such consistent global <b>checkpoints...</b>|$|R
40|$|Abstract—The {{increasing}} {{size and}} complexity of high performance computing (HPC) systems have lead to major concerns over fault frequencies and the mechanisms necessary to tolerate these faults. Previous {{studies have shown that}} state-of-the-field checkpoint/restart mechanisms will not scale sufficiently for future generation systems. Therefore, optimizations that reduce <b>checkpoint</b> overheads are necessary to keep checkpoint/restart mechanisms effective. In this work, we demonstrate that <b>checkpoint</b> data compression is a feasible mechanism for reducing <b>checkpoint</b> commit latency and storage overheads. Leveraging a simple model for <b>checkpoint</b> compression viability, we show: (1) <b>checkpoint</b> data compression is feasible for many types of scientific applications expected to run on extreme scale systems; (2) <b>checkpoint</b> compression viability scales with <b>checkpoint</b> size; (3) user-level versus system-level <b>checkpoints</b> bears little impact on <b>checkpoint</b> compression viability; and (4) <b>checkpoint</b> compression viability scales with application process count. Lastly, we describe the impact <b>checkpoint</b> compression might have on projected extreme scale systems. Keywords-Fault tolerance; <b>Checkpoint</b> Compression; I...|$|R
40|$|Object-based <b>checkpoints</b> are {{consistent}} in the object-based system {{but may be}} inconsistent according to the traditional message-based definition. We present a protocol for taking object-based <b>checkpoints</b> among objects. An object to take a <b>checkpoint</b> in the traditional message-based protocol does not take a <b>checkpoint</b> if the current <b>checkpoint</b> is object-based consistent with the other objects. The number of <b>checkpoints</b> can be reduced by the object-based protocol...|$|R
5000|$|... guievict - {{a system}} for <b>checkpointing</b> and {{migrating}} the GUI of an X window application ...|$|E
50|$|Application <b>checkpointing</b> {{can be used}} {{to restore}} a given state of the system when a node fails during a long multi-node computation. This is {{essential}} in large clusters, given that as the number of nodes increases, so does the likelihood of node failure under heavy computational loads. <b>Checkpointing</b> can restore the system to a stable state so that processing can resume without having to recompute results.|$|E
5000|$|Checkpoint: The {{purpose of}} <b>checkpointing</b> {{is to provide}} a {{snapshot}} of the data within the database. A checkpoint, in general, is any identifier or other reference that identifies the state of the database at a point in time. Modifications to database pages are performed in memory and are not necessarily written to disk after every update. Therefore, periodically, the database system must perform a checkpoint to write these updates which are held in-memory to the storage disk. Writing these updates to storage disk creates a point in time in which the database system can apply changes contained in a transaction log during recovery after an unexpected shut down or crash of the database system. If a checkpoint is interrupted and a recovery is required, then the database system must start recovery from a previous successful checkpoint. <b>Checkpointing</b> can be either transaction-consistent or non-transaction-consistent (called also fuzzy <b>checkpointing).</b> Transaction-consistent <b>checkpointing</b> produces a persistent database image that is sufficient to recover the database to the state that was externally perceived at the moment of starting the <b>checkpointing.</b> A non-transaction-consistent <b>checkpointing</b> results in a persistent database image that is insufficient to perform a recovery of the database state. To perform the database recovery, additional information is needed, typically contained in transaction logs. Transaction consistent <b>checkpointing</b> refers to a consistent database, which doesn't necessarily include all the latest committed transactions, but all modifications made by transactions, that were committed at the time checkpoint creation was started, are fully present. A non-consistent transaction refers to a checkpoint which is not necessarily a consistent database, and can't be recovered to one without all log records generated for open transactions included in the checkpoint. Depending on the type of database management system implemented a checkpoint may incorporate indexes or storage pages (user data), indexes and storage pages. If no indexes are incorporated into the checkpoint, indexes must be created when the database is restored from the checkpoint image.|$|E
40|$|Abstract — For full <b>checkpoint</b> on a {{large-scale}} HPC system, huge memory contexts must potentially be transferred through {{the network and}} saved in a reliable storage. As such, the time taken to <b>checkpoint</b> becomes a critical issue which directly impacts the total execution time. Therefore, incremental <b>checkpoint</b> as a less intrusive method to reduce the waste time has been gaining significant attentions in the HPC community. In this paper, we built a model that aims to reduce full <b>checkpoint</b> overhead by performing a set of incremental <b>checkpoints</b> between two consecutive full <b>checkpoints.</b> Moreover, a method to find {{the number of those}} incremental <b>checkpoints</b> is given. Furthermore, most of the comparison results between the incremental <b>checkpoint</b> model and the full <b>checkpoint</b> model [19] on the same failure data set show that the total waste time in the incremental <b>checkpoint</b> model is significantly smaller than the waste time in the full <b>checkpoint</b> model...|$|R
50|$|Drugs or drug {{candidates}} that inhibit/block the inhibitory <b>checkpoint</b> molecules (above) are confusingly sometimes known as immune <b>checkpoint</b> inhibitors; {{this idea is}} often referred to as immune <b>checkpoint</b> blockade, or simply <b>checkpoint</b> blockade. <b>Checkpoint</b> inhibitor drugs have seen growth in pharmaceutical research in cancer by companies including Merck and AstraZeneca.|$|R
50|$|Expedition Impossible is run in ten stages, each {{of which}} has a series of <b>checkpoints.</b> At each <b>checkpoint,</b> teams receive {{instructions}} on how to reach the next <b>checkpoint</b> and at some <b>checkpoints</b> they face challenges that must be completed before heading to the next <b>checkpoint.</b> The last team in each stage to reach the final <b>checkpoint</b> is eliminated. If any member of a team quits, the team is eliminated.|$|R
50|$|<b>Checkpointing</b> schemes are {{scientific}} computing algorithms uses {{in solving}} time dependent adjoint equation, {{as well as}} reverse mode automatic differentiation.|$|E
50|$|Since all subdivisions of {{the series}} can be {{computed}} independently of each other, binary splitting lends well to parallelization and <b>checkpointing.</b>|$|E
50|$|This allows {{establishing}} a lower bound on what other hosts know, and {{is useful in}} applications such as <b>checkpointing</b> and garbage collection.|$|E
50|$|Banteay Meanchey {{has one of}} Cambodia's busiest <b>checkpoints,</b> Poipet International Border <b>Checkpoint,</b> {{for both}} people and goods. The <b>checkpoint</b> oversees {{approximately}} 2,000 tourists (50,000 tourists or 14% of nation's tourists annually in 2015) and 300 trucks carrying goods every day. In response to the increase of trade between Cambodia and Thailand, a new border <b>checkpoint,</b> Stueng Bot which is only 7 km from Poipet <b>Checkpoint,</b> is being constructed and slated {{to be completed by}} 2018. The new <b>checkpoint</b> will focus on trade while leaving Poipet <b>Checkpoint</b> for tourists.|$|R
40|$|Corresponding author, E-mail: sdbao 26 @yahoo. com[中文摘要] 细胞周期检控点是维持细胞基因组稳定性的一个重要机制,主要包括DNA损伤检控点、DNA复制检控点和纺锤体组装检控点。其中DNA损伤检控点能检测细胞在生命活动过程中出现的DNA损伤并引发细胞周期阻滞,为修复损伤提供足够的时间,以保证细胞遗传的稳定性。有关DNA损伤检控点的研究近年来已经取得了突破性进展,现简要介绍近年来在DNA损伤检控点研究中的一些新进展。[英文摘要] Cell cycle <b>checkpoint</b> {{is a vital}} {{mechanism}} to maintain the genomic stability of the cell. It mainly includes DNA damage <b>checkpoint,</b> DNA replication <b>checkpoint</b> and spindle assembly <b>checkpoint.</b> Among these <b>checkpoints,</b> DNA damage <b>checkpoint</b> can detect the DNA damages in the cell and cause cell cycle arrest, which will guarantee proper damage repair and ensure genomic stability. Studies of DNA damage <b>checkpoint</b> have achieved great progress in recent years. This paper will make a brief review about these advances. 国家自然科学基金(No. 30170463 、 30370307);福建省青年科技人才创新项目资金(No. 2003 J 017...|$|R
5000|$|<b>Checkpoint</b> tags: There are touch ibuttons or RFID tags. The <b>checkpoint</b> tags {{replace the}} <b>checkpoints</b> which guards need to patrol.|$|R
5000|$|Programs {{designed}} for calculating [...] may have better performance than general-purpose mathematical software. They typically implement <b>checkpointing</b> and efficient disk swapping to facilitate extremely long-running and memory-expensive computations.|$|E
50|$|In {{distributed}} computing, <b>checkpointing</b> is {{a technique}} that helps tolerate failures that otherwise would force long-running application to restart from the beginning. The most basic way to implement <b>checkpointing,</b> is to stop the application, copy all the required data from the memory to reliable storage (e.g., Parallel file system) and then continue with the execution. In case of failure, when the application restarts, it {{does not need to}} start from scratch. Rather, it will read the latest state ("the checkpoint") from the stable storage and execute from that.|$|E
50|$|The {{session layer}} {{controls}} the dialogues (connections) between computers. It establishes, manages and terminates {{the connections between}} the local and remote application. It provides for full-duplex, and half-duplex or simplex operation, and establishes <b>checkpointing,</b> adjournment, termination, and restart procedures. The OSI model made this layer responsible for graceful close of sessions, which is a property of the Transmission Control Protocol, and also for session <b>checkpointing</b> and recovery, which is not usually used in the Internet Protocol Suite. The session layer is commonly implemented explicitly in application environments that use remote procedure calls.|$|E
40|$|We have {{identified}} an S-phase DNA damage <b>checkpoint</b> in Schizosaccharomyces pombe. This <b>checkpoint</b> {{is dependent on}} Rad 3, the S. pombe homolog of the mammalian ATM/ATR <b>checkpoint</b> proteins, and Cds 1. Cds 1 had previously been believed to be involved only in the replication <b>checkpoint.</b> The requirement of Cds 1 in the DNA damage <b>checkpoint</b> suggests that Cds 1 may be a general target of S-phase <b>checkpoints.</b> Unlike other <b>checkpoints,</b> the S. pombe S-phase DNA damage <b>checkpoint</b> discriminates between different types of damage. UV-irradiation, which causes base modification that can be repaired during G 1 and S-phase, invokes the <b>checkpoint,</b> while gamma-irradiation, which causes double-stranded breaks that cannot be repaired by a haploid cell if induced before replication, does not invoke the <b>checkpoint.</b> Because the same genes are required to respond to UV- and gamma-irradiation during G 2, this discrimination may represent an active suppression of the gamma response during S-phase...|$|R
2500|$|The spindle <b>checkpoint</b> or SAC (for spindle {{assembly}} <b>checkpoint),</b> {{also known as}} mitotic <b>checkpoint,</b> is a cellular mechanism responsible for detection of: ...|$|R
50|$|The name <b>Checkpoint</b> 303 was {{inspired}} by the Bethlehem <b>Checkpoint</b> 300 (one of numerous Israeli <b>checkpoints</b> restricting and controlling passage between the Palestinian self-controlled areas and Israel). A co-founding member of <b>Checkpoint</b> 303 lives and performs field recordings in Bethlehem.|$|R
