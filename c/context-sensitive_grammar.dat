68|111|Public
2500|$|Given a <b>context-sensitive</b> <b>grammar,</b> does it {{describe}} a context-free language? ...|$|E
5000|$|Membership of {{a string}} in a {{language}} defined by an arbitrary <b>context-sensitive</b> <b>grammar,</b> or by an arbitrary deterministic <b>context-sensitive</b> <b>grammar,</b> is a PSPACE-complete problem.|$|E
5000|$|... #Subtitle level 2: Transforming into <b>context-sensitive</b> <b>grammar</b> ...|$|E
50|$|The LuZc parser is {{a working}} {{example of a}} program which can parse <b>Context-sensitive</b> <b>grammars.</b>|$|R
5000|$|According to the {{original}} characterization by Joshi, a class of mildly <b>context-sensitive</b> <b>grammars</b> should have the following properties: ...|$|R
40|$|A {{direction}} independent {{variant of}} the standard normal form for <b>context-sensitive</b> <b>grammars</b> is given: the context-free productions are of the form A → a or A → BC and the context-sensitive productions are of the form AB → AC or BA → CA, where AB → AC is a production {{if and only if}} BA → CA is a production. The equivalence of these <b>grammars</b> with the <b>context-sensitive</b> <b>grammars</b> is proved...|$|R
50|$|Some {{definitions}} of a <b>context-sensitive</b> <b>grammar</b> only require that for any production {{rule of the}} form u → v, the length of u shall be {{less than or equal}} to the length of v. This seemingly weaker requirement is in fact weakly equivalent, see Noncontracting grammar#Transforming into <b>context-sensitive</b> <b>grammar.</b>|$|E
50|$|A <b>context-sensitive</b> <b>grammar</b> for {{the same}} {{language}} is shown below.|$|E
5000|$|Given a <b>context-sensitive</b> <b>grammar,</b> does it {{describe}} a context-free language? ...|$|E
40|$|This thesis {{deals with}} the topic of {{unrestricted}} grammars, normal forms, and their applications. It focuses on <b>context-sensitive</b> <b>grammars</b> as their special cases. Based on {{the analysis of the}} set, an algorithm was designed using the principles of the Cocke-Younger-Kasami algorithm to make a decision of whether an input string is a sentence of a context-sensitivegrammar. The final application, which implements this algorithm, works with <b>context-sensitive</b> <b>grammars</b> in the Penttonen normal form...|$|R
50|$|In {{addition}} to these, {{it is understood}} that every class of mildly <b>context-sensitive</b> <b>grammars</b> {{should be able to}} generate all context-free languages.|$|R
25|$|Another {{extension}} is {{to allow}} additional terminal symbols to appear at the left-hand side of rules, constraining their application. This produces the formalism of <b>context-sensitive</b> <b>grammars.</b>|$|R
5000|$|All {{languages}} in [...] {{can be produced}} by a <b>context-sensitive</b> <b>grammar.</b>|$|E
50|$|The {{emptiness}} {{problem for}} context-sensitive grammars (given a <b>context-sensitive</b> <b>grammar</b> G, is L(G)=∅ ?) is undecidable.|$|E
50|$|As {{the name}} suggests, for every <b>context-sensitive</b> <b>grammar,</b> {{there exists a}} weakly {{equivalent}} one-sided/Penttonen normal form.|$|E
50|$|Tree-adjoining grammars {{are more}} {{powerful}} (in terms of weak generative capacity) than context-free grammars, but less powerful than linear context-free rewriting systems, indexed or <b>context-sensitive</b> <b>grammars.</b>|$|R
50|$|Another {{extension}} is {{to allow}} additional terminal symbols to appear at the left hand side of rules, constraining their application. This produces the formalism of <b>context-sensitive</b> <b>grammars.</b>|$|R
5000|$|By 1985, several {{researchers}} in descriptive and mathematical linguistics had provided evidence against {{the hypothesis that}} the syntactic structure of natural language can be adequately described by context-free grammars.At the same time, the step to the next level of the Chomsky hierarchy, to <b>context-sensitive</b> <b>grammars,</b> appeared both unnecessary and undesirable.In an attempt to pinpoint the exact formal power required for the adequate description of natural language syntax, Aravind Joshi characterized [...] "grammars (and associated languages) that are only slightly more powerful than context-free grammars (context-free languages)".He called these <b>grammars</b> mildly <b>context-sensitive</b> <b>grammars</b> and the associated languages mildly context-sensitive languages.|$|R
50|$|The {{decision}} problem that asks whether a certain string s {{belongs to the}} language of a given <b>context-sensitive</b> <b>grammar</b> G, is PSPACE-complete. Morever, there are context-sensitive grammars whose languages are PSPACE-complete. In other words, there is a <b>context-sensitive</b> <b>grammar</b> G such that deciding whether a certain string s belongs {{to the language of}} G is PSPACE-complete (so G is fixed and only s is part of the input of the problem).|$|E
5000|$|Every noncontracting grammar (N, Σ, P, S) can be {{transformed}} into a <b>context-sensitive</b> <b>grammar</b> (N’, Σ, P’, S) as follows: ...|$|E
5000|$|Computational {{complexity}} of natural language, largely modeled on automata theory, with {{the application of}} <b>context-sensitive</b> <b>grammar</b> and linearly bounded Turing machines.|$|E
25|$|Some {{questions}} that are undecidable for wider classes of grammars become decidable for context-free grammars; e.g. the emptiness problem (whether the grammar generates any terminal strings at all), is undecidable for <b>context-sensitive</b> <b>grammars,</b> but decidable for context-free grammars.|$|R
5000|$|NooJ {{can often}} apply grammars to texts in linear time: for instance, most NooJ Context-Free Grammars {{can often be}} derecursived. NooJ <b>Context-Sensitive</b> <b>Grammars</b> are made of two parts: one part is a Context-Free (or even a Finite-State Grammar) that is applied to texts very efficiently, the second {{consists}} {{in a set of}} constraints applied to matching sequences, each one performed in constant time.NooJ unrestricted <b>grammars</b> are <b>context-sensitive</b> <b>grammars</b> that can contain variables and can modify the text input. They are typically used to perform transformational analysis & generation (see Zellig Harris), but several teams of linguists have shown that, when used in conjunction with multilingual lexicons, they can be used to perform Machine Translation ...|$|R
40|$|This paper {{introduces}} weakly growing <b>context-sensitive</b> <b>grammars.</b> Such grammars generalize {{the class}} of growing <b>context-sensitive</b> <b>grammars</b> (studied by several authors), in that these grammars have rules that "grow" according to a position valuation. If a position valuation coincides with the initial part of an exponential function, it is called a steady position valuation. All others are called unsteady. The complexity of the language generated by a grammar depends crucially on whether the position valuation is steady or not. More precisely, for every unsteady position valuation, {{the class of}} languages generated by WGCSGs with this valuation coincides with the class CSL of context-sensitive languages. On the other hand, for every steady position valuation, the class of languages generated corresponds {{to a level of}} the hierarchy of exponential time-bounded languages in CSL. We show that the following three conditions are equivalent: [...] The hier [...] ...|$|R
50|$|A <b>context-sensitive</b> <b>grammar</b> for the {{language}} { a2i : i ≥ 1 } is constructed in Example 9.5 (p. 224) of (Hopcroft, Ullman, 1979).|$|E
5000|$|For example, {{the above}} noncontracting grammar for { anbncn | n ≥ 1 } {{leads to the}} {{following}} <b>context-sensitive</b> <b>grammar</b> (with start symbol S) for the same language: ...|$|E
5000|$|In formal {{language}} theory, a growing <b>context-sensitive</b> <b>grammar</b> is a <b>context-sensitive</b> <b>grammar</b> {{in which the}} productions increase {{the length of the}} sentences being generated. These grammars are thus noncontracting and context-sensitive. A growing context-sensitive language is a context-sensitive language generated by these grammars. In these grammars the [...] "start symbol" [...] S does not appear on the right hand side of any production rule and the length of the right hand side of each production exceeds the length of the left side, unless the left side is S.|$|E
5000|$|If {{the rule}} AB → CD is {{eliminated}} from the above, then one obtains context-free languages. The Penttonen normal form (for unrestricted grammars) is a special case where A = C in the first rule above. For <b>context-sensitive</b> <b>grammars,</b> the Penttonen normal form, also called the one-sided normal form (following Penttonen's own terminology) is just: ...|$|R
40|$|We {{investigate}} word {{problems and}} conuence {{problems for the}} following four classes of terminating semi-Thue systems: lengthreducing systems, weight-reducing systems, length-lexicographic systems, and weight-lexicographic systems. For each of these four classes we determine the complexity of several variants of the word problem and confluence problem. Finally we show that the variable membership problem for quasi <b>context-sensitive</b> <b>grammars</b> is EXPSPACE-complete...|$|R
40|$|Growing <b>context-sensitive</b> <b>grammars</b> (GCSG) are investigated. The {{variable}} membership {{problem for}} GCSG {{is shown to}} be NP-complete. This solves a problem posed in [DW 86]. It is also shown that the languages generated by GCSG form an abstract family of languages and several implications are presented. Institut fur Informatik, Universitat Wurzburg, D- 8700 Wurzburg, Germany. y Instytut Informatyki, Uniwersytet Wroc/lawski, 51 - 151 Wroc/law, Poland (permanent address). This {{research was supported by}} the Humboldt Foundation. 1 Introduction It is well known that the class of languages generated by <b>context-sensitive</b> <b>grammars</b> is equal to NSPACE(n) and that, even for fixed grammars, the membership problem can be PSPACE-complete. On the other hand the context-free grammars are known to have, for many applications, too weak derivative power. While many modifications extending context-free grammars have been studied, only a few papers concern some restricted versions of context-sensitive gramm [...] ...|$|R
50|$|In {{computational}} linguistics, {{the term}} mildly <b>context-sensitive</b> <b>grammar</b> formalisms refers to several grammar formalisms {{that have been}} developed with the ambition to provide adequate descriptions of the syntactic structure of natural language.|$|E
50|$|None of {{the rules}} of a noncontracting grammar {{decreases}} the length of the string that is being rewritten. If each rule even properly increases the length, the grammar is called a growing <b>context-sensitive</b> <b>grammar.</b>|$|E
50|$|Every mildly <b>context-sensitive</b> <b>grammar</b> {{formalism}} {{defines a}} class of mildly context-sensitive grammars (the grammars that can be specified in the formalism), and therefore also {{a class of}} mildly context-sensitive languages (the formal languages generated by the grammars).|$|E
50|$|EPDAs {{were first}} {{described}} by K. Vijay-Shanker in his 1988 doctoral thesis. They {{have since been}} applied to more complete descriptions of classes of mildly <b>context-sensitive</b> <b>grammars</b> and have had important roles in refining the Chomsky hierarchy. Various subgrammars, such as the linear indexed grammar, can thus be defined. EPDAs are also beginning {{to play an important}} role in natural language processing.|$|R
40|$|In this paper, {{we define}} Dependency Structure Grammars (DSG), which are {{rewriting}} rule grammars generating sentences {{together with their}} dependency structures, are more expressive than CF-grammars and non-equivalent to mildly <b>context-sensitive</b> <b>grammars.</b> We show that DSG are weakly equivalent to Categorial Dependency Grammars (CDG) recently introduced. In particular, these dependency grammars naturally express long distance dependencies and enjoy good mathematical properties...|$|R
50|$|It {{has been}} shown that nearly all natural {{languages}} may in general be characterized by <b>context-sensitive</b> <b>grammars,</b> but the whole class of CSG's seems to be much bigger than natural languages. Worse yet, since the aforementioned decision problem for CSG's is PSPACE-complete, that makes them totally unworkable for practical use, as a polynomial-time algorithm for a PSPACE-complete problem would imply P=NP.|$|R
