47|2|Public
50|$|ECAD's {{first product}} was Dracula, {{introduced}} in April 1983. It included a design-rule checker, an electrical rule checker, and a layout-versus-schematic <b>consistency</b> <b>checker</b> among other programs. This {{was followed by}} SYMBAD, an IC layout product suite.|$|E
50|$|The Software Cost Reduction Toolkit is {{an example}} of this. The toolkit is a suite of {{utilities}} including a specification editor to create a requirements specification, a dependency graph browser to display variable dependencies, a <b>consistency</b> <b>checker</b> to catch missing cases in well-formed formulas in the specification, a model checker and a theorem prover to check program properties against the specification, and an invariant generator that automatically constructs invariants based on the requirements.|$|E
50|$|Active Directory synchronizes changes using multi-master {{replication}}. Replication {{by default}} is 'pull' rather than 'push', meaning that replicas pull changes from the server where {{the change was}} effected. The Knowledge <b>Consistency</b> <b>Checker</b> (KCC) creates a replication topology of site links using the defined sites to manage traffic. Intrasite replication is frequent and automatic {{as a result of}} change notification, which triggers peers to begin a pull replication cycle. Intersite replication intervals are typically less frequent and do not use change notification by default, although this is configurable and can be made identical to intrasite replication.|$|E
40|$|Abstract. Modern {{concurrent}} programming languages like Java and C # have {{a programming language}} level memory model; it captures the set of all allowed behaviors of programs on any implementation platform — uni- or multi-processor. Such a memory model is typically weaker than Sequential Consistency and allows reordering of operations within a program thread. Therefore, programs verified correct by assuming Sequential Consistency (that is, each thread proceeds in program order) may not behave correctly on certain platforms! The {{solution to this problem}} is to develop program checkers which are memory model sensitive. In this paper, we develop such an invariant checker for the programming language C#. Our checker identifies program states which are reached only because the C # memory model is more relaxed than Sequential <b>Consistency.</b> Furthermore, our <b>checker</b> identifies (a) operation reorderings which cause such undesirable states to be reached, and (b) simple program modifications — by inserting memory barrier operations — which prevent such undesirable reorderings. ...|$|R
40|$|In {{developing}} an information system, software specification {{is one of}} the common activities to any system development methodologies. A software model is among the ways to specify software functionalities and constraints. It is constructed as a way to understand the software prior to actually building or modifying it, and it can help in reducing defect density in the software design. In an object oriented based development, Unified Modeling Language (UML) is a famous language used for visualising, capturing and documenting software requirements. Currently, UML has a set of fourteen (14) diagrams that permits modellers to describe different aspects of a system. Each diagram comprises of graphical notations that adhered to UML elements. These situations rendered UML model vulnerable to consistency problems where two or more overlapping elements of different diagrams are not jointly satisfiable. Even though the research in consistency between UML diagrams is rapidly increased, there is still lack of researches of consistency based on use case in use case diagram. UML consistency management is becoming a difficult task because UML itself lacks of formal syntax and semantics and current approaches using simplified version of UML make their approaches hard to implement in CASE (Computer-aided Software Engineering) tool environment. Due to those problems, this research introduces formal syntactical rules to UML elements of four (4) most popular UML diagrams used by UML practitioners: use case diagram, activity diagram, sequence diagram and class diagram. Referring to the formal syntactical rules for UML elements, formal horizontal consistency rules based on use case are also specified. The formal specifications introduced in this research are using logical approach. Based on the syntactical and horizontal <b>consistency</b> rules, UML <b>Checker</b> is implemented in the CASE tool environment. Then, the UML Checker is validated by using UML model of Lecture Assessment System (LAS) as a case study. It shows that the UML Checker can detect inconsistencies between four (4) UML diagrams in the UML model and guide software modeller to correct them...|$|R
40|$|Institutt for datateknikk og informasjonsvitenskapUML {{consistency}} checking In large UML documents inconsistencies can occur {{more or less}} frequently, something that can prove to be costly in software development projects. In light of this we are looking into the need for, the specifications of and implementation of a <b>consistency</b> <b>checker</b> for UML diagrams/documents. In a summer job project {{in the summer of}} 2001 we have already made a simple <b>consistency</b> <b>checker,</b> and we are looking to expand on that, possibly with a rule based <b>consistency</b> <b>checker</b> in this project. i UML {{consistency checking}} Preface This paper is the result of our project about “UML consistency checking”, a part of the course SIF 8094 taken in the fall of 2001 at the department of computer an...|$|E
30|$|The verifiable {{symptoms}} {{related to}} network state mismatching are sent as checkpoints {{to the external}} <b>Consistency</b> <b>Checker,</b> in which several off-the-shelf tools (e.g., VeriFlow [19], Anteater [9]) are used to verify the related symptoms. Actively (i.e., from <b>Consistency</b> <b>Checker)</b> and passively (i.e., from system logs) observed symptoms are provided to the Fault Reasoning & Verification module to identify the most likely root causes, which are further verified later through some testing tools (e.g., ATPG [8]).|$|E
40|$|This package {{accompanies the}} paper "A <b>consistency</b> <b>checker</b> for memory {{subsystem}} traces" {{to appear at}} FMCAD 2016. It includes a snapshot of our memory <b>consistency</b> <b>checker</b> (axe) taken in July 2016 along with the traces used to test and evaluate it. Please note that {{the latest version of}} axe should always be obtained from [URL] [EP/K 008528 / 1 ("REMS") ], DARPA/AFRL [FA 8750 - 10 -C- 0237 ("CTSRD") and FA 8750 - 11 -C- 0249 ("MRC 2 ") ...|$|E
40|$|A help {{development}} tool {{is a system}} to produce applications specific help systems. It consists of the folllowing three components: input language, display tool, <b>consistency</b> <b>checker.</b> The input language provides commands to introduce a hypertext oriented syntactical structure into the help text under development. The display tool uses commands of the language to show the help text according to the hypertext concept in a special window following the OST/Motif guide lines. The <b>consistency</b> <b>checker</b> guarantees that {{the author of a}} help system writes the selected help text and the proper commands in the right way to ensure correct behaviour of the whole system...|$|E
40|$|This paper {{demonstrates}} that machine {{learning is a}} suitable approach for rapid parser development. From 1000 newly treebanked Korean sentences we generate a deterministic shift-reduce parser. The quality of the treebank, particularly crucial given its small size, {{is supported by a}} <b>consistency</b> <b>checker.</b> ...|$|E
40|$|Although formal {{methods for}} {{developing}} computer sys-tems {{have been available}} {{for more than a}} decade, few have had significant impact in practice. A major barrier to their use is that software developers find formal methods diffi-cult to understand and apply. One exception is a formal method called SCR for specifying computer system require-ments which, due to its easy to use tabular notation and its demonstrated scalability, has already achieved some suc-cess in industry. Recently, a set of software tools, including a specification editor, a <b>consistency</b> <b>checker,</b> a simulator, and a verifier, has been developed to support the SCR method [9, 11, 5]. This paper describes recent enhancements to the SCR tools: a new dependency graph browser which displays the dependencies among the variables in the specification, an improved <b>consistency</b> <b>checker</b> which produces detailed feedback about detected errors, and an assertion checker which checks application properties during simulation. To illustrate the tool enhancements, a simple automobile cruise control system is presented and analyzed. 1...|$|E
40|$|Abstract—The {{complexity}} of variability models {{makes it hard}} for product line engineers to maintain their consistency over time. Engineers need support to detect and resolve inconsistencies. In this paper, we describe our initial results towards tool support for incremental consistency checking on variability models. The main aim of our research is to improve the overall performance and scalability of consistency checking. We report on experiences of integrating an existing incremental <b>consistency</b> <b>checker</b> in the DOPLER product line tool suite...|$|E
40|$|Briefly {{presenting}} a generalization of Allen's interval-based approach to temporal reasoning, {{this paper will}} see point & typed-based structure of time intervals as an intended model of point & interval-based time theory to illustrate a <b>Consistency</b> <b>Checker</b> for Uncertain or Incomplete Temporal System {{which can be used}} to check whether there are circuit(s) among the temporal intervals and whether the temporal intervals are consistent or not, and this paper also succinctly discourses the future work about how to find the best solution of this checker...|$|E
40|$|A set of CASE tools is {{described}} for developing formal requirements speci cations {{expressed in the}} SCR (Software Cost Reduction) tabular notation. The tools include an editor for building the speci cations, a <b>consistency</b> <b>checker</b> for testing the speci cations for consistency with a formal requirements model, a simulator for symbolically executing the speci cations, and a veri er for checking that the speci cations satisfy selected application properties. As background, the SCR method for specifying requirements is reviewed, and a formal requirements model is introduced. Examples are presented to illustrate the tools. ...|$|E
40|$|We {{introduce}} the Casl <b>Consistency</b> <b>Checker</b> (CCC), {{a tool that}} supports consistency proofs in the algebraic specification language Casl. CCC is a faithful implementation of a previously described consistency calculus. Its system architecture combines flexibility with correctness ensured by encapsulation in a type system. CCC offers tactics, tactical combinators, forward and backward proof, {{and a number of}} specialised static checkers, as well as a connection to the Casl proof tool HOL-Casl to discharge proof obligations. We demonstrate the viability of CCC by an extended example taken from the Casl standard library of basic datatypes...|$|E
40|$|AbstractInconsistency {{frequently}} {{exists in}} a rule-based expert system. Detecting the existence of inconsistency in a fuzzy rule-based environment is difficult and may be {{different from that of}} traditional rule-based systems. An affinity measure, which is based on the similarity measure, is introduced to determine the likeness of two fuzzy terms. By using the affinity measure, the techniques for consistency checking in a non-fuzzy environment can be easily applied to a fuzzy environment. A <b>consistency</b> <b>checker</b> (CCFE) is implemented to detect possible inconsistency in a mixed fuzzy and non-fuzzy environment...|$|E
40|$|Abstract. We {{introduce}} the Casl <b>Consistency</b> <b>Checker</b> (CCC), {{a tool that}} supports consistency proofs in the algebraic specification language Casl. CCC is a faithful implementation of a previously described con-sistency calculus. Its system architecture combines flexibility with cor-rectness ensured by encapsulation in a type system. CCC offers tactics, tactical combinators, forward and backward proof, {{and a number of}} spe-cialised static checkers, as well as a connection to the Casl proof tool HOL-Casl to discharge proof obligations. We demonstrate the viability of CCC by an extended example taken from the Casl standard library of basic datatypes. ...|$|E
40|$|Efficient flight {{software}} development from natural language requirements needs {{an effective way}} to test designs earlier in the software design cycle. A method to automatically derive logical safety constraints and the design state space from natural language requirements is described. The constraints can then be checked using a logical <b>consistency</b> <b>checker</b> and also be used in a symbolic model checker to verify the early design of the system. This method was used to verify a hybrid control design for the suit ports on NASA Johnson Space Center's Space Exploration Vehicle against safety requirements...|$|E
40|$|A {{general system}} is {{presented}} in this paper which supports the expression of relative temporal knowledge in process control and management. This system allows knowledge of Allen's temporal relations over time elements, which may be both intervals and points. The objectives and characteristics of two major temporal attributes, i. e. ‘transaction time’ and ‘valid time’, are described. A graphical representation for the temporal network is presented, and inference over the network may be made by means of a <b>consistency</b> <b>checker</b> in terms of the graphical representation. An illustrative example of the system as applied to process control and management is provided...|$|E
40|$|Complete and Absolute {{temporal}} {{knowledge is}} usually not always available for many knowledge based systems, notably {{in the domain of}} Artificial Intelligence. Based on a time theory that takes both points and intervals as primitive, this paper introduces a graphical representation for uncertain and incomplete temporal knowledge, which allows logical expressions of both absolute and relative temporal relations, including both logical conjunctions and disjunctions. The consistency of any given collection of uncertain and incomplete temporal knowledge depends on if there is at one temporal scenario that is temporal consistent, where a <b>consistency</b> <b>checker</b> for temporal scenarios is provided. ...|$|E
40|$|We {{describe}} {{the first full}} implementation of the Comon-Nieuwenhuis method for implicit induction, including a <b>consistency</b> <b>checker,</b> in a novel system where the proof and refutation programs communicate via sockets. This allows the system to attempt to prove and disprove a conjecture at the same time, using parallel theorem proving processes. As well as refuting several non-theorems, this system has accomplished what is, {{to the best of}} our knowledge, the first fully automated proof by implicit induction of the commutativity of gcd. This had been posed as a challenge problem to the technique in the past...|$|E
40|$|The {{notion of}} time plays a vital and {{ubiquitous}} {{role of a}} common universal reference. In knowledge-based systems, temporal information is usually represented {{in terms of a}} collection of statements, together with the corresponding temporal reference. This paper introduces a visualized <b>consistency</b> <b>checker</b> for temporal reference. It allows expression of both absolute and relative temporal knowledge, and provides visual representation of temporal references in terms of directed and partially weighted graphs. Based on the temporal reference of a given scenario, the visualized checker can deliver a verdict to the user as to whether the scenario is temporally consistent or not, and provide the corresponding analysis / diagnosis...|$|E
40|$|Ensuring that {{specifications}} {{are consistent}} {{is an important}} part of specification development and testing. In this paper we introduce the ConsVISor tool for consistency checking of RM-ODP specifications. This tool is a category theory based <b>consistency</b> <b>checker</b> for formal specifications in a variety of languages, including both graphical and non-graphical modeling languages. Because RM-ODP supports multiple viewpoints, it is necessary to have a logical framework that can compose viewpoints and that can detect inconsistencies (feature interactions) among multiple viewpoints. The ConsVISor tool composes viewpoints by using the colimit operation of category theory. ConsVISor checks consistency using a combination of theorem proving and model-based reasoning. Some examples of the use of the tool are given. ...|$|E
40|$|ABSTRACT. Acomputer {{algorithm}} for restriction-site mapping {{consists of}} a generator of partial maps and a <b>consistency</b> <b>checker.</b> This paper examines consistency checking and argues that a method based on separation theory extracts {{the maximum amount of}} information from fragment lengths in digest data. It results in the minimum number of false maps being generated. 1. Introduction. Restriction-site mapping involves locating certain restriction sites on a circular plasmid, on a linear phage or on some other sequence of DNA. The raw data for the problem consist of fragment lengths from one or more digests carried out on the DNA. Deducing the map is a combinatorial problem often performed {{with the aid of a}} computer program [1 − 9]. While there is only one real map, the data ca...|$|E
40|$|Abstract. Software design {{models are}} {{routinely}} adapted to domains, companies, and applications. This requires customizable consistency checkers that allow engineers to dynamically adapt model constraints. To benefit from quick design feedback, such consistency checkers should evaluate {{the consistency of}} such changeable constraints incrementally with design changes. This paper presents such a freely customizable, incremental <b>consistency</b> <b>checker.</b> We demonstrate that constraints can be defined and re-defined at will. And we demonstrate that its performance is instant for many kinds of constraints without manual annotations or restrictions on the constraint language used. Our approach supports both model and meta-model constraints and was evaluated on over 20 software models and 24 types of constraints. It is fully automated and integrated into the IBM Rational Software Modeler tool...|$|E
40|$|A new {{coordination}} {{model for}} computations is presented. It offers increased {{confidence in the}} correctness of imperative programs and considerable simplification of imperative programming and debugging. In this model, programs consist of formal specifications of computations by recursive function definitions and explicit mappings (coordinations) of these specifications to imperative programs. The consistency between coordination and specification is guaranteed by a special mechanism, called the <b>consistency</b> <b>checker,</b> during the program's execution. It automatically detects any inconsistency by comparisons against symbolic names associated with values. The formal specification of Gaussian elimination and two coordinations that implement a sequential and a parallel algorithm are used to present the model. 1 INTRODUCTION Imperative programming is widely used for expressing scientific computations. It {{has the advantage of}} per- Copyright c fl 1998 by the Association for Computing Machinery [...] ...|$|E
40|$|Abstract. DepAnn is an {{interactive}} annotation tool for dependency treebanks, providing both graphical and text-based annotation interfaces. The tool is aimed for semi-automatic creation of treebanks. It aids the manual inspection and correction of automatically created parses, making the annotation process faster and less error-prone. A novel {{feature of the}} tool is that it enables the user to view outputs from several parsers {{as the basis for}} creating the final tree to be saved to the treebank. DepAnn uses TIGER-XML, an XML-based general encoding format for both, representing the parser outputs and saving the annotated treebank. The tool includes an automatic <b>consistency</b> <b>checker</b> for sentence structures. In addition, the tool enables users to build structures manually, add comments on the annotations, modify the tagsets, and mark sentences for further revision. ...|$|E
40|$|A set of CASE tools is {{described}} for developing formal requirements specifications {{expressed in the}} SCR (Software Cost Reduction) tabular notation. The tools include an editor for building the specifications, a <b>consistency</b> <b>checker</b> for testing the specifications for consistency with a formal requirements model, a simulator for symbolically executing the specifications, and a verifier for checking that the specifications satisfy selected application properties. As background, the SCR method for specifying requirements is reviewed, and a formal requirements model is introduced. Examples are presented to illustrate the tools. 1 Introduction High assurance computer systems are computer systems where compelling evidence is required that the system delivers its services {{in a manner that}} satisfies certain critical properties. Examples of high assurance systems include military command and control systems, nuclear power plants, telephone networks, medical systems (e. g., patient monitoring sys [...] ...|$|E
40|$|Abstract. Ensuring that ontologies are {{consistent}} {{is an important}} part of ontology development and testing. This is especially important when autonomous software agents are to use ontologies in their reasoning. Reasoning with inconsistent ontologies may lead to erroneous conclusions. In this paper we introduce the ConsVISor tool for consistency checking of ontologies. This tool is a <b>consistency</b> <b>checker</b> for formal ontologies, including both traditional data modeling languages and the more recent ontology languages. ConsVISor checks consistency by verifying axioms. ConsVISor is part of the UBOT toolkit that uses a variety of techniques such as theorem proving and logic programming. Some examples of the use of these tools are given. 1 Introduction to ConsVISor Formal ontologies are fundamental for the Semantic Web. They are especially important for autonomous software agents for which a shared ontology is necessary for meaningful communication. However, because autonomous softwar...|$|E
40|$|Precision and {{consistency}} are important prerequisites for class models {{to conform to}} their intended domain semantics. Precision {{can be achieved by}} augmenting models with design constraints {{and consistency}} can be achieved by avoiding contradictory constraints. However, there are different views of what constitutes a contradiction for design constraints. Moreover, state-of-the-art analysis approaches for proving constrained models consistent either scale poorly or require the use of interactive theorem proving. In this paper, we present a heuristic approach for efficiently analyzing constraint specifications built from constraint patterns. This analysis is based on precise notions of consistency for constrained class models and exploits the semantic properties of constraint patterns, thereby enabling syntax-based consistency checking in polynomial-time. We introduce a <b>consistency</b> <b>checker</b> implementing these ideas and we report on case studies in applying our approach to analyze industrial-scale models. These studies show that pattern-based constraint development supports the creation o...|$|E
40|$|Automated {{consistency}} checking of UML models becomes necessary as models grow {{in size and}} complexity. Since the UML metamodel does not enforce model consistency, there are no fixed guidelines on how to approach the consistency problem. Current solutions are generally partial. The translation of the metamodel and the user designed model into Description Logics has proved to provide a solution in detecting a large set of inconsistencies. In order to make this solution available to system designers, we have implemented MCC+, a UML model <b>consistency</b> <b>checker,</b> built as a plug-in for Poseidon for UML, and relying on Jena as a reasoning engine. Compared to other approaches, we propose a usable and scalable solution, interoperable with a known modeling tool. We show the application of MCC+ to a real world large example of a meshing tool. The work of Nancy Hitschfeld-Kahler has been supported by project Fondecyt No. 1061227...|$|E
40|$|This paper {{demonstrates}} that machine {{learning is a}} suitable approach for rapid parser development. From 1000 newly treebanked Korean sentences we generate a deterministic shift-reduce parser. The quality of the treebank, particularly crucial given its small size, {{is supported by a}} <b>consistency</b> <b>checker.</b> 1 Introduction Given the enormous complexity of natural language, parsing is hard enough as it is, but often unforeseen events like the crises in Bosnia or East-Timor create a sudden demand for parsers and machine translation systems for languages that have not benefited from major attention of the computational linguistics community up to that point. Good machine translation relies strongly on the context of the words to be translated, a context that often goes well beyond neighboring surface words. Often basic relationships, like that between a verb and its direct object, provide crucial support for translation. Such relationships are usually provided by parsers. The NLP resources f [...] ...|$|E
40|$|Validation {{has emerged}} as a {{significant}} problem in the development of knowledgebased systems (KBS). Verification of KBS correctness and completeness has been cited {{as one of the most}} difficult aspects of validation. A number of software tools have been developed to perform such verification, but none of these are in widespread use. One of the reasons for this is that little quantitative evidence exists to demonstrate the effectiveness of the tools. This paper presents an experimental study of three KBS verification tools: a <b>consistency</b> <b>checker,</b> a completeness checker, and a testing tool (for correctness). The tools are evaluated on their ability to reveal plausible faults seeded into a complex, realistic KBS application. The cost of using the tools is also measured. It is shown that each tool is independently effective at detecting certain kinds of fault, and that the capabilities of the tools are complementary [...] - a result not revealed by previous studies...|$|E
40|$|SCR (Software Cost Reduction) is {{a formal}} method for specifying and {{analyzing}} system requirements that {{has previously been}} applied to control systems. This paper describes {{a case study in}} which the SCR method was used to specify and analyze a different class of system, a cryptographic system called CD, which must satisfy a large set of security properties. The paper describes how a suite of tools supporting SCR [...] a <b>consistency</b> <b>checker,</b> simulator, model checker, invariant generator, theorem prover, and validity checker [...] were used to detect errors in the SCR specification of CD and to verify that the specification satis es seven security properties. The paper also describes issues of concern to software developers about formal methods [...] e. g., ease of use, cost-effectiveness, scalability, how to translate a prose specification into a formal notation, and what process to follow in applying a formal method [...] and discusses these issues based on our experience with CD. Also described are some unexpected results of our case study...|$|E
40|$|Performance {{problems}} in complex systems are often caused by underprovisioning, workload interference, incorrect expectations or bugs. Troubleshooting such systems {{is a difficult}} task faced by service engineers. We have built CLUEBOX, a non-intrusive toolkit that aids rapid problem diagnosis. It employs machine learning techniques on the available performance logs to characterize workloads, predict performance and discover anomalous behavior. By identifying the most relevant anomalies to focus on, CLUEBOX automates the most onerous aspects of performance troubleshooting. We have experimentally validated our methodology in a networked storage environment with real workloads. Using CLUEBOX to learn from a set of historical performance observations, {{we were able to}} distill over 2000 performance counters into 68 counters that succinctly describe a running workload. Further, we demonstrate effective troubleshooting of two scenarios that adversely impacted application response time: (1) an unknown competing workload, and (2) a file system <b>consistency</b> <b>checker.</b> By reducing the set of anomalous counters to examine to a dozen significant ones, CLUEBOX was able to guide a systems engineer towards identifying the correct root-cause rapidly. ...|$|E
40|$|Abstract. In {{this paper}} {{we present a}} {{proposal}} for safely evolving a software system against run-time changes. This proposal {{is based on a}} reflective architecture which provides objects with the ability of dynamically changing their behavior by using their design information. The meta-level system of the proposed architecture supervises the evolution of the software system to be adapted that runs as the base-level system of the reflective architecture. The meta-level system is composed of cooperating components; these components carry out the evolution against sudden and unexpected environmental changes on a reification of the design information (e. g., object models, scenarios and statecharts) of the system to be adapted. The evolution takes place in two steps: first a meta-object, called evolutionary meta-object, plans a possible evolution against the detected event then another meta-object, called <b>consistency</b> <b>checker</b> meta-object validates the feasibility of the proposed plan before really evolving the system. Meta-objects use the system design information to govern the evolution of the base-level system. Moreover, we show our architecture at work on a case study...|$|E
