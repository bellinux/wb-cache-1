82|19|Public
2500|$|Einstein's first {{paper on}} {{relativity}} was published {{three months after}} Poincaré's short paper, but before Poincaré's longer version. Einstein relied {{on the principle of}} relativity to derive the Lorentz transformations and used a similar <b>clock</b> <b>synchronisation</b> procedure (Einstein synchronisation) to the one that Poincaré (1900) had described, but Einstein's paper was remarkable in that it contained no references at all. Poincaré never acknowledged Einstein's work on special relativity. However, Einstein expressed sympathy with Poincaré's outlook obliquely in a letter to Hans Vaihinger on 3 May 1919, when Einstein considered Vaihinger's general outlook to be close to his own and Poincaré's to be close to Vaihinger's. In public, Einstein acknowledged Poincaré posthumously in the text of a lecture in 1921 called Geometrie und Erfahrung in connection with non-Euclidean geometry, but not in connection with special relativity. A few years before his death, Einstein commented on Poincaré as being one of the pioneers of relativity, saying [...] "Lorentz had already recognised that the transformation named after him is essential for the analysis of Maxwell's equations, and Poincaré deepened this insight still further ...." ...|$|E
50|$|Flaviu Cristian (25 June 1951 - 27 April 1999) was a Romanian {{computer}} scientist noted {{for his work}} in distributed systems and, in particular, the development of a method for <b>clock</b> <b>synchronisation</b> which bears his name, Cristian's algorithm.|$|E
5000|$|The same {{synchronisation}} {{is achieved}} by [...] "slowly" [...] transporting a third clock from clock 1 to clock 2, {{in the limit of}} vanishing transport velocity. The literature discusses many other thought experiments for <b>clock</b> <b>synchronisation</b> giving the same result.|$|E
40|$|I {{present a}} review of the study of optical {{phenomena}} in moving bodies during the 19 th century. I show how Lorentz's progressive stages approach successfully explained these phenomena and how he finally got his relativistic formulae. The important role of H. Poincaré as a critic reviewer of existent theory is underlined. I discuss with some details the Poincaré's distant <b>clocks</b> <b>synchronisation,</b> which clarifies the meaning of Lorentz's local time. SCOPUS: cp. jinfo:eu-repo/semantics/publishe...|$|R
50|$|The Einstein {{synchronisation}} looks {{this natural}} only in inertial frames. One can easily forget {{that it is}} only a convention. In rotating frames, even in special relativity, the non-transitivity of Einstein synchronisation diminishes its usefulness. If clock 1 and clock 2 are not synchronised directly, but by using a chain of intermediate <b>clocks,</b> the <b>synchronisation</b> depends on the path chosen. Synchronisation around the circumference of a rotating disk gives a non vanishing time difference that depends on the direction used. This is important in the Sagnac effect and the Ehrenfest paradox. The Global Positioning System accounts for this effect.|$|R
25|$|Local {{differences}} in topography (such as {{the presence of}} mountains), geology (such as the density of rocks in the vicinity), and deeper tectonic structure cause local and regional {{differences in}} the Earth's gravitational field, known as gravitational anomalies. Some of these anomalies can be very extensive, resulting in bulges in sea level, and throwing pendulum <b>clocks</b> out of <b>synchronisation.</b>|$|R
50|$|The Berkeley {{algorithm}} {{is a method}} of <b>clock</b> <b>synchronisation</b> in distributed computing which assumes no machine has an accurate time source. It was developed by Gusella and Zatti at the University of California, Berkeley in 1989. Like Cristian's algorithm, it is intended for use within intranets.|$|E
50|$|In December 2011, {{the system}} went into {{operation}} on a trial basis. It has started providing navigation, positioning and timing data to China and the neighbouring area for free from 27 December. During this trial run, Compass will offer positioning accuracy to within 25 meters, but the precision will improve as more satellites are launched. Upon the system's official launch, it pledged to offer general users positioning information accurate {{to the nearest}} 10 m, measure speeds within 0.2 m per second, and provide signals for <b>clock</b> <b>synchronisation</b> accurate to 0.02 microseconds.|$|E
50|$|Many {{experiments}} {{intended to}} measure the one-way speed of light, or its variation with direction, have been (and occasionally still are) performed in which light follows a unidirectional path. Claims have been made that those experiments have measured the one-way speed of light independently of any <b>clock</b> <b>synchronisation</b> convention, but they have all been shown to actually measure the two-way speed, because they are consistent with generalized Lorentz transformations including synchronizations with different one-way speeds {{on the basis of}} isotropic two-way speed of light (see sections the one-way speed and generalized Lorentz transformations).|$|E
30|$|In {{the case}} of RFID or sensor applications, the high data rate is shifted to the uplink. Since the tags or sensors are very small and the {{available}} power has {{to be used as}} efficiently as possible, it is advantageous to have a fast transmission in the uplink. The downlink, from a reader station to a sensor or tag, provides the energy, control commands, and <b>clock</b> for <b>synchronisation</b> in a UHF band, with the data rate being usually lower. A concept of an asymmetric communication scheme for RFID scenarios was introduced by Zheng et al. in [1] and has been manufactured and characterised in the works of Baghaei-Nejad and Radiom et al. in [2] and [3].|$|R
40|$|Bistatic and multistatic SAR constellations offer {{increased}} {{performance at}} the expense of increased operational complexity. Due to geometric or cost constraints, multistatic SAR constellations might be forced to operate in a partially cooperative manner, i. e., without a direct synchronisation link. In demanding scenarios, like high-resolution bistatic SAR imaging or cross-platform SAR interferometry or tomography, the data need undergo a calibration step to compensate the lack of synchronisation between transmitter and receiver master <b>clocks.</b> Autonomous <b>synchronisation,</b> based on the inversion of the phase and positioning errors of the bistatic SAR images caused by the lack of synchronisation, is used to calibrate the time and phase references of the system with the sole help of the received radar data, which drastically reduces the requirements on the hardware of the system...|$|R
40|$|Following {{the success}} of the first {{bistatic}} spaceborne-airborne experiment between TerraSAR-X and FSAR carried out in November 2007, DLR has performed a second bistatic experiment in July 2008 with new challenging acquisitions. Furthermore, the existing bistatic processing chain has been updated with two significant improvements: a) <b>clock</b> offset <b>synchronisation</b> is now performed without the use of reference targets, and b) SAR imaging is done using a fast focussing technique. The new SAR imaging algorithm, based on the fast factorised backprojection algorithm, has proved very good focussing qualities while dramatically reducing (up to a factor 100 with respect to direct backprojection) the overall computational load. The new processing chain is tested using the image of the first TerraSAR-X experiment. Results of a dualpol acquisition performed during the second TerraSAR-X/F-SAR experiment and showing the first dual-pol bistatic spaceborneairborne images are also presented in this paper...|$|R
5000|$|Einstein's first {{paper on}} {{relativity}} was published {{three months after}} Poincaré's short paper, but before Poincaré's longer version. Einstein relied {{on the principle of}} relativity to derive the Lorentz transformations and used a similar <b>clock</b> <b>synchronisation</b> procedure (Einstein synchronisation) to the one that Poincaré (1900) had described, but Einstein's paper was remarkable in that it contained no references at all. Poincaré never acknowledged Einstein's work on special relativity. However, Einstein expressed sympathy with Poincaré's outlook obliquely in a letter to Hans Vaihinger on 3 May 1919, when Einstein considered Vaihinger's general outlook to be close to his own and Poincaré's to be close to Vaihinger's. In public, Einstein acknowledged Poincaré posthumously in the text of a lecture in 1921 called Geometrie und Erfahrung in connection with non-Euclidean geometry, but not in connection with special relativity. A few years before his death, Einstein commented on Poincaré as being one of the pioneers of relativity, saying [...] "Lorentz had already recognised that the transformation named after him is essential for the analysis of Maxwell's equations, and Poincaré deepened this insight still further ...." ...|$|E
40|$|<b>Clock</b> <b>synchronisation</b> is an {{important}} requirement for various applications in wireless sensor networks (WSNs). Most of the existing <b>clock</b> <b>synchronisation</b> protocols for WSNs use some hierarchical structure that introduces an extra overhead due to the dynamic nature of WSNs. Besides, {{it is difficult to}} integrate these <b>clock</b> <b>synchronisation</b> protocols with sleep scheduling scheme, which is a major technique to conserve energy. In this paper, we propose a fully distributed peer-to-peer based <b>clock</b> <b>synchronisation</b> protocol, named Distributed <b>Clock</b> <b>Synchronisation</b> Protocol (DCSP), using a novel technique of pullback for complete sensor networks. The pullback technique ensures that synchronisation phases of any pair of clocks always overlap. We have derived an exact expression for a bound on maximum synchronisation error in the DCSP protocol, and simulation study verifies that it is indeed less than the computed upper bound. Experimental study using a few TelosB motes also verifies that the pullback occurs as predicted...|$|E
40|$|<b>Clock</b> <b>synchronisation</b> is {{conventional}} when inertial {{systems are}} involved. This statement {{is no longer}} true in accelerated systems. A demonstration is given {{in the case of}} a rotating platform. We conclude that theories based on the Einstein's <b>clock</b> <b>synchronisation</b> procedure are unable to explain, for example, the Sagnac effect on the platform. Implications on very precise <b>clock</b> <b>synchronisation</b> on earth are discussed. Comment: 10 pages, Latex type, 2 figures; contribution to the London conference on Physical Interpretations of Relativity Theory (6 - 9 / 09 / 1996...|$|E
40|$|Abstract. Recently a new {{software}} <b>clock</b> and <b>synchronisation</b> algorithm {{based on the}} TSC register (clock cycle counter) was developed, with several advantages over the existing system clock. However, as it uses a modified kernel to support driver timestamping, installation is non-trivial, limiting its use. We present a modified TSC clock {{without the need for}} kernel modifications, using only user-level timestamps and existing system kernel timestamps exploited in a careful way. Using weeks of test data, we show how the system performance is virtually identical to that of a kernel implementation. Compared against a GPS synchronised DAG card reference, it performs very well under both BSD and Linux. We also show how the system can replace ntpd to improve the existing system clock. The software allows for significantly improved timestamping for both packet and internal system events, and is trivial to install. It is publicly available. ...|$|R
50|$|SDLC and Low- and full-speed USB {{data are}} sent NRZI encoded: a 0 bit causes a signal transition, whereas a 1 bit causes no change. After a long {{sequence}} of 1 bits {{there could be}} no transitions in the transmitted data, and it would be possible for the transmitter and receiver <b>clocks</b> to lose <b>synchronisation.</b> By inserting a 0 after five (SDLC) or six (USB) sequential 1s the transmitter guarantees a maximum time between transitions. The receiver can synchronise its clock against the transitions to ensure proper data recovery.|$|R
40|$|In this paper, {{we present}} a new method for neural spike sorting based on Continuous Time (CT) signal processing. A set of CT based {{features}} are proposed and extracted from CT sampled pulses, and a complete event-driven spike sorting algorithm that performs classification based on these features is developed. Compared to conventional methods for spike sorting, the hardware implementation of the proposed method does not require any <b>synchronisation</b> <b>clock</b> for logic circuits, and thus its power consumption depend solely on the spike activity. This has been implemented using a variable quantisation step CT analogue to digital converter (ADC) with custom digital logic that is driven by level crossing events. Simulation results using synthetic neural data shows a comparable accuracy compared to template matching (TM) and Principle Components Analysis (PCA) based discrete sampled classification...|$|R
40|$|<b>Clock</b> <b>synchronisation</b> is {{a widely}} studied problem. Most {{research}} has focused on real-time <b>clock</b> <b>synchronisation</b> algorithms, which run as background processes to maintain synchronisation between the clocks of a collection of computers. Research has also been done into off-line <b>clock</b> <b>synchronisation</b> algorithms. These algorithms can be used where time-stamped event records have been recorded on a collection of computers. In evaluating the effectiveness of a <b>clock</b> <b>synchronisation</b> algorithm, it is important to determine the offsets of clocks from each other or from an external reference. The reason that the <b>clock</b> <b>synchronisation</b> problem is a difficult one is because {{it is not possible to}} directly measure the offsets between two clocks without using special hardware. Consequently, in all of the <b>clock</b> <b>synchronisation</b> work with which we are familiar, effectiveness is assessed by indirect measures of clock offsets, or by simulation. We have developed hardware and software to enable us to directly determine clock offsets so the performance of <b>clock</b> <b>synchronisation</b> algorithms can be accurately assessed. The main hardware component is a "clockcard" that connects to any IBM PC compatible parallel port. On the clockcard are two logical 32 -bit binary counters that can be latched at exactly the same time. One of the counters is clocked from an on board oscillator that mimics the accuracy of modern day computer oscillators. The other counter is driven via an external clock. In a collection of computers under test, all the external counters are driven from the same external clock, so each clockcard has a notion of external global time. The local counter on the clockcard is used as a replacement for the local clock on the computer that the clockcard is attached to. The new local clock is the one synchronised by a <b>clock</b> <b>synchronisation</b> algorithm under test. Whenever timestamps are read from the clockcard, the values of both counters are returned. The global timestamps allow offsets between local clocks to be measured very accurately. We describe the design and construction of the test bed hardware, design and implementation of software to interface <b>clock</b> <b>synchronisation</b> programs to the test bed, and present results from initial experiments performed to check that the test bed works as intended...|$|E
40|$|The {{weighted}} average based <b>clock</b> <b>synchronisation</b> protocols for {{wireless sensor networks}} (WSNs), viz., energy efficient and fault-tolerant <b>clock</b> <b>synchronisation</b> (EFCS) protocol, {{weighted average}} based internal <b>clock</b> <b>synchronisation</b> (WICS) protocol, and weighted average based external <b>clock</b> <b>synchronisation</b> (WECS) protocol, have several fault-tolerant properties including automatic interchangeability among these protocols, but a major problem with these protocols is that their synchronisation accuracy is not very high. In this paper, we propose a generic technique to improve the synchronisation accuracy in these three protocols. We also give a proof that the synchronisation error in the EFCS protocol is bounded. The improved protocols also make use of estimated drift rate to provide an accurate reading of time at any instant, and the logical time provided by these protocols is monotonic. The simulation and experimental studies clearly show that the average synchronisation error in the improved protocols is much less than that in the original protocols...|$|E
40|$|The paper {{describes}} first {{results of}} "Common-View" <b>clock</b> <b>synchronisation</b> between DLR, BIPM and NPL using AOA TTR- 4 P GPS time receivers. CIA code measurements have been analyzed and compared to data with usual one-channel receivers. It will {{be concluded that}} such receivers will certainly have a large impact for future <b>clock</b> <b>synchronisation,</b> and for more investigation work is still required...|$|E
40|$|This {{paper is}} based on the theory of True Relativity and only uses dynamic {{geometry}} to calculate time dilation and represents a paradigm shift in the way we view Space and Time. An accuracy drift within the GPS must be present if General Relativity was used to calculate the time dilation for the spacecraft and will only be corrected by using True Relativity and the Universal clock©. As the author lacks information of all the acceleration forces the spacecraft <b>clocks</b> underwent since <b>synchronisation</b> with the Earth clock, this paper calculates the Time dilation for an experiment using two atomic clocks and a centrifuge. If this experiment is undertaken and successful then the resynchronisation of any spacecraft clock with the clocks here on Earth becomes possible, and the accuracy of the GPS will not only become stable but greatly improved...|$|R
40|$|In {{measurement}} and control systems {{there is often a}} need to synchronise distributed <b>clocks.</b> Traditionally, <b>synchronisation</b> has been achieved using a dedicated medium to convey time information, typically using the IRIG-B serial protocol. The precision time protocol (IEEE 1588) has been designed as an improvement to current methods of synchronisation within a distributed network of devices. IEEE 1588 is a message based protocol that can be implemented across packet based networks including, but not limited to, Ethernet. Standard Ethernet switches introduce a variable delay to packets that inhibits path delay measurements. Transparent switches have been introduced to measure and adjust for packet delay, thus removing the negative effects that these variations cause. This thesis describes the hardware and firmware design of an IEEE 1588 transparent end-to-end Ethernet switch for Tekron International Ltd based in Lower Hutt, New Zealand. This switch has the ability to monitor all Ethernet traffic, identify IEEE 1588 timing packets, measure the delay that these packets experience while passing through the switch, and account for this delay by adjusting a time-interval field of the packet as it is leaving the switch. This process takes place at the operational speed of the port, and without introducing significant delay. Time-interval measurements can be made using a high-precision timestamp unit with a resolution of 1 ns. The total jitter introduced by this measurement process is just 4. 5 ns through a single switch...|$|R
2500|$|Concepts used in Fast14 are {{described}} in a white paper: and {{include the use of}} multi-phase <b>clocks</b> so that <b>synchronisation</b> is not required at every cycle boundary (that is, a pipelined design does not require latches at every clock cycle); 1-of-N encoding where a signal with N states is carried as a voltage on one of N wires with the other N-1 grounded, rather than being carried on log(N) wires which can be in arbitrary states; and a variety of sophisticated routing algorithms including ones which permute the order of the wires in a bundle carrying a 1-of-N signal {{in such a way as}} to reduce noise exposure, and ones which allow complicated gates to 'borrow' delay from simple ones to allow a shorter clock cycle than a more pessimistic design approach permits. [...] Converters between the two signal encodings are readily available, and are useful for interfacing to blocks of static logic.|$|R
40|$|The {{standard}} method of measuring one-way delay and delay {{variance in the}} Internet uses synchronous techniques which require <b>clock</b> <b>synchronisation</b> between source and destination. In this paper, we propose an asynchronous method of measuring one way delay and delay variance in the Internet, which does not require <b>clock</b> <b>synchronisation</b> between source and destination. The proposed asynchronous method requires minor additional functionality in the Internet routers. 1. Introduction The {{standard method}} [4] of measuring one-way delay and delay variance in the Internet uses synchronous techniques which require <b>clock</b> <b>synchronisation</b> between source and destination. Such synchronous techniques are inherently prone to synchronisation errors due to clock drifts. To achieve high accuracy with synchronous performance measurement (SPM), we need to install spcialised hardware/software, such as Global Positioning System (GPS) based infrastructure, at each measurement host. In this paper, we propose a [...] ...|$|E
40|$|The special {{relativistic}} test {{theory of}} Mansouri and Sexl is sketched. Theories based on different clock synchronisations {{are found to}} be equivalent to special relativity, as regards experimental results. The conventionality of <b>clock</b> <b>synchronisation</b> is shown not to hold, by means of an example, in a simple accelerated system and through the principle of equivalence in gravitational fields, especially when the metric is not static. Experimental implications on very precise <b>clock</b> <b>synchronisation</b> on earth are discussed. Comment: 4 pages, Latex; contribution to the Journees Relativistes, 199...|$|E
40|$|Wireless Sensor Networks (WSNs) {{have many}} {{application}} scenarios where external <b>clock</b> <b>synchronisation</b> {{may be required}} because a WSN may consist of components which are not connected to each other. In this paper, we first propose a novel weighted average-based internal <b>clock</b> <b>synchronisation</b> (WICS) protocol, which synchronises all the clocks of a WSN with the clock of a reference node periodically. Based on this protocol, we then propose our weighted average-based external <b>clock</b> <b>synchronisation</b> (WECS) protocol. We have analysed the proposed protocols for maximum synchronisation error and shown that it is always upper bounded. Extensive simulation studies of the proposed protocols {{have been carried out}} using Castalia simulator. Simulation results validate our above theoretical claim and also show that the proposed protocols perform better in comparison to other protocols in terms of synchronisation accuracy. A prototype implementation of the WICS protocol using a few TelosB motes also validates the above conclusions...|$|E
40|$|In {{high-speed}} all-optical {{time division}} multiplexed (OTDM) routers {{it is desirable}} to carry out data routing, switching, <b>clock</b> recovery and <b>synchronisation</b> in the optical domain {{in order to avoid}} the bottleneck due to optoelectronics conversion. The authors propose an optical switch based on all-optical symmetric Machâ€“Zehnder (SMZ) switching and investigate its characteristics. The proposed switch is to be used as a building block for a simple 1 x 2 OTDM router for asynchronous OTDM packet routing, where clock recovery, address recognition and payload routing are all carried out in the optical domain. Simulation and numerical results demonstrate that clock recovery, address recognition and payload routing are possible with small amounts of crosstalk. Also presented are simulation results for bit error rate (BER) performance for the 1 x 2 router. For a BER of 10 e- 9 the receiver sensitivity is - 26 dB compared with baseline detection without a router of - 38 dB. The proposed router displays great potential for use in ultrahigh- speed OTDM networks...|$|R
40|$|This thesis {{describes}} {{the development of}} an on-chip point-to-point link, with particular emphasis on the reduction of its global metal area footprint. To reduce its metal footprint, the interconnect uses a serial transmission approach. 8 -bit data is sent using just two wires, through a pulse-based technique, inspired by the GasP interconnect from Sun Microsystems. Data and control signals are transmitted bi-directionally on a wire using this double-edged, pulse-based signalling protocol, and formatted using a variant of dual-rail encoding. These choices enable a {{reduction in the number of}} wires needed, an improvement in the acknowledgement overhead of the asynchronous protocol, and the ability to cross <b>clock</b> domains without <b>synchronisation</b> hazards. New, stateful, repeaters are demonstrated, and results from spice simulations of the system show that data can be transferred at over 1 Gbit/s, over 1 mm of minimum-sized, minimally-spaced metal 5 wiring, on a 180 nm (0. 18 µm) technology. This reduces to only 926 Mbit/s, when 10 mm of wiring is considered, an...|$|R
40|$|Time {{measurement}} in sports, {{which are}} based on speed and fast movement, require high accuracy. In the most commonly used manual timing this requirement cannot be met. Errors due to human factor are too high and vary between persons who carry out measurements. These errors can be avoided by using electronic sensors, which sample events with high accuracy. In this thesis, we designed a distributed system for electronical time measurement. It consists of the control unit and sensor units that mutually communicate over radio frequencies. Units have their own clocks, which must be synchronized before measurements. Events triggered by moving objects are captured by infrared beam gates, while a special switch is responsible for sampling starting events. In the development we have given attention to the following elements that affect the accuracy of measurement : <b>clock</b> accuracy, time <b>synchronisation</b> and sensor event capturing. Finally, we experimentally confirmed that such a system suffices accuracy measures stating that accuracy is at least 10 times the measurement resolution being 0. 01 s...|$|R
40|$|In a {{distributed}} system, no hardware facilities {{exist to}} synchronise the clocks of the computers within the system. Algorithms designed to synchronise clocks in such {{systems have been}} the subject of much research. The lack of a global clock has meant that the accuracy of these algorithms has generally been assessed using indirect measures of clock o#sets. We have developed a <b>clock</b> <b>synchronisation</b> test bed that allows for direct measurement of clock o#sets. The test bed is now operational, and we have used it to produce initial results for the widely-used xntp package, and for some o#-line synchronisation algorithms. 1 Introduction <b>Clock</b> <b>synchronisation</b> in distributed computer systems is a widely studied problem. The primary aim of a <b>clock</b> <b>synchronisation</b> algorithm is to ensure that the maximum di#erence (or o#set) between any two clocks amongst a group of clocks being synchronised is small. Di#erent applications have di#erent requirements as to the degree to which clocks must [...] ...|$|E
40|$|This thesis {{addresses}} currently open {{problems in}} the stability analysis and control of discrete linear systems with <b>clock</b> <b>synchronisation</b> errors. Such errors can lead to insta- bility of an overall system even in the case when it is composed of linear sub-systems that are stable. Previous work in this general area has focused almost exclusively on stability analysis and this thesis therefore focuses on the synthesis {{problem of how to}} design control laws that ensure stability and performance of the overall system in the presence of <b>clock</b> <b>synchronisation</b> errors and, in particular, on the robustness problem. For many applications, intensive matrix computations are required and hence the time complexity of the algorithms used is critical. A major part of the new results in this thesis is the development of two new algorithms for undertaking the computations in the case where uncertainty is present and an investigation of their merits relative to linear matrix inequality and brute force alternatives. An identification method for detecting the presence of <b>clock</b> <b>synchronisation</b> errors from system data is also developed. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|E
40|$|This paper {{describes}} {{the implementation of}} the first portable, embedded data acquisition unit (BabelFuse) that is able to acquire and timestamp generic sensor data and trigger General Purpose I/O (GPIO) events against a microsecond-accurate wirelessly-distributed ‘global’ clock. A significant issue encountered when fusing data received from multiple sensors is the accuracy of the timestamp associated with each piece of data. This is particularly important in applications such as Simultaneous Localisation and Mapping (SLAM) where vehicle velocity forms {{an important part of the}} mapping algorithms; on fast-moving vehicles, even millisecond inconsistencies in data timestamping can produce errors which need to be compensated for. The timestamping problem is compounded in a robot swarm environment especially if non-deterministic communication hardware (such as IEEE- 802. 11 -based wireless) and inaccurate <b>clock</b> <b>synchronisation</b> protocols are used. The issue of differing timebases makes correlation of data difficult and prevents the units from reliably performing synchronised operations or manoeuvres. By utilising hardware-assisted timestamping, <b>clock</b> <b>synchronisation</b> protocols based on industry standards and firmware designed to minimise indeterminism, an embedded data acquisition unit capable of microsecond-level <b>clock</b> <b>synchronisation</b> is presented...|$|E
40|$|The {{model of}} {{population}} protocols {{refers to the}} growing in popularity theoretical framework suitable for studying pairwise interactions within a large collection of simple indistinguishable entities, frequently called agents. In this paper {{the emphasis is on}} the space complexity in fast leader election via population protocols governed by the random scheduler, which uniformly at random selects pairwise interactions within the population of n agents. The main result of this paper is a new fast and space optimal leader election protocol. The new protocol utilises O(log^ 2 n) parallel time (which is equivalent to O(n log^ 2 n) sequential pairwise interactions), and each agent operates on O(log log n) states. This double logarithmic space usage matches asymptotically the lower bound 1 / 2 log log n on the minimal number of states required by agents in any leader election algorithm with the running time o(n/polylog n). Our solution takes an advantage of the concept of phase <b>clocks,</b> a fundamental <b>synchronisation</b> and coordination tool in distributed computing. We propose a new fast and robust population protocol for initialisation of phase clocks to be run simultaneously in multiple modes and intertwined with the leader election process. We also provide the reader with the relevant formal argumentation indicating that our solution is always correct, and fast with high probability...|$|R
40|$|Abstract: A new general {{method for}} {{designing}} asynchronous datapath components, called speculative completion, is introduced. The method has {{many of the}} advantages of a bundled data approach, {{such as the use of}} single-rail synchronous datapaths, but it also allows early completion. As a case study, the method is applied to the high-performance parallel BLC adder design of Brent and Kung. Through careful gate-level analysis, performance improvements of up to 30 % over a comparable synchronous implementation are expected. 1 introduction Asynchronous design has enjoyed a resurgence in th last five to ten years, with a number of technical and practical advances [11. In principle, asynchronous systems promise several advantages over synchronous systems: (i) lower power, since an asynchronous component computes only when necessary; (ii) higher performance, since global <b>clock</b> distribution and <b>synchronisation</b> can be avoided; and finally, (iii) greater modularity and ease of design, since there are no global timing constraints. An important recent trend is the design and, in many cases, fabrication of practical large-scale asynchronous systems, such as microprocessors [2 - 7] and DSP chips [8]. Critical to these systems is the design of efficient datapath support components, such as adders. This paper proposes a new method for designing asynchronous data-path components, targeted towards high-performance design. Many approaches have been proposed to designing asynchronous datapath components. Most fall into one of two categories, depending on how completion is determined: bundled data and completion detection. A bundled data design uses a worst-case model delay, designed to exceed the longest path through the subsystem [l, 91. This delay may be an inverter chain or a replicated portion of the critical path. This method has been widely used [3 - 5, 81. The main advantage is that a standard synchronous (i. e. non-hazard-free) single-rail implementation may be used, so implementations ar...|$|R
40|$|A {{fault-tolerant}} <b>clock</b> <b>synchronisation</b> {{technique is}} presented. In a distributed system {{the discrepancy between}} a node’s view of current time {{and the rest of}} a system can cause critical deadlines to be missed. It may also be the cause of many unknown system errors. In fact, many real-time applications, such as redundancy management, synchronous data acquisition and simultaneous triggering of actuators at several nodes, are impossible without such a global reference time. DRTS Ltd have developed and have protected a software-based fault-tolerant <b>clock</b> <b>synchronisation</b> technique for broadcast networks such as CAN. It provides a predictable and reliable service that enables networked system synchronisation to micro-second precision using negligible network bandwidth. 1...|$|E
