4|6|Public
5000|$|Shortly {{after their}} formation, the districts issued $1.9 {{million in revenue}} bonds to finance the dam and canal {{infrastructure}} that would supply the land. In 1913 the districts built Goodwin Dam, about 2.5 mi upstream of Knights Ferry, to divert water into their respective canals. They filed claims for [...] of Stanislaus River water, divided evenly between the two districts. In the early years, maintaining a sufficient water supply in the summer was nearly impossible, because the Sierra snowpack usually melts out by mid-June. Agriculture relied heavily on wells {{in the late summer}} when the river was low, and this could only support about 20000 acre of crops. The lower Stanislaus River was often completely dry in the summertime due to water diversions. The irrigation districts desperately needed water storage for the dry season, and a number of small off-stream reservoirs were built, including Woodward Reservoir in 1916, though their benefit was limited at best. In 1925 the districts issued $2.2 million of bonds to build a storage dam on the Stanislaus River. The original Melones Dam, completed 1926, was a 211 ft tall concrete arch structure capable of storing [...] of water, enough to irrigate 144000 acre of land for a single season but too small to provide <b>carry-over</b> <b>storage</b> for drought years.|$|E
40|$|AbstractThe {{conversion}} of the potential energy of dammed water into hydropower depends on both reservoir storage and release, which are the major difficulties in hydropower reservoir operation. This study evaluates the marginal utility principle, which determines the optimal <b>carry-over</b> <b>storage</b> between periods, for long-term hydropower scheduling. Increasing marginal cost and decreasing marginal return are two important characteristics that determine the marginal utility principle in water supply. However, the notion of decreasing marginal return is inapplicable in hydropower scheduling. Instead, the <b>carry-over</b> <b>storage</b> from one period has an increasing marginal contribution to the power generation in the next period. Although <b>carry-over</b> <b>storage</b> incurs an increasing marginal cost to the power generation in the current period, the marginal return {{is higher than the}} marginal cost. The marginal return from the <b>carry-over</b> <b>storage</b> further increases in the multi-period case. These findings suggest saving as much <b>carry-over</b> <b>storage</b> as possible, which is bounded by the operational constraints of storage capacity, environmental flow, and installed capacity in actual hydropower scheduling. The marginal utility principle is evaluated for a case study of the Three Gorges Reservoir, and the effects of the constraints are discussed. Results confirm the theoretical findings and show that the marginal return from <b>carry-over</b> <b>storage</b> is larger than the marginal cost. The operational constraints help determine the optimal <b>carry-over</b> <b>storage...</b>|$|E
30|$|The {{reservoir}} operation schedule (with Guide Curve and integrated approach as adopted by DVC Authority) {{was used for}} simulating the operation of system of reservoirs in integrated manner, starting from 1 st June (beginning of water year in India). The integrated approach involves consideration of {{the operation of the}} Tilaiya reservoir in tandem with the Maithon reservoir, the operation of the Konar and Tenughat reservoirs in tandem with the Panchet reservoir and combined operation of Maithon and Panchet reservoirs for the Durgapur Barrage for conservation as well as flood management purposes. The operation schedule invokes attempt to maintain conservation storages of the reservoirs full (throughout the month of October) so as to ensure conservation requirement up to the end of summer (or up to the onset of monsoon i.e. the first week of June) along with some <b>carry-over</b> <b>storage</b> if onset of monsoon is delayed.|$|E
40|$|Recent {{research}} has shown early economies to exhibit market behavior by using institutions that reduce price volatility. In this paper we focus on storage as a price stabilizing strategy in Babylon using a recent dataset with agricultural prices for the Late Achaemenid and Hellenistic periods (ca. 400 – 65 BC). This dataset allows us to assess the importance of interannual <b>storage</b> (<b>carry-over)</b> in this economy. Comparing this economy with that of medieval England using a cost-benefit analysis, we find, after correcting for the differential crop structure in both regions, {{a low level of}} inter-annual storage. Yet, contrary to the expectations of the cost-benefit analysis, the evidence does not indicate a lower interest rate (i. e. costs) in Babylon. This implies that both social structure as well as access to capital markets played a more important role than traditionally assumed in the question of <b>carry-over.</b> Hellenistic Babylonia, <b>storage,</b> England, Babylon, seasonality, ancient history, medieval history...|$|R
40|$|Traditionally, small dams (tanks) {{have been}} both centres of village {{settlements}} {{and the source}} of irrigation in Asia. Being solely dependent on local rainfall characteristics and other climatic factors, the water storage behaviour closely follows the rainfall pattern. <b>Carry-over</b> of <b>storage</b> from year to year is rare because of natural evaporation and withdrawals for irrigation. The efficient allocation of storage, within any year, is analogous to the optimization of a time-varying exhaustible resource stock. This study attempts to model water storage of dams using weekly data with a view to intrayear optimization of storage. The behaviour of storage is approximated by a dynamic system driven by rainfall distribution and temperature, and characterized by a linear transfer function model following modification of rainfall to allow for losses. The order of the linear part of the model is identified and parameters estimated for three tanks in Sri Lanka using a recursive estimation procedure. This model can be used for the prediction of storage for a given rainfall scenario. This is demonstrated for past realistic rainfall experiences using stochastic simulation of storage...|$|R
5000|$|The general {{consensus}} among {{inhabitants of the}} Colorado River basin and government officials was that a high dam had to be built on the Colorado to control floods and provide <b>carry-over</b> water <b>storage</b> for times of drought. Possible locations for this dam were debated for years, {{and in fact the}} Bureau of Reclamation's first study for a dam at Glen Canyon was made in 1924, in addition to studies for locations at Black and Boulder Canyons lower on the Colorado, below Grand Canyon. These studies found that the lower Colorado sites had stronger foundation rock which might result in less reservoir seepage. The Glen Canyon site, furthermore, was so remote that delivering supplies and transporting workers there would be infeasible at the time. However, what really killed the first Glen Canyon proposal was the fact that it lies upstream of the Lee's Ferry dividing line, and thus would be considered the Upper Basin's water. With its substantial Congressional clout, California refused to allow the [...] "virtual faucets" [...] of a Colorado River dam [...] "to be built in what amounted to hostile territory." ...|$|R
40|$|Research Doctorate - Doctor of Philosophy (PhD) Several {{large scale}} ocean-atmosphere climate {{mechanisms}} {{are known to}} influence the Australasian climate, including the El Niño Southern Oscillation (ENSO), the Interdecadal Pacific Oscillation (IPO) and the closely related Pacific Decadal Oscillation (PDO), the Indian Ocean Dipole (IOD) and the Southern Annular Mode (SAM). The variability explained by these mechanisms presents a valuable means for improving the ability of stochastic models to characterise temporal and spatial hydrological behaviour. Whilst there is significant interannual (and higher frequency) hydrological variability due to ENSO, the IOD and SAM, water supply reservoirs typically have sufficient <b>carry-over</b> <b>storage</b> to maintain supply through shorter (e. g. El Niño) drought spells with run-lengths up to 12 - 18 months. Reservoir systems are usually not designed however to cope with decadal-scale dry periods. The evidence of low frequency hydrological variability due to the IPO-PDO and the vulnerability of water supply systems to prolonged drought sequences prompt {{the need for a}} better understanding of this variability. If poorly understood, the IPO-PDO phenomenon could present a significant threat to the security of water resources. This study develops a new combined palaeoclimate IPO (CPIPO) index using multiple sources of palaeoclimate data from around the Pacific basin, in order to better characterise low frequency Pacific Ocean variability (IPO-PDO) going back around 440 years. The resulting distribution of IPO-PDO run-lengths has a mean of 16. 7 years, a mode of 10 - 15 years, a standard deviation of 10. 6 years and 90 % probability limits of 5 and 36 years. The CPIPO was found to be an improvement in representing IPO-PDO variability during the instrumental period in comparison to previous IPO-PDO palaeoclimate reconstructions. The index therefore provides the best available estimate of Pacific decadal climate variability for the last four centuries. Despite this, significant uncertainty still exists in relation to the underlying physical mechanisms and impacts of the IPO-PDO. Further work remains to understand the proportion of the variability in the IPO-PDO run-length distribution that can be attributed to multi-decadal persistence or uncertainty in the multi-decadal persistence. This study does not discount the possibility that an improved understanding of the physical mechanisms of the IPO-PDO, in particular its relation to the El Niño Southern Oscillation, could result in different estimates of the IPO-PDO persistence structure. This study assesses a range of candidate stochastic models for the IPO-PDO. Formal model selection identifies the gamma distribution as a suitable stochastic model for the simulation of IPO-PDO run-lengths. In doing so, this study shows that the widely-used Hidden State Markov (HSM) model and related Markov family models with their monotonically decreasing run-length probability density and mode at one are structurally inappropriate for the simulation of quasi-periodic data such as the run-lengths of the IPO-PDO. This study then develops a general framework for incorporating modes of climate variability into stochastic hydrological models. The framework, termed the climate-informed multi-time time scale stochastic (CIMSS) framework, utilises Bayesian hierarchical methods to simulate multiple scales of climate mechanisms and their impacts on hydrological data. The physical phenomena operating at multiple time scales are simulated with stochastic models. A stochastic model for seasonal rainfall is then developed that incorporates the decadal-scale climate variability of the IPO-PDO. Spatial and temporal characteristics of the impacts of the IPO-PDO are investigated in detail using a range of statistics based on Australia-wide gridded data and site data from 22 stations on the east coast of Australia. A Bayesian methodology is used to infer the joint posterior distribution of the CIMSS framework parameters and therefore provide a reliable estimate of parameter uncertainty. The CIMSS approach is compared to the non-climate-informed annual AR(1) -BC stochastic model. The AR(1) -BC model is unable to adequately capture the observed rainfall distribution within separate IPO-PDO states. Therefore, due to the CIMSS model’s ability to capture decadal-scale climate variability, the climate-informed approach is shown to be an advance over non-climate-informed stochastic rainfall models. The impacts of decadal-scale hydrological variability on water supply drought risk are then investigated. A nonparametric k-nearest neighbour (kNN) sampling approach is used to transform simulated rainfall into reservoir inflows. The design storage capacity of a fictional reservoir in the Hunter region of NSW is determined using a traditional long-term mean drought risk approach based on typical drought security and reliability criteria. A new method for assessing short-term conditional water supply drought risk is developed. This approach represents an advance on previous position analysis approaches as it explicitly incorporates the influence of a climate mechanism in the drought risk estimates, in this case the IPO-PDO. A time-based drought risk threshold equal to the annual demand is advocated over absolute levels, since this is considered to be more amenable to planning decisions which can be time-limited. When the drought risk simulations are conditioned to enter an IPO-PDO positive phase, the CIMSS-modelled short-term risks are significantly higher than those for the annual AR(1) -BC model, with higher risk persisting for up to 20 - 25 years for the CIMSS model. The AR(1) -BC model, with no explicit mechanism to incorporate climate information, does not capture this hydrological variability. The CIMSS model better depicts the hydrological impacts of Pacific decadal-scale climate variability. Since current drought risk evaluation approaches do not explicitly incorporate knowledge of climate mechanisms they could be significantly underestimating the risks of water supply system failure. This result could be of serious concern to water resource planners seeking to provide adequate drought security to growing populations. This study illustrates the value of stochastic rainfall models that are informed by climate data in addition to the hydrological record, as well as the value of the short-term conditional drought risk approach. The CPIPO index, CIMSS model and short-term drought risk approach introduced in this study together provide a new opportunity for better understanding the risks to water supply systems from large-scale climate mechanisms...|$|E
40|$|Optimization of runoff {{agriculture}} {{involves the}} selection of a crop whose water requirements correspond to the precipitation patterns of the area; {{the selection of}} a runoff treatment which, when applied to the catchment area, produces the greatest amount of water at the lowest cost; and the establishment of the ratio of catchment area to crop area. A model is presented which utilizes linear programming and watershed cropland simulation to select the best suited crop and runoff treatment for the system being considered. The model is then modified to determine the optimum catchment area ratio to be used. The model was applied to the reclaimed coal mine lands on the Black Mesa of northern Arizona. Results show that maximum economic returns can be obtained for conventional irrigated agriculture by using a ratio of 55 acres of catchment area with no runoff treatment to one acre of cropland producing corn. The use of <b>carry-over</b> pond <b>storage</b> to allow for supplemental irrigation is prohibited due to high evaporation rates on the Black Mesa. By reducing the corn crop density from the conventional 20, 000 plants per acre to 5, 000 plants per acre, the catchment area ratio can be reduced to an apparent ratio of 13 : 1. Hopi Indian farmers on the Black Mesa use a density of 5, 000 plants per acre for cultivating a highly adapted strain of Indian corn...|$|R
40|$|Although {{regenerating}} forests make up {{an increasingly}} {{large portion of}} humid tropical landscapes, comparatively little is known of their water use and effects on streamflow (Q). Since the 1950 s the island of Puerto Rico has experienced widespread abandonment of pastures and agricultural lands, followed by forest regeneration. This paper examines the possible impacts of forest regeneration on several Q metrics for 12 meso-scale catchments (23 – 346 km 2; mean precipitation 1720 – 3422 mm yr − 1) with long (33 – 51 yr) and simultaneous records for Q, precipitation (P), potential evapotranspiration (PET), and land cover. A simple spatially-lumped, conceptual rainfall-runoff model that uses daily P and PET time series as inputs (HBV-light) was used to simulate Q for each catchment. Annual time series of observed and simulated values of four Q metrics were calculated. A least-squares trend was fitted through annual time series of the residual difference between observed and simulated time series of each Q metric. From this the total cumulative change Â was calculated, representing the change in each metric after controlling for climate variability and water <b>storage</b> <b>carry-over</b> effects between years. Negative values of Â were found for most catchments and Q metrics, suggesting enhanced actual evapotranspiration overall following forest regeneration. However, correlations between changes in urban or forest area and values of Â were insignificant (p ≥ 0. 389) for all Q metrics. This suggests there is no convincing evidence that changes in the chosen Q metrics in these Puerto Rican catchments can be ascribed to changes in urban or forest area. The present results {{are in line with}} previous studies of meso- and macro-scale (sub-) tropical catchments, which generally found no significant change in Q that can be attributed to changes in forest cover. Possible explanations for the apparent lack of a clear signal may include: errors in the land-cover, climate, Q, and/or catchment boundary data; changes in forest area occurring mainly in the less rainy lowlands; and heterogeneity in catchment response. Different results were obtained for different catchments, and using a smaller subset of catchments could have led to very different conclusions. This highlights the importance of including multiple catchments in land-cover impact analysis at the meso scale...|$|R
40|$|Horton {{overland}} runoff, Dunne overland runoff and {{subsurface flow}} {{are the three}} major runoff generation mechanisms contributing to streamflow. The control of the climatic conditions and landscape properties on the occurrence and relative dominance of these different runoff components, i. e., and therefore the runoff partitioning, is captured in a qualitative manner by the famous Dunne Diagram. However, an improved, quantitative understanding of the controls runoff partitioning at the catchment scale is necessary to constrain and improve hydrological predictions at catchment scale, especially in ungauged catchments. This dissertation systematically investigates the controls of climate, soil and topography on runoff partitioning at the catchment scale, and consequent of runoff partitioning on the transportation of water and nutrients, using both the downward and upward approaches. In the downward approach, given observed patterns at some higher level, we look for the most possible process interactions at a lower level that might have led to them. In the upward approach, knowing the processes at a lower level or scale, we explore how their interactions may have lead to the observed patterns {{at a higher level}} or scale. In the first example, a large catchment scale distributed model has been applied to two basins in Oklahoma, the Illinois River basin near Tahlequah and Blue River basin near Blue. After validating the model against observed streamflow data, the model is used as a tool to diagnose the controlling factors underlying the temporal and spatial pattern of runoff partitioning. It is found that in both basins there is a competition between Dunne runoff and subsurface flow, and this competition is quantitatively shown to be controlled by the seasonality of climatic forcing, and the relative magnitudes of the saturated hydraulic conductivity of the soils and the topographic slope. The effects of the spatial trend of runoff partitioning are thus examined in terms of signatures of runoff response derived from the predictions of the same hydrological model. The signatures are mainly constructed at the event scale, such as instantaneous response function which describes the advection and dispersion effect of catchment on generated runoff. Dimensionless flood peak and time-to-peak are used to explore the advection and dispersion separately. The results in this work are on the one hand consistent with previous theoretical studies, {{and on the other hand}} also somewhat surprising. For example, the power-law relationship between peak of the IRF and drainage area is seen to become flatter under wet conditions than under dry conditions, even though the (faster) saturation excess mechanism is more dominant under wet conditions. This result appears to be caused by partial area runoff generation: under wet conditions, the fraction of saturation area is about 30 %, while under dry conditions it is less than 10 % for the same input of rainfall. This means travel times associated with overland flow (that mostly contributes to the peak and time to peak) are in fact longer under wet conditions than during dry conditions. We go further to explore the possible controlling factors of runoff partitioning in a broader context with the use of an upward diagnostic approach. In this case, a simple highly distributed hydrologic model based on point scale processes has been built for this purpose, which is comprehensive enough to simulate the effects of different combinations of climate, soil and topography, and generate a diversity of runoff generation mechanisms. With this model numerous virtual experiments have been conducted to produce a variety of runoff responses under various climate, soil and topographic combinations. A small set of dimensionless similarity numbers, which are physically meaningful, have been shown to effectively quantify runoff partitioning at both the annual and catchment scales. A few hypothetical relationships have been proposed. Each combination of these dimensionless numbers could be feasible in theory, but only some of these combinations actually occur in nature. By constraining the predictions of the model with the empirical Budyko curve, we narrow down to these feasible or ???behavioral??? combinations, which are further governed by close interconnections between climate, soil and topography. Based on the above diagnostic analysis of runoff partitioning, we then investigate the transportation of different runoff components from their locations of generation all the way to the catchment outlet, which is shown to be effectively quantified in terms of the mean residence time (to account for the advection effect) and dimensionless catchment instantaneous response function (IRF, to account for the dispersion effect) for each runoff component. In addition, the consequent impacts of runoff partitioning on the transportation of nutrients (nitrogen and phosphorous, and sediments) have been studied at an agricultural basin with extensive tile drains, The Upper Sangamon River basin located in central Illinois. It is found that there is a <b>carry-over</b> of nitrogen <b>storage</b> from dry years to wet years, and this is mainly caused by the loading of NO 3 -N from the hillslope to the channel by way of tile drainage that is prevalent in this region. From this dissertation, the resulting improved understanding of the controls and subsequence of runoff partitioning at the catchment scale, especially the quantitative description of runoff partitioning in terms of the inter-connections between climate, soil and topography, could be potentially tested in the field, and if deemed reasonable, could also be used to constrain/improve hydrological model predictions, and advance water resources management in a context of both water quantity and quality...|$|R

