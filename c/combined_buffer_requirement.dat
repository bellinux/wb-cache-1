0|564|Public
40|$|The {{article is}} devoted to the {{analysis}} of the enhancement to the Basel III framework in the Ukrainian banking sector. The package of reforms offered by the Basel Committee on Banking Supervision is investigated. The author has defined the difficulties to implementation Basel III capital requirements to Ukrainian banking sector in conditions of growing economic instability. The rate of <b>combined</b> <b>buffer</b> <b>requirements</b> for Ukrainian banks’ absorbing ability has been given more exactly. Out of minimum total capital was assessed to mitigate the systemic risks in the Ukrainian banking sector. The proposals for strengthening of prudential supervisory activity were suggested by author to raising the resilience of the financial system of Ukraine and prediction of regulatory arbitrage...|$|R
40|$|A {{primary concern}} in all {{adaptive}} networks {{is the cost}} of deadlock prevention. While wormhole routing can be considered superior to other routing schemes when looked at in terms of low latency <b>combined</b> with low <b>buffer</b> <b>requirements,</b> it makes the deadlock issue more complex to resolve, as packets of a single message can block several links at the same time. Because planar-adaptive routing limits routing freedom to two dimensions at a time, it makes it possible to prevent deadlock with only a fixed number of virtual channels, independent of the number of network dimensions. In this essay, i will study two planar-adaptive schemes (the Chien and Kim’s algorithm and the turn model) i...|$|R
40|$|In this paper, we {{investigate}} the <b>buffer</b> <b>requirement</b> {{to support a}} set of continuous media playbacks and develop an algorithm which dynamically changes the service mode of the playback to minimize the total <b>buffer</b> <b>requirement.</b> A certain amount of memory buffer is required in continuous media playback to synchronize the asynchronous disk I/O and synchronous playback operation. The most serious problem is {{the rate of increase}} in <b>buffer</b> <b>requirement</b> as disk utilization reaches 100 %. We argue that in a large scale VOD server, where user access pattern is skewed, a certain playback can use the data blocks loaded by the preceding playback for the same file, and thus achieving less <b>buffer</b> <b>requirement.</b> We have developed an efficient algorithm to determine the service mode of each request...|$|R
30|$|One of the {{earliest}} approach proposed for routing in partitioned networks is epidemic routing [3]. However, it is very expensive in terms of message traffic and buffer space, which reduces {{the life of the}} network. To overcome the problem of heavy traffic and high <b>buffer</b> <b>requirement,</b> probabilistic routing [4, 5] and social routing [6 - 10] schemes were proposed. Both the approaches provide considerable improvement in the delivery ratio under low <b>buffer</b> <b>requirement.</b>|$|R
40|$|In this paper, {{we address}} the problem of {{minimizing}} <b>buffer</b> storage <b>requirement</b> in <b>buffer</b> binding for SDF (Synchronous Dataflow) graphs. First, we propose a new two-port FIFO buffer structure that can be efficiently shared by two producer/consumer pairs. Then we propose a buffer binding algorithm based on this two-port buffer structure for minimizing the <b>buffer</b> size <b>requirement.</b> Experimental results demonstrate 9. 8 %~ 37. 8 % improvement in <b>buffer</b> <b>requirement</b> compared to the conventional approaches...|$|R
40|$|This paper {{considers}} reliable {{data transfer}} in a high-speed network (HSN) {{in which the}} per-connection capacity is very large. We focus on sliding window protocols employing selective repeat for reliable data transfer and study two reliability mechanisms based on ARQ and FEC. The question we ask is which mechanism is more suitable for an HSN in which the scalability of reliable data transfer in terms of receiver's <b>buffer</b> <b>requirement</b> and achievable delay and throughput is a concern. To efficiently utilize the large bandwidth available to a connection in an HSN, sliding window protocols require a large transmission window. In this regime of large transmission windows, we show that while both mechanisms achieve the same asymptotic throughput {{in the presence of}} packet losses, their delay and <b>buffer</b> <b>requirements</b> are different. Specifically, an FEC-based mechanism has delay and receiver's <b>buffer</b> <b>requirement</b> that are asymptotically smaller than that of an ARQ-based selective repeat mechanism by a factor of log W, where W is the window size of the selective repeat mechanism. This result is then used to investigate the implications of each reliability mechanism on protocol design in an HSN in terms of throughput, delay, <b>buffer</b> <b>requirement,</b> and control overhead...|$|R
40|$|In this paper, we {{analyze the}} effects of delay jitter on {{receiver}} <b>buffer</b> <b>requirements</b> in distributed Videoon -Demand systems. We use a general purpose realtime producer-consumer model to describe the distributed architecture of a Video-on-Demand system. We prove a Theorem that states {{that the amount of}} data in the receiver buffer is linear in network delay jitter. We present necessary conditions for preventing buffer overflow and underflow situations. Finally, we show through numerical analysis that controlling network delay jitter results in reducing <b>buffer</b> <b>requirements</b> at the receiver. Keywords: Distributed VoD, Network Performace Parameters, <b>Buffer</b> <b>Requirements</b> 1 Introduction The next generation of distributed Video-onDemand (VoD) systems will be supported by different combinations of high speed networks, high capacity storage devices, and powerful workstations and PCs. A typical VoD architecture consists of three subsystems: a real-time producer of synchronized multimedia data, a [...] ...|$|R
40|$|In {{this paper}} we analyze {{the effect of}} {{reshaping}} traffic using various network service disciplines on Videoon -Demand (VoD) applications. Using a client centric approach we develop a methodology based on a realtime producer-consumer framework. We present an anlytical model of client <b>buffer</b> <b>requirements</b> in presence of network delay bounds and delay jitter bounds. We show through numerical analysis that controlling delay jitter not only reduces <b>buffer</b> <b>requirements</b> but also provides the option of accomodating heterogenous clients with different buffer sizes for the same server transmission schedule. Keywords: Distributed VoD, Network Performace Parameters, <b>Buffer</b> <b>Requirements</b> 1 Introduction In this paper, we analyze the effect of traffic reshaping using various network service disciplines on Video-on-Demand (VoD) application. We model a distributed VoD system with servers and high speed networks using real-time producer-consumer approach. The model is general enough to accomodate any d [...] ...|$|R
40|$|In a single-chip digital color imaging sensor, a {{color filter}} array (CFA) {{is used to}} obtain sampled {{spectral}} components (red, green and blue) in an interleaved fashion. Color demosaicing {{is the process of}} interpolating these regularly spaced sampled values into a dense pixel map for each spectral component. In this paper we present two new color interpolation techniques with low <b>buffer</b> <b>requirements</b> for processing while developing color images with very good quality. We also present a comparative study with other interpolation techniques of similar <b>buffer</b> <b>requirements...</b>|$|R
40|$|We {{address the}} problem of {{real-time}} streaming applications scheduling on hybrid CPU/FPGA architectures. The main contribution is a two-step approach to minimize the <b>buffer</b> <b>requirement</b> for streaming applications with throughput guarantees. A novel declarative way of constraint based scheduling for real-time hybrid SW/HW systems is proposed, while the application throughput is guaranteed by periodic phases in execution. We use a voice-band modem application to exemplify the scheduling capabilities of our method. The experimental results show the advantages of our techniques in both less <b>buffer</b> <b>requirement</b> and higher throughput guarantees compared to the traditional PAPS method...|$|R
40|$|In this paper, we {{consider}} the scheduling problem where data packets from K input flows need to be delivered to K corresponding wireless receivers over a heterogeneous wireless channel. Our objective is to design a wireless scheduler that optimizes the <b>buffer</b> <b>requirement</b> at each wireless receiver while maintaining good throughput and fairness performance. This is a challenging problem due to the unique characteristics of the wireless channel. We propose a novel idea of exploiting both the long-term and short-term error behavior of the wireless channel in the scheduler design. In addition to typical first-order Quality of Service (QoS) metrics such as throughput and delay, our performance analysis of the scheduler permits the evaluation of higher-order metrics, which are needed to evaluate the <b>buffer</b> <b>requirement.</b> We show that variants of the proposed scheduler can achieve high overall throughput or fairness as well as low <b>buffer</b> <b>requirement</b> {{when compared to other}} wireless schedulers that only make use of the instantaneous channel state in a heterogenous channel...|$|R
40|$|TCP {{is one of}} {{the most}} widely used {{transport}} protocols for video streaming. However, the rate variability of TCP makes it difficult to provide good video quality. To accommodate the variability, video streaming applications require receiver-side buffering. In current practice, however, there are no systematic guidelines for the provisioning of the receiver buffer, and smooth playout is insured through over-provisioning. In this work, we are interested in memory-constrained applications where it is important to determine the right size of receiver buffer in order to insure a prescribed video quality. To that end, we characterize video streaming over TCP in a systematic and quantitative manner. We first model a video streaming system analytically and derive an expression of receiver <b>buffer</b> <b>requirement</b> based on the model. Our analysis shows that the receiver <b>buffer</b> <b>requirement</b> is determined by the network characteristics and desired video quality. Experimental results validate our model and demonstrate that the receiver <b>buffer</b> <b>requirement</b> achieves desired video quality...|$|R
50|$|Write {{combining}} (WC) allows {{data to be}} temporarily {{stored in}} write <b>combine</b> <b>buffers</b> (WCB) and released in burst mode instead of writing single bits.|$|R
40|$|Virtual Circuit (VC) is well {{recognized}} as being capable to provide guaranteed services in both latency and bandwidth. We propose {{a method of}} modeling TDM based VC by using Network Calculus. We derive a tight upper bound of end-to-end delay and <b>buffer</b> <b>requirement</b> for indivdual VC. The performance analysis using Latency-Rate server is also presented in comparsion with our Performance model for TDM Virtual Circuit in NoCs (Pemvin). We conducted experiments on comparing Pemvin to the Latency-Rate server model. Our experiment results show the improvement of Pemvin on tightening the upper bound of end-to-end delay and <b>buffer</b> <b>requirement.</b> ...|$|R
40|$|Land Application Setback and <b>Buffer</b> <b>Requirements</b> for NPDES Permitted Large CAFOs Large Concentrated Animal Feeding Operation (CAFO) owners/operators are {{required}} to implement setbacks, buffers, or an alternative conservation practice on all fields to which manure is applied. This newsletter discusses the federal rules and some guidance on how the rule may be applied to land application sites. The setbacks and <b>buffer</b> <b>requirements</b> apply to large CAFOs only. Most states are authorized to implement the CAFO program and may have additional, more stringent requirements. Check with your state permitting authority to determine the requirements that apply to your operation...|$|R
40|$|In this paper, we {{consider}} the scheduling problem where data packets from K input-flows need to be delivered to K corresponding wireless receivers over a heterogeneous wireless channel. Our objective is to design a wireless scheduler that achieves good throughput and fairness performance while minimizing the <b>buffer</b> <b>requirement</b> at each wireless receiver. This is a challenging problem due to the unique characteristics of the wireless channel. We propose a novel idea of exploiting both the long-term and short-term error behavior of the wireless channel in the scheduler design. In addition to typical first-order Quality of Service (QoS) metrics such as throughput and average delay, our performance analysis of the scheduler permits the evaluation of higher-order metrics, which are needed to evaluate the <b>buffer</b> <b>requirement.</b> We show that variants of the proposed scheduler can achieve high overall throughput or fairness as well as low <b>buffer</b> <b>requirement</b> {{when compared to other}} wireless schedulers that either make use only of the instantaneous channel state or are channel-state independent in a heterogenous channel...|$|R
30|$|Remark 4 : The leaky bucket {{regulators}} and aggregators do not increase the upper bounds on buffer queue length/delay/effective bandwidth of a sensor node, and {{also do not}} increase the <b>buffer</b> <b>requirements</b> of the sensor node.|$|R
40|$|We propose (σ, ρ) -based flow {{regulation}} as {{a design}} instrument for System-on-Chip (SoC) architects to control quality-of-service and achieve cost-effective communication, where σ bounds the traffic burstiness and ρ the traffic rate. This regulation changes the burstiness {{and timing of}} traffic flows, {{and can be used}} to decrease delay and reduce <b>buffer</b> <b>requirements</b> in the SoC infrastructure. In this paper, we define and analyze the regulation spectrum, which bounds the upper and lower limits of regulation. Experiments on a Network-on-Chip (NoC) with guaranteed service demonstrate the benefits of regulation. We conclude that flow regulation may exert significant positive impact on communication performance and <b>buffer</b> <b>requirements...</b>|$|R
40|$|International audienceIn Network-on-Chip (NoC), Time-Division-Mutiplexing (TDM) Virtual Circuit (VC) is well {{recognized}} as being capable to provide guaranteed services in both latency and bandwidth. We propose {{a method of}} modeling TDM based VC by using Network Calculus. We derive a tight upper bound of end-to-end delay and <b>buffer</b> <b>requirement</b> for indivdual VC. The performance analysis using Latency-Rate server is also presented in comparsion with our Performance model for TDM Virtual Circuit in NoCs (Pemvin). We conducted experiments on comparing Pemvin to the Latency-Rate server model. Our experiment results show the improvement of Pemvin on tightening the upper bound of end-to-end delay and <b>buffer</b> <b>requirement...</b>|$|R
40|$|Abstract: This paper first {{presents}} an analysis model named flow-competing congestion model (FCCM) {{for this type}} of congestion. Based on FCCM, the paper derives the distribution of competing flows at the congested link, and analyzes the conditions under which the flow-competing congestion would happen. This paper also explores how much buffers a congested link requires to keep full link utilization when the flow-competing congestion occurs. This paper proves that when sizing buffers for a congested internet link with the aim of keeping full link utilization, the <b>buffer</b> <b>requirement</b> of the flow-competing congestion is not bigger than the minimum <b>buffer</b> <b>requirement</b> of the famous BSCL (buffer sizing for congested internet links) scheme...|$|R
40|$|Abstract—We propose (σ, ρ) -based flow {{regulation}} as {{a design}} instrument for System-on-Chip (SoC) architects to control quality-of-service and achieve cost-effective communication, where σ bounds the traffic burstiness and ρ the traffic rate. This regulation changes the burstiness {{and timing of}} traffic flows, {{and can be used}} to decrease delay and reduce <b>buffer</b> <b>requirements</b> in the SoC infrastructure. In this paper, we define and analyze the regulation spectrum, which bounds the upper and lower limits of regulation. Experiments on a Network-on-Chip (NoC) with guaranteed service demonstrate the benefits of regulation. We conclude that flow regulation may exert significant positive impact on communication performance and <b>buffer</b> <b>requirements.</b> I...|$|R
40|$|Famous rule-of-thumb {{states that}} a buffer sized at B = RT T × BW, where RTT {{is the average}} round trip time and BW is the {{bandwidth}} of output link is {{necessary in order to}} achieve high utilization with TCP flows. However, as the link speeds continue increasing with technological advances, this <b>buffer</b> <b>requirement</b> starts becoming an important cost factor on routers of electronic networks. On the other hand, bursty nature of TCP limits further decreasing the <b>buffer</b> <b>requirements,</b> because it brings a very high packet drop rate in small buffered networks. In this paper, we evaluate several transmission control algorithms in small buffered networks. The algorithms include TCP Reno, TCP NewReno, Highspeed TCP with SACK, an...|$|R
40|$|In many {{applications}} of sensor networks, {{it is essential}} to ensure that messages are transmitted to their destinations as early as possible and the buffer size of each sensor node is as small as possible. In this paper, we firstly propose a mesh sensor network system model. Based on this system model, the expressions for deriving the delay bound and <b>buffer</b> <b>requirement</b> bound are presented using network calculus. In order to balance traffic load and improve resource utilization, three traffic splitting mechanisms are proposed. The numerical results show that the delay bound and <b>buffer</b> <b>requirement</b> bound are lowered while applying those traffic splitting mechanisms. And thus the performance of the whole sensor network is improved. 1...|$|R
40|$|The routing and {{signaling}} protocols {{for supporting}} multipoint-to-multipoint connections in ATM networks {{have been presented}} earlier. VP-Merge and VC-Merge techniques have been proposed as the likely candidates for resolving the sender identification problem associated with these connections. The additional <b>buffer</b> <b>requirements</b> in the VC-Merge mechanism and the excessive use of VPI/VCI space in the VP-Merge mechanism have been {{the main reasons for}} concern about their effective utility. In this paper, we propose improvements to the traditional VC-Merge technique to minimize the need for additional buffers at intermediate merge points. Aptly named Dynamic Multiple VCMerge (DMVC), Fixed Multiple VC-Merge (FMVC) and Selective Multiple VC-Merge (SMVC), these mechanisms define a generic scheme for merging the data from multiple senders onto one or more outgoing links. By appropriately choosing the number of connection identifiers per connection, these schemes lead to a large reduction in the <b>buffer</b> <b>requirements</b> and an effective utilization of the VPI/VCI space. Based on extensive simulations, we show that by using two connection identifiers per connection, there is an 80 % reduction in <b>buffer</b> <b>requirements</b> for DMVC and FMVC when compared to the buffer required for traditional VC-Merge...|$|R
30|$|Remark 9 : The fractal leaky bucket {{regulators}} and aggregators do not in-crease the upper bounds on buffer queue length/delay and the <b>buffer</b> <b>requirements</b> of a sensor node, {{and do not}} increase the upper bounds on single-hop/multi-hops delay/jitter/effective bandwidth of the WSNs.|$|R
40|$|Abstract-With the {{advancement}} of broadband networking technology, many clients are enabled to enjoy various Video on Demand (VoD) services. To provide VoD services {{to a number of}} clients, the network needs to consider various factors together; they are each viewer’s waiting time, <b>buffer</b> <b>requirement</b> at the client, channel management for video delivery, and complexity for video segmentation. Among the currently available VoD approaches, the Polyharmonic broadcasting approach and the staircase multicasting approach show the best performance in terms of viewer’s waiting time and <b>buffer</b> <b>requirement,</b> respectively. However, these approaches need to divide a video into too many segments, and require many channels at a time. To overcome these limitations, we propose Polyharmonic-Staircase-Staggered (PSS) multicasting approach which combines the Polyharmonic scheme with the staircase scheme. It is simple and bandwidth efficient. The numerical results demonstrate that each viewer’s waiting time in our approach is comparable to that in the polyharmonic approach, at the cost of a slight increase in bandwidth <b>requirement,</b> and its <b>buffer</b> <b>requirement</b> is about 60 % less than that in the staircase approach by simply adjusting the front part of video segmentation. More importantly, our approach shows the best performance in number of channels to be managed and used simultaneously, which is a critical factor in real deployment. I...|$|R
30|$|Authors in [25] {{analyze the}} {{overhead}} associated with FMIPv 6 including the signaling cost and the packet delivery cost. They also compare FMIPv 6 with MIPv 6 {{in terms of}} packet loss rates and <b>buffer</b> <b>requirements.</b> However, handoff latency {{and the impact of}} user mobility models are not investigated.|$|R
40|$|The server array {{is a novel}} {{video server}} {{architecture}} based on partitioning each video over multiple server nodes, thereby achieving perfect load balancing for any demand distribution. We discuss the main design issues, compute the <b>buffer</b> <b>requirements</b> at the client, and compare the reliability of different video server architectures...|$|R
40|$|ATM (asynchronous {{transfer}} mode) is {{the technology}} {{chosen for the}} Broadband Integrated Services Digital Network (B-ISDN). The ATM ABR (available bit rate) service {{can be used to}} transport ``best-effort'' traffic. In this paper, we extend our earlier work on the <b>buffer</b> <b>requirements</b> problem for TCP over ABR. Here, a worst case scenario is generated such that TCP sources send a burst of data at the time when the sources have large congestion windows and the ACRs (allowed cell rates) for ABR are high. We find that ABR using the ERICA+ switch algorithm can control the maximum queue lengths (hence the <b>buffer</b> <b>requirements)</b> even for the worst case. We present analytical arguments for the expected queue length and simulation results for different number of sources values and parameter values. Comment: SICON' 98, June 9...|$|R
40|$|Many packet schedulers for QoS {{networks}} {{are equipped with}} a rate control mechanism. The function of a rate control mechanism (rate controller) is to buffer packets from flows which exceed their negotiated traffc profile. It has been established that rate controllers lead to reduced <b>buffer</b> <b>requirements</b> at packet switches, and do not increase the worst-case delays in a deterministic service. On the other hand, rate controllers make a scheduler non-workconserving, and, thus, may yield higher average end-to-end delays. In this study, we show that by properly modifying a rate controller, one can design a scheduler which balances <b>buffer</b> <b>requirements</b> against average delays. We present a scheduler, called Earliness-based Earliest Deadline First (EEDF), which achieves such a balancing using a tunable rate control mechanism. In simulation experiments, we compare EEDF with a rate-controlled EDF scheduler and a workconserving version of EDF...|$|R
40|$|Abstract We {{analyze the}} {{intermediate}} <b>buffer</b> <b>requirements</b> in a tandem queue where service times of each customer are deterministically correlated between the servers, and arbitrarily distributed between customers. The major {{issue at hand}} is determination of intermediate buffer sizes assuring no blocking when the arrivals pattern is arbitrary and unpredictable. The analysis shows that the worst arrival process is the Just In Time (JIT) process. Further, it shows that ordering of the servers with respect to service rates may be detrimental and that the most vulnerable architectural design is that in which the servers have almost the same service rates. It is shown that the total <b>buffer</b> <b>requirement</b> in the system may be quite sensitive to the server ordering: A proper ordering requires just O(M) (where M {{is the number of}} queues) buffer size while an improper ordering may require O(M 2) ...|$|R
50|$|Write {{combining}} (WC) is {{a computer}} bus technique for allowing data to be combined and temporarily stored in a buffer — the write <b>combine</b> <b>buffer</b> (WCB) — to be released together later in burst mode instead of writing (immediately) as single bits or small chunks.|$|R
3000|$|Node buffer size, b: since G-ER, {{similar to}} ER, is a {{replication}} or flooding-based DTN protocol, {{we are interested}} to see how sensitive G-ER is to b. Therefore, {{in order to show}} how much G-ER can lower the <b>buffer</b> <b>requirement</b> for the delivery of all packets, ER is used for comparison [15, 16, 18].|$|R
40|$|A {{modified}} selective automatic-repeat-request (S-ARQ) {{scheme is}} proposed as an error-correction scheme for the NASA ground communication facility upgrade communications system. The operation of this scheme is presented {{and illustrated by}} examples. An analysis of queue and <b>buffer</b> <b>requirements</b> for this scheme is also presented. Numerical examples are provided to demonstrate {{the performance of the}} proposed algorithm. link_to_subscribed_fulltex...|$|R
40|$|Current {{algorithms}} for schedulability {{analyses of}} the worst case delay and worst case <b>buffer</b> <b>requirements</b> for real-time network traffic have made one of two assumptions. 1) The networks are rate controlled (i. e. the source traffic pattern is reconstructed at each node) or 2) Traffic from multiple channels sharing a physical link can arrive simultaneously. This paper presents analysis which removes the restriction of the first assumption and reduces the calculated worst case delay and <b>buffer</b> <b>requirements</b> by replacing the second assumption with a more accurate network node model. 1 Introduction A major challenge to broadband networks {{is the ability to}} support the loss, delay and delay variation (jitter) requirements of real-time traffic. Existing best effort network designs can not guarantee that quality of service (QOS) specifications which rely on these requirements can be maintained. Connection oriented, virtual channel networks using connection admission control and traffic polici [...] ...|$|R
50|$|The Nanda Devi National Park and Valley of Flowers National Parks is an UNESCO World Heritage Site in Uttarakhand, India. It {{possesses}} of two {{core areas}} about 20km apart, {{made up by}} the Nanda Devi National Park and the Valley of Flowers National Park, plus an encompassing <b>Combined</b> <b>Buffer</b> Zone.|$|R
