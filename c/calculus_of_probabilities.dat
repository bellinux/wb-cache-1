22|10000|Public
2500|$|In 1654, {{prompted}} {{by his friend}} the Chevalier de Méré, he corresponded with Pierre de Fermat {{on the subject of}} gambling problems, and from that collaboration was born the mathematical theory of probabilities. The specific problem was that of two players who want to finish a game early and, given the current circumstances of the game, want to divide the stakes fairly, based on the chance each has of winning the game from that point. [...] From this discussion, the notion of expected value was introduced. Pascal later (in the Pensées) used a probabilistic argument, Pascal's Wager, to justify belief in God and a virtuous life. The work done by Fermat and Pascal into the <b>calculus</b> <b>of</b> <b>probabilities</b> laid important groundwork for Leibniz' formulation of the calculus.|$|E
60|$|On {{the other}} side, though the writer knows {{several people who}} have 'seen ghosts' in haunted houses, and other odd phenomena, he knows nobody, at first hand, who has seen a 'veridical hallucination,' or rather, knows only one, a very young one indeed. Thus, between these {{personally}} collected statistics of spectral 'sells' on one part, and the world-wide diffusion of belief in 'coincidental' hallucination on the other, the human mind is left in a balance which mathematics, and the <b>Calculus</b> <b>of</b> <b>Probabilities</b> (especially if one does not understand it) fail to affect.|$|E
60|$|THERE are few persons, {{even among}} the calmest thinkers, who have not {{occasionally}} been startled into a vague yet thrilling half-credence in the supernatural, by coincidences of so seemingly marvellous a character that, as mere coincidences, the intellect {{has been unable to}} receive them. Such sentiments--for the half-credences of which I speak have never the full force of thought--such sentiments are seldom thoroughly stifled unless by reference to the doctrine of chance, or, as it is technically termed, the <b>Calculus</b> <b>of</b> <b>Probabilities.</b> Now this Calculus is, in its essence, purely mathematical; and thus we have the anomaly of the most rigidly exact in science applied to the shadow and spirituality of the most intangible in speculation.|$|E
40|$|This paper shows that, among diverse axiomatic systems (many-valued logics, fuzzy sets, <b>calculus</b> <b>of</b> <b>probability,</b> {{and theory}} <b>of</b> evidence), the <b>calculus</b> <b>of</b> <b>probability</b> uniquely {{provides}} a paradigm able to process uncertainty without violating any classical logic’s law (excluded middle, non-contradiction, and so on). A characterization of this paradigm is outlined in mathematical logic terms, focusing on quantitative treatment of measurement uncertainty...|$|R
2500|$|... 1933– Andrey Nikolaevich Kolmogorov publishes {{his book}} Basic notions <b>of</b> the <b>calculus</b> <b>of</b> <b>probability</b> (Grundbegriffe der Wahrscheinlichkeitsrechnung), which {{contains}} an axiomatization <b>of</b> <b>probability</b> based on measure theory.|$|R
2500|$|This {{result is}} {{completely}} devastating to the inductive interpretation <b>of</b> the <b>calculus</b> <b>of</b> <b>probability.</b> All probabilistic support is purely deductive: {{that part of}} a hypothesis that is not deductively entailed by the evidence is always strongly countersupported by the evidence ... There {{is such a thing}} as probabilistic support; there might even be such a thing as inductive support (though we hardly think so). But the <b>calculus</b> <b>of</b> <b>probability</b> reveals that probabilistic support cannot be inductive support.|$|R
60|$|All these {{drawbacks}} are {{acknowledged to}} exist, and are allowed for, and, {{as far as}} possible, provided against, by the very fair-minded people who have conducted this inquisition. Thus Mr. Henry Sidgwick, in 1889, said, 'I do not think we can be satisfied with less than 50,000 answers'. {195} But these 50,000 answers have not been received. When we reflect that, to our knowledge, out of twenty-five questions asked among our acquaintances in one place, none would {{be answered in the}} affirmative: while, by selecting, we could get twenty-five affirmative replies, the delicacy and difficulty of the inquisition becomes painfully evident. Mr. Sidgwick, after making deductions on all sides of the most sportsmanlike character, still holds that the coincidences are more numerous by far than the <b>Calculus</b> <b>of</b> <b>Probabilities</b> admits. This is a question for the advanced mathematician. M. Richet once made some experiments which illustrate the problem. One man in a room thought of a series of names which, ex hypothesi, he kept to himself. Three persons sat at a table, which, as tables will do, 'tilted,' and each tilt rang an electric bell. Two other persons, concealed from the view of the table tilters, ran through an alphabet with a pencil, marking each letter at which the bell rang. These letters were compared with the names secretly thought of by the person at neither table.|$|E
60|$|It is obvious, too, {{that even}} when the probabilities are derived from {{observation}} and experiment, a very slight improvement in the data, by better observations, or by taking into fuller consideration the special circumstances of the case, is of more use than the most elaborate application of the calculus to probabilities founded on the data in their previous state of inferiority. The neglect of this obvious reflection {{has given rise to}} misapplications of the <b>calculus</b> <b>of</b> <b>probabilities</b> which have made it the real opprobrium of mathematics. It is sufficient to refer to the applications made of it to the credibility of witnesses, and to the correctness of the verdicts of juries. In regard to the first, common sense would dictate {{that it is impossible to}} strike a general average of the veracity and other qualifications for true testimony of mankind, or of any class of them; and even if it were possible, the employment of it for such a purpose implies a misapprehension of the use of averages, which serve, indeed, to protect those whose interest is at stake, against mistaking the general result of large masses of instances, but are of extremely small value as grounds of expectation in any one individual instance, unless the case be one of those in which the great majority of individual instances do not differ much from the average. In the case of a witness, persons of common sense would draw their conclusions from the degree of consistency of his statements, his conduct under cross-examination, and the relation of the case itself to his interests, his partialities, and his mental capacity, instead of applying so rude a standard (even if it were capable of being verified) as the ratio between the number of true and the number of erroneous statements which he may be supposed to make in the course of his life.|$|E
60|$|For, {{in respect}} to the latter branch of the supposition, it should be {{considered}} that the most trifling variation in {{the facts of the}} two cases might give rise to the most important miscalculations, by diverting thoroughly the two courses of events; very much as, in arithmetic, an error which, in its own individuality, may be inappreciable, produces, at length, by dint of multiplication at all points of the process, a result enormously at variance with truth. And, in regard to the former branch, we must not fail to hold in view that the very <b>Calculus</b> <b>of</b> <b>Probabilities</b> to which I have referred, forbids all idea of the extension of the parallel:--forbids it with a positiveness strong and decided just in proportion as this parallel has already been long-drawn and exact. This is one of those anomalous propositions which, seemingly appealing to thought altogether apart from the mathematical, is yet one which only the mathematician can fully entertain. Nothing, for example, is more difficult than to convince the merely general reader that the fact of sixes having been thrown twice in succession by a player at dice, is sufficient cause for betting the largest odds that sixes will not be thrown in the third attempt. A suggestion to this effect is usually rejected by the intellect at once. It does not appear that the two throws which have been completed, and which lie now absolutely in the Past, can have influence upon the throw which exists only in the Future. The chance for throwing sixes seems to be precisely as it was at any ordinary time--that is to say, subject only to the influence of the various other throws which may be made by the dice. And this is a reflection which appears so exceedingly obvious that attempts to controvert it are received more frequently with a derisive smile than with anything like respectful attention. The error here involved--a gross error redolent of mischief--I cannot pretend to expose within the limits assigned me at present; and with the philosophical it needs no exposure. It may be sufficient here to say that it forms one of an infinite series of mistakes which arise in the path or Reason through her propensity for seeking truth in detail.|$|E
50|$|His {{main field}} of study was {{philosophy}} of physics, history of science, multi-valued logic and relation of multi-valued logic to <b>calculus</b> <b>of</b> <b>probability.</b>|$|R
40|$|The <b>calculus</b> <b>of</b> <b>probability</b> is {{a branch}} of mathematics. Its {{foundations}} have {{so far not been}} fully investigated. There are, perhaps, many such branches of mathematics, but the <b>calculus</b> <b>of</b> <b>probability</b> is unique among them regarding the specific course of the development of its fundamental principles. This is bound up with what H. Steinhaus calls the “tavern” origin <b>of</b> <b>probability.</b> A theory <b>of</b> gambling games at first, it gradually extended its range of applicability, becoming finally a mathematical theory of great practical and theoretical importance...|$|R
5000|$|... 1935. Wahrscheinlichkeitslehre : eine Untersuchung über die logischen und mathematischen Grundlagen der Wahrscheinlichkeitsrechnung. English translation: 1949, The theory <b>of</b> <b>probability,</b> {{an inquiry}} into the logical and {{mathematical}} foundations <b>of</b> the <b>calculus</b> <b>of</b> <b>probability.</b> University <b>of</b> California Press.|$|R
5000|$|... "The <b>Calculus</b> <b>of</b> <b>Probabilities</b> Applied to Psychic Research, I & II", 1885, 1886, Proceedings of Society for Psychic Research ...|$|E
5000|$|Jean Trembley (1749 [...] - [...] September 18, 1811), born at Geneva, {{contributed to}} the {{development}} of differential equations, finite differences, and the <b>calculus</b> <b>of</b> <b>probabilities.</b>|$|E
50|$|Darmois {{earned his}} {{doctorate}} from the University of Paris in 1921, under supervision of Édouard Goursat. In 1949, he succeeded Maurice René Fréchet on the Chair of <b>Calculus</b> <b>of</b> <b>Probabilities</b> and Mathematical Physics at the University of Paris.|$|E
50|$|This volume {{attempts}} to formulate certain patterns of plausible reasoning. The relation of these patterns with the <b>calculus</b> <b>of</b> <b>probability</b> are also investigated. Their relation to mathematical invention and instruction are also discussed. The following aresome of {{the patterns of}} plausible inference discussed by Polya.|$|R
40|$|Any {{statistical}} observational unit is probabilistic. The <b>probability</b> <b>of</b> such a {{unit has}} to be computed {{on the basis of}} homogeneous data if {{we do not want to}} violate the basic principle <b>of</b> the <b>calculus</b> <b>of</b> <b>probability.</b> The model <b>of</b> the homogeneous representativeness can be employed to test data for homogeneity...|$|R
40|$|Each {{organization}} has among its multiple secondary endpoints subordinated to a centralobjective {{that one of}} avoiding the contingencies. The direct procurement is carried out on themarket in SEAP (Electronic System of Public Procurement), and a performing management in apublic institution has as sub-base and risk management. The risks may be investigated byeconometric simulation, which is calculated by the use <b>of</b> <b>calculus</b> <b>of</b> <b>probability</b> and the sample fordetermining the relevance <b>of</b> these <b>probabilities...</b>|$|R
50|$|In 1928 Fréchet {{decided to}} move back to Paris, thanks to {{encouragement}} from Borel, who was then Chair in the <b>Calculus</b> <b>of</b> <b>Probabilities</b> and Mathematical Physics at the Sorbonne. Fréchet briefly held a position of lecturer at the Sorbonne's Rockefeller Foundation and from 1928 was a Professor (without a Chair). Fréchet was promoted to tenured Chair of General Mathematics in 1933 and to Chair of Differential and Integral Calculus in 1935. In 1941 Fréchet succeeded Borel as Chair in the <b>Calculus</b> <b>of</b> <b>Probabilities</b> and Mathematical Physics, a position Fréchet held until he retired in 1949. From 1928 to 1935 Fréchet was also put in charge of lectures at the École Normale Supérieure; in this latter capacity Fréchet was able to direct a significant number of young mathematicians toward research in probability, including Doeblin, Fortet, Loeve, and Ville.|$|E
50|$|In 1833, {{he became}} a French citizen. His friend Arago, the {{secretary}} of the Académie des sciences helped him obtain professorship at the Collège de France in 1833, succeeding the great mathematician Legendre and in and 1834 he was elected as assistant professor in the <b>calculus</b> <b>of</b> <b>probabilities</b> at the Sorbonne. He was elected to the Academy and given the Légion d'honneur.|$|E
50|$|In 1654, {{prompted}} {{by his friend}} the Chevalier de Méré, he corresponded with Pierre de Fermat {{on the subject of}} gambling problems, and from that collaboration was born the mathematical theory of probabilities. The specific problem was that of two players who want to finish a game early and, given the current circumstances of the game, want to divide the stakes fairly, based on the chance each has of winning the game from that point. From this discussion, the notion of expected value was introduced. Pascal later (in the Pensées) used a probabilistic argument, Pascal's Wager, to justify belief in God and a virtuous life. The work done by Fermat and Pascal into the <b>calculus</b> <b>of</b> <b>probabilities</b> laid important groundwork for Leibniz' formulation of the calculus.|$|E
2500|$|The actual term [...] "central limit theorem" [...] (in German: [...] "zentraler Grenzwertsatz") {{was first}} used by George Pólya in 1920 {{in the title of}} a paper. Pólya {{referred}} to the theorem as [...] "central" [...] due to its importance in probability theory. According to Le Cam, the French school <b>of</b> <b>probability</b> interprets the word central in the sense that [...] "it describes the behaviour of the centre of the distribution as opposed to its tails". The abstract of the paper On the central limit theorem <b>of</b> <b>calculus</b> <b>of</b> <b>probability</b> and the problem of moments by Pólya in 1920 translates as follows.|$|R
5000|$|The {{occurrence}} <b>of</b> the Gaussian <b>probability</b> density [...] in repeated experiments, in {{errors of}} measurements, which {{result in the}} combination of very many and very small elementary errors, in diffusion processes etc., can be explained, as is well-known, by the very same limit theorem, which plays {{a central role in}} the <b>calculus</b> <b>of</b> <b>probability.</b> The actual discoverer of this limit theorem is to be named Laplace; it is likely that its rigorous proof was first given by Tschebyscheff and its sharpest formulation can be found, as far as I am aware of, in an article by Liapounoff. … ...|$|R
3000|$|The <b>calculus</b> <b>of</b> these <b>probabilities</b> {{depends on}} the coding scheme used to design the GLDPC-Staircase code (scheme A or B). Next, we give more details for each case. At {{iteration}} ℓ, the LDPC symbols are erased with probability P [...]...|$|R
50|$|He {{published}} extensively (17 {{papers in}} 1930 alone, according to Lindley) and acquired an international {{reputation in the}} small world of probability mathematicians. He taught mathematical analysis in Padua and then won a chair in Financial Mathematics at Trieste University (1939). In 1954 {{he moved to the}} Sapienza University of Rome, first to another chair in Financial Mathematics and then, from 1961 to 1976, one in the <b>Calculus</b> <b>of</b> <b>Probabilities.</b> De Finetti developed his ideas on subjective probability in the 1920s independently of Frank P. Ramsey. Still, according to the preface of his Theory of Probability, he drew on ideas of Harold Jeffreys, I. J. Good and B.O. Koopman. He only became known in the Anglo-American statistical world in the 1950s when L. J. Savage, who had independently adopted subjectivism, drew him into it; another great champion was Dennis Lindley. De Finetti died in Rome.|$|E
5000|$|In 1880-2, Westergaard {{worked for}} the Danish Insurance Office and he {{developed}} an interest in demography. His international reputation {{was made by the}} publication of Die Lehre von der Mortalität und Morbilität (1881). This work won him a gold medal from the University and led to his appointment as a lecturer in 1883. In 1886, he became a Professor at the early age of 33. He retired in 1924. Westergaard's late work Contributions to the History of Statistics (1932) described the history of vital and economic statistics up {{to the end of the}} nineteenth century. Statistical theory, whether of the Laplace or Pearson variety, is discussed but given a subordinate place. In the Introduction, Westergaard remarks, [...] "For a long while ... the <b>calculus</b> <b>of</b> <b>probabilities</b> had less influence on statistics than might have been expected, the authors confining themselves to abstract theories which had little or nothing to do with reality." ...|$|E
5000|$|Drawing on Canguilhem's work, Foucault {{develops}} {{the notion of}} biopolitics as an open system that is a process free of deterministic relationship. Biopolitics {{can be described as}} when the “basic biological features of the human species became the object of a political strategy of a general strategy of power.” The biopolitics becomes the governmental reason of modern society which Foucault referred as security society. The individualizing technique of the care of the self in the disciplinary society and the totalizing technique of the management of the population through apparatuses of security is called governmentality. The governmental apparatuses of security produce optimum risk or danger, which subjectivize individuals in terms of the care of the self {{and at the same time}} manage the population. Insurance technologies, as an apparatus of security for instance, use a <b>calculus</b> <b>of</b> <b>probabilities</b> that transform everything into risk, but most importantly, it “keep a type of criminality, theft for instance, within socially and economically acceptable limits and around an average that will be considered as optimal for a given social functioning.” [...] Thus, there are two streams of thought in Foucault’s work. The earlier work relates to disciplining or individualizing of the body through the police state. The later thought develops around the notion of biopolitics, as a totalizing technique, that targets the biological given of the population through the apparatus of security. These two techniques, individualizing-totalizing, microphysics-macrophysics, care of the self-management of the population, are the two modalities of power that function in a non-deterministic relationship. It is a model different from Louis Althusser's idea of Ideological State Apparatuses as structure of dominance and hegemony functioning in a top-down manner. In Foucault's work, there is no top-down and bottom-up approach.|$|E
40|$|Newtonian {{deterministic}} mechanichs {{can only}} describe and predict {{the behavior of}} simple natural systems with few components, which represent approximately 10 % of those conforming the universal reality known until now. The remaining 90 %, whose complexity and degree of uncertainty make them practically inaccessible to this approach, require a new holistic or total vision, with an approach that includes concepts of Newton's and Descartes's classical mechanics, as much as those emanated from the indeterministic stream, such as nonlinearity and aleatory sequences, <b>calculus</b> <b>of</b> <b>probability</b> and statistics, chaos and order, exponential instability, quantum Theory, attractors and fractals, and information theory...|$|R
40|$|The hilbert-space {{structure}} {{of quantum mechanics}} {{is related to the}} causal {{structure of}} space-time. The usual measurement hypotheses apparently preclude nonlinear or stochastic quantum evolution. By admitting a difference in the <b>calculus</b> <b>of</b> joint <b>probabilities</b> <b>of</b> events in space-time according to whether the separation is space-like or time-like, a relativistic nonlinear or stochastic quantum theory may be possible...|$|R
40|$|Starting {{from the}} main {{statement}} that “... natural selection is not evolution... ”, R. A. Fisher built {{the foundation of the}} genetic theory of population in his famous work Genetical Theory of Natural Selection (1930). He rewrote the scientific paradigm proposed by Darwin in statistical terms using the <b>calculus</b> <b>of</b> <b>probability</b> and, most importantly, statistics. The key to his formal transposition is in the analysis of variance inwhich Fisher interpreted as phenomenical variability by means of random variability: this completely original result would become a fundamental chapter of statisticalmethod. It is not by chance {{that at the same time}} he published his statistical method for research workers in which the analysis of variance dominated his primary elements of the design of experiments...|$|R
40|$|We {{summarize}} the papers published by Einstein in the Annalen der Physik {{in the years}} 1902 - 04 on the derivation of the properties of thermal equilibrium {{on the basis of}} the mechanical equations of motion and of the <b>calculus</b> <b>of</b> <b>probabilities.</b> We point out the line of thought that led Einstein to an especially economical foundation of the discipline, and to focus on fluctuations of the energy as a possible tool for establishing the validity of this foundation. We also sketch a comparison of Einstein's approach with that of Gibbs, suggesting that although they obtained similar results, they had different motivations and interpreted them in very different ways. Comment: 22 pages, submitted to JS...|$|E
40|$|This article {{responds}} to Paul Bergman and Al Moore 2 ̆ 7 s doubt that ideal triers of facts would be Bayesians. They argue that Bayes 2 ̆ 7 rule, and probability theory in general, fails as a theoretical factfinding model. While probability {{has long been}} an accepted measure of belief in empirical propositions and the validity of inductive arguments, this articles addresses Bergman and Moore 2 ̆ 7 s doubts directly. It shows how their examples demonstrating the 2 ̆ 2 frequentist 2 ̆ 2 character of Bayesian methodology or the fallacies in Bayesian analysis are easily handled without a frequentist interpretation of probability. Then it shows that an ideal juror 2 ̆ 7 s partial beliefs will conform to the <b>calculus</b> <b>of</b> <b>probabilities...</b>|$|E
40|$|By {{analysing}} probabilistic {{foundations of}} quantum theory we {{understood that the}} so called quantum <b>calculus</b> <b>of</b> <b>probabilities</b> (including Born’s rule) is not the main distinguishing feature of “quantum”. This calculus is just a special variant of a contextual probabilistic calculus. In particular, we analysed the EPR-Bohm-Bell approach by using contextual probabilistic models (e. g., the frequency von Mises model). It is demonstrated that the EPR-Bohm-Bell consideration {{are not so much}} about “quantum”, but they are merely about contextual. Our conjecture is that the “fundamental quantum element ” is the Schrödinger evolution describing the very special dependence of probabilities on contexts. The main quantum mystery is neither the probability calculus in a Hilbert space nor the nonncommutative (Heisenberg) representation of physical observables, but the Schrödinger evolution of contextual probabilities. ...|$|E
5000|$|One of the {{hallmarks}} of evolutionary epistemology is the notion that empirical testing alone does not justify the pragmatic value of scientific theories, but rather that social and methodological processes select those theories with the closest [...] "fit" [...] to a given problem. The mere fact that a theory has survived the most rigorous empirical tests available does not, in the <b>calculus</b> <b>of</b> <b>probability,</b> predict its ability to survive future testing. Karl Popper used Newtonian physics {{as an example of a}} body of theories so thoroughly confirmed by testing as to be considered unassailable, but which were nevertheless overturned by Einstein's insights into the nature of space-time. For the evolutionary epistemologist, all theories are true only provisionally, regardless of the degree of empirical testing they have survived.|$|R
30|$|However, {{reckoning}} {{does not}} eliminate dangers in everyday life, {{and does not}} give any information on the single case. The average of car accidents does not inform the policyholder {{whether or not he}} will be involved (whether or not insurance is profitable). Nonetheless, it can justify a risky decision that remains right also when it eventually proves to be wrong. Consequently, the <b>calculus</b> <b>of</b> <b>probability</b> problematizes and de-problematizes the future that the calculus itself pretends to anticipate. It problematizes future because it calculates what indeed cannot be calculated – which is better than fatalism, in any case. It de-problematizes future because it offers a reason (in a sense, an alibi) for taking a decision despite the uncertainty of the situation. In short, what is calculated is the ignorance of the decision-maker, and the oddity is that this <b>calculus</b> <b>of</b> ignorance is based on a highly sophisticated mathematical calculus ([62] p. 50).|$|R
40|$|Abstract. This paper {{addresses}} {{the problem of}} constructing subjective imprecise probabilities using qualitative and conflicting pieces of information (arguments) as evidence. We propose formulae for the <b>calculus</b> <b>of</b> imprecise <b>probabilities</b> and show that the probabilities obtained reflect the indeterminacy of the subject, faithfully quantify the support offered by the arguments and constitute previsions that are mathematically coherent {{in the sense of}} [Walley, 1991]...|$|R
