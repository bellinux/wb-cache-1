1|28|Public
40|$|International audienceIn 1996 Arqués & Michel [(1996) 182, 45 - 58] {{discovered}} {{the existence of}} a common circular code in eukaryote and prokaryote genomes. Since then, circular code theory has provoked great interest and underwent a rapid development. In this paper we discuss some theoretical issues related to the synchronization properties of coding sequences and circular codes with particular emphasis on the problem of retrieval and maintenance of the reading frame. Motivated by the theoretical discussion, we adopt a rigorous statistical approach {{in order to try to}} answer to different questions. First, we investigate the <b>covering</b> <b>capability</b> of the whole class of 216 self-complementary, C maximal codes with respect to a large set of coding sequences. The results indicate that, on average, the code proposed by Arqués & Michel has the best <b>covering</b> <b>capability</b> but, still, there exists a great variability among sequences. Second, we focus on such code and explore the role played by the proportion of the bases by means of a hierarchy of permutation tests. The results show {{the existence of a}} sort of optimization mechanism such that coding sequences are tailored as to maximize or minimize the coverage of circular codes on specific reading frames. Such optimization clearly relates the function of circular codes with reading frame synchronization...|$|E
40|$|Network coding is an {{effective}} way to achieve the maximum flow of multicast networks. In this letter, we focus on the statistical properties of the maximum flow or the capacity of network coding for ad-hoc networks based on random graph models. Theoretical analysis shows that the maximum flow can be modelled as extreme order statistics of Gaussian distribution for both wired and wireless ad-hoc networks as the node number is relatively large under a certain condition. We also investigate the effects of the nodes' <b>covering</b> <b>capabilities</b> on the capacity of network coding...|$|R
5000|$|SAP S/4HANA Enterprise Management Cloud - {{for full}} ERP <b>capabilities,</b> <b>covering</b> all lines of business; cloud {{enterprise}} edition {{is the equivalent}} to the Enterprise Management on premises offering (country/regional scope: U.S., Germany, Australia, Canada, UK) ...|$|R
25|$|Projects and technology– {{manages the}} {{delivery}} of Shell's major projects, provides technical services and technology <b>capability</b> <b>covering</b> both upstream and downstream activities. It is also responsible for providing functional leadership across Shell {{in the areas of}} health, safety and environment, and contracting and procurement.|$|R
50|$|The Testing Maturity Model (TMM) {{has been}} {{designed}} to complement CMMI and is based on best industry practices. The TMM has 2 components; firstly, a set of 5 levels that define testing <b>capability</b> <b>covering</b> maturity goals, subgoals and activities, tasks and responsibilities and secondly, an assessment model consisting of a maturity questionnaire and an assessment procedure.|$|R
40|$|The fourth Social Barometer {{examines}} {{the extent of}} disadvantage among older Australians through indicators of people 2 ̆ 7 s <b>capabilities</b> <b>covering</b> eight key dimensions of life, including employment, income, health, housing, safety and social participation. The barometer concentrates on national data, and {{draws attention to the}} different experiences of retirement and ageing and the different phases of the life course which require distinctive policy responses...|$|R
40|$|The Brotherhood’s third Social Barometer {{examines}} how well equipped Australians of working age are for full {{economic and social}} participation in a rapidly changing world. Prepared with assistance from the Allen Consulting Group, it presents indicators of their <b>capabilities</b> <b>covering</b> eight key dimensions of life from employment and education and employment to health and social involvement. The barometer concentrates on national data, and pays particular attention to people with socioeconomically disadvantaged and Indigenous backgrounds...|$|R
50|$|NFC Forum is a {{non-profit}} industry association formed on March 18, 2004, by NXP Semiconductors, Sony and Nokia {{to advance the}} use of NFC wireless interaction in consumer electronics, mobile devices and PCs. Standards include the four distinct tag types that provide different communication speeds and <b>capabilities</b> <b>covering</b> flexibility, memory, security, data retention and write endurance. NFC Forum promotes implementation and standardization of NFC technology to ensure interoperability between devices and services. As of June 2013, the NFC Forum had over 190 member companies.|$|R
40|$|Preliminary {{results from}} an {{investigation}} of the applicability of the electronic beam squint (EBS) tracking technique to land mobile satellite terminals. Two systems are described, based on the EBS technique, which use both conventional waveguide and phased-array technology. Results are presented <b>covering</b> the error-detection <b>capabilities</b> of the systems, along with some operational analyses to illustrate the dynamic capabilities of the performance of such schemes. The systems described are intended for use at L-band and Ku-band. Both techniques apppear to offer a simple, and hence cost-effective, alternative to the current terminal arrangements...|$|R
40|$|Location-based {{services}} assist {{people in}} their decision-making during the performance of tasks in space. They do not consider the user’s individual preferences, time constraints, and possible subtasks to be performed. In order to account for these important aspects, a user centered spatio-temporal theory of location-based services is required. We propose such a theory by combining classical time geography with an extended theory of affordances. It assumes that affordances belong to three realms: physical, social-institutional, and mental. In addition to <b>covering</b> the <b>capability,</b> coupling, and authority constraints from time geography, this allows for a user centered perspective because affordances describe action possibilities {{with respect to a}} specific person. Furthermore, the integration of mental affordances offers the possibility to account for cognitive time constraints due to the duration of decision-making processes. This new theory for location-based services is closer to the individual user and more plausible with respect to their daily lives. A business traveler scenario is used as a case study to demonstrate this...|$|R
40|$|This is {{a conference}} paper. The close {{relationship}} between science, technology and mathematics {{that exists in the}} world of practising engineers, scientists and technologists is not replicated in any significant way in many school situations. The National Curriculum has not encouraged teachers to undertake any developments that could change this situation. If Technology in the National Curriculum is {{to be seen as a}} rigorous and challenging subject the underpinning scientific and mathematical concepts and skills must be developed alongside the other essential elements of technology such as aesthetic sense, the ability to make and develop products and an understanding of values and human factors. Full technological capability can only arise from an interaction between all of these elements. This paper will present a model for active collaboration between science and technology in secondary schools. It will explore areas common to the two subjects <b>covering</b> procedural <b>capability</b> and the development of conceptual understanding. The importance of establishing meaningful contexts for the work to be done by students will be emphasised...|$|R
50|$|SIAIS is {{performing}} antibody and immunochemistry research, {{dedicated to the}} understanding of the basic structure and design of biological molecules. It has eight key laboratories in the fields of antibody design, ADC chemistry, phenotypic screening, structure biochemistry, cell biology, stem cell biology, antibody engineering and antibody structure, <b>covering</b> all the <b>capabilities</b> that one needs to go from discovery of an important antibody through all the steps necessary to turn it into a drug. Besides, seven large technical platforms including cell sorting, imaging, protein & gene, HTS, informatics, analytical and animal sciences are also being developed. Nobel laureate James Rothman is a Professor-in-Residence of SIAIS.|$|R
40|$|The Lyman-FUSE (Far Ultraviolet Spectroscopic Explorer) mission {{selected}} in 1989 for definition {{and development for}} flight is described. FUSE will obtain spectra in the 912 to 1250 angstrom region with unprecedented sensitivity. This spectral interval is extraordinarily rich in strong atomic and molecular transitions, including the Lyman series of hydrogen and deuterium, molecular hydrogen (H 2 and HD) and the strong transitions of important ions such as N I to III, C I to IV, P II to V, O VI and S III to VI. FUSE will bridge the spectral gap between Hubble Space Telescope and the x ray regime with an additional moderate resolution spectroscopic <b>capability</b> <b>covering</b> 100 to 912 angstroms...|$|R
40|$|Eddington is a space {{mission for}} extrasolar planet finding and for asteroseismic observations. It has been {{selected}} by ESA as an F 2 /F 3 reserve mission with a potential implementation in 2008 - 13. Here we describe Eddington's capabilities to detect extrasolar planets, {{with an emphasis on}} the detection of habitable planets. Simulations <b>covering</b> the instrumental <b>capabilities</b> of Eddington and the stellar distributions in potential target fields lead to predictions of about 10, 000 planets of all sizes and temperatures, and a few tens of terrestrial planets that are potentially habitable. Implications of Eddington for future larger scale missions are briefly discussed. Comment: 3 pages, 3 figures, to appear in Proc. of IAU Symp. 202 - Planetary Systems in the Universe (Manchester, 8 / 2000...|$|R
40|$|The {{purpose of}} this study to {{describe}} (1) Planning of integrated thematic learning at SDN 1 Karangasem Wirosari Grobogan. (2) The implementation of integrated thematic learning at SDN 1 Karangasem Wirosari Grobogan. (3) Evaluation of integrated thematic learning at SDN 1 Karangasem Wirosari Grobogan. This research was qualitative. Held at SDN 1 Karangasem Wirosari Grobogan. Data collection methods used are observation, interviews, and documentation. Test the validity of the data in this study, using triangulation techniques. The results of the study are (1) Planning begins with the preparation of lesson plans, teacher planning materials, teaching methods, instructional media, learning resources and assessment techniques used. Equipped learning activity that contains the introduction, core activities, and cover with the time allocation in accordance with the competencies, learning objectives and allocation of available time. (2) Implementation of learning is good, <b>covering</b> planning <b>capabilities</b> open lessons, presenting the material, using methods / media, using props, using communicative language, motivate students, organizing activities, interact with students in a communicative, concluded learning, providing feedback, providing an assessment, and the use of time. (3) The evaluation was appropriate learning lesson preparation (syllabus, RPP) with steps evaluation of learning that evaluation planning, evaluation, evaluation data processing, and reporting the results of the evaluation...|$|R
40|$|This paper {{attempts}} {{to examine the}} theoretical relationship between income poverty and multidimensional poverty, and to explore the empirical linkages and discrepancies between {{these two types of}} poverty using the Alkire-Foster (AF) multidimensional poverty measurement method with 2011 China Health and Nutrition Survey (CHNS) data. Regarding the relationship between income poverty and multidimensional poverty, poverty can be summarised as not the mere lack of income but the deprivation of human basic <b>capability,</b> <b>covering</b> both monetary and non-monetary poverty. The statistical analysis on income poverty and multidimensional poverty measurement shows that the coincidence of income poverty and multidimensional poverty is 31 %. In other words, 69 % of multidimensionally poor households are not considered poor in terms of income poverty. The econometric results indicate that an increase in income can significantly reduce the incidence of multidimensional poverty in each dimension, but the impact is limite. Creation-Date: 2016 - 0...|$|R
40|$|International audienceHerschel is {{a spatial}} submillimetre {{observatory}} with spectroscopic and imaging <b>capabilities</b> <b>covering</b> the range from 55 to 671 μm (0. 44 to 5. 5 THz) partly explored {{for the first}} time here. With a primary mirror of 3. 5 m, it is presently the largest telescope launched. Its primary targets are the cold dust, the light hydrides, with a special focus on H 2 O, and a few species of high interest like C+ and O 2 in both our Galaxy and other galaxies. Its main focus is on star formation in all its possible aspects including cosmological metal enrichment evolution, statistics on prestellar cores or chemistry of protostar outflow terminal shocks to name only a few. We will describe the telescope and its three instruments, a selection of general results and we will focus on one typical case in greater detail, the observation of water in massive star forming regions. Herschel was launched in May 2009 and should function 3. 5 years...|$|R
40|$|Abstract. Eddington is a space {{mission for}} extrasolar planet finding and for asteroseismic observations. It has been {{selected}} by ESA as an F 2 /F 3 reserve mission with a potential implementation in 2008 - 13. Here we describe Eddington’s capabilities to detect extrasolar planets, {{with an emphasis on}} the detection of habitable planets. Simulations <b>covering</b> the instrumental <b>capabilities</b> of Eddington and the stellar distributions in potential target fields lead to predictions of about 10, 000 planets of all sizes and temperatures, and a few tens of terrestrial planets that are potentially habitable. Implications of Eddington for future larger scale missions are briefly discussed. 1. The Eddington mission The Eddington mission is a space telescope designed for two primary goals: asteroseismic studies and extrasolar planet finding. Both goals will be achieved through the acquisition of high-precision wide-field photometry, with a temporal stability that is possible only from space. The basic design is an f/ 3 triplereflectin...|$|R
40|$|The {{traditional}} 2 ̆ 7 {{coming of}} age 2 ̆ 7 is a longer and less clear-cut process for this generation of young people, who often enjoy the benefits of more study, but also less secure job prospects according to Martina Boese and Rosanna Scutella. The 2 ̆ 7 Youth Transition Social Barometer 2 ̆ 7 throws {{new light on the}} experiences of young people, particularly the socially disadvantaged, in areas such as health, economic resources and education. The second issue of the Brotherhood’s Social Barometer examines how well equipped Australian youth are (or are not) to negotiate successfully the transition from childhood to adulthood, from school to work, in a changing world. It presents indicators of <b>capabilities</b> <b>covering</b> seven dimensions from physical and mental health to education and employment and social participation. Each section is introduced by an individual’s story. The barometer concentrates on national data, paying particular attention to young people with socioeconomically disadvantaged, refugee and Indigenous backgrounds...|$|R
40|$|Diffuse optics is a {{powerful}} tool for clinical applications ranging from oncology to neurology, but also for molecular imaging, and quality assessment of food, wood and pharmaceuticals. We show that ideally time-domain diffuse optics can give higher contrast and a higher penetration depth with respect to standard technology. In order to completely exploit the advantages of a time-domain system a distribution of sources and detectors with fast gating <b>capabilities</b> <b>covering</b> all the sample surface is needed. Here, we present the building block to build up such system. This basic component is made of a miniaturised source-detector pair embedded into the probe based on pulsed Vertical-Cavity Surface-Emitting Lasers (VCSEL) as sources and Single-Photon Avalanche Diodes (SPAD) or Silicon Photomultipliers (SiPM) as detectors. The possibility to miniaturized and dramatically increase the number of source detectors pairs open the way to an advancement of diffuse optics in terms of improvement of performances and exploration of new applications. Furthermore, availability of compact devices with reduction in size and cost can boost the application of this technique...|$|R
40|$|Explaining the {{chromatic}} {{methodology for}} the intelligent monitoring of complex systems, Chromatic Monitoring of Complex Conditions demonstrates that chromatic processing {{is analogous to}} human vision yet also extends into {{a wide range of}} nonoptical domains. Taking a practical approach that utilizes many examples and graphs, the book presents the origin and methodology of chromaticity, before delving into the various applications of chromatic methods. It first describes characteristics of chromatic systems and chromatic processing algorithms, such as H, S, V transformation and basic x, y, z algorithms. The book then discusses the areas in which chromatic monitoring can be deployed, including electrical plasmas, industrial liquids, broadband interferometry and polarimetry, biological tissues and fluids, the environment, and acoustical and vibration signals. With contributions from international authorities in the field, this volume shows how chromatic analysis is useful for investigating diverse complex systems and for processing large amounts of information about system behavior, from direct physical parameters to holistic system overviews. By <b>covering</b> the broad <b>capabilities</b> of the methodology, it provides the basis for adapting chromatic techniques in future work...|$|R
40|$|From {{environmental}} management to land planning and geo-marketing, {{the number of}} application domains that may greatly benefit from using data enriched with spatio-temporal features is expanding very rapidly. This book shows that a conceptual design approach for spatio-temporal databases is both feasible and easy to apprehend. While providing a firm basis through extensive discussion of traditional data modeling concepts, the major focus {{of the book is}} on modeling spatial and temporal information. The authors provide a detailed and comprehensive description of an approach that fills the gap between application conceptual requirements and system <b>capabilities,</b> <b>covering</b> both data modeling and data manipulation features. The ideas presented summarize several years of research on the characteristics and description of space, time, and perception. In addition to the authors' own data modeling approach, MADS (Modeling of Application Data with Spatio-temporal features), the book also surveys alternative data models and approaches (from industry and academia) that target support of spatio-temporal modeling. Visual notations and examples are employed extensively to. © Springer-Verlag Berlin Heidelberg 2006. All rights are reserved. SCOPUS: bk. binfo:eu-repo/semantics/publishe...|$|R
40|$|This paper {{describes}} a Conceptual Framework underpinning “Systems that Care” {{in terms of}} educational systems that take account of motivation, metacognition and affect, in addition to cognition. The main focus is on motivation, as learning requires the student to put in effort and be engaged, in other words to be motivated to learn. But motivation is {{not the whole story}} as it is strongly related to metacognition and affect. Traditional intelligent educational systems, whether learner-centred or teacher-centred in their pedagogy, are characterised as having deployed their intelligence to assist {{in the development of the}} learner’s knowledge or skill in some domain. They have operated largely at the cognitive level and have assumed that the learner is already able to manage her own learning, is already in an appropriate affective state and also is already motivated to learn. This paper starts by outlining theories of motivation and their interactions with affect and with metacognition, as developed in the psychological and educational literatures. It then describes how such theories have been implemented in intelligent educational systems. The first part of the Conceptual Framework develops the notion of a partial hierarchy of systems in terms of their pedagogic focus. These range from traditional, cognitively intelligent systems, essentially concerned with cognition up to “Systems that Care”. Intermediate classes of system include Metacognitively Intelligent systems, Affectively Intelligent systems and Motivationally Intelligent systems. The second part of the Conceptual Framework is concerned with the design of systems. This is characterised in terms of (i) the kinds of diagnostic input data (such as the learner’s facial expression offering clues as to her demeanour) and (ii) the repertoire of tactical and strategic pedagogic moves (such as offering encouragement), applicable at different levels of the hierarchy. Attention is paid to metacognition, meta-affect and meta-motivation <b>covering</b> the <b>capability</b> of both the learner and the educational system to understand, reason about and regulate cognition, affect and motivation. Finally, research questions and areas of further work are identified in theory development, the role of the meta levels, and design considerations...|$|R
40|$|The {{objective}} {{of this study was}} to define the temporal resolution of future space missions dedicated to field-scale agriculture. The approach consisted in the assessment of the retrieval performance of the green area index (LAI) as a function of satellite revisit frequency. In this respect, different acquisition scenarios were simulated taking into consideration realistic LAI evolutions on large wheat fields, as well as realistic hypotheses: three levels of measurement errors and models uncertainties (10 %, 20 % and 25 %), two probability levels of daily clouds occurrence (0. 5 and 0. 7), all these factors being combined with six scenarios of revisit frequency, <b>covering</b> the current <b>capabilities</b> of sensors (from 1 to 30 days). The high revisit frequency at high space resolution was routinely achieved by the concurrent use of three SPOT satellite sensors. The lack of continuous temporal coverage of estimated LAI values was overcome using a semi-empirical evolution model (MODLAI). The results of the simulations indicated that RMSE between the estimated and reference LAI values are low, and quite similar, up to 7 days revisit frequency, regardless of the error level or the cloudiness probability. These results were explained by the very good temporal interpolation performances of MODLAI, when the number of good quality acquisitions allowed its fine adjustment. 1...|$|R
40|$|In {{order to}} enhance {{innovation}} {{education for the}} engineering and business students, a web-based interactive Fundamental Teaching Platform(hereafter as FTP),has recently been proposed in the campus of Ta Hwa Institute of Technology in Taiwan. FTP is a collaborative scheme that involves teachers from widely different backgrounds to work on an interdisciplinary curriculum. Under a grant support from government, Ta Hwa has started to implement a cross curriculum arrangement {{in the areas of}} Manufacturing and Commerce. Three departments in those areas, Business, Information Management and Automation Engineering, have been designated to develop course materials for this purpose. Though this FTP program is still in its early stage (whole project runs into three years), much anticipated and even unanticipated benefits have already emerged. This paper will present some preliminary results in the course development and discuss its impact to the methodology in developing integrative curriculum that cuts across traditional disciplinary boundaries. Index Terms- Fundamental Teaching Platform, Integration of Manufacturing and Commerce Curriculum, Web-based teaching DEMAND FOR INTEGRATIVE CURRICULUM In the much-cited knowledge-based economy age, universities are supposed to provide business and society with talented human resources who can integrate knowledge and thus add potential value to their jobs 1. However, traditional technical education system, which is based upon the concept of vocational training and skill-development, usually fails to meet this challenge. Yet as shown by TABLE I, (overleaf) environments drivers have made the need for integrative <b>capabilities</b> <b>covering</b> both engineering and business fields more imperative than ever. Universities nowadays have to invest grea [...] ...|$|R
40|$|This 6 month period {{continued}} the effort on absolute spectrally continuous stellar calibration begun in January 1991. The Midcourse Space Experiment (MSX) DCATT team has continued its analysis and intercomparisons of the Spatial Infrared Imaging Telescope (SPIRIT-III) ground calibration, the on-orbit stellar calibration (using our stellar spectra), and the on-orbit {{observations of the}} MIT Lincoln Labs. "emissive spheres". All three approaches are in very good agreement, at about the +/- 3 % level (absolute). This demonstrates the consistency of our overall calibration scheme and validates {{the context in which}} Infrared Space Observatory (ISO) and MSX data also reside. Final "globalization" of the overall MSX calibration is in progress, combining calibrations by stars, by the "emissive spheres" experiments, and by the NIST-traceable ground calibration. The work in support of the Infrared Telescope Satellite (IRTS) continues. I am currently calculating the contribution of diffuse starlight to the background in "dark" regions of the sky observed by the IRTS Near-IR Spectrometer. To accomplish this I am using the SKY model with a new extended wavelength <b>capability,</b> <b>covering</b> the 1. 00 - 2. 00 micron region for the first time. These calculations, together with models of the zodiacal light, will be used to seek the presence of a cosmic near-IR background. Papers VIII and IX in the calibration series appeared in this 6 month period. These describe our results on asteroid thermal nodes and anticipate the eventual production of a new network of stellar calibrators, numbering over 400 and extending over the whole sky. These will be constructed as stellar "templates", building on the legacy of our series of calibration papers. The first analyses of star counts from MSX are under way using SKY...|$|R
40|$|Modern sky {{surveys are}} {{returning}} precision measurements of cosmological statistics such as weak lensing shear correlations, {{the distribution of}} galaxies, and cluster abundance. To fully exploit these observations, theorists must provide predictions that {{are at least as}} accurate as the measurements, as well as robust estimates of systematic errors that are inherent to the modeling process. In the nonlinear regime of structure formation, this challenge can only be overcome by developing a large-scale, multi-physics simulation <b>capability</b> <b>covering</b> a range of cosmological models and astrophysical processes. As a first step to achieving this goal, we have recently developed a prediction scheme for the matter power spectrum (a so-called emulator), accurate at the 1 % level out to k~ 1 /Mpc and z= 1 for wCDM cosmologies based on a set of high-accuracy N-body simulations. It is highly desirable to increase the range in both redshift and wavenumber and to extend the reach in cosmological parameter space. To make progress in this direction, while minimizing computational cost, we present a strategy that maximally re-uses the original simulations. We demonstrate improvement over the original spatial dynamic range by an order of magnitude, reaching k~ 10 h/Mpc, a four-fold increase in redshift coverage, to z= 4, and now include the Hubble parameter as a new independent variable. To further the range in k and z, a new set of nested simulations run at modest cost is added to the original set. The extension in h is performed by including perturbation theory results within a multi-scale procedure for building the emulator. This economical methodology still gives excellent error control, ~ 5 % near the edges of the domain of applicability of the emulator. A public domain code for the new emulator is released as part of the work presented in this paper. Comment: 17 pages, 14 figures; version accepted for publication in ApJ; added references and new simulation results for additional accuracy verification; overall results and conclusions unchanged; the emulator is publicly available at: [URL]...|$|R
40|$|Video-based camera {{tracking}} {{consists in}} trailing the three dimensional pose {{followed by a}} mobile camera using video as sole input. In order to estimate the pose of a camera {{with respect to a}} real scene, one or more three dimensional references are needed. Examples of such references are landmarks with known geometric shape, or objects for which a model is generated beforehand. By comparing what is seen by a camera with what is geometrically known from reality, it is possible to recover the pose of the camera that is sensing these references. In this thesis, we investigate the problem of camera tracking at two levels. Firstly, we work at the low level of feature point recognition. Feature points are used as references for tracking and we propose a method to robustly recognise them. More specifically, we introduce a rotation-discriminative region descriptor and an efficient rotation-discriminative method to match feature point descriptors. The descriptor is based on orientation gradient histograms and template intensity information. Secondly, we have worked at the higher level of camera tracking and propose a fusion of top-down (TDA) and bottom-up approaches (BUA). We combine marker-based tracking using a BUA and feature points recognised from a TDA into a particle filter. Feature points are recognised with the method described before. We take advantage of the identification of the rotation of points for tracking purposes. The goal of the fusion is to take advantage of their compensated strengths. In particular, we are interested in <b>covering</b> the main <b>capabilities</b> that a camera tracker should provide. These capabilities are automatic initialisation, automatic recovery after loss of track, and tracking beyond references known a priori. Experiments have been performed at the two levels of investigation. Firstly, tests have been conducted to evaluate the performance of the recognition method proposed. The assessment consists in a set of patches extracted from eight textured images. The images are rotated and matching is done for each patch. The results show that the method is capable of matching accurately despite the rotations. A comparison with similar techniques {{in the state of the}} art depicts the equal or even higher precision of our method with much lower computational cost. Secondly, experimental assessment of the tracking system is also conducted. The evaluation consists in four sequences with specific problematic situations namely, occlusions of the marker, illumination changes, and erratic and/or fast motion. Results show that the fusion tracker solves characteristic failure modes of the two combined approaches. A comparison with similar trackers shows competitive accuracy. In addition, the three capabilities stated earlier are fulfilled in our tracker, whereas the state of the art reveals that no other published tracker covers these three capabilities simultaneously. The camera tracking system has a potential application in the robotics domain. It has been successfully used as a man-machine interface and applied in Augmented Reality environments. In particular, the system has been used by students of the University of art and design Lausanne (ECAL) with the purpose of conceiving new interaction concepts. Moreover, in collaboration with ECAL and fabric | ch (studio for architecture & research), we have jointly developed the Augmented interactive Reality Toolkit (AiRToolkit). The system has also proved to be reliable in public events and is the basis of a game-oriented demonstrator installed in the Swiss National Museum of Audiovisual and Multimedia (Audiorama) in Montreux...|$|R

