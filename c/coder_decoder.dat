3|90|Public
40|$|Dicode pulse-position {{modulation}} {{is a new}} modulation format, {{which has}} been found that offers improved sensitivity over digital PPM and multiple PPM. The power spectral density of that format theory has been described with mathematic equation and graph of that have been taken. Software simulation has been programmed and hardware (<b>coder,</b> <b>decoder)</b> have been constructed for the Dicode PPM theory. Also DiPPM’s window has been development for the proper use of the software spectral analyzer. The reliability of both power spectrum density results has been described. Although, previous equation and graph of the power spectrum density of DiPPM, have been proved for its faultiness. At last found that the DiPPM format gives output signal with increased power than that of the input signal...|$|E
40|$|Voice {{communication}} systems are {{moving at a}} steady pace from circuit-switched to packet-switched networks. Converged networks, in which data traffic and multimedia traffic share the same infrastructures, have yet to face many challenges. Unlike data traffic, voice traffic is very sensitive to issues such as delay, jitter and packet losses. The Quality of Service (QoS) of IP networks has greatly improved over the recent years. Nevertheless, {{it is not uncommon}} to experience loss in QoS on some networks caused by lack of resources or software/hardware failures. The speech codec (<b>COder</b> <b>DECoder)</b> is an essential component in a digital voice communication system. It converts the speech signal into a compact representation in order to efficiently use the available bandwidth. To compress the signal, speech codecs usually exploit the high redundancy present in a speech signal using techniques known as predictive coding. The most widely used speech coding model is the Code Excited Linear Prediction (CELP) model upon which are based most of the modern standardized speech codecs. The use of predictive codebooks, the Adaptive CodeBook (ACB) in particular, allows a tremendous reduction in bitrate. Unfortunately, the extensive use of prediction renders CELP codecs more vulnerable to packet losses than non-predictive codecs. A possible solution is to avoid using prediction at the cost of an increased bitrate. In this thesis, we propose several techniques to reduce the vulnerability of CELP codecs to packet losses caused by the use of prediction. Solutions that aim at limiting the contribution of the ACB and thus that reduce the sensitivity of the codec to packet losses are presented and discussed. Techniques based on sending side information, in order to help the decoder recover after a packet loss, are also proposed. The solutions are constrained to be low delay and low bitrate solutions, and are required to maintain interoperability if used in a standardized codec. Objective and subjective test results that demonstrate the performances of the proposed solutions are presented. We show that the robustness of CELP codecs can significantly be improved without sacrificing their compression performances. In spite of packet loss issues, we show that it is still beneficial to use predictive coding to efficiently exploit the available bandwidth...|$|E
40|$|Duobinary pulse-position {{modulation}} (PPM), a novel {{channel coding}} scheme, {{has been proposed}} in this thesis as an alternative method of improving bandwidth utilisation efficiency and sensitivity over existing coding schemes such as digital PPM, dicode PPM, multiple PPM and offset PPM while operating over slightly or highly dispersive graded-index (GI) plastic optical fibre (POF) channels of limited bandwidth. Theoretical investigation based on simulations of mathematical models with maximum likelihood sequence detection (MLSD) at 1 Gbps on-off keying (OOK) data shows that duobinary PPM significantly outperforms optimised digital PPM at low fibre bandwidths by 8. 7 dB while only operating at twice the original pulse code modulation (PCM) data rate. It {{has also been shown}} at high fibre bandwidth duobinary PPM gives a sensitivity of - 42. 2 dBm which is favourably comparable to digital PPM seven-level coding sensitivity of - 44. 1 dBm. Results presented in the thesis also demonstrate that at very low normalised fibre bandwidths (below 1 and down to 0. 43) duobinary PPM outperforms dicode PPM by 1. 2 dB requiring 27 x 103 photons per pulse compared to 40. 3 x 103 required by Dicode PPM. Due to the use of MLSD at low bandwidths, wrong-slot errors are completely eliminated, and the effect of erasure and false-alarm errors are significantly reduced thus resulting in significantly improved sensitivity. Successful VHSIC hardware description language (VHDL) and field programmable gate array (FPGA) implementation of duobinary PPM <b>coder,</b> <b>decoder</b> and MLSD as a single system has been presented in the thesis. An FPGA embedded bit error rate (BER) test device has also been implemented for sensitivity measurements purposes and all the designs have been tested successfully with back-to-back testing. A purpose-built VCSEL 850 nm wavelength based transceiver system has been designed and successful functional tests have been carried out. Maximum operational data rate of the transceiver is currently 622 Mbps to match the maximum operating frequency of the FPGA, however, it has the capability to operate up to 3. 2 Gbps. Further work on receiver characterisation and slot and frame synchronisation of duobinary PPM is required. All the results and analyses indicate that duobinary PPM is an ideal alternative to be considered for highly dispersive optical channels, and performance evaluation for higher bandwidths also favourably compares to existing coding schemes with only twice the expansion of original PCM data rate...|$|E
40|$|This work {{deals with}} theory of coding, {{analyses}} current groups of error correction codes and describes features and parametres of chosen representatives of these groups. By comparing these parametres along with given criteria it choses extended Hamming code as suitable code for securing read-only-memories (ROM). For this code it choses way of realization of synthetisable modules of <b>coder</b> and <b>decoder</b> and describes their design. The work describes design of synthetizable modules of <b>coder</b> and <b>decoder</b> in VHDL. Then it explains functionality of created application which {{is able to}} generate these synthetisable modules. For verification of generated modules it creates authentication environment. Part of this environment is also model of ROM allowing writing of any error value into the memory. In the end it automatically verifies generated modules of <b>coder</b> and <b>decoder</b> with various width of input information vector...|$|R
50|$|FAAC and FAAD2 {{stand for}} Freeware Advanced Audio <b>Coder</b> and <b>Decoder</b> 2 respectively. FAAC {{supports}} audio object types LC, Main and LTP. FAAD2 supports audio object types LC, Main, LTP, SBR and PS. Although FAAD2 is free software, FAAC {{is not free}} software.|$|R
40|$|The article {{presents}} a <b>coder</b> and <b>decoder</b> of fractal signals of comb-type structure (FSCS) based on microcontrollers (MC). The <b>coder</b> and <b>decoder</b> consist of identical control modules, while their managed modules have different schematic constructions. The control module performs forming or recognition of signals, and also carries out {{the function of}} information exchange with a computer. The basic element of the control module is a PIC 18 F 2550 microcontroller from MicroChip. The coder of the system forms fractal signals of a given order according to the information bits coming from the computer. Samples of the calculated values of the amplitudes of elementary rectangular pulses that constitute the structure of fractal pulses are stored {{in the memory of}} the microcontroller as a table. Minimum bit capacity of the DAC necessary for the generation of FSCS of fourth order is four bits. The operation algorithm, "wired" into the controller of the program, provides for encoding of the transmitted information by two-bit symbols. Recognition of the start of transmission of each byte in communication channel is performed by the transmission of the timing signal. In a decoder the microcontroller carries out reception and decoding of the received fractal signals which are then transmitted to the computer. The developed algorithm of the program for the microcontroller of the decoder is carried out by determination of order of fractal impulse after the value of sum of amplitudes of elementary impulses, constituents fractal signal. The programs for <b>coder</b> and <b>decoder</b> are written in "C". In the most critical places of the program influencing on the fast-acting of chart “assembler” insertions are done. The blocks of the <b>coder</b> and <b>decoder</b> were connected with a coaxial 10 meters long cable with an impendance of 75 Ohm. The signals generated by the developed coder of FSCS, were studied using a digital oscillograph. On the basis of the obtained spectrums, it is possible to draw a conclusion, that the fractal signals formed by the coder are wideband and can be used in noise-resistant and protected communication systems...|$|R
40|$|This work {{deals with}} {{problematic}} basic characteristic common linear block codes, concretely with creation generating and controlling matrix and individual ways decoding common linear block codes and then are theoretic knowledge {{used in the}} next part bachelor’s thesis. Next part this work is bent on the concrete layout of common liner block code satisfactory specifications by submission. In this part it can by find way haw create generating matrix be able to correcting tree single errors then create control matrix for decoding and correct network for correcting errors. Programs are used in this work are explained there. In the end this part is example of coding and decoding. Lastly work is realization codec. In this part is description of <b>coder</b> and <b>decoder</b> realizations. This codec is simulating by program Matlab Simulink in part five. In last part are create boards of printed circuits by program Eagle for <b>coder</b> and <b>decoder...</b>|$|R
40|$|The key {{functional}} modules in an HDTV codec are motion estimator, 2 -D DCT/IDCT, and variable-length <b>coder</b> and <b>decoder.</b> The state-of-the-art VLSI implementation {{techniques for}} these key modules will be presented. For HDTV applications, these implementations are pointing towards cost effective design. Based on these, reasonable cost HDTV codecs {{can be realized}} by using powerful CAD tools as well as advanced VLSI technology...|$|R
40|$|Recent {{trends in}} video coding {{technology}} {{have included the}} coding of arbitrarily shaped objects and {{the improvement of the}} robustness of video bitstreams when subjected to errors during transmission. In this paper, we examine the interaction of these two technologies, using a <b>coder</b> and <b>decoder</b> based on MPEG 4 -video. Effective techniques are proposed for concealing the effects of these transmission errors. I...|$|R
30|$|Thus, {{the total}} amount of memory {{required}} for the embedded quantizer is slightly less than twice of the memory used for the initial codebooks. In the applications based on fast tree-structured search, {{there is no need to}} have internal codewords at the decoder. This is while the internal codewords must be available in both <b>coder</b> and <b>decoder</b> in an embedded quantization scheme ([3, page 413]).|$|R
3000|$|From the {{analysis}} of the MJLS in Section 3, {{it is not easy to}} assess the computational burden required, when using the proposed system in practice. In this section, we provide a brief overview of the complexity of the encoder and decoder. The encoder includes the controller, quantizer, entropy coder, and channel (FEC) <b>coder.</b> The <b>decoder</b> includes channel decoder, entropy decoder, buffering, and selection of the control values: [...]...|$|R
30|$|The entire method {{summarized}} in Figure 5 a,b {{can be implemented}} according to Algorithms 2 and 3, respectively, for the <b>coder</b> and the <b>decoder.</b> The results obtained with our implementation are detailed and discussed in Section 4.7.|$|R
40|$|The {{contents}} of this thesis is a delineation of the European Standard ETSI EN 300 744 for terrestrial {{digital video broadcasting}} (DVB-T) and a description of created OFDM <b>coder</b> and <b>decoder</b> for baseband signal transmission in 2 K mode without error correction capabilities. The proper function of both devices is verified by means of Matlab simulations and practically implemented into Texas Instruments’ digital signal processor TMS 320 C 6711 using Starter Kits...|$|R
40|$|This paper {{presents}} the hardware {{implementation of the}} pulse code modulation <b>coder</b> and <b>decoder</b> (PCM Codec), that aims at improving the delay of the speech compression of this codec, which is originally implemented in software for Voice-over Internet Protocol (VoIP) Telephony. This design provides a solution known as intellectualproperty (IP) core ready to be deployed in a reconfigurable architecture with other voice codecs. Such architecture can then {{be used to improve}} the Quality-of-Service (QoS) of VoIP Telephony...|$|R
40|$|Dicode Pulse Position Modulation {{has been}} {{proposed}} as an alternative coding scheme which has many advantages over previous Pulse Position Modulation formats. As {{it is a new}} coding scheme, few analyses and less experimental results have been published. For the first time, the original design of an experimental Dicode Pulse Position Modulation <b>coder</b> and <b>decoder</b> and experimental results are presented in this paper. These circuits are the basic tools needed for any further investigation of this format...|$|R
40|$|There {{is a new}} {{generation}} of digital signal processors for image and video compression and decompression. Regardless of their complexity, most of the image and video compression ar-chitectures share three major components: an accelerator for computing two-dimensional DCTs and IDCTs, a motion estimator, and a variable length <b>coder</b> and <b>decoder.</b> This paper presents a general overview {{of some of the most}} common designs and architectures for the hardware implementation of these key components in image compression ICs...|$|R
40|$|The paper {{discusses}} linear predictive <b>coder</b> and <b>decoder</b> for speech signals. The {{basic idea}} behind linear predictive analysis {{is that a}} speech sample can be approximated as a linear combination of past speech samples. The predictor coefficients and basic speech parameters such as pitch and voiced/unvoiced estimation are done at analysis end. These coefficients along with the various speech parameters are transmitted to the synthesis end. The speech is synthesized using the received predictor coefficients and speech parameters. A linear predictive model has been developed using MATLAB software tool...|$|R
40|$|Some text {{compression}} methods {{take advantage}} from using more complex compression units than characters. The synchronization between <b>coder</b> and <b>decoder</b> then {{can be done}} by transferring the unit dictionary together with the compressed message. We propose to use a dictionary compression method based on a proper ordering of nodes of the tree-organized dictionary. This reordering allows achieving of better compression ratio. The proposed dictionary compression method has been tested to compress dictionaries for word- and syllable-based compression methods. It seems to be effective for compressing dictionaries of syllables, and promising for larger dictionaries of words...|$|R
50|$|Existing {{frequency-division}} multiplexing carrier systems {{worked well for}} connections between distant cities, but required expensive modulators, demodulators and filters for every voice channel. For connections within metropolitan areas, Bell Labs in the late 1950s sought cheaper terminal equipment. Pulse-code modulation allowed sharing a <b>coder</b> and <b>decoder</b> among several voice trunks, so this method was chosen for the T1 system introduced into local use in 1961. In later decades, the cost of digital electronics declined {{to the point that}} an individual codec per voice channel became commonplace, but by then the other advantages of digital transmission had become entrenched.|$|R
3000|$|The {{issue of}} robust and joint source-channel {{decoding}} of quasi-arithmetic codes is addressed. Quasi-arithmetic coding is a reduced precision and complexity implementation of arithmetic coding. This amounts to approximating {{the distribution of}} the source. The approximation of the source distribution leads to the introduction of redundancy that can be exploited for robust decoding in presence of transmission errors. Hence, this approximation controls both the trade-off between compression efficiency and complexity {{and at the same time}} the redundancy (excess rate) introduced by this suboptimality. This paper provides first a state model of a quasi-arithmetic <b>coder</b> and <b>decoder</b> for binary and [...]...|$|R
40|$|Security {{proof of}} {{practical}} {{quantum key distribution}} (QKD) has attracted a lot of attentions in recent years. Most of real-life QKD implementations are based on phase-coding BB 84 protocol, which usually uses Unbalanced Mach-Zehnder Interferometer (UMZI) as the information <b>coder</b> and <b>decoder.</b> However, the long arm and short arm of UMZI will introduce different loss in practical experimental realizations, the state emitted by Alice's side is nolonger standard BB 84 states. In this paper, we will give a security analysis in this situation. Counterintuitively, active compensation for this different loss will only lower the secret key bit rate. Comment: 4 pages, 3 figures...|$|R
40|$|This thesis {{deals with}} Matlab {{application}} developed for simulation of the DVB-T channel <b>coder</b> and <b>decoder.</b> The {{first part of}} this thesis includes description of terrestrial digital video broadcasting system and comparison with analogue television. Channel coding and OFDM modulation, used in the DVB-T standard, is described in detail. Application developed in the Matlab environment is described in the second part. The application simulates data transfer of the DVB-T system. Results of the simulated transmission, using developed application are presented in the last part. Namely dependence of the BER on the S/N ratio, using various coder settings, was examined. Maximal possible data rate was determined for these various setting. All obtained values are graphically represented...|$|R
40|$|Text {{compression}} over alphabet {{of words}} or syllables {{brings up a}} new concern to deal with - the alphabet needs to be transferred between <b>coder</b> and <b>decoder</b> along with the message. Especially with small or middle-sized documents the code of the alphabet forms a signi cant part of the resulting le. Therefore it is desirable to represent the alphabet as dense as possible. The topic of this thesis is a comparison of three approaches to large alphabet compression - static, semiadaptive and adaptive approach. Moreover the potential of static initialization of adaptive methods with frequent words is analyzed. Furthermore a new and highly eff ective method for compression {{of a set of}} strings is introduced...|$|R
40|$|Orthogonal {{frequency}} division multiplexing (OFDM) {{is a well-known}} modulation technique which is used in broadband wired and wireless communication systems, such as standard 802. 11 a/b/g/n, digital video broadcasting television (DVB-TV), and Long Term Evolution in the next mobile generation, due to its capacity in solving {{the problem of the}} Inter-symbol Interference caused by the effects of a dispersive channel. Since a few years ago, this technique has been used in optical communications which is the aim of this thesis. In this Master Thesis, the most relevant aspects of optical OFDM communication are described and implemented in optical simulation software called VPItransmissionMaker™ and VPIphotonicsAnalyzer™, (VPI). We find out that the OFDM <b>coder</b> and <b>decoder</b> provided by this program cannot be upgraded. This handicap does not allow modifying the main work algorithm and therefore the system cannot be improved. To solve this problem, it has been designed a Matlab OFDM <b>coder</b> and <b>decoder</b> to study the behaviour of optical OFDM systems using Intensity Modulation (IM) and Direct Detection (DD). As it will be detailed along the thesis, two different optical OFDM simulation scenarios using IM/DD are developed: an IM/DD RF and Hermitian Symmetry demos. Both of them are optical OFDM systems with an intensity modulation transmission and direct detection. The focus has been set primarily in obtaining a flexible, efficient and user-friendly simulation platform allowing for straightforward setup of advanced simulation of optical OFDM systems. The performance of these two scenarios is studied, taking advantage from the Simulation Script which VPI software provided in a more manageable mode, specifically, scripts using Tcl/tk language have been developed to derive power budget plots at desired Bit Error Ratio (BER) ...|$|R
40|$|International audienceEROS is {{the largest}} {{database}} {{in the world of}} high resolution art pictures. The TSAR project is designed to open it in a secure, efficient and user-friendly way that involves cryptography and watermarking as well as compression and region-level representation abilities. This paper more particularly addresses the two last points. The LAR codec is first presented as a suitable solution for picture encoding with compression ranging from highly lossy to lossless. Then, we detail the concept of self-extracting region representation, which consists of performing a segmentation process at both the <b>coder</b> and <b>decoder</b> from a highly compressed image, and later locally enhancing the image in a region of interest. The overall scheme provides an efficient, consistent solution for advanced data browsing...|$|R
40|$|Abstract—With block-based {{compression}} {{approaches for}} both still images and sequences of images annoying blocking artifacts are exhibited, primarily at high compression ratios. They {{are due to}} the independent processing (quantization) of the block transformed values of the intensity or the displaced frame difference. In this paper, we propose {{the application of the}} hierarchical Bayesian paradigm to the reconstruction of block discrete cosine transform (BDCT) compressed images and the estimation of the required parameters. We derive expressions for the iterative evaluation of these parameters applying the evidence analysis within the hierarchical Bayesian paradigm. The proposed method allows for the combination of parameters estimated at the <b>coder</b> and <b>decoder.</b> The performance of the proposed algorithms is demonstrated experimentally. Index Terms—Bayesian models, evidence analysis, image coding, post-processing, reconstruction. I...|$|R
40|$|EROS is {{the largest}} {{database}} {{in the world of}} high resolution art pictures. The TSAR project is designed to open it in a secure, efficient and user-friendly way that involves cryptography and watermarking as well as compression and region-level representation abilities. This paper more particularly addresses the two last points. The LAR codec is first presented as a suitable solution for picture encoding with compression ranging from highly lossy to lossless. Then, we detail the concept of self-extracting region representation, which consists of performing a segmentation process at both the <b>coder</b> and <b>decoder</b> from a highly compressed image, and later locally enhancing the image in a region of interest. The overall scheme provides an efficient, consistent solution for advanced data browsing. 1...|$|R
40|$|In {{this project}} was created a {{simulation}} of a radio-communication channel in Simulink (Matlab). It is a graphical tool that allows modeling, simulation and analysis of dynamic systems. The radio-communication channel includes: JPEG <b>coder</b> and <b>decoder,</b> BPSK modulator and demodulator, AWGN channel and some additional boxes to adjust the flow of data. Group of images have been sent through the channel and while changing the parameters of each box the image distortion changes. There were used two subjective methods for image evaluation: DSIS and DSCQS. The methods correlate well. Correlation with the objective methods depended on each method and a type of image distortion. Subjective and objective methods are both equally important for evaluation of image qualityEscuela Técnica Superior de Ingeniería de TelecomunicaciónUniversidad Politécnica de Cartagen...|$|R
40|$|In current {{interframe}} {{video compression}} systems, the encoder performs predictive coding {{to exploit the}} similarities of successive frames. The Wyner-Ziv Theorem on source coding with side information available only at the decoder suggests that an asymmetric video codec, where individual frames are encoded separately, but decoded conditionally (given temporally adjacent frames) could achieve similar e#ciency. We propose a transformdomain Wyner-Ziv coding scheme for motion video that uses intraframe encoding, but interframe decoding. In this system, the transform coe#cients of a Wyner-Ziv frame are encoded independently using a scalar quantizer and turbo <b>coder.</b> The <b>decoder</b> uses previously reconstructed frames to generate side information to conditionally decode the Wyner-Ziv frames. Simulation results show significant gains above DCT-based intraframe coding and improvements over the pixel-domain Wyner-Ziv video coder...|$|R
50|$|If the {{characteristics}} of the input data do not follow the pattern that every eighth bit is '1', the coder using alternate mark inversion adds a '1' after seven consecutive zeros to maintain synchronisation. On the decoder side, this extra '1' added by the coder is removed, recreating the correct data. Using this method the data sent between the <b>coder</b> and the <b>decoder</b> is longer than the original data by less than 1% on average.|$|R
40|$|A {{universal}} noiseless coding {{structure was}} developed that provides efficient performance over an extremely {{broad range of}} source entropy. This is accomplished by adaptively selecting the best of several easily implemented variable length coding algorithms. Custom VLSI <b>coder</b> and <b>decoder</b> modules capable of processing over 20 million samples per second are currently under development. The first of the code options used in this module development is shown to be equivalent to a class of Huffman code under the Humblet condition, other options are shown to be equivalent to the Huffman codes of a modified Laplacian symbol set, at specified symbol entropy values. Simulation results are obtained on actual aerial imagery, and they confirm the optimality of the scheme. On sources having Gaussian or Poisson distributions, coder performance is also projected through analysis and simulation...|$|R
40|$|Most {{state-of-the-art}} {{image compression}} techniques exploit the dependencies between the subbands in a wavelet transformed image. We propose a progressive image coding technique {{which is based}} upon the augmented zerotrees of wavelet coefficients. An augmented zerotree can be regarded as a spatial orientation tree with some extended characteristics. Both the <b>coder</b> and <b>decoder</b> require to maintain only one list. The augmented zerotrees are constructed in an efficient recursive manner and the algorithms are provided. A comparison reveals that the coder performance is close to, and sometimes outperforms, other well known coding methods. Suggestions are made for further improvements regarding the speed and compression performance of the coder. i Contents 1 Introduction 1 2 Wavelet Transform and Subband Decomposition 2 2. 1 Filter Banks............................ 4 2. 2 Perfect Reconstruction...................... 4 2. 3 Other Wavel [...] ...|$|R
40|$|International audienceThis paper {{proposes a}} new {{informed}} source separation technique which combines music transcription with source separation. The presented system {{is based on}} a <b>coder</b> / <b>decoder</b> configuration where a classic (not informed) multiple-F 0 estimation is applied on each separated source signal assumed known at the coder before the mixing process. Thus, the extra information required to recover the reference transcription of each isolated instrument is computed and inaudibly embedded into the mixture using a watermarking technique. At the decoder, where the original source signals are unknown, instruments are separated from the mixture using the informed transcription of each source signal. In this paper, we show that a classic (non-informed) F 0 estimator can be used {{to reduce the amount of}} bits necessary to transmit the exact transcription of each isolated instrument...|$|R
40|$|Abstract—In this paper, {{we propose}} a {{systematic}} procedure for designing spherical lattice (space–time) codes. By employing stochastic optimization techniques we design lattice codes which are well matched to the fading statistics {{as well as}} to the decoder used at the receiver. The decoders we consider here include the optimal albeit of highest decoding complexity maximum-likelihood (ML) decoder, the suboptimal lattice decoders, as well as the suboptimal lattice-reduction-aided (LRA) decoders having the lowest decoding complexity. For each decoder, our design methodology can be tailored to obtain low error-rate lattice codes for arbitrary fading statistics and signal-to-noise ratios (SNRs) of interest. Further, we obtain fundamental lower bounds on the error probabilities yielded by lattice and LRA decoders and characterize their asymptotic behavior. Index Terms—Lattice <b>coder,</b> lattice <b>decoder,</b> multiple-input multiple-output (MIMO) fading channels, stochastic optimization. I...|$|R
40|$|This paper {{describes}} {{the implementation of}} the modified continuously variable slope delta modulator (MCVSD), in which the basic step size δ 0 is made to vary as a function of input signal level. The information needed to carry out this is extracted at the local decoder output so that the <b>coder</b> and the <b>decoder</b> track each other. The result is a significant improvement in the dynamic range (about 15 dB) as compared to CVSD coder without degrading the peak signal to noise ratio...|$|R
40|$|Long-term memory {{prediction}} {{extends the}} spatial displacement vector utilized in hybrid video coding by a variable time delay permitting {{the use of}} more than one reference frame for motion compensation. This extension leads to improved rate-distortion performance. However, motion compensation in combination with transmission errors leads to temporal error propagation that occurs when the reference frames at <b>coder</b> and <b>decoder</b> dier. In this paper, we present a framework that incorporates an estimated error into rate-constrained motion estimation and mode decision. Experimental results with a Rayleigh fading channel show that long-term memory prediction signicantly outperforms the single-frame prediction H. 263 -based anchor. When a feedback channel is available, the decoder can inform the encoder about successful or unsuccessful transmission events by sending positive (ACK) or negative (NACK) acknowledgments. This information is utilized for updating the error estimates at the encoder. Si [...] ...|$|R
