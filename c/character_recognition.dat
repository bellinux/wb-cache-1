4129|296|Public
5|$|The {{new field}} was unified and {{inspired}} {{by the appearance of}} Parallel Distributed Processing in 1986—a two volume collection of papers edited by Rumelhart and psychologist James McClelland. Neural networks would become commercially successful in the 1990s, when they began to be used as the engines driving programs like optical <b>character</b> <b>recognition</b> and speech recognition.|$|E
5|$|Initially {{looking for}} ways to further improve its {{electronic}} forms software, in November 1991 Delrina had attempted to buy two associated firms that produced Optical <b>Character</b> <b>Recognition</b> (OCR) software, with the intention of incorporating OCR functionality into its forms products. The acquisition deal fell through, though by Fall 1992 Delrina had made a deal with Caere Corporation to include its AnyFax OCR software within its products. This functionality was incorporated into WinFax PRO 3.0 in late 1992, and subsequently in FormFlow Despite the agreement with Caere, the subsequent version of WinFax used Xerox's TextBridge OCR engine instead.|$|E
5|$|This {{initial release}} had {{multiple}} built-in applications, {{many of them}} similarly branded to match their desktop counterparts; such as Microsoft Reader, Microsoft Money, Pocket Internet Explorer and Windows Media Player. A version of Microsoft Office called Pocket Office was also bundled and included Pocket Word, Pocket Excel and Pocket Outlook. Notes, a note-taking app saw its first release and would be supported by most later versions of Windows Mobile. Intelligent <b>character</b> <b>recognition</b> support allowed Notes to distinguish styles of handwriting to be learned by the OS during processing to improve accuracy and recognition levels.|$|E
40|$|Feature {{extraction}} {{is one of}} {{the most}} improtant step on <b>characters</b> <b>recognition</b> system. Transition features is one from many features used on <b>characters</b> <b>recognition</b> system. This paper report a research on handwritten basic Jawanesse <b>characters</b> <b>recognition</b> system to found the proper numbers of transitions used on transition features. To recognize the characters,the Multiclass Support Vector Machines were used. The Directed Acyclic Graph (DAG) SVM were used for multiclass classification strategy and to map each input vector to a higher dimention space, the Gaussian Radial Basis Function (RBF) kernel with parameter 1 were used. It can be shown, for basicJawanesse <b>characters</b> <b>recognition</b> system, the optimal numbers of transitions used for transition features is 4 (a half of maximum numbers of transition on all patterns) ...|$|R
40|$|This work is {{interested}} in possibilities of personal <b>character's</b> <b>recognition</b> from text data with computer contribution. It's based on Kreitler & Kreitler method that's why it's focused on separating sentences into meaning units, assigning a dimension to a meaning unit and gaining characters of author (neuroticism and extroversion) from meaning unit's dimensions...|$|R
50|$|After the {{extraction}} of individual <b>characters</b> occurs, a <b>recognition</b> engine is used to identify the corresponding computer <b>character.</b> Several different <b>recognition</b> techniques are currently available.|$|R
5|$|The 2010 Zambian census was {{conducted}} in Zambia in 2010 under {{the approval of the}} Government of Zambia, which recorded demographic data from 13 million people and 3.2 million households. The 2010 Census of Population and Housing {{was conducted}} between 16 October and 15 November 2010, with all parts of the country covered by 30 November 2010. It was the fifth national population census exercise of Zambia since its independence in 1964, with the previous censuses conducted in 1969, 1980, 1990 and 2000. A total of 3.2 million questionnaires were used for data collection and the processing started in April 2011 by the Central Statistical Office. Optical Mark Reading (OMR) and Intelligent <b>Character</b> <b>Recognition</b> (ICR) technology were used for data capture. The census was funded by United Nations Population Fund (UNFPA), the United Kingdom AID (UKAID-formerly DFID), the United States Agency for International Development (USAID) and the African Development Bank (AfDB), who contributed close to 60 per cent of the total expenditure and rest contributed by the Ministry of Finance of the Government of Zambia.|$|E
25|$|Graphotactical {{rules are}} useful in error {{detection}} by optical <b>character</b> <b>recognition</b> systems.|$|E
25|$|Optical <b>character</b> <b>recognition</b> (OCR)identifying {{characters}} in images of printed or handwritten text, usually {{with a view}} to encoding the text in a format more amenable to editing or indexing (e.g. ASCII).|$|E
40|$|AbstractCharacters are {{the most}} {{important}} instrument of human communication. With the information age development, people use computer to store large number of character information. Meanwhile, the image processing technology development makes possibility of character information abstracting from character images. This article research and realize one recognition system of print form characters. In the first place, preprocess the images that achieve the easier abstraction of characteristic value. The second is to abstract the characteristic value as the basis of <b>characters</b> <b>recognition.</b> In the last, identify the character information according to the characteristic value and <b>character</b> library <b>recognition...</b>|$|R
40|$|Handwritten <b>characters</b> <b>recognition</b> (HCR) {{presents}} {{a great challenge}} {{in the field of}} image processing and pattern recognition. This paper presents handwritten English characters recognised using shape based zoning features with the help of neural network (NN) as a classifier. The neural network used is pattern-net. The recognition rate is observed almost 96 %. Key words:HCR, NN, Zoning, Pattern-net, Classifier...|$|R
40|$|In this paper, {{we present}} an off line method of Arabic Handwritten <b>Characters</b> <b>Recognition.</b> The study {{is based on}} the {{analysis}} of several performances of feature vectors. It is hoped that the results of the evaluation contribute to the conception of operational systems. The futures are the projection moments, Barr-features, and Fourier descriptors. The classification is achieved by a standard multi-layer perception...|$|R
25|$|Optical <b>character</b> <b>recognition</b> is {{performed}} on images (e.g., brochures, photos, prints, scans, screen clips) {{so that any}} text that appears in them is searchable. Handwritten text on a tablet PC is also searchable.|$|E
25|$|Despite the {{development}} of alternative input devices, such as the mouse, touchscreen, pen devices, <b>character</b> <b>recognition</b> and voice recognition, the keyboard remains {{the most commonly used}} device for direct (human) input of alphanumeric data into computers.|$|E
25|$|Bulk {{business}} mail, using Mailmark® technology, attracts reduced {{prices of}} up to 32%, if the sender prints an RM4SCC barcode, or prints the address in a specified position on the envelope using a font readable by optical <b>character</b> <b>recognition</b> (OCR) equipment.|$|E
40|$|Text {{extraction}} {{is one of}} the key {{tasks in}} document image analysis. Automatic text extraction without <b>characters</b> <b>recognition</b> capabilities is to extract regions just contains text. The text extraction process includes detection, localization, segmentation and enhancement of the text from the given input image. In this paper we present a comparative study and performance evaluation of various text extraction techniques...|$|R
40|$|In this paper, {{we present}} an off line Tifinaghe <b>characters</b> <b>recognition</b> system. Texts are scanned using a flatbed scanner. Digitized text are normalised, noise is reduced using a median filter, {{baseline}} skew is corrected {{by the use}} of the Hough transform, and text is segmented into line and lines into words. Features are extracted using the Walsh Transformation. Finally characters are recognized by a multilayer neural network...|$|R
40|$|In this project, I built a web {{application}} for handwritten Chinese <b>characters</b> <b>recognition</b> in real time. This system determines a Chinese character while a user is drawing/writing it. The techniques and steps I use {{to build the}} recognition system include data preparation, preprocessing, features extraction, and classification. To increase the accuracy, {{two different types of}} neural networks ared used in the system: a multi-layer neural network and a convolutional neural network...|$|R
25|$|The {{magazine}} has an online archive with the unformatted text for every article published. The articles are indexed and were converted from scanned images using optical <b>character</b> <b>recognition</b> technology. There are still minor {{errors in the}} text that are remnants of the conversion into digital format.|$|E
25|$|Phishers {{have even}} started using images instead of text {{to make it}} harder for {{anti-phishing}} filters to detect text commonly used in phishing emails. However, this has led to the evolution of more sophisticated anti-phishing filters that are able to recover hidden text in images. These filters use OCR (optical <b>character</b> <b>recognition)</b> to optically scan the image and filter it.|$|E
25|$|The main Google Drive {{mobile app}} {{supported}} editing of documents and spreadsheets until April 2014, when the capability {{was moved to}} separate, standalone apps for Google Docs, Sheets, and Slides. The Google Drive app on Android allows users to take {{a photo of a}} document, sign, or other text and use optical <b>character</b> <b>recognition</b> to convert to text that can be edited. In October 2014, the Android app was updated with a Material Design user interface, improved search, the ability to add a custom message while sharing a file, and a new PDF viewer.|$|E
40|$|The applicatiQn Qf the {{structural}} learning technique knQwn as ErrQr CQrrecting Gra,tlatical Inference to Planar Shape recQ! 1 nitiQn is discussed and il-lustrated with a nQn-trivial printed digit recQgnitiQn task. Experi,nental {{results are presented}} and cQmpared with thQse Qf Qther 'nQre cQnventiQnal (non-structural) techniques, shQwing the new technique to provide sig-nificantly imprQved perfQrmance. lndex Ternl. s- Syntactic, structural, pattern recognition, stochastic error-correcting, parsing, learning, grammatical inference, planar shape, printed <b>characters</b> <b>recognition.</b> ...|$|R
40|$|In {{spite of}} {{advances}} in object recognition technology, Handwritten Bangla <b>Characters</b> <b>Recognition</b> (HBCR) (such as alpha-numeric and special) remains largely unsolved {{due to the}} presence of many ambiguous handwritten characters and excessive cursive in Bangla handwritings. Even the best existing recognizers do not lead to satisfactory performance for practical applications, and have much lower performance than those developed for English alpha-numeric characters. To improve the performance of HBCR, we herein present Bangla handwritten <b>characters</b> <b>recognition</b> methods by employing the state-of-the-art Deep Convolutional Neural Networks (DCNN) including VGG Network, All Convolution Network (All-Conv Net), Network in Network (NiN), Residual Network, FractalNet, and DenseNet. The deep learning approaches have the advantage of extracting and using feature information, improving the recognition of 2 D shapes {{with a high degree of}} invariance to translation, scaling and other distortions. We systematically evaluated the performance of DCNN models on publicly available Bangla handwritten character dataset called CMATERdb, and achieved the state-of-the-art recognition accuracy when using DCNN models. Such improvement fills a significant gap between practical requirements and the actual performance of Bangla handwritten characters recognizers. Comment: 12 pages, 22 figures, 5 table...|$|R
40|$|We present here {{a library}} for graphic {{documents}} recognition: the PSI Library. The PSI Library proposes complete processings chains from images processing to classification. It {{can be used}} for different applications like: images pre-processing, <b>characters</b> <b>recognition,</b> vectorisation, symbols recognition, and so on. The PSI library's processings export their results in XML format. This enables an easy data manipulation during the recognition process, especially for XML objects reconstruction. Like this, the PSI library provides an embeddable processings set for graphics recognition systems, allowing various recognition approaches...|$|R
25|$|Google Keep has {{received}} mixed reviews. A review just after launch in 2013 praised its speed, {{the quality of}} voice notes, synchronization, and the widget that could {{be placed on the}} Android home screen. Reviews in 2016 have criticized the lack of formatting options, inability to undo changes, and an interface that only offers two view modes where neither was liked for their handling of long notes. However, Keep received praise for features including universal device access, native integration with other Google services, and the option to turn photos into text through optical <b>character</b> <b>recognition.</b>|$|E
25|$|On 25 September 2013, Nintendo {{announced}} it had purchased a 28% {{stake in a}} Panasonic spin-off company called PUX Corporation. The company specializes in face and voice recognition technology, with which Nintendo intends to improve the usability of future game systems. Nintendo has also worked with this company {{in the past to}} create <b>character</b> <b>recognition</b> software for a Nintendo DS touchscreen. After announcing a 30% dive in profits for the April to December 2013 period, president Satoru Iwata announced he would take a 50% pay-cut, with other executives seeing reductions by 20%–30%.|$|E
25|$|Optical <b>character</b> <b>recognition</b> (OCR) is {{preferable}} to rekeying for converting existing text that is already written down but not in machine-readable format (for example, a Linotype-composed book from the 1940s). In other words, to convert the text from an image to editable text (that is, a string of character codes), a person could re-type it, or a computer could look at the image and deduce what each character is. OCR technology has already reached an impressive state (for example, Google Book Search) and promises more for the future.|$|E
40|$|International audienceSkew angle {{detection}} {{is one of}} {{the most}} important component of Optical <b>Characters</b> <b>Recognition</b> (OCR) systems and documents analysis. Taking documents by the blind and visually impaired people with a mobile phone always have a degree of inclination. In this paper, a novel and an efficient method based on extraction of Harris corner features points and Hough transform is presented to estimate skew angle of printed documents. A comparative study using the ICDAR 2015 database with the wellknown methods in literature, shown the effectiveness and the performance of the proposed algorith...|$|R
40|$|Abstract—In this paper, we {{are focused}} on <b>characters</b> <b>recognition,</b> for this we present a {{comparison}} between the Krawtchouk Invariant Moment (KIM) and the Pseudo Zernike Invariant Moment (PZIM) for the recognition of printed Arabic characters (translated, rotated and contaminated by noise). In the preprocessing phase, we use the thresholding technique, and in the learning-classification phases, we use the supports vectors machines (SVM). The simulation results demonstrates that the KIM method gives more significant results that the PZIM for each Arabic character. Index Terms—Recognition, Printed Arabic characters, Krawtchouk invariant moments, Pseudo Zernike invarian...|$|R
40|$|<b>Characters</b> <b>recognition</b> {{in natural}} images is a {{challenging}} problem, asit involves segmenting characters of various colours on various background. Inthis article, {{we present a}} method for segmenting images that use a colour percep-tion graph. Our algorithm is inspired by graph cut segmentation techniques andit use an edge detection technique for filtering the graph before the graph-cut aswell as merging segments as a final step. We also present both qualitative andquantitative results, which show that our algorithm perform at slightly better andfaster {{to a state of}} the art algorithm. CADICS; ELLIIT; CUA...|$|R
25|$|Google Keep is a note-taking service {{developed}} by Google. Launched on March 20, 2013, Google Keep {{is available on}} the web, and has mobile apps for the Android and iOS mobile operating systems. Keep offers a variety of tools for taking notes, including text, lists, images, and audio. Users can set reminders, which are integrated with Google Now. Text from images can be extracted using optical <b>character</b> <b>recognition,</b> and voice recordings can be transcribed. The interface allows for a single-column view or a multi-column view. Notes can be color-coded, and labels can be applied for organization. Later updates have added functionality to pin notes, and to collaborate on notes with other Keep users in real-time.|$|E
25|$|Monospaced typefaces {{function}} {{better for}} some purposes because their glyphs {{line up in}} neat, regular columns. No glyph is given any more weight than another. Most manually operated typewriters use monospaced fonts. So do text-only computer displays and third- and fourth-generation game console graphics processors, which treat the screen as a uniform grid of character cells. Most computer programs which have a text-based interface (terminal emulators, for example) use only monospaced fonts (or add additional spacing to proportional fonts to fit them in monospaced cells) in their configuration. Monospaced fonts are commonly used by computer programmers for displaying and editing source code so that certain characters (for example parentheses used to group arithmetic expressions) are easy to see. Monospaced fonts may also {{make it easier to}} perform optical <b>character</b> <b>recognition.</b>|$|E
500|$|In the 1950s, SRI {{worked under}} the {{direction}} of the Bank of America to develop ERMA (Electronic Recording Machine, Accounting) and magnetic ink <b>character</b> <b>recognition</b> (MICR). The ERMA project was led by computer scientist Jerre Noe, who was at the time SRI's assistant director of engineering. [...] As of 2011, MICR remains the industry standard in automated check processing.|$|E
40|$|This paper {{focuses on}} the {{segmentation}} of printed Bangla <b>characters</b> for efficient <b>recognition</b> of the <b>characters.</b> Bangla {{is one of the}} most popular scripts in the world. The segmentation of characters is an important step in the process of <b>character</b> <b>recognitions</b> because it allows the system to classify the characters more accurately and quickly. In case of Bangla, the problem is a more difficult one because there are about 300 basic, modified and com-pound character shapes in the script. Here the characters are topologically connected and Bangla is an inflectional language. Because of these complexities there exists no efficient system relating to segmentation. These complex problems have been overcome in our proposal. We have applied a two phase approach in order to overcome the common problems related to the segmentation of printed Bangla characters...|$|R
40|$|This paper {{focuses on}} the {{segmentation}} of printed Bangla <b>characters</b> for efficient <b>recognition</b> of the <b>characters.</b> The segmentation of characters {{is an important step}} in the process of <b>character</b> <b>recognitions</b> because it allows the system to classify the characters more accurately and quickly. The system takes the scanned image file of the printed document as its input. A structural feature extraction method is used to extract the feature. In this case, each individual Bangla character is converted to a M × N feature matrix. A Multi-Layer Perceptron (MLP) neural network with back propagation algorithm is chosen to feed the feature matrix to train with the set of input patterns and to develop knowledge to classify the character. The effectiveness of the system has been tested with several printed documents and the success rates in all cases are over 90 %...|$|R
40|$|Abstract—This paper {{describes}} {{the method of}} handwritten <b>characters</b> <b>recognition</b> and the experiments carried out with it. The characters used in our experiments are numeric characters used in post code of mail pieces. The article contains basic image processing of the character and calculation of characteristic features, on basis of which it will be recognized. The main objective {{of this article is}} to use Radon Transform and Principal Component Analysis methods to obtain a set of features which are invariant under translation, rotation, and scaling. Sources of errors as well as possible improvement of classification results will be discussed. I...|$|R
