30|26|Public
50|$|DIACAP {{differs from}} DITSCAP in several ways—in particular, in its {{embrace of the}} idea of {{information}} assurance controls (defined in DoDD 8500.1 and DoDI 8500.2) as the primary set of security requirements for all automated information systems (AISs). IA Controls are determined based on the system's mission assurance category (MAC) and <b>confidentiality</b> <b>level</b> (CL).|$|E
5000|$|Mandatory Security Policy - Enforces {{access control}} rules based {{directly}} on an individual's clearance, authorization {{for the information}} and the <b>confidentiality</b> <b>level</b> of the information being sought. Other indirect factors are physical and environmental. This policy must also accurately reflect the laws, general policies and other relevant guidance from which the rules are derived.|$|E
5000|$|The Commission {{meets the}} {{requirements}} for an independent body {{as defined by the}} UN Convention against Corruption since it is not subordinate to any other state institution or ministry, and does not receive direct instructions from either the executive or the legislative branches. Parliament determines its budget yearly. The Commission is autonomous in the way it allocates the financial resources. It does not have power of the law enforcement or prosecution system, but it has access to financial and other documents (notwithstanding the <b>confidentiality</b> <b>level),</b> and power to conduct administrative investigations. It has power to issue fines for different violations (sanctions can be appealed to the Court).|$|E
40|$|Abstract—Non–interference is a {{semantic}} program property that assigns <b>confidentiality</b> <b>levels</b> to data objects and prevents illicit information flows to occur from high to low security levels. Erasure {{is a way}} of strengthening confidentiality by upgrading data <b>confidentiality</b> <b>levels,</b> up to the extreme of demanding the removal of secret data from the system. In this paper, we propose a certification technique for confidentiality of complete Java classes that includes non–interference and erasure policies. This technique is based on rewriting logic, which is a very general logical and semantic framework that is efficiently implemented in the high-level programming language Maude. In order to achieve a finite state transition system, we develop an abstract Jav{{a semantic}}s which correctly approximates non– interference and erasure. The analysis produces certificates that are independently checkable, and are small enough to be used in practice. We have implemented our methodology and developed some experiments that demonstrate the feasibility of our approach. I...|$|R
30|$|While {{relevant}} {{reliability and}} <b>confidentiality</b> <b>levels</b> with a reasonable SNR gap between Bob and Eve may seem illusive with simple coding schemes {{such as the}} mentioned BCH code, this metric enables the selection of t-error correcting codes {{that can be used}} in more evolved concatenated coding schemes combined with the generation of interference [6] to provide desired levels of reliability and confidentiality, as will be described in Section 4.1.|$|R
40|$|We {{address the}} issue of {{declassification}} in a language-based security approach. We introduce, in a Core ML-like language with concurrent threads, a declassification mechanism that {{takes the form of a}} local flow policy declaration. The computation in the scope of such a declaration is allowed to implement information flow according to the local policy. This dynamic view of information flow policies is supported by a concrete presentation of the security lattice, where the <b>confidentiality</b> <b>levels</b> are sets of principals, similar to access control lists. To take into account declassification, and more generally dynamic flow policies, we introduce a generalization of non-interference, that we call the non-disclosure policy, and we design a type and effect system for our language that enforces this policy. 1...|$|R
40|$|AbstractIn cloud {{computing}} systems, {{the data is}} stored on remote servers accessed through the internet. The increasing volume of personal and vital data, brings up more focus on storing the data securely. Data can include financial transactions, important documents, and multimedia contents. Implementing {{cloud computing}} services may reduce local storage reliance {{in addition to reducing}} operational and maintenance costs. However, users still have major security and privacy concerns about their outsourced data because of possible unauthorized access within the service providers. The existing solutions encrypt all data using the same key size without taking into consideration the <b>confidentiality</b> <b>level</b> of data which in turn will increase the cost and processing time. In this research, we propose a secure cloud computing model based on data classification. The proposed cloud model minimizes the overhead and processing time needed to secure data through using different security mechanisms with variable key sizes to provide the appropriate <b>confidentiality</b> <b>level</b> required for the data. The proposed model was tested with different encryption algorithms, and the simulation results showed the reliability and efficiency of the proposed framework...|$|E
30|$|This metric {{can also}} be used to {{fine-tune}} the security and reliability levels of a coding scheme that relies on t-error correcting codes. For example, if we assume no inner code and set the outer code to a BCH(127, 64) code that corrects up to 10 errors, and if we want a reliability level of Pr(E≤ 10)> 0.99, Bob would have to operate at an SNR above 1.95 dB as indicated in Fig.  3. For a <b>confidentiality</b> <b>level</b> of 0.99, i.e., Pr(E≤ 10)< 0.01, Eve would need to operate at SNR below −[*] 2.78 dB.|$|E
40|$|<b>Confidentiality</b> <b>Level</b> Public Abstract: We {{present a}} system for {{multi-modal}} immersion through 3 D vision, haptics and audio in a collocated setup. A platform, I-Touch, was developed to easily integrate various modalities in software {{for the purpose of}} testing the effect of different modalities on the user in an immersive environment. In addition, the data exploration system from workpackage 7 was integrated in the setup resulting in an improved exploration experience for segmentation of the small intestine. Finally, a multi-modal bone-drilling tool is being developed to demonstrate the usability of the ViSHaRD 10 haptic device...|$|E
40|$|Access control {{mechanisms}} {{are widely used}} {{with the intent of}} enforcing confidentiality and other policies, but few formal connections have been made between information flow and access control. Java and C ♯ are object-oriented languages that provide fine-grained access control. An access control list specifies local policy by authorizing permissions for principals (code sources) associated with class declarations; a mechanism called stack inspection checks permissions at run time. An example is given to show how this mechanism can be used to achieve confidentiality goals in situations where a single system call serves callers of differing <b>confidentiality</b> <b>levels</b> and dynamic access control prevents release of high information to low callers. A novel static analysis is given which applies to such examples. The analysis is shown to ensure a noninterference property formalizing confidentiality. 1...|$|R
40|$|Abstract. Non–interference is a {{semantic}} program property that assigns <b>confidentiality</b> <b>levels</b> to data objects and prevents illicit information flows from occurring from high to low security levels. In this paper, {{we present a}} novel security model for global non–interference which approximates non–interference as a safety property. We also propose a certification technique for global non-interference of complete Java classes based on rewriting logic, a very general logical and semantic framework that is efficiently implemented in the high-level programming language Maude. Starting from an existing Jav{{a semantic}}s specification written in Maude, we develop an extended, information–flow Java semantics {{that allows us to}} correctly observe global non-interference policies. In order to achieve a finite state transition system, we develop an abstract Java semantics that we use for secure and effective non-interference Java analysis. The analysis produces certificates that are independently checkable and are small enough to be used in practice. ...|$|R
40|$|Non-interference is a {{semantic}} program property that assigns <b>confidentiality</b> <b>levels</b> to data objects and prevents illicit information flows from occurring from high to low security levels. In this paper, {{we present a}} novel security model for global non-interference which approximates non-interference as a safety property. We also propose a certification technique for global non-interference of complete Java classes based on rewriting logic, a very general logical and semantic framework that is efficiently implemented in the high-level programming language Maude. Starting from an existing Jav{{a semantic}}s specification written in Maude, we develop an extended, information-flow Java semantics {{that allows us to}} correctly observe global non-interference policies. In order to achieve a finite state transition system, we develop an abstract Java semantics that we use for secure and effective non-interference Java analysis. The analysis produces certificates that are independently checkable and are small enough to be used in practice. Comment: 26 pages. ACM class (full) : D. 2. 4 [Software Engineering]: Software/Program Verification [...] -Formal Methods; F. 3. 2 [Logics and Meaning of Programs]: Semantics of Programming Languages [...] -Program Analysi...|$|R
40|$|In {{this paper}} we address {{confidentiality}} issues in distributed data clustering, particularly the inference problem. We present KDEC-S algorithm for distributed data clustering, which is shown to provide mining results while preserving confidentiality of original data. We also present a confidentiality framework {{with which we can}} state the <b>confidentiality</b> <b>level</b> of KDEC-S. The underlying idea of KDEC-S is to use an approximation of density estimation such that the original data cannot be reconstructed to a given extent. Key words: Privacy-preserving data mining, distributed data mining, data clustering, inference problem. ...|$|E
40|$|Data leakage means sending {{confidential}} data to an unauthorized person. Nowadays, identifying {{confidential data}} {{is a big}} challenge for the organizations. We developed a system by using data mining techniques, which identifies confidential data of an organization. First, we create clusters for the training data set. Next, identify confidential terms and context terms for each cluster. Finally, based on the confidential terms and context terms, the <b>confidentiality</b> <b>level</b> of the detected document calculated in terms of score. If the score of the detected document beyond a predefined threshold, then the document is blocked and marked as a confidential...|$|E
40|$|This paper {{analyzes}} various distributed storage {{systems that}} use data fragmentation and dispersal {{as a way}} of protection. Existing solutions have been organized into two categories: bitwise and structurewise. Systems from the bitwise category are operating on unstructured data and in a uniform environment. Those having structured input data with predefined <b>confidentiality</b> <b>level</b> and disposing of a heterogeneous environment in terms of machine trustworthiness were classified as structurewise. Furthermore, we outline high-level requirements and desirable architecture traits of an eficient data fragmentation system, which will address performance (including latency), availability, resilience and scalability. Comment: arXiv admin note: text overlap with arXiv: 1512. 0295...|$|E
40|$|Data-related {{properties}} of the activities involved in a service composition {{can be used to}} facilitate several design-time and run-time adaptation tasks, such as service evolution, distributed enactment, and instance-level adaptation. A number of these properties can be expressed using a notion of sharing. We present an approach for automated inference of data properties based on sharing analysis, which is able to handle service compositions with complex control structures, involving loops and sub-workflows. The properties inferred can include data dependencies, information content, domain-defined attributes, privacy or <b>confidentiality</b> <b>levels,</b> among others. The analysis produces characterizations of the data and the activities in the composition in terms of minimal and maximal sharing, which can then be used to verify compliance of potential adaptation actions, or as supporting information in their generation. This sharing analysis approach can be used both at design time and at run time. In the latter case, the results of analysis can be refined using the composition traces (execution logs) at the point of execution, in order to support run-time adaptation...|$|R
40|$|Modern network {{technologies}} {{were not}} designed for high assurance applications. As the DOD moves towards implementing the Global Information Grid (GIG), hardened networks architectures will be required. The Monterey Security Architecture (MYSEA) is one such project. This work addresses the issue of object reuse {{as it pertains to}} volatile memory spaces in untrusted MYSEA clients. When a MYSEA client changes <b>confidentiality</b> <b>levels,</b> it is possible that classified material remains in volatile system memory. If the system is not power cycled before the next the login, an attacker could retrieve sensitive information from the previous session. This thesis presents a conceptual design to protect against such an attack. A processor may undergo a hard or soft reboot. The proposed design uses a secure coprocessor to sense the reboot type of the host platform. In addition, a count is kept of the number of hard reboots the host platform has undergone. Using services provided by the secure coprocessor, the host platform can trustfully attest to a remote entity that it has undergone a hard reboot. This addresses the MYSEA object reuse problem. The design was tested using the CPU simulator software SimpleScalar...|$|R
40|$|Complete {{security}} proofs for {{quantum communication}} protocols can be notoriously involved, which convolutes their verification, and obfuscates the key physical insights the security finally relies on. In such cases, {{for the majority}} of the community, the utility of such proofs may be restricted. Here we provide a simple proof of confidentiality for parallel quantum channels established via entanglement distillation based on hashing, in the presence of noise, and a malicious eavesdropper who is restricted only by the laws of quantum mechanics. The direct contribution lies in improving the linear <b>confidentiality</b> <b>levels</b> of recurrence-type entanglement distillation protocols to exponential levels for hashing protocols. The proof directly exploits the security relevant physical properties: measurement-based quantum computation with resource states and the separation of Bell-pairs from an eavesdropper. The proof also holds for situations where Eve has full control over the input states, and obtains all information about the operations and noise applied by the parties. The resulting state after hashing is private, i. e., disentangled from the eavesdropper. Moreover, the noise regimes for entanglement distillation and confidentiality do not coincide: Confidentiality can be guaranteed even in situation where entanglement distillation fails. We extend our results to multiparty situations which are of special interest for secure quantum networks. Comment: 4 + 11 pages, 0 + 4 figures, A. Pirker and M. Zwerger contributed equally to this wor...|$|R
40|$|International audienceIn {{the field}} of video protection, {{selective}} encryption (SE) is a scheme which ensures a visual security of video by encrypting {{a small part of}} data. This paper presents a new SE algorithm for H. 264 /AVC in CAVLC mode. This algorithm controls the amount of encrypted alternative coefficients (AC) of the integer transform in the entropic encoder. Two visual quality measures, the peak signal-to-noise ratio (PSNR) and the structural similarity (SSIM), are used to measure the visual <b>confidentiality</b> <b>level</b> of each video frame and to regulate the amount of encrypted alternatives coefficients. This method can be applied on intra and inter frame video sequences...|$|E
40|$|Abstract. Workflow {{management}} systems {{are increasingly being}} used to automate scientific discovery. Provenance meta-data is collected about workflows, processes, simulations and data to add value. This meta-data and provenance information may have as much value as the raw data. Typically, sensitive information produced by a computational processes or experiments is well guarded. However, this {{may not necessarily be}} true when it comes to provenance information. The issue is how to appropriately share confidential provenance information. We present a model for sharing provenance information when the <b>confidentiality</b> <b>level</b> is dynamically decided by the user. The key characteristic of this model is the Query Sharing concept. We illustrate the model for workflows implemented using provenance enabled Kepler system...|$|E
40|$|This work {{presents}} an implementation strategy which exploits separation of concerns and reuse in a multi-tier architecture {{to improve the}} security (availability, integrity, and <b>confidentiality)</b> <b>level</b> of an existing application. Functional properties are guaranteed via wrapping of the existing software modules. Security mechanisms are handled by the business logic of the middle-tier: availability and integrity are achieved via replication of the functional modules, confidentiality is obtained via cryptography. The technique is presented with regard to a case study application. We believe our experience {{can be used as}} a guideline for software practitioners to solve similar problems. We thus describe the conceptual model behind the architecture, discuss implementation issues, and present technical solutions...|$|E
40|$|In {{this thesis}} we propose an {{abstraction}} based certification technique for Java programs {{which is based}} on rewriting logic, a very general logical and semantic framework efficiently implemented in the functional programming language Maude. We focus on safety properties, i. e. properties of a system that are defined in terms of certain events not happening, which we characterize as unreachability problems in rewriting logic. The safety policy is expressed in the style of JML, a standard property specification language for Java modules. In order to provide a decision procedure, we enforce finite-state models of programs by using abstract interpretation. Starting from a specification of the Java semantics written in Maude, we develop an abstraction based, finite-state operational semantics also written in Maude which is appropriate for program verification. As a by-product of the verification based on abstraction, a dependable safety certificate is delivered which consists of a set of rewriting proofs that can be easily checked by the code consumer by using a standard rewriting logic engine. The abstraction based proof-carrying code technique, called JavaPCC, has been implemented and successfully tested on several examples, which demonstrate the feasibility of our approach. We analyse local properties of Java methods: i. e. properties of methods regarding their parameters and results. We also study global confidentiality properties of complete Java classes, by initially considering non [...] interference and, then, erasure with and without non [...] interference. Non [...] interference is a semantic program property that assigns <b>confidentiality</b> <b>levels</b> to data objects and prevents illicit information flows from occurring from high to low security levels. In this thesis, we present a novel security model for global non [...] interference which approximates non [...] interference as a safety property. Alba Castro, MF. (2011). Abstract Certification of Java Programs in Rewriting Logic [Tesis doctoral no publicada]. Universitat Politècnica de València. doi: 10. 4995 /Thesis/ 10251 / 13617. Palanci...|$|R
40|$|An {{overview}} of two R&D projects provides summarised {{case studies of}} the ongoing development of two distinct performance improvement systems that can help empower different segments of the industry. The first project focuses on a Management Support System (MSS) for large clients (LCs); while the second aims at Information and Knowledge Management Systems (IKMSs) for Small & Medium Contractors (SMCs). Finally, the paper points to the potential for an integrated system that can provide useful linkages across these extremities of the construction supply chain by proposing a LC based Project Information & Knowledge Management Platform (PIKMAP). The latter could serve specific projects by providing useful seamless interfaces with all stakeholders, including the LC, its consultants, contractors and suppliers, as well as SMCs involved. Certain issues will of course need to be carefully addressed e. g. in terms of <b>confidentiality,</b> security <b>levels</b> and legal liabilities in respect of each stakeholder...|$|R
40|$|Abstract — This article {{emphasizes}} a {{new layer}} to information rights management {{as it applies}} to security, privacy and <b>confidentiality</b> of field <b>level</b> data elements. In the interconnected economy, consumers and corporations develop an electronic relationship where commercial and online applications provide convenient access to account data. As consumer use of digital information systems become widespread, the greater the need to protect their proprietary information with more secure authentication protocols. Human Digitization (“HD”) involves creating a customer profile {{at the onset of the}} data collection and encoding each data element with an access key. The use of authentication profiles in digital information rights management systems mitigates unauthorized data access and provides protection on three levels: 1) internal-employee access, 2) external-customer access, and 3) computer-program access...|$|R
40|$|The cloud {{database}} as {{a service}} is a novel paradigm that can support several Internet-based applications, but its adoption requires the solution of information confidentiality problems. We propose a novel architecture for adaptive encryption of public cloud databases that offers an interesting alternative to the trade-off between the required data <b>confidentiality</b> <b>level</b> and {{the flexibility of the}} cloud database structures at design time. We demonstrate the feasibility and performance of the proposed solution through a software prototype. Moreover, we propose an original cost model that is oriented to the evaluation of cloud database services in plain and encrypted instances and that takes into account the variability of cloud prices and tenant workload during a medium-term period...|$|E
40|$|Abstract—The cloud {{database}} as {{a service}} is a novel paradigm that can support several Internet-based applications, but its adoption requires the solution of information confidentiality problems. We propose a novel architecture for adaptive encryption of public cloud databases that offers an interesting alternative to the tradeoff between the required data <b>confidentiality</b> <b>level</b> and {{the flexibility of the}} cloud database structures at design time. We demonstrate the feasibility and performance of the proposed solution through a software prototype. Moreover, we propose an original cost model that is oriented to the evaluation of cloud database services in plain and encrypted instances and that takes into account the variability of cloud prices and tenant workloads during a medium-term period. Index Terms—Cloud database, confidentiality, encryption, adaptivity, cost model Ç...|$|E
40|$|This thesis {{improves}} {{the current state}} of the art on information-flow control of interactive and object-oriented programs, respectively. Given a policy which specifies which information flows are permitted in a program, the objective here is to ensure that only flows satisfying the policy can occur. The challenge is to develop a sane policy and an automated, permissive enforcement mechanism for said policy. For interactive programs, we give a progress-sensitive noninterference (PSNI) policy which takes into account the <b>confidentiality</b> <b>level</b> of the pres-ence of messages. We show that the finer granularity obtained through pres-ence levels makes PSNI parallel compositional, and we give a proven-sound, static, flow-sensitive type-based enforcement of PSNI. We show that for de-terministic interactive programs, it suffices to consider simple stream-based attackers. We develop in this setting a progress-bounded noninterference (PBNI) which bounds the leak through progress observations to a logarith...|$|E
40|$|The {{controlled}} {{interaction of}} processes in a computing environment is fundamental for its security and reliability. Processes can be attacked by other processes or by external clients, errors in one process can propagate to others. We show here three patterns {{that can help}} provide a secure and reliable execution environment although {{they need to be}} complemented with other patterns. They include Protected Entry Points, which control the correct use of entry points according to their signatures (type and length of parameters); and Protection Rings, which control the calls between processes, enforcing constraints on entry points and signatures according to the level of trust in the processes. Finally, the Multilevel Secure Partitions (MSP) pattern, confines execution of a process to a system partition that has a specific <b>confidentiality</b> or integrity <b>level.</b> 1...|$|R
40|$|Secret {{communication}} {{techniques are}} of great demand since last 3000 years {{due to the}} need of information security and <b>confidentiality</b> at various <b>levels</b> of communication such as while communicating confidential personal data, medical data of patients, defence and intelligence information of countries, data related to examinations etc. With advancements in image processing research, Image encryption and Steganographic techniques have gained popularity over other forms of hidden communication techniques {{during the last few}} decades and a number of image encryption models are suggested by various researchers from time to time. In this paper, we are suggesting a new image encryption model based on Fibonacci and Lucas series. Comment: International Journal on Cryptography and Information Security (IJCIS),Vol. 2, No. 3, September 2012, Pp. 131 - 141 (11 Pages), 6 figures. [URL]...|$|R
40|$|Globalisation and {{technology}} {{have resulted in}} an increase in international commerce, capital flows and the movement of goods and services across borders. Such factors have also increased opportunities to launder money and reintergrate the proceeds of crime into the legitimate economy. In response to such developments, as well as perceived threats to their national economies and tax-bases, the G 7 /G 8 and the OECD have created various International initiatives, to combat money-laundering, which have targeted jurisdictions offering limited financial regulation, bank <b>confidentiality</b> and low <b>levels</b> of taxation. These initiatives, however suffer from a legitimacy gap, owing to the vertical unilaterality of the regimes they seek to institute. This work will attempt to examine the origins and purpose of the homogenising global anti-money laundering regime. It shall also examine its legitimacy and effectiveness, with emphasis on Offshore Financial Centres...|$|R
40|$|We {{address the}} issue of {{declassification}} in a language-based security approach. We introduce, in a Core ML-like language with concurrent threads, a declassification mechanism that {{takes the form of a}} local flow policy declaration. The computation in the scope of such a declaration is allowed to implement information flow according to the local policy. To take into account declassification, and more generally dynamic flow policies, we introduce a generalization of non-interference, that we call the non-disclosure policy, and we design a type and effect system for our language that enforces this policy. Besides dealing with declassification, our type system improves over previous systems for checking information flow in two directions: first, we show that the typing of terminations leaks can be largely improved, by particularizing the case where the alternatives in a conditional branching both terminate. Moreover, we also provide a quite precise way of approximating the <b>confidentiality</b> <b>level</b> of an expression, by ignoring the level of values that are only used for side-effects. 1...|$|E
40|$|URL] audienceNoninterference is the {{mathematical}} basis for confidentiality analyses. The {{idea is to}} ensure that private data will not be observable at a public level. Understood in a strict way noninterference is a too strong property. Standard every day life examples like password checks or message encryption formally break the noninterference property. In this paper we propose a framework in which it is possible to define an interference policy allowing to define safe data declassification. Moreover this policy is dynamic, i. e. the <b>confidentiality</b> <b>level</b> of data may evolve during computation: think at policies in which you want to express that a user has a limited number of guesses or to the sending of a pay-per-view information. We develop a notion of program safety with relation to a dynamic interference policy and give an algorithm (in the form of an abstract evaluation of the program) to check that a program is safe with relation to a dynamic interference policy...|$|E
40|$|Security Assessment {{is widely}} used to audit the {{security}} protection of web applications. However, it is often performed by outside security experts or third party that has been appointed by the company. The problem appears when the assessment involves highly confidential areas that might impact company’s privacy data which directly reveal the important information to the third party. Even though they might have signed an agreement of non-disclosure information, but as they have already had {{the information on the}} infrastructure and architecture regardless of the confidential data, it has to be considered as a high risk. It is important to keep the information within the project members to protect the confidential data used by the system. Therefore, due to <b>confidentiality</b> <b>level</b> of the system, we proposed Self- Assessment framework to conduct security assessment internally {{to ensure the safety of}} all the assets of the organization. The main objective of this paper is to discuss the activities and processes involve in conducting security assessment...|$|E
40|$|Project Specification Basic Systems Monitoring This is now {{done with}} a CERN-made custom {{collector}} which sends data {{in the form of}} "notifications" via Apache Flume to HDFS for long-term storage. The notifications are also sent to ElasticSearch and displayed with Kibana (à la Splunk). Due to limitations of the architecture, the system data is collected every 5 minutes which is not ideal. The idea is to implement a solution which allows more fine-grained sampling of system metrics. Possible ideas are OpenTSDB (to leverage the existing Hadoop infrastructure) or prometheus. io, which should be simpler to setup but it only scales out by sharding. OpenTSDB initially seems like a more promising solution, so investigate the various collection and display alternatives. Logs Management and Centralisation. This is now done only for syslog with Apache Flume - shipping to HDFS (and kept "forever") and to Elasticsearch/Kibana, with a 1 month retention time. There are two issues: flexibility of the collection process, and authorisation. On the flexibility side, collected messages need to be split into different fields before being stored in HDFS/Elasticsearch, in order to ease the data mining process. Logstash and grok are potentially promising solutions. On the authorisation side, the idea here is to specifically target the Weblogic installations in order to expose to clients their application logs in a convenient way, and as we host very different applications with different <b>confidentiality</b> <b>levels</b> (amazing what can be found in some application logs!) we need to put an authorisation layer on top of HDFS and ElasticSearch (Kibana just being JS querying ElasticSearch directly). For this there are some methods that could be implemented on HDFS, and for ElasticSearch there is a FOSS plugin to be checked. This part would probably involve setting up an ElasticSearch cluster first. Abstract There are a number of problems with the current monitoring infrastructure in IT-DB which currently make it difficult to diagnose certain system issues. These include lack of support for certain log formats, latency in messages, and inflexibility of architecture. Several changes to the log monitoring service architecture were evaluated over the period of several weeks, focusing on improving performance, verbosity, and reducing latency. Additionally, several changes to the metric monitoring architecture were evaluated, including deploying a new time-series database to test performance and latency. There were also a number of extra tests conducted on third-party visualisation dashboards and Elasticsearch security software. The proposed log monitoring architecture was found to be useful, and will be the subject of further development and evaluation. The proposed metric monitoring architecture was also found to be useful, but needs further investigation to decide if it is a significant enough improvement over the current architecture to be of value. There were also several software packages found to be unsuitable or unstable, and these are not used in the proposed system architectures. The evaluation was largely successful as much of the work was either found to be unsuitable or will be the subject of further development...|$|R
40|$|Confidentiality {{is a most}} {{significant}} and least understood security issue in cyber-physical systems. Many aspects of the system can jeopardize confidentiality. A great deal of research and effort is spent in integrity and confidentiality through authentication and encryption. However, even with the authentication mechanism working properly, the system's confidential information can be breached through unrestricted information flow or other implicit deducible information channels at the cyber-physical boundary. This paper conducts an information flow analysis using security models of <b>confidentiality</b> at different <b>levels</b> of the advanced electric power grid using cooperating FACTS devices. Taking only the FACTS device's settings and control operations as confidential information, even if the information flow satisfies certain security models, confidential information may still be deducible by observation or inference. The information flow analysis in this paper raises awareness that authentication itself {{is not enough to}} protect the confidentiality of a cyber-physical system. The analysis of the architecture of FACTS power system can be extended to many other cyber-physical systems...|$|R
40|$|Mental {{illness is}} high in prison populations and {{collaboration}} between mental health (MHS) and criminal justices systems (CS) is required to address this. Cultural historical activity theory {{is used as a}} lens to explore the complexity of these interactions through informing the analysis of interviews with MHS and CS leaders (n= 12) that explored the nature of collaborative practice between these two systems in a Norwegian context. This analysis showed collaborative practice between the MHS and CS to revolve largely around the work goal of rehabilitating and reintegrating the offender back into society. The boundary space at the point of overlap between the two systems is an activity system within its own right, where communication between the two systems are mediated by a range of tools, norms and rules that include multi agency meetings and coordination tools. Key contradictions occur within this boundary space activity system, that limits collaboration between the MHS and CS, and include conflicts related to different interpretations of patient <b>confidentiality</b> and threshold <b>levels</b> for transfer of prisoners from prison into specialist mental health facilities. The paper explores the potential of the Change Laboratory method to improve collaborative practice in this context...|$|R
