0|30|Public
3000|$|..., in the {{forthcoming}} T slots. This implies that if keeping the current <b>queue</b> <b>configuration</b> unchanged with the bit service rate V [...]...|$|R
40|$|In recent year’s {{organizations}} are increasingly utilizing workflow management systems technology, based on queuing models, to automate manual business processes. One {{industry that has}} seen {{one of the most}} rapid implementation and deployment of workflow systems in recent years is the services call center industry. Despite the great promise, workflow queue monitoring and work distribution continue to pose great challenges to organizations in terms of operational efficiency and performance. The primary reason for the inherent performance problems is whether the queues are configured as static or dynamic queues. In this study, static and dynamic <b>queue</b> <b>configurations,</b> based on M/M/c and M/M/I queuing models in the call center context are compared across several performance dimensions. An empirical study was used to compare the performance of a static versus a dynamic configuration in a call center context. Results suggest that dynamic <b>queue</b> <b>configurations</b> perform better than static <b>queue</b> <b>configurations.</b> A simulation model using parameter estimates from the real-life case was used to understand the results further. Overall, the superiority of dynamic workflow systems over static workflow systems in the call center context is confirmed in this study...|$|R
40|$|In systems {{consisting}} of multiple clusters of processors which employ space sharing for scheduling jobs, such as our Distributed ASCI Supercomputer (DAS), co-allocation, i. e., the simultaneous allocation of processors to single jobs in multiple clusters, may be required. In order to handle both single-cluster (local) jobs and multi-cluster (global) jobs, such systems may have only local schedulers (which then {{need to be}} aware of the whole system), or only a single global scheduler or both, and each scheduler has its own queue. We assess with simulations the response times of both local and global jobs in multicluster systems for different <b>configurations</b> of <b>queues,</b> for different priority orders in which the associated schedulers are allowed to schedule jobs, and for different job-stream compositions...|$|R
50|$|Baxter {{finally decided}} on the current <b>configuration,</b> with the <b>queue</b> going {{underneath}} a themed footbridge, thereby freeing the walkway. He then {{set his sights on}} Walt's old Royal Suite, just above the queue. Baxter designed a pair of ornamental staircases that would hug the footbridge and create a unique frame for the building exterior. Baxter had thought that a beautiful place like Walt's suite was going to waste not being seen by park guests.|$|R
40|$|We {{study how}} <b>queue</b> <b>configuration</b> affects human servers’ service time by {{comparing}} dedicated queues with shared queues using field {{data from a}} natural experiment in a supermarket. We hypothesize that <b>queue</b> <b>configuration</b> may affect servers’ service rate through several mechanisms: pooling may affect service rate directly {{as a result of}} social loafing effect and competition effect and indirectly via its impact on queue length. To investigate these impacts, we take advantage of the supermarket’s checkout layout and use a data set containing both checkout transaction details and queue information collected from video recordings in the supermarket. After we control for the queue length, we find that servers in dedicated queues are about 10. 7 % faster than those in shared queues, mainly because of the social loafing effect. We also demonstrate that pooling has an indirect negative effect on service time through its impact on queue length. In addition, the queue configuration’s direct effect and its indirect queue length effect function independently of each other. In aggregation, the social loafing effect dominates, and servers slow down (a 6. 86 % increase in service time) in shared queues. postprin...|$|R
40|$|The multidimensional {{stock control}} that {{functions}} {{in a random}} Markov environment is considered. The mathematical formalization of this model was considered {{with the use of}} sums of the random variables defined on the Markov chains. The authors introduce a definition of risk function of the type of downside risk measures and find the explicit formulas for its determinations. The example of the application of these formulas is provided: the tasks of the reliability and optimal <b>configuration</b> for the <b>queueing</b> problem are regarded. The formulas defining the function by the system parameters were obtainedstock control, multidimensional model, risk function, Markov chain, queueing system...|$|R
30|$|In this work, we {{consider}} {{a selection of}} performance metrics based on [40]. To represent the clients requesting service, {{we consider}} a queuing system M/M/ 1 /K, meaning that the arrival process is a Poisson process with rate λ (M), the service time is independent and exponentially distributed with parameter μ (M), {{there is only a}} single server to process the requests (1), and the capacity of the system is limited (K). This <b>queue</b> <b>configuration</b> allows the evaluation of relevant aspects of the system, such as the impact of different arrival times and different queue capacities [41]; it is commonly used to represent cloud requests ([42 – 46]).|$|R
40|$|OPNET Modeler {{represents}} nowadays one of {{the most}} important simulation tools used by the research community in the area of Quality of Service (QoS). Because of the complexity and of the multitude of configurations that are possible in a network domain or in the Internet, a number of specific implementations of QoS mechanisms are not yet available in simulation tools. This paper presents a new type of <b>queue</b> <b>configuration</b> mechanism that enables the dynamic creation of Resource Reservation Protocol (RSVP) queues, while maintaining the properties of the Differentiated Service (DiffServ) queue scheduling discipline for a specific interface. Practical considerations for extending the queue management facilities and supported QoS abilities of OPNET Modeler are illustrated. status: publishe...|$|R
40|$|This paper {{presents}} comprehensive {{decision-making procedures}} for designing a new toll plaza {{with the right}} initial capacity, then finding the optimal dynamic lane configuration for operations, evaluating the effects of increasing future traffic volume on waiting time by sensitivity analysis, and establishing a long-term quantitative strategy by transferring low-throughput lane users to high-throughput lanes. We develop a non-linear integer programming model integrated with the M/G/ 1 queueing process. A case study based on actual data demonstrates how effective the model and the strategy are in reducing operating and user-waiting costs and, thus, improving overall system performance at toll plazas. Toll plaza Transportation Optimization Dynamic <b>configuration</b> M/G/ 1 <b>queueing</b> process Non-linear integer programming...|$|R
50|$|In field experiments, {{researchers}} manipulate one or {{more independent}} variables in a natural setting {{to determine the effect}} on behavior. This method represents the most extreme form of intervention in observational methods, and researchers are able to exert more control over the study and its participants. Conducting field experiments allows researchers to make causal inferences from their results, and therefore increases external validity. However, confounding may decrease internal validity of a study, and ethical issues may arise in studies involving high-risk.For a great example of a field experiment study, see this study by Milgram, Liberty, Toledo, and Wackenhut exploring the relation between the unique spatial <b>configuration</b> of the <b>queue</b> and the means by which its integrity is defended.|$|R
40|$|To obtain large speed-up {{factors in}} Monte Carlo {{simulation}} using irnport. ance sampling (IS), the modification, or bias {{of the underlying}} probability measures must be carefully chosen. In this paper we present two stochastic gradient op tirnizat ion techniques that lead to favorable IS parameter settings in the simulation of queueing networks, including queues with bursty trafIic. Namely, we motivate and describe the Stochastic Gradient Descent (SCI)) algorithm, aud the Stochastic [lmporimit Event) F 1 'equcn('y Ascent (SFA) algorithm. 'vVe demonstrate the effectiveness of our algorithms by applying them {{to the problem of}} esl. imal. ing the cell loss probability of several queueing systems: first, a queue with an Interrupted Beruou lli arrival process, geolnetric service times, and finite capacity 1 < (denoted here by IBP /Geo / 1 / 1 <:); then, single and tandem <b>configurations</b> of <b>queues</b> with two arrival streams, a Modified Interrupted Bernoulli stream and a Markov Modulated Bernoulli stream with batch arrivals, deterministic service times, and finite capacity I ((denoted here by M-IBP+MlVIBBP/D/l/I. Such queueing systems arc useful building blocks in performance models for ATM nodes and networks. Speed-up factors of 1 to H orders of magnitude ove...|$|R
40|$|Abstmct — We {{present a}} new scheduler, the two-dimenswnal {{round-robin}} (2 DRR) scheduler, that provides high throughput and fair access in a packet switch that uses multiple input queues. We consider an architecture {{in which each}} input port maintains a separate queue for each output. In an. V x. V switch, our scheduler determines which of the queues in the total of. Y 2 input queues are served during each time slot. We demonstrate the fairness properties of the 2 DRR scheduler and compare its performance {{with that of the}} input and output <b>queueing</b> <b>configurations</b> showing that our scheme achieves the same saturation throughput as output queueing. The 2 DRR scheduler can be implemented using simple logic components thereby allowing a very high-speed implementation...|$|R
40|$|Both {{queuing theory}} {{analysis}} and discrete-event process simulation {{have often been}} used, sometimes jointly, to analyze and improve the performance of queuing systems. Queuing theory provides closed-form solutions for various canonical <b>queuing</b> <b>configurations,</b> whereas discrete-event process simulation is highly valuable for analysis of many queuing systems {{beyond the reach of}} such closed-form solutions. Since queues are extremely ubiquitous, both queuing theory analysis and discrete-process simulation are frequently and beneficially used by analysts, engineers, and business managers. During the study presented in this paper, discrete-event process simulation was used to analyze, specify, and improve operational policies in a large retail store. Results of the model guided store management toward policies, ultimately proved successful in practice, governing the thresholds of congestion warranting the opening and closing of cash-register lanes during a retailbusiness day...|$|R
40|$|Abstract — In {{this paper}} {{we present a}} study on mutual {{interactions}} between queue management algorithms implemented in Internet routers. The aim {{of this research was}} to detect possible issues connected with deployment of the active queue management (AQM) algorithms in the Internet. For that purpose, we simulated a net-work with four routers and checked its performance in different <b>configurations</b> of <b>queue</b> management algorithms. In particular, three basic configurations were considered: all routers in the network use the passive queue management, only one router in the network uses the active queue management (other routers use the passive queue management), all routers in the network use the active queue management. Six different AQM algorithms were used and tested in two congestion scenarios. In every case the performance of all bottleneck links was observed as well as the average performance of the whole network. In all the simulations, the average performance of the network, measured in terms of the queueing delay, was improved by when at least one router used an AQM algorithm. Moreover, in most cases the performance of every bottleneck link was also improved. These results give strong arguments for using AQM in the Internet. However, in some experiments we observed a performance degradation of particular bottleneck links when an AQM algorithm was used, indicating that some problems may indeed arise due to the mutual interactions of AQM routers...|$|R
40|$|Based on {{the vision}} {{that the most}} {{important}} component of the next generation of scientific computing environments is not the High-Performance Computer (HPC) itself, but rather a distributed computing infrastructure of national and/or even global scale, it is the goal of the project Interactive Scientific Computing over Networks (ISCN) to conduct feasibility studies and to incrementally prototype a distributed object-oriented framework for scientific computing applications on distributed HPC systems. In the initial stage of the ISCN project, we have implemented a client-server framework supporting simple interactive selection of different remote HPC servers, <b>configurations,</b> and batch <b>queues,</b> interactive access to the running application, even when submitted to batch queues, interactive supervision /steering of the application and immediate visualization of results, and an interactive mechanism to manipulate output data visualization. The communication infrastructure used is the CORBA-ba [...] ...|$|R
40|$|Currently, conflict-free routing in AGV {{systems is}} {{established}} {{by means of}} one of the following three approaches: (i) the problem elimination through the adoption of a segmented path flow or tandem <b>queue</b> <b>configuration,</b> (ii) the identification of imminent collisions through forward sensing and their aversion through vehicle backtracking and/or rerouting, or (iii) the imposition of zone control and extensive route pre-planning, typically based on deterministic timing of the vehicle traveling and docking stages. Among these three approaches, the segmented path flow-based approach presents the highest robustness to the system stochasticities/randomness, but at the cost of restricted vehicle routings and the need for complicated handling operations. This paper proposes an alternative conflict resolution strategy that will ensure robust AGV conflict resolution, while maintaining the operational flexibility provided by free vehicle travel on arbitrarily structured guidepath networks. Specific [...] ...|$|R
40|$|This diploma {{dissertation}} {{is dealing}} with the VoIP software exchange Asterisk. In the dissertation there are described its abilities and possible ways of its configuration. Special attention is given to the signalling protocol SIP, which is described in one of the chapters. Within this dissertation a dial plan, which demonstrates the technique of dial plan creating, was created. Within the boundaries of the dialplan following services could be found: a voicemail, conference, Interactive Voice Response and call <b>queues.</b> <b>Configuration</b> files, with the help of which the exchange is configurated, are described in my dissertation as well. Finally, three laboratory assignments for purposes of the subject Multimedia Services are mentioned. Their main aim is to familiarise students with the creation of SIP accounts in the exchange, their mutual connections, defining the Interactive Voice Response and forming a new call centre...|$|R
5000|$|Queuing is an {{analytic}} {{method for}} determining waiting time when customers must {{wait in line}} to get service. The length of the queue and waiting time can be calculated based on the arrival rate, service rate, number of servers and type of lines. There are many formulas for various types of queuing theory problems. [...] The formulas generally predict that the average service time must be significantly less than the average time between arrivals when there is randomness in arrivals and/or service time. The {{reason for this is}} that a long line will build up when randomness of arrivals occurs faster than the average and service times are longer than the average. If the distributions of arrival times and service times are known, formulas are available for calculating the exact waiting times and line lengths for many different <b>queuing</b> <b>configurations</b> of servers, types of lines, server distributions and arrival distributions.|$|R
40|$|We {{present a}} novel static {{analysis}} to infer the peak cost of distributed systems. The different locations of a distributed system communicate and coordinate their actions by posting tasks among them. Thus, {{the amount of}} work that each location has to perform can greatly vary along the execution depending on: (1) the amount of tasks posted to its queue, (2) their respective costs, and (3) the fact that they may be posted in parallel and thus be pending to execute simultaneously. The peak cost of a distributed location refers to the maximum cost that it needs to carry out along its execution. Inferring the peak cost is challenging because it increases and decreases along the execution, unlike the standard notion of total cost which is cumulative. Our key contribution is the novel notion of quantified <b>queue</b> <b>configuration</b> which captures the worst-case cost of the tasks that may be simultaneously pending to execute at each location along the execution. A prototype implementation demonstrates the accuracy and feasibility of the proposed peak cost analysis...|$|R
40|$|The data {{plane is}} in a {{continuous}} state of flux. Every few months, researchers publish {{the design of a}} new highperformance queueing or scheduling scheme that runs inside the network fabric. Many such schemes have been queen for a day, only to be surpassed soon after as methods — or evaluation metrics — evolve. The lesson, in our view: there will never be a conclusive victor to govern queue management and scheduling inside network hardware. We provide quantitative evidence by demonstrating bidirectional cyclic preferences among three popular contemporary AQM and <b>queueing</b> <b>configurations.</b> We argue that the way forward requires carefully extending Software-Defined Networking to control the fast-path scheduling and queueing behavior of a switch. To this end, we propose adding a small FPGA to switches. We have synthesized, placed, and routed hardware implementations of CoDel and RED. These schemes require only a few thousand FPGA “slices ” to run at 10 Gbps or more — a minuscule fraction of current low-end FPGAs — demonstrating the feasibility and economy of our approach. 1...|$|R
40|$|We {{consider}} {{a system of}} parallel queues where arriving service tasks are buffered, according to type. Available service resources are dynamically configured and allocated to the queues to process the tasks. At each point in time, a scheduler chooses a service <b>configuration</b> across the <b>queues,</b> in response to queue backlogs. Switching from one service config-uration to another incurs a setup time, during which idling occurs and service bandwidth is lost. Such setup times are inherent in manufacturing and computer systems. Frequent switchings can significantly compromise the service capacity of such systems. A Maximum Weight Matching (MWM) scheduler, which is known to maximize throughput {{in the absence of}} setups, can easily go unstable with setups, even under low load. To remedy this problem, we propose a new MWM-H scheduler which utilizes a controller introduced Hysteresis and achieves maximum throughput even with setups, without requiring knowledge of arrival rates and average traffic loads. During prolonged traffic bursts, the queues may become overloaded and the issue becomes how to reasonably distribute the growing backlog under MWM-H. It is shown that by appropriately selecting the MWM-H parameters, one can control the backlog amongst the individual queues in order to achieve a desired balance...|$|R
40|$|We propose and {{evaluate}} a passive measurement methodology that estimates {{the distribution of}} Round-Trip Times (RTTs) for the TCP connections that flow through a network link. Such an RTT distribution is important in buffer provisioning, <b>configuration</b> of active <b>queue</b> management, and detection of congestion unresponsive traffic. The proposed methodology is based on two techniques. The first technique is applicable to TCP caller-to-callee flows, and {{it is based on}} the 3 -way handshake messages. The second technique is applicable to callee-to-caller flows, when the callee transfers a number of MSS segments to the caller, and {{it is based on the}} slow-start phase of TCP. The complete estimation algorithm reports an RTT for 55 - 85 % of the TCP workload, in terms of bytes, in the traces that we examined. Verification experiments show that about 90 % of the passive measurements are within 10 % or 5 ms, whichever is larger, of the RTT that ping would measure. Also, measurements on several NLANR traces show that the two estimation techniques agree within 25 ms for 70 - 80 % of the processed TCP connections. We also apply the estimation methodology on a number of NLANR traces and examine the variability of the measured RTT distributions in both short and long timescales...|$|R
40|$|Daemon {{error log}} files Daemon error log files {{are stored in}} the {{directory}} defined by LSF_LOGDIR in lsf. conf. LSF base system daemon log files LSF batch system daemon log files pim. log. host_name mbatchd. log. host_name res. log. host_name sbatchd. log. host_name lim. log. host_name mbschd. log. host_name If EGO_LOGDIR is defined in ego. conf, file lim. log. host_name is stored in the directory defined by EGO_LOGDIR. Configuration files lsf. conf, lsf. shared, and lsf. cluster. cluster_name are located in LSF_CONFDIR. lsb. params, lsb. queues, lsb. modules, and lsb. resources are located in LSB_CONFDIR/ cluster_name/configdir/. File Description install. config Options for Platform LSF installation and configuration lsf. conf Generic environment configuration file describing the configuration and operation of the cluster lsf. shared Definition file shared by all clusters. Used to define cluster name, host types, host models and site-defined resources lsf. cluster. cluster_name Cluster configuration files used to define hosts, administrators, and locality of site-defined shared resources lsf. licensescheduler Configures Platform LSF License Scheduler lsb. applications Defines application profiles to define common parameters for {{the same types of}} jobs lsb. params Configures LSF batch parameters lsb. <b>queues</b> Batch <b>queue</b> <b>configuration</b> file lsb. resources Configures resource allocation limits, exports, and resource usage limits lsb. serviceclasses Defines service-level agreements (SLAs) in an LSF cluster as service classes, which define the properties of the SLA lsb. users Configures user groups, hierarchical fairshare for users and user groups, and job slot limits for users and user group...|$|R
40|$|This paper {{surveys the}} {{contributions}} and applications of queueing {{theory in the}} field of banking data networks. We start by highlighting the history of IT and banks and we continue by providing information regarding the main prudential regulations on the banking area as Basel Accords and green IT regulations, that on one side generate more computing needs {{and on the other side}} promote conscientious use of the existing IT systems. Continuing with a background of the network technologies used in Economics, the focus will be on the queueing theory, describing and giving an overview of the most important queueing models used in economical informatics. While the queueing theory is characterized by its practical, intuitive and subtle attributes, the queueing models are described by a set of 3 factors: an input process, a service process and a physical <b>configuration</b> of the <b>queue</b> or the queueing discipline. The Erlang B and C mathematical definitions of formulas for a specific number of s servers, at the λ arrival rate, and the τ average service time will be described, used and confirmed by computer simulations of real queues usually found in the banking computing systems. The goal is to provide sufficient information to computer performance analysts who are interested in usingthe queueing theory to model a network of banking computer systems using the right simulation model applied in real-life scenarios, e. g. overcoming the negative impacts of the European banking regulationswhile moving towards green computing...|$|R
40|$|Microprocessors are {{traditionally}} {{designed to provide}} "best overall" performance across {{a wide range of}} applications and operating environments. Several groups have proposed hardware techniques that save energy by "downsizing " hardware resources that are underutilized by the current application phase. Others have proposed a different energy-saving approach: dividing the processor into domains and dynamically changing the clock frequency and voltage within each domain during phases when the full domain frequency is not required. What has not been studied to date is how to exploit the adaptive nature of these approaches to improve performance rather than to save energy. In this paper, we describe an adaptive globally asynchronous, locally synchronous (GALS) microprocessor with a fixed global voltage and four independently clocked domains. Each domain is streamlined with modest hardware structures for very high clock frequency. Key structures can then be upsized on demand to exploit more distant parallelism, improve branch prediction, or increase cache capacity. Although doing so requires decreasing the associated domain frequency, other domain frequencies are unaffected. Our approach, therefore, is to maximize the throughput of each domain by finding the proper balance between the number of clock periods, and the clock frequency, for each application phase. To achieve this objective, we use novel hardware-based control techniques that accurately and efficiently capture the performance of all possible cache and <b>queue</b> <b>configurations</b> within a single interval, without having to resort to exhaustive online exploration or expensive offline profiling...|$|R
40|$|Abstract—Active queue {{management}} (AQM) is {{an effective}} means to enhance congestion control, and to achieve trade-off between link utilization and delay. The de facto standard, Random Early Detection (RED), {{and many of its}} variants employ queue length as a congestion indicator to trigger packet dropping. Despite their simplicity, these approaches often suffer from unstable behaviors in a dynamic network. Adaptive parameter settings, though might solve the problem, remain difficult in such a complex system. Recent proposals based on analytical TCP control and AQM models suggest the use of both queue length and traffic input rate as congestion indicators, which effectively enhances stability. Their response time generally increases however, leading to frequent buffer overflow and emptiness. In this paper, we propose a novel AQM algorithm that achieves fast response time and yet good robustness. The algorithm, called Loss Ratio-based RED (LRED), measures the latest packet loss ratio, and uses it as a complement to queue length for adaptively adjusting the packet drop probability. We develop an analytical model for LRED, which demonstrates that LRED is responsive even if the number of TCP flows and their persisting times vary significantly. It also provides a general guideline for the parameter settings in LRED. The performance of LRED is further examined under various simulated network environments, and compared to existing AQM algorithms. Our simulation results show that, with comparable complexities, LRED achieves shorter response time and higher robustness. More importantly, it trades off the goodput with queue length better than existing algorithms, enabling flexible system <b>configurations.</b> Index Terms—Active <b>queue</b> management, congestion control, TCP, packet loss ratio. Ç...|$|R
40|$|This paper {{presents}} {{a method for}} admitting voice calls in Telephony over IP (ToIP) scenarios. This method, called QoS-Weighted CAC, aims to guarantee Quality of Service to telephony applications. We use a measurement-based call admission control algorithm, which detects network congested links through a feedback on overall link utilization. This feedback {{is based on the}} measures of packet delivery latencies related to voice over IP connections {{at the edges of the}} transport network. In this way we introduce a close loop control method, which is able to auto-adapt the quality margin on the basis of network load and specific service level requirements. Moreover we evaluate the difference in performance achieved by different <b>Queue</b> management <b>configurations</b> to guarantee Quality of Service to telephony applications, in which our goal was to evaluate the weight of edge router <b>queue</b> <b>configuration</b> in complex and real-like telephony over IP scenario. We want to compare many well-know queue scheduling algorithms, such as SFQ, WRR, RR, WIRR, and Priority. This comparison aims to locate queue schedulers in a more general control scheme context where different elements such as DiffServ marking and Admission control algorithms contribute to the overall Quality of Service required by real-time voice conversations. By means of software simulations we want to compare this solution with other call admission methods already described in scientific literature in order to locate this proposed method in a more general control scheme context. On the basis of the results we try to evidence the possible advantages of this QoS-Weighted solution in comparison with other similar CAC solutions (in particular Measured Sum, Bandwidth Equivalent with Hoeffding Bounds, and Simple Measure CAC), on the planes of complexity, stability, management, tune-ability to service level requirements, and compatibility with actual network implementation...|$|R
40|$|Bisimulation {{theory is}} a co-inductive tool {{used as a}} {{tractable}} method for studying equivalence relations in process calculi. This dissertation studies bisimulation theory for session types. We define the Asynchronous Session π-calculus (ASP for short), which is a session type calculus with <b>queue</b> <b>configurations</b> acting as a communication medium at each session endpoint The semantics for ASP offer fine-grained communication that enjoys the non-blocking property of asynchrony and the order-preserving property of session types. The ASP typing system is shown to be sound to guarantee type safety {{in the presence of}} subtyping. A typed labelled transition system gives rise to a bisimilarity which is sound and complete with respect to typed reduction-closed congruence. The bisimilarity theory of ASP highlights the determinacy and confluence properties of session types. Event-driven programming {{is one of the major}} paradigms that utilise the asynchronous nature of distributed systems, where events are recognised as the presence of messages and their typed information in the communication medium. To justify the design choices made, we develop a superset of ASP, called the Eventful Session π-calculus (ESP for short), equipped with the minimal session primitives for an expressive event-driven computational model. The eventful session type system introduces the session set type, which is a collection of session types used to type a set of possible events. The ESP typing system maintains its consistency with respect to the ASP session typing system up-to a subtyping relation for session set types. The straightforward extension from ASP to ESP offers behavioural transparency, making the bisimilarity theory for the ASP a special case for the ESP theory – the bisimilarity relation coincides with typed reduction-closed congruence and determinacy and confluence properties are shown to hold for session transitions. Many studies regarding event-driven computation have identified the selector or its equivalent, the polling operator, as the key construct for describing an event-driven framework. The selector is defined as a higher level construct in ESP and it is used to implement the core event handling routine called the event loop. Following the empirical study by Lauer and Needham, we define a session-based transformation from a multi-threaded server to an event loop server. Confluence theory proves that the transformation is type- and semantics-preserving. In the last part of the dissertation we extend the behavioural theory to multiparty session types, both in the synchronous and the asynchronous cases. For each case, we examine two different typed labelled transition systems. In the first case we examine a standard labelled transition system with respect to the local session typing of processes. In the second case a choreography specification governs the behaviour of a multiparty session process and its observer. Each labelled transition system defines a bisimilarity relation, which coincides with the corresponding reduction-closed congruence. Open Acces...|$|R
40|$|Most used {{security}} {{mechanisms in}} high-speed networks {{have been adopted}} without adequate quantification of their impact on performance degradation. Appropriate quantitative network models may be employed for the evaluation and prediction of ¿optimal¿ performance vs. security trade-offs. Several quantitative models introduced in the literature are based on queueing networks (QNs) and generalised stochastic Petri nets (GSPNs). However, these models do not take into consideration Performance Engineering Principles (PEPs) and the adverse impact of traffic burstiness and security protocols on performance. The contributions of this thesis {{are based on the}} development of an effective quantitative methodology for the analysis of arbitrary QN models and GSPNs through discrete-event simulation (DES) and extended applications into performance vs. security trade-offs involving infrastructure and infrastructure-less high-speed networks under bursty traffic conditions. Specifically, investigations are carried out focusing, for illustration purposes, on high-speed network routers subject to Access Control List (ACL) and also Robotic Ad Hoc Networks (RANETs) with Wired Equivalent Privacy (WEP) and Selective Security (SS) protocols, respectively. The Generalised Exponential (GE) distribution is used to model inter-arrival and service times at each node in order to capture the traffic burstiness of the network and predict pessimistic ¿upper bounds¿ of network performance. In the context of a router with ACL mechanism representing an infrastructure network node, performance degradation is caused due to high-speed incoming traffic in conjunction with ACL security computations making the router a bottleneck in the network. To quantify and predict the trade-off of this degradation, the proposed quantitative methodology employs a suitable QN model consisting of two queues connected in a tandem <b>configuration.</b> These <b>queues</b> have single or quad-core CPUs with multiple-classes and correspond to a security processing node and a transmission forwarding node. First-Come-First-Served (FCFS) and Head-of-the-Line (HoL) are the adopted service disciplines together with Complete Buffer Sharing (CBS) and Partial Buffer Sharing (PBS) buffer management schemes. The mean response time and packet loss probability at each queue are employed as typical performance metrics. Numerical experiments are carried out, based on DES, in order to establish a balanced trade-off between security and performance towards the design and development of efficient router architectures under bursty traffic conditions. The proposed methodology is also applied into the evaluation of performance vs. security trade-offs of robotic ad hoc networks (RANETs) with mobility subject to Wired Equivalent Privacy (WEP) and Selective Security (SS) protocols. WEP protocol is engaged to provide confidentiality and integrity to exchanged data amongst robotic nodes of a RANET and thus, to prevent data capturing by unauthorised users. WEP security mechanisms in RANETs, as infrastructure-less networks, are performed at each individual robotic node subject to traffic burstiness as well as nodal mobility. In this context, the proposed quantitative methodology is extended to incorporate an open QN model of a RANET with Gated queues (G-Queues), arbitrary topology and multiple classes of data packets with FCFS and HoL disciplines under bursty arrival traffic flows characterised by an Interrupted Compound Poisson Process (ICPP). SS is included in the Gated-QN (G-QN) model in order to establish an ¿optimal¿ performance vs. security trade-off. For this purpose, PEPs, such as the provision of multiple classes with HoL priorities and the availability of dual CPUs, are complemented by the inclusion of robot¿s mobility, enabling realistic decisions in mitigating the performance of mobile robotic nodes in the presence of security. The mean marginal end-to-end delay was adopted as the performance metric that gives indication on the security improvement. The proposed quantitative methodology is further enhanced by formulating an advanced hybrid framework for capturing ¿optimal¿ performance vs. security trade-offs for each node of a RANET by taking more explicitly into consideration security control and battery life. Specifically, each robotic node is represented by a hybrid Gated GSPN (G-GSPN) and a QN model. In this context, the G-GSPN incorporates bursty multiple class traffic flows, nodal mobility, security processing and control whilst the QN model has, generally, an arbitrary configuration with finite capacity channel queues reflecting ¿intra¿-robot (component-to-component) communication and ¿inter¿-robot transmissions. Two theoretical case studies from the literature are adapted to illustrate the utility of the QN towards modelling ¿intra¿ and ¿inter¿ robot communications. Extensions of the combined performance and security metrics (CPSMs) proposed in the literature are suggested to facilitate investigating and optimising RANET¿s performance vs. security trade-offs. This framework has a promising potential modelling more meaningfully and explicitly the behaviour of security processing and control mechanisms as well as capturing the robot¿s heterogeneity (in terms of the robot architecture and application/task context) in the near future (c. f. [1]. Moreover, this framework should enable testing robot¿s configurations during design and development stages of RANETs as well as modifying and tuning existing configurations of RANETs towards enhanced ¿optimal¿ performance and security trade-offs. Ministry of Higher Education in Libya and the Libyan Cultural Attaché bureau in Londo...|$|R

