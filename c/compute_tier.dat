0|16|Public
40|$|Approved {{for public}} release; {{distribution}} is unlimited. This study analyzes the Marine Corps reenlistment {{process and the}} relationship between a Marine's expiration of active service (EAS), reenlistment request submission month, and submission timeline on the quality of first-term Marines. In 2011, a <b>computed</b> <b>tier</b> was added to reenlistment requests and added an objective component to an otherwise subjective request. This study also looks at the influence of stakeholders in identifying and retaining quality under both reenlistment measures. Graphical trend analysis, cross tabulation, and linear regression models were used to analyze Total Force Retention System and Total Force Data Warehouse data with quality identified using a <b>computed</b> submitted <b>tier,</b> commander's recommended tier, and modified tier score. The findings indicate that reenlistment requests submitted within 30 days of a Marine's EAS have had negative effects on quality and outside of this window there is no observable effect on quality. Additionally, {{over the course of the}} reenlistment period, lower quality is associated with months following the start of the reenlistment period in July. The graphical analysis also suggests that the <b>computed</b> <b>tier</b> provides an objective anchor for commanders' recommendations. Captain, United States Marine Corp...|$|R
50|$|A Java EE {{application}} or a Java Platform, Enterprise Edition {{application is}} any deployable unit of Java EE functionality. This {{can be a}} single Java EE module {{or a group of}} modules packaged into an EAR file along with a Java EE application deployment descriptor. Java EE applications are typically engineered to be distributed across multiple <b>computing</b> <b>tiers.</b>|$|R
40|$|This paper {{describes}} the Integrated Supportability Analysis and Cost System (ISACS+) and the features {{which will be}} demonstrated. ISACS+ is a distributed, client/server system for evaluating operation and support characteristics of weapon systems and, in future builds, commercial aircraft systems. This tutorial briefly {{describes the}} ISACS+ Concept of Operations and how Operation and Support studies are conducted using the ISACS+ tool. This tutorial also describes the architecture used to distribute the ISACS+ software over multiple <b>computing</b> <b>tiers</b> {{in support of the}} concept of operations...|$|R
40|$|The Large Hadron Collider (LHC), whose {{experiments}} {{include the}} Compact Muon Solenoid (CMS), produces over 30 million gigabytes of data annually, and implements a distributed <b>computing</b> architecture—a <b>tiered</b> hierarchy, from Tier- 0 through Tier- 3 —in order to process and store {{all of this}} data. Out {{of all of the}} <b>computing</b> <b>tiers,</b> Tier- 3 clusters allow scientists the most freedom and flexibility to perform their analyses of LHC data. Tier- 3 clusters also provide local services such as login and storage services, provide a means to locally host and analyze LHC data, and allow both remote and local users to submit grid-based jobs. Using the Rocks cluster distribution software version 6. 1. 1, along with the Open Science Grid (OSG) roll version 3. 2. 35, a grid-enabled CMS Tier- 3 computing cluster was deployed at Florida International University’s Modesto A. Maidique campus. Validation metric results from Ganglia, MyOSG, and CMS Dashboard verified a successful deployment...|$|R
40|$|Enterprise {{computing}} facilities, such as {{data centers}} or server farms typically employ service-oriented architectures (SOA) to support multiple, XML-based Web Services. They are typically architected in multiple <b>computing</b> <b>tiers,</b> {{in which one}} tier is used for, say, offloading the CPU-intensive XML processing onto a cluster of (potentially virtual) middle-ware appliances. Service differentiation in enterprise networks addresses the issues of managing the enterprise network resources {{in order to achieve}} desired performance objectives. In this paper, we define a dynamic algorithm that manages allocation of CPU time in the appliance tier. We evaluate the service differentiation capabilities of this algorithm via simulations...|$|R
40|$|The CMS Computing Model was {{developed}} and documented in 2004. Since then the model has evolved to be more flexible and {{to take advantage of}} new techniques, but many of the original concepts remain and are in active use. In this presentation we will discuss the changes planned for the restart of the LHC program in 2015. We will discuss the changes planning in the use and definition of the <b>computing</b> <b>tiers,</b> that were defined with the MONARC project. We will present how we intend to use new services and infrastructure to provide more efficient and transparent access to the data. We will discuss the computing plans to make better use of the computing capacity by scheduling more of the processor nodes, making better use of the disk storage, and more intelligent use of the networking...|$|R
40|$|In {{the summer}} of 2005, CMS like the other LHC {{experiments}} published a Computing Technical Design Report (C-TDR) for the LHCC, which describes the CMS computing models as a distributed system of Tier- 0, Tier- 1, and Tier- 2 regional computing centers, and the CERN analysis facility, the CMS-CAF. The C-TDR contains information on resource needs for the different <b>computing</b> <b>tiers</b> that are derived from a set of input assumptions and desiderata on how to achieve high-throughput and a robust computing environment. At the CERN Computing Resources Review Board meeting in October 2005, the funding agencies agreed on a Memorandum of Understanding (MoU) describing the worldwide collaboration on LHC computing (WLCG). In preparation for this meeting the LCG project had put together information from countries regarding their pledges for computing resources at Tier- 1 and Tier- 2 centers. These pledges include the amount of CPU power, disk storage, tape storage library space, and network connectivity {{for each of the}} LHC experiment for the subsequent five years. In this White Paper we describe the current situation for CMS regarding pledged computing resources...|$|R
30|$|Another study [95] {{presented}} a theorem {{to explain the}} big data characteristics, called HACE: the characteristics of big data usually are large-volume, Heterogeneous, Autonomous sources with distributed and decentralized control, and we usually {{try to find out}} some useful and interesting things from complex and evolving relationships of data. Based on these concerns and data mining issues, Wu and his colleagues [95] also {{presented a}} big data processing framework which includes data accessing and <b>computing</b> <b>tier,</b> data privacy and domain knowledge tier, and big data mining algorithm tier. This work explains that the data mining algorithm will become much more important and much more difficult; thus, challenges will also occur on the design and implementation of big data analytics platform. In addition to the platform performance and data mining issues, the privacy issue for big data analytics was a promising research in recent years. In [96], Laurila et al. explained that the privacy is an essential problem when we try to find something from the data that are gathered from mobile devices; thus, data security and data anonymization should also be considered in analyzing this kind of data. Demirkan and Delen [97] presented a service-oriented decision support system (SODSS) for big data analytics which includes information source, data management, information management, and operations management.|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedThis thesis investigates how Marine recruit information available at entry {{can be used}} to predict which occupational field (OCCFLD) is best suited to an individual and if a Marine successfully completes the first term of enlistment. Multinomial regression models are developed to calculate estimated probabilities that a given recruit will attain United States Marine Corps (USMC) <b>Computed</b> Reenlistment <b>Tiers</b> I, II, III, or IV in a particular OCCFLD. Optimization of OCCFLD assignment based on the developed models illustrates the potential value of insight gained from recruit information available prior to enlistment. The relationship of recruit characteristics available prior to enlistment and the USMC Computed Tier Score assigned {{in the last year of}} a Marine's first enlistment is dependent upon the OCCFLD assigned. We recommend identifying OCCFLDs with the highest estimated probabilities of Tier I or Tier II attainment at the recruitment phase. Providing recruits and recruiters a tool that provides estimated probabilities of attaining Tier I or Tier II in descending order for each OCCFLD during initial assignment has the potential to increase the caliber of Marines across all OCCFLDs and to aid in assessing the current OCCFLD assignment practices. Outstanding ThesisCaptain, United States Marine Corp...|$|R
40|$|Abstract:- With the {{widespread}} use of N <b>tier</b> <b>computing</b> technologies in the enterprise and the increased dependence on the services provided by these applications, greater emphasis is now being placed on the performance and health of these applications. It’s now not enough that the application merely functions, but it needs to meet the QoS 1 metrics that is expected of it. It turns out that QoS is dependent, not just on how well the application has been designed and built but also on how is gets deployed and distributed. We present here ongoing work in the area of autonomic computing of distributed component based applications – an effort that seeks to make distributed enterprise applications and the environments in which they run self-configuring and self-healing. Key-Words:- J 2 EE, performance prediction, analytical models, queueing Petri-nets, QoS of We...|$|R
40|$|Large-scale {{computing}} in ATLAS {{is based}} on a grid-linked system of <b>tiered</b> <b>computing</b> centers. The ATLAS Great Lakes Tier- 2 came online in September 2006 and now is commissioning with full capacity to provide significant computing power and services to the USATLAS community. Our Tier- 2 Center also host the Michigan Muon Calibration Center which is responsible for daily calibrations of the ATLAS Monitored Drift Tubes for ATLAS endcap muon system. During the first LHC beam period in 2008 and following ATLAS global cosmic ray data taking period, the Calibration Center received a large data stream from the muon detector to derive the drift tube timing offsets and time-to-space functions with a turn-around time of 24 hours. We will present the Calibration Center commissioning status and our plan for the first LHC beam collisions in 2009. Comment: To be published in the proceedings of DPF- 2009, Detroit, MI, July 2009, eConf C 09072...|$|R
40|$|This thesis {{presents}} {{a study of}} the Grid data access patterns in distributed analysis in the CMS experiment at the LHC accelerator. This study ranges from the deep analysis of the historical patterns of access to the most relevant data types in CMS, to the exploitation of a supervised Machine Learning classification system to set-up a machinery able to eventually predict future data access patterns - i. e. the so-called dataset “popularity” of the CMS datasets on the Grid - with focus on specific data types. All the CMS workflows run on the Worldwide LHC Computing Grid (WCG) <b>computing</b> centers (<b>Tiers),</b> and in particular the distributed analysis systems sustains hundreds of users and applications submitted every day. These applications (or “jobs”) access different data types hosted on disk storage systems at a large set of WLCG Tiers. The detailed study of how this data is accessed, in terms of data types, hosting Tiers, and different time periods, allows to gain precious insight on storage occupancy over time and different access patterns, and ultimately to extract suggested actions based on this information (e. g. targetted disk clean-up and/or data replication). In this sense, the application of Machine Learning techniques allows to learn from past data and to gain predictability potential for the future CMS data access patterns. Chapter 1 provides an introduction to High Energy Physics at the LHC. Chapter 2 describes the CMS Computing Model, with special focus on the data management sector, also discussing the concept of dataset popularity. Chapter 3 describes the study of CMS data access patterns with different depth levels. Chapter 4 offers a brief introduction to basic machine learning concepts and gives an introduction to its application in CMS and discuss the results obtained by using this approach {{in the context of this}} thesis...|$|R
40|$|My {{research}} {{is motivated by}} the idea that mathematical models can provide insight into the design of computer systems. My goal is to strip away the complexities of real systems, isolate the important components, and then develop models that characterize the impact of design decisions on the system as a whole. In order to accomplish this goal, I apply analytic models and tools that are traditionally used in the operations research community, in particular stochastic modeling and queueing theory. However, performance evaluation of computer systems often necessitates the development of new, non-traditional, stochastic and queueing models. Thus, my research contributes both to the understanding of computer system design and to the modernization of queueing theory. At the heart of this style of {{research is}} a tension between modeling the complexities of real systems and the task of analyzing the resulting models. Thus, this type of research requires working hand-in-hand with both practitioners, {{in order to understand the}} details of the design decisions being considered, and theoreticians, in order to develop new mathematical tools. As a testament to this interaction, notice that my publications appear in both top <b>tier</b> <b>compute...</b>|$|R
40|$|In the ATLAS <b>computing</b> {{model the}} <b>tiered</b> {{hierarchy}} {{ranged from the}} Tier- 0 (CERN) down to desktops or workstations (Tier- 3). The focus on defining the roles of each tiered component has evolved with the initial emphasis on the Tier- 0 and Tier- 1 definition and roles. The various LHC (Large Hadron Collider) projects, including ATLAS, then evolved the tiered hierarchy to include Tier- 2 ’s (Regional centers) {{as part of their}} projects. Tier- 3 centres, on the other hand, have been defined as whatever an institution could construct to support their Physics goals using institutional and otherwise leveraged resources and therefore have not been considered {{to be part of the}} official ATLAS computing resources. However, Tier- 3 centres are going to exist and will have implications on how the computing model should support ATLAS physicists. Tier- 3 users will want to access LHC data and simulations and will want to enable their resources to support their analysis and simulation work. This document will define how IFIC (Instituto de F´ısica Corpuscular de Valencia), after discussing with the ATLAS Tier- 3 task force, should interact with the ATLAS computing model, detail the conditions under which Tier- 3 centres can expect some level of support and set reasonable expectations for the scope and support of ATLAS Tier- 3 sites...|$|R
40|$|With the {{decreasing}} {{cost and}} wide-spread use of commodity hard drives, {{it has become}} possible to create very large-scale storage systems with less expense. However, as we approach exabyte-scale storage systems, maintaining important features such as energy-efficiency, performance, reliability and usability became increasingly difficult. Despite the decreasing cost of storage systems, the energy consumption of these systems {{still needs to be}} addressed in order to retain cost-effectiveness. Any improvements in a storage system can be outweighed by high energy costs. On the other hand, large-scale storage systems can benefit more from the object storage features for improved performance and usability. One area of concern is metadata performance bottleneck of applications reading large directories or creating a large number of files. Similarly, computation on big data where data needs to be transferred between compute and storage clusters adversely affects I/O performance. As the storage systems become more complex and larger, transferring data between remote <b>compute</b> and storage <b>tiers</b> becomes impractical. Furthermore, storage systems implement reliability typically at the file system or client level. This approach might not always be practical in terms of performance. Lastly, object storage features are usually tailored to specific use cases that makes it harder to use them in various contexts. In this thesis, we are presenting several approaches to enhance energy-efficiency, performance, reliability and usability of large-scale storage systems. To begin with, we improve the energy-efficiency of storage systems by moving I/O load to a subset of the storage nodes with energy-aware node allocation methods and turn off the unused nodes, while preserving load balance on demand. To address the metadata performance issue associated with large creates and directory reads, we represent directories with object storage collections and implement lazy creation of objects. Similarly, in-situ computation on large-scale data is enabled by using object storage features to integrate a computational framework with the existing object storage layer to eliminate the need to transfer data between compute and storage silos for better performance. We then present parity-based redundancy using object storage features to achieve reliability with less performance impact. Finally, unified storage brings together the object storage features {{to meet the needs of}} distinct use cases; such as cloud storage, big data or high-performance computing to alleviate the unnecessary fragmentation of storage resources. We evaluate each proposed approach thoroughly and validate their effectiveness in terms of improving energy-efficiency, performance, reliability and usability of a large-scale storage system...|$|R
30|$|In [13], {{the authors}} use {{relaying}} and cooperation {{to prolong the}} network lifetime. They also investigate path loss while considering different body parts for both single-hop and multi-hop topologies. Similarly, the authors in [24] use topology control to account for access delays due to the underlying medium access control (MAC) layer, however, {{at the cost of}} high energy consumption. In [25], the authors set an upper bound to determine the number of relay nodes, sensors, and their respective distances to the sink. Each sensor node performs single-hop communication while relaying nodes perform multi-hop communication to the sink. In [14], J. Elias et al. provide an optimal design for WBASNs by studying the joint data routing and relay positioning problem in order to increase the network lifetime. In this research work, the authors present an inter-based linear programming model which aims for (i) optimized number of relay positions, (ii) minimization of energy consumption of sensors and relays, and (iii) minimization of the installation cost. Simulation results show that this framework has a very short computing time as compared to the other frameworks. In [26], the authors study propagation models subject to network lifetime prolongation. These models reveal that single-hop communication is inefficient for far away nodes from the sink and the multi-hop communication is more suitable. In order to avoid hot spot links, extra nodes in the network, i.e., dedicated relay devices, are introduced. The authors in [19] propose M-ATTEMPT routing protocol in which they use single-hop communication for the delivery critical data and multi-hop communication for the delivery of normal data. In order to prevent damage of body tissues, they also introduce a temperature sensing mechanism to detect the hot spot problem of in-body sensors. In [27], Chen et al. introduce a new interference-aware WBASN that can continuously monitor vital signs of multiple patients and efficiently prioritize data transmission based on patients’ conditions. The authors proposed a solution that is based on an integrated hybrid scheduler which guarantees end-to-end delay with the capability to select the best possible route (best link quality) and minimum generated interference which results in high end-to-end packet reliability. In [28], sensing is considered as a service while improving energy efficiency. Thus, the authors present a unique set of design challenges and propose different solutions which are very helpful for current as well as future researchers. In [29], the authors present anycast routing protocol for monitoring patients vital signs while coping with the end-to-end traffic. To achieve minimum network latency, the protocol chooses a nearest data receiver related to the patient. The wireless network performs fall detection, indoor positioning, and electrocardiogram (ECG) monitoring for the patients. Whenever, a fall is detected, the hospital crew gets intimated of the exact position of the patient. In [30], the authors present a cluster-based self-organization protocol. It focuses on relaying data via cluster heads to improve energy efficiency. Initially, the protocol builds a cluster-based structure and then efficiently transmits packets from source to destination. An interesting feature of this technique is the stability in terms of the selected number of cluster heads per round. In [31], the authors balance load of the sensor nodes by presenting a global routing protocol which is tested against real-time experiments along with computer-based simulations. Similarly, [32] introduces a personal wireless hub to collect personal health information of its user(s) through biomedical sensors. The sensed information is securely routed towards the health care unit if found eligible. In [33], Otto et al. present a prototype system for the health monitoring of people/patients at home. The system consists of an uninterrupted WBASN and a home health server. The WBASN sensors sense heart rate and locomotive activity such that the sensed information is periodically uploaded at the home server. The home server may integrate this information with a local database for user inspection, or it may further be forwarded to a medical server. Similarly, the idea of embedding medical devices with hospital information system is presented in [34]. The integration of ubiquitous echograph with the home information network make it very easy for the doctors to immediately diagnose the patients. In [35], Wang et al. present a distributed WBASN model for medical supervision. The system consists of three tiers: sensor network <b>tier,</b> mobile <b>computing</b> network <b>tier,</b> and remote monitoring network tier. This model provides collection, demonstration, and storage of vital information like ECG, blood oxygen, body temperature, and respiration rate. The system demonstrates many advantages such as low-power, easy configuration, convenient carrying, and real-time reliable data. In [36], the authors use wearable sensors to monitor daily activities of humans which they perform during different activities. The correct monitoring of these complex actions is challenging. For this purpose, they introduce activity recognition with the help of wearable sensing devices.|$|R

