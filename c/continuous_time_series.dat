230|10000|Public
50|$|Strata from {{successive}} {{periods of}} time may be viewed across the landscape due to the titled orientation of the sedimentary rock layers. The presence of fossils from a <b>continuous</b> <b>time</b> <b>series</b> allow for the observation of faunal succession. On Isle La Motte, the oldest fossils occur {{at the southern end}} of the island, with progressively newer layers visible toward the island's north end.|$|E
50|$|The FDSN goals {{related to}} station siting and {{instrumentation}} are to provide stations with good geographic distribution, recording data with 24 bits of resolution in <b>continuous</b> <b>time</b> <b>series</b> {{with at least}} a 20 sample per second sampling rate. The FDSN was also instrumental in development of a universal standard for distribution of broadband waveform data and related parametric information (QuakeML). The Standard for Exchange of Earthquake Data (SEED) format is the result of that effort.|$|E
50|$|MUSIC (Multi-Simulation Coordinator) is {{software}} {{developed and}} {{released by the}} INCF and Royal Institute of Technology (KTH) School of Computer Science and Communication in Stockholm, Sweden. MUSIC is designed for interconnectinglarge scale neuronal network simulators, either with each other or with othertools. It allows spike events and <b>continuous</b> <b>time</b> <b>series</b> to be communicated between such applications in a cluster computer. The typical usage cases are connecting models developed for different simulators and connecting a parallel simulator to a post-processing tool.|$|E
40|$|In {{symbolic}} dynamics, {{the definition}} of a symbolic sequence from a <b>continuous</b> <b>times</b> <b>series</b> depends on the use of an appropriate par-tition of the phase space. In fact, the best way is to estimate a gen-erating partition. However, {{it is not possible to}} find generating partitions for most ex-perimental observations because such partitions do not exist when noise is present. In this paper, different partition methods applied to stochastic and chaotic system will be compared in order to choose one which con-serves system entropy rate. This partition is called a Markov parti-tion. General Terms: Markov partition, symbolic dynami...|$|R
40|$|This {{document}} {{describes the}} squad 2. 0 package, {{a collection of}} anomaly detection tools for univariate <b>continuous</b> sequences (<b>time</b> <b>series</b> data) and univariate discrete sequences. The package depends on the tools library package, which {{is a collection of}} routines to read/write such sequences, as well as routines for distance/similarity computations...|$|R
40|$|Atmospheric Sciences, Georgia Institute of Technology, Atlanta,the {{first attempt}} to geodetically {{constrain}} the volcanic deformation source volume at Long Valley, a parameter for hazard assessment. Including fault slip along the SMF explains significant deformation observed with several EDM baselines and components of two <b>continuous</b> GPS <b>time</b> <b>series.</b> Additionally, the model explains the spatial extent of deformation observed b...|$|R
50|$|Ocean {{observatories}} {{can collect}} data for different purposes from scientific research to environmental monitoring for marine operations or governance {{for the benefit}} of economy and society as a whole.Ocean observatories provide real-time, or near real time data allowing to detect changes as they happen, such as geo-hazards for example. Furthermore <b>continuous</b> <b>time</b> <b>series</b> data allow to investigate interannual-to-decadal changes and to capture episodic events, changes in ocean circulation, water properties, water mass formation and ecosystems, to quantify air-sea fluxes, and to analyse the role of the oceans for the climate.|$|E
5000|$|The Rapid Climate Change-Meridional Overturning Circulation and Heatflux Array (RAPID/MOCHA) {{program is}} a {{collaborative}} research project between the National Oceanography Centre (Southampton, U.K.), the University of Miami’s Rosenstiel School of Marine and Atmospheric Science (RSMAS), and NOAA’s Atlantic Oceanographic and Meteorological Laboratory (AOML) that measure the meridional overturning circulation (MOC) and ocean heat transport in the North Atlantic Ocean. [...] This array was deployed in March 2004 to continuously monitor the MOC and ocean heat transport that are primarily associated with the Thermohaline Circulation across the basin at 26°N. The RAPID-MOCHA array is planned to be continued through 2014 to provide a decade or longer <b>continuous</b> <b>time</b> <b>series.</b>|$|E
30|$|In {{this study}} only <b>continuous</b> <b>time</b> <b>series</b> {{rainfall}} data belonging to 12 meteorological stations (one representative station per district) of GWB (Fig.  1) {{for the period}} of 1901 – 2002 have been used.|$|E
40|$|Several hundred {{hours of}} wind {{velocity}} measurements {{made with the}} Arecibo 430 -MHz radar {{during the past few}} years have indicated the presence of persistent wave like structures just above the tropopause. To further investigate these structures, a nearly <b>continuous</b> <b>times</b> <b>series</b> of wind measurements in the upper troposphere and lower stratosphere was made from May 5 to May 12, 1982 at Arecibo. Each of 16 compass points was sampled as the 430 -MHz feed was rotated in a velocity azimuth display (VAD) mode at a zenith angle of 15 degrees off-vertical. Using a nonlinear least squares parameter estimation technique line of sight velocities were calculated from Doppler shifts of the received spectra. These velocities were reduced to zonal and meridional components of the wind vector; the vertical component of the wind vector will be available after further reduction...|$|R
40|$|Heisenberg's {{principle}} of indeterminacy {{is applied to}} stationary <b>time</b> <b>series</b> models. The position and velocity of a forecast are defined and are shown to be imperfectly correlated. Then a first-order autoregression is used to illustrate the trade-off between precision of position and precision of velocity. A counterpart of Planck's constant is identified, and the Heisenberg bound is derived for several autoregressive moving- average models. The time-energy version of the Heisenberg principle is discussed {{in the context of}} a stationary model in <b>continuous</b> <b>time.</b> Stationary <b>time</b> <b>series</b> Heisenberg uncertainty principle...|$|R
40|$|The reological {{properties}} of the crust and the upper mantle beneath Iceland make the earth surface sensitive to recent ice mass changing. On a short time scale, strong correlation exists between seasonal variations in <b>continuous</b> GPS <b>time</b> <b>series</b> and snow covering. The overall retreat of Icelandic glaciers is causing uplift of over 2 cm/yr around Vatnajökull, the largest Icelandic ice cap. Recent modelling also suggests that the same phenomena is causing increased mantle melting and magma generation under Vatnajökul...|$|R
40|$|We study {{non-parametric}} {{measures for}} the problem of comparing distributions, which arise in anomaly detection for <b>continuous</b> <b>time</b> <b>series.</b> Non-parametric measures take two distributions as input and produce two numbers as output: {{the difference between the}} input distributions and the statistical significance of this difference. Some of these measures, such as Kullback-Leibler measure, are defined for comparing probability distribution functions (PDFs) and some others, such as Kolmogorov-Smirnov measure, are for cumulative distribution functions (CDFs). We first show how to adapt the PDF based measures to compare CDFs, resulting in a total of 23 CDF based measures. We then provide a unified functional form that subsumes all these measures. We present our methodology to determine the significance (of the measures) by simulations only. Finally, we evaluate these measures for the anomaly detection in <b>continuous</b> <b>time</b> <b>series.</b> ...|$|E
40|$|Graduation date: 2015 Wind-driven coastal {{upwelling}} brings {{subsurface water}} onto the central-Oregon shelf after the spring transition each year. This cold and salty source water is oxygen-poor, yet above the hypoxic threshold, dissolved oxygen < 1. 4 ml l⁻¹. Once on the shelf, dissolved oxygen (DO) concentrations of upwelled near-bottom waters are modified by physical and biological shelf processes, such as advection, mixing and microbial respiration. The influences of shelf processes on near-bottom DO concentrations on tidal, event and seasonal time scales are investigated using moored <b>continuous</b> <b>time</b> <b>series</b> and underwater glider cross-shelf transects over the Heceta and Stonewall Bank complex (HSBC) off central Oregon. A linear, seasonal decline rate of 0. 01 ml l⁻¹ day⁻¹ is observed from moored near-bottom <b>continuous</b> <b>time</b> <b>series</b> on the mid shelf over HSBC. This seasonal decline rate is only 30...|$|E
40|$|A joint {{analysis}} of <b>continuous</b> (<b>time</b> <b>series</b> demand observations) and discrete (well-describing parameters) data is studied. Such data mining techniques as data collection, preprocessing, clustering analysis, and classification are considered. Upon continuous data preprocessing and clustering, images of possible sales development are constructed. A new product’s demand is searched for using inductive decision trees built on well-describing data...|$|E
30|$|Monitoring and {{forecasting}} capability {{might be}} improved by deploying additional geophysical- and geochemical-monitoring capabilities in the near vicinity of the summit crater. Magnetometers will be deployed to monitor the magnetic total field, which may help to map ongoing hydrothermal alteration and temperature changes at relatively shallow depths. Gas monitoring will also help to understand the ongoing hydrothermal processes. Generating <b>continuous</b> long-term <b>time</b> <b>series</b> will require sustained effort in a remote near-summit environment that is characterized by extreme weather and discharge of high-temperature, low-pH hydrothermal fluids.|$|R
40|$|Rule {{discovery}} from <b>time</b> <b>series</b> data is a {{data mining}} technique {{that tries to}} find relationships of sequential data. Finding association rules from <b>time</b> <b>series</b> data is different from finding such rules in traditional data because <b>time</b> <b>series</b> data is orderly data with a sequence that must be preserved. Many researchers have proposed many methods of analyzing and mining <b>time</b> <b>series</b> data, {{but most of them}} did not focus on finding association rules, and the data used in their experimentations were discretized symbols. In fact, many situations collect data in <b>continuous</b> numeration <b>time</b> <b>series.</b> In this paper, we propose a novel technique to find association rules from <b>time</b> <b>series</b> data. Our technique can analyze either the numerical <b>time</b> <b>series</b> or the symbolic <b>time</b> t <b>series</b> and show the resulting rules as X ⎯⎯→Y, which means that the group of pattern Y shoul...|$|R
40|$|A {{method for}} {{evaluating}} attitude and measuring angular rate of uncontrolled bodies in space, such as space debris, has been developed. The measurement {{can be obtained}} by elaborating data coming from tracking few natural features of the objects. Tracking can be pursued for instance through a chaser spacecraft equipped with 3 D-cameras. <b>Continuous</b> quaternion <b>time</b> <b>series</b> are obtained via compressed sensing (CS) techniques while a linear Kalman filter (KF) is used to estimate the angular rate. The developed method is robust to typical occlusions of cameras in space environment. © 2016 IEE...|$|R
40|$|AbstractThis paper {{discusses}} {{a method}} of modeling temporal pattern and event detection based on Hidden Markov Model (HMM) for a <b>continuous</b> <b>time</b> <b>series</b> data. We also provide methods for checking model adequacy and predicting future events. These methods are applied to a real example of sludge bulking data for detecting sludge bulking for a water plant in Chicago...|$|E
40|$|This {{paper is}} {{a note on}} the use of Bayesian nonparametric mixture models for <b>continuous</b> <b>time</b> <b>series.</b> We {{identify}} a key requirement for such models, and then establish that there is a single type of model which meets this requirement. As it turns out, the model is well known in multiple change-point problems. Comment: 1 figur...|$|E
40|$|A {{comprehensive}} process-based {{numerical model}} of catchment hydrology and alluvial channel dynamics {{is applied to}} the evolution of the river Maas during the Last Glacial-Interglacial Transition. Palaeo-climatological reconstructions based on a number of climatic and environmental proxies are combined with atmospheric circulation model predictions to yield <b>continuous</b> <b>time</b> <b>series</b> for temperature, precipitation and vegetation cover for the period of 14 -...|$|E
40|$|Probabilistic flood hazard {{assessment}} are usually carried out through juxtaposed reach-wise hydraulic simulations, using as input “representative” hydrographs for the studied return periods - {{at least by}} their peak discharge. However, reach-wise approaches have drawbacks, especially {{in the presence of}} natural or man-made singularities. An approach based on continuous simulation is developed to better assess flood hazard at the scale of the catchment and of the flood regime. A stochastic rainfall fields generator yields <b>continuous</b> <b>times</b> <b>series,</b> thus keeping the variability of the rainfall fields. Catchment-wise rainfall-runoff modelling, completed when necessary by a hydraulic model, allows to reproduce the individual and combined response of each feature to a heterogeneous rainfall event. The current CPU performances allow to process long rainfall time-series, but the codes have to be adapted to deal with unusually long input and output files. Local flood quantiles are then derived from discharge time-series, and flooding probability can be derived from local inundation frequency. This approach can be used in all contexts, urban floods or catchment-scale management; the modules have just to be chosen accordingly. This approach offers many perspectives, and in particular to better estimate local expected annual damages using damages time-series and multivariate damage curves...|$|R
40|$|Abstract – <b>Continuous</b> global <b>time</b> <b>series</b> of {{vegetation}} indices, {{which are available}} since early 1980 s, are of great value to detect changes in vegetation status at large spatial scales. Most change detection methods, however, assume a fixed change trajectory – defined by the start {{and end of the}} <b>time</b> <b>series</b> – and a linear or monotonic trend. Here, we apply a change detection method which detects abrupt changes within the <b>time</b> <b>series.</b> This Breaks For Additive Season and Trend (BFAST) approach showed that large parts of the world are subjected to trend changes. The timing of the breakpoints could in some cases be related to satellite changes, but also to large-scale natural influences like the Mt. Pinatubo eruption. Shifts from greening to browning (or vice versa) occurred in 15 % of the global land surface, which demonstrates the importance of accounting for trend breaks when analyzing long-term NDVI <b>time</b> <b>series...</b>|$|R
40|$|Generative Adversarial Networks (GANs) {{represent}} a promising class of generative networks that combine neural networks with game theory. From generating realistic images and videos to assisting musical creation, GANs are transforming many fields {{of arts and}} sciences. However, their application to healthcare has not been fully realized, more specifically in generating electronic health records (EHR) data. In this paper, we propose a framework for exploring the value of GANs {{in the context of}} <b>continuous</b> laboratory <b>time</b> <b>series</b> data. We devise an unsupervised evaluation method that measures the predictive power of synthetic laboratory test <b>time</b> <b>series.</b> Further, we show {{that when it comes to}} predicting the impact of drug exposure on laboratory test data, incorporating representation learning of the training cohorts prior to training GAN models is beneficial. Comment: NIPS ML 4 H 201...|$|R
40|$|The paper {{deals with}} variational {{approaches}} to the segmentation of time series into smooth pieces, but allowing for sharp breaks. In discrete time, the corresponding functionals are of Blake-Zisserman type. Their natural counterpart in continuous time are the Mumford-Shah functionals. Time series which minimise these functionals are proper estimates or representations of the signals behind recorded data. We focus on consistent behaviour of the functionals and the estimates, as parameters vary or as the sampling rate increases. For each time <b>continuous</b> <b>time</b> <b>series</b> f ([0, 1]) we take conditional expectations w. r. t. to σ-algebras generated by finer and finer partitions of the time domain into intervals, and thereby construct a sequence (f n) n#N of discrete time series. As n increases this amounts to sampling the <b>continuous</b> <b>time</b> <b>series</b> {{with more and more}} accuracy. Our main result is consistent behaviour of segmentations w. r. t. to variation of parameters and increasing sampling rate...|$|E
40|$|In {{order to}} {{forecast}} time {{evolution of a}} binary response variable from a related <b>continuous</b> <b>time</b> <b>series</b> a functional logit model is proposed. The estimation of this model from discrete time observations of the predictor is solved by using functional principal component analysis and ARIMA modelling of the associated discrete time series of principal components. The proposed model is applied to forecast the risk of drought from El Niño phenomenon. ...|$|E
40|$|This is {{the fourth}} {{consecutive}} report presenting R-ISEW (regional index of sustainable economic well-being) calculations for the nine Government Office Regions (GORs) of England. 1 New data available {{in the summer of}} 2010 allows a <b>continuous</b> <b>time</b> <b>series</b> from 1994 to 2008 – 15 years. Because {{of the nature of the}} data required for the R-ISEW, there is always a two-year lag before results for any given year can be completed...|$|E
40|$|A {{survey is}} given of {{recently}} developed mathematical models for <b>continuous</b> variate non-Gaussian <b>time</b> <b>series.</b> The {{emphasis is on}} marginally specific models with given correlation structure. Exponential, Gamma, Weibull, Laplace, Beta, and Mixed Exponential models are considered for the marginal distributions of the stationary <b>time</b> <b>series.</b> Most of the models are random coefficient, additive linear models. Some discussion {{of the meaning of}} autoregression and linearity is given, as well as suggestions for higher-order linear residual analysis for nonGaussian models. (Author) Prepared for: Office of Naval Research Arlington, VA[URL]...|$|R
40|$|Abstract. Some of {{the models}} {{obtained}} {{in the study of}} <b>time</b> <b>series</b> using data mining in the group of Málaga are presented. Firstly, two methods to assign discrete values to <b>continuous</b> values from <b>time</b> <b>series</b> are proposed; these methods use dynamic information about the series. The first method is based on a particular statistic which allows us to select a discrete value for a new continuous value from the series. The second one is based on the proposed concept of significant distance between consecutive values from <b>time</b> <b>series.</b> Secondly, the use of probabilistic finite automata to model <b>time</b> <b>series</b> are described. Finally, an algorithm to generate <b>time</b> <b>series</b> with the same statistical properties that the real ones is presented. ...|$|R
40|$|International audienceThis paper {{presents}} a new method to analyse cardiac electrophysiological dynamics. It aims to classify or to cluster (i. e. to find natural groups) patients {{according to the}} dynamics of features extracted from their ECG. In this work, {{the dynamics of the}} features are modelled with Continuous Density Hidden Semi-Markovian Models (CDHSMM) which are interesting for the characterization of <b>continuous</b> multivariate <b>time</b> <b>series</b> without a priori information. These models can be easily used for classification and clustering. In this last case, a specific method, based on a fuzzy Expectation Maximisation (EM) algorithm, is proposed. Both tasks are applied to the analysis of ischemic episodes with encouraging results and a classification accuracy of 71 %...|$|R
40|$|In this article, the nonparametric {{version of}} {{estimation}} equations is investigated, which unifies various statistical methodologies, for both nonlinear discrete and <b>continuous</b> <b>time</b> <b>series</b> data. The weak consistency and asymptotic normality {{of the resulting}} estimators are established. Under this general framework, a nonparametric regression estimator can be obtained easily and the asymptotic theory can be derived without going through case-by-case. [alpha]-mixing Continuous and discrete data Estimation equations Local linear fitting Nonlinear time series Robustness...|$|E
40|$|An {{integral}} transform {{method is}} used to obtain <b>continuous</b> <b>time</b> <b>series</b> of wave amplitude and period from ocean wave measurements. The joint statistics of these two variables are determined and directly compared with the theoretical probability density predicted by Longuet-Higgins (1983). Good agreement is found for data from both calm and stormy sea states. This method avoids the ambiguities in the definitions of wave amplitude and period found in earlier comparisons of field data with theory...|$|E
40|$|The Atmospheric Radiation Measurement (ARM) Program {{defined a}} {{specific}} metric {{for the third}} quarter of Fiscal Year 2006 to produce and refine a one-year <b>continuous</b> <b>time</b> <b>series</b> of cloud microphysical properties based on cloud radar measurements for each of the fixed ARM sites. To accomplish this metric, we used a combination of recently developed algorithms that interpret radar reflectivity profiles, lidar backscatter profiles, and microwave brightness temperatures into the context of the underlying cloud microphysical structure...|$|E
40|$|ABSTRACT: This study {{discusses}} how to {{roll over}} European Union Allowances (EUAs) and Certified Emissions Reduction (CERs) futures contracts with different maturities. The aim is to elucidate {{whether or not the}} choice of rollover date is important when constructing EUAs and CERs <b>continuous</b> futures <b>time</b> <b>series.</b> We have applied five different methodologies to link the series and our findings indicate that return distributions do not significantly differ for the different criteria. This result has direct practical implications in the field of applied econometrics of carbon markets given that we prove that the selection of the simple last-day rollover methodology criterion has no downside {{not only in terms of}} returns distribution but also with respect to liquidity levels...|$|R
40|$|This paper {{presents}} a new method to analyse cardiac electrophysiological dynamics. It aims to classify or to cluster (i. e. to find natural groups) patients {{according to the}} dynamics of features extracted from their ECG. In this work, {{the dynamics of the}} features are modelled with Continuous Density Hidden Semi-Markovian Models (CDHSMM) which are interesting for the characterization of <b>continuous</b> multivariate <b>time</b> <b>series</b> without a priori information. These models can be easily used for classification and clustering. In this last case, a specific method, based on a fuzzy Expectation Maximisation (EM) algorithm, is proposed. Both tasks are applied to the analysis of ischemic episodes with encouraging results and a classification accuracy of 71...|$|R
40|$|We derive {{tests of}} {{stationarity}} for <b>continuous</b> univariate <b>time</b> <b>series</b> by combining change-point tests sensitive {{to changes in}} the contemporary distribution with tests sensitive {{to changes in the}} serial dependence. Rank-based cumulative sum tests based on the empirical distribution function and on the empirical autocopula at a given lag are considered first. The combination of their dependent p-values relies on a joint dependent multiplier bootstrap of the two underlying statistics. Conditions under which the proposed combined testing procedure is asymptotically valid under stationarity are provided. After discussing the choice of the maximum lag to investigate, extensions based on tests solely focusing on second-order characteristics are proposed. The finite-sample behaviors of all the derived statistical procedures are investigated in large-scale Monte Carlo experiments and illustrations on two real data sets are provided. Extensions to multivariate <b>time</b> <b>series</b> are briefly discussed as well. Comment: 35 pages, 8 table...|$|R
