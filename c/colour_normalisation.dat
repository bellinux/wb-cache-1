9|0|Public
50|$|Color {{normalization}} is a {{topic in}} computer vision concerned with artificial color vision and object recognition. In general, the distribution of color values in an image depends on the illumination, which may vary depending on lighting conditions, cameras, and other factors. <b>Colour</b> <b>normalisation</b> allows for object recognition techniques based on colour to compensate for these variations.|$|E
40|$|Images of {{the human}} retina vary {{considerably}} in their appearance depending on the skin pigmentation (amount of melanin) of the subject. Some form of normalisation of colour in retinal images is required for automated analysis of images if good sensitivity and specificity at detecting lesions is to be achieved in populations involving diverse races. Here we describe an approach to <b>colour</b> <b>normalisation</b> by shade-correction intra-image and histogram normalisation inter-image. The <b>colour</b> <b>normalisation</b> is assessed by {{its effect on the}} automated detection of microaneurysms in retinal images. It is shown that the Na¨ıve Bayes classifier used in microaneurysm detection benefits from the use of features measured over colour normalised images...|$|E
40|$|Abstract. Retinal exudates are {{typically}} manifested as spatially random yellow/white patches of varying sizes and shapes. They are a characteristic feature of retinal {{diseases such as}} diabetic maculopathy. An automatic method {{for the detection of}} exudate regions is introduced comprising image <b>colour</b> <b>normalisation,</b> enhancing the contrast between the objects and background, segmenting the colour retinal image into homogenous regions using Fuzzy C-Means clustering, and classifying the regions into exudates and non exudates patches using a neural network. Experimental results indicate that we are able to achieve 92 % sensitivity and 82 % specificity. ...|$|E
40|$|This paper {{deals with}} the problem of colour {{constancy}} for real-time face tracking. We present two extensions of the Grey World (GW) algorithm {{in order to deal with}} dynamic image sequences with varying illumination intensity. The first extension consists in a new <b>colour</b> <b>normalisation,</b> the Projective Grey World Normalisation, which makes GW more robust to illumination intensity variations. The second extension, the Dynamic Grey World Algorithm, permits the use of GW with dynamic image sequences. We have conducted several experiments with these extensions and compared the results obtained with the rg-normalisation algorithm, possibly the most popular colour constancy procedure among the face tracking community...|$|E
40|$|Abstract. Colour is an {{important}} cue in many applications of computer vision and image processing, but robust usage often requires estimation of the unknown illuminant colour. Usually, to obtain images invariant to the illumination conditions under which they were taken, color nor-malisation is used. In this work, we develop a such <b>colour</b> <b>normalisation</b> technique, where true colours are not important per se but where ex-amples of same classes have photometrically consistent appearance. This is achieved by supervised estimation of a class specific canonical colour space where the examples have minimal variation in their colours. We demonstrate the effectiveness of our method with qualitative and quan-titative examples from the Caltech- 101 data set and a real application of 3 D pose estimation for robot grasping. ...|$|E
40|$|Abstract. The {{development}} of a nationwide eye screening programme {{for the detection of}} diabetic retinopathy has generated much interest in automated screening tools. Currently most such systems analyse only intensity information — discarding colour information if it is present. Including colour information in the classification process is not trivial; large natural variations in retinal pigmentation result in colour differences between individuals which tend to mask the more subtle variation between the important lesion types. This study investigated the effectiveness of three <b>colour</b> <b>normalisation</b> algorithms for reducing the background colour variation between subjects. The normalisation methods were tested using a set of colour retinal fundus camera images containing four different lesions which are important in the screening context. Regions of interest were drawn on each image to indicate the different lesion types. The distribution of chromaticity values for each lesion type from each image was plotted, both without normalisation and following application of each of the three normalisation techniques. Histogram specification of the separate colour channels was found to be the most effective normalisation method, increasing the separation between lesion type clusters in chromaticity space and making possible robust use of colour information in the classification process. ...|$|E
40|$|Abstract. Colour {{consistency}} in light microscopy based histology is {{an increasingly important}} problem {{with the advent of}} Gigapixel digital slide scanners and automatic image analysis. This paper presents an evaluation of two novel <b>colour</b> <b>normalisation</b> approaches against the previously utilised method of linear normalisation in lαβ colourspace. These approaches map the colour distribution of an over/under stained image to that of a well stained target image. The first novel approach presented is a multi-modal extension to linear normalisation in lαβ colourspace using an automatic image segmentation method and defining separate transforms for each class. The second approach normalises in a representation space obtained using stain specific colour deconvolution. Additionally, we present a method for estimation of the required colour deconvolution vectors directly from the image data. Our evaluation demonstrates the inherent variability in the original data, the known theoretical problems with linear normalisation in lαβ colourspace, and that a multi-modal colour deconvolution based approach overcomes these problems. The segmentation based approach, while producing good results on the majority of images, is less successful than the colour deconvolution method for a significant minority of images as robust segmentation is required to avoid introducing artifacts. ...|$|E
40|$|The GUT {{value of}} Weinberg’s angle {{is also the}} value that minimises the total square matrix {{elements}} of Z 0 decay, independently of any GUT consideration, and thus the one that maximises the neutrino branching ratio against total width. We review the proof of this result and some related facts. From any textbook (eg [1]), the amplitude for decay of Z 0 into a fermion pair, at leading order, is Γ(Z 0 → f ¯ f) = Cf (|Vf | 2 + |Af | 2) GF M 3 Z 6 √ 2 π where Cf is a <b>colour</b> <b>normalisation</b> constant, 1 for fermions and 3 for quarks, and Vf and Af are the vector and axial charges, (1) Vf = T 3 f − 2 Qf sin 2 θW (2) Af = T 3 f (3) If we are interested on the decay into a set of fermions, we add the contributions to get the total square matrix element: K {f} = � f Cf ((T 3 f) 2 + (T 3 f − 2 Qf ˆs) 2) (4) We want to know for which value of ˆs ≡ sin 2 θW will the relative coupling, and then the decay width 1, to be a minimum. Thus we ask (ˆs) = 2 Cf (T 3 f − 2 Qf ˆs) (− 2 Qf) = 4 � Cf (2 ˆsQ 2 f − T 3 f Qf) (5...|$|E
40|$|Background: Digital image {{analysis}} {{has the potential}} to address issues surrounding traditional histological techniques including a lack of objectivity and high variability, through the application of quantitative analysis. A key initial step in {{image analysis}} is the identification of regions of interest. A widely applied methodology is that of segmentation. This paper proposes the application of image analysis techniques to segment skin tissue with varying degrees of histopathological damage. The segmentation of human tissue is challenging {{as a consequence of the}} complexity of the tissue structures and inconsistencies in tissue preparation, hence there is a need for a new robust method with the capability to handle the additional challenges materialising from histopathological damage. Methods: A new algorithm has been developed which combines enhanced colour information, created following a transformation to the L*a*b* colourspace, with general image intensity information. A <b>colour</b> <b>normalisation</b> step is included to enhance the algorithm's robustness to variations in the lighting and staining of the input images. The resulting optimised image is subjected to thresholding and the segmentation is fine-tuned using a combination of morphological processing and object classification rules. The segmentation algorithm was tested on 40 digital images of haematoxylin & eosin (H&E) stained skin biopsies. Accuracy, sensitivity and specificity of the algorithmic procedure were assessed through the comparison of the proposed methodology against manual methods. Results: Experimental results show the proposed fully automated methodology segments the epidermis with a mean specificity of 97. 7 %, a mean sensitivity of 89. 4 % and a mean accuracy of 96. 5 %. When a simple user interaction step is included, the specificity increases to 98. 0 %, the sensitivity to 91. 0 % and the accuracy to 96. 8 %. The algorithm segments effectively for different severities of tissue damage. Conclusions: Epidermal segmentation is a crucial first step in a range of applications including melanoma detection and the assessment of histopathological damage in skin. The proposed methodology is able to segment the epidermis with different levels of histological damage. The basic method framework could be applied to segmentation of other epithelial tissues...|$|E

