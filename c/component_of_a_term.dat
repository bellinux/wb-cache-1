2|10000|Public
40|$|Complex {{numbers are}} a {{fundamental}} {{aspect of the}} mathematical formalism of quantum physics. Quantum-like models developed outside physics often overlooked the role of complex numbers. Specifically, previous models in Information Retrieval (IR) ignored complex numbers. We argue that to advance the use of quantum models of IR, one has to lift the constraint of real-valued representations of the information space, and package more information within the representation by means of complex numbers. As a first attempt, we propose a complex-valued representation for IR, which explicitly uses complex valued Hilbert spaces, and thus where terms, documents and queries are represented as complex-valued vectors. The proposal consists of integrating distributional semantics evidence within the real <b>component</b> <b>of</b> <b>a</b> <b>term</b> vector; whereas, ontological information is encoded in the imaginary component. Our proposal has the merit of lifting the role of complex numbers from a computational byproduct of the model to the very mathematical texture that unifies different levels of semantic information. An empirical instantiation of our proposal is tested in the TREC Medical Record task of retrieving cohorts for clinical studies...|$|E
40|$|Abstract. Complex {{numbers are}} a {{fundamental}} {{aspect of the}} mathematical for-malism of quantum physics. Quantum-like models developed outside physics often overlooked the role of complex numbers. Specifically, previous models in Information Retrieval (IR) have ignored complex numbers. In this paper, we argue {{that in order to}} advance the use of quantum models of IR, one has to lift the con-straint of real-valued representations of the information space, and package more information within the representation by means of complex numbers. As a first attempt, we propose a complex-valued representation for IR, which explicitly uses complex valued Hilbert spaces, and thus where terms, documents and queries are represented as complex-valued vectors. The proposal consists of integrating distri-butional semantics evidence within the real <b>component</b> <b>of</b> <b>a</b> <b>term</b> vector; whereas, ontological information is encoded in the imaginary component. Our proposal has the merit of lifting the role of complex numbers from a computational byprod-uct of the model to the very mathematical texture that unifies different levels of semantic information. An empirical instantiation of our proposal is tested in the TREC Medical Record task of retrieving cohorts for clinical studies. ...|$|E
40|$|Evaluates <b>components</b> <b>of</b> <b>a</b> short <b>term</b> {{test for}} {{trypanotolerance}} criteria in N'Dama post-weaners {{exposed to a}} medium natural trypanosome challenge in Gabon; compares the effectiveness of different measures of control of development of anaemia; and measures the post-test recovery of packed red cell volume (PCV) values following treatment with a trypanocidal drug...|$|R
40|$|Subsequent to the October 1979 {{shift in}} {{monetary}} {{policy in the}} United States, interest rates in North America not only reached unprecedented levels,but also exhibited unprecedented volatility. This paper shows that the anticipated quarterly changes in long-term rates associated with the rational expectations model have remained small during this post-shift period. Recorded forecasts of long-term interest rates in Canada continue to prove inferior to the no-change prediction of the martingale model. The "perverse" relationship between {{the slope of the}} yield curve and the subsequent movementin long-term rates exists in the Canadian data, but is of only modest value in a forecasting context. The excess return on long-term bonds implicit in the recorded forecasts of the level of interest rates varies sharply, yet {{there is no evidence that}} forecasters have identified <b>a</b> predictable <b>component</b> <b>of</b> <b>a</b> time-varying <b>term</b> premium. ...|$|R
40|$|In this paper, we {{will develop}} an {{iterative}} procedure {{to determine the}} detailed asymptotic behaviour <b>of</b> solutions <b>of</b> <b>a</b> certain class <b>of</b> nonlinear vector differential equations which approach a nonlinear sink as time tends to infinity. This procedure is indifferent to resonance in the eigenvalues. Moreover, we will address the writing <b>of</b> one <b>component</b> <b>of</b> <b>a</b> solution in <b>terms</b> <b>of</b> {{the other in the}} case <b>of</b> <b>a</b> planar system. Examples will be given, notably the Michaelis-Menten mechanism of enzyme kinetics. Comment: 31 pages, 1 figure, condensed or removed some sections and expanded other...|$|R
2500|$|The {{elementary}} mechanical <b>components</b> <b>of</b> <b>a</b> machine are <b>termed</b> machine elements. [...] These elements {{consist of}} three basic types (i) structural components such as frame members, bearings, axles, splines, fasteners, seals, and lubricants, (ii) mechanisms that control movement {{in various ways}} such as gear trains, belt or chain drives, linkages, cam and follower systems, including brakes and clutches, and (iii) control components such as buttons, switches, indicators, sensors, actuators and computer controllers. [...] While generally {{not considered to be}} a machine element, the shape, texture and color <b>of</b> covers are <b>an</b> important part <b>of</b> <b>a</b> machine that provide a styling and operational interface between the mechanical <b>components</b> <b>of</b> <b>a</b> machine and its users.|$|R
40|$|Term {{rewriting}} {{systems are}} widely used throughout computer science as they provide <b>an</b> abstract model <b>of</b> computation while retaining a comparatively simple syntax and semantics. In order to reason within large term rewriting systems, structuring operations are {{used to build large}} term rewriting systems from smaller ones. Of particular interest is whether key properties are modular, thatis,ifthe <b>components</b> <b>of</b> <b>a</b> structured <b>term</b> rewriting system satisfy a property, then does the term rewriting system as a whole? <b>A</b> body <b>of</b> literature addresses this problem, but most of the results and proofs depend on strong syntactic conditions and do not easily generalize. Although many specific modularity results are known, a coherent framework which explains the underlying principles behind these results is lacking. This thesis posits that {{part of the problem is}} the usual, concrete and syntaxoriented semantics of term rewriting systems, and that a semantics is needed which on the one hand elides unnecessary syntactic details but on the other hand still possesses enough expressive power to model the key concepts arising fro...|$|R
40|$|<b>Term</b> {{weighting}} is <b>an</b> {{essential part}} <b>of</b> the modern information retrieval systems. Out {{of the three}} main <b>components</b> <b>of</b> <b>a</b> <b>term</b> weighting strategy [...] - term frequency, inverse document frequency, and document length normalization [...] - the term frequency factor has been investigated recently by researchers. In this work, we study the inverse document frequency, and document length normalization <b>components</b> <b>of</b> term weights. We observe that a document length normalization scheme that retrieves documents of all lengths with similar chances as their likelihood of relevance will outperform another scheme which retrieves documents with chances very different from their likelihood of relevance. We present pivoted normalization, a technique {{that can be used}} to modify normalization functions to reduce the gap between the relevance and the retrieval probabilities. We present two new normalization functions [...] - pivoted unique normalization and pivoted byte size normalization, both of which yield significant improvements over the previous state of the art normalization functions. When optical character recognition is used to create large information bases, term weighting schemes can be highly sensitive to the errors in the input text, introduced by the OCR process. This work examines the effects of the well known cosine normalization method in the presence of OCR errors, and proposes a new, more robust, normalization method. Experiments show that the new scheme is less sensitive to OCR errors and facilitates the use of more diverse basic weighting schemes. This study also explains why the use of cosine normalization in presence of the inverse document frequency factor is not advisable in large document collections. When a user types a natural language query for an IR system, certain keywords in the query are more pertinent to the user's information need than others. Most modern IR systems incorporate these distinctions by using an inverse document frequency (idf) factor in term weighting. Preliminary experiments show that the usefulness <b>of</b> <b>an</b> idf type function is high at low ranks. We observe that the main reason for this effect is the widened gap between the weights of the rare terms and the non-rare query terms. The standard idf function works very well across query sets. Experiments show that there is room for improvement in the idf function. Further studies are needed to discover a better replacement for the standard idf function...|$|R
40|$|Automatic {{terminology}} extraction can {{be divided}} into two tasks. The first task measures the unithood which is used to identify a string as a lexical unit. The second task measures the so called termhood, used to identify a lexical unit being <b>a</b> domain specific <b>term.</b> This paper proposes a method to measure termhood in Chinese ATE. It considers the domain specificity <b>of</b> both the <b>components</b> <b>of</b> <b>a</b> candidate <b>term</b> as well as statistical information and other contextual information across different domains and applied to a support vector machine model for terminology extraction. The experiments are based on the Chinese corpus in the IT domain with cross validation of data from outside of the IT domain. Results show that the precision of the open tests can reach over 80 % for the top 2, 000 candidates and around 50 % for the top 20, 000 candidate. Furthermore, experiments with different lexicon size shows that the algorithm does not require a comprehensive domain lexicon <b>of</b> <b>a</b> large size. A few thousand basic domain terms would be sufficient to achieve the above mentioned performance. Department of ComputingRefereed conference pape...|$|R
40|$|This paper {{focuses on}} {{identifying}} meaning {{components in the}} translation of English medical terms into Indonesian. The data {{used in this study}} are the English medical term disorder and its Indonesian equivalent penyakit (disease). The two terms are purposively chosen as the data of the present study, which is a comparative research on the lexical meaning investigation in two different languages. The investigation involving <b>a</b> particular <b>term</b> in one language and its equivalent in the other language is worth doing since the lexicons in every language have their own specific concepts that may be synonymous, yet they are not always interchangeable in all contexts. The analysis into meaning components is called decomposition by means of several semantic theories to analyse the meaning <b>of</b> <b>a</b> lexical item (Löbner 2013). Here, the meaning <b>components</b> <b>of</b> the two compared terms are demonstrated through a semantic approach, particularly Natural Semantic Metalanguage (NSM) supported by the investigation on their synonyms and how the terms are used in different contexts. The results show that the meaning <b>components</b> <b>of</b> <b>a</b> particular <b>term</b> in one language like the English term disorder are not always found in the Indonesian term penyakit, or, conversely, some <b>of</b> the meaning <b>components</b> <b>of</b> the Indonesian term do not always exist in the English term...|$|R
5000|$|Thus aiki's {{meaning is}} to fit, join, or combine energy. However, {{care must be}} taken about the {{absolute}} meanings of words when discussing concepts derived from other cultures and expressed in different languages. This is particularly true when the words we use today have been derived from symbols, in this case, Chinese and Japanese kanji, which represent ideas rather than literal translations <b>of</b> the <b>components.</b> Historical use <b>of</b> <b>a</b> <b>term</b> can influence meanings and be passed down by those wishing to illustrate ideas with the best word or phrase available to them. In this way, there may be <b>a</b> divergence <b>of</b> the meaning between arts or schools within the same art. The characters [...] "ai" [...] and [...] "ki" [...] have translations to many different English words.|$|R
40|$|Although the {{elements}} <b>of</b> <b>a</b> fully stated rule (discriminative stimulus [SD], some behavior, and a consequence) can occur nearly contemporaneously {{with the statement}} of the rule, {{there is often a}} delay between the rule statement and the SD. The effects of this delay on rule following have not been studied in behavior analysis, but they have been investigated in rule-like settings in the areas of prospective memory (remembering to do something in the future) and goal pursuit. Discriminative events for some behavior can be event based (a specific setting stimulus) or time based. The latter are more demanding with respect to intention following and show age-related deficits. Studies suggest that the specificity with which the <b>components</b> <b>of</b> <b>a</b> rule (<b>termed</b> intention) are stated has a substantial effect on intention following, with more detailed specifications increasing following. Reminders <b>of</b> <b>an</b> intention, too, are most effective when they refer specifically to both the behavior and its occasion. Covert review and written notes are two effective strategies for remembering everyday intentions, but people who use notes appear {{not to be able to}} switch quickly to covert review. By focusing on aspects of the setting and rule structure, research on prospective memory and goal pursuit expands the agenda for a more complete explanation of rule effects...|$|R
40|$|The {{budgets for}} the Reynolds {{stresses}} {{and for the}} dissipation rate of the turbulence kinetic energy are computed using direct simulation data <b>of</b> <b>a</b> turbulent channel flow. The budget data reveal that all the terms in the budget become important close to the wall. For inhomogeneous pressure boundary conditions, the pressure-strain term is split into <b>a</b> return <b>term,</b> <b>a</b> rapid <b>term,</b> and <b>a</b> Stokes <b>term.</b> The Stokes term is important close to the wall. The rapid and return terms play different roles depending on the <b>component</b> <b>of</b> the <b>term.</b> <b>A</b> split <b>of</b> the velocity pressure-gradient <b>term</b> into <b>a</b> redistributive <b>term</b> and <b>a</b> diffusion <b>term</b> is proposed, which should be simpler to model. The budget data is used to test existing closure models for the pressure-strain term, the dissipation rate, and the transport rate. In general, further work is needed to improve the models...|$|R
40|$|Cosmological {{constant}} {{corresponds to}} the maximally symmetric cosmological term with the equation of state p = − ρ. Introducing <b>a</b> cosmological <b>term</b> with the reduced symmetry, p r = − ρ in the spherically symmetric case, makes cosmological constant intrinsically variable <b>component</b> <b>of</b> <b>a</b> variable cosmological <b>term</b> which describes time-dependent and spatially inhomogeneous vacuum dark energy. Relaxation of the cosmological constant from the big initial value to the presently observed value can be then described in general setting by the spherically symmetric cosmology of the Lemaître class. We outline in detail the cosmological model with the global structure of the de Sitter spacetime distinguished by the holographic principle as the only stable product of quantum evaporation of the cosmological horizon entirely determined by its quantum dynamics. Density of the vacuum dark energy is presented by semiclassical description of vacuum polarization in the spherically symmetric gravitational field, and its initial value is chosen at the GUT scale. The final non-zero value of the cosmological constant is tightly fixed by the quantum dynamics of evaporation and appears in the reasonable agreement with its observational value...|$|R
40|$|This {{discussion}} paper is meant to:- Reaffirm {{the need to}} develop performance measures by which to measure progress over time in the field of civil justice reform- Provide a conceptual framework within which to make decisions about the scope and feasibility of establishing pan-Canadian performance measures- Stimulate thinking about the <b>components</b> <b>of</b> <b>a</b> short <b>term</b> Action Plan that would set out: o Agreement on <b>a</b> short <b>term</b> list <b>of</b> 5 - 10 dimensions or characteristics within which measures and indicators need to be developed or refined o A work plan for the development of future performance measures o The critical success factors required from a data development and collection perspective that will be required in the longer term o The respective roles of the justice partners in the development and implementation <b>of</b> <b>a</b> performance measurement platform B. The Vision In the simplest of terms, there needs to be consensus about what it is we wish to measure. The vision <b>of</b> <b>an</b> accessible, effective, fair and efficient civil justice system ought to be the conceptual rubric within which performance measurement is discussed. This paper takes the intellectual underpinnings of the CBA Task Force as the starting point for discussion. The authors of the report see a modern and effective civil justice system as being 1 : � Responsive to the needs of users � Encouraging and valuing public involvement � Providing many options for litigants for dispute resolution � Resting within a framework managed by courts � Providing an incentive structure that rewards early settlement � Resulting in trials being <b>a</b> mechanism <b>of</b> valued but last resort for determining dispute...|$|R
40|$|Abstract Quantitative {{analysis}} {{by means of}} discrete-state stochastic processes is hindered by the well-known phenomenon of state-space explosion, whereby {{the size of the}} state space may have an exponential growth with the number of agents of the system under scrutiny. When the stochastic process underlies a Markovian process algebra model, this problem may be alleviated by suitable notions of behavioural equivalence that induce lumping at the underlying continuous-time Markov chain, establishing an exact relation between a potentially much smaller aggregated chain and the original one. For the analysis of massively parallel systems, however, lumping techniques may not be sufficient to yield a computationally tractable problem. Recently, much work has been directed towards forms of fluid techniques that provide <b>a</b> set <b>of</b> ordinary differential equations (ODEs) approximating the expected path of the stochastic process. Unfortunately, even fluid models of realistic systems may be too large for feasible analysis. This paper studies a behavioural relation for process algebra with fluid semantics, called projected label equivalence, which is shown to yield an exactly fluid lumpable model, i. e., an aggregated {ODE} system which can be related to the original one without any loss of information. Project label equivalence relates sequential <b>components</b> <b>of</b> <b>a</b> process <b>term.</b> In general, for any two sequential components that are related in the fluid sense, nothing can be said about their relationship from the stochastic viewpoint. We define and study <b>a</b> notion <b>of</b> well-posedness which allows us to relate fluid lumpability to the stochastic notion of semi-isomorphism, which is <b>a</b> weaker version <b>of</b> the common notion of isomorphism between the doubly labelled transition systems at the basis of the Markovian interpretation...|$|R
40|$|AbstractGrammar {{is defined}} as “a science which {{identifies}} the rules <b>of</b> <b>a</b> language after analysing phonology, syntax and sentence structure” (Turkish Language Institution 2005). Functional Linguistics has gained popularity in the recent centuries after related researches. Again by Turkish Language Institution (2005) defines “function” as: “Any duty, any functionality or ability to perform a duty. ” From the distinctions given above, {{it is necessary to}} classify and define Functional Linguistics and Functional Grammar separately. Functional Grammar is a Structural Linguistic Trend which deals with the components and the connections between these <b>components</b> <b>of</b> <b>a</b> language in <b>terms</b> <b>of</b> informational functions, which gives priority to informational function to identify and evaluate language facts and finally by this concept, which tries to find out correct linguistic description. As for the methodology the main rule here is to identify the functions of linguistic facts which try to fulfill the informative duties and thereby find the specific value of it in the language system. (Vardar ad, 1998 : page 129; by İşcan, 2007). “Functional Linguistics tries to identify the main meaningful <b>components</b> <b>of</b> the language system, the connections between these components and their functionalities of informative duties. ” (Rifat, 2000, Page. 63) ...|$|R
40|$|AbstractIntersection {{types are}} well known to type theorists mainly for two reasons. Firstly, they type all and only the {{strongly}} normalizable lambda terms. Secondly, the intersection type operator is a meta-level operator, that is, {{there is no direct}} logical counterpart in the Curry–Howard isomorphism sense. In particular, its meta-level nature implies that it does not correspond to the intuitionistic conjunction. The intersection type system is naturally a type inference system (system à la Curry), but the meta-level nature of the intersection operator does not allow to easily design an equivalent typed system (system à la Church). There are many proposals in the literature to design such systems, but none <b>of</b> them gives <b>an</b> entirely satisfactory answer to the problem. In this paper, we will review the main results in the literature both on the logical interpretation of intersection types and on proposed typed lambda calculi. The core of this paper is a new proposal for a true intersection typed lambda calculus, without any meta-level notion. Namely, any typable term (in the intersection type inference) has <b>a</b> corresponding typed <b>term</b> (which {{is the same as the}} untyped term by erasing the type decorations and the typed term constructors) with the same type, and vice versa. The main idea is to introduce <b>a</b> relevant parallel <b>term</b> constructor which corresponds to the intersection type constructor, in such <b>a</b> way that <b>terms</b> in parallel share the same resources, that is, the same context of free typed variables. Three rules allow us to generate all typed terms. The first two rules, Application and Lambda-abstraction, are performed on all the <b>components</b> <b>of</b> <b>a</b> parallel <b>term</b> in <b>a</b> synchronized way. Finally, via the third rule of Local Renaming, once a free typed variable is bounded by lambda-abstraction, each of the terms in parallel can do its local renaming, with type refinement, of that particular resource...|$|R
40|$|Loricrin is {{the major}} <b>component</b> <b>of</b> <b>a</b> {{specialized}} structure, <b>termed</b> the cornified cell envelope, that is formed beneath the plasma membrane of stratified squamous epithelial cells and is coexpressed with profilaggrin in terminally differentiating epidermal keratinocytes. Full-length cDNAs for both mouse and human loricrin have been cloned and characterized, as has the human gene. Here we report the isolation and characterization of the mouse loricrin gene. The gene has a simple structure consisting <b>of</b> <b>a</b> single intron <b>of</b> 1091 bp within the 52 ̆ 7 noncoding sequence and an uninterrupted open reading frame. Using PCR analyses of DNAs isolated from mouse x Chinese hamster somatic cell hybrids, we have mapped both the loricrin and the profilaggrin genes to chromosome 3. Genetic linkage analysis has shown that mouse loricrin and profilaggrin lie within 1. 5 ± 1. 1 centimorgans of each other. We have further shown that both genes map {{in the vicinity of}} the flaky tail (ft) and soft coat (soc) loci. These mouse mutants exhibit <b>a</b> number <b>of</b> changes in their integument, suggesting that abnormalities in these genes may contribute to the mutant phenotype...|$|R
40|$|The NPS 1 /STH 1 gene encodes {{a nuclear}} protein {{essential}} for the progression of G 2 /M phase in Saccharomyces cerevisiae. Nps 1 p shares homology to Snf 2 /Swi 2 p, <b>a</b> subunit <b>of</b> <b>a</b> protein complex known as the SNF/SWI complex. Recently, Nps 1 p {{was found to be}} <b>a</b> <b>component</b> <b>of</b> <b>a</b> protein complex <b>termed</b> RSC (3) essential for mitotic growth, whereas its function is unknown. We isolated a temperature-sensitive mutant allele of NPS 1, nps 1 - 105, and found that the mutation increases the sensitivity to thiabendazole (TBZ). At the restrictive temperature, nps 1 - 105 arrested at the G 2 /M phase in MAD 1 -dependent manner and missegregated the mini-chromosome with higher frequency than the wild type cells. The nuclease digestion of the chromatin of the mutant cells revealed that the mutation causes the alteration of the chromatin structure around centromeres at the restrictive temperature. The results suggested that, in the nps 1 - 105 mutant, impaired chromatin structure surrounding centromeres may lead to <b>an</b> impairment <b>of</b> kinetochore function and the cells arrest at G 2 /M phase through the spindle-assembly checkpoint system...|$|R
40|$|In vitro {{modelling}} {{offers the}} potential of recapitulating human degenerate tissue for physiological studies and pharmacological screening. Yet, few systems {{have been developed to}} date, primarily {{due to the lack of}} vascularisation in engineered tissue. Here, the development <b>of</b> <b>an</b> in vitro pump is addressed. This will be the first <b>component</b> <b>of</b> <b>a</b> long <b>term</b> strategy to build internal circulatory systems for in vitro engineered tissue. Firstly, mechanical characterisation and surface biocompatibility of spin coated poly(dimethylsiloxane) (PDMS) elastomeric membranes was investigated to assess whether PDMS could be used as a structural constituent. Results showed that spin coating speed defines both film thickness and specific mechanical properties since tensile testing revealed that PDMS membranes exhibit thickness-dependent mechanical properties. Plasma polymerisation of allylamine was used to surface engineer the hydrophobic PDMS surface to promote cell adhesion and proliferation. Surface characterisation revealed that PDMS surfaces became hydrophilic and nitrogen enriched as <b>a</b> result <b>of</b> plasma polymerised allylamine (ppAAm) deposition. Additionally, a thick ppAAm deposition (92 nm) is required to minimise hydrophobic recovery of PDMS. Cell culture studies showed that cells readily attached to ppAAm (92 nm) deposited PDMS and that these surfaces were best suited to cultivating cells compared to other surface treatments. Secondly, a method was developed to control cell positioning on the PDMS surface, since cell alignment is required to generate directional and contractile force. The deposition of ppAAm (92 nm) and airbrushing of extracellular matrix (ECM) aerosols can be spatially restricted using a micro-stencil. Individual and multiple cell line patterns were achieved that remained faithful for ≤ 10 days. Importantly, this technique micropatterned cells at high resolution over macro scales. External mechanical stimulation was used to influence cell alignment and cytoskeletal organisation on ppAAm (92 nm) / Fibronectln (Fn) micropatterned PDMS. Results showed that incorporating substrate strain with surface micropatterning can be used to control site- and alignment- specific cell attachment...|$|R
40|$|Laboratory for Foundations of Computer ScienceTerm {{rewriting}} {{systems are}} widely used throughout computer science as they provide <b>an</b> abstract model <b>of</b> computation while retaining a comparatively simple syntax and semantics. In order to reason within large term rewriting systems, structuring operations are {{used to build large}} term rewriting systems from smaller ones. Of particular interest is whether key properties are modular, that is, if the <b>components</b> <b>of</b> <b>a</b> structured <b>term</b> rewriting system satisfy a property, then does the term rewriting system as a whole? <b>A</b> body <b>of</b> literature addresses this problem, but most of the results and proofs depend on strong syntactic conditions and do not easily generalize. Although many specific modularity results are known, a coherent framework which explains the underlying principles behind these results is lacking. This thesis posits that {{part of the problem is}} the usual, concrete and syntax-oriented semantics of term rewriting systems, and that a semantics is needed which on the one hand elides unnecessary syntactic details but on the other hand still possesses enough expressive power to model the key concepts arising from the term structure, such as substitutions, layers, redexes etc. Drawing on the concepts of category theory, such a semantics is proposed, based on the concept <b>of</b> <b>a</b> monad, generalising the very elegant treatment of equational presentations in category theory. The theoretical basis of this work is the theory of enriched monads. It is shown how structuring operations are modelled on the level of monads, and that the semantics is compositional (it preserves the structuring operations). Modularity results can now be obtained directly at the level of combining monads without recourse to the syntax at all. As an application and demonstration of the usefulness of this approach, two modularity results for the disjoint union of two term rewriting systems are proven, the modularity of confluence (Toyama's theorem) and the modularity of strong normalization for <b>a</b> particular class <b>of</b> <b>term</b> rewriting systems (non-collapsing term rewriting systems). The proofs in the categorical setting provide <b>a</b> mild generalisation <b>of</b> these results...|$|R
40|$|Term {{rewriting}} {{systems are}} widely used throughout computer science as they provide <b>an</b> abstract model <b>of</b> computation while retaining a comparatively simple syntax and semantics. In order to reason within large term rewriting systems, structuring operations are {{used to build large}} term rewriting systems from smaller ones. Of particular interest is whether key properties are modular, that is, if the <b>components</b> <b>of</b> <b>a</b> structured <b>term</b> rewriting system satisfy a property, then does the term rewriting system as a whole? <b>A</b> body <b>of</b> literature addresses this problem, but most of the results and proofs depend on strong syntactic conditions and do not easily generalize. Although many specific modularity results are known, a coherent framework which explains the underlying principles behind these results is lacking. This thesis posits that {{part of the problem is}} the usual, concrete and syntaxoriented semantics of term rewriting systems, and that a semantics is needed which on the one hand elides unnecessary syntactic details but on the other hand still possesses enough expressive power to model the key concepts arising from the term structure, such as substitutions, layers, redexes etc. Drawing on the concepts of category theory, such a semantics is proposed, based on the concept <b>of</b> <b>a</b> monad, generalising the very elegant treatment of equational presentations in category theory. The theoretical basis of this work is the theory of enriched monads. It is shown how structuring operations are modelled on the level of monads, and that the semantics is compositional (it preserves the structuring operations). Modularity results can now be obtained directly at the level of combining monads without recourse to the syntax at all. As an application and demonstration of the usefulness of this approach, two modularity results for the disjoint union of two term rewriting systems are proven, the modularity of confluence (Toyama's theorem) and the modularity of strong normalization for <b>a</b> particular class <b>of</b> <b>term</b> rewriting systems (non-collapsing term rewriting systems). The proofs in the categorical setting provide <b>a</b> mild generalisation <b>of</b> these results...|$|R
40|$|This paper {{seeks to}} {{discover}} {{in what sense}} we can classify vocabulary items as technical terms in the later medieval period. In order to arrive at <b>a</b> principled categorization <b>of</b> technicality, distribution is taken as a diagnostic factor: vocabulary shared across the widest range of text types may be assumed to be both prototypical for the semantic field, but also the most general and therefore least technical terms since lexical items derive {{at least part of}} their meaning from context, <b>a</b> wider range <b>of</b> contexts implying <b>a</b> wider range <b>of</b> senses. <b>A</b> further way <b>of</b> addressing the question of technicality is tested through the classification of the lexis into semantic hierarchies: in the terms of componential analysis, having more <b>components</b> <b>of</b> meaning puts <b>a</b> <b>term</b> lower in the semantic hierarchy and flags it as having <b>a</b> greater specificity <b>of</b> sense, and thus as more technical. The various text types are interrogated through comparison of the number of levels in their hierarchies and number of lexical items at each level within the hierarchies. Focusing on the vocabulary <b>of</b> <b>a</b> single semantic field, DRESS AND TEXTILES, this paper investigates how four medieval text types (wills, sumptuary laws, petitions, and romances) employ technical terminology in the establishment of the conventions of their genres...|$|R
40|$|Bacterial {{evolution}} {{is characterized by}} frequent gain and loss events of gene families. These events can be inferred from phyletic pattern data—a compact representation of gene family repertoire across multiple genomes. The maximum parsimony paradigm is a classical and prevalent approach {{for the detection of}} gene family gains and losses mapped on specific branches. We and others have previously developed probabilistic models that aim to account for the gain and loss stochastic dynamics. These models are <b>a</b> critical <b>component</b> <b>of</b> <b>a</b> methodology <b>termed</b> stochastic mapping, in which probabilities and expectations of gain and loss events are estimated for each branch <b>of</b> <b>an</b> underlying phylogenetic tree. In this work, we present a phyletic pattern simulator in which the gain and loss dynamics are assumed to follow a continuous-time Markov chain along the tree. Various models and options are implemented to make the simulation software useful for <b>a</b> large number <b>of</b> studies in which binary (presence/absence) data are analyzed. Using this simulation software, we compared the ability of the maximum parsimony and the stochastic mapping approaches to accurately detect gain and loss events along the tree. Our simulations cover <b>a</b> large array <b>of</b> evolutionary scenarios in terms of the propensities for gene family gains and losses and the variability of these propensities among gene families. Although in all simulation schemes, both methods obtain relatively low levels of false positive rates, stochastic mapping outperforms maximum parsimony in terms of true positive rates. We further studied the factors that influence the performance of both methods. We find, for example, that the accuracy of maximum parsimony inference is substantially reduced when the goal is to map gain and loss events along internal branches of the phylogenetic tree. Furthermore, the accuracy of stochastic mapping is reduced with smaller data sets (limited number of gene families) due to unreliable estimation of branch lengths. Our simulator and simulation results are additionally relevant for the analysis of other types of binary-coded data, such as the existence of homologues restriction sites, gaps, and introns, to name a few. Both the simulation software and the inference methodology are freely available at a user-friendly server: [URL]...|$|R
40|$|Dysbindin was {{identified}} as a dystrobrevin-binding protein potentially involved in the pathogenesis of muscular dystrophy. Subsequently, genetic studies have implicated variants of the human dysbindin-encoding gene, DTNBP 1, in the pathogeneses of Hermansky–Pudlak syndrome and schizophrenia. The protein is <b>a</b> stable <b>component</b> <b>of</b> <b>a</b> multisubunit complex <b>termed</b> BLOC- 1 (biogenesis of lysosome-related organelles complex- 1). In the present study, the significance of the dystrobrevin–dysbindin interaction for BLOC- 1 function was examined. Yeast two-hybrid analyses, and binding assays using recombinant proteins, demonstrated direct interaction involving coiled-coil-forming regions in both dysbindin and the dystrobrevins. However, recombinant proteins bearing the coiled-coil-forming regions of the dystrobrevins failed to bind endogenous BLOC- 1 from HeLa cells or mouse brain or muscle, under conditions in which they bound the Dp 71 isoform of dystrophin. Immunoprecipitation of endogenous dysbindin from brain or muscle resulted in robust co-immunoprecipitation of the pallidin subunit of BLOC- 1 but no specific co-immunoprecipitation of dystrobrevin isoforms. Within BLOC- 1, dysbindin is engaged in interactions with three other subunits, named pallidin, snapin and muted. We herein provide evidence that the same 69 -residue region of dysbindin that is sufficient for dystrobrevin binding in vitro also contains the binding sites for pallidin and snapin, and {{at least part of the}} muted-binding interface. Functional, histological and immunohistochemical analyses failed to detect any sign of muscle pathology in BLOC- 1 -deficient, homozygous pallid mice. Taken together, these results suggest that dysbindin assembled into BLOC- 1 is not a physiological binding partner of the dystrobrevins, likely due to engagement of its dystrobrevin-binding region in interactions with other subunits...|$|R
40|$|Preliminary: Please do not cite without authorspermission Existing {{theoretical}} and empirical research on dowries has di ¢ culty accounting for the large changes in dowry levels observed in many countries {{over the past few}} decades. To explain trends in dowry levels in Bangladesh, we draw attention to <b>an</b> institutional feature <b>of</b> marriage contracts previously ignored in the literature: the mehr or traditional Islamic brideprice, which functions as a prenuptial agreement in Bangladesh, due to the default practice of being only payable upon divorce. We develop <b>a</b> model <b>of</b> marriage contracts in which mehr serves as a barrier to husbands from exiting marriage, and <b>an</b> important <b>component</b> <b>of</b> dowry is <b>a</b> <b>term</b> that ex ante compensates the groom for the cost of mehr chosen by the couple. The contracts are welfare improving because they induce husbands to internalize the social costs of divorce for women. We investigate how mehr and dowry respond to exogenous changes in the costs of polygamy and divorce, and show that both decrease when costs of divorce increase for men. This is in contrast with the predictions of traditional models of dowry. To test the models predictions empirically, we use novel data collected on marriage contracts between 1956 and 2004 from a large household survey from the Northwest region of the country, and make use of key changes in Muslim Family Law between 1961 and 1999. We show that major changes in dowry levels took place precisely after the legal changes, corresponding to simultaneous changes in levels of mehr. We argue that the documented pattern of responses can only be explained if dowries include <b>a</b> <b>component</b> <b>of</b> compensation for mehr...|$|R
40|$|The {{dynamical}} {{analysis of}} large biological regulatory networks requires {{the development of}} scalable methods for mathematical modeling. Following the approach initially introduced by Thomas, we formalize the interactions between the <b>components</b> <b>of</b> <b>a</b> network in <b>terms</b> <b>of</b> discrete variables, functions, and parameters. Model simulations result in directed graphs, called state transition graphs. We are particularly interested in reachability properties and asymptotic behaviors, which correspond to terminal strongly connected components (or "attractors") in the state transition graph. A well-known problem is the exponential increase {{of the size of}} state transition graphs with the number <b>of</b> network <b>components,</b> in particular when using the biologically realistic asynchronous updating assumption. To address this problem, we have developed several complementary methods enabling the analysis of the behavior of large and complex logical models: (i) the definition of transition priority classes to simplify the dynamics; (ii) a model reduction method preserving essential dynamical properties, (iii) a novel algorithm to compact state transition graphs and directly generate compressed representations, emphasizing relevant transient and asymptotic dynamical properties. The power <b>of</b> <b>an</b> approach combining these different methods is demonstrated by applying them to a recent multilevel logical model for the network controlling CD 4 + T helper cell response to antigen presentation and to a dozen cytokines. This model accounts for the differentiation of canonical Th 1 and Th 2 lymphocytes, as well as of inflammatory Th 17 and regulatory T cells, along with many hybrid subtypes. All these methods have been implemented into the software GINsim, which enables the definition, the analysis, and the simulation of logical regulatory graphs. EU FP 7 (APOSYS large scale project), EU EraSysBio+ program (project ModHeart), ANR (Project Grant ANR- 08 -SYSC- 003), Belgian Science Policy Office (IAP BioMaGNet) ...|$|R
40|$|Theorists {{including}} Michael Worthington (1998) and Jessica Helfand (1994) recognise in temporal media {{the capacity}} to add additional dimensions to typography. ???Type in motion??? is indeed <b>an</b> established field <b>of</b> typographic practice. In most cases, however, texts fail to acknowledge that temporal media allow type {{to do more than}} just ???move???. Contemporary examples feature typography that evolves, or exhibits behaviour, further blurring the boundary between image and type. At present, no method of analysis, or even terminology, exists to sufficiently identify and describe this kind of typography. Perhaps the most appropriate term, ???fluid??? typography, was identified by Eduardo Kac (1996) as typography that presents different identities over time. This aptly describes the typography that is currently encountered, for example, in MPC???s Channel 4 identity, in which the figure ??? 4 ??? is constructed from environmental objects. These objects are, for a time, pictorial (<b>a</b> part <b>of</b> the landscape), then their identity changes; they become abstract <b>components</b> <b>of</b> <b>a</b> letterform. Kac???s <b>term,</b> however, was never intended for such artefacts. It was formulated specifically for his holographic poetry, in which letterforms appear to change when the viewer changes his or her physical location relative to the hologram. Similar features can now be seen in contemporary, digital examples, such as the fluid, typographic works of artists such as Dan Waber and Komninos Zervos. Yet these examples go further than Kac???s own works. They present forms in flux that are, in a moment, text, and in another, image. This presentation will propose <b>a</b> definition <b>of</b> ???fluid??? typography that can incorporate this new form of temporal typography, and observe how theorists have, as yet, failed to acknowledge this unique hybrid of text and image. I will ask how typographic theory can be updated to allow for such type, propose new terminology to distinguish varying forms of temporal typography, and propose methodologies for the analysis of ???fluid??? typographic artefacts...|$|R
40|$|It {{would be}} easy to read a review like this and be {{overwhelmed}} by the “to do” lists, accounts of barriers to progress and lack of positive comment. However that is in the nature of being asked to provide recommendations for the future; such recommendations are bound to be focused around improvements. Nevertheless our abiding impression is that much has already been achieved by the Online Learning Project at CAFRE; a surprising amount given the resources available. There are <b>a</b> number <b>of</b> examples where teaching staff have produced innovative and effective elearning materials, CE 6 has been implemented and is running well and there is <b>an</b> enthusiastic core <b>of</b> staff who have the capability to take online learning forward. Obviously there are problems to be overcome, but there is a solid platform on which to build. In the medium term (the next three years) the greatest gain will be through consolidation and extension of what is already in place. The current system has plenty of spare capacity and the overall functionality of CE 6 has not yet been fully exploited. So the immediate message is to make the best use of what we already have. As is often the case making the best use of what is already in place is not <b>a</b> matter <b>of</b> technological appreciation but of designing learning and teaching activities to create technology enhanced learning environments which benefit all students and staff. This requires high quality staff development particularly in online learning pedagogy. Simply doing what we have always done but with a bit more technology is not going to result in major advances. But many of these developments are relatively straightforward ones and staff and students are already aware of them. Some simple things done well and consistently will repay effort greatly. However the most cost effective mechanism for promoting development of the online learning environment would be a ‘Champion’ at the senior management level. Someone who could provide encouragement and reassurance to the staff and who would ensure that minor obstacles do not cause a major block to progress. In the longer term e-learning must be seen as more than deployment of CE 6, and as involving the use <b>of</b> <b>a</b> wide range <b>of</b> interoperating applications, from email and the provision of course information at the most basic to video, simulations and collaborative learning environments at the most complex. <b>A</b> wide choice <b>of</b> elearning tools is needed to satisfy an increasingly diverse population of learners studying many different subjects at <b>an</b> increasing range <b>of</b> levels. Delivery to a more diverse population will throw the questions of how to exploit wireless networks and mobile computing into sharp relief. Indeed <b>a</b> strategic view <b>of</b> network development in general is perhaps the most vital <b>component</b> <b>of</b> <b>a</b> longer <b>term</b> e-learning strategy at CAFRE...|$|R
40|$|International audienceThe {{dynamical}} {{analysis of}} large biological regulatory networks requires {{the development of}} scalable methods for mathematical modeling. Following the approach initially introduced by R. Thomas, we formalize the interactions between the <b>components</b> <b>of</b> <b>a</b> network in <b>terms</b> <b>of</b> discrete variables, functions and parameters. Model simulations result in directed graphs, called state transition graphs. We are particularly interested in reachability properties and asymptotic behaviors, which correspond to terminal strongly connected components (or " attractors ") in the state transition graph. A well-known problem is the exponential increase {{of the size of}} state transition graphs with the number <b>of</b> network <b>components,</b> in particular when using the biologically realistic asynchronous updating assumption. To address this problem, we have developed several complementary methods enabling the analysis of the behavior of large and complex logical models: (i) the definition of transition priority classes to simplify the dynamics; (ii) a model reduction method preserving essential dynamical properties, (iii) a novel algorithm to compact state transition graphs and directly generate compressed representations, emphasizing relevant transient and asymptotic dynamical properties. The power <b>of</b> <b>an</b> approach combining these different methods is demonstrated by applying them to a recent multilevel logical model for the network controlling CD 4 + T helper cell response to antigen presentation and to a dozen cytokines. This model accounts for the differentiation of canonical Th 1 and Th 2 lymphocytes, as well as of inflammatory Th 17 and regulatory T cells, along with many hybrid subtypes. All these methods have been implemented into the software GINsim, which enables the definition, the analysis and the simulation of logical regulatory graphs. The dynamical analysis of comprehensive biological regulatory networks requires the development of scalable mathematical modeling methods. In this context, discrete (Boolean or multi-valued) logical modeling is increasingly used to handle and analyze large molecular networks 18. This article focuses on the presentation of several approaches to cope with the inherent exponential growth of the discrete state space as the size of the regulatory networks considered increases...|$|R
40|$|Urban {{development}} threatens {{local and}} global ecosystems. In the Puget Sound region, urbanization has dramatically altered stream ecosystems by changing their flow regimes and their physical attributes. This study of urbanization effects on streams had three objectives: 1) to assess physical stream conditions within and among four watersheds spanning <b>a</b> range <b>of</b> urbanization, 2) to use a geographic information system (GIS) to comprehensively characterize the urban landscape within these watersheds, and 3) to relate in-stream physical conditions to the landscape conditions of each watershed. To address the first objective, I used a rapid stream assessment technique to document the condition of several physical attributes along the mainstem channels of the four watersheds. The assessed streams had considerable heterogeneity in physical condition. In order to rate the overall physical condition, six attributes were used as <b>components</b> <b>of</b> <b>a</b> multi-metric index, <b>termed</b> the physical stream conditions index (PSCI). The PSCI helped quantify relationships between stream and landscape conditions. Landscape conditions of each watershed were measured using several GIS-derived landscape metrics (the second objective). The final objective was to consider how the location and distribution of urban land might affect the degree <b>of</b> impact to <b>a</b> stream’s physical attributes. Physical conditions (as measured by the PSCI) were best explained by three of the landscape metrics: the quantity of urban land {{in that part of}} the watershed draining to the sampled site, the quantity of urban land within 500 m upslope of the sampled site, and the proximity of the sampled site to the closest upstream road crossing. A stream’s physical condition improved downstream from degraded reaches when the stream flowed through portions of intact forested riparian buffers devoid of road crossings. In sum, the results of this study suggest that if urban development can be built such that riparian areas are untouched, functioning stream reaches may be better preserved. Further, similar studies using GIS-based landscape analysis may quickly target rehabilitation efforts to stream reaches that have realistic opportunities for improvement. University of Washington Valle Scholarship; National Science Foundation Graduate Fellowship progra...|$|R
40|$|The {{purpose of}} this paper, “Role of Nuclear Energy in Japan Post – Fukushima: Alternatives and their Impact onJapan’s GHG Emission Targets”, is to {{emphasize}} that Japan’s expected new energy policy must be in accordancewith its existing environmental targets with regards to GHG emissions. The main research question is how Japan cancontinue to meet its emissions targets {{in the aftermath of}} the Fukushima crisis, where public opinion—gaugedthrough newspaper articles—in Japan has now become outright anti-nuclear, and Japan has become compelled toadopt a new nuclear-free energy policy built around renewable energy. However, given the extremely low share ofrenewable energy in Japan’s existing energy mix, an extremely pro-nuclear government, an influential energy lobbyand <b>an</b> overall lack <b>of</b> suitable infrastructure; this goal does appear ambitious. The framework of analysis in thispaper will be of ‘sustainable development’, entailing <b>an</b> analysis <b>of</b> the three pillars of sustainability – environment,economy and social factors. In addition to these factors, security of supply will also be considered as a vital measureto determine the policy’s overall sustainability. The paper will show that while it is indeed possible for Japan tomeet its GHG emissions targets by replacing nuclear energy with renewable energy, Japan’s ability to deployrenewable energy at such a large scale remains inadequate. Through a comparison with the German experience inrenewable energy, any withdrawal from nuclear energy without properly propping up renewable energy will onlyresult in a greater shift towards primary fossil fuels – jeopardizing Japan’s emission targets, security of supply andincurring heavy import costs to its economy. The result of this analysis is to suggest measures such as an expansiveFeed-in tariff system, grid integration and stability and investment in R&D as major <b>components</b> <b>of</b> <b>a</b> focused andlong <b>term</b> energy policy up till 2030, to promote renewable energy. This paper will also posit steps required toimprove the safety and efficiency of its nuclear reactors during the interim period when renewable energy grows inits share of Japan’s energy mix...|$|R
40|$|The {{impact of}} {{filamentous}} fungi on human welfare {{has never been}} greater. Fungi are acknowledged as the most economically devastating plant pathogens (1) and are attaining increasing notoriety {{for their ability to}} cause life-threatening infections in humans (57, 71), and fungal products sustain a billion dollar manufacturing industry (70). The tools available to study filamentous fungi are more sophisticated than ever and include the complete annotated genome sequences of multiple filamentous fungi (12), resources being made available through various functional genomics projects, and advanced bioimaging methods, including high-resolution live-cell imaging (20, 32) and electron tomography (19, 50). The increasing impact of filamentous fungi, along with the rediscovery of pseudohyphal growth in yeast (22), has focused attention on the molecular mechanisms underlying hyphal morphogenesis. Attempts to understand hyphal morphogenesis have historically followed two different lines of investigation. Microscopists have defined, with increasing detail, the subcellular organization of the hyphal tip. This led to the description <b>of</b> the Spitzenkö̈rper, <b>an</b> apical cluster <b>of</b> vesicles, cytoskeletal elements, and other proteins, which plays a crucial role in hyphal extension (4). Geneticists have identified gene products required for hyphal morphogenesis by characterizing morphological mutants (51, 52). Initial studies in the laboratories of Beadle, Tatum, and colleagues attempted to link morphogenesis to specific biochemical pathways. More recent screens have identified <b>a</b> multitude <b>of</b> signaling and cytoskeletal functions required for hyphal extension (62, 72). In the past few years, comparative genomics efforts have allowed fungal biologists interested in hyphal morphogenesis to exploit the wealth of knowledge about polarized growth in the yeast Saccharomyces cerevisiae. Many informative homologies between filamentous fungi and yeast have been uncovered. Notably, this includes several <b>components</b> <b>of</b> <b>a</b> multiprotein complex <b>termed</b> the polarisome (28), which regulates microfilament formation at polarized growth sites in yeast (61). Perhaps more importantly, several gene products involved in hyphal morphogenesis have been shown to have no homologue outside of the filamentous fungi. This emphasizes the potential novelty of the mechanisms underlying hyphal morphogenesis. In this review, we summarize past efforts to understand hyphal morphogenesis and pose <b>a</b> series <b>of</b> questions designed to focus future efforts in this area...|$|R
40|$|The highly conserved Dis 1 /XMAP 215 {{family of}} microtubule-associated {{proteins}} (MAPs) {{play a central}} role in cytoplasmic microtubule organisation and mitotic spindle formation. The fission yeast S. pombe has two family members, Alp 14 and Dis 1. Both localise to interphase microtubules, spindle pole bodies (the yeast equivalent of the centrosome), and kinetochores. Here we present the characterisation of Alp 14 and Dis 1 during interphase. We find that Alp 14 localisation resembles that <b>of</b> Mal 3, <b>a</b> canonical plus end tracking protein. Deletion results in a decrease in the number and length of interphase microtubule bundles at low temperatures. Alp 14 is temperature sensitive. At the restrictive temperature we find that an interphasic intranuclear microtubule bundle forms, nucleated from the region of the spindle pole bodies and kinetochores. This intranuclear bundle has a structure and displays dynamics similar to that <b>of</b> <b>a</b> normal interphase bundle and is able to move the nucleus. Dis 1 localises to interphase microtubules but does not show plus end tracking behaviour. Deletion has no apparent effect on the organisation of interphase microtubules, but Dis 1 is cold sensitive and at the restrictive temperature the cells become blocked in mitosis with aster-like spindles. Deletion of both alp 14 and dis 1 is lethal. We investigate the functional redundancy between Alp 14 and Dis 1 during interphase. Over-expression of Dis 1 in alp 14 deletion cells can partially rescue the mutant microtubule phenotype. Conversely, attenuated expression of Dis 1 in an alp 14 deletion background results in almost complete loss of interphase microtubules. We conclude that the presence of at least one of the Dis 1 /XMAP 215 homologues is essential for the maintenance of interphase microtubule arrays. Similar to Alp 14, Tip 1 is a microtubule plus-end tracking protein, homologous to human CLIP 170. Together with the EB 1 homologue, Mal 3, Tip 1 spatially regulates microtubule dynamics, ensuring that the cylindrical cell shape of S. pombe is maintained. In the second part of this thesis the characterisation of the protein SPCC 736. 15 (Toi 4), identified in a screen for Tip 1 -interacting proteins is presented. During interphase, Toi 4 p-GFP localises to the central regions of the cell cortex. Shortly before mitosis, Toi 4 p-GFP begins to accumulate at the cell ends. Concurrent with the onset of mitosis, there is exclusion of Toi 4 p-GFP from the region of the cell cortex where the actomyosin ring forms and the cell subsequently divides. The S. cerevisiae homologue of Toi 4 p is Pil 1 p, which is proposed to be the major <b>component</b> <b>of</b> <b>an</b> endocytic organelle <b>termed</b> the eisosome. We tested for such a role for Toi 4 in S. pombe, however we detect no link between Toi 4 and endocytosis, suggesting that the homologues, although they have a similar localisation pattern, may perform different functions...|$|R
40|$|Breast {{cancer in}} one of the most common cancer worldwide. Among women this tumor {{accounts}} for over 25 % of cancer diagnosis and 15 % of cancer related deaths. 5 - 10 % of breast cancer cases are hereditary, with a germline mutation in a known cancer susceptibility gene. Inherited susceptibility to developing breast and ovarian cancer most commonly results from mutation in BRCA 1 and BRCA 2 genes which are inherited in an autosomal dominant way. BRCA 1 is a tumor suppressor gene which encodes for a nuclear protein involved in <b>a</b> wide array <b>of</b> cellular functions, including cell cycle regulation, DNA damage response, maintenance of the genomic stability, transcription regulation, replication, recombination and higher chromatin hierarchical control. BRCA 1 is <b>a</b> <b>component</b> <b>of</b> <b>a</b> protein complex <b>termed</b> BASC (BRCA 1 -Associated Genome Surveillance Complex) and, therefore it has been associated with <b>a</b> variety <b>of</b> proteins implicated in DNA damage response and repair mechanism, such as MLH 1, MSH 2, MSH 6, BLM and the MRN complex constituted by RAD 50, MRE 11 A and NBS 1. Many proteins of this complex can bind damaged DNA structures and act as sensors of DNA damage. The aim of this study is to determine if some of the DNA repair partners of BRCA 1 may contribute to breast and ovarian cancer development and progression. Preliminary results obtained by our research group through functional assays in S. cerevisiae suggested that MSH 2, MSH 6, MRE 11 A, RAD 50 and RAD 51 genes might have a role in genomic instability induced by BRCA 1 in yeast. Moreover a mutational screening revealed a surprisingly high frequency of MSH 2 somatic mutations in breast and ovarian tumors from carriers of BRCA 1 VUS (variants of unknown significance). On the basis of these preliminary results the first task of this project is to perform a mutational analysis by next generation sequencing of MSH 6, MRE 11 A, RAD 50 and RAD 51 genes in selected breast and/or ovarian tumors from BRCA 1 VUS carriers, BRCA 1 mutation carriers and BRCA 1 wt individuals. This mutational screening identified 8 rare somatic variants pathogenic or predicted pathogenic distributed on 7 patients. 4 / 8 variants were located on MSH 6 gene, 2 / 8 on RAD 51, 1 / 8 on RAD 50 and 1 / 8 on MRE 11 A. In the second part of this study it was performed a GFP dependent homology directed repair assay whereby a recombination substrate is integrated into the genome. This functional assay was carried out in HeLa and MCF 7 cell lines transfected with BRCA 1 wild type and four BRCA 1 VUS (p. Y 179 C, p. N 550 H, p. M 1775 R and p. A 1789 T). The results of this assay showed an increase in homologous recombination frequency associated to the pathogenic variants p. M 1775 R and p. A 1789 T in both cell lines. Finally, the CRISPR-Cas 9 system was used in order to obtain HeLa and MCF 7 cell lines knockout for MSH 2, but so far it was possible to isolate only HeLa MSH 2 knockout clones. The MSH 2 knockout clones will be tested with the homology directed repair assay to investigate the combined effect of MSH 2 deficiency and BRCA 1 VUS on homologous recombination. On the basis of these results it is possible to conclude that the mismatch repair system seems to be frequently impaired in breast and ovarian tumors. Moreover the homologous recombination assay could be another powerful tool to help in the classification of BRCA 1 VUS...|$|R
