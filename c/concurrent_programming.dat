1370|2871|Public
5|$|A <b>concurrent</b> <b>programming</b> {{language}} called Alef {{was available}} {{in the first two}} editions, but was then dropped for maintenance reasons and replaced by a threading library for C.|$|E
5|$|<b>Concurrent</b> <b>programming</b> languages, libraries, APIs, and {{parallel}} programming models (such as algorithmic skeletons) {{have been created}} for programming parallel computers. These can generally be divided into classes based on the assumptions they make about the underlying memory architecture—shared memory, distributed memory, or shared distributed memory. Shared memory programming languages communicate by manipulating shared memory variables. Distributed memory uses message passing. POSIX Threads and OpenMP {{are two of the}} most widely used shared memory APIs, whereas Message Passing Interface (MPI) is the most widely used message-passing system API. One concept used in programming parallel programs is the future concept, where one part of a program promises to deliver a required datum to another part of a program at some future time.|$|E
25|$|Concurrent logic {{programming}} integrates concepts of {{logic programming}} with <b>concurrent</b> <b>programming.</b> Its development {{was given a}} big impetus in the 1980s by its choice for the systems programming language of the Japanese Fifth Generation Project (FGCS).|$|E
40|$|Abstract. We {{show that}} any <b>concurrent</b> <b>program</b> that is {{amenable}} to compositional reasoning can be effectively translated to a sequential program. More precisely, we give a reduction from the verification problem for <b>concurrent</b> <b>programs</b> against safety specifications to the verification of sequential programs against safety specifications, where the reduction is parameterized {{by a set}} of auxiliary variables A, such that the <b>concurrent</b> <b>program</b> compositionally satisfies its specification using auxiliary variables A iff the sequentialization satisfies its specification. Existing sequentializations for <b>concurrent</b> <b>programs</b> work only for underapproximations like bounded context-switching, while our sequentialization has the salient feature that it can prove <b>concurrent</b> <b>programs</b> entirely correct, as long as it has a compositional proof. The sequentialization allows us to use sequential verification tools (including deductive verification tools and predicate abstraction tools) to analyze and prove <b>concurrent</b> <b>programs</b> correct. We also report on our experience in the deductive verification of <b>concurrent</b> <b>programs</b> by proving their sequential counterparts using the program verifier Boogie...|$|R
40|$|This paper {{extends the}} notion of slicing, which was {{originally}} proposed and studied for sequential <b>programs,</b> to <b>concurrent</b> <b>programs</b> and presents a graph-theoretical approach to slicing <b>concurrent</b> <b>programs.</b> In addition to the usual control and data dependences proposed and studied for sequential programs, the paper introduces three new types of primary <b>program</b> dependences in <b>concurrent</b> <b>programs,</b> named the selection dependence, synchronization dependence, and communication dependence. The paper also propose a new <b>program</b> representation for <b>concurrent</b> <b>programs,</b> named the Process Dependence Net (PDN), which is an arc-classified digraph to explicitly represent the five types of primary program dependences in the programs. As a result, various notions about slicing <b>concurrent</b> <b>programs</b> can be formally defined based on the representation, {{and the problem of}} slicing a <b>concurrent</b> <b>program</b> can be simply reduced to a vertex reachability problem in its PDN representation. 1. Introd [...] ...|$|R
40|$|In {{this paper}} we propose a scheme for {{reachability}} testing to achieve statement cov-erage in the dynamic testing of <b>concurrent</b> <b>programs.</b> Previous studies on reachability testing have only enumerated the feasible interleavings of a <b>concurrent</b> <b>program</b> for a given input. The proposed scheme derives inputs from SYN-sequences obtained in reachability testing and uses these inputs to perform reachability testing multiple times in order to achieve statement-coverage testing for a <b>concurrent</b> <b>program.</b> We prove formally that the proposed method can achieve statement-coverage testing if all the path condi-tions derived from SYN-sequences can be solved and the <b>concurrent</b> <b>program</b> contains no dead code...|$|R
25|$|In 1968 Dijkstra {{published}} his seminal paper 'Cooperating sequential processes', a 70-page essay that originated {{the field of}} <b>concurrent</b> <b>programming.</b> He discussed in it the notion of mutual exclusion (mutex) and the criteria a satisfactory solution should satisfy. He also redressed the historical perspective left out of his 1965 paper by including the first known correct solution to the mutual exclusion problem, for two processes, due to Theodorus Dekker. Dijkstra subsequently generalized Dekker's solution to n processes. Further, he proposed the first synchronisation mechanism for concurrent processes, the semaphore with its two operations, P and V. He also identified the 'deadlock problem' (called there 'the problem of the deadly embrace') and proposed an elegant 'Banker's algorithm' that prevents deadlock. The deadlock detection and prevention became perennial research problems {{in the field of}} <b>concurrent</b> <b>programming.</b>|$|E
25|$|While threads require {{external}} library {{support in}} most languages, Erlang provides language-level features for creating and managing processes {{with the aim}} of simplifying <b>concurrent</b> <b>programming.</b> Though all concurrency is explicit in Erlang, processes communicate using message passing instead of shared variables, which removes the need for explicit locks (a locking scheme is still used internally by the VM).|$|E
25|$|Danes {{have made}} {{significant}} contributions to the field of computer science. Some notable figures include: Per Brinch Hansen, known for <b>concurrent</b> <b>programming</b> theory; Bjarne Stroustrup, who invented the C++ programming language; Janus Friis, the co-inventor of Skype; Jens and Lars Rasmussen, the co-founders of Google Maps; and Peter Naur, a contributor to ALGOL 60 and a recipient of the Turing Award.|$|E
40|$|Program slicing is a {{technique}} to identify statements that may influence the computations at other statements. Precise slicing {{has been shown to}} be undecidable for <b>concurrent</b> <b>programs.</b> This work presents the first context-sensitive approach to slice <b>concurrent</b> <b>programs</b> accurately. It extends the well known structures of the control flow graph and the (interprocedural) program dependence graph for <b>concurrent</b> <b>programs</b> with interference. This new technique does not require serialization or inlining...|$|R
40|$|Partial-order {{reduction}} methods form {{a collection}} of state exploration techniques set to relieve the stateexplosion problem in <b>concurrent</b> <b>program</b> verification. One such method is implemented in the verification tool SPIN. Its use often reduces significantly the memory and time needed for verifying local and termination properties of <b>concurrent</b> <b>programs</b> and, moreover, for verifying that <b>concurrent</b> <b>programs</b> satisfy their linear temporal logic specifications (i. e. for LTL model-checking). This paper builds on SPIN's partial-order reduction method to yield an approach which enables further reductions {{in space and time}} for verifying <b>concurrent</b> <b>programs.</b> Keywords Concurrency, program correctness, model-checking, partial-order reduction, temporal logic 1 Introduction Partial-order reduction methods [2 - 4, 7, 10, 19, 20, 24 - 26] form {{a collection of}} state exploration techniques set to relieve the state-explosion problem in <b>concurrent</b> <b>program</b> verification. The main observation underlyin [...] ...|$|R
40|$|Abstract Read-write locking is an {{important}} mecha-nism to improve concurrent granularity, {{but it is difficult}} to reason about the safety of <b>concurrent</b> <b>programs</b> with read-write locks. Concurrent Separation Logic(CSL) provides a simple but powerful technique for locally rea-soning about <b>concurrent</b> <b>programs</b> with mutual exclusive locks. Unfortunately, CSL cannot be directly applied to reason about <b>concurrent</b> <b>programs</b> with read-write locks due to the different concurrent control mechanisms. This paper focuses on extending CSL and present a proof-carrying code(PCC) system for reasoning about <b>concurrent</b> <b>programs</b> with read-write locks. We extend the heap model with a writing permission set, denoted as logical heap, then define "strong separation " and "weak separation " over logical heap. Following CSL’s local-reasoning idea, we develop a novel program logic to enforces weak separations of heap between different threads and support verification of <b>concurrent</b> <b>programs</b> with read-write locks...|$|R
25|$|In a one-page {{paper from}} 1965 Dijkstra {{introduced}} the 'mutual exclusion problem' for n processes and discussed {{a solution to}} it. It was probably the first published concurrent algorithm. The notion, standard by now, of a 'critical section' was also introduced in this paper. Per Brinch Hansen, {{a pioneer in the}} field of concurrent computing, considers Dijkstra's Cooperating Sequential Processes (1965) to be the first classic paper in <b>concurrent</b> <b>programming.</b> As Brinch Hansen notes, 'Dijkstra lays the conceptual foundation for abstract concurrent programming' with that paper.|$|E
2500|$|O'Haskell, an {{extension}} of Haskell adding object-orientation and <b>concurrent</b> <b>programming</b> support that [...] "has ... been superseded by Timber." ...|$|E
2500|$|Dijkstra, Edsger W. (1965). [...] "Solution of a Problem in <b>Concurrent</b> <b>Programming</b> Control". Communications of the ACM 8 (9): 569.|$|E
40|$|Abstract We {{present a}} {{framework}} for the specification and verification of reactive <b>concurrent</b> <b>programs</b> using general-purpose mechanical theorem proving. We define specifications for <b>concurrent</b> <b>programs</b> by formalizing a notion of refinements analogous to stuttering trace containment. The formalization supports the definition of intuitive specifications of the intended behavior of a program. We present a collection of proof rules that can be effectively orchestrated by a theorem prover to reason about complex programs using refinements. The proof rules systematically reduce the correctness proof for a <b>concurrent</b> <b>program</b> to the definition and proof of an invariant. We include automated support for discharging this invariant proof with a predicate abstraction tool that leverages the existing theorems proven about {{the components of the}} <b>concurrent</b> <b>programs.</b> The framework is integrated with the ACL 2 theorem prover and we demonstrate its use in the verification of several <b>concurrent</b> <b>programs</b> in ACL 2...|$|R
40|$|Abstract. A logic for {{reasoning}} about timing {{properties of}} <b>concurrent</b> <b>programs</b> is presented. The logicisbased on proof outlinesand can handlemaximal parallelismas well as resourceconstrainedexecutionenvironments. The correctnessproofforamutualexclusionprotocolthatuses executiontimingsinasubtleway illustrates thelogicinaction. Key words: <b>concurrent</b> <b>program</b> verification, timing properties, safety properties, real-tim...|$|R
40|$|We {{present a}} {{pairwise}} normal form for finite-state shared memory concurrent programs: all variables are shared between exactly two processes, and the guards on transitions are conjunctions of conditions over this pairwise shared state. This representation {{has been used}} to efficiently (in polynomial time) synthesize and model-check correctness properties of <b>concurrent</b> <b>programs.</b> Our main result is that any finite state <b>concurrent</b> <b>program</b> can be transformed into pairwise normal form. Specifically, if Q is an arbitrary finite-state shared memory <b>concurrent</b> <b>program,</b> then there exists a finite-state shared memory <b>concurrent</b> <b>program</b> P expressed in pairwise normal form such that P is strongly bisimilar to Q. Our result is constructive: we give an algorithm for producing P, given Q. ...|$|R
2500|$|Dijkstra {{was one of}} {{the very}} early pioneers of the {{research}} on principles of distributed computing. As the citation for the Dijkstra Prize recognizes, [...] "no other individual has had a larger influence on research in principles of distributed computing." [...] Some of his papers are even considered to be those that established the field. Dijkstra's 1965 paper, Solution of a Problem in <b>Concurrent</b> <b>Programming</b> Control was the first to present the correct solution to the mutual exclusion problem. Leslie Lamport writes that this work [...] "is probably why PODC exists" [...] and it [...] "started the field of concurrent and distributed algorithms".|$|E
2500|$|The {{version of}} CSP {{presented}} in Hoare's original 1978 paper {{was essentially a}} <b>concurrent</b> <b>programming</b> language rather than a process calculus. It had a substantially different syntax than later versions of CSP, did not possess mathematically defined semantics, {{and was unable to}} represent unbounded nondeterminism. Programs in the original CSP were written as a parallel composition of a fixed number of sequential processes communicating with each other strictly through synchronous message-passing. In contrast to later versions of CSP, each process was assigned an explicit name, and the source or destination of a message was defined by specifying the name of the intended sending or receiving process. For example, the process ...|$|E
2500|$|Dijkstra's {{algorithmic}} work (especially graph algorithms, concurrent algorithms, {{and distributed}} algorithms) {{plays an important}} role in many areas of computing science. According to Leslie Lamport (2002), Dijkstra [...] "started the field of concurrent and distributed algorithms with his 1965 CACM paper [...] "Solution of a Problem in <b>Concurrent</b> <b>Programming</b> Control", in which he first stated and solved the mutual exclusion problem." [...] As Lamport explains, [...] "that paper is probably why PODC exists (...). It remains to this day the most influential paper in the field. That it did not win a PODC Influential Paper Award reflects an artificial separation between concurrent and distributed algorithms–a separation that has never existed in Dijkstra's work." ...|$|E
40|$|Multicore {{hardware}} {{is making}} <b>concurrent</b> <b>programs</b> pervasive. Unfortunately, <b>concurrent</b> <b>programs</b> {{are prone to}} bugs. Among different types of concurrency bugs, atomicity violation bugs are common and important. Existing techniques to detect atomicity violation bugs suffer from one limitation: requiring bugs to manifest during monitored runs, which is an open problem in <b>concurrent</b> <b>program</b> testing. This paper makes two contributions. First, it studies the interleaving characteristics of the common practice in <b>concurrent</b> <b>program</b> testing (i. e., running a program over and over) to understand why atomicity violation bugs are hard to expose. Second, it proposes CTrigger to effectively and efficiently expose atomicity violation bugs in large programs. CTrigger focuses on a special type of interleavings (i. e., unserializabl...|$|R
40|$|Synthesis of Fault-Tolerant <b>Concurrent</b> <b>Programs</b> Methods for {{mechanically}} synthesizing <b>concurrent</b> <b>programs</b> from {{temporal logic}} speci cations obviate {{the need to}} manually construct a program and compose a proof of its correctness [EC 82, MW 84, PR 89, PR 89 b, AM 94]. A serious drawback of extant synthesis methods, however, is that they produce <b>concurrent</b> <b>programs</b> for models of computation that are often unrealistic. In particular, these methods assume completely fault-free operation, i. e., the programs they produce are fault-intolerant. In this paper, we show how to mechanically synthesize fault-tolerant <b>concurrent</b> <b>programs</b> for various fault classes. We illustrate our method by synthesizing fault-tolerant solutions to the mutual exclusion and barrier synchronization problems. ...|$|R
40|$|Writing and {{debugging}} <b>concurrent</b> (shared-variable) <b>programs</b> {{is notoriously}} difficult. This motivated {{the development of}} numerous static analysis and run-time analysis techniques designed to (help) ensure that <b>concurrent</b> <b>programs</b> satisfy common correctness requirements for <b>concurrent</b> <b>programs,</b> such as absence of race conditions and absence of deadlocks. This paper focuses on another common correctness requirement for <b>concurrent</b> <b>programs,</b> namely, atomicity, which requires that any set of concurrent invocations of designated procedures is equivalent to performing those invocations serially in some order. Run-time analysis algorithms for detecting violations of atomicity are presented. The algorithms vary in cost and precision...|$|R
5000|$|... #Subtitle level 2: Languages {{supporting}} <b>concurrent</b> <b>programming</b> ...|$|E
5000|$|Shared-nothing <b>concurrent</b> <b>programming</b> via {{message passing}} (Actor model) ...|$|E
50|$|A protothread is a low-overhead {{mechanism}} for <b>concurrent</b> <b>programming.</b>|$|E
40|$|The {{design of}} <b>concurrent</b> <b>programs</b> is {{error-prone}} {{due to the}} interaction between concurrently executing threads. Traditional automated techniques for finding errors in <b>concurrent</b> <b>programs,</b> such as model checking, explore all possible thread interleavings. Since the number of thread interleavings increases exponentially {{with the number of}} threads, such analyses have high computational complexity. In this paper, we present a novel analysis technique for <b>concurrent</b> <b>programs</b> that avoids this exponential complexity. Our analysis transforms a <b>concurrent</b> <b>program</b> into a sequential program that simulates the execution of a large subset of the behaviors of the <b>concurrent</b> <b>program.</b> The sequential program is then analyzed by a tool that only needs to understand the semantics of sequential execution. Our technique never reports false errors but may miss errors. We have implemented the technique in KIS, an automated checker for multithreaded C programs, and obtained promising initial results by using KIS to detect race conditions in Windows device drivers. 1...|$|R
40|$|Abstract — We {{present a}} {{framework}} for the specification and verification of reactive <b>concurrent</b> <b>programs</b> using generalpurpose mechanical theorem proving. We define specifications for <b>concurrent</b> <b>programs</b> by formalizing a notion of refinements analogous to stuttering trace containment. The formalization supports the definition of intuitive specifications of the intended behavior of a program. We present a collection of proof rules that can be effectively orchestrated by a theorem prover to reason about complex programs using refinements. The framework is integrated with the ACL 2 theorem prover and we demonstrate its use in the verification of several <b>concurrent</b> <b>programs</b> in ACL 2. I. OVERVIEW Reactive <b>concurrent</b> <b>programs</b> consist of interacting processes which perform ongoing, non-terminating computations while receiving stimulus from an external environment. Th...|$|R
40|$|We give a {{translation}} from <b>concurrent</b> <b>programs</b> to sequential programs {{that reduces the}} context-bounded reachability problem in the <b>concurrent</b> <b>program</b> to a reachability problem in the sequential one. The translation has two salient features: (a) the sequential program tracks, at any time, the local state of only one thread (though it does track multiple copies of shared variables), and (b) all reachable states of the sequential program correspond to reachable states of the <b>concurrent</b> <b>program.</b> We also implement our transformation {{in the setting of}} <b>concurrent</b> recursive <b>programs</b> with finite data domains, and show that the resulting sequential program can be model-checked efficiently using existing recursive sequential program reachability tools...|$|R
5000|$|Shared nothing <b>concurrent</b> <b>programming</b> via {{message passing}} (Actor model) ...|$|E
5000|$|... #Subtitle level 4: Example: <b>Concurrent</b> <b>programming</b> and Transactional memory ...|$|E
50|$|Multithreaded, Parallel, and Distributed {{programming}} (MPD) is a <b>concurrent</b> <b>programming</b> language whose syntax {{is derived}} from the one used in the book Foundations of Multithreaded, Parallel, and Distributed Programming The name thus lists the distinguishing features of the language, namely that it supports all three of these <b>concurrent</b> <b>programming</b> techniques.|$|E
40|$|AbstractMost of {{the models}} used to {{describe}} the behaviours of <b>concurrent</b> <b>programs</b> and to prove some of their properties assume the atomicity of actions at some level. When atomicity is ensured only at a low level, the need {{to increase the number of}} basic operations leads to a high complexity for the representations. If each execution of a <b>concurrent</b> <b>program</b> is serializable, some sets of basic actions may be considered atomic and this can reduce the complexity. In this paper, we give an algorithm for the detection of global serializability of a <b>concurrent</b> <b>program...</b>|$|R
40|$|Concurrency bugs are {{becoming}} increasingly important due to the prevalence of <b>concurrent</b> <b>programs.</b> A fundamental problem of <b>concurrent</b> <b>program</b> bug detection and testing is that the interleaving space is too large to be thoroughly explored. Practical yet effective interleaving coverage criteria are desired to systematically explore the interleaving space and effectively expose concurrency bugs. This paper proposes a <b>concurrent</b> <b>program</b> interleaving coverage criteria hierarchy, including seven (including five new) coverage criteria. These criteria are all designed based on different concurrency fault models. Their cost ranges from exponential to linear...|$|R
40|$|This paper {{presents}} {{adaptations of}} the Hoare triple for reasoning about <b>concurrent</b> <b>programs.</b> The {{rules for the}} Hoare triple, familiar to programmers from their experience with sequential programming, {{can be applied to}} develop proofs of <b>concurrent</b> <b>programs</b> as well. The basis for the adaptations of the Hoare triple is temporal logic...|$|R
