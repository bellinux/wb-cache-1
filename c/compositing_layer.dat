0|23|Public
50|$|Kinetic {{typography}} {{is often}} produced using standard animation programs, including Adobe Flash, Adobe After Effects, and Apple Motion. The effect {{is most often}} achieved by <b>compositing</b> <b>layers</b> of text such that either individual letters or words can be animated separately from the rest.|$|R
5000|$|The super-giant Midway-Sunset {{field has}} {{produced}} approximately [...] of crude oil, {{most of it}} heavy gravity (13-14 degrees [...] API). Enhanced oil recovery operations {{in the form of}} steam production and injection have been used on the thick viscous crude oil of the Midway-Sunset field since the mid-to-late-1960s. The reservoirs of the Midway-Sunset field are <b>composited</b> <b>layers</b> of mostly unconsolidated sandstones of late Miocene age, shallowly buried. The shallow burial depth and ideal nature of the sandstones make them almost perfectly suited for steam injection. As a result, the amount of oil that can be recovered has greatly increased.|$|R
40|$|A novel {{composite}} photoalignment layer for ferroelectric {{liquid crystal}} (FLC) displays is explored. The key technique is to introduce a functional liquid crystal polymer into azo-dye material with proper mixing. Bearing good alignment quality derived from the azo-dye, the composite layer provides strong anchoring energy {{comparable to that of}} rubbed polyimide layers. Furthermore, by using a two-step exposure process, the composite layer shows much better stability than that with a pure azo-dye material. The photostability has been evaluated by the exposure energy needed to rearrange the orientation of SD 1 molecules. The photostability is improved by more than 20 times using <b>composited</b> <b>layer</b> compared with pure SD 1 material...|$|R
40|$|Felt is mankind’s {{oldest and}} {{simplest}} textile, {{composed of a}} pressed mass of fibers. Images can be formed directly in the fabric by arranging the fibers to represent the image before pressure is applied. We describe a computational method for transforming input images into objects which {{look as if they}} were produced by a felting process. The synthesis method places three dimensional line segments one by one, analogous to individual fibers being placed. Individual layers of fibers are drawn according to image structure and a probabilistic framework. A fuzzy three dimensional felt object is created by <b>compositing</b> <b>layers</b> of fibers; rendering uses a deep shadow map for correct self-shadowing of the matted felt...|$|R
5000|$|Layer-based {{compositing}} represents each {{media object}} in a composite {{as a separate}} layer within a timeline, {{each with its own}} time bounds, effects, and keyframes. All the layers are stacked, one above the next, in any desired order; and the bottom layer is usually rendered as a base in the resultant image, with each higher layer being progressively rendered on top of the previously <b>composited</b> of <b>layers,</b> moving upward until all layers have been rendered into the final composite. Layer-based compositing is very well suited for rapid 2D and limited 3D effects such as in motion graphics, but becomes awkward for more complex composites entailing a large number of layers. A partial solution to this is some programs' ability to view the composite-order of elements (such as images, effects, or other attributes) with a visual diagram called a flowchart to nest compositions, or [...] "comps," [...] directly into other compositions, thereby adding complexity to the render-order by first <b>compositing</b> <b>layers</b> in the beginning composition, then combining that resultant image with the layered images from the proceeding composition, and so on. An example of this exists in the Adobe program After Effects.|$|R
5000|$|Chroma key compositing, or chroma keying, is {{a visual}} effects / {{post-production}} technique for <b>compositing</b> (<b>layering)</b> two images or video streams together based on color hues (chroma range). The technique {{has been used}} heavily in many fields to remove a [...] from {{the subject of a}} photo or video - particularly the newscasting, motion picture and videogame industries. A color range in the foreground footage is made transparent, allowing separately filmed background footage or a static image to be inserted into the scene. The chroma keying technique is commonly used in video production and post-production. This technique is also referred to as color keying, colour-separation overlay (CSO; primarily by the BBC), or by various terms for specific color-related variants such as green screen, and blue screen - chroma keying can be done with backgrounds of any color that are uniform and distinct, but green and blue backgrounds are more commonly used because they differ most distinctly in hue from most human skin colors. No part of the subject being filmed or photographed may duplicate the color used as the backing.|$|R
50|$|The music video, shot in HD, was {{directed}} by Zbigniew Rybczyński. Set {{against a backdrop of}} Times Square and various neon signs, the video features a high level of video <b>compositing,</b> with multiple <b>layers</b> of the band members and dancers appearing on screen at once.|$|R
30|$|We {{collected}} {{forest floor}} and soil samples for seed bank analysis in September 1987, approximately {{four years after}} the burns were completed. We stratified sampling according to burn depth: six samples were deep (October burn), seven samples were intermediate (July burn), and six samples were from unburned patches inside the July and October burn units. Each sample consisted of three subsamples randomly selected from areas within 5 m of the sampling point and <b>composited</b> by <b>layer.</b> Even though samples were collected in multiple burn units, the level of replication was insufficient for the treatment to be considered replicated.|$|R
50|$|In {{the fourth}} quarter of 2008, two {{separate}} branches of Compiz were created: compiz++ and NOMAD; compiz++ was geared toward the separation of <b>compositing</b> and OpenGL <b>layers</b> for the rendering of the window manager without compositing effects, and the port from C to C++ programming language. NOMAD was geared towards the improvement of remote desktop performance for Compiz installations.|$|R
50|$|Inherited from Final Cut Pro, Final Cut Express {{features}} RT Extreme, {{which allows}} previews of some video filters and transitions without rendering. Audio {{that is not}} in the native AIFF file format needs rendering before it can be played back. RT Extreme has three modes: 'Safe', for seeing multiple video layers at a quality that more or less guarantees a smooth playback; 'Unlimited', which allows the maximum number of <b>composited</b> video <b>layers</b> to be viewed at the same time; and 'Dynamic', which alternates between these settings depending on how many simultaneous video tracks are present. Frame dropping may result from using 'Unlimited' on low-resource machines.|$|R
40|$|International audienceGIS {{software}} applications and other mapping tools enable users to correlate data from multiple layers and gain insight from the resulting visualizations. However, {{most of these}} applications only feature basic, monolithic <b>layer</b> <b>compositing</b> techniques. These techniques do not always support users effectively in their tasks, as we observed during interviews with GIS experts. We introduce MapMosaic, a novel approach based on dynamic visual compositing that enables users to interactively create and manipulate local composites of multiple vector and raster map layers, {{taking into account the}} semantics and attribute values of objects and fields in the composit-ing process. We evaluate MapMosaic's interaction model against that of QGIS (a widely-used desktop GIS) and MAPublisher (a professional cartography tool) using the " Cognitive Dimensions " framework and through an analytical comparison, showing that MapMosaic's model is more flexible and can support users more effectively in their tasks. We also report on feedback obtained from experts, which further confirms the potential of this highly dynamic approach to map <b>layer</b> <b>compositing...</b>|$|R
50|$|With {{the advance}} of digital <b>compositing,</b> the {{discrete}} <b>layers</b> could be edited in groups, and lighting effects {{could be applied to}} the entire frame, or to each layer selectively. This greatly helped the production of Hayao Miyazaki's Princess Mononoke by creating a depth of field previously unseen in an animated feature. In Blood: The Last Vampire, this also contributed into having a deep, and hitherto unseen active background supporting the foreground characters.|$|R
40|$|Amorphous carbon (a-C) films <b>composited</b> with {{transition}} <b>layers</b> {{exhibit the}} desirable improvement of adhesion strength between films and substrate, but the further understanding on the interfacial structure transformation of a-C structure induced by transition layers is still lacked. In this paper, using ab initio calculations, we comparatively studied the interfacial structure between Ti, Cr, or W transition layers and a-C film from the atomic scale, and {{demonstrated that the}} addition of Ti, Cr, or W catalyzed the graphitic transformation of a-C structure at different levels, which provided the theoretical guidance for designing a multilayer nanocomposite film for renewed application...|$|R
50|$|When Talisman {{was first}} made widely public at the 1996 SIGGRAPH meeting, they promised a {{dramatic}} {{reduction in the}} cost of implementing a graphics subsystem. They planned on working with vendors to sell the concept of Talisman for inclusion into other companies' display systems. That is, Talisman was hoped {{to be a part of}} a larger media chip, as opposed to an entire 3D system that would stand alone in a system. Their basic system would support 20-30,000 polygons on a 1024 x 768 display at 32 bit/pixel, with a 40 Mpixel/s polygon rendering rate and 320 Mpixel/s image <b>layer</b> <b>compositing</b> rate.|$|R
500|$|Visual effects {{supervisor}} Jay Worth found {{inspiration for}} the ash storyline from holding his grandmother-in-law's hands while at her funeral. He noted during production, [...] "The Ash Man definitely had {{its own set of}} challenges, because we wanted to utilize a lot of real elements, and because we didn't have the time to do all the simulation and particle work needed to make it look real. The thing that sold The Ash Man more than anything was the aftermath shot: This half-disintegrated body with a pile of ash for the head on the ground. It ended up being a <b>layering,</b> <b>compositing,</b> tweaking challenge beyond belief. I got to shoot the elements myself and had more control over them." ...|$|R
50|$|After its {{acquisition}} by Avid, DS {{was always}} positioned {{as a high}} end video finishing tool. However, many users {{found it to be}} uniquely soup-to-nuts in its capabilities. From version 1.0 of the product, it competed with products like Autodesk Smoke, Quantel and Avid Symphony. The toolset in DS offered video timeline editing, an object-oriented vector-based paint tool, 2D <b>layer</b> <b>compositing,</b> sample based audio and starting with version 3.01 of the product, a 3D environment. Originally, a subset of the SoftimageXSI 3D software was planned {{to become part of the}} DS toolset, both were built on the same software foundation, but over time the code bases divided between the applications and the integration never happened.|$|R
40|$|In this paper, {{we present}} a {{watercolor}} inspired method for the rendering of surfaces. Our approach mimics the watercolor process by building up an illuminated scene through the <b>compositing</b> of several <b>layers</b> of semitransparent paint. The key steps consist of creating textures for each layer using LIC of Perlin Noise, and then calculating the layer thickness distribution using an inverted subtractive lighting model. The resulting watercolor-style images have color coherence that results from the mixing of a limited palette of paints. The new lighting model helps to better convey large shape changes, while texture orientations give hints of less dominant features. The rendered images therefore possess perceptual clues to more effectively communicate shape and texture information...|$|R
5000|$|Visual effects {{supervisor}} Jay Worth found {{inspiration for}} the ash storyline from holding his grandmother-in-law's hands while at her funeral. He noted during production, [...] "The Ash Man definitely had {{its own set of}} challenges, because we wanted to utilize a lot of real elements, and because we didn't have the time to do all the simulation and particle work needed to make it look real. The thing that sold The Ash Man more than anything was the aftermath shot: This half-disintegrated body with a pile of ash for the head on the ground. It ended up being a <b>layering,</b> <b>compositing,</b> tweaking challenge beyond belief. I got to shoot the elements myself and had more control over them." ...|$|R
40|$|SiO 2 was {{actually}} etched, the plasma composition {{in our case}} is l ikely rich in F and CF~, and there is l ittle SiF 4 present o react with the surface exposed to the plasma. Therefore, the surface contamination <b>layer</b> <b>composit</b> ion in this case should be somewhat different from what has been reported. Peak widths {{and the presence of}} the na-t ive si l icon oxide under the polymer film confirm that mixing near the film-silicon interface is small. Our results are at variance with the results of Coyle and Oehriein (5) Who describe that the interface between the Teflon-like residue layer and silicon consists of SiC. We attribute this difference to their samples which were silicon dioxide on silicon and the plasma etching system used in processing the sil icon wafers. This tudy shows that the surface of the Teflon-like layer, which is expose...|$|R
40|$|We {{present a}} {{technique}} which automatically converts {{a small number}} of single-view volume rendered images of the same 3 D data set into a compact representation of that data set. This representation is a multi-layered image, or an explorable image, which enables interactive exploration of volume data in transfer function space without accessing the original data. We achieve this by automatically extracting <b>layers</b> depicted in <b>composited</b> images. The <b>layers</b> can then be recombined in different ways to simulate opacity changes and recoloring of individual features. Our results demonstrate that explorable images are especially useful when the volume data is too large for interactive exploration, takes too long to render due to the underlying mesh structure or desired shading effect, or if the original volume data is not available. Explorable images can offer real-time image-based interaction as a preview mechanism for remote visualization or visualization of large volume data on low-end hardware, within a mobile device, or a Web browser...|$|R
40|$|Variety of {{professional}} software tools connected with graphics and design teacher poses {{a difficult task}} of choice a specific software tools developed {{in the absence of}} teaching methods appropriate technology. Currently, most schools are using and exploring mainly MS Windows operating system and application software Microsoft Office, Adobe Photoshop, CorelDraw etc. But free software is almost no way inferior in its functionality and even in some aspects superior software and analogs (vector graphics Adobe Photoshop – GIMP, vector graph- ics CorelDraw, Adobe Illustrator – Inkscape). In the learning process, GIMP should be used in art and design, to find ideas that cannot always be noticed while using conventional inks on paper or pencils (the program has 48 brushes, textures and effects). GIMP can be used to create and process digital graphics and photographs (crop and retouch photos, styling photo edition), creating images and logos for use in presentations and other educational projects. The software allows the manipulation of images colors, animation, <b>compositing</b> images using <b>layers,</b> remove image elements, converting between different types of image files...|$|R
30|$|Shalini et al. [13] {{emphasized}} on sensitizers, including ruthenium complexes, metal-free organic dyes, quantum-dot sensitizer, perovskite-based sensitizer, mordant dyes, {{and natural}} dyes. However, {{this article provides}} a great knowledge about {{the different types of}} sensitizers, but lacks the information regarding other important components of the DSSCs. Again, apart from discussing all different components of DSSCs, the review article by Jihuai Wu et al. [14] was concentrated over the counter electrode part. They have discussed the study of different types of counter electrodes based on transparency and flexibility, metals and alloys, carbon materials, conductive polymers, transition metal compounds, and hybrids. A highest efficiency of 14.3 % was discussed for the DSSC fabricated with Au/GNP as a counter electrode, Co 3 +/ 2 + as a redox couple, and LEG 4 [*]+[*]ADEKA- 1 as a sensitizer [15] and was shown in the review article. Similarly, Yeoh et al. and Fan et al. [16, 17] have given a brief review over the photoanode of DSSC. They have classified modification of photoanode into three categories, namely interfacial modification through the introduction of blocking and scattering <b>layer,</b> <b>compositing,</b> doping with non-metallic anions and metallic cations, interfacial engineering, and replacing the conventional mesoporous semiconducting metal oxide films like with 1 -D or 2 -D nanostructures.|$|R
40|$|In this thesis, I {{study how}} color data from {{different}} styles of paintings can be extracted from photography with the end result maintaining the artistic integrity of the art style and having {{the look and feel}} of skin. My inspiration for this work came from the impasto style portraitures of painters such as Rembrandt and Greg Cartmell. I analyzed and studied the important visual characteristics of both Rembrandt?s and Cartmell?s styles of painting. These include how the artist develops shadow and shading, creates the illusion of subsurface scattering, and applies color to the canvas, which will be used as references to help develop the final renders in computer graphics. I also examined how color information can be extracted from portrait photography in order to gather accurate dark, medium, and light skin shades. Based on this analysis, I have developed a process for creating portrait paintings from 3 D facial models. My process consists of four stages: (1) Modeling a 3 D portrait of the subject, (2) data collection by photographing the subjects, (3) Barycentric shader development using photographs, and (4) <b>Compositing</b> with filtered <b>layers.</b> My contributions has been in stages (3) and (4) as follows: Development of an impasto-style Barycentric shader by extracting color information from gathered photographic images. This shader can result in realistic looking skin rendering. Development of a compositing technique that involves filtering layers of images that correspond to different effects such as diffuse, specular and ambient. To demonstrate proof-of-concept, I have created a few animations of the impasto style portrait painting for a single subject. For these animations, I have also sculpted high polygon count 3 D model of the torso and head of my subject. Using my shading and compositing techniques, I have created rigid body animations that demonstrate the power of my techniques to obtain impasto style portraiture during animation under different lighting conditions...|$|R

