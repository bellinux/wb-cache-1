50|10000|Public
30|$|The goal of {{this project}} was to design and {{construct}} an electronic stethoscope with an associated software system that can transfer respiratory sounds to a PC for recording and subsequent computer-aided analysis and diagnosis. The hardware-software system was used to <b>collect</b> <b>a</b> <b>dataset</b> of respiratory sounds to train SVM and CNN machine learning algorithms for the automated analysis and diagnosis. The complete system {{can also be used}} for all types of body sounds (e.g., lung, heart, intestines) and is expected to be in widespread clinical use.|$|E
40|$|Several hundred Wikipedia {{articles}} are deleted every day {{because they lack}} sufficient significance {{to be included in}} the encyclopedia. We <b>collect</b> <b>a</b> <b>dataset</b> of deleted articles and analyze them to determine whether or not the deletions were justified. We find evidence to support the hypothesis that many deletions are carried out correctly, but also find that a large number were done very quickly. Based on our conclusions, we make some recommendations to reduce the number of non-significant pages and simultaneously improve retention of new editors...|$|E
40|$|In this paper, {{we present}} a shadow removal {{technique}} which effectively eliminates a human shadow cast from an unknown direction of light source. A multi-cue shadow descriptor is proposed to characterize the distinctive properties of shadows. We employ a 3 -stage process to detect then remove shadows. Our algorithm improves the shadow detection accuracy by imposing the spatial constraint between the foreground subregions of human and shadow. We <b>collect</b> <b>a</b> <b>dataset</b> containing 81 human-shadow images for evaluation. Both descriptor ROC curves and qualitative results demonstrate the superior performance of our method. 1...|$|E
5000|$|Incremental {{learning}} allows OPTIMOL to <b>collect</b> <b>a</b> better <b>dataset</b> ...|$|R
3000|$|Dataset description. Using the {{previously}} described data extraction techniques, we <b>collected</b> <b>a</b> <b>dataset</b> of news events spanning from August 2013 to June 2015. This dataset consisted of 20, 066 news events, which contained 193, 445, 734 tweets produced by 26, 127, 624 different users. 3 [...]...|$|R
40|$|The ATLAS {{experiment}} at the Large Hadron Collider at CERN has <b>collected</b> <b>a</b> <b>dataset</b> ofppcollisions atps= 13 TeV, {{with the}} earliest analysed data corresponding to an integratedluminosity of 6. 4 pb= 1. Kinematic distributions are presented for events passing selectionsthat targetWandZboson production with subsequent decay to`or``, where`=e;andis the corresponding neutrino or anti-neutrino. These distributions are compared to theexpected contributions fromWandZboson production, including associated jet production,and other Standard Model processes with similar final stat...|$|R
40|$|Significant {{portion of}} {{contemporary}} computer users are children, who {{are vulnerable to}} threats coming from the Internet. To protect children from such threats, in this study, we investigate how successfully typing data {{can be used to}} distinguish children from adults. For this purpose, we <b>collect</b> <b>a</b> <b>dataset</b> comprising keystroke data of 100 users and show that distinguishing child Internet users from adults is possible using Keystroke Dynamics with equal error rates less than 10 percent. However the error rates increase significantly when there are impostors in the system. Comment: 18 page...|$|E
40|$|Networked {{applications}} {{interact with}} the TCP/IP stack through the socket API. Over the years, various extensions {{have been added to}} this popular API. In this paper, we propose and implement the TCPSnitch software that tracks the interactions between Linux and Android applications and the TCP/IP stack. We <b>collect</b> <b>a</b> <b>dataset</b> containing the interactions produced by more than 120 different applications. Our analysis reveals that applications use a variety of API calls. On Android, many applications use various socket options even if the Java API does not expose them directly. TCPSnitch and the associated dataset are publicly available. Comment: See [URL]...|$|E
40|$|Researchers study social {{networks}} {{to understand how}} individuals with similar behavior form clusters, and what causes them to do so. Universities are interested in learning more about influential factors of student behavior, including the impact that their {{social networks}} have on these behaviors. We have done foundational work to <b>collect</b> <b>a</b> <b>dataset</b> about UCSD student social network data gathered from Facebook and academic data from the UCSD Registrar. Once complete, the social network portion of this dataset will also be combined with datasets on health behaviors, potentially to build predictive models for depression, substance abuse, and other important condition...|$|E
40|$|The {{current work}} <b>collected</b> <b>a</b> <b>dataset</b> on the {{interaction}} between people {{to be used in}} future research on sentiment analysis. Based on messages sent from an individual to others, a crawler is build to able to identify individual with high likelihood of response. Based on a random forest model that analyzes features in message and frequent term count analysising the text body, the crawler was able to detect replyied individuals with 75...|$|R
40|$|A {{major part}} of {{membrane}} function is conducted by proteins, both integral and peripheral. Peripheral membrane proteins temporarily adhere to biological membranes, either to the lipid bilayer or to integral membrane proteins with non-covalent interactions. The {{aim of this study}} was to construct and analyze the interactions of the human plasma membrane peripheral proteins (peripherome hereinafter). For this purpose, we <b>collected</b> <b>a</b> <b>dataset</b> of peripheral proteins of the human plasma membrane. We also <b>collected</b> <b>a</b> <b>dataset</b> of experimentally verified interactions for these proteins. The interaction network created from this dataset has been visualized using Cytoscape. We grouped the proteins based on their subcellular location and clustered them using the MCL algorithm in order to detect functional modules. Moreover, functional and graph theory based analyses have been performed to assess biological features of the network. Interaction data with drug molecules show that ~ 10 % of peripheral membrane proteins are targets for approved drugs, suggesting their potential implications in disease. In conclusion, we reveal novel features and properties regarding the protein-protein interaction network created by peripheral proteins of the human plasma membrane. Comment: 39 pages, 5 figures, 3 supplement figures, under review in BMR...|$|R
40|$|AbstractStudies of quarkonium {{and charm}} {{production}} in the forward region provide important tests of NRQCD. During 2010 and 2011 the LHCb experiment has <b>collected</b> <b>a</b> <b>dataset</b> corresponding to <b>an</b> integrated luminosity of 1 fb− 1 in proton-proton collisions at s= 7 TeV. We present studies of the production of open charm, charmonium, and bottomonium states and compare the results to recent theoretical predictions. We also present measurements of double charm production, performed {{for the first time}} at a hadron collider...|$|R
40|$|In this paper, a new {{framework}} is proposed for clothing style recognition in natural scenes. Clothing region is first detected through {{the fusion of}} super-pixel segmentation, saliency detection and Gaussian Mixture Model (GMM). Next, a group of fashion attribute detectors are trained to get the likelihood of each attribute in the clothing image. Finally, the correlation matrix between clothing styles and fashion attributes is adopted to predict the clothing style. For evaluation, we <b>collect</b> <b>a</b> <b>dataset</b> for clothing style recognition which contains 5 styles and 14 fashion attributes. Extensive experiments demonstrate that the proposed framework has a promising ability to recognize the clothing style...|$|E
40|$|In {{this work}} we analyze the discussions on Twitter around the Human {{papillomavirus}} (HPV) vaccinations. We <b>collect</b> <b>a</b> <b>dataset</b> consisting of tweets {{related to the}} HPV vaccinations by searching for relevant keywords, by retrieving the conversations on Twitter, and by retrieving tweets from our user group mentioning semi-relevant keywords. We find that by tracking the conversations on Twitter relevant tweets can be found with reasonable precision. Although sentiments and opinions change regularly in a discussion, we find few cases of topic drift. © 2014 Springer International Publishing Switzerland. City of Amsterdam; et al.; Google; Microsoft Research; Textkernel; The Netherlands Organization for Scientific Research (NWO...|$|E
40|$|Whilst {{conducting}} {{some preliminary}} research for an industrially-based Wireless Sensor Network (WSN) project within the rail industry, {{it became apparent}} that a method to obtain real world Radio Frequency (RF) performance characteristics without requiring expensive test hardware did not exist. It was also apparent that informative data on the real world characterisation of environments where WSN nodes are likely to be deployed was a neglected area of research. A design has been completed that addresses these issues. A cross platform set of tools will be able to <b>collect</b> <b>a</b> <b>dataset</b> from a number of test sites using standard WSN nodes. The project is now moving into the implementation and testing phase which will be completed by late August 2005...|$|E
40|$|Abstract. The {{ability to}} {{automate}} {{the assignment of}} primary care medical diagnoses from free-text holds many interesting possibilities. We have <b>collected</b> <b>a</b> <b>dataset</b> of free-text clinical encounter notes and their corresponding manually coded diagnoses {{and used it to}} built a document classifier. Classifying a test set of 2, 000 random encounter notes yielded a coding accuracy rate of 49. 7 %. Automated coding of primary care encounter notes is a novel application area, and though imperfect our method proves interesting enough to warrant further research. ...|$|R
40|$|Abstract Human-activity {{recognition}} {{is one of}} the most challenging problems in computer vision. Researchers from around the world have tried to solve this prob-lem and have come a long way in recognizing simple motions and atomic activ-ities. As the computer vision community heads toward fully recognizing human activities, a challenging and labeled dataset is needed. To respond to that need, we <b>collected</b> <b>a</b> <b>dataset</b> of realistic scenarios in a multi-camera network environment (VideoWeb) involving multiple persons performing dozens of different repetitive and non-repetitive activities. This chapter describes the details of the dataset. W...|$|R
40|$|Studies of quarkonia {{production}} in the forward region provide important tests of NRQCD. The LHCb experiment has <b>collected</b> <b>a</b> <b>dataset</b> corresponding to <b>an</b> integrated luminosity of about 3 fb^- 1 in proton-proton collisions at √(s) = 7 and 8 TeV. We present studies of the production and polarisation of the J/ψ, ψ(2 S) and χ_c charmonium {{states as well as}} those of Υ and χ_b bottomonia. Absolute and relative production cross-sections are presented and compared to the most recent theoretical predictions when available. We also discuss the future prospects for these measurements...|$|R
40|$|The {{potential}} of mining tourist information from social multimedia data {{gives rise to}} new applications offering much richer impressions of the city. In this paper we propose Scenemash, a system that generates multimodal summaries of multiple alternative routes between locations in a city. To get insight into the geographic areas on the route, we <b>collect</b> <b>a</b> <b>dataset</b> of community-contributed images and their associated annotations from Foursquare and Flickr. We identify images and terms representative of a geographic area by jointly analysing distributions {{of a large number}} of semantic concepts detected in the visual content and latent topics extracted from associated text. Scenemash prototype is implemented as an Android app for smartphones and smartwatches...|$|E
40|$|Recent work in {{semantic}} parsing for {{question answering}} {{has focused on}} long and complicated questions, many of which would seem unnatural if asked in a normal conversation between two humans. In an effort to explore a conversational QA setting, we present a more realistic task: answering sequences of simple but inter-related questions. We <b>collect</b> <b>a</b> <b>dataset</b> of 6, 066 question sequences that inquire about semi-structured tables from Wikipedia, with 17, 553 question-answer pairs in total. Existing QA systems face two major problems when evaluated on our dataset: (1) handling questions that contain coreferences to previous questions or answers, and (2) matching words or phrases in a question to corresponding entries in the associated table. We conclude by proposing strategies to handle both of these issues...|$|E
40|$|In recent years, {{there has}} been an {{increasing}} interest in cross-domain recommender systems. However, most existing works focus on the situation when only users or users and items overlap in different domains. In this paper, we investigate whether the source domain can boost the recommendation performance in the target domain when only items overlap. Due to the lack of publicly available datasets, we <b>collect</b> <b>a</b> <b>dataset</b> from two domains related to music, involving both the users’ rating scores and the description of the items. We then conduct experiments using collaborative filtering and content-based filtering approaches for validation purpose. According to our experimental results, the source domain can improve the recommendation performance in the target domain when only items overlap. However, the improvement decreases with the growth of non-overlapping items in different domains...|$|E
30|$|<b>Collected</b> ACP: is <b>a</b> <b>dataset</b> {{consists}} of combined {{access control policy}} sentences collected by Xiao et al. (2012).|$|R
30|$|The {{proposed}} method estimates 3 D human pose {{and shape}} including non-skeletal shape information under clothing. We optimize the parametric 3 D human model using a single-image human silhouette with clothing region segmentation while considering pre-constructed statistics of the displacement by clothing (i.e., {{the distance between}} the naked and clothed contours) for each clothing category. The displacement modeling is a significant challenge in our study since <b>collecting</b> <b>a</b> <b>dataset</b> of image pairs of clothed and naked people is unfeasible. We, therefore, model the displacement based on clothed person shapes generated from naked silhouettes by a clothing simulator.|$|R
40|$|This paper {{examines}} {{the relationship between}} differences in civil society development under communism and the political, economic and institutional change and transformation after 1989. We <b>collected</b> <b>a</b> unique <b>dataset</b> on nature and intensity ofcivil society, institutions, economic reform, democratization...|$|R
40|$|Natural touch interfaces, common now in {{devices such}} as tablets and smartphones, make it {{cumbersome}} for users to select text. There {{is a need for}} a new text selec-tion paradigm that goes beyond the high acuity selection-by-mouse that we have re-lied on for decades. In this paper, we in-troduce such a paradigm, called Smart Se-lection, which aims to recover a user’s in-tended text selection from her touch input. We model the problem using an ensemble learning approach, which leverages mul-tiple linguistic analysis techniques com-bined with information from a knowledge base and a Web graph. We <b>collect</b> <b>a</b> <b>dataset</b> of true intended user selections and simu-lated user touches via a large-scale crowd-sourcing task, which we release to the academic community. We show that our model effectively addresses the smart se-lection task and significantly outperforms various baselines and standalone linguistic analysis techniques. ...|$|E
40|$|Energy Roadmap {{outlined}} by the European Commission sets out several routes for a more sustainable, competitive and secure energy system in 2050. All the outlined scenarios consider energy efficiency, renewable energy, nuclear energy and carbon capture and storage. In this paper, more attention {{has been devoted to}} the energy efficiency issue, by the identification of new micro and small networks opportunity fed by hybrid plants in the North-East of Italy. National energy balance and national transmission system operator data allowed to collect industrial energy consumptions data on the investigated area. Applying industrial statistics to the local energy needs allows to <b>collect</b> <b>a</b> <b>dataset</b> including consumption information by factory and by company structure (size and employees) for each industrial sector highlighting the factory density in the area. Preliminary outcomes from the model address to the exploitation of local by-product for energy purposes...|$|E
40|$|In this paper, we {{investigate}} how people construct clarification questions. Our {{goal is to}} develop similar strategies for handling errors in automatic spoken dialogue systems {{in order to make}} error recovery strategies more efficient. Using a crowd-sourcing tool [7], we <b>collect</b> <b>a</b> <b>dataset</b> of user responses to clarification questions when presented with sentences in which some words are missing. We find that, in over 60 % of cases, users choose to continue the conversation without asking a clarification question. However, when users do ask a question, our findings support earlier research showing that users are more likely to ask a targeted clarification question than a generic question. Using the dataset we have collected, we are exploring machine learning approaches for determining which system responses are most appropriate in different contexts and developing strategies for constructing clarification questions. 1 Index Terms: clarification, questio...|$|E
30|$|In {{order to}} utilize the-state-of-the-art {{fine-grained}} visual classification methods for maritime vessel categorization, we <b>collected</b> <b>a</b> <b>dataset</b> consisting of <b>a</b> total of 2 million images downloaded from the Shipspotting website [12], where hobby photographers upload images of maritime vessels and corresponding detailed annotations including types, categories, tonnage, draught, length, summer deadweight, year built, and International Maritime Organization (IMO) numbers, which uniquely identify ships. To {{the best of}} our knowledge, the collected dataset, MARitime VEsseLs (MARVEL) [13, 14], is the largest-scale dataset with meta-data composed of the aforementioned attributes, suited for fine-grained visual categorization, recognition, retrieval, and verification tasks, as well as any possible future applications.|$|R
40|$|We study a {{symmetric}} collaborative dialogue {{setting in}} which two agents, each with private knowledge, must strategically communicate to achieve a common goal. The open-ended dialogue state in this setting poses new challenges for existing dialogue systems. We <b>collected</b> <b>a</b> <b>dataset</b> of 11 K human-human dialogues, which exhibits interesting lexical, semantic, and strategic elements. To model both structured knowledge and unstructured language, we propose a neural model with dynamic knowledge graph embeddings that evolve as the dialogue progresses. Automatic and human evaluations show that our model is both more effective at achieving the goal and more human-like than baseline neural and rule-based models. Comment: ACL 201...|$|R
40|$|The {{establishment}} of an Australian medical rehabilitation clinical quality registry which <b>collects</b> <b>a</b> prescribed <b>dataset</b> from participating facilities describing each of their rehabilitation episodes and then provides casemix adjusted benchmarking information to each member facility to allow reflection on process and outcomes and ultimately drive better outcomes for patients...|$|R
40|$|Photographs taken {{through a}} window are often compro-mised by dirt or rain present on the window surface. Com-mon cases of this include {{pictures}} taken from inside a ve-hicle, or outdoor security cameras mounted inside a pro-tective enclosure. At capture time, defocus {{can be used to}} remove the artifacts, but this relies on achieving a shallow depth-of-field and placement of the camera close to the win-dow. Instead, we present a post-capture image processing solution that can remove localized rain and dirt artifacts from a single image. We <b>collect</b> <b>a</b> <b>dataset</b> of clean/corrupted image pairs which are then used to train a specialized form of convolutional neural network. This learns how to map corrupted image patches to clean ones, implicitly capturing the characteristic appearance of dirt and water droplets in natural images. Our models demonstrate effective removal of dirt and rain in outdoor test conditions. 1...|$|E
40|$|We {{provide a}} {{detailed}} analysis of two largely unexplored aspects of the security decisions made by the Android operating system during the app installation process: update integrity and UID assignment. To inform our analysis, we <b>collect</b> <b>a</b> <b>dataset</b> of Android application metadata and extract features from these binaries {{to gain a better understanding}} of how developers interact with the security mechanisms invoked during installation. Using the dataset, we find empirical evidence that Android’s current signing architecture does not encourage best security practices. We also find that limitations of Android’s UID sharing method force developers to write custom code rather than rely on OS-level mechanisms for secure data transfer between apps. As a result of our analysis, we recommend incrementally deployable improvements, including a novel UID sharing mechanism with applicability to signature-level permissions. We additionally discuss mitigation options for a security bug in Google’s Play store, which allows apps to transparently obtain more privileges than those requested in the manifest...|$|E
40|$|Can humans fly? Emphatically no. Can cars eat? Again, {{absolutely}} not. Yet, these absurd inferences {{result from}} the current disregard for particular types of actors in action understanding. There is no work we know of on simulta-neously inferring actors and actions in the video, {{not to mention a}} dataset to experiment with. Our paper hence marks the first effort in the computer vision community to jointly consider various types of actors undergoing various actions. To start with the problem, we <b>collect</b> <b>a</b> <b>dataset</b> of 3782 videos from YouTube and label both pixel-level actors and actions in each video. We formulate the general actor-action understanding problem and instantiate it at vari-ous granularities: both video-level single- and multiple-label actor-action recognition and pixel-level actor-action semantic segmentation. Our experiments demonstrate that inference jointly over actors and actions outperforms infer-ence independently over them, and hence concludes our ar-gument of the value of explicit consideration of various ac-tors in comprehensive action understanding. 1...|$|E
40|$|Intrapersonal {{synchronization}} of limb movements is {{a relevant}} feature for assessing coordination of motoric behavior. In this paper, {{we show that}} it can also distinguish between full-body movements performed with different expressive qualities, namely rigidity, uidity, and impulsivity. For this purpose, we <b>collected</b> <b>a</b> <b>dataset</b> of movements performed by professional dancers, and annotated the perceived movement qualities {{with the help of}} a group of experts in expressive movement analysis. We computed intra personal synchronization by applying the Event Synchronization algorithm to the time-series of the speed of arms and hands. Results show that movements performed with different qualities display a significantly different amount of intra personal synchronization: Impulsive movements are the most synchronized, the uid ones show the lowest values of synchronization, and the rigid ones lay in between...|$|R
40|$|In {{this paper}} we {{describe}} {{a system for}} automatic people counting in crowded environments. The approach we pro-pose is a counting-by-detection method based on depth im-agery. It {{is designed to be}} deployed as an autonomous ap-pliance for crowd analysis in video surveillance application scenarios. Our system performs foreground/background segmentation on depth image streams in order to coarsely segment persons, then depth information is used to localize head candidates which are then tracked in time on an auto-matically estimated ground plane. The system runs in real-time, at a frame-rate of about 20 fps. We <b>collected</b> <b>a</b> <b>dataset</b> of RGB-D sequences representing three typical and chal-lenging surveillance scenarios, including crowds, queuing and groups. An extensive comparative evaluation is given between our system and more complex, Latent SVM-based head localization for person counting applications. 1...|$|R
40|$|This paper {{addresses}} {{the task of}} readability assessment for the texts aimed at second language (L 2) learners. One of the major challenges in this task {{is the lack of}} significantly sized level-annotated data. For the present work, we <b>collected</b> <b>a</b> <b>dataset</b> of CEFR-graded texts tailored for learners of English as an L 2 and investigated text readability assessment for both native and L 2 learners. We applied a generalization method to adapt models trained on larger native corpora to estimate text readability for learners, and explored domain adaptation and self-learning techniques {{to make use of the}} native data to improve system performance on the limited L 2 data. In our experiments, the best performing model for readability on learner texts achieves an accuracy of 0. 797 and PCC of 0. 938...|$|R
