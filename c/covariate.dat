8399|10000|Public
25|$|Least-angle {{regression}} is an estimation {{procedure for}} linear regression models {{that was developed}} to handle high-dimensional <b>covariate</b> vectors, potentially with more covariates than observations.|$|E
25|$|It is {{possible}} that the unique effect can be nearly zero even when the marginal effect is large. This may imply that some other <b>covariate</b> captures all the information in x'j, so that once that variable is in the model, there is no contribution of x'j to the variation in y. Conversely, the unique effect of x'j can be large while its marginal effect is nearly zero. This would happen if the other covariates explained {{a great deal of the}} variation of y, but they mainly explain variation in a way that is complementary to what is captured by x'j. In this case, including the other variables in the model reduces the part of the variability of y that is unrelated to x'j, thereby strengthening the apparent relationship with x'j.|$|E
50|$|In statistics, a <b>covariate</b> is a {{variable}} that is possibly predictive {{of the outcome}} under study. A <b>covariate</b> may be of direct interest {{or it may be}} a confounding or interacting variable.|$|E
40|$|Content: Supplemental Methods S 1 Multiple imputations {{for missing}} data of <b>covariates</b> Table S 1 Associations of <b>covariates</b> with {{childhood}} anthropometric measures Table S 2 Associations of <b>covariates</b> with childhood body fat distribution outcomes Table S 3 Associations of <b>covariates</b> with childhood cardiovascular outcomes Table S 4 Fetal and childhood growth characteristic...|$|R
50|$|Functional {{regression}} is {{a version}} of regression analysis when responses or <b>covariates</b> include functional data. Functional regression models can be classified into four types {{depending on whether the}} responses or <b>covariates</b> are functional or scalar: (i) scalar responses with functional <b>covariates,</b> (ii) functional responses with scalar <b>covariates,</b> (iii) functional responses with functional <b>covariates,</b> and (iv) scalar or functional responses with functional and scalar <b>covariates.</b> In addition, functional regression models can be linear, partially linear, or nonlinear. In particular, functional polynomial models, functional single and multiple index models and functional additive models are three special cases of functional nonlinear models.|$|R
40|$|Objectives: Reviews of the {{handling}} of <b>covariates</b> in trials have explicitly excluded cluster randomized trials (CRTs). In this study, we review the use of <b>covariates</b> in randomization, the reporting of <b>covariates,</b> and adjusted analyses in CRTs. Study Design and Setting: We reviewed {{a random sample of}} 300 CRTs published between 2000 and 2008 across 150 English language journals. Results: Fifty-eight percent of trials used <b>covariates</b> in randomization. Only 69 (23 %) included tables of cluster- and individual-level <b>covariates.</b> Fifty-eight percent reported significance tests of baseline balance. Of 207 trials that reported baseline measures of the primary outcome, 155 (75 %) subsequently adjusted for these in analyses. Of 174 trials that used <b>covariates</b> in randomization, 30 (17 %) included an analysis adjusting for all those <b>covariates.</b> Of 219 trial reports that included an adjusted analysis of the primary outcome, only 71 (32 %) reported that <b>covariates</b> were chosen a priori. Conclusion: There are some marked discrepancies between practice and guidance on the use of <b>covariates</b> in the design, analysis, and reporting of CRTs. It is essential that researchers follow guidelines on the use and reporting of <b>covariates</b> in CRTs, promoting the validity of trial conclusions and quality of trial reports...|$|R
50|$|While the {{inclusion}} of a <b>covariate</b> into an ANOVA generally increases statistical power by accounting for some {{of the variance in the}} dependent variable and thus increasing the ratio of variance explained by the independent variables, adding a <b>covariate</b> into ANOVA also reduces the degrees of freedom. Accordingly, adding a <b>covariate</b> which accounts for very little variance in the dependent variable might actually reduce power.|$|E
5000|$|... <b>covariate</b> (large areas {{affected}} by one phenomenon such as drought) ...|$|E
5000|$|... #Subtitle level 3: Domain {{adaptation}} under <b>covariate,</b> target, and conditional shift ...|$|E
5000|$|... {{along with}} P(ym = 0 ∨ ym-1 = 0, xm, cm= 0) and {{use this to}} set up the partial {{likelihood}} for person i. So, essentially, the partial likelihood with time-varying <b>covariates</b> resembles the partial likelihood with time-invariant <b>covariates</b> where the time-invariant <b>covariates</b> are replaced by the time-variant <b>covariates.</b> This likelihood, however, only holds under the assumptions stated above.|$|R
40|$|Consider a {{case where}} cause-effect {{relationships}} between variables can be described by a causal path diagram and the corresponding linear structural equation model. The paper proposes a graphical selection criterion for <b>covariates</b> to estimate the causal effect of a control plan. For designing the control plan, {{it is essential to}} determine both <b>covariates</b> that are used for control and <b>covariates</b> that are used for identification. The selection of <b>covariates</b> used for control is only constrained by the requirement that the <b>covariates</b> be non-descendants of a treatment variable. However, the selection of <b>covariates</b> used for identification is dependent on the selection of <b>covariates</b> used for control and is not unique. In the paper, the difference between <b>covariates</b> that are used for identification is evaluated {{on the basis of the}} asymptotic variance of the estimated causal effect of an effective control plan. Furthermore, the results can be also described in terms of a graph structure. Copyright 2003 Royal Statistical Society. ...|$|R
40|$|Given data $y$ and $k$ <b>covariates</b> $x$ {{the problem}} is to decide which <b>covariates</b> to include when {{approximating}} $y$ by a linear function of the <b>covariates.</b> The decision is based on replacing subsets of the <b>covariates</b> by i. i. d. normal random variables and comparing the error with that obtained by retaining the subsets. If the two errors are not significantly different for a particular subset it is concluded that the <b>covariates</b> in this subset are no better than random noise {{and they are not}} included in the linear approximation to $y$...|$|R
5000|$|... #Subtitle level 4: Cox model using a <b>covariate</b> in the {{melanoma}} data ...|$|E
5000|$|<b>Covariate</b> Shift {{in which}} the {{marginal}} distribution of the covariates changes across domains: ...|$|E
5000|$|... #Caption: Cox PH output for {{melanoma}} {{data set}} with <b>covariate</b> log tumor thickness ...|$|E
40|$|The {{requirement}} of constant censoring parameter [beta] in Koziol-Green (KG) model is too restrictive. When <b>covariates</b> are present, the conditional KG model (Veraverbekea and Cadarso-Suárez, 2000) which allows [beta] to {{be dependent on}} the <b>covariates</b> is more realistic. In this paper, using sufficient dimension reduction methods, we provide a model-free diagnostic tool to test if [beta] {{is a function of the}} <b>covariates.</b> Our method also allows us to conduct a model-free selection of the related <b>covariates.</b> A simulation study and a real data analysis are also included to illustrate our approach. Conditional Koziol-Green model Multiple <b>covariates</b> Proportional hazards model Sufficient dimension reduction...|$|R
40|$|We {{study the}} {{asymptotic}} properties of bridge estimators in sparse, high-dimensional, linear regression models {{when the number}} of <b>covariates</b> may increase to infinity with the sample size. We are particularly interested in the use of bridge estimators to distinguish between <b>covariates</b> whose coefficients are zero and <b>covariates</b> whose coefficients are nonzero. We show that under appropriate conditions, bridge estimators correctly select <b>covariates</b> with nonzero coefficients with probability converging to one and that the estimators of nonzero coefficients have the same asymptotic distribution that they would have if the zero coefficients were known in advance. Thus, bridge estimators have an oracle property in the sense of Fan and Li [J. Amer. Statist. Assoc. 96 (2001) 1348 – 1360] and Fan and Peng [Ann. Statist. 32 (2004) 928 – 961]. In general, the oracle property holds only if the number of <b>covariates</b> is smaller than the sample size. However, under a partial orthogonality condition in which the <b>covariates</b> of the zero coefficients are uncorrelated or weakly correlated with the <b>covariates</b> of nonzero coefficients, we show that marginal bridge estimators can correctly distinguish between <b>covariates</b> with nonzero and zero coefficients with probability converging to one even {{when the number of}} <b>covariates</b> is greater than the sample size...|$|R
5000|$|Minimize {{allocation}} bias (or confounding). This {{may occur}} when <b>covariates</b> {{that affect the}} outcome are not equally distributed between treatment groups, and the treatment effect is confounded with {{the effect of the}} <b>covariates</b> (i.e., an [...] "accidental bias"). If the randomization procedure causes an imbalance in <b>covariates</b> related to the outcome across groups, estimates of effect may be biased if not adjusted for the <b>covariates</b> (which may be unmeasured and therefore impossible to adjust for).|$|R
5000|$|Treatment {{assignment}} is {{based solely on}} <b>covariate</b> data and independent of potential outcomes.|$|E
50|$|A {{time-varying}} <b>covariate</b> (also called time-dependent <b>covariate)</b> is a {{term used}} in statistics, particularly in survival analyses. It reflects the phenomenon that a <b>covariate</b> is not necessarily constant through the whole study. For instance, if one wishes to examine the link between area of residence and cancer, this would be {{complicated by the fact}} that study subjects move from one area to another. The area of residency could then be introduced in the statistical model as a time-varying <b>covariate.</b> In survival analysis, this would be done by splitting each study subject into several observations, one for each area of residence. For example, if a person is born at time 0 in area A, moves to area B at time 5, and is diagnosed with cancer at time 8, two observations would be made. One with a length of 5 (5 − 0) in area A, and one with a length of 3 (8 − 5) in area B.|$|E
5000|$|... : greater {{variability}} {{in a particular}} <b>covariate</b> leads to proportionately less variance in the corresponding coefficient estimate ...|$|E
40|$|In {{observational}} studies, the non-parametric {{estimation of}} a binary treatment effect is often performed by matching each treated individual with {{a control unit}} which is similar in observed characteristics (<b>covariates).</b> In practical applications, the reservoir of <b>covariates</b> available may be extensive and the question arises which <b>covariates</b> should be matched for. The current practice consists in matching for <b>covariates</b> which are not balanced for the treated and the control groups, i. e. <b>covariates</b> affecting the treatment assignment. This paper develops a theory based on graphical models, whose results emphasize the need for methods looking both at how the <b>covariates</b> affect the treatment assignment and the outcome. Furthermore, we propose identification algorithms to select at minimal set of <b>covariates</b> to match for. An application to the estimation {{of the effect of}} a social program is used to illustrate the implementation of such algorithms. Graphical models; matching estimators; observational studies; potential outcomes; social programs...|$|R
40|$|A {{statistical}} {{study is}} presented quantifying {{the effects of}} <b>covariates</b> such as gender, age, expression, image resolution and focus on three face recognition algorithms. Specifically, a Generalized Linear Mixed Effect model is used to relate probability of verification to subject and image <b>covariates.</b> The data and algorithms are selected from the Face Recognition Grand Challenge and {{the results show that}} the effects of <b>covariates</b> are strong and algorithm specific. The paper presents in detail all of the significant effects including interactions among <b>covariates.</b> One significant conclusion is that <b>covariates</b> matter. The variation in verification rates as a function of <b>covariates</b> is greater than the difference in average performance between the two best algorithms. Another is that few or no universal effects emerge; almost no <b>covariates</b> effect all algorithms in the same way and to the same degree. To highlight one specific effect, there is evidence that verification systems should enroll subjects with smiling rather than neutral expressions for best performance...|$|R
2500|$|Minimize {{allocation}} bias (or confounding). [...] This {{may occur}} when <b>covariates</b> {{that affect the}} outcome are not equally distributed between treatment groups, and the treatment effect is confounded with {{the effect of the}} <b>covariates</b> (i.e., an [...] "accidental bias"). [...] If the randomization procedure causes an imbalance in <b>covariates</b> related to the outcome across groups, estimates of effect may be biased if not adjusted for the <b>covariates</b> (which may be unmeasured and therefore impossible to adjust for).|$|R
50|$|This {{expression}} {{gives the}} hazard rate {{at time t}} for subject i with <b>covariate</b> vector (explanatory variables) Xi.|$|E
5000|$|... where [...] is the {{centered}} functional <b>covariate,</b> [...] is a scalar coefficient, [...] and [...] are coefficient functions with domains [...] and , respectively, and [...] is {{a random}} error with mean zero and finite variance. By analogy to FLMs with scalar responses, estimation of functional polynomial models {{can be obtained}} through expanding both the centered <b>covariate</b> [...] and the coefficient functions [...] and [...] in an orthonormal basis.|$|E
5000|$|The {{alternative}} terms explanatory variable, independent variable, or predictor, {{are used}} in a regression analysis. In econometrics, the term [...] "control variable" [...] is usually used instead of [...] "covariate". An example {{is provided by the}} analysis of trend in sea level by [...] Here the dependent variable (and variable of most interest) was the annual mean sea level at a given location for which a series of yearly values were available. The primary independent variable was time. Use was made of a <b>covariate</b> consisting of yearly values of annual mean atmospheric pressure at sea level. The results showed that inclusion of the <b>covariate</b> allowed improved estimates of the trend against time to be obtained, compared to analyses which omitted the <b>covariate.</b>|$|E
40|$|In many medical studies, {{there are}} <b>covariates</b> that change their values {{over time and}} their {{analysis}} is most often modeled using the Cox regression model. However, many of these time-dependent <b>covariates</b> can be expressed as an intermediate event which can be modeled using a multi-state model. Using the relationship of time-dependent (discrete) <b>covariates</b> and multi-state models, we compare (via simulation studies) the Cox model with time-dependent <b>covariates</b> with {{the most frequently used}} multi-state regression models. This paper also details the procedures for generating survival data arising from all approaches, including the Cox model with time-dependent <b>covariates.</b> Fundação para a Ciência e a Tecnologia (FCT...|$|R
30|$|A clear {{implication}} of Mackie’s {{notion of a}} causal field and Woodward’s manipulability account of causation for causal inference in LSAs {{is the need to}} collect as many relevant ancillary <b>covariates</b> as possible. Mackie’s notions of a causal field and the resulting inus condition for causal inference is helpful in narrowing down the number of <b>covariates</b> to be collected; however there still remains a number of practical concerns. First and foremost is the collection of the “right” <b>covariates.</b> The concept of the causal field notwithstanding, it still remains that relevant <b>covariates</b> need to be chosen and measured to help insure that strong ignorability holds given the observed <b>covariates.</b> Naturally this falls in the domain of the content experts who advise contractors and governing bodies as to the relevant <b>covariates</b> to be collected in support of the priority causal questions. For example, guided by policy priorities, experts in early childhood education and in reading would work to develop a list of possible <b>covariates</b> {{that could be used in}} a propensity score analysis for modeling the non-random selection into pre-primary education.|$|R
30|$|Both the {{cross-sectional}} and panel {{samples are}} used for analysis, with propensity scores estimated separately for each sample. For the panel sample, I construct propensity scores using baseline <b>covariates</b> measured in 2001. For the much larger cross-sectional sample, I use <b>covariates</b> measured in 2002 because baseline <b>covariates</b> are missing for {{approximately half of the}} observations.|$|R
5000|$|The ANCOVA {{procedure}} {{is described as}} follows, assuming that a linear relationship between the response (DV) and <b>covariate</b> (CV) exists: ...|$|E
50|$|In contrast, one can first cluster {{variables}} into {{highly correlated}} groups, and then extract a single representative <b>covariate</b> from each cluster.|$|E
50|$|Palloni, A., & Thomas, J. R. (2013). Estimation of <b>covariate</b> effects {{with current}} status data and {{differential}} mortality. Demography, 50(2), 521-544.|$|E
40|$|In this thesis, we {{have studied}} the {{preselection}} bias that can occur {{when the number of}} <b>covariates</b> in a high dimensional regression problem is reduced prior to a high dimensional regression analysis like the lasso. Datasets in genomics often include ten- or hundred thousands, or even millions, of <b>covariates</b> and a few hundred or less patients. To reduce computations or to make the problem tractable, practitioners often rank the <b>covariates</b> according to univariate importance for the response, and preselect some thousand <b>covariates</b> {{from the top of the}} list for multivariate analysis via penalized regression. If the preselection of <b>covariates</b> is not done in a controlled way, this leads to preselection bias. We {{have studied the}} effect of preselection on estimation and prediction and the bias this might induce. With a small preselected dataset, the lasso in combination with cross validation tends to select many <b>covariates,</b> which together are able to explain the data at hand very well. However, for a new independent dataset, these <b>covariates</b> predict rather poorly. This is preselection bias. We have visualized the preselection bias through boxplots in several different datasets from genomics and in simulated data. We have also demonstrated that the problem of preselection bias is most evident in datasets where there is a lot of noise, and where there are heavy dependencies between <b>covariates,</b> as the univariate ranking will not be able to capture the structure of the complex relations in this case. To be able to trust predictions made from penalized regression on preselected <b>covariates,</b> the preselection should be coupled with some algorithm that controls how many <b>covariates</b> that should be included in order to avoid the bias. We have studied methods like ``SAFE'', ``strong'' and ``freezing'' that all make preselection more safe, the word safe meaning that the lasso analysis for the preselected set of <b>covariates</b> should conclude with the same result as if all <b>covariates</b> were included...|$|R
40|$|In {{this talk}} I {{will present a}} {{framework}} for modelling the sampling and responses of longitudinal data. To identify regression parameters for the response based on random sampling {{what is needed is}} basically that the the models contains sufficient with <b>covariates</b> that the response and the sampling times are independent given the <b>covariates</b> (Martinussen and Scheike, 2006). In the case where subjects will always be at risk certain simplifications are possible {{and it turns out that}} in this case one can identify the marginal means of the response given the <b>covariates</b> (Lin, Scharfstein and Rosenheck, 2004). The models considered are the partial linear models where some <b>covariates</b> effects lead to timevarying effects and other <b>covariates</b> have constan...|$|R
40|$|Since {{survival}} data occur over time, often important <b>covariates</b> that {{we wish to}} consider also change over time. Such <b>covariates</b> are referred as time-dependent <b>covariates.</b> Quantile regression offers flex-ible modeling of {{survival data}} by allowing the <b>covariates</b> to vary with quantiles. This paper provides a novel quantile regression model ac-commodating time-dependent <b>covariates,</b> for analyzing survival data subject to right censoring. Our simple estimation technique assumes the existence of instrumental variables. In addition, we present a doubly-robust estimator {{in the sense of}} Robins & Rotnitzky (1992). The asymptotic properties of the estimators are rigorously studied. Finite-sample properties are demonstrated by a simulation study. The utility of the proposed methodology is demonstrated using the Stan-ford heart transplant dataset. 1. Introduction. Quantil...|$|R
