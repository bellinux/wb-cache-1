0|11|Public
40|$|Abstract — This work investigates {{reliable}} wireless broadcast with {{asynchronous data}} access. A wireless broadcast {{system based on}} LT-codes, a realization of the recently introduced Fountain codes, is introduced. We review the traditional problem formalization for Fountain codes operating on erasure channels and generalize the framework to arbitrary types of <b>channels</b> <b>coining</b> the terminology {{and the concept of}} information collecting. Thesum-product algorithm in order to exploit soft-information available at the wireless receiver for decoding of LT codes is applied. Simulation results on the AWGN, as well as the fading channel, show remarkable performance gains compared to traditional erasure decoding. I...|$|R
50|$|In {{the summer}} of 1922, {{and for the next}} seven years, Bretz {{conducted}} field research of the Columbia River Plateau. Since 1910 he had been interested in unusual erosion features in the area after seeing a newly published topographic map of the Potholes Cataract. Bretz <b>coined</b> the term <b>Channeled</b> Scablands in 1923 to describe the area near the Grand Coulee, where massive erosion had cut through basalt deposits. The area was a desert, but Bretz's theories required cataclysmic water flows to form the landscape, for which Bretz coined the term Spokane Floods in a 1925 publication.|$|R
2500|$|Geologist J Harlen Bretz first {{recognized}} {{evidence of}} the catastrophic floods, which he called the Spokane Floods, in the 1920s. He was researching the Channeled Scablands in Eastern Washington, the Columbia Gorge, and the Willamette Valley of Oregon. In the summer of 1922, {{and for the next}} seven years, Bretz conducted field research of the Columbia River Plateau. He had been interested in unusual erosion features in the area since 1910 after seeing a newly published topographic map of the Potholes Cataract. Bretz <b>coined</b> the term <b>Channeled</b> Scablands in 1923 to refer to the area near the Grand Coulee, where massive erosion had cut through basalt deposits. [...] Bretz published a paper in 1923, arguing that the channeled scablands in Eastern Washington were caused by massive flooding in the distant past.|$|R
30|$|Embedded {{systems are}} a crucial asset in {{many aspects of}} technology. They are used in various {{applications}} including motion estimation in imaging [3, 4], computing optimization [5], secure exchange of information, and among others. Yet every computational device emits a series of leakages <b>coined</b> as side <b>channels.</b> These {{can be in the}} form of power dissipation, electromagnetic emissions, execution time of a process, emanated light, and among other physical attributes. The methods used to determine a cryptographic device’s physical vulnerabilities lie within the realm of side-channel analysis, while the use of it for the purpose of extracting private or secret keys from a cryptographic protocol is described as side-channel attacks (SCAs) which was pioneered by Kocher in [6]. SCAs largely depend on statistical schemes to extract keys and are relatively cheap to mount and perform [7, 8]. Advancements in side-channel cryptanalytics have highlighted the need to account for countermeasures against them especially in the design of secure systems.|$|R
40|$|International audienceThis paper {{considers}} pilot-based channel estimation in large-scale multiple-input multiple-output (MIMO) communication systems, {{also known}} as "massive MIMO". Unlike previous works on this topic, which mainly considered the impact of inter-cell disturbance due to pilot reuse (so-called pilot contamination), we {{are concerned with the}} computational complexity. The conventional minimum mean square error (MMSE) and minimum variance unbiased (MVU) channel estimators rely on inverting covariance matrices, which has cubic complexity in the multiplication of number of antennas at each side. Since this is extremely expensive when there are hundreds of antennas, we propose to approximate the inversion by an L-order matrix polynomial. A set of low-complexity Bayesian <b>channel</b> estimators, <b>coined</b> Polynomial ExpAnsion <b>CHannel</b> (PEACH) estimators, are introduced. The coefficients of the polynomials are optimized to yield small mean square error (MSE). We show numerically that near-optimal performance is achieved with low polynomial orders. In practice, the order L can be selected to balance between complexity and MSE. Interestingly, pilot contamination is beneficial to the PEACH estimators in the sense that smaller L can be used to achieve near-optimal MSEs...|$|R
40|$|This paper {{considers}} pilot-based channel estimation in large-scale multiple-input multiple-output (MIMO) communication systems, {{also known}} as "massive MIMO". Unlike previous works on this topic, which mainly considered the impact of inter-cell disturbance due to pilot reuse (so-called pilot contamination), we {{are concerned with the}} computational complexity. The conventional minimum mean square error (MMSE) and minimum variance unbiased (MVU) channel estimators rely on inverting covariance matrices, which has cubic complexity in the multiplication of number of antennas at each side. Since this is extremely expensive when there are hundreds of antennas, we propose to approximate the inversion by an L-order matrix polynomial. A set of low-complexity Bayesian <b>channel</b> estimators, <b>coined</b> Polynomial ExpAnsion <b>CHannel</b> (PEACH) estimators, are introduced. The coefficients of the polynomials are optimized to yield small mean square error (MSE). We show numerically that near-optimal performance is achieved with low polynomial orders. In practice, the order L can be selected to balance between complexity and MSE. Interestingly, pilot contamination is beneficial to the PEACH estimators in the sense that smaller L can be used to achieve near-optimal MSEs. Comment: Published at IEEE International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC 2013), 8 - 11 September 2013, 6 pages, 4 figures, 1 tabl...|$|R
40|$|The {{problem of}} {{communicating}} covertly over the Internet has recently received considerable attention from both industry and academic communities. However, the previously proposed network covert channels are plagued by their unreliability and very low data rate. In this paper, we show {{through a new}} class of timing <b>channels</b> <b>coined</b> as Cloak {{that it is possible to}} devise a 100 percent reliable covert channel and yet offer a much higher data rate (up to an order of magnitude) than the existing timing channels. Cloak is novel in several aspects. First, Cloak uses the different combinations of N packets sent over X flows in each round to represent a message. The combinatorial nature of the encoding methods increases the channel capacity largely with (N,X). Second, based on the well-known 12 -fold Way, Cloak offers 10 different encoding and decoding methods, each of which has a unique tradeoff among several important considerations, such as channel capacity and camouflage capability. Third, the packet transmissions modulated by Cloak can be carefully crafted to mimic normal TCP flows for evading detection. We have implemented Cloak and evaluated it in the PlanetLab and a controlled testbed. The results show that it is not uncommon for Cloak to have an order of channel goodput improvement over the IP Timing channel and JitterBug. Moreover, Cloak does not suffer from any message loss under various loss and reordering scenarios. Department of Computin...|$|R
40|$|International audience—This paper {{considers}} pilot-based channel estimation in large-scale multiple-input multiple-output (MIMO) communi-cation systems, {{also known}} as "massive MIMO", where {{there are hundreds of}} antennas at one side of the link. Motivated by the fact that computational complexity {{is one of the main}} challenges in such systems, a set of low-complexity Bayesian <b>channel</b> estima-tors, <b>coined</b> Polynomial ExpAnsion <b>CHannel</b> (PEACH) estimators, are introduced for arbitrary channel and interference statistics. While the conventional minimum mean square error (MMSE) estimator has cubic complexity in the dimension of the covariance matrices, due to an inversion operation, our proposed estimators significantly reduce this to square complexity by approximating the inverse by a L-degree matrix polynomial. The coefficients of the polynomial are optimized to minimize the mean square error (MSE) of the estimate. We show numerically that near-optimal MSEs are achieved with low polynomial degrees. We also derive the exact com-putational complexity of the proposed estimators, in terms of the floating-point operations (FLOPs), by which we prove that the proposed estimators outperform the conventional estimators in large-scale MIMO systems of practical dimensions while providing a reasonable MSEs. Moreover, we show that L needs not scale with the system dimensions to maintain a certain normalized MSE. By analyzing different interference scenarios, we observe that the relative MSE loss of using the low-complexity PEACH estimators is smaller in realistic scenarios with pilot con-tamination. On the other hand, PEACH estimators are not well suited for noise-limited scenarios with high pilot power; therefore, we also introduce the low-complexity diagonalized estimator that performs well in this regime. Finally, we also investigate numerically how the estimation performance is affected by having imperfect statistical knowledge. High robustness is achieved for large-dimensional matrices by using a new covariance estimate which is an affine function of the sample covariance matrix and a regularization term...|$|R

