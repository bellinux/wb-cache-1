0|51|Public
40|$|ABSTRACT Execution {{profiles}} {{have become}} increasingly important for guid-ing code optimization. However, little {{has been done to}} develop ways to check automatically that a profile does, in fact, reflect theactual execution behavior of a program. This paper describes a framework that uses program monitoring techniques in a way thatallows the automatic checking {{of a wide variety of}} profile data. We also describe our experiences with using an instance of this frame-work to <b>check</b> <b>edge</b> profiles. The profile verifier uncovered profiling anomalies that we had been unaware of and that would havebeen very difficult to identify using existing techniques. 1...|$|R
5000|$|<b>Check</b> Point UTM-1 <b>Edge,</b> Power-1, VSX-1, IP Appliances (Formerly a Nokia Product Line).|$|R
5000|$|For each <b>edge,</b> <b>check</b> if {{deleting}} {{the edge}} will further disconnect the graph.|$|R
40|$|Abstract:- Whether the {{assembling}} {{angle and}} the extension elongation of the razor match the requirement will directly affect {{the function of}} razor. In this paper, {{a new kind of}} machine vision system for detecting the assembling angle and the extension elongation of razor is designed. And a special measure method——wavelet is applied to <b>check</b> the <b>edge</b> of razor, which can afford the more accurate data of razor <b>edge</b> <b>checking</b> than traditional measure method and has a great help to detect assembling quality of razor. The experiments results show this system has a great accuracy and reached the Standard of blade assemble detecting...|$|R
3000|$|The relax {{function}} in Algorithm 7 takes hop count n, after which edge (u,v) is reached. The first condition in the if-statement <b>checks</b> whether this <b>edge</b> satisfies the non-decreasing edge weight path property after traveling the n-hop path to vertex u. The second condition <b>checks</b> whether this <b>edge</b> constitutes a shorter path than up to n-hop paths to vertex v. Because {{of the way}} hop-vertices are extracted from the min-heap, h [...]...|$|R
40|$|PURPOSE. To {{evaluate}} macular {{function and}} neural conduction along postretinal visual pathways in amblyopic patients. METHODS. Twenty-five anisometropic amblyopic patients (mean age, 7 1. 9 years; visual acuity [VA]: 0. 44 0. 27 logMAR in ambly-opic [AM] eyes and 0. 023 0. 067 logMAR in sound [SE] eyes) and 25 age-similar control subject ([CE] eyes, VA of 0. 0 0. 0 logMAR in both eyes) were enrolled. In AM, SE, and CE eyes, simultaneous pattern electroretinograms (PERGs) and visual evoked potentials (VEPs) {{were recorded in}} response to checks reversed {{at the rate of}} two reversals/second stimulating macu-lar or extramacular areas (the <b>check</b> <b>edge</b> subtended 15 min-utes and 60 minutes of visual arc, respectively). RESULTS. Nonsignificant differences (ANOVA, P 0. 005) were observed in PERG, in VEP responses to the 60 -minute stimulus, and in retinocortical time with the 60 -minute stimulus (RCT...|$|R
5000|$|When an edge {{is deleted}} {{in a general}} graph, we don't know whether its {{component}} remains a single component (connected by other edges) or broken to two components. So we use two processes which run in parallel (or in an interleaved way). Process A <b>checks</b> whether the <b>edge</b> deletion breaks a component, {{and if it does}}, both processes halt. Process B <b>checks</b> whether the <b>edge</b> deletion does not break the component to which it belongs, and if it does not, again both processes halt.|$|R
30|$|Then {{for each}} <b>edge</b> we <b>check</b> {{adjacent}} <b>edges</b> from the EdgeList prepared {{and see if}} they have the common vertex. The sign of the vertex depends on the sign of edge (i, j)th in S. If edge (i, j) is positive then corresponding vertex would be positive otherwise it would be negative. This way new matrix of L(S) is computed.|$|R
5000|$|Deleting an <b>edge,</b> <b>checking</b> the {{connectivity}} of {{the resulting}} graph, and (if it is disconnected) re-inserting the edge {{can be done in}} O(logV (log log V)3) time per operation [...]|$|R
40|$|This paper {{investigates the}} problem of optimally determin-ing source-destination {{connectivity}} in random graphs. We consider the classic Erdos-Renyi (ER) random graph with n nodes, where an edge independently exists between any two nodes with probability p. The problem examined is that of determining whether a given pair of nodes, a source S and a destination D, are connected by a path. Assuming that at each step one edge can be tested {{to see if it}} exists or not, we determine an optimal policy that minimizes the total ex-pected number of steps. The optimal policy has several interesting features. In or-der to establish connectivity of S and D, a policy needs to <b>check</b> all <b>edges</b> on some path to see if they all exist, but to establish disconnectivity it has to <b>check</b> all <b>edges</b> on some cut to see if none of them exists. The optimal policy has the following form. At each step it examines the conden-sation multigraph formed by contracting each known con-nected component to a single node, and then <b>checks</b> an <b>edge</b> that is simultaneously on a shortest S-D path as well as in a minimum S-D cut. Among such edges, it chooses that which leads to the most opportunities for connection. In-terestingly, the optimal strategy does not depend on p or n, even though the entire graph itself undergoes a sharp transi-tion from disconnectivity to connectivity around p = lnn=n. The policy is efficiently implementable, requiring no more than 30 log 2 n operations to determine which edge to test next. The result also extends to some more general graphs. 1...|$|R
40|$|Abstract: This paper {{deals with}} the concept of {{self-similarity}} fractals of four types of square ladder fractal with existence of Edge cordial labeling. A square graph is considered as base for square fractals which leads to construction of some of ladder type fractals. For our study each iterations and the generalized form are considered as graph. Eventually each graph is <b>checked</b> with <b>edge</b> cordial and total edge cordial labeling...|$|R
40|$|Abstract • Background: The aim of {{our work}} was to {{evaluate}} neural conduction i visual pathways in subjects with ocular hypertension and glaucoma. • Methods: We as-sessed simultaneous recordings of pattern electroretinograms (PERG) and visual evoked potentials (VEP) in 16 subjects with ocular hyper-tension (OHT), in 16 subjects with primary open-angle glaucoma (POAG) and in 15 age-matched controls. The visual stimuli were checkerboard patterns (the <b>check</b> <b>edges</b> subtend 15 rain of visual arc; contrast 70 %) reversed {{at the rate of}} 2 reversals/s. • Results: In OHT and POAG patients we found PERG and VEP latencies ignfi-cantly longer than in controls. The P 50 -N 95 PERG amplitudes were significantly reduced in OHT and POAG eyes. VEP amplitudes were significantly reduced in POAG eyes, while in OHT they were simi-lar to controls. The retinocortical time (RCT; difference between VEP P 100 latency and PERG P 50 latency) was longer in POAG pa-tients than in controls; no differ-ences between patients with OHT and controls were observed. More-over, we observed that in POAG the longer RCT was inversely related to the PERG amplitude. • Conclu-sion: Our results suggest that in-volvement of the innermost retinal layers in POAG is accompanied by slowed neural conduction i the vi-sual pathways...|$|R
40|$|Objectve: To {{correlate}} {{the nerve}} fiber layer (NFL) thickness {{and the visual}} function evaluated by electro-physiologic retinal and cortical responses assessed in open-angle glaucoma (OAG) eyes. Design: Prospective case-control study. Participants: Thirty glaucoma patients (mean age, 47. 1 6 7. 15 years; refractive error range, 6 2 spherical equivalent) with a mean deviation of computerized static perimetry (24 / 2 Humphrey, Dublin, CA) from 25 to 228 dB and intraocular pressure less than 21 mmHg on pharmacologic treatment and 14 age-matched control participants. Methods: Nerve fiber layer thickness was measured by optical coherence tomography. Retinal and visual pathway function was assessed by simultaneously recording pattern electroretinograms (PERGs) and visual evoked potentials (VEPs) using high-contrast (80 %) checkerboard stimuli (the single <b>check</b> <b>edges</b> subtend 15 minutes of the visual arc) reversed {{at the rate of}} two reversals per second. Linear regression analyses were adopted to establish the correlation between NFL thickness and PERG and VEP parameters. Main Outcome Measures: Nerve fiber layer thickness measurements in each quadrant (superior, inferior, nasal, and temporal) were taken and then averaged (12 values averaged) and identified as NFL overall, whereas the data obtained in the temporal quadrant only (three values averaged) were identified as NFL temporal. PER...|$|R
30|$|The {{original}} vertex relaxation algorithm refined to {{work under}} these conditions is given in Algorithm 1. The condition in the if-statement <b>checks</b> whether the <b>edge</b> is in a non-decreasing order in the path. Edge weights are not accumulated as in the original version because they are absolute contact times.|$|R
40|$|ABSTRACT⎯This paper proposes {{two kinds}} of complexity-reduced {{algorithms}} for a low density parity check (LDPC) decoder. First, sequential decoding using a partial group is proposed. It has the same hardware complexity and requires a fewer number of iterations with little performance loss. The amount of performance loss can {{be determined by the}} designer, based on a tradeoff with the desired reduction in complexity. Second, an early detection method for reducing the computational complexity is proposed. Using a confidence criterion, some bit nodes and <b>check</b> node <b>edges</b> are detected early on during decoding. Once the edges are detected, no further iteration is required; thus early detection reduces the computational complexity. Keywords⎯LDPC codes, low complexity, early detect algorithm...|$|R
60|$|He {{rejected}} that hypothesis with scorn, and, <b>checked</b> on the <b>edge</b> of the pavement, made ready {{to cross the}} road and proceed up the wide street facing {{the head of the}} bridge; and that for no other reason except that it was there before him. But at the moment a couple of carriages and a slow-moving cart interposed, and suddenly he turned sharp to the left, following the quay again, but now away from the lake.|$|R
40|$|We study {{interaction}} induced topological {{phase transition}} in Bernevig-Hughes-Zhang model. Topological {{nature of the}} phase transition is revealed by directly calculating the Z 2 index of the interacting system from the single-particle Green's function. The interacting Z 2 index is also consistently <b>checked</b> through the <b>edge</b> spectra. Combined with ab initio methods, present approach is a useful tool searching for correlated topological insulating materials from the first-principle point of view. Comment: 4. 5 pages, 4 figures, reference adde...|$|R
5000|$|Hull structure: A FNORM module for the {{definition}} of standards of structure is provided with a user interface, including multi dock windows and snap points; furthermore, it allows adding geometrical restrictions and includes the possibility of layer management. The increase of the lengths of the identifications and descriptions of blocks, materials and geometrical norms, {{as well as the}} hierarchical structure for {{the definition}} of the standards and geometrical norms are other capabilities of this module. Moreover, following features must be highlighted: hull structure modeling: an algorithm to represent corrugated parts more accurately, commands for <b>checking</b> the <b>edge</b> preparation of plates and profiles, options for {{the definition of}} face bars and an algorithm to represent more accurately curved shell and deck plates. Regarding profiles and plates nesting, the NEST module allows the nesting of identical parts assigned to different interim products and keeps information to recognize each individual part.|$|R
50|$|Focus {{the gaze}} {{on a small}} {{specific}} point, known in yoga as a drishte. This is ideally something directly ahead which does not move. Engage the standing foot by lifting the arch and pressing down through the lateral <b>edge.</b> <b>Check</b> that weight is distributed through the ball of the large toe, the ball of the small toe, and the heel. Draw in the navel to improve core stability and posture. Faults include leaning to one side, twisting, pushing one hip out; bending or rotating the supporting knee outwards; looking downwards and lacking concentration.|$|R
40|$|Many graph {{properties}} (e. g., connectedness, {{containing a}} complete subgraph) {{are known to}} be difficult to check. In a decision-tree model, the cost of an algorithm is measured by the number of edges in the graph that it queries. R. Karp conjectured in the early 1970 s that all monotone graph properties are evasive [...] that is, any algorithm which computes a monotone graph property must <b>check</b> all <b>edges</b> in the worst case. This conjecture is unproven, but a lot of progress has been made. Starting with the work of Kahn, Saks, and Sturtevant in 1984, topological methods have been applied to prove partial results on the Karp conjecture. This text is a tutorial on these topological methods. I give a fully self-contained account of the central proofs from the paper of Kahn, Saks, and Sturtevant, with no prior knowledge of topology assumed. I also briefly survey some of the more recent results on evasiveness. Comment: Book version, 92 page...|$|R
50|$|Machine code programmers {{have another}} alternative. Using 4 bits per square, an entire row can be {{represented}} in 32 bits, and the board in 8 registers (with an additional one for remaining position information). By use of a jump table, adding the piece value to the program counter can {{go directly to the}} code to generate moves for this type of piece on this square. Although the program is longer than for a conventional move generation methods, no <b>checks</b> for the <b>edge</b> of the board are required, and no moves off the board are considered, increasing move generation speed.|$|R
50|$|The {{development}} of a polyhedron can be described concretely by a collection of two-dimensional polygons together with instructions for gluing them together along their edges to form a metric space, and the conditions of Alexandrov's theorem for such spaces are easily <b>checked.</b> However, the <b>edges</b> of the gluing pattern will not necessarily become {{the edges of the}} polyhedron. Alexandrov's original proof does not lead to an algorithm for constructing the polyhedron (for instance by giving coordinates for its vertices) realizing the given metric space. In 2008, Bobenko and Izmestiev provided such an algorithm. Their algorithm can approximate the coordinates arbitrarily accurately, in pseudo-polynomial time.|$|R
40|$|A {{method for}} {{puncturing}} a low density parity check (LDPC) code that is decoded through a parity check matrix expressed {{by a factor}} graph including check nodes and bit nodes connected to the <b>check</b> nodes through <b>edges.</b> The method includes classifying the bit nodes mapped to a parity part of a codeword into hierarchical groups according to their decoding facilities when the bit nodes are punctured, determining puncturing order of the groups, and sequentially performing puncturing on the bit nodes from a bit node belonging to a corresponding group according to the puncturing order of the groups to acquire a codeword with a desired coding rate. Samsung Electronics Co., Ltd. Georgia Tech Research Corporatio...|$|R
5000|$|Megaphone heist: When Randal called Radio Shack {{to ask for}} megaphones, the {{assistant}} told him another group of people (Capital Edge) called in for megaphones. Randal and Rebecca engaged in a [...] "Megaphone Heist". This is the turning point of the task. Randall and Rebecca pretended to be Capital Edge's [...] "colleagues" [...] {{and went into the}} store to pick them up [...] "for them". Randall and Rebecca left with only nine instead of 10 because the tenth megaphone was set up in a display window and Rebecca was nervous of Capital Edge coming in and spotting them. When Alla called to <b>check</b> on Capital <b>Edge's</b> megaphones, the receptionist told them they had already given them to Excel.|$|R
40|$|Objective. The aim of {{this study}} was to {{establish}} and validate the measurement properties of the Disability Rating Index (DRI) in a population of adults undergoing hip replacement. Methods. One hundred and twenty-six adults participating in a randomized controlled trial completed the Oxford Hip Score, Harris Hip Score, DRI and EuroQol Group–Five Dimensions (EQ- 5 D) questionnaires at four time points. The structural validity of the DRI was assessed using principal component analysis. Cronbach’s α was used to determine the internal consistency and scale reliability was also assessed. Correlation between the DRI and the other functional and health-related quality of life scales was used to check criterion validity. DRI responsiveness was estimated and the interpretability of the scale was also assessed by <b>checking</b> for <b>edge</b> effects. Results. Results of analyses showed that the DRI was internally consistent (Cronbach’s α = 0. 92), had good association with both function-specific and general health-related quality of life scores and was sensitive to change (smallest detectable change = 2. 7). No evidence of edge effects was found. Furthermore, structural assessment of the DRI revealed two novel subscales representing simple tasks and difficult tasks. Conclusions. The DRI is structurally valid, responsive and concurs with functional assessment in adults undergoing hip replacement...|$|R
40|$|The {{improved}} GVC Algorithm proposed aims at {{high quality}} of 2 -D to 3 -D reconstruction by incorporating additional <b>check</b> of <b>edge</b> detection and usage of Histogram- based consistency as a photo consistency measure. The improved GVC algorithm comprises of two-stage consistency check, where at the first stage the multi modal histogram consistency check is applied on each uncarved voxel to determine its color consistency. At the next stage, all the voxels that were declared inconsistent after the first stage are tested for edges and features. If matches are found between the sets of pixels of images on which voxels project to (also called as footprints), the voxel is declared consistent, and else it is carved. The final output is reconstructed 3 -D object/scene that resembles the original image. The histogram consistency measure is suited for lambertian surfaces, i. e. the surfaces that reflect light equally are all directions. Histograms are well suited for characterising multi modal distributions of color and hence are applicable to footprints of voxel with multiple clusters of color. Due to this reason, this consistency test yields better reconstruction results than obtained from tests based on means and variances. Keywords-consistency check, GVC, reconstruction, histogram intersection, voxel, 2 -D images, 3 -D object/scene I...|$|R
40|$|Overload <b>checking,</b> {{forbidden}} regions, <b>edge</b> finding, and not-first/not-last detection are well-known propagation {{rules to}} prune the start times of activities which {{have to be}} processed without any interruption and overlapping on an exclusively available resource, i. e. machine. These rules are extendible by two other rules which take the number of activities into account which are at most executable after or before another activity. To our knowledge, these rules are based on approximations of the (minimal) earliest completion times and the (maximal) latest start times of sets of activities. In this paper, the precise definitions of these time values {{as well as an}} efficient procedure for their calculations are given. Based on the resulting time values the rules are re-formulated and applied to a well-known job shop scheduling benchmark...|$|R
40|$|Overload <b>checking,</b> {{forbidden}} regions, <b>edge</b> finding, and not-first/not-last detection are well-known propagation {{rules to}} prune the start times of tasks which {{have to be}} processed without any interruption and overlapping on an exclusively available resource, i. e. machine. We show that these rules are correct and that "sweeping" over task intervals is an efficient and sufficient technique to achieve maximal pruning with respect to all these propagation rules. All the presented algorithms have quadratic time and linear space complexity {{with respect to the}} number of tasks. To our knowledge, this is the first presentation where the correctness of all these rules is proved and where it is shown and proved that the combination of these algorithms achieves the same pruning of the start times achieved by other algorithms with cubic time and quadratic space complexity...|$|R
40|$|Abstract. Overload <b>checking,</b> {{forbidden}} regions, <b>edge</b> finding, and notfirst/not-last detection are well-known propagation {{rules to}} prune the start times of activities which {{have to be}} processed without any interruption and overlapping on an exclusively available resource, i. e. machine. These rules are extendable by two other rules which take the number of activities into account which are at most processable after or before another activity. To our knowledge, these rules are based on approximations of the (minimal) earliest completion times and the (maximal) latest start times of sets of activities. In this paper, the precise definitions of these time values {{as well as an}} efficient procedure for their calculations are given. Based on the precise time values the rules are re-formulated and applied to a well-known job shop scheduling benchmark. ...|$|R
40|$|In this paper, {{we discuss}} {{on the use}} of {{self-organizing}} protocols to improve the reliability of dynamic Peer-to-Peer (P 2 P) overlay networks. Two similar approaches are studied, which are based on local knowledge of the nodes' 2 nd neighborhood. The first scheme is a simple protocol requiring interactions among nodes and their direct neighbors. The second scheme adds a <b>check</b> on the <b>Edge</b> Clustering Coefficient (ECC), a local measure that allows determining edges connecting different clusters in the network. The performed simulation assessment evaluates these protocols over uniform networks, clustered networks and scale-free networks. Different failure modes are considered. Results demonstrate the effectiveness of the proposal. Comment: The paper has been accepted to the journal Peer-to-Peer Networking and Applications. The final publication is available at Springer via [URL]...|$|R
50|$|Regin {{confidently}} makes Sigurd {{an admirable}} sword, but when Sigurd sees it, he is disappointed and breaks {{it over the}} anvil. On his second attempt, Regin makes him a sword superior to the last, but it also breaks. On his third attempt, Sigurd brings Regin {{the two halves of}} Gram, his father's sword, and when he strikes the anvil with Gram, it is cloven in two. Once he tested the strength of the sword, he left the workshop and went to a nearby stream to <b>check</b> its <b>edge.</b> Throwing a piece of wool upstream, he lets it press against Gram, causing it to be sliced through. After testing the blade's sharpness, he uses it to avenge his father, Sigmund, slaying King Lyngvi. Of the many feats done by Gram, by far the most well known and important is the slaying of Fafnir the dragon. This deed is accomplished by Sigurd with a single, mighty thrust to the left shoulder where he drives the sword so deep he gets his arms bloodied up to the shoulder. Eventually Gram is used as a sign of chastity when it is placed between Sigurd and Brynhild on their funeral pyre, after Brynhild arranged Sigmunds death before killing herself in turn. After this the sword is no longer found in the manuscript.|$|R
30|$|Our {{choice of}} e {{results from a}} trial of several {{different}} values. Our width definition somewhat differs from that by Coley and Heelis (1995), who identified density widths as two edges in which the plasma density is enhanced above 40  % in 140  km, and the overall enhancement is larger than 100  % above the background. When a density enhancement only has a single peak, we <b>checked</b> that the <b>edges</b> obtained by our method and Coley and Heelis’s method give essentially the same result. However, {{in cases where the}} enhanced density has multiple peaks, multiple sharp slopes meet their criteria, and hence, it becomes difficult to uniquely define density widths. Thus, our method can quantitatively find two edges that characterize density enhancements, and we confirmed the calculated widths by comparing to optical patch sizes from the AGO image data.|$|R
40|$|A {{cognitive}} vision neuronal network based on leaky integrate-and-fire (LIF) neurons is proposed for object recognition and depth analysis. In this network every LIF neuron {{is able to}} capture the edge flowing through it and record the temporal information. If the neuron issues a spike, the temporal information will be encoded by the time constant of the spike potential and transferred to its successor neuron through synapses. The successor neuron, on reception of the spike, will <b>check</b> whether that <b>edge</b> arrives at its sensor. In the case that both events synchronise the successor neuron will fire to confirm the correct edge propagation. Meanwhile, in the process the spike-timing-dependent plasticity (STDP) is employed to achieve the suitable synapse efficacies to reject spurious edge propagation. On recognition of the effective CMOS realisation of LIF neuron, our model aims to be a biologically inspired neuromorphic system amenable to aVLSI implementation. ...|$|R
40|$|The paper {{presents}} a new method {{and the corresponding}} program of presentation of bayesian belief networks. The belief network can be viewed and updated via World Wide Web. Consistency <b>checks</b> are possible. <b>Edge</b> removal and insertion operations are done in an `intelligent way' that is corrections of valuations are carried out automatically in a user-friendly way. The corresponding program is implemented as a Java applet at the front end, and is backed by some Java applications at the server site. Knowledge representation, knowledge acquisition from the user, belief networks. 1 Introduction Bayesian networks (also called belief networks or bayesian belief networks) encode properties of probability distributions using directed acyclic graphs (dag). Their usage is spread among many disciplines such as Artificial Intelligence [14], Decision Analysis [9], [17], Economics [31], Genetics [32], Philosophy [7], and Statistics [11], [22]. Bayesian networks are popular due to existence of [...] ...|$|R
5000|$|In 1563, a Spanish pirate, Cervantes de Leon stole Soul Edge from a dealer's ship, but {{gradually}} became corrupted by its spirit until it devoured his soul, influencing him to terrorize {{the world for}} twenty years. This terror made several warriors to venture out and stop him, including a female ninja, Taki, who wanted to destroy Soul Edge for having corrupted her master, and a German rebel, Siegfried Schtauffen, who desperately wanted to blame someone for the accidental murder of his father. Eventually, a Greek warrior, Sophitia Alexandra, confronted and managed to destroy one of Cervantes' blades, but the battle was eventually ended by Taki, who managed to slay Cervantes. Siegfried then came to <b>check</b> Soul <b>Edge,</b> but he became possessed by {{the release of the}} [...] "Evil Seed" [...] and turned into the monstrous Nightmare. The Evil Seed event had major impact to the world, including several people going insane, and Nightmare replaced Cervantes in terrorizing the world, wanting to recover the lost Soul Edge fragments. Three years later, Nightmare had prepared for the ritual to complete Soul Edge, but three warriors from Asia, Chai Xianghua, Kilik, and Maxi stormed his castle, the Ostrheinsburg and managed to defeat Nightmare, with Soul Edge's spirit (Inferno) being shattered by Xianghua's blade, which was revealed to be the lost Soul Calibur. Though Siegfried temporarily regained his sanity, he became possessed again shortly after, as did Soul Calibur, which succumbed to the darkness of Inferno.|$|R
40|$|Variable {{block size}} used for inter coding {{is one of}} the key {{technologies}} in H. 264 /AVC. When different objects contained in the same macroblock have different motions, smaller block sizes probably achieve better predictions. However, this feature results in extremely high computational complexity when all the block sizes are considered to decide a best one. This paper proposes a new inter mode decision algorithm to reduce the number of inter modes that has to be checked, and then encoding time is reduced. We use the co-located macroblock in previous frame and its neighbors as candidates, and <b>check</b> whether an <b>edge</b> of moving object is crossing the middle of these candidates by using the score given to the modes. The experimental results show that the proposed algorithm is able to reduce 31 %- 41 % total encoding time and about 41 %- 54 % motion estimation time with a negligible PSNR loss of 0. 05 dB and bit-rate increment of 2 % on the average...|$|R
