8|14|Public
40|$|Abstract—In this paper, we {{describe}} {{a method to}} photogrammetrically estimate the intrinsic and extrinsic parameters of fish-eye cameras using the properties of equidistance perspective, particularly vanishing point estimation, {{with the aim of}} providing a rectified image for scene viewing applications. The estimated intrinsic parameters are the optical center and the fish-eye lensing parameter, and the extrinsic parameters are the rotations about the world axes relative to the checkerboard <b>calibration</b> <b>diagram.</b> Index Terms—Fish-eye, calibration, perspective...|$|E
40|$|This bacelor´s {{thesis is}} about {{uncertainty}} of measurement. Methods for evalution of standard uncernatainty types A and B are determined. Also methods for evalution of expression of combined and expanded uncertainty are determined. Next methods for expresion {{and influence of}} source of these uncertainties. In the end are all the mesurements reviewed and its kompatibility is compared with referential measure. Also all <b>calibration</b> <b>diagram</b> are compiled. This thesis is based on practical measurement. I tis about measurement of capacitance and resistance, methods for evalution of these measurement are determined. All calculation were provided with real values. All values originate from real measurement in school´s lab E 607 DCI FEEC BUT [...] All results were compared in the end...|$|E
40|$|Oxidation {{mechanism}} of quercetin {{in three different}} electrolytes (KCl, NaCl and LiCl) was studied by cyclic and differential pulse voltammetry. The results have shown that quercetin oxidation is reversible and diffusion controlled process in all three investigated electrolytes. <b>Calibration</b> <b>diagram</b> of quercetin was obtained in KCl, so this electrolyte was selected for total polyphenol content determination in apple peel extracts. Total polyphenol content was analysed by differential pulse voltammetry (dpv) and spectrophotometric Folin-Ciocalteu method (FC) in several ancient Croatian apple varieties and a wild apple variety grown in Croatia by using quercetin as a standard. Very high correlation for TP content obtained by two methods was observed since the TPdpv/TPFC ratio was around 1 and a correlation coefficient (R 2) for TPdpv vs. TPFC was 0. 98. The highest total polyphenol content was found in Slavonska srčika variety. This work is licensed under a Creative Commons Attribution 4. 0 International License...|$|E
40|$|Summary. We discuss {{tools for}} the {{evaluation}} of probabilistic forecasts and the critique of statistical models for ordered discrete data. Our proposals include a non-randomized version of the probability integral transform, marginal <b>calibration</b> <b>diagrams</b> and proper scoring rules, such as the predictive deviance. In case studies, we critique count regression models for patent data, and assess the predictive performance of Bayesian age-period-cohort models for larynx cancer counts in Germany...|$|R
40|$|The {{possibility}} of chlorine detection in water by using of amperometric sensor with dialysis membrane was investigated. The sensor consists of platinum cathode and silver anode, which were immersed in electrolyte whose pH was controlled. The <b>calibration</b> <b>diagrams</b> were constructed for different electrolytes and polarization potentials. The detection limit of 0. 1 mg/dm 3 was obtained, middle value of sensor sensitivity was approximatelly 14 nA/mgdm' 3 and response time {{was less than}} 1 s for designed amperometric sensor in laboratory conditions...|$|R
40|$|We discuss {{tools for}} the {{evaluation}} of probabilistic forecasts and the critique of statistical models for count data. Our proposals include a nonrandomized version of the probability integral transform, marginal <b>calibration</b> <b>diagrams,</b> and proper scoring rules, such as the predictive deviance. In case studies, we critique count regression models for patent data, and assess the predictive performance of Bayesian age-period-cohort models for larynx cancer counts in Germany. The toolbox applies in Bayesian or classical and parametric or nonparametric settings and to any type of ordered discrete outcomes...|$|R
40|$|Abstract: Straightness {{measurements}} for the geometrical inspection of machining tools have been operated in a weakly controlled environment (concerning temperature, pressure, humidity and induced mechanical vibrations) {{with reference to}} industrial manufacturing departments. Measurements have been performed {{by means of a}} Wollaston prism laser interferometer. A first experimental characterization of this instrumentation has been operated by repeatability tests conducted in controlled and not controlled environments, considering different relative positions for the interferometer and the laser head. Then a <b>calibration</b> <b>diagram</b> has been constructed, assessing the accuracy and the instrumental uncertainty in the case of displacement measurements in a plane perpendicular to the laser beam direction. In a second stage a suitable method has been developed to estimate the uncertainty level associated to straightness measures operated by the laser interferometric technique and also by traditional instrumentation, such as taut-wire and microscope and precision level. Measurement uncertainty is estimated by means of the Monte Carlo Method and according to standards. Measures obtained by the laser interferometric method prove to be affected by higher levels of uncertainty than those coming from traditional approaches...|$|E
40|$|The {{cross-sectional}} area, AD, of {{a compound}} oriented in an amphiphilic gradient {{such as the}} air-water or lipid-water interface has previously {{been shown to be}} crucial for membrane partitioning and permeation, respectively. Here, we developed an algorithm that determines the molecular axis of amphiphilicity and the cross-sectional area, ADcalc, perpendicular to this axis. Starting from the conformational ensemble of each molecule, the three-dimensional conformation selected as the membrane-binding conformation was the one with the smallest cross-sectional area, ADcalcM, and the strongest amphiphilicity. The calculated, ADcalcM, and the measured, AD, cross-sectional areas correlated linearly (n= 55, slope, m= 1. 04, determination coefficient, r 2 = 0. 95). The calculated cross-sectional areas, ADcalcM, were then used together with the calculated octanol-water distribution coefficients, log D 7. 4, of the 55 compounds (with a known ability to permeate the blood-brain barrier) to establish a <b>calibration</b> <b>diagram</b> for the prediction of blood-brain barrier permeation. It yielded a limiting cross-sectional area (ADcalcM= 70 A 2) and an optimal range of octanol-water distribution coefficients (- 1. ...|$|E
40|$|A {{method has}} been devised for {{predicting}} {{the ability of}} drugs to cross the blood-brain barrier. The criteria depend on the amphiphilic properties of a drug as reflected in its surface activity. The assessment was made with various drugs that either penetrate or do not penetrate the blood-brain barrier. The surface activity of these drugs was quantified by their Gibbs adsorption isotherms in terms of three parameters: (i) the onset of surface activity, (ii) the critical micelle concentration, and (iii) the surface area requirement of the drug at the air/water interface. A <b>calibration</b> <b>diagram</b> is proposed in which the critical micelle concentration is plotted against the concentration required for the onset of surface activity. Three different regions are easily distinguished in this diagram: a region of very hydrophobic drugs which fail to enter {{the central nervous system}} because they remain adsorbed to the membrane, a central area of less hydrophobic drugs which can cross the blood-brain barrier, and a region of relatively hydrophilic drugs which do not cross the blood-brain barrier unless applied at high concentrations. This diagram can be used to predict reliably the central nervous system permeability of an unknown compound from a simple measurement of its Gibbs adsorption isotherm...|$|E
40|$|A {{potentiometric}} method {{involving a}} three-electrode cell {{was applied to}} determine the concentration stability constants (K 2 ̆ 7 n) of chlorocadmium complexes in water at 298. 15 K and ionic strength I= 1 mol dm- 3. Initially, <b>calibration</b> <b>diagrams</b> were derived for the cadmium and chloride ion, based on the measurements of the potential difference between the glass and the cadmium-amalgam electrode for known Cd 2 + ion concentrations, and between the glass and AgCl / Ag electrode for known Cl- ion concentrations. To determine the concentrations of free Cd 2 + and Cl- ions by means of <b>calibration</b> <b>diagrams,</b> potential differences between the same electrodes were measured in the three-electrode cell by changing the concentration of total chlorides while keeping the concentration of cadmium ions constant. These data {{were used to determine}} the concentration stability constants of the formed complexes CdCl+, CdCl 2, and CdCl 3 - by applying Leden’s graphical method and three numerical methods: nonlinear regression without scaling, nonlinear regression with scaling, and orthogonal polynomials. The two latter methods gave identical constants: 24. 6 (CdCl+), 68 (CdCl 2), and 69 (CdCl 3 -). The obtained concentration stability constants were compared with the available data for the same complexes obtained from the electromotive force measurements (e. m. f.) of the concentration cell with transference, calculated using the same methods. As a result, it was possible to compare both experimental methods applied in determining the concentration stability constants of chlorocadmium complexes in water medium at 298. 15 K and ionic strength I= 1 mol dm- 3...|$|R
40|$|A {{relatively}} new method for measuring optically induced forces on microparticles and cells, {{different from the}} conventional Brownian motion and viscous drag force calibration methods widely used, is introduced. It makes use of the phenomenon of dielectro-phoresis for the calibration of optical tweezers through the dielectrophoretic force calculations. A pair of microelectrodes is fabricated by photolithography on a microscope slide and it is connected to a high-frequency generator. The calibration of the optical tweezers setup is performed by the manipulation of polystyrene beads and yeast cells. <b>Calibration</b> <b>diagrams</b> of the transverse forces versus power are deduced for different cell radii and numerical apertures of the objective lenses. The optical system and the related technique provide a fast and easy method for optical tweezers calibration. (c) 2006 Society of PhotoOptical Instrumentation Engineers...|$|R
40|$|Spektrofotometrijos metodu tirtas aminazino, barbamilio ir {{nitrazepam}}o mišinys. Tinkamiausias tirpiklis, kuriame galima identifikuoti ir diferencijuoti šias medžiagas – 0, 1 N sieros rūgšties tirpalas. Šių preparatų kiekiui nustatyti sudaryti kalibravimo grafikai. Standartinis nuokrypis, nustatant aminazino kiekį – 2, 8; 4, 0; 4, 3; barbamilio – 1, 0; 2, 5; 1, 15; nitrazepamo – 2, 64; 1, 0; 1, 35. The {{mixture of}} psychotropic drugs aminazine, barbamylum and nitrazepam using ultraviolet (UV) spectrophotometric method was researched. As the solvent, most acceptable for identification and differentiation of these preparation was found 0. 1 N solution of sulphuric acid. By measuring the optical {{density of the}} solutions in different concentration the <b>calibration</b> <b>diagrams</b> for all preparations were made. The standard deviation, by determining the quantity of aminazine is 2. 8; 4. 0; 4. 3; barbamylum – 1. 0; 2. 5; 1. 15; nitrazepam – 2. 64; 1. 0; 1. 35...|$|R
40|$|Febrile convulsions (FC) are {{the most}} common {{neurologic}} disorder in children 6 - 60 months of age. Zinc (Zn) and copper (Cu) play role as cofactors in more than 300 enzymatic activities significantly. The aim {{of this study was to}} evaluate the relationship serum levels of Zn and Cu with seizure occurrence in febrile children. In this case-control study, 270 children with 6 month to 6 years were evaluated. The patients were enrolled in three groups: a) children with febrile convulsion, b) febrile children without convulsion and c) healthy ones. After recording of all patients’ characteristics, 5 mL blood was taken from peripheral vessels at the first 12 hours of hospitalization. Absorption of all samples was read by BRAIC (Rayleigh instrument) company, WFX- 130 model with <b>calibration</b> <b>diagram,</b> considering samples dilution levels. The mean of serum Zn levels in children with FC were significantly lower than other two groups. Mean serum Cu levels in children with FC and non-FC patients were significantly higher than healthy children. No meaningful differences were observed in serum levels of Zn and Cu among the girl or boy cases. This study showed significant lower serum zinc level in children with febrile seizure and meaningful higher serum copper level than control group cases. There was no significant difference in level of serum zinc and copper in term of sex...|$|E
40|$|Summary of {{the results}} and {{experiences}} obtained during the work with the oxygen recorder. The apparaus is very simple to build and use, and it works rapidly. It is possible by means of this apparature to take continuous readings of the variations of oxygen content in the water downward from the surface. The readings give a picture which is available immediately, and which may be useful for the marine biologist working at sea. For hydrographic work it may be of interest that the recorder indicates the depths where the oxygen content changes rapidly, which may be important in deciding where to take additional observations. With a few determinations of the oxygen content by the usual method {{it is possible to}} obtain a linear <b>calibration</b> <b>diagram</b> (see Fig. 3) by means of which the oxygen content at various depths can be determined with fairly good accuracy. It is recommended that anyone who starts using the apparatus should at the beginning make usual Winkler determinations of the oxygen content whenever the oxygen recorder is used. This is necessary because the ammeter values are dependent on the purity of the mercury and on the speed of the falling drops. The calibration curve, therefore, will not always go through zero. In water with sharp discontinuity layers it should never be possible lo determine salinity and oxygen content of such layers by means of the usual with any accuracy at all. This is because the water sampler itself is so long that it collects water of greatly varying properties. In such discontinuity layers only continuous recording can give the correct picture. Fig. 4 gives examples of curves obtained by the oxygen recorder...|$|E
40|$|The {{design and}} {{capabilities}} of CLAES are described. The CLAES is an instrument on NASA's Upper Atmosphere Research Satellite (UARS) and measures the global concentrations of stratospheric species and temperature over the altitude range 10 - 60 km. Consideration {{is given to}} the motorized limb acquisition and adjustment mirror, solid cryogen cooler, optical system, electronics subsystems, cryostat, and IR <b>calibration</b> source. <b>Diagrams</b> of the CLAES and UARS are provided...|$|R
40|$|Abstract: In the {{preliminary}} aerodynamic aircraft design, optimum calculation methods should be used, which enable engineers {{to perform a}} vast number of test runs in a reasonably short time. Such tools should not only be fairly simple but also reliable. In the first part, this paper briefly presents aerodynamic analyses performed by a 3 D vortex lattice method (VLM), with an aim to verify its capabilities to give results that coincide well with the experimental data of an existing airplane. Since this computational model is based on inviscid flow concept, effectiveness of control surfaces and flaps are inherently overestimated. In order to compensate for the omitted boundary layer influence, a set of <b>calibration</b> <b>diagrams</b> for effectiveness and circulation influence has been successfully derived and good agreements with wind tunnel test data have been achieved. After several necessary adjustments, calibration functions have been applied to VLM analysis within a new light aircraft conceptual study. Those results have been compared with results obtained by well known Datcom method and verygood agreements have been achieved, proving that VLM computations with properly defined calibration functions can be both efficient and reliable tools in preliminary aerodynamic design...|$|R
40|$|Species {{distribution}} models (SDMs) are {{an important}} tool in biogeography and phylogeography studies, that most often require explicit absence information to adequately model the environmental space on which species can potentially inhabit. In the so called background pseudoabsences approach, absence locations are simulated {{in order to obtain}} a complete sample of the environment. Whilst the commonest approach is random sampling of the entire study region, in its multiple variants, its performance may not be optimal, and the method of generation of pseudoabsences is known to have a significant influence on the results obtained. Here, we compare a suite of classic (random sampling) and novel methods for pseudo-absence data generation and propose a generalizable three-step method combining environmental profiling with a new technique for background extent restriction. To this aim, we consider 11 phylogenetic groups of Oak (Quercus sp.) described in Europe. We evaluate the influence of different pseudo-absence types on model performance (area under the ROC curve), <b>calibration</b> (reliability <b>diagrams)</b> and the resulting suitability maps, using a cross-validation approach. Regardless of the modelling algorithm used, randomsampling models were outperformed by the methods that incorporate environmental profiling of the background, stressing the importance of the pseudo-absence generation techniques for the development of accurate and reliable SDMs. We also provide an integrated modelling framework implementing the methods tested in a software package for the open source R environment...|$|R
40|$|The {{principle}} of carbon- 14 dating {{is well known}} (1) : the content of this radioisotope {{in a sample of}} an animal or a plant origin is assessed and the time elapsed from the formation of the organic material to the moment of assessment is calculated comparing the present content of carbon- 14 to that at the time the plant or animal was alive. This last is assumed at equilibrium with the atmospheric concentration of carbon- 14, which, in turn, is assumed to have been constant through the ages. Knowing the decay constant of carbon- 14, the time elapsed is deduced. Then this calculated age is entered in <b>calibration</b> <b>diagrams</b> that account for the actual variable atmospheric content through the years, to obtain the age of the sample, or more precisely, a time interval in which the age falls. Thus, the main idea behind the technique is that the atmospheric concentration of carbon- 14 marked CO 2 is essentially constant, or slowly variable, from year to year. To this, one word of caution needs be added: after WW 2, and particularly from the 1950 s, the concentration of carbon- 14 in the atmosphere has become quite erratic due to nuclear weapon tests, and hence this technique is not used for dating samples from that time on. In the present work, the whole carbon- 14 idea has been reused in a somewhat different context, and with a different purpose in mind. Afact to be kept in mind is thatCO 2 contained in vast amounts within the Earth’s crust beneath the volcanic apparatus, the so-called fossil CO 2, either degassed by the mantle or having been formed by metamorphic reactions in the crust, contains no trace of the carbon- 14 isotope. Fossil CO 2 release is often associated to seismic and volcanic activity: the question may then arise whether, on occasion of such major releases and in the presence of landscape conformation conducive to slow mixing (narrow valley bottoms, canyons, and the like), the carbon- 14 contents of local vegetation may be affected by the presence of spent CO 2. The Solfatara at Pozzuoli presented both the above-mentioned conditions: it has the required shape and it has endured large releases of fossil CO 2 in the early 1980 s. It presented itself as an ideal location to test this hypothesis. There are pine trees planted in the 1930 s, as part of a reforestation plan: it was possible to select two recently dead trees, one in the Solfatara area and presumably as affected by the CO 2 release as could be possible, and the other immediately outside and upwind of the area, constituting an ideal blank. Sections were taken from the two trees and analysed to determine the carbon- 14 content of several rings corresponding to the years of interest. In the following sections, the method and the results will be presented and commented upon...|$|R
40|$|Road traffic {{increases}} {{constantly and}} the negative consequences {{in the form of}} traffic jams can be realized especially in urban areas. In order to provide real time traffic information to road users and traffic managers, accurate computer models gain relevance. A software called Mobile Millennium Stockholm (MMS) was developed to estimate and predict travel times and has been implemented on a 7 km test stretch in the north of Stockholm. The core of the software is the cell transmission model (CTM) which is a macroscopic traffic flow model based on aggregated speed observations. This thesis focuses on different calibration techniques of the so called fundamental diagram as an important input factor to the CTM. The diagrams illustrate the mathematical function which defines the relation between traffic flow, density and speed. The calibration is performed in different scenarios based on the least square (LS) and total least square (TLS) error minimization. Furthermore, sources, representing the traffic demand, and sinks, representing the surrounding of the modeled network, are implemented as dynamic parameters to model the change in traffic behavior throughout the day. Split ratios, as a representation of the drivers 9 ̆ 1 route choice in the CTM are estimated and implemented as well. For the framework of this work, the MMS software is run in a pure prediction mode. The CTM is based on the source, sink, split and fundamental diagram parameters only and run forward in time. For each fundamental <b>diagram</b> <b>calibration</b> scenario an independent model run is performed. The evaluation of the scenarios is based on the output of the model. The results are compared to existing Bluetooth travel time measurements for the test stretch, which are used as ground truth observations, and a mean average percentage error (MAPE) is calculated. This leads to a most reasonable technique for the fundamental <b>diagram</b> <b>calibration</b> 9 ̆ 6 the total least square error minimization...|$|R
40|$|Some of {{the most}} {{frequently}} claimed dynamic speed limits (DSL) benefits (e. g. increase of throughput or speed homogenization) still remain a controversial topic among the scientific community, practitioners and society in general. The objective of the paper is to present an empirical assessment of this policy, aiming to provide an insightful response to the main issues related with the aggregated traffic flow behavior. Thanks to the DSL equipments installed over a metropolitan freeway accessing to Barcelona since February 2009, a comparison between non-DSL scenarios (dated on October 2008) and DSL-affected can be performed. For this purpose, a new methodology has been proposed. The whole process excels in being simple, traffic flow theory consistent, achievable with common available traffic data and easily integrable in a programming language. In doing so, a reliable characterization of the traffic flow behavior under DSL strategies has been obtained. Revealing results concerning to the driver’s behavior when facing different speed limits were obtained. The fundamental <b>diagram</b> <b>calibration</b> shows no capacity increments under DSL together with a significant critical occupancy value shift, when are compared with the non-DSL case. It is also reported certain vehicle speed and lane use (i. e. occupancy) homogenization over the DSL controlled sections. Postprint (published version...|$|R
40|$|Figure 1 : Visuo-haptic {{augmented}} reality {{system with a}} PHANToM haptic device. Virtual stylus overlaid (a) with joint angle cal-ibration only (b) with our additional gimbal angle <b>calibration.</b> (c) System <b>diagram</b> for workspace <b>calibration</b> demonstration with additional AR guides. Visuo-haptic {{augmented reality}} systems enable users to see and touch digital information that {{is embedded in the}} real world. Precise colocation of computer graphics and the haptic stylus is necessary to provide a realistic user experience. PHANToM haptic devices are often used in such systems to provide haptic feedback. They consist of two interlinked joints, whose angles define the position of the haptic stylus and three sensors at the gimbal to sense its ori-entation. Previous work has focused on a calibration procedures that align the haptic workspace within a global reference coordinate system and an algorithms that compensate the non-linear position error, which is caused by inaccuracies in the joint angle sensors. In our science and technology paper ”Comprehensive Workspace Calibration for Visuo-Haptic Augmented Reality ” [1], we present an improved workspace calibration that additionally compensates for errors in the gimbal sensors. This enables us to also align the orientation of the haptic stylus with high precision. To reduce the required time for calibration and to increase the sampling coverage, we utilize time-delay estimation to temporally align external sensor readings. This enables users to continuously move the haptic stylus during the calibration process, as opposed to commonly used point and hold processes. This demonstration showcases the complete workspace calibra-tion procedure as described in our paper including a mixed real-ity demo scenario, that allows users to experience the calibrated workspace. Additionally, we demonstrate an early stage of our pro-posed future work in improved user guidance during the calibration procedure using visual guides...|$|R

