18|23|Public
50|$|Kitcher's {{interest}} in cognition manifested early and {{has continued to}} shape and inform her work throughout her career. Her doctoral dissertation defended a psychological <b>continuity</b> <b>criterion</b> for personal identity but extended {{the scope of the}} psychological criterion beyond that traditionally posited to include broader and more abstract cognitive characteristics, such as cognitive approach or cognitive style. Since then her work has ranged widely from traditional philosophy of psychology, to Sigmund Freud, and ultimately to her greatest philosophical passion: Kant scholarship.|$|E
40|$|We {{develop a}} {{stochastic}} calculus for the fractional Brownian motion with Hurst parameter H> 1 2 using {{the techniques of}} the Malliavin calclulus. We establish estimates in Lp, maximal inequalities and a <b>continuity</b> <b>criterion</b> for the stochastic integral. Finally, we derive an Itô’s formula for integral processes...|$|E
30|$|Thus, Kolmogorov's <b>continuity</b> <b>criterion</b> {{implies that}} sub-fBm is Hölder {{continuous}} of order γ for any γ < H. But its increments are not stationary. More works for sub-fBm {{can be found}} in Bardina and Bascompte [16], Bojdecki et al. [17 – 19], Shen et al. [20 – 22], Tudor [23] and Yan et al. [24, 25].|$|E
30|$|We may {{remove the}} <b>continuity</b> <b>criteria</b> on T in Theorem  15 as follows.|$|R
40|$|We {{study the}} {{continuity}} of mappings of finite distortion, a set of mappings intended to model elastic deformations in non-linear elasticity. We focus on <b>continuity</b> <b>criteria</b> for the inner-distortion function and prove that certain modulus of continuity estimates are sharp, i. e. cannot be im- proved. We also give a proof of {{the continuity of}} mappings of finite distortion under simplified conditions on the integrability of the distortion function. ...|$|R
40|$|We {{consider}} {{a family of}} stochastic processes {X_t^ϵ, t ∈ T} on a metric space T, with a parameter ϵ↓ 0. We study {{the conditions under which}} _→ 0 (_t ∈ T |X_t^| < δ) = 1 when one has the a priori estimate on the modulus of continuity and the value at one point. We compare our problem to the celebrated Kolmogorov <b>continuity</b> <b>criteria</b> for stochastic processes, and finally give an application of our main result for stochastic intergrals with respect to compound Poisson random measures with infinite intensity measures. Comment: Referee comments incorporated, the main result is stated in a more general for...|$|R
40|$|The {{contemporary}} {{problem of}} personal identity {{can be traced}} to Locke's initial formulation of the problem, and to the difficulties inherent in his solution. Following Locke, the favoured view in contemporary literature is that the primary locus of personal identity is in a person's psychological states or mind, to the exclusion of other factors, such as a person's body, or a person's environment. This thesis critically challenges the view that psychological continuity alone grounds personal identity. In addressing the psychological <b>continuity</b> <b>criterion,</b> I argue that the most fully developed version of this criterion contains untenable presuppositions about the nature of psychological states. In particular, I argue that the thought experiments advanced in support of the psychological <b>continuity</b> <b>criterion</b> are not adequate to establish that psychological continuity alone grounds personal identity. I also challenge the internalist conception of mental states implicit in the psychological <b>continuity</b> <b>criterion,</b> and the commitment to an atomistic, owner-independent characterisation of mental states. I argue instead for a characterisation that is holistic and owner-dependent. I also defend the view that the body plays a positive role in personal identity, and that self-unity is a necessary condition for the possibility of experience. Throughout the thesis there is a strong commitment to the view that conceptual analysis alone is insufficient to solve the crucial issues involved in personal identity. There is, therefore, a significant utilisation of current empirical research and studies to support this commitment. Throughout the thesis also, attention is paid to the ethical implications of the psychological continuity criterion's conception of personhood, and to the practical consequences which are likely to be involved in this conception, were it to be adopted...|$|E
40|$|Abstract – In {{this paper}} a stereovision method is {{described}} developed for autonomous vehicle navigation in unstructured terrain. The {{disparity between the}} stereo image sequences is calculated with sub-pixel accuracy. Robust distance values are obtained by adding a <b>continuity</b> <b>criterion</b> term in the evaluation criterion and by using confidence measures for the found disparities. From the disparities a height map is calculated. Path planning is based on these height maps avoiding negative and positive obstacles. The viability of the approach is shown from real stereo image sequences of unstructured terrain...|$|E
40|$|We {{consider}} {{a family of}} stochastic processes on a metric space T, with a parameter [epsilon][downwards arrow] 0. We study {{the conditions under which}} when one has an a priori estimate on the modulus of continuity and the value at one point. We compare our problem to the celebrated Kolmogorov continuity criteria for stochastic processes, and finally give an application of our main result for stochastic integrals with respect to compound Poisson random measures with infinite intensity measures. Compensated Poisson random measure Generic chaining Kolmogorov <b>continuity</b> <b>criterion</b> Metric entropy Suprema of stochastic processes...|$|E
40|$|We {{show that}} {{the law of the}} overall {{supremum}} X_t=_s 0, if and only if the resolvent measure of X is absolutely continuous. We also study the cases where 0 is not regular for one of the halflines (-∞, 0) or (0,∞). Then we give absolute <b>continuity</b> <b>criterions</b> for the laws of (X_t,X_t), (g_t,X_t) and (g_t,X_t,X_t), where g_t is the time at which the supremum occurs before t. The proofs of these results use an expression of the joint law (g_t∈ ds,X_t∈ dx,X_t∈ dy) in terms of the entrance law of the excursion measure of the reflected process at the supremum and that of the reflected process at the infimum. As an application, this law is made (partly) explicit in some particular instances...|$|R
40|$|This article {{discusses}} harmonic sinusoid modeling. Unlike standard sinusoid analyzers, {{the harmonic}} sinusoid analyzer keeps {{close watch on}} partial harmony from {{an early stage of}} modeling, therefore guarantees the harmonic relationship among the sinusoids. The key element in harmonic sinusoid modeling is the harmonic sinusoid particle, which can be found by grouping short-time sinusoids. Instead of tracking short-time sinusoids, the harmonic tracker operates on harmonic particles directly. To express harmonic partial frequencies in a compact and robust form, we have developed an inequality-based representation with adjustable tolerance on frequency errors and inharmonicity, which is used in both the grouping and tracking stages. Frequency and amplitude <b>continuity</b> <b>criteria</b> are considered for tracking purpose. Numerical simulations are performed on simple synthesized signals. 1...|$|R
40|$|We {{show that}} {{the law of the}} overall {{supremum}} overline{X}_{t}=sup_{slet}X_{s}overline{X}_{t}=sup_{slet}X_{s} of a Lévy process XX, before the deterministic time tt is equivalent to the average occupation measure μ+t(dx) =∫t 0 P(Xs∈dx) dsmu_{t}^{+}(dx) =int_{ 0 }^{t}mathbb{P} (X_{s}in dx),ds, whenever 0 is regular for both open halflines (−∞, 0) (-infty, 0) and (0,∞) (0,infty). In this case, P(X¯¯¯t∈dx) mathbb{P} (overline{X}_{t}in dx) is absolutely continuous for some (and hence for all) t> 0 t> 0 if and only if the resolvent measure of XX is absolutely continuous. We also study the cases where 0 is not regular for both halflines. Then we give absolute <b>continuity</b> <b>criterions</b> for the laws of (gt,X¯¯¯t) (g_{t},overline{X}_{t}) and (gt,X¯¯¯t,Xt) (g_{t},overline{X}_{t},X_{t}), where gtg_{t} is the time at which the supremum occurs before tt. The proofs of these results use an expression of the joint law P(gt∈ds,Xt∈dx,X¯¯¯t∈dy) mathbb{P} (g_{t}in ds,X_{t}in dx,overline{X}_{t}in dy) in terms of the entrance law of the excursion measure of the reflected process at the supremum and that of the reflected process at the infimum. As an application, this law is made (partly) explicit in some particular instances...|$|R
40|$|This paper {{reviews the}} {{derivative}} method and explores its capac-ity for estimating time-varying sinusoids of complicated parame-ter variations. The method is reformulated on a generalized sig-nal model. We show that under certain arrangements the estima-tion task becomes solving a linear system, whose coefficients can be computed from discrete samples using an integration-by-parts technique. Previous derivative and reassignment methods are {{shown to be}} special cases of this generic method. We include a discussion on the <b>continuity</b> <b>criterion</b> of window design for the derivative method. The effectiveness of the method and the win-dow design criterion are confirmed by test results. We also show that, thanks to the generalization, off-model sinusoids can be ap-proximated by the derivative method with a sufficiently flexible model setting. 1...|$|E
40|$|We {{advocate}} {{the use of}} an Indirect Inference method to estimate the parameter of a COGARCH process for equally spaced observations. This requires that the true model can be simulated and a reasonable estimation method for an approximate auxiliary model. We follow previous approaches and use linear projections leading to an auxiliary autoregressive model for the squared COGARCH returns. The asymptotic theory of the Indirect Inference estimator relies on a uniform SLLN and asymptotic normality of the parameter estimates of the auxiliary model, which require continuity and differentiability of the COGARCH process with respect to its parameter and which we prove via Kolmogorov's <b>continuity</b> <b>criterion.</b> This leads to consistent and asymptotically normal Indirect Inference estimates under moment conditions on the driving Lévy process. A simulation study shows that the method yields a substantial finite sample bias reduction compared to previous estimators. Comment: 40 page...|$|E
40|$|The {{seventeenth century}} Muslim philosopher Muhammad Sadr al-Din Shirazi, known as Mulla Sadra, {{introduced}} {{the idea of}} substantial motion in Islamic philosophy. This view {{is characterized by a}} <b>continuity</b> <b>criterion</b> for diachronic identity, a four-dimensional view of individual substances, the notion that possibilities change, and the continual creation of all creatures. Modern philosophical logic provides means to model a variety of claims about individuals, substances, modality and time. In this paper, the semantics of formal systems discussed by Carnap, Bressan and Gupta are reviewed with regard to the issue of substance and identity. Next a model introduced by Storrs McCall is described that is able to build upon and yet resolve some of the issues about substance and identity as characterized by Bressan and others. McCall’s model is also shown to be able to provide an illustration of Mulla Sadra’s doctrine of substantial motion...|$|E
50|$|This sort of {{approach}} to the thought experiment appears to show that since the person who expresses the psychological characteristics of person A to be person A, then intuition is that psychological <b>continuity</b> is the <b>criterion</b> for personal identity.|$|R
30|$|Time {{of union}} was {{determined}} according to both radiological and clinical parameters. Radiological criteria included: bridging of the fracture site by bone, callus or trabeculae; bridging of the fracture {{seen at the}} cortices; and obliteration of the fracture line or cortical <b>continuity.</b> Clinical <b>criteria</b> were represented by the patient’s ability to bear weight on the injured limb and perform activities of daily living, {{and the presence of}} pain at the fracture site upon palpation and physical stress.|$|R
40|$|This paper {{presents}} {{a framework for}} nonlinear dimensionality reduction methods aimed at projecting data on a non-Euclidean manifold, when their structure is too complex to be embedded in an Euclidean space. The methodology proposes an optimization procedure on manifolds to minimize a pairwise distance criterion that implements a control of the trade-off between trustworthiness and <b>continuity,</b> two <b>criteria</b> that, respectively, represent the risks of flattening and tearing the projection. The methodology is presented as general as possible and is illustrated in the specific case of the sphere. (C) 2009 Elsevier B. V. All rights reserved...|$|R
40|$|The wave {{equation}} _g_M,aψ= 0 on subextremal Kerr spacetimes (M_M,a,g_M,a), 0 0. Exponentially growing modes are also obtained after perturbing the potential V. Then, as {{an application of}} the above result, we construct a family of spacetimes (M_M,a,g_M,a^(def)) which are compact in space perturbations of (M_M,a,g_M,a), have the same symmetries as (M_M,a,g_M,a) and moreover admit real and exponentially growing modes. These spacetimes contain stably trapped null geodesics, but we also construct a more complicated family of spacetimes with normally hyperbolic trapped set, admitting real and exponentially growing modes, {{at the expense of}} having conic asymptotics. The above results are in contrast with the case of stationary asymptotically flat (or conic) spacetimes (M,g) with a globally timelike Killing field T, where real modes for equation _gψ-Vψ= 0 are always absent, giving a useful zero-frequency <b>continuity</b> <b>criterion</b> for showing stability for a smooth family of equations _gψ-V_λψ= 0, with λ∈[0, 1] and V_ 0 = 0. We show explicitly that this criterion fails on Kerr spacetime. Comment: 67 page...|$|E
40|$|This thesis tackles the {{manipulation}} planning for documented objects. The {{difficulty of the}} problem is the coupling of a symbolic and a geometrical problem. Classical approaches combine task and motion planning. They are hard to implement and time consuming. This approach is different on three aspects. The first aspect is a theoretical framework to model admissible motions of the robot and objects. This model uses constraints to link symbolic task and motions achieving such task. A graph of constraint models {{the manipulation}} rules. A planning algorithm using this graph is proposed. The second aspect is the handling of constrained motion. In manipulation planning, an abstract definition of numerical constraint is necessary. A <b>continuity</b> <b>criterion</b> for Newton-Raphson methods is proposed to ensure the continuity of trajectories in sub-manifolds. The last aspect is object documentation. Some information, easy to define for human beings, greatly speeds up the search. This documentation, specific to each object and end-effector, is used to generate a graph of constraint, easing the problem specification and resolution...|$|E
40|$|Multifractal {{analysis}} of stochastic processes {{deals with the}} fine scale properties of the sample paths and seeks for some global scaling property that would enable extracting the so-called spectrum of singularities. In this paper we establish bounds on {{the support of the}} spectrum of singularities. To do this, we prove a theorem that complements the famous Kolmogorov's <b>continuity</b> <b>criterion.</b> The nature of these bounds helps us identify the quantities truly responsible for the support of the spectrum. We then make several conclusions from this. First, specifying global scaling in terms of moments is incomplete due to possible infinite moments, both of positive and negative order. For the case of ergodic self-similar processes we show that negative order moments and their divergence do not affect the spectrum. On the other hand, infinite positive order moments make the spectrum nontrivial. In particular, we show that the self-similar stationary increments process with the nontrivial spectrum must be heavy-tailed. This shows that for determining the spectrum it is crucial to capture the divergence of moments. We show that the partition function is capable of doing this and also propose a robust variant of this method for negative order moments...|$|E
40|$|Little {{empirical}} evidence {{is available on}} older adults regarding {{the existence of a}} continuum between "normal" personality traits and DSM-IV-TR Axes I and II disorders (American Psychiatric Association, 2000). Given the typical complexity of clinical presentations in advanced age, it is feasible to expect a dimensional conceptualization of psychopathology to apply to older adults. In this pilot investigation, we first tested age differences in psychopathology, upholding the view that older adults should be considered separately from younger individuals in research on psychopathology. Then, in support of the dimensional approach, we tested the hypothesized continuity between normality and psychopathology by verifying the fulfillment of two operational <b>criteria</b> of <b>continuity.</b> A non-clinical sample of 100 Italian respondents was divided into two groups (50 people per group, 25 women and 25 men), aged 25 - 64 and 65 - 84, respectively. The instruments used were a measure of normal personality, SFERAS (Boncori & Barruffi, 2004) and one of Axes I and II psychopathology, TALEIA- 400 A (Boncori, 2007). MANOVA analyses demonstrated a significant effect on both measures, with older adults achieving higher Axis I scores and higher scores on normal personality traits connected to anxiety. The continuum hypothesis was confirmed on older and younger adults through correlational analyses that verified the fulfillment of both <b>continuity</b> <b>criteria.</b> Our results show that Italian older adults differ significantly in psychopathology from younger individuals; however, contrary to findings from other countries, in a negative direction. The continuity results (although in need of replication with larger samples, utilizing statistical methods better suited for these analyses, such as taxometric procedures) offer preliminary support for the notion that the dimensional approach to psychopathology could work well in older age...|$|R
30|$|All the {{radiographic}} measurements, including palmar tilt, radial inclination and ulnar variance, {{were performed}} on the last follow-up X-rays using a picture archiving and communication system (PACS software, Fuji Synapse). Time of union was determined according to both radiological and clinical parameters. Radiological criteria included: bridging of the fracture site by bone, callus or trabeculae; bridging of the fracture seen at the cortices; and obliteration of the fracture line or cortical <b>continuity.</b> Clinical <b>criteria</b> were represented by the patient’s ability to bear weight on the injured limb and perform activities of daily living, {{and the presence of}} pain at the fracture site upon palpation and physical stress. Moreover, possible early or late complications such as non-union, infection, tendon rupture or tendon irritation, and nervous lesions were documented.|$|R
40|$|Methods {{of ceramic}} {{chronology}} building {{are based on}} certain assumptions concerning the pattern of stylistic change in ceramics. These assumptions are, however, not necessarily identical in different methods. Also, the general applicability of the assumptions in each method is not endorsed by solid empirical observations of stylistic change in ceramics and theoretical considerations concerning processes producing stylistic change in ceramics. The inapplicability of assumptions of a method undermines the reliability of ceramic chronology created by the method. In order to evaluate the reliability of existing ceramic chronologies, (1) theoretical considerations were made concerning processes producing stylistic change in ceramics and (2) empirical observations were made concerning aspects of stylistic change in ceramics in a well-controlled archaeological setting, i. e., stylistic change of Tusayan White and Gray Wares in the American Southwest between A. D. 850 and 1150 where tree-ring dating is available as an independent means of temporal control. As a result, {{it was revealed that}} (1) substantial temporal overlap can be present in the manufacture of successive styles of ceramics, (2) <b>continuity</b> <b>criteria</b> of the typological method are not necessarily applicable to stylistic change in ceramics even in a continuous population, and (3) significantly large time lags can be present in the diffusion of manufacturing frequencies of styles even within an area in which the styles are shared. In light of these findings, the typological method cannot be accepted as a method of ceramic chronology building. Occurrence and frequency seriations are, on the other hand, acceptable methods. However, for reliable chronological seriation attention must be paid to potential errors caused by contemporaneous variation of stylistic compositions among assemblages due to time lags in diffusion and variation in generational composition of individuals who produced assemblages...|$|R
40|$|International audienceWe give {{an account}} of results already {{obtained}} in the direction of regularity of solution of Lipschitzian SDE by Dirichlet forms methods and we present in details a new example which gives rise to an extension of the stochastic calculus. The first part introduces the framework of the Dirichlet space related to the Ornstein-Uhlenbeck semigroup on the Wiener space and recalls the absolute <b>continuity</b> <b>criterion</b> for functionals and some consequences on Lipschitz SDE. The second part is devoted to the regularity of solutions of Lipschitz SDE with respect to initial data. It is shown that the solution is differentiable in a slightly weakened sense. That gives for example the following simple result: under these hypotheses, if the initial variable Xo has a density, then X(t) has a density for all t. It is shown in the third part, that the solutions of Lipschitz SDE can be refined, by taking quasi-continuous versions for each t, into processes with continuous paths outside a polar set and unique up to a quasi- evanescent set. The main tool here is an extension of the Kolmogorov theorem on existence of continuous versions to the case where the measure is changed to a capacity...|$|E
40|$|WOSInternational audienceOne of {{the most}} {{challenging}} applications of time-frequency representations deals with the analysis of the signal issued from natural environment. Recently, the interest for passive underwater context increased, basically due to the rich information carried out by the natural signals. Taken into account the non-linear multi-component time-frequency behaviour of such signals, their analysis is a challenging problem. In this context, the analysis of underwater mammal's whistles is aimed to extract, accurately and adaptively, their main time-frequency components. In this paper, we define a time-frequency-phase tracker which is composed of three steps. The first one consists of modelling the short-time segments of the vocalization by a set of third order polynomial phase modulations. The second step consists in the fusion of local polynomial phase modulations according to a local phase <b>continuity</b> <b>criterion.</b> Finally, in the third step, the detected time-frequency track is used to design the time-frequency filter, in charge of extracting the samples corresponding to the detected track. This procedure is then iterated until all component of interest are extracted. Tests provided for realistic scenarios and real data taken in Bay of Biscay at September 2009 containing whistles of common dolphin Delphinus delphis illustrate the potential and the benefits of the proposed approach...|$|E
40|$|Abstract. Forests {{are among}} the most {{important}} habitats of the Earth for several ecological reasons and their management is a prior task when dealing with landscape conservation. Thematic maps and remote sensing data are powerful tools to be used in landscape planning and forest management; nevertheless, most of the European and Mediterranean forest monitoring and conservation programs do {{not take into account the}} continuity of the variation of habitats within the landscape but they only rely on boolean classification methods. The utilisation of a classification method that applies a <b>continuity</b> <b>criterion</b> is fundamental because it is expected to better represent the ecological gradients within a landscape. The aim of this paper is to assess the amount of classification uncertainty related to crisp (boolean) classes, particularly focusing on forest identification uncertainty. Forest fuzzy membership of the Tuscany region (Italy) derived from a Landsat ETM+ image scene was compared with the widely used crisp datasets in European forests management and conservation practices, i. e. the European JRC Forest/Non-Forest map, the CORINE Land Cover 2000 (levels 1 and 2), as well as the Global Land Cover 2000, in order to qualitatively and quantitatively assess the separability of crisp classes with respect to forest fuzzy membership. A statistically significant (p < 0. 001) forest fuzzy membership separability among the considered crisp classes was found. Despite the crisp dataset and hierarchical level taken into account...|$|E
50|$|In {{the first}} approach, intuition {{is to show}} that one's {{psychological}} <b>continuity</b> is the <b>criterion</b> for personal identity, but in second approach, intuition is that it is one's bodily continuity that is the criterion for personal identity. To resolve this conflict Williams feels one's intuition in the second approach is stronger and if he was given the choice of distributing a punishment and a reward he would want his body-person to receive the reward and the other body-person to receive the punishment, even if that other body-person has his memories.|$|R
5000|$|In {{the field}} of complex {{analysis}} in mathematics, the Cauchy-Riemann equations, named after Augustin Cauchy and Bernhard Riemann, consist {{of a system of}} two partial differential equations which, together with certain <b>continuity</b> and differentiability <b>criteria,</b> form a necessary and sufficient condition for a complex function to be complex differentiable, that is, holomorphic. This system of equations first appeared in the work of Jean le Rond d'Alembert [...] Later, Leonhard Euler connected this system to the analytic functions [...] [...] then used these equations to construct his theory of functions. Riemann's dissertation [...] on the theory of functions appeared in 1851.|$|R
40|$|This paper {{presents}} a new method of model selection for regression problems using the modulus of continuity. For this purpose, we suggest the prediction risk bounds of regression models using the modulus of continuity {{which can be}} interpreted as the complexity of functions. We also present the model selection criterion referred to as the modulus of <b>continuity</b> information <b>criterion</b> (MCIC) which is derived from the suggested prediction risk bounds. The suggested MCIC provides a risk estimate using the modulus of continuity for a trained regression model (or an estimation function) while other model selection criteria such as the AIC and BIC use structural information such as the number of training parameters. As a result, the suggested MCIC is able to discriminate the performances of trained regression models, even with the same structure of training models. To show the effectiveness of the proposed method, the simulation for function approximation using the multilayer perceptrons (MLPs) was conducted. Through the simulation for function approximation, it was demonstrated that the suggested MCIC provides a good selection tool for nonlinear regression models, even with the limited size of data...|$|R
40|$|Abstract—An {{unsupervised}} learning algorithm for {{the separation of}} sound sources in one-channel music signals is presented. The algorithm is based on factorizing the magnitude spectrogram of an input signal into a sum of components, {{each of which has}} a fixed magnitude spectrum and a time-varying gain. Each sound source, in turn, is modeled as a sum of one or more components. The parameters of the components are estimated by minimizing the reconstruction error between the input spectrogram and the model, while restricting the component spectrograms to be nonnegative and favoring components whose gains are slowly varying and sparse. Temporal continuity is favored by using a cost term which is the sum of squared differences between the gains in adjacent frames, and sparseness is favored by penalizing nonzero gains. The proposed iterative estimation algorithm is initialized with random values, and the gains and the spectra are then alternatively updated using multiplicative update rules until the values converge. Simulation experiments were carried out using generated mixtures of pitched musical instrument samples and drum sounds. The performance of the proposed method was compared with independent subspace analysis and basic nonnegative matrix factorization, which are based on the same linear model. According to these simulations, the proposed method enables a better separation quality than the previous algorithms. Especially, the temporal <b>continuity</b> <b>criterion</b> improved the detection of pitched musical sounds. The sparseness criterion did not produce significant improvements. Index Terms—Acoustic signal analysis, audio source separation, blind source separation, music, nonnegative matrix factorization, sparse coding, {{unsupervised learning}}. I...|$|E
40|$|The aim of {{this paper}} is to analyze the {{announcement}} e¤ects on ex-change rate movements using the basic asset pricing model, where cur-rency trade is partly determined by technical trading in the form of mov-ing averages since it is the most commonly used technique according to questionnaire surveys. Speci 8 ̆ 5 cally, the announcement and implementa-tion of temporary as well as permanent monetary policy are analyzed, where the exchange rate model developed is summarized in a linear dif-ference equation in current exogenous fundamentals, a large number of lags of the endogenous exchange rate and time-t dating of exchange rate expectations. However, since there are a large number of rational expec-tations equilibria, continuity is proposed as a selection criterion among the equilibria, meaning that the parameter for the time-t 1 exchange rate should have the limit 0 when there is no technical trading to have an economically meaningful equilibrium. It turns out that there is a unique rational expectations equilibrium that satisfy the <b>continuity</b> <b>criterion,</b> and focusing on this equilibrium, it is shown that the exchange rate is much more sensitive to changes in money supply than when technical trading is absent in currency trade. This result is important since it sheds light on the so-called exchange rate disconnect puzzle in international 8 ̆ 5 nance. Earlier versions of this paper has been presented at WEHIA, in Colchester, England, June 13 - 15, 2005, and at seminars at the Bank of Finland, HECER and RUESG. I am grateful for helpful comments given at these occasions as well as to Seppo Honkapohja for discussing the paper with me. I am also grateful to the OP Bank Group Foundation for giving me a research grant. Of course, the usual disclaimer applies. y JEL classi 8 ̆ 5 cation: E 51, E 52, F 31 and G 12...|$|E
40|$|Water and {{sanitation}} services provide a cost-effective solution for alleviating {{the impact of}} water-borne diseases. Actually, for water supply projects a top-down approach is followed, giving priority to deliver sufficient quantities of water, increasing its availability by investment in new systems. Little {{attention is paid to}} the functioning of these systems on the long-term, and its maintenance and operational constraints. In this paper, a methodology was developed to technically assess water supply systems based on four criteria, namely availability, capacity, continuity and condition. The practicality of the approach is demonstrated by a technical assessment of a number of water supply systems in the Vhembe District in South Africa. The systems consist of piped distribution systems with public standpipes, mostly fed by groundwater. In general, it can be concluded that the performance of the systems, although relatively new, is poor. The availability (criterion 1) of the drinking water is a problem due to poorly constructed boreholes or disagreement on the payment of the operational cost after construction. In most villages the capacity (criterion 2) of the installed infrastructure is sufficient, although storage volume is in some villages too small. The <b>continuity</b> (<b>criterion</b> 3) of the water supply is threatened by disputes about payment of diesel for the pump and maintenance and repair of the pump. Finally, the condition (criterion 4) is poor mostly due to taps at the standpipes which are damaged and require frequent replacement. Despite the simplicity of the proposed assessment methodology, it provides rapid insight in the state of a system and is ideal for bench marking the performance of different systems in different regions. Furthermore, the quantitative measures of the four different criteria allow system operators and planners to rapidly pinpoint the reasons for poor performance and to take the appropriate corrective action. The used weighting factors in this demonstration are arbitrary – different users could adapt them to their own specific situations without invalidating the overall approach to technical assessment suggested in this paper...|$|E
40|$|International audienceWe {{develop an}} existence, {{regularity}} and potential theory for nonlinear integrodifferential equations involving measure data. The nonlocal elliptic operators considered are possibly degenerate {{and cover the}} case of the fractional p-Laplacean operator with measurable coefficients. We introduce a natural function class where we solve the Dirichlet problem, and prove basic and optimal nonlinear Wolff potential estimates for solutions. These are the exact analogs of the results valid in the case of local quasilinear degenerate equations established by Boccardo & Gallouët BG 1, BG 2 and Kilpeläinen & MalýKM 1, KM 2. As a consequence, we establish a number of results which can be considered as basic building blocks for a nonlocal, nonlinear potential theory: fine properties of solutions, Calderón-Zygmund estimates, <b>continuity</b> and boundedness <b>criteria</b> are established via Wolff potentials. ...|$|R
40|$|A {{procedure}} involving simultaneous {{experimental and}} numerical research is described {{for the purposes}} of understanding the mechanisms involved when extreme precipitation is transformed to flood stream discharge. It is shown that experiments and model applications by themselves are not sufficient for process identification, but that their combined application provides considerable insight into the subsurface flow processes. The proposed approach is unconventional in that a numerical model, based on stringent <b>continuity</b> and momentum <b>criteria,</b> is used as a tool for process identification only. Unlike other studies, it is not intended to demonstrate the applicability of the utilised model for general hydrological applications, or to provide evidence of the suitability of particular model simplifications. Rather, different and sometimes conflicting model realisations are used to examine the plausibility of flow processes which may occur on natural hill slopes. Hereby, small scale effects such as those relating to the mechanisms of water entry into the macropores, and the movement of water to the surrounding matrix are identified from the results of well instrumented field experiments...|$|R
40|$|International audienceOn {{the basis}} of a recent work {{proposed}} by the authors on a double-minimization method for evaluating inter-element forces and stresses transmitted across mesh lines, the crack opening conditions at a corner node of the FE mesh, from where several lines (potential cracks) emanate, is examined in this paper. The study is developed locally as a post-processing step of a standard displacement-based FE calculation, in terms of an always-increasing external (macroscopic) load factor μ. The cracking laws for each potential crack line are assumed rigid-plastic with hyperbolic failure criterion in terms of normal and shear components of the stress traction at that point. It is observed that, as μ increases, in general such point may undergo up to four phases of evolution until a crack can effectively open through it. First, while stress tractions across mesh lines at the point are all below cracking criterion, forces may be evaluated with the double minimization method recently proposed. Second, cracking criterion is reached for one of the lines only. Stress evaluation requires a modified minimization method with one (hyperbolic) constraint; however, crack still does not open at the node {{because of the lack of}} kinematic <b>continuity.</b> Third, cracking <b>criterion</b> is satisfied for a second of the lines converging at the nodal point. Stress tractions may then be calculated with a system of equations involving the two hyperbolic constraints alone and no minimization is needed. But in general the through crack cannot open yet at this stage because of non-coincident flow rules, until either (i) a third line reaches the cracking criterion, or (ii) these get reoriented to exhibit parallel directions in the global reference system. Two simple examples of application are provided which illustrates the development of the various cracking stages and shows different situations that may take place...|$|R
