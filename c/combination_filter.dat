16|783|Public
40|$|The {{inversion}} of variations of terrestrial water storage by the earth time-variable gravity filed model {{makes a great}} contribution to global climate change, however, the spherical harmonics of time-variable gravity field have correlation problem and significant errors in high orders and degrees, and so optimal filtering method is needed to solve this problem. In this article, a new filter was devised named‘non-isotropic combination filter’, and showed a better performance. The basic idea of the new filter is to apply the Gaussian filter and the RMS filter to low-degree and high-degree harmonic coefficients separately. In this paper, we first analyze the error characteristics of the latest GRACE RL 05 series variable gravity field model, compare the validity and precision with Gaussian filter, improved Gaussian filter, RMS filter, DDK filter, the non-isotropic <b>combination</b> <b>filter</b> and verified them with the model. It shows that the mean square error of the non-isotropic <b>combination</b> <b>filter</b> and model is the least. Based on above analysis, {{we find that the}} non-isotropic <b>combination</b> <b>filter</b> can suppress the noises in high-degrees and high-orders, eliminate the N-S striping errors, lower signal leakage errors, improve the ratio of signal-to-noise more effectively compared with the previous filters...|$|E
40|$|Quality of {{fingerprint}} image is most essential to ensure good performance of minutiae extraction result since it depends {{heavily on the}} quality of {{fingerprint image}}s. Fingerprint image with noise usually will produce spurious minutiae. In this paper, new <b>combination</b> <b>filter</b> called Median Sigmoid (MS) filter is introduced to remove the unwanted noise created during the acquisition process and hence increasing the accuracy of minutiae extraction result. The result shows that MS filter is an effective filter in enhancing the quality of a noisy image...|$|E
30|$|Filter {{material}} {{may therefore}} be modelled {{as a single}} homogeneous porous medium (which does not require fine CFD mesh resolution). Coefficients can be determined experimentally by placing a sample filter of known cross-sectional area and thickness in a constant section duct flow. For that given filter material, it is then possible to use CFD to find the optimum cross-sectional area, thickness and orientation to minimise the losses for the combined filter/duct geometry <b>combination.</b> <b>Filter</b> life {{can also be considered}} using this approach; local rate of fouling is related to local flow velocity. By maximising filter area and ensuring as uniform a flow velocity over the whole filter area as possible, filter maintenance intervals will be maximised.|$|E
2500|$|ABEK, ABEK-P3, ABEK-HgP3 {{or other}} <b>combination</b> <b>filters</b> against {{multiple}} hazards ...|$|R
50|$|Data can be {{transformed}} before it is loaded into a destination table (e.g. Data <b>combination,</b> <b>filtering,</b> calculations, etc.). DMT can perform its own transformation with predefined functions and operators or let the target database perform the transformations with the target database set of functions and operators.|$|R
50|$|Potentiometers used in <b>combination</b> with <b>filter</b> {{networks}} act as tone controls or equalizers.|$|R
40|$|Abstract. For {{the output}} of {{photovoltaic}} generation is {{of the characteristics of}} intermittent and uncertainties because of the changes of weather, the application of mathematical morphological and backward difference in voltage disturbance detection of the PV system. In order to overcome the defects caused by using fixed structural elements in general morphological filters, a form of adaptive weighted <b>combination</b> <b>filter</b> combined morphological open and closed operation is put forward. A more effective algorithm is designed by weight adding combination of morphological operation to get better effect. Three cases of examples such as voltage liter, voltage dips and voltage interruption are simulated through Matlab. The result shows the method can quickly and accurately extract the dynamic characteristics of power quality parameters of PV system...|$|E
40|$|Abstract. The {{traditional}} <b>combination</b> <b>filter</b> {{method in}} the practical process is often {{two layers of}} composite filtering de-noising for the image containing the gaussian mixture noise and pulse noise. This paper proposes a three filter combination algorithm based on the two layers filters, To the Gaussian and pulse mixed noise of the remote sensing image, we use wavelet threshold de-nosing and adaptive median filter de-nosing, and then using the third layer adaptive Wiener filtering de-noising to remove the residual noise. Through theoretical analysis and practical application, the de-nosing results of this method is obvious in processing mixed noise of remote sensing image, this is a practical method of combination filtering de-noising, it can be widely used {{in the field of}} image processing...|$|E
40|$|The high-altitude {{electromagnetic}} pulse(HEMP) conducted {{environment and}} the HEMP radiated environment are established as {{the consequences of a}} high-altitude nuclear explosion. The IEC 61000 - 2 - 10, the international standard, defines the HEMP conducted environment. The IEC 61000 - 5 - 5 defines how protective devices for conducted distur-bance proposed for HEMP protection shall be specified. The IEC 61000 - 4 - 24 deals with methods for testing protective devices for HEMP conducted disturbance. The IEC 61000 - 4 - 24 : 1997 mainly describes the measurement method of small protective components. However, it does not provide the measurement method for a <b>combination</b> <b>filter</b> of a protective component and a filter which is widely used in recent. It is important to consider the characteristic of the measurement setup parameters like thickness and length of the cable and its height above ground plane etc. in establishing measurement setup because HEMP conducted disturbances include the frequency spectrum below 50 MHz. This paper deals with the optimized measurement method, considering the frequency spectrum of HEMP conducted disturbance...|$|E
40|$|Proportionate {{adaptive}} filters, such as {{the improved}} proportionate normalized least-mean-square (IPNLMS) algorithm, have been proposed for echo cancellation as an interesting alternative to the normalized least-mean-square (NLMS) filter. Proportionate schemes offer improved performance when the echo path is sparse, but are still subject to some compromises. In this paper, we study how combination schemes, where the output of two independent adaptive filters are adaptively mixed together, {{can be used to}} increase IPNLMS robustness to channels with different degrees of sparsity, as well as to alleviate the rate of convergence vs steady-state misadjustment tradeoff imposed by the selection of the step size. The advantages of these combined filters are illustrated in several echo cancellation scenarios. Index Terms — <b>Combination</b> <b>filters,</b> proportionate filters, echo cancellation, sparse channel identificatio...|$|R
30|$|It is {{possible}} to combine adaptive filters implementing different tasks or using different filter operating parameters, structures, and learning algorithms [30]. The recent examples of adaptive <b>filter</b> <b>combination</b> tasks include the <b>combination</b> of adaptive <b>filters</b> from different families such as one gradient and one Hessian based in [31], the adaptive <b>combination</b> of proportionate <b>filters</b> for sparse echo cancelation in [32], the adaptive combination of subband adaptive filters for acoustic echo cancelation in [33], the convex combination of H 2 and H∞ filters for space-time adaptive equalization in [34], the online tracking {{of the changes in}} the nonlinearity within a signal by using a collaborative adaptive signal processing approach based on a <b>combination</b> (hybrid) <b>filter</b> in [35], the adaptive combination of Volterra kernels and its application to nonlinear echo cancelation in [36], the convex combination of nonlinear adaptive filters for active noise control in [37], the <b>combination</b> of adaptive <b>filters</b> for relative navigation in [38], finite impulse response (FIR)-infinite impulse response (IIR) adaptive hybrid combination in [39], the affine combination of two adaptive sparse filters for estimating large-scale multiple-input multiple-output (MIMO) channels in [40], the combinations of multiple kernel adaptive filters in [41], the low-complexity approximation to the Kalman <b>filter</b> using convex <b>combinations</b> of adaptive <b>filters</b> from different families in [42], and the proposition of a family of combined-step-size proportionate filters in [43].|$|R
50|$|COSFIRE {{stands for}} <b>Combination</b> Of Shifted <b>FIlter</b> REsponses.|$|R
40|$|In Scandinavia, {{people live}} in climatic {{conditions}} that makes it favorable to stay indoors at wintertime. Norway has a relatively small population, even so Bergen and Oslo reaches annual average nitrogen dioxide concentrations equal to or above the levels in large European cities. Newspapers in Bergen recommend the population to stay indoors in urban areas that are highly polluted. Bergen municipality takes measurements of the outdoor pollution continuously, but more knowledge is needed on the propagation of the pollution from the outdoor and to the indoor environment. Danmarksplass intersection {{is one of the}} most trafficked and polluted areas in Bergen, Norway. Surrounding terrain and meteorological conditions during wintertime results in accumulation of local air pollution, locally known as the lid. Bergen municipality is then often obligated to implement mitigating actions. Particles and nitrogen oxides from traffic emissions has been recognized as a major contribution source to local air pollution. Nitrogen oxides are formed during combustion. Among the different nitrogen oxide components mainly nitrogen dioxide (NO 2) is associated with negative health effects. This study was set up to compare the effectiveness at reducing NO 2 -concentration from outdoor to indoor environment at an office building by a <b>combination</b> <b>filter</b> (active coal + particle) and a regular particle filter. In addition, NO 2 propagation from the location of the municipality instrument and mentioned office building was examined. Two Teledyne API 200 E direct reading instruments were used for measuring NO 2. The instruments were deployed outdoors and indoors at an office building. The measurements took place in January to March 2014, when the highest concentration of air pollution was expected. A total of 625 1 -hour mean values of NO 2 were included in the study. The results show that the NO 2 -concentrations are approximately 30 % lower at the location of the office building than the municipality deployed instrument. The results show that when a regular particle filter was used there was no reduction of the NO 2 -concentration. However, the combination- filter reduced the average indoor NO 2 - concentrations by approximately 70 % compared to outdoor level. Thus, when local historical data show that the outdoor NO 2 -concentration can reach levels close to or above the Norwegian Institute of Public Health recommendations, the present study indicates that it is advisable to install a <b>combination</b> <b>filter...</b>|$|E
40|$|Objective: To {{evaluate}} {{the impact of}} tube voltage, tube current, pulse number, and magnification factor on the image quality of a novel experimental set-up and the corresponding radiation. Materials and Methods: Six human temporal bones with cochlear implant were imaged using various tube voltages, tube currents, pulse numbers, and magnification. The effect of radiation was evaluated using a metaloxide semiconductor field-effect transistor (MOSFET) dosimeter device on an anthropomorphic RANDO RAN 102 male head phantom. A copper and aluminum <b>combination</b> <b>filter</b> was used for hardware filtration. Results: Overall, 900 frames, 11 mA, and 88 kV provided the best image quality. In temporal bones imaged with the optimized parameters, the cochlea, osseous spiral lamina, modiolus, stapes, round window niche, and oval window landmarks were demonstrated with anatomic structures still fully assessable in all parts and acceptable image quality. The most dominant contributor to the effective dose was bone marrow (36 %- 37 %) followed by brain (34 %- 36 %), remainder tissues (12 %), extra-thoracic airways (7 %), and oral mucosa (5 %). Conclusions: By {{increasing the number of}} frames, the image quality of the inner ear details obtained using the novel cone-beam computed tomography improved...|$|E
40|$|A new {{temporal}} gravity {{field model}} called WHU-Grace 01 s solely recovered from Gravity Recovery and Climate Experiment (GRACE) K-Band Range Rate (KBRR) data based on dynamic integral approach {{is presented in}} this paper. After meticulously preprocessing of the GRACE KBRR data, the root mean square of its post residuals is about 0. 2 micrometers per second, and seventy-two monthly temporal solutions truncated to degree and order 60 are computed for the period from January 2003 to December 2008. After applying the <b>combination</b> <b>filter</b> in WHU-Grace 01 s, the global temporal signals show obvious periodical change rules in the large-scale river basins. In terms of the degree variance, our solution is smaller at high degrees, and shows a good consistency {{at the rest of}} degrees with the Release 05 models from Center for Space Research (CSR), GeoForschungsZentrum Potsdam (GFZ) and Jet Propulsion Laboratory (JPL). Compared with other published models in terms of equivalent water height distribution, our solution is consistent with those published by CSR, GFZ, JPL, Delft institute of Earth Observation and Space system (DEOS), Tongji University (Tongji), Institute of Theoretical Geodesy (ITG), Astronomical Institute in University of Bern (AIUB) and Groupe de Recherche de Geodesie Spatiale (GRGS), which indicates that the accuracy of WHU-Grace 01 s has a good consistency with the previously published GRACE solutions...|$|E
40|$|Whether a two-color {{reproduction}} from a red {{and green}} additive process is acceptable depends largely {{on the nature of}} the scene and its illumination. Additive two-color reproduction will be explored here using different scene illuminants and also different red and green <b>filter</b> <b>combinations.</b> Two projection methods are also examined. Red and green separations were produced by photographing a scene through 16 different <b>filter</b> <b>combinations</b> and 3 different scene illuminants. These separations are then projected two different ways. One method involves projecting the separations back through the red and green filters they were taken through, while in the other method the green filter is removed and replaced with a neutral density. It was found that tungsten was the best scene illuminant at reproducing the original scene colors, and that the best overall <b>filter</b> <b>combination</b> at doing this was a 26, 61 Wratten <b>filter</b> <b>combination...</b>|$|R
40|$|<b>Combinations</b> of <b>filters</b> and subgrid scale stress {{models for}} large eddy {{simulation}} of the Navier-Stokes equations are examined by a priori tests and numerical simulations. The {{structure of the}} subgrid scales is found to depend strongly {{on the type of}} filter used, and consistency between model and filter is essential to ensure accurate results. The implementation of consistent <b>combinations</b> of <b>filter</b> and model gives more accurate turbulence statistics than those obtained in previous investigations in which the models were chosen independently from the filter. Results and limitations of the a priori test are discussed. The effect of grid refinement is also examined...|$|R
40|$|In {{the area}} of <b>combination</b> of {{adaptive}} <b>filters,</b> two main approaches, namely convex and affine combinations have been introduced. In this article, the relation between these two approaches is investigated. First, the problem of obtaining optimal convex combination coefficients is formulated as the projection of the optimal affine combination weights to the unit simplex in a weighted inner product space. Based on this formulation the closed form expressions for optimal combination weights and target MSE levels are obtained for two and three branch cases. Index Terms — adaptive <b>filtering,</b> <b>combination</b> of adaptive <b>filters,</b> projection to unit simplex 1...|$|R
30|$|Adaptive {{filtering}} algorithms promise {{an improvement}} of the active noise control (ANC) problem encountered in many scenarios. Just to name a few, the Filtered-X Least Mean Square (FXLMS) algorithm, the Leaky FXLMS (LFXLMS) algorithm, and other modified LMS-based algorithms have been developed and utilized to combat the ANC problem. All of these algorithms enjoy great performance when the signal-to-noise ratio (SNR) is high. On the other hand, when the SNR is low, which is a known trend in ANC scenarios, the performance of these algorithms is not attractive. The performance of the Least Mean Fourth (LMF) algorithm has never been tested on any ANC scenario under low or high SNR. Therefore, in this work, reflecting the development in the LMS family on the LMF, we are proposing two new adaptive filtering algorithms, which are the Filtered-X Least Mean Fourth (FXLMF) algorithm and the Leakage-based variant (LFXLMF) of the FXLMF algorithm. The main target of this work is to derive the FXLMF and LFXLMF adaptive algorithms, study their convergence behaviors, examine their tracking and transient conduct, and analyze their performance for different noise environments. Moreover, a convex <b>combination</b> <b>filter</b> utilizing the proposed algorithm and algorithm robustness test is carried out. Finally, several simulation results are obtained to validate the theoretical findings and show {{the effectiveness of the}} proposed algorithms over other adaptive algorithms.|$|E
40|$|Optical Engineering 44 (4), 047002 (April 2005) linear filters can {{be found}} in Ref. 2, where it was shown that order-statistic filters provide {{excellent}} robustness to es-timated filter parameters and performance for varying im-age characteristics. 3, 4 In addition, the operation of the basic order-statistics filter allows for both extendibility and com-patibility with new and existing algorithms. Possibly the most well-known order-statistics filter is the median filter. First introduced by Tukey 5 for time-series analysis, it quickly became a favorite among the image processing research community. This quick acceptance of the median filter was due primarily to its simplicity, both conceptually and in terms of computation, as well as its robustness and good performance. As such, the standard median filter operation has formed the basis for many so-phisticated order-statistics filters. Another very successful order-statistics filter is the L filter. 6 The L filter is derived from the set of robust estima-tors known as L estimators and is essentially a linear com-bination of order statistics. By selecting appropriate coeffi-cients, the L filter can be generalized to act as a median, midpoint, r-ranked, or a trimmed mean filter. 7, 8 An exten-sion to the L-filter technique is the weighted sum, or linear <b>combination,</b> <b>filter</b> operation, where a number of subfilter outputs are linearly combined. 9, 10 The majority of the L-filter processing operations such as coefficient optimization and the general form of the coefficient set is equal to unity. If we let C denote the coefficient set, i. e. ...|$|E
40|$|Advance {{in medical}} imaging {{technologies}} enables various imaging modalities such as ultrasound, MRI 	(magnetic resonance imaging), PET (positron emission tomography) and CT (computed tomography) to be 	used in medical diagnosis. However, their imaging performance {{is limited by}} various constraints. That causes 	degradation of the medical image quality. Especially, the hazard associated with X-ray exposure is greater for 	 3 D-CT methods such as MDCT (multi-detector row computed tomography) than for conventional CT. The 	best method of mitigating this hazard is to lower the X-ray dose level. However, the radiographic noise, i. e., 	quantum noise, in MDCT images increases when radiation exposure is reduced. Therefore, {{there is a strong}} 	desire to reduce patient dose and to improve image quality by increasing spatial resolution and decreasing 	quantum noise in MDCT modality. 	Although various image improvement and evaluation methods have been developed, they all focused on 	improving the image quality in a whole image or in an entire 3 D dataset. Their performance is not enough for 	the radiologists who should not miss the small tumors whose size is around 5 mm and preferably down to 2 	mm. To overcome these difficulties, this thesis proposes several linear and non-linear filtering methods to 	enhance the low-dose MDCT images according to the size and local voxel value distribution of the small 	regions which are suspected of tumors. 	Firstly, 3 D weighted average filter is designed to enhance the low-dose MDCT images. In order to retain 	the subtle characteristics of the small tumors, the center weight of the 3 D weighted average filter is given a large 	value. The other weights decrease with the increasing of the radius away {{from the center of the}} filter template. 	However, the 3 D weighted average filter is a linear filter. Therefore, edges and subtle structure of 	parenchyma are prone to be blurred to some degree after filtering. To alleviate this limitation, 3 D non-linear 	diffusion-based filter is designed to reduce the quantum noise as well as to maintain the subtle structure of the 	small tumors and the parenchyma. Experimental results show that the edges of the tumors remain well while 	the noise level has been lowered by this diffusion type filter. However, the point noises of the images are not be 	removed well, since this diffusion type filtering method can not distinguish noise candidates from the voxels 	with large gradients. Therefore a <b>combination</b> <b>filter</b> consisting of 3 D weighted average filter and 3 D non-linear 	diffusion based filter are proposed. 	To improve the quality of low-dose clinical MDCT images degraded by the quantum noise, a new 3 D 	adaptive median filter with local average (3 D AMLA) is also proposed. This new method differs from 	approaches in the literature since not only it is designed based on the size of the small tumors but also this 	scheme detects and replaces the noise candidates with local averaging according to the distribution of voxel 	value adaptively. In this study, the 2 D adaptive median filter (AM) is extended to 3 D AM to show the 	effectiveness of 3 D filtering, firstly. Then adaptive local averaging strategy is introduced to this 3 D AM. That is 	 3 D AMLA. The 2 D AM, 3 D AM and 3 D AMLA are applied to 80 -, 60 -, 40 - and 20 %-dose low-dose datasets. 	Image quality is assessed by visual evaluation, voxel value profiles and several quantitative methods, 	including newly proposed entropy of correlation (EC) and mutual information and correlation (MIC) which are 	developed according to the graininess correlation of the little intro-hepatic tumors in directions of X, Y and Z axes. Experimental results show the high performance of both the filtering and the evaluating methods and 	X-ray dose level can be reduced to a large degree by applying the 3 D AMLA and the <b>combination</b> <b>filter...</b>|$|E
40|$|A {{method is}} {{developed}} for extracting six degree-of-freedom stability and control derivatives from helicopter flight data. Different <b>combinations</b> of <b>filtering</b> and derivative estimate are investigated and {{used with a}} Bayesian approach for derivative identification. The <b>combination</b> of <b>filtering</b> and estimate found to yield the most accurate time response match to flight test data is determined and applied to CH- 53 A and CH- 54 B flight data. The method found to be most accurate consists of (1) filtering flight test data with a digital filter, followed by an extended Kalman filter (2) identifying a derivative estimate with a least square estimator, and (3) obtaining derivatives with the Bayesian derivative extraction method...|$|R
40|$|Thirty-one Canadian {{brands of}} {{fine-cut}} tobaccos for roll-your-own cigarettes (RYOs) were evaluated under standard conditions using mandated tube and <b>filter</b> <b>combinations.</b> Results indicate {{no evidence of}} {{a significant difference in the}} amounts of tar, nicotine, and carbon monoxide produced by the 31 brands. In addition, the data emphasize that it is primarily the tube and <b>filter</b> <b>combination</b> that determines delivery of toxic constituents...|$|R
50|$|Due to {{its broad}} specificity, the hAAG {{performs}} the substrate selection through a <b>combination</b> of selectivity <b>filters.</b>|$|R
40|$|This thesis {{describes}} innovative {{techniques for}} reducing speckle noise {{and improving the}} intensity profile of the speckle correlation fringes. The methods are based on reducing {{the range of the}} modulation intensity values of the speckle interference pattern. After the fringe pattern is corrected adaptively at each pixel, a simple morphological filtering of the fringes is sufficient to obtain smoothed fringes. The concepts are presented both analytically and by simulation by using computer-generated speckle patterns and experimental verifications are performed wherever possible. A new generalized method for designing continuous amplitude-only pupil filters for transverse superresolution using a nonlinear programming method is also presented. The thesis emphasises the principal advantage of amplitude-only filters over their phase-only counterparts, that the side lobe intensities can be highly reduced along with the spot size. A quantitative comparison with continuous phase-only filters as well as the two-zone binary phase filter is shown with respect to spot size and ratio of side lobe to central peak intensity. The work is extended to combine the advantages of amplitude and phase filters in one complex filter that performs better than either phase or amplitude filters designed so far. The performance here refers to having a smaller spot size along with higher peak to side lobe intensity ratio. Using numerical simulation the limitations of phase and amplitude filters are assessed. The experimental verification of the designed <b>combination</b> <b>filter</b> is performed with two LCD spatial light modulators used for displaying separately the phase and amplitude part of the filter. Results obtained from this setup confirm the simulation. Finally, the effect of optical superresolution on speckle correlations is studied. Simulations reveal that using a lateral super-resolution pupil filter more than twice the out of plane correlation length of the clear pupil can be achieved. This means that the measurement range in speckle correlation measurements doubles. To verify the correlation length an experiment is performed using a liquid crystal (LCD) spatial light modulator as a programmable superresolution filter. The results corroborate the simulation...|$|E
40|$|BACKGROUND: Exposure to {{particulate}} matter (PM) air pollution especially derived from traffic {{is associated with}} increases in cardiorespiratory morbidity and mortality. In this study, we evaluated the ability of novel vehicle cabin air inlet filters to reduce diesel exhaust (DE) -induced symptoms and markers of inflammation in human subjects. METHODS: Thirty healthy subjects participated in a randomized double-blind controlled crossover study where they were exposed to filtered air, unfiltered DE and DE filtered through two selected particle filters, one with and one without active charcoal. Exposures lasted for one hour. Symptoms were assessed before and during exposures and lung function was measured before and after each exposure, with inflammation assessed in peripheral blood five hours after exposures. In parallel, PM were collected from unfiltered and filtered DE and assessed for their capacity to drive damaging oxidation reactions in a cell-free model, or promote inflammation in A 549 cells. RESULTS: The standard particle filter employed in this study reduced PM 10 mass concentrations within the exposure chamber by 46 %, further reduced to 74 % by the inclusion of an active charcoal component. In addition use of the active charcoal filter was associated by a 75 % and 50 % reduction in NO 2 and hydrocarbon concentrations, respectively. As expected, subjects reported more subjective symptoms after exposure to unfiltered DE compared to filtered air, which was significantly reduced by the filter with an active charcoal component. There were no significant changes in lung function after exposures. Similarly diesel exhaust did not elicit significant increases {{in any of the}} inflammatory markers examined in the peripheral blood samples 5  hour post-exposure. Whilst the filters reduced chamber particle concentrations, the oxidative activity of the particles themselves, did not change following filtration with either filter. In contrast, diesel exhaust PM passed through the active charcoal <b>combination</b> <b>filter</b> appeared less inflammatory to A 549 cells. CONCLUSIONS: A cabin air inlet particle filter including an active charcoal component was highly effective in reducing both DE particulate and gaseous components, with reduced exhaust-induced symptoms in healthy volunteers. These data demonstrate the effectiveness of cabin filters to protect subjects travelling in vehicles from diesel exhaust emissions...|$|E
40|$|The {{access to}} clean water {{is one of}} the {{prerequisites}} for a modern, industrialized society. The amount of water withdrawn for human activities has risen exponentially during the last 100 years. This rise in water use is accompanied by the production of vast quantities of contaminated water. These wastewaters may be contaminated by substances ranging from heavy metals and organic compounds to nutrients like nitrogen and phosphorous. The aggregate effect of combinations of water contaminants can be difficult to predict as different contaminant substances may interact, leading to additive, synergistic or antagonistic toxic effects in a receiving aquatic ecosystem. With increasing water quality legislation, the pressure to characterize and potentially treat contaminated waters increases. Suitable effect-based assessment methods may greatly reduce the costs of both the wastewater characterization process and the water treatment evaluation. The overall aim of this thesis was to show how a combination of ecotoxicity bioassays may be employed in water treatment method development for initial characterization, assessment of treatment requirements and finally treatment evaluation. The wastewaters characterized originated from different activities such as waste management, metal surfacing and explosives destruction. To fully assess the hazard of the waters sampled, a holistic approach using a combination of chemical tests and bioassays was taken. A combination of acute and chronic assays was used to determine mode-of-action effects and apical endpoints in the aquatic environment. The basic battery consisted of the acute Vibrio fischeri test, the chronic algae test using Pseudokirchneriella subcapitata and either the planktonic crustacean Daphnia magna (for aqueous samples) or the meiobenthic crustacean Heterocypris incongruens (for whole-sediment/soil samples).  In addition to the basic test battery, the mode-of-action Salmonella typhimurium test was used to assess genotoxic effects. Results from the water hazard characterization show that ecotoxicological tests contribute to the evaluation of treatment methods for complex wastewaters by assessing the aggregate biological effect of water treatment. The tests may be used as a screening method to indicate where further treatment may be required, even when chemical measurements show a satisfactory reduction of known contaminants. The toxic effect exerted by the assessed waters did not always correlate with measured levels of contaminants or the chemical measures of bioavailability, e. g. leached fraction. The water treatment evaluation showed that the industrial by-product pine bark is an effective adsorbent for capturing metal contaminants from landfill leachates and stormwater. The pine bark column filter had higher zinc removal efficiency than the polonite filter and the <b>combination</b> <b>filter</b> column with pine bark/polonite. In conclusion, a pine bark filter is a suitable alternative to activated carbon for small-scale, decentralized treatment of wastewaters. Furthermore, the ecotoxicity tests were able to detect effects of unknown contaminants and provided unique characterization data, which complemented the information provided by the chemical analyses. CLEANBIORE...|$|E
5000|$|For {{a careful}} {{design of the}} {{regenerator}} and an appropriate <b>combination</b> of <b>filter</b> parameter (spectral offset and bandwidth) / fiber parameter (length, dispersion and nonlinearity values), a reduction of amplitude fluctuations can also be achieved, leading to power equalization of the pulse stream.|$|R
40|$|The aim of {{this study}} was to select the best <b>combination</b> of <b>filters</b> for {{detecting}} various weed species located within carrot rows. In-field images were taken under artificial lighting with a multispectral device consisting of a black and white camera coupled with a rotating wheel holding 22 interference filters in the VIS-NIR domain. Measurements were performed over a period of 19 days, starting 1 week after crop emergence (early weeding can increase yields) and seven different weeds species were considered. The selection of the best <b>filter</b> <b>combination</b> was based on a quadratic discriminant analysis. The best <b>combination</b> of <b>filters</b> included three interference filters, respectively centred on 450, 550 and 700 nm. With this combination, the overall classification accuracy (CA) was 72 %. When using only two filters, a slight degradation of the CA was noticed. When the classification results were reported on field images, a systematic misclassification of carrot cotyledons appears. Better results were obtained with a more advanced growth stage. (c) 2007 Elsevier B. V. All rights reserved. Peer reviewe...|$|R
2500|$|By default, 7-Zip creates 7z-format {{archives}} with a [...]7z file extension. Each archive {{can contain}} multiple directories and files. As a container format, security or size reduction are achieved using a stacked <b>combination</b> of <b>filters.</b> These can consist of pre-processors, compression algorithms, and encryption filters.|$|R
3000|$|... a white noise, unit {{variance}} drive. The {{voltage power}} spectrum for {{this model is}} a <b>combination</b> of low-pass <b>filters</b> [...]...|$|R
50|$|The gills lie on {{the inner}} surface of the carapace. The {{thoracic}} limbs wash water towards the mouth, filtering out small particles of food with the mouthparts or maxillipeds. Some species actively hunt prey, either as their only food source, or in <b>combination</b> with <b>filter</b> feeding.|$|R
40|$|We {{investigate}} possible diagnostics of {{the thermal}} structure of coronal loops from Hinode/XRT observations made with several filters. We consider {{the observation of}} an active region with five filters. We study various possible <b>combinations</b> of <b>filter</b> data to optimize for sensitivity to thermal structure and for signal enhancement...|$|R
40|$|Abstract. We {{consider}} {{the problem of}} finding a minimum diameter spanning tree with maximum node degree B in a complete undirected edge-weighted graph. We provide an O(logB n) -approximation algorithm for the problem. Our algorithm is purely combinatorial, and relies on a <b>combination</b> of <b>filtering</b> and divide and conquer...|$|R
40|$|Various <b>combinations</b> of <b>filters</b> and subgrid scale stress {{models for}} large eddy {{simulation}} of the Navier-Stokes equations are studied by a priori tests and numerical simulations. Consistency between model and filter {{is found to}} be essential to ensure accurate results. Results and limitations of the a priori test are discussed. The effect of grid refinement is also examined...|$|R
40|$|Sifted colimits, {{important}} for algebraic theories, are "almost" just the <b>combination</b> of <b>filtered</b> colimits and reflexive coequalizers. For example, given a finitely cocomplete category $cal A$, then a functor with domain $cal A$ preserves sifted colimits iff it preserves filtered colimits and reflexive coequalizers. But for general categories $cal A$ that statement is not true: we provide a counter-example...|$|R
