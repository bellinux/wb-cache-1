849|10000|Public
2500|$|In {{the episode}} [...] "In Security," [...] Don hides {{the level of}} {{intimacy}} he had with Leah Wexford and information contained in clearanced FBI files therein concerned, after she is killed. He appears close to her son, comforting him over his loss. Don feels overwhelmingly guilty, and so Charlie performs a <b>Classification</b> <b>And</b> <b>Regression</b> <b>Tree</b> (CART) analysis behind his back. The result shows {{that he was not}} responsible for her death, and that his assertions of such lessen Leah's bravery.|$|E
2500|$|An {{alternating}} {{decision tree}} consists of decision nodes and prediction nodes. [...] Decision nodes specify a predicate condition. [...] Prediction nodes contain a single number. [...] ADTrees always have prediction nodes as both root and leaves. [...] An instance is classified by an ADTree by following all paths for which all decision nodes are true and summing any prediction nodes that are traversed. [...] This {{is different from}} binary classification trees such as CART (<b>Classification</b> <b>and</b> <b>regression</b> <b>tree)</b> or C4.5 in which an instance follows only one path through the tree.|$|E
50|$|The term <b>Classification</b> <b>And</b> <b>Regression</b> <b>Tree</b> (CART) {{analysis}} is an umbrella {{term used to}} refer to both of the above procedures, first introduced by Breiman et al. Trees used for regression and trees used for classification have some similarities - but also some differences, such as the procedure used to determine where to split.|$|E
5000|$|... #Subtitle level 3: CART (<b>Classification</b> <b>and</b> <b>Regression</b> <b>Trees)</b> ...|$|R
5000|$|... #Subtitle level 4: <b>Classification</b> <b>and</b> <b>regression</b> <b>trees</b> (CART) ...|$|R
40|$|Binary {{segmentation}} procedures (in particular, <b>classification</b> <b>and</b> <b>regression</b> <b>trees)</b> are {{extended to}} study the relation between dissimilarity data {{and a set of}} explanatory variables. The proposed split criterion is very flexible, and can be applied {{to a wide range of}} data (e. g., mixed types of multiple responses, longitudinal data, sequence data). Also, it can be shown to be an extension of well-established criteria introduced in the literature on binary <b>trees.</b> Dissimilarity matrix <b>Classification</b> <b>and</b> <b>regression</b> <b>trees</b> Binary segmentation Multivariate responses Perception data Ecological data...|$|R
50|$|The Kerby {{method is}} similar to the Burgess method, but differs in two ways. First, while the Burgess method uses {{subjective}} judgment to select a cutoff score for a multi-valued predictor with a binary outcome, the Kerby method uses <b>classification</b> <b>and</b> <b>regression</b> <b>tree</b> (CART) analysis. In this way, the selection of the cutoff score is based not on subjective judgment, but on a statistical criterion, such as the point where the chi-square value is a maximum.|$|E
5000|$|In {{the episode}} [...] "In Security," [...] Don hides {{the level of}} {{intimacy}} he had with Leah Wexford and information contained in clearanced FBI files therein concerned, after she is killed. He appears close to her son, comforting him over his loss. Don feels overwhelmingly guilty, and so Charlie performs a <b>Classification</b> <b>And</b> <b>Regression</b> <b>Tree</b> (CART) analysis behind his back. The result shows {{that he was not}} responsible for her death, and that his assertions of such lessen Leah's bravery.|$|E
50|$|An {{alternating}} {{decision tree}} consists of decision nodes and prediction nodes. Decision nodes specify a predicate condition. Prediction nodes contain a single number. ADTrees always have prediction nodes as both root and leaves. An instance is classified by an ADTree by following all paths for which all decision nodes are true and summing any prediction nodes that are traversed. This {{is different from}} binary classification trees such as CART (<b>Classification</b> <b>and</b> <b>regression</b> <b>tree)</b> or C4.5 in which an instance follows only one path through the tree.|$|E
50|$|<b>Classification</b> <b>and</b> <b>regression</b> <b>trees</b> (CART) are a {{non-parametric}} {{decision tree}} learning technique that produces either classification or <b>regression</b> <b>trees,</b> {{depending on whether}} the dependent variable is categorical or numeric, respectively.|$|R
3000|$|... 50 estimators are {{employed}} in this work: non-intrusive room acoustic estimation using <b>classification</b> <b>and</b> <b>regression</b> <b>trees</b> (NIRA-CART) <b>and</b> non-intrusive room acoustic estimation using bidirectional long-short term memory (NIRA-BLSTM). In this work, we use C [...]...|$|R
40|$|Abstract—The paper {{deals with}} {{implementation}} of the <b>classification</b> <b>and</b> <b>regression</b> <b>trees</b> into the DMAIC phases of Six Sigma methodology. Six Sigma methodology seeks {{to improve the quality}} of manufacturing process by identifying and minimizing variability of this process. Using the <b>classification,</b> <b>regression</b> <b>and</b> segmentation <b>trees</b> as a part of the Data Mining methods could improve results of DMAIC phases. This improvement has a direct impact on the Sigma performanc...|$|R
5000|$|Used by the CART (<b>classification</b> <b>and</b> <b>regression</b> <b>tree)</b> algorithm, Gini {{impurity}} is {{a measure}} of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset. Gini impurity can be computed by summing the probability [...] of an item with label [...] being chosen times the probability [...] of a mistake in categorizing that item. It reaches its minimum (zero) when all cases in the node fall into a single target category.|$|E
50|$|More recently, a {{study of}} {{symptomatic}} children in Mali has led to increased interest in specific sets of EAEC virulence factors. The study utilized <b>Classification</b> <b>and</b> <b>Regression</b> <b>Tree</b> analysis, or CART analysis, to identify sets of EAEC factors which were implicated in virulence amongst pediatric patients who presented with acute diarrhea. The researchers found that a subset which encoded the gene for the cryptic serine protease SepA, previously described in Shigella, and lacking the transcriptional regulator of hemolysin expression, rmoA were associated with virulence. Furthermore, a set of EAEC which encoded the flagellar antigen H33 and the EAST-1 toxin were associated with diarrhea. These results and more recent efforts have suggested that {{a specific set of}} virulence determinants may be more important in pathogenesis of EAEC than {{the presence or absence of}} singular virulence factors.|$|E
50|$|CRE {{resistance}} {{depends upon}} {{a number of}} factors such as the health of the patient, whether the patient has recently undergone a transplant, risk of co-infection, and use of multiple antibiotics. Carbapenem minimal inhibitory concentrations (MICs) results may be more predictive of clinical patient outcomes than the current categorical classification of the MICs being listed as susceptible, intermediate, or resistant. The study aimed to define an all-cause hospital mortality breakpoint for carbapenem MICs that were adjusted for risk factors. Another objective was to determine if a similar breakpoint existed for indirect outcomes, such as the time to death and length of stay after infection for survivors. Seventy-one patients were included, of which 52 patients survived and 19 patients died. <b>Classification</b> <b>and</b> <b>regression</b> <b>tree</b> analysis determined a split of organism MIC between 2 and 4 mg/liter and predicted differences in mortality (16.1% for 2 mg/liter versus 76.9% for 4 mg/liter). In logistic regression controlling for confounders, each imipenem MIC doubling dilution doubled the probability of death. This classification scheme correctly predicted 82.6% of cases. Patients were accordingly stratified to MICs of ≤2 mg/liter (58 patients) and ≥4 mg/liter (13 patients). Patients in the group with a MIC of ≥4 mg/liter tended to be more ill. Secondary outcomes were also similar between groups. Patients with organisms that had an MIC of ≥4 mg/liter had worse outcomes than those with isolates of an MIC of ≤2 mg/liter.|$|E
40|$|We {{describe}} an algorithm for the fitting of multivariate responses using <b>classification</b> <b>and</b> <b>regression</b> <b>trees,</b> named the intersection-seeking algorithm. Although motivated by problems of record linkage and imputation of missing values in surveys, the algorithm {{may be used}} in other contexts. File completion Imputation <b>Regression</b> <b>and</b> <b>classification</b> <b>trees...</b>|$|R
30|$|Turkish has {{one-to-one}} {{relationship between}} its graphemes and phonemes in most cases. However, Turkish sounds have nuances {{and there are}} exceptions to the rules. Therefore, <b>classification</b> <b>and</b> <b>regression</b> <b>trees</b> (CART) were used to model grapheme-to-phoneme mappings of Turkish. A pronunciation lexicon [19] was used to train the CART tree.|$|R
40|$|Motivation: <b>Classification</b> <b>and</b> <b>regression</b> <b>trees</b> {{have long}} been used for cancer {{diagnosis}} and prognosis. Nevertheless, instability and variable selection bias, as well as overfitting, are well-known problems of tree-based methods. In this article, we investigate whether ensemble tree classifiers can ameliorate these difficulties, using data from two recent studies of radical prostatectomy in prostate cancer...|$|R
40|$|Aim: This paper {{presents}} {{a discussion of}} <b>classification</b> <b>and</b> <b>regression</b> <b>tree</b> analysis and its utility in nursing research. Background: <b>Classification</b> <b>and</b> <b>regression</b> <b>tree</b> analysis is an exploratory research method used to illustrate associations between variables not suited to traditional regression analysis. Complex interactions are demonstrated between covariates and variables of interest in inverted tree diagrams. Design: Discussion paper. Data sources: English language literature was sourced from eBooks, Medline Complete and CINAHL Plus databases, Google and Google Scholar, hard copy research texts and retrieved reference lists for terms including classification and regression tree* and derivatives and recursive partitioning from 1984 - 2013. Discussion: <b>Classification</b> <b>and</b> <b>regression</b> <b>tree</b> analysis is an important method used to identify previously unknown patterns amongst data. Whilst {{there are several reasons}} to embrace this method as a means of exploratory quantitative research, issues regarding quality of data as well as the usefulness and validity of the findings should be considered. Implications for Nursing Research: <b>Classification</b> <b>and</b> <b>regression</b> <b>tree</b> analysis is a valuable tool to guide nurses to reduce gaps in the application of evidence to practice. With the ever-expanding availability of data, it is important that nurses understand the utility and limitations of the research method. Conclusion: <b>Classification</b> <b>and</b> <b>regression</b> <b>tree</b> analysis is an easily interpreted method for modelling interactions between health-related variables that would otherwise remain obscured. Knowledge is presented graphically, providing insightful understanding of complex and hierarchical relationships in an accessible and useful way to nursing and other health professions...|$|E
40|$|AbstractBased on {{data mining}} {{classification}} technique, the neural {{network and the}} decision tree algorithms were studied to build a prediction system of water inrushes through coal floors. The back propagation neural network and the probabilistic neural network were compared to select features and algorithms. Rules of water inrushes through coal floors were obtained by the C 4. 5 decision tree and the <b>classification</b> <b>and</b> <b>regression</b> <b>tree.</b> The water inrush prediction system was built using the probabilistic neural network and the <b>classification</b> <b>and</b> <b>regression</b> <b>tree.</b> The result shows a prediction system which based on data mining classification technique is a practical and workable system...|$|E
40|$|Previous {{research}} has identified various {{risk factors for}} mortality in older people. The aim {{of this paper was}} to use <b>Classification</b> <b>and</b> <b>Regression</b> <b>Tree</b> to predict 15 -year survival in community-dwelling older people. Data were obtained from a United Kingdom representative sample of 1042 community-dwelling people aged 65 and over. Outcome was time from 1985 interview to death or censorship on February 29, 2000. <b>Classification</b> <b>and</b> <b>Regression</b> <b>Tree</b> is a non-parametric technique widely used in medical domain classification. We applied CART to the set of risk-factors identified in a previous research. The selected CART model is based on age, dose of drug prescribed and handgrip measures. It predicts survival with a sensitivity rate of 76. 3...|$|E
50|$|Breiman's work {{helped to}} bridge the gap between {{statistics}} and computer science, particularly in the field of machine learning. His most important contributions were his work on <b>classification</b> <b>and</b> <b>regression</b> <b>trees</b> <b>and</b> ensembles of trees fit to bootstrap samples. Bootstrap aggregation was given the name bagging by Breiman. Another of Breiman's ensemble approaches is the random forest.|$|R
40|$|Credit {{is one of}} the {{facilities}} provided by banks to lend money to someone or a business entity within the prescribed period. The smooth repayment of credit is essential for the bank because it influences the performance as well as its presence in daily life. Acceptance of prospective credit customers should be considered to minimize the occurrence of bad credit. <b>Classification</b> <b>and</b> <b>Regression</b> <b>Trees</b> (CART) is a statistical method {{that can be used to}} identify potency of credit customer status such as current credit and bad credit. The predictor variables used in this study are gender, age, marital status, number of children, occupation, income, tenor / period, and home ownership. To improve the stability and accuracy of the prediction were used the Bootstrap Aggregating <b>Classification</b> <b>and</b> <b>Regression</b> <b>Trees</b> (Bagging CART) method. The classification of credit customers using Bagging CART gives the classification accuracy 81, 44 %...|$|R
40|$|<b>Classification</b> <b>and</b> <b>regression</b> <b>trees</b> (CART) {{were among}} the {{earliest}} proposed approaches for pattern <b>classification</b> <b>and</b> data mining [3]. While being powerful in terms of accuracy and efficiency of induction, their results are also simple to understand as they mimic the decision-making logic of human experts. The renewed emphasis on data mining propagated by the KDD community in the 1990 s has fuele...|$|R
40|$|In {{the paper}} {{electricity}} load {{analysis was performed}} for a power region in Poland. Identifying {{the factors that influence}} the electricity demand and determining the nature of the influence is a crucial element of an effective energy management. In order to analyse the electricity load level the CART (<b>Classification</b> <b>and</b> <b>Regression</b> <b>Tree)</b> method has been used. The data for the analysis are hourly observations of the electricity load and weather throughout one year period. Two categories of factors were taken as predictor variables, on which the demand for the electricity load depends: variables describing weather and variables representing structure days in a year. An analysis of the errors of the presented models was carried out. data mining, <b>classification</b> <b>and</b> <b>regression</b> <b>tree,</b> electricity load, weather...|$|E
40|$|Abstract. This paper studies {{medical data}} {{classification}} methods, comparing decision tree and system reconstruction analysis {{as applied to}} heart disease medical data mining. The data we study is collected from patients with coronary heart disease. It has 1, 723 records of 71 attributes each. We use the system-reconstruction method to weight it. We use decision tree algorithms, such as induction of decision trees (ID 3), <b>classification</b> <b>and</b> <b>regression</b> <b>tree</b> (C 4. 5), <b>classification</b> <b>and</b> <b>regression</b> <b>tree</b> (CART), Chi-square automatic interaction detector (CHAID), and exhausted CHAID. We use the results to compare the correction rate, leaf number, and tree depth of different decision-tree algorithms. According to the experiments, we know that weighted data can improve the correction rate of coronary heart disease data but has {{little effect on the}} tree depth and leaf number...|$|E
30|$|Feature {{extraction}} {{was carried}} out through an empirical mode decomposition. The extracted features were forwarded to two classifiers, the <b>classification</b> <b>and</b> <b>regression</b> <b>tree</b> and the C 4.5 classifiers. The method using the C 4.5 classifier suggested by Martis et al. [14] obtained good experimental results of 95.33, 98 and 97  % for accuracy, sensitivity and specificity, respectively.|$|E
30|$|Methods: This {{study was}} a retrospective, {{observational}} analysis of data from 204, 277 episodes of bystander-witnessed OHCA between 2006 and 2012 in Japan. We used <b>classification</b> <b>and</b> <b>regression</b> <b>trees</b> (CARTs) <b>and</b> receiver operating characteristic (ROC) curve analysis to determine the threshold of response time associated with favorable neurological outcomes (Cerebral Performance Category 1 or 2) one month after cardiac arrest.|$|R
40|$|This paper {{provides}} {{an introduction to}} ensemble statistical proce- dures as a special case of algorithmic methods. The discussion beings with <b>classification</b> <b>and</b> <b>regression</b> <b>trees</b> (CART) as a didactic device to introduce many of the key issues. Following the material on CART is a consideration of cross-validation, bagging, random forests and boosting. Ma jor points are illustrated with analyses of real data...|$|R
40|$|Several {{applications}} of statistical tree-based modelling are described here to problems in speech <b>and</b> language. <b>Classification</b> <b>and</b> <b>regression</b> <b>trees</b> are {{well suited to}} many of the pattern recognition problems encountered in this area since they (1) statistically select the most significant features involved (2) provide "honest" estimates of their performance, (3) permit both categorical and continuous features to be considered, an...|$|R
30|$|To {{identify}} {{the most effective}} criteria and indicators on desertification hazard, we applied CART (<b>classification</b> <b>and</b> <b>regression</b> <b>tree)</b> analysis. <b>Classification</b> <b>and</b> <b>regression</b> <b>tree</b> model is a nonparametric method introduced by Breiman et al. (1984). This method is able to predict the quantitative variables (regression tree) and classification variables (classification tree) based {{on a set of}} qualitative and quantitative variables (Yeh 1991). A classification or regression tree model has been formed from the several branches and some nodes. The first node that includes all the samples is called the parent node. Other nodes are called child nodes. Then, based on one of the predictor variables, two branches take place and this situation continues to the end node (Frisman 2008). Another parameter is pruning the tree structure and selecting the appropriate size of the tree. The CART analysis was done using R software (apart and rpart.plot packages).|$|E
40|$|Classification of Indian {{stock market}} data {{has always been}} a certain appeal for researchers. In this paper, first time {{combination}} of three supervised machine learning algorithms, <b>classification</b> <b>and</b> <b>regression</b> <b>tree</b> (CART), linear discriminant analysis (LDA) and quadratic discriminant analysis (QDA) are proposed for classification of Indian stock market data, which gives simple interpretation of stock market data in the form of binary tree, linear surface and quadratic surface respectively. These resulted forms help market analyst to make decision on selling, purchasing or holding stock for a particular company in Indian stock market. In section IV and V, experimental results and performance comparison section show that <b>classification</b> <b>and</b> <b>regression</b> <b>tree</b> misclassification rate is only 56. 11 % whereas LDA and QDA show 74. 26 % and 76. 57 % respectively. Smaller misclassification reveals that CART algorithm performs betterclassification of Indian stock market data as compared to LDA and QDA algorithms...|$|E
40|$|OBJECTIVES: Recent {{guidelines}} {{recommend that}} all cirrhotic patients should undergo endoscopic screening for esophageal varices. That identifying cirrhotic patients with esophageal varices by noninvasive predictors {{would allow for}} the restriction {{of the performance of}} endoscopy to patients with a high risk of having varices. This study aimed to develop a decision model based on <b>classification</b> <b>and</b> <b>regression</b> <b>tree</b> analysis for the prediction of large esophageal varices in cirrhotic patients. METHODS: 309 cirrhotic patients (training sample, 187 patients; test sample 122 patients) were included. Within the training sample, the <b>classification</b> <b>and</b> <b>regression</b> <b>tree</b> analysis was used to identify predictors and prediction model of large esophageal varices. The prediction model was then further evaluated in the test sample and different Child-Pugh classes. RESULTS: The prevalence of large esophageal varices in cirrhotic patients was 50. 8 %. A tree model that was consisted of spleen width, portal vein diameter and prothrombin time was developed by <b>classification</b> <b>and</b> <b>regression</b> <b>tree</b> analysis achieved a diagnostic accuracy of 84 % for prediction of large esophageal varices. When reconstructed into two groups, the rate of varices was 83. 2 % for high-risk group and 15. 2 % for low-risk group. Accuracy of the tree model was maintained in the test sample and different Child-Pugh classes. CONCLUSIONS: A decision tree model that consists of spleen width, portal vein diameter and prothrombin time may be useful for prediction of large esophageal varices in cirrhotic patient...|$|E
5000|$|Bagging {{leads to}} [...] "improvements for {{unstable}} procedures" [...] (Breiman, 1996), which include, for example, artificial neural networks, <b>classification</b> <b>and</b> <b>regression</b> <b>trees,</b> <b>and</b> subset selection in linear regression (Breiman, 1994). An interesting application of bagging showing improvement in preimage learning is provided here. On the other hand, it can mildly degrade {{the performance of}} stable methods such as K-nearest neighbors (Breiman, 1996).|$|R
30|$|The RF {{classification}} {{algorithm is}} an extension of the <b>classification</b> <b>and</b> <b>regression</b> <b>trees</b> (CART) (Breiman 1984). <b>Classification</b> <b>and</b> <b>regression</b> <b>trees</b> have been widely used to group two or more known classes of observations based on a suite of predictor variables. Classification using CART is achieved through recursive partitioning of the dataset into successively more homogeneous groups. The results are homogeneous subsets of the data based on a series of splits using all of the predictor variables, where the best tree structure is determined by the Gini Index. We used the cforest function in the party package to build our random forest model which using conditional permutation importance. Random forest in this implementation produces multiple CART-like tree classifiers, each based on sub-sampling without replacement (Hothorn et al. 2006). The advantage of using the ctree function in the party package over the original random forest implementation by Breiman (2001) is that it produces unbiased individual trees.|$|R
40|$|This paper {{presents}} a novel scheme for fast color invariant ball detection in the RoboCup context. Edge filtered camera images {{serve as an}} input for an Ada Boost learning procedure that constructs a cascade of <b>classification</b> <b>and</b> <b>regression</b> <b>trees</b> (CARTs). Our system is capable to detect different soccer balls in the RoboCup and other environments. The resulting approach for object classification is real-time capable and reliable...|$|R
