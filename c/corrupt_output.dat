2|56|Public
5000|$|Using only field widths {{to provide}} for tabulation, as with a format like [...] for three {{integers}} in three 8-character columns, will not guarantee that field separation will be retained if large numbers occur in the data. Loss of field separation can easily lead to <b>corrupt</b> <b>output.</b> In systems which {{encourage the use of}} programs as building blocks in scripts, such corrupt data can often be forwarded into and corrupt further processing, regardless of whether the original programmer expected the output would only be read by human eyes. Such problems can be eliminated by including explicit delimiters, even spaces, in all tabular output formats. Simply changing the dangerous example from before to [...] addresses this, formatting identically until numbers become larger, but then explicitly preventing them from becoming merged on output due to the explicitly included spaces. Similar strategies apply to string data.|$|E
40|$|As we move {{deep into}} {{nanometer}} regime of CMOS VLSI (45 nm node and below), the device noise margin gets sharply eroded because of continuous lowering of device threshold voltage together with ever increasing rate of signal transitions {{driven by the}} consistent demand for higher performance. Sharp erosion of device noise margin vastly {{increases the likelihood of}} intermittent failures (also known as parametric failures) during device operation as opposed to permanent failures caused by physical defects introduced during manufacturing process. The major sources of intermittent failures are capacitive crosstalk between neighbor interconnects, abnormal drop in power supply voltage (also known as droop), localized thermal gradient, and soft errors caused by impact of high energy particles on semiconductor surface. In nanometer technology, these intermittent failures largely outnumber the permanent failures caused by physical defects. Therefore, it is of paramount importance to come up with efficient test generation and test application methods to accurately detect and characterize these classes of failures. ^ Soft error rate (SER) is an important design metric used in semiconductor industry and represented by number of such errors encountered per Billion hours of device operation, known as Failure-In-Time (FIT) rate. Soft errors are rare events. Traditional techniques for SER characterization involve testing multiple devices in parallel, or testing the device while keeping it in a high energy neutron bombardment chamber to artificially accelerate the occurrence of single events. Motivated by the fact that measurement of SER incurs high time and cost overhead, in this thesis, we propose a two step approach: 〈i〉 a new filtering technique based on amplitude of the noise pulse, which significantly reduces the set of soft error susceptible nodes to be considered for a given design; followed by 〈ii〉 an Integer Linear Program (ILP) -based pattern generation technique that accelerates the SER characterization process by 1 - 2 orders of magnitude compared to the current state-of-the-art. ^ During test application, it is important to distinguish between an intermittent failure and a permanent failure. Motivated by {{the fact that most of}} the intermittent failures are temporally sparse in nature, we present a novel design-for-testability (DFT) architecture which facilitates application of the same test vector twice in a row. The underlying assumption here is that a soft fail will not manifest its effect in two consecutive test cycles whereas the error caused by a physical defect will produce an identically <b>corrupt</b> <b>output</b> signature in both test cycles. Therefore, comparing the output signature for two consecutive applications of the same test vector will accurately distinguish between a soft fail and a hard fail. We show application of this DFT technique in measuring soft error rate as well as other circuit marginality related parametric failures, such as thermal hot-spot induced delay failures. ^ A major contribution of this thesis lies on investigating the effect of multiple sources of noise acting together in exacerbating the noise effect even further. The existing literature on signal integrity verification and test falls short of taking the combined noise effects into account. We particularly focus on capacitive crosstalk on long signal nets. A typical long net is capacitively coupled with multiple aggressors and also tend to have multiple fanout gates. Gate leakage current that originates in fanout receivers, flows backward and terminates in the driver causing a shift in driver output voltage. This effect becomes more prominent as gate oxide is scaled more aggressively. In this thesis, we first present a dynamic simulation-based study to establish the significance of the problem, followed by proposing an automatic test pattern generation (ATPG) solution which uses 0 - 1 Integer Linear Program (ILP) to maximize the cumulative voltage noise at a given victim net due to crosstalk and gate leakage loading in conjunction with propagating the fault effect to an observation point. Pattern pairs generated by this technique are useful for both manufacturing test application as well as signal integrity verification for nanometer designs. This research opens up a new direction for studying nanometer noise effects and motivates us to extend the study to other noise sources in tandem including voltage drop and temperature effects. ...|$|E
5000|$|... luit interprets {{application}} output {{according to}} the locale's character set with ISO 2022 shifts and ECMA-48 escape sequences. If an application is speaking a different language than the locale's character set (one that may have matched the terminal emulator's expectations {{in the absence of}} luit), luit can misinterpret the application's <b>output</b> and produce <b>corrupted</b> <b>output</b> to the terminal.|$|R
2500|$|In stacked {{denoising}} auto encoders, {{the partially}} <b>corrupted</b> <b>output</b> is cleaned (de-noised). This idea {{was introduced in}} 2010 by Vincent et al. with a specific approach to good representation, a good representation is {{one that can be}} obtained robustly from a corrupted input and that will be useful for recovering the corresponding clean input. Implicit in this definition are the following ideas: ...|$|R
5000|$|Some {{versions}} of [...] lack explicit field delimiters in their printf-generated output, leading to numeric fields running together and thus <b>corrupting</b> the <b>output</b> data.|$|R
50|$|Developers should design {{programs}} that fail {{in a manner}} that is easy to localize and diagnose or in other words “fail noisily”. This rule aims to prevent incorrect output from a program from becoming an input and <b>corrupting</b> the <b>output</b> of other code undetected.|$|R
40|$|In this paper, {{we propose}} a novel low-density parity-check real-number code, based on {{compressed}} sensing. A real-valued message is encoded by a coding matrix (with more rows than columns) and transmitted over an erroneous channel, where sparse errors (impulsive noise) corrupt the codeword. In the decoding procedure, we apply a structured sparse (low-density) parity-check matrix, the Permuted Block Diagonal matrix, to the <b>corrupted</b> <b>output,</b> and the errors can be corrected by solving a compressed sensing problem. A compressed sensing algorithm, Cross Low-dimensional Pursuit, {{is used to}} decode the code by solving this compressed sensing problem. The proposed code has high error correction performance and decoding efficiency. The comparative experimental results demonstrate both advantages of our code. We also apply our code to cryptography...|$|R
40|$|In {{almost all}} {{applications}} of power electronics {{there is always}} an influence of harmonics and noise in voltage and current waveforms. In this paper, a harmonic rejection technique has been proposed based on neural network platform. An ANN model has been developed which when trained can remove harmonics from {{the output of the}} buck converter. In this paper, a buck converter has been designed in MATLAB environment and the output voltage waveform is corrupted with harmonics. The <b>corrupted</b> <b>output</b> voltage is then passed through an ANN model. The developed model will remove the harmonics by hetero associative neural network approach. In the whole process a buck converter is simulated, one ANN model is developed, which is trained and tested on MATLAB platform...|$|R
3000|$|... is a real-valued vector {{containing}} the L most recent time {{samples of the}} input signal, x(n), and v(n) (i.e., the near-end signal) {{plays the role of}} the system noise (assumed to be quasi-stationary, zero mean, and independent of x(n)) that <b>corrupts</b> the <b>output</b> of the unknown system.|$|R
3000|$|For color images, {{we assume}} that <b>corrupted</b> image has <b>output</b> equal to the {{original}} image x(n,m;r)=f(n,m;r) with percentage 1 −p [...]...|$|R
40|$|Redundancy {{techniques}} {{are commonly used}} to design dependable systems to ensure high reliability, availability and data integrity. Triple Modular Redundancy (TMR) is a widely used redundancy technique that masks faults. In a TMR system, we have three implementations of the same logic function and their outputs are voted using a voter circuit. In this paper, we present a new voter design called the Word-Voter that has some distinct advantages over the bit-by-bit voting schemes used in conventional TMR systems. This paper demonstrates {{the usefulness of the}} word-voter design in increasing the data integrity (reducing the probability of <b>corrupt</b> <b>outputs)</b> of TMR systems. The area and delay overhead of the word-voter design is compared to that of the bit-by-bit voter. An efficient design of a TMR-Simplex system using the word-voter is also presented...|$|R
40|$|Grid environments {{are ideal}} for {{executing}} applications that require {{a huge amount of}} computational work, both due to the big number of tasks to execute and to the large amount of data to be analysed. Unfortunately, current tools may require that users deal themselves with <b>corrupted</b> <b>outputs</b> or early termination of tasks. This becomes incovenient as the number of parallel runs grows to easily exceed the thousands. ReGS is a user-level software designed to provide automatic detection and restart of corrupted or early terminated tasks. ReGS uses a web interface to allow the setup and control of grid execution, and provides automatic input data setup. ReGS allows the automatic detection of job dependencies, through the GRID-ADL task management language. Our results show that besides automatically and effectively managing a huge number of tasks in grid environments, ReGS is also a good monitoring tool to spot grid nodes pitfalls. 1...|$|R
40|$|Preprint / Technische Universität Ilmenau, Institut für Mathematik; 04 - 18 Abstract We {{consider}} digital input-constrained adaptive output {{feedback control}} of a class of nonlinear systems which arise as models for controlled exothermic chemical reactors. Our objective is set-point control of {{the temperature of the}} reaction, with prespecified asymptotic tracking accuracy set by the designer. Our approach is based on. Our objective is set-point control of the temperature of the reaction, with prespecified asymptotic tracking accuracy set by the designer. Our approach is based on lamda-tracking controllers, but we introduce a piecewise constant sampled-data output feedback strategy with adapted sampling period. The approach does not require any knowledge of the systems parameters, does not invoke an internal model, is simple in its design, copes with noise <b>corrupted</b> <b>output</b> measurements, and requires only a feasibility assumption in terms of the reference temperature and the input constraints. Übersicht: Preprint / Technische Universität Ilmenau, Institut für Mathematik</a...|$|R
40|$|Abstract—Error {{injection}} {{is a well}} accepted {{method to}} eval-uate hardware error detection mechanisms. An error detection mechanism is effective if it considerably reduces the amount of silently <b>corrupted</b> <b>output</b> of protected applications compared to unprotected applications. For a good representativeness of the error injection, the error model used has to mirror real world errors as accurately as possible. We introduce Error Injection Slicing (EIS) which emulates the symptoms of hardware errors. Furthermore, EIS provides means to debug single injection runs using slicing. With EIS we make the following novel con-tributions: (1) easy usage through hardware independence, (2) a symptom-based, flexible and comprehensive error model (e. g., not only bit-flips), and (3) debugging support to improve the detection coverage of the evaluated error detection mechanism. We evaluated {{the usefulness of the}} injector by analyzing the AN-encoding compiler that applies an AN-code to applications to facilitate hardware error detection. Keywords-error injection; slicing; error propagation analy-sis; debugging; I...|$|R
40|$|This {{paper is}} {{concerned}} with the clos control of discrete-time systems in the presence certainty. The uncertainty may arise as disturbance system dynamics, disturbances corrupting the measurements or incomplete knowledge of the initi of the system. In all cases, the uncertain quanti assumed unknown except that they lie in given sets. tion is first given to the problem of driving the syst{ at the final time into a prescribed target set under possible combination of disturbances. This is then e to the problem of keeping the entire state traject(given target "tube". Necessary and sufficient condit reachability of a target set and a target tube are the case where the system state can be measured while sufficient conditions for reachability are giver case when only disturbance <b>corrupted</b> <b>output</b> measu are available. An algorithm is given for the effici struction of ellipsoidal approximations to the sets i: and it is shown that this algorithm leads to linear laws. The application of the results in this Paler to evasion games is also discusse...|$|R
3000|$|... th {{spectral}} band by the ij th photo-detector at the k th sample time. The terms a(i,j) and b(i,j) represent, respectively, all the multiplicative and additive noise sources <b>corrupting</b> the <b>output</b> of a PBHC. The additive term V(i,j,k) {{is known as}} the temporal white noise associated with the readout electronic for the ij th photo-detector. However, in most of the cameras the white noise V(i,j,k) is negligible compared to the term b(i,j), so it can be disregarded. Finally, the parameter r(λ [...]...|$|R
3000|$|..., as the {{pipeline}} {{of the internal}} elaborations would be <b>corrupted</b> and the <b>output</b> messages of the two layers would overlap in time. This is not but another kind of pipeline hazard, and again, it can be solved by delaying the update of the second layer with [...]...|$|R
30|$|There {{are several}} {{advantages}} of the proposed architecture including implementation of flat reconfigurable SEs with any shape that fits within the maximum hardware realised SE boundaries. The SE flexibility {{can be used to}} avoid processing data outside the image borders, which can introduce inaccuracies and <b>corrupt</b> the <b>output</b> response. The SE can be explicitly controlled using a soft microprocessor to ignore pixels outside the image dimension boundaries or form any SE shape through generating false signals at specific SE points with the previously described pixel sample processing system.|$|R
40|$|Faults {{due to the}} {{incorrect}} functioning of the computation system, or the transmission errors of the internal data, could <b>corrupt</b> the <b>output</b> code stream of the Huffman encoder. In this paper, a fault detection method is proposed for the Huffman encoding system, which is implemented in the JPEG image compression standard [1]. The detection method {{based on the information}} input and the code stream output is described. The practical test results show the improvement of the reconstructed image quality. Index Terms: Huffman coding, zigzag sequence, runlength coding. I...|$|R
40|$|This paper {{introduces}} a robust nonlinear controller for a switch mode DC-DC boost converter. This innovative controller is employed {{to achieve the}} desired dynamic performance during steady state and transient operations. Step changes are considered in the load, the input and the desired output voltages, while unknown, but bounded disturbances <b>corrupt</b> the <b>output</b> load and the supply voltage. Practical stability of the converter is assured {{in the presence of}} those disturbances provided their maximum possible variation is known. Simulation results are provided to substantiate the applicability of the proposed control scheme. © 2010 IEEE...|$|R
40|$|Fixed {{major issue}} causing <b>corrupt</b> SAM <b>output</b> when using many threads (-p/ [...] threads) on certain systems. Fixed an issue whereby bowtie 2 {{processes}} could overwrite each others' named pipes on HPC systems. Fixed an issue causing bowtie 2 -build and bowtie 2 -inspect to return prematurely on Windows. Fixed {{issues raised by}} compiler "sanitizers" that could potentially have caused memory corruption or undefined behavior. Added the "continuous FASTA" input format (-F) for aligning all the k-mers in the sequences of a FASTA file. Useful for determining mapability of regions of the genome, and similar tasks...|$|R
40|$|The {{deconvolution}} {{problem is}} to design a deconvolution 2 lter that reconstructs a signal from the noise <b>corrupted</b> measurement <b>output</b> of a signal transmission channel. In this paper, we consider the deconvolution problem for uncertain periodic FIR transmission channels. The uncertainty appears in the channel coe 3 cients and is norm bounded. The aim is to design an optimal H 2 deconvolution 2 lter subject to an H &# 8734; performance constraint. A solution to this mixed H 2 =H&# 8734; problem is given in terms of linear matrix inequalities. An advantage of the linear matrix inequality solution is in its computational e 3 ciency using standard software...|$|R
40|$|Blind Quantum Computing (BQC) {{allows a}} client {{to have a}} server carry out a quantum {{computation}} for them such that the client’s input, output and computation remain private. A desirable property for any BQC protocol is verification, whereby the client can verify with high probability whether the server has followed the instructions of the protocol, or {{if there has been}} some deviation resulting in a <b>corrupted</b> <b>output</b> state. A verifiable BQC protocol can be viewed as an interactive proof system leading to consequences for complexity theory. The authors, together with Broadbent, previously proposed a universal and unconditionally secure BQC scheme where the client only {{needs to be able to}} prepare single qubits in separable states randomly chosen from a finite set and send them to the server, who has the balance of the required quantum computational resources. In this paper we extend that protocol with new functionality allowing blind computational basis measurements, which we use to construct a new verifiable BQC protocol based on a new class of resource states. We rigorously prove that the probability of failing to detect an incorrect output is exponentially small in a security parameter, while resource overhead remains polynomial in this parameter. The new resource state allows entangling gates to be performed between arbitrary pairs of logical qubits with only constant overhead. This is a significant improvement on the original scheme, which required that all computations to be performed must first be put into a nearest neighbour form, incurring linear overhead in the number of qubits. Such an improvement has important consequences for efficiency and fault-tolerance thresholds. ...|$|R
40|$|This paper {{considers}} {{the problem of}} continuous-time model identification from non-uniformly sampled input-output data, having the measured <b>output</b> <b>corrupted</b> by colored noise. We concentrate on the continuous-time transfer function model identification. A Box-Jenkins model structure is {{used to describe the}} system, thus providing independent parameterizations for the plant and the noise. Monte Carlo simulation analysis is also used to illustrate the properties of the proposed estimation method...|$|R
40|$|This paper {{deals with}} {{denoising}} of color video sequences using improved median-based filters appropriate for realtime implementations. In the paper, {{it is proven}} that application of prediction error processing results in improved efficiency of video restoration. The basic idea is to predict a pixel value by using a nonlinear filter, and then to calculate the prediction error by a comparison with the input value that maybe is <b>corrupted.</b> The <b>output</b> value is a sum of the prediction and the prediction error processed according to a nonlinear function. The experimental results prove that such filters are appropriate for rejection of scratches from video even in the interlaced format. The computational overhead is less than # 0 % as compared to classic median-based filters...|$|R
40|$|Transient faults are {{becoming}} a critical concern among current trends of design of generalpurpose multiprocessors. Because of their capability to <b>corrupt</b> programs <b>outputs,</b> their impact gains importance when considering long duration, parallel scientific applications, due to {{the high cost of}} re-launching execution from the beginning in case of incorrect results. This paper introduces SMCV tool which improves reliability for high-performance systems. SMCV replicates application processes and validates the contents of the messages to be sent, preventing the propagation of errors to other processes and restricting detection latency and notification. To assess its utility, the overhead of SMCV tool is evaluated with three computationallyintensive, representative parallel scientific applications. The obtained results demonstrate the efficiency of SMCV tool to detect transient faults occurrences. Facultad de Informátic...|$|R
40|$|Various {{geometric}} and algebraic computations (e. g., of the convex hulls, Voronoi diagrams, and scalar, univariate {{and multivariate}} resultants) {{boil down to}} computing the sign or {{the value of the}} determinant of a matrix. For these tasks numerical factorizations of the input matrix is the most attractive approach under the present day computer environment provided the rounding errors are controlled and do not <b>corrupt</b> the <b>output.</b> This is the case where the input matrix is well conditioned. Ill conditioned input matrices, however, frequently arise in geometric and algebraic applications, and this gives upper hand to symbolic algorithms. To overcome the problem, we apply our novel techniques of additive preconditioning and combine them with some nontrivial symbolic-numerical techniques. We analyze our approach analytically and demonstrate its power experimentally...|$|R
40|$|A Doctoral Thesis. Submitted in partial {{fulfillment}} of the requirements for the award of Doctor of Philosophy of Loughborough University. The work presented in this thesis concerns the identification of vehicle occupant models. Mathematical models of the vehicle occupant {{are used in the}} preliminary design and development phase of vehicle design. In the design phase, the model is used to guide the decision on restraint system feasibility. In the development phase the model is used to suggest solutions to problems associated with the dummy trajectory or restraint system performance. Current methods used -to determine such models involve independent component testing. The conditions under which the components are tested are often not typical of a crash test, hence iterations of the computer model are needed to successively improve model and test correlation. In order to address these problems which cause inaccurate specification of the mathematical models, an alternative method of data set assembly for crash victim models is suggested. This alternative method is based on the techniques of system identification which allow unknown system parameters to be determined from experimental input/output data. Initially the viability of using system identification techniques to develop a valid mathematical model of the vehicle occupant and restraint system was investigated. This initial study used input and output measurementsfr om computer simulations of the occupant in frontal impact, as source data for the identification. Effects of simulated disturbances (noise <b>corrupted</b> <b>output</b> signals) and the effects of simplified model structure on the identification are also investigated. Several methods for analysing the likely errors in the identified parameters are defined and discussed in this simulation study. Results relating to the identification of seat contact and seat belt characteristics from physical tests are also presented and these are interpreted in light of the simulation results...|$|R
40|$|Contrast {{discrimination}} {{functions for}} simple gratings famously {{look like a}} dipper. Discrimination thresholds are lower than detection thresholds for moderate pedestal contrasts, {{and the rate of}} growth of thresholds as the pedestal contrast gets larger typically lies between the values implied by two popular treatments of noise. Here, we suggest a new normative treatment of the dipper, showing how it emerges from Bayesian inference based on the responses of a population of orientation-tuned units. Our central assumption concerns the noise <b>corrupting</b> the <b>outputs</b> of these units {{as a function of the}} contrast: We suggest that it has the shape of a hinge. We show the match to the psychophysical data and discuss the neurobiological and statistical rationales for this form of noise. Finally, we relate our model to other major accounts of contrast discrimination...|$|R
40|$|It {{is shown}} that a simple {{modification}} (introducing a dead zone in the adaptation law) of the known adaptive high-gain control strategy u(t) = -k(t) y(t), k(t) = ||y(t) || 2 yields lambda-tracking {{in the presence of}} <b>output</b> <b>corrupted</b> noise for a large class of reference signals and a large class of multivariable nonlinear minimum-phase systems of relative degree one. These results are applied to a realistic chemical reactor, showing the practical usefulness of these control laws...|$|R
40|$|We {{establish}} the equivalence between the optimal least-squares state estimator for a linear time-invariant dynamic system with noise <b>corrupted</b> input and <b>output,</b> and an appropriately modified Kalman filter. The approach used is algebraic {{and the result}} shows that the noisy input/output filtering problem is not fundamentally di#erent from the classical Kalman filtering problem. The result is illustrated with a simulation example. LINEAR DYNAMIC FILTERING WITH NOISY INPUT AND OUTPUT Ivan Markovsky # and Bart De Moor # # ESAT, SCD-SISTA, K. U. Leuven, Kasteelpark Arenberg 10, B- 3001 Leuven-Heverlee, Belgium {Ivan. Markovsky,Bart. DeMoor}@esat. kuleuven. ac. be [URL] Tel: + 32 [...] 16 [...] 3217 09, Fax: + 32 [...] 16 [...] 3219 70 Abstract: We {{establish the}} equivalence between the optimal least-squares state estimator for a linear time-invariant dynamic system with noise <b>corrupted</b> input and <b>output,</b> and an appropriately modified Kalman filter. The approach used is algebraic and the result shows that the noisy input/output filtering problem is not fundamentally different from the classical Kalman filtering problem. The result is illustrated with a simulation example. Keywords: dynamic errors-in-variables model, Kalman filtering, optimal smoothing, total least squares. 1...|$|R
40|$|Due {{to modern}} {{technology}} trends such as decreasing feature sizes and lower voltage levels, fault tolerance {{is becoming increasingly}} important in computing systems. Shared memory in modern multiprocessor systems is supported by cache coherence mechanisms. The correctness of cache coherence {{of the system is}} crucial for the data integrity. This work proposes an error detection scheme for snoopingbased cache coherence protocols. For the widely used MESI coherence protocol, the proposed method does not introduce any performance overhead. Only a limited amount of additional hardware is required. Existing systems can be easily extended to support the proposed technique. Almost all single faults that are able to affect data integrity in the system are covered, {{with the exception of a}} few very rare cases. Experimental results involving fault injection do not encounter any undetected faults leading to <b>corrupted</b> application <b>output...</b>|$|R
40|$|Line {{synchronization}} of {{grid connected}} power converters {{is a well}} recognized problem when the grid is weak, or derives from a remote area power supply with poor frequency regulation. Such systems can suffer significant line voltage distortion due to notches caused by power device switching and/or low frequency harmonic content, which can easily <b>corrupt</b> the <b>output</b> of a conventional zero crossing detector. This paper presents a method of filtering the incoming grid voltage using a recursive discrete Fourier transform (DFT). The filter provides {{a high degree of}} noise immunity but does produce a phase shift between the incoming grid voltage and the filtered output voltage when the DFT time window does not match the grid period. Two methods of compensating this phase shift are presented, based on tracking the drift in the phase predicted by the recursive DFT...|$|R
40|$|The {{advantages}} of a navigation system that can monitor its own integrity are obvious. Integrity monitoring requires that the navigation system detect faulty measurement sources before they <b>corrupt</b> the <b>outputs.</b> This paper describes a parity approach to measurement error detection when redundant measurements are available. The general form of the detector operating characteristic (DO 0 is devel-oped. This equation relates the probability of missed detection to the probability of false alarm, the measurement observation matrix, and {{the ratio of the}} detectable bias shift to the standard deviation of tbe measurement noise. Rvo applications are presented: skewed axis strapdown inertial navigation sys-tems, where DOCs are used to compare the integrity monitoring capabilities of various redundant sensor strapdown system configurations; and GPS navigation sets, where DOCs are used to discuss GPS integrity monitoring for meeting non-precision approach requirements. A fault identification algorithm is also presented...|$|R
40|$|This paper {{addresses}} {{the problem of}} detection and reconstruction of cyber-attacks <b>corrupting</b> states and/or <b>outputs</b> of a linear Cyber-Physical System. Robust state/sensor attack observers are designed able both to work as detection monitors with guaranteed performances, and to reconstruct the attacks within a finite-time. Detection and reconstruction are performed robustly with respect to bounded modeling errors possibly affecting the state equation. Compensation of attacks is also addressed for square plants. An extensive simulation study using test-cases taken from the literature is shown to support the theoretical findings...|$|R
40|$|We {{study the}} effect of regularization in an on-line {{gradient-descent}} learning scenario for a general two-layer student network with an arbitrary number of hidden units. Training examples are randomly drawn input vectors labelled by a two-layer teacher network with an arbitrary number of hidden units which may be <b>corrupted</b> by Gaussian <b>output</b> noise. We examine {{the effect of}} weight decay regularization on the dynamical evolution of the order parameters and generalization error in various phases of the learning process, in both noiseless and noisy scenarios...|$|R
