64|183|Public
50|$|VirtualCL (VCL) <b>cluster</b> <b>platform</b> http://www.MOSIX.org/txt_vcl.html is a wrapper for OpenCL™ {{that allows}} most unmodified {{applications}} to transparently utilize multiple OpenCL devices in a cluster {{as if all}} the devices are on the local computer.|$|E
50|$|Designed for {{large-scale}} ad hoc clusters, once booted, CHAOS runs from memory allowing the CD {{to be used}} on the next node (and allowing for automated rebooting into the host operating system). CHAOS aims {{to be the most}} compact, secure and straightforward openMosix <b>cluster</b> <b>platform</b> available.|$|E
50|$|The Intel Cluster Ready {{certification}} is {{a marketing}} program from Intel. It {{is aimed at}} hardware and software vendors in the low-end and mid-range cluster market. To get certified, systems have to fulfill a minimum set of cluster-specific requirements. This way, vendors of parallel software can build their applications on a basic <b>cluster</b> <b>platform,</b> trusting certain components to be present. Other drivers, libraries and tools {{will have to be}} provided by the software vendor or its partners, or by a system integrator.|$|E
5000|$|Being {{active in}} facilitating sharing of arts {{education}} practices at national / <b>cluster</b> <b>platforms</b> ...|$|R
5000|$|In 2008, AMAX {{introduced}} {{a line of}} high performance computing products based on the Nvidia Tesla Personal Supercomputer, with GPU technology. The systems were configured with Nvidia Tesla C1060/C2050/C2070/C2075 cards. [...] Other servers and <b>cluster</b> <b>platforms</b> available are configured with the Nvidia Tesla M2075/M2090/K10/K20/K40.|$|R
40|$|Parallel {{implementations}} of two {{computer vision}} algorithms on distributed <b>cluster</b> <b>platforms</b> are described. The first algorithm is a square-error data clustering method whose parallel implementation {{is based on}} the well-known sequential CLUSTER program. The second algorithm is a motion parameter estimation algorithm used to determine correspondence between two images taken of the same scene. Both algorithms have been implemented and tested on <b>cluster</b> <b>platforms</b> using the PVM package. Performance measurements demonstrate {{that it is possible to}} attain good performance in terms of execution time and speedup for large-scale problems, provided that adequate memory, swap space, and I/O capacity are available at each node. 1 Introduction Many tasks in computer vision are computationally intensive. In order to reduce the total time required to solve these problems, special-purpose hardware or vector supercomputers have often been used. Recently, parallel processing has started to dominate the [...] ...|$|R
5000|$|... GIMPS has a {{sustained}} aggregate throughput of approximately 137 TeraFLOPS (or TFLOPS). In November 2012, GIMPS maintained 95 TFLOPS, theoretically earning the GIMPS virtual computer a {{place among the}} TOP500 most powerful known computer systems in the world. Also theoretically, in November 2012, the GIMPS held a rank of 330 in the TOP500. The preceding place was then held by an 'HP <b>Cluster</b> <b>Platform</b> 3000 BL460c G7' of Hewlett-Packard. As of November 2014 TOP500 results, these old GIMPS numbers would no longer make the list.|$|E
50|$|The filers use NetApp's {{proprietary}} {{operating system}} called Data ONTAP which includes code from Berkeley Net/2 BSD Unix, Spinnaker Networks technology and other operating systems.Data ONTAP originally only supported NFS, but later added support for SMB, iSCSI and Fibre Channel (including Fibre Channel over Ethernet). In June 16, 2006 NetApp provided two variants of Data ONTAP. Data ONTAP 7G and a nearly complete rewrite called Data ONTAP GX, based upon grid technology acquired from Spinnaker Networks. In 2010 these software product lines merged into one OS - Data ONTAP 8, which folded Data ONTAP 7G onto the Data ONTAP GX <b>cluster</b> <b>platform.</b> Data ONTAP 8 has two distinct operating modes - 7-Mode and Cluster-Mode.|$|E
30|$|In the section, {{we design}} some {{interactive}} fluid scenes {{to illustrate the}} visualization effect and performance. All results are generated on multi-GPU <b>cluster</b> <b>platform</b> with four worker nodes, each node has two GPUs, windows 10 OS, NVIDIA Geforce GTX 480 GPU.|$|E
5000|$|Apache Mesos, a {{large-scale}} <b>cluster</b> management <b>platform</b> based on container isolation ...|$|R
40|$|Keywords:industry cluster;collaboration design platform;enterprise; {{construction}} mechanism Abstract. From {{the perspective}} of the synergy effect, the paper discusses how to construct the industry <b>cluster</b> collaboration design <b>platform.</b> As is known, the concept of industry <b>cluster</b> collaboration <b>platform</b> has been paid great attention with the economic growth, which has become a national leading research programs and key research projects in various provinces and cities. Therefore, it is very necessary to build industry <b>cluster</b> collaboration design <b>platform.</b> In this paper, the construction mechanism of industry <b>cluster</b> collaboration design <b>platform</b> is divided into collaborative session, collaborative browsing, collaborative text editing, collaborative tagging and collaborative inquiry. In detail, the policy should adopt the temporal characteristics, including remote synchronous mode, remote asynchronous mode, synchronousmodel and asynchronous model. The characteristics ofindustrial <b>cluster</b> collaboration design <b>platform</b> The establishment of appropriate industry or regional industrial clusters collaboration design platformshould be supplemented to specific sectors and regions. In certain industries or geographic scope (such as province, city, and county), with the adoption of th...|$|R
5000|$|By {{clustering}} services {{across multiple}} hardware machines and using load balancing, single points of failure can be eliminated, increasing {{availability of a}} website and other web services beyond that of ordinary single server hosting. A single server can require periodic reboots for software upgrades and the like, whereas in a <b>clustered</b> <b>platform</b> you can stagger the restarts such that the service is still available whilst still upgrading all necessary machines in the cluster.|$|R
40|$|The recent arrivals of fast networks, such as Myrinet, {{asynchronous}} {{transfer mode}} (ATM) coupled with powerful personal computers and workstations, has allowed for cost effective high−performance and high−availability clusters to be built from commodity parts. Additionally, the new <b>cluster</b> <b>platform</b> offers enough raw hardware performance to allow execution of applications such as parallel scientific computing or parallel servers, which use...|$|E
40|$|Abstract — Orchid {{is one of}} the {{economic}} crops in world market. The varieties of shape, style, color and smell of orchids attract people to create products in many ways, such as cut orchid, orchid plant, bouquet, lei, corsage, and orchid loose bloom and so on. Thailand {{is one of the}} biggest exporters in orchid market. There are a lot of processes in the chain, such as reproduction, cultivation, market trend survey and analysis, transportation, international trade standard, traceability and so on. In order to provide a smart knowledge service, we have to 1) managing knowledge efficiently in terms of sharing and reusing knowledge and 2) providing knowledge which matches to stakeholders. In this paper, we propose a general framework on ontology base orchid <b>cluster</b> <b>platform</b> for developing a user-centric model of knowledge services in orchid cluster. We give some examples on semantic search model, recommended system model and tracking and monitoring model respectively. knowledge service, ontology and model, orchid <b>cluster</b> <b>platform</b> I...|$|E
40|$|Infrastructure {{as of now}} Pointers to useful docs Open Cluster Stack (OCS) Used {{to build}} a Beowulf style <b>cluster</b> <b>Platform</b> OCS is a integrated, vendor certified, {{software}} stack that simplifies building of clusters. Applications within academic High Performance Computing domain. Google “Teracluster”. Really simple to build and use if you stick to documentation and don't try to improvise. Different approach, algorithms to develop applications-MPI, shared memory, synchronization & so on...|$|E
3000|$|After the {{definition}} of SECRET, the increasing number and the growing complexity of real-time data analytics applications led to a bloom of new distributed SPEs that target <b>cluster</b> <b>platforms</b> to scale with the volume and velocity of input data. This poses two interesting and related research questions: (1) how did the semantics of windows and time change in distributed SPEs? (2) Is SECRET still adequate to fully capture the execution semantics of modern distributed SPEs? [...]...|$|R
40|$|Abstract — This {{research}} paper discusses performance issues of cluster and grid computing platforms, and reasons {{to support the}} implementation of these computing infrastructures. A number of benchmark programs are executed in these computing systems, in order to perform performance analysis of experimental results. We {{will be able to}} show that <b>cluster</b> <b>platforms</b> are excellent alternatives to access to supercomputing, due to its cost/performance, scalability and commodity components factors. In addition, we also show that grid technology is viable by increasing total system performance at no additional cost...|$|R
40|$|In today’s world, {{the use of}} {{computers}} and net-works is growing and the vision of a single infrastructure for voice and data is becoming a reality. However, with different technolo-gies and services using the same networking infrastructure, the realization of this vision re-quires higher levels of security to be imple-mented in computer systems. Current secu-rity solutions do not address all of the security challenges facing today’s computer systems, including <b>clustered</b> <b>platforms,</b> in one compre-hensive and coherent fashion. This paper presents the previous work done in the area of access control and then focus on new mechanisms for clustered Linux server...|$|R
40|$|We {{present an}} {{analysis}} of high performance computational method for solving the problem of crystal grows. The method uses PETSc and PETIGA C-language based libraries and supports parallel computing. The evolution of calculation process was studied in series of special computations are obtained on innovative mobile <b>cluster</b> <b>platform,</b> which provides exclusive system tuning abilities. The results of research confirm the high efficiency of the proposed algorithm on multi-core computer systems and allow us to recommend the use of PETSc and PETIGA for solving high order differential equations...|$|E
40|$|Abstract—This paper † {{illustrates}} a distributed multi-agent platform on which load-balancing strategies are experimented and compared. Rather than focusing solely on computation workload, we examined {{a new approach}} to load-balancing, a communication-efficient algorithm (Comet), which takes communication effects into account. We implemented a Linux <b>cluster</b> <b>platform</b> using Java based on this concept, and drove the system with a set of systematically defined workloads and communication requests. Our extensive experimental results showed improved load-balancing performance of Comet over the traditional workload-based load balancing (WBLB) scheme...|$|E
40|$|It {{has been}} argued that the Chinese market is a {{potential}} consumer of overseas products, and several documents identify the opportunities and risks that the Chinese market also represents. Nevertheless, on one hand, it Commercial Cluster Integration Initiative would create more opportunities for Latin American economies (review the formula that clarifies how the Chinese market operates their strategic prices, Chapter 1, Prices Equation) to follow up as example. On other hand, the CELAC could benefit from more opportunities with the Chinese internal market {{and at the same time}} these countries would increase their economies. In this way, LAC–Latin American Countries could reduce its unemployment rate. This study will look at the feasibility of a Commercial <b>Cluster</b> <b>Platform</b> CCP–Commercial <b>Cluster</b> <b>Platform</b> between LAC countries to work freely at internal Chinese market. The formulated research question will explore the various advantages and measures to manage SEN–Strategic Enterprise Networking. This dissertation evaluates the possibility of management LACI–Latin American Commercial Integration; to reach a common free agreement as part of the Chinese approach to new preferential trade agreements characterized by the term competitive liberalization. It bases on the idea that competition among large countries (US/EU) in negotiating preferential arrangements with smaller countries or regions will lower barriers, an...|$|E
40|$|We present {{preliminary}} {{results of a}} project to create a tuning system that adaptively optimizes programs to the underlying execution platform. We will show initial results from two related efforts, (i) Our tuning system can efficiently select the best combination of compiler options, when translating programs to a target system, (ii) By tuning irregular applications that operate on sparse matrices, our system is able to achieve substantial performance improvements on <b>cluster</b> <b>platforms.</b> This project {{is part of a}} larger effort that aims at creating a global information sharing system, where resources, such as software applications, computer platforms, and information can be shared, discovered, and adapted to local needs...|$|R
40|$|Abstract. HeteroMPI is an {{extension}} of MPI designed for high performance computing on heterogeneous networks of computers. The recent new feature of HeteroMPI is the optimized version of collective communications. The optimization is based on a novel performance communication model of switch-based computational clusters. In particular, the model reflects significant non-deterministic and non-linear escalations of the execution time of many-to-one collective operations for medium-sized messages. The paper outlines this communication model and describes how HeteroMPI uses this model to optimize one-to-many (scatter-like) and many-to-one (gather-like) communications. We also demonstrate that HeteroMPI collective communications outperform their native counterparts for various MPI implementations and <b>cluster</b> <b>platforms...</b>|$|R
40|$|Fortran {{was one of}} {{the first}} {{high-level}} computer programming languages, and has been in use for over 50 years. During that time, a huge reservoir of HPC applications has been developed in Fortran. The Fortran language has evolved to support both performance-oriented programming and modern best practices features in programming languages and parallel computing, and many HPC applications have incorporated components in C and C++ as well. As a result, there is an incredible range and diversity of HPC applications in use today, most of which were developed on UNIX-heritage HPC and <b>cluster</b> <b>platforms.</b> This paper presents the compiler and tools resources available and shows practical examples of porting such code...|$|R
40|$|A {{small scale}} {{distributed}} computing {{system that is}} {{able to meet the}} needs of parallel intelligent techniques for engineering and science applications is reported. The system is a cluster of powerful yet low cost general-purpose PCs interconnected in a network. While, most applications written for cluster systems are programmed in MPI-C, results from the proposed system have shown that it is advantageous to use Java due to its simplicity, distribution enabling, and mobility. These results suggest there are advantages in considering a Java-enhanced <b>cluster</b> <b>platform</b> for many engineering and science applications...|$|E
30|$|To {{deal with}} the {{challenges}} of storing and accessing big data, one distributed <b>cluster</b> <b>platform</b> is necessary. Such a system must provide large storage space (petabyte) and location transparent access to data files to the servers on the cluster. Hadoop Distributed File System (HDFS) [28] {{is an example of}} cluster file system which is designed for reliably storing large amount of various structure or no structure data across machines in a large scale cluster. Interestingly, HDFS was originally derived from Google Files System (GFS) paper [29]. It has ability to deliver an open source cluster file system similar to GFS.|$|E
40|$|Creative {{industries}} development {{strategies have}} largely adopted a regionally embedded <b>cluster</b> <b>platform</b> {{to enhance the}} economic contribution of the sector. Such an isolated approach {{has done little to}} curb significant labour precarity and exploitation within the sector. Correspondingly, creative workers have sought to up-scale their networks, from local to global, to enhance their labour outcomes. This paper analyses the impact creative workers 2 ̆ 7 up-scaled network arrangements on their labour outcomes. The research identifies significant policy implications concerning the support of up-scaled arrangements for economic segments that are vulnerable to labour precarity, such as the creative industries...|$|E
40|$|Modern massively {{parallel}} computers are built from commodity processors and a trend towards commodity interconnect components for Clusters of PCs (CoPs) is visible. Most of today’s networking solutions are still proprietary, {{but they do}} connect to standard buses (i. e. PCI) and {{in the near future}} the networking solutions of the Internet (e. g. Gigabit Ethernet) can offer Gigabit speeds at mass market prices. <b>Cluster</b> <b>platforms</b> like CoPs offer good compute performance, but still they cannot yet utilize the potential of Gigabit/s communication technology, at least not with commodity network adapters like Ethernet NICs and standard protocols like TCP/IP. While the speed of Ethernet has grown to 1 Gbit/s the functionality and the architectural support in the network interfaces remained the same for more tha...|$|R
30|$|Finally, modern SPEs {{introduce}} {{fault tolerance}} mechanisms {{to cope with}} the rather frequent hardware failure in the <b>cluster</b> <b>platforms</b> in which they operate. Different SPEs provide different guarantees in the presence of failures: in most cases, the SPE guarantees exactly once semantics, meaning that no loss or duplicate processing are possible and hence failure do not affect the execution semantics. However, some platforms offer weaker guarantees. For instance, Storm offers at least once semantics, in which duplicate processing of some elements is allowed. In this case, failures impact on the execution semantics and need to be modeled. This demands for a model that not only contemplates the presence of loss or duplicate elements in one operator, but also how loss and duplicate elements affect the entire processing graph.|$|R
40|$|Parallel {{computing}} {{is becoming}} increasing central and mainstream, driven {{both by the}} widespread availability of commodity SMP and high-performance <b>cluster</b> <b>platforms,</b> {{as well as the}} growing use of parallelism in general-purpose applications such as image recognition, virtual reality, and media processing. In addition to performance requirements, the latter computations impose soft real-time constraints, necessitating efficient, predictable parallel resource management. Unfortunately, traditional resource management approaches in both parallel and real-time systems are inadequate for meeting this objective; the parallel approaches focus primarily on improving application performance and/or system utilization at the cost of arbitrarily delaying a given application, while the real-time approaches are overly conservative sacrificing system utilization in order to meet application deadlines. In this paper, we propose a novel approach for increasing parallel system utilization while meeting a [...] ...|$|R
40|$|This work aims at {{analyzing}} how {{two different}} concurrency models, namely the shared memory {{model and the}} actor model, can influence the development of applications that manage huge masses of data, dis-tinctive of Big Data applications. The paper compares the two models by analyzing a couple of concrete projects based on the MapReduce and Bulk Synchronous Parallel algorithmic schemes. Both projects are dou-bly implemented on two concrete platforms: Akka Cluster and Managed X 10. The result is both a conceptual comparison of models in the Big Data Analytics scenario, and an experimental analysis based on concrete executions on a <b>cluster</b> <b>platform.</b> ...|$|E
40|$|Abstract † —This paper {{proposes a}} new load {{balancing}} strategy, called Comet, for fast multi-agent cluster computing. We use a new load index {{that takes into}} account the cost of inter-agent communications. Agents with predictable workload are assigned statically to cluster nodes, whereas agents with unpredictable workload are allowed to migrate dynamically between cluster nodes using a creditbased load balancing algorithm based on the proposed load index. We have implemented and tested our load balancing strategy in a multi-agent <b>cluster</b> <b>platform</b> consisting of Linux PC machines. Experimental results indicate that the proposed Comet system outperforms traditional distributed load balancing strategies for applications with regular as well as irregular communication patterns...|$|E
40|$|Abstract- In this paper, an {{automatic}} parallelization tool for C code, named Intelligent Automatic Parallel Detection Layer (IAPDL), is presented. It generates parallelized MPI code, and OpenMp code from the sequential code; at the loop level, {{to be executed}} on a <b>cluster</b> <b>platform</b> and multicore platform respectively. In addition to, a tool that uses {{a new approach to}} choosing loop transformations, called Intelligent Loop Transformation Selector (ILTS), is developed. It is designed as an integrated part in IAPDL. The selection process of appropriate loop transformation was accomplished intelligently; a Kohonen’s Self-Organizing Map (SOM) neural network is used to select the appropriate loop transformation or sequence of them...|$|E
5000|$|Service Management Function (SMF) or Service Management Point (SMP) is a <b>platform</b> or <b>cluster</b> of <b>platforms</b> that {{operators}} use {{to monitor}} and manage the IN services. It contains the management database which stores the services' configuration, collects the statistics and alarms, and stores the Call Data Reports and Event Data Reports.|$|R
40|$|The {{performance}} analysis of {{computational fluid dynamics}} code can yield unexpected results, and translating the performance data into code improvements {{is not always a}} straightforward task. A possible approach for increasing comprehension {{is to look at the}} performance of multiple codes simultaneously. In this manner, differences in the codes may be connected to differences in the performance, allowing for the better methodology to be adopted across the codes. This paper presents such a comparative analysis for two CFD codes, the structured two-dimensional code GHOST and the unstructured two-/three-dimensional code UNCLE, both in-house codes at the University of Kentucky. These codes are used regularly across several commodity <b>cluster</b> <b>platforms,</b> two of which are briefly described. This paper presents the initial performance evaluation of these codes followed by a discussion of some of the optimization techniques applied and the resulting changes in performance. ...|$|R
40|$|Ricochet is a time-critical {{multicast}} {{protocol for}} use in <b>clustered</b> <b>platforms</b> and datacenters. Applications in such settings often are cloned for scalability and availability, hence updates involve multicast or publishsubscribe, {{with large numbers of}} heavily overlapping multicast groups. The applications that interest us are ones for which rapid response reflecting the most recent updates is important. Ricochet, a multicast protocol that combines native IP multicast with proactive forward error correction, achieves high levels of consistency with stable and tunable overhead. Evaluation on a 64 -node rack-style cluster shows that existing technologies perform poorly relative to our goals, whereas Ricochet achieves extremely low and consistent delay, performs well with as many as 1024 multicast groups per node, and is not disrupted by packet loss. The price of this low latency is a modest loss in peak throughput. ...|$|R
