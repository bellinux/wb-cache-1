18|106|Public
50|$|The TopShot <b>camera</b> <b>arm</b> {{looks like}} a handle. It looks so much like a handle {{that one has to}} resist the temptation to lift the MFP with it. Because of this, the <b>camera</b> <b>arm</b> is {{designed}} to be light enough that it feels too weak to lift the device. The panel on the device where the camera is mounted is also designed to be flexible making it even more obvious that the <b>camera</b> <b>arm</b> is not a handle. This is why HP begins most of the user documentation with a warning to resist using the <b>camera</b> <b>arm</b> as a handle. Making the <b>camera</b> <b>arm</b> lighter also costs less, which reduces the cost of the MFP.|$|E
50|$|Resident Evil: The Final Chapter movie, year 2015, Olivia Jackson, stuntwoman, had her arm amputated {{after her}} {{motorbike}} crashed to a metal <b>camera</b> <b>arm</b> during high-speed chase.|$|E
50|$|A {{modified}} double arm design minimizes tangent error {{by raising}} the point of rotation of the arm on which the camera is mounted. This {{has the effect of}} tilting the arc traced by the <b>camera</b> <b>arm</b> backwards causing it to follow a better path.|$|E
50|$|Ar 234 C-4: Armed {{reconnaissance}} version, {{fitted with}} two <b>cameras,</b> <b>armed</b> with four 20 mm MG 151/20 cannon.|$|R
25|$|Photo-reconnaissance version, {{fitted with}} <b>camera</b> equipment, <b>armed</b> with two 20mm (.79in) cannons, 60 built.|$|R
50|$|Photo-reconnaissance version, {{fitted with}} <b>camera</b> equipment, <b>armed</b> with two 20 mm (.79 in) cannons, 60 built.|$|R
50|$|The TopShot {{camera is}} {{placed at the}} end of an arm that the user must lift before scanning. The arm is just the right length to allow the camera to aim and focus properly. Since the {{position}} of the <b>camera</b> <b>arm</b> is critical to the success of capturing images, it has a detent in the fully lifted position.|$|E
5000|$|The {{episode was}} shot over 21 days, and {{featured}} {{a large amount}} of in-camera effects rather than just CGI. For instance, Hawley said that one day of filming was [...] "upside-down day, so you're not just setting up a camera with two people talking. We're trying to tell the story with the camera and the visuals ... we're ambitious." [...] For the two sequences where Haller destroys elements of his environment, Hawley particularly wanted to avoid visual effects so that it was believable that the character was actually doing it himself. For the scene where a kitchen explodes around Haller, a [...] "repeatable <b>camera</b> <b>arm,</b> high-speed, high-frame" [...] was used to film the set as kitchen items were exploded from drawers and cabinets for real. The camera, called the Bolt, is a [...] "2,000-pound unit and it’s on a track. It will do a two-second move, or three-second move, and it shoots about 1,000 frames a second." [...] The set decorator provided doubles and triples of the kitchen elements, which were blown across the room in multiple takes by 30 to 40 air cannons. This provided [...] "the raw material for a 3-D spin in a kitchen of chaos"; all the filmed elements were then layered over Stevens, who was filmed separately with the camera on the same set. Similar actions were taken to show Haller destroying the interrogation room table.|$|E
5000|$|Nendogami (14): Created {{from old}} dark clay {{and a new}} camera. Able to change his own figure, freely like clay, create grenades from his clay, with his <b>camera</b> <b>arm</b> able to change {{memories}} and dreams in people's minds, as well as able to change existences itself. He was disguised as Natsuki's younger sister [...] "Miria" [...] (although {{it is not known}} whether there is such a person), and planted fake memory in Natsuki, as well as giving her a bracelet exactly like her own, {{which turned out to be}} a mind controlling device. Natsuki, who was deceived, pounced on Masumi and the other Boukengers. It was only Masumi admitting his love for Natsuki and the destroying of the bracelet that freed her. After being defeated by the Dual Crusher (used by Bouken Yellow), the giant Nendogami futilely tried to avoid being terminated by Super DaiBouken by taking Masumi's human form, thinking that because he looked like Masumi, the Boukengers wouldn't attack him. Unsurprisingly, Natsuki wasn't fooled, as she instantly realized that Masumi was sitting right next to her, and was not normally over 30 stories tall. [...] means [...] "clay" [...] in Japanese. Nendogami's design is based on Ninpuu Sentai Hurricanegers Fuuraimaru. Voiced by Keiichi Sonobe (Sonobe Keiichi), while his human form is portrayed by Yukiko Ikari (Ikari Yukiko).|$|E
40|$|Two photos {{taken in}} ONE Archives garden area located outside the building, {{following}} ONE Archives Pink Ink Garden Party. (Top photo) Unidentified woman with long dark hair, tattoo on left arm, wearing backless shirt or dress, {{who is standing}} with back to the <b>camera,</b> <b>arms</b> folded behind her back, and who is looking toward the cactus garden. (Bottom photo) Ann Bradley and Dana Champion. May 4, 2003...|$|R
5000|$|A dynamic {{destruction}} {{system where}} vehicles can be destroyed by severing their <b>cameras,</b> robotic <b>arms,</b> and individual struts and wheels.|$|R
50|$|Reconnaissance {{version with}} glazed nose for second crewman (navigator) and two <b>cameras.</b> Aircraft <b>armed</b> with 23mm cannon, 10 {{pre-production}} aircraft built.|$|R
30|$|Figure 14 a {{shows the}} view sent from Robot-W’s <b>camera</b> <b>arm.</b> The <b>camera</b> <b>arm</b> was {{programmed}} {{to track the}} second arm’s end effector. Therefore, the operator was able to remote control Robot-W and perform various manipulations using only the <b>camera</b> <b>arm.</b> However, the view was limited, and the operator had to constantly change the end effector’s direction to see the surroundings. To visually confirm that the object was grasped, the operator might need to also move Robot-W’s cart and determine how to approach the objects to get a suitable view. Since {{the view from the}} <b>camera</b> <b>arm</b> was not intuitive to operate the robot, and the camera was able to capture only a limited area, the teleoperation process became very difficult and time consuming.|$|E
30|$|Relying on <b>camera</b> <b>arm</b> + {{developed}} support system.|$|E
30|$|Relying on <b>camera</b> <b>arm</b> + two fixed cameras.|$|E
5000|$|Detachable payload tray {{allows the}} owner to carry objects on robot or {{customize}} it with <b>cameras,</b> robotic <b>arm</b> and so on.|$|R
50|$|Between the {{platforms}} B and C was a metal-glass {{barrier that}} practically fulfilled the same {{function as the}} Berlin wall: East German border troops had separated the station into two completely isolated areas, both fully under armed control, the one for people within East Berlin {{and the other for}} transit travellers, persons switching between the different westbound train lines and the few Easterners with a hard-to-obtain exit visa, all within one station building with a maze of connecting hallways, barriers, numerous <b>cameras,</b> <b>armed</b> guards with sniffer dogs, plain-clothes agents, and a loggia under the roof for surveillance by armed border patrol and Stasi officers.|$|R
50|$|ARM {{has been}} the CPU {{architecture}} of choice for manufacturers of smartphones (95% <b>ARM),</b> PDAs, digital <b>cameras</b> (80% <b>ARM),</b> set-top boxes, DSL routers, smart televisions (70% ARM), storage devices and tablet computers (95% ARM). This dominance began {{with the release of}} the mobile-focused and comparatively power-efficient 32-bit ARM610 processor originally designed for the Apple Newton in 1993 and ARM3-using Acorn A4 laptop in 1992. The chip was adopted by Psion, Palm and Nokia for PDAs and later smartphones, camera phones, <b>cameras,</b> etc. <b>ARM's</b> licensing model supported this success by allowing device manufacturers to license, alter and fabricate custom SoC derivatives tailored to their own products. This has helped manufacturers extend battery life and shrink component count along with the size of devices.|$|R
30|$|Since {{the view}} from each camera was {{outputted}} on a different display, participants had a difficulty in choosing which view is the most appropriate {{at a given time}} during remote control operation. An experienced operator can efficiently use static cameras to position the robot in environment and adjust the <b>camera</b> <b>arm</b> to the desirable view. However, it requires practicing and high concentration.|$|E
40|$|Camera control methods play a {{significant}} role in remote surgery. Two methods have been developed to control the <b>camera</b> <b>arm</b> of the da Vinci Surgical System: a standard clutch-based method for manual movement of the camera and an autonomous camera (auto-camera) method. In the standard method, the surgeon positions the camera manually using a pair of hand controllers. This happens frequently during the surgery and may serve as a distraction during surgical procedures. The second method was developed in order to help surgeon to remove the issue mentioned in the standard method. Auto-camera method enables the system to move the camera autonomously. In this method, the camera is moved with-respect-to the center of surgical tool arms with automatic zoom control ability. There are still many issues with automatically moving a camera. We will show the feasibility of an intermediate solution using an Oculus rift head mounted stereo display. Achieving the optimal camera viewpoint with simple control methods is of utmost importance for remote surgical systems. We propose a new method to move the <b>camera</b> <b>arm</b> based on sensors within the Oculus Rift. Can a surgeon put the Oculus Rift (virtual reality headset), get a stereoscopic view and control the camera with simple head gestures? In this case, the surgeon will be able to see the 3 D camera view of scope inside of the Oculus Rift and move the viewpoint by his/her head orientation. Position and orientation of the Oculus rift is measured by an inertial measuring unit and optical tracking sensors within the Oculus platform. These data can be used to control the position and orientation of the <b>camera</b> <b>arm.</b> In this thesis, a complete system will be created based on the Robot Operating System (ROS) and a 3 D simulation of the da Vinci robot in RViz. In addition, a usability study will be conducted to analyze system accuracy. For this system evaluation, headset orientation will be compared to corresponding orientation of the camera in simulation. We will also check whether subjects can use the system comfortable during a simple operation. In this study, we propose controlling of the <b>camera</b> <b>arm</b> by Oculus Rift as a new method for camera control. It is anticipated that the headset movement will be the same as its corresponding simulation in RViz (simulation environment for the robot). We anticipate that our results will demonstrates feasibility for this method to control a camera. We will propose next steps for testing this system on the da Vinci hardware leading towards a system for the operating room of the future...|$|E
30|$|The {{experiment}} {{took place}} in our laboratory. The KUKA youBot with two 5 DoF manipulators {{was used as a}} teleoperation robot, hereinafter called a working robot (Robot-W). One of the working robot’s manipulators was equipped with a camera and was programmed to track another arm’s end effector. Thus, the operator could see the manipulator’s end effector and perform various tasks while relying on the images from the <b>camera</b> <b>arm.</b> The proposed support system consisted of two robots: a fixed wide-view monitoring robot (Robot-M_W) and a moving local-view monitoring robot (Robot-M_L). Both monitoring robots were equipped with RGB-D cameras. The task site contained both known and unknown system objects.|$|E
40|$|Photos {{from the}} Long Beach Pride Parade 2008. (Top photo) Rainbow flags waving {{in the breeze}} in front of Ocean Boulevard condos. (Bottom photo) People {{standing}} on the curb watching the parade {{in front of the}} Beach City Hotel. Standing with back to <b>camera</b> with <b>arm</b> pointing into the air is Carolyn Weathers. May 2008...|$|R
5000|$|... #Caption: Ginas Restaurant, a {{photograph}} by Charles Thomson (centre). He states: [...] "The photos that I am in, I took with the <b>camera</b> held at <b>arms</b> length." ...|$|R
5000|$|Robotic <b>Arm</b> <b>Camera</b> (RAC): Located on {{the robotic}} arm, the charge coupled camera {{included}} two red, two green, and four blue lamps to illuminate soil samples for analysis.|$|R
40|$|Abstract. Aim: To {{investigate}} the clinical {{assessment of a}} full high-definition (HD) three-dimensional robot-assisted laparoscopic device in gynaecological surgery. Patients and Methods: This study included 70 women who underwent gynaecological laparoscopic procedures. Demographic parameters, type and duration of surgery and perioperative complications were analyzed. Fifteen surgeons were postoperatively interviewed regarding their assessment of this new system with a standardized questionnaire. Results: The clinical assessment revealed that three-dimensional full-HD visualisation is comfortable and improves spatial orientation and hand-to-eye coordination. The majority of the surgeons stated they would prefer a three-dimensional system to a conventional two-dimensional device and stated that the robotic <b>camera</b> <b>arm</b> led to more relaxed workin...|$|E
40|$|A reading machine from LVI {{which can}} scan {{and read a}} text for visual {{impaired}} people needed a redesign to stay competitive. This redesign is done by two students. The students made a specialized method to execute the redesign. They {{found out that the}} focus of the redesign should lay on: easy to use, reliable result and appealing for the user. With this taken in consideration the students achieved to design a more competitive reading machine. Prototypes where made for a new <b>camera</b> <b>arm</b> (which goes high enough to scan A 3 format) and a new control panel. The students gave a recommendation how to continue with the project from now on...|$|E
40|$|The Shear History Extensional Rheology Experiment (SHERE) is a {{proposed}} International Space Station (ISS) glovebox experiment designed {{to study the}} effect of preshear on the transient evolution of the microstructure and viscoelastic tensile stresses for monodisperse dilute polymer solutions. Collectively referred to as Boger fluids, these polymer solutions have become a popular choice for rheological studies of non-Newtonian fluids and are the non-Newtonian fluid used in this experiment. The SHERE hardware consists of the Rheometer, <b>Camera</b> <b>Arm,</b> Interface Box, Cabling, Keyboard, Tool Box, Fluid Modules, and Stowage Tray. Each component will be described in detail in this paper. In the area of space exploration, the development of in-situ fabrication and repair technology represents a critical element in evolution of autonomous exploration capability. SHERE has the capability to provide data for engineering design tools needed for polymer parts manufacturing systems to ensure their rheological properties have not been impacted in the variable gravity environment {{and this will be}} briefly addressed...|$|E
40|$|Fine {{motions of}} robotic {{manipulator}} controlled {{with help of}} visual feedback by new method reducing position errors by order of magnitude. Robotic vision subsystem includes five cameras: three stationary ones providing wide-angle views of workspace and two mounted on wrist of auxiliary robot <b>arm.</b> Stereoscopic <b>cameras</b> on <b>arm</b> give close-up views of object and end effector. Cameras measure errors between commanded and actual positions and/or provide data for mapping between visual and manipulator-joint-angle coordinates...|$|R
40|$|The {{capacity}} for learning to recognize and exploit environmental affordances is an im-portant consideration {{for the design of}} current and future developmental robotic systems. We present a system that uses a robotic <b>arm,</b> <b>camera</b> systems and self-organizing maps to learn basic affordances of objects. 1...|$|R
50|$|Memo Cruz (Luis Fernando Peña), {{works at}} a factory, one of several sleep dealers. Here, workers are {{connected}} to the network via suspended cables connected to implanted nodes in their arms and back, allowing them to control the robots that have replaced them as unskilled labor {{on the other side of}} the border. The sleep dealers are called so because one may collapse if one works long enough. The story is told as a flash back, as Memo remembers his home in Santa Ana Del Rio, Oaxaca. His father wants him to participate in growing crops on the meagre family homestead. Memo's passion however is electronics and hacking. The homestead also has dried up on account of a dam built nearby and owned by the private corporation Del Rio Water. Memo and his father must trek on foot to buy water by the bag, while monitored by security <b>cameras</b> <b>armed</b> with machine guns. The media on American hi-def TV shows glimpses of a technological dystopia, although in a positive light with superficial spin-doctoring. As a hobby, Memo is building an electronic receiver that can tap into communications. As he continues to work on it, its range increases to far away cities.|$|R
40|$|Nearly {{three decades}} ago as Voyager 2 {{spacecraft}} raced out of the Solar System. NASA engineers turned its <b>camera</b> <b>arm</b> around (at {{the request of the}} American astronomer Carl Sagan) to take a parting snapshot of Earth. Earth's image was a single pale blue pixel, its color caused by the Rayleigh scattering of sunlight in the water of our oceans. Earth is a water planet, and this is the color of life. No matter how far we travel on our planet, no matter how high or deep, if we find liquid water, we find some form of life that manages to survive there. And yet there is a cruel irony. Water in its solid crystalline form is hostile to life. Organisms can roost in geysers, wallow in brine and gulp down acid, but they cowered from ice. The rigid ordering of water molecules in ice crystals expels impurities and tears organic tissue beyond repair. In fact, about the only good thing you can say about ice is that it gets out of the way: Its low density ensures that it floats and leaves the water dwelling creatures in peace. Recent discoveries have caused us to rethink this basic premise. New lines of evidence both observational and experimental - suggest that prebiotic organic compounds are not only comfortable in, but in fact had their origin in a peculiar form of solid water ice that is ubiquitous in interstellar space, but completely absent from Earth. Only recently have we been able to create even submicroscopic quantities of this ice in terrestrial laboratories, yet it constitutes the most abundant form of water in the universe. Interstellar ice {{is a far cry from}} the ice we are so familiar with on Earth. This interstellar ice has no crystalline structure, and despite the fact that its temperature is a scant few degrees above absolute zero (where all molecular motion ceases), it is highly reactive and can flow like water when exposed to radiation. It is in fact this ice's similarity to liquid water that allows it to participate in the creation of the very first organic compounds...|$|E
40|$|Lameness in sows {{not only}} poses a {{health and welfare}} concern, but also leads to {{considerable}} economic losses for the farmer. The disease condition increases labour and treatment costs and leads to premature culling and euthanasia of sows. Since the obligation to house sows in groups in the European Union in 2013, an increase in lameness prevalence is seen. It is therefore essential that lameness is detected accurately and at an early stage. Visual detection of lameness is difficult due to the group-housing of sows {{and the increase in}} farm size. It is also a subjective technique, usually only detecting severe lameness cases. Recently, at ILVO SowSIS (sow stance information system) was designed and validated for objective lameness detection in sows. SowSIS performs automatic force measurements and additionally generates visual stance variables using a transportable device with four load cells (one for each leg of the sow) and a <b>camera</b> <b>arm.</b> A sow is guided into the device and the force exerted by each of the four legs is measured. Using the camera, a lateral digital image can be taken of the hind legs. An adapted version of the SowSIS system has now been implemented in four electronic sow feeders (ESF), using only the force stance variables. We want to validate this adapted system for individual online and repeated measurements of group-housed sows, without interfering with their daily routine. A trigger is used to start the measurements automatically while a sow is feeding. The sow is automatically identified at the trough. Due to the asymmetric design of the ESF (feed trough in the left or right front corner of the ESF), a correction for the uneven balance of the sow is necessary. Measurements are performed in four pens on ILVO’s experimental farm. Sows will be followed-up throughout time to validate the adapted system and its ability to detect changes in the force stance variables related to lameness development. When the system has been validated, the automatically gathered data can be used to signal the farmer when a lameness case is arising. The SowSIS implementation in ESF thus aims at early detection of lameness cases and possible prevention of economic losses. status: publishe...|$|E
40|$|The Liquid Waste Technology Development {{organization}} is investigating technologies to support closure of radioactive waste tanks at the Savannah River Site (SRS). Tank closure includes {{removal of the}} wastes that have propagated to the tank annulus. Although amounts and types of residual waste materials in the annuli of SRS tanks vary, simple salt deposits are predominant on tanks with known leak sites. This task focused on developing and demonstrating a technology to inspect and spot clean salt deposits from the outer primary tank wall located in the annulus of an SRS Type I tank. The Robotics, Remote and Specialty Equipment (RRSE) and Materials Science and Technology (MS&T) Sections of the Savannah River National Laboratory (SRNL) collaborated to modify and equip a Force Institute magnetic wall crawler with the tools necessary to demonstrate the inspection and spot cleaning in a mock-up of a Type I tank annulus. A remote control <b>camera</b> <b>arm</b> and cleaning head were developed, fabricated and mounted on the crawler. The crawler was then tested and demonstrated on a salt simulant also developed in this task. The demonstration showed that the camera is capable of being deployed in all specified locations and provided the views needed for the planned inspection. It also showed that the salt simulant readily dissolves with water. The crawler features two different techniques for delivering water to dissolve the salt deposits. Both water spay nozzles were able to dissolve the simulated salt, one is more controllable and the other delivers a larger water volume. The cleaning head also includes a rotary brush to mechanically remove the simulated salt nodules in the event insoluble material is encountered. The rotary brush proved {{to be effective in}} removing the salt nodules, although some fine tuning may be required to achieve the best results. This report describes the design process for developing technology to add features to a commercial wall crawler and the results of the demonstration testing performed on the integrated system. The crawler was modified to address the two primary objectives of the task (inspection and spot cleaning). SRNL recommends this technology as a viable option for annulus inspection and salt removal in tanks with minimal salt deposits (such as Tanks 5 and 6.) This report further recommends that the technology be prepared for field deployment by: (1) developing an improved mounting system for the magnetic idler wheel, (2) improving the robustness of the cleaning tool mounting, (3) resolving the nozzle selection valve connections, (4) determining alternatives for the brush and bristle assembly, and (5) adding a protective housing around the motors to shield them from water splash. In addition, SRNL suggests further technology development to address annulus cleaning issues that are apparent on other tanks that will also require salt removal in the future such as: (1) Developing a duct drilling device to facilitate dissolving salt inside ventilation ducts and draining the solution out the bottom of the ducts. (2) Investigating technologies to inspect inside the vertical annulus ventilation duct...|$|E
50|$|Just {{before the}} dive, Askew and Ron Taylor were {{kneeling}} on the dive platform a few centimetres above water, with their hands in the water filming. Askew stood up and stepped back, {{and at that moment}} a four-metre Great White slid onto the platform and stopped 3 inches from his foot before sliding back, but made no attempt to snap or lunge at him. It would have taken his <b>camera</b> and <b>arms,</b> and maybe pulled him in if he had not got up. Askew sees that incident as pure opportunism and not savagery.|$|R
25|$|In a November {{afternoon}} of 1999, Cárdenas {{learned that a}} Gulf Cartel informant was being transported through Matamoros, Tamaulipas, by the FBI and DEA. According to the story mentioned in the interviews 11 years after this life-or-death incident, the DEA agent Joe DuBois and FBI agent Daniel Fuentes were riding in a white Ford Bronco with diplomatic plates along the streets of Matamoros, Tamaulipas. For years, both were working for the disarticulation of the cartels in Mexico, and both knew how the drug cartels worked south of the border. In {{the back seat of}} the car, a Mexican informant from a local newspaper on crime coverage guided the two agents and gave them a tour on the city's drug routes and on the homes of the drug lords of the city. They even cruised by Cárdenas' house, a pink-colored mansion with tall walls, security <b>cameras,</b> <b>armed</b> guards and roof-snipers. Within moments, according to DuBois, a Lincoln Continental was on their tail, then a stolen pickup truck with Texan plates. The federal agents were cut off and surrounded by at least five vehicles, including one by a former state police officer. Just yards away from Matamoros' police department, the agents were surrounded by a convoy of gunmen from the Gulf Cartel, which included Costilla Sánchez. Some wore police and military uniforms. Nearby, other men, also in police uniform, directed traffic.|$|R
25|$|On a November {{afternoon}} in 1999, Osiel Cárdenas {{learned that a}} Gulf Cartel informant was being transported through Matamoros, Tamaulipas, by the FBI and DEA. According to the story mentioned in the interviews 11 years after this life-or-death incident, the DEA agent Joe DuBois and FBI agent Daniel Fuentes were riding in a white Ford Bronco with diplomatic plates along the streets of Matamoros, Tamaulipas. For years, both were working for the disarticulation of the cartels in Mexico, and both knew how the drug cartels worked south of the border. In {{the back seat of}} the car, a Mexican informant from a local newspaper on crime coverage guided the two agents and gave them a tour on the city's drug routes and on the homes of the drug lords of the city. They even cruised by Cárdenas' house, a pink-colored mansion with tall walls, security <b>cameras,</b> <b>armed</b> guards and roof-snipers. Within moments, according to DuBois, a Lincoln Continental was on their tail, then a stolen pickup truck with Texan plates. The federal agents were cut off and surrounded by at least five vehicles, including one by a former state police officer. Just yards away from Matamoros' police department, the agents were surrounded by a convoy of gunmen from the Gulf Cartel. Nearby, other men, also in police uniform, directed traffic.|$|R
