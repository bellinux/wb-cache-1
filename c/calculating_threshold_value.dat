3|10000|Public
40|$|In {{order to}} deliver {{high quality video}} {{compressed}} by H. 264 /AVC standard with flexible macroblock ordering (FMO) applied over wireless environment, new motion energy based unequal error protection technique (UEP) is proposed. Motion energy (ME) of video frames is computed to determine the importance of frames. According to two different methods in <b>calculating</b> <b>threshold</b> <b>value</b> of motion energy, video frames can be scaled in three different levels and two different levels respectively. Appropriate forward error correction (FEC) codes with various coding rates are applied to different frames according to their importance. In two-level UEP method, low coding rate will be applied for high important frames while low important frames will be protected by the same code with high coding rate. While in three-level UEP method, one more coding rate named as medium coding rate is introduced to operate on middle-important frames. The proposed techniques will be verified by simulations...|$|E
40|$|Recently, Wireless Body Area Network (WBAN) has {{witnessed}} significant attentions {{in research and}} product development due to {{the growing number of}} sensor-based applications in healthcare domain. Design of efficient and effective Medium Access Control (MAC) protocol is one of the fundamental research themes in WBAN. Static on-demand slot allocation to patient data is the main approach adopted in the design of MAC protocol in literature, without considering the type of patient data specifically the level of severity on patient data. This leads to the degradation of the performance of MAC protocols considering effectiveness and traffic adjustability in realistic medical environments. In this context, this paper proposes a Traffic Priority-Aware MAC (TraPy-MAC) protocol for WBAN. It classifies patient data into emergency and non-emergency categories based on the severity of patient data. The threshold value aided classification considers a number of parameters including type of sensor, body placement location, and data transmission time for allocating dedicated slots patient data. Emergency data are not required to carry out contention and slots are allocated by giving the due importance to threshold value of vital sign data. The contention for slots is made efficient in case of non-emergency data considering threshold value in slot allocation. Moreover, the slot allocation to emergency and non-emergency data are performed parallel resulting in performance gain in channel assignment. Two algorithms namely, Detection of Severity on Vital Sign data (DSVS), and ETS Slots allocation based on the Severity on Vital Sign (ETS-SVS) are developed for <b>calculating</b> <b>threshold</b> <b>value</b> and resolving the conflicts of channel assignment, respectively. Simulations are performed in ns 2 and results are compared with the state-of-the-art MAC techniques. Analysis of results attests the benefit of TraPy-MAC in comparison with the state-of-the-art MAC in channel assignment in realistic medical environments...|$|E
40|$|Wireless ad-hoc {{networks}} are autonomous systems composed of mobile hosts that {{are free to}} move around arbitrarily. Routing is difficult in MANET’s since mobility may cause radio links to break frequently. When any link of a path breaks, this path needs to be either repaired by finding another link if any or replaced with a new path. To reduce rerouting operation, selecting an optimal path in such networks should consider both path reliability and energy efficiency. End-to-end reliability is used to reflect the probability of sending data successfully from the source to destination node. In existing system ACO frame work named Simple Ant Routing Algorithm(SARA) used to reduce the overhead, by using a new route discovery technique, based {{on the concept of}} Control Neighbor Broadcast (CNB). The CNB allows SARA to control the control packets flooding level in the network. This flooding mechanism as the disadvantage of increase the time required to discover a route. It lacks an efficient support of MANETs, as they require the use of a significant amount of control information during the route discovery process. The network capability to maintain the routes decreases. In high mobility scenarios it decrease SARA’s performance and increase the overhead. The Dynamic Source Routing (DSR) plays a prominent role in source routing, where reliability and energy efficiency {{plays an important role in}} the performance of routing in MANET”. A bio inspired algorithm dynamic source routing has been designed to enhance dynamic source routing based on the integration of ant colony and bee colony optimization techniques. The route discovery process is done by applying ACO and BCO by <b>calculating</b> <b>threshold</b> <b>value</b> based on energy consumed by each intermediate node and pheromone value. The path with minimum threshold and maximum pheromone is chosen as the best path and the path is considered for sending data packets the results show that the energy consumed by BeeDSR is less, PDR is high and delay is reduced...|$|E
50|$|It has no {{learning}} process as such. Its transfer function weights are <b>calculated</b> and <b>threshold</b> <b>value</b> are predetermined.|$|R
40|$|In this paper, a new {{algorithm}} using wavelet {{properties to}} compress an image is proposed. This algorithm concern on reducing the wavelet coefficients {{produced by the}} Discrete Wavelet Transform (DWT) process. The proposed algorithm start with <b>calculating</b> the <b>threshold</b> <b>value</b> by using the proposed <b>threshold</b> <b>value</b> estimator at wavelet detail subbands (Diagonal, Vertical and Horizontal subband). This proposed algorithm will estimate the suitable <b>threshold</b> <b>value</b> for each individual subband. The <b>calculated</b> <b>threshold</b> <b>values</b> are then applied to its’ respective subband. The coefficient with a lower <b>value</b> than the <b>calculated</b> <b>threshold</b> will be discarded while the rest are retained. The novelty of the proposed method is it use {{the principle of the}} standard deviation method of deriving the <b>threshold</b> <b>value</b> estimator equation. Experiments show that the proposed method can effectively remove a large amount of unnecessary wavelet coefficient with a higher Peak Signal to Noise Ratio (PSNR) and compression ratio as well as shorter elapse time...|$|R
3000|$|... с[*]≈[*] 1.95  vol. %) binary composites. <b>Calculated</b> {{percolation}} <b>threshold</b> <b>values</b> (in vol. %) {{for several}} different CNT:GNP ratios are quite comparable with each other: φ [...]...|$|R
30|$|The {{comparison}} of leaf density values for Urtica in Fig.  1 confirms this conclusion {{for the actual}} EFSA Panel model [1, 4]. All three EFSA Panel scenarios (MR, DC, CO) generate considerably lower estimates than the one based on our observations, which covers the whole distance range from 0.2 to 4.42  km. The <b>calculated</b> <b>threshold</b> <b>values</b> at 20 – 30  m of the EFSA Panel scenarios can only be met beyond the kilometre range.|$|R
40|$|Segmentation of {{the white}} matter from the brain fMRI images {{for the study of}} brain {{activities}} and for the diagnosis for various brain related diseases caused by the changes and damages to regions of the brain continues on a manual time consuming segmentation technique. We present a solution for automatic segmentation of the brain fMRI images; the solution contains three steps which are pre-processing the raw images, threshold estimation using an Otsu’s algorithm and finally performing the segmentation by binarization of the images based on the <b>calculated</b> <b>threshold</b> <b>value...</b>|$|R
30|$|Positive margin: Used to <b>calculate</b> {{the upper}} <b>threshold</b> <b>value</b> above which the section is {{considered}} to be occupied.|$|R
30|$|In this study, {{human health}} risk models {{including}} carcinogenic and non-carcinogenic risks raised by United States Environmental Protection Agency (USEPA) were <b>calculated.</b> The <b>threshold</b> <b>values</b> proposed by USEPA {{were employed to}} assess the potential health risks on the consumers. Currently, there is no agreed limit for acceptable maximum carcinogenic and non-carcinogenic risk levels in Bangladesh.|$|R
30|$|Wireless sensor {{networks}} (WSNs) {{demand the}} implementation of energy-aware techniques and low-complexity protocols in all layers. Recently, a MIMO-based structure has been proposed to offer enhanced energy savings in WSNs. In this paper, we examine and compare MIMO-based WSN with a multihop transmission in terms of energy efficiency. The results depend on the network density, the channel conditions, and {{the distance to the}} destination node. We reach analytical expressions to <b>calculate</b> <b>threshold</b> <b>values</b> of these parameters, which determine the areas where the MIMO-based structure outperforms multihop transmission. Moreover, we present a detailed analysis of the dissipated power during a sensor node_s operation, to prove that as microelectronics develops, the MIMO-based architecture will outperform the equivalent multihop structure for most of the cases examined. Finally, we implement a simple cooperative node selection algorithm to achieve higher energy gains in the MIMO approach, and we examine how this algorithm affects the <b>calculated</b> <b>thresholds.</b>|$|R
50|$|In 2013, a {{re-examination}} of Gould's algorithm and the utilisation {{of advanced}} Python programming modules (i.e., numpy and scipy) {{has made it}} possible to <b>calculate</b> the squared-error <b>threshold</b> <b>values</b> for identifying outliers.|$|R
40|$|Abstract Wireless sensor {{networks}} (WSNs) {{demand the}} implementation of energy-aware techniques and low-complexity protocols in all layers. Recently, a MIMO-based structure has been proposed to offer enhanced energy savings in WSNs. In this paper, we examine and compare MIMO-based WSN with a multihop transmission in terms of energy efficiency. The results depend on the network density, the channel conditions, and {{the distance to the}} destination node. We reach analytical expressions to <b>calculate</b> <b>threshold</b> <b>values</b> of these parameters, which determine the areas where the MIMO-based structure outperforms multihop transmission. Moreover, we present a detailed analysis of the dissipated power during a sensor node_s operation, to prove that as microelectronics develops, the MIMO-based architecture will outperform the equivalent multihop structure for most of the cases examined. Finally, we implement a simple cooperative node selection algorithm to achieve higher energy gains in the MIMO approach, and we examine how this algorithm affects the <b>calculated</b> <b>thresholds.</b> </p...|$|R
30|$|In this paper, {{we study}} a predator-prey-mutualist system with {{digestion}} delay. First, we <b>calculate</b> the <b>threshold</b> <b>value</b> of delay and {{prove that the}} positive equilibrium is locally asymptotically stable when the delay {{is less than the}} <b>threshold</b> <b>value</b> and the system undergoes a Hopf bifurcation at the positive equilibrium when the delay is equal to the <b>threshold</b> <b>value.</b> Second, by applying the normal form method and center manifold theorem, we investigate the properties of Hopf bifurcation, such as the direction and stability. Finally, some numerical simulations are carried out to verify the main theoretical conclusions.|$|R
30|$|Negative margin: Used to <b>calculate</b> {{the lower}} <b>threshold</b> <b>value</b> below which the section is {{considered}} to be vacant, this value should be more conservative than the positive threshold as it will decide for this section and its channels to be vacant.|$|R
40|$|Digital {{image has}} size and {{object in the}} form of {{foreground}} and background. To separate it, it is necessary to be conducted the image segmentation process. Otsu thresholding method is one of image segmentation method. In this research is divided into five processes, which are input image, pre-processing, segmentation, cleaning, and accuracy calculation. First process was input color images which consists of multiple objects. Second process was conversion from color image to grayscale image. Third process was automatically <b>calculated</b> <b>threshold</b> <b>value</b> using Otsu <b>thresholding</b> method, followed by binary image transformation. The fourth process, the result of third process is changed into negative image as the segmentation results, noise removal with a <b>threshold</b> <b>value</b> of 150, and morphology. The last accuracy calculation is conducted to measure proposed segmentation method performance. The experimental result have been compared to the image of Ground Truth as the direct user observation to calculate accuracy. To examine the proposed method, Weizmann Segmentation Database is used as data set. It conconsist of 30 color images. The experimental results show that 93. 33 % accuracy were achieved...|$|R
3000|$|In Equations 16 and 17, we give a new {{formulation}} of the parameters {{that allows us to}} <b>calculate</b> the multichannel <b>threshold</b> <b>value</b> T. The first term specified an intra-scale relationship (spatial), and the second defined an inter-channel correlation. We note that in the second term of [...]...|$|R
30|$|A {{simple and}} quick method was {{proposed}} {{in this paper}} for determining DEMATEL <b>threshold</b> <b>value</b> by adopting the concepts of fractional factorial design. A food and beverage information system was analyzed with a DTPB model; that model with rebuilt with DEMATEL <b>threshold</b> <b>value.</b> The results proved that by rebuilding, one can <b>calculate</b> reasonable DEMATEL <b>threshold</b> <b>value</b> and one can determine additional relationships of variables from the original DTPB model.|$|R
30|$|This paper {{discusses}} {{the importance of}} the reasonable calculation of DEMATEL <b>threshold</b> <b>value</b> using the example of a food and beverage system. Subsequently, the DTPB information model theory that is used in this study is described. The proposed calculation steps and fractional factorial designs provide a reasonable and quick way to <b>calculate</b> DEMATEL <b>threshold</b> <b>value.</b> A food and beverage information system is planned by combining DEMATEL and DTPB model to discover the behaviors and inclinations of dining service workers in using the food and beverage information system. This paper argues for conclusions and notes limitations of the present work.|$|R
40|$|International audienceAbstractPhosphorus (P), a non-renewable resource, {{needs to}} be used more {{efficiently}} in agriculture. This requires using soil P tests. However, the P test <b>threshold</b> <b>values</b> for fertilizer response depend on many soil properties, {{some of which may}} be useful to estimate these <b>threshold</b> <b>values,</b> others not. Therefore, we searched here which soil properties are useful to estimate P <b>threshold</b> <b>values.</b> We <b>calculated</b> the <b>threshold</b> <b>values</b> for Olsen P and 0. 01  M CaCl 2 extractable P of 18 representative agricultural soils of the Mediterranean region of Spain. For that, we performed a P starvation experiment in which wheat and sunflower were alternatively pot-cropped. Results show that Olsen P <b>threshold</b> <b>values</b> are negatively correlated to P buffer capacity (r of − 0. 74, P lower than 0. 001), clay content (− 0. 82, 0. 001), pH (− 0. 76, 0. 001), and Fe oxide content (− 0. 55, 0. 05). Multiple regression models involving clay, pH or soil organic C, and phosphatase activity or organic hydrolysable P accounted for as much as 87  % of the variance in <b>calculated</b> Olsen P <b>threshold</b> <b>values.</b> In particular, there is a major effect of organic P on Olsen P <b>threshold</b> <b>values.</b> Single models based on routinely measured soil properties such as clay content and pH made accurate predictions of Olsen P <b>threshold</b> <b>values</b> with r 2 of 0. 81 and P lower than 0. 001...|$|R
40|$|We {{have used}} the Vienna ab-initio Simulation Package (VASP) to study the {{electronic}} and optical properties of ordered defect compounds (ODC's) CuIn 5 Se 8 and CuIn 3 Se 5. The supercells are generated with the parent chalcopyrite structure of CuInSe 2. The defect pair (2 V(Cu) (-) + In-Cu(2 +)) in CuInSe 2 {{plays an important role}} in the electronic and optical properties of the ODC's are investigated. The band structure and density of states of ODC's are discussed in terms of the parent chalcopyrite compound CuInSe 2. The calculated low defect formation energy explains the existence of the ODC's CuIn 5 Se 8 and CuIn 3 Se 5. The optical absorption peaks in the epsilon(2) (omega) are explained in the terms of band structure and density of states. The upper valence band of ODC is exclusively formed by the p-d hybridization of Cu- 3 d and Se- 4 p states. The obtained results are in good agreement with the available experimental data. The <b>calculated</b> <b>threshold</b> <b>values</b> for CuInSe 2 and ODC's are underestimated. ...|$|R
40|$|Abstract. We compare two routing-control {{strategies}} in a high-speed communication network with c parallel channels (routes), where information on service completions in down-stream servers is randomly delayed. The controller can either hold arriving messages {{in a common}} buffer, dispatching them to servers only when the delayed information becomes available (Wait option), or route jobs to the various channels, in a round-robin fashion, immediately upon their arrival. Interpreting the delays as servers’s vacations and considering overall queue sizes {{as a measure of}} performance, we show that the Wait strategy is superior as long as the mean information delay is below a <b>threshold.</b> We <b>calculate</b> <b>threshold</b> <b>values</b> for various combinations of load and c and show that, for a given load, the threshold increases with c and, for fixed c, the threshold decreases with an increasing load. If information is delayed on arrival instants, rather than on service completions, we show that the system {{can be viewed as a}} tandem queue and derive a generalization of a queue-decomposition result obtained by Altman, Kofman and Yechiali...|$|R
40|$|This paper proposes an {{improved}} image denoising algorithm based on M-Band Ridgelet Transform for speckle noise {{present in the}} medical images. NeighCoeff Thresholding algorithm is used to <b>calculate</b> the <b>threshold</b> <b>values.</b> The result of the improved method is tested on ultrasound and Magnetic Resonance Imaging (MRI) images affected with speckle noise. Peak Signal to Noise Ratio (PSNR), Mean Square Error (MSE) and Edge Preservation Index (EPI) {{has been used as}} parameters for evaluation of results. The performance of new method is compared with existing methods such as Wavelets, Ridgelet, and Curvelet...|$|R
40|$|Abstract — Traditionally {{firewall}} {{has been}} used to stop the intrusion attempts by an attacker. But firewalls have static configurations that block attacks based on source and destination ports and IP addresses. These are not sufficient to provide security from all the attacks. Therefore, we need IDS type systems which could analyze the payload of the packet to detect these attacks. Proposed IDS is in two phases to identified attacks. In Phase-I, A database is maintained in the server side which contains the authorized IP address of the Local Area Network (LAN). If the IP address of the incoming packets match in stored IP address then proposed concept allow that packet as normal packet because of predefined authorized IP address which is increase efficiency of the IDS. If the IP address of those packets does not match the stored IP address in the database then proposed concept check the <b>threshold</b> <b>value</b> of the incoming packets if the <b>threshold</b> <b>value</b> of the incoming packet are less then <b>calculated</b> <b>threshold</b> <b>value</b> then the packet is reported as normal packet otherwise reported packet as infected packets and reported to the admin by an alert message like email. In Phase-II, the proposed concept includes state protocol analysis and packet filtering techniques. At last the proposed IDS can effectively and efficiently detect the attacks that are similar to DOS, U 2 R, RST and Experimental results are also show that the proposed method can effectively detect the attack that is similar to TCP SYN FLOOD and other attacks...|$|R
40|$|BACKGROUND: The {{extent of}} sperm DNA fragmentation, {{which can be}} {{measured}} by the TUNEL assay, {{is one of the}} determinants of male fertility. However, the clinical application of this test to in-vivo situations is difficult owing to the absence of a statistically validated <b>threshold</b> <b>value.</b> METHODS: The aim {{of this study was to}} compare the results of TUNEL assay applied to semen samples from men of proven fertility (n = 47) and patients from an infertile population (n = 66), in order to establish a discriminating <b>threshold</b> <b>value.</b> RESULTS: Infertile patients had a higher mean level of DNA fragmentation than men of proven fertility (40. 9 ± 14. 3 % versus 13. 1 ± 7. 3 %, respectively; P < 0. 001). The area under the receiver operating characteristics curve was 0. 93 for 20 % sperm DNA fragmentation. The <b>calculated</b> <b>threshold</b> <b>value</b> for TUNEL assay to distinguish between fertile controls and infertile men was 20 %. At this threshold, specificity was 89. 4 [95 % confidence interval (CI) 83. 7 – 95. 1] and sensitivity was 96. 9 % (95 % CI 93. 8 – 100). The positive and negative predictive values of the 20 % sperm DNA fragmentation threshold were high: 92. 8 % (95 % CI 87. 9 – 97. 5) and 95. 5 % (95 % CI 91. 6 – 99. 3), respectively. CONCLUSION: This study demonstrates that sperm DNA fragmentation, as measured by TUNEL assay, is a highly valuable indicator of male fertility. Key words: DNA integrity/male infertility/spermatozoa/threshold value/TUNE...|$|R
40|$|A {{mathematical}} model of HIV/AIDS transmission incorporating treatment and drug resistance {{was built in}} this study. We firstly <b>calculated</b> the <b>threshold</b> <b>value</b> of the basic reproductive number (R 0) by the next generation matrix and then analyzed stability of two equilibriums by constructing Lyapunov function. When R 0 < 1, the system was globally asymptotically stable and converged to the disease-free equilibrium. Otherwise, the system had a unique endemic equilibrium which was also globally asymptotically stable. While an antiretroviral drug tried to reduce the infection rate and prolong the patients’ survival, drug resistance was neutralizing the effects of treatment in fact...|$|R
40|$|Abstract: — This {{paper is}} {{concern about the}} study of {{universal}} mobile technology system (UMTS) and handovers. CDMA cellular network support soft handover which guarantees the continuity of wireless service and enhance communication quality. Handover means transfer of user connection from one radio channel to another. Cellular network performance depends upon soft handover. Soft handover is that in which channel in the resource cell is retained and used {{for a while in}} parallel with channel in target cell. The main goal {{of this paper is to}} show that soft handover probability can be <b>calculated</b> with <b>threshold</b> <b>value...</b>|$|R
3000|$|When {{determining}} adequate buffer isolation distances, it {{is important}} to define threshold levels of leaf pollen density that must not be exceeded. For their proposed isolation buffer distances of 20 – 30  m, the EFSA Panel <b>calculated</b> a maximum <b>threshold</b> <b>value</b> for mean leaf pollen density of 0.28 n/cm 2 at 20  m and 0.01 n/cm 2 at 30  m ([14] log 10 [...]...|$|R
40|$|With {{rapid growth}} of the {{internet}} the amount of image and video data is increasing exponentially. The text data present in images and videos is useful for automatic annotations, indexing and structuring of images. There is huge increment in images and video database online. In such database, there is need to fetch, explore and inspect the images and videos. Text extraction {{plays a major role}} in finding vital and valuable information. Noise is an important factor that influences the quality of image which is mainly produced in the processes of image acquirement and transmission. An image can be contaminated by noise like salt and pepper noise, random valued impulse noise, speckle noise and Gaussian noise. For the removal of noise from images, the filtering algorithm like adaptive filter, average filter, maximum filter, median filter, minimum filter, trimmed filter and wiener filter are used. After removing noise from input complex image the text is extracted in binary form through proposed algorithm. The proposed method uses the techniques of local contrast, local gradient, adaptive map contrast, canny edge detection for detection of text strokes and Otsu threshold for calculation of <b>threshold</b> <b>value.</b> On the basis of <b>calculated</b> <b>threshold</b> <b>value</b> the pixels are classified into background and foreground. A comparative study of some popular existing filtering method is done for text extraction from complex images. The proposed method is simulated in MATLAB to verify and validate th...|$|R
40|$|In [1], a {{clustering}} algorithm {{was given}} to find the centers of clusters quickly. However, the accuracy of this algorithm heavily depend on the <b>threshold</b> <b>value</b> of d-c. Furthermore, [1] has not provided any efficient way to select the <b>threshold</b> <b>value</b> of d-c, that is, one can have to estimate the value of d_c depend on one's subjective experience. In this paper, based on the data field [2], we propose {{a new way to}} automatically extract the <b>threshold</b> <b>value</b> of d_c from the original data set by using the potential entropy of data field. For any data set to be clustered, the most reasonable value of d_c can be objectively calculated from the data set by using our proposed method. The same experiments in [1] are redone with our proposed method on the same experimental data set used in [1], the results of which shows that the problem to <b>calculate</b> the <b>threshold</b> <b>value</b> of d_c in [1] has been solved by using our method...|$|R
40|$|Abstract—Canny {{algorithm}} {{can be used}} in extracting the object’s contour clearly {{by setting}} the appropriate parameters. The Otsu algorithm can <b>calculate</b> the high <b>threshold</b> <b>value</b> which is significant to the Canny algorithm, and then this <b>threshold</b> <b>value</b> {{can be used in}} the Canny algorithm to detect the object’s edge. From the exprimental result, the Otsu algorithm can be applied in choosing the <b>threshold</b> <b>value</b> which can be used in Canny algorithm, and this method improves the effect of extracting the edge of the Canny algorithm, and achieves the expect result finally. Index Terms—image segmentation; Otsu; Canny; threshold; edge detectio...|$|R
40|$|Abstract. The {{severity}} {{of the impact of}} elevated atmospheric pCO 2 to coral reef ecosystems depends, in part, on how seawater pCO 2 affects the balance between calcification and dissolution of carbonate sediments. Presently, there are insufficient published data that relate concentrations of pCO 2 and CO 2 − 3 to in situ rates of reef calcification in natural settings to accurately predict the impact of elevated atmospheric pCO 2 on calcification and dissolution processes. Rates of net calcification and dissolution, CO 2 − 3 concentrations, and pCO 2 were measured, in situ, on patch reefs, bare sand, and coral rubble on the Molokai reef flat in Hawaii. Rates of calcification ranged from 0. 03 to 2. 30 mmol CaCO 3 m − 2 h − 1 and dissolution ranged from – 0. 05 to – 3. 3 mmol CaCO 3 m − 2 h − 1. Calcification and dissolution varied diurnally with net calcification primarily occurring during the day and net dissolution occurring at night. These data were used to <b>calculate</b> <b>threshold</b> <b>values</b> for pCO 2 and CO 2 − 3 at which rates of calcification and dissolution are equivalent. Results indicate that calcification and dissolution are linearly correlated with both CO 2 − 3 and pCO 2. Threshold pCO 2 and CO 2...|$|R
40|$|The Hillgrove mineral field, {{part of the}} New England Orogen, host’s gold, {{antimony}} and tungsten in {{the form}} of scheelite mineralisation in a number of structures. Mineralisation is hosted in the Girrakool beds, Hillgrove Plutonic Suite and Bakers Creek Diorite Complex. Commercial mining of antimony has been undertaken on numerous occasions since its discovery in the late 1800 ’s, without long-term success. Straits Resources Limited undertook large-scale soil sampling of their exploration tenements, a subset of their data was provided for analysis. The majority of samples, within the study area, a sheep farm adjacent to the town of Metz, were acquired from soils derived from the Girrakool beds. Statistical analysis identified antimony and arsenic as the two best pathfinders for gold. Arsenic, mercury and gold were discovered as the best pathfinders for antimony and mercury was also found to be a pathfinder for tungsten. Acceptable maximum thresholds in the O horizon for the trace element concentrations of gold (0. 0025 ppm), antimony (22 ppm) and tungsten (0. 65 ppm) as well as the pathfinders, arsenic (24 ppm) and mercury (0. 11 ppm) were calculated. The distribution of trace element concentrations was mapped over the study area using the <b>calculated</b> <b>threshold</b> <b>values</b> to identify possible locations of mineral occurences. A potential stibnite vein was identifie...|$|R
40|$|Stability {{analysis}} {{programs are}} a primary tool used by power system planning and operating engineers {{to predict the}} response of the system to various disturbances. Important conclusions and decisions are made {{based on the results of}} stability studies. The conventional method of analyzing stability is to calculate the transient behaviour of generators due to a given disturbance. Direct methods of stability analysis identify whether or not the system will remain stable once the disturbance is removed by comparing it with a <b>calculated</b> <b>threshold</b> <b>value.</b> Direct methods not only avoid the time consuming solutions required in the conventional method, but also provide a quantitative measure of the degree of system stability. This additional information makes direct methods very attractive when the relative stability of different plans must be compared or when stability limits must be calculated quickly. Direct methods of transient stability analysis of a multi machine power system, using a function describing the system's transient energy, are discussed. By examining the trajectory of the disturbed system, the following fundamental questions are dealt with: the concept of a controlling unstable equilibrium point (U. E. P), the manner in which some generators tend to lose synchronism, and identifying the energy directly responsible for system separation. Resolving this issue will substantially improve transient stability analysis by direct method...|$|R
40|$|The {{severity}} {{of the impact of}} elevated atmospheric pCO 2 to coral reef ecosystems depends, in part, on how seawater pCO 2 affects the balance between calcification and dissolution of carbonate sediments. Presently, there are insufficient published data that relate concentrations of pCO 2 and CO 3 ** 2 - to in situ rates of reef calcification in natural settings to accurately predict the impact of elevated atmospheric pCO 2 on calcification and dissolution processes. Rates of net calcification and dissolution, CO 3 ** 2 - concentrations, and pCO 2 were measured, in situ, on patch reefs, bare sand, and coral rubble on the Molokai reef flat in Hawaii. Rates of calcification ranged from 0. 03 to 2. 30 mmol CaCO 3 /m** 2 /h and dissolution ranged from - 0. 05 to - 3. 3 mmol CaCO 3 /m** 2 /h. Calcification and dissolution varied diurnally with net calcification primarily occurring during the day and net dissolution occurring at night. These data were used to <b>calculate</b> <b>threshold</b> <b>values</b> for pCO 2 and CO 3 ** 2 - at which rates of calcification and dissolution are equivalent. Results indicate that calcification and dissolution are linearly correlated with both CO 3 ** 2 - and pCO 2. Threshold pCO 2 and CO 3 ** 2 - values for individual substrate types showed considerable variation. The average pCO 2 <b>threshold</b> <b>value</b> for all substrate types was 654 ± 195 µatm and ranged from 467 to 1003 µatm. The average CO 3 ** 2 - <b>threshold</b> <b>value</b> was 152 ± 24 µmol/kg, ranging from 113 to 184 µmol/kg. Ambient seawater measurements of pCO 2 and CO 3 ** 2 - indicate that CO 3 ** 2 - and pCO 2 <b>threshold</b> <b>values</b> for all substrate types were both exceeded, simultaneously, 13 % of the time at present day atmospheric pCO 2 concentrations. It is predicted that atmospheric pCO 2 will exceed the average pCO 2 <b>threshold</b> <b>value</b> for calcification and dissolution on the Molokai reef flat by the year 2100...|$|R
40|$|Our attempt {{consists}} of modelling the heart left ventricle at stress and rest situation, using the myocardial scintigraphic data {{and focuses on}} how to demonstrate differences in obtained 3 D stress/rest images. 70 cardiac patients had completed myocardium tests by Tc- 99 m tetrofosmin and a GE-Starcam - 4000 SPECT gamma - camera. SPECT (Single Photon Emission Computed Tomography) slices were created and used. The myocardial perfusion was estimated by comparing those slices and the suspicion of an ischemia was indicated. 3 D myocardium images were reconstructed by GE Volumetrix software in the GE Xeleris processing system by FBP reconstruction method, Hanning frequency 0. 8 filter and a ramp filter and transferred in a Dicom format. The Dicom file, for each patient and each phase is imported to MATLAB 7. 8 (R 2009 a). A series of isocontour surfaces were studied, {{in order to identify}} the appropriate <b>threshold</b> <b>value,</b> which isolates the myocardium surface from the rest area of the image. Based on the previously <b>calculated</b> <b>threshold</b> <b>value,</b> the myocardium volume was evaluated and be reconstructed in a 3 D image. The possible difference relating to the rest and stress data of the 3 D images, in voxels, was calculated, using MATLAB image processing analysis; the quantification and analysis of differences was followed. We tried to determine an index of quantification and define the global quantitative defect size as a fraction of the myocardial volume area in 3 D images that will give confidence in cardiac perfusion efficiency recognition by SPECT. © 2010 IEEE...|$|R
