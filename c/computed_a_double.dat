1|10000|Public
40|$|We {{demonstrate}} a rupture front focusing phenomenon {{at the initial}} stage of earthquake, which causes high slip rate pulses and therefore generates high frequency seismic waves. In this computation, we assume a pre-slip region, where stress has already lowered quasi-statically to the dynamic friction level. And due to the pre-slip, we suppose a stress concentration {{at the edge of}} preslip area. Then a dynamic rupture starts at a certain point {{on the rim of the}} pre-slip region. We could observe a rupture front focusing that causes high slip rate pulse. We also observed a high frequency pulse in ground velocity seismogram. We <b>computed</b> <b>a</b> <b>double</b> pre-slip model, where two pre-slip region exist, and found that multiple pre-slips enhances this effect...|$|E
2500|$|This {{reduces the}} problem of <b>computing</b> <b>a</b> <b>double</b> {{integral}} to <b>computing</b> one-dimensional integrals. Because of this, another notation for the integral over R uses <b>a</b> <b>double</b> integral sign: ...|$|R
50|$|In {{mathematical}} analysis Fubini's theorem, introduced by , {{is a result}} that gives conditions under which {{it is possible to}} <b>compute</b> <b>a</b> <b>double</b> integral using iterated integrals. One may switch the order of integration if the <b>double</b> integral yields <b>a</b> finite answer when the integrand is replaced by its absolute value.|$|R
40|$|Abstract. Elliptic Curve Cryptography can be {{vulnerable}} to Side-Channel Attacks, such as the Zero Power Analysis (ZPA). This attack {{takes advantage of the}} occurrence of special points that bring <b>a</b> zero-value when <b>computing</b> <b>a</b> <b>doubling</b> or <b>an</b> addition of points. This paper consists in analysing this attack. Some properties of the said special points are explicited. A novel dynamic countermeasure is described. The elliptic curve formulæ are updated depending on the elliptic curve and the provided base point...|$|R
40|$|Partial metric spaces generalise metric spaces, {{allowing}} non zero self distance. This {{is needed}} to model computable partial information, but falls short in an important respect. The present cost of computing information, such as processor time or memory used, is rarely expressible in domain theory, but contemporary theories of algorithms incorporate precise control over cost of computing resources. Complexity theory in Computer Science has dramatically advanced through an intelligent understanding of algorithms over discrete totally defined data structures such as directed graphs, without using partially defined information. So we have an unfortunate longstanding separation of partial metric spaces for modelling partially defined computable information from the complexity theory of algorithms for costing totally defined computable information. To bridge that separation we seek an intelligent theory of cost for partial metric spaces. As examples we consider the cost of <b>computing</b> <b>a</b> <b>double</b> negation ¬¬p in two-valued propositional logic, the cost of computing negation as failure in logic programming, and a cost model for the hiaton time delay...|$|R
30|$|We {{also studied}} the {{precision}} of the convolution in a practical application. The results revealed that for this application the computation in a single precision is acceptable (and it will be probably so for many other applications). In the case the single precision is not enough {{it is also possible}} to <b>compute</b> in <b>a</b> <b>double</b> precision. However, in this precision the recent graphic cards perform poorly. With the release of new architectures (e.g., nVidia Fermi) double precision will become feasible.|$|R
30|$|The {{gravity of}} the Earth can be {{represented}} by a geopotential model in terms of harmonic coefficients, also known as Stokes coefficients. The gravity field of the Earth at an external point outside of the Earth can be <b>computed</b> as <b>a</b> <b>double</b> summation of the Stokes coefficients, Clm, Slm, to degree l and order m, derived usually {{from a combination of}} diverse satellite and terrestrial data. The “topography” is represented by a model of the bedrock topography for Antarctica achieved dominantly but not only via the airborne radio-echo sounding (RES) techniques.|$|R
40|$|In this note, we give a {{description}} of the graded Lie algebra of <b>double</b> derivations of <b>a</b> path algebra as a graded version of the necklace Lie algebra equipped with the Kontsevich bracket. Furthermore, we formally introduce the notion of double Poisson-Lichnerowicz cohomology for double Poisson algebras, and give some elementary properties. We use the description of the graded necklace Lie algebra to <b>compute</b> <b>an</b> example of <b>double</b> Poisson-Lichnerowicz cohomology. ...|$|R
40|$|This is a {{proof of}} the {{fundamental}} theorem of algebra {{which is due to}} Gauss, in 1816. It is based on [1, pp. 680 – 682]. The proof is accessible, in principle, to anyone who has had multivariable calculus and knows about complex numbers. The main idea will be to <b>compute</b> <b>a</b> certain <b>double</b> integral and then compute the integral in the other order. We take for granted the following result from calculus, which is a special case of Fubini’s theorem. Lemma 1. Let [a, b] × [c, d] ⊂ R 2 be a rectangle, and f be a continuous function on this rectangle, with real values. Then ∫ d (∫ b) ∫ b (∫ d f(x, y) dx dy = f(x, y) dy dx...|$|R
40|$|ISBN : 978 - 3 - 662 - 45610 - 1 International audienceThe fastest {{implementations}} of {{elliptic curve}} cryptography {{in recent years}} have been achieved on curves endowed with nontriv-ial efficient endomorphisms, using techniques due to Gallant–Lambert– Vanstone (GLV) and Galbraith–Lin–Scott (GLS). In such implementa-tions, a scalar multiplication [k]P is <b>computed</b> as <b>a</b> <b>double</b> multiplication [k 1]P + [k 2]ψ(P), for ψ an efficient endomorphism and k 1, k 2 appropri-ate half-size scalars. To <b>compute</b> <b>a</b> random scalar multiplication, one can either select the scalars k 1, k 2 at random, hoping that the resulting k = k 1 + k 2 λ is close to uniform, or pick a uniform k instead and decom-pose it as k 1 + k 2 λ afterwards. The main goal {{of this paper is to}} discuss security issues that may arise using either approach. When k 1 and k 2 are chosen uniformly at random in [0, √ n), n = ord(P), we provide a security proofs under mild assumptions. However, if they are chosen as random integers of 1...|$|R
40|$|A {{study of}} {{typification}} of cider brandies {{on the basis}} of the origin of the raw material used in their manufacture was conducted using chemometric techniques (principal component analysis, linear discriminant analysis, and Bayesian analysis) together with their composition in volatile compounds, as analyzed by gas chromatography with flame ionization to detect the major volatiles and by mass spectrometric to detect the minor ones. Significant principal components <b>computed</b> by <b>a</b> <b>double</b> cross-validation procedure allowed the structure of the database to be visualized as a function of the raw material, that is, cider made from fresh apple juice versus cider made from apple juice concentrate. Feasible and robust discriminant rules were computed and validated by a cross-validation procedure that allowed the authors to classify fresh and concentrate cider brandies, obtaining classification hits of > 92 %. The most discriminating variables for typifying cider brandies according to their raw material were 1 -butanol and ethyl hexanoate...|$|R
40|$|Summary. The {{question}} {{of interest is}} whether a particular model appears to provide an adequate fit with the observed data. In complicated hierarchical models {{it is easy to}} loose track of the different layers, and standard and existing methods may not work very well in such cases. The present work focuses on extensions of the posterior predictive p-value for models with hierarchical structure, designed for testing assumptions made on underlying processes. The posterior predictive p-values are typically non-uniform under the model assumptions. However, a post-processing of the p-values, generally <b>computed</b> by <b>a</b> <b>double</b> simulation scheme, makes the resulting calibrated p-values uniformly distributed under the prior and model conditions. By exploring posterior predictive p-values and their post-processed versions in models of simple structures, the effect of signal to noise levels is evaluated for testing different parts of the model. A real application illustrates how the post-processed posterior predictive p-values can be used in practise. Keywords: p-value...|$|R
30|$|The {{original}} infinite {{precision of}} an algorithm {{based on the}} use of real arithmetic must be reduced to the practical precision bounds imposed by digital computing systems. Word-length optimization (WLO) aims at the selection of the variables' word-lengths of an algorithm to comply with a certain output noise constraint while optimizing the characteristics of the implementation (e.g., area, speed or power consumption). Normally, the precision loss committed is <b>computed</b> by using <b>a</b> <b>double</b> precision floating-point arithmetic description of the algorithm as a reference and, although there are some works on quantization for custom floating-point arithmetic [1 – 3], the common approach is to implement the system using fixed-point (FxP) arithmetic, since this leads to lower cost implementations in terms of area, speed, and power consumption [4 – 7].|$|R
40|$|Abstract: Sticker {{systems were}} first {{introduced}} {{as a language}} generating device based on the operation of sticking. A new molecule is produced from the starting axiom, which is prolonged {{to the left or}} to the right using given single stranded strings or dominoes. For each sticker operation, an element of a group (called valence) will be associated with the axioms and dominoes and then the value of the group operation of the newly produced string is computed. Valence grammars were introduced as grammars with regulated rewriting using permutation groups and groups as control mechanisms. The definition for valence grammar is later extended to valence H systems which associate integer numbers with strings and the values associated with the result of newly produced strings are <b>computed.</b> <b>A</b> complete <b>double</b> stranded molecule is considered to be valid if the computation of the associated element produces the identity element. However, the converse is not true. Using the idea from the definition of valence H system and extended valence H system, the concept of valence sticker system over permutation groups is introduced in this research and the computational power of the language produced is also investigated. Key words: Valence grammar • valence sticker system • h system • sticker operatio...|$|R
40|$|A new meta-heuristic method, called Chemical Reaction Optimization (CRO), {{has been}} {{proposed}} very recently. The method encodes solutions as molecules and mimics the interactions of molecules in chemical reactions to search the optimal solutions. The CRO method has demonstrated its capability in solving NP-hard optimization problems. In this paper, the CRO scheme is used to formulate the scheduling of Directed Acyclic Graph (DAG) jobs in heterogeneous <b>computing</b> systems, and <b>a</b> <b>Double</b> Molecular Structure-based Chemical Reaction Optimization (DMSCRO) method is developed. There are two molecular structures in DMSCRO: one is used to encode the execution order of the tasks in a DAG job, {{and the other to}} encode the task-to-computing-node mapping. The DMSCRO method also designs four elementary chemical reaction operations and the fitness function suitable for the scenario of DAG scheduling. In this paper, we have also conducted the simulation experiments to verify the effectiveness and efficiency of DMSCRO over a large set of randomly generated graphs and the graphs for real-world problems...|$|R
40|$|The Distributed Processing Library (DPL) {{provides}} multiple processing services across heterogeneous {{collections of}} UNIX workstations for the ASTERIX data analysis package. The DPL programmer provides a worker task {{to perform the}} units of parallel computation, and writes the flow control logic in the client using DPL to manage queues of jobs on multiple workers. DPL conceals the interprocess communication from the client and worker processes allowing existing sequential algorithms to be adapted easily. The system has been tested on a mixture of machines running Solaris and OSF, and {{has shown that the}} library is useful for units of computation taking as little as 50 milliseconds. 1. Introduction Despite exponential growth in available <b>computing</b> power (with <b>a</b> <b>doubling</b> time of order 18 months), many of the jobs for which we use our machines are still cpu limited. There are two easy ways of increasing your usable cpu resource; buy a faster machine or make more effective use of existing c [...] ...|$|R
40|$|We {{consider}} {{the motion of}} a damped particle in a potential oscillating slowly between a simple and <b>a</b> <b>double</b> well. The system displays hysteresis effects which can be of periodic or chaotic type. We explain this behaviour by <b>computing</b> <b>an</b> analytic expression of a Poincar'e map. Comment: 4 pages RevTeX, 3 PS figs, uses psfig. sty. Submitted to Phys. Rev. Letters. PS file also available at [URL]...|$|R
40|$|Includes bibliographical references. This {{dissertation}} {{concerns the}} specification and description of complex communicating systems using Formal Description Techniques. Specifically, we propose a standard graphical representation for the Formal Description Technique Estelle and present a prototype editor {{based on this}} representation. Together they integrate the new graphical representation with existing Estelle textual tools to create a powerful graphical design technique for Estelle. The perennial popularity of graphical techniques, combined with recent advances in computer graphics hardware and software which enable their effective application in <b>a</b> <b>computing</b> environment, provide <b>a</b> <b>double</b> impetus {{for the development of}} a graphical representation for Estelle. Most importantly, a graphical technique is more easily read and understood by humans, and can better describe the complex structure and inter-relationships of components of concurrent communicating systems. Modern graphical technology also presents a number of opportunities, separate from the specification method, such as hyperlinking, multiple windows and hiding of detail, which enrich the graphical technique. The prototype editor makes use of these opportunities to provide the protocol engineer with an advanced interface which actively supports the protocol design process to improve the quality of design. The editor also implements translations between the graphical representation and the standard Estelle textual representation, on the one hand allowing the graphical interpretation to be applied to existing textual specifications, and on the other, the application of existing text-based processing tools to a graphical specification description...|$|R
40|$|Successful {{adaptive}} {{echo cancellation}} in telecommunications {{depends on a}} control device called <b>a</b> <b>double</b> talk detector. Double talk refers to the situation that signals {{at both ends of}} a communication link are simultaneously active. In the presence of <b>a</b> <b>double</b> talk situation, the role of <b>a</b> <b>double</b> talk detector is to assure convergence and to prevent divergence of the adaptive filter in an echo cancellation system. Following a thorough study of the subject matter, this thesis presents <b>a</b> <b>double</b> talk detection algorithm for a single-channel echo cancellation application using a psychoacoustic auditory model. The model exploits the frequency masking properties of the human auditory system. It performs an analysis of the far-end signal to <b>compute</b> <b>a</b> perceptual threshold, and then removes spectral components below the perceptual threshold to create spectral holes without affecting the perceptual quality of the signal. Double talk conditions are detected by monitoring the spectral levels at the created holes in the near-end input signal. To evaluate the proposed algorithm, results of simulations with real speeches and performance comparisons with certain other double talk detection algorithms are presented. It is shown with simulation results and analysis that the proposed algorithm outperforms those algorithms in overall...|$|R
40|$|International audienceIn {{this paper}} we adopt Skew Symmetric Bilinear (SSB) utility {{functions}} to compare policies in Markov Decision Processes (MDPs). By considering pairs of alternatives, SSB utility theory generalizes von Neumann and Morgenstern’s expected utility (EU) theory to encompass rational decision behaviors that EU cannot accommodate. We provide a game-theoretic {{analysis of the}} problem of identifying an SSB-optimal policy in finite horizon MDPs and propose an algorithm based on <b>a</b> <b>double</b> oracle approach for <b>computing</b> <b>an</b> optimal (possibly randomized) policy. Finally, we present and discuss experimental results where SSB-optimal policies are <b>computed</b> for <b>a</b> popular TV contest according to several instantiations of SSB utility functions...|$|R
40|$|International audienceBirkhoff-von Neumann (BvN) {{decomposition}} of doubly stochastic matrices expresses <b>a</b> <b>double</b> stochastic matrix as a convex {{combination of a}} number of permutation matrices. There are known upper and lower bounds for the number of permutation matrices that take part in the BvN {{decomposition of}} a given doubly stochastic matrix. We investigate the problem of <b>computing</b> <b>a</b> decomposition with the minimum number of permutation matrices and show that the associated decision problem is strongly NP-complete. We propose a heuristic and investigate it theoretically and experimentally...|$|R
40|$|We study {{superfluid}} {{behavior of}} a gas of spatially indirect magnetoexcitons with reference {{to a system of}} two graphene layers embedded in a multilayer dielectric structure. The system is considered as an alternative of <b>a</b> <b>double</b> quantum well in a GaAs haterostructure. We determine a range of parameters (interlayer distance, dielectric constant, magnetic field and gate voltage) where magnetoexciton superfluidity can be achieved. Temperature of superfluid transition is <b>computed.</b> <b>A</b> reduction of critical parameters caused by impurities is evaluated and critical impurity concentration is determined...|$|R
40|$|Abstract. <b>A</b> {{method for}} <b>computing</b> <b>a</b> few eigenpairs of sparse {{symmetric}} matrices is presented and analyzed that combines {{the power of}} preconditioning techniques with {{the efficiency of the}} Lanczos algorithm. The method is related to Davidson’s method and its generalizations, but can be less expensive for matrices that are fairly sparse. <b>A</b> <b>double</b> iteration is used. An effective termination criterion is given for the inner iteration. Quadratic convergence with respect to the outer loop is shown. Key words, eigenvalues, sparse matrices, Lanczos, preconditioning, Davidson’s method AMS(MOS) subject classifications...|$|R
40|$|In this article, {{we study}} {{superfluid}} {{behavior of a}} gas of spatially indirect magnetoexcitons with reference {{to a system of}} two graphene layers embedded in a multilayer dielectric structure. The system is considered as an alternative of <b>a</b> <b>double</b> quantum well in a GaAs heterostructure. We determine a range of parameters (interlayer distance, dielectric constant, magnetic field, and gate voltage) where magnetoexciton superfluidity can be achieved. Temperature of superfluid transition is <b>computed.</b> <b>A</b> reduction of critical parameters caused by impurities is evaluated and critical impurity concentration is determined...|$|R
40|$|The 11 / 5 / 2011 Lorca, Spain {{earthquake}} (Mw 5. 2) {{and related}} seismicity produced extensive {{damage in the}} town of Lorca and vicinity. During these earthquakes, evidence of rotations and permanent deformations in structures were observed. To analyze these aspects and study the source properties from the near field, the displacement time histories were obtained including the static component at Lorca station. Displacement time histories were <b>computed</b> by <b>an</b> appropriate <b>double</b> time integration procedure of accelerograms. Using these data, the foreshock and mainshock slip distributions were calculated by means of a complete waveform kinematic inversion. To study the dynamic deformations, the 3 D tensor of displacement gradients at Lorca station was first estimated by a single station method. Using the finite fault inversion results and by means of a first order finite difference approach, the dynamic deformations tensor at surface was calculated at the recording site. In order to estimate the distribution of the peak dynamic deformations, the calculation was extended to the close neighboring area of the town. The possible influence of the near-field deformations on the surface structures was analyzed. Comment: 29 pages, 8 figure...|$|R
40|$|We {{demonstrate}} the high-speed computation of core elliptic curve operations with full protection against timing-type side-channel attacks. We use a state-of-the-art GLV-GLS curve in twisted Edwards form defined over a quadratic extension field of large prime characteristic, which supports a four dimensional decomposition of the scalar. We present highly optimized algorithms and formulas for {{speeding up the}} different arithmetic layers, including techniques especially suitable for high-speed, side-channel protected computation on GLV-based implementations. Analysis and performance results are reported for modern x 64 and ARM processors. For instance, on an Intel Ivy Bridge processor we <b>compute</b> <b>a</b> variable-base scalar multiplication in 94, 000 cycles, a fixed-base scalar multiplication in 53, 000 cycles using a table of 6 KB, and <b>a</b> <b>double</b> scalar multiplication in 118, 000 cycles using a table of 3 KB. Similarly, on an ARM Cortex-A 15 processor we <b>compute</b> <b>a</b> variable-base scalar multiplication in 244, 000 cycles, a fixed-base scalar multiplication in 116, 000 cycles (table of 6 KB), and <b>a</b> <b>double</b> scalar multiplication in 285, 000 cycles (table of 3 KB). All these numbers and the proposed techniques represent a significant improvement of the state-of-the-art performance of elliptic curve computations. Most remarkably, our optimizations allow us {{to reduce the cost}} of adding protection against timing attacks in the computation of variable-base scalar multiplication to around or below 10 %...|$|R
50|$|In this way, each thresholded pixel {{has one of}} {{the three}} values. Neighboring pixels are {{combined}} after thresholding into <b>a</b> ternary pattern. <b>Computing</b> <b>a</b> histogram of these ternary values will result in a large range, so the ternary pattern is split into two binary patterns. Histograms are concatenated to generate <b>a</b> descriptor <b>double</b> the size of LBP.|$|R
40|$|International audienceWe tackle fair multi-agent {{optimization}} {{problems and}} use a generalized Gini index to determine a fair and efficient solution. We claim that considering mixed solutions (i. e., lotteries over solutions) enables to enhance the fairness of an optimal solution. Interpreting a fair multi-agent optimization problem as a zero-sum two-player game between an optimization player choosing a solution and an adversary which has some control over the payoffs of the game, we propose two methods (a cutting-plane method and <b>a</b> <b>double</b> oracle method) to <b>compute</b> <b>an</b> optimal mixed solution. Numerical tests are provided to compare their efficiency...|$|R
40|$|A {{tutorial}} and diagnostic visual tool {{is used to}} <b>compute</b> <b>a</b> set {{of strange}} attractors for <b>a</b> <b>double</b> oscillator. The tool provides a visual environment to detect chaotic behaviour from a time series. Here, computation and visualization are coupled together in a single environment. Common techniques to detect chaos involve the visualization of phase portraits and Poincare maps, apart from the computation of fractal dimension, Lyapunov exponents and Fast Fourier Transforms (FFT). Results from these computations must be viewed graphically before a decision about the chaotic behaviour of a system can be made. In many cases, {{the use of a}} single technique may not always guarantee conclusive evidence that a system's behaviour is chaotic. A few numerical integration schemes are built into the environment to generate a time series. The environment is demonstrated first {{with the use of the}} Duffing oscillator and the chaotic behaviour of <b>a</b> <b>double</b> oscillator is then presented, which provides an interesting set of strange attractors...|$|R
40|$|We quantitatively {{describe}} {{the main features}} of the magnetically induced conductance modulation of a Kondo quantum dot [...] or chessboard pattern [...] in terms of <b>a</b> constant-interaction <b>double</b> quantum dot model. We show that the analogy with <b>a</b> <b>double</b> dot holds down to remarkably low magnetic fields. The analysis is extended by full 3 D spin density functional calculations. Introducing an effective Kondo coupling parameter, the chessboard pattern is self-consistently <b>computed</b> as <b>a</b> function of magnetic field and electron number, which enables us to quantitatively explain our experimental data. Comment: 4 pages, 3 color figure...|$|R
40|$|Abstract 1 In just thirty years, we {{have gone}} from punched cards to Second Life. But, as the American National Science Foundation (NSF) {{recently}} noted, “undergraduate computing education today often looks {{much as it did}} several decades ago ” (NSF, 2006). Consequently, today’s “Nintendo Generation ” have voted with their feet. We bore them. The contrast between the changes wrought via computer research over the last 30 years, and the failure of computing education to adapt to those changes, is because <b>computing</b> academics lead <b>a</b> <b>double</b> life. In our research lives we see ourselves as part of a community that reaches beyond our own university. We read literature, we attend conferences, we publish, and the cycle repeats, with community members building upon each other’s work. But in our teaching lives we rarely discuss teaching beyond our own university, we are not guided by any teaching literature; instead we simply follow our instincts. Academics in computing, or in any other discipline, can approach their teaching as research into how novices become experts. Several recent multi-institutional research collaborations have studied the development of novice programmers. This paper describes some of the results from those collaborations. The separation of our teaching and research lives diminishes not just our teaching but also our research. The modern practice of stripping away all ‘distractions’ to maximize research output is like the practice of stripping away rainforest to grow beef ─ both practices appear to work, for a little while, but not indefinitely. Twenty-first century academia needs to bring teaching and research together, to form <b>a</b> scholarship of <b>computing</b> that is <b>an</b> integrated, sustainable, ecological whole...|$|R
30|$|This aligns <b>a</b> <b>double</b> {{applicative}} with <b>a</b> <b>double</b> transitive—like <b>a</b> <b>double</b> transitive, <b>a</b> <b>double</b> applicative {{occurs as}} a complex predicate. In the complex predicate, an IA head functions as a matrix predicate and introduces an applied object for the secondary predicate to be predicated of. Nonetheless, <b>a</b> <b>double</b> applicative differs from <b>a</b> <b>double</b> transitive in that (i) it sets an IA in its I-function rather than in its T-function; (ii) it advances as the trigger a genuine IO instead of an IO in the disguise of a DO.|$|R
40|$|AbstractBackgroundComplications {{associated}} with the use of percutaneous intra-thecal lumbar indwelling spinal catheters include infection, hematoma, neurologic dysfunction, and persistent undesired retention among others. A case of iatrogenic splicing {{associated with}} neurologic dysfunction with the use of a percutaneous intra-thecal indwelling spinal catheter is presented in this study. MethodSingle case study review. ResultsReview of case materials indicate Y pattern splicing/fragmentation of an indwelling intra-thecal catheter causing neurologic dysfunction and resistance to removal during attempted removal. Pain and weakness were evident soon after insertion of the catheter and were amplified with attempted catheter removal. <b>Computed</b> tomography revealed <b>a</b> <b>double</b> dot sign on axial view and a Y appearance on sagittal view. Surgical findings revealed entrapment of nerve rootlets in the axilla of the spliced catheter. ConclusionsSplicing/fragmentation causing neurologic dysfunction as well as catheter retention is described as a potential complication of intra-thecal indwelling cerebrospinal fluid catheters. A symptom of fragmentation of a catheter may include neurologic dysfunction including pain and weakness of a lumbar nerve root. If resistance is experienced upon attempted catheter removal, with or without associated neurologic dysfunction, further attempts at removal should not be attempted. In those cases in which pain and/or lumbar weakness are evident post catheter placement and/or following attempted removal, computed tomography should be performed. If fragmentation of a catheter is evident on CT scan, spinal surgical consultation should be obtained. Recommended spinal surgical intervention includes an open durotomy and visualization of catheter fragments and nerve rootlets and removal of catheter fragments...|$|R
5000|$|... #Caption: Example of <b>a</b> <b>double</b> tressure: Argent <b>a</b> <b>double</b> tressure Gules ...|$|R
25|$|As a rule, the {{simplest}} representation is always chosen. <b>A</b> <b>double</b> vowel is never written {{in an open}} syllable, and <b>a</b> <b>double</b> consonant is never written {{at the end of}} a word or when next to another consonant. <b>A</b> <b>double</b> vowel is rarely followed by <b>a</b> <b>double</b> consonant, as it could be simplified by writing them both single.|$|R
5000|$|... #Caption: Example of <b>a</b> <b>double</b> tressure flory-counter-flory: Argent <b>a</b> <b>double</b> tressure flory-counter-flory Gules ...|$|R
