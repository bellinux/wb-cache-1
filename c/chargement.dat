24|5|Public
40|$|L'AMELIORATION DES PERFORMANCES DANS LE DOMAINE DE L'AERONAUTIQUE EST ACTUELLEMENT LIEE A L'AUGMENTATION DU RAPPORT POUSSEE/MASSE. ON CHERCHE DONC A INTRODUIRE DES MATERIAUX PLUS LEGERS MAIS GARDANT DES PROPRIETES MECANIQUES EQUIVALENTES. DANS CET OBJECTIF, LES COMPOSITES SONT D'EXCELLENTS CANDIDATS, EN PARTICULIER LES COMPOSITES A MATRICE METALLIQUE DE TYPE SIC/TI. DANS CE TRAVAIL, NOUS AVONS ESSAYE DE CARACTERISER LES MECANISMES D'ENDOMMAGEMENT DANS CE COMPOSITE EN NOUS LIMITANT A L'ENDOMMAGEMENT MATRICIEL ET A CELUI DE L'INTERFACE FIBRE/MATRICE. CONCERNANT LA MATRICE, UNE LOI DE COMPORTEMENT ELASTOVISCOPLASTIQUE COUPLEE A L'ENDOMMAGEMENT A ETE IDENTIFIEE. CONCERNANT L'INTERFACE, DES ESSAIS DE TRACTION SUR EPROUVETTE MONOFILAMENTAIRE ONT ETE REALISES AFIN DE CARACTERISER LA DECOHESION ENTRE LA FIBRE ET LA MATRICE. DEUX TYPES DE SOLLICITATIONS ONT ETE CONSIDEREES, UN <b>CHARGEMENT</b> UNIAXIAL TRANSVERSALEMENT A LA FIBRE ET UN <b>CHARGEMENT</b> BIAXIAL AVEC UNE COMPOSANTE DANS LE SENS DE LA FIBRE. DANS UN DEUXIEME TEMPS, IL A FALLU SIMULER NUMERIQUEMENT CES ESSAIS AFIN DE REMONTER AUX CARACTERISTIQUES DE L'INTERFACE. DES CALCULS TRIDIMENSIONNELS SE SONT AVERES NECESSAIRES. LA DERNIERE PARTIE DE CETTE ETUDE EST QUANT A ELLE DEDIEE A LA SIMULATION DU <b>CHARGEMENT</b> DU COMPOSITE DANS SON APPLICATION. SudocFranceF...|$|E
40|$|Resume: La {{transition}} ductile-fragile du tungstkne form 6 B chaud a CtC examinee sous des conditions de <b>chargement</b> de choc au cours &experiences de choclrCcupQation douce h 22 " C et 400 " C. Les rCsultats de I'expCrience h 22 ' C indiquent que des tensions r 6 sultant de chocs (19 GPa) apparaissent sous forme de processus de fractures, c'est h dire qu'il n'y avait aucune indication de dCformation plastique rksultant du choc et 1 'Cchantillon a QC riduit en morceaux. A 400 " C 1 'Cchantillon a Ctt rCcupCrC intact et la plasticit 6 entrainee par le choc a entrain 6 {{la formation}} de bandes de dCformation et une augmentation de la densit 6 de dislocation du matCriau. Les rksultats de cette expkrience montrent le principe de la transition ductile-fragile du tungstkne dans des conditions de <b>chargement</b> de choc uni-axial et indiquent qu'une dkformation explosive du tungstkne resultera en une pulvkrisation due au <b>chargement</b> de choc. Abstract: The ductile-brittle transition behavior of warm-forged tungsten under shock loading conditions was examined by performing shocklsoft-recovery experiments at 22 " C and 400 " C. The {{results of a}} recovery experiment at 22 " C indicate that shock (19 GPa) -induced strains were accommodated by fracture processes, i. e. there were no indications of shock-induced plastic deformation, and the test sample was reduced to rubble. At 400 " C the test sample was recovered intact and the shock-induced plasticity caused deformation banding {{and an increase in}} the dislocation density of the material. The results of these experiments demonstrate the principle of a ductile-brittle transition behavior of tungsten under uniaxial shock loading conditions and indicate that explosively-driven deformation of the material studied will likely result in pulverization due to shock loading. 1...|$|E
40|$|International audienceON PRESENTE UN MAILLAGE D'ELEMENTS FINIS UTILISE POUR ETUDIER LA CAPACITE PORTANTE DES FONDATIONS PROFONDES. LES RESULTATS POUR UN PIEU RIGIDE EN MILIEU ELASTIQUE ET EN MILIEU DILATANT SONT COMPARES. LA DILATANCE, INTRODUITE PAR UNE METHODE DE CONTRAINTE INITIALE, AJOUTANT UNE VARIATION DE VOLUME D'ORIGINE DEVIATORIQUE, NE MODIFIE QUE TRES PEU LE COMPORTEMENT MEME DU PIEU. PAR CONTRE, SON INFLUENCE DANS LE MASSIF DE SOL EST IMPORTANTE. D'UNE MANIERE GENERALE, LE MECANISME DE <b>CHARGEMENT</b> SE TRADUIT PAR UN CISAILLEMENT PUR DU MILIEU...|$|E
40|$|Abstract: During cyclic loadings, such {{as those}} {{produced}} by earthquakes, liquefaction of undrained saturated cohesionless materials are well recognized as being the main devastating phenomenon on structures. Various remedial treatment methods {{for this type of}} soil are widely used, such as densification methods by compacting the soil, solidification methods by increasing the density of the material, or lowering the water table down to improve the effective stress of the in situ soil. Remedial treatment methods of soils to avoid possible initiation of liquefaction are based either on the principle of improving the characteristics of the soil or by means of draining the water, and thus present the same disadvantages modifying the in situ soil before construction. This research will study an alternative system using micropiles. This reinforces the soil by its structural elements rather than changing its properties. Micropiles have been used effectively in many applications of ground improvement to increase the bearing capacity and reduce the settlement particularly in strengthening existing foundations. This paper deals with a case study in which micropiles have been used to improve the liquefaction strength of the soil by using the results of Standard Penetration Test (SPT) on a real site, before and after installation of the micropile systems. The results show that, using micropiles reduces the liquefaction potential of the soil. Résumé: Pendant les <b>chargements</b> cycliques, tels que ces produit par les tremblements de terre, la liquéfactio...|$|R
40|$|Les objectifs de cette thèse sont de développer et d'optimiser des traitements de surface (dépôts durs) et de développer au travers d'un contact model de {{fretting}} wear un modèle prédictif de l'endurance de ces traitements de surfaces pour des sollicitations variables et constantes de {{fretting wear}}. La démarche énergétique proposée, introduisant le concept de capacité énergétique, pour rationaliser l'endurance des traitements de surface permet non seulement de comparer les traitements de surface mais aussi et surtout de formaliser la durée de vie pour un très large spectre de <b>chargements.</b> Cette démarche permet aussi une analyse physique des endommagements et ainsi de développer une approche thermodynamique de l'usure. Elle permet aussi d'isoler respectivement les différents mécanismes d'endommagement activés. The main research {{objective of this}} work is to introduce the criterion to establish the coatings durability under fretting wear under variable and constant loading conditions. The local dissipated energy density approach has been applied where quantity of the energy dissipated within the contact area {{is related to the}} maximum wear depth. In the work this energy approach has been developed by introduction of the critical energy value related to the durability of a coating. This critical value indicates the specific quantity of energy that has to be delivered to the coating in order to worn through its total thickness and is characteristic for each material. The durability of the investigated coatings has been depicted by means of novel Energy-Whöle wear chart. The proposed criterion allows to indicate a single coating with the best tribological properties among the others but also delivers the information : what is the duration of this surface treatment. LYON-Ecole Centrale (690812301) / SudocSudocFranceF...|$|R
40|$|L'approche DNLR (Distribution of Non Linear Relaxation) repose sur la théorie des {{fluctuations}} et l'analyse modale de la dissipation. Elle permet la description d'un grand nombre de comportements physiques. L'objet de ce travail est de valider le modèle mécanique sous <b>chargements</b> cycliques complexes et d'intégrer les équations constitutives dans un code d'éléments finis (MscMarc). La formulation thermodynamique sous-jacente traite la dissipation à l'aide de réorganisations internes, dont la cinétique est fortement non linéaire. Nous avons mis en place, dans le schéma d'intégration, des procédures numériques qui accélèrent le calcul. Il s'agit de la technique de pas variable qui s'avère performante lorsque qu'on compare le modèle DNLR au modèle NLK, {{a priori}} plus favorable puisque le nombre de variables internes est nettement plus réduit. La MAGIT bien adaptée pour le calcul des cycles conduit à des temps de calcul similaires au schéma avec accélération du pas d'intégration. The DNLR approach (distribution of non linear relaxation) relies upon the fluctuation {{theory and the}} modal analysis of dissipation. It allows the description {{of a wide range}} of physical behaviours. The goal of the present work consists of a validation of the mechanical model for complex cyclic loadings and the implementation of the constitutive equations into a finite element code (Msc-Marc). The underlying thermodynamical formulation treats the dissipation thanks to internal reorganisations, the kinetics of which is strongly non-linear. We have established numerical procedures within the integration scheme, that do speed up the calculation. It consists in the variable step technique, which proves to be efficient compared to the NLK model (non linear kinematics), although being a priori more favourable regarding this aspect, since the number of internal variables is strongly reduced. The method using large time increments (LATIN) planed for the calculation of cycles leads to calculation times similar to the scheme involving an acceleration of the integration step...|$|R
40|$|THE PURPOSE OF THIS STUDY IS TO REPLACE, FOR STRUCTURAL CALCULATIONS, A MICRO-CRACK MATERIAL (ROCK, CONCRETE) BY A FICTITIOUS MATERIAL, EQUIVALENT IN TERMS OF AVERAGE DEFORMATION AND DEFORMATION ENERGY, BUT HOMOGENEOUS AND NOT CRACKED. SEEKING TO MODELIZE A MICRO-CRACK MATERIAL WITH FRICTION ON THE CRACKS, WE SHOW THAT IT IS POSSIBLE TO OBTAIN AN EQUIVALENT MATERIAL PRESENTING A LAW OF ELASTIC BEHAVIOUR WITH INTERNAL PARAMETERS. WE DEDICATE AN ENERGETIC CRITERION OF INITIATION OF THE PROPAGATION OF MICRO-CRACKS. THIS MODEL ALLOWS US TO INTERPRET, BY MEANS OF A FINITE ELEMENT CALCULATION, A CERTAIN NUMBER OF EXPERIMENTAL PHENOMENA LINKED TO MICRO-CRACKING (TIGHTENING OF CRACKS, HYSTERESIS DURING LOADING CYCLES) Translated with www. DeepL. com/TranslatorETUDE AYANT POUR BUT DE REMPLACER, POUR LE CALCUL DES STRUCTURES, UN MATERIAU MICROFISSURE (ROCHE, BETON) PAR UN MATERIAU FICTIF, EQUIVALENT EN CE QUI CONCERNE LES DEFORMATIONS MOYENNES ET L'ENERGIE DE DEFORMATION, MAIS HOMOGENE ET NON FISSURE. CHERCHANT A MODELISER UN MATERIAU MICROFISSURE AVEC FROTTEMENT SUR LES FISSURES, ON MONTRE QUE L'ON PEUT OBTENIR UN MATERIAU EQUIVALENT PRESENTANT UNE LOI DE COMPORTEMENT ELASTOPLASTIQUE AVEC PARAMETRE INTERNE. ON DEDUIT UN CRITERE ENERGETIQUE D'INITIATION DE LA PROPAGATION DES MICROFISSURES. CE MODELE PERMET D'INTERPRETER PAR UN CALCUL AUX ELEMENTS FINIS, UN CERTAIN NOMBRE DE PHENOMENES EXPERIMENTAUX LIES A LA MICROFISSURATION (SERRAGE DES FISSURES, HYSTERESIS LORS DE CYCLE DE <b>CHARGEMENT...</b>|$|E
40|$|Abstract — Idling losses {{constitute}} {{a significant amount}} of the fuel consumption of internal com-bustion engines. Therefore, shutting down the engine during idling phases can improve its overall effi-ciency. For driver acceptance a fast restart of the engine must be guaranteed. A fast engine start can be performed using a powerful electric starter and an appropriate battery which are found in hybrid electric vehicles, for example. However, these devices involve additional cost and weight. An alter-native method is to use a tank with pressurized air that can be injected directly into the cylinders to start the engine pneumatically. In this paper, pneumatic engine starts using camshaft driven charge valves are discussed. A general methodology for an air-optimal charge valve design is pre-sented which can deal with various requirements. The proposed design methodology is based on a pro-cess model representing pneumatic engine operation. A design example for a two-cylinder engine is shown, and the resulting optimized pneumatic start is experimentally verified on a test bench engine. The engine’s idling speed of 1200 rpm can be reached within 350 ms for an initial pressure in the air tank of 10 bar. A detailed system analysis highlights the characteristics of the optimal design found. Résumé—Méthodologie pour le design des valves de <b>chargement</b> opérées par arbre a ̀ cames — Les pertes a ̀ vide représentent une partie essentielle de la consommation des moteurs a ̀ combustio...|$|E
40|$|Abstract: Compact Tension {{specimens}} {{were loaded}} at I and 7 mls with two different accelerations imposed. Experimental photoelastic patterns recorded {{by a high}} speed camera were compared with those simulated by dynamic elastic Finite Elernent (FE) analysis. The positive results of this comparison validated the FE analysis. It is demonstrated that when the initial acceleralion of the specimen is low (using a damper in the loading device), static analysis can be applied for both testing speeds used. In high accelerations tests (without damper used), a transient dynamic stress state in thc specimens is found, therefore a dynamic analysis should be used. Furthermore, in high acceleration tests a transient mixed mode of loading at the crack tip occurs. R&um&: Deux accilirations diffirentes sont imposies i d e s eprouvettes de tension compacte (CT) sollicities i 1 et 7 mls. Les contraintes son 1 visualisie par la photoClasticite a l'aide d'une camera i haute vitesse, et comparies avec les franges phototlastiques sirnulies par BlCments finis. Les rksultats positifs de ces comparaisons permettent & valider les calculs. I 1 est dimontre par Ih que lorsque I'accilCration initiale de I'kchantillon est riduite par un amodsseur dans le systkme de <b>chargement,</b> I'analyse statique e s ~ applicable. Pour les accelerations ilevtcs, un etat de contrainte dynarnique transitoire est predominent dans la phase in~tiale du chargernent, et l'analyse dynamique doit &tre appliquee. De plus, dans ces tests une mixiti de mode esl prksente en tete de fissure...|$|E
40|$|We {{studied the}} pore {{structure}} in intact and inelastically compacted Indiana limestone using X-ray microtomography imaging. Guided by detailed microstructural observations and using Otsu’s global thresholding method, the 3 D images acquired at voxel side length of 4 μm were segmented into three domains: solid grains, macropores and an intermediate zone dominated by microporosity. The macropores were individually identified by morphological processing and their shape quantified by their sphericity and equivalent diameter. Our new data {{revealed a significant}} reduction {{of the number of}} macropores in hydrostatically and triaxially compressed samples with respect to the intact material, in agreement with previous microstructural analysis. The intermediate (microporosity) domains remained interconnected in compacted samples. Our data suggest that the inelastic compaction in Indiana limestone is manifested as not only a decrease in the volume fraction of the microporosity backbone but also a corresponding decrease in its thickness. La structure des pores dans des echantillons de calcaire de l’Indiana intact et deforme a ete etudiee par microtomographie a rayons X. En se basant sur une etude detaillee de la microstructure et en utilisant la methode de seuillage global d’Otsu, les images 3 D acquises avec un voxel de 4 μm ont ete segmentees en trois domaines : les grains, les macropores et une zone intermediaire dominee par la microporosite. Les macropores ont ete individualises grace a une analyse morphologique qui a egalement permis de quantifier leurs formes (sphericite et diametre equivalent). Nos nouvelles donnees 3 D montrent une reduction significative du nombre de macropores dans les echantillons deformes sous <b>chargements</b> hydrostatique et triaxial par rapport a la roche intacte, en accord avec les etudes anterieures sur la microstructure du calcaire de l’Indiana. Le domaine intermediaire (microporosite) reste interconnecte dans les echantillons deformes. Notre analyse suggere que la deformation irreversible dans le calcaire de l’Indiana se manifeste par une diminution a la fois du volume et de la surface de cette zone microporeuse...|$|R
40|$| l’adaptation d’une gaussienne ou d’une loi de Gumbel sur la queue de {{distribution}} empirique, la formule de Rice appliquée à l’histogramme des dépassements de niveaux, la méthode des maxima par blocs ou celle des dépassements de seuils élevés. Les fondements et les utilisations faites de ces méthodes pour modéliser les effets extrêmes du trafic sur les ouvrages sont donnés dans un premier chapitre. De plus, une comparaison quantitative entre ces méthodes est réalisée. Deux études sont présentées, l’une basée sur un échantillon numérique et l’autre sur un échantillon réaliste d’effets du trafic. L’erreur induite par ces méthodes est évaluée à l’aide d’indicatifs statistiques simples, comme l’écart-type et les moindres carrés, évalués sur les valeurs caractéristiques et les probabilités de rupture. Nos conclusions sont, qu’en général, les méthodes sont moins précises lorsqu’il s’agit de déterminer des probabilités de rupture que lorsqu’elles cherchent des valeurs caractéristiques. Mais la raison peut en être les faibles probabilités recherchées (10 - 6 par an). De plus, bien qu’aucune méthode n’ait réalisée des extrapolations de manière correcte, les meilleures sont celles qui s’intéressent aux queues de probabilités, et en particulier des dépassements au-dessus d’un seuil élevé. Ainsi une étude de cette dernière méthode est réalisée : en effet, cette méthode, nommé "dépassements d’un seuil élevé", considère que les valeurs au-dessus d’un seuil correctement choisi, assez élevé, suit une distribution de Pareto généralisée (GPD). Cette méthode est utilisée de manière intensive dans les domaines de l’hydrologie et la finance, mais non encore appliquée dans le domaine des effets du trafic sur les ouvrages. Beaucoup de facteurs influencent le résultat lorsqu’on applique cette méthode, comme la quantité et la qualité des données à notre disposition, les critères utilisés pour déterminer les pics indépendants, l’estimation des paramètres et le choix du seuil. C’est pour cette raison qu’une étude et une comparaison des différentes méthodes d’estimation des paramètres de la distribution GPD sont effectuées : les conditions, hypothèses, avantages et inconvénients des différentes méthodes sont listés. Différentes méthodes sont ainsi étudiées, telles la méthode des moments (MM), la méthode des moments à poids (PWM), le maximum de vraisemblance (ML), le maximum de vraisemblance pénalisé (PML), le minimum de la densité de la divergence (MDPD), la méthode des fractiles empiriques (EPM), la statistique du maximum d’adaptation et la vraisemblance des moments (LM). Pour comparer ces méthodes, des échantillons numériques, des effets de trafic simulés par Monte Carlo et des effets mesurés sur un ouvrage réel sont utilisés. Comme prévu, les méthodes ont des performances différentes selon l’échantillon considéré. Néanmoins, pour des échantillons purement numériques, MM et PWM sont recommandées pour des distributions à paramètre de forme négatif et des échantillons de petite taille (moins de 200 valeurs). ML est conseillé pour des distributions à paramètre de forme positif. Pour des effets du trafic simulés, ML et PML donne des valeurs de retour plus correctes lorsque le nombre de valeurs au-dessus du seuil est supérieur à 100; dans le cas contraire, MM et PWM sont conseillés. De plus, comme c’est prouvé dans l’étude de valeurs réelles mesurées, les valeurs {{a priori}} aberrantes ("outliers") ont une influence notable sur le résultat et toutes les méthodes sont moins performantes. Comme cela a été montré dans la littérature, ces "outliers" proviennent souvent du mélange de deux distributions, qui peuvent être deux sous-populations. Dans le cas de l’effet du trafic sur les ouvrages, cela peut être la raison d’une estimation des paramètres non correcte. Les articles existant sur le sujet soulignent le fait que les effets du trafic sont dus à des <b>chargements</b> indépendants, qui correspondant au nombre de véhicules impliqués. Ils ne suivent pas la même distribution, ce qui contredit l’hypothèse classique en théorie des valeurs extrêmes que les événements doivent être indépendants et identiquement distribués. Des méthodes permettant de prendre en compte ce point et utilisant des distributions mélangées (exponentielles ou valeurs extrêmes généralisées) ont été proposées dans la littérature pour modéliser les effets du trafic. Nous proposons une méthode similaire, que nous appelons dépassement de seuils mélangés, afin de tenir des différentes distributions sous-jacentes dans l’échantillon tout en appliquant à chacune d’entre elles la méthode des dépassements de seuil. Pour des ponts ayant des portées supérieures à 50 m, le scénario déterminant est celui de la congestion, qui n’est pas ce qui est étudié ici. De plus, le trafic n’est pas la composante déterminante pour la conception des ponts de longue portée. Mais des problèmes de fatigue peuvent apparaître dans certains ponts, tels les ponts métalliques à dalle orthotrope, où l’étude du trafic peut devenir nécessaire. Ainsi nous avons fait une étude de l’influence de la position des véhicules sur le phénomène de fatigue. Pour cela, quatre fichiers de trafic réels, mesurés en 2010 et 2011 par quatre stations de pesage différentes, ont été utilisés. Ils ont mis à jour des comportements latéraux différents d’une station à l’autre. Si nous les appliquons au viaduc de Millau, qui est un pont métallique à haubans et à dalle orthotrope, nous voyons que l’histogramme des effets et l’effet de fatigue cumulé est beaucoup affecté par le comportement latéral des véhicules. Ainsi, des études approfondies utilisant les éléments finis pour modéliser les ouvrages et des enregistrements de trafic réel, peuvent être utilisées pour pré-déterminer quels éléments, donc quelles soudures, doivent être examinés dans les ponts afin d’estimer leur santé structurelle...|$|R
40|$|We make {{progress}} towards proving the strong Eshelby’s conjecture in three dimensions. We prove that if {{for a single}} nonzero uniform loading the strain in-side inclusion is constant and further the eigenvalues of this strain are either all the same or all distinct, then the inclusion must be of ellipsoidal shape. As a con-sequence, we show that for two linearly independent loadings the strains inside the inclusions are uniform, then the inclusion must be of ellipsoidal shape. We then use this result to address a problem of determining {{the shape of an}} inclu-sion when the elastic moment tensor (elastic polarizability tensor) is extremal. We show that the shape of inclusions, for which the lower Hashin-Shtrikman bound either on the bulk part or on the shear part of the elastic moment tensor is attained, is an ellipse in two dimensions and an ellipsoid in three dimensions. Résumé Nous progressons dans la résolution de la conjecture d’Eshelby en trois dimensions. En effet, nous démontrons que si pour un seul <b>chargement</b> uniforme (non trivial), le champ de contraintes dans une inclusion élastique est constant et de plus, ses valeurs propres sont soit toutes les mêmes soit différentes les unes des autres alors l’inclusion est nécessairement de forme ellipsöıdale. Il en découle que si pour deux chargements uniformes, linéairement ∗This work was partially supported by the ANR project EchoScan (AN- 06 -Blan- 0089), the STAR project 190117 RD, KRF- 2008 - 220 -C 00002, and research grants at the Inha University, NSF throug...|$|E
40|$|International audienceSince the mid- 20 th century, {{farming and}} {{livestock}} systems have undergone {{a series of}} modifications, which have led to changes in how farmlandsare used and in landscape composition. This study examined whether a link exists between these long-term changes and the occurrence of watervole outbreaks in certain regions of France. A comparison of the patterns observed in 7 different regions was carried out using town-level dataobtained during the French Census of Agriculture; these regions are located in eastern France (Burgundy, the Jura, and the Alps) and are associatedwith different mountain ranges. Although the baseline values of land use descriptors (e. g., ratio of land under permanent grass to usable farm area,ratio of land under permanent grass to total land under grass, and stocking rate) were found to vary across regions, the occurrence of water voleoutbreaks was always associated with grasslands being stocked at moderate rates. Land use and landscape composition patterns were similar forstudy regions in the Doubs and Burgundy that experience water vole outbreaks; they differed for natural reserves in the Alps. Une comparaison a été menée entre territoires de divers massifs montagneux de l’est de la France (Alpes, Bourgogne, Jura) en utilisant,avec quelques précautions, les données communales du Recensement Général de l’Agriculture. Si les valeurs de seuil (STH/SAU,STH/Surface en herbe, <b>chargement</b> [...] .) diffèrent d’une zone à l’autre, la présence de pullulation est toujours associée à des espacesessentiellement herbagers utilisés à des chargements modérés. Les trajectoires sont assez semblables entre les territoires du Doubs etde Bourgogne concernés par les pullulations mais diffèrent avec celles des zones alpines...|$|E
40|$|RtsumG: Des expkriences d'impact combinant la mesure {{de vitesse}} par interfkromkuie ont t t t rtalisees pour dtterminer le {{comportement}} de bureaux d'aluminc Coors-, 40995. Des mat 6 riau. u d'impkdance variable ont CtO utilisks pour impacter A la fois le baureuu nu el des barreaux revStus de manchons. Les rksultats de calculs avec le code CTH demonuent les c~acttristiques uniques de cette nouvelle mOthode: @ une impulsion d i conuainte dependante du temps genere au cours de I'impact permet la uansition progressive d'un iftilt de dliormarion uni:~uiale vers un knr de conuainre uni;~uide, et 3 : une vltesse de <b>chargement</b> intermediaire est ohtenue e w e la technique des h n e s de Hopkinsoil et la technique d'impacr de plaque classique. Abstract: Gas gun experiments combined with velocity interferomeuic techniques {{have been used}} to experimentally determine the loading behavior of a Coors-AD 995 alumina rod 19 mm in diameter by either 74 mm or 151 mm in length. Graded-density materials were used to impact both bare and sleeved alumina rods, while the velocity interfer-ometer was used to monitor the axial-velocity of the free end of the rods. Results of these experiments and CTH cal-culations will demonstrate a unique feature of this novel test methodology: (1) a time-dependent suess pulse generated during impact allows for a smooth and efficient transition from the initial uniaxial smin loading to a uniax-ial stress state as the stress pulse propagates through the rod. and (2) the intermediate loadin_e rates obtained in this configuration lie between those available From split Hopkinson bar and shock-loading techniques and are not achieved easily by either one of these techniques. 1...|$|E
40|$|Les références du Corpen (1999 - 2001) définissent les restitutions organiques des bovins et permettent de mieux connaître les quantités d’azote et de {{phosphore}} à recycler, lesquelles sont très liées au système de production. Les rejets des laitières sont estimés {{en fonction}} soit de la part d’herbe dans la surface fourragère principale, soit de la valeur nutritive moyenne annuelle des régimes alimentaires. Des évaluations sont également fournies pour le reste du troupeau (élèves, génisses, vaches allaitantes). Ces références directement utilisables conduisent au calcul des quantités totales d’azote et de phosphore maîtrisables et non maîtrisables, et des charges organiques par hectare épandable de cultures et de prairies, selon le <b>chargement</b> par hectare de SFP. An adequate fertilisation policy, {{taking into account}} especially the organic restitutions by the dairy herds, constitutes a major agricultural and environmental concern. The Corpen references supply detailed estimations of the dejections by cattle; they are presented here in a way adapted to the different dairying systems. The Corpen references (1999 - 2001) define the organic rejections by cattle, supplying data for a better knowledge of the amounts of nitrogen and of phosphorus to be re-cycled, the latter being {{closely related to the}} production system. The dejections by dairy cows are estimated either according to the proportion of pastures in the main fodder area or according to the mean annual nutritive value of the diets. Estimations are also given for the other animals in the herd (young cattle, heifers, suckling cows). These references can be utilized directly for the computation of the total amounts of nitrogen and phosphorus, controllable or not, and of the organic loads per hectare of crop lands and pastures, according to the stocking-rate per hectare of the main fodder area...|$|E
40|$|CE TRAVAIL DE THESE A VISE A AMELIORER LE CALCUL DES FILETS PARAVALANCHES ET LA PREDICTION DES EFFORTS AUXQUELS CES OUVRAGES SONT SOUMIS. DANS CE CADRE, SEULS LES MOUVEMENTS LENTS DE LA NEIGE SOUS L EFFET DE LA GRAVITE ONT ETE PRIS EN COMPTE. CE TRAVAIL EST COMPOSE DE DEUX PARTIES. DANS UN PREMIER TEMPS, L INTERACTION ENTRE LE MANTEAU ET LA STRUCTURE A ETE ABORDEE DANS UN CADRE BIDIMENSIONNEL PAR UNE DESCRIPTION CONTINUE DU MANTEAU (METHODE DES ELEMENTS FINIS). LA STRUCTURE, REPRESENTEE PAR UN CABLE, EST PRISE EN COMPTE AU TRAVERS D UNE CONDITION LIMITE MIXTE PERMETTANT DE RELIER LES EFFORTS DE REACTION APPLIQUES AUX NŒUDS AVAL DU MANTEAU A LEURS DEPLACEMENTS. CETTE APPROCHE A PERMIS DE CONSTATER QUE L INFLUENCE DE LA COMPOSANTE NORMALE A LA PENTE DE LA GRAVITE SUR LE <b>CHARGEMENT</b> APPLIQUE AU CABLE RESTAIT NEGLIGEABLE PAR RAPPORT A CELLE DE SA COMPOSANTE PARALLELE AU TERRAIN. CELA A CONDUIT A METTRE EN ŒUVRE, DANS UNE SECONDE PARTIE, UNE APPROCHE DISCRETE DANS LAQUELLE LE MANTEAU EST DECRIT PAR UN ENSEMBLE D ELEMENTS PARALLELEPIPEDIQUES RIGIDES POUVANT GLISSER ENTRE EUX SELON LA LIGNE DE PLUS GRANDE PENTE. LE PHENOMENE DE PENETRATION DU MANTEAU AU SEIN DU FILET PEUT ETRE AINSI DECRIT. DEVELOPPEE TOUT D ABORD DANS UN CADRE BIDIMENSIONNEL, CETTE APPROCHE A ETE ENSUITE ETENDUE AU CAS TRIDIMENSIONNEL. EN PARALLELE DE CE TRAVAIL DE MODELISATION, UNE IMPORTANTE CAMPAGNE D EXPERIMENTATIONS A ETE MENEE SUR UN OUVRAGE OPERATIONNEL IMPLANTE A FLAINE (HTE SAVOIE). L ENREGISTREMENT DES EFFORTS APPLIQUES AUX ANCRAGES DE LA STRUCTURE, COMPLETE PAR UNE CARACTERISATION REGULIERE DU MANTEAU, A PERMIS D OBTENIR DES PREMIERS ELEMENTS DE COMPARAISON TENDANT A CONFORTER LA VALIDITE DU MODELE. GRENOBLE 1 -BU Sciences (384212103) / SudocSudocFranceF...|$|E
40|$|LE PROCEDE SMART-CUT S'APPUIE SUR LA CAPACITE DE L'HYDROGENE INTRODUIT DANS LE SILICIUM A FORTE CONCENTRATION, A FORMER DES CAVITES ET/OU MICRO-FISSURES, POUVANT MENER A LA FRACTURE. NOUS AVONS IDENTIFIE DEUX MODES DE CROISSANCE DES CAVITES SOUS ACTIVATION THERMIQUE. LE PREMIER DECOULE DE LA MINIMISATION DE L'ENERGIE INTERFACIALE GLOBALE DU SYSTEME FORME PAR LES DEFAUTS LENTICULAIRES LIES A L'HYDROGENE DANS LE SILICIUM : C'EST UN MURISSEMENT D'OSTWALD. IL APPARAIT DANS CERTAINES CONDITIONS EXPERIMENTALES ET NOTAMMENT DANS LES PREMIERS INSTANTS DE CROISSANCE DES CAVITES. UN AUTRE MECANISME INTERVIENT SOUS ACTIVATION THERMIQUE DANS LA CROISSANCE DES CAVITES ET MICRO-FISSURES QUI DONNERONT LIEU A LA FRACTURE FINALE DU MATERIAU. IL A ETE ASSIMILE A UN PHENOMENE D'OUVERTURE PAR PROPAGATION DE FISSURES DONT LA FORCE MOTRICE EST NOTAMMENT LA PRESSION DE GAZ PRESENTE DANS CES MICRO-FISSURES. L'ETUDE CINETIQUE DE LA FRACTURE A REVELE QUE LE PHENOMENE LIMITANT LE MECANISME EST LA DIFFUSION DE L'HYDROGENE AU NIVEAU DE LA ZONE IMPLANTEE. L'ENERGIE D'ACTIVATION DANS LE DOMAINE DES HAUTES TEMPERATURES CORRESPOND A LA MIGRATION DE L'HYDROGENE LIBRE DANS LE SILICIUM; DANS LE DOMAINE DES BASSES TEMPERATURES, LA DIFFUSION DE L'HYDROGENE NECESSITE SA DISSOCIATION DE SITES DE PIEGEAGE, CE QUI SE TRADUIT PAR UNE AUGMENTATION DE L'ENERGIE D'ACTIVATION DU MECANISME DE FRACTURE. NOUS AVONS SOULIGNE L'EQUIVALENCE ENTRE LA CONTRIBUTION MECANIQUE DE LA PRESSION INTERNE DES MICRO-FISSURES SOUS ACTIVATION THERMIQUE ET UNE SOLLICITATION MECANIQUE EXTERNE APPLIQUEE A LA STRUCTURE IMPLANTEE POUR ABOUTIR A LA FRACTURE. A CET EFFET, DEUX ESSAIS MECANIQUES RELEVANT DE MODES DE <b>CHARGEMENT</b> DIFFERENTS (TRACTION ET MIXTE) ONT ETE MIS EN UVRE. L'ANALYSE DES FACIES DE RUPTURE DANS TOUS LES CAS DE PROPAGATION DE FRACTURE (THERMIQUE ET/OU MECANIQUE) A MIS EN EVIDENCE DES CONDITIONS EXPERIMENTALES FAVORISANT LA QUALITE DU TRANSFERT ET LA RUGOSITE DES SURFACES FRACTUREES. GRENOBLE 1 -BU Sciences (384212103) / SudocSudocFranceF...|$|E
40|$|Many {{engineering}} structures {{are subjected to}} random loading. The problem of predicting crack growth rates in this case cannot be solved without an accurate knowledge of load-time history occurring in service. There are many calculating models of crack propagation under spectrum loading, such as Wheeler model [Wheeler O. Spectrum loading and crack growth. J Basic Eng D 1972; 94 : 181 – 86], Huang et al. [Huang XP, Zhang JB, Cui WC, Leng JX. Fatigue crack growth with overload under spectrum loading. Theor Appl Mech 2005; 44 : 105 – 15] which use different approaches trying to explain fatigue crack growth. In this paper we use Decoopman's [Decoopman X. Influence des conditions de <b>chargement</b> sur le retard à la propagation d'une fissure de fatigue après l'application d'une surcharge. Thesis, Université de Sciences et Technologies de Lille; 1999] model. He has developed an empirical model which describes the fatigue crack propagation after an overload cycle on 12 NC 6 steel in fatigue. This model describes how the crack growth rate evolves during the delay induced by the overload. Nevertheless, it is limited to overload cycles. But, many authors [[4] and [5]; Huang XP, Zhang JB, Cui WC, Leng JX. Fatigue crack growth with overload under spectrum loading. Theor Appl Mech 2005; 44 : 105 – 15; Paris P, Erdogan F. A critical analysis of crack propagation laws. J Basic Eng Trans Am Soc Mech Eng 1963; 528 – 34] have shown that an underload cycle occurring after an overload cycle reduces the delay. This study proposes to implement the underload effect in order to decrease the conservative results expected from this model. Decoopman's model proposes a delay weighting factor after an overload cycle. In order {{to take into account}} of an underload cycle, we suggest an acceleration coefficient to correct the model. The main advantage of this model is that the delay weighting factor and the acceleration coefficient are only dependent on yield stress σY, the crack length a, and the various plastic zone sizes. Many experimental results have been compared to simulated results. These comparisons show a good agreement...|$|E
40|$|The {{objective}} of this work is to study the machinability of CMMP as a structural material in substitution for refractory alloys and to understand the mechanisms generating dust related to their dry machining. The different levels of reinforcement of CMM (5, 15, 25, 35 % of SiCp) and the variety of PCD tools and nanostructured diamond coatings studied, assessed in a first step the structural choice of tools in relationship with the industrial feasibility of their use in high speed dry machining of CMM Al / SiC. The feasibility study and recommendation tool were made taking into account different criteria: the energy, the structural and environmental quality. Damage modes {{and the performance of}} cutting tools have been observed and analyzed in tests of wear and durability. The presence of adhesive wear mode followed by an abrasive consumption interface increases the importance {{of the structure of the}} tool (homogeneity, multiple interfaces [...] .) The dust emission is finally analyzed in terms of structural modification of the composite material (heat treatment) and the reinforcement rate. Environmental sustainability of its machining is also assessed by an analysis of tool life. The process of dust generation is strongly related to tools behaviour, and the predominance of friction phenomena that arise at the tool / chip interface. L'objectif de ce travail est d'étudier l'usinabilité des CMMp comme matériau de structure en substitution aux alliages réfractaires et de comprendre les mécanismes générateurs de poussière inhérents à leur usinage à sec. Les différents niveaux de <b>chargement</b> en céramique du CMM (5, 15, 25, 35 % de SiCp) ainsi que la variété d'outils PCD et des revêtements diamants nanostructurés étudiés, a permis d'évaluer dans un premier temps le choix structurel d'outillages en liaison avec la faisabilité industrielle de leur usage en usinage grande vitesse à sec d'un CMM Al/SiC. L'étude de faisabilité et la préconisation d'outillages ont été effectuées en prenant en compte des critères énergétiques et de qualité structurelle et environnementale. Les modes d'endommagement ainsi que les performances d'outils coupants ont été observés et analysés lors d'essais d'usure accélérée et de durabilité. La présence d'une usure adhésive suivie d'un mode abrasif de consommation d'interface accroit l'importance de la structure de l'outil (homogénéité, multiplicité des interface...|$|E
40|$|SAHC 2014 - 9 th International Conference on Structural Analysis of Historical Constructions, MEXICO, MEXIQUE, 14 -/ 10 / 2014 - 17 / 10 / 2014 The Paris {{subway system}} was mainly {{constructed}} with a masonry vault as a definitivestructure of the tunnel. Almost 85 % {{of the underground}} assets administrated by the Régie Autonome des Transports Parisiens (RATP) are masonry made and some parts of it are more than 100 years old. Knowing the present structural state of these tunnels is a key priority to the RATP, {{in order to ensure}} the continuity of the metro service and also to model and predict the effects of some proposed engineering works in the tunnel itself or in its vicinity (for example, a new building on the surface, excavations near the tunnel or a new adjacent tunnel) that might compromise the safety of the existing structure. Searching to broaden the knowledge of the behaviour of the masonry tunnels, we aim to develop a specific model for the masonry lining which will be implemented in the finite element code CESAR-LCPC. An analytical homogenization technique will be utilized along with a damage model, as a means to describe the evolution of the properties of the vault. Damage is applied locally to each component of the masonry, described by means of an isotropic law, and an appropriate technique linking the micro and macro levels simulates the global anisotropic behaviour across the vault. Geometrical considerations are taken into account to assess the directions of the anisotropy. The goal is to identify potential cracking areas in the tunnel as well as its deformation resulting from a given load case. La plupart des tunnels du métro de Paris comportent une voute en maçonnerie. Près de 85 % des ouvrages du patrimoine géré par la RATP est constitué de maçonnerie et certains de ces ouvrages ont plus de 100 ans. La connaissance de leur état structurel actuel est une priorité pour la RATP, pour assurer la continuité du service et pour prédire les effets de travaux projetés à proximité des tunnels qui pourraient compromettre leur stabilité. Pour élargir la connaissance sur le comportement de la maçonnerie, nous avons entrepris de développer un modèle spécifique dans le code de calcul CESAR-LCPC. Une technique d'homogénéisation sera utilisée en combinaison avec un modèle d'endommagement, pour décrire l'évolution des propriétés de la voute. L'endommagement est évalué localement pour chaque composant (considéré comme isotrope), et une technique appropriée de changement d'échelle permet de simuler le comportement global anisotrope de la voute. Le but est d'identifier les zones de fissuration potentielle et les déformations résultant d'un <b>chargement</b> donné...|$|E
40|$|At {{the time}} of my arrival in Laboratoire Aimé Cotton (LAC) in November 2006, the {{activity}} of the experimental group of cold molecules in LAC was, on one hand on the formation and manipulation of cold molecules in a Magneto-Optical Trap (MOT), and on the other, in the realization of a dipole trap for cesium atoms. The preparation of a dipole trap of Cs atoms aimed both in the preparation of Bose-Einstein Condensation (BEC) of atomic Cs, and in the study of preparation and manipulation of Cs dimers in ultra-low temperatures. My enrollment in the activity of the experimental group of cold molecules in LAC was both in the preparation of the dipole trap, and in the study of cold molecule's creation and manipulation. In the first part of my thesis, I describe the studies conducted in the period November 2006 to October 2008. In this period, I focused my efforts on the study of different techniques for the loading of a dipole trap with Cs atoms, using a pre-existing set-up. The target was the creation of a cold and dense trapped atomic sample, in which the evaporation technique could be applied, to further cool the sample down to the critical temperature {{for the creation of a}} Cs BEC. At the beginning of the experiment, a Cs BEC had been reported only once [Web 03], after years of unsuccessful efforts by many groups [Sod 98, Boir 98, Thom 04]. Despite the difficulty of the subject, the interest in preparing samples of ultra-cold Cs atoms remained high, especially due to experiments related to ultra-cold molecules, as the creation of a molecular BEC [Herb 03], or the formation of Cs trimers and the observation of Efimov states [Lee 07, Knoo 08]. The strategy upon which the dipole trap experiment was based, is theoretically studied in a previous publication of the group [Comp 06], which considers rapid evaporation of a dense atomic sample in a crossed, deep dipole trap. This dense dipole trap, is provided by superimposing the dipole laser to a much larger trapped atomic sample, the so-called atomic reservoir. Collisions in this atomic reservoir can thermalize the sample and lead to the transfer of atoms in the dipole trap. Since this process can last for relatively large time intervals, it can result to higher loading efficiencies with comparison to alternative, instantaneous loading methods. This approach is very different to the one used in the only successful BEC experiment at that time [Web 03], in which a shallow, very cold, but not so dense dipole trap, is prepared with the use of Raman Sideband Cooling. In the theoretical proposal reported in [Comp 06], a magnetic trap was considered for the realization of the atomic reservoir, while the initial experimental study of this approach is the subject of a previous thesis in our group [Stern 08]. However, the general ideas considered in this approach, allowed for the substitution of this magnetic reservoir, by several atomic traps. Thus, the experimental studies discussed in the first part of my thesis, are the continuation of the work made during the thesis of G. Stern [Stern 08], with whom I collaborated in the beginning of my thesis. In particular, I studied the loading a dipole trap from a magnetic trap reservoir, and compared it to the loading obtained when the magnetic reservoir is replaced by a Dark-SPOT and a Compressed MOT (C-MOT). Furthermore, all these reservoir-loading methods are compared to a simpler, instantaneous-loading method which involves optical molasses. By June 2008, it was made clear that our experimental approach to the dipole trap loading, could not lead to the preparation of a sufficiently cold and dense atomic sample, in which evaporating cooling could be applied for the preparation of cesium atoms in ultra-low temperatures. In the same time, the approach considered in the first successful realization of a Cs BEC [Web 03] gained ground, since the experiments reported in [Hung 08] showed that it could provide with a Cs BEC with a fast and relatively simple experimental sequence. Thus, we also attempted the preparation of an ultra-cold Cs sample with the use of a shallow, not very dense, but very cold dipole trap provided by Raman Sideband Cooling. Unfortunately, a series of experimental problems related to the old vacuum system used in our experiment, prevented us from creating an ultra-cold atomic cesium sample with such an approach, despite the encouraging preliminary results. On the same period, the studies of the manipulation of cold molecules created in a MOT, conducted by members of the experimental group of cold molecules in LAC, advanced considerably, leading to the demonstration of the vibrational cooling technique reported in [Vit 08]. The operating principle of the vibrational cooling technique is similar to the one of optical pumping in atoms [Kast 66]. In this process, molecules that initially lie in different vibrational levels, are simultaneously excited by shaped broadband light and are accumulated to a single vibrational level via spontaneous emission. The accumulation to a single vibrational level, is accomplished by choosing to remove from the shaped pulse, all frequencies resonant to transitions from this level and thus turn it to a dark state. The technique enjoys simplicity and generality, and its demonstration opened the way for many interesting extensions, some of which are the subject of the second part of my thesis. More particularly, my activity in the cold molecule experiment which is discussed in the second part of my thesis, considered several extensions and generalizations of the vibrational cooling technique. The first extension to be considered, was the transfer of the molecular population to any pre-selected vibrational level, via optical pumping induced by more sophisticated, shaped femptosecond pulses, and is also discussed in [Sof 09]. Another extension, considered the realization of vibrational cooling and molecular population transfer with the use of a broadband, non-coherent, diode light source, instead of a femptosecond laser and is reported in [Sof 09 b]. Another extension was considered to be the vibrational cooling of Cs molecules in their ground triplet electronic state, in addition to the ground singlet state, that was so far manipulated. Despite the optimistic initial predictions, the experimental study did not led to considerable results. However, this 'failed' experimental study, provides with an opportunity to revisit the various key elements of the vibrational cooling technique, and to consider the possible reasons that can lead to its failure. Such a discussion is particularly useful for the following study of the extension of the vibrational cooling technique to heteronuclear molecules through the example of NaCs. Finally, the generalization of the vibrational cooling technique to include rotation, which is theoretically considered in various publications of the group in which I participated [Vit 09, Sof 09, Sof 09 c], is discussed. In addition to these theoretical considerations, I discuss the preliminary experiments considered for rotational cooling, which involve the preparation of rotationally resolved depletion spectroscopy, and which are also discussed in [Fio 09]. Au début de mon travail de thèse dans l'équipe Atomes et Molécules Froides du Laboratoire Aimé Cotton, l'intérêt du groupe était, d'un côté, la préparation et la manipulation des molécules de Césium créées via photoassociation, et de l'autre, à la préparation d'un échantillon de Césium à basse température et de grande densité dans un piége dipolaire. Initialement, j'ai participé aux études de realization du piége dipolaire atomique, et ensuite aux études de préparation et de manipulation des molécules. Dans la période entre Novembre 2006 jusqu'a Octobre 2008 j'ai développé une série de techniques différentes pour le <b>chargement</b> d'un piége dipolaire à partir d'un réservoir atomique, réalisé soit par un piége magnétique, soit par un piége du type 'Dark-SPOT', soit par C-MOT (piége magnéto-optique comprimé) et un mêlasse optique. Au commencement du mon travail, un BEC de Césium a été rapporté un seule fois [Web 03], après des années des efforts de plusieurs équipes [Sod 98, Boir 98, Thom 04]. De plus, l'intérêt sur l'atome de Césium a augmenté à cause des expériences liées à la formation de trimères de Césium et des résonances du type 'Efimof' [Lee 07, Knoo 08]. La stratégie sur laquelle notre approche pour le <b>chargement</b> du piége dipolaire était basée, est discutée dans une publication rédigée avant mon intégration au sein d'équipe Atomes et Molécules Froides du Laboratoire Aimé Cotton [Comp 06]. Il s'agit d'un <b>chargement</b> à partir d'un réservoir obtenu par un piége magnétique. L'objectif de cette proposition était la préparation d'un échantillon ultra froid avec un dispositif expérimental beaucoup plus simple que celui de la référence [Web 03]. De plus, la proposition [Comp 06] prédit la préparation d'un condensat de Césium en un temps beaucoup plus court que les temps de préparation rapportée dans la référence [Web 03]. L'étude de la réalisation expérimentale de cette proposition théorique a déjà commencé, dans le cadre de la thèse de G. Stern [Stern 08]. J'ai continué cette étude et j'ai réalisé plusieurs études avec différents types de réservoir (Dark-SPOT, C-MOT) et aussi de un type de <b>chargement</b> différent qui est basé sur le refroidissement par bandes latérales (Raman-Sideband Cooling). Toutes les piéges préparés par ces méthodes, avait une densité inférieure a celle nécessaire pour la réalisation d'un processus de refroidissement évaporatif, qui est nécessaire pour la réalisation d'un condensat. Les problèmes techniques que nous avons rencontrés vers Mai 2008 (destruction de vide), nous ont conduit d'arrêter les études de refroidissement des atomes, et de s'orienter vers les études de manipulation des molécules de Césium. Pendant cette période, l'équipe avait beaucoup progressé dans manipulation des molécules de Césium, et plus spécifiquement sur la réalisation du refroidissement du degré de liberté qui correspond à la vibration des molécules. La nouvelle technique que l'équipe avait introduit et qui est rapporté à la référence [Vit 08], permet le refroidissement de la vibration des molécules de Césium par un laser femtoseconde faconné, avec un processus de pompage optique [Kast 66]. Mon objectif dans la thématique de la manipulation des molécules froides, était d'étudier la généralisation de cette technique. Par example le transfert de la population moléculaire dans un seul état vibrationnel pré – sélectionné a été observé. Ce résultat est discuté dans la référence [Sof 09]. Une autre généralisation est la réalisation du refroidissement vibrationnel et du transfert de la population moléculaire avec une source de lumière non cohérente, résultat qui est discuté dans la référence [Sof 09 b]. Une autre généralisation importante est le refroidissement de la rotation moléculaire. Cette étude théorique est discutée dans les articles de l'équipe auxquels j'ai participé [Vit 09, Sof 09, Sof 09 c], et les études expérimentales préliminaires dans la référence [Fio 09]. Finalement, la généralisation de la technique pour le refroidissement vibrationnel des molécules heteronucleaires est discuté dans le dernière chapitre de ma thèse. Le document de ma thèse est donc divisé en deux parties, dans chacune d'elles je discute en détails ma contribution scientifique dans l'équipe Atomes et Molécules Froides du Laboratoire Aimé Cotton...|$|E
40|$|WITHIN THE FRAMEWORK OF FEASABILITY STUDIES OF UNDERGROUND REPOSITORIES FOR RADIOACTIVE WASTE, THE STUDY OF PERMEABILITY EVOLUTION WITH DAMAGE OF THE HOST LAYER IS CRUCIAL. THE GOALS OF THIS WORK WERE : (i) TO CHARACTERIZE EXPERIMENTALLY THE DAMAGE OF TWO CLAYEY ROCKS (BEAUCAIRE MARL AND EAST SHALE) WITH X-RAY MICRO TOMOGRAPHY, (ii) TO DEVELOPP A HIGH PRESSURE TRIAXIAL SET-UP ADAPTED TO PERMEABILITY MEASUREMENT ON VERY LOW PERMEABILITY ROCKS. A NUMBER OF ORIGINAL TRIAXIAL DEVICES HAVE BEEN REALISED TO CHARACTERIZE DAMAGE OF CLAYEY ROCKS, UNDER DEVIATORIC LOADING, WITH X-RAY MICRO TOMOGRAPHY ON A SYNCHROTRON BEAMLINE AT THE ESRF (GRENOBLE). LOCALIZED DAMAGE AND ITS EVOLUTION HAVE BEEN CHARACTERIZED AT A FINE SCALE (OF ORDER OF TEN MICRONS). DIGITAL IMAGE CORRELATION TECHNIQUES, EXTENDED TO 3 D IMAGES, HAVE BEEN USED TO MEASURE INCREMENTAL STRAIN FIELDS FROM TOMOGRAPHIC IMAGES. WE DEMONSTRATED THAT THESE TECHNIQUES ARE VERY USEFUL IN THE STUDY OF THE LOCALIZED DAMAGE OF GEOMATERIALS AND ESPECIALLY FOR THE INITIATION. A HIGH PRESSURE TRIAXIAL DEVICE HAS BEEN REALISED TO MEASURE PERMEABILITY EVOLUTION OF THE EAST SHALE AS A FUNCTION OF APLLIED STRESS (ISOTROPIC AND DEVIATORIC). THE PARTICULARITY OF THIS SET-UP IS THE SMALL SIZE OF THE TEST SPECIMEN (CYLINDER OF 10 MM IN DIAMETER AND 20 MM IN HEIGHT) WHICH ALLOWS SIGNIFICANT REDUCTION OF TEST DURATION. DANS LE CADRE DES ETUDES DE FAISABILITE DU STOCKAGE DES DECHETS RADIOACTIFS EN COUCHES GEOLOGIQUES PROFONDES, L'ETUDE DE L'EVOLUTION DE LA PERMEABILITE DE LA COUCHE HOTE EN FONCTION DE L'ENDOMMAGEMENT EST PRIMORDIALE. CE TRAVAIL A CONSISTE D'UNE PART, A ETUDIE EXPERIMENTALEMENT L'ENDOMMAGEMENT DE DEUX ROCHES ARGILEUSES (MARNE DE BEAUCAIRE ET ARGILITE DE L'EST) A L'AIDE DES TECHNIQUES DE MICRO TOMOGRAPHIE A RAYONS X, ET D'AUTRE PART, A DEVELOPPER UNE INSTALLATION TRIXIALE HAUTE PRESSION ADAPTEE AUX MESURES DE PERMEABILITE SUR DES ROCHES DE TRES FAIBLES PERMEABILITES. DES INSTALLATIONS TRIAXIALES ORIGINALES ONT ETE REALISEES AFIN DE CARACTERISER SOUS <b>CHARGEMENT</b> DEVIATOIRE L'ENDOMMAGEMENT DES ROCHES ARGILEUSES A L'AIDE DE LA MICRO TOMOGRAPHIE A RAYONS X SUR UNE LIGNE SYNCHROTRON A L'ESRF (GRENOBLE). L'ENDOMMAGEMENT LOCALISE ET SON EVOLUTION EN COURS D'ESSAI, ONT AINSI PU ETRE CARACTERISES A UNE ECHELLE FINE (DE L'ORDRE DE LA DIZAINE DE MICRONS). LES TECHNIQUES DE CORRELATION D'IMAGES NUMERIQUES ETENDUES AUX IMAGES TRIDIMENSIONNELLLES ONT ETE UTILISEES POUR MESURER LES CHAMPS INCREMENTAUX DE DEFORMATION ET ONT MONTRE LEUR INTERET DANS L'ETUDE DE L'ENDOMMAGEMENT LOCALISE DANS LES GEOMATERIAUX ET NOTAMMENT DE SON EVOLUTION. ENFIN, UNE INSTALLATION TRIAXIALE HAUTE PRESSION A ETE REALISEE POUR MESURER L'EVOLUTION DE LA PERMEABILITE DE L'ARGILITE DE L'EST EN FONCTION DU NIVEAU DE CONTRAINTES (ISOTROPE ET DEVIATOIRE) APPLIQUEES. SA PARTICULARITE EST LA PETITE TAILLE DES ECHANTILLONS (CYLINDRES DE 10 MM DE DIAMETRE ET 20 MM DE HAUTEUR) AFIN DE REDUIRE LES TEMPS D'ESSAIS...|$|E
40|$|TO OBTAIN THE OPTIMAL MATERIAL PROPERTIES, AUTOMOTIVE CYLINDER HEADS, MADE OF ALUMINIUM ALLOYS, ARE HEAT TREATED (QUENCHING - AGEAING). THIS THERMAL TREATMENT GENERATES RESIDUAL STRESSES AND HAS TO BE TAKEN INTO ACCOUNT IN THE NUMERICAL HIGH CYCLE FATIGUE DESIGN. SINCE THE RESIDUAL STRESSES ARE PRINCIPALLY DUE TO THE INHOMOGENEOUS QUENCHING COOLING, THE THERMAL EVOLUTION MUST BE CORRECTLY SIMULATED. HEAT TRANSFER COEFFICIENTS H(T), DEFINING THE HEAT EXCHANGES, ARE USED TO OBTAIN THE NUMERICAL COOLING. A SIMPLE ANALYTICAL FUNCTION IS PROPOSED WHOSE PARAMETERS ARE OPTIMISED TO FIT THE EXPERIMENTAL CURVES. THE REMAINNING RESIDUAL STRESSES FOLLOW FROM A SIMPLE MECHANICAL ANALYSIS. IT IS FOUND THAT THE STRESSES IN THE LOCAL CRACKING AREA ARE TENSILE AND THEREFORE STRONGLY UNFAVOURABLE FOR THE HIGH CYCLE FATIGUE ENDURANCE. IN ADDITION, TAKING INTO ACCOUNT THE RESIDUAL STRESSES IN THE FATIGUE DESIGN, AT THE END OF THE THERMAL TREATMENT, LEADS TO PREDICTIONS FOR THE RISK REGIONS THAT ARE CONSISTENT WITH EXPERIMENTAL OBSERVATIONS. MOREOVER, IN ORDER TO USE NUMERICAL SIMULATION IN THE OPTIMISATION OF THE DESIGN PROCESS, COMPUTATIONAL TIME MUST BE REDUCED IN THE RESOLUTION OF AN EVOLUTION PROBLEM OR THE SEARCH OF THE STABILIZED SOLUTION OF A STRUCTURE SUBMITTED TO A PERIODIC LOADING. THE METHOD IS BASED ON THE LARGE TIME INCREMENT METHOD AND THE DIRECT CYCLIC METHOD : THE GLOBAL EQUILIBRIUM, WRITTEN UNDER ITS RESIDUAL FORM, IS SOLVED ONTO A REDUCED WAVELET BASE. A SUPSTENSIAL REDUCTION OF COMPUTATIONAL TIME IS OBTAINED WHEN THE STABILISED SOLUTION IS SEARCHED. AFIN D'OBTENIR LES PROPRIETES METALLURGIQUES OPTIMALES DU MATERIAU, LES CULASSES AUTOMOBILES EN ALLIAGE D'ALUMINIUM SUBISSENT UN TRAITEMENT THERMIQUE (TREMPE-REVENU) GENERANT D'IMPORTANTES CONTRAINTES RESIDUELLES. LEUR MODELISATION EST NECESSAIRE POUR POUVOIR PREDIRE LA TENUE EN FATIGUE POLYCYCLIQUE. LES CONTRAINTES RESIDUELLES ETANT PILOTEES PAR LA THERMIQUE DE TREMPE, IDENTIFIER L'HISTOIRE THERMIQUE DU REFROIDISSEMENT EST PRIMORDIAL. LES COEFFICIENTS D'ECHANGE H(T), MODELISANT LES TRANSFERTS THERMIQUES AVEC L'EXTERIEUR, DETERMINENT LE REFROIDISSEMENT. LEUR EVOLUTION EST DEFINIE PAR UNE FONCTION ANALYTIQUE SIMPLE DONT LES PARAMETRES SONT RECALES PAR OPTIMISATION A PARTIR DE DONNEES EXPERIMENTALES. UNE FOIS L'HISTOIRE THERMIQUE SIMULEE CORRECTEMENT, LES CONTRAINTES RESIDUELLES SONT OBTENUES SUITE A UN CALCUL MECANIQUE METTANT EN EVIDENCE, DANS LES REGIONS A RISQUE, DES ZONES DE TRACTION DEFAVORABLES A LA TENUE EN SERVICE. LA PRISE EN COMPTE DE CET ETAT INITIAL PERMET ALORS DE CARACTERISER LES ZONES CRITIQUES EXPERIMENTALEMENT OBSERVEES. PAR AILLEURS, AFIN DE RENDRE L'OUTIL OPERATIONNEL EN BE, IL EST NECESSAIRE DE PROPOSER UNE METHODE NUMERIQUE PERMETTANT DE DIMINUER LES DUREES DE SIMULATION POUR LA RESOLUTION D'UN PROBLEME D'EVOLUTION ET POUR LA RECHERCHE DIRECTE DE LA REPONSE STABILISEE D'UNE STRUCTURE SOUMISE A UN <b>CHARGEMENT</b> CYCLIQUE. L'APPROCHE DEVELOPPEE REPOSE SUR LA METHODE A GRAND INCREMENT DE TEMPS ET LA METHODE CYCLIQUE DIRECTE : L'EQUILIBRE GLOBAL, ECRIT SOUS SA FORME RESIDUELLE, EST RESOLU SUR UNE BASE D'ONDELETTES REDUITE. DES GAINS SIGNIFICATIFS EN TEMPS CPU SONT OBTENUS POUR LA RECHERCHE DU CYCLE STABILISE...|$|E
40|$|LES TRAVAUX PRESENTES DANS CE MEMOIRE CONCERNENT L EXPLORATION DE L ESPACE DE CONCEPTION DES ARCHITECTURES SOC POUR DES APPLICATIONS ORIENTEES TELECOMMUNICATION. L EVOLUTION IMPORTANTE DES SEMI-CONDUCTEURS A PERMIT L IMPLEMENTATION DES SYSTEMES COMPLETS SUR UNE PUCE. CETTE IMPLEMENTATION A ETE RENDUE POSSIBLE PAR DES METHODOLOGIES DE CONCEPTION BASEES SUR LA REUTILISATION DES COMPOSANTS EXISTANTS, COMBINEES ENSEMBLE, CONSTITUENT LE SYSTEME; LE PROBLEME POSE EST L OPTIMISATION MATHEMATIQUE DES PARAMETRES DE L ENSEMBLE DES IPS SOFT CONSTITUANT LE SOC. LE PROBLEME DEVIENT ALORS UNE OPTIMISATION MULTIOBJECTIFS. DANS UNE PREMIERE ETAPE, DES TECHNIQUES D EXPLORATION POUR LE DIMENSIONNEMENT D IP DE PROCESSEUR SUPERSCALAIR SONT PROPOSEES. LA SECONDE ETAPE EST UNE EXTENSION DE CADRE PRECEDENT PAR COUPLAGE DE L EXPLORATION MULTIOBJECTIFS AVEC UNE IMPLEMENTATION MATERIELLE SUR CIRCUITS FPGA, ELLE PERMET ALORS UNE EXPLORATION AVEC MATERIEL DANS LA BOUCLE. CETTE APPROCHE EST APPLIQUEE AU PROCESSEUR LEON V 2. 0 DE L ESA SUR DES CIRCUITS XILINX VIRTEX-II, QUI DE PAR LEUR RECONFIGURABILITE PERMETTENT LE <b>CHARGEMENT</b> DE NOUVELLES CONFIGURATIONS LORS DE L EXPLORATION. ENFIN, L IMPORTANCE DES SOC MIXTES ANALOGIQUES/NUMERIQUES, NOUS A POUSSE A NOUS INTERESSER A L OPTIMISATION DES CIRCUITS ANALOGIQUES ET CE SUR LE MEME PRINCIPE MAIS EN UTILISANT DES CIRCUITS FPAA QUI PERMETTENT LA CONCEPTION ET L IMPLEMENTATION D APPLICATIONS SUR CIRCUITS ANALOGIQUES RE-PROGRAMMABLES. MOTS-CLEFS : SOC, SOPC, FPGA, FPAA, ALGORITHME GENETIQUE, OPTIMISATION MULTIOBJECTIFS, ALGORITHME NSGA-II, EXPLORATION DE L ESPACE DE CONCEPTION, ESTIMATION DES PERFORMANCES, UMTS, WCDMA, TURBO CODE. IN THIS DOCUMENT WE PRESENT A DESIGN SPACE EXPLORATION METHODOLOGY FOR SOC ARCHITECTURES IN TELECOMMUNICATION DOMAIN. THE SIGNIFICANT EVOLUTION OF SEMICONDUCTORS TECHNOLOGY HAS ALLOWED THE IMPLEMENTATION OF COMPLETE SYSTEMS ON A SINGLE CHIP. THIS IMPLEMENTATION WAS MADE POSSIBLE BY THE DESIGN METHODOLOGIES BASED ON THE RE-USE OF EXISTING COMPONENTS IN THE SYSTEM. SO THE PROBLEM BECOMES A MULTIDIMENSIONAL PROBLEM OF MULTI-OBJECTIVE OPTIMIZATION. THIS THESIS CONTRIBUTES TO THE RESOLUTION OF THIS PROBLEM PROPOSING A SOLUTION CONSISTING OF SEVERAL STAGES. IN A FIRST STAGE, THE TECHNIQUES OF EXPLORATION FOR THE DIMENSIONING OF SUPERSCALAR PROCESSOR IPS ARE PROPOSED WHICH TAKE ACCOUNT OF THE THREE CRITERIA: PERFORMANCE, CONSUMPTION OF ENERGY AND SILICON SURFACE AREA. A SECOND CONTRIBUTION WHICH EXTENDS THE PRECEDING FRAMEWORK BY COUPLING MULTI-OBJECTIVE EXPLORATION WITH A PHYSICAL IMPLEMENTATION ON FPGA CIRCUITS ALLOWING AN EXPLORATION WITH PHYSICAL HARDWARE IN THE LOOP. THIS APPROACH IS APPLIED TO LEON PROCESSOR V 2. 0 ESA TO XILINX CIRCUITS VIRTEX-II WHICH FROM THEIR RECONFIGURABILITY ALLOW THE LOADING OF NEW CONFIGURATIONS DURING EXPLORATION. LASTLY, THE IMPORTANCE OF THE MIXED ANALOG-DIGITAL SOC RAISED OUR INTEREST TO DEVISE AN OPTIMIZATION METHODOLOGY FOR THE ANALOG CIRCUITS BASED PRIMARILY ON THE SAME PRINCIPLE. ONLY DIFFERENCE IN THIS METHODOLOGY WAS THE USAGE OF FPAA CIRCUITS WHICH ALLOWS THE DESIGN AND THE IMPLEMENTATION OF APPLICATIONS ON REPROGRAMMABLE ANALOG CIRCUITS. KEY-WORDS: SOC, SOPC, FPGA, FPAA, RECONFIGURABLE ARCHITECTURES, GENETIC ALGORITHM, MULTI-OBJECTIVE OPTIMIZATION, DESIGN SPACE EXPLORATION, PERFORMANCES ESTIMATION, UMTS, WCDMA, TURBO CODER. ORSAY-PARIS 11 -BU Sciences (914712101) / SudocSudocFranceF...|$|E
40|$|The {{objective}} {{of our work}} {{is to develop a}} container assignment system for intelligent autonomous vehicles (AIVS) in a container terminal. Given the complexity of this problem, it was proposed to decompose it into three problems: The problem of dispatching containers to AIVS, the AIVS routing problem and the problem of scheduling containers to queues of AIVS. To achieve this goal, we developed in the first phase, a static system for multi-objective problem to optimize the total duration of the containers transportation, the waiting time of vehicles at loading points and the equilibrium of working time between vehicles. The approach used was the genetic algorithm (GA). This approach was applied to optimize only the assignment operation without influence on the choice of the path traveled by each AIV. An extension of this work was then made to improve the results found. For this purpose, a comparative study was carried out between three approaches: The first approach is the AG, the second approach is the GA and the Dijkstra algorithm (DIJK) that was used to find the shortest path for each vehicle and the third approach is the AG and DIJK and heuristic (HEUR) which was proposed to choose the nearest vehicle of each container. The numerical study showed the best performance of the AG & DJK & HEUR approach over the other two approaches. In the second phase of our project, the robustness of our system in a dynamic environment has been studied. A delay of the arrival of a ship at the port or malfunction of one of any equipment of the port can cause a delay of one of the operations of loading or unloading process. This will affect the container assignment operation. The idea was to add new containers to vehicles that are already unavailable. The traffic can also cause a delay in arrival of the vehicle at the position of the container or the unavailability of one of the paths crossing point. These cases were investigated experimentally, numerical results showed the robustness of our approach to dynamic case. L’objectif de ce travail est de développer un système d’affectation des conteneurs aux véhicules autonomes intelligents (AIVs) dans un terminal à conteneurs. Dans la première phase, on a développé un système statique pour résoudre le problème multi-objectif optimisant la durée totale des opérations de déplacement des conteneurs, le temps d’attente des véhicules aux niveaux de points de <b>chargement</b> et de déchargement et l’équilibre de temps de travail entre les véhicules. L’approche proposée est l’algorithme génétique(AG). Une extension de cette approche a été ensuite effectuée pour corriger les limites de la précédente. Pour choisir la meilleure approche, une étude comparative a été réalisée entre trois approches : AG, AG & DIJK et AG & DIJK & HEUR. Les résultats numérique ont montré que l’approche AG & DIJK & HEUR est meilleure. Dans la deuxième phase, on a étudié la robustesse de notre système dans un environnement dynamique. Un retard de l’arrivée d’un navire au port ou un dysfonctionnement de l’un des équipements peutperturber le planning des opérations et donc influencer sur les opérations d’affectation des conteneurs. L’idée était d’ajouter les nouveaux conteneurs aux véhicules qui sont déjà non disponibles. D’autres cas de perturbation comme la congestion routière, la non disponibilité de certaines portions de la routes ont été étudiés expérimentalementEt les résultats numériques ont montré la robustesse de notre approche pour le cas dynamique. Mots-clés : Conteneurs, AIV, routage, optimisation, algorithme génetique, environnement dynamique...|$|E
40|$|International audienceThe Pellet-Cladding {{mechanical}} Interaction (PCI) {{occurs in}} Pressurized Water Reactors and might pose {{a risk to}} the integrity of the cladding containing the fuel. In this paper, the Local Defect Correction multigrid method (LDC) is performed in order to improve the PCI simulation accuracy. From an initial coarse mesh, this method consists in recursively adding local sub-grids in zones where higher accuracy is required. In order to automatically detect the zones to be refined, the LDC method is coupled with the Zienkiewicz-Zhu a posteriori error estimator. This estimator is based on the stress discontinuities between elements obtained by the finite element method. It provides hence a tool to detect the stress singularity zones. The strategy proposed enables us to automatically refine the mesh around the stress concentration zones and to stop the refinement process when the solution is accurate enough or when the refinement does not improve the solution accuracy anymore. The numerical results on 2 D elasticity test cases show the efficiency of this strategy but also the limit of the Zienkiewicz-Zhu a posteriori error estimator. L'interaction mécanique pastille-gaine est un phénomène se produisant dans les réacteurs à eau pres-surisée et pouvant mettre à défaut l'intégrité de la gaine entourant le combustible. Dans cet article, la méthode multigrille Local Defect Correction (LDC) est utilisée afin d'améliorer la précision de la simulation de ce phénomène. A partir d'un maillage initial, cette méthode consiste à ajouter récursivement des sous-grilles locales dans des zones où une solution précise est recherchée. Afin de détecter automa-tiquement les zones à raffiner, la méthode LDC est couplée avec l'estimateur d'erreur a posteriori de type Zienkiewicz et Zhu. Cet estimateur se base sur le fait que les contraintes obtenues par la méthode des éléments finis sont discontinues entre éléments. Il permet ainsi de détecter les zones de singularité de contraintes. La stratégie proposée permet de raffiner automatiquement le maillage dans les zones de concentration de contraintes et également d'arrêter le raffinement quand la solution est suffisamment précise ou lorsque le raffinement n'apporte plus d'amélioration de la solution. Les résultats numériques obtenus sur des cas tests 2 D élastiques avec discontinuité de <b>chargement</b> montrent l'efficacité de cette stratégie mais également les limites de l'estimateur d'erreur a posteriori de type Zienkiewicz et Zhu. Abstract : The Pellet-Cladding mechanical Interaction (PCI) occurs in Pressurized Water Reactors and might pose a risk {{to the integrity of}} the cladding containing the fuel. In this paper, the Local Defect Correction multigrid method (LDC) is performed in order to improve the PCI simulation accuracy. From an initial coarse mesh, this method consists in recursively adding local sub-grids in zones where higher accuracy is required. In order to automatically detect the zones to be refined, the LDC method is coupled with the Zienkiewicz-Zhu a posteriori error estimator. This estimator is based on the stress discontinuities between elements obtained by the finite element method. It provides hence a tool to detect the stress singularity zones. The strategy proposed enables us to automatically refine the mesh around the stress concentration zones and to stop the refinement process when the solution is accurate enough or when the refinement does not improve the solution accuracy anymore. The numerical results on 2 D elasticity test cases show the efficiency of this strategy but also the limit of the Zienkiewicz-Zhu a posteriori error estimator...|$|E
40|$|A {{major issue}} in {{fracture}} mechanics is to model the nucleation of a crack in a sound material. There are two difficulties: {{the first one is}} to propose a law able to predict that nucleation; the second is a purely numerical issue. It is indeed difficult to compute with a good accuracy all the mechanical quantities like the energy release rate associated with a crack of small length which appears at the tip of a notch. The classical finite element method leads to inaccurate results because of the overlap of two singularities which cannot be correctly captured by this method: one due to the tip of the notch, the other due to the tip of the crack. A specific method of approximation based on asymptotic expansions is preferable as it is developed in analog situations with localized defects. The first chapter of the thesis is devoted to the presentation of this Matched Asymptotic Method (shortly, the MAM) {{in the case of a}} defect (which includes the case of a crack) located at the tip of a notch in the simplified context of antiplane linear elasticity. The main goal of the thesis is to use these asymptotic methods to predict the nucleation or the propagation of defects (like cracks) near those singular points. The second chapter of the thesis will be devoted to this task. This requires, of course, to overcome the first issue by introducing a criterion for nucleation. This delicate issue has not received a definitive answer at the present time and it was considered for a long time as a problem which could not be solved in the framework of Griffith theory of fracture. The main invoked reason is that the release of energy due to a small crack tends to zero when the length of the crack tends to zero. Therefore, if one follows the Griffith criterion which stands that the crack can propagate only when the energy release rate reaches a critical value characteristic of the material, no nucleation is possible because the energy release rate vanishes when there is no preexisting crack. This "drawback" of Griffith's theory was one of the motivations which led Francfort and Marigo to replace the Griffith criterion by a principle of least energy. It turns out that this principle of global minimization of the energy is really able to predict the nucleation of cracks in a sound body. However, the nucleation is necessarily brutal in the sense that a crack of finite length suddenly appears at a critical loading. Moreover the system has to cross over an energy barrier which can be high when the minimum is "far". Another way to overcome the issue of the crack nucleation is to leave the pure Griffith setting by considering cohesive cracks. Indeed, since any cohesive force model contains a critical stress, it becomes possible to nucleate crack without invoking global energy minimization. Accordingly, we propose to revisit the problem of nucleation of a crack at the tip of a notch by comparing the three criteria. One of our goal is to use the MAM to obtain semi-analytical expressions for the critical loading at which a crack appears and the length of the nucleated crack. Specifically, the thesis is organized as follows. Chapter 1 is devoted to the description of the MAM on a generic anti-plane linear elastic problem where the body contains a defect near the tip of a notch. We first decompose the solution into two expansions: one, the outer expansion, valid far enough from the tip of the notch, the other, the inner expansion, valid in a neighborhood of the tip of the notch. These expansions contain a sequence of inner and outer terms which are solutions of inner and outer problems and which are interdependent by the matching conditions. Moreover each term contains a regular and a singular part. We explain how all the terms and the coefficients entering in their singular and regular parts are sequentially determined. The chapter finishes by an example where the exact solution is obtained in a closed form and hence where we can verify the relevance of the MAM. In Chapter 2, the MAM is applied to the case where the defect is a crack. Its main goal is to compute with a good accuracy the energy release rate associated with a crack of small length near the tip of the notch. Indeed, it is a real issue in the case of a genuine notch (by opposition to a crack) because the energy release rate starts from 0 when the length of the nucleated crack is 0, then is rapidly increasing with the length of the crack before reaching a maximum and finally is decreasing. Accordingly, after the setting of the problem, one first explains how one computes the energy release rate by the FEM and why the numerical results are less accurate when the crack length is small. Then, one uses the MAM to compute the energy release rate for small values of the crack length and one shows, as it was expected, that the smaller the size of the defect, the more accurate is the approximation by the MAM at a certain order. It even appears that one can obtain very accurate results by computing a small number of terms in the matched asymptotic expansions. We discuss also the influence of the angle of the notch on the accuracy of the results, this angle playing an important role in the process of nucleation (because, in particular, the length at which the maximum of the energy release rate is reached depends on the angle of the notch). It turns out that when the notch is sufficiently sharp, i. e. sufficiently close to a crack, it suffices to calculate the first two non trivial terms of the expansion of the energy release rate to capture with a very good accuracy the dependence of the energy release rate on the crack length. Then a cohesive model, the so-called Dugdale model, is considered in the last section of the chapter. Combining the MAM with the G method allows us to calculate in an almost closed form the nucleation and the evolution of the crack, namely the relations between the external load and the lengths of the non-cohesive zone and the cohesive zone. Specifically, it turns out that the inner problem can be seen as an Hilbert problem which can be solved with the help of complex potentials. Thus, the access to the solution is reduced to a few quadratures which are computed numerically. One obtains so an analytical expression of the critical load at which a "macroscopic" crack will appear in the body after an unstable stage of propagation of the nucleated crack. The order of magnitude of that critical load is directly associated with the power of the singularity of the solution before nucleation which is itself a known function of the angle of the notch. Chapter 3 proposes a generalization of all the previous results in the plane elasticity setting. Specifically, the goal is still to study the nucleation of non cohesive or cohesive cracks at the angle of a notch in the case of a linearly elastic isotropic material but now by considering plane displacements. Moreover, we will consider as well pure mode I situation as mixed modes cases. In the first part of the chapter we use the global minimization principle in the case of a non cohesive crack. In the second part we consider Dugdale cohesive force model. In both cases the MAM is used to compensate the non accuracy of the finite element method. All the derived results can be seen as simple generalizations of those developed in the antiplane case. Indeed, from a conceptual and qualitative viewpoint, we obtain essentially the same types of properties. However, from a technical point of view, the MAM is more difficult to apply in plane elasticity because the sequence of singularities can be obtained only by solving transcendental equations. Therefore, the numerical procedure becomes more expansive. Moreover, from the analytical point of view, the calculations become much more intricate and consequently a part of these calculations are given in the appendix. Un enjeu majeur de mécanique de la rupture est de modéliser l'initiation d'une fissure dans une structure saine. Il y a deux difficultés: la première est de proposer une loi capable de prédire la nucléation, la seconde est d'ordre purement numérique. En ce qui concerne ce deuxième point, il est en effet difficile de calculer avec une bonne précision toute quantité comme le taux de restitution d'énergie associée à une fissure de faible longueur qui apparaît en fond d'entaille. La méthode des éléments finis classique conduit à des résultats inexacts en raison de la superposition de deux singularités (l'une due à l'entaille, l'autre à la pointe de la fissure) qui ne peuvent être correctement capturées par cette méthode. Une méthode spécifique d'approximation basée sur des développements asymptotiques est préférable comment il a déjà été constaté dans des situations analogues présentant des défauts localisés. Le premier chapitre de la thèse est consacré à la présentation de cette méthode asymptotique dite Méthode des Développements Asymptotiques Raccordés (MAM) dans le cas d'un défaut (ce qui inclut le cas d'une fissure) situé à l'extrémité d'une entaille. Cette première étude est faite dans le cadre simplifié de l'élasticité linéaire antiplane avant d'être étendue à l'élasticité plane dans le troisième chapitre. Un objectif majeur est d'utiliser cette méthode asymptotique pour prédire la nucléation ou la propagation d'une fissure à proximité d'un point singulier. Le deuxième chapitre de la thèse sera consacré à cette tâche. Cela nécessite, bien sûr, de lever la première difficulté en proposant un critère de nucléation physiquement raisonnable. Cette délicate question n'a pas reçu de réponse définitive à l'heure actuelle et a été considérée pendant longtemps comme un problème qui ne pouvait être résolu dans le cadre de la théorie de Griffith. La principale raison invoquée est que le taux de restitution de l'énergie dû à une petite fissure tend vers zéro lorsque la longueur de la fissure tend vers zéro. Par conséquent, si l'on suit le critère de Griffith qui stipule que la fissure peut se propager que lorsque le taux de libération d'énergie atteint une valeur caractéristique du matériau, il n'y a pas de nucléation possible. Ce "défaut" de la théorie de Griffith fut l'une des motivations qui conduit Francfort et Marigo à remplacer le critère de Griffith par un principe de minimisation de l'énergie. Il s'avère que ce principe de minimum global de l'énergie est vraiment en mesure de prédire la nucléation des fissures dans un corps sain. Cependant, la nucléation est nécessairement brutale dans le sens où une fissure de longueur finie apparaît brutalement à une charge critique et de plus il faut que le système franchisse une barrière d'énergie qui peut être d'autant plus haute que le minimum est "loin". Une autre façon de rendre compte de la nucléation de fissures est de quitter le cadre de la théorie de Griffith en introduisant le concept de forces cohésives. L'intérêt d'une telle approche est qu'elle contient automatiquement la notion de contrainte critique qui permet de régir naturellement la nucléation sans passer par le principe de minimisation globale de l'énergie. En résumé, nous proposons de traiter le problème de la nucléation d'une fissure à la pointe d'une entaille de trois façons et de comparer les trois critères correspondants. L'un de nos objectifs est aussi d'utiliser la MAM pour obtenir des expressions semi-analytiques pour la charge critique à partir de laquelle une fissure apparaît ainsi que la longueur de la fissure une fois nucléée. De façon précise, la thèse est organisée comme suit. Le chapitre 1 est consacré à la description de la MAM sur un problème générique d'élasticité linéaire antiplane où la structure contient un défaut situé au voisinage de la pointe d'une entaille. Nous avons d'abord décomposé la solution en deux développements: l'un, le développement extérieur, valable assez loin de la pointe de l'entaille, l'autre, le développement intérieur, valable au voisinage de la pointe de l'entaille. Ces développements contiennent une séquence de termes "intérieurs" et "exterieurs" qui sont solutions de problèmes "intérieurs" et "extérieurs" reliés les uns aux autres par des conditions de raccord. En outre, chaque terme contient une partie régulière et une partie singulière. Nous expliquons ensuite comment tous les termes et les 4 coefficients qui entrent dans les parties singulières et régulières sont déterminés séquentiellement. Le chapitre se termine par un exemple où la solution exacte est connue et peut donc être développée directement avant d'être comparée à celle fournie par la MAM. Dans le chapitre 2, laMAMest appliquée au cas où le défaut est une fissure. Le premier objectif est de calculer avec une bonne précision le taux de restitution d'énergie associée à une fissure non cohésive de faible longueur située près de la pointe de l'entaille. En effet, il s'agit d'un véritable problème dans le cas où l'entaille n'est elle-même pas une fissure parce que le taux de restitution d'énergie est voisin de 0 lorsque la longueur de la fissure nucléée est voisine de 0, puis augmente rapidement avec la longueur de la fissure avant d'atteindre un maximum pour finalement redécroître. On explique d'abord comment le taux de restitution d'énergie est calculé par la Méthode des Elémenst Finis et pourquoi les résultats numériques sont moins précis lorsque la longueur de la fissure est faible. Ensuite, on utilise la MAM pour calculer le taux de restitution d'énergie pour les petites valeurs de la longueur de la fissure et on montre, comme il était prévu, que plus la taille de la fissure est petite, plus le résultat fourni par la MAM à un ordre donné est précis. Il s'avère même que l'on peut obtenir des résultats très précis en calculant seulement un petit nombre de termes. Nous discutons aussi de l'influence de l'angle de l'entaille sur l'exactitude des résultats. Cet angle joue un rôle important dans le processus de nucléation (parce que, en particulier, la longueur à partir de laquelle le maximum du taux de restitution d'énergie est atteinte dépend de l'angle de l'entaille). Lorsque l'angle de l'entaille est suffisamment grand, il suffit de calculer les deux premiers termes non triviaux du développement du taux de restitution d'énergie pour obtenir avec une très bonne précision la dépendance du taux de restitution d'énergie avec la longueur de fissure. Nous considérons ensuite le cas des fissures cohésives en introduisant le modèle de forces cohésives de Dugdale. En combinant la MAM avec la méthode G, nous obtenons un système de deux équations non linéaires couplées régissant l'évolution des longueurs de la zone non-cohésive et la zone cohésive en fonction du <b>chargement.</b> Il s'avère que le problème intérieur fourni par la MAM est un problème de Hilbert qui peut être résolu par la méthode des potentiels complexes. Ce faisant, la résolution se ramène à de simples quadratures qui sont calculées numériquement. On obtient ainsi, de façon quasiment analytique, la charge critique à partir de laquelle la petite fissure se propage de façon instable pour donner lieu à une fissure "macroscopique". En particulier, l'ordre de grandeur de cette charge critique est directement relié à l'exposant de la singularité de la solution avant fissuration qui est lui-même fonction de l'angle de l'entaille. Le chapitre 3 propose une généralisation de toutes les méthodes et résultats précédents au cas de l'élasticité plane. De façon précise, le but est toujours d'étudier la nucléation de fissures cohésives ou non cohésives à l'angle d'une entaille dans un milieu linéairement élastique et isotrope, mais maintenant en considérant des déplacements plans. De plus, il s'agit de traiter les conditions de nucléation aussi bien sous mode I pur que sous mode mixte. Dans la première partie du chapitre, nous utilisons le principe de minimisation globale pour traiter le cas des fissures non cohésives, alors que dans la deuxième partie nous utilisons le modèle de Dugdale pour traiter le cas des fissures cohésives. Dans les deux cas, la MAM est mise en oeuvre pour pallier le manque de précision de la méthode des éléments finis. Tous les résultats qui sont obtenus peuvent être considérés comme de simples généralisations de ceux développés dans le cas antiplan. En effet, d'un point de vue conceptuel et qualitatif, nous obtenons essentiellement le même type de propriétés. Toutefois, d'un point de vue technique, la MAM est plus délicate d'application en élasticité plane parce que l'obtention de la suite des fonctions singulières passe par la résolution d'équations transcendantes. Ce faisant, la mise en oeuvre numérique est sensiblement plus coûteuse. De plus, d'un point de vue analytique, les calculs et les démonstartions sont beaucoup plus lourds et une partie est donc passée en annexe...|$|E
40|$|In the {{framework}} of the conservation of early reinforced concrete structures from the last third of the 19 th century up to 1914, this research deals with superstructures (excluding foundations, roads, pipes, etc.) in reinforced concrete (in the modern sense of the term – i. e. concrete made with artificial cement and rebars supplying tensile strength; thus, the combination of a metal profile embedded in concrete is excluded). The development of reinforced concrete as a building material started around 1880 and became widespread {{around the time of the}} First World War. Some of the structures concerned are listed as heritage properties today. Therefore they deserve specific and careful study to ensure long-term preservation of their historic, architectural, technical and socio-economic value. They bear witness to a period in construction history when reinforced concrete was a new material. The outbreak of the First World War marked the end of the initial period of innovation, exploration and experimentation. By then, reinforced concrete had become widely accepted and adopted as a suitable and effective building material. However, present-day attempts at restoration often prove inadequate, due to incomplete understanding of this period of construction and the characteristics of the first generation of reinforced concrete. If the causes of degradation are incorrectly diagnosed, the repairs are likely to be inappropriate. Moreover, the number of reinforced concrete structures requiring repair work is currently increasing with the natural ageing of the material. This phenomenon will continue to grow in the coming years. With this in mind, the present research aims at identifying the specific structural characteristics of reinforced concrete structures erected before the First World War. Several axes of investigation were pursued in this PhD research and have resulted in the main observations detailed below. - Based on a case study of the region of Brussels (Belgium), a database of structures built in reinforced concrete prior to 1914 was drawn up in order to place the material in its historical and geographical context. The inventory currently contains 507 examples and provides a panorama of the uses of reinforced concrete, ranging from numerous foundations and slabs to a complete structure from the end of the 1890 s. This list is supplemented by a survey of a total of 605 patents filed for reinforced concrete in Belgium before the First World War. The early development of reinforced concrete was strongly related to national patenting, with a considerable number of systems being patented by private inventors for commercial purposes. Reinforced concrete profoundly transformed the building industry. All the professions working with the composite material had to change their approach, from the planning stage through to execution on the site. From the viewpoint of construction history, all these modifications make the time of the advent of reinforced concrete a particularly fruitful period to study. - From the survey of early reinforced concrete structures in Brussels and the database of Belgian patents, the supremacy of the Frenchman François Hennebique and his system on the Brussels market for reinforced concrete (and, by extension, on the Belgian market) before 1914 is incontestable. This commercial achievement resulted from a combination of factors: an efficient structural system, meticulous attention to the quality of on-site reinforced concrete execution, and the commercial acumen to develop the business through advertising and other media. The well-known Hennebique system represents a monolithic structure including slabs, beams and columns. In fact, this system changed over the decades of operation of Hennebique’s company, not so much in relation to the design methods (his original semi-empirical method continued to be used) but particularly in practical terms (the type and location of the rebars among others). The evolution of the system is analysed by means of technical drawings from about 30 Belgian projects designed by Hennebique between 1900 and 1930. - After the building contractors, who had been the first to believe in the structural and economic potential of reinforced concrete, engineers invented the calculation models and architects started developing new shapes. The Belgian engineer Paul Christophe was among the first theorists of reinforced concrete. The publication of his book Le béton armé et ses applications in 1899 is internationally recognised as a milestone in the rational modelling of structural reinforced concrete elements. Prior to the present study, details of his life and work remained largely uninvestigated, but the discovery of large parts of his personal archives has allowed clarification of his role in the popularisation of reinforced concrete, especially at the theoretical level. - Reinforced concrete structures around the beginning of the 20 th century were initially governed by empirical models of calculation (and execution) developed by the individual constructors. Gradually, reinforced concrete standards, published between 1904 and 1923 and based on working stress analysis and elastic modular ratio theory, replaced the utility of the patented systems. The different theoretical approaches are briefly described in this research. Mastering the theoretical assumptions and calculation methods used at the time represents the first step towards an appreciation of the structural behaviour and the possible weaknesses that can be expected. - A review, based on literature published at that time, of the properties of the components of reinforced concrete allows identification of the characteristic materials used in the concrete matrix and the metal reinforcements. The execution process and the available technological tools for erecting a reinforced concrete structure are also addressed, as these would have had a direct influence on the quality of construction. Non-destructive and destructive experimental laboratory tests were performed on original samples, mainly removed from the Colo-Hugues viaduct (1904, Braine-l’Alleud, Hennebique system) in order to assess the mechanical properties, chemical features and durability issues for concrete and ferrous reinforcements. Comparing the results obtained using different techniques also makes it possible to determine the extent to which these techniques are reliable for the appraisal of early reinforced concrete structures. - The structural efficiency of the Hennebique system is assessed based on an understanding of the principles of Hennebique’s semi-empirical method of calculation, but also – and primarily – by means of observations from experimental tests carried out on full-sized beams removed from the Colo-Hugues viaduct. Analysing and understanding the behaviour of the new composite material was a critical issue for promoting the use of reinforced concrete at the beginning of the 20 th century. Today, what is required is a re-assessment of its structural behaviour. Three bending tests up to failure in simply supported conditions were performed at the BATir Department of the Université libre de Bruxelles on T-beams from the Colo-Hugues viaduct. This case study is representative of the majority of Hennebique structures, because the typical continuous straight T-beam is the main structural element of any Hennebique structure (bridge, building, etc.). The first test is a four-point bending test on a complete span (6 m) of the viaduct to obtain the response of the central part under positive bending moment. The flexural failure was ductile and occurred through yielding of the reinforcements followed by crushing of the concrete at mid-span. The second and third tests are three-point bending tests on 4 m long specimens centred on the column, representing the behaviour of the beam around the supports. These showed a sudden slipping failure due to loss of the adhesive bond between rebars. The results of these three experiments combined reproduce the actual behaviour of the viaduct in service. The bearing capacity of the Hennebique system in service and at ultimate has been demonstrated, at least for one loading case. These experimental tests provide essential data for a better understanding of the mechanisms of failure and reveal the main weaknesses of the Hennebique T-beam. Two strengthening solutions are suggested as supplementary information. - The pathologies observed in early reinforced concrete structures (honeycombs, corrosion of the rebars, and so on) are mainly attributable to the tools and techniques that the builders had at their disposal (handmade compaction, high water-to-cement ratio, etc.) and by the limited contemporary knowledge of the physical and chemical phenomena, especially with regard to long-term effects. In fact, the concrete quality of the viaduct is surprisingly satisfactory despite its great age, due to the fact that the whole structure was covered with plaster, like the majority of reinforced concrete structures designed at that time. This research establishes that reinforced concrete structures from 1880 to 1914 differ from later reinforced concrete structures. Taking into consideration the features of early reinforced concrete structures will contribute to ensuring sustainable conservation with limited intervention, thus preserving as much as possible of the original structure when restoration work is undertaken. Working on existing buildings often requires a multidisciplinary and holistic approach. The present study could thus be extended in various areas. For example, other structural aspects could be studied more in depth, such as demonstration of the shear strength of the Hennebique system or detailed consideration of the reinforcements (low adherence, particular anchorage devices, etc.) / C'est dans le cadre de la conservation, au sens large du terme, que s'inscrit cette recherche sur les constructions en béton armé de première génération, c'est-à-dire de la fin du 19 ème siècle au début du 20 ème siècle. Cette recherche traite uniquement des superstructures, à l'exclusion des fondations, routes, tuyaux, etc. et en béton armé au sens moderne du terme, c'est-à-dire un béton réalisé à base de ciment artificiel et dont les armatures interviennent surtout pour reprendre les efforts de traction, ce qui exclut par exemple les utilisations de poutrelles métalliques enrobées de béton. Certains de ces ouvrages, réalisés entre 1880 et 1914, font aujourd'hui partie intégrante du patrimoine bâti, pour leurs valeurs architecturale, historique, technique ou aussi socio-économique. Ils jalonnent désormais l'histoire de la construction comme témoins d'une époque où le béton armé était un matériau nouveau. La Première Guerre mondiale marque la fin de cette période de premières innovations, d'explorations et d'expérimentations. Elle entérine l'acceptation et la diffusion du béton armé comme matériau de construction à part entière. Cependant, ainsi que le montrent certains projets de restauration actuels aux interventions inadéquates, il y a encore une méconnaissance des spécificités du béton armé de cette époque. Les causes de leurs dégradations mal diagnostiquées sont traitées de façon inappropriée. Or, dans les prochaines années, nombre de structures en béton armé construites dans la première moitié du 20 ème siècle seront amenées à subir une rénovation suite au vieillissement naturel du matériau. C'est pourquoi pour conserver au mieux ces structures, il est indispensable d'étudier en détails leurs caractéristiques techniques pour ensuite intervenir, si nécessaire, de façon précise et adaptée. Ce doctorat s'attèle donc à identifier les particularités des constructions en béton armé construites avant l'avènement de la Première Guerre mondiale, et plus spécifiquement à étudier leurs aspects structuraux. Plusieurs axes de recherche ont été développés et ont abouti aux principaux résultats suivants. - Basé sur le cas de la région de Bruxelles-Capitale (Belgique), un inventaire des interventions en béton armé, construites avant 1914, a été dressé pour replacer le matériau dans son contexte historique et géographique. Cette base de données, comprenant 507 biens jusqu'à présent, illustre les types d'utilisation du béton armé dans la construction au début du 20 ème siècle, d'abord des fondations ou simples planchers, jusqu'à une structure monolithique complète dès la fin des années 1890. Cet inventaire est complété par le relevé détaillé des brevets, au nombre de 605, déposés à ce sujet en Belgique avant la Première Guerre mondiale. Les brevets ont joué un rôle fondamental dans le développement du béton armé. Celui-ci était, en effet, régi par un foisonnement de systèmes commerciaux, majoritairement brevetés. L'introduction du béton armé a transformé en profondeur le secteur de la construction et notamment les professions liées tant à la phase de conception qu'au chantier lui-même. Du point de vue de l'histoire de la construction, toutes ces mutations font de l'avènement du béton armé une période historique riche. - A la lecture du panorama offert par les inventaires des constructions et des brevets, la prééminence de la compagnie du Français François Hennebique, et donc de son système, sur le marché bruxellois (et par extrapolation sur le marché belge) du béton armé avant 1914 est indéniable. La réussite commerciale de Hennebique résulte d'une combinaison de facteurs: un système efficace sur le plan structural, une qualité d'exécution de béton coulé en place fiable et méticuleuse ainsi qu'un sens développé des affaires, en maîtrisant l'art de la promotion et de la publicité notamment. Le système bien connu de Hennebique comprend un ensemble monolithique formé par des dalles (hourdis), poutres et colonnes. Ce système a, en réalité, évolué dans le temps, pas tant d'un point de vue théorique (les calculs de dimensionnement sont les mêmes) mais plutôt pratique (positionnement, type d'armatures, etc.). Cette évolution a été observée par l'étude d'une trentaine de cas pratiques exécutés par Hennebique entre 1900 et 1930 en Belgique. - Après les entrepreneurs, qui ont été les premiers à croire aux nouvelles possibilités constructives qu'offre le béton armé ainsi qu'à son succès commercial, les ingénieurs en inventent les principes de calcul et les architectes en révolutionnent les formes. L'ingénieur belge Paul Christophe fut parmi les premiers théoriciens du béton armé. La publication de son ouvrage Le béton armé et ses applications en 1899 constitue une étape importante, et internationalement reconnue, pour le dimensionnement rationnel d'éléments structuraux en béton armé. Jusqu'à la présente recherche, sa vie et son œuvre étaient restées assez confidentielles mais la découverte d'une partie de ses archives personnelles a permis de clarifier son rôle dans la diffusion, surtout théorique, du béton armé. - Les structures en béton armé d'avant la Première Guerre mondiale furent d'abord gouvernées par des méthodes empiriques de dimensionnement (et d'exécution) développées par chaque constructeur. L'apparition des premières règlementations entre 1904 et 1923, basées sur une analyse en contraintes admissibles et la théorie du coefficient d'équivalence, remplace ensuite peu-à-peu l'utilité des systèmes brevetés. Les différentes approches théoriques sont brièvement décrites dans cette recherche. Maitriser les hypothèses et les méthodes de calculs employées à l'époque est, en effet, une première étape pour comprendre le fonctionnement structural prévu et les potentielles défaillances de dimensionnement. - A travers une lecture attentive de la littérature publiée à cette période, les matériaux intervenants dans la fabrication du béton armé (c'est-à-dire le béton et les armatures) et utilisés couramment au début du 20 ème siècle ont été identifiés ainsi que les moyens disponibles à cette époque pour produire des structures en béton armé. Des méthodes d'essais non-destructives et destructives ont été appliquées principalement, sur le viaduc Colo-Hugues (1904, Braine-l'Alleud, système Hennebique) afin d'évaluer les caractéristiques mécaniques, les propriétés chimiques et la durabilité tant du béton que des renforcements métalliques. Comparer les résultats de ces différentes méthodes permet d'aborder les limites d'utilisation de ces techniques, lorsqu'il s'agit d'évaluer structuralement des bétons armés de première génération. - Grâce à la compréhension des principes, semi-empiriques, de dimensionnement appliqués par le bureau Hennebique en son temps mais surtout grâce aux observations déduites des essais expérimentaux réalisés sur des poutres de grandeur réelle, prélevées sur le viaduc Colo-Hugues, le fonctionnement structural réel du système Hennebique est évalué. Comprendre et modéliser le comportement du nouveau matériau composite fut une problématique fondamentale pour accroître l'usage du béton armé au début du 20 ème siècle. Actuellement, il s'agit de réévaluer le comportement de ces structures. Trois essais jusqu'à rupture ont été menés, au département BATir de l'Université libre de Bruxelles, sur des poutres à gousset en T provenant du viaduc Colo-Hugues en conditions isostatiques et soumises à flexion. Ce viaduc des chemins de fer vicinaux est un cas d'étude représentatif de la majorité des constructions Hennebique, car la poutre de section en T est la structure typique du système Hennebique, utilisée tant dans les ouvrages d'art que dans les bâtiments. Le premier essai est une flexion 4 points sur une travée complète du viaduc (6 m de portée) pour obtenir la réponse en zone de moment maximum positif. La rupture ductile a eu lieu par plastification des armatures suivie d'un écrasement du béton en zone centrale, c'est-à-dire dans la zone la plus sollicitée. Deux éléments identiques de longueur de 4 m ont été essayés en flexion 3 points pour représenter le comportement sur appuis. La rupture de ces deux dernières expériences s'est produite suite à un glissement des armatures sur appuis (goussets à côté de la colonne). Il s'agit donc d'une rupture à caractère fragile. Les trois essais combinés représentent correctement la structure hyperstatique du viaduc dans son fonctionnement en service. La capacité portante réelle du système Hennebique en service et à l'état limite ultime, du moins dans un cas de <b>chargement,</b> a pu être expliquée. Ces essais fournissent les données essentielles pour estimer l'efficacité structurale du système Hennebique et identifier ses faiblesses. Deux solutions de renforcement sont proposées en complément d'information. - Les pathologies observées dans les bétons armés datant du début du 20 ème siècle (nids de graviers, corrosion des armatures, etc.) sont, la plupart du temps, causées par les outils sommaires à la disposition des constructeurs (vibration à la main, rapport eau/ciment plus élevé qu'aujourd'hui, etc.) et par une connaissance limitée des phénomènes physiques et chimiques, surtout à long terme. En fait, la qualité du béton du viaduc Colo-Hugues est particulièrement satisfaisante malgré l'âge avancé du béton, grâce notamment à l'enduit recouvrant l'ensemble du viaduc, ce qui est le cas pour la majorité des structures de la période étudiée. Cette recherche démontre que les constructions en béton armé datant de 1880 à 1914 diffèrent des ouvrages postérieurs en béton armé et qu'il serait utile pour leur restauration de tenir compte de ces spécificités. La connaissance approfondie des particularités des constructions en béton armé de première génération permettra, espérons-le, de contribuer à leur longévité en intervenant le moins possible sur les structures d'origine. Etant donné que l'étude des structures existantes nécessite le plus souvent une approche pluridisciplinaire, ce travail pourrait être poursuivi dans plusieurs domaines variés. Il resterait notamment à approfondir d'autres aspects de stabilité, comme par exemple la démonstration de l'efficacité à l'effort tranchant du système Hennebique ou encore la prise en considération plus détaillée des armatures (adhérence limitée, forme d'ancrage particulier, etc.). Doctorat en Sciences de l'ingénieurinfo:eu-repo/semantics/nonPublishe...|$|E
40|$|It {{has been}} known for more than 150 years that action effects in bridges due to traffic action are higher than it has to be {{expected}} for purely static loads. In the design of road bridges, this difference is considered by multiplying static traffic loads with a "dynamic amplification factor". The amplification factors defined in codes are based on dynamic load tests on existing bridges. Despite of hundreds of tests in several countries, experimental investigation has not given satisfactory explanation of the observed phenomena, which has resulted in marked differences between amplification factors defined in different codes. This {{is due to the fact}} that the core of the matter – the dynamic interaction between vehicles and bridges– is a complex mechanical problem. Based on a detailed analysis it is shown in the introduction, that it can also be attributed to the fact, that the experimental investigation is more part of the problem than its solution. This thesis aims at getting a solid and systematic grounding in the problem using theoretical analysis. The centre of attention is the question, which importance dynamic phenomena have in those scenarios which are effectively relevant for the structural safety of a bridge. All scenarios are considered that justify an amplification factor, and not only dynamic vehicle – bridge interaction. The structural safety evaluation of a bridge includes the verification of the ultimate and the fatigue limit state. Accordingly, this thesis distinguishes between the interaction at ultimate limit state, for which inelastic bridge behaviour is assumed, and the interaction at service limit state with linear elastic bridge behaviour. The structural analysis of a bridge shows in addition, that the elements of the bridge deck differ considerably from the main girders: For the elements of the deck – i. e. primarily for the deck slab – dynamic interaction is of little importance, and amplification of action effects is essentially due to amplification of traffic action. In the case of the main girders, action effects are additionally amplified due to the oscillations of the structure. In order to analyse interaction at service limit state in detail, very sophisticated models are required, which do not only cover all relevant eigenmodes of the bridge but also the non-linear, dynamic behaviour of heavy vehicles and the precise road surface profile. Design and analysis of such models are mostly conferred to specialists in numeric analysis and structural dynamics. In the contrary, this thesis aims at capturing the fundamental connections by simple models, which facilitates the identification of the key parameters and the interpretation of their influence. The most important result of the analysis of vehicle – bridge interaction at service limit state is that the amplification factor is most influenced by the weight and the number of vehicles on a bridge. Whereas the amplification is negligible for high vehicle loads, tests with relatively lightweight vehicles on long bridges lead to a significant over-estimation of amplification factors. Furthermore it is shown that neither the span nor the natural frequency of a bridge is appropriate for fixing the amplification factor for a particular bridge and safety verification, respectively. It has been observed in dynamic load tests that deflection measurements consistently result in higher amplification factors than strain measurements. This phenomenon {{has been known}} for more than fifty years, but no explanation has been given so far. In this thesis an explanation is proposed and it is shown that deflection measurements result in an over-estimation of amplification factors. Similar considerations lead to a proposal for a more suitable application of amplification factors in the verification of shear force. A completely new approach is chosen for the analysis of vehicle – bridge interaction at ultimate limit state. The effective behaviour at rupture is taken into account, which necessitates first to deal with the influence of loading velocity on material strength. It is shown that only for impact loading of deck slabs due to dynamic tyre forces a minor increase in concrete strength can be expected. An important prerequisite for the understanding of dynamic behaviour at ultimate limit state is the "gravity effect", which is shown to cause massive reduction in the dissipation capacity of a structure. The determinant criterion with inelastic behaviour is deformability and not stiffness. Simple models are used to study the influence of deformability and gravity effect in the most important cases of dynamically amplified traffic action. The results show, under which conditions the dynamic amplification of action effects can be compensated by plastic deformation of the structure without causing its failure. If the steel yield stress is already attained due to the static part of traffic action, compensation of the dynamic part is only assured if the rupture behaviour is characterised by strain hardening. A simple condition of equilibrium shows that dynamic amplification due to centrifugal forces cannot be absorbed by deformations of the structure. However, rupture behaviour characterised by significant deformation causes a delay in the failure of the structure, which can be sufficient to prevent the definitive rupture anyway, depending on the scenario. In addition to these reflections, it is attempted to determine the importance of shear failures with respect to flexural failures, in order to estimate the probability of this comparatively brittle failure mechanism. In view of the application of the findings, the relevant results are synthesized and a concept for the safety verification accounting for dynamic traffic action is developed. The concept is based on the distinction between verifications at ultimate and service limit state on the one hand, and the separate treatment of elements of the deck and main girders on the other hand. This differentiation allows integrating risk based considerations using explicit hazard scenarios. An important point in the application of the findings is the recommendation to emphasize the benefit of good road surface evenness in the maintenance of structures. A necessary complement in establishing the recommended amplification factors is the detailed analysis of the reaction of vehicles to road surface irregularities. The dynamic tyre forces for different vehicle and axle types, respectively, are analysed, since the findings indicate that the amplification of tyre forces is much more important in fixing amplification factors than the dynamic behaviour of bridges. The investigations clearly show that higher axle loads imply lower amplification factors, and that the maximum amplification of axle forces in axle groups never occurs simultaneously for all axles. The thesis is finished by an annexe including introductions to the dynamic behaviour of vehicles and bridges as well as to the modelling of traffic loads and road surface irregularities. In addition to an extensive review of the state of the art, these introductions constitute an important basis of the work and facilitate understanding of the calculations in the main part. Seit mehr als 150 Jahren ist bekannt, dass die Beanspruchung einer Brücke bei der Belastung durch bewegte Fahrzeuge höher ist als bei Stillstand derselben Fahrzeuge. Diesem Unterschied wird in der Bemessung von Strassenbrücken dadurch Rechnung getragen, dass die statischen Verkehrslasten mit einem "dynamischen Vergrösserungsfaktor" multipliziert werden. Die in den Tragsicherheitsnachweisen verwendeten Vergrösserungsfaktoren stützen sich auf Lastversuche an bestehenden Brücken. Trotz hunderter Versuche in diversen Ländern haben diese Versuche jedoch keine befriedigende Erklärung der Phänomene geliefert, sodass sich die Vergrösserungsfaktoren von Land zu Land teilweise beträchtlich unterscheiden. Dies hängt damit zusammen, dass es sich beim Kernproblem – der dynamischen Wechselwirkung zwischen Fahrzeug und Brücke – um eine komplizierte mechanische Fragestellung handelt. Aufgrund einer eingehenden Analyse in der Einleitung wird dies jedoch auch darauf zurückgeführt, dass die experimentelle Untersuchung mehr Teil des Problems als dessen Lösung ist. Diese Arbeit zielt darauf ab, die Fragestellung aufgrund einer theoretischen Analyse systematisch aufzubereiten. Im Zentrum steht dabei die Fragestellung, welche Bedeutung dynamische Phänomene in jenen Szenarien haben, welche effektiv für die Tragsicherheit einer Brücke massgeblich sind. Zudem werden alle Szenarien betrachtet, welche einen Vergrösserungsfaktor rechtfertigen, und nicht nur die Szenarien mit dynamischer Wechselwirkung. Der Tragsicherheitsnachweis einer Brücke umfasst die Nachweise des Bruch- und des Ermüdungswiderstands. Dementsprechend wird unterschieden zwischen der Wechselwirkung auf Bruchniveau, bei der von inelastischem Materialverhalten ausgegangen wird, sowie der Wechselwirkung auf Gebrauchsniveau unter Beschränkung auf rein elastisches Verhalten. Die Analyse des Tragverhaltens einer Brücke zeigt zudem, dass sich die Elemente der Fahrbahn von den Brückenlängsträgern ganz wesentlich unterschieden: Bei den Elementen der Fahrbahn – das heisst vor allem bei der Fahrbahnplatte – spielt die dynamische Wechselwirkung praktisch keine Rolle, und die Vergrösserung der Beanspruchung besteht im Wesentlichen aus der Lastvergrösserung. Bei den Brückenlängsträgern erhöht sich die Beanspruchung, zusätzlich zur Lastvergrösserung, durch deren eigene Schwingungen. Zur genauen Erfassung der dynamischen Wechselwirkung auf Gebrauchniveau sind sehr komplizierte Modelle erforderlich, welche nicht nur alle Eigenschwingungsformen der Brücke sondern auch das nicht-lineare, dynamische Verhalten von Fahrzeugen sowie die Fahrbahnunebenheiten präzise abbilden. Erstellung und Analyse dieser Modelle werden daher meistens von Spezialisten der Numerik und Baudynamik übernommen. In der vorliegenden Arbeit wird im Gegensatz dazu versucht, die wesentlichen Zusammenhänge durch möglichst einfache Modelle zu erfassen. Dies vereinfacht es, den Einfluss der wichtigsten Parameter zu erfassen und auszuwerten. Das wichtigste Resultat der Analyse der Wechselwirkung auf Gebrauchsniveau ist, dass das Fahrzeuggewicht sowie die Anzahl an Fahrzeugen auf einer Brücke einen enormen Einfluss auf den Vergrösserungsfaktor haben. Während die dynamische Vergrösserung bei hohen Verkehrslasten praktisch vernachlässigbar ist, führen Versuche mit relativ leichten Fahrzeugen auf langen Brücken zu einer markanten Überschätzung des Vergrösserungsfaktors für den Tragsicherheitsnachweis. Weiters konnte gezeigt werden, dass sich weder die Spannweite einer Brücke noch deren Grundfrequenz zur Festlegung eines Vergrösserungsfaktors eignen. Bei dynamischen Lastversuchen ergeben Durchbiegungsmessungen durchwegs höhere Vergrösserungsfaktoren als Dehnungsmessungen. Dieses Phänomen ist seit fünfzig Jahren bekannt, ohne dass bisher eine Erklärung gegeben werden konnte. In dieser wird eine Erklärung vorgeschlagen und gezeigt, dass der Vergrösserungsfaktor aufgrund von Durchbiegungsmessungen deutlich überschätzt wird. Analoge Überlegungen erlauben auch zu zeigen, wie die dynamische Vergrösserung der Querkraft besser erfasst werden kann als dies bis anhin der Fall ist. Für die Analyse der Wechselwirkung auf Bruchniveau wird ein gänzlich neuer Ansatz gewählt, der das effektive Bruchverhalten der Brücke berücksichtigt. Daher wird zuerst grundsätzlich auf den Einfluss der Belastungsgeschwindigkeit bei der Beanspruchung durch Verkehrslasten eingegangen. Es zeigt sich, dass nur bei der stossförmigen Belastung der Fahrbahnplatte durch dynamische Radkräfte eine gewisse Erhöhung der Festigkeiten erwartet werden kann. Eine wichtige Voraussetzung für das Verständnis des dynamischen Verhaltens auf Bruchniveau ist die Schwerkraftwirkung. Diese bewirkt eine drastische Verringerung der Dissipationskapazität des Tragwerks. Entscheidend ist bei inelastischem Verhalten die Verformbarkeit und nicht die Steifigkeit des Tragwerks. Anhand einfacher Modelle wird versucht, die wichtigsten Szenarien mit dynamischer Vergrösserung zu erfassen, wobei in erster Linie das Versagen auf Biegung untersucht wird. Anhand des Vergleichs der Resultate für verschiedene Kraft-Verschiebungs-Diagramme wird abgeschätzt, unter welchen Voraussetzungen der dynamische Anteil der Beanspruchung durch plastische Verformungen aufgenommen werden kann, ohne dass es zum Bruch kommt. Wenn die statische Beanspruchung bereits das Fliessmoment erreicht, dann gelingt dies aufgrund der Schwerkraftwirkung nur noch bei einem Bruchverhalten mit Dehnungsverfestigung. Anhand einer einfachen Gleichgewichtsbetrachtung wird gezeigt, dass bei der dynamischen Lastvergrösserung infolge von Kurvenfahrt oder Bremsung der dynamische Anteil der Einwirkung nicht dissipiert werden kann. Ein verformungsreiches Bruchverhalten führt in diesem Fall jedoch zu einer Verzögerung des Bruchs, die je nach Szenario ausreichen kann, damit ein Auto den Gefahrenbereich verlässt. Darüber hinaus wird auch versucht, die Bedeutung des Schubbruchs im Vergleich zum Biegebruch zu bestimmen, um die Wahrscheinlichkeit dieses verformungsarmen Bruchs abzuschätzen. Die gewonnenen Erkenntnisse fliessen schliesslich in ein Nachweiskonzept ein, in welchem geeignete Vergrösserungsfaktoren angegeben werden, wobei einerseits zwischen Bruch- und Gebrauchsniveau und andererseits zwischen Elementen der Fahrbahn und Brückenlängsträgern unterschieden wird. Die empfohlenen Werte beruhen dabei auf expliziten Gefährdungsbildern, was die Einbeziehung von Risikoüberlegungen ermöglicht. Die Erkenntnisse zeigen bei der Erhaltung bestehender Brücken künftig mehr auf die Gewährleistung einer möglichst ebenen Fahrbahn zu achten. Abgerundet wird die Arbeit durch ausführliche Einführungen zum dynamischen Verhalten von Schwerfahrzeugen und Strassenbrücken, sowie zu Verkehrslasten und Fahrbahnunebenheiten. Dies erleichtert Fachleuten aus dem Brückenbau den Zugang, welche nicht Spezialisten der Baudynamik sind. Den dynamischen Radkräften verschiedener Fahrzeug- bzw. Achstypen infolge von Fahrbahnunebenheiten wird sehr grosse Aufmerksamkeit gewidmet, da dieser Aspekt oft zu Gunsten der Fokussierung auf das Verhalten der Brücke vernachlässigt wurde. Il est connu depuis plus de 150 ans que les efforts internes d'un pont sollicité par le trafic sont plus grands quand les charges sont en mouvement que quand elles sont à l'arrêt. Cette différence est prise en compte lors du dimensionnement d'un pont routier en multipliant les charges de trafic statiques par un « facteur d'amplification dynamique ». Les facteurs d'amplification utilisés dans la vérification structurale se basent sur des essais de charge sur des ponts routiers existants. Malgré des centaines d'essais dans différents pays, l'expérimentation n'a pas fourni une explication satisfaisante des phénomènes observés. En conséquence, les facteurs d'amplification prescrits dans les normes varient parfois considérablement. D'une coté ceci peut être ramené au fait que le cœur du problème – l'interaction dynamique entre un véhicule et un pont – est un problème mécanique complexe. D'un autre coté, une analyse approfondie dans l'introduction de cette thèse montre que l'étude expérimentale fait plutôt partie du problème que de sa solution. Cette thèse a pour but de traiter le problème de manière systématique à l'aide d'une approche théorique. Le cœur est formé par la question : quelle est l'importance des phénomènes dynamiques dans les scénarios, qui sont effectivement déterminants pour la sécurité structurale d'un pont. Tous les scénarios, qui justifient un facteur d'amplification, sont considérés, et non pas seulement l'interaction dynamique véhicule – pont. L'évaluation de la sécurité structurale d'un pont comprend la vérification de la résistance à l'état ultime ainsi qu'à la fatigue. En conséquence, cette thèse distingue entre l'interaction véhicule – pont à l'état ultime, caractérisée par un comportement inélastique du pont, et l'interaction à l'état de service, où un pont se comporte essentiellement de manière linéaire élastique. L'analyse du comportement structural d'un pont montre de plus que, les éléments du tablier se distinguent fondamentalement des poutres longitudinales : pour les éléments du tablier – principalement la dalle de roulement – l'interaction dynamique n'a pratiquement pas d'importance, et l'amplification de la sollicitation est due à l'oscillation des véhicules. Pour les poutres longitudinales s'ajoutent les oscillations de la structure aux oscillations des véhicules. Une étude théorique précise de l'interaction dynamique au niveau de service nécessite des modèles très complexes, qui reproduisent non seulement les modes d'oscillation d'un pont mais aussi le comportement non-linéaire et dynamique des véhicules ainsi que le profil précis de la chaussée. Par conséquence, le développement et l'analyse de tels modèles sont normalement pris en charge par des spécialistes du calcul numérique et dynamique. Cette thèse tente, au contraire, de reproduire les effets principaux à l'aide de modèles les plus simples possibles. Ceci facilite l'identification des paramètres clés et la mise en évidence de leurs influences. Le résultat principal de l'analyse de l'interaction véhicules - pont à l'état de service est l'identification du poids et du nombre des véhicules comme paramètre principal pour le facteur d'amplification. Alors que l'amplification dynamique est pratiquement négligeable pour des charges très élevées, les essais avec des véhicules relativement légers, sur un grand pont, résultent dans une surestimation significative du facteur d'amplification pour une vérification structurale. En outre on montre que ni une portée, ni la fréquence fondamentale d'un pont, ne sont des critères adéquats pour déterminer un facteur d'amplification dans le cas concret d'une vérification structurale. Lors d'un essai dynamique, les mesures de flèches résultent dans des facteurs d'amplification plus élevés que des mesures de déformations. Ce phénomène est connu depuis cinquante ans, sans qu'une explication n'ait été fournie. Cette thèse propose une explication et montre la surestimation de facteurs d'amplification dérivés de mesures de flèches. Des réflexions analogues amènent à une proposition pour une meilleure application du facteur d'amplification dans la vérification de l'effort tranchant. Une approche nouvelle est utilisée pour analyser l'interaction dynamique à l'état ultime. Elle tient compte du comportement effectif à la rupture, ce qui nécessite d'étudier d'abord l'influence de la vitesse de <b>chargement</b> sur la résistance apparente des matériaux. Dans le cas de charges de trafic, seul une légère augmentation de la résistance du béton de la dalle de roulement est à attendre, si une roue heurte un obstacle. Une condition essentielle pour comprendre le comportement à l'état ultime est « l'effet de la gravité », qui cause une réduction radicale de la capacité de dissipation de la structure. Le critère déterminant dans un comportement inélastique est la déformabilité et non la rigidité. Des modèles simples sont utilisés pour étudier l'influence de la déformabilité ainsi que de l'effet de la gravité dans les scénarios avec une amplification dynamique importante. Les résultats montrent sous quelles conditions l'amplification dynamique peut être compensée par la déformation plastique de la structure sans qu'une rupture n'ait lieu. Si l'acier atteint sa limite d'élasticité sous l'effet des charges statiques, une sollicitation dynamique additionnelle ne peut être compensée si l'acier présente un comportement durcissant. Une simple considération d'équilibre montre que l'amplification dynamique due aux forces centrifuges ou aux forces de freinage ne peut pas être compensé par une déformation de la structure. Dans ce cas, un comportement ductile aide à ralentir la rupture, ce qui peut être suffisante pour permettre un véhicule de passer la zone critique. En outre, des réflexions sont présentées sur l'importance d'une rupture à l'effort tranchant, qui consiste généralement en un mode de rupture avec peu de déformation. On montre que la probabilité que ce mode ait lieu avant une rupture à la flexion est faible. En vue de l'application des résultats, les points les plus importants sont résumés et un concept pour la vérification structurale est développé, qui contient de valeurs explicites pour le facteur d'amplification. Le concept se base sur la distinction entre l'état ultime et l'état de service. On distingue également le cas des éléments du tablier et celui des poutres longitudinales. Cette différentiation permet l'intégration de critères de risque sur la base de scénarios détaillés. En plus du concept de vérification, il est recommandé de mettre l'accent plus explicitement sur le bénéfice d'une bonne planéité de la chaussée lors de la maintenance d'une structure. Un complément nécessaire pour l'établissement des facteurs d'amplification recommandés est l'analyse détaillée de l'excitation de véhicules par les irrégularités dans la chaussée. Les forces de roues dynamiques pour différents types de véhicules et d'essieux, respectivement, sont analysées, car les résultats des autres chapitres indiquent que l'amplification des forces d'essieux est nettement plus importante que le comportement dynamique du pont. Les résultats de cette analyse montrent clairement que des essieux plus chargés ont des facteurs d'amplification plus bas, et que la force maximale n'est jamais atteinte pour tous les essieux d'un groupe simultanément...|$|E

