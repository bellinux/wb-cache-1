5|112|Public
2500|$|Burns, Greg, Commemoration of Death: {{the medals}} of the Lusitania murders. (August 2012), full <b>color</b> <b>bleed,</b> 194 pages, ...|$|E
50|$|Consumers can refill ink {{cartridges}} {{themselves with a}} kit, or they can take the cartridge to a refiller or remanufacturer where ink is pumped back into cartridges made up of components from previously used cartridge products. PC World reports that refilled cartridges have higher failure rates, print fewer pages than new cartridges, and demonstrate more on-page problems like streaking, curling, and <b>color</b> <b>bleed.</b>|$|E
50|$|The {{opposite}} problem, luminance {{interference in}} chroma, is {{the appearance of}} a colored noise in image areas with high levels of detail. This results from high-frequency luminance detail crossing into the frequencies used by the chrominance channel and producing false coloration, known as <b>color</b> <b>bleed.</b> Bleed can also make narrowly spaced text difficult to read. Some computers, such as the Apple II, utilized this to generate color.|$|E
50|$|In {{printing}} and graphic arts, mixing of two dissimilar colors in two adjacent printed dots before they dry and absorb in substrate {{is referred to}} as <b>color</b> <b>bleeding.</b> Unless it is done for effect, <b>color</b> <b>bleeding</b> reduces print quality.|$|R
5000|$|... #Caption: <b>Color</b> <b>bleeding</b> in {{newspaper}} print. Note jagged edges of digit's contour lines, part being {{a result of}} surface roughness.|$|R
40|$|<b>Color</b> <b>bleeding</b> is an {{annoying}} chromatic color artifact in DCT-coded technology. We propose an efficient postprocessing technique in YCbCr color space, which {{is commonly used}} in image and video compression, based on adaptive filtering specifically to reduce <b>color</b> <b>bleeding</b> artifacts while preserving the edge sharpness of the reconstructed images. Simulation {{results show that the}} method effectively improves image quality both objectively and subjectively. The PSNR in chroma channels gains a lot and the visual quality is improved effectively...|$|R
50|$|Diffuse {{interreflection}} {{is apparent}} when light from one diffuse object is reflected onto another. Photon mapping is particularly adept at handling this effect because the algorithm reflects photons from one surface to another {{based on that}} surface's bidirectional reflectance distribution function (BRDF), and thus light from one object striking another is a natural result of the method. Diffuse interreflection was first modeled using radiosity solutions. Photon mapping differs though in that it separates the light transport from {{the nature of the}} geometry in the scene. <b>Color</b> <b>bleed</b> is an example of diffuse interreflection.|$|E
50|$|Dot crawl can {{be greatly}} reduced {{by using a}} good comb filter in the {{receiver}} to separate the encoded chrominance signal from the luminance signal. When the NTSC standard was adopted in the 1950s, TV engineers realized that it should theoretically be possible to design a filter to properly separate the luminance and chroma signals. However, the vacuum tube-based electronics of the time did not permit any cost-effective method of implementing a comb filter. Thus, the early color TVs used only notch filters, which cut the luminance off at 3.5 MHz. This effectively reduced the luminance bandwidth (normally 4 MHz) {{to that of the}} chroma, causing considerable <b>color</b> <b>bleed.</b> By the 1970s, TVs had begun using solid-state electronics and the first comb filters appeared. However, they were expensive and only high-end models used them, while most color sets continued to use notch filters.|$|E
50|$|In {{computer}} graphics and 3D rendering, <b>color</b> <b>bleeding</b> is the phenomenon in which objects or surfaces are colored by reflection of colored light from nearby surfaces.|$|R
5000|$|... #Caption: Straight pen-drawn line <b>color</b> <b>bleeding,</b> causing jagged edges. Use of {{the term}} in prior art {{involved}} unwanted propagation of single color due to capillary action in paper fibers and other factors.|$|R
50|$|Another {{common problem}} is <b>color</b> <b>bleeding.</b> For example, washing a red shirt with white {{underwear}} {{can result in}} pink underwear. Often only like colors are washed together to avoid this problem, which is lessened by cold water and repeated washings.|$|R
50|$|Colored {{wrapping}} tissue can be {{used for}} an assortment of visually creative purposes. For example, when wetted, the <b>color</b> <b>bleeds</b> a watercolor-like layer of tissue paper that stays when you peel off the tissue paper. Tissue paper can be crumpled up to form objects, such as flowers.|$|R
30|$|Image cloning {{has many}} useful applications, such as {{removing}} unwanted objects, fixing damaged parts of images, and panorama stitching. Instead of using pixel intensities, the gradient domain {{is used in}} Poisson image editing; however, it suffers from two main problems: <b>color</b> <b>bleeding</b> and bleeding artifacts. In this paper, a modified Poisson blending (MPB) technique is presented which ensures dependency on the boundary pixels of both target and source images rather than just those of the target. The problem of bleeding artifacts is reduced. This makes the proposed technique suitable for use in video compositing as it avoids the flickering caused by bleeding artifacts. To reduce the problem of <b>color</b> <b>bleeding,</b> we use an additional alpha compositing step. Our experimental results using the proposed technique show that MPB reduces the bleeding problems and generates more natural composited images than other techniques.|$|R
40|$|Ray tracing and photon mapping {{provide a}} {{practical}} way of efficiently simulating global illumination including interreflections, caustics, <b>color</b> <b>bleeding,</b> participating media and subsurface scattering in scenes with complicated geometry and advanced material models. This halfday course {{will provide the}} insight necessary to efficiently implement and use ray tracing and photon mapping to simulate global illumination in complex scenes. The presentation will cover the fundamentals of ray tracing and photon mapping including efficient techniques and data-structures for managing large numbers of rays and photons. In addition, we will describe how to integrate {{the information from the}} photon maps in shading algorithms to render global illumination effects such as caustics, <b>color</b> <b>bleeding,</b> participating media, subsurface scattering, and motion blur. Finally, we will describe recent advances for dealing with highly complex movie scenes as well as recent work on realtime ray tracing and photon mapping...|$|R
40|$|Real-time global {{illumination}} in VR systems enhances scene realism {{by incorporating}} soft shadows, reflections {{of objects in}} the scene, and <b>color</b> <b>bleeding.</b> The virtual light field (VLF) method enables real-time global illumination rendering in VR. The VLF has been integrated with the extreme VR system for real-time GPU-based rendering in a cave automatic virtual environment...|$|R
50|$|Printed {{magazines}} and newspapers often use a halftone system. Typical newsprint paper is not very dense, and has relatively high dot gain or <b>color</b> <b>bleeding,</b> so newsprint is usually around 85 LPI. Higher-quality paper, such as that used in commercial magazines, has less dot gain, and can range up to 300 LPI with quality glossy (coated) paper.|$|R
50|$|This simple {{approach}} {{works well}} {{in areas with}} constant color or smooth gradients, but it can cause artifacts such as <b>color</b> <b>bleeding</b> in areas where there are abrupt changes in color or brightness especially noticeable along sharp edges in the image. Because of this, other demosaicing methods attempt to identify high-contrast edges and only interpolate along these edges, but not across them.|$|R
40|$|International audiencePoint based {{rendering}} can simulate global illumination phenomenon {{fast and}} {{is widely used}} in movie production. This paper proposes a point based <b>color</b> <b>bleeding</b> algorithm based on GPU efficiently. In our algorithm, we reorderthe shading points according to the similarity of them to use the coherency of the GPU memory. Then, we proposea novel idea named chunking to accelerate the point cloud traversal process by using the constant memory ofGPU...|$|R
50|$|The {{original}} kit {{colors in}} 1899 were all white. This {{turned out to}} be problematic at that time. To avoid <b>color</b> <b>bleeding</b> from the red and yellow club badge when cleaning the white shirts, the badge had to be removed from each shirt prior to washing and then re-attached afterwards. The club therefore changed to dark blue, and is now nicknamed after the dark blue color of their shirts.|$|R
40|$|Simulating {{light is}} a very {{computationally}} expensive proposition. There are {{a wide variety of}} global illumination algorithms that are implemented and used by major motion picture companies to render interesting and believable scenes. Every algorithm strives to find a balance between speed and accuracy. The Point Based Approximate <b>Color</b> <b>Bleeding</b> algorithm {{is one of the most}} widely used algorithms in the field today. The Point Based Approximate Color Bleeding(PBACB) global illumination algorithm is based on the central idea that the geometry and direct illumination of the scene can be approximated by using a point cloud representation. This point cloud representation can then be used to generate the indirect illumination. The most basic unit of the point cloud is a surfel. A surfel is a two dimensional circle in space that contains the direct illumination for that section of space. The surfels are gathered in a tree structure and approximations are generated for the different levels of the tree. This tree is then used to calculate the appropriate <b>color</b> <b>bleeding</b> effect to apply to the surfaces in a rendered image...|$|R
40|$|We present {{techniques}} which {{create a}} consistent illumination between real and virtual objects inside an application specific optical see-through display: the Virtual Showcase. We use projectors and cameras to capture reflectance information from diffuse real objects and to illuminate them under new synthetic lighting conditions. Matching {{direct and indirect}} lighting effects, such as shading, shadows, reflections and <b>color</b> <b>bleeding</b> can be approximated at interactive rates in such a controlled mixed environment. 1...|$|R
5000|$|Canadian {{animator}} John Kricfalusi (of The Ren & Stimpy Show fame) {{has become}} a prominent critic of digital remastering, particularly in regards to its effects on Western animation. In his blog [...] "John K. Stuff," [...] he has admonished remasters for over-saturating colors and sharpening lines {{to the point of}} <b>color</b> <b>bleeding</b> (among other criticisms). He has gone on record in his blog to describe remastering as [...] "digital ruination" [...] and [...] "digital destruction." ...|$|R
5000|$|However, all {{of these}} {{projects}} had problems with <b>colors</b> <b>bleeding</b> from one phosphor to another. In spite of their best efforts, the wide electron beams simply could not focus tightly enough to hit the individual dots, at least over {{the entirety of the}} screen. Moreover, most of these devices were unwieldy; the arrangement of the electron guns around the outside of the screen resulted in a very large display with considerable [...] "dead space".|$|R
30|$|The {{panorama}} of consumer solutions available as plug-in or as standalone application includes also Noise Ninja [18] and Dfine [19]. Noise Ninja {{is a powerful}} software produced by the PictureCode LLC that removes chroma noise with an algorithm in the wavelet domain. It is a good trade-off between noise reduction and details preservation. The main feature {{is the ability to}} limit the introduction of edge blurring and <b>color</b> <b>bleeding,</b> which are defects not properly managed by conventional wavelets.|$|R
40|$|Direct volume {{rendering}} {{has become}} a popular method for visualizing volumetric datasets. Even though computers are continually getting faster, it remains a challenge to incorporate sophisticated illumination models into direct volume rendering while maintaining interactive frame rates. In this paper, we present a novel approach for advanced illumination in direct volume rendering based on GPU ray-casting. Our approach features directional soft shadows taking scattering into account, ambient occlusion and <b>color</b> <b>bleeding</b> effects while achieving very competitive frame rates. In particular, multiple dynamic lights and interactive transfer function changes are fully supported. Commonly, direct volume rendering {{is based on a}} very simplified discrete version of the original volume rendering integral, including the development of the original exponential extinction into a-blending. In contrast to a-blending forming a product when sampling along a ray, the original exponential extinction coefficient is an integral and its discretization a Riemann sum. The fact that it is a sum can cleverly be exploited to implement volume lighting effects, i. e. soft directional shadows, ambient occlusion and <b>color</b> <b>bleeding.</b> We will show how this can be achieved and how it can be implemented on the GPU...|$|R
40|$|Obscurances are a {{powerful}} technique that simulates diffuse illumination, i. e. radiosity, {{with a much}} lower cost. Its advantage is based in that it considers only neighbour interactions instead of considering global ones, and in being decoupled from direct illumination computation. In this paper we present an implementation of this technique on a 3 D game engine that allows realtime recomputation of obscurances for moving objects. Other extensions to deal with <b>color</b> <b>bleeding</b> and difficult lighting conditions are also discussed...|$|R
50|$|Greater Buffalo Press (GBP) {{developed}} and improved web-fed four color rotogravure technology, {{which was used}} to print color comic supplements inserted in Sunday newspapers, and color advertising inserts for daily and weekend newspapers. In four-color rotogravure printing, long rolls of newsprint are fed to the press four separate times, one for each color. The ability to align the feeds longitudinally and laterally is critical to quality control, as any misalignment results in color gaps, or <b>colors</b> <b>bleeding</b> to spaces they were not intended to cover. Its principal competitor was Waterbury, Connecticut's Eastern Color Printing.|$|R
40|$|The work {{described}} {{here is the}} second version of the Automatic Tricolor Cartograph (ATC). Phase one {{of the project was}} completed in 1968. At that time it was decided that certain improvements could and should be made on the machine. These improvements were (a) to alleviate a <b>color</b> <b>bleeding</b> problem, (b) to remove a moire pattern that plagued the display, and (c) to add shades of gray capability. The solution of these problems {{is the subject of this}} work. This work was supported, in part by Contract No. AEC AT(11 - 1) 146...|$|R
50|$|Most digital {{cinematography}} systems {{further reduce}} data rate by subsampling color information. Because the human visual system {{is much more}} sensitive to luminance than to color, lower resolution color information can be overlaid with higher resolution luma (brightness) information, to create an image that looks very similar to one in which both color and luma information are sampled at full resolution. This scheme may cause pixelation or <b>color</b> <b>bleeding</b> under some circumstances. High quality digital cinematography systems are capable of recording full resolution color data (4:4:4) or raw sensor data.|$|R
5000|$|Because {{of the low}} {{capacity}} of Game Boy Advance cartridges (ranging from 4 to 32 MB) {{and the length of}} the video content (generally feature-length movies and episodes), GBA Video Paks are heavily compressed, with visual artifacts marring nearly every frame. The image quality has a similar appearance to early Cinepak compression, and the [...] "quilting" [...] and <b>color</b> <b>bleeding</b> effect found in other compressed video formats is also present. Also, in cases where certain videos are available both as a 45-minute two-part episodes or a 22-minute edited version, the 22-minute version is used.|$|R
40|$|The Fluidic Lens Camera System {{provides}} an exciting {{opportunity for the}} Image Processing Community. Designed for a surgical envi-ronment, this camera has higher magnification and has better porta-bility than traditional laparoscopic cameras. From an image process-ing prospective, the fluid causes non-uniform blur of different color planes. While the green image is sharp, the red and blue images are blurred. Previous methods {{have been developed to}} separate out the edge and shading components of the green image and to use the edge information in green to replace the blurred blue edges. This al-gorithm succeed in most areas, however in some areas, color bleed-ing artifacts occurred. We restate this problem as a classification problem. Using the contourlet and wavelet coefficients as features, the proposed algorithm determines in what areas <b>color</b> <b>bleeding</b> will occur and does not apply the sharpening algorithm in these areas. By applying the previous contourlet method in areas where it suc-ceeds, we can produce an overall sharper image with reduced <b>color</b> <b>bleeding</b> artifacts. The ability to correctly classify when the previ-ous algorithm will succeed is crucial {{to the success of the}} algorithm. The principal application is medical imaging, however, the fields of satellite pan-sharpening and image denoising can benefit from the results found in this paper. Index Terms — Biomedical image processing, image enhance-ment, image reconstruction, image color analysis. 1...|$|R
40|$|Traditional global {{illumination}} lighting techniques like Radiosity and Monte Carlo sampling are computationally expensive. This {{has prompted}} {{the development of}} the Point-Based <b>Color</b> <b>Bleeding</b> (PBCB) algorithm by Pixar in order to approximate complex indirect illumination while meeting the demands of movie production; namely, reduced memory usage, surface shading independent run time, and faster renders than the aforementioned lighting techniques. The PBCB algorithm works by discretizing a scene’s directly illuminated geometry into a point cloud (surfel) representation. When computing the indirect illumination at a point, the surfels are rasterized onto cube faces surrounding that point, and the constituent pixels are combined into the final, approximate, indirect lighting value. In this thesis we present a performance enhancement to the Point-Based <b>Color</b> <b>Bleeding</b> algorithm through hardware acceleration; our contribution incorporates GPU-accelerated rasterization into the cube-face raster phase. The goal is to leverage the powerful rasterization capabilities of modern graphics processors in order to speed up the PBCB algorithm over standard software rasterization. Additionally, we contribute a preprocess that generates triangular surfels that are suited for fast rasterization by the GPU, and show that new heterogeneous architecture chips (e. g. Sandy Bridge from Intel) simplify the code required to leverage the power of the GPU. Our algorithm reproduces the output of the traditional Monte Carlo technique with a speedup of 41. 65 x, and additionally achieves a 3. 12 x speedup over software-rasterized PBCB...|$|R
40|$|Abstract. Achieving {{realistic}} or believable global illumination in {{scenes with}} participating media is expensive. Light {{interacts with the}} parti cles of a volume, creating complex radiance patterns. This paper in troduces an explicit extension to the commonly used point-based <b>color</b> <b>bleeding</b> technique which allows fast, believable in- and out-scattering ef fects building on existing data structures and paradigms. The proposed method achieves results {{comparable to that of}} existing Monte Carlo inte gration methods, that is realistic looking renders of scenes which include volume data elements, obtaining render speeds between 10 and 36 times faster while keeping memory overhead under 5 %. ...|$|R
40|$|We {{present an}} {{image-based}} algorithm for interactive rendering depth-of-field effects in images with depth maps. While previously published methods for interactive depth-of-field rendering suffer from various rendering artifacts such as <b>color</b> <b>bleeding</b> and sharpened or darkened silhouettes, our algorithm achieves a significantly improved image quality by employing recently proposed GPU-based pyramid methods for image blurring and pixel disocclusion. Due {{to the same}} reason, our algorithm offers an interactive rendering performance on modern GPUs and is suitable for real-time rendering for small circles of confusion. We validate the image quality provided by our algorithm by side-by-side comparisons with results obtained by distributed ray tracing...|$|R
40|$|Achieving {{realistic}} or believable global illumination in {{scenes with}} participating media is expensive. Light {{interacts with the}} particles of a volume, creating complex radiance patterns. This paper introduces an explicit extension to the commonly used point-based <b>color</b> <b>bleeding</b> technique which allows fast, believable in- and out-scattering effects building on existing data structures and paradigms. The proposed method achieves results {{comparable to that of}} existing Monte Carlo integration methods, that is realistic looking renders of scenes which include volume data elements, obtaining render speeds between 10 and 36 times faster while keeping memory overhead under 5 %...|$|R
5000|$|It is {{for this}} reason that each of the text and {{graphics}} modes described above exists twice: Once as the normal [...] "color" [...] version and once as a [...] "monochrome" [...] version. The [...] "monochrome" [...] version of each mode turns off the NTSC color decoding in the viewing monitor completely, resulting in a black-and-white picture, but also no <b>color</b> <b>bleeding,</b> hence, a sharper picture.On RGBI monitors, the two versions of each mode are identical, with the exception of the 320x200 graphics mode, where the [...] "monochrome" [...] version produces the third palette, as described above.|$|R
