14|249|Public
50|$|W1: is the <b>code</b> <b>figure</b> for {{forecast}} weather.|$|E
50|$|S: is the <b>code</b> <b>figure</b> for the {{forecast}} sea state.|$|E
50|$|D: is the <b>code</b> <b>figure</b> for the {{forecast}} {{direction of the}} wind.|$|E
40|$|This work {{deals with}} {{localization}} and decoding of the linear barcode EAN- 13 in the image. It describes types and qualities of barcodes and pose posibble accesses into the localization and decoding. The practical part concerns {{with the concept}} {{and implementation of the}} algorithm having regard to effectiveness for processing in real time. The localization is established on finding similar features of the barcode among the read rows of the image and decoding is made by finding of the supreme conformity towards referential <b>code</b> <b>figures...</b>|$|R
3000|$|... [...]. If this {{condition}} holds, {{as for the}} WLAN LDPC <b>codes</b> (see <b>Figure</b> 11), it can be worth reversing the output order of SOs so that the messages in [...]...|$|R
40|$|Codes {{with various}} kinds of decipherability, weaker than the usual unique decipherability, have been studied since multiset decipherability was {{introduced}} in mid- 1980 s. We consider decipherability of directed <b>figure</b> <b>codes,</b> where directed <b>figures</b> are defined as labelled polyominoes with designated start and end points, equipped with catenation operation that may use a merging function to resolve possible conflicts. This is one of possible extensions generalizing words and variable-length codes to planar structures. Here, verification whether a given set is a code is no longer decidable in general. We study the decidability status of <b>figure</b> <b>codes</b> depending on catenation type (with or without a merging function), decipherability kind (unique, multiset, set or numeric) and code geometry (several classes determined by relative positions of start and end points of figures). We give decidability or undecidability proofs in all but two cases that remain open. Comment: Preliminary, short {{version of this paper}} appeared in IWOCA 2012 proceedings volume as M. Kolarz and W. Moczurad, Multiset, set and numerically decipherable <b>codes</b> over directed <b>figures,</b> in Springer's LNCS vol. 7643, pp. 224 - 23...|$|R
5000|$|... 2: {{identifies}} {{the group as}} a supplementary group. The 2 group is valid for the same period as the group that immediately precedes it.V: is the <b>code</b> <b>figure</b> for the forecast visibility.|$|E
5000|$|... 1GDFmW11: is an {{identifying}} number required by international practice. Each code group following {{the name of}} the lake will begin with 1.G: is the <b>code</b> <b>figure</b> for the period of time covered by the forecast given in the group.|$|E
40|$|We {{performed}} large-eddy {{simulations of}} the flow over a typical two-dimensional dune geometry at laboratory scale (the Reynolds number based on the average channel height and mean velocity is 18, 900) using the La-grangian dynamic eddy-viscosity subgrid-scale model [1, 2]. The govern-ing differential continuity and Navier-Stokes equations are discretized on a nonstaggered grid using a second order {{in time and space}} curvilinear finite-volume <b>code.</b> <b>Figure</b> 1 : Sketch of the physical configuration. Every fourth grid line is shown. The computational configuration is sketched in Figure 1. Periodic bound-ary conditions are used in the streamwise (x) and spanwise (z) directions. At the free surface, the wall normal velocity is set to zero, as are the vertical 1 a...|$|E
3000|$|... = 2, ∀l, and in [20] for L = 1 and N 1 ≥ 2 with {{analog network}} <b>coding</b> transmission. <b>Figure</b> 1 c shows {{an example of}} MGMW {{relaying}} using the multicasting strategy when L = 2 and N 1 = N 2 = 3 nodes.|$|R
40|$|This archive {{contains}} data generated {{as part of}} the AudioCommons project. Data {{relate to}} Deliverable D 5. 1 [Pearce et al. 2016] which: (i) generated a hierarchy of terms describing the timbral attributes of audio; (ii) determined the search frequency for each of these terms on the www. freesound. org audio database. Data comprise excel and csv files, Python <b>code,</b> <b>figures</b> and documentation. This research made use of data from Deliverable D 2. 1 [Barthet et al. 2016]. References M. Barthet, G. Fazekas, D. Juric, J. Pauwels, M. Sandler., L. Vetter, “Deliverable D 2. 1 : Requirements Report and Use Cases”, AudioCommons Deliverable Report, June 2016 - [URL] A. Pearce. T. Brookes, R. Mason, "Deliverable D 5. 1 Hierarchical ontology of timbral semantic descriptors", AudioCommons Deliverable Report, August 2016 - [URL]...|$|R
30|$|HDF {{consists}} of MAC stage when both terminals transmit simultaneously to the relay with exclusively coded data decoding and broadcast (BC) stage when the relay broadcasts the exclusively <b>coded</b> data, <b>Figure</b> 1 c). The exclusive code (XC) permits message decoding at the terminals {{using their own}} messages serving as a complementary-side information [7].|$|R
40|$|Fig. 4. Bayesian {{consensus}} {{trees of}} COI (A), Cytb (B) and concatenated sequences of 28 S and LW Rh (C) for Proformica workers from southern France and outgroups. Labels {{are composed of}} the locality name, the colony <b>code</b> (<b>figure),</b> the code of the individual (w 1 for worker 1, w 2 for worker 2) and, for COI, the primer pair used (Ci for CI 13 and CI 14, Lep for LepF 1 and LepR 1). Sequences where a stop codon was detected are labelled with a red " STOP ". Sequences with an asterisk specify individuals for which another sequence was obtained and fitted outside the clade of putative numts. Colours match the groups defined in the morphological analysis. Posterior probabilities are given for major nodes. Accession numbers are indicated for sequences retrieved from GenBank...|$|E
40|$|We present Brian, a new clock driven {{simulator}} for spiking {{neural networks}} which is available on almost all platforms. Brian is easy to learn and use, highly flexible and easily extensible. The Brian package itself and simulations using it are all written in the Python programming language, which is very well adapted to these goals. Python is an easy, concise and highly developed language with many advanced features and development tools, excellent documentation and a large community of users providing support and extension packages. Brian allows you to write very concise, natural and readable code for simulations, and makes it quick and efficient to play with these models (for example, changing the differential equations doesn't require a recompile of the <b>code).</b> <b>Figure</b> 1 shows {{an example of a}} complete network implemented in Brian, a randomly connected network of integrate and fire neurons with exponential inhibitory and excitatory currents (the CUBA network from [1]). Defining the model, running Brian in actio...|$|E
40|$|TSFOIL 2 is a {{solution}} of the transonic small disturbance theory equations. It will run on PCs or a MAC and provides useful results, although Euler solutions are preferred if {{you have access to}} that level of code. The method obtains the solution by solving a set of coupled nonlinear algebraic equations. As such, the process does not necessarily converge, and the convergence history must be examined before accepting the results as valid. It is entirely possible to specify a Mach number and angle of attack which causes the iterative process to diverge. The program typically computes the solution on a sequence of progressively finer meshes. It is the convergence history on the final mesh that is important. The references given below should be studied to obtain a full understanding of the theory and use of the <b>code.</b> <b>Figure</b> 1 shows the agreement obtained between TSFOIL 2 and a full potential code, FLO 36. Comparison of solution from FLO- 36 (full potential) and TSFOIL 2 (small disturbance) NACA 0012 airfoi, M = 0. 75, a = 2...|$|E
3000|$|For our XORs <b>coding,</b> {{from the}} <b>figure,</b> {{we know that}} the energy {{consumption}} with sleep scheduling is less than that without sleep scheduling when [...]...|$|R
3000|$|In this paper, the rate- 1 RSC <b>code</b> in <b>Figure</b> 1, {{we choose}} {{is a simple}} repeat-accumulate (RA) code with {{transfer}} function 1 /(1 +D) and memory length 1. The ‘doping’ rate is set to be 1 / 60, i.e., 59 info-bits and 1 parity-bit within a doping period [21]. The packetization rule is set as N [...]...|$|R
40|$|CompHEP is {{a package}} for {{automatic}} calculations of elementary particle decay and collision {{properties in the}} lowest order of perturbation theory (the tree approximation). The main idea prescribed into the CompHEP is to make available passing on from the Lagrangian to the final distributions effectively {{with a high level}} of automation. Comment: 126 pages (standard LaTeX <b>code),</b> 14 <b>figures,</b> misprints improve...|$|R
40|$|OpenFlow [4] {{has been}} {{demonstrated}} {{as a way for}} researchers to run networking experiments in their production network. Last year, we demonstrated how an OpenFlow controller running on NOX [3] could move VMs seamlessly around an OpenFlow network [1]. While OpenFlow has potential [2] to open control of the network, only one researcher can innovate on the network at a time. What is required is a way to divide, or slice, network resources so that researchers and network administrators can use them in parallel. Network slicing implies that actions in one slice do not negatively affect other slices, even if they share the same underlying physical hardware. A common network slicing technique is VLANs. With VLANs, the administrator partitions the network by switch port and all traffic is mapped to a VLAN by input port or explicit tag. This coarse-grained type of network slicing complicates more interesting experiments such as IP mobility or wireless handover. Here, we demonstrate FlowVisor, a special purpose OpenFlow controller that allows multiple researchers to run experiments safely and independently on the same production OpenFlow network. To motivate FlowVisor’s flexibility, we demonstrate four network slices running in parallel: one slice for the production network and three slices running experimental <b>code</b> (<b>Figure</b> 1). Our demonstration runs on real network hardware deployed on our production network 1 at Stanford and a wide-area test-bed with a mix of wired and wireless technologies...|$|E
40|$|The super proton synchrotron, SPS {{is used as}} LHC injector, {{but also}} to {{accelerate}} and extract protons and ions for fixed target experiments and for producing neutrinos (CNGS). In particular the risks during the fast extraction of LHC and CNGS beams must be considered since any failure during this process can lead to serious equipment damage. When the SPS operates as LHC injector, up to 288 bunches are accelerated, each bunch with about 1. 1 × 10 11 protons. The bunch length is 0. 5 ns and two neighboring bunches are separated by 25 ns so that {{the duration of the}} entire beam is about 7 µs. The beam focal spot size (σ) in this case is 0. 88 mm. When the SPS is used as a collider,σ is of the order of 0. 06 mm. To assess the damage caused by full impact of the SIS beam we have simulated hydrodynamic and thermodynamic response of solid copper and tungsten cylindrical targets that are facially irradiated by the beam. These simulations have been carried out using a two-dimensional computer code, BIG- 2. Three different values for the beam focal spot, namely, with σ = 0. 088 mm, 0. 28 mm and 0. 88 mm have been considered. The energy deposition of 450 GeV protons in the SPS beam has been calculated using the FLUKA <b>code.</b> <b>Figure</b> 1 shows specific energy deposition vs target length along the beam axis for the three values of beam spot size. In Figs. 2 – 3 we plot the temperature, pressure and density vs target radius at the point of maximum energy deposition along the target length {{at the end of the}} pulse...|$|E
40|$|This report {{provides}} {{results of}} a Micrometeoroid and Orbital Debris (MMOD) risk assessment of the Mars Sample Return Earth Entry Vehicle (MSR EEV). The assessment was performed using standard risk assessment methodology illustrated in Figure 1 - 1. Central to the process is the Bumper risk assessment <b>code</b> (<b>Figure</b> 1 - 2), which calculates the critical penetration risk based on geometry, shielding configurations and flight parameters. The assessment process begins by building a finite element model (FEM) of the spacecraft, which defines {{the size and shape}} of the spacecraft as well as the locations of the various shielding configurations. This model is built using the NX I-deas software package from Siemens PLM Software. The FEM is constructed using triangular and quadrilateral elements that define the outer shell of the spacecraft. Bumper-II uses the model file to determine the geometry of the spacecraft for the analysis. The next step of the process is to identify the ballistic limit characteristics for the various shield types. These ballistic limits define the critical size particle that will penetrate a shield at a given impact angle and impact velocity. When the finite element model is built, each individual element is assigned a property identifier (PID) to act as an index for its shielding properties. Using the ballistic limit equations (BLEs) built into the Bumper-II code, the shield characteristics are defined for each and every PID in the model. The final stage of the analysis is to determine the probability of no penetration (PNP) on the spacecraft. This is done using the micrometeoroid and orbital debris environment definitions that are built into the Bumper-II code. These engineering models take into account orbit inclination, altitude, attitude and analysis date in order to predict an impacting particle flux on the spacecraft. Using the geometry and shielding characteristics previously defined for the spacecraft and combining that information with the environment model calculations, the Bumper-II code calculates a probability of no penetration for the spacecraft...|$|E
40|$|Data, <b>Code,</b> and <b>Figures</b> for "Global {{patterns}} and impacts of El Niño events on coral reefs: a meta-analysis" Danielle C. Claar 1, Lisa Szostek 1, Jamie M. McDevitt-Irwin 1, Julian J. Schanze 2, Julia K. Baum 1 1 Department of Biology, University of Victoria, Victoria, British Columbia, Canada 2 Earth and Space Research, Seattle, Washington, United States of America In Press at PLOS On...|$|R
40|$|Can we use {{the past}} to predict the future? Moore’s Law is a great example: {{performance}} doubles and prices halve approximately every 18 months. This trend has held up well to {{the test of time}} and is expected to continue for some time. Similar arguments can be found in speech demonstrating consistent progress over decades. Unfortunately, there are also cases where history repeats itself, as well as major dislocations, fundamental changes that invalidate fundamental assumptions. What will happen, for example, when petabytes become a commodity? Can demand keep up with supply? How much text and speech would it take to match this supply? Priorities will change. Search will become more important than <b>coding</b> and dictation. <b>Figure</b> 1 : Moore’s Law 1. Progress as a function of time Moore’s Law (Figure 1) uses past performance to predict future capability in a very convincing way. Figure 2 [1] demonstrates consistent progress in speech <b>coding.</b> <b>Figure</b> 3 [2] makes a similar argument for speech recognition; see [3] for predictions of where the field will go over the next 10 years. We have grown accustom under Moore’s Law to incredible improvements in disks, memory, CPU cycles, network bandwidth, etc. Performance doubles and prices halve every 18 months or so. The time constant varies considerably depending on physical limitations, market forces and other factors. Disk capacities, for example, have improved faster than disk seek times because of physical limitations. Market forces account for the dramatic improvements in PCs. PCs are not only cheaper than supercomputers, but ironically, they can be faster as well...|$|R
40|$|Figure 1. Distribution and Sampling Locations of Different Giraffe Subspecies in Africa (A) Distribution ranges (colored shading) {{provided}} by the Giraffe Conservation Foundation [7], plotted on a map of Africa ([URL] // www. naturalearthdata. com /). Circles represent sampling locations; for <b>coding,</b> see <b>Figure</b> 2. (B) Enlarged view of the South Sudan region. Note that the samples of the putative Nubian giraffe were taken west and east of the Nile River. See also Table S 1...|$|R
40|$|International audienceEXTENDED ABSTRACT In typical {{large-scale}} scientific applications, several {{parameters of}} complex computational models {{have to be}} predefined in a simulation, each {{with a wide range}} of possible values. Listing all possible combinations of parameters and exhaustively trying them all is nearly impossible even in extreme-scale High Performance Computing (HPC). There may be a huge number of possible combinations and processing each one may take several hours or days, making the whole computation last for weeks or months. Typically, after the initial set ups, the scientist starts the computation and occasionally fine-tunes specific parameters based on intermediate result analysis. The term " human-in-the-loop " is used when computational scientists can actively participate in the computational process. Specific adaptations can generate an important improvement on performance, resource consumption, and quality of results [2]. To allow for online human adaptation, dynamic workflow solutions are required. Most existing workflow solutions do not allow for online human adaptations, which is considered a future research challenge in a recent survey [4]. Chiron[3], WorkWays [7], and Copernicus [8] are a few exceptions that allow for online data adaptation. Parameter tuning – the subject of research of this work – is only one among many other types of adaptations possible in human-adapted workflows in HPC [6]. Registering the adaptations is essential to track and analyze the effects of fine-tunings. In [1], the authors discuss past, present and future of scientific workflows, and as a future issue they mention that "monitoring and logging will be enhanced with more interactive components for intermediate stages of active workflows. " We did not find any work that registers workflow adaption in logs or in provenance databases. This work aims at capturing and registering such human adaptation data (e. g., values before and after a specific parameter fine-tuning; reason for the tuning), relating them with other relevant data (e. g., domain-specific strategic values and execution data), and allowing all these data to be efficiently integrated. This contributes for online data analysis and data-driven decisions (e. g., how a specific user action impacted the processing time), helping to put humans in the online loop of large-scale scientific computing. Also, recording those adaptations contributes to the results' reliability and reproducibility. We developed DfAdapter [5], a tool that collects human adaptations in the dataflow, while the workflow runs. It controls and stores specific parameter-tunings in a provenance database, relating the human adaptation data with data for: domain, dataflow provenance, execution, and performance. As shown in Figure 1, initially DfAdapter registers the user Bob, who is going to adapt the dataflow; then it registers identifiers of the current state of the workflow (e. g. step i of the loop). To track the tunings, it receives from Bob the set of parameters, e. g. attr 5 to be modified to "val 5 " into Dataset 2. Then, DfAdapter modifies the values in Dataset 2. Finally, it registers the iteration counter, the execution state at the adaptation moment, the dataset, values before and after, and the current wall-time all in the provenance database. Relevant insight is obtained with visualizations complemented by tracking queries like: "List all Bob's tunings correlating with time step" or "Avg. of values 10 iterations before DfAdapter can be coupled to a workflow and after the tunings". managed by a parallel workflow management system or by a workflow defined using an HPC library, or even a script. DfAdapter works as a debugging tool on an instrumented <b>code.</b> <b>Figure</b> 1. Tuning parameters in a dataset in a dataflow...|$|E
40|$|Authors: Massmiliano Cavallini, Denis Gentili, Pierpaolo Greco, Francesco Valle & Fabio Biscarini ### Abstract This {{protocol}} {{provides the}} instructions for designing and fabricating stamping tools with features ranging from nanometer to micrometer scale, including the fabrication using commercial tools such as compact disks or digital video disks. In particular the reported procedures are oriented towards the tools fabrication for lithographically controlled wetting and soft lithography. Because the versatility of these methods that has almost no restrictions concerning the materials used for the stamps, {{a wide range of}} methods are provided in this protocol including photolithography, electron beam lithography, replica molding, laser engraving and nanoimprinting. ### Introduction **GENERAL INFORMATION** **PHOTOLITHOGRAPHY** Presently the most common method to fabricate rigid stamps (usually in silicon) and masters required for replica molding of the soft stamps is photolithography (see the protocol in ref. (1)). This process, widely used for microfabrication, is based on the selective removing of parts of a film upon the exposition to light (usually UV). This is achieved thanks to some materials known as photoresists, that are light-sensitive, meaning that, according to their composition, they become soluble or insoluble to their developing solution upon illumination. The first family is called positive photoresist and the second negative. The light is sent through a photomask that shadows the parts of the film that, according to the kind of resist used, must be removed or preserved. Different kind of masks can be used but their common feature is the ability to shadow as much as possible some parts of the photoresist below (contrasting power), the most used are transparent foils with pattern drawn by an ink non-transparent to UV-light or highly reflecting foils (usually metallic) where some portion have been removed by laser engraving. The current limits of photolithography is approximately 250 nm and the minimum feature size is 100 nm (2). These values are important on the one hand to define the ranges of fabrication of soft stamps for LCW {{but on the other hand}} for the forthcoming comparison with the feature sizes and resolution that LCW can achieve. The masks are usually drawn using CAD software and then transferred either by common printers on transparent foils, where the marks will represent the shadowed areas, or by laser engraving of highly reflective metallic sheets where the removed part will corresponding to the illuminated path. The photoresist film, upon illumination is then developed in the appropriate solution leaving on the surface only the features that will be used as master for replica molding or directly as stamp. **ELECTRON BEAM LITHOGRAPHY** When the resolution limits required by the process are below those of photolithography (diffraction limit), electron beam lithography (EBL) is usually chosen for fabricating the masters. This technique is in fact able to achieve resolution of 20 - 30 nm in lateral size (see the protocol in ref. (1)), because it make use of an electron beam to locally alter the chemical properties of a material (resist) that will be then removed in a development step. Beside the illustrated resolution advantage one must remind that EBL is an expensive technology and it is a serial technique, thus it is much slower than photolithography. **REPLICA MOLDING** Replica molding (RM) is the most common way of fabricating the elastomeric stamp for soft lithography and LCW and it is one of the most important tools for these techniques. RM is based on the reticulation of the elastomeric precursors onto the master that is then removed, upon curing, by peeling it off. It is worth mentioning that the LCW is not limited to the elastomeric materials as other soft-lithographic methods and it makes wide use of rigid and metallic materials as it is shown other sections of this protocol. Nevertheless replica molding of the elastomeric materials still plays a crucial role because, making use of well known materials such as Polydimethylsiloxane (PDMS), it allows tuning the surface properties of the stamp by liquid or plasma chemical treatments. Elastomeric stamps made of PDMS are deformed easily under the effect of capillary adhesion. The attractive force, exerted by the solution trapped between the substrate and the stamp, may involve sagging of the PDMS stamp and poor patterning in the region where the PDMS displaced the solution. The capillary force may be estimated according to De Gennes,(3) and needs to be considered during the design of the spacer and the dimensioning of the full PDMS replica. In this case, an effective parameter is the aspect ratio AR, defined as the ratio of width over thickness of the window delimited by the spacer. If we put PDMS Young modulus E ≈ 460 kPa, contact angle of solution θ = π/ 6, and surface tension γ = 0. 02 N/m (organic solvents), we derived the critical value for AR that will induce sagging for various distances between the substrate and the PDMS replica, by finite element calculation (Figure 1). The empirical relationship can be summarized with a linear abacus for fast design, providing that the overall dimension of the stamp is exceeding the window defined by the spacer. **NANOIMPRINT LITHOGRAPHY** Nanoimprint lithography (NIL) is another important technique useful to fabricate tools (i. e. master for RM and stamps) for LCW. NIL consists of a physical (morphological) deformation of a thermoplastic material in a temperature and pressure controlled printing process. A silicon stamp fabricated by a conventional lithography such as EBL or photolithography is usually employed. In NIL the thermoplastic material (usually a polymer) is deformed by pressing the stamp into the polymer at a temperature above the polymer’s glass-transition temperature. The polymer is then cooled down below the glass-transition temperature and the stamp is removed. **VACUUM SUBLIMATION OF METALS** One of the advantages of LCW is the versatility with respect to the material of the stamp used for patterning. In this frame, a role is played also by metallic stamps, some of them (gold for instance) can be functionalized using thiol based Self Assembled Monolayers (SAM) to tune their surface properties. These stamps are usually fabricated by vacuum sublimation of a thin metallic layer on a master previously realized by one of the above mentioned techniques. For some substrates such as silicon or mica an adhesive layer (usually made of chromium or titanium) has to be previously evaporated on the underlying material to favour the stability of the metallic film. **COMMERCIAL AVAILABLE MASTER/STAMPS** Commercial metallic grids commonly used for Electron Microscopy experiments have proven to be very suitable for as a stamp for LCW (See Fig 2). When the grid comes as a large sheet that must be cut, it is crucial to cut it with very sharp scissors to avoid large deformations of the areas near the cut. For the most kind of patterning inexpensive masters such as Compact Disc (CD) Digital versatile disk (DVD) or diffraction gratings are commercially available. This kind of devices are made of: Blank CD, parallel stripes 1. 5 µm pitch, 500 nm width and 220 nm depth. Blank DVD, parallel stripes with 750 µm pitch, 300 nm width and 110 nm depth. Written disks contain a pattern o doth and line with the same size containing an information in digital (binary) <b>code.</b> <b>Figure</b> 3 shows typical AFM images CD and DVD masters. ### Reagents 1. Photoresists SU- 8 - SU- 8 developer 1 -Methoxy- 2 -propanol acetate - PolyMethylMethacrylate (PMMA) (Allresist, AR-P 679. 01) - Sylgard 184 silicone elastomer base and Sylgard 184 elastomer curing agent  (Dow Corning). CRITICAL Sylgard 184 is a thermal curable elastomer, which is provided as a two-component kit consisting of the base and the curing agent. The standard ratio between base and the curing agent 1 : 10 small variation led to adjust the softness of cured elastomer (higher value of 10 % led more rigid stamp). Use glove powder-free for these operations. - Ethanol (Sigma-Aldrich, cat. no. 459836) - Hydrogen peroxide (Sigma-Aldrich, cat. no. 216763) - Sulfuric acid (Sigma-Aldrich, cat. no. 320501) - Masks (supplier Toppan inc.) **REAGENT SETUP** - Piranha solution 3 : 1 mixture of concentrated H 2 SO 4 and H 2 O 2 (30 % vol/vol). Add very slowly and mix with a glass rod one volume of H 2 O 2 to three volumes of H 2 SO 4 in a clean beaker whose volume is at least 10 times the volume of the final solution. - CRITICAL Piranha solution  must be prepared fresh and cooled to room temperature before use. - ! CAUTION Keep attention because there are exothermic processes involved when you add the hydrogen peroxide to the sulphuric acid. Piranha solution can reacts violently with organic compounds, is very aggressive to skin, and should be handled with care. It is important to work in a fume hood and wear personal protective clothing (e. g., nitrile or latex gloves, lab coat, safety glasses) when handling solutions and keep away from organic chemicals ### Equipment 1. IR fiber laser marker (for metallic photomask engraving e. g., LaserPoint, Marko 10 P) - Laser marker IR 1064 nm - Spin coater (for the application of thin films of resists, e. g., Laurell ws- 650 - 6 NNP/Lite) - UV mask aligner (for photolithography, e. g., Karl Suss, Mask Aligner MJB 4) - Electron-beam writer (for e-beam lithography, e. g., SEM-FEG Hitachi S 4000 with Nabity NPGS e-beam source) - Vacuum line (for removal of bubbles) - Hotplates (for baking resist films and surface cleaning, e. g., MR Hei-Standard, Heidolph) - Nitrogen gas line (for drying stamps and substrates) - Precision hydraulic press (for imprint semirigid stamps, e. g, PW 20, P/O Weber) - Ultrasonic cleaner (for surface cleaning, e. g., Elmasonic S 30 H) - System for metal vacuum sublimation (for preparing supported thin films of gold or, e. g., EDUARS System) - Optical microscope (for characterizing patterns on masters and stamps at the microscale, e. g., Nikon Eclipse 80 i) - Scanning electron microscope (SEM, for characterizing patterns on masters and stamps at both micro- and nanoscale, e. g., SEM-FEG Hitachi S 4000) - Atomic force microscope (AFM, for characterizing patterns on masters and stamps at both micro- and nanoscale, e. g., NT-MDT NTEGRA). ### Procedure Photolithography: fabrication of masters and rigid stamps - TIMING 1 - 3 days Follow protocols in refs. (1),(4),(5) or: 1. Design the masks by CAD or other vectorial graphic software. - CRITICAL STEP Define properly the distances and geometry of the stamp to prevent sagging using soft stamps. - Photomask fabrication: - A. for low-resolution mask (feature size > 20 µm), print by a high-resolution printer the features on transparent plastic sheet. - B. for high-resolution mask (feature size 10 µm 500 µm thick of polycarbonate in between the plate of a press. A thickness ranging between 0. 5 mm and 1 mm are ideal for an easy manipulation by tweezers normally the flat side of commercial CD or DVD can work properly (Note the unpatterned side of CD or DVD can properly work). - Place the master on top of the polycarbonate foil with the features in contact with the polymer. - Put the plates of the press in contact, sandwich the polycarbonate and master and apply a low pressure 50 nm of Au taking the crucible at a temperature suitable for a rate < 1 nm/min. (thickness ranging between 50 and 100 nm offer adequate protection of the polymer without alter the stamp features) the sample must kept at room temperature. Monitor the growth rate by the quartz microbalance (a quartz microbalance tool is usually present in each commercial metallization system). - CRITICAL POINT the metallization take all polymers impermeable to the solvent, thus in some case it changes the result of your patterning. Metallic grids and masks fabrication - TIMING 1 - 2 days 1. Design the masks by CAD or other vectorial graphic software. - Take a metallic foil thick enough to be self standing, aluminium is the most suitable and easier to find as a commercial product, and let it adhere well and uniformly onto a glass support or onto any other material that is flat and transparent to IR light. - Place the metal+support onto the scanner of a IR marker and start writing (Note: the laser intensity and the focus of the beam will define the size of the feature where metal is removed). - CRITICAL POINT Tuning the laser intensity one has to pay attention to avoid the formation of rims of metal on the border of the engraved areas and to tune the speed of the laser to have the borders of the features as much as possible uniform. - Detach the metallic foil from the support and use this mask for PRINTING. Metallized stamp from blank CD - TIMING 20 min 1. Rinse the label layer of the blank CD with ethanol and dry in a stream of nitrogen for 60 s. - Rinse the solid substrate (e. g., glass, silicon wafer) with ethanol and dry in a stream of nitrogen for 30 s. - Stick a double-sided tape on the solid substrate and use a razor blade to remove the tape in excess. - CRITICAL STEP it is important to use a double-sided tape compatible with the solvent used in the next steps. - Stick the substrate on the label layer of the blank CD using the second adhesive layer of the tape and press down with hand to achieve a homogeneous contact. Use a razor blade to cut the label layer of the blank CD along the edges of the substrate. - Peel off the substrate with the metal layer of the blank CD carefully with the aid of a flat head tweezers. - CRITICAL STEP it is important to peel off the substrate slowly to prevent the breaking of the metal layer. - Rinse the metallic side of the blank CD with ethanol to remove the organic dye and dry in a stream of nitrogen for 30 s. Soft stamp from blank CD - TIMING 8 h 1. Peel-off the label (and metallic) layer of the CD from its polycarbonate layer using an adhesive tape. - CRITICAL STEP To facilitate this step, make a little scratch on the border of the label layer with a razor blade. - Rinse the polycarbonate layer of the blank CD with ethanol to remove the organic dye and dry in a stream of nitrogen for 60 s. - Follow fabrication of soft stamp using the polycarbonate side of the CD as master. (Note to achieve stamps with a thickness in the range of 0. 3 - 0. 5 cm use 25 g of mixture for single CD). - CRITICAL STEP It is important to peel off the substrate slowly to prevent the breaking of the metal layer. Metallized stamp from Digital Video Disc (DVD) - TIMING 10 min 1. Separate the two polycarbonate layers of the DVD using spatula and robust tweezers.  CRITICAL STEP It is important to separate the substrates slowly to prevent the breaking of the metal layer. 2. Rinse the metallic layer of the blank DVD with ethanol to remove the organic dye and dry in a stream of nitrogen for 60 s. 3. Cut the metallic layer supported on polycarbonate with a razor blade into stamps with the desired dimensions. Soft stamp from diffraction grating - TIMING 8 h 1. Rinse the diffraction grating with the proper solvent and dry in a stream of nitrogen for 60 s. - CRITICAL STEP It is important to use a solvent that does not damage the diffraction grating. - Follow fabrication of soft stamp using the diffraction grating as master. ### References 1. Qin, D., Xia, Y. N. & Whitesides, G. M. ...|$|E
50|$|In the 1920s Rudolf Laban, in {{collaboration}} with colleagues, developed a notation system {{that could be used}} to describe movement in terms of spatial models and concepts. This contrasts with other movement notation systems based on anatomical analysis, letter <b>codes,</b> stick <b>figures,</b> music notes, foot tracks or word notes. The system precisely and accurately portrays temporal patterns, actions, floor plans, body parts and a three-dimensional use of space. Laban's notation system eventually evolved into modern-day Labanotation and Kinetography Laban.|$|R
40|$|This paper {{summarizes}} {{recent research}} on {{functions of the}} cochlea of the inner ear. The cochlea is described as {{the seat of the}} first step in the auditory sound analysis and transduction of mechanical vibration into electrochemical processes leading to the generation of neural action potentials. The cochlea is also described as a frequent seat of auditory disorders. This research summary addresses findings concerning: the classical model of cochlear functioning developed by ter Kuile and modified by H. Davis; explanations for the sharp tuning and great sensitivity of the auditory nerve fibers and inner hair cells; the role of the outer hair cells in cochlear acoustic emissions; contradictions of the classical model of hair cell stimulation posed by evidence for the depolarization of the hair cells during basilar membrane displacement; effects of removing the outer hair cells; possible mechanisms for hair cell depolarization; increased damping of th. i cochlea at high sound intensities; and the nature of the cochlear pitch <b>code.</b> <b>Figures</b> and graphs illustrate these findings. Contains 49 references. (DB) Reproductions supplied by EDRS are the best that can be made from the original document. U 5 DEPARTMENT CF EDUCATION Office of Evfof atonal Research and onolkwfmen...|$|R
3000|$|To {{illuminate}} {{how well}} short PA codes perform on correlated channels, we {{compare them with}} turbo codes (which are the best-known codes at short <b>code</b> lengths) in <b>Figure</b> 5. The comparing turbo code has 16 -state component convolutional codes whose generator polynomial is [...]...|$|R
40|$|This master thesis {{presents}} {{a collection of}} tools for solving partial differential equations using Python. Three different Python modules make {{up the majority of}} the thesis. When solving partial differential equations using the finite difference method, the resulting code can get quite complicated, for instance when trying to solve a 3 D wave equation with a variable diffusion coefficient. Fdmgen is a Python module that helps solving such equations by generating the code for the difference schemes based on keyword arguments. The code that is output from Fdmgen supports several programming languages. Ptex 2 tex is a tool developed for simplifying writing documents based on your research. By dynamically including source <b>code,</b> <b>figures,</b> and the result of running computer programs on the commandline, we avoid having to do this work manually, with the errors often resulting from such manual work. Ptex 2 tex generates LaTeX environments based on configuration files and keywords in the text. Latexslides allows you to generate presentation slides using Python. It supports several backends, currently Prosper LaTeX, Beamer LaTeX, and HTML. Additional backends can be added as they become available. The LaTeX code is generated by using instances of various Python classes, requiring the knowledge of programming Python...|$|R
40|$|That {{the workers}} and working life {{should have been a}} regular topic of {{representation}} in East German film, documentary film in particular, is no surprise given the significance of the worker in the state's self-understanding as the ‘first socialist state on German soil’. This article considers the role of the worker in East German film before focusing on those directors whose representations of workers either directly challenged or subtly undermined the state's preferred presentation. While many films used the worker in order to legitimise the state as the dictatorship of the proletariat and to promote a worker's consciousness in the German Democratic Republic, some filmmakers were more interested in de-anonymising their subjects, looking past the working environment to portray the worker as an individual, not an ideologically <b>coded</b> <b>figure.</b> The article looks in particular at a selection of films made by Jürgen Böttcher, including Drei von vielen/Three of Many (1960), Stars (1963) and Rangierer/Shunters (1981), and argues that some of Böttcher's portraits are simultaneously sympathetic and subversive, looking at both form (audiovisual composition) and content (in particular his focus on leisure, on individualism). Finally, I argue that the later films demonstrate the politics of silence and reflect on the implications of abandoning both voiceover and minimising dialogue...|$|R
30|$|The first type {{of fixed}} charge {{is the one}} that is closest to what in Spanish law we call hipoteca (which is a derecho real, a real right). It is {{regulated}} by articles 1874 et seq of the Spanish Civil <b>Code.</b> The <b>figure</b> is close to the hypothèque in French law (articles 2393 et seq of the French Civil Code). When there is a hipoteca or equivalent figures, the ownership of the property remains to the buyer, but there is a charge over that property right which disappears only when the loan has been repaid.|$|R
5000|$|After {{decades of}} social {{democratic}} governments, the Swedish children's author Astrid Lindgren faced an infamous marginal tax rate of 102% in 1976, in effect creating a wage ceiling. Though the example was {{partly due to}} inverted loop holes in the tax <b>code,</b> the <b>figure</b> {{was seen as an}} important catalyst for the results in the election that year, in which the Social Democratic Party lost power after 40 consecutive years in power. After a [...] "tax rebellion" [...] and demanded the top marginal tax rates were reduced to 50% in the late 1980s.|$|R
5000|$|The most {{distinctive}} characteristic of Chingichngish beliefs concerned {{the existence of}} a set of [...] "Chingichngish avengers" [...] who spied on human beings and enforced the moral <b>code.</b> These <b>figures</b> included Raven, Rattlesnake, Bear, Mountain Lion, and others. There were also ceremonial items sacred to Chingichngish, including mortars and winnowing trays. Chingichngish beliefs were associated with the initiation ceremonies for adolescent boys, during which the hallucinogenic plant Datura (Toloache, Jimsonweed, Datura wrightii) was ingested, but elements of these ceremonies were much more widely shared than were belief in the specific character of Chingichngish.|$|R
40|$|Figure 1 - Bayesian tree {{based on}} the COI dataset. The three clades (A–C) {{containing}} Rogue-Umpqua haplotypes are color <b>coded</b> as in <b>Figure</b> 2. Posterior probabilities for nodes are shown when > 95 %. Specimen codes are from Suppl. material 1; Rogue-Umpqua haplotype codes (in parentheses) are from Suppl. material 2...|$|R
40|$|In {{linguistic}} morphology {{and information}} retrieval, stemming {{is the process}} for reducing inflected (or sometimes derived) words to their stem, base or root form; generally a written word form. In this work is presented suffix stripping stemmer for Serbian language, one of the highly inflectional languages. Comment: 16 pages, 8 <b>figures,</b> <b>code</b> include...|$|R
