3|1264|Public
5000|$|A third 320&times;200 4-color palette is {{achieved}} by disabling the composite color burst bit while in graphics mode. This is what IBM BIOS Mode 5 does, as described above. This switches the current color palette to red, cyan, white and the background color. The intense versions of these colors {{can also be used}} and the background color may be changed, but the palette cannot be switched to official palettes 0 or 1 without enabling the <b>composite</b> <b>color</b> <b>signal</b> again. As such, it can only be seen on RGB monitors and will simply appear in grayscale on composite displays. This palette was often used by games because it looked more attractive than the cyan/magenta/white colors. Notably, it is not mentioned in the IBM Technical Reference manual, and some CGA clones may not support it.|$|E
40|$|Composite color {{television}} signals are sampled at {{four times the}} color subcarrier and transformed using intraframe two dimensional Walsh functions. It is shown that by properly sampling a <b>composite</b> <b>color</b> <b>signal</b> and employing a Walsh transform the YIQ time signals which sum to produce the <b>composite</b> <b>color</b> <b>signal</b> can be represented, in the transform domain, by three component signals in space. By suitably zonal quantizing the transform coefficients, the YIQ signals can be processed independently to achieve data compression and obtain the same results as component coding. Computer simulations of three bandwidth compressors operating at 1. 09, 1. 53 and 1. 8 bits/ sample are presented. The above results can also {{be applied to the}} PAL color system...|$|E
40|$|Coding {{scheme for}} {{transmission}} of color-television pictures reduces crosstalk between chrominance and luminance. Picture elements arranged in zigzag pattern to accommodate scanning. Resulting chrominance signal combined with horizontally and vertically interlaced output of luminance scan converter to form <b>composite</b> <b>color</b> <b>signal.</b> Applicable to color-video cameras with solid-state image-sensing devices using National Television System Committee (NTSC) standard color-television system, or other systems...|$|E
40|$|An {{adaptive}} algorithm for intraframe {{compression of}} NTSC <b>composite</b> <b>color</b> video <b>signal</b> is described. With {{an average of}} 80 percent compression (1. 6 bits/pixel) and a bit error rate of 0. 0001, excellent broadcast quality pictures were obtained. This is confirmed by a subjective evaluation of processed pictures by five viewers. The algorithm {{and the results of}} the subjective evaluation are given in this paper...|$|R
40|$|Advances in very {{large-scale}} {{integration and}} recent {{work in the}} field of bandwidth efficient digital modulation techniques have combined to make digital video processing technically feasible and potentially cost competitive for broadcast quality television transmission. A hardware implementation was developed for a DPCM-based digital television bandwidth compression algorithm which processes standard NTSC <b>composite</b> <b>color</b> television <b>signals</b> and produces broadcast quality video in real time at an average of 1. 8 bits/pixel. The data compression algorithm and the hardware implementation of the CODEC are described, and performance results are provided...|$|R
40|$|The paper {{deals with}} the digital {{implementation}} of the generator of test signal sin^ 2 20 T. This function has a limited spectrum in the luminance and chrominance areas of the <b>color</b> <b>composite</b> <b>signal.</b> The signal is frequently used for measurements of the transmission channels in color television technology. The paper arises from the contribution [1]...|$|R
5000|$|... 640×200 pixels, as {{with the}} 80×25 text mode. All pixels can be {{addressed}} independently. This mode is monochrome with a pixel aspect ratio of 1:2.4. By default the colors are black and bright white, but the foreground color can be changed to any other color of the CGA palette. This can be done at runtime without refreshing the screen. The background color cannot be changed from black on a true IBM CGA card. BIOS Mode 6 sets up the 640×200 graphics mode. This mode disables the <b>composite</b> <b>color</b> burst <b>signal</b> by default. The BIOS does not provide an option to turn the color burst on in 640×200 mode, and the user must write directly to the mode control register to enable it.|$|R
5000|$|In the 80-column text mode, the pixel {{clock is}} doubled, {{and all the}} {{synchronization}} signals are output for {{twice the number of}} clock cycles in order to last for their proper duration. The <b>composite</b> output's <b>color</b> burst <b>signal</b> circuit is an exception: because it still outputs the same number of cycles now at twice the clock rate, the <b>color</b> burst <b>signal</b> produced is too short for most monitors, yielding no or unstable color. Hence, IBM documentation lists the 80-column text mode as a [...] "feature" [...] only for RGBI and black-and-white <b>composite</b> monitors. Stable <b>color</b> can still be achieved by setting the border color to brown, which happens to produce a phase identical to the correct <b>color</b> burst <b>signal</b> and serves as a substitute for it.|$|R
50|$|The {{chrominance}} subcarrier is {{a separate}} subcarrier signal that carries the color information during transmission of a video signal. It is modulated and synchronized using the colorburst signal and then attached to the back porch of the <b>color</b> <b>composite</b> video <b>signal.</b> By synchronizing the subcarrier with the local oscillator of the television receiver, the RGB colors can be decoded successfully.|$|R
40|$|The authors {{present the}} {{hardware}} {{implementation of a}} digital television bandwidth compression algorithm which processes standard NTSC (National Television Systems Committee) <b>composite</b> <b>color</b> television <b>signals</b> and produces broadcast-quality video in real time {{at an average of}} 1. 8 b/pixel. The sampling rate used with this algorithm results in 768 samples over the active portion of each video line by 512 active video lines per video frame. The algorithm is based on differential pulse code modulation (DPCM), but additionally utilizes a nonadaptive predictor, nonuniform quantizer, and multilevel Huffman coder to reduce the data rate substantially below that achievable with straight DPCM. The nonadaptive predictor and multilevel Huffman coder combine to set this technique apart from prior-art DPCM encoding algorithms. The authors describe the data compression algorithm and the hardware implementation of the codec and provide performance results...|$|R
40|$|The lack of {{available}} wideband digital links {{as well as}} the complexity of implementation of bandwidth efficient digital video CODECs (encoder/decoder) has worked to keep the cost of digital television transmission too high to compete with analog methods. Terrestrial and satellite video service providers, however, are now recognizing the potential gains that digital video compression offers and are proposing to incorporate compression systems to increase the number {{of available}} program channels. NASA is similarly recognizing the benefits of and trend toward digital video compression techniques for transmission of high quality video from space and therefore, has developed a digital television bandwidth compression algorithm to process standard National Television Systems Committee (NTSC) <b>composite</b> <b>color</b> television <b>signals.</b> The algorithm is based on differential pulse code modulation (DPCM), but additionally utilizes a non-adaptive predictor, non-uniform quantizer and multilevel Huffman coder to reduce the data rate substantially below that achievable with straight DPCM. The non-adaptive predictor and multilevel Huffman coder combine to set this technique apart from other DPCM encoding algorithms. All processing is done on a intra-field basis to prevent motion degradation and minimize hardware complexity. Computer simulations have shown the algorithm will produce broadcast quality reconstructed video at an average transmission rate of 1. 8 bits/pixel. Hardware implementation of the DPCM circuit, non-adaptive predictor and non-uniform quantizer has been completed, providing realtime demonstration of the image quality at full video rates. Video sampling/reconstruction circuits have also been constructed to accomplish the analog video processing necessary for the real-time demonstration. Performance results for the completed hardware compare favorably with simulation results. Hardware implementation of the multilevel Huffman encoder/decoder is currently under development along with implementation of a buffer control algorithm to accommodate the variable data rate output of the multilevel Huffman encoder. A video CODEC of this type could be used to compress NTSC <b>color</b> television <b>signals</b> where high quality reconstruction is desirable (e. g., Space Station video transmission, transmission direct-to-the-home via direct broadcast satellite systems or cable television distribution to system headends and direct-to-the-home) ...|$|R
40|$|In {{this paper}} {{the design of}} a {{high-speed}} cryptographic coprocessor is presented. This coprocessor is named Subterranean and can be used for both cryptographic pseudorandom sequence generation (Substream) and cryptographic hashing (Subhash). In Substream mode the chip can be used for stream encryption/decryption under control of a 256 -bit key. A cryptographic resynchronization mechanism is provided for fast accessibility of encrypted data by legitimate parties. Application fields include the real-time encryption of digital HDTV signals as well as high speed telecommunication and networking such as ATM. The chip has been fabricated within the INVOMEC / EUROCHIP educational VLSI Design Facilities in MIETEC 2 : 4 ¯ CMOS technology. Measured samples are operating at encryption / decryption rates of 286 Mbits/sec and hashing rates of 572 Mbits/sec. The operation of the chip is demonstrated by a setup showing the real-time encryption and decryption of digitized PAL <b>color</b> <b>composite</b> video <b>signals</b> [...] ...|$|R
5000|$|... #Subtitle level 2: Special {{effects on}} <b>composite</b> <b>color</b> {{monitors}} ...|$|R
5000|$|... #Subtitle level 3: With a <b>composite</b> <b>color</b> monitor/television set ...|$|R
5000|$|Built-in display: 5" [...] inch (127 mm) <b>composite</b> <b>color</b> monitor (CRT) ...|$|R
50|$|Many of {{the more}} {{high-profile}} game titles offered graphics optimized for <b>composite</b> <b>color</b> monitors.|$|R
5000|$|BIOS Modes 4 & 5 {{set up the}} 320×200 {{graphics}} modes. Similar to {{the text}} modes, Mode 4 enables the <b>composite</b> <b>color</b> burst bit, Mode 5 disables it. Unlike the text modes, disabling the <b>composite</b> <b>color</b> burst bit (which setting Mode 5 does) in 320×200 affects the colors displayed on an RGB monitor with the IBM CGA card and true compatibles (see below.) ...|$|R
40|$|Takaaki Harada and Rei Kawakami who {{had many}} {{precious}} opinions enjoyed in creating this paper. Moreover, I say gratitude also to {{you of the}} Ikeuchi laboratory A number of methods have been proposed to separate a <b>color</b> <b>signal</b> into its components: illumination spectral power distribution and surface spectral reflectance. Most of these methods usually use a minimization technique from solely a single <b>color</b> <b>signal,</b> which works in theoretical framework but is not effective for real data. The reason is it lacks the constraints necessary to make the iteration converge into correct separation. To resolve this problem, we proposed a minimization technique that, unlike the existing methods, uses multiple <b>color</b> <b>signals.</b> In our implementation, we introduce three different approaches: first, <b>color</b> <b>signals</b> obtained from two different surface reflectance lit by an identical illumination spectral power distribution; second, <b>color</b> <b>signal</b> from an identical surface reflectance lit by different illumination spectral power distributions; and third, <b>color</b> <b>signals</b> from identical surface reflectance but with different types o...|$|R
50|$|However, in {{practice}} {{this goal is}} almost never attained. The amplification factor of <b>color</b> <b>signal</b> is always slightly different than that of CVS. (The <b>color</b> <b>signal</b> is superimposed on CVS).|$|R
40|$|A {{method for}} obtaining {{electronic}} chroma signals {{with a single}} scanning-type image device is described. A <b>color</b> multiplexed light <b>signal</b> is produced using an arrangement of dichroic filter stripes. In the particular system described, a two layer filter is used to color modulate external light which is then detected by an image pickup tube. The resulting time division multiplexed electronic signal from the pickup tube is converted by a decoder into a green <b>color</b> <b>signal,</b> and a single red-blue multiplexed signal, which is demultiplexed to produce red and blue <b>color</b> <b>signals.</b> The three primary <b>color</b> <b>signals</b> can be encoded as standard NTSC <b>color</b> <b>signals...</b>|$|R
50|$|The low {{resolution}} of this <b>composite</b> <b>color</b> artifacting method led to it being used almost exclusively in games. Many of the more high-profile titles optionally, sometimes exclusively, offering graphics optimized for <b>composite</b> <b>color</b> monitors. Ultima II, the first game in the game series to be ported to IBM PC, used CGA composite graphics. King's Quest I was innovative in its use of 16-color graphics on the PC, PCjr and Tandy 1000; even CGA owners could enjoy the 16-color graphics by using a <b>composite</b> <b>color</b> monitor or television, thanks to programmers exploiting the inaccuracies of composite NTSC chroma decoding. Selecting 'RGB mode' at the title screen would instead result in the usual CGA graphics mode limited to 4 colors. In this mode, dithering was employed to simulate extra colors.|$|R
5000|$|The 320&times;200 {{variant of}} this {{technique}} (see above) is how the standard BIOS-supported graphics mode looks on a <b>composite</b> <b>color</b> monitor. The 640&times;200 variant, however, requires modifying a bit (color burst disable) directly in the CGA's hardware registers, as a result, it is usually {{referred to as a}} separate [...] "mode", often just as [...] "the" [...] <b>composite</b> <b>color</b> mode, since its more distinctive set of artifact colors led it to being more commonly used than the 320&times;200 variant.|$|R
50|$|In {{order to}} be able to {{separate}} the <b>color</b> <b>signal</b> from the monochrome one in the receiver, a fixed frequency sub carrier is used, this sub carrier being modulated by the <b>color</b> <b>signal.</b>|$|R
50|$|Being {{completely}} {{dependent on}} the NTSC encoding/decoding process, <b>composite</b> <b>color</b> artifacting is not available on an RGBI monitor, nor is it emulated by EGA, VGA or contemporary graphics adapters.|$|R
50|$|Vertical <b>color</b> light <b>signals</b> are {{the second}} major pattern of <b>color</b> light <b>signals,</b> and today {{represent}} the most popular form of signal in North America, supplanting the searchlight. These signals are not different from the triangular type <b>color</b> <b>signal</b> in function, but present a much altered visual appearance.|$|R
5000|$|The {{modulation}} technique {{of the color}} subcarrier is quadrature amplitude modulation (QUAM [...] ) both in PAL and NTSC systems. The amplitude of the <b>color</b> <b>signal</b> represents the saturation of the color and the phase lag of the <b>color</b> <b>signal</b> {{with respect to a}} certain reference which is called colorburst represents the hue; i.e., each phase lag is assigned for a different color hue. So, in order to reproduce the original color in the receiver, the phase difference between the colorburst and the <b>color</b> <b>signal</b> must be kept constant throughout the broadcasting.|$|R
50|$|Any color can {{be totally}} {{described}} by luminance, saturation and hue. When the gain of the reproduced <b>color</b> <b>signal</b> {{is lower than}} that of luminance, the perceived colors are paler than their originals. Conversely, when the gain of the reproduced <b>color</b> <b>signal</b> is higher than the luminance, the perceived colors are too loud.|$|R
5000|$|<b>Color</b> <b>signal,</b> {{which is}} {{actually}} a subcarrier modulated by chroma information ...|$|R
5000|$|... #Caption: <b>Color</b> <b>signals</b> {{mixed with}} video signal (two {{horizontal}} lines in sequence) ...|$|R
5000|$|On {{broadcast}} equipment, such as timebase correctors {{and studio}} monitors, this control is typically marked [...] "phase," [...] as it adjusts {{the phase of}} the <b>color</b> <b>signal</b> {{with respect to the}} <b>color</b> burst <b>signal.</b>|$|R
40|$|Absorption and {{scattering}} by molecules, aerosols and hydrosols, and {{the reflection}} and transmission {{over the sea}} surface can modify the original polarization state of sunlight. However, water-leaving radiance polarization, containing embedded water constituent information, has largely been neglected. Here, {{the efficiency of the}} parallel polarization radiance (PPR) for enhancing ocean <b>color</b> <b>signal</b> of suspended particulate matter is examined via vector radiative transfer simulations and laboratory experiments. The simulation results demonstrate that the PPR has a slightly higher ocean <b>color</b> <b>signal</b> at the top-of-atmosphere as compared with that of the total radiance. Moreover, both the simulations and laboratory measurements reveal that, compared with total radiance, PPR can effectively enhance the normalized ocean <b>color</b> <b>signal</b> for a large range of observation geometries, wavelengths, and suspended particle concentrations. Thus, PPR has great potential for improving the ocean <b>color</b> <b>signal</b> detection from satellite. © 2017 Optical Society of America. </p...|$|R
40|$|The skin <b>color</b> <b>signal</b> is {{the product}} of skin reflectances and {{spectral}} power distribution of illuminants. In this paper we use principal component analysis to obtain basis functions for an ensemble of skin <b>color</b> <b>signals</b> and test the reconstruction goodness with different number of basis functions and types of normalization. We demonstrate the usefulness of the basis functions in two applications: (1) the reconstruction of new skin <b>color</b> <b>signals</b> which are due to the combination of two light sources that simultaneously impinge on the skin, and (2) the computation of the "skin locus" of a color camera, which is the range of possible skin chromaticities that the camera can measure...|$|R
2500|$|US Patent No. 4,278,972: [...] "Digitally-controlled <b>color</b> <b>signal</b> {{generation}} {{means for}} use with display" ...|$|R
40|$|In 1982, Horace Barlow {{considered}} {{the question of}} human trichromacy {{in the context of}} information theory: according to the Sampling Theorem, three types of receptors covering the visible spectrum (400 - - 700 nm) might be sufficient to reconstruct the <b>color</b> <b>signal.</b> Although Barlow was led to reject the direct application of the Sampling Theorem to explain color dimensionality, the theoretical framework offers a fresh point of view for analyzing the color system in conjunction with the physical characteristics of natural <b>color</b> <b>signals.</b> This review aims to illustrate that if the strict mathematical reconstruction (as implied by the Sampling Theorem) is replaced by a pragmatic approximation of <b>color</b> <b>signals,</b> then trichromacy, with its subsequent opponent-color process, could be regarded as an optimization of color constancy abilities in the spectral environment of primates. Higher dimension systems (tetrachromacy) found in other species can also serve the purpose of color constancy optimization in environments where <b>color</b> <b>signals</b> exhibit a finer spectral structure...|$|R
50|$|Additionally, for compatibility, it is {{required}} to use no more bandwidth than the monochrome <b>signal</b> alone; the <b>color</b> <b>signal</b> has to be somehow inserted into the monochrome signal, without disturbing it. This insertion is possible because the spectrum of the monochrome TV signal is not continuous (for most typical video content), hence empty space exists which can be utilized. This typical lack of continuity results from the discrete nature of the signal, which is divided into frames and lines. (Strictly speaking, monochrome video does use the full spectrum, if arbitrary and unconstrained movement of subjects and/or cameras is permitted. Therefore, all of these color systems compromise luma quality to some extent {{in exchange for the}} addition of color—i.e. all of these <b>color</b> <b>signals</b> look worse at some time or other than they would if the <b>color</b> <b>signal</b> were absent.) Analog color systems differ by the way in which infrequently used space in the frequency band of the signal is used. In all cases, the <b>color</b> <b>signal</b> is inserted {{at the end of the}} spectrum of the monochrome signal, where it causes less visual distortion (only affecting fine detail) in the uncommon case that the monochrome signal had significant frequency components overlapping the <b>color</b> <b>signal.</b>|$|R
40|$|Many {{species of}} stomatopod {{crustaceans}} have multiple spectral classes of photoreceptors in their retinas. Behavioral evidence {{also indicates that}} stomatopods are capable of discriminating objects by their spectral differences alone, Most animals use only two to four different types of photoreceptors in their color vision systems, typically with broad sensitivity functions, but the stomatopods apparently include eight or more narrowband photoreceptor classes for color recognition. It is also known that stomatopods use several colored body regions in social interactions. To examine why stomatopods may be so 2 ̆ 7 concerned 2 ̆ 7 with color, we measured the absorption spectra of visual pigments and intrarhabdomal filters, and the reflectance spectra {{from different parts of}} the bodies of several individuals of the gonodactyloid stomatopod species, Gonodactylus smithii. We then applied a model of multiple dichromatic channels for color encoding to examine whether the finely tuned color vision was specifically co-evolved with their complex <b>color</b> <b>signals.</b> Although the eye design of stomatopods seems suitable for detecting <b>color</b> <b>signals</b> of their own, the detection of <b>color</b> <b>signals</b> from other animals, such as reef fishes, can be enhanced as well. Color vision in G. smithii is therefore not exclusively adapted to detect its own <b>color</b> <b>signals,</b> but the spectral tuning of some photoreceptors (e. g. midband Rows 2 and 3) enhances the contrast of certain <b>color</b> <b>signals</b> to a large enough degree to make co-evolution between color vision and these rather specific <b>color</b> <b>signals</b> likely. Copyright (C) 2000 S. Karger AG, Basel...|$|R
