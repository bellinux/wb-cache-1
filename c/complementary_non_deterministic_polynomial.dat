0|793|Public
40|$|Abstract — The vertex cover (VC) problem {{belongs to}} the class of <b>Non</b> <b>Deterministic</b> <b>Polynomial</b> time {{complete}} (NPC) graph theoretical problems, which plays {{a central role in}} theoretical computer science and it has a numerous real life applications. Since the problem is <b>Non</b> <b>Deterministic</b> <b>Polynomial</b> time complete (NPC) it is unlikely to find a polynomial-time algorithm for solving vertex-cover problem exactly. This paper analyses the various algorithms to find minimum vertex cover for standard classes of random graph. The performance of all algorithms is compared with the complexity and the output solution that of the approximation algorithm, clever greedy algorithm, branch-and-bound algorithm, and simple genetic algorithm (GA). Index Terms — Minimum vertex cover, Branch and bound, greedy algorithm, genetic algorithm, crossover, mutation. I...|$|R
40|$|Abstract. We {{introduce}} {{polynomial time}} enumeration reducibility (≤pe) and we retrace Selman’s {{analysis of this}} reducibility and its relationship with <b>non</b> <b>deterministic</b> <b>polynomial</b> time conjunctive reducibility. We discuss the basic properties of the degree structure induced by ≤pe over the computable sets and we show how to construct meets and joins. We are thus able to prove that this degree structure is dense and to show the existence of two types of lattice embeddings therein. ...|$|R
40|$|ABSTRACT- In {{this paper}} new fuzzy graphs are {{constructed}} using special graph configurations. Hamiltonian fuzzy graph, fuzzy Hamiltonian circuit, cubic fuzzy graphs and its properties are introduced. Algorithmic development of spanning trees in graphs, matching in bipartite graphs, maximum flows in network are discussed. This paper concludes that if a fuzzy graph is planar, cubic connected then the Hamiltonian circuit problem for this graph is NP – complete. Index Terms- Hamiltonian circuit fuzzy graph – <b>Non</b> <b>deterministic</b> <b>polynomial</b> I...|$|R
40|$|University course {{timetabling}} {{which has}} been determined as <b>non</b> <b>deterministic</b> <b>polynomial</b> problem that accept widely as problem that are intractable. An efficient algorithm does not exist that is guaranteed to find an optimal solution for such problems. The design of good algorithm to find new methods and techniques to solve such problem is a very active area of research. This paper presents the adaption of the hybridizing between harmony search with great deluge algorithm for solving curriculum-based course timetabling problems. The algorithm {{can be adapted to}} the problem. Results were not comparatively better than those previously known as best solution. Proper modification in terms of the approach in this algorithm would make the algorithm perform better on curriculum-based course timetabling...|$|R
40|$|The word {{algorithm}} is the magical {{word in the}} field of computer science because the imagination of the existence of any branch of computer science like artificial intelligence, computer network, human computer interaction etc. is useless without the word algorithm. There are some problems for which no any researcher is able to design those algorithms, which have polynomial time complexity in the worst case. No any researchers have even proved that no any polynomial time algorithm can solve them in worst case. NP complete problems arise in domains like automata and language theory, sequencing and scheduling, mathematical programming, algebra and number theory, games and puzzles, optimization problems,Boolean logic, graphs, arithmetic, designing of network, sets and partitions, storage and retrieval, biology, chemistry, physics etc. In this paper such kind of the problems (<b>non</b> <b>deterministic</b> <b>polynomial</b> type complete problem) is being studied along with the approximation algorithm for vertex cover problem. Researchers are applying their best efforts to design new approximation algorithms for nondeterministic polynomial type problems which have comparable less time complexity and space complexity as compared to the existing approximation algorithms...|$|R
40|$|Reliable {{communication}} is {{the backbone of}} advanced metering infrastructure (AMI). Within the AMI, the neighbourhood area network (NAN) transports a multitude of trafﬁc, each with unique requirements. In order to deliver an acceptable level of reliability and latency, the underlying network, such as the wireless mesh network(WMN), must provide or guarantee the quality-of-service (QoS) level required by the respective application trafﬁc. Existing WMN routing protocols, such as optimised link state routing (OLSR), typically utilise a single metric and do not consider the requirements of individual trafﬁc; hence, packets are delivered on a best-effort basis. This paper presents a QoS-aware WMN routing technique that employs multiple metrics in OLSR optimal path selection for AMI applications. The problems arising from this approach are <b>non</b> <b>deterministic</b> <b>polynomial</b> time (NP) -complete in nature, which were solved through the combined use of the analytical hierarchy process (AHP) algorithm and pruning techniques. For smart meters transmitting Internet Protocol (IP) packets of varying sizes at different intervals, the proposed technique considers the constraints of NAN and the applications’ trafﬁc characteristics. The technique was developed by combining multiple OLSR path selection metrics with the AHP algorithminns- 2. Compared with the conventional link metric in OLSR, the results show improvements of about 23 % and 45 % in latency and Packet Delivery Ratio (PDR), respectively, in a 25 -node grid NAN...|$|R
40|$|Background: Location-allocation is a {{combinatorial}} optimization problem, and {{is defined as}} <b>Non</b> <b>deterministic</b> <b>Polynomial</b> Hard (NP) hard optimization. Therefore, solution of such a problem should be shifted from exact to heuristic or Meta heuristic due {{to the complexity of}} the problem. Locating medical centers and allocating injuries of an earthquake to them has high importance in earthquake disaster management so that developing a proper method will reduce the time of relief operation and will consequently decrease the number of fatalities. Methods: This paper presents the development of a heuristic method based on two nested genetic algorithms to optimize this location allocation problem by using the abilities of Geographic Information System (GIS). In the proposed method, outer genetic algorithm is applied to the location part of the problem and inner genetic algorithm is used to optimize the resource allocation. Results: The final outcome of implemented method includes the spatial location of new required medical centers. The method also calculates that how many of the injuries at each demanding point should be taken to any of the existing and new medical centers as well. Conclusions: The results of proposed method showed high performance of designed structure to solve a capacitated location-allocation problem that may arise in a disaster situation when injured people has to be taken to medical centers in a reasonable time...|$|R
40|$|AbstractJob shop {{scheduling}} {{is predominantly}} an <b>Non</b> <b>deterministic</b> <b>polynomial</b> (NP) - complete challenge which is successfully tackled by the ABC algorithm by elucidating its convergence. The Job Shop Scheduling Problem (JSSP) {{is one of}} the most popular scheduling models existing in practice which is among the hardest combinatorial optimization problems. The ABC (Artificial Bee Colony) technique is concerned, it is observed that the entire specific artificial bees move about in a search space and select food sources by suitably adapting their location, know-how and having a full awareness of their nest inhabitants. Moreover, several scout bees soar and select the food sources discretely without making use of any skills. In the event of the quantity of the nectar in the fresh source becoming larger than the nectar quantity of an available source, they remember the fresh location and conveniently disregard the earlier position. In this way, the ABC system integrates local search techniques, executed by employed and onlooker bees, with universal search approaches, administered by onlookers and scouts. In our ambitious approach we have employed these three bees to furnish optimization in makespan, machine work load and the whole run period in an optimized method. In this way, with the efficient employment of our effective technique we make an earnest effort to minimize the makespan and number of machines. This paper compares GA to minimize the make span of the job scheduling process with ABC and proved that ABC algorithm produces the better result...|$|R
40|$|The League Championship Algorithm (LCA) is sport-inspired {{optimization}} algorithm that {{was introduced by}} Ali Husseinzadeh Kashan in the year 2009. It has since drawn enormous interest among the researchers because of its potential efficiency in solving many optimization problems and real -world applications. The LCA has also shown great potentials in solving <b>non</b> - <b>deterministic</b> <b>polynomial</b> time (NP- complete) problems. This survey presents a brief synopsis of the LCA literatures in peer- reviewed journals, conferences and book chapters. These research articles are then categorized according to indexing in the major academic databases (Web of Science, Scopus, IEEE Xplore and the Google Scholar). The analysis was also done to explore the prospects and {{the challenges of the}} algorithm and its acceptability among researchers. This systematic categorization {{can be used as a}} basis for future studies...|$|R
40|$|International audienceMachine {{to machine}} (M 2 M) {{communications}} pose significant {{challenges to the}} cellular networks due to its unique features such as the massive number of machine type devices (MTDs) {{as well as the}} limited data transmission session. Thus, advanced cellular network releases, such as long-term evolution (LTE) and LTE-Advanced (LTE-A), optimally designed to support human to human (H 2 H) communications, should cater to M 2 M communications. In this paper, we consider an M 2 M/H 2 H coexistence scenario where a simultaneous access to the spectrum is enabled. Taking the opportunity of the new device to device (D 2 D) communication paradigm offered in LTE-A and at the aim of enabling an efficient resource sharing, we propose to combine M 2 M and D 2 D owing to the MTD low transmit power. First, we formulate the resource sharing problem as a maximization of the sum-rate, problem for which the optimal solution has been proved to be <b>non</b> <b>deterministic</b> <b>polynomial</b> time hard (NP-Hard). Then, we formulate the problem as a novel interference-aware bipartite graph to overcome the computational complexity of the optimal solution. Thus, we consider here a two-phase resource allocation approach. In the first phase, H 2 H radio resource assignment is performed in a conventional way. In the second phase, we introduce two algorithms, one centralized and one semi-distributed to perform the M 2 M resource allocation. The computational complexity of both introduced algorithms is of polynomial complexity. Simulation results show that the semi-distributed M 2 M resource allocation algorithm achieves quite good performance in terms of network aggregate sum-rate with markedly lower communication overhead compared to the centralized one...|$|R
40|$|Network coding (NC) is a {{relatively}} recent novel technique that generalises network operation beyond traditional store-and-forward routing, allowing intermediate nodes to combine independent data streams linearly. The rapid integration of bandwidth-hungry applications such as video conferencing and HDTV means that NC is a decisive future network technology. NC is gaining popularity since it offers significant benefits, such as throughput gain, robustness, adaptability and resilience. However, it does this at a potential complexity cost {{in terms of both}} operational complexity and set-up complexity. This is particularly true of network code construction. Most NC problems related to these complexities are classified as <b>non</b> <b>deterministic</b> <b>polynomial</b> hard (NP-hard) and an evolutionary approach is essential to solve them in polynomial time. This research concentrates on the multicast scenario, particularly: (a) network code construction with optimum network and coding resources; (b) optimising network coding resources; (c) optimising network security with a cost criterion (to combat the unintentionally introduced Byzantine modification security issue). The proposed solution identifies minimal configurations for the source to deliver its multicast traffic whilst allowing intermediate nodes only to perform forwarding and coding. In the method, a preliminary process first provides unevaluated individuals to a search space that it creates using two generic algorithms (augmenting path and linear disjoint path. An initial population is then formed by randomly picking individuals in the search space. Finally, the Multi-objective Genetic algorithm (MOGA) and Vector evaluated Genetic algorithm (VEGA) approaches search the population to identify minimal configurations. Genetic operators (crossover, mutation) contribute to include optimum features (e. g. lower cost, lower coding resources) into feasible minimal configurations. A fitness assignment and individual evaluation process is performed to identify the feasible minimal configurations. Simulations performed on randomly generated acyclic networks are used to quantify the performance of MOGA and VEGA...|$|R
40|$|International audienceTraditional {{cellular}} {{networks have}} been considered the most promising candidates to support machine to machine (M 2 M) communication mainly due to their ubiquitous coverage. Optimally designed to support human to human (H 2 H) communication, an innovative access to radio resources is required to accommodate M 2 M unique features such as the massive number of machine type devices (MTDs) {{as well as the}} limited data transmission session. In this paper, we consider a simultaneous access to the spectrum in an M 2 M/H 2 H coexistence scenario. Taking the advantage of the new device to device (D 2 D) communication paradigm enabled in long term evolution-advanced (LTE-A), we propose to combine M 2 M and D 2 D owing to the MTD low transmit power and thus enabling efficiently the resource sharing. First, we formulate the resource sharing problem as a maximization of the sum-rate, problem for which the optimal solution has been proved to be <b>non</b> <b>deterministic</b> <b>polynomial</b> time hard (NP-Hard). We next model the problem as a novel interference-aware bipartite graph to overcome the computational complexity of the optimal solution. To solve this problem, we consider here a two-phase resource allocation approach. In the first phase, H 2 H users resource assignment is performed in a conventional way. In the second phase, we introduce two alternative algorithms, one centralized and one semi-distributed to perform M 2 M resource allocation. The computational complexity of both introduced algorithms whose aim is to solve the M 2 M resource allocation, is of polynomial complexity. Simulation results show that the semi-distributed M 2 M resource allocation algorithm achieves quite good performance in terms of network aggregate sum-rate with markedly lower communication overhead compared to the centralized one...|$|R
40|$|Problem: The process {{planning}} task {{for a given}} design problem in additive manufacturing can be greatly enhanced by referencing previously developed process plans. However, identifying appropriate process plans for the given design problem requires appropriate mapping between the design domain and the {{process planning}} domain. Hence, {{the objective of this}} research is to establish mathematical mapping between the design domain and the process planning domain such that the previously developed appropriate process plans can be identified for the given design task. Further more, identification of an appropriate mathematical theory that enables computational mapping between the two domains is of interest. Through such computational mapping, previously developed process plans are expected to be shared in a distributed environment using an open repository. Approach: The design requirements and process plans are discretized using empirical models that compute exact values of process variables for the given design requirements. Through this discretization, subsumption relations among the discretized design requirements and process plans are identified. Appropriate process plans for a given design requirement are identified by subsumption relations in the design requirements. Also, the design requirements that can be satisfied by the given process plans are identified by subsumption relations among the process plans. To computationally realize such mapping, a description logic (ALE) is identified and justified to represent and compute subsumption relation. Based on this investigation, a retrieval method (DFM framework) is realized that enables storage and retrieval of process plans. Validation: Theoretical and empirical validations are performed using the validation square method. For the theoretical validation, an appropriate description logic (ALE) is identified and justified. Also, subsumption utilization in mapping two domains and realizing the DFM framework is justified. For the empirical validation, the storing and retrieval performance of the DFM framework is tested to demonstrate its theoretical validity. Contribution:	In this research, two areas of contributions are identified: DFM and engineering information management. In DFM, the retrieval method that relates the design problem to appropriate process plans through mathematical mapping between design and process planning domain is the major contribution. In engineering information management, the major contributions are the development of information models and the identification of their characteristics. Based on this investigation, an appropriate description logic (ALE) is selected and justified. Also, corresponding computational feasibility (<b>non</b> <b>deterministic</b> <b>polynomial</b> time) of subsumption is identified. Ph. D. Committee Chair: David Rosen; Committee Member: Charles Eastman; Committee Member: Christiaan Paredis; Committee Member: Janet Allen; Committee Member: Nelson Bake...|$|R
40|$|<b>Non</b> <b>deterministic</b> {{applications}} {{arise in}} many domains, including, stochastic optimization, multi-objectives optimization, stochastic planning, contingent stochastic planning, reinforcement learning, reinforcement learning in partially observable Markov decision processes, and conditional planning. We present a logic programming framework called <b>non</b> <b>deterministic</b> logic programs, {{along with a}} declarative semantics and fixpoint semantics, to allow representing and reasoning about inherently <b>non</b> <b>deterministic</b> real-world applications. The language of <b>non</b> <b>deterministic</b> logic programs framework is extended with non-monotonic negation, and two alternative semantics are defined: the stable <b>non</b> <b>deterministic</b> model semantics and the well-founded <b>non</b> <b>deterministic</b> model semantics {{as well as their}} relationship is studied. These semantics subsume the deterministic stable model semantics and the deterministic well-founded semantics of deterministic normal logic programs, and they reduce to the semantics of deterministic definite logic programs without negation. We show the application of the <b>non</b> <b>deterministic</b> logic programs framework to a conditional planning problem...|$|R
40|$|This is {{the final}} article {{in a series of}} four articles. Richard Karp has proven that a <b>deterministic</b> <b>polynomial</b> time {{solution}} to K-SAT will result in a <b>deterministic</b> <b>polynomial</b> time solution to all NP-Complete problems. However, it is demonstrated that a <b>deterministic</b> <b>polynomial</b> time solution to any NP-Complete problem does not necessarily produce a <b>deterministic</b> <b>polynomial</b> time solution to all NP-Complete problems. Comment: 12 Pages; ftp://ftp% 40 micrognu% 2 Ecom:anon% 40 anon@ftp. micrognu. com/pnenp/conclusion. pd...|$|R
40|$|AbstractJob shop {{scheduling}} {{problem is a}} well known {{scheduling problem}} in which {{most of them are}} categorised into <b>non</b> <b>polynomial</b> <b>deterministic</b> (NP) hard problem because of its complexity. Many researchers intended to solve the problem by applying various optimization techniques. While using traditional methods they observed huge difficulty in solving high complex problems. Later 90 's many researchers addressed JSSP by using intelligent technique such as fuzzy logic, simulated annealing etc. After that genetic algorithm (GA), Selective breeding algorithm (SBA), taboo search algorithm and Ant colony algorithm [are popularly known as Meta heuristic algorithms were proved most efficient algorithms to solve various JSSP so far. The objective of this paper is as follows i) to make use of a recently developed meta heuristic called Firefly algorithm (FA) because of inspiration on Firefly and its characteristic. ii) to find the makespan minimization using 1 - 25 Lawrance problems as a bench marking from a classical OR- library. iii) the analysis of the experimental resultson Firefly algorithm is compared with other algorithms...|$|R
40|$|AbstractA <b>deterministic</b> <b>polynomial</b> time {{algorithm}} is presented for finding the distinct-degree factorization of multivariate polynomials over finite fields. As a consequence, one can {{count the number}} of irreducible factors of polynomials over finite fields in <b>deterministic</b> <b>polynomial</b> time, thus resolving a theoretical open problem of Kaltofen from 1987...|$|R
5000|$|... #Caption: [...] A {{deterministic}} algorithm that performs f(n) steps always {{finishes in}} n steps and always returns {{the same result}}. A <b>non</b> <b>deterministic</b> algorithm that has f(n) levels might not return the same result on different runs. A <b>non</b> <b>deterministic</b> algorithm may never finish due to the potentially infinite size of the fixed height tree.|$|R
40|$|A <b>deterministic</b> <b>polynomial</b> time {{algorithm}} is presented for finding the distinct-degree factorization of multivariate polynomials over finite fields. As a consequence, one can {{count the number}} of irreducible factors of polynomials over finite fields in <b>deterministic</b> <b>polynomial</b> time, thus resolving a theoretical open problem of Kaltofen from 1987. © 2004 Elsevier Ltd. All rights reserved...|$|R
40|$|This paper {{addresses}} {{the issue of}} <b>non</b> <b>deterministic</b> extensions of logic database languages. After providing {{an overview of the}} main proposals in the literature, we concentrate on the analysis of the dynamic choice construct {{from the point of view}} of the expressive power. We show how such construct is capable of expressing several interesting <b>deterministic</b> and <b>non</b> <b>deterministic</b> problems, such as forms of negation, and ordering. We then prove that Datalog augmented with the dynamic choice expresses exactly the <b>non</b> <b>deterministic</b> time-polynomial queries. We thus obtain a complete characterization of the class of queries NDB-PTIME by means of a simple, declarative, and efficiently implementable language...|$|R
40|$|Previously {{the author}} has {{demonstrated}} that a representative polynomial search partition is required to solve a NP-complete problem in <b>deterministic</b> <b>polynomial</b> time. It has also been demonstrated that finding such a partition can only be done in <b>deterministic</b> <b>polynomial</b> time if {{the form of the}} problem provides a simple method for producing the partition. It is {{the purpose of this article}} to demonstrate that no <b>deterministic</b> <b>polynomial</b> time method exists to produce a representative polynomial search partition for the Knapsack problem. Comment: 14 Pages; The author is delaying submission for publication so that counter arguments may be proposed. ftp://ftp% 40 micrognu% 2 ecom:anon% 40 anon@ftp. micrognu. com/pnenp/knapsack. pd...|$|R
2500|$|An {{important}} {{consequence of}} this theorem is that if there exists a <b>deterministic</b> <b>polynomial</b> time algorithm for solving Boolean satisfiability, then every NP problem can be solved by a <b>deterministic</b> <b>polynomial</b> time algorithm. [...] The question of whether such an algorithm for Boolean satisfiability exists is thus equivalent to the P versus NP problem, which is widely considered the most important unsolved problem in theoretical computer science.|$|R
40|$|In this paper, <b>non</b> <b>deterministic</b> Indirect Reinforcement Learning (RL) {{techniques}} for controlling the transmission times {{and power of}} Wireless Network nodes are presented. Indirect RL facilitates planning and learning which ultimately leads to convergence on optimal actions with reduced episodes or time steps compared to direct RL. Three Dyna architecture based algorithms for <b>non</b> <b>deterministic</b> environments are presented. The results show improvements over direct RL and conventional static power control techniques. © 2009 Crown...|$|R
5000|$|The {{verifier}} verifies {{that the}} certificate is valid in <b>deterministic</b> <b>polynomial</b> time. If it is valid, it accepts; otherwise, it rejects.|$|R
5000|$|In the {{presence}} of linear order, first-order logic with a least fixed point operator gives P, the problems solvable in <b>deterministic</b> <b>polynomial</b> time.|$|R
5000|$|With Füredi {{he proved}} that no <b>deterministic</b> <b>polynomial</b> time {{algorithm}} determines {{the volume of}} convex bodies in dimension d within a multiplicative error dd.|$|R
40|$|AbstractWe {{prove that}} each {{element of a}} class of {{functions}} (denoted by NPCtP), whose graphs can be accepted in nondeterministic polynomial time, can be evaluated in <b>deterministic</b> <b>polynomial</b> time {{if and only if}} γ-reducibility is equivalent to polynomial time many-one reducibility. We also modify the proof technique used to obtain part of this result to obtain the stronger result that if every γ-reduction can be replaced by a polynomial time Turing reduction, then every function in NPCtP can be evaluated in <b>deterministic</b> <b>polynomial</b> time...|$|R
40|$|We {{investigate}} {{the effect on}} the space complexity when a language family K is extended by means of iterated λ-free deterministic substitution to a family η(K). If each language in K is accepted by a one-way nondeterministic multi-tape Turing machine within space S(n) for some monotonic space bound S(n) ≥ n, then η(K) is included in NSPACE(S(n)). Thus for each monotonic space bound S(n) ≥ n, the inclusion K⊆ NSPACE(S(n)) implies that η(K) is also included in NSPACE(S(n)). An implication similar to the latter one also holds for DSPACE(S(n)). Consequently, some well-known space-bounded complexity classes such as the families of (<b>non)</b> <b>deterministic</b> context-sensitive languages, of two-way (<b>non)</b> <b>deterministic</b> nonerasing stack automaton languages, and PSPACE are AFL's closed under intersection and iterated λ-free deterministic substitution. On the other hand no space-bounded complexity class which includes DSPACE(n) is closed under controlled iterated λ-free (<b>non)</b> <b>deterministic</b> substitution...|$|R
40|$|Abstract: Membrane {{computing}} is {{a recent}} area that belongs to natural computing. This field works on computational models based on nature's behavior to process the information. Recently, numerous models have been developed and implemented with this purpose. P-systems are the structures which have been defined, developed and implemented to simulate the behavior {{and the evolution of}} membrane systems which we find in nature. What we analyze in this paper is the power of the tools we currently have to simulate the randomness we find in nature. The main problem we face here, is trying to simulate <b>non</b> <b>deterministic</b> events by using deterministic tools. The goal we want to achieve is to propose an optimal method when simulating <b>non</b> <b>deterministic</b> processes. Talking about simulation of <b>non</b> <b>deterministic</b> method makes no sense when using deterministic tools; however we can get closer to the idea of non determinism by using more powerful randomness generators...|$|R
40|$|Abstract—In {{this paper}} {{we use a}} Markovian model previ-ously applied to cache related delay {{modeling}} and preemption delay modeling to a subset of dynamic branch predictors related WCET delays. Our model allows the modeling of a de-terministic or <b>non</b> <b>deterministic</b> automaton or set of automata thanks to a Markovian model. We previously applied this formalism to cache related delay and cache related preemption delays [7], [9] and to <b>non</b> <b>deterministic</b> cache policy [8]. Now {{we would like to}} introduce an application to some forms of branch prediction associated Worst Case Execution Time (WCET) computation. I...|$|R
40|$|In this paper, {{we focus}} on Assume/Guarantee {{contracts}} consisting in (i) a <b>non</b> <b>deterministic</b> model of components behaviour, and (ii) a stochastic and <b>non</b> <b>deterministic</b> model of systems faults. Two types of contracts capable of capturing reliability and availability properties are considered. We show that Satisfaction and Refine-ment can be checked by effective methods thanks to a reduction to classical verification problems on Markov Decision Processes and transition systems. Theorems supporting compositional reasoning and enabling the scalable analysis of complex systems are also de-tailed in the paper. 1...|$|R
40|$|Abstract. For RSA, May {{showed a}} <b>deterministic</b> <b>polynomial</b> time equiv-alence of {{computing}} d to factoring N(= pq). On the other hand, Takagi showed {{a variant of}} RSA such that the decryption algorithm is faster than the standard RSA, where N = prq while ed = 1 mod (p− 1) (q− 1). In this paper, we show that a <b>deterministic</b> <b>polynomial</b> time equivalence also holds in this variant. The coefficient matrix T to which LLL algo-rithm is applied is no longer lower triangular, and hence we develop a new technique to overcome this problem...|$|R
40|$|It is known, {{that over}} 1 -dimensional strings, the {{expressive}} power of 2 -way multihead (<b>non)</b> <b>deterministic</b> automata and (<b>non)</b> <b>deterministic</b> Transitive Closure formulas is (<b>non)</b> <b>deterministic</b> log space [Ib 73, Im 88]. However, the subset of formulas needed to simulate exactly k heads is unknown. It is also unknown if the automata and formulas {{have the same}} expressive power over more general structures such as multidimensional grids. We define a reduction from k-head automata to formulas of arity k, which works also for grids. The method used is a generalization of [Kl 56], and the formulas obtained are a generalization of regular expressions to multihead automata and to grid languages. As simple applications, we use the reduction {{to show that the}} power of formulas of arity 1 over strings define (classical) regular languages, to give a simpler equivalent of the L=NL open problem, and to establish the equivalence of the automata and formulas over grids. Faculty of Computer Science, Technio [...] ...|$|R
40|$|In {{this paper}} we {{consider}} <b>non</b> <b>deterministic</b> linear top-down tree transducers {{in the letter}} to letter case, {{that is to say}} tree transducers for which trees which appear in the rules are reduced to one letter in the right-hand side as in the left one. We establish the decidability of equivalence for this class of transducers. 1 Introduction Tree transducers, which are a generalization of rational transformations in the word case (see [1], [4] for a synthesis), have been widely studied. The authors have choosed either the algebraic point of view ([2], [5]), or the machine point of view ([7], [8], [11] for instance). In the word case, the main results of decidability of equivalence are: - Equivalence is undecidable in the <b>non</b> <b>deterministic</b> case (T. Griffiths 1968). - Equivalence is decidable in the deterministic one (Bird 1973, Valiant 1974). The same results have been obtained in trees. Equivalence is, in general, undecidable in the <b>non</b> <b>deterministic</b> case. And it is decidable for: - bot [...] ...|$|R
50|$|A binary {{relation}} P(x,y) is in FP if {{and only if}} there is a <b>deterministic</b> <b>polynomial</b> time algorithm that, given x, can find some y such that P(x,y) holds.|$|R
2500|$|... 2002– Manindra Agrawal, Nitin Saxena, and Neeraj Kayal of IIT Kanpur {{present an}} {{unconditional}} <b>deterministic</b> <b>polynomial</b> time algorithm {{to determine whether}} a given number is prime (the AKS primality test).|$|R
