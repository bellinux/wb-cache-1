1|18|Public
40|$|Abstract — This paper {{considers}} a hybrid Token-CDMA based {{medium access control}} (MAC) scheme where users attain data channel through a Token-passing procedure. The MAC scheme is then modeled as a multiserver multiqueue system {{in the case of}} gated service discipline. We present approximated analytical results for the mean server <b>cycle,</b> <b>server</b> inte-visit and interpolling time, as well as approximated closed form expressions for the mean queue vacation time. The system is assumed to accommodate several traffic classes where each class has different loading condition. Packet arrival process is assumed to be Poisson, with the same rate for the queues in each traffic class, and data rate quality of service (QoS) is incorporated to regulate the input. Packet service times and token walk times are modeled with independent, identically distributed random variables with exponential distributions. The system is assumed to be in the steady state...|$|E
40|$|In {{this paper}} we address power {{conservation}} for clusters of workstations or PCs. Our approach is to develop systems that dynamically turn cluster nodes on [...] {{to be able to}} handle the load imposed on the system efficiently [...] and off [...] to save power under lighter load. The key component of our systems is an algorithm that makes cluster reconfiguration decisions by considering the total load imposed on the system and the power and performance implications of changing the current configuration. The algorithm is implemented in two common cluster-based systems: a network server and an operating system for clustered <b>cycle</b> <b>servers.</b> Our experimental results are very favorable, showing that our systems conserve both power and energy in comparison to traditional systems...|$|R
40|$|Intelligent power {{solutions}} allow {{administrators to}} remotely power <b>cycle</b> <b>servers</b> and devices and troubleshoot problems, reducing server downtime by providing {{direct access to}} power control. Several important aspects of intelligent power management products can help promote uptime and allow for more effective power management. These features include smart load shedding, centralized management capability, branch circuit protection, and threephase power. _______________________________________________________________________________________________ Power management is a top concern for data center managers. (1) To efficiently and effectively manage power, data center managers are increasingly implementing remote or “intelligent ” power management solutions, which leverage hardware and/or software to monitor and control server-level power state and condition. Intelligent power {{can be used in}} environments of varying sizes, with solutions available {{for a wide range of}} applications—from control of a few outlets in a small office/home office (SOHO) environment or standalone kiosk to integrated vertically mounted solutions for medium to large-sized datacenters. Intelligent Power Management Intelligent power solutions allow administrators to remotely power <b>cycle</b> <b>servers</b> and devices and troubleshoot problems, reducing server downtime by providing direct access to power control. In a 2005 survey conducted by Cyclades, organizations that used intelligent power products reported an average recovery time of 10 - 30 minutes for remotely managed devices, compared to 1 - 2 hours for devices that were not remotely managed. (2) In addition to reducing downtime and shortening the mean time to repair, intelligent power products offer several significant benefits including: providing administrators with the ability to proactively monitor and protect missioncritical equipment with onboard or third-party environmental monitoring devices, eliminating or reducing late night trips to the datacenter and reducing third-party service calls for server reboots, and allowing the implementation of cost-effective “lights-out ” operation at remote offices and branch locations...|$|R
5000|$|Micro Focus ZENworks, a {{suite of}} {{software}} products developed and maintained by Micro Focus International for computer systems management, aims to manage the entire life <b>cycle</b> of <b>servers,</b> of desktop PCs (Windows, Linux or Mac), of laptops, and of handheld devices such as Android and iOS Mobile Phones and Tablets. [...] Novell planned to include full disk encryption functionality within ZENworks.ZENworks supports multiple server platforms and multiple directory services.|$|R
50|$|Autoscaling {{differs from}} having a fixed daily, weekly, or yearly <b>cycle</b> of <b>server</b> use {{in that it is}} {{responsive}} to actual usage patterns, and thus reduces the potential downside of having too few or too many servers for the traffic load. For instance, if traffic is usually lower at midnight, then a static scaling solution might schedule some servers to sleep at night, but this might result in downtime on a night where people happen to use the Internet more (for instance, due to a viral news event). Autoscaling, on the other hand, can handle unexpected traffic spikes better.|$|R
40|$|Network stack {{performance}} {{is critical to}} server scala-bility and user-perceived application experience. Per-packet overhead is a major bottleneck in scaling network I/O. While much effort is expended on reducing per-packet overhead for data-carrying packets, small control packets such as pure TCP ACKs have received relatively scarce attention. In this paper, we show that ACK receive processing can consume up to 20 % <b>cycles</b> in <b>server</b> appli-cations. We propose a simple kernel-level optimization which reduces this overhead through fewer memory allo-cations and a simplified code path. Using this technique, we demonstrate cycles savings of 15 % in a Web applica-tion, and 33 % throughput improvement in reliable mul-ticast. ...|$|R
40|$|This paper {{reports on}} {{empirical}} work aimed at comparing evidential reasoning techniques. While there is {{prima facie evidence}} for some conclusions, this i 6 work in progress; the present focus is methodology, with the goal that subsequent results be meaningful. The domain is a network of UNIX* <b>cycle</b> <b>servers,</b> and the task is to predict properties {{of the state of}} the network from partial descriptions of the state. Actual data from the network are taken and used for blindfold testing in a betting game that allows abstention. The focal technique has been Kyburg's method for reasoning with data of varying relevance to a particular query, though the aim is to be able eventually to compare various uncertainty calculi. The conclusions are not novel, but are instructive. 1. All of the calculi performed better than human subjects, so unbiased access to sample experience is apparently of value. 2. Performance depends on metric: (a) when trials are repeated, net = gains - losses favors methods that place many bets, if the probability of placing a correct bet is sufficiently high; that is, it favors point-valued formalisms; (b) yield = gains/(gains + lossee) favors methods that bet only when sure to bet correctly; that is, it favors interval-valued formalisms. 3. Among the calculi, there were no clear winners or losers. Methods are identified for eliminating the bias of the net as a performance criterion and for separating the calculi effectively: in both cases by posting odds for the betting game in the appropriate way. Comment: Appears in Proceedings of the Fourth Conference on Uncertainty in Artificial Intelligence (UAI 1988...|$|R
40|$|For {{a closed}} <b>cycle</b> of Bernoulli <b>servers</b> in {{discrete}} {{time with a}} single bottleneck we prove weak convergence of the suitably rescaled joint queue length vector for all nodes and weak convergence of the suitably rescaled cycle time when the network approaches heavy trac regime. We further investigate asymptotic dependencies of the sojourn time vector and nd unexpected behaviour of the covariance structure. A technical device for our proofs is a Harrison-type formula for arrival probabilities which is of independent interest...|$|R
40|$|We {{describe}} a distributed high-performance compute server {{that has been}} implemented for running compute-intensive applications on a mixture of HPC systems interconnected by Inter- and Intranet. With a practical industrial background, our work focusses on high availability, efficient job load-balancing, security, and the easy integration of HPC computing into the daily work-flow at pharmaceutical companies. The work {{was done in the}} course of the ESPRIT project Phase (A Distributed Pharmaceutical Application Server). The client software is implemented in Java. All results are displayed in a web browser and can be forwarded to the next stage of applications used in the drug design <b>cycle.</b> The <b>server</b> software handles the job load-balancing between the participating HPC nodes and is capable of managing multi-site applications. Our environment currently supports four key applications that are used in rational drug design and drug target identification. They range from the automatic functiona [...] ...|$|R
40|$|The {{popularity}} of virtualization has increased considerably {{during the past}} few decades. One claim that virtualization is not a brand new technology. It is known that the concept of virtualization has its origins in the mainframe days in the late 1960 s and early 1970 s, when IBM invested {{a lot of time and}} effort and, of course money, in developing robust time-sharing solutions. The best way to improve resource utilization, and at the same time to simplify data center management was seen as virtualization during those years. Data centers today use virtualization techniques to make abstraction of the physical hardware, create large aggregated pools of logical resources consisting of CPUs, memory, disks, file storage, applications and networking. In this thesis, going over available references, a life <b>cycle</b> for <b>server</b> virtualization is proposed. Later, the steps of this life cycle were applied on a fictitious enterprise information system for security reasons. As an extension of the study, cloud computing has been planned and summarized in the Summary and Conclusions chapter...|$|R
40|$|Abstract We {{introduce}} {{and study}} cyclic polling systems in which service times of customers increase {{after the completion}} of each cycle due to increased tiredness of the server. To prevent the system from exploding, the server must be deactivated to regain (some or all of) its efficiency while another server takes its place. Performing a ”change of guard ” takes some additional random time. This requires the determination of a ”swapping policy ” between the two servers. We model such systems under the gated, exhaustive, and globally-gated service regimes. In the case of swapping policies which call for a swap {{at the end of every}} fixed number of cycles, we show that, contrary to classical polling systems, the stability condition for the exhaustive regime differs from its counterpart for the gated regime. A single queue case with identical servers is further studied and analyzed. Assuming stability we show that, in the latter case, the maximal number of consecutive <b>cycles</b> a <b>server</b> can serve without resting under the gated regime is approximately double than that under the exhaustive regime. In addition, we construct an algorithm to obtain an optimal swapping policy for the case where two identical servers alternate every fixed number of cycles in a system operating under the exhaustive service regime...|$|R
40|$|The {{execution}} of emptying policy ensures {{the convergence of}} any solution to the system to a unique periodic orbit, which does not impose constraints on service-time and capacity of buffers. Motivated by these problems, in this paper, the service-time-limited policy is first proposed {{based on the information}} resulted from the periodic orbit under emptying policy, which imposes lower and upper bounds on emptying time for the queue in each buffer, by introducing lower-limit and upper-limit service-time factors. Furthermore, the {{execution of}} service-time-limited policy in the case of finite buffer capacity is considered. Moreover, the notion of feasibility of states under service-time-limited policy is introduced and then the checking condition for feasibility of states is given; that is, the solution does not exceed the buffer capacity within the first <b>cycle</b> of the <b>server.</b> At last, a sufficient condition for determining upper-limit service-time factors ensuring that the given state is feasible is given...|$|R
40|$|Assume that a b usy server is {{transferring}} files {{across the}} network, {{and during the}} transfer certain data present in the file is replaced with erroneous data. If the client node or receiver node {{does not have any}} technique to detect errors, then it would process the erroneous data got, and provide unexpected results. Now assume that the client just has a er ror detecting technique, it would be able to detect if errors were present in the received file or not, but {{will not be able to}} correct it, and in case it wants the correct data it will have to request the busy server to send the file again, this in turn leads to wastage of precious <b>server</b> <b>cycles</b> and bandwidth. Hence an efficient and effective error detection algorithm is required to overcome the above mentioned problems. Proposed algorithm can recover the erroneous data. It can be applied to all kind of data files...|$|R
40|$|This work {{analyzes}} various polling {{systems with}} both random breakdowns and repairs. A few {{works in the}} literature investigated polling networks with failing nodes, but none has treated the associated repair process or the combined eect of breakdowns and repairs on such systems. We consider three service mechanisms: Gated, Exhaustive and Globally-Gated. For each service regime we study several variations, diering from each other by (i) whether the arrival process to a queue being repaired continues or stops during the repair process, and (ii) whether the failure is observed immediately when it occurs or {{only at the end}} of a service duration. For each of the twelve models studied we provide analyses regarding the system state at polling instants (law of motion, probability generating functions, rst and second order moments) and derive expressions for several performance measures, such as (distribution and mean of) number of customers at the dierent queues, their waiting and sojourn times, <b>server's</b> <b>cycle</b> times, etc. We derive stability conditions for the various models and express all results in a unied generalized form...|$|R
40|$|Abstract—Today’s {{data centers}} offer IT {{services}} mostly hosted on dedicated physical servers. Server virtualization provides a technical means for server consolidation. Thus, multiple virtual servers can be hosted {{on a single}} server. Server consolidation describes the process of combining the workloads of several different servers {{on a set of}} target servers. We focus on server consolidation with dozens or hundreds of servers, which can be regularly found in enterprise data centers. Cost saving is among the key drivers for such projects. This paper presents decision models to optimally allocate source servers to physical target servers while considering real-world constraints. Our central model is proven to be an NP-hard problem. Therefore, besides an exact solution method, a heuristic is presented to address large-scale server consolidation projects. In addition, a preprocessing method for server load data is introduced allowing for the consideration of quality-of-service levels. Extensive experiments were conducted based on a large set of server load data from a data center provider focusing on managerial concerns over what types of problems can be solved. Results show that, on average, server savings of 31 percent can be achieved only by taking <b>cycles</b> in the <b>server</b> workload into account. Index Terms—Management of services delivery, modeling of resources, data center management services, optimization of services systems. ...|$|R
40|$|In {{this paper}} we {{consider}} {{a ring of}} N = 1 queues served by a single server in a cyclic order. After having served a queue (according to a service discipline that may vary from queue to queue), there is a switch-over period and then the server serves the next queue and so forth. This model is known in the literature as a polling model. Each of the queues is fed by a non-decreasing Lévy process, which can be different during each of the consecutive periods within the <b>server's</b> <b>cycle.</b> The N-dimensional Lévy processes obtained in this fashion are described by their (joint) Laplace exponent, thus allowing for non-independent input streams. For such a system we derive the steady-state distribution of the joint workload at embedded epochs, i. e. polling and switching instants. Using the Kella-Whitt martingale, we also derive the steady-state distribution at an arbitrary epoch. Our analysis heavily relies on establishing a link between fluid (Lévy input) polling systems and multi-type Jirina processes (continuous-state discrete-time branching processes). This is done by properly defining {{the notion of the}} branching property for a discipline, which {{can be traced back to}} Fuhrmann and Resing. This definition is broad enough to contain the most important service disciplines, like exhaustive and gated...|$|R
40|$|Adaptive {{systems can}} be {{modelled}} as being constructed from Adaptive Service Elements that, individually and collectively, use resources to provide users with services and then adapt how those services are delivered based on changes in the system’s context and available resources. People interact with such adaptive systems both as users of services and as {{those responsible for the}} allocation and use of the resources employed, e. g. network bandwidth, file access, device displays, <b>server</b> <b>cycles</b> etc. Person Centric Service Adaptation addresses how the needs of such users are interpreted and mapped onto the adaptive mechanisms of the adaptive system and its components. Adaptation must be conducted {{in a manner that is}} both natural to use and transparent to the user, while at the same time ensuring the user has a sense of control over the adaptive mechanisms. In this paper we review how adaptive systems have largely focussed on how a user interacts with an adaptive system. We argue, however, that for adaptive systems to be deployed in ubiquitous computing environments we must address more natural interaction with the system, enabled by the wider range of multi-model devices available. We also argue that for wide-spread deployment of adaptive systems, stronger abstractions must be developed in the constraining of adaptive behaviour, especially when adaptive ubiquitous computing systems are used in organisations and collaborative activities. Initial work towards these goals is presented. 1...|$|R
40|$|Assume that a busy server is {{transferring}} files {{across the}} network, {{and during the}} transfer certain data present in the file is replaced with erroneous data. If the client node or receiver node {{does not have any}} technique to detect errors, then it would process the erroneous data got, and provide unexpected results. Now assume that the client just has a error detecting technique, it would be able to detect if errors were present in the received file or not, but {{will not be able to}} correct it, and in case it wants the correct data it will have to request the busy server to send the file again, this in turn leads to wastage of precious <b>server</b> <b>cycles</b> and bandwidth. Hence an efficient and effective error detection algorithm is required to overcome the above mentioned problems. Proposed algorithm can recover the erroneous data. It can be applied to all kind of data files. Here we divide the input data into a 2 D square matrix, calculate xor value of all rows, and columns present in the matrix. This information is transferred along with the actual data, and at receiver end we use backtracking algorithm to recover erroneous data if any. It contains three stages, encoding of the data, testing for errors, decoding the data. Before sending any file across the network it is encoded by adding header to the actual data, header contains the necessary information required for backtracking algorithm. The output file received is tested for errors and if errors are found it is corrected using backtracking algorithm and the resultant data file is decoded to obtain the original data. If the file size is of n bytes then the backtracking algorithm can correct upto andamp;amp;# 8730;n bytes of the data...|$|R
40|$|The {{increasing}} demand for computing infrastructure, such as data centers and storage systems, has increased their energy footprint. As {{a result of}} this growth, computing infrastructure today contribute 2 - 3 % of the global carbon emissions. Furthermore, the energy-related costs have now become a significant fraction of the total cost of ownership (TCO) of a modern computing infrastructure. Hence, to reduce the financial and environmental impact of growing energy demands the design of eco-friendly green infrastructure has become an important societal need. This thesis focuses on designing distributed systems, primarily data centers and storage systems, to run on renewable energy sources such as solar and wind. ^ As renewables are intermittent in nature, accurate predictions of future energy is important for a distributed system to balance workload demand and energy supply, and optimize its performance amid significant and frequent changes in both demand and supply. To accurately predict energy harvesting in all weather conditions, I develop two prediction models that leverage weather forecasts to predict solar and wind energy harvesting. The first prediction model is an empirical model that uses sky cover forecast and wind speed forecast to predict solar energy and wind energy, respectively, in the future. The second prediction model is a machine learning based model that uses statistical power of machine learning techniques to give better predictions of solar energy harvesting than the empirical model. ^ To regulate the energy footprint of a server I propose a new energy abstraction, called Blink, that applies duty <b>cycle</b> to the <b>server</b> to cap power consumption to supply. I also propose several blinking policies to coordinate blinking across servers to regulate cluster-wide power consumption with changes in the available power. Further, I show that a real-world application can be redesigned, with modest complexity, to perform well on intermittent power. ^ To extend the applicability of blinking beyond an in-memory cache server I use the blinking abstraction to design two different distributed systems—(a) Distributed File System, and (b) Multimedia Cache—for intermittent power. I propose several design techniques, including a staggered blinking policy and power-balanced data layout, to optimize the performance of these systems under intermittent power scenarios. Additionally, I experiment with three unmodified real-world applications—(a) Memcache, (b) MapReduce, and (c) Search Engine—to test the practicality of our blink-aware file system. Our results show that real-world applications can perform reasonably well for real workloads in spite of significant and frequent variations in power supply. Finally, I use a real WiMAX testbed to demonstrate that our blink-aware multimedia cache can significantly save bandwidth usage of cell towers while providing good performance under intermittent power constraints...|$|R

