0|18|Public
40|$|In an invited {{commentary}} article, SMU Behavioural Sciences Institute Director Professor David Chan discussed {{issues of}} public expectations. He explained {{the power of}} unmet expectations and two popular myths about public expectations. He then suggested several attitudes and approaches that help prevent or mitigate negative public reactions. Professor Chan concluded that both people and Government should and can improve the ways they <b>calibrate,</b> <b>frame</b> and manage public expectations...|$|R
40|$|Abstract: A {{new method}} is {{proposed}} for recovering 3 D human poses in video sequences {{taken from a}} single uncalibrated camera. This is achieved by exploiting two important constraints observed from human bipedal motion: coplanarity of body key points during the mid-stance position {{and the presence of}} a foot on the ground – i. e. static foot- during most activities. Assuming 2 D joint locations have been extracted from a video sequence, the algorithm is able to perform camera auto-calibration on specific frames when the human body adopts particular postures. Then, a simplified pin-hole camera model is used to perform 3 D pose reconstruction on the <b>calibrated</b> <b>frames.</b> Finally, the static foot constraint which is found in most human bipedal motions is applied to infer body postures for non-calibrated frames. We compared our method with (1) “orthographic reconstruction ” method and (2) reconstruction using manually calibrated data. The results validate the assumptions made for the simplified pin-hole camera model and reconstruction results reveal a significant improvement over the orthographic reconstruction method. ...|$|R
40|$|The Confederation Bridge is {{the world}} longest spanned {{prestressed}} concrete box girder bridge standing in salt water. This bridge is subjected to severe dynamic loads, such as transverse loads and vibrations, induced by strong winds and stormy sea waves, destructive seismic loads from possible ground shaking, and impact loads from heavy vehicles and huge ice floe. Therefore, the dynamic behavior of the bridge {{is a very important}} factor affecting its safety and serviceability. In the present study, a three-dimensional (3 -D) model using shell elements is developed to investigate the free vibration behavior of one repetitive unit, while a frame model using 3 -D beam elements is employed to simulate dynamic responses of two repetitive units with a drop-in span. The effects of nonstructural mass, pier-water interaction and foundation flexibility on free vibration behavior are also studied by means of the frame model. The results are representative for the entire bridge because of the repetitiveness in the bridge configuration. Further, field data from pull tests are used to calibrate the finite element models. Computer simulation of the pull test using the <b>calibrated</b> <b>frame</b> model correlates reasonably well with the field data...|$|R
40|$|International audienceA {{method for}} {{calibrating}} linear cameras is described. It is {{shown that the}} more classical 2 -D camera calibration techniques are necessary but not sufficient for solving the linear-camera calibration problem. A model for linear cameras is proposed, and a two-step procedure is presented for estimating its parameters. A camera-centered coordinate frame is defined, and the extrinsic parameters of the camera are determined, that is, the rigid transformation between the <b>calibrating</b> coordinate <b>frame</b> and the camera frame. The accuracy of the calibration method was analyzed through an example application...|$|R
40|$|Real-world camera {{networks}} are often characterized by very wide baselines covering {{a wide range}} of viewpoints. We describe a method not only calibrating each camera se-quence added to the system automatically, but also taking advantage of multi-view correspondences to make the en-tire calibration framework more robust. Novel camera se-quences can be seamlessly integrated into the system at any time, adding to the robustness of future computations. One of the challenges consists in establishing correspon-dences between cameras. Initializing a bag of features from a <b>calibrated</b> <b>frame,</b> correspondences between cameras are established in a two-step procedure. First, affine invariant features of camera sequences are warped into a common coordinate frame and a coarse matching is obtained be-tween the collected features and the incrementally built and updated bag of features. This allows us to warp images to a common view. Second, scale invariant features are ex-tracted from the warped images. This leads to both more numerous and more accurate correspondences. Finally, the parameters are optimized in a bundle adjustment. Adding the feature descriptors and the optimized 3 D positions to the bag of features, we obtain a feature-based scene ab-straction, allowing for the calibration of novel sequences and the correction of drift in single-view calibration track-ing. We demonstrate that our approach can deal with wide baselines. Novel sequences can seamlessly be integrated in the calibration framework. 1. Introduction and Relate...|$|R
40|$|Moving and {{interacting}} with the environment require a reference for orientation and a scale for calibration in space and time. There is {{a wide variety of}} environmental clues and <b>calibrated</b> <b>frames</b> at different locales, but the reference of gravity is ubiquitous on Earth. The pull of gravity on static objects provides a plummet which, together with the horizontal plane, defines a three-dimensional Cartesian frame for visual images. On the other hand, the gravitational acceleration of falling objects can provide a time-stamp on events, because the motion duration of an object accelerated by gravity over a given path is fixed. Indeed, since ancient times, man has been using plumb bobs for spatial surveying, and water clocks or pendulum clocks for time keeping. Here we review behavioral evidence in favor of the hypothesis that the brain is endowed with mechanisms that exploit the presence of gravity to estimate the spatial orientation and the passage of time. Several visual and non-visual (vestibular, haptic, visceral) cues are merged to estimate the orientation of the visual vertical. However, the relative weight of each cue is not fixed, but depends on the specific task. Next, we show that an internal model of the effects of gravity is combined with multisensory signals to time the interception of falling objects, to time the passage through spatial landmarks during virtual navigation, to assess the duration of a gravitational motion, and to judge the naturalness of periodic motion under gravity...|$|R
40|$|In this paper, {{the system}} scheme and system {{architecture}} for transceiver of WIA-PA are presented. The low-IF topology and direct up conversion method are employed, corresponding to receiver part and transmitter part. And in the baseband part, differential and correlation demodulate received signals, {{as well as}} time sync, frequency offset <b>calibrate</b> and <b>frame</b> sync operations are designed for salvation the problem of real radio environmental effects. The chip implements using 0. 18 m CMOS process has small chip area and low power consumption. The minimum sensitivity of receiver is less than - 85 dBm for 1 % PER (packet error rate), which {{is better than the}} required sensitivity for specification...|$|R
40|$|Abstract. <b>Calibrated</b> ACS/WFC science <b>frames</b> {{processed}} {{through the}} CALACS pipeline exhibit a residual offset in their absolute levels {{at the edge}} separating the Amp A-B and Amp C-D quadrants. This effect can be attributed primarily to uncertainties in the bias level subtraction. We present {{an analysis of the}} overscan levels and of the amplitude and behavior of the residual offsets for a large sample of bias frames. The scientific impact of this residual is discussed. 1...|$|R
40|$|This paper {{describes}} a theory and a practical algorithm for the autocalibration of a moving projective camera, from m 5 {{views of a}} planar scene. The unknown camera calibration, and (up to scale) the unknown scene geometry and camera motion are recovered from {{the hypothesis that the}} camera's internal parameters remain constant during the motion. This work extends the various existing methods for non-planar autocalibration to a practically common situation in which {{it is not possible to}} bootstrap the calibration from an intermediate projective reconstruction. It also extends Hartley's method for the internal calibration of a rotating camera, to allow camera translation and to provide 3 D as well as calibration information. The basic constraint is that the projections of orthogonal direction vectors (points at infinity) in the plane must be orthogonal in the <b>calibrated</b> camera <b>frame</b> of each image. Abstractly, since the two circular points of the 3 D plane (representing its Euclidean structu [...] ...|$|R
40|$|A transmission-electron-microscope-based {{orientation}} mapping {{technique that}} {{makes use of}} beam precession to achieve near-kinematical conditions was used to map the phase and crystal orientations in nanolamellar Cu/Nb composites with average layer thicknesses of 86, 30 and 18 nm. Maps of high quality and reliability were obtained by comparing the recorded diffraction patterns with pre-calculated templates. Particular care was taken in optimizing the dewarping parameters and in <b>calibrating</b> the <b>frames</b> of reference. Layers with thicknesses as low as 4 nm were successfully mapped. Heterophase interface plane and character distributions (HIPD and HICD, respectively) of Cu and Nb phases from the samples were determined from the orientation maps. In addition, local orientation relation stereograms of the Cu/Nb interfaces were calculated, and these revealed the detailed layer-to-layer texture information. The results are in agreement with previously reported neutron-diffraction-based and precession-electron-diffraction-based measurements on an accumulated roll bonding (ARB) -fabricated Cu/Nb sample with an average layer thickness of 30 nm as well as scanning-electron-microscope-based electron backscattered diffraction HIPD/HICD plots of ARB-fabricated Cu/Nb samples with layer thicknesses between 200 and 600 nm. close 3...|$|R
40|$|A {{document}} {{discusses the}} focal-plane calibration of the Spitzer Space Telescope {{by use of}} the instrument pointing frame (IPF) Kalman filter, which was described in Kalman Filter for Calibrating a Telescope Focal Plane (NPO- 40798), NASA Tech Briefs, Vol. 30, No. 9 (September 2006), page 62. To recapitulate: In the IPF Kalman filter, optimal estimates of both engineering and scientific focal-plane parameters are obtained simultaneously, using data taken in each focalplane survey activity. The IPF Kalman filter offers greater efficiency and economy, relative to prior calibration practice in which scientific and engineering parameters were estimated by separate teams of scientists and engineers and iterated upon each other. In the Spitzer Space Telescope application, the IPF Kalman filter was used to <b>calibrate</b> 56 <b>frames</b> for precise telescope pointing, estimate > 1, 500 parameters associated with focal-plane mapping, and process calibration runs involving as many as 1, 338 scientific image centroids. The final typical survey calibration accuracy {{was found to be}} 0. 09 arc second. The use of the IPF Kalman filter enabled a team of only four analysts to complete the calibration processing in three months. An unanticipated benefit afforded by the IPF Kalman filter was the ability to monitor health and diagnose performance of the entire end-to-end telescope-pointing system...|$|R
40|$|Abstract The Rockwell {{hardness}} test {{is commonly used}} and accepted by many industrial users, but the hardness value requires conversion between scales because the geometry of the indenters and the load ranges are different. On the other hand, hardness calculation using pyramidal indenters is quite simple and {{can be applied to}} any load range, though it is much more complicated to <b>calibrate</b> the <b>frame</b> compliance and the truncation of indenters in nanoindentation measurement. For this reason, nanoindentation measurement is not yet fully industrially friendly. In order to improve the above situation, newly developed industrial {{hardness test}} methods and a new concept of Equivalent indentation depth (or indentation depth index) were proposed and investigated in this paper. These methods are based on the principle of similarity of Vickers and other pyramidal indenters, and take advantage of the industrial and practical usability of the Rockwell hardness test. Experimental results that covered macroscopic through nanoscopic ranges show that the methods can be applied {{to a wide range of}} test loads. One of the expected advantages of the methods of performing nanoindentation and other instrumented indentation tests (ISO 14577) is that the hardness is not significantly influenced by the frame compliance or the truncation of indenters. Other advantages over conventional hardness tests are also discussed in this paper. More experimental work is necessary to confirm and establish the new methods. Key words new hardness test, similarity, indentation depth index, nanoindentation, Rockwell hardnes...|$|R
40|$|AbstractThis {{manuscript}} {{presents a}} deterministic model to register heterogeneous 3 D data arising from {{a ring of}} eight ultrasonic sonar, one high data density LiDAR (light detection and ranging), and a semi-ring of three visual sensors. The three visual sensors are arranged in a cylindrical ring, and although they provide 2 D colour images, a radial multi-stereo geometric model is proposed to yield 3 D data. All deployed sensors are geometrically placed on-board a wheeled mobile robot platform, and data registration is carried out navigating indoors. The sensor devices in discussion are coordinated and synchronized by a home-made distributed sensor suite system. Mathematical deterministic formulation for data registration is used to obtain experimental and numerical results on global mapping. Data registration relies on a geometric model to compute depth information from a semi- circular trinocular stereo sensor that is proposed to rectify and <b>calibrate</b> three image <b>frames</b> with different orientations and positions, but with same projection point...|$|R
40|$|Distance {{measurements}} using Type Ia Supernovae {{have enabled}} the startling discovery that {{the expansion of}} the universe is accelerating. To determine the nature and the source of this acceleration, systematic uncertainties on distance measurement must be reduced. Due to their importance to high-redshift optical SN Ia cosmology and their sensitivity to dust and progenitor metallicity effects, understanding rest-frame near-UV (NUV) measurements of Type Ia SNe is key to reducing these systematic uncertainties. Unfortunately, the calibration and acquisition of this data is challenging. We use direct comparisons of low-redshift SDSS-II and Carnegie Supernova Project NUV SN Ia photometry to quantify uncertainties on our ability to <b>calibrate</b> observer <b>frame</b> observations, and find that photometry in this region is consistent at the level of 2 % in flux with a 6 % scatter about the mean. Monte Carlo simulated SN Ia samples are used to directly measure Hubble Diagram biases resulting from SN Ia model training. Four simulated SN Ia samples are used to train the SALT-II SN Ia model: two width-luminosity adjustments and two intrinsic scatter models are tested. Adding intrinsic scatter to the training sample yields biased color laws and wavelength-dependent scatter in the NUV region, and causes the color correction parameter β to be systematically underestimated. Assuming a flat ΛCDM cosmology and including BAO and CMB constraints, three of our tests correctly recover the Dark Energy equation of state parameter w. The fourth test gives a w offset of 0. 02, with a 4 -σ significance. The software developed to support this work may be adapted to measure Hubble Diagram biases for any combination of SN Ia model and surveys. ...|$|R
40|$|Bibliography: pages [54]- 56. This {{study was}} {{conducted}} to analyze cinematographically the takeoff phase of the long jump as performed by competitive long jumpers of various performance levels. Variations in approach velocity and the distance jumped were also observed. Six long jumpers, who were considered to represent the upper 20 % of their performance level, were chosen from each of three performance levels: college, high school, and junior high school. During film processing the second college jumper's data were lost, thus resulting in one college jumper, which was the better of the two in personal best and in test results. All subjects were filmed performing the long jump with a maximum of five jumps each, allowing for at least one good jump. Film data of the takeoff were obtained by means of a 15 mm high speed motion picture camera. Approach velocities were obtained by marking known distances on the runway and <b>calibrating</b> the <b>frame</b> rate of the video tape recorder. Prior to filming, all subjects were prepared by placing 4 in. black dots in position to represent the major joint centers of the body. Film analysis was accomplished {{through the use of a}} Numonics digitizer and an Apple 11 + microcomputer. Segmental representations of the body were generated through film analysis and used to determine displacement, velocity, and acceleration of the jumper's center of gravity. Conclusions drawn from this study indicated that the mechanics used by all subjects were basically similar and tended to support commonly accepted mechanical parameters. Findings showed similarities in approach velocity patterns and the percentage of the approach distance necessary to reach maximal velocity, with only small variations in the takeoff. Large differences were apparent only in the percentage of velocity lost throughout the takeoff. The lower performance levels experienced greater degrees of negative acceleration throughout the takeoff. These results were related to a misapplication of vertical force prior to the subject's center of gravity moving to a position over the takeoff foot. M. S. (Master of Science...|$|R
40|$|Chest {{radiography}} {{is one of}} {{the most}} commonly performed radiographic examinations worldwide. Routinely acquired in the erect posteroanterior (PA) position, a chest radiograph displays substantial amounts of medical information when accurate patient positioning is achieved. However, a rotated PA chest radiograph has reduced diagnostic quality and appearances may mask or mimic chest pathology. Radiographic assessment of patient rotation around the sagittal plane has traditionally been undertaken by assessing the distance between the medial end of the clavicles and a line drawn through the spinous processes at the level of the clavicles. This approach continues to be advocated in radiographic technique textbooks internationally although no identified author has provided criteria to determine when a rotated PA chest radiograph should be repeated; determined the relationship between perceived clavicle to spinous process distance and actual degree of patient rotation; or considered the impact of body morphology, in particular the anteroposterior thoracic diameter, on radiographic appearances of rotation. Objectives To determine the impact of anteroposterior chest diameter on radiographic appearances of sagittal rotation on PA chest radiographs. Design Experimental study. Methods and Settings Sixty computed tomography thorax examinations, stratified for gender, were reviewed and data aggregated to determine average anteroposterior (AP) thoracic dimensions. A bespoke experimental unit was constructed specifically to enable testing of the impact of sagittal rotation on radiographic appearances. The experimental unit was situated within a <b>calibrated</b> circular <b>frame</b> enabling 360 ° rotation at 1 ° intervals around a central rotational point. The experimental unit components were varied in 1 cm intervals from 9 cm to 15 cm around the central rotation point to reflect varying AP chest diameters. At each interval, images were acquired at 0, 2, 5, 7, 10, and 15 ° sagittal rotation using a horizontal central ray, consistent centring point, and a source-image distance of 180 cm. Results A clear linear relationship between AP thoracic diameter and the radiographic appearances of sagittal rotation was noted. Considering significant rotation to be when the medial end of clavicle overlaps the spinous process on the radiographic image, this appearance occurred at a much smaller degree of rotation on wide AP thoracic diameters (15 cm, 5 °) than narrower AP thoracic diameters (9 cm, 10 °). Conclusions The routine application of the distance between the medial end of the clavicles and a line drawn through the spinous processes at the level of the clavicles as a method of assessing degree of sagittal rotation, diagnostic image quality, and need for repeat is flawed. Persistence in the application of this approach without cognisance of the impact of body morphology on radiographic appearances will result in persons with large AP thoracic diameters being more likely to have a PA chest radiograph repeated for a specified degree of rotation than persons with smaller AP thoracic diameters. © 2015 Elsevier. Reproduced in accordance with the publisher's self-archiving policy...|$|R
40|$|Receivers able {{to track}} {{satellites}} belonging to different GNSSs (Global Navigation Satellite Systems) {{are available on the}} market. To compute coordinates and velocities it is necessary to identify all the elements that contribute to interoperability of the different GNSSs. For example the timescales kept by different GNSSs have to be aligned. Receiver-specific biases, or firmware-dependent biases, need to be <b>calibrated.</b> The reference <b>frame</b> used in the representation of the orbits must be unique. In this paper we address the interoperability issues from the standpoint of a Single Point Positioning (SPP) user, i. e., using pseudoranges and broadcast ephemeris. The biases between GNSSs timescales and receiver-dependent biases are analyzed for a set of 31 MGEX (Multi-GNSS Experiment) stations over a time span of more than three years. Time series of biases between timescales of GPS (Global Positioning System), GLONASS (Global Navigation Satellite System), Galileo, BeiDou, QZSS (Quasi-Zenith Satellite System), SBAS (Satellite Based Augmentation System) and NAVIC (Navigation with Indian Constellation) are investigated, in addition to the identification of events like discontinuity of receiver-dependent biases due to firmware updating. The GPS broadcast reference frame is shown to be aligned to the one (IGS 14) realized by the precise ephemeris of CODE (Center for Orbit Determination in Europe) to within 0. 1 m and 2 milliarcsec, with values dependent on whether IIR-A, IIR-B/M or IIF satellite blocks are considered. Larger offsets are observed for GLONASS, up to 1 m for GLONASS K satellites. For Galileo the alignment of the broadcast orbit to IGS 14 /CODE is again at the 0. 1 m and several milliarcsec level, with the FOC (Full Operational Capability) satellites slightly better than IOV (In Orbit Validation). For BeiDou an alignment of the broadcast frame to IGS 14 /CODE comparable to GLONASS is observed, regardless of whether IGSO (Inclined Geosynchronous Orbit) or MEO (Medium Earth Orbit) satellites are considered. For all satellites, position differences according to the broadcast ephemeris relative to IGS 14 /CODE orbits are projected to the radial, along-track and crosstrack triad, with the largest periodic differences affecting mostly the along track component. Sudden discontinuities at the level of up to 1 m and 2 – 3 ns are observed for the along-track component and the satellite clock, respectively. The time scales of GLONASS, Galileo, QZSS, SBAS and NAVIC are very closely aligned to GPS, with constant offsets depending on receiver type. The offset of the BeiDou time scale to GPS has an oscillatory pattern with peak-to-peak values up to 100 ns. To characterize receiver-dependent biases the average of six Septentrio receivers is taken as reference, and relative offsets of the other receiver types are investigated. These receiver-dependent biases may depend on the individual station, or for the same station on the update of the firmware. A detailed calibration history is presented for each multiGNSS station studied...|$|R
40|$|The {{purpose of}} this thesis is the {{analysis}} and evaluation of methods to orient a strip of images using an automated approach. Automatic orientation of strips of video frame imagery would facilitate the construction of three dimensional models with less demand on a human operator for tedious measurement. Often one has no control points, so only relative orientation is possible. The relative orientation process gives camera parameters such as attitudes and selected baseline components {{and it can be}} implemented by using either collinearity or coplanarity equations. To automate the point selection, the pass and/or tie points were detected by the Colored Harris Laplace Corner detector along a strip of images and they were matched by cross correlation across multiple scales. However, the matched points from cross correlation still include the outliers. Therefore, the Random Sample Consensus (RANSAC) method with the essential matrix was applied to detect only inliers of point pairs. Then relative orientation was performed for this series of video imagery using the coplanarity condition. However, {{there is no guarantee that}} three rays for a single point will intersect in a single point. Therefore for all photos, subsequent to the first one, the scale restraint equation was applied along with the coplanarity equation to ensure these three rays 2 ̆ 7 intersection. At this point, the Kalman Filtering algorithm was introduced to address the problem of uncompensated systematic error accumulation. Kalman Filtering is more parsimonious of computing effort than Simultaneous Least Squares, and it gives superior results compared with Cantilever Least Squares models by including trajectory information. ^ To conform with accepted photogrammetric standards, the camera was <b>calibrated</b> with selected <b>frames</b> extracted from the video stream. For the calibration, minimal constraints are applied. Coplanarity and scale restraint equations in relative orientation were also used for initial approximation for the nonlinear bundle block adjustment to accomplish camera calibration. For calibration imagery, the main building of the bell tower at the University of Texas was used as an object because it has lots of three dimensional features with an open view and the data could be acquired at infinity focus distance. Another two sets of calibrations were implemented with targets placed inside of a laboratory room. ^ The automated relative orientation experiment was carried out with one terrestrial, one aerial and another simulated strip. The real data was acquired by a high definition camcorder. Both terrestrial and aerial data were acquired at the Purdue University campus. The terrestrial data was acquired from a moving vehicle. The aerial data of the Purdue University campus was acquired from a Cessna aircraft. The results from the aerial and simulation cases were evaluated by control points. The three estimation strategies are stripwise Simultaneous, Kalman Filtering and Cantilever, all employing coplanarity equations. For the aerial and simulation case, an absolute comparison was made between the three experimental techniques and the bundle block adjustment. In all cases, the relative solutions were transformed to ground coordinates by a rigid body, 7 -parameter transformation. In retrospect, the aerial case was too short (8 photographs) to demonstrate the compensation of strip formation errors. Therefore a simulated strip (30 photographs) was used for this purpose. Absolute accuracy for the aerial and simulation approaches was evaluated by ground control points. Precision of each approach was evaluated by error ellipsoid at each intersected point. Also memory occupancy for each approach was measured to compare resource requirements for each approach. When considering computing resources and absolute accuracy, the Kalman Filter solution is superior compared with the Simultaneous and the Cantilever methods. ...|$|R

