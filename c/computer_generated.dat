3668|1236|Public
5|$|The {{visual effects}} supervisor, John Sullivan, hired Arc Productions to create just under 500 shots with <b>computer</b> <b>generated</b> imagery, between a quarter {{and a third}} of what a {{blockbuster}} film would feature. The Covenant that appear are all completely <b>computer</b> <b>generated,</b> as is the academy's space elevator, weapons' muzzle flashes and a few shots of Master Chief. Hendler felt that the visual effects were the area that needed particular focus and spent a much larger percentage of the budget on the Master Chief costume and <b>computer</b> <b>generated</b> imagery than is normal for a production.|$|E
5|$|The missile silo {{used for}} the episode's climactic scene was {{incomplete}} when the scene was filmed, as the crew {{did not have enough}} time or money left to complete the set. The crew built the incomplete silo on a sound stage around a completed spacecraft prop, and were able to digitally extend the set with <b>computer</b> <b>generated</b> interiors to give the impression of a much larger silo. Exterior shots of the silo building were also enhanced digitally, with various buildings and machinery created with <b>computer</b> <b>generated</b> imagery and composited into the exterior shots.|$|E
5|$|The opening {{sequences}} of each episode show Cortana, an artificial intelligence, aboard the spaceship Forward Unto Dawn as she malfunctions. The five sequences were entirely <b>computer</b> <b>generated</b> by Polynoid, the animation team of Blacklist, a production company.|$|E
40|$|A <b>computer</b> system {{automatically}} <b>generates</b> CNC {{code for}} a stitching machine. The computer determines {{the locations of}} a present stitching point and a next stitching point. If a constraint is not found between the present stitching point and the next stitching point, the <b>computer</b> <b>generates</b> code for making a stitch at the next stitching point. If a constraint is found, the <b>computer</b> <b>generates</b> code for changing a condition (e. g., direction) of the stitching machine's stitching head...|$|R
25|$|Position keeper: This <b>computer</b> <b>generates</b> a {{continuously}} updated {{estimate of}} the target position based on earlier target position measurements.|$|R
5000|$|The player {{must first}} specify {{the number of}} snipes, hives and {{difficulty}} before they play. Each game is different because the <b>computer</b> <b>generates</b> a random new maze.|$|R
5|$|At 33 seconds a neon monster, {{with the}} 'SFA' logo on his chest, appears amongst the {{translucent}} buildings. More {{shots of the}} band and the <b>computer</b> <b>generated</b> city follow before the monster reappears during the second chorus, this time with electric bolts shooting from his body. As the track reaches its middle 8 a multicoloured neon spacecraft appears.|$|E
5|$|Like its predecessor, Riven is a {{point and}} click {{adventure}} game played from a first-person perspective. The player explores immersive environments depicted through a large series of <b>computer</b> <b>generated</b> stills using mouse clicks for movement or to manipulate objects within reach. By operating mechanical contraptions and deciphering codes and symbols discovered in the surroundings, the vaguely explained goal can eventually be reached.|$|E
5|$|GoldenEye was {{the last}} film of special effects {{supervisor}} Derek Meddings, to whom the film was dedicated. Meddings' major contribution was miniatures. It {{was also the first}} Bond film to use <b>computer</b> <b>generated</b> imagery. Among the model effects are most external shots of Severnaya, the scene where Janus' train crashes into the tank, and the lake which hides the satellite dish, since the producers could not find a round lake in Puerto Rico. The climax in the satellite dish used scenes in Arecibo, a model built by Meddings' team and scenes shot with stuntmen in Britain.|$|E
5000|$|The Rise of Exotic Computing is {{composed}} {{in a single}} movement and has a duration of roughly 12 minutes. [...] The music critic Mark Kanny wrote, [...] "The piece {{was inspired by the}} idea of synthetic computing - <b>computers</b> <b>generating</b> their own ideas." ...|$|R
40|$|A BBC {{microcomputer}} {{was incorporated}} into a closed circuit television system while it was being used to show microscope slides. The <b>computer</b> <b>generates</b> screens of text that complement the demonstration of the microscopy. An additional feature is {{the capacity of the}} system to produce 35 mm transparencies...|$|R
50|$|The website {{allows users}} to specify {{the name of the}} {{individual}} or company that the complaint is directed toward, as well as the number of paragraphs the complaint will be. After submitting the data, the <b>computer</b> <b>generates</b> sentences that are composed of arbitrary verbs, nouns, and adjectives.|$|R
5|$|The {{blood that}} spurts {{out of the}} Klingon's wounds was created using <b>computer</b> <b>generated</b> imagery; the animators {{had to make sure}} that the blood floated in a convincing manner while still looking {{interesting}} and not too gory. The effects artist looked at NASA footage of floating globules of water to inform the physics of the blood particles. Initially, the blood was to be colored green, but the filmmakers realized that McCoy had referred to Spock as green-blooded.|$|E
5|$|The film saw {{breakthrough}} in <b>computer</b> <b>generated</b> effects. About 1,950 {{of the shots}} in The Phantom Menace have visual effects. The scene in which toxic gas is released on the Jedi is the only sequence with no digital alteration. The work was so extensive that three visual effects supervisors divided the workload among themselvesJohn Knoll supervised the on-set production and the podrace and space battle sequences, Dennis Muren supervised the underwater sequence and the ground battle, and Scott Squires, alongside teams assigned for miniature effects and character animation, worked on the lightsaber effects.|$|E
5|$|When {{a pattern}} is called digital, this most often {{means that it}} is visibly {{composed}} of computer-generated pixels. The term is sometimes also used of <b>computer</b> <b>generated</b> patterns like the non-pixellated Multicam and the Italian fractal Vegetato pattern. Neither pixellation nor digitization contribute to the camouflaging effect. The pixellated style, however, simplifies design and eases printing on fabric, compared to traditional patterns. While digital patterns are becoming widespread, critics maintain that the pixellated look {{is a question of}} fashion rather than function.|$|E
40|$|Redundant command lines use two {{different}} "true" signals to avoid common failure modes. When function {{is required to}} operate, <b>computer</b> <b>generates</b> command and transmits it to demultiplexer, where it is split along two paths, producing outputs from separate electronic cards. Outputs combine to drive AND gate high and begin function...|$|R
5000|$|A TFM file {{is broken}} down {{into a series of}} four-byte words, which can contain data fields of various lengths. Any data fields that are more than one byte long are held in big endian order. (The exact same file will be generated, {{regardless}} of architecture of the <b>computer</b> <b>generating</b> it.) ...|$|R
5000|$|Word Soup - (a {{new name}} for Word Up) Here the <b>computer</b> <b>generates</b> a [...] "random" [...] matrix of letters with {{different}} point values {{based upon the}} machine's 'willingness' to pay out, players must form English words from adjoining letters {{in order to reach}} a predetermined prize target which ranges from 450-2100 points. '''' ...|$|R
5|$|Zoe Saldana as Neytiri, the {{daughter}} of the leader of the Omaticaya (the Na'vi clan central to the story). She is attracted to Jake because of his bravery, though frustrated with him for what she sees as his naiveté and stupidity. She serves as Jake's love interest. The character, like all the Na'vi, was created using performance capture, and its visual aspect is entirely <b>computer</b> <b>generated.</b> Saldana has also signed on for potential sequels.|$|E
5|$|D is {{a horror}} themed {{interactive}} movie and adventure game developed by WARP {{and directed by}} Kenji Eno. It is the first entry in the D series and was first published by Panasonic for the 3DO Interactive Multiplayer in 1995, later being ported to the Sega Saturn, PlayStation, and MS-DOS. The story follows Laura Harris as she goes to investigate a hospital after learning her father went on a mass murdering spree and barricaded himself inside. The hospital morphs into a castle upon her arrival, which she must explore to find her father. The player controls Laura through <b>computer</b> <b>generated</b> full motion video (FMV) sequences, and must complete the game within two hours without a save or pause function.|$|E
5|$|Owens did {{not have}} time to {{complete}} the shot before the Cannes screenings, but afterwards he used cineSync to conduct most of the work from home. The shot includes two blocks of computer-generated buildings that recede into the distance of a downtown set extension. As Collins disappears into the crowd about a minute into the shot, the live footage is gradually joined with more digital work. The streetcars, tracks and power lines were all <b>computer</b> <b>generated.</b> Live-action extras appear for the first minute of the shot before being replaced by digital ones. The shot was made more complicated by the need to add Massive extras. Owens constructed the scene by first building the digital foreground around the live action footage. He then added the background before filling the scene with vehicles and people.|$|E
5000|$|Text mode demos [...] - [...] <b>computer</b> {{animations}} <b>generated</b> in {{text mode}} ...|$|R
50|$|In {{a typical}} first-person shooter (FPS) deathmatch session, players connect {{individual}} computers together via a computer network in a peer-to-peer model or a client-server model, either locally {{or over the}} Internet. Each individual <b>computer</b> <b>generates</b> the first person view that the computer character sees in the virtual world, hence the player sees {{through the eyes of}} the computer character.|$|R
40|$|Abstract. We address {{parallel}} jobs {{scheduling problem}} for computational GRID systems. We concentrate on two-level hierarchy scheduling: {{at the first}} level broker allocates computational jobs to parallel computers. At the second level each <b>computer</b> <b>generates</b> schedules of the parallel jobs assigned to it by its own local scheduler. Selection, allocation strategies, and efficiency of proposed hierarchical scheduling algorithms are discussed. ...|$|R
5|$|Overseeing {{the visual}} effects {{department}} for New Moon was Susan MacLeod, {{who had previously}} worked with Weitz during the production of The Golden Compass. MacLeod enlisted Tippett Studio to create the <b>computer</b> <b>generated</b> wolves, while Prime Focus of Vancouver handled {{the effects of the}} vampires. To prepare for the aggressive task of making the wolves look real, Tippet artists studied wolf culture. They also were able to reflect leadership and human muscle size by adjusting certain features of the wolves, such as their fat and tallness. In February 2009, a group of artists were able to travel to Wolf Mountain Sanctuary, outside of Los Angeles, and see real wolves. The artists were able to observe the behavior of both the timber and arctic wolves, who ran in packs of three to five. The idea was to give everyone a deeper feeling of the creature that they were creating.|$|E
5|$|Principal {{photography}} {{took place}} over approximately 10 weeks on a $20 million budget. Filming began in China in December 2010 in locations including the city of Shanghai and Hengdian World Studios, and continued until March 2011. Corey Yuen was the film's action choreographer. To compensate for time lost to filming issues, some scenes were filmed in a single take. Approximately 6 weeks into filming, RZA began pushing the crew to work faster to remain on schedule. His assistant director eventually informed RZA {{that because of the}} push, some stunt workers were injured and being sent to hospital. After this, RZA abandoned some of his intended shots and replaced them with <b>Computer</b> <b>Generated</b> Images (CGI). Roth also directed some shots for RZA. Crowe and Le were originally scripted to fight each other, but because of Crowe's limited shooting schedule, {{he did not have the}} time to rehearse the fight, and instead Le was scripted to fight Liu.|$|E
5|$|The Expendables 2 {{contains}} approximately 1,547 {{digital effect}} shots. The main effects studio was Worldwide FX (WWFX), which produced 1,186 of the shots, and a further 800 shots which were discarded {{in response to}} changes to the film's story. Several other studios, including El Ranchito, Malditochrome, Tata Elxsi, Reliance Mediaworks, and , also produced effects shots for the film through WWFX. Digital effect pre-production began in July 2011 and was completed one year later. WWFX's primary facility is situated in Sofia, allowing them to have constant access to the production, and model assets of the sets before their practical versions were built; this enabled WWFX to raise issues relating to the designs early and develop an optimised construction plan. Anything that was considered to potentially need a <b>computer</b> <b>generated</b> double was photographed and digitally modeled {{even if it was}} not scheduled to appear in the film, which later served useful as the film's story was adjusted, requiring WWFX to rebuild entire scenes.|$|E
50|$|The {{on-board}} <b>computer</b> <b>generates</b> two speed-thresholds {{based on}} the received signals from the balises. If the train is over the speed limit, passing the first speed-threshold, an audible alarm sounds and the control panel indicates to the driver to adjust the train speed without delay. If the second speed threshold is passed, the KVB automatically engages emergency brakes on the train.|$|R
40|$|Elliptic method generates {{composite}} grids about three-dimensional aircraft body. Grid {{lines on}} surface of wing and body vary in spacing, depending on {{level of detail}} needed to model airflow accurately in region. Grid intervals for zone might be unchanged in one direction, halved in second orthogonal direction, and reduced to much finer spacing in third direction. <b>Computer</b> <b>generates</b> grids {{with little or no}} human intervention...|$|R
40|$|AbstractHolographic {{presentation}} of three-dimensional data from CT, NMR, PET or ultrasonic scan should greatly aid in diagnostic and therapeutic procedures. Originally a multiplex white light hologram was formed from many X-rays of a cadaver's hand. Many methods of <b>computer</b> <b>generating</b> a hologram have been explored. In this paper we examine {{a method of}} calculating an Image Plane Hologram by computer and show the white light characteristics of the Image Plane Hologram...|$|R
5|$|The four-minute ride uses 85-foot IMAX Dome {{screens and}} Sony Projectors. There are 24 ride cars, each seating eight people, and {{approximately}} 2000 people can ride it per hour. The projection system uses four overlapping Sony SXRD 4K resolution projectors on each dome, using custom-made semi-circular fisheye lenses to project undistorted images {{at a rate}} of 60 frames per second (in comparison, most feature films project at 24 frames per second). The video is projected onto two dome screens which are made of 416 panels (each 4feet by two feet) and are approximately 80feet tall and 85feet wide. The animation in the ride uses <b>computer</b> <b>generated</b> 3D animation rendered by Blur Studio and Reel FX, rather than the traditional 2-D animation seen on The Simpsons and the queue and pre-show of the ride. The animation reference was provided by Film Roman, the animation studio that animates the series. Each car contains 12 speakers and a Dolby 6.1 surround sound, while the domes contain an additional 90 speakers.|$|E
5|$|Seoul unit {{director}} Dan Glass and Jim Mitchell {{were the}} visual effects supervisors {{of the first}} season. The season had a total VFX shot count of about 1200. An in-house VFX team was established in Chicago which completed over 700 shots. The major external VFX vendors were Locktix VFX (160-180 shots), Technicolor VFX (over 100 shots) and Encore VFX. Additional work was done by Studio 8 FX, Trace VFX and Almost Gold. Because of the series' tight budget and timeline the production {{made the decision to}} do most of the effects in-camera and only enhance them digitally where appropriate. In fact for a great number of shots which involved the sensates communicating and visiting each other telepathically the cast were simply moving {{in and out of the}} frame in timely fashion requiring no additional work. According to Glass, most of the VFX work that was done is invisible in the final show and consisted mostly of split-screens, crew and rig removal, weather augmentation and screen inserts. Executive producer Grant Hill commented he would be impressed if one would be able to recognize as many as 150 of the 1200 VFX shots, because most of them consisted of small things used to help the narrative, and they do not call attention to themselves. Of the more visible work done, Glass provided the examples of age manipulation of actors, dramatic enhancement of the weather in the car scenes in Iceland, a few greenscreens, and <b>computer</b> <b>generated</b> blades, blood and wounds.|$|E
5|$|While filming in Washington, D.C., {{the crew}} {{shot on the}} National Mall, and Bay stated {{that there would be}} a car race on the location. Two further {{locations}} announced were the Milwaukee Art Museum and the former Tower Automotive complex on Milwaukee's north side, then under redevelopment for mixed use as well as the city's equipment yard. Filming was scheduled to take place there after work was done in Chicago. On September 23, scenes were filmed at the former city hall in Detroit. On October 16, a scene in the later-1960s was shot at the Johnson Space Center in Houston, utilizing extras with period fashion and hairstyles. One day of shooting was also spent at the Angkor Wat temple complex in Cambodia. Other planned filming locations included Africa and China. Though about 70% of the film's live action footage was shot in 3-D using Arri Alexa and Sony F35 cameras, more than half of the film still had to be converted into 3-D in post production to fix technical flaws 3-D filming produces. Other footage that needed to be converted into 3-D in post production was either entirely <b>computer</b> <b>generated</b> or shot in the anamorphic format on 35mm film. 35mm film was used for scenes filmed in slow motion and scenes such as closeups of faces or shots of the sky which required higher image quality than the HD digital 3-D cameras could provide. 35mm cameras were also used for scenes where the 3-D cameras proved to be too heavy, or were subject to strobing or electrical damage from dust. Principal photography officially concluded on November 9, 2010.|$|E
40|$|In our information-rich world, <b>computers</b> <b>generate</b> so much {{data that}} it comprehending and {{understanding}} {{it in its}} raw form is difficult. Visual representations are imperative {{if we are to}} understand even a small part of it. In addition or as an alternative to visual mappings we could map information into nonvisual forms, any form that stimulates any of our senses: from auditory, haptic, olfactory, and gustatory to vestibular...|$|R
40|$|Abstract ⎯ Web surfing, e-mail (electronic mail), chat {{and still}} the mere use of a <b>computer,</b> <b>generate</b> inside the {{interpersonal}} communication what we denominate a “protected environment". We have defined protected environment to be the type of communication in which the risk of personal exhibition does not exist. We base ourselves in {{that is a very}} frequent practice in the chat, for example, the use of an alias instead of the use of the name...|$|R
50|$|Another typical use is to {{generate}} periodic interrupts {{by dividing the}} output of a crystal oscillator and having an interrupt handler count the interrupts {{in order for a}} processor to keep time. These periodic interrupts are often used by the OS's task scheduler to reschedule the priorities of running processes. Some older <b>computers</b> <b>generated</b> periodic interrupts from the power line frequency because it was controlled by the utilities to eliminate long-term drift of electric clocks.|$|R
