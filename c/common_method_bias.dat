99|10000|Public
50|$|Using {{simulated}} data sets, Richardson et al. (2009) investigate three ex post {{techniques to}} test for common method variance: the correlational marker technique, the confirmatory factor analysis (CFA) marker technique, and the unmeasured latent method construct (ULMC) technique. Only the CFA marker technique turns out to provide some value. A comprehensive example of this technique has been demonstrated by Williams et al. (2010). Kock (2015) discusses a full collinearity test that is successful {{in the identification of}} <b>common</b> <b>method</b> <b>bias</b> with a model that nevertheless passes standard convergent and discriminant validity assessment criteria based on a CFA.|$|E
30|$|We adopted {{classical}} survey {{procedure and}} statistical control technique {{to minimize the}} <b>common</b> <b>method</b> <b>bias</b> issues (Chung et al. 2015). After statistical analysis (factor analysis), we found {{that there are no}} <b>common</b> <b>method</b> <b>bias</b> issues in the data set.|$|E
30|$|Since {{this study}} uses {{subjective}} measures for dependent and independent variables, {{there is a}} risk for <b>common</b> <b>method</b> <b>bias</b> which results {{from the fact that the}} respondents provide these measures by a common rater (Podsakoff et al. 2003). To examine the existence of <b>common</b> <b>method</b> <b>bias,</b> Harman’s single-factor test was conducted. Five factors were drawn out and the largest factor explained 24.32  % of the total variance.|$|E
40|$|Background: Researchers {{have yet}} to fully explore and {{adequately}} measure Professional Identity (PI) in nursing. Objectives: This paper aims to examine the psychometrics of five measures of PI and compare these results in first and third year nursing students. As a consequence of utilising multiple self-assessed survey tools this study also examines <b>common</b> <b>methods</b> <b>bias.</b> Design: The study utilised an on-line survey to gather responses from nursing students. Methods: The pilot study examined the validity and reliability of the five measures while investigating the potential for <b>common</b> <b>methods</b> <b>bias.</b> Results: All five measures tested demonstrated poorer psychometric properties or model fits for this sample than those reported by their original authors. One measure demonstrated a small mean score increase from first to third year, while all others revealed a fall from first to third year, although these were not significant. Harman 2 ̆ 7 s tests performed on all scales were negative for <b>common</b> <b>methods</b> <b>bias.</b> Conclusions: A psychometrically strong measure of PI was not determined however, this may relate to the sample size in this pilot study. The fall of PI from first to third year and {{the factors that influence}} such change may have implications for the recruitment and retention of nurses...|$|R
30|$|Fourth, {{surveys are}} subject to several {{possible}} <b>biases.</b> For example, <b>common</b> <b>method</b> <b>biases</b> could have distorted the results (Podsakoff et al. 2003). While we have addressed the major <b>common</b> <b>method</b> <b>biases</b> relevant to our research, which are the common scale bias and the consistency motif bias, by randomising {{the order of the}} questions (also cf. Hull and Wright 1990) and, for example, placing questions about research methods and journal rankings at different places in the questionnaire, some additional limitations might nonetheless exist. Like other perception studies, we also suffer from not knowing the context from which respondents acted as judges when they evaluated the journals (Milne 2002; Weber and Stevenson 1981). We tested for possible non-response bias in that we compared those participants who took part after the final call (n =  36) with the rest of our sample with regard to the assessments of familiarity with journals. We did not detect any significant differences with regard to either group.|$|R
50|$|Podsakoff, P., & Organ, D. (1986). Self-reports in {{organizational}} research: Problems and prospects. Journal of Management, 12, 531-544.Podsakoff, P., & Todor, W. D. (1985). Relationships between leader reward and punishment behavior andgroup processes and productivity. Journal of Management, 11, 55-73.Podsakoff, P. M., MacKenzie, S. B., Lee, J. Y., & Podsakoff, N. P. (2003). <b>Common</b> <b>method</b> <b>biases</b> inbehavioral research: A critical {{review of the}} literature and recommended remedies. Journal of AppliedPsychology, 88, 879-903.|$|R
40|$|<b>Common</b> <b>method</b> <b>bias</b> is a {{potentially}} serious methodological problem in research in marketing. Several statistical remedies {{have been proposed}} in the literature, and used by academic researchers. MacKenzie and Podsakoff (2012) identify the causes of <b>common</b> <b>method</b> <b>bias,</b> and then provide a set of procedural remedies that might prevent the occurrence of the problem. In this commentary, we expand on their contribution by articulating {{the different types of}} measurement error that could occur in survey research, how a procedural remedy might simultaneously affect more than one type of error, and how <b>common</b> <b>method</b> <b>bias</b> might manifest itself in the domain of stimulus-centered measures. © 2012 New York University. Published by Elsevier Inc. All rights reserved...|$|E
30|$|Using {{the same}} method {{to collect data}} on {{dependent}} and independent variables involves a risk that results may be influenced by <b>common</b> <b>method</b> <b>bias.</b> However, the results indicated that the influence of leadership on the ILT of the VET-students was attributable only to supervisors’, and not to teachers’ leadership. If the relation found were due to <b>common</b> <b>method</b> <b>bias,</b> similar relational patterns would have been expected for both categories.|$|E
3000|$|The one-factor model also {{provides}} a test for <b>common</b> <b>method</b> <b>bias</b> (Podsakoff, et al., 2003). The hypothesized measurement model fit the data better than a single factor model: χ [...]...|$|E
40|$|The {{issue of}} <b>common</b> <b>method</b> {{variance}} and <b>bias</b> in Indonesia {{still has not}} gained much attention; even the terminology is less popular, except among psychometric enthusiasts and experts. In fact, the potential for <b>common</b> <b>method</b> variance and <b>bias</b> infiltrating in research results is very high, especially in studies that use a single method, a single source, and concurrent design, which are highly favored by psychological lecturers and researchers in Indonesia. This paper is a critical review, exposing the debate and serious impact regarding <b>common</b> <b>method</b> variance and <b>bias,</b> as well as procedures for detecting, addressing and correcting its effects. The author hoped this paper contributes in filling {{the gap in the}} literature, especially in Psychology Research Methodology text books in the Indonesian language, so that psychological researches in Indonesia continue to increase their quality and to have their better place in international publications...|$|R
40|$|Despite {{recurring}} {{concerns about}} <b>common</b> <b>method</b> variance (CMV) in survey research, the information systems (IS) community remains largely uncertain {{of the extent}} of such potential biases. To address this uncertainty, this paper attempts to systematically examine the impact of CMV on the inferences drawn from survey research in the IS area. First, we describe the available approaches for assessing CMV and conduct an empirical study to compare them. From an actual survey involving 227 respondents, we find that although CMV is present in the research areas examined, such biases are not substantial. The results also suggest that few differences exist between the relatively new marker-variable technique and other well-established conventional tools in terms of their ability to detect CMV. Accordingly, the marker-variable technique was employed to infer the effect of CMV on correlations from previously published studies. Our findings, based on the reanalysis of 216 correlations, suggest that the inflated correlation caused by CMV may be expected to be on the order of 0. 10 or less, and most of the originally significant correlations remain significant even after controlling for CMV. Finally, by extending the marker-variable technique, we examined the effect of CMV on structural relationships in past literature. Our reanalysis reveals that contrary to the concerns of some skeptics, CMV-adjusted structural relationships not only remain largely significant but also are not statistically differentiable from uncorrected estimates. In summary, this comprehensive and systematic analysis offers initial evidence that (1) the marker-variable technique can serve as a convenient, yet effective, tool for accounting for CMV, and (2) <b>common</b> <b>method</b> <b>biases</b> in the IS domain are not as serious as those found in other disciplines. <b>common</b> <b>method</b> variance, <b>method</b> <b>biases,</b> marker variable, logit analysis, path analysis...|$|R
40|$|Benbasat and Barki (2007) {{argue that}} TAM {{has been both}} a blessing and curse for the IS field and they detail reasons why this is the case. Our {{response}} to their critique is to highlight areas of agreement, disagree with one of their assertions, and extend their thinking along another, related line. Specifically, we agree that some TAM constructs, namely perceived usefulness and system usage, {{need to be more}} closely examined in order to break up the "black box " portrayal of these concepts. Our view of Benbasat and Barki's characterization of TAM as unassailable is that <b>common</b> <b>methods</b> <b>bias</b> has never been well tested and that TAM linkages may in fact be methodological artifacts. Finally, it is argued that the field desperately needs more parsimony in TAM models and that meta-analysis is one good way of achieving this goal...|$|R
30|$|Common method biases {{may occur}} when data is {{collected}} via only one method (survey {{in the case}} of this study), or via the same method but only at one point in time (Straub et al. 2004). This may result in a variance that the items have in common with each other due to the data collection method rather than the hypothesized relationships between constructs or between measures and constructs. To assess whether or not potential <b>common</b> <b>method</b> <b>bias</b> was a significant issue (Malhotra et al. 2006), we performed Harman’s one-factor test to all reflective items (Podsakoff et al. 1986). The test was done by entering all constructs into an unrotated principal components factor analysis and examining the resultant variance. <b>Common</b> <b>method</b> <b>bias</b> threat is high if a single factor accounts for more than 50 % of the variance (Podsakoff et al. 1986). The analysis revealed that there was no single factor which explained a substantial amount of variance (the most covariance explained by one factor is only 35 %, see the last row of Table 6), which indicates that <b>common</b> <b>method</b> <b>bias</b> does not pose a significant threat to the measurement validity of this study (Chin et al. 2012). To decrease the possibility of <b>common</b> <b>method</b> <b>bias,</b> we also distributed (not grouped together) the items that represent one construct in the questionnaire (Gregor & Klein 2014).|$|E
30|$|Although the {{information}} collected was self-reported and variables were largely measured objectively, <b>common</b> <b>method</b> <b>bias</b> {{was not a}} concern in this study. This {{was supported by the}} results of a factor analysis (Podsakoff and Organ 1986).|$|E
40|$|Recent work, in {{journals}} such as MIS Quarterly and Management Science, has {{highlighted the}} importance of evaluating the influence of <b>common</b> <b>method</b> <b>bias</b> (CMB) {{on the results of}} statistical analysis. In this research note, we assess the utility of the unmeasured latent method construct (ULMC) approach in partial least squares (PLS), introduced by Liang et al. (2007). Such an assessment of the ULMC approach is important, because it has been employed in 76 studies since it appeared in MIS Quarterly in early 2007. Using data generated via Monte Carlo simulations, we use PLS structural equation modeling (SEM) to demonstrate that the ULMC approach of Liang et al. is neither able to detect, nor control for, <b>common</b> <b>method</b> <b>bias.</b> Method estimates using this approach resulted in negligible estimates, regardless of whether there were some, large, or no method bias introduced in the simulated data. Our study contributes to the IS and research methods literature by illustrating that, and explaining why the ULMC approach does not accurately detect <b>common</b> <b>method</b> <b>bias</b> in PLS. Further, our results build on prior work done using covariance-based SEM questioning the usefulness of the ULMC technique for detecting CMB...|$|E
40|$|Arranging survey {{items to}} group {{measures}} of the same construct together has several benefits, including ease of administration and enhanced statistical {{reliability and validity of}} constructs. Yet some IS researchers claim this practice contributes to <b>common</b> <b>methods</b> <b>bias</b> and camouflages “true ” measures of reliability. Our study takes a new approach to this issue by using a range of IS research measures in an online survey context to contrast grouped-item survey administration with a design in which the ordering of item administration is programmatically re-randomized for each individual subject. We find significant differences in construct reliability between grouped-item and individually randomized treatments as well as strong temporal effects and widespread anomalies related to item-ordering in the grouped-item treatment. Our results suggest the purported benefits of grouped-item surveys are outweighed by hazards these create to the integrity of research findings, and we caution IS researchers against their continued use...|$|R
40|$|The {{potential}} inflation of {{correlations between}} measures assessed via the same method (e. g., self-report) is well known. This study applied CFA models to 24 multitrait-multimethod correlation matrices {{in order to}} assess the extent of <b>common</b> <b>methods</b> <b>bias</b> (CMB). While not trivial, CMB is often minor in magnitude The influence of <b>common</b> <b>methods</b> variance (CMV) has been a pervasively cited concern in organizational research (Podsakoff, MacKenzie, Lee, & Podsakoff, 2003). As outgoing editor of Journal of Applied Psychology, John Campbell explicitly cited exclusive use of self report measures as an indication that a study contributes little to the literature (Campbell, 1982). Additionally, reviewers continue to cite CMV as a source of concern, particularly for research involving self-report measures (Spector, 2006). As a result, several researchers have investigated the extent to which CMV has biased correlations in psychological and organizational research (e. g., Crampton & Wagner, 1994; Doty & Glick, 1998). While these studies prove insightful as to {{the nature and extent of}} the effects of <b>common</b> <b>methods</b> of measurement, they differ considerably in methodology and scope. In this study, we examined the extent to which CMV is pervasive in organizational research as well as the extent to which these methods are likely to have biased trait correlations...|$|R
40|$|Pertinent {{questions}} on the measurement of social indicators are: the verification of data gained online (e. g., controlling for self-representation on social networks), and appropriate uses in community management and policy-making. Across platforms like Facebook, LinkedIn, Twitter, and blogging services, users (sub) consciously represent themselves {{in a way which}} is appropriate for their intended audience (Qui et al., 2012; Zhao et al., 2008). However, scholars in the social sciences and computer science have not yet adequately addressed controlling for self-representation, or the propensity to display or censor oneself, in their analyses (Zhao et al., 2008; Das and Kramer, 2013). As such researchers on these platforms risk working with ‘gamified’, socially responding, or online disinhibitive (trolls) personas which goes above and beyond efforts to contain <b>Common</b> <b>Method</b> <b>Biases</b> (CMB) (Linville, 1985; Suler, 2004; Podsakoff et al., 2003). What has not been approached in a systematic way is the verification of such data on offline and actual personality. In this paper, we focus on the alignment of traditional survey methods with unobtrusive methods to gather profile data from online social media via crowdsourcing platforms...|$|R
30|$|However, {{to address}} <b>common</b> <b>method</b> <b>bias,</b> we {{calculated}} the condition index {{in the regression}} test. The condition index for the full model is 166, which suggests a severe multicollinearilty problem. Thus, {{we designed an experiment}} in Study 2 to increase internal validity.|$|E
30|$|To {{ensure that}} there is no <b>Common</b> <b>Method</b> <b>bias</b> in the {{questionnaire}} survey, we performed Harman’s single factor test. This revealed that the first factor accounted for 45.018  % of variance, which is less than threshold level of 50  % of total variance explained (Podsakoff et al. 2003).|$|E
30|$|Furthermore, {{this study}} uses single {{informant}} reports for the variables {{included in the}} models, indicating {{the possibility of a}} <b>common</b> <b>method</b> <b>bias.</b> Because this study focuses on a rather narrow issue concerning KMC and organizational effectiveness and the informants were well-qualified to report on the variables, this weakness should be able to be mitigated. To ensure that the <b>common</b> <b>method</b> <b>bias</b> is not a problem and to generalize these research findings to other sectors and different geographical areas, future research can replicate this study in other sectors and different countries to overcome the limitations. In addition, this study suggests that scholars can conduct cross-regional comparative studies to expand the research scope in the future. Such research results will help expand the breadth of research and serve as a significant reference for managers who are preparing cross-regional KMC strategies.|$|E
40|$|Social {{scientists}} often estimate {{models from}} correlational data, where {{the independent variable}} has not been exogenously manipulated; they also make implicit or explicit causal claims based on these models. When can these claims be made? We answer this question by first discussing design and estimation conditions under which model estimates can be interpreted, using the randomized experiment as the gold standard. We show how endogeneity [...] which includes omitted variables, omitted selection, simultaneity, <b>common</b> <b>methods</b> <b>bias,</b> and measurement error [...] renders estimates causally uninterpretable. Second, we present methods that allow researchers to test causal claims in situations where randomization is not possible or when causal interpretation is confounded, including fixed-effects panel, sample selection, instrumental variable, regression discontinuity, and difference-in-differences models. Third, we take stock of the methodological rigor with which causal claims are being made in a social sciences discipline by reviewing {{a representative sample of}} 110 articles on leadership published in the previous 10 years in top-tier journals. Our key finding is that researchers fail to address at least 66 % and up to 90 % of design and estimation conditions that make causal claims invalid. We conclude by offering 10 suggestions on how to improve non-experimental research...|$|R
40|$|Purpose: The {{purpose of}} this study was to {{summarize}} safety management of manager into two aspects (design behavior and management behavior) and to figure out the different impact these two behaviors might have. Design/methodology/approach: In order to verify the reasonableness of the assumptions, expert investigation was used by the means of semi-structured interview. And the Structural Equation Modeling?SEM? is estimated using 850 individual questionnaire responses from five companies in the form of Likert-type scale. What’s more, taking the measurement error causing by <b>common</b> <b>method</b> <b>biases</b> into consideration, Univariate Testing was taken to measure the deviation effect. Findings: The results obtained with this description showed that certain measures should be adopt by managers to develop purposively the safety knowledge and safety motivation of the skilled labor migrations (SLMs). Research limitations/implications: Unsafe behavior, which has aroused extensive concern in recent years, is the subject of many safety management studies. However, there have not been any studies on the influence of management behavior on SLMs unsafe behavior. Practical implications: As the unsafe behavior of SLMs is the most important accident reason, this paper may help reduce the incidence of accidents. Originality/value: The conclusion of this study will certainly provide the beneficial reference views on the management behavior. </p...|$|R
40|$|The ethical {{operation}} model demonstrated {{four different}} types of the ethics by ethical leadership and catalytic mechanics. The objective {{of this paper was}} examined the different types ethical operation model but also further explore the model’s antecedents and consequences. The research gap focused on the behavior side of the practices of the ethics was included in the consequences variables in the paper. We also move further to explore the antecedents of the ethical operation model. As to the research methods, in the first study, we adopted case method of carrying out in-depth case studies. To explore the theoretical relationship more deeply, this research was done by conducted survey in the second study. The author collected data from various sources, but not wanting to be limited by the data provided in case study, this paper also collected data via a survey. Efforts were made to collect the data from multiple sources to avoid the possibility of <b>common</b> <b>method</b> <b>biases.</b> The empirical results demonstrated that the organization characteristics and leader’s characteristics influence the ethical leadership and catalytic mechanism further influence the adoptive of the different type of the ethical operation model. And conclude that {{different types of}} ethical operation affect the degree of school administrative ethics. </p...|$|R
30|$|Another {{limitation}} {{is the use}} of self-reported measures, which could lead to <b>common</b> <b>method</b> <b>bias.</b> Although the longitudinal design helps to overcome this bias, given that previous levels of the variables are controlled for to a certain degree, future studies should consider also the use of objective data (e.g., physiological measures), {{particularly when it comes to}} happiness.|$|E
30|$|Since {{the data}} were {{collected}} from single informants we assessed <b>common</b> <b>method</b> <b>bias</b> using Harman’s [77] single factor test and a modified marker variable test [78 - 80]. Assessing the data using Harman’s single factor approach we found no single factor emerged from a factor analysis of all survey items. No one factor accounted {{for the majority of the}} variance in the model with one factor explaining only 33 % [78]. In addition to the Harman’s single factor approach we also performed Lindell and Whitney’s [81] marker variable test. We assessed the correlation between a theoretically unrelated construct (marker variable) and the other constructs. The results from the model indicate that the marker variable did not have any significant influence on the endogenous latent variables. Based on these results we conclude that <b>common</b> <b>method</b> <b>bias</b> does not seem to be a limiting factor in this model.|$|E
30|$|Therefore, {{no single}} factor has {{explained}} {{the majority of}} the total variance leading to the conclusion of the inexistence of <b>common</b> <b>method</b> <b>bias.</b> Additionally, a confirmatory factor analysis (CFA) was conducted to compare the fit indexes of a multi-factor model and a single overall latent factor model in which all items designed for the questionnaire were loaded (Anderson and Gerbing 1988).|$|E
40|$|Purpose – This study aims to {{demonstrate}} that the investments in social capital do not always pay off. Although an important function of social capital is its potential for influencing co-located companies' opportunistic behavior, social capital also has a negative side. This study seeks to examine the negative and positive effects of the social capital dimensions on a company's profitability and on the perception that co-located firms free ride and shirk. Design/methodology/approach – By including data from 224 firms in 112 true-paired dyadic relationships, this study provides a unique and valid basis for empirical study within SEM analysis. The ability to link different information sources in the analysis creates a unique data set that controls for the confounding effects of <b>common</b> <b>method</b> <b>biases</b> in the analysis. Findings – Markets with a low degree of collective activity gain less advantage from cognitive social capital, because its primary effect lies in its transparency and ability to detect opportunistic behavior. The effect of relational social capital is more stable because of the positive direct effect on profitability. Structural social capital indicates markets that would benefit from creating private incentives with the intention to transfer collective activities into private payoffs. This reduces the need to follow up the co-localized businesses. Originality/value – This study shows that the dimensions of social capital vary regarding whether they reduce or facilitate the perceived withholding efforts by co-located firms...|$|R
40|$|Background Four {{explanations}} for the concurrent and prospective associations between temperament and psychopathology in children have been suggested: predisposition, complication/scar, common cause/continuity, and pathoplasty/exacerbation. Because the confounding effects of common causes have not been ruled out in prior work, the support for the various explanations is uncertain. Methods Screen-stratified community samples of 4 -year olds in Trondheim, Norway (n = 1, 042), and 3 -year olds in Barcelona, Spain (n = 622), were assessed biennially for symptoms of attention-deficit/hyperactivity (ADHD), oppositional defiant (ODD), conduct (CD), anxiety, and depressive disorders through interviewer-based psychiatric interviews across four waves of data collection. The parents completed child temperament ratings. The data were analyzed with random and fixed effects regression adjusted for all time-invariant unmeasured confounders (e. g., genetics, <b>common</b> <b>methods</b> <b>bias,</b> item overlap). Results In both Norway and Spain and across ages, negative affect predisposed children to symptoms of all disorders except CD, low effortful control predisposed children to ADHD and ODD-symptoms, and surgency predisposed children to increased ADHD-symptoms. Complication effects were observed in the Spanish children for ADHD-symptoms, which increased surgency and diminished effortful control, and for ODD-symptoms, which decreased surgency. The common cause and pathoplasty/exacerbation explanations were not supported. Conclusions The present {{results are consistent with}} the view that temperament plays a causal {{role in the development of}} symptoms of psychiatric disorders in children. Because temperament is malleable, interventions targeting the affective, attentional, and behavioral regulatory components of temperament may reduce psychopathology in children...|$|R
40|$|This is the author’s {{accepted}} and refereed manuscript to the articlePurpose – This study aims {{to demonstrate that}} the investments in social capital do not always pay off. Although an important function of social capital is its potential for influencing co-located companies' opportunistic behavior, social capital also has a negative side. This study seeks to examine the negative and positive effects of the social capital dimensions on a company's profitability and on the perception that co-located firms free ride and shirk. Design/methodology/approach – By including data from 224 firms in 112 true-paired dyadic relationships, this study provides a unique and valid basis for empirical study within SEM analysis. The ability to link different information sources in the analysis creates a unique data set that controls for the confounding effects of <b>common</b> <b>method</b> <b>biases</b> in the analysis. Findings – Markets with a low degree of collective activity gain less advantage from cognitive social capital, because its primary effect lies in its transparency and ability to detect opportunistic behavior. The effect of relational social capital is more stable because of the positive direct effect on profitability. Structural social capital indicates markets that would benefit from creating private incentives with the intention to transfer collective activities into private payoffs. This reduces the need to follow up the co-localized businesses. Originality/value – This study shows that the dimensions of social capital vary regarding whether they reduce or facilitate the perceived withholding efforts by co-located firms...|$|R
30|$|The {{study has}} several limitations. First, {{to assess the}} affective state, we {{collected}} data in two waves separated by a two-week interval. However, this design could not test the causal effect of the key variables. A more rigorous design is needed to explore the causal relationships among these variables. Second, we used employee self-reported questionnaires, {{which can lead to}} <b>common</b> <b>method</b> <b>bias</b> (Podsakoff et al. 2003). Although the two-wave design should reduce <b>common</b> <b>method</b> <b>bias</b> and the confirmatory factor analysis showed that the bias did not seriously impact our results, use of leader ratings for employee voice behavior would be a better option in future research. Third, we failed to control for some important cognitive variables that might influence the simple association between positive affect and voice. We have focused on the influence of affective factors on voice in this study, but we believe that researchers should examine the joint influence of cognition and affect on voice.|$|E
40|$|Abstract We {{believe that}} journal reviewers (as well as editors and {{dissertation}} or thesis committee members) have {{to some extent}} perpetuated misconceptions about <b>common</b> <b>method</b> <b>bias</b> in self-report measures, including (a) that relationships between self-reported variables are necessarily and routinely upwardly biased, (b) other-reports (or other methods) are superior to self-reports, and (c) rating sources (e. g., self, other) constitute measurement methods. We argue against these misconceptions and make recommendations for what reviewers (and others) should reasonably expect from authors regarding <b>common</b> <b>method</b> <b>bias.</b> We believe {{it is reasonable to}} expect (a) an argument for why self-reports are appropriate, (b) construct validity evidence, (c) lack of overlap in items for different constructs, and (d) evidence that authors took proactive design steps to mitigate threats of method effects. We specifically do not recommend post hoc statistical control strategies; while some statistical strategies are promising, all have significant drawbacks and some have shown poor empirical results...|$|E
30|$|Because all the {{measures}} {{were based on}} self-reported data collected at one time point, the analysis {{may be subject to}} common method variance (Podsakoff et al. 2003). We used Harman’s single factor test to investigate the potential influence of <b>common</b> <b>method</b> <b>bias</b> (Podsakoff and Organ 1986). Results of the principal component factor analysis, using varimax rotation, show that the largest factor accounted for only 9.4 % of the variance. This suggests the absence of serious threats of <b>common</b> <b>method</b> <b>bias</b> to the results. Further, we conducted confirmatory factor analysis (CFA). The CFA results show that a six-factor model with items loaded on the constructs they are supposed to measure fitted the data well (χ 2 (1160)[*]=[*] 2033.86, p[*]<[*] 0.01; CFI[*]=[*] 0.93, TLI[*]=[*] 0.92, RMSEA[*]=[*] 0.04). The Average Variance Extracted (AVE) of all constructs are equal or above 0.50, except for preference for authoritarian leadership (AVE[*]=[*] 0.45). Adding an additional latent method factor with all items loaded on it, the model failed to converge, suggesting severe ill-fit. Hence, the CFA approach also indicates that a common method factor does not fit the data.|$|E
30|$|The {{current study}} has some limitations. First, as {{mentioned}} above, causality {{could not be}} established because of the cross-sectional design. Thus, future research should use a prospective design or test the effects of an intervention that ameliorates psychological inflexibility (e.g., based on ACT) to examine the relationships between psychological inflexibility and depressive and insomnia symptoms. Second, self-report cross-sectional data are subject to <b>biases</b> due to <b>common</b> <b>method</b> variance (CMV). However, the current study used many of the procedures suggested by Podsakoff et al. (2012) to control for <b>common</b> <b>method</b> <b>biases,</b> including protecting respondent anonymity, reducing evaluation apprehension, and using reliable and valid measures for each construct. Regardless, future research should use other methods (e.g., depressive symptom and sleep difficulty scores obtained from a psychiatric diagnosis, daily sleep diaries, and actigraphy, instead of self-report), {{as well as a}} longitudinal design to reduce potential CMV biases (see Podsakoff et al. 2012). Third, as the sample was comprised of only Japanese college students, generalizations to other samples should be made with caution. Our sample in the current study was a group of young adults (M =  17.75, SD =  8.95) who had nearly the same AAQ-II mean as another age group, which consisted of employees in the United Kingdom (M =  18.53, SD =  7.52, N =  583, Bond et al. 2011); a t test of the difference between the AAQ-II means in the current study and in Bond et al.’s study (2011) was not significant (t(1244) =  1.65, p =  0.099). However, further research with different ages may contribute to understanding the association between psychological inflexibility, depressive symptoms, and insomnia. In particular, it is important to determine the generalizability to clinical populations due to the use of symptom questionnaires and the potential transient nature of the symptoms. Moreover, the current study did not assess the participant’s health status, which is a potential confounding variable and an obvious shortcoming.|$|R
40|$|Purpose – This paper aims {{to explore}} the effect of {{business}} strategy on socially responsible supply chain management (SR‐SCM). Design/methodology/approach – This study draws on data from 178 UK‐based companies, and 340 buyer‐supplier relationships. A novel data collection approach is used, which minimizes social desirability and <b>common</b> <b>methods</b> <b>bias,</b> to capture socially responsible supply chain management. The data are analysed {{through a set of}} OLS regressions. Findings – Business strategies significantly influence socially responsible supply chain management. Low‐cost producers largely neglect their social responsibilities in the supply chain. In contrast, firms pursuing differentiation strategies are considerably more engaged with these issues, partly because they have better supply chain processes. Practical implications – Practitioners should carefully consider the fit between strategic position and level of engagement with SR‐SCM, since our results emphasise the relationship between SR‐SCM and business strategy. Proactive engagement with SR‐SCM, however, also implies sound supply chain processes, which must also be aligned with business strategy. Policy‐makers should consider the low engagement with SR‐SCM of low‐cost producers and the implications for SR‐SCM in cost sensitive and competitive global markets. Originality/value – This is the first systematic cross‐sectional study of the relationship between business strategy and socially responsible supply chain management (SR‐SCM). These results suggest that there is a clear relationship between the strategic position of the firm and their SR‐SCM practices. These results contribute to the on‐going debate on relationships between strategy and supply chain management, and the emerging debate on the relationships between strategy and SR‐SCM. 33 page(s...|$|R
40|$|Marketing {{academics}} and practitioners frequently employ crosssectional surveys. In recent years, editors, reviewers, and authors have expressed increasing {{concern about the}} validity of this approach. These validity concerns center on reducing <b>common</b> <b>method</b> variance <b>bias</b> and enhancing causal inferences. Longitudinal data collection is commonly offered as a solution to these problems. In this article, the authors conceptually examine the role of longitudinal surveys in addressing these validity concerns. Then, they provide an illustrative comparison of the validity of cross-sectional versus longitudinal surveys using two data sets and a Monte Carlo simulation. The conceptualization and findings suggest that under certain conditions, the results from cross-sectional data exhibit validity comparable to the results obtained from longitudinal data. This article concludes by offering a set of guidelines to assist researchers in deciding whether to employ a longitudinal survey approach...|$|R
