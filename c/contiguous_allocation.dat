33|31|Public
50|$|It {{does not}} support directories, and only allows <b>contiguous</b> <b>allocation</b> for files, to make it simpler {{to be used by}} the boot loader.|$|E
50|$|A system using single <b>contiguous</b> <b>allocation</b> {{may still}} {{multitask}} by swapping {{the contents of}} memory to switch among users. Early versions of the Music operating system used this technique.|$|E
50|$|The {{most severe}} problem caused by {{fragmentation}} is causing a process or system to fail, due to premature resource exhaustion: if a <b>contiguous</b> <b>allocation</b> is needed and cannot be satisfied, failure occurs. Fragmentation causes this to occur {{even if there}} is enough of the resource, but not a contiguous amount. For example, if a computer has 4 GiB of memory and 2 GiB are free, but the memory is fragmented in an alternating sequence of 1 MiB used, 1 MiB free, then a request for 1 contiguous GiB of memory cannot be satisfied even though 2 GiB total are free.|$|E
40|$|In this paper, {{we study}} the classic problem of fairly allocating {{indivisible}} items {{with the extra}} feature that the items lie on a line. Our goal {{is to find a}} fair <b>allocation</b> that is <b>contiguous,</b> meaning that the bundle of each agent forms a contiguous block on the line. While allocations satisfying the classical fairness notions of proportionality, envy-freeness, and equitability are not guaranteed to exist even without the contiguity requirement, we show the existence of <b>contiguous</b> <b>allocations</b> satisfying approximate versions of these notions that do not degrade as the number of agents or items increases. We also study the efficiency loss of <b>contiguous</b> <b>allocations</b> due to fairness constraints. Comment: To appear in the 10 th International Symposium on Algorithmic Game Theory (SAGT), 201...|$|R
40|$|In this paper, we {{evaluate}} the performance implications {{of using a}} buddy scheme for <b>contiguous</b> node <b>allocation,</b> {{in conjunction with a}} backfilling job scheduler for clusters. When a <b>contiguous</b> node <b>allocation</b> strategy is used, there is a trade-off between improved run-time of jobs (due to reduced link contention and lower communication overhead) and increased wait-time of jobs (due to external fragmentation of the processor system). Using trace-based simulation, a buddy strategy for <b>contiguous</b> node <b>allocation</b> is shown to be unattractive compared to the standard noncontiguous allocation strategy used in all production job schedulers. A simple but effective scheme for selective buddy allocation is then proposed, that is shown to perform better than non-contiguous allocation. ...|$|R
5000|$|Some resources, notably {{memory and}} storage space, have {{a notion of}} [...] "location", and one can {{distinguish}} <b>contiguous</b> <b>allocations</b> from non-contiguous allocations. For example, allocating 1 GiB of memory in a single block, versus allocating it in 1,024 blocks each of size 1 MiB. The latter is known as fragmentation, and often severely impacts performance, so contiguous free space is a subcategory of the general resource of storage space.|$|R
40|$|Abstract. The {{performance}} of <b>contiguous</b> <b>allocation</b> strategies can be significantly {{affected by the}} distribution of job execution times. In this paper, the {{performance of}} the existing <b>contiguous</b> <b>allocation</b> strategies for 3 D mesh multicomputers is re-visited in the context of heavy-tailed distributions (e. g., a Bounded Pareto distribution). The strategies are evaluated and compared using simulation experiments for both First-Come-First-Served (FCFS) and Shortest-Service-Demand (SSD) scheduling strategies under a variety of system loads and system sizes. The results show that {{the performance of the}} allocation strategies degrades considerably when job execution times follow a heavytailed distribution. Moreover, SSD copes much better than FCFS scheduling strategy in the presence of heavy-tailed job execution times. The results also show that the strategies that depend on a list of allocated sub-meshes for both allocation and deallocation have lower allocation overhead and deliver good system performance in terms of average turnaround time and mean system utilization. ...|$|E
40|$|Given a capacitated loss network, traffic arrivals with {{different}} bandwidth demands and reward rates (heterogeneous) -in {{the case that}} each traffic demand must be assigned in contiguous position, the problem is to find call admission/packing algorithms, such that the objective function (long-run average revenue) will be maximized. With <b>contiguous</b> <b>allocation</b> constraint, the First-Fit (FF) and Best-Fit (BF) policy simulation was examined, assuming Poisson arrivals with exponential holding time. The blocking probabilities from these two policies are compared with the Complete-Sharing (CS) policy and OptimalComplete -Partitioning (OCP) policy, which have no <b>contiguous</b> <b>allocation</b> concern. A loose optimal lower bound is obtained by using the theory of Semi-Markov Decision Processes (SMDP). The value-iteration algorithm is applied due to the huge cardinality of the system state space. Our systemic numerical study (among CS, FF, BF, OCP, SMDP policies) suggests that two novel heuristic admission/packing policies, Best-Fit with Reservation (BFR) and Moving Boundary First-Fit (MBFF), might have higher efficiency...|$|E
40|$|Abstract Efficient {{processor}} allocation and {{job scheduling}} algorithms are critical if the full computational power of large-scale multicomputers {{is to be}} harnessed effectively. Processor allocation is responsible for selecting the set of processors on which parallel jobs are executed, whereas job scheduling is responsible for determining {{the order in which}} the jobs are executed. Many processor allocation strategies have been devised for mesh-connected multicomputers and these can be divided into two main categories: contiguous and non-contiguous. In <b>contiguous</b> <b>allocation,</b> jobs are allocated distinct contiguous processor sub-meshes for the duration of their execution. Such a strategy could lead to high processor fragmentation which degrades system performance in terms of, for example, the turnaround time and system utilisation. In non-contiguous allocation, a job can execute on multiple disjoint smaller sub-meshes rather than waiting until a single sub-mesh of the requested size and shape is available. Although non-contiguous allocation increases message contention inside the network, lifting the contiguity condition can reduce processor fragmentation and increase system utilisation. Processor fragmentation can be of two types: internal and external. The former occurs when more processors are allocated to a job than it requires while the latter occurs when there are free processors enough in number to satisfy another job request, but they are not allocated to it because they are not contiguous. A lot of efforts have been devoted to reducing fragmentation, and a number of <b>contiguous</b> <b>allocation</b> strategies have been devised to recognize complete sub-meshes during allocation. Most of these strategies have been suggested for 2 D mesh-connected multicomputers. However, although the 3 D mesh has been the underlying network topology for a number of important multicomputers, there has been relatively little activity with regard to designing similar strategies for such a network. The very few <b>contiguous</b> <b>allocation</b> strategies suggested for the 3 D mesh achieve complete sub-mesh recognition ability only at the expense of a high allocation overhead (i. e., allocation and de-allocation time). Furthermore, the allocation overhead in the existing contiguous strategies often grows with system size. The main challenge is therefore to devise an efficient <b>contiguous</b> <b>allocation</b> strategy that can exhibit good performance (e. g., a low job turnaround time and high system utilisation) with a low allocation overhead. The first part of the research presents a new <b>contiguous</b> <b>allocation</b> strategy, referred to as Turning Busy List (TBL), for 3 D mesh-connected multicomputers. The TBL strategy considers only those available free sub-meshes which border from the left of those already allocated sub-meshes or which have their left boundaries aligned with that of the whole mesh network. Moreover TBL uses an efficient scheme to facilitate the detection of such available sub-meshes while maintaining a low allocation overhead. This is achieved through maintaining a list of allocated sub-meshes in order to efficiently determine the processors that can form an allocation sub-mesh for a new allocation request. The new strategy is able to identify a free sub-mesh of the requested size as long as it exists in the mesh. Results from extensive simulations under various operating loads reveal that TBL manages to deliver competitive performance (i. e., low turnaround times and high system utilisation) with a much lower allocation overhead compared to other well-known existing strategies. Most existing non-contiguous allocation strategies that have been suggested for the mesh suffer from several problems that include internal fragmentation, external fragmentation, and message contention inside the network. Furthermore, the allocation of processors to job requests is not based on free contiguous sub-meshes in these existing strategies. The second part of this research proposes a new non-contiguous allocation strategy, referred to as Greedy Available Busy List (GABL) strategy that eliminates both internal and external fragmentation and alleviates the contention in the network. GABL combines the desirable features of both contiguous and non-contiguous allocation strategies as it adopts the <b>contiguous</b> <b>allocation</b> used in our TBL strategy. Moreover, GABL is flexible enough in that it could be applied to either the 2 D or 3 D mesh. However, {{for the sake of the}} present study, the new non-contiguous allocation strategy is discussed for the 2 D mesh and compares its performance against that of well-known non-contiguous allocation strategies suggested for this network. One of the desirable features of GABL is that it can maintain a high degree of contiguity between processors compared to the previous allocation strategies. This, in turn, decreases the number of sub-meshes allocated to a job, and thus decreases message distances, resulting in a low inter-processor communication overhead. The performance analysis here indicates that the new proposed strategy has lower turnaround time than the previous non-contiguous allocation strategies for most considered cases. Moreover, in the presence of high message contention due to heavy network traffic, GABL exhibits superior performance in terms of the turnaround time over the previous contiguous and non-contiguous allocation strategies. Furthermore, GABL exhibits a high system utilisation as it manages to eliminate both internal and external fragmentation. The performance of many allocation strategies including the ones suggested above, has been evaluated under the assumption that job execution times follow an exponential distribution. However, many measurement studies have convincingly demonstrated that the execution times of certain computational applications are best characterized by heavy-tailed job execution times; that is, many jobs have short execution times and comparatively few have very long execution times. Motivated by this observation, the final part of this thesis reviews the performance of several <b>contiguous</b> <b>allocation</b> strategies, including TBL, in the context of heavy-tailed distributions. This research is the first to analyze the performance impact of heavy-tailed job execution times on the allocation strategies suggested for mesh-connected multicomputers. The results show that the performance of the <b>contiguous</b> <b>allocation</b> strategies degrades sharply when the distribution of job execution times is heavy-tailed. Further, adopting an appropriate scheduling strategy, such as Shortest-Service-Demand (SSD) as opposed to First-Come-First-Served (FCFS), can significantly reduce the detrimental effects of heavy-tailed distributions. Finally, while the new <b>contiguous</b> <b>allocation</b> strategy (TBL) is as good as the best competitor of the previous <b>contiguous</b> <b>allocation</b> strategies in terms of job turnaround time and system utilisation, it is substantially more efficient in terms of allocation overhead...|$|E
40|$|Some modern {{processors}} such as later Opterons R © and Power R © processors {{are able}} to support large pages sizes such as 1 GiB and 16 GiB. These page sizes are imprac-tical to reserve at boot time because {{of the amount of}} memory that is potentially wasted. Currently, Linux R© as it stands is not well suited to support multiple page sizes because it makes no effort to satisfy <b>allocations</b> for <b>contiguous</b> regions of memory. This paper will discuss features under development that aim to support the allo-cation of large contiguous areas. This paper begins by discussing the current status of mechanisms to reduce external fragmentation in the page allocator. The reduction of external fragmenta-tion results in sparsely populated superpages that must be reclaimed for <b>contiguous</b> <b>allocations</b> to succeed. We describe how poor reclaim decisions offset the perfor-mance benefits of superpages in low-memory situations, before introducing a mechanism for the intelligent re-claim of contiguous regions. Following a presentation of metrics used to evaluate the features and the results, we propose a memory compaction mechanism that mi-grates pages from sparsely populated to dense regions when enough memory is free to avoid reclaiming pages. We conclude by highlighting that parallel allocators pre-vent <b>contiguous</b> <b>allocations</b> by taking free pages from regions being reclaimed. We propose a method for ad-dressing this by making pages temporarily unavailable to allocators. ...|$|R
3000|$|Using the {{constraints}} (3) to (8), we can fully characterize the <b>contiguous</b> spectrum block <b>allocation.</b> Note we can treat [...]...|$|R
3000|$|... [...]. So {{the problem}} of channel width {{adaptation}} {{is equivalent to the}} <b>contiguous</b> spectrum blocks <b>allocation.</b> For example, in Figure 2, we can set [...]...|$|R
40|$|Abstract-This paper {{presents}} a fast and efficient <b>contiguous</b> <b>allocation</b> strategy for 3 D mesh multicomputers, {{referred to as}} Turning Busy List (TBL for short), which can identify a free sub-mesh of the requested size {{as long as it}} exists in the mesh system. Turning means that the orientation of the allocation request is changed when no sub-mesh is available in the requested orientation. The TBL strategy relies on a new approach that maintains a list of allocated sub-meshes to determine all the regions consisting of nodes that cannot be used as base nodes for the requested sub-mesh. These nodes are then subtracted from the right border plane of the allocated sub-meshes to find the nodes that can be used as base nodes for the required sub-mesh size. Results from extensive simulations under a variety of system loads confirm that the TBL strategy incurs much less allocation overhead than all of the existing <b>contiguous</b> <b>allocation</b> strategies for 3 D mesh multicomputers and delivers competitive performance in terms of parameters such as the average turnaround times and system utilization. Moreover, the time complexity of the TBL strategy is much lower than that of the existing strategies...|$|E
40|$|Abstract—With {{the power}} {{consumption}} issue of mobile handset taken into account, Single-carrier FDMA (SC-FDMA) {{has been selected}} for 3 GPP Long-Term Evolution (LTE) uplink multiple access scheme. Like in OFDMA downlink, it enables multiple users to be served simultaneously in uplink as well. However, its single carrier property requires that all the subcarriers allocated to a single user must be contiguous in frequency within each time slot. This <b>contiguous</b> <b>allocation</b> constraint limits the scheduling flexibility, and frequency-domain packet scheduling algorithms in such system need to incorporate this constraint while trying to maximize their own scheduling objectives. In this paper we explore this fundamental problem of LTE SC-FDMA uplink scheduling by adopting the conventional timedomain Proportional Fair algorithm to maximize its objective (i. e. proportional fair criteria) in the frequency-domain setting. We show the NP-hardness of the frequency-domain scheduling problem under this <b>contiguous</b> <b>allocation</b> constraint and present a set of practical algorithms fine tuned to this problem. We demonstrate that competitive performance can be achieved in terms of system throughput as well as fairness perspective, which is evaluated using 3 GPP LTE system model simulations. I...|$|E
40|$|Scheduling {{algorithms}} {{in parallel}} computers {{fall into two}} basic categories: time and space sharing algorithms. Space-sharing based processor allocation algorithms can be contiguous or non-contiguous. Studies show that non-contiguous allocation is superior due to decrease in fragmentation. Other studies have reported that executing jobs on fewer processors (folding) can improve the performance of contiguous and non-contiguous allocation. However, the problem with folding {{is that it is}} not always applicable because of parallel programming languages and parallel operating systems limitations. Most of previous studies used simulation. Our study is an experimental one for studying time and space sharing on a real parallel machine (the PowerXplorer), with eight processors arranged as a two-dimensional mesh. A set of five scientific applications with differing communication characteristics were implemented and executed using time and space sharing. The observed execution times were used to study and compare time-sharing and contiguous and non-contiguous space sharing with and without folding. Our study showed that time-sharing gave comparable results to space sharing allocation. Further, non-contiguous allocation gave better results than <b>contiguous</b> <b>allocation</b> when folding is not supported. However, when folding is supported <b>contiguous</b> <b>allocation</b> gave the best mean turnaround times...|$|E
40|$|Partitionable [...] array {{machines}} {{have emerged}} as popular target architectures for efforts to devise effective on [...] line processor allocation strategies. As the available processors become fragmented, <b>contiguous</b> processor <b>allocation</b> schemes can fail to allocate a task despite there being sufficient processors in total to service the request. Tasks consequently wait longer to be serviced, and the system response degrades. In this paper, {{we report on the}} use of a new paradigm, partial compaction of tasks, to improve the performance of <b>contiguous</b> processor <b>allocation</b> methods for partitionable linear arrays. A quadratic sequential time algorithm to schedule the ordered compaction of tasks on a reconfigurable bus system is presented. The length of the schedule is shown to be within twice that of the minimum schedule length. Experimental results indicate that the algorithm almost eliminates the problem of fragmentation, and reduces the response times of tasks by significantly reducing allocation [...] ...|$|R
50|$|Based on this insight, Blackburn and McKinley {{designed}} {{a new class}} of garbage collectors, they named mark-region. Their Immix mark-region collector manages memory hierarchically using fixed sized blocks consisting of lines. <b>Contiguous</b> object <b>allocation</b> may cross lines, but noblocks. Immix collection mixes line marking and object copying in a single pass. This design delivers substantial performance benefits due to smaller heap footprints and improvements in locality.|$|R
40|$|We {{study the}} classic cake cutting problem from a {{mechanism}} design perspective, in particular focusing on deterministic mechanisms that are strategyproof and fair. We begin {{by looking at}} mechanisms that are non-wasteful and primarily show that for even the restricted class of piecewise constant valuations there exists no direct-revelation mechanism that is strategyproof and even approximately proportional. Subsequently, we remove the non-wasteful constraint and show another impossibility result stating {{that there is no}} strategyproof and approximately proportional direct-revelation mechanism that outputs <b>contiguous</b> <b>allocations,</b> again, for even the restricted class of piecewise constant valuations. In addition to the above results, we also present some negative results when considering an approximate notion of strategyproofness, show a connection between direct-revelation mechanisms and mechanisms in the Robertson-Webb model when agents have piecewise constant valuations, and finally also present a (minor) modification to the well-known Even-Paz algorithm that has better incentive-compatible properties for the cases when there are two or three agents. Comment: A shorter version of this paper will appear at IJCAI 201...|$|R
40|$|This paper explores and quantifies garbage {{collection}} behavior for three whole heap collectors and generational counterparts: copying semi-space, mark-sweep, and reference counting, the canonical algorithms from which essentially all other collection algorithms are derived. Efficient implementations in MMTk, a Java memory management toolkit, in IBM’s Jikes RVM share all common mechanisms {{to provide a}} clean experimental platform. Instrumentation separates collector and program behavior, and performance counters measure timing and memory behavior on three architectures. Our experimental design reveals key algorithmic features and how they match program characteristics to explain the direct and indirect costs of {{garbage collection}} {{as a function of}} heap size on the SPEC JVM benchmarks. For example, we find that the <b>contiguous</b> <b>allocation</b> of copying collectors attains significant locality benefits over free-list allocators. The reduced collection costs of the generational algorithms together with the locality benefit of <b>contiguous</b> <b>allocation</b> motivates a copying nursery for newly allocated objects. These benefits dominate the overheads of generational collectors compared with non-generational and no collection, disputing the myth that “no garbage collection is good garbage collection. ” Performance is less sensitive to the mature space collection algorithm in our benchmarks. However the locality and pointer mutation characteristics for a given program occasionally prefer copying or mark-sweep. This study is unique in its breadth of garbage collection algorithms and its depth of analysis. Categories and Subject Descriptors D. 3. 4 [Programming Languages]: Processors—Memory managemen...|$|E
40|$|<b>Contiguous</b> <b>allocation</b> of {{parallel}} jobs usually {{suffers from the}} degrading effects of fragmentation as it requires that the allocated processors be contiguous and has the same topology as the network topology connecting these processors. In non-contiguous allocation, a job can execute on multiple disjoint smaller sub-meshes rather than always waiting until a single sub-mesh of the requested size is available. Lifting the contiguity condition in non-contiguous allocation is expected to reduce processor fragmentation and increase processor utilization. However, the communication overhead is increased because the distances traversed by messages can be longer. The extra communication overhead depends on how the allocation request is partitioned an...|$|E
40|$|A t-interval is a {{union of}} at most t half-open {{intervals}} on the real line. An interval is the special case where t = 1. Requests for <b>contiguous</b> <b>allocation</b> of a linear resource can be modeled as a sequence of t-intervals. We consider the problems of online selection of intervals and t-intervals, which show up in Video-on-Demand services, high speed networks and molecular biology, among others. We derive lower bounds and (almost) matching upper bounds on the competitive ratios of randomized algorithms for selecting intervals, 2 -intervals and t-intervals, for any t > 2. While offline t-interval selection has been studied before, the online version is considered {{here for the first}} time...|$|E
40|$|We {{investigate}} {{effects of}} ordering in blocked matrix [...] matrix multiplication. We find that submatrices {{do not have}} to be stored contiguously in memory to achieve near optimal performance. Instead it is the choice of execution order of the submatrix multiplications that leads to a speedup of up to four times for small block sizes. This is in contrast to results for single matrix elements showing that <b>contiguous</b> memory <b>allocation</b> quickly becomes irrelevant as the blocksize increases. Comment: Fixed typo...|$|R
30|$|Both PRAMFS and Ext 2 {{employ the}} bitmap data {{structure}} to distinguish allocated and free blocks. The bitmap structure {{can be a}} good solution to manage free blocks for HDDs because it makes it easy to find a free block that is close to another one and helps to make the allocated blocks of a file as contiguous as possible. While <b>contiguous</b> block <b>allocation</b> is important for rotating HDDs to efficiently access files, it adds too much cost for NV memory because bitwise operations to find a clear bit in the bitmap structure are significantly time consuming. Therefore, the free block management of a file system on NV memory requires an alternative mechanism.|$|R
50|$|This has {{the effect}} of {{batching}} together allocations into larger runs. Such delayed processing reduces CPU usage, and tends to reduce disk fragmentation, especially for files which grow slowly. It can also help in keeping <b>allocations</b> <b>contiguous</b> when there are several files growing at the same time. When used in conjunction with copy on write as it is in ZFS, it can convert slow random writes into fast sequential writes.|$|R
40|$|In {{this work}} we {{address the problem}} of ergodic sum-rate {{maximization}} under proportional rate constraints for the uplink of single-carrier frequency division multiple access (SC-FDMA) systems. Finding optimal solution generally requires high computational complexity, because SC-FDMA imposes the <b>contiguous</b> <b>allocation</b> of the available frequency resources. To reduce complexity we propose a novel sub-optimal algorithmic solution, based on Lagrangian relaxation of the rate constraints, which exploits a simple but effective estimation of the average number of the resources to allocate {{in order to reduce the}} search space. The complexity of the resulting algorithm increases only linearly with the number of users and the number of resources, while the performance gap to optimal solution is limited to the 10 % of the sum-rate...|$|E
30|$|We {{describe}} a novel and flexible real-time kernel, called Yartek, with low overhead and low footprint suitable for embedded systems. The motivation of this development {{was due to}} the difficulty to find a free and stable real-time kernel suitable for our necessities. Yartek has been developed on a Coldfire microcontroller. The real-time periodic tasks are scheduled using nonpreemptive EDF, while the non-real-time tasks are scheduled in background. It uses a deferred interrupt mechanism, and memory is managed using <b>contiguous</b> <b>allocation.</b> Also, a design methodology was devised for the nonpreemptive EDF scheduling, based on the computation of bounds on the periodic task durations. Finally, we {{describe a}} case study, namely, an embedded system developed with Yartek for the implementation of nonvisual perception for mobile robots. This application has been designed using the proposed design methodology.|$|E
40|$|Current {{processor}} allocation {{techniques for}} highly parallel systems are typically restricted to <b>contiguous</b> <b>allocation</b> strategies for which performance suffers significantly {{due to the}} inherent problem of fragmentation. As a result, message passing systems have yet to achieve the high utilization levels exhibited by traditional vector supercomputers. We are investigating processor allocation algorithms which lift the restriction on contiguity of processors {{in order to address}} the problem of fragmentation. Three non-contiguous processor allocation strategies: Paging allocation, Random allocation and the Multiple Buddy Strategy (MBS) are proposed and studied in this paper. Simulations compare the performance of the non-contiguous strategies with that of several well-known contiguous algorithms. We show that non-contiguous allocation algorithms perform better overall than the contiguous ones, even when message-passing contention is considered. We also present the results of experiments on [...] ...|$|E
40|$|Efficient {{utilization}} of processing resources in a large, multiuser parallel computer depends on processor allocation algorithms that minimize system fragmentation. We propose three processor allocation algorithms for the k-ary n-cube class of parallel architectures, {{which includes the}} hypercube and multidimensional torus. The k-ary Partner strategy is a conventional <b>contiguous</b> processor <b>allocation</b> strategy that improves subcube recognition. The non-contiguous Multiple Buddy and Multiple Partner strategies lift the restriction of contiguity {{in order to address}} the problem of fragmentation associated with contiguous strategies. Simulations compare the performance of these three strategies with the performance of other k-ary n-cube allocation strategies, showing that non-contiguous allocation provides significantly increased system utilization by eliminating fragmentation. 1 Introduction Our work addresses the problem of processor allocation in distributed memory multicomputers. Allocat [...] ...|$|R
40|$|Current {{processor}} allocation {{techniques for}} multicomputers {{are based on}} centralized front-end based algorithms. As a result, the applied strategies are usually restricted to static, <b>contiguous,</b> structure preserving <b>allocation,</b> and suffer from low parallelism and weak fault tolerance. To lift these restrictions we are investigating a distributed approach to the processor allocation problem for mesh interconnected distributed memory machines. We conducted several experiments, some simulated and some running over a Simens hpcLine Primergy Server with 96 nodes, which showed that distributed allocation is feasible with current technologies...|$|R
40|$|International audienceOne of {{the main}} {{drawbacks}} of classical Optical Burst Switching (OBS) solutions {{is the loss of}} bursts when contentions occur. Time-domain Wavelength Interleaved Networking (TWIN) is a lossless solution with contention resolution in the edge nodes providing a simple and passive switching in the core nodes and satisfying both low-energy and efficient bandwidth use criteria. However, this solution requires an efficient control plane. In this paper, we compare three different control planes based on either centralized or distributed schemes. Moreover we use two different slot <b>allocation</b> strategies (<b>contiguous</b> or disjoint). The performances of the proposed solutions are compared in terms of total delay, jitter, queue length and bandwidth utilization. The simulation parameters are carefully chosen to take into account implementation constraints. We find that the centralized solution with <b>contiguous</b> slot <b>allocation</b> is the most efficient and it allows a throughput up to 7 Gb/s...|$|R
40|$|Abstract We {{describe}} a novel and flexible real-time kernel, called Yartek, with low overhead and low footprint suitable for embedded systems. The motivation of this development {{was due to}} the difficulty to find a free and stable real-time kernel suitable for our necessities. Yartek has been developed on a Coldfire microcontroller. The real-time periodic tasks are scheduled using nonpreemptive EDF, while the non-real-time tasks are scheduled in background. It uses a deferred interrupt mechanism, and memory is managed using <b>contiguous</b> <b>allocation.</b> Also, a design methodology was devised for the nonpreemptive EDF scheduling, based on the computation of bounds on the periodic task durations. Finally, we {{describe a}} case study, namely, an embedded system developed with Yartek for the implementation of nonvisual perception for mobile robots. This application has been designed using the proposed design methodology. </p...|$|E
40|$|Abstract—Contiguous {{processor}} allocation improves {{both the}} network and the application performance, by decreasing the congestion probability among communication of different applications. Consequently, the average, standard deviation and worst-case latency of the network is decreased signifi-cantly. This makes the <b>contiguous</b> <b>allocation</b> a good solution for time-critical applications with bounded deadlines. On the other hand, non-contiguous allocation will increase the system throughput significantly. Isolated nodes are utilized and more applications can finish their job in a time unit. However, this will lead to poor network metrics, unsuitable for real-time applications. In this work, we combine these two approaches in order to manage workloads with mixed-critical characteristics. Real-time applications are mapped contiguously, while non-critical applications are allowed to get dispersed over the available system nodes. Results show over 50 % improvement in worst-case latency and 100 times improvement in deadline misses. Keywords—Processor allocation; Application Mapping; Dy-namic Many-Core Systems; Contiguous Task Mapping...|$|E
30|$|In this section, {{we compare}} the {{performance}} of the 5 G waveform candidates in a typical multi-user asynchronous access scheme [21]. We consider two users, user equipment (UE) 1 and UE 2. The first user occupies three RBs and is assumed to be perfectly synchronized in time and frequency domains with its serving base station. The secondary user occupies nine RBs and suffers from a delay error (i.e. a timing offset) and a potential carrier frequency offset due to a synchronization mismatch with downlink channel. Due to the timing and frequency errors, the secondary user interferes with the first one. The data stream of the first user is decoded (assuming no channel and no noise), and the performance in terms of mean square error (MSE) on the decoded constellation is evaluated. The interference only comes from the interferer user. The spacing in terms of guard carriers between the two users is variable: no guard carrier (<b>contiguous</b> <b>allocation),</b> one guard carrier and two guard carriers.|$|E
40|$|Abstract—Increasing {{the number}} of {{processors}} in a single chip toward network-based many-core systems requires a run-time task allocation algorithm. We propose an efficient mapping algorithm that assigns communicating tasks of incoming applications onto resources of a many-core system utilizing Network-on-Chip paradigm. In our <b>contiguous</b> neighborhood <b>allocation</b> (CoNA) algorithm, we target at the reduction of {{both internal and external}} congestion due to detrimental impact of congestion on the network performance. We approach the goal by keeping the mapped region contiguous and placing the communicating tasks in a close neighborhood. A completely synthesizable simulation environment where none of the system objects are assumed to be ideal is provided. Experiments show at least 40 % gain in different mapping cost functions, as well as 16 % reduction in average network latency compared to existing algorithms. Keywords-Network-on-Chip; MPSoC; run-time; dynamic; task mapping; processor allocation; congestion; contiguous; latency; performance I...|$|R
40|$|Abstract—We design fast {{iterative}} {{policies for}} resource alloca-tion in the uplink of LTE. We generalize recent works on iterative delay and queue based scheduling policies to more general system settings. We model all constraints due to <b>contiguous</b> bandwidth <b>allocation,</b> peak transmit power and fractional power control. We design a novel mechanism for inferring the packet delays approximately from the buffer status reports (BSR) and construct a new non-differentiable objective function which enables delay based scheduling. For frequency flat fading, we construct an O(N logL) optimal resource allocation algorithm for N users and L points of non-differentiability in the objective function. For a frequency diversity scheduler with M sub-bands, the corresponding complexity is essentially O(N(M 2 +L 2)). Through detailed system simulations (based on NGMN and 3 GPP evalu-ation methodology) which model H-ARQ, finite resource grants per sub-frame, realistic traffic, power limitations, interference, and channel fading, we demonstrate {{the effectiveness of}} our schemes for LTE. I...|$|R
40|$|The {{utilization}} of frequency spectrum for space-to-ground communications applications has generally progressed from the lowest available bands capable of supporting transmission {{through the atmosphere}} to the higher bands, which have required research and technological advancement to implement. As communications needs increase and the available spectrum in the microwave frequency bands (3 30 GHz) becomes congested globally, future systems will move into the millimeter wave (mm-wave) range (30 300 GHz). While current systems are operating in the Ka-band (20 30 GHz), systems planned for the coming decades will initiate operations in the Q-Band (33 50 GHz), V-Band (50 75 GHz) and W Band (75 110 GHz) of the spectrum. These bands offer extremely broadband capabilities (<b>contiguous</b> <b>allocations</b> of 500 MHz to 1 GHz or more) and an uncluttered spectrum {{for a wide range}} of applications. NASA, DoD and commercial missions that can benefit from moving into the mm-wave bands include data relay and near-Earth data communications, unmanned aircraft communications, NASA science missions, and commercial broadcast/internet services, all able to be implemented via very small terminals. NASA Glenn Research Center has a long history of performing the inherently governmental function of opening new frequency spectrum by characterizing atmospheric effects on electromagnetic propagation and collaborating with the satellite communication industry to develop specific communications technologies for use by NASA and the nation. Along these lines, there are critical issues related to W/V-band propagation that need to be thoroughly understood before design of any operational system can commence. These issues arise primarily due to the limitations imposed on W/V-band signal propagation by the Earth s atmosphere, and to the fundamental lack of understanding of these effects with regards to proper system design and fade mitigation. In this paper, The GRC RF propagation team recommends measurements that are required to assure that the risk associated with the use of mm-wave is minimized. We develop first order beacon and transponder system payload requirements and beacon terminal requirements. We will suggest and discuss a possible hardware implementation for the space segment, as well for the ground segment. A discussion on a propagation measurement campaign for taking relevant statistical data is also included...|$|R
