12|57|Public
40|$|Trammel’s Trace was a {{nineteenth century}} road that traversed East Texas. Recognized {{today as a}} {{historic}} <b>cartographic</b> <b>feature,</b> this road appeared in different ways on nineteenth century printed published maps over time, and in the mid-to-late nineteenth century was reduced from a route to a fragment. This study {{is the first to}} examine the portrayal of the Trace as a historic <b>cartographic</b> <b>feature,</b> how it was presented to the general public, how its portrayal changed over time, and why it appears on the maps at all. In addition, this study is the first to use geographic information systems (GIS) to analyze the presentation of the Trace on printed, published maps...|$|E
40|$|The {{availability}} of VHR SAR images depicting in detail urban areas allow starting and considering {{the use of}} these data for <b>cartographic</b> <b>feature</b> extraction. This has been proved already by means of airborne data [1] [2] but has to be further improved in order to achieve the quality that is currently available from optical VHR data...|$|E
40|$|Describing {{the quality}} of digital geodata in a {{geodatabase}} is required for many applications. We present our developments for automated quality control of the German topographic vector data set ATKIS using images. The automation comprises automatic <b>cartographic</b> <b>feature</b> extraction and comparison with ATKIS data, which both are triggered by additional knowledge derived from the existing scene description. To reach an operational solution the system is designed as an automated system which admits user interaction to perform a final check of the fully automatically derived quality description of the data...|$|E
40|$|The {{digitizing}} of <b>cartographic</b> <b>features</b> is {{a necessary}} but laborious task to many research analysts undertaking cartographic or GIS studies. The requirements of a good digitizing module for the capture of such <b>cartographic</b> <b>features</b> are discussed in this paper. To meet these requirements, {{the advantages and disadvantages}} of using an existing cartographic digitizing module or a CAD package are discussed. As a CAD package cannot meet all of the requirements, the design of a CAD post-processing program for assembling polygons from chains and for automatically relating attributes to objects is presented...|$|R
40|$|The {{demand for}} maps and related cartographic {{products}} has increased greatly {{over the past}} years. This increase in the demand for cartographic products has greatly increased the work load for the cartographer because current practice requires the cartographer to manually identify and delineate the significant <b>cartographic</b> <b>features</b> from an image. The availability of digital image data {{has made it possible}} to use the computer to assist in the extraction and delineation of <b>cartographic</b> <b>features.</b> This research presents one approach to automating the delineation of large area features using neural networks for texture pattern classification...|$|R
40|$|Of all {{tasks in}} {{photogrammetry}} {{the extraction of}} <b>cartographic</b> <b>features</b> is the most time consuming. Fully automatic acquisition of features like roads and buildings, however, appears to be very difficult. The extraction of <b>cartographic</b> <b>features</b> form digital satellite imagery requires interpretation of this imagery. The knowledge one needs about the topographic objects and their appearances in satellite images in order to recognize these objects and extract the relevant object outlines is difficult to model and to implement in computer algorithms. This paper introduces Particle Swarm Optimization based method of object extraction from Google Earth image (satellite image). This paper deals with the land cover mapping by using swarm computing techniques. The motivation {{of this paper is}} to explore the improved swarm computing algorithms for the satellite image object extraction...|$|R
40|$|Recent {{years have}} seen {{significant}} improvements {{in the performance of}} automatic <b>cartographic</b> <b>feature</b> extraction (CFE) systems. Early systems, painstakingly tweaked to work in a very limited fashion on small images, have given way to sys-tems which produce credible results in situations representative of production environments. While no existing automatic system is yet ready for incorporation into a production environment, significant strides have been made toward this goal. Semi-automated systems, with significant man-in-the-loop capabilities, continue to be developed by photogrammetric workstation vendors. However, a fundamental requirement for system development, and an absolute prerequisite for production applications, is the rigorous evaluation of automated system performance. Indeed, without meaningful evaluation, we can hardly be said to be doing science. Rigorous evaluation requires the definition of a set of metrics, relevant to user requirements and meaningful in terms of expected system performance. These metrics must be generated across common, well-documented datasets which are representative of production sources and scenes. To provide concrete examples of system evaluation techniques, this paper describes work in the Digital Mapping Lab-oratory on the evaluation of automated <b>cartographic</b> <b>feature</b> extraction systems. Activities include the definition and publication of metrics for several types of feature extraction systems, the generation and distribution of several large test data sets, and extensive evaluations on our CFE systems. The paper concludes with a discussion of future activities and directions in system evaluation. ...|$|E
40|$|The needing for up dated Cartographic {{documents}} {{has called}} for techniques which can be wide used in <b>Cartographic</b> <b>feature</b> extraction. In this paper we present the chosen one. We allied the knowledge provided by Remote Sensing to Digital Processing of Images (DPI) to develop a methodology suitable to detect and extract tags from orbital images. Among the several existing tools of DPI, the used one in this paper was the Mathematical Morphology. Some of the morphological operators used were thinning, pruning and conditional dilation. The results were satisfactory and reaffirmed the potential of using Mathematical Morphology in the semi-automation of features extraction processes. Pages: 1245 - 125...|$|E
40|$|Commission VII Current {{and future}} remote sensing {{programs}} such as Landsat, SPOT, MOS, ERS, JERS, and the space platform's Earth Observing System (Eos) {{are based on a}} variety of imaging sensors that will provide timely and repetitive multisensor earth observation data on a global scale. Visible, infrared and microwave images of high spatial and spectral resolution will eventually be available for all parts of the earth. It is essential that efficient processing techniques be developed to cope with the large multisensor data volumes. This paper discusses data fusion techniques that have proved successful for synergistic merging of SPOT HRV, Landsat TM and SIR-B images. Examples are given for integrative rectification, enhancement of <b>cartographic</b> <b>feature</b> extraction and improvement of spatial resolution...|$|E
40|$|Traces {{the history}} of {{celestial}} cartography and relates this history to the changing ideas of man''s {{place in the universe}} and to advances in map-making. This book features reproductions of maps from antiquarian celestial atlases and prints. It includes a legend for each illustration to explain its astronomical and <b>cartographic</b> <b>features...</b>|$|R
50|$|<b>Cartographic</b> <b>features</b> are {{types of}} {{abstract}} geographical features, which appear on maps {{but not on}} the planet itself, even though they are located on the planet. For example, the Equator is shown on maps of the Earth, but it does not physically exist. It is a theoretical line used for reference, navigation, and measurement.|$|R
25|$|Some organisations {{provide a}} Melway year of {{publication}} {{in addition to their}} map reference (e.g., (2006) 70 F6), to avoid confusion if map references change in newer versions of the directory. However Melway have kept the need for this to an absolute minimum over the years and have held off several <b>cartographic</b> <b>features,</b> including a more logical overall tiling of pages across the entire metropolitan area (which do appear in the Sydway and Brisway) {{in order to protect the}} integrity and continuity of the original 1966 grid references.|$|R
40|$|A {{geographic}} information system (GIS) is a powerful decision-support platform for environmental modeling and policy formulation. Before any analysis can be made, however, cartographic features need to be extracted from images and maintained in a database. The process of populating the database {{is estimated to be}} 60 - 80 % of the cost of implementing a GIS. This bottleneck will only increase with the unprecedented flow of images provided by such programs as NASA's Mission to Planet Earth. This paper presents research issues of creating an adaptive imagemapping tool that uses machine learning to automate the process of <b>cartographic</b> <b>feature</b> extraction. This tool works by watching the user select a sample subset of desired features, then uses these features to train a learning algorithm. Such a tool would allow a novice user to quickly create an automated feature-extraction program model that is, due to the embedded learning, easily adaptable to changing parameters such as resolution, lightin [...] ...|$|E
40|$|Automatic {{classification}} of regions towards <b>cartographic</b> <b>feature</b> extraction by the airborne AeS [...] 1 instrument is presented. We extract regions corresponding to cartographic features for the classes built [...] up area, forest, water and open area. Water and built [...] up area are {{extracted from the}} intensity image. The use of a DEM as additional source of information allows to distinguish built [...] up land and forest from all other classes. The mathematical tools for feature extraction from intensity and DEM data are fractal dimension estimation and mathematical morphology. The classification is done employing a decision tree. Keywords: decision tree classifier, mathematical morphology, fractals, local statistics 1. INTRODUCTION Extraction of cartographic information is a time [...] consuming process {{in the case of}} visual interpretation. High [...] accurate remotely sensed data as provided by the Aero [...] Sensing AeS [...] 1 interferometric airborne SAR system operating in X [...] band make it possible to a least se [...] ...|$|E
40|$|Post-launch {{performance}} analysis {{carried out to}} characterize spatial and radiometric aspects of IRS-CARTOSAT- 1 is reported in this paper. The radiometric characteristics are estimated with scene dynamic range analysis, signal-to-noise ratio, impact of onboard data compression on image quality, and the spatial characteristics is by modulation transfer function (MTF). Histograms of about 42 scenes comprising of different land-cover features across the country were computed to estimate overall and most significant dynamic ranges of the sensor output. Similarly, the signal-to-noise ratios were estimated by visually selecting uniform target areas viz., water body, tar-road and snow to study the sensor radiometry at low, middle and high input signal levels. Also, the effect of JPEG data compression onboard (Compression Ratio = 1 : 3. 2) on the data quality was studied by analyzing the satellite data over the same area with compression off- and on-modes of data acquisition. The MTF was estimated base on slant-edge algorithm, which allows to extract edge information at sub-pixel level for accurate estimation of the edge profile. The MTF was evaluated using the slant edge algorithm on an image edge over an airstrip target. It {{was found that the}} sensors onboard CARTOSAT- 1 spacecraft has met all the mission set specifications, and would help to generate data products with adequate image sharpness, radiometric quality and insignificant image distortion due to onboard compression scheme to extract <b>cartographic</b> <b>feature</b> extraction and analysis...|$|E
40|$|In {{the present}} study a {{comparison}} {{has been carried out}} between manually and digitally simplified lines in order to estimate appropriate algorithmic tolerances. For this purpose two algorithms have been used to simplify coastlines, <b>cartographic</b> <b>features</b> of high complexity, over a wide range of scale change. Digitally derived coastlines were compared with a reference data set representing the manual simplification procedure. The tolerances ensure small magnitude of displacement. This method may be followed for producing derived cartographic lines at a wide range of scales from a base map...|$|R
40|$|The {{use of the}} Thermal Infrared Multispectral Scanner (TIMS) data in {{agricultural}} landscapes is discussed. The TIMS allows for narrow-band analysis in the 8. 2 - 11. 6 micron range at spatial resolutions down to 5 meters in cell size. A coastal plain region in SE Alabama was studied using the TIMS. The crop/plant vigor, canopy density, and thermal response changes for soils obtained from thermal imagery are examined. The application of TIMS data to hydrologic and topographic issues, inventory and conservation monitoring, and the enhancement and extraction of <b>cartographic</b> <b>features</b> is described...|$|R
50|$|Some organisations {{provide a}} Melway year of {{publication}} {{in addition to their}} map reference (e.g., (2006) 70 F6), to avoid confusion if map references change in newer versions of the directory. However Melway have kept the need for this to an absolute minimum over the years and have held off several <b>cartographic</b> <b>features,</b> including a more logical overall tiling of pages across the entire metropolitan area (which do appear in the Sydway and Brisway) {{in order to protect the}} integrity and continuity of the original 1966 grid references.|$|R
40|$|Remote sensing {{has been}} used mostly to produce {{analyses}} on different aspects and phenomena concerning territory. The approach is not {{different from the one}} employed when analysing maps in the sense that analysis depends on the nature of data, maps and satellite images being two different sources of spatial data. Obviously, analysis based on cartographic data is different from the one based on satellite data, because of the different nature of data and the consequently different tools of analysis. Until now remote sensing techniques are not used in the mapping production, which rather makes use of photogrammetry in order to obtain all the cartographic objects defined by the cartographic legend. Research in applying image processing techniques to extract automatically cartographic features by using digital aerial photographs, as well as studies in integrating results from SPOT images with cartographic layers has been made in different case studies. The interest of this kind of research lies in the possibility of updating by automatic procedures the cartographic Gis. The themes mostly investigated are roads and urban areas. Following this line of research, the recent availability of Ikonos images at 1 meter's resolution leads researchers to put forward and experiment procedures to extract cartographic features in order to update Gis. It is worth noting that working in the cartographic context is quite different from working with analyses as in this case a specific <b>cartographic</b> <b>feature</b> must be distinguish and extract...|$|E
40|$|Determination of {{the maximum}} ability for feature {{extraction}} from satellite imageries based on ontology procedure using <b>cartographic</b> <b>feature</b> determination is the main objective of this research. Therefore, a special ontology has been developed to extract maximum volume of information available in different high resolution satellite imageries and compare them to the map information layers required in each specific scale due to unified specification for surveying and mapping. ontology seeks to provide an explicit and comprehensive classification of entities in all sphere of being. This study proposes a new method for automatic maximum map feature extraction and reconstruction of high resolution satellite images. For example, in order to extract building blocks to produce 1 : 5000 scale and smaller maps, the road networks located around the building blocks should be determined. Thus, a new building index has been developed based on concepts obtained from ontology. Building blocks have been extracted with completeness about 83 %. Then, road networks have been extracted and reconstructed to create a uniform network with less discontinuity on it. In this case, building blocks have been extracted with proper performance and the false positive value from confusion matrix was reduced by about 7 %. Results showed that vegetation cover and water features have been extracted completely (100 %) and about 71 % of limits have been extracted. Also, the proposed method in this article {{had the ability to}} produce a map with largest scale possible from any multi spectral high resolution satellite imagery equal to or smaller than 1 : 5000...|$|E
40|$|Scene {{development}} {{plays the}} first step for synthetic image generation using DIRSIG (The Digital Imaging and Remote Sensing Image Generation Model). Traditionally the scenes are built manually; the procedure is very time consuming especially for complex urban scenes. The research focuses on contributing to the DIRSIG scene model development based on information retrieval from high-resolution multispectral images, such as WorldView- 2 sensor imagery. The proposed approach takes advantage of a sequence of image processing routines to enhance the spectral images and extracts key geographical features for the man-made road network and naturally occurring water bodies. These routines {{take into account the}} spatial as well as spectral signatures in the multispectral images. They constitute a chained process, which includes several steps: pan-sharpening, image filtering, classification, segmentation, morphological processing, vectorization and final refinement. In {{the first step}} of the process, a novel and highly parallel nearest-neighbor diffusion based pan-sharpening procedure (NNDiffuse) is designed to fuse a high spatial resolution panchromatic image with the spectral image. Image filtering using trilateral filters for multispectral images is devised to process the image, removing small variances in the image as well as preserving significant edges. Spectral features such as Spectral Angle Mapper (SAM) are used to locate natural resource coverage such as water bodies. Multispectral flood fill technique, a graph based connected component technique and a knowledge-based system is used to extract the road networks. Both the road network and the water bodies can be refined and exported as vectorized ArcGIS shapefile. The outcome of the research is a workflow to facilitate scene development from spectral images; it also contributes to the development in the field of <b>cartographic</b> <b>feature</b> extraction, photogrammetry and target detection...|$|E
40|$|Cartography uses {{large-scale}} {{digital images}} obtained by remote sensing. Such images {{are commonly used}} for the extraction and / or detection of <b>cartographic</b> <b>features,</b> which are the targets of interest in mapping. Extracting targets of interest from digital images streamlines the mapping, but the accuracy of this mapping depends {{on the characteristics of}} the features of interest present in the extracted image. Therefore, this paper proposes an automated way to calculate and display statistical values so that the extraction processes of any feature type mapping can be assessed considering its quality and quantity. With this purpose in mind, a computer program has been developed. This program applies an already established methodology to calculate statistical values concerning the results obtained by the automatic extraction process. The implemented program performs calculations in a quick and objective manner. In addition, it also generates resultant images that provide the user viewing of the errors obtained by the reported method. This paper presents the results obtained from the use of this computer program. Thus, the program developed accomplishes the proposed objectives, allowing the user to perform a consistent analysis of the automated extraction, since this evaluation is performed based on statistical calculations. Therefore, this program assists researchers and scholars of cartography to evaluate automatic extraction processes in the <b>cartographic</b> <b>features</b> of interest...|$|R
40|$|GeoNode is {{open source}} {{geospatial}} software that provides free, robust software for devel-oping spatial data infrastructures. Originally engineered by OpenGeo {{and now a}} growing GeoNode developer community, its contributors are increasingly tasked with enhancing geovisualization – adding <b>cartographic</b> <b>features</b> to make compelling data displays, particu-larly of time series and natural disaster data, as vital to the project as enabling SDI. This pa-per {{provides an overview of}} how adding features to support visualization to an open source, collaborative software stack offers both considerable technical challenges and benefits in data discovery, spatio-temporal data viewing, data publishing and collaboration...|$|R
40|$|Vector map {{databases}} {{offer the}} potential for customised cockpit moving-map displays, in which user-specified <b>cartographic</b> <b>features</b> can be layered to meet mission requirements. The disadvantage of vector moving-maps is {{the potential for}} increased user workload. In 1995, the Naval Research Laboratory and the Naval Air Weapons Center jointly performed a preference study, during which aircrew viewed demonstrations of prototype moving-map displays and responded to a detailed questionnaire concerning the usefulness of each display. This paper summarises aircrew interviews from that study pertaining to both vector moving-map displays and vector feature overlays, including Height-Above-Threshold (HAT), threat rings, and Clear Line-of-Sight (CLOS) ...|$|R
40|$|We {{examine the}} {{computational}} complexity of cartographic label placement, a problem {{derived from the}} cartographer's task of placing text labels adjacent to map features {{in such a way}} as to minimize overlaps with other labels and map <b>features.</b> <b>Cartographic</b> label placement is one of the most time-consuming tasks in the production of maps. Consequently, several attempts have been made to automate the label-placement task for some or all classes of <b>cartographic</b> <b>features</b> (punctual, linear, or areal features), but all previously published algorithms for the most basic task [...] -point-feature-label placement [...] - either exhibit worst-case exponential time complexity, or incorporate incomplete heuristics that may fail to find an admissible labeling even when one exists. The computational complexity of label placement is therefore a matter of practical significance in automated cartography. We show that admissible label placement is NP-complete, even for very simple versions of the problem. Thus, no [...] ...|$|R
40|$|There {{has been}} a concerted effort in the U. S., {{over the past four}} years, to bring forth a {{national}} standard for dig ital cartographic data. A major portion of the project has been directed toward <b>cartographic</b> <b>features.</b> The assigned Working Group III of the National Committee for Digital Cartographic Data standards at first dealt with the issues and then developed alternatives. In the next stage, an interim proposed standard with a model schema of features, attributes, and attribute values plus definitions was pub lished. The preparation of these definitions and the testing of the standard are both described as are the problems en countered enroute and the work remaining...|$|R
40|$|In this paper, an {{interactive}} technique for extracting <b>cartographic</b> <b>features</b> from aerial and spatial images is presented. The method is essentially {{an interactive}} method of image region segmentation based on pixel grey level and texture information. The underlying segmentation method is seeded region growing. The criterion for growing regions is based on both texture and grey level, where texture is quantified using cooccurrence matrices. The Kullback distance is utilised with co-occurrence matrices in order to describe the image texture, then the Theory of Evidence is applied to merge the information coming from texture and grey level image from the RGB bands. Several results from aerial and spatial images that support the technique are presente...|$|R
40|$|The paper {{describes}} {{research and}} preliminary results relating to an auxiliary data structure for modelling space in map generalisation research. The representation {{is based on}} a regular grid that is then aligned with linear <b>cartographic</b> <b>features,</b> such that the topology of the grid and the topology of the features is shared. The author first outlines the motivation for using the structure in relation to their research. How the model is generated is then described with reference to previous work by researchers in the field of computer graphics. Next, the author’s own experiences in adapting the model to the cartographic domain are discussed. Finally, preliminary results are presented and the outlook for continuing and future research described...|$|R
40|$|A digital cartographic {{multisensor}} image database of excellent geometry and improved resolution {{was created by}} registering SIR-B images to a rectified Landsat TM reference image and applying intensity-hue-saturation enhancement techniques. When evaluated against geodetic control, RMSE(XY) values of approximately + or - 20 m were noted for the composite SIR-B/TM images. The completeness of <b>cartographic</b> <b>features</b> extracted from the composite images exceeded those obtained from separate SIR-B and TM image data sets by approximately 10 and 25 percent, respectively, indicating that the composite images may prove suitable for planimetric mapping at a scale of 1 : 100, 000 or smaller. At present, the most effective method for extracting cartographic information involves digitizing features directly from the image processing display screen...|$|R
40|$|This paper {{presents}} the Geoportal of Colombian Environmental Information (GCEI) of Valle University (Colombia) for aiding {{the research and}} planning management of sustainable development. The GCEI {{was designed to be}} used by the scientific community under RENATA (National Academic Net-work of Advanced Technology), which is equivalent to UCAID – University Corporation for Advances Internet Development. The spatial environmental information is derived from remote sensing data available from Moderate Resolution Imaging Spectro-radiometer (MODIS) which are: daily precipitation and temperature, water bodies, thermal anoma-lies, forest fires, and vegetation cover (VC). The GCEI allows the spatial information to be: 1) displayed by a graphic interface, 2) interrogated by SQL queries, 3) downloaded for use in personal com-puter and 4) printed with <b>cartographic</b> <b>features.</b> The GCEI can be found a...|$|R
40|$|Building {{extraction}} and delineation {{is one of}} {{the most}} salient problems in <b>cartographic</b> <b>features</b> extraction. This paper presents a novel framework for reliable and accurate building extraction from high-resolution color imagery focusing on building boundary delineation and building roof compositional polygon segmentation. Proposed framework consists of three steps. First, anisotropic diffusion and clustering are applied as pre-processing for denoising and color quantization and then building boundary is extracted by active contour driven by edge-flow. Finally, building roof compositional polygons are segmented by JSEG. The framework is tested on a number of buildings and the results are shown. The result shows the completeness and accuracy that this framework can provide for extracting building from a high-resolution color image data set. 1...|$|R
40|$|Spatial {{information}} is often presented as maps in location-based services, {{which makes it}} necessary to label <b>cartographic</b> <b>features</b> in real time. Features may be dense all over the map, or in certain areas. Owing to the limited free spaces, it is always difficult to label dense features. Aiming to utilize free spaces efficiently, this paper proposed a density-based method of labelling dense features. The method placed labels of dense features earlier than sparse ones, so that free spaces were allotted to dense features before consumed by sparse features. An efficient algorithm was developed for map labelling in real time. We implemented this method in a Java environment. A case study shows sound cartographic results and acceptable efficiency of the labelling...|$|R
40|$|Vectorization of <b>cartographic</b> <b>features</b> is a {{difficult}} task in geographic information acquisition from topographic maps. This paper presents a semi-automatic approach to linear feature vectorization directly in original scanned colour topographic maps without layer separation. In the approach, a sliding window is added on a user-given linear feature, and the current line in the window is segmented adaptively by using colour space conversion, k-means clustering and directional region growing. A thinning operation is then performed in {{the window and the}} line is tracked from the centre to the edge. By moving the window continuously along the line, vectorization is carried out by iterative operations of image segmentation, thinning and line tracking. Experimental results show that linear features in colour topographic maps can be vectorized rapidly and accurately, especially in those maps with forest tints and relief shadings...|$|R
40|$|ISO {{standards}} 19115 and 19113 on metadata {{and quality}} on geographic information together with standards on quality measures, testing and reporting (ISO 19138, ISO 2859, ISO 3951 and ISO 19114) give a proposal about metadata and quality descriptions. Standards are wide {{in scope and}} need further development when applied in different circumstances and environments. Metadata standard is especially wide and gives a comprehensive framework for describing GI data sets. Quality part of the standards, however, would need some development work which is already done in several groups aiming to definitions of quality measures and test methods. One limitation of the quality standard {{is that it has}} been clearly designed for geographical data stored in databases. However, many data sets that are transferred from producers to users and re-users are not pure collections of separate geographical entities but rather ready-made cartographic products. Those products require in addition to already standardized quality elements also quality elements that describe the <b>cartographic</b> <b>features</b> and the entire cartographic product...|$|R
40|$|Neither the European Commission nor {{any person}} acting {{on behalf of}} the Commission is {{responsible}} for the use that might be made of the following information. All Rights Reserved No part of the material protected by this copyright notice may be reproduced or utilised in any form or by any means, electronic or mechanical, including photocopying, recording or by any information storage and retrieval system without the written permission from the copyright owner. Printed in Belgium and Italy. <b>Cartographic</b> Representations <b>Cartographic</b> <b>features</b> depicted on the maps of this atlas are derived from the EUROSTAT GISCO database (Geographic Information System for the European Commission, EUROSTAT, Luxembourg) and from the Digital Chart of the World. These cartographic data do not have an explicit legal status; hence, no legal aspects should be derived from the information depicted on any of the maps in this publication. Cover: The different colours on the map correspond to the distribution of the major soil reference groups across the European continent (JRC) ...|$|R
40|$|This paper {{provides}} {{an introduction to}} the Humanities Special Issue on “Deep Mapping”. It sets out the rationale for the collection and explores the broad-ranging nature of perspectives and practices that fall within the “undisciplined” interdisciplinary domain of spatial humanities. Sketching a cross-current of ideas that have begun to coalesce around the concept of “deep mapping”, the paper argues that rather than attempting to outline a set of defining characteristics and “deep” <b>cartographic</b> <b>features,</b> a more instructive approach is to pay closer attention to the multivalent ways deep mapping is performatively put to work. Casting a critical and reflexive gaze over the developing discourse of deep mapping, it is argued that what deep mapping “is” cannot be reduced to the otherwise a-spatial and a-temporal fixity of the “deep map”. In this respect, as an undisciplined survey of this increasing expansive field of study and practice, the paper explores the ways in which deep mapping can engage broader discussion around questions of spatial anthropology...|$|R
