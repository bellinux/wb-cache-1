65|13|Public
500|$|Kilburn's next project, {{known as}} Atlas, aimed {{to create a}} fast {{computer}} by making maximum use of existing and new technologies. The project was backed by Ferranti and a £300,000 grant from the National Research Development Corporation. It incorporated numerous technologies and techniques such as [...] "multiprogramming, job scheduling, spooling, interrupts, pipelining, interleaved storage, autonomous transfer units, virtual storage and paging – though none of these techniques had been invented when the project started in 1956." [...] Other innovations included read only memory and a <b>compiler-compiler.</b> The greatest innovation was virtual memory, which allowed the drum storage {{to be treated as}} if it were core. Three of them were built, and installed at Manchester University, the University of London and the Rutherford Laboratory.|$|E
50|$|Stephen C. Johnson is {{credited}} with establishing the naming convention in the late 1970s when he named his <b>compiler-compiler</b> yacc (Yet Another <b>Compiler-Compiler),</b> since he felt there were already numerous compiler-compilers in circulation at the time.|$|E
5000|$|META II An early <b>compiler-compiler,</b> {{influential}} in OMeta's implementation ...|$|E
50|$|One of the {{earliest}} (1964), surprisingly powerful, versions of <b>compiler-compilers</b> is META II, which accepted grammars and code generation rules, {{and is able to}} compile itself and other languages.|$|R
50|$|<b>Compiler-compilers</b> {{exist in}} many flavors, {{including}} bottom-up rewrite machine generators (see JBurg) used to tile syntax trees {{according to a}} rewrite grammar for code generation, and attribute grammar parser generators (e.g. ANTLR {{can be used for}} simultaneous type checking, constant propagation, and more during the parsing stage).|$|R
5000|$|UNCOL was {{an ambitious}} effort {{for the early}} 1960s. An attempt to solve the compiler-writing problem, it {{ultimately}} failed because language and compiler technology were not yet mature.In the 1970s, <b>compiler-compilers</b> ultimately contributed to solving the problem that UNCOL set itself: the economical production of compilers for new languages and new machines.|$|R
5000|$|PQCC, a <b>compiler-compiler</b> that is {{more than}} a parser generator.|$|E
50|$|In a 1976 paper, Andrew S. Tanenbaum {{describes}} using ML/I as a <b>compiler-compiler.</b>|$|E
50|$|Defense Advanced Research Projects Agency DARPA {{sponsored}} a compiler project with Wulf's CMU research team in 1970. The Production Quality <b>Compiler-Compiler</b> PQCC design {{would produce a}} Production Quality Compiler (PQC) from formal definitions of source language and the target. PQCC tried to extend the term <b>compiler-compiler</b> beyond the traditional meaning as a parser generator (e.g., YACC) without much success. PQCC might more properly {{be referred to as}} a compiler generator.|$|E
40|$|Context-free grammars {{provide the}} basis for many useful tools such as parsergenerators, <b>compiler-compilers</b> and syntax-directed editors. This paper {{demonstrates}} the potential benefits obtained when context-free grammars are used to define complex objects in the relational model. The grammar formalism facilitates relational queries on the hierarchical structure of these objects and promotes the use of grammar-based tools as front ends to relational database systems...|$|R
50|$|The Builder is {{the primary}} {{component}} and main application of the system. The Builder is {{used to analyze the}} syntax of a language (specified as a grammar) and construct LALR and DFA tables. During this process, any ambiguities in the grammar will be reported. This is essentially the same task that is performed by <b>compiler-compilers</b> such as YACC and ANTLR.|$|R
50|$|Some {{experimental}} <b>compiler-compilers</b> take as input {{a formal}} description of programming language semantics, typically using denotational semantics. This approach {{is often called}} 'semantics-based compiling', and was pioneered by Peter Mosses' Semantic Implementation System (SIS) in 1978. However, both the generated compiler and the code it produced were inefficient in time and space. No production compilers are currently built in this way, but research continues.|$|R
50|$|The Production Quality <b>Compiler-Compiler</b> Project (or PQCC) was a {{long-term}} project led by William Wulf at Carnegie Mellon University {{to produce an}} industrial-strength <b>compiler-compiler.</b> PQCC would produce full, optimizing programming language compilers from descriptions of the programming language and the target machine. Though {{the goal of a}} fully automatic process was not realized, PQCC technology and ideas were the basis of production compilers from Intermetrics, Tartan Laboratories, and others.|$|E
50|$|The Production Quality <b>Compiler-Compiler</b> {{project at}} Carnegie-Mellon University does not formalize semantics, but {{does have a}} semi-formal {{framework}} for machine description.|$|E
5000|$|The NLS was {{implemented}} using several domain-specific languages implemented with the Tree Meta <b>compiler-compiler.</b> [...] The eventual implementation language was called L10.|$|E
40|$|A {{formalism}} {{is presented}} for describing {{the actions of}} processors for programming languages [...] compilers, interpreters, assemblers [...] and their interactions in complex systems such as <b>compiler-compilers</b> or extendible languages. The formalism here {{might be used to}} define and answer such a question as "Can one do bootstrapping using a metacompiler whose metaphase is interpretive? " In addition an algorithm is presented for deciding whether or not a given system can be produced from a given set of component processors...|$|R
50|$|A {{metacompiler}} is {{a software}} development tool used chiefly {{in the construction}} of compilers, translators, and interpreters for other programming languages. They are a subset of a specialized class of compiler writing tools called <b>compiler-compilers</b> that employ metaprogramming languages.Metaprogramming is the writing of computer programs with the ability to treat programs as their data. The input to a metacompiler is a metaprogram written in a specialized metalanguage designed chiefly for the purpose of constructing compilers. The language of the compiler produced is called the object language. The minimal input producing a compiler is a metaprogram specifying the object language grammar and semantic transformations into an object program.|$|R
40|$|Model {{transformation}} {{based on}} triple graph grammars (TGGs) is a general, intuitive and formally well defined technique for {{the translation of}} models [5, 6, 2]. While previous concepts and case studies were focused mainly on visual models of software and systems, this article describes an industrial application of model transformations based on TGGs as a powerful technique for software translation using the tool Henshin [1]. The general problem in this scenario is to translate source code that is currently in use into corresponding source code that shall run on a new system. Up to now, this problem was addressed based on manually written converters, parser generators, <b>compiler-compilers</b> or meta-programming environments using term rewriting or similar techniques (see e. g. [4]) ...|$|R
50|$|There is no {{connection}} between Meta-IV, and Schorre's Meta-II language, or its successor Tree Meta; these were <b>compiler-compiler</b> systems rather than being suitable for formal problem descriptions.|$|E
5000|$|In {{the early}} 1960s, Robert McClure at Texas Instruments invented a <b>compiler-compiler</b> called TMG, the name taken from [...] "transmogrification". In the {{following}} years TMG was ported to several UNIVAC and IBM mainframe computers.|$|E
50|$|Dermot is {{the author}} of several Open Source Software applications, {{including}} DBOW, a database <b>compiler-compiler</b> or front-end, and beanie, a UNIX-based accounting and invoicing system. He {{is also the author of}} RFC 2431, an RTP payload format for BT.656 video encoding.|$|E
40|$|It {{is common}} {{practice}} to bootstrap compilers of programming languages. By using the compiled language {{to implement the}} compiler, compiler developers can code in their own high-level language and gain a large-scale test case. In this paper, we investigate bootstrapping of <b>compiler-compilers</b> as they occur in language workbenches. Language workbenches support the development of compilers {{through the application of}} multiple collaborating domain-specific meta-languages for defining a language’s syntax, analysis, code generation, and editor support. We analyze the bootstrapping problem of language workbenches in detail, propose a method for sound bootstrapping based on fixpoint compilation, and show how to conduct breaking meta-language changes in a bootstrapped language workbench. We have applied sound bootstrapping to the Spoofax language workbench and report on our experience. Programming Language...|$|R
40|$|Earley’s parsing {{algorithm}} is an O(n 3) algorithm for parsing according to any context-free grammar. Its theoretical importance {{stems from the}} fact that it was one of the first algorithms to achieve this time bound, but it has also seen success in <b>compiler-compilers,</b> theorem provers and natural language processing. It has an elegant struc-ture, and its time complexity on restricted classes of grammars is often as good as specialized algorithms. Grammars with ɛ-productions, however, require special con-sideration, and have historically lead to inefficient and inelegant implementations. In this thesis, we develop the algorithm from specification using the B-Method. Through refinement steps, we arrive at a list-processing formulation, in which the problems with ɛ-productions emerge and can be understood. The development high-lights the essential properties of the algorithm, and has also lead to the discovery of an implementation optimization. We end by giving a concept-test of the algorithm as a literate Pascal program. ii...|$|R
40|$|This paper {{investigates the}} {{applicability}} of 3 D freehand sketching to implement a human-computer interface for virtual environments, {{and the possibility of}} using context-free grammars to interpret the sketches. Dynamic gestures are the foundation for outlining virtual objects on a sketch-like basis to create them, and for interacting with the objects in the three dimensional space. Specifically, the question whether the support of the third dimension improves the user's articulation possibility, in contrast to sketching within two dimensions only, is one point of interest. We focus on the application of standard LALR parser generators, which are commonly used as <b>compiler-compilers</b> to create parsers which support multiple gesture recognition, and automatically reconstruct sketched objects with their indicated properties. In combination with a gesture-based interaction metaphor and the consideration of different modalities, we achieve to maximize the information flow between human and computer. In addition, we propose a complementary navigation method for virtual planes that makes use of physical reflective props...|$|R
50|$|The TREE-META (or Tree Meta, TREEMETA) Translator Writing System is a <b>compiler-compiler</b> {{system for}} {{context-free}} languages originally {{developed in the}} 1960s. Parsing statements of the metalanguage resemble augmented Backus-Naur form with embedded tree-building directives. Unparsing rules include extensive tree-scanning and code-generation constructs.|$|E
50|$|TMG (TransMoGrifier) is a <b>compiler-compiler</b> {{created by}} Robert M. McClure and {{presented}} in 1968, and implemented by Douglas McIlroy. TMG ran on systems like OS360 and early Unix. It {{was used to}} build EPL, {{an early version of}} PL/I. Ken Thompson used TMG in 1970 on PDP-7 as a tool to offer Fortran, but ended up creating the B programming language which was much influenced by BCPL.|$|E
5000|$|Yacc is a parser {{generator}} (loosely, <b>compiler-compiler),</b> {{not to be}} confused with lex, which is a lexical analyzer frequently used as a first stage by Yacc. Yacc was developed by Stephen C. Johnson at AT&T for the Unix operating system. The name is an acronym for [...] "Yet Another Compiler Compiler." [...] It generates an LALR(1) compiler based on a grammar written in a notation similar to Backus-Naur form.|$|E
40|$|<b>Compiler-compilers</b> are {{tools that}} {{generate}} substitutes for hand-written compiler components from high-level formal specifications. Such tools exist for lexical, syntactic and semantic analysis, optimizers and code generation. The established benefits are reduced development time and increased {{confidence in the}} correctness of the resulting software. This thesis presents a generator for type checkers. Given {{a description of the}} type system by typing rules, the generator yields a type checker that constructs proofs using the typing rules. Unlike earlier approaches, we derive suitable notions of proof and typing rule from an analysis of type systems and from corresponding constructs in mathematical proof theory. The approach thus respects the structure and intention of the typing rules, rather than expressing the rules in some pre-existing formalism. The given applications comprise type checkers for imperative, object-oriented and functional languages, including ML type inference. The typing rules for these checkers directly represent those found in the literature. They naturally describe the typing of single language constructs and they can be re-used in different checkers...|$|R
50|$|In {{computer}} science, a <b>compiler-compiler</b> or {{compiler generator}} is a programming tool {{that creates a}} parser, interpreter, or compiler from some form of formal description of a language and machine. The input may be a text file containing the grammar written in BNF or EBNF that defines the syntax of a programming language, and whose generated output is some source code of the parser for the programming language, although other definitions exist.|$|E
50|$|Throughout the 1950s Tony led a {{group at}} Manchester {{working on the}} {{theoretical}} underpinnings of compilers. This culminated in the <b>compiler-compiler,</b> a seminal idea first presented at a British Computer Society Conference in July 1960 by Brooker and Morris. This was subsequently implemented on the Ferranti ATLAS and used for high-level language development. The ATLAS was regarded as the world's most powerful computer when it was brought into service in December 1962.|$|E
5000|$|Tartan's initial {{engineering}} {{focus was}} to commercialize {{use of the}} Production Quality <b>Compiler-Compiler</b> Project approach towards building optimizing compilers that Wulf had worked on at Carnegie Mellon. This involved having optimizing code generators semi-automatically produced from architecture descriptions. Tartan made native Ada compilers for VAX/VMS and Sun-3/SunOS, and embedded system Ada cross-compilers, hosted on those platforms, to the MIL-STD-1750A, Motorola 680x0, and later Intel i960 architectures. [...] In addition, in March 1982, the company received a contract to maintain and enhance the DIANA intermediate representation that was intended as the cornerstone to various Ada tools.|$|E
5000|$|The first paper usually {{associated}} with the extensible programming language movement is M. Douglas McIlroy's 1960 paper on macros for higher-level programming languages. [...] Another early description {{of the principle of}} extensibility occurs in Brooker and Morris's 1960 paper on the <b>Compiler-Compiler.</b> [...] The peak of the movement was marked by two academic symposia, in 1969 and 1971. [...] By 1975, a survey article on the movement by Thomas A. Standish was essentially a post mortem. The Forth programming language was an exception, but it went essentially unnoticed.|$|E
5000|$|YACC (Yet Another <b>Compiler-Compiler)</b> is a {{computer}} program for the Unix operating system. It is a Look Ahead Left-to-Right (LALR) parser generator, generating a parser, {{the part of a}} compiler that tries to make syntactic sense of the source code, specifically a LALR parser, based on an analytic grammar written in a notation similar to Backus-Naur Form (BNF). Yacc itself used to be available as the default parser generator on most Unix systems, though it has since been supplanted as the default by more recent, largely compatible, programs.|$|E
50|$|A parser {{generator}} generates the lexical-analyser {{portion of a}} compiler. It is a program that takes {{a description of a}} formal grammar of a specific programming language and produces a parser for that language. That parser {{can be used in a}} compiler for that specific language. The parser detects and identifies the reserved words and symbols of the specific language from a stream of text and returns these as tokens to the code which implements the syntactic validation and translation into object code. This second part of the compiler can also be created by a <b>compiler-compiler</b> using a formal rules-of-precedence syntax-description as input.|$|E
50|$|However, {{there are}} many {{different}} types of compiler. If the compiled program can run on a computer whose CPU or operating system is different from the one on which the compiler runs, the compiler is a cross-compiler. A bootstrap compiler is written in the language that is compiled. A program that translates from a low-level language to a higher level one is a decompiler. A program that translates between high-level languages is usually called a source-to-source compiler or transpiler. A language rewriter is usually a program that translates the form of expressions without a change of language. The term <b>compiler-compiler</b> refers to tools used to create parsers that perform syntax analysis.|$|E
50|$|PQCC {{research}} into code generation process sought {{to build a}} truly automatic Compiler-Writing system. The effort discovered and designed the phase structure of the PQC. The BLISS-11 compiler provided the initial structure. The phases included analyses (front end), intemmediate translation to virtual machine (middle end), and translation to the target (back end) TCOL was developed a tool for the PQCC research to handle language specific constructs in the intermediate representation. Variations of TCOL supported various languages. The Production Quality <b>Compiler-Compiler</b> (PQCC) project investigated techniques of automated compiler construction. The design concepts proved useful in optimizing compilers and compilers for the object-oriented programming language Ada.|$|E
