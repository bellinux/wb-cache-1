2|168|Public
40|$|Introduction: Our {{aim was to}} {{investigate}} is there association between level of religious moral beliefs and severity of PTSD symptoms, depressiion symptoms, anxiety and severity of alcohol abuse we tested 152 war veterans on presence of PTSD, depression symptoms, anxiety, alcohol misuse and level of religious moral beliefs. Subjects and Methods: We used Harvard trauma questionnaire (HTQ), Hopkins <b>Check</b> <b>Scale</b> SBCL 25, check list for alcohol misuse MAST. Subjects were assessed {{with regard to the}} level of belief in some basic ethical principles that arise from religiou...|$|E
40|$|Introduction: Our {{aim was to}} {{investigate}} is there association between level of religious moral beliefs and severity of PTSD symptoms, depresiion symptoms, anxiety and severity of alcohol abuse we tested 152 war veterans on presence of PTSD, depression symptoms, anxiety, alcohol misuse and level of religious moral belifes. Subject and Methods: we used Harvard trauma questionnarie (HTQ), Hopkins <b>Check</b> <b>Scale</b> SBCL 25, check list for alcohol misuse MAST. Subjects were assessed {{with regard to the}} level of belief in some basic ethnical principles that arise from religous moral values. The score of religous moral belief index was used to correlate with severity of PTSD symptoms, depression symptoms, anxiety and severity of alcohol misuse. Results: Mean age of tested subjects was 40. 8 (SD= 6. 6) years. The score of the moral belief index was negatively correlated to PTSD symptom severity and depressiveness (Pearson 2 ̆ 7 s r= 0. 325, p< 0. 001; r=- 0. 247, p= 0. 005, respectively). Besides that the score of moral belief index negatively correlated with presented anxiety (Pearson 2 ̆ 7 s r=- 0. 199, p= 0. 026). Related to severity of tobacco and alcohol misuse we found negative association of these with the moral belief index (Pearson 2 ̆ 7 s r=- 0. 227, p= 0. 011; r=- 0. 371, p< 0. 001, respectively). Conclusion: A higher index of religious moral beliefs in war veterans enables better control distress, providing better mental health stability. It enables post traumatic conflicts typical for combatants 2 ̆ 7 survivors to be more easily overcome. It also causes healthier reactions to external stimuli. A higher index of religious moral beliefs of war veterans provides a healthier and more efficient mechanism of tobacco and alcohol misuse control. In this way, it helps overcoming postwar psychosocial problems and socialization of the personality, leading to the improvement in mental health...|$|E
5000|$|An {{automatic}} checkweigher {{incorporates a}} series of conveyor belts. These checkweighers are known also as belt weighers, in-motion scales, conveyor scales, dynamic scales, and in-line scales. In filler applications, they are known as <b>check</b> <b>scales.</b> Typically, there are three belts or chain beds: ...|$|R
40|$|Accurate {{determinations}} of {{the physical}} scale of a lattice action are required to <b>check</b> <b>scaling</b> and take the continuum limit. We present a high statistics study of the static potential for the SU(3) Wilson gauge action on coarse lattices (5. 54 ≤β≤ 6. 0). Using an improved analysis procedure we determine the string tension and the Sommer scale r_ 0 (and related quantities) to 1...|$|R
40|$|Abstract. Goanna is an industrial-strength static {{analysis}} tool used in academia and industry alike to find bugs in C/C++ programs. Unlike existing approaches Goanna uses the off-the-shelf NuSMV model checker as its core analysis engine on a syntactic flow-sensitive program abstraction. The CTL-based model checking approach enables {{a high degree}} of flexibility in writing <b>checks,</b> <b>scales</b> to large number of <b>checks,</b> and can <b>scale</b> to large code bases. Moreover, the tool incorporates techniques from constraint solving, classical data flow analysis and a CEGAR inspired counterexample based path reduction. In this paper we describe Goanna’s core technology, its features and the relevant techniques, as well as our experiences of using Goanna on large code bases such as the Firefox web browser. ...|$|R
40|$|Head-discharge {{equations}} are {{fitted to}} a set of physical models of dam breach, covering 378 different geometries. The method of fitting consists of three aspects: 1) the integration of the ideal weir equation over the geometric boundaries of the notch, 2) use of the Buckingham Pi theorem to remove data with explainable deviations from the fitting, and 3) the use of simulated annealing to do the fitting, with an objective function of mean absolute relative error. The equations are applied to an additional 60 geometries to <b>check</b> <b>scaling...</b>|$|R
40|$|We {{report on}} {{preliminary}} {{results of a}} high statistics quenched lattice QCD calculation of nucleon matrix elements within the Symanzik improvement programme. Using the recently determined renormalisation constants from the alpha collaboration we present a fully non-pertubative calculation of the forward nucleon axial matrix element with O(a) lattice artifacts completely removed. Runs are made at #beta# = 6. 0 and #beta# = 6. 2, {{in an attempt to}} <b>check</b> <b>scaling</b> and O(a" 2) effects. We shall also briefly describe results for left angle x right angle, the matrix element of a higher derivative operator. (orig.) SIGLEAvailable from FIZ Karlsruhe / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekDEGerman...|$|R
40|$|Head-discharge {{equations}} are {{fitted to}} a set of physical models of dam breach for the cases where there is a drop below the jet but apparently no aeration. Investigations with simulated annealing and a commercial curve-fitting program suggest that the reductions in flow from that of a free-falling, aerated jet can be fitted with equations in a dimensionless scaling system derived from the Buckingham Pi theorem and integration of the ideal weir equation. A set of linear corrections are fitted to data for a breach width of 0. 406 m and applied to data for breach widths of 0. 203 m and 0. 813 m, to <b>check</b> <b>scaling...</b>|$|R
2500|$|... is a CSP {{parallel}} refinement checker. The <b>checking</b> performance linearly <b>scales</b> up to 32 physical cores.|$|R
40|$|Proving program {{termination}} {{is key to}} guaranteeing {{absence of}} undesirable behaviour, such as hanging programs and even security vulnerabilities such as denial-of-service attacks. To make termination <b>checks</b> <b>scale</b> to large systems, interprocedural termination analysis seems essential, which is a largely unexplored area of research in termination analysis, where most effort has focussed on difficult single-procedure problems. We present a modular termination analysis for C programs using template-based interprocedural summarisation. Our analysis combines a context-sensitive, over-approximating forward analysis with the inference of under-approximating preconditions for termination. Bit-precise termination arguments are synthesised over lexicographic linear ranking function templates. Our experimental results show that our tool 2 LS outperforms state-of-the-art alternatives, and demonstrate the clear advantage of interprocedural reasoning over monolithic analysis in terms of efficiency, while retaining comparable precision. Comment: extended versio...|$|R
50|$|One by Dave Wood, ex-Metropolitan Police detective, the UKBA's head of {{enforcement}} and crime group. This was a two-week inquiry designed to discover {{to what extent}} <b>checks</b> were <b>scaled</b> down, and what the security implications might have been. It was alleged that a draft copy of Mr Wood's report was leaked to the Daily Mail.|$|R
5000|$|Controls: Hand Valve, Motor Valve, Pneumatic Valve, Hydraulic Valve, Float Valve, <b>Check</b> Valve, Conveyor <b>Scale,</b> Pressure Gauge, Level Control, Bulk Level Control, Flow Meter, Switch Cabinet ...|$|R
30|$|As {{shown in}} Figure 10, {{there is a}} slight {{difference}} in the thermal gradient in the lid and in the rheological sublayer; therefore, Equations 38 and 39 may result in slightly different <b>scaling</b> exponents. We <b>check</b> both <b>scaling</b> relations {{to see whether the}} stresses at the lid base and those in the lid can be scaled similarly.|$|R
40|$|Abstract. The {{problem of}} formalizing {{architectural}} styles has been re-cently tackled {{with the introduction}} of the concept of architectural type. The internal behavior of the system components can vary from instance to instance of an architectural type in a controlled way, which preserves the absence of deadlock related architectural mismatches proved via the architectural compatibility and interoperability checks. In this paper we extend the notion of architectural type by permitting a controlled vari-ability of the component topology as well. This is achieved by declaring some component connections to be extensible, {{in the sense that the}} num-ber of connected components can vary from instance to instance of an architectural type. We show that such a controlled variability of the topology is still manageable from the analysis viewpoint, as the archi-tectural compatibility and interoperability <b>checks</b> <b>scale</b> with respect to the number of components attached to the extensible connections. ...|$|R
40|$|The aim of {{this study}} was to develop and examine the psychometric {{properties}} of the Brief Body Avoidance and <b>Checking</b> <b>Scale</b> (BBACS) for physically active men. The BBACS is designed to assess the frequency of body checking and avoidance behaviors common among users of gyms and health clubs. Following development of an initial pool of items and content judgment, data from 325 men were collected from gym users and participants in organized sporting events. Confirmatory factor analysis showed a good fit for a model with two factors and 12 items. Satisfactory evidence of construct validity and internal consistency was also generated through analysis of factor loadings, t-values, correlations with drive for muscularity and body satisfaction measures, group differences, Cronbach’s alpha, and construct reliability tests. The BBACS appears to be a valid and reliable scale for assessing the frequency of body checking and body avoidance behaviors among physically active men...|$|R
40|$|The {{problem of}} formalizing {{architectural}} styles has been recently tackled {{with the introduction}} of the concept of architectural type. The internal behavior of the system components can vary from instance to instance of an architectural type in a controlled way, which preserves the absence of deadlock related architectural mismatches proved via the architectural compatibility and interoperability checks. In this paper we extend the notion of architectural type by permitting a controlled variability of the component topology as well. This is achieved by declaring some component connections to be extensible, {{in the sense that the}} number of connected components can vary from instance to instance of an architectural type. We show that such a controlled variability of the topology is still manageable from the analysis viewpoint, as the architectural compatibility and interoperability <b>checks</b> <b>scale</b> with respect to the number of components attached to the extensible connections...|$|R
40|$|Recently, a {{model was}} {{proposed}} {{to explain the}} non-linearity of the V–I characteristics of the reactive magnetron discharge with a Ti-cathode in an Ar–N 2 gas mixture. It accounts for the rapid development of an additional (lower impedance) metal–target discharge, which is coupled in parallel to the existent one, after outrunning a current threshold. Here, we employed various surface science techniques to confirm the connection between mentioned non-linearity and target nitridation-versus-sputtering processes. Surface atomic N/Ti ratios were measured for different N 2 pressures, and ion current densities using X-ray photoelectron spectroscopy, Auger electron spectroscopy and low-energy ion scattering spectroscopy. Systematic experiments showed that while the nitridation enhancement process {{plays a significant role}} at lower current densities, the sputtering process becomes predominant after outrunning a critical current density. Taking into account the <b>checked</b> <b>scaling</b> effect of pressure and ion beam density, we were able to correlate the mentioned critical current density with the threshold currents in the V–I plots...|$|R
40|$|The vacuum {{dynamics}} of SU(2) lattice gauge theory is studied {{by means of}} a gauge-invariant effective action, both at zero and finite temperature. Working with lattices up to 32 ^ 4 we <b>check</b> the <b>scaling</b> of the energy density with the magnetic length. We find that the screening at zero temperature of the applied external magnetic field weakens by increasing the temperature. Comment: LATTICE 98 (confine...|$|R
40|$|Assertions are a {{powerful}} bug detection technique. Traditional assertion checking, however, is performed synchronously, imposing its full cost on the runtime of the program. As a result, many useful kinds of checks are impractical because they lead to extreme slowdowns. We present {{a solution that}} decouples assertion evaluation from program execution: assertions are evaluated asynchronously while the program continues to execute. Our technique ensures that the assertion checking thread operates on a consistent view of the global state, and that an assertion always produces the same result as it would in a serial execution. We implemented our technique in a system called STROBE, a snapshot-based system for asynchronous assertion checking in both single-and multi-threaded Java applications. STROBE runs inside the Java virtual machine and uses copy-on-write to build snapshots incrementally. We find that asynchronous <b>checking</b> <b>scales</b> almost perfectly over synchronous checking in many cases, indicating that the snapshot overhead is quite low. STROBE provides tolerable overheads (under 2 X) even for heavy-weight assertions that would otherwise result in crushing slowdowns. 1...|$|R
40|$|Accurate {{determinations}} of {{the physical}} scale of a lattice action are required to <b>check</b> <b>scaling</b> and take the continuum limit. We present a high statistics study of the static potential for the SU(3) Wilson gauge action on coarse lattices (5 : 54 fi 6 : 0). Using an improved analysis procedure we determine the string tension and the Sommer scale r 0 (and related quantities) to 1 % accuracy, including all systematic errors. Combining our results with earlier ones on finer lattices, we present parameterizations of these quantities that should be accurate to about 1 % for 5 : 6 fi 6 : 5. We estimate the-parameter of quenched QCD to be MS = 247 (16) MeV. 1 Introduction One of the technical but very important parts of a lattice simulation is the determination {{of the physical}} scale of the lattice. Only with accurate scale determinations can one check if the ratio of an observable to the physical scale has the theoretically expected scaling violations (e. g. order a 2 for the Wilson gauge action [...] ...|$|R
40|$|To {{identify}} and correct improper weighing, poor scaling, or record keeping by the timber operator {{at the time}} of data collection. To ensure timber production is maintained within sustainable levels. Policy Procedure The Timber Management Regulation and the Forests Act both require all timber operators to provide information to the government regarding timber harvest and wood product manufacture. It is imperative that this information be accurate and complete. To ensure this, the attached procedures should be followed when <b>checking</b> weigh <b>scale</b> operations. <b>Checking</b> the Weigh <b>Scale</b> In order to account for timber volumes, a weigh scale must be approved by the Department. The weigh scale must conform to the specifications outlined in Sections 4. 2 & 4. 3 of the Alberta Scaling Manual. All weigh scales are governed by the Federal Weights and Measures Act and it...|$|R
40|$|An {{experimental}} study of the acoustic emission generated during a martensitic transformation is presented. A statistical analysis of the amplitude and lifetime {{of a large number}} of signals has revealed power-law behavior for both magnitudes. The exponents of these distributions have been evaluated and, through independent measurements of the statistical lifetime to amplitude dependence, we have <b>checked</b> the <b>scaling</b> relation between the exponents. Our results are discussed in terms of current ideas on avalanche dynamics...|$|R
30|$|The {{variables}} for age and education were recoded into categories, and assumptions for normality were <b>checked.</b> The <b>scale</b> variables Physical Activity Enjoyment Scale (Cronbach’s α =  0.87) and self-efficacy (Cronbach’s α =  0.69) were calculated, recoding each item {{into the same}} direction, and excluding system missing values. An ordered probit analysis was used (SPSS 22) to assess factors predicting WTPmoney and WTPtime. The different expectations for WTPmoney and WTPtime were tested, using p <  0.10 as the upper limit for statistical significance (Greene 2003; Jackson 2008).|$|R
40|$|We {{describe}} an access control model {{that has been}} implemented in the web content management framework "Deme" (which rhymes with "team"). Access control in Deme {{is an example of}} what we call "bivalent relation object access control"(BROAC). This model builds on recent work by Giunchiglia et al. on relation-based access control (RelBAC), as well as other work on relational, flexible, fine-grained, and XML access control models. We describe Deme's architecture and review access control models, motivating our approach. BROAC allows for both positive and negative permissions, which may conflict with each other. We argue for the usefulness of defining access control rules as objects in the target database, and for the necessity of resolving permission conflicts in a social Web/collaboration architecture. After describing how Deme access control works, including the precedence relations between different permission types in Deme, we provide several examples of realistic scenarios in which permission conflicts arise, and show how Deme resolves them. Initial performance tests indicate that permission <b>checking</b> <b>scales</b> linearly in time on a practical Deme website. Comment: in Waleed W. Smari and William MacQuay (Editors), Proceedings of the 2010 International Symposium on Collaborative Technologies and Systems (CTS 2010), IEEE, May 2010, pp. 57 - 66; 10 pages, 2 figures, 3 table...|$|R
50|$|After Clark {{refused the}} offer to take early retirement, he was {{suspended}} and the investigation began. A two-week inquiry led by former Metropolitan Police detective Dave Wood, currently head of the agency's enforcement and crime group, sought to discover to what extent <b>checks</b> were <b>scaled</b> down, and what the security implications might have been. A second investigation, led by former MI6 official Mike Anderson, the Director General of the Home Office's strategy, immigration and international group, sought to investigate wider issues relating {{to the performance of}} UKBA regarding racism.|$|R
40|$|Graduation date: 1976 The Purpose of the Study The central {{purpose of}} this study was to {{determine}} if certain personality characteristics differ between community college persisters and those who drop out of school. The following 12 a priori hypotheses involving six Adjective <b>Check</b> List personality <b>scales</b> were tested: 1. Male persisters would have a significant higher mean average than male non-persisters on the Deference (Def) Scale. 2. Female persisters would have a significantly higher mean average than female non-persisters on the Deference (Def) Scale. 3. Male persisters would have a significantly higher mean average than male non-persisters on the Succorance (SUC) scale. 4. Female persisters would have a significantly higher mean average than female non-persisters on the Succorance (SUC) scale. 5. Male persisters would have a significantly higher mean average than male non-persisters on the Order (Ord) Scale. 6. Female persisters would have a significantly higher mean average than female non-persisters on the Order (Ord) Scale. 7. Male non-persisters would have a significantly higher mean average than male persisters on the Autonomy (Aut) Scale. 8. Female non-persisters would have a significantly higher mean average than female persisters on the Autonomy (Aut) Scale. 9. Male non-persisters would have a significantly higher mean average than male persisters on the Exhibition (Exb) Scale. 10. Female non-persisters would have a significantly higher mean average than female persisters on the Exhibition (Exb) Scale. 11. Male non-persisters would have a significantly higher mean average than male persisters on the Change (Cha) Scale. 12. Female non-persisters would have a significantly higher mean average than female persisters on the Change (Cha) Scale. Procedures The project was conducted at Mt. Hood Community College, in Gresham, Oregon. One hundred and seventy-three students participated; 49 women persisters and 24 women dropouts, and 63 men persisters and 37 men who dropped out the first four weeks of spring term, 1974. The data were statistically analyzed using the F-test statistic for main effects and a t-value statistic for the subanalysis of data. Selected Findings Each of the 12 a priori hypotheses was rejected as no significant differences occurred between persisters on the following Adjective Check List scales: Order, Exhibition, Autonomy, Change, Succorance, or Deference. However, significant differences did exist on six scales when the enrollment category effect was tested. The male persisters scored significantly higher on the Defensiveness, Personal Adjustment, Intraception, Affiliation, and Number of Favorable Adjectives <b>checked</b> <b>scales.</b> And male and female persisters scored significantly higher than non-persisters on the Total Number of Adjectives <b>Checked</b> <b>scale.</b> Selected Conclusions Although all a priori hypotheses were rejected, there were a number of related findings. For instance, there were more differences between male persisters and non-persisters than female persisters when compared to female non-persisters. Differences between the categories of men occurred six times, while occurring only once among women. Generally speaking, the male dropouts appear to have a less positive self-image than male persisters. However, because personality differences vary so much among dropouts, and between persisters and dropouts, it was concluded that personality tests should not be used to attempt to predict those prone to dropping out, or to generalize that all dropouts exhibit certain unique personality traits or characteristics when compared to persisters. Selected Recommendations Based on the findings and conclusions of this project, it is recommended that additional studies be conducted to examine the conclusions listed above and the implications listed in Chapter V. In addition, it is felt that all Oregon Community Colleges should cooperatively study the dropout problem, and that the exit interview should receive more emphasis at all community colleges...|$|R
40|$|We {{explicitly}} {{compute the}} critical exponents associated with logarithmic corrections (the so-called hatted exponents) {{starting from the}} renormalization group equations and the mean field behavior for a wide class of models at the upper critical behavior (for short and long range φ^n-theories) and below it. This allows us to <b>check</b> the <b>scaling</b> relations among these critical exponents obtained by analysing the complex singularities (Lee-Yang and Fisher zeroes) of these models. Moreover, we have obtained an explicit method to compute the coppa exponent and, finally, we have found a new derivation of the scaling law associated with it...|$|R
3000|$|... (S)). We {{compare the}} {{effectiveness}} of our proposed MULTIPLEXSHIELD methods against the baseline algorithms (Random Immunization, AV, TIM, and SpreadingDegree). On the other hand, we measure the scalability by evaluating the computational time of MULTIPLEXSHIELD on various value of the budget k to <b>check</b> how it <b>scales</b> with the changing of graph size (n and m).|$|R
40|$|AbstractGoanna is an industrial-strength static {{analysis}} tool used in academia and industry alike to find bugs in C/C++ programs. Unlike existing approaches, Goanna uses the off-the-shelf model checker NuSMV as its core analysis engine on a syntactic flow-sensitive program abstraction. The CTL-based model checking approach enables {{a high degree}} of flexibility in writing <b>checks</b> and <b>scales</b> to large code bases. In this paper, a new approach to pointer analysis for C is described. It is detailed how this technique is integrated into the model checking approach in order to perform interprocedural analysis. The performance and precision of this approach are demonstrated using a case study...|$|R
40|$|During {{the course}} of {{observations}} on the growth <b>checks</b> in the <b>scales</b> of the sciaenid fish, Johzzieops ossezrs (Day), one ctenoid scale which markedly differed in structure {{from all the other}} scales was encountered in a female specimen, 160 mm in length. The scale was taken from the seventh row below the lateral line in the middle region of the body...|$|R
40|$|We {{discuss the}} 2 + 1 flavor Polyakov loop {{enhanced}} Nambu [...] Jona-Lasinio model in a finite volume. The main {{objective is to}} <b>check</b> the volume <b>scaling</b> of thermodynamic observables for various temperatures and chemical potentials. We observe the possible violation of the scaling with system size in a considerable window along the whole transition region in the T-μ_q plane...|$|R
40|$|Over {{the last}} decade process mining {{techniques}} have matured {{and more and more}} organizations started to use process mining to analyze their operational processes. The current hype around 2 ̆ 2 big data 2 ̆ 2 illustrates the desire to analyze ever-growing data sets. Process mining starts from event logs—multisets of traces (sequences of events) —and for the widespread application of process mining it is vital {{to be able to handle}} 2 ̆ 2 big event logs 2 ̆ 2. Some event logs are 2 ̆ 2 big 2 ̆ 2 because they contain many traces. Others are big in terms of different activities. Most of the more advanced process mining algorithms (both for process discovery and conformance <b>checking)</b> <b>scale</b> very badly in the number of activities. For these algorithms, it could help if we could split the big event log (containing many activities) into a collection of smaller event logs (which each contain fewer activities), run the algorithm on each of these smaller logs, and merge the results into a single result. This paper introduces a generic framework for doing exactly that, and makes this concrete by implementing algorithms for decomposed process discovery and decomposed conformance checking using Integer Linear Programming (ILP) based algorithms. ILP-based process mining techniques provide precise results and formal guarantees (e. g., perfect fitness), but are known to scale badly in the number of activities. A small case study shows that we can gain orders of magnitude in run-time. However, in some cases there is tradeoff between run-time and quality...|$|R
40|$|Abstract. Over {{the last}} decade process mining {{techniques}} have matured {{and more and more}} organizations started to use process mining to analyze their op-erational processes. The current hype around “big data ” illustrates the desire to analyze ever-growing data sets. Process mining starts from event logs—multisets of traces (sequences of events) —and for the widespread application of process mining it is vital {{to be able to handle}} “big event logs”. Some event logs are “big” because they contain many traces. Others are big in terms of different activities. Most of the more advanced process mining algorithms (both for process discov-ery and conformance <b>checking)</b> <b>scale</b> very badly in the number of activities. For these algorithms, it could help if we could split the big event log (containing many activities) into a collection of smaller event logs (which each contain fewer activities), run the algorithm on each of these smaller logs, and merge the results into a single result. This paper introduces a generic framework for doing ex-actly that, and makes this concrete by implementing algorithms for decomposed process discovery and decomposed conformance checking using Integer Linear Programming (ILP) based algorithms. ILP-based process mining techniques pro-vide precise results and formal guarantees (e. g., perfect fitness), but are known to scale badly in the number of activities. A small case study shows that we can gain orders of magnitude in run-time. However, in some cases there is tradeoff between run-time and quality. Key words: Process discovery, conformance analysis, big data, decomposition...|$|R
40|$|A {{hierarchical}} {{model for the}} growth of planar arch structures for RNA secondary structures is presented, and shown to be equivalent to a tree-growth model. Both models can be solved analytically, giving access to scaling functions for large molecules, and corrections to <b>scaling,</b> <b>checked</b> by numerical simulations of up to 6500 bases. The equivalence of both models should be helpful in understanding more general tree-growth processes...|$|R
40|$|The {{extended}} scaled {{equation of}} state (namely, the scaled form of the wave·number dependent nonlinear susceptibility) is confirmed {{up to the first}} order of 1 /n, in the classical n·vector model with general range of interactions. Critical exponents r, IJ, 1 /, 11 and. d are evaluated systematically to order 1 /n, both for short·range and long-range interactions to <b>check</b> universality and <b>scaling</b> relations...|$|R
40|$|Explicit-state model {{checking}} tools often incorporate partial-order reductions {{to reduce}} the number of system states explored (and thus the time and memory required) for verification. As model <b>checking</b> techniques are <b>scaled</b> up to software systems, it is important to develop and assess partial-order reduction strategies that are effective for addressing the complex structures found in software and for reducing the tremendous cost of model checking software systems. In this paper [...] ...|$|R
