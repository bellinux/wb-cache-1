1053|80|Public
25|$|Several schemes assist {{managing}} programmer activity so {{that fewer}} bugs are produced. Software engineering (which addresses software design issues as well) applies many techniques to prevent defects. For example, formal program specifications state the exact behavior of programs so that design bugs may be eliminated. Unfortunately, formal specifications are impractical {{for anything but}} the shortest programs, because of problems of <b>combinatorial</b> <b>explosion</b> and indeterminacy.|$|E
25|$|The general {{problem of}} solving Sudoku puzzles on n2×n2 grids of n×n blocks {{is known to}} be NP-complete. Many {{computer}} algorithms, such as backtracking and dancing links can solve most 9×9 puzzles efficiently, but <b>combinatorial</b> <b>explosion</b> occurs as n increases, creating limits to the properties of Sudokus that can be constructed, analyzed, and solved as n increases. A Sudoku puzzle can be expressed as a graph coloring problem. The aim is to construct a 9-coloring of a particular graph, given a partial 9-coloring.|$|E
500|$|<b>Combinatorial</b> <b>explosion</b> (with {{summary of}} grid count of Sudoku {{compared}} to Latin squares) ...|$|E
40|$|Do {{there exist}} general principles, which any system must obey {{in order to}} achieve {{advanced}} general intelligence using feasible computational resources? Here we propose one candidate: “cognitive synergy, ” a principle which suggests that general intelligences must contain different knowledge creation mechanisms corresponding to different sorts of memory (declarative, procedural, sensory/episodic, attentional, intentional); and that these different mechanisms must be interconnected {{in such a way as}} to aid each other in overcoming memory-type-specific <b>combinatorial</b> <b>explosions...</b>|$|R
40|$|The {{construction}} of expert problem-solving systems requires {{the development of}} techniques for using modular representations of knowledge without encountering <b>combinatorial</b> <b>explosions</b> in the solution effort. This report describes an {{approach to dealing with}} this problem based on making some knowledge which is usually implicitly part of an expert problem solver explicit, thus allowing this knowledge about control to be manipulated and reasoned about. The basic components of this approach involve using explicit representations of the control structure of the problem solver, and linking this an...|$|R
40|$|A {{range of}} {{research}} has explored the problem of generating referring expressions that uniquely identify a single entity from the shared context. But what about expressions that identify sets of entities? In this paper, I adapt recent semantic research collective and distributive readings and using sets of assignments to represent dependencies among references—to describe a search problem for set-identifying expressions that largely mirrors the search problem for singular referring expressions. By structuring the search space {{only in terms of}} the words that can be added to the description, the proposal defuses potential <b>combinatorial</b> <b>explosions</b> that might otherwise arise with reference to sets. ...|$|R
500|$|... (The report {{specifically}} {{mentioned the}} <b>combinatorial</b> <b>explosion</b> problem {{as a reason}} for AI's failings.) ...|$|E
500|$|Intractability and the <b>combinatorial</b> <b>explosion.</b> In 1972 Richard Karp (building on Stephen Cook's 1971 theorem) showed {{there are}} many {{problems}} that can probably only be solved in exponential time (in {{the size of the}} inputs). Finding optimal solutions to these problems requires unimaginable amounts of computer time except when the problems are trivial. This almost certainly meant that many of the [...] "toy" [...] solutions used by AI would probably never scale up into useful systems.|$|E
2500|$|<b>Combinatorial</b> <b>explosion</b> - (with {{summary of}} grid count of Sudoku {{compared}} to Latin squares) ...|$|E
40|$|ADATE) [2] is {{a system}} for {{automatic}} programming based on the neutral theory of evolution [1]. This theory states {{that the majority of}} molecular changes in evolution are due to neutral or almost neutral mu-tations. A consequence {{is that most of the}} variabil-ity and polymorphism within a species comes from mutation-driven drift of alleles that are selectively neu-tral or nearly neutral. In ADATE, as well as in natural evolution, neutral walks in genotype space are essential for avoiding <b>combinatorial</b> <b>explosions</b> due to complex mutations. The compound transformations in ADATE were de-signed according to this model of transition from one species to the next. In ADATE, the rst part of a com-pound program transformation is the neutral walk an...|$|R
50|$|In {{normalized}} {{systems theory}} it's believed that today's IT problems are symptoms of something {{deeper and more}} fundamental. The theory {{is the result of}} identifying these fundamental principles, patterns and other methodological elements for building evolvable software architectures for enterprise systems. Indeed, the basic assumption of normalized systems is that information systems should be able to evolve over time, and should be designed to accommodate change. Normalized systems principles define the rules according to which software architectures have to be built so that there are no <b>combinatorial</b> <b>explosions</b> in the impacts of predefined changes to the system. In normalized systems vision, Douglas McIlroy's dream of constructing information systems based upon rational principles becomes a reality.|$|R
40|$|Model-based vision systems must {{be capable}} of dealing with large {{quantities}} of hypothetical interpretations. Hypothesise-and-test methods often lead to <b>combinatorial</b> <b>explosions</b> of possible inter-pretations. Discrimination graphs prevent such explosions by im-posing a hierarchical organisation on the domain of interpretation. Such an organisation effectively reduces the number of interpre-tations that the system has to deal with. This paper presents an algorithm which automatically constructs discrimination graphs. 1 In t roduc t i on If we are to develop a "general-purpose * vision system which can take as input a digitised picture of any natural scene and which produces as output a meaningful description of such a scene, then we must equip the system with a representation which allows for a quick and smooth access to domain-specific knowledge. Mos...|$|R
2500|$|There {{are several}} {{computer}} algorithms that will solve most 9×9 puzzles (=9) in fractions of a second, but <b>combinatorial</b> <b>explosion</b> occurs as [...] increases, creating {{limits to the}} properties of Sudokus that can be constructed, analyzed, and solved as [...] increases.|$|E
2500|$|For instance, it {{has been}} {{estimated}} that the yeast scaffold protein Ste5 can be a part of 25666 unique protein complexes. In E. coli, chemotaxis receptors of four different kinds interact in groups of three, and each individual receptor can exist in at least two possible conformations and has up to eight methylation sites, resulting in billions of potential states. The protein kinase CaMKII is a dodecamer of twelve catalytic subunits, arranged in two hexameric rings. [...] Each subunit can exist in at least two distinct conformations, and each subunit features various phosphorylation and ligand binding sites. A recent model incorporated conformational states, two phosphorylation sites and two modes of binding calcium/calmodulin, for a total of around one billion possible states per hexameric ring. A model of [...] coupling of the EGF receptor to a MAP kinase cascade presented by Danos and colleagues accounts for [...] distinct molecular species, yet the authors note several points at which the model could be further extended. A more recent model of ErbB receptor signalling even accounts for more than one googol (...) distinct molecular species. The problem of <b>combinatorial</b> <b>explosion</b> is also relevant to synthetic biology, with a recent model of a relatively simple synthetic eukaryotic gene circuit featuring 187 species and 1165 reactions.|$|E
5000|$|<b>Combinatorial</b> <b>explosion</b> (with {{summary of}} grid count of Sudoku {{compared}} to Latin squares) ...|$|E
40|$|Abstract. Over {{the last}} few years, a few {{approaches}} have been proposed aiming to combine genetic and evolutionary computation (GECCO) with inductive logic programming (ILP). The underlying rationale is that evolutionary algorithms, such as genetic algorithms, might mitigate the <b>combinatorial</b> <b>explosions</b> generated by the inductive learning of rich representations, such as those used in first-order logic. Particularly, the binary representation approach presented by Tamaddoni-Nezhad and Muggleton has {{attracted the attention of}} both the GECCO and ILP communities in recent years. Unfortunately, a series of systematic and fundamental theoretical errors renders their framework moot. This paper critically examines the fallacious claims in the mentioned approach. It is shown that, far from restoring completeness to the learner progol’s search of the subsumption lattice, the binary representation approach is both overwhelmingly unsound and severely incomplete. ...|$|R
40|$|Knowledge Intensive CAD {{requires}} {{extension of}} the object-oriented paradigm because object-oriented hierarchies are fundamentally based upon ancestral relations. Knowledge Intensive CAD demands software capabilities to allow the user to model relationships that are significantly more complex than inheiritance. Propagations are proposed as an object-oriented software engineering extension to facilitate modeling of interrelationships between features. Such object modeling provides an effective software tool for localized perspectives upon design knowledge stored in rule and case bases. These local views show promise {{as a means to}} avoid the <b>combinatorial</b> <b>explosions</b> common to knowledge based systems, as will be discussed with respect to a completed industrial example and to ongoing work on rapid prototyping data. Keywords Object modeling, knowledge bases, CAD, features, case-based reasoning. 1 Introduction: Objects and Knowledge Feature definitions are fundamental to CAD knowledge repre [...] ...|$|R
40|$|Our goal is {{to enable}} {{military}} planners to rapidly critique alternative battle plans by simulating multiple outcomes of adversarial plans. We describe a novel simulator, SimPath, that combines qualitative reasoning, a geographic information system (GIS), and targeted probabilistic calculations to envision how adversarial battle plans can play out. We outline the problem and describe the overall operation of the simulator. We then explain how qualitative process theory is extended with actions to model military tasks, how envisioning is factored to reduce <b>combinatorial</b> <b>explosions,</b> and how probabilities are computed for transitions and used to filter possibilities. Empirical results, including an experiment conducted by an independent evaluator, are summarized. The results show {{that it is possible}} to identify dozens of possible outcomes on each of 9 combinations of adversarial plans (COAs) in under two minutes. We close with a discussion of future work...|$|R
5000|$|A <b>combinatorial</b> <b>explosion</b> {{can also}} occur in some puzzles {{played on a}} grid, such as Sudoku. A Sudoku {{is a type of}} Latin square with the {{additional}} property that each element occurs exactly once in sub-sections of size [...] (called boxes). <b>Combinatorial</b> <b>explosion</b> occurs as [...] increases, creating limits to the properties of Sudokus that can be constructed, analyzed, and solved, as illustrated in the following table.|$|E
5000|$|... {{as a model}} checker, JPF is {{susceptible}} to <b>Combinatorial</b> <b>explosion,</b> although it performs on-the-fly Partial order reduction ...|$|E
50|$|In mathematics, a <b>combinatorial</b> <b>explosion</b> is an {{informal}} {{term used to}} describe the rapid growth of the complexity of a problem due to how the combinatorics of the problem is affected by the input, constraints, and bounds of the problem. <b>Combinatorial</b> <b>explosion</b> is sometimes used to justify the intractability of certain problems. Examples of such problems include certain mathematical functions, the analysis of some puzzles and games, and some pathological examples which can be modelled as the Ackermann function.|$|E
40|$|Implicit {{enumeration}} {{of prime}} implicates in Truth Maintenance System (TMS) is investigated. CMS (Clause Management System), {{an extension of}} Assumption-based TMS (ATMS), that accepts any type of justification has a burden to compute all prime implicates, since its complexity is NP-complete. To improve the performance of multiple-context TMS such compact representation of boolean functions. In this paper, we propose a BDD-based Multiple-context TMS (BMTMS) and present the design and implementation of interface between TMS and BDD. The interface provides high level specifications of logical formulas, and has mechanisms to schedule BDD commands to avoid <b>combinatorial</b> <b>explosions</b> in constructing BDDs. In BMTMS, most TMS operations are carried out without enumerating all prime implicates. 1 INTRODUCTION The capability of thinking with explicit multiple alternatives is required by sophisticated problem solving systems such as qualitative simulation, multi-fault diagnosis or non-monotonic reas [...] ...|$|R
40|$|The {{problem of}} {{constructing}} a combination set {{to represent a}} collection of all solutions by solving constraint satisfaction problems is considered. Two kinds of combination set operations, restriction and exclusion, are invented. Simplification theorems on these two operations {{plays an important role}} to avoid <b>combinatorial</b> <b>explosions.</b> In addition, a zero-suppressed BDD, a variation of ordered binary decision diagrams, is adopted to represent a combination set and efficient implementations of the two operations are presented. Keywords: combination set operations; restriction and exclusion operators; constraint satisfaction problem; binary decision diagram; zero-suppressed BDD 1 Introduction A combination set can be manipulated efficiently by means of a zero-suppressed binary decision diagram (ZBDD) [5], a variant of reduced ordered BDD [1]. We apply combination sets to construct a collection of all solutions by solving a constraint satisfaction problem (CSP) [4]. The conventional way t [...] ...|$|R
40|$|A {{range of}} {{research}} has explored the problem of generating referring expressions that uniquely identify a single entity from the shared context. But what about expressions that identify sets of entities ? In this paper, I adapt recent semantic research on plural descriptions [...] -using covers to abstract collective and distributive readings and using sets of assignments to represent dependencies among references [...] -to describe a search problem for set-identifying expressions that largely mirrors the search problem for singular referring expressions. By structuring the search space {{only in terms of}} the words that can be added to the description, the proposal defuses potential <b>combinatorial</b> <b>explosions</b> that might otherwise arise with reference to sets. 1 Introduction Natural language interaction lends itself to tasks like generalization, abstraction, comparison, and summarization which call for SETS of objects to be picked out using definite referring expressions. For example, consider the [...] ...|$|R
50|$|The Combs {{method is}} a method of writing fuzzy logic rules {{described}} by William E. Combs in 1997. It is designed to prevent <b>combinatorial</b> <b>explosion</b> in fuzzy logic rules.|$|E
50|$|At {{present the}} theory is limited by incomputability (the halting problem). Approximations {{may be used to}} avoid this. Processing speed and <b>combinatorial</b> <b>explosion</b> remain the primary {{limiting}} factors for artificial intelligence.|$|E
5000|$|The [...] "C" [...] in CPQ {{deals with}} the complex {{challenges}} of combining components and parts into a sellable product.There are three main approaches employed to alleviate the problem of <b>combinatorial</b> <b>explosion.</b>|$|E
40|$|Abstract. Ontologies {{have been}} highly {{successful}} in applications involving annotation and data fusion. However, ontologies {{as the core}} of “Knowledge Driven Architectures ” have not achieved the same influence as “Model Driven Architectures”, {{despite the fact that}} many biomedical applications require features that seem achievable only via ontological technologies – composition of descriptions, automatic classification and inference, and management of <b>combinatorial</b> <b>explosions</b> in many contexts. Our group adopted Knowledge Driven Architectures based on ontologies to address these problems in the early 1990 s. In this paper we discuss first the use cases and requirements and then some of the requirements for more effective use of Knowledge Driven Architectures today: clearer separation of language and formal ontology, integration with contingent knowledge, richer and better distinguished annotations, higher order representations, integration with data models, and improved auxiliary structures to allow easy access and browsing by users...|$|R
40|$|While a {{reinforcement}} learning agent {{can rely on}} memoryless policies to solve a completely observable Markov problem, {{it is no longer}} the case with partially observable problems. An alternative is to use the history of previous observations. In theory, an infinite memory of the past is required, but to prevent <b>combinatorial</b> <b>explosions,</b> a finite memory, either with finite or infinite horizon (remember a finite number of events which can be arbitrary old) is usually used. The work presented here belongs to the last category as the agents must choose an action given the present observation and contextual information. This contextual-memory architecture should be able to solve many usual partially observable Markov problems by allowing the agent to distinguish between ambiguous observations. But the learning agent is still confronted to a highly non-Markovian task. Figure 1 illustrates this on a simple example. To that effect, several learning algorithms [...] ...|$|R
40|$|A common {{approach}} to social distancing in robot navigation are spatial cost functions around humans {{that cause the}} robot to prefer paths that do not come too close to humans. However, in unpredictably dynamic scenarios, following such paths may produce robot behavior that appears confused. The concept of directional costs in cost functions [9] is supposed to alleviate this problem without incurring the problem of <b>combinatorial</b> <b>explosions</b> using temporal planning. With directional cost functions, a robot attempts to solve spatial conflicts by adjusting the velocity instead of the path, where possible. To complement results from simulations, {{in this paper we}} describe a user study we conducted with a PR 2 robot and human participants to evaluate the new cost function type. The study shows that the real robot behavior is similar to the observations in simulation, and that participants rate the robot behavior less confusing with the adapted cost model. The study also shows other important behavior cues that can influence motion legibility...|$|R
50|$|Higher {{branching}} factors make algorithms {{that follow}} every branch at every node, such as exhaustive brute force searches, computationally more expensive {{due to the}} exponentially increasing number of nodes, leading to <b>combinatorial</b> <b>explosion.</b>|$|E
50|$|A {{generalisation}} to k-point alignments (ignoring edge effects) iswhich has roughly similar asymptotic scaling properties as {{the crude}} approximation {{in the previous}} section, with <b>combinatorial</b> <b>explosion</b> for large n overwhelming the effects of other variables.|$|E
5000|$|In {{administration}} and computing, a <b>combinatorial</b> <b>explosion</b> is the rapidly accelerating increase in communication lines as organizations are {{added in a}} process. (This growth is often casually described as [...] "exponential" [...] but is actually polynomial.) ...|$|E
40|$|Workflow {{verification}} {{has been}} a well studied research topic {{during the past few}} years. Theorem proof based approaches to workflow verification become popular due to several advantages including being based on formal characterization with rigorous and non-ambiguous inference mechanisms. However, a common problem to these inference mechanisms is <b>combinatorial</b> <b>explosions,</b> which forms a major performance hurdle to workflow verification systems based on inference. In this paper, we study how randomization enables reuse and reduces processing time in logic based workflow verification approaches. We, in particular, look at a propositional logic based workflow verification technique. For the logic inference rules, which are used to infer new truthful propositions from existing truthful propositions in this logic, we apply randomization to the inference rules after each verification task such that new inference rules reflecting the componentized verification are added to the inference rule sets. We reviewed the savings incurred in verifying a workflow pattern and provide a theoretical analysis...|$|R
40|$|The {{emergence}} of complex patterns of organization {{close to the}} Cambrian boundary {{is known to have}} happened over a (geologically) short period of time. It involved the rapid diversification of body plans and stands as one of the major transitions in evolution. How it took place is a controversial issue. Here we explore this problem by considering a simple model of pattern formation in multicellular organisms. By modeling gene network-based morphogenesis and its evolution through adaptive walks, we explore the question of how <b>combinatorial</b> <b>explosions</b> might have been actually involved in the Cambrian event. Here we show that a small amount of genetic complexity including both gene regulation and cell-cell signaling allows one to generate an extraordinary repertoire of stable spatial patterns of gene expression compatible with observed anteroposterior patterns in early development of metazoans. The consequences for the understanding of the tempo and mode of the Cambrian event are outlined. Comment: to appear in International Journal of Developmental Biology, special issue on Evo-Devo (2003...|$|R
40|$|The {{number of}} ways a system must be tested can often be overwhelming. There {{are a number of}} {{automatic}} testcase generation tools available but these can suffer from <b>combinatorial</b> <b>explosions</b> in the number of possibilities to test. We have combined table based testing, code coverage with Bellcore's Automatic Efficient Testcase Generator (AETG) to generate small efficient sets of testcases. AETG uses a pair-wise testcase generation technique to generate tables of test vectors, which a test driver can then execute immediately. Code coverage is then used to indicate missing functionality from AETG's model. Our initial trial of this was on a subset Nortel's internal e-mail system where we able cover 97 % of branches with less than 100 valid and invalid testcases, as opposed to 27 trillion exhaustive testcases. Since then we have used it to implement low level white box testing of individual procedures up to high level black box testing of interactions between different call processing feature [...] ...|$|R
