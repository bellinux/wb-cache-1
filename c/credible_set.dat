65|103|Public
5|$|Genotyping arrays {{designed}} for GWAS rely on linkage disequilibrium to provide {{coverage of the}} entire genome by genotyping a subset of variants. Because of this, the reported associated variants {{are unlikely to be}} the actual causal variants. Associated regions can contain hundreds of variants spanning large regions and encompassing many different genes, making the biological interpretation of GWAS loci more difficult. Fine-mapping is a process to refine these lists of associated variants to a <b>credible</b> <b>set</b> most likely to include the causal variant.|$|E
50|$|In 1995, {{the trial}} court found the recantations <b>credible,</b> <b>set</b> aside Joe Elizondo’s {{conviction}} and ordered a new trial. In December 1996, the Texas Court of Criminal Appeals upheld {{the trial court}} ruling. “Robert’s recantation not only voids his trial testimony which implicated (Joe Elizondo), but constitutes affirmative evidence of (Joe Elizondo’s) innocence,” the appeals court ruled. “We are convinced by clear and convincing evidence that no rational jury would convict him {{in light of the}} new evidence.” On June 23, 1997, Jefferson County District Attorney Paul McWilliams dismissed the charges against Joe Elizondo and he was released from prison that day. Mary Ann then sought to vacate her conviction. In November 2005, the Texas Court of Criminal Appeals, following the decision made in Joe Elizondo’s case, vacated her conviction and the charges were dismissed. Sadly, Joe Elizondo, who's health was poor in prison, died in 2003. In October 2008, Mary Ann (Barbosa), who had filed a state compensation claim, received her compensation of $370,833. It is unknown as to whether charges were ever filed against Richard Bienvenue, Sr., for causing his sons to falsely accuse sexual abuse against Joe and Mary Ann Elizondo.|$|E
5000|$|The International Social and Environmental Accreditation and Labelling (ISEAL) Alliance is {{a global}} {{association}} for social and environmental standards whose members include many of the major standards systems active in sustainable coffee such as: Fair trade, Rainforest Alliance, UTZ Certified and the 4C Association. Its members have resolved to abide by applying a new Impacts Code in 2010 that requires them to develop a transparent Assessment Plan to provide reasonable measurement of their impacts. Another initiative is already developing and applying scientific metrics to understand sustainability impacts at the field level. The non-profit Committee on Sustainability Assessment (COSA), is a consortium of global organizations led by the International Institute for Sustainable Development, (IISD) and the United Nations Conference on Trade and Development (UNCTAD), {{as part of their}} Sustainable Commodity Initiative (SCI), is already developing and applying scientific metrics to understand sustainability impacts at the field level. COSA’s stated purpose is to measure sustainability and its mandate is to achieve [...] "a <b>credible</b> <b>set</b> of common global measures for agricultural sustainability along the three balanced principles (environmental, social, and economic)". [...] The unanimous International Coffee Organization endorsement of the COSA program notes that COSA builds management capacity with local partnerships in producing countries to facilitate an understanding of the effects (costs and benefits) of the many sustainability initiatives. [...] The United Nations International Trade Centre (ITC) and its Trade for Sustainable Development program is also developing a global online platform to better understand the distinctions of the diverse sustainability initiatives with basic comparisons of the standards and also a mapping system of their availability. ITC has also announced partnering with COSA to make the COSA database of thousands of scientific observations on this topic available publicly in 2011-12.|$|E
40|$|International audienceMAP estimators and HPD <b>credible</b> <b>sets</b> {{are often}} criticized in the {{literature}} because of paradoxical behaviour {{due to a lack}} of equivariance under reparametrization. In this paper, we propose a new version of MAP estimators and HPD <b>credible</b> <b>sets</b> that avoid this undesirable feature. Moreover, in the special case of non-informative prior, the new MAP estimators coincide with the equivariant frequentist ML estimators. We also propose several adaptations in the case of nuisance parameters...|$|R
40|$|In {{this paper}} we develop and study {{adaptive}} empirical Bayesian smoothing splines. These are smoothing splines with both smoothing parameter and penalty order determined via the empirical Bayes method from the marginal likelihood of the model. The selected order and smoothing parameter {{are used to}} construct adaptive <b>credible</b> <b>sets</b> with good frequentist coverage for the underlying regression function. We use these <b>credible</b> <b>sets</b> as a proxy to show the superior performance of adaptive empirical Bayesian smoothing splines compared to frequentist smoothing splines...|$|R
40|$|A {{large sample}} {{approximation}} of the posterior distribution of partially identified structural parameters is derived for models {{that can be}} indexed by a finite-dimensional reduced form parameter vector. It is {{used to analyze the}} differences between frequentist confidence <b>sets</b> and Bayesian <b>credible</b> <b>sets</b> in partially identified models. A key difference is that frequentist set estimates extend beyond the boundaries of the identified set (conditional on the estimated reduced form parameter), whereas Bayesian <b>credible</b> <b>sets</b> can asymptotically be located in the interior of the identified set. Our asymptotic approximations are illustrated in the context of simple moment inequality models and a numerical illustration for a two-player entry game is provided. ...|$|R
40|$|In robust Bayesian analysis, {{it is of}} {{interest}} to find the optimal robust <b>credible</b> <b>set,</b> viz: the smallest set with posterior probability at least, say [gamma], with respect to each prior in the class. Here, we derive the optimal robust <b>credible</b> <b>set</b> for the [var epsilon]-contamination class of priors with arbitrary contaminations. Optimal robust credible sets [var epsilon]-contamination classes Bayesian robustness posterior probability...|$|E
40|$|In Rethinking the Economics of Land and Housing. Josh Ryan-Collins, Toby Lloyd and Laurie Macfarlane offer a {{critical}} {{exploration of the}} UK land economy {{and its impact on}} contemporary issues such as housing policy. This is a crisp and incisive critique of the inadequate treatment afforded to land and housing within mainstream economics that provides readers with a <b>credible</b> <b>set</b> of alternatives, writes John Tomaney...|$|E
40|$|We {{study the}} problem of {{estimating}} the mode and maximum of an unknown regression function {{in the presence of}} noise. We adopt the Bayesian approach by using tensor product B-splines and endowing the coefficients with Gaussian priors. In the usual fixed-in-advanced sampling plan, we establish posterior contraction rates for mode and maximum and show that they coincide with the minimax rates for this problem. To quantify estimation uncertainty, we construct credible sets for these two quantities that have high coverage probabilities with optimal sizes. If one is allowed to collect data sequentially, we further propose a Bayesian two-stage estimation procedure, where a second stage posterior is built based on samples collected within a <b>credible</b> <b>set</b> arising from a first stage posterior. Under appropriate conditions on the radius of this <b>credible</b> <b>set,</b> we can accelerate optimal contraction rates in the fixed-in-advanced setting to the minimax sequential rates. A simulation experiment shows that our Bayesian two-stage procedure outperforms single-stage procedure and also slightly improves upon a non-Bayesian two-stage procedure, due to shrinkage effect of our Bayesian estimators. Comment: 29 pages, 2 figure...|$|E
40|$|We {{consider}} {{the problem of}} constructing Bayesian based confidence sets for linear functionals in the inverse Gaussian white noise model. We work with a scale of Gaussian priors indexed by a regularity hyper-parameter and apply the data-driven (slightly modified) marginal likelihood empirical Bayes method for the choice of this hyper-parameter. We show by theory and simulations that the <b>credible</b> <b>sets</b> constructed by this method have sub-optimal behaviour in general. However, by assuming "self-similarity" the <b>credible</b> <b>sets</b> have rate-adaptive size and optimal coverage. As an application of these results we construct L_∞-credible bands for the true functional parameter with adaptive size and optimal coverage under self-similarity constraint. Comment: 11 pages, 2 figure...|$|R
40|$|The {{posterior}} distribution in a nonparametric inverse problem {{is shown to}} contract to the true parameter {{at a rate that}} depends on the smoothness of the parameter, and the smoothness and scale of the prior. Correct combinations of these characteristics lead to the minimax rate. The frequentist coverage of <b>credible</b> <b>sets</b> is shown to depend on the combination of prior and true parameter, with smoother priors leading to zero coverage and rougher priors to conservative coverage. In the latter case <b>credible</b> <b>sets</b> are of the correct order of magnitude. The results are numerically illustrated by the problem of recovering a function from observation of a noisy version of its primitive. © Institute of Mathematical Statistics, 2011...|$|R
40|$|It {{has long}} been {{asserted}} that in univariate location-scale models, when concerned with inference for either the location or scale parameter, {{the use of the}} inverse of the scale parameter as a Bayesian prior yields posterior <b>credible</b> <b>sets</b> which have exactly the correct frequentist confidence set interpretation. This claim dates to at least Peers (1965), and has subsequently been noted by various authors, with varying degrees of justification. We present a simple, direct demonstration of the exact matching property of the posterior <b>credible</b> <b>sets</b> derived under use of this prior in the univariate location-scale model. This is done by establishing an equivalence between the conditional frequentist and posterior densities of the pivotal quantities on which conditional frequentist inferences are based...|$|R
40|$|The {{paper is}} {{discussing}} {{the need for}} convergence in European higher education, as it was claimed and negotiated in the last decade, accompanied by the results and prospects of a research project advancing and testing a <b>credible</b> <b>set</b> of indicators of convergence in the European Higher Education Area. The main limitations and problems are addressed to, together with {{an overview of the}} indicators proposed, and of the ways of advancing the research in the field...|$|E
40|$|New {{application}} of the Full Bayesian Significance Test (FBST) for precise hypotheses is presented. The FBST is an alternative to significance tests or, equivalently, to p-values. In the FBST we compute {{the evidence of the}} precise hypothesis. This evidence is the complement of the probability of a <b>credible</b> <b>set</b> "tangent" to the sub-manifold (of the parameter space) that defines the null hypothesis. We use the FBST to compare coefficients of variation, in applications arising in finance and industrial engineering...|$|E
40|$|A {{common problem}} in Bayesian {{statistics}} {{is to determine}} whether a quantity obtained from a Bayesian posterior distribution is also meaningful in a frequentist context. In this thesis, we try to answer this question for credible sets in the so-called fixed design model. Taking a specific prior distribution, we study whether credible sets based on this prior can also be used as confidence intervals. In particular, our aim is to construct a <b>credible</b> <b>set</b> for a parameter function. Under certain assumptions on the smoothness of the function, it turns out that we can obtain meaningful results about both the frequentist coverage and the width of the <b>credible</b> <b>set.</b> We consider several different classes of functions in this thesis, each with a different set of assumptions. In the first chapter, we assume that we know rather a lot about the structure of the function, and use this to obtain a useful method. In chapter 2, we extend this to a method that adapts to the structure of the function. Finally, in the last chapter, we extend this to so-called credible bands, that describe the behaviour of the entire function, rather than at a specific point. Promotor: A. W. van der VaartWith Summary in Dutc...|$|E
40|$|We {{study the}} Bernstein-von Mises (BvM) phenomenon, i. e., Bayesian <b>credible</b> <b>sets</b> and frequentist {{confidence}} regions for the estimation error coincide asymptotically, for the infinite-dimensional Gaussian white noise model governed by Gaussian prior with diagonal-covariance structure. While in parametric statistics {{this fact is}} a consequence of (a particular form of) the BvM Theorem, in the nonparametric setup, however, the BvM Theorem is known to fail even in some, apparently, elementary cases. In the present paper we show that BvM-like statements hold for this model, provided that the parameter space is suitably embedded into the support of the prior. The overall conclusion is that, unlike in the parametric setup, positive results regarding frequentist probability coverage of <b>credible</b> <b>sets</b> can only be obtained if the prior assigns null mass to the parameter space...|$|R
40|$|We {{investigate}} {{the problem of}} constructing Bayesian <b>credible</b> <b>sets</b> that are honest and adaptive for the L 2 L 2 -loss over a scale of Sobolev classes with regularity ranging between [D, 2 D][D, 2 D], for some given DD {{in the context of}} the signal-in-white-noise model. We consider a scale of prior distributions indexed by a regularity hyper-parameter and choose the hyper-parameter both by marginal likelihood empirical Bayes and by hierarchical Bayes method, respectively. Next we consider a ball centred around the corresponding posterior mean with prescribed posterior probability. We show by theory and examples that both the empirical Bayes and the hierarchical Bayes <b>credible</b> <b>sets</b> give misleading, overconfident uncertainty quantification for certain oddly behaving truth. Then we construct a new empirical Bayes method based on risk estimation, which provides the correct uncertainty quantification and optimal size...|$|R
30|$|Coverage probabilities {{are used}} to value a prior good or bad. The idea, as {{suggested}} by Ye (1993), is that if prior π _ 1 has generally smaller difference between the posterior probabilities of Bayesian <b>credible</b> <b>sets</b> and the frequentist probabilities of the corresponding confidence sets than does π _ 2, then prior π _ 1 is favorable.|$|R
40|$|For {{a general}} {{statistical}} model, we introduce {{the notion of}} data dependent measure (DDM) on the model parameter. Typical examples of DDM are the posterior distributions. Like for posteriors, {{the quality of a}} DDM is characterized by the contraction rate which we allow to be local, i. e., depending on the parameter. We construct confidence sets as DDM-credible sets and address the issue of optimality of such sets, via a trade-off between its "size" (the local radial rate) and its coverage probability. In the mildly ill-posed inverse signal-in-white-noise model, we construct a DDM as empirical Bayes posterior with respect to a certain prior, and define its (default) <b>credible</b> <b>set.</b> Then we introduce 'excessive bias restriction' (EBR), more general than 'self-similarity' and 'polished tail condition' recently studied in the literature. Under EBR, we establish the confidence optimality of our <b>credible</b> <b>set</b> with some local (oracle) radial rate. We also derive the oracle estimation inequality and the oracle DDM-contraction rate, non-asymptotically and uniformly in ℓ_ 2. The obtained local results are more powerful than global: adaptive minimax results for a number of smoothness scales follow as consequence, in particular, the ones considered by Szabo, van der Vaart and van Zanten (2015). Comment: 26 pages + supplement 18 page...|$|E
40|$|Jul- 01 - 2000 rev. Oct- 10 - 2000 New {{application}} of the Full Bayesian Signi cance Test (FBST) for precise hypotheses are presented. The FBST is an alternative to signi cance tests or, equivalently, top-values. In the FBST we compute {{the evidence of the}} precise hypothesis. This evidence is the probability of a <b>credible</b> <b>set</b> " to the sub-manifold (of the parameter space) that de nes the null hypothesis. We use the FBST to compare coe cients of variation, in applications arising in nance and industrial engineering...|$|E
40|$|The Full Bayesian Signi cance Test (FBST) for precise {{hypotheses}} is presented, {{with some}} applications relevant to reliability theory. The FBST {{is an alternative}} to signi cance tests or, equivalently, to p-values. In the FBST we compute {{the evidence of the}} precise hypothesis. This evidence is the probability of the complement of a <b>credible</b> <b>set</b> " to the sub-manifold (of the parameter space) that de nes the null hypothesis. We use the FBST in an application requiring a quality control of used components, based on remaining life statistics...|$|E
40|$|Higher-order {{asymptotic}} {{arguments for}} a scalar parameter of interest {{have been widely}} investigated for Bayesian inference. In this paper the theory of asymptotic expansions is discussed for a vector parameter of interest. A modified loglikelihood ratio is suggested, {{which can be used}} to derive approximate Bayesian <b>credible</b> <b>sets</b> with accurate frequentist coverage. Three examples are illustrated...|$|R
40|$|To further {{investigate}} susceptibility loci {{identified by}} genome-wide association studies, we genotyped 5, 500 SNPs across 14 associated regions in 8, 000 samples from {{a control group}} and 3 diseases: type 2 diabetes (T 2 D), coronary artery disease (CAD) and Graves 2 ̆ 7 disease. We defined, using Bayes theorem, <b>credible</b> <b>sets</b> of SNPs that were 95...|$|R
40|$|We {{consider}} the likelihood and Bayesian {{estimation of the}} stress-strength reliability based on lower record values from the generalized exponential distribution. The estimators are derived and their properties are studied. Confidence intervals, exact and approximate, {{as well as the}} Bayesian <b>credible</b> <b>sets</b> for the stress-strength reliability are obtained. A simulation study is conducted to investigate and compare the performance of the intervals. ...|$|R
40|$|The {{salamander}} Ensatina eschscholtzii Gray is {{a classic}} example of a ring species, or a species that has expanded around a central barrier to form a secondary contact characterized by species-level divergence. In the original formulation of the ring species scenario, an explicit biogeographical model was proposed to account for the occurrence of intraspecific sympatry between two subspecies in southern California (the 'southern closure' model). Here we develop an alternative ring species model that is informed by the geomorphological development of the California Coast Ranges, and which situates the point of ring closure in the Monterey Bay region of central coastal California (the 'Monterey closure' model). Our study has two aims. The first is to use phylogenetic methods to evaluate the two competing biogeographical models. The second is to describe patterns of phylogeographical diversity throughout the range of the Ensatina complex, and to compare these patterns with previously published molecular systematic data. Western North America, with a focus on the state of California, USA. We obtained mitochondrial DNA sequence data from 385 individuals from 224 populations. A phylogeny was inferred using Bayesian techniques, and the geographical distributions of haplotypes and clades were mapped. The two biogeographical ring species models were tested against our Bayesian topology, including the associated Bayesian 95 % <b>credible</b> <b>set</b> of trees. High levels of phylogeographical diversity were revealed, especially in central coastal and northern California. Our Bayesian topology contradicts the Monterey closure model; however, 0. 08 % of the trees in our Bayesian 95 % <b>credible</b> <b>set</b> are consistent with this model. In contrast, the classic ring species biogeographical model (the southern closure model) is consistent with our Bayesian topology, as were 99. 92 % of the trees in our 95 % <b>credible</b> <b>set.</b> Our Bayesian phylogenetic analysis most strongly supports the classic ring species model, modified to accommodate an improved understanding of the complex geomorphological evolution of the California Coast Ranges. In addition, high levels of phylogeographical diversity in central and northern California were identified, which is consistent with the striking levels of allozymic differentiation reported previously from those regions...|$|E
40|$|AFIT-ENG-MS- 15 -M- 033 Traditional {{estimation}} schemes such as Maximum A Posterior (MAP) or Maximum Likelihood Estimation (MLE) {{determine the}} most likely parameter set associated with received signal data. However, traditional schemes do not retain entire posterior distribution, provide no confidence information associated with the final solution, and often rely on simple sampling methods which induce significant errors. Also, traditional schemes perform inadequately when applied to complex signals which often result in multi-modal parameter sets. <b>Credible</b> <b>Set</b> Estimation (CSE) provides a powerful and flexible alternative to traditional estimation schemes. CSE provides an estimation solution that accurately computes posterior distributions, retains confidence information, and provides {{a complete set of}} credible solutions...|$|E
40|$|In this paper, we {{extend the}} optimal {{securitization}} model of Pagès [41] and Possamaï and Pagès [42] between an investor and a bank to a setting allowing both moral hazard and adverse selection. Following the recent approach {{to these problems}} of Cvitanić, Wan and Yang [12], we characterize explicitly and rigorously the so-called <b>credible</b> <b>set</b> of the continuation and temptation values of the bank, and obtain the value function of the investor {{as well as the}} optimal contracts through a recursive system of first-order variational inequalities with gradient constraints. We provide a detailed discussion of the properties of the optimal menu of contracts. Comment: 60 page...|$|E
40|$|We {{investigate}} the <b>credible</b> <b>sets</b> and marginal <b>credible</b> intervals {{resulting from the}} horseshoe prior in the sparse multivariate normal means model. We do so in an adaptive setting without assuming knowledge of the sparsity level (number of signals). We consider both the hierarchical Bayes method of putting a prior on the unknown sparsity level and the empirical Bayes method with the sparsity level estimated by maximum marginal likelihood. We show that credible balls and marginal credible intervals have good frequentist coverage and optimal size if the sparsity level of the prior is set correctly. By general theory honest confidence sets cannot adapt in size to an unknown sparsity level. Accordingly the hierarchical and empirical Bayes <b>credible</b> <b>sets</b> based on the horseshoe prior are not honest over the full parameter space. We show that {{this is due to}} over-shrinkage for certain parameters and characterise the set of parameters for which credible balls and marginal credible intervals do give correct uncertainty quantification. In particular we show that the fraction of false discoveries by the marginal Bayesian procedure is controlled by a correct choice of cut-off...|$|R
40|$|To further {{investigate}} susceptibility loci {{identified by}} genome-wide association studies, we genotyped 5, 500 SNPs across 14 associated regions in 8, 000 samples from {{a control group}} and 3 diseases: type 2 diabetes (T 2 D), coronary artery disease (CAD) and Graves' disease. We defined, using Bayes theorem, <b>credible</b> <b>sets</b> of SNPs that were 95 % likely, based on posterior probability, to contain the causal disease-associated SNPs. In 3 of the 14 regions, TCF 7 L 2 (T 2 D), CTLA 4 (Graves' disease) and CDKN 2 A-CDKN 2 B (T 2 D), much of the posterior probability rested on a single SNP, and, in 4 other regions (CDKN 2 A-CDKN 2 B (CAD) and CDKAL 1, FTO and HHEX (T 2 D)), the 95 % sets were small, thereby excluding most SNPs as potentially causal. Very few SNPs in our <b>credible</b> <b>sets</b> had annotated functions, illustrating the limitations in understanding the mechanisms underlying susceptibility to common diseases. Our results also show the value of more detailed mapping to target sequences for functional studies. © 2012 Nature America, Inc. All rights reserved...|$|R
40|$|With {{reference}} to a general class of empirical-type likelihoods, we develop higher-order asymptotics for the frequentist coverage of Bayesian <b>credible</b> <b>sets</b> based on posterior quantiles and highest posterior density. These asymptotics, in turn, characterise {{members of the class}} that allow approximate frequentist validity of such sets. It is seen that the usual empirical likelihood does not enjoy this property up to the order of approximation considered here. Copyright 2006, Oxford University Press. ...|$|R
40|$|This paper {{presents}} a novel Bayesian method {{based on the}} complex Watson shape distribution that is used in detecting shape differences between the second thoracic vertebrae for two groups of mice, small and large, categorized according to their body weight. Considering the data provided in Johnson et al. (1988), we provide Bayesian methods of estimation as well as highest posterior density (HPD) estimates for modal vertebrae shapes within each group. Finally, we present a classification procedure {{that can be used}} in any shape classification experiment, and apply it for categorizing new vertebrae shapes in small or large groups. Average shape difference, complex Watson shape distribution, HPD <b>credible</b> <b>set,</b> modal shape,...|$|E
40|$|Key {{features}} of NZ business cycles were {{established for the}} period 1966 q 4 to 1990 q 1 by Kim, Buckle and Hall (1994) (KBH), but the conduct of fiscal, monetary and labour market policy and the behaviour of New Zealand's economy have changed considerably since then. Our results for the period 1987 q 2 to 2010 q 4 show a reduction in volatility and a rise in persistence for both the real economy and for price and monetary variables. Government sector, open economy, monetary and labour market results differ from those advanced in KBH. Overall, we establish a more <b>credible</b> <b>set</b> of benchmark regularities, to help underpin the construction and use of contemporary NZ macroeconomic models...|$|E
40|$|For {{estimating}} a lower bounded parametric {{function in}} the framework of Marchand and Strawderman (2006), we provide through a unified approach a class of Bayesian confidence intervals with credibility 1 -α and frequentist coverage probability bounded below by 1 -α/ 1 +α. In cases where the underlying pivotal distribution is symmetric, the findings represent extensions with respect to the specification of the <b>credible</b> <b>set</b> achieved through the choice of a spending function, and include Marchand and Strawderman's HPD procedure result. For non-symmetric cases, the determination of a such a class of Bayesian credible sets fills a gap in the literature and includes an "equal-tails" modification of the HPD procedure. Several examples are presented demonstrating wide applicability. Comment: This is an expanded version of an earlier pos...|$|E
40|$|To the frequentist who computes posteriors, not all priors {{are useful}} asymptotically: {{in this paper}} Schwartz's 1965 Kullback-Leibler {{condition}} is generalised to enable frequentist interpretation of convergence of posterior distributions with the complex models and often dependent datasets in present-day statistical applications. We prove four simple and fully general frequentist theorems, for posterior consistency; for posterior rates of convergence; for consistency of the Bayes factor in hypothesis testing or model selection; and a theorem to obtain confidence <b>sets</b> from <b>credible</b> <b>sets.</b> The latter has a significant methodological consequence in frequentist uncertainty quantification: use of a suitable prior allows one to convert <b>credible</b> <b>sets</b> of a calculated, simulated or approximated posterior into asymptotically consistent confidence sets, in full generality. This extends the main inferential implication of the Bernstein-von Mises theorem to non-parametric models without smoothness conditions. Proofs require {{the existence of a}} Bayesian type of test sequence and priors giving rise to local prior predictive distributions that satisfy a weakened form of Le~Cam's contiguity with respect to the data distribution. Results are applied {{in a wide range of}} examples and counterexamples. Comment: journal article: main text 20 pp., appendices 35 pp., 1 figur...|$|R
40|$|We study a Bayesian {{approach}} to recovering the initial {{condition for the}} heat equation from noisy observations of the solution at a later time. We consider a class of prior distributions indexed by a parameter quantifying "smoothness" and show that the corresponding posterior distributions contract around the true parameter {{at a rate that}} depends on the smoothness of the true initial condition and the smoothness and scale of the prior. Correct combinations of these characteristics lead to the optimal minimax rate. One type of priors leads to a rate-adaptive Bayesian procedure. The frequentist coverage of <b>credible</b> <b>sets</b> is shown to depend on the combination of the prior and true parameter as well, with smoother priors leading to zero coverage and rougher priors to (extremely) conservative results. In the latter case <b>credible</b> <b>sets</b> are much larger than frequentist confidence sets, in that the ratio of diameters diverges to infinity. The results are numerically illustrated by a simulated data example. Comment: 17 pages, 4 figures. Published in Comm. Statist. Theory Methods. This version differs from the original in pagination and typographic detail. arXiv admin note: text overlap with arXiv: 1103. 269...|$|R
40|$|Abstract This paper reviews recent {{developments}} in higher-order asymptotics for marginal posterior distributions, and related quantities, for practical use in Bayesian analysis. In this respect, we outline how modern asymptotic theory, which provides accurate inferences {{in a variety of}} parametric statistical problems even for small sample sizes, may routinely be applied in practice. The focus is on default Bayesian inference in the presence of nuisance parameters. Key words: Asymptotic expansions, highest posterior density <b>credible</b> <b>sets,</b> match-ing prior, tail area approximations. ...|$|R
