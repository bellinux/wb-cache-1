170|320|Public
25|$|The {{beating and}} {{roughness}} sensations associated with certain complex signals are therefore usually {{understood in terms}} of sine-component interaction within the same frequency band of the hypothesized auditory filter, called <b>critical</b> <b>band.</b>|$|E
25|$|Although the A-weighting curve, in {{widespread}} use for noise measurement, {{is said to}} have been based on the 40-phon Fletcher-Munson curve, research in the 1960s demonstrated that determinations of equal-loudness made using pure tones are not directly relevant to our perception of noise. This is because the cochlea in our inner ear analyses sounds in terms of spectral content, each 'hair-cell' responding to a narrow band of frequencies known as a <b>critical</b> <b>band.</b> The high-frequency bands are wider in absolute terms than the low frequency bands, and therefore 'collect' proportionately more power from a noise source. However, when more than one <b>critical</b> <b>band</b> is stimulated, the outputs of the various bands are summed by the brain to produce an impression of loudness. For these reasons equal-loudness curves derived using noise bands show an upwards tilt above 1kHz and a downward tilt below 1kHz when compared to the curves derived using pure tones.|$|E
2500|$|Dissonance is more {{generally}} {{defined by the}} amount of beating between partials (called harmonics or overtones when occurring in harmonic timbres) ( [...] , [...] ). , [...] calls this [...] "sensory dissonance". By this definition, dissonance is dependent not only on the width of the interval between two notes' fundamental frequencies, but also on the widths of the intervals between the two notes' non-fundamental partials. Sensory dissonance (i.e., presence of beating and/or roughness in a sound) is associated with the inner ear's inability to fully resolve spectral components with excitation patterns whose critical bands overlap. If two pure sine waves, without harmonics, are played together, people tend to perceive maximum dissonance when the frequencies are within the <b>critical</b> <b>band</b> for those frequencies, which is as wide as a minor third for low frequencies and as narrow as a minor second for high frequencies (relative to the range of human hearing) [...] If harmonic tones with larger intervals are played, the perceived dissonance is due, at least in part, to the presence of intervals between the harmonics of the two notes that fall within the <b>critical</b> <b>band</b> [...]|$|E
50|$|The scale {{ranges from}} 1 to 24 and {{corresponds}} to the first 24 <b>critical</b> <b>bands</b> of hearing.|$|R
3000|$|... is {{the number}} of {{considered}} <b>critical</b> <b>bands.</b> The global BSD for the whole signal is the mean of the local BSDs.|$|R
50|$|Since {{the direct}} {{measurements}} of the <b>critical</b> <b>bands</b> are subject to error, the values in this table have been generously rounded.|$|R
2500|$|Generally, the sonance (i.e., a {{continuum}} with pure consonance {{at one end}} and pure dissonance at the other) of any given interval can be controlled by adjusting the timbre in which it is played, thereby aligning its partials with the current tuning's notes (or vice versa) [...] The sonance of the interval between two notes can be maximized (producing consonance) by maximizing the alignment of the two notes' partials, whereas it can be minimized (producing dissonance) by mis-aligning each otherwise nearly aligned pair of partials by an amount equal to the width of the <b>critical</b> <b>band</b> at the average of the two partials' frequencies ( [...] ; , [...] ).|$|E
2500|$|Coincidence of partials: with consonance being {{a greater}} {{coincidence}} of partials ( [...] , [...] ). By this definition, consonance is dependent {{not only on}} the width of the interval between two notes (i.e., the musical tuning), but also on the combined spectral distribution and thus sound quality (i.e., the timbre) of the notes (see the entry under <b>critical</b> <b>band).</b> Thus, a note and the note one octave higher are highly consonant because the partials of the higher note are also partials of the lower note [...] Although Helmholtz's work focused almost exclusively on harmonic timbres and also the tunings, subsequent work has generalized his findings to embrace non-harmonic tunings and timbres ( [...] ; [...] , , , [...] ).|$|E
50|$|The {{beating and}} {{roughness}} sensations associated with certain complex signals are therefore usually {{understood in terms}} of sine-component interaction within the same frequency band of the hypothesized auditory filter, called <b>critical</b> <b>band.</b>|$|E
50|$|These {{formulas}} are for single-frequency sine waves or narrowband signals. For multi-component or broadband signals, a {{more elaborate}} loudness model is required, accounting for <b>critical</b> <b>bands.</b>|$|R
5000|$|The phon {{model can}} be {{extended}} with a time-varying transient model which accounts for [...] "turn-on" [...] (initial transient) and long-term, listener fatigue effects. This time-varying behavior {{is the result of}} psychological and physiological audio processing. The equal-loudness contours on which the phon is based apply only to the perception of pure steady tones: tests using octave or third-octave bands of noise reveal a different set of curves, owing {{to the way in which}} the <b>critical</b> <b>bands</b> of our hearing integrate power over varying bandwidths and our brain sums the various <b>critical</b> <b>bands</b> ...|$|R
50|$|In {{order to}} {{determine}} the time periods, where the direct sound prevails and which can be used for directional evaluation, the auditory system analyzes loudness changes in different <b>critical</b> <b>bands</b> and also the stability of the perceived direction. If there is a strong attack of the loudness in several <b>critical</b> <b>bands</b> and if the perceived direction is stable, this attack is in all probability caused by the direct sound of a sound source, which is entering newly or which is changing its signal characteristics. This short time period is used by the auditory system for directional and loudness analysis of this sound. When reflections arrive a little bit later, they do not enhance the loudness inside the <b>critical</b> <b>bands</b> in such a strong way, but the directional cues become unstable, because there is a mix of sound of several reflection directions. As a result, no new directional analysis is triggered by the auditory system.|$|R
5000|$|The Chicago math {{rock band}} 90 Day Men wrote and {{recorded}} a song entitled [...] "Hans Lucas" [...] that {{pays homage to}} Godard for their 2000 album (it (is) it) <b>critical</b> <b>band.</b>|$|E
50|$|Sound {{processing}} {{of the human}} auditory system is performed in so-called critical bands. The hearing range is segmented into 24 critical bands, each with a width of 1 Bark or 100 Mel. For a directional analysis the signals inside the <b>critical</b> <b>band</b> are analyzed together.|$|E
50|$|This {{experience}} led to {{the idea}} of engaging in some kind of research and training programme for instrumentalists in microtonal performance, and so in 1990 Wood founded London's first Centre for Microtonal Music, and its ensemble, <b>Critical</b> <b>Band.</b> The purpose of the Microtonal Centre was to research instrumental microtonal playing techniques, to teach these to young musicians whilst at the same time educating composers in the historical, theoretical, emotional and practical implications of microtonality. The initiative involved the collaboration of the Society for the Promotion of New Music (SPNM), the Guildhall School of Music and Drama, and the Barbican Centre in London, which held a Weekend of Microtonal Music, 'In Tune?', in 1990, 1991 and 1992. Aside from its presence at the 'In Tune?' Festivals, the ensemble 'Critical Band' undertook several recordings, concerts and tours, including a CD of three of Wood's own compositions: Venancio Mbande talking with the Trees, Phainomena and Two men meet, each presuming the other to be from a distant planet (NMC-D044). This latter work was also premiered by <b>Critical</b> <b>Band</b> at the 1995 BBC Proms (September 11). But since the late 1990s both the Centre for Microtonal Music and <b>Critical</b> <b>Band</b> became disbanded through lack of funding.|$|E
40|$|It {{has been}} found that second‐order {{harmonic}} smoothing of musical instrument spectral data can {{have a significant effect on}} timbral perception, depending on the instrument tested [McAdams et al., J. Acoust. Soc. Am. 102, 882 – 897 (1999) ]. With critical‐band smoothing, the lower harmonics, since they are in different <b>critical</b> <b>bands,</b> retain their individual amplitudes and temporal envelopes. Thus, it is hypothesized that critical‐band smoothing has a lesser perceptual effect on most instrument tones than harmonic smoothing. On the other hand, upper <b>critical</b> <b>bands</b> consist of groups of harmonics. It is hypothesized that it is difficult to hear out individual harmonics within <b>critical</b> <b>bands.</b> Thus, for each band the independent harmonic temporal envelopes can be replaced by a composite rms‐amplitude envelope. Spectra within bands can be replaced by time‐averaged spectra. Alternatively, time‐dependent amplitude versus Bark‐frequency spectral envelopes can be smoothed for each individual analysis frame. Further, amplitudes can be averaged in dB or linear units. Results for various processing combinations and various musical instrument sounds will be given and demonstrated...|$|R
3000|$|... into Equation (20) renders a {{modified}} matrix M′ with new DWPT coefficients. Once the processes {{in all the}} involved <b>critical</b> <b>bands</b> are completed, the watermarked signal is attained by taking inverse DWPT {{with respect to the}} modified DWPT coefficients.|$|R
3000|$|... (513 for 1024 -point DFT) {{spectral}} bins {{are divided}} into subbands. In this paper, we use 27 subbands to approximate the psychoacoustic <b>critical</b> <b>bands.</b> Table 1 shows the number of spectral bins and the index of the first spectral bins in each subband.|$|R
5000|$|In {{his letter}} [...] "Subdivision of the Audible Frequency Range into Critical Bands", Zwicker states:"These bands have been {{directly}} measured in experiments {{on the threshold}} for complex sounds, on masking, on the perception of phase, and most often on the loudness of complex sounds. In all these phenomena, the <b>critical</b> <b>band</b> seems {{to play an important}} role. It must be pointed out that the measurements taken so far indicate that the critical bands have a certain width, but that their position on the frequency scale is not fixed; rather, the position can be changed continuously, perhaps by the ear itself."Thus the important attribute of the Bark scale is the width of the <b>critical</b> <b>band</b> at any given frequency, not the exact values of the edges or centers of any band.|$|E
50|$|Although the A-weighting curve, in {{widespread}} use for noise measurement, {{is said to}} have been based on the 40-phon Fletcher-Munson curve, research in the 1960s demonstrated that determinations of equal-loudness made using pure tones are not directly relevant to our perception of noise. This is because the cochlea in our inner ear analyses sounds in terms of spectral content, each 'hair-cell' responding to a narrow band of frequencies known as a <b>critical</b> <b>band.</b> The high-frequency bands are wider in absolute terms than the low frequency bands, and therefore 'collect' proportionately more power from a noise source. However, when more than one <b>critical</b> <b>band</b> is stimulated, the outputs of the various bands are summed by the brain to produce an impression of loudness. For these reasons equal-loudness curves derived using noise bands show an upwards tilt above 1 kHz and a downward tilt below 1 kHz when compared to the curves derived using pure tones.|$|E
50|$|Musically, {{the album}} {{presents}} Hipodil as a mature though still restless and highly <b>critical</b> <b>band</b> with strong connections to punk, ska and heavy metal. The band demonstrated significant growth in both musical and lyrical direction {{and even though}} some hardcore fans criticized the album for being a bit far from the raw sound of the bands early recordings, Nadurveni vuglishta was obviously of higher production and historical value.|$|E
50|$|The {{coefficients}} {{are grouped}} {{to resemble the}} <b>critical</b> <b>bands</b> of the human auditory system. The entire amount of energy of each group is analysed and the values quantised for data reduction and compressed through prediction by only transmitting the difference to the predicted values (delta encoding).|$|R
50|$|In 1961, Professor Donald D. Greenwood {{utilized}} {{experimental methods}} {{within the field}} of psychoacoustics to measure the frequency resolution between <b>critical</b> <b>bands</b> within the human cochlea and develop a function correlating the anatomic location of the inner ear hair cells and the frequencies at which they are stimulated (Greenwood 1961a,b).|$|R
40|$|Abstract: In this paper, {{we propose}} a novel wavelet {{coefficient}} threshold (WCT) depended on both time and frequency information for providing robustness to non-stationary and correlated noisy environments. A perceptual wavelet filter-bank (PWFB) is firstly used to decompose the noisy speech signal into <b>critical</b> <b>bands</b> according to <b>critical</b> <b>bands</b> of psycho-acoustic model of human auditory system. The estimation of wavelet coefficient threshold (WCT) is then adjusted with the posterior SNR, which {{is determined by}} estimated noise power, through the well-known “Quantum Neural Networks (QNN) ”. In order to suppress the appearance of musical residual noise produced by thresholding process, we consider masking properties of human auditory system to reduce the effect of musical residual noise. Simulation {{results showed that the}} proposed system is capable of reducing noise with little speech degradation and the overall performance is superior to several competitive methods. Key-Words: Speech enhancement; perceptual wavelet packet transformation; adaptive wavelet coefficient threshold; musical residual noise. ...|$|R
5000|$|In {{audiology}} and psychoacoustics {{the concept}} of critical bands, introduced by Harvey Fletcher in 1933 and refined in 1940, describes the frequency bandwidth of the [...] "auditory filter" [...] created by the cochlea, the sense organ of hearing within the inner ear. Roughly, the <b>critical</b> <b>band</b> is the band of audio frequencies within which a second tone will interfere with {{the perception of the}} first tone by auditory masking.|$|E
5000|$|Dissonance is more {{generally}} {{defined by the}} amount of beating between partials (called harmonics or overtones when occurring in harmonic timbres) ( [...] , [...] ). , [...] calls this [...] "sensory dissonance". By this definition, dissonance is dependent not only on the width of the interval between two notes' fundamental frequencies, but also on the widths of the intervals between the two notes' non-fundamental partials. Sensory dissonance (i.e., presence of beating and/or roughness in a sound) is associated with the inner ear's inability to fully resolve spectral components with excitation patterns whose critical bands overlap. If two pure sine waves, without harmonics, are played together, people tend to perceive maximum dissonance when the frequencies are within the <b>critical</b> <b>band</b> for those frequencies, which is as wide as a minor third for low frequencies and as narrow as a minor second for high frequencies (relative to the range of human hearing) [...] If harmonic tones with larger intervals are played, the perceived dissonance is due, at least in part, to the presence of intervals between the harmonics of the two notes that fall within the <b>critical</b> <b>band</b> [...]|$|E
5000|$|... #Caption: One {{component}} of dissonance - the uncertainty or confusion {{as to the}} virtual pitch evoked by an interval or chord, or the difficulty of fitting its pitches to a harmonic series (as discussed by Goldstein and Terhardt, see main text) - is modelled by harmonic entropy theory. Dips in this graph show consonant intervals such as 4:5 and 2:3. Other components not modeled by this theory include <b>critical</b> <b>band</b> roughness, and tonal context (e.g., an augmented second is more dissonant than a minor third although in equal temperament the interval, 300 cents, {{is the same for}} both).|$|E
40|$|Thresholds for {{a change}} in the {{spectral}} slope of noise bands were measured {{as a function of the}} bandwidth. A roving intensity level was introduced to prevent subjects from using loudness cues. Results show that subjects are able to discriminate sounds on the basis of the change in spectral shape, which indicates that they can compare relative energy changes in the different <b>critical</b> <b>bands</b> simultaneously (profile analysis). Detection of changes in the spectral slope is dependent on the bandwidth and reaches a minimum value near 3 - 6 semitones (ST). For bandwidths smaller than 1 ST, results can be explained in terms of a model that states that spectral changes are perceived as changes in pitch. For greater bandwidths the auditory system is not able to compare the output of all <b>critical</b> <b>bands</b> together, as in a filter-bank model, but rather focusses on only two or perhaps a few more critical-band regions...|$|R
40|$|Mashinter’s (2006) {{mathematical}} model of sensory dissonance neglects {{the dependence of}} roughness on waveform, the role of masking, the distribution of roughness across <b>critical</b> <b>bands,</b> the possible positive contribution of fusion or toneness to euphony, and the familiarity and music-theoretical functions of a sonority. Of course not all these aspects can reasonably {{be included in a}} model, but they can affect the data with which its predictions are compared...|$|R
30|$|TEO {{analysis}} {{takes place}} on the sixteen <b>critical</b> <b>bands.</b> Gabor band pass filters are used {{to focus on a}} particular spectral band while each one's TEO profile is windowized into frames of 200 milliseconds with 75 % overlap. Subsequently the autocorrelation envelope area is computed and then normalized by half the frame length. The output feature vector has sixteen coefficients like the number of the <b>critical</b> <b>bands.</b> The audio analysis which relies on Teager energy operator can reveal aspects of verbal or non-verbal human reactions which are not captured by MFCC and are related to stress expression. It has been reported to be indicative of the alterations that the airflow pattern exhibits regarding the speech production under atypical circumstances. They are appended to pitch, pitch derivative and HNR (based on a forward cross-correlation analysis) which depict the variation of intonation regarding typical and atypical speech. Together with the already computed MFCC they form a vector for discriminating between normal and screamed speech audio events. For their calculation we used PRAAT software [13] which is optimized for speech signals.|$|R
5000|$|Generally, the sonance (i.e., a {{continuum}} with pure consonance {{at one end}} and pure dissonance at the other) of any given interval can be controlled by adjusting the timbre in which it is played, thereby aligning its partials with the current tuning's notes (or vice versa) [...] The sonance of the interval between two notes can be maximized (producing consonance) by maximizing the alignment of the two notes' partials, whereas it can be minimized (producing dissonance) by mis-aligning each otherwise nearly aligned pair of partials by an amount equal to the width of the <b>critical</b> <b>band</b> at the average of the two partials' frequencies ( [...] ; , [...] ).|$|E
5000|$|The {{majority}} of Tenney's mature works (post-1964) are instrumental pieces, often for unconventional instrumental combinations (e.g. Glissade for viola, cello, double bass and tape delay system (1982), Bridge for two pianos eight {{hands in a}} microtonal tuning system (1982-84), Changes for six harps tuned a sixth of a semitone apart, 1985) or for variable instrumentation (<b>Critical</b> <b>Band,</b> 1988, In a Large Open Space, 1994). His pieces are most often tributes to other composers or colleagues and subtitled as such. As his friend Philip Corner says, For Ann (rising), [...] "must be optimistic! (Imagine the depressing effectiveness of it — he could never be so cruel — downward)..." ...|$|E
5000|$|Robert Lowe {{joined the}} group in 1997 on trumpet and vocals but later moved to bass guitar when McWilliams departed. Their first {{recording}} with this line-up was the 7" [...] single, [...] "If You Can Bake a Cake, You Can Build a Bomb", in 1997, followed by an EP on Temporary Residence in 1998. In late 1998, they signed with Southern Records, who released their first full-length album, entitled (It (Is) It) <b>Critical</b> <b>Band,</b> in 2000. By this time, the keyboard player Andy Lansangan had {{joined the group}}. Two further LPs followed, To Everybody in 2002 and Panda Park in 2004, which {{was the subject of}} significant critical acclaim.|$|E
40|$|The use of {{magnitude}} estimation {{as well as}} axiomatic measurement theory {{has led to the}} sug-gestion that loudness adds across <b>critical</b> <b>bands.</b> In the present paper, we challenge this postu-late by applying a more sensitive methodology, based onFalmagne’s (1976) random conjoint mea-surement procedure. A necessary condition for additivity of loudness was investigated in tone complexes consisting of 2 -kHz and 5 -kHz (resp. 3 -kHz) components; the results showed system-atic deviations from additivity. We argue that these deviations are due to asymmetric masking of the higher component by the lower one, and we propose a tentative quantitative model to ac-count for the data. Such a model is in line with results from tone-on-tone masking, which show masking to be effective over a range of several <b>critical</b> <b>bands.</b> A problem central to models of loudness and noise evaluation is to determine how different frequency com-ponents combine to produce what is perceived as the over-all loudness of a sound. In the most elementary situation conceivable, that of a two-tone complex, classical inves...|$|R
40|$|In this paper, {{we present}} a new design of a psychoacoustic model {{following}} the example model used in audio standard MPEG- 1 layer 3 with the gammachirp wavelet packet decomposition. The essential characteristic of this model is that it proposes an analysis by wavelet packet transformation on the frequency bands that come closer the <b>critical</b> <b>bands</b> of the ear that differs from the existing model based on an analysis by a short-term Fourier transformation. 1...|$|R
40|$|In this paper, {{an audio}} coder using the {{discrete}} wavelet transform (DWT) and a warped linear prediction (WP) model, is proposed. In contrast to conventional LP, WLP {{allows for the}} control of frequency resolution closely match {{the response of the}} human auditory system. The residual from the inverse WLP filtering is analyzed by a wavelet filterband designed to approximate the <b>critical</b> <b>bands.</b> For monophonic signals sampled at 44. 1 KHz, the coder achieves near transparent quality at an average bit-rate of 64 Kb/s...|$|R
