6|618|Public
30|$|With the {{projection}} matrix P {{it is possible}} to backproject any 2 D point to a 3 D projection ray. If this is done on both cameras, the intersection of the <b>corresponding</b> <b>projection</b> <b>rays</b> will represent the reconstructed 3 D position.|$|E
40|$|International audienceIn {{this paper}} {{we deal with}} general camera models that allow to {{describe}} any kind of camera as a mapping between each pixel and the <b>corresponding</b> <b>projection</b> <b>rays.</b> This work is inspired by [19] and proposes {{a study of the}} multi-view geometry of such cameras and a new formulation of multi-view matching tensors working for projection rays crossing the same 3 D line. We also delineate a method to estimate such tensors and recover the motion between the views...|$|E
40|$|Abstract. A novel method which entirely resides inside {{conformal}} geometric algebra (CGA) {{is presented}} estimating the pose {{of a camera}} from one image of a known object. At first, subproblems covering only three feature points are solved and globally assessed. The object model is accordingly pruned and rigidly fitted to <b>corresponding</b> <b>projection</b> <b>rays</b> by evaluating a succinct CGA expression which emerged from a purely geometric approach. It results a set of 3 -point poses each given by a motor. These spinor elements of CGA embody rigid body motions from the manifold SE(3). The poses are then to be averaged according to their quality. This is the second aspect of this work as the respective motors do not come from a linear space and averaging {{must be carried out}} appropriately. For this purpose, a technique called weighted intrinsic mean is used...|$|E
40|$|International audienceWe {{consider}} the self-calibration {{problem for a}} generic imaging model that assigns <b>projection</b> <b>rays</b> to pixels without a parametric mapping. We {{consider the}} central variant of this model, which encompasses all camera models with a single effective viewpoint. Self-calibration refers to calibrating a camera's <b>projection</b> <b>rays,</b> purely from matches between images, i. e. without knowledge about the scene such as using a calibration grid. In order to do this we consider specific camera motions, concretely, pure translations and rotations, although without the knowledge of rotation and translation parameters (rotation angles, axis of rotation, translation vector). Knowledge {{of the type of}} motion, together with image matches, gives geometric constraints on the <b>projection</b> <b>rays.</b> We show for example that with translational motions alone, self-calibration can already be performed, but only up to an affine transformation of the set of <b>projection</b> <b>rays.</b> We then propose algorithms for full metric self-calibration, that use rotational and translational motions or just rotational motions...|$|R
40|$|Practically all image {{rendering}} methods today use {{the perspective}} projection, {{or try to}} approximate it. We develop a new image-based rendering approach {{which is based on}} a new projection model [...] the Crossed-Slits X-Slits projection. The model is obtained by relaxing the requirement that all <b>projection</b> <b>rays</b> intersect at a single point (the focal-point). Instead, <b>projection</b> <b>rays</b> are required by definition to intersect two curves in space...|$|R
40|$|This article {{deals with}} {{a new way of}} portraying a three- {{dimensional}} object on a two-dimensional plane surface. In classical perspective each point of an object or scene is projected upon a plane by means of a bundle of straight <b>projection</b> <b>rays</b> departing from a unique point or point of view. The author proposes a similar procedure except that the straight <b>projection</b> <b>rays</b> of classical perspective are replaced with special curved one...|$|R
40|$|International audienceGeneral camera models {{relax the}} {{constraint}} on central projection and characterize cameras as mappings between each pixel and the <b>corresponding</b> <b>projection</b> <b>rays.</b> This allows to describe most cameras types, including classical pinhole cameras, cameras with various optical distortions, catadioptric cameras and other acquisition devices. We {{deal with the}} structure from motion problem for such general models. We first consider an hierarchy of general cameras first introduced in [28] where the cameras are described according {{to the number of}} points and lines that have a non-empty intersection with all the projection rays. Then we propose a study of the multi-view geometry of such cameras and a new formulation of multi-view matching tensors working for projection rays crossing the same 3 D line, the counterpart of the fundamental matrices and the multifocal tensors of the standard perspective cameras. We also delineate a method to estimate such tensors and recover the motion between the views...|$|E
50|$|Orthographic {{projection}} {{is derived}} from the principles of descriptive geometry, and is a type of parallel projection where the <b>projection</b> <b>rays</b> are perpendicular to the projection plane. It is the projection type of choice for working drawings.|$|R
40|$|Abstract — A new {{efficient}} {{method of}} calibration for catadioptric sensors {{is presented in}} this paper. It {{is based on an}} accurate reconstruction of the mirror by means of polarization imaging and it permits to relax most of the constraints related to the calibration of the catadioptric systems. No image processing and no calibration pattern are required so that the calibration can be performed in “one click”. As a result, the coordinates of the <b>projection</b> <b>rays</b> and a mapping between <b>projection</b> <b>rays</b> and image pixels is obtained. Besides, two methods of triangulation have been adapted to catadioptric sensors and tested. Experiments prove the validity of the method with some preliminary results on 3 D reconstruction. I...|$|R
3000|$|... p^k_p,m is the <b>corresponding</b> <b>projection</b> of p^k {{onto the}} {{hyperplane}} {{defined by the}} mth row g_m^T of matrix G, m= 1,...,M.|$|R
50|$|Starting with a 2D image, image {{points are}} {{extracted}} which correspond to corners in an image. The <b>projection</b> <b>rays</b> from the image points are reconstructed from the 2D points {{so that the}} 3D points, which must be incident with the reconstructed rays, can be determined.|$|R
2500|$|The <b>corresponding</b> <b>projection</b> to the {{canonical}} decomposition [...] in which [...] is an isotype of [...] is for compact groups given by ...|$|R
40|$|Focusing on {{the serious}} {{occlusion}} problem in city images, this paper makes {{full use of}} the advantage of multi-view image matching, and proposes a reliable multi-view image matching method based on the moving Z-Plane constraint. It supposes a fictitious plane in the object space, and the plane is divided to regular grid cell (small plane element) by a certain interval (≥ image resolution). By moving the plane to different elevation positions, this algorithm makes feature point <b>projection</b> <b>ray</b> in overall images intersect with the plane, and constrains the candidate points by grid cells in the plane. Feature points which come from different images <b>projection</b> <b>ray</b> in the same grid cell on the plane may {{be regarded as the}} matching candidates. It selects the images which matching candidate points by gray similarity constraint to avoid the effect from occlusion image. According to the number of <b>projection</b> <b>ray</b> in the grid cell, this algorithm adopts hierarchy matching strategy of "the best candidate will be matched in the first instant", and uses initial matching results as constraint condition in the latter matching process. Finally, the validity of the algorithm proposed in this paper is verified by the experiments using four UltraCamX (UCX) digital aerial images and the algorithm is shown to have reliable matching results...|$|R
40|$|In this paper, {{we study}} the {{performance}} of an iterative algorithm for pinhole SPECT, in which the correction for pinhole blurring is realized by averaging multiple <b>projection</b> <b>rays.</b> In addition, we compare the effects of regularization obtained by using blob basis functions and voxels with and without post-smoothing...|$|R
3000|$|... [...]) (being 1 or 0) {{constitute}} a connected relationship matrix of size [...] N×C_ 2 ^N- 1 for N feature points to their <b>corresponding</b> <b>projection</b> points f [...]...|$|R
40|$|A generic {{imaging model}} {{refers to a}} {{non-parametric}} camera model where every camera is treated {{as a set of}} unconstrained <b>projection</b> <b>rays.</b> Calibration would simply be a method to map the <b>projection</b> <b>rays</b> to image pixels; such a mapping can be computed using plane based calibration grids. However, existing algorithms for generic calibration use more point correspondences than the theoretical minimum. It has been well-established that non-minimal solutions for calibration and structure-from-motion algorithms are generally noise-prone compared to minimal solutions. In this work we derive minimal solutions for generic calibration algorithms. Our algorithms for generally central cameras use 4 point correspondences in three calibration grids to compute the motion between the grids. Using simulations we show that our minimal solutions are more robust to noise compared to non-minimal solutions. We also show very accurate distortion correction results on fisheye images. 1...|$|R
50|$|The terms orthographic {{projection}} and orthogonal projection are sometimes reserved specifically for multiviews. However, orthographic and orthogonal more correctly {{refer to the}} right angle formed between the <b>projection</b> <b>rays</b> and the <b>projection</b> plane, versus the angle formed between {{the subject of the}} drawing and the projection plane. Thus, {{orthographic projection}}s include axonometric or auxiliary views in addition to multiviews.|$|R
40|$|International audienceWe {{consider}} calibration {{and structure}} from motion tasks for a previously introduced, highly general imaging model, where cameras are modeled as possibly unconstrained sets of <b>projection</b> <b>rays.</b> This allows to describe most existing camera types (at least for those {{operating in the}} visible domain), including pinhole cameras, sensors with radial or more general distortions, catadioptric cameras (central or non-central), etc. Generic algorithms for calibration and structure from motion tasks (pose and motion estimation and 3 D point triangulation) are outlined. The foundation for a multi-view geometry of non-central cameras is given, leading to the formulation of multi-view matching tensors, analogous to the fundamental matrices, trifocal and quadrifocal tensors of perspective cameras. Besides this, we also introduce a natural hierarchy of camera models: the most general model has unconstrained <b>projection</b> <b>rays</b> whereas the most constrained model dealt with here is the central model, where all rays pass through a single point...|$|R
5000|$|The <b>corresponding</b> <b>projection</b> to the {{canonical}} decomposition [...] in which [...] is an isotype of [...] is for compact groups given bywhere [...] and [...] is the character {{corresponding to the}} irreducible representation ...|$|R
3000|$|... {{for each}} {{dictionary}} atom {{in the training}} process and anchors each patch to its most similar dictionary atom and maps it to output the high-frequency detail patch with the <b>corresponding</b> <b>projection</b> matrix P [...]...|$|R
40|$|International audienceWe {{consider}} the structure-from-motion {{problem for a}} highly general imaging model where cameras are modeled as possibly unconstrained sets of <b>projection</b> <b>rays.</b> This allows to describe most existing camera types, including pinhole cameras, sensors with radial or more general distortions, catadioptric cameras (central or non-central), etc. We introduce a hierarchy of general camera models: the most general model has unconstrained <b>projection</b> <b>rays</b> whereas the most constrained model dealt with here is the central model, where all rays pass through a single point. Intermediate models are what we call axial cameras (all rays touch a single line), and x-slit cameras (rays touch two lines). The foundations for a multi-view geometry of completely non-central cameras are given, leading to the formulation of multi-view matching tensors, analogous to the fundamental/essential matrices, trifocal and quadrifocal tensors of perspective cameras. This framework is then specialized explicitly for the two-view case, for the intermediate camera types mentioned above...|$|R
40|$|In {{this paper}} {{we present a}} {{framework}} to formalize several dierent scenarios for pose estimation in a unifying natural algebraic embedding {{by the use of}} conformal geometric algebra. The main contribution of the paper is the theoretical analysis and embedding of dierent pose estimation scenarios. It can be seen that the conformal geometric algebra is more suited to describing the pose estimation scenario, than either the motor algebra or dual quaternion algebra [10]. The dierent scenarios described below relate <b>projection</b> <b>rays</b> to 3 D points, projection planes to 3 D points or lines, and <b>projection</b> <b>rays</b> to spheres and circles. The constraints are mostly very compact and easy to implement. 1 Contents Contents 1 Introduction 3 2 The scenario of pose estimation 3 3 Pose estimation in the motor algebra 4 4 Pose estimation in conformal geometric algebra 7 4. 1 Introduction to conformal geometric algebra................ 7 4. 2 Formalization of the constraints in conformal geo [...] ...|$|R
40|$|We {{consider}} the structure from motion {{problem for a}} previously introduced, highly general imaging model, where cameras are modeled as possibly unconstrained sets of <b>projection</b> <b>rays.</b> This allows to describe most existing camera types, including pinhole cameras, sensors with radial or more general distortions, catadioptric cameras (central or non-central), etc. We introduce a hierarchy of general camera models: the most general model has unconstrained <b>projection</b> <b>rays</b> whereas the most constrained model dealt with here is the central model, where all rays pass through a single point. Intermediate models are what we call axial cameras (all rays touch a single line), and x-slit cameras (rays touch two lines). The foundations for a multi-view geometry of completely non-central cameras are given, leading to the formulation of multi-view matching tensors, analogous to the fundamental/essential matrices, trifocal and quadrifocal tensors of perspective cameras. This framework is then specialized explicitly for the two-view case, for the intermediate camera types mentioned above. 1...|$|R
40|$|International audienceWe {{introduce}} a generic structure-from-motion approach {{based on a}} previously introduced, highly general imaging model, where cameras are modeled as possibly unconstrained sets of <b>projection</b> <b>rays.</b> This allows to describe most existing camera types (at least for those operating in the visible domain), including pinhole cameras, sensors with radial or more general distortions, catadioptric cameras (central or non-central), etc. We {{introduce a}} structure-from-motion approach for this general imaging model, that allows to reconstruct scenes from calibrated images, possibly taken by cameras of different types (cross-camera scenarios). Structure-from-motion is naturally handled via camera independent ray intersection problems, solved via linear or simple polynomial equations. We also propose two approaches for obtaining optimal solutions using bundle adjustment, where camera motion, calibration and 3 D point coordinates are refined simultaneously. One is relatively straightforward, minimizing distances between 3 D points and <b>projection</b> <b>rays.</b> The other minimizes reprojection error; the general imaging model does not provide analytical expressions for the reprojection error and its derivatives, which are desirable for efficient optimization. To achieve this, we propose to approximate the set of <b>projection</b> <b>rays</b> of a general non-central camera by several clusters of central rays, allowing us to formulate an analytical cost function. % that can be minimized using non-linear iteration. We present results for two cross-camera scenarios [...] a pinhole used together with an omnidirectional camera and a stereo system used with an omnidirectional camera. Using ground-truth and 3 D reconstruction results from classical techniques, we show that our generic algorithm is simple, general and accurate for extensions to various cross-camera and multi-camera scenarios...|$|R
40|$|We {{present a}} camera-projection system for single/multiparty tele-presence which {{inherently}} allows for correct eye gaze, and unlike standard videophony, provides {{a great deal}} of spatial context. The unique feature of our system is a combination of omnidirectional video capture and display from <b>corresponding</b> <b>projection</b> centers. 1...|$|R
50|$|A {{straightforward}} calculation {{shows that}} W = Ran P, {{the range of}} P, is invariant under T if and only of PTP = TP. In other words, a subspace W being an element of Lat(T) {{is equivalent to the}} <b>corresponding</b> <b>projection</b> satisfying the relation PTP = TP.|$|R
3000|$|... {{angles of}} the <b>projections</b> of <b>rays</b> onto the xz plane with the optical axis at the {{input and output}} planes [...]...|$|R
5000|$|... #Caption: In practice, {{the image}} points y1 and y2 cannot be {{measured}} with arbitrary accuracy. Instead points y1 and y2 are detected {{and used for}} the triangulation. The <b>corresponding</b> <b>projection</b> lines (blue) do not, in general, intersect in 3D space and may also not intersect with point x.|$|R
40|$|We {{propose a}} method to compute the {{direction}} of heading from the di erential changes in the angles between the <b>projection</b> <b>rays</b> of pairs of point features. These angles, the image deformations, do not depend on viewer rotation, so the key problem of separating the e ects of rotation from those of translation is solved at the input. Experiments show both the feasibility of the method onreal images and the advantages of using deformations rather than optical ow. ...|$|R
5000|$|Each {{of the two}} image points [...] and [...] has a <b>corresponding</b> <b>projection</b> line (blue in {{the right}} image above), here denoted as [...] and , which can be {{determined}} given the camera matrices [...] Let [...] be a distance function between a (3D line) L1 and a x (3D point) such that ...|$|R
40|$|AbstractWe study {{anisotropic}} mixed norm {{spaces of}} n-harmonic {{functions in the}} unit polydisc of Cn. Bergman type reproducing integral formulas are established by means of fractional derivatives and some continuous inclusions. It gives us a tool to construct <b>corresponding</b> <b>projections</b> and related operators and prove their boundedness on the mixed norm and Besov spaces...|$|R
40|$|We {{construct}} noncommutative principal fibrations over a 4 -sphere {{which are}} deformations {{of the classical}} SU(2) Hopf fibration. We realize the noncommutative vector bundles associated to the irreducible representations of SU(2) as modules of coequivariant maps and construct <b>corresponding</b> <b>projections.</b> The index of Dirac operators with coefficients in the associated bundles is computed with the Connes-Moscovici local index formula...|$|R
25|$|Besides {{providing}} a uniform description of circles, ellipses, parabolas, and hyperbolas, conic sections {{can also be}} understood as a natural model of the geometry of perspective in the case where the scene being viewed consists of circles, or more generally an ellipse. The viewer is typically a camera or the human eye and the image of the scene a central projection onto an image plane, i.e., all <b>projection</b> <b>rays</b> pass a fixed point O, the center. The lens plane is a plane parallel to the image plane at the lens O.|$|R
40|$|In {{this paper}} we {{formulate}} the point-line registration problem, which generalizes absolute orientation to pointline matching, {{in terms of}} an instance of the orthogonal Procrustes problem, and derive its solution. The same formulation solves the Non-Perspective-n-Point camera pose problem, which in turn generalizes exterior orientation to non-central cameras, i. e., generalized cameras where <b>projection</b> <b>rays</b> do not meet in a single point. Our Procrustean solution is very simple and compact, and copes also with scaling. Experiments with simulated data demonstrate that our method compares favourably with the state-of-the-art in terms of accuracy...|$|R
50|$|To render each such picture, a ray {{of sight}} (also called a <b>projection</b> line, <b>projection</b> <b>ray</b> or line of sight) towards the object is chosen, which determines on the object various points of {{interest}} (for instance, the points that are visible {{when looking at the}} object along the ray of sight); those points of interest are mapped by an orthographic projection to points on some geometric plane (called a projection plane or image plane) that is perpendicular to the ray of sight, thereby creating a 2D representation of the 3D object.|$|R
40|$|This paper {{presents}} an optimal estimate for the projection matrix for points {{of a camera}} from an arbitrary mixture of six or more observed points and straight lines in object space. It gives expressions for determining the <b>corresponding</b> <b>projection</b> matrix for straight lines together with its covariance matrix. Examples on synthetic and real images demonstrate the feasibility of the approach...|$|R
