10000|6102|Public
25|$|Least-angle {{regression}} is an estimation {{procedure for}} linear regression models {{that was developed}} to handle high-dimensional covariate vectors, potentially with more <b>covariates</b> than observations.|$|E
25|$|Hierarchical {{linear models}} (or {{multilevel}} regression) organizes the data into {{a hierarchy of}} regressions, for example where A is regressed on B, and B is regressed on C. It is often used where the variables of interest have a natural hierarchical structure such as in educational statistics, where students are nested in classrooms, classrooms are nested in schools, and schools are nested in some administrative grouping, such as a school district. The response variable might be a measure of student achievement such as a test score, and different <b>covariates</b> would be collected at the classroom, school, and school district levels.|$|E
25|$|It is {{possible}} that the unique effect can be nearly zero even when the marginal effect is large. This may imply that some other covariate captures all the information in x'j, so that once that variable is in the model, there is no contribution of x'j to the variation in y. Conversely, the unique effect of x'j can be large while its marginal effect is nearly zero. This would happen if the other <b>covariates</b> explained {{a great deal of the}} variation of y, but they mainly explain variation in a way that is complementary to what is captured by x'j. In this case, including the other variables in the model reduces the part of the variability of y that is unrelated to x'j, thereby strengthening the apparent relationship with x'j.|$|E
40|$|A new {{approach}} for constructing tests for association between a random right censored life time variable and a <b>covariate</b> is proposed. The basic {{idea is to}} first arrange the observations in increasing order of the <b>covariate</b> and then base the test on a certain point process defined by the observation times. Tests constructed by this approach are robust against outliers in the <b>covariate</b> values or misspecification of the <b>covariate</b> scale since they only use the ordering of the <b>covariate.</b> Of particular interest is a test based on the Anderson-Darling statistic. This test has good power properties both against monotonic and nonmonotonic dependencies between the <b>covariate</b> and the life time variable...|$|R
40|$|We {{consider}} the conditional randomization test {{as a way}} to account for <b>covariate</b> imbalance in randomized experiments. The test accounts for <b>covariate</b> imbalance by comparing the observed test statistic to the null distribution of the test statistic conditional on the observed <b>covariate</b> imbalance. We prove that the conditional randomization test has the correct significance level and introduce original notation to describe <b>covariate</b> balance more formally. Through simulation, we verify that conditional randomization tests behave like more traditional forms of <b>covariate</b> adjustmet but have the added benefit of having the correct conditional significance level. Finally, we apply the approach to a randomized product marketing experiment where <b>covariate</b> information was collected after randomization...|$|R
40|$|In a {{randomized}} controlled trial, a decision {{needs to be}} made about the total number of subjects for adequate statistical power. One way to increase the power of a trial is by including a predictive <b>covariate</b> in the model. In this article, the effects of various <b>covariate</b> adjustment strategies on increasing the power is studied for discrete-time survival endpoints; the circumstances are examined under which the <b>covariate</b> adjustment results in a sufficient increase in power. Using a predictive <b>covariate</b> may increase the costs for each subject, so it is useful to quantify when using a <b>covariate</b> is a cost-efficient strategy. The results reveal that using a <b>covariate</b> is highly recommended if the costs for measuring the <b>covariate</b> are relatively small and the correlation with the outcome sufficiently high...|$|R
2500|$|Minimize {{allocation}} bias (or confounding). [...] This {{may occur}} when <b>covariates</b> {{that affect the}} outcome are not equally distributed between treatment groups, and the treatment effect is confounded with {{the effect of the}} <b>covariates</b> (i.e., an [...] "accidental bias"). [...] If the randomization procedure causes an imbalance in <b>covariates</b> related to the outcome across groups, estimates of effect may be biased if not adjusted for the <b>covariates</b> (which may be unmeasured and therefore impossible to adjust for).|$|E
2500|$|The log-logistic {{distribution}} {{can be used}} as the basis of an accelerated failure time model by allowing [...] to differ between groups, or more generally by introducing <b>covariates</b> that affect [...] but not [...] by modelling [...] as a linear function of the <b>covariates.</b>|$|E
2500|$|... {{are called}} regressors, {{exogenous}} variables, explanatory variables, <b>covariates,</b> input variables, predictor variables, or independent variables (see dependent and independent variables, {{but not to}} be confused with independent random variables). The matrix [...] is sometimes called the design matrix.|$|E
40|$|Three (3) {{different}} methods (logistic regression, <b>covariate</b> shift and k-NN) {{were applied to}} five (5) internal datasets and one (1) external, publically available dataset where <b>covariate</b> shift existed. In all cases, k-NN’s performance was inferior to either logistic regression or <b>covariate</b> shift. Surprisingly, there was no obvious advantage for using <b>covariate</b> shift to reweight the training data in the examined datasets...|$|R
40|$|Confounding {{of three}} binary-variables {{counterfactual}} model {{is discussed in}} this paper. According to the effect between the control variable and the <b>covariate</b> variable, we investigate three counterfactual models: the control variable is independent of the <b>covariate</b> variable, the control variable has {{the effect on the}} <b>covariate</b> variable and the <b>covariate</b> variable affects the control variable. Using the ancillary information based on conditional independence hypotheses, the sufficient conditions to determine whether the <b>covariate</b> variable is an irrelevant factor or a confounder in each counterfactual model are obtained...|$|R
40|$|In a {{regression}} analysis, suppose {{we suspect that}} there are several heterogeneous groups in the population that a sample represents. Mixture regression models have been applied to address such problems. By modeling the conditional distribution of the response given the <b>covariate</b> as a mixture, the sample can be clustered into groups and the individual regression models for the groups can be estimated simultaneously. This approach treats the <b>covariate</b> as deterministic so that the <b>covariate</b> carries no infor-mation as to which group the subject is likely to belong to. Although this assumption may be reasonable in experiments where the <b>covariate</b> is completely determined by the experimenter, in observational data the <b>covariate</b> may behave differently across the groups. Thus the model should also incorporate the heterogeneity of the <b>covariate,</b> which allows us to estimate {{the membership of the}} subject from the <b>covariate.</b> In this paper, we consider a mixture regression model where the joint distribution of the response and the <b>covariate</b> is modeled as a mixture. Given a new observation of the <b>covariate,</b> this approach allows us to compute the posterior probabilities that the subject belongs to each group. Using these posterior probabilities, the prediction of the response can adaptively use the <b>covariate.</b> We introduce an inference procedure 1 a...|$|R
2500|$|A fitted linear {{regression}} {{model can be}} used to identify the relationship between a single predictor variable x'j and the response variable y when all the other predictor variables in the model are [...] "held fixed". Specifically, the interpretation of β'j is the expected change in y for a one-unit change in x'j when the other <b>covariates</b> are held fixed—that is, the expected value of the partial derivative of y with respect to x'j. This is sometimes called the unique effect of x'j on y. In contrast, the marginal effect of x'j on y can be assessed using a correlation coefficient or simple {{linear regression}} model relating only x'j to y; this effect is the total derivative of y with respect to x'j.|$|E
2500|$|They gave a {{multiple}} correlation (R) of [...]81 with the MSCEIT (perfect prediction would be 1). This {{result has been}} replicated by Fiori and Antonakis (2011),; they found {{a multiple}} R of [...]76 using Cattell’s [...] "Culture Fair" [...] intelligence test and the Big Five Inventory (BFI); significant <b>covariates</b> were intelligence (standardized beta = [...]39), agreeableness (standardized beta = [...]54), and openness (standardized beta = [...]46). Antonakis and Dietz (2011a), who investigated the Ability Emotional Intelligence Measure found similar results (Multiple R = [...]69), with significant predictors being intelligence, standardized beta = [...]69 (using the Swaps Test and a Wechsler scales subtest, the 40-item General Knowledge Task) and empathy, standardized beta = [...]26 (using the Questionnaire Measure of Empathic Tendency)--see also Antonakis and Dietz (2011b), who show how including or excluding important controls variables can fundamentally change results—thus, {{it is important to}} always include important controls like personality and intelligence when examining the predictive validity of ability and trait EI models.|$|E
50|$|Functional {{regression}} is {{a version}} of regression analysis when responses or <b>covariates</b> include functional data. Functional regression models can be classified into four types {{depending on whether the}} responses or <b>covariates</b> are functional or scalar: (i) scalar responses with functional <b>covariates,</b> (ii) functional responses with scalar <b>covariates,</b> (iii) functional responses with functional <b>covariates,</b> and (iv) scalar or functional responses with functional and scalar <b>covariates.</b> In addition, functional regression models can be linear, partially linear, or nonlinear. In particular, functional polynomial models, functional single and multiple index models and functional additive models are three special cases of functional nonlinear models.|$|E
40|$|The human gait is a discriminative feature {{capable of}} {{recognising}} a person by their unique walking manner. Currently gait recognition {{is based on}} videos captured in a controlled environment. These videos contain challenges, termed <b>covariate</b> factors, which affect the natural appearance and motion of gait, e. g. carrying a bag, clothing, shoe type and time. However gait recognition has yet to achieve robustness to these <b>covariate</b> factors. To achieve enhanced robustness capabilities, {{it is essential to}} address the existing gait recognition limitations. Specifically, this thesis develops an understanding of how <b>covariate</b> factors behave while a person is in motion and the impact <b>covariate</b> factors have on the natural appearance and motion of gait. Enhanced robustness is achieved by producing a combination of novel gait representations and novel <b>covariate</b> factor detection and removal procedures. Having addressed the limitations regarding <b>covariate</b> factors, this thesis achieves the goal of robust gait recognition. Using a skeleton representation of the human figure, the Skeleton Variance Image condenses a skeleton sequence into a single compact 2 D gait representation to express the natural gait motion. In addition, a <b>covariate</b> factor detection and removal module is used to maximise the mitigation of <b>covariate</b> factor effects. By establishing the average pixel distribution within training (<b>covariate</b> factor free) representations, a comparison against test (<b>covariate</b> factor) representations achieves effective <b>covariate</b> factor detection. The corresponding difference can effectively remove <b>covariate</b> factors which occur at the boundary of, and hidden within, the human figure. The Engineering and Physical Sciences Research Council (EPSRC...|$|R
40|$|We propose Bayesian {{inference}} in hazard {{regression models}} where the baseline hazard is unknown, <b>covariate</b> e¤ects are possibly agevarying (non-proportional), {{and there is}} multiplicative frailty with arbitrary distribution. Our framework incorporates {{a wide variety of}} order restrictions on <b>covariate</b> dependence and duration dependence (ageing). We propose estimation and evaluation of age-varying <b>covariate</b> e¤ects when <b>covariate</b> dependence is monotone rather than proportional. In particular, we consider situations where the lifetime conditional on a higher value of the <b>covariate</b> ages faster or slower than that conditional on a lower value; this kind of situation is common i...|$|R
40|$|The final {{publication}} {{is available}} at Springer via [URL] new approach for constructing tests for association between a random right censored life time variable and a <b>covariate</b> is proposed. The basic idea is to first arrange the observations in increasing order of the <b>covariate</b> and then base the test on a certain point process defined by the observation times. Tests constructed by this approach are robust against outliers in the <b>covariate</b> values or misspecification of the <b>covariate</b> scale since they only use the ordering of the <b>covariate.</b> Of particular interest is a test based on the Anderson-Darling statistic. This test has good power properties both against monotonic and nonmonotonic dependencies between the <b>covariate</b> and the life time variable...|$|R
5000|$|... {{along with}} P(ym = 0 ∨ ym-1 = 0, xm, cm= 0) and {{use this to}} set up the partial {{likelihood}} for person i. So, essentially, the partial likelihood with time-varying <b>covariates</b> resembles the partial likelihood with time-invariant <b>covariates</b> where the time-invariant <b>covariates</b> are replaced by the time-variant <b>covariates.</b> This likelihood, however, only holds under the assumptions stated above.|$|E
5000|$|Minimize {{allocation}} bias (or confounding). This {{may occur}} when <b>covariates</b> {{that affect the}} outcome are not equally distributed between treatment groups, and the treatment effect is confounded with {{the effect of the}} <b>covariates</b> (i.e., an [...] "accidental bias"). If the randomization procedure causes an imbalance in <b>covariates</b> related to the outcome across groups, estimates of effect may be biased if not adjusted for the <b>covariates</b> (which may be unmeasured and therefore impossible to adjust for).|$|E
50|$|In 2005, Zou and Hastie {{introduced}} the elastic net to address several shortcomings of lasso. When p > n (the number of <b>covariates</b> {{is greater than}} the sample size) lasso can select only n <b>covariates</b> (even when more are associated with the outcome) and it tends to select only one covariate from any set of highly correlated <b>covariates.</b> Additionally, even when n > p, if the <b>covariates</b> are strongly correlated, ridge regression tends to perform better.|$|E
40|$|This paper {{examines}} {{the problem of}} nonparametric testing for the no-effect of a random <b>covariate</b> (or predictor) on a functional response. This means testing whether the conditional expectation of the response given the <b>covariate</b> is almost surely zero or not, without imposing any model relating response and <b>covariate.</b> The <b>covariate</b> could be univariate, multivariate or functional. Our test statistic is a quadratic form involving univariate nearest neighbor smoothing and the asymptotic critical values are given by the standard normal law. When the <b>covariate</b> is multidimensional or functional, a preliminary dimension reduction device is used which allows {{the effect of the}} <b>covariate</b> to be summarized into a univariate random quantity. The test is able to detect not only linear but nonparametric alternatives. The responses could have conditional variance of unknown form and the law of the <b>covariate</b> {{does not need to be}} known. An empirical study with simulated and real data shows that the test performs well in applications...|$|R
40|$|This paper {{describes}} a simple extension of popular tests of equality of hazard rates in a two-sample or k-sample setup {{to a situation}} where the <b>covariate</b> under study is continuous. In other words, we test the null hypothesis that the hazard does not depend on the value of the <b>covariate</b> against the omnibus alternative, where the <b>covariate</b> is continuous. The tests developed are also useful in detecting trend in the underlying hazard rates (i. e., when the alternative hypothesis postulates that the hazard function is increasing or decreasing {{in the value of the}} <b>covariate,</b> for all durations) or changepoint trend alternatives (where the hazard function increases in <b>covariate</b> value over one range of the <b>covariate</b> space, and decreases over another). Asymptotic distributions of the test statistics are established using counting process techniques. Small sample properties of the tests are studied, and the use of the tests in empirical applications is illustrated. <b>Covariate</b> dependence; Continuous covariate; Two-sample tests; Trend tests...|$|R
40|$|We {{consider}} {{the problem of}} inference on the regression coefficient in the Cox's proportional hazards regression model with a censored <b>covariate.</b> The relative risk function depends on the baseline hazard {{as well as the}} distribution of the <b>covariate.</b> Since the <b>covariate</b> may not be observed due to censoring, we propose a method to empirically estimate the relative risk function based on the uncensored <b>covariate</b> data and derive a partial likelihood function using the estimated relative risk function. This approach enables us to use all possible information contained in the censored <b>covariate</b> data. Asymptotic properties of the proposed estimator are derived, and its efficiency is assessed for exponential failure times using an exponential relative risk function through simulation studies. Censored <b>covariate</b> Partial likelihood Kaplan-Meier estimator Martingale central limit theorem Proportional hazards regression model...|$|R
50|$|If {{parameter}} {{estimates are}} sensitive to removing or adding <b>covariates</b> to the model, then this may {{cast doubt on the}} validity of the regression discontinuity design. A significant change may suggest that those who just barely got treatment differ in these <b>covariates</b> from those who just barely did not get treatment. Including <b>covariates</b> would remove some of this bias. If a large amount of bias is present, and the <b>covariates</b> explain a significant amount of this, then their inclusion or exclusion would significantly change the parameter estimate.|$|E
5000|$|In addition, the {{principal}} components are {{obtained from the}} eigen-decomposition of [...] that involves the observations for the explanatory variables only. Therefore, the resulting PCR estimator obtained from using these principal components as <b>covariates</b> need not necessarily have satisfactory predictive performance for the outcome. A somewhat similar estimator that tries {{to address this issue}} through its very construction is the partial least squares (PLS) estimator. Similar to PCR, PLS also uses derived <b>covariates</b> of lower dimensions. However unlike PCR, the derived <b>covariates</b> for PLS are obtained based on using both the outcome as well as the <b>covariates.</b> While PCR seeks the high variance directions in the space of the <b>covariates,</b> PLS seeks the directions in the covariate space that are most useful for the prediction of the outcome.|$|E
5000|$|Recently, {{a variant}} of the {{classical}} PCR known as the supervised PCR was proposed by Bair, Hastie, Paul and Tibshirani (2006). In a spirit similar to that of PLS, it attempts at obtaining derived <b>covariates</b> of lower dimensions based on a criteria that involves both the outcome as well as the <b>covariates.</b> The method starts by performing a set of [...] simple linear regressions (or univariate regressions) wherein the outcome vector is regressed separately on each of the [...] <b>covariates</b> taken one at a time. Then, for some , the first [...] <b>covariates</b> that {{turn out to be the}} most correlated with the outcome (based on the degree of significance of the corresponding estimated regression coefficients) are selected for further use. A conventional PCR, as described earlier, is then performed, but now it is based on only the [...] data matrix corresponding to the observations for the selected <b>covariates.</b> The number of <b>covariates</b> used: [...] and the subsequent number of principal components used: [...] are usually selected by cross-validation.|$|E
40|$|Two sample nonparametic tests, e. g. Wilcoxon rank sum {{test has}} been widely used in {{clinical}} trials. However, few studies evaluated the <b>covariate</b> adjustment to these tests. In my dissertation, I evaluated the empirical power and the type I error rates for the test with <b>covariate</b> adjusting approaches when there is <b>covariate</b> imbalance. I also evaluated the mean square error and 95 % coverage probability for the point estimation. In the simulation study, we identified ANCOVA approach is not valid when there is severe <b>covariate</b> imbalance and quantile-stratification is not valid when <b>covariate</b> is extremely imbalanced. We applied the proposed approaches to three Phase II clinical trials, TIME, LateTIME, and FOCUS. ...|$|R
40|$|The {{impact of}} <b>covariate</b> aggregation, well studied in {{relation}} to linear regression, is less clear in the Cox model. In this paper, the authors use real-life epidemiologic data to illustrate how aggregating individual <b>covariate</b> values may lead to important underestimation of the exposure effect. The issue is then systematically assessed through simulations, with six alternative <b>covariate</b> representations. It is shown that aggregation of important predictors results in a systematic bias toward the null in the Cox model estimate of the exposure effect, even if exposure and predictors are not correlated. The underestimation bias increases with increasing strength of the <b>covariate</b> effect and decreasing censoring and, for a strong predictor and moderate censoring, may exceed 20 %, with less than 80 % coverage of the 95 % confidence interval. However, <b>covariate</b> aggregation always induces smaller bias than <b>covariate</b> omission does, even if the two phenomena are shown to be related. The impact of <b>covariate</b> aggregation, but not omission, is independent of the covariate-exposure correlation. Simulations involving timedependent aggregates demonstrate that bias results from failure of the baseline <b>covariate</b> mean to account for nonrandom changes over time in the risk sets and suggest a simple approach that may reduce the bias if individual data are available but have to be aggregated...|$|R
30|$|P-values {{for each}} <b>covariate</b> in each final model are presented, {{together}} with odds ratios and 95 % confidence intervals for each <b>covariate</b> category versus an appropriate reference group.|$|R
50|$|A {{propensity}} score is {{the probability of}} a unit (e.g., person, classroom, school) being assigned to a particular treatment given a set of observed <b>covariates.</b> Propensity scores are used to reduce selection bias by equating groups based on these <b>covariates.</b>|$|E
50|$|A {{crossover}} study has two advantages over both a parallel study and a non-crossover longitudinal study. First, {{the influence of}} confounding <b>covariates</b> is reduced because each crossover patient serves as {{his or her own}} control. In a non-{{crossover study}}, even randomized, it is often the case that different treatment-groups are found to be unbalanced on some <b>covariates.</b> In a controlled, randomized crossover designs, such imbalances are implausible (unless <b>covariates</b> were to change systematically during the study).|$|E
5000|$|Therefore, highly {{correlated}} <b>covariates</b> {{will tend to}} have similar regression coefficients, with the degree of similarity depending on both [...] and , which {{is very different from}} lasso. This phenomenon, in which strongly correlated <b>covariates</b> have similar regression coefficients, {{is referred to as the}} grouping effect and is generally considered desirable since, in many applications, such as identifying genes associated with a disease, one would like to find all the associated <b>covariates,</b> rather than selecting only one from each set of strongly correlated <b>covariates,</b> as lasso often does. In addition, selecting only a single covariate from each group will typically result in increased prediction error, since the model is less robust (which is why ridge regression often outperforms lasso).|$|E
40|$|<b>Covariate</b> shift relaxes the widely-employed {{independent}} and identically distributed (IID) assumption by allowing different training and testing input distributions. Unfortunately, common methods for addressing <b>covariate</b> shift {{by trying to}} remove the bias between training and testing distributions using importance weighting often provide poor performance guarantees in theory and unreliable predictions with high variance in practice. Recently developed methods that construct a predictor that is inherently robust to the difficulties of learning under <b>covariate</b> shift are restricted to minimizing logloss and can be too conservative when faced with high-dimensional learning tasks. We address these limitations in two ways: by robustly minimizing various loss functions, including non-convex ones, under the testing distribution; and by separately shaping the influence of <b>covariate</b> shift according to different feature-based views {{of the relationship between}} input variables and example labels. These generalizations make robust <b>covariate</b> shift prediction applicable to more task scenarios. We demonstrate the benefits on classification under <b>covariate</b> shift tasks...|$|R
40|$|This thesis {{presents}} a simulation study on parameter estimation for binary and multinomial logistic regression, and {{the extension of}} the clustering partitioning strategy for goodness-of-fit test to multinomial logistic regression model. The motivation behind this study is influenced by two main factors. Firstly, parameter estimation is often sensitive to sample size and types of data. Simulation studies are useful to assess and confirm the effects of parameter estimation for binary and multinomial logistic regression under various conditions. The first phase of this study covers the effect of different types of <b>covariate,</b> distributions and sample size on parameter estimation for binary and multinomial logistic regression model. Data were simulated for different sample sizes, types of <b>covariate</b> (continuous, count, categorical) and distributions (normal or skewed for continuous variable). The simulation results show that the effect of skewed and categorical <b>covariate</b> reduces as sample size increases. The parameter estimates for normal distribution <b>covariate</b> apparently are less affected by sample size. For multinomial logistic regression model with a single <b>covariate,</b> a sample size of at least 300 is required to obtain unbiased estimates when the <b>covariate</b> is positively skewed or is a categorical <b>covariate...</b>|$|R
40|$|This {{dissertation}} {{consists of}} three papers written on the design and analysis of experiments {{in the presence of}} spatial correlation. The first paper discusses the use of optimality criteria in the design of experiments. In the context of linear models, an optimality criterion is developed for models that include random effects. This criterion also allows for the inclusion of fixed and/or random nuisance parameters in the model and for the presence of a general covariance structure. Also, a general formula is presented for which all previously published optimality criteria are special cases. ^ The second paper presents a simulation study on changing the support of a spatial <b>covariate.</b> Researchers are increasingly able to capture spatially referenced data on both a response and a <b>covariate</b> more frequently and in more detail. A combination of geostatisical models and analysis of covariance methods is used to analyze such data. However, basic questions regarding the effects of using a <b>covariate</b> whose support differs from that of the response variable must be addressed to utilize these methods more efficiently. A simulation study was conducted to assess the effects of including a <b>covariate</b> whose support differs from that of the response variable in the analysis. This study suggests that the support of the <b>covariate</b> should be {{as close as possible to}} the support of the response variable. ^ The third paper presents a new method for analysis of covariance with a spatial <b>covariate.</b> Data sets which contain measurements on a spatially referenced response and <b>covariate</b> are analyzed using either cokriging or spatial analysis of covariance. While cokriging accounts for the correlation structure of the <b>covariate,</b> it is purely a predictive tool. Alternatively, spatial analysis of covariance allows for parameter estimation yet disregards the correlation structure of the <b>covariate.</b> A method is proposed which both accounts for the correlation in and between the response and <b>covariate</b> and allows for the estimation of model parameters; also, this method allows for analysis of covariance when the response and <b>covariate</b> are not colocated. ...|$|R
