460|8275|Public
25|$|Scratch – a cross {{platform}} teaching IDE using visual blocks that stack like Lego™ originally developed by MIT's Life Long Kindergarten group. The Pi version is very heavily optimised for the limited <b>compute</b> <b>resources</b> available and is {{implemented in the}} Squeak Smalltalk system.|$|E
5000|$|... avoids idling the <b>compute</b> <b>resources</b> without minute-by-minute human {{supervision}} ...|$|E
50|$|DreamHost's DreamCompute is {{a public}} cloud {{computing}} service that provides scalable <b>compute</b> <b>resources</b> for developers and entrepreneurs. DreamCompute users select the amount of <b>compute</b> <b>resources</b> and storage resources needed and define their own virtual networks. DreamCompute is powered by OpenStack and Ceph and is designed for scalability, resiliency, and security.|$|E
40|$|Mobile crowdsourcing, as an {{emerging}} service paradigm, enables the <b>computing</b> <b>resource</b> requestor (CRR) to outsource computation tasks to each <b>computing</b> <b>resource</b> provider (CRP). Considering {{the importance of}} pricing as an essential incentive to coordinate the real-time interaction among the CRR and CRPs, in this paper, we propose an optimal real-time pricing strategy for <b>computing</b> <b>resource</b> management in mobile crowdsourcing. Firstly, we analytically model the CRR and CRPs behaviors in form of carefully selected utility and cost functions, based on concepts from microeconomics. Secondly, we propose a distributed algorithm through the exchange of control messages, which contain the information of <b>computing</b> <b>resource</b> demand/supply and real-time prices. We show that there exist real-time prices that can align individual optimality with systematic optimality. Finally, we also {{take account of the}} interaction among CRPs and formulate the <b>computing</b> <b>resource</b> management as a game with Nash equilibrium achievable via best response. Simulation results demonstrate that the proposed distributed algorithm can potentially benefit both the CRR and CRPs. The coordinator in mobile crowdsourcing can thus use the optimal real-time pricing strategy to manage <b>computing</b> <b>resources</b> towards the benefit of the overall system...|$|R
40|$|In this research, {{we suggest}} {{appropriate}} information technology (IT) governance structures {{to manage the}} cloud <b>computing</b> <b>resources.</b> The interest in acquiring IT resources a utility is gaining momentum. Cloud <b>computing</b> <b>resources</b> present organizations with opportunities to manage their IT expenditure on an ongoing basis, and are providing organizations access to modern IT resources to innovate and manage their continuity. However, cloud <b>computing</b> <b>resources</b> are no silver bullet. Organizations would need to have appropriate governance structures and policies in place to ensure its effective management and fit into existing business processes to leverage the promised opportunities. Using a mixed method design, we identified four possible governance structures for managing the cloud <b>computing</b> <b>resources.</b> These structures are a chief cloud officer, a cloud management committee, a cloud service facilitation centre, and a cloud relationship centre. These governance structures ensure appropriate direction of cloud <b>computing</b> <b>resources</b> from its acquisition {{to fit into the}} organizations business processes...|$|R
40|$|CompuP 2 P is an {{architecture}} for sharing of <b>computing</b> <b>resources</b> in peer-to-peer (P 2 P) networks. It provide resources, such as processing power, memory storage etc., to user applications that might require them. CompuP 2 P creates dynamic markets for different amounts of <b>computing</b> <b>resources</b> without relying on any trusted centralized entity {{to monitor the}} activities of nodes in those markets. Moreover, the pricing of <b>computing</b> <b>resources</b> takes into account selfishness of network users and uses ideas from game theory and microeconomics...|$|R
5000|$|... #Caption: The carrier cloud synchronizes {{delivery}} of network and <b>compute</b> <b>resources</b> ...|$|E
50|$|The National Grid has {{the mission}} of {{transforming}} Singapore into a nation where <b>compute</b> <b>resources</b> can be interconnected via a next-generation cyberinfrastructure that allows the sharing of <b>compute</b> <b>resources</b> in a secure, reliable and efficient manner by authenticated users for education, commerce entertainment, R&D, and national security {{in order to improve}} the economic and technological competitiveness of the country.|$|E
50|$|Databases are {{available}} as Standalone databases or in database pools which allow multiple databases to share storage and <b>compute</b> <b>resources.</b>|$|E
25|$|<b>Computing</b> <b>resources</b> are not {{administered}} centrally.|$|R
30|$|BBU scaling: BBUs are {{dynamically}} scaled {{according to}} the network requirements. For example, {{when there is an}} increase in network traffic, a virtual BBU can be scaled up to utilize more <b>computing</b> <b>resources.</b> In addition, in case of future network extensions, more virtual BBUs can be instantiated. A novel resource optimization algorithm which takes into account thermal and <b>computing</b> <b>resource</b> models was developed in [28]. Optimization is achieved by allocating the maximum load to BBU under thermal constraints. The optimization problem is solved using Lagrange multiplier with Kuhn-Tucker condition. In [29], Zhang et al. aimed at minimizing the total amount of <b>computing</b> <b>resources</b> needed, while balancing the allocated <b>computing</b> <b>resources</b> among BBUs. The optimization is formulated as a bin-packing problem and solved using a heuristic genetic algorithm.|$|R
5000|$|... allows around-the-clock high {{utilization}} of expensive <b>computing</b> <b>resources</b> ...|$|R
50|$|Management {{features}} for <b>compute</b> <b>resources</b> include CPU pinning, defining NUMA topology, enabling kernel same-page merging, memory over-provisioning, HA VM reservation etc.|$|E
5000|$|HP Cloud Load Balancers are a managed load {{balancing}} service {{that allow for}} the automatic distribution of incoming traffic across <b>compute</b> <b>resources.</b>|$|E
50|$|To {{qualify for}} support {{research}} groups should form a Virtual Organization, a VO. The VO provides <b>compute</b> <b>resources</b> for sharing and NDGF Tier-1 operates a Grid interface for {{the sharing of}} these resources.|$|E
40|$|The {{production}} of 2 D and 3 D animated films demands high end systems with massive <b>computing</b> <b>resource.</b> Handling massive <b>computing</b> <b>resources</b> requires high investment in infrastructure and maintenance, which is amajor hindrance for the animation industry / animators {{who want to}} produce few minutes of film. The cloud services promises to deliver on-demand and scalable <b>computing</b> <b>resources</b> to the animation industry. In this paper, it is proposed to investigate the cloud services in animation. The research is designed in two case studies to analyze the scenarios in both traditional and through the cloud services...|$|R
5000|$|Distributed <b>computing</b> <b>resources</b> (Estonian Scientific <b>Computing</b> Infrastructure, Estonian Grid) ...|$|R
5000|$|... #Subtitle level 3: UNICORE: {{easy access}} to <b>computing</b> <b>resources</b> ...|$|R
50|$|Google compute {{engine unit}} (GCEU), which is {{pronounced}} as GQ, is an abstraction of <b>compute</b> <b>resources.</b> According to Google, 2.75 GCEUs represent the minimum power of one logical core (a hardware hyper-thread) {{based on the}} Sandy Bridge platform.|$|E
50|$|HP CloudSystem is a {{component}} of HP Cloud. It enables user organizations to burst workloads to external or internal cloud resources in times of increased workloads or when they want additional <b>compute</b> <b>resources.</b> This function is known as cloud bursting.|$|E
5000|$|Scratch - a cross {{platform}} teaching IDE using visual blocks that stack like Lego™ originally developed by MIT's Life Long Kindergarten group. The Pi version is very heavily optimised for the limited <b>compute</b> <b>resources</b> available and is {{implemented in the}} Squeak Smalltalk system.|$|E
50|$|Device nodes are {{physical}} <b>computing</b> <b>resources</b> with processing {{memory and}} services to execute software, such as typical computers or mobile phones. An execution environment node (EEN) is a software <b>computing</b> <b>resource</b> that runs within an outer node and which itself provides a service to host and execute other executable software elements.|$|R
40|$|<b>Computing</b> <b>resources</b> {{supporting}} our {{activities are}} moving over from PC and workstations to the Clouds across Internet. Cloud is collective <b>computing</b> <b>resources,</b> which consist from computers, network, data storage, and data themselves. Cloud serves {{a large number}} of users and clients and it is pushing the demand for large-scale dat...|$|R
5000|$|Volunteer {{computing}} {{is a type}} of distributed computing,"an {{arrangement in}} which people, so-called volunteers, provide <b>computing</b> <b>resources</b> to projects, which use the resources to do distributed computing and/or storage". Thus, computer owners or users donate their <b>computing</b> <b>resources</b> (such as processing power and storage) to one or more [...] "projects".|$|R
5000|$|AWS Lambda is an event-driven, {{serverless}} computing platform {{provided by}} Amazon {{as a part}} of the Amazon Web Services. It is a compute service that runs code in response to events and automatically manages the <b>compute</b> <b>resources</b> required by that code. It was introduced in 2014.|$|E
50|$|Azul's Java Compute Appliances (JCAs) were {{designed}} to massively scale up the usable <b>compute</b> <b>resources</b> available to Java applications. A proxy Java Virtual Machine (JVM) installed on the existing system will transparently redeploy Java applications to the Azul appliance, {{the latest version of}} which, the Vega 3, can contain up to 864 processor cores and 768 GB of memory.|$|E
50|$|The Slovenian National Grid Initiative (NGI) {{provides}} {{resources to}} the European Grid Initiative (EGI). It is represented in the EGI Council by ARNES. ARNES manages a cluster for testing computing technology where users can also submit jobs. The cluster consists of 2300 cores and is growing. Arctur also provides <b>compute</b> <b>resources</b> on its Arctur-1 supercomputer to the Slovenian NGI.|$|E
40|$|This {{viewgraph}} presentation {{provides information}} on NASA's geographically dispersed <b>computing</b> <b>resources,</b> and the various methods by which the disparate technologies are integrated within a nationwide computational grid. Many large-scale science and engineering projects are accomplished through the interaction of people, heterogeneous <b>computing</b> <b>resources,</b> information systems and instruments at different locations. The overall goal is to facilitate the routine interactions of these resources to reduce the time spent in design cycles, particularly for NASA's mission critical projects. The IPG (Information Power Grid) seeks to implement NASA's diverse <b>computing</b> <b>resources</b> in a fashion {{similar to the way}} in which electric power is made available...|$|R
5000|$|Database Resource Manager (DRM), which {{controls}} {{the use of}} <b>computing</b> <b>resources.</b>|$|R
3000|$|... [*]Participants {{expected}} a quicker response in VNC for the real-time collaboration. There was still some latency (lag) in synchronizing the MR scenes {{between the two}} collaborators because the VNC conveyed the video stream which occupied {{too much of the}} available <b>computing</b> <b>resource.</b> The performance was heavily dependent on the <b>computing</b> <b>resource</b> and the network bandwidth.|$|R
50|$|Azul {{produces}} Zing, a Java Virtual Machine (JVM) and runtime {{platform for}} Java applications {{that is designed}} to remove memory limitations and scale elastically. The company was formerly known for its Vega Java Compute Appliances (JCAs), specialized hardware designed to massively scale the usable <b>compute</b> <b>resources</b> available to Java applications. Zing utilizes and improves on the software technology developed for the Vega hardware.|$|E
5000|$|Managing {{a private}} cloud {{requires}} software tools {{to help create}} a virtualized pool of <b>compute</b> <b>resources,</b> provide a self-service portal for end users and handle security, resource allocation, tracking and billing. [...] Management tools for private clouds tend to be service driven, as opposed to resource driven, because cloud environments are typically highly virtualized and organized in terms of portable workloads.|$|E
50|$|A {{key feature}} of {{the design of the}} system has been its support for data {{management}} within the workflow engine itself. This is an important feature since scientific experiments typically generate and use large amounts of heterogeneous and distributed data sets. The system was thus designed to support persistence and caching of intermediate data products and also to support scalable workflow execution over potentially large data sets using remote <b>compute</b> <b>resources.</b>|$|E
50|$|A message {{queueing}} service {{also creates}} new value by providing reduced costs, enhanced performance and reliability. In {{order to provide}} those benefits, a message queueing service leverages cloud <b>computing</b> <b>resources</b> such as storage, network, memory and processing capacity. By using virtually unlimited cloud <b>computing</b> <b>resources,</b> a message queueing service provides an internet scale messaging platform.|$|R
5000|$|SRMs {{are used}} by TJNAF to provide the CLAS and Lattice QCD collaborations with remote access to the JASMine mass storage system. Such access has allowed {{researchers}} to utilize <b>computing</b> <b>resources</b> at universities and other collaborating institutions to process and analyze data weeks or months sooner than if done using only TJNAF <b>computing</b> <b>resources.</b>|$|R
40|$|Abstract: Applications using Grid {{computing}} infrastructure usually require resources allocation {{to satisfy}} their Quality of Service (QoS) requirements. Given that the Grid infrastructure {{is a set of}} <b>computing</b> <b>resources</b> geographically distributed, the support of Grid applications requires the allocation of <b>computing</b> <b>resources</b> and bandwidth to enable communication among these resources. The objective is to accommodate as many applications as possible while still satisfying their requirements. Ideally, we would like to accommodate a given Grid application using a set of <b>computing</b> <b>resources</b> (e. g., one server) that are not geographically distributed (e. g., in the same LAN); however, this is not always possible. Indeed, to increase the probability of accommodating Grid applications, we may need to use <b>computing</b> <b>resources</b> scattered all over the network; in this case, bandwidth allocation is required to enable communication among these resources. In this paper, we propose an optimization model that enables the “simultaneous ” allocation of <b>computing</b> <b>resources</b> and bandwidth for Grid application while maximizing the number of Grid applications being accommodated. A heuristic is proposed to solve the model with an acceptable response time; simulations show that the proposed approach outperforms existing classical approaches...|$|R
