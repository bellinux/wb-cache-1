1|273|Public
40|$|AbstractWe formalize higher-order {{separation}} logic for a first-order {{imperative language}} with procedures and local variables in Isabelle/HOLCF. The assertion language is modeled {{in such a}} way that one may use any theory defined in Isabelle/HOLCF to construct assertions, e. g., primitive recursion, least or greatest fixed points etc. The higher-order logic ensures that we can show non-trivial algorithms correct without having to extend the semantics of the language as was done previously in verifications based on first-order separation logic [Birkedal, L., N. T. Smith and J. C. Reynolds, Local reasoning about a copying garbage collector, in: Proceedings of the 31 st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (2004), pp. 220 – 231; Yang, H., An example of local reasoning in BI pointer logic: the Schorr-Waite graph marking algorithm (2000) ]. We provide non-trivial examples to support this claim and to show how the higher-order logic enables natural assertions in specifications. To support abstract reasoning we have implemented rules for representation hiding and data abstraction as seen in [Biering, B., L. Birkedal and N. Torp-Smith, BI-hyperdoctrines, higher-order separation logic, and abstraction, ACM Trans. Program. Lang. Syst. 29 (2007) ]. The logic is represented as lemmas for reasoning about the denotational semantics of the programming language. This follows the definitional approach common in HOL theorem provers, i. e., the soundness of our model only relies on the soundness of Isabelle/HOL [Gordon, M., Introduction to the HOL system, in: HOL Theorem Proving System and Its Applications, 1991., International Workshop on the, 1991, pp. 2 – 3]. We use our formalization to give a formally verified proof of Cheney's copying garbage collector [Cheney, C. J., A nonrecursive list <b>compacting</b> <b>algorithm,</b> Commun. ACM 13 (1970), pp. 677 – 678] using a tagged representation of objects. The proof generalizes the results in [Birkedal, L., N. T. Smith and J. C. Reynolds, Local reasoning about a copying garbage collector, in: Proceedings of the 31 st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (2004), pp. 220 – 231]. The proof uses an encoding of the separation logic formula this(h) to capture the heap from before the garbage collection and thus shows another novel use of higher-order separation logic...|$|E
25|$|Faster {{and more}} <b>compact</b> <b>algorithms</b> for Gregorian Easter Sunday exist.|$|R
40|$|Challenges in many {{real-world}} optimization {{problems arise}} from limited hardware availability, {{particularly when the}} optimization must be performed on a device whose hardware is highly restricted due to cost or space. This paper proposes a new <b>algorithm,</b> namely Enhanced <b>compact</b> Artificial Bee Colony (EcABC) to address this class of optimization problems. The algorithm benefits from the search logic of the Artificial Bee Colony (ABC) algorithm, and similar to other <b>compact</b> <b>algorithms,</b> it does not store the actual population of tentative solutions. Instead, EcABC employs a novel probabilistic representation {{of the population that}} is introduced in this paper. The proposed algorithm has been tested on a set of benchmark functions from the CEC 2013 benchmark suite, and compared against a number of <b>algorithms</b> including modern <b>compact</b> <b>algorithms,</b> recent population-based ABC variants and some advanced meta-heuristics. Numerical results demonstrate that EcABC significantly outperforms other state of the art <b>compact</b> <b>algorithms.</b> In addition, simulations also indicate that the proposed algorithm shows a comparative performance when compared against its population-based versions...|$|R
40|$|<b>Compact</b> {{evolutionary}} <b>algorithms</b> {{have proven}} to be an efficient alternative for solving optimization problems in computing environments with low processing power. In this kind of solution, a probability distribution simulates the behavior of a population, thus looking for memory savings. Several <b>compact</b> <b>algorithms</b> have been proposed, including the <b>compact</b> genetic <b>algorithm</b> and <b>compact</b> differential evolution. This work aims to investigate the use of compact approaches in other important evolutionary algorithms: evolution strategies. This paper proposes two different approaches for compact versions of evolution strategies. Experiments were performed and the results analyzed. The results showed that, depending on the nature of problem, the use of the compact version of Evolution Strategies can be rewarding. </p...|$|R
40|$|<b>Compact</b> <b>algorithms</b> {{generating}} {{and solving}} finite-difference approximations of partial differential equations for propagation of waves obtained by new method. Based on concept of discrete dispersion relation. Used in wave propagation to relate frequency to wavelength and is key measure of wave fidelity...|$|R
40|$|We {{study the}} {{effective}} numerical solution of first-exit-time problems {{in any number}} of dimensions with an arbitrary boundary. We show how a full discretization of the diffusive process, both in space and time, gives accurate results, allowing a clean mathematical analysis and the realization of fast and <b>compact</b> <b>algorithms...</b>|$|R
50|$|Van Flandern and Henry Fliegel {{developed}} a <b>compact</b> <b>algorithm</b> to calculate a Julian date from a Gregorian date {{that would fit}} on a single IBM card. They described this {{in a letter to}} the editor of a computing magazine in 1968. This was available for use in business applications.|$|R
40|$|The {{cryptography}} {{approach to}} the Turing machine is defined {{not only by the}} construction of neural networks, but also by the robust need for digital-toanalog converters. In this position paper, we show the refinement of write-back caches. In our research, we use <b>compact</b> <b>algorithms</b> to prove that reinforcement learning and IPv 4 can agree to answer this quagmire. ...|$|R
40|$|Abstract—This paper {{describes}} a novel virtual population based truncation selection operator that extends our previously proposed virtual population based tournament selection opera-tor [1]. Moreover, two extensions of <b>compact</b> genetic <b>algorithm</b> (CGA) that {{make use of}} virtual population based selection operators are presented in this paper: one is the tournament selection on virtual population based <b>compact</b> genetic <b>algorithm</b> (SVPCGA-TO); {{the other is the}} truncation selection on virtual population based <b>compact</b> genetic <b>algorithm</b> (SVPCGA-TR). Both SVPCGA-TO and SVPCGA-TR are tested on several benchmark problems and their results are compared with those obtained by CGA [2] and ne-CGA [3]. Some superiorities of SVPCGA in search reliability can be achieved. I...|$|R
40|$|A very <b>compact</b> <b>algorithm</b> is {{presented}} for fitting an ellipse to points in images by maximum likelihood (ML) in the strict sense. Although our algorithm produces the same solution as existing ML-based methods, {{it is probably}} the simplest and the smallest of all. By numerical experiments, we show that the strict ML solution practically coincides with the Sampson solution. 1...|$|R
40|$|<b>Compact</b> <b>algorithms</b> are Estimation of Distribution Algorithms which {{mimic the}} {{behavior}} of population-based algorithms {{by means of a}} probabilistic representation of the population of candidate solutions. These algorithms have a similar behaviour with respect to population-based algorithms but require a much smaller memory. This feature is crucially important in some engineering applications, especially in robotics. A high performance <b>compact</b> <b>algorithm</b> is the <b>compact</b> Differential Evolution (cDE) algorithm. This paper proposes a novel implementation of cDE, namely compact Differential Evolution light (cDElight), to address not only the memory saving necessities but also real-time requirements. cDElight employs two novel algorithmic modifications for employing a smaller computational overhead without a performance loss, with respect to cDE. Numerical results, carried out on a broad set of test problems, show that cDElight, despite its minimal hardware requirements, does not deteriorate the performance of cDE and thus is competitive with other memory saving and population-based algorithms. An application in the field of mobile robotics highlights the usability and advantages of the proposed approach...|$|R
5000|$|Treyfer - A {{simple and}} <b>compact</b> {{encryption}} <b>algorithm</b> with 64 bit key size and block size.|$|R
40|$|This paper {{presents}} a cellular <b>compact</b> genetic <b>algorithm</b> (CCGA) for evolvable and adaptive hardware. The CCGA has cellular-like structure which {{is suitable for}} hardware implementation. The CCGA is developed from <b>compact</b> genetic <b>algorithm</b> (CGA) and parallel estimation of distribution algorithm (EDA). The concept and algorithm of the CCGA are presented. The standard test functions are selected to measure {{the effectiveness of the}} CCGA. The experimental results significantly shows that the CCGA outperforms the normal compact GA and deliver compatible results to the cooperative <b>compact</b> genetic <b>algorithm</b> while employs only one type of cell. The implemented hardware in FPGA demonstrates the feasibility to use this new kind of genetic algorithm to evolvable and adaptive hardware. 1...|$|R
40|$|Abstract: We {{consider}} multidimensional density estimation. Eilers et al. (2006) used multidimensional P-splines {{together with}} a new fast and <b>compact</b> <b>algorithm</b> to smooth multidimensional histograms. Currie et al. (2006) emphasized the array nature of the method and demonstrated that a mixed model could also be fitted into this array structure. In this paper we combine these ideas and show how array methods and mixed models give rise to an efficient method of estimating multidimensional densities...|$|R
40|$|A new compact third-order multidimensional {{residual}} distribution scheme for {{the solution of}} the unsteady Navier-Stokes equations on unstructured grids is proposed. This is a <b>compact</b> cell-based <b>algorithm</b> which uses a finite-element reconstruction over the cell to achieve, its high-order of accuracy. The new <b>compact</b> high-order <b>algorithm</b> has ail excellent parallel scalability, which makes it well suited for large scale computations on parallel-computers. Some results of large Eddy simulation of the fully developed turbulent channel flow are presente...|$|R
40|$|Abstract. A very <b>compact</b> <b>algorithm</b> is {{presented}} for fundamental matrix computation from point correspondences over two images. The computation {{is based on}} the strict maximum likelihood (ML) principle, minimizing the reprojection error. The rank constraint is incorporated by the EFNS procedure. Although our algorithm produces the same solution as all existing ML-based methods, it is probably the most practical of all, being small and simple. By numerical experiments, we confirm that our algorithm behaves as expected. ...|$|R
40|$|This paper {{shows how}} the {{extended}} <b>compact</b> genetic <b>algorithm</b> can be scaled using dataintensive computing techniques such as MapReduce. Two different frameworks (Hadoop and MongoDB) are used to deploy MapReduce implementations of the compact and extended <b>compact</b> genetic <b>algorithms.</b> Results show that both are good choices to deal with large-scale problems as they can scale {{with the number of}} commodity machines, as opposed to previous efforts with other techniques that either required specialized high-performance hardware or shared memory environments. ...|$|R
40|$|We {{propose a}} {{hardware}} {{implementation of the}} <b>Compact</b> Genetic <b>Algorithm</b> (<b>Compact</b> GA). The design is realized using Verilog HDL, then fabricated on FPGA. Our design, though simple, runs about 1, 000 {{times faster than the}} software executing on a workstation. An alternative hardware for linkage learning is also proposed in order to enhance the capability of Compact GA to solve highly deceptive problems...|$|R
40|$|Cryptographersagreethatlarge-scalealgorithms are an {{interesting}} new topic {{in the field of}} machine learning, and information theorists concur. In fact, few information theorists would disagree with the synthesis of 802. 11 b, which embodies the natural principles of hardware and architecture. In order to achieve this aim, we disprove that though neural networks and linked lists can cooperate to achieve this intent, the acclaimed <b>compact</b> <b>algorithm</b> for the emulation of rasterization by Martin et al. [54, 58, 59, 62, 68, 70, 95...|$|R
40|$|In {{this paper}} we {{investigate}} {{the design of}} a coarse-grained parallel implementation of Cga-LK, a hybrid heuristic for the Traveling Salesman Problem (TSP). Cga-LK exploits a <b>compact</b> genetic <b>algorithm</b> in order to generate high-quality tours which are then refined by means of an e#cient implementation of the Lin-Kernighan local search heuristic. The results of several experiments conducted on a cluster of workstations with di#erent TSP instances show the e#cacy of the parallelism exploitation. Keywords: Parallel <b>algorithms,</b> TSP, <b>compact</b> genetic <b>algorithm,</b> LinKernighan algorithm, hybrid GA. ...|$|R
40|$|This paper {{presents}} a general framework for agglomerative hierarchical clustering based on graphs. Specifying an inter-cluster similarity measure, a subgraph of the βsimilarity graph, and a cover routine, different hierarchical agglomerative clustering algorithms can be obtained. We also describe two methods obtained from this framework called Hierarchical <b>Compact</b> <b>Algorithm</b> and Hierarchical Star Algorithm. These algorithms {{have been evaluated}} using standard document collections. The experimental results show that our methods are faster and obtain smaller hierarchies than traditional hierarchical algorithms while achieving a comparable clustering quality. 1...|$|R
40|$|The <b>compact</b> genetic <b>algorithm</b> is an Estimation of Distribution Algorithm for binary {{optimisation}} problems. Unlike {{the standard}} Genetic Algorithm, no cross-over or mutation is involved. Instead, the <b>compact</b> Genetic <b>Algorithm</b> uses a virtual population {{represented as a}} probability distribution over the set of binary strings. At each optimisation iteration, exactly two individuals are generated by sampling from the distribution, and compared exactly once to determine a winner and a loser. The probability distribution is then adjusted to {{increase the likelihood of}} generating individuals similar to the winner. This paper introduces two straightforward variations of the <b>compact</b> Genetic <b>Algorithm,</b> each of which lead to a significant improvement in performance. The main idea is to make better use of each fitness evaluation, by ensuring that each evaluated individual is used in multiple win/loss comparisons. The first variation is to sample $n> 2 $ individuals at each iteration to make $n(n- 1) / 2 $ comparisons. The second variation only samples one individual at each iteration but keeps a sliding history window of previous individuals to compare with. We evaluate methods on two noisy test problems and show that in each case they significantly outperform the <b>compact</b> Genetic <b>Algorithm,</b> while maintaining the simplicity of the algorithm. Comment: 11 pages, 2 tables, 8 figure...|$|R
40|$|We {{present the}} first {{universal}} <b>compact</b> routing <b>algorithm</b> with maximum stretch bounded by 3 that uses sublinear space at every vertex. The algorithm uses local routing tables of size O(n 2 j 3 log 413 n) and achieves paths {{that are most}} 3 times {{the length of the}} shortest path distances for all nodes in an arbitrary weighted undirected network. This answers an open question of Gavoille and Gengler who showed that any universal <b>compact</b> routing <b>algorithm</b> with maximum stretch strictly less than 3 must use Q(n) local space at some vertex. ...|$|R
40|$|Abstract-Based on Harik's <b>compact</b> genetic <b>algorithm,</b> in {{this paper}} a real-coded type of <b>compact</b> genetic <b>algorithm,</b> RCGA, based on {{probability}} distribution function of each gene is developed. The algorithm is applied to design a new small-size tapered monopole ultra-wideband antenna as a practical utilization. The antenna is a modified PTMA which is able to improve the bandwidth using eleven degrees of freedom. The final optimized antenna design works from 3. 1 to 11. 7 GHz and has only 48 % of the size compared to previous work. I...|$|R
40|$|In this paper, {{a dynamic}} co-evolution <b>compact</b> genetic <b>algorithm</b> (DCCGA) is {{proposed}} for flexible flow shop scheduling problem (FFSP) {{to minimize the}} total earliness and tardiness (E/T) penalties. In this new algorithm, a dynamic co-evolution mechanism containing two probabilistic models and a best individual inheritance strategy are integrated into the <b>compact</b> genetic <b>algorithm</b> (CGA). For improving {{the stability of the}} evolutionary trend in the evolution processes, the diversity of evolution trend and the convergence speed. Lastly, the experimental results show that, DCCGA outperforms CGA by 11. 74 % on the problem we study...|$|R
40|$|The Internet {{relies on}} its inter-domain routing system to allow data {{transfer}} between any two endpoints {{regardless of where}} they are located. This routing system currently uses a shortest path routing algorithm (modified by local policy constraints) called the Border Gateway Protocol. The massive growth of the Internet has led to large routing tables {{that will continue to}} grow. This will present a serious engineering challenge for router designers in the long-term, rendering state (routing table) growth at this pace unsustainable. There are various short-term engineering solutions that may slow the growth of the inter-domain routing tables, at the expense of increasing the complexity of the network. In addition, some of these require manual configuration, or introduce additional points of failure within the network. These solutions may give an incremental, constant factor, improvement. However, we know from previous work that all shortest path routing algorithms require forwarding state that grows linearly with the size of the network in the worst case. Rather than attempt to sustain inter-domain routing through a shortest path routing <b>algorithm,</b> <b>compact</b> routing <b>algorithms</b> exist that guarantee worst-case sub-linear state requirements at all nodes by allowing an upper-bound on path length relative to the theoretical shortest path, known as path stretch. Previous work has shown the promise of these algorithms when applied to synthetic graphs with similar properties to the known Internet graph, but they haven't been studied in-depth on Internet topologies derived from real data. In this dissertation, I demonstrate the consistently strong performance of these <b>compact</b> routing <b>algorithms</b> for inter-domain routing by performing a longitudinal study of two <b>compact</b> routing <b>algorithms</b> on the Internet Autonomous System (AS) graph over time. I then show, using the k-cores graph decomposition algorithm, that the structurally important nodes in the AS graph are highly stable over time. This property makes these nodes suitable for use as the "landmark" nodes used by the most stable of the <b>compact</b> routing <b>algorithms</b> evaluated, and the use of these nodes shows similar strong routing performance. Finally, I present a decentralised <b>compact</b> routing <b>algorithm</b> for dynamic graphs, and present state requirements and message overheads on AS graphs using realistic simulation inputs. To allow the continued long-term growth of Internet routing state, an alternative routing architecture may be required. The use of the <b>compact</b> routing <b>algorithms</b> presented in this dissertation offer promise for a scalable future Internet routing system. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|This paper {{proposes a}} novel and {{unconventional}} Memetic Computing approach for solving continuous optimization problems characterized by memory limitations. The proposed algorithm, unlike employing an explorative evolutionary framework {{and a set}} of local search algorithms, employs multiple exploitative search within the main framework and performs a multiple step global search by means of a randomized perturbation of the virtual population corresponding to a periodical randomization of the search for the exploitative operators. The proposed Memetic Computing approach is based on a populationless (compact) evolutionary framework which, instead of processing a population of solutions, handles its statistical model. This evolutionary framework is based on a Differential Evolution which cooperatively employs two exploitative search operators: the first is based on a standard Differential Evolution mutation and exponential crossover, and the second is the trigonometric mutation. These two search operators have an exploitative action on the algorithmic framework and thus contribute to the rapid convergence of the virtual population towards promising candidate solutions. The action of these search operators is counterbalanced by a periodical stochastic perturbation of the virtual population, which has the role of ‘‘disturbing’’ the excessively exploitative action of the framework and thus inhibits its premature convergence. The proposed algorithm, namely Disturbed Exploitation compact Differential Evolution, is a simple and memory-wise cheap structure that makes use of the Memetic Computing paradigm in order to solve complex optimization problems. The proposed approach has been tested on a set of various test problems and compared with state-of-the-art <b>compact</b> <b>algorithms</b> and with some modern population based meta-heuristics. Numerical results show that Disturbed Exploitation compact Differential Evolution significantly outperforms all the other <b>compact</b> <b>algorithms</b> present in literature and reaches a competitive performance with respect to modern population algorithms, including some memetic approaches and complex modern Differential Evolution based algorithms. In order to show the potential of the proposed approach in real-world applications, Disturbed Exploitation compact Differential Evolution has been implemented for performing the control of a space robot by simulating the implementation within the robot micro-controller. Numerical results show the superiority of the proposed algorithm with respect to other modern <b>compact</b> <b>algorithms</b> present in literature...|$|R
40|$|Abstract. Based on an {{explicit}} {{description of the}} idealization of a graded submodule of a graded free module, we examine the behaviour of Gröbner bases and minimal homogeneous systems of generators under this process. Then we show how one can idealize a homogeneous presentation. Using this theory, we present a unified description of several strategies for computing minimal homogeneous presentations and minimal graded free resolutions, in particular of the vertical and horizontal strategies. We obtain at a simple and <b>compact</b> <b>algorithm</b> for computing minimal graded free resolutions degree-by-degree which lends itself well to further optimizations. 1...|$|R
40|$|The present work {{addresses}} {{the problem of}} model estimation and computations for discrete data when some covariates are modeled smoothly using splines. We propose to introduce and explicitly estimate individual deviance effects (one for each observation), constrained by a ridge penalty. This {{turns out to be}} an effective way to absorb model excess variation and detect systematic patterns. Large but very sparse systems of penalized likelihood equations have to be solved. We present fast and <b>compact</b> <b>algorithms</b> for fitting, estimation and computation of the effective dimension. Applications to counts, binomial, and survival data illustrate practical use of this model. © The Author(s) 2009...|$|R
40|$|<b>Compact</b> routing <b>algorithms</b> {{have been}} {{presented}} as candidates for scalable routing in the future Internet, achieving near-shortest path routing with considerably less forwarding state than the Border Gateway Protocol. Prior analyses have shown strong performance on power-law random graphs, but {{to better understand the}} applicability of <b>compact</b> routing <b>algorithms</b> {{in the context of the}} Internet, they must be evaluated against real- world data. To this end, we present the first systematic analysis of the behaviour of the Thorup-Zwick (TZ) and Brady-Cowen (BC) <b>compact</b> routing <b>algorithms</b> on snapshots of the Internet Autonomous System graph spanning a 14 year period. Both algorithms are shown to offer consistently strong performance on the AS graph, producing small forwarding tables with low stretch for all snapshots tested. We find that the average stretch for the TZ algorithm increases slightly as the AS graph has grown, while previous results on synthetic data suggested the opposite would be true. We also present new results to show which features of the algorithms contribute to their strong performance on these graphs...|$|R
40|$|In this paper, a TSK-type fuzzy model (TFM) with {{a hybrid}} {{evolutionary}} learning algorithm (HELA) is proposed. The proposed HELA method combines the <b>compact</b> genetic <b>algorithm</b> (CGA) and the modified variable-length genetic algorithm (MVGA). Both {{the number of}} fuzzy rules and the adjustable parameters in the TFM are designed concurrently using the HELA method. In the proposed HELA method, individuals of the same length constitute the same group, with multiple groups in a population. Moreover, the proposed HELA method adopts the <b>compact</b> genetic <b>algorithm</b> (CGA) {{to carry out the}} elite-based reproduction strategy. The CGA represents a population as a probability distribution over the set of solutions and is operationally equivalent to the order-one behavior of the simple GA. The evolution processes of a population consist of three major operations: group reproduction using the <b>compact</b> genetic <b>algorithm,</b> variable two-part individual crossover, and variable two-part mutation. Computer simulations have demonstrated that the proposed HELA method performs better than some existing methods. Keywords: evolutionary algorithms, TSK-type fuzzy model, variable-length genetic algorithm, identification, control 1...|$|R
40|$|Tool {{inventory}} {{has a large}} {{difference with}} the traditional static inventory since the tool can be reused by grinding. In this paper, according to the life characteristics of tool, the tool inventory cost model has been built by studying the using process of tool. The model takes all costs which includes the shortage cost in the product life cycle into account under the circumstances of demand uncertainty. The <b>compact</b> genetic <b>algorithm</b> is successfully used in the cost function optimization process. The reasonableness of the tool inventory cost model {{and the effectiveness of}} the <b>compact</b> genetic <b>algorithm</b> have been demonstrated by simulation results. © 2014 IEEE...|$|R
40|$|Compressed <b>compact</b> genetic <b>{{algorithm}}</b> (c 2 GA) is an algorithm that utilizes {{the compressed}} chromosome encoding and <b>compact</b> genetic <b>algorithm</b> (cGA). The advantage of c 2 GA {{is to reduce}} the memory usage by representing population as a probability vector. In this paper, we analyze the performance in term of robustness of c 2 GA. Since the compression and decompression strategy employ two parameters, which are the length of repeating value and the repeat count, we vary these two parameters to see the performance affected in term of convergence speed. The experimental results show that c 2 GA outperforms cGA and is a robust algorithm...|$|R
40|$|Route {{diversity}} {{systems as}} available means {{to improve the}} rain outage performance are examined by comparison to tandem systems. A general and somewhat rigorous analysis {{for the evaluation of}} the joint probability on a pair of opposite hops has been performed, which is valid for any frequency. The total rain outage performance has been shown explicitly to be given approximately by the summation of joint probabilities on pair hops of the diversity system. A general and <b>compact</b> <b>algorithm</b> for the evaluation of the path length enlargement effect has been constructed which is valid for any frequency, above 10 GHz and single hop-length of the corresponding tandem system...|$|R
40|$|This paper proposes {{the compact}} {{differential}} evolution (cDE) algorithm. cDE, like other <b>compact</b> evolutionary <b>algorithms,</b> does not process {{a population of}} solutions but its statistic description which evolves similarly to all the evolutionary algorithms. In addition, cDE employs the mutation and crossover typical of differential evolution (DE) thus reproducing its search logic. Unlike other <b>compact</b> evolutionary <b>algorithms,</b> in cDE, the survivor selection scheme of DE can be straightforwardly encoded. One important feature of the proposed cDE algorithm is the capability of efficiently performing an optimization process despite a limited memory requirement. This fact makes the cDE algorithm suitable for hardware contexts characterized by small computational power such as micro-controllers and commercial robots. In addition, due to its nature cDE uses an implicit randomization of the offspring generation which corrects and improves the DE search logic. An extensive numerical setup has been implemented {{in order to prove}} the viability of cDE and test its performance with respect to other modern <b>compact</b> evolutionary <b>algorithms</b> and state-of-the-art population-based DE algorithms. Test results show that cDE outperforms on a regular basis its corresponding population-based DE variant. Experiments have been repeated for four different mutation schemes. In addition cDE outperforms other modern <b>compact</b> <b>algorithms</b> and displays a competitive performance with respect to state-of-the-art population-based algorithms employing a DE logic. Finally, the cDE is applied to a challenging experimental case study regarding the on-line training of a nonlinear neuralnetwork-based controller for a precise positioning system subject to changes of payload. The main peculiarity of this control application is that the control software is not implemented into a computer connected to the control system but directly on the micro-controller. Both numerical results on the test functions and experimental results on the real-world problem are very promising and allow us to think that cDE and future developments can be an efficient option for optimization in hardware environments characterized by limited memory...|$|R
40|$|In this letter, a new {{optimization}} <b>algorithm,</b> the Modified <b>compact</b> Genetic <b>Algorithm</b> (M-cGA) {{is introduced}} {{and applied to}} the synthesis of thinned arrays. The M-cGA has been derived from the <b>compact</b> Genetic <b>Algorithm</b> (cGA), properly modified and improved by implementing more than one probability vector (PV) and adding suitable learning scheme between these PVs. The so-obtained algorithm {{has been applied to}} the optimized synthesis of different-size linear and planar thinned arrays: In all the considered cases, it outperforms not only the cGA, but also the other optimization schemes previously applied to this kind of problem, both in terms of goodness of the solution (minimization of the peak sidelobe level) and of computational cost...|$|R
