4583|599|Public
25|$|Personnel {{selection}} {{procedures are}} usually validated, i.e., {{shown to be}} job relevant to personnel selection, using {{one or more of}} the following types of validity: <b>content</b> <b>validity,</b> construct validity, and/or criterion-related validity. I/O psychologists must adhere to professional standards in personnel selection efforts. SIOP (e.g., Principles for validation and use of personnel selection procedures) and APA together with the National Council on Measurement in Education (e.g., Standards for educational and psychological testing are sources of those standards. The Equal Employment Opportunity Commission's Uniform guidelines are also influential in guiding personnel selection decisions.|$|E
25|$|There are {{a number}} of {{different}} forms of validity. Criterion-related validity can be assessed by correlating a measure with a criterion measure theoretically expected to be related. When the criterion measure is collected {{at the same time as}} the measure being validated the goal is to establish concurrent validity; when the criterion is collected later the goal is to establish predictive validity. A measure has construct validity if it is related to measures of other constructs as required by theory. <b>Content</b> <b>validity</b> is a demonstration that the items of a test do an adequate job of covering the domain being measured. In a personnel selection example, test content is based on a defined statement or set of statements of knowledge, skill, ability, or other characteristics obtained from a job analysis.|$|E
50|$|In psychometrics, <b>content</b> <b>validity</b> (also {{known as}} logical validity) {{refers to the}} extent to which a measure {{represents}} all facets of a given construct. For example, a depression scale may lack <b>content</b> <b>validity</b> if it only assesses the affective dimension of depression but fails to take into account the behavioral dimension. An element of subjectivity exists in relation to determining <b>content</b> <b>validity,</b> which requires a degree of agreement about what a particular personality trait such as extraversion represents. A disagreement about a personality trait will prevent the gain of a high <b>content</b> <b>validity.</b>|$|E
5000|$|After this controversy, two symposia {{were held}} to discuss the thesis's <b>content</b> and <b>validity</b> : ...|$|R
40|$|COMPEL {{exists for}} the {{discussion}} {{and dissemination of}} computational and analytical methods in electrical and electronic engineering. The main emphasis of papers Is on methods and new techniques, or the application of existing techniques in a novel way. Whilst papers with immediate application to particular engineering problems are featured. so too are papers that form a basis for further development {{in the area of}} study. A double-blind review process ensures the <b>content’s</b> <b>validity</b> and relevance...|$|R
50|$|<b>Content</b> ValidityContent <b>validity</b> {{has been}} {{demonstrated}} by extensive research on all major aspects of achievement motivation. Expert ratings ensured that only relevant aspects are included. Additionally, confirmatory factor analysis shows a good fit of the model to theory.|$|R
5000|$|<b>Content</b> <b>validity</b> is {{different}} from face validity, which refers not to what the test actually measures, but to what it superficially appears to measure. Face validity assesses whether the test [...] "looks valid" [...] to the examinees who take it, the administrative personnel who decide on its use, and other technically untrained observers. <b>Content</b> <b>validity</b> {{requires the use of}} recognized subject matter experts to evaluate whether test items assess defined content and more rigorous statistical tests than does the assessment of face validity. <b>Content</b> <b>validity</b> is most often addressed in academic and vocational testing, where test items need to reflect the knowledge actually required for a given topic area (e.g., history) or job skill (e.g., accounting). In clinical settings, <b>content</b> <b>validity</b> refers to the correspondence between test items and the symptom content of a syndrome.|$|E
5000|$|One {{widely used}} method of {{measuring}} <b>content</b> <b>validity</b> {{was developed by}} C. H. Lawshe. It is essentially a method for gauging agreement among raters or judges regarding how essential a particular item is. Lawshe (1975) proposed {{that each of the}} subject matter expert raters (SMEs) on the judging panel respond to the following question for each item: [...] "Is the skill or knowledge measured by this item 'essential,' 'useful, but not essential,' or 'not necessary' to the performance of the construct?" [...] According to Lawshe, if more than half the panelists indicate that an item is essential, that item has at least some <b>content</b> <b>validity.</b> Greater levels of <b>content</b> <b>validity</b> exist as larger numbers of panelists agree that a particular item is essential. Using these assumptions, Lawshe developed a formula termed the <b>content</b> <b>validity</b> ratio: ...|$|E
5000|$|... <b>content</b> <b>validity</b> may {{refer to}} {{symptoms}} and diagnostic criteria; ...|$|E
5000|$|In the 1970s {{there was}} growing debate between theorist {{who began to}} see {{construct}} validity as the dominant model pushing towards a more unified theory of validity and those who continued to work from multiple validity frameworks. [...] Many psychologists and education researchers saw [...] "predictive, concurrent, and <b>content</b> <b>validities</b> as essentially ad hoc, construct validity was the whole of validity from a scientific point of view" [...] In the 1974 version of The Standards for Educational and Psychological Testing the inter-relatedness of the three different aspects of validity was recognized: [...] "These aspects of validity can be discussed independently, but only for convenience. They are interrelated operationally and logically; only rarely {{is one of them}} alone important in a particular situation".|$|R
50|$|While historians {{agree about}} {{most of the}} hard facts {{of the history of}} the pact, that is not the case of the content and {{interpretation}} of the treaty. Both sides agree that the treaty was oriented against Chile but differ in how much Chile knew about the existence, <b>content,</b> and <b>validity</b> of the Treaty.|$|R
40|$|Background. The “Patterns of Activity Measure” (POAM-P) is a self-administered {{questionnaire}} that assesses “avoidance”, “pacing” and “overdoing” activity patterns in chronic pain patients. Objectives. To adapt the POAM-P to French (“POAM-P/F”) and test its {{validity and reliability}} in Chronic Musculo-Skeletal Pain patients (CMSP). Methods. We followed the recommended procedure for translation of questionnaires. Five hundred and ninety five inpatients, admitted to a tertiary rehab center in the French-speaking part of Switzerland for chronic pain after orthopedic trauma, were included (sex ratio M/F = 4. 36, mean age 43 ± 12). Face, <b>content</b> and criterion <b>validities,</b> internal consistency and reliability were assessed. Data included: TAMPA Scale for Kinesiophobia (TSK), Chronic Pain Coping Inventory (CPCI), Pain Catastrophizing Scale (PCS), Brief Pain Inventory (BPI), Hospital Anxiety and Depression Scale (HADS). Results. Face and <b>content</b> <b>validities</b> were checked during the translation process. Correlations between POAM-P/F-avoidance and TSK, POAM-P/F-pacing and CPCI-pacing, POAM-P/F-overdoing and CPCI-task persistence were highly significant (r> 0. 3, p 0. 8) and test-retest reliability (Intraclass Correlation Coefficients > 0. 8). They correlated very differently with the other scales. Discussion and Conclusion. The three POAM-P/F subscales clearly assess different behaviors in CMSP. The POAM-P/F is a suitable questionnaire for classifying French speaking CMSP into avoiders, pacers or overdoers...|$|R
5000|$|... where [...] <b>content</b> <b>validity</b> ratio, [...] {{number of}} SME panelists {{indicating}} [...] "essential", [...] {{total number of}} SME panelists. This formula yields values which range from +1 to -1; positive values indicate that {{at least half the}} SMEs rated the item as essential. The mean CVR across items may be used as an indicator of overall test <b>content</b> <b>validity.</b>|$|E
50|$|Linguistic {{validation}} is {{the process}} of investigating the reliability, conceptual equivalence, and <b>content</b> <b>validity</b> of translations of patient-reported outcome (PRO) measures.|$|E
50|$|A {{comprehensive}} linguistic {{validation process}} including cognitive debriefing {{is vital to}} demonstrate <b>content</b> <b>validity</b> in translations {{for use in a}} U.S. Food and Drug Administration (FDA) submission.|$|E
30|$|Fit {{statistics}} and reliability analysis, {{principal component analysis}} of Rasch residuals, {{and the results of}} differential item functioning supported the hypothesized structure of the Qiyas for L 1 Arabic language test. However, the results of a person-item map analysis suggested that the <b>content</b> aspect <b>validity</b> of the Qiyas for L 1 Arabic language test lacked representation to some extent.|$|R
40|$|Official {{regulations}} {{with regard}} to medical fitness to drive ignore important scientific research findings. In particular, {{although it has been}} shown that there is a gray zone where fitness to drive is less dependent on the severity of specific impairments than on compensatory functions, skills and technical aids, insufficient emphasis is placed on on-road and driving simulator methods for testing fitness to drive. An advantage of including compensation skills in the assessment of fitness to drive is that there is a logical connection between assessment and the development of driver rehabilitation methods. However, compared to traditional medical and psychological assessment of fitness to drive, on-road and simulator tests suffer from limited standardization and a lack of knowledge about the <b>contents,</b> <b>validity</b> and reliability of the test drives. A scientifically based and rehabilitation-oriented approach to fitness to drive and promotion of multidisciplinary scientific research in this area is recommended. (Author/publisher...|$|R
40|$|Aim: To {{develop an}} Australian nursing {{documentation}} in aged care (Quality of Australian Nursing Documentation in Aged Care (QANDAC)) instrument {{to measure the}} quality of paper-based and electronic resident records. Methods: The instrument {{was based on the}} nursing process model and on three attributes of documentation quality identified in a systematic review. The development process involved five phases following approaches to designing criterion-referenced measures. The face and <b>content</b> <b>validities</b> and the inter-rater reliability of the instrument were estimated using a focus group approach and consensus model. Results: The instrument contains 34 questions in three sections: completion of nursing history and assessment, description of care process and meeting the requirements of data entry. Estimates of the validity and inter-rater reliability of the instrument gave satisfactory results. Conclusion: The QANDAC instrument has a potential as a useful audit tool for the purposes of quality improvement and research in aged care documentation...|$|R
50|$|<b>Content</b> <b>validity</b> {{refers to}} how {{comprehensively}} the measure assesses the underlying construct that it claims to assess. As an example, let's {{look at a}} job interview for a position as a banker. This measure would have low <b>content</b> <b>validity</b> if it assessed whether the candidate was comfortable talking to many different people but not whether they were comfortable with math, because the candidate {{would not have been}} thoroughly evaluated on every facet of being a banker. The measure didn't cover the full breadth of what the job requires.|$|E
5000|$|Face {{validity}} is {{very closely}} related to <b>content</b> <b>validity.</b> While <b>content</b> <b>validity</b> depends on a theoretical basis for assuming if a test is assessing all domains of a certain criterion (e.g. does assessing addition skills yield in a good measure for mathematical skills? To answer this you have to know, what different kinds of arithmetic skills mathematical skills include) face validity relates to whether a test {{appears to be a}} good measure or not. This judgment is made on the [...] "face" [...] of the test, thus it can also be judged by the amateur.|$|E
5000|$|There {{are also}} a number of psychometric (statistical) {{strengths}} of the PAI, importantly including <b>content</b> <b>validity</b> and discriminant validity (for a detailed review of the PAI and its validity, see.) ...|$|E
40|$|Background: This study {{developed}} and validated a questionnaire {{to measure the}} sexual health of patients with spinal cord injuries (SCI). Materials and Methods: This was a cross-sectional study conducted at the Brain and Spinal Injury Research Center (BASIR), Tehran, Iran. Extensive review of literature, expert opinions, and encounters with SCI patients were used to develop and validate the questionnaires. There were 40 (32 males, 8 females) patients with SCI that presented for treatment at BASIR who enrolled in the study. Participants completed the questionnaires while they were admitted for medical care and during treatment follow-up visits. Participants completed the questionnaires twice, at a 2 - 4 week interval. Reliability testing for each measure was performed separately. Cronbach’s alpha was used for internal consistency and test-retest was used for reliability. Results: An expert committee approved the face and <b>content</b> <b>validities</b> of the ques-tionnaires, Internal consistency of our questionnaires, was acceptable according to Cronbach’s alpha that ranged from 0. 73 for the sexual activity measure to 0. 90 fo...|$|R
30|$|An anonymous, self-administered {{questionnaire}} {{was developed by}} a multidisciplinary study panel consisting of physicians, epidemiologists, a media expert, and a pharmacoepidemiologist with business experience in pharmacovigilance activities at a pharmaceutical company. In this survey, safety risk communication {{was defined as the}} exchange of drug information regarding safety risks by pharmaceutical companies with the aim of ensuring the rational use of drugs in practical clinical settings. Three operational domains related to safety risk communication were identified, namely contents, targets, and measures, and question items for each were developed by expert discussion. The questionnaire also enquired about background information of companies and respondents. The draft {{questionnaire was}} reviewed for face and <b>content</b> <b>validities</b> before finalization by an independent senior pharmacovigilance executive at a pharmaceutical company, and by the chairman of the Post-Marketing Surveillance (PMS) Subcommittee of the Drug Evaluation Committee of the JPMA. The final contents of the survey questionnaire were also reviewed and approved by the Subcommittee Chairman and by the Subcommittee Secretariat Officer regarding the protection of anonymity and confidentiality (Additional file 1).|$|R
30|$|Although many {{publications}} have sufficiently {{demonstrated that}} both virtual reality and box models are efficient for training laparoscopic skills, {{and that they}} have face, <b>content</b> and construct <b>validity,</b> their concurrent and predictive validity remains largely unknown and demands further studies.|$|R
5000|$|... {{allows for}} a {{referrals}} nominations strategy that, in certain cases, could improve response rates, while the nominations strategy acts as an ultimate validation of expertise for informants and therefore improves <b>content</b> <b>validity.</b>|$|E
50|$|A {{test has}} <b>content</b> <b>validity</b> built into it by careful {{selection}} of which items to include (Anastasi & Urbina, 1997). Items are chosen {{so that they}} comply with the test specification which is drawn up through a thorough examination of the subject domain. Foxcroft, Paterson, le Roux & Herbst (2004, p. 49) note that by using {{a panel of experts}} to review the test specifications and the selection of items the <b>content</b> <b>validity</b> of a test can be improved. The experts will be able to review the items and comment on whether the items cover a representative sample of the behaviour domain.|$|E
50|$|The Western Aphasia Battery {{has high}} {{validity}} and reliability. These measures include high test-retest reliability, inter and intra-judge reliability, face and <b>content</b> <b>validity,</b> and construct validity. High scores correlate with good functional communication skills in stroke patients with aphasia.|$|E
40|$|AbstractThe study {{investigated}} personal decision making about sex among men in Nigeria so as attitude of men towards HIV prevention. The study utilized a field survey to collect primary data. A total of 150 men whose ages were between 20 and 45 years {{and who were}} undergraduate students of the University of Ado-Ekiti were sampled for the study. The sample was selected using simple random sampling technique. Data for the study was collected using a self-constructed instrument titled (HIVDM). The methods used in validating the instrument were face and <b>content</b> <b>validities.</b> A test re-test method of establishing reliability was used. The reliability co-efficient was 0. 80. The statistical techniques used were frequency counts, percentages and Pearson product Movement Correlation method. The result of the findings shows that knowledge of HIV/AIDS will not be significantly related to personal decision making concerned with HIV/AIDS prevention among men. There was no significant relationship between HIV preventing behaviour {{and the fact that}} someone has seen an individual who died of HIV/AIDS before. The study recommended among other things that counsellors should encourage men to make responsible and careful decision about their sexual lives...|$|R
40|$|No sponsorships or {{competing}} interests have been disclosed for this article. Objective. To assess the face, <b>content,</b> and construct <b>validities</b> of a low-cost sinus surgery task trainer in acquisition of skills for endoscopic sinus surgery. Study Design. Prospective validation study. Setting. Tertiary academic center...|$|R
40|$|Purpose: The {{purpose of}} this study was to examine the psychometric {{properties}} of the Children's Somatization Inventory (CSI) in Turkish schoolchildren and adolescents. Methods: The CSI was translated using translation and back-translation. The participants were 813 schoolchildren, adolescents and their parents (n= 453). <b>Content</b> and construct <b>validity</b> were assessed to test the validity of the CSI- 24. Internal consistency reliability, interrater reliability (child-parent agreement) and test-retest reliability were assessed to test the reliability of the CSI- 24. Results: Psychometric analyses of the Turkish version of the CSI- 24 indicate high reliability and good <b>content</b> and construct <b>validity.</b> Conclusion: The Turkish version of the CSI- 24 is a useful instrument for measuring self-reported somatic complaints in Turkish schoolchildren and adolescents between the ages of 9 and 15...|$|R
50|$|The {{items in}} the QLDS were derived from {{statements}} made in qualitative interviews by 30 depressed or recently recovered patients. Further interviews were held with patients {{in order to assess}} whether the proposed scale had face and <b>content</b> <b>validity.</b>|$|E
5000|$|The {{tests have}} high <b>content</b> <b>validity</b> {{with respect to}} the subjectspeciﬁc {{curriculum}} for the particular grade level in the State of Michigan. Theparticipation at MEAP testing sessions is mandatory for all public school students. (Journal of Vocational Behavior 60, 178-198 (2002) ...|$|E
50|$|Validity is {{concerned}} with {{different aspects of the}} measurement process.Each of these types uses logic, statistical verification or both to determine the degree of validity and has special value under certain conditions. Types of validity include <b>content</b> <b>validity,</b> predictive validity, and construct validity.|$|E
40|$|Qualitative {{research}} has highlighted the complex interplay of multiple factors that preclude persons with schizophrenia in rural Indian settings for discontinued psychiatric treatment. In this context, this paper aims {{to establish the}} face and <b>content</b> <b>validities</b> of an interview schedule titled „Schedule of Factors Influencing Adherence (SOFIA) to Psychiatric Treatment in Persons with Schizophrenia‟ which comprehensively assesses factors for discontinued psychiatric treatment and the feasibility of its administration of the schedule. SOFIA contains 16 factors. This schedule involves three phases of interviewing patients and family members. This was given to twelve experts who used likert scales to rate each items wells as {{the dimensions of the}} schedule. Later on, fifteen persons with schizophrenia were interviewed with SOFIA to test the feasibility of administration. The results showed that Fourteen items were rated as either satisfactory (score= 4) or very much satisfactory (score= 5) by all twelve experts; remaining two were rated as 4 or 5 by 11 experts. Regarding comprehensiveness of the factors, scoring methods and general instructions given to the interviewers, all provided scores > 4; regarding method of interviewing, 11 provided score of > 4; with regard to overall interview schedule, all experts provided scores > 4. Pilot testing revealed that it took 60 minutes to administer SOFIA...|$|R
40|$|This paper {{presents}} {{findings from}} the validation of a survey instrument constructed in response to what Indigenous parents/carers and students believe constitutes culturally responsive pedagogies that positively influence Indigenous student learning. Characteristics of culturally responsive pedagogies established through interviews with Australian Indigenous parents, community members and students generated themes which were distilled into survey items {{by a team of}} Indigenous and other educators. The instrument was then put on trial with 141 teachers for statistical validation. Analyses employing the Rasch model confirmed that the instrument measured a unidimensional latent trait: culturally responsive pedagogy. Seven subscales, <b>content</b> <b>validities</b> of which were determined by a panel of experts, were also confirmed. Results highlighted differences between primary and secondary teachers’ self-reported practice, and important facets of teacher pedagogy in the two different school contexts emerged. Analyses of four of the subscales of the instrument—Indigenous cultural value, self‐regulation support, literacy teaching and explicitness—are presented in the context of current emphases on quality teaching and Indigenous student outcomes. The instrument can be used to measure teachers’ nuances in pedagogy, and the resulting teacher profiles can be used to assist teachers to focus on particular aspects of their pedagogy {{to meet the needs of}} their students...|$|R
40|$|An {{important}} {{strand of}} research on cognitive trait organization is connected with Peabody’s (1967) tetradic model stressing two non-evaluative dimensions: tight–loose and assertive–unassertive. The relationship of this model with the communion/agency model involving two evaluative dimensions is discussed and empirically investigated. It is shown that the models are orthogonally related suggesting four trait categories: agentic tight–loose, communal tight–loose, agentic assertive–unassertive and communal assertive–unassertive. Implications are discussed regarding the interpretation of stereotype <b>contents,</b> the <b>validity</b> of the tetradic and communion/agency models {{and the development of}} a functionalist approach of social perception and judgment. status: publishe...|$|R
