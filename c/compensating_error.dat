12|1199|Public
50|$|An error {{amplifier}} is {{most commonly}} encountered in feedback unidirectional voltage control circuits, where the sampled output voltage of the circuit under control, is fed back and {{compared to a}} stable reference voltage. Any {{difference between the two}} generates a <b>compensating</b> <b>error</b> voltage which tends to move the output voltage towards the design specification.|$|E
50|$|Rodney David Wingfield {{was born}} in Hackney, east London in 1928. He was educated at the Coopers' Company School and during the Second World War was {{evacuated}} to Frome, Somerset. Wingfield was exempted from National Service due to poor eyesight and had various office jobs in the East End before joining the Petrofina oil company. His first radio play, <b>Compensating</b> <b>Error</b> was accepted by the BBC in 1968 and two more were then commissioned, at which point Wingfield resigned from his job. His radio plays are discussed at ukonline. Wingfield's radio plays are always clever, with crisp often acerbic dialogue, having well-defined characters and action that intrigues. After hooking the listener he often leads them astray with his trademark tricks, twists and surprises.|$|E
40|$|Abstract. The {{algorithms}} and {{the applications}} of UKF filtering of UAV MEMS Gyro based on time-series model {{are presented in}} this paper. First Gyro output signals are preprocessed and modeled by time-series analysis theory, and then use UKF filtering method to <b>compensating</b> <b>error</b> based on the time-series model. Examples with actual experiment demonstrate that the method has apparent superiority. The simulation result shows that, both in static and dynamic cases, after eliminate the precision error MEMS gyro accuracy can achieve the miniature UAV standards...|$|E
5000|$|Andersen, Kirsti (2011) [...] "One of Berkeley's {{arguments}} on <b>compensating</b> <b>errors</b> in the calculus", Historia Mathematica 38(2): 219-231.|$|R
50|$|<b>Compensating</b> <b>errors</b> are {{multiple}} unrelated errors that would individually {{lead to an}} imbalance, but together cancel each other out.|$|R
40|$|We {{present a}} method to {{construct}} high-fidelity quantum phase gates, which are insensitive to errors in various experimental parameters. The phase gates consist {{of a pair of}} two sequential broadband composite pulses, with a phase difference π+α/ 2 between them, where α is the desired gate phase. By using composite pulses which <b>compensate</b> systematic <b>errors</b> in the pulse area, the frequency detuning, or both the area and the detuning, we thereby construct composite phase gates which <b>compensate</b> <b>errors</b> in the same parameters. Particularly interesting are phase gates which use the recently discovered universal composite pulses, which <b>compensate</b> systematic <b>errors</b> in any parameter of the driving field, which keep the evolution Hermitian (e. g., pulse amplitude and duration, pulse shape, frequency detuning, Stark shifts, residual frequency chirps, etc. Comment: 5 pages, 4 figure...|$|R
40|$|An {{investigation}} was undertaken {{to study the}} factors which cause grossly elevated values in an automated procedure for chloride when the sample is contaminated with bromide. The questioned mercuric thiocyanate method of the autoanalyzer was compared to a similar system utilizing mercuric 2, 4, 6 -tripyridyl-s-triazine as a substitute ligand source in the chloride exchange system. It was determined that variation {{in the rate of}} dialysis of the halides was one factor which provided a <b>compensating</b> <b>error</b> apparently owing to a graded increase in rate of diffusion with an increase in hydrated ion size. The variable release of thiocyanate by the different halides as compared to the equivalent release of ligand from the tripyridyl-s-triazine (TPTZ) complex by the halides was another important factor. When both factors were considered, the non-linear elevated results could at least be partially explained. Es wurden die Faktoren untersucht, die bei der automatischen Chloridbestimmung in Gegenwart von Bromid die erheblich erhöhten Werte verursachen. Die unter Gebrauch von Autoanalysatoren in Frage kommende Quecksilberthiocyanatmethode wurde mit einer ähnlichen Methode verglichen, die Quecksilber- 2, 4, 6 -Tripyridyl-S-Triazin als Bindemittel im Chloridaustauschsystem verwendet...|$|E
40|$|This paper {{investigates the}} problem of {{cooperative}} path following for a fleet of underactuated autonomous underwater vehicles (AUVs) with uncertain nonlinear dynamics. Path following controllers for individual AUVs are developed to ensure that each AUV converges to the desired position. The coordination mission is completed by reaching synchronization on a suitably defined path variable, even {{in the presence of}} partial knowledge of the reference speed. The key features of the proposed cooperative path following design scheme can be summarized as follows. First, the command filter design technique based cooperative path following control strategy is derived by introducing <b>compensating</b> <b>error</b> signals to remove the requirement of the higher derivative of reference signal, and a simplified cooperative path following controller is proposed. Second, a smoothly switching function is designed to yield neural network (NN) based energy-efficient controller. Third, by designing the distributed speed estimator, the global knowledge of the reference speed is relaxed. Finally, all the signals in the closed-loop system are guaranteed to be globally uniformly ultimately bounded (GUUB) under the proposed algorithm, and the path following error is proven to converge to a small neighborhood of the origin. Simulation example is provided to validate the performance of the control strategy...|$|E
40|$|This study {{explores the}} {{opportunities}} created by subjecting {{a system of}} interacting fast-acting parameter-izations to long-term single-column model evaluation against multiple independent measurements at a per-manent meteorological site. It is argued that constraining the system at multiple key points facilitates the tracing and identification of compensating errors between individual parametric components. The extended time range of the evaluation helps to enhance the statistical significance and representativeness of the single-column model result, which facilitates the attribution of model behavior as diagnosed in a general circulation model to its subgrid parameterizations. At the same time, the high model transparency and computational efficiency typical of single-column modeling is preserved. The method is illustrated by investigating {{the impact of a}} model change in the Regional Atmospheric Climate Model (RACMO) on the representation of the coupled boundary layer–soil system at the Cabauw meteorological site in the Netherlands. A set of 12 relevant variables is defined that covers all involved processes, including cloud structure and amplitude, radiative transfer, the surface energy budget, and the thermodynamic state of the soil and various heights of the lower atmosphere. These variables are either routinely measured at the Cabauw site or are obtained from continuous large-eddy simulation at that site. This 12 -point check proves effective in revealing the existence of a <b>compensating</b> <b>error</b> between cloud structure and radiative transfer, residing in the cloud overlap assumption. In this exercise, the application of conditional sampling proves a valuable tool in establishing which cloud regime exhibits the biggest impact. 1...|$|E
5000|$|Gray coding <b>compensates</b> for <b>errors</b> on rotary {{encoders}} and linear encoders.|$|R
40|$|CNC {{grinding}} controls {{now offer}} {{a wide range}} of customized functions. To meet the exacting demands of grinding accuracy, a number of errors resulting from the grinding and dressing process need to be compensation system for a family of CNC grinder controls. Besides spindle lead errors, this method can also used to <b>compensate</b> <b>errors</b> due to dresser wear...|$|R
60|$|The {{theory of}} the {{mechanic}} forces is another example. What we gain in power is lost in time, and the converse. The periodic or <b>compensating</b> <b>errors</b> of the planets is another instance. The influences of climate and soil in political history are another. The cold climate invigorates. The barren soil does not breed fevers, crocodiles, tigers or scorpions.|$|R
30|$|At present, {{the thermal}} error {{compensation}} has been intensively studied in precise CNC machine [3], yet few researches in the {{spherical plain bearing}} test benches. The existing researches only build the thermal error models, and do not compensate effectively the thermal errors. Zhou [4] built the thermal error compensation model of the spherical plain bearing test bench under the high temperature operating condition, but did not verify the fitting precision and the applicability of this model, nor compensated the thermal errors. Hu et al. [5] made a comprehensive compensating model for the wear-depth detecting system of the spherical plain bearing test bench based on the multi-body kinematics and verified its accuracy by FEM, but didn’t compensate the thermal errors, either. Li et al. [6], designed a wear-depth detecting module with a mechanical compensating device, which can online compensate the thermal errors caused by varying environmental temperatures, but still not verified the compensation efficiency of this method in the experiment. Relevant researches of CNC machine {{can be used on}} thermal compensating method, bringing in software-based <b>compensating</b> <b>error</b> method. In other words, {{on the basis of the}} thermal deformation analysis, the mathematical compensating model of the thermal errors is built, and then the thermal deformation is predicted in the control system. At last, the thermal errors are compensated in real time [7, 8]. In this process, many mathematical methods are used for the thermal error modeling, such as, regression analysis method [9], FEM, neural networks [10], time series analysis [11], screw theory, fuzzy theory [12], grey theory [13], support vector machine [14], genetic algorithm [15], ant colony algorithm [16].|$|E
40|$|Model {{simulation}} {{and control}} of pumped storage unit (PSU) are essential to improve the dynamic quality of power station. Only under {{the premise of the}} PSU models reflecting the actual transient process, the novel control method can be properly applied in the engineering. The contributions of this paper are that (1) a real-time accurate equivalent circuit model (RAECM) of PSU via error compensation is proposed to reconcile the conflict between real-time online simulation and accuracy under various operating conditions, and (2) an adaptive predicted fuzzy PID controller (APFPID) based on RAECM is put forward to overcome the instability of conventional control under no-load conditions with low water head. Respectively, all hydraulic factors in pipeline system are fully considered based on equivalent lumped-circuits theorem. The pretreatment, which consists of improved Suter-transformation and BP neural network, and online simulation method featured by two iterative loops are synthetically proposed to improve the solving accuracy of the pump-turbine. Moreover, the modified formulas for <b>compensating</b> <b>error</b> are derived with variable-spatial discretization to improve the accuracy of the real-time simulation further. The implicit RadauIIA method is verified to be more suitable for PSUGS owing to wider stable domain. Then, APFPID controller is constructed based on the integration of fuzzy PID and the model predictive control. Rolling prediction by RAECM is proposed to replace rolling optimization with its computational speed guaranteed. Finally, the simulation and on-site measurements are compared to prove trustworthy of RAECM under various running conditions. Comparative experiments also indicate that APFPID controller outperforms other controllers in most cases, especially low water head conditions. Satisfying results of RAECM have been achieved in engineering and it provides a novel model reference for PSUGS...|$|E
40|$|We {{present a}} {{detailed}} analysis of the ENSO atmospheric feedbacks in a perturbed atmospheric physics ensemble with the Kiel Climate Model (KCM) and for the CMIP 5 data base. We further untangle the interaction between perturbed physics and the mean state differences in the KCM ensemble by conducting additional atmospheric only simulations. The results show that the atmospheric part of the amplifying Bjerknes Feedback (the zonal wind feedback) and the net heat flux damping feedback are strongly, linearly linked with each other via the mean state sea surface temperature (SST) and perturbed model physics play only a minor role. In observations, strong wind and heat flux feedbacks are caused by a convective response in the Niño 4 region during ENSO events, resulting from an eastward shift of the raising branch of the Walker Circulation during El Niño (vice versa for La Niña). Coupled General Circulation Models (CGCM), with an equatorial SST cold bias in the Niño 4 region and accompanied La Niña-like mean state, yield a too westward raising branch of the Walker Circulation (by up to 30 ◦) and hence only a weak convective response, explaining the too weak wind and heat flux feedback. Thus the position of Walker Circulation determines the strength of the wind and heat flux feedback and explains the <b>compensating</b> <b>error</b> between these two feedbacks, seen in KCM and many CGCM of the CMIP 5 data base. Furthermore, improved atmospheric feedbacks lead to a substantial improvement of important ENSO properties as phase locking of ENSO to the annual cycle and asymmetry between El Niño and La Niña. In order to successfully represent atmospheric ENSO dynamics in CGCM a correct mean state of the Walker Circulation is important and this serves as an explanation for the too diverse simulated ENSO in current CGCM...|$|E
30|$|Inspection of (7) and (8) {{shows that}} the HC and RC have been {{modelled}} as having the same errors. That {{is due to the}} fact that they are identical channels of the same receiver, and therefore they share common receiver errors and approximately equal atmospheric errors. Therefore, errors tracked during the HC synchronisation can be used to <b>compensate</b> <b>errors</b> in the RC.|$|R
40|$|Systematic and <b>compensating</b> <b>errors</b> {{can lead}} to {{degraded}} predictive skill in climate models. Such errors may be identified by comparing different models {{in an analysis of}} individual physical processes. We examine model simulations of El Niño–Southern Oscillation (ENSO) in five Coupled Model Intercomparison Project (CMIP) models, using transfer functions to analyze nine processes critical to ENSO's dynamics. The input and output of these processes are identified and analyzed, some of which are motivated by the recharge oscillator theory. Several <b>errors</b> and <b>compensating</b> <b>errors</b> are identified. The east-west slope of the equatorial thermocline is found to respond to the central equatorial Pacific zonal wind stress as a damped driven harmonic oscillator in all models. This result is shown to be inconsistent with two different formulations of the recharge oscillator. East Pacific sea surface temperature (SST) responds consistently to changes in the thermocline depth in the eastern Pacific in the five CMIP models examined here. However, at time scales greater than 2 years, this consistent model response disagrees with observations, showing that the SST leads thermocline depth at long time scales. <b>Compensating</b> <b>errors</b> are present in the response of meridional transport of water away from the equator to SST: two different models show different response of the transport to off-equatorial wind curl and wind curl response to East Pacific SST. However, these two models show the same response of meridional transport to East Pacific SST. Identification of errors in specific physical processes can hopefully lead to model improvement by focusing model development efforts on these processes...|$|R
5000|$|... e.g. Known word pronunciations {{or legal}} word sequences, which can <b>compensate</b> for <b>errors</b> or {{uncertainties}} at lower level; ...|$|R
40|$|The {{quality factor}} used in {{radiation}} protection {{is defined as}} a function of LET, Q(sub ave) (LET). However, tissue equivalent proportional counters (TEPC) measure the average quality factors as a function of lineal energy (y), Q(sub ave) (Y). A model of the TEPC response for charged particles considers energy deposition as a function of impact parameter from the ion s path to the volume, and describes the escape of energy out of sensitive volume by delta-rays and the entry of delta rays from the high-density wall into the low-density gas-volume. A common goal for operational detectors is to measure the average radiation quality to within accuracy of 25 %. Using our TEPC response model and the NASA space radiation transport model we show that this accuracy is obtained by a properly calibrated TEPC. However, when the individual contributions from trapped protons and galactic cosmic rays (GCR) are considered; the average quality factor obtained by TEPC is overestimated for trapped protons and underestimated for GCR by about 30 %, i. e., a <b>compensating</b> <b>error.</b> Using TEPC's values for trapped protons for Q(sub ave) (y), we obtained average quality factors in the 2. 07 - 2. 32 range. However, Q(sub ave) (LET) ranges from 1. 5 - 1. 65 as spacecraft shielding depth increases. The average quality factors for trapped protons on STS- 89 demonstrate that the model of the TEPC response is in good agreement with flight TEPC data for Q(sub ave) (y), and thus Q(sub ave) (LET) for trapped protons is overestimated by TEPC. Preliminary comparisons for the complete GCR spectra show that Q(sub ave) (LET) for GCR is approximately 3. 2 - 4. 1, while TEPC measures 2. 9 - 3. 4 for QQ(sub ave) (y), indicating that QQ(sub ave) (LET) for GCR is underestimated by TEPC...|$|E
40|$|Convection-permitting {{climate model}} are {{promising}} tools for improved representation of extremes, {{but the number}} of regions for which these models have been evaluated are still rather limited to make robust conclusions. In addition, an integrated interpretation of near-surface characteristics (typically temperature and precipitation) together with cloud properties is limited. The objective {{of this paper is to}} comprehensively evaluate the performance of a ‘state-of-the-art’ regional convection-permitting climate model for a mid-latitude coastal region with little orographic forcing. For this purpose, an 11 -year integration with the COSMO-CLM model at Convection-Permitting Scale (CPS) using a grid spacing of 2. 8 km was compared with in-situ and satellite-based observations of precipitation, temperature, cloud properties and radiation (both at the surface and the top of the atmosphere). CPS clearly improves the representation of precipitation, in especially the diurnal cycle, intensity and spatial distribution of hourly precipitation. Improvements in the representation of temperature are less obvious. In fact the CPS integration overestimates both low and high temperature extremes. The underlying cause for the overestimation of high temperature extremes was attributed to deficiencies in the cloud properties: The modelled cloud fraction is only 46 % whereas a cloud fraction of 65 % was observed. Surprisingly, the effect of this deficiency was less pronounced at the radiation balance at the top of the atmosphere due to a <b>compensating</b> <b>error,</b> in particular an overestimation of the reflectivity of clouds when they are present. Overall, a better representation of convective precipitation and a very good representation of the daily cycle in different cloud types were demonstrated. However, to overcome remaining deficiencies, additional efforts are necessary to improve cloud characteristics in CPS. This will be a challenging task due to compensating deficiencies that currently exist in ‘state-of-the-art’ models, yielding a good representation of average climate conditions. In the light of using the CPS models to study climate change it is necessary that these deficiencies are addressed in future research. status: publishe...|$|E
40|$|Error {{equivalence}} {{concerns the}} mechanism whereby different error sources result in identical deviation and variation patterns on part features. This could have dual effects on process variation reduction: it significantly increases {{the complexity of}} root cause diagnosis in process control, and provides an opportunity to use one error source as based error to compensate the others. There are fruitful research accomplishments on establishing error equivalence methodology, such as error equivalence modeling, and an error <b>compensating</b> <b>error</b> strategy. However, no {{work has been done}} on developing an efficient process design approach by investigating error equivalence. Furthermore, besides the process mean shift, process fault also manifests itself as variation increase. In this regard, studying variation equivalence may help to improve the root cause identification approach. This thesis presents engineering driven approaches for process design and control via embedding error equivalence mechanisms to achieve a better, insightful understanding and control of manufacturing processes. The first issue to be studied is manufacturing process design and optimization based on the error equivalence. Using the error prediction model that transforms different types of errors to the equivalent amount of one base error, the research derives a novel process tolerance stackup model allowing tolerance synthesis to be conducted. Design of computer experiments is introduced to assist the process design optimization. Secondly, diagnosis of multiple variation sources under error equivalence is conducted. This allows for exploration and study of the possible equivalent variation patterns among multiple error sources and the construction of the library of equivalent covariance matrices. Based on the equivalent variation patterns library, this thesis presents an excitation-response path orientation approach to improve the process variation sources identification under variation equivalence. The results show that error equivalence mechanism can significantly reduce design space and release us from considerable symbol computation load, thus improve process design. Moreover, by studying the variation equivalence mechanism, we can improve the process diagnosis and root cause identification...|$|E
25|$|Posidonius was {{informed}} in {{his approach to}} finding the Earth's circumference by Eratosthenes, who a century earlier used the elevation of the sun at different latitudes {{to arrive at a}} figure of 250,000 stadia, a result which he rounded to 252,000 so that it would be divisible by 60. Both men's figures for the Earth's circumference were uncannily accurate, aided in part in each case by mutually <b>compensating</b> <b>errors</b> in measurement.|$|R
40|$|Proposed {{reflecting}} telescope includes large, low-precision primary mirror stage and small, precise correcting mirror. Correcting mirror machined under computer control to <b>compensate</b> for <b>error</b> in primary mirror. Correcting mirror machined by diamond cutting tool. Computer analyzes interferometric measurements of primary mirror to determine shape of surface of correcting mirror needed to <b>compensate</b> for <b>errors</b> in wave front reflected from primary mirror and commands position and movement of cutting tool accordingly...|$|R
50|$|Posidonius was {{informed}} in {{his approach to}} finding the Earth's circumference by Eratosthenes, who a century earlier used the elevation of the sun at different latitudes {{to arrive at a}} figure of 250,000 stadia, a result which he rounded to 252,000 so that it would be divisible by 60. Both men's figures for the Earth's circumference were uncannily accurate, aided in part in each case by mutually <b>compensating</b> <b>errors</b> in measurement.|$|R
40|$|For {{the surface}} energy of jellium at alkali-metal densities, the local-density {{approximation}} (LDA) and more advanced density-functional methods disagree strongly with the wave-function-based Fermi hypernetted-chain and diffusion Monte Carlo methods. We present a wave-vector interpolation correction to the generalized gradient approximation which gives jellium surface energies consistent {{with two other}} estimates based on advanced density functionals. LDA makes <b>compensating</b> <b>errors</b> at intermediate and small wave vectors. Studies of small jellium clusters also support the density-functional estimate for the jellium surface energ...|$|R
40|$|This {{viewgraph}} presentation describes wavefront aberrations due to {{the alignment}} and improper compensation of the NASA James Webb Space Telescope. The contents include: 1) James Webb Space Telescope (JWST); 2) Optical design of JWST; 3) Alignment Observables for JWST; 4) Low order Zernike Polynomials; 5) PM SM Ability to Target Low Order Aberrations; 6) Compensator definitions and Modes; 7) Field impact from compensation; 8) PM align <b>error</b> <b>compensated</b> by PM figure; 9) PM align <b>error</b> <b>compensated</b> by SM alignment; 10) SM align <b>error</b> <b>compensated</b> by PM figure; 11) SM figure <b>error</b> <b>compensated</b> by SM alignment; 12) Worst Case Pupil Maps; 13) Worst Case Pupil Maps at BEST FOCUS; 14) Field impact from compensation (+/- 1 arcmin FOV); and 15) Concluding Remarks...|$|R
40|$|In this article, {{results of}} thermal error {{assessments}} are evaluated {{from a range}} of modern machine tools operating with active thermal compensation. The standard models assume a linear relationship between temperature and displacement and implementations address only a limited subset of error sources. However, significant residual errors were found on the analysed machines. The aim of this work is to improve the accuracy and increase the scope of <b>compensated</b> <b>errors,</b> without introducing onerous complexity, by using optimised linear correlation models applied to existing controllers...|$|R
5000|$|A {{reference}} station calculates differential corrections {{for its own}} {{location and}} time. Users may be up to 200 nautical miles (370 km) from the station, however, {{and some of the}} <b>compensated</b> <b>errors</b> vary with space: specifically, satellite ephemeris errors and those introduced by ionospheric and tropospheric distortions. For this reason, the accuracy of DGPS decreases with distance from the reference station. The problem can be aggravated if the user and the station lack [...] "inter visibility"—when they are unable to see the same satellites.|$|R
40|$|Nonlinear control {{algorithms}} to <b>compensate</b> for kinematic <b>error</b> in harmonic drives {{provide a}} solid basis {{to improve their}} performance of harmonic drives in precision positioning applications. The present closed loop control algorithms <b>compensate</b> for kinematic <b>error</b> irrespective of its form in both set-point and trajectory tracking applications...|$|R
50|$|Coastal {{managers}} must <b>compensate</b> for <b>error</b> {{and uncertainty}} in the information regarding the erosive processes. Video-based monitoring can collect data continuously and produce analyses of shoreline processes.|$|R
40|$|We {{refute the}} claim that {{previous}} works on the one-loop quantum mass of solitons had incorrectly dropped a surface term from a partial integration. Rather, the paper quoted in the title contains a fallacious derivation with two <b>compensating</b> <b>errors.</b> We also remark that the ϕ^ 2 cos^ 2 (ϕ^ 2) model considered in that paper does not have solitons at the quantum level because at two-loop order the degeneracy of the vacua is lifted. This may be remedied, however, by a supersymmetric extension. Comment: 6 pages LATEX 2 e, using elsart. cls, 1 figur...|$|R
40|$|Abstract. Working in {{a passive}} mode, {{the result of}} instability, slow {{convergence}} and low convergence precision were easy to appear when the underwater target is located by using Kalman filtering algorithm, so an adaptive Kalman filtering algorithm based on Doppler frequency was proposed. The algorithm estimated the statistical characteristics of the system process noise and measurement noise in real-time, dynamically <b>compensate</b> <b>error</b> caused by linearizing observation model, and reduce the bad impact by the observation error. Through the simulation, experiments show that the algorithm performs better in aspects of convergence precision and stability...|$|R
40|$|I {{agree with}} the authors of hep-th/ 0211149 that the claim made in Phys. Lett. B 542, 282 (2002) is {{incorrect}} and that the derivation of its main formula, although correct, contains two <b>compensating</b> <b>errors.</b> In this reply the main formula of Phys. Lett. B 542, 282 (2002) is rederived. This new derivation shows that not only the energy momentum cut off regularization method still works in the calculation of the soliton quantum mass corrections, but also that the so called mode number regularization emerges naturally from it. Comment: 4 pages, no figures, RevTe...|$|R
40|$|The new {{torque and}} flux {{controllers}} with constant switching frequency and low torque and flux ripples for direct torque control induction machine drives are presented. The core of these proposed controllers {{is based on}} the comparison between the <b>compensated</b> <b>error</b> signals with high frequency triangular waveforms, thus does not require complex calculation to generate the inverter switching signals. The controllers are therefore can be implemented using analog and/or digital circuits. Modeling and simulation of the new controllers are presented and the results show that the torque and flux ripples are reduced significan...|$|R
5000|$|By {{making the}} {{objective}} {{lens of the}} telescopic sight adjustable so the telescopic sight can <b>compensate</b> parallax <b>errors.</b> These models are often called AO or A/O models, for adjustable objective.|$|R
3000|$|... 3) In {{order to}} <b>compensate</b> the <b>error</b> {{caused by the}} {{linearization}} method, the compensation factor is proposed. The compensation factor, in respect to accurate short circuit currents, is updated in each iteration.|$|R
