9|1067|Public
40|$|Space-time trellis code designs mainly {{focus on}} maximizing the {{diversity}} and coding gains. However, {{the performance of a}} space-time <b>code</b> (<b>frame</b> or bit error) is also a function of its "distance spectrum". In this work, expurgated union bounds for frame and bit error probability using the distance spectrum are derived. An efficient distance spectrum computation method which uses a reduced error state diagram is proposed. Distance spectrum results for the best recently proposed codes are presented...|$|E
30|$|There are {{a number}} of {{powerful}} and efficient FEC schemes to recover from erasures and/or errors [4], such as low density parity check (LDPC) codes and tornado codes, which use bipartite graphs [2, 5]. Also, Reed Solomon (R-S) codes are used in many applications. However, the codewords in these codes are rather short, and this dictates the construction of the parity packets, which are usually visualized as arranging information packets row-wise and running the FEC code column-wise [6, 7]. An alternative to this is to use the turbo codes to construct the turbo <b>code</b> <b>frame,</b> and then split the frame into packets. This is only feasible in turbo codes because of the large size of the codewords [8].|$|E
40|$|Abstract: We {{propose a}} {{binarization}} method based pigment in the ZIP code of 24 bmp image simulation and digital identification by CCD sensors, were extracted the grid binary image of zip code box and {{message of the}} two characters binary image; analyze the image processing, which includes <b>code</b> <b>frame</b> edge detection and separation of the image binarization, denoising smoothing, tilt correction, the extraction code number, position, normalization processing, digital image thinning, character recognition feature extraction. Through testing, the recognition rate of this method can be over 90 %. The recognition time of characters for character is less than 1. 3 second, which means the method is of more effective recognition ability and can better satisfy the real system requirements...|$|E
30|$|For {{complexity}} {{control of}} the frame layer, {{it is important to}} maintain good rate distortion performance. In the proposed algorithm, we estimate the actual time saving of the <b>coded</b> <b>frame</b> by considering the difference between the normal coding time of the <b>coded</b> <b>frame</b> and the actual coding time. Then, the following strategies are adopted. (1) If the sum of the actual time saving of already <b>coded</b> <b>frames</b> is greater than the target time saving of the entire sequence, normal coding is carried out in time to avoid degradation of the rate distortion performance. (2) When the sum of actual time saving of the <b>coded</b> <b>frames</b> is less than the target time saving of the entire sequence, the remaining frames still need to be encoded under control. (3) When the actual time saving of the previous frame is much greater than the target time saving of the previous frame, the degree of {{control of the}} current frame needs to be reduced. Therefore, the current frame only uses the CSD method to save the coding time and achieve better rate distortion performance.|$|R
40|$|Genetic {{scale of}} reading frame cod-ing of usage of trinucleotide <b>codes.</b> Reading <b>frame</b> <b>coding</b> of the C 3 self-complementary {{circular}} code X. Genes with genetic information for reading <b>frame</b> <b>coding.</b> Genes of bacteria and plasmids {{with the highest}} efficiencies for reading <b>frame</b> <b>coding.</b> Gene evolution by coding...|$|R
50|$|In both cases, data {{is removed}} from the buffer in varying chunks, {{depending}} on the actual size of the <b>coded</b> <b>frames.</b>|$|R
40|$|Blog {{software}} {{is an important}} structural aspect of blogging practices, since the various functionalities built into the <b>code</b> <b>frame,</b> but not determine, actual use. It is also subject to ongoing change, either through innovations in the software itself, or through the (re-) combination of different tools. This working paper reports findings {{on the use of}} and the satisfaction with blogging software for the german-speaking blogosphere. By comparing users of stand-alone software and blogging software as well as comparing Wordpress users to users of different stand-alone systems, the study brings differences in the respective user bases to light, for example in regard to gender and age. The findings also show how changes in the technical base lead to different levels of satisfaction, with lack of functionalities being a major reason for changing the software. The paper concludes with a short outlook on possible future research that takes software as a defining characteristic of blogging practices into account but avoids fallacies of technological or social determinism...|$|E
40|$|Abstract. In Java 2 and Microsoft. NET Common Language Runtime (CLR), trusted code {{has often}} been {{programmed}} to perform accessrestricted operations not explicitly requested by its untrusted clients. Since an untrusted client {{will be on the}} call stack when access control is enforced, an access-restricted operation will not succeed unless the client is authorized. To avoid this, a portion of the trusted code can be made “privileged. ” When access control is enforced, privileged code causes the stack traversal to stop at the trusted <b>code</b> <b>frame,</b> and the untrusted code stack frames will not be checked for authorization. For large programs, manually understanding which portions of code should be made privileged is a difficult task. Developers must understand which authorizations will implicitly be extended to client code and make sure that the values of the variables used by the privileged code are not “tainted” by client code. This paper presents an interprocedural analysis for Java bytecode to automatically identify which portions of trusted code should be made privileged, ensure that there are no tainted variables in privileged code, and detect “unnecessary ” and “redundant ” privileged code. We implemented the algorithm and present the results of our analyses on a set of large programs. While the analysis techniques are in the context of Java code, the basic concepts are also applicable to non-Java systems with a similar authorization model...|$|E
40|$|We {{explore the}} {{application}} of supervised machine learning (SML) to frame coding. By automating the coding of frames in news, SML facilitates the incorporation of large-scale content analysis into framing research, even if financial resources are scarce. This furthers a more integrated investigation of framing processes conceptually as well as methodologically. We conduct several experiments in which we automate the coding of four generic frames that are operationalised {{as a set of}} indicator questions. In doing so, we compare two approaches to modelling the coherence between indicator questions and frames as an SML task. The results of our experiments show that SML is well suited to automate frame coding but that coding performance is dependent on the way SML is implemented. In most framing studies, news frames are coded with indicator questions in manual Content Analysis (CA) (Matthes, 2009). Generally, measures of several indicators are combined to cover different aspects of a frame (e. g., Simon & Xenos, 2000). Human coders can be properly trained to <b>code</b> <b>frame</b> indicators, and through training their performance can be improved until accu-racy and reliability reach satisfactory levels. However, human coding is a time-consuming and costly process. This limits the scope of CA in framing research. Computers, in contrast, are more naturally suited for the processing of large quantities of documents and the repetitiveness of cod...|$|E
3000|$|... where MV′ and D′MC are {{the motion}} vector and the {{corresponding}} motion compensation distortion of the collocated block in the previously <b>coded</b> <b>frame.</b>|$|R
3000|$|... [...]. For example, given a <b>coded</b> <b>frame,</b> after entropy decoding, the {{macroblock}} {{information is}} extracted as follows, the type is intra, the partition belongs to [...]...|$|R
50|$|A small {{percentage}} of the time <b>code</b> <b>frames</b> (typically less than 10%) may be replaced by one-minute message frames, containing other information, such as emergency broadcasts.|$|R
40|$|Establishing a {{professional}} police {{must be taken}} through various stages of education and experience. In carrying out their authority policemen are framed by {{a code of ethics}} to prevent any interference from any party. But in fact this ethic <b>code</b> <b>frame</b> could not work optimally for monitoring police performance because there are still many irregularities committed by the police officer themselves. Deviations that occur in law enforcement, especially those conducted by police officers happened {{due to the lack of}} awareness that the authority being given is a moral responsibility to uphold the law, and by doing so is the requirement for law supremacy. How to control crime which is committed by members of the police department? What obstacles are in the prevention of criminal acts which are committed by the members of the police department? To answer these two questions, the writer applied a normative legal research methods. In addition to the application of criminal sanctions and ethic codes, the prevention efforts are also supported by the program of activities such as: mental and spiritual guidance, technical guidelines direction and supervision which are expected to improve police department performance and professionalism as well as fix their deficiencies as an organization in line with the spirit and ideals of police department reformation. The writer gives some suggestions. Firstly, there is a need to increase the quality of education / training within the police department environment to maximize performance and professionalism of its members in order to minimize the violations and errors in the field. Secondly, the public is also advised to understand the process of criminal law enforcement, particularly against members of the police. Thirdly, related to the Police members' welfare problem which has been a factor that lead to violations, it is advisable for the government to improve the welfare of members of the police department. Last, the continuous cooperation between police and non-governmental organizations that specifically deal with the police department to fix the deficiencies that become police problems...|$|E
40|$|Abstract {{copyright}} UK Data Service {{and data}} collection copyright owner. The 'National Adult Learning Survey 2001 ' (NALS 2001) is the third study in a series which explores participation {{in a range of}} learning experiences. The NALS series is used by the Department for Education and Skills (DfES) {{to evaluate the effectiveness of}} their adult learning policies. It is also used to monitor progress in meeting the government National Learning Target for adult participation. The third survey aimed to collect data on a wide range of learning experiences, including taught and self-directed learning, vocational learning and other types of job-related earning. It covered not only people who have done some learning, training or education, but also those who have not done any in recent years. The survey aimed to increase understanding of why some people decide to learn while others do not. The DfES are keen to identify barriers to learning that people experience such as course fees, bad past experience of learning at school and lack of time. Therefore, they are particularly interested in those who have not done any learning recently. The first survey in the series, NALS 1997 is held at the UK Data Archive under SN: 3815, and was conducted by the National Centre for Social Research under its former name, Social and Community Planning Research (SCPR). The second survey, NALS 2000, conducted by Ipsos-RSL, is held under SN: 4578. Main Topics : The dataset includes information on: full-time education and qualifications; taught learning: subject, mode and use of information and communication technology (ICT), time and place of learning, motivations and outcomes, advice received and problems with courses; self-directed learning: subject, use of ICT, motivations and outcomes, problems with learning experience; information and advice about learning; future learning and knowledge of learning initiatives; use of ICT. Standard Measures For qualifications, the NVQ level equivalent was derived using the Labour Force Survey <b>code</b> <b>frame.</b> Employment data were classified using Standard Occupational Classification (SOC 1990) and Socio-Economic Group (SEG). The Department of Environment, Transport and the Regions (DETR) multiple deprivation index (2000) was added to the data (England only) ...|$|E
40|$|Namen diplomske naloge je prikazati razvoj spletnih aplikacij s pomočjo ogrodja CodeIgniter. Na primeru izdelave spletne aplikacije za rezervacijo prostih terminov so prikazane vse prednosti in zmogljivosti, ki jih omogoča ogrodje CodeIgniter. Poleg omenjenega ogrodja so v diplomski nalogi opisane tudi ostale tehnologije, ki smo jih uporabili pri razvoju spletne aplikacije. Opisana in primerjana so tudi ostala priljubljena orodja, napisana v jeziku PHP. V praktičnem delu je narejena analiza obstoječih spletnih aplikacij, ki prav tako omogočajo rezervacijo prostih terminov. Na podlagi analize so izluščene funkcionalnosti in definirane zahteve. Pri načrtovanju spletne aplikacije smo uporabili UML diagramske tehnike. V fazi implementacije predstavimo, kako smo izvedli določeno funkcionalnost, ter katere razrede in knjižnice smo uporabili. Predstavimo tudi, kako zaščititi in poskrbeti za varnost spletne aplikacije, in kako poteka testiranje s pomočjo ogrodja CodeIgniter. V diplomski nalogi ugotavljamo, da lahko razvoj spletne aplikacije s pomočjo ogrodja CodeIgniter bistveno pohitrimo. Z uporabo MVC arhitekture dosežemo ločitev logičnega nivoja od uporabniškega vmesnika spletne aplikacije. To pripomore k boljši preglednosti in vzdrževanju izvorne kode. Ogrodje zelo dobro poskrbi za varnost in zaščito spletne aplikacije. Ogrodje je v primerjavi z ostalimi ogrodji malo okrnjeno, vendar obstaja cela vrsta dodatkov, ki nadomestijo manjkajoče funkcionalnosti. The {{purpose of}} the thesis is to show the {{development}} of web applications using CodeIgniter framework. On the case of making web application for booking appointments are shown all the advantages and facilities provided by this framework. In addition to this frame, the thesis also describes other technologies {{that were used in}} the development, as well as the comparison of some other popular tools written in PHP. The practical part represents the analysis of existing web applications which also enable booking appointments. Based on this analysis we describe functionalities and define requirements. When designing web application, we used UML diagramming techniques. In the implementation phase, we present how we implemented certain functionality, as well as which classes and libraries were used. We also suggest how to protect and provide best possible security of web application. The practical part is finished with description of how testing using CodeIgniter framework can be conducted. From the thesis we can discover that CodeIgniter framework significantly speeds up the development of web applications. By using the MVC architecture we can achieve the separation of logical level from the user interface. This helps with better transparency and maintenance of the source <b>code.</b> <b>Frame</b> also very well ensures the security and protection of web application. In comparison with other frameworks it is a bit truncated, but there is a whole range of possible additions, which can replace the missing functionalities very well...|$|E
3000|$|WZ coding {{distortion}} estimation. This module has {{the target}} {{to estimate the}} distortion of the WZ <b>coded</b> <b>frames,</b> at band level, for all possible QL values, using the computed variance [...]...|$|R
5000|$|Fluorescent tagging: Here a gene {{encoding}} {{a fluorescent}} protein is inserted into the <b>coding</b> <b>frame</b> of the protein to be tagged. Texture and intensity features can be extracted from images of the tagged protein.|$|R
40|$|The paper {{proposes a}} novel {{algorithm}} {{to enhance the}} quality of H. 264 /AVC compressed video sequences by using an in-loop spatio-temporal motion compensated ſlter (MCSTF). Extra information from surrounding <b>coded</b> <b>frames</b> are used together with the information of the current <b>coded</b> <b>frame</b> to reduce the coding artifacts. With the availability of the original frame, the MCSTF coefſcients are optimized at the encoder and then are implemented at the decoder. Furthermore, an overlapped motion compensated scheme is proposed to reduce the blocking artifacts from surrounding motion compensated frames. Simulation results are judged by PSNR and ƀickering metric. Index Terms — Quality enhancement, H. 264 /AVC com-pressed sequences, spatio-temporal ſltering, coding artifacts...|$|R
40|$|This paper {{focuses on}} the problem of {{estimating}} the distortion for <b>coded</b> and non-coded <b>frames</b> in a video coder that employs variable frameskip. The distortion for <b>coded</b> <b>frames</b> is given by classic rate-distortion models, however the distortion for non-coded frames has not been considered. Based on the optical flow equation, we formulate a method for estimating the distortion of the non-coded frames...|$|R
30|$|Building {{models to}} {{classify}} data {{according to a}} predefined coding scheme is an essential task in data science, especially in research involving machine classification of subjective matter. Building a model to predict house prices can use historical and factual data. Building a model to predict emotions, beliefs or sentiments (such as hateful remarks) in electronic text requires an additional step to establish a ‘gold standard’ that is suitable for training and testing supervised machine classifiers, {{and is based on}} human agreement on which class a piece of text belongs to. Commonly, this is obtained by sampling from a larger data set and employing human annotators to label each data point (tweet) according to a <b>coding</b> <b>frame</b> ([16, 17]). The <b>coding</b> <b>frame</b> serves as a set of categories or classes into which each data point can be classified. Computationally crowdsourcing human annotations is now becoming popular, and Web services such as CrowdFlower or the Amazon Mechanical Turk provide programmatic application programming interfaces (APIs) through which researchers can automatically upload a data set, <b>coding</b> <b>frame,</b> and set of instructions for annotation. The results of the annotation tasks can then be split into training and testing data sets for machine learning.|$|R
30|$|In {{this section}} {{we discuss the}} {{specifics}} of the different parts of the system. Both the time and subbands indices have been dropped from most of the equations, since the same process is applied to all the subbands for each of the WZ <b>coded</b> <b>frames.</b>|$|R
40|$|The {{proposed}} algorithm {{consists of}} insert {{a new type}} of image in the MPEG- 2 compression scheme with I: Intra, P: Predictive and B: Bidirectional frames. This new type of frame is IC: Illumination <b>coded</b> <b>frame.</b> When a IC frame is inserted, a reference frame must be indicated and the low frequency component of the new frame is sent to the decoder and with the reference high frequencies, the <b>coded</b> <b>frame</b> is recovered. The separation between low and high frequencies is made using a Discrete Wavelet Transform (DWT) {{in order to reduce the}} number of coefficients needed. The results obtained show that the compression ratio is dramatically increased with a reduced lost of image reconstruction quality that do not result in an appreciable lost of visual quality...|$|R
40|$|While {{reviewing}} {{two recent}} series which draw together photography and abstract painting, Scott perceives a favouring of the "sensed" over the "seen" in Gagnon's evocations of encounters with archetypal natural and urban landscapes. Investigations into <b>coding,</b> <b>framing,</b> observation, and knowledge are addressed. Biographical notes. 13 bibl. ref...|$|R
40|$|This is the {{questionnaire}} and <b>coding</b> <b>frame</b> {{used in the}} article: The assessment of {{the risks associated with}} reactionary financial restraint on nursing budgets in an acute hospital setting, which has been submitted for future publication in the journal, International Journal of Health Care Quality Assurance [© Emerald]...|$|R
40|$|In this paper, {{we present}} a Gaussian mixture model-based block quantiser for coding line {{spectral}} frequencies that uses multiple frames and mean squared error as the quantiser selection criterion. The efficiency gained from jointly <b>coding</b> multiple <b>frames</b> permits {{the use of the}} mean squared error distortion (MSE) criterion rather than the computationally expensive spectral distortion. The proposed coder encompasses improvements in both distortion performance and complexity with transparency achieved at 23 bits per <b>frame</b> when <b>coding</b> two <b>frames</b> jointly or 21 bits per <b>frame</b> when <b>coding</b> 3 <b>frames.</b> 1...|$|R
40|$|The {{employment}} of proper codings, {{such as the}} base- 2 coding, has allowed to establish the universal approximation property of Boolean functions: if a sufficient number b of inputs (bits) is taken, {{they are able to}} approximate arbitrarily well any real Borel measurable mapping. However, if the reduced set of monotone Boolean functions, whose expression involves only and and or operators, is considered, the standard approach points out significant limitations in their approximation capability. These limitations can be overcome by introducing new specific codings, called lattice <b>coding</b> and <b>frame</b> <b>coding,</b> which permit to show that also monotone Boolean functions possess the universal approximation property. The characteristics of these codings are analyzed in details, focusing on the ability of preserving metric and ordering. In particular, a comparison with classical base- 2 coding shows that the lattice and the <b>frame</b> <b>coding</b> require an increase of O(log b) and of O (√ b), respectively, in the number of bits. Key words: universal approximator, monotone Boolean function, Boolean lattice, lattice <b>coding,</b> <b>frame</b> <b>coding.</b> AMS subject classification: 06 E 30, 03 G 10, 41 A 30. ...|$|R
40|$|H. 264 does block based <b>coding.</b> • Each <b>frame</b> {{is divided}} into blocks of 16 x 16 pixels called macroblocks (MB). • Each MB can be encoded using blocks of pixels that are already encoded within the current frame- Intra <b>frame</b> <b>coding.</b> • MBs can be coded using blocks of pixels in {{previous}} or future encoded frames- Inter <b>frame</b> <b>coding.</b> • The process of finding a match of pixel blocks in inter <b>frame</b> <b>coding</b> is called Motion Estimation...|$|R
40|$|Error {{concealment}} {{techniques such}} as motion copying require significant changes to HEVC (High Efficiency Video Coding) motion estimation process when incorporated in error resilience frameworks. This paper demonstrates a novel motion estimation mechanism incorporating the concealment impact from future <b>coding</b> <b>frames</b> to achieve an average 0. 73 dB gain over the state-of-the-art...|$|R
30|$|The blockiness metric is {{measure of}} the visible edges on the coded picture block boundary; it is {{calculated}} based on the Boundary Strength (BS) of the transform block boundaries {{which is part of the}} encoder standard. The amount of blockiness present over a widow of frames is accumulated and a normalized blockiness metric (BM) is computed based on this amount of blockiness. BS value of 4 is high blockiness and BS value of 0 is less blockiness. For the calculation of amount of blockiness, all the block boundaries which have BS equal to 4 for intra <b>coded</b> <b>frames</b> and BS equal to 2 for the inter <b>coded</b> <b>frames</b> are counted. This count is accumulated over a frame and based on this the normalized BM metric is calculated and converted to percentage terms. So the value of the BM is between 0 to 100.|$|R
40|$|Abstract. H. 264 /AVC video coding {{standard}} inherited the quadratic rate-distortion model of VM 8, and proposed a linear tracking model to predict Mean Absolute Difference {{of the current}} frame. Since Rate-Distortion Optimization is introduced, the <b>frame</b> <b>coding</b> complexity MAD is predicted in H. 264 /AVC rate control. However, any single-mode prediction approach of <b>frame</b> <b>coding</b> complexity has its shortages due to unexpected changes of video source. In this paper, we induct the <b>frame</b> <b>coding</b> complexity based on extensive experiments, and propose an optimized choice approach to predict the <b>frame</b> <b>coding</b> complexity. Simulation results demonstrate that the novel approach for <b>frame</b> <b>coding</b> complexity gains better precision than that of joint model in H. 264 /AVC reference software...|$|R
30|$|The MVP for inter-view {{prediction}} is calculated using the MV of the 16 x 16 partition of the MB {{located in the}} same position, but in the temporally previous inter-view <b>coded</b> <b>frame.</b> Otherwise, an inaccurate MVP would be calculated, thus affecting coding efficiency, since an inaccurate MVP means that the optimal (or nearly optimal) matching block cannot be found.|$|R
30|$|In {{addition}} to avoiding potential self-esteem biases in individuals’ responses about the educational requirements of their jobs, our method avoids {{the use of}} hard-to-replicate expert judgements and deploys an observer-neutral classification procedure based on relatively simple statistical classification methods. Our method is also updatable, transferable to new or old occupation <b>coding</b> <b>frames,</b> and applicable across countries.|$|R
30|$|Step 3 : Perform AMP {{decision}} skipping. Derive the co-located CU {{in previous}} <b>coded</b> <b>frame</b> of current CU; {{if it was}} encoded as SKIP mode, current CU should also be decided as SKIP mode and go to step 6; otherwise, current CU should further be decided as AMP or still as SMP and go to step 4.|$|R
30|$|The {{proposed}} scheme adopts a GOP <b>frame</b> <b>coding</b> structure, {{as found in}} traditional video coding. Herein, the first frame is encoded with the traditional intra frame encoding, and the other frames function using skip block encoding. With this procedure, as with the traditional video <b>coding</b> results, intra <b>frame</b> <b>coding</b> prevents the entire GOP frame from distorting.|$|R
40|$|The International Classification of Diseases (ICD) E {{codes are}} {{the most widely used}} <b>coding</b> <b>frame</b> for categorising the {{circumstances}} of injury and poisoning. In 1992 major revisions to the E codes were released. The aim of this paper was to consider whether the changes made are a step forward or backwards in terms of facilitating injury prevention...|$|R
50|$|Motion {{estimation}} based {{video compression}} helps in saving bits by sending encoded difference images which have inherently less entropy {{as opposed to}} sending a fully <b>coded</b> <b>frame.</b> However the most computationally expensive and resource extensive operation in the entire compression process is motion estimation. Hence, fast and computationally inexpensive algorithms for motion estimation {{is a need for}} video compression.|$|R
