3|1023|Public
5000|$|Craig D. Ball is a <b>computer</b> <b>forensic</b> <b>analyst</b> {{and former}} trial lawyer who advises judges and lawyers {{on the use}} of {{electronic}} evidence. [...] He is also an adjunct professor at the University of Texas at Austin School of Law, {{and is the author of}} the column Ball in Your Court column of the Law Technology News [...] [...] He has served as a special master in U.S. court cases involving electronic evidence, and been featured in the New York Times.|$|E
40|$|Creating a {{forensic}} copy (image) {{of a hard}} disk drive {{is one of the}} fundamental tasks a <b>computer</b> <b>forensic</b> <b>analyst</b> must perform. Time is often critical, and {{there is a need to}} consider a trade-off between a number of factors to achieve best results. This paper reports the results from an exploratory study into the impact of using disk drive compression on the time needed to image (and verify) a hard disk drive. It was found that time reduction may be achieved once the trade-off of contributing variables was properly estimated. The findings led the investigators to suggest a step-by-step decision making process for analysts when considering disk compression as a means for reducing total image processing time...|$|E
40|$|Project (M. S., Computer Science) [...] California State University, Sacramento, 2010. Computer Forensics {{involves}} {{analysis of}} a digital artifact to look for evidence associated with an illegal activity. With the growing role of electronic media in our daily lives, most crimes involve the use of electronic media {{in the process and}} hence Computer Forensics has become a vital aspect of Crime Investigation Units. There is a variety of Computer Forensic tools (e. g. FTK, EnCase etc.) available to help the experts, but these tools only help in categorizing the information. Examples of categorization include, searching for key words, looking for the deleted files, showing the directory structure etc. Thus to help the decision making process Computer Forensics completely depends on the knowledge, skill and expertise of the Forensic Expert. There is no tool available that can help the forensic experts in the decision making process. The goal of this project is to present a computational cognitive model which simulates the behavior of a <b>computer</b> <b>forensic</b> <b>analyst.</b> Mainly two types of decision making are involved in the computer analysis process: ???	Which path to follow when {{there are a number of}} options? ???	When is it the right time to leave one patch of information and look for evidence somewhere else? The presented cognitive model simulates both kinds of decision making. This project proposes the use of ???Information Foraging Theory??? to achieve the purpose. Information Foraging Theory is an approach to understanding how strategies and technologies for information seeking, gathering, and consumption are adapted to the flux of information in the environment. This theory assumes that people, when needed, will modify their foraging strategies or the structure of the environment to maximize their rate of gaining valuable information. The computational cognitive model of a foraging system (to perform Computer Forensics) presented in this project embodies a built-in cognitive process, which makes use of the information foraging techniques. The presented model forms the basis for future development of an intelligent computer forensic system, which can potentially reduce the dependency of the computer forensic process on the experience and skills of forensic expert, though it cannot be completely removed. Computer Scienc...|$|E
40|$|The official, Guidance Software-approved book on {{the newest}} EnCE exam! The EnCE exam tests that <b>computer</b> <b>forensic</b> <b>analysts</b> and {{examiners}} have thoroughly mastered computer investigation methodologies, {{as well as the}} use of Guidance Software's EnCase Forensic 7. The only official Guidance-endorsed study guide on the topic, this book prepares you for the exam with extensive coverage of all exam topics, real-world scenarios, hands-on exercises, up-to-date legal information, and sample evidence files, flashcards, and more. Guides readers through preparation for the newest EnCase Certified Examine...|$|R
5000|$|On 8 December 2015, Wired {{wrote that}} Craig Steven Wright, an Australian former academic, [...] "either invented bitcoin or is a {{brilliant}} hoaxer who very badly wants us to believe he did". Craig Wright took down his Twitter account and {{neither he nor his}} ex-wife responded to press inquiries. The same day, Gizmodo published a story with evidence obtained by a hacker who supposedly broke into Wright's email accounts, claiming that Satoshi Nakamoto was a joint pseudonym for Craig Steven Wright and <b>computer</b> <b>forensics</b> <b>analyst</b> David Kleiman, who died in 2013. A number of prominent bitcoin promoters remained unconvinced by the reports. Subsequent reports also raised the possibility that the evidence provided was an elaborate hoax, which Wired acknowledged [...] "cast doubt" [...] on their suggestion that Wright was Nakamoto.|$|R
40|$|When {{computer}} security violations are detected, <b>computer</b> <b>forensic</b> <b>analysts</b> attempting {{to determine the}} relevant causes and effects are forced to perform the tedious tasks of finding and preserving useful clues in large networks of operational machines. To augment a computer crime investigator 's efforts, the approach {{presented in this paper}} is an expert system with a decision tree that uses predetermined invariant relationships between redundant digital objects to detect semantic incongruities. By analyzing data from a host or network and searching for violations of known data relationships, particularly when an attacker is attempting to hide his presence, an attacker's unauthorized changes may be automatically identified. Examples of such invariant data relationships are provided, as are techniques to identify new, useful ones. By automatically identifying relevant evidence, experts can focus on the relevant files, users, times and other facts first...|$|R
40|$|Despite the {{existence}} of a number of advanced authentication mechanisms such as twofactor tokens, biometrics etc., the use of passwords is still the most popular means of authenticating users in a computing system. Consequently, we need to generate and remember a large number of passwords, and these passwords need to be as strong as the assets they protect. During the course of a <b>forensic</b> examination a <b>computer</b> <b>forensics</b> <b>analyst</b> may come across a number of situations where the recovery of passwords is required, either in order to access a particular user account, or to unlock encrypted or otherwise obfuscated digital content. In this paper we create a cognitive model to describe the creation of end-user generated passwords that may be applied particularly during an attempt to forensically recover such passwords. We propose that it may be feasible to recover a password by reversing the logic of its creation, taking into account contextual and other parameters, instead of applying computationally expensive brute force. 1...|$|R
40|$|E-mail {{has become}} the most popular Internet {{application}} and with its rise in use has come an inevitable increase in the use of e-mail for criminal purposes. It is possible for an e-mail message to be sent anonymously or through spoofed servers. <b>Computer</b> <b>forensics</b> <b>analysts</b> need a tool {{that can be used to}} identify the author of such e-mail messages. This thesis describes the development of such a tool using techniques from the fields of stylometry and machine learning. An author's style can be reduced to a pattern by making measurements of various stylometric features from the text. E-mail messages also contain macro-structural features that can be measured. These features together can be used with the Support Vector Machine learning algorithm to classify or attribute authorship of e-mail messages to an author providing a suitable sample of messages is available for comparison. In an investigation, the set of authors may need to be reduced from an initial large list of possible suspects. This research has trialled authorship characterisation based on sociolinguistic cohorts, such as gender and language background, as a technique for profiling the anonymous message so that the suspect list can be reduced...|$|R
40|$|Flaws in system {{security}} may persist {{for the foreseeable}} future. Yet, software developers and system administrators are not learning from security mistakes because identifying {{the cause of a}} computer intrusion is time-consuming, tedious and unlikely to yield definitive results. Investigations are fraught with data volatility, privacy and legal issues as well. When intrusions are detected, <b>computer</b> <b>forensics</b> <b>analysts</b> are swamped in evidence because of the large volume of data encountered, the dearth of trained investigators and the lack of automated techniques to analyze computer crime data. An expert system with a decision tree that uses predetermined invariant relationships between redundant digital objects (like an application log entry and an audit trail) to detect semantic incongruities could augment a computer crime investigator's efforts. By analyzing data from a system and searching for violations of known data relationships, an attacker's changes to the system may be automatically identified. Examples of such invariant data relationships are provided, as are techniques to identify new, useful ones. A requirement for such a system is to have the evidence available in a standard machine-readable format. A prototype of this general approach has been written, integrating The Coroner's Toolkit and JESS, The Expert System Shell for the Java Platform, that automatically identifies files that have been modified, accessed or changed when their owners were not logged in. By automatically identifying relevant evidence, experts can focus on the relevant files, users, times and other facts first...|$|R
40|$|Steganography {{deals with}} secrecy and convert {{communication}} {{and today the}} techniques for countering this {{in the context of}} <b>computer</b> <b>forensics</b> has somewhat fallen behind. This paper will discuss on how steganography is used for information hiding and its implications on <b>computer</b> <b>forensics.</b> While this paper is not about recovering hidden information, tools that are used for both steganography and steganalysis is evaluated and identifies the shortcomings that the <b>forensic</b> <b>analysts</b> would face. In doing so this paper urges on what the stakeholders in the field of <b>computer</b> <b>forensics</b> needs to do to keep ahead of criminals who are using such techniques to their advantage and obscure their criminal activities...|$|R
5000|$|With {{a view to}} {{tackling}} cybercrime, Hong Kong Customs {{established the}} <b>Computer</b> <b>Forensic</b> Laboratory, the <b>Computer</b> Analysis & Response Team, and the Anti-Internet Piracy Investigation Team in 2000. [...] These specialized establishments prominently enhanced Customs' enforcement capability and the credibility of digital evidence presented to the courts. The Customs <b>Computer</b> <b>Forensic</b> Laboratory offers professional assistance in collecting, preserving, analyzing, and presenting digital evidence to law court in customs related cases. [...] The digital <b>forensic</b> <b>analysts</b> from the laboratory are qualified to testify as expert witnesses in court of law. The forensic laboratory has been awarded ISO 9001 on quality management and ISO 27001 (BS 7799) on information security since 2006. [...] The Hong Kong Customs <b>Computer</b> <b>Forensic</b> Laboratory is the first government unit of HKSAR (Hong Kong Special Administrative Region) to implement ISO 27001. [...] In 2013, an Electronic Crime Investigation Centre was set up within the department.|$|R
40|$|We {{present a}} visual {{analytic}} framework {{for exploring the}} relationship of textual evidence for <b>computer</b> <b>forensics.</b> Based upon a task analysis study performed with practitioners, our tool addresses the inefficiency of searching for related text documents on a hard drive. Our framework searches both allocated and unallocated sectors for text and performs some pre-analysis processing; this information is then presented via a visualization that displays both the frequency of relevant terms and their location on the disk. We also present a case study that demonstrates our framework’s operation, and we report on an informal evaluation conducted with <b>forensics</b> <b>analysts</b> from the Mississippi State Attorney General’s Office and National Forensics Training Center...|$|R
50|$|The {{two most}} common TTPs are <b>forensic</b> <b>analysts</b> and notaries. A <b>forensic</b> <b>analyst</b> specializing in {{handwriting}} {{can look at}} a signature, compare it to a known valid signature, and make a reasonable assessment of {{the legitimacy of the}} first signature. A notary provides a witness whose job is to verify the identity of an individual by checking other credentials and affixing their certification that the party signing is who they claim to be. Further, a notary provides the extra benefit of maintaining independent logs of their transactions, complete with the type of credential checked and another signature that can independently be verified by the preceding <b>forensic</b> <b>analyst.</b> For this double security, notaries are the preferred form of verification.|$|R
50|$|Eric Robi is a noted <b>forensic</b> <b>computer</b> examiner, {{president}} of a <b>computer</b> <b>forensic</b> consulting firm, and a university instructor in advanced <b>computer</b> <b>forensics.</b>|$|R
40|$|Abstract With the {{popularity}} of computer and network technology, information security problem is increasingly highlighted, and the computer related crime phenomenon more and more. <b>Computer</b> <b>forensics</b> to protect information security and {{to crack down on}} computer crime provides scientific methods and means, can provide evidence of the court need. This paper first gives the definition of <b>computer</b> <b>forensics,</b> and then introduces the features of computer evidence, principles and classification of <b>computer</b> <b>forensics,</b> finally describes the research status of <b>computer</b> <b>forensics,</b> points out the problems existing in the <b>computer</b> <b>forensics</b> and its development trend is forecasted...|$|R
40|$|<b>Computer</b> <b>forensics</b> and anti <b>computer</b> <b>forensics</b> are two {{opposing}} fields. <b>Computer</b> <b>forensics</b> {{is done by}} a <b>computer</b> <b>forensics</b> expert {{in order to obtain}} accurate data and evidence of cyber crime cases for investigation, while the anti-computer forensics conducted by the attacker to remove traces at once difficult <b>computer</b> <b>forensics</b> expert in performing its duties. For the attacker, the selection of anti-computer forensics tool that default on the target machine, more effective and faster than installing it first on the victim machine. For this reason the author chose shred as anti <b>computer</b> <b>forensics</b> applications on GNU / Linux machine. If anti forensic work, forensic experts would be difficult to perform <b>computer</b> <b>forensics</b> to data as evidence of cyber crime. This paper describes the anti-forensics performed by the attacker to remote machines GNU / Linux for cyber crime cases in a <b>computer</b> network. Anti <b>forensic</b> performed using shred the syslog file to remove traces of the crime at the same time make it difficult for the <b>forensic</b> process by <b>computer</b> <b>forensics</b> expert. Tests performed on three pieces of computer-based GNU / Linux on System Signals Lab intranet ITB. Each act as the target machine (server), firewall machine, and the machine attacker. Doing the anti <b>computer</b> <b>forensics</b> and <b>computer</b> <b>forensics</b> at the server machine. The test results are recorded and analyzed in order to then be deduced...|$|R
50|$|There {{are several}} <b>computer</b> <b>forensics</b> {{certifications}} available, {{such as the}} ISFCE Certified <b>Computer</b> Examiner, Digital <b>Forensics</b> Investigation Professional (DFIP) and IACRB Certified <b>Computer</b> <b>Forensics</b> Examiner.|$|R
40|$|Cloud {{computing}} and <b>computer</b> <b>forensics</b> {{for business}} applications The paper reviews {{issues related to}} teaching <b>computer</b> <b>forensics</b> with Cloud Computing. It examines the key issues that <b>Computer</b> <b>Forensics</b> is facing today and the challenges and opportunities that Cloud Computing brings for <b>computer</b> <b>forensics.</b> Computing {{can be seen in}} all basic tasks of <b>Computer</b> <b>Forensic</b> Investigation: Data Acquisition and Validation, Bookmaking data, File Signature Analysis and Hash Analysis, Analysis of Data, securing evidence files and reporting. Colleges and university are beginning to identify and manage applications and services available through Cloud Computing. For example, Ohio State University and many other universities (Indiana University 2009 Teaching, administrative support, and research. IBM and Google had started programs on college campuses to promote computer known as “clouds” Teaching <b>Computer</b> <b>Forensics</b> in Cloud Computing environment offers opportunities far beyond traditional <b>computer</b> <b>forensics</b> at the advance edge of technological innovations...|$|R
50|$|Naomi Kimishima (Kirsten Potter) - Returning from Second Opinion, Kimishima {{now works}} with the FBI as a <b>forensics</b> <b>analyst.</b>|$|R
40|$|Python, a {{high-level}} language, provides an outstanding interface for <b>forensic</b> <b>analysts</b> to write scripts to examine evidence. Python {{is the driving}} language for several current open-source forensic analysis projects from Volatility, for memory analysis to libPST for abstracting the process of examining email. This paper provides a taxonomy of the different forensics libraries and examples of code that a <b>forensic</b> <b>analyst</b> can quickly generate using Python to further examine evidence. Copyright SANS Institut...|$|R
50|$|<b>Computer</b> <b>Forensics</b> Section The <b>Computer</b> <b>Forensics</b> Team {{focuses on}} computer-involved {{criminal}} investigations, computer seizures, data recovery/preservation, and documentation of evidential data.|$|R
50|$|Farmer and Venema collaborated {{again to}} develop a <b>computer</b> <b>forensics</b> suite called The Coroner's Toolkit, and later coauthored Forensic Discovery (2005), a book about <b>computer</b> <b>forensics.</b>|$|R
50|$|<b>Computer</b> <b>{{forensic}}s</b> (also {{known as}} <b>computer</b> <b>forensic</b> science) is {{a branch of}} digital forensic science pertaining to evidence found in computers and digital storage media. The goal of <b>computer</b> <b>forensics</b> is to examine digital media in a forensically sound manner {{with the aim of}} identifying, preserving, recovering, analyzing and presenting facts and opinions about the digital information.|$|R
5000|$|Lisa Van Camp - Van Camp is a <b>forensic</b> <b>analyst</b> (appeared in [...] "Roswell" [...] and [...] "Paranormal Hotspots" [...] episodes, {{filling in}} for Dobrydney) ...|$|R
40|$|AbstractComputer {{forensics}} {{and privacy}} protection fields are two conflicting directions in computer security. In the other words, <b>computer</b> <b>forensics</b> tools try {{to discover and}} extract digital evidences related to a specific crime, while privacy protection techniquesaim at protecting the data owner's privacy. As a result, finding a balance between these two fields is a serious challenge. Existing privacy-preserving <b>computer</b> <b>forensics</b> solutions consider all data owner's data as private and, as a result, they collect and encrypt the entire data. This increases the investigation cost {{in terms of time}} and resources. So, {{there is a need for}} having privacy levels for <b>computer</b> <b>forensics</b> so that only relevant data are collected and then only private relevant data are encrypted. This research paper proposes privacy levels for <b>computer</b> <b>forensics.</b> It starts with classifying forensic data, and analyzing all data access possibilities in <b>computer</b> <b>forensics.</b> Then, it defines several privacy levels based on the found access possibilities. The defined privacy levels lead to more efficient privacy-preserving <b>computer</b> <b>forensics</b> solution...|$|R
40|$|In this paper, {{we discuss}} the role that machine {{learning}} can play in <b>computer</b> <b>forensics.</b> We begin our analysis by considering the role that machine learning has gained in computer security applications, {{with the aim of}} aiding the <b>computer</b> <b>forensics</b> community in learning the lessons from the experience of the computer security community. Afterwards, we propose a brief literature review, with the purpose of illustrating the areas of <b>computer</b> <b>forensics</b> where machine learning techniques have been used until now. Then, we remark the technical requirements that should be meet by tools for computer security and <b>computer</b> <b>forensics</b> applications, with the goal of illustrating in which way machine learning algorithms can be of any practical help. We intend this paper to foster applications of machine learning in <b>computer</b> <b>forensics,</b> and we hope that the ideas in this paper may represent promising directions to pursue in the quest for more efficient and effective <b>computer</b> <b>forensics</b> tools...|$|R
40|$|This paper {{describes}} {{our experience}} {{in the design and}} implementation of a <b>computer</b> <b>forensics</b> specialisation for the Bachelor of Computer Science degree and its capstone subject <b>Computer</b> <b>Forensics</b> Workshop. Our motivation for introducing this specialisation was to respond to the growing demand for professional services in <b>computer</b> <b>forensics</b> by the government and industry as well as to attract undergraduate students back to computing. <b>Computer</b> <b>forensics</b> is an emerging multidisciplinary field with foundations in computer science and law, and academically it is best positioned as a stream in general computer science degrees. The capstone subject in the specialisation, <b>Computer</b> <b>Forensics</b> Workshop, is practically oriented with a substantial laboratory component. The subject is taught by a team of academics, each contributing their expert knowledge in operating systems, file systems, network security and cryptography. The aim is to prepare the students to enter the job market as a professional <b>computer</b> <b>forensics</b> specialist, either in a law enforcement agency or a business organisation relying on computer information systems. ...|$|R
40|$|With the {{increasing}} of computer crime, instant {{emergence of new}} digital product, new computer technology and <b>computer</b> <b>forensics</b> technology is promoted, developed constantly. This paper described basic information/content of <b>computer</b> <b>forensics,</b> and elaborated the development of current <b>computer</b> <b>forensics</b> at domestic and overseas market. The trends of <b>computer</b> <b>forensics</b> are pointed out and recent hot topics of research are introduced. © 2011 IEEE. published_or_final_versionThe 7 th International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP 2011), Dalian, China, 14 - 16 October 2011. In Proceedings of the 7 th IIH-MSP, 2011, p. 388 - 39...|$|R
40|$|This paper {{outlines}} {{a number}} of key lessons learned from an investigation into the techniques malicious executable software can employ to hinder digital forensic examination. Malware signature detection has been recognised by researchers to be far less than ideal. Thus, the <b>forensic</b> <b>analyst</b> may be required to manually analyse suspicious files. However, in order to hinder the <b>forensic</b> <b>analyst,</b> hide its true intent and to avoid detection, modern malware can be wrapped with packers or protectors, and layered with a plethora of antianalysis techniques. This necessitates the <b>forensic</b> <b>analyst</b> to develop static and dynamic analysis skills tailored to navigate a hostile environment. To this end, the analyst must understand the anti-analysis techniques that can be employed and how to mitigate them, the limitations of existing tools and how to extend them, and how to employ an appropriate analysis methodology to uncover the intent of the malware...|$|R
2500|$|Article {{forthcoming}} in the American Journal of Criminal Law, critiquing {{court decisions}} after Melendez-Diaz that have allowed witnesses {{to testify in}} place of the original <b>forensic</b> <b>analyst.</b>|$|R
50|$|The Open <b>Computer</b> <b>Forensics</b> Architecture (OCFA) is an {{distributed}} open-source <b>computer</b> <b>forensics</b> framework used {{to analyze}} digital media within a digital forensics laboratory environment. The framework was built by the Dutch national police.|$|R
40|$|This thesis {{lays the}} groundwork for {{creation}} of a graduate-level <b>computer</b> <b>forensics</b> course. It begins with an introduction explaining how computing has invaded modern life and explains what <b>computer</b> <b>forensics</b> is and its necessity. The thesis then argues why universities need {{to be at the}} forefront of educating students in the science of <b>computer</b> <b>forensics</b> as opposed to proprietary education courses and the benefits to law enforcement agencies of having a <b>computer</b> scientist perform <b>forensic</b> analyses. It continues to detail what <b>computer</b> <b>forensics</b> is and is not. The thesis then addresses legal issues and the motivation for the topic. Following this section is a review of current literature pertaining to the topic. The last half of the thesis lays a groundwork for design of a <b>computer</b> <b>forensics</b> course at the graduate level by detailing a methodology to implement which contains associated laboratory praxis for the students to follow...|$|R
40|$|Computer has {{influenced}} our daily work, activities {{and played a}} vital role in every corner of our life. We are surfing the net for news, jobs, entertainment, transferring information and data online, purchasing, checking accounts, sending and receiving emails almost every day. For this widespread use, some computer users have misused this technology in illegal activities. As a result the <b>computer</b> <b>forensic</b> and investigation has emerged to carry out the investigation process for solving and discovering different types of internet or computer crimes and bring it to the court. In the paper we will discuss the challenging aspects of forensic investigation, skills needed by a <b>computer</b> <b>forensics,</b> knowledge needed by <b>computer</b> <b>forensic</b> investigator, and phases of <b>computer</b> <b>forensic</b> investigation. Overall the purpose of the paper is to provide the scientific awareness about the <b>computer</b> <b>forensic</b> to face the e-criminal activities of the e-user...|$|R
40|$|As <b>computer</b> <b>forensics</b> {{develops}} {{into one}} of the fastest-growing areas in the computer related fields, many universities and colleges are offering or are planning to offer a course in <b>computer</b> <b>forensics.</b> When instructors begin to develop a new course in the area, one of critical questions they would ask is what textbook should be used. To better answer the question, we conducted a study in which we tried to find which textbooks are being used in <b>computer</b> <b>forensic</b> courses. We believe that the results and analysis of our study will help instructors in choosing adequate textbooks for their new course in <b>computer</b> <b>forensics.</b> 1...|$|R
40|$|Abstract. Criminals often destructed or hided {{evidence}} {{after making}} crime by computer, they hindered <b>computer</b> <b>forensics</b> by anti-forensics technology. A new approach of <b>computer</b> <b>forensics</b> based on steganalysis is proposed. The common anti-forensics technologies, such as steganography, data encryption delete evidence and make forensics invalid. In order {{to enhance the}} evidence efficiency, steganalysis is applied in the <b>computer</b> <b>forensics</b> to collect and transfer evidence. Simulation results show that steganography based on least significant bit (LSB) by java program embeds the text files into the BMP image files, which sizes are nearly invariable. Steganalysis restores the hidden information and provides convenient method for <b>computer</b> <b>forensics...</b>|$|R
40|$|It is {{important}} for computer professionals to understand the technology that is used in <b>computer</b> <b>forensics.</b> <b>Computer</b> <b>forensics</b> basically include the recovery of deleted data. This paper present study about how to hide the useful information by using steganography and cryptography, and also introduce Steganalysis for <b>computer</b> <b>forensic</b> investigation. In the process of Steganalysis, it detects the hide data or message and decodes the hidden data or message. Keywords:Computer forensic, security, Steganography, Steganalysis, watermarking, Cryptography...|$|R
