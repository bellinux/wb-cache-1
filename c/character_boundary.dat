10|320|Public
40|$|With the {{proliferation}} of digital libraries, {{an increasing number of}} document im-ages of different characteristics are being produced. Information retrieval accord-ingly becomes an urgent problem for the access of the text information within these archived document images. This chapter presents a word shape coding approach that retrieves document images without OCR (optical character recog-nition). Several word shape coding schemes are presented, which convert a word image in a word shape code by using a few topological word shape features such as <b>character</b> <b>boundary</b> extrema, character holes, and character water reservoirs. A document image can then be converted into a document vector that encodes the occurrence frequency of the contained word images. Document images can thus be retrieved based on the similarity between the converted document vec-tors. Experiments show that the word shape coding approach is fast, robust, and capable of retrieving document images efficiently without OCR. With {{the proliferation}} of digital libraries and the promise of paper-less office, a...|$|E
40|$|Abstract. The grain {{boundary}} energy anisotropy in BCC Fe-based polycrystals is considered. The {{correlation between the}} energy in BCC random grain boundaries {{and the distribution of}} {{grain boundary}} planes in the bulk was examined with a special attention on the presence of low index (low surface energy) planes in the internal surfaces. For a BCC structure, { 100 } and { 110 } planes are known to be the lowest energy planes dominating the equilibrium crystal shapes. Experimental evidences demonstrated that these planes were predominant in the texture of surfaces controlled by surface energy [2]. Moreover, the relation between the grain boundary character distribution and the crystallographic dependence on the grain boundary energy in the bulk after annealing treatment was studied. The grain <b>character</b> <b>boundary</b> distribution (GCBD) was calculated using the crystallographic information obtained from OIM-EBSD maps from samples showing columnar grains. Preliminary results showed no particular distribution trend within the standard stereographic triangle (001 - 101 - 111) ...|$|E
40|$|International audienceKanungo noise {{model is}} widely {{used to test the}} {{robustness}} of different binary document image analysis methods towards noise. This model only works with binary images while most document images are in grayscale. Because binarizing a document image might degrade its contents and lead to a loss of information, more and more researchers are currently focusing on segmentation-free methods (Angelika et al [2]). Thus, we propose a local noise model for grayscale images. Its main principle is to locally degrade the image in the neighbourhoods of "seed-points" selected close to the <b>character</b> <b>boundary.</b> These points define the center of "noise regions". The pixel values inside the noise region are modified by a Gaussian random distribution to make the final result more realistic. While Kanungo noise models scanning artifacts, our model simulates degradations due to the age of the document itself and printing/writing process such as ink splotches, white specks or streaks. It is very easy for users to parameterize and create a set of benchmark databases with an increasing level of noise. These databases will further be used to test the robustness of different grayscale document image analysis methods (i. e. text line segmentation, OCR, handwriting recognition) ...|$|E
40|$|Over-Segmentation and Validation (OSV) {{is a well}} {{anticipated}} segmentation {{strategy in}} cursive off-line hand writing recognition. Over-Segmentation {{is a means of}} locating all possible <b>character</b> <b>boundaries,</b> and the excessive segmentation points called over-segmentation points. Validation is a process to check and validate the segmentation points {{whether or not they are}} correct <b>character</b> <b>boundaries</b> by commonly employing an intelligent classifier trained with knowledge of characters. The existing OSV algorithms use ordered validation which means that the incorrect segmentation points might account for the validity of the next segmentation point. The ordered validation creates problems such as chain-failure. This paper presents a novel Binary Segmentation with Neural Validation (BSNV) to reduce the chain-failure. BSNV contains modules of over-segmentation and validation but the main distinctive feature of BSNV is an un-ordered segmentation strategy. The proposed algorithm has been evaluated on CEDAR benchmark database and the results of the experiments are promising...|$|R
40|$|The {{extraction}} of character images {{is an important}} front-end processing task in optical character recognition (OCR) and other applications. This process is extremely important because OCR applications usually extract salient features and process them. The existence of noise not only destroys features of characters, but also introduces unwanted features. We propose a new algorithm which removes unwanted background noise from a textual image. Our algorithm {{is based on the}} observation that the magnitude of the intensity variation of <b>character</b> <b>boundaries</b> differs from that of noise at various scales of their wavelet transform. Therefore, most of the edges corresponding to the <b>character</b> <b>boundaries</b> at each scale can be extracted using a thresholding method. The internal region of a character is determined by a voting procedure, which uses the arguments of the remaining edges. The interior of the recovered characters is solid, containing no holes. The recovered characters tend to become fatten [...] ...|$|R
25|$|UTF-8 is self-synchronizing: <b>character</b> <b>boundaries</b> {{are easily}} {{identified}} by scanning for well-defined bit patterns in either direction. If bytes are lost due to error or corruption, one can always locate the next valid character and resume processing. If {{there is a}} need to shorten a string to fit a specified field, the previous valid character can easily be found. Many multi-byte encodings are much harder to resynchronize.|$|R
40|$|Abstract — The current OCR cannot segment {{words and}} {{characters}} from video images due to complex background {{as well as}} low resolution of video images. To have better accuracy, this paper presents a new gradient based method for words and character segmentation from text line of any orientation in video frames for recognition. We propose a Max-Min clustering concept to obtain text cluster from the normalized absolute gradient feature matrix of the video text line image. Union of the text cluster with the output of Canny operation of the input video text line is proposed to restore missing text candidates. Then a run length algorithm is applied on the text candidate image for identifying word gaps. We propose a new idea for segmenting characters from the restored word image {{based on the fact}} that the text height difference at the <b>character</b> <b>boundary</b> column is smaller than that of the other columns of the word image. We have conducted experiments on a large dataset at two levels (word and character level) in terms of recall, precision and f-measure. Our experimental setup involves 3527 characters of English and Chinese, and this dataset is selected from TRECVID database of 2005 and 2006. Keywords- Video document analysis, Word segmentation, Vide...|$|E
40|$|Text {{detection}} and recognition in natural scene can give valuable information for many applications. However, getting text from images with complex background is challenging task due to less {{frequency of occurrence}} text and presence of background outliers resembling text characters. In text detection, algorithms from previous work are applied to localize text region in scene image. First, character descriptor is employed to extract structure features. Second, we tend to designed novel feature representation, stroke configuration map using <b>character</b> <b>boundary</b> and skeleton to build character structure. Our algorithm style is improved to compatible with mobile application. Developed algorithm style {{is compatible with the}} appliance of scene text extraction in good mobile devices. The Android-based demo system is developed to highlight the effectiveness of the method of scene text extraction from nearby objects. Also demo system gives the detailed information about algorithm design and performance improvement of text extraction from natural image. The demo system conjointly provides United States some insight into rule design and performance improvement of scene text extraction. The analysis results on benchmark knowledge sets demonstrate that our projected theme of text recognition is comparable the best existing ways. The evaluation results on benchmark datasets demonstrate that proposed framework outperforms in comparison to best existing ways. Keywords Scene text {{detection and}} recognition, character descriptor...|$|E
40|$|Background: With the {{increasing}} availability of full text articles through open access publishing, {{the scope of}} biomedical text mining is no longer limited to the abstracts of research literature. Cross-species gene normalization using full-text articles {{is an important step}} towards the use of full text articles in the area of biomedical text-mining research. This was {{one of the goals of}} the BioCreative III Challenge. Results: In this paper, we present a gene normalization strategy based on the identification of gene and species entities in full text articles and their association. ABNER and LingPipe were used as gene name taggers and LINNAEUS was used for species identification. To associate a species name with a gene name, proximity of the gene and species names was considered. Various window sizes for character boundaries were chosen for this proximity-based association. Based on these associations, a unique Entrez gene identifier, if found, was returned for each gene mentioned in an article. Conclusions: For the test set, our estimation shows best results with a strategy that considers only the Entrez Gene identifiers found in common by separate runs using ABNER and LingPipe as gene name taggers. This strategy used a 1000 <b>character</b> <b>boundary</b> window for gene-species name association. The highest TAP-k (k = 20) score returned by our system was 0. 1662 for this strategy (Run 2) ...|$|E
50|$|What {{this means}} that a 7-bit ASCII {{character}} of a message that falls on a boundary can and will be split between two code words, and that the alignment of <b>character</b> <b>boundaries</b> in a particular alpha message code word depends on which code word it is of a message. The side benefit {{of this is a}} slightly increased error-correcting code reliability for messages that span more than one POCSAG packet.|$|R
40|$|Nanocrystalline {{materials}} {{are defined by}} their fine grain size, but details of the grain <b>boundary</b> <b>character</b> distribution should also be important. Grain <b>boundary</b> <b>character</b> distributions are reported for ball milled, sputter deposited, and electrodeposited Ni and Ni-based alloys, all with average grain sizes of 20 nm, to study the influence of processing route. The two deposited materials had nearly identical grain <b>boundary</b> <b>character</b> distributions, both marked by a Σ 3 length percentage of 23 - 25...|$|R
5000|$|... i be the {{position}} of an element (i.e., a <b>character</b> or <b>boundary)</b> in s2 whose palindromic span is being determined, with i always {{to the right of}} c ...|$|R
40|$|International audienceWe propose an {{approach}} dedicated to recognize characters from binary images by an hybrid strategy. A statistical method {{is used to}} identify the global shape of each alphanumeric symbol. This approach {{is based on the}} Fourier Descriptor computation of the outer and potentially inner contours extracted from the input image. %The mapping to the Fourier space enables us to smooth the signal of the <b>character</b> <b>boundary</b> and makes the approach robust to noise. The recognition is managed by a Hierarchical Neural Network (HNN), that is able to deal with topological errors in the contour extraction. This strategy is extremely efficient {{for the majority of the}} classes: the recognition rate reaches about 99. 5 %. However, the performances sensitively decrease for 'similar characters', i. e 8 /B. For these classes, the statistical strategy is not adapted for performing an accurate recognition. Indeed, not only the binary images are hard to distinguish, but the Fourier Descriptor extraction emphasizes the difficulty to discriminate sailent features such as corners. For these characters, we adopt a strategy that revolves around decomposing the characters into structural elements. The Reeb graph generated from the binary images and a simple polygonal approximation permit to capture both topological and geometrical relevant features. The classification stage is carried out by a boosting algorithm (ADABOOST). Several results validate the conjoint use of the structural/statistical approach for character recognition, and point out the relevance of the strategy for a general pattern recognition purpose...|$|E
40|$|Abstract — This paper {{presents}} a new method based on Fourier and moments features to extract words and characters from a video text line {{in any direction}} for recognition. Unlike existing methods which output the entire text line to the ensuing recognition algorithm, the proposed method obtains each extracted character from the text line as input to the recognition algorithm because the background of a single character is relatively simple compared to the text line and words. Max-Min clustering criterion is introduced to obtain text cluster from the extracted Fourier and moments feature set. Union of the text cluster with Canny operation of the input video text line is proposed to obtain missing text candidates. Then a run length criterion is used for extraction of words. From the words, we propose a new idea for extracting characters from the text candidates of each word image {{based on the fact}} that the text height difference at the <b>character</b> <b>boundary</b> column is smaller than that at other columns of the word image. We evaluate the method on a large dataset at three levels namely text line, words and characters in terms of recall, precision and f-measure. In addition to this, we show that the recognition result for the extracted character is better than words and lines. Our experimental set up involves 3527 characters including Chinese. The dataset is selected from TRECVID database of 2005 and 2006. Keywords- Video word segmentation, Video character extraction, Fourier-Moments, Run length, Text height difference, Video character recognitio...|$|E
40|$|The ParaMor {{algorithm}} for unsupervised morphology induction, which {{competed in}} the 2007 and 2008 Morpho Challenge competitions, does not assign a numeric score to its segmentation deci-sions. Scoring each <b>character</b> <b>boundary</b> in each word with the likelihood that it falls at a true mor-pheme boundary would allow ParaMor to adjust the confidence level at which the algorithm pro-poses segmentations. A sliding threshold on segmentation confidence would, in turn, permit a trade off between precision and recall that could optimize F 1 or other metrics of interest. Our sub-mission to Morpho Challenge 2009 enriches ParaMor with segmentation confidences by training an off-the-shelf statistical natural language tagger to mimic ParaMor’s morphological segmenta-tions. For a given word, the tagger’s probabilistic confidence that ParaMor would propose the character, c, as the first character of a new morpheme serves as the numeric score of the candidate morpheme boundary that immediately precedes c. We have trained a ParaMor tagger mimic over a development data set of 500, 000 unique Hungarian word types. By adjusting the threshold above which the ParaMor mimic proposes morpheme boundaries, we improve ParaMor’s F 1 score for Hungarian by 5. 9 % absolute, from 41. 4 % to 47. 3 %. Moreover, by training a probabilistic tagger to emulate the segmentations of a second unsupervised morphology induction system, Morfessor, {{we are able to}} combine ParaMor’s segmentation decisions with Morfessor’s to form a single joint segmentation of each word. Our joint ParaMor-Morfessor tagger mimic enhances F 1 performance on our Hungarian development set by a further 3. 4 % absolute, ultimately achieving an F 1 score o...|$|E
40|$|The {{effects of}} grain <b>boundary</b> <b>character</b> on the {{intergranular}} corrosion susceptibility of 2124 aluminum alloy were examined. In the study, the alloy was heat treated at 540 ºC and corrosion tested according to ASTM G 110 standards. After obtaining grain orientations from the automated Electron Back-Scatter Diffraction (EBSD), both grain <b>boundary</b> <b>character</b> and grain <b>boundary</b> plane distributions were analyzed. Results show that low-angle boundaries and boundaries with a sigma- 3 or sigma- 7 coincident site lattice relationship {{tend to have}} a higher corrosion resistance than other random boundaries...|$|R
40|$|Abstract. A mesoscale, variational {{simulation}} of grain growth in two-dimensions {{has been used}} to explore the effects of grain boundary properties on the grain <b>boundary</b> <b>character</b> distribution. Anisotropy in the grain boundary energy has a stronger influence on the grain <b>boundary</b> <b>character</b> distribution than anisotropy in the grain boundary mobility. As grain growth proceeds from an initially random distribution, the grain <b>boundary</b> <b>character</b> distribution reaches a steady state that depends on the grain boundary energy. If the energy depends only on the lattice misorientation, then the population and energy are related by the Boltzmann distribution. When the energy depends on both lattice misorientation and boundary orientation, the steady state grain <b>boundary</b> <b>character</b> distribution is more complex and depends on both the energy and changes in the gradient of the energy with respect to orientation...|$|R
50|$|Melikgazi itself counts eight {{depending}} municipalities, some {{of which}} retain their semi-rural <b>character,</b> administrative <b>boundaries</b> of Kayseri's metropolitan area sometimes extending faster than the city itself. Melikgazi also has nine depending villages.|$|R
40|$|Abstract. A local {{curvature}} multi-vertex {{model was}} developed. This {{model is the}} straightforward two-dimensional topological network model based on the physical principles which are the curvatures of grain boundaries and the grain boundary tensions at triple junctions. The model {{was applied to the}} artificial random microstructure under some conditions of grain <b>boundary</b> <b>characters.</b> The misorientation distribution was changed very little under constant grain boundary energy and mobility, but it was change much under grain <b>boundary</b> <b>character</b> dependent on misorientation. Therefore, in order to discuss actual textures, it is important to take grain <b>boundary</b> <b>characters</b> into account...|$|R
40|$|The grain <b>boundary</b> <b>character</b> {{distribution}} {{and the relative}} grain boundary energy of 100 ppm Ca-doped yttria were measured before and after a previously identified grain boundary com-plexion transition. The grain <b>boundary</b> <b>character</b> distribution of samples exhibiting normal grain growth (before the complexion transition) favored { 111 } planes, whereas those exhibiting abnormal grain growth (after the complexion transition) favored { 001 } planes. Additionally, the relative grain boundary-to-surface energy ratios in the sample exhibiting abnormal grain growth were 33 pct lower than in the sample exhibiting normal grain growth. The results also indicate that the complexion transition increased the anisotropy of the grain boundary energy, {{and this may be}} responsible for the increase in the anisotropy of the grain <b>boundary</b> <b>character</b> distribution...|$|R
40|$|The five {{parameter}} grain <b>boundary</b> <b>character</b> distribution quantifies {{the relative}} areas {{of different types}} of grain boundaries, distinguished by their lattice misorientation and grain boundary plane orientation. The viewpoint presented in this paper is that this distribution is a sensitive metric of polycrystalline structure that can be related to macroscopic properties. To demonstrate the influence of the grain <b>boundary</b> <b>character</b> distribution on macroscopic properties, the stored elastic energy is calculated in model microstructures. 1...|$|R
40|$|We {{propose a}} variational method for model based {{segmentation}} of highly degraded gray scale images of historical documents. Given a training set of characters (of a certain letter), we construct a small set of shape models that cover {{most of the}} training set’s shape variance. For each gray scale image of a respective degraded character, we construct a custom made shape prior using those fragments of the shape models that best fit the <b>character’s</b> <b>boundaries.</b> Therefore, we {{are not limited to}} any particular shape in the shape model set. Experiments show that our method achieves very accurate results in segmentation of highly degraded characters. When compared with manual segmentation, the average distance between the the boundaries of respective segmented characters was 0. 8 pixels (the average size of the characters is 70 ∗ 70 pixels) ...|$|R
40|$|A {{model is}} {{described}} {{for the development}} of anisotropic grain <b>boundary</b> <b>character</b> distributions from initially random distributions. The model is based on biased topological changes in the grain boundary network that eliminate and create boundaries during grain growth. The grain boundary energy influences the rates of these topological changes by altering the relative areas of the interfaces. The model predicts grain <b>boundary</b> <b>character</b> distributions that are inversely related to the grain boundary energy and are consistent with experimental observations...|$|R
40|$|Abstract A stereological {{analysis}} of electron backscatter diffraction data {{has been used}} to measure the five-parameter grain <b>boundary</b> <b>character</b> distribution of chemically modified 316 LN stainless steel exposed to both elevated and cryogenic temperature. The results were analyzed to determine if the thermal treatments induced any significant changes in the overall grain <b>boundary</b> <b>character</b> distribution and fractional twin density. The results of this study show that the grain <b>boundary</b> <b>character</b> distribution of this steel is very similar to other FCC polycrystals and not affected by typical thermal treatments used in processing or the cryogenic temperatures employed during service. Background 316 LN-type stainless steels have been heavily utilized as structural materials for high field magnets. The chemically modified 316 LN steel examined in this study is currently used as a conduit for Nb 3 Sn superconductors in the Superconductin...|$|R
5000|$|Maxine {{has been}} noted as [...] "a {{transgender}} <b>character,</b> overcame massive <b>boundaries</b> {{to become one of}} the strongest and most likable characters." [...] by Metro.|$|R
40|$|ED in {{the initial}} {{submission}} for double blind review In this paper, we present an off-line methodology for isolated Greek handwritten character recognition based on efficient feature extraction followed by a suitable feature vector dimensionality reduction scheme. Extracted features are based on (i) horizontal and vertical zones, (ii) the projections of the character profiles, (iii) distances from the <b>character</b> <b>boundaries</b> and (iv) profiles from the character edges. The combination {{of these types of}} features leads to a 325 -dimensional feature vector. At a next step, a dimensionality reduction technique is applied, according to which the dimension of the feature space is lowered down to comprise only the features pertinent to the discrimination of characters into the given set of letters. In this paper, we also present a new Greek handwritten database of 36, 960 characters that we created in order to measure the performance of the proposed methodology...|$|R
40|$|In {{domain of}} {{analytic}} cursive word recognition, {{there are two}} main approaches: explicit segmentation based and implicit segmentation based. However, both approaches have their own shortcomings. To overcome individual weaknesses, this paper presents a hybrid strategy for recognition of strings of characters (words or numerals). In a two stage dynamic programming based, lexicon driven approach, first an explicit segmentation is applied to segment either cursive andwritten words or numeric strings. However, at this stage, segmentation points are not finalized. In the second verification stage, statistical features are extracted from each segmented area to recognize characters using a trained neural network. To enhance segmentation and recognition accuracy, lexicon is consulted using existing dynamic programming matching techniques. Accordingly, segmentation points are altered to decide true <b>character</b> <b>boundaries</b> byusing lexicon feedback. A rigorous experimental protocol shows high performance of the proposed method for cursive handwritten words and numeral strings...|$|R
40|$|Stress {{corrosion}} and {{corrosion fatigue}} cracks are frequently very branched {{and there have}} been extensive attempts to define the characteristics of crack-stopping features. EBSD has been used to examine the full length (8 mm) of a corrosion fatigue crack in stainless steel. The grain <b>boundary</b> <b>character</b> distribution of the cracked boundaries is compared to that {{of the rest of the}} material and observations presented on the effect of grain <b>boundary</b> <b>character</b> on the choice of crack path at grain boundary junctions of different configurations and orientations with restect to the principle stres...|$|R
40|$|Abnormal {{subgrain}} {{growth has}} been proposed as the nucleation mechanism for recrystallization. To test this hypothesis, Monte Carlo Potts model simulations of subgrain growth were performed on single-phase, strain-free subgrain structures with experimentally validated microstructure, texture, <b>boundary</b> <b>character,</b> and <b>boundary</b> properties. Results indicate that abnormal growth events emerge spontaneously during evolution in such systems, and abnormal subgrains behave as predicted by mean field theory. An analysis predicts the frequency of abnormal growth events {{as a function of}} local neighborhood and the boundary misorientation distribution. A recrystallization model is derived based on the abnormal subgrain growth analysis. Using data for aluminum subgrain structures, the model predicts reasonable recrystallized grain sizes as a function of von Mises strain. The extension of these results to abnormal grain growth is discussed...|$|R
40|$|On {{the basis}} of recent {{knowledge}} of structure-dependent boundary properties, the design and control of boundary-related bulk properties and performance of advanced polycrystalline materials are discussed. The grain <b>boundary</b> <b>character</b> distribution (GBCD) which has been recently introduced as a new microstructural factor is {{shown to be a}} powerful tool for designing and controlling the bulk properties in polycrystalline materials. The relationship between texture and GBCD has been discussed in connection with other microstructural factors associated with grain boundaries. It has been shown that the relationship between texture and GBCD can provide an important clue to the grain boundary design and control for polycrystalline materials with desirable properties and performance. The present paper shows recent successful achievement of toughening of brittle materials by controlling texture and GBCD. The potential and prospective of the grain boundary design and control for functional materials are also discussed. KEY WORDS Grain <b>boundary</b> <b>character,</b> iron-silicon, coincidence <b>boundaries,</b> grain boundary design. 1...|$|R
40|$|Chinese {{calligraphy}} {{is an art}} {{unique to}} Asian cultures. This paper presents a novel method for generating outline font from historical documents of Chinese calligraphy. The method consists of detecting feature points from <b>character</b> <b>boundaries,</b> and approximating contour segments. The feature-pointdetection is based on statistical method considering {{the characteristics of a}} calligrapher. A database of basic strokes and some overlapping stroke components of Chinese characters extracted from the calligrapher are constructed in advance. And the relation between the noise level of stroke contours and the standard deviation of Gaussian kernel is retrieved from the database using linear regression. Thus, given an input character contour, the standard deviation for smoothing the noisy character contour can be calculated. Furthermore, a new method is employed to determine the feature points at the standard deviation. The feature points at a character contour subdivide the contour into segments. Each segment can be fitted by a parametric curve to obtain the outline font. Some experimental results and the comparisons to existing methods are also presented in the paper. ? 2011 Springer-Verlag Berlin Heidelberg...|$|R
40|$|This paper {{presents}} an over-segmentation and validation strategy for off-line cursive handwriting recognition. Over-segmentation module is employed {{to find all}} the possible <b>character</b> <b>boundaries.</b> Then, the incorrect segmentation points from over-segmenting module are removed by validating processes. The over-segmentation was performed based on the vertical pixel density between upper and lower baselines. Wherever the pixel density is less than threshold, an over-segmentation point is assigned. After the over-segmentation is done, validation starts removing over-segmentation points. The first validation module checks if a segmentation point lies in hole region. The second validation module compares total foreground pixel between two neighbouring segmentation points to a threshold value. The third validation module is neural network voting by neural network classifier trained on pre-segmented characters. Finally, the oversized segment validation process checks {{if there is any}} missing segmentation point between neighbouring characters. The proposed approach has been implemented, and the experiments on CEDAR benchmark database have been conducted. The results of the experiments are very promising and the overall performance of the algorithm is more effective than the other existing segmentation algorithms...|$|R
5000|$|Logographic {{languages}} such as Chinese, Japanese, and Korean (known {{collectively as}} CJK) need {{far more than}} 256 characters (the limit of a one 8-bit byte per-character encoding) for reasonable representation. The normal solutions involved keeping single-byte representations for ASCII and using two-byte representations for CJK ideographs. Use of these with existing code led to problems with matching and cutting of strings, the severity of which depended on how the character encoding was designed. Some encodings such as the EUC family guarantee that a byte value in the ASCII range will represent only that ASCII character, making the encoding safe for systems that use those characters as field separators. Other encodings such as ISO-2022 and Shift-JIS do not make such guarantees, making matching on byte codes unsafe. These encodings also were not [...] "self-synchronizing", so that locating <b>character</b> <b>boundaries</b> required backing up {{to the start of}} a string, and pasting two strings together could result in corruption of the second string (these problems were much less with EUC as any ASCII character did synchronize the encoding).|$|R
40|$|A {{method for}} {{examining}} large masses {{of data and}} extracting useful information from it was described. The information theoretic method proposed, was used for context recognition and classification of strings of <b>characters.</b> The <b>boundary</b> demarcation problem, was central to defining and optimizing suitable observables that could reveal sudden changes in complex data sequences. The method {{was found to be}} useful for extracting information from DNA and protein sequences, geological time series, stock market data, and medical monitoring...|$|R
5000|$|Juniper Green Conservation Area is {{situated}} seven {{miles to the}} west of Edinburgh around the main Lanark Road. The conservation area is centred on the historic core of the village of Juniper Green, {{one of a number of}} villages, which have been absorbed intothe City of Edinburgh. A recognisable village character still remains and the conservation area status was originally designated on 19 November 1993 to protect that <b>character.</b> The <b>boundary</b> was extended in March 2007.Conservation Appraisal ...|$|R
5000|$|The Friends of the Boundary Waters, {{based in}} Minneapolis, Minnesota, is a {{non-profit}} organization that was formed in May 1976 whose mission is “To protect, preserve and restore the wilderness <b>character</b> of the <b>Boundary</b> Waters Canoe Area Wilderness and the Quetico-Superior Ecosystem.” ...|$|R
