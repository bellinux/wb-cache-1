1|7|Public
5000|$|... de Groot, A. & Gobet, F. (1996). Perception {{and memory}} in <b>chess.</b> <b>Heuristics</b> of the {{professional}} eye. Assen: Van Gorcum.|$|E
50|$|Kaplan {{was always}} {{interested}} in computer <b>chess,</b> founding <b>Heuristic</b> Software Corporation whose first development was Heuristic Alpha in 1990-91. That evolved into Socrates and later Socrates II.|$|R
40|$|Chess and Artificial Intelligence {{have long}} been {{associated}} with one another. Since playing chess {{is a good way}} of testing how well an AI works, a logical extension of that is to use a <b>chess</b> state evaluation <b>heuristic</b> as the search space for an optimizing evolutionary algorithm. This is done using the Island Model in conjunction with a parallelizatio...|$|R
40|$|For some two-player games (e. g. Go), no {{accurate}} and inex-pensive heuristic {{is known for}} evaluating leaves of a search tree. For other games (e. g. <b>chess),</b> a <b>heuristic</b> is known (sum of piece values). For other games (e. g. Hex), only a local heuristic — one that compares children reliably, but non-siblings poorly — is known (cell voltage drop in the Shan-non/Anshelevich electric circuit model). In this paper we in-troduce a search algorithm for a two-player perfect informa-tion game with a reasonable local heuristic. Sibling Conspiracy Number Search (SCNS) is an anytime best-first version of Conspiracy Number Search based not on evaluation of leaf states of the search tree, but — for each node — on relative evaluation scores of all children of that node. SCNS refines CNS search value intervals, converging to Proof Number Search. SCNS is a good framework for a game player. We tested SCNS {{in the domain of}} Hex, with promising re-sults. We implemented an 11 -by- 11 SCNS Hex bot, Deep-Hex. We competed DeepHex against current Hex bot cham-pion MoHex, a Monte-Carlo Tree Search player, and previ-ous Hex bot champion Wolve, an Alpha-Beta Search player. DeepHex widely outperforms Wolve at all time levels, and narrowly outperforms MoHex once time reaches 4 min/move. ...|$|R
40|$|AbstractHeuristic search {{effectiveness}} depends directly {{upon the}} quality of heuristic evaluations of states in a search space. Given {{the large amount of}} research effort devoted to computer chess throughout the past half-century, insufficient {{attention has been paid to}} the issue of determining if a proposed change to an evaluation function is beneficial. We argue that the mapping of an evaluation function from <b>chess</b> positions to <b>heuristic</b> values is of ordinal, but not interval scale. We identify a robust metric suitable for assessing {{the quality of}} an evaluation function, and present a novel method for computing this metric efficiently. Finally, we apply an empirical gradient-ascent procedure, also of our design, over this metric to optimize feature weights for the evaluation function of a computer-chess program. Our experiments demonstrate that evaluation function weights tuned in this manner give equivalent performance to hand-tuned weights...|$|R
40|$|Most of the {{research}} in the area of evaluation function learning is focused on self-play. However in many domains, like chess, expert feedback is amply available in the form of annotated games. This feedback comes usually in the form of qualitative information due to the inability of humans to determine precise utility values for game states. We are presenting a first step towards integrating this qualitative feedback into evaluation function learning by reformulating it in terms of preferences. We extract preferences from large-scale database for annotated chess games and use them for calculating the feature weights of a <b>heuristic</b> <b>chess</b> position evaluation function. This is achieved by extracting the feature weights out of the linear kernel from a learned SVMRANK model, based upon the given preference relations. We evaluate the resulting function by creating multiple heuristics based upon different sized subsets of the trainings data and compare them in a tournament scenario. Although our results did not yield a better chess playing program, the results confirm that preferences derived from game annotations may be used to learn chess evaluation functions. ...|$|R
40|$|Proof-number search (pn-search) {{has shown}} its merit in {{contributing}} to the solution of Connect-Four, Qubic and Go-Moku. In this contribution we show that pn-search is a highly capable searcher for mates in chess. Pn-search achieves its results without using any <b>heuristic</b> <b>chess</b> knowledge. We present the results of comparing the performances of pn-search {{and a number of}} other mate searchers on a large number of problems. Finally, we discuss how pn-search can be applied to general tactical searches. 0 S 0 Z 0 Z 0 Z Z 0 Z 0 Z 0 oK 0 Z 0 Z 0 o 0 Z Z 0 Z 0 o 0 Z 0 0 A 0 o 0 Z 0 m Z 0 Z 0 Z 0 Z 0 pZpZpo 0 Z ZkZ 0 ZbZ 0 Mate in 38, L. Ugren, 1967 1 Background A major attraction of chess is the number of different skills necessary to play all stages of the game at a high level. To play the opening well, one needs to select an opening repertoire, study the lines in it, understand the positions resulting from it, and constantly keep up to date with enhancements introduced by top-level players. In the middle game, a deep understanding of th [...] ...|$|R

