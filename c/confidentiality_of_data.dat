246|10000|Public
50|$|The {{confidentiality}} (C) metric {{describes the}} impact on the <b>confidentiality</b> <b>of</b> <b>data</b> processed by the system.|$|E
5000|$|Ensure {{integrity}} and <b>confidentiality</b> <b>of</b> <b>data</b> {{crucial to the}} wide range of online services that will be offered; ...|$|E
50|$|Disk {{encryption}} software is computer security software {{that protects the}} <b>confidentiality</b> <b>of</b> <b>data</b> stored on computer media (e.g., a hard disk, floppy disk, or USB device) by using disk encryption.|$|E
5000|$|... • {{reflecting}} the <b>confidentiality</b> <b>of</b> that <b>data</b> as intended {{by the author}} and patient.|$|R
30|$|Ensuring <b>confidentiality</b> <b>of</b> the <b>data</b> being {{preserved}} in personal computing devices {{can be achieved}} by encryption. However, traditional encryption cannot defend against coercive adversaries (“A unified adversarial model for PDE and secure deletion” section). Therefore, we mainly focus on plausibly deniable encryption (PDE), which can protect <b>confidentiality</b> <b>of</b> the <b>data</b> present in the computing devices against both coercive and non-coercive adversaries.|$|R
5000|$|Service {{providers}} {{are required to}} protect the <b>confidentiality</b> <b>of</b> retained <b>data</b> by encrypting the information and protecting (Recommendation 42) ...|$|R
50|$|MSL {{can also}} provide design {{services}} for complex mechanical structures for various marine applications. MSL can provide services for measurement of acoustic signatures of ships and submarines. Special arrangements {{can be made with}} the user to assure security and <b>confidentiality</b> <b>of</b> <b>data.</b>|$|E
5000|$|For {{industries}} that must maintain strict <b>confidentiality</b> <b>of</b> <b>data,</b> NextLabs solutions address specific industry and compliance requirements, {{and provide a}} complete approach to information risk management by eliminating policy silos and controlling information exposure, {{inside and outside the}} enterprise. NextLabs offer the following types of solutions: ...|$|E
50|$|Several US federal {{agencies}} have privacy statutes that cover their collection {{and use of}} private information. These include the Census Bureau, the Internal Revenue Service, and the National Center for Education Statistics (under the Education Sciences Reform Act). In addition, the CIPSEA statute protects <b>confidentiality</b> <b>of</b> <b>data</b> collected by federal statistical agencies.|$|E
30|$|Encryption {{of network}} traffic, {{especially}} the payload, {{to protect the}} integrity and <b>confidentiality</b> <b>of</b> the <b>data</b> in the packets traversing the network.|$|R
40|$|A natural {{strategy}} {{to protect the}} <b>confidentiality</b> <b>of</b> individual <b>data</b> is to aggregate them at the lowest possible level. Some studies realised in Eurostat on this topic will be presented: properties of classifications in clusters of fixed sizes, micro-aggregation as a generic method to protect the <b>confidentiality</b> <b>of</b> individual <b>data,</b> application to the Community Innovation Survey. The work performed in Eurostat will be put in line with other projects conducted at European level on the topic <b>of</b> statistical <b>confidentiality...</b>|$|R
40|$|Abstract. The {{exponential}} growth of databases containing personal information has rendered {{the task of}} extracting high quality information from collections of such databases very important. This task is hindered by the security concerns that arise, due to the <b>confidentiality</b> <b>of</b> the <b>data</b> records, and the reluctance of the organizations to disclose their data. This paper proposes a clustering algorithmic scheme that ensures privacy and <b>confidentiality</b> <b>of</b> the <b>data</b> without compromising {{the effectiveness of the}} clustering algorithm nor imposing high communication costs. ...|$|R
50|$|The main law {{governing}} {{the work of}} the C&SD is the Census and Statistics Ordinance, which provides for the taking of a census of population and the collection, compilation and publication of statistical information concerning Hong Kong and for matters connected therewith. The Ordinance also provides strict safeguards on the <b>confidentiality</b> <b>of</b> <b>data</b> pertaining to individuals or undertakings.|$|E
50|$|The {{geographic}} location of data helps determine privacy and confidentiality. The location of clients {{should be taken}} into account. For example, clients in Europe won't be interested in using datacenters located in United States, because that affects the guarantee of the <b>confidentiality</b> <b>of</b> <b>data.</b> In order to deal with that problem, some cloud computing vendors have included the {{geographic location}} of the host as a parameter of the service-level agreement made with the customer, allowing users to choose themselves the locations of the servers that will host their data.|$|E
5000|$|Although {{there are}} many {{benefits}} to video ethnography, there are also important issues that arise {{from the use of}} videos. For instance, there are numerous ethical issues regarding the privacy of research participants or subjects. Schaeffer addresses the issues of voluntary consent and <b>confidentiality</b> <b>of</b> <b>data.</b> Voluntary consent is the control of involvement in the research lying firmly with the participant who needs complete knowledge of the research and its goals to exercise this control properly. There must also be mutual trust and respect between the researchers and the participants. Confidentiality implies the proper use of the gathered data as to maintain the highest degree of confidentiality possible while also maintaining the integrity of the research. Schaeffer provides three requirements to prevent the misuse of ethnographic videos: ...|$|E
30|$|According to the <b>confidentiality</b> <b>of</b> the <b>data</b> base <b>of</b> {{the central}} {{pharmacy}} under study, several cases of problem were considered for which several instances were generated randomly.|$|R
40|$|Abstract: In today’s {{computer}} world security, integrity, <b>confidentiality</b> <b>of</b> the organization’s <b>data</b> is {{the most}} important issue. This paper deals with the <b>confidentiality</b> <b>of</b> the <b>data</b> that organization manages and works with. This paper proposes a new approach to data security using the concept of genetic algorithm and brain mu waves with pseudorandom binary sequence to encrypt and decrypt the <b>data.</b> The feature <b>of</b> such an approach includes high data security and high feasibility for practical implementation...|$|R
30|$|This {{work had}} the {{approval}} from Research and Ethical committee of Faculty of Medicine, Assiut University. Informed consent {{was taken from}} all individuals {{who participated in the}} study. <b>Confidentiality</b> <b>of</b> the <b>data</b> was guaranteed.|$|R
50|$|The {{reflections}} {{gathered from}} curved surfaces on close-by objects indeed pose a substantial {{threat to the}} <b>confidentiality</b> <b>of</b> <b>data</b> displayed on the screen. Fully invalidating this threat without {{at the same time}} hiding the screen from the legitimate user seems difficult, without using curtains on the windows or similar forms of strong optical shielding. Most users, however, will not be aware of this risk and may not be willing to close the curtains on a nice day. The reflection of an object, a computer display, in a curved mirror creates a virtual image that is located behind the reflecting surface. For a flat mirror this virtual image has the same size and is located behind the mirror at the same distance as the original object. For curved mirrors, however, the situation is more complex.|$|E
50|$|Census and Statistics Ordinance, {{which was}} first {{effective}} in 1978, {{is the main}} law governing {{the work of the}} Census and Statistics Department. The Ordinance provides for the taking of a census of population and the collection, compilation and publication of statistical information concerning Hong Kong and for matters connected therewith. It also provides strict safeguards on the <b>confidentiality</b> <b>of</b> <b>data</b> pertaining to individuals or undertakings. For example, CAP. 316 S Census and Statistics (2001 Population Census) Order and CAP. 316 U Census and Statistics (2006 Population Census) Order ordered the Commissioner shall take a census of population in specified period to obtain particulars of persons dwelling in Hong Kong. In particular, Section 4 stated that each person aged 15 or above occupying any premises subject to census shall give to the Commissioner particulars of the matters specified in the Ordinance.|$|E
30|$|<b>Confidentiality</b> <b>of</b> <b>Data.</b>|$|E
40|$|The {{application}} <b>of</b> <b>data</b> mining {{techniques to}} health-related data is beneficial to medical research. However, the use <b>of</b> <b>data</b> mining or knowledge discovery in databases, and data matching and profiling techniques, raises ethical concerns relating to consent and undermines the <b>confidentiality</b> <b>of</b> medical <b>data.</b> Data mining and data matching requires active {{collaboration between the}} medical practitioner and the data miner. This article examines the ethical management <b>of</b> medical <b>data</b> including personal information and sensitive information in the healthcare sector. It offers some ethical and legal perspectives on privacy and the <b>confidentiality</b> <b>of</b> medical <b>data.</b> It examines the International landscape of health information privacy protection, relevant Australian legislation and recommendations to improve the ethical handling <b>of</b> medical <b>data</b> proposed by the Australian Law Reform Commission...|$|R
30|$|Ethical {{approval}} {{was obtained}} from Samara University’s ethical review committee. Written permission was given from the Afar Regional Health Bureau. Informed consent {{was obtained from}} the interviewee mothers after explaining the purpose and <b>confidentiality</b> <b>of</b> the <b>data.</b>|$|R
30|$|Achieving {{plausible}} deniability {{and secure}} deletion {{in a single}} system. Most of the existing systems either provide deniability or achieve secure deletion. However, data confidentiality should be simultaneously ensured {{during and after the}} lifetime <b>of</b> the <b>data,</b> because: First, by recovering the data being deleted, the adversary can achieve a similar gain comparable to compromising <b>confidentiality</b> <b>of</b> the <b>data</b> being stored; Second, if the <b>confidentiality</b> <b>of</b> the <b>data</b> cannot be ensured during their lifetime, secure deletion (i.e., ensuring <b>confidentiality</b> <b>of</b> the <b>data</b> after their lifetime) turns meaningless since the adversary has already obtained the data before they are “securely” removed. Therefore, we expect a system which can achieve both plausible deniability and secure deletion. Simply combining the existing PDE and secure deletion may be problematic, since secure deletion may require a fine-grained encryption mechanism, and plausibly deniable encryption is not necessarily designed as fine-grained. In addition, when pre-processing data for secure deletion purpose, careful consideration may be needed to avoid bringing in any deniability compromises. The only attempt for this type of system is DEFY (Peters et al. 2015), but DEFY itself may suffer from deniability compromise (Jia et al. 2017).|$|R
30|$|A {{retrieval}} {{scheme is}} proposed to answer queries over encrypted data at the CSP, ensuring <b>confidentiality</b> <b>of</b> <b>data</b> outsourced by the DO.|$|E
30|$|With {{the above}} two {{criteria}} strictly enforced, the proposed {{approach would be}} able to ensure the <b>confidentiality</b> <b>of</b> <b>data.</b> This is achieved without encrypting the data.|$|E
40|$|Abstract—The {{diffusion}} of cloud database services {{requires a lot}} of efforts to improve <b>confidentiality</b> <b>of</b> <b>data</b> stored in external infrastructures. We propose a novel scheme that integrates data encryption with users access control mechanisms. It can be used to guarantee <b>confidentiality</b> <b>of</b> <b>data</b> with respect to a public cloud infrastructure, and to minimize the risks of internal data leakage even in the worst case of a legitimate user colluding with some cloud provider personnel. The correctness and feasibility of the proposal is demonstrated through formal models, while the integration in a cloud-based architecture is left to future work. I...|$|E
30|$|All {{students}} were asked to participate voluntarily in the study and, were informed that the study regarded happiness. After we had their consent, guaranteed the anonymity and <b>confidentiality</b> <b>of</b> their <b>data</b> and explained to them the possibility of withdrawal, we proceeded with the collection <b>of</b> <b>data.</b>|$|R
30|$|No {{sensitive}} {{questions were}} included in the study. Risk factors for transmission and preventive measures were explained in a simple way to children. Medical advice and treatment were offered for free to the affected children. <b>Confidentiality</b> <b>of</b> all <b>data</b> was assured.|$|R
40|$|The {{difficult}} conciliation {{between the}} protection of the right to respect for private life, specially the <b>confidentiality</b> <b>of</b> personal <b>data,</b> and the rights to protection of copyright and to an effective remedy is the key issue decided by the Judgment of the Court of Justice in Case C- 275 / 06, Promusicae. In order to safeguard other persons’ rights, the Court approves of limits to the privacy and these limits are sanctioned to damage the <b>confidentiality</b> <b>of</b> personal <b>data,</b> generated by the traffic in the electronic communications. In our opinion, in spite of the Court’s praiseworthy efforts to balancing the rights concerned, the judgement creates an instrument that entails a danger for freedom...|$|R
30|$|Confidentiality-related risks arise between IoT {{devices and}} the {{gateways}} {{in the network}} layer. The resource-constrained nature of the low-level devices in IoT systems poses an indirect challenge {{with regard to the}} <b>confidentiality</b> <b>of</b> <b>data</b> transmission in IoT networks [35].|$|E
40|$|International audienceCloud {{computing}} is a {{new paradigm}} providing software and hardware resources according to the customers' needs. However, it introduces new security risks such as <b>confidentiality</b> <b>of</b> <b>data</b> stored in cloud databases. Actually, this last risk is a crucial issue {{that must be addressed}} as ciphering mechanisms are not sufficient to guarantee a strong <b>confidentiality</b> <b>of</b> <b>data.</b> In this paper, we discuss the main cloud computing security risks and focus on the data confidentiality problem in the context of e-commerce clouds. We describe the design of a data concealment component that we propose to resolve this problem. Evaluating this component, we find that it successfully conceal data of legitimate users and protect them against potential attacks...|$|E
40|$|Protecting <b>confidentiality</b> <b>of</b> <b>data</b> {{has become}} {{increasingly}} important for computing systems. Information-flow techniques have been developed {{over the years to}} achieve that purpose, leading to special-purpose languages that guarantee information-flow security in programs. However, rather than producing a new language from scratch, information-flow security can also be provided as a library. This has been done previously in Haskell using the arrow framework. In this paper, we show that arrows are not necessary to design such libraries and that a less general notion, namely monads, is sufficient to achieve the same goals. We present a monadic library to provide information-flow security for Haskell programs. The library introduces mechanisms to protect <b>confidentiality</b> <b>of</b> <b>data</b> for pure computations, that we then easily, and modularly, extend to include dealing with side-effects. We also present combinators to dynamically enforce different declassification policies when release of information is required in a controlled manner. It is possible to enforce policies related to what, by whom, and when information is released or a combination of them. The well-known concept of monads together with the light-weight characteristic of our approach makes the library suitable to build applications where <b>confidentiality</b> <b>of</b> <b>data</b> is an issue...|$|E
5000|$|For {{encryption}} and decryption <b>of</b> the <b>data</b> flow (and hence {{for providing}} <b>confidentiality</b> <b>of</b> the <b>data</b> flow), SRTP (together with SRTCP) utilizes AES as the default cipher. There are two cipher modes defined which allow the original block cipher AES {{to be used}} as a stream cipher: ...|$|R
40|$|Abstract. The {{automatic}} dependent surveillance-broadcast (ADS-B) {{system is}} {{the backbone of the}} next-gen air traffic control (ATC) modernization plan. Unfortunately, ADS-B system suffers from serious cyber-security vulnerabilities due to the open broadcast <b>of</b> aircraft <b>data,</b> without regard to message confidentiality. However, using common encryption scheme to provide <b>confidentiality</b> <b>of</b> ADS-B <b>data</b> is not a good solution, because encrypting data with ordinary cryptosystem would violate the original openness intention of ADS-B system design. In this paper, based on the new format-preserving encryption (FPE), we present an efficient data encryption scheme for the ADS-B data. The security analysis demonstrates that our scheme can achieve <b>confidentiality</b> <b>of</b> ADS-B <b>data.</b> The performance evaluation shows that the scheme is computationally efficient for the typical avionics devices with limited resources...|$|R
30|$|Binding Key Creation. To ensure <b>confidentiality</b> <b>of</b> {{sensitive}} <b>data,</b> images sent by {{the camera}} to the CS have to be encrypted. This encryption can be done for full images or special regions of interest where, for example, motion or faces have been detected.|$|R
