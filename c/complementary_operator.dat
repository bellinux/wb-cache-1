5|29|Public
5000|$|... are points x {{for which}} f(x) attains its {{smallest}} value. The <b>complementary</b> <b>operator</b> is argmax.|$|E
40|$|Morphological image {{processing}} filters preserve shapes {{related to the}} structuring element shape of the operator. The basic morphological operators are minimum (erosion) and maximum (dilation) operations performed on the pixels within a structuring element. Although these operators (and the compound operators formed from them) are able to smooth noise, they also introduce a statistical and deterministic bias, which is unacceptable in some applications. However, since every morphological operator has a <b>complementary</b> <b>operator</b> that is equally and oppositely biased, we propose averaging the complementary operators to alleviate the bias. Of the three filters formed by averaging the standard morphological operators, two are the previously-defined midrange filter and pseudomedian filter, while one is a new filter, which we call the LOCO filter. Under most conditions, the LOCO filter {{is the best of}} these at reducing impulses and noise...|$|E
40|$|Abstract. Recently, we {{introduced}} a morphological texture contrast (MTC) operator that allows detection of textural and non-texture regions in images. In this paper we provide {{comparison of the}} MTC with other available techniques. We show that, in contrast to other approaches, the MTC discriminates between texture details and isolated features, and does not extend borders of texture regions. Using the ideas underlying the MTC operator, we develop a <b>complementary</b> <b>operator</b> called morphological feature contrast (MFC) that allows extraction of isolated features while not being confused by texture details. We illustrate an application of the MFC operator for extraction of isolated objects such as individual trees or buildings that should be distinguished from forests or urban centers. We furthermore provide {{an example of how}} this operator can be used for detection of isolated linear structures. We also derive an extended version of the MFC that works with vector-valued images. ...|$|E
40|$|The {{recently}} developed concurrent <b>complementary</b> <b>operators</b> method (C-COM) for mesh truncation of finitedifference time-domain (FDTD) problems {{has been shown}} to produce a substantial improvement in differential equationbased absorbing boundary conditions (ABC's). In this letter, the C-COM and the perfectly matched layer (PML) approachs are compared using two-dimensional problems. Two representative geometries are considered that address the absorption of evanescent waves and waves traveling at near-grazing incidence. It is found that the C-COM yields significant improvements over the PML solution for these geometries...|$|R
40|$|We present {{algebraic}} multilevel iteration (AMLI) {{methods for}} isogeometric discretization of scalar second order elliptic problems. The construction of coarse grid <b>operators</b> and hierarchical <b>complementary</b> <b>operators</b> are given. Moreover, for a uniform mesh on a unit interval, the explicit representation of B-spline basis functions for a fixed mesh size $h$ is given for $p= 2, 3, 4 $ and for $C^{ 0 }$- and $C^{p- 1 }$-continuity. The presented methods show $h$- and (almost) $p$-independent convergence rates. Supporting numerical results for convergence factor and iterations count for AMLI cycles ($V$-, linear $W$-, nonlinear $W$-) are provided. Numerical tests are performed, in two-dimensions on square domain and quarter annulus, and in three-dimensions on quarter thick ring. Comment: 27 pages, 16 tables, 2 figure...|$|R
40|$|The <b>complementary</b> <b>operators</b> method (COM) has {{recently}} been introduced as a meshtruncation technique for open-domain radiation problems in electromagnetics. The COM entails the construction of two solutions that employ absorbing boundary conditions (ABCs) with complementary behavior, i. e., the reflection coefficients associated with the two ABCs are exactly opposite each other. The average of these solutions then yields a new solution in which the errors caused by artificial reflections from the termination of grid are nearly eliminated. In this work, we introduce COM for the finite-difference time-domain (FDTD) solution of acoustics problems. The development of COM is presented in terms of Higdon's absorbing boundary operators, but generalization to non-Higdon operators is straightforward. The effectiveness of COM in comparison to other absorbing boundary conditions is demonstrated with numerical experiments in two and three dimensions...|$|R
40|$|We {{present a}} {{morphological}} texture contrast (MTC) operator that allows detection of textural and non texture regions in images. We {{show that in}} contrast to other approaches, the MTC discriminates between texture details and isolated features and does not extend borders of texture regions. A comparison with other methods used for texture detection is provided. Using the ideas underlying the MTC operator, we develop a <b>complementary</b> <b>operator</b> called morphological feature contrast (MFC) that allows extraction of isolated features while not being confused by texture details. We illustrate an application of the MFC operator to extraction of isolated objects such as individual trees or buildings that should be distin guished from forests or urban centers. We also propose an MFC based detector of isolated linear features and compare it with an alternative approach used for detection of edges and lines in cluttered scenes. We furthermore derive an extended version of the MFC that can be directly applied to vector valued images. 1...|$|E
40|$|International audienceFeature models (FMs) are {{a popular}} {{formalism}} for describing the commonality and variability of software product lines (SPLs) {{in terms of}} features. SPL development increasingly involves manipulating many large FMs, and thus scalable modular techniques that support compositional development of complex SPLs are required. In this paper, we describe how a set of <b>complementary</b> <b>operators</b> (aggregate, merge, slice) provides practical support for separation of concerns in feature modeling. We show how {{the combination of these}} operators can assist in tedious and error prone tasks such as automated correction of FM anomalies, update and extraction of FM views, reconciliation of FMs and reasoning about properties of FMs. For each task, we report on practical applications in different domains. We also present a technique that can efficiently decompose FMs with thousands of features and report our experimental results...|$|R
40|$|International audienceAbstract: In this article, we {{describe}} speciﬁc constraints of vision {{systems that are}} dedicated to be embedded in mobile robots. If PC based hardware architecture is convenient in this ﬁeld because of its versatility, its ﬂexibility, its performance and its cost, current real-time operating systems are not completely adapted to long processings with varying duration, and it is often necessary to oversize the system to guarantee fail-safe functioning. Also, interactions with other robotic tasks having more priority are diﬃcult to handle. To answer this problem, we have developed a dynamically reconﬁgurable vision processing system, based on the innovative features of Cl´eopatre real-time applicative layer concerning scheduling and fault tolerance. This framework allows to deﬁne emergency and optional tasks to ensure a minimal quality of service for the other subsystems of the robot, while allowing to adapt dynamically vision processing chain to an exceptional overlasting vision process or processor overload. Thus it allows a better cohabitation of several subsystems in a single hardware, and to develop less expensive but safe systems, as they will be designed for the regular case and not rare exceptional ones. At last, it brings {{a new way to}} think and develop vision systems, with pairs of <b>complementary</b> <b>operators...</b>|$|R
40|$|Coherent states (CS) for non-Hermitian {{systems are}} {{introduced}} as eigenstates of pseudo-Hermitian boson annihilation operators. The set of these CS includes two subsets which form bi-normalized and bi-overcomplete system of states. The subsets consist of eigenstates of two complementary lowering pseudo-Hermitian boson operators. Explicit constructions are provided on {{the example of}} one-parameter family of pseudo-boson ladder operators. The wave functions of the eigenstates of the two <b>complementary</b> number <b>operators,</b> which form a biorthonormal system of Fock states, {{are found to be}} proportional to new polynomials, that are bi-orthogonal and can be regarded as a generalization of standard Hermite polynomials. ...|$|R
50|$|Although Wi-Fi and WiMAX are {{designed}} for different situations, they are <b>complementary.</b> WiMAX network <b>operators</b> typically provide a WiMAX Subscriber Unit that connects to the metropolitan WiMAX network and provides Wi-Fi connectivity within the home or business for computers and smartphones. This enables the user to place the WiMAX Subscriber Unit in the best reception area, such as a window, and have date access throughout their property.|$|R
40|$|AbstractThe present paper {{deals with}} a minimal {{extension}} of the classical semigroup theory for second-order damped differential equations in Banach spaces with closed, densely defined linear operators as coefficients. We do not ask anymore from our operators than {{in the case of}} first-order equations, i. e., semigroups. We present here generalizations of the Miyadera–Phillips–Feller theorem, the Hille type theorem, and the Trotter–Kato type theorem. The method is quite general and could be used for equations of any order. We focus our attention on a particular dynamical operator solution or main propagator and we assume some properties about it. From this we can obtain some information about the <b>complementary</b> basis <b>operator</b> solutions or secondary propagators...|$|R
40|$|The density matrix {{renormalization}} group (DMRG) {{has become}} an indispensable numerical tool to find exact eigenstates of finite-size quantum systems with strong correlation. In the fields of condensed matter, nuclear structure and molecular electronic structure, it has significantly extended the system sizes that can be handled compared to full configuration interaction, without losing numerical accuracy. For quantum chemistry (QC), the most efficient implementations of DMRG require the incorporation of particle number, spin and point group symmetries in the underlying matrix product state (MPS) ansatz, {{as well as the}} use of so-called <b>complementary</b> <b>operators.</b> The symmetries introduce a sparse block structure in the MPS ansatz and in the intermediary contracted tensors. If a symmetry is non-abelian, the Wigner-Eckart theorem allows to factorize a tensor into a Clebsch-Gordan coefficient and a reduced tensor. In addition, the fermion signs have to be carefully tracked. Because of these challenges, implementing DMRG efficiently for QC is not straightforward. Efficient and freely available implementations are therefore highly desired. In this work we present CheMPS 2, our free open-source spin-adapted implementation of DMRG for ab initio QC. Around CheMPS 2, we have implemented the augmented Hessian Newton-Raphson complete active space self-consistent field method, with exact Hessian. The bond dissociation curves of the 12 lowest states of the carbon dimer were obtained at the DMRG(28 orbitals, 12 electrons, D_SU(2) = 2500) /cc-pVDZ level of theory. The contribution of 1 s core correlation to the X^ 1 Σ_g^+ bond dissociation curve of the carbon dimer was estimated by comparing energies at the DMRG(36 o, 12 e, D_SU(2) = 2500) /cc-pCVDZ and DMRG-SCF(34 o, 8 e, D_SU(2) = 2500) /cc-pCVDZ levels of theory. Comment: 16 pages, 13 figure...|$|R
40|$|We {{consider}} the thermal properties of IIA string theory on the pp-wave {{which comes from}} the circle compactification of the maximally supersymmetric eleven dimensional pp-wave. The one-loop free energy is computed and Hagedorn temperature is found {{as a function of}} the RR-flux μ. In the μ→∞ limit, the free energy is shown to be identical with that of IIB string theory on maximally supersymmetric pp-wave. We use two <b>complementary</b> approaches, <b>operator</b> and path integral methods. Several points, including the zero point energy and the modular properties of the free energy, are more illuminating and transparent in the path integral method. We find the complete agreement between those two approaches in the free energy expression and the dependency of the Hagedorn temperature on the RR-flux...|$|R
40|$|This {{thesis is}} aimed at {{analysis}} of sampled-data feedback systems. Our approach is in the frequency-domain, and stresses the study of sensitivity and <b>complementary</b> sensitivity <b>operators.</b> Frequency-domain methods have proven very successful in the analysis and design of linear time-invariant control systems, for which the importance and utility of sensitivity operators is well-recognized. The extension of these methods to sampled-data systems, however, is not straightforward, since they are inherently time-varying due to the intrinsic sample and hold operations. In this thesis we present a systematic frequency-domain framework to describe sampled-data systems considering full-time information. Using this framework, we develop a theory of design limitations for sampled-data systems. This theory allows us to quantify the essential constraints in design imposed by inherent open-loop characteristics of the analog plant. Our results show that: (i) sampled-data systems inherit the difficulty imposed upon analog feedback design by the plant's non-minimum phase zeros, unstable poles, and time-delays, independently {{of the type of}} hold used; (ii) sampled-data systems are subject to additional design limitations imposed by potential non-minimum phase zeros of the hold device; and (iii) sampled-data systems, unlike analog systems, are subject to limits upon the ability of high compensator gain to achieve disturbance rejection. As an application, we quantitatively analyze the sensitivity and robustness characteristics of digital control schemes that rely on the use of generalized sampled-data hold functions, whose frequency-response properties we describe in detail. In addition, we derive closed-form expressions to compute the L 2 -induced norms of the sampled-data sensitivity and <b>complementary</b> sensitivity <b>operators.</b> These expressions are important both in analysis and design, particularly when uncertainty in the model of the plant is considered. Our methods provide some interesting interpretations in terms of signal spaces, and admit straightforward implementation in a numerically reliable fashion. PhD Doctorat...|$|R
40|$|From the Rodrigues {{representation}} of polynomial eigenfunctions {{of a second}} order linear hypergeometric-type differential (difference or q-difference) <b>operator,</b> <b>complementary</b> polynomials for classical orthogonal polynomials are constructed using a straightforward method. Thus a generating function in a closed form is obtained. For the complementary polynomials we present a second order linear hypergeometric-type differential (difference or q-difference) operator, a three-term recursion and Rodrigues formulas which extend the results obtained by H. J. Weber for the standard derivative operator...|$|R
40|$|Abstract: In this {{preprint}} {{we investigate}} connection between boundary problems for general linear systems of difference equations and Ryaben'kii's difference potentials and boundary projections. A concept of <b>complementary</b> boundary value <b>operators</b> is introduced and, bearing on it, {{a class of}} so called generalized difference Poincare-Steklov operators is characterized for difference systems of considered type. Representation of the action of generalized Poincare-Steklov is obtained in terms of boundary projections and operators of boundary conditions for some well-posed difference boundary-value problems. Note: Publication language:russia...|$|R
40|$|This paper {{develops}} complementarity constraints for nonlinear {{feedback control}} systems with additive output disturbances and sensor noise, and for nonlinear filtering {{in the presence}} of process noise and additive measurement noise. In the control case, the complementarity constraint is the nonlinear counterpart of the well known fact in linear feedback control theory that the sum of the sensitivity <b>operator,</b> S(s), and <b>complementary</b> sensitivity <b>operator,</b> T (s), is the identity operator. Performance limitations induced by this nonlinear complementarity constraint in the case of open loop unstable and non-minimum phase plants are explored. Keywords. Complementarity Constraints, Nonlinear Systems, Open Loop Unstable Systems, Non-Minimum Phase Systems, Performance limits. 1 COMPLEMENTARITY CONSTRAINTS AND PERFORMANCE LIMITS: FROM LINEAR TO NONLINEAR When designing a controller or a filter for a certain process, it is desirable to recognize, a priori, the limitations in achievable perfor [...] ...|$|R
40|$|The Breeder Genetic Algorithm BGA models {{artificial}} selection as performed by human breeders. The science of breeding {{is based on}} advanced statistical methods. In this paper a connection between genetic algorithm theory and the science of breeding is made. We show how the response to selection equation {{and the concept of}} heritability can be applied to predict the behavior of the BGA. Selection, recombination and mutation are analyzed within this framework. It is shown that recombination and mutation are <b>complementary</b> search <b>operators.</b> The theoretical results are obtained under the assumption of additive gene effects. For general fitness landscapes regression techniques for estimating the heritability are used to analyze and control the BGA. The method of decomposing the genetic variance into an additive and a nonadditive part connects the case of additive fitness functions with the general case...|$|R
40|$|Relational Lattice is a succinct {{mathematical}} model for Relational Algebra. It reduces {{the set of}} six classic relational algebra operators to two: natural join and inner union. In this paper we push relational lattice theory in two directions. First, we uncover a pair of <b>complementary</b> lattice <b>operators,</b> and organize the model into a bilattice of four operations and four distinguished constants. We take a notice a peculiar way bilattice symmetry is broken. Then, we give axiomatic introduction of unary negation operation and prove several laws, including double negation and De Morgan. Next we reduce the model back to two basic binary operations and twelve axioms, and exhibit a convincing argument that the resulting system is complete in model-theoretic sense. The final parts of the paper casts relational lattice perspective onto database dependency theory and into cylindric algebras. Comment: 15 page...|$|R
40|$|In open-region {{electromagnetic}} simulations, the computational domain {{has to be}} truncated by an absorbing {{boundary condition}} (ABC) to model the infinite space. The performance of ABC strongly affects the accuracy of overall numerical simulation. For a class of advanced problems demanding high accuracy, {{such as in the}} modeling of medical detection devices, indoor wireless communication systems and remote sensing equipments, the received signal can be several orders of magnitude less than the transmitted signal. Furthermore, wide-band simulations require long running times for transients-based simulations, which increase the potential for instability. Therefore, accuracy and stability of absorbing boundary conditions are identified as critical in the design of numerical algorithms compatible with advanced applications. In this work, theory of Concurrent <b>Complementary</b> <b>Operators</b> Method (C-COM) in both transient and frequency-domain numerical simulations is investigated. The C-COM is based on the basic premise of primary reflection cancellation. The C-COM applications to numerically derived ABCs in finite difference time-domain (FDTD) method, and to frequency domain ABCs in both finite difference frequency domain (FDFD) method and finite element method (FEM) method are developed. Extensive numerical experiments are conducted showing dramatic increase in accuracy when the C-COM is applied in comparison to previous published techniques. Previous works that addressed the boundary instability arising from the application of the absorbing boundary condition used either the von Neumann analysis or the Gustafsson-Kreiss-Sundström (GKS) analysis. These earlier works, however, did not explain the inconsistencies that have been observed between the theoretical predictions and numerical experiments. This thesis presents a new stability analysis applicable to boundary conditions. This new analysis, referred to as Coupled Stability Analysis (CSA), is based on the fundamental assumption that absorbing boundary conditions are not perfect, and therefore, generate waves that reflect back into the computational domain. It is found that this analysis yields results that are fully consistent with those obtained from numerical experiments. As an important consequence of this analysis, and contrary to earlier conjectures, we show that Higdon's absorbing boundary condition of order 3 (and possibly, higher orders) to be unconditionally unstable...|$|R
40|$|In the one-loop {{approximation}} for Euclidean quantum gravity, {{the boundary}} conditions which are completely invariant under gauge transformations of metric perturbations cannot {{be written in}} terms of <b>complementary</b> projection <b>operators.</b> By contrast, they express the h_{ 00 } and h_{ 0 i} perturbations at the boundary as integrals at the boundary of the action {{of a set of}} differential operators on metric perturbations. Hence they are non-local. The corresponding trace anomaly for pure gravity has been recently evaluated by means of analytic techniques. It now remains to compute the contribution of all perturbative modes of gauge fields and gravitation to the one-loop effective action for problems with boundaries. The functional determinant has a non-local nature, independently of boundary conditions. Moreover, the analysis of trace anomalies for pure gravity and supergravity with non-local boundary conditions has not yet been completed and is still under active investigation...|$|R
40|$|There is {{considerable}} {{interest in the}} use of genetic algorithms to solve problems arising in the areas of scheduling and timetabling. However, the classical genetic algorithm paradigm is not well equipped to handle the conflict between objectives and constraints that typically occurs in such problems. In order to overcome this, successful implementations frequently make use of problem specific knowledge. This paper is concerned with the development of a GA for a nurse rostering problem at a major UK hospital. The structure of the constraints is used as the basis for a co-evolutionary strategy using co-operating sub-populations. Problem specific knowledge is also used to define a system of incentives and disincentives, and a <b>complementary</b> mutation <b>operator.</b> Empirical results based on 52 weeks of live data show how these features are able to improve an unsuccessful canonical GA {{to the point where it}} is able to provide a practical solution to the proble...|$|R
40|$|It is {{well known}} that the edge vector space of an {{oriented}} graph can be decomposed in terms of cycles and cocycles (alias cuts, or bonds), and that a basis for the cycle and the cocycle spaces can be generated by adding and removing edges to an arbitrarily chosen spanning tree. In this paper we show that the edge vector space can also be decomposed in terms of cycles and the generating edges of cocycles (called cochords), or of cocycles and the generating edges of cycles (called chords). From this observation follows a construction in terms of oblique <b>complementary</b> projection <b>operators.</b> We employ this algebraic construction to prove several properties of unweighted Kirchhoff-Symanzik matrices, encoding the mutual superposition between cycles and cocycles. In particular, we prove that dual matrices of planar graphs have the same spectrum (up to multiplicities). We briefly comment on how this construction provides a refined formalization of Kirchhoff's mesh analysis of electrical circuits, which has lately been applied to generic thermodynamic networks...|$|R
40|$|One of the {{settings}} that most affect {{the performance of}} Evolutionary Algorithms is {{the selection of the}} variation operators that are efficient to solve the problem at hand. The control of these operators can be handled in an autonomous way, while solving the problem, at two different levels: at the structural level, when deciding which operators {{should be part of the}} algorithmic framework, referred to as Adaptive Operator Management (AOM); and at the behavioral level, when selecting which of the available operators should be applied at a given time instant, called as Adaptive Operator Selection (AOS). Both controllers guide their choices based on a common knowledge about the recent performance of each operator. In this chapter, we present methods for these two <b>complementary</b> aspects of <b>operator</b> control, the ExCoDyMAB AOS and the Blacksmith AOM, providing case studies to analyze them in order to highlight the major issues that should be considered for the design of more autonomous Evolutionary Algorithms...|$|R
40|$|Abstract—Two one-speed {{radiation}} transport equations cou-pled by {{a dynamic}} equation for {{the distribution of}} fluorophore electronic states are used to model the migration of excitation photons and emitted fluorescence photons. The conditions for producing appreciable levels of fluorophore in the excited state are studied, with the conclusion that minimal saturation occurs under the conditions applicable to tissue imaging. This simplifies the derivation of the frequency response and of the imaging operator for a time-harmonic excitation source. Several factors known to influence the fluorescence response—the concentration, mean lifetime and quantum yield of the fluorophore, and the modulation frequency of the excitatory source—are examined. Optimal sensitivity conditions are obtained by analyzing the fluorescence source strength {{as a function of}} the mean lifetime and modulation frequency. The dependence of demodulation of the fluorescent signal on the above factors is also examined. In <b>complementary</b> studies, transport-theory-based <b>operators</b> for imaging fluorophore distributions in a highly scattering medium are derived. Experimental data were collected by irradiating a cylindrical phantom containing one or two fluorophore-filled balloons with continuous wave laser light. The reconstruction results show that qualitatively and quantitatively good images can be obtained, with embedded objects accurately located and the fluorophore concentration correctly determined. Index Terms — Image reconstruction, luminescent materials/ devices, optical imaging, random media, tomography...|$|R
40|$|For gasless {{combustion}} in a one-dimensional solid, we show {{a type of}} nonlinear {{stability of}} the physical combustion front: if a perturbation of the front is small in both a spatially uniform norm and an exponentially weighted norm, then the perturbation stays small in the spatially uniform norm and decays in the exponentially weighted norm, provided the linearized operator has no eigenvalues in the right half-plane other than zero. Using the Evans function, we show that the zero eigenvalue must be simple. Factors that complicate the analysis are: (1) the linearized operator is not sectorial, and (2) the linearized operator has good spectral properties only when the weighted norm is used, but then the nonlinear term is not Lipschitz. The result is nevertheless physically natural. To prove it, we first show that when the weighted norm is used, the semigroup generated by the linearized operator decays on a subspace <b>complementary</b> to the <b>operator’s</b> kernel, by showing {{that it is a}} compact perturbation of the semigroup generated by a more easily analyzed triangular operator. We then use this result to help establish that solutions stay small in the spatially uniform norm, which in turn helps establish nonlinear convergence in the weighted norm...|$|R
40|$|This paper {{proposes a}} new {{approach}} based on quantum inspired evolutionary algorithm (QIEA) for effective selection and definition of fuzzy if-then control rules {{as well as the}} shapes of membership functions (MFs) to design fuzzy logic controllers (FLCs). The majority of works done on designing FLCs rely on the knowledge base derived from imprecise heuristic knowledge of experienced operators or persons. These traditional methods, however, are cumbersome to implement and very time consuming to evaluate. Our proposed approach is a self-learning adaptive method and decomposes a problem {{in such a way that}} leads to more effective knowledge acquisition and improved control performance with the FLCs. In order to verify the effectiveness of this self-learning adaptive method, a standard test-bed, the truck backer-upper problem, is considered as the test problem. During each generation, the rules are updated and the MFs&rsquo; parameters are altered using a <b>complementary</b> double mutation <b>operator</b> (CDMO) and a discrete crossover (DC). This paper also demonstrates the effect of different fuzzification and defuzzification methods on the response of the FLC. The center of gravity (COG) and modified COG are used as defuzzifier to analyze the results of the fuzzy controller. The experimental results show that the proposed approach with different fuzzification and MCOG to design FLCs performs better than the traditional methods with triangular fuzzification and COG in terms of required time to backing up the truck...|$|R
40|$|In many countries, {{including}} some developed ones, freight forwarders are neither' defined nor regulated and therefore {{suffer from a}} lack of identity in their promotional and regulatory framework. In the absence of internationally recognized definitions, the use of expressions such as "Freight Forwarders" or "international Freight Forwarders" is consequently a frequent cause of misunderstanding -and confusion. The recent use of the expression ''Multimodal Transport Operator" (MTO), introduced in the UN Convention on International Multimodal Transport, further increased the confusion. They are today increasingly taking a carrier's responsibility of offering door-to-door transport operations and, by doing so; they are becoming multimodal transport operators. At the time when international transport was confined to port-to-port operations, freight forwarders were considered as subordinates of shipping companies and their agents. With the advent of containerization and the growing demand for tailored transport services, freight forwarders started identifying their role as <b>complementary</b> to modal <b>operators</b> by securing certain continuity in the intermodal movement of goods across borders. Today, they are becoming carriers and their profession is now essential to the international trade of a country. As a first-step towards Solving the Human Resource and Institutional Development (HRID) and training problems in freight forwarding is the preparation of this document. This document, in a guideline format, looks into ways and means to improve the human resource and institutional development of an important profession supporting both the trade and transport sectors of country - freight forwarding...|$|R
40|$|Nonmonotonic logics are logics {{capable of}} formalizing defeasible inferences, i. e. inferences leading to {{conclusions}} that are withdrawn in case additional information, or additional premises, contradicts the defeasible conclusion. In other terms, {{the set of}} defeasible conclusions does not increase by incrementing the set of beliefs, it might rather decrease. In 1990, H. J. Levesque introduced a modal logic of belief capable of formalizing defeasible reasoning. There are two keys in his system that make the formalism possible. First, {{the introduction of a}} <b>complementary</b> belief <b>operator</b> that, combined with the usual belief operator, make it possible to express the exact content of an agent’s beliefs. Second, an axiom schema stating that a proposition is a logical possibility, provided that the proposition is consistent in the framework. The condition that the proposition is consistent in the framework causes the logic to not being closed under uniform substitution. Moreover, the mentioned axiom means that the reasoning is carried out not entirely at the object level. Motivated by, among others, these points of criticism, Arild Waaler, dep. of Informatics, University of Oslo, introduced a logic of belief where the axiom of Levesque is replaced by a particular formula, the logical space, from which the logical possibilities, and necessities are derived entirely at the object level. This also has the effect that the notion of necessity is a notion of personal necessity. I. e. necessity surpasses the level of analytic relations between concepts. This thesis aims at generalizing the notions of Waaler to the multi-agent case. The advantages of operating with a logical space in place of a multi-modal Levesque axiom are many. First, the advantages given for the single-modality case hold for the multi-agent case also. Second, and more importantly, the condition that the axiom of Levesque applies to consistent formulae is highly problematic in the multi-modal context. In the single agent case, this formula is of the language of propositional language, and the question of consistency is a propositional logical question. This is not the case in the multi-modal context, because the axiom says that a formula not mentioning the beliefs of a given agent is a logical possibility of this agent. But the formula is in general a modal formula, and the question of consistency of this formula must be solved within the multi-modal axiom system. Intrinsic to this is a danger of a vicious circularity, but by replacing the axiom with a logical space, we are able to go around this problem. However, the construction of a logical space for the multi-modal case is highly non-trivial. We {{need to be able to}} express every single possibility of what a state of affairs might be from a given agent point of view. In the multi-modal case, a state of affairs must capture the belief set of every agent, where these belief sets in turn involves expressions in the modal language. The construction of the logical space is core of the thesis. In general, the thesis provides a study of modal logics, defeasible logics, multi-modal logics and multi-modal defeasible logics. Additionally, a modal reduction theorem is presented, a result that proves the ability to reduce any belief representation to a set of representations, each explicitly expressing the belief set, and each compatible with the initial representation. Comparative studies, relating the system of this thesis to other formalisms are also provided. Finally, we suggest an extension of the system allowing the logical space to be deducible instead of explicitly given...|$|R
40|$|Executive Summary Numerous {{initiatives}} that are policy driven by national, European and global agencies target {{the preservation of}} our environment, human society’s health and our ecology. Ireland’s EPA 2020 Vision outlines a mandate {{to prepare for the}} unavoidable impact of climate change, the reduction of greenhouse gas (GHG) emissions, the control of air-emissions standards, the sustainable use of resources and the holding to account of those who flout environmental laws. These strategies are echoed in the Europe 2020 : Resource-efficient Europe Flagship Initiative, which also advocates the creation of new opportunities for economic growth and greater innovation. The promotion of research and technical development is central to each of these strategies – specifically the achievement of accurate environmental monitoring technologies that will inform policy-makers and effect change. This is described in the EPA Strategic Plan 2013 – 2015 as the provision of ‘high quality, targeted and timely environmental data, information and assessment to inform decision making at all levels’. Specific to landfills, the Environmental Protection Agency’s (EPA) Focus on Landfilling in Ireland stipulates the management of landfill gas to eliminate environmental harm and public nuisance, to promote energy generation where possible and to avoid liabilities in site closure and aftercare. It was in this context that the EPA STRIVE programme granted funding for this research project on developing autonomous sensor platforms for the real-time monitoring of gases generated in landfill facilities. Managing landfill gas is one of the crucial operations in a landfill facility, where gases (primarily methane [CH 4] and carbon dioxide [CO 2] generated from the decomposition of biodegradable waste) are extracted and combusted in a flare or preferably an engine (as biogas fuel). These gases, classified as greenhouse gases (GHGs), also pose localised hazards due to fire risk and asphyxiation, and are indicative of odorous nuisance compounds. Gas-monitoring on site is conducted to (i) ensure against gas migration into the local environment and to (ii) maintain the thorough gas extraction and optimum composition for combustion. This is becoming more relevant because of the numerous landfill closures brought by Europe-wide changes in waste-management policy. Even for landfills no longer actively receiving waste, substantial gas generation remains ongoing for years and even decades. Despite diminished financial resources and reduced manpower, management of this gas must be maintained. Traditionally, monitoring involves taking manual measurements using expensive handheld equipment and requiring laborious travel over difficult and expansive terrain. Consequently, it is conducted relatively infrequently – typically once a month. These issues can be addressed by adopting distributed continuous monitoring systems. These low-cost remotely deployable sensor platforms offer a valuable <b>complementary</b> service to <b>operators</b> and the EPA. They enable easier adherence to their licence criteria, the prevention of expensive remediation measures and the potential boost in revenue from increasing energy production through the use of biogas. Challenges arise in terms of achieving a long-term monitoring performance in a harsh environment while maintaining accuracy, reliability and cost-effectiveness. To meet these challenges, this project developed cost- effective autonomous sensor platforms to allow long- term continuous monitoring of gas composition (methane and carbon dioxide) and extraction pressure. The project’s work represents one of the only developments of autonomous sensor technology in this space; the few other market alternatives tend to be expensive or difficult to implement for remotely deployable continuous monitoring. Beyond the development of a platform technology, the challenge was to apply this technology to the adverse environmental conditions. The project delivered a total of 14 autonomous sensor platforms in deployments involving Irish landfill sites, a Scottish landfill site and a Brazilian wastewater treatment plant. The analysis and interpretation of acquired data, coupled with local meteorological data and on-site operational data, provided the translation from raw environmental data to meaningful conclusions that could inform decision-making. This report presents a number of case studies to illustrate this. Characteristics of site gas dynamics could be identified; for example, it was possible to show if excessive gas concentrations in a perimeter well could be resolved by increasing the flare extraction rate for a particular well. Furthermore, the potential for quantifying methane generation potential at distributed locations within the landfill was identified in addition to diagnosing the effectiveness of the extraction network – hence aiding in field-balancing and landfill gas utilisation. The extensive wealth of data enabled by this platform technology will help better-informed decision-making and improve operational practices in managing gas emissions. In landfills, this signifies alleviating gas migration with perimeter monitoring and enhancing flare/ engine operation by evaluating gas quality at distributed locations within the gas field. While landfilling is becoming outmoded as a waste-management process, the need for continuous monitoring will be relevant for many years to come. Indeed, a number of existing facilities are considering retrofitting engines because of the significant potential for additional landfill gas utilisation being identified by Sustainable Energy Authority Ireland in 2010. Furthermore, the technology’s low-cost and autonomous nature would benefit the hundreds of historical and legacy landfills if any were deemed to be problematic in terms of their environmental impact. Beyond landfills, this work pertains to other applications within the waste sector, as demonstrated by measuring emissions from wastewater treatment plant lagoons. With some further development, this technology could apply to efforts in dealing with climate change (e. g. in evaluating GHG inventories), where applications include managed peatlands (one case study is presented in this report and future efforts could also be targeted at carbon sinks/storage) and agriculture (Ireland’s greatest contributor to GHGs). Further scope could also be pursued in air-quality monitoring, particularly relevant at present with 2013 being dubbed the ‘Year of Air’ by European leaders. Throughout this project, the commercial prospect of this technology was affirmed with positive feedback from landfill operators, environmental regulators and private consultancies. Continual technical developments and refinements in mechanical/electronic design delivered a platform with expanded functionality and reduced price-point, thus becoming more viable for scaled-up deployments and commercial feasibility. Ultimately, this innovative development shows good promise as a high-potential commercial venture, with this work continuing under Enterprise Ireland’s Commercialisation Fund...|$|R

