57|102|Public
6000|$|Blakeney set {{his teeth}} and murmured a good, sound, British oath when he thought of those interrogatories. Armand St. Just, highly strung, a dreamer and a bundle of nerves--how he would suffer under the mental rack of {{questions}} and cross-questions, cleverly-laid traps to <b>catch</b> <b>information</b> from him unawares! ...|$|E
50|$|Lake Murray is {{open for}} shore fishing and private boats, kayaks, and float tubes {{seven days a week}} from 5:30 a.m. to 8:00 p.m. On days or times when the {{concession}} is closed, patrons can purchase permits from the iron ranger boxes (envelope system) at the lake. The reservoir is stocked with Florida-strain largemouth bass, bluegill, channel catfish, black crappie, and trout. Minimum size limit for bass is 12 inches. Fish limits are five trout, five bass, five catfish, and twenty-five crappie and bluegill in aggregate, with no limit on other species. Anglers 16 years of age or older must have a California state fishing license. Fish <b>catch</b> <b>information</b> is weekly.|$|E
40|$|A {{new way of}} {{representing}} texts written in natural language is introduced, as a conditional probability distribution at the letter level learned with a variable length Markov model called adaptive context tree model. Text categorization experiments demonstrate the ability of this representation to <b>catch</b> <b>information</b> about the semantic content of the text...|$|E
2500|$|... <b>catch</b> sensors give <b>information</b> {{about the}} rate at which the cod end is filling.|$|R
40|$|Parents of {{disabled}} children have substantial {{health and social}} care needs and therefore, a great need for information. The Central Mass Access to Child Health <b>Information</b> (<b>CATCH)</b> project attempted to address this problem. CATCH provided these community-based, public health agency staff members with training to locate and effectively use quality Internet health <b>information.</b> <b>CATCH</b> developed a model for outreach and collaboration as well as established new community partnerships for the Lamar Soutter Library (LSL) of the University of Massachusetts Medical School...|$|R
50|$|Where {{the local}} fishery economy permits, perhaps with {{international}} funding, near-real-time catch reporting {{will become a}} basic feature of vessel management systems. Software at fisheries management centers will cross-correlate VMS position <b>information,</b> <b>catch</b> reports, and spot inspection reports.|$|R
40|$|A Pismo clam, Tivela stultorum, {{survey was}} {{conducted}} in January 1977 on selected southern California beaches. Effort and <b>catch</b> <b>information</b> was collected through clammer interviews. Estimates for the two day survey were 1, 596 clammers spending 2, 506 hours to take 6, 139 clams. Comparisons were made between the 1977 survey results and previous surveys. Clams were collected for length and age studies. Compliance to the 4. 5 -inch (114. 3 mm) minimum size limit appeared to be good. (15 pp. ...|$|E
40|$|Shark nets {{have been}} set off the beaches of KwaZulu–Natal, South Africa, since 1952 {{to reduce the risk}} of shark attack. The nets fish in fixed localities 400 m from shore and both {{directly}} affect local shark populations and act as fisheries-independent monitoring devices. Reliable <b>catch</b> <b>information</b> at the species level was available for the period 1978 – 2003. Trends in catch rate and size were used to assess the population status of 14 commonly caught shark species. In addition, a demographic modelling approach was used in conjunction with the <b>catch</b> <b>information</b> to assess the potential effect of the nets on populations. Catch rates of four species (Carcharhinus leucas, C. limbatus, Sphyrna lewini and S. mokarran) showed a significant decline, as did the mean or median length of three species (Carcharhinus amboinensis, C. limbatus and female Carcharodon carcharias). For three species that showed declining catch rates or length the potential effect of the shark nets was assessed to be low, suggesting that other sources of catch were responsible for the declining status. The potential effect of the shark nets was assessed to be high for two species (Carcharhinus obscurus and Carcharias taurus, neither of which showed declines in catch rate or length), because of very low intrinsic rates of population increase...|$|E
40|$|Four {{important}} {{insect pests}} of sweet corn, European corn borer, corn earworm, fall armyworm, and Western bean cutworm, cause damage to sweet corn ears in their larval stage. These pests are moths in their adult stage {{and can be}} monitored using traps baited with pheromone lures specific for each species. Traps are placed near sweet corn fields to monitor moth flights. The weekly trap <b>catch</b> <b>information</b> allows growers, consultants, Cooperative Extension and vegetable processor field staff to track the flights and make informed decisions about when sweet corn fields need to be scouted or treated with an insecticide. This project is {{funded in part by}} in-kind contributions from growers and consultants who host and check traps...|$|E
40|$|OBJECTIVES: 1. Analyse current {{monitoring}} and logbook data sets, {{as well as}} survey and other information,to establish whether these data provide sufficient power to develop critical indicators of fishery performance. 2. Provide a risk analysis that examines the use of age structure and <b>catch</b> rate <b>information</b> for development of critical indicators, and response rules for those criteria, {{in the absence of}} other fishery information. 3. Develop a monitoring program that uses commercial vessels from the fishery to provide independent data...|$|R
40|$|The informationlized society needs so many {{real time}} analog and digital information. The CCD camera is good device to <b>catch</b> for image <b>information.</b> In this study, we used MATLAB {{language}} to get 3 -dimensional information using digital stereo camera images. MATLAB is a technical computing environment for high-performance numeric computation and visualization. And also, {{there are so}} many Toolbox like a image processing required to research for photogrammetry. Especially, the Image Processing Toolbox is a collection of fuctions bult on MATLAB's powerful numeric computing environment. The Toolbox functions support a wide range of image processing operation, from image display to filtering, analysis and image transforms. We estimate bias (RMS) of 3 -dimentional information using CCD images with C and MATLAB language in laboratory work. As a result, we can obtain the most probable to apply MATLAB language to <b>catch</b> 3 -dimentional <b>information...</b>|$|R
40|$|Abstract. —Recreational and {{commercial}} harvest of American shad Alosa sapidissima in the Virginia {{waters of the}} Chesapeake Bay and its tributaries has been prohibited since 1994. The Atlantic States Marine Fisheries Commission Shad and River Herring Management Plan requires that Virginia develop restoration targets for its shad populations, but estimates of their sizes are not available {{and there is little}} information about historic population levels. Thus, establishing restoration targets based on population size is problematic. A current spawning stock monitoring program yields <b>catch</b> rate <b>information</b> that can be compared with historic <b>catch</b> rate <b>information</b> recorded in commercial fishery logbooks from the 1950 s and the 1980 s. However, multifilament gill nets were used in the 1950 s and monofilament nets were used in the 1980 s (as well as in the current monitoring program). A Latin square design was employed to test the differences in relative fishing power of the two gear types over 2 years of seasonal sampling on the York River, Virginia. Estimates are that the monofilament nets are roughly twice as efficient as the multifilament nets. Reported catch rates in the 1950 s and 1980 s are roughly equivalent. However, when adjustments are made for the differences in fishing gear, catch rates for the 1950 s are twice as high as those during the 1980 s. These results provide valuable information for setting restoration targets for Virginia stocks of American shad. A complete moratorium on fishing for America...|$|R
40|$|Goldband snapper (Pristipomoides multidens) is an ecologically and {{economically}} important {{species in the}} Northern Demersal Scalefish Fishery (NDSF). The Carolina M, a trap fishing vessel operating in the NDSF, was equipped with Simrad ES 70 echosounders, operated at 38 and 120 kHz. In 2014 acoustic data, in combination with optical recordings of the catch, were opportunistically collected during routine fishing operations. In December 2014 pure, low density goldband snapper schools were observed on the echograms. In situ target strength (TS) estimates were derived and linked to length distributions of <b>catch</b> <b>information</b> with the curve fitting method. Estimated TS-Length (L) at 38 kHz was 20. 1 log 10 (L) - 70. 5 and 16. 4 log 10 (L) - 77 at 120 kHz. Three fishing grounds, where near simultaneously recorded acoustic and optical information was available were selected. Fish school densities observed within the 38 kHz acoustic data were disaggregated according to catch proportions using kriging. Goldband snapper density estimates ranged between 9518 individuals per nmi 2 in the high-density fishing region and 2512 and 945 individuals per nmi 2 in the two low density fishing regions. Sampling variance was estimated using geostatistics (coefficient of variance, CV = 10 – 20. 9 %). Other errors considered were signal-to-noise ratio (CV < 1 %), variation in the acoustic signal due to fluctuations in temperature and salinity (CV = 0. 5 – 1. 15 %), effects of diurnal vertical migration and variability of <b>catch</b> <b>information</b> (CV = 1. 2 – 2 %). A total CV of 28. 2 – 50. 6 % was estimated for all considered sources, for the three fishing regions...|$|E
40|$|A Pismo clam, Tivela stultorum, census was {{conducted}} in January 1976 on selected southern California beaches. Effort and <b>catch</b> <b>information</b> was collected through clamer interviews. Estimates for January 17 on beaches sampled were 3, 296 clammer-hours, 2, 170 clammers, and 10, 739 legal clams (4. 5 inches or larger) harvested. Clams were collected for age and growth studies. Samples of clams from the Long Beach to Newport Beach pier area demonstrate the fastest growth rates of any Pismo clams reported in the literature. Clams begin to be recruited to the fishery at age 40 months. (14 pp.) The 1974 year class was the largest on beaches sampled. Recruitment to the fishery will be poor for the 1976 - 77 and 1977 - 78 seasons and clamming will be dependent on large older clams...|$|E
40|$|An {{economic}} {{survey of the}} commercial operators currently active in the Queensland Coral Reef Fin-Fish Fishery has been carried out, {{as part of a}} research project aimed at evaluating alternative management options for this fishery. This paper presents the background analysis used as a basis to develop the sampling design for this survey. The background analysis focuses on activity patterns of the fleet based on effort and <b>catch</b> <b>information,</b> as well as patterns of quota ownership. Based on this information, a fishing business profile describing the micro-economic structure of fishing operations is developed. This profile, in conjunction with the qualitative information gained in undertaking the {{economic survey}}s, allows preliminary understanding of the key drivers of profitability in the CRFFF, and possible impacts of external factors on fishing operations...|$|E
50|$|The Catch Documentation Scheme (CDS) for Patagonian {{toothfish}} (Dissostichus eleginoides) and Antarctic toothfish (Dissostichus mawsoni) was {{one measure}} that ensured reductions in illegal fishing for toothfish {{and reduced the}} scope for trade in illegally caught fish. The CDS is an innovative online <b>catch</b> document <b>information</b> system (DCD: Dissostichus Catch Document) developed to identify legal toothfish harvested, which tracks toothfish {{from the point of}} landing throughout the trade cycle to point of sale. The CDS requires verification and authorisation by national authorities at regular intervals in the trade cycle. Identification of the origin of toothfish entering the ports and markets of CDS Parties is essential.|$|R
40|$|Abstract. This paper {{describes}} the Mediating Agent, an animated pedagogical agent inserted in a computational system for distance learning, {{which has the}} goal of motivating the student to learn as well as promoting a positive mood in the student, which is more appropriate to learning. In order to accomplish its function, the agent should recognize the student’s emotions to respond appropriately. Thus, it <b>catches</b> some <b>information</b> from observing the student’s behaviour in the interface of the educational system, which allows it to infer the student’s affective states according to the cognitive approach of emotion. This information is stored in an affective model and it is used so that the agent may choose an affective pedagogical tactic to be applied...|$|R
30|$|Human {{visual system}} has an {{excellent}} ability to quickly <b>catch</b> salient <b>information</b> from complex scenes. The mechanism in the brain that determines which part of the visual data is currently of the most interest is called selective attention [1]. The mechanism is critical for human to understand scenes. In recent years, many computational models have been proposed to mimic the mechanism of selective visual attention. The models can compute saliency maps from image or video inputs. The pixels with higher intensity values in saliency map denote that the corresponding pixels are visually important. The saliency map {{can be used for}} applications, such as object-of-attention segmentation [2 – 4], object detection [5, 6], image and video summarization [7], video surveillance [8], and image and video compression [9].|$|R
40|$|NYS IPM Type: Project ReportFor 22 years, the Sweet Corn Pheromone Trap Network {{has been}} {{monitoring}} {{the flight of}} three important insect pests of sweet corn, European corn borer, corn earworm, fall armyworm, and more recently, 2010, Western bean cutworm. These insects cause damage to sweet corn ears in their larval stage. These pests are moths in their adult stage and can be monitored using traps baited with pheromone lures specific for each species. Traps are placed near sweet corn fields to monitor moth flights. The weekly trap <b>catch</b> <b>information</b> allows growers, consultants, Cooperative Extension and vegetable processor field staff to track the flights and make informed decisions about when sweet corn fields need to be scouted or treated with an insecticide. This project was {{funded in part by}} in-kind contributions from growers and consultants who host and check traps...|$|E
40|$|Part 3 : PLM MaturityInternational audienceThe {{product design}} {{requires}} {{the interaction of}} several disciplines {{and the use of}} a wide set of PLM tools. They are used both to design the product elements and also, to manage product data and information that are generated. For company working as ETO (Engineering To Order), the complexity increases. Generally, customers requires a certification of the design process and a clear and formalized workflow of approval and validation. The paper describes a methodology for evaluating the use of PLM tools in the design process of products. The proposed methodology aims to be an objective tool able to <b>catch</b> <b>information</b> of the impact of ICT directly from the processes using them. Techniques specific of the Business Process Management discipline have been used. Phases and indicators of the methodology can be applied to analyze the product design process in different context...|$|E
40|$|A stock {{production}} model (ASPIC) {{was applied to}} age-aggregated biomass indices covering {{the same time period}} and from surveys used in the XSA assessment accepted by Scientific Council in recent years. Results were sensitive to the starting estimates for several parameters, and resulted in two very different estimates of relative biomass and fishing mortality. Retrospective patterns were also problematic for the two resulting solutions. When standardized CPUE series (from Canadian, Russian and Portuguese fisheries) were included in the model with the catch and survey indices, model diagnostics and fit were poor and results were considered unacceptable. Using only the CPUE series and <b>catch</b> <b>information</b> resulted in model fits and results similar to those using biomass indices and catch alone. Sensitivity analyses for the model including only CPUE and catch also indicated two possible solutions. Retrospective patterns for the CPUE/catch runs were severe and were not considered acceptable...|$|E
40|$|International audienceEntropy Congealing is an {{unsupervised}} joint image alignment method, {{in which}} the transformation parameters are obtained by minimizing a sum-of- entropy function. Our previous work presented a forward formulation of entropy Congealing to estimate all the transformation parameters at the same time. In this paper, we propose an inverse compositional Lucas-Kanade formulation of entropy Congealing. This yields constant parts in Jacobian and Hessian which can be precomputed to decrease the computational complexity. Moreover, we combine Congealing with POEM descriptor to <b>catch</b> more <b>information</b> about face. Experimental {{results indicate that the}} proposed algorithm performs better than other alignment methods, regarding several evaluation criteria on different databases. Concerning the complexity, the proposed algorithm is more efficient than other considered approaches. Also, compared to the forward formulation, the inverse method produces a speed improvement of 20 %...|$|R
40|$|Shearlets {{not only}} possess all {{properties}} that other transforms have, but also {{are equipped with}} a rich mathematical structure similar to wavelets, which are associated to a multi-resolution analysis. Recently, shearlets {{have been used in}} image denoising, sparse image representation, and edge detection. However, its application in image fusion is still under study. In this letter, we study the feasibility of image fusion using shearlets. Fusion rules of larger high-frequency coefficients based on regional energy, regional variance, and absolute value are proposed because shearlet transform can <b>catch</b> detailed <b>information</b> in any scale and any direction. The fusion accuracy is also further improved by a region consistency check. Several different experiments are adopted to prove that fusion results based on shearlet transform can acquire better fusion quality than any other method...|$|R
40|$|This paper proposes {{structural}} {{features for}} content-based image retrieval (CBIR), especially edge/structure features extracted from edge maps. The feature vector is computed through a “Water-Filling Algorithm ” applied {{on the edge}} map of the original image. The purpose of this algorithm is to efficiently extract information embedded in the edges. The new features are more generally applicable than texture or shape features. Experiments show that the new features can <b>catch</b> salient edge/structure <b>information</b> and improve the retrieval performance...|$|R
40|$|Three {{important}} {{insect pests}} of sweet corn, European corn borer, corn earworm, and fall armyworm, cause damage to ears in their worm or larval stage. These pests are moths in their adult stage. Traps baited with the pheromones that {{male and female}} moths use to find each other are set up near sweet corn production in NY. The trap <b>catch</b> <b>information</b> allows growers, consultants, and Cooperative Extension and vegetable processor field staff to track the flights of the adults of these three pests, and trap numbers contribute to making informed decisions about when sweet corn fields need to be scouted or treated with an insecticide. In 2010 traps for a new pest, the western bean cutworm, {{were added to the}} trap network to survey where in the state they are being found. This project is funded in part by in-kind contributions from growers and consultants who host and check traps...|$|E
40|$|Spanish <b>catch</b> <b>information</b> {{used in this}} Report {{is based}} on the logbook data contributed by the Spanish Administration. Table 1 {{presents}} the catches by species and Division in 2015 based on this information. The split of catches and effort between the different gears in this Report are based on information from NAFO observers on board. In 2015 NAFO observers information from 1, 272 days was available while total effort of the Spanish fleet in NAFO Regulatory Area was 1, 317 days (around 97 % coverage). In addition to NAFO observers, IEO scientific observers were on board 320 fishing days that it means 24 % of the Spanish total effort. All length, age and biological information presented in this paper is based on sampling carried out by IEO scientific observers: 576 samples were taken in 2015, with 59, 883 individuals of different species examined (Table 2). Postprint 0, 000...|$|E
40|$|Ventral target {{strength}} (TS) of smelt (Osmerus eperlanus) {{was measured}} using a bottom deployed Simrad EK 60 200 kHz echosounder in the shallow lake Ijsselmeer (The Netherlands). Ventral TS values recorded (TS = 20 log 10 (L) – 74. 39) were lower but comparable to previous studies looking at the dorsal TS in other areas. Biological samples were collected simultaneously close {{to the bottom and}} close to the surface. The combination of acoustic measurements and <b>catch</b> <b>information</b> revealed a diurnal migration of smelt. Smelt was observed to be more dispersed during the night than during daytime, but showing no clear avoidance pattern for any environmental variable recorded by CTD measurements. Smelt was found in the upper water column during times of highest light intensity. Such behaviour is likely to occur due to a combination of turbid water conditions and predator avoidance, mainly of piscivorous fish species such as pike–perch (Stizostedion luciperca) and perch (Perca fluviatilis...|$|E
40|$|BS) has {{wavelength}} dependent property. So Eve {{will get}} {{almost all of}} the secret information without being discovered in the beam splitter attack. This paper proposes a solution to solve the beam splitter attack. It uses three beam splitters to remove the incredible photons which could have been attacked by Eve. Bob gets a proper three-beam-splitter group, so Eve can’t <b>catch</b> any secret <b>information</b> without being found. Index Terms- beam splitter, quantum key distribution (QKD), quantum bit error rate (QBER). 1...|$|R
40|$|International audienceVisual object {{recognition}} {{is one of}} the most challenging problems in computer vision, due to both inter-class and intra-class variations. The local appearance-based features, especially SIFT, have gained a big success in such a task because of their great discriminative power. In this paper, we propose to adopt two different kinds of feature to characterize different aspects of object. One is the Local Binary Pattern (LBP) operator which catches texture structure, while the other one is segment-based feature which <b>catches</b> geometric <b>information.</b> The experimental results on PASCAL VOC benchmark show that the LBP operator can provide complementary information to SIFT, and segment-based feature is mainly effective to rigid objects, which means its usefulness is class-specific. We evaluated our features and approach by participating in PASCAL VOC Challenge 2009 for the very first attempt, and achieved decent results...|$|R
40|$|This paper {{presents}} {{a method for}} video collection overviewing based the dynamic content of the scenes. In an unsupervised context, our approach relies on the nonlinear temporal modeling of wavelet-based motion features directly estimated from the image sequence. Based on SVM-regression, the nonlinear model is able to learn {{the behavior of the}} motion descriptors along the temporal dimension and to <b>catch</b> useful <b>informations</b> of the dynamic content. A similarity measure associated to the temporal model is then defined. It allows to compare video segments according to motion descriptors and thus defines a high-dimensional feature space where the video sequences under investigation are projected. The Curvilinear Component Analysis algorithm is finally used to map the feature space onto a 2 D space. This operation enables us to display the video collection and gives an overview of the content according to motion features...|$|R
40|$|All {{effort and}} <b>catch</b> <b>{{information}}</b> in this Report {{are based on}} information from NAFO observers on board. In 2009 information from 1459 days was available while total effort of the Spanish fleet in NAFO Regulatory Area was 1470 days (99 % coverage). Spanish catches by species and Division in 2009 collected by NAFO Observers are presented in Table 1. The split by species of grenadiers were calculated based upon the percentage observed by the IEO scientific observers. In addition to NAFO observers, IEO scientific observers were on board 241 fishing days that it means 16. 5 % of the Spanish total effort. All length, age and biological information {{presented in this paper}} are based on sampling carried out by IEO observers: in 2009, 233 samples were taken, with 30 418 individuals of different species examined. SUBAREA 1 and 2 A. Status of the fisheries There was not Spanish fishing activity in these Subareas during 2008...|$|E
40|$|International audienceA new {{descriptor}} called Multi-modal Binary Patterns (MMBP) {{is proposed}} for face recognition. It balances well important requirements for real-world applications, including the robustness, discriminative power, {{and the low}} computational cost. The proposed algorithm has several desirable properties: 1) it captures information from face image in any direction as it is oriented feature, 2) being a spatial multi-scale structure, the descriptor catches not only local but also more global information about object, 3) it is robust to image transformation like variations of lighting, expressions, and 4) it is computationally efficient. In more detail, to <b>catch</b> <b>information</b> in a given direction, a Local Line Binary Pattern (LLBP) based operator is first applied. The MMBP feature is then built by applying a LBP-based self-similarity operator on the values being calculated by LLBP operators across different directions. A Whitened PCA dimensionality reduction technique is applied to get more a compact and efficient descriptor. Experimental results achieved on the comprehensive FERET data set being comparable to state-of-the-art validates the efficiency of our method...|$|E
40|$|Defining the {{geographic}} extent of suitable fishing grounds at a scale relevant to resource exploitation for commercial benthic species can be problematic. Bathymetric {{light detection and ranging}} (LiDAR) systems {{provide an opportunity}} to enhance ecosystem-based fisheries management strategies for coastally distributed benthic fisheries. In this study we define the spatial extent of suitable fishing grounds for the blacklip abalone (Haliotis rubra) along 200 linear kilometers of coastal waters for the first time, demonstrating the potential for integration of remotely-sensed data with commercial <b>catch</b> <b>information.</b> Variables representing seafloor structure, generated from airborne bathymetric LiDAR were combined with spatially-explicit fishing event data, to characterize {{the geographic}} footprint of the western Victorian abalone fishery, in south-east Australia. A MaxEnt modeling approach determined that bathymetry, rugosity and complexity were the three most important predictors in defining suitable fishing grounds (AUC = 0. 89). Suitable fishing grounds predicted by the model showed a good relationship with catch statistics within each sub-zone of the fishery, suggesting that model outputs may be a useful surrogate for potential catch...|$|E
40|$|We make a {{first attempt}} to give an extreme value {{analysis}} of data, connected to catastrophic events. While the data are readily accessible from SWISSRE, their analysis doesn’t {{seem to have been}} taken up. A first set refers to insured claims over the last 35 years; the second deals with victims from natural catastrophes. Together these sets should provide ample proof that extreme value analysis might be able to <b>catch</b> some essential <b>information</b> that traditional statistical analysis might overlook. We finish with a number of cautious remarks...|$|R
40|$|This report {{summarizes}} the 1979 ocean salmon fishing season off the Oregon coast. Troll fishery landings were obtained directly from commercial fish receiving tickets supplemented with {{a survey of}} fish buyers to obtain the most up-to-date estimate of total landings. Recreational catch and effort were obtained from creel census survey at coastal ports by ODFW personnel. Recreational <b>catch</b> and effort <b>information</b> is included for the period May 12 through September 16 while commercial troll landings encompass the period from May 1 through November 13...|$|R
40|$|Web {{applications}} allow legitimate website {{visitors to}} submit and retrieve data to/from a database over the Internet. Web applications {{are used for}} collecting information, and analyze it. Sql injection {{is one of the}} most dangerous attacks which are used to access database without authentication. SQL is used to retrieve; insert data to/from the database. Using sql command make it a malicious code for attack at authentication section of front end of web application and send to the server. This process is known as SQL injection authorization attack. SQL injection authorization attack easily gets entry in the database and <b>catches</b> all <b>information</b> from database. This paper illustrates the method for prevention from SQL injection authorization attack i. e. recursively authentication or double authentication. Automatically authentication will increase. We are going to implement recursive method on web based program using string inputs and its ASCII valu...|$|R
