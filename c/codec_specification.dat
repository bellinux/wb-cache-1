3|11|Public
5000|$|May 2017: Standards {{documents}} on <b>codec</b> <b>specification</b> and storage format specification. Informational document on reference implementation.|$|E
50|$|The VC-1 <b>codec</b> <b>specification</b> has so {{far been}} {{implemented}} by Microsoft in the form of 3 codecs, each identified with a unique four character code.|$|E
50|$|This {{distinction}} is not consistently reflected terminologically in the literature. The H.264 specification calls H.261, H.262, H.263, and H.264 video coding standards {{and does not}} contain the word codec. The Alliance for Open Media clearly distinguishes between the AV1 video coding format and the accompanying codec they are developing, but calls the video coding format itself a video <b>codec</b> <b>specification.</b> The VP9 specification calls the video coding format VP9 itself a codec.|$|E
30|$|The host {{interface}} {{provides the}} architecture with necessary data for video processing. It can also control video accelerators {{to operate in}} sequential or parallel mode, {{in accordance with the}} H. 264 video <b>codec</b> <b>specifications.</b> The hardware-software partitioning is simplified so that the host interface can focus on the data communication as well as flow control for video tasks, while hardware accelerators deal with local memory accesses and video codec functions. Therefore, the software abstraction layer covers the feature of data exchange and video task flow control for hardware performance.|$|R
40|$|Abstract—Crucial to {{supporting}} voice over 802. 11 b is {{the knowledge of}} voice capacity (Nc) of a single Access Point. This paper provides an analytical formulation of Nc in the case where all traffic in the network is voice. Our formulation, which can apply {{to a range of}} voice <b>codec</b> <b>specifications,</b> are verified by detailed simulations. We also investigate how to deliver, within the 802. 11 b standard, priority service to voice in the presence of best effort background traffic. It is known that the voice capacity degrades very quickly in the presence of other traffic sources if all packets are treated as best effort. Using an experimental deployment in which all voice packets are prioritized by having their channel back-off times set to zero, we determine the rate of the best effort background traffic below which our analytical formulation of voice-only capacity remains useful...|$|R
40|$|Nowadays, {{the design}} flow of complex signal {{processing}} embedded systems {{starts with a}} specification of the application {{by means of a}} large and sequential program (usually in C/C++). As we are entering in the multicore era, sequential programs are no longer the most appropriate way to specify algorithms targeted to run on several processing units. The new ISO/MPEG Reconfigurable Video Coding (RVC) standard is proposing a new paradigm for specifying and designing complex signal processing systems. The RVC standard enables specifying new codecs by assembling blocks, or so called Functional Units (FUs) from a standard Video Tool Library (VTL). Flexibility, reusability, and modularity are the key features of RVC. This new way of specifying algorithms clearly simplifies the task of designing future video coding applications by allowing software and hardware reuse across multiple video coding standards. Specifications are provided {{in the form of an}} actor and dataflow-based language called CAL. Although the RVC standard does not imply any specific implementation design flow, it is an appropriate starting point for targeting multiple processing units platforms. This paper describes a new model-driven design flow which considers both algorithm and architecture to map RVC <b>codec</b> <b>specifications</b> onto heterogeneous and multi-core systems. 1...|$|R
40|$|Abstract — Digital {{broadcasting}} {{environment in}} which digitalized AV contents can be sent has a room for data transmission as well. In this circumstance, effective encoding method of verbose XML type TV-Anytime metadata becomes important and also the broadcasting environment-specific refinement of TV-Anytime transportation specification is in great need. This paper suggests a well-tuned framework for encoding TV-Anytime metadata. Our TV-Anytime codec, the main subject of this paper, includes revision of the whole TVA <b>codec</b> system <b>specification</b> and external programming interfaces {{to communicate with the}} external modules in our uni-directional broadcasting head-end system...|$|R
40|$|International audienceVideo coding {{technology}} has evolved in the past years {{into a variety of}} different and complex algorithms. So far the specification of such standard algorithms has been done case by case providing monolithic textual and reference SW specifications, but without any attention on commonalities and the possibility of incremental improvements or modifications of such monolithic standards. The MPEG Reconfigurable Video Coding (RVC) framework is a new ISO standard, currently under development aiming at providing video <b>codec</b> <b>specifications</b> at the level of library functions instead of monolithic algorithms. The possibility to select a subset of standard coding algorithms to specify a decoder that satisfies application specific constraints is very attractive. However, such possibility to reconfigure codecs requires systematic procedures and tools capable of describing the new bitstream syntaxes of such new codecs. Moreover, it is also necessary to generate the associated parsers which are capable to parse the new bitstreams because they are not available "a priori" in the RVC library. This paper further explains the problem and describes the technologies used to describe new bitstream syntaxes within RVC. In addition, the paper describes the methodology and the tools for the validation of bitstream syntaxes descriptions as well as an example of systematic procedures for the direct synthesis of parsers in the same data flow formalism in which the RVC library component are implemented...|$|R
40|$|International audienceThe current {{monolithic}} and lengthy scheme {{behind the}} standardization {{and the design}} of new video coding standards is becoming inappropriate to satisfy the dynamism and changing needs of the video coding community. Such scheme and specification formalism does not allow the clear commonalities between the different codecs to be shown, {{at the level of}} the specification nor {{at the level of the}} implementation. Such a problem is one of the main reasons for the typically long interval elapsing between the time a new idea is validated until it is implemented in consumer products as part of a worldwide standard. The analysis of this problem originated a new standard initiative within the International Organization for Standardization (ISO) / International Electrotechnical Commission (IEC) Moving Pictures Experts Group (MPEG) committee, namely Reconfigurable Video Coding (RVC). The main idea is to develop a video coding standard that overcomes many shortcomings of the current standardization and specification process by updating and progressively incrementing a modular library of components. As the name implies, flexibility and reconfigurability are new attractive features of the RVC standard. Besides allowing for the definition of new codec algorithms, such features, as well as the dataflow-based specification formalism, open the way to define video coding standards that expressly target implementations on platforms with multiple cores. This article provides an overview of the main objectives of the new RVC standard, with an emphasis on the features that enable efficient implementation on platforms with multiple cores. A brief introduction to the methodologies that efficiently map RVC <b>codec</b> <b>specifications</b> to multicore platforms is accompanied with an example of the possible breakthroughs that are expected to occur in the design and deployment of multimedia services on multicore platforms...|$|R
40|$|International audienceVideo coding {{technology}} in the last 20 years has evolved producing {{a variety of different}} and complex algorithms and coding standards. So far the specification of such standards, and of the algorithms that build them, has been done case by case providing monolithic textual and reference software specifications in different forms and programming languages. However, very little attention has been given to provide a specification formalism that explicitly presents common components between standards, and the incremental modifications of such monolithic standards. The MPEG Reconfigurable Video Coding (RVC) framework is a new ISO standard currently under its final stage of standardization, aiming at providing video <b>codec</b> <b>specifications</b> at the level of library components instead of monolithic algorithms. The new concept {{is to be able to}} specify a decoder of an existing standard or a completely new configuration that may better satisfy application-specific constraints by selecting standard components from a library of standard coding algorithms. The possibility of dynamic configuration and reconfiguration of codecs also requires new methodologies and new tools for describing the new bitstream syntaxes and the parsers of such new codecs. The RVC framework is based on the usage of a new actor/ dataflow oriented language called CAL for the specification of the standard library and instantiation of the RVC decoder model. This language has been specifically designed for modeling complex signal processing systems. CAL dataflow models expose the intrinsic concurrency of the algorithms by employing the notions of actor programming and dataflow. The paper gives an overview of the concepts and technologies building the standard RVC framework and the non standard tools supporting the RVC model from the instantiation and simulation of the CAL model to software and/or hardware code synthesis...|$|R
40|$|Complexity management, {{portability}} {{and long}} term adaptivity are common challenges in different fields of embedded systems, normally colliding {{with the needs of}} efficient resource utilization and power balance. Image/signal processing systems, though required to offer a large variety of complex functions, have also to deal with battery-life limitations. Wearable signal processing systems, for example, should provide high performance and support new generation standards without compromising their portability and their long-term usability. These constraints challenge hardware designers: early stage trade-off analysis and power management automated techniques are helpful to guarantee a reasonable time-to-market. In the field of video <b>codec</b> <b>specifications,</b> the MPEG standard known as Reconfigurable Video Coding (RVC) framework addresses functional complexity and adaptivity leveraging on the intrinsic modularity of the dataflow model of computation, but it still lacks in offering power management support. The main contribution of this work is providing an automatic early-stage power management methodology to be adopted within the MPEG-RVC context. Starting from different high-level specifications, our mapping methodology identifies directly on the high-level models disjointed homogeneous logic clock regions, where the platform resources can be enabled/disabled together without affecting the overall system performance. To extend its usability to the RVC community, we have integrated this methodology within the Multi-Dataflow Composer (MDC) tool. MDC is a tool for on-the-fly reconfigurable signal processing platforms deployment. In this paper, we extended MDC to address power-aware multi-context systems. To prove the effectiveness of our work, a coprocessor for image and video processing acceleration has been assembled. This latter has been synthesized on a 90 nm ASIC technology, where demonstrated up to 90 % of reduction in the dynamic power consumption on different dataflow-intensive applications. The coprocessor has been implemented also on FPGA, confirming, partially, the benefits of adopting the proposed methodology...|$|R
50|$|Although video coding formats such as H.264 are {{sometimes}} referred to as codecs, there is a clear conceptual difference between a specification and its implementations. Video coding formats are described in specifications, and software or hardware to encode/decode data in a given video coding format from/to uncompressed video are implementations of those specifications. As an analogy, the video coding format H.264 (specification) is to the codec OpenH264 (specific implementation) what the C Programming Language (specification) is to the compiler GCC (specific implementation). Note that for each specification (e.g. H.264), there can be many <b>codecs</b> implementing that <b>specification</b> (e.g. x264, OpenH264, H.264/MPEG-4 AVC products and implementations).|$|R
40|$|In this study, {{we present}} SimCommSys, a {{simulator}} of communication systems {{that we are}} releasing under an open source license. The core of the project {{is a set of}} C + + libraries defining communication system components and a distributed Monte Carlo simulator. Of principal interest is the error-control coding component, where various kinds of binary and non-binary codes are implemented, including turbo, LDPC, repeat-accumulate and Reed–Solomon. The project also contains a number of ready-to-build binaries implementing various stages of the communication system (such as the encoder and decoder), a complete simulator and a system benchmark. Finally, SimCommSys also provides a number of shell and python scripts to encapsulate routine use cases. As long as the required components are already available in SimCommSys, the user may simulate complete communication systems of their own design without any additional programming. The strict separation of development (needed only to implement new components) and use (to simulate specific constructions) encourages reproducibility of experimental work and reduces the likelihood of error. Following an overview of the framework, we provide some examples of how to use the framework, including the implementation of a simple <b>codec,</b> the <b>specification</b> of communication systems and their simulation...|$|R
40|$|Due to the {{character}} of the original source materials and the nature of batch digitization, quality control issues may be present in this document. Please report any quality issues you encounter to digital@library. tamu. edu, referencing the URI of the item. Includes bibliographical references: p. 64 - 66. Issued also on microfiche from Lange Micrographics. This thesis is about the evaluation of a prediction algorithm for a standard video codec proposed in [1]. This video <b>codec</b> follows the <b>specifications</b> of the ISO H. 261 Recommendation. The video codec and the proposed algorithm were written in software, and the algorithm was implemented into the predictor of the video codec. Using Mean Field Annealing, the predictor iterates the reconstructed image to eliminate blocking artifacts, noise, and other image degradations. This is supposed to be achieved by using "a priori" information about the image to be iterated. The implemented video codec was run with and without the proposed algorithm on different PC platforms, and the results evaluated with various criteria. The results presented show that the proposed algorithm seems to be inappropriate for the intended application. Computing speed is slowed down considerably because of the iterative nature of the algorithm. Furthermore, the worse the quality of the considered image, the better results yields the algorithm. However, the resulting image quality is not good enough to justify an employment of this algorithm in real video telephony or conferencing systems. Other means of improving video image quality like reducing frame rates or reallocating bandwidth would be more beneficial...|$|R

