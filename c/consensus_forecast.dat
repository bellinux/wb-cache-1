136|240|Public
500|$|The Systematic Approach Forecast Aid (SAFA) was {{developed}} by the Joint Typhoon Warning Center to create a selective <b>consensus</b> <b>forecast</b> which removed more erroneous forecasts at a 72‑hour time frame from consideration using the United States Navy NOGAPS model, the GFDL, the Japan Meteorological Agency's global and typhoon models, as well as the UKMET. [...] All the models improved during SAFA's five-year history and removing erroneous forecasts proved difficult to do in operations.|$|E
2500|$|... where EPS is a firm's {{earnings}} per share, and Forecast is analysts' <b>consensus</b> <b>forecast</b> of its {{earnings per}} share.|$|E
50|$|As of April 28, 2017, the <b>consensus</b> <b>forecast</b> amongst 2 polled {{investment}} analysts covering Wockhardt Limited advises {{that the}} company will underperform the market. This has been the <b>consensus</b> <b>forecast</b> since the sentiment of investment analysts deteriorated on November 17, 2016. The previous <b>consensus</b> <b>forecast</b> advised investors to hold their position in Wockhardt Limited..|$|E
50|$|In addition, monthly {{forecast}} data is {{also available}} for currency exchange rates {{as well as a}} range of commodity prices. These appear in Foreign Exchange <b>Consensus</b> <b>Forecasts</b> and Energy and Metals <b>Consensus</b> <b>Forecasts.</b>|$|R
50|$|Prominent {{examples}} of probability forecasting are those undertaken in surveys whereby forecasters are asked, {{in addition to}} their central forecasts, for their probability estimates within a specified range. The Monetary Authority of Singapore (MAS) is one such organisation which publishes probability forecasts in its quarterly MAS Survey of Professional Forecasters. Another is Consensus Economics, a macroeconomic survey firm, which publishes a special survey on forecast probabilities each January in its <b>Consensus</b> <b>Forecasts,</b> Asia Pacific <b>Consensus</b> <b>Forecasts</b> and Eastern Europe <b>Consensus</b> <b>Forecasts</b> publications.|$|R
30|$|The {{process of}} subjectively {{compiling}} seasonal forecasts for South Africa continued unabated for about 10  years, despite {{the evidence that}} objective forecast combination schemes can hold great benefit (Klopper and Landman 2003). However, when verification on 7  years of <b>consensus</b> <b>forecasts</b> was completed (Moatshe 2008), {{it was discovered that}} forecast skill for austral mid-summer rainfall of the <b>consensus</b> <b>forecasts</b> was lower than the skill associated with the <b>consensus</b> rainfall <b>forecasts</b> for spring and for autumn. This result is in contrast to verification results obtained from raw model output that shows that austral mid-summer predictability is the highest. Although the <b>consensus</b> <b>forecasts</b> for spring and autumn did not experience the same skill deterioration as the <b>consensus</b> <b>forecasts</b> for mid-summer, it was decided to follow the international trend to develop objective multi-model systems. A modelling effort to investigate the advantages of objectively combining seasonal probabilistic forecasts was subsequently completed in 2008 (Landman et al. 2009 b).|$|R
50|$|In 2007, he {{was named}} California’s most {{accurate}} forecaster by the Western Blue Chip <b>Consensus</b> <b>Forecast,</b> besting UCLA, Wells Fargo and other esteemed forecasting groups.|$|E
5000|$|<b>Consensus</b> <b>forecast,</b> {{also known}} as {{combining}} forecasts, forecast averaging or model averaging (in econometrics and statistics) and committee machines, ensemble averaging or expert aggregation (in machine learning) ...|$|E
50|$|The Western Blue Chip Economic Forecast is a <b>consensus</b> <b>forecast</b> {{prepared}} by the W. P. Carey School of Business at Arizona State University for the economies of {{the states in the}} Western United States.|$|E
50|$|<b>Consensus</b> <b>Forecasts</b> {{data has}} been cited by other {{academic}} literature, such as discussion of the Asian financial crisis.|$|R
5000|$|Consensus Economics, {{publisher}} of <b>Consensus</b> <b>Forecasts,</b> a monthly publication with macroeconomic forecasts of 85 countries {{based on a}} poll of 700 economists.|$|R
5000|$|Loungani, Prakash, 2001. [...] "How {{accurate}} {{are private}} sector forecasts? Cross-country evidence from <b>consensus</b> <b>forecasts</b> of output growth," [...] International Journal of Forecasting, Elsevier, vol. 17(3), pages 419-432.|$|R
50|$|NABE Surveys: NABE {{regularly}} conducts three {{surveys of}} its membership: the Outlook Survey, the Industry Survey, and the Economic Policy Survey. The NABE Outlook Survey, {{the most well-known}} of the NABE surveys, provides the <b>consensus</b> <b>forecast</b> of NABE’s professional economic forecasters.|$|E
50|$|Earnings growth {{which may}} be {{reflected}} in measures like the Prospective Earnings Growth (PEG) ratio. The PEG ratio is a projected one-year annual growth rate, determined by taking the <b>consensus</b> <b>forecast</b> of next year’s earnings, less the current year’s earnings, and dividing the result by the current year’s earnings.|$|E
5000|$|A 2011 {{paper by}} Filip Novotny and Marie Rakova for the Czech National Bank {{compared}} {{the accuracy of}} the Consensus Forecasts estimates with those of the International Monetary Fund and the Organisation for Economic Co-operation and Development. Echoing the result of Ager, Kappler, and Osterloh, it found: [...] "In the period from 1994 to 2009 Consensus forecasts for effective euro-area consumer price inflation and GDP growth beat the alternatives by a difference which is typically statistically significant. The results are more diverse for the pre-crisis sample (1994-2007). The <b>Consensus</b> <b>forecast</b> for euro-area producer price inflation significantly outperforms the naïve forecast in the short-term. Finally, the <b>Consensus</b> <b>forecast</b> for the USD/EUR exchange rate during the period from 2002 to 2009 is more precise than the naïve forecast and the forecast implied by the forward rate." ...|$|E
40|$|This paper {{tests the}} {{rationality}} of forecasts made {{by individuals who}} contribute to the Blue Chip <b>consensus</b> <b>forecasting</b> service and tries, {{by means of a}} questionnaire on forecasting methods, to establish why some forecasters appear more rational than others. Tests based on <b>consensus</b> <b>forecasts</b> prove unreliable as guides to the number of individuals who produce rational forecasts. Individual forecasts {{are more likely to be}} rational if they are based on a mainstream economic theory and incorporate a substantial element of judgment. Copyright 1991 by Ohio State University Press. ...|$|R
40|$|This paper {{analyses}} {{the performance}} of <b>consensus</b> <b>forecasts,</b> published by <b>Consensus</b> Economics, for 12 countries over the period from 1996 to 2006 regarding bias and information efficiency. A pooled approach is employed which permits the evaluation of all forecasts for each target variable over 24 horizons simultaneously. It is shown how the pooled approach needs {{to be set up}} in order to accommodate the forecasting scheme of the <b>consensus</b> <b>forecasts.</b> Furthermore, the pooled approach is extended by a sequential test for detecting the critical horizon after which the forecast should be regarded as biased. Moreover, heteroscedasticity in the form of target-year-specific variances of macroeconomic shocks is taken into account. The results show that in the analysed period, which was characterised by pronounced macroeconomic shocks, several countries show biased forecasts, especially with forecast horizons of more than 12 months. In addition, information efficiency has to be rejected in almost all cases. Evaluating forecasts Business cycle <b>forecasting</b> Inflation <b>forecasting</b> <b>Consensus</b> <b>forecasts</b> Bias and efficiency...|$|R
40|$|In this study, we {{investigate}} the characteristics and information content of whisper forecasts of earnings. Based on data on earnings whispers obtained from public sources and from one private website (‘getwhispers. com’), we examine whether whisper forecasts are more optimistic, on average, than <b>consensus</b> analyst <b>forecasts,</b> {{and how the}} market perceives whisper forecasts as compared to <b>consensus</b> analyst <b>forecasts.</b> Our results indicate that whisper forecasts are more optimistic, on average, than <b>consensus</b> analyst <b>forecasts.</b> Further, we find that <b>consensus</b> <b>forecasts</b> are as accurate as whisper forecasts. Our market perception tests reveal that in both the short-run and the long-run, whispers are not incrementally informative to <b>consensus</b> analyst <b>forecasts.</b> Further, we find no evidence that analysts use {{the information contained in}} whispers to revise their forecasts. On the contrary, we find that analysts 2 ̆ 7 <b>consensus</b> <b>forecasts</b> often have incremental information content over whisper numbers. However, our inferences are not applicable to recent whisper data since our sample period ends in March 2001. Proprietary ways of analyzing market and street expectations have the potential to add value in picking stocks and assessing market direction. Our findings do not apply to data disseminated via existing, commercial whisper websites that {{are not part of the}} sample which may have the potential to add value through proprietary data or analyses using proprietary algorithms...|$|R
5000|$|A 2007 {{paper by}} Batchelor used Consensus Forecasts data to {{consider}} various theories of bias in macroeconomic forecasts, and concluded: [...] "In all countries {{there is evidence}} that individual forecasters converge on the <b>consensus</b> <b>forecast</b> too slowly. However, the persistent optimism of some forecasters, and the persistent pessimism of others, is not consistent with the predictions of models of “rational bias” that have become popular in the finance and economics literature." ...|$|E
50|$|Tax {{cuts will}} expire for the wealthiest taxpayers to {{increase}} revenues, returning marginal rates to the Clinton levels. Further, the base Department of Defense budget increases slightly through 2014 (Table S-7), from $534 to $575 billion, although supplemental appropriations for the Iraq War {{are expected to}} be reduced. In addition, estimates of revenue are based on GDP growth assumptions that exceed the Blue Chip Economists' <b>consensus</b> <b>forecast</b> considerably through 2012 (Table S-8).|$|E
50|$|The Systematic Approach Forecast Aid (SAFA) was {{developed}} by the Joint Typhoon Warning Center to create a selective <b>consensus</b> <b>forecast</b> which removed more erroneous forecasts at a 72‑hour time frame from consideration using the United States Navy NOGAPS model, the GFDL, the Japan Meteorological Agency's global and typhoon models, as well as the UKMET. All the models improved during SAFA's five-year history and removing erroneous forecasts proved difficult to do in operations.|$|E
40|$|This paper investigates whether survey forecasters {{are able}} to make more {{accurate}} forecasts than simply supposing that the future values of the variable will move monotonically to the long-run expectation. We consider the forecasts individually, and the <b>consensus</b> <b>forecasts.</b> <b>Consensus</b> survey <b>forecasts</b> {{are able to}} do so to varying degrees depending on the variable, but this ability is largely limited to forecasts of the current quarter...|$|R
50|$|Academics {{have looked}} at the {{projections}} and forecasting record of the OECD as well as the International Monetary Fund, in some cases comparing these to <b>consensus</b> <b>forecasts</b> such as those published by Consensus Economics.|$|R
40|$|In {{capital markets}} research, market {{expectation}} of future earnings plays a vital role. However, almost all proxies inevitably measure the market expectation of future earnings with error, {{which results in}} unsatisfactory empirical outcomes in prior research (e. g., small empirical values of earnings response coefficient and poor quality estimates of expected rates of return). Using analysts' <b>consensus</b> <b>forecasts,</b> this study investigates how noisy measurement of the market expectation of future earnings affects the predictability of future earnings and stock returns. Based on the errors-in-variables approach, this study first provides a framework to capture cross-sectional variation of the measurement error in analysts' <b>consensus</b> <b>forecasts.</b> With this framework in place, this study documents that analysts' <b>consensus</b> <b>forecasts</b> with more measurement error have less ability to predict future earnings and stock returns, and that incorporating information about cross-sectional variation of the measurement error can improve the predictability of future earnings and stock returns. These findings will be useful to accounting research that relies on the market expectation of future earnings and to practitioners seeking to forecast profitability and stock returns...|$|R
50|$|In 2009 the {{institute}} founded the ULI Center for Capital Markets and Real Estate. According to ULI, {{the mission is}} “to promote understanding {{of the real estate}} capital markets and provide leadership in fostering a healthy and productive real estate capital markets sector.” The center hosts an annual capital markets and real estate conference, where it convenes industry practitioners, experts and economists for two days of panel sessions. The center also publishes a semiannual Real Estate <b>Consensus</b> <b>Forecast</b> that is often cited in financial news publications. In addition, since its founding, the center has assumed responsibility for partnering with PricewaterhouseCoopers to publish its annual Emerging Trends in Real Estate report.|$|E
5000|$|In sum, the {{usefulness}} of the <b>consensus</b> <b>forecast</b> technique has been supported by a wealth of empirical studies in recent decades. The use of equal weights in the combining method is appealing because of its simplicity and is easy to describe. Among others, this simple method of averaging the forecasts of individual forecasters has been put into practice by many of the world's central banks as they try to gauge expectations in the private sector. An empirical study carried out by Roy Batchelor in 2000 demonstrates greater accuracy in the consensus forecasts over macroeconomic projections produced by leading multinational agencies such as the International Monetary Fund and the Organisation for Economic Co-operation and Development. A study by Robert C. Jones found: [...] "At least since the publication of “The Combination of Forecasts” (Bates and Granger 1969), economists have known that combining forecasts from different sources can both improve accuracy and reduce forecaster error. In the intervening years, numerous studies have confirmed these conclusions, outlined conditions under which forecast combinations are most effective, and tried to explain why simple equal weights work so well relative to more sophisticated statistical techniques.” ...|$|E
50|$|This {{method of}} taking a simple mean average of a panel of {{independent}} forecasts, derived from different forecasting methods, is known as combining forecasts {{and the result is}} often referred to as a <b>consensus</b> <b>forecast.</b> Unless a particular forecast model which produces smaller forecast errors compared to other individual forecasts can be identified, adopting the consensus approach can be beneficial due to diversification gains. Combining economic forecasts is well established in many countries and can count central banks, government institutions and businesses among the users. In recent decades, consensus forecasts have attracted much interest, backed by the publication of a huge swathe of academic research on forecast accuracy. Empirical studies show that pooling forecasts increased forecast accuracy. One of the advantages of using consensus forecasts is that it can prove useful if there is a high degree of uncertainty or risk attached to the situation and the selection of the most accurate forecast in advance is difficult. Even if one method is identified as the best, combining is still worthwhile if other methods can make some positive contribution to the forecast accuracy. Moreover, many factors can affect the independent forecast and these, along with any additional useful information, might be captured by using the consensus approach. Another argument in favour of this method is that individual forecasts may be subject to numerous behavioural biases, but these can be minimised by combining independent forecasts together. Hence, combining is seen as helping to improve forecast accuracy by reducing the forecast errors of individual forecasts. Furthermore, averaging forecasts is likely to be more useful when the data and the forecasting techniques that the component forecasts are drawn from differ substantially. And even though it is only a simple approach (typically an unweighted mean average), this method is just as useful as other more sophisticated models. Indeed, more recent studies in the past decade have shown that, over time, the equal weights combined forecast is usually more accurate than the individual forecast which make up the consensus.|$|E
5000|$|Methods of {{forecasting}} include Econometric models, Economic base analysis, Shift-share analysis, Input-output {{model and}} the Grinold and Kroner Model. See also Land use forecasting, Reference class forecasting, Transportation planning, Calculating Demand <b>Forecast</b> Accuracy and <b>Consensus</b> <b>forecasts</b> ...|$|R
50|$|Consensus Economics publishes Consensus ForecastsTM, {{a widely}} cited monthly {{compilation}} of macroeconomic forecasts and topical analyses by country for 115 economies. The countries covered include member {{countries of the}} G-7 industrialized nations, Asia Pacific, Eastern Europe, and Latin America. It also has more specialized publications such as the Foreign Exchange forecasts and Energy & Metals <b>Consensus</b> <b>Forecasts.</b> Each publication is distributed in hard-copy format and via email as PDF files and Excel spreadsheets. Once a year the company releases The <b>Consensus</b> <b>Forecasts</b> Global Outlook {{at the start of}} November, which covers long-term forecasts for countries in Western and Eastern Europe, North and South America and the Asia Pacific.|$|R
50|$|In early 2013, The NAVGEM {{replaced}} the NOGAPS as the Navy's primary operational global forecast model. For the 2013 season, and until model verification can occur, {{it is not}} being utilized {{in the development of}} any <b>consensus</b> <b>forecasts.</b>|$|R
40|$|This paper {{presents}} the results of a survey of 510 finance and economics professors. The <b>consensus</b> <b>forecast</b> for the 1 -year equity premium is about 3 % to 3. 5 %, the <b>consensus</b> <b>forecast</b> for the 30 -year equity premium (arithmetic) is about 5 % to 5. 5 %. The consensus 30 -year stock market forecast is about 10 %. These forecasts are considerably lower than those taken just 3 years ago. I thank Hersh Shefrin for feedback. 1...|$|E
40|$|This article {{evaluates the}} quality of an average or <b>consensus</b> <b>forecast</b> for {{economic}} growth in Belgium. A quarterly series of current and one-year-ahead growth forecasts is constructed as the average of forecasts published by Belgian institutions. In similar foreign studies a fixed number of forecasts is considered since a forecaster is only included if he published forecasts in every quarter of the sample; we do not take this restrictive view but calculated the average of all forecasts made available in any quarter. The consensus growth forecasts will be evaluated graphically, statistically and econometrically. The conclusion is that the Belgian <b>consensus</b> <b>forecast</b> is rather good, although some efficiency tests are not passed. info:eu-repo/semantics/publishe...|$|E
40|$|Abstract We utilize new {{income tax}} reserve {{disclosures}} required under FIN 48 {{to examine whether}} managers use discretion over this accrual to manage earnings to meet the consensus analyst forecast. We find that firms with pre-managed earnings (i. e., earnings before {{the change in the}} tax reserve) that are below the consensus analyst forecast {{are far more likely to}} reduce their tax reserves and thus report higher net income. In fact, we find that 37 percent of firm-years with pre-managed earnings below the <b>consensus</b> <b>forecast</b> meet the forecast when the change in the tax reserve is included in earnings. In contrast, only 9. 8 percent of firm-years with pre-managed earnings above the <b>consensus</b> <b>forecast</b> increased their tax reserves to the extent that it caused them to miss the <b>consensus</b> <b>forecast.</b> This asymmetric result is consistent with managers using their discretion over tax reserves to meet consensus analyst forecasts. Using a proxy for changes in tax reserves developed by Blouin and Tuna (2007), we also document a decline in the use of tax reserves to meet the consensus analyst forecast following the adoption of FIN 48. Nonetheless, our results using both estimated and actual changes in tax reserves clearly suggest that managers continue to use their discretion over this account to meet the consensus analys...|$|E
40|$|This study {{examines}} {{the ability of}} economists to forecast ten major economic series. The {{data for this study}} were provided by J. A. Livingston of the Philadelphia Inquirer, who since 1947 has collected forecasts for the upcoming 6 and 12 months. The results reveal that, in general, for the period from 1947 through 1978, the economists in Livingston's sample did not produce efficient forecasts and were not able to outperform simple statistical models. It should be noted, however, that a substantial and consistent improvement in forecasting performance by economists in Livingston's sample did occur over this same period. These results contain important information for managers who use macro-economic <b>consensus</b> <b>forecasts.</b> <b>consensus</b> <b>forecasts,</b> macro-economic variables, efficient forecasts, forecast errors...|$|R
40|$|An initial {{configuration}} of the Operational <b>Consensus</b> <b>Forecasts</b> (OCF) system was operationally implemented in NMOC beginning with the 00 UTC run on 8 March 2005. The OCF system, formally known in the non-operational state as BOG (Best Objective Guidance) {{was developed by the}} Weather Forecasting Group in BMRC...|$|R
40|$|The Wave OCF (Operational <b>Consensus</b> <b>Forecasting)</b> system optimally {{combines}} the direct model outputs {{from a number}} of wave models and produces wave forecasts for the selected wave buoy sites around the Australian coasts (Woodcock and Greenslade, 2007). It produces forecasts of significant wave height, peak wave period, win...|$|R
