451|672|Public
5|$|Watson took a {{commanding}} lead in Double Jeopardy!, correctly responding to both Daily Doubles. Watson {{responded to the}} second Daily Double correctly with a 32% <b>confidence</b> <b>score.</b>|$|E
25|$|The data is {{weighted}} {{and integrated}} and a <b>confidence</b> <b>score</b> is calculated for all protein interactions. Results {{of the various}} computational predictions can be inspected from different designated views. There are two modes of STRING: Protein-mode and -mode. Predicted interactions are propagated to proteins in other organisms for which interaction {{has been described by}} inference of orthology. A web interface is available to access the data and to give a fast overview of the proteins and their interactions. A plug-in for cytoscape to use STRING data is available.|$|E
25|$|A {{significant}} increase in accuracy (to nearly ~80%) was made by exploiting multiple sequence alignment; knowing the full distribution of amino acids that occur at a position (and in its vicinity, typically ~7 residues on either side) throughout evolution provides a much better picture of the structural tendencies near that position. For illustration, a given protein might have a glycine at a given position, which by itself might suggest a random coil there. However, multiple sequence alignment might reveal that helix-favoring amino acids occur at that position (and nearby positions) in 95% of homologous proteins spanning nearly a billion years of evolution. Moreover, by examining the average hydrophobicity at that and nearby positions, the same alignment might also suggest a pattern of residue solvent accessibility consistent with an α-helix. Taken together, these factors {{would suggest that the}} glycine of the original protein adopts α-helical structure, rather than random coil. Several types of methods are used to combine all the available data to form a 3-state prediction, including neural networks, hidden Markov models and support vector machines. Modern prediction methods also provide a <b>confidence</b> <b>score</b> for their predictions at every position.|$|E
40|$|This paper {{proposes a}} method for the <b>confidence</b> <b>scoring</b> of {{intention}} recognition results in spoken dialogue systems. To achieve tasks, a spoken dialogue system has to recognize user intentions. However, because of speech recognition errors and ambiguity in user utterances, it sometimes has difficulty recognizing them correctly. <b>Confidence</b> <b>scoring</b> allows errors to be detected in intention recognition results and has proved useful for dialogue management. Conventional methods use the features obtained from speech recognition results for single utterances for <b>confidence</b> <b>scoring.</b> However, this may be insufficient since the intention recognition result {{is a result of}} discourse processing. We propose incorporating discourse features for a more accurate <b>confidence</b> <b>scoring</b> of intention recognition results. Experimental results show that incorporating discourse features significantly improves the <b>confidence</b> <b>scoring.</b> 1...|$|R
40|$|In {{this paper}} we present an {{approach}} to recognition <b>confidence</b> <b>scoring</b> and a method for integrating <b>confidence</b> <b>scores</b> into the understanding and dialogue components of a speech understanding system. The system uses a multi-tiered approach where <b>confidence</b> <b>scores</b> are computed at the phonetic, word, and utterance levels. The scores are produced by extracting confidence features from the computation of the recognition hypotheses and processing these features using an accept/reject classifier for word and utterance hypotheses. The output of the confidence classifiers can then {{be incorporated into the}} parsing mechanism of the language understanding component. To evaluate the system, experiments were conducted using the JUPITER weather information system. Evaluation was performed at the understanding level using key-value pair concept error rate as the evaluation metric. When <b>confidence</b> <b>scores</b> were integrated into the understanding component of the system, the concept error rate was reduced [...] ...|$|R
40|$|In this study, {{we aim to}} test our {{hypothesis}} that <b>confidence</b> <b>scores</b> of sentiment values of tweets aid in classification of sentiment. We used several feature sets consisting of lexical features, emoticons, features based on sentiment scores and combination of lexical and sentiment features. Since our dataset includes <b>confidence</b> <b>scores</b> of real numbers in [0 - 1] range, we employ regres-sion analysis on each class of sentiments. We determine the class label of a tweet {{by looking at the}} maximum of the <b>confidence</b> <b>scores</b> assigned to it by these regressors. We test the results against classification results obtained by converting the confi-dence scores into discrete labels. Thus, the strength of sentiment is ignored. Our expectation was that taking the strength of sentiment into consideration would im-prove the classification results. Contrary to our expectations, our results indicate that using classification on discrete class labels and ignoring sentiment strength per-form similar to using regression on contin-uous <b>confidence</b> <b>scores.</b> ...|$|R
5000|$|... #Caption: Protein-protein {{interaction}} network visualized by STRING. In this view, {{the color}} saturation of the edges represents the <b>confidence</b> <b>score</b> of a functional association ...|$|E
50|$|Watson took a {{commanding}} lead in Double Jeopardy!, correctly responding to both Daily Doubles. Watson {{responded to the}} second Daily Double correctly with a 32% <b>confidence</b> <b>score.</b>|$|E
5000|$|Estimated {{accuracy}} of the predicted models (including a <b>confidence</b> <b>score</b> of all models, predicted TM-score and RMSD for the first model, and per-residue error of all models) ...|$|E
40|$|We are {{interested}} in the problem of robust understanding from noisy spontaneous speech input. In goal driven humanmachine dialog, utterance classification is a key component of the understanding process to determine the intent of the speaker. In this paper we propose a novel algorithm for exploiting ASR word <b>confidence</b> <b>scores</b> for better utterance classification of spoken utterances. Word <b>confidence</b> <b>scores</b> for automatic speech recognition (ASR) provide estimates for word error rates. While previous work has focused on straightforward combination of word <b>confidence</b> <b>scores</b> into Bayesian classifiers, in this paper we extend the mathematical formulation for Boosting classifiers. This extension of the algorithm allows to exploit <b>confidence</b> <b>scores</b> from a 1 -best ASR output or from word confusion networks (WCNs). We present methods for on-line and off-line score combinations. The results we show are for a large database of utterances collected using the AT&T VoiceTone spoken dialog system. Our experiments show between 5 %- 10 % reduction in error () foragiven using WCNs compared to ASR output. 1...|$|R
3000|$|... will be obtained, {{approaching}} 0, {{which makes}} the classification <b>confidence</b> <b>scores</b> rather closed to each other.|$|R
40|$|Abstract. Computational Trust and Reputation (CTR) {{systems are}} {{platforms}} capable of collecting trust information about candidate partners and of comput-ing <b>confidence</b> <b>scores</b> {{for each one}} of these partners. These systems start to be viewed as vital elements in environments of electronic institutions, as they sup-port fundamental decision making processes, such as the selection of business partners and the automatic and adaptive creation of contractual terms and asso-ciated enforcement methodologies. In this article, we propose a model for the aggregation of trust evidences that computes <b>confidence</b> <b>scores</b> taking into account dynamic properties of trust. We compare our model with a traditional statistical model that uses weighted means to compute trust, and show experi-mental results that show that in certain scenarios the consideration of the trust dynamics allows for a better estimation of <b>confidence</b> <b>scores.</b> ...|$|R
50|$|Early {{after his}} election, he left Marois' {{organization}} to back Bernard Landry who was gaining support {{in order to}} get a decent <b>confidence</b> <b>score</b> at a mandatory PQ internal vote.|$|E
5000|$|The ASR and NLU modules {{are usually}} not 100% sure they {{understood}} the user; they usually return a <b>confidence</b> <b>score</b> reflecting the quality of understanding. In such cases, the DM should decide whether to: ...|$|E
50|$|The {{image to}} the right is the {{predicted}} tertiary structure of GPATCH11 based on results obtained from I-tasser. The <b>confidence</b> <b>score</b> was very low though, so reliability is uncertain. However, it does match up with the secondary structure prediction of the protein being composed primarily of alpha-helices and coiled coils.|$|E
40|$|Recognition errors {{hinder the}} {{proliferation}} of speech recognition (SR) systems. Based on the observation that recognition errors may result in ungrammatical sentences, especially in dictation application where an acceptable level of accuracy of generated documents is indispensable, we propose to incorporate two kinds of linguistic features into error detection: lexical features of words, and syntactic features from a robust lexicalized parser. Transformation-based learning is chosen to predict recognition errors by integrating word <b>confidence</b> <b>scores</b> with linguistic features. The experimental results on a dictation data corpus show that linguistic features alone are not as useful as word <b>confidence</b> <b>scores</b> in detecting errors. However, linguistic features provide complementary information when combined with word <b>confidence</b> <b>scores,</b> which collectively reduce the classification error rate by 12. 30 % and improve the F measure by 53. 62 %. ...|$|R
3000|$|Late {{fusion of}} the {{audiovisual}} and text <b>confidence</b> <b>scores,</b> where a fixed weight w for the text stream was chosen: C [...]...|$|R
50|$|PEAKS {{provides}} a complete sequence for each peptide, <b>confidence</b> <b>scores</b> on individual amino acid assignments, simple reporting for high-throughput analysis, amongst other information.|$|R
5000|$|Fold Prediction: In fold {{recognition}} strategies, {{a prediction}} of secondary structure is first made and then compared {{to either a}} library of known protein folds, such as CATH or SCOP, or {{what is known as}} a [...] "periodic table" [...] of possible secondary structure forms. A <b>confidence</b> <b>score</b> is then assigned to likely matches.|$|E
5000|$|To return {{only those}} terms {{with a high}} <b>confidence</b> <b>score,</b> a filter {{can be used on}} the Score column with the {{following}} method call: [...] The query result is shown in the following table. In this case, only four rows are returned, as these are the only terms that meet the criterion of the filter.|$|E
50|$|The one-vs.-rest (or one-vs.-all, OvA or OvR, one-against-all, OAA) {{strategy}} involves {{training a}} single classifier per class, with the samples of that class as positive samples {{and all other}} samples as negatives. This strategy requires the base classifiers to produce a real-valued <b>confidence</b> <b>score</b> for its decision, rather than just a class label; discrete class labels alone can lead to ambiguities, where multiple classes are predicted for a single sample.|$|E
40|$|Word <b>confidence</b> <b>scores</b> {{are crucial}} for {{unsupervised}} learning in automatic speech recognition. In {{the last decade}} {{there has been a}} flourish of work on two fundamentally different approaches to compute <b>confidence</b> <b>scores.</b> The first paradigm is acoustic and the second is based on word lattices. The first approach is dataintensive and it requires to explicitly model the acoustic channel. The second approach is suitable for on-line (unsupervised) learning and requires no training. In this paper we present a comparative analysis of off-the-shelf and new algorithms for computing <b>confidence</b> <b>scores,</b> following the acoustic and lattice-based paradigms. We compare the performance of these algorithms across three tasks for small, medium and large vocabulary speech recognition tasks and for two languages (Italian and English). We show that wordlattice based algorithm provides consistent and effective performance across automatic speech recognition tasks. 1...|$|R
30|$|<b>Confidence</b> <b>scores</b> sorting so as {{to define}} the {{segments}} {{to be included in}} the summary; a five times faster summary than real time was created.|$|R
40|$|In {{this paper}} {{we present a}} method for {{integrating}} <b>confidence</b> <b>scores</b> into the understanding and dialogue components of a speech understanding system. The understanding component of our system receives an #-best list of recognition hypotheses augmented with word-level <b>confidence</b> <b>scores.</b> The <b>confidence</b> <b>scores</b> are used by the understanding component to hypothesize when words in a recognizer's #-best list have been misrecognized. The understanding component {{has the ability to}} predict the semantic class of misrecognized words based on the surrounding context and also to suggest when key words which may have been misunderstood should be re-confirmed by the user. The output of the understanding component is passed onto a dialogue control component which can act on various suggestions made by the understanding component. To evaluate the system, experiments were conducted using the JUPITER weather information system. Evaluation was performed at the understanding level using key-value pair conc [...] ...|$|R
5000|$|To {{view the}} five {{suggested}} five {{terms with the}} corresponding <b>confidence</b> <b>score,</b> a third parameter {{can be used to}} indicate that statistics should be returned: [...] The query result is shown in the following table along with columns for score and support. The results are similar to those available through the Data Mining Extensions (DMX) in SQL. Score represents the confidence or probability; support represents the number of cases supporting the rule in the training dataset.|$|E
50|$|The data is {{weighted}} {{and integrated}} and a <b>confidence</b> <b>score</b> is calculated for all protein interactions. Results {{of the various}} computational predictions can be inspected from different designated views. There are two modes of STRING: Protein-mode and COG-mode. Predicted interactions are propagated to proteins in other organisms for which interaction {{has been described by}} inference of orthology. A web interface is available to access the data and to give a fast overview of the proteins and their interactions. A plug-in for cytoscape to use STRING data is available.Another possibility to access data STRING is to use the application programming interface (API) by constructing a URL that contain the request.|$|E
5000|$|The {{interaction}} between GPATCH11 and BAI3 was found via PSICQUIC, mentha, and STRING. The <b>confidence</b> <b>score</b> given by mentha is only [...]454, however, according to STRING the {{interaction between}} the two proteins has been experimentally determined by a validated two-hybrid approach. The two proteins are thought to have a direct physical interaction. BAI3 is a transmembrane protein and a p53 target gene. BAI3 may regulate the number of excitatory synapses that are formed on the hippocampus neurons, and may be involved in angiogenesis inhibition and suppression of glioblastoma. As GPATCH11does have higher expression than the average gene in the hippocampus and the spinal cord, this could be a real interaction.|$|E
40|$|Knowledge of all {{molecular}} {{interactions that}} poten-tially {{take place in}} the cell is a key for a detailed understanding of cellular processes. Currently avail-able interaction data, such as protein–protein inter-action maps, are known to contain false positives that inevitably diminish the accuracy of network-based inferences. Interaction <b>confidence</b> <b>scoring</b> is thus a crucial intermediate step after obtaining interaction data and before using it in an interaction network-based inference approach. It enables to weight individual interactions according to the likelihood that they actually {{take place in the}} cell, and can be used to filter out false positives. We describe a web tool called IntScore which cal-culates <b>confidence</b> <b>scores</b> for user-specified sets of interactions. IntScore provides six network topology- and annotation-based <b>confidence</b> <b>scoring</b> methods. It also enables the integration of scores calculated by the different methods into an aggregate score using machine learning approaches. IntScore is user-friendly and exten-sively documented. It is freely available a...|$|R
40|$|Abstract—The {{application}} of Bayesian fusion of confidence measures to speech recognition is proposed. Feature level, decision level, and hybrid fusion are considered under the Bayesian framework. The use of speaker-adapted feature-level Bayesian fusion reduced the error rate by 19. 4 % {{as compared to}} the conventional single feature-based <b>confidence</b> <b>scoring</b> in an isolated word out-of-vocabulary rejection test. The decision-level Bayesian fusion also showed better performance than the majority rule. Finally, hybrid Bayesian fusion, which can combine both confidence measure features and local decisions, achieved the best performance. Index Terms—Adaptive <b>confidence</b> <b>scoring,</b> Bayesian fusion, <b>confidence</b> measure (CM), speech recognition. I...|$|R
40|$|For {{extractive}} meeting summarization, {{previous studies}} have shown performance degradation when using speech recognition transcripts because of the relatively high speech recognition errors on meeting recordings. In this paper we investigated using confusion networks to improve the summarization performance on the ASR condition under an unsupervised framework by considering more word candidates and their <b>confidence</b> <b>scores.</b> Our experimental results showed improved summarization performance using our proposed approach, with more contribution from leveraging the <b>confidence</b> <b>scores.</b> We also observed that using these rich speech recognition results can extract similar or even better summary segments than using human transcripts. ...|$|R
50|$|However, once trained, {{the network}} {{can also be}} run in reverse, being asked to adjust the {{original}} image slightly so that a given output neuron (e.g. the one for faces or certain animals) yields a higher <b>confidence</b> <b>score.</b> This {{can be used for}} visualizations to understand the emergent structure of the neural network better, and is the basis for the DeepDream concept. However, after enough reiterations, even imagery initially devoid of the sought features will be adjusted enough that a form of pareidolia results, by which psychedelic and surreal images are generated algorithmically. The optimization resembles Backpropagation, however instead of adjusting the network weights, the weights are held fixed and the input is adjusted.|$|E
50|$|The {{detection}} and tracking takes place from an aerial view, which implies that each {{object in the}} scene is composed {{of only a few}} pixels. Therefore, there are only a couple of pixels {{that can be used for}} tracking.A major part used for detection is the shadow of an object. The shadow of an object goes through a normalization procedure and is then passed into a trained Gentle AdaBoost Classifier. The AdaBoost Classifier is a machine learning meta-algorithm which can be used with many other types of algorithms to improve their performance, like it is used in this case. This produces a <b>confidence</b> <b>score</b> of the likeliness of an object being in that area. These results are used to form the base of the Tracking-by-Detection approach.|$|E
5000|$|Once data is uploaded, {{the system}} {{automatically}} allocates {{the work to}} contributors and tests them against known answers hidden within the task (what CrowdFlower refers to as a [...] "job" [...] ). The way in which contributors perform on these hidden test questions calibrates how much the system trusts them on an individual level. As long as contributors remain trusted they're allowed to continue working on a given job. If they become untrusted, they're removed from the job and all of their work is disregarded. Multiple contributor judgments are collected and an aggregate answer with an associated <b>confidence</b> <b>score</b> (agreement of the contributors weighted by the trust of each contributor) is provided as a result - effectively returning the [...] "most trusted judgment," [...] for a given unit of data.|$|E
40|$|In this paper, a {{discourse}} modeller for conversational spoken dialogue systems, called GALATEA, is presented. Apart from handling {{the resolution of}} ellipses and anaphora, it tracks the “grounding status ” of concepts that are mentioned during the discourse, i. e. information about who said what when. This grounding information also contains concept <b>confidence</b> <b>scores</b> that are derived from the speech recogniser word <b>confidence</b> <b>scores.</b> The discourse model may then be used for concept-level error handling, i. e. grounding of concepts, fragmentary clarification requests, and detection of erroneous concepts in the model at later stages in the dialogue. ...|$|R
40|$|This paper {{describes}} {{a technique to}} include acoustic <b>confidence</b> <b>scores</b> as returned by automated speech recognisers in generic semantic representations. The method we propose requires only minimal changes to an existing grammar used for speech applications. Special {{attention is paid to}} the treatment of multi-word lexemes and combining several (N-best) speech recognition results into one semantic representation. The approach has been implemented and tested using the Nuance speech recognition software and a chart parser, in the formalism of underspecified discourse representations. The potential relevance of <b>confidence</b> <b>scores</b> in rich semantic representations is illustrated by generating more flexible clarification questions in dialogue systems...|$|R
40|$|Computing Confidence Values: Does Trust Dynamics Matter?Em um Sistema Multi-agente, a selecção de outros agentes para trabalho conjunto depende da {{eventual}} confiança que é esperada existir no desempenho desses outros. Propomos uma forma de agregar indícios para computar correctamente uma função cujo resultado seja um valor de confiançaComputational Trust and Reputation (CTR) {{systems are}} platforms capable of collecting trust information about candidate partners and of computing <b>confidence</b> <b>scores</b> {{for each one}} of these partners. These systems start to be viewed as vital elements in environments of electronic institutions, as they support fundamental decision making processes, such as the selection of business partners and the automatic and adaptive creation of contractual terms and associated enforcement methodologies. In this article, we propose a model for the aggregation of trust evidences that computes <b>confidence</b> <b>scores</b> taking into account dynamic properties of trust. We compare our model with a traditional statistical model that uses weighted means to compute trust, and show experimental results that show that in certain scenarios the consideration of the trust dynamics allows for a better estimation of <b>confidence</b> <b>scores...</b>|$|R
