0|6187|Public
50|$|AA+ {{systems would}} be shipped with the {{forthcoming}} AmigaOS 4 which added RTG support for <b>chunky</b> <b>pixels.</b>|$|R
5000|$|New Agnus/Alice {{replacement}} chip 'Andrea' with {{an updated}} 32-bit blitter and Copper which can handle <b>chunky</b> <b>pixels.</b>|$|R
50|$|Commodore {{stated that}} AA+ was {{designed}} to support ALL 32-bit 680x0 CPUs. For <b>Chunky</b> <b>pixels</b> support, low end systems would most likely feature a 68020 with full 32-bit memory addressing (i.e. not 68EC020) or even 68EC030 which could handle RTG drivers easily. Commodore did not add <b>chunky</b> <b>pixels</b> to AGA at the time because RTG required at least 68020 (not 68020EC as in A1200) with 4 MB memory at least, while the standard A1200 had only 2 MB and 68EC020 CPU.|$|R
50|$|AA+ {{would use}} 60 ns DRAM, but AA+ systems would {{need at least}} 4 MB as a {{standard}} to support RTG and packed (<b>Chunky)</b> <b>pixels,</b> an A1200 like systems (A1400?) would most likely be shipped with 8 MB which was the standard in 1994 for low end PCs.|$|R
50|$|The framebuffer {{organization}} may be <b>chunky</b> (packed <b>pixel)</b> or planar.|$|R
50|$|In 2007 {{he made a}} C64-version of Deep Throat {{together}} with Role Model. The full movie was converted into <b>chunky</b> <b>pixel</b> graphics, which was streamed from the C64 datasette in realtime. He has also remixed more contemporary artists, such as Monster Zoku Onsomb, Icarus, Tim Koch, Psilodump, Dubmood, Damn! and Best Fwends.|$|R
5000|$|Direct <b>Chunky</b> 16-bit <b>pixels</b> (15 bits for 32768 {{colors and}} 1 bit for genlock overlay), {{provided}} by custom chip 'Monica', this mode requires RTG driver.|$|R
30|$|This {{chain code}} feature {{has been applied}} twice for {{skeleton}} and boundary <b>pixel</b> <b>image</b> drawing orders as: first find chain codes occurrences for all 61 and 131 points of skeleton and boundary <b>pixel</b> <b>image</b> drawing order; second, find chain code occurrences for chain codes derived from every odd pixel position from 61 and 131 points of skeleton and boundary <b>pixel</b> <b>image</b> drawing order.|$|R
30|$|The {{points are}} {{resampled}} to 61 and 131 for skeleton and boundary <b>pixel</b> <b>images</b> drawing order, respectively. We have experimented to resample from 41 to 91 for skeleton and 91 to 181 for boundary <b>pixels</b> <b>images</b> drawing order. The selection of 61 and 131 points for skeleton and boundary <b>pixels</b> <b>images</b> drawing order {{are made on}} the basis of lowest error rate achieved.|$|R
5000|$|During an {{interview}} with tumblr blog fuckyeahspacefuneral, developer thecatamites stated that the game's artstyle was [...] "based on the weird <b>chunky</b> <b>pixel</b> gore from Monster Party especially the way it could be {{hard to figure out}} what a wall of tiled bloody heads was meant to represent in game space." [...] The music selection of Space Funeral was stated to have been selected by [...] "pulling together things based on kind of superficially similar tendencies and almost creating a fake tradition in that way which could change how you progress from there." ...|$|R
30|$|Anyway, {{with this}} parallelization scheme, the {{computation}} of the optical flow achieves a throughput of 30 images per second with 502 × 288 <b>pixel</b> <b>images.</b> For 720 × 576 <b>pixel</b> <b>images,</b> the throughput obtained is ten images per second.|$|R
30|$|For the × 5  mm lens—a 256  ×  256 <b>pixel</b> <b>image</b> was scanned at zoom 1 (field of view (FOV) of 2  ×  2  mm), or a 128  ×  128 <b>pixel</b> <b>image</b> was scanned at zoom 2 (FOV 1  ×  1  mm).|$|R
50|$|Additionally, the Akiko chip is able {{to perform}} simple 'chunky' to 'planar' {{graphics}} conversion in hardware. The Amiga's native display is a planar display which is simple and efficient to manipulate for routines like scrolling. However, chunky displays are faster and more efficient for 3D graphics manipulation. Akiko allows this conversion to be performed in hardware instead of relying on software conversion which would cause more overhead. The conversion works by writing 32 8-bit <b>chunky</b> <b>pixels</b> to Akiko's registers and reading back eight 32-bit words of converted planar data which can then be copied to the display buffer.|$|R
30|$|Now, {{the cover}} image will {{be divided into}} a number of 8 <b>pixels</b> <b>image</b> blocks.|$|R
50|$|After {{the header}} the image itself starts.This example {{will use the}} {{following}} 72x28 <b>pixel</b> <b>image.</b>|$|R
5000|$|... "AA+ {{will be a}} more {{profitable}} version of AA with {{all the things we}} wished we'd got in but didn't have time. We have {{a list of all the}} problems we currently have at the low end. The serial port, we can't read high density floppies, there isn't enough band width to do 72 Hz screens plus there are no <b>chunky</b> <b>pixel</b> modes for rendering. We listed all those and said, [...] "OK let's go out and fix them as quickly as we can", so AA+ is an extension, not radically new architecture. We're doing the best that we can, taking advantage of advances in technology, significantly reducing the cost and that's the goal." ...|$|R
5000|$|For example, a 640 * 480 <b>pixel</b> <b>image</b> with 24-bit color would occupy {{almost a}} {{megabyte}} of space: ...|$|R
50|$|JPEG 2000 {{supports}} any bit depth, such as 16- and 32-bit {{floating point}} <b>pixel</b> <b>images,</b> and any color space.|$|R
3000|$|... [...]. In this article, one {{orientation}} per {{image is}} randomly selected. The 576 [*]×[*] 576 <b>pixels</b> <b>images</b> are here {{divided into four}} 288 [*]×[*] 288 <b>pixels,</b> non-overlapping, sub <b>images</b> resulting in 640 samples of each class.|$|R
30|$|For the × 10  mm lens, a 128  ×  128 <b>pixel</b> <b>image</b> was scanned at zoom 1 (FOV 1  ×  1  mm).|$|R
40|$|An {{apparatus}} {{for providing}} an image is provided. The apparatus comprises a sensor (110) comprising {{a plurality of}} sensor pixels, wherein each of the sensor pixels of the sensor (110) comprises one or more photosensitive elements, wherein each of {{the one or more}} photosensitive elements comprises a photosensitive area, wherein the sensor (110) is configured to provide image data comprising a plurality of first <b>image</b> <b>pixels,</b> and wherein each of the sensor pixels is configured to provide one of the first <b>image</b> <b>pixels</b> of the <b>image</b> data. Moreover, the apparatus comprises an image reconstructor (120; 220) for providing the image, wherein the image comprises a plurality of second <b>image</b> <b>pixels,</b> wherein the <b>image</b> reconstructor (120; 220) is configured to generate the second <b>image</b> <b>pixels</b> of the <b>image</b> depending on the first <b>image</b> <b>pixels</b> of the <b>image</b> data, wherein the number of the first <b>image</b> <b>pixels</b> of the <b>image</b> data is smaller than the number of the second <b>image</b> <b>pixels</b> of the <b>image</b> data, wherein the image reconstructor (120; 220) is configured to generate each of a group of {{one or more of the}} second <b>image</b> <b>pixels</b> depending on at least two of the first <b>image</b> <b>pixels.</b> At least one of the sensor pixels of the sensor (110) comprises two or more photosensitive elements being connected such that said one of the first <b>image</b> <b>pixels</b> provided by said sensor pixel depends on each of the two or more photosensitive elements. Or, the photosensitive area of a first one of the photosensitive elements of the sensor pixels of the sensor (110) has a first shape being different from a second shape of the photosensitive area of a second one of the photosensitive elements of the sensor pixels, wherein said first shape is concave...|$|R
40|$|This Program {{created for}} hide {{messages}} in the image. The program uses {{least significant bit}} method to hide the messages into edge <b>pixel</b> of <b>image.</b> In this program, hiding of messages {{will be carried out}} on the edges <b>pixel</b> of <b>image</b> (<b>pixels</b> that have a value of 255) starting from the random coordinates of edge <b>pixels.</b> The <b>images</b> will be processed edge detection first using Sobel method to obtain edges <b>pixel</b> <b>image.</b> There will also decode process to take the hidden message in the image. The result of steganography is an image that is similar to the original image but inside it there is a message / information. The result of the decoding process is the message contained in the image. This project is not perfect yet, because sometimes the decode messages result is not equal to encode messages...|$|R
50|$|The pixel {{aspect ratio}} {{is always the}} same for {{corresponding}} 720 and 704 pixel resolutions because the center part of a 720 <b>pixels</b> wide <b>image</b> is equal to the corresponding 704 <b>pixels</b> wide <b>image.</b>|$|R
50|$|Each {{image is}} about 300x200 <b>pixels.</b> <b>Images</b> of {{oriented}} {{objects such as}} airplanes and motorcycles were mirrored {{to be left to}} right aligned and vertically oriented structures such as buildings were rotated to be off axis.|$|R
50|$|The M uses a CMOS 24-megapixel (6,000 × 4,000 <b>pixels)</b> <b>image</b> sensor {{designed}} for Leica by the Belgian company CMOSIS, and made by STMicroelectronics in Grenoble. The pixels {{are on a}} 6 x 6 µm² grid.|$|R
30|$|The total needed clock cycles to {{complete}} an eye state recognition in an 11152 <b>pixels</b> <b>image</b> is 11310 clocks, 11153 clocks to obtain projection vector, 137 clocks to obtain smoothed data; and 20 clocks to check the conditions.|$|R
3000|$|... [...]. When a Short-Exposure <b>Image</b> <b>pixel</b> value {{falls into}} a bin, a second test is done where the {{normalized}} Long-Exposure <b>Image</b> <b>pixel</b> value should fall in a range about the Short-Exposure <b>Image</b> <b>pixel</b> value. If both tests are [...]...|$|R
50|$|The three {{images were}} {{combined}} digitally and interpolated {{to the final}} size of 1.75 mega-pixels (1528 × 1146 <b>pixels).</b> <b>Images</b> were stored on an internal PCMCIA hard drive. The camera used Minolta AF A-mount lenses with a crop factor of 2.|$|R
50|$|A common-usage {{standard}} for web badges are 88x31 pixel and 80x15 <b>pixel</b> <b>images</b> typically in GIF or PNG image format {{composed of a}} small graphic to the left with text on the right. Web badges may however come in any size or configuration.|$|R
5000|$|It {{features}} a Kodak-made custom CCD sensor measuring 30×45 mm and containing 37 million pixels. [...] This sensor has a 26% longer diagonal and 56% larger area than a [...] "full-frame″ 24×36 mm DSLR sensor and outputs an approximately 5000x7500 <b>pixel</b> <b>image.</b>|$|R
40|$|Corner {{detection}} {{is used in}} many {{computer vision}} applications that require fast and efficient feature matching. In addition, hexagonal <b>pixel</b> based <b>images</b> have been recently investigated for image capture and processing due {{to their ability to}} represent curved structures that are common in real images better than traditional rectangular <b>pixel</b> based <b>images.</b> Therefore, we present an approach to corner detection on hexagonal images and demonstrate that accuracy is comparable to well-known existing corner detectors applied to rectangular <b>pixel</b> based <b>images...</b>|$|R
3000|$|... {{memories}} are configured to hold 2 [*]k datawords by default, {{which should be}} sufficient for a 1 [*]k range <b>pixel</b> <b>image.</b> This number is a compile-time parameter in the VHDL source and can be changed. The resource constraint {{is the number of}} available BlockRAMs.|$|R
40|$|Abstract—The pinned {{photodiode}} {{is the primary}} photodetector structure used in most CCD and CMOS image sensors. This paper reviews the development, physics, and technology of the {{pinned photodiode}}. Index Terms—Charge-coupled device (CCD), CMOS active <b>pixel</b> <b>image</b> sensor (CIS), photodetector, pinned photodiode (PPD), pixel. I...|$|R
40|$|The {{majority}} of the current advances in computer graphic rendering strive for fast and realistic creation of <b>pixel</b> <b>images,</b> e. g., for the film and gaming industry. This development, unfortunately, leads to various problems due to limitations of <b>pixel</b> <b>images,</b> in particular, {{when they are not}} used for screen viewing. Thus, in this paper we argue for the placement of greater emphasis on the generation of vector graphics. Vector graphics offer the best approach for achieving effectiveness for both media simulation and illustration techniques. We discuss advantages of using vector graphics, pose a number of questions in this context, and evaluate directions of further research. Categories and Subject Descriptors (according to ACM CCS) : I. 3. 0 [Computer Graphics]: General 1...|$|R
5000|$|A {{megapixel}} (MP) is {{a million}} pixels; {{the term is}} used {{not only for the}} number of <b>pixels</b> in an <b>image,</b> but also to express the number of image sensor elements of digital cameras or the number of display elements of digital displays. For example, a camera that makes a 2048×1536 <b>pixel</b> <b>image</b> (3,145,728 finished <b>image</b> <b>pixels)</b> typically uses a few extra rows and columns of sensor elements and is commonly said to have [...] "3.2 megapixels" [...] or [...] "3.4 megapixels", depending on whether the number reported is the [...] "effective" [...] or the [...] "total" [...] pixel count.|$|R
40|$|In most {{applications}} of image processing data is collected and displayed in square pixels. Hexagonal pixels offer {{the advantage of}} greater rotational symmetry in addition to close packed structure and a nearly circular pixel. We compared the image quality of <b>images</b> using square <b>pixels</b> with that of <b>images</b> employing hexagonal <b>pixels.</b> The comparison was done using various images, each considering a different aspect of geometry (i. e., lines at different angles, curves, etc.). The square <b>pixel</b> <b>images</b> were constructed using the average of a square area of smaller square <b>pixels.</b> Hexagonal <b>pixel</b> <b>images</b> were constructed using two techniques. The first one was called the “two-template approach”, wherein two different templates were {{used to create a}} close packed hexagonal image from smaller square pixels. The second approach was called the “sixneighbor approach ” which creates a rectangular template using the six neighbors of a hexagonal pixel. An Euclidean distance measure was used to compare the square pixel and hexagonal <b>pixel</b> <b>images.</b> A brief explanation of the algorithm and the results are provided in the paper. Based on our results obtained using the Euclidean distance as a quality measure, we conclude that contrary to our intuition and their widespread use in nature (retinas and ommatidia), hexagonal pixels do not offer any advantage over conventional square pixels...|$|R
