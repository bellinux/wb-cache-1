23|10000|Public
2500|$|... {{the totality}} of {{protection}} mechanisms within it, including hardware, firmware, and software, the combination of {{which is responsible for}} enforcing a <b>computer</b> <b>security</b> <b>policy.</b>|$|E
2500|$|The BellLaPadula Model (BLP) is a {{state machine}} model used for {{enforcing}} access control in government and military applications. It was developed by David Elliott Bell [...] and Leonard J. LaPadula, subsequent to strong guidance from Roger R. Schell, to formalize the U.S. Department of Defense (DoD) multilevel security (MLS) policy. The model is a formal state transition model of <b>computer</b> <b>security</b> <b>policy</b> that describes a set of access control rules which use security labels on objects and clearances for subjects. Security labels range from the most sensitive (e.g., [...] "Top Secret"), down to the least sensitive (e.g., [...] "Unclassified" [...] or [...] "Public").|$|E
5000|$|<b>Computer</b> <b>security</b> <b>policy</b> issues: {{from past}} {{toward the future}} - 1987 ...|$|E
30|$|Security incident: A {{security}} incident {{can be defined}} as a single attack or a group of attacks that can be distinguished from other attacks by the method of attack, identity of attackers, victims, sites, objectives or timing, etc. It results in the violation or imminent threat of violation of <b>computer</b> <b>security</b> <b>policies,</b> acceptable use <b>policies,</b> or standard <b>security</b> practices.|$|R
40|$|Networked {{computers}} and electronic data storage make <b>computer</b> <b>security</b> a fundamental {{component of a}} company’s survival. Security incidents can cause reputation damage, loss customers, or even liability. Companies that are {{unable or unwilling to}} hire certified security professionals often rely on non-security IT professionals for assistance. This paper provides a checklist the non-security professional can use to assist the company in the critical areas of conducting risk analysis, performing vulnerability assessments, educating employees and developing <b>computer</b> <b>security</b> <b>policies</b> and procedure...|$|R
50|$|The Site Security Handbook, RFC 2196, is a {{guide on}} setting <b>computer</b> <b>security</b> <b>policies</b> and {{procedures}} for sites that have systems on the Internet (however, the information provided should also be useful to sites not yet connected to the Internet). The guide lists issues and factors that a site must consider when setting their own policies. It makes a number of recommendations and provides discussions of relevant areas.|$|R
5000|$|... {{the totality}} of {{protection}} mechanisms within it, including hardware, firmware, and software, the combination of {{which is responsible for}} enforcing a <b>computer</b> <b>security</b> <b>policy.</b>|$|E
50|$|In 1984, {{during the}} Reagan Administration, she was {{recruited}} by the U.S. Department of State to develop computer security policies for the newly formed Office of Information Systems Security. Markey served as Director of <b>Computer</b> <b>Security</b> <b>Policy</b> and Training and worked with all bureaus to craft <b>computer</b> <b>security</b> <b>policy.</b> She created the Department’s first comprehensive computer security training program for management, security personnel and support staff globally. For her work, Markey received the State Department’s Meritorious Honor Award. Markey left the Department in 1988 at the GS-14 level.|$|E
50|$|Most of the invariants {{rely on the}} use of safer memory-managed languages, such as Sing#, {{which have}} a garbage collector, allow no {{arbitrary}} pointers, and allow code to be verified to meet a given <b>computer</b> <b>security</b> <b>policy.</b>|$|E
40|$|Emerging {{requirements}} for {{learning in the}} enterprise are developing critical reasoning and keeping the learner engaged. Advanced didactical material that exploits gameful design should increase engagement by creating a product that has the spirit, {{and not just the}} mechanics, of a good game. This article presents game design guidelines for the development of an Educational Adventure Game and how they have been applied during the development of SIRET Security Game, a game that teaches workers the importance of following <b>computer</b> <b>security</b> <b>policies...</b>|$|R
5000|$|The {{company has}} {{released}} {{a number of}} white papers on <b>computer</b> <b>security,</b> compliance, and <b>policy</b> development.|$|R
40|$|Information is an {{important}} business asset and is valuable to an organization. Thus, {{it needs to be}} protected to ensure its confidentiality, integrity and availability. The very first thing in information security is to set up policies and procedures on how to protect information. This paper presents a systematic approach in developing <b>computer</b> <b>security</b> <b>policies</b> and procedures. All the processes in the Policy Life Cycle will be discussed. In particular, it will list all the issues and factors that must be considered wh [...] ...|$|R
50|$|A {{computer}} security {{model is a}} scheme for specifying and enforcing security policies. A security model may be founded upon a formal model of access rights, a model of computation, a model of distributed computing, or no particular theoretical grounding at all. A {{computer security}} model is implemented through a <b>computer</b> <b>security</b> <b>policy.</b>|$|E
5000|$|Special {{publication}} 800-14 describes {{common security}} principles that are used. It provides {{a high level}} description of what should be incorporated within a <b>computer</b> <b>security</b> <b>policy.</b> It describes {{what can be done}} to improve existing security as well as how to develop a new security practice. Eight principles and fourteen practices are described within this document.|$|E
50|$|The Biba Model or Biba Integrity Model {{developed}} by Kenneth J. Biba in 1975, is a formal state transition system of <b>computer</b> <b>security</b> <b>policy</b> that describes {{a set of}} access control rules designed to ensure data integrity. Data and subjects are grouped into ordered levels of integrity. The model is designed so that subjects may not corrupt data in a level ranked higher than the subject, or be corrupted by data from a lower level than the subject.|$|E
40|$|One of the {{emerging}} requirements for learning in the enterprise is {{finding new ways to}} keep the learner engaged. The use of advanced learning technologies that exploit a gameful design should increase engagement and encourage students to make connections between the simulated environment and the real world. This article presents game design guidelines for the development of an Educational Adventure Game and how they have been applied during the development of SIRET Security Game, a game that teaches workers the importance of following <b>computer</b> <b>security</b> <b>policies...</b>|$|R
40|$|This memo {{provides}} {{information for the}} Internet community. It does not specify an Internet standard of any kind. Distribution of this memo is unlimited. This handbook is a guide to developing <b>computer</b> <b>security</b> <b>policies</b> and procedures for sites that have systems on the Internet. The purpose of this handbook is to provide practical guidance to administrators trying to secure their information and services. The subjects covered include policy content and formation, {{a broad range of}} technical system and network security topics, and security inciden...|$|R
5000|$|If the {{computer}} has (at time=0) any high (i.e., classified) information within it, or low users create high information subsequent to time=0 (so-called [...] "write-up," [...] which is allowed by many <b>computer</b> <b>security</b> <b>policies),</b> then the <b>computer</b> can legally leak all that high {{information to the}} low user, and can still be said {{to comply with the}} non-interference policy. The low user {{will not be able to}} learn anything about high user activities, but can learn about any high information that was created through means other than the actions of high users.(von Oheimb 2004) ...|$|R
50|$|A <b>computer</b> <b>security</b> <b>policy</b> {{defines the}} goals and {{elements}} of an organization's computer systems. The definition can be highly formal or informal. Security policies are enforced by organizational policies or security mechanisms. A technical implementation defines whether a computer system is secure or insecure. These formal policy models can be categorized into the core security principles of: Confidentiality, Integrity and Availability. For example, the Bell-La Padula model is a confidentiality policy model, whereas Biba model is an integrity policy model.|$|E
5000|$|In {{computer}} security, {{a covert}} channel {{is a type}} of computer security attack that creates a capability to transfer information objects between processes that are not supposed to be allowed to communicate by the <b>computer</b> <b>security</b> <b>policy.</b> The term, originated in 1973 by Lampson is defined as channels [...] "not intended for information transfer at all, such as the service program's effect on system load" [...] to distinguish it from Legitimate channels that are subjected to access controls by COMPUSEC. Although covert channel is mainly attributed to the computer networks, covert communication is a more general word that is used in both wired networks and wireless communications.|$|E
5000|$|The Bell - LaPadula Model (BLP) is a {{state machine}} model used for {{enforcing}} access control in government and military applications. It was developed by David Elliott Bell [...] and Leonard J. LaPadula, subsequent to strong guidance from Roger R. Schell, to formalize the U.S. Department of Defense (DoD) multilevel security (MLS) policy. The model is a formal state transition model of <b>computer</b> <b>security</b> <b>policy</b> that describes a set of access control rules which use security labels on objects and clearances for subjects. Security labels range from the most sensitive (e.g., [...] "Top Secret"), down to the least sensitive (e.g., [...] "Unclassified" [...] or [...] "Public").|$|E
40|$|Abstract: To {{enable the}} growth of {{wireless}} networks in high assurance computer systems, {{it is essential to}} establish a security engineering methodology that provides system security managers with a procedural engineering process to develop <b>computer</b> <b>security</b> <b>policies.</b> Our research demonstrates how wireless communication technology is deployed using the Multiple Independent Levels of Security (MILS) architecture for high assurance computer system design of security and safety-critical multi-enclave systems to provide a framework for supporting the enforcement of diverse security multi-policies. The established wireless inter-enclave multi-policy paradigm manages multiple wireless <b>security</b> <b>policies</b> within heterogeneous systems. Applying the policy refinement rules presented in this work for a security enforcement procedure of an application system will reduce the proof effort for secure components...|$|R
40|$|The {{notion of}} Computer Policy is {{fundamental}} {{to the study of}} <b>computer</b> <b>security</b> models, the analysis of computer vulnerabilities, the development of intrusion detection tools, and the development of misuse detection tools. Security only makes sense in relation to <b>security</b> <b>policies</b> that specify what is being protected, how it must be protected, who has access to what is being protected, etc. Policies are, however, difficult to write, normally ambiguous, and difficult to understand. Existing policy specification models are not suitable for most commercial off the shelf (COTS) systems. The source code for the system may not be available, they operate under constantly changing environments, and the policy requirements may change frequently. Also existing policy models do not capture the temporal characteristics of many real-world <b>computer</b> <b>security</b> <b>policies.</b> In this paper we present a functional approach to the specification of policies that allows their stepwise refinement, such that at hi [...] ...|$|R
40|$|<b>Computer</b> <b>security</b> {{auditing}} {{constitutes an}} important part of any organization's security procedures. Because of the many inadequacies of currently used manual methods, thorough and timely auditing is often difficult to attain. Recent literature suggests that expert systems techniques can offer significant benefits when applied to security procedures such as risk analysis, security auditing and intrusion detection. This paper presents an example of a novel expert systems application, an Expert System for Security Auditing (AudES). Issues in development and use of the expert system that are unique to the application domain are discussed. 1 Introduction The importance of effective <b>computer</b> <b>security</b> measures has become increasingly evident with the advent of recently publicized intrusion attempts and virus attacks. Any organization implementing <b>computer</b> <b>security</b> <b>policies</b> is faced {{with a wide range of}} potential threats. While some types of threats can be effectively countered using real-tim [...] ...|$|R
40|$|Intrusion Detection System is an {{integral}} component of the computer security infrastructure. It is usually {{put in place to}} detect <b>computer</b> <b>security</b> <b>policy</b> violations. While its role is important, its effectiveness is not easily measurable. This paper proposes a framework for assessing how well a rule-based Intrusion Detection System is performing its intended task. 1...|$|E
40|$|With {{respect to}} confidentiality, a <b>computer</b> <b>security</b> <b>policy</b> defines what {{information}} {{stored in a}} computer users have the permission to know. We propose to express these policies with an epistemic and deontic logic. In this context, confidentiality is de ned by the formula KA ' ! RA ' that could be read "if A knows ' then A should have the permission to know '". We provide a new possible-worlds semantics for the RA operator {{that depends on the}} security policy to be modeled. Finally, we express within our framework three examples of security policies...|$|E
40|$|Recent {{academic}} {{investigations of}} <b>computer</b> <b>security</b> <b>policy</b> violations have largely focused on non-malicious noncompliance due to poor training, low employee motivation, weak affective commitment, or individual oversight. Established theoretical foundations applied to this domain have related to protection motivation, deterrence, planned behavior, self-efficacy, individual adoption factors, organizational commitment, and other individual cognitive factors. But another class of violation demands greater research emphasis: the intentional commission of <b>computer</b> <b>security</b> <b>policy</b> violation, or insider computer abuse. Whether motivated by greed, disgruntlement, or other psychological processes, this act {{has the greatest}} potential for loss and damage to the employer. We argue the focus must include not only the act and its immediate antecedents of intention (to commit computer abuse) and deterrence (of the crime), but also phenomena which temporally precede these areas. Specifically, we assert the {{need to consider the}} thought processes of the potential offender and how these are influenced by the organizational context, prior to deterrence. We believe the interplay between thought processes and this context may significantly impact the efficacy of IS security controls, specifically deterrence safeguards. Through this focus, we extend the Straub and Welke (1998) security action cycle framework and propose three areas worthy of empirical investigation—techniques of neutralization (rationalization), expressive/instrumental criminal motivations, and disgruntlement as a result of perceptions of organizational injustice—and propose questions for future research in these areas...|$|E
40|$|The Internet {{is growing}} explosively, {{as is the}} number of crimes {{committed}} against or using computers. As a response to the growth of computer crime, the field of Computer and Network Forensics emerged. Computer forensics is the art of discovering and retrieving information about a crime in such a way to make it admissible in court. It is after-the-fact in that the only preventative capability of computer forensics is as a crime deterrent. In this paper, we propose enterprise network and computer related policies that will deter computer crime and enhance recovery from attacks by facilitating computer and network forensics. Index Terms-computer forensics, <b>computer</b> <b>security,</b> <b>policies.</b> I...|$|R
40|$|The authors {{surveyed}} technology {{directors in}} 7 {{local school districts}} to understand the impact of <b>computer</b> <b>security</b> <b>policies</b> on the integration of computer technologies into classroom learning environments. The data suggest that well-intentioned policies and practice may be adversely affecting the ways teachers and students use instructional technologies in local schools. Fear of exposing schools to the ills of the connected age is prompting decision-makers to react, first, {{to the possibility of}} threats. Districts must consider carefully the implications of restricted technology practices related to the development of knowledge and skills needed by students in the 21 st century. Teacher preparation programs must also examine program expectations with respect to district policies and practices for technology integration...|$|R
40|$|This KSC {{database}} {{is being}} {{made available to the}} scientific research community to facilitate the development of crop development models, to test monitoring and control strategies, and to identify environmental limitations in crop production systems. The KSC validated dataset consists of 17 parameters necessary to maintain bioregenerative life support functions: water purification, CO 2 removal, O 2 production, and biomass production. The data are available on disk as either a DATABASE SUBSET (one week of 5 -minute data) or DATABASE SUMMARY (daily averages of parameters). Online access to the VALIDATED DATABASE will be made available to institutions with specific programmatic requirements. Availability and access to the KSC validated database are subject to approval and limitations implicit in KSC <b>computer</b> <b>security</b> <b>policies...</b>|$|R
40|$|In {{order to}} provide for secure {{authentication}} to UMBC systems, and {{to comply with the}} University System of Maryland's <b>computer</b> <b>security</b> <b>policy,</b> UMBC is implementing the following password construction, aging, locking, and resetting procedures for all users of it's enterprise authentication system. UMBC has chosen a password policy based on the practices set in NIST publication 800 - 63. This publication puts forth a science-based approach for password construction and aging rules allowing an institution to build a policy that best fits it's business needs, and sets standards for credential revocation, change, and maintenance. Aligning our policies with this standard will allow UMBC to fully participate in various federated authentication & authorization communities, such as InCommon and the federal government's E...|$|E
40|$|Managing {{something}} that is not measured is difficult to near impossible and information security is not an exception. In the recent years, this has become increasingly apparent. Noticeable {{progress has been made in}} advancing the areas of information security measurement and reporting. However, a number of challenges and gaps still remain, and the existing paradigms meant to address them are not without limitations. In this paper, we suggestsa socio-technical model that was previously used to model USA's national <b>computer</b> <b>security</b> <b>policy</b> as a model that can be applied to the information security metrics area. The model can provide a unifying, holistic view on the area, illustrating interrelationships and gaps between various efforts at different abstraction levels. The proposed model can be mapped to some of the existing paradigms and, possibly, help address some of their individual limitations by offering a more unified perspectiv...|$|E
40|$|This report {{provides}} an overview of Canadian legislation, regulations and policies concerning Information Privacy. Aspects raised by upcoming technological changes and regulations concerning these are examined. The issues related to government agencies, as well as the private sector are given special emphasis. Some of the `Information Superhighway' issues and considerations in the global North American context are also discussed. 1991 AMS Classification: 94 - 02 Key Words and Phrases: Information Privacy, Privacy Legislation, Communication Legislation, <b>Computer</b> <b>Security</b> <b>Policy,</b> Information Superhighway. Information and Systems Science program, Carleton University, School of Computer Science, Ottawa, ON, Canada K 1 S 5 B 6 y Faculty of Information Science, Masaryk University, Buresova 20, 659 59 Brno, Czech Republic "As new technology has brought us the information age, it has underscored the fact that knowledge is often synonymous with power. Information itself has become a commodity [...] ...|$|E
40|$|The {{existence}} of Trojan horses, viruses, and other malicious software has motivated the <b>computer</b> <b>security</b> industry to invent mechanisms that protect against malicious software. One such mechanism {{is called the}} Trusted Path. The Trusted Path provides {{a way for the}} system to authenticate itself to the user. Once invoked, the Trusted Path provides an environment in which the user can perform trusted operations such as login, logout, and change password. This thesis provides a high level design for a Trusted Path and an in depth analysis of how a Trusted Path can be implemented in the Linux operating system. Research of process family creation and keyboard handling has led to the implementation of a Secure Attention Key {{that can be used to}} invoke a Trusted Path in Linux. This research is meant to be used in combination with other efforts to enhance the Linux operating system as an inexpensive platform for instruction on <b>computer</b> <b>security</b> <b>policies.</b> NANAU. S. Navy (U. S. N.) author...|$|R
40|$|The paper {{presents}} {{an extension of}} temporal epistemic logic with operators that quantify over agent strategies. Unlike previous work on alternating temporal epistemic logic, the semantics works with systems whose states explicitly encode the strategy being used by each of the agents. This provides a natural way to ex-press what agents would know were they {{to be aware of}} the strategies being used by other agents. A number of examples that rely upon the ability to express an agent’s knowledge about the strategies being used by other agents are presented to motivate the framework, including reasoning about game theoretic equilibria, knowledge-based programs, and information theoretic <b>computer</b> <b>security</b> <b>policies.</b> Relationships to several variants of alternating temporal epistemic logic are dis-cussed. The computational complexity of model checking the logic and several of its fragments are also characterized. ...|$|R
40|$|<b>Computer</b> <b>security</b> <b>policies</b> {{often are}} stated informally {{in terms of}} conﬁdentiality, integrity, and {{availability}} of information and resources; these policies can be qualitative or quantitative. To formally quantify conﬁdentiality and integrity, {{a new model of}} quantitative information ﬂow is proposed in which information ﬂow is quantiﬁed as the change in the accuracy of an observer’s beliefs. This new model resolves anomalies present in previous quantitative informationﬂow models, which are based on change in uncertainty. And the new model is sufﬁciently general that it can be instantiated to measure either accuracy or uncertainty. To formalize <b>security</b> <b>policies</b> in general, a generalization of the theory of trace properties (originally developed for program veriﬁcation) is proposed. <b>Security</b> <b>policies</b> are modeled as hyperproperties, which are sets of trace properties. Although important <b>security</b> <b>policies,</b> such as secure information ﬂow, cannot be expressed as trace properties, they can be expressed as hyperproperties. Safety and liveness are generalized from trace properties to hyperproperties, and every hyperproperty is shown to be the intersection of a safety hyperproperty and a liveness hyperproperty. Veriﬁcation, reﬁnement, and topology of hyperproperties are also addressed. Hyperproperties for system representations beyond trace sets are investigated...|$|R
