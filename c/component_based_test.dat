2|10000|Public
40|$|Abstract Test {{techniques}} for analog circuits characterize the input-output relationship based on coefficients of transfer function, polynomial expansion, wavelet transform, V-transform or Volterra series. However, these coefficients always suffer from errors due to measurement accuracy and noise. This paper presents closed form expressions for an {{upper bound on}} the defect level and a lower bound on fault coverage achievable in such analog circuit test methods. The computed bounds have been validated on several benchmark circuits. Further, application of these bounds to scalable RC ladder networks reveal a number of interesting characteristics. The approach adopted here is general and can be extended to find bounds on defect level and fault coverage in other <b>component</b> <b>based</b> <b>test</b> methods for linear circuits...|$|E
40|$|This is {{a conference}} paper. Increased machine {{performance}} through reduction of drivetrain power losses {{is an important}} goal in powertrain engineering. One key area of power loss in the driven axles of heavy on-road vehicles and off-highway vehicles is the disengaged wet brake conjunctions. The resultant power loss, particularly under cold start conditions, can be quite significant. The addition of patterned grooves into the brake friction linings assists lubricant flow to dissipate heat during contact, which complicates the prediction of performance, making design improvement a multi-variate problem. A Reynolds-based numerical model with the inclusion of lubricant inertial terms is developed, allowing time efficient prediction of the conjunctional torsional viscous losses. The numerical model is validated with CFD as well as experimental measurements, using a developed <b>component</b> <b>based</b> <b>test</b> rig. Good agreement is found for predictions against measurements for lower viscosity lubricant flow at higher bulk oil temperatures. The results show deviations at lower temperatures promoting higher viscosity inlet starvation, which is not taken into account with the assumed fully flooded inlet...|$|E
40|$|Abstract. <b>Component</b> <b>based</b> <b>testing</b> {{concerns}} {{the integration of}} components which have already been tested separately. We show that, with certain restrictions, the ioco-test theory for conformance testing is suitable for <b>component</b> <b>based</b> <b>testing,</b> {{in the sense that}} the integration of fully conformant components is guaranteed to be correct. As a consequence, there is no need to re-test the integrated system for conformance. This result is also relevant for testing in context, since it implies that every failure of a system embedded in a test context can be reduced to a fault of the system itself...|$|R
40|$|Compositional testing {{concerns}} {{the testing of}} systems that consist of communicating components which can also be tested in isolation. Examples are <b>component</b> <b>based</b> <b>testing</b> and interoperability testing. We show that, with certain restrictions, the ioco-test theory for conformance testing is suitable for compositional testing, {{in the sense that}} the integration of fully conformant components is guaranteed to be correct. As a consequence, there is no need to re-test the integrated system for conformance. This resul...|$|R
40|$|Abstract. Compositional testing {{concerns}} {{the testing of}} systems that consist of communicating components which can also be tested in isolation. Examples are <b>component</b> <b>based</b> <b>testing</b> and interoperability testing. We show that, with certain restrictions, the ioco-test theory for conformance testing is suitable for compositional testing, {{in the sense that}} the integration of fully conformant components is guaranteed to be correct. As a consequence, there is no need to re-test the integrated system for conformance. This result is also relevant for testing in context, since it implies that every failure of a system embedded in a test context can be reduced to a fault of the system itself. ...|$|R
40|$|Abstract. UniTESK is a <b>testing</b> {{technology}} <b>based</b> on formal models or formal specifications of {{requirements to}} the behavior of software and hardware components. The most significant applications of UniTESK in industrial projects are described, the experience is summarized, and the prospective directions to the <b>Component</b> Model <b>Based</b> <b>Testing</b> development are estimated...|$|R
40|$|The Solar Rating and Certification Corporation (SRCC) has {{recently}} implemented a novei simulation-based process for generating solar {{domestic hot water}} thermal performance ratings using TRNSYS 13. 1. Experience has revealed several implementation issues that have lead to increased emphasis on system testing. First, many of the certified systems have incorporated components and processes that have proven difficult to model, {{particularly with regard to}} heat exchangers, tanks, and natural convection loops. Consequently, the ability to rate all systems with literal modeling to a uniform uncertainty has been difficult to achieve. Second, the use of simulation models developed without rigid validation is not defensible, and can lead to decreased credibility. This paper summarizes these issues, and elaborates on the continuing research to produce validated models from either <b>component</b> <b>based</b> <b>tests</b> or whole system tests. 1...|$|R
40|$|The {{widespread}} {{usefulness of}} Graphical User Interfaces has made GUIs {{the most important}} component of software today. As the GUI have characteristics like event driven input, mouse clicks etc., and the testing of conventional software cannot be applied on the GUI’s. One {{of the most important}} innovations that strongly contribute to solve this issue has been the introduction of the Extensible Markup Language (XML). The XML Schema <b>based</b> <b>testing</b> is introduced to combine the great potential of XML Schema in describing input data in open and standard form, with testing activity. We have theoretically analyzed different <b>components</b> <b>based</b> <b>testing</b> techniques especially XML <b>based</b> <b>testing</b> and regression testing. We have written the representation or specification of GUI in XML which is validated by XML Schema. Program have been written reads the XML and to generate the test sequences. We have developed XML Regression Test Suite Modeler to perform testing of GUI component. It includes Test Case Generator, GUI Comparer and Regression Test Suite Generator as the main components. A case study applying the proposed approach is described and results are presented...|$|R
40|$|In {{order not}} only to meet the current targets in terms of safety, but {{also in terms of}} {{lightweight}} that means lower polluting gas emissions and fuel consumption, for a newly developed vehicle it is necessary to perform a number of <b>component</b> <b>based</b> <b>tests.</b> This kind of experimental tests is time consuming and very expensive. Therefore, it is recommended to develop cost effective design methodology and analysis using existing finite element methods in order to evaluate the performance of different design solutions under various loading, material and environmental conditions, since from the earliest stages of the design activity. This paper intends to address such design aspects and method of analysis with particular reference to the application of composite and recyclable thermoplastic materials to automotive front bumper design. Major constraints that have been dealt with are bumper crash resistance, absorbed energy and stiffness with particular reference to the existing bumper standards. Finally, the results predicted by the finite element analysis are evaluated and interpreted to insight the effectiveness of the proposed solutio...|$|R
30|$|Third, {{we compare}} dynamic {{specification}} tests for the underlying <b>components</b> with <b>tests</b> <b>based</b> on the reduced form prediction errors. In this regard, we study their relative power and discuss some {{cases in which}} they are numerical equivalent.|$|R
40|$|A {{model for}} {{software}} <b>component</b> certification <b>based</b> on <b>test</b> certificates supplied by developers {{in a standard}} portable form is proposed. Purchasers are expected to use the model to determine the quality and suitability of purchased software. The model involves the designing of standard test specifications that are devoid of language specific features. The tests described by the test specifications are run by Java programming. The advantages of the approach over the certification laboratory approach includes reduced costs, added value, augmented functional requirements and guaranteed trust...|$|R
40|$|This report {{documents}} the {{research into the}} application of hierarchical Bayesian methods for characterizing the population failure rate (i. e. probability of defect) of an electronic <b>component</b> <b>based</b> on <b>test</b> data {{from a number of}} different test modalities. Classical statistical methods, those based on a frequency approach permit the combination of point estimates but stumble when characterizing the resulting confidence limits. Classical Bayesian methods permit the logical combination of test data, but are not fully efficient in incorporating all available information. In particular, classical Bayesian methods assume that the articles under test are not related in any manner even though the articles may be identical. Alternatively, hierarchical Bayesian methods permit the relationship between test articles to be explicitly included in the analysis. Data from four different test modalities are considered in the analysis. Comparisons are made between the current analysis approach (using traditional statistical methods), classical Bayesian methods and a hierarchical Bayesian approach...|$|R
40|$|Several {{methods have}} been {{utilized}} to study the response of concrete structural <b>components.</b> Experimental <b>based</b> <b>testing</b> has been widely used {{as a means to}} analyze individual elements and the effects of concrete strength under loading. The use of finite element analysis to study these components has also been used. This thesis is a study of reinforced and prestressed concrete beams using finite element analysis to understand their load-deflection response. A reinforced concrete beam model is studied and compared to experimental data. The parameters for the reinforced concrete model were then used to model a prestressed concrete beam. Characteristic points on the load-deformation response curve predicted using finite element analysis were compared to theoretical (hand-calculated) results. Conclusions were then made as to the accuracy of using finite element modeling for analysis of concrete. The results compared well to experimental and hand calculated. ACKNOWLEDGMENTS This research was performed under the supervision of Dr. Christopher M. Foley. I a...|$|R
40|$|ABSTRACT New {{reliability}} {{models are}} used in order to estimates {{the reliability of the}} software depends upon the com-ponent structure of code. The analyses of these models emphasize the dependence of <b>component</b> failures, com-ponent <b>based</b> <b>testing</b> and <b>component</b> <b>based</b> implementation. These models can provide quality based assurance of the components reuse in the system and also the component of the system are provide feasibility of software reliability of this type are important for two main reasons. Traditionally, the complexity of a computation is measured {{in terms of the number}} of elemental computations used. In contrast, a statistical complexity measure is proposed to describe complexity in terms of statistical software testability. A highly complex program requires intense testing in order to justify a claim that the program achieves a given level of reliability. A low complexity program requires less testing to achieve the same claim. In this Research paper I tend to emphasize the analysis of the software reliability on the basis of the components of the system. Software Reliability Analysis- A Ne...|$|R
40|$|This paper {{presents}} {{a method of}} <b>component</b> <b>testing</b> <b>based</b> on algebraic specifications. An algorithm for generating checkable test cases is proposed. A proto-type testing tool called CASCAT for testing Java En-terprise Beans is developed. It has the advantages of high degree of automation, which include test case generation, test harness construction and test result checking. It achieves scalability by allowing incre-mental integration. It also allows testing {{to focus on a}} subset of used functions and key properties, thus suit-able for component testing. The paper also reports an experimental evaluation of the method and the tool. 1...|$|R
40|$|International audienceThis review issue {{gives an}} {{accurate}} {{insight into the}} research work being {{carried out by the}} principal research and industrial establishments in our country, without claiming to offer a list of active researchers which is entirely complete. We believe the work herein will show a French research community which is active over a wide range of activities. The work presented covers fabrication of specialty fibres, fibre <b>based</b> <b>components,</b> <b>test</b> and characterisation and some more industrial aspects involving equipment providers. This Special Issue of Fiber an Integrated Optics, was appearing in three separate issues in 2008 and 2009...|$|R
40|$|Instead of de-correlating image {{luminance}} from chrominance, {{some use}} {{has been made}} of using the correlation between the luminance component of an image and its chromatic components, or the correlation between colour components, for colour image compression. In one approach, the Green colour channel was taken as a base, and the other colour channels or their DCT subbands were approximated as polynomial functions of the base inside image windows. This paper points out that we can do better if we introduce an addressing scheme into the image description such that similar colours are grouped together spatially. With a Luminance <b>component</b> <b>base,</b> we <b>test</b> several colour spaces and rearrangement schemes, including segmentation, and settle on a log-geometric-mean colour space. Along with PSNR versus bits-per-pixel, we found that spatially-keyed s-CIELAB colour error better identifies problem regions. Instead of segmentation, we found that rearranging on sorted chromatic components has almost equal performance and better compression. Here, we sort on each of the chromatic components and separately encode windows of each. The result consists of the original greyscale plane plus the polynomial coefficients of windows of rearranged chromatic values, which are then quantized. The simplicity of the method produces a fast and simple scheme for colour image and video compression, with excellent results. Keywords: Image Compression, Colour, Grey-to-colour 1...|$|R
40|$|The {{presence}} of production-related defects in cast aluminium alloy components leads to reduction in their fatigue strength. The optimal {{use of their}} high strength-to-weight benefits is thereby restricted. There is currently only qualitative approach relating the defects characteristics to fatigue analysis. This work presents a method to quantitatively evaluate the fatigue life of defect-prone cast aluminium alloys. The investigation is carried-out by non-destructive analysis of cast aluminium alloy samples using X-Ray computed tomography. The microstructure discontinuities are characterized and quantified in terms of defect size, morphology and distance to specimen surface. These are subsequently used as input in a new parameter model for fatigue life calculation. The results correlate with fatigue experiments and finite-element calculations. This approach provides the possibility to extensively evaluate the fatigue properties of cast aluminium alloy <b>components</b> <b>based</b> on non-destructive <b>test</b> methods. It guarantees an improvement of control mechanisms {{within the scope of}} quality assurance...|$|R
40|$|Abstract [...] Several {{methods have}} been {{utilized}} to study the response of concrete structural <b>components.</b> Experimental <b>based</b> <b>testing</b> has been widely used {{as a means to}} analyze individual elements and the effects of concrete strength under loading. The use of finite element analysis to study these components has also been used. This paper focuses on the behavior of reinforced concrete beam for different pattern of shear reinforcement to evaluate the effective shear reinforcement pattern and also compare the variation in behavior of reinforced concrete beam for with and without shear reinforcement with a simulation. To carry out the analysis, six 3 D beams without and with different patterns of shear reinforcement is built using comprehensive computer software ANSYS 10 © 2005 SAS IP, Inc package. The static non linear analysis is done to find out ultimate capacity, formation of first crack and its distance from support, initiation of diagonal crack and its distance from support. Load deflection response was also closely observed and compared with the result from theoretical calculation. From close observation of analyses results it was found that all types of web reinforcements were almost same effective for static loading condition. Index Term [...] ANSYS, shear reinforcement, finite element analysis, diagonal crack. I...|$|R
40|$|This {{thesis is}} {{concerned}} with change point analysis for time series, i. e. with detection of structural breaks in time-ordered, random data. This long-standing research field regained popularity {{over the last few}} years and is still undergoing, as statistical analysis in general, a transformation to high-dimensional problems. We focus on the fundamental »change in the mean« problem and provide extensions of the classical non-parametric Darling-Erdős-type cumulative sum (CUSUM) testing and estimation theory within highdimensional Hilbert space settings. In the first part we contribute to (long run) principal <b>component</b> <b>based</b> <b>testing</b> methods for Hilbert space valued time series under a rather broad (abrupt, epidemic, gradual, multiple) change setting and under dependence. For the dependence structure we consider either traditional m-dependence assumptions or more recently developed m-approximability conditions which cover, e. g., MA, AR and ARCH models. We derive Gumbel and Brownian bridge type approximations of the distribution of the test statistic under the null hypothesis of no change and consistency conditions under the alternative. A new formulation of the test statistic using projections on subspaces allows us to simplify the standard proof techniques and to weaken common assumptions on the covariance structure. Furthermore, we propose to adjust the principal components by an implicit estimation of a (possible) change direction. This approach adds flexibility to projection based methods, weakens typical technical conditions and provides better consistency properties under the alternative. In the second part we contribute to estimation methods for common changes in the means of panels of Hilbert space valued time series. We analyze weighted CUSUM estimates within a recently proposed »high-dimensional low sample size (HDLSS) « framework, where the sample size is fixed but the number of panels increases. We derive sharp conditions on »pointwise asymptotic accuracy« or »uniform asymptotic accuracy« of those estimates in terms of the weighting function. Particularly, we prove that a covariance-based correction of Darling-Erdős-type CUSUM estimates is required to guarantee uniform asymptotic accuracy under moderate dependence conditions within panels and that these conditions are fulfilled, e. g., by any MA(1) time series. As a counterexample we show that for AR(1) time series, close to the non-stationary case, the dependence is too strong and uniform asymptotic accuracy cannot be ensured. Finally, we conduct simulations to demonstrate that our results are practically applicable and that our methodological suggestions are advantageous...|$|R
40|$|This {{research}} {{focuses on}} the development of a child restraint system installation-aid device (CRSIAD) for the purpose of mitigating child safety seat misuse in terms of installation. A geometric study was performed base on surveying dimensions of currently existing child safety seat products. Material property experiments were conducted to develop an anisotropic wood material model for the CRSIAD in order to virtually evaluate device stress levels. Finite element analysis (FEA) of both the material model and CRSIAD were performed in comparison with lab test data to validate structural performance. The CRSIAD was then fabricated and finalized after multiple design iterations for geometry and <b>components</b> <b>based</b> on in-car <b>testing.</b> User satisfaction survey and professional review by certified CRS installation personnel were completed to ensure the value of CRSIAD as well as provide feedback for future improvements. From the testing results and user feedbacks, the CRSIAD was believed to be an important contribution towards the improvement of child safety in vehicles...|$|R
40|$|Abstract — This Software {{testing is}} “Performing Verification and Validation of the Software Product ” for its {{correctness}} {{and accuracy of}} working. Every time {{it is not possible}} to perform each and every test case. Hence it is important to decide test cases prioritization. The aim of Test case prioritization is to prioritize the test case sequences and finding the faults as early as possible to improve proficiency of testing. Here we define a new prioritization method which prioritizes test cases in descending order for <b>Component</b> <b>Based</b> Software Development (CBSD) using the concept of Prim’s algorithm. Our main aim is to implement and observe the model <b>based</b> <b>test</b> case prioritization algorithm which make use of CIG (Component interaction Graph) as input for a medium / large size CBSD (<b>Component</b> <b>Based</b> Software Development Process) by taking any real-time system as an example and to generate prioritized test cases in descending order...|$|R
40|$|Fatigue {{failure is}} one of the main failure modes for wind turbine {{drivetrain}} components made of cast iron. The wind turbine drivetrain consists of a variety of heavily loaded components, like the main shaft, the main bearings, the gearbox and the generator. The failure of each component will lead to substantial economic losses such as cost of lost energy production and cost of repairs. During the design lifetime, the drivetrain components are exposed to variable loads from winds and waves and other sources of loads that are uncertain and have to be modeled as stochastic variables. The types of loads are different for offshore and onshore wind turbines. Moreover, uncertainties about the fatigue strength play an important role in modeling and assessment of the reliability of the components. In this paper, a generic stochastic model for fatigue failure of cast iron <b>components</b> <b>based</b> on fatigue <b>test</b> data and a limit state equation for fatigue failure based on the SN-curve approach and Miner’s rule is presented. The statistical analysis of the fatigue data is performed using the Maximum Likelihood Method which also gives an estimate of the statistical uncertainties. Finally, illustrative examples are presented with reliability analyses depending on various stochastic models and partial safety factors...|$|R
40|$|In {{this paper}} {{comprehensive}} investigations of laser induced deposit formation are reported. In a high vacuum chamber (p < 10 - 6 mbar) different space relevant materials containing epoxy, silicone and polyurethane <b>based</b> <b>components</b> were <b>tested</b> under space conditions. The experiments were performed with a pulsed Nd:YAG laser with peak fluences up to 2. 5 J/cm² at 355 nm wavelength and 3 ns pulse width. Additional tests were performed with an UV cw laser diode at 375 nm and 10 mW mean power. The onset {{and growth of}} the deposits was monitored in-situ and online by UV induced fluorescence imaging. The influence of roughness, temperature and chemical composition of the optical surface on the deposition process was investigated. Time-of-flight secondary ion mass spectroscopy (ToF-SIMS) was used for chemical characterization of the deposits. Furthermore the influence of deposits on the UV-transmission of the optics was estimated...|$|R
50|$|<b>Component</b> <b>based</b> {{development}} environments include: Peltarion Synapse, NeuroDimension NeuroSolutions, Scientific Software Neuro Laboratory, and the LIONsolver integrated software. Free {{open source}} <b>component</b> <b>based</b> environments include Encog and Neuroph.|$|R
40|$|<b>Component</b> <b>Based</b> Approach {{has been}} {{introduced}} in core engineering discipline long back but the introduction to <b>component</b> <b>based</b> concept in software perspective is recently developed by Object Management Group. Its benefits from the re-usability {{point of view is}} enormous. The intertwining relationship of domain engineering with <b>component</b> <b>based</b> software engineering is analyzed. The object oriented approach and its basic difference with component approach is of great concern. The present study highlights the life-cycle, cost effectiveness and the basic study of <b>component</b> <b>based</b> software from application perspective. Comment: 25 pages, 3 figure...|$|R
40|$|<b>Component</b> <b>based</b> {{technology}} {{is widely used}} for both academicians and business. There are numbers of benefits for using this type of technology. First, it helps {{to increase the efficiency}} and maintainability of software. Second, it im proves quality and helps to enhance productivity. Third, the reuse approach that supports <b>component</b> <b>based</b> technology decreases the time to market. <b>Component</b> <b>based</b> e-commerce can be used to solve e-commerce difficulties at application level as well as at system level. This paper introduces how <b>component</b> <b>based</b> activities have effect mainly on building the framework of the e-commerce. It also discusses how the architectural design of the application can be synthesized. </p...|$|R
5000|$|... #Caption: Construction of {{two-dimensional}} Log Gabor filter. The {{two dimensional}} filter {{consists of a}} <b>component</b> <b>based</b> on frequency (a) and a <b>component</b> <b>based</b> on orientation (b). The two components are combined to form the final component (c).|$|R
40|$|<b>Component</b> <b>Based</b> Software Development (CBSD) aims {{to lower}} {{software}} development costs by providing sophisticated facilities for software reuse. The Sun Microsystem's Enterprise Java Beans (EJB) [4] {{is one of}} the currently used <b>component</b> <b>based</b> platforms for development of distributed, object-oriented applications...|$|R
40|$|<b>Component</b> <b>Based</b> Software Engineering (CBSE) is anenvironment {{which uses}} {{software}} components as main building block during designing {{and creation of}} a software system. A Component is a software entity with independent identity which has a perceptible reusable interface. This property motivates the programmer to design and develop Softwareusing <b>Component</b> <b>Based</b> Software Development (CBSD) and further Software Metrics for these systems. In this paper, new early stage <b>component</b> <b>based</b> software metrics are designed for CBSD namely Component Composition Metrics (CCM) & Component Ratio Metrics (CRM) to determine the Effort using Likert 3 -point rating in terms of time, cost, quality, operability, changeability, adaptability etc. for a software system. CCM and CRM are designed and analyzed using knot model of <b>component</b> <b>based</b> software life cycle...|$|R
5000|$|... #Caption: Peltarion Synapse <b>component</b> <b>based</b> {{development}} environment.|$|R
40|$|We {{propose a}} novel {{technique}} {{to boost the}} power of testing a high-dimensional vector H: θ = 0 against sparse alternatives where the null hypothesis is violated only {{by a couple of}} <b>components.</b> Existing <b>tests</b> <b>based</b> on quadratic forms such as the Wald statistic often suffer from low powers due to the accumulation of errors in esti-mating high-dimensional parameters. More powerful tests for sparse alternatives such as thresholding and extreme-value tests, on the other hand, require either stringent conditions or bootstrap to derive the null distribution and often suffer from size dis-tortions due to the slow convergence. Based on a screening technique, we introduce a “power enhancement component”, which is zero under the null hypothesis with high probability, but diverges quickly under sparse alternatives. The proposed test statistic combines the power enhancement component with an asymptotically pivotal statistic, and strengthens the power under sparse alternatives. The null distribution does not require stringent regularity conditions, and is completely determined by that of the ∗The authors are grateful to the comments from seminar and conference participants at UChicago, Prince...|$|R
40|$|<b>Component</b> <b>Based</b> Software Engineering {{is based}} on {{reusability}} of code. It is an approach which let customer to have quality product by paying less amount of money and spending less time to produce. In this paper {{we will find out}} the factors which greatly effects reliability of <b>component</b> <b>based</b> system by conducting literature survey. The focus {{of this paper is to}} provide an overview of estimation of reliability factors from literature survey. We will prioritized reliability factors by applying soft computing techniques which in turn result factor which greatly effects reliability of <b>component</b> <b>based</b> system...|$|R
5000|$|... (11) Recommend reprioritization of WMD program <b>components</b> <b>based</b> on ...|$|R
40|$|In process algebras like µCRL [6] and ACP [2] {{communication}} is defined globally. In {{the context of}} <b>component</b> <b>based</b> architectures one wishes to define subcomponents of a system separately, including communication within that subcomponent. In this document we define a process algebra that has a local communication function that facilitates <b>component</b> <b>based</b> architectures. ...|$|R
40|$|Over {{the last}} couple of years, the shift towards <b>component</b> <b>based</b> {{software}} engineering (CBSE) methods has become a cost effective way to get an application to implementation stage much earKer. Adoption of <b>Component</b> <b>Based</b> Development methods acknowledges the use of third party components wherever possible to reduce the cost of software development, shorten the development phase and provide a richer set of processing options for the end user. The use of these tools is particularly relevant in Web based applications, where commercial off the shelf (COTS) products are so prevalent. However, {{there are a number of}} risks associated with the use of <b>component</b> <b>based</b> development methods. This thesis investigates these risks within the context of a software engineering project and attempts to provide a means to minimise and or at least manage the risk potential when using <b>component</b> <b>based</b> development method...|$|R
