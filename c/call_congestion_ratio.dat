0|174|Public
40|$|This study {{proposes a}} new method to describe, compare, and {{classify}} the traffic congestion states in 23 Chinese cities using the online map data and further reveals the influential {{factors that may}} affect them. First, the real-time traffic congestion information is obtained from the online map of AutoNavi in a 15 -minute interval. Next, a new measuring index is introduced to describe the overall characterization of congestion patterns in each city based on online map data, which is named as the <b>congestion</b> <b>ratio.</b> The next analysis is the cluster analysis based on the temporal distribution of the <b>congestion</b> <b>ratio,</b> which helps to identify groups of the selected cities with similar traffic congestion states. These cities are categorized as four groups according to the severity of traffic congestion: severely congested, less severely congested, amble, and smooth cities. Lastly, multiple linear regression models are developed to identify the primary factors that affect the <b>congestion</b> <b>ratio.</b> The result shows that the influences of per capita road area, car ownership, and vehicle miles traveled (VMT) on the <b>congestion</b> <b>ratio</b> are significant. Sensitivity analyses are also implemented in order to reveal more effective policy measures in mitigating traffic congestion in urban areas...|$|R
50|$|When the {{congestion}} window {{exceeds the}} ssthresh threshold, the algorithm enters a new state, <b>called</b> <b>congestion</b> avoidance. In congestion avoidance state {{as long as}} non-duplicate ACKs are received, the congestion window is additively increased by one MSS every round-trip time.|$|R
40|$|Simple and {{computationally}} attractive {{lower and}} upper bounds are presented for the <b>call</b> <b>congestion</b> {{such as those}} representing multi-server loss or delay stations. Numerical computations indicate a potential usefulness of the bounds for quick engineering purposes. The bounds correspond to product-form modifications and are intuitively appealing. A formal proof of the bounds and related mono tonicity results will be presented. The technique of this proof, {{which is based on}} Markov reward theory, is of interest in itself and seems promising for further application. The extension to the non-exponential case is discussed. For multi-server loss stations the bounds are argued to be insensitive. Keywords: Tandem queues, product form, <b>call</b> <b>congestion,</b> bounds, monotonicity results, Markov chains...|$|R
40|$|This {{dissertation}} {{describes a}} strategy which makes all commuters better off (i. e. a Pareto effecient strategy) for the time-dependent morning commute problem, {{even if the}} collected revenues are not returned to the population of commuters. The proposed strategy will apply road pricing {{as a tool for}} congestion management, a practice usually <b>called</b> <b>congestion</b> pricing. ...|$|R
40|$|We {{propose a}} new multirate {{teletraffic}} loss {{model for the}} calculation of time and <b>call</b> <b>congestion</b> probabilities in CDMA-based networks that accommodate calls of different serviceclasses whose arrival follows a batched Poisson process. The latter is more "peaked" and "bursty" than the ordinary Poisson process. The acceptance of calls in the system {{is based on the}} partial batch blocking discipline. This policy accepts a part of the batch (one or more calls) and discards the rest if the available resources are not enough to accept the whole batch. The proposed model takes into account the multiple access interference, the notion of local (soft) blocking, user’s activity and the interference cancellation. Although the analysis of the model does not lead to a product form solution of the steady state probabilities, we show that the calculation of the call-level performance metrics, time and <b>call</b> <b>congestion</b> probabilities, can be based on approximate but recursive formulas. The accuracy of the proposed formulas are verified through simulation and found to be quite satisfactory...|$|R
40|$|CDMA-based {{technologies}} deserve assiduous {{analysis and}} evaluation. We study the performance, at call-level, of a CDMA cell with interference cancellation capabilities, while {{assuming that the}} cell accommodates different service-classes of batched Poisson arriving calls. The partial batch blocking discipline is applied for Call Admission Control (CAC). To guarantee certain Quality of Service (QoS) for each service-class, the Bandwidth Reservation (BR) policy is incorporated in the CAC; i. e., a fraction of system resources is reserved for high-speed service-classes. We propose a new multirate loss model for the calculation of time and <b>call</b> <b>congestion</b> probabilities. The notion of local (soft) and hard blocking, users activity, interference cancellation, {{as well as the}} BR policy, are incorporated in the model. Although the steady state probabilities of the system do not have a product form solution, time and <b>call</b> <b>congestion</b> probabilities can be efficiently determined via approximate but recursive formulas. Simulation verified the high accuracy of the new formulas. We also show the consistency of the proposed model in respect of its parameters, while comparison of the proposed model with that of Poisson input shows its necessity...|$|R
40|$|Growth of {{consumer}} of peripatetic telecommunications of cellular GSM claims {{the existence of}} optimal capacities of traffic to be including maximum customer. One of the improving capacities of traffic by Transceiver Group Synchronization that is merger two Radio Bases of Station or more become one Site. Conducted by Transceiver Group Synchronization will improve capacities of Traffic Channel (TCH) Availability, TCH Traffic, Stand Alone Dedicated Control Channel (SDCCH), degrading TCH Assignment Drop Call and of TCH <b>Congestion</b> <b>Ratio.</b> Herewith will improve Handover Success Ratio (HOSR) and of saving usage of Transceiver Unit (TRU) ...|$|R
40|$|Abstract — Optical {{networks}} with book-ahead bandwidth schedulers {{are being}} deployed {{to meet the}} high-speed and predictable-service networking requirements of applications in the scientific research community. We present an analytical model for a single-link book-ahead bandwidth scheduler, which responds to advance reservation requests with the first-available time interval in which a channel is available. The link {{is assumed to be}} divided into m channels, and time is discretized into intervals. Our proposed model is a non-homogeneous continuous-time Markov chain, which has an embedded discrete-time Markov chain. We solve the model for <b>call</b> <b>congestion,</b> mean scheduling delay, and link utilization. This model can be used by network designers to select the size of the reservation window, K, in timeinterval units, corresponding to a desired set of values for the output metrics, for a given value of m. For example, when m is 8, increasing the reservation window beyond 4 intervals does not affect the <b>call</b> <b>congestion</b> or system utilization, but causes the mean scheduling delay to increase. We show with comparative simulations that our analytical model {{can be used as a}} solution for an M/D/m/p queueing system at moderate-to-high loads. I...|$|R
40|$|Abstract — We design network topologies and routing {{strategies}} which optimize several measures simultaneously: low cost, small routing diameter, bounded {{degree and}} low congestion. This set of design issues is broader than traditional network design and hence, {{our work is}} useful and relevant {{to a set of}} traditional and emerging design problems. Surprisingly, a simple idea from the research on small-world models, inspires a fruitful approach and useful techniques here. Starting with a simple model we consider adding long links to an n×n grid graph. Ideally, for a given budget to buy additional long links, we consider mechanisms for choosing links such that the routing diameter is small enough (poly-log of n) while the <b>congestion</b> <b>ratio</b> (between the most used link and the average one) is minimized, assuming uniform traffic between any two of the n 2 nodes. We show that by adding O(1) long links to each node we achieve an almost logarithmic routing diameter and maintain a near optimal trade-off between <b>congestion</b> <b>ratio</b> and average weight (of long links) : W eight×CongestionRatio = O(n). Our results are comparable to the best similar network structures when the trade-off space we consider is reduced to those in the compared designs (with fewer trade-off factors). We also consider extensions of our results to more general settings. We propose two construction schemes: 1) a static (fixed link) design and 2) a dynamic (random link) design. While the former provides our best trade-off results, the later is more scalable, better suited for dynamic and fault-tolerance issues, and can be useful for wireless ad-hoc networks. I...|$|R
50|$|Any <b>call</b> that {{encounters}} <b>congestion</b> {{is immediately}} lost.|$|R
40|$|In this lecture we will concern {{ourselves}} with {{the existence and}} price of Nash equilibrium in several game classes. We will: • Define a class of games <b>called</b> <b>congestion</b> games and we’ll show {{the existence of a}} pure Nash Equilibirum in any congestion game. • Define a class called potential games and we’ll study the existence of pure equilibrium in those games. (Actually the two classed are equivalent) • Study two variants of a Network Creation game (unfair and fair), and study the price of anarchy (when a Nash equilibrium exists) • Define the Price of Stability (PoS) and analyze the PoS in a Network Creation gam...|$|R
5000|$|... 2) The TOS {{field has}} then been redefined as the Differentiated Services Code Point (DSCP-> RFC 2474) which {{consists}} of the first 6 bits and 2 bits used for a TCP mechanism <b>called</b> Explicit <b>Congestion</b> Notification (ECN) defined in RFC 3168.|$|R
40|$|Abstract—The {{most common}} {{technology}} in Local Area Networks is the Ethernet protocol. The continuing evolution of Ethernet has propelled {{it into the}} scope of Metropolitan Area Networks. Even though Ethernet is fast and simple, the Spanning Tree in Ethernet is inefficient in terms of network utilization and load balancing. In this work, we compare the performance of Spanning Tree and Link State algorithms {{in the context of}} layer 2 switching. In addition, we introduce a hybrid scheme that is customized for Metro Ethernet Networks. The results show that the hybrid scheme increases utilization and reduces the <b>congestion</b> <b>ratio</b> and delay. The performance gained as compared to RSTP, link state, and MSTP are 20. 9 %, 9. 4 %, and 11. 4 %, respectively. In addition, the hybrid scheme is more scalable than using pure link state. Keywords-Link state, Metro Ethernet Network,Spanning Tree, routing...|$|R
40|$|Today’s {{fast and}} {{mobility}} oriented era of communication the networking infrastructure requires efficient communication. SPT and MCT {{are the two}} standard algorithms to provide efficient communication in wireless networking. SPT provides communication by recognizing the shortest path in a tree and propel the packet throughout this path. Since failures exist in the network, the SPT algorithm resists the failure by sending an ICMP messages which increases <b>congestion</b> <b>ratio</b> and rerouting of the packets while MCT algorithm forwards the packets {{on the basis of}} least number of transmissions. As the MCT algorithm transmits by consuming less number of cost, but during failure of intermediate links, it is also having the scope of improvement in the efficiency, i. e. transmission cost, rerouting cost and complexity of the network. These drawbacks are overcome by the proposed algorithm which works efficiently during failure of intermediate links. NS- 2 is used to simulate the results and shown the results with comparative analysis of three algorithm...|$|R
50|$|One of {{the most}} {{controversial}} aspects of the plan is the mayor’s <b>call</b> for <b>congestion</b> pricing, specifically a bid to levy a fee of $8.00 on all cars entering midtown Manhattan during peak hours on weekdays. The proposal has stalled in Albany despite support from environmental groups and the governor’s office.|$|R
40|$|In the {{competitive}} power market environment, congestion is an indicator {{for the need}} of transmission system reconfiguration by compensation devices or its expansion with new lines erection. Due to economic considerations, the short time solution like re-dispatch is also playing {{a key role in}} the present scenario. In some inevitable cases, moderating the congestion by load shedding is the only solution which is not good in practice. Hence this paper addresses a solution for congestionrelief, i. e. re-scheduling of generators if required simultaneously with load reduction. In re-schedule method, some of the generators are required to increase/decrease their actual market schedule which causes to increase/decrease transmission losses. Simultaneously, the increase in production cost so <b>called</b> <b>congestion</b> cost. The IEEE- 6 bus and IEEE 14 bus test systems are used to show the effectiveness of the proposed method...|$|R
40|$|This paper {{describes}} {{joint work}} done by IBM Research (development of the solution) and GrandLyon (assessment of the solution) for real-time traffic estimation and prediction on the urban road network of Lyon Metropolis, France. The methods are described and a new feature <b>called</b> <b>congestion</b> thresholds is presented which enhances prediction accuracy on the highly-variable conditions on an urban road network {{such as the one}} in Lyon, France. The methods were deployed in a pilot study on live real-time traffic data from Lyon. Numerical results and analysis are provided. The novelty of the work lies in three main features: the application of real-time traffic prediction to an urban road network; the definition and use of congestion thresholds as part of the prediction scheme; and the live piloting of the prediction technology with an urban traffic management center...|$|R
40|$|In this lesson, {{we learn}} about models used for {{circuit-switched}} networks. We start with an M/M/m/ m model, also called the m-server loss system [1]. We note here that [2], page 379 states that a system with a finite customer population will always be stable, no matter what value of ρ. This statement is made for any finite state space MC. Does this explain why in M/M/m/m model we often talk about ρ being 1, 10, 100 - see [3], pg. 235. Unlike in the M/M/m case, here ρ or offered load is defined to be λ ⁄ µ. In the M/M/m case, recall, we defined ρ to be λ ⁄ (mµ). In Section 1, we derive the Erlang-B formula for an infinite population. In Section 2, we derive the simple time congestion or blocking probability for a finite population model, called the Engset for-mula. In Section 3, we show the difference between <b>call</b> <b>congestion</b> or <b>call</b> loss probability and time congestion. For these two sections, refer to [6], page 518 - 521. Both [4] and [6] refer to [5] for the dif-ference between time <b>congestion</b> and <b>call</b> <b>congestion.</b> Section 4 describes the recursion formulation for numerically computing the Engset call loss probabilities from [4]. Section 5 derives the Blocked Call Queueing (BCQ) equations. Only the system in Section 1 is characterized using the queueing theory notation. In Sections 2 - 5, we are modeling {{a system in which}} the number of sources is limited. There is no place to indicate the number of sources from which jobs arrive in the Kendall notation. The last two numbers are for num-ber of servers, and number of jobs in the system. Thus the BCQ derivation for mean waiting delay is different from the mean delay derivations for M/M/ 1, M/M/m type queues that we learned in an ear-lier lesson. This lesson is entirely on the single-link case and is hence more about TDM/FDM sharing on a single link rather than circuit-switched networks...|$|R
40|$|Mobile Ad Hoc Networks {{consists}} of mobile nodes which are organized {{in a random}} manner. It can {{communicate with each other}} without any centralized infrastructure. Due to congestion, the packet loss is heavily occurred in the particular link. In order to avoid congestion, cross layer based congestion control scheme is proposed for reducing the packet losses in the network. The proposed scheme contains four phases. In first phase, the cross layer design is proposed to ensure that the information sharing can be done between the different layers in protocol stack. In second phase, the congestion detection scheme is explored which attains packet loss rate and congestion scale factor. In third phase, congestion control is achieved using cross layer approach. Here the congestion route is determined based on the path gain, buffer tenancy fraction. In fourth, new packet format is proposed. Each node maintains the congestion scale value, buffer tenancy fractional value. By extensive simulation, the proposed scheme achieves better throughput, <b>congestion</b> <b>ratio,</b> packet delivery ratio, low end to end delay and overhead than the existing schemes...|$|R
40|$|Abstract — In {{traditional}} channelized {{multiple access}} systems, e. g., TDMA and FDMA, each user is assigned {{a fixed amount}} of bandwidth during the whole service time, and the teletraffic performance {{in terms of time}} <b>congestion,</b> <b>call</b> <b>congestion</b> and traffic congestion can be easily obtained by using the classical Erlang-B formula. However, with the introduction of adaptive modulation and coding (AMC) scheme employed at the physical layer, the allocation of bandwidth to each user is no longer deterministic, but in a dynamic manner based on the wireless channel conditions. Thus a new connection attempt will be blocked with certain probability depending {{on the state of the}} system and the bandwidth requirement of that new connection. In this paper, we present an integrated analytical model of multirate loss system with state-dependent blocking to evaluate the performance of multi-class OFDM-TDMA systems with AMC scheme with some numerical examples. I...|$|R
40|$|We {{introduce}} {{the idea of}} a European-type <b>congestion</b> <b>call</b> option to value commuting to work along a given path for a given departure time selected by automobile drivers who are modeled as Cournot-Nash non-cooperative agents competing for limited roadway capacity when the alternative of telecommuting exists. We show how to compute flow patterns based on <b>congestion</b> <b>call</b> options and contrast these to traditional user optimized flow patterns. In particular, a numerical example is presented that shows congestion options have the potential to lower the network-wide social costs of congestion. ...|$|R
40|$|This {{document}} {{presents a}} novel approach for modeling sector <b>congestion</b> <b>called</b> the Sector <b>Congestion</b> Analytical Modeling Program (SCAMP) and the congestion metric it produces – the Standard Index of Sector COngestion (SISC 0). SCAMP is an airspace modeling program that calculates a component congestion metric for each pair of aircraft in a given volume of airspace. This document describes the theoretical basis for SCAMP and an experiment that validates {{the utility of the}} SISCO metric. The appendices present mathematical derivations of the SISCO metric, the SCAMP source code. SCAMP and SISC...|$|R
500|$|Johnson {{announced}} in July 2008 {{that the new}} CO2 charging structure {{will no longer be}} implemented. Among other reasons, he said the environmental charge would encourage travel by thousands of smaller vehicles free of charge, resulting in increased congestion and pollution. He also discarded plans for extending the charge zone to the suburbs, and announced he will review the western extension implemented in 2007, based on a public consultation planned for September 2008. Having held a five-week public consultation with residents in the autumn of 2008, Johnson decided to remove the 2007 Western Extension from the congestion charging zone beginning on January 4, 2011, to increase the basic charge to , and also to introduce an automated payment system <b>called</b> <b>Congestion</b> Charging Auto Pay (CC Auto Pay), which will charge vehicles {{based on the number of}} charging days a vehicle travels within the charging zone each month, and the drivers of these vehicles will pay a reduced [...] daily charge.|$|R
40|$|Abstract — Nowadays, {{the telecom}} network traffic {{environment}} is composed mostly of emerging multirate services whose calls can tolerate bandwidth compression either by extending their service-time (elastic services) or not (adaptive services). The coexistence of elastic and adaptive services makes the call-level performance analysis {{and evaluation of}} modern networks much more complicated. To contribute, in this paper, we present a new multirate loss model for elastic and adaptive services with finite traffic-source population. Thus, the call arrival process is a quasi-random process which is, in many cases, a more realistic consideration than a random (Poisson) process. The proposed model {{does not have a}} product form solution, and therefore, we propose approximate but recursive formulas for the efficient calculation of the call-level performance metrics, such as time and <b>call</b> <b>congestion</b> probabilities and link utilization. The consistency and the accuracy of the new model are verified through simulation and found to be quite satisfactory...|$|R
40|$|Abstract – The {{performance}} of TCP is {{strongly influenced by}} the congestion control algorithms that {{limit the amount of}} traffic a sender can transmit based on an estimated network capacity. These algorithms have been analysed in environments where applications have stable requirements on the anticipated transmission rate, however recent use of TCP with applications that exhibit significant variation in transmission rate present a new challenge, especially when these applications need to share a capacity-limited internet bottleneck. This paper investigates a technique <b>called</b> <b>Congestion</b> Window Validation (CWV) that seeks to modify TCP when flows do not utilise the full capacity allowed by the congestion window. This change is expected to reduce the impact of application-limited flows on other flows, by limiting the rate at which these applications can transmit following an idle or application-limited period, while allowing applications to appropriately restore their traffic rate when they cease being idle. The paper includes a survey of implementation within a range of operating systems...|$|R
40|$|Making end-systems {{accountable}} for the congestion they cause, will give an incentive to control one’s con-gestion appropriate. re-ECN is a new Transmission Control Protocol (TCP) mechanism to expose the ex-pected congestion on a network path. Based on such an announcement, the amount of congestion one end-system is allowed to introduce into the network can be limited. Therefore, a policer at network ingress is proposed which drops packets in congestion situa-tions, if no so <b>called</b> <b>congestion</b> credits are available. However, this will only allow to limit congestion of upstream traffic. If data is requested by a client, the server {{will not be able}} to decide about an appropri-ate data handling as the intention of the client is not known. To address this problem an architecture to transfer congestion credits from the client-side po-licer to the server-side policer could be used. This allows the server application to send with a higher data rate in congestion situations and hence give a higher priority to a respective data transmission. ...|$|R
40|$|Rapid {{development}} of wireless communications {{in recent years}} has imposed great chal-lenges for network support. As most current networking protocols were designed mainly for wired networks, many assumptions that make these protocols efficient in wired net-works are no longer true and cause severe performance degradation in wireless environ-ment. An urgent task for today’s networking research is to identify such deficiencies and to enhance these protocols. This dissertation contains four major enhancement results. The first result is a wireless TCP enhancement scheme <b>called</b> <b>Congestion</b> Coherence. Through a statistical analysis, we find the leading contributor of wireless TCP performance degradation is the timeout resulting from frequent packet losses. This scheme uses ECN to reduce number of time-outs, and based on the observation that congestion neither happens nor disappears suddenly, uses the sequential coherence of packet marking to determine cause of packet losses. Sim-ulations show this scheme works better than existing enhancements and produces good performance...|$|R
40|$|In Wireless Sensor Networks (WSN’s), {{congestion}} {{plays an}} important role in degrading the performance of the network. Under idle condition, the network load is very low whereas when an event is detected the network load becomes high which leads to congestion. Due to congestion the overall performance of the network degrades. Hence it is necessary to detect and control congestion. In this paper an efficient technique to detect and control congestion has been proposed. The congestion is detected by calculating a metric <b>called</b> <b>Congestion</b> Degree (Cd). It is the ratio between packet inter arrival time and packet inter service time. Once the congestion is detected, it is notified using Implicit Congestion Notification (ICN) signaling. On receiving the congestion notification signal, the transmission rate is controlled in order to reduce congestion. Further congestion control is implemented using Fuzzy Logic Controller. The performance of the network is measured for delivery ratio with different transmission rate and the PDR is compared with CODA...|$|R
40|$|Transit IP internetworks {{supporting}} USAF bases {{are highly}} congested during duty-hours {{and attempts to}} access to the Internet often fail. Often, during these connection failures, transit networks {{are in a state}} known as congestion collapse and connections time out when a user attempts to reach the Internet. This paper presents the results of a simple IP congestion analysis between four USAF bases and the Internet, graphically illustrating the congestion domains. We demonstrate that congestion in DISN links are primarily responsible for the congestion collapse. A skeleton framework for creating similar tests is included and suggestions for improvements to the simple test script are provided. INTRODUCTION "When too many packets are present in (a part of) the subnet, performance degrades. This situation is <b>called</b> <b>congestion.</b> " - Tanenbaum [1] Access to commercial, government and educational sites on the Internet has become a mission requirement for numerous functional areas in the USAF and [...] ...|$|R
40|$|The {{essential}} requirement in MANET is now group communication or multicasting {{since it is}} used in applications such as network news dissemination, collaborative computing, disaster relief operation, sensor network, military services. In this type of application reliability plays an important role. Designing a reliable multicast protocol in MANET is challenging task due to the dynamic topology, limited bandwidth, constraints of node capability, and frequent disconnections in MANET. In this paper, we propose a scheme <b>called</b> <b>Congestion</b> Control Anonymous Gossip(CCAG) to improve the reliable packet delivery of multicast routing protocols and decrease the variation {{in the number of}} packets received by the different nodes. It also consider the issues of reliability, low end to end delay, control overhead and packet delivery in mobile ad-hoc networks. The propose scheme works in two phases. In the first phase any suitable protocol is used to multicast the message to the group, while in second phase, the gossip protocol tries to recover lost messages...|$|R
5000|$|Johnson {{announced}} in July 2008 {{that the new}} CO2 charging structure {{will no longer be}} implemented. Among other reasons, he said the environmental charge would encourage travel by thousands of smaller vehicles free of charge, resulting in increased congestion and pollution. He also discarded plans for extending the charge zone to the suburbs, and announced he will review the western extension implemented in 2007, based on a public consultation planned for September 2008. Having held a five-week public consultation with residents in the autumn of 2008, Johnson decided to remove the 2007 Western Extension from the congestion charging zone beginning on January 4, 2011, to increase the basic charge to , and also to introduce an automated payment system <b>called</b> <b>Congestion</b> Charging Auto Pay (CC Auto Pay), which will charge vehicles {{based on the number of}} charging days a vehicle travels within the charging zone each month, and the drivers of these vehicles will pay a reduced [...] daily charge.|$|R
3000|$|In (5), a scalar λ {{is called}} as an energy component, which is LMP at a slack bus. The other vector term, H^T([...] μ_max - μ_min), is <b>called</b> a <b>congestion</b> component, which {{represents}} the congestion prices at all buses. If a marginal unit is connected to a slack bus, λ {{is equal to the}} marginal cost). Otherwise, λ has some implicit value involving the congestion condition.|$|R
40|$|Abstract—As mobile {{devices are}} popular portals for {{internet}} users; {{they have some}} basic design limitations of the TCP having congestion control mechanism. But in mobile wireless networks, non congestion related packet losses due to varying signal power inherent with mobility and handover between base-stations are dominant. Due to the misinterpretation of such non congestion related packet losses optimum performance is compromised. This paper {{provides an overview of}} the challenges and suggests optimization techniques for TCP in wireless network environments. The consequence is a wireless enhancement scheme for TCP <b>called</b> <b>Congestion</b> Coherence. By several investigations and statistical analysis, we identified that the performance degradation of wireless TCP is mainly due to the timeout resulting from frequent packet losses. This scheme determines the cause of packet loss by using the sequential coherence of packet marking, it uses three-level ECN signals to detect congestion loss and to reduce number of timeouts established on the perception that congestion neither happens nor disappears abruptly. Simulations show that the performance and efficiency of this technique is better than the existing techniques. Keywords-ECN, TCP, ECN-Echo I...|$|R
40|$|Abstract. With {{the wide}} {{application}} of computer network, network security issues become increasingly prominent. Currently, {{the most commonly}} used network security evaluation method is risk assessment method, as well as to test and evaluation system of safety degree by software vulnerability scanning tools and so on. However, network security is related to computer, communication, physics, mathematics, biology, management, social, and many other fields, which is complicated system engineering. As a result, poor operational safety exist in the existing method, thus in this paper, the research of computer complex network reliability evaluation method based on GABP algorithm is put forward. The development and status quo of network reliability research Network reliability research and development Computer network reliability research dates back to the 1955 when Mr. Lee explored telecommunications switching network. Due to network components failure makes telecommunications switching network transmission capacity always dropped substantially, cause <b>call</b> <b>congestion,</b> lead to large telecommunications switching network paralysis, cause huge economic losses. When Mr. Lee will see congestion as network link failures and for the first tim...|$|R
40|$|Traditional TCP cannot detect link {{contention}} {{losses and}} route failure losses which occur in MANET and considers every packet loss as congestion. This results in severe degradation of TCP performance. In this research work, we modified {{the operations of}} TCP to adapt to network states. The cross-layer notifications are used for adapting the congestion window and achieving better performance. We propose Cross-layer information based Transmission Control Protocol (CTCP) which consists of four network states. Decelerate state to recover from contention losses, Cautionary state to deal with route failures, Congested state to handle network congestion and Normal state to be compatible with traditional TCP. Decelerate state makes TCP slow down if the packet loss {{is believed to be}} due to contention rather than congestion. Cautionary state suspends the TCP variables and after route reestablishment resumes with conservative values. <b>Congestion</b> state <b>calls</b> <b>congestion</b> control when network is actually congested and normal state works as standard TCP. Simulation results show that network state based CTCP is more appropriate for MANET than packet loss based traditional TCP...|$|R
40|$|A {{major concern}} in adult-to-adult living donor liver {{transplantation}} is {{the selection of}} graft type; that is, is {{it is better to}} use the right lobe with or without the middle hepatic vein (MHV) ? This choice has a considerable impact on donor safety, vascular reconstruction and graft function in the recipient. To facilitate making an appropriate choice, {{on the basis of a}} preliminary study (n = 17), we herein propose a graft selection algorithm using three parameters: graft-to-recipient body weight ratio (GRWR), percentage remnant liver volume (%RLV) and estimated <b>congestion</b> <b>ratio</b> (ECR). The algorithm was evaluated with 50 consecutive cases with respect to postoperative liver function of donors and recipients and survival of recipients. Postoperative recovery was comparable between the two groups (p = NS). The overall cumulative 18 -month survival rate was 86. 7 % for the 'with MHV graft group', and 76. 1 % for the gwithout MHV graft grouph (p = NS). For 41 cases (82 %), graft types were chosen according to the algorithm, whereas the remaining 9 cases (18 %) needed detailed discussion of donor, recipient and operative factors. In conclusion, we constructed a graft selection algorithm based on congestion volume, which will contribute to objective graft-type selection in adult-to-adult LDLT...|$|R
