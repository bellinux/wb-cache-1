11|14|Public
5000|$|Further {{observations}} led {{to further}} improvements [...] - [...] scheduling the die {{changes in a}} standard sequence (as part of FRS) as a new model moved through the factory, dedicating tools to the die-change process so that all needed tools were nearby, and scheduling use of the overhead cranes so that the new die would be waiting as the old die was removed. Using these processes, Toyota engineers cut the <b>change-over</b> <b>time</b> to less than 10 minutes per die, and thereby reduced the economic lot size below one vehicle.|$|E
5000|$|Flow through {{reducing}} batch sizes: Every traditional business, {{whether in}} production or services, is addicted to batch. The idea as that once work {{is set up}} one way, we’d better get on and quickly make as many pieces of work as we can to keep the unit cost down. Lean thinking looks at this differently in trying to optimize the flow of work {{in order to satisfy}} real demand now, not imaginary demand next month. By working strenuously on reducing <b>change-over</b> <b>time</b> and difficulty, it is possible to approach the lean thinking ideal of single piece flow. In doing so, one reduces dramatically the general cost of the business by eliminating the need for warehouses, transports, systems, subcontractor use and so on.|$|E
40|$|In {{this paper}} a one-machine {{scheduling}} model is analyzed where [TeX: n] different jobs are classified into [TeX: K] groups {{depending on which}} additional resource they require. The <b>change-over</b> <b>time</b> from one job to another consists of the removal time or of the set-up time of the two jobs. It is sequence-dependent {{in the sense that}} the <b>change-over</b> <b>time</b> is determined by whether or not the two jobs belong to the same group. The objective is to minimize the makespan. This problem can be modeled as an asymmetric Traveling Salesman Problem with a specially structured distance matrix. For this problem we give a polynomial time solution algorithm that runs in [TeX: O(n...|$|E
40|$|Passive {{tracking}} of maneuvering emitters is of fundamental interest. For this purpose, an appropriate motion model, the piecewise curvilinear motion model, {{is presented in}} this paper. The high-dimensional target state is characterized by position, speed, course, piecewise constant tangential and normal velocity, as well as maneuver <b>change-over</b> <b>times.</b> A single moving sensor collects azimuth measurements to obtain the target state. In {{order to determine the}} maximum achievable estimation accuracy, we derive the Cramér-Rao bounds for this estimation problem. A maximum likelihood estimator is propsed to solve the localization problem and to calculate the maneuver <b>change-over</b> <b>times.</b> Estimation results are obtained in Monte Carlo simulations and the efficiency of the estimator is proven by comparing these results with the theoretical Cramér-Rao bound...|$|R
40|$|A multi-item capacitated make-to-order {{production}} system with considerable demand fluctuations is discussed. The {{relationship between the}} available capacity and the inventory needed to meet customer requirements with a pre-defined service level is modeled. Furthermore, the total cost for both capacity and inventory is minimized and it is shown that, assuming negligible <b>change-over</b> <b>times,</b> the double of the surplus inventory cost has to be equal to the excess capacity cost to ensure minimum total cost. Capacity Inventory Service level Excess capacity Surplus inventory Utilization...|$|R
50|$|The final {{branch line}} in the area was a short access line into the Holden car plant at Elizabeth, opened in 1959. This left the Gawler line around two {{kilometres}} north of Salisbury station and was used mainly by freight trains, but had passenger trains at shift <b>change-over</b> <b>times.</b> The last passenger train on the Holden branch ran in August 1992, and the remaining freight traffic stopped when the Melbourne to Adelaide line was converted to standard gauge in 1995.|$|R
40|$|Under {{the impact}} of {{transition}} to the new post-industrial society, mass production recently faced the most numerous difficulties. They are caused by turbulences in the external environment in which companies operate, manifested in particular by enhancing the dynamism of markets and by deep changes {{in the structure of}} consumers’ demands. In this context, specialized literature records the concerns for increasing the efficiency and flexibility of products, elements involving radical changes of management and manufacturing technologies methods. Given these issues, the paper approaches two separate ways to improve the management of serial production: increasing economic efficiency by optimizing the size of batches and flexible production systems by implementing techniques to reduce the <b>change-over</b> <b>time.</b> information society, serial production, batch production, the optimal batch size, SMED method, the <b>change-over</b> <b>time,</b> input exchange die, output exchange die...|$|E
40|$|In {{this paper}} a one-machine {{scheduling}} model is analysed where n different jobs are classified into K groups {{depending on which}} additional resource they require. The <b>change-over</b> <b>time</b> from one job to another consists of the removal or the set-up time of the two jobs and is sequence-dependent {{in the sense that}} the <b>change-over</b> <b>time</b> is determined by whether or not the two jobs belong to the same group. The objective is to minimize the makespan. The problem can also be modeled as an asymmetric Traveling Salesman Problem with a special structure on the distance matrix. For this problem we give an exact solution algorithm that requires O(n 2) elementary operations. Keywords: Scheduling, Traveling Salesman Problem, Polynomial Time Algorithm. Nijenrode University, The Netherlands School of Business, Straatweg 25, 3621 BG Breukelen, The Netherlands y Econometric Institute, Erasmus University Rotterdam, P. O. Box 1738, 3000 DR Rotterdam, The Netherlands 1 Introduction In this paper we c [...] ...|$|E
40|$|Background: The non-operative {{time during}} the process of patient {{change-over}} between operating theatre cases is a significant source of delay and overall theatre inefficiency. The aim {{of this study was to}} integrate and trial a working strategy to improve this <b>change-over</b> <b>time.</b> Method: This was a single-blinded, randomised controlled intervention study comparing a surgeon-led, team-based model of strategies versus routine patient change-over. This model was trialled by a single surgeon, and the primary outcome was the difference in change-over times compared with 4 other surgeons who were blinded and served as controls. Secondary outcome measures included overall differences in complications between the groups, and the number and differences in operative case cancellations due to inadequate theatre time. Results: 1265 patients were randomised into 5 general surgical lists, and included all major and minor cases. Median number of operative cases were 214 per surgeon, with an overall median change over time of 17. 9 ± 3. 7 min. Surgeon A in the intervention group had a median <b>change-over</b> <b>time</b> of 12. 1 ± 5. 4 min (p < 0. 001), with a median difference of 8. 5 min ± 21. 4 min (p < 0. 0001), translating to a 58 % reduction in median <b>change-over</b> <b>time</b> between the intervention and control groups. There were no differences in complication rates amongst the groups. The intervention group had no cancellations due to lack of time, compared with 37 cancellations in the control group. Conclusion: This study demonstrates a statistically significant improvement in median change-over times using this model. This re-design can be implemented without incurring extra costs, staff, or operating theatres...|$|E
50|$|Many of the TPS/Lean {{techniques}} work in {{a similar}} way. By planning to reduce manpower, or reduce <b>change-over</b> <b>times,</b> or reduce campaign lengths, or reduce lot sizes the question of waste comes immediately into focus upon those elements that prevent the plan being implemented. Often {{it is in the}} operations' area rather than the process area that muda can be eliminated and remove the blockage to the plan. Tools of many types and methodologies can then be employed on these wastes to reduce or eliminate them.|$|R
40|$|Genetic {{algorithms}} were intensively {{investigated in}} various modifications and in combinations with other algorithms for solving the NP-hard scheduling problem. This extended abstract describes a genetic algorithm approach for solving large job shop problems that uses hints from the schedule evaluation in the genetic operators. The {{result is a}} hybrid genetic algorithm with smaller randomness and more managed search to find better solutions in shorter processing time. The hybridized genetic algorithm was tested with data from wafer production with thousands of jobs and hundreds of machine alternatives. The hybridized genetic algorithm not only achieved smaller tardiness in shorter computation time but was also able to reduce the sequence dependent <b>change-over</b> <b>times</b> between jobs {{in comparison with the}} classical genetic algorithm...|$|R
40|$|Increasing {{productivity}} in splitting up of metal sheets {{by means of}} mechanical cutting processes is today limited by long <b>change-over</b> <b>times</b> as well as nonproductive times and insufficient quality caused by tool wear. In the case of highquality materials even a slight quality reduction concerning development of dross attachment and induced stress leads {{to a lot of}} rejects. In order to increase the cutting speeds within a range economical for industrial use, i. e. about 100 m/min, a completely new type of laser cutting processhad to be developed. As opposed to conventional laser cutting, during which a semicylindric cutting front is formed, a closed keyhole with subsequent melt film ejection is produced during the completely new laser cutting process. The incoupling of energy no longer only results from pure surface absorption but in addition from plasma formation and multiple reflection...|$|R
40|$|This note {{presents}} a dynamic programming formulation {{for the one}} machine sequencing problem. For each job the following are given: 1. (i) an arbitrary cost function of its completion time, 2. (ii) a processing time, 3. (iii) a set-up cost and a set-up time if this job {{is the first of}} the sequence. For each pair of jobs are given: 4. (iv) a change-over cost and a <b>change-over</b> <b>time.</b> This formulation contains two formulations of Held and Karp as special cases. ...|$|E
40|$|In {{this paper}} we {{consider}} the problem of scheduling n jobs such that makespan is minimized. It is assumed that the jobs {{can be divided into}} K job-classes and that the <b>change-over</b> <b>time</b> between two consecutive jobs depends on the job-classes to which the two jobs belong. In this setting, we discuss the one machine scheduling problem with arbitrary processing times and the parallel machines scheduling problem with identical processing times. In both cases it is assumed that the number of job-classes K is fixed. By using an appropriate integer programming formulation with a fixed number of variables and constraints, it is shown that these two problems are solvable in poly-nomial time. For the one machine scheduling case it is shown that the complexity of our algorithm is linear in the number of jobs n...|$|E
40|$|The {{process of}} live sound spatialisation has many {{unpredictable}} parameters. Large numbers of loudspeakers with variable frequency responses, hastily configured routings, live and recorded audio sources that change between works, unforeseen technical requirements, compatibility issues, unfamiliar control interfaces, limited setup, rehearsal and <b>change-over</b> <b>time,</b> complex power and signal routing schemes, long cable runs and unpredictable venue acoustics are all issues familiar to performers of electroacoustic music. Unsurprisingly, {{the articulation of}} space in a live, multi-loudspeaker scenario can be problematic. Even 'simple' CD-only diffusion requires dexterity {{on the part of}} the performer and considerable technical planning. If we consider multiple sources, with more than two channels of audio, each source to be diffused independently under the control of a single performer, the difficulties are compounded. Now consider that we want to stage a live performance of multiple works where each item on the programme has different requirements, and we have a real problem on our hands. A solution to this problem is needed. In Towards and New Architecture, Corbusier observes that a problem, clearly stated, naturally yields solutions through the process of design. Thus, the aeroplane is the logical conclusion to the problem, clearly stated, of sustaining flight. This ethos has been adopted by the authors in beginning to address the 'problem' of sound spatialisation, and in the ongoing development of Resound, a system comprising a bespoke hardware design and open-source software. This paper begins by stating the problem of sound spatialisation. Against this background, the Resound system is presented in design and implementation...|$|E
40|$|This thesis {{presents}} {{three different}} problems belonging to different planning {{stages of the}} workforce scheduling process. The first article addresses a tour scheduling problem faced by a ground-handling agency at airports. In this problem, multiskilled agents are assigned to shifts and days-off within a planning horizon of one month to cover the airlines agent requirements. The second article considers a technician routing and scheduling problem form an external maintenance provider. This problem mainly involves obtaining weekly schedules such that the maintenance tasks requested by geographically distributed customers are fulfilled. The considered decisions consist of the assignment of technicians to teams, the assignment teams to tasks, and the dispatch of teams to service routes. The third article addresses a task scheduling problem for check-in counters personnel at airports. This problem involves the daily assignment of multiskilled agents to flights (check-ins and boardings) considering the <b>change-over</b> <b>times</b> between gates, such that the agent requirements from the airlines are satisfied...|$|R
30|$|When a ship {{is going}} to pass through an {{emission}} control area, it has to start a fuel <b>change-over</b> procedure, in <b>time</b> and {{in such a way that}} the engine will be burning MGO at the inlet of the area.|$|R
40|$|In this exploratory, {{empirical}} {{study of}} modernizing durable goods plants, {{it was found}} that typical measures of flexibility (e. g., number of unique parts and part families) are independent. More importantly, plants and firms with greater strategic manufacturing focus, regardless of specific emphasis (e. g., cost or quality), scheduled fewer part numbers on new flexible automation systems. This suggests that product focus and strategic focus are related in plants producing discrete parts. When flexibility is emphasized as a strategic manufacturing focus, new automation systems are significantly more likely to have shorter <b>change-over</b> <b>times</b> per part family. In general, part family-changeover time ratios appear to have the greatest potential of measures evaluated for building a useful theory of flexibility in discrete parts manufacturing. An evaluation of changes made in part types and part families during the implementation period showed that product flexibility is pursued as a way to reduce high labor costs in manufacturing. These plants accomplished this end by increasing the number of parts scheduled on new systems. Implications for strategic management of flexibility and scope are presented. flexibility ratios, manufacturing strategy, flexibility, agile manufacturing...|$|R
40|$|Tightening {{system for}} bent sheet metal products. This final {{project has been}} {{developed}} by Joseba Lasa and the research group EMAP from the XIOS Hogeschool Limburg. I came from the University of the Basque Country in San Sebastian. I have done my thesis for the electromechanics department. The objective of this project has been to design and develop a tightening system for bent sheet metal parts, {{because one of the}} subjects in the research group EMAP is the dimensional accuracy control of this kind of pieces. Different kind of bent parts have been proposed. These pieces are being studied by EMAP in cooperation with sheet metal processing companies. The bent parts have to be measured accurately and therefore the product has to be positioned and fixed as good as possible. When designing a tightening or fixing system we have to be sure that this system will be as flexible as possible and can tight more than one piece in the same system. It also has to be as easy as possible to use, to get a good positioning and to have a short <b>change-over</b> <b>time.</b> And at last, the system has to be as cheap as possible. It is also interesting to be able to measure pieces in series to spend less time measuring the pieces. The following steps have been taken to find the most interesting fixing system for the different bent plates. 1. - A market study on different tightening methods and tools. 2. - Designing different kind of fixing methods. 3. - Developing the best fixing system 4. - Evaluating the system (resistance calculations, choosing material,...|$|E
40|$|Valeo Engine Cooling in Mjällby mainly {{produces}} truck coolers. At {{the production}} site, there is on-going work {{to phase out}} the automobile cooler manufacturing and concentrate the production to one facility. At {{the same time the}} main production flow needs to be improved. The purpose of this Master’s Thesis is to analyze the flow of coolers from the brazing furnaces through the different crimping and welding assembly stations, to find problem areas and implement changes to improve the situation. The analysis has pointed out three different areas: • The need to increase throughput of the brazing furnaces and lower the work in progress levels by reducing change-over times • The necessity to organize the crimping stock in FIFO and improve the layout • The importance of having a separate stock area assigned for manual welding assembly Currently, the brazing furnaces are operated 24 hours a day and this is still not sufficient to meet customer demands. Therefore, every extra hour of production that can be gained is valuable. The work with the change-overs in the brazing furnaces has resulted in a step-by-step guide to shorten the <b>change-over</b> <b>time.</b> It is based on the SMED methodology (Single Digit Minute Exchange of Die) and an analysis of shift reports from the furnaces. The yearly extra profit that would be made by implementing each step has been calculated to be between 2 and approximately 15 million SEK. The work is supposed to point out the importance of working on reducing the change-over times and show which actions are the most profitable. The actions include: reducing the number of belt speeds in the furnaces, having an end of line stock for all products, optimizing change-overs on the same belt speed and shorten the time used for changing belt speeds. Today, the crimping storage is very unorganized and difficult to overview. The plan is to store the cores in rows of wagons, instead of pallets, and to use the FIFO (First In First Out) principle. The stock levels fluctuate heavily over the week. To be able to dimension the new storage area the variations have been carefully analyzed. Two layout suggestions were created and compared. Both alternatives have advantages, but one of them was found to be superior due to higher safety and better stock organisation. The layout of a nearby water leak test station had to be changed in order to have the cell working as efficiently as today. The final layout alternative made this possible using a smaller area than today. The analysis of the main process flow showed that today there is no separate storage area for manual welding. Instead, these products are mixed within the robot welding assembly stock, and thereby complicating the work for the operators. A new storage area was needed with an area able to store 15 pallets. From the decision factors two layout alternatives were created. The chosen alternative is located closer to the manual welding cells and requires less extensive layout changes. To have everything working on the least possible area, the supply of tanks to a nearby crimping station had to be done with supply trains. These wagons were designed and built. They were also tested in a supply loop and at the crimping press with good results. Unfortunately, the wagons could not be added to the train loop since {{there was no room for}} the tanks in the service area. Still, it served as a good example of how much space is made available in a work cell by using small boxes and supply trains. Validerat; 20101217 (root...|$|E
50|$|It {{was from}} the {{automotive}} industry in the USA that the PLC was born. Before the PLC, control, sequencing, and safety interlock logic for manufacturing automobiles was mainly composed of relays, cam timers, drum sequencers, and dedicated closed-loop controllers. Since these could number in the hundreds or even thousands, the process for updating such facilities for the yearly model <b>change-over</b> was very <b>time</b> consuming and expensive, as electricians needed to individually rewire the relays to change their operational characteristics.|$|R
40|$|The thesis {{describes}} short-term load forecasting by {{an expert}} system approach based on knowledge engineering. Conventionally, short-term load prediction {{is based on}} mathematical models which either extract the mathematical properties in the time series of load data, or present the static causal relationships between the load demand and its effective factors. The conventional methods can predict the electrical demand under normal situations, but not for special events. The thesis proposes {{a new approach to}} estimate the loads for special events, such as time change-overs, public holidays, which is mainly based on knowledge about the system load. Based on the ARIMA model, modifications have been made to predict weekend loads, which take the weather effects into consideration. The thesis also proposes a method to disaggregate the overall load into its components in order to study the relationships between the components and the causal variables. The <b>time</b> <b>change-over</b> (from Greenwich Mean Time to British Summer Time and vice versa) effects can be considered by separately estimating the lighting load and the rest load. The thesis investigates the holiday load characteristics and presents different estimation methods for different public holidays ranging from normal Monday Bank Holidays to Christmas Day holiday periods. Knowledge about the load is represented in production rules. The proposed estimation methods are written in POP- 11 which can be interfaced with FORTRAN in which the ARIMA model is programmed for the prediction of the load under normal situations...|$|R
40|$|The {{formulated}} article aims {{to demonstrate}} how Geographic Information System (GIS) contribute as an important tool in the elaboration process of patrimony's inventory list. This paper has the Architecture School of Minas Gerais' Federal University (EA-UFMG) as case of study. Located in Belo Horizonte, Minas Gerais, Brazil; EA-UFMG is a relevant reference to the city's memory as it incorporates an outstanding cultural value by your modernist architectural attributes and so, by your contribution to the urban image construction. Recognized as cultural heritage, the edification chosen for case of study, is protected by the Deliberative Cultural Heritage Council of Belo Horizonte (CDPCM-BH). The elaboration of a patrimony's inventory list is an intricate and detailed task, which demands a specific and deep research of all components that constitute the protected patrimony. Using GIS to elaborate the referred task, by integrating cartographic and alphanumeric data base to an object, results in a substantial, nimble and accessible information record. Not only the data set mapping of the Architecture School's elements, it's comprehension and analysis was allowed {{by the use of}} ArcGIS, but employing it also provided possibility to observe such objects according to their <b>time</b> <b>change-over.</b> The case of study foments a further skilled process to elaborate patimony's inventory list and, also, stimulates a broad interaction among the several envolved sectors. As a valuable result, the data set compilation having GIS as work tool provides rich information that can be used supporting govermental management's heritage and improving the comunicattion range for the patrimony's promotion. Pages: 4944 - 495...|$|R
40|$|Summary Optimization-based {{decision}} support systems for planning problems in processing industries Nowadays, efficient planning of material flows {{within and between}} supply chains is of vital importance and {{has become one of}} the most challenging problems for {{decision support}} in practice. The tremendous progress in hard- and software of the past decades was an important gateway for developing computerized systems that are able to support decision making on different levels within enterprises. The history of such systems started in 1971 when the concept of Decision Support Systems (DSS) emerged. Over the years, the field of DSS has evolved into a broad variety of directions. The described research in this thesis limits to the category of model-driven or optimization-based DSS. Simultaneously with the emergence of DSS, software vendors recognized the high potentials of available data and developed Enterprise Systems to standardize planning problems. Meanwhile, information oriented systems like MRP and its successors are extended by the basic concepts of optimization based decision support. These systems are called Advanced Planning Systems (APS). The main focus of APS is to support decision making at different stages or phases in the material flow, i. e. from procurement, production, distribution to sales (horizontal-axis), on different hierarchical aggregation levels (vertical-axis) ranging from strategic (long-term) to operational (short- term) planning. This framework of building blocks decomposes planning tasks hierarchically into partial planning problems. This basic architecture of the planning processes in APS is known as the Supply Chain Planning Matrix (SCPM). Compared to, for instance, discrete parts  manufacturing, planning tasks  are much more complicated in processing industries due to a natural variation in the composition of raw materials, the impact of processing operations on properties of material flows, sequence dependent <b>change-over</b> <b>times,</b> the inevitable decline in quality of product flows and relatively low margins. These specific characteristics gave rise to focus on optimization-based decision support in the domain of processing industries. The problems to be addressed in this field call for (inter-related) decisions with respect to the required raw materials, the production quantities to be manufactured, the efficient use of available resources, and the times at which raw materials must be available. Although different APS modules can interact directly, coordination  and integration is often restricted to the exchange of data flows between different modules. Given the need for specific integrated decision support, the research presented in this thesis focusses particularly on medium to short term decision support at production stage in processing industry, including the vertical and horizontal integration and coordination with adjacent building blocks in the SCPM. Extensive reviews from literature show that the gap between research and practice of DSS is widening. As the field of DSS was initiated as an application oriented discipline, the strategy of what is referred to as “application-driven theory” was taken as the preferred approach for this thesis. “Application-driven” refers to a bottom-up approach which means that the relevance of the research should both be initiated and obtained from practice. The intended successful use of the proposed approaches should, where possible, be represented by tests of adequacy. Simultaneously, the contribution  to  “theory”  aims  to  be  a  recognizable  part  of  the  research  effort,  i. e. obtained understanding and insights from problems in practice should provide the basis for new approaches. Based on the preceding considerations we defined the following general research objective:   General research objective To support medium- to short term planning problems by optimization-based models and solution techniques such that:   i)           The applicability and added value of (prototype) systems is recognized and carried by decision makers in practice ii)          The proposed approaches contribute to knowledge, understanding and insights from a model building and – solving point of view. In order to link the general objective with the different studies in the thesis, we defined five, recurring research premises, i. e. Professional relevance and applicability  (P 1), Aggregation (P 2), Decomposition and reformulation (P 3), Vertical integration at production level (P 4), and  Horizontal coordination and integration (P 5). The overarching premise P 1 refers to the first part of the research objective. All other premises refer to the second part of the research objective, i. e. model building and/or – solving. Several planning issues are studied to give substance to the research objective and each study is connected to at least two research premises. Study 1 : Planning and scheduling in food processing industry The main question in Chapter 2 was:” How to apply aggregation, decomposition and reformulation in model-based DSS at planning and scheduling level such that the aspect of decision support is recognized and appreciated by decision makers in practice, and which level of aggregation is needed to integrate production planning (i. e. lot-sizing) and scheduling problems in a single model? The study consists of two parts. The first part of the study refers to a case study for the bottleneck packaging facilities of a large dairy company. The goal was  to develop, implement and test a pilot DSS which was able to deliver solutions recognized and carried by decision makers at lower decision levels. The latter aim implied that a straight-forward aggregation on time, product type, resources or product stage, was not preferred. The key to develop an approach for regular use was to identify and take advantage of specific problem characteristics. Clustering of numerous jobs, while retaining information at order level, could be exploited in a reformulation approach. The inclusion of (combined) generalized- and variable upper bound constraints gave very tight lower bounds and sparse search trees. An extensive test phase in daily practice showed that the main benefit of the DSS was the initial quality of the generated plans including the time needed to generate these schedules. Hence, decision makers could i) postpone their planning tasks, ii) conveniently cope with rush orders or planned maintenance and iii) easily generate alternatives or revised plans when unforeseen disturbances occur. Moreover, the graphical presentation and overview of the (future) working schedule enabled order acceptance to make use of remaining capacity. The study also showed that planning problems in practice cannot be captured exhaustively by a (simplified) model. Decision makers need the opportunity to modify automatically generated plans manually and use human judgement and experience such that the solution is tuned to the actual situation. Hence, the DSS should not be considered as an optimizer but rather as a tool for generating high quality plans to be used for further analysis. Within this context the various options of a user-friendly, graphical, and fully interactive user interface, were of major importance. Although the case study clearly demonstrates the validity of earlier case based DSS research for current days APS, the proposed approach is hardly a generic solution for a complete vertical integration between lot-sizing and scheduling. If lot-size decisions are strongly affected by the sequence of jobs, production planning and scheduling should be performed simultaneously. As the described case refers to an earlier study and today’s APS do not provide modules for integrated lot-sizing and scheduling, the second part of the study gives an overview of developments in literature regarding lot-sizing and scheduling models and assess their suitability for addressing sequence-dependent setups, non-triangular setups and product decay. The review shows a tendency in which so-called Big Bucket (BB) models are currently proposed for short term time horizons too. However, we argue that segmentation of the planning horizon is a key issue for simultaneous lot-sizing and scheduling. The advantage of BB models may become a major obstacle for i) the effectiveness of simultaneous lot-sizing and scheduling, and ii) addressing specific characteristics in food processing industry. Study   2 :   Vertical  integration  of  lot-sizing  and  scheduling  in  food  processing industry Chapter 3 focused on a complete integration of lot-sizing and scheduling decisions in a single model. The main question was:” How to integrate production planning (i. e. lot- sizing) and scheduling problems in a single model, such that common assumptions regarding the triangular setup conditions are relaxed and issues of product decay and limited shelf lives are taken into account?” The literature research in Chapter 2 revealed that the computational advantage of time oriented aggregation in BB models may become a major obstacle in addressing the identified characteristics in FPI. In addition, product decay is primarily associated with the “age” of products and consequently relates to the segmentation of the time- horizon. Therefore, two SB models are developed to demonstrate the impact of non- triangular setups and product decay on the generated solutions. Small scale examples were used to demonstrate how a small change in the balance between inventory - and changeover costs may generate significantly different solutions, especially when the triangular setup conditions do not hold. The developed models are potentially very large formulations and, as expected, hard to solve. Exploratory research was conducted with a Relax-and-Fix (R&F) heuristic. The heuristic is based on a decomposition of the time horizon. Numerical results of small to medium sized problem instances are promising. However, solving real-size|$|R

