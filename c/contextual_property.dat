4|116|Public
40|$|The role of {{contingent}} {{contexts in}} formulating relations between properties of systems at di¤erent descriptive levels is addressed. Based on {{the distinction between}} necessary and su ¢ cient conditions for interlevel relations, a comprehen-sive classi 8 ̆ 5 cation of such relations is proposed, providing a transparent concep-tual framework for discussing particular versions of reduction, emergence, and supervenience. One of these versions, contextual emergence, is demonstrated using two physical examples: molecular structure and chirality, and thermal equilibrium and temperature. The concept of stability is emphasized as a basic guiding principle of <b>contextual</b> <b>property</b> emergence...|$|E
40|$|The article {{explores the}} ways in which in early modern England masters {{exercised}} power over servants by means of threats and reproaches. More precisely, it investigates power-(im) politeness and the power-aggressiveness interfaces using data collected manually from a non-electronic corpus of advice manuals for masters (and mistresses), servants and apprentices published in English between 1660 and 1750. As we approach the mid-eighteenth century there is a growing concern for servants’ feelings and insistence on masters’ empathy towards servants. This was probably due to the new form of politeness emerging in the period, one which emphasised complaisance and social harmony. From a strictly linguistic viewpoint, I argue that in these texts (but this may apply to others too) threats are not presented as inherently impolite acts but as aggressive ones, and that impoliteness is only a <b>contextual</b> <b>property</b> aggravating intimidation and affirmation of power. Whatever the master’s degree of power and social status, therefore, they cannot be considered forms of ‘politic unmarked behaviour’. Reproaches share with threats a potentially intimidating perlocutionary effect, but unlike threats, they are not inherently aggressive, and can be a form of politic or contextually appropriate behaviour {{on the part of a}} master.   </p...|$|E
40|$|In Newtonian gravity, mass is an {{intrinsic}} property of matter while in general relativity (GR), mass is a <b>contextual</b> <b>property</b> of matter, i. e., matter can simultaneously possess two different values of mass {{when it is}} responsible for two different spatiotemporal geometries. Herein, we explore {{the possibility that the}} astrophysical missing mass attributed to non-baryonic dark matter (DM) actually obtains because we have been assuming the Newtonian view of mass rather than the GR view. Since an exact GR solution for realistic astrophysical situations is not feasible, we explore GR-motivated ansatzes relating proper mass and dynamic mass for one and the same baryonic matter, as justified by GR contextuality. We consider four GR alternatives and find that the GR ansatz motivated by metric perturbation theory works well in fitting galactic rotation curves (THINGS data), the mass profiles of X-ray clusters (ROSAT and ASCA data) and the angular power spectrum of the cosmic microwave background (CMB, Planck 2015 data) without DM. We compare our galactic rotation curve fits to modified Newtonian dynamics (MOND), Burkett halo DM and Navarro-Frenk-White (NFW) halo DM. We compare our X-ray cluster mass profile fits to metric skew-tensor gravity (MSTG) and core-modified NFW DM. We compare our CMB angular power spectrum fit to scalar-tensor-vector gravity (STVG) and ΛCDM. Overall, we find our fits to be comparable to those of MOND, MSTG, STVG, ΛCDM, Burkett, and NFW. We present and discuss correlations and trends for the best fit values of our fitting parameters. For the most part, the correlations are consistent with well-established results at all scales, which is perhaps surprising given the simple functional form of the GR ansatz. Comment: 18 pages text. Twice revised per referee/reviewer comments. Fit of CMB angular power spectrum and dark matter halo fits adde...|$|E
40|$|The {{vision of}} the ambient society relies on the {{constant}} exchange of personal information among multiple devices, individuals and organisations. The high number of microtrust decisions required in such a scenario calls for automated trust management. In this {{paper we discuss a}} set of <b>contextual</b> <b>properties</b> of transactions that ensure trust and trustworthy action in everyday situation and suggest how they can be incorporated in trust management for ambient technologies. We identify institutions, repeated interactions and reputation as <b>contextual</b> <b>properties</b> that support cooperation. We then discuss the limitations and risks of assuring cooperation based on <b>contextual</b> <b>properties</b> alone. Firstly, a subjective assessment of personal properties (e. g. benevolence and integrity) also forms an important basis for trust in others. Furthermore trust based on <b>contextual</b> <b>properties</b> is hard to establish in the case of vague outcomes, and multi-dimensional risks. Finally, establishing one's own trustworthiness requires giving access to personal information. Ambient technologies must also allow individuals to remain untrusted but private...|$|R
40|$|Turkish is an agglutinative {{language}} with complex morphological structures, therefore using only word forms {{is not enough}} for many computational tasks. In this paper we analyze the effect of morphology in a Named Entity Recognition system for Turkish. We start with the standard word-level representation and incrementally explore the effect of capturing syntactic and <b>contextual</b> <b>properties</b> of tokens. Furthermore, we also explore a new representation in which roots and morphological features are represented as separate tokens instead of representing only words as tokens. Using syntactic and <b>contextual</b> <b>properties</b> with the new representation provide an 7. 6 % relative improvement over the baseline. ...|$|R
40|$|Background: In {{order to}} extract {{meaningful}} information from electronic medical records, such as signs and symptoms, diagnoses, and treatments, {{it is important}} {{to take into account the}} <b>contextual</b> <b>properties</b> of the identified information: negation, temporality, and experiencer. Most work on automatic identification of these <b>contextual</b> <b>properties</b> has been done on English clinical text. This study presents ContextD, an adaptation of the English ConText algorithm to the Dutch language, and a Dutch clinical corpus. Results: The ContextD algorithm utilized 41 unique triggers to identify the <b>contextual</b> <b>properties</b> in the clinical corpus. For the negation property, the algorithm obtained an F-score from 87 % to 93 % for the different document types. For the experiencer property, the F-score was 99 % to 100 %. For the historical and hypothetical values of the temporality property, F-scores ranged from 26 % to 54 % and from 13 % to 44 %, respectively. Conclusions: The ContextD showed good performance in identifying negation and experiencer property values across all Dutch clinical document types. Accurate identification of the temporality property proved to be difficult and requires further work. The anonymized and annotated Dutch clinical corpus can serve as a useful resource for further algorithm development...|$|R
40|$|This {{dissertation}} {{is about}} one of the most robust and widespread types of pragmatic meaning in natural language: scalar implicatures (SIs). A scalar implicature is the inference that when a speaker uses a linguistic item that is on a scale with another item, the hearer concludes the sentence with the stronger scale member does not hold. For instance the inferences from 'It was okay' to 'It was not excellent' and from 'Some students passed' to 'Not all students passed' are scalar implicatures. It is widely acknowledged that these inferences are context-dependent, yet {{little is known about the}} properties of the context that determine their presence or absence. This thesis aims to contribute to the filling of this gap by considering the relation between SIs and the <b>contextual</b> <b>property</b> of information focus. Additionally, it addresses the psychological reality of the view that the exclusive reading of 'or', on which 'A or B' means 'A or B but not both', comes about by an SI. The thesis addresses these questions through a set of 11 experiments, both off-line (questionnaires) and on-line (processing). Next to the relation between SIs and focus, these experiments consider relevance of the stronger scalar alternative, the processing cost of SI-calculation, the assumption of speaker expertise and the relation between SIs and exhaustivity. The results support the prediction that information focus affects SI-calculation. However, the array of data taken together raise doubts about the view that the exclusive reading of 'or' is the result of a scalar implicature. The author discusses and tests theoretical insights from truth-conditional semantics, logic, pragmatics and reasoning as well as insights and results from (experimental) psycholinguistics, so this dissertation should be of interest to scholars in any of these domains...|$|E
40|$|It is {{well known}} that in quantum {{mechanics}} we cannot always define consistently properties that are context independent. Many approaches exist to describe <b>contextual</b> <b>properties,</b> such as Contextuality by Default (CbD), sheaf theory, topos theory, and non-standard or signed probabilities. In this paper we propose a treatment of <b>contextual</b> <b>properties</b> that is specific to quantum mechanics, as it relies on the relationship between contextuality and indistinguishability. In particular, we propose that if we assume the ontological thesis that quantum particles or properties can be indistinguishable yet different, no contradiction arising from a Kochen-Specker-type argument appears: when we repeat an experiment, we are in reality performing an experiment measuring a property that is indistinguishable from the first, but not the same. We will discuss how the consequences of this move may help us understand quantum contextuality. Comment: 21 pages, no figure...|$|R
40|$|IEEE/IFIP 8 th International Conference on Embedded and Ubiquitous Computing, EUC 2010, Hong Kong, 11 - 13 December 2010 Context-awareness is an {{essential}} feature of pervasive applications, and runtime detection of <b>contextual</b> <b>properties</b> {{is one of the}} primary approaches to enabling context-awareness. However, existing context-aware middleware does not provide sufficient support for detection of <b>contextual</b> <b>properties</b> in asynchronous environments. We argue that in asynchronous environments, the concept of time needs to be reexamined. Instead of assuming the availability of global time or synchronous interaction, we should rely on logical time. To this end, we present the Middleware Infrastructure for Predicate detection in Asynchronous environments (MIPA), which supports context-awareness based on logical time. Design and operation of MIPA are explained in detail. We also evaluate MIPA with a comprehensive case study. The evaluation results show the cost-effectiveness and scalability of MIPA. Department of Computin...|$|R
40|$|An {{extended}} CIE transformation {{was employed}} to deal with data reduction problems of hyperdimensional spectral data for NASA airborne and Shuttle imaging spectrometers. A simple descriptor {{was found to be}} very effective in analyzing spectral data covers from 0. 4 to 2. 4 microns. Results reveal <b>contextual</b> <b>properties</b> of minerals, vegetation, and crops. It provides a means to monitor seasonal growth variations for crops. It can also serve as pseudocolor indexing for imaging spectrometer imagery extended beyond the visible range...|$|R
40|$|Abstract. Various {{characteristics}} of the problem domain define {{the context in which}} the system is to operate and thus impact heavily on its requirements. However, most requirements specifications do not consider <b>contextual</b> <b>properties</b> and few modeling notations explicitly specify how domain variability affects the requirements. In this paper, we propose an approach for using contexts to model domain variability in goal models. We discuss the modeling of contexts, the specification of their effects on system goals, and the analysis of goal models with contextual variability. The approach is illustrated with a case study. 1...|$|R
40|$|The chapter first {{discusses}} {{the status of}} cognitive maps {{and goes on to}} pay attention to issues in capturing individuality. This is followed by a plea of comparisons to be made which attend to differences and similarities in meaning (structural and <b>contextual</b> <b>properties)</b> as well as suggestions about how this might be done when computer software is available to investigate many properties of a map. Finally, the chapter argues for an holistic approach to comparison by declaring the properties of a map as a systemic portfolio of ways of viewing the map...|$|R
40|$|Road {{extraction}} from {{satellite images}} is challenging research area in information extraction from high-resolution remote sensing images such as IKONOS and QUICKBIRD. The road from satellite {{images can be}} identified based on its geometric, spectral, topological and <b>contextual</b> <b>properties</b> {{as well as on}} various illumination and geographical environment. The road network extraction results in map generation in short time. In this paper roads are extracted by semi automatic method road network. Image Binarization is achieved by C means clustering algorithm followed by morphological operation which includes filtering and image thinning...|$|R
40|$|It {{has been}} an {{empirical}} fact that almost all the words are polysemous. A standard dictionary such as the Petit Robert lists 60, 000 entries which correspond to 300, 000 meanings. Thus, in this particular dictionary one word is paired with five different senses on average. Moreover, what is being dealt with here {{is no more than}} a general reference work, designed for a daily use. It contains only most frequent and general items, but disregards all other available meanings. In what follows, <b>contextual</b> <b>properties</b> will be demonstrated to be able to set apart each instance of polysemy, thus offering an effectual tool likely to do away with ambiguities. It {{has been an}} empirical fact that almost all the words are polysemous. A standard dictionary such as the Petit Robert lists 60, 000 entries which correspond to 300, 000 meanings. Thus, in this particular dictionary one word is paired with five different senses on average. Moreover, what is being dealt with here {{is no more than a}} general reference work, designed for a daily use. It contains only most frequent and general items, but disregards all other available meanings. In what follows, <b>contextual</b> <b>properties</b> will be demonstrated to be able to set apart each instance of polysemy, thus offering an effectual tool likely to do away with ambiguities...|$|R
40|$|Linguistic {{convention}} allows speakers various options. Evidence is accumulating {{that the}} various options are preferred in different contexts yet the criteria governing {{the selection of the}} appropriate form are often far from obvious. Most researchers who attempt to discover the factors determining a preference rely on the linguistic analysis and statistical modeling of data extracted from large corpora. In this paper, we address {{the question of how to}} evaluate such models and explicitly compare the performance of a statistical model derived from a corpus with that of native speakers in selecting one of six Russian TRY verbs. Building on earlier work by Divjak (2003, 2004, 2010) and Divjak & Arppe (2013), we trained a polytomous logistic regression model to predict verb choice given the context. We compare the predictions the model makes for 60 unseen sentences to the choices adult native speakers make in those same sentences. 1 We then look in more detail at the interplay of the <b>contextual</b> <b>properties</b> and model computationally how individual differences in assessing the importance of <b>contextual</b> <b>properties</b> may impact the linguistic knowledge of native speakers. Finally, we compare the probability the model assigns to encountering each of the 6 verbs in the 60 test sentences to the acceptability ratings the adult native speakers give to those sentences. We discuss the implications of our findings for both usage-based theory and empirical linguistic methodology...|$|R
40|$|Computational {{processing}} of text exchanged in interactive venues {{in which participants}} engage in simultaneous conversations can benefit from techniques for automatically grouping overlapping sequences of messages into separate conversations, a problem known as “disentanglement. ” While previous methods exploit both lexical and non-lexical information that exists in conversations for this task, the inter-dependency between {{the meaning of a}} message and its temporal and social contexts is largely ignored. Our approach exploits <b>contextual</b> <b>properties</b> (both explicit and hidden) to probabilistically expand each message to provide a more accurate message representation. Extensive experimental evaluations show our approach outperforms the best previously known technique. ...|$|R
40|$|In this paper, {{we develop}} a simple model {{to study and}} analyze {{communication}} dynamics in the blogosphere and use these dynamics to determine interesting correlations with stock market movement. This work can drive targeted advertising on the web as well as facilitate understanding community evolution in the blogosphere. We describe the communication dynamics by several simple <b>contextual</b> <b>properties</b> of communication, e. g. the number of posts, the number of comments, the length and response time of comments, strength of comments and the different information roles that can be acquired by people (early responders / late trailers, loyals / outliers). We study a “technology-savvy” community called Engadge...|$|R
40|$|The precise {{specification}} of software models {{is a major}} concern in the model-driven design of object-oriented software. Models are commonly given as graph-like diagrams so that graph grammars are a natural candidate for specifying them. However, context-free graph grammars are not powerful enough to specify all static properties of a model. Even the recently proposed adaptive star grammars cannot capture all properties of object-oriented models. So we extend adaptive star rules by positive and negative application conditions to overcome these deficiencies without sacrificing parsing algorithms. It turns out that conditional adaptive star grammars are powerful enough to generate program graphs, a software model with rather complicated <b>contextual</b> <b>properties...</b>|$|R
40|$|With an {{increasing}} number of technologies supporting transactions over distance and replacing traditional forms of interaction, designing for trust has become a core concern for researchers in both HCI and CMC. While much research focuses on increasing trust in mediated interactions, this paper takes a systemic view to identify the factors that support trustworthy behavior. In a second step, we analyze how the presence of these factors can be signaled to allow the formation of well-placed trust. For our analysis we draw on relevant research from sociology, economics, and psychology, as well as empirical findings in HCI and CMC research. The key factors that warrant trust in another actor are <b>contextual</b> <b>properties</b> (temporal, social, and institutional embeddedness) and the trusted actor’s intrinsic properties (ability and motivation). In first interactions, trust is mainly warranted by <b>contextual</b> <b>properties,</b> as they provide external incentives and threat of punishment. As interactions are repeated over time and trust grows, intrinsic properties become more important. To increase the level of well-placed trust, researchers and designers need to identify signals for the presence of such trust-warranting properties that are reliable and easy to interpret. At the same time, they must be cheap to emit for actors whose actions are governed by them but costly to mimic for untrustworthy actors. Our analysis provides a frame of reference for the design of studies on trust in technology-mediated exchanges, as well as a guide for identifying trust requirements in design processes. We demonstrate application of the model in three scenarios: ecommerce, voice-enabled online gaming, and ambient technologies...|$|R
40|$|Abstract. After some {{suggestions}} {{about how to}} clarify the confused metaphysical distinctions between dispositional and non-dispositional or categorical properties, I review {{some of the main}} interpretations of QM in order to show that – with the relevant exception of Bohm’s minimalist interpretation – quantum ontology is irreducibly dispositional. Such an irreducible character of dispositions must be explained differently in different interpretations, but the reducibility of the <b>contextual</b> <b>properties</b> in the case of Bohmian mechanics is guaranteed {{by the fact that the}} positions of particles play the role of the categorical basis, a role that in other interpretations cannot be filled by anything else. In Bohr’s and Everett-type interpretations, dispositionalism is instrumentalism in disguise...|$|R
40|$|International audienceThe {{integration}} of lexical semantics and pragmatics {{in the analysis}} of the meaning of natural lan- guage has prompted changes to the global framework derived from Montague. In those works, the original lexicon, in which words were assigned an atomic type of a single-sorted logic, has been re- placed by a set of many-facetted lexical items that can compose their meaning with salient <b>contextual</b> <b>properties</b> using a rich typing system as a guide. Having related our proposal for such an expanded framework ΛTYn, we present some recent advances in the logical formalisms associated, including constraints on lexical transformations and polymorphic quantifiers, and ongoing discussions and research on the granularity of the type system and the limits of transitivity...|$|R
40|$|Abstract. In this paper, {{we address}} the problem of scientific-social network {{integration}} to find a matching relationship between members of these networks. Utilizing several name similarity patterns and <b>contextual</b> <b>properties</b> of these networks, we design a focused crawler to find high probable matching pairs, then the problem of name disambiguation is reduced to predict the label of each candidate pair as either true or false matching. By defining matching dependency graph, we propose a joint label prediction model to determine the label of all candidate pairs simultaneously. An extensive set of experiments have been conducted on six test collections obtained from the DBLP and the Twitter networks to show the effectiveness of the proposed joint label prediction model. ...|$|R
40|$|After some {{suggestions}} {{about how to}} clarify the confused metaphysical distinctions between dispositional and non-dispositional or categorical properties, I review {{some of the main}} interpretations of QM in order to show that – with the relevant exception of Bohm’s minimalist interpretation – quantum ontology is irreducibly dispositional. Such an irreducible character of dispositions must be explained differently in different interpretations, but the reducibility of the <b>contextual</b> <b>properties</b> in the case of Bohmian mechanics is guaranteed {{by the fact that the}} positions of particles play the role of the categorical basis, a role that in other interpretations cannot be filled by anything else. In Bohr’s and Everett-type interpretations, dispositionalism is instrumentalism in disguise...|$|R
40|$|In this paper, {{we address}} the problem of scientific-social network {{integration}} to find a matching relationship between members of these networks. Utilizing several name similarity patterns and <b>contextual</b> <b>properties</b> of these networks, we design a focused crawler to find high probable matching pairs, then the problem of name disambiguation is reduced to predict the label of each candidate pair as either true or false matching. By defining matching dependency graph, we propose a joint label prediction model to determine the label of all candidate pairs simultaneously. An extensive set of experiments have been conducted on six test collections obtained from the DBLP and the Twitter networks to show the effectiveness of the proposed joint label prediction model...|$|R
40|$|In this work, {{we examine}} an access scope, a concept in {{authorization}} management broadly {{applied for the}} specification of access constraints in web service integrations. By analyzing a typical use-case of cross-organizational cloud service automation, we show the suboptimal capabilities of static, coarse-grained and inflexible scopes that negatively impact security and management of service integrations on a web scale. Using the graph-based structure that relies on semantic technologies we introduce dereferenceable and selfdescriptive authorization extents that allow expressive, granular and dynamic specification of security requirements. Through its application in the running scenario, we show how this construct can be administered to support confidentiality, integrity and privacy requirements of service integrations by allowing selective information sharing based on <b>contextual</b> <b>properties...</b>|$|R
40|$|This Letter proposes an object‐based image {{classification}} procedure {{which is based}} on fuzzy image‐regions instead of crisp image‐objects. The approach has three stages: (a) fuzzification in which fuzzy image‐regions are developed, resulting in a set of images whose digital values express the degree of membership of each pixel to target land‐cover classes; (b) feature analysis in which <b>contextual</b> <b>properties</b> of fuzzy image‐regions are quantified; and (c) defuzzification in which fuzzy image‐regions are allocated to target land‐cover classes. The proposed procedure is implemented using automated statistical techniques that require very little user interaction. The results indicate that fuzzy segmentation‐based methods produce acceptable thematic accuracy and could represent a viable alternative to current crisp image segmentation approaches...|$|R
40|$|The {{integration}} of lexical semantics and pragmatics {{in the analysis}} of the meaning of natural lan- guage has prompted changes to the global framework derived from Montague. In those works, the original lexicon, in which words were assigned an atomic type of a single-sorted logic, has been re- placed by a set of many-facetted lexical items that can compose their meaning with salient <b>contextual</b> <b>properties</b> using a rich typing system as a guide. Having related our proposal for such an expanded framework, we present some recent advances in the logical formalisms associated, including constraints on lexical transformations and polymorphic quantifiers, and ongoing discussions and research on the granularity of the type system and the limits of transitivity...|$|R
40|$|With an {{increasing}} number of technologies supporting interaction at a distance, trust in mediated interactions has become a key interest in the field of human computer interaction (HCI). Research covers the role of trust in mediated interactions with other individuals (e. g. in virtual teams) and organisations (e. g. via e-commerce web sites). This chapter synthesises current research into a framework that introduces the key factors that affect trust and trustworthy behaviour. These are <b>contextual</b> <b>properties</b> (motivation based on temporal, social, and institutional embeddedness), and the actor’s intrinsic properties (ability, and motivation based on internalized norms and benevolence). Knowledge of these underlying factors can help designers in structuring the design space and researchers in planning and generalising from studies on trust in mediated interactions...|$|R
40|$|Given the intractability of exhaustively verifying soft-ware, {{the use of}} runtime-verification {{to verify}} single {{execution}} paths at runtime, is becoming increasingly popular in industrial settings. In this paper we present dynamic communicating automata with timers and events to describe properties of systems, implemented in LARVA, an event-based runtime verification tool for monitoring temporal and <b>contextual</b> <b>properties</b> of Java programs. We give the mathematical framework behind LARVAand show how real time logics can be trans-lated into LARVAproviding additional benefits to the runtime monitoring framework. These benefits include guarantees on the memory upperbound required for the monitoring system and guarantees {{on the effect of}} varying the execution speed of the system with regards to real-time properties. Index Terms runtime verification, real-time properties, duration cal-culus 1. peer-reviewe...|$|R
40|$|Abstract — The {{classification}} methods {{applied in}} the objectoriented image analysis approach are often based {{on the use of}} domain knowledge. A key issue in this approach is the acquisition of this knowledge which is generally implicit and not formalized. In this paper, we examine the possibilities of using genetic programming for the automatic extraction of classification rules from urban remotely sensed data. The method proposed is composed of several steps: segmentation, feature extraction, selection of training sets, acquisition of rules, classification. Features related to the spectral, spatial and <b>contextual</b> <b>properties</b> of the objects are used in the classification procedure. Experiments are made on a Quickbird MS image. The quality of the results shows the effectiveness of the proposed genetic classifier in the object-oriented, knowledge-based approach. Keywords- genetic classifier, knowledge-based classification method, object-oriented approach. I...|$|R
40|$|We {{propose a}} new class of spatial logics for concurrency, Dynamic Epis-temic Spatial Logics, to be used for specifying {{properties}} of concurrent and distributed systems. These logics are developed as extensions of Hennessy-Milner logic, with spatial and epistemic operators. We propose the use of epistemic operators to express contextual situations and to treat pro-cesses/programs as epistemic agents. Knowledge is thus defined as infor-mation (about the overall, global processes) that is locally available (to an agent/suprocess). The novelty with respect to spatial logics comes from proposing a way to express <b>contextual</b> <b>properties</b> of dynamic systems within the limits of decid-ability. For our logics, satisfiability, validity and model-checking problems have been proved to be decidable in combination with temporal and dynamic operators. This idea is also new for epistemic logics, as we have an algebraical struc...|$|R
40|$|Abstract Context-aware {{applications}} monitor {{changes in}} their operating environment and switch their behaviour to keep satisfying their requirements. Therefore, they must be equipped with the capability to detect variations in their operating context and to switch behaviour in response to such variations. However, specifying monitoring and switching in such applications can be difficult due to their dependence on varying <b>contextual</b> <b>properties</b> which {{need to be made}} explicit. In this paper, we present a problemoriented approach to represent and reason about contextual variability and assess its impact on requirements; to elicit and specify concerns facing monitors and switchers, such as initialisation and interference; and to specify monitoring and switching behaviours that can detect changes and adapt in response. We illustrate our approach by applying it to a published case study...|$|R
40|$|Fuzzy Image Regions were {{proposed}} {{recently as}} an alternative GEOBIA method for conducting qualitative land cover classification. In this paper, these fuzzy segments are applied for estimation of quantitative (i. e. compositional) land cover. The method comprises three main stages: (i) fuzzy segmentation to create segments with indeterminate boundaries and uncertain thematic allocation; (ii) feature analysis to evaluate <b>contextual</b> <b>properties</b> of fuzzy image regions; and (iii) final regression to estimate compositional land cover. The method is implemented using advanced machine learning techniques and tested in a rapidly urbanizing area using Landsat multispectral imagery. Experimental {{results suggest that the}} method produces accurate sub-pixel characterization of land cover classes. Thus, the proposed method is potentially useful for bridging the gap between the traditional quantitative and qualitative perspectives of remote sensing image analysis...|$|R
40|$|Context-aware {{applications}} monitor {{changes in}} their operating environment and switch their behaviour to keep satisfying their requirements. Therefore, they must be equipped with the capability to detect variations in their operating context and to switch behaviour in response to such variations. However, specifying monitoring and switching in such applications can be difficult due to their dependence on varying <b>contextual</b> <b>properties</b> which {{need to be made}} explicit. In this paper, we present a problem-oriented approach to represent and reason about contextual variability and assess its impact on requirements; to elicit and specify concerns facing monitors and switchers, such as initialisation and interference; and to specify monitoring and switching behaviours that can detect changes and adapt in response. We illustrate our approach by applying it to a published case study...|$|R
40|$|Context, by nature, {{involves}} {{real world}} entities {{and is therefore}} subject to uncertainty and inaccuracies. Ontologies are often used to model context in a formal way {{in order to achieve}} a shared semantic understanding of concepts and the relationships that hold among them. However, they lack support for representing ambiguous context and appropriate comparison algorithms. As such, context-aware applications may make the assumption that the context they use is completely accurate. In this paper we propose a simple and lightweight yet generic approach to extend context ontologies with quality of context properties and discuss the use of these quality properties for context ontology matching under uncertainty using fuzzy set theory. We illustrate the proposed extensions and uncertainty mechanisms with a small example where uncertain spatiotemporal coverage is combined with other <b>contextual</b> <b>properties...</b>|$|R
40|$|International audienceWe {{present the}} main {{findings}} and preliminary {{results of an}} ongoing project aimed at developing a system for collocation extraction based on <b>contextual</b> morpho-syntactic <b>properties.</b> We explored two hybrid extraction methods: the first method applies language-indepedent statistical techniques followed by a linguistic filtering, while the second approach, available only for German, {{is based on a}} set of lexico-syntactic patterns to extract collocation candidates. To define extraction and filtering patterns, we studied a specific collocation category, the Verb-Noun constructions, using a model inspired by the systemic functional grammar, proposing three level analysis: lexical, functional and semantic criteria. From tagged and lemmatized corpus, we identify some <b>contextual</b> morpho-syntactic <b>properties</b> helping to filter the output of the statistical methods and to extract some potential interesting VN constructions (complex predicates vs complex predicator). The extracted candidates are validated and classified manually...|$|R
