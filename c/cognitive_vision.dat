132|122|Public
40|$|The {{emerging}} {{discipline of}} <b>cognitive</b> <b>vision</b> requires a proper representation of visual information including {{spatial and temporal}} relationships, scenes, events, semantics and context. The goal of this review article is to summarize existing representational schemes which might be useful for <b>cognitive</b> <b>vision,</b> and to discuss promising future research directions. We structure the various approaches into appearance-based, spatio-temporal and graph-based representations for <b>cognitive</b> <b>vision.</b> The representation of objects has been covered extensively in computer vision research, both from a reconstruction {{as well as from}} a recognition point of view. <b>Cognitive</b> <b>vision,</b> however, will also require new ideas how to represent scenes. We introduce new concepts for scene representations and discus...|$|E
40|$|This {{volume is}} a post-event {{proceedings}} volume and contains selected papers {{based on the}} presentations given, and the lively discussions that ensued, during a seminar held in Dagstuhl Castle, Germany, in October 2003. Co-sponsored by ECVision, the <b>cognitive</b> <b>vision</b> network of excellence, it was organized to further strengthen cooperation between research groups from different countries {{working in the field}} of <b>cognitive</b> <b>vision</b> systems...|$|E
40|$|In this paper, we {{describe}} user experiences {{with a system}} equipped with <b>cognitive</b> <b>vision</b> that interacts with the user {{in the context of}} personal assistance in the office. A <b>cognitive</b> <b>vision</b> computer can see the user and user responses and react to situations that happen in the environment, crossing the boundary between the virtual and the physical world. How should such a seeing computer interact with its users? Three different interface styles – a traditional GUI, a cartoon-like embodied agent and a realistic embodied agent – are tested in two tasks where users are actively observed by a (simulated) <b>cognitive</b> <b>vision</b> system. The system assists them in problem solving. Both the non-embodied and the embodied interaction styles offer the user certain advantages and the pros and cons based on the experiment results are discussed in terms of performance, intelligence, trust, comfort, and social presence. Author Keywords <b>Cognitive</b> <b>vision,</b> embodied agent, personal assistant...|$|E
5000|$|Future {{embedded}} systems {{will have more}} intelligence and <b>cognitive</b> functionality. <b>Vision</b> is paramount to such intelligent capacity ...|$|R
50|$|Treisman's {{work has}} {{formed the basis}} for {{thousands}} of experiments in <b>cognitive</b> psychology, <b>vision</b> sciences, <b>cognitive</b> science, neuropsychology and cognitive neuroscience.|$|R
50|$|Smith's current {{research}} interests include secular art of the Middle Ages and issues involving the <b>cognitive</b> function of <b>vision</b> in medieval theology and art theory.|$|R
40|$|This paper {{considers}} {{arguments for}} {{the necessity of}} embodiment in <b>cognitive</b> <b>vision</b> systems. We begin by delineating the scope of <b>cognitive</b> <b>vision,</b> and follow this by {{a survey of the}} various approaches that can be taken to the realization of artificial <b>cognitive</b> <b>vision</b> systems, focussing on cognitive aspects. These range from the cognitivist symbolic representational paradigm, through connectionist systems and self-organizing dynamical systems, to the enactive cognition paradigm. We then consider various arguments for embodiment, beginning with paradigm-specific cases, and concluding with a paradigm-independent argument for embodied perception and cognition. We explore briefly different forms of embodiment and their relevance to the foregoing viewpoints. We highlight some of the key problems associated with embodied <b>cognitive</b> <b>vision,</b> including the phylogeny/ontogeny trade-off in artificial systems and the developmental limitations imposed by real-time environmental coupling. Finally, we conclude by considering some aspects of natural cognitive systems to see how they can provide insights to help in addressing these problems...|$|E
40|$|International audienceExtracting {{automatically}} the semantics from visual data {{is a real}} challenge. We {{describe in}} this paper how recent work in <b>cognitive</b> <b>vision</b> leads to significative results in activity recognition for visualsurveillance and video monitoring. In particular we present work performed {{in the domain of}} video understanding in our PULSAR team at INRIA in Sophia Antipolis. Our main objective is to analyse in real-time video streams captured by static video cameras and to recognize their semantic content. We present a <b>cognitive</b> <b>vision</b> approach mixing 4 D computer vision techniques and activity recognition based on a priori knowledge. Applications in visualsurveillance and healthcare monitoring are shown. We conclude by current issues in <b>cognitive</b> <b>vision</b> for activity recognition...|$|E
40|$|<b>Cognitive</b> <b>Vision</b> {{is a new}} {{sub-area}} {{of computer}} vision that tries to enhance vision with apparently cognitive methods such as learning and reasoning. We want to {{go a step further}} and review ideas from embodied AI and situated cognition as well as critiques of traditional computer vision, and propose a set of guidelines that might help to build a new kind of <b>cognitive</b> <b>vision</b> system that could overcome the limitations of contemporary approaches. 1...|$|E
40|$|Participatory {{planning}} experiences {{highlight the}} crucial role of cognitions produced, shared and used throughout participatory processes. The construction of spatial plans {{is more and more}} intended as a socio/political activity producing highly <b>cognitive</b> <b>visions</b> able to guide collective action and make a common good of it. In accordance with the view that a relevant portion of such knowledge is revealed only through action, the article proposes the idea of structuring-scenarios as open entities able to structure action and, consequently, to bridge participatory knowledge to the impetuous practice of action. The article first presents and discusses the role of structuring-scenarios in the work carried out while developing an environmental plan for the delta area of the Po River in Italy. Then it reflects on the main features of content and structure of such scenarios. Finally, the paper analyses the ‘structuring properties’ of these scenarios and their role in structuring action...|$|R
50|$|As of 2016, various {{companies}} are developing coprocessors aimed at accelerating artificial neural networks for <b>vision</b> and other <b>cognitive</b> tasks (e.g. <b>Vision</b> processing units, TrueNorth, and Zeroth).|$|R
50|$|People with {{multiple}} sclerosis {{are at risk}} of falling due to gait disturbances, drop foot, ataxia, reduced proprioception, improper or reduced use of assistive devices, reduced <b>vision,</b> <b>cognitive</b> changes, and medications to treat MS.|$|R
30|$|The {{emerging}} <b>cognitive</b> <b>vision</b> paradigm {{deals with}} vision systems that apply machine learning and automatic reasoning {{in order to}} learn from what they perceive. <b>Cognitive</b> <b>vision</b> systems can rate the relevance and consistency of newly acquired knowledge, they can adapt to their environment and thus will exhibit high robustness. This contribution presents vision systems that aim at flexibility and robustness. One is tailored for content-based image retrieval, the others are <b>cognitive</b> <b>vision</b> systems that constitute prototypes of visual active memories which evaluate, gather, and integrate contextual knowledge for visual analysis. All three systems are designed to interact with human users. After we will have discussed adaptive content-based image retrieval and object and action recognition in an office environment, the issue of assessing cognitive systems will be raised. Experiences from psychologically evaluated human-machine interactions will be reported and the promising potential of psychologically-based usability experiments will be stressed.|$|E
40|$|The textual {{description}} of video sequences exploits conceptual {{knowledge about the}} behavior of depicted agents. An explicit representation of such behavioral knowledge facilitates not only the {{textual description}} of video evaluation results, but {{can also be used}} for the inverse task of generating synthetic image sequences from textual descriptions of dynamic scenes. Moreover, it is shown here that the behavioral knowledge representation within a <b>cognitive</b> <b>vision</b> system can be exploited even for prediction of movements of visible agents, thereby improving the overall performance of a <b>cognitive</b> <b>vision</b> system...|$|E
40|$|We {{present a}} novel {{representation}} of visual information, based on local symbolic descriptors {{that we call}} visual primitives. These primitives: (1) combine different visual modalities, (2) associate semantic to local scene information, and (3) reduce the bandwidth while increasing the predictability of the information exchanged across the system. This representation leads {{to the concept of}} Early <b>Cognitive</b> <b>Vision,</b> that we define as an intermediate level between dense, signal based Early Vision and high level <b>Cognitive</b> <b>Vision.</b> The framework’s potential is demonstrated in several applications, in particular in the area of robotics and humanoid robotics, which are briefly outlined...|$|E
40|$|In {{this paper}} {{we present a}} model of the interplay between learning, {{incentives}} and the allocation of decision rights {{in the context of a}} generalized agency problem. Within this context, not only actors face conflicting interests but diverging <b>cognitive</b> ?<b>visions?</b> of the right course of action as well. We show that a principal may obtain the implementation of desired organizational policies by means of appropriate incentives or by means of appropriate design of the allocation of decisions, when the latter is cheaper but more complex. We also show that when the principal is uncertain about which course of action is more appropriate and wants to learn it from the environment, organizational structure and incentives interact in non-trivial ways and must be carefully tuned. When learning is not at stake, incentives and organizational structure are substitutes. When instead learning is at stake, organizational structure and incentives may complement each other and have to be fine tuned according to the complexity of the learning process and the competitive pressure which is put on fast or slow learning. Incentives, Organizational Structure, Learning...|$|R
5000|$|Fei-Fei {{works on}} {{computer}} <b>vision,</b> <b>cognitive</b> neuroscience and computational neuroscience, and Big Data analysis. She has authored more than 100 scientific articles. Her work appears {{in computer science}} and neuroscience journals including Nature,Proceedings of the National Academy of Sciences, ...|$|R
40|$|Treball de Final de Màster Universitari en Professor/a d'Educació Secundària Obligatòria i Batxillerat, Formació Professional i Ensenyaments d'Idiomes. Codi: SAP 419. Curs acadèmic 2015 - 2016 Teaching prepositions {{is one of}} {{the most}} {{difficult}} issues in the language teaching field. I have conducted a study based on learning the most common prepositions in, at, on at Escola Oficial d’Idiomes from Castelló. First the students were offered a pre-test where they had to answer initial questions about how they study prepositions. Many of them said they study prepositions through learning by heart, studying expressions and phrasal verbs, uses of time and place, using the context and doing exercises, by reading or watching TV, etc. The main purpose of this Master Thesis is to provide another approach in order to learn prepositions taking other premises such as topological, force-dynamics, and functional sets of senses, plus a combination of them into consideration and focusing on semantic and cognitive views. The final results have shown that the students have learnt semantic and <b>cognitive</b> <b>visions</b> of in, at and on. They have improved and revised their use of English and have discovered a new learning methodology they were unaware of...|$|R
40|$|Owing to {{the ever}} growing {{complexity}} of present day computer vision systems, system architecture {{has become an}} emerging topic in vision research. Systems that integrate numerous modules and algorithms of different I/O and time scale behavior require sound and reliable concepts for interprocess communication. Consequently, topics and methods known from software and systems engineering are becoming increasingly important. Especially framework technologies for system integration are required. This contribution results from a cooperation between two multinational projects on <b>cognitive</b> <b>vision.</b> It discusses functional and non-functional requirements in <b>cognitive</b> <b>vision</b> and compares and assesses existing solutions. 1. Motivatio...|$|E
40|$|The {{emerging}} <b>cognitive</b> <b>vision</b> {{paradigm is}} concerned with vision systems that evaluate, gather and integrate con- textual knowledge for visual analysis. In reasoning about events and structures, <b>cognitive</b> <b>vision</b> systems should rely on multiple computations in order to perform robustly even in noisy domains. Action recognition in an unconstrained office environment thus provides an excellent testbed for re- search on cognitive computer vision. In this contribution, we present a system that consists of several computational modules for object and action recognition. It applies atten- tion mechanisms, visual learning and contextual as well as probabilistic reasoning to fuse individual results and verify their consistency. Database technologies are used for infor- mation storage and an XML based communication frame- work integrates all modules into a consistent architecture...|$|E
40|$|This paper {{presents}} a generic <b>cognitive</b> <b>vision</b> {{platform for the}} automatic recognition of natural complex objects. The recognition consists of three steps : image processing for numerical object description, mapping of numerical data into symbolic data and semantic interpretation for object recognition. The focus {{of this paper is}} the distributed platform architecture composed of three highly specialized Knowledge Based Systems (KBS). The first KBS is dedicated to semantic interpretation. The second one has to deal with the anchoring of symbolic data into image data. The last KBS is dedicated to intelligent image processing. After a brief overview of the natural object recognition problem, this paper describes the three subcomponents of the platform. Keywords : <b>Cognitive</b> <b>Vision,</b> Natural Object Recognition, Knowledge Based System 1...|$|E
40|$|Vision dominates {{philosophical}} theorizing about perception, experience, and the mind. The {{psychology and}} <b>cognitive</b> science of <b>vision</b> have captivated philosophers, and other modalities of sensation and perception have received little consideration. Increasingly, however, philosophers recognize the drawbacks of this unbalanced approach, and interest recently has grown i...|$|R
40|$|Studies {{show that}} {{approximately}} 20 – 30 % of diabetes medication is not taken as recommended {{and this is}} associated with higher healthcare costs. The rate of disability due to diabetes complications is also increasing as many people with diabetes are living longer. These disabilities, which include <b>cognitive</b> decline, <b>vision</b> loss and impaired dexterity, can impact on a person’s ability to self-manage their diabetes. This article outlines some of these disabilities and discusses the role of insulin delivery devices on adherence, {{and the need for}} research involving these devices to include people with disabilities...|$|R
40|$|The ongoing {{discussion}} whether modern vision {{systems have}} {{to be viewed as}} visually-enabled cognitive systems or cognitively-enabled vision systems is groundless, because perceptual and <b>cognitive</b> faculties of <b>vision</b> are separate components of human (and consequently, artificial) information processing system modeling. Comment: To be published as chapter 5 in "Frontiers in Brain, Vision and AI", I-TECH Publisher, Viena, 200...|$|R
40|$|Robotic {{systems that}} {{interact}} with changing and unknown environments and humans need to possess dependability higher than current vision systems alone can provide. Most autonomous robots therefore fuse vision system with laser-sensors or ultrasonic-sensors. Within the <b>Cognitive</b> <b>Vision</b> Project ActIPret, we experiment with a pure vision controlled stationar...|$|E
40|$|Language {{for use in}} <b>Cognitive</b> <b>Vision,</b> {{to enable}} {{separate}} research groups to collaborate with each other as well as making their research results more available {{to other areas of}} science and industry, without having to reveal any proprietary ideas, algorithms or even software. The Computer Vision Markup Language can communicate any type and amount of information, making unavailable functionality accessible to anyone. In this paper we introduce the language and describe how we have implemented it in a very large <b>cognitive</b> <b>vision</b> project. We provide a free open source library for working with this language, which can easily be implemented into existing code providing seamless network communication abilities and multi-platform support. Last we describe the future of CVML and how it might evolve to include other areas of research...|$|E
40|$|We are {{entering}} {{an era of}} more intelligent <b>cognitive</b> <b>vision</b> systems. Such systems can analyse activity in dynamic scenes to compute conceptual descriptions from motion trajectories of moving people and the objects they interact with. Here we review progress {{in the development of}} flexible, generative models that can explain visual input as a combination of hidden variables and can adapt to new types of input. Such models are particularly appropriate for the tasks posed by <b>cognitive</b> <b>vision</b> as they incorporate learning as well as having sufficient structure to represent a general class of problems. In addition, generative models explain all aspects of the input rather than attempting to ignore irrelevant sources of variation as in exemplar-based learning. Applications of these models in visual interaction for education, smart rooms and cars, as well as surveillance systems is also briefly reviewed...|$|E
40|$|We {{investigated}} the hazard perception ability of older drivers. A sample of 118 older drivers (65 years and older) completed a video-based hazard perception test and an assessment battery {{designed to measure}} aspects of <b>cognitive</b> ability, <b>vision,</b> and simple reaction time that might plausibly be linked to hazard perception ability. We found that hazard perception response times increased significantly with age but that this age-related increase could {{be accounted for by}} measures of contrast sensitivity and useful field (of view. We found that contrast sensitivity, useful field of view, and simple reaction time could account for the variance in hazard perception, independent of one another and of individual differences in age...|$|R
40|$|The article {{deals with}} the {{mechanisms}} of metabolism of linoleic and α- linoleic polyunsaturated fatty acids as precursors of long-chain polyunsaturated fatty acids — arachidonic (ω- 6 family) and docosahexaenoic acid (ω- 3 famyli). The authors demonstrate the results of modern experimental and clinical trials, studying their influence on <b>cognitive</b> development and <b>vision</b> keenness in animals, preterm and term infants. </em...|$|R
50|$|The {{faculty and}} {{students}} of the School conduct a variety of research in areas including <b>Cognitive</b> science, Computer <b>vision,</b> Human-computer interaction, Learning sciences, Machine learning, and Robotics. A common theme across research is an emphasis on interactive computing, which is an increasingly recognized term for describing a class of research problems that sit {{at the intersection of}} computing and the human environment.|$|R
40|$|We are {{interested}} in methods for building more intelligent <b>cognitive</b> <b>vision</b> systems in our ActIPret project. The aim of this project is understanding the activities of expert operators for teaching and education. Our approach is to learn models for the components and later the task and context of the visual processing in the ActIPret system. The paper first introduces general issues and some approaches for the example of gesture learning and recognition. Second, aspects of our <b>cognitive</b> <b>vision</b> framework are described as they {{are relevant to the}} evaluation of the two approaches tested here. Third, the computational models for the time delay RBF (TDRBF) network and Hidden Markov Model (HMM) are described and results given. Finally, extensions of this work and conclusions for system integration of the results are discussed in the light of task-based control and contextual processing...|$|E
40|$|International audienceAdvanced seismic {{interpretation}} most commonly rests on transforming original data representations by considering {{more or less}} numerous seismic attributes, which bear no explicit relation with geology. For this reason, they hardly allow fully solving problems such as reassembling sparse geological surface elements or specifying chronological or topological relationships between surfaces such as unconformity, on lap, interruption by fault. The present work intends to make further progress in geology-based interpretation of seismic data by using artificial intelligence tools based on <b>cognitive</b> <b>vision.</b> We propose a <b>cognitive</b> <b>vision</b> workflow for {{seismic interpretation}} based on a visual ontology and on three associated module dealing for data management, visual characterisation and geological correlation. An example of results is given showing the possibilities of the method for easily merging disconnected reflectors within one stratigraphical horizon taking into account simple geological criteria (amplitude, thickness, dip, vertical distance between reflectors) ...|$|E
40|$|In {{recent years}} {{there has been}} {{increasing}} interest in constructing <b>cognitive</b> <b>vision</b> systems capable of interpreting the high level semantics of dynamic scenes. Purely quantitative approaches to the task of constructing such systems have met with some success. However, qualitative analysis of dynamic scenes has the advantage of allowing easier generalisation of classes of different behaviours and guarding against the propagation of errors caused by uncertainty and noise in the quantitative data. Our aim is to integrate quantitative and qualitative modes of representation and reasoning for the analysis of dynamic scenes. In particular, in this paper we outline an approach for constructing <b>cognitive</b> <b>vision</b> systems using qualitative spatial-temporal representations including prototypical spatial relations and spatio-temporal event descriptors automatically inferred from input data. The overall architecture relies on abduction: the system searches for explanations, phrased in terms of the learned spatio-temporal event descriptors, to account for the video data...|$|E
40|$|I {{propose the}} {{following}} {{reflections on the}} major issues that have been discussedin previous sessions of this workshop based on my professional and personalinterests in epistemology, <b>cognitive</b> psychology and <b>vision</b> science. I also hopethat my modest final contribution to this Workshop will open a window tointerdisciplinarity, to the psycho-bio-physical unity of knowledge, and to itsfoundation on the radical ontological unity of the universe. [ [...] . ...|$|R
30|$|Cognitive {{networking}}. Cognitive networking broadly encompasses {{models of}} cognition and learning {{that have been}} defined for CRs while emphasizing an end-to-end network-wide scope. Such cognitive networks can perceive current conditions to plan, decide, and act while catering to the overall network’s end-to-end goals[64, 142]. Figure 4 serves to illustrate the <b>vision</b> of <b>cognitive</b> networks. To help CRNs become cognitive networks (CN), {{it is imperative that}} intelligence be integrated into the fabric of CRN architecture and protocols across the stack. The <b>cognitive</b> networking <b>vision</b> foresees an intelligent network capable of setting itself up given high-level instructions and which can continually adapt and manage itself according to changing environmental conditions to optimize network-wide performance metrics.|$|R
50|$|Gregory K. Beale (born 1949 in Dallas, Texas) (also {{known as}} G. K. Beale) is a biblical scholar, {{currently}} a Professor of New Testament and Biblical Theology at Westminster Theological Seminary. He is an ordained {{minister in the}} Orthodox Presbyterian Church. He has {{made a number of}} contributions to conservative Biblical hermeneutics, particularly {{in the area of the}} use of the Old Testament in the New Testament. He served as the president of the Evangelical Theological Society in 2004. In 2013, he was elected by Westminster Theological Seminary to be the first occupant of the J. Gresham Machen Chair of New Testament. At his inauguration he delivered an address titled The <b>Cognitive</b> Peripheral <b>Vision</b> of Biblical Writers.|$|R
