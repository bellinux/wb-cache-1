11|0|Public
5000|$|Reviews are {{mentioned}} by English sinologist and translator David E. Pollard, [...] "Lin Yutang {{is his own}} worst enemy: one can visualize the hackles of reviewers everywhere rising both at his claims, which are mostly phony, and his denials, which are often untrue." [...] (1973: 786). After criticizing faults in Lin Yutang's dictionary, one reviewer gave a balanced conclusion, [...] "the mistakes and omissions are far outweighed by his index system even with its kinks, and by his typable, indexable, <b>computerizable</b> romanization system, his generally excellent English translations, and his comprehensive and up-to-date entries." [...] (Ching 1975: 524).|$|E
30|$|The first {{integral}} {{method was}} employed successfully to solve some important nonlinear partial differential equations, including the double sine-Gordon and Burgers equations, analytically. Some exact solutions for these equations were formally obtained {{by applying the}} first integral method. Due to the good performance of the first integral method, we {{feel that it is}} a powerful technique in handling a wide variety of nonlinear partial differential equations. Also, this method is <b>computerizable,</b> which permits us to accomplish difficult and tiresome algebraic calculations on a computer with ease.|$|E
40|$|Summary. Researchers often seek robust {{inference}} for a parameter through semiparametric estimation. Efficient semipara-metric estimation currently requires theoretical derivation of {{the efficient}} influence function (EIF), {{which can be}} a challenging and time-consuming task. If this task can be computerized, it can save dramatic human effort, which can be transferred, for example, to the design of new studies. Although the EIF is, in principle, a derivative, simple numerical differentiation to calculate the EIF by a computer masks the EIF’s functional dependence on the parameter of interest. For this reason, the standard approach to obtaining the EIF relies on the theoretical construction of the space of scores under all possible parametric submodels. This process currently depends on the correctness of conjectures about these spaces, and the correct verification of such conjectures. The correct guessing of such conjectures, though successful in some problems, is a nondeduc-tive process, i. e., is not guaranteed to succeed (e. g., is not <b>computerizable),</b> and the verification of conjectures is generally susceptible to mistakes. We propose a method that can deductively produce semiparametric locally efficient estimators. The proposed method is <b>computerizable,</b> meaning that it does not need either conjecturing, or otherwise theoretically deriving the functional form of the EIF, and is guaranteed to produce the desired estimates even for complex parameters. The method is demonstrated through an example...|$|E
40|$|There exist many {{situations}} where an ordinary differential equation admits a movable critical singularity which {{the test of}} Kowalevski and Gambier fails to detect. Some possible reasons are: existence of negative Fuchs indices, insufficient number of Fuchs indices, multiple family, absence of an algebraic leading order. Mainly giving examples, we present the methods which answer all these questions. They are all based on the theorem of perturbations of Poincaré and <b>computerizable.</b> Comment: 11 pages, no figure, standard Latex, {{to appear in the}} proceedings of "Nonlinear dynamics: integrability and chaos", Tiruchirapalli, 12 [...] 16 Feb 1998, ed. S. Danie...|$|E
40|$|EmotionsOnto is {{a generic}} {{ontology}} for describing emotions and their detection and expression systems taking contextual and multimodal elements into account. The ontology is proposed {{as a way}} to develop an easily <b>computerizable</b> and flexible formal model. Moreover, {{it is based on the}} Web Ontology Language (OWL) standard, which also makes ontologies easily shareable and extensible. Once formalized as an ontology, the knowledge about emotions can be used in order to make computers more personalised and adapted to users' needs. The ontology has been validated and evaluated by means of an applications based on a emotions-aware Tangible User Interface (TUI). The TUI is guided by emotion knowledge previously gathered using the same TUI and modelled using EmotionsOnto...|$|E
40|$|Whether integrable, {{partially}} integrable or nonintegrable, nonlinear partial {{differential equations}} (PDEs) {{can be handled}} from scratch with essentially the same toolbox, when one looks for analytic solutions in closed form. The basic tool is the appropriate use of the singularities of the solutions, and {{this can be done}} without knowing these solutions in advance. Since the elaboration of the singular manifold method by Weiss et al., many improvements have been made. After some basic recalls, we give an interpretation of the method allowing us to understand why and how it works. Next, we present {{the state of the art}} of this powerful technique, trying as much as possible to make it a (<b>computerizable)</b> algorithm. Finally, we apply it to various PDEs in 1 + 1 dimensions, mostly taken from physics, some of them chaotic: sine-Gordon, Boussinesq, Sawada-Kotera, Kaup-Kupershmidt, complex Ginzburg-Landau, Kuramoto-Sivashinsky, etc. Comment: LaTeX, 85 pages, subject index, no figure, to appear in Direct and inverse methods in nonlinear evolution equations, ed. A. Greco (Springer, Berlin). CIME school, Cetraro, 5 [...] 12 September 199...|$|E
40|$|This paper aims at {{constructing}} a two-phase iterative <b>computerizable</b> numerical algorithm for an improved approximation by ‘Modified Lupas’operator. The algorithm uses the ‘statistical perspectives’ for exploiting {{the information about}} the unknown function ‘f’ available in terms of its known values at the ‘equidistant-knots’ in C[0, 1] more fully. The improvement, achieved by an aposteriori use of this information, happens iteratively. Any typical iteration uses the concepts of ‘Mean Square Error (MSE) ’ and ‘Bias’; the application of the former being preceded by that of the latter in the algorithm. At any iteration, the statistical concept of ‘MSE’ is used in “Phase II”, after that of the ‘Bias’ in “Phase I”. Like a ‘Sandwich’, the top and bottom-breads are the operations of ‘Bias-Reduction’ per the “Phase I” of our algorithm, and the operation of ‘MSEReduction’per the “Phase II” is the stuffing in the sandwich. The algorithm is an iterative one amounting to a desired-height ‘Docked-Pile’ ofsandwiches with the bottom–bread of the first iteration serving as the top-bread for the seconditeration sandwich, and so-on-and-so forth. The potential of the achievable improvements through the proposed ‘computerizable numerical iterative algorithm’ is illustrated per an ‘empirical study’ for which the function ‘f’ is assumed to be known in the sense of simulation. The illustration has been confined to “Three Iterations” only, for the sake of simplicity of the illustration...|$|E
40|$|Several {{indices of}} {{ventilatory}} heterogeneity {{can be identified}} from the expiratory CO 2 partial pressure or CO 2 elimination versus volume curves. The aims of this study were: 1) to analyse several <b>computerizable</b> indices of volumetric capnography in order to detect ventilatory disturbances; and 2) to establish the relationship between those indices and respiratory system mechanics in subjects with normal lungs and in patients with acute respiratory distress syndrome (ARDS), both receiving mechanical ventilation. We studied six normal subjects and five patients with early ARDS mechanically ventilated at three levels of tidal volume (VT). Respiratory system mechanics were assessed by end-expiratory and end-inspiratory occlusion methods, respectively. We determined Phase III slopes, Fletcher's efficiency index, Bohr's dead space (VD,Bohr/VT), and the ratio of alveolar ejection volume to tidal volume (VAE/VT) from expiratory capnograms, {{as a function of}} expired volume. Differences between normal subjects and ARDS patients were significant both for capnographic and mechanical parameters. Changes in VT significantly altered capnographic indices in normal subjects, but failed to change ventilatory mechanics and VAE/VT in ARDS patients. After adjusting for breathing pattern, VAE/VT exhibited the best correlation with the mechanical parameters. In conclusion, volumetric capnography, and, specifically, the ratio of alveolar ejection volume to tidal volume allows evaluation and monitoring of ventilatory disturbances in patients with adult respiratory distress syndrome...|$|E
40|$|The precoat {{filtration}} with body-feed is an {{unit operation}} of agricultural and food engineering. Mostly {{it is implemented}} by using centrifugal pump, which pump curve has a partial horizontal trend. Classically, in filtration theory, this prerogative of the centrifugal pumps leads to the simplifying assumption that filtration occurs with constant pressure. Because of this, {{it is easy to}} integrate the Darcy’s differential equation [1, 2 and 3] for the precoat filtration with body-feed, obtaining the well known Carman equation [4]. This is the equation which relates the filtration time with the filtrate volume, the operating pressure, the filter area, and the solid-liquid suspension characteristics. The Carman equation is the start point for the subsequent optimization of the filtration cycles, e. g. by establishing the relationship between the filtration time and the filter cleaning time [5]. A better optimization of the precoat filtration with body-feed could be obtain, with some economic benefits, if an integration of the Darcy ODE was developed starting from actual trend of the pressure produced by the centrifugal pump, that is if a variable pressure was considered, as expected from the pump curve. In this sense a proposal was done by Tiller and Crump [6] many years ago in accordance with a graphic method of integration of the Darcy ODE. However the graphic procedure is tedious since it is iterative and not <b>computerizable.</b> For this reason the aim of this work was to find an analytical solution to the Darcy ODE for the filtration with variable pressure in order to obtain a quick and easy-to-use equation for the subsequent optimization calculations of filtration cycles, even if more complex of the Carman equation...|$|E
40|$|Background: Consortia of microorganisms, {{commonly}} known as biofilms, are attracting much attention from the scientific community due to their impact in human activity. As biofilm research grows to be a data-intensive discipline, the need for suitable bioinformatics approaches becomes compelling to manage and validate individual experiments, and also execute inter-laboratory large-scale comparisons. However, biofilm data is widespread across ad hoc, non-standardized individual files and, thus, data interchange among researchers, or any attempt of cross-laboratory experimentation or analysis, is hardly possible or even attempted. Methodology/Principal findings This paper presents BiofOmics, the first publicly accessible Web platform specialized in the management and analysis of data derived from biofilm high-throughput studies. The aim is to promote data interchange across laboratories, implementing collaborative experiments, and enable the development of bioinformatics tools {{in support of the}} processing and analysis of the increasing volumes of experimental biofilm data that are being generated. BiofOmics data deposition facility enforces data structuring and standardization, supported by controlled vocabulary. Researchers are responsible for the description of the experiments, their results and conclusions. BiofOmics curators interact with submitters only to enforce data structuring and the use of controlled vocabulary. Then, BiofOmics search facility makes publicly available the profile and data associated with a submitted study so that any researcher can profit from these standardization efforts to compare similar studies, generate new hypotheses to be tested or even extend the conditions experimented in the study. Significance BiofOmics novelty lays on its support to standardized data deposition, the availability of <b>computerizable</b> data files and the free-of-charge dissemination of biofilm studies across the community. Hopefully, this will open promising research possibilities, namely: the comparison of results between different laboratories, the reproducibility of methods within and between laboratories, and the development of guidelines and standardized protocols for biofilm formation devices and analytical methods. The financial support from the Institute of Biotechnology and Bioengineering - Center of Biological Engineering (IBB-CEB), Fundacao para a Ciencia e Tecnologia (FCT) and European Community fund FEDER (Program COMPETE), project PTDC/SAU-ESA/ 646091 / 2006 /FCOMP- 01 - 0124 -FEDER- 007480 and PhD grant of Idalina Machado (SFRH/BD/ 31065 / 2006) are gratefully acknowledged. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript...|$|E

