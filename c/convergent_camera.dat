9|8|Public
40|$|This {{dissertation}} {{describes the}} research and development of some techniques to enhance the disparity compensation in 3 D video compression algorithms. Disparity compensation is usually performed using a block matching technique between views, disregarding the various levels of disparity present for objects at different depths in the scene. An alternative coding scheme is proposed, taking advantage of the cameras setup information and the object’s depth in the scene, to compensate more complex spatial distortions, being able to improve disparity compensation even with convergent cameras. In order to perform a more accurate disparity compensation, the reference picture list is enriched with additional geometrically transformed images, for the most relevant object’s levels of depth in the scene, resulting from projections of one view to another. This scheme can be implemented in any state-of-the-art video codec, as H. 264 /AVC or HEVC, in order to improve the disparity matching accuracy between views. Experimental results, using MV-HEVC extension, show the efficiency of the proposed method for coding stereo video, presenting bitrate savings up to 2. 87 %, for <b>convergent</b> <b>camera</b> sequences, and 1. 52 % for parallel camera sequences. Also a method to choose the geometrically transformed inter view reference pictures was developed, in order to reduce unnecessary overhead for unused reference pictures. By selecting and adding to the reference picture list, only the most useful pictures, all results improved, presenting bitrate savings up to 3. 06 % for <b>convergent</b> <b>camera</b> sequences, and 2 % for parallel camera sequences...|$|E
40|$|A high {{precision}} and easy-to-use CCD camera calibration technique for industrial vision metrology is discussed. A well-known method is self-calibration by <b>convergent</b> <b>camera</b> configuration of a two- or three-dimensional target field. Only with this technique {{the central part}} of a sensor area is precisely calibrated, but off the centre the precision rapidly deteriorates. The presented technique is a simultaneous adjustment of both pan and close exposures, which compensates the lack of distortion data in the fringe area of the sensor and offers both uniform and high-precision calibration. Some patterns of camera configuration are compared in an experiment in terms of the precision and its uniformity over the sensor. And the combination of convergent pan exposures and vertical close exposures is proved the best. 1...|$|E
40|$|Image-based {{rendering}} {{systems are}} designed to render a virtual view of a scene based {{on a set of}} images and correspondences between these images. This approach is attractive as it does not require explicit scene reconstruction. In this paper we identify that the level of realism of the virtual view is dependent on the camera set-up {{and the quality of the}} image analysis and synthesis processes. We explain how wide-baseline <b>convergent</b> <b>camera</b> set-ups and virtual view independent approaches to surface selection have led to the development of very system specific solutions. We then introduce a unique scalable and modular system solution. This scalable system is configured using building blocks defined as SCABs. These provide design flexibility and improve the image analysis process. Virtual view creation is modular in such that we can add or remove SCABs based on our particular requirements without having to modify the view synthesis algorithm...|$|E
40|$|Abstract: This paper {{presents}} new low-cost {{systems for}} the automation of some fish farm operations. Particularly, computer vision is applied to noncontact fish weight estimation. Stereo vision systems with synchronised <b>convergent</b> <b>cameras</b> are employed to perform fish 3 -D segmentation in tanks and sea cages. Several pre-processing algorithms are applied to compensate illumination local variations. The approach applied for fish 3 -D segmentation consists in detecting in both images certain fish features. Once these points have been detected and validated in both images, the fish are 3 -D segmented by applying stereo vision matching considerations. Fish weight is estimated by using simple length-weight relations {{well known in the}} aquaculture domain. The paper also presents a robotic system for fish feeding and an underwater robot for autonomous pond cleaning...|$|R
40|$|The paper {{presents}} some {{improvements to}} {{a novel approach}} for the determination of 3 -D flow velocity fields, {{which is based on}} 3 -D particle tracking in a tomographic reconstruction of an observation volume seeded with tracer particles. The basic idea of the approach is using multiple camera views for a full tomographic reconstruction of the object space, which is represented by a 3 -D voxel structure with a resolution adapted to the camera resolution. Based on the images of four or more <b>convergent</b> <b>cameras</b> with their orientation known from a prior calibration procedure, a complete 3 -D light intensity distribution in the observation volume can be reconstructed by a projective transformation of each camera image contents into each depth layer of the object space and a consecutive minimum search. 3 -D velocity field information can then be obtained by volume-based tracking in time-resolved voxel space representations. This procedure represents a rather elegant way of completely avoiding detection and matching ambiguities, thus allowing for a significant increase of the spatial resolution of 3 -D particle tracking. The paper will show the basic concept of tomographic reconstruction and tracking in 3 D-PTV and show some first results from processing synthetic data sets. The computational effort, accuracy and spatial resolution potential of the technique will be compared to conventional 3 -D particle tracking velocimetry. 1...|$|R
40|$|To {{effectively}} encode data-intensive, multi-view imaging content, H. 264 /AVC as {{a state-of-the-art}} coding standard is often adopted for its superior coding efficiency. However, an H. 264 encoder is very complex {{because of the}} many advanced but computationally complicated schemes it employs in achieving a high-coding performance. The most time-consuming component is variable block-size motion estimation (ME). A ME technique is proposed in this paper to accelerate the encoding by employing {{what is known as}} epipolar geometry, which provides constraints for multiview image sequences. Theoretical analyses and experimental results prove that the proposed ME’s use of epipolar geometry can greatly reduce a search region and effectively track large and irregular motion, typical for <b>convergent</b> multi-view <b>camera</b> setups. As a result, compared with fast full search at large search size adopted in H. 264, our proposed ME algorithm can obtain a similar coding efficiency while achieving a speedup ratio of 2. 1...|$|R
40|$|The {{proposed}} {{approach is}} motivated by applications which allow user navigation and individual viewpoint specification in shared virtual environments with telepresence quality. In this context, we present a synthesis method for arbitrary virtual views in a multi-view camera set-up. This method generates a close to realtime, view adaptable reconstruction of a 3 dimensional, (3 D), object taken from at least two cameras. In this method, we use the recently developed Incomplete 3 D, (IC 3 D), technique, a disparity-based multiview representation for a weakly <b>convergent</b> <b>camera</b> setup {{in combination with the}} trilinear warping functions to describe new virtual camera positions. Previously, only virtual views inside the baseline could be described by IC 3 D. Hence, user movement in virtual environments (VE) was restricted. In order to create a virtual camera position and orientation outside the baseline we apply point correspondences across the two reference images to a trilinear tensor, built from the fundamental matrix between the reference views. The trilinearities provide a general warping function from the reference images to virtual view that is governed directly by the virtual camera parameters. ...|$|E
40|$|This journal {{article was}} {{published}} in the journal, The Photogrammetric Record [Remote Sensing and Photogrammetry Society and Blackwell Publishing Ltd / © The authors] and is available at: [URL] internal geometry of consumer grade digital cameras is generally considered unstable. Research conducted recently at Loughborough University indicated the potential of these sensors to maintain their internal geometry. It also identified residual systematic error surfaces or “domes”, discernible in digital elevation models (DEMs) (Wackrow et al., 2007), caused by slightly inaccurate estimated lens distortion parameters. This paper investigates these systematic error surfaces and establishes a methodology to minimise them. Initially, simulated data were used to ascertain the effect of changing the interior orientation parameters on extracted DEMs, specifically the lens model. Presented results demonstrate the relationship between “domes” and inaccurately specified lens distortion parameters. The stereopair remains important for data extraction in photogrammetry, often using automated DEM extraction software. The photogrammetric normal case is widely used, in which the camera base is parallel to the object plane and the optical axes of the cameras intersect the object plane orthogonally. During simulation, the error surfaces derived from extracted DEMs using the normal case, were compared with error surfaces created using a mildly convergent geometry. In contrast to the normal case, the optical camera axes intersect the object plane at the same point. Results of the simulation process clearly demonstrate that a mildly <b>convergent</b> <b>camera</b> configuration eradicates the systematic error surfaces. This result was confirmed through practical tests and demonstrates that mildly convergent imagery effectively improves the accuracies of DEMs derived with this class of sensor...|$|E
40|$|Real-time stereo {{analysis}} {{is an important}} research area in computer vision. In this context, we propose a stereo algorithm for an immersive video-conferencing system by which conferees at different geographical places can meet under similar conditions as in the real world. For this purpose, virtual views of the remote conferees are generated and adapted to the current viewpoint of the local participant. Dense vector fields of high accuracy are {{required in order to}} guarantee an adequate quality of the virtual views. Due to the usage of a wide baseline system with strongly <b>convergent</b> <b>camera</b> configurations, the dynamic disparity range is about 150 pixels. Considering computational costs, a full search or even a local search restricted to a small window of a few pixels, as it is implemented in many real-time algorithms, is not suitable for our application because processing on full-resolution video according to CCIR 601 TV standard with 25 frames per second is addressed-the most desirable as a pure software solution running on available processors without any support from dedicated hardware. Therefore, we propose in this paper a new fast algorithm for {{stereo analysis}}, which circumvents the window search by using a hybrid recursive matching strategy based on the effective selection of a small number of candidates. However, stereo analysis requires more than a straightforward application of stereo matching. The crucial problem is to produce accurate stereo correspondences {{in all parts of the}} image. Especially, errors in occluded regions and homogenous or less structured regions lead to disturbing artifacts in the synthesized virtual views. To cope with this problem, mismatches have to be detected and substituted by a sophisticated interpolation and extrapolation scheme...|$|E
40|$|In {{this paper}} a new multi-view/ 3 D human action/interaction {{database}} is presented. The database {{has been created}} using a <b>convergent</b> eight <b>camera</b> setup to produce high definition multi-view videos, where each video depicts one of eight persons performing one of twelve different human motions. Various types of motions have been recorded, i. e., scenes where one person performs a specific movement, scenes where a person executes different movements in a succession and scenes where two persons interact with each other. Moreover, the subjects have different body sizes, clothing and are of different sex, nationalities, etc [...] The multi-view videos have been further processed to produce a 3 D mesh at each frame describing the respective 3 D human body surface. To increase {{the applicability of the}} database, for each person a multi-view video depicting the person performing sequentially the six basic facial expressions separated by the neutral expression has also been recorded. The database is freely available for research purposes. ...|$|R
40|$|Abstract—Effectively coding {{multiview}} {{visual content}} is an indispensable research topic because multiview image and video that provide greatly enhanced viewing experiences often contain {{huge amounts of}} data. Generally, conventional hybrid predic-tive-coding methodologies are adopted to address the compression by exploiting the temporal and interviewpoint redundancy ex-isting in a multiview image or video sequences. However, their key yet time-consuming component, motion estimation (ME), is usually not efficient in interviewpoint prediction or disparity estimation (DE), because interviewpoint disparity is completely different from temporal motion existing in the conventional video. Targeting a generic fast DE framework for interviewpoint prediction, we propose a novel DE technique in this paper to accelerate the disparity search by employing epipolar geom-etry. Theoretical analysis, optimal disparity vector distribution histograms, and experimental {{results show that the}} proposed epipolar geometry-based DE can greatly reduce search region and effectively track large and irregular disparity, which is typical in <b>convergent</b> multiview <b>camera</b> setups. Compared with the existing state-of-the-art fast ME approaches, our proposed DE can obtain a similar coding efficiency while achieving a significant speedup for interviewpoint prediction and coding. Moreover, a robustness study shows that the proposed DE algorithm is insensitive to the epipolar geometry estimation noise. Hence, its wide application for multiview image and video coding is promising. Index Terms—Disparity estimation (DE), epipolar geometry, fast motion estimation (ME), H. 264 /AVC, multiview image, multiview image compression, multiview video, multiview video compression, video coding. I...|$|R
40|$|Today many photogrammetric works {{involved}} {{the use of}} digital cameras due to it's in low cost. Digital camera {{has been used in}} many photogrammetric applications such as archaeology, architecture, accident investigation, cultural heritage and etc. Theoretically, most digital camera is known as non-metric camera where the interior geometrical of digital camera is not stable, however, the optical quality is not acceptable. The need for camera calibration has been fundamental requirement for obtaining accurate measurement since the inception of photogrammetry. This study deals with the acquisition and processing of different configuration of digital <b>camera</b> (<b>convergent</b> and generic network) which are position at different height versus different digital camera setup. The accuracy assessment was performed for two high resolution digital cameras which are Nikon D 90 and Rollei D 30 metric 5 digital cameras. The height of digital camera is setup at approximately 80 cm and 100 cm. Finally, this study evaluates the accuracy of the camera calibration based on standard deviation of interior camera calibration parameters. This study shows that high resolution Nikon D 90 digital camera which is categorized as low cost could be used in photogrammetric application with good accuracy achievable...|$|R
40|$|Area-based {{least squares}} {{matching}} has existed since the 1980 s, and its development may therefore be regarded by some photogrammetrists as complete. However, {{this is a}} relatively short time in a rapidly changing discipline, and the method does have scope for further refinement. This paper aims to enhance the fidelity of the fundamental mathematical model, which relates pixel positions in area-based matching. If successful, its benefit is seen to lie within close-range photogrammetry, in which object undulations, <b>convergent</b> <b>camera</b> directions and large image scales can introduce significant levels of perspective distortion. It is hypothesised that a model, which takes into account the surface shape within the match window, would provide a pixel position relationship which is applicable across larger windows than those which are applicable with the conventional matching model, based on an affine transformation. The use of larger windows for the image matching increases the redundancy. Revised co-ordinate transformations, based on mathematical surface models across the windows, are proposed in this paper. When tested on the measurement of real objects, even simple surface models are found to increase the complexity of the matching mathematics, but when compared with the traditional affine transformation solution using three test objects, precision improved noticeably. Generally, accuracy also improved, but the improvements were not as distinct as they were for precision. Quicker convergence with fewer iterations was usually obtained, and this is seen as particularly indicative of a more faithful model. Yet more rigorous surface modelling may be worth developing, but the means of choosing the most appropriate models for different objects also remains a question deserving to be pursued...|$|E
40|$|Abstract—Real-time 3 D {{analysis}} {{is an important}} research area in computer vision. In this context we propose a 3 D analysis algorithm for an immersive video conferencing system by which conferees at different geographical places can meet under similar conditions as in real world. For this purpose virtual views of the remote conferees are generated and adapted to the current viewpoint of the local participant. Dense vector fields of high accuracy are {{required in order to}} guarantee an adequate quality of the virtual views. Due to the usage of a wide baseline system with strongly <b>convergent</b> <b>camera</b> configurations the dynamic disparity range is about 150 pixels. Considering computational costs, a full search or even a local search restricted to a small window of a few pixels, as it is implemented in many real-time algorithms, is not suitable for our application because processing on full resolution video according to CCIR 601 TV standard with 25 frames per second is addressed- most desirable as pure software solution running on available processors without any support from dedicated hardware. In this paper we therefore propose a new fast algorithm for 3 D analysis, which circumvents the window search by using a hybrid recursive matching strategy based on the effective selection of a small number of candidates. However, 3 D analysis requires more than a straightforward application of stereo matching. The crucial problem is to produce accurate stereo correspondences {{in all parts of the}} image. Especially, errors in occluded regions and homogenous or less structured regions lead to annoying artefacts in the synthesized virtual views. To cope with this problem mismatches have to be detected and substituted by a sophisticated inter- and extrapolation scheme. Index Terms—disparity analysis, real-time application, segmentation based post-processing, stereo visio...|$|E
40|$|Current {{state of}} the art {{computational}} fluid dynamics (CFD) and in particular, river flow modelling, require accurate estimation of the “free surface” in order to accurately predict the three dimensional flow field along a river. Such models are increasingly important for management of river basins and mitigation of river floods as the incidence of extreme rainfall events increases, causing widespread flooding, disruption and loss of life. To increase the accuracy of such flow models, it has become necessary to calibrate model outputs using field data, demanding improved measurement of the flow field along rivers. A substantial and funded research project being conducted at Loughborough University is developing image based river measurement methods using a combination of Particle Image Velocimetry (PIV) and close range photogrammetry (CRP). This paper will report on the use of digital close range photogrammetry to measure the dynamic topographic water surface exhibited by real and flooding rivers. A pair of Nikon D 80 (10 Mega-pixel) digital cameras have been purchased, each equipped with a variables zoom lens (f: 18 - 70 mm). The two cameras have been synchronized using two cables connected via a single relay operated switch, tests demonstrating that the accuracy of synchronization is better than 100 th of a second. The cameras are mounted on two standard camera tripods, providing convergent and stereoscopic coverage of the river reach, which is between 10 and 20 m distant. In initial tests, conventional photogrammetric control was provided using temporary targeted points, coordinated using a Reflectorless Total Station. Subsequent work is being conducted on a semi-engineered river at Farnborough, in the UK, where fixed targets have been permanently installed and coordinated to be in position necessary for the two year duration of the project. Imagery is being processed using the Leica Photogrammetry System (LPS); commercial software which provides the ability to automatically extract digital elevation models. A key issue is the targeting of the water surface and a variety of seeding particles have been tested. Natural materials are clearly preferred, to avoid polluting the natural riverine environment. Leaves, sawdust, and wood chips have all demonstrated some localised success but suffer because of a basic lack of contrast in the imagery captured. It has always been recognized that white polystyrene chips used for packing and posting delicate objects would resolve such difficulties but are clearly undesirable from an environmental perspective. Fortunately, biodegradable packaging chips are now available and tests demonstrate that LPS can successfully generate DEMs representing the dynamic and flooding water surface. Such material degrades within a few days, less if subjected to the mechanical action associated with a flowing river. This presentation will outline the development and application of the methodology, focusing on the accuracies attainable. Specific tests were developed to assess accuracy using a fixed, horizontal survey staff located just above the water surface. Accuracies of 3 mm were achieved using the Nikon cameras located 11 m away, more than sufficient for the uncertainties associated with the flow modelling. Key issues to be discussed include: synchronization, seeding and significantly, the use of a <b>convergent</b> <b>camera</b> configuration to increase the accuracy of data generated still further. The approach will be used over the next two winter seasons and combined with PIV to parameterise water flow and develop the 3 D computerised flow models further...|$|E
40|$|Today, {{there are}} several low cost softwares that are {{available}} in the market {{that could be used for}} digital close range photogrammetry applications such as for medical photogrammetry. Most softwares could be used to calibrate digital camera or other sensors and produce accurate results. This paper discusses about the experience of calibrating a consumer digital camera using low cost digital close range photogrammetric software. A test field was used to calibrate the digital <b>cameras.</b> <b>Convergent</b> images and retro-reflective targets were employed in the study. The process of photography and processing the photographs were carried out within short period of time. In this study, self-calibrating bundle adjustment embedded in the software was used to recover the camera calibration parameters of the consumer digital camera. Subsequently, the consumer digital camera was used to capture the photographs of human face for medical photogrammetry application. Output of calibrating the digital cameras include exterior orientation parameters, camera calibration parameters and the object space coordinates. The results showed that all the camera calibration parameters could be recovered without any difficulties and could be used to capture photographs or data for medical photogrammetry applications. Also the results from this study suggest that consumer digital camera is potential to be used in many close range photogrammetric applications and when the budget is limited...|$|R
40|$|Although {{the camera}} {{eye of the}} octopus {{is very similar to}} that of humans, phylogenetic and embryological {{analyses}} have suggested that their camera eyes have been acquired independently. It has been known as a typical example of convergent evolution. To study the molecular basis of <b>convergent</b> evolution of <b>camera</b> eyes, we conducted a comparative analysis of gene expression in octopus and human camera eyes. We sequenced 16, 432 ESTs of the octopus eye, leading to 1052 nonredundant genes that have matches in the protein database. Comparing these 1052 genes with 13, 303 already-known ESTs of the human eye, 729 (69. 3 %) genes were commonly expressed between the human and octopus eyes. On the contrary, when we compared octopus eye ESTs with human connective tissue ESTs, the expression similarity was quite low. To trace the evolutionary changes that are potentially responsible for camera eye formation, we also compared octopus-eye ESTs with the completed genome sequences of other organisms. We found that 1019 out of the 1052 genes had already existed at the common ancestor of bilateria, and 875 genes were conserved between humans and octopuses. It suggests that a larger number of conserved genes and their similar gene expression may be responsible for the convergent evolution of the camera eye...|$|R

