27|10000|Public
40|$|In this paper, {{we present}} a path {{dependency}} graph for Verilog-HDL programs called path sequence. This path sequence {{can be used in}} static analysis based techniques, such as program slicing, and model abstraction as well as in functional test generation. We have implemented this graph inside a model reduction tool. It enhanced the <b>capability</b> <b>of</b> <b>the</b> <b>tool</b> without adding significant timing overhead...|$|E
40|$|International audienceThe paper {{describes}} an automated crystal orientation and phase mapping technique that allows nanoscale characterization of crystalline materials with a transmission electron microscope. The template matching strategy {{used to identify}} the diffraction patterns is detailed and the resulting outputs of the technique are illustrated. Some examples of applications are used to demonstrate the <b>capability</b> <b>of</b> <b>the</b> <b>tool</b> and potential developments are discussed...|$|E
40|$|The paper {{presents}} a new measurement method for residual stresses introduced by manufacturing in BEoL structures. Material removal by FIB ion milling {{is used to}} release elastically frozen stresses. Normal stress components are calculated from local stress relaxation nearby milled trenches. A validation of the new technique is accomplished by additional bow measurements on defined layers on substrate. Spatially resolved determination of stress values in metal lines and the dielectrics in between demonstrates the <b>capability</b> <b>of</b> <b>the</b> <b>tool</b> for future applications...|$|E
40|$|We study {{data traffic}} on {{distributed}} shared memory machines and conclude that data placement and grouping improve performance of scientific codes. We present several methods which user can employ to improve data traffic in his code. We {{report on implementation}} of a <b>tool</b> which detects <b>the</b> code fragments causing data congestions and advises user on improvements of data routing in these fragments. <b>The</b> <b>capabilities</b> <b>of</b> <b>the</b> <b>tool</b> include deduction <b>of</b> data alignment and affinity from the source code; detection <b>of</b> <b>the</b> code constructs having abnormally high cache or TLB misses; generation of data placement constructs. We demonstrate <b>the</b> <b>capabilities</b> <b>of</b> <b>the</b> <b>tool</b> on experiments with NAS parallel benchmarks and with a simple computational fluid dynamics application ARC 3 D...|$|R
5000|$|Once all the {{information}} has been received into the Revenue Assurance systems it time to crunch numbers and generate reports. The critical part is <b>the</b> analytical <b>capabilities</b> <b>of</b> <b>the</b> <b>tool.</b> <b>The</b> <b>tool</b> needs {{to have the ability}} to make sense <b>of</b> <b>the</b> problems in <b>the</b> vast set <b>of</b> data that it has gathered. This can only be done by a high performance analytical engine which should be capable <b>of</b> <b>the</b> following activities (non exhaustive): ...|$|R
40|$|GeoTime and nSpace are two {{interactive}} visual analytics <b>tools</b> {{that support}} <b>the</b> process <b>of</b> analyzing massive and complex datasets. <b>The</b> two <b>tools</b> {{were used to}} examine and interpret the 2007 VAST contest dataset. This poster paper describes how <b>the</b> <b>capabilities</b> <b>of</b> <b>the</b> <b>tools</b> were used to facilitate and expedite every stage of an analyst workflow...|$|R
40|$|Compaan is a {{software}} tool capable of automatically translating nested loop programs, written in Matlab, into parallel Kahn process network descriptions suitable for implementation in hardware. In this paper {{we present a}} tool for converting these process networks into FPGA implementations. The QR decomposition algorithm is used to demonstrate the <b>capability</b> <b>of</b> <b>the</b> <b>tool</b> to quickly generate high-performance parallel implementations. This allows us to rapidly explore a range of transformations, such as loop unrolling and skewing, to generate a circuit that meets the requirements of a particular application. We present results showing how the control logic complexity and number of clock cycles vary with these transformations. ...|$|E
40|$|General Purpose {{computing}} on Graphics Processing Unit {{offers a}} remarkable speedup for data parallel workloads, leveraging GPUs computational power. However, differently from graphic computing, it requires highly reliable operation in several application domains. In this paper we present SIFI a reliability evaluation framework for soft-errors on AMD GPUs built {{on top of}} Multi 2 Sim, a micro-architectural level simulator. SIFI is capable of computing different reliability metrics by means of two different techniques: fault injection and ACE analysis. Experiments performed {{on a set of}} 14 GPGPU applications targeting the AMD Southern Islands GPU architecture show the <b>capability</b> <b>of</b> <b>the</b> <b>tool</b> and the potential of its use to support decisions about the best architectural parameters for a given application...|$|E
40|$|The {{evaluation}} and certification of packages for transportation of radioactive materials is performed by analysis, testing, {{or a combination}} of both. Within the last few years, many transport packages that were certified have used a combination of analysis and testing. The ability to combine and display both kinds of data with interactive graphical tools allows a faster and more complete understanding of the response of the package to these environments. Sandia National Laboratories has developed an initial version of a visualization tool that allows the comparison and display of test and of analytical data as part of a Department of Energy-sponsored program to support advanced analytical techniques and test methodologies. The <b>capability</b> <b>of</b> <b>the</b> <b>tool</b> extends to both mechanical (structural) and thermal data...|$|E
40|$|This paper {{describes}} {{dynamic and}} spatial reasoning enhancements to the Graph-Based Interface Language tool (GRBIL), which creates ACT-R models by demonstration. A new ability for users to create monitors enables procedures to be dynamically triggered. A new integration of ACT-R with a diagrammatic reasoning theory allows ACT-R to perform spatial reasoning. <b>Capabilities</b> <b>of</b> <b>the</b> <b>tool</b> are demonstrated in a robotic control task...|$|R
40|$|International audienceIn this paper, a novel {{research}} tool, {{which allows}} real-time implementation {{and evaluation of}} sound synthesis of musical instrument, is described. <b>The</b> <b>tool</b> is a PC-based application and allows the user to evaluate <b>the</b> effects <b>of</b> parameter changes on the sound quality in an intuitive manner. Tuning makes use of a Genetic Algorithm (GA) technique. Flute and plucked string modeling examples are used to illustrate <b>the</b> <b>capabilities</b> <b>of</b> <b>the</b> <b>tool...</b>|$|R
40|$|This paper {{presents}} an analog circuit design assistance <b>tool</b> called Adapt. <b>The</b> <b>tool</b> can perform automatic circuit sizing {{over a wide}} range of heterogeneous design parameters. We present Adapt's architecture and the design flow, discuss important user-interface aspects <b>of</b> <b>the</b> <b>tool,</b> disclose details on the optimization algorithms incorporated in <b>the</b> <b>tool,</b> and demonstrate <b>the</b> practical strength <b>of</b> <b>the</b> <b>tool.</b> <b>The</b> industrial-strength <b>capabilities</b> <b>of</b> <b>the</b> <b>tool</b> are showcased using an RF low-noise amplifier that is used in Bluetooth applications...|$|R
40|$|In {{collaboration}} with the University of Ottawa, a toot has been produced to evaluate the Competitive Intelligence Process exercised by a practitioner/team/corporation. Accepted principles of CI (as determined by extensive literature review and consultation with CI experts) have been incorporated into a survey and used to quantify the process as a whole, as well as break down the process into manageable parts and identify specific areas of strength and/or weakness. Face validation of the tool has been demonstrated through its application on four large firms (a sample of convenience) operating in the telecommunications industry. Analysis of {{strengths and weaknesses of}} the firm's CI process were highlighted and summarized in a concise report. The <b>capability</b> <b>of</b> <b>the</b> <b>tool</b> for industry characterization was demonstrated, as well as the potential for effective benchmarking against best CI practices. Finally, areas of future focus and development have been highlighted...|$|E
30|$|Features {{selection}} and extraction {{can be performed}} using tools, such as NetMate [21] and WEKA [288]. However, in this case, the extraction and selection techniques are limited by the <b>capability</b> <b>of</b> <b>the</b> <b>tool</b> employed. Therefore, often specialized filter, embedded, and wrapper-based methods are employed for feature selection. Filtering prunes out the training data after carefully analyzing the dataset for identifying the irrelevant and redundant features. In contrast, wrapper-based techniques take an iterative approach, using a different subset of features in every iteration to identify the optimal subset. Whereas, embedded methods combine the benefits of filter and wrapper-based methods, and perform feature selection during model creation. Examples of feature selection techniques include, colored traffic activity graphs (TAG) [221], breadth-first search (BFS) [496], L 1 Regularization [259], backward greedy feature selection (BGFS) [137], consistency-based (CON) and correlation-based feature selection (CFS) [321, 476]. It is crucial to carefully select an ideal set of features that strikes a balance between exploiting correlation and reducing/eliminating over-fitting for higher accuracy and lower computational overhead.|$|E
40|$|Compaan is a {{software}} tool that {{is capable of}} automatically translating nested loop programs, written in Matlab, into parallel process network descriptions suitable for implementation in hardware. In this article, we show a methodology and tool to convert these process networks into FPGA implementations. We will show that we can in principle obtain high performing realizations in a fraction of the design time currently employed to realize a parameterized implementation. This allows us to rapidly explore a range of transformations, such as loop unrolling and skewing, to generate a circuit that meets the requirements of a particular application. The QR decomposition algorithm is used to demonstrate the <b>capability</b> <b>of</b> <b>the</b> <b>tool.</b> We present results showing how the number of clock cycles and calculations-persecond vary with these transformations using a simple implementation of the function units. We also provide an indication of what we expect to achieve in the near future once the tools are completed and applied the transformations to parallel, highly pipelined implementations of the function units...|$|E
30|$|According to LORM, {{the process}} starts with <b>the</b> {{determination}} <b>of</b> <b>the</b> instructional needs. Second {{step is to}} search in existing Learning Object Repositories (LOR). Once the related content packages (i.e., LOs) are found, they are extracted using <b>the</b> LO Authoring <b>Tool.</b> Using <b>the</b> authoring <b>capabilities</b> <b>of</b> <b>the</b> <b>tool,</b> <b>the</b> users can integrate their own content {{according to their own}} instructional needs., repurposed, and prepared as a new LO content package. Then, the metadata to define this new content package is entered, and the content is packaged for reuse. In the last phase, the new content can be reused after being transferred to related LMSs and/or other systems as a content package.|$|R
40|$|The paper {{presents}} two visualization {{applications that}} enable to visualize traffic flow simulation results obtained with the TRANSIMS system. The applications, designed and implemented at <b>the</b> Institute <b>of</b> Machines and Motor Vehicles of Poznan University of Technology, {{are written in}} Java and, as freeware, can be used free of charge. Both visualizers use GIS-based data manipulation techniques to provide precise and customizable 2 D visualization. First, <b>the</b> problem <b>of</b> traffic flow modeling and simulation, and the TRANSIMS system were introdu-ced. Then a general design and features of both applications were described. In order to demonstrate <b>the</b> most essential <b>capabilities</b> <b>of</b> <b>the</b> <b>tools,</b> <b>the</b> author presented an example of visualization of traffic in a segment of a real urban network...|$|R
40|$|Abstract. TAPAAL {{is a new}} {{platform}} independent tool for modelling, simulation and verification of timed-arc Petri nets. TAPAAL provides a stand-alone editor and simulator, while the verification module translates timed-arc Petri net models into networks of timed automata and uses the UPPAAL engine for the automatic analysis. We report on <b>the</b> status <b>of</b> <b>the</b> first release <b>of</b> TAPAAL (available at www. tapaal. net), on its new modelling features and we demonstrate the efficiency and modelling <b>capabilities</b> <b>of</b> <b>the</b> <b>tool</b> on a few examples. ...|$|R
40|$|Health Literacy (HL) is {{the degree}} to which {{individuals}} have the capability to obtain, understand and process basic health information needed to make appropriate health decisions. It affects persons' ability to access and use health care, to interact with providers, and to care for themselves. Established literacy screeners have practical limitations (such as practictioner's attendance, time to complete, etc.) : to address these, a short, self-administered measure of HL, the Medical Term Recognition Test (METER) was introduced in USA. In this study an Italian version (IMETER) of this measure has been validated administering it to undergraduate students, attending Medicine, Arts and Engineering faculties. The results of this study show a high degree of reliability and validity of the test when comparing the skills of students educated in medical matters and those of non-biological faculties, indicating the potential <b>capability</b> <b>of</b> <b>the</b> <b>tool</b> to screen low HL levels in larger population. Despite the limits of this pilot study, IMETER's quick and easy administration method seems useful not only in clinical settings, but also to ease the implementation of future larger studies...|$|E
40|$|This paper {{describes}} a network planning tool {{that has been}} developed {{in order to provide}} support for network planners who need to dimension next generation IP networks to meet quality of service (QoS) objectives. Specifically, the proposed network planning tool takes account of the new technologies that enable QoS in IP-based networks (i. e., DiffServ/MPLS) and allows for multiple QoS constraints so that guaranteed performance can be achieved for each of the traffic classes. The primary-decisions for the planning tool include determining class-based bandwidth allocations on the links, total link capacities and how traffic of each class is to be routed through the network. Furthermore, the planning tool incorporates traffic characterisation and dimensioning procedures that allow the known burstiness of IP traffic to be effectively modelled. After discussing some of the specific features and algorithms that have been incorporated into the planning methodology, the planning tool is briefly described and the solution to a simple network problem is demonstrated. The simulation results demonstrate the <b>capability</b> <b>of</b> <b>the</b> <b>tool</b> in achieving the required performance levels for the traffic classes...|$|E
40|$|The Web systems domain {{has faced}} an {{increasing}} number of devices, browsers, and platforms to cope with, driving software systems to be more flexible to accomodate them. Software product line (SPL) engineering {{can be used as a}} strategy to implement systems capable of handling such a diversity. To this end, automated tool support is almost indispensable. However, current tool support gives more emphasis to modeling variability in the problem domain, over the support of variability at the solution domain. There is a need for mapping the variability between both abstraction levels, so as to determine what implementation impact a certain variability has. In this paper, we propose the FeatureJS, a FeatureIDE extension aiming at Javascript and HTML support for SPL engineering. The tool combines feature-oriented programming and preprocessors, as a strategy to map variability at source code with the variability modeled at a higher level of abstraction. We carried out a preliminary evaluation with an industrial project, aiming to characterize the <b>capability</b> <b>of</b> <b>the</b> <b>tool</b> to handle SPL engineering in the Web systems domain...|$|E
40|$|This study {{presents}} a brief introduction to Auger Spectroscopy with experimental results {{taken from a}} spectrometer donated by Kodak in 2000. <b>The</b> <b>tool</b> has been calibrated using materials with high electron energy signals, primarily Titanium and Gold. Analysis of thin film spectra include the materials Aluminum, Gold, Si~N 4, Germanium, and Tungsten. Depth profile measurements were made using a groove-etch technique and ion bombardment sputtering of a multi-layer metal stack. Future work will involve enabling x-Ray spectroscopy <b>capabilities</b> <b>of</b> <b>the</b> <b>tool</b> and increasing sensitivity of measurements...|$|R
50|$|After {{receiving}} many unfavorable {{reviews from}} clients regarding {{the changes to}} Insight for the 3.0 release, Knowland launched Insight 3.1 the following year (2015). Insight 3.1 was designed almost entirely around user feedback. This release leveraged the powerful, and once again enhanced, search <b>capabilities</b> <b>of</b> <b>the</b> <b>tool,</b> putting popular search features in the spotlight. Insight 3.1 made <b>the</b> focus <b>of</b> Knowland technology less about social media-influenced networking and more about <b>the</b> power <b>of</b> its raw, historical data on groups, planners, meetings, and contact information to help clients optimize their sales tactics.|$|R
40|$|Euclide {{is a new}} Constraint-Based Testing {{tool for}} verifying safety-critical C programs. By using a mixture of {{symbolic}} and numerical analyses (namely static single assignment form, constraint propagation, integer linear relaxation and search-based test data generation), it addresses three distinct applications in a single framework: structural test data generation, counter-example generation and partial program proving. This paper presents <b>the</b> main <b>capabilities</b> <b>of</b> <b>the</b> <b>tool</b> and relates an experience we had when verifying safety properties for a well-known critical C component <b>of</b> <b>the</b> TCAS (Traffic Collision Avoidance System). Thanks to Euclide, we found an unrevealed counter-example to a given anti-collision property. ...|$|R
40|$|AbstractConcept of {{fractional}} order calculus {{is as old}} as {{the regular}} calculus. With the advent of high speed and cost effective computing power, now it is possible to model the real world control and signal processing problems using fractional order calculus. For the past two decades, applications of fractional order calculus, in system modeling, control and signal processing, have grown rapidly. This paper presents a systematic procedure for hardware implementation of the basic operators of fractional calculus i. e. fractional integrator and derivative, using Grünwald–Letnikov definition, on field programmable gate array (FPGA) in LabVIEW environment. The simulation and hardware implementation results for fractional order integrator and derivative of sinusoid and square waveform signals for some selected fractional orders have been presented. A close agreement between the simulated and the experimental results demonstrated the suitability of FPGA device in fractional order control and signal processing applications. LabVIEW being one of the finest tools for measurement and control, and signal processing applications the fractional order operator implementation is expected to further enhance the <b>capability</b> <b>of</b> <b>the</b> <b>tool</b> to cater to the needs of advanced experimental research employing fractional order operators...|$|E
40|$|With a {{structure}} that provides control and choice over time, place, and pace, e-learning {{has emerged as a}} viable mode for working adults who wish to upgrade their knowledge. However, such flexibility provides leeway for these adults to procrastinate and for their motivation to dwindle. After all, many adults, especially Malaysian adults, are used to studying in {{a structure}}d learning environment. It is thus necessary to scaffold these learners’ needs, particularly during the early stages of their learning endeavour. The {{purpose of this paper is}} to highlight the problem of sustaining the e-learners ’ motivation in a Malaysian higher education setting. It also illustrates an approach taken to scaffold the learners ’ regulation of motivation. Four-phase design and development research carried out to design, develop, and evaluate a web-based task support tool called the learning console is described. The paper also draws attention to the design principles upon which the affective component is built into the tool. Findings from the formative evaluation of the tool conducted among 40 participants consisting of experts, instructors, and e-learners suggested the <b>capability</b> <b>of</b> <b>the</b> <b>tool</b> to regulate the motivation of the learners. In addition, characteristics of both personalized and group learning were also apparent. The Learning console was found to scaffold the e-learners ’ motivation and could be integrated into the existing learning management system...|$|E
40|$|An {{accurate}} {{study of}} a floating offshore wind turbine (FOWT) system requires 16 interdisciplinary knowledge about wind turbine aerodynamics, floating platform 17 hydrodynamics and mooring line dynamics, as well as interaction between these 18 discipline areas. Computational Fluid Dynamics (CFD) provides a new means of 19 analysing a fully coupled fluid-structure interaction (FSI) system in a detailed manner. 20 In this paper, a numerical tool based on the open source CFD toolbox OpenFOAM for 21 application to FOWTs will be described. Various benchmark cases are first modelled 22 to demonstrate the <b>capability</b> <b>of</b> <b>the</b> <b>tool.</b> The OC 4 DeepCWind semi-submersible 23 FOWT model is then investigated under different operating conditions. 24 With this tool, {{the effects of the}} dynamic motions of the floating platform on the wind 25 turbine aerodynamic performance and the impact of the wind turbine aerodynamics 26 on the behaviour of the floating platform and on the mooring system responses are 27 examined. The present results provide quantitative information of three-dimensional 28 FSI that may complement related experimental studies. In addition, CFD modelling 29 enables the detailed quantitative analysis of the wind turbine flow field, the pressure 30 distribution along blades and their effects on the wind turbine aerodynamics and the 31 hydrodynamics of the floating structure, which is difficult to carry out experimentally...|$|E
40|$|RFID {{transponder}} {{systems with}} ID and sensor functionality {{are used in}} manifold application areas. Especially, passive transponders with integrated sensors represent miniaturised and autonomous devices {{that can be used}} in industry and medical engineering. Considering these manifold usage scenarios and considering different specifications on performance and capabilities a customised dimensioning of transponder systems are needed. Therefore, efficient methods for modelling, analysing and computer-aided optimisation are helpful. That paper focuses on <b>the</b> introduction <b>of</b> these methods and the realisation in a design tool. Additionally, an example is described to show the usage and <b>the</b> <b>capabilities</b> <b>of</b> <b>the</b> <b>tool...</b>|$|R
40|$|Abstract- A {{comprehensive}} tool {{has been}} implemented for <b>the</b> comparison <b>of</b> different test preparation techniques and target faults. It comprises <b>of</b> <b>the</b> realistic fault characterisation program LIFT that can extract sets of various faults from a given analogue or mixed-signal circuit layout and the automatic analogue fault simulation program AnaFAULT which can handle arbitrary catastrophic and parametric faults. For a fabricated integrated VCO circuit <b>the</b> <b>capabilities</b> <b>of</b> <b>the</b> <b>tool</b> are demonstrated and simulation results are presented. assumption <b>of</b> <b>the</b> complete set <b>of</b> possible faults {{taken from the}} schematic. After the introduction and the state-of-the-art, <b>the</b> application procedure <b>of</b> <b>the</b> universal CAT <b>tool</b> within th...|$|R
40|$|Abstract. <b>The</b> goal <b>of</b> this {{research}} {{is to develop a}} tool that employs intelligent technologies to capture <b>the</b> patterns <b>of</b> urban change driven by a diverse set of context factors. Data mining provides opportunities, which complement and extend the knowledge previously obtained with other approaches. A series of exploratory case studies are in place to investigate the modeling and predictive <b>capabilities</b> <b>of</b> <b>the</b> <b>tool.</b> A number <b>of</b> simulations have revealed distinctive local patterns of urban change in <b>the</b> city <b>of</b> Skopje, shaped by local urban spatial and institutional structures. This study shows <b>the</b> importance <b>of</b> intelligent technologies in <b>the</b> interpretation <b>of</b> <b>the</b> historical evidence <b>of</b> urban development...|$|R
40|$|Step and Flash Imprint Lithography (S-FIL) is one {{of several}} new methods of imprint {{lithography}} being actively developed. As with other nanoimprint methods, S-FIL resolution appears to be limited only by template resolution, and offers a significant cost of ownership reduction when compared to other NGL methods such as EUVL and 157 nm lithography. Market segments capable of being addressed with S-FIL technology include nanodevice fabrication, compound semiconductors, photonic and optical devices, data storage, and advanced packaging. Successful implementation will require a commercial supplier of S-FIL tools, as well as an infrastructure that will support fabrication of the necessary 1 X templates. The Imprio 100, manufactured by Molecular Imprints, Inc. is the first commercially available S-FIL tool. The {{purpose of this paper is}} to describe the performance and capabilities of the Imprio 100. Performance related to several tool parameters including layer-to-layer overlay, pre-aligner precision, residual layer thickness and uniformity, resolution, wafer throughput, and exposure lamp intensity uniformity was evaluated. Several spin-coatable organic materials were evaluated for their efficacy as transfer layers. Contact angle analysis of each material along with a comparison of the spread time and resulting residual layer, and overall resolution using each material was also done. This paper will present the results of both the factory and site acceptance tests, and will also cover the imprinting <b>capability</b> <b>of</b> <b>the</b> <b>tool...</b>|$|E
40|$|BACKGROUND: We {{recently}} published PROGgene, {{a tool that}} can be used to study prognostic implications of genes in various cancers. The first version of the tool had several areas for improvement. In this paper we present some major enhancements we have made on the existing tool in the new version, PROGgeneV 2. RESULTS: In PROGgeneV 2, we have made several modifications to enhance survival analysis <b>capability</b> <b>of</b> <b>the</b> <b>tool.</b> First, we have increased the repository of public studies catalogued in our tool by almost two folds. We have also added additional functionalities to perform survival analysis in a variety of new ways. Survival analysis can now be performed on a) single genes b) multiple genes as a signature, c) ratio of expression of two genes, and d) curated/published gene signatures in new version. Users can now also adjust the survival analysis models for available covariates. Users can study prognostic implications of entire gene signatures in different cancer types, which are searchable by keywords. Also, unique to our tool, in the new version, users will be able to upload and use their own datasets to perform survival analysis on genes of interest. CONCLUSIONS: We believe, like its predecessor, PROGGeneV 2 will continue to be useful for the scientific community for formulating research hypotheses and designing mechanistic studies. With added datasets PROGgeneV 2 is the most comprehensive survival analysis tool available. PROGgeneV 2 is available at [URL]...|$|E
40|$|Friction stir welding is a {{relatively}} new joining process, which involves the joining of metals without fusion or filler materials. The amount of the heat conducted into the work piece dictates a successful process which is defined by the quality, shape and microstructure of the processed zone, as well as the residual stress and the distortion of the work piece. The amount of the heat gone to the tool dictates the life of the tool and the <b>capability</b> <b>of</b> <b>the</b> <b>tool</b> to produce a good processed zone. Hence, understanding the heat transfer aspect of the friction stir welding is extremely important for improving the process. Many research works were carried out to simulate the friction stir welding using various soft wares to determine the temperature distribution for a given set of welding conditions. Very few attempted to determine the maximum temperature by varying the input parameters using ANSYS. The objective of this research is to develop a finite element simulation of friction stir welding of AA 6061 -T 6 Aluminium alloy. Trend line equations are developed for thermal conductivity, specific heat and density to know the relationship of these factors with peak temperature. Tensile and hardness values for the welded specimens are found for different rotational speed and feed. Variation of temperature with input parameters is also observed. The simulation model is tested with experimental results. The results of the simulation are in good agreement with that of experimental results...|$|E
40|$|<b>The</b> {{potential}} <b>of</b> building energy simulation is {{now well}} recognised and <b>the</b> use <b>of</b> <b>the</b> technology by progressive energy sector companies is growing. <b>The</b> success <b>of</b> any building performance assessment hinges on <b>the</b> <b>capabilities</b> <b>of</b> <b>the</b> <b>tool,</b> <b>the</b> collective competences <b>of</b> <b>the</b> team formed {{to apply it}} and, most crucially, <b>the</b> rigour <b>of</b> <b>the</b> inhouse quality control procedure. Two core issues facing the professions are <b>the</b> management <b>of</b> simulation and <b>the</b> quality assurance <b>of</b> <b>the</b> related models and appraisal results. This paper describes how the Scottish Energy Systems Group (SESG) aims to transfer simulation to energy sector companies and, through specialist staff secondments, to support this transfer in <b>the</b> context <b>of</b> day-to-day work practices. The intention is to demonstrate that simulation-based design can yield results, quicker, cheaper and better than conventional methods. The SESG is a joint Scottish Office, Industry, Scottish Enterprise venture. This paper outlines <b>the</b> aims <b>of</b> <b>the</b> SESG and describes <b>the</b> core elements <b>of</b> its operation...|$|R
40|$|<b>The</b> goal <b>of</b> this {{research}} {{is to develop a}} tool that employs intelligent technologies to capture <b>the</b> patterns <b>of</b> urban change driven by a diverse set of context factors. Data mining provides opportunities and knowledge embedded in the urban structure, which complement and extend the data previously obtained with other approaches. A case study is in place to investigate the modeling and predictive <b>capabilities</b> <b>of</b> <b>the</b> <b>tool.</b> A number <b>of</b> simulations have revealed distinctive local patterns of urban change in <b>the</b> city <b>of</b> Skopje, shaped by local urban spatial and institutional structures. This study shows <b>the</b> possibilities <b>of</b> intelligent technologies in <b>the</b> interpretation <b>of</b> <b>the</b> historical evidence <b>of</b> urban development and better understanding <b>of</b> <b>the</b> urban phenomenon. 1...|$|R
40|$|Fraunhofer SAVE (Software Architecture Visualization and Evaluation) is a {{tool for}} {{analyzing}} and optimizing <b>the</b> architecture <b>of</b> implemented software systems. SAVE is a joint development between Fraunhofer IESE (Institute for Experimental Software Engineering IESE in Kaiserslautern, Germany) and Fraunhofer Center Maryland (Center for Experimental Software Engineering in College Park, Maryland, USA). In this work we describe <b>the</b> <b>capabilities</b> <b>of</b> <b>the</b> <b>tool</b> to assure compliance of existing systems with their architecture. In particular, we show how compliance checking features of SAVE work to assure compliance with structural and behavioral architectural views, to assure compliance among variants in a product line context, and to incorporate constructive compliance checking to enable built-in compliance during development and evolution...|$|R
