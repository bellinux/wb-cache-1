5|21|Public
50|$|Crosses {{are common}} in fire {{sprinkler}} systems (where stress caused by thermal expansion is not generally an issue), but are not common in plumbing. One <b>cross</b> <b>fitting</b> is more expensive than two tees.|$|E
40|$|We {{propose a}} fully {{automatic}} spliced image detection method based on consistency checking of camera characteristics among different areas in an image. A test image is first segmented into distinct areas. One camera response function (CRF) is estimated from each area using geometric invariants from locally planar irradiance points (LPIPs). To classify a boundary segment between two areas as authentic or spliced, CRF <b>cross</b> <b>fitting</b> scores and area intensity features are computed and fed to SVM-based classifiers. Such segment-level scores are further fused {{to form the}} image-level decision. Tests on both the benchmark data set and an unseen high-quality spliced data set reach promising performance levels with 70 % precision and 70 % recall. 1...|$|E
40|$|A {{multifunctional}} electrodialytic generator (EDG) for capillary {{ion chromatography}} (CIC) is described. The same device can generate acidic, basic or saline eluents. Two oppositely charged ion exchange beads {{are used to}} fabricate the EDG; the dual ion exchanger configuration ensures the production of gas-free eluent, obviating the need of a gas removal device used with single ion exchanger EDG's. The ability of the same EDG to produce different eluents is governed solely by {{the choice of the}} respective feed solutions; this is presently demonstrated by generation of diverse eluents such as Na(2) CO(3) /NaHCO(3). CH(3) SO(3) H, and KNO(3). The EDG is implemented simply in a commercial <b>cross</b> <b>fitting</b> and has been tested up pressures to 2000 psi. Under typical operating conditions, the zero current concentration (open circuit penetration, OCP) is negligible. The generated eluent concentration linearly increases with applied current with a slope that is essentially Faradaic. The device permits both isocratic and gradient operation with good reproducibility, as demonstrated by the analysis of anions using HCO(3) -/CO(3) (2 -) EDG. (c) 2009 Elsevier B. V. All rights reserved...|$|E
50|$|Crosses, {{also known}} as four-way <b>fittings</b> or <b>cross</b> branch lines, have one inlet and three outlets (or vice versa), and often have solvent-welded socket or female-threaded ends. <b>Cross</b> <b>fittings</b> may stress pipes as {{temperatures}} change, because {{they are at the}} center of four connection points. A tee is steadier than a cross; it behaves like a three-legged stool, and a cross behaves like a four-legged stool. Geometrically, any three non-collinear points can self-consistently define a plane; three legs are inherently stable, whereas four points overdetermine a plane, and can be inconsistent, resulting in physical stress on a fitting.|$|R
50|$|Version 2.1 of the ATX {{specification}} {{states that}} the length of standoffs needs {{to be at least}} 0.25 in, with their <b>cross</b> sections <b>fitting</b> within 0.40x0.40 in square areas centered around each mounting hole on ATX motherboards.|$|R
6000|$|... "He {{never comes}} until the evening train," [...] another said. [...] "He always {{declares}} {{it has something}} to do with <b>cross</b> lines not <b>fitting</b> in." ...|$|R
40|$|Abstract—We {{present a}} fully {{automatic}} method to detect doctored digital images. Our method {{is based on}} a rigorous consistency checking principle of physical characteristics among different arbitrarily shaped image regions. In this paper, we specifically study the camera response function (CRF), a fundamental property in cameras mapping input irradiance to output image intensity. A test image is first automatically segmented into distinct arbitrarily shaped regions. One CRF is estimated from each region using geometric invariants from locally planar irradiance points (LPIPs). To classify a boundary segment between two regions as authentic or spliced, CRF-based <b>cross</b> <b>fitting</b> and local image features are computed and fed to statistical classifiers. Such segment level scores are further fused to infer the image level authenticity. Tests on two data sets reach performance levels of 70 % precision and 70 % recall, showing promising potential for real-world applications. Moreover, we examine individual features and discover the key factor in splicing detection. Our experiments show that the anomaly introduced around splicing boundaries plays the major role in detecting splicing. Such finding is important for designing effective and efficient solutions to image splicing detection. Index Terms—Camera response function (CRF), image forensics, splicing detection, tampering detection. I...|$|E
40|$|This study {{describes}} several refinements {{and improvements}} in whole stand growth and yield modelling of Douglas-fir grown in four regions of the South Island of New Zealand, namely Canterbury, Nelson, Southland and Westland. Modelling growth and forecasting yields are necessary for providing adequate tools with which to manage wood production from forests. The study comprised three major components: 1) development of whole stand growth and yield models with data sets of various interval lengths; 2) <b>cross</b> <b>fitting</b> models with different data sets reciprocally; and 3) check estimates using a growth and yield model derived from a data set free of auto-correlation. The methodology emphasised in developing the equations in this study involved rearrangement of the data to reflect different interval lengths among re-measurements for modelling purposes. Modification of data sets allowed an investigation into which growth intervals {{should be used to}} obtain the least biased models overall, and efficiently. The approach involved fitting single equations to each of three state variables, mean top height (h 1 OO), basal area/ha (0) and stocking/ha (N). Differences in growth trajectories across the four regions were identified and incorporated into single variable equations using dummy variables for improving the fitting of mean top height (h 1 OO), basal area/ha (0), and stocking/ha (N) equations. The main finding from this study was the level of improvement in making predictions through adoption of a mixed interval projection equation strategy compared with other options. Examining consistency among the predicting equations which had been developed from the different interval data sets, involved testing each form of model individually for all the data sets. The models based on mixed intervals were found to fit well for all the other interval length data sets. A subset of uncorrelated data was then created by selecting one re-measurement from each permanent sample plot (PSP), which was then used to validate the appropriateness of the equations derived from the full data sets, in order to overcome problems of dealing with correlated data. Coefficients for each of the equations for mean top height, basal area/ha and stocking/ha which were derived from this check data set were found to be very similar to the regression coefficients obtained from the full data set. Although the growth models developed in this study may require further examination, they do provide a very useful guide for selecting appropriate re-measurement interval lengths to derive satisfactory models which are the least biased overall. It is strongly recommended that modellers in the future adopt a mixed interval strategy as one data set option to evaluate...|$|E
40|$|The {{cross section}} of the e^+e^-→ωπ^ 0 →π^ 0 π^ 0 γ {{reaction}} was measured by the SND detector at VEPP- 2 M e^+e^- collider in the energy range from threshold up to 1. 4 GeV. Results of the <b>cross</b> section <b>fitting</b> by the sum of ρ, ρ^' and ρ^" contributions are presented. Comment: 8 pages, 3 figures, 2 tables. Submitted to Phys. Lett. ...|$|R
40|$|Results of {{research}} {{efforts in the}} following areas are discussed: review of the major theoretical and experimental data of subshell photoionization cross sections and ionization edges of atomic ions to assess {{the accuracy of the}} data, and to compile the most reliable of these data in our own database; detailed atomic physics calculations to complement the database for all ions of 17 cosmically abundant elements; reconciling the data from various sources and our own calculations; and <b>fitting</b> <b>cross</b> sections with functional approximations and incorporating these functions into a compact computer code. Also, efforts included adapting an ionization equilibrium code, tabulating results, and incorporating them into the overall program and testing the code (both ionization equilibrium and opacity codes) with existing observational data. The background and scientific applications of this work are discussed. Atomic physics cross section models and calculations are described. Calculation results are compared with available experimental data and other theoretical data. The functional approximations used for <b>fitting</b> <b>cross</b> sections are outlined and applications of the database are discussed...|$|R
40|$|In real space we {{may move}} closer, or glance at someone {{to express our}} {{willingness}} for conversation. The act of approaching someone is accompanied by ancillary information such {{as the sound of}} footsteps, or air movement, which the potential conversation partner can detect, but may easily ignore. We call this "soft initiation". To include such ancillary cues in virtual space, we provide the sense of physically <b>crossing</b> paths, by <b>fitting</b> a vibrating device on the participants' bodies. This is an extension of the "HyperMirror" video communication system in which participants see each other as though present in the same space together...|$|R
5000|$|Lalique {{was best}} known for his creations in glass art. In the 1920s, he became noted for his work in the Art Deco style. He was {{responsible}} for the walls of lighted glass and elegant coloured glass columns which filled the dining room and [...] "grand salon" [...] of the [...] and the interior <b>fittings,</b> <b>cross,</b> screens, reredos and font of St. Matthew's Church at Millbrook in Jersey (Lalique's [...] "Glass Church"). His earlier experiences in Ay were his defining influence in his later work. As a result, many of his jewellery pieces and vases showcase plants, flowers and flowing lines.|$|R
40|$|The {{differential}} cross section, dσ/dt, for ρ 0 meson photoproduction on the proton above the resonance region was measured up to a momentum transfer -t = 5 GeV 2 using the CLAS detector at the Thomas Jefferson National Accelerator Facility. The ρ 0 channel was {{extracted from the}} measured two charged-pion <b>cross</b> sections by <b>fitting</b> the π+π- and pπ+ invariant masses. The low momentum transfer region shows the typical diffractive pattern expected from Reggeon exchange. The flatter behavior at large -t cannot be explained solely in terms of QCD-inspired two-gluon exchange models. The data indicate that other processes, like quark interchange, are important to fully describe ρ photoproduction...|$|R
50|$|The new BH Persona has 3 hp {{less than}} the {{outgoing}} CM series, but the full 107 hp is accessible earlier at 5,750 rpm, compared to 6,500 rpm in the old CM. Additionally, the BH has 2 Nm more torque over the CM, while access speed is unchanged at 4,000 rpm. Acceleration has also improved, with the CVT-equipped BH taking 10.9 seconds to reach 100 km/h from a standstill, which is 3 seconds faster than the old 4-speed automatic CM. Proton {{has decided not to}} offer the Iriz's 1.3 L VVT engine in the new Persona, as they intend to prevent overlapping and <b>cross</b> cannibalisation by <b>fitting</b> it in the upcoming 2016 Proton Saga instead.|$|R
40|$|Yellow {{passion fruit}} pulp is unstable, {{presenting}} phase separation {{that can be}} avoided {{by the addition of}} hydrocolloids. For this purpose, xanthan and guar gum [0. 3, 0. 7 and 1. 0 % (w/w) ] were added to yellow passion fruit pulp and the changes in the dynamic and steady - shear rheological behavior evaluated. Xanthan dispersions showed a more pronounced pseudoplasticity and the presence of yield stress, which was not observed in the guar gum dispersions. <b>Cross</b> model <b>fitting</b> to flow curves showed that the xanthan suspensions also had higher zero shear viscosity than the guar suspensions, and, for both gums, an increase in temperature led to lower values for this parameter. The gums showed different behavior as a function of temperature in the range of 5 - 35 ºC. The activation energy of the apparent viscosity was dependent on the shear rate and gum concentration for guar, whereas for xanthan these values only varied with the concentration. The mechanical spectra were well described by the generalized Maxwell model and the xanthan dispersions showed a more elastic character than the guar dispersions, with higher values for the relaxation time. Xanthan was characterized as a weak gel, while guar presented a concentrated solution behavior. The simultaneous evaluation of temperature and concentration showed a stronger influence of the polysaccharide concentration on the apparent viscosity and the G' and G" moduli than the variation in temperature...|$|R
40|$|We present {{measurements}} of interspecies thermalization between ultracold samples of ^ 133 Cs and either ^ 174 Yb or ^ 170 Yb. The two species {{are trapped in}} a far-off-resonance optical dipole trap and ^ 133 Cs is sympathetically cooled by Yb. We extract effective interspecies thermalization <b>cross</b> sections by <b>fitting</b> the thermalization measurements to a rate equation model, giving σ_Cs^ 174 Yb = (5 ± 2) × 10 ^- 13 cm^ 2 and σ_Cs^ 170 Yb = (18 ± 8) × 10 ^- 13 cm^ 2. We perform quantum scattering calculations of the thermalization cross sections and optimize the CsYb interaction potential to reproduce the measurements. We predict scattering lengths for all isotopic combinations of Cs and Yb. We also demonstrate the independent production of ^ 174 Yb and ^ 133 Cs Bose-Einstein condensates using the same optical dipole trap, an important step towards the realization of a quantum-degenerate mixture of the two species. Comment: 12 pages, 7 figure...|$|R
40|$|We present S factor data {{obtained}} from the Coulomb dissociation of 83 MeV/nucleon 8 B, and analyze 7 Be longitudinal momentum distributions measured at 44 and 81 MeV/nucleon using a potential model, first-order perturbation theory, and dynamical solution of the time-dependent Schroedinger equation. Comparing our results with independent continuum-discretized coupled channels calculations, we examine the reaction model and beam energy dependence of the E 2 contribution to the dissociation <b>cross</b> section. By <b>fitting</b> radiative capture and Coulomb breakup data taken below relative energies of 400 keV with a potential model constrained by 7 Be + p elastic scattering data, we examine the mutual consistency of recent S 17 measurements. Evaluating the central values consistently and the extrapolation uncertainties on a case-by-case basis, we take a weighted average {{of the results of}} four direct and three indirect measurements to obtain a recommended value for S 17 (0) of 19. 0 +/- 1. 0 eV b (95 % confidence level) ...|$|R
40|$|The Jeener–Broekaert {{experiment}} {{has recently}} been applied to heterogeneous biological systems for selective observation of spinI= 3 / 2 nuclei which exhibit residual quadrupolar splittings. This paper describes {{the use of a}} two-dimensional version of this experiment to extract the homogeneous linewidths of such nuclei. The powderlike spectra produced by the one-dimensional Jeener–Broekaert experiment have lineshapes which depend on both homogeneous and inhomogeneous quadrupolar broadening. In two-dimensional Jeener–Broekaert spectra, the inhomogeneous broadening appears along the ω 1 = ω 2 and ω 1 = −ω 2 diagonal axes, with the result that the two broadenings are separated. The homogeneous linewidth can then be extracted by <b>fitting</b> <b>cross</b> sections through analytically generated lineshapes to the experimental spectra. The reliability of this technique is evaluated by computer simulation, and 23 Na NMR linewidths are measured experimentally in disordered liquid crystalline and heterogeneous biological samples. The possibility of measuring frequency-dependent variations in the homogeneous linewidth is also discussed...|$|R
40|$|In this paper, a {{three-dimensional}} {{quantitative structure-activity relationship}} (3 D-QSAR) study for 62 HIV- 1 integrase(IN) inhibitors was established using Topomer CoMFA. The multiple correlation coefficient of <b>fitting,</b> <b>cross</b> validation and external validation were 0. 942, 0. 670 and 0. 748, respectively. The {{results indicated that the}} Topomer CoMFA model obtained has both favorable estimation stability and good prediction capability. Topomer Search was used to search R group from ZINC database. As the result, a series of R groups with relatively high activity contribution was obtained. By filtering with the most potent molecule in the set, 1 Ra group and 21 Rb groups were selected. We employed the 1 Ra groups and 21 Rb groups to alternately substitute the Ra and Rb of sample 42. Finally, we designed 21 new compounds and further predicted their activities using the Topomer CoMFA model and there were 10 new compounds with higher activity than that of the template molecule. The results suggested the Topomer Search technology could be effectively used to screen and design new HIV- 1 IN inhibitors and has good predictive capability to guide the design of new HIV/AIDS drugs...|$|R
40|$|K → ππ, KL-KS mass {{difference}} and KL → γγ (∗) are studied systematically by decomposing their amplitude into a sum of factorizable and nonfactorizable ones. The former is calculated {{by using the}} naive factorization while the latter {{is assumed to be}} dominated by dynamical contributions of various hadron states. Non-factorizable amplitudes for the K → ππ decays are estimated by using a hard pion approximation in the infinite momentum frame. Long distance non-factorizable contributions to the KL-KS mass difference is dominated by those of pseudo scalar meson poles and ππ intermediate states. The amplitude for the KL → γγ (∗) is given by a sum of pole contributions of pseudo scalar mesons in the s-channel and K ∗ meson in the <b>crossed</b> channel. By <b>fitting</b> the results on the K → ππ, KL-KS mass {{difference and}} KL → γγ to the observations, values of unknown parameters involved are estimated and then, by using the resulting values of these parameters, the form factor for the Dalitz decays of KL and their rates are predicted. The results are It has been known that short distance contribution is small in the KL → γγ decay [1] and a naively factorized |∆I | = 1 amplitude for the K → ππ decays is much smaller than th...|$|R
40|$|We {{discuss the}} {{construction}} of the Galaxy And Mass Assembly (GAMA) 10 h region (G 10) using publicly available data in the Cosmic Evolution Survey region (COSMOS) in order to extend the GAMA survey to z _ 1 in a single _ 1 deg 2 field. In order to obtain the maximum number of high precision spectroscopic redshifts we re-reduce all archival zCOSMOS-bright data and use the GAMA automatic <b>cross</b> correlation redshift <b>fitting</b> code autoz. We use all available redshift information (autoz, zCOSMOS-bright 10 k, PRIMUS, VVDS, SDSS and photometric redshifts) to calculate robust best-fit redshifts for all galaxies and visually inspect all 1 D and 2 D spectra to obtain 16, 583 robust redshifts in the full COSMOS region. We then define the G 10 region to be the central _ 1 deg 2 of COSMOS, which has relatively high spectroscopic completeness, and encompasses the CHILES VLA region. We define a combined r < 23 : 0 mag & i < 22 : 0 mag G 10 sample (selected to have the highest bijective overlap) with which to perform future analysis, containing 9, 861 sources with reliable high precision VLT-VIMOS spectra. All tables, spectra and imaging are available at: [URL]...|$|R
40|$|The {{off-axis}} {{powers of}} five types of progressive power lenses were {{measured on a}} modified vertometer. The lens types assessed were the Sola Graduate, the Hoya Varilux II, the Rodenstock Progressiv R, the American Optical Truvision, and Zeiss Gradal HS. The performance characteristics assessed were size and stability of distance and near zones, intermediate zone width, regularity of power increase in the intermediate and near zones, and distribution and axes of aberrations in the peripheral zone. None of these lenses is clearly superior or inferior to others; all have their strengths and weaknesses. Progressive lens types can be classified either as "hard" or "soft" types. Hard designs have their aberrated areas confined to smaller areas on the lens surface than do soft designs, but {{the rate of change}} of aberrations of the hard designs is greater. In lenses of soft design the aberrations extend well above the 180 degree meridian through the <b>fitting</b> <b>cross.</b> The order of decreasing "softness" of the tested lens types is Hoya Varilux II, Zeiss Gradal HS, and Sola Graduate (all classified as "soft"), Rodenstock Progressiv R and American Optical Truvision (both "hard"). This order is generally reflected by the extents of near zone sizes, intermediate zone widths and peripheral astigmatism...|$|R
40|$|We {{present the}} {{measurement}} of the t{bar t} cross section in the lepton plus jets channel with {ge} 1 and {ge} 2 secondary vertex tags. We use the scalar sum of transverse energies of the event (H{sub T}) to discriminate t{bar t} from the other backgrounds. We also use the transverse mass of the leptonic W-boson (M{sub T}{sup W}) to further reduce the Non-W backgrounds. We {{use a combination of}} data and Monte Carlo to estimate the backgrounds from electroweak processes, single top, fake leptons, W+ Light Flavor fake tags, and real W+ Heavy Flavor production. We obtain a value of {sigma} {sub {ge} 1 } = 8. 7 {sub - 0. 9 }{sup + 0. 9 }(stat) {sub - 0. 9 }{sup + 1. 2 }(sys) pb for the {ge} 1 tag cross section, and {sigma}{sub {ge} 2 } = 8. 7 {sub - 1. 6 }{sup + 1. 8 }(stat) {sub - 1. 3 }{sup + 1. 9 }(sys) pb for the {ge} 2 tag cross section. The authors also present a measurement of the t{bar t} <b>cross</b> section by <b>fitting</b> the N{sub jet} spectrum. They combine the = 1 and {ge} 2 tag cross sections to obtain {sigma}{sub t{bar t}} = 8. 9 {sub - 0. 9 }{sup + 0. 9 }(stat) {sub - 1. 3 }{sup + 1. 4 }(syst) pb...|$|R
40|$|Electron-impact double-ionization {{processes}} of light positive ions from He- to Ne-like isoelectronic sequences, {{as well as}} of the heavy ions Arq+ (q = 1 – 7) and Kr q+ (q = 1 – 4) are considered for incident-electron energies E < 50 Ith where Ith is the threshold energy for double-electron ionization. On the basis of reliable experimental data and quantum-mechanical calculations, simple semiempirical formulae with three fitting parameters, by taking into account the contribution of direct double ionization and of inner-shell ionization processes, are obtained which describe the experimental cross sections within an accuracy of 20 – 30 %. With this accuracy, the formulae suggested can be used for prediction of the double-ionization cross sections of positive ions with the nuclear charge Z ≤ 26 in the electron energy range of E < 50 Ith. According to the model suggested, the direct ionization cross section σdir (simultaneous ionization of two outer electrons) is scaled as I- 3 th against scaled electron energy E/Ith and contains only one fitting parameter. Two additional fitting parameters are obtained using the least-squares method in conjunction with numerically calculated single-electron inner-shell ionization <b>cross</b> sections. All <b>fitting</b> parameters are found to be constant for ions within a given isoelectronic sequence. The present analysis also provides a method for indirect determination of K-shell ionization cross sections for ions from Be-like to Ne-like sequences. The fluorescence yields ωK for a single K-shell vacancy in ions from Li-like to Ne-like sequences with nuclear charges 3 ≤ Z ≤ 26 are calculated as well...|$|R
40|$|Progressive {{addition}} lenses (PALs) are {{an increasingly}} preferred mode for the correction of presbyopia, gaining an increased {{share of the}} prescription lens market. Sales volumes are likely to increase {{over the next few}} years, given the increasing cohort of presbyopic patients in the population. This research investigated adaptation to PAL wear, investigating head movement parameters with and without progressive lenses in everyday visual tasks, and examined symptoms of spatial distortions and illusory movement in a crossover wearing trial of three PAL designs. Minimum displacement thresholds in the presence and absence of head movement were also investigated across the lens designs. Experiment 1 investigated head movements in two common visual tasks, a wordprocessing copy task, and a visual search task designed to replicate a natural environment task such as looking for products on supermarket shelving. Head movement parameters derived from this experiment were used to set head movement amplitude and velocity in the third experiment investigating minimum displacement thresholds across three PAL designs. Head movements were recorded with a Polhemus Inside Track head movement monitoring system which allows real time six degrees of freedom measurement of head position. Head position in azimuth, elevation and roll was extracted from the head movement recorder output, and data for head movement angular extent, average velocity (amplitude/duration) and peak velocity were calculated for horizontal head movements Results of the first experiment indicate a task dependent effect on head movement peak and average velocity, with both median head movement average and peak velocity being faster in the copy task. Visual task and visual processing demands were also shown to affect the slope of the main sequence of head movement velocity on head movement amplitude, with steeper slope in the copy task. A steeper slope, indicating a faster head movement velocity for a given head movement amplitude, was found for head movements during the copy task than in the search task. Processing demands within the copy task were also shown to affect the main sequence slopes of velocity on amplitude, with flatter slopes associated with the need for head movement to bring gaze to a specific point. These findings indicate selective control over head movement velocity in response to differing visual processing demands. In Experiment 2, parameters of head movement amplitude and velocity were assessed in a group of first time PAL wearers. Head movement amplitude, average and peak velocity were calculated from head movement recordings using the search task, as in Experiment 1. Head movements were recorded without PALs, on first wearing a PAL, and after one month of PAL wear to assess adaptation effects. In contrast to existing literature, PAL wear did not alter parameters of head movement amplitude and velocity in a group of first time wearers either on first wearing the lenses or after one month of wear: this is due to task related effects in this experiment compared to previous work. Task demand in this experiment may not have required wearers to use the progressive power corridor to accomplish identification of visual search targets, in contrast to previous studies where experimental conditions were designed to force subjects to use the progressive corridor. In Experiment 3, minimum displacement thresholds for random dot stimuli were measured in a repeated measures experimental design for a single vision lens as control, and three PAL designs. Thresholds were measured in central vision, and for two locations in the temporal peripheral field, 30 ° temporal fixation and 10 ° above and below the horizontal midline. Thresholds were determined with and without the subjects' head moving horizontally in an approximate sinusoidal movement at a frequency of about 0. 7 Hz. Minimum displacement thresholds were not significantly affected by PAL design, although thresholds with PALs were higher than with a single vision lens control. Head movement significantly increased minimum displacement threshold across lens designs, by a factor of approximately 1. 5 times. Results indicate that the local measures of minimum displacement threshold determined in this experiment are not sensitive to lens design differences. Sensitivity to motion with PAL lenses may be more a global than a localized response. For Experiment 4, symptoms of spatial distortion and illusory movement were investigated in a crossover wearing trial of three PAL designs, and related to optical characteristics of the lenses. Peripheral back vertex powers of the PALs were measured at two locations in the right temporal zone of the lenses, 15. 6 mm temporal to the <b>fitting</b> <b>cross,</b> and 2. 7 m above and below the horizontal to the <b>fitting</b> <b>cross.</b> These locations corresponded to the zones of the lenses through which minimum displacement thresholds were measured in the previous experiment. The effect of subjects' self movement on symptoms is able to discriminate between PAL designs, although subjective symptoms alone were not related to the lens design parameters studied. Subjects' preference for one PAL design over the other designs studied in this experiment is inversely related to the effect on subject movement on their symptoms of distortion. An optical parameter, blur strength, derived from the power vector components of the peripheral powers, may indicate preference for particular PAL designs, as higher blur strength values are associated with lower lens preference scores. Head movement amplitude and velocity are task specific, and are also influenced by visual processing demands within tasks. PALs do not affect head movement amplitude and velocity unless tasks are made demanding or performed in less natural situations designed to influence head movement behaviour. Both head movement and PALs have large effects on minimum displacement thresholds; these effects may be due in part to complexity of the subjects' task within the experiment. Minimum displacement thresholds however were not influenced by PAL design. The most sensitive indicator for subject's preference of PALs was the effect of subjects' self movement on their perception of symptoms, rather than the presence of actual symptoms. Blur strength should be further investigated for its role in PAL acceptance...|$|R
40|$|The Fast TracKer {{project and}} in {{particular}} the Associative Memory system aims at setting new standards for speed of computation for pattern recognition, enabling technological advancements useful to research and society. This technology is based on a Processing Unit made of the combination of FPGAs and a full custom associative memory AM-chip. In the Associative Memory system, pattern matching is executed with the maximum parallelism, and the results are then refined using FPGAs. The Processing Unit has been developed for high energy physics, and its purpose is the real time track reconstruction at hadron collider experiments which is a crucial task for the success of such experiments. There, the most interesting processes are very rare and hidden in an extremely large level of background information. Selecting interesting events from the background in real time is therefore essential to fully exploit the physics potential of experiments where only a very limited fraction of the produced data can be recorded. Only 1 over 107 produced data sets, called "events", can be written to disk to perform physics analysis. Therefore, the selection system must be extremely accurate and fast in order to store and post-process potentially interesting events. Tracking devices, {{and in particular}} silicon detectors that are becoming the predominant tracking technology, play an essential role in the identification of interesting events. In fact, they provide very detailed information for charged particles and they can separate most of the different particle trajectories in the overlapping collisions recorded in the same event. However, these detectors contain hundreds of millions of channels, so they make the problem of complete tracking a formidable challenge even for large computing farms. The events contain many soft, not interesting collisions superimposed to the interesting one, the hard scattering. This level of confusion is due to the collider extremely high collision rate necessary to produce rare particles, as the Higgs boson recently discovered at CERN, at an appreciable rate. These conditions are going to worsen in the future experiments. The Large Hadron Collider (LHC) at CERN will produce 80 overlapped events before 2020 and this number will grow up to hundreds of collisions for the following machine upgrade. On the other hand, the state-of-the-art electronics are advanced enough to overcome the problem. We provided real-time tracking using a massively-parallel high-performance system. Our solution provides the required performance for a relatively low cost, lower energy consumption, and saving space (by using a more compact system). We implemented an innovative strategy, based on the optimal mapping of a complex algorithm on different technologies. Our target is to get the optimal results by combining the high performance of rigid dedicated hardware with the distinctive flexibility of the FPGA and of general-purpose, but lower-performance, CPUs. The architecture’s key role is played by FPGAs, while the majority of computing power is provided by cooperating full-custom ASICs named Associative Memory. The AM-chip is suitable for massive parallelism in data correlation searches and it has {{a key role in the}} system. One Processing Unit hosts 64 AM-chips, and it is able to perform bitwise comparisons at 120 Pbit/s. The memory access bandwidth and number of comparisons per second has, to the best of our knowledge, no equal in commercial resources. It takes full advantage of the intrinsic parallel nature of the combinatorial problem by comparing at once the data under analysis to a set of pre-calculated "expectations", or patterns. This approach reduces to linear the exponential complexity of CPU-based algorithms and the problem is solved by the time data are loaded into the system. Data processing speed is achieved with pipelining, and parallel processing. Track reconstruction is executed with a two steps pipeline architecture. The AM system implements the first stage by recognizing track candidates at low resolution. The second stage, the Track Fitter, is implemented using FPGAs. The Track Fitter receives track candidates and high resolution hits to refine pattern recognition at the associative memory output rate. "Hit" refers to the centroid of the charge left by the ionization process due to the <b>crossing</b> particle. Track <b>fitting</b> is done rapidly by replacing a helical fit with a simplified calculation that is linear in the local hit position in each silicon layer. The calculation is a set of scalar products of the hit coordinates and pre-calculated constants that take into account the detector geometry and alignment. While FTK is under construction at ATLAS experiment, the CMS experiment is developing its R&D for online tracking. The CMS R&D exploits a similar approach for real time track reconstruction at much higher rates in the CMS upgraded experiment that should take data after 2020. In this thesis is briefly described the Large Hadron Collider and the ATLAS experiment in Chapter 1. Chapter 2 shows the Fast TracKer project, and a description of the main parts of the system. Chapter 3 describes the Associative Memory system, and the detailed description of the main elements of the system. The main activities and results of my PhD studies are described in this chapter. I designed the motherboard (AMB) and the daughter-board (LAMB). I performed an interesting study concerning signal integrity in an high serial links density PCB. I presented these results in San Diego 2015 IEEE Nuclear Science Symposium and Medical Imaging Conference, and the results have been published on a journal article on IEEE Transactions on Nuclear Science. I designed the programmable logic and wrote the VHDL code for the FPGAs on those boards. I gave my contribution and advise to design the AM-chip package, and the new generation of AM-chip. At the end of the Chapter 3 there are also the tests, results and validation procedure that I performed before the production and installation phase. The final results and performances are described in Section 3. 6. 3. In Chapter 4 is described the Associative Memory system infrastructure. Since the AM system is a custom processor with high density of power consumption, we designed a dedicated rack layout and designed a custom fan unit in order to maintain the temperatures low. Concerning these issues I designed the PCB with particular care to the power dissipation and the low air flow resistance. I gave also my contribution to the temperature simulations that we performed on the chips, boards and on the crate. These results have been presented in the 20 th IEEE Real Time Conference 2016 and the relative IEEE TNS paper will be published soon. The AM system has been developed for high energy physics, but it is a flexible and powerful embedded system for potential application in a wide range of fields. These future possible evolutions are described in the Chapter 5. I gave my contributions and feedbacks concerning these future applications which are under developing. The very first results have been published and presented in the 14 th Vienna Conference on Instrumentation, and an IEEE TNS paper (to be published) related to the presentation at the 20 th IEEE Real Time Conference 2016. Con il progetto Fast TracKer ed in particolare con il sistema Associative Memory System si vogliono raggiungere prestazioni per l’esecuzione di algoritmi di pattern recognition mai raggiunte prima, rendendo disponibili le sue potenzialità tecnologiche all’ambito della ricerca e della società. Questa tecnologia è costituita da un’unità di processamento, chiamata Processing Unit. La PU è a sua volta composta da numerosi FPGA e da decine di chip full custom di memoria associativa, chiamati AM chip. Nel sistema di Memoria Associativa, l’esecuzione dell’algoritmo di pattern matching è estremante parallelizzato, infatti è eseguito da decine di AM chip che lavorano in parallelo. Il risultato è successivamente elaborato da decine di FPGA. La PU è stata sviluppata per elaborare dati prodotti in esperimenti nel campo della fisica delle alte energie, e il suo scopo è quello di ricostruire in tempo reale tutte le tracce prodotte in esperimenti ai collisori adronici. Questo è un compito cruciale per la riuscita di tali esperimenti. In questo ambito i processi di fisica più interessanti sono molto rari e sono nascosti da un rumore di fondo ordini di grandezza più grande. Selezionare i set di dati (chiamati eventi) interessanti in tempo reale è essenziale, poichè è impossibile salvare tutti i dati prodotti per un’analisi successiva. Solo 1 evento su 107 può essere salvato su disco per analisi successive. Quindi la selezione degli eventi deve essere estremamente accurata e veloce. I sistemi di tracciatura e in particolare quelli in silicio, che stanno diventando sempre più predominanti, giocano un ruolo fondamentale nell’identificazione di eventi interessanti. Infatti forniscono informazioni molto dettagliate e possono discriminare le differenti traiettorie di particelle prodotte in collisioni simultanee all’interno dello stesso evento. D’altro canto, questi sistemi di tracciatura in silicio hanno centinaia di milioni di canali di lettura in uscita, che rendono il problema della completa tracciatura di un evento una sfida impossibile anche per grandi computer farm. Gli eventi contengono decine di collisioni non interessanti sovrapposte a quella interessante e questo livello di confusione è dovuto all’alta frequenza di collisioni necessaria a produrre particelle rare, come il Bosone di Higgs scoperto al CERN. Queste condizioni saranno sempre più estreme in esterimenti futuri. Il Large Hadron Collider al CERN produrrà 80 collisioni sovrapposte per ogni singolo evento entro il 2020 e questo numero supererà il centinaio negli anni successivi. D’altro canto anche lo stato dell’arte dell’elettronica è migliorato in termini di prestazioni ed è quindi|$|R

