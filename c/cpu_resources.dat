380|455|Public
5|$|The V7 {{client is}} {{the seventh and}} latest {{generation}} of the Folding@home client software, and is a full rewrite and unification of the prior clients for Windows, macOS, and Linux operating systems. It was released on March22, 2012. Like its predecessors, V7 can run Folding@home in the background at a very low priority, allowing other applications to use <b>CPU</b> <b>resources</b> as they need. It is designed to make the installation, start-up, and operation more user-friendly for novices, and offer greater scientific flexibility to researchers than prior clients. V7 uses Trac for managing its bug tickets so that users can see its development process and provide feedback.|$|E
5|$|To {{implement}} {{the transformation of}} the creature based on its alignment, Alex Evans developed an exporter program to export 3D Studio Max's models and animations, and Roberts created one to import them and apply them to the lion. Each version of the creature was then loaded, and interpolation code was written, as well as a blended animation between two similar ones. The system has a two-way blend: one for the alignment, and the other for how fat the creature is. As there {{was not going to be}} many creatures on one map, the team were able to use <b>CPU</b> <b>resources</b> to run many animations simultaneously on a single creature.|$|E
25|$|Windows Vista also {{includes}} a new Multimedia Class Scheduler Service (MMCSS) that allows multimedia applications to register their time-critical processing to run at an elevated thread priority, thus ensuring prioritized access to <b>CPU</b> <b>resources</b> for time-sensitive DSP processing and mixing tasks.|$|E
3000|$|Equations (2) and (3) {{represent}} the capacity constraints, where ReqCPU(i) indicates the <b>CPU</b> <b>resource</b> requests for i virtual node, CPU(j) represents the total <b>CPU</b> <b>resource</b> for j physical node, ReqBWL(l [...]...|$|R
30|$|To detect stolen <b>CPU,</b> <b>resource</b> over-sharing {{and other}} {{undesirable}} phenomena.|$|R
30|$|Amazon’s CloudWatch API, for {{collecting}} performance data from <b>CPU</b> <b>resource</b> instances.|$|R
25|$|Since Android {{devices are}} usually battery-powered, Android is {{designed}} to manage processes to keep power consumption at a minimum. When an application is not in use the system suspends its operation so that, while available for immediate use rather than closed, it does not use battery power or <b>CPU</b> <b>resources.</b> Android manages the applications stored in memory automatically: when memory is low, the system will begin invisibly and automatically closing inactive processes, starting with {{those that have been}} inactive for longest. Lifehacker reported in 2011 that third-party task killers were doing more harm than good.|$|E
500|$|Like all BOINC projects, Rosetta@home {{runs in the}} {{background}} of the user's computer, using idle computer power, either at or before logging into an account on the host operating system. [...] The program frees resources from the CPU as they are needed by other applications so that normal computer use is unaffected. [...] Many program settings can be specified via user account preferences, including: the maximum percentage of <b>CPU</b> <b>resources</b> the program can use (to control power consumption or heat production from a computer running at sustained capacity), the times of day during which the program can run, and many more.|$|E
2500|$|Soulblighter {{received}} {{considerably more}} {{attention from the}} modding community than either The Fallen Lords or The Wolf Age. Between 2003 and 2013, Project Magma released multiple major patches, each of which included fixes for bugs, graphical problems, gameplay problems, and interface issues, as well as improve the Fear and Loathing tools and the online multiplayer mode. However, each patch also tended to feature one or more [...] "major" [...] enhancement. For example, v1.3.2, developed in association with MythDevelopers in 2003, allowed Soulblighter to run natively under OS X. Also developed in association with MythDevelopers in 2003 was v1.4, which introduced OpenGL support for the OS X version and allowed the player to play Soulblighter with Fallen Lords style gameplay (dubbed vTFL). In 2004, Magma released their first standalone patch, v1.5, which was originally intended as a minor clean-up patch {{for some of the}} problems introduced in v1.4. For example, v1.4 broke a number of fan-developed plug-ins. Additionally, as the developers did not have access to The Fallen Lords source code when designing vTFL, the feature was unreliable. Magma's plan with v1.5 was to get the gameplay and plug-in compatibility back to the standard of Bungie's last official version of the game, but retain the v1.4 features that worked. During development of v1.5, they also gained access to The Fallen Lords source code, and so completely rewrote the vTFL option. Magma's final patch, v1.8, was released in 2013, and added several new game modes to multiplayer gaming, improved the usage of <b>CPU</b> <b>resources,</b> added a new texture decompression code which loads sprite frames twice as fast as before, enhanced both the texture mapping and the pixel shader, and included (for {{the first time in a}} Magma patch) Linux-specific improvements.|$|E
2500|$|Monitoring of host <b>CPU</b> <b>resource</b> {{utilization}} by {{guests and}} protection (limiting CPU usage by guests) ...|$|R
40|$|The {{existing}} <b>CPU</b> <b>resource</b> characterization techniques {{perform well}} for the applications running as individual processes, or distributed applications involving simple interaction between two-party systems, such as traditional client/server or database systems. They do not work when function invocation spans processes and processors in the multithreaded and distributed applications built upon component technologies such as CORBA, COM, and J 2 EE. We introduce a tool to characterize and estimate change impact of <b>CPU</b> <b>resource</b> consumption in such multithreaded and distributed applications. The tool relies on a component-based system monitoring framework to acquire {{the information about the}} <b>CPU</b> <b>resource</b> spent on function invocations, and the system-wide causality propagation regarding such function invocations. As the result, the tool is able to perceive the propagation of CPU consumption across threads, processes and processors. A multi-hyperbolic-tree visualization scheme is also devised to facilitate seamless navigation and inspection of the analysis report regarding CPU consumption characterization and its impact change, along with other aspects of system behaviors. 1...|$|R
3000|$|... {{in view of}} {{the thread}} {{scheduling}} mechanism. The scheme breaks down the obstacle between threads and etasks, allowing the threads of an urgent etask to preempt the <b>CPU</b> <b>resource</b> in real-time.|$|R
5000|$|Windows Process Watcher (WinTop) - To {{watch how}} much of <b>CPU</b> <b>resources</b> are taken by {{individual}} programs ...|$|E
50|$|This service {{should not}} be {{confused}} with the scheduler that allocates <b>CPU</b> <b>resources</b> to processes already in memory.|$|E
50|$|An IDS {{that also}} {{monitors}} encrypted traffic {{can spend a}} large portion of its <b>CPU</b> <b>resources</b> on decrypting incoming data.|$|E
50|$|The Completely Fair Scheduler (CFS) is {{a process}} {{scheduler}} which was merged into the 2.6.23 (October 2007) release of the Linux kernel and is the default scheduler. It handles <b>CPU</b> <b>resource</b> allocation for executing processes, and aims to maximize overall CPU utilization while also maximizing interactive performance.|$|R
3000|$|... where ξ is a core, f is the {{utilized}} frequency for core ξ, and Γ is a computation. The {{transition rule}} specifies that {{the utilization of}} <b>CPU</b> <b>resource</b> on core ξ – which is operating at frequency f – for computation Γ makes the system progress from state [...]...|$|R
30|$|The {{diversity}} of offering at this layer {{leads to a}} practical question: how well does a cloud provider perform {{compared to the other}} providers? For example, how does a CDN application engineer compare the cost/performance features of CPU, storage, and network resources offered by Amazon EC 2, Microsoft Azure, GoGrid, FelxiScale, TerreMark, and RackSpace. For instance, a low-end <b>CPU</b> <b>resource</b> of Microsoft Azure is 30 % more expensive than the comparable Amazon EC 2 <b>CPU</b> <b>resource,</b> but it can process CDN application workload twice as quickly. Similarly, a CDN application engineer may choose one provider for storage intensive applications and another for computation intensive CDN applications. Hence, there is need to develop novel decision making framework that can analyse existing cloud providers to help CDN service engineers in making optimal selection decisions.|$|R
50|$|On IBM {{mainframes}} {{running the}} z/OS operating system, Intelligent Resource Director (IRD) is software that automates {{the management of}} <b>CPU</b> <b>resources</b> and certain I/O resources.|$|E
5000|$|Performance {{profilers}} (Profiling (computer programming)). The data on {{the performance}} of the software system help to analyze which areas of code consume the most <b>CPU</b> <b>resources.</b>|$|E
50|$|Based on CLISP (a Common Lisp implementation), Simple Grid Protocol allows {{computer}} programs {{to utilize the}} unused <b>CPU</b> <b>resources</b> ofother computers on a network or the Internet.|$|E
3000|$|The value {{distribution}} of the <b>CPU</b> <b>resource</b> value of the physical nodes is [50, 100] and is subject to uniform distribution. The value range of the bandwidth resources of physical links is [50, 100] and is uniformly distributed. The value distribution range of the virtual node <b>CPU</b> <b>resource</b> request amount is [0, 14] and obeys the uniform distribution. The value range of the virtual link bandwidth resource requirement is [0, 34] and follows the uniform distribution. An average of 100 time units can reach 20 virtual network requests among all requests, and these requests obey the Poisson distribution. The number of requests to reach the virtual network in the experiment statistics is 2000, {{and the number of}} runtime units is about 14, 000. The constant values for node and link energy consumption are set as follows: P [...]...|$|R
40|$|We have {{developed}} fully functional Video Server and Client applications which can transmit, receive, decompress and display compressed video over various networks. Our video transport allows dynamic rate control feedback, loss detection and repair request from Clients to the Server. Our experiments show how feedbackbefore -degradation scheme for rate adaptation maintains desired QoS for video playback. We demonstrate how the playback degradation occurs {{and what happens}} if corrective measures are not taken to improve the situation. We attribute this degradation to increased internal kernel buffering which consumes scarce <b>CPU</b> <b>resource.</b> While comparing the ATM performance of our video applications with that of ServerNet, we observe that ServerNet, which provides improved hardware delivery guarantees, can significantly reduce host <b>CPU</b> <b>resource</b> consumption serving video streams. We determine {{the maximum number of}} streams which can be served for each of these two interconnects. The appropria [...] ...|$|R
40|$|The Java {{platform}} {{has many}} characteristics {{that make it}} very desirable for integrated continuous media processing. Unfortunately, it lacks the necessary <b>CPU</b> <b>resource</b> management facility to support quality of service guarantees for soft real-time multimedia tasks. In this paper, we present our new Java Virtual Machine, Q-JVM, which brings <b>CPU</b> <b>resource</b> management to the Java platform. Q-JVM is based on Sun's JVM version 1. 1. 5. It implements an enhanced version of the MTR-LS algorithm in its thread scheduler. Combined with admission control that could be implemented in an application-level resource manager, {{it is able to}} support QoS parameters such as fairness, bandwidth partitioning and delay bound guarantees, as well as the cumulative service guarantee. Our test results show that QJVM is backward compatible with the standard JVM from Sun, has low scheduling overhead, and is able to provide QoS guarantees as specified...|$|R
50|$|These data {{identified}} the Memory Management component as consuming about 20% of <b>CPU</b> <b>resources,</b> {{and was used}} to justify {{a task force to}} try to improve the performance.|$|E
5000|$|... is the {{procedure}} that decides which {{process is the}} next one to receive <b>CPU</b> <b>resources</b> and is thus {{one of the few}} processes that uses the MoveStack instruction.|$|E
50|$|Oracle Resource Manager aims to {{allocate}} <b>CPU</b> <b>resources</b> between users {{and groups of}} users when such resources become scarce.As of Oracle Release 10.2, Database Resource Manager operates in Enterprise Edition.|$|E
40|$|The {{explosive}} {{growth of the}} WWW (World Wide Web) is placing a heavy demand on servers. Thus, improving server performance is important and {{can be achieved by}} scheduling resources more efficiently in operating systems. We have proposed a <b>CPU</b> <b>resource</b> scheduling policy for improving response time of a WWW server. This policy gives preferential use of the <b>CPU</b> <b>resource</b> to any process of a server that is predicted to be a server process handling an HTML file request. This allows users to view text data and the general layout of a WWW page in a timely manner during periods of high demand. In order to determine which processes are server processes handling HTML file requests, we introduced scheduling parameters SLP and RW. In this paper, we describe how we predicted and updated parameter RW based on the behavior of a WWW server, and present experimental validation of our method...|$|R
40|$|International audienceIn an Infrastructure as a Service (IaaS), {{the amount}} of {{resources}} allocated to a virtual machine (VM) at creation time may be expressed with relative values (relative to the hardware, i. e., {{a fraction of the}} capacity of a device) or absolute values (i. e., a performance metric which is independent from the capacity of the hardware). Surprisingly, disk or network resource allocations are expressed with absolute values (bandwidth), but <b>CPU</b> <b>resource</b> allocations are expressed with relative values (a percentage of a processor). The major problem with CPU relative value allocations is that it depends on the capacity of the CPU, which may vary due to different factors (server heterogeneity in a cluster, Dynamic Voltage Frequency Scaling (DVFS)). In this paper, we analyze the side effects and drawbacks of relative allocations. We claim that CPU allocation should be expressed with absolute values. We propose such a <b>CPU</b> <b>resource</b> management system and we demonstrate and evaluate its benefits...|$|R
30|$|Zhang et al. (2010) {{presents}} {{another method}} based on compression approach with data deduplication in migration. By utilizing the self-similarity of run-time memory image, authors apply RLE method during migration to remove redundant memory data. For calculating {{the similarity of}} pages, hash based fingerprints are used. For this, it maintains two FNHash and FPHash LRU hash tables. This approach improves migration performance with space and <b>CPU</b> <b>resource</b> overhead.|$|R
5000|$|The core client also {{downloads}} science applications, {{provides a}} unified logging mechanism, makes sure science application binaries are up-to-date, and schedules <b>CPU</b> <b>resources</b> between science applications (if several are installed).|$|E
50|$|A {{dedicated}} Pulse Width Modulation (PWM) block {{makes it}} possible for the CPU to control power converters, resistive loads, motors, etc., without using lots of <b>CPU</b> <b>resources</b> in tight timer loops.|$|E
50|$|Software-based RAM disks {{remain in}} use as of 2016 {{because they are}} an order of {{magnitude}} faster than other technology, though they consume <b>CPU</b> <b>resources</b> and cost much more on a per-GB basis.|$|E
30|$|In this paper, {{we address}} the problem from a {{different}} perspective: resource management point of view. First, we model resources and computations at fine-grain, {{and the evolution of}} the system as the process of resource consumption; second, we model energy consumption as the cost/consequence of a specific <b>CPU</b> <b>resource</b> allocation; third, the model is energy-aware, and can be used to generate an energy-efficient resource allocation plan for any given computations.|$|R
40|$|We {{present a}} distributed, {{adaptive}} resource allocation approach for multiagent systems called ARAMS. ARAMS allows {{a collection of}} agents to adaptively allocate <b>CPU</b> <b>resource</b> among themselves to handle dynamic events encountered in a noisy and uncertain environment in real-time manner. Each event encountered may incur a CPU shortage crisis in an agent. ARAMS is aimed to reduce the occurrence and amount of shortage crises of each agent {{as well as the}} entire system as a whole. The underlying problem-solving strategy of ARAMS is the integration of a monitor-reactive cycle and a goaldirected coalition formation model. The monitor-reactive cycle requires the agent to monitor the crisis and attempt to fix it on its own. The goal-directed coalition formation allows the agent to ask for help from other agents rationally once it has the resources to do so. Agents also learn how to form better coalitions faster from their past experience. We conducted a series of experiments and the experimental results show that our approach to <b>CPU</b> <b>resource</b> allocation is able to learn and adapt coherently, reacting to and planning for CPU shortages. 1...|$|R
40|$|The {{design of}} an Operating System (OS) {{scheduler}} {{is meant to}} allocate its resources appropriately to all applications. In this paper, we present the scheduling techniques used by two Linux schedulers: O(1) and Completely Fair Scheduler (CFS). CFS is the Linux kernel scheduler that replaces the O(1) scheduler in the 2. 6. 23 kernel. The design goals of CFS are to provide fair <b>CPU</b> <b>resource</b> allocation among executing tasks without sacrificing interactive performance. The ability to achieve good fairness in distributing <b>CPU</b> <b>resource</b> among tasks is important to prevent starvation. However, these design goals have never been scientifically evaluated {{despite the fact that}} there are many conventional operating system benchmarks that are geared towards measuring systems performance in terms of throughput. We therefore scientifically evaluate the design goals of CFS by empirical evaluation. We measure the fairness and interactivity performance by using fairness and interactivity benchmarks. To provide a meaningful representation of results, comparisons of O(1) and CFS kernel schedulers of the open source Linux OS are used. Our experience indicates the CFS does achieve its design goals...|$|R
