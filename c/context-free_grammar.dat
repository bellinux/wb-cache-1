1278|1608|Public
5|$|The chief {{device of}} ancient Hebrew Biblical poetry, {{including}} {{many of the}} psalms, was parallelism, a rhetorical structure in which successive lines reflected each other in grammatical structure, sound structure, notional content, or all three. Parallelism lent itself to antiphonal or call-and-response performance, which could also be reinforced by intonation. Thus, Biblical poetry relies much less on metrical feet to create rhythm, but instead creates rhythm based on much larger sound units of lines, phrases and sentences. Some classical poetry forms, such as Venpa of the Tamil language, had rigid grammars (to {{the point that they}} could be expressed as a <b>context-free</b> <b>grammar)</b> which ensured a rhythm. In Chinese poetry, tones as well as stresses create rhythm. Classical Chinese poetics identifies four tones: the level tone, rising tone, departing tone, and entering tone.|$|E
25|$|Technically, given a <b>context-free</b> <b>grammar,</b> the PDA has {{a single}} state, 1, and its {{transition}} relation is constructed as follows.|$|E
25|$|Every regular grammar is {{context-free}}, {{but not all}} context-free grammars are regular. The following <b>context-free</b> <b>grammar,</b> however, is also regular.|$|E
40|$|AbstractState-alternating <b>context-free</b> <b>grammars</b> are introduced, and the {{language}} classes obtained from them are compared to the classes of the Chomsky hierarchy {{as well as to}} some well-known complexity classes. In particular, state-alternating <b>context-free</b> <b>grammars</b> are compared to alternating <b>context-free</b> <b>grammars</b> (Theoret. Comput. Sci. 67 (1989) 75 – 85) and to alternating pushdown automata. Further, various derivation strategies are considered, and their influence on the expressive power of (state-) alternating <b>context-free</b> <b>grammars</b> is investigated...|$|R
40|$|Extended <b>context-free</b> <b>grammars</b> are <b>context-free</b> <b>grammars</b> {{in which}} the {{right-hand}} sides of productions are allowed to be any regular language rather than being restricted to be any finite language. We develop a novel approach to top-down predictive parser construction for extended <b>context-free</b> <b>grammars</b> {{that is based on}} rewriting of partial syntax trees. This work is motivated by our development of ECFG, a Java toolkit for the manipulation of extended <b>context-free</b> <b>grammars,</b> and by our continuing investigation of XML...|$|R
40|$|<b>Context-free</b> <b>grammars</b> {{have become}} an {{increasingly}} popular solution to procedural text generation. However, standard <b>context-free</b> <b>grammars</b> have inherent limitations with handling state and continuity. This thesis describes the implementation and evaluation of a domain specific language that aims to combine the simplicity of <b>context-free</b> <b>grammars</b> and the expressiveness of high-level programming languages...|$|R
25|$|For a <b>context-free</b> <b>grammar</b> in Greibach normal form, {{defining}} (1,γ) ∈ δ(1,a,A) {{for each}} grammar rule A → aγ also yields an equivalent nondeterministic pushdown automaton.|$|E
25|$|Every <b>context-free</b> <b>grammar</b> can be {{effectively}} {{transformed into a}} weakly equivalent one without unreachable symbols, a weakly equivalent one without unproductive symbols, and a weakly equivalent one without cycles.|$|E
25|$|Every <b>context-free</b> <b>grammar</b> not {{producing}} ε can {{be effectively}} {{transformed into a}} weakly equivalent one without ε-productions; altogether, every such grammar can be effectively transformed into a weakly equivalent proper CFG.|$|E
40|$|Extended <b>context-free</b> <b>grammars</b> are <b>context-free</b> <b>grammars</b> {{in which}} the {{right-hand}} sides of productions are allowed to be any regular language rather than being restricted to only finite languages. We present a novel view on top-down predictive parser construction for extended <b>context-free</b> <b>grammars</b> {{that is based on}} the rewriting of partial syntax trees. This work is motivated by our development of ECFG, a Java toolkit for the manipulation of extended <b>context-free</b> <b>grammars,</b> and by our continuing investigation of XML. © Springer-Verlag Berlin Heidelberg 2003...|$|R
50|$|Languages {{generated}} by <b>context-free</b> <b>grammars</b> {{are known as}} context-free languages (CFL). Different <b>context-free</b> <b>grammars</b> can generate the same context-free language. It is important to distinguish properties of the language (intrinsic properties) from properties of a particular grammar (extrinsic properties). The language equality question (do two given <b>context-free</b> <b>grammars</b> generate the same language?) is undecidable.|$|R
40|$|Document {{specification}} languages {{like for}} instance XML, model documents using extended <b>context-free</b> <b>grammars.</b> These differ from standard <b>context-free</b> <b>grammars</b> {{in that they}} allow arbitrary regular expressions {{on the right-hand side}} of productions. To query such documents, we introduce a new form of attribute grammars (extended AGs) that work directly over extended <b>context-free</b> <b>grammars</b> rather than over standard <b>context-free</b> <b>grammars.</b> Viewed as a query language, extended AGs are particularly relevant as they can take into account the inherent order of the children of a node in a document...|$|R
25|$|The {{formation}} {{rules for}} the terms and formulas of formal logic fit the definition of <b>context-free</b> <b>grammar,</b> except that the set of symbols may be infinite {{and there may be}} more than one start symbol.|$|E
25|$|An {{extended}} <b>context-free</b> <b>grammar</b> (or regular right part grammar) is one {{in which}} the right-hand side of the production rules is allowed to be a regular expression over the grammar's terminals and nonterminals. Extended context-free grammars describe exactly the context-free languages.|$|E
25|$|A common {{example of}} {{ambiguity}} in computer programming languages is the dangling else problem. In many languages, the else in an If–then(–else) statement is optional, {{which results in}} nested conditionals having multiple ways of being recognized {{in terms of the}} <b>context-free</b> <b>grammar.</b>|$|E
25|$|Languages {{generated}} by <b>context-free</b> <b>grammars</b> {{are known as}} context-free languages (CFL). Different <b>context-free</b> <b>grammars</b> can generate the same context-free language. It is important to distinguish {{the properties of the}} language (intrinsic properties) from the properties of a particular grammar (extrinsic properties). The language equality question (do two given <b>context-free</b> <b>grammars</b> generate the same language?) is undecidable.|$|R
50|$|In formal grammar theory, the {{deterministic}} <b>context-free</b> <b>grammars</b> (DCFGs) are {{a proper}} {{subset of the}} <b>context-free</b> <b>grammars.</b> They are the subset of <b>context-free</b> <b>grammars</b> that {{can be derived from}} deterministic pushdown automata, and they generate the deterministic context-free languages. DCFGs are always unambiguous, and are an important subclass of unambiguous CFGs; there are non-deterministic unambiguous CFGs, however.|$|R
40|$|We {{consider}} {{the problem of}} parsing non-recursive <b>context-free</b> <b>grammars,</b> i. e., <b>context-free</b> <b>grammars</b> that generate finite languages. In natural language processing, this problem arises in several areas of application, including natural language generation, speech recognition and machine translation. We present two tabular algorithms for parsing of non-recursive <b>context-free</b> <b>grammars,</b> and show that they perform well in practical settings, {{despite the fact that}} this problem is PSPACEcomplete. ...|$|R
25|$|In {{computer}} science, {{an ambiguous}} grammar is a <b>context-free</b> <b>grammar</b> {{for which there}} exists a string that can {{have more than one}} leftmost derivation or parse tree, while an unambiguous grammar is a <b>context-free</b> <b>grammar</b> for which every valid string has a unique leftmost derivation or parse tree. Many languages admit both ambiguous and unambiguous grammars, while some languages admit only ambiguous grammars. Any non-empty language admits an ambiguous grammar by taking an unambiguous grammar and introducing a duplicate rule or synonym (the only language without ambiguous grammars is the empty language). A language that only admits ambiguous grammars is called an inherently ambiguous language, and there are inherently ambiguous context-free languages. Deterministic context-free grammars are always unambiguous, and are an important subclass of unambiguous grammars; there are non-deterministic unambiguous grammars, however.|$|E
25|$|An L-system is {{context-free}} if each {{production rule}} refers only {{to an individual}} symbol and not to its neighbours. Context-free L-systems are thus specified by a <b>context-free</b> <b>grammar.</b> If a rule depends not only on a single symbol but also on its neighbours, it is termed a context-sensitive L-system.|$|E
25|$|The {{especially}} simple form {{of production}} rules in Chomsky normal form grammars has both {{theoretical and practical}} implications. For instance, given a <b>context-free</b> <b>grammar,</b> one can use the Chomsky normal form to construct a polynomial-time algorithm that decides whether a given string is in the language represented by that grammar or not (the CYK algorithm).|$|E
25|$|In linguistics, {{some authors}} {{use the term}} phrase {{structure}} grammar to refer to <b>context-free</b> <b>grammars,</b> whereby phrase-structure grammars are distinct from dependency grammars. In computer science, a popular notation for <b>context-free</b> <b>grammars</b> is Backus–Naur form, or BNF.|$|R
50|$|Parikh's theorem {{proves that}} some {{context-free}} languages {{can only have}} ambiguous grammars. Such languages are called inherently ambiguous languages. From a formal grammar perspective, this means that some ambiguous <b>context-free</b> <b>grammars</b> cannot be converted to equivalent unambiguous <b>context-free</b> <b>grammars.</b>|$|R
40|$|Phrase-structure grammars are an {{effective}} rep-resentation for important syntactic and semantic aspects of natural languages, but are computa-tionally too demanding {{for use as}} language mod-els in real-time speech recognition. An algorithm is described that computes finite-state approxi-mations for <b>context-free</b> <b>grammars</b> and equivalent augmented phrase-structure grammar formalisms. The approximation is exact for certain <b>context-free</b> <b>grammars</b> generating regular languages, in-cluding all left-linear and right-linear <b>context-free</b> <b>grammars.</b> The algorithm {{has been used to}} con-struct finite-state language models for limited-domain speech recognition tasks. ...|$|R
25|$|The {{efficiency}} of <b>context-free</b> <b>grammar</b> parsing {{is determined by}} the automaton that accepts it. Deterministic context-free grammars are accepted by deterministic pushdown automata and can be parsed in linear time, for example by the LR parser. This is a subset of the context-free grammars which are accepted by the pushdown automaton and can be parsed in polynomial time, for example by the CYK algorithm. Unambiguous context-free grammars can be nondeterministic.|$|E
25|$|This is {{resolved}} {{in various ways}} in different languages. Sometimes the grammar is modified {{so that it is}} unambiguous, such as by requiring an endif statement or making else mandatory. In other cases the grammar is left ambiguous, but the ambiguity {{is resolved}} by making the overall phrase grammar context-sensitive, such as by associating an else with the nearest if. In this latter case the grammar is unambiguous, but the <b>context-free</b> <b>grammar</b> is ambiguous.|$|E
25|$|An {{obvious way}} {{to extend the}} <b>context-free</b> <b>grammar</b> {{formalism}} is to allow nonterminals to have arguments, the values of which are passed along within the rules. This allows natural language features such as agreement and reference, and programming language analogs such as the correct use and definition of identifiers, to be expressed in a natural way. E.g. we can now easily express that in English sentences, the subject and verb must agree in number. In computer science, examples of this approach include affix grammars, attribute grammars, indexed grammars, and Van Wijngaarden two-level grammars. Similar extensions exist in linguistics.|$|E
40|$|AbstractA new {{dynamical}} {{measure of}} the descriptional complexity for <b>context-free</b> <b>grammars</b> and languages, namely the degree of cooperation, is introduced and studied. This measure is connected with respect to both families of languages considered, namely the regular and context-free languages. We prove {{that the degree of}} cooperation is computable for regular and unambigous <b>context-free</b> <b>grammars</b> and it is not computable for arbitrary <b>context-free</b> <b>grammars.</b> The computability status of this measure for languages remains to be investigated...|$|R
40|$|In the {{compiler}} literature, parsing algorithms for <b>context-free</b> <b>grammars</b> {{are presented}} using string rewriting systems or abstract machines such as pushdown automata. Unfortunately, the resulting descriptions can be baroque, {{and even a}} basic understanding of some parsing algorithms, such as Earley’s algorithm for general <b>context-free</b> <b>grammars,</b> can be elusive. In this paper, we present a graphical representation of <b>context-free</b> <b>grammars</b> called the Grammar Flow Graph (GFG) that permits parsing problems to be phrased as path problems in graphs; intuitively, the GFG plays the same role for <b>context-free</b> <b>grammars</b> that nondeterministic finite-state automata play for regular grammars. We show that the GFG permits an elementary treatment of Earley’s algorithm that is much easier to understand than previous descriptions of this algorithm. In addition, look-ahead computation can be expressed as a simple inter-procedural dataflow analysis problem, providing an unexpected link between front-end and back-end technologies in compilers. These results suggest that the GFG can be a new foundation for the study of <b>context-free</b> <b>grammars...</b>|$|R
40|$|We {{present an}} {{algorithm}} for the inference of some Multiple <b>Context-Free</b> <b>Grammars</b> from Membership and Equivalence Queries, using the Minimally Adequate Teacher model of Angluin. This {{is an extension}} of the congruence based methods for learning some <b>Context-Free</b> <b>Grammars</b> proposed by Clark (ICGI 2010). We define the natural extension of the syntactic congruence to tuples of strings, and demonstrate we can efficiently learn the class of Multiple <b>Context-Free</b> <b>Grammars</b> where the non-terminals correspond to the congruence classes under this relation...|$|R
25|$|Every <b>context-free</b> <b>grammar</b> can be {{transformed}} into an equivalent nondeterministic pushdown automaton. The derivation process of the grammar is simulated in a leftmost way. Where the grammar rewrites a nonterminal, the PDA takes the topmost nonterminal from its stack and replaces it by the right-hand part of a grammatical rule (expand). Where the grammar generates a terminal symbol, the PDA reads a symbol from input when it is the topmost symbol on the stack (match). In a sense the stack of the PDA contains the unprocessed data of the grammar, corresponding to a pre-order traversal of a derivation tree.|$|E
2500|$|Given a <b>context-free</b> <b>grammar,</b> does it {{describe}} a regular language? ...|$|E
2500|$|Similar to a CFG, a {{probabilistic}} <b>context-free</b> <b>grammar</b> [...] can {{be defined}} by a quintuple: ...|$|E
40|$|<b>Context-free</b> <b>grammars</b> {{cannot be}} {{identified}} in the limit from positive examples (Gold, 1967), yet natural language grammars are more powerful than <b>context-free</b> <b>grammars</b> and humans learn them with remarkable ease from positive examples (Marcus, 1993). Identifiability results for formal languages ignore a potentially powerful source of information available to learners of natural languages, namely, meanings. This paper explores the learnability of <b>context-free</b> <b>grammars</b> given positive examples and lexical semantics. That is, the learner has {{a representation of the}} meaning of each lexical item...|$|R
5000|$|... #Subtitle level 4: Extensible <b>Context-Free</b> <b>Grammars</b> (Wegbreit) ...|$|R
5000|$|... #Subtitle level 2: Language {{equations}} and <b>context-free</b> <b>grammars</b> ...|$|R
