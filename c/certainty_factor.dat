158|126|Public
50|$|In 2015, WSC {{introduced}} a new element to the Scholar's Challenge, the <b>certainty</b> <b>factor.</b> Whereas normal multiple choice quizzes let you pick one answer per question, the <b>certainty</b> <b>factor</b> allowed scholars to choose multiple answers for each question. The number of points scored is inversely proportional {{to the number of}} answers chosen. For example, if a scholar chose one choice and got it right, they would score a point. If they chose two answers and one was right, they would score 1/2 a point. If they chose three and one was right, they would score 1/3 of a point, and so forth. If time was running out, a student could shade in all five answers and automatically win 1/5 of a point.|$|E
50|$|Subsequent studies later {{showed that}} the <b>certainty</b> <b>factor</b> model could indeed be {{interpreted}} in a probabilistic sense, and highlighted problems with the implied assumptions of such a model. However the modular structure of the system would prove very successful, leading {{to the development of}} graphical models such as Bayesian networks.|$|E
5000|$|In MYCIN it was {{possible}} that two or more rules might draw conclusions about a parameter with different weights of evidence. For example one rule may conclude that the organism in question is E. Coli with a certainty of 0.8 whilst another concludes that it is E. Coli with a certainty of 0.5 or even -0.8. In the event the certainty is less than zero the evidence is actually against the hypothesis. In order to calculate the <b>certainty</b> <b>factor</b> MYCIN combined these weights using the formula below to yield a single certainty factor: ...|$|E
40|$|An {{expert system}} {{inference}} engine is described {{which is based}} on the utilization of <b>certainty</b> <b>factors,</b> and has a structure similar to Naylor's probabilistic inference engine. After {{a brief description of the}} latter, a modified probabilistic criterion is developed which naturally leads to the <b>certainty</b> <b>factors</b> question selection criterion employed in the inference engine. Also, the case in which there is user reporting bias is considered, and a method for dealing with it is presented. The paper discusses the required aspects of the model of <b>certainty</b> <b>factors,</b> and presents the major implementation issues relating to the new inference engine, which is written in pascal. Â© 1994...|$|R
40|$|This paper {{joins the}} effort in {{developing}} new techniques for zoning landslide hazard. The favourability modeling (FM) approach, a frame-work for implementing quantitative techniques, is suggested for spatial data integration using <b>certainty</b> <b>factors</b> (CF). The framework solves {{some of the problems}} associated with zoning and geographic information systems (GIS), the first being the dilemma of selecting either a qualita-tive or quantitative approach. Favourability modeling with <b>certainty</b> <b>factors</b> is a good com-promise, offering a valid quantitative method, where subjectivity or expert knowledge can be incorporated in the analysis, particularly when data are not sufficient or reliable...|$|R
40|$|Uncertainty {{processing}} methods are analysed {{from the viewpoint}} of their sensitivity to small variations of <b>certainty</b> <b>factors.</b> The analysis makes use of the algebraic theory which defines the function for combining partial <b>certainty</b> <b>factors</b> by means of a group operation of the ordered Abelian group over the interval of uncertainty. Two approaches are introduced: (a) sensitivity analysis of the inference network and (b) calculation of second order probabilities. Sensitivity functions are defined as partial derivatives of the combining function with respect to their arguments. Based on the sensitivity functions, we define the path sensitivity which measures the sensitivity of a larger part of the inference network. If a set of samples of <b>certainty</b> <b>factors</b> is available instead of a single value, the second order probability distribution can be approximated by the distribution of an average value. It is shown that the parametric form of the distribution is completely determined by the combining function. ...|$|R
40|$|In this paper, we {{prove that}} the EMYCIN formula for the {{sequential}} propagation can be derived strictly from {{the definition of the}} <b>certainty</b> <b>factor</b> according to probability theory. Some researchers think that this combination formula is inconsistent with the definition of <b>certainty</b> <b>factor</b> in the sense of probability theory. This was not correct. Moreover, under the condition that there exists no need for prior probabilities to be supplied with values, we reformulate the parallel propagation from the definition of the <b>certainty</b> <b>factor</b> according to probability theory. Therefore, the paper normalizes the relationship between the definition of the <b>certainty</b> <b>factor</b> and combination formulae for sequential and parallel propagations. In conclusion, this paper demonstrated that the <b>certainty</b> <b>factor</b> model can be built on the foundation of probability theory. Keywords: Uncertainty, Expert System, Prior Probability, Extension Conditional Probability, <b>Certainty</b> <b>Factor,</b> Ternary Rule Strength. 1 Int [...] ...|$|E
40|$|Error based pruning {{can be used}} {{to prune}} a {{decision}} tree and it does not require the use of validation data. It is implemented in the widely used C 4. 5 decision tree software. It uses a parameter, the <b>certainty</b> <b>factor,</b> that affects the size of the pruned tree. Several researchers have compared error based pruning with other approaches, and have shown results that suggest that error based pruning results in larger trees that give no increase in accuracy. They further suggest that as more data is added to the training set, the tree size after applying error based pruning continues to grow even though there is no increase in accuracy. It appears that these results were obtained with the default <b>certainty</b> <b>factor</b> value. Here, we show that varying the <b>certainty</b> <b>factor</b> allows significantly smaller trees to be obtained with minimal or no accuracy loss. Also, the growth of tree size with added data can be halted with an appropriate choice of <b>certainty</b> <b>factor.</b> Methods of determining the <b>certainty</b> <b>factor</b> are discussed for both small and large data sets. Experimental results support the conclusion that error based pruning {{can be used to}} produce appropriately sized trees with good accuracy when compared with reduced error pruning...|$|E
40|$|A {{method is}} {{described}} for using Radial Basis Function (RBF) neural networks {{to generate a}} <b>certainty</b> <b>factor</b> reliability measure along with the network's normal output. The <b>certainty</b> <b>factor</b> approach is then compared with another technique for measuring RBF reliability, Parzen windows. Both methods are implemented into RBF networks, {{and the results of}} using each approach are compared. Advantages and disadvantages of each approach are discussed. Results indicate that certainty factors are a superior reliability measure...|$|E
50|$|Where X and Y are the <b>certainty</b> <b>factors.</b> This formula can {{be applied}} more than once if more than two rules draw {{conclusions}} about the same parameter. It is commutative, so {{it does not matter}} in which order the weights were combined.|$|R
40|$|Rule-based {{expert systems}} may be {{structurally}} and functionally mapped onto a special class of neural networks called expert networks. This mapping {{lends itself to}} adaptation of connectionist learning strategies for the expert networks. A parsing algorithm to translate C Language Integrated Production System (CLIPS) rules into a network of interconnected assertion and operation nodes has been developed. The translation of CLIPS rules to an expert network and back again is illustrated. Measures of uncertainty similar to those rules in MYCIN-like systems are introduced into the CLIPS system and techniques for combining and hiring nodes in the network based on rule-firing with these <b>certainty</b> <b>factors</b> in the expert system are presented. Several learning algorithms are under study which automate the process of attaching <b>certainty</b> <b>factors</b> to rules...|$|R
40|$|This paper {{joins the}} effort in {{developing}} new techniques for zoning landslide hazard. The favourability modeling (FM) approach, a framework for implementing quantitative techniques, is suggested for spatial data integration using <b>certainty</b> <b>factors</b> (CF). The framework solves {{some of the problems}} associated with zoning and geographic information systems (GIS), the first being the dilemma of selecting either a qualitative or quantitative approach. Favourability modeling with <b>certainty</b> <b>factors</b> is a good compromise, offering a valid quantitative method, where subjectivity or expert knowledge can be incorporated in the analysis, particularly when data are not sufficient or reliable. A second problem is associated with the popularity of thematic data which may limit the establishment of quantitative models. With favourability modeling, thematic data are transformed into continuous data, by considering the degree of relationship, using <b>certainty</b> <b>factors</b> in this paper, between the hazard and classes of each map. Another issue concerns the rigidity of some quantitative techniques. As it may be more effective to use surrogates, simply because of the cost, accessibility, or difficulty of measuring the original property, the FM approach provides the advantage of flexibility as results are generated independently from the input data. The technique is also capable of zoning more than one type of geological hazard. Landslide hazard maps were generated from a 1960 dataset, and compared with the occurrenc...|$|R
40|$|With {{the rapid}} {{advancement}} {{of technology and}} information at this time, it had and impact {{on the progress of}} computerâs development. Particulary in the health world. Application of artificial intelligence in the website is a form of these technologies development. The purpose of this research is to develop an artificial intelligence application that is a able to diagnose malaria in children, making it easier for the user to know what diseases suffered and what the appropariate treatment solution with a fitted value of confidence in the diagnose. The confidence value is obtained by using a method called the <b>certainty</b> <b>factor.</b> <b>Certainty</b> <b>factor</b> is one of the techniques used to overcome uncertainty in decision making. <b>Certainty</b> <b>factor</b> can occur with a variety of conditions. Among them is a condition that occurs, there are several different rule with a consequent same. The results of this study shows that diagnosis expert system malaria by using <b>certainty</b> <b>factor</b> method can help folving problem malaria in children. This system will provide information what kind of malaria disease in the suffering of patients and solutions what treatment which is given...|$|E
30|$|A {{level shift}} is {{perceived}} better as more observations are seen out-of-control limits, i.e., as n is increasing. However, {{even a single}} out-of- control limit observation can signal a true level shift with a <b>certainty</b> <b>factor</b> of p(B|Aâ²). In other words, with probability 1 âp(B|Aâ²), such a single observation could {{be associated with a}} spike or an outlier and not a true level shift. Thus, our <b>certainty</b> <b>factor</b> improves as more out-of-control limit data are seen (i.e. as n increases), causing the probability p(B|Aâ²) to increase.|$|E
40|$|Development of {{computer}} technology is very rapid effects on human life, not least in the world ealth. Application of expert system in the website and mobile with JSP and J 2 ME is one manifestation {{of the development of}} these technologies. This final project built an expert system that can diagnose and provide therapy in diabetes Nephropathy and completed with a confidence alue of the diagnosis. Confidence value is obtained by using method called <b>certainty</b> <b>factor.</b> <b>Certainty</b> <b>factor</b> is a method used in MYCIN in the mid of 1970, in anticipation of knowledge is usually incomplete and uncertain. By providing accurate knowledge based on nowledge and followed by test conducted which is done seriously, it is expected that this system can help to make diagnosis and provide therapy of diabetes mellitus correctly and accurately. Keywords: Expert System, <b>Certainty</b> <b>factor,</b> Diabetes Nephropathy, JSP, J 2 ME...|$|E
40|$|The {{development}} of expert systemsâbased applications {{has been very}} popular since 1950, with a rather wide coverage. Expert systems in organizations are aimed at adding value, increasing productivity and assisting management to take quick decisions. Similarly, organization engaging in the farming industry, while very promising, requires high awareness against diseases, such as poultry (chicken) which are very susceptible to various types of diseases caused by viruses or bacteria. Benefits of implementing the expert system are that they can diagnose the symptoms of diseases quickly and accurately and {{they are expected to}} be able to help farmers in anticipating the losses resulting from disease attack. Accurate and precise calculations are required to diagnose symptoms in order to conclude the output by means of the <b>Certainty</b> <b>Factors</b> (CFs) Keywords: expert system, diagnosing the diseases, method of <b>Certainty</b> <b>Factors</b> (CFs...|$|R
50|$|Many {{reasoning}} systems provide capabilities for reasoning under uncertainty. This {{is important}} when building situated reasoning agents which {{must deal with}} uncertain representations of the world. There are several common approaches to handling uncertainty. These {{include the use of}} <b>certainty</b> <b>factors,</b> probabilistic methods such as Bayesian inference or Dempster-Shafer theory, multi-valued (âfuzzyâ) logic and various connectionist approaches.|$|R
40|$|A {{new method}} for the {{sequential}} clustering of data, that gives better results {{compared to the}} conventional sequential clustering method, is presented in this paper. This method utilizes <b>certainty</b> <b>factors</b> and it is independent of the technique used for data representation and/or distance computation. Examples are given for cases where the data are represented as feature vectors as well as strings of symbols (syntactic patterns). Â© 1989...|$|R
40|$|The {{starting}} point of rough set theory is an information system. The information system contains data about objects of interest characterized in terms of some attributes. If we distinguish condition and decision attributes in the information system, then such a system is called a decision table. To every subset of attributes we associate a set of formulas. The decision table contains a set of decision rules. For every decision rule we associate a conditional probability which is called <b>certainty</b> <b>factor.</b> In this paper, we define the so called very positive, positive, boundary and negative regions for a decision based on the <b>certainty</b> <b>factor.</b> These regions divide the set of formulas on condition attributes according to <b>certainty</b> <b>factor</b> of decision rules. Then, some interesting relations among these divided sets of formulas are proved which are useful in decision making. Finally, a numerical example is given to show the potential application of our theoretical findings regarding selection of candidates to a school...|$|E
40|$|An {{experiment}} replicated {{and extended}} recent findings on psychologically realistic ways of modeling propagation of uncertainty in rule based reasoning. Within a single production rule, the antecedent evidence {{can be summarized}} by taking the maximum of disjunctively connected antecedents and the minimum of conjunctively connected antecedents. The maximum <b>certainty</b> <b>factor</b> attached {{to each of the}} rule's conclusions can be sealed down by multiplication with this summarized antecedent certainty. Heckerman's modified <b>certainty</b> <b>factor</b> technique can be used to combine certainties for common conclusions across production rules. Comment: Appears in Proceedings of the Sixth Conference on Uncertainty in Artificial Intelligence (UAI 1990...|$|E
40|$|It {{has been}} {{asserted}} that, using traditional pruning methods, growing decision trees with increasingly larger amounts of training data {{will result in}} larger tree sizes even when accuracy does not increase. With regard to error-based pruning, the experimental data used to illustrate this assertion have apparently been obtained using the default setting for pruning strength; in particular, using the default <b>certainty</b> <b>factor</b> of 25 in the C 4. 5 decision tree implementation. We show that, in general, an appropriate setting of the <b>certainty</b> <b>factor</b> for error-based pruning will cause decision tree size to plateau when accuracy is not increasing with more training data. 1...|$|E
40|$|Abstract: In {{this paper}} we discuss {{reasoning}} under uncertainty in distributed, adaptive and multiagent rule-based expert systems. It was shown that a multiple activation of rules is a main property of these systems. On the contrary to traditional systems such a multiple activation may lead to false results. Some solutio ns of this problem designed for the <b>certainty</b> <b>factors</b> model and the Dempster-Schafer theory are presented...|$|R
40|$|This paper {{describes}} Rapture [...] {{a system}} for revising probabilistic knowledge bases that combines connectionist and symbolic learning methods. Rapture uses {{a modified version of}} backpropagation to refine the <b>certainty</b> <b>factors</b> of a probabilistic rule base and it uses ID 3 's information-gain heuristic to add new rules. Results on refining three actual expert knowledge bases demonstrate that this combined approach generally performs better than previous methods...|$|R
40|$|This paper {{describes}} Rapture [...] {{a system}} for revising probabilistic theories that combines symbolic and neural-network learning methods. Rapture uses {{a modified version of}} backpropagation to refine the <b>certainty</b> <b>factors</b> of a Mycin-style rule-base and it uses ID 3 's information gain heuristic to add new rules. Results on two real-world domains demonstrate that this combined approach performs as well or better than previous methods...|$|R
40|$|Tuberculosis is {{not only}} attacking the lungs (called {{pulmonary}} Tuberculosis), but it also can infect other organs such as the brain (Miningitis Tuberculosis), lymphatic (Lymphedenopathy Tuberculosis), lung (Pleyrisy Tuberculosis), skin (Miliary Tuberculosis), Spin of Tuberculosis, and urogenital tuberculosis. The algorithm used in the diagnosis is the algorithm <b>Certainty</b> <b>Factor.</b> there are 6 tuberkulosis disease that will be diagnosed such as Pulmonary TB, TB Miningitis, TB lymphadenopathy, TB Pleurisy, TB of the Spine, and urogenital tuberculosis. While the number of symptoms that {{will be asked to}} the user there are 31 symptoms. The number of rules stored in the knowledge base amounted to 52 rules. Results of applications made available a similar conclusion with manual calculations using formulas <b>certainty</b> <b>factor.</b> ...|$|E
40|$|Expert {{system is}} a program {{that can be used}} to help provide {{alternatives}} or solutions with quality experts to solve problems from a specific domain. Systems experts act as consultants who can explain the steps that must be pursued to a conclusion and decision. The existence of a web-based expert system that will better help the users of an expert system to conduct the consultation process. Conclusion or decision given by an expert would be more convincing to users of expert systems, especially in decision-making process that requires quick time, for example the handling of a car engine failure, the decision making process with a web-based expert system that includes a method of <b>certainty</b> <b>factor</b> is expected to be more helpful handling process damage the engine. Web-based expert system with <b>certainty</b> <b>factor</b> method begins by answering questions from the symptoms of existing symptoms, so that the answers will be found. The result of the recommendations of this expert system in the form of damage to a car engine that includes the value of <b>certainty</b> <b>factor</b> as a measure to convince users that the recommendations of an expert system are given fairly good...|$|E
40|$|Health is {{something}} that is very valuable. Along the changing times, the type disease are growing. Disease in {{is one of the most}} common diseases. Disease in having a diverse indications and symptoms that appear almost similar. One is a disease caused by the animal. This causes a lot of medical personel, even ordinary people struggle to identify types of illness. One tool that is very helpful in making the diagnosis of the disease is an expert system. Expert systems in general is trying to adopt a system of human knowledge to the computer. Applications developed an expert system that is used to diagnose diseases caused by animals with <b>Certainty</b> <b>Factor</b> method. Diagnosis is done by analyzing the input symptoms of questions about what is perceived by the patient. The results of the analysis then checked against the results of the doctor's diagnosis to find out the truth. Programs created using the programming language Visual Basic 6. 0 and Microsoft Access databases. The results of an expert system for the analysis of diseases caused by these animals are three alternatives in the disease are presented in order of the value of the <b>certainty</b> <b>factor</b> of the greatest. The value of the <b>certainty</b> <b>factor</b> depends on the number of entries matching the symptoms of the disease as well as the value of the <b>certainty</b> <b>factor</b> per correlation between symptoms and diseases. It is expected that with the making of this expert system can be used by the public as a reference to an early diagnosis of diseases caused by animals and as a tool for doctors to diagnose patients more accurately and carefull...|$|E
40|$|Verification of knowledge-bases is a {{critical}} step {{to ensure the quality}} of a knowledge-based system. The success of these systems depends heavily on how qualitative the knowledge is. Manual verification is however cumbersome and error prone, especially for large knowledge-bases. This thesis provides a design theory, based upon the suggested framework by Gregor and Jones (2007). The theory proposes a general design of automated verification tools, which have the abilities of verifying heuristic knowledge in rule-based systems utilizing <b>certainty</b> <b>factors.</b> Included is a verification of completeness and consistency technique customized to this class of knowledge-based systems. The design theory is instantiated in a real-world verification tool development project at Uppsala University. Considerable attention is given to the design and implementation of this artifact â uncovering issues and considerations involved in the development process. For the knowledge management practitioner, this thesis offers guidance and recommendations for automated verification tool development projects. For the IS research community, the thesis contributes with extensions of existing design theory, and reveals some of the complexity involved with verification of a specific rule-based system utilizing <b>certainty</b> <b>factors...</b>|$|R
40|$|Abstract. In this paper, {{we present}} an expert system, called PASS (Predicting Ability of Students to Succeed), {{which is used}} to predict how certain is that a student of a {{specific}} type of high school in Greece will pass the national exams for entering a higher education institute. Prediction is made at two points. An initial prediction is made after the second year of studies and the final {{after the end of the}} first semester of the third (last) year of studies. Predictions are based on various types of studentâs data. The aim is to use the predictions to provide suitable support to the students during their studies towards the national exams. PASS is a rule-based system that uses a type of <b>certainty</b> <b>factors.</b> We introduce a generalized parametric formula for combining the <b>certainty</b> <b>factors</b> of two rules with the same conclusion. The values of the parameters (weights) are determined via training, before the system is used. Experimental results show that PASS is comparable to Logistic Regression, a well-known statistical method. ...|$|R
40|$|The {{purpose of}} the Expert System CRN 5 EXP is to assist in {{checking}} {{the quality of the}} coils at two very important mills: Hot Rolling and Cold Rolling in a steel plant. The system interprets the statistical quality control charts, diagnoses and predicts the quality of the steel. Measurements of process control variables are recorded in a database and sample statistics such as the mean and the range are computed and plotted on a control chart. The chart is analyzed through patterns using the C Language Integrated Production System (CLIPS) and a forward chaining technique to reach a conclusion about the causes of defects and to take management measures for the improvement of the quality control techniques. The Expert System combines the <b>certainty</b> <b>factors</b> associated with the process control variables to predict the quality of the steel. The paper presents the approach to extract data from the database, the reason to combine <b>certainty</b> <b>factors,</b> the architecture {{and the use of the}} Expert System. However, the interpretation of control charts patterns requires the human expert's knowledge and lends to Expert Systems rules...|$|R
40|$|Real {{world is}} {{actually}} revolving around data i. e. data plays {{a very important}} role in the currentinformation era. Different types of uncertainty are addressed in different forms of data. Till date,probabilistic theory, fuzzy logic, <b>certainty</b> <b>factor</b> was developed to handle uncertainty. All these approacheswere quite successful in handling uncertainty but there are some situations where when these methods takenindividually, failed to handle uncertainty. So there was a need to develop a hybrid approach which willhandle uncertainty to a high level. In this paper, we present an approach wherein we integrate probabilistic theory, <b>certainty</b> <b>factor</b> and fuzzylogic concepts. Once we use all these approaches together, uncertainty model is developed which will addressthe various limitations inherent in these approaches when applied individually...|$|E
40|$|In this paper, we {{investigate}} {{the problem of}} interpretation uncertainty caused by the conventional deterministic approaches to drawing image understanding from the three view points of homograph, heuristic knowledge and data ambiguity. To reduce these three factors of uncertainties, we propose new paradigm with context-sensitive and hierarchical interpretation for homograph, multiple-interpretation for heuristic knowledge, and finally a <b>certainty</b> <b>factor</b> for data ambiguity. The validity of this paradigm is investigated by establishing a structure analysis system for drawing images with five hierarchical levels The interpretation proceeds from the lower level to the higher level in bottom-up manner using heuristic knowledge described as rules in a production system The heuristic knowledge is effectively used to compute or modify the <b>certainty</b> <b>factor</b> of multipleinterpretation in context-sensitive manner. I...|$|E
40|$|On the {{development}} of medical knowledge-based system, the inability of a patient in a complaint {{must be dealt with}} by the fuzzy logic method, while the inability of an expert in defining the relationship between the symptoms of the disease can be treated with <b>certainty</b> <b>factor</b> method. In this study, both methods were combined to make diagnosis of tropical infectious diseases. Knowledge acquired from medical specialist in internal medicine, with produce fact, a crisp and fuzzy symptoms, and rule with the certainty value of the specialist. Reasoning process starts from the implication, decomposition, defuzzification and <b>certainty</b> <b>factor</b> calculation. System developed on web based platform and provide a workplace, explanation facility and knowledge improvement. System testing is done to compare the results of specialist diagnosis and system diagnosis, which results of testing show the system, has similarity with the expert at 91. 07 %...|$|E
40|$|An {{expert system}} is being {{developed}} using CLIPS to assist clinicians {{in the analysis of}} multivariate flow cytometry data from cancer patients. Cluster analysis is used to find subpopulations representing various cell types in multiple datasets each consisting of four to five measurements on each of 5000 cells. CLIPS facts are derived from results of the clustering. CLIPS rules are based on the expertise of Drs. Stewart, Duque, and Braylan. The rules incorporate <b>certainty</b> <b>factors</b> based on case histories...|$|R
40|$|The {{uncertainty}} and unexpectedness of security risk makes it exceedingly challenging {{to assess and}} monitor. This paper outlines a hybrid approach which factors in the uncertainty, unexpectedness and complexity of risk. In this work, IT security risk in an organization is evaluated using and expert system which utilizes fuzzy reasoning and <b>certainty</b> <b>factors.</b> Since often the value of risk comes with some level of believe, uncertainty is calculated and presented {{as part of the}} output in the system...|$|R
40|$|Although the {{traditional}} knowledge representation based on rules {{is simple and}} explicit, it is not effective {{in the field of}} syndrome differentiation in Traditional Chinese Medicine (TCM), which involves many uncertain concepts. To represent uncertain knowledge of syndrome differentiation in TCM, two methods were presented respectively based on <b>certainty</b> <b>factors</b> and <b>certainty</b> intervals. Exploiting these two methods, an approach to syndrome differentiation in TCM was proposed based on neural networks to avoid some limitations of other approaches. The main advantage of the approach is that it may realize uncertain inference of syndrome differentiation in TCM, whereas it doesn't request experts to provide all possible combinations for certainty degrees of symptoms and syndromes. Rather than Back Propagation (BP) algorithm but its modification was employed to improve the capability of generalization of neural networks. First, the standard feedforward multilayer BP neural network and its modification were introduced. Next, two methods for knowledge representation, respectively based on <b>certainty</b> <b>factors</b> and <b>certainty</b> intervals, were presented Then, the algorithm was proposed based on neural network for the uncertain inference of syndrome differentiation in TCM. Finally, an example was demonstrated to illustrate the algorithm...|$|R
