2|3091|Public
50|$|In {{broadcast}} systems, {{an analog}} generator-lock signal usually consists of {{vertical and horizontal}} synchronizing pulses together with chrominance phase reference {{in the form of}} colorburst. No picture information is usually carried to avoid disturbing the timing signals, and the name reference, black and burst, color black, or black burst is usually given to such a signal. A composite <b>colour</b> <b>video</b> <b>signal</b> inherently carries the same reference signals and {{can be used as a}} generator-locking signal, albeit at the risk of being disturbed by out-of-specification picture signals.|$|E
40|$|In this paper, a {{new digital}} {{intermediate}} fre-quency modulator for conventional TV signals using {{digital signal processing}} is presented. A composite <b>colour</b> <b>video</b> <b>signal</b> and two associated audio signals are converted into a digital composite TV signal with spectrum at intermediate frequency. The modulator is designed for the high quality require-ments that exist in professional equipment for CATV head ends. The architecture of the digital modulator shown is optimized for an implementa-tion with ASICs. The signal processing with reduced complexity is described in detail, the structures and {{the design of the}} filters are illustrated and the simulated results are presented. 1...|$|E
40|$|This paper {{describes}} {{a method for}} incorporating the chrominance information when estimating motion in a colour image sequence. It {{is based on a}} Maximum-Likelihood (ML) formulation of the motion estimation problem which assumes homogeneous additive Gaussian noise in each colour component, with known inter-field correlation statistics. It defines a noise-decorrelating colour space transform which provides a simple implementation of the ML formulation. Results for noisy synthesised colour sequences with known motion and noise statistics demonstrate the superiority of the exact ML formulation over straightforward, unweighted three-component estimation, most noticeably in high noise conditions. 1 Introduction <b>Colour</b> <b>video</b> <b>signals</b> consist of both luminance (intensity) and chrominance information. The chrominance has two degrees of freedom, so a full colour signal consists of three fields for every frame. There are a variety of representations of these three fields, most commonly defined a [...] ...|$|R
40|$|Abstract:Quality of the <b>Colour</b> Composite <b>video</b> <b>signal</b> {{has become}} the basic {{criteria}} of today’s TV transmission systems (Terrestrial / Satellite / Cable). Video streaming is increasingly finding its way in day-to-day lives of people. The videos typically passes through several processing stages {{before they reach the}} end user. The effect of most processing stages is to degrade the quality of the video that passes through it. The only reliable method to assess the video quality perceived by a human observer is to ask human subjects for their opinion, which is termed subjective video quality assessment (VQA). Subjective VQA is impractical for most applications due to the human involvement in the process. Hence we go for objective analysis, which includes the verifying <b>Colour</b> Composite <b>Video</b> <b>Signal</b> parameters like sync pulses, colour burst and the luminance. The need to have a low cost video switcher and a CCVS analyzer with high performance and to easily carry the analyzer equipment from one place to other i. e., a portable system, made us to develop the low cost microcontroller based automatic video switcher and CCVS analyzer. Keywords:Colour composite <b>video</b> <b>signal,</b> <b>Colour</b> Burst...|$|R
50|$|In some analog video formats (Frequency {{modulation}} is {{the standard}} method for recording the luminance part of the signal, and is used to record a composite <b>video</b> <b>signal</b> in Direct <b>colour</b> systems), e.g. <b>Video</b> 2000 and some Hi-band formats a pilot tone {{is added to the}} signal to detect and correct timebase errors.|$|R
500|$|... a <b>colour</b> <b>video</b> {{of the gun}} {{being brought}} into, and out of, action.|$|R
5000|$|<b>Colour</b> <b>video</b> {{camera with}} pan and zoom {{control in the}} front and back.|$|R
50|$|Video ProcAmps can be {{used for}} {{processing}} standard definition 525/30 (NTSC) 625/25 (PAL) or high definition <b>video</b> <b>signals.</b> ProcAmps can process <b>video</b> <b>signals</b> ranging from analog composite to SDI <b>video</b> <b>signals.</b>|$|R
40|$|The paper {{deals with}} a novel {{segmentation}} technique applicable to <b>colour</b> <b>video</b> sequences. The algorithm uses Fast Marching Method for automatic extraction of semantic objects from natural <b>colour</b> <b>video</b> sequences by joint motion and colour analysis. The algorithm handles background {{in the same way}} as other objects, thus it does not need global motion compensation. The number of control parameters is small...|$|R
5000|$|Video {{modulation}} is {{a strategy}} of transmitting <b>video</b> <b>signal</b> {{in the field of}} radio modulation and television technology. This strategy enables the <b>video</b> <b>signal</b> to be transmitted more efficiently through long distances. In general, video modulation means that a higher frequency carrier wave is modified according to the original <b>video</b> <b>signal.</b> In this way, carrier wave contains the information in the <b>video</b> <b>signal.</b> Then, the carrier will [...] "carry" [...] the information in the form of radio frequency (RF) signal. When carrier reaches its destination, the <b>video</b> <b>signal</b> is extracted from the carrier by decoding. In other words, the <b>video</b> <b>signal</b> is first combined with a higher frequency carrier wave so that carrier wave contains the information in <b>video</b> <b>signal.</b> The combined signal is called radio-frequency signal. At the end of this transmitting system, the RF signals stream from a light sensor and hence, the receivers can obtain the initial data in the original <b>video</b> <b>signal.</b>|$|R
50|$|A Video Distribution Amplifier (also {{known as}} a {{distribution}} amp or VDA) takes a <b>video</b> <b>signal</b> as an input, amplifies it, and outputs the amplified <b>video</b> <b>signal</b> to two or more outputs. It is primarily used to supply a single <b>video</b> <b>signal</b> to multiple pieces of video equipment. It adjusts the amplitude of a <b>video</b> <b>signal</b> to compensate for loss of <b>signal</b> in a <b>video</b> distribution system. Extending {{the distance of the}} <b>video</b> <b>signal</b> is the main purpose of the VDA. There are VDAs built for all video formats, NTSC, ATSC, QAM16, QAM32, QAM64, Composite Video and Component Video.|$|R
50|$|Originally shot on <b>colour</b> <b>video</b> tape, {{the play}} only survives {{now as a}} black and white 16mm fiilm recording.|$|R
50|$|In video technology, {{blanking}} level {{is the level}} of the composite <b>video</b> <b>signal</b> during the front and back porches of the <b>video</b> <b>signal.</b>|$|R
40|$|Products to {{complete}} the <b>video</b> <b>signal</b> chain Maxim is a registered trademark of Maxim Integrated Products, Inc. © 2009 Maxim Integrated Products, Inc. All rights reserved. End-to-end solutions {{to complete}} the <b>video</b> <b>signal</b> chain This guide highlights select products for every link in the <b>video</b> <b>signal</b> chain. Targeted end equipment include: • Security and surveillanc...|$|R
40|$|An EPLD based {{low cost}} {{transient}} recorder of <b>video</b> <b>signal</b> bandwidth (sampling rate 25 MHz) is presented. It {{will be used}} to record and replay <b>video</b> <b>signals.</b> These <b>video</b> <b>signals</b> are handled by a video processing unit, under construction in a VHDL environment. The main advantage of this self made transient recorder is that the <b>video</b> <b>signal</b> processing device, which is under construction in a VHDL environment, uses the same analog components as the EPLD based transient recorder. Thus, the <b>video</b> <b>signal</b> passes the same signal path and components in the final device. This results in a simulation environment very close to the final system environment. 1 Introduction The speed of EPLDs available now allow applications in the area of <b>video</b> <b>signal</b> processing. As in the present case, the integration density of current EPLDs allows one to build a low cost transient recorder with few EPLDs {{and a handful of other}} components. The relative low effort in realizing a prototype caused by using EPLDs jus [...] ...|$|R
5000|$|EP1319308 Method and {{apparatus}} {{for processing}} a <b>video</b> <b>signal</b> for attaining copy protection, a <b>video</b> <b>signal</b> obtained therewith {{and the use}} thereof (Analogue video Copy Protection: vertical sync modification; 2000) ...|$|R
50|$|The COMX {{used the}} RCA CDP1869 and CDP1870 Video Interface System (VIS), {{consisting}} of the CDP1869 address and sound generator and the CDP1870 <b>colour</b> <b>video</b> generator.|$|R
50|$|Kramer Electronics is {{a company}} that designs, {{manufactures}} and distributes signal management products for analog and digital <b>video</b> <b>signals,</b> audio <b>signals,</b> computer graphics <b>video</b> <b>signals</b> and control signals which are used in the professional AV, broadcast and production and residential AV markets worldwide.|$|R
40|$|Fiber network {{security}} {{has become a}} very essential and important topic for optical network. Fault isolation became an important issue {{in order to provide}} an efficient fiber network and provide continuous services to the end user without being interrupted by any failure in fiber line. The aim {{of this study was to}} develope a <b>video</b> <b>signal</b> detector in order to determine the presence or loss of optical signal in FTTH. Phase detection method is used detect the existence of <b>video</b> <b>signal.</b> This is faster and more accurate than contrast detection. This device can accept an AC-coupled composite (CVBS), luma (Y), or any other <b>video</b> <b>signal</b> with sync and outputs a logic-level <b>signal.</b> The <b>Video</b> <b>Signal</b> Identifier (VSI) output is low when no sync is detected and high impedance when sync is detected. The device operates from a single + 3. 3 V supply and is capable to detect the <b>video</b> <b>signal</b> in less than 2 sec. Hence, it offers a complete solution to detect the presence or loss of <b>video</b> <b>signal</b> with no external components in the FTTH network...|$|R
50|$|Natlock is a picture-source {{synchronizing}} system using {{audio tone}} signals {{to describe the}} timing discrepancies between composite <b>video</b> <b>signals,</b> whilst Icelock uses digital information conveyed in the vertical blanking interval of a composite <b>video</b> <b>signal.</b>|$|R
40|$|This paper {{describes}} {{the use of}} variable kernels based on the normalized Chamfer distance transform (NCDT) for mean shift, object tracking in <b>colour</b> <b>video</b> sequences. This replaces the more usual Epanechnikov kernel, improving target representation and localization without increasing the processing time, minimising the distance between successive frame RGB distributions using the Bhattacharya coefficient. The target shape which defines the NCDT is found either by regional segmentation or background-difference imaging, dependent {{on the nature of}} the video sequence. The improved performance is demonstrated on a number of <b>colour</b> <b>video</b> sequences...|$|R
40|$|Abstract. In this paper, {{based on}} the FPGA and with a PAL decoder chip, LVDS coding chip and large {{capacity}} SRAM, the design and implementation of a PAL system for analog signals to the LVDS conversion of the <b>video</b> <b>signal</b> interface board. First of all, convert the analog signal of PAL to RGB 565 digital <b>video</b> <b>signal,</b> and transform the interlaced scan into progressive scan. Then, through the frame rate conversion, resolution expansion etc. algorithm method to handle. Finally, to achieve the interlaced scanning, a resolution of 720 × 576, 25 Hz PAL analog <b>video</b> <b>signal,</b> is converted to a progressive scan, a resolution of 1024 × 768, 60 Hz LVDS <b>video</b> <b>signal</b> transmission. After the measurement, the resolution and frame rate of the <b>video</b> <b>signal</b> conversion interface board are all meet the design requirements. It has been verified the effectiveness of scheme...|$|R
50|$|The intercarrier {{method is}} a system in {{television}} that reduces the cost of transmitters and receiver sets by processing audio and <b>video</b> <b>signals</b> together and minimizing the number of separate stages for audio and <b>video</b> <b>signals.</b>|$|R
5000|$|Vertical Interval Timecode (VITC, {{pronounced}} [...] "vitsee") {{is a form}} of SMPTE timecode encoded on one {{scan line}} in a <b>video</b> <b>signal.</b> These lines are typically inserted into the vertical blanking interval of the <b>video</b> <b>signal.</b>|$|R
40|$|A {{system for}} {{transmitting}} <b>video</b> <b>signal</b> of compressed bandwidth is described. The transmitting station {{is provided with}} circuitry for dividing a picture to be transmitted into a plurality of blocks containing a checkerboard pattern of picture elements. <b>Video</b> <b>signals</b> along corresponding diagonal rows of picture elements in the respective blocks are regularly sampled. A transmitter responsive to {{the output of the}} sampling circuitry is included for transmitting the sampled <b>video</b> <b>signals</b> of one frame at a reduced bandwidth over a communication channel. The receiving station is provided with a frame memory for temporarily storing transmitted <b>video</b> <b>signals</b> of one frame at the original high bandwidth frequency...|$|R
50|$|SCH {{phase is}} {{important}} when merging {{two or more}} <b>video</b> <b>signals.</b> To avoid color shifts or “picture jumps,” the <b>video</b> <b>signals</b> must have the same horizontal, vertical, and subcarrier timing and the phases must be closely matched. To achieve these timing constraints, the <b>video</b> <b>signals</b> must have the same SCH phase relationship since the horizontal sync and subcarrier are continuous signals with a defined relationship. It is common for an encoder to allow adjustment of the SCH phase to simplify merging two or more <b>video</b> <b>signals.</b> Maintaining proper SCH phase is also important since NTSC and PAL decoders may monitor the SCH phase to determine which color field is being decoded.|$|R
30|$|Case IV: <b>video</b> <b>signal</b> transmission: The fourth {{case study}} is {{performed}} with <b>video</b> <b>signal</b> storage and retrieval. The on-board DB 15 VGA connector port [20] {{has been used to}} display the video frames in a CRT monitor. The VGA signal timing is specified, published, copyrighted, and sold by the Video Electronics Standards Association (VESA) [20]. Thus in this paper, the detail specifications of the processing <b>video</b> <b>signals</b> are not mentioned in depth.|$|R
5000|$|William Courtenay [...] (1896 - 6 June 1960) was a British {{soldier and}} war {{correspondent}} who created unprecedented <b>colour</b> <b>videos</b> of various locales and {{events of the}} Second World War.|$|R
40|$|We {{propose the}} use of H. 264 {{redundant}} slices for Systematic Lossy Error Protection (SLEP) of a <b>video</b> <b>signal</b> transmitted over an error-prone channel. In SLEP, the <b>video</b> <b>signal</b> is transmitted to the decoder without channel coding. Additionally, a Wyner-Ziv encoded version of the <b>video</b> <b>signal</b> is transmitted {{in order to provide}} error-resilience. In the event of channel errors, the Wyner-Ziv description is decoded as a substitute for the error-prone portions of the primary <b>video</b> <b>signal.</b> Since the Wyner-Ziv description is typically coarser than the primary <b>video</b> <b>signal,</b> SLEP is a lossy error protection technique which trades-off residual quantization distortion for improved error-resilience properties, such as graceful degradation of decoder picture quality. We describe how H. 264 redundant slices can be used to generate the Wyner-Ziv description, and present simulation results to demonstrate the advantages of this method over traditional methods such as FEC...|$|R
40|$|DE 3507152 A UPAB: 19930925 Several {{subscribers}} are interconnected by {{a system}} of cameras, monitors, microphones and loudspeakers in each subscriber station. A central exchange (BZ) transmits <b>video</b> <b>signals</b> (BSq,BSs) between the cameras and monitors of the individual subscribers (SO). It comprises image memories (GSp), each associated with a subscriber during the built-up of the conference circuit. They receive the camera <b>video</b> <b>signals</b> of a complete image for further processing. A multiplexer (MUX) is also allocated to a certain subscriber for selective access to all camera <b>video</b> <b>signals</b> in the image memory. Each multiplexer supplies <b>video</b> <b>signals</b> to a specified monitor. Directional controls (BC) form specific monitor <b>video</b> <b>signals</b> from signals of individual subscribers. The subscribers are fitted with terminals (EE) containing selectors (WE) for the built-up of {{a connection to the}} directing control. ADVANTAGE - Allows viewing of both partial and complete images of conference subscribers. 1 / 1...|$|R
40|$|Error {{concealment}} of plural processed {{representations of}} a single <b>video</b> <b>signal</b> received in a video program In one embodiment, a method that includes receiving a single video stream, wherein the video stream includes plural processed representations {{of a single}} <b>video</b> <b>signal,</b> wherein each of the plural processed representations of the <b>video</b> <b>signal</b> (PPROTVS) includes a respective sequence of compressed latticed pictures, wherein each compressed latticed picture {{of each of the}} PPROTVS represents a corresponding respective picture of the <b>video</b> <b>signal,</b> wherein each respective picture of the <b>video</b> <b>signal</b> is represented by at most one compressed latticed picture from each of the PPROTVS, wherein corresponding segments of the PPROTVS are ordered and time shifted relative to each other to facilitate error concealment, the time-shift imposed by interspersing of non-corresponding segments between each of the corresponding segments; and providing error concealment on the received video stream...|$|R
5000|$|The {{types of}} video {{modulation}} {{can be classified}} by {{the way that a}} carrier wave is combined with <b>video</b> <b>signal.</b> The <b>video</b> <b>signal</b> and carrier wave both exist in waveform and when the carrier wave [...] "carries" [...] the <b>video</b> <b>signal,</b> the shape of carrier wave is changed and the changed carrier wave is the RF signal. Hence, how the shape of carrier wave is changed is the key to classify the types of video modulation.|$|R
40|$|International Telemetering Conference Proceedings / October 14 - 16, 1980 / Bahia Hotel, San Diego, CaliforniaThe recent {{development}} of compact, rugged, reliable and easy-to-use video cameras, recorders, amplifiers, digitizers and monitors {{has made this}} equipment increasingly attractive for data acquisition purposes. When analog and/or digital data is combined with <b>video</b> <b>signals,</b> the resulting configuration is a video instrumentation system. Two examples of video instrumentation systems are described in this paper. The TV Display Generator accepts four independent analog signals, modulated IRIG B serial time code, three different standard composite <b>video</b> <b>signals</b> and several digital control signals. The analog and time code signals are digitized and inserted into the composite <b>video</b> input <b>signals</b> for recording and display. The Video Countdown Programmer generates four color and two monochrome standard composite <b>video</b> <b>signals</b> and formats and inserts up to six sets of parallel BCD and ASCII digital data into each <b>video</b> <b>signal.</b> The output <b>video</b> <b>signals</b> are displayed by large screen monitors. As these two systems indicate, the recording and display functions of video instrumentation system provide additional capabilities in data acquisition applications...|$|R
40|$|One of the challanges in {{building}} successful Video-on-demand system {{is how to}} transmit <b>video</b> <b>signal</b> from the server to the customers. Previous methods have been based upon the real-time modeling of <b>video</b> <b>signals.</b> Since the <b>video</b> <b>signals</b> are inherently variable bit rate (VBR), {{it is not easy}} to model the signals effectively. Some of the widely used models are Markov modulated fluid source and Markov modulated Poisson soource and these models require a significant amount of buffer space to reduce cell loss rate. Since the VOD system usually deals with stored video, it is possible to extract useful information in advance and use them while sending the <b>video</b> <b>signal.</b> In this paper, we propose a scheme to transmit VBR <b>video</b> <b>signals</b> using a fixed bandwidth without any data loss. The proposed scheme sends some of the video data in advance so that the video can be played without interruption. The minimum amount of client's buffer space requirement and the startup delay are derived. Using this sc [...] ...|$|R
40|$|DE 102009010921 A 1 UPAB: 20100915 NOVELTY - The device (100) has a {{processing}} device (110), which is formed around a <b>video</b> <b>signal</b> (112) of a virtual image {{to produce and}} to provide a real image (102), a local information (104) of a camera and a local information (106) of the object. The virtual image has a representation of the object or object information. DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following: (1) a method for providing <b>video</b> <b>signal</b> of a virtual image based on a real image of a camera; and (2) a computer program with a program code for execution of the method. USE - Device for providing <b>video</b> <b>signal</b> of a virtual image based on a real image of a camera. ADVANTAGE - The device has a {{processing device}}, which is formed around a <b>video</b> <b>signal</b> of a virtual image to produce {{and to provide a}} real image, and hence ensures cost effective and improved <b>video</b> <b>signal</b> providing device...|$|R
50|$|Amplitude {{modulation}} {{works by}} varying the amplitude of the carrier wave {{according to the}} bent waveform of original <b>video</b> <b>signal.</b> In other words, when the carrier wave is combined with the <b>video</b> <b>signal,</b> frequency of the combined signal {{is the same as}} the frequency of the carrier wave while the amplitude is varied. The picture above can more directly explain how the shape is changed. In the combining process, if the <b>video</b> <b>signal</b> is at its peak (highest amplitude value), the amplitude of the varied carrier wave will be the highest and as for trough (lowest amplitude value), the amplitude of varied carrier wave will be the lowest. In other words, at the point in carrier wave that corresponds to the peak of <b>video</b> <b>signal,</b> the shape of wave will be most bulged and at the point corresponding to the trough, the shape will be most sunk. In fact, the change in amplitude of carrier wave is proportional to the amplitude of the <b>video</b> <b>signal.</b>|$|R
