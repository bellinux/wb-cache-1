9|37|Public
40|$|We {{propose a}} CUSUM type test for {{constant}} correlation {{that goes beyond}} a previously suggested correlation <b>constancy</b> <b>test</b> by considering Spearman's rho in arbitrary dimensions. By using copula-based expressions, we simultaneously extend a previously suggested copula <b>constancy</b> <b>test.</b> We calculate the asymptotic null distribution using an invariance principle for the sequential empirical copula process. The limit distribution is free of nuisance parameters and critical values can be obtained without bootstrap techniques. We give a local power result and analyse the test's behaviour in small samples...|$|E
40|$|Simulations {{are used}} to check the {{probability}} of detecting a time-varying equilibrium correction by applying the existing tests of no cointegration and parameter constancy. Smooth transition regressions are chosen to describe the nonlinearity and the Johansen cointegration test and the Lin and Teräsvirta parameter <b>constancy</b> <b>test</b> are applied. It turns out that both tests perform well separately but the joint power is quite low. The most notable result {{of this study is}} the high power when dealing with unrestricted cointegration, that is, when no cointegrating vector is estimated and the cointegrated variables freely enter the model in levels. The power of the parameter <b>constancy</b> <b>test</b> for the unrestricted cointegration is close to the power when the cointegrating vector is assumed to be known. Time-varying equilibrium correction; cointegration; parameter constancy; smooth transition regression...|$|E
40|$|This note {{investigates the}} {{behaviour}} of a parameter-constancy test statistic when near I(2) (integrated of order 2) variables are incorporated in a cointegrated vector autoregressive system. Simulation {{studies indicate that}} the presence of such variables has a significant impact on size properties of the <b>constancy</b> <b>test.</b> Parameter Constancy, Cointegraed Vector Autoregression, Near I(2) Variable. ...|$|E
40|$|This paper {{investigates the}} {{movement}} of manufacturing inventories and production over the business cycle to arrive at an asymmetric structural equilibrium-correction model. Initially crosscorrelation coefficients and deepness and steepness tests for skewness are utilised to present desriptive statistics of the time series. Cointegration analysis is performed on each disaggregate inventory by stage of production (finished goods, work in progress and raw materials) {{with a set of}} explantory variables. Restricted cointegration vectors are added to the symmetric and non-symmetric specifications of the structural equilibrium-correction model. These are compared by parameter <b>constancy</b> <b>tests</b> and one-step ahead forecasts...|$|R
40|$|We {{investigate}} the potential presence of time {{variation in the}} coefficients of the ''Fama regression'' for Uncovered Interest Rate Parity. We implement coefficient <b>constancy</b> <b>tests,</b> rolling regression techniques, and stochastic coefficient models based on state space modelling. Among six major US bilateral exchange rates we find significant evidence for stochastic time variation. Using the statistical equivalence between stochastically varying coefficients and conditional heteroscedasticity we derive a proxy for time-varying 'risk', and investigate whether it explains the well known "negative bias" or "foreign discount bias puzzle" in the foreign exchange rate literature. We contrast our identification scheme to the ARCH-in-mean approach for empirically identifying risk premia...|$|R
40|$|In {{this paper}} we analyze the {{empirical}} relevance of exchange rate pass-through for Finland, Sweden and Denmark {{during the period}} 1980 – 1994. Further, we attempt {{to determine if there}} has been a structural change in the pass-through relationship in the 1990 s. We find that about half the changes in exchange rates and world prices are passed through to import prices within one year, and three-quarters of such changes are passed through to import prices in two years. Moreover, there are no major differences among countries. Parameter <b>constancy</b> <b>tests</b> indicate the possibility of a structural change where the pass-through has slowed in recent years. Possible explanations of this are that the exchange rate regime has changed and competition has increased. exchange rate pass-through; import prices; structural change...|$|R
40|$|A CUSUM {{type test}} for {{constant}} correlation {{that goes beyond}} a previously suggested correlation <b>constancy</b> <b>test</b> by considering Spearman's rho in arbitrary dimensions is proposed. Since the new test {{does not require the}} existence of any moments, the applicability on usually heavy-tailed financial data is greatly improved. The asymptotic null distribution is calculated using an invariance principle for the sequential empirical copula process. The limit distribution is free of nuisance parameters and critical values can be obtained without bootstrap techniques. A local power result and an analysis of the behavior of the test in small samples is provided...|$|E
40|$|In {{this article}} we derive a {{parameter}} <b>constancy</b> <b>test</b> of a stationary vector autoregressive model against {{the hypothesis that the}} parameters of the model change smoothly over time. A single structural break is contained in this alternative hypothesis as a special case. The test is a generalization of a single-equation test of a similar hypothesis proposed in the literature. An advantage here is that the asymptotic distribution theory is standard. The performance of the tests is compared to that of generalized Chow-tests and found satisfactory in terms of both size and power. Econometric modelling, Misspecification test, Parameter stability, Smooth transition, Structural break, JEL, C 32, C 12,...|$|E
30|$|The 131 I-tositumomab {{activity}} in the vial was measured using a CRC®- 15 R (Capintec, Inc., Ramsey, NJ, USA) radionuclide activity meter on D 0, D 3, and D 6. The radionuclide activity meter was originally calibrated by the manufacturer. A <b>constancy</b> <b>test</b> for this calibrator was performed every morning as part of routine quality control using a 57 Co source where the read activity value was compared to the predicted value calculated by accounting for radioactive decay. From 2007 to 2011, three 57 Co sources, each from a different vendor, {{were used for the}} test. The initial activities of these sources (185, 185, and 370  MBq) were provided by the vendors and were traceable to NIST standards. Note that {{the results of this study}} would not be affected by the accuracy of the activity meter calibration as only the variability of the calibration factor was studied. In addition, only the constancy, the difference between the indicated and true activity of the calibration source, was used in the statistical analysis. Records of the accuracy of the activity of the sources used for the <b>constancy</b> <b>test</b> are not available. However, current sources were purchased from Eckert & Ziegler (Berlin, Germany) and have an accuracy of ± 5 %. A plot of the constancy values over time showed no discontinuities due to source changes. A reproducibility test (ten successive measurements [15]) performed with the same 57 Co source showed a variability of 0.1 % of the calibration source activity measurement for this radionuclide activity meter.|$|E
30|$|The {{data used}} came from imaging studies {{performed}} for dosimetry calculations for 46 patients from 2007 to 2011 {{treated with the}} Bexxar® therapeutic regimen for non-Hodgkin’s [13] and Hodgkin’s lymphoma. In order to quantify the drug distribution obtained by planar whole-body scans, a calibration factor (in units of cps·MBq− 1) was measured using a vial containing 131 I-tositumomab imaged in air before each patient image acquisition. The calibration source was prepared for each patient and its activity was measured using the radionuclide activity meter described below before each calibration scan. In addition to {{the data from the}} calibration scans, radionuclide activity meter variability was assessed using data from daily <b>constancy</b> <b>tests,</b> and camera variability was evaluated using count rates from daily extrinsic flood quality control acquisitions. All the data were analyzed using a statistical mixed-effects model [14], described in more detail below, {{in order to determine the}} global variability of the calibration factor and the magnitude of components of its variance due to various factors.|$|R
40|$|A {{fundamental}} {{element of}} future generic pattern recognition {{technology is the}} ability to extract similar patterns for the same scene despite wide ranging extraneous variables, including lighting, turbidity, sensor exposure variations, and signal noise. In the process of demonstrating pattern constancy of this kind for retinex/visual servo (RVS) image enhancement processing, we found that the pattern constancy performance depended somewhat on scene content. Most notably, the scene topography and, in particular, the scale and extent of the topography in an image, affects the pattern constancy the most. This paper will explore these effects in more depth and present experimental data from several time series tests. These results further quantify the impact of topography on pattern constancy. Despite this residual inconstancy, the results of overall pattern <b>constancy</b> <b>testing</b> support the idea that RVS image processing can be a universal front-end for generic visual pattern recognition. While the effects on pattern constancy were significant, the RVS processing still does achieve a high degree of pattern constancy over a wide spectrum of scene content diversity, and wide ranging extraneousness variations in lighting, turbidity, and sensor exposure...|$|R
40|$|The aim of {{this work}} was to {{evaluate}} {{the reliability of the}} square of the signal-to-noise ratio rate, SNR 2 rate, as a precise measurement for quality control test in a digital fluoroscopy system. The quasi-ideal model observer was used to measure SNR 2 rate. The dose rate, pulse rate and field of view were varied, and their effect on dose efficiency, defined as SNR 2 rate=PKA;rate, was evaluated (where PKA;rate is the air kerma-area product rate). Measurements were repeated to assess reproducibility. The relative standard deviation in SNR 2 rate=PKA;rate over seven consecutive measurements was 5 %. No significant variation in SNR 2 rate=PKA;rate was observed across different pulse rates (10 – 30 pulses s- 1). The low-dose-rate setting had a superior dose efficiency compared with the medium- and high-dose-rate settings. A smaller field of view resulted in higher dose efficiency. The results show that SNR 2 rate=PKA;rate measurements offer the high precision required in quality control <b>constancy</b> <b>tests.</b> Funding agencies: ALF (Avtal om Lakarutbildning och Forskning) grants from Region Ostergotland [LIO- 357651]</p...|$|R
40|$|On {{open and}} {{controversial}} issue in empirical data analysis is to de-cide whether scaling and multifractal properties observed in empiri-cal data actually exist, {{or whether they}} are induced by intricate non stationarities. To contribute to answering this question, we propose a procedure aiming at testing the constancy along time of multifrac-tal attributes estimated over adjacent non overlapping time windows. The procedure is based on non parametric bootstrap resampling and on wavelet Leader estimations for the multifractal parameters. It is shown, by means of numerical simulations on synthetic multifractal processes, that the proposed procedure is reliable and powerful for discriminating true scaling behavior against non stationarities. We {{end up with a}} practical procedure that can be applied to a single fi-nite length observation of data with unknown statistical properties. Index Terms — Multifractal analysis, Non parametric bootstrap, Stationarity test, Time <b>constancy</b> <b>test,</b> Wavelet Leader...|$|E
40|$|A test {{based on}} {{measures}} of distortion-product otoacoustic emissions (DPOAEs) was developed in lightly anesthetized guinea pigs and alert rabbits to assess the effective activation or functional "strength" of the cochlear efferent system. The multifrequency method described here used the DP-gram frequency function to evaluate the fast component of the olivocochlear adaptive effect on DPOAE levels over a 2 -octave frequency range. An estimate of any concurrent muscle activation was also determined over the identical frequency range by monitoring the levels of the eliciting f 1 primary tone throughout its duration. The acoustic reflex, as measured by this f 1 level <b>constancy</b> <b>test,</b> {{did not appear to}} contribute to the average efferent strength of sedated guinea pigs, but the acoustic reflex did contribute to the average "efferent" strength of awake rabbits. Hence, the average efferent effect in alert rabbits is contaminated by the acoustic reflex, which confounds its interpretation...|$|E
30|$|The {{development}} of SPECT reconstruction methods including advanced corrections for physical interactions {{in the patient}} and detectors has provided the ability to obtain images with absolute activity quantification using SPECT/CT imaging. However, the conversion of voxel values to activity units, which is performed {{with the use of}} a calibration factor, is not well standardized and methods to reliably estimate this factor are needed. In this work, we focused on a calibration factor obtained from a planar acquisition of a small calibration source imaged in air due to its relative simplicity. We evaluated the repeatability of this method and studied the factors that affect the variability of the resulting calibration factor. The calibration factor estimate was obtained based on acquisition of an image of a vial containing a measured quantity of the radionuclide of interest before each patient image acquisition. The process of filling a new vial for each patient and the use of a radionuclide activity meter to measure the calibration source activity for each acquisition were potential sources of variability. The <b>constancy</b> <b>test</b> performed as part of daily radionuclide activity meter quality control was used as an indicator of radionuclide activity meter instrumentation variability. The background count rate, another potential source of variability, was measured by a planar acquisition without any calibration source in the field of view and was subtracted from the calibration source count rate. Finally, the calibration factor repeatability could be affected by variations in camera sensitivity or table speed over time. A sensitivity factor calculated from a daily 57 Co extrinsic flood acquisition, also acquired as part of routine quality control, was used to evaluate the impact of the camera sensitivity variations that are independent of radionuclide and collimator on the calibration factor measurement. In order to estimate the components of the total variance of the calibration factor and to determine the parameters that affect the variability of the calibration factor, a mixed-effects model was used to analyze the data.|$|E
40|$|Elliott and Jansson {{developed}} a powerful test for unit roots, published in Journal of Econometrics (2003), extending the Elliott-Rothenberg-Stock test (dfgls) by adding stationary covariates. I will discuss and demonstrate a Stata {{implementation of the}} test. Elliott and Müller's Review of Economic Studies paper (2006) illustrates how <b>tests</b> for parameter <b>constancy</b> and <b>tests</b> for a unknown break process can be unified to produce a single efficient test for stability of the regression function. I will discuss and demonstrate a Stata implementation of the test. ...|$|R
40|$|Literature in {{economics}} has identified many channels {{through which the}} financial liberalization may affect demand for money. There are evidences of stability as well as instability of demand for money due to financial development for developing economies. The objective {{of the current study}} is to examine the effect of financial liberalization on demand for money in Pakistan, i. e. whether financial liberalization has affected the demand for money or not. The issue is important as stable demand for money function is a prerequisite for formulating and operating monetary policy. To achieve the objective JJ cointegration and auto regressive distributed lag (ARDL) to the cointegration is employed to estimate the long-run equilibrium relationship between broad money M 2 and composite financial liberalization index along with other determinants of demand for money like gross domestic product, real deposit rate and exchange rate. In order to assess the stability of the model, the parameter <b>constancy</b> <b>tests,</b> i. e. recursive residuals, CUSUM and CUSUMSQ tests have been applied. The empirical results indicated that for broad money, there exists long-run money demand function. The financial liberalization, gross domestic product and real deposit rate positively affect the demand for money in the long as well as short-run. ...|$|R
40|$|The aim of {{this paper}} is to study the dynamic {{evolution}} of inflation rate. The model is constructed by extending the ARFIMA-GARCH to ARFIMA with a time varying GARCH model where the transition from one regime to another is evolving smoothly over time. We show by Monte Carlo experiments that the <b>constancy</b> parameter <b>tests</b> perform well. We apply then this new model on eight countries from Europe, Japan and Canada and find that this model is appropriate for six among these countries. ARFIMA model, Generalised autoregressive conditional heteroscedasticity model, Inflation rate, Long memory process, Nonlinear time series, Time-varying parameter mode...|$|R
40|$|The First Principle of Continuum Thermodynamics is {{formulated}} as a variational condition whose {{test fields}} are piecewise constant virtual temperatures. Lagrange multipliers theorem {{is applied to}} relax the constraint of piecewise <b>constancy</b> of <b>test</b> fields. This provides the existence of square summable vector fields of heat flow through the body fulfilling a virtual thermal work principle, analogous to the virtual work principle in Mechanics. The issue of compatibility of thermal gradients is dealt with and expressed by the complementary variational condition. Primal, complementary and mixed variational inequalities leading to computational methods in heat-conduction boundary-value problems are briefly discussed...|$|R
40|$|This study {{examines}} the constancy of the wheat acreage supply elasticity between 1950 and 1976. A binary variable approach {{is used to}} <b>test</b> <b>constancy</b> over time and over price levels. The results indicate that this elasticity has not been constant, and the paper suggests a model formulation that is more appropriate than the one used in past research...|$|R
40|$|Abstract Background The high {{diversity}} of New Caledonia {{has traditionally been}} seen {{as a result of its}} Gondwanan origin, old age and long isolation under stable climatic conditions (the museum model). Under this scenario, we would expect species diversification to follow a constant rate model. Alternatively, if New Caledonia was completely submerged after its breakup from Gondwana, as geological evidence indicates, we would expect species diversification to show a characteristic slowdown over time according to a diversity-dependent model where species accumulation decreases as space is filled. Results We reanalyze available datasets for New Caledonia and reconstruct the phylogenies using standardized methodologies; we use two ultrametrization alternatives; and we take into account phylogenetic uncertainty as well as incomplete taxon sampling when conducting diversification rate <b>constancy</b> <b>tests.</b> Our results indicate that for 8 of the 9 available phylogenies, there is significant evidence for a diversification slowdown. For the youngest group under investigation, the apparent lack of evidence of a significant slowdown could be because we are still observing the early phase of a logistic growth (i. e. the clade may be too young to exhibit a change in diversification rates). Conclusions Our results are consistent with a diversity-dependent model of diversification in New Caledonia. In opposition to the museum model, our results provide additional evidence that original New Caledonian biodiversity was wiped out during the episode of submersion, providing an open and empty space facilitating evolutionary radiations. </p...|$|R
40|$|To {{gain insight}} into the neural basis of colour constancy, we {{examined}} the colour vision of twenty-seven patients with defined unilateral lesions mainly located in the parieto-temporo-occipital cortex. Patients were tested with a battery of vision and colour vision tests. Detection and grouping thresholds for isoluminant chromatic and for luminance stimuli were measured to assess retinal and early cortical processing. To examine higher cortical functions, we tested colour memory, colour - object association, and colour constancy. For the evaluation of colour constancy, subjects had to adjust the colour of a test field until it appeared as neutral gray. The test field was embedded amid a set of coloured patches, and the illuminant was varied from trial to trial. A control group of healthy subjects was tested in the same tasks. Five of the twenty-seven patients showed a selective deficit in the colour <b>constancy</b> <b>tests.</b> All five patients showed normal colour discrimination. A comparison with anatomical lesion data, based on CT- or MRI-scans, showed {{that one of the}} five patients had a lesion near the fusiform and lingual gyri, whose importance for colour constancy had been suggested in earlier studies. However, three other patients had overlapping lesions in a region of parieto-temporal cortex, which so far had not been associated with colour vision. These results indicate that the computations underlying colour constancy are mediated by specialised cortical circuitry, which is independent of the neural substrate for colour discrimination and for assigning colours to objects...|$|R
40|$|The {{measurement}} of Low IQ {{is subject to}} far more error than has previously been acknowledged. The five point error that is usually acknowledged only {{takes into account the}} internal <b>constancy</b> of the <b>test.</b> When other errors due to changes in assessment conditions, the floor effect, the Flynn Effect and the lack of consistency between test the error is about 18 points...|$|R
40|$|NoIn {{this study}} human color <b>constancy</b> was <b>tested</b> for {{two-dimensional}} (2 D) and three-dimensional (3 D) setups with real objects and lights. Four different illuminant changes, a natural selection task {{and a wide}} choice of target colors were used. We found that color constancy was better when the target color was learned as a 3 D object in a cue-rich 3 D scene than in a 2 D setup. This improvement was independent of the target color and the illuminant change. We {{were not able to}} find any evidence that frequently experienced illuminant changes are better compensated for than unusual ones. Normalizing individual color constancy hit rates by the corresponding color memory hit rates yields a color constancy index, which is indicative of observers¿ true ability to compensate for illuminant changes...|$|R
40|$|This {{research}} {{investigates the}} long-run equilibrium relationship between money demand and its determinants in China {{over the period}} 1952 - 2004 for three definitions of money – currency in circulation m 0, narrow money m 1 and broad money m 2. The appropriate dummy variable has been added into the functions to assess and evaluate effects of economic reform in China. The additional influences on money demand in China, such as wages, monetization process and saving effects are explored. The real wage index w, the ratio of urban population to total population ROP, the ratio of total deposit to currency DCR, and the ratio of total deposit to income RDG have been considered as additional variables in the same money demand functions. To test the stable long-run money demand functions, the Engle-Granger two-stage cointegration method (EGTS), Phillips-Hansen cointegration approach, Pesaran et al. (2001) ARDL cointegration procedure along with CUSUM and CUSUMSQ stability tests and Johansen Multivariate Cointegration procedures are employed. Granger Causality Test is applied to indicate either uni-directional or bi-directional causality exists in the variables. Wald tests for homogeneity and parameter <b>constancy</b> <b>tests</b> are employed in this study as well. The estimation results, especially the cointegration analyses show that the real money demand functions perform better than the nominal money demand functions. Narrow money demand m 1 presents more satisfactory coefficients {{than the other two}} in terms of economic theory and econometric diagnostics. The stabilisation policy should primarily aim at the narrow money m 1. This study reveals that the economic reform did bring significant changes to the Chinese economy. Income is shown {{to be the most important}} determinant of money demand. The other additional variables also have significant effects on the money demand. The wage index influence on money demand models is important. The raise of monetization process made the money play a more vital role. The impact of ratio of total deposit to income is significant. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|We <b>tested</b> the <b>constancy</b> of floral choice by Trigona carbonaria Smith in {{a garden}} by examining, using a {{scanning}} electron microscope, {{the composition of the}} pollen loads of individual foragers over time. <b>Constancy</b> was <b>tested</b> on three levels. Within a single trip, 88 % of the samples examined comprised pure pollen loads (97 % or more of one pollen type). Within a single day, 88 % of bees visited the same species across trips sampled. Across 2 and 3 days, 82 % and 73 %, respectively, of individual bees foraged on a single pollen type. The majority of the remaining bees collected only two species of pollen. This pattern is consistent with that of other highly social bees. It enhances the pollinator efficacy of these insects by increasing the chances of pollen being transferred to stigmas of the same plant species. This increases the ecological importance of these bees and their value in crop pollination...|$|R
40|$|Color {{constancy}} {{refers to}} the unchanging nature of the perceived color of an object despite considerable variation in the wavelength composition of the light illuminating it. The color contrasts between objects and their backgrounds {{play a crucial role}} in color <b>constancy.</b> We <b>tested</b> a patient whose right striate cortex had been removed and demonstrated that he made no use of color contrast in judging color appearance but instead made judgments based simply on wavelength comparison. This was shown by presenting pairs of colored stimuli against a background color that gradually changed across space. When presented with such displays, both normal observers and those with cerebral achromatopsia (cortical color blindness) judge the color appearance of such stimuli on the basis of the chromatic contrast the stimuli make against their background rather than on the physical wavelengths of the light emitted from them. However, our patient made no such use of color contrast but, instead, made color discriminations simply on the basis of wavelength composition. This is consistent with recent findings from monkey electrophysiology that identify cells in early cortical visual areas that signal local contrast and so contribute to the likely mechanism for achieving color constancy. ...|$|R
40|$|Colour {{constancy}} is {{the capacity}} of visual systems to keep colour perceptionconstant despite changes in the illumination spectrum. Colour <b>constancy</b> hasbeen <b>tested</b> extensively in humans and has also been described in manyanimals. In humans, colour constancy is often studied quantitatively, butbesides humans, this has only been done for the goldfish and the honeybee. In this study, we quantified colour constancy in the chicken by training thebirds in a colour discrimination task and testing them in changed illuminationspectra to find the largest illumination change {{in which they were}} ableto remain colour-constant. We used the receptor noise limited model foranimal colour vision to quantify the illumination changes, and found thatcolour constancy performance depended on the difference between the coloursused in the discrimination task, the training procedure and the time thechickens were allowed to adapt to a new illumination before making achoice. We analysed literature data on goldfish and honeybee colour constancywith the same method and found that chickens can compensate forlarger illumination changes than both. We suggest that future studies oncolour constancy in non-human animals could use a similar approach toallow for comparison between species and populations...|$|R
30|$|IQ for dose calibrators {{should be}} straightforward, {{considering}} that {{these kind of}} instruments are relatively simple and consist of a suitable detector connected to a PC or to an electronic control case with a display. Thus, a check of documentation and installation conditions (electrical connections, cabling between detector and measuring / display device) should be sufficient. OQ test should be aimed to verify calibration status of the dose calibrator. This could be done with accuracy and reproducibility tests, to be performed using suitable calibrated radioactivity sources. Chosen radionuclides should be of adequate activity, energy and half-life (e.g. Cs- 137,with γ emission at 662  keV, whose T 1 / 2 is[*]=[*] 30  years). OQ might also include other tests, such as verification of calibration through accurate measurements of the output current in response to increasing activities, but usually the monitoring of the above cited parameters is considered sufficient to provide an adequate operational qualification of the instrument. The same test should be performed {{with the aim of}} qualifying the performance of the instruments, but using the intended (or one of the intended, in case more radionuclides are measured with the same instrument) radionuclide(s). For instance, in a [18 F]FDG preparation facility, accuracy, reproducibility and linearity should be determined using F- 18 with activity in the normal working range. For PQ purposes, also Limit of Quantitation (LOQ) should be determined. OQ and PQ tests should take into account the geometry of the sample (e.g. shape and size of the container, and distance to the sensitive surface of the detector). Re-qualification policy of dose calibrators should account that daily checks (e.g. <b>constancy</b> <b>tests)</b> are usually performed, and also verification of linearity and reproducibility are relatively frequent, so as to avoid the need of re-qualification, that should be only done in case the instrument is moved to a different location or due to other significant changes. There are a number of useful reference documents that may help during the implementation of the IQ, OQ and PQ validation steps. Table 6 of EANM guidelines on “Acceptance testing for nuclear medicine instrumentation” (EANM guidelines) provide a list of tests to be performed both at the acceptance of the instrument and to periodically verify its correct functionality. More experimental details related to the above suggested tests are described in EANM guidelines on “Routine quality control recommendations for nuclear medicine instrumentation” (EANM guidelines). Finally, recommendations relevant to assuring the continuing acceptability of the performance of radionuclide calibrators are set by European Commission Radiation Protection document n° 162 “Criteria for Acceptability of Medical Radiological Equipment used in Diagnostic Radiology, Nuclear Medicine and Radiotherapy” (EU Commission & Radiation Protection n. 162).|$|R
30|$|However, in Magidor’s favor is {{the fact}} that the “presuppositions” which she {{mentions}} seem to pass the projection tests (pp. 134 – 138). The first projection test is simply the <b>constancy</b> under negation <b>test,</b> but, in my view, constancy under negation is not a sufficient test for presupposition. 9 For one thing, c-selection and conventional implicatures survive negation, e.g. in both Mary is poor but honest and It is not true that Mary is poor but honest the presence of but leads one to conclude that the speaker thinks that there is a contrast between being poor and being honest. Similar remarks apply to conditionals. Her supposed presuppositions also pass the projection tests involving conjunctions and questions, but once again, so will various other types of things, such as conventional implicatures.|$|R
40|$|Abstract. This paper {{presents}} a negative result: current machine colour constancy algorithms {{are not good}} enough for colour-based object recognition. This result has surprised us since we have previously used the better of these algorithms successfully to correct the colour balance of images for display. Colour balancing has been the typical application of colour constancy, rarely has it been actually put to use in a computer vision system, so our goal was to show how well the various methods would do on an obvious machine colour vision task, namely, object recognition. Although all the colour <b>constancy</b> methods we <b>tested</b> proved insufficient for the task, we consider this an important finding in itself. In addition we present results showing the correlation between colour constancy performance and object recognition performance, and as one might expect, the better the colour constancy the better the recognition rate. ...|$|R
40|$|In many {{biomedical}} studies, it is {{of interest}} to assess dependence between bivariate failure time data. We focus here on a special type of such data, referred to as semi-competing risks data. In this article, we develop methods for making inferences regarding dependence of semi-competing risks data across strata of a discrete covariate Z. A class of rank statistics for <b>testing</b> <b>constancy</b> of association across strata are proposed; its asymptotic properties are also derived. We develop a novel resampling-based technique for calculating the variances of the proposed test statistics. In addition, we develop methods for combining test statistics for assessing marginal eects of Z on the dependent censoring variable {{as well as its}} eects on association. The nite-sample properties of the proposed methodology are assessed using simulation studies, and they are applied to data from a leukaemia transplantation study. Copyright? 2005 John Wiley & Sons, Ltd...|$|R
40|$|This article {{goes beyond}} the {{principle}} of relative <b>constancy</b> (PRC) by <b>testing</b> 2 new models of consumer mass media spending using 1953 - 1991 Belgian data. Unlike traditional PRC models, which have focused exclusively on the long-term relationship between income and mass media spending, these 2 models contain additional regressors (price, population, unemployment, and interest rate) in current (Model 1) and lagged (Model 2) form. Time-series regression analyses were performed to determine which variables significantly predict changes in consumer mass media expenditures. Model 1 regressions revealed that price and population were better predictors of mass media expenditures than income, stressing the importance of developing models of consumer mass media spending that go beyond a simple mass media expenditures-income relation. Model 2 regressions showed that lagged variables {{played an important role}} in explaining changes in mass media expenditures, indicating the need for incorporating lags in future mass media spending work. ...|$|R
40|$|This paper {{presents}} a negative result: current machine colour constancy algorithms {{are not good}} enough for colour-based object recognition. This result has surprised us since we have previously used the better of these algorithms successfully to correct the colour balance of images for display. Colour balancing has been the typical application of colour constancy, rarely has it been actually put to use in a computer vision system, so our goal was to show how well the various methods would do on an obvious machine colour vision task, namely, object recognition. Although all the colour <b>constancy</b> methods we <b>tested</b> proved insufficient for the task, we consider this an important finding in itself. In addition we present results showing the correlation between colour constancy performance and object recognition performance, and as one might expect, the better the colour constancy the better the recognition rate. 1 Introduction We set out to show that machine colour constancy had matured to [...] ...|$|R
40|$|Growth at 42 °C is {{advocated}} {{to differentiate}} {{species of the}} fluorescent pseudomonas group {{as well as to}} differentiate other nonfermentative bacteria. Methodologies vary in the performance of the test, resulting in differing and often discrepant results between investigators. During this evaluation, the test was performed by inoculating 3 ml of Trypticase soy broth with a loopful of an overnight broth culture. Growth in the 42 °C tube was judged as heavy or slight after 24 and 48 h incubation at 41. 5 ± 0. 5 °C. Pseudomonas aeruginosa grew abundantly after overnight incubation, whereas 16 of 74 isolates of P. putida (22 %) showed slight turbidity in the broth after 24 or 48 h which could not be regarded as an inoculum effect. Trypticase soy agar was used in conjunction with Trypticase soy broth, with the growth again judged as heavy or slight. Growth of P. putida on slants was still seen in some cases (6 %) although the number of strains showing growth had declined. Triphenyltetrazolium chloride was added to Trypticase soy broth (0. 005 %) as a color indicator of growth. Strains of P. putida, although showing visible evidence of growth, gave no color change when compared with the 35 °C control. The <b>constancy</b> in <b>test</b> results using nonfermentative bacteria is not only method dependent but also strain dependent. Although the test for growth at 42 °C is important as a taxonomic tool when used under controlled conditions, other tests such as acetamide are preferred as a substitute for use in the clinical laboratory...|$|R
40|$|We have {{recently}} {{shown that the}} Japanese yellow swallowtail butterfly Papilio xuthus uses colour vision when searching for food. In the field, these butterflies feed on nectar provided by flowers of various colours not only in direct sunlight but also in shaded places and on cloudy days, suggesting that they have colour <b>constancy.</b> Here, we <b>tested</b> this hypothesis. We trained newly emerged Papilio xuthus to feed on sucrose solution on a paper patch of a certain colour under white illumination. The butterflies were then tested under both white and coloured illumination. Under white illumination, yellow- and red-trained butterflies selected the correctly coloured patch from a four-colour pattern and from a colour Mondrian collage. Under four different colours of illumination, we obtained results that were fundamentally similar to those under white illumination. Moreover, we performed critical tests using sets of two similar colours, which were also correctly discriminated by trained butterflies under coloured illumination. Taken together, we conclude that the butterfly Papilio xuthus exhibits some degree of colour constancy when searching for food...|$|R
