329|710|Public
25|$|Amerindian {{linguist}} Lyle Campbell also assigned different percentage {{values of}} probability and confidence for various proposals of macro-families and language relationships, depending on his {{views of the}} proposals' strengths. For example, the Germanic language family would receive probability and confidence percentage values of +100% and 100%, respectively. However, if Turkish and Quechua were compared, the probability value might be −95%, while the <b>confidence</b> <b>value</b> might be 95%. 0% probability or confidence would mean complete uncertainty.|$|E
50|$|It can output a <b>confidence</b> <b>value</b> {{associated}} with its choice (in general, a classifier {{that can do}} {{this is known as}} a confidence-weighted classifier).|$|E
5000|$|The <b>confidence</b> <b>value</b> of a rule, [...] , {{with respect}} to a set of {{transactions}} , is the proportion of the transactions that contains [...] which also contains [...]|$|E
30|$|Criterion 1 : Negative samples {{should have}} low {{saliency}} <b>confidence</b> <b>values.</b>|$|R
30|$|Currently, {{we make a}} hard {{assignment}} to the particular binary/categorical label and discard the <b>confidence</b> <b>values.</b> While it may be preferable {{in some cases to}} use the <b>confidence</b> <b>values,</b> such as when an image is labeled as “No beard” and “No mustache” but the person has visible stubble, we find that the final labels are quite accurate.|$|R
30|$|Confidence of a rule A → B {{defines the}} ratio of the {{occurrence}} of A and B together to the occurrence of A only and can be calculated using Eq. (4). Higher the <b>confidence</b> <b>values</b> of a rule A → B, higher the chances of occurrence of B with the occurrence of A. Sometimes, only <b>confidence</b> <b>values</b> are not sufficient enough to evaluate the descriptive interest of a rule.|$|R
50|$|A <b>confidence</b> <b>value</b> was {{determined}} from the voting using a weighted {{average of the}} points given for each bead; the text was color-coded from red to black (with the same significance as the bead colors) according to {{the outcome of the}} voting.|$|E
50|$|When cursive {{handwriting}} is in play, {{for each}} word analyzed, the system {{breaks down the}} words into a sequence of graphemes, or subparts of letters. These various curves, shapes and lines make up letters and IWR considers these various shape and groupings in order to calculate a <b>confidence</b> <b>value</b> associated with the word in question.|$|E
5000|$|They output a <b>confidence</b> <b>value</b> {{associated}} with their choice. (Note that some other algorithms may also output confidence values, but in general, only for probabilistic algorithms is this value mathematically grounded in probability theory. Non-probabilistic confidence values can in general not be given any specific meaning, and only used to compare against other confidence values output by the same algorithm.) ...|$|E
40|$|Automated {{ontology}} population {{using information}} extraction algorithms can produce inconsistent knowledge bases. <b>Confidence</b> <b>values</b> {{assigned by the}} extraction algorithms may serve as evidence in helping to repair inconsistencies. The Dempster-Shafer theory of evidence is a formalism, which allows appropriate interpretation of extractors’ <b>confidence</b> <b>values.</b> This chapter presents an algorithm for translating the subontologies containing conflicts into belief propagation networks and repairing conflicts based on the Dempster-Shafer plausibility...|$|R
40|$|This paper {{describes}} and evaluates how <b>confidence</b> <b>values</b> {{can be used}} {{to improve}} the quality of exploration in QRouting for adaptive packet routing in communication networks. In Q-Routing each node in the network has a routing decision maker that adapts, on-line, to learn routing policies that can sustain high network loads and have low average packet delivery time. These decision makers maintain their view of the network in terms of Q values which are updated as the routing takes place. In Confidence based Q-Routing (CQ-Routing), the improved implementation of Q-Routing with <b>confidence</b> <b>values,</b> each Q value is attached with a <b>confidence</b> (C <b>value)</b> which is a measure of how closely the corresponding Q value represents the current state of the network. While the learning rate in Q-Routing is a constant, the learning rate in CQ-Routing is computed as a function of <b>confidence</b> <b>values</b> of the old and estimated Q values for each update. If either the old Q value has a low confidence or the estim [...] ...|$|R
40|$|Abstract – This paper {{reports on}} new {{improvements}} of an operational oil slick detection algorithm. The existing algorithm {{is based on}} a combination of statistical classification and decision rules. We have experimented with using wind information estimated from the SAR scene to compute <b>confidence</b> <b>values.</b> The wind-based <b>confidence</b> <b>values</b> have some merit, but sometimes they fail. In order to provide reliable <b>confidence</b> <b>values,</b> the estimated wind values can not be used alone. Another issue is whether monitoring should be performed uniformly over large areas, or if the effort should be concentrated on selected areas. We have analyzed oil spill statistics and generated an oil spill intensity map. This map may be used to focus the oil spill monitoring service. However, some degree of full coverage monitoring should still be performed...|$|R
5000|$|The [...] "Generalized Kuwahara filter" [...] {{proposed}} by P. Bakker considers several windows that contain a fixed pixel. Each window is then assigned an estimate and a <b>confidence</b> <b>value.</b> The {{value of the}} fixed pixel then takes {{the value of the}} estimate of the window with the highest confidence. This filter is not characterized by the same ambiguity in the presence of noise and manages to eliminate the block artifacts.|$|E
50|$|Amerindian {{linguist}} Lyle Campbell also assigned different percentage {{values of}} probability and confidence for various proposals of macro-families and language relationships, depending on his {{views of the}} proposals strengths. For example, the Germanic language family would receive probability and confidence percentage values of +100% and 100%, respectively. However, if Turkish and Quechua were compared, the probability value might be −95%, while the <b>confidence</b> <b>value</b> might be 95%. 0% probability or confidence would mean complete uncertainty.|$|E
5000|$|... where T is {{the overall}} {{assessment}} {{of confidence in}} a proposition; Resolve is a function which returns the single <b>confidence</b> <b>value</b> which is the resolution of any pair of values; For and Against are the sets of arguments supporting and opposing the proposition, respectively; Ca,x, Cb,y, …, are the confidence values for those arguments; Max{...} is a function which returns the strongest member of the set upon which it operates (For or Against).|$|E
3000|$|... and Δ T can be {{expressed}} as a probability measure, the optional computation of all <b>confidence</b> <b>values</b> runs in quadratic time [...]...|$|R
30|$|We also {{propose a}} {{modification}} of the classification algorithm to mask noisy joint trajectories by using the <b>confidence</b> <b>values</b> from the skeleton tracker.|$|R
30|$|Criterion 2 : Negative samples {{should contain}} those similar objects which also have high <b>confidence</b> <b>values</b> {{computed}} by the strong classifier around the target.|$|R
5000|$|The Knowledge Graph {{pulled in}} {{information}} from structured sources like Freebase, Wikidata and Wikipedia, while the Knowledge Vault is {{an accumulation of}} facts from across the entire web, including unstructured sources. [...] "Facts" [...] in Knowledge Vault also include a <b>confidence</b> <b>value,</b> giving the capability of distinguishing between knowledge statements that have a high probability of being true from others that {{may be less likely}} to be true (based on the source that Google obtained the data from and other factors).|$|E
50|$|In {{the table}} below, all {{predicted}} interactions, except SMARCD3, {{are supported by}} two-hybrid screen experimental data. This information is supported by both NextProt database and IntAct database. The two interactions with the highest <b>confidence</b> <b>value</b> are also supported by materials found by text-mining in STRING. Together, it is with reasonably high confidence that the proteins in red are interacting with MEGF8, and with moderate confidence that the proteins in green interact with MEGF8. The confidence level for the proteins in blue is much lower, which may mean that the two-hybrid assay provided a false positive, or that they actually are interacting.|$|E
50|$|The range (−V, V) can be {{employed}} in deciding whether a trend estimated from the actual data is unlikely {{to have come from}} a data series that truly has a zero trend. If the estimated value of the regression parameter a lies outside this range, such a result could have occurred {{in the presence of a}} true zero trend only, for example, one time out of twenty if the <b>confidence</b> <b>value</b> S=95% was used; in this case, it can be said that, at degree of certainty S, we reject the null hypothesis that the true underlying trend is zero.|$|E
40|$|We {{introduce}} a novel model for spatially varying variational data fusion, driven by point-wise <b>confidence</b> <b>values.</b> The proposed model {{allows for the}} joint estimation of the data and the <b>confidence</b> <b>values</b> based on the spatial coherence of the data. We discuss the main properties of the introduced model as well as suitable algorithms for estimating {{the solution of the}} corresponding biconvex minimization problem and their convergence. The performance of the proposed model is evaluated considering the problem of depth image fusion by using both synthetic and real data from publicly available datasets...|$|R
40|$|Automatic feature {{learning}} algorithms {{are at the}} forefront of modern day machine learning research. We present a novel algorithm, supervised Q-walk, which applies Q-learning to generate random walks on graphs such that the walks prove to be useful for learning node features suitable for tackling with the node classification problem. We present another novel algorithm, k-hops neighborhood based <b>confidence</b> <b>values</b> learner, which learns <b>confidence</b> <b>values</b> of labels for unlabelled nodes in the network without first learning the node embedding. These <b>confidence</b> <b>values</b> aid in learning an apt reward function for Q-learning. We demonstrate the efficacy of supervised Q-walk approach over existing state-of-the-art random walk based node embedding learners in solving the single / multi-label multi-class node classification problem using several real world datasets. Summarising, our approach represents a novel state-of-the-art technique to learn features, for nodes in networks, tailor-made for dealing with the node classification problem. Comment: 7 pages, 10 figures, 1 tabl...|$|R
40|$|AbstractIn this paper, a fuzzy Petri net (FPN) {{approach}} to modeling fuzzy rule-based reasoning is proposed to determining <b>confidence</b> <b>values</b> for bases called in DNA sequencing. The proposed {{approach is to}} bring DNA bases-called {{within the framework of}} a powerful modeling tool FPN. The three input features in our fuzzy model-the height, the peakness, and the spacing of the first most likely candidate (the base called) and the peakness and height for the second likely candidate can be formulated as uncertain fuzzy tokens to determines the <b>confidence</b> <b>values.</b> The FPN components and functions are mapped from the different type of fuzzy operators of If-parts and Then-parts in fuzzy rules. The validation was achieved by comparing the results obtained with the FPN model and fuzzy logic using the MATLAB Toolbox; both methods have the same reasoning outcomes. Our experimental results suggest that the proposed models, can achieve the <b>confidence</b> <b>values</b> that matches, of available software...|$|R
50|$|FAM203B {{contains}} two domains of unknown function: DUF383 (residues 110-288) and DUF384 (residues 292-349). The protein is alanine-, proline-, and leucine-rich, but poor in serine, asparagine, threonine, isoleucine, lysine, and phenylalanine. The following internal repeats {{can be found}} in the primary sequence: LPFL (26-29, 245-248), ELAP (70-73), GRAL (54-57, 111-114), and LAADPGL (88-94, 99-105). There are no positive, negative, mixed charge, or hydrophobic clusters; no transmembrane domains; and no clusters of amino acid multiplets. The secondary structure prediction generated by the Phyre 2.0 bioinformatic server shows only α-helices, almost all of which have high confidence values. The overall <b>confidence</b> <b>value</b> of the model is 99.5%.|$|E
50|$|In 2000, {{a system}} was {{developed}} by the GRADE (short for Grading of Recommendations Assessment, Development and Evaluation) working group and takes into account more dimensions than just the quality of medical research. It requires users of GRADE who are performing an assessment of the quality of evidence, usually as part of a systematic review, to consider the impact of different factors on their confidence in the results. Authors of GRADE tables grade the quality of evidence into four levels, {{on the basis of their}} confidence in the observed effect (a numerical value) being close to what the true effect is. The <b>confidence</b> <b>value</b> is based on judgements assigned in five different domains in a structured manner. The GRADE working group defines 'quality of evidence' and 'strength of recommendations' based on the quality as two different concepts which are commonly confused with each other.|$|E
5000|$|In a 2015 paper, Gerhard Jäger {{reported}} [...] "intriguing" [...] and [...] "controversial" [...] {{findings regarding}} Chukotko-Kamchatkan. Using {{a variant of}} mass lexical comparison, augmented by computational linguistic techniques, such as large-scale statistical analysis, to investigate [...] "deep genetic relations between languages", Jäger found evidence that Chukotko-Kamchatkan and the Indo-European languages had statistically-significant similarities with each other. On the whole, {{the similarities between the}} two families were greater than either shared with any other language family. This was the case even though Jäger factored in the possibility of language contact. The results were unaffected by the removal of similarities in phonology that were likely random coincidences - such as a [...] "surprisingly high number" [...] of resemblances in vocabulary between Chukotko-Kamchatkan and two Goidelic languages (namely Scottish Gaelic and Manx): according to Jäger, the <b>confidence</b> <b>value</b> of a notional [...] "Indo-European/Chukotko-Kamchatkan clade", when these [...] "rogue taxa" [...] were removed, fell only slightly, from 0.969 to a still statistically-significant 0.964.|$|E
25|$|Load {{and save}} {{arbitrary}} attributes on nodes and edges. For example, input {{a set of}} custom annotation terms for your proteins, create a set of <b>confidence</b> <b>values</b> for your protein–protein interactions.|$|R
50|$|There {{are many}} {{possible}} transcription factor binding {{sites in the}} FAM203B promoter. Below is a table of the best possibilities, which have high <b>confidence</b> <b>values,</b> evolutionary conservation, and/or multiple possible binding sites in the promoter.|$|R
3000|$|... [...]. The {{value of}} α is {{determined}} by various factors, such as engineering grade, engineering scale, operation progress and so on. Meanwhile, several <b>confidence</b> <b>values</b> of α shall be set for the dam risk management: α [...]...|$|R
30|$|In VANET environments, high vehicle {{mobility}} {{situation and}} low traffic density situation are main performance challenges for application systems. To evaluate {{the applicability of}} ERS under high vehicle mobility and low traffic density situations, we analyze the average accumulation speed for vehicles on event reputation value and event <b>confidence</b> <b>value</b> under different vehicle mobility and traffic density. Here we define the average event reputation value as {{the average of the}} two largest event reputation values among all vehicles at a specific simulation timestamp. A similar definition for the average event <b>confidence</b> <b>value</b> is applied. The reason is that in a VANET the vehicle with the highest reputation value and <b>confidence</b> <b>value</b> of an occurred event will be the first node to broadcast the traffic warning message to others.|$|E
40|$|Ontology mapping {{negotiation}} aims {{to achieve}} consensus among real-world entities {{about the process}} of transforming information between different models (ontologies). This paper describes a novel approach for ontology mapping negotiation, in which agents representing the real-world entities are able to achieve consensus among agents, about the mapping rules defined between two different ontologies. The proposed approach is based on utility functions that evaluate the confidence in a certain mapping rule. According to the <b>confidence</b> <b>value,</b> the mapping rule is accepted, rejected or negotiated. Since the negotiation process requires relaxation of the <b>confidence</b> <b>value,</b> a metautility function is applied, evaluating the effort made in relaxing (increasing) the <b>confidence</b> <b>value,</b> so that the mapping rule might be accepted. This convergence value is further applied by each agent in the evaluation of the global agreement...|$|E
30|$|The {{confidence}} function {{indicates a}} relative preference among different {{candidates for the}} uncertain quantity. Generally speaking, we prefer to take the candidate that has the largest <b>confidence</b> <b>value.</b>|$|E
30|$|Following the {{previous}} pixel-level segmentation approach [1], we extract color features from RGB, HSV, and LAB color spaces and texture feature using HOG [31]. By using {{a pool of}} combination of features and random forest classifiers [32], we classify the unknown pixels and obtain fine-grained hand segmentations. After that, we also get a more precision description of the confidence of a superpixel belonging to the hand region. The <b>confidence</b> <b>values</b> of superpixels are updated with their portion of positive labeled pixels. Then, we re-train the superpixel-level classifier by using the superpixel having high <b>confidence</b> <b>values.</b> By doing this, we update the hand and background models on-the-fly which makes the method more robust to varying environment.|$|R
40|$|The paper {{describes}} {{our investigation}} into the neural gas (NG) network algorithm and the hierarchical overlapped architecture (HONG) which we have built by retaining {{the essence of the}} original NG algorithm. By defining an implicit ranking scheme, the NG algorithm was made to run faster in its sequential implementation. Each HONG network generated multiple classifications for every sample data presented as <b>confidence</b> <b>values.</b> These <b>confidence</b> <b>values</b> were combined to obtain the final classification of the HONG architecture. Three HONG networks based on three different feature sets with global and structural features were also trained to obtain better classification on conflicting handwritten data. An excellent recognition rate for the NIST SD 3 database was consequently obtained...|$|R
40|$|Abstract — In {{uncertain}} and probabilistic databases, <b>confidence</b> <b>values</b> (or probabilities) {{are associated with}} each data item. Con-fidence values are assigned to query results based on combining confidences from the input data. Users may wish to apply a threshold on result <b>confidence</b> <b>values,</b> ask for the “top-k ” results by confidence, or obtain results sorted by confidence. Efficient algorithms for these types of queries can be devised by exploit-ing properties of the input data and the combining functions for result confidences. Previous algorithms for these problems assumed sufficient memory was available for processing. In this paper, we {{address the problem of}} processing all three types of queries when sufficient memory is not available, minimizing retrieval cost. We present algorithms, theoretical guarantees, and experimental evaluation. I...|$|R
