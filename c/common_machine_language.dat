3|2057|Public
50|$|In some {{computer}} architectures, {{the machine}} code is implemented by {{an even more}} fundamental underlying layer called microcode, providing a <b>common</b> <b>machine</b> <b>language</b> interface across a line or family of different models of computer with widely different underlying dataflows. This is done to facilitate porting of machine language programs between different models. An example of this use is the IBM System/360 family of computers and their successors. With dataflow path widths of 8 bits to 64 bits and beyond, they nevertheless present a common architecture at the machine language level across the entire line.|$|E
40|$|A <b>common</b> <b>machine</b> <b>language</b> is an {{essential}} abstraction that allows programmers to express an algorithm {{in a way that}} can be efficiently executed on a variety of architectures. The key properties of a <b>common</b> <b>machine</b> <b>language</b> (CML) are: 1) it abstracts away the idiosyncratic differences between one architecture and another so that a programmer doesn't have to worry about them, and 2) it encapsulates the common properties of the architectures such that a compiler for any given target can still produce an eficient executable. For von-Neumann architectures, the canonical CML is C: instructions consist of basic arithmetic operations, executed sequentially, which operate on either local variables or values drawn from a global block of memory. C has been implemented efficiently {{on a wide range of}} architectures, and it saves the programmer from having to adapt to each kind of register layout, cache configuration, and instruction set. However, recent years have seen the emergence of a class [...] ...|$|E
40|$|With the {{increasing}} miniaturization of transistors, wire delays {{are becoming a}} dominant factor in microprocessor performance. To address this issue, a number of emerging architectures contain replicated processing units with software-exposed communication between one unit and another (e. g., Raw, SmartMemories, TRIPS). However, for their use to be widespread, it will be necesary to develop a <b>common</b> <b>machine</b> <b>language</b> to allow programmers to express an algorithm {{in a way that}} can be efficiently mapped across these architectures. We propose a new <b>common</b> <b>machine</b> <b>language</b> for grid-based software-exposed architectures: StreamIt. StreamIt is a high-level programming language with explicit support for streaming computation. Unlike sequential programs with obscured dependence information and complex communication patterns, a stream program is naturally written as a set of concurrent filters with regular steady-state communication. The language imposes a hierarchical structure on the stream graph that enables novel representations and optimizations within the StreamIt compiler. We have implemented a fully functional compiler that parallelizes StreamIt applications for Raw, including several load-balancing transformations. Though StreamIt exposes the parallelism and communication patterns of stream programs, analysis is needed to adapt a stream program to a software-exposed processor. We describe a partitioning algorithm that employs fission and fusion transformations to adjust the granularity of a stream graph, a layout algorithm that maps a stream graph to a given network topology, and a scheduling strategy that generates a fine-grained static communication pattern for each computational element. Using the cycle-accurate Raw simulator, we demonstrate that the StreamIt compiler can automatically map a high-level stream abstraction to Raw. We consider this work to be a first step towards a portable programming model for communication-exposed architectures. Singapore-MIT Alliance (SMA...|$|E
5000|$|... virtual {{machines}} as in Java virtual <b>machine,</b> <b>Common</b> <b>Language</b> Runtime, etc.|$|R
50|$|Most calculators capable {{to being}} {{connected}} to a computer can be programmed in assembly <b>language</b> and <b>machine</b> code, although on some calculators this is only possible through using exploits. The most <b>common</b> assembly and <b>machine</b> <b>languages</b> are for TMS9900, SH-3, Zilog Z80, and various Motorola chips (e.g. a modified 68000) which serve as the main processors of the machines although many (not all) are modified to some extent from their use elsewhere. Some manufacturers do not document and even mildly discourage the assembly language programming of their machines because they must be programmed in this way by putting together the program on the PC and then forcing it into the calculator by various improvised methods.|$|R
50|$|On early models, {{the power}} supply over-heated the CPU {{and had to}} be {{replaced}} under warranty. The original Linn 9000 operating system was mostly written in an esoteric high-level programming language called FORTH with some <b>machine</b> <b>language.</b> In early versions, some of the FORTH code produced unacceptable delays in user interface functions and was rewritten in <b>machine</b> <b>language.</b> But the operating system had numerous bugs and it was <b>common</b> for the <b>machine</b> to lock-up and lose data.|$|R
50|$|The {{majority}} of software {{is written in}} high-level programming languages that are easier and more efficient for programmers to use because they are closer than <b>machine</b> <b>languages</b> to natural languages. High-level languages are translated into <b>machine</b> <b>language</b> using a compiler or an interpreter {{or a combination of}} the two. Software may also be written in a low-level assembly language, which has strong correspondence to the computer's <b>machine</b> <b>language</b> instructions and is translated into <b>machine</b> <b>language</b> using an assembler.|$|R
50|$|Type-ins {{were usually}} written in BASIC or a {{combination}} of a BASIC loader and <b>machine</b> <b>language.</b> In the latter case, the opcodes and operands of the <b>machine</b> <b>language</b> part were often simply given as DATA statements within the BASIC program, and were loaded using a POKE loop, since few users had access to an assembler. In some cases, a special program for entering <b>machine</b> <b>language</b> numerically was provided. Programs with a <b>machine</b> <b>language</b> component sometimes included assembly language listings for users who had assemblers and who were interested in the internal workings of the program.|$|R
50|$|The {{computer}} {{could be}} programmed using an assembly language system called QUIKOMP(TM), but its simple <b>machine</b> <b>language</b> instruction set and slow operation speed encouraged many programmers to code directly in <b>machine</b> <b>language.</b>|$|R
5000|$|Hardwired into a CPU's {{circuitry}} {{is a set}} {{of basic}} operations it can perform, called an instruction set. Such operations may involve, for example, adding or subtracting two numbers, comparing two numbers, or jumping to a different part of a program. Each basic operation is represented by a particular combination of bits, known as the <b>machine</b> <b>language</b> opcode; while executing instructions in a <b>machine</b> <b>language</b> program, the CPU decides which operation to perform by [...] "decoding" [...] the opcode. A complete <b>machine</b> <b>language</b> instruction consists of an opcode and, in many cases, additional bits that specify arguments for the operation (for example, the numbers to be summed {{in the case of an}} addition operation). Going up the complexity scale, a <b>machine</b> <b>language</b> program is a collection of <b>machine</b> <b>language</b> instructions that the CPU executes.|$|R
40|$|Abstract: The {{semantic}} analyses {{phase of}} a compiler must translate abstract syntax into abstract <b>machine</b> code. <b>machine</b> <b>language</b> that can express the target-machine operations without committing to too much machinespecific details. But it is also independent {{of the details of}} the source language. The front-end of the compiler does lexical analysis, parsing, semantic analyses, and translation to intermediate representation. The back-end does optimization of the intermediate representation and translation to <b>machine</b> <b>language.</b> Key-Words: compiler, lexical analysis, abstract syntax, intermediate representation, abstract <b>machine</b> <b>language...</b>|$|R
40|$|One of {{the most}} {{difficult}} tasks a compiler writer faces is the construction of the instruction selector. The instruction selector is that part of the compiler that translates compiler intermediate representation (IR) into instructions for a target machine. Unfortunately, implementing an instruction selector “by hand” is a difficult, time consuming, and error prone task. The details of both the IR and target instruction set must be carefully considered in order to generate correct and efficient code. This, in turn, requires an expert in both the compiler internals as well as the target machine. Even an expert, however, can implement an instruction selector that is difficult to verify and debug. In this dissertation we describe the instruction selector problem, cover previous attempts at solving it, and identify what we believe to be the most prominent factor inhibiting their widespread adoption. ^ This dissertation proposes a generalized approach toward generating instruction selectors automatically. In particular, we propose CISL, a <b>common</b> <b>machine</b> description <b>language</b> for specifying the semantics of compiler IR and target instructions, and GIST, a machine independent heuristic search procedure that can find equivalent instruction sequences between compiler IR and target instructions. CISL is an object-oriented-based language leveraging modern programming language constructs (e. g., classes, inheritance, mixins) and is capable of describing instructions for a variety of IR and target ISAs (Instruction Set Architecture). GIST leverages CISLs well-defined semantics and a canonicalization process to discover automatically instruction selector patterns: target instruction sequences that implement IR semantics. These instruction selector patterns are then generated in a compiler implementation independent format (XML). Small adapter programs use the generated instruction selector patterns to generate compiler specific implementation code. Our experiments show that instruction selector patterns can be discovered automatically and independent of a particular compiler framework or target machine. In addition, experience proved that adapter programs are easy to implement and instruction selector code is easy to generate from generated patterns. Furthermore, the generated instruction selectors are comparable in performance to the original compilers. ...|$|R
50|$|Simulation of <b>machine</b> <b>language</b> {{code and}} {{implementation}} of assembler.|$|R
5000|$|Algebraic Theory of <b>Machines,</b> <b>Languages</b> and Semigroups (January, 1968) ...|$|R
5000|$|Charles J. Roslund (Charlie's Machine): a <b>machine</b> <b>language</b> utility column; ...|$|R
30|$|An OpCode (short for {{operational}} code) is {{the portion}} of a <b>machine</b> <b>language</b> instruction that specifies the operation to be performed. A complete <b>machine</b> <b>language</b> instruction contains an OpCode and, optionally, the specification {{of one or more}} operands. The operations of an OpCode may include arithmetic, data manipulation, logical operations, and program control.|$|R
5000|$|Counting <b>machine</b> <b>language</b> {{instructions}} {{would be}} misleading {{because they can}} do varying amounts of work in different ISAs. The [...] "instruction" [...] in the standard measurements is not a count of the ISA's actual <b>machine</b> <b>language</b> instructions, but a unit of measurement, usually based on {{the speed of the}} VAX computer architecture.|$|R
50|$|A code {{generator}} generates <b>machine</b> <b>language</b> {{instructions for the}} target processor.|$|R
5000|$|... {{reserves}} {{memory for}} string variables, and optionally, a <b>machine</b> <b>language</b> program ...|$|R
5000|$|... 1984 Joseph Nechvatal, <b>Machine</b> <b>Language</b> Book by Willoughby Sharp, 74 pages ...|$|R
50|$|The Pascal MicroEngine was {{a series}} of {{microcomputer}} products manufactured by Western Digital from 1979 through the mid-1980s, designed specifically to run the UCSD p-System efficiently. Compared to other microcomputers, which ran a <b>machine</b> <b>language</b> p-code interpreter, the Pascal Microengine had its interpreter implemented in microcode. So, p-code was, effectively, its native <b>machine</b> <b>language.</b>|$|R
40|$|Abstract—Theano is a {{compiler}} for mathematical expressions in Python {{that combines}} {{the convenience of}} NumPy’s syntax {{with the speed of}} optimized native <b>machine</b> <b>language.</b> The user composes mathematical expressions in a high-level description that mimics NumPy’s syntax and semantics, while being statically typed and functional (as opposed to imperative). These expressions allow Theano to provide symbolic differentiation. Before performing computation, Theano optimizes the choice of expressions, translates them into C++ (or CUDA for GPU), compiles them into dynamically loaded Python modules, all automatically. <b>Common</b> <b>machine</b> learn-ing algorithms implemented with Theano are from 1. 6 × to 7. 5 × faster than competitive alternatives (including those implemented with C/C++, NumPy/SciPy and MATLAB) when compiled for the CPU and between 6. 5 × and 44 × faster when compiled for the GPU. This paper illustrates how to use Theano, outlines the scope of the compiler, provides benchmarks on both CPU and GPU processors, and explains its overall design...|$|R
50|$|Malbolge is <b>machine</b> <b>language</b> for a ternary virtual machine, the Malbolge interpreter.|$|R
5000|$|An {{input tape}} {{containing}} all the <b>machine</b> <b>language</b> {{programs at the}} installation.|$|R
5000|$|... 1978, with Jack Dennis and Joe Qualitz. <b>Machines,</b> <b>Languages,</b> and Computation. Prentice-Hall.|$|R
50|$|<b>Machine</b> <b>languages</b> and the {{assembly}} languages that represent them (collectively termed low-level programming languages) {{tend to be}} unique to {{a particular type of}} computer. For instance, an ARM architecture computer (such as may be found in a smartphone or a hand-held videogame) cannot understand the <b>machine</b> <b>language</b> of an x86 CPU that might be in a PC.|$|R
50|$|The {{earliest}} {{computers were}} often programmed {{without the help}} of a programming language, by writing programs in absolute <b>machine</b> <b>language.</b> The programs, in decimal or binary form, were read in from punched cards or magnetic tape or toggled in on switches on the front panel of the computer. Absolute <b>machine</b> <b>languages</b> were later termed first-generation programming languages (1GL).|$|R
40|$|In the IPTES {{project a}} dual {{language}} approach is proposed for overcoming both the problems {{derived from the}} use of a user-friendly, high-level, but notformally -defined language and from a lower-level, formal, but difficult-to-use language. The approach uses a user-friendly, high-level language as user interface and a lower-level, formal <b>language</b> as <b>machine</b> <b>language.</b> In this way the users can both access the IPTES environment through a nice interface and can profit from non-ambiguity-checks and proofs algorithms based on the formal kernel <b>machine</b> <b>language.</b> The correspondence between the two languages is built-in in the IPTES environment that provides a transparent mapping mechanism that relates the users specifications expressed by means of the high-level interface-language with the formal definitions expressed in the formal <b>machine</b> <b>language.</b> This paper presents the mapping mechanism that relates the current IPTES user interface (SA/RT [Ward& 85]) with the IPTES <b>machine</b> <b>language</b> (high-l [...] ...|$|R
40|$|This paper {{argues that}} through affording {{communications}} between machines and humans, <b>machine</b> <b>languages</b> become structures of media. To examine the argument, the paper selects a virtual city {{model of the}} Alphatown {{as a case study}} and draws on Roman Jakobson’s linguistic theory, at first analyses how the metalanguage functions via the mediums of listing and navigation in the Alphatown, then looks at how the affects of boredom, being lost and strangeness arise from the media infrastructures based upon metalanguage, and analyses where the poetic function lies in the transmission of affects and how the sensual and the material aspects of <b>machine</b> <b>languages</b> emerge thus functioning as poetic. With analysing the metalingual and poetic functions in a diagrammatic thought of <b>machine</b> <b>languages,</b> different levels of <b>machine</b> <b>languages</b> can be considered as media structures, while media structures manifest themselves as material and processual in the meantime...|$|R
50|$|It is also {{possible}} to program the HP 48 directly in <b>machine</b> <b>language.</b>|$|R
50|$|The computer's <b>machine</b> <b>language</b> {{consisted}} of 34 instructions, including arithmetical, logical and control instructions.|$|R
50|$|A {{programming}} language such as C, FORTRAN, or Pascal enables a programmer to write {{programs that are}} more or less independent from a particular type of computer. Such languages are considered high-level because they are closer to human languages and further from <b>machine</b> <b>languages.</b> In contrast, assembly languages are considered as low-level because they are very close to <b>machine</b> <b>languages.</b>|$|R
40|$|We give a {{disassembler}} for PET 2001 {{which is}} a popular personal computer using 6502 as a CPU. This assembler is written by <b>machine</b> <b>language.</b> Including a routine outputting to a dot printer, the memory size is 1067 bites. Furthermore, we give a method of loading a <b>machine</b> <b>language</b> program from the casette tape recorder into the BASIC TEXT area...|$|R
50|$|MLX is {{a series}} of <b>machine</b> <b>language</b> entry {{utilities}} published by the magazines COMPUTE! and COMPUTE!'s Gazette, as well as books from COMPUTE! Publications. These programs were designed to allow relatively easy entry of the type-in <b>machine</b> <b>language</b> listings that were often included in these publications. Versions were available for the Commodore 64, PET, VIC-20, Atari 8-bit family and Apple II.|$|R
5000|$|An {{input tape}} to contain all the <b>machine</b> <b>language</b> {{programs}} - unchanged, new or reassembled.|$|R
5000|$|... loads <b>machine</b> <b>language</b> {{program from}} cassette. If no name is specified, the next program is loaded ...|$|R
