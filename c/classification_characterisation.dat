4|44|Public
40|$|Software {{forensics}} {{is the use}} of authorship analysis {{techniques to}} analyse computer programs for a legal or official purpose. This generally consists of plagiarism detection and malicious code analysis. IDENTIFIED is a system that has been designed to assist with the extraction of count based metrics from source code, and with the development of models of authorship using statistical and machine learning approaches. Software forensic models can be used for identification, <b>classification,</b> <b>characterisation,</b> and intent analysis. One of the more promising methods for identification is case-based reasoning, where samples of code can be compared to those collected from known authors...|$|E
40|$|Two {{environmental}} rating systems, {{based on}} {{a comparison of the}} damage caused by vehicle emissions, are analysed and compared with each other. Both rating systems use a Well-to-Wheel approach. The first methodology, BIM-Ecoscore, was developed for the Brussels Capital Region and the second methodology, EC-Cleaner Drive, is being developed in the framework of a 5 th FP European project. The comparison of both methodologies was made by the following five steps, which are used in a life cycle analysis: inventory, <b>classification,</b> <b>characterisation,</b> normalisation and weighting. At each step both methodologies are evaluated and advantages and draw backs are summarised. A sensitivity analysis was carried out, to determine their robustness...|$|E
40|$|This study {{describes}} and {{evaluates the}} various schemes available for weighting the different impacts of alternative waste management options, including landfill, composting, re-use, recycling and source reduction. The {{context of the}} study is life cycle assessment (LCA), which seeks to describe and quantify the impacts on the environment, both in terms of resource use and emissions or wastes, of a product, process or policy. There are four stages of life cycle assessment: goal definition, inventory, impact assessment and improvement assessment. Impact assessment can be divided into three main parts: <b>classification,</b> <b>characterisation</b> and valuation. Classification involves the classification and aggregation of the environmental loadings of the inventory stage into categories. These categories are then characterised by aggregation of the impacts on the basis of equivalency factors. Finally, the valuation step requires the assignment of relative values or weights to the various impacts and impact groups. Weighted impacts may then be added to derive an indicator, or possibly more than one indicator, of overall impact...|$|E
30|$|Some of {{the data}} and methods {{presented}} above {{have been used in}} several case studies which have been conducted according to selected aspects of the VDI Guideline 4330 Part 1 [2]. Three of them are summarised below: (1) ecological land <b>classification</b> for <b>characterisation</b> of GMP-receiving environments and representative EM, (2) selection of representative sites for modelling GMP dispersal and (3) delineation and mapping of isolation zones.|$|R
40|$|Within CU 5 AlertPipe is a data {{processing}} pipeline {{dedicated to the}} near real-time detection, classification and alerting of flux-based transient phenomena. AlertPipe Xmatch is a package within the pipeline designed to aid the <b>classification</b> and <b>characterisation</b> of potential transient phemonena that ultimately informs the pipeline whether to publish an alert or not. This technical note describes the various implementations of the Xmatch catalogue search algorithms...|$|R
40|$|This test is {{intended}} to assess the resistance of rock sample to weakening and disintegration when subjected to two standard cycles of drying and wetting. The test describes {{in this article is}} recommended for <b>classification</b> and <b>characterisation</b> of rock materials based on Slake Durability Index (SDI). SDI value of the resistance of a rock to weakening was calculated by two different rock samples of Western Carpathians...|$|R
40|$|Competitive {{industries}} in the manufacturing sector have a holistic Life Cycle Management (LCM) view of business practices. Life Cycle Assessment (LCA), which forms part of the LCM approach, is increasingly used as a decision support tool in the South African manufacturing industry. The Life Cycle Impact Assessment (LCIA) phase of the LCA tool has been standardised within the ISO 14000 family and aims to quantify {{the environmental impacts of}} economic activities. A number of LCIA methodologies have been developed in Europe, which can be applied directly when life cycle systems are assessed. The LCIA procedures that are most commonly used in the South African manufacturing industry include the CML, Ecopoints, EPS and Eco-indicators 95 and 99 procedures. The five European methods are evaluated based on the applicability of the respective <b>classification,</b> <b>characterisation,</b> normalisation and weighting elements for the South African situation. The evaluation and comparison is further based on a cradle-to-gate Screening Life Cycle Assessment (SLCA) case study of the production of dyed two-fold wool yarn in South Africa. Shortcomings are identified with the European methodologies in the South African context in terms of comprehensiveness and modelling approaches. A LCIA framework and calculation procedure, termed the Resource Impact Indicator (RII) model, is subsequently proposed for South Africa, which is based on the protection of four natural resource groups: water, air, land, and mined abiotic resources. A distance-to-target approach is used for the normalisation of midpoint categories, which focuses on the ambient quality and quantity objectives for the four resource groups. The quality and quantity objectives are determined for defined South African Life Cycle Assessment (SALCA) regions and take into account endpoint or damage targets. Following the precautionary approach, RIIs are calculated for the resource groups from conventional Life Cycle Inventories (LCIs). The calculation of the RIIs ensures that all natural resources that are important from a South African perspective are duly considered in a LCIA. The results of a LCIA are consequently not reliant on detailed LCIs and the number of midpoint categories that converge on a single resource group. The proposed model is evaluated with the SLCA wool case study. The case study establishes the importance of region-specificity, for LCIs and LCIAs. The proposed LCIA model further demonstrates reasonable ease of communication of LCIA results to decision-makers or managers. Subjective weighting values for the resource groups are also proposed, based on survey results from manufacturing industry sectors in the South African automotive value chain, and the expenditure of the South African national government on environmental issues. The subjective weighting values are used to calculate overall Environmental Performance Resource Impact Indicators (EPRIIs) when comparing life cycle systems with each other. The EPRII approach is applied to a specific LCM problem in the South African context, i. e. evaluating and comparing environmental performance for supply chain management purposes in the developing country context. Thereby, RIIs are provided for key Cleaner Production process parameters in the South Africa context: water usage, energy usage, and waste produced per manufactured product. Thesis (PhD (Engineering and Technology Management)) [...] University of Pretoria, 2005. Graduate School of Technology Management (GSTM) unrestricte...|$|E
40|$|In {{this report}} is a brief {{overview}} of many of the aspects that are considered when integrating heterogeneous database systems. Reviewed are the <b>classification</b> and <b>characterisation</b> of database integration. The solution space is large which is reflected in the diversity of the academic and commercial solutions. This paper is intended to rationalise the diverse array of heterogeneous database integration solutions. 2 Table of Contents Table of Contents [...] 2 1 Introduction [...] . 3 2 Aspects of Database Integration [...] 4 Dimensions [...] . 4 Transparency [...] 4 Coupling [...] . 5 Component Database Intrusion [...] 5 Five Level Schema Model [...] . ...|$|R
40|$|Ph. D. (Biochemistry) This study consistsof {{two parts}} namely: • Phosphoproteins in {{ripening}} mango fruit tissue: Effect of y-irradiation and various effectors on protein phosphorylation during the climacteric rise, climacteric peak and post-climacteric stages of ripening. • Protein kinase (EC 2. 7. 10 and EC 2. 7. 11) activities in ripening mango fruit tissue: <b>Classification,</b> purification and <b>characterisation...</b>|$|R
40|$|The aim of {{this study}} is to tackle the {{semantic}} function of proper names, analysing whether they may be included within lexemes or morphemes. To do so we take into consideration some of the <b>classifications</b> and <b>characterisations</b> that, from Philosophy and Linguistics, have benn proposed. These different proposals seem organised on the basis of their similitudes: the most fréquentes ones are "the reference theory" and "the concept theory". We posit the differences proper names exhibit with respect to nouns, which in fact support their inclusion as deictic morphemes. Once their category has been established, the several uses should be explained in terms of syntactic combinatory. All in all, it is a study on the semantics and syntax of proper names...|$|R
40|$|SAR (Synthetic Aperture Radar) {{signatures}} of maritime targets are often affected by {{various types of}} distortions, with {{negative impact on the}} <b>classification</b> and <b>characterisation</b> of the targets. Two of these distortions are defocusing and presence of sidelobes. The first one occurs when the radar returns from a scatterer are not accurately focused in a single point but spread out in the azimuth direction. The second one manifests itself around bright scatterers that are surrounded by areas with a much lower radar cross-section. Several techniques exist that try to compensate for those distortions in Single Look Complex (SLC) SAR images, but they are mostly applied to airborne SAR. This paper presents the results of applying these methods to satellite SAR. JRC. G. 3 -Maritime affair...|$|R
40|$|The {{emerging}} {{field of}} mobile computing (MC) studies systems in which computational components may change locations. In terms of hardware, mobile work is usually across heterogeneous systems in Web extended by novel mobile devices. In terms of software, mobile work technically involves mobile agents and {{new generation of}} middleware. However, in general mobile work presents a new challenge and great opportunities to research in software engineering as a whole. In this paper, we focus our attention on process support for mobile work, that is {{an important aspect of}} software engineering. We present a <b>classification</b> and <b>characterisation</b> of mobile work mainly from the process point of view, and specify the requirements of process support for mobile work. The last part of the paper compares three process centred environments in regards to mobility support, and identifies their shortcomings. Keywords: Mobile Computing, Heterogeneous Web-based Systems, Mobile Agents, Middleware, Software Processes...|$|R
50|$|The {{calculation}} of the eco-costs is based on <b>classification</b> and <b>characterisation</b> tables as well (combining tables from IPCC (http://www.ipcc.ch/publications_and_data/ar4/wg1/en/ch2s2-10-2.html), the USEtox model (usetox.org), tables of the ILCD (http://lct.jrc.ec.europa.eu/pdf-directory/LCIA-CF-20-02-2013-clean.pdf), and RiskPoll (http://www.arirabl.org/Software_files/ExternE_2005_%28ERFs_and_UnitCosts%29.pdf)), however has {{a different approach to}} the normalisation and weighting steps. Normalisation is done by calculating the marginal prevention costs for a region (i.e. the European Union), as described above. The weighting step is not required in the eco-costs system, since the total result is the sum of the eco-costs of all midpoints.The advantage of such a calculation is that the marginal prevention costs are related to the cost of the most expensive Best Available Technology which is needed to meet the target, and the corresponding level of Tradable Emission Rights which is required in future. Example: For reduction of CO2 emissions to a sustainable level, the marginal prevention costs are the costs of replacement of coal-fired power plants by windmill parks at the sea.|$|R
40|$|In {{this paper}} we {{present the results}} of {{monitoring}} soil movements over an about 10 km 2 area around {{the border between the}} Calabria and Basilicata regions in Italy. Monitoring has been performed using the satellite differential SAR interferometry measurements integrated with GPS measurements. In particular, we used ERS data acquired at time interval of several months (about two acquisitions per year), and after particularly strong pluvial events. Terrain displacement spatial and temporal analysis has been performed by employing the original method described in Berardino et al. (2002, 2003). Obtained results allow us to characterise unstable areas, and can be used within projects aimed at territory <b>classification</b> and <b>characterisation,</b> and at performing damage evaluation. Accordingly, this technique has been included in the framework of a proposed UE project (WEDELOP project) aimed at developing an integrated methodology to devise a damage scale for hydrogeological disasters. This scale is of great interest in many fields; in particular, definition of a damage scale would be highly desirable from the viewpoint of insurance compani...|$|R
40|$|In Sweden, two LCA-based {{tools for}} the built {{environment}} have been developed the last years: the "Environmental Load Profile" and "EcoEffect". Both are {{standing in front of}} an implementation phase and it is therefore important that they may deliver credible and consistent results to end users and facilitate a transition to more environmentally benign building construction and administration. The present study looked at the differences in results that may appear when using the tools and where they come from. Applying the two tools for assessment of a new building on equal basis created differences in results. However, both tools pointed at energy use in the administration phase of the life cycle being the most significant factor for environmental impact, consistent with other studies. The results indicate that: (i) differences in material grouping and life expectancy for the construction materials used, (ii) differences in LCI-data used and (iii) different <b>classification</b> and <b>characterisation</b> models used, give rise to important differences. Environmental assessment tools, built environment, life cycle assessment, Environmental Load Profile, EcoEffect...|$|R
40|$|Life Cycle Assessment (LCA) {{has been}} applied in the leather {{footwear}} industry. Due {{to the fact that}} the goal of the study is to point those steps in the footwear cycle which contribute most to the total environmental impact, only a simplified semi-quantitative methodology is used. Background-data of all the inputs and outputs from the system have been inventoried. Impact assessment has been restricted to <b>classification</b> and <b>characterisation.</b> From the results of this LCA it has been concluded that energy consumption is an important impact generator phase, due to the characteristics of the electricity production in the studied area (Catalonia and the rest of Spain). A remarkable impact is generated in the solid waste management phase, also due to its characteristics in the studied area. Another significant impact source is the cattle raising phase where great values of Global Warming, Acidification and Eutrophication Potentials are estimated. At the tannery, a great value of water eutrophication potential is observed and this phase is also important for its non-renewable resource consumption. Peer ReviewedPostprint (published version...|$|R
40|$|The recently-defined four {{molecular}} {{subgroups of}} medulloblastoma have required updating of {{our understanding of}} in vitro models to include molecular classification and risk stratification features from clinical practice. This review seeks to build a more comprehensive picture of the in vitro systems available for modelling medulloblastoma. The subtype <b>classification</b> and molecular <b>characterisation</b> for over 40 medulloblastoma cell-lines has been compiled, {{making it possible to}} identify the strengths and weaknesses in current model systems. Less than half (18 / 44) of established medulloblastoma cell-lines have been subgrouped. The majority of the subgrouped cell-lines (11 / 18) are Group 3 with MYC-amplification. SHH cell-lines are the next most common (4 / 18), half of which exhibit TP 53 mutation. WNT and Group 4 subgroups, accounting for 50...|$|R
40|$|Small {{wetlands}} in Kenya and Tanzania cover about 12 million ha and {{are increasingly}} converted for agricultural production. There {{is a need}} to provide guidelines for their future protection or use, requiring their systematic <b>classification</b> and <b>characterisation.</b> Fifty-one wetlands were inventoried in 2008 in four contrasting sites, covering a surveyed total area of 484 km 2. Each wetland was subdivided into sub-units of 0. 5 – 458 ha based on the predominant land use. The biophysical and socio-economic attributes of the resulting 157 wetland sub-units were determined. The wetland sub-units were categorized using multivariate analyses into five major cluster groups. The main wetland categories comprised: (1) narrow permanently flooded inland valleys that are largely unused; (2) wide permanently flooded inland valleys and highlands floodplains under extensive use; (3) large inland valleys and lowland floodplains with seasonal flooding under medium use intensity; (4) completely drained wide inland valleys and highlands floodplains under intensive food crop production; and (5) narrow drained inland valleys under permanent horticultural production. The wetland types were associated with specific vegetation forms and soil attributes. Agricultural land use of wetlands was linked to their physical accessibility and the availability of adjacent upland areas, irrespective of wetland size or soil type...|$|R
40|$|There {{are various}} {{approaches}} available {{for assessing the}} flood vulnerability and damage to buildings and critical infrastructure. They cover pre- and post-event methods for different scales. However, there can hardly be found any method that allows for a large-scale pre-event assessment of the built structures with a high resolution. To make advancements in this respect, the paper presents, first, a conceptual framework for understanding the physical flood susceptibility of buildings and, second, a methodological framework for its assessment. The latter ranges from semi-automatic extraction of buildings, mainly from remote sensing with a subsequent <b>classification</b> and systematic <b>characterisation,</b> to {{the assessment of the}} physical flood susceptibility on the basis of depth–impact functions. The work shows results of the methodology's implementation and testing in a settlement of the city of Magangué, along the Magdalena River in Colombia...|$|R
40|$|Background, aim, {{and scope}} The {{interest}} in polyethylene terephthalate (PET) recycling is quite recent, {{but it has}} been growing steadily over the past few years. In this context, the aim {{of this paper is to}} assess the eco-profile, the energy savings and the environmental benefits of the use of recycled raw materials to manufacture products for thermal insulation of buildings in Italy (i. e., PET bottles postconsumer). Materials and methods The life cycle analysis is developed according to ISO 14040 / 44. In this paper, based on the LCA, the main types of environmental impact of a thermal insulation product have been outlined. This study is specifically focused on polyester nonwovens, produced by a company located in Italy. The cradle-to-gate life cycle inventory is performed for the mass of product needed to give a thermal resistance R of 1 (m 2 K/W). The calculation of the impacts is done with SimaPro software. With an environmental product declaration-oriented approach, a set of impact categories is used for the <b>classification</b> and <b>characterisation</b> of the life cycle impact assessment. Results The results of the impact assessment for 1 m 2 K/W of thermal insulation panels made with recycled PET are then compared with similar products made with virgin PET. The lower impact associated with the recycled PET for each category is underlined: the percentage reduction is around 46...|$|R
40|$|Copyright © 2015 Policy and Society Associates (APSS). Published by Elsevier Ltd. This {{manuscript}} {{version is}} made available under the CC-BY-NC-ND 4. 0 license [URL] This author accepted manuscript is made available following 24 month embargo from {{date of publication}} (June 2015) {{in accordance with the}} publisher's copyright policy. Corruption demoralises government and weakens the whole endeavour of policy formulation and its implementation. It diminishes services and causes fiscal stress, but most of all it undermines trust and corrodes legitimate community expectations. Corruption takes many forms and is found in many contexts. This paper develops a framework for the analysis of corruption which identifies types, activities, sectors and places (TASP). With the TASP framework identified or suspected corruption in any setting can be analysed as a precursor to the controls and processes that are most appropriate for the control and modification of corrupt behaviour, which ideally can enhance public sector performance. The TASP framework assists in pinpointing the nature, location and context of public sector corruption, and illustrates more precisely where the risks of corrupt activity might arise. This paper demonstrates, with empirical work from New York City and the State of Victoria in Australia (Australia's second most populous state), that more precise <b>classification</b> and <b>characterisation</b> of the nature and types of corrupt activity is an essential precondition to the development and design of targeted anti-corruption measures...|$|R
40|$|We {{present a}} data mining system, EasyMiner {{which has been}} {{developed}} for interactive mining of interesting patterns in time-oriented databases. This system implements {{a wide spectrum of}} data mining functions, including generalisation, <b>characterisation,</b> <b>classification,</b> association and relevant analysis. By enhancing several interesting data mining techniques, including attribute induction and association rule mining to handle time-oriented data the system provide a user friendly, interactive data mining environment with good performance. These algorithms were tested on time-oriented medical data and experimental results show that the algorithms are efficient and effective for discovery of pattern in databases. INTRODUCTION Knowledge Discovery in Databases (KDD) is the effort to understand, analyse, and eventually make use of the huge volume of data available. According to Fayyad et al. [1] KDD is the non trivial process of identifying valid, novel, potentially useful, and ultimately und [...] ...|$|R
40|$|Genre {{classification}} is {{the process}} of grouping objects together based on defined similarities such as subject, format, style, or purpose. Genre classification as a means of managing information is already established in music (e. g. folk, blues, jazz) and text and is used, alongside topic classification, to organise materials in the commercial sector (the children's section of a bookshop) and intellectually (for example, in the Usenet newsgroup directory hierarchy). However, in the case of text, genre is not a well-defined notion (it is better defined in music and arts) and discussions over what exactly constitutes genre abound in the <b>classification</b> community. The <b>characterisation</b> of information using the notion of genre may not be as explicit in other forms of material but, nevertheless, it implicitly permeates the way we view and segment the information space surrounding us...|$|R
40|$|The aim of {{the paper}} is to discuss the {{distinction}} between <b>characterisation</b> (<b>classification)</b> and denomination (naming, identifying) {{in the context of}} information systems (IS). The paper has a special focus on the design of identifiers, i. e. terms used for identifying individual phenomenon. The {{reason for this is that}} the distinction between denomination and characterisation is especially important when designing identifiers. Identifiers e. g. article numbers, telephone numbers, e-mail addresses and personal numbers, constitute an important part of the information infrastructure of companies and society as a whole, and therefore it is crucial that these terms are well designed. The paper illustrates that who designs, assigns and withdraws electronic identifiers is a significant economic and policy issue both within companies and for society as a whole, with farther reaching consequences than often perceived at first glanc...|$|R
30|$|In {{focussing}} {{solely on}} occupational health and safety, the authors {{do not agree}} with the identification of SVHC substances based only on their hazard <b>classification</b> without risk <b>characterisation</b> of the substance as applied at the moment. However, the legal text of REACH is not so specific. SVHC by definition of the REACH regulation are those substances that are included in the candidate list for authorisation {{on the basis of their}} classification as CMR, their PBT or vPvB properties or of their equivalent level of concern (ELC) [27]. In 2010, the EU commissionaires Tajani and Potočnik asked the Member State Competent Authorities and ECHA to intensify their work to accomplish the inclusion of 136 substances into the candidate list. This goal was hardly achieved and therefore the European Commission initiated a roadmap of SVHC stating that until 2020, the candidate list should contain all relevant substances [28].|$|R
40|$|The {{problem of}} {{choosing}} one method {{to use in}} the reverse engineering of existing relational database systems is not a trivial one. On one hand, methods hold different input requirements. On the other hand, each legacy system has its particular characteristics that restrict the available information. Our experience has identified different information types, with different degrees of availability and reliability, which can be found in existing systems. In this paper we present a short description of several reverse engineering methods and propose one <b>classification</b> model. The <b>characterisation</b> of the methods is organized in 5 categories: input, assumptions, output, methodology and main contributions. The classification model is based on the input requirements of the method, namely, attribute semantics, attribute's name coherency, data instances, applications code, candidate keys, 3 NF, inclusion dependencies and human input. We analyse the applicability of each method to existing database [...] ...|$|R
40|$|The {{formation}} and turnover of {{soil organic matter}} (SOM) includes the biogeochemical processing of the macronutrient elements nitrogen (N), phosphorus (P) and sulphur (S), which alters their stoichiometric relationships to carbon (C) and to each other. We sought patterns among soil organic C, N, P and S in data for c. 2000 globally distributed soil samples, covering all soil horizons. For non-peat soils, strong negative correlations (p < 0. 001) were found between N:C, P:C and S:C ratios and % organic carbon (OC), showing that SOM of soils with low OC concentrations (high in mineral matter) is rich in N, P and S. The results can be described approximately with a simple mixing model in which nutrient-poor SOM (NPSOM) has N:C, P:C and S:C ratios of 0. 039, 0. 0011 and 0. 0054, while nutrient-rich SOM (NRSOM) has corresponding ratios of 0. 12, 0. 016 and 0. 016, so that P is especially enriched in NRSOM compared to NPSOM. The trends hold {{across a range of}} ecosystems, for topsoils, including O horizons, and subsoils, and across different soil classes. The major exception is that tropical soils tend to have low P:C ratios especially at low N:C. We suggest that NRSOM comprises compounds selected by their strong adsorption to mineral matter. The stoichiometric patterns established here offer a new quantitative framework for SOM <b>classification</b> and <b>characterisation,</b> and provide important constraints to dynamic soil and ecosystem models of carbon turnover and nutrient dynamics...|$|R
40|$|This study {{proposes a}} method to {{determine}} the gender and age group of a speaker {{by means of an}} automatic speech recognition system that is trained on six different sets of phones: one for each intersection of the two gender and three age-group classes. The study uses the Australian National Database of Spoken Language (ANDOSL) with 18 speakers in each class reading a set of 200 phonetically rich sentences. The system trains 44 context-independent phone models for each of the six classes and determines the gender and age group of an unknown utterance by finding the best matching phone sequence against the combined set of 264 phone models. Two methods of utilising the resulting phone sequences for gender and age-group recognition are evaluated: firstly, simple counting of the number of phones that belong to each class is used {{as the basis for the}} six-way class decision; secondly, the recognised phone sequence is converted to a 264 -dimensional vector, whose components contain the phone counts in the phone sequence for each of the 6 x 44 phones in the combined set. An artificial neural network is trained to make the final gender and age-group decision using the count vectors as input. The artificial neural network outperforms the simple counting method with an average correct recall for gender of 97. 7 %, an average correct recall for age group of 60. 5 % and an average correct recall for combined gender and age group of 58. 9 %. Index Terms: Gender classification, age <b>classification,</b> speaker <b>characterisation.</b> 1...|$|R
40|$|In this thesis, a {{combination}} of skeletonisation and graph matching techniques, coupled with a blend of supervised and unsupervised learning methodology {{is applied to the}} task of characterising and classifying natural shapes. A novel navigation-based skeletonisation algorithm is used to gather low level structural and morphological information about the shape. Subsequently, the data are converted into a series of attributed graphs, which characterise the image. Graphs of the same type can then be compared using an approximate graph matcher, which identifies a degree of similarity between them. Each degree of similarity corresponds to a data point in a conceptual space (as defined by Gärdenfors). The proposed method is applied to two distinct problems; the classification of leaf types, and the characterisation of river networks. The <b>classification</b> and <b>characterisation</b> systems are tested on a database of images of leaves and a collection of satellite images respectively. The novel navigation-based skeletonisation algorithm features several advantages; first, it allows the collection of topological and morphological information on the fly. This eliminates the need for any post-processing on the extracted skeletons. In addition, the adaptation of the algorithm to suit different applications is facilitated by the fact that any sort of morphological information can be included without alterations to the function of the algorithm. The conversion of the skeletons to attributed graphs is simplified by the existence of structural and morphological flags in the skeletal points. Last, concepts are created in the resulting conceptual space by means of a best-guess approach as well as a mechanism for accommodating external user input. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|Geophysical {{techniques}} Electrical Resistivity Tomography (ERT) and Ground Penetrating Radar (GPR) {{supported by}} traditional field methods {{are used for}} the geological mapping, description and interpretation of Quaternary unconsolidated sediments in a site located in theMidlands of Ireland. The site comprises {{a broad range of}} glacial and postglacial sediments (diamicton, esker sand and gravel, glaciolacustrine sand, glaciolacustrine silt/clay and peat). Preliminary fieldwork comprising, geomorphological mapping, lithostratigraphic analysis of exposures and borehole drilling and laboratory testing encompassing particle size distribution analysis were carried out to broadly characterise the geology of the study area. These data aided locating the geophysical profiles and supported the geophysical data interpretation. FiveGPR radargrams were collected and permitted depicting the subsurface internal architecture within low conductivity unconsolidated sediments and aided to the <b>classification</b> and <b>characterisation</b> of sedimentological and deformational structures. Four ERT profiles allowed the depth to bedrock to be determined and lithological classification of the sediments. The use of these geophysical techniques in combination with geotechnical and geological data allowed (i) the determination of the lithological composition and detailed internal architecture of the subsurface, (ii) the characterisation and description of the geology of the site and (iii) understanding the depositional processes acting in the area during ice withdrawal. Diamicton and esker gravelswere deposited subglacially by an ice sheetwithdrawingwestwards; glaciolacustrine sediments located along the southmargin of the esker ridgewere laid down in an ice marginal environment as a subaqueous fan composed of silt, sand and gravel, and as distal deposits composed of silt and clay in the lower ground area between the fan and the esker ridge. Peat developed during postglacial times andwas partially cut away by anthropogenic action at a later stage...|$|R
40|$|This paper {{introduces}} a novel workflow for {{the reconstruction of}} nowadays disappeared cultural landscapes based on the extraction of morphological information from historic aerial photographs. This methodology has been applied {{for the first time}} for the detection, <b>classification</b> and <b>characterisation</b> of upstanding, flattened and buried archaeological sites and various off-site ancient landscape features in the plain of Karditsa, western Thessaly. Although Thessaly {{has been the focus of}} prehistoric, and especially Neolithic, research in Greece, since the beginning of the 20 th century, western Thessaly has not received as much archaeological attention and its archaeological record remains rather scanty. Moreover, an extensive land reclamation project implemented in the western Thessalian plain during the early 1970 s resulted in the flattening of habitation tells and funerary sites of all periods. Thus, recognition of archaeological sites and relict landscape features becomes extremely difficult, whereas standard landscape analysis and application of mainstream Remote Sensing (RS) techniques based on multispectral satellite images are problematic. Digital photogrammetric reconstruction techniques and the subsequent GIS-based treatment of the results allowed overcoming these challenging limitations: the combined use of pre- 1970 s aerial photographs with later imagery provided a powerful means to reconstruct the landscape before the land reclamation process, using a workflow designed to highlight photogrammetry-derived topographic differences and multi-temporal imagery analysis. Hundreds of previously unknown mounded archaeological sites, as well as other ancient landscape traits such as roads, city grids and field systems were detected. More importantly, invaluable insights into the type and character of these archaeological features were gained, which would have been impossible to obtain by conventional RS techniques...|$|R
40|$|This {{handbook}} {{produced by}} the members of the COST Action TU 1205 ? Building Integrated Solar Thermal Systems (BISTS), funded by COST, 2013 - 2017. It covers introductory subjects on the presentation of the Action, the <b>classification</b> and <b>characterisation</b> of BISTS and basic resource (solar radiation) analysis. Following on, Section 2 details the basic BISTS design, including architectural planning, thermal and optical design of BISTS, modelling of the systems, installation, testing, commissioning and maintenance as well as life cycle analysis, economics and legal issues. Section 3 presents new options with respect to emerging architectural design concepts, system and application options, materials, retrofitting BISTS and thermal storage integration. Section 4 presents five different innovative BISTS designs developed by various Action members, a building erected in Israel where BISTS are applied extensively, as well as the modelling of novel solar thermal collectors suitable for building integration. The last two sections deal with the outlook of the technology and basic conclusions obtained from this Action with supporting material, including journals that publish material relevant to BISTS, participant research and testing centres and infrastructures, international activities, networks and projects and a comprehensive database of BISTS applications, presented in a connected publication produced by this Action. Many more details {{can be found in the}} Action website: [URL] We hope that the material presented in this handbook will be of interest to architects, solar engineers, building services engineers, government bodies and anyone who has an interest in this subject. Many thanks to the Action members and non-members who participated in the writing of the various chapters and of course to the COST Office for funding this Action. info:eu-repo/semantics/publishedVersio...|$|R
40|$|Autoimmune {{diseases}} {{are associated with}} a breakdown in central or peripheral self-tolerance, resulting in the initiation of pathogenic immune responses against self. Regulatory T-cells (Tregs) expressing the transcription factor forkhead box P 3 (FoxP 3) are potent regulators of peripheral self-tolerance. Defects in the number or function of Tregs have been associated with the development of many autoimmune diseases, generating interest in the use of Tregs as cell-based immunotherapy. However, uncertainty regarding the identification, stability and function of human Tregs has prevented the application of Tregs as therapy for autoimmune diseases. Such research demonstrates that Tregs are a heterogeneous population with varying regulatory phenotypes and the potential to convert into pro-inflammatory T-helper 17 cells. Therefore, prior to using Tregs as cellular therapy for autoimmune disease, these potential drawbacks must be fully investigated. In this thesis I describe in detail the development, <b>classification,</b> migration, molecular <b>characterisation</b> and stability of Tregs. In addition to, proposing a new protocol for the isolation of highly pure FoxP 3 + Tregs to be used as immunotherapy for autoimmune disease. ...|$|R
30|$|The {{approval}} {{of genetically modified}} organisms [GMO] for deliberate release and {{placing on the market}} requires GMO environmental risk assessment [ERA] and GMO environmental monitoring [EM]. Both GMO ERA and GMO EM are still under discussion. The goal of this article is, firstly, to analyse principles of GMO EM as published in the Association of German Engineers [VDI] Guideline 4330 Part 1, focusing on the characterisation of the receiving environment affected by GMO cultivation and the representativeness of GMO EM to assess large-scale implications of GMO cultivation. Secondly, the article introduces measures to meet these issues by the use of map data and statistics within a geographical information system [GIS]. Finally, three case studies exemplify the application of data and methods. To deal with spatial issues of GMO EM as outlined in the VDI Guideline 4330 Part 1, a GIS-based approach is presented. It relies on both spatial data collected from several sources which were derived from sample point data and geostatistical and multivariate statistical methods within a GIS environment. Data used for describing the receiving environment and for planning and evaluating monitoring schemes comprise information about land use, climate, phenology, soil coverage, species distribution and ecoregions. The case studies deal with (1) ecological land <b>classification</b> for <b>characterisation</b> of GMO-receiving environments and representative EM, (2) selection of representative sites for modelling GMO dispersal, and (3) delineation and mapping of segregation distances. Even a systematic and stepwise-structured risk assessment cannot cover all risk relevant questions, especially large-scale, long-term and combinatory effects which may not occur before the conventional application of the respective GMO. Hence, GMO EM is crucial to deal with unanticipated and undesirable effects. The article gives an overview of a GIS implementation and relevant geodata promoting GMO EM.|$|R
40|$|The Gaia {{mission is}} {{designed}} as a Galaxy explorer, and will measure simultaneously, in a survey mode, the five or six phase space parameters of all stars brighter than 20 th magnitude, {{as well as providing}} a description of their astrophysical characteristics. These measurements are obtained by combining an astrometric instrument with micro-arcsecond capabilities, a photometric system giving the magnitudes and colours in 15 bands and a medium resolution spectrograph named the Radial Velocity Spectrometer (RVS). The latter instrument will produce spectra in the 848 to 874 nm wavelength range, with a resolving power R = 11 500, from which radial velocities, rotational velocities, atmospheric parameters and abundances can be derived. A companion paper (Katz et al. 2004) presents the characteristics of the RVS and its performance. This paper details the outstanding scientific impact of this important part of the Gaia satellite on some key open questions in present day astrophysics. The unbiased and simultaneous acquisition of multi-epoch radial velocities and individual abundances of key elements in parallel with the astrometric parameters is essential for the determination of the dynamical state and formation history of our Galaxy. Moreover, for stars brighter than V= 15, the resolving power of the RVS will give information about most of the effects which influence the position of a star in the Hertzsprung-Russell diagram, placing unprecedented constraints on the age, internal structure and evolution of stars of all types. Finally, the RVS multi-epoch observations are ideally suited to the identification, <b>classification</b> and <b>characterisation</b> of the many types of double, multiple and variable stars. Comment: 33 pages, 11 figures, in press at MNRAS. Figs 1, 3 and 9 included at reduced resolution; available in full resolution at [URL]...|$|R
40|$|AbstractThe recently-defined four {{molecular}} {{subgroups of}} medulloblastoma have required updating of {{our understanding of}} in vitro models to include molecular classification and risk stratification features from clinical practice. This review seeks to build a more comprehensive picture of the in vitro systems available for modelling medulloblastoma. The subtype <b>classification</b> and molecular <b>characterisation</b> for over 40 medulloblastoma cell-lines has been compiled, {{making it possible to}} identify the strengths and weaknesses in current model systems. Less than half (18 / 44) of established medulloblastoma cell-lines have been subgrouped. The majority of the subgrouped cell-lines (11 / 18) are Group 3 with MYC-amplification. SHH cell-lines are the next most common (4 / 18), half of which exhibit TP 53 mutation. WNT and Group 4 subgroups, accounting for 50 % of patients, remain underrepresented with 1 and 2 cell-lines respectively. In vitro modelling relies not only on incorporating appropriate tumour cells, but also on using systems with the relevant tissue architecture and phenotype as well as normal tissues. Novel ways of improving the clinical relevance of in vitro models are reviewed, focusing on 3 D cell culture, extracellular matrix, co-cultures with normal cells and organotypic slices. This paper champions the establishment of a collaborative online-database and linked cell-bank to catalyse preclinical medulloblastoma research...|$|R
