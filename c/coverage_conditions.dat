56|264|Public
50|$|Healthcare {{rationing}} in the United States {{exists in}} various forms. Access to {{private health insurance}} is rationed based on price and ability to pay. Those not able to afford a health insurance policy are unable to acquire one, and sometimes insurance companies pre-screen applicants for pre-existing medical conditions and either decline to cover the applicant or apply additional price and medical <b>coverage</b> <b>conditions.</b> Access to state Medicaid programs is restricted by income and asset limits via a means-test, and to other federal and state eligibility regulations. Health maintenance organizations (HMOs) that commonly cover {{the bulk of the}} population, restrict access to treatment via financial and clinical access limits.|$|E
5000|$|As {{with other}} {{insurance}}, {{an insurance policy}} {{is part of the}} insurance transaction. In mortgage insurance, a master policy issued to a bank or other mortgage-holding entity (the policyholder) lays out the terms and conditions of the coverage under insurance certificates. The certificates document the particular characteristics and conditions of each individual loan. The master policy includes various conditions including exclusions (conditions for denying <b>coverage),</b> <b>conditions</b> for notification of loans in default, and claims settlement. The contractual provisions in the master policy have received increased scrutiny since the subprime mortgage crisis in the United States. Master policies generally require timely notice of default include provisions on monthly reports, time to file suit limitations, arbitration agreements, and exclusions for negligence, misrepresentation, and other conditions such as pre-existing environmental contaminants. The exclusions sometimes have [...] "incontestability provisions" [...] which limit the ability of the mortgage insurer to deny coverage for misrepresentations attributed to the policyholder if twelve consecutive payments are made, although these incontestability provisions generally don't apply to outright fraud.|$|E
50|$|Experiments, {{conducted}} in laboratory settings, allow {{the testing of}} effects resulting from mere exposure to controlled stimuli. This research method is primarily used in psychological approaches to election campaign communication research. Experiments can, e.g., detect the effects election campaign commercials have on the electorate. By exposing subjects to particular election spots and varying specific details in the ad, the variables causing an effect can be revealed.June Woong Rhee, e.g., makes use of two kinds of experiments within in his study on framing effects in election campaign news coverage. To examine the influence of framing effects on voters’ interpretation of campaigns, a broadcast-print experiment and a broadcast-only experiment were conducted. As pretest, the participants of the study had {{to write a letter}} about the 1992 U.S. presidential election campaign. Afterwards the participants were confronted with print and broadcast news stories about the 1991 Philadelphia mayoral election campaign, which were created using a strategy or an issue frame and simulating the actual <b>coverage.</b> <b>Conditions,</b> e.g., within the broadcast-print experiment were strategy frames in broadcast and print news, issue frames in broadcast and print news, or a mixture, i.e., either an issue frame in printed news and a strategy frame in broadcasts, or strategy-framed broadcast and issue-framed print news. The participants of the experiments were “asked to read or watch the news stories for five days in their homes”. After the five days of exposure to the manipulated news, the participants met with the experimenter and, as a posttest, had to “write a letter about the Philadelphia mayoral campaign”. To interpret the results a content analysis was conducted by Rhee. The study revealed that “both strategy-framed and issue-framed print news stories are effective in influencing campaign interpretation“.|$|E
40|$|Abstract This paper {{describes}} {{an approach to}} formalization of crite-ria of computer systems software testing. A brief review of control-flow criteria is introduced. As a formal language fordescribing the criteria, the Z notation is selected. Z schemas are presented for definitions of the following criteria: state-ment <b>coverage,</b> decision <b>coverage,</b> <b>condition</b> <b>coverage,</b> decision/condition coverage, full predicate coverage, modifiedcondition/decision <b>coverage,</b> and multiple <b>condition</b> <b>coverage.</b> This characterization could help in the correct under-standing {{of different types of}} testing and also the correct application of a desired testing regime. ...|$|R
40|$|Functional {{testing of}} HDL {{specifications}} {{is one of}} the most promising approaches for the verification of the functionalities of a design before synthesis. The contribution of this work is the development of a test generation algorithm targeting a new coverage metric (called bit-coverage) that provides full statement <b>coverage,</b> branch <b>coverage,</b> <b>condition</b> <b>coverage</b> and partial path coverage for behaviorally sequential models...|$|R
30|$|Timeslot {{measurement}} supplies direct measuring technological {{means for}} frequency <b>coverage</b> <b>condition</b> analysis, noise floor analysis, interference condition and locating of interference source analysis, radio network structure analysis, etc. Timeslot measurement {{offers the most}} important radio measuring technological means for precise optimization and the improvement of radio networks' performance.|$|R
40|$|In coverage-based testing, <b>coverage</b> <b>conditions</b> are {{generated}} from the program text. For example, a branch generates two conditions: that it be taken in the false direction and in the true direction. The proportion of <b>coverage</b> <b>conditions</b> a test suite exercises {{can be used as}} an estimate of its quality. Some <b>coverage</b> <b>conditions</b> are impossible to exerise, and some are more cost-effectively eliminated by static analysis. The remainder, the feasible <b>coverage</b> <b>conditions,</b> are the subject of this paper. What percentage of branch, loop, multi-condition, and weak mutation coverage can be expected from thorough unit testing? Seven units from application programs were tested using an extension of traditional black box testing. Nearly 100 % feasible coverage was consistently achieved. Except for weak mutation, the additional cost of reaching 100 % feasible coverage required only a few percent of the total time. The high cost for weak mutation was due to the time spent identifying impossible <b>coverage</b> <b>conditions.</b> Because the incremental cost of coverage is low, it is reasonable to set a unit testing goal of 100 % for branch, loop, multi-condition, and a subset of weak mutation coverage. However, reaching that goal after measuring coverage is less important than nearly reaching it with the initial black box test suite. A low initial coverage signals a problem in the testing process...|$|E
40|$|Abstract — We {{propose a}} general {{framework}} for broadcasting in ad hoc networks through self-pruning. The approach {{is based on}} selecting a small subset of hosts (also called nodes) to form a forward node set {{to carry out a}} broadcast process. Each node, upon receiving a broadcast packet, determines whether to forward the packet based on two neighborhood <b>coverage</b> <b>conditions</b> proposed in this paper. These <b>coverage</b> <b>conditions</b> depend on neighbor connectivity and history of visited nodes, and in general, resort to global network information. Using local information such as k-hop neighborhood information, the forward node set is selected through a distributed and local pruning process. The forward node set can be constructed and maintained through either a proactive process (i. e., “up-to-date”) or a reactive process (i. e., “on-the-fly”). Several existing broadcast algorithms can be viewed as special cases of the <b>coverage</b> <b>conditions</b> with k-hop neighborhood information. Simulation results show that new algorithms, which are more efficient than existing ones, can be derived from the <b>coverage</b> <b>conditions,</b> and self-pruning based on 2 - or 3 -hop neighborhood information is relatively cost-effective. Index Terms—- Ad hoc networks, broadcasting, localized algorithms, pruning. ...|$|E
40|$|Traditional {{vegetation}} indices like normalized difference vegetation index (NDVI) tend to saturate under high canopy <b>coverage</b> <b>conditions</b> and do {{not perform}} very well for diagnosing nitrogen status of high yielding crops. Red edge indices {{have been shown to}} be more sensitive to nitrogen status and are promising alternatives. The objective of this study is to evaluate different red edge indices for estimating winter wheat (Triticum aestivum L.) nitrogen status under high canopy <b>coverage</b> <b>conditions</b> in farmers’ fields. Six 200 × 200 m fields in four villages from Shandong Province, China were selected for this research from 2005 to 2007. Hyperspectral reflectance was determined at Feekes growth stage 7 - 9 when wheat canopy was fully covered. Subsequently, linear relationships between red edge indices and plant N uptake and concentration were established. Results indicated that red edge position indices REP and REIP performed better in estimating plant N status than normalized and simple ratio red edge indices. Plant N uptake, as a better indicator of crop N status, was easier to estimate using red edge indices than plant N concentration...|$|E
5000|$|... #Subtitle level 3: Meeting <b>Conditions</b> for <b>Coverage</b> and <b>Conditions</b> of Participation ...|$|R
40|$|<b>Condition</b> <b>coverage</b> {{testing is}} a family of testing {{techniques}} {{that are based on}} the logical flow of control through a program. The <b>condition</b> <b>coverage</b> techniques include a variety of requirements, including that each statement in the program is executed and that each branch is executed. Mutation testing is a fault-based testing technique that is widely considered to be very powerful, and that imposes requirements on testing that include, and go beyond, many other techniques. In this paper, we consider the six common <b>condition</b> <b>coverage</b> techniques, and formally show that these techniques are subsumed by mutation testing, in the sense that if mutation testing is satisfied, then the <b>condition</b> <b>coverage</b> techniques are also satisfied. The fact that <b>condition</b> <b>coverage</b> techniques are subsumed by mutation has immediate practical significance because the extensive research that has already been done for mutation can be used to support <b>condition</b> <b>coverage</b> techniques, including automated tool [...] ...|$|R
40|$|Testing is an {{important}} activity for checking the correctness of system implementations. It is performed by applying test experiments to an implementation under test, by making observations during {{the execution of the}} tests, and by subsequently assigning a verdict about the correct functioning of the implementation. The correctness criterion that is to be tested should be given in the System specifications. The specification prescribes what the system has to do and what not, and, consequently, constitutes the basis for any testing activity. This paper describes an approach to formalization of criteria of computer systems software testing. A brief review of control-flow criteria is introduced. As a formal language for describing the criteria, the Z notation is selected. Z schemas are presented for definitions of the following criteria: statement <b>coverage,</b> decision <b>coverage,</b> <b>condition</b> <b>coverage,</b> decision/condition coverage, full predicate coverage, modified condition/decision <b>coverage,</b> and multiple <b>condition</b> <b>coverage...</b>|$|R
40|$|A pattern shaping {{synthesis}} method {{along with}} a new sidelobe shaping scheme are used to design antenna arrays capable of delivering a much better radiation performance in terms of homogenous coverage and reduced interference with respect to commercial antennas. For verification, radiation within an urban scenario for the region {{inside and outside the}} cell has been studied {{with the aid of a}} 3 D ray-tracing simulator. Re-sults show a 15 % radiation reduction outside the cell for the synthesized antenna with respect to commercial antennas un-der equal <b>coverage</b> <b>conditions.</b> 1...|$|E
30|$|Based on {{the above}} studies, {{it is known}} that coal mining reduces water {{resources}} via destruction of hydrogeological conditions and soil physical properties, and that soil bulk density and infiltration capacity are two important soil hydrological parameters that also are closely related to types of covering vegetation. To identify the effects of mining subsidence on infiltration and soil bulk density in sandy land with consideration of vegetation, changes in soil bulk density and water infiltration rate generated by mining subsidence under different vegetation <b>coverage</b> <b>conditions</b> and the relationship between infiltration rates and these factors were studied at the Shendong Bulianta mine.|$|E
40|$|Abstract. We {{address the}} problem of verifying {{planning}} domains as used in model-based planning, for example in space missions. We propose a methodology for testing flight rules of planning domains which is selfcontained, in the sense that flight rules are verified using a planner and no external tools are required. We review and analyse <b>coverage</b> <b>conditions</b> for requirements-based testing, and we reason in detail on ”Unique First Cause ” (UFC) coverage for test suites. We characterise flight rules using patterns, encoded using LTL, and we provide UFC coverage for them. We then present a translation of LTL formulae into planning goals, and illustrate our approach on a case study. ...|$|E
5000|$|<b>Conditions</b> for <b>Coverage</b> and <b>Conditions</b> of Participation {{apply to}} {{these kinds of}} organizations: ...|$|R
30|$|Test {{cases are}} {{selected}} based on the risk analysis results so that the states with the high probability of risk must be tested. Risk analysis optimizes the test case selection and execution process. Reduction in original test suite is represented using Test Suite Reduction Rate (TSRR). The reduced test suite is subjected to coverage criteria {{in order to identify}} its coverage percentage to the entire system model. Coverage is the measure {{of the degree to which}} the system is tested. There are a number of coverage criteria namely statement coverage, function <b>coverage,</b> branch <b>coverage,</b> <b>condition</b> <b>coverage</b> and many more. Transition coverage is taken as the performance metric since each system model is represented in extended finite state machine (EFSM).|$|R
40|$|Functional {{testing of}} HDL {{specifications}} {{is one of}} the most promising approaches for the verification of the functionalities of a design before synthesis. The contribution of this work is the development of a test generation algorithm targeting a new coverage metric (called bit-coverage) that provides full statement <b>coverage,</b> branch <b>coverage,</b> <b>condition</b> <b>coverage</b> and partial path coverage for behaviorally sequential models. The behavioral test sequences can be also the only way to evaluate testability of VHDL model for which a gate-level representation is not available (e. g third-party cores), since the behavioral error model is characterized also by a high correlation with the RT and gate-level stuck-at fault model. Moreover the preciseness of the proposed coverage metric makes the identified test sequences more effective in identifying design errors, than other test patterns developed by following standard coverage metric...|$|R
40|$|Schwing et al. : The California Current, 1996 - 1997, CalCOFI Rep., Vol. 38, 1997 A {{large number}} of data sets from within the California Current region, and the {{large-scale}} fields that affect this region, are available for timely assessment of recent environmental conditions in this system. In addition to the long-running quarterly CalCOFI cruises, which featured the initial research cruise of RV Roger Revelle, several surveys off Baja California and central California have provided information on coastal areas adjacent to the present CalCOFI <b>coverage.</b> <b>Conditions</b> throughout the north Pacific and in the California Current are summarized and interpreted for the 1996 - 97 period...|$|E
40|$|We {{present a}} {{methodology}} and {{a tool for}} the problem of testing and verifying that a PDDL planning domain satisfies a set of requirements, a need that arises for instance in space missions. We first review and analyse <b>coverage</b> <b>conditions</b> for requirement-based testing, and present how test cases can be derived automatically from requirements. Additionally, we show how test cases can be translated into additional planning goals. To automate this process, we introduce PDVer, an Eclipse plug-in for the automatic generation of PDDL code from requirements expressed in LTL. We {{evaluate the effectiveness of}} our approach and the usability of our tool against the Rovers domain from the fifth International Planning Competition (IPC- 5) ...|$|E
40|$|The {{interactions}} of n-hexane, benzene, chloroform, and tetrahydrofuran with dried (amorphous) chromia (I) and chromia heated at 1073 K (crystalline) (II), both {{obtained from a}} colloidal dispersion, and a commercially available chromia (III) were studied by inverse gas chromatography (IGC) under finite surface <b>coverage</b> <b>conditions.</b> The isotherms, in the temperature range 383 – 423 K, were used to estimate the surface area, the adsorption energy distribution, the isosteric heat of adsorption, and the spreading pressure on the surfaces of the solids. The uniformly reduced adsorption ability of the heated chromia was attributed to the dehydroxylation of the surface at the higher temperatures. Both solids showed an increased affinity toward chloroform molecules, {{as a result of}} strong acid-base interaction...|$|E
30|$|Although the Kriging method {{can easily}} {{establish}} a velocity model, a high station density (e.g., the approximately 5  km spacing {{in this study}} area) is required for providing a satisfactory spatial <b>coverage</b> <b>condition</b> for interpolation in SW Taiwan. In addition, a long data-acquisition duration is also required to minimize contamination from inelastic deformation or artificial sources. Conversely, constructing a block model of velocity is relatively difficult because more geological information is required to build the block boundaries and fault parameters (McCaffrey 2002). However, fewer observations are required in the tectonic block model because of the physical constraints originating from geological investigations.|$|R
5000|$|<b>Coverage</b> (absolute <b>condition</b> for FM shutdown): Before 2015, {{the public}} {{broadcaster}} NRK must achieve coverage of 99.5%, the commercial broadcasters {{on the national}} network #1 are required to reach 90% of the population ...|$|R
30|$|Condition/Decision Coverage (CDC). Requires that both, <b>condition</b> <b>coverage</b> and {{decision}} coverage are achieved.|$|R
30|$|Recently, it {{has been}} {{proposed}} the use of WiMAX for the return channel in digital television systems using a new frequency profile bellow 1 GHz, which has been calledWiMAX- 700. The profile operates from 400 MHz to 960 MHz as primary band, which includes the UHF band, and optionally from 54 MHz to 400 MHz as secondary band. This work presents {{some aspects of the}} WiMAX- 700 technology and some simulation results of models designed to determine the system capacity concerning the number of actives subscriber stations, according to specific proposed scenarios, traffic sources profiles, specifics propagation, and <b>coverage</b> <b>conditions.</b> The results presented in this work provide elements to determine the suitability of WiMAX- 700 technology as the return channel for the interactive digital television applications.|$|E
40|$|Adsorption of alkanethiols on GaAs (001) surface under low <b>coverage</b> <b>conditions</b> was studied using density {{functional}} calculations in {{a periodic}} supercell approach. The study of physisorbed precursor and transition to chemisorption revealed that hydrogen atoms {{stay on the}} surface upon S-H bond cleavage and significantly affect desorption products and energies, in agreement with available experimental data. Binding of thiols to GaAs {{is found to be}} comparable or stronger than that of thiols to noble metals surfaces. Calculated thiolate-surface binding energies are found to be higher for Ga-rich than for As-rich surfaces, and are strongly dependent on surface reconstruction, adsorption site and coverage. This dependence is explained by the violation or fulfillment of electron counting rule, rehybridization of surface atom orbitals and strain relaxation upon addition of extra electrons brought by adsorption...|$|E
40|$|Self-assembled monolayers (SAMs) of octanethiol and benzeneethanethiol were {{deposited}} on clean Pt(111) surfaces in ultrahigh vacuum (UHV). Highly resolved images of these SAMs produced by an in situ {{scanning tunneling microscope}} (STM) showed that both systems organize into a super-structure mosaic of domains of locally ordered, closely packed molecules. Analysis of the STM images indicated a (√ 3 × √ 3) R 30 ° unit cell for the octanethiol SAMs and a 4 (√ 3 × √ 3) R 30 ° periodicity based on 2 × 2 basic molecular packing for the benzeneethanethiol SAMs under the <b>coverage</b> <b>conditions</b> investigated. SAMs on Pt(111) exhibited differences in molecular packing and a lower density of disordered regions than SAMs on Au(111). Electron transport measurements were performed using scanning tunneling spectroscopy. Benzeneethanethiol/Pt(111) junctions exhibited a higher conductance than octanethiol/Pt(111) junctions. close 141...|$|E
40|$|Previous studies {{identified}} the train compartment {{as the place}} where people can experience the highest exposure levels to electromagnetic fields in the radiofrequency range. Thus, in this study, a possible scenario of a train compartment has been reproduced and characterized, both numerically and experimentally, {{in order to assess}} the individual exposure. A very good agreement between the electric field values measured and simulated has been found. Results indicate that the individual exposure may increase, depending on the number of active cell phones, the <b>coverage</b> <b>condition,</b> and the position inside the compartment, while remaining well below the limits imposed by the international regulations. © 2011 IEEE...|$|R
5000|$|<b>Condition</b> <b>coverage</b> (or {{predicate}} coverage)Has each Boolean sub-expression evaluated both to true and false? ...|$|R
5000|$|The {{techniques}} used in white box testing are <b>condition</b> <b>coverage,</b> decision coverage, statement coverage, cyclomatic complexity.|$|R
40|$|In this paper, {{we present}} our method of the array data-flow {{analysis}} {{in a real}} compiler, the HPC parallelizing compiler for MPP machines. It has two aspects: the local array data-flow analysis and the global array data-flow analysis. We introduce a new representation called solution tree which allows us to compute array data-flow information more effectively and efficiently. We optimize the analysis by performing array data-flow computation from the highest dependence level to the lowest dependence level, sequencing the writes by the lexicographical order {{in the presence of}} multiple writes, and checking the solution tree against the <b>coverage</b> <b>conditions</b> to avoid any further computation once the sources have been found. Our experiments of both the local array data-flow analysis and the global array data-flow analysis on 7 programs of the Perfect Benchmarks shows that our analysis has acceptable performances for analyzing real scientific and engineering applications. 1 Introduction The a [...] ...|$|E
30|$|Another {{important}} {{problem is}} the provision of high-quality services within vehicles on the move. One possible solution {{to address the problem}} in the future will be the deployment of a relay within the vehicle. The relay can be connected to the vehicular rooftop antenna, in order to establish a robust (relay/backhaul) link to the cellular network. On the other hand, relays allow for optimum <b>coverage</b> <b>conditions</b> inside the vehicle and a certain control of the consumed resources through the usage of closed subscriber groups. Since the use of a relay eliminates the vehicle penetration loss (VPL) and provides additional antenna gains due to better characteristics of the rooftop antenna, this solution improves significantly the link budget [20] and allows for a more efficient resource utilization of the cellular network. However, in current LTE networks, an additional overhead burden due to signaling exists (around 10 %), and therefore, the benefit from the use of those relays is to be demonstrated.|$|E
40|$|Improvements of TCP {{performance}} in wireless networks have been tossed around for several years. One mechanism {{that has received}} considerable attention {{is the use of}} error recovery techniques thereby compensating for the wireless loss characteristics. However, surprisingly, to our knowledge no study in error avoidance has been carried out. This paper proposed the use of an error avoidance scheme for improving the performance of TCP in wireless environments by simply avoiding transmitting data under poor radio <b>coverage</b> <b>conditions.</b> The decision to transmit or not is taken by comparing the signal to noise ratio (SNR). In effect, the transmissions are suspended when the SNR is decreasing and goes below a given threshold, and resume transmission when the SNR goes back above the SNR threshold. This can be realized without modifying TCP by using a thin layer between the network and transport layers. The result showed that the TCP sender could obtain significantly better performance, improvements up to 15 % on TCP throughput by using this technique...|$|E
40|$|Previous studies {{identified}} the train compartment {{as the place}} where people can experience the highest exposure levels (still below the international guideline limits) to electromagnetic fields in the radiofrequency range. Here a possible scenario of a train compartment has been reproduced and characterized, both numerically and experimentally. A good agreement between the simulated electric field distributions and measurements has been found. Results indicate that the higher values of exposure in specific positions inside the train compartment depend {{on the number of}} active cell phones, the bad <b>coverage</b> <b>condition,</b> the cell orientation, and the presence of metallic walls. This study shows that the proposed approach, based on the scenarios characterization, may efficiently support the assessment of the individual electromagnetic exposure...|$|R
50|$|C/C++test {{includes}} {{options for}} line coverage, meaning has the line been executed, block coverage, statement coverage, path coverage, decision coverage, branch <b>coverage,</b> and simple <b>condition</b> <b>coverage.</b> It also supports modified condition/decision coverage or MCDC because projects that require safe reliable software such as aircraft and cars, tend to required {{this form of}} coverage as it's {{believed to be a}} better measure of whether or the code has been thoroughly exercised.|$|R
30|$|The {{wireless}} {{sensor network}} for surveillance in specific area is proposed in [8, 9]. After that, more and more researchers focus on putting the {{wireless sensor network}} into practice. Some paper discussed the problem in full coverage network mode [10 – 12]. The concept of barrier coverage was first introduced by Gage {{in the context of}} robot systems [13]. An interesting algorithm to determine whether a network provides barrier coverage is provided in Kumar et al. [14]. Some researchers interested in maximizing the lifetime of network. A centralized wakeup/sleep scheme for reaching the full <b>coverage</b> <b>condition</b> is proposed in [15]. Ai designed a localized wakeup/sleep scheme to supplement the problem of activating sensors and it achieved a good performance [16].|$|R
