2|17|Public
40|$|We {{present a}} scheme for online, {{unsupervised}} state discovery and detection from streaming, multi-featured, asynchronous data in high-frequency financial markets. Online feature correlations are computed using an unbiased, lossless Fourier estimator. A high-speed maximum likelihood clustering algorithm is {{then used to}} find the feature cluster configuration which best explains the structure in the correlation matrix. We conjecture that this feature configuration is a <b>candidate</b> <b>descriptor</b> for the temporal state of the system. Using a simple cluster configuration similarity metric, {{we are able to}} enumerate the state space based on prevailing feature configurations. The proposed state representation removes the need for human-driven data pre-processing for state attribute specification, allowing a learning agent to find structure in streaming data, discern changes in the system, enumerate its perceived state space and learn suitable action-selection policies. Comment: 19 pages, 6 figures, 3 tables, under review at Pattern Recognition Letter...|$|E
40|$|Content-based {{complex data}} {{retrieval}} {{is becoming increasingly}} common in many types of applications. The content of these data is represented by intrinsic characteristics, extracted from them which together with a distance function allows similarity queries. Aimed at reducing the “semantic gap”, characterized by the disagreement between the computational representation of the extracted low-level features and how these data are interpreted by the human perception, {{the use of multiple}} descriptors {{has been the subject of}} several studies. This paper proposes a new method to carry out the combination of multiple descriptors for different boundary conditions in which the balancing is carried out in pairs, starting by the best <b>candidate</b> <b>descriptor.</b> In the experiments, the proposed method achieved computational cost up to 3650 times smaller than the exhaustive search for the best linear combination of descriptors, keeping almost the same average precision, with variations lower than 0. 9 %. Fundação de Amparo à Pesquisa do Estado de São Paulo (FAPESP) Coordenação de Aperfeiçoamento de Pessoal de Nível Superior (CAPES) Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq...|$|E
40|$|Abstract. In {{this paper}} we {{describe}} our {{participation in the}} third edi-tion of the BioASQ biomedical semantic indexing challenge. Unlike our participation in previous editions, we have chosen to follow an approach based solely on conventional information retrieval tools. We have eval-uated various alternatives for creating textual representations of MED-LINE articles to be stored in an Apache Lucene textual index. Those indexed representations are queried using {{the contents of the}} article to be annotated and a ranked list of <b>candidate</b> <b>descriptors</b> is created from the retrieved similar articles. Several strategies to post-process those lists of <b>candidate</b> <b>descriptors</b> were evaluated. Performance in the official runs were far from the most competitive systems, but taking into account that our approach in the performed runs did not employ any external knowledge sources, we think that the proposed method could benefit from richer representations for MEDLINE contents. ...|$|R
50|$|The {{following}} table {{shows how}} the Cambridge English: Advanced (CAE) <b>candidate</b> profile <b>descriptors</b> for each individual paper (Reading, Writing, Speaking, Listening, and Use of English) compare to IELTS band scores.|$|R
40|$|We {{propose a}} study on the use of {{hierarchical}} taxonomies for musical instrument recognition on solo recordings. Both a natural taxonomy (inspired by instrument families) and a taxonomy inferred automatically by means of hierarchical clustering are examined. They are used to build a hierarchical classification scheme based on Support Vector Machine classifiers and an efficient selection of features from a wide set of <b>candidate</b> <b>descriptors.</b> The classification results found with each taxonomy are compared and analysed. The automatic taxonomy is found to perform slightly better than the “natural ” one. However, our analysis of the confusion matrices related to these taxonomies suggest that both are limited. In fact, it shows that it could be more advantageous to utilise taxonomies such that the instruments which are commonly confused are put in distinct decision nodes. 1...|$|R
40|$|This {{contribution}} {{focuses on}} the matching of local features between images. Given a set of query descriptors and a database of <b>candidate</b> <b>descriptors,</b> {{the goal is to}} decide which ones should be matched. This is a crucial issue, since the matching procedure is often a preliminary step for object detection, scene identification or image matching. In practice, this matching step is often reduced to a specific threshold on the Euclidean distance to the nearest neighbor. We first introduce a robust distance between descriptors, making use of the Earth Mover’s Distance (EMD). We then propose an a contrario framework for the matching procedure, which enables us to control the number of false alarms. This approach yields validation thresholds automatically adapted to the complexity of the descriptor to be matched and to the diversity and size of the database. The method makes it possible to detect multiple occurrences and to rate the validated matches according to their meaningfulness. 1...|$|R
40|$|This paper {{focuses on}} the {{matching}} of local features between images. Given a set of query descriptors and a database of <b>candidate</b> <b>descriptors,</b> {{the goal is to}} decide which ones should be matched. This is a crucial issue, since the matching procedure is often a preliminary step for object detection or image matching. In practice, this matching step is often reduced to a specific threshold on the Euclidean distance to the nearest neighbor. Our first contribution is a robust distance between descriptors, relying on the adaptation of the Earth Mover's Distance to circular histograms. It is shown that this distance outperforms classical distances for comparing SIFT-like descriptors, while its time complexity remains reasonable. Our second contribution is a statistical framework for the matching procedure, which yields validation thresholds automatically adapted to the complexity of each query descriptor and to the diversity and size of the database. The method makes it possible to detect multiple occurrences, as well as to deal with situations where the target is not present. Its performances are tested through various experiments on a large image database...|$|R
40|$|This paper {{presents}} in {{a systematic}} way problems encountered {{in the construction of}} Lyapunov function <b>candidates</b> for <b>descriptor</b> systems. The solutions to some of the major difficulties in the application of Lyapunov's direct method to descriptor systems are presented. Some new results regarding the extension of Lyapunov's direct method tied to the construction of the Lyapunov functions are given. Also, the algebraic necessary and sufficient conditions for some specific properties of motions of descriptor systems are developed...|$|R
40|$|Abstract—This paper {{focuses on}} the {{matching}} of local features between images. Given a set of query descriptors and a database of <b>candidate</b> <b>descriptors,</b> {{the goal is to}} decide which ones should be matched. This is a crucial issue, since the matching procedure is often a preliminary step for object detection or image matching. In practice, this matching step is often reduced to a specific threshold on the Euclidean distance to the nearest neighbor. Our first contribution is a robust distance between descriptors, relying on the adaptation of the Earth Mover’s Distance to circular histograms. It is shown that this distance outperforms classical distances for comparing SIFT-like descriptors, while its time complexity remains reasonable. Our second contribution is a statistical framework for the matching procedure, which yields validation thresholds automatically adapted to the complexity of each query descriptor and to the diversity and size of the database. The method makes it possible to detect multiple occurrences, as well as to deal with situations where the target is not present. Its performances are tested through various experiments on a large image database. Index Terms—Statistical analysis of matching processes, local feature matching, dissimilarity measure, Earth Mover’s Distance, a contrario...|$|R
40|$|Abstract. This paper {{focuses on}} the {{matching}} of local features between images. Given a set of query descriptors and a database of <b>candidate</b> <b>descriptors,</b> {{the goal is to}} decide which ones should be matched. This is a crucial issue, since the matching procedure is often a preliminary step for object detection or image matching. In practice, this matching step is often reduced to a specific threshold on the Euclidean distance to the nearest neighbor. Our first contribution is a robust distance between descriptors, relying on the adaptation of the Earth Mover’s Distance to circular histograms. It is shown that this distance outperforms classical distances for comparing SIFT-like descriptors, while its time complexity remains reasonable. Our second and main contribution is a statistical framework for the matching procedure, which yields validation thresholds automatically adapted to the complexity of each query descriptor and to the diversity and size of the database. The method makes it possible to detect multiple occurrences, as well as to deal with situations where the target is not present. Its performances are tested through various experiments on a large image database. Key words. Statistical analysis of matching processes, local feature matching, dissimilarity measure, Earth Mover’s Distance, a contrario. AMS subject classifications. 62 H 35, 68 T 45, 68 T 1...|$|R
40|$|The {{study of}} {{otoliths}} is a well-established {{source of information}} for understanding the life offish and fish populations. Conducting fish species identification from otolith samples found in the stomach contents of marine fish-eating animals finds interesting applications such as dietary studies, stock monitoring, assessment and management. Fish species identification can provide useful data for climatology, archaeology and palaeontology research, as otoliths can be sourced from geological sediments or archaeological excavations. Analysing an otolith is a highly complex and time-consuming procedure Therefore, an automated otolith classification system can {{prove to be a}} vital tool {{for a wide variety of}} scientific research. The aim of the programme of work seeks the development of a novel automated fish species identification system. The main focus of this investigation is on the commercially interesting fish of the Northern Aegean Sea. The methodology described in this thesis exploits the inherent shape variability offish otoliths according to their corresponding species. This is based on the processing and analysis of images acquired using a stereoscopic microscope fitted with a digital camera. A compact feature vector is then constructed out of a list of <b>candidate</b> <b>descriptors</b> derived from the morphology as well as the image statistics of the otoliths. The identification is carried out by an intelligent classifier based on an artificial neural network. Several configurations of multi-layer perceptron, radial basis function and hybrid neural networks are considered in pursuit of a practical and expandable classification system. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
30|$|In this paper, we {{formally}} {{demonstrate the}} usefulness of the CAC representation for shape similarity computation. Our shape representation has interesting properties that makes it a good <b>candidate</b> for shape <b>descriptor.</b> However, we would {{like to point out that}} our purpose in this work is not to focus on the CAC representation as a shape descriptor. This issue is left as future work.|$|R
40|$|International audienceThis paper {{presents}} a work on head pose estimation. Here, face images are tagged with head pose information. To achieve head pose estimation, anatomic regions (eyes, nose and mouth) are extracted using a facial <b>descriptor.</b> <b>Candidates</b> for these regions are extracted from an energy map based on Haar-like features. Then, a multi-threshold analysis {{is applied to}} find the position {{and the size of}} each region. Region projections on vertical and horizontal axis enable to define a set of rules in order to estimate head pos...|$|R
40|$|This paper {{presents}} in {{a systematic}} way problems encountered {{in the construction of}} Lyapunov function <b>candidates</b> for <b>descriptor</b> systems. The solutions to some of the major difficulties in the application of Lyapunov's direct method to descriptor systems are presented. Some new results regarding the extension of Lyapunov's direct method tied to the construction of the Lyapunov functions are given. Also, the algebraic necessary and sufficient conditions for some specific properties of motions of descriptor systems are developed. INTRODUCTION AND BACKGROUND It is a tradition to consider the equations describing internal system dynamics of continuous time systems in the normal form of the so-called state equations @ 7 9 #i#^TM 7 ^TM #(S [...] . # (1) where @ 9. B. # is the ordinary time derivative operator, and where # S [...] ., # S [...] . # and 7 S [...] . # denote the time, the input vector and the state vector, respectively. Systems governed by the model (1) we usually call the state [...] ...|$|R
40|$|The {{clustering}} {{phenomenon of}} arrivals known as burstiness {{is an important}} and poorly understood characteristic of broadband traffic. Most of the B-ISDN services produce bursty traffic and the burstiness has {{a significant impact on}} the network performance. However, the nature of burstiness of the various traffic types can be very different. Since, for the time being, there is no well established notion of burstiness there is need for finding an easily computable measure which can express the inherent nature of burstiness in such a way that it fits well to the practical network dimensioning tasks. In this paper we review the most popular burstiness measures and give an analysis study by evaluating them with different kinds of traffic produced by a large set of traffic models. Our aim is to contribute to the understanding of the behaviour of the <b>candidate</b> burstiness <b>descriptors</b> which could take us a step closer to establishing a generally acceptable burstiness measure. ...|$|R
40|$|In machine translation, {{information}} on word ambiguities is usually {{provided by the}} lexicographers who construct the lexicon. In this paper we propose an automatic method for word sense induction, i. e. for {{the discovery of a}} set of sense descriptors to a given ambiguous word. The approach is based on the statistics of the distributional similarity between the words in a corpus. Our algorithm works as follows: The 20 strongest first-order associations to the ambiguous word are considered as sense <b>descriptor</b> <b>candidates.</b> All pairs of these candidates are ranked according to the following two criteria: First, the two words in a pair should be as dissimilar as possible. Second, although being dissimilar their co-occurrence vectors should add up to the co-occurrence vector of the ambiguous word scaled by two. Both conditions together have the effect that preference is given to pairs whose co-occurring words are complementary. For best results, our implementation uses singular value decomposition, entropy-based weights, and second-order similarity metrics. ...|$|R
40|$|Aiming at {{stability}} of line descriptor {{in the process}} of line segment matching, MSLD mean-standard deviation descriptor with corresponding points constraint method is proposed. The method is based on close-range images corresponding points matching and line extraction, in the beginning, determined the points which have the closest distance between the both sides of the target lines on the reference images, virtual line is composed by connecting corresponding points on the search image, and the line which intersects virtual line on the search image is defined as the candidate line segment. Then calculating the MSLD description of the straight lines and the candidate lines respectively, the specific construction steps are as followed: (1) gradient direction and normal direction of the straight line should be determined firstly; (2) for each pixel on the straight line, a rectangular area which is defined as Pixel Support Region (PSR) is established along the gradient direction and the normal direction, and the PSR is decomposed into several same size sub-regions in the normal direction; (3) recording each sub-region the gradient vectors of four directions to obtain a four-dimensional feature vector, and the gradient description matrix of straight line L is composed of all sub-regions feature vectors; (4) mean and standard deviation of the description matrix should be calculated by the row vector, then mean and standard deviation vectors should be normalized to obtain the normalized mean-standard deviation description. Finally, the similarity between the target lines and each <b>candidate</b> lines <b>descriptor</b> is calculated based on the Euclidean distance, using the nearest neighbor distance ratio to determine the corresponding line. Typical region image is selected to perform line matching experiment in this paper, results show that the proposed method has great stability and matching accuracy...|$|R
30|$|According to the {{preceding}} research, the main factors {{to drive the}} size of licensing deals in the life sciences area are development phase, drug class, contract type, contract scope, licensee, molecular structure, market, strategies, competition, IP, and novelty (Arnold et al. 2002). Market size, licensee revenue, molecular structure, and IP {{can be converted to}} numerical value and can be used for the input for prediction for royalty-related data such as running royalty rate (back-end payments) and up-front payment (up-front fee[*]+[*]milestones). In the case of market size, it requires a great amount of time to estimate the proper market size for the subclass of a drug class (e.g., epidermal growth factor, anticancer immunity, ovarian cancer, alpha interferon as a subclass of the anticancer drug class). In the case of molecular structure, it requires professional chemical software to convert chemical structure into numeric code and requires the collection of molecular structure information for the drug candidate. In the case of IP, identifying what could be the unique descriptor for the drug-related patents for input for the X-axis of regression requires more thought (e.g., the technology cycle time median value for the International Patent Classification (IPC) code can be the <b>descriptor</b> <b>candidate).</b> This study selected drug class, licensee revenue, and attrition rate for the development phase as descriptors for the input for the X-axis of regression.|$|R
40|$|The cotton leaf disease {{detection}} is {{the process}} of detecting disease by analyzing their visual properties. The visual properties extraction process from the images is known as the feature extraction. The feature extraction process can be done using the various feature descriptors like SIFT, SURF or other most suitable <b>candidate.</b> The feature <b>descriptors</b> are then passed to the classifier for the evaluation of the feature. The classifier is the algorithm, which is used to classify the feature {{on the basis of its}} similarity with the training dataset. The training dataset is the collection of features previously extracted from the known objects (the leaves with specific disease in this case). The leaves with disease are classified on the basis of their similarity with the training dataset of disease samples previously described by the feature descriptors. In this paper, our aim is to solve the cotton disease detection problem using the image processing techniques automatically from the input image. The disease classification will primarily based upon the visibility of the disease on the cotton leaves, which further can be used for the identification using the classifier. The proposed model implementation would be done using the MATLAB simulator and the proposed model results would be obtained in the form of the accuracy, precision, recall, elapsed time and many other similar parameters...|$|R

