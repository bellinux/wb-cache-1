0|10000|Public
5000|$|Assertions are {{assumptions}} about the model that can be <b>checked</b> using <b>the</b> Alloy <b>Analyzer</b> ...|$|R
30|$|The {{analysis}} of standard HCO 3 − and base excess (BE) and measurement of serum potassium {{were performed on}} a Rapid-Lab 1265 blood gas analyzer (Siemens Medical Solutions, Eschborn, Germany) with automated sample delivery, parameter calibration, and daily quality control <b>checks.</b> <b>The</b> <b>analyzer</b> included electrochemical sensors for measuring pH, pO 2, pCO 2, sodium, potassium (mmol/l), chloride, ionized calcium, glucose, and lactate. HCO 3 − was calculated using the Henderson-Hasselbalch equation: HCO 3 − (mmol/l)[*]=[*] 0.03037 [*]×[*]pCO 2  ×[*] 10 pH− 6.105. The BE was calculated as BE (mmol/l)[*]=[*](1 [*]−[*] 0.014 [*]×[*]ctHb)[*]×[*][(HCO 3 −[*]−[*] 24.8)[*]+[*](1.43 [*]×[*]ctHb[*]+[*] 7.7)[*]×[*](pH[*]−[*] 7.40)].|$|R
5000|$|Yuri Tkachenko, {{the police}} {{explosives}} expert who defused the Ryazan bomb, {{insisted that it}} was in fact RDX, in reply to an FSB report the chemical test was inaccurate due to contamination of the apparatus. [...] Mr. Tkachenko said that the explosives, including a timer, a power source, and a detonator were genuine military equipment and obviously prepared by a professional. He also said that <b>the</b> gas <b>analyzer</b> that tested <b>the</b> vapors coming from the sacks unmistakably indicated the presence of RDX. Mr. Tkachenko said that it {{was out of the question}} that <b>the</b> <b>analyzer</b> could have malfunctioned, as <b>the</b> gas <b>analyzer</b> was of world class quality, costing $20,000 and was maintained by a specialist who worked according to a strict schedule, <b>checking</b> <b>the</b> <b>analyzer</b> after each use and making frequent prophylactic checks. Mr Tkachenko pointed out that meticulous care in the handling of <b>the</b> gas <b>analyzer</b> was a necessity because the lives of the bomb squad experts depended on the reliability of their equipment. The police officers who answered the original call and discovered the bomb also insisted that it was obvious from its appearance that the substance in the bomb was not sugar.|$|R
50|$|In {{computer}} science and software engineering, Alloy is a declarative specification language for expressing complex structural constraints and {{behavior in a}} software system. Alloy provides a simple structural modeling tool based on first-order logic. The mathematical underpinnings of the language were heavily influenced by the Z notation, although the syntax of Alloy owes more to languages such as Object Constraint Language. Alloy is targeted at the creation of micro-models that can then be automatically checked for correctness. Alloy specifications can be <b>checked</b> using <b>the</b> Alloy <b>Analyzer.</b>|$|R
40|$|Abstract. This paper {{describes}} {{the analysis of}} Pull-Based Asynchronous Rekeying Framework (ARF), a recently proposed solution to the scalable group key management problem in secure multicast. A model of this protocol is constructed in Alloy, a lightweight relational modeling language, and analyzed using <b>the</b> Alloy <b>Analyzer,</b> a fully automatic simulation and checking tool for Alloy models. In this analysis, some critical correctness properties that should be satisfied by any secure multicast protocol are checked. Some flaws, previously unknown to the protocol’s designers are exposed, including one serious security breach. To eliminate the most serious flaw, some fixes are proposed and <b>checked</b> using <b>the</b> Alloy <b>Analyzer.</b> <b>The</b> case study also illustrates a novel modeling idiom that supports better modularity and is generally simpler and more intuitive than the conventional idiom used for modeling distributed systems...|$|R
40|$|Rubicon is a {{verifier}} for web applications. Specifications {{are written}} in an embedded domain-specific language and are checked fully automatically. Rubicon is designed to fit with current practices: its language is based on RSpec, a popular testing framework, and its analysis leverages the standard Ruby interpreter to perform symbolic execution (generating verification conditions that are <b>checked</b> by <b>the</b> Alloy <b>Analyzer).</b> Rubicon has been evaluated on five open-source applications; in one, a widely used customer relationship management system, a previously unknown security flaw was revealed. National Science Foundation (U. S.) (CRI: CRD - Development of Alloy Technology and Materials Grant 0707612...|$|R
40|$|A {{software}} system interacts with its environment through interfaces. Improper handling of exceptional returns from system interfaces can cause robustness problems. Robustness of {{software system}}s {{are governed by}} various temporal properties related to interfaces. Static verification {{has been shown to}} be effective in checking these temporal properties. But manually specifying these properties is cumbersome and requires the knowledge of interface specifications, which are often either unavailable or undocumented. In this paper, we propose a novel framework to automatically infer system-specific interface specifications from program source code. We use a model checker to generate traces related to the interfaces. From these model checking traces, we infer interface specification details such as return value on success or failure. Based on these inferred specifications, we translate generically specified interface robustness rules to concrete robustness properties verifiable by static <b>checking.</b> Hence <b>the</b> generic rules can be specified at an abstract level that needs no knowledge of the source code, system, or interfaces. We implement our framework for an existing static analyzer that employs push down model <b>checking</b> and apply <b>the</b> <b>analyzer</b> to <b>the</b> well known POSIX-API system interfaces. We found 28 robustness violations in 10 open source packages using our framework. ...|$|R
3000|$|... [...]. In addition, {{we need to}} <b>check</b> <b>the</b> aliveness and {{synchronization}} of {{the mobile}} device and the cloud server during the authentication. We use <b>the</b> security <b>analyzer</b> Scyther to <b>check</b> <b>the</b> vulnerability {{of each of these}} parameters.|$|R
5000|$|<b>The</b> SANY {{syntactic}} <b>analyzer,</b> which parses and <b>checks</b> <b>the</b> spec for syntax errors.|$|R
30|$|The State Analyzer: <b>The</b> <b>analyzer</b> is {{responsible}} for gathering information about the current DOM, such as the list of event handlers in the current DOM. In addition, {{it is used to}} extract information (such as the screenshots of the current DOM) when a new state is found. Furthermore, <b>the</b> <b>analyzer</b> <b>checks</b> whether <b>the</b> DOM has been updated completely after an action is being executed by the “Action Executor”.|$|R
40|$|The {{electron}} optics of a 90 degree spherical deflecting analyzer (SDA- 90) is investigated with an imaging matrix formalism. As a preanalyzer in the UTAneutrino experiment, high transmission and reasonable energy resolution are {{the choices of}} optimization. The magnification of the source through <b>the</b> <b>analyzer</b> plays <b>the</b> key {{role in determining the}} energy resolution. The imaging matrix approach provides graphical information to facilitate such an evaluation. We can demonstrate that in case where <b>the</b> <b>analyzer</b> is asymmetrically charged, the rotation of the image helps increase both transmission probability and resolution. A telefocus electron gun is used to <b>check</b> <b>the</b> numerical result, and to investigate the transverse focusing behavior. 1 2...|$|R
40|$|We have {{designed}} and implemented a prototype tool, called Embee, which {{makes use of}} <b>the</b> Alloy <b>Analyzer</b> to automatically <b>check</b> <b>the</b> conformance of Java executions against Alloy specifications. Running time tests were conducted {{as part of the}} performance analysis of this tool. This report describes these tests and their results. Some of the results were unexpected, leading to questions about how <b>the</b> Alloy <b>Analyzer</b> functions. ...|$|R
40|$|In {{this paper}} we have {{proposed}} a spam filtering technique using (2 + 1) -tier classification approach. The main focus {{of this paper is}} to reduce the false positive (FP) rate which is considered as an important research issue in spam filtering. In our approach, firstly the email message will classify using first two tier classifiers and the outputs will appear to <b>the</b> <b>analyzer.</b> <b>The</b> <b>analyzer</b> will <b>check</b> <b>the</b> labeling of the output emails and send to the corresponding mailboxes based on labeling, for the case of identical prediction. If there are any misclassifications occurred by first two tier classifiers then tier- 3 classifier will invoked by <b>the</b> <b>analyzer</b> and <b>the</b> tier- 3 will take final decision. This technique reduced the analyzing complexity of our previous work. It has also been shown that the proposed technique gives better performance in terms of reducing false positive as well as better accuracy. <br /...|$|R
40|$|In this paper, {{we present}} a {{efficient}} security protocol analyzer to verify cryptographic security protocols. Our analyzer verifies security protocols based on notions of provable security. <b>The</b> <b>analyzer</b> only <b>checks</b> whether <b>the</b> core properties of security protocols satisfy the notions, making it faster than previous tools. <b>The</b> <b>analyzer</b> automatically <b>checks</b> whether authentication and key distribution protocols satisfy definitions such as Secure Mutual Authentication, Semantic Security, and Forward Secrecy. A user can design and evaluate security protocols by using our <b>analyzer,</b> according to <b>the</b> condition that the protocol will be used. Furthermore, our analyzer has a sophisticated GUI to set security protocols to be evaluated. Thus, <b>the</b> <b>analyzer</b> is useful for constructing and checking security protocols for many services. Key words...|$|R
40|$|While rigorous, {{mathematical}} {{techniques are}} helpful {{for improving the}} quality of software engineering, the threshold of learning and adapting formal methods keep many practitioners from embracing these kinds of approaches. We present the emph{Arctis Analyzer}, a tool for supporting a developer by formal methods, without the developer having to understand any formal language. To realize this tool, we developed an extensible analysis framework that is used by <b>the</b> <b>analyzer</b> to assist <b>the</b> user when problems are encountered. We combine model checking with syntactic analysis so as to provide a developer with not only symptoms, but also diagnoses and fixes for the underlying flaws in the specifications. Our work is based in SPACE, an approach for specifying reactive and distributed systems. In this approach, systems are composed of service specifications as opposed to traditional component specifications. Services are expressed by UML collaborations and activities representing their structure and behavior, respectively. This work focuses on analyzing the behavior of the services, hence on the UML activities. <b>The</b> <b>analyzer</b> transforms <b>the</b> UML models into tlaplus{}, the language of the Temporal Logic of Actions, TLA. It also generates TLA theorems for a number of properties that should hold. In order to detect property violations, the tool uses the model checker TLC to <b>check</b> <b>the</b> entire state space of the formal specifications. <b>The</b> <b>analyzer</b> can visualize any error traces from TLC in terms of the graphical model that the user is working on. This thesis presents <b>the</b> <b>analyzer</b> and how it is implemented. It also presents the analysis framework detailing twelve theorems, eleven symptoms, seven diagnoses and nine fixes. Out of these, ten theorems, six symptoms, three diagnoses and two fixes, have been implemented in <b>the</b> <b>analyzer</b> as proof of concept. The thesis also contains a number of examples showing the use of <b>the</b> <b>analyzer</b> within Arctis. </p...|$|R
40|$|Only a small {{fraction}} of the output generated by typical static analysis tools tends to reveal serious software defects. Finding the important defects in a long list of warnings can be a frustrating experience. The output often reveals more about the limitations of <b>the</b> <b>analyzer</b> than about <b>the</b> code being analyzed. There are two main causes for this phenomenon. The first is that <b>the</b> typical static <b>analyzer</b> casts its nets too broadly, reporting everything reportable, rather than what is likely to be a true bug. The second cause is that most static <b>analyzers</b> can <b>check</b> <b>the</b> code for only a predetermined, fixed, set of bugs: the user cannot make <b>the</b> <b>analyzer</b> more precise by defining and experimenting with a broader range of application-dependent properties. We describe a source code analyzer called UNO that tries to remedy these problems. The default properties searched for by UNO are restricted to the three most common causes of serious error in C programs: use of uninitialized variables, nil-pointer dereferencing, and out-of-bound array indexing. <b>The</b> <b>checking</b> capabilities of UNO can be extended by the user with the definition of application-dependent properties, which can be written as simple ANSI-C functions...|$|R
40|$|This work {{includes}} design, {{implementation and}} testing of a microcontroller  based spectrum analyzer system. Both hardware and software structures are built to verify the main functions that are required by such system. Their design utilizes the permissible and available tools to achieve the main functions of the system {{in such a way}} to be modularly permitting any adaptation for a specific changing in the application environment. The analysis technique, mainly, depends on the Fourier analysis based methods of spectral analysis with the necessary required preconditioning processes. The software required for waveform analysis has been prepared. The spectrum of the waveform has been displayed, and the instrument accuracy has been <b>checked.</b> <b>The</b> basic hardware parts of <b>the</b> <b>analyzer</b> are <b>the</b> processor and the associated logic, storage media, communication to a central master computer and the data acquisition parts. However, the input / output structure is modular and may change according to the application requirements. The basic operating software modules, which are independent of an application, may be used {{as a part of a}} software package that can carryout other functions. A complete software development tools package to develop application programs, using IBM-PC and <b>the</b> <b>analyzer</b> instrument, are installed and realized at levels, the PC level and <b>the</b> <b>analyzer</b> instrument level...|$|R
40|$|<b>The</b> Logfile <b>Analyzer</b> is a {{tool for}} {{automatically}} analyzing the logfiles generated during a parallel program execution. The purpose of the tool is to <b>check</b> <b>the</b> communication consistency of parallel programs using MPI. It can help the programmer to detect the communication errors, improve the parallel program reliability, and give the programmer an overall picture of the communication sequence. Along with <b>the</b> <b>Analyzer,</b> <b>the</b> tool also provides the Logger and the Wrapper enabling the automatic generation of the logfiles from MPI programs. The logging procedure is hidden from the user. The logfiles contain all information needed for analyzing. Currently, the tool supports all major MPI functions. The tool is implemented in C++. It is extensible and reusable. Key words: Parallel Programming, Message Passing, Debugging, MPI. 1 Introduction Parallel programming using message passing is prone to errors such as communication inconsistency, for example unmatched send and receive. In this paper, [...] ...|$|R
40|$|The paper {{presents}} a rapid method {{of developing a}} shallow Arabic morphological <b>analyzer.</b> <b>The</b> <b>analyzer</b> will only be concerned with generating the possible roots of any given Arabic word. <b>The</b> <b>analyzer</b> is based on automatically derived rules and statistics. For evaluation, <b>the</b> <b>analyzer</b> is compared to a commercially available Arabi...|$|R
50|$|<b>The</b> <b>analyzer</b> {{is used to}} {{identify}} sections of code that can be executed concurrently. <b>The</b> <b>analyzer</b> uses <b>the</b> static data information provided by <b>the</b> scanner-parser. <b>The</b> <b>analyzer</b> will first find out all the functions that are totally independent {{of each other and}} mark them asindividual tasks. Then analyzer finds which tasks are having dependencies.|$|R
40|$|We present Prioni, a {{tool that}} {{integrates}} model checking and theorem proving for relational reasoning. Prioni takes as input formulas written in Alloy, a declarative language based on relations. Prioni uses <b>the</b> Alloy <b>Analyzer</b> to <b>check</b> <b>the</b> validity of Alloy formulas for a given scope that bounds the universe of discourse. <b>The</b> Alloy <b>Analyzer</b> can refute a formula if a counterexample exists within the given scope, but cannot prove that the formula holds for all scopes. For proofs, Prioni uses Athena, a denotational proof language. Prioni translates Alloy formulas into Athena proof obligations and uses the Athena tool for proof discovery and checking...|$|R
40|$|Cerebrospinal fluid is {{examined}} {{using a variety}} of methods, which also include determining the number and type of each cell. Now the method of the first choice to determine the cellular elements is a microscopic method. This determination, however, can also be done using <b>the</b> <b>analyzer</b> method, which is not yet so widespread. The aim of my thesis was to compare these two methods and determine whether the examination of cerebrospinal fluid on <b>the</b> <b>analyzer</b> Sysmex XE- 5000 in the "Body Fluid" mode can replace commonly used microscopic methods. To this purpose, we gathered the laboratory data measured by using both these methods. These data was compared, evaluated and statistically processed. The resulting data suggest that the values measured on <b>the</b> <b>analyzer</b> Sysmex XE- 5000 are more accurate than from microscopic determination, especially at highly cell samples of cerebrospinal fluid. To this end, we came evaluation of Bland-Altman graphs and comparison graphs with marked of limits of physiological oligocytosis. For <b>checking</b> of <b>the</b> accuracy of measurements, we verified the repeatability of <b>the</b> <b>analyzer</b> for <b>the</b> values of leukocytes and erythrocytes, coefficients of variation corresponding to the values specified by the manufacturer's documentation. We also investigated the stability of samples of [...] ...|$|R
30|$|<b>The</b> <b>Analyzer</b> {{engine starts}} each scan (call 4 of the UML {{sequence}} diagram) and stores its ID. A scan may take several minutes to complete, {{as the current}} OpenVAS database includes more than 50, 000 entries. Besides, the scan duration may {{vary according to the}} number of services on the target and the processing load on the Scanner and the Server being scanned. Currently, the VAS is queried every five seconds to <b>check</b> whether <b>the</b> scan has finished, at which point <b>the</b> <b>Analyzer</b> engine uses <b>the</b> stored ID as a key to recover its report (call 5). Each report from the OpenVAS includes, among other data: the CVE, the CVSS, the host, the port bound to the affected service, the protocol, the suggested solution type, and the affected software name. <b>The</b> <b>Analyzer</b> engine process <b>the</b> received report (call 6) to check whether a vulnerability has been detected, or a vulnerability previously detected is no longer present. When a vulnerability is detected the Decision engine is activated to handle it (call 7).|$|R
50|$|<b>The</b> <b>analyzer</b> {{is used to}} {{identify}} sections of code that can be executed concurrently. <b>The</b> <b>analyzer</b> uses <b>the</b> static data information provided by <b>the</b> scanner-parser.The <b>analyzer</b> will first find out all the functions that are totally independent {{of each other and}} mark them asindividual tasks. Then analyzer finds which tasks are having dependencies.|$|R
40|$|International audienceWe have {{designed}} and built a hemispherical retarding field energy analyzer {{in order to facilitate}} characterization of large area electron emitters (typically field emitter arrays with active areas up to 1 cm 2) with large angular aperture. A complete numerical model of <b>the</b> <b>analyzer</b> has been built, including perturbations due to secondary particles, in order to determine <b>the</b> <b>analyzer</b> performances. <b>The</b> <b>analyzer</b> energy resolution is better than 100 meV for an energy range up to 120 eV. <b>The</b> <b>analyzer</b> has a global field of view of 112 ° and allows measurements of the energy distribution of the beam {{as a function of the}} emission angle, as well as measurements of the beam intensity profile along any section of the beam. We have successfully used <b>the</b> <b>analyzer</b> to characterize <b>the</b> electron beam emitted by 1 cm 2 Mo microtips-based field emitter arrays...|$|R
40|$|This paper {{represents}} a Semantic <b>Analyzer</b> for <b>checking</b> <b>the</b> semantic correctness of the given input text. We describe our system {{as the one}} which analyzes the text by comparing it with {{the meaning of the}} words given in the WordNet. <b>The</b> Semantic <b>Analyzer</b> thus developed not only detects and displays semantic errors in the text but it also corrects them...|$|R
30|$|After these verifications, we {{assembled}} the flight HV board and further <b>checked</b> <b>the</b> {{response to the}} electron beam. As we mentioned above, it is generally difficult to compare the simulation with the laboratory results for electron beams due to the deflection by the geomagnetic field. Nonetheless, we confirmed the predicted relativistic effect (e.g., at 70  keV, the SV value corresponding to the peak count shifted 7 % compared to the nonrelativistic case). Figure  10 d shows the simulation result for 70  keV with the relativistic effect (in gray), fitting well to the laboratory result for a 70  keV electron beam (in cyan). Through these results, we confirmed that <b>the</b> <b>analyzer</b> was manufactured and assembled properly as per the design. In addition, we <b>checked</b> <b>the</b> EUV rejection, using a D 2 lamp with a photon flux similar to the solar irradiance. We confirmed there was no increase in noise from the background level.|$|R
40|$|A droplet {{actuator}} with cartridge is provided. According to one embodiment, {{a sample}} analyzer is provided {{and includes a}}n analyzer unit comprising electronic or optical receiving means, a cartridge comprising self-contained droplet handling capabilities, and a wherein the cartridge is coupled to <b>the</b> <b>analyzer</b> unit by a means which aligns electronic and/or optical outputs from the cartridge with electronic or optical receiving means on <b>the</b> <b>analyzer</b> unit. According to another embodiment, a sample analyzer is provided and includes a sample analyzer comprising a cartridge coupled thereto and a means of electrical interface and/or optical interface between the cartridge and <b>the</b> <b>analyzer,</b> whereby electrical signals and/or optical signals may be transmitted from the cartridge to <b>the</b> <b>analyzer...</b>|$|R
40|$|The aim of {{the project}} is to design a generic logic {{analyzer}} based on an FPGA. <b>The</b> <b>analyzer</b> {{should be able to}} analyze protocols such as I 2 C, SPI, RS 232, RS 485 and GPIO. The captured data can be observed using an embedded graphical display or using a PC. The PC can be used to control <b>the</b> <b>analyzer</b> and to save the captured data. The thesis is divided into several parts. First, the basic structure of <b>the</b> <b>analyzer</b> is described including detailed description of its particular components. Later on, the most common protocols that can be decoded using <b>the</b> <b>analyzer</b> are described. Finally, the FPGA subsystem and microcontroller application are presented together with corresponding source codes...|$|R
40|$|Modern Intrusion Detection Systems (IDSs) are {{distributed}} real-time systems that detect unauthorized use or attacks upon an organization’s network and/or hosts. The components of most distributed IDSs {{are arranged in}} a hierarchical tree structure, where the sensor nodes pass information to <b>the</b> <b>analyzer</b> nodes. Optimal placement of <b>the</b> <b>analyzer</b> nodes results in an improved response time for the IDS, and isolation of attacks within the IDS network. Since the network topology and workload are constantly changing, {{we are able to}} maintain near-optimal placement of <b>the</b> <b>analyzer</b> nodes by instantiating them as mobile agents. <b>The</b> <b>analyzer</b> nodes may then relocate, reproduce or be deleted as necessary. Such flexibility improves the response times and the stability of an IDS. The movement of <b>the</b> <b>analyzer</b> nodes also offers some protection against denial-ofservice attacks, since secure analyzer nodes will be relocated to take over some of the functionality of the host under attack. KEY WORDS: intrusion detection systems; mobile agents; scalability. 1...|$|R
40|$|Biomass {{gasification}} is {{the process}} of partially oxidizing organic matter into hydrogen, carbon monoxide, and other gases that can be combusted in engines to generate electricity. The process emits nitrogen oxides (NOx gases) whose concentrations must be accurately measured. This project evaluated the accuracy of the portable Continental Smart NOx Sensor by comparing its readings to those of an external laboratory grade <b>analyzer.</b> <b>The</b> Continental sensor consistently read higher NOx concentrations than <b>the</b> <b>analyzer,</b> though it is unclear whether the sensor simply measured inaccurately or was affected by ammonia in the exhaust, as is known to be a potential issue with onboard NOx sensors. Because the ammonia content of the exhaust was not <b>checked,</b> <b>the</b> Continental sensor’s accuracy was ultimately not determined and more research is required. This research was supported by the Undergraduate Research Opportunities Program (UROP) ...|$|R
40|$|This {{bachelor}} thesis {{deals with}} the basic description of produced by fatigue failure of ball bearings. In the paper there is a description of basic diagnostic methods of machine parts. Following there is a study of vibration, their recording and the evaluation concerning bearing lifetime. The aim of the experimental part of the paper is to <b>check</b> <b>the</b> functionality and suitability od <b>the</b> VDT 2000 <b>analyzer</b> and VDT Control Center software, both made by company VidiTech, s. r. o. together with the SA 67 laboratory experimental stations owned by the Department of Design at Faculty of Mechanical Engineering, which were used for examining the 6204 - 2 Z bearings. The aim of the lifespan exam is to confirm {{the reliability of the}} bearing failure warning by <b>the</b> <b>analyzer</b> and to assess the ability to record the first stages of bearing damage...|$|R
50|$|Today, {{there are}} three basic types of analyzer: <b>the</b> swept-tuned {{spectrum}} <b>analyzer,</b> <b>the</b> vector signal <b>analyzer,</b> and <b>the</b> real-time spectrum <b>analyzer.</b>|$|R
30|$|<b>The</b> {{resource}} <b>analyzer</b> {{takes care}} of the resource descriptors provided by OGE and the private Cloud environment. <b>The</b> <b>analyzer</b> component generates eight different job configurations {{on the basis of the}} cluster resource descriptor setting the amount of compute nodes for this job between one and eight nodes. Additionally, <b>the</b> <b>analyzer</b> component creates twelve job configurations setting the amount of Cloud nodes to be allocated from one to twelve.|$|R
40|$|In usual {{measurement}} {{with the}} Senarmont method using a conventional polarization microscope, the azimuth angle of <b>the</b> <b>analyzer</b> at extinction {{of the emerging}} light is detected by naked eyes. If the intensity of light is measured {{as a function of}} the azimuth angle of <b>the</b> <b>analyzer,</b> one can find the direction at which the intensity is minimized more accurately by fitting. However, this procedure requires much numbers of operations as compared to the usual method, and thus is time-consuming. To circumvent this problem a setting with which the intensity is measured {{as a function of the}} azimuth angle of <b>the</b> <b>analyzer</b> is constructed with rotation of <b>the</b> <b>analyzer</b> through a computer control. As a result, the time required for the measurement has been greatly decreased. Comment: 16 pages, 3 figures; Instrumentation Science & Technology, accepte...|$|R
40|$|In {{present report}} {{operational}} principle {{and construction of}} the multiple view lines neutral particle analyzer for hydrogen atoms is described. <b>The</b> <b>analyzer</b> is built according to the pin-hole camera scheme. The same approach has already been used for space studies [1, 2]. Our instrument fulfils some specific requirements for the magnetically confined plasma diagnostics. <b>The</b> <b>analyzer</b> is designed to measure spatial distribution of fast charge-exchange atoms emitted by high temperature plasma. The dispersion system of <b>the</b> <b>analyzer</b> {{is based on the}} electrostatic analysis. Hydrogen atoms stripping may be performed both in the gas cell containing molecular hydrogen and in the thin carbon foil. <b>The</b> <b>analyzer</b> was calibrated for both targets. Data on absolute efficiency and energy resolution as a function of energy are presented. <b>The</b> <b>analyzer</b> has seven spatial channels covering full view angle of about 45 o with common crossover {{at the center of the}} front flange. It has energy range from 1 to 50 keV. Energy resolution may be varied between 3 and 12 % in the existin...|$|R
