1|10000|Public
40|$|The {{purpose of}} this manual is to provide {{guidance}} to UAA employees who have administrative oversight or technical research responsibility relative to restricted fund accounts. In addition, it provides the users {{with an understanding of}} the role UAA Grants and Contract Services plays in the administration of restricted funds. The role of UAA Grants and Contract Services (UAA GCS) is to provide support to UAA constituents for all post award activities at the University of Alaska. UAA GCS’ responsibilities include the establishment of new restricted fund accounts, budget revisions, the preparation of invoices and the <b>collection</b> <b>of</b> <b>amounts</b> due from funding agencies. GCS also provides compliance reviews for all actions subsequent to award. The purpose is to minimize conflicts of interest and assure compliance with applicable regulations and requirements for restricted funds according to award terms and conditions. UAA GCS is the central point of contact for funding agencies in all matters relating to sponsored programs. The Authorized Organization Representative (AOR) duties for all awards under $ 500, 000 are delegated to the Director of the Grants and Contract Services. For awards greater than $ 500, 000, the Vice Provost for Research/Dean of the Graduat...|$|E
50|$|In {{finance the}} term {{recovery}} refers to <b>collection</b> <b>of</b> <b>amount</b> due. The normally recovery {{depends on the}} purpose, time and condition, business running process etc.|$|R
50|$|The {{specimens}} <b>of</b> the <b>collection</b> <b>of</b> paleontology <b>amount</b> to tens <b>of</b> thousands. They {{date from}} the Paleoarchean to the Eocene.|$|R
5000|$|In 2015-2016, {{the gross}} tax <b>collection</b> <b>of</b> the Centre <b>amounted</b> to [...]|$|R
30|$|The GA-based hybrid {{approach}} provides {{flexibility and}} facilitates the <b>collection</b> <b>of</b> large <b>amounts</b> <b>of</b> information {{in terms of}} altering the α level and shape parameters in the exponential membership function and providing various scenario analyses to the DM for fuzzy allocation strategy.|$|R
40|$|The {{development}} of high-throughput biotechnology, such as microarrays, has {{made possible the}} <b>collection</b> <b>of</b> large <b>amounts</b> <b>of</b> genomic data. In turn, we face new challenges in applying existing statistical methods or developing novel ones to properly analyze this new generation of biological data. One problem in bioinformatic...|$|R
40|$|Atmospheric {{simulation}} is {{an important}} means of understanding the environment around us. Through the <b>collection</b> <b>of</b> large <b>amounts</b> <b>of</b> atmospheric data and computer modeling one can predict how variuos particulates such as dirt, smog, and fire can affect our cities and overall public health. However, gleaning insight from numerica...|$|R
40|$|Management of lake {{ecosystems}} in {{the territory}} of protected areas {{is associated with a}} number <b>of</b> difficulties, the <b>collection</b> <b>of</b> large <b>amounts</b> <b>of</b> data, their operational processing, analysis and informed decision-making environmental focus. GIS allows us to solve, as well as to enhance the effectiveness and efficiency of such decision...|$|R
40|$|A {{world of}} {{ubiquitous}} computing, full of networked mobile and embedded technologies, is approaching. The {{benefits of this}} technology are numerous, and act as the major driving force behind its development. These benefits are brought about, in part, by ubiquitous monitoring (UM) : the continuous and wide spread <b>collection</b> <b>of</b> ?significant <b>amounts</b> <b>of</b> data about user...|$|R
40|$|In {{recent years}} laser {{scanning}} and terrestrial imaging have enabled the <b>collection</b> <b>of</b> large <b>amounts</b> <b>of</b> LiDAR (Light Detection and Ranging) data. New laser scanning equipment {{made it easier}} to acquire 3 -D representations of real world entities as high-density point clouds, which may then be generalized to compact forms such as TINs, meshes, surfaces and solids. Increasing LiDAR densities bring new dat...|$|R
40|$|Personalized {{interaction}} with computer {{systems can be}} at odds with privacy since it necessitates the <b>collection</b> <b>of</b> considerable <b>amounts</b> <b>of</b> personal data. Numerous consumer surveys revealed that computer users are very concerned about their privacy online. The <b>collection</b> <b>of</b> personal data is also subject to legal regulations in many countries and states. This talk presents work in the area of Privacy-Enhanced Personalization that aims at reconciling personalization with privacy through suitable human-computer interaction strategies and privacy-enhancin...|$|R
40|$|Rapid {{development}} of wireless and mobile technologies which enable the <b>collection</b> <b>of</b> large <b>amounts</b> <b>of</b> data from moving objects. Spatio-temporal databases that represent and manage changes {{related to the}} movement of objects. Such collected data contain the instant vital information of moving objects. Traditional DBMSs are not well equipped to handle data from moving objects. This poster presents the challenges in handling Spatio-temporal databases...|$|R
50|$|The CPU {{time spent}} on finding these factors by a <b>collection</b> <b>of</b> {{parallel}} computers <b>amounted</b> approximately to the equivalent of almost 2000 years of computing on a single-core 2.2 GHz AMD Opteron-based computer.|$|R
40|$|To {{understand}} better a complex disease such as psoriatic arthritis (PsA), <b>collection</b> <b>of</b> a large <b>amount</b> <b>of</b> information on clinical, laboratory, and radiological features is required {{over an extended}} period of time. Longitudinal data can be effectively collected and stored in clinical registries and databases. This article reviews current databases in PsA and proposes a structure for an international PsA registry. Careful <b>collection</b> and analysis <b>of</b> patient data through collaborative efforts will likely advance our knowledge of pathogenesis and provide new and much needed insights about the course and prognosis of the disease. T he study of a complex disease such as psoriatic arthritis (PsA) requires <b>collection</b> <b>of</b> a large <b>amount</b> <b>of</b> informa-tion on clinical, laboratory, and radiological features ove...|$|R
40|$|Many {{research}} {{projects in the}} biological sciences have benefited from software and hardware that allows the automatic <b>collection</b> <b>of</b> large <b>amounts</b> <b>of</b> data. However, the full benefits of having this wealth of new data remain unrealized as much tedious analysis is still done by hand. Stem cell research is one sub-field suffering from this problem. Stem cell researchers have collected time-lapsed images of microwells populated with dividing stem cells...|$|R
50|$|Key to {{the success}} of this {{approach}} is the <b>collection</b> <b>of</b> large <b>amounts</b> <b>of</b> data with which to train the models and the use of data from as wide and heterogeneous range of sources as possible to maximise the generalisability of the models’ predictions. In order to achieve this, the RDI set out to involve as many clinics worldwide as possible and to be the single repository for the data required, in an attempt to avoid unnecessary duplication of effort and competition.|$|R
5000|$|Translational Bioinformatics (TBI) is a {{relatively}} new field that surfaced in the year of 2000 when human genome sequence was released (Tenenbaum, 2016). The commonly used definition of TBI is lengthy and could be found on the. In simpler terms, TBI could be defined as a <b>collection</b> <b>of</b> colossal <b>amounts</b> <b>of</b> health related data (biomedical and genomic) and translation of the data into individually tailored clinical entities (Tenenbaum, 2016).Today, TBI field is categorized into four major themes that are briefly described below: ...|$|R
50|$|Many {{open science}} {{projects}} focus on gathering and coordinating encyclopedic <b>collections</b> <b>of</b> large <b>amounts</b> <b>of</b> organized data. The Allen Brain Atlas maps gene expression in human and mouse brains; the Encyclopedia of Life documents all the terrestrial species; the Galaxy Zoo classifies galaxies; the International HapMap Project maps the haplotypes {{of the human}} genome; and the Sloan Digital Sky Survey which regularizes and publishes data sets from many sources. All these projects accrete information provided by many different researchers with different standards of curation and contribution.|$|R
5000|$|The Article 29 Data Protection Working Party {{delivered}} {{an opinion}} on April 13, 2016, stating that the Privacy Shield offers major improvements compared to the Safe Harbour decisions, but that three major points of concern still remain. They relate to deletion <b>of</b> data, <b>collection</b> <b>of</b> massive <b>amounts</b> <b>of</b> data, and clarification of the new Ombudsperson mechanism. The European Data Protection Supervisor issued {{an opinion on}} 30 May 2016 in which he stated that [...] "the Privacy Shield, as it stands, is not robust enough to withstand future legal scrutiny before the European Court".|$|R
40|$|The glycoproteinaceous {{constituents}} of molluscan shell matrices usually resist chromatographical fractionation. We describe a protocol that overcomes this difficulty and permits <b>collection</b> <b>of</b> a large <b>amount</b> <b>of</b> shell proteins for further in vitro characterization. After {{dissolution of the}} mineral phase, the glycoproteins are fractionated �blind� on a preparative electrophoresis. They are subsequently detected with a polyclonal antibody raised against the whole matrix...|$|R
40|$|As {{a result}} {{of state and federal}} {{education}} requirements, administrators must collect prodigious <b>amounts</b> <b>of</b> information on exceptional pupils and special education programs. Automated information management systems are thought to provide numerous advantages for administrators overloaded by paperwork. The lure of these benefits has caused many special educators to rush headlong to automate the information-management function. Technologically inexperi-enced administrators, however, have been surprised to find their overly optimis-tic expectations severely challenged by the realities of automated systems. This paper describes three real advantages and five common misconceptions brought to automating special education information management. State and federal regulations gov-erning the education of excep-tional children require the <b>collection</b> <b>of</b> substantial <b>amounts</b> <b>of</b> pupil and program data by the local school dis-trict. The <b>collection</b> <b>of</b> pupil and pro...|$|R
40|$|In {{the context}} of {{required}} increase of food production for rapid population growth, {{it is critical to}} improve the productivity of water in the irrigation systems. It may require a lot of field investigations to gather this information at large and especially complex systems like the Liyuankou Irrigation System (LIS), located in located on the right bank of Yellow River in North West China. The use of geo-information techniques such as remote sensing and GIS data has come to override most of the difficulties encountered in <b>collection</b> <b>of</b> large <b>amount</b> <b>of</b> data, especially following the state-of-the-art development on the calculation of actual evapotranspiration...|$|R
40|$|The {{advances}} in the digital world has rendered the <b>collection</b> <b>of</b> colossal <b>amounts</b> <b>of</b> data called Big Data. This voluminous data if analyzed in an expedient way can help us gain valuable insights. On the other hand, securing Big Data has become an important aspect as {{it can lead to}} disastrous results if intercepted by intruders. Through this paper, we describe the management of authentication and access control by providing an overview of the existing protocols. Further, we propose a modified protocol which amalgamates the authentication and authorization processes there by speeding up the entire procedure...|$|R
40|$|The <b>collection</b> <b>of</b> large <b>amounts</b> <b>of</b> {{airborne}} {{particulate matter}} (PM) over {{short periods of time}} has obvious benefits for toxicological studies, allowing rapid supply of enough fresh material for assays and particle characterisation. A high-volume air particle collector (originally developed by Harvard University), operating at 1100 l/min, is currently being used to collect PM 10 and PM 2. 5 separately in specific locations throughout the UK, chosen according to their air pollution range. To date (2002), airborne samples have been collected in London, Birmingham, Port Talbot and Cardiff. Future locations also include Belfast and south Cornwall...|$|R
40|$|The {{first and}} one of the most {{important}} processes in the field of genome annotation is to find all genes encoded in a genome and to identify all variation of transcripts. Although great progress in <b>collection</b> <b>of</b> a large <b>amount</b> <b>of</b> cDNA and EST sequences has been achieved, the goal is not yet close. A promising approach toward solution of this problem is to use comparative analyses of genomes an...|$|R
5000|$|He {{would only}} be {{in his early twenties}} when in 1829 he {{published}} a <b>collection</b> <b>of</b> his songs, <b>amounting</b> to 24 pages filled with humour. The Chapbook was called A <b>Collection</b> <b>of</b> original local songs; it was [...] "Printed for the author by Wm Fordyce, Dean Street, Newcastle 1829" [...] In the early 19th century, Newcastle had quite a <b>collection</b> <b>of</b> local eccentrics (also referred to as “worthies”, and John Marshall mentioned them, and their peculiarities, in many of the songs.|$|R
40|$|Abstract. Recent {{technological}} advances enable the <b>collection</b> <b>of</b> huge <b>amounts</b> <b>of</b> data. Commonly, {{these data are}} generated, stored, and owned by multiple entities that are unwilling to cede control of their data. This distributed environment requires statistical tools that can produce correct results while preserving data privacy. Privacy-preserving protocols have been proposed to solve specific statistical analysis such as linear regression, clustering, and classification. In this paper, we present methods and protocols for privacy-preserving maximum likelihood estimation in general settings. We discuss both horizontally and vertically partitioned data, and propose procedures that allow participating parties {{to withdraw from the}} joint computation. Logistic regression is used to demonstrate our method. ...|$|R
5000|$|The CPU {{time spent}} on finding these factors by a <b>collection</b> <b>of</b> {{parallel}} computers <b>amounted</b> [...] - [...] very approximately [...] - [...] to the equivalent of 75 years work for a single 2.2 GHz Opteron-based computer. Note that while this approximation serves to suggest {{the scale of the}} effort, it leaves out many complicating factors; the announcement states it more precisely.|$|R
40|$|Floating {{water-plantain}} (Luronium natans L Rafinesque) is {{a critically}} endangered aquatic macrophyte species inhabiting two localities {{in the north}} of the Czech Republic (PLA Labské pískovce). Due to planned reconstruction of one of the native localities, called Kralovomlynsky pond, it is necessary to provide survival of the endangered species. Large transplant experiment allowed for optimizing methodology for careful <b>collection</b> <b>of</b> a large <b>amount</b> <b>of</b> native plants from the pond and their transplantation to three refugees...|$|R
5|$|Later, Don Wenceslao Molo, a local from Romblon town, was {{appointed}} governor and became {{responsible for the}} <b>collection</b> <b>of</b> a total <b>amount</b> <b>of</b> , Romblon’s share to the war expenditures of the Revolutionary Government from 31 May 1898 to 28 February 1899. A local election was also held in Romblon town for its ministers of justice and barrio officials. However, Molo’s term was a brief transition to another era as the Americans arrived in the province a few months later.|$|R
30|$|However, documenting these public-available online {{records and}} mining them for useful {{information}} about Chinese movie audiences and their behavior toward international films is a challenging undertaking {{especially with a}} single machine. It involves the <b>collection</b> <b>of</b> massive <b>amounts</b> <b>of</b> data created by movie reviewers, ranging from individual users to geographically based catchments that grow over time. Furthermore, to gain a comprehensive understanding of Chinese-based UGC in this area, {{a variety of factors}} must be considered, such as specific features of films and movie reviews, as well as user profiles. In summary, the Douban OSN offers great potential of the Big Data application for analyzing Chinese UGC in ways that other studies such as [34] have yet to master.|$|R
40|$|Recent {{laboratory}} calibrations of the Airborne Visible/Infrared Imaging Spectrometer (AVIRIS) include {{new methods}} for {{the characterization of}} the geometric, spectral, temporal and radiometric properties of the sensor. New techniques are desired in order to: (1) increase measurement accuracy and precision, (2) minimize measurement time and expense, (3) prototype new field and inflight calibration systems, (4) resolve measurement ambiguities, and (5) add new measurement dimensions. One of the common features of these new methods {{is the use of}} the full data collection and processing power of the AVIRIS instrument and data facility. This allows the <b>collection</b> <b>of</b> large <b>amounts</b> <b>of</b> calibration data {{in a short period of}} time and is well suited to modular data analysis routines...|$|R
50|$|Long-term {{ecological}} research (LTER) {{sites are}} research sites {{funded by the}} government that have collected reliable long-term data {{over an extended period}} of time in order to identify long-term climatic or ecological trends. These sites provide long-term temporal and spatial data such as average temperature, rainfall and other ecological processes. The main purpose of LTERs for urban ecologists is the <b>collection</b> <b>of</b> vast <b>amounts</b> <b>of</b> data over long periods of time. These long-term data sets can then be analyzed to find trends relating to the effects of the urban environment on various ecological processes, such as species diversity and abundance over time. Another example is the examination of temperature trends that are accompanied with the growth of urban centers.|$|R
50|$|The <b>collections</b> <b>of</b> {{the museum}} <b>amount</b> to nearly 1,500 items: furniture, light fittings, glass art items {{and other things}} {{designed}} by Aino Aalto and Alvar Aalto. They also include paintings by Alvar Aalto and more than 30 models of his buildings. In addition to unique pieces <b>of</b> furniture, the <b>collections</b> include almost all models that were mass-produced, {{as well as a}} great number of prototypes.|$|R
40|$|Abstract Web sites {{allow the}} <b>collection</b> <b>of</b> vast <b>amounts</b> <b>of</b> navigational data- clickstreams of user traversals through the site. These massive data stores offer the tantalizing {{possibility}} of uncovering interesting patterns within the dataset. For e-businesses, {{always looking for}} an edge in the hyper-competitive online marketplace, this possibility is of particular interest. Of significant particular interest to e-businesses is the discovery of Critical Edge Sequences (CES), which denote frequently traversed subpaths in the catalog. CESs {{can be used to}} improve site performance and site management, increase the effectiveness of advertising on the site, and gather additional knowledge of customer interest patterns on the site. Using traditional graph-based and web mining strategies to find CESs {{could turn out to be}} expensive in both space and time. In this paper, we propose a number of approximate algorithms to compute the most popular paths bewteen node pairs in a catalog, which are then used to discover CESs. Our methods are both space-efficient and accurate, providing a vast reduction in the storage requirement with a minimum impact on accuracy. These algorithms, which can be executed off-line in batch mode, are also practical with respect to running time. As variants of single-source shortest-path, they run in log linear time. Λ Georgia Institute of Technology y University of Massachusetts and IIT, Bombay 1 Introduction Web sites allow the <b>collection</b> <b>of</b> vast <b>amounts</b> <b>of</b> navigational data- clickstreams of user traversals through the site. These massive data stores offer the tantalizing possibility of uncovering interesting patterns within the dataset. For e-businesses, always looking for an edge in the hyper-competitive online marketplace, this possibility is of particular interest...|$|R
40|$|Expressed {{breast milk}} used to feed preterm infants is {{precious}} and so, despite heterogeneity of composition, all available milk is used. A study of 274 samples of expressed breast milk supplied by preterm mothers and National Childbirth Trust donors showed pronounced variation in fat content {{as measured by}} the "creamatocrit" method. This was not due to differences between term and preterm mothers or between transitional and mature milk. The composition was affected by diurnal variation and method <b>of</b> <b>collection.</b> Substantial <b>amounts</b> <b>of</b> fat were also wasted as a result of continuous nasogastric feeding. Several milk samples did not contain enough fat to supply even a fraction of the recommended energy requirements of these infants. Some type of quality control over samples of expressed breast milk is clearly essential. The creamatocrit method is simple and feasible...|$|R
