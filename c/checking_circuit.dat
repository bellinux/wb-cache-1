16|129|Public
25|$|The lower 15 bits of each {{memory word}} held AGC {{instructions}} or data, with each word being {{protected by a}} 16th odd parity bit. This bit was set to 1 or 0 by a parity generator circuit so a count of the 1s in each memory word would always produce an odd number. A parity <b>checking</b> <b>circuit</b> tested the parity bit during each memory cycle; if the bit didn't match the expected value, the memory word {{was assumed to be}} corrupted and a parity alarm panel light was illuminated.|$|E
50|$|On {{the receive}} section the {{signal from the}} radio {{receiver}} comes to a tone demodulator, then a polarity inverter, and then to an error <b>checking</b> <b>circuit,</b> {{and at the same}} time to an input shift register that converts from serial to parallel. Next it goes to a code translator to convert from seven bits to five bits. From here the five bit code goes to a parallel to serial converter, controlled by a repetition cycle timer on the receive side.|$|E
50|$|The lower 15 bits of each {{memory word}} held AGC {{instructions}} or data, with each word being {{protected by a}} 16th odd parity bit. This bit was set to 1 or 0 by a parity generator circuit so a count of the 1s in each memory word would always produce an odd number. A parity <b>checking</b> <b>circuit</b> tested the parity bit during each memory cycle; if the bit didn't match the expected value, the memory word {{was assumed to be}} corrupted and a parity alarm panel light was illuminated.|$|E
40|$|Abstract—Online Testability is used {{to detect}} bit error of Reversible Circuit at runtime using <b>Check</b> <b>circuit</b> to {{propagate}} all errors into single line. In this paper, we propose an improved design of <b>check</b> <b>circuit,</b> Modified Test Cell (MTC) can detect error in short time and also able to identify affected cell(s) simultane-ously. We also present a cost effective design of Online Testable Ripple Carry Adder (RCA) with proposed MTC. Proposed design of <b>check</b> <b>circuit</b> is able to enhance the reusability of circuit by replacing corresponding faulty cell(s). I...|$|R
5000|$|The <b>Checking</b> Integrated <b>Circuit,</b> or CIC, is a lockout chip {{designed}} for the Nintendo Entertainment System which had three main purposes: ...|$|R
40|$|ISBN: 0 - 7695 - 1290 - 9 The {{following}} {{topics are}} dealt with: dependability evaluation; on-line testing for reconfigurable systems; on-line testable and fault tolerable circuits and systems; yield, test and reliability issues for very deep submicron chips; logic verification for on-line tested systems; built-in self-testing; self-checking, concurrent detection and radiation effects; automotive applications and on-line monitoring of temperature; self <b>checking</b> <b>circuits</b> and error control coding implementation; {{hardware and software}} techniques for fault tolerance; applications; and on-line testing of digital, analog and mixed signal circuit...|$|R
40|$|Abstract. A {{method for}} rotary speed and torque {{measuring}} using JC sensors {{was introduced in}} the paper. The approximate sine signals output by JC sensors are transformed into rectangular signals by the transform circuit. The <b>checking</b> <b>circuit</b> consists of an 8031 singlechip, it determines the rotary speed by measuring the frequency of the rectangular signals, and determines torque by measuring their pulse width...|$|E
40|$|This paper shows {{improvement}} in the efficiency of self <b>checking</b> <b>circuit</b> {{with the use of}} exhaustive fault injection with analysis of property of circuit is shown. Experimental results from fault injection on a Reed-Solomon Decoder demonstrated that by observing the occurred errors and the correspondent detection module has been possible {{to reduce the number of}} detection module, while paying a small reduction of the percentage of SEUs that can be detected...|$|E
40|$|To verify {{hardware}} designs by model <b>checking,</b> <b>circuit</b> specifications {{are commonly}} {{expressed in the}} temporal logic CTL. Automatic conversion of English to CTL requires the definition of an appropriately restricted subset of English. We show how the limited semantic expressibility of CTL can be exploited to derive a hierarchy of subsets, Our strategy avoids potential difficulties with approaches that take existing computational semantic analyses of English as their starting point-such as the need {{to ensure that all}} sentences in the subset possess a CTL translation...|$|E
40|$|Abstract — The paper {{deals with}} {{synthesis}} technique for de-signing circuits with on-line errors detection. We present {{a new technique}} of designing a concurrently <b>checking</b> functional <b>circuit</b> by partitioning the circuit into two independent sub-circuits. The technique does not require any redundant coding variables. Instead, we propose to utilize some input variables. These variables are transferred directly into the checker providing the self-checking property for arbitrary errors (not necessarily unidirectional). A method for constructing the overall system is presented. Benchmark results are presented and show {{the efficiency of the}} proposed approach. Index Terms — Concurrent error detection, on-line <b>checking,</b> combinational <b>circuits,</b> partitionin...|$|R
40|$|Side-channel {{attacks are}} {{nowadays}} a serious concern when implementing cryptographic algorithms. Powerful ways for gaining {{information about the}} secret key as well as various counter-measures against such attacks have been recently developed. Although {{it is well known}} that such attacks can exploit information leaked from different sources, most prior works have only addressed the problem of protecting a cryptographic device against a single type of attack. Consequently, there is very little knowledge on how a scheme for protecting a device against one type of side-channel attack may affect its vulnerability to other types of side-channel attacks. In this paper we focus on devices that include protection against fault injection attacks (using different error detection schemes) and explore whether the presence of such fault detection circuits affects the resistance against attacks based on power analysis. Using the AES S-Box as an example, we performed attacks on the unprotected implementation as well as modified implementations with parity <b>check</b> <b>circuits</b> or residue <b>check</b> <b>circuits</b> (mod 3 and mod 7). In particular, we focus on the question whether the knowledge of the presence of error detection circuitry in the cryptographic device can help an attacker who attempts to mount a power attack on the device. Our results show that the presence of error detection circuitry helps the attacker even if he is unaware of this circuitry, and that the benefit to the attacker increases with the number of check bits used for the purpose of error detection...|$|R
40|$|Abstract—A {{method of}} control is {{proposed}} {{on the basis of}} representing the <b>checked</b> <b>circuits</b> as consequently connected subcircuits (cascades). The subdivision of the circuits into cascades is made {{in such a way that}} any failure in each of them results in a distortion of no more than one binary digit at its input. There is developed an universal sequential-sampling circuit with step-by-step control, where the detection of errors does not require additional (coding) variables. The results of this investigation showed that the proposed method for operational control entails considerably lesser hardware and power expenditure as compared with the circuits based on application of the Berger code...|$|R
40|$|Hardware {{verification}} and {{sequential test}} generation are {{aspects of the}} [...] . In this paper, a common formal framework for hardware verification and sequential test pattern generation is presented, {{which is based on}} modeling the circuit behavior with temporal logic. In addition, a new approach to cope with non resetable ipops in sequential test generation is proposed, which is not restricted to stuck-at faults. Based on this verification view, it is possible to provide the designer with one tool for <b>checking</b> <b>circuit</b> correctness and generating test patterns. Its first implementation and application is also described...|$|E
40|$|This paper {{shows that}} cascade {{circuits}} in the logic cells of all current lookup table based FP-GAs support only linear cascading chain and, as a result, contribute to long cascading delay. We present an enhanced cascade circuit that will re-duce cascading delay signicantly: from linear time to log time {{in terms of}} the number of logic cells cascaded. We show that the additional area for the new cascade circuit is very small. We dis-cuss an interaction between architecture design decision and CAD (in particular, placement) for the design of dedicated routing structure for cas-cade signals between logic cells. We illustrate the advantage of the new cascade circuit with an ex-ample of 32 -bit equality <b>checking</b> <b>circuit.</b> ...|$|E
40|$|Introduction Propositional theorem provers [...] {{also known}} as satisfiability (SAT) solvers [...] are {{receiving}} increased attention {{in the area of}} formal verification since recent developments in algorithms has made it possible to use propositional theorem proving to a variety of largescale problems, such as symbolic model <b>checking,</b> <b>circuit</b> equivalence and formal verification by refinement proof. Greentech Computing Ltd 1. was seeking industrial-scale problems not taken from the circuit verification domain to try out on their GSVT theorem prover. As Industrilogik works with problems of this kind, we were given the opportunity to evaluate GSVT. To get a general idea of {{the current state of the}} art in propositional theorem proving, we carried out the evaluation as a comparison of GSVT and three other theorem provers: HeerHugo [5], NP-Tools [4] and SATO [6]. 2. The problems 2. 1. Background With the exception of two prime number problems s...|$|E
50|$|Whenever feasible, {{registers}} {{and other}} circuits appear in duplicate. Their contents are continuously compared so that inconsistencies between {{the data in}} the identical units give an indication of faulty operation, and stall the computer. At this point, the instruction may be repeated. The pulse code used in the Univac System is so designed that all characters contain an odd number of pulses. At several strategic points within Univac, every character is checked for an odd number of pulses. An indication is given whenever an even number of pulses is detected, and the computer stalls. Other types of <b>checking</b> <b>circuits</b> cause Univac to stall when other types of errors occur.|$|R
40|$|Recovery in a {{fault-tolerant}} {{computer means}} {{the continuation of}} system operation with data integrity after an error occurs. This paper delineates two parallel concepts embodied in the hardware and software functions required for recovery; detection, diagnosis, and reconfiguration for hardware, data integrity, checkpointing, and restart for the software. The hardware relies on the recovery variable set, <b>checking</b> <b>circuits,</b> and diagnostics, and the software relies on the recovery information set, audit, and reconstruct routines, to characterize the system state and assist in recovery when required. Of particular utility is a handware unit, the recovery control unit, which serves as an interface between error detection and software recovery programs in the supervisor and provides dynamic interactive recovery...|$|R
50|$|Testing is the {{real-world}} counterpart to verification, testing involves physically building {{at least a}} prototype of the design and then (in combination with the test procedures in the specification or added to it) <b>checking</b> the <b>circuit</b> really does do what it was designed to.|$|R
40|$|INTRODUCTION 1. 1. Parallel Processing for CAD As {{the sizes}} of VLSI {{circuits}} increases in the future, the computational requirements for performing various computer-aided design (CAD) tasks such as simulation, design-rule <b>checking,</b> <b>circuit</b> extraction, cell placement and wire routing will increase tremendously. There will be an increasing need for more accuracy and capabilities from these CAD tools which would involve substantially more computations. Parallel processing provides an effective way for increasing {{the capabilities of the}} CAD tools. It not only reduces the time taken by various CAD tasks, but also increases {{the sizes of}} circuits that can be effectively handled by the CAD tools. There are two approaches to the use of parallel processing. The first approach involves the use of special-purpose hardware accelerators. Special-purpose hardware accelerators have been proposed to speed up a wide variety of CAD tasks including logic simulation, wire-routing, design ru...|$|E
40|$|A {{new method}} is {{proposed}} for checking the equivalence of two irredundant logic implementations of a combinational Boolean function. The procedure consists of generation of complete checkpoint fault test sets for both circuits. The two test sets are concatenated and both circuits are simulated {{to obtain the}} response to the combined test set. If the responses of the two circuits match for all vectors, then they are declared to be equivalent. We examine a case where this heuristic fails. In such cases, the use of fault simulation is shown to discover nonequivalence even when the two circuits produce the same output. We prove that if the two circuits were different, then some faults on the primary inputs of a composite equivalence <b>checking</b> <b>circuit</b> must be detectable. Using the simulation of single stuck-at faults at the primary inputs of that circuit, the new heuristic recommends the use of a vector set in which the Hamming distance between any two vectors does not exceed 3...|$|E
40|$|Hardware {{verification}} and {{sequential test}} generation are {{aspects of the}} same problem, namely to prove the equal behavior determined by two circuit descriptions. During test generation, this attempt succeeds for the faulty and fault free circuit if redundancy exists, and during verification it succeeds, if the implementation is correct with regard to its specification. This observation {{can be used to}} cross-fertilize both areas, which been treated separately up to now. In this paper, a common formal framework for hardware verification and sequential test pattern generation is presented, which is based on modeling the circuit behavior with temporal logic. In addition, a new approach to cope with non resetable flipflops in sequential test generation is proposed, which is not restricted to stuck-at faults. Based on this verification view, it is possible to provide the designer with one tool for <b>checking</b> <b>circuit</b> correctness and generating test patterns. Its first implementation and application is also described...|$|E
40|$|We {{explore a}} distance- 3 homological CSS quantum code, namely the small stellated dodecahedron code, for dense storage of quantum {{information}} and we compare its performance with the distance- 3 surface code. The data and ancilla qubits {{of the small}} stellated dodecahedron code can be located on the edges resp. vertices of a small stellated dodecahedron, making this code suitable for 3 D connectivity. This code encodes 8 logical qubits into 30 physical qubits (plus 22 ancilla qubits for parity check measurements) as compared to 1 logical qubit into 9 physical qubits (plus 8 ancilla qubits) for the surface code. We develop fault-tolerant parity <b>check</b> <b>circuits</b> and a decoder for this code, allowing us to numerically assess the circuit-based pseudo-threshold. Comment: 19 pages, 14 figures, comments welcome...|$|R
40|$|This {{bachelor}} thesis {{deals with}} application of {{machine learning algorithms}} for generation of <b>checking</b> <b>circuits.</b> It contains detailed descriptions of the individual algorithms of machine learning which have been chosen to achieve this purpose. Except familiarization with it's theoretical properties there are also parts devoted to the specific utilization of the mentioned algorithms {{in the form of}} classifiers. Classifiers can work with different settings which influence the accuracy of the learning and the subsequent classification. The differences between the individual classifiers and their settings are illustrated in the experimental part of the thesis. Experiments were conducted on various circuits, including the control units of the robot, developed on the Department of Computer Systems, Faculty of Information Technology, Brno University of Technology...|$|R
40|$|A {{simple and}} general {{model of the}} {{interfaces}} and <b>check</b> <b>circuits</b> used for comparing and detecting faults {{in a pair of}} 16 -bit processors is described, and problems encountered in the application of TI 9900 processors are discussed. The greatest incompatibility is found to lie between the rollback structures of the CPUs and the interface and check logic (ICL) model. The ICL model generates a reset when an error is detected, and a rollback is expected to occur when it is released. The TI 9900 requires a reset of minimum duration, and after release goes through an initialization cycle, obtains rollback parameters from fixed memory locations, and executes the rollback, consistent with the ICL. The ICL is relatively simple, having a complexity equivalent to fewer than 1000 gates...|$|R
40|$|In {{this paper}} we analyze the {{probability}} that transient faults, multiple or single, affecting a checker of a self-checking circuit (with particular reference {{to the case of}} circuits using the two-rail code, the parity code, the Berger code and the Bose–Lin code) give rise to no-harm alarms, here defined as indications of errors neither denoting the presence of an incorrect word at the output of the functional block, nor denoting the presence of checker internal faults possibly compromising its ability to discriminate input codewords from input non-codewords. Differently from all other error indications, no-harm alarms could be conveniently ignored (or tolerated) by the system, with no need to adopt any recovery strategy upon their reception, otherwise for instance leading to exclude the self <b>checking</b> <b>circuit</b> from the whole system, or to degrade system’s performance. A new property (No-Harm Alarm Robustness) is defined for checkers, allowing to discriminate “true” error indications from no-harm alarms. A possible approach to design checkers featuring such a property is proposed. The behavior of the derived checkers has been verified by means of electrical level simulations, and their costs are discussed...|$|E
40|$|The LC 72717 PW is a data {{demodulation}} LSI for DARC format. This LSI {{includes an}} on-signal. It also supports ITU-R recommended FM multiplex frame structures (methods A, A implement a compact, multifunction DAR Note that {{a contract with}} the NHK Engineering Service may be required to produce DARC compatible products in case, please contact with the NHK Engineering Service Function • Adjustment-free 76 kHz SCF bandpass filter • Supports all FM multiplex frame structures (methods A, A • MSK delay detection system based on a 1 T delay. • Error correction function based on a 2 T delay (in the MSK detection stage) • Digital PLL based clock regeneration • Shift-register 1 T and 2 T delay circuits • Block and frame synchronization detection circuits • Functions for setting the number of allowable BIC errors and the number of synchronization protection operations. • Error correction using (272, 190) codes • Built-in layer 4 CRC code <b>checking</b> <b>circuit</b> • On-chip frame memory and memory control circuit for vertical correction • 7. 2 MHz crystal oscillator circuit • Two power saving modes: STNBY and EC STOP • Applications can use either a parallel CPU inter...|$|E
40|$|We {{give new}} proofs for the {{hardness}} amplification of efficiently samplable predicates and of weakly verifiable puzzles which generalize to new settings. More concretely, {{in the first}} part of the paper, we give a new proof of Yao's XOR-Lemma that additionally applies to related theorems in the cryptographic setting. Our proof seems simpler than previous ones, yet immediately generalizes to statements similar in spirit such as the extraction lemma used to obtain pseudo-random generators from one-way functions [Hastad, Impagliazzo, Levin, Luby, SIAM J. on Comp. 1999]. In the second part of the paper, we give a new proof of hardness amplification for weakly verifiable puzzles, which is more general than previous ones in that it gives the right bound even for an arbitrary monotone function applied to the <b>checking</b> <b>circuit</b> of the underlying puzzle. Both our proofs are applicable in many settings of interactive cryptographic protocols because they satisfy a property that we call "non-rewinding". In particular, we show that any weak cryptographic protocol whose security is given by the unpredictability of single bits can be strengthened with a natural information theoretic protocol. As an example, we show how these theorems solve the main open question from [Halevi and Rabin, TCC 2008] concerning bit commitment. Comment: Revision 2 : Added references, minor changes, slight improvements in presentation of some proof sketche...|$|E
40|$|An LUT cascade {{emulator}} realizes {{an arbitrary}} sequential circuit. Given a sequential circuit, we convert the combinational part into {{one or more}} LUT cascades, and store LUT(cell) data into a memory in the LUT cascade emulator. The emulator evaluates multi-output logic functions by reading cell data sequentially. To improve the tolerance to soft errors, cell data in the memory are encoded by error correcting codes. Also, error-correcting <b>circuits</b> and <b>checking</b> <b>circuits</b> that periodically scan the memories are appended. When a soft error is detected, it removes the error by rewriting the correct data into the memory. To mask soft errors in flip-flops, a TMR (Triple Module Redundancy) technique is employed. Our system detects a soft error in a single bit. Also, the mission time {{of the system is}} more than 1000 x of time of an ordinary LUT cascade emulator. ...|$|R
40|$|In {{this report}} we revisit the theory {{introduced}} in [2]. We formulate {{it in terms}} of correlation functions so showing that the introduction of filtering functions is not necessary. We also describe an algorithm of equivalence <b>checking</b> for <b>circuits</b> with a known specification that is based on computation of correlation functions only (no filtering functions are computed). 1...|$|R
40|$|Abstract — This paper {{shows how}} the use of {{exhaustive}} fault injection campaigns {{in conjunction with the}} analysis of the property of a circuit, allows to improve the efficiency of the checker of self <b>checking</b> <b>circuits.</b> Experimental results coming from fault injection campaigns on a Reed-Solomon Decoder demonstrated that by observing the occurred errors and the correspondent detection module has been possible {{to reduce the number of}} detection module, while paying a small reduction of the percentage of SEUs that can be detected. II. FAULT INJECTION ENVIRONMENT The fault injection system we developed is composed by: a host computer; an FPGA board equipped with a Virtex II-Pro device, and a serial communication link to the host computer. The host computer is used for configuring the Virtex-II Pro, for the generation of a fault location list and to collect the results in terms of fault-effect classification. I...|$|R
40|$|Quantum {{computing}} is {{an emerging}} technology {{that has the}} potential to change the perspectives and applications of computing in general. A wide range of applications are enabled: from faster algorithmic solutions of classically still difficult problems to theoretically more secure communication protocols. A quantum computer uses the quantum mechanical effects of particles or particle-like systems, and a major similarity between quantum and classical computers consists of both being abstracted as information processing machines. Whereas a classical computer operates on classical digital information, the quantum computer processes quantum information, which shares similarities with analog signals. One of the central differences between the two types of information is that classical information is more fault-tolerant when compared to its quantum counterpart. Faults are the result of the quantum systems being interfered by external noise, but during the last decades quantum error correction codes (QECC) were proposed as methods to reduce the effect of noise. Reliable quantum circuits are the result of designing circuits that operate directly on encoded quantum information, but the circuit’s reliability is also increased by supplemental redundancies, such as sub-circuit repetitions. Reliable quantum circuits have not been widely used, and one of the major obstacles is their vast associated resource overhead, but recent quantum computing architectures show promising scalabilities. Consequently the number of particles used for computing can be more easily increased, and that the classical control hardware (inherent for quantum computation) is also more reliable. Reliable quantum circuits haev been investigated for almost as long as general quantum computing, but their limited adoption (until recently) has not generated enough interest into their systematic design. The continuously increasing practical relevance of reliability motivates the present thesis to investigate some of the first answers to questions related to the background and the methods forming a reliable quantum circuit design stack. The specifics of quantum circuits are analysed from two perspectives: their probabilistic behaviour and their topological properties when a particular class of QECCs are used. The quantum phenomena, such as entanglement and superposition, are the computational resources used for designing quantum circuits. The discrete nature of classical information is missing for quantum information. An arbitrary quantum system can be in an infinite number of states, which are linear combinations of an exponential number of basis states. Any nontrivial linear combination of more than one basis states is called a state superposition. The effect of superpositions becomes evident when the state of the system is inferred (measured), as measurements are probabilistic with respect to their output: a nontrivial state superposition will collapse to one of the component basis states, and the measurement result is known exactly only after the measurement. A quantum system is, in general, composed from identical subsystems, meaning that a quantum computer (the complete system) operates on multiple similar particles (subsystems). Entanglement expresses the impossibility of separating the state of the subsystems from the state of the complete system: the nontrivial interactions between the subsystems result into a single indivisible state. Entanglement is an additional source of probabilistic behaviour: by measuring the state of a subsystem, the states of the unmeasured subsystems will probabilistically collapse to states from a well defined set of possible states. Superposition and entanglement are the building blocks of quantum information teleportation protocols, which in turn are used in state-of-the-art fault-tolerant quantum computing architectures. Information teleportation implies that the state of a subsystem is moved to a second subsystem without copying any information during the process. The probabilistic approach towards the design of quantum circuits is initiated by the extension of classical test and diagnosis methods. Quantum circuits are modelled similarly to classical circuits by defining gate-lists, and missing quantum gates are modelled by the single missing gate fault. The probabilistic approaches towards quantum circuits are facilitated by comparing these to stochastic circuits, which are a particular type of classical digital circuits. Stochastic circuits can be considered an emulation of analogue computing using digital components. A first proposed design method, based on the direct comparison, is the simulation of quantum circuits using stochastic circuits by mapping each quantum gate to a stochastic computing sub-circuit. The resulting stochastic circuit is compiled and simulated on FPGAs. The obtained results are encouraging and illustrate the capabilities of the proposed simulation technique. However, the exponential number of possible quantum basis states was translated into an exponential number of stochastic computing elements. A second contribution of the thesis is the proposal of test and diagnosis methods for both stochastic and quantum circuits. Existing verification (tomographic) methods of quantum circuits were targeting the reconstruction of the gate-lists. The repeated execution of the quantum circuit was followed by different but specific measurement at the circuit outputs. The similarities between stochastic and quantum circuits motivated the proposal of test and diagnosis methods that use a restricted set of measurement types, which minimise the number of circuit executions. The obtained simulation results show that the proposed validation methods improve the feasibility of quantum circuit tomography for small and medium size circuits. A third contribution of the thesis is the algorithmic formalisation of a problem encountered in teleportation-based quantum computing architectures. The teleportation results are probabilistic and require corrections represented as quantum gates from a particular set. However, there are known commutation properties of these gates with the gates used in the circuit. The corrections are not applied as dynamic gate insertions (during the circuit’s execution) into the gate-lists, but their effect is tracked through the circuit, and the corrections are applied only at circuit outputs. The simulation results show that the algorithmic solution is applicable for very large quantum circuits. Topological quantum computing (TQC) is based on a class of fault-tolerant quantum circuits that use the surface code as the underlying QECC. Quantum information is encoded in lattice-like structures and error protection is enabled by the topological properties of the lattice. The 3 D structure of the lattice allows TQC computations to be visualised similarly to knot diagrams. Logical information is abstracted as strands and strand interactions (braids) represent logical quantum gates. Therefore, TQC circuits are abstracted using a geometrical description, which allows circuit input-output transformations (correlations) to be represented as geometric sub-structures. TQC design methods were not investigated prior to this work, and the thesis introduces the topological computational model by first analysing the necessary concepts. The proposed TQC design stack follows a top-down approach: an arbitrary quantum circuit is decomposed into the TQC supported gate set; the resulting circuit is mapped to a lattice of appropriate dimensions; relevant resulting topological properties are extracted and expressed using graphs and Boolean formulas. Both circuit representations are novel and applicable to TQC circuit synthesis and validation. Moreover, the Boolean formalism is broadened into a formal mechanism for proving circuit correctness. The thesis introduces TQC circuit synthesis, which is based on a novel logical gate geometric description, whose formal correctness is demonstrated. Two synthesis methods are designed, and both use a general planar representation of the circuit. Initial simulation results demonstrate the practicality and performance of the methods. An additional group of proposed design methods solves the problem of automatic correlation construction. The methods use validity criteria which were introduced and analysed beforehand in the thesis. Input-output correlations existing in the circuit are inferred using both the graph and the Boolean representation. The thesis extends the TQC state-of-the-art by recognising the importance of correlations in the validation process: correlation construction is used as a sub-routine for TQC circuit validation. The presented cross-layer validation procedure is useful when investigating both the QECC and the circuit, while a second proposed method is QECC-independent. Both methods are scalable and applicable even to very large circuits. The thesis completes with the analysis of TQC circuit identities, where the developed Boolean formalism is used. The proofs of former known circuit identities were either missing or complex, and the presented approach reduces the length of the proofs and represents a first step towards standardising them. A new identity is developed and detailed during the process of illustrating the known circuit identities. Reliable quantum circuits are a necessity for quantum computing to become reality, and specialised design methods are required to support the quest for scalable quantum computers. This thesis used a twofold approach towards this target: firstly by focusing on the probabilistic behaviour of quantum circuits, and secondly by considering the requirements of a promising quantum computing architecture, namely TQC. Both approaches resulted in a set of design methods enabling the investigation of reliable quantum circuits. The thesis contributes with the proposal of a new quantum simulation technique, novel and practical test and diagnosis methods for general quantum circuits, the proposal of the TQC design stack and the set of design methods that form the stack. The mapping, synthesis and validation of TQC circuits were developed and evaluated based on a novel and promising formalism that enabled <b>checking</b> <b>circuit</b> correctness. Future work will focus on improving the understanding of TQC circuit identities as it is hoped that these are the key for circuit compaction and optimisation. Improvements to the stochastic circuit simulation technique have the potential of spawning new insights about quantum circuits in general...|$|E
40|$|Circuits {{implemented}} with two-phase level-clocked latches {{have the}} theoretical potential to operate faster and require less state than equivalent circuits implemented with edge-triggered latches. We investigated {{to what extent}} one can achieve this theoretical potential with real circuits. We found that level-clocked circuits are no faster than edge-triggered circuits except when the delay between any two latches is approximately equal to the maximum gate delay. On the other hand, level-clocked circuits can often be implemented with significantly less state than equivalent edgetriggered circuits clocked at the same speed. Over one-third of the circuits tested had a reduction in state of at least 25 percent. These tests were performed in Tim, a computer-aided design tool for verification and optimization of two-phase, level-clocked circuitry. Tim consists of several efficient polynomial-time algorithms that can <b>check</b> <b>circuit</b> timing and modify circuit layout {{in order to meet}} various timi [...] ...|$|R
40|$|In {{this work}} {{we are going}} to {{simulate}} a field programmable cyclic redundancy <b>check</b> <b>circuit</b> architecture. The transmitted data or stored data must be free from error. The increased use of error correction techniques by digital communications designers has created a demand for tools to evaluate and exercise error correction coding approaches before they are committed to expensive ASICs or firmware. Cyclic redundancy check is an error detection method but it can be used only for a specific application. A field programmable circuit is one which enables a wide range of polynomial width and input port width to be used with in the same circuit. The parameters are reprogrammable and it is fully flexible. The circuit also consists of an embedded configuration controller that reduces the programming time and complexity. The hardware cost is reduced and the line speed is increased. The primary tool used is modelsim 6. 1 a...|$|R
50|$|The {{computer}} received {{input from}} peripherals via magnetic scanners, composed of ferrod sensors, similar {{in principle to}} magnetic core memory except that the output was controlled by control windings analogous to the windings of a relay. Specifically, the ferrod was a transformer with four windings. Two small windings ran through holes {{in the center of}} a rod of ferrite. A pulse on the Interrogate winding was induced into the Readout winding, if the ferrite was not magnetically saturated. The larger control windings, if current was flowing through them, saturated the magnetic material, hence decoupling the Interrogate winding from the Readout winding which would return a Zero signal. The Interrogate windings of 16 ferrods of a row were wired in series to a driver, and the Readout windings of 64 ferrods of a column were wired to a sense amp. <b>Check</b> <b>circuits</b> ensured that an Interrogate current was indeed flowing.|$|R
40|$|We {{significantly}} reduce the complexity of BDD-based symbolic verification by using partitioned transition relations to represent state transition graphs. This method {{can be applied to}} both synchronous and asynchronous circuits. The times necessary to verify a synchronous pipeline and an asynchronous stack are both bounded by a low polynomial {{in the size of the}} circuit. We were able to handle stacks with over 10 50 reachable states and pipelines with over 10 120 reachable states. 1 Introduction Although methods for verifying sequential circuits by searching their state transition graphs have been investigated for many years, it is only recently that such methods have begun to seem practical. Before, the largest circuits that could be verified had about 10 6 states. Now it is easy to <b>check</b> <b>circuits</b> that have many orders of magnitude more states [3, 5, 6, 7]. The reason for the dramatic increase is the use of special data structures such as binary decision diagrams (BDDs) [2] for [...] ...|$|R
40|$|In recent years, {{large volumes}} of data are {{transferred}} between a computer system and various subsystems through digital logic circuits and interconnected wires. And there always exist potential errors when data are transferred due to electrical noise, device malfunction, or even timing errors. In general, parity <b>checking</b> <b>circuits</b> are usually employed for detection of single-bit errors. However, it {{is not sufficient to}} enhance system reliability and availability for efficient error detection and necessary to detect and further correct errors up to a certain level within the affordable cost. To handle a large number of information bits, the associated circuits become quite complex and irregular on the other the CA’s circuit structure having simple, regular and modular propertiesis amenable for VLSI implementation. The {{purpose of this paper is}} investigateencoding and decodingof bit error correction methods using the properties of CA. The results show that these schemesarepossible to correct errors by the easy and fast analysis of syndrome...|$|R
