1|10000|Public
40|$|In this paper, {{we study}} several tests for the {{equality}} of two unknown distributions. Two are based on empirical distribution functions, three others on nonparametric probability density estimates, and the last ones on differences between sample moments. We suggest controlling the size of such tests (under nonparametric assumptions) by using permutational versions of the tests jointly with the method of Monte Carlo tests properly adjusted to deal with discrete distributions. We also propose a <b>combined</b> <b>test</b> <b>procedure,</b> whose level is again perfectly controlled through the Monte Carlo test technique and has better power properties than the individual tests that are combined. Finally, in a simulation experiment, we show that the technique suggested provides perfect control of test size and that the new tests proposed can yield sizeable power improvements. nonrametric methods, two-same oblem, discrete distribution, discontinuous distribution, goodness-of-fit test, Kolmogorov-Smirnov test, Cramér-von Mises, kernel density estimator, exact test, rmutation test, Monte Carlo test, bootstra combined test ocedure, induced test...|$|E
40|$|Concerning {{the actual}} {{significance}} level, we investigate the commonly used <b>combined</b> <b>test</b> <b>procedures</b> of meta-analysis, which contain {{the choice of}} the model, in which the analysis is carried out, and the commonly used tests for treatment effect in the fixed and random effects model, and some new <b>combined</b> <b>test</b> <b>procedures,</b> which use an alternative test statistic in the random effects model or the t-distribution as test distribution of the commonly used test statistics. A simulation study indicates that the new <b>combined</b> <b>test</b> <b>procedures</b> are better with respect to a prescribed significance level. (orig.) SIGLEAvailable from TIB Hannover: RR 8460 (2000, 9) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekDEGerman...|$|R
40|$|Concerning {{the actual}} {{significance}} level, we investigate the commonly used <b>combined</b> <b>test</b> <b>procedures</b> of meta-analysis, which contain {{the choice of}} the model, in which the analysis is carried out, and the commonly used tests for treatment effect in the fixed and random effects model, and some new <b>combined</b> <b>test</b> <b>procedures,</b> which use an alternative test statistic in the random effects model or the t-distribution as test distribution of the commonly used test statistics. A simulation study indicates that the new <b>combined</b> <b>test</b> <b>procedures</b> are better with respect to a prescribed significance level. 1. Introduction In this paper we consider the test for treatment effect in the meta-analysis of controlled clinical trials, i. e. we want to judge if an overall treatment effect is present given stochastically independent study-specific estimates of the treatment effect. The test for treatment effect is carried out either in the fixed effects model of meta-analysis assuming homogeneous treatment [...] ...|$|R
40|$|When {{testing for}} the {{equality}} of two distributions in a case-control design with treatment effects presumed to act possibly {{on more than one}} aspect, different tests may be properly considered for testing for different features of a null hypothesis, leading to the multiple aspect testing issue. Two different aspects are therefore of interest: the location-aspect, based on the comparison of location indexes, and the distributional-aspect, based on the comparison of the empirical distribution functions. A simulation study shows that the <b>combined</b> <b>testing</b> <b>procedure</b> exhibits a good robust overall performance, and an application in biomedical research is also presented. Copyright Springer-Verlag Berlin Heidelberg 2005 Case-control design, Multi-aspect, Multiple hypotheses testing, Nonparametric combination methodology, Permutation tests,...|$|R
40|$|Using {{learning}} theory approaches and definitions of persuasion generated from learning theotists a {{study examined the}} effects of anxiety on mescege-induced persuasion by using meta-analytic techniques to quantitatively assess the effect of anxiety manipulation in persuasive situations. Studies used in the meta-analysis were similar in context and intention in that they examined anxiety and persuasive communication, and they obtained a measure of the effects produced. The studies were subjected to <b>combined</b> <b>testing</b> <b>procedures</b> to ca%culate effect sizes and consequently, determine the statistical significance of the results across categories of studies. r. l. wo hypotheses were proposed and supported. The meta-analysis revealed that anxiety can increase the effect of persuasive meaisages and persuasive messages can alter the level of receiver anxiety. Results indicate an overall positiv...|$|R
40|$|We derive {{tests of}} {{stationarity}} for continuous univariate time series by <b>combining</b> change-point <b>tests</b> sensitive {{to changes in}} the contemporary distribution with tests sensitive {{to changes in the}} serial dependence. Rank-based cumulative sum tests based on the empirical distribution function and on the empirical autocopula at a given lag are considered first. The combination of their dependent p-values relies on a joint dependent multiplier bootstrap of the two underlying statistics. Conditions under which the proposed <b>combined</b> <b>testing</b> <b>procedure</b> is asymptotically valid under stationarity are provided. After discussing the choice of the maximum lag to investigate, extensions based on tests solely focusing on second-order characteristics are proposed. The finite-sample behaviors of all the derived statistical procedures are investigated in large-scale Monte Carlo experiments and illustrations on two real data sets are provided. Extensions to multivariate time series are briefly discussed as well. Comment: 35 pages, 8 table...|$|R
40|$|In {{this paper}} we {{systematically}} compare forecasting accuracy of hypothesis <b>testing</b> <b>procedures</b> {{with that of}} a model <b>combining</b> algorithm. <b>Testing</b> <b>procedures</b> are commonly used in applications to select a model, based on which forecasts are made. However, besides the well-known difficulty in dealing with multiple tests, the testing approach has a potentially serious drawback: controlling the probability of Type I error at a conventional level (e. g., 0. 05) often excessively favors the null, which can be problematic for the purpose of forecasting. In addition, as shown in this paper, <b>testing</b> <b>procedures</b> can be very unstable, which results in high variability in the forecasts. ...|$|R
40|$|Estimation {{procedures}} for ordered categories usually {{assume that the}} estimated coefficients of independent variables do not vary between the categories (parallel-lines assumption). This view neglects possible heterogeneous effects of some explaining factors. This paper describes {{the use of an}} autofit option for identifying variables that meet the parallel-lines assumption when estimating a random effects generalized ordered probit model. We <b>combine</b> the <b>test</b> <b>procedure</b> developed by Richard Williams (gologit 2) with the random effects estimation command regoprob by Stefan Boes. ...|$|R
40|$|International audienceIn cancer studies, {{patients}} often experience {{two different}} types of events: a non-terminal event such as recurrence or metastasis, and a terminal event such as cancer-specific death. Identifying pathways and networks of genes associated with one or both of these events is an important step in understanding disease development and targeting new biological processes for potential intervention. These correlated outcomes are commonly dealt with by modeling progression-free survival, where the event time is the minimum between the times of recurrence and death. However, identifying pathways only associated with progression-free survival may miss out on pathways that affect time to recurrence but not death, or vice versa. We propose a <b>combined</b> <b>testing</b> <b>procedure</b> for a pathway’s association with both the cause-specific hazard of recurrence and the marginal hazard of death. The dependency between the two outcomes is accounted for through perturbation resampling to approximate the test’s null distribution, without any further assumption {{on the nature of the}} dependency. Even complex non-linear relationships between pathways and disease progression or death can be uncovered thanks to a flexible kernel machine framework. The superior statistical power of our approach is demonstrated in numerical studies and in a gene expression study of breast cancer...|$|R
40|$|In {{this paper}} we {{systematically}} compare forecasting accuracy of hypothesis <b>testing</b> <b>procedures</b> {{with that of}} a model <b>combining</b> algorithm. <b>Testing</b> <b>procedures</b> are commonly used in applications to select a model, based on which forecasts are made. However, besides the well-known difficulty in dealing with multiple tests, the testing approach has a potentially serious drawback: controlling the probability of Type 1 error at a conventional level (e. g., 0. 05) often excessively favors the null, which can be problematic for the purpose of forecasting. In addition, as shown in this paper, <b>testing</b> <b>procedures</b> can be very unstable, which results in high variability in the forecasts. Selecting a candidate forecast by <b>testing</b> and <b>combining</b> forecasts are both useful but for complementary situations. Currently, there seems to be little guidance in the literature on when combining should be preferred to selecting. We propose instability measures that are helpful for a forecaster to gauge the difficulty in selecting a single optimal forecast. Based on empirical evidences and theoretical considerations, we advocate the use of forecast combining when there is considerable instability in model selection by <b>testing</b> <b>procedures.</b> On the other hand, when there is little instability, <b>testing</b> <b>procedures</b> could work well or even better than forecast combining in terms of forecast accuracy...|$|R
40|$|The University of Wisconsin – Madison FutureTruck Team has {{designed}} and built a four-wheel drive, charge sustaining, parallel hybrid-electric sport utility vehicle for entry into the FutureTruck 2000 competition. The base vehicle is a 2000 Chevrolet Suburban nicknamed the “Moollennium. ” Weighing approximately 2495 kg, the vehicle uses a high efficiency, 2. 4 liter, turbo-charged, compression ignition direct-injection engine supplying approximately 99 kW of peak power, and a three phase AC induction motor that provides an additional 78 kW (peak) of power. This hybrid drivetrain is an attractive alternative to the large displacement V 8 drivetrain, as it provides similar performance with lower emissions and fuel consumption. The ADVISOR model predicts a <b>combined</b> Federal <b>Testing</b> <b>Procedure</b> (FTP) cycle fuel economy of 10. 6 km/L (25 mpg) and California Ultra Low Emission Vehicle (ULEV) emissions levels. These goals will be met while maintaining the full passenger/cargo capacity, appearance, and towing capacity of 3175 kg...|$|R
40|$|We {{advocate}} {{the use of}} absolute moment ratio statistics in conjunction with standard variance ratio statistics in order to disentangle linear dependence, non-linear dependence, and leptokurtosis in financial time series. Both statistics are computed for multiple return horizons simultaneously, {{and the results are}} presented in a comprehensive way using a graphical device. We construct a formal joint <b>testing</b> <b>procedure</b> based on bootstrapped and block-bootstrapped uniform confidence intervals. The methodology is hybrid because it <b>combines</b> a formal <b>testing</b> <b>procedure</b> with volatility curve pattern recognition based on expert opinions. An application to forex data illustrates the procedure. JEL Codes: C 14, F 31, G 14 Keywords: variance ratios; absolute returns; fat-tails; linear dependence; volatility clustering; bootstrap; forex market e#ciency; stable distributions. # We thank Jon Danelsson, Laurens de Haan, Henk Hoek, and Benne Weger for helpful comments. We also benefited from a presentat [...] ...|$|R
40|$|The {{residential}} {{oil burner}} market is currently {{dominated by the}} pressure-atomized, retention head burner. At low firing rates pressure atomizing nozzles suffer rapid fouling of the small internal passages, leading to bad spray patterns and poor combustion performance. To overcome the low input limitations of conventional burners, a low pressure air-atomized burner has been developed watch can operate at fining rates as low as 0. 25 gallons of oil per hour (10 kW). In addition, the burner can be operated in a high/low fining rate mode. Field tests with this burner have been conducted at a fixed input rate of 0. 35 gph (14 kW) with a side-wall vented boiler/water storage tank combination. At the test home, instrumentation was installed to measure fuel and energy flows and record trends in system temperatures. Laboratory efficiency testing with water heaters and boilers has been completed using standard single purpose and <b>combined</b> appliance <b>test</b> <b>procedures.</b> The <b>tests</b> quantify benefits due to low firing rates and other burner features. A two stage oil burner gains a strong advantage in rated efficiency while maintaining capacity for high domestic hot water and space heating loads...|$|R
40|$|High-dimensional {{tests are}} applied to find {{relevant}} sets of variables and relevant models. If variables are selected by analyzing the sums of products matrices and a corresponding mean-value test is performed, there is the danger that the nominal error of first kind is exceeded. In the paper, well-known multivariate tests receive a new mathematical interpretation such that the error of first kind of the <b>combined</b> <b>testing</b> and selecting <b>procedure</b> can more easily be kept. The null hypotheses on mean values are replaced by hypotheses on distributional sphericity of the individual score responses. Thus, model choice is possible without too strong restrictions. The method is presented for all linear multivariate designs. It is illustrated by an example from bioinformatics: The selection of gene sets for the comparison of groups of patients suffering from B-cell lymphomas. Comment: 18 page...|$|R
40|$|A {{class of}} {{independent}} multivariate linear models is considered, having a common parameter matrix [Theta] in their means, but having different covariance matrices. For testing H 0 :[Theta] = 0, some <b>test</b> <b>procedures</b> are derived, which combine {{the information from}} the different models. In the context of the interblock analysis of block designs, simulated powers of some <b>combined</b> <b>tests</b> are reported in the bivariate case, for combining the intra- and interblock tests based on the Wilk's [Lambda] criterion. The numerical results indicate that the <b>combined</b> <b>tests</b> offer substantial improvement in power compared to the Wilk's [Lambda] test based only on intrablock information. ...|$|R
40|$|Abstract: It is {{well known}} that in a general multi-parameter setting, there may not exist any unique best test. More importantly, unlike the {{univariate}} case, the power of dierent <b>test</b> <b>procedures</b> could vary remarkably. In this article we extend results of Hsu (1945) and introduce a new class of tests that have best average power for multivariate linear hypotheses. A simple method to implement the new tests is also provided. Key words and phrases: Average power, multivariate linear hypotheses, multivari-ate location problem, Fisher's method of <b>combining</b> <b>tests,</b> U distribution. 1...|$|R
30|$|There {{are many}} <b>test</b> <b>procedures</b> and methods for testing bonded joint strength. The most {{commonly}} used test methods for determining mechanical properties of joints are tensile strength tests in different directions and stress angles. Since {{it is not possible}} to determine all mechanical properties by one test, joints must be <b>tested</b> by <b>combining</b> several <b>tests</b> [16, 17].|$|R
40|$|The aim of {{this study}} is to {{determine}} the influence of withdrawal of reimbursement on the uptake of the first-trimester <b>combined</b> <b>test.</b> Until January 2007 the <b>combined</b> <b>test</b> was offered to all pregnant women in a designated geographical area as a pilot study before the introduction of the national screening program in the Netherlands, to <b>test</b> the logistic <b>procedures.</b> In January 2007 the insurance companies suddenly stopped paying for the <b>combined</b> <b>test</b> with respect to women aged 35 years by decision of the government. In 2006 the <b>combined</b> <b>test</b> was performed in 4616 women compared with 3459 who had the <b>combined</b> <b>test</b> in 2007, a reduction of 25 % (95 % CI 23. 8 - 26. 3 %, p < 0. 001). A decline was observed in the uptake of the <b>combined</b> <b>test</b> in women aged 35 years (p < 0. 001) as opposed to an increase in uptake in women aged 36 years (p < 0. 001). The financial impact on the uptake of the first-trimester <b>combined</b> <b>test</b> should not be underestimate...|$|R
40|$|The {{mutagenicity}} test methodology in vitro {{has been extensively}} used during recent years {{in the identification of}} potential carcinogenic agents. Mutagenic analyses have been applied to the study of chemical reaction products for the demonstration of the formation of mutagenic agents. Recent studies have indicated that secondary and tertiary amines, when reacted with nitrite in acidic conditions, yield N-nitroso compounds, including the potent carcinogen N-dimethylnitrosamine (NDMA). This finding raises the problem of risk evaluation of several food components of human diets for the presence of potential carcinogenic compounds. By <b>combining</b> a mutagenicity <b>test</b> <b>procedure</b> with yeast cells inoculated into the blood system of mice and incubated in the liver for various times (minutes or hours) we have devised a model methodology which allows the detection of the formation of N-dimethylnitrosamine (NDMA) at a level lower than 1 mg/kg. The methodology has been examined for its use in the study of activators of the nitrosation, such as thiocyanate, and of inhibitors of the nitrosation, such as ascorbic acid and tannic acid. Other food components of the human diet, such as red wine, have also been investigated by this methodology...|$|R
40|$|Joint {{analysis}} of multiple phenotypes can increase statistical power in genetic association studies. Principal component analysis, {{as a popular}} dimension reduction method, especially {{when the number of}} phenotypes is high-dimensional, has been proposed to analyze multiple correlated phenotypes. It has been empirically observed that the first PC, which summarizes the largest amount of variance, can be less powerful than higher order PCs and other commonly used methods in detecting genetic association signals. In this paper, we investigate the properties of PCA-based multiple phenotype analysis from a geometric perspective by introducing a novel concept called principal angle. A particular PC is powerful if its principal angle is 0 ^o and is powerless if its principal angle is 90 ^o. Without prior knowledge about the true principal angle, each PC can be powerless. We propose linear, non-linear and data-adaptive omnibus <b>tests</b> by <b>combining</b> PCs. We show that the omnibus PC test is robust and powerful {{in a wide range of}} scenarios. We study the properties of the proposed methods using power analysis and eigen-analysis. The subtle differences and close connections between these combined PC methods are illustrated graphically in terms of their rejection boundaries. Our proposed tests have convex acceptance regions and hence are admissible. The p-values for the proposed tests can be efficiently calculated analytically and the proposed tests have been implemented in a publicly available R package MPAT. We conduct simulation studies in both low and high dimensional settings with various signal vectors and correlation structures. We apply the proposed tests to the joint {{analysis of}} metabolic syndrome related phenotypes with data sets collected from four international consortia to demonstrate the effectiveness of the proposed <b>combined</b> PC <b>testing</b> <b>procedures...</b>|$|R
40|$|In this article, {{multiple}} scan {{statistics of}} variable window sizes are derived for independent and identically distributed 0 - 1 Bernoulli trials. Both {{one and two}} dimensional, as well as, conditional and unconditional cases are treated. The advantage in using multiple scan statistics, as opposed to single fixed window scan statistics, {{is that they are}} more sensitive in detecting a change in the underlying distribution of the observed data. We show how to derive simple approximations for the significance level of these <b>testing</b> <b>procedures</b> and present numerical results to evaluate their performance. <b>Combining</b> <b>test</b> statistics, one-dimensional scan statistics, p-values, two-dimensional scan statistics, variable windows,...|$|R
50|$|Multiple <b>test</b> <b>procedures</b> {{developed}} {{using the}} graphical approach for constructing and illustrating multiple <b>test</b> <b>procedures</b> are a subclass of closed <b>testing</b> <b>procedures.</b>|$|R
40|$|In {{this article}} we {{introduce}} and evaluate <b>testing</b> <b>procedures</b> for specifying the number k of nearest neighbours in the weights matrix of spatial econometric models. The spatial J-test is used for specification search. Two <b>testing</b> <b>procedures</b> are suggested: an increasing neighbours <b>testing</b> <b>procedure</b> and a decreasing neighbours <b>testing</b> <b>procedure.</b> Simulations show that the increasing neighbours <b>testing</b> <b>procedures</b> {{can be used in}} large samples to determine k. The decreasing neighbours <b>testing</b> <b>procedure</b> is found to have low power, and is not recommended for use in practice. An empirical example involving house price data is provided to show how to use the <b>testing</b> <b>procedures</b> with real data. k-nearest neighbours; model specification; spatial j-test; weights matrix...|$|R
40|$|A {{multiple}} <b>test</b> <b>procedure</b> {{for assessing}} multivariate normality (MVN) is proposed. The new <b>test</b> <b>combines</b> a finite set of affine invariant test statistics for MVN through an improved Bonferroni method. The usefulness {{of such an}} approach is illustrated by a multiple test including Mardia's and BHEP (Baringhaus-Henze-Epps-Pulley) tests that {{are among the most}} recommended <b>procedures</b> for <b>testing</b> MVN. A simulation study carried out {{for a wide range of}} alternative distributions, in order to analyze the finite sample power behavior of the proposed multiple <b>test</b> <b>procedure,</b> indicates that the new test demonstrates a good overall performance against other highly recommended MVN tests...|$|R
40|$|A {{study of}} the effects of an Electronic Throttle Control system on {{conventional}} compression <b>testing</b> <b>procedures</b> performed on a sample group of 22 vehicles. Multiple compression <b>testing</b> <b>procedures</b> were performed to determine if current, conventional compression <b>testing</b> <b>procedures</b> are valid for ETC equipped vehicles...|$|R
5000|$|Sikorsky {{developed}} the X2 helicopter on a $50 million budget. The design includes expertise gathered from several earlier design projects. The S-69/XH-59A Advancing Blade Concept Demonstrator {{had shown that}} high speed was possible with a coaxial helicopter with auxiliary propulsion (two jet engines), but that vibration and fuel consumption was excessive; the Cypher UAV expanded the company's knowledge of the unique aspects of coaxial flight control laws with a fly-by-wire aircraft; and the RAH-66 Comanche developed expertise in composite rotors and advanced transmission design. Other features include slowed [...] "de-swirling" [...] rigid rotors two feet apart, active force counter-vibration inspired by the Black Hawk, and using most of the power in forward flight for the pusher propeller rather than the rotor. Test flights and flight simulations were <b>combined</b> to improve <b>test</b> <b>procedure.</b> The fly-by-wire system is provided by Honeywell, the rotor by Eagle Aviation Technologies, anti-vibration technology from Moog Inc, and propeller by Aero Composites. The rotor hub can have 10-20 times the drag of the blade. Sikorsky intended to test hub fairings to reduce drag by 40%, and test flew fairings on the hubs themselves but not the central hub fairing ("aero sail") in between the hubs. Sikorsky has since patented a [...] "Standpipe" [...] (fixed tube between rotating rotor axes) suitable for a central hub fairing.|$|R
40|$|Following (1), (2) and (3), who {{proposed}} {{a test of}} uniformity based on m-th order disjoint sample spacings, we propose its analog based on m-th order overlapping sample spacings. Three interesting and intuitively appealing motivations, {{in favor of the}} proposed <b>test</b> <b>procedure,</b> are given. Asymptotic, normality of the proposed test statistic is derived under the null hypothesis and under a large class of fixed alternatives. The proposed <b>test</b> <b>procedure</b> is shown to be consistent against a large class of alternatives. For a sequence of local alternatives, which, converges to the null hypothesis at the rate of n(- 1 / 4), the proposed <b>test</b> <b>procedure</b> is compared with three existing <b>test</b> <b>procedures</b> (i. e. the Greenwood-type <b>test</b> <b>procedure</b> proposed in (4), which is known to be locally most powerful among all <b>test</b> <b>procedures</b> based symmetrically on spacings, a procedure due to (5) and a procedure due to (3)), in terms of the Pitman asymptotic relative efficiency. It is observed that the proposed <b>test</b> <b>procedure</b> has larger efficacies than <b>test</b> <b>procedures</b> proposed by (5) and (3), and has efficacies comparable to the Greenwood-type <b>test</b> <b>procedure.</b> Using Monte Carlo simulations, we simulate finite sample critical points and power results against seven alternatives. We observe that, compared with other tests of uniformity, our test possesses good power properties for many alternatives. status: publishe...|$|R
40|$|Consider {{the problem}} of testing s null {{hypotheses}} simultaneously. In {{order to deal with}} the multiplicity problem, the classical approach is to restrict attention to multiple <b>testing</b> <b>procedures</b> that control the familywise error rate (FWE). The closure method of Marcus et al. (1976) reduces {{the problem of}} constructing such procedures to one of constructing single tests that control the usual probability of a Type 1 error. It was shown by Sonnemann (1982, 2008) that any coherent multiple <b>testing</b> <b>procedure</b> can be constructed using the closure method. Moreover, it was shown by Sonnemann and Finner (1988) that any incoherent multiple <b>testing</b> <b>procedure</b> can be replaced by a coherent multiple <b>testing</b> <b>procedure</b> which is at least as good. In this paper, we first show an analogous result for dissonant and consonant multiple <b>testing</b> <b>procedures.</b> We show further that, in many cases, the improvement of the consonant multiple <b>testing</b> <b>procedure</b> over the dissonant multiple <b>testing</b> <b>procedure</b> may in fact be strict {{in the sense that it}} has strictly greater probability of detecting a false null hypothesis while still maintaining control of the FWE. Finally, we show how consonance can be used in the construction of some optimal maximin multiple <b>testing</b> <b>procedures.</b> This last result is especially of interest because there are very few results on optimality in th...|$|R
40|$|The phase II {{clinical}} trial {{is a critical}} step in the drug development process. In the oncology setting, phase II studies typically evaluate one primary endpoint, which is efficacy. In practice, a binary measurement representing {{the response to the}} new treatment defines the efficacy. The single-arm, multiple-stage designs are popular and the Simon 2 -Stage design is preferred. Although the study designs evaluate the efficacy, the subject 2 ̆ 7 s safety is an important concern. Safety is monitored through the number of grade 3 or grade 4 toxic events. The phase II {{clinical trial}} design based on the primary endpoint is typically augmented with an ad hoc monitoring rule. The studies are designed in two steps. First, the sample size and critical values are determined based on the primary endpoint. Then an ad hoc toxicity monitoring rule is applied to the study. Previous authors recommended a method to monitor toxic events after each patient is enrolled which is also known as continuous toxicity monitoring. A trial designed at the JG Brown Cancer Center combined the Simon 2 -Stage design with continuous toxicity monitoring. We describe how to integrate the continuous toxicity monitoring methodology with the Simon 2 -Stage design for response. Theoretical justification is given for the nominal size, power, probability of early termination (PET), and average sample size (ASN) of the <b>combined</b> <b>testing</b> <b>procedure.</b> A series of simulations were conducted to investigate the performance of the combined procedure. We discover that the type I error rate, type II error rate, PET, and ASN are subject to the correlation between toxicity and response. In fact, the study may have a smaller type I error rate than expected. The theoretical expressions derived to describe the operating characteristics of the combined procedure were utilized to create a new flexible, bivariate, multistage clinical trial. The design is considered flexible because it can monitor toxicity on a different schedule than response. An example is considered in which toxicity is measured after four equally spaced intervals and the response is evaluated only at the second and fourth toxicity examinations. This example corresponds to a data monitoring committee 2 ̆ 7 s meeting schedule that may happen every 6 months over a two year span. The effect of the correlation on the type I and type II error rates is examined through simulation. The simulations also examine the power over the range of response rates with a fixed toxicity rate in the alternative region and vice-versa. There are several single-arm, multiple-stage clinical trial designs that consider multiple endpoints at the same time. A subset of the designs includes those that consider both efficacy and toxicity as binary endpoints. A common problem, considered after the conduct of the trial, is appropriate inference given the repeated examinations of the multiple endpoints. We propose a uniformly minimum variance unbiased estimator (UMVUE) for the response in a multistage clinical trial design incorporating toxicity effects. The proposed estimator and the typical maximum likelihood estimator (MLE) are evaluated through simulation. The estimator requires further modification when continuous toxicity monitoring is combined with a multistage design for response. The modified estimator maintains low bias over the range of possible response values. The larger phase lIb or phase III clinical trial is the logical extension of the bivariate research based on exact calculations. The phase lIb or III clinical trials typically include an ad hoc toxicity monitoring rule ensuring participant protection. The designs also include provisions to allow early stopping for futility or efficacy utilizing group sequential theory or stochastic curtailment. We also examine a novel large sample clinical trial design that incorporates correlation between the response and toxicity events. The design uses the typical critical values associated with the standard normal distribution. It also searches for critical values specific to the global hypothesis associated with both response and toxicity. The bivariate <b>test</b> is then <b>combined</b> with efficacy and safety monitoring based on a flexible time-varying conditional power methodology. The type I and type II error rates of the bivariate <b>test</b> <b>procedure,</b> along with the bivariate <b>test</b> <b>procedure</b> <b>combined</b> with the conditional power methodology, are investigated through simulation. A modification is developed for the conditional power methodology to preserve the type I and type II error rates. In the end, the research extends the bivariate clinical trial designs in an attempt to make them more appealing in practice. Although, the research resulted in positive outcomes, additional work is required...|$|R
40|$|It {{is shown}} that the {{standard}} two one-sided <b>tests</b> <b>procedure</b> for bioe-quivalence is a biased test. Better tests exist. In this paper, an unbiased -level test and other tests which are uniformly {{more powerful than the}} two one-sided <b>tests</b> <b>procedure</b> are constructed. Its power can be noticeably larger than that of the -level two one-sided <b>tests</b> <b>procedure.</b> 1. Introduction. Recentl...|$|R
40|$|From the decision-theoretic viewpoint, using a {{weighted}} loss we compare {{the risks of}} <b>testing</b> <b>procedures</b> in the location and scale parameter cases. We also get numerically the minimax solution of Bayes <b>testing</b> <b>procedures</b> w. r. t. a parameter of the prior distribution, under the weighted loss. Key words and phrases: Bayes <b>testing</b> <b>procedure,</b> loss function, Neyman-Pearson test, p-value, risk. 1...|$|R
50|$|A TPS report (<b>Testing</b> <b>Procedure</b> Specification) is a {{document}} {{used by a}} quality assurance group or individual, particularly in software engineering, that describes the <b>testing</b> <b>procedures</b> and the <b>testing</b> process.|$|R
40|$|This document, D 16 a-TPP, is {{the output}} of BETA WP 5100 and {{describes}} the specific <b>test</b> <b>procedures</b> for Prague airport. It {{is one of three}} parts of the “Test Plan and Test Procedures” series of documents. A document is available for each of the test airports {{to be used in the}} BETA project: •	D 16 a-TPP	Test Plan and Test <b>Procedures</b> document, <b>test</b> <b>procedures</b> for Prague (PRG). •	D 16 b-TPP	Test Plan and Test <b>Procedures</b> document, <b>test</b> <b>procedures</b> for Hamburg (HAM). •	D 16 c-TPP	Test Plan and Test <b>Procedures</b> document, <b>test</b> <b>procedures</b> for Braunschweig (BWE) ...|$|R
40|$|The present paper {{deals with}} a {{hypothesis}} testing problem based on conditional specification in a three-way random effect model. A sometimes pool <b>test</b> <b>procedure</b> using two preliminary tests has been proposed for testing the main hypothesis. The power of the proposed test has been proposed for test has been derived. Numerical study of the power and size has been made for certain sets of degrees of freedom. It is found {{that the power of}} the proposed <b>test</b> <b>procedure</b> is more than that of the <b>test</b> <b>procedure</b> proposed by Gupta and Singh (1977), for certain set of values of the nuisance parameters. Thus, the proposed method is an improvement over the existing <b>test</b> <b>procedure,</b> incorporating one preliminary test of significance. Key words: Random-effects model (ANOVA model-Ii), <b>test</b> <b>procedure,</b> power nuisance parameter, preliminary test of significance. 1...|$|R
40|$|This paper {{discusses}} and applies {{an alternative}} <b>test</b> <b>procedure</b> {{to the debate}} regarding the inclusion of real money balances in the neoclassical production function. The alternative <b>test</b> <b>procedure</b> involves {{the development of a}} counterexample of the model of a theory being tested and simultaneously testing the model and its counterexample using the same <b>testing</b> conventions and <b>procedures.</b> The results obtained by using the <b>test</b> <b>procedure</b> cast doubt on the practice of including real money balances in the neoclassical production function. ...|$|R
5000|$|... #Caption: MSFC {{used the}} Neutral Buoyancy Facility to <b>test</b> Skylab <b>procedures.</b> Here, {{engineers}} are <b>testing</b> <b>procedures</b> for repairing Skylab.|$|R
