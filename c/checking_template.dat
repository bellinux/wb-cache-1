3|21|Public
40|$|In this paper, {{we develop}} a general {{formalism}} for describing the C++ programming language, and regular enough {{to cope with}} proposed extensions (such as concepts) for C++ 0 x that affect its type system. Concepts are a mechanism for <b>checking</b> <b>template</b> arguments currently being developed to help cope with the massive use of templates in modern C++. The main challenges in developing a formalism for C++ are scoping, overriding, overloading, templates, specialization, and the C heritage exposed in the built-in types. Here, we primarily focus on templates and overloading...|$|E
40|$|This note {{presents}} problems, ideals, {{and design}} ideas for ways of <b>checking</b> <b>template</b> arguments. The {{aim is to}} simplify the writing and use of templates without loss of run-time performance or expressive power compared to the original template design while maintaining complete backwards compatibility with the original template design. A specification of the requirements {{on a set of}} template arguments is called a concept. Because specifying and using such requirements are central to thinking about templates, several apparently independent suggestions for language extensions, such as a uniform function call syntax, are also briefly presented. The problems Templates provide unprecedented flexibility to C++ without loss of performance. They add to compile-time type safety and precise specification compared to most popular alternatives. They are key to most parts of the C++ standard library and the basis for most novel techniques for using C++ over the last ten years or so. However, they also present the programmer with significant problems: The expectations o...|$|E
40|$|Abstract. Rivet joint is {{a widely}} used {{connection}} mode in the aircraft assembly. The size of rivet deformation {{affect the quality of}} connection directly. This article design a riveting deformation detection element based on the displacement sensor. It can achieve the accurate measurement of pier diameter and height of the rivet. With adjustable measuring tool and data acquisition element, computer displays measurement measurement results, accomplishing the riveting quality testing. Intorduction In aircraft assembly, rivet joint {{is a widely}} used and high reliable connection mode. The traditional method is to use riveting pier gauge, <b>checking</b> <b>template,</b> feeler, dial gauge with auxiliary bracket[1] and so on. Inspectors labor intensity is relatively large, and test accuracy is not high. Therefore, the author designed a new type of measurement element, It can achieve the accurate measurement of pier diameter and height of the rivet, improving measurement accuracy and efficiency. The Overall Composition of the Measuring Element Element Structure. The composition of measurement unit is as shown in Figure 1. Element is mainly composed of measuring tool, displacement sensors, data acquisition card, software modules and other components. Software modules run on the computer, Data transfer through the data acquisition card with RS 232 serial data transmission line[2, 3]. Displacement sensors and measuring instruments connected with a regulating rod. Measurement range of element is the range of displacement sensor(0 ～ 25 mm), linearity reach 0. 1 % of the range,namely 25 µm[4]...|$|E
40|$|Water {{jet cutter}} is a {{powerful}} tool in the present engineering scenario which works {{on the principle of}} micro erosion occurring when large volume of water is forced through a nozzle of reduced cross section at high velocity (Mach No: 3) and elevated pressure (3000 bar). Water jet cutter was used to cut lumber by forestry engineer Dr. Norman Franz in 1950 s. [1] Water jet cutting find applications in diverse industries from mining to aerospace, where it is used for cutting, shaping, carving and reaming. Water jet cutting has many advantages like no local heat generation, smaller kerf width hence less material wastage, faster and cheaper, higher accuracy, automation capability, and less burr and rough edge etc. Advanced Composites Division (ACD) is actively engaged in the development of various aircraft parts for on-going National Programmes like TEJAS, SARAS etc. For the development of composite parts the most important aspect is tooling. To develop a tool, one has to start with master model. The technology used in ACD for composite tooling is based on splash technique. To fabricate master models and moulds, we require templates such as base plates, master model <b>check</b> <b>templates,</b> mould-ribs, reference pad fixing location <b>templates</b> and mould <b>check</b> <b>templates</b> etc. These are cut precisely using water jet cutter. In this paper, importance of the water jet cutter for composite tooling, space structure fabrication and ceramic test coupon generation has been highlighted. Abrasive water jet technique is normally used to cut hard materials like titanium, ceramics, Kevlar fibre composites etc., The advantage of using water jet cutter with abrasives is also addressed...|$|R
40|$|This paper {{presents}} how acquisition, {{storage and}} communication of clinical documents are implemented at the University Hospitals of Geneva. Careful {{attention has been}} given to user-interfaces, in order to support complex layouts, spell <b>checking,</b> <b>templates</b> management with automatic prefilling in order to facilitate acquisition. A dual architecture has been developed for storage using an attributes-values entity unified database and a consolidated, patient-centered, layout-respectful files-based storage, providing both representation power and sinsert (peed of accesses. This architecture allows great flexibility to store a continuum of data types from simple type values up to complex clinical reports. Finally, communication is entirely based on HTTP-XML internally and a HL- 7 CDA interface V 2 is currently studied for external communication. Some of the problem encountered, mostly concerning the typology of documents and the ontology of clinical attributes are evoked...|$|R
5000|$|Interview and Reference <b>Checking</b> Guides - <b>Template</b> {{interview}} and reference checking guides are developed for varied types of jobs/ roles, including instructions and rating guides. These are {{made available to}} hiring managers and HR Advisors.|$|R
40|$|We formalize the {{informal}} definition of C ++ concepts {{that is currently}} considered by the C ++ standardization committee {{for inclusion in the}} next version of the language. Our definition captures the basic semantics of separate type <b>checking,</b> where conceptconstrained <b>templates</b> are <b>checked</b> separately from their uses and comprises of three main parts: non-standard name lookup, type <b>checking</b> of constrained <b>templates,</b> and implementation binding in concept maps. The formalization reveals two possible problems in {{the informal}} definition: hiding of names is not respected and incompatible implementations can be bound to concept entities. Furthermore, our definition allows formulating intuitively correct code that is rejected by the informal specification. ...|$|R
50|$|All of {{the drivers}} who {{qualified}} {{were born in the}} United States. Clem Proctor won the 100-lap Sportsman race that was held the day before this race in a 1963 Thunderbird. The 1971 winner George Follmer withdrew after his owner had a dispute with the way NASCAR was inspecting the cars, seems like only two cars (Follmer's and Sonny Easley's) were being <b>checked</b> with <b>templates</b> as both were 1968 models and everything else was older.|$|R
5000|$|Template Interview and Reference <b>Checking</b> Guides - <b>Template</b> {{interview}} and reference checking guides are developed for roles/career streams and levels within Occupational Groups including instructions and rating guides. These are {{made available to}} hiring managers and HR Advisors.|$|R
40|$|Templates are {{effective}} tools {{for increasing the}} precision of natural language requirements and for avoiding ambiguities that may arise {{from the use of}} unrestricted natural language. When templates are applied, it is important to verify that the requirements are indeed written according to the templates. If done manually, <b>checking</b> conformance to <b>templates</b> is laborious, presenting a particular challenge when the task has to be repeated multiple times in response to changes in the requirements. In this article, using techniques from Natural Language Processing (NLP), we develop an automated approach for <b>checking</b> conformance to <b>templates.</b> Specifically, we present a generalizable method for casting templates into NLP pattern matchers and reflect on our practical experience implementing automated checkers for two well-known templates in the Requirements Engineering community. We report on the application of our approach to four case studies. Our results indicate that: (1) our approach provides a robust and accurate basis for checking conformance to templates; and (2) the effectiveness of our approach is not compromised even when the requirements glossary terms are unknown. This makes our work particularly relevant to practice, as many industrial requirements documents have incomplete glossaries...|$|R
40|$|A {{library for}} the {{emulation}} of C++ 0 x concepts developed using the emerging C++ 11 programming language is presented. The library integrates existing techniques for concept <b>checking</b> and <b>template</b> metaprogramming {{to provide a}} uniform interface to defining and using concepts. The purpose of this work is to establishing a concrete foundation for experimentation of design techniques for concepts and to motivate and evaluate language design. The viability of the approach is demonstrated by applying it to characterize a number of previously identified usability problems with concepts in the proposed C++ 0 x language. In particular, {{issues related to the}} use of explicit and automatic concepts in generic library design from the perspective of this experiment are examined. Issues related to concept refinement, default implementations of requirements, and the generation of error messages are also discussed. Keywords: C++, Concepts, Generic Librarie...|$|R
40|$|The mCRL 2 {{tool set}} [GKM+ 08] {{is a tool}} set for {{verification}} and validation of concurrent processes, based on process algebra speci??cations. The mCRL 2 language {{is based on the}} Algebra of Communicating Processes (ACP), which is extended to include data and time. This paper reports on experiences with generic programming in C++ as applied in the implementation of the tool set. C++ concepts, a type system for templates [RS 06], form a key ingredient of this style of programming. Using concept definitions, requirements on template types can be defined that are type checked during compile time. The main benefits for the mCRL 2 tool set are uniform and exible interfaces that operate on well-defined types, and a signi??cant increase in code reuse. The use of concepts also promotes the writing of code that corresponds closely to pseudo code, since the chosen concepts correspond naturally with domain specific concepts. This will be illustrated by a simple use case, namely substitution functions. Generic programming is about generalizing software components, to enable reuse {{in a wide variety of}} situations. In C++, generic programming is enabled using templates. C++ concepts are proposed as a means to type <b>check</b> <b>template</b> types. A concept is a set of requirements (valid expressions, associated types, semantic invariants, complexity guarantees, and so on) that a type must fulfill to be correctly used as an argument in a call to a generic algorithm, see [RS 06]. Language support for concepts has been proposed [GJS+ 06] for the next version of the C++ standard, C++ 0 x. Concepts will be used to make the specification of the C++ standard library more complete and precise. A derivative of the GNU C++ compiler [Gre 08] already implements language support for concepts. In the mCRL 2 tool set we have used a portable library for concept checking. Most uses of generic programming in general, and more specifically the use of concepts, that are described in the literature treat the construction of data structures and algorithms that operate on these, see e. g. [GL 05]...|$|R
40|$|Abstract — This paper {{presents}} an intrinsically verifiable library of Quasi Delay Insensitive asynchronous templates providing an efficient debugging platform for large asynchronous circuits. We proposed using State Transition Graph to determining necessary properties {{which must be}} <b>checked.</b> For every <b>template</b> of a Pre-Charged Full Buffer library, we defined PSL properties which are used as monitors verifying correctness of necessary handshaking protocols between templates under simulation. Experimental results show that with a 8 % increase in simulation time, all faults in handshaking protocols can be detected. I...|$|R
40|$|The C++ {{programming}} language remains widely used, de-spite inheriting many unsafe features from C—features that {{often lead to}} failures of type or memory safety that manifest as buffer overflows, use-after-free vulnerabilities, or abstrac-tion violations. Malicious attackers can exploit such viola-tions to compromise application and system security. This paper introduces Ironclad C++, an approach to bringing the benefits of type and memory safety to C++. Ironclad C++ is, in essence, a library-augmented, type-safe subset of C++. All Ironclad C++ programs are valid C++ programs that can be compiled using standard, off-the-shelf C++ compilers. However, not all valid C++ programs are valid Ironclad C++ programs: a syntactic source-code val-idator statically prevents the use of unsafe C++ features. To enforce safety properties {{that are difficult to}} check statically, Ironclad C++ applies dynamic <b>checks</b> via <b>templated</b> “smart pointer ” classes. Using a semi-automatic refactoring tool, we have ported nearly 50 K lines of code to Ironclad C++. These benchmarks incur a performance overhead of 12 % on average, compared to the original unsafe C++ code...|$|R
40|$|The {{second edition}} of Benefits Management has been updated with current examples, further {{insights}} from experience and recent research. It {{shows how the}} enduring challenges achieving business value from information systems and technology projects can be addressed successfully. The approach, which is synthesized from best practices, sound theories and proven techniques {{from a range of}} management disciplines, is exemplified from the authors' extensive experience of working {{with a wide range of}} organizations. The book includes examples from a wide variety of projects including non-IT projects. The book is written in an accessible style, ideal for practicing managers, and includes <b>check</b> lists and <b>templates</b> for using the processes, tools and techniques and real-life case studies of their application and impacts. ...|$|R
40|$|We {{present a}} {{technique}} for automatically extracting mutual exclusion invariants from temporal planning instances. It first identifies {{a set of}} invariant templates by inspecting the lifted representation of the domain and then <b>checks</b> these <b>templates</b> against properties that assure invariance. Our technique builds on other approaches to invariant synthesis presented in the literature, but departs from their limited focus on instantaneous actions by addressing temporal domains. To deal with time, we formulate invariance conditions that account for the entire structure of the actions and the possible concurrent interactions between them. As a result, we construct a significantly more comprehensive technique than previous methods, which is able to find not only invariants for temporal domains, but also a broader set of invariants for non-temporal domains. The experimental results reported in this paper provide evidence that identifying a broader set of invariants results in the generation of fewer multi-valued state variables with larger domains. We show that, in turn, this {{reduction in the number}} of variables reflects positively on the performance of a number of temporal planners that use a variable/value representation by significantly reducing their running time...|$|R
30|$|To {{determine}} the localization of Y 38 F 2 AR. 9, the cherry::y 38 f 2 ar. 9 construct was injected into gfp::tram- 1 animals at {{the concentration of}} 1 ng/μL and pRF 4 (rol- 6 [su 1006]) was co-injected. The F 1 animals were checked with Zeiss LSM 710 META confocal microscope. For RNAi injection experiments, single-stranded RNA was transcribed from T 7 - and SP 6 -flanked PCR templates. ssRNAs were then annealed and injected into animals carrying Phsp- 4 ::GFP. The F 1 animals were <b>checked.</b> The DNA <b>template</b> used for RNA synthesis was y 38 f 2 ar. 9 (YAC Y 38 F 2 AR: nt 56335 – 56636). For rescue assay, the indicated construct was injected into the Phsp- 4 ::GFP worms together with pRF 4 (rol- 6 [su 1006]) and y 38 f 2 ar. 9 RNAi was then injected into the F 2 animals. The F 3 animals were checked with Zeiss LSM 710 META confocal microscope.|$|R
40|$|This paper {{investigates the}} main causes {{that make the}} {{application}} migration to Cloud complicated and error-prone through two case studies. We first discuss the typical configuration errors in each migration case study based on our error categorization model, which classifies the configuration errors into seven categories. Then we describe the common installation errors across both case studies. By analyzing operator errors in our case studies for migrating applications to cloud, we present the design of CloudMig, a semi-automated migration validation system with two unique characteristics. First, we develop a continual query (CQ) based configuration policy checking system, which facilitate operators to weave important configuration constraints into CQ-based policies and periodically run these policies to monitor the configuration changes and detect and alert the possible configuration constraints violations. Second, CloudMig combines the CQ based policy <b>checking</b> with the <b>template</b> based installation automation to help operators reduce the installation errors and increase the correctness assurance of application migration. Our experiments show that CloudMig can effectively detect {{a majority of the}} configuration errors in the migration process...|$|R
40|$|International audienceConcepts {{are likely}} to be {{introduced}} in a future C++ standard. They can be used for constraining template parameters, which enables <b>checking</b> requirements on <b>template</b> parameters sooner in the compilation process, and thus providing more intelligible error messages to the user. They can also be used in the specialization of templates, thus leading to a better control over the selection of the most appropriate version of a template for a given instantiation. This latter aspect offers new possibilities in the design of template libraries, as it enhances the specialization mechanism of templates, and set it up as a solid alternative to inheritance when static binding can replace dynamic binding. This report addresses the design of expression templates (i. e. templates that represent expressions and are usually built through operator overloading) that are useful to develop an embedded domain specific language (EDSL), and can speed up the evaluation of an expression by delaying the evaluation of intermediate operations to avoid unnecessary temporary objects. We propose to use concept-based template specialization to parse expression templates in order to ease the design of an EDSL. This approach is a static variant of the well-known visitor design pattern that replaces the overridden methods in the double dispatch of the original design pattern by template specializations based on concepts. An example of EDSL for linear programming developed with our solution demonstrates that a concept-based design helps producing concise and reliable code...|$|R
40|$|Natural Language (NL) {{is arguably}} the most common vehicle for specifying requirements. This {{dissertation}} devises automated assistance for some important tasks that requirements engineers need to perform in order to structure, manage, and elaborate NL requirements in a sound and effective manner. The key enabling technology underlying the work in this dissertation is Natural Language Processing (NLP). All the solutions presented herein have been developed and empirically evaluated in close collaboration with industrial partners. The dissertation addresses four different facets of requirements analysis: • <b>Checking</b> conformance to <b>templates.</b> Requirements templates are an effective tool for improving the structure and quality of NL requirements statements. When templates are used for specifying the requirements, an important quality assurance task is to ensure that the requirements conform to the intended templates. We develop an automated solution for checking the conformance of requirements to templates. • Extraction of glossary terms. Requirements glossaries (dictionaries) improve the understandability of requirements, and mitigate vagueness and ambiguity. We develop an auto- mated solution for supporting requirements analysts in the selection of glossary terms and their related terms. • Extraction of domain models. By providing a precise representation of the main concepts in a software project and the relationships between these concepts, a domain model serves as an important artifact for systematic requirements elaboration. We propose an automated approach for domain model extraction from requirements. The extraction rules in our approach encompass both the rules already described in the literature {{as well as a number}} of important extensions developed in this dissertation. • Identifying the impact of requirements changes. Uncontrolled change in requirements presents a major risk to the success of software projects. We address two different dimen- sions of requirements change analysis in this dissertation: First, we develop an automated approach for predicting how a change to one requirement impacts other requirements. Next, we consider the propagation of change from requirements to design. To this end, we develop an automated approach for predicting how the design of a system is impacted by changes made to the requirements...|$|R
40|$|With {{the ever}} {{increasing}} global competitive business environment, capturing new lucrative markets {{has taken the}} forefront for Multinational Entities (MNE’s). In the recent past, emerging countries have gained prominence as a focal growth destination for many MNEs. Despite the business opportunities that they offer, they still remain complex markets in which to do business. Consequently, for the MNEs that have made entry into these markets, adequate growth strategies designed to include sets of activities that deliver a unique mix of value to the organization are imperative. 1 This therefore calls for such organisations to adapt their existing growth strategies in emerging markets to various demands. This is in order to maximise performance through well-orchestrated growth agendas that work {{in concert with the}} overall corporate strategy. Nevertheless, for overall success, businesses are becoming more aware that operational and control failures can be extremely costly. 2 This is because growth comes with increased risks hence a need for new solutions to mitigate and manage the risks. Consequently, the discipline of compliance which is designed to mitigate risks through adherence of; legal requirements, internal and external policies is no longer a second-thought function that requires action down the road. Corporate leaders now recognize that it is important for business expansion and the protection of shareholder value. 3 In these markets, compliance related issues have proved to be difficult hurdles for many organisations and they are widely viewed high risk compliance markets. 4 Despite this, many MNEs that venture into such markets fail to integrate their growth strategies and compliance programmes/strategies. This paper explores the hypothesis that for organisations to optimise performance, their compliance programmes/strategies should work in concert with their broader strategic goals, e. g. growth. This thesis aims to show how the two can be integrated by using Rolls-Royce Power Systems’ AG (RRPS) growth strategy in China and its compliance programme as a case study. The hypothesis is that, if successfully integrated, RRPS can maximise its growth performance in China. Secondly the study seeks to provide a flexible <b>check</b> list or <b>template</b> that RRPS can adapt in its future Integrated Sales Road Maps (ISRMs) in other targeted countries or regions...|$|R
40|$|This is an {{official}} report. This report, D 1. 2 Project Report - months 1 – 18, {{provides an overview}} of the work undertaken in the SafetyCube project. At the time of the preparation of the project the reporting requirements were not known and an internal mid-term evaluation of the project was considered to be helpful to the project team. Since then the formal project reporting requirements have become known and the internal mid-term evaluation of the project has been superseded by the Mid-term Project Review which covers M 1 – M 18. The objectives for the first 18 months of the project were to: 1. Implement the project management framework to support communication between partners and achievement of project objectives. 2. Establish a project dissemination and consultation platform to ensure all stakeholders can remain informed of the project progress and can contribute to the DSS. 3. Develop the methodological framework of the DSS, and process for extracting data on risks and measures. 4. Estimate the numbers of seriously injured traffic casualties in Europe and the resulting health impacts. 5. Define the functionality of the DSS and prepare the underlying structure. Very good {{progress has been made in}} the first 18 months of the project and all objectives have been achieved. Notably; 1. The project now has a very effective management framework that is focussed on: • The project coordinator and a dedicated project administrator. • Monthly Work Package (WP) Leaders meetings for routine decision making. • Regular WP partner meetings. • Periodic full partner plenary meetings. • A dedicated web conferencing system to facilitate communication together with a central web-based document repository. 2. A dissemination platform has been established to facilitate communication between the project and future DSS users. • The project website (www. safetycube-project. eu) provides information about the project and news of recent developments. • A newsletter, published typically four times each year, provides more detailed information to recipients. • A series of stakeholder consultation workshops have provided the project team with very useful guidance regarding the functionality and content of the DSS. 3. The methodological framework for the DSS has been established and data on risks has been evaluated and recorded for entry to the DSS. • The procedure to be used to record details of risks and measures from studies has been defined. • A sophisticated data entry template has been developed to provide a consistent means to gather data for entry onto the database and to enable an automatic quality <b>check</b> of <b>template</b> use. • A total of 600 studies have been reviewed and data of 3, 500 risks has been entered onto the templates. The studies cover road user, infrastructure and vehicle risks. • A total of 60 topic syntheses have been prepared to provide summaries and critical evaluation of the existing knowledge about road safety risks. The studies cover road user, infrastructure and vehicle risks. 4. Important advances have been made regarding the enumeration of serious injuries and the societal level impact. • With the assistance of EC DG-MOVE a strong collaboration has been established with the EU CARE experts group representing the Member States. • The methods used across the EU to estimate the numbers of seriously injured casualties have been reviewed and the comparability assessed. • Recommendations for approaches to improve accuracy of serious injury counting have been made. 5. The structure and functionality of the DSS has been developed and a provisional “look and feel” prepared. • A comprehensive taxonomy of risks and measures has been prepared to provide the internal structure of the DSS. • The basic functionality of the DSS has been specified and entry points, search methodologies and output descriptions have been prepared. • Wireframe screens have been prepared to illustrate the possible appearance of the DSS...|$|R
40|$|Replicative DNA polymerases (DNAPs) are {{molecular}} motors {{responsible for}} high fidelity replication {{of the genome}} prior to each cellular division. These enzymes require two divalent cations (Me 2 +) to catalyze nucleotidyl transfer reactions. Many DNAPs {{have the ability to}} perform this chemical transformation in two active sites; (i) the polymerase active site where deoxyribonucleoside-triphosphate (dNTP) is selected and <b>checked</b> for <b>template</b> directed Watson-Crick base pairing prior to phosphodiester bond formation, and (ii) the exonuclease active site, where the 3 ʹ primer terminal nucleotide can be excised {{in a manner consistent with}} proofreading the nascent DNA strand. Replicative DNAPs must choose the dNTP complementary to the template from a mixture of both dNTPs and ribonucleoside-triphosphates (rNTPs). A balance exists between substrate selection and proofreading, the primary mechanisms that ensure DNAP fidelity. Decades of biochemical research have identified several conserved residues associated with the activities of these two catalytic centers, using the highly processive DNAP from the bacteriophage phi 29, structural studies implicated a residues Y 254, Y 390 & Y 226, in the mechanism of translocation. Translocation occurs after nucleotide addition in the polymerase active site and is essential for processive DNAP replication. The translocation is a single nucleotide step that is required to move the DNAP along its DNA substrate, thus resetting the active site with the next template nucleotide poised for subsequent dNTP selection. 	The kinetic complexity of replicative DNAPs requires an experimental method capable of distinguishing the multiple kinetic steps associated with DNAP activity. We developed the first such method for direct measurement of translocation, uniquely capable of making robust quantitative measurements with single nucleotide spatial precision and submillisecond temporal resolution. This method utilizes an α-Hemolysin nanopore embedded in a lipid bilayer which separates two wells of ionic solution to capture phi 29 DNAP-DNA complexes in an electric field applied by a patch clamp amplifier. We have modeled the noncovalent kinetic transitions of translocation, nucleotide binding and primer strand transfer between the polymerase and exonuclease active sites. We demonstrated that in the pre-translocation state, which is analogous to the state the DNAP-DNA complex is in immediately following phosphodiester bond formation, a kinetic checkpoint exists where the polymerase can either send the primer terminus from the polymerase active site, in the pre-translocation state, to the exonuclease active site or it can retain the primer strand in the polymerase active site and translocate to the post-translocation state. If the polymerase transfers the primer strand to the exonuclease active site and the primer terminus is unedited then it can be returned from the exonuclease active site back to the polymerase active site in the pre-translocation state. If the polymerase translocates from the pre-translocation state to the post-translocation state then it is capable of binding to complimentary dNTP. Bound dNTP must dissociate before the polymerase can reverse translocate, from the post to the pre-translocation state. 	We applied this experimental method to test several hypotheses regarding the mechanisms of high fidelity DNA replication. In the second chapter we describe the role of two conserved residues, Y 226 & Y 390, suggested by structural studies to be critical to the mechanism of translocation. Our data indicate that rather than being major determinants in the kinetic mechanism of translocation they are instead associated with active site assembly during dNTP substrate selection. In the third chapter we describe the kinetic mechanisms contributing to the stable incorporation of rNTPs into DNA by replicative DNAPs. In this study we systematically show that while the affinity for correctly base paired rNTP is considerably lower than it is for complementary dNTP, after incorporation of rNTP into the primer terminus the kinetic decision to edit or translocate is no more probable for complementary rNTP than dNTP. In chapter four we describe the role of divalent cations (Me 2 +) on the noncovalent transitions associated with DNAPs. Here we determined at submillimolar concentrations of Me 2 + the kinetic pathway for primer strand transfer, from the pre-translocation state in the polymerase active site to and from the exonuclease active site, is composed of more than the two kinetic states identified in prior experiments with > 1 mM Me 2 +. We also showed that across five orders of magnitude Me 2 + causes a concentration dependent decrease in the rate of translocation from the pre to the post-translocation state and a concentration dependent increase in the rate of translocation from the post to the pre-translocation state. Also, we demonstrated that, in the presence of Ca 2 +, the presence of the primer terminal 3 ʹOH does not contribute to the ground state stabilization of dNTP binding...|$|R

