0|9896|Public
40|$|The {{development}} of a high density Schottky barrier Infrared Charged Coupled Device (IRCCD) <b>type</b> <b>image</b> <b>sensor</b> for earth observation was initiated. A dual band 512 pixel linear array was developed, which was capable of being butted end to end to make an arbitrarily long linear array. Measurement made on palladium silicide IRCCDs that were two-dimensional 63 x 32 pixel arrays were summarized. The test data on a 512 pixel linear array is also summarized...|$|R
5000|$|... "In July 2003, Nikon {{introduced}} LBCAST- {{a completely}} new <b>type</b> of <b>image</b> <b>sensor,</b> different from CCD and CMOS, that is a high-speed, power-efficient, low-noise device to be installed in Nikon's flagship camera, the D2Hs." ...|$|R
5000|$|There {{are several}} main <b>types</b> of color <b>image</b> <b>sensors,</b> differing by {{the type of}} color-separation mechanism: ...|$|R
30|$|Infrared {{and visible}} image fusion {{is part of}} multi-source image fusion. Multi-source image fusion {{is the process of}} {{acquiring}} unified description towards the formation of high-performance perception system with employing different <b>types</b> of <b>image</b> <b>sensors,</b> and combing two of more kinds of image information effectively. It is the technology with comprehensive and optimized treatment for multi-information’s acquisition, presentation, and internal relations [1].|$|R
40|$|An {{overview}} of ionizing radiation effects in imagers manufactured in a 0. 18 -μm CMOS <b>image</b> <b>sensor</b> technology is presented. Fourteen <b>types</b> of <b>image</b> <b>sensors</b> are characterized and irradiated by a 60 Co source up to 5 kGy. The {{differences between these}} 14 designs allow us to separately estimate the effect of ionizing radiation on microlenses, on low- and zero-threshold-voltage MOSFETs and on several pixel layouts using P+ guard-rings and edgeless transistors. After irradiation, wavelength dependent responsivity drops are observed. All the sensors exhibit a large dark current increase attributed to the shallow trench isolation that surrounds the photodiodes. Saturation voltage rises and readout chain gain variations are also reported. Finally, the radiation hardening perspectives resulting from this paper are discussed...|$|R
50|$|The {{two major}} <b>types</b> of digital <b>image</b> <b>sensor</b> are CCD and CMOS. A CCD sensor has one {{amplifier}} {{for all the}} pixels, while each pixel in a CMOS active-pixel sensor has its own amplifier. Compared to CCDs, CMOS sensors use less power. Cameras with a small sensor use a back-side-illuminated CMOS (BSI-CMOS) <b>sensor.</b> Overall final <b>image</b> quality is more dependent on the image processing capability of the camera, than on sensor type.|$|R
40|$|In {{this paper}} we are {{presenting}} preliminary results from 4 T technology based CMOS <b>image</b> <b>sensors</b> with global shutter, i. e. all pixels {{in the active}} array integrate light simultaneously. The global shutter operation mode is particularly important for high-speed video applications, where the more commonly implemented rolling line shutter creates motion blur. Our chips were fabricated using a 0. 18 micron 4 T, CIS technology with pinned photodiode and transfer gate. Different from conventional 3 T <b>type</b> CMOS <b>image</b> <b>sensors</b> with global shutter pixel, in these 4 T technology based global shutter pixels, the charge is transferred, not just sampled, onto the sense node. This translates into very high sensitivity and low readout noise at low power. For an imager with 7 transistors per pixel that is operated in global shutter, “Integrate While Read ” mode, we measure an input referred noise of 10 electrons. The extinction ratio at full well signal charge is ~ 97. 7 %. 1...|$|R
40|$|Abstract-The Tacking CCD is a {{new type}} of charge trans-port {{mechanism}} that is suitable for junction- as well as MOS-type CCD’s. A specific form, the Trenched Tacking CCD (TTCCD), promises high pixel density and high charge han-dling capability per unit of surface area. The TTCCD structure is suitable for making new <b>types</b> of solid-state <b>image</b> <b>sensors</b> with increased light sensitivity and there is the possibility of incorporating a vertical overflow drain. First samples of the TTCCD have been realized and its functionality has been con-firmed. I...|$|R
40|$|This work {{presents}} {{preliminary results}} {{in the study of}} a novel structure for a laser scanned photodiode (LSP) <b>type</b> of <b>image</b> <b>sensor.</b> In order to increase the signal output, a stacked p-i-n-p-i-n structure with an intermediate light-blocking layer is used. The image and the scanning beam are incident through opposite sides of the sensor and their absorption is kept in separate junctions by an intermediate light-blocking layer. As in the usual LSP structure the scanning beam-induced photocurrent is dependent on the local illumination conditions of the image. The main difference between the two structures arises from the fact that in this new structure the image and the scanner have different optical paths leading to an increase in the photocurrent when the scanning beam is incident on a region illuminated on the image side of the sensor, while a decreasing in the photocurrent was observed in the single junction LSP. The results show that the structure can be successfully used as an <b>image</b> <b>sensor</b> even though some optimization is needed to enhance the performance of the device...|$|R
40|$|The Defense Advanced Research Projects Agency (DARPA) has a {{substantial}} program {{to develop a}} 2200 x 2200 pixel CCD (Charge Coupled Device) mosaic array made up of 400 individual CCD's, 110 x 110 pixels square. This <b>type</b> of <b>image</b> <b>sensor</b> appeared to have application in space and ground-based astronomy. Under this grant a CCD television camera system was built which was capable of operating an array of 4 CCD's to explore the suitability of the CCD's to explore the suitability of the CCD for astronomical applications. Two individual packaged CCD's were received and evaluated. Evaluation of the basic characteristics of the best individual chips was encouraging, but the manufacturer found that their yield in manufacturing this design is two low to supply sufficient CDD's for the DARPA mosaic array. The potential utility of large mosaic arrays in astronomy is still substantial and continued monitoring of the manufacturers progress {{in the coming year}} is recommended...|$|R
40|$|This paper {{presents}} a modulation scheme {{in the time}} domain based on On-Off-Keying and proposes various compatible supports for different <b>types</b> of <b>image</b> <b>sensors.</b> The content {{of this article is}} a sub-proposal to the IEEE 802. 15. 7 r 1 Task Group (TG 7 r 1) aimed at Optical Wireless Communication (OWC) using an <b>image</b> <b>sensor</b> as the receiver. The compatibility support is indispensable for <b>Image</b> <b>Sensor</b> Communications (ISC) because the rolling shutter <b>image</b> <b>sensors</b> currently available have different frame rates, shutter speeds, sampling rates, and resolutions. However, focusing on unidirectional communications (i. e., data broadcasting, beacons), an asynchronous communication prototype is also discussed in the paper. Due to the physical limitations associated with typical <b>image</b> <b>sensors</b> (including low and varying frame rates, long exposures, and low shutter speeds), the link speed performance is critically considered. Based on the practical measurement of camera response to modulated light, an operating frequency range is suggested along with the similar system architecture, decoding procedure, and algorithms. A significant feature of our novel data frame structure is that it can support both typical frame rate cameras (in the oversampling mode) as well as very low frame rate cameras (in the error detection mode for a camera whose frame rate is lower than the transmission packet rate). A high frame rate camera, i. e., no less than 20 fps, is supported in an oversampling mode in which a majority voting scheme for decoding data is applied. A low frame rate camera, i. e., when the frame rate drops to less than 20 fps at some certain time, is supported by an error detection mode in which any missing data sub-packet is detected in decoding and later corrected by external code. Numerical results and valuable analysis are also included to indicate the capability of the proposed schemes. Comment: 24 pages, 15 figures, 5 tables, Sensors Journa...|$|R
5000|$|Presently {{the terms}} APS-C and APS-H {{are most often}} used in {{reference}} to various makes of digital SLR that contain imaging sensors that are (very) roughly equivalent to their respective film dimensions given above (see Crop factor). Concurrently to their APS SLR film cameras, some manufacturers released lenses intended for use on APS film cameras - such as the Canon EF 22-55mm - which had a wider field of view {{to account for the}} relative-to-35mm crop factor. Some of these lenses have survived and are now marketed towards use on [...] "APS" [...] digital SLRs for the same reason. In reference to digital cameras, APS may also mean active pixel sensor, a <b>type</b> of CMOS <b>image</b> <b>sensor.</b>|$|R
40|$|<b>Image</b> <b>sensors</b> play a {{vital role}} in many image sensing and capture applications. Among the various <b>types</b> of <b>image</b> <b>sensors,</b> {{complementary}} metal oxide semiconductor (CMOS) based active pixel sensors (APS), which are characterized by reduced pixel size, give fast readouts and reduced noise. APS are used in many applications such as mobile cameras, digital cameras, Webcams, and many consumer, commercial and scientific applications. With these developments and applications, CMOS APS designs are challenging the old and mature technology of charged couple device (CCD) sensors. With the continuous improvements of APS architecture, pixel designs, along with the development of nanometer CMOS fabrications technologies, APS are optimized for optical sensing. In addition, APS offers very low-power and low-voltage operations and is suitable for monolithic integration, thus allowing manufacturers to integrate more functionality on the array and building low-cost camera-on-a-chip. In this thesis, I explore the current state-of-the-art of CMOS APS by examining various types of APS. I show design and simulation results of one of the most commonly used APS in consumer applications, i. e. photodiode based APS. We also present an approach for technology scaling of the devices in photodiode APS to present CMOS technologies. Finally, I present the most modern CMOS APS technologies by reviewing different design models. The design of the photodiode APS is implemented using commercial CAD tools...|$|R
50|$|A back-illuminated sensor, {{also known}} as {{backside}} illumination (BSI or BI) sensor, is a <b>type</b> of digital <b>image</b> <b>sensor</b> that uses a novel arrangement of the imaging elements {{to increase the amount}} of light captured and thereby improve low-light performance. The technique was used for some time in specialized roles like low-light security cameras and astronomy sensors, but was complex to build and required further refinement to become widely used. Sony was the first to reduce these problems and their costs sufficiently to introduce a 5-megapixel 1.75 µm BI CMOS sensor at general consumer prices in 2009. BI sensors from OmniVision Technologies have since been used in consumer electronics from other manufacturers as in the HTC EVO 4G Android smart phone, and as a major selling point for the camera in Apple's iPhone 4.|$|R
25|$|The {{two primary}} <b>types</b> of HDR <b>images</b> are {{computer}} renderings and images resulting from merging multiple low-dynamic-range (LDR) or standard-dynamic-range (SDR) photographs. HDR images {{can also be}} acquired using special <b>image</b> <b>sensors,</b> such as an oversampled binary <b>image</b> <b>sensor.</b>|$|R
40|$|The CMOS (Complementary Metal-Oxide-Semiconductor) {{is a new}} <b>type</b> {{of solid}} <b>image</b> <b>sensor</b> device widely used in object tracking, object recognition, {{intelligent}} navigation fields, and so on. However, images captured by outdoor CMOS sensor devices are usually affected by suspended atmospheric particles (such as haze), causing a reduction in image contrast, color distortion problems, and so on. In view of this, we propose a novel dehazing approach based on a local consistent Markov random field (MRF) framework. The neighboring clique in traditional MRF is extended to the non-neighboring clique, which is defined on local consistent blocks based on two clues, where both the atmospheric light and transmission map satisfy the character of local consistency. In this framework, our model can strengthen the restriction of the whole image while incorporating more sophisticated statistical priors, resulting in more expressive power of modeling, thus, solving inadequate detail recovery effectively and alleviating color distortion. Moreover, the local consistent MRF framework can obtain details while maintaining better results for dehazing, which effectively improves the image quality captured by the CMOS <b>image</b> <b>sensor.</b> Experimental results verified that the method proposed has the combined advantages of detail recovery and color preservation...|$|R
30|$|<b>Image</b> <b>sensors</b> {{are used}} in {{numerous}} <b>types</b> of <b>image</b> acquisition devices such as digital cameras, camcorders, and CCTV cameras. Recently, their application region has broadened to include smart devices, and the acquired images are not merely for storage but also for interaction between a human and a computer. To satisfy the many goals of <b>image</b> <b>sensors,</b> the role of image enhancement {{is more important than}} ever before.|$|R
40|$|This is a Ph. D. thesis {{dissertation}} {{in which}} a new <b>type</b> of <b>image</b> <b>sensor</b> is investigated as possible successor to the charge coupled device (CCD) for scientific applications. As {{a result of the}} work described in this dissertation, the active pixel charge injection device (AP-CID) has been developed. This device retains most of the positive features of both the charge injection device (CJD) imager (random readout, non destructive readout, antiblooming, increased UV sensitivity, radiation tolerance, low power consumption, low manufacturing price) and the CCD imager (low noise, high dynamic range). The device lacks most of the drawbacks of the aforementioned devices. A functional array architecture was created. Based on this architecture several devices were fabricated. One of the arrays was fully measured, characterized and suggestions for improvement were formulated. Most of the characterizationalysis work described in this dissertation was centered on the following issues: temporal noise, linearity and FPN. The measured noise performance of the new device is excellent and comparable to the noise performance of the scientific CCD. The newly developed sensor is necessary for scientific imaging applications in space based operation. However due to its qualities, this device could be used in a much wider range of applications including commercial digital cameras, spectroscopy, biological, nuclear and other scientific applications...|$|R
40|$|Single plane {{illumination}} microscopy based fluorescence {{correlation spectroscopy}} (SPIM-FCS) is a new method for imaging FCS in 3 D samples, providing diffusion coefficients, transport, flow velocities and concentrations in an imaging mode. SPIM-FCS records correlation functions over a whole plane in a sample, which requires array detectors for recording the fluorescence signal. Several <b>types</b> of <b>image</b> <b>sensors</b> are suitable for FCS. They differ in properties such as effective area per pixel, quantum efficiency, noise level and read-out speed. Here we compare the performance of several low light array detectors based on three different technologies: (1) Single-photon avalanche diode (SPAD) arrays, (2) passive-pixel electron multiplying charge coupled device (EMCCD) and (3) active-pixel scientific-grade {{complementary metal oxide semiconductor}} cameras (sCMOS). We discuss the influence of the detector characteristics on the effective FCS observation volume, and demonstrate that light sheet based SPIM-FCS provides absolute diffusion coefficients. This is verified by parallel measurements with confocal FCS, single particle tracking (SPT), and the determination of concentration gradients in space and time. While EMCCD cameras have a temporal resolution in the millisecond range, sCMOS cameras and SPAD arrays can extend the time resolution of SPIM-FCS down to 10 ?s or lower. MicroelectronicsElectrical Engineering, Mathematics and Computer Scienc...|$|R
30|$|Digital {{recording}} {{devices such as}} digital cameras and digital camcorders adopt various <b>types</b> of digital <b>image</b> <b>sensors,</b> e.g., a charge-coupled device (CCD), complementary metal-oxide-semiconductor (CMOS), and a junction field-effect transistor (JFET). The digital <b>image</b> <b>sensor</b> consists of numerous photon detectors that convert photoelectrons into electrical signals using the photoelectric effect. The strength of the electrical signal {{is affected by the}} sensitivity of the photon detectors to light. The light sensitivity of the photon detectors varies slightly depending on the imperfections created during the manufacturing process of the silicon that forms the photon detectors. This difference in light sensitivity of each pixel generates uncorrelated multiplicative pattern noise. Consequently, every digital sensor casts a unique sensor pattern noise (SPN) onto images (frames) it takes. The SPN acts as a sensor fingerprint that identifies a source digital imaging device. Using the identifiable attribute of SPN, source digital camera (camcorder) identification methods have been proposed [17 – 19]. In order to identify the source digital camera, the fine quality of the reference SPN is estimated from uniform images, e.g., blue sky images. Then, the test SPN is estimated from the test image. If the correlation value calculated using the reference SPN and test SPN is higher than a specified threshold, the digital camera is determined to be the source camera of the test image.|$|R
40|$|DE 102007042984 A 1 UPAB: 20090403 NOVELTY - The device {{comprises}} an <b>image</b> <b>sensor</b> array (2) {{with multiple}} array-like <b>image</b> <b>sensor</b> units (20). A photo-sensitive surface and a micro lens array (3) {{are assigned to}} the <b>image</b> <b>sensor</b> array and are arranged between an imaging object (6) and the <b>image</b> <b>sensor</b> array. Each <b>image</b> <b>sensor</b> unit is assigned a micro lens (30). A substrate layer, particularly made of silicone or polychlorinated biphenyl or plastic is arranged between a carrier and the <b>image</b> <b>sensor</b> array or the radiation source. DETAILED DESCRIPTION - An INDEPENDENT CLAIM is included for an input unit, particularly a computer mouse or a radio control or a console control unit for a data-processing system. USE - Device for optical navigation for controlling a cursor of an image output unit by a relative movement between <b>image</b> <b>sensor</b> and imaging object (Claimed). ADVANTAGE - The photo-sensitive surface and a micro lens array are assigned to the <b>image</b> <b>sensor</b> array and are arranged between an imaging object and the <b>image</b> <b>sensor</b> array, and each <b>image</b> <b>sensor</b> unit is assigned a micro lens, and thus ensures a good resolution and brightness {{at the edge of}} the <b>image</b> <b>sensor...</b>|$|R
5000|$|<b>Image</b> <b>sensor</b> format, {{the sizes}} and shapes of common <b>image</b> <b>sensors</b> ...|$|R
40|$|We {{present a}} {{monolithic}} ultraviolet(UV) <b>image</b> <b>sensor</b> {{based on a}} standard CMOS process. A compact UV sensitive device structure is designed as a pixel for the <b>image</b> <b>sensor.</b> This UV <b>image</b> <b>sensor</b> consists of a CMOS pixel array, high-voltage switches, a readout circuit and a digital control circuit. A 16 × 16 <b>image</b> <b>sensor</b> prototype chip is implemented in a 0. 18 μm standard CMOS logic process. The pixel and <b>image</b> <b>sensor</b> were measured. Experimental results demonstrate that the <b>image</b> <b>sensor</b> has a high sensitivity of 0. 072 V/(mJ/cm 2) and can capture a UV image. It is suitable for large-scale monolithic bio-medical and space applications. ? 2011 Chinese Institute of Electronics...|$|R
40|$|The {{increasing}} miniaturization {{and resolution}} of <b>image</b> <b>sensors</b> bring challenges to conventional optical {{elements such as}} spectral filters and polarizers, the properties of which are determined mainly by the materials used, including dye polymers. Recent developments in spectral filtering and optical manipulating techniques based on nanophotonics have opened up {{the possibility of an}} alternative method to control light spectrally and spatially. By integrating these technologies into <b>image</b> <b>sensors,</b> it will become possible to achieve high compactness, improved process compatibility, robust stability and tunable functionality. In this Review, recent representative achievements on nanophotonic <b>image</b> <b>sensors</b> are presented and analyzed including <b>image</b> <b>sensors</b> with nanophotonic color filters and polarizers, metamaterial-based THz <b>image</b> <b>sensors,</b> filter-free nanowire <b>image</b> <b>sensors</b> and nanostructured-based multispectral <b>image</b> <b>sensors.</b> This novel combination of cutting edge photonics research and well-developed commercial products may not only lead to an important application of nanophotonics but also offer great potential for next generation <b>image</b> <b>sensors</b> beyond Moore's Law expectations...|$|R
50|$|In digital photography, the <b>image</b> <b>sensor</b> {{format is}} {{the shape and}} size of the <b>image</b> <b>sensor.</b>|$|R
40|$|A new CMOS-based <b>image</b> <b>sensor</b> that is {{intrinsically}} compatible with on-chip CMOS circuitry is reported. The new CMOS active pixel <b>image</b> <b>sensor</b> achieves low noise, high sensitivity, X-Y addressability, and has simple timing requirements. The <b>image</b> <b>sensor</b> was fabricated using a 2 micrometer p-well CMOS process, {{and consists of}} a 128 x 128 array of 40 micrometer x 40 micrometer pixels. The CMOS <b>image</b> <b>sensor</b> technology enables highly integrated smart <b>image</b> <b>sensors,</b> and makes the design, incorporation and fabrication of such sensors widely accessible to the integrated circuit community...|$|R
30|$|A {{quadrate}} ultraviolet LED as excitation {{light source}} {{was to make sure}} that samples accept the same amount of irradiation. It is also critical to select a good optical sensor. Photodiode, photomultiplier tube, linear CCDs, and <b>image</b> <b>sensors</b> are widely used optical sensors. However, photodiode, photomultiplier tube, and linear CCDs have a limited surveyed area. On the contrary, <b>image</b> <b>sensors</b> could provide a more flexible and wider detection area. Moreover, <b>image</b> <b>sensors</b> could realize short time detection [1]. Based on the above benefits, we decided to employ an <b>image</b> <b>sensor.</b> CCD and CMOS are two most popularly used <b>image</b> <b>sensors.</b> Compared with CMOS, CCD has the advantages of low noise and better imaging quality [24], so a color CCD <b>image</b> <b>sensor</b> was chosen. This digital CCD <b>image</b> <b>sensor</b> with a USB not only solved the problem of employing an image acquisition card but also provided stable and rapid data transmission.|$|R
40|$|In this paper, {{we propose}} a novel 2 D-to- 3 D video {{conversion}} method for 3 D entertainment applications. 3 D entertainment {{is getting more}} and more popular and can be found in many contexts, such as TV and home gaming equipment. 3 D <b>image</b> <b>sensors</b> are a new method to produce stereoscopic video content conveniently and at a low cost, and can thus meet the urgent demand for 3 D videos in the 3 D entertaiment market. Generally, 2 D <b>image</b> <b>sensor</b> and 2 D-to- 3 D conversion chip can compose a 3 D <b>image</b> <b>sensor.</b> Our study presents a novel 2 D-to- 3 D video conversion algorithm which can be adopted in a 3 D <b>image</b> <b>sensor.</b> In our algorithm, a depth map is generated by combining global depth gradient and local depth refinement for each frame of 2 D video input. Global depth gradient is computed according to <b>image</b> <b>type</b> while local depth refinement is related to color information. As input 2 D video content consists of a number of video shots, the proposed algorithm reuses the global depth gradient of frames within the same video shot to generate time-coherent depth maps. The experimental results prove that this novel method can adapt to different <b>image</b> <b>types,</b> reduce computational complexity and improve the temporal smoothness of generated 3 D video...|$|R
40|$|The optical {{detector}} includes {{at least one}} <b>image</b> <b>sensor</b> (10) which produces an output dependent on the light (12) falling on it. An output amplifier (14) with variable gain is provided for amplifying the outputs from the <b>image</b> <b>sensor(s).</b> A gain varying device (16, 18, 20) detects the output signal from the <b>image</b> <b>sensor</b> prior to amplification by the output amplifier, and sets the gain of the output amplifier based on the detected level of the <b>image</b> <b>sensor</b> output. The <b>image</b> <b>sensor,</b> output amplifier and gain varying device are integrated in one IC. ADVANTAGE - Provides output signals having higher signal-to-noise ratio...|$|R
40|$|Abstract—We {{consider}} optimal {{resource allocation}} for wireless video sensors (WVSs), including the <b>image</b> <b>sensor</b> subsystem {{into the system}} analysis. By assigning a power-rate-distortion (P-R-D) characteristic for the <b>image</b> <b>sensor,</b> we build a comprehensive P-R-D framework for WVS optimization. Within {{the scope of the}} developed framework, we solve {{the problem of how to}} allocate power among the <b>image</b> <b>sensor,</b> compression, and transmission modules of a WVS, to achieve the optimal reconstructed video quality under power and rate constraints. To demonstrate the optimization method, we further establish a P-R-D model for an <b>image</b> <b>sensor</b> based on pixel level sigma-delta (∑∆) <b>image</b> <b>sensor</b> design. A P-R-D performance analysis for a WVS verifies that including the <b>image</b> <b>sensor</b> in the system optimization procedure can improve the overall video quality and prolong the life-time of the wireless video network. I...|$|R
30|$|The VD (or VSYNC) and HD (or HSYNC) pins {{indicate}} {{the end of}} frame and end of row, respectively. Pixel data bytes are available for sampling at the DOUT(0 [*]:[*] 7) bus at the positive edge of the DCLK signal. The EXTCLK is the clock input for the <b>image</b> <b>sensor.</b> The frequency of DCLK is half or quarter of the frequency of EXTCLK depending on {{the configuration of the}} <b>image</b> <b>sensor.</b> The initialization and configuration of the <b>image</b> <b>sensor</b> is done by the 2 -wire (SCL and SDA) I 2 C protocol. In the context of <b>image</b> <b>sensor,</b> it is often called as Serial Camera Control Bus (SCCB) interface [32]. The frame size, colour, sleep mode, and wake up mode can be controlled by sending I 2 C commands to the <b>image</b> <b>sensor.</b> The RESET is an active low reset signal for the <b>image</b> <b>sensor.</b> Some <b>image</b> <b>sensors</b> have a pin (PWDN) to control the active-sleep mode. Some HD <b>image</b> <b>sensors</b> may contain additional control pins (as shown as dotted line in Figure 2), which are used in special modes; however, these extra pins may be tied to VDD or GND or left unconnected in normal operation.|$|R
40|$|This thesis focuses {{at first}} the basics of the field {{integrated}} <b>image</b> <b>sensor</b> systems in CMOS technology. The available photosensing elements are characterized and modelled. A novel photosensing element, the so-called Photo-MOSFET is introduced and characterized. A further part of the thesis deals with system theoretical aspects of imaging focussing linear imaging. The final part of the thesis is build out of three application examples of integrated CMOS <b>image</b> <b>sensor</b> systems: (I.) A highly parallel programmable <b>image</b> <b>sensor</b> system for different applications; (II.) an <b>image</b> <b>sensor</b> system with two photosensing arrays and digital correlation processor; and (III.) an <b>image</b> <b>sensor</b> system for velocity measurement...|$|R
50|$|Sony {{produces}} {{a wide range}} of semiconductors and electronic components including <b>image</b> <b>sensors</b> (Exmor), <b>image</b> processor (BIONZ), laser diodes, system LSIs, mixed-signal LSIs, OLED panels, etc. The company has a strong presence in the <b>image</b> <b>sensor</b> market. Sony-manufactured CMOS <b>image</b> <b>sensors</b> are widely used in digital cameras, tablet computers and smartphones.|$|R
40|$|NOVELTY - The <b>image</b> <b>sensor</b> element has {{a circuit}} part with a wiring part (400) occupying {{respective}} {{parts of the}} surface of the element. The <b>image</b> <b>sensor</b> element has a light sensitive surface which covers the whole width of a section of the element. The length-breadth ratio is 2 : 1. The light sensitive area may be octagonal and comprise a photodiode, phototransistor or photo resistor. DETAILED DESCRIPTION - DETAILED DESCRIPTION - An arrangement of <b>image</b> <b>sensor</b> elements, {{and the use of the}} <b>image</b> <b>sensor</b> in a high speed camera are also claimed. USE - For high-speed camera. ADVANTAGE - The <b>image</b> <b>sensor</b> is cheaper and faster, without having reduced image sharpness or resolution...|$|R
40|$|Abstract—A CMOS <b>image</b> <b>sensor</b> for time-resolved {{fluorescence}} lifetime imaging with subnanosecond time resolution is presented. In order {{to analyze the}} {{fluorescence lifetime}}, the proposed CMOS <b>image</b> <b>sensor</b> has two charge transfer stages using a pinned pho-todiode structure in which the first charge transfer stage is for the time-resolved sifting of fluorescence in all the pixels simulta-neously and the second charge transfer stage is for reading the signals in each pixel sequentially with correlated double sampling operation. A 0. 18 -μm CMOS <b>image</b> <b>sensor</b> technology with a pinned photodiode process option {{is used for the}} implementation of a 256 × 256 CMOS <b>image</b> <b>sensor.</b> The decaying <b>images</b> and lifetimes of fura- 2 solutions having different concentrations are successfully measured with a 250 -ps time step using the CMOS <b>image</b> <b>sensor</b> and ultraviolet laser diode as a light source. Index Terms—CMOS <b>image</b> <b>sensor,</b> fluorescence lifetime imag-ing, time-resolved image, two charge transfer stages. I...|$|R
40|$|We have {{proposed}} a new <b>image</b> <b>sensor</b> for optical wire-less LAN systems. This <b>image</b> <b>sensor</b> has not only a conventional <b>image</b> <b>sensor</b> mode for detecting the posi-tion of communication nodes but also a high-speed read-out mode for concurrent data acquisition from multiple nodes. The feature of pixel structure of the proposed <b>image</b> <b>sensor</b> is a hybrid use of an active pixel sensor and a high-speed photocurrent amplifier without storing. We have designed and fabricated the test pixel circuits by use of 0. 8 µm BiCMOS process, and their fundamental operations were verified. 1...|$|R
