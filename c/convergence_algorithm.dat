84|3343|Public
50|$|The Brooks-Iyengar hybrid {{algorithm}} for {{distributed control}} {{in the presence of}} noisy data combines Byzantine agreement with sensor fusion. It bridges the gap between sensor fusion and Byzantine fault tolerance. This seminal algorithm unified these disparate fields for the first time. Essentially, it combines Dolev’s algorithm for approximate agreement with Mahaney and Schneider’s fast <b>convergence</b> <b>algorithm</b> (FCA). The algorithm assumes N processing elements (PEs), t of which are faulty and can behave maliciously. It takes as input either real values with inherent inaccuracy or noise (which can be unknown), or a real value with apriori defined uncertainty, or an interval. The output of the algorithm is a real value with an explicitly specified accuracy. The algorithm runs in O(NlogN) where N is the number of PEs: see Big O notation. It is possible to modify this algorithm to correspond to Crusader’s <b>Convergence</b> <b>Algorithm</b> (CCA), however, the bandwidth requirement will also increase. The algorithm has applications in distributed control, software reliability, High-performance computing, etc.|$|E
5000|$|After {{acquiring}} a B.S. from Michigan Technological University, {{he went into}} the Army Corps of Engineers, and from there to the Philippines to help repair damages during World War II. When he returned after the war, he married Alice McCullough and returned to Michigan Technological University, where he taught mathematics. After, he moved to Cincinnati, Ohio, and worked for General Electric's engines division, where he developed a <b>convergence</b> <b>algorithm</b> and wrote a program to perform performance cycle calculations for GE's first aircraft jet engines. He also went to the University of Cincinnati, where in 1951 he acquired a M.S. in mathematics and, in 1959, acquired his Ph.D. in Mathematics. In July of that year he published the shell sort algorithm and [...] "The Share 709 System: A Cooperative Effort". In 1958, he and A. Spitzbart had published [...] "A Chebycheff Fitting Criterion".|$|E
30|$|In this paper, we {{introduce}} a weak <b>convergence</b> <b>algorithm</b> {{and a strong}} <b>convergence</b> <b>algorithm</b> for the split common solution problem when the nonlinear operator T is a quasi-nonexpansive mapping. Some strong and weak convergence theorems are established. We also give some examples to illustrate our results.|$|E
30|$|In [1], {{the author}} {{established}} weak <b>convergence</b> <b>algorithms</b> and strong <b>convergence</b> <b>algorithms</b> for SEP (see [1] for more details).|$|R
30|$|In this section, we {{introduce}} two strong <b>convergence</b> <b>algorithms</b> for (HSP); see Theorem  4.1 and Theorem 4.2.|$|R
30|$|Strong <b>convergence</b> <b>algorithms</b> for {{the split}} common {{solution}} problem for Lipschitzian accretive mappings and nonexpansive mappings (see Corollary  4.1 below).|$|R
30|$|The {{paper is}} {{organized}} as follows. The next section presents some preliminary results. A weak <b>convergence</b> <b>algorithm</b> and its special case {{are presented in}} Section  3. In the last section, we combine the method presented in Section  3 with the hybrid projection method for obtaining a strong <b>convergence</b> <b>algorithm</b> for SEPNM.|$|E
30|$|Next, we {{introduce}} a strong <b>convergence</b> <b>algorithm</b> for the split common solution problem.|$|E
40|$|The gateway {{technique}} {{is a method}} for switching segments of code {{into and out of}} the instruction stream. When added to the straight-line code generated by a compiled simulator, gateways can be used to enhance the performance of the generated code by switching only those segments of code that actually need to be executed into the instruction stream. The <b>convergence</b> <b>algorithm</b> is an oblivious compiled code algorithm that can be used with many different types of circuits, including cyclic asynchronous circuits. In its oblivious form, the <b>convergence</b> <b>algorithm</b> provides only modest gains in performance over interpreted event-driven simulation, but with the addition of gateways, the performance of the algorithm increases significantly. Experimental data shows that with gateways, the <b>convergence</b> <b>algorithm</b> runs in about 1 / 5 th the time required for an interpreted event-driven simulation. Additional work has been done to reduce the amount of code generated by the <b>convergence</b> <b>algorithm,</b> and to enhance the locality of the code to improve its performance on machines with caches...|$|E
30|$|Strong <b>convergence</b> <b>algorithms</b> for {{the split}} common {{solution}} problem for Lipschitzian accretive mappings and demicontractive nonexpansive mappings (see Theorem  4.1 below).|$|R
30|$|Having {{proved the}} <b>convergence</b> of <b>Algorithm</b> 1, we proceed {{to discuss the}} <b>convergence</b> of <b>Algorithm</b> 2, devoted to the {{reconstruction}} of the i-th decomposition layer.|$|R
3000|$|Remark 2.1 In Definition  2.1, the {{particular}} case of demiclosedness at zero is frequently {{used in some}} iterative <b>convergence</b> <b>algorithms,</b> which is {{the particular}} case when [...]...|$|R
30|$|In this paper, {{we first}} propose a weak <b>convergence</b> <b>algorithm</b> for solving SEPNM {{by using a}} {{combination}} of the extragradient method with Armijo linesearch type rule for an equilibrium problem [29] (see also [30 – 32] for more detail on extragradient algorithms) and the Mann method [33] (see also [34, 35]) for a fixed point problem. We then combine this algorithm with hybrid cutting technique [36] (see also [37]) to get a strong <b>convergence</b> <b>algorithm</b> for SEPNM.|$|E
30|$|In this paper, {{we first}} propose a weak <b>convergence</b> <b>algorithm,</b> called the linesearch algorithm, for solving a split {{equilibrium}} problem and nonexpansive mapping (SEPNM) in real Hilbert spaces, {{in which the}} first bifunction is pseudomonotone with respect to its solution set, the second bifunction is monotone, and fixed point mappings are nonexpansive. In this algorithm, we combine the extragradient method incorporated with the Armijo linesearch rule for solving equilibrium problems and the Mann method for finding a fixed point of an nonexpansive mapping. We then combine the proposed algorithm with hybrid cutting technique to get a strong <b>convergence</b> <b>algorithm</b> for SEPNM. Special cases of these algorithms are also given.|$|E
3000|$|Algorithm 2.1, the <b>convergence</b> <b>algorithm</b> {{for finding}} a common {{element of the}} set of common fixed points of p strict pseudocontractions and the set of {{solutions}} of equilibrium problems for pseudomonotone bifunctions is presented as follows: [...]...|$|E
30|$|Next, {{we discuss}} the global <b>convergence</b> of <b>Algorithm</b> 1 and 2. Note that Algorithm 2 is similar to Algorithm 1, we only discuss the <b>convergence</b> of <b>Algorithm</b> 1.|$|R
30|$|We give strong <b>convergence</b> <b>algorithms</b> for {{the split}} common fixed point problem of quasi-nonexpansive mappings. Our results improve and generalize some {{well-known}} results in [3, 11] and so on.|$|R
30|$|Some strong <b>convergence</b> <b>algorithms</b> are {{introduced}} to solve the split common fixed point problem for quasi-nonexpansive mappings. These results develop the related ones for fixed point iterative methods in the literature.|$|R
30|$|Although Theorem  3.1 gives {{a strong}} <b>convergence</b> <b>algorithm</b> for two {{countable}} families of quasi-nonexpansive mappings, {{the condition that}} each mapping must be demiclosed at θ is very strong. In addition, we guess the speed of convergence is not too fast for the algorithm (3.3). Therefore, the algorithm (3.3) should be improved further in the future.|$|E
40|$|This paper {{presents}} an efficient hardware algorithm for variable-precision division. The algorithm {{is based on}} a well-known <b>convergence</b> <b>algorithm,</b> however, modifications are made to allow it to efficiently handle variable-precision operands. The proposed algorithm reduces the number of fixed-precision operation by only computing significant words in intermediate results. Compared to previous variable-precision division algorithms, this algorithm requires significantly fewer fixed-point arithmetic operations...|$|E
40|$|The article {{covers the}} use of perseptron, Hopfild {{artificial}} neural network and semantic network for classification of text information. Network training algorithms are studied. An algorithm of inverse mistake spreading for perceptron network and <b>convergence</b> <b>algorithm</b> for Hopfild network are implemented. On {{the basis of the}} offered models and algorithms automatic text classification software is developed and its operation results are evaluated...|$|E
30|$|We {{have proved}} a {{generalized}} Presic-Hardy-Rogers contraction principle and Ciric-Presic type contraction principle for two mappings in a b-metric space. As an application, we derive some convergence results {{for a class}} of nonlinear matrix equations. Numerical experiments are also presented to illustrate the <b>convergence</b> <b>algorithms.</b>|$|R
30|$|Now, we {{state the}} <b>convergence</b> of <b>Algorithm</b> 3.1.|$|R
30|$|Let us {{discuss the}} global <b>convergence</b> of <b>Algorithm</b> 2.1.|$|R
40|$|The {{proposed}} <b>convergence</b> <b>algorithm</b> {{is aimed}} at enhancing the performance of distributed applications running on sizeable networks exemplified by the Internet. The aim is achieved by quickly and accurately predicting the mean message response time of a communication channel with only end-to-end consideration. With the predicted mean the correct window size of the desired coverage of time-out tolerance for message transmission and response can be computed. The correct window size contributes to reduce excessive message retransmissions caused by time-outs. The proposed algorithm is particularly useful in helping time-critical distributed applications deliver their correct functions because prolonged delays in message response in these applications can lead to fatal errors. The discussion in this paper is focused mainly {{on the development of}} the <b>convergence</b> <b>algorithm.</b> Results from experiments have concluded that the proposed algorithm is indeed an effective solution for the stated aim. The simplicity of the algorithm is an advantage because it makes its implementation in real systems easy. Department of Computin...|$|E
40|$|Abstract — This paper {{proposes a}} fast <b>convergence</b> <b>algorithm</b> for L 2 -sensitivity {{minimization}} problem of two-dimensional (2 -D) separable-denominator state-space digital filters subject to L 2 -scaling constraints. The proposed algorithm reduces a con-strained optimization problem to an unconstrained optimization problem by appropriate variable transformation, and minimizes the L 2 -sensitivity by iterative calculation called successive substi-tution method. Our novel algorithm can achieve the L 2 -sensitivity minimization with quite fast convergence behavior. I...|$|E
40|$|This paper {{presents}} an e cient hardware algorithm for variable-precision division. The algorithm {{is based on}} a well-known <b>convergence</b> <b>algorithm,</b> however, modi cations are made to allow it to e ciently handle variable-precision operands. The proposed al-gorithm reduces the number of xed-precision operation by only computing signi cant words in intermediate results. Compared to previous variable-precision division algo-rithms, this algorithm requires signi cantly fewer xed-point arithmetic operations. Key words: Computer arithmetic, variable-precision, division, error analysis. ...|$|E
30|$|Next we {{prove the}} strong <b>convergence</b> of <b>Algorithm</b> 3.1.|$|R
30|$|The next theorem {{shows the}} <b>convergence</b> of <b>Algorithm</b> 3.4.|$|R
30|$|Now we {{establish}} the weak <b>convergence</b> of <b>Algorithm</b> 3.1.|$|R
40|$|A {{review of}} current {{multiple}} objective planning techniques is presented. A critique of certain classes {{of these techniques}} is offered, {{especially in terms of}} the degree to which they facilitate certain information needs of the planning process. Various tools in operations research are used to constructed a new multiple objective planning methodology, called the 2 ̆ 2 Vector Optimization Decision <b>Convergence</b> <b>Algorithm</b> 2 ̆ 2 (VODCA). An application of the methodology pertaining to water resources development in Utah is documented...|$|E
40|$|AbstractOur {{approach}} {{combines a}} method of an inexact steepest descent with the method of contractor directions to obtain a backtracking linear-time <b>convergence</b> <b>algorithm</b> for solving systems of nonlinear equations. Using the fundamental inequality of contractor directions, we prove the convergence and give an error estimate for our method. The algorithm is well-suited for parallel computation. In fact, for systems with m equations and n unknowns, each iteration may be computed in parallel time O(log m + log n) with O(mn) processors...|$|E
40|$|Schneider generalizes {{a number}} of {{protocols}} for Byzantine fault tolerant clock synchronization and presents a uniform proof for their correctness. The authors present a machine checked proof of this schematic protocol that revises {{some of the details}} in Schneider's original analysis. The verification was carried out with the EHDM system developed at the SRI Computer Science Laboratory. The mechanically checked proofs include the verification that the egocentric mean function used in Lamport and Melliar-Smith's Interactive <b>Convergence</b> <b>Algorithm</b> satisfies the requirements of Schneider's protocol...|$|E
30|$|The <b>convergence</b> of <b>Algorithm</b> 2 is {{guaranteed}} by Theorem 1, since {{it can be}} expressed as an instance of problem (13). G is a full column rank matrix, and functions f, g are closed, proper, convex. These meet the conditions in Theorem 1, and hence the <b>convergence</b> of <b>Algorithm</b> 2 {{is guaranteed}}.|$|R
30|$|In this article, {{we study}} the {{convergence}} of iterative sequences of Prešić type involving new general classes of operators {{in the setting of}} metric spaces. As application, we derive some convergence results for a class of nonlinear matrix difference equations. Numerical experiments are also presented to illustrate the <b>convergence</b> <b>algorithms.</b>|$|R
30|$|Now, {{we discuss}} the local {{quadratic}} <b>convergence</b> of <b>Algorithm</b> 3.1. For this purpose, we need the strong semismoothness of transformation H which {{can be obtained by}} Proposition 2.3 (ii). In a similar way as the one in [17, Theorem 3.2], we can obtain the local quadratic <b>convergence</b> of <b>Algorithm</b> 3.1.|$|R
