36|1092|Public
5|$|In some countries, the {{nameplate}} {{capacity of a}} photovoltaic power stations is rated in megawatt-peak (MWp), which refers to the solar array's DC power output. However, Canada, Japan, Spain and {{some parts of the}} United States often specify using the converted lower nominal power output in MWAC; a measure directly comparable to other forms of power generation. A third and less <b>common</b> <b>rating</b> is the mega volt-amperes (MVA). Most solar parks are developed at a scale of at least 1MWp. As at the start of 2017, the world's largest operating photovoltaic power station has a capacity of over 800 megawatts and projects up to 1 gigawatt are planned. As at the end of 2016, about 4,300 projects with a combined capacity of 96GWAC were solar farms larger than 4MWAC.|$|E
50|$|What {{was needed}} was a <b>common</b> <b>rating</b> or an agreed International rule, which would enable yachts {{from one country to}} race {{competitively}} in a different country.|$|E
50|$|Accordingly, {{the basic}} {{objective}} was to bring together a number of independent regional agencies, {{with a view to}} agreeing <b>common</b> <b>rating</b> standards, methodologies & symbols, and operating under a single “brand”. The ultimate end goal is the establishment of a single international ratings group covering all the emerging markets.|$|E
3000|$|Figure 2 {{shows the}} power control {{for a single}} {{tactical}} radio network. An inner loop determines the power allocation maximizing the <b>common</b> <b>rate</b> subject to a total power constraint. Then, an outer loop minimizes the power such that a <b>common</b> <b>rate</b> constraint [...]...|$|R
40|$|In this paper, we {{investigate}} {{the impact of}} channel estimation error on the achievable <b>common</b> <b>rate</b> and error performance of amplify and forward (AF) multi-way relay networks (MWRNs). Assuming lattice codes with large dimensions, we provide the analytical expressions for the end-to-end SNR at the users and obtain upper bounds on the achievable <b>common</b> <b>rate</b> for an AF MWRN. Moreover, considering binary phase shift keying (BPSK) modulation as the simplest case of lattice codes, we obtain the average bit error rate (BER) for a user in an AF MWRN. The analysis shows that the average BER is a linearly increasing function and the achievable <b>common</b> <b>rate</b> is a linearly decreasing function of the channel estimation error. On the other hand, the average BER decreases and the achievable <b>common</b> <b>rate</b> increases with increasing correlation between the true and the estimated channel. Also, we observe that the AFprotocol is robust against increasing number of users in terms of error performance. We show that when the decoding user has better channel conditions compared to other users, AF relaying gives a better error performance and <b>common</b> <b>rate.</b> Finally, simulation results are provided to verify the validity of our analysis...|$|R
30|$|Algorithm 1 : Minimization of {{the power}} subject to a <b>common</b> <b>rate</b> constraint.|$|R
5000|$|The Elo {{system was}} invented by Arpad Elo and is the most <b>common</b> <b>rating</b> system. It is used by FIDE and other organizations. Elo once stated {{that the process of}} rating players was in any case rather approximate; he {{compared}} it to [...] "the measurement of the position of a cork bobbing {{up and down on the}} surface of agitated water with a yard stick tied to a rope and which is swaying in the wind".|$|E
5000|$|Fireproof gun safes have an UL classification, and {{depending}} on the build of the gun safe, the inside must not get warmer than a certain temperature during {{a certain period of}} time. A <b>common</b> <b>rating</b> for gun safes is [...] "350-1 hour" [...] or [...] "350-2 hour", which means that when the safe is in a fire, the inside will not get warmer than 350 degrees Fahrenheit for 1 or 2 hours. [...] It has been noted that fireproof safes may be insecure against unauthorized entry.|$|E
5000|$|Self-assessment - Typically, the {{behavioral}} indicators for the competencies and proficiency levels needed within the target role / job {{are used as}} the standard for assessing {{the performance of the}} employee using a <b>common</b> <b>rating</b> scale (e.g., five-point scales from Never to Always) for assessing each indicator. The results are compiled and a report is provided that includes the results for all competencies, highlighting both employee strengths as well as competencies requiring improvement. This information can then be used to support the development of an individual learning plan (see below).|$|E
30|$|For {{more details}} on <b>common</b> <b>rate</b> {{definition}} and its applications in MWRCs, the reader is referred to[4, 10]. Note that for a general Gaussian MWRC, the <b>common</b> <b>rate</b> capacity {{is yet to be}} known. Thus, in the following, we use the capacity upper bound for our capacity gap analysis instead of the capacity itself. For this purpose, we borrow the following lemma from[4].|$|R
40|$|Abstract. Recommender systems play an {{important}} role in supporting people getting items they like. One type of recommender systems is userbased collaborative filtering. The fundamental assumption of user-based collaborative filtering is that people who share similar preferences for common items behave similar in the future. The similarity of user preferences is computed globally on <b>common</b> <b>rated</b> items such that partial preference similarities might be missed. Consequently, valuable ratings of partially similar users are ignored. Furthermore, two users may even have similar preferences but the set of <b>common</b> <b>rated</b> items is too small to infer preference similarity. We propose first, an approach that computes user preference similarities based on learned user preference models and second, we propose a method to compute partial user preference similarities based on partial user model similarities. For users with few <b>common</b> <b>rated</b> items, we show that user similarity based on preferences significantly outperforms user similarity based on <b>common</b> <b>rated</b> items. ...|$|R
25|$|The most <b>common</b> <b>rate</b> was 10Hz, {{while the}} 16Hz and 20Hz modes were rather rare.|$|R
50|$|The {{plethora of}} ranking {{systems and the}} lack of a shared metric has created the {{equivalent}} of a “Tower of Babel” in international tennis. National federations, tournaments, coaches, teams, colleges, and individual players all speak different languages that do not readily translate into one another. The lack of a <b>common</b> <b>rating</b> system has created a host of problems on many levels in the sport. In response to this, the International Tennis Federation and many of the national governing bodies for tennis, including the United States Tennis Association (USTA), have become interested in developing a standard rating metric that, like a golf handicap, could function globally. While many governing bodies have tried out various rating systems, no one system has yet gained broad international acceptance.|$|E
50|$|In some countries, the {{nameplate}} {{capacity of a}} photovoltaic power stations is rated in megawatt-peak (MWp), which refers to the solar array's DC power output. However, Canada, Japan, Spain and {{some parts of the}} United States often specify using the converted lower nominal power output in MWAC; a measure directly comparable to other forms of power generation. A third and less <b>common</b> <b>rating</b> is the mega volt-amperes (MVA). Most solar parks are developed at a scale of at least 1 MWp. As at the start of 2017, the world's largest operating photovoltaic power station has a capacity of over 800 megawatts and projects up to 1 gigawatt are planned. As at the end of 2016, about 4,300 projects with a combined capacity of 96 GWAC were solar farms larger than 4 MWAC.|$|E
5000|$|Shaft {{horsepower}} (shp) is {{the power}} delivered to a propeller shaft, a turbine shaft — or to an output shaft of an automotive transmission. This shaft horsepower can be measured with a torque (torsion) meter, or estimated from the horsepower at the crankshaft and a standard figure for the losses in the transmission (typical figures are around 10%). While shaft horsepower is a <b>common</b> <b>rating</b> for jet engines, industrial turbines, and some marine applications, it is not commonly used in the internal-combustion-engine automobile industry {{because of the need}} to estimate losses in the transmission; instead, this industry in the USA typically uses SAE certified net power, which is measured at the engine's crankshaft, and so does not account for losses in the transmission (see [...] "Engine power test standards", below).|$|E
40|$|We {{address the}} <b>common</b> <b>rate</b> {{maximization}} problem in two-layer cellular networks where high-power and low-power base stations are colocated {{in the same}} geographical area. Interference becomes a serious problem when two or more layers are considered in the same network. For this purpose, power control in the downlink needs {{to be used to}} limit the interference and to fully exploit the benefits of additional layer deployments. We present an analytical framework to the <b>common</b> <b>rate</b> maximization problem both with and without maximum power constraints and propose a heuristic algorithm. We present simulation results for the proposed approaches in a two-layer network setup and observe a significant <b>common</b> <b>rate</b> increase compared to single-layer wireless networks. Comment: 6 pages, 4 figure...|$|R
30|$|Algorithm 2 : Distributed power {{allocation}} for minimization of {{the power}} subject to a <b>common</b> <b>rate</b> constraint.|$|R
5000|$|The most <b>common</b> <b>rate</b> was 10 Hz, {{while the}} 16 Hz and 20 Hz modes were rather rare.|$|R
5000|$|The {{previous}} classification regime {{had been}} introduced in the 1967 Public Service Employment Act but began {{to be seen as}} overly complex by the early 1970s. The changes proposed by the PS2000 were seen as less ambitious than needed but were considered compromises in order to appeal to unions and make them easier to implement. Eliminating occupational categories, large reductions of occupational groups, the introduction of a <b>common</b> <b>rating</b> strategy as well as putting a 3-page limit on job descriptions were all recommendations that hoped to streamline public service employment and do away with an occupational hierarchy that had taken hold. Although the recommendation for job description page limits was never fully adopted, the other recommendations were seen as improvements by managers in pruning the public service organizational structure and allowing for more mobility for career development.|$|E
5000|$|One of {{the most}} <b>common</b> <b>rating</b> scales is the Likert scale. A {{statement}} is used and the participant decides how strongly they {{agree or disagree with}} the statements. For example the participant decides whether Mozzarella cheese is great with the options of [...] "strongly agree", [...] "agree", [...] "undecided", [...] "disagree", and [...] "strongly disagree". One strength of Likert scales is that they can give an idea about how strongly a participant feels about something. This therefore gives more detail than a simple yes no answer. Another strength is that the data are quantitative, which are easy to analyse statistically. However, there is a tendency with Likert scales for people to respond towards the middle of the scale, perhaps to make them look less extreme. As with any questionnaire, participants may provide the answers that they feel they should. Moreover, because the data is quantitative, it does not provide in-depth replies.|$|E
5000|$|Many gun safe {{manufacturers}} {{state that}} their gun safe is [...] "DOJ approved". The state of California Department of Justice (DOJ) has required that any gun safe sold in California should {{be approved by}} the Regulatory Gun Safe Standards. This DOJ standard has now become a <b>common</b> <b>rating</b> for the classification of gun safes. However, in 2012, a report appeared in Forbes written by the investigative attorney and physical security specialist Marc Weber Tobias, presenting the results of his investigation into the quality of the security provided by eleven different models among three leading brands of gun safes sold in the U.S. through many retail outlets. Eight models from one of the brands are said to conform to the DOJ standard. Tobias reported that he and his colleagues found that all eleven models could be opened with one of a variety of simple implements and techniques, including bouncing and rapping, or insertion of paperclips, wires, drinking straws, screwdrivers, or brass strips that can be purchased from a hardware store. Four of the models were unlocked by a three-year old child. (It was a fatality resulting from such an occurrence that led to the investigation.) When Tobias reported their findings to the manufacturers and retailers of the [...] "safes", no useful dialog or corrective action resulted. Tobias concluded that the DOJ [...] "Standards are woefully inadequate and do not address any of the issues that we found in any of the gun safes that we tested. If the Standards do not cover a method of entry, then they are meaningless." ...|$|E
30|$|In {{the first}} part of the paper (Section 2), we extend the water-filling {{strategy}} [11] to multiple receivers considering parallel multicast channels with perfect channel state information (CSI) at the transmit side. In this case, the extended water-filling strategy maximizes the <b>common</b> <b>rate</b> subject to a power constraint (inner loop) or minimizes the power subject to a <b>common</b> <b>rate</b> constraint (outer loop). Mathematical derivations show that the optimal power allocation can be found in closed form under multiple hypothesis testing [14, 17, 18].|$|R
60|$|The portion, too, of {{the gross}} profit, which forms the {{remuneration}} for the labor and skill of the dealer or producer, is very different in different employments. This is the explanation always given of the extraordinary rate of apothecaries’ profit. There are cases, again, in which {{a considerable amount of}} labor and skill is required to conduct a business necessarily of limited extent. In such cases a higher than <b>common</b> <b>rate</b> of profit is necessary to yield only the <b>common</b> <b>rate</b> of remuneration.|$|R
30|$|The {{achievable}} rate of lattice-based relaying {{was first}} studied in[8] for TWRC. Later, the following lemma was proposed[10] for the achievable <b>common</b> <b>rate</b> of FDF.|$|R
40|$|Abstract. Recommender systems always aim {{to provide}} {{recommendations}} for a user based on historical ratings collected {{from a single}} domain (e. g., movies or books) only, which may suffer from the data sparsity problem. Recently, several recommendation models have been proposed to transfer knowledge by pooling together the rating data from multiple domains to alleviate the sparsity problem, which typically assume that multiple domains share a latent <b>common</b> <b>rating</b> pattern based on the user-item co-clustering. In practice, however, the related domains do not necessarily share such a <b>common</b> <b>rating</b> pattern, and diversity among the related domains might outweigh the advantages of such common pattern, which may result in performance degradations. In this paper, we propose a novel cluster-level based latent factor model to enhance the cross-domain recommendation, which can not only learn the <b>common</b> <b>rating</b> pattern shared across domains with the flexibility in controlling the optimal level of sharing, but also learn the domain-specific rating patterns of users in each domain that involve the discriminative information propitious to performance improvement. To this end, the proposed model is formulated as an optimization problem based on joint nonnegative matrix tri-factorization and an efficient alternating minimization algorithm is developed with convergence guarantee. Extensive experiments on several real world datasets suggest that our proposed model outperforms the state-of-the-art methods for the cross-domain recommendation task. ...|$|E
40|$|Includes bibliographical {{references}} (pages 46 - 47) The mixed standard scale {{developed by}} Blanz & Ghiselli (1972) {{was compared to}} two graphic rating scale formats {{to determine if the}} mixed standard scale reduced the <b>common</b> <b>rating</b> errors of halo, leniency and central tendency, and improved the interrater reliability. Thirty-six Ss were randomly assigned to three equal groups with each group using a different rating scale. The three scales used were the mixed standard scale, a graphic scale with descriptive cue points identical to those used in the mixed standard scale, and a graphic scale with non-descriptive cue points. The Ss viewed and rated three video-taped speeches using one of the scales. The results indicate no clear superiority of any one scale format in terms of halo, leniency, central tendency or reliability. There were, however, trends towards less halo and more central tendency when using the mixed standard scale. The differences between scales were very much dependent on the particular speech being rated. It was concluded that the mixed standard scale did not reduce the <b>common</b> <b>rating</b> errors...|$|E
40|$|Cross-domain {{recommendation}} {{has been}} proposed to transfer user behavior pattern by pooling together the rating data from multiple domains to alleviate the spar-sity problem appearing in single rating domains. How-ever, previous models only assume that multiple do-mains share a latent <b>common</b> <b>rating</b> pattern based on the user-item co-clustering. To capture diversities among different domains, we propose a novel Probabilistic Cluster-level Latent Factor (PCLF) model to improve the cross-domain recommendation performance. Ex-periments on several real world datasets demonstrate that our proposed model outperforms the state-of-the-art methods for the cross-domain recommendation task. ...|$|E
3000|$|... {{bit with}} the <b>common</b> <b>rate</b> {{capacity}} of symmetric Gaussian MWRCs. For AF and DF, we first {{show that they}} may have a larger than [...]...|$|R
5000|$|Defect {{raises the}} price above the <b>common</b> <b>rate</b> 1 tenth ............... 3 tenths 2 tenths ............... 8 tenths 3 tenths ............... 16 tenths 4 tenths ............... 28 tenths 5 tenths ............... 45 tenths ...|$|R
3000|$|... {{bit of the}} <b>common</b> <b>rate</b> {{capacity}} where K is {{the number}} of users. Also, for TWRCs with FDF, it is shown that the capacity gap is less than [...]...|$|R
40|$|Abstract — Accuracy of {{predicting}} the user preference score {{is the most}} important element of collaborative filtering. This paper proposes novel similarity measures using difference score entropy of <b>common</b> <b>rating</b> items between two users. The proposed similarity measures can apply various weights according to the score difference, to evaluate the similarity. We implemented a recommender system using the proposed similarity measures and, experimented on performance with memory-based collaborative filtering. Based on the experimental results, the proposed similarity measures significantly improve the prediction accuracy with respect to existing similarity measures, and we confirmed that the proposed measure is robust to sparse data sets. Index Terms—similarity, collaborative filtering, entropy I...|$|E
40|$|We {{examine the}} {{information}} value contained in insurer rating changes. Using a contemporary event study approach, we document an asymmetric reaction of stock prices to rating changes: downgrades cut share prices by approximately 7 percent but upgrades have little significant effect. This result varies across agencies as share prices react more strongly to A. M. Best and Standard & Poor's downgrades than to Moody's. We observe a similar asymmetric reaction to rating changes {{subject to a}} <b>common</b> <b>rating</b> benchmark. Finally, we find that prices fall most dramatically when a rating downgrade from one rating agency follows a downgrade from another agency. Copyright (c) The Journal of Risk and Insurance, 2010. ...|$|E
30|$|Maternal {{as well as}} filial {{interaction}} {{behavior is}} assessed using a macro analytic rating system whereby various interactional characteristics are evaluated on five-point-rating scales with qualitatively specified graduations ([EKIE]; Sommer and Mann 2015). The assessment of maternal behavior covers emotional supportive interaction behavior (like sensitivity to distress and non-distress, positive regard for the child, emotionality) and stimulating interaction behavior, including a <b>common</b> <b>rating</b> for language and play stimulation {{in the first two}} waves and differentiating language and mathematical stimulation in wave 3 when children were 2  years of age (see Table  3). The mother’s intrusiveness, detachment, and negative regard of the child were also rated. The coding of the child’s behavior and emotions focuses on the child’s mood, activity level, social interest in the mother, and sustained attention to objects.|$|E
60|$|Elv. Do you {{consider}} the hazard I have run to see you here? if you do, methinks it should inform you, that I love not at a <b>common</b> <b>rate.</b>|$|R
3000|$|... where c is the <b>common</b> <b>rate</b> vector {{formed by}} {C_k^K,C_k'^K_g| k∈K, k'∈K_g, g∈G}. For a given weight vector, problem (28) {{can be solved}} by simply modifying the WMMSE {{approach}} discussed in Section 4.7.|$|R
50|$|Examples of such {{univariate}} distributions are:Normal distribution, Poisson distribution, Binomial distribution (with common success probability), Negative {{binomial distribution}} (with common success probability), Gamma distribution(with <b>common</b> <b>rate</b> parameter), Chi-squared distribution, Cauchy distribution, Hyper-exponential distribution.|$|R
