15|27|Public
2500|$|... where [...] is a polynomial-time <b>computable</b> <b>predicate.</b> The Karp–Lipton theorem {{states that}} this type of formula can be {{transformed}} in polynomial time into an equivalent formula in which the quantifiers appear in the opposite order; such a formula belongs to [...] Note that the subformula ...|$|E
2500|$|... where [...] is any polynomial-time <b>computable</b> <b>predicate.</b> The existential {{power of}} the first {{quantifier}} in this predicate {{can be used to}} guess a correct circuit for SAT, and the universal {{power of the}} second quantifier can be used to verify that the circuit is correct. Once this circuit is guessed and verified, the algorithm in class [...] can use it as a subroutine for solving other problems.|$|E
2500|$|To {{understand}} the Karp–Lipton proof in more detail, {{we consider the}} problem of testing whether a circuit c is a correct circuit for solving SAT instances of a given size, and show that this circuit testing problem belongs to [...] That is, there exists a polynomial time <b>computable</b> <b>predicate</b> V such that c is a correct circuit if and only if, for all polynomially-bounded z, V(c,z) is true.|$|E
40|$|We {{explore the}} {{computational}} power of networks of small resource-limited mobile agents. We define two new models of computation based on pairwise interactions of finite-state agents in populations of finite but unbounded size. With a fairness condition on interactions, we define {{the concept of}} stable computation of a function or predicate, and give protocols that stably compute functions in a class including Boolean combinations of threshold-k, parity, majority, and simple arithmetic. We prove that all stably <b>computable</b> <b>predicates</b> are in NL. With uniform random sampling of pairs to interact, we define the model of conjugating automata and show that any counter machine with O(1) counters of capacity O(n) can be simulated with high probability by a protocol in a population of size n. We prove that all <b>predicates</b> <b>computable</b> with high probability in this model are in P #RL...|$|R
40|$|This paper {{considers}} the relational {{versions of the}} surjective and multifunction weak pigeonhole principles for PV, # 1 and # 2 -formulas. We show that the relational surjective pigeonhole principle for # 2 formulas 2 implies a circuit block-recognition principle which in turn implies the surjective weak pigeonhole principle for # 1 formulas. We introduce a class of predicates corresponding to poly-log length iterates of polynomial-time <b>computable</b> <b>predicates</b> and show that over R 2, the multifunction pigeonhole principle for such predicates is equivalent to an "iterative" circuit block-recognition principle. A consequence {{of this is that}} if R 3 proves this circuit iteration principle then RSA is vulnerable to quasi-polynomial time attacks...|$|R
40|$|Abstract The {{computational}} {{power of}} networks of small resource-limited mobile agents is explored. Two new models of computation based on pairwise interactions of finite-state agents in populations of finite but unbounded size are defined. With a fairness condition on interactions, {{the concept of}} stable computation of a function or predicate is defined. Protocols are given that stably compute any predicate in the class definable by formulas of Presburger arithmetic, which includes Boolean combinations of threshold-k, majority, and equivalence modulo m. All stably <b>computable</b> <b>predicates</b> are shown to be in NL. Assuming uniform random sampling of interacting pairs yields the model of conjugating automata. Any counter machine with O(1) counters of capacity O(n) can be simulated with high probability by a conjugating automaton in a population of size n. All <b>predicates</b> <b>computable</b> with high probability in this model are shown to be in P; {{they can also be}} computed by a randomized logspace machine in exponential time. Several open problems and promising future directions are discussed...|$|R
5000|$|Given a Blum {{complexity}} measure [...] {{and a total}} computable function [...] {{with two}} parameters, then there exists a total <b>computable</b> <b>predicate</b> [...] (a boolean valued computable function) so that for every program [...] for , there exists a program [...] for [...] so that for almost all ...|$|E
5000|$|To {{understand}} the Karp-Lipton proof in more detail, {{we consider the}} problem of testing whether a circuit c is a correct circuit for solving SAT instances of a given size, and show that this circuit testing problem belongs to [...] That is, there exists a polynomial time <b>computable</b> <b>predicate</b> V such that c is a correct circuit if and only if, for all polynomially-bounded z, V(c,z) is true.|$|E
50|$|Matiyasevich's {{completion}} of the MRDP theorem settled Hilbert's tenth problem. Hilbert's tenth problem {{was to find a}} general algorithm which can decide whether a given Diophantine equation has a solution among the integers. While Hilbert's tenth problem is not a formal mathematical statement as such, the nearly universal acceptance of the (philosophical) identification of a decision algorithm with a total <b>computable</b> <b>predicate</b> allows us to use the MRDP theorem to conclude that the tenth problem is unsolvable.|$|E
40|$|Summary. The {{computational}} {{power of}} networks of small resource-limited mobile agents is explored. Two new models of computation based on pairwise interactions of finite-state agents in populations of finite but unbounded size are defined. With a fairness condition on interactions, {{the concept of}} stable computation of a function or predicate is defined. Protocols are given that stably compute any predicate in the class definable by formulas of Presburger arithmetic, which includes Boolean combinations of threshold-k, majority, and equivalence modulo m. All stably <b>computable</b> <b>predicates</b> are shown to be in NL. Assuming uniform random sampling of interacting pairs yields the model of conjugating automata. Any counter machine with O(1) counters of capacity O(n) can be simulated with high probability by a conjugating automaton in a population of size n. All <b>predicates</b> <b>computable</b> with high probability in this model are shown to be in P ∩RL. Several open problems and promising future directions are discussed...|$|R
40|$|Abstract. We {{consider}} a {{scenario in which}} anonymous, finite-state sensing devices are deployed in an ad-hoc communication network of arbitrary size and unknown topology, and explore what properties of the network graph can be stably computed by the devices. We show that they can detect whether the network has degree bounded by a constant d, and, if so, organize a computation that achieves asymptotically optimal linear memory use. We define a model of stabilizing inputs to such devices and show that a large class of predicates of the multiset of final input values are stably computable in any weakly-connected network. We also show that nondeterminism in the transition function does not increase the class of stably <b>computable</b> <b>predicates.</b> ...|$|R
40|$|Solid {{modelling}} and {{computational geometry}} {{are based on}} classical topology and geometry in which the basic predicates and operations, such as membership, subset inclusion, union and intersection, are not continuous and therefore not computable. But a sound computational framework for solids and geometry can only be built in a framework with <b>computable</b> <b>predicates</b> and operations. In practice, correctness of algorithms in computational geometry is usually proved using the unrealistic Real RAM machine model of computation, which allows comparison of real numbers, with the undesirable result that correct algorithms, when implemented, turn into unreliable programs. Here, we use a domaintheoretic approach to recursive analysis to develop {{the basis of an}} eective and realistic framework for solid modelling. This framework is equipped with a well-dened and realistic notion of computability which reects the observable properties of real solids. The basic predicates and operations o [...] ...|$|R
5000|$|The {{assumption}} of the Karp-Lipton theorem, that these circuits exist, is weaker. But {{it is still possible}} for an algorithm in the complexity class [...] to guess a correct circuit for SAT. The complexity class [...] describes problems of the formwhere [...] is any polynomial-time <b>computable</b> <b>predicate.</b> The existential power of the first quantifier in this predicate can be used to guess a correct circuit for SAT, and the universal power of the second quantifier can be used to verify that the circuit is correct. Once this circuit is guessed and verified, the algorithm in class [...] can use it as a subroutine for solving other problems.|$|E
5000|$|The Karp-Lipton theorem can be restated as {{a result}} about Boolean {{formulas}} with polynomially-bounded quantifiers. Problems in [...] are described by formulas of this type, with the syntaxwhere [...] is a polynomial-time <b>computable</b> <b>predicate.</b> The Karp-Lipton theorem states {{that this type of}} formula can be transformed in polynomial time into an equivalent formula in which the quantifiers appear in the opposite order; such a formula belongs to [...] Note that the subformulais an instance of SAT. That is, if c is a valid circuit for SAT, then this subformula is equivalent to the unquantified formula c(s(x)). Therefore, the full formula for [...] is equivalent (under the assumption that a valid circuit c exists) to the formulawhere V is the formula used to verify that c really is a valid circuit using self-reducibility, as described above. This equivalent formula has its quantifiers in the opposite order, as desired. Therefore, the Karp-Lipton assumption allows us to transpose the order of existential and universal quantifiers in formulas of this type, showing that [...] Repeating the transposition allows formulas with deeper nesting to be simplified to a form in which they have a single existential quantifier followed by a single universal quantifier, showing that ...|$|E
40|$|We {{propose a}} new {{technique}} for the high-level construction of type-safe web-oriented user interfaces. Our approach is useful to equip applications processing structured data with interfaces to manipulate these data in an efficient and maintainable way. The interfaces are web-based, i. e., the data can be manipulated with standard web browsers without any specific requirements on the client side. In order to support type-safe user interfaces, i. e., interfaces where users can only input type-correct data (types can be standard types of a programming language {{as well as any}} <b>computable</b> <b>predicate</b> on the data), we propose a set of type-oriented building blocks from which interfaces for more complex types can be easily constructed. This technique leads to a very concise and maintainable implementation of web-based user interfaces. ...|$|E
40|$|AbstractSolid {{modelling}} and {{computational geometry}} {{are based on}} classical topology and geometry in which the basic predicates and operations, such as membership, subset inclusion, union and intersection, are not continuous and therefore not computable. But a sound computational framework for solids and geometry can only be built in a framework with <b>computable</b> <b>predicates</b> and operations. In practice, correctness of algorithms in computational geometry is usually proved using the unrealistic Real RAM machine model of computation, which allows comparison of real numbers, with the undesirable result that correct algorithms, when implemented, turn into unreliable programs. Here, we use a domain-theoretic approach to recursive analysis to develop {{the basis of an}} effective and realistic framework for solid modelling. This framework is equipped with a well defined and realistic notion of computability which reflects the observable properties of real solids. The basic predicates and operations on solids are computable in this model which admits regular and non-regular sets and supports a design methodology for actual robust algorithms. Moreover, the model is able to capture the uncertainties of input data in actual CAD situations...|$|R
5000|$|... where [...] is a <b>predicate</b> <b>computable</b> in time [...] (which implicitly bounds {{the length}} of yi). Also equivalently, EH is the class of {{languages}} computable on an alternating Turing machine in time [...] for some c with constantly many alternations.|$|R
40|$|AbstractThis paper {{considers}} the relational {{versions of the}} surjective, partial surjective, and multifunction weak pigeonhole principles for PV, ∑ 1 b, ∏ 1 b, and B(∑ 1 b) formulas as well as relativizations of these formulas {{to higher levels of}} the bounded arithmetic hierarchy. We show that the partial surjective weak pigeonhole principle for ∏ 1 b formulas implies that for each k there is a string of length 22 nk which is hard to block-recognize by circuits of size nk. These principles in turn imply the partial surjective principle for ∑ 1 b formulas. We show that the surjective weak pigeonhole principle for B(∑ 1 b) formulas in S 21 implies our hard-string principle which in turn implies the surjective weak pigeonhole principle for ∑ 1 b formulas. We introduce a class of predicates corresponding to poly-log length iterates of polynomial time <b>computable</b> <b>predicates</b> and show that over S 21, the multifunction weak pigeonhole principle for such predicates is equivalent to an “iterative” circuit block-recognition principle. A consequence of this is that if S 21 proves this principle then RSA is vulnerable to polynomial time attacks...|$|R
40|$|Abstract. We {{consider}} {{a problem of}} inner constructivizability of admis-sible sets by means of elements of a bounded rank. For hereditary finite superstructures we find a precise estimates for the rank of inner construc-tivizability: it is equal to ω for superstructures over finite structures and less or equal to 2 otherwise. We introduce examples of hereditary fi-nite superstructures with ranks 0, 1, 2. It is shown that hereditary finite superstructure over field of real numbers has rank 1. Notations and terminology used below are standard and corresponds to [1, 2]. We denote the domains of a structure M and KPU-model A by M and A re-spectively. Further on, {{without loss of generality}} we will consider only structures and KPU-models with predicate signatures. Let M be a structure of <b>computable</b> <b>predicate</b> signature 〈Pn 00, [...] ., Pnkk, [...] . 〉, and let A be a KPU-model, i. e. a structure of signature containing symbols U 1,∈ 2, which is a model of the system of axioms KPU. Following [1], M is called Σ-definable (constructivizable) in A if there exists a computable sequence of Σ-formula...|$|E
40|$|Abstract. We study private {{computations}} in {{a system}} of tiny mobile agents. We consider the mobile population protocol model of Angluin et al. [2] and ask what can be computed without ever revealing any input to a curious adversary. We show that any <b>computable</b> <b>predicate</b> of the original population model can be made private through an obfuscation procedure that exploits the inherent non-determinism of the mobility pattern. In short, the idea is for every mobile agent to generate, besides its actual input value, a set of wrong input values to confuse the curious adversary. To converge to the correct result, the procedure has the agents eventually eliminate the wrong values; however, the moment when this happens is hidden from the adversary. This is achieved without jeopardizing the tiny nature of the agents: they still have very small storage size that is independent of the cardinality of the system. We present three variants of this obfuscation procedure that help compute respectively, remainder, threshold, and or predicates which, when composed, cover all those that can be computed in the population protocol model. ...|$|E
40|$|This paper {{proposes a}} new {{technique}} for the high-level construction of type-safe web-oriented user interfaces. Our approach is useful to equip applications processing structured data with interfaces to manipulate these data in an efficient and maintainable way. The interfaces are web-based, i. e., the data can be manipulated with standard web browsers without any specific requirements on the client side. In order to support type-safe user interfaces, i. e., interfaces where users can only input type-correct data (types can be standard types of a programming language {{as well as any}} <b>computable</b> <b>predicate</b> on the data), we propose a set of type-oriented building blocks from which interfaces for more complex types can be easily constructed. This technique leads to a very concise and maintainable implementation of web-based user interfaces. We show an implementation of this concept in the declarative multi-paradigm language Curry. In particular, its integrated functional and logic features are exploited to enable the high level of abstraction proposed in this paper. Categories and Subject Descriptors D. 1. 1 [Programming Techniques]...|$|E
40|$|The domain-theoretic {{model of}} {{computational}} geometry {{provides us with}} continuous and <b>computable</b> <b>predicates</b> and binary operations. It {{can also be used}} to generalise the theory of computability for real numbers and real functions into geometric objects and geometric operations. A geometric object is computable if it is the effective limit of a sequence of finitary partial objects of the same type as the original object. We are also provided with two different quantitative measures for approximation using the Hausdorff metric and the Lebesgue measure. In this thesis, we introduce a new data type to capture imprecise data or approximate points on the plane, given in the shape of compact convex polygons. This data type in particular includes rectangular approximation and is invariant under linear transformations of coordinate system. Based on the new data type, we define the notion of a number of partial geometric operations, including partial perpendicular bisector and partial disc and we show that these operations and the convex hull, Delaunay triangulation and Voronoi diagram are Hausdorff and Scott continuous and nestedly Hausdorff and Lebesgue computable. We develop algorithms to obtain the partial convex hull, partial Delaunay triangulation and partial Voronoi diagram. We prove that the complexity of the partial convex hull is N log N in 2 D and 3 D, whereas the partial Delaunay triangulation and partial Voronoi diagram algorithms for non-degenerate data have the same complexity as their classical counterparts. ...|$|R
40|$|Induction is {{the process}} by which we reason from the {{particular}} to the general. In this paper we use ideas from the theory of abstract machines and recursion theory to study this process. We focus on pure induction in which the conclusions “go beyond the information given” in the premises from which they are derived and on simple induction, which is rather a stark kind of induction that deals with <b>computable</b> <b>predicates</b> on the integers in rather straightforward ways. Our basic question is “What are the relationships between the kinds of abstract machinery we bring to bear on the job of doing induction and our ability to do that job well?” Our conclusions are as follows: (1) If we use only the abstract machinery of the digital computer in a computing center (which we assume to be capable of only evaluating totally computable functionals or functionals in Σ 0 of the Arithmetic Hierarchy) then a single inductive procedure can only develop finitely many sound theories. (2) If we use only the abstract machinery of the mathematician (which we assume to be the machinery required to evaluate a functional in Σ 2 of the Arithmetic Hierarchy) then we can develop inductive procedures that generate infinitely many sound theories but no procedure that is analytic {{in the sense that the}} theories it puts forth as sound will be sound in “all possible worlds”. (3) If we use the machinery of the trial and error machine (or the machinery required to evaluate functionals in Σ 2 of the Arithmetic Hierarchy) then we can develop consistent procedures for induction but none that are complete in the sense that they generate all useful theories in a fairly natural sense of “useful”. (4) Finally, if we use the machinery of the hyper-trial-anderror machine (or the machinery required to evaluate functionals in Σ 3 of the Arithmetic Hierarchy) then we can develop procedures that are both consistent and complete...|$|R
40|$|Abstract. Chandy et al. {{proposed}} {{the methodology of}} “self-similar algorithms” for distributed computation in dynamic environments. We further characterize the class of functions computable by such algorithms by showing that self-similarity induces an additive relationship among the level-sets of such functions. Angluin et al. introduced the population protocol model for computation in mobile sensor networks and characterized the class of <b>predicates</b> <b>computable</b> in a standard population. We define and characterize the class of self-similar predicates and show when they are computable by a population protocol. ...|$|R
40|$|We {{propose a}} {{framework}} to construct web-oriented user interfaces in a high-level way by exploiting declarative programming techniques. Such user interfaces {{are intended to}} manipulate complex data in a type-safe way, i. e., {{it is ensured that}} only type-correct data is accepted by the interface, where types can be specified by standard types of a programming language as well as any <b>computable</b> <b>predicate</b> on the data. The interfaces are web-based, i. e., the data can be manipulated with standard web browsers without any specific requirements on the client side. However, if the client’s browser has JavaScript enabled, one could also check the correctness of the data on the client side providing immediate feedback to the user. In order to release the application programmer from the tedious details to interact with JavaScript, we propose an approach where the programmer must only provide a declarative description of the requirements of the user interface from which the necessary JavaScript programs and HTML forms are automatically generated. This approach leads to a very concise and maintainable implementation of web-based user interfaces. We demonstrate an implementation of this concept in the declarative multi-paradigm language Curry where the integrated functional and logic features are exploited to enable the high level of abstraction proposed in this paper...|$|E
40|$|We {{extend the}} {{framework}} [1] to construct web-oriented user interfaces (WUIs) in a high-level way by exploiting declarative programming techniques. Such user interfaces {{are intended to}} manipulate complex data in a type-safe way, i. e., {{it is ensured that}} only type-correct data is accepted by the interface, where types can be specified by standard types of a programming language as well as any <b>computable</b> <b>predicate</b> on the data (see Fig. 1). The interfaces are web-based, i. e., the data can be manipulated with standard web browsers without any specific requirements on the client side. However, if the client’s browser has JavaScript enabled, one could also check the correctness of the data on the client side providing immediate feedback to the user and reducing network traffic. In order to release the application programmer from the tedious details to interact with JavaScript, we propose an approach where the programmer must only provide a declarative description of the requirements of the user interface from which the necessary JavaScript programs and HTML forms are automatically generated. This approach leads to a very concise and maintainable implementation of web-based user interfaces. We demonstrate an implementation of this concept in the declarative multiparadigm language Curry where the integrated functional and logic features are exploited to enable the high level of abstraction proposed in this paper...|$|E
40|$|We {{assume that}} all {{combinatorial}} objects that we refer to (graphs, boolean formulas, families of sets) are represented as binary strings. For a binary string x, we denote its length as |x|. We represent a decision problem as a language, that is, as the set of all inputs for which the answer is YES. We define P as the class of languages that can be decided in polynomial time. We define NP as the class of languages L such {{that there is a}} polynomial time <b>computable</b> <b>predicate</b> V and a polynomial q() such that x ∈ L if and only if there is w, |w | ≤ q(|x|) such that V (x, w) accepts. We think of w as a proof, or witness that x is in the language. For two languages L 1 and L 2, we say that L 1 reduces to L 2, and we write L 1 ≤m L 2 if there is polynomial time computable f such that x ∈ L 1 if and only if f(x) ∈ L 2. A language A is NP-hard if every language L in NP reduces to A. A language is NP-complete if it is NP-hard and it belongs to NP. NPO Problems A combinatorial optimization problem O is defined 1 by a cost function costO() that given an instance x of the problem and a solution s outputs costO(x, s) which is either the cost of the solution (a non-negative real number) or the special value ⊥ if s is not a feasible solution for x. For every x, there is only a finite number of feasible solutions s such that costO(x, s) = ⊥. If O is a maximization problem (respectively, maximization), then our goal is, given x to find a feasible solution s such that cost(x, s) is smallest (respectively, largest). We denote by opt O(x) the cost of an optimal solution for x. For example, in the independent set problem, an instance is an undirected graph G = (V, E), a feasible solution is a subset S ⊆ V such that no two vertices of S are connected by an edge. The cost of a feasible S is the number of vertices in S. An optimization problem O is an NP-optimization problem, and it belongs to the class NPO, if costO() is computable in polynomial time {{and if there is a}} polynomial q such that for every instance and every solution s that is feasible for x we have |s | ≤ q(|x|). The independent set problem is clearly an NPO problem...|$|E
40|$|Within Valiant's {{model of}} {{learning}} as formalized by Kearns, {{we show that}} <b>computable</b> total <b>predicates</b> for two formally uncomputable problems (the classical Halting Problem, and the Halting Problem relative to a specified oracle) are formally learnable from examples, to arbitrarily high accuracy with arbitrarily high con dence, under any probability distribution. The Halting Problem relative to the oracle is learnable in time polynomial in the measures of accuracy, confidence, {{and the length of}} the learned predicate. The classical Halting Problem is learnable in expected time polynomial in the measures of accuracy, confidence, and the (1, = 16) th percentile length and run-time of programs which do halt on their inputs (these quantities are always finite). Equivalently, the mean length and run-time may be substituted for the percentile values in the time complexity statement. The proofs are constructive. While the problems are learnable, they are not polynomially learnable, even though we do derive polynomial time bounds on the learning algorithm...|$|R
40|$|In this paper, {{we discuss}} the problem of {{generating}} test instances for promised NP search problems. A technical framework is proposed for studying this problem, and it is shown that all known distNP-hard search problems are "complete" for test instance generation problems. 1. Introduction Suppose someone claims that he invented a new algorithm that, when given a satisfying Boolean formula, computes one of its satisfying assignments in polynomial-time on average (under certain distribution). One way to check his claim is to test the algorithm by giving randomly generated satisfiable Boolean formulas. In this paper, {{we discuss the}} problem of generating such test instances for promised NP search problems. We propose one technical goal for this problem, and prove that all known distNP-hard search problems are "complete" for test instance generation problems. For any polynomial-time <b>computable</b> binary <b>predicate</b> R, an NP search problem specified by R is to find, for a given input x, one of [...] ...|$|R
40|$|International audiencePopulation {{protocols}} {{have been}} introduced by Angluin et {al. } {{as a model of}} networks consisting of very limited mobile agents that interact in pairs but with no control over their own movement. A collection of anonymous agents, modeled by finite automata, interact pairwise according to some rules that update their states. Predicates on the initial configurations that can be computed by such protocols have been characterized as semi-linear predicates. In an orthogonal way, several distributed systems have been termed in literature as being realizations of games in the sense of game theory. We investigate under which conditions population protocols, or more generally pairwise interaction rules, correspond to games. We show that restricting to asymetric games is not really a restriction: all <b>predicates</b> <b>computable</b> by protocols can actually be computed by protocols corresponding to games, i. e. any semi-linear predicate can be computed by a Pavlovian population multi-protocol...|$|R
40|$|Population {{protocols}} [Angluin et al., PODC, 2004] are {{a formal}} model of sensor networks consisting of identical mobile devices. Two devices can interact and thereby change their states. Computations are infinite sequences of interactions satisfying a strong fairness constraint. A population protocol is well-specified if for every initial configuration C of devices, and every computation starting at C, all devices eventually {{agree on a}} consensus value depending only on C. If a protocol is well-specified, then {{it is said to}} compute the predicate that assigns to each initial configuration its consensus value. While the <b>predicates</b> <b>computable</b> by well-specified protocols have been extensively studied, the two basic verification problems remain open: is a given protocol well-specified? Does a protocol compute a given predicate? We prove that both problems are decidable. Our results also prove decidability of a natural question about home spaces of Petri nets...|$|R
40|$|Population {{protocols}} {{have been}} introduced by Angluin et al. {{as a model of}} networks consisting of very limited mobile agents that interact in pairs but with no control over their own movement. A collection of anonymous agents, modeled by finite automata, interact pairwise according to some rules that update their states. Predicates on the initial configurations that can be computed by such protocols have been characterized as semi-linear predicates. In an orthogonal way, several distributed systems have been termed in literature as being realizations of games in the sense of game theory. We investigate under which conditions population protocols, or more generally pairwise interaction rules, correspond to games. We show that restricting to asymetric games is not really a restric- tion: all <b>predicates</b> <b>computable</b> by protocols can actually be computed by protocols corresponding to games, i. e. any semi-linear predicate can be computed by a Pavlovian population multi-protocol...|$|R
40|$|AbstractWe extend {{here the}} Population Protocol (PP) model of Angluin et al. (2004, 2006) [2, 4] {{in order to}} model more {{powerful}} networks of resource-limited agents that are possibly mobile. The main feature of our extended model, called the Mediated Population Protocol (MPP) model, is to allow {{the edges of the}} interaction graph to have states that belong to a constant-size set. We then allow the protocol rules for pairwise interactions to modify the corresponding edge state. The descriptions of our protocols preserve both the uniformity and anonymity properties of PPs, that is, they do not depend {{on the size of the}} population and do not use unique identifiers. We focus on the computational power of the MPP model on complete interaction graphs and initially identical edges. We provide the following exact characterization of the class MPS of stably <b>computable</b> predicates: a <b>predicate</b> is in MPS iff it is symmetric and is in NSPACE(n 2) ...|$|R
40|$|We extend {{here the}} Population Protocol (PP) model of Angluin et al. (2004, 2006) [2, 4] {{in order to}} model more {{powerful}} networks of resource-limited agents that are possibly mobile. The main feature of our extended model, called the Mediated Population Protocol (MPP) model, is to allow {{the edges of the}} interaction graph to have states that belong to a constant-size set. We then allow the protocol rules for pairwise interactions to modify the corresponding edge state. The descriptions of our protocols preserve both the uniformity and anonymity properties of PPs, that is, they do not depend {{on the size of the}} population and do not use unique identifiers. We focus on the computational power of the MPP model on complete interaction graphs and initially identical edges. We provide the following exact characterization of the class MPS of stably <b>computable</b> predicates: a <b>predicate</b> is in MPS iff it is symmetric and is in NSPACE(n 2). © 2010 Elsevier B. V. All rights reserved...|$|R
40|$|We {{show how}} {{automated}} random testing {{can be used}} to effectively find bugs in complex software, such as an optimising compiler. To test the GHC Haskell compiler we created a generator of simple random programs, used GHC to compile them with different optimisation levels, and then compared the results of running them. Using this simple approach we found a number of optimisation bugs in GHC. This approach for finding bugs proved to be very effective, but we found that implementing a generator of random programs by hand required a large amount of effort. Therefore, we developed an automatic method for deriving random generators of complex test data based on <b>computable</b> boolean <b>predicates</b> that specify the well-formed values of the data type. Defining such a predicate is usually much quicker than implementing a dedicated generator, even if its performance might be comparably lower. In addition, we discovered that the pseudorandom number generator used by us for random testing is unreliable, and that no reliable contruction exists that supports our particular requirements. Consequently, we designed and implemented a high-quality pseudorandom number generator, which is based on a known and reliable cryptographic construction, and whose correctness is supported by a formal argument. Finally, we present how random testing {{can be used to}} rank a group of programs according to their relative correctness with respect to their observed behaviour. The ranking method removes the influence of the distribution of the random data generator used for testing, which results in a reliable ranking...|$|R
40|$|Counter Automata are Finite State Automata {{which include}} a set of {{registers}} containing natural numbers, and where state transitions occur based on these register values. The contribution of our work is to extend previous work on verification of counter automata properties to cover arbitrary <b>computable</b> functions and <b>predicates</b> (in principle). In order to achieve this, we use the dependently typed language Agda to verify properties. The advantage {{of this approach is}} that it allows us to verify both functional and extra-functional properties such as resource consumption, in the presence of iteration and control parameters. However, we are not able to achieve fully automatic verification. We illustrate our approach using three examples: i) verifying that a particular finite state automaton accepts exactly those binary sequences divisible by 3, if they are interpreted as numbers; ii) verifying the worst-case execution time of a system of three boxes, depending on an unknown control parameter; and iii) verifying the number of box executions for a system of two boxes, which is non-linear...|$|R
