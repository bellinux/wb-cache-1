0|115|Public
40|$|We {{introduce}} WiIRE, {{a prototype}} system for conducting interactive information retrieval (IIR) experiments via the Internet. We conceived WiIRE to increase validity while streamlining procedures and adding efficiencies to {{the conduct of}} IIR experiments. The system incorporates password-controlled access, online questionnaires, study instructions and tutorials, <b>conditional</b> interface <b>assignment,</b> and <b>conditional</b> query <b>assignment</b> as well as provision for data collection. As an initial evaluation, we used WiIRE in-house to conduct a Web-based interactive information retrieval experiment using an external search engine with customized search interfaces and the TREC 11 Interactive Track search queries. Our evaluation of the prototype indicated significant cost efficiencies {{in the conduct of}} IIR studies, and additionally had some novel findings about the human perspective: about half participants would have preferred some personal contact with the researcher, and participants spent a significantly decreasing amount of time on tasks {{over the course of a}} session...|$|R
50|$|In {{programming}} languages {{that have}} associative arrays or comparable data structures, such as Python, Perl, PHP or Objective-C, it is idiomatic {{to use them}} to implement <b>conditional</b> <b>assignment.</b>|$|R
40|$|MBASIC is high-level, {{interactive}} {{computer language}} that reduces time of computer task programming. Outstanding features of MBASIC include: multiple assignments or statements in single instruction; <b>conditional,</b> <b>assignment,</b> and repetitive statement modifiers; and excellent string-handling capabilities. Two machine versions are available: UNIVAC (written in reentrant Assembler code for execution under EXEC 8) AND DEC- 10 (written in Assembler code for execution under TOPS- 10) ...|$|R
40|$|Core course {{offered in}} Fall and spring) Bulletin Description: Introduction to computers. Simple {{algorithms}} and flowcharts. Solving engineering and mathematical problems using a mathematically-oriented programming language. Programming concepts: I/O, <b>assignment,</b> <b>conditional</b> loops, functions and subroutines. Programming selected numerical and non-numerical problems o...|$|R
40|$|Comparing two {{approaches}} for estimating the found. Propensity score matching {{has the advantage}} of using statistically-matched pairs and relying on the assumption that given the measured covariates, outcome is independent of treatment <b>assignment</b> (<b>conditional</b> independence Boulay et al. Malaria Journal 2014, 13 : 34...|$|R
40|$|In {{this paper}} we extend a program logic for verifying Java Card {{applications}} by introducing a "throughout" operator {{that allows us}} to prove "strong" invariants. Strong invariants can be used to ensure "rip out" properties of Java Card programs (properties that are to be maintained in case of unexpected termination of the program). Along with introducing the "throughout" operator, we show how to handle the Java Card transaction mechanism (and, thus, <b>conditional</b> <b>assignments)</b> in our logic. We present sequent calculus rules for the extended logic...|$|R
5000|$|The {{condition}} is evaluated {{true or false}} as a Boolean expression. On {{the basis of the}} evaluation of the Boolean condition, the entire expression returns value_if_true if {{condition is}} true, but value_if_false otherwise. Usually the two sub-expressions value_if_true and value_if_false must have the same type, which determines the type of the whole expression. The importance of this type-checking lies in the operator's most common use—in <b>conditional</b> <b>assignment</b> statements. In this usage it appears as an expression {{on the right side of}} an assignment statement, as follows: ...|$|R
40|$|Abstract. In {{this paper}} we extend a program logic for verifying JAVA CARD {{applications}} by introducing a “throughout ” operator {{that allows us}} to prove “strong ” invariants. Strong invariants can be used to ensure “rip out ” properties of JAVA CARD programs (properties that are to be maintained in case of unexpected termination of the program). Along with introducing the “throughout ” operator, we show how to handle the JAVA CARD transaction mechanism (and, thus, <b>conditional</b> <b>assignments)</b> in our logic. We present sequent calculus rules for the extended logic. ...|$|R
50|$|The {{conditional}} operator's {{most common}} usage {{is to make}} a terse simple <b>conditional</b> <b>assignment</b> statement. For example, if we wish to implement some C code to change a shop's normal opening hours from 9 o'clock to 12 o'clock on Sundays, we may useint opening_time = (day == SUNDAY) ? 12 : 9;instead of the more verboseint opening_time;if (day == SUNDAY) opening_time = 12;else opening_time = 9;The two forms are nearly equivalent. Keep in mind that the ?: is an expression and if-then-else is a statement. Note that neither the true nor false portions can be omitted from the conditional operator without an error report upon parsing. This contrasts with if-then-else statements, where the else clause can be omitted.|$|R
40|$|An {{introduction}} to programming {{in general and}} a manual for programming in Modula- 2. It covers all facilities of that language. Part 1 covers basic notions of the variable, expression, <b>assignment,</b> <b>conditional</b> and repetitive statement, and array data structures. Part 2 introduces the important concept of the procedure or subroutine. Part 3 is concerned with data types and structures, and Part 4 introduces {{the notion of the}} modul...|$|R
50|$|The {{main feature}} of BMDFM {{is to provide}} a {{conventional}} programming paradigm at the top level, so-called transparent dataflow semantics. A user understands BMDFM as a virtual machine, which runs all statements of an application program in parallel having all parallelization and synchronization mechanisms fully transparent. The statements of an application program are normal operators, which any single threaded program might consist of - they include variable <b>assignments,</b> <b>conditional</b> processing, loops, function calls, etc.|$|R
40|$|Abstract — This paper {{examines}} several {{mechanisms to}} improve the performance of life science applications on highperformance computer architectures typically designed for more traditional supercomputing tasks. In particular, {{we look at the}} detailed performance characteristics {{of some of the most}} popular sequence alignment and homology applications on the POWER 5 architecture offering from IBM. Through detailed analysis of performance counter information collected from the hardware, we identify the main performance bottleneck in the current POWER 5 architecture for these applications is the high branch misprediction penalty of the most time-consuming kernels of these codes. Utilizing our PowerPC full system simulation environment, we show the performance improvement afforded by adding <b>conditional</b> <b>assignments</b> to the PowerPC ISA. We also show the impact of changing the number of functional units t...|$|R
40|$|A {{numerical}} {{method for}} the computation of the Singular Value Decomposition of 3 × 3 matrices is presented. The proposed methodology robustly handles rank-deficient matrices and guarantees orthonormality of the computed rotational factors. The algorithm is {{tailored to the}} characteristics of SIMD or vector processors. In particular, {{it does not require}} any explicit branching beyond simple <b>conditional</b> <b>assignments</b> (as in the C++ ternary operator?:, or the SSE 4. 1 instruction VBLENDPS), enabling trivial data-level parallelism for any number of operations. Furthermore, no trigonometric or other expensive operations are required; the only floating point operations utilized are addition, multiplication, and an inexact (yet fast) reciprocal square root which is broadly available on current SIMD/vector architectures. The performance observed approaches the limit of making the 3 × 3 SVD a memory-bound (as opposed to CPU-bound) operation on current SMP platforms...|$|R
40|$|In {{this paper}} we study {{supervisory}} control of discrete event systems using state variables for representation and specification. The motivation is two fold: firstly, a state variable representation allows a concise characterization of systems with infinitely many states, and secondly, state variable specification allows characterization of qualitative properties of general nondeterministic systems. An assignment program consisting of state variables and a finite set of <b>conditional</b> <b>assignment</b> statements {{is used for}} representing a discrete event system, {{and a set of}} forbidden states is used for representing a control specification. Although the state avoidance control of infinite state systems has been studied in literature, there is little work on computation of supervisors for general infinite state systems (except for certain classes of Petri nets). The contribution {{of this paper is to}} show that the supervisory control problem in such settings reduces to that of solving arith [...] ...|$|R
40|$|In {{this paper}} we study {{supervisory}} control of discrete event systems using state variables for representation and specification. The motivation is two fold: firstly, a state variable representation allows a concise characterization of systems with infinitely many states, and secondly, state variable specification allows characterization of qualitative properties of general nondeterministic systems. An assignment program consisting of state variables and a finite set of <b>conditional</b> <b>assignment</b> statements {{is used for}} representing a discrete event system, {{and a set of}} forbidden states is used for representing a control specification. The control synthesis problem is undecidable in the general setting. However, in the special case when a single uncontrollable event is present, we show that the problem of computing a maximally permissive supervisor reduces to that of solving an arithmetic equation. Also, in another special case when the system can be represented as a vector addition system [...] ...|$|R
40|$|SummaryThe {{automated}} {{building of}} a protein model into an electron density map remains a challenging problem. In the ARP/wARP approach, model building is facilitated by initially interpreting a density map with free atoms of unknown chemical identity; all structural information for such chemically unassigned atoms is discarded. Here, this is remedied by applying restraints between free atoms, and between free atoms and a partial protein model. These are based on geometric considerations of protein structure and tentative (<b>conditional)</b> <b>assignments</b> for the free atoms. Restraints are applied in the REFMAC 5 refinement program and are generated on an ad hoc basis, allowing them to fluctuate from step to step. A large set of experimentally phased and molecular replacement structures showcases individual structures where automated building is improved drastically by the conditional restraints. The concept and implementation we present can also find application in restraining geometries, such as hydrogen bonds, in low-resolution refinement...|$|R
40|$|We {{introduce}} the basic concepts of a relational model of parallel programming. We define {{the concepts of}} a problem, an abstract program and a solution. Our approach is functional, problems are given an own semantical meaning. The abstract program {{is regarded as a}} relation generated by a set of nondeterministic <b>conditional</b> <b>assignments</b> similar to the concept of abstract program in UNITY. We {{introduce the}} behaviour relation of a parallel program which is easy to compare to the relation which is the interpretation of a problem. This paper covers only a brief summary of the model. For further information see [7]. The main goal {{of this paper is to}} introduce some basic composition methods for parallel programs and problems. We define the union, extension and sequence of problems. Similarly we formalize the concept of union, superposition and sequence of parallel programs. We analyze how one can solve a compound problem using the appropriate program construct. Categories and Subject Descripto [...] ...|$|R
40|$|This paper {{shows an}} {{application}} {{of the theory of}} sorting networks to facilitate the synthesis of optimized general purpose sorting libraries. Standard sorting libraries are often based on combinations of the classic Quicksort algorithm with insertion sort applied as the base case for small fixed numbers of inputs. Unrolling the code for the base case by ignoring loop conditions eliminates branching and results in code which is equivalent to a sorting network. This enables the application of further program transformations based on sorting network optimizations, and eventually the synthesis of code from sorting networks. We show that if considering the number of comparisons and swaps then theory predicts no real advantage of this approach. However, significant speed-ups are obtained when taking advantage of instruction level parallelism and non-branching <b>conditional</b> <b>assignment</b> instructions, both of which are common in modern CPU architectures. We provide empirical evidence that using code synthesized from efficient sorting networks as the base case for Quicksort libraries results in significant real-world speed-ups. Comment: IMADA-preprint-c...|$|R
5000|$|Critics of Yoda {{conditions}} see {{the lack}} of readability as a disadvantage that outweighs the benefits described above. Some programming languages as Python and Swift do not allow variable <b>assignments</b> within <b>conditionals,</b> by defining <b>assignments</b> to not return a value, in which case this error is impossible to make. [...] Many compilers produce a warning for code such as [...] (e.g., the GCC [...] option warns suggest parentheses around assignment used as truth value), which alerts the programmer to the likely mistake. In JavaScript, linters such as ESLint can warn on <b>assignment</b> inside a <b>conditional.</b>|$|R
40|$|In {{this paper}} we give a new, constraint-based {{model of the}} {{manufacturing}} process planning problem. This problem is hard {{because of the large}} amount and intricate relations of the available pieces of domain knowledge. The planning model captures resource, precedence and setup constraints, and provides means for representing conditional constraints. Most of the constraint types have both hard and soft versions. Elements of the planning model are mapped to the concepts and techniques of constraint programming. Issues of search, optimization and conict resolution are discussed. The model is demonstrated with examples from the domain of machining prismatic parts. Keywords: process planning, sequencing, resource <b>assignment,</b> <b>conditional</b> constraints, conict, optimization...|$|R
40|$|This report {{presents}} a semantics for an object-oriented language with classes, visibility, dynamic binding, mutual recursive methods and recursion. Our semantic framework identifies both class declarations and commands as designs. All the programming constructs of our language, such as <b>assignment,</b> <b>conditional,</b> composition and recursion, are {{defined in the}} exactly same way as {{their counterparts in the}} imperative programming languages. This makes the approach more accessible to users who are already familiar with imperative program design and also enables the use of existing tools and methods of verification and refinement developed for these languages. Furthermore, the algebraic laws developed for the imperative languages remain applicable in designing object-oriented programs...|$|R
40|$|ACL- 2 International audienceThe {{most widely}} used measure of {{segregation}} is the so‐called dissimilarity index. It is now well understood that this measure also reflects randomness in the allocation of individuals to units (i. e. it measures deviations from evenness, not deviations from randomness). This leads to potentially large values of the segregation index when unit sizes and/or minority proportions are small, {{even if there is}} no underlying systematic segregation. Our response to this is to produce adjustments to the index, based on an underlying statistical model. We specify the assignment problem in a very general way, with differences in <b>conditional</b> <b>assignment</b> probabilities underlying the resulting segregation. From this, we derive a likelihood ratio test for the presence of any systematic segregation, and bias adjustments to the dissimilarity index. We further develop the asymptotic distribution theory for testing hypotheses concerning the magnitude of the segregation index and show that the use of bootstrap methods can improve the size and power properties of test procedures considerably. We illustrate these methods by comparing dissimilarity indices across school districts in England to measure social segregation...|$|R
3000|$|Bayesian {{particle}} filters Particle filter methods utilise Monte-Carlo Markov chain (MCMC) {{to approximate}} the <b>conditional</b> posterior probability <b>assignment</b> p(x [...]...|$|R
40|$|Abstract Program slicing is {{a source}} code {{extraction}} techniquethat {{can be used to}} support reverse engineering by automatically extracting executable subprograms that preservesome aspect of the original program's semantics. Although minimal slices are not generally computable, safe approx-imate algorithms can be used to good effect. However, the precision of such slicing algorithms is a major factor in de-termining the value of slicing for reverse engineering. Amorphous slicing has been proposed as a way of re-ducing the size of a slice. Amorphous slices preserve the aspect of semantic interest, but not the syntax that denotesit, making them generally smaller than their syntactically restricted counterparts. Amorphous slicing is suitable formany reverse engineering applications, since reverse engineering typically abandons the existing syntax to facilitatestructural improvements. Previous work on amorphous slicing has not attemptedto exploit its potential to apply loop-squashing transformations. This paper presents an algorithm for amorphous slic-ing of loops, which identifies induction variables, transformation rule templates and iteration-determining compile-time expressions. The algorithm uses these to squash certain loops into <b>conditional</b> <b>assignments.</b> The paper also presentsan inductive proof of the rule templates and illustrates the application of the algorithm with a detailed example of loopsquashing...|$|R
40|$|The {{most widely}} used measure of {{segregation}} is the dissimilarity index, D. It is now well understood that this measure also reflects randomness in the allocation of individuals to units; that is, it measures deviations from evenness not deviations from randomness. This leads to potentially large values of the segregation index when unit sizes and/or minority proportions are small, {{even if there is}} no underlying systematic segregation. Our response to this is to produce an adjustment to the index, based on an underlying statistical model. We specify the assignment problem in a very general way, with differences in <b>conditional</b> <b>assignment</b> probabilities underlying the resulting segregation. From this we derive a likelihood ratio test for the presence of any systematic segregation and a bootstrap bias adjustment to the dissimilarity index. We further develop the asymptotic distribution theory for testing hypotheses concerning the magnitude of the segregation index and show that use of bootstrap methods can improve the size and power properties of test procedures considerably. We illustrate these methods by comparing dissimilarity indices across school districts in England to measure social segregation. segregation, dissimilarity index, bootstrap methods, hypothesis testing...|$|R
40|$|International audienceFloating-point {{numbers are}} used to {{approximate}} the exact real numbers {{in a wide range}} of domains like numerical simulations, embedded software, etc. However, floating-point numbers are a finite approximation of real numbers. In practice, this approximation may introduce round-off errors and this can lead to catastrophic results. To cope with this issue, we have developed a tool which corrects partly these round-off errors and which consequently improves the numerical accuracy of computations by automatically transforming programs in a source to source manner. Our transformation, relies on static analysis by abstract interpretation and operates on pieces of code with <b>assignments,</b> <b>conditionals</b> and loops. In former work, we have focused on the intraprocedural transformation of programs and, in this article, we introduce the interprocedural transformation to improve accuracy...|$|R
40|$|Program slices {{have long}} been used {{as an aid to}} program understanding, {{especially}} in maintenance activities. Most slicing methods involve data and control flow analysis to determine what statements might affect a set of variables. Here, we develop a more precise slicing concept, called p-slices, defined using Dijkstra’s weakest precondition (wp), to determine which statements will affect a specified predicate. Weakest preconditions are already known to be an effective technique for program understanding and analysis, and this paper unifies wp analysis and slicing and simplifies existing slicing algorithms. Slicing rules for <b>assignment,</b> <b>conditional,</b> and repetition statements are developed. The authors are currently using these techniques in their work with software maintenance teams and are incorporating p-slice computation into a program analysis tool...|$|R
3000|$|... |xt− 1) as a <b>conditional</b> {{probability}} <b>assignment</b> {{to measure}} the confidence in next step prediction. Probabilistic prediction assignment provides {{more information about the}} state of the system compared to next event prediction. The loss in prediction is measured between the designed predictor’s guess and the true value of x [...]...|$|R
5000|$|A {{streaming}} {{subset of}} XPath {{is used in}} W3C XML Schema 1.0 for expressing uniqueness and key constraints. In XSD 1.1, the use of XPath is extended to support <b>conditional</b> type <b>assignment</b> based on attribute values, and to allow arbitrary boolean assertions to be evaluated against the content of elements.|$|R
40|$|We {{present a}} {{framework}} for high-level design validation using an efficient register-transfer level (RTL) automatic test pattern generator (ATPG). The RTL ATPG generates the test environments for validation targets, which include variable <b>assignments,</b> <b>conditional</b> statements, and arithmetic expressions in the HDL description. A test environment {{is a set of}} conditions that allow for full controllability and observability of the validation target. Each test environment is then translated to validation vectors by filling in the unspecified values in the environment. Since the observability of error effect is naturally handled by our ATPG, our approach is superior to methods that only focus on the excitation of HDL descriptions. The experimental results on ITC 99 benchmark circuits and an industrial circuit demonstrate that very high design error coverage can be obtained in a small CPU times...|$|R
40|$|Program slicing is {{a source}} code {{extraction}} technique {{that can be used}} to support reverse engineering by automatically extracting executable subprograms that preserve some aspect of the original program’s semantics. Although minimal slices are not generally computable, safe approximate algorithms can be used to good effect. However, the precision of such slicing algorithms is a major factor in determining the value of slicing for reverse engineering. Amorphous slicing has been proposed as a way of reducing the size of a slice. Amorphous slices preserve the aspect of semantic interest, but not the syntax that denotes it, making them generally smaller than their syntactically restricted counterparts. Amorphous slicing is suitable for many reverse engineering applications, since reverse engineering typically abandons the existing syntax to facilitate structural improvements. Previous work on amorphous slicing has not attempted to exploit its potential to apply loop–squashing transformations. This paper presents an algorithm for amorphous slicing of loops, which identifies induction variables, transformation rule templates and iteration–determining compile– time expressions. The algorithm uses these to squash certain loops into <b>conditional</b> <b>assignments.</b> The paper also presents an inductive proof of the rule templates and illustrates the application of the algorithm with a detailed example of loop squashing. 1...|$|R
40|$|A {{theory of}} Sequential Hybrid Programs (SHP) is studied. These {{programs}} consist of phase statements and the normal sequential programming constructs such as <b>assignments,</b> <b>conditionals</b> and iterations. Phase statements are specifications representing some time-dependent dynamical activity. Intermixing {{of these two}} features leads to programs with a rich diversity of behaviours including super-dense time, infinite executions, finitely divergent executions and even instantaneously divergent executions. Duration calculus is extended with super-dense time, fixed point operators and infinite intervals to give a logic ¯SDCI. A compositional semantics of SHP programs is defined using the logic ¯SDCI. Several high-level proof rules are derived for establishing specific kinds of properties of SHP programs such as total correctness and invariants. These high-level proof rules provide a modular and syntax directed method for establishing the properties SHP programs where the program structure guides [...] ...|$|R
40|$|International audienceIn floating-point arithmetic, a {{desirable}} property of computations {{is to be}} accurate, since in many industrial context small or large perturbations due to round-off errors may cause considerable damages. To cope with this matter of facts, we have developed a tool which corrects these errors by transforming automatically programs in a source to source manner. Our transformation, relying on static analysis by abstract abstraction, concerns pieces of code with <b>assignments,</b> <b>conditionals</b> and loops. By transforming programs, we significantly optimize the numer- ical accuracy of computations by minimizing the error relatively to the exact result. An interesting side-effect of our technique is that more accurate computations may {{make it possible to}} use smaller data-types. In this article, we show that our transformed programs, executed in single precision, may compete with not transformed codes executed in double precision...|$|R
40|$|<b>Conditional</b> {{independence}} of treatment <b>assignment</b> from potential outcomes is a commonly used but nonrefutable assumption. We derive identified sets for various treatment effect parameters under nonparametric deviations from this conditional independence assumption. These deviations are defined via a <b>conditional</b> treatment <b>assignment</b> probability, {{which makes it}} straightforward to interpret. Our results {{can be used to}} assess the robustness of empirical conclusions obtained under the baseline conditional independence assumption...|$|R
40|$|The {{propensity}} score is {{the probability of}} treatment <b>assignment</b> <b>conditional</b> on observed baseline characteristics. The {{propensity score}} allows one to design and analyze an observational (nonrandomized) study so that it mimics some of the particular characteristics of a randomized controlled trial. In particular, the propensity score is a balancing score: conditional on the propensity score, the distribution of observed baseline covariates will be similar between treated and untreated subjects. I describe 4 different propensity score methods: matching on the propensity score, stratification on the propensity score, inverse probability of treatment weighting using the propensity score, and covariate adjustment using the propensity score. I describe balance diagnostics for examining whether the propensity score model has been adequately specified. Furthermore, I discuss differences between regression-based methods and propensity score-based methods {{for the analysis of}} observational data. I describe different causal average treatment effects and their relationship with propensity score analyses...|$|R
40|$|Quantum leap {{matching}} {{is introduced}} as a generic pattern matching {{strategy for the}} single keyword exact pattern matching problem, {{that can be used}} on top of existing Boyer-Moore-style string matching algorithms. The cost of the technique is minimal: an additional shift table (of one dimension, for shifts in the opposite direction to the parent algorithm’s shifts), and the replacement of a simple table lookup assignment statement in the original algorithm with a similar <b>conditional</b> <b>assignment.</b> Together with each of the conventional shift table lookups, the additional shift table is typically also indexed on the text character that is at a distance of z away from the current sliding window. Under conditions that are identified, the returned values from the two shift tables allow a “quantum leap” of distance more than the length of the keyword for the next matching attempt. If the conditions are not met, then there is a fall back is to the traditional shift. Quick Search (by Sunday) is used as a case study to illustrate the technique. The performance of the derived “Quantum Leap Quick Search” algorithm is compared against Quick Search. When searching for shorter patterns over natural language and genomic texts, the technique improves on Quick Search’s time for most values of z. Improvements are also sometimes seen for various values of z on larger patterns. Most interestingly, under best case conditions it performs, on average, at about three times faster than Quick Search...|$|R
