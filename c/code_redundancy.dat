68|421|Public
50|$|Fundamentally {{one uses}} {{redundancy}} to counter faults. This includes running extra <b>code</b> (<b>redundancy</b> in time) {{as well as}} keeping extra bits (redundancy in space).|$|E
5000|$|Another similar use is the [...] "Barton-Nackman trick", {{sometimes}} referred to as [...] "restricted template expansion", where common functionality can be placed in a base class that is used not as a contract but as a necessary component to enforce conformant behaviour while minimising <b>code</b> <b>redundancy.</b>|$|E
50|$|The {{inability}} to store a NUL requires that string data and binary data be kept distinct and handled by different functions (with the latter requiring {{the length of}} the data to also be supplied). This can lead to <b>code</b> <b>redundancy</b> and errors when the wrong function is used.|$|E
3000|$|Define λ =M/N as {{the coding}} rate and R[*]=[*]N[*]−[*]M as the <b>coding</b> <b>redundancy.</b> Better {{spectral}} containments {{can be achieved}} {{at the cost of}} higher <b>coding</b> <b>redundancy.</b> If R[*]≥[*]K, x[*]=[*] 0 for any arbitrary data vector d [...]...|$|R
3000|$|In our cross-layer FEC schemes, we {{consider}} the following issues. First, the AL and PL FEC codes share the same available channel bandwidth to add their <b>coding</b> <b>redundancy.</b> As the channel [...]...|$|R
30|$|After {{performing}} CIM-based DCT computation, {{the following}} steps for the compression of the image are carried out. The DCT coefficients are quantized to a pre-determined level to reduce psycho-visual redundancy. Zigzag scanning ensures the scanning of high-frequency DCT coefficients, and the scanned coefficients are encoded to reduce <b>coding</b> <b>redundancy.</b>|$|R
5000|$|The front {{controller}} {{software design}} pattern {{is listed in}} several pattern catalogs and related {{to the design of}} Web applications. It is [...] "a controller that handles all requests for a Web site", which is a useful structure for Web application developers to achieve the flexibility and reuse without <b>code</b> <b>redundancy.</b>|$|E
50|$|Key to the {{benefits}} of Intentional Programming is that domain code which capture the intentions are not stored in source code text files, but in a tree-based storage (could be binary or XML). Tight integration of the environment with the storage format brings some of the nicer features of database normalization to source <b>code.</b> <b>Redundancy</b> is eliminated by giving each definition a unique identity, and storing the name of variables and operators in exactly one place. This {{makes it easier to}} intrinsically distinguish declarations from references, and the environment can show them differently.|$|E
50|$|ImageJ {{is older}} and hence {{it is more}} mature and has more plugins. This limits how much of ImageJ can be changed without {{breaking}} backwards-compatibility, which has caused design flaws to accumulate over time. Endrov sacrifices all backwards-compatibility for a clean design. While ImageJ consists of a core and rather independent plugins, Endrov has few core functions and plenty of plugin-plugin dependencies. The goal is to tighten the integration and increase encapsulation, thus reduce <b>code</b> <b>redundancy</b> and ease maintenance. As an example, the GUI is separate from most algorithm plugins; algorithms merely provide descriptions of input and output.|$|E
40|$|Packet headers exhibit {{considerable}} <b>coding</b> <b>redundancy</b> {{from both}} a theoretical and a practical standpoint. We propose to exploit this redundancy {{to create an}} additional communication channel between hosts as a by-product of normal packet transfers. This channel would be zero cost: the number and size of packets transfered would not change. Dissemination of dynamic resource information is a natural user of such a channel. In the paper, we begin by illustrating the significant theoretical <b>coding</b> <b>redundancy</b> of typical TCP/IP traffic using widely available packet trace data. Next, we discuss {{a number of ways}} to practically exploit this redundancy using only end-system changes and evaluate their prospects. Then we describe proof-of-concept experiments that we have conducted using a user-level network stack. Finally, we describe how common forms of resource information could be communicated using this mechanism...|$|R
40|$|Abstract—An {{integrated}} system for code-division multiple ac-cess (CDMA) radio access to {{asynchronous transfer mode}} (ATM) network is considered. The inherently high error rate associated with the Rayleigh fading channel is overcome by two-dimensional CRC codes for efficient ATM–CDMA interfacing. Simulations show promising error probability performance with low <b>coding</b> <b>redundancy.</b> Index Terms—ATM, CDMA, channel coding. I...|$|R
40|$|In {{this paper}} we {{prove that the}} maximum data {{expansion}} ffi of Huffman codes is upper bounded by ffi ! 1 : 39. This bound improves on the previous best known upper bound ffi ! 2. We also provide some characterizations of the maximum data expansion of optimal codes. Index Terms - Huffman codes, data expansion of optimal <b>codes,</b> source <b>coding,</b> <b>redundancy</b> of optimal <b>codes...</b>|$|R
40|$|TCP {{performance}} degrades when end-to-end connections extend over wireless connections [...] - links {{which are}} characterized by high bit error rate and intermittent connectivity. Such link characteristics can significantly degrade TCP performance as the TCP sender assumes wireless losses to be congestion losses resulting in unnecessary congestion control actions. Link errors can be reduced by increasing transmission power, <b>code</b> <b>redundancy</b> (FEC) or number of retransmissions (ARQ). But increasing power costs resources, increasing <b>code</b> <b>redundancy</b> reduces available channel bandwidth and increasing persistency increases end-to-end delay. The paper proposes a TCP optimization through proper tuning of power management, FEC and ARQ in wireless environments (WLAN and WWAN) ...|$|E
30|$|Tasks {{which are}} {{typically}} duplicated in several network layers (ie: packet creation, packet manipulation, packet sending and buffer provisioning) are delegated to the system, thus avoiding <b>code</b> <b>redundancy.</b> As a result, the overall code size is reduced, {{making it possible}} to support a large number of services even on resource-constrained devices.|$|E
40|$|An object {{oriented}} approach to implementing non-interactive cryptographic mechanisms is presented. The primary design goals are object reuse, minimal <b>code</b> <b>redundancy,</b> easy update and extension by new algorithms and an intuitive application programming interface. The object orientation proved {{to cause a}} run time overhead {{of no more than}} 4 %. Keywords Cryptographic library, application programming interface, {{object oriented}} programming...|$|E
40|$|The MPEG video {{compression}} standard effectively exploits spatial, temporal, and <b>coding</b> <b>redundancies</b> in the algorithm. In its generic form, however, only a minimal amount of scene adaptation is performed. Video {{can be further}} compressed {{by taking advantage of}} scenes where the temporal statistics allow larger inter-reference frame distances. This paper proposes the use of motion analysis (MA) to adapt to scene content. The actual picture type (I, P, or B) decision is made by examining the accumulation of motion measurements since the last reference frame was labeled. Depending on the video content, this proposed algorithm can achieve from 2 maintaining similar quality. 1 Introduction The MPEG {{video compression}} standard addresses many of the important issues relating to the exploitation of redundancies in video. Spatial, temporal, and <b>coding</b> <b>redundancies</b> are all taken advantage of in the algorithm. In its generic form, however, only a minimal amount of scene adaptation is performed. Indeed [...] ...|$|R
40|$|Preface Design Process and Technology Theory {{of logic}} design Analysis and {{synthesis}} Implementation technologies Predictable technologies Contemporary CAD of logic networks Number Systems Positional numbers Counting in a positional number system Basic arithmetic operations in various number systems Binary arithmetic Radix-complement representations Techniques for conversion of numbers in various radices Overflow Residue arithmetic Other binary <b>codes</b> <b>Redundancy</b> and reliability Graphical Data Structures Graphs in discrete devices and systems design Basic definitions...|$|R
40|$|This {{research}} {{is concerned with}} the delivery of scalably compressed data over erasure channels. Recent works proposed several strategies for assigning optimal <b>code</b> <b>redundancies</b> to elements of scalable data, which form a linear structure of dependency, under the assumption that all source elements are encoded onto a common group of network packets. Given large data and small network packets, such schemes require very long channel codes with high computational complexity. In networks with high loss, small packets are more desirable than long packets. A strategy for optimally assigning elements of the scalable data to clusters of packets according to their dependency structure, subject to constraints on packet size and code complexity is proposed. Given a packet cluster arrangement, the scheme then assigns optimal <b>code</b> <b>redundancies</b> to the source elements, subject to a constraint on transmission length. Then the scheme is modified to accommodate limited retransmission of lost data. An optimization algorithm determines the transmission and level of protection for each source element, using information about the success of earlier transmission...|$|R
3000|$|Quasi-cyclic (QC) LDPC {{codes are}} {{a class of}} codes able to join the {{excellent}} performance of LDPC iterative decoding with the low complexity encoding which characterizes QC codes. In fact, QC codes have the desirable property of being encodable through simple barrel shift registers, which have complexity increasing in the <b>code</b> <b>redundancy.</b> We remind that a code is QC if a shift of a codeword by n [...]...|$|E
40|$|International audienceExecutable {{models are}} {{essential}} to define the behavior of models, such as constraints put on model elements. However their implementation crosscut multiple model elements. Model semantics will facilitate Model Driven Development, without it, Design and Implementation won?t necessarily represent different abstractions of the same system. This paper introduces a mechanism to query executable models and weave constraints in order to localize their implementation, which improves <b>code</b> <b>redundancy</b> and modularity...|$|E
40|$|Abstract. TCP {{performance}} degrades when end-to-end connections extend over wireless connections — links {{which are}} characterized by high bit error rate and intermittent connectivity. Such link characteristics can significantly degrade TCP performance as the TCP sender assumes wireless losses to be congestion losses resulting in unnecessary congestion control actions. Link errors can be reduced by increasing transmission power, <b>code</b> <b>redundancy</b> (FEC) or number of retransmissions (ARQ). But increasing power costs resources, increasing <b>code</b> <b>redundancy</b> reduces available channel bandwidth and increasing persistency increases end-to-end delay. The paper proposes a TCP optimization through proper tuning of power management, FEC and ARQ in wireless environments (WLAN and WWAN). In particular, we conduct analytical and numerical analysis {{taking into account the}} three aforementioned factors, and evaluate TCP (and “wireless-aware ” TCP) performance under different settings. Our results show that increasing power, redundancy and/or retransmission levels always improves TCP performance by reducing link-layer losses. However, such improvements are often associated with cost and arbitrary improvement cannot be realized without paying a lot in return. It is therefore important to consider some kind of net utility function that should be optimized, thus maximizing throughput at the least possible cost. ...|$|E
40|$|The formal {{theory of}} the {{development}} of early perception and motor control presented here deals with cognitive development as a mapping from a finite set of given experiences to a set of perceptual and motor-control functions. The theory involves seven constraints that uniquely define the mapping. The compatibility with observational phenomena and sufficiency of these constraints shows the validity of the theory. The principle underlying these constraints is a coding by the most efficient representation of information. The efficiency of representation is evaluated by the <b>coding</b> <b>redundancy</b> of given experiences defined as the number of real numbers that characterize experiences plus the size of the minimum continuous decoding function. The <b>coding</b> <b>redundancy</b> of experiences by the most efficient representation corresponds to the Kolmogorov complexity of the experiences. The mapping accounts for the dependence on neonatal experience {{of the development of}} perceptual and motor-control functions. This theory of development can also be seen as a metatheory of cognition that presents us a unified view of the diversity of perceptual and motor-control modules. Kolmogorov complexity, computational theory, cognition development, constraints, motor control, perception...|$|R
40|$|Abstract: The {{quality of}} video streams {{transmitted}} via today’s Internet suffers severely from significant packet losses. To reduce the quality degradation, {{we need the}} error-resilient <b>coding</b> method. Video <b>Redundancy</b> <b>Coding</b> is an efficient error resilience mechanisms built in the H. 263 +. In this paper, we propose an Adaptive Video <b>Redundancy</b> <b>Coding</b> using network status and scene characteristics. Experimental {{results indicate that the}} proposed method does not only utilize network resources efficiently, but also reduces the fluctuation of the video quality. 1...|$|R
40|$|This paper {{presents}} a multilevel (ML) Flash memory onchip error correction system design {{based on the}} concept of trellis coded modulation (TCM). This is motivated by the non-trivial modulation process in ML memory storage and the effectiveness of TCM on integrating coding with modulation to provide better performance. Using code storage 2 bits/cell Flash memory as a test vehicle, the effectiveness of TCM-based systems, in terms of error-correcting performance, <b>coding</b> <b>redundancy,</b> silicon cost, and operation latency, has been successfully demonstrated. 1...|$|R
40|$|Abstract — A variable-length code is a fix-free code if no {{codeword}} is a prefix or a suffix of {{any other}} codeword. In a fix-free code any finite sequence of codewords can be decoded in both directions, which can improve the robustness to channel noise and speed up the decoding process. In this paper we prove a new sufficient condition {{of the existence of}} fix-free codes and improve the upper bound on the redundancy of optimal fix-free codes. Index Terms — Fix-free <b>code,</b> <b>redundancy.</b> I...|$|E
40|$|Summary- We {{will present}} coding {{techniques}} for transmission and storage channels with unknown gain and/or offset. It {{will be shown}} that a codebook of length-n q-ary codewords, S, where all codewords in S have equal balance and energy show an intrinsic resistance against unknown gain and/or offset. Generating functions for evaluating the size of S will be presented. We will present an approximate expression for the <b>code</b> <b>redundancy</b> for asymptotically large values of n. Key words: Constant composition code, permutation code, flash memory, optical recording I...|$|E
40|$|Abstract—a variable-length code is a fix-free code if no {{codeword}} is a prefix or a suffix of {{any other}} codeword. This class of codes is applied {{to speed up the}} decoding process, for the decoder can decode {{from both sides of the}} compressed file simultaneously. In this paper, we study some basic properties of fix-free codes. We prove a sufficient and a necessary condition for the existence of fix-free codes, and we obtain some new upper bounds on the redundancy of optimal fix-free codes. Index Terms—Fix-free code, prefix <b>code,</b> <b>redundancy.</b> I...|$|E
50|$|RozoFS {{is a free}} {{software}} distributed file system. It comes as a {{free software}}, licensed under the GNU GPL v2. RozoFS uses erasure <b>coding</b> for <b>redundancy.</b>|$|R
40|$|A {{distributed}} fault-tolerant {{information processing}} system is proposed, comprising a central multiprocessor, dedicated local processors, and multiplexed input-output buses connecting them together. The processors in the multiprocessor are duplicated for error detection, which is {{felt to be}} less expensive than using <b>coded</b> <b>redundancy</b> of comparable effectiveness. Error recovery is {{made possible by a}} triplicated scratchpad memory in each processor. The main multiprocessor memory uses replicated memory for error detection and correction. Local processors use any of three conventional redundancy techniques: voting, duplex pairs with backup, and duplex pairs in independent subsystems...|$|R
40|$|A fully {{adaptive}} algorithm for multiuser blind channel equalization is presented. The {{algorithm is}} based on an adaptive matrix singular value decomposition (SVD) for a (virtual) channel identification type operation and the Viterbi algorithm for subsequent symbol detection. Unlike other blind multiuser detection schemes that have recently appeared in the literature, the present algorithm removes multiple access interference (MAI) by exploiting the finite alphabet property of the input signals together with channel <b>coding</b> <b>redundancy.</b> The latter is believed to be a crucial new ingredient for performance in the context of MAI suppression. status: publishe...|$|R
40|$|E-learning is an {{application}} of information and communication technology {{in the field of}} learning. Through steganography the e-learning institution can provide security to other participants of e-learning like teacher and learner. Here we use text steganography with modified SNOW algorithm while passing secret texts from the administrator to the learner in an e-learning system. In this paper, we calculate the object oriented metric based analysis of CK and MOOD metrics of our proposed model, which ensures the advantages of <b>code</b> <b>redundancy,</b> code reusability, and cost effectiveness and so on...|$|E
40|$|To satisfy {{high data}} {{availability}} requirements for cloud storage systems, the data layer of cloud storage systems {{is regarded as}} a virtual storage body consists of two virtual storage nodes of a full copy and a encoded copy. A hadoop distributed file system-based complex redundancy scheme integrating the copy redundant mode and coding redundant mode is proposed. <b>Code</b> <b>redundancy</b> is achieved by splitting a data block into several data pieces and using random linear network coding among the pieces. When the storage node availability ranges from 0. 6 to 0. 9, with the system data availability target of 99. 999 %, the composite redundancy scheme saves over 35 % storage space than full backup scheme. To satisfy high data availability requirements for cloud storage systems, the data layer of cloud storage systems {{is regarded as a}} virtual storage body consists of two virtual storage nodes of a full copy and a encoded copy. A hadoop distributed file system-based complex redundancy scheme integrating the copy redundant mode and coding redundant mode is proposed. <b>Code</b> <b>redundancy</b> is achieved by splitting a data block into several data pieces and using random linear network coding among the pieces. When the storage node availability ranges from 0. 6 to 0. 9, with the system data availability target of 99. 999 %, the composite redundancy scheme saves over 35 % storage space than full backup scheme...|$|E
40|$|Abstract- The error {{performance}} of optical storage and Non-Volatile Memory (Flash) {{is susceptible to}} unknown offset of the retrieved signal. Balanced codes offer immunity against unknown offset {{at the cost of}} a significant <b>code</b> <b>redundancy,</b> while minimum Pearson distance detection offers immunity with low-redundant codes at the price of lessened noise margin. We will present a hybrid detection method, where the distance measure is a weighted sum of the Euclidean and Pearson distance, so that the system designer may trade noise margin versus amount of immunity to unknown offset. Key words: Constant composition code, permutation code, flash memory, digital data storage, Non-Volatile Memory...|$|E
40|$|In this paper, deep {{holes of}} Reed-Solomon (RS) codes are studied. A {{new class of}} deep holes for {{generalized}} affine RS codes is given if the evaluation set satisfies certain combinatorial structure. Three classes of deep holes for projective Reed-Solomon (PRS) codes are constructed explicitly. In particular, deep holes of PRS <b>codes</b> with <b>redundancy</b> three are completely obtained when the characteristic of the finite field is odd. Most (asymptotically of ratio $ 1 $) of the deep holes of PRS <b>codes</b> with <b>redundancy</b> four are also obtained. Comment: 31 page...|$|R
40|$|This work {{presents}} a multiple description coding (MDC) scheme for compressed three dimensional (3 D) meshes based on {{forward error correction}} (FEC). It allows flexible allocation of <b>coding</b> <b>redundancy</b> for reliable transmission over error-prone channels. The proposed scheme is based on progressive geometry compression, which is performed by using wavelet transform and modified SPIHT algorithm. The proposed algorithm is optimized for varying packet loss rates (PLR) and channel bandwidth. Modeling distortion-rate function considerably decreases computational complexity of bit allocation. Index Terms — Multiple description coding, 3 D geometry, compute...|$|R
40|$|This {{research}} {{is concerned with}} the reliable delivery of scalable compressed data over lossy communication channels. Recent works proposed several strategies for assigning optimal <b>code</b> <b>redundancies</b> to elements of scalable data, which form a linear structure of dependency, under the assumption that all source elements are encoded onto a common group of network packets. Given large data and small network packets, such schemes require very long channel codes with high computational complexity. In networks with high loss, small packets are more desirable than long packets. The first contribution of this thesis is to propose a strategy for optimally assigning elements of the scalable data to clusters of packets, subject to constraints on packet size and code complexity. Given a packet cluster arrangement, the scheme then assigns optimal <b>code</b> <b>redundancies</b> to the source elements, subject to a constraint on transmission length. Experimental results show that the proposed strategy can outperform the previous code assignment schemes subject to the above-mentioned constraints, particularly at high channel loss rates. Secondly, we modify these schemes to accommodate complex structures of dependency. Source elements are allocated to clusters of packets according to their dependency structure, subject to constraints on packet size and channel codeword length. Given a packet cluster arrangement, the proposed schemes assign optimal <b>code</b> <b>redundancies</b> to the source elements, subject to a constraint on transmission length. Experimental results demonstrate the superiority of the proposed strategies for correctly modelling the dependency structure. The last contribution of this thesis is to propose a scheme for optimizing protection of scalable data where limited retransmission is possible. Previous work assumed that retransmission is not possible. For most real-time or interactive applications, however, retransmission of lost data may be possible up to some limit. In the present work we restrict our attention to streaming sources (e. g., video) where each source element can be transmitted in one or both of two time slots. An optimization algorithm determines the transmission and level of protection for each source element, using information about the success of earlier transmissions. Experimental results confirm the benefit of limited retransmission...|$|R
