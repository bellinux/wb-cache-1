5|3|Public
40|$|AbstractHow much must I reduce my {{greenhouse}} gas (GHG) emissions if I {{want to do}} my fair share to contribute towards the global effort to keep global warming below a 2 °C rise in average temperature over preindustrial times? This paper suggests an answer for nations and corporations that want to move ahead of legislation on a voluntary basis. If all nations reduce their “GHG emissions per unit of GDP” by 5 % per year, global GHG emissions will be 50 % lower in 2050 than in 2010 {{as long as the}} global economy continues to grow at its historical rate of 3. 5 % per year. The suggested 5 % per year decline can be translated into a corporate resolution to reduce corporate “GHG emissions per unit of value added” (GEVA) by 5 % per year. If all corporations cut their GEVA by 5 % per year, the same global result will be achieved. The suggested 5 % per year decline {{can be used as a}} guideline for responsible action on a voluntary basis. The guideline is unlikely to be made mandatory soon, but <b>compulsory</b> <b>publication</b> of the necessary emissions and productivity data by nations and corporations could help civil society highlight top performers...|$|E
40|$|This is the {{originally}} published {{version of the}} article, as published by the publisher Elsevier. Paid Open Access in a hybrid journal. How much must I reduce my greenhouse gas (GHG) emissions if I want to do my fair share to contribute towards the global effort to keep global warming below a 2 °C rise in average temperature over preindustrial times? This paper suggests an answer for nations and corporations that want to move ahead of legislation on a voluntary basis. If all nations reduce their “GHG emissions per unit of GDP” by 5 % per year, global GHG emissions will be 50 % lower in 2050 than in 2010 {{as long as the}} global economy continues to grow at its historical rate of 3. 5 % per year. The suggested 5 % per year decline can be translated into a corporate resolution to reduce corporate “GHG emissions per unit of value added” (GEVA) by 5 % per year. If all corporations cut their GEVA by 5 % per year, the same global result will be achieved. The suggested 5 % per year decline {{can be used as a}} guideline for responsible action on a voluntary basis. The guideline is unlikely to be made mandatory soon, but <b>compulsory</b> <b>publication</b> of the necessary emissions and productivity data by nations and corporations could help civil society highlight top performers...|$|E
40|$|Scholars {{have long}} been {{making the case for}} {{expanding}} transparency in the international commercial arbitration system, but recently these proposals have taken on a greater sense of urgency and an apparent willingness to forcibly impose transparency reforms on unwilling parties. These new transparency advocates exhort the general public 2 ̆ 7 s stakehold in many issues being arbitrated, which they contend necessitates transparency reforms, including <b>compulsory</b> <b>publication</b> of international commercial arbitration awards. In this symposium essay, I begin by developing a definition of transparency in the adjucatory setting, and conceptually distinguishing from other concepts, like 2 ̆ 2 public access 2 ̆ 2 and 2 ̆ 2 disclosure, 2 ̆ 2 which are often improperly treated as conceptually interchangable. I argue that transparency reforms forcibly imposed on the international arbitration system are impracticable because parties could effectively avoid them by resort to 2 ̆ 2 gray-market 2 ̆ 2 arbitration. Moreover, I argue that such reforms {{would be less likely to}} serve public stakeholds than disclosure obligations, meaning national regulatory requirements that parties disclose specific categories of substantive information. Focusing on the substantive information sought, as opposed to the procedures through which it is developed, and channeling reform efforts at the national level, avoids the political and practical difficulties in implementing system-wide changes at the international level. I also argue that, while there are limits to the effectiveness of disclosure obligations, it would be premature if not counterproductive to consider imposing transparency reforms. Unlike investment arbitration or other international tribunals, where transparency reforms were produced in reaction to public outcry and corresponding governmental pressure, a range of competitive and cooperative forces within the international commercial arbitration system have induced it on a tempered, but voluntary and steady march toward greater transparency...|$|E
50|$|Local {{industry}} {{began to}} develop in the Lak district during this period. Mechanized mills and factories were built for processing raw materials. A small hydroelectric power plant was built to supply electricity. Primary-school education was made <b>compulsory.</b> Mass <b>publication</b> and distribution of books and newspapers in Lak language were initiated.|$|R
5000|$|Dutch: In the Netherlands and the Flanders {{region of}} Belgium, {{standardized}} spelling norms are <b>compulsory</b> for government <b>publications</b> and in education (see Wordlist of the Dutch language). Flemish press and media also adhere to these rules. In the Netherlands, however, the media apply a slightly adapted spelling, {{as outlined in}} the White Booklet.|$|R
50|$|Resolution of the Government of the Russian Federation {{are subject}} to <b>compulsory</b> {{official}} <b>publication,</b> except for acts or separate provisions, containing information constituting a state secret, or confidential information. Resolution of the Government of the Russian Federation must be officially published in Rossiskaya Gazeta and the Assembly of the RF legislation, within ten days from the date of signing. Control over the correctness and timeliness of publication of government decrees implementing Government Office. Other acts of the Russian government, including acts that contain information containing state secrets or confidential information, enter into force on the date of signing. The decisions of the Government of the Russian Federation can be equipped with a different order of their entry into force.|$|R
40|$|Data {{are key to}} {{empirical}} research. But data {{by themselves}} are not yet information. Raw numbers need to be transformed into measurements and, finally, into robust evidence, {{which can be used}} to help designing evidence-based policies. In this thesis, three different steps in this transformation are examined: (i) collecting good-quality data; (ii) quantifying concepts and (iii) accounting for the imperfections in quantified concepts to obtain robust evidence. Different challenges are encountered at every step. This thesis focuses on household survey data from developing countries collected by universities, NGOs or (inter) national institutions with the explicit objective of `enhancing the evidence base'. Household surveys are still the most important source of information in developing countries where administrative data are often incomplete and where `big data', such as data from mobile phones, are still in their infancy. This is unlikely to change in the near future. Monitoring the implementation of the Sustainable Development Goals is likely to increase the demand for household surveys even further. More awareness about the process of transforming raw numbers from household survey into robust evidence is therefore indispensable. The first critical step towards robust evidence is collecting high quality data since using `wrong numbers' will lead to the `wrong results'. It is often argued that the lack of data in developing countries impedes the design of sensible policies. Perhaps even more critical, however, are data of poor quality that are used to design policies or to support far-reaching reforms. The first case study in this thesis illustrates that this is indeed a real threat. Different datasets that purport to measure the impact of large-scale and controversial agricultural reforms on yields in Rwanda provide very different results. However, only the most positive estimates have been incorporated into the international data management system of the FAO, amplifying the risk that these numbers will be accepted as the `truth' and possibly used for policy design elsewhere. The second step in the transformation of raw numbers into robust evidence requires quantifying theoretical concepts. The difficulty here is that these concepts are often not directly observable. Household surveys, for instance, are frequently designed to measure the concepts of poverty or food security. Yet, these concepts are not directly observable and require the development of measurement instruments. These measurement instruments are based on a set of rules that define how observable household characteristics should be translated into the unobservable concept. The development of such measurement instruments is challenging and involves making many different assumptions. Moreover, one can always question whether the final measurement instrument measures the concept it is intended to measure and under what circumstances it measures the concept precisely and accurately. Addressing these questions in the social sciences is notoriously difficult {{because of the lack of}} gold standards or the absence of benchmarks against which a newly developed measurement instrument can be assessed. Moreover, the validity of measurement instruments should ideally be tested in many different contexts. However, in practice, social scientists work outside of a laboratory and cannot manipulate the context in which they operate. In this thesis, the challenge of quantifying concepts is illustrated by evaluating the validity of four measurement instruments: GPS to measure the directly observable concept of land area and three poverty and food insecurity indicators, which quantify unobservable concepts. The evaluation of GPS measurement of land area is straightforward as it can be assessed against the gold standard of compass and rope measurement. The evaluation of food security and poverty indicators requires more creativity since gold standards are unavailable. The three case studies of poverty and food security indicators are used to illustrate three different aspect of validity: cross-sectional validity, inter-temporal validity and internal validity. The first indicator, the Progress out of Poverty Index (PPI) in Rwanda, is benchmarked against expenditure data. It turns out that this indicator is cross-sectionally valid, that is, it consistently distinguishes poor from non-poor households. The second indicator, the Household Food Insecurity Access Scale (HFIAS), is benchmarked against total agricultural production. This indicator is cross-sectionally valid, but its inter-temporal validity is questionable. While total food production decreased over a period of five years, the HFIAS pointed towards an improved food security situation over the same period. This implies that the indicator cannot be used to monitor the evolution of food security over time. The third food security indicator, the Household Dietary Diversity Score (HDDS), is not assessed against an external benchmark. Instead, its internal validity is evaluated using Rasch models. In other words, it is analyzed if the different food groups included in the HDDS measure a single underlying concept. This is not the case, raising the question of what the HDDS actually measures. Even with good-quality data and excellent measurement instruments, concepts may still be imprecisely or inaccurately measured. Hence, the third and final step of the transformation of raw numbers into robust evidence consists of accounting for these imperfections when establishing (causal) relations between two (or more) imperfectly measured concepts. To illustrate the relevance of accounting for measurement error, it is shown that imprecise measurement of the harvest at plot level can generate a spurious, negative correlation between productivity and plot size. This has implications for the stylized fact of the inverse productivity-size relationship. The transformation of raw numbers into robust evidence is a long journey with several steps along the way, all of which are decisive for the final outcome. At every step, new challenges need to be tackled. This requires skilful interventions by researchers and an open discussion about the minimum set of assumptions needed to overcome the challenges. These steps also hold some implications for the interpretation of the final outcome of the journey: robust evidence. A first policy implication is that the academic community pays more attention to the issue of data quality. The <b>compulsory</b> <b>publication</b> of the data alongside journal articles would be an important first step in this process. In addition, studying systematic measurement error can help to limit bias in empirical work and to improve survey design. A second implication has to do with the development of measurement instruments, and in particular, poverty and food security indicators. There is definitely a demand for indicators that can quickly estimate the prevalence of poverty and food insecurity at a regional level in order to monitor development programmes, target the most vulnerable household and design policies. Yet, with so many indicators in existence, choosing the one that is most useful for the purpose at hand is complicated since every indicator has its own strengths and weaknesses. More validation exercises of existing indicators could help to clarify the circumstances under which a particular indicator works and/or is useful. An important advantage of these `validity exercises' is that researchers will remain keenly aware of the shortcomings of a particular indicator, which are likely to be context-specific. Given the existence of so many indicators one can argue that the validation of existing indicators should be prioritized over the development of yet more indicators. Finally, we should remain aware that the principal driver for funding the collection and interpretation of raw numbers is the call for more `evidence-based policy'. The main –- and perhaps unexpected –- lesson of this thesis is that `quantitative evidence' should not be considered the gold standard for the design of evidence-based policies. Quantitative evidence is man-made and needs to be complemented by other sets of evidence when designing policies. Researchers should be at the forefront of weighing the quality of different evidence bases and of attempting to synthesize them...|$|E

