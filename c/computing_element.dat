91|1227|Public
5000|$|CEMon- {{responsible}} for providing information coming from the <b>computing</b> <b>element</b> (CE) ...|$|E
5000|$|CREAM- Computing Resource Execution And Management Service for job {{management}} operation at the <b>computing</b> <b>element</b> (CE) level ...|$|E
5000|$|Grid2Win- {{a project}} aiming {{to create a}} gLite User Interface (UI) and a gLite <b>Computing</b> <b>Element</b> (CE) running on Microsoft Windows ...|$|E
40|$|There is {{a growing}} trend of {{combining}} human-based computation with machine-based computation to solve complex problems which cannot be answered with machine-based computation alone. From the computing perspective, integrating machine-based <b>computing</b> <b>elements</b> with human-based <b>computing</b> <b>elements</b> and provisioning them under the same model will facilitate the resource elasticity required by complex applications. Although certain works investigate techniques for integrating human-based <b>computing</b> <b>elements</b> with machine-based <b>computing</b> <b>elements,</b> existing <b>computing</b> models for such integrated computing systems are very limited. In fact, the architectures, interconnections, non-functional properties of human-based <b>computing</b> <b>elements</b> {{are very different from}} that of contemporary machine-based counterparts. Human-based <b>computing</b> <b>elements</b> are built based on social and bio concepts, thus their architectures, interconnects and non-functional properties are extremely complex and dynamic, compared with that of machine-based <b>computing</b> <b>elements.</b> In this paper, we examine fundamental issues in virtualizing human-based <b>computing</b> <b>elements</b> and machine-based <b>computing</b> <b>elements</b> using service-oriented <b>computing</b> concepts in order to create highly scalable computing systems of hybrid services to support the elasticity of software and people in complex applications. We will outline our Vienna Elastic Computing Model which aims at introducing techniques and frameworks to support multi-dimensional elastic processes atop multiple cloud systems of software-based and human-based services. This paper will analyze several service management issues to support the virtualization of machine-based and human-based <b>computing</b> <b>elements</b> to support such elastic processes...|$|R
40|$|We {{built as}} a trial an {{electronic}} analog <b>computing</b> <b>elements</b> with linear integrated circuits (IC), which are constructed of twelve summing amplifiers, six summing integrators and five time-division analog multipliers. Compared with transistor amplifiers, IC amplifiers have advantage in respect to size, power requirements, adjustment and reliability. Static errors of these linear and nonlinear <b>computing</b> <b>elements</b> are within 0. 05 and 0. 1 per cent of full-scale, respectively. These electronic analog <b>computing</b> <b>elements</b> are accurate enough for practical usage...|$|R
5000|$|Write {{elements}} of 1st column : 1, 1, 4, 3, 2, 4 (contains 4 quotients) <b>Compute</b> <b>elements</b> of 2nd column : 1, 1, 4, 10, 2 (contains 3 quotients) <b>Compute</b> <b>elements</b> of 3rd column : 1, 1, 42, 10 (contains 2 quotients) <b>Compute</b> <b>elements</b> of 4th column : 1, 52, 42 (contains 1 quotient) <b>Compute</b> <b>elements</b> of 5th column : 94, 52 (contains no quotients) [...] The computational procedure is shown below: [...] Quotient 1 : 1 1 1 1 94 [...] Quotient 2 : 1 1 1 52 (52×1 + 42 = 94) 52 [...] Quotient 3 : 4 4 42 (42×1 + 10 =52) 42 [...] Quotient 4 : 3 10 (10×4 + 2 = 42) 10 [...] k : 2 (2×3 + 4 = 10) 2 [...] Difference : 4 of remainders ...|$|R
50|$|The {{purpose of}} the Workload Management System (WMS) is to accept user jobs, to assign them to the most {{appropriate}} <b>Computing</b> <b>Element,</b> to record their status and retrieve their output. The Resource Broker (RB) is the machine where the WMS services run.|$|E
5000|$|Unfortunately, the Cyclone was {{completed}} {{just as the}} transistor was replacing the vacuum tube as an active <b>computing</b> <b>element.</b> The Cyclone had about 2,500 vacuum tubes, 1,521 of which were type 5844. (The IBM 1401 computer, announced the same year, was fully transistorized. About 15,000 IBM 1401 machines were produced.) ...|$|E
50|$|The 5400 and 7400 series {{were used}} in many popular {{minicomputers}} in the 1970s and early 1980s. Some models of the DEC PDP series 'minis' used the 74181 ALU as the main <b>computing</b> <b>element</b> in the CPU. Other examples were the Data General Nova series and Hewlett-Packard 21MX, 1000, and 3000 series.|$|E
25|$|Other <b>computing</b> <b>elements</b> include analog multipliers, {{nonlinear}} function generators, and analog comparators.|$|R
5000|$|<b>Compute</b> <b>elements</b> {{may have}} {{different}} instruction set architectures, leading to binary incompatibility.|$|R
50|$|Parallel {{computing}} {{focuses on}} improving {{the performance of}} the computers/algorithms through the use of several <b>computing</b> <b>elements</b> (such as processing <b>elements).</b> The <b>computing</b> speed is improved by using several <b>computing</b> <b>elements.</b> Parallel <b>computing</b> is an extension of conventional sequential computing. However, in lateral computing, the problem is solved using unconventional information processing whether using a sequential or parallel computing.|$|R
50|$|A <b>Computing</b> <b>Element</b> (CE), in Grid terminology, is some set of {{computing}} resources localized {{at a site}} (i.e. a cluster, a computing farm). A CE includes a Grid Gate (GG), which acts as a generic interface to the cluster; a Local Resource Management System (LRMS) (sometimes called batch system), and the cluster itself, a collection of Worker Nodes (WNs), the nodes where the jobs are run.|$|E
50|$|Advanced Resource Connector (ARC) is a grid {{computing}} middleware {{introduced by}} NorduGrid. It provides a common interface for submission of computational tasks to different distributed computing systems {{and thus can}} enable grid infrastructures of varying size and complexity. The set of services and utilities providing the interface is known as ARC <b>Computing</b> <b>Element</b> (ARC-CE). ARC-CE functionality includes data staging and caching, developed {{in order to support}} data-intensive distributed computing. ARC is an open source software distributed under the Apache License 2.0.|$|E
5000|$|Reflective {{memory was}} {{developed}} in the 1980s by VMIC for applications in VME systems 2. Usually reflective memory devices are connected together by means of fiber optic. It is commonly used with real-time operating systems, VXI and other platforms. VMIC was acquired by GE Fanuc, a cooperative venture between GE and Fanuc of Japan. This business became GE Intelligent Platforms, and the embedded <b>computing</b> <b>element</b> of the business was spun off in 2015 as Abaco Systems, who now market reflective memory.|$|E
5000|$|Library and OS {{services}} {{may not be}} uniformly available to all <b>compute</b> <b>elements.</b>|$|R
5000|$|... the <b>compute</b> <b>elements</b> run the Catamount {{microkernel}} (which {{itself is}} based on Cougaar) ...|$|R
5000|$|... the <b>compute</b> <b>elements</b> run <b>Compute</b> Node Linux (CNL) (which is a {{customized}} Linux kernel) ...|$|R
5000|$|Receiving a $3,000 investment, Gerber {{patented}} his Variable Scale {{and founded}} the Gerber Scientific Instrument Company in Hartford, Conn. {{to produce and}} market the device. Before {{the widespread use of}} digital computers, performing computations based on graphically recorded data and curves was extremely time-consuming and complex. The Gerber Variable Scale—which used a triangular calibrated spring as a <b>computing</b> <b>element</b> to eliminate all scaling and conversions between numerics and graphics—provided means for quick, efficient calculations, [...] and became known as the greatest engineering tool since the slide rule.|$|E
5000|$|Contrary to {{the purely}} spatial {{computing}} model of FPGA, a reconfigurable computing platform that employs a temporal computing model (or {{a combination of}} both temporal and spatial) has also been investigated [...] in the context of improving performance and energy over conventional FPGA. These platforms, referred as Memory Based Computing (MBC), use dense two-dimensional memory array to store the LUTs. Such frameworks rely on breaking a complex function (f) into small sub-functions; representing the sub-functions as multi-input, multi-output LUTs in the memory array; and evaluating the function f over multiple cycles. MBC can leverage on the high density, low power and high performance advantages of nanoscale memory. [...] shows the high-level block diagram of MBC. Each <b>computing</b> <b>element</b> incorporates a two-dimensional memory array for storing LUTs, a small controller for sequencing evaluation of sub-functions and a set of temporary registers to hold the intermediate outputs from individual partitions. A fast, local routing framework inside each computing block generates the address for LUT access. Multiple such computing elements can be spatially connected using FPGA-like programmable interconnect architecture to enable mapping of large functions. The local time-multiplexed execution inside the computing elements can drastically reduce the requirement of programmable interconnects leading to large improvement in energy-delay product and better scalability of performance across technology generations. The memory array inside each <b>computing</b> <b>element</b> can be realized by Content-addressable memory (CAM) to drastically reduce the memory requirement for certain applications.|$|E
50|$|Computing with Memory {{refers to}} {{computing}} platforms where function response {{is stored in}} memory array, either one or two-dimensional, {{in the form of}} lookup tables (LUTs) and functions are evaluated by retrieving the values from the LUTs. These computing platforms can follow either a purely spatial computing model, as in Field-programmable gate array (FPGA), or a temporal computing model, where a function is evaluated across multiple clock cycles. The latter approach aims at reducing the overhead of programmable interconnect in FPGA by folding interconnect resources inside a <b>computing</b> <b>element.</b> It uses dense two-dimensional memory arrays to store large multiple-input multiple-output LUTs. Computing with Memory differs from Computing in Memory or Processor-in-memory (PIM) concepts, widely investigated in the context of integrating a processor and memory on the same chip to reduce memory latency and increase bandwidth. These architectures seek to reduce the distance the data travels between the processor and the memory. The Berkeley IRAM project is one notable contribution in the area of PIM architectures.|$|E
50|$|GridLite is a {{framework}} being developed at HP Labs that allows mobile/ubiquitous <b>computing</b> <b>elements</b> {{to act as}} part of computing grids.|$|R
3000|$|... (i)Each {{row of the}} [...] "Data in Threads" [...] table {{shows the}} <b>computed</b> <b>elements</b> {{labelled}} according to the equivalent input data locations.|$|R
50|$|Later, he {{conducted}} initial design {{work with other}} scientists such as John von Neumann, Vannevar Bush, and Claude Shannon on emerging <b>computing</b> <b>elements,</b> including ciphering.|$|R
30|$|Physically, the {{elementary}} <b>computing</b> <b>element</b> is the <b>computing</b> <b>element.</b> A few <b>computing</b> <b>element</b> {{together with a}} given amount of SDRAM, scheduling unit, and special function unit forms a computing unit (CU). A device consists of several CUs and a global memory (off-chip).|$|E
40|$|The {{nonlinear}} frustrated-total-reflection filter {{is proposed}} as a remarkably simple all-optical <b>computing</b> <b>element.</b> Potential advantages of this device over nonlinear prism couplers and nonlinear thin films are presented. Optical bistability is experimentally demonstrated {{by using a}} liquid crystal as an optically nonlinear material. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|E
40|$|International audienceNowadays {{computer}} applications are becoming heavier and require, {{at the same}} time, real-time results. The Heterogeneous clusters with their computing power represent a good solution to this request. However, {{it is possible that}} during the execution, a <b>computing</b> <b>element</b> of the cluster becomes defaulting, needs maintenance, or that the load needs to be re-balanced... In this paper, we propose a migration strategy for relocating the execution of a task to another <b>computing</b> <b>element.</b> In particular, we are interested in remap nodes of Data Flow Graph (DFG), representing Digital Signal Processing (DSP) application, onto heterogeneous (CPU-GPU) clusters while keeping up the flow of data and minimizing the temporal perturbation. For our approach, we give a lower bound for the flow of data after the migration and, validate it by the real-time construction of visual saliency map from video input...|$|E
5000|$|<b>Compute</b> <b>elements</b> may {{interpret}} {{memory in}} different ways. This may include both endianness, calling convention, and memory layout, and depends {{on both the}} architecture and compiler being used.|$|R
40|$|We discuss {{cellular}} automata (CA) architectural {{considerations that}} led to the design of the cam- 8 CA machine; describe some of the spatial modeling tasks that CA's have been applied to on this machine; and discuss some of the interesting practical and theoretical modeling challenges that remain. 1 Introduction For the past 20 years, feature sizes of <b>computing</b> <b>elements</b> have decreased at a rather constant exponential rate. If these trends are extrapolated forwards, we will have <b>computing</b> <b>elements</b> the size of an atom in about 20 years. Clearly there are new kinds of difficulties, and new kinds of physics, that will intervene as we try to scale down towards atomic dimensions. One of the first difficulties we will encounter will be with wires. Trying to make conducting elements that are very narrow, and trying to drive them with near-atomic-scale systems will be a tremendous problem. One solution is to build computers that have no wires[18, 8, 1]. Uniform arrays of <b>computing</b> <b>elements,</b> eac [...] ...|$|R
50|$|There {{are simple}} {{algorithms}} to <b>compute</b> all the <b>elements</b> {{in a row}} or diagonal without <b>computing</b> other <b>elements</b> or factorials.|$|R
40|$|Describes the {{architecture}} of a parallel computera 3 called multidimensional multilink system (MMS) which was designed and developed at the Indian Institute of Science. This system is a general-purpose multicomputer where each <b>computing</b> <b>element</b> comprises a processor and its local memory. The computing elements communicate using message passing. There is no shared memory in the syste...|$|E
40|$|This screen demo {{introduces}} {{an educational}} function of VisualFEA {{for teaching and}} learning the procedure of <b>computing</b> <b>element</b> stiffness matrices in finite element method. The step by step process of numerical integration is displayed using graphical images and numerical expressions. The purpose of the function is to study the computational details through inspecting the numerical data produced in the integration process. 1 _mag 2 tmc...|$|E
40|$|Various systems, methods, and {{computing}} {{units are}} provided for variable scaling of computing elements. In one representative embodiment, a method comprises: receiving {{a plurality of}} computing resource levels; and providing one of the plurality of computing resource levels to each of a plurality of computing elements, each <b>computing</b> <b>element</b> having an associated output, the provided voltage level based upon associated output significance. Georgia Tech Research Corporatio...|$|E
40|$|Autonomic (self-managing) {{computing}} systems {{face the}} critical problem of resource allocation to different <b>computing</b> <b>elements.</b> Adopting a recent model, we view {{the problem of}} provisioning resources as involving utility elicitation and optimization to allocate resources given imprecise utility information. In this paper, we propose a new algorithm for regret-based optimization that performs significantly faster than that proposed in earlier work. We also explore new regret-based elicitation heuristics {{that are able to}} find near-optimal allocations while requiring a very small amount of utility information from the distributed <b>computing</b> <b>elements.</b> Since regret-computation is intensive, we compare these to the more tractable Nelder-Mead optimization technique w. r. t. amount of utility information required. ...|$|R
40|$|Commercial FPGA {{companies}} now provide tools that allow users to implement designs comprising soft-core processors and modules of dedicated logic. If a designer chooses to partition a system into multiple processors and hardware modules, tools and techniques for design analysis {{are necessary to}} understand system performance. This paper introduces WOoDSTOCK, a tool that profiles system performance by adding monitors to the circuit running in real time on the chip. The user is able to generate a system specific profiler tailored to monitor the communication links between the different <b>computing</b> <b>elements.</b> This provides a macroscopic picture of system performance, which highlights the <b>computing</b> <b>elements</b> that cause bottlenecks in the design...|$|R
40|$|This paper {{presents}} an approach for efficiently mapping loops and array intensive applications onto FPGA architectures with distributed RAMs, multipliers and logic. We perform a data dependency based, two level partitioning of the application’s iteration space under target FPGA architectural constraints, to achieve better performance. It is shown that, this approach {{can result in}} a super-linear speedup; linear speedup due to concurrent computation on multiple <b>compute</b> <b>elements</b> and additional speedup due to improvement in the clock frequency (up to 30 %). The clock period reduction is made possible because computation and accesses are now localized, i. e. the <b>compute</b> <b>elements</b> interact only with memories which are close by. ...|$|R
