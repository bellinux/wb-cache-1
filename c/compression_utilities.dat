30|60|Public
50|$|Versions of Windows {{using the}} NT kernel, {{including}} {{the most recent}} versions, XP and Vista, contain intrinsic disk compression capability. The use of separate disk <b>compression</b> <b>utilities</b> has declined sharply.|$|E
50|$|Not all <b>compression</b> <b>utilities</b> would {{confirm the}} absence of errors in the FAT file system before {{compressing}} a disk in place. Some errors, such as crosslinked files, could result in additional data loss during the transfer process.|$|E
50|$|Command line {{interfaces}} {{for software}} other than operating systems include {{a number of}} programming languages such as Tcl/Tk, PHP and others, as well as utilities such as the <b>compression</b> <b>utilities</b> WinZip and UltimateZip, and some FTP and ssh/telnet clients.|$|E
50|$|A disk <b>compression</b> <b>utility</b> {{increases}} {{the amount of}} information that can be stored on a hard disk drive of given size. Unlike a file <b>compression</b> <b>utility</b> which compresses only specified files - and which requires the user designate the files to be compressed - an on-the-fly disk <b>compression</b> <b>utility</b> works automatically without the user needing to be aware of its existence.|$|R
50|$|A disk <b>compression</b> {{software}} <b>utility</b> {{increases the}} amount of information that can be stored on a hard disk drive of given size. Unlike a file <b>compression</b> <b>utility,</b> which compresses only specified files—and which requires the user to designate the files to be compressed—an on-the-fly disk <b>compression</b> <b>utility</b> works automatically without the user needing to be aware of its existence. When information needs to be stored to the hard disk, the utility will compress the information. When information needs to be read, the utility will decompress the information. A disk <b>compression</b> <b>utility</b> overrides the standard operating system routines. Since all software applications access the hard disk using these routines, they continue to work after disk compression has been installed.|$|R
5000|$|Compression - {{general purpose}} <b>compression</b> <b>utility,</b> similar to ZIP (file format) ...|$|R
5000|$|With {{increasing}} PC processor power software-only solutions {{began to}} reach or even outperform {{the performance of}} hardware-assisted solutions in most scenarios. These <b>compression</b> <b>utilities</b> were sold independently. A user had to specifically choose to install and configure the software.|$|E
5000|$|... {{compress}} is a Unix shell compression program {{based on}} the LZW compression algorithm. Compared to more modern <b>compression</b> <b>utilities</b> such as gzip and bzip2, compress performs faster and with less memory usage, {{at the cost of}} a significantly lower compression ratio.|$|E
50|$|As Aladdin Systems, they {{originally}} developed exclusively for Macintosh, focusing on data compression and management utilities, {{such as the}} StuffIt family of <b>compression</b> <b>utilities</b> and the StuffIt InstallerMaker delivery suite, the ShrinkWrap disk image utility, and its Spring Cleaning system optimization utility.|$|E
5000|$|PKZIP, the <b>compression</b> <b>utility</b> {{that quickly}} became the {{standard}} in file compression.|$|R
50|$|KGB Archiver is a file archiver {{and data}} <b>{{compression}}</b> <b>utility</b> {{based on the}} PAQ6 compression algorithm.|$|R
5000|$|Headers in ZIP files {{begin with}} [...] "PK" [...] ( [...] ), the {{initials}} of Phil Katz, author of DOS <b>compression</b> <b>utility</b> PKZIP.|$|R
50|$|With {{the huge}} leaps in hard drive {{capacity}} and lower costs for these ever larger drives, {{and the building}} of compression into late versions of DOS and Windows, the need for SQZ! and other file <b>compression</b> <b>utilities</b> disappeared and the SQZ! product was discontinued by the mid 1990s.|$|E
50|$|LZW {{was used}} in the public-domain program compress, which became a more or less {{standard}} utility in Unix systems around 1986. It has since disappeared from many distributions, both because it infringed the LZW patent and because gzip produced better compression ratios using the LZ77-based DEFLATE algorithm, but as of 2008 at least FreeBSD includes both compress and uncompress {{as a part of the}} distribution. Several other popular <b>compression</b> <b>utilities</b> also used LZW or closely related methods.|$|E
50|$|This was {{the first}} version of Plus! and had an initial cost of US$ 49.99. It {{included}} Space Cadet Pinball, the Internet Jumpstart Kit (which was the introduction of Internet Explorer 1.0), DriveSpace 3 and Compression Agent disk <b>compression</b> <b>utilities,</b> the initial release of theme support along with a set of 12 themes, dial-up networking server, dial-up scripting tool, and the graphical improvements such as anti-aliased screen fonts, full-window drag, the ability to stretch or shrink the wallpaper to fit the screen and highcolor icons.|$|E
50|$|It was {{a virtual}} memory <b>compression</b> <b>utility</b> for Windows 3.1, Windows For Workgroups and Windows 95. MagnaRAM is {{included}} with QEMM 97.|$|R
50|$|When {{information}} {{needs to be}} stored to the hard disk, the utility will compress the information. When {{information needs}} to be read, the utility will decompress the information. A disk <b>compression</b> <b>utility</b> overrides the standard operating system routines. Since all software applications access the hard disk using these routines, they continue to work after disk compression has been installed. The compression/expansion process adds {{a small amount of}} overhead to disk access and may complicate error recovery on the affected volume. Also, if the <b>compression</b> <b>utility's</b> device driver was uninstalled or became corrupted, all data on the disk would be lost.|$|R
2500|$|Long {{after the}} [...] "venerable old Beeb" [...] was superseded, {{additional}} {{hardware and software}} has been developed. Such developments have included Sprow's 1999 zip <b>compression</b> <b>utility</b> and a ROM Y2K bugfix for the BBC Master.|$|R
50|$|Genetics {{compression}} algorithms (not to {{be confused}} with genetic algorithms) are the latest generation of lossless algorithms that compress data (typically sequences of nucleotides) using both conventional compression algorithms and specific algorithms adapted to genetic data. In 2012, a team of scientists from Johns Hopkins University published the first genetic compression algorithm that does not rely on external genetic databases for compression. HAPZIPPER was tailored for HapMap data and achieves over 20-fold compression (95% reduction in file size), providing 2- to 4-fold better compression and in much faster time than the leading general-purpose <b>compression</b> <b>utilities.</b>|$|E
5000|$|Several other Mac <b>compression</b> <b>utilities</b> {{appeared}} and disappeared during the 1990s, but none became {{a real threat}} to StuffIt's dominance. The only ones to see any widespread use were special-purpose [...] "disk expanders" [...] like DiskDoubler and SuperDisk!, which served a different niche. Apparently as a side-effect, StuffIt once again saw few upgrades. The file format changed {{in a number of}} major revisions, leading to incompatible updates. PC-based formats long surpassed StuffIt in terms of compression, notably newer systems like RAR and 7z. These had little impact on the Mac market, as most of these never appeared in an easy-to-use program on the Mac.|$|E
50|$|Complexity (variable): With Speex, it is {{possible}} to vary the complexity allowed for the encoder. This is done by controlling how the search is performed with an integer ranging from 1 to 10 in a way similar to the -1 to -9 options to gzip <b>compression</b> <b>utilities.</b> For normal use, the noise level at complexity 1 is between 1 and 2 dB higher than at complexity 10, but the CPU requirements for complexity 10 is about five times higher than for complexity 1. In practice, the best trade-off is between complexity 2 and 4, though higher settings are often useful when encoding non-speech sounds like DTMF tones, or if encoding is not in real-time.|$|E
5000|$|FCX file {{compression}} is a file <b>compression</b> <b>utility</b> and file format. [...] It is supported {{on a large}} number of platforms. [...] It is published by Compact Data Works and was originally released in 1988 for VAX/VMS.|$|R
50|$|Synex Systems {{products}} were diverse and targeted accounting, civil engineering, minicomputer thin client, and file <b>compression</b> <b>utility</b> markets. By 2001 the concentration was {{only on the}} accounting reporting product F9 and all other {{products were}} discontinued or sold.|$|R
50|$|Stac Electronics, {{originally}} incorporated as State of the Art Consulting {{and later}} shortened to Stac, Inc., was a technology company founded in 1983. It is known primarily for its Lempel-Ziv-Stac lossless compression algorithm and Stacker disk <b>compression</b> <b>utility</b> for compressing data for storage.|$|R
50|$|Disk <b>compression</b> <b>utilities</b> {{were popular}} {{especially}} in the early 1990s, when microcomputer hard disks were still relatively small (20 to 80 megabytes). Hard drives were also rather expensive at the time, costing roughly 10 USD per megabyte. For the users who bought disk compression applications, the software proved {{to be in the}} short term a more economic means of acquiring more disk space as opposed to replacing their current drive with a larger one. A good disk compression utility could, on average, double the available space with negligible speed loss. Disk compression fell into disuse by the late 1990s, as advances in hard drive technology and manufacturing led to increased capacities and lower prices.|$|E
50|$|Genetics {{compression}} algorithms are {{the latest}} generation of lossless algorithms that compress data (typically sequences of nucleotides) using both conventional compression algorithms and genetic algorithms adapted to the specific datatype. In 2012, {{a team of scientists}} from Johns Hopkins University published a genetic compression algorithm that does not use a reference genome for compression. HAPZIPPER was tailored for HapMap data and achieves over 20-fold compression (95% reduction in file size), providing 2- to 4-fold better compression and in much faster time than the leading general-purpose <b>compression</b> <b>utilities.</b> For this, Chanda, Elhaik, and Bader introduced MAF based encoding (MAFE), which reduces the heterogeneity of the dataset by sorting SNPs by their minor allele frequency, thus homogenizing the dataset. Other algorithms in 2009 and 2013 (DNAZip and GenomeZip) have compression ratios of up to 1200-fold—allowing 6 billion basepair diploid human genomes to be stored in 2.5 megabytes (relative to a reference genome or averaged over many genomes).|$|E
40|$|Abstract: The growing {{computational}} {{and storage}} needs of several scientific applications mandate {{the deployment of}} extreme-scale parallel machines, such as IBM’s Blue Gene/L which can accommodate as many as 128 K processors. One {{of the biggest challenges}} these systems face, is to manage generated system logs while deploying in production environments. Large amount of log data is created over extended period of time, across thousands of processors. These logs generated can be voluminous because of the large temporal and spatial dimensions, and containing records which are repeatedly entered to the log archive. Storing and transferring such large amount of log data is a challenging problem. Commonly used generic <b>compression</b> <b>utilities</b> are not optimal for such large amount of data considering a number of performance requirements. In this paper we propose a compression algorithm which preprocesses these logs before trying out any standard <b>compression</b> <b>utilities.</b> The compression ratios and times for the combination shows 28. 3 % improvement in compression ratio and 43. 4 % improvement in compression time on average over different generic <b>compression</b> <b>utilities.</b> The test data used is log data produced by 64 racks, 65536 processor Blue Gene/L installation at Lawrence Livermore National Laboratory...|$|E
50|$|In computing, DGCA is a {{freeware}} <b>compression</b> <b>utility</b> {{created in}} 2001 by Shin-ichi Tsuruta (Tsuruta Shin'ichi). DGCA {{is also a}} compressed archive format, {{the next generation of}} 'GCA'. DGCA has a better compression ratio than ZIP, stronger encryption and Unicode filenames. However, DGCA is not a major compression format.|$|R
50|$|SQZ! is a <b>compression</b> <b>utility</b> {{specifically}} designed to compress spreadsheet files and was marketed starting 1986. Sqz! is available as an add-in for 1-2-3 Release 2/2.01, and as a terminate-and-stay-resident (TSR) utility for any version of 1-2-3, Symphony or any other programs that read or write 1-2-3 R2 format worksheets.|$|R
50|$|Since {{the late}} 1990s, bzip2, a file <b>compression</b> <b>utility</b> {{based on a}} block-sorting algorithm, has gained some {{popularity}} as a gzip replacement. It produces considerably smaller files (especially for source code and other structured text), but {{at the cost of}} memory and processing time (up to a factor of 4).|$|R
40|$|The growing {{computational}} {{and storage}} needs of several scientific applications mandate {{the deployment of}} extreme-scale parallel machines, such as IBM’s Blue Gene/L which can accommodate as many as 128 K processors. One {{of the biggest challenges}} these systems face, is to manage generated system logs while deploying in production environments. Large amount of log data is created over extended period of time, across thousands of processors. These logs generated can be voluminous because of the large temporal and spatial dimensions, and containing records which are repeatedly entered to the log archive. Storing and transferring such large amount of log data is a challenging problem. Commonly used generic <b>compression</b> <b>utilities</b> are not optimal for such large amount of data considering a number of performance requirements. In this paper we propose a compression algorithm which preprocesses these logs before trying out any standard <b>compression</b> <b>utilities.</b> The compression ratios and times for the combination shows 28. 3 % improvement in compression ratio and 43. 4 % improvement in compression time on average over different generic <b>compression</b> <b>utilities.</b> The test data used is log data produced by 64 racks, 65536 processor Blu...|$|E
40|$|Abstract—The {{health and}} fitness data traffic {{originating}} on mobile devices has been continually increasing, with an exponen-tial {{increase in the number}} of personal wearable devices and mobile health monitoring applications. Lossless data compression can increase throughput, reduce latency, and achieve energy-efficient communication between personal devices and the cloud. This paper experimentally explores the effectiveness of common <b>compression</b> <b>utilities</b> on mobile devices when uploading and downloading a representative mHealth data set. Based on the results of our study, we develop recommendations for effective data transfers that can assist mHealth application developers. Keywords—mobile sensing; health monitoring; wearable devic-es; data communication. I...|$|E
40|$|Abstract — Lossless {{compression}} and decompression are routinely used in mobile computing devices {{to reduce the}} costs of communicating and storing data. This paper {{presents the results of}} an experimental evaluation of common <b>compression</b> <b>utilities</b> on Pandaboard, a development platform similar to current commercial mobile devices. We study the compression ratio, {{compression and}} decompression throughput, and energy efficiency of different usage scenarios typical for mobile computing. We observe a wide variety of energy costs associated with data compression and provide practical guidelines for selecting the most energy-efficient configurations. Keywords—mobile computing; measurement techniques; data compression; energy-aware systems This work is supported by NSF grants 1205439, 1217231 and 1217470. I...|$|E
50|$|DriveSpace (initially {{known as}} DoubleSpace) is a disk <b>compression</b> <b>utility</b> {{supplied}} with MS-DOS starting from version 6.0. The purpose of DriveSpace {{is to increase}} the amount of data the user could store on disks, by transparently compressing and decompressing data on-the-fly. It is primarily intended for use with hard drives, but use for floppy disks is also supported.|$|R
50|$|ALZip is {{an archive}} and <b>{{compression}}</b> <b>utility</b> from ESTsoft for Microsoft Windows.ALZip is a file compression program that can unzip 40 different zip file archives.ALZip can zip files into 8 different archives such as ZIP, EGG, TAR and others. In ALZip version 8, ALZip’s own EGG format, that Unicode and other powerful function supported, can be used.|$|R
50|$|PackIt is a {{software}} data <b>compression</b> <b>utility</b> for archiving and compressing files on the Apple Macintosh platform. It {{was the first}} such program to see widespread use on the Mac, and most Mac software archives accepted uploads only in PackIt format for some time. StuffIt, introduced {{in the summer of}} 1987, offered much improved compression, and PackIt quickly disappeared.|$|R
