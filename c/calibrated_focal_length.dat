2|4485|Public
40|$|Recent {{developments}} of digital cameras {{in terms of}} size of Charged Coupled Device (CCD) arrays and reduced costs are leading to their applications to traditional {{as well as new}} photogrammetric, surveying, and mapping functions. Digital cameras, intended to replace the conventional film based mapping cameras, are becoming available along with many smaller format digital cameras capable of precise measurement applications. All such cameras require careful assessment to determine their metric characteristics, which are essential to carry out photogrammetric activities. These characteristics include estimates of the <b>calibrated</b> <b>focal</b> <b>length,</b> location of the principal point relative to the array coordinate system, lens distortion, and the short and long-term stability of these quantities. These characteristics are known collectively as the Interior Orientation Parameters (IOP). Current calibration methods are based on traditional test fields with numerous distinct targets, which have to be professionally surveyed prior to the calibration procedure in order to precisely determine their three-dimensional coordinates. Establishing, surveying, and maintaining traditional calibration test fields are very expensive and not easy tasks for non-photogrammetric users of digital cameras. This paper relates {{to the development of a}} new laboratory calibration procedure that requires an easy-to-establish calibration test field (group of straight lines). In addition, the whole calibration process can be automatically carried out with minimal human interaction. It is expected that this calibration procedure would provide a good tool for studying the short and long-term stability of off-the-shelf digital cameras. In addition, it will give a great push to using those cameras in large scale mapping applications as well as various close range photogrammetric activities. 1...|$|E
40|$|The article {{presents}} {{a set of}} initial results of a quality assessment study of 2 different types of sensors mounted on an unmanned aerial vehicle, carried out over an especially designed and constructed test field. The PIQuAT (Portable Imagery Quality Assessment Test Field) field had been designed especially {{for the purposes of}} determining the quality parameters of UAV sensors, especially in terms of the spatial, spectral and radiometric resolutions and chosen geometric aspects. The sensor used include a multispectral framing camera and a high-resolution RGB sensor. The flights were conducted from a number of altitudes ranging from 10 m to 200 m above the test field. Acquiring data at a number of different altitudes allowed the authors to evaluate the obtained results and check for possible linearity of the calculated quality assessment parameters. The radiometric properties of the sensors were evaluated from images of the grayscale target section of the PIQuAT field. The spectral resolution of the imagery was determined based on a number of test samples with known spectral reflectance curves. These reference spectral reflectance curves were then compared with spectral reflectance coefficients at the wavelengths registered by the miniMCA camera. Before conducting all of these experiments in field conditions, the interior orientation parameters were calculated for the MiniMCA and RGB sensor in laboratory conditions. These parameters include: the actual pixel size on the detector, distortion parameters, <b>calibrated</b> <b>focal</b> <b>length</b> (CFL) and the coordinates of the principal point of autocollimation (miniMCA - for each of the six channels separately...|$|E
40|$|Abstract- For {{omnidirectional}} cameras, most of {{the previous}} calibration methods from lines use conic fitting. This paper presents a calibration method for para-catadioptric-like cameras from lines without conic fitting under a single view. We establish equations on the five camera intrinsic parameters. These equations are linear for the <b>focal</b> <b>lengths</b> and skew factor once the principal point is known. The principal point can be approximated well by {{the center of the}} imaged mirror contour in practice or can be accurately estimated by quadric equations. After obtaining the principal point, we propose an algorithm to <b>calibrate</b> the <b>focal</b> <b>lengths</b> and skew factor. The algorithm needs neither prior structure knowledge nor conic fitting and is linear, which make it easy to implement. Other omnidirectional cameras can also use this presented work if high accuracy is not required. Experiments demonstrate the efficiency of the proposed algorithm...|$|R
40|$|In this article, {{we present}} the {{projective}} equation {{of a circle}} in a perspective view, which naturally encodes such important geometric entities as the projected circle center, the vanishing point of the normal direction of the circle’s supporting plane and the degenerate conic envelope spanned by the image of circular points (ICPs). Based on this projective equation, we propose an easy technique to <b>calibrate</b> the <b>focal</b> <b>length</b> and the extrinsic parameters of a camera merely by using one perspective view of two arbitrary coplanar circles. Unlike existing optimization algorithm, our method offers a closed form solution through simple matrix manipulation. Experimental results verify the correctness and efficiency of our proposed technique. 1...|$|R
40|$|This paper {{addresses}} {{the problem of}} recovering the 3 D shape of a surface of revolution from a single uncalibrated perspective view. The algorithm introduced here makes use of the invariant properties of a surface of revolution and its silhouette to locate {{the image of the}} revolution axis, and to <b>calibrate</b> the <b>focal</b> <b>length</b> of the camera. The image is then normalized and rectified such that the resulting silhouette exhibits bilateral symmetry. Such a rectification leads to a simpler differential analysis of the silhouette, and yields a simple equation for depth recovery. Ambiguities in the reconstruction are analyzed and experimental results on real images are presented, which demonstrate the quality of the reconstruction. ...|$|R
40|$|Abstract: Camera {{calibration}} is {{an important}} step in 3 D reconstruction of scenes. Many natural and man made objects are circular and form good candidates as calibration objects. We present a linear calibration algorithm to estimate the intrinsic camera parameters using at least three images of concentric circles of unknown radii. Novel methods to determine the projected center of concentric circles of unknown radii using the projective invariant, cross ratio, and calculating the vanishing line of the circle are proposed. The circular calibration pattern can be easily and accurately created. The calibration algorithm does not require any measurements of the scene or the homography between the images. Once the camera is fully <b>calibrated</b> the <b>focal</b> <b>length</b> of zooming cameras can be estimated from a single image. The algorithm was tested with real and synthetic images with different noise levels. ...|$|R
40|$|Photogrammetric mapping using Commercial of the Shelf (COTS) cameras is {{becoming}} more popular. Their popularity is augmented by {{the increasing use of}} Unmanned Aerial Vehicles (UAV) as a platform for mapping. The mapping precision of these methods can be increased by using a calibrated camera. The USGS/EROS has developed an inexpensive, easy to use method, particularly for <b>calibrating</b> short <b>focal</b> <b>length</b> cameras. The method builds on a self-calibration procedure developed for the USGS EROS Data Center by Pictometry (and augmented by Dr. C. S Fraser), that uses a series of coded targets. These coded targets form different patterns that are imaged from nine different locations with differing camera orientations. A free network solution using collinearity equations is used to determine the calibration parameters. For the smaller <b>focal</b> <b>length</b> COTS cameras, the USGS has developed a procedure that uses a small prototype box that contains these coded targets. The design of the box is discussed, along with best practices for calibration procedure. Results of calibration parameters obtained using the box are compared with the parameters obtained using more established standard procedures...|$|R
40|$|A 1 D {{object is}} a segment with several known-distance markers, and {{calibration}} methods with 1 D objects are more flexible {{than those with}} 2 D/ 3 D objects. Under the pinhole camera model, it is proved that the calibration with free-moving 1 D objects is not possible. For a central catadioptric camera setup, can the camera be calibrated by a 1 D object under general motions? In this paper, we prove that a central catadioptric camera can indeed be calibrated, and propose a catadiop-tric camera calibration method using 1 D objects undertaking general motions. The proposed method consists of two steps. Firstly, the principal point is calculated with geometric invariants under catadioptric camera model; Secondly, we use images of 1 D object to <b>calibrate</b> the <b>focal</b> <b>lengths,</b> skew factor and mirror parameter. The method needs neither prior knowledge of catadioptric parameters nor conic fitting, and it is linear, which {{makes it easy to}} implement. Experiments demonstrate its usefulness and stability. © 2011 IEEE. IEEE; IEEE Signal Processing SocietyA 1 D object is a segment with several known-distance markers, and calibration methods with 1 D objects are more flexible than those with 2 D/ 3 D objects. Under the pinhole camera model, it is proved that the calibration with free-moving 1 D objects is not possible. For a central catadioptric camera setup, can the camera be calibrated by a 1 D object under general motions? In this paper, we prove that a central catadioptric camera can indeed be calibrated, and propose a catadiop-tric camera calibration method using 1 D objects undertaking general motions. The proposed method consists of two steps. Firstly, the principal point is calculated with geometric invariants under catadioptric camera model; Secondly, we use images of 1 D object to <b>calibrate</b> the <b>focal</b> <b>lengths,</b> skew factor and mirror parameter. The method needs neither prior knowledge of catadioptric parameters nor conic fitting, and it is linear, which makes it easy to implement. Experiments demonstrate its usefulness and stability. © 2011 IEEE...|$|R
40|$|The {{calibration}} of a line-based {{panoramic camera}} can be {{split into two}} independent subtasks: first <b>calibrate</b> the effective <b>focal</b> <b>length</b> and the principal row, and second, calibrate the off-axis distance and the principal angle. The paper provides solutions for three different methods, and compares these methods based on experiments using a superhigh resolution line-based panoramic camera. It {{turns out that the}} second subtask is solved best if a straightsegment based approach is used, compared to point-based or correspondence-based calibration methods, all already known for traditional (planar) pinhole cameras, but not yet previously discussed for panoramic cameras...|$|R
40|$|A set {{of simple}} time to contact estimators are derived, using {{isolated}} points or curve segments. For this purpose {{the use of}} both optic flow and optic acceleration is suggested. For curves it is pointed out, {{that there is no}} aperture problem present, since normal flow and acceleration of the curve segment is sufficient for estimating time to contact. Time to contact with a curve segment may be calculated without <b>calibrating</b> camera <b>focal</b> <b>length</b> and camera coordinate system, without computing spatial velocity and depth maps and without computing the complete optic flow field for the curve segment. Computational illustrations with actual camera data are reported. 1 Introduction For a moving observer various visual measures are useful, while navigating through a scene, let it be the ambulant human observer, as studied in for example (Koenderink and Doorn 1975) and (Koenderink 1976), or let it be the autonomous robot, as studied in for example (Horn 1986) and (Ballard and Brown 1982). On [...] ...|$|R
40|$|This paper {{studies the}} problem of {{determining}} the absolute pose of a perspective camera observing a scene through a known refractive plane, the flat boundary between transparent media with different refractive indices. Efficient minimal solvers are developed for the 2 D, known orientation and known rotation axis cases, and near-minimal solvers for the general <b>calibrated</b> and unknown <b>focal</b> <b>length</b> cases. We show that ambiguities in the equations of Snell's law {{give rise to a}} large number of false solutions, increasing the complexity of the problem. Evaluation of the solvers on both synthetic and real data show excellent numerical performance, and the necessity of explicitly modelling refraction to obtain accurate pose estimates...|$|R
40|$|This paper {{addresses}} {{the problem of}} recovering the 3 D shape of a surface of revolution from a single uncalibrated perspective view. The algorithm introduced here makes use of the invariant properties of a surface of revolution and its silhouette to locate {{the image of the}} revolution axis, and to <b>calibrate</b> the <b>focal</b> <b>length</b> of the camera. The image is then normalized and rectified such that the resulting silhouette exhibits bilateral symmetry. Such a rectification leads to a simpler differential analysis of the silhouette, and yields a simple equation for depth recovery. It is shown that under a general camera configuration, there will be a 2 -parameter family of solutions for the reconstruction. The first parameter corresponds to an unknown scale, whereas the second one corresponds to an unknown attitude of the object. By identifying the image of a latitude circle, the ambiguity due to the unknown attitude can be resolved. Experimental results on real images are presented, which demonstrate the quality of the reconstruction. © 2004 Elsevier B. V. All rights reserved. postprin...|$|R
5000|$|... 1.Purchase 2 sets of 2 lenses with {{different}} <b>focal</b> <b>lengths</b> f1 and f2 (4 lenses total, 2 with f1 <b>focal</b> <b>length,</b> and 2 with f2 <b>focal</b> <b>length).</b>|$|R
5000|$|... is the {{objective}} <b>focal</b> <b>length</b> and [...] is the eyepiece <b>focal</b> <b>length.</b>|$|R
50|$|Quoted 35 mm {{equivalent}} <b>focal</b> <b>lengths</b> typically ignore {{depth of}} field (DOF), which depends on both <b>focal</b> <b>length</b> and aperture. The perceived DOF of smaller sensors is deeper due to the shorter <b>focal</b> <b>length</b> lenses.|$|R
50|$|The two {{fundamental}} parameters of an optical lens are the <b>focal</b> <b>length</b> and the maximum aperture. The lens' <b>focal</b> <b>length</b> determines the magnification {{of the image}} projected onto the image plane, and the aperture the light intensity of that image. For a given photographic system the <b>focal</b> <b>length</b> determines the angle of view, short <b>focal</b> <b>lengths</b> giving a wider field of view than longer <b>focal</b> <b>length</b> lenses. A wider aperture, identified by a smaller f-number, allows using a faster shutter speed for the same exposure.|$|R
5000|$|... #Caption: How <b>focal</b> <b>length</b> affects perspective: Varying <b>focal</b> <b>lengths</b> at {{identical}} field size {{achieved by}} different camera-subject distances. Notice that the shorter the <b>focal</b> <b>length</b> {{and the larger}} the angle of view, perspective distortion and size differences increase.|$|R
5000|$|The {{multifocal}} spots {{location is}} a function of refractive <b>focal</b> <b>length</b> fRefractive and predetermined diffractive <b>focal</b> <b>length</b> fDiffractive The <b>focal</b> spot at the [...] "zero" [...] order refers to the refractive <b>focal</b> <b>length</b> of the lens being used.|$|R
5000|$|... #Caption: Some {{manufacturers}} {{provide both}} the real <b>focal</b> <b>length</b> and the 35 mm equivalent <b>focal</b> <b>length</b> ...|$|R
50|$|The narrowness of {{the band}} of colors that a {{monochromator}} can generate {{is related to the}} <b>focal</b> <b>length</b> of the monochromator collimators. Using a longer <b>focal</b> <b>length</b> optical system also unfortunately decreases the amount of light that can be accepted from the source. Very high resolution monochromators might have a <b>focal</b> <b>length</b> of 2 meters. Building such monochromators requires exceptional attention to mechanical and thermal stability. For many applications a monochromator of about 0.4 meter <b>focal</b> <b>length</b> is considered to have excellent resolution. Many monochromators have a <b>focal</b> <b>length</b> less than 0.1 meter.|$|R
5000|$|The {{effective}} <b>focal</b> <b>length</b> {{is nearly}} {{equal to the}} stated <b>focal</b> <b>length</b> of the lens (F), except in macro photography where the lens-to-object distance {{is comparable to the}} <b>focal</b> <b>length.</b> In this case, the magnification factor (m) must be taken into account: ...|$|R
25|$|A device which {{produces}} converging or diverging light rays due to refraction {{is known as}} a lens. Lenses are characterized by their focal length: a converging lens has positive <b>focal</b> <b>length,</b> while a diverging lens has negative <b>focal</b> <b>length.</b> Smaller <b>focal</b> <b>length</b> indicates that the lens has a stronger converging or diverging effect. The <b>focal</b> <b>length</b> of a simple lens in air is given by the lensmaker's equation.|$|R
40|$|Accurate {{estimation}} of effective camera <b>focal</b> <b>length</b> {{is crucial to}} the success of panoramic image stitching. Fast techniques for estimating the <b>focal</b> <b>length</b> exist, but are dependent upon a close initial approximation or the existence of a full circle panoramic image sequence. Numerical solutions of the <b>focal</b> <b>length</b> demonstrate strong coupling between the <b>focal</b> <b>length</b> and the angles used to position each component image about the common spherical center. This paper demonstrates that parameterizing image position using distance over the sphere surface instead of angles effectively decouples the <b>focal</b> <b>length</b> from the image position. This new parameterization does not require an initial <b>focal</b> <b>length</b> estimate for quick convergence, nor does it require a full circle panorama in order to refine the <b>focal</b> <b>length.</b> Experiments with synthetic and real image sets demonstrate the robustness of the method and a speedup of 5 to 20 times over angle based positioning...|$|R
25|$|The <b>focal</b> <b>length</b> f is {{positive}} for converging lenses, and negative for diverging lenses. The reciprocal of the <b>focal</b> <b>length,</b> 1/f, is the optical {{power of the}} lens. If the <b>focal</b> <b>length</b> is in metres, this gives the optical power in dioptres (inverse metres).|$|R
50|$|The guide telescopes are 180 mm diameter/2300 mm <b>focal</b> <b>length</b> and 80 mm diameter/1200 mm <b>focal</b> <b>length</b> refracting telescopes.|$|R
5000|$|... where [...] is the <b>focal</b> <b>length</b> of the {{objective}} lens and [...] is the <b>focal</b> <b>length</b> of the eyepiece.|$|R
5000|$|... wherefo = {{original}} <b>focal</b> <b>length</b> of telescope,d = {{distance from}} telecompressor to image plane, andfr = <b>focal</b> <b>length</b> of telecompressor.|$|R
5000|$|... 3.6× optical zoom, Carl Zeiss T* Vario Sonnar lens (28-100 mm 35mm {{equivalent}} <b>focal</b> <b>length</b> range mm actual <b>focal</b> <b>length)</b> ...|$|R
50|$|Zoom ring: This {{control is}} found on most EF zoom lenses. It {{is used for}} {{changing}} the <b>focal</b> <b>length</b> of the lens. The zoom ring usually has certain, common, <b>focal</b> <b>lengths</b> marked on it. To set the zoom ring to any given <b>focal</b> <b>length,</b> one must turn the ring so that the marked <b>focal</b> <b>length</b> matches the zoom index. The zoom index is typically a white, or black, line found next to the zoom ring.|$|R
50|$|One can {{see that}} if {{magnification}} remains constant, a longer <b>focal</b> <b>length</b> results in a smaller axial magnification, and a smaller <b>focal</b> <b>length</b> a larger axial magnification. That is, when using a longer <b>focal</b> <b>length</b> while moving the camera/lens away from the object to maintain the same magnification M, objects seem shallower, and the axial distances between objects seem shorter. The opposite-- increased axial magnification -- happens with shorter <b>focal</b> <b>lengths</b> while moving the camera/lens towards the object.|$|R
5000|$|Small maximum aperture: {{it is not}} {{feasible}} to make long <b>focal</b> <b>length</b> lenses with the wide maximum apertures available with shorter <b>focal</b> <b>lengths.</b>|$|R
50|$|According to CIPA guidelines, 35 mm {{equivalent}} <b>focal</b> <b>length</b> is to {{be calculated}} like this:“Converted <b>focal</b> <b>length</b> into 35mm camera” = (Diagonal distance of image area in the 35mm camera (43.27mm) / Diagonal distance of image area on the image sensor of the DSC) × <b>focal</b> <b>length</b> of {{the lens of the}} DSC.|$|R
50|$|Magnification increases, therefore, {{when the}} <b>focal</b> <b>length</b> of the {{eyepiece}} is shorter or the <b>focal</b> <b>length</b> {{of the objective}} is longer. For example, a 25 mm eyepiece in a telescope with a 1200 mm <b>focal</b> <b>length</b> would magnify objects 48 times. A 4 mm eyepiece in the same telescope would magnify 300 times.|$|R
5000|$|The {{intrinsic}} matrix [...] contains 5 intrinsic parameters. These parameters encompass <b>focal</b> <b>length,</b> {{image sensor}} format, and principal point. The parameters [...] and [...] represent <b>focal</b> <b>length</b> {{in terms of}} pixels, where [...] and [...] are the scale factors relating pixels to distance and [...] is the <b>focal</b> <b>length</b> in terms of distance.|$|R
5000|$|... #Caption: In this {{computer}} simulation, adjusting the angle and <b>focal</b> <b>length</b> {{of a camera}} lens while keeping the subject in frame results in vastly differing images. At <b>focal</b> <b>lengths</b> approaching infinity, the light rays are nearly parallel to each other, resulting in the subject looking [...] "flattened". At small <b>focal</b> <b>lengths,</b> the subject appears [...] "foreshortened". (Note that the distance measurement displayed in the image is the camera's distance, in meters, from the subject, not its <b>focal</b> <b>length.</b> But the principle still applies.) ...|$|R
5000|$|The <b>focal</b> <b>length</b> can be {{determined}} by a suitable parameter transformation (which {{does not change the}} geometric shape of the parabola). The <b>focal</b> <b>length</b> is ...|$|R
